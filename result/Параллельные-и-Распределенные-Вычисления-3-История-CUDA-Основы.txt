Всем доброго дня, мы с вами, да, тут это кажется очень смешным, но все-таки где-то минут 15, но в целом, как говорится, мы строили-строили и наконец построили.
Вот, мы с вами сегодня начинаем проходить блог, посвященный вычислением на видеокартах,
и наша цель вообще будет познакомиться с тем, а как в сферах параллельных вычислений пришло понятие видеокарта и графические вычисления.
Да, потому что, ну, кажется, для чего обычно нужны видеокарты? Ну, классическая, а? В игры играть, да.
Ну, вот почему, как ни странно, вот компания Nvidia, вот, кстати, недавно вышел буквально отчет финансовый за 2023 год, они порвали все рекорды.
Свои, и котировки акций Nvidia выросли там еще на 15-20%. То есть, это там реально тузымун, если посмотреть на котировки акций Nvidia, то это прям явно видно.
Но на самом деле компания Nvidia, если так честно говорить, она сейчас зарабатывает не только за счет того, что продают видеокарты, но она вообще предоставляет разные решения, связанные с искусственным интеллектом.
Поэтому, так или иначе, сейчас программирование на видеокарте очень полезно в концепции обработки больших объемов данных, ну, и вообще процессирование этих объемов данных.
Поэтому важно, как минимум, в основе понимать, каким образом происходит программирование на вот этих устройствах.
Вот, и самое главное про инструмент, который используется в данном кейсе, это инструмент под названием CUDA.
Значит, я еще введу аббревиатуру понятия CUDA. Вот, наша сегодня цель будет понять в том, в чем состоит история этого процесса, и разобрать основные концепции для того, чтобы на первых семинарах вы уже спокойно могли с этими концепциями работать.
Давайте как раз начнем. Что мы узнаем сегодня на сегодняшней лекции? Во-первых, мы сегодня поймем, чем же процессор отличается от видеокарт.
Во-вторых, вспомним, что такое закон Мура, и поймем, почему он в оригинальной постановке, так сказать, которая обычно считается неверной, работает до сих пор для видеокарт.
Для центральных процессоров классический закон Мура сейчас не работает.
Значит, как ускорять программы на видеокарте? Ну, собственно, это цель того, посмотреть, каким образом это все работает.
И последняя вещь, мы поймем с вами, как использовать всю мощность на видеокарте. Почему это важно?
Потому что, когда мы говорим с вами про обработку на видеокарте, то оказывается, что у нее модель вычислений немного другая по сравнению с центральным процессором.
И это необходимо учитывать для работы. То есть, если вы кажется, что, ну, вот сейчас мы с вами все распараллели, грубо говоря, на тысячу потоков, у нас будет ускорение в тысячу раз.
Ну, вообще, это неправда. Если вы попробуете распараллелиться на ГПУ ровно так же, как на ЦПУ, то вас постигнет фиаско.
Вы ускоритесь не в тысячу раз, а раз, ну, не знаю, раз в двадцать от силы. То есть, как бы законом ДАЛа пойдет гулять лесом. Вы знаете, что такое законом ДАЛа?
В этом мире.
Да, вроде говорили. Это максимальное ускорение, которое можно получить в программе.
Да, в зависимости от числа потоков и доли программы, которая выполняется последовательно.
Вот, хорошо. Значит, давайте поймем, вообще, с чем мы с вами работаем.
И что такое ГПУ? Значит, ГПУ расшифровывается как Graphic Processing Unit.
Если мы говорим про обычные задачи, то они обычно выполняются у нас на ЦПУ. Что такое ЦПУ?
Это Центровый Процессинг Unit. Это электронная схема, которая необходима для того, чтобы вы производите операции в произвольной компьютерной программе.
То есть, любое действие, которое вы по умолчанию делаете на вашем компьютере, так или иначе выпускается в набор регистров.
И там по факту есть язык Assembler, в котором мы стараемся транслировать все команды.
Понятно, что на уровне процессора у нас с вами, помимо Assembler, есть микрокод.
Это такое устройство, которое умеет транслировать команды Assembler в внутренней инструкции процессора.
Но зачастую вы не имеете понятия, каким образом устроен микрокод.
То есть, ваша цель просто ввести к программе Assembler, а дальше ЦПУ в режиме конвейерности будет решать, что именно делать.
Так, вопрос такой. Понятие конвейера, знаете, это такое последствие действия, в котором нам говорится, что операции должны идти в строго определенном порядке.
И, собственно, у самого ЦПУ есть несколько вычислительных частей, несколько очередей, через которые этот конвейер может быть сделан.
Да, представьте себе кейс. Мы делаем какую-нибудь машину.
Понятно, что у нас с вами одна часть, один отдел, допустим, строит корпус, другой отдел красят его.
Понятно, что эти действия выполняются последовательно, но в принципе параллельно двумя разными командами можем делать разные действия.
То есть, одни собирают машину, другие, допустим, ее красят.
В итоге мы получаем некоторую цепочку действий, в которой это все работает достаточно быстро.
Так, а на доске ничего не видно, да?
То есть, вот она у нас в две стадии. Это сборка и покраска.
Понятно, что мы тогда можем сделать вот такой конвейер.
Вот, и это все делать в момент времени Т. То есть, у нас две разные команды могут заниматься одной и той же параллельной сборкой нескольких машин.
В центральном процессоре мы этого с вами не видим, а вот на графических ускорителях это можно увидеть, но правда связано с обработкой памяти.
Так, значит, что такое Graphic Processing Unit? Это, на самом деле, обычно специально электронная схема, которая необходима для того, чтобы выводить изображение на экран.
Процедура отрисовки объектов на экране называется рендерингом.
И, значит, если мы говорим про Graphic Processing Unit, то в нашем, так сказать, обиходе в русском языке есть некоторое другое понятие, которое заменяет понятие Graphic Processing Unit.
Как мы это называем?
Да, это мы называем видеокартой.
Конечно, то есть у нас по факту есть отдельное устройство, и мы его называем видеокартой.
Вот, и давайте вот детально представим себе, значит, как у нас выглядит обычная видеокарта.
Кто-нибудь видел?
Ну, давайте я открою, наверное, какие-нибудь рендеры.
Так. Ну, давайте посмотрим какой-нибудь процессор. Какой вам процессор больше нравится, Intel или AMD?
Блин. А, давайте какой-нибудь Ryzen, открою, 9.
И посмотрим, как они выглядят. Так, давайте мне без коробки.
Вот, смотрите, то есть, ну, допустим, вот выглядит процессор вот таким вот образом.
То есть, это именно такой чип, он обычно занимает немного места.
Вот, и там по факту он вставляется в материнскую плату, и дальше мы, собственно, к нему подключаем некоторый набор вентиляторов.
Ну, то есть, кажется, устройство приблизительно вот такое.
Там вместе со слотом материнской плати оно занимает немного места.
Ну, что, давайте теперь откроем видеокарту. Какую откроем?
Ну, давайте, допустим, RTX.
4090.
Не знаю, видно ли объемы или нет.
О, ну, давайте вот какую-нибудь сборку компьютера.
Так, откроем, откроем сайт. Я надеюсь, что тут позволит нам это.
Значит, смотрите, теперь, чтобы вы понимали все по объемам.
Да-да-да-да-да, спасибо, спасибо, что предлагаете мне это купить.
Значит, вот видите, вот это вот, то, что я на экране вывожу, это у нас вот такая вот коробочка.
Вот это центральный процессор.
Вот, собственно, поверх него привязана помпа, и справа от него видно вентиляторы.
А теперь вот это, видите, вот параллельно сбоку еще одно устройство.
Называется GeForce RTX.
Оцените размеры.
Ну, то есть, это такая бандура, на ней висит три вентилятора.
Вот, и она еще сама занимает три слота PCI-Express.
Выводы информации.
То есть, по факту, вы классический компьютер, вряд ли его поставите больше, чем две.
Вот, а если вы захотите поставить три видеокарты, то вам придется сделать приблизительно то же самое, что мне в свое время пришлось сделать.
Идти в магазин, арендовать дрель и просверливать дырку для системного блока.
Да, потому что системный блок у меня железный.
Ну, вот такой вот аспект, то есть понятно, что оно занимает очень-очень много места.
Ну, понятно, что большая часть из этого вентилятора, но в принципе, вот такая вот плашка.
Что мы с вами из этого можем сказать?
Что видеокарты и центральные процессоры сейчас выглядят по-другому.
По-разному совсем.
Но это было далеко не всегда так.
Были времена, когда центральные процессоры и видеокарты выглядели одинаково, приблизительно.
Давайте поймем почему.
Для этого нам нужно отмотаться, поверьте, где-то на 40 лет назад.
40 лет назад.
Да, 80-е годы.
Представьте себе, живем мы в 80-х годах.
И у нас есть замечательное устройство.
Ну, на самом деле, если мы живем, так сказать, на Западе, то у нас есть,
как раз, такое устройство, как Nintendo Entertainment System.
Значит, она у нас есть, как раз, такое устройство, как Nintendo Entertainment System.
Значит, она до нас доехала в 90-е годы, и это приставка Dendy.
Возможно, слышали про такое.
Вот, давайте как раз разберем характеристики этого устройства и поймем,
на самом деле, сколько нам нужно информации прогонять за единицу времени
для того, чтобы отрисовывать изображение на экране.
То есть, какой рендеринг нам нужен.
Значит, давайте оценим, сколько ресурсов вообще занимает 2D отрисовка объекта.
Значит, для этого нам нужно понять, что у нас с вами есть количество пикселей.
Да, сразу скажу, что игрушки были плоскими.
То есть, не было никакого 3D тогда.
То есть, это всякие новомодные технологии, их еще тогда не было.
Значит, давайте посмотрим внимательно на экране.
На экране тот, который я сейчас нарисую на доске.
У нас изображение.
У нас есть ширина.
У нас есть высота.
Сейчас мы понимаем с вами, что у современных мониторов ширина это 1920 в пикселях,
высота 1080 в пикселях.
Но, когда были 80-е годы, то ширина была 320, а высота 240.
И то, если повезет.
То есть, иногда еще меньше объема.
Вот, значит, сколько цветов могло храниться в одном пикселе?
Сейчас мы понимаем с вами, что у современных мониторов ширина это 1920 в пикселях,
высота 1080 в пикселях.
И мы понимаем с вами, что у нас на хранение каждого пикселя отводится 32 бита.
Ну, либо 64 бита.
Это, собственно, RGB.
8, 8, 8.
Ну, иногда еще, считая так, анал.
Значит, в тех приставках вообще было 8-битное разрешение экрана.
То есть, у нас как бы один пиксель занимал 8 бит.
Так, хорошо.
То есть, что у нас получается?
Значит, для отрисовки одного пикселя, одного экрана, сколько нам нужна информация?
Что нам нужно сделать с этими всеми числами?
Да, теперь у нас получается объем.
Это 320 на 240 на, давайте, один байт сразу же.
Значит, это сколько мы перегоняем с вами, точнее, за один кадр per frame.
А теперь как оценить объем?
Информация, которую нам необходимо перегнать за одну секунду.
Ложь на FPS.
Надо вот эту величину.
Умножить на frame per second.
Значит, тут нужно сказать сразу, что несмотря на то, что тогда частотность была 24 кадра в секунду, либо 25 кадра, либо 30 кадров в секунду.
На самом деле у нас есть два буфера.
Точнее, у нас кадр состоит из основного экрана и буфера, который отрисовывается.
Да, поэтому нам на самом деле нужно в два раза больше ресурсов для отрисовки.
Ну, можно считать так, что все равно некоторые, если посмотреть приставки, которые отрисовывают изображение, все равно они старались соблюдать частоту кадров, либо 50 кадров в секунду, либо 60 кадров в секунду.
Еще в те времена.
Поэтому давайте мы оцепим по минимуму это все дело и скажем, что у нас будет 50 frame per second.
Frame per second.
Здесь у нас было делить на frame.
Размерности сокращаются.
Так, тут byte получается.
И сколько это у нас выходит?
А мы считаем, что включаем на каждую длину одна америка?
А, да.
Да, да, да, да.
То есть у нас получается, каждый пиксель отрисовывается восьми битами.
Восемь бит – это один byte.
Так.
Да, да, да.
Да, да.
А?
Ну, понятно, что там есть статические картинки и так далее.
Понятно, что там надо смотреть в ресурсы процессора.
По-хорошему говоря.
То есть мы оцениваем прикидочно припады.
Ну, давайте посчитаем.
Сколько это будет у нас?
320 на 240?
Ну...
Ну...
366 мегабайтами в самом деле.
Понятно, что если мы отрисовываем 25 кадров в секунду, то получаем где-то 108-109 мегабайт в секунду.
Ну, вроде я нигде не обманулся счетом.
А теперь давайте поймем, приблизительно какой объем информации мы можем перегонять в единицу времени.
Здесь делается еще одно крайне неточное допущение, поскольку память и центральный процессор – это все-таки разные.
Давайте будем считать, что приблизительно за один такт мы будем перегонять один байт информации.
Понятно, что это неправда, но если говорить про битность процессоров, вроде это совпадает.
То есть, приблизительно для того, чтобы отрисовать этот объем, нам нужно порядка 2-4 мегагерца иметь частоту процесса.
Опять же, это грубые оценки.
Так, ну теперь смотрите, если мы пойдем в Google, спросим следующий запрос, мощность процессора Dendy, то что мы с вами увидим?
1 вольт 7 мегагерц. То есть, в принципе, мы попадаем в ту оценку, которая у нас есть для центральных процессоров.
То есть, в принципе, за отрисовку изображения можно использовать классический центральный процессор для отрисовки 2D объектов.
Хорошо, так, это понятно?
Это грубая оценка, потому что там были спрайты, то же самое приставки Dendy, Dt, Dt.
Коны были статическими, ну и так далее. То есть, есть достаточно большое ограничение на ресурс.
Итак, значит, а если мы говорим про более широкие разрешения, то VGA-экран появился там в 1987 году, и разрешение у него стало 640 на 480.
То есть, как бы тогда появилось все. Кажется, что, вот, типа, тут так, может процессор Dendy у меня указан неверно, значит, оно на самом деле два раза меньше.
То есть, 2D все хорошо. Так, а давайте подумаем, что у нас произойдет, когда мы из 2D в 3D перейдем?
В чем будет отличие? Значит, это будет уже не в 80-е годы, это уже будут 90-е годы.
Давайте прикинем. Значит, теперь у нас чистота будет, как ни странно, 32 пито.
То есть, нам как бы появилась полная цветовая гамма. Раз, ну может быть, не совсем полная.
Значит, разрешение экрана увеличилось в 640 на 480. Могло увеличиться. Так, хорошо.
А теперь, даже если мы сейчас подставим, то у нас получается, смотрите, X2, X2, X4, то есть у нас получается X16 от этого объема, ну и это уже, кажется, в 50 мегабайт в секунду.
Ну, кажется, что, в принципе, не сильный рост, но здесь мы забываем учесть один важный фактор. Какой?
Как понять, как пиксели выводить? Да, как понять, какой пиксель выводить? Для этого что нам нужно сделать?
Да, смотрите, что-то спровицировать. То есть, как минимум, нам нужно взять какой-то трехмерный объект и его обсчитать.
А если мы предполагаем, давайте прикинем следующую вещь, что у нас трехмерный объект будет сферическим.
С учетом того, что вся 3D-графика отрисовывается треугольничками, то количество треугольников, ну они маленькие достаточно, можем оценить приблизительно опять же сверху, как площадь фигуры.
Понятно, что у нас есть квадратные, которые достаточно просто отрисовываются, но вот сферообразные, у нас сегодня какая-то проблема.
А чему ровняется площадь сферы? Ну, не 6, а 4 пиро-квадратные.
Ну, не 6, а 4 пиро-квадратные.
Кажется, пора снова на вышмате учить вычислять фигуру.
Ну вот, да. Ладно. Сколько это приблизительно будет?
Ну, r квадрат нам не важен, нам нужно понять вот этот коэффициент. Ну, где-то 12,5.
То есть, вот эту штуку нам по факту еще нужно будет умножить на где-то 12,5.
Да. Ну, смотрите, нам нужно, значит, вычислительным мы рисуем сферу. Каким-то образом она у нас вращается, она представим себе такая разноцветная, то есть у нее какой-то градиент есть.
Вот. И нам нужно каждый раз вычислить, какой цвет нам нужен для этой сферы. Ну, для спроецировать экран в часть сферы.
То есть, нам нужно обсчитать все треугольники, которые у нас имеются, которые водятся на экран.
Ну, да, половина. Ну, как, нам нужно понять, для половины объектов сферы находятся они внутри или нет, половину отрисовать.
Картинка меняется динамически каждую секунду. Ну, сфера вращается у нас.
Ну, это понятно. Не-не-не, это уже чудеса оптимизации происходит, и про чудеса оптимизации как раз и получается.
Почему некоторые игры, которые были тогда в PS1, они реально выглядели достаточно круто, несмотря на ограничения по ресурсам.
Да, да, да. Ну, еще плюс порядка. Ну, да, да, да. Вот. Ну, на самом деле, с оптимизациями константа будет реально порядка 50-100 мегабайт в секунду.
Вот. Без оптимизации это получается где-то 600-700 мегабайт.
Вот. И что у нас получается? Смотрите, то есть вот такой объем информации нам нужно перегонять за секунду. Ну, если грубо прикидывать.
Хотите вас обратно, как вы думаете, какая мощность процессора была у приставки PS1?
Тут тоже определенные вычисления были. Мощность процессора PlayStation 1.
То есть частота процессора не выросла в порядке. То есть нам нужен был скачок. Но порядка, у нас произошел скачок только на один порядок.
То есть мы не успеваем вывозить разрешение на экран. Ну, и тогда смотреть. Классический пример. Давайте сделаем следующее.
Посмотрим на вот эту игру и посмотрим на картинки. Не знаю, вот к примеру. Так, это In Unity какой-то.
Ну вот, смотрите. Открою картинку. Вот так выделила игрушка Crash Bandicoot в 90-е годы. То есть видно какие-то очень грубые фигуры.
И как выглядит она сейчас на перезапуске. То есть тогда мощность центрального процессора просто не хватало для того, чтобы это отрисовывать.
Поэтому старались максимально все оптимизировать. И из-за этого переход из 2D в 3D оказался, ну, некоторые игры просто, так сказать, потеряли свой шарм при переходе от 2D в 3D.
То есть у вас была красивая картинка, грубо говоря. Тот же самый Марио бегает, прыгает, прыгает, все хорошо. Да, вы переходите на 3D и у вас какая-то кашель на экране.
Понятно, что это людям не нравилось. Вот. И здесь как раз возникает первый фазовый переход.
Который заключается в том, что некоторые компании решили как раз заняться тем, а что если мы вместо классической видеокарты будем к ней подключать, которые будут чисто заниматься отрисовкой изображений на экран.
Вот. И так появилась компания 3DFX, и у нее был графический ускоритель по имени Voodoo. Значит, здесь скриншот с сайта, собственно, 3DFX Historia.
И слева мы видим изображение с вами игры без графического ускорителя Voodoo, справа с графическим ускорением Voodoo. То есть левая рендерилась на CPU, правая рендерилась на обновленный GPU.
Разница видна?
Нет.
Понятно.
Ну, на самом деле просто деталь стала отрисовываться намного больше, и фигурки стали на более платье.
Честно, я почему это привожу, потому что я сам с этим столкнулся. Правда, тогда уже Glide не был, это в 2005-2006 году стоял, но как бы был специальный патч, который позволял отрисовать, перейти в поддержку Glide.
Ну, реально игра стала совсем другой. Вот. Ну, кажется, что все замечательно. Есть компания 3DFX, есть графический ускоритель Voodoo.
Вопрос. Вы сейчас в первый раз услышали про этот графический ускоритель?
Да.
Да, а это значит, что что-то с ним произошло.
Значит, компания 3DFX начала выпускать графический ускоритель Voodoo, Voodoo 2, Voodoo 3.
Более того, такая популярная игра, как Quake 3 в свое время, она просто без Glide нормально не запускалась.
Ну, и компания сказала, значит, здрасте. Мы такие, ура, у нас все идет в гору, все замечательно, мы живем в шоколаде.
Но это был конец 90-х, начало нулевых годов, а в то время как раз был этот, крах.ком.
То есть, когда все IT-компании реально повалились в цене и в итоге нужно было выживать каким-то образом.
А более того, помимо компании 3DFX появились новые компании.
Значит, первая компания это компания Nvidia. Она как раз тогда набирала обороты.
Это 2000 год. Они сделали следующую вещь. Это создатели шейдеров.
То есть, что такое шейдер? Это программированные модули для вычисления световых характеристик или цветовых характеристик.
То есть, свет, это отражение света падает, который у нас свет, это отрисовка разных экранов, разных цветов, текстуры наложить.
И появилась вторая компания, которая называется Silicon Graphics.
Она по факту создала стандарт под названием OpenGL, Open Graphical Language.
И на самом деле, до где-то 17-19-го года, это был стандарт de facto для отрисовки графики.
То есть, у вас появляется интерфейс, в котором вы можете работать независимо от видеокарт.
Ну и, собственно, они дали API для этого доступа.
И компания 3DFX была встала в обороты, поскольку проект был достаточно приоперитарным и не замечал конкурентов.
В итоге, что произошло?
Произошло следующее исторически.
Значит, компания 3DFX была выкуплена компанией NVIDIA за гроши.
Реально за гроши.
После этого компания Silicon Graphics тоже была продана, по-моему, компанией ETI.
А компания AMD потом выкупила компанию ETI.
То есть, в итоге сейчас у нас есть два крупных производителя видеокарт.
Это NVIDIA и AMD.
Вот такая вот история.
У нас появились с вами шейдеры, которые позволяют отрисовывать изображение на экран.
То есть, программирование модуля.
Это значит, что у нас есть всякие функции, которые мы с вами можем использовать.
И давайте посмотрим, чтобы понимать, что мы хотим сделать.
Мы хотим, чтобы у нас программы быстро работали.
Пока что у нас какой-то графический язык и непонятно вообще, как это связано.
Для этого нам нужно посмотреть то, каким образом рендерится экран в OpenGL.
То есть, у нас с вами есть два шейдера.
Первый называется Vertex Processor, который, по факту, позволяет вам построить изображение.
Дальше построить точки в пространстве по определенным координатам.
Делать какие-то геометрические преобразования.
Дальше у вас есть Rasterizer, который, по факту, вы берете границы, он, так сказать, выстраивает фигуры.
То есть, у вас есть каркас, вы каркас заливаете.
Дальше у вас есть Fragment Processor, который позволяет вычислять цвет.
И после этого, значит, фрагменты у нас мерзнутся на экран и проецируются.
То есть, как минимум, у нас с вами появляются проецированные модули, которые можно использовать.
Вот. И после этого у нас на выходе получается экран.
Все замечательно. Но здесь, как говорится, все не без интересных вещей.
А программируемые модулями, ну и вообще, вся операция по работе с графикой делается в преобразованиях матрицы 4 на 4.
Не матрицы 3 на 3.
Как вы думаете, почему?
А?
Не, не, не. Не по этой причине.
Да, однородные координаты.
То есть, смотрите, у нас получается так, что мы работаем с вами, когда мы говорим с графикой, не в евклидовой геометрии.
Потому что если бы мы работали в классической евклидовой геометрии, то у нас были бы преобразования в вида матрицы 3 на 3.
Мы работаем с вами в проективной геометрии.
Почему это важно?
Мне кажется, у нас сегодня урок в физике.
Итак.
Извините, пожалуйста, те, кто физику не любят.
Но для понимания процесса нам это нужно.
Так, смотрите.
Ну, так обычно делают, когда говорят, что давайте мы теоретическую механику скроем и назовем математической физикой.
Вот.
Значит, смотрите, я рисую вот такой замечательный объект.
И рисую вот тут вот такую вот штуку.
Собственно, догадайтесь, что это такое.
Линза, да.
Собственно, когда мы работаем в графике, мы на самом деле смотрим все сквозь поверхность некоторых линз.
Значит, что у нас происходит?
Когда мы пускаем пучок параллельных прямых, то что мы знаем с ней?
Вот эти пучки.
Куда они?
Фокус, да.
То есть смотрите, что у нас получается.
У нас получается, что пучок параллельных прямых при прохождении через линзу пересекается с фокусом.
А это означает, что если прямые пересекались здесь, то прямые, которые были здесь...
Замеряли?
Нет.
Не, в проективной геометрии я говорю.
Тоже должны пересекаться.
То есть как бы, смотрите, у нас две прямые пересекаются.
Первая постула от проективной геометрии, что любые две прямые пересекаются.
Если здесь они пересекались вот так, то значит, где они здесь пересекаются?
Да, где-то в бесконечности.
Опять же, формула для нахождения расстояния, это нам тоже говорит.
То есть если мы в качестве f поставим f, то мы получим равновесие бесконечности.
То есть здесь все четко.
Так, формула для нахождения расстояния в линзе.
Мы вообще понимаем, почему у нас матрицы преобразования 4 на 4 должны быть.
Да, вот.
Вот, смотрите, вот у нас были прямые до преобразования.
После преобразования они пересеклись в фокусе.
Значит, до преобразования они должны были пересекаться в какой-то точке.
Аксиома геометрии такая.
То есть мы вводим новую геометрию, которая называется проективной,
в которой говорим, что любые две прямые должны пересекаться.
Ну, преобразование должно сохранить свойство пересечения прямых.
Расскажи это вот этому товарищу, который снимает.
Он же пропускает всю информацию через линзу.
И он фокусирует пучок параллельных прямых в одну точку на экране.
Да, да, да, мы хотим проецировать это на плоскость, да.
Вот.
То есть смотрите, что у нас получается.
У нас любые две параллельные прямые должны пересекаться.
В некоторые точки.
Значит, эта точка называется бесконечно удаленной точкой.
Это постулаток проективной геометрии.
Но при этом, смотрите.
Что у нас происходит, если мы пустим вот другой пучок параллельных прямых?
А?
Они пересекутся на фокальной плоскости.
Угу.
Ну, вот.
've changed course.
Ой,ange it expressed.
А что мы можем сказать про вот эту точку А.
И вот эту точку Б?
Они на одной прямой лежат.
Но они лежат на фокальной плоскости.
Значит, смотрите, если точки у нас лежат
на фокальной плоскости, на одной плоскости.
То и то при образовании они должны лежать на одной и той же плоскости.
На бесконечно удаленной.
что все бесконечно удаленные прямые, все бесконечно удаленные точки лежат на бесконечно удаленной прямой в случае 2D и на бесконечно удаленной плоскости в случае 3D.
Вот аксема проективной геометрии. А теперь смотрите, какие чудеса. Чудеса заключаются в том, что всю вот эту геометрию можно зашить при помощи как раз однородных координат.
То есть, любая точка в проективной геометрии может представляться в виде пары x, y, z, t, где у нас есть эквалютное преобразование.
То есть, любое домножение всех координат на альфу приводит нас к однородности.
Значит, каким образом зашить в эту геометрию теперь бесконечно удаленную прямую и не бесконечно удаленную прямую?
Значит, если мы говорим, что нам нужна бесконечно удаленная прямая, то мы полагаем t равное нулю.
То есть, у этих объектов t равное нулю.
Значит, если мы говорим про классическую эвклидную геометрию, то в ней будет t равно единиц.
Тогда у нас все преобразования могут отнормироваться на этот коэффициент t.
Чего?
То есть, t просто отнормировано?
Да, да, t просто…
Да, бесконечно удаленную, не бесконечно удаленную.
Уже вот x, y, z, t, это тоже какая-то проективная геометрия?
Да.
Какая?
В смысле?
В плане, как кризнаты задают?
А, для этого нужно смотреть, для этого нужно посмотреть на…
Тоже пустить, так сказать, пучок, выполнить проекцию и понять, где на плоскости эта проекция будет.
Ну, чтобы было удобно с этим работать.
Да, просто накоалентность удобна и матрица преобразований из одной системы кардинат другую будет намного проще писаться.
Ну да, если мы говорим про классическую эвклидную геометрию,
да, если это не бесконечно удаленная прямая.
Да, в общем, вот такая интересная геометрия.
То есть у нас есть, смотрите, перемножение на матрицу вида 4 на 4.
И о чудо совпадения, 4 это степень двойки.
А представьте себе, что вот для математического моделирования,
ну и вообще для компьютерных всяких вычислений степень двойки это отличное число.
Да, в памяти находится хорошо и все замечательно.
Значит, а тут проективной геометрии…
Значит, тут еще показывают какие преобразования можно использовать для различных переводов.
То есть мы начинаем рисовывать объект, каким образом он рендерится на экран.
То есть здесь у нас есть несколько как раз перемножений вида проективной матрицы.
То есть все эти перемножения можно использовать для своих целей.
А теперь главный трюк.
Давайте мы будем использовать их не для того, чтобы выводить изображение на экран.
А для того, чтобы считать что-то для себя.
То есть нам не важно, что будет отрисовываться на экране.
Нам, допустим, нужно перемножить матрицу быстро.
Мы задаем нашу входную матрицу как набор точек в проективной геометрии.
Задаем проективные преобразования.
А это по факту блочное перемножение матриц.
И получаем результат, который получается на выходе относительно этих преобразований.
А?
Нет, это не то, к чему мы будем заниматься, а то, к чему мы идем.
Ну, я так скажу, наперед забегу.
Компания Nvidia увидела все это и решила сделать нормальный интерфейс.
Для всего этого.
Вот, значит, идея такая.
Давайте ничего не изображать, а использовать матрицу для вычислений.
И здесь у нас возникает концепция из классификации по Флину.
Single Instruction Multiple Data.
Значит, мы можем одну векторную инструкцию выполнять на некотором векторе значения в один такт времени.
Одной ассемлерной инструкцией.
Вот как раз, посмотрите, у нас по факту есть набор точек.
Этот набор точек нужно быстро привести проективным преобразованием в какой-то другой набор точек.
Почему бы это не сделать одной ассемлерной командой?
Просто поставить одно устройство управления на некоторый набор регистров.
Как говорится, сказано, сделано.
То есть, это у нас как раз есть в видеокарте и появился как раз специальным механизм.
Язык в то время назывался brook.
Это обертка на DAP компьютерная графика.
То есть, у нас был OpenGL, а поверх него был brook.
Точнее, поверх механизма шейдеров, которое позволяет выполнить некоторые векторные операции.
Ну, даже есть статья, которая позволяет это сделать.
API напоминаю, что это Application Programming Interface.
То есть, это тот формат, в котором мы взаимодействуем.
Вы уже, наверное, знакомы с тем, как работает MPI.
Все были на семинарах по MPI.
И вы пользовались компилятором MPiCC.
Здесь такая же была обертка, код brookCC.
Язык назывался.
Я не знаю, у меня, по-моему, даже где-то здесь должны быть исходники этого всего.
Вот они.
Собственно, это код на этом.
Исходный код brook.
Здесь, на самом деле, видно, что есть вот такой вот механизм.
Давайте откроем текстовый редактор.
Не знаю, видно ли что-то или нет.
Вот. Ну, тут есть специальные именно коды.
То есть, видите, какие-то коды.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Коды.
То есть, видите, какие-то слова, которые отличаются от классического C.
Да, смотрите, появляется ключевое слово kernel, которое обозначает, что этот набор инструкций нужно трансформировать в набор команд для видеокарт.
То есть, обычно пишутся на видеокарте ядра.
Вот.
И второе здесь дополнительное ключевое слово есть reduce.
То есть, это операция свертки.
Для того, чтобы сложить какой-то результат.
Понятно, что это все использует OpenGL runtime.
То есть, и как раз, видите, тут уже большое количество прямо было написано разных вещей.
Даже трассировка была написана.
В принципе, можно почитать исходный код, но это не наша цель, на самом деле.
Наша цель – понять вот такую вещь.
Это график производительности, который был получен на разных видеокартах в зависимости от временной шкалы.
И что мы с вами здесь замечаем?
Процессор Pentium 4, несмотря на то, что они выпускались как процессор нового поколения, мы видим, что производительность растет не сильно.
Да, но при этом код, который был написан на разных видеокартах, NVIDIA и ATI,
в каком у него рост по производительности?
Прямо порядке.
Да, порядке. То есть, смотрите, как раз у нас появляется следующее, что за какое-то обозримое время у нас скорость вычисления увеличивается в разы.
А это как раз и то, что говорит закон Moora в неверной постановке.
Что говорит закон Moora в неверной постановке?
Что за каждые два года, за каждые 24 месяца количество транзисторов в электронной схеме будет возрастать два раза.
Количество транзисторов в компьютерной схеме.
И, как ни странно, это выполняется.
Ну, возможно, сейчас уже с некоторыми ограничениями, но потому что у нас есть техпроцесс.
И сейчас, собственно, величина транзистора измеряется несколькими нанометрами.
И это уже не очень много.
А на видеокарте, как ни странно, до сих пор выполняется закон Moora, но он выполняется как раз про количество операций.
То есть, до сих пор новые версии видеокарты позволяют получить все большее и большее количество операций в секунду.
Ну, это было все в NVIDIA VTI, и компания поняла, что это золотая жила, и они решили сделать следующее.
Они решили придумать свой механизм для вычисления кода всяких механизмов на видеокарте.
Значит, смотрите, это модель шейдера.
Каким он выглядит?
Что подойдет на вход шейдера?
У нас есть некоторый набор входных регистров, через которые у нас передаются, так сказать, константы.
Типа, у нас есть точка на плоскости, и нам нужно ее отрисовать.
Покрасьте в какой-то цвет.
Значит, что в ходу можно туда присобачить?
Текстуру, которую нам нужно отрисовать.
Что такое текстура?
Это по факту обои либо цвет, который нам нужно прорисовать.
Дальше у нас есть некоторый набор констант, который мы можем зашить, и некоторый набор регистров общего назначения.
Они все подойдут в фрагментную программу, и мы получаем с вами выходные регистры.
То есть, выходные регистры это по факту...
Что там?
Для каждой точки на экране мы определяем ее цветом.
То есть, это то, как изначально пользовались эти всеми на видеокарте.
Но понятно, что таким образом мы с вами не можем работать никаким образом с массивами.
Это проблемно.
Но тогда что мы сможем с вами сделать с массивами?
Давайте мы вместо того, чтобы использовать в данной концепции входные регистры,
давайте мы передадим идентификатор нашего потока.
То есть, у нас с вами будет на вход подаваться номер потока,
который отвечает за выполнение операции, не какой-то набор значений.
А фрагментную программу переименуем в thread program.
То есть, она на входе будет принимать какое-то число,
и в зависимости от этого числа будет выполнять какую-то операцию.
Значит, давайте я спрошу.
MPI все заботали?
Хорошо.
Тогда рубрика повторяем MPI.
Когда у нас компьютер запускается в одну,
когда он из несколько процессоров запускается,
в несколько процессов запускается в общую программу,
то что назначается каждому процессу?
Да.
Этот номер обращается от rank.
То есть, у нас есть группа под названием combo,
из которой мы можем знать world size, размер группы.
И каждому процессу назначается rank ID.
От 0 до world size минус 1.
Это позволяет нам использовать концепцию single program multiple data.
То есть, мы пишем одну программу на обработку большого объема данных.
Это под концепцией multiple instruction multiple data.
В данной концепции мы говорим следующее.
Давайте вместо того, чтобы у нас был rank,
мы с вами передадим некоторую константу,
которая называет straight IDX.
То есть, у нас будет номер потоков и вещества.
На самом деле, мы можем получить элементы массива,
которые должны обрабатываться данным массивом.
Там они будут от нуля до бесконечности.
Ну, не до бесконечности, до максимального ограничения.
Сразу скажу, что это логическая абстракция.
На физическом уровне это будет немного по-другому.
Значит, у нас появляется вот такой вот номер потока,
который мы с вами, в принципе, можем использовать.
А дальше мы сделаем следующее.
Ну, понятно, что выходные регистры писать неудобно,
поэтому было бы неплохо иметь память для хранения тех ресурсов.
То есть, не дать больший контроль нашим исполнению.
То есть, вместо того, чтобы указывать,
что вот эти пиксели отрисовываются в какое-то место на экране,
давайте мы будем указывать, что именно запиши, пожалуйста,
это все вот конкретный элемент массива.
То есть, у нас будет номер потока.
То есть, мы будем required на экране.
И третий переход, который здесь был.
Это, собственно, нужно добавить разделяемую память.
Что такое разделяемая память?
Это память, которая доступна соседним элементам.
То есть, представь себе, что нам нужно посчитать какую-нибудь локальную свертку.
Вот, у нас, допустим, есть сверточный слой,
и нам нужно взять значение только соседних элементов,
но не всех элементов.
И поэтому нам нужен более, более-более большой диагноз,
быстрый доступ к соседним элементам, чем к глобальной памяти, а-ля кэш. Вот. И про что мы
будем с вами в следующий раз говорить? Мы будем говорить с вами про то, что на самом деле в
видеокарте кэш управляемый, в отличие от центральных процессоров. Вот. И в итоге вот такая вот
архитектура нам позволила сделать следующее. Она позволяет нам сказать, что есть некоторая
архитектура, которая по факту выполняется на видеокартах, но при этом уже готова к тому,
чтобы мы с вами могли обрабатывать наши массивы, наши элементы при помощи классических стандартных
операций. То есть это максимально приближено у нас получается к MPI. Вот. Но при этом мы будем
все считать на видеокартах. Значит, это называется CUDA, а расшифровывается как Compute Unified Device
with Architecture. То есть это архитектура, которая позволяет на самом деле использовать графические
ускорители от компании NVIDIA, как процессоры общего назначения. То есть вы можете написать,
смотрите, в чем особенность. Вы в принципе можете написать похожий код как на CPU, и он у нас
запустится. Правда, он будет работать сильно медленнее, но он запустится. Вот. И какая история
этой всей, этого всего процесса? А первая версия CUDA появилась 15 февраля 2007 года. То есть это сколько
лет назад? Ну уже 17, наверное. Да. То есть уже через несколько лет, вы понимаете, CUDA будет старше,
чем люди, которые будут проходить эту CUDA. Вот. А последняя версия, которая сейчас является стабильной,
это CUDA 12. Она была выпущена в 2022 году для поддержки карты RTX 40 звездочка-звездочка. Не исключаю,
что в этом году выйдет 13-я CUDA. Ну или если посчитают, что 13 это плохое число, будет выпущена
сразу 14-я версия CUDA. Ну посмотрим. Вот. И, естественно, вот эта архитектура нам позволяет каким-то
образом выполнять ускорение. Пока, правда, непонятно каким образом она это будет делать,
но сейчас мы это посмотрим. Так, есть ли вопросы? Это такое введение. История, как мы дожили до жизни такой.
Хорошо. Давайте теперь поговорим про базовые понятия, которые у нас есть в CUDA. Сейчас сразу скажу,
что будет большое количество определений, потому что архитектурно это все отличается. Первое,
что нам нужно понять, это какие виды памяти существуют в концепции CUDA. Значит, у нас,
у оперативной, на нашем компьютере есть своя собственная память, это оперативная память,
и есть память видеокарты. Это называется host memory, это наша память, нашего компьютера. И есть
device memory, это память устройства. То есть они находятся независимо друг от друга. И не поверите,
зачастую как раз указывается количество памяти, которое у нас есть на видеокарте. То есть вы открываете
какой-нибудь интернет-магазин, или идете в магазин, и у вас там написано, образно говоря, GTX 3080,
столько-то гигабайт. Это означает, сколько гигабайт у вас есть. Это оперативная память. Давайте я как
раз параллельно буду открывать. Здравствуй, Crash. RTX 3090. Ну, собственно, ценник тут понятный.
Да, игрушка недешевая. Ну, кстати, дешевле становится. Техпроцесс 5 нм, то есть это не очень много.
И вот что мы здесь видим с вами. Здесь нам нужно количество памяти. Видите, объем видеопамяти 24
гигабайт. То есть девайс memory, который мы можем алоцировать, это 24 гигабайта на видеокарте. То есть видно,
что уже на некоторых компьютерах оперативной памяти уже меньше. Вот сколько оперативной
памяти на ваших компьютерах? Ну, 8.16 у кого-то 32, у кого-то 64. То есть видно, что как бы есть разница.
То есть понятно, что память одна, девайс память другая. Так, давайте дальше. Потоки. Вот тут важная вещь.
Сейчас я буду говорить про физическую абстракцию. Поэтому, чтобы вы понимали, я обычно рисую таблицу.
Значит, у нас есть физическая абстракция и есть логическая абстракция. Мы начнем с физики.
Вот, хотя код, когда вы будете писать, вы будете говорить, мы будем говорить про логи. То есть это как
первая абстракция. Это кудоядро. Это атомная единица вычисления на видеокарте.
Вот, количество кудоядер можно посмотреть на спецификации сайта, но при этом его тоже
можно вычислить самостоятельно. Дальше следующая абстракция, которая у нас есть, это абстракция ворб.
Она состоит из набора кудо-потоков. И смотрите, в чем особенность. Особенность в том, что устройство
управления находится не в кудоядре, а находится в ворте. То есть именно здесь происходит управление
регистрами. Не здесь. При этом обычно, если мы говорим про спецификацию, у нас получается,
что на один ворб, по современным архитектурам видеокарты, 32 ворпа. То есть одно устройство
управления одновременно управляет 32 ядрами. Это означает следующее, что если у вас, допустим,
будет некоторое дивергентное поведение. Что это означает? Это означает, допустим,
что у вас на первые 16 кудоядер вы хотите отправить одну команду, а на вторые 16 ядер вы хотите
отправить другую команду. Они будут вставать последовательно. То есть первые 16 будут
обрабатывать одну команду, и вторые 16 будут ждать, пока первые 16 выполнят эту команду. Поэтому
лучше делать все эти команды плочно, чтобы все 32 кудоядра, которые находятся в одном ворпе,
выполняли одну и ту же команду. Но он так и сделает. Он сделает это в два такта.
То есть желательно, чтобы они все-таки в одном такте все это делали. Ну да, то есть у нас получается,
ну мы используем, так сказать, половину ресурсов видеокарты. Ну просто потому,
что мы делаем две операции. Хотя можно было бы, допустим, смотрите, если у вас первые 16 делают
одну, вторые 16 делают вторую, потом еще 16 делать одну и еще 16 делать вторую. Может быть, надо
поменять порядок и сделать вот так. То есть чтобы эти 32 выполняли последний, эти 32 выполняли
последний, одну операцию. То есть вот такой шаблон будет работать два раза быстрее, чем вот такой шаблон.
Ну как быстро, так сказать, они выполняют ее параллельно. Они все-таки обрабатывают чуть
медленнее, чем центральный процессор. Потому что здесь как раз одна команда будет, каждым кудоядром
будут выполняться в спецификациях в частоте. То есть у нас там, грубо говоря, центральный процессор имеет
частоту порядка 3 ГГц, то есть они могут делать 3 на 10 9 операции. Здесь они будут выполнять порядка
полутора на 10 в 9 операции в секунду, каждый отдельно, но получается за счет того, что у нас есть общий
ворб, то как бы количество операций будет умножаться на 32 в этот момент времени. Так, значит, это ворб,
да, несколько кудоядр, как и одно единое целое, выполняют. А дальше есть еще одна абфракция,
которая называется стриминг мультипроцессор. Она состоит из набора ворбов, причем наборов ворбов
в физическом исполнении. И вот здесь как раз у нас возникает одно такое интересное понятие.
Значит, в центральных процессорах, вы как понимаете, существует два типа ядер. Это физическое ядро и,
Господи, как оно еще называется? Виртуальные ядра, да. Вот SM это как раз аналог физического ядра.
Вот, если мы говорим про ворб, это больше виртуальный ядро. Вот, и как мы понимаем,
в центральных процессорах обычно физическое ядро состоит из двух виртуальных. Здесь же тоже
есть некоторые ограничения, в зависимости от архитектуры видеокарты. У нас получается на один
стриминг мультипроцессор приходится либо два, либо четыре виртуальных ядра, то есть ворпа.
В большинстве видеокарт у нас будет использоваться именно четыре ворпа, но, как ни странно, на том
сервере, на который мы с вами будем работать, там будет именно на одно физическое ядро два виртуальных
ядра, два ворпа. То есть это зависит от архитектуры самой видеокарты. Вот такая вот у нас физическая
абстракция. Но, опять же, если у нас физическая абстракция есть, с ней непонятно, что пока делать.
Но она будет важна для того, чтобы мы понимали с вами, как организовывать логическое пространство.
И тут как раз есть задача, которая есть. Представьте себе, что у некоторого Паша есть видеокарта.
Старая видеокарта. Что он прочитал? Он прочитал, что в нём находится 2560 кудоядер. Это правда.
Дальше он пытался долгим вечером разобраться, собственно, какая здесь константа, два или четыре.
И узнал, что в спецификации количество стриминг-мультипроцессоров равняется 20.
То есть здесь у нас 23 мультипроцессоров на 2560 кудоядер. Вопрос. Сколько ворпов в одном стриминг-мультипроцессоре?
Ну, смотрите, нужно вот эту величину поделить на вот эту. Тогда мы поймем, сколько ворпов у нас всего
существует. То есть это у нас получается 2560 поделить на 128. Ой, на 20. Мы получаем с вами 128.
И дальше вот эту величину нужно поделить на количество ядер в ворпе. Получаем, что здесь константа четыре.
То есть на самом деле по количеству стриминг-мультипроцессоров вы явно можете
посчитать количество кудоядер. О, количество ворпов в одном стриминг-мультипроцессоре.
Это важно. Так, понятно, как эта задача решается?
А размер ворпа это сколько кудоядер помещается в одном ворпе?
Да, мы хотели узнать, сколько ворпов находится в одном стриминг-мультипроцессоре. Вот, их оказалось
столько. Просто в старых версиях архитектуры видеокарты их было 16, а они 32. Так, хорошо,
это что касается физической абстракции, теперь давайте про логические абстракции. Да, кстати,
картинка. Вот так выглядит один стриминг-мультипроцессор. Вы не поверите, вы можете
даже тут пересчитать, сколько тут регистров есть. Вот оно, то есть у нас есть стриминг-мультипроцессор,
у него есть LED 1 cache, и здесь можно пересчитать, сколько юнитов здесь находится. Как ни странно,
если сложить тут INT плюс FP32, тут их как раз получится 32. То есть это по факту ворпы. Вот,
а то устройство, которое управляет ворпами, оно оранжевое, это ворпшедулер. То есть в нем как
раз мы можем с вами вычислить 32 потока. Значит, здесь есть в новых версиях видеокарты есть
еще тензорные ядра, но я думаю, мы про них поговорим чуть позже, потому что это необходимо
для того, чтобы как раз всякие нейросети обучать. То есть сейчас компания NVIDIA занимается еще тем,
что устройство внедряет всякие штуки для того, чтобы быстрее нейросети обучались, потому что это
коммерчески успешно. Вот, одна из таких вещей — это как раз тензорное ядро. Теперь давайте
поговорим про логические абстракции. Значит, в качестве логической абстракции у нас здесь находится
трет, и обычно один трет выполняется на одном CUDA-ядре. То есть здесь соотношение один к одному.
Следующая абстракция, которая есть, я и нарисую чуть ниже, это блок. Это набор потоков,
которые логически исполняется на единицу времени. Я ее нарисую здесь ниже, почему? Потому что хоть
блок состоит из 3DO, но когда мы будем выполнять блок, он, видеокарта, его будет автоматически бить на ворпы.
То есть блок будет делиться на ворпы и посылаться команду будет через ворпы.
Поэтому размер блока, который мы с вами задаем, должен быть кратен размеру ворпа. То есть это 32,
64, 128, 256 и так далее. Но, опять же, есть максимальное ограничение. Я напишу его так,
что на один блок можно использовать максимум 1024 потока. Возможно, что архитектура видеокарты
поменяется и вот эта консанта будет меняться в зависимости от архитектуры видеокарты.
Да, он просто заиспользует лишний блок и, соответственно, получается в последнем ворпе
будет использоваться 8 элементов из 32. Ну, в целом ладно, но там 8 там, 8 там накопится в итоге.
Вот, поэтому это лучше как раз... Блоки делятся на ворпы, я сказал. И дальше здесь еще есть одна
абстракция, которая называется гридом. Это набор из блоков,
который выполняется логически. Значит, смотрите, что происходит, когда работает видеокарта? Она
берет грид и делит это все на стриминг мультипроцессоры. То есть у нас один стриминг
мультипроцессор, точнее сказать, один блок выполняется на одном стриминг мультипроцессоре.
То есть что делает стриминг мультипроцессор? Он берет один блок и берет его в обработку.
То есть у нас здесь есть 128 кудо-потоков, кудоядер, допустим, размер блока 256,
он берет и за два такта обрабатывает этот блок. 128 плюс 128. Вот. А грид это логическая абстракция,
которую мы с вами можем использовать для решения наших задач. Для того, чтобы мы не
занимались распределением блоков по стриминг мультипроцессорам, потому что мы не знаем,
сколько стриминг мультипроцессоров в каждой видеокарте есть. То есть у нас наша цель будет
написать код. Опять же, мы про параллельное вычисление здесь говорим, мы больше говорим про ученых,
которые пишут этот код. Поэтому как-то не очень хочется делать так, чтобы указывать явно стриминг
мультипроцессоров, насколько из них параллельно. Тем более часть из них может быть свободна,
часть из них может быть не свободна. Так, хорошо. И смотрите, когда мы запускаем грид. То есть на самом
деле, когда мы запускаем код, мы будем с вами запускать именно грид. Что у нас с вами будет
происходить в этот момент времени? В этот момент времени мы будем с вами задавать при вызове ядра.
Нам нужно будет задать два параметра. Я специально пишу тройные угловые скобки.
Первое это grid-size, а второе это block-size. Это у нас будет количество блоков, а вот это у нас будет
количество потоков в одном блоке. А почему это называется grid? Что такое grid в переводе с английского
языка? Сетка. То есть у нас с вами организуется вот такая сетка. Видеокарта самостоятельно
организует. Значит по горизонтали у нас будет блок dim, а вот этот параметр это grid dim. Давайте
всех переименую, чтобы... И дальше каждый поток, который у нас будет выполнять на исполнение,
получит две определенных константы. Значит вот эта константа будет обозначаться как блок ADX,
а вот эта константа будет обозначаться как thread ADX. Нумерация идет с нуля, то есть у нас
получается здесь ноль и здесь ноль. То есть когда мы задаем логически вот эту вещь, то у нас
автоматически, когда мы будем запускать код ядра, будет выделяться две константы, каждая из которых
будет отличаться у собственного ядра. Давайте вопрос, который я хочу задать. Как вычислить
идентификатор вот этого потока? Вот в этой общей нотации. Да, смотрите, вот это все что до него.
Это что у нас получается? Блок ADX на блок DIM, а вот это thread ADX. То есть
зачастую, когда вы хотите получить номер какого-то потока, то это можно сделать вот таким вот
способом. Вот такой формулой. И при этом это все будет происходить параллельно. Обычно в базовой
концепции что делают? Берут, просто говорят, что у нас green DIM получается, это верхняя целая часть,
N на блок DIM. Да, то есть у нас получается весь массив мы запихиваем в сетку. А дальше видеокарта сама
будет вычислять для каждого элемента массива его позицию. Понятно, что у нас в последних каких-то
элементах у нас элементов не будет. То есть здесь у нас не будет каких-то элементов. Но тогда мы
это можем легко решить. Сказать, что если у нас ADX будет меньше, чем число элементов,
тогда делаем вычисление. Иначе вычисление мы проводить не будем. А потому что если нижняя
грань, то у нас несколько последних элементов просто не будут обрабатываться. Как бы нам
нужна сетка, которая минимально покроет наше все пространство. Да, то есть у нас получается
N делить на размер блока. Понятно, что это не оптимальная конструкция для некоторых вычислений,
но в целом это можно сделать. Почему это важно? Почему важно именно сдавать таким образом? Потому
что на самом деле, когда это все происходит, каждый из этих блоков будет браться определенным
стриммультипроцессором. А мы с вами понимаем, что когда мы берем стриммультипроцессор один,
да, и назначить, допустим, размер блока равный количеству стриммультипроцессора – это плохая
задача. Потому что у нас некоторые стриммультипроцессоры могут работать быстрее,
некоторые освобождаются и так далее. Поэтому вместо того, чтобы городить огород, так сказать,
мы можем сделать следующее. А давайте-ка поверх вот этих вот гридов мы по факту с вами сделаем,
так сказать, thread pool. Так, всем знакомым понятие thread pool. Мы сделаем с вами thread pool поверх
стриммультипроцессоров. Соответственно, как только у нас стриммультипроцессор будет свободен,
он будет вычислять определенную команду. Он будет брать этот блок и обрабатывать. Тем самым вы
можете сами указывать, вам не надо указывать количество стриммультипроцессоров, они просто у вас
начнут с вычисления. Это вот такая вот эффективная абстракция. Тут есть, правда, картинки. Да,
что в этой абстракции есть что? Давайте поймем. Сразу скажу, что здесь изображена логическая
абстракция. Как вы думаете, что здесь является? Да, одно растение. Хорошо, что является блоком?
Да, грядка называется. Что грядом является? Поле, огород. Так, теперь давайте разобремся с
физической абстракцией. Что можно с растениями делать? Зачастую. Что чаще всего делают с растениями?
Поливают, да. Хорошо. Значит, что тогда будет у нас куду-ядром? Да, когда мы поливаем одно
растение. Что такое будет ворб тогда? Ну, вот смотрите, вы берете вот такую большую-большую
вещь, я сейчас ее покажу. Ассинизатор называется. Вот такую вот. Бандурину и берете, проливает.
Соответственно, как только у вас ассинизатор проходит часть ряда по факту, мы можем считать,
что она проходит определенный ворб. То есть, она проливает часть не весь ряд целиком, а вот
маленький кусочек этого ряда. Соответственно, за несколько итераций она берет и обрабатывает
весь ряд. То есть, обрабатывает весь блок. А вот это вот такой вот большой-большой стриминг
мультипроцессор. Она берет и это все проливает. Понятно, что таким образом огород мы можем
пролить намного быстрее. Вот, приблизительно вот так работает видеокарта. Вот. В общем,
вот такие вещи. Ну и давайте, может быть, что-нибудь на затравку я покажу какую-нибудь картинку. Как раз из
исследований, которые мы сейчас делаем. Так, так покажу. Секунду. Вот, для sparse matrix.
Во, не знаю, видно картинка или нет. Давайте я скачаю тогда. Во. Это время обработки. Мы
делаем пакет, который занимается вычислением матриц расстояний. Посмотрите внимательно,
то есть, в зависимости от разреженности матриц, какая скорость работы программ. Значит,
последний метод, который предпоследний, это GPU классический, который считает попарные расстояния,
а это в dense режиме. Значит, слева это временная шкала в порядках микросекунд. То есть, шестерка
это одна секунда. Семерка это десять секунд, восьмерка это сто секунд. Значит, вот они GPU. Вот
видно, где они находятся. И видно, где находится sparse GPU. Впечатляет ли вас скорость работы?
Матрица расстояний вычислять. То есть, всякие корреляции и так далее. Именно на GPU. То есть,
у нас есть матрица, у нас есть вторая матрица, и мы хотим посчитать попарное расстояние между всеми
строками в матрице. Вот. При этом у нас матрица бывает обычная, а бывает sparse матрица. Вот. Здесь
корреляция кендала попарные считается. То есть, смотрите, что у нас получается. У нас получается,
что если у нас GPU считает что-то от одного до десяти секунд, то сколько времени необходимо
для этого всего, для того чтобы посчитать это все с пул пакетом? От десяти до сотен секунд. То есть,
ускорение видно в порядке. Поэтому мы это так или иначе и проходим с вами. Все, давайте,
наверное, вопросы. Что такое grid? Grid это сетка, при помощи которой видеокарта будет
назначать задачи на обработчики. То есть, у нас есть размер блока. То есть, что делает? Она создает
сетку и для каждого элемента этой сетки выдаёт отдельную задачу на исполнение. То есть, как бы,
вот так вот видеокарта передает задачи в физическую инфраструктуру. Каждая строка в этой
истории обрабатывается одним стриминг-мультипроцессором. То есть, что берётся? Берётся вот эта строка,
отдаётся на стриминг-мультипроцессор. Потом стриминг-мультипроцессор берёт вот эту строку
блока и бьёт её на варпы и её исполняет. Вот, просто чтобы нам с физической абстракцией не сталкиваться,
мы как раз отдаём максимально это всё на выполнение видеокарты.
А dance это означает, что мы работали тут с part с матрицами в разных режимах.
А это мы подаём part с матрицей с разной степенью разреженности.
Ну да, это просто продублированный график, чтобы показать просто динамику.
Чем меньше элементов матрицы физически находятся, то есть 99% значений это нули.
