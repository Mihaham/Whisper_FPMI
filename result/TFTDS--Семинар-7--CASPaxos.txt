Я с вами хотел сегодня договорить последний раз про сингл и грипп аксус.
И кое-что, скажем так, неожиданное про него рассказать, если это еще возможно.
Но мне кажется, что возможно.
А для начала, чтобы перейти к основному содержанию, нам нужно вспомнить про домашку
и подумать, со всеми мы из нее справились.
Нет ли у нас вопросов, как стоило ее написать?
Нет, если ты еще не написал, то нужно выйти.
Но вообще дедлайн уже прошел.
Тех, кто написал, есть ли вопросы?
У меня есть вопрос по поводу отзрания ролей Алисы.
Попробуй мне рассказать.
Да, очень легко. Представь, что ты мультипаксис.
То есть ты реплика в мультипаксисе.
Тебе приходят препэры и аксепты, ты на них реагируешь, отвечаешь и ничего не понимаешь.
Но твоя задача – понимать, что какая-то команда закомитилась.
Сам по себе ты ничего не понимаешь, ты просто голоса отдаешь, особенно если ты не лидер.
Лидер тебе может что-то сообщать, но это нужно делать аккуратно.
Во-первых, во-вторых, он может перезагрузиться и все потерять.
В общем, это роли для того, чтобы ты, помимо того, чтобы голосовал и предлагал команды,
еще узнавал о том, что некоторые команды выбраны, для того, чтобы их применять к себе.
Для одного паксиса это оптимизация, которая позволяет тебе быстрее узнавать о выбранном значении, если оно уже было выбрано.
Ну или узнавать вообще о том, что оно выбрано, для того, чтобы ты применял к себе реплицированный лог.
Что мне важно в этой задачи, в том, чтобы вы разобрались, как работать правильно с ретраями.
Ну скажем, если вы использовали комбинатор Quorum, который был раньше, то вы написали точно плохой код.
То есть можно не сомневаться, но вроде бы это в условии намекания на то, что так не стоит делать.
Вы, наверное, написали свой комбинатор, но свой комбинатор можно немного по-разному писать.
Вот чем acceptor в паксисе отличается от реплики в прошлой Домашке?
Тем, что в прошлой Домашке реплика отвечала всегда, да, я сделал запись, даже если она пригнанировала ее.
То есть она всегда выполняла команду успешно.
Но либо она вообще не отвечала, если не рвалась, потому что машина перезагрузилась или умерла.
Вот здесь добавляется третий ответ, и третий ответ должен как-то явно быть представлен.
То есть она либо согласна с вами, либо отвечает ack, либо отвечает not ack, либо отвечает дисконнектом, скажем.
Ну либо не отвечает очень долго, потому что partition, но рано или поздно вы дождетесь чего-нибудь,
или дисконнекта, или какого-то ответа.
Понятно ли, почему эти три ответа должны быть равны?
В смысле, почему мы разделяем ответ ack и ответ nak?
Ну, совсем понятно, почему мы разделяем их на стороне проповзора,
но почему мы разделяем их на стороне кворума?
Какая из этого может быть польза?
Но какую информацию вместе с наком мы посылаем по-хорошему?
Мы посылаем некоторую нижнюю границу, ниже которой проповзул number предлагать уже не стоит.
И, видимо, кворум, который вы пишете, он мог бы быть, ну, это какой-то специальный кворум,
который написан специально для паксиса и который понимает, что можно собрать результаты в смысле положительные ответы,
а если вдруг они не собрались, потому что слишком много нак,
то вы вернете advice, от которого нужно дальше выбирать себе новый n.
Следующее, ну, техническое с этим замечание по коду.
Не нужно дублировать RPC-колы, то есть не нужно делать отдельную функцию для первой фазы, отдельную для второй фазы.
Если у вас два раза собирается кворум, два раза написан коминатор кворум, два раза написаны RPC вызовы, то зачем?
Да?
Да вы понимаете, что зачем вы это сделали?
Ну, короче, у меня-то в коде один написан, одна функция шаблонный написан, она просто принимает параметры фазы,
у фазы есть request-response, у ответов какая-то общая структура,
там всегда есть флажок да-нет, если нет, то advice, если да, то есть vote,
не важно, vote я даже не могу использовать.
Этой общей структуры достаточно для того, чтобы написать общий комбинатор или написать общий код, который кворум собирает.
Код дублировать не нужно.
Ну и содержательное замечание про retry.
Как мы поступаем с retry здесь?
Ну вот делать бесконечный retry, возможно, не стоит.
Ну или по-другому, вот у вас есть три реплики, вы получили от одной да, другой нет, а третьи пока ничего не получили.
Если вы используете at least once тимантику, то есть дожидаетесь, что каждый реплик вам ответит,
то получается, что вы не вправе дожидаться более чем n пополам плюс одного ответа.
Потому что если вы прям будете настойчиво ждать дольше, то получается, что вы можете зависеть, когда у вас откажет одна реплика из трех,
это вроде бы OK, но вы в этот момент заблокируетесь.
Поэтому вы действуете очень уныло, вы дожидаетесь n пополам плюс одного и принимаете решение.
Но с другой стороны, это решение может быть слишком пессимистично, потому что для того, чтобы собрать кворум из ack'ов
и при этом не ждать больше majority ответа, то получается, что один n и все, и вы отказываетесь от выбора.
В смысле вы ретраитесь с новым n.
Возможно, можно делать эффективнее, и даже если вы получили один n, то пока их не слишком много, все-таки можно ждать дальше.
Но важно, что вы не нужно просто ждать бесконечно.
И так вы приходите к тому, что нужно ограничивать число ретраев.
И к этому можно прийти с другой стороны, потому что у вас ретраи на отдельном RPC вызове есть по дефолту.
Ну, точнее не по дефолту, не помню, что по дефолту.
По дефолту есть, да? Нужно дефолт изменить.
Вот у вас по дефолту есть ретраи в отдельном RPC вызове, и у вас есть ретраи на уровне алгоритма.
Вот в этот момент нужно задуматься, что класть ретраи в ретраи это, возможно, не самая разумная идея.
И что нужно как-то эти ретраи понять, на каком уровне их лучше разумно делать.
И так вы приходите к тому, что вам не нужно использовать at least once для отдельных RPC вызовов.
Вы можете сделать какое-то ограниченное число ретраев, или вы можете сделать...
Ну, там есть флажок at most once, то есть вы делаете просто одну попытку.
То есть канал с ретраями, который вы написали, он вообще не используется, вы проходите сквозь него.
Вот, ну вот так получается вроде бы какой-то разумный небольшой код.
Это, в общем-то, единственные сложности, у которых эти задачи были, нужно было на них не напороться.
Ну вот at least once – это то, что нам потребуется дальше и в мультипаксосе,
но потому что этот код у нас следуется почти без изменений, и, конечно, в рафте, потому что там...
Ну, про него еще рано. Там тоже есть такой код.
Ну вот, мы решаем задачу консенсуса.
И кажется, что сама по себе задача консенсуса бесполезна.
Ну, по крайней мере, в таком вот изолированном состоянии.
Вот я сегодня покажу, мне кажется, забавную штуку.
Вроде бы в продакшене не используют, хотя могли бы.
Но эта вещь у нас совершенно удивительная для понимания,
потому что, в общем-то, в рафте, в рафте, в рафте, в рафте, в рафте, в рафте, в рафте.
В продакшене не используют, хотя могли бы.
Но эта вещь у нас совершенно удивительная для понимания.
То есть алгоритм паксос, он не так прост, как выглядит.
Ну, он не то, что выглядит простым, но он еще хитрее, чем нам кажется сейчас.
Для этого нужно некоторое вступление.
И вступление – это будет...
А мне видно на доске сейчас или нет?
Видно, но, возможно, не очень ярко.
Вот, так лучше.
Совсем недавно, в 2021 году вышла статья,
которая называется «Виртуальный консенсус Делос».
Ее написали снова в Facebook, но мы сегодня смотрели на файловую систему.
Это статья про то, как они строили свою систему Делос,
а это сервис-координация, то есть это их альтернатива ЧАБи.
Но они написали не в 2021 году, конечно, написали несколько годами раньше,
статью фабриковали сейчас.
Вот про сам Делос есть, ну, запись у них в техническом блоге.
И о чем они пишут?
Ну, вот Делос – это там, не знаю, какая-то таблица,
с помощью которой можно делать координацию.
В общем, для того же самого, для чего нужен ЧАБи, для чего нужен Зукипер,
а про Зукипер мы в другом курсе еще поговорим в любом случае.
Но статья не про сам Делос, а про то, как они реплицируют данные там.
Они делают РСМ, но вводят там дополнительную абстракцию.
То есть мало абстракции, они, известно, любую проблему
можно решить еще одним слоем.
Вот они добавляют его, делают виртуальный консенсус.
Они делают виртуальный лог.
Не то, чтобы они пишут поверх рафта или поверх мультипакса
со своей репликацией, они пишут поверх вот некоторого абстрактного лога.
И вот этот дополнительный уровень косвенности,
дополнительная абстракция, она удивительным образом помогает им
получить решение еще проще, но и лучше почувствовать,
где консенсус нужен, а где консенсус не нужен.
Вот у них есть база данных, это какие-то реплики с РСМ.
Реплики РСМ.
И они работают поверх виртуального лога, в котором откуда-то берутся
закромиченные записи.
Сейчас мы найдем интерфейс.
Вот виртуальный лог.
В него можно добавлять, из него можно читать
и можно отрезать префикс, когда он уже не нужен.
Тут есть еще какие-то операции.
Почему-то тут два интерфейса, не один.
Вот этому как раз статья и посвящена.
Ну вот есть же рафт с другой стороны.
Вот авторы говорят, что рафт...
Где они говорят про рафт?
Что рафт смешивает два уровня, два измерения.
В распределенных системах часто уделяют вот такие плоскости
control plane и data plane.
То есть у вас есть некоторая система, ну и там как бы много всего в ней происходит.
Там, не знаю, какие-то переконфигурации, вы меняете состав машины, вы пишете данные, читаете данные.
Так вот, вот есть пользователь и есть его write pass и read pass.
То есть путь, который он проходит в системе для того, чтобы сделать запись или сделать чтение.
И вот компонента, которую он задевает, называется data plane.
А есть control plane.
Это слой, который нужен для того, чтобы система функционировала.
Это слой, который, не знаю, управляет всеми остальными узлами в ней.
Но при этом через него проходить на быстром пути не нужно.
И вот они говорят, авторы статьи, что в algorithm.raft все вместе, и переконфигурации, и репликация, все в один протокол замешано.
Вот мы сейчас выделим две абстракции, которые помогают эти слои разделить.
Control plane и data plane.
И реализовать их по-разному.
Вот они выделяют две абстракции.
Вот они выделяют две абстракции.
Собственно, виртуальный лог, с которым работают реплики RSM, и выделяют loglet.
Это компонентный кусочек лога.
Вот чем такая декомпозиция оказывается полезной?
Помните, что когда я говорил вам про multipaxos, в конце лекции я вам говорил, что на самом деле algorithm.paxos не про то, чтобы выбирать очередную команду в логе.
Он про то, чтобы решать проблему конкуренции лидеров.
Когда у вас лидер один, то он просто назначает команды, пишет их в лог, но как бы нему никто не мешает, ordering делает он.
Вот для того, чтобы команды упорядочивать, консенсус не нужен.
Консенсус нужен тогда, когда у вас появляется новый лидер, а старого нужно заблокировать.
Вот только вот в период смены эпохи.
А Facebook идут в эту сторону и разделяют обязанности.
Вот у них есть логлит, который занимается только тем, что упорядочивает команды.
В него можно сделать append, из него можно читать, ну и его можно запечатать.
Вот операция запечатывания, это такое, мы один раз запечатываем и все, и в этом месте логлит заканчивается.
А виртуальный лог выстраивается из логлитов, то есть он умеет их склеивать в одну бесконечную цепочку.
Зачем это нужно?
Вот оказывается, что в такой декомпозиции, немного искусственной по началу,
можно сделать так, чтобы логлит, вот этот кусочек лога, был реализован вообще без консенсуса.
Тут можно сделать репликацию, где у вас есть один лидер, два фоллвера, и он получает все команды, пишет на них.
И если вдруг лидер умирает, то все. Думать про перевыборы не нужно, думать про консенсус не нужно.
Вот можно строить такие очень простые компоненты, причем, ну это уже такая инженерная задача, на нас меньше степь не касается.
Можно реализацию этих логлитов менять. Можно сделать одну реализацию, потом другую.
Ну и скажем, вот представьте, что вы пишете мультипаксис, и у вас там есть какие-то метапараметры,
типа альфа для переконфигурации, то есть в каком окне действует переконфигурация.
Вот некоторые такие большие параметры в алгоритме сложно на ходу менять.
Вот вы можете разделить их на такие логлиты и в каждом наборе использовать свои параметры.
Ну или вообще разную реализацию.
И скажем, если вы логлит закрыли, то есть кусочек лога зафиксировали,
то вы можете вообще избавиться от лога и поместить его на какое-то другое хранилище,
на какой-то холодный storage, который очень эффективно жмет данные и не умеет их особенно быстро читать.
Так вот, вы можете построить логлит, в котором консенсуса вообще не будет,
а будет просто primary backup, то есть лидер, который принимает команды, реплицирует на всех.
И все, что нужно уметь, нужно сказать лидеру, что перестань, просто как бы остановись.
Вот это не совсем тривиальная задача, то есть это примерно страница текста посвящена как это сделать,
но все же задача решаемая, и консенсус еще раз не нужен.
А вот на верхнем уровне нужен консенсус, вот здесь вот,
потому что здесь нужно переконфигурировать систему, переключаться с одной реализацией на другую.
Так вот, к чему я все это рассказываю?
К тому, что здесь консенсуса вообще нет для репликации лога,
а вот этот уровень, который строит из кусочков одну непрерывную цепочку команд,
он называется у них Metastore.
Но это не совсем тот Metastore.
Там используется Multipaxs.
Сейчас я найду.
Metastore использует протокол уже консенсуса Multipaxs.
Так вот, этот Metastore – это control plane.
Там редко что-то происходит.
Там работы происходят тогда, когда система переходит из одного логлята в другой.
Сейчас я найду, где они это пишут именно.
Смотрите, что они пишут.
Я не знаю, стало ли лучше видно или хуже.
Ну вот, чтобы сделать этот верхний слой Metastore, мы взяли
и сделали реплицированный автомат с помощью оригинальной статьи про Paxos.
Я сейчас не помню, они ссылаются на греков.
Наверное, ссылаются на большую статью.
Так, мы откатываемся.
Но они пишут, что они взяли и реализовали самый тупой протокол.
То есть, у них каждый слот – это тупой single-slot Paxos без оптимизации
без каких-то лидеров, с конкуренцией пропозеров.
То есть, самый базовый вариант, который мы построили примерно через 15 минут после начала.
И это единственный консенсус в их системе.
То есть, они как бы строят RSM, но они не используют никаких оптимизаций вот на этом уровне,
на уровне протокола консенсуса.
Просто немного выделив дополнительный слой абстракции, они умеют упростить
сделать две задачи вместо одной, и каждую задачу решать проще, чем одну большую.
Так вот, и зачем им нужен Multipaxos?
Им Multipaxos нужен для того, чтобы сделать вот такую штуку, по сути.
Metastore – у них это версионируемый регистр, у которого есть операция условной записи.
То есть, мы пишем в него, если он равен чему-то.
Короче говоря, нам нужна ячейка памяти с операцией CAS.
И вот мы с ней работают редко, потому что эта ячейка хранит текущий логрит.
Она не должна быть устроена супер-эффективно, и вот только для нее нужен консенсус во всей этой системе.
Так вот, я сейчас покажу, что имея не то чтобы лог из single degree Paxos,
что само по себе уже довольно просто, а имея просто один single degree Paxos, можно сделать такую ячейку.
То есть, одного single degree Paxos достаточно для того, чтобы построить распределенную систему.
Ну и давайте мы сейчас это сделаем довольно быстро.
Но это, мне кажется, совершенно удивительно, что так можно.
Итак, мы с вами все знаем, как устроен Paxos, конечно.
Мы знаем, что там пропозеры выбирают себе bellot number, проходят через первую фазу, через вторую фазу.
Мне сейчас это все не очень важно. Мне важно, как...
Где-то красный маркинг был.
Как работает фаза prepare, как она взаимодействует с accept.
Давайте я сейчас буду странные вещи какие-то делать, но потом я объясню, что это все значит.
Я объясню, что это все значит, но точнее мы сами поймем.
Вот берем Paxos, там, я знаю, три пропозера, три accept, они запускаются, что-то там выбирают.
Вот в этом исполнении появляются какие-то proposal numbers, вот n, которые мы выбираем.
Давайте из них сделаем граф.
Ориентированный граф, в котором n будут соединяться друг с другом.
Вот каким образом, естественно, можно связать разные n?
Как я буду строить этот граф?
Тут не то чтобы много способов это выдумать.
Я понимаю, что пока смыслов происходящего нет, но интрига какая-то должна быть.
Вот как бы вы построили из n направленный граф?
Какие бы вы n соединили?
Что значит один поменялся на другой?
Было n1 и значение было n1, а теперь стало n1, значит...
Где стало?
Сейчас я хочу сделать вершинами графа n, у тебя здесь много accept'ров.
У тебя будут такие параллельные графы, альтернативные, или что?
n было number, он глобальный, он рождается в алгоритме, он есть один, ну и есть другие.
Вот я хочу как-то их связать. Как они алгоритмологически связываются, эти n?
Давайте я пример нарисую.
Помните, у нас был на лекции про паксис контур пример, что нельзя считать значение выбранным, когда оно лежит на большинстве.
И мы там брали три accept'ра и рисовали такую картинку.
У нас был сначала первый пропозер, у него был n1, пропозер n1.
Он говорил prepar на первых двух репликах.
Потом говорил здесь a1x.
Потом его перебивали, говорили здесь p2p2.
Говорили здесь a2y.
Этот 1x сломался, и здесь, и здесь.
Потом появлялся кто-то третий.
p3, p3.
Здесь мы выбирали x, здесь мы выбирали ничего.
И говорили accept 3x.
Ну вот какое-то исполнение.
Вот у меня здесь три разных n, 1, 2 и 3.
Ну есть некоторое нулевое n у каждого accept'ра с самого начала.
Вот я хочу на них какую-то картинку, какой-то граф нарисовать.
Как мне это сделать?
Что?
Мне кажется, паксос не нужен для того, чтобы такую картинку нарисовать.
Вы написали паксос, но так и не поняли, да, его?
Что?
Ну вот, у нас была фаза prepare на зеленом пропозере.
Мы собрали quorum.
Нам каждый accept'р ответил каким-то своим локальным голосом и промессом.
И вот этот сказал accept'р, что у него есть голос за 1x, у этого есть голос за...
Ну ни за кого пока.
С нулевым n, пустой голос.
И мы посмотрели на эти голоса, и раз кто-то за что-то уже проголосовал,
мы выбрали под своим ballot number 3 значение с максимальным nx, которое мы получали в ответ.
Значение с единицей.
Да?
Ну, собственно, так...
А, ты же не замеришь. Прости.
То есть мы из этого голоса взяли себе значение.
Но почему мы взяли это значение? Потому что здесь был максимальный nx.
Ну вот давайте я скажу, что у меня вот здесь 3 связалось с единицей.
Из пропозула 1, пропозул 3 получает свое значение.
Да?
Вот, в итоге у меня был 0, был 1, и он получал свое значение сам, то есть он был связан с 0.
Цеплялся к 0.
У меня был 2, который тоже цеплялся к 0.
И у меня была тройка, которая цеплялась к чему, к единице, да?
Понятная конструкция?
Вот, ну дальше эта картинка может дополняться, потому что что?
Потому что появляется четвертый пропозор, и он приходит куда?
Ну, тут разные варианты есть.
Он может прийти
P4, P4, и тогда что получится?
Тогда он прицепится к этой двойке, да?
Потому что она максимальная.
Тогда я нарисую здесь вот, ну так, виртуально эту четверку.
А может быть я приду сюда и сюда четвертым пропозором?
И тогда я прицеплюсь, видимо, к тройке.
Прицеплюсь, видимо, к тройке.
И тогда я нарисовал бы ее здесь.
Ну вот, живет в себе такой граф.
Давайте выделим в нем некоторые вершины, некоторые n.
Там же есть какие-то особенные n?
Ну, пока нет особенных, пока они все просто разноцветные и одинаковые.
Ну, скажем, если четверка придет вот сюда и...
А нет, пусть сюда приходит.
Сюда и сюда.
То она выберет себе в качестве значения y, потому что двойка была больше, чем единица.
И мы закомитим эту двойку на первого-второго аксептора.
В смысле y закомитим.
Хотя он лежал не на большинстве.
Это не очень важно для нас.
Важно, что у нас вот детерминируется выбор.
Мы четверку приклеим вот сюда.
Вот, давайте я четверку в кружочек обведу, потому что чем она отличается от остальных?
Вот, этот пропозал был успешным.
Ну, вот вообще во всем алгоритме каждый пропозал,
каждый конкретный пропозал для конкретного n может быть успешным либо неуспешным.
Ну вот представьте себе исполнение, и в нем есть успешные пропозалы и неуспешные пропозалы.
И вот мы нарисовали для всего этого исполнения некоторый граф.
Ну, давайте дорисуем еще чего-нибудь.
Что получается? 4, да?
А потом появляется...
О, ерунду пишу.
P5, P5.
Потом приходит
P6, P6.
A6, Y.
Ну, Y уже не может поменяться, он закоммичен, все, навертвое.
По свойствам Паксиса.
А вот пятый пропозал проиграет.
Что получится?
Что?
И П вместо А, да?
Ну, в смысле...
А, да, да, да, да, конечно.
Простите.
Что получается?
Ну, Y закоммитился, это же...
Как огорчаешь меня.
Получается вот такая картинка, да?
Почему?
Почему квадратная, да?
Странно.
Я правильно рисую?
Ну, пора бы уже смысл в этом найти.
Ну, точнее, не то, что смысл, а какую-то структуру.
Я просто могу дальше продолжать, ну, точнее, не могу, у меня доска закончится.
Я же к чему-то это все веду.
Круглые прицепляются круглым, да?
В этом графике могло бы быть иначе?
Мне кажется, что могло.
Вот представь, что было бы...
Представь, что было бы вот так.
Твоя гипотеза провалилась.
Круглая прицепилась к некруглому.
Ну, что же надо посмотреть.
Вот посмотреть, так я сказал, у тебя...
Я в крошу у меня был, я не мог бы в крошу...
Круглая прицепилась к некруглому.
Я не могу в крошу.
Я не могу в крошу.
Вот, вот это было бы не так.
Многое было бы не так.
так я сказал, я в кружок обвожу те пропузлы, которые были приняты на фазе accept.
Не понял, пришел пятый, он выбрал себе Y, потому что он получил 4Y, но 5 прицепился к четырем.
Пришел шестой, он отправил UPR на второго и на третьего, и с третьего получил голос 5Y,
прицепился по нашему представлению к пятому, но при этом не дал пятому закомититься,
потому что теперь у него у пятого проваливается проверка на UPR.
Сейчас еще раз, я предлагаю конкретную конструкцию, не надо фантазировать,
я говорю, что я соединяю такие N, если у тебя после фазы prepare для N берется значение
из голоса N' V' какого-то более старого.
Вот я такие пары соединяю, вот я взял здесь этот Y отсюда.
А как так окажется, пятерка пришла?
Что?
Пятерка должна быть accepted, чтобы она появилась в голосе.
Так вот, она успела сюда прийти.
Но ее уже должно быть большинство принять, чтобы ее затеснять как последний голос.
В смысле, вот, я зеленый accept, я пришел с ballot number 5, мне пришли...
Я получил отсюда четверку, 4Y, собрал quorum из двух prepare'ов, пошел писать на...
пошел писать на вторую фазу, на третьем accept успел записать, а потом меня перебили.
Но вроде валидное исполнение.
Но это граф распространения значения, это правда, но...
Когда мы проходим через две фазы?
Я посмотри, как граф строится, понятно?
Вот можно в нем какое-то свойство обнаружить?
Вот, все круглые вершинки находятся на одной цепи, почему так?
Ну, это более-менее рассуждение про корректность.
Вот у нас есть некоторая N, и... сейчас вот возьмем N и N'.
Такие, что они оба были закомичаны, то есть прошли оба через две фазы.
Вот мы хотим показать, что N является... ну, и N меньше, чем N', мы хотим показать, что N является предком.
Ну, вот посмотрим на N', что с ним было.
Да, в этом графе, разумеется, только те N', которые прошли через первую фазу, потому что иначе они не могут...
Ну, непонятно вообще, к чему они цепляются.
Ну вот, посмотрим на N'3', который прошел через вторую фазу.
Видимо, он записал что-то через accept на quorum.
Вот, но этот N, он... сейчас...
Нет, я хочу сказать, что N' прошел через prepare.
Перезапутался.
А N прошел через accept, наверное так.
Вот, ну и в пересечении есть узел, и мы через этот prepare для N' связались с каким-то меньшим нас N, правда?
Вот мы получили... мы хотим понять, к чему цепляется этот N' в графе.
Он цепляется к максимальному N', который N' получил от фазы prepare.
Это максимальная N', оно какое может быть?
Но оно не меньше N, потому что вот на этой реплике лежит N' по крайней мере N.
Потому что и N и N' были chosen.
Так что у N' есть предок, и он не меньше N.
Ну он бы меньше N' уж точно, и он не меньше N.
Ну вот, повторим рассуждение для вот этого предка.
Вот кажется, что мы всегда будем спускаться вниз по N, но при этом никогда не выйдем,
то есть никогда не станем меньше, чем... мы будем спускаться по proposal number, но никогда не станем меньше, чем N.
Но явно это делать бесконечно нельзя, поэтому рано или поздно мы в N должны прийти.
Так что вот эти вершинки лежат на одной цепи, но что из этого можно дальше извлечь?
Ну или по-другому. Вот есть одна ветка, и вот есть другая ветка.
И вот эта ветка, как будто кружочков уже нет, кружочки все здесь.
Что значит кружочки, мы понимаем, это успешные пропозалы.
А что значит стрелочка? Ну вот в смысле алгоритма.
Как в вашем коде реализована стрелочка?
Мы взяли голос максимальным N, A, взяли оттуда V, A и выбрали его в качестве V со звездочкой здесь.
То есть на входе было значение, на выходе было значение.
Ну одно и то же. Вот тут была написана тождественная функция, получается, на этой стрелочке.
Понятно ли, к чему я клоню? Ну ладно, вспомогательный вопрос.
Понятно ли, что от этой тождественной функции, то есть от значений сам граф вообще никак не зависел?
То есть это вообще было неважно все. Как я новые V со звездочкой выбираю, что там вообще за V,
этот граф строится в зависимости от фаз и выбора N.
Так что, что бы я здесь не писал на стрелках, все равно получится такой же граф.
Ну вот и отлично. Теперь я могу это использовать для чего-то разумного.
Что я могу здесь сделать? Что я положу на этих стрелках?
Я положу свои операции клиентские, которые будут менять значение.
Как устроена моя операция? Я прихожу, выбираю себе N, прохожу через фазу prepare.
Если не прохожу, значит я ухожу обратно, моя операция проводилась.
Ну как бы ничего плохого не сделано, кажется, ее притрайть можно.
В смысле, выбрать новое N, это уже будет такой новый трай, новая операция.
Ну вот, если я со своей операцией прихожу и прохожу через первую фазу,
то вот я получил какое-то значение старое.
Из этого VA и с максимальным NA. То есть вот я здесь получил какое-то старое значение.
Вот я пятая операция, я получил значение Y.
И я на него действую своим преобразованием. Я же хочу это значение как-то изменить.
Вот действую преобразованием и пытаюсь это новое значение записать.
Если я прохожу через вторую фазу, я записал значение.
Если я не прохожу через вторую фазу, то что?
Да нет, не так.
Ну вот смотри, у нас была история такая в начале.
Было вот синий, красный, зеленый. И граф был вот такой.
И была четвертая операция.
Вот смотри, тут прямо сейчас реализовалось две альтернативные ветки жизни ячейки памяти.
Вот есть одна ветка и другая ветка. И чем именно история продолжится, непонятно.
Если мой препарат приземлиться на первую и вторую, то получается, что я продолжу ветку вот эту вот.
Если приземлиться на первую и третью, то я продолжу ветку вот эту вот.
Ну и как судьба сложится, та ветка и станет в конце концов закомиченной.
То есть если я комичу какое-то значение, то значит я финализирую всю ветку перед ней.
Вот эти три операции, операция один началась и провалилась, операция два началась и провалилась.
В некотором смысле неуспешна. Но она неуспешна не в том смысле, что она вот зафейлилась и можно ее повторить.
Наоборот, она завершилась непредсказуемым исходом. В зависимости от того, что будет дальше,
эта операция, например, три, она либо может стать частью истории, либо выпадет из нее.
В зависимости от того, что будет дальше происходить.
Так вот, мы упорядочили операцию довольно странным образом.
Но тем не менее, мы получили цепочку, такую историю.
И что предлагается делать дальше? Предлагается в качестве сделать в нашем алгоритме три операции.
Вот кажется так видно. У нас есть операция чтения, это тождественная функция.
То есть мы читаем с Quorum и пишем на Quorum то же самое. У нас есть операция CAS.
То есть мы в качестве значения храним пару версия и содержимые.
И каждая операция выглядит так. Если версия равна чему-то, то записать новое значение с версии плюс один.
То есть у нас есть операция чтения, у нас есть операция CAS.
И мы научились их выполнять с помощью одного единственного паксуса.
Смотрите, вы выполняете операцию CAS, она проходит через первую фазу, а на второй фазе фейлится.
Это означает, что она либо успешно закоммитилась, либо закоммитилась, мы пока этого не поняли.
Точнее не так. Она осталась в подвешенном состоянии в этом графе.
И она либо закоммитится чем-то другой операцией в будущем или нет.
Но мы этого не понимаем, поэтому мы просто делаем чтение.
Чтение безопасно ретравить. И вот если чтение закоммитилось, то он зафиксировал некоторую историю.
И после этого мы финализировали предшествующую операцию.
То есть она либо откатилась, либо накатилась, либо зафиксировалась надежно уже.
Это очень странно. Но мне кажется, что это очень странно.
Но тем не менее, так можно делать. Правда, тут есть один нюанс.
То есть вы применили CAS, он завершился значением maybe. То есть он непонятно, применился или нет.
Как вам понять, применился он или нет?
То есть вы делали CAS из первой версии во вторую.
Вторая фаза паксуса провалилась, поэтому вы делаете чтение, а чтение вам говорит, версия уже пятая.
Вот вы не можете понять, вы закоммитили свой старый CAS или не закоммитили.
Применился или не применился, потому что тут уже несколько CAS прошло.
Но если вы в одной чехии памяти храните всю историю изменений,
то получается, что по этой истории можно понять, закоммитился ваш CAS или нет.
И вы можете повторить его, либо считать, что он готов, потому что его накрыло сверху вот этим закоммичным чтением.
То есть вы применили все предыдущие состояния нашей чехии памяти?
Получается, что да. Если мы так делаем, то мы вообще все понимаем.
Даже несмотря на то, что у нас операция заканчивалась от значения maybe.
То есть потому, что вы проверили, мы просто входим по всем имени?
Нет, мы читаем до тех пор, пока чтение будет успешно.
И после чтения можно считать, что наша операция либо отменилась, либо применилась.
Мы прочитали успешно и смотрим, применилась или откатилась.
Мы прошли для некоторого n через две фазы паксуса.
То есть у тебя каждый кружочек, он же финализирует альтернативу некоторую.
То есть применилась, значит, в кружочек?
Твоя чтение применилась, значит, она ввелась в кружочек.
А это значит, что оно зафиксировало перед собой все операции, которые тоже могли бы закоммититься.
А какие-то ветки, наоборот, закатились.
То есть у нас здесь, в отличие от мультипаксуса, нет истории одной изменений.
Есть такие веточки, которые отмирают.
Но, тем не менее, есть одна ветка, на которой попадает все закоммиченное.
Чем-то на блокчейн похоже.
Ну так вот, а Фейсбук говорит, что для их сервиса координации достаточно одного регистра, который умеет делать условную перезапись.
То есть они могли бы войтись одним синглдикрипаксусом, в принципе, для того, чтобы свою систему построить.
Что довольно странно.
Он поверх этого сервиса координации, можно строить уже колоссус, и в итоге...
То есть если довести до абсурда, то, в принципе, можно в один синглдикрипаксус все упаковать, всю сложность.
Да, ну тут она неудобна тем, что она завершается иногда непонятным значением,
и поэтому нужно как бы историю изменения помнить в самом значении ячейки памяти.
Но если вдруг ты сумеешь даже как-то без этого обойтись, то тогда тебе даже историю помнить не нужно.
Но тогда операция CAS, она хорошая.
Но вот ZooKeeper, он тебе ровно такой API дает.
То есть ты можешь записать в узел дерева новое значение, если текущая версия узла равна этому чему-то.
И вот с помощью ZooKeeper ты дальше можешь строить другие системы.
Ну там, не знаю, кавка у вас будет, можно кавку построить.
Такие дела.
Не знаю, это на самом деле все, что я хотел сегодня рассказать.
Поэтому если у вас вопросы есть, то...
Кто-нибудь делал такое?
Что?
В продакшене я не видел, а системы, которые более-менее академические.
Эту идею по-разному придумали, но придумывали.
Вообще этот алгоритм придумал человек, который работал в Яндексе, он просто ушел,
как бы из Яндекса переехал в Штаты, где-то в Facebook работает, в свободное время написал статью.
Она многих удивила, потому что какой-то неожиданный исход.
А потом оказалось, что вот эту идею как-то в разной степени разные люди придумывали, но так не очень явно.
Не старались особо ее описать.
То ли общее место какое-то, но неважно, кто ее придумал.
Важно, что даже в простом алгоритме есть такая цепочка операции, которая может упорядочить все действия.
Это совершенно неожиданно.
