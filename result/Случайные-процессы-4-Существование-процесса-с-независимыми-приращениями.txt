С независимыми превращениями.
Ну, название говорит стамозно себя, поэтому повторять не буду, что это такое.
Но сейчас давайте обсудим критерий существования процесса с независимыми превращениями.
Я уже это напоминал, критерий существования использует характеристические функции,
или преобразование фурье.
Я напомню, что это такое.
Значит, если mu мера на Rn, а ее характеристическая функция,
ее разными буквами обозначают, вот так обозначают, вот так обозначают.
Вот это вот такой интеграл.
Значит, это функция комплексного переменного, и это важная характеристика меры.
Меры однозначно по своим характеристическим функциям определяются,
и важное свойство будет использоваться.
Случайные величины.
Да, еще одно замечание.
Характеристическая функция случайного вектора это характеристическая функция распределения.
То есть характеристическая функция случайного вектора со значениями в Rn это мат ожидания,
е в степени у кси.
Ну, для случайной величины это функция на R и вот такая вот функция.
Значит, функция, обратите внимание, комплексная, но это не страшно.
Значит, как я уже говорил, все те, кто сдавал комплексный анализ, немного напрягаются при появлении комплексного,
но обычно это бывает привлечение комплексного по делу и полезно.
Вот, например, здесь буква И всегда вызывает какие-то эмоции, но тут она за нас.
Потому что если бы буква И не была, то интеграл мог бы не существовать.
А так вот функция стоит по модулю равной единице, поэтому никаких не нужно предположений, чтобы этот интеграл был.
Значит, вот что важно.
Значит, простая вещь, но это относится к обычной теории валютности, но можно вспомнить, откуда это берется.
Что если случайные величины кси и это независимые, ну или векторы, то характеристическая функция, ну или фурье суммы распадается в произведение.
И еще важное замечание критерий Колмогорова существования.
Давайте, чтобы обозначения соответствовали конспекту, я выпишу как конспекте.
Значит, следствие, ну или давайте не следствие, а форма, форма критерия Колмогорова.
О существовании процесса задана мерспределением в терминах характеристических функций.
Значит, пусть, значит, это часть Р и при всех упорядоченных наборах в Т заданы, заданы меры.
Ну вот как было у Колмогорова, значит, на РН.
Ну и вот критерий Колмогорова говорил, что там нечто должно выполняться, чтобы был процесс с такими распределениями.
Значит, меры с характеристическими функциями фи, значит, t1, tn.
Существование процесса с конечномерными распределениями.
Значит, вот этими вот заданными равносильно тому, что при всех m верно соотношение.
Значит, вот такой вот, значит, если вот эта функция, она на РН.
Значит, и она ограничивается на гиперплоскость, где mt координата равна нулю.
И вот это должно быть равно вот чему.
Значит, когда мы ограничили, то как бы осталось на одну меньше переменных.
И вот здесь должно быть, значит, вот такое вот, сейчас как это лучше написать.
Давайте, чтобы переменные, давайте, вот я здесь напишу.
Сейчас или давайте, давайте я все это, все вот это равенство напишу вот здесь.
Значит, вот это должно равняться вот чему.
Значит, вот такое соотношение.
Значит, здесь стоит ограничение функции на гиперплоскость.
Стало быть, в этой гиперплоскости m-той переменной нет.
Значит, и вот должно выполняться такое соотношение.
Ну, почему это, почему это равносильно, ну, давайте сейчас, значит, потратим минуты, чтобы понять, почему это равносильная форма теоремии Колмогорова.
Значит, теоремия Колмогорова вот в такой форме, когда t, ну, вообще общая, я помню, общая теоремия Колмогорова для общего множества там никаких упорядоченностей нет, оно не в r и так далее.
Но здесь, значит, в несколько более специфической ситуации, когда оно множество параметрическое r и распределение задано для упорядоченных наборов.
Значит, я напомню, что требуется в теоремии Колмогорова.
Там требуется следующее, что когда вы спроектируете эту меру на подпространство меньшей размерности,
а исключив одну из вот этих точек, то должна как раз получиться соответствующая мера, где этой точки нет. Вот такое условие согласования.
В общей теоремии Колмогорова там еще про перестановки есть что-то, но когда моменты времени упорядоченные, это условие пропадает, как мы обсуждали.
Так вот, что происходит, когда мера на r и n проектируется на гиперплоскость? Что происходит с характеристической функцией?
Нужно просто характеристическую функцию ограничить на эту гиперплоскость.
Поэтому вот это условие, что такое соотношение выполнено с учетом того, что меры своими характеристическими функциями однозначно определяются,
как раз и говорит, что проекция меры на r и n будет равна той мере, которая дана для этого меньшего подпространства.
И это видно из того, что равны характеристические функционалы проекции и той меры, которая была дана для меньшего подпространства.
Зачем это нужно для процессов с независимыми приращениями? Потому что в этой форме удобнее сформулировать критерий.
Критерий состоит в следующем. В прошлый раз, кажется, до этого критерий не дошел, так что сейчас я его выпишу.
Теорема. Пусть на r дана вероятностная мера.
Мера q0 и при всех парах st таких, что они от нуля и с меньше t.
Дана вероятностная мера q, st.
Мы хотим, чтобы был процесс с такими распределениями разностей.
Существование стационарного процесса с независимыми приращениями.
Существование процесса ксиатте с независимыми приращениями, для которого q0 это начальное распределение.
Для которого q0 это распределение кси0 и qst это распределение вот этого приращения.
Существование равносильно вот такому соотношению.
Набор дан двухындексных, которые отвечают за распределение, и еще зафиксировано начальное распределение.
Как видно, в этом условии от начального распределения ничего не просят, а от этих распределений ожидаемых разностей просят вот такое соотношение.
Фи, ст это характеристическая функция q, st.
Условия в терминах характеристических функций.
Но это условия в терминах характеристических функций, конечно, есть условия, это можно переписать как условия на вот эти вот меры, но видите для характеристических функций условия совсем компактно записываются.
А в терминах самих мер несколько более громоздко будет.
Доказательства, давайте мы это докажем.
Если уже есть процесс, то тогда смотрите, что получается.
Тогда получается, что x t минус x u и x u минус x s независимы при вот таком расположении точек.
Ну раз они независимы, то тогда мы получаем, что характеристическая функция суммы есть произведение характеристических функций.
Но вот это, это есть просто разность, так что как раз получается вот из этого соображения,
что для независимых характеристическая функция суммы распадается произведение, но как раз вот это соотношение ровно и есть.
Вот характеристическая функция этой, получилось произведение вот этих складываемых.
А они как раз в наших обозначениях вот они так записаны.
Так что в одну сторону это совсем банально, ну в другую сторону несколько менее банально, но тоже в общем несловно.
В другую сторону, значит, что нужно проверить?
Надо проверить вот эту форму, условия из вот этой формы теоремы Колмогорова.
Но пока нету объектов, которые там фигурируют в этой форме, потому что у нас даны пока только вот эти пары,
а в том, ну у Колмогорова распределения даны не только для пары, а для всех n-х.
И в этом критерии с характеристическими функциями там тоже фигурируют не только пары, а все n-ки.
Значит, поэтому нужно создать эти n-ки.
Ну они создаются вот так.
Давайте сначала считаем, что процесс этот будет с нулевым начальным распределением.
То есть q0, значит, это мера Дерака в нуле.
Так, значит, эта мера сидит, вероятностная мера, сидящая в нуле.
Ну ее характеристический функционал это просто единица, поэтому она тут сейчас ни на что влиять не будет.
Вот, а теперь мы распределение, значит, вот такое вот распределение, которое требуется в теореме Колмогорова при n-ках,
значит, положительных чисел. Зададим так, значит, зададим как образ вот такой вот меры.
Значит, произведение вот такого вот произведения.
Значит, при линейном операторе.
Значит, при линейном операторе вот так вот.
y1 это x1, y2 это x1 плюс x2, ну и так далее.
yn это сумма всех.
Значит, вот у нас были одномерные такие вот меры, ну меры напрямой.
Значит, это распределение ожидаемых разностей. То есть это были меры напрямой.
А в теореме Колмогорова, ну и в ее вот этой форме характеристическими функциями, просят меры на rn.
И мы эти меры на rn фабрикуем так. Мы перемножаем вот эти одномерные распределения и линейно преобразуем.
Так, значит, вот получилась такая мера.
Значит, давайте посмотрим.
Да, но в теореме Колмогорова еще должны быть разрешены наборы, когда t1 равно 0.
И тогда мы сделаем так.
Такая мера с t1 равном 0, есть мера, значит, есть мера,
вот эта вот, которая у нас rn-1, сидящая в rn.
Значит, если мера сидит на rn-1, то можно считать, что она и мера на rn.
И вот мы для таких наборов, где начинается с нуля, мы будем считать, что эта мера пришла, ну, в этот ноль губрали.
Ну, а как делась эта мера, как делась вот эта мера?
Ну, она делась по этому шагу. Ну, значит, ну, а вы скажете, а вдруг t2-0?
Что делать, если t2-0?
Ну, естественно, нужно тогда тоже t2 убрать и еще укоротить наборы.
Ну, вы скажете, а вдруг нам так не повезло, что вот и t1-2, и t2-0, и t3, что все-все они нули.
Ну, тогда мы в итоге пойдем к мере герака в нуле.
Но если они не все нули, то в какой-то момент мы окажемся в ситуации с положительными, ну, и получится мера.
Таким образом, охватены все наборы.
Не только, ну, тут еще можно сделать так.
Тут, как я написал, даже не надо рассматривать такой случай, когда следующие t2, они у нас все...
Ну, это я уже в свое время говорил, что достаточно не совпадающие точки рассматривать,
потому что совпадающими по ним распределения однозначно вычисляются.
Вот если делать, как я тут написал, даже тогда и не нужно, случай этот, когда t2-0.
Тогда если t1-0, t2 уже точно не ноль, ну и тогда работает вот эта схема.
Значит, вот настроили эти распределения.
Теперь надо проверять.
Значит, смотрите, первый шаг из одномерных распределений изготовили всевозможные инмерные.
Ну и теперь надо проверять, что выполнено условие Колмогорова.
Заметим следующее, что при линейном операторе L
измера, ну скажем, mu с характеристической функцией phi-mu
переходит, ну по формуле замены переменных, переходит в меру характеристической функции вот такой вот
phi-mu, L звёздочка от Y, ну где L звёздочка сопряжённый оператор.
Ну, действительно, давайте вспомним, почему так получается из формула замены переменных,
потому что дальше это простое наблюдение как раз используется в вычислении.
Значит, считаем образ, меры берём и считаем характеристическую функцию.
Значит, это по определению, что нужно сделать, нужно вот это проинтегрировать по этой мере.
Но по определению образа меры, сюда нужно подставить L и интегрировать по мере mu.
Ну теперь L перекидываем вот сюда, ну и вот получился вот этот объявленный ответ.
Так, теперь, значит, теперь когда мы берём произведение мер, то какой получается характеристический функционал?
Значит, давайте так напишем, значит, характеристический функционал, произведение вот этих вот мер.
Qt-i, вот такое произведение берём и как считается, ну это из теоремы Фубини,
довольно очевидно, как считается, будет просто произведение характеристических функционалов вот этих вот одномерных мер.
Значит, такой ответ для вот этого произведения.
Но это произведение, это ещё не то, что нам нужно было, а мы ещё его преобразовали.
Поэтому вот это соображение теперь нужно применить.
Ну и получается, что характеристическая функция вот этой вот меры, значит, rn, это есть вот что такое.
Значит, дальше, дальше это я пишу умножение.
Значит, вот такой получился ответ.
Значит, вот для него, то, что нам нужно проверять из формы вот этой характеристических функциональной теоремы Колмогорова,
это вот для этой штуки нам нужно проверять.
Значит, вот у нас получилась функция.
И теперь мы должны смотреть, что будет, когда ym равно нулю.
Вот то, что там было в этом критерии.
Значит, ну, смотрим.
Значит, смотрим, когда ym равняется нулю.
Значит, смотрите, что здесь получается.
Значит, давайте посмотрим, что здесь получается.
Значит, когда ym равно нулю.
Значит, что здесь будет?
Значит, давайте посмотрим, что здесь будет.
Значит, ym, ну, давайте считать, что какая-то ситуация нетривиальная, что ym там где-то в серединке затесалось.
Что оно там ни первое, ни последнее.
Значит, ym там где-то в серединке затесалось.
Значит, и вот эта штука, смотрите, вот стоит такое произведение.
И какое-то срединное ym равно нулю.
Значит, что же здесь получается?
Ну, вот на это не повлияло.
На это не повлияло.
Но потом, наконец, дошли, значит, давайте так напишем.
Значит, различие возникает в какой момент?
Вот, значит, было yn.
Ну, и, наконец, дошли до...
Значит, вот в каком месте возникает.
Значит, лучше так написать.
Сейчас, давайте лучше никогда оно возникает.
Значит, различий нет.
В множителях...
Ну, до такого множителя.
Значит, вот такого множителя.
Значит, вот до такого множителя, значит, различий нет.
Так?
Значит, значит, затем...
Значит, смотрите, затем идет.
Вот после такого множителя, смотрите, что идет.
Значит, затем идет вот такой.
Значит, ну почему идет такой?
Ну, если смотреть на эти выражения, то идет такой с ym.
Тут как раз должен был быть ym.
Так?
Но его нет.
Ну, и вот такой.
Ну, и вот такой.
Ну, и вот такой.
Ну, и вот такой.
Ну, и вот такой.
Так?
Но его нет.
Значит, он стал нулем.
Так?
И видите, значит, в этом...
Ну, вот на этом месте, где что-то новое возникло,
получился одинаковый аргумент.
То есть здесь...
То есть здесь одинаковый аргумент.
Вот этот вот.
Из-за того, что у этого ym еще не было никакого,
а у этого уже он есть, но он ноль.
Поэтому он оказался таким же, на самом деле.
Ну, и поэтому...
Значит, что получается?
Из-за того, что...
Вот тут у нас как раз произведение.
Значит, вот тут стоит...
Значит, вот такой.
А тут стоит вот такой.
Вот.
И поэтому вот это сворачивается по условию.
Так?
И получается tm-1, tm-1.
То есть вот эта точка убирается.
Вот это как раз вот это условие свертки.
Так?
Получается...
Ну, получается то, что нужно.
Значит...
Значит, получается...
Нужное соотношение.
Значит, вот эта пара ушла, соседних,
и дала, значит, одну точку.
Ну, и как раз вот получилось то условие согласования.
Значит, это надо немного осмыслить,
потому что это, когда пишется на таске,
может быть не так очевидно, как когда сам на листочке вычислишь.
В общем, это полезно вычислить, что тут получается.
Значит, это дает случай, когда q0 имела единичный характеристический функционал.
Вот.
Но теперь, значит, общий случай.
Значит, общий случай.
Когда q0 не единица.
Тогда мы делаем следующее.
Значит, берем процесс.
Берем построенный процесс.
Значит...
Берем построенный процесс к СТ
и добавляем независимую с ним случайную величину
с распределением...
Ну, случайную величину x0 с распределением q0.
Ну, это...
Все это, конечно, на языке характеристических функций вычислить.
То есть, получится, что надо еще умножать единицу, как мы делали.
Вообще, нужно просто домножать на языке характеристических функций.
Значит, нужно взять характеристическую функцию вот этой отдельной случайной величины,
ну, и чудо на нее домножать, когда появляются распределения с нулевым t.
Ну, вот здесь опять пользуемся тем, что у независимых случайных величин
характеристические функции перемножаются.
Ну, и наоборот, если у двух случайных величин характеристическая функция суммы
распалась в произведении, то они оказываются независимыми.
Вот из-за этого соотношения получается, что вот...
Ну, проще всего, конечно, вот так сделать и добавлять.
Но тут, правда, вы можете спросить, а почему для заданного процесса есть независимая
с ним случайная величина с данным распределением?
Конечно, такой вопрос возникает, но это тоже из теоремы Колмогорова можно извлечь.
Значит, вот таким образом в терминах характеристических функций получается такой критерий.
И из этого критерия сразу получается, что существуют два самых важных процесса,
про которые я говорил, это Виннеровский и Пуассоновский.
Давайте сразу эти примеры рассмотрим как основные примеры.
Ну, а потом еще у нас будет еще один пример, будет гауссовский, общий гауссовский
процесс с независимыми прощениями, но для этого будет короткое обсуждение
отдельно гауссовский процесс.
А сейчас, до этого, вот два основных примера.
Виннеровский процесс.
Ну, он у нас уже был.
Но это такой процесс, что он должен появляться неоднократно,
потому что он и в реальной жизни возникает в разных ситуациях.
Значит, Виннеровский процесс.
Значит, я напомню, что это процесс, у которого начальное распределение
мера Дерак, ну, то есть начальное значение ноль, приращение независимых.
И вот такая разность.
Это гауссовская, со средним, ну, со средним, с нулевым средним.
И дисперсии равной разности.
Ну, то есть в частности, в частности, когда этот с ноль, то будет t.
Значит, почему такой процесс есть?
Это сразу вытекает из критерии.
Значит, существование вытекает из критерии, которые мы сейчас обсуждали.
Ну, действительно, какая характеристическая функция у такого процесса?
Ну, для этого нужно помнить, что у гауссовской случайной величины,
а с нулевым средним и дисперсией сигма характеристическая функция
это минус одна вторая y квадрат умножить на дисперсию сигму,
но в данном случае это t минус s.
Значит, вот такая получается, значит, такой здесь получается ответ.
Значит, то есть здесь q, значит, st от y.
Это, ну, вот то, что написано.
Есть степень минус одна вторая t минус sy квадрат.
Ну, когда s меньше t.
Ну, и очевидно, что условие согласования, конечно, выполнено.
Значит, условие согласования выполнено очевидным образом.
Значит, смотрите тут какое условие.
Значит, qsu на qut должно быть qst.
Но оно так и есть.
Потому что когда вы перемножаете, здесь будет стоять u минус s.
Здесь будет стоять t минус u.
Значит, они сложатся и дадут t минус s.
Так что тут все выполнено.
Так что вот существование, видите, вытекает в частности
из общего критерии для процессов независимого превращения.
Значит, я в прошлый раз уже отмечал, что этот Винеровский процесс
удовлетворяет основному критерию Колмогорова
с конечномерными распределениями.
Вот там хотя бы что-то проверять и считать надо.
А здесь, ну, это даже счетом не назовешь.
Так что вот у нас был первый способ, такое прямое применение теоремы Колмогорова.
Но, значит, вот этот способ чем лучше?
Тем, что вообще ничего считать не надо.
Сейчас становится супер, так сказать, очевидно.
Ну, еще я напомню, что, значит, непрерывность траектории
следует из равенства.
Но это вот тоже нужно вспомнить, что у Гауссовской случайной величины
с нулевым средним и некой дисперсией
можно явным образом сосчитать четвертый момент.
И, значит, это оказывается равно вот этому.
И поэтому применима теорема Колмогорова.
А Виннерский процесс у нас еще одним способом будет.
Значит, уже там третьим способом построен в виде ряда.
Но это вот в следующий раз про него отдельно поговорим.
Но уже вот в этот момент он уже есть.
Вот эти предыдущие теоремы уже его дают.
А, значит, это Виннерский процесс.
И, значит, еще один процесс очень важный.
Второй. Даже трудно сказать, кто из них важнее.
Но, наверное, Виннерский все-таки важнее.
Значит, Пуассоновский процесс.
Только давайте, чтобы у меня буквы были такие же, как в конспекте.
Давайте я посмотрю.
Ну, конечно, буквы можно разные применять.
В принципе, тут...
Вот Виннерский процесс почему-то обозначает такая традиция.
Ну, видимо, это связано.
Вот эта буква W, она связана, конечно, с именем Виннера.
А вот про Пуассоновский процесс такой уж прямо канонической нету буквы.
Значит, Пуассоновский процесс.
Значит, Пуассоновский процесс.
Значит, у нас он будет E на T.
Ну, почему E на T?
Ну, никакого отношения к Пуассону не имеет.
Значит, Пуассоновский процесс E на T с интенсивностью лямбда больше нуля.
Значит, это процесс с независимыми перерощениями на полуаси.
Так.
И, значит, вот какой.
Н 0 это 0.
Значит, N 0 это 0.
И, значит, N T минус N S.
Это имеет Пуассоновское распределение.
Пуассоновское распределение с параметром лямбда умножить на T минус S.
Ну, то есть что это значит?
Ну, это значит, что вероятность того, что вот это равно K.
Ну, где K?
Это 0, 1, 2 и так далее.
Значит, это равно лямбда на T минус S в степени K.
Значит, делить на K факториал и умножить на D в степени минус лямбда T минус S.
Ну, тут имеется в виду, конечно, S меньше D.
Значит, разности.
Значит, вот эти разности, которые все определяют, это Пуассоновские случайные величины.
Но, как видите, сами эти N от T, они тоже Пуассоновские, потому что N 0 это 0.
Поэтому сами эти N от T Пуассоновские и разности Пуассоновские.
Но между самими и разностями имеется принципиальнейшее отличие.
Сами не являются независимыми. Вот так же, как у единого стоп-процесса сами WT.
Они не являются независимыми, а разности являются.
Ну и опять нужно проверить.
Опять проверка существования нужна, конечно.
Проверка существования.
Но опять нужно проверять эти согласования.
Давайте сосчитаем характеристическую функцию приращения.
Смотрите, чему она равна.
У нас по определению характеристическая функция это какой-то интеграция.
Здесь распределение дискретное, и поэтому это становится рядом.
Рядом это вот каким становится.
Это становится таким вот рядом.
Ну и смотрите.
Ну вот ряд.
Нужно его сосчитать.
Нужно вспомнить молодость, матанализ.
Не тот, который в банаховыми пространствами, а настоящий матанализ, где ряды считаются.
Ну и надо считать. Как же его считать?
Вот этот множественный за нас.
Он, когда не зависит, его можно вынести.
Неприятность создают вот эти.
Ну как полагается считать такие ряды?
В общем, нужно заполнять новые ворота.
А потом замечать, что тут стоит К.
Их надо выединить.
Ну вот на первый взгляд кажется это чудно.
Экспоненту объединять с множителем.
Но ничего не поделаешь. У них степень К одна.
Поэтому нужно загнать это все дело в экспоненты.
И получается на первый взгляд ужасный ответ.
Смотрите, какой ответ получается.
Вот такой вот получается ответ.
Ну почему получается такой ответ?
Ну потому что здесь будет E в степени...
Ну давайте сосчитаем. Может я его, кстати, и не правильно выписал.
Сейчас заодно проверим.
Вот есть кто-нибудь, кто недавно с перездачей матанающего помнит, как ряды считать?
Ну давайте сосчитаем.
Смотрите, что здесь получилось.
Ну когда вынесли...
Ну вот это вынесли.
Будет E в степени И таум.
На лямбда T минус S.
Ну вот так.
Таум на лямбда T минус S.
Значит это в степени K.
И делить на K факториал.
Правильно? Пока? Вроде пока без обмана.
Значит это ряд для экспоненты.
Значит ряд для экспоненты.
Экспоненты от чего? Вот от такого.
Давайте я его накричу.
Экспоненты E в степени И таум лямбда T минус S.
Вот так.
Но у нас был еще отдельно припасен вот этот множитель,
которому мы радовались, что хоть в нем не надо ряды считать.
Ну и он выдал такой ответ.
Так что вот действительно ответ получается такой.
Ну и смотрите что тут.
Значит опять нам нужно проверять вот это соотношение.
Значит опять нужно проверять вот такое соотношение.
Значит опять вот это наше соотношение.
Ну, значит вот хотим проверить,
что тут происходит какое-то нужное сокращение.
Ну давайте посмотрим.
Происходит оно? Ну да, все отлично происходит, потому что тут, видите, как раз разность стоит в экспоненте, так?
И когда мы напишем два таких произведения, то в этих произведениях, ну в экспонентах будут такие разности,
ну они сложатся и дадут разность t-s, так что все окей.
Так что действительно тут все это выполнено, все условия тоже выполнены.
Значит, сплосоновский процесс тоже существует по той же самой теории.
А вот интересно, что, ну, сосчитайте, что у Винеровского процесса и у Пуассоновского процесса, что у них одинаковые кавариационные функции.
Процессы очень разные, а кавариационные функции у них как ни странно одинаковые.
Ну, сосчитайте, это, кстати, полезно и все для одного способа, так, Винеровский процесс.
Но я к этому вернусь позже, когда у Винеровского процесса еще в одном обличье появится галк.
Вот теперь еще, вот еще есть полезный факт, но я его хочу сделать задачей.
Почему? Потому что, значит, смотрите, сейчас, ну, потому что уже осталось мало времени, так?
Значит, следующая пятница опять лекции нет, значит, так наливаем.
Поэтому, чтобы не было таких вот, так сказать, больших отставаний от обычного режима, значит, следующая теория будет задачей.
Но эта задача такая очень вычислительная, и мне еще и поэтому на доске ее не охота выписывать, но в конспекте это все есть.
Значит, я конспект вызвал, по-моему, охматывающий, вот, все до сих пор, но на днях я, ну, там, я, естественно, продолжаю бесконечно что-то править в нем,
значит, на днях я, так сказать, апдейт вышлю.
И заодно приложу формулу, ну, которую семинаристы, наверное, вам разослали,
значит, мы там после долгих обсуждений какую-то формулу утвердили.
Ну, формула ужасная, я, ну, я у семинаристов спрашивал, у вас студенты не подают за такую формулу?
Ну, вот меня не так в обиду с мнением придумал.
Значит, ну, они говорят, нет, я не знаю, пестехи уже привыкли к такой формуле.
Ну, в общем, посмотрите, какая-то формула, я, ее невозможно выписать, она такая, ну, какая-то такая вот, ну, какая-то она,
там, ну, много чего учитывается и каким, причем формула, вот вы думаете, формула, это нечто детерминированное,
но отнюдь, если вы посмотрите на эту формулу, то увидите, что это тоже какой-то случайный процесс,
потому что там в нее входят, ну, ну, помимо того, что диктуется случаем, там, удачность решения контрольной,
там, значит, диктуется еще и вовсе не случайно, ну, не пойми чем, оценка, оценка символистов.
Так, вот, ведь это может быть вообще, так сказать, полный волюнторизм, так что даже не знаю, можно ли это объявлять случайным процессом.
Ну, еще там, значит, в этой формуле присутствует такой, как бы, предварительный экзамен,
это сдача теор минимума, что есть усеченная программа, но это для тех, кто не хочет получить полный балл,
а для тех, кто хочет получить максимальный балл, ну, после этого теор минимума, значит, еще продолжение экзамена,
ну, на котором можно получить уже полный балл. В общем, посмотрите, это такая неописуемая формула, в общем, но она есть.
Так, теперь, значит, вот теорема, значит, вот давайте ее в виде задачи сформулирую,
значит, пуасоновский процесс можно получить как так называемый процесс восстановления,
ну, значит, пусть, пусть это процесс восстановления,
так вот делается. Давайте я в скобках это отмечу, то есть в кавычках это отмечу, значит, с экспоненциальным
распределением
с лямбда больше нуля, значит, это вот что значит, значит, это значит, что это от омега,
а это есть супремум таких n, что sn от омега меньше либо равно t,
так, где смена от омега, это просто сумма,
кси 1 плюс кси n, с 0 это 0, значит, это 0, значит, 0 и
кси n независимые
независимые случайные величины,
ну, вот с экспоненциальным
распределением с параметром лямбда,
то есть иначе говоря, значит, устраивается такая штука,
значит, берется нечто более элементарное, чем процесс,
а именно последовательность независимых случайных величин
с экспоненциальным распределением,
ну, экспоненциальное распределение,
ну, это там плотность,
знаете, что такое плотность на полуаси,
экспоненциального вида и в экспоненте,
вот это минус лямбда,
плотность на полуаси с множителем,
это такая вот классика,
теория вероятности обычная,
складываются они,
но дальше,
что делают,
в теории вероятности очень часто складывают
случайные величины независимые,
это один из таких начальных ходов,
многих операций,
и дальше с ними чего-то еще делают,
ну, например,
делят на n, делят на q или n,
ну, еще какие-то манипуляции начинают
производить и из этих манипуляций
что-то пристекает, про что,
ну, какие-то там классики доказали,
ну, что это там
к чему-то сходится или
какие-то полезные вещи про это доказали,
но здесь немножко
манипуляция такая более,
так сказать,
более нелинейная,
вот, значит,
из этих сумм
изготавливается случайный процесс,
вот просто по явной форме,
то есть вот это явная формула, значит,
ведь сначала все было
дискретное,
но теперь t
теперь t
стало уже
недискретным, значит,
из процесса,
видите, из процесса с дискретным
временем изготовили, вот, по этой
формуле изготовили
процесс
с, значит,
с временем
непрерывным.
Ну,
за этим названием,
процесс восстановления
на самом деле, ну, скрывается
что-то с мнимоническим содержанием,
а именно
ну, например,
это можно
трактовать как время
непрерывной работы там какого-нибудь
девайса, там
лампочки какой-нибудь, там
ну, батарейки там какой-нибудь,
или щечки, или чипа какого-нибудь,
вот, уже
сто лет назад было
вон это
появились какие-то первые
девайсы
с регулярными заменами,
типа лампочек
или там каких-то деталей в радио
приемнике,
вот, уже это появилось,
такое наблюдение, что
за их
за их время работы
непрерывные,
вот это
отвечает по осоновским процессам.
Так, вот, значит,
нужно
доказать, в этом стоит задача,
что то, что
получилось,
это по осоновским
процессам.
Ну, в конспекте
вычисление проведено,
ну, как сами понимаете,
это вычислительная задача,
потому что что нужно проверить?
Нужно проверить независимость
приращений
и, ну, распределение
приращений сосчитать, потому что это
такая некая вычислительная задача.
Так, теперь,
значит,
теперь,
так, сколько-то
времени, кажется, есть.
А?
Да, значит,
время есть,
давайте еще
поговорим еще про один важный класс
процессов.
Ну, тоже
он
монастырь,
и на самых важных,
это галкинские процессы.
Значит, вот
Виннерский процесс у нас в следующий раз
еще будет,
ну, появится как гауссовский процесс,
гауссовский
процесс.
Значит,
что такое гауссовский процесс?
Ну, давайте я
напишу, что такое
гауссовская
случайная величина.
Значит, это
либо
константа,
так,
или
или с распределения,
или с плотностью
распределения
вот такого вот вида.
Единицы на
корене 2 пи
сигма есть в степени минус
х минус
а в квадрате делить на 2
сигма, где сигма
больше 0,
а больше r,
и сигма,
ну, а это среднее,
среднее,
а сигма
это дисперсия.
Так, ну, что значит
дисперсия? Ну, дисперсия
это значит,
ну, вернее, давайте начнем со средней.
Средняя, но есть средняя,
а дисперсия это
когда
центрировали
мат ожиданием и взяли
значит, интеграл от квадрата.
Значит, это вот тоже
классика,
придуманная очень давно,
а
ее часто
называют не гауссовской,
его это распределение
часто называют не гауссовским,
а нормальным,
вот в особенности в статистике
там редко употребляется слово
гауссовская случайная величина,
обычно говорят там нормальная случайная
величина, а в прежние
времена
еще называли это лапласовскими
распределениями.
Ну, а
гауса тут вполне
уместно
привязать
к этому распределению,
потому что он много чего с ним делал
и действительно
одним из
был самых больших пропагандистов
гауссовских распределений.
Эти
гауссовские распределения действительно
их конечно нельзя
так вот
выбирать,
какое самое важное распределение их
может быть неправомерно
сравнивать, но вот если бы
нужно было одно выбрать,
то вот
в качестве самого важного распределения,
то вот наверное все-таки
гауссовское заслуживало
что бы быть самым
главным.
Значит
это
гауссовское одно распределение,
так?
Теперь
что такое
гауссовский
значит
определение
гауссовский
вектор.
Значит гауссовский
случайный вектор.
Значит ВРН.
Ну
можно было бы наивно подумать, что
это набор гауссовских случайных величин,
но это не так.
Это значит
все
линейные
комбинации
гауссовские.
Значит вот в качестве упражнения
значит упражнения
нужно привести
пример
двух
гауссовских
случайных величин
кси1 и кси2
для которых
для которых
вектор
кси1 кси2
не гауссовский.
Ну то есть
попросту говоря
пару таких, что они
гауссовские, но скажем разность
или сумма не гауссовские.
То есть видите
уже такой
ну такой вот
немножко
видите более технический
такой объект.
Значит ну и
случайный процесс
это как раз обобщение вот этого.
Так
гауссовский определение
определение гауссовский
случайный процесс
все от
Т, ну с каким-то
параметрическим множеством
Т. Значит это
случайный процесс
для которого
для которого
все
вот такие вот
гауссовские.
Ну то есть иначе говоря
можно сказать
еще и так.
То есть процесс
ну если
использовать уже
значит конечномерное распределение
то есть процесс
с гауссовскими
конечномерными распределениями.
Значит
полезно вспомнить
из обычной теории
вероятности пару
понятия и свойств
связанных с распределениями
гауссовских
случайных векторов.
Значит
гауссовская
гауссовская мера
на rn
это
распределение
гауссовского
случайного вектора.
Значит
что это
дает?
Значит
давайте
поймем
что это дает.
Значит это дает следующее
значит ее
характеристическая
функция
ну скажем
phi гамма
от y.
Значит это есть
получается
мат ожидания
это есть мат ожидания
вот чего
у
кси.
То есть
это есть
у
а тут у1
кси1
и так далее
ксиn.
Но это гауссовская
случайная величина.
А значит
видите тут вроде тут якобы
многомерное все.
Но мы сразу попали
в одномерный случай.
Потому что вот эта сумма
она одномерная
и у гауссовской случайной
величины
уже одномерный.
Как выглядит характеристическая
функция?
Она выглядит так.
Нужно взять
мат ожидания
значит нужно взять
среднее вот этой штуки.
И плюс
то есть не плюс а минус
минус одна
вторая
сигма
тоже ее.
Значит дисперсии
и y квадрат.
Вот такой получается ответ.
Сейчас только не y
и никакого y квадрата нет.
Тут y равно единиц.
Вот получается так.
Мы считаем
преобразование фурье
гауссовской случайной величины
в точке 1.
И поэтому получается вот такой ответ.
Значит теперь
это
это можно
это можно расписать
поподробней.
Вот что
получится и
а кто
среднее?
А
среднее
ну тут будет вот что стоять
тут будет стоять
y житы
на
вот на эти числа.
Здесь будет так стоять
и минус одна вторая
а здесь смотрите что будет стоять
а здесь дисперсия стоит.
Значит дисперсия это
вот кто так
кто такое. Значит это
сумма
ну давайте я напишу сумма
y житых
на
кси житые.
Из них надо
вычесть вот этих же.
Поэтому я их сразу
я их сразу
значит вычту
и квадрат.
То есть
в сухом остатке
в сухом остатке
это вот какая экспонента.
Это и
умножить у
скалярно
с вектором а
а это вектор из средних.
И
значит
минус одна вторая
ну и вот тут квадратичная форма
видите.
Значит q от y.
Q
это квадратичная форма.
Ну еще
сейчас квадратичная форма
и еще
вот здесь
вот здесь
квадратичная форма и еще
ну давайте вот так напишем
q у минус
а вот так.
Вот тогда будет вот так.
Значит вот так будет.
Правильно. Значит q
квадратичная форма.
Так.
Вот.
Значит
сейчас
сейчас
сейчас
сейчас не так я написал.
Сейчас
сейчас не так
нехорошо я написал.
Сейчас
Сейчас ну
сейчас давайте
следующий раз
к этому моменту вернемся.
Значит
сейчас
Ну она уже и так квадратичная форма.
Да.
Значит дисперсия
будет
Так. Да.
Она уже и так квадратичная форма.
А можно не вычитать. Вот так вот.
Значит смотрите какой итог.
Значит
преобразование курье
характеристический функционал
гауссовского распределения
имеет такой вид.
Ну и в следующий раз мы проверим
что и обратное.
Что если у меры
вот такой характеристический
функционал, то она гауссовская.
Поэтому в терминах
характеристических функционалов
получается такое
описание
гауссовских распределений
конечномерных.
Обратное в следующий раз
выпишем.
И из этого
получится в следующий раз
критерии
существования гауссовского процесса
заданной кавариационной функции.
Ну и
потом поговорим про минерский процесс.
А потом дальше пойдут
другие процессы мартингалы.
Но
как я уже отмечал
следующий раз у нас не через неделю,
а через две.
