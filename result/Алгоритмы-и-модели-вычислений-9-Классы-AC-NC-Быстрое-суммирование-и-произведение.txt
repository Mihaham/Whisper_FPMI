В конце прошлого занятия мы изучили модель тем из функциональных элементов и, соответственно,
Сегодня мы внутри него поизучаем более подробно. Давайте я вкратце напомню, как эти схемы выглядят.
Схемы функциональных элементов. Можно себе представлять напрямую какую-то микросхему.
Сюда заходят проводки. На каждом проводке может быть либо 0, либо 1, то есть либо сигнала нет,
либо сигнал есть. На выходе может быть тоже много проводков, но я буду изучать ситуацию, когда на
выходе один проводок. Ну и внутри разного рода элементов можно использовать любые логические
функции. Стандартный набор, когда тут конъюнция, дезюнция или отрицание. Соответственно,
есть много элементов, которые как-то спаяны между собой, так чтобы не было цикла. То есть можно считать,
что даже если стрелочек нет на ребрах, можно считать, что они как бы сверху вниз идут, и тогда,
соответственно, циклов нет. Ну и, соответственно, если сюда на вход подают 0 и 1, то дальше они все
проходят через эти элементы. Каждый раз на выходном проводе появляется значение соответствующей
функции. Ну и в итоге вот здесь тоже получается какое-то значение. Ну и то, что здесь, это будет
функция, которая зависит от того, что на входе. Соответственно, получается некоторая функция,
у которой фиксируется число аргументов булевых. Ну и, соответственно, есть два параметра у схемы.
Размер это число элементов и глубина. Глубина это самый длинный путь от входа к выходу.
Ну и, соответственно, мы обсуждали теорему, что если у нас размер экспоненциальный,
то можно вообще любую функцию выразить. Да, и тут как бы нет противоречия, потому что тут для
каждой функции не обязан быть вычислимой, потому что для каждой длины у нас своя схема. Поэтому
последовательная схема это бесконечный объект и, соответственно, и будет столько же,
сколько и всех функций, в отличие от вычислимых функций. Вот, но, например, если потребовать,
что схема каким-то образом вычислима зависит от m, то тогда сразу мы возвращаемся в теорию
вычислимых функций. Вот, но, как правило, нас интересует схема не экспоненциального размера,
а полиномиального, потому что это вообще модель чего? Это модель какого-то реального устройства,
какой-то реальной микросхемы, которая спаяна из каких-то франзистов, релеев и так далее,
и, соответственно, ей на вход какие-то сигналы подаются, и что-то происходит на выходе. Вот,
вот размер – это, грубо говоря, стоимость схемы, то есть сколько элементов нам нужно, чтобы ее
спаять. Вот, и если размер будет экспоненциальный, то тогда это очень дорого будет такой схемам
паять, и место намного занимает. Вот, так что это не очень хорошее решение. Вот, а вот глубина
отвечает за быстродействие, да, потому что, как бы, каждый, да, по каждому проводку сигнал идет какое-то
время, да, и пока он сверху до низу дойдет, это как раз более-менее глубина. Вот, поэтому нас и
то и другое интересует, в принципе. Вот, ну и мы обсуждали, значит, что p-slash-poly
значит, p-slash-poly – это класс языков, да, если у нас на выходе один бит, да, то это то же самое,
что распознавание языка, да, то есть верно ли, что то, что на входе, принадлежит какому-то
языку. Значит, p-slash-poly – это класс языков, класс языков, распознаваемых,
имействованный схем, имействованный схем размера полинома от n. Вот, ну а нас интересует,
значит, нас интересуют классы схем еще маленькой глубины. Так, давайте вот я сюда перейду,
это значит будет новая, новая тема, новые классы. Значит, nc с индексом d. Значит, это класс языков,
класс языков, распознаваемых, семействованный схем, семействованный схем полиномиального
размера и глубины, вот большой, вот логарифм n в степени d. Вот, значит, буквы nc на самом деле
ничего специального не обозначают, этот класс имеет как бы назван в честь конкретного человека,
а именно nc означает nix-класс. А ник это Николас Пипинджер, в общем, такой ученый. Не знаю,
почему так сложилось. Видимо, он там как-то о нем заговорил в какой-то момент, в честь него назвали.
Есть еще аналогичный класс sc, sc – это Steve's-класс в честь Тивина Кука,
которую теряем Кукулевину. А там, кажется, сейчас, я не помню, что такое sc, может посмотреть. Там
что-то одновременно про, а, кажется, это полиномиальное время и полиномиальная память,
потому что логарифмическая память автоматически по полиномиальное время, а полиномиальная
логарифмическая уже не автоматически. И наоборот тоже. Если то и другое, то это Steve's-класс.
Вот, а еще есть аналог, аналог ac с индексом D. Это аналогично, но элементы конъюнкции
могут получать сколько угодно проводков на входе. Но элементы конъюнкции и дезюнкция имеют
сколько угодно входов. То есть даже, может быть, нефиксированное число,
но, конечно, полиномиальное, потому что всего полиномиальное число элементов.
Можно эту оговорку не делать, потому что это автоматически будет получаться. Если вдруг два
провода идут параллельно, то можно из них один оставить. А тогда будет всего проводов не больше
чем элементов, а элементов всего полиномов. Но можно и явным образом указать. А тут буквка K
вообще означает any. То есть сколько угодно. Any number of inputs-класс. В общем, сложились такие
обозначения. Давно сложилось в 80-х годах. Вообще, можно сказать, если немножко обратиться к
истории этой науки, то в начале 70-х предложили вопрос о равенстве P и NP. Нашли кучу NP полных
задач. Но также увидели, что известные методы типа диагонализации не работают. Потому что
начали сразу изучать анонимичную теорию с аракулами. Аракула означает, что значение какой-то
функции можно получать мгновенно. И это может вообще расширить класс вычислимых функций, может
ускорить существенные вычисления. Там есть такая теория М. Бейкера, Джилла С. Л. Вэя, которая говорит,
что для какого-то аракула P равно NP, а для какого-то P не равно NP. Ну а разные известные методы,
еще есть теория вычислимости типа диагонализации, они, если уж работают, то работают и с аракулом тоже.
Например, теорема о том, что проблема остановки неразрешима, она работает и для обычных
вычислений, для вычисления с аракулом. Получит, что она неразрешима с тем же самым аракулом.
И всякие другие теоремы с теоремой вычислимости тоже этому соответствуют.
Ну а вот здесь не так. Ну и стали думать, что еще можно делать потом в 80-х годах. То есть вообще
теорию схемы еще даже раньше была известна, в конце сороковых ее Шинон придумал. Но постараться
прикрутить ее к проблеме P равно NP придумали вот в 80-х годах. И план был такой, что попробовать
доказать, что вот сюда не входит NP. То есть для задачи выполнимости доказать, что для нее нет
семейства схем полинейного размера. В общем, тогда был некоторый энтузиазм. Мы придумали
новый способ, комбинаторный подход. Сейчас там что-нибудь сделаем. Но оказалось, что нет,
не получится. Закончилось это все теоремой о естественных доказательствах разбора Ивырудича,
которая в общем-то говорит, что простые методы тут точно не подойдут. Но тем не менее,
в том и теории много чего интересного. Ну и в частности, вот эти вот семейства классов,
они на самом деле образуют иерархию. Значит, каким образом? Ну, НС0 вложено в АС0. Это вложено
в НС1. Значит, это вложено в АС1. Это вложено в НС2. Ну и так далее. Ну, значит, здесь, то есть в
общем случае получается, что НСДТ вложено в АСДТ. Это вложено в НСД, плюс первое. Ну, здесь первое
вложение очевидно, потому что два — это пример произвольного числа. То есть если можно сколько
угодно входов, то в частности можно два входа, поэтому та же схема подойдет. Здесь вот просто
годится та же схема. Вот, а второе, что АСДТ вложено в НСД, плюс первое, тоже довольно легко. Ну,
а именно мы просто делаем двоечное дерево. Мы заменяем конъюнцию К переменных на двоечное
дерево. Значит, сначала их по парам берем конъюнцию, потом результаты тоже по парам и так далее.
Соответственно, тут получается, что заменяем функцию. Функция — это конъюнция или дезюнция
от К переменных. Значит, функция от К переменных на двоечное дерево, на двоечное дерево глубины
логарифм К. Ну, формально, да, можно прямо поставить что-то. Даже без два большого
можно ценить верхнюю целую часть от логарифма К. Вот, значит, возникает вопрос, насколько это
строгие вложения. Значит, про строгие вложения известно не так много. Значит, известно сиарема,
что НС0 строго вложено в АС0. А что, когда вообще, если у нас ноль в инэрсе? То есть что? Логарифм
нулевой степени. А что, когда логарифм нулевой степени? Это единица. То есть получается, что глубина
константная. Да, и получается, что НС0 — значит, это схемы константной глубины. Значит, схемы
константной глубины. Вот, и при этом входная степень у конюнса-дизюнкса будет ровно два. Значит,
схемы константной глубины с элементами сходящей степени два. Вот, ну что это значит? Это означает,
что у нас, как бы, самый нижний элемент максимум имеет там два входа. Те, откуда туда идет,
и тут проводки имеют тоже максимум два входа. То есть на следующем же максимум четыре. Элемент
зависит дальше, максимум восемь. И так далее. Мы идем до самого верха. Но поскольку всего уровня
константа, то получается, что если глубина С, то тогда ответ зависит максимум от два в степени С
бита входа. Да, то есть получается, что если глубина С, то тогда ответ зависит от не больше
чем два в степени С битов входа, независимо от общего их числа. Значит, при любом их общем числе.
Вот. Ну а тогда что же получается? Получается, что если всего битов больше, чем два в степени С,
то от некоторых ответ не будет зависеть. Потому что просто не хватит проводов, чтобы ко всем
подключиться. Получается, что если Н больше, чем два в степени С, а поскольку С константа,
так может быть. Если Н больше, чем два в степени С, то ответ зависит не от всех битов входа.
Вот. Ну а если мы возьмем просто конъюнцию всех аргументов, то это с одной стороны будет вакция
ноль. С очевидным причином, да, потому что у нас просто есть такой элемент конъюнции всех входов.
Вот. А с другой стороны, эта функция будет уже зависеть от всех битов входа. Но конъюнция
тех аргументов, получается, что лежит вакция ноль, и при этом зависит от всех битов входа.
Вот. Ну то есть получается, что такая конъюнция, она лежит вакция ноль, но не вэнсэ ноль.
Конъюнция лежит вакция ноль, но не вэнсэ ноль. Так. Ну вот, довольно простое рассуждение. Есть
более сложная теорема, что вакция ноль строго вложена в вэнсэ один. Вот. Это я уже не докажу
целиком. Там довольно сложная агитабрическая техника. Вот. Но я покажу пример. Да, значит,
идея доказательства, или даже может конструкция доказательства, что нужно рассмотреть parity
function, значит, XOR. Вот. Сумма у нас для 2, но там не пары, а всех аргументов. Значит, XOR от всех
аргументов, значит, лежит вэнсэ один, но не вакция ноль. Вот. Но есть легко первую часть доказать,
да, почему XOR лежит вэнсэ один. Значит, XOR лежит вэнсэ один. Просто, значит, рассматриваем,
значит, рассматриваем двоичное дерево, рассматриваем двоичное дерево из XOR. Ну и как раз,
чтобы подключиться ко всем элементам, нам нужно, чтобы глубина была логарифмем.
Глубины логарифма. Вот. Ну и поскольку XOR ассоциативен, то можно вот так вот делать. Вот. И кроме того,
значит, XOR можно заменить на схему там глубины 3. Поэтому общая глубина будет вот эта логарифма
умножить на 3. Значит, XOR от двух элементов вычисляется схемой глубины 3. Вот. Поэтому, значит,
поэтому XOR лежит вэнсэ один. Вот. Ну а вот то, что он не лежит вакция ноль. Ну вот это вот сложное
рассуждение, но идея здесь такая. Значит, сложное рассуждение. Значит, идея такая, что у XOR очень сильно
зависит от всех своих аргументов. То есть у XOR при изменении любого аргумента меняется значение.
Значит, XOR при изменении любого аргумента меняется значение. Вот. Ну а вакция ноль так не получится,
да, потому что. Ну вообще у конъюнции, у дезюнции. Ну отрицание, оно просто одинаково
приворачивает аргумент, да, и оно как бы не сильно увеличивает зависимость. А вот у конъюнции,
у дезюнции получается, что на самом деле довольно редко бывает так, что изменение одного аргумента
меняет значение. Вот. Ну и дальше нужно сказать, что действительно константом числа уровня не
хватит, чтобы добиться вот таких изменений. Вот. Соответственно, конъюнция и дезюнция редко
меняется, редко меняется значение при изменении аргумента. Ну и как бы доказывается, что константной
глубины не хватит. Константной глубины не хватит. Вот. Ну это, конечно, ни в коем случае
не доказательство, да, это некоторое объяснение природы, почему так получается. Вот. Ну а доказательства,
здесь хотите, можно в Нишкиароро-Рыбарак, например, найти. Вот. Или еще где-нибудь. Так. Ну ладно,
значит, вот эта вот краткая идея. Так, теперь перейдем к тому, что я анонсировал. Значит, это
быстрые сумматоры. Вот. Ну вообще сложение чисел двоечной записи, это одна из базовых операций
в компьютерном процессоре. Вот. Поэтому хорошо бы, чтобы оно происходило быстро. Вот. Ну, значит,
это немножко, да, значит, отличается от того, что нарисовано на первой доске. Да, значит, там выход один.
Ну а сумматор, можно, конечно, ставить задачу проверки корректности вычисления. Но вообще-то,
да, в процессоре не нужно проверять корректность стационирования, да, нужно суммировать. Вот.
Поэтому можно себе представлять, да, как бы сумматор, как вот такую вот микросхему. Значит,
где вот есть одна группа входов, это число А. Вот. И есть другая группа входов, это число В. Вот. Ну и,
соответственно, есть выходы, которых, наверное, один больше. Вот. Соответственно, да, должно быть так,
что вот, значит, здесь на вход А, здесь на вход В, а здесь С, которое равно А плюс В, и уже не Х,
а какое-нибудь побитое, а настоящее сложение в речной записи. Вот. Соответственно, вот. Глубина,
значит, глубина, ну это получается время работы. Вот. И поскольку это базовая операция,
значит, чем быстрее процесс будет это делать, тем лучше. Вот. А если делать обычным образом,
да, значит, сложение в столбик справа налево, вот, получится глубина порядка m. Значит, dn число знаков.
Значит, соответственно, школьный алгоритм. Школьный алгоритм. Сложение в столбик
дает глубину, ну, n я напишу. В таких, значит, таких случаях часто говорят о большой от m,
но это, вообще говоря, немножко неграмотно. Надо вообще записать омега большой от m, потому что
нас интересует нижняя оценка, а не верхняя. То есть нас интересует не то, что не больше n
глубина, а то, что она не меньше n. Но в принципе, она будет ровной, n там плюс-минус 1. Вот. Почему
так происходит? Ну, как вообще устроена алгоритм в столбик? Ну, у нас, ой, слушайте, давайте я
c лучше, дайте, тут r будет основной результат, или а, s давайте, s от слова сумма. С от слова
сумма, а c это у нас будет от слова carry и перенос. Значит, вот здесь сумма, сумма а плюс b. Значит,
нужно вычислить, нужно вычислить c. Значит, c это трокопереносок, трокопереносок. Вот. И после этого
будет просто то результат, s ита, это будет а ита, xор б ита, xор c ита. Если мы уже откуда-то выяснили,
какие переносы, то дальше можно просто вот так вот вычислить, да, и ни о чем не думать. Вот.
А с другой стороны, откуда переносы возникают? Ну, смотрите, у нас на предыдущем шаге надо еще
договориться, с какой стороны мы нумируем биты. Вам как больше нравится, последнего или с первого?
С первого, да. В общем, по-разному, да. Ну, ладно, с первого, значит, они тут будут нумерироваться,
значит, первой и так далее и энной, значит, первой и так далее и энной, а вот здесь еще нулевой
получит, да, потому что сумма может быть на 1 бит длиннее. Значит, 0, 1 и так далее. Вот.
Тогда, соответственно, чтобы посчитать перенос, нужно посмотреть на биты в более мальшем разряде,
да, если там есть хотя бы и надо посмотреть на бит А, на бит В и на бит переноса в мальшем разряде.
Вот. Если там хотя бы две единицы, то тогда перенос будет. А если там 0 или 1 единица,
перенос не будет. Вообще-то, функция большинства на самом деле.
Значит, вычисление СИТ, да, на самом деле СИТ будет равен большинству, значит, большинству из,
соответственно, С, а и плюс первая, В и плюс первая и С и плюс первая. Вот. И эта формула даже на краях
работает, да, если считать, что те биты, которых нет, равны нулю. Да, значит, получается, что,
когда мы СН вычисляем, то у нас АН плюс первая и БН плюс первая равны нулю. А СН плюс первая,
даже неважно, можно считать тоже АН нулю, да, в любом случае большинство будет ноль. Значит,
поэтому самым последним столцей переноса не может быть. Вот. Ну а дальше уже, может быть,
и еще мы С0 можем вычислить. Значит, С0 может получиться единицей, но вот А0 или Б0 точно ноль,
это тогда здесь будет один. Вот. Ну и вот за счет, значит, за счет вот такого вот, да, значит,
за счет такой зависимости, что у нас СН минус первой зависит от СН-ого. Ну ладно, СН равно нулю,
так что не зависит. А оно зависит от АН-ого и БН-ого, да. Вот. А поэтому, значит, чтобы штур Crown
минус первая, ну нужно посмотреть на АН и БН-ое, а чтобы штур СН-ой, нужно и на СН-ой тоже посмотреть,
чтобы штур С later N-а встрет side ANDfry, нужно посмотреть на С Минус Второе. И так далее,
значит каждый бит зависит от следующего, и поэтому получается глубина N есть, если это вычислять
непосредственно. Что же делать? Нужно каким-то образом
научиться вычислять переносы, не проводя всю эту цепочку.
Нужно научиться учислять переносы,
значит, не проводя всю цепочку, не проводя рекурсию,
не раскручивая всю цепочку. Ну, соответственно, могут быть разные
конкретные алгоритмы, значит, любой алгоритм, который так делает, и после этого
просто вычисляет по этой формуле, значит, называется бетонсуматором.
Ну и некоторые из них используются в реальных процессах. Так, ну давайте я один из них расскажу.
Значит, идея стоит в том, чтобы вместо переносов научиться вычислять другие биты,
так называемые биты, бит-генерация, бит-генерация – это бит-генерация переноса.
Это означает, что на каком-то участке перенос точно есть. Так, значит, это g, g ежитая равно единице,
если а ежитая плюс, так, сейчас ежитая непонятная, давайте я так напишу, и многоточие g,
то есть это участок, значит, участок числа а с этого индекса дожитого и плюс b, значит,
плюс b и так далее ежитая. Значит, если это будет, в общем, если это точно даст перенос,
а что значит перенос? Значит, будет сумма больше, чем 2 в какой-то степени, но если и и g включительно,
может, либо равно, то это будет 2 в степени g минус и плюс 1. Значит, как проверить? Ну, если и равно g,
если и равно g, то перенос будет, если в сумме равно 2. Вот, соответственно, как раз если и равно g,
то это сократится будет как раз 2 в первый. Вот, да, если там, если и и g соседнее, то там теперь оно должно быть равно, чтобы перенеслось.
Так, хорошо, значит, это бит-генерация, g от слова generation, еще есть бит-проталкивание,
проталкивание propagation. Бит-проталкивание, значит, это p и gt, p и gt равно единице, значит, если,
если мы посуммируем то же самое и получим число из одних единиц. Вот, то есть число из одних единиц будет,
здесь a и и так далее gt, плюс b и и так далее gt, значит, это будет равно 2 в степени g минус и плюс 1,
значит, и минус 1. Так, зачем нам это нужно? Ну, смотрите, если у нас получились на участке одни единицы, то если из младших разрядок пришел перенос,
то он как бы с этими единичками по принципу доминов поступит, соответственно, все эти единички будут заменяться на нули,
а перенос также появится, наоборот, в младших разрядах, то есть в старших наборах. Значит, если пришло из младших, то передастся в старшие.
Но если не пришло из младших, то старшие тоже ничего не передастся. То есть вот генерация, значит, генерация работает в любом случае,
независимо того, пришел перенос из младших или не пришел. Вот, а проталкивание работает только если пришел перенос из младших,
тогда он передается дальше. Вот. Ну что, понятная идея?
Мы как бы вырезаем, вырезаем из числа разряды световопожитые и их складываем, как обычно, то есть это миксора, это обычная сумма.
Вот. Соответственно, что потом дальше происходит? Ну, значит, дальше, если к этой сумме пришел перенос из более младших разрядов,
то там последние единички заменяются на нули, а последний нулик на единичку, если там хотя бы один нулик есть.
Вот. Но если оно из одних единиц стоит, как вот здесь, тогда там нет нулика, как перенос проталкивается.
Вот. А если получилось слишком много, если на разряд залезло, то неважно, пришел перенос или нет, в любом случае старший разряд переноса уходит.
Так. Ну ладно, сейчас перенос сделаем, а потом расскажу, как это считать и как потом, собственно, стать ответом.
Значит, два-третье. Тут идея следующая. Мы будем вот эти вот биты генерации проталкивания вычислять для выровненных, значит, как бы для выровненных участков длиной степень двойки.
То есть тут, давайте я нарисую пример. Пусть, например, длина будет 8.
Да, то есть сначала мы для каждой биты в отдельности вычислим, значит, потом, соответственно, значит, для участков по 2 бита, значит, потом для участков по 4 бита, ну и, наконец, для всего в целом.
Вот, значит, как это делается. Ну, значит, база очень простая. Значит, g i t i t это, на самом деле, конъюнция a i t i b i t.
Да, то есть точно, если у нас две единицы стоят, то тогда перенос генерируется. Вот, а проталкивается он, если одна единица стоит.
То есть g i t i t это будет xor, a i t xor b i t. Так как я там обозначал, что это самое. Вот, и это как бы база будет.
Ну, а дальше, дальше переход. Значит, переход проще всего делается с проталкиванием, то есть проталкивание, скажем, от i до k, это будет проталкивание от i до j и проталкивание от g plus 1 до k.
Ну, нужно, чтобы и, например, когда у нас будет вот здесь сумма всех единиц. Ну, когда вот здесь была сумма всех единиц и здесь сумма всех единиц.
Ну, потому что реально, ну реально это получается просто, в каждом столце здесь там стоит xor. Вот, да, то есть если это раскручивается, то будет просто конъюнция всех вот таких вот xor.
Ну, а с генерацией немножко более интересная формула. Значит, с генерацией формула такая. Значит, генерация на отрезке от i до k, это что может быть? Во-первых, может быть генерация от i до j.
Да, что если уже, если уже вот здесь вот генилируется перенос вот здесь. Да, то есть здесь вообще не важно, что происходит вот здесь, даже если там одни нули стоят, все равно уже здесь генерация произошла.
Вот. Или есть другой вариант. Другой вариант, что генерация произошла в раньшех разрядах, но при этом протолкнулась через старшие.
Да, то есть как бы у нас есть перенос отсюда сюда, а тут-то это одни единицы, поэтому получился перенос отсюда сюда.
Вот. Ну, соответственно, по таким формулам можно вычислить биты генерации переноса для всех вот таких вот выровненных отрезков.
А то есть, соответственно, если здесь, если здесь получаются n знаков, то здесь получается логарифмы.
Значит, логарифмы н-уровней.
Вот.
Ну, а дальше, как, например, понять?
Сейчас я здесь нумирую слева-направо, то есть от старших к младшим.
Да, как вот на той доске, условно, значит, нумируется бита от старших, которые слева, к младшим.
Поэтому, соответственно, в младших возникает перенос и проталкивается сквозь старшие.
Да, если наоборот нумировать, то и формулы будут тоже наоборот.
Вот.
Ну, а дальше, значит, дальше как... Так, давайте вот тут наверх.
0, 1, 2, 3, 4, 5, 6, 7, 8.
Значит, тут общие формулы не очень удобно писать, так что давайте я напишу конкретно, и тогда будет понятие общий смысл.
Например, теперь я утверждаю, что всех вот этих вот битов генерации проталкивания достаточно, чтобы вычислить все переносы.
Да, например.
Так, ну, например, C0 это просто генерация, да, генерация на всем числе, от 1 до 8.
Да, например, C4 это будет генерация от 5 до 8.
Вот, а вот, например, C2.
C2 это будет следующее, значит, это будет генерация от 3 до 4 или, значит, генерация от 5 до 8 и проталкивание от 3 до 4.
Да, эта вот формула очень похожа на вот эту.
Да, но, что еще раз?
Вот, значит, C это перенос.
Значит, C это перенос, откуда он возникает?
Он либо генерируется сразу, либо генерируется более мальше и проталкивается к данной точке.
Вот, значит, вот эта формула такая же, как здесь, только к этому отрезку мы не применяли эту формулу.
Вот, но можно, значит, когда мы по всем таким выровнянным уже все посчитали, можно и для более сложных посчитать, например, C1.
C1 это будет следующее, значит, будет либо генерация сразу во втором разряде, либо это будет генерация от 3 до 4 и проталкивание через второй.
Либо это будет генерация от 5 до 8 и проталкивание от 3 до 4 и проталкивание от 3 до 4 и проталкивание от 3 до 2.
Вот, ну, в общем, вот такого рода формулы для каждого бита, для каждого бита переноса можно написать.
То есть, в чем идея?
Идея в том, что мы в каком-то разряде смотрим и берем участок от этого разряда, ну, точнее, от следующего разряда до самого конца, до младшего,
и его разбиваем, значит, разбиваем на как можно больше участки, которые мы уже посчитали, проталкивание и генерация.
Ну, и вот таким образом мы из них, соответственно, набираем ответ.
Так, ну, чего, понятная идея?
Вот, ну, теперь надо аккуратно посчитать, надо аккуратно посчитать, какой тут, собственно, размер, какая глубина получится.
Вот, ну, размер-то, понятно, что полинамиальный, да, потому что у нас всего, его N, N на логарифм N, вот этих битов генерации проталкиваем, мы считаем,
и еще считаем N битов переноса, да, и все формулы тут полинамиальной длины максимум, вообще даже логарифмической,
вот, поэтому все это получается полинамиального размера.
Ну, а глубина получается логарифмическая, да, потому что, смотрите, один логарифм, это, собственно, вот это вот,
потому что здесь все, все биты с более низких уровней используют биты с более высоких,
но при этом используют, то, как они используют, это константная глубина,
да, то есть, тут, ну, тут это на самом деле формула от трех битов, да, тут индексы сложные,
да, но реально здесь просто три бита представляются, вот, в такую простую комбинацию.
Вот, поэтому получается сначала логарифмический этап, значит, логарифмический этап, это вычисление битов генерации проталкивания,
а потом еще вот это вот все, вот, но и это, даже если у нас дезюнкция и конъюнкция только двух зависит,
это все равно будет логарифмическое, вот, и, соответственно, этот логарифм добавится к этому,
да, там не перемножится, а добавится, потому что мы последовательно, да,
последовательно сначала вычисляем одно, потом вычисляем другое.
Умножаться будет на логарифме, если бы мы ввяли какую-нибудь логарифмическую цепочку,
и в ней каждый элемент заменили на какую-то схему глубины логарифма,
да, вот тогда глубины будут перемножаться, да, значит, если мы на каждом уровне заменяем просто элемент на что-то большее,
вот, а здесь мы не заменяем, а просто сначала идет одно, потом другое,
поэтому логарифмы складываются и все вместе тоже получается логарифм.
Вот, значит, в итоге получаем, что сложение будет в Nc1,
да, то есть,
итог получаем, что сложение будет даже, да, даже не в Nc1, а в Nc1.
Так, ну ничего, понятно?
Есть какие-нибудь вопросы?
Вот, но вот в реальных процессорах примерно это используется,
только обычно там в качестве базы не один бит берется, а, кажется, четыре,
да, то есть, когда мы четыре бита складываем, то быстрее получается по определению.
Ну, как бы непосредственно, да, не усложнять, да,
а вот если и дальше вот эти блоки с четырех берутся как базовые, и дальше они уже комбинируются,
ну, либо таким образом, либо каким-то еще.
Так, что еще я хотел бы обсудить?
Ну, кроме, значит, кроме суматости,
кроме сумматоров еще бывают мантипликаторы.
Опять же, каждый процессор, кроме
сложения, требует и умножения. И вообще, как
правило, умножение — это более трудоемкая
операция, чем сложение.
Есть, например, такая известная
тема. Это оптимальные алгоритмы
умножения матриц. И там идет, например,
экономия на мультипикативных операциях
при увеличении аддитивных.
То есть, когда ставится вопрос
о оба симпатически сложных
умножения матриц, то считают
именно мультипикативная операция,
если оказывается меньше умножения
за счет большего числа сложений, то это
теоретически асимпатически будет
лучше. На практике матрицы умножают
просто по определению, хотя
асимпатически там больше умножений,
но все-таки это получается лучше.
Так, ну хорошо, тем не менее, какая
сложность будет с точки зрения схемы?
Так, теперь, значит, мы умножаем.
Умножение двоечных чисел.
Ну, смотрите, что вообще происходит при
умножении. Да, умножать тоже можно в
столбик, что конкретно там происходит.
Ну, давайте я покажу какой-нибудь пример.
Значит, например, там 1, 0, 1, 1, 0. Мы умножаем
на какой-нибудь там 1, 1, 0, 1, 1.
Например, вот так вот. Значит, что происходит?
Да, ну как? Ну, как нас в школе учили,
умножаем на это число, но оно здесь
либо 0, либо 1. То есть, фактически мы либо
копируем вот это вот, либо просто
пропускаем строчку. То есть, как получается
там 1, 0, 1, 1, 0. Дальше потом сдвигаем там
1, 0, 1, 1, 0. Дальше как бы строчка пропускается,
но можно написать там строчку задних нулей.
Вот, и еще два раза так.
Вот. И дальше нужно это все сложить, да, и
будет ответ. Вот. То есть, что получается?
Получается, что сложение, это
итерированное сложение, да. То есть, нам
на самом деле, чтобы получить ответ, да,
чтобы получить ответ умножения, нужно сложить
сколько чисел, сколько у нас разрядов, да. То есть,
на самом деле, умножение, умножение
n-битовых чисел, значит, сводится
к сложению n штук, значит, n штук
соответственно n-битовых чисел.
Вот. Ну, соответственно, первая идея, это
просто использовать предыдущие, но тогда
как раз логариф в квадрате получится, да. То есть,
мы как бы что можем делать, да, мы можем сложить
сначала вот эти вот два, там потом вот эти вот
два, потом результаты, и потом еще добавить
последние, да. Но вот так как раз будет
глубина логарифа в квадрате, да, потому что как раз
у нас дерево-дерево-сложение глубины
логарифмен, и каждое отдельное сложение тоже
тоже глубина логарифмен. Да, соответственно,
если, значит, можно сложить при помощи
двоичного дерева,
но так получится глубина логарифа в квадрате. То
есть, это, по крайней мере, n-c, да, я, кстати, не
сказал, n-c без индекса, это обзнение всех n-c
деток, да, то есть, хоть с какой-то
полиэлографмической глубиной. Значит,
так получится глубина порядка логарифма в квадрате.
Вот, что, конечно, хорошо, но не настолько хорошо,
как могло бы быть, да, потому что лучше бы все-таки
была, да, значит, лучше бы была глубина
логарифма. Вот, и так действительно можно
сделать. Так, значит, можно добиться, можно добиться
глубины порядка логарифма, если действовать
иначе. Так, я вам расскажу, как, довольно интересно.
Да, тут, на самом деле, я не знаю, что конкретно
в процессорах делают, надо посмотреть где-нибудь.
Вот, но мне кажется, что вот этот момент, который
я сейчас расскажу, он и на практике должен быть
довольно эффективен. Да, не только теория. Вот,
соответственно, тут базовая, значит, базовая операция
такая, да, значит, мы превращаем тройку, значит,
тройка чисел x, y, z превращается в пару u, v, такую, что x, x
plus y plus z равняется u plus v, и при этом это преобразование
делается в схемы константной глубины. Да, то есть глубина
здесь получается константной. Вот. Так, как это делается?
Ну, а сами смотрите, тут происходит следующее,
значит, мы просто суммируем, значит, суммируем в каждом
разряде без переноса. Тогда, если у нас три числа, в каждом
0 или 1, то получится число от 0 до 3. То есть, вот это
делает так. Значит, суммируем каждый разряд, каждый разряд
без переноса. Вот, соответственно, три числа, три числа 0
или 1 превращается в одно число от 0 до 3. Вот. Но число
от 0 до 3 как раз выражается двумя битами. Значит, и, соответственно,
первый бит этого числа это соответствующий бит u, ну,
со сдвигом как бы, да, а второй это бит v. Значит, первый бит
этого числа это бит u, значит, а второй это бит v. Так, ну,
давайте я какой-нибудь пример покажу. Значит, например, 1, 0, 1, 1, 0
плюс, например, 1, 1, 0, 1, 0 и плюс, скажем, 1, 0, 1, 1, 0.
Так, два одинаковых. Давайте, чтобы все разные. Вот так вот. Нет, все.
Давайте вот так вот. Вот. Так все варианты есть. Вот. Тогда, смотрите, да, значит,
так, как бы, если мы просто просуммируем, да, без переносов, да, то получается
3, 1, 1, 2, 0. Вот. Ну, а если представить двоечную записи, да, то тут получается
как бы 1, 1, 0, 1, 0, 1, 1, 0 и 0, 0. Вот. Ну, и, соответственно, получается так,
значит, это у нас x, это y, это z. Значит, скажем, второй бит это бит v.
Значит, соответственно, v получается из вторых битов 0, 0, 1, 1, 1, а u получается
из первых битов, но со сдвигом. Да, соответственно, 0, 1, 0, 0, 1.
Вот. Ну, это действительно, да, как бы вот это вот 0, 0, оно дает 0 сюда и 0 сюда,
а 0, 1 даёт 0 вот в этот разверт, 1 вот в этот разверт.
Там 1, 1 даёт 1 в этот разверт, 1 в этот разверт. Вот.
Это действительно, значит, действительно суммирование ровно так и получается.
Так. Ну чего, понятно, почему у нас сумма та же самая получится?
Вот. И глубина действительно, да, глубина действительно константа, да,
потому что, ну, фактически тут получается то, что у нас уже было, да, то есть
фактически бит v это xor, да, прямо можно формулу написать, да, там v и t это
x и t, xor, y и t, xor, z и t, а u и минус первое, это, соответственно, большинство,
большинство из x и t, y и t, z и t.
Вот. Ну, вот такие, такие формулы дают рецепт как-то вычислить.
Вот. Ну, а дальше-то что получается? Если нам нужно сложить n чисел, да, то мы
их разобьём на тройке и теперь каждую тройку заменим на пару.
Дальше, соответственно, у нас получается n чисел.
Дальше-то мы тройку заменили на пару, соответственно, у нас вместо трёх чисел
осталось два числа, то есть мы поделили в полтора раза, да, получается две
трети n, потом ещё раз полтора раза, там, четыре девятых n, вот, ну и так далее.
Вот. И дальше, соответственно, там будут какие-то, понятно, если нам
что-то не делится, будут какие-то лишние оставаться, мы их тоже присоединим
и так далее. Вот. В общем, в конце будет тридцать, а в конце, в самом конце
будет два числа.
Вот. И этапов тут будет примерно логарифм n по основанию 3 вторых.
Да, то есть тут вот будет логарифм n по основанию 3 вторых этапов.
Вот. Ну, это будет порядка логарифма, да, потому что логарифмы все, если
приходить к другому основанию, то будут изменяться в конце анатураза, да,
по известным формулам.
Вот. Ну, а после этого, когда уже в самом конце два числа уже
будет третий этап, то это будет логарифм н по основанию 3 вторых этапов.
Вот. Ну, а после этого, когда уже в самом конце два числа осталось, то мы их
сложим уже исходным алгоритмом.
Да, значит, когда осталось два числа, то тогда следовательно сложим
сложим исходным алгоритмом.
Ну, вот, значит, итоговая глубина будет действительно логарифмическая, да,
потому что вот это вот число этапов умножится на константу, которая здесь, да,
будет логарифм, но еще добавится, добавится еще логарифм вот отсюда.
Вот.
Есть какие-то вопросы?
Так. Ну, а, значит, у меня чуть-чуть времени остаёт. Дальше я так срокими
мозгами в конце свяжу вот эту вот тему с логарифмической памятью.
Значит, на самом деле будет верно следующее.
Значит, связь, связь с логарифмической памятью.
Значит, оставим вот в той иерархии NC и AC классов, там еще и L и NL будут.
Значит, а именно верно следующее.
Значит, NC1, но при этом не просто NC1, а то, что называется лог равномерная,
лог-юниформ.
Это означает, что можно генерировать, значит, можно генерировать
тему для N-входов на памяти порядка логарифма M.
Тема с N-входами не просто вычислима, а вычислима, вычислима на памяти
этого большого от логарифма M.
Вот, тогда вот эта NC1 будет ложна в L, значит, L, как мы знаем, ложна в NL,
а NL будет ложна в AC1.
И на эту тоже можно ставить лог-юниформ, но это не очень важно.
Вот, значит, на чем это основано.
Значит, опять же я подробно не буду объяснять, но идея следующая.
Ну, вот это вот на чем основано.
Ну, на том, что мы просто...
Ну, тут, смотрите, сама схема может быть вовсе не логарифмического размера,
а полинамиального.
Но получается, что любой конкретный...
Да, и тут еще важно, что это именно NC1, то есть у каждого элемента ровно два предыдущего.
Ну, соответственно, идея, что мы на логарифмической памяти устроим рекурсию
и просто все вычислям.
То есть у нас есть какой-то ответ.
Для него сначала две части нужно посчитать.
И мы сначала посчитаем одну часть, потом другую, если надо.
Если надо, имеется в виду следствие, что если мы конъюнцию считаем
и у нас первая половина 0 получилась, то уже может трое не считать, уже ответ 0.
А если первая половина 1, тогда вторую тоже нужно посчитать.
И что получится, то и будет ответом.
Не-не-не, прямо сама схема вычисляется.
Строчка, ну да, то есть нужно сказать, что машина получает N в унарной записи,
то есть машина получает строчку из N единиц
и возвращает прямо схему, используя порядок логарифма N в рабочей памяти.
Нет, смотрите, мы не только можем вычислить саму схему,
но еще и ее ответ на любом входе.
То есть как бы вот эта вот программа, которая вот здесь,
которая на лог памяти вычисляет функцию, она делает следующее.
Она вычисляет схему и в нее подставляет свой аргумент.
Но она не может целиком вычислить схему и ее хранить.
Да, она только может, любой участок схемы может по заказу вычислить,
а целиком она не может хранить.
Ну, соответственно, работа у нее будет как раз такая, что она берет выходной проводок,
у него там два входа, значит, она идет к одному, вычисляет налог памяти,
потом идет к другому, на той же самой памяти ее вычисляет.
И так все рекурсивно получается.
И за счет того, что здесь логарифмическая глубина, ну, за счет вот этого,
не это в логарифме, а вот это в логарифме,
за счет того, что здесь логарифмическая глубина,
глубина рекурсии тоже будет логарифмическая,
и поэтому выдаст вашу логарифмическую память.
Такая вот идея.
Ну не знаю, что-то я чувствую, что это не очень медительно, нормально.
Не, ну подробно, подробно не хочется мне развесть, более времени не осталось.
Ну дайте я кем-нибудь какую-то основную идею напишу, что можно вычислять значение схемы
на заданном входе на логеретмической памяти. Вот, ну то, что L в NL это мы уже знаем.
Вот, ну а вот здесь вот, значит, почему NL вложено в Oc1, это еще некоторый шаг,
с умножением кисел. Нужен шаг с умножением матов. Потому что NL, ну там еще нужно отдельно
доказать, скажем, что Oc1 замкнута относительно лог свадимости. Тут нужно сказать, что Oc1
замкнута относительно свадимости. И второе, что задача достижимости F лежит в Oc1.
Ну и вот это вот основано на умножение матриц, потому что вот если мы матрицу смежности умножаем,
то мы получаем матрицу из кисел, которые будут равны числу путей из одной мишины с другой.
Вот это вот на основе умножения матрицы. Вот, ну а соответственно, нам фактически нужно
NL возводить, а это будет логарифм N в изведении в квадрат. То есть, чтобы возвести A в N,
нужно возвести в квадрат, еще в квадрат, еще в квадрат, и так логарифм N раз. Матрица
в N в степени, это будет A в квадрате, еще в квадрате, еще в квадрате, и так далее.
Значит так, логарифм N раз. Ну а соответственно, просто квадрат вычисляется как раз в Oc0.
Ну, просто более-менее по определению, что такое умножение, что это в каждой ячейке мы
вычисляем какую-то сумму произведений. Но произведение просто комьюнсы, а сумма,
ну а на самом деле, так, я тут немножко в ловушку попался, если прямо обычное умножение брать,
то там будет сумма, а сумму нельзя в Oc0 сделать. Но на самом деле нам нужно не обычное умножение,
а дизюнкное, где вместо суммы будет дизюнкция. Нам не важно сколько путей, нам важно есть или нет.
А дизюнкция, раз, можно в Oc0 сделать, и поэтому получится именация 1, а не Nc2.
Ладно, вообще вот такая вот интересная область, интересная с точки зрения теории, с точки зрения
практики. Конечно, я только какие-то самые азы ее затронул, надеюсь, это было интересно.
В следующий раз мы начнем рассуждение про вероятностные числения, вероятностные
машины тюринга, вероятностные основные классы. На этом на сегодня все, спасибо.
