Сегодня мы начнем говорить вообще про новую тему, которая у нас не было.
Давайте, прежде чем мы начнем, вспомним, на чем мы закончили в прошлый раз,
потому что это нам будет достаточно важно в контексте сегодняшнего занятия.
У нас была лемма о разрастании, мы с вами сказали, что один язык не является автоматом.
И нам нужно попытаться сделать такую конструкцию, которая сможет расширить этот пример.
Так, товарищи братья и товарищ сосед, вы забыли, где мы находимся, да?
Спасибо. В прошлый раз мы с вами построили минимальный PDKI и поняли, что класса языков распознаваемых автоматами достаточно мало.
Поэтому нам нужно расширять некоторую концепцию.
Сегодня мы с ним будем расширять. Мы ведем понятие порождающих грамматик.
То есть мы переходим от более высокого синтеза от регуляра к грамматикам.
И наша цель сегодня построить иерархию порождающего грамматику.
С кем-то на семинарах мы уже начинали, но те, кто еще контрольную не писал,
с теми, кто контрольную писал, вы начнете это делать на следующих семинарах.
Вот. Давайте введем в определение.
Значит, сразу я параллельно буду тублировать на доске.
Значит, порождающая грамматика это у нас четверка, не пятенка.
N sigma PS, где N называется множество вспомогательных и нетерминальных символов.
Sigma это алфавит, S это стартовый не терминал. То есть то, с чего мы всегда будем начинать.
И P это под множество правил.
Значит, N умножить на N и объединить sigma.
Звездочка. Только там не звездочка, а плюсик.
Видите, заметьте, что в определении P тут не звездочка, а плюсик.
И вот эти все дичайшие вещи мы будем обозначать греческими буквами.
Вот. То есть все правила будут иметь вид у нас.
Из альфа будет выходить β, где альфа это вот такая вот штучка, а β предложить вот.
Правила буду писать так.
Сложный пример.
Это вот концепция, именно ворождающая грамматик.
Замечу, что здесь может быть какая-то последний звук, и здесь может быть какая-то последний звук.
Только я почему-то люди не слышал.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Ну давайте пример какой-нибудь грамматики приведем.
Пример контакт ворождающей грамматики.
Лизы P.
Да хоть что угодно, на самом деле.
Все что угодно, что угодно.
Да хоть что угодно, на самом деле.
Все что угодно, что вычислимо, будет порождающая грамматика.
Вот это стукно.
С кубочными последствиями.
С кубочными последствиями мы разберем позже, это более узкий класс.
Чем это?
Давайте пример.
Там не знаю, А, В, А.
Тут пусть будет, А, В у нас будет запрещаться в какой-то ц.
А будет с переводителем в какой-то глагах.
Я не знаю.
Да, будет переводитель в какой-то ц.
Да.
Что у нас тут N?
Значит смотрите.
Маленькие группы, это символ алпанито будут.
Большие.
Будут состоять из-за терминала.
Ну, то есть это такая гатаса у нас с вами будет.
Так, хорошо.
Тогда у нас получается сигма.
В нашем случае, чему равняется?
Вот, например, это.
А?
Ну, А маленькая, ц маленькая, D маленькая.
А мы маленькая, что нележно.
А N большой, что у нас такое?
А,
А,
и?
И С.
И С.
С принадлежит к нам всем.
Тут можно поговорить, какие слова тут выводятся.
На самом деле, я тут подмашнил, и выводится здесь только одно слово.
А,
нет, сейчас.
С, D, C.
И только оно.
Давайте подумаем, чем не удобен этот пример?
А?
А как D, C бывают?
А, D, C.
А, да, а D, C тоже бывают.
Чем не удобен этот пример?
Это класс.
Да, тут сильно большая неоднозначность,
и то, что мы пытаемся раскрыть в левой части, оно состоит из чего-то непонятного перемешки.
Да, то есть тут может быть последствия с нитерминалов,
может быть последствия с терминалов, нитерминалов и так далее.
То есть это максимально недетерминированная фигня.
Давайте поймем, как мы эту штуку можем привести в порядок.
Не, ну понятно, что мы можем граф построить.
Но это вообще нет, чтобы это хоть как-то можно было использовать на практике.
А?
Можно ввести новые терминалы, но давайте немножко пойдем в другую сторону.
Пойдем в сторону ограничения.
Ну да, ограничение типа направо пойдем.
А?
Длину вывода можно ограничить.
Да, давайте сделаем позже.
Смотрите, к чему проблема.
Здесь вот надо, чтобы заменить одну часть на вторую, нам нужно собрать вот такой вот паттерн.
А этот паттерн может находиться, ну это здесь в простом примере, паттерн находится несложно.
А если мы захотим какой-то более продвинутый пример,
то у нас может быть, что нам эту часть надо как-то раскрыть,
и после этого только воспользоваться таким примером.
Первое ограничение, которое делается,
первое ограничение, которое делается,
давайте я в слайдах посмотрю, чтобы не путаться.
Да, в общем, да.
Давайте я немножечко про ограничение сразу поговорю, потом про выводим.
Значит первое упрощение, это контекстно-борождающая грамматика.
Не, контекстно-зависимая.
У них правила будут такие.
А фин, а.
Вот такого вида все правила будут иметь.
Где фин?
Дедочкой.
А, это не терминал.
А си, это тоже вот это вот фигня.
Альфа принадлежит.
В чем понт?
Почему та грамматика не является контекстно-зависимой?
Ну да, смотрите, вот это вот пример для того, чтобы вот пофиксить его.
То есть вот это вот правило, чтобы оно вошло в контекстно-зависимое,
нам нужно написать вот такую вот вещь, чтобы из АВ выводилось АС.
То есть у нас было АВС, нам нужно превратить в правило из АВ выводит АС.
Да, потому что вы должны сохранять контекст слева.
Вот он, контекст слева, мы его должны сохранить.
Давайте поймем тогда, как нам надо будет переделать правило из БА переходит в ДЦ.
Тут его можно несколькими способами пофиксить.
Как это правило можно преобразовать, чтобы эта история стала контекстно-зависимой?
Ну мы хотим понять, почему вот эта грамматика не является контекстно-зависимой
и построить какой-нибудь пример контекстно-зависимой грамматики.
Вот определение.
У него все правила имеют вид.
ФИАС выводится ФИАС.
То есть здесь фишки одинаковые, здесь фишки одинаковые.
То есть контекст относительно которого у нас раскрывается на терминал,
с левой и с правой он одинаковый.
Может быть теперь никакое заменение ФИАС в ДЦ не будет?
Мы его заменили вот таким вот Маккадом.
Это не точная замена правил грамматики, сразу скажу.
А мы здесь говорим следующую фигню.
Вот у нас нет терминала Б есть, да?
Это значит по определению.
У нас вот в правиле только один.
Это значит, что нам надо сделать?
Мы будем взять слева контекст.
Вот ФИАС в нашем случае это А будет.
И мы получаем с вами, что относительно того, что мы вводили,
должны добавить слева контекст ФИАС.
Получается, что здесь у нас должен быть А.
Чтобы этот правил был контекст-зависим.
Нет, мы не делаем эту штуку эквивалентной, конечно же.
Чтобы сделать эквивалентную, это надо постараться.
Здесь что мы с вами можем сделать?
Ну чтобы контекст сохранился.
Смотрите, здесь у нас в качестве А будет либо вот это Б.
И тогда у нас это правило можно переписать вот так.
Вот так.
То есть БА будет выводиться БДЦ.
Потому что А контекст.
Либо здесь мы можем сказать, что наш терминал это Б.
А А это контекст справа.
Тогда у нас появляется правило ДЦА.
То есть вот он.
Тут все это у нас.
Вот эта штука.
А ФИАС у нас это вот эта штука.
Что, разобрались в итоге с охраной, да?
Насколько я понял.
Так.
YouTube, здрасте.
Вот это.
Примеры строим.
Интересные.
Так.
Понятно, что такое контекстно-зависимая грамматика.
И как ее правило выглядит на примере.
Угу.
Ну, давайте теперь полный пример этой грамматики запишем.
Вообще вот тот пример.
Который у нас получается.
Из С выводится АБА.
Дальше.
Из АБ.
Выводится АС.
Ой, АС маленькая.
Третье правило нам не нужно переделывать.
А вот это давайте переделываем вот так.
Вот это пример контекстно-зависимой грамматики.
Угу.
То есть всегда у вас для терминала есть какой-то контекст.
А?
А, ну потому что слева пустой, вправо пустой.
Вот.
Тут АЛЬФ стоит.
Тут АЛЬФ в нашем случае это АБА.
Нет, нет.
Не, мы не делаем проект на грамматику.
Так, хорошо.
Давайте проверим тогда рубрику интуи...
А?
Почему?
Не, ну последнее правило у нас АЛЬФ это ТС.
А?
А почему?
Слева и справа пустой контекст.
Все.
То есть здесь все что угодно может быть написано.
Главное чтобы если у вас какие-то терминалы
что-то написано слева и что-то написано справа,
то здесь правая часть справа, оно тоже должно продублироваться.
А?
Да, пустой контекст слева, а справа контекст А.
Ну все равно сложно парсить, да?
Согласны?
Для человека сложно воспринять.
Так, переходим к следующему классу.
Класс номер получается.
Тут у нас...
Давайте вот этот класс нулевой будет у нас.
Контексты порождающие.
Контексты зависимы первый класс.
А второй класс будет контекст свободный.
И мы как раз с этим классом будем разбираться очень-очень долго.
Что вам не нравится в определенном контексте независимой грамматики?
Зависимость от контекста.
Зависимость от контекста.
Ну давайте его уберем.
Значит все файлы будут иметь вид.
А альфа?
Ведучка.
Ведучка.
Что, закрытие?
Ну давайте подвесим.
Так.
Пока, скажите какой пример контекста свободной карачки вы знаете, наверное.
Вы спустите по поводу этого.
А?
Да.
А?
Да, PSP находится здесь.
А?
Пример.
Да?
Какой еще пример был?
Ардиналы?
Нет.
PSP.
Как строится PSP?
Да, смотрите.
Первое правило.
Засвобуется S он?
То есть он пустой вот.
Так.
Так?
S?
Тут обозначают либо символ, давайте я скажу вот так.
Так алфавит, какой у нас тут?
В этом примере.
Из каких символов состоит?
Левая столбка и правая столбка.
А N это S.
Вот так.
Наоборот.
Вот такой пример.
И давайте второй пример разберем сразу.
А?
Epsilon.
Epsilon пустой слова.
А оно как было пустым словом, так и у нас остается.
И пример второй.
Давайте придумаем.
Давайте подумаем, как N и B в N построить.
Давайте начнем со старта.
Epsilon.
Ага.
А если можно поделить его A6?
Да.
Именно так.
Ну на семинарах более формально, покажем как это доказывается.
То есть смотрите, что у нас получается.
То есть смотрите, что у нас получается.
Класс контекстно-свободного грамматика уже шире, чем класс автоматных языков.
Ну больше выключение.
Ну это мы еще покажем сегодня.
Ну такая загвоздь.
Давайте так точнее, что у нас есть пример контекстно-свободного языка, который не является автоматным.
Да, и вообще он будет шире.
Так.
Это второй класс.
Чем эта штука неудобна?
Ну мы сейчас предоставляем, вы в предыдущих рассказали, чем эта штука неудобна.
Давайте подумаем здесь, чем эта штука может быть неудобна.
Да, вот этот ССС непонятно как ветвится.
Да, типа где у нас первая эска заканчивается, где вторая эска заканчивается.
Это вопрос однозначности разбора.
Мы тоже его поднимать будем.
Поэтому будем третий, более простой класс.
Поэтому будем третий, более простой класс.
Давайте скажем сразу, что у нас сначала будет проводиться какой-то набор не терминалов, а потом будет проводиться какой-то набор терминалов.
Ой, точнее, какой-то набор не терминалов, а потом какой-то набор терминалов, символов всего будет, потом не терминалов.
И это называется праволинейная грамматика.
Правила все имеют такой вид, либо из A в В, либо из A в W.
Где AB не терминал В, а В это ВО.
Ну то есть мы сразу понимаем, сначала у нас будет набор не терминалов, а потом мы раскрываем это все в В.
Что это терминал?
Не терминал.
Я что-то меняю.
Путаю терминал и не терминал.
Давайте пример.
Можно практично.
Есть идея?
А?
Ну хорошо, давайте просто берем вот такой вот.
Да, а сэмплера задается праволинейной грамматикой.
Почему?
Потому что у вас программа, что у вас может идти?
У вас может быть какая-то метка?
Ой, точнее, вот это слово у нас свое будет.
После этого у нас может быть какое-то правило драматичное.
Ну и это там, что-то в конце.
Что в конце сэмплера, программа?
Находится.
А?
Ну можно редко, потому что правила.
Ну можно сказать, что у нас программа пустым словом заканчивается, и все.
Вот эти правила, это как раз все манипуляции с регистрами.
Перекините из одного регистр в другой, делайте какую-то операцию.
Эти наборы конечные.
Плюс количество меток, которые у нас есть в ассендеровской программе, оно тоже ограничено.
Потому что размер метки ограничен 30 луней сегодня.
Вот эти конечные, эти конечные, по этому количеству правила у нас тут конечные.
Вот такой пример.
На самом деле мы сейчас построим намного больше препера, потому что мы с вами будем строить эквивалентность этого класса драматики какому-то другому классу языков, которые мы с вами уже знаем.
Ага.
Понятно? Вот это 4 класса драматики.
Повторяю. Контекстно-порождающая.
Ой.
Просто порождающая, контекстно-зависимая, контекстно-свободная и правая линия.
А у порождающих какое особенное свойство?
А?
А вот какое у порождающих было особенное свойство?
Да никакое, там бардак полный.
Нет.
Вот. Теперь давайте определим термин выводимости слов, опять же, для того, чтобы мы могли с вами все это формально задавать именно штопор.
Смотрите.
Значит, выводим определение штопора, это опять же, наименьшее рефлексивное отношение.
Такое, что для любого правила, которое лежит в нашей громой спе, все, что вы напишите слева и напишите справа, у вас будет выводимость.
На что это похоже сильно?
Не знаю.
Не-не-не.
Вот с учетом определений, которые мы давали.
На какое похоже? На зависимость на свободность или на этот?
На этот зависимость.
Так, на этот зависимость.
Так, на этот зависимость.
Смотрите, штопор мы делаем такое соотношение, что слева и справа мы можем дописывать какое-то контекст, и у нас все с вами будет получаться.
Ну давайте пример.
Пример штопора напишем с вами.
Давайте выведем PSP-шку вот такую.
Как мы ее можем вывести?
Ну давайте мы начинаем со стартового состояния.
Мы можем вывести вот так.
Значит у нас есть правило вот такое вот.
Дальше что мы можем сделать?
Какую-то скобок раскрыть?
Да, давайте чуть погромче где-нибудь напишу.
Смотрите.
Дальше у нас есть такое правило.
Такое правило.
Поэтому мы можем написать, что контекст SS выводится.
То есть вот это у нас с вами PSI, вот этого штучка.
И вот это PSI.
ФИ пустое.
Дальше что мы с вами можем сделать?
Да, можем раскрыть второе S.
То есть взяли вот эту штучку и подменили вот этой штучкой.
Дальше что?
Ну теперь нам нужно заменить.
У нас есть правило пустое, поэтому я тут уже буду писать по транзитивности.
У нас эту штуку выводят вот такую штуку.
И дальше мы еще раз заменяем этот контекст.
То есть получается...
Этот контекст.
То есть получается под этой заменой левый контекст это вот эта последовательность,
правый контекст это вот эта последовательность.
То есть смотрите, что у нас получилось.
У нас получилось, что из стартования терминала мы вывели какое-то слово.
Вопрос тогда.
Как мы можем определить язык, задаваемый грамматикой?
Да, все слова, которые выводим из стартового терминала.
Ну вот в принципе определение.
Слово выводится грамматикой, если из S можно достичь слова W,
а из S можно достичь слова D.
Если из S можно достичь слова W,
а язык распознается по рождаемой грамматикой,
если это множество всех слов, которые мы с вами выводим в грамматике.
Понятное определение?
Так, теперь смотрите, поскольку я немножечко поменял порядок слайдов
с методолога видения, давайте вспомним.
Эта штука, которую мы с вами задали, это иерархия Охомского.
Только она тут, видите, немножко в обратном порядке.
То есть сначала идут праволинейные грамматики,
контексты свободные, конъективы и порождающие.
Мы их с вами разобрали, но здесь по уровню вложенности языков
они находятся в обратном порядке.
Я думаю, этот слайд мы с вами уже подробно разобрали, со всеми примерами.
А теперь, бинго, как это соотносится с историями с автоматами
и всякими конструкциями?
А вот так это соотносится.
Значит, смотрите, праволинейная грамматика это, на самом деле,
ничто иное, как автоматы.
То есть любой язык, который распознается праволинейной грамматикой,
можно распознать недетерминированным конечным автоматом.
И обратно.
А любой контекстно свободный язык распознается автоматами с магазинной памятью.
Что такое магазин?
Не, не, не.
Да, да, да.
Да, да, да. Ну, там получается это.
Как вы можете себе представить?
Пока что мы не воем поделения, будем поделить это позже.
Представьте себе у вас автомат, которому сбоку стэк пределом.
Вот, и вы туда что-то можете пихать и выпихивать.
Дальше сложнее.
Контекст зависимой грамматики задают линейно-ограниченные,
недетерминированные машины тюринга.
То есть это машины тюринга, у которых вы в каждый момент времени
можете располагать только каким-то количеством символов
слева от ленты и справа от ленты.
То есть обычная лента тюринга, она бесконечна в обе стороны.
А здесь такая лента тюринга недоделанная, в которой слева и справа есть ограничения.
И вы не можете за них уходить.
Ну да, тут практически конечная.
То есть это абстракция, которая может есть.
То есть вы живете в каких-то рамках.
А?
А недетерминированная это история про то, что в каждый момент времени
вы по сути можете делать разный набор операций.
И потом, если у вас будет приходить какой-то ответ в результате,
то вы выбираете один из них.
Это также, я не знаю, рассказывал ли вам Тенил Владимирович, по-моему,
про класс NP.
Да, два.
Это в общем история N, это не нот-полиномиал,
а недетерминированно-полиномиальный алгоритм.
То есть это алгоритм, который можно распознать
на недетерминированной машине тюринга за полиномиальное время.
Недетерминированную машину тюринга вы там по сути можете
такое дерево ветвящееся сделать.
А что сделать, если я буду двигать либо коретку влево,
либо коретка вправо, либо еще что-то?
То есть такое поведение, недетерминированное.
Потому что вообще, по идее, если вы работаете с машиной тюринга,
она является детерминированной.
То есть у вас вы приходите в какое-то состояние,
вы сразу понимаете, что надо с ним делать.
Оттуда вы мешаете.
Ну и порождающая грамматики это сыр в барах лам,
поэтому он задается классической машиной тюринга.
То есть все, что вы можете задать машин тюринга,
что может задать порождающая грамматика.
Как вы думаете, какие из этих фактов эквивалентности
мы с вами будем показывать в ходе курса?
Ну первые две мы с вами будем показывать,
остальные две это вообще дичь сложная.
Поэтому их за троих не будем.
Вот. И сегодня как раз давайте сейчас сделаем небольшой перерыв.
И как раз после перерыва мы покажем,
почему класс правлений на грамматике эквивалентен
классу недетерминированных автоматов.
Давайте потихоньку продолжать.
Сегодня мы зададим вопрос,
как вы думаете, как вы думаете,
а сегодня наша конечная цель
доказать следующую теорию.
Что множество автоматик языков
совпадает с множеством языков,
задаваемых праволинейной грамматикой.
То есть для любого НКА
N
Сейчас.
Давайте вот так.
Значит, для любого языка L
существует НКА N
такой, что L равно L от M,
тогда и только тогда,
когда существует праволинейная грамматика G,
такая, что L равно L от G.
Вот такой факт мы сегодня с вами доказывать будем.
Итак, идея,
давайте сначала расскажу идею доказательства.
Мы будем доказать две стороны.
Первая, из грамматики будем показывать,
вот, для любой грамматики существует автомат.
А потом, для любого автомата существует грамматика.
Вот смотрите, грамматика, у нее интересные правила.
Вы можете заметить,
что у нас правила всегда
стоят таким образом,
что у нас сначала идет не терминал,
а потом идет только правила слова
и потом правила грамматики.
для всех таких правил
давайте я напишу идея сначала
что для всех правил из A следует WB
мы будем делать преобразование
автомат, который будет из A
по W переход в B
а для такого правила
у нас будет переход такой
из A по слову WB
мы перейдем в какую-нибудь вершину
которую мы назовем стоковой вершиной
потому что там на нем слово не заканчивается
ну немножко небольшая магия
с тем как эту всю конструкцию переставить
теперь давайте наверное формально начнем
записываю доказательства
давайте я тут на 3 части доску поделу
у нас ватерлиния
итак, доказательства
сначала хочу спросить, идея эта понятна?
в чем мы делали?
человек формально доказательств
из грамматики мусульмана
пусть у нас l равно lg
где этот набор n сильно появится
тогда построим граммат автомат m
в котором состояние будут?
какие?
какое множество?
не терминальные и объединить в ту вершину стоковую
которую мы с вами заводим
гаварит тут такой же
дельта штрих определим
стартовое состояние какое будет?
s
завершающее
может завершать состояние
сток
может и сток
где дельта штрих
равняется множеству тех правил
a, b
идет переход по b
при условии того, что у нас
с a, b ближе к грамматике
и объединить
с множеством
a, b
переходящих в сток
если у нас было правило без a, b
это формальное построение
что нам надо показать?
да, нам нужно показать, что
как мы это делаем?
давайте сначала из l от g
каким образом?
вспоминаем наши любимые слова
индукция, по какому параметру?
да, и нечего
нет
по количеству замен штопора
помните, мы опять штопор определили
по тлене вывода грамматики
я напишу количество штопора
и пусть будущее поколение разгадывает
смотрите, идея сразу
вот такие нам надо вещи показать
формально
если у нас есть вывод грамматики
вот такие два факта
скажите, почему l от g совпадающие с l от m обозначают эти два утверждения?
по факту нам нужно показать
язык задаваемый грамматикой лежит в языке задаваемым автоматом
и это то же самое, что будет
если у нас l от v принадлежит l от g
тогда из этого что следует?
что у нас с вами из s существует вывод слова дубль v в грамматике g
и тогда нам нужно с вами некоторые выводы пропустить
и получить из этого, что s, ε выводят в автомате m конфигурацию столка ε
и из этого будет следовать, что слово лежит в языке задаваемой грамматикой
понимаете откуда это будет следовать?
то есть нам нужно вот эту цепочку рассуждения установить
и нас требует показать факт
можно сказать вот тот факт, который есть
но дополнительно нам надо будет с вами показать верхний факт
давайте его покажем
покажем, что если из c у нас идет вывод какой-то дубль v
то это в грамматике g
то из конфигурации c
что у нас получается?
c w будет выходить в грамматике m d ε
и вот это мы тоже можем показывать индукции по длине вывода
согласны?
давайте вот тут я поставлю заказ шагов
и тогда у нас индукция покажется
база к чему равняется?
а?
нет, за 0 сложно
не, не, не
а, да, слушайте, да, реально
давайте k равно 0 и k равно 1 тогда
значит k равно 0, тогда что у нас получается?
из c за 0 шагов мы можем вывести c
только
а из этого что следует?
из этого следует, что чему наше слово w равняется
в данном контексте?
то что ему слово
и из этого получается как раз по определению
что мы из состояния c никуда с вами не переходим
ничего не считываем
так, наверное, тут даже переход нам
даже базы для карамонной единицы проверять не надо будет
давайте сразу тогда перейдем к переходу
итак, переход
у нас с вами из c
выводится слово w в д
заказ шагов
тут мы иногда пишем символ кар
это вопрос, как мы это могли получить?
этот переход заказ шагов
да, смотрите, тогда у нас
существует такое е, у и в
что?
из c мы за k-1 шаг
вывели слово
у
е
если стоит неусловно единица
а дальше за один шаг мы с вами приводили это в и в в
господи, какие у нас сегодня абстракции
скажите, чему равняется w?
тогда, по предположению, что мы с вами должны показать?
что мы знаем с вами?
это что у нас?
почему у нас эквалентность?
а?
да
а здесь у нас получается есть правило из е в д
следовательно, из е в д мы можем вывести с вами
д
и тогда у нас получается как раз тот переход, который мы хотели с вами
по транзитивности
из с у в, который равняется w
мы выводим с вами е
е только д
так, честно?
вроде честно получилось
мы считывали, что у нас есть право из е
ну да
сейчас
мы же это умеем делать
давайте когда это
возьмем еще один шаг
значит с у получается вот так
д е в
и вот тут получается д е в
вот так это умеем делать
по свойственной конфигурации
так, теперь дальше
то есть вот этот факт мы с вами доказали
так, теперь давайте покажем факт
что если у нас из с выводится какое-то слово w, то здесь мы приходим в сток
так, где писать?
слева можно писать?
будем слева писать?
нормально
так, вопрос
если у нас из с выводится слово w
то из с, значит, аж слово w
мы переходим всегда
100 тепсов
так, без этого
это почему?
вопрос, у нас есть переход из стока куда-нибудь?
в нашу конструкцию автомата?
нет, да?
значит, смотрите
тогда что получается?
так как
так как в сток нет перехода
то существует такая решенная емм
что
мы из с w
переходим к е
какое-то слово w
и делаем это за камеру с одним переход
а здесь мы это делаем за один переход
потому что мы попадаем
это вот как раз путь, который у нас с вами работает в стоковой решении
ой, типа, а что я решу?
нет, так нельзя
так лопаться я не смогу
извиняйте
значит, из с мы за камеру с одним переходим
переходим к какую-то решению у е
а из е мы читаем за один переход у в
вот так
и сначала у нас е
е
вот так
тогда что у нас получается?
тогда
первое
из с
в
тогда мы можем перейти
по тому факту, который у нас был уже
в
е, в
а из этой штуки
мы можем перейти уже в сток
е
по определению
по определению правил
по тому правилу, который у нас был
давайте мы его подначим 2
вытянем
вытянем
понятно?
ну то есть чисто
чисто математически формальная манипуляция
ну тогда у нас получается как раз
давайте
вот сразу что
поставим
а вот этот факт у нас
будет
что нам нужно поставить
тогда
чтобы получить требуемое состояние
вместо с что нам нужно поставить
чтобы мы получили с вами
тот факт
который мы хотим с вами показать
вот этот вот
да
из этого мы получаем что
из этой штуки
будет наладиться
по-первых
у меня в этом означает
что
это в одну сторону
еще 3 стороны
ну давайте
может быть подускоримся
так, поэтому пойдемте переходом
так, что мы стерем
правила не стирать
а стоп
это что мы показали с вами
а мы уже все показали
да
а мы показали что lg лежит в lm
теперь нам нужно показать что lm лежит в lg
ну поехали
вот
опять же давайте исследовать
что значит что v лежит в lm
да
значит
получаем что
из s
из s
мы можем попасть
в строк прочта
оставив конфигурации epsilon
да
а
потому что я тупой
да, немного что
так
теперь что нам нужно показать
нам нужно на самом деле тот же факт показать
который мы с вами уже показывали
значит нам
покажем
что если
из c w
мы выводим
d epsilon
в автомате m
то
d выводится
vd
в грамматике g
это как мы показывали
индукция, почему
да
индукция по длине пути в автомате
давайте
вот тут справа на доске
как раз пытаемся это сделать
база индукции
по длине пути k
база чему равняется
ага
тогда что у нас получается с вами
за ноль переходов мы из c переходим в d
а слово w пишем на epsilon
ну из этого будет следовать что
c равно d
w равно epsilon
ну вот
из c мы можем вывести g
в грамматике g
от слова c
ничего сложного
ну вот
пусть у нас
с вами был переход
за k раз
и для меньше всех верно
тогда у нас получается
что существует e
и u
опять же
такие что
из c w
мы можем прочитать
с вами какой-то кусок
вот
оставить тут только дубль u
вот это за k есть один переход
а тут за один переход мы с вами
делаем переход в
d epsilon
тогда что мы с вами получаем
ага
да, давайте
обозначим w
равно w
тогда
что по предположению индукции
что мы получаем
ага
из c что
и правила w
а
из c что
и правила w
а
из
поскольку у нас
получается
из e по u переход в d есть
то мы получаем что
из e у нас есть переход в u d
из этого
по транзитивности мы с вами получаем
что из c мы можем вывести
в u d
которая у нас в d
вроде
чисто получилось
а
где
что
да ничего
я что-то не понимаю
у нас правила сейчас есть
у нас есть правило что если
у нас есть вот такой вот переход
но у нас правила грамматики
правила в автомате есть из e по u
переход в d
как это получается когда из e
у нас есть переход
в грамматики вот такой вот
так, ну хорошо
теперь нам нужно показать
следующий факт
давайте чуть попроще
значит
что такое
опять же
так как
в исток
и нет переходов
то
смотрите из w
в исток
это значит
что существует такое
e
что у нас
из s
есть какой-то переход
тут e у v надо опять же
у v
потом
у нас идет переход из e по v
и потом
за один переход
мы попадаем с вами в сток
да, то есть мы смотрим
первый переход который
попадает в сток
тогда какой вывод мы с вами
из этого можем сделать
получается
получаем что
из s в u
мы переходим в
e эпсон
и это значит
что из s мы можем вывести
у e
а из
вот этой истории
мы можем вывести с вами что
из e мы попадаем
в весток
в итоге у нас получается
что из s мы попадаем
в v
сток
равное думаю в
сток
ой сток, что-то я не то пишу
кто багу найдет
да, просто без стока
да, потому что
сток это у нас совершенно в автомате
здесь у нас ее нет
ну и все, это получается что
в этом автоматике же
так
так
по одну сторону понятен переход
из того что грамматика
из грамматики можно автомат получить
что, теперь надо обратную
сторону
длине пути между конфигурациями
длина
теперь обратно
значит
тут история такая
значит
смотрите
опять же по переходу в
автомате
который у нас есть
мы строим правила
в автомате, то есть идея
доказательства в другую сторону
заключается в том
что
смотрите
что мы делаем
возьмем автомат с этим завершающим состоянием
назовем его сток
а
при этом
заметим что
этот сток
да, если что
мы скажем
в чем
делаем так чтобы из этого стока
не было перекодов
и
и
и
и
и
и
и
и
можно так сделать
ну да
это если у вас были некоторые наборы завершающих состояния
что вы делаете
мы делаем вот такую
вот такую картину
Что мы делаем? Мы делаем вот такую картину, да, и по доказательству этого факта, как раз у нас не будет циклов на себя.
Ой, ну и теперь смотрите, что мы делаем. А тут интересная вещь.
Вот у нас был переход, автомат n, вот такой вот у сигма дельта у ноль, и тут у нас одна вершина, пусток.
Встроим по нему автомат, ой, грамматику g, которая состоит, что сюда вставляем?
Да, можно и со стоком, тут можно, а, не, да, тут кубе стока, да.
Дальше, алфавит такой же, правила сейчас определим, а здесь у нас стартовое состояние, стартовый терминал будет какой?
Так, ну, с русского на английский мы научились переводить, теперь в обратную сторону научимся переводить.
Если у нас тут был в завершающем состоянии множество из стока, да, а тут у нас было s, точнее вот у нас s, вот тут, вот здесь у нас s остался.
Двигайте, двигайте, автомат, вот он, s, вот видите, они совпадают, стартовые здесь и стартовое состояние здесь.
Значит, что нам нужно положить стартовым терминалом в автомате, ой, в грамматике?
Q0, вот, причем, смотрите, теперь мы с вами что можем сделать? Мы теперь с вами можем сделать ту же самую картинку, давайте правила обозначим, а правила ровно такие же.
Значит, у нас Q1 будет выводиться в Q2, если Q2 не равно кусток, а Q2 принадлежал от этого.
И объединить, из Q1 выводят в, если у нас есть переход вот такой, Q1 в.
Товарищи, кто понимает, почему нам этот, почему нам сейчас не надо тратить еще 20 минут для того, чтобы показывать, что язык, задаваемый вот этим вот автоматом, вот эта грамматика будет совпадать с языком, задаваемым этим исходным автоматом?
А? Где-где-где? Вот тут? А, кусток.
Вопрос, кто понимает, почему сейчас нам не надо повторять те же самые доказательства?
Да, просто те же самые буквки, просто мы переобозначим определение, немножко там логику с местами, следствие с выводом сделано. То есть, потому что там мы этот факт доказывали в обе стороны.
Да? Напишем вот так, сделаем find and replace и повторим предыдущий пункт.
Ровно то же самое, потому что мы с вами добились той конфигурации автомата, которую мы с вами хотели. Ага. Давайте мы просто не будем тратить на это время. Если захотите, мы это с вами сделаем.
То есть, смотрите, идея интуитивно простая. Да, то есть, если у нас справа нет правила, взводим это в сток, если нет, если есть справа, не терминал, но привезем в это новому состоянию.
Ага. Ну это да. Ну так, технические вещи. Наша цель еще к тому же научиться эти технические вещи формально показывать по ходу курса, но уже один из правил.
Вот. Теперь смотрите. Интересный пример. Дерево вывода КС грамматики. Давайте просмотрим пример. Вот такая грамматика. Из А выводится СА. Давайте где-нибудь напишем.
Из А выводится СА. Из А выводится Д. Из С выводится А. Это пример грамматики.
Нам нужно определиться, как выводится слово А, С, Д, А, С, Д, А. Я надеюсь, не опечатался тут. Смотрите, что мы можем сделать. Мы будем заменять с вами части.
Да, тут если что, штопоры везде стоят, но их с стрелочками можно видеть, потому что они не символы. Давайте поймем, что происходит между второй и третьей стрелкой. Ой, на второй стрелке.
Да, к С применяем правила. Потом что делаем? Потом к С последнее правило, убираем А. Потом? Да, СА.
Так, первое применяем Д. Потом? Ага. И потом? Ну все, забили слово. Смотрите, вот так это сложно представлять. Поэтому люди придумали вот такую картинку.
А? А? Да, после вывода только каждый терминал здесь отображается, куда мы выводим. И как слово тут собрать? Ну надо сделать этот, как он называется?
А, А, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а, а
А выходим наверх. Вот эта штука называется дерево вывода грамматики.
То есть формальное определение это последовательность. Вот такая вывода слов.
Неформально это дерево. И мы будем идею формулировать с помощью деревьев.
Вот. Да, да. Вот.
И смотрите история какая. Вообще, чтобы понимать, как делается дерево вывода,
раскрывать не терминалы сикость-накость это не очень хорошая идея.
Поэтому мы с вами будем фиксировать дерево вывода либо правосторонний, либо левосторонний.
И на каждом шаге мы заменяем либо самый правый не терминал, либо самый левый не терминал.
И фиксируем этот порядок.
То есть мысль, на самом деле, вот здесь вот построили левосторонний дерево вывода.
Потому что мы самый левый не терминал здесь раскрывали.
А?
Потому что операция выводимости ассоциативна и транзитивна.
Операция штопора, она ассоциативна и транзитивна. Поэтому мы можем менять порядок местами.
Скобок, в котором мы это все делаем.
Вот. И давайте вот last. Да, это last.
Значит, смотрите. История такая. Есть однозначные грамматики.
И они нас очень сильно будут интересовать по ходу курса.
Конечно, грамматика называется однозначная.
Если для любого слова есть ровно одно, либо левостороннее, либо правостороннее дерево вывода.
Ну, мы фиксируем, допустим, правостороннее дерево вывода.
То есть ровно одна последовательность, которым мы можем получить этот вывод.
А в следующий раз мы с вами посмотрим, почему у нас с вами
правильные скобочные последствия, которые мы с вами задали, они являются однозначной грамматикой.
Вот. Но бывают такие грамматики, языки, в которых невозможно задать однозначную грамматику.
И такие языки называются существенно неоднозначными.
Ага. Мы еще это поговорим.
Может быть, если у нас останется время, мы покажем, почему, докажем с вами,
почему вот такой вот существенно неоднозначный язык, его нельзя задать однозначной грамматикой.
То есть это A в N, B в N, C в K.
При этом либо первые, количество букв A с количеством букв B совпадает,
либо количество букв B с количеством букв C совпадает.
Вообщем, смотрите, сегодня мы начали с вами знакомиться с классами на грамматику.
Посмотрели, что такое иерархия Хомского.
Показали, что праволинейные грамматики аналогичны автоматам.
Ну и построили дерево вывода грамматики.
Ну и немножко познакомились с тем, как у нас появляется одно значение.
В следующий раз мы с вами будем упрощать грамматики,
потому что то, что мы сейчас написали, это дичь.
Кто-то говорил, что длину правой части можно сильно ограничить.
И посмотрим алгоритмы, связанные с этим.
Как проверять принадлежные слова KS-грамматики,
когда у нас грамматика будет в более простом виде.
Всё, извините, что задержал. Давайте вопросы задавать.
Спасибо.
