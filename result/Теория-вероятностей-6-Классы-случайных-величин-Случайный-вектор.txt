так ну что коллеги был звонок да начинаем значит в прошлый раз мы остановились на
конкретных типах случайных величин если меня не изменяет памяти мы рассмотрели
бернульскую случайную величину равномерную в общем случае на ab они на 0 1 как этот написал
и пуассонскую случайную величину с параметром лямбда правильно да
так было дело да ну давайте значит двинемся дальше следующая случайная величина из класса
дискретных это случайная величина имеющая геометрическое распределение это случайная
величина с одним параметром п и задается своими вероятностями вероятность того что
геометрическая случайная величина равна к есть к у в степени к на п к принимает значение 0 1 2 и
так далее п число от нуля до единицы ку традиционно единица минус п значит мысленный
эксперимент соответствующий данной случайной величине это количество неудачных испытаний до
первого успеха количество неудачных испытаний до первого успеха то есть если вы проводите
независимые испытания значит и как бы на каком-то шаге у вас появляется успех то вот количество
неудачных испытаний до этого первого успеха это случайная величина имеющая геометрическое
распределение значит наверное правильно теперь вести или может быть до этого надо было ввести
биномиальную случайную личину которая имеет два параметра n и p это тоже дискретная случайная
величина которая тоже задается своими распределением сочетание а значит того что она равна к это
вероятность равна сочетании из n пока п в степени к у в степени n минус к в данном
случае к принимает значение 0 1 так далее n то есть это дискретная случайная величина принимающая
конечное число значений значит это настолько важная величина что соответствующие мысленные
эксперименты имеет даже собственное название и называется схемой испытаний bernoulli или схемой
независимых испытаний bernoulli значит речь вот о чем у вас есть некий эксперимент в результате
которого ну некое событие либо произошло либо произошло не произошло если оно произошло мы
говорим об успехе не произошло о неудаче так вот bernoulli случайная величина это вероятность к
успехов в серии независимых испытаний серии n независимых испытаний то есть если вы n раз
проводите некий эксперимент примеру подбрасываете кубик и успехом считаете выпадение там шестерки
например да то вот количество шестерок выпавших при этих н испытаниях это как раз случайная
величина точнее говоря этот мысленный эксперимент описывает случайную величину
имеющую биномиальное распределение биномиальное распределение и еще раз повторюсь что в отличие
от остальных случайных величин у этого мысленного эксперимента есть собственное имя это прямо
называется так схема независимых испытаний bernoulli вот ну что еще мы на что еще можно обратить
внимание так если не очень строго можно сказать что биномиальная случайная величина это есть
сумма n штук сумма n штук bernoulli случайных величин с параметром p здесь индекс g поставлю
поскольку для bernoulli случайной величины экспериментом есть соответствием является
проведение эксперимента и фиксация наступила события а или не наступила то bernoulli случайная
величина это вот надо n штук сложить так без особой строгости значит дальше как к распределению
bernoulli примыкает биномиальное распределение но знаете почему она называется биномиальным понятно
да потому что ну точнее говоря не трудно так сказать убедиться вероятность обладает тем свойством что
сумма вероятности по всем возможным исходном равна единице так сумма всех вот этих вероятностей как
не трудно видеть это п плюс q степени n ну то есть единица вот ну и вот как к биномиальному
распределению ну так сказать из него следует или примыкает распределение точнее говоря к
распределению bernoulli примыкает биномиальное распределение со схемой независимых испытаний
bernoulli так геометрическому распределению в этом смысле примыкает так называемое отрицательно
биномиальное распределение которое тоже содержит два параметра n нет p и к задается тоже своими
вероятностями вероятность того что отрицательно биномально случайно влечена равна некому n равна
c из n плюс к минус 1 по к минус 1 значит q в степени q в степени n п в степени
n принимает значение 0 1 2 и так далее выглядит немного страшно но соответствующий этому
мысленный эксперимент состоит в проведении независимых испытаний до появления катова
успеха и вот количество неудачных опытов это есть случайно влечена имеющие биномиальное
распределение то есть для геометрической случайной величины вы проводите испытания
до появления первого успеха а для отрицательно биномиально случайной величины вы проводите
эксперимент до появления катова успеха и вот количество неудачных опытов это есть случайно
влечена имеющая соответствующий распределение события независимые в том смысле как мы говорили
о независимых событиях мы же понятие независимых событий вводили с вами или я не понял вопроса
а значит понял вопрос спасибо значит в данном случае мы говорим о независимости в совокупности
пока вот значит так это мы прошли с вами по дискретным распределениям давайте теперь перейдем к
непрерывном к второму классу распределений с которыми мы имеем место значит пока мы из
непрерывных распределений с вами познакомились только с равномерном на об следующей класс или
следующей случайно влечена имеющий непрерывных непрерывные в из определение это на самом деле
вам в общем за так уже знакомая это нормально распределенная случайно влечена который имеет
два параметра m и сигма квадрат. m называется пока не очень понятным словом
мат ожидания, а сигма квадрат называется дисперсией.
Значит, непрерывная случайная, ну вообще любая случайная величина может быть
задана своей функцией распределения и должна быть задана. В некотором смысле
это она и есть, функция распределения. Но для непрерывных случайных величин
она может быть задана своей функцией плотности вероятности. Вот я здесь и
записал то, на чем мы вчера, не вчера, на прошлой лекции остановились. Вот,
поэтому зададим нормально распределенную случайную величину ее функции плотности.
В качестве индекса обычно пишется сама величина. Функция имеет вид единица на
сигма корень из двух пи е в степени минус х минус м в квадрате делить на два
сигма квадрат. Два сигма квадрат. Ну, знакомая вам вещь, интеграл ошибок, ну и
наверное в разных еще и постасяк связывались. Я даже не буду сейчас говорить о
эксперименте, соответствующем этой случайной величиной, потому что мы этому
посвятим большое количество времени. Это очень важное распределение, потому что
она еще предельная. Напомню, что, как бы, если в двух словах пытаться сформулировать
про что теория вероятности, это про существование неких предельных мер,
концентрации объектов наших, теперь, теперь случайных величин, ну, вокруг
каких-то предельных мер. Вот нормальное распределение одна из них. Так,
следующая непрерывная случайная величина, которая тесно связана с нормальным
распределением, мы ее зададим чуть-чуть другим образом. Значит, пока мы все
случайные величины, ну, по сути, задавали их функциями распределения. А теперь мы
зададим случайную величину как функцию от случайной величины, как Борелевскую
функцию. Давайте введем такую случайную величину log n. Она имеет также два параметра
и определяется как е в степени n, m сигма квадрат. Log n, очевидно, случайная величина,
потому что экспонента Борелевская функция. Ну и, собственно, можно было бы на этом
остановиться, но уж давайте получим для нее какую-нибудь характеристику, например,
функцию распределения или, точнее говоря, получить мы сможем функцию плотности. Ну,
начнем с функции распределения. Функции распределения вот этой нашей случайной величины.
Сам задающий такой вопрос не знаю. Вот, действительно, я надо было бы назвать
какой-нибудь экспоненциальный, но вот называется лог нормальный. Значит, итак,
функция распределения по определению, это вероятность того, ну, вместо log n сразу
поставлю е в степени n, m сигма квадрат меньше х. Ну, здесь отмечу, что х у нас больше нуля,
имею как, ну, имеет смысл рассматривать. Вот, и давайте напишем тождественное равенство,
это вероятность того, что n, m сигма квадрат будет меньше логарифом х. Ну, вот это по
определению. Функция распределения случайной величины нормальной, взятая в точке логарифом х.
Ну, чтобы получить плотности, возьмем производную и получим. Функция плотности
лог нормальной случайной величины равна, ну, функции плотности нормальной случайной величины,
взятой в точке логарифом х, только еще производную от аргумента, от логарифма х. И поэтому получим
единица делить на х сигма корень из 2p е в степени минус логарифом х минус m в квадрате делить на 2
сигма квадрат. Еще раз повторю, х больше нуля. Вот, значит, вот еще одна непрерывная случайная
величина. Ну, на самом деле тоже довольно важная. Ну, еще как бы ее там определенные
свойства увидим и поймем. Итак, это пример случайной величины, который мы определили не
через введение ее в функции распределения, а как функцию от случайной величины, а потом же,
как следствие, получили ее функцию плотности. Значит, следующий целый класс непрерывных
случайных величин. Это так называемая гамма распределения имеет два параметра, лямда или
альфа и лямда. Альфа и лямда. Определена для альфа, лямда и х больше нуля. Задается своей
функцией плотности. Ну, я так не буду длинно писать, г напишу, альфа лямда от х равно лямда в степени
альфа делить на гамма от альфа, х в степени альфа минус 1, е в степени минус лямда х. Вот такое
гамма распределения. Да, это гамма функция, но она, собственно, потому так и называется. Вот,
значит, это функция плотности и давайте выделим два важных класса. Могу. Гамма от альфы это интеграл
от нуля до бесконечности, t в степени альфа минус 1, е в степени минус альфа dt. Значит,
свойства которыми мы чаще всего пользуемся. Гамма от альфа равно альфа минус 1 факториал,
когда целая. И еще такая полезная гамма от одной второй это корень из пи. Ну, или еще вот так
от можно записать. Альфа минус 1 на гамма от альфы минус 1, собственно. Так, значит, гамма,
случайная личина, имеющая гамма распределения выглядит вот так. И выделяем два как бы частных
случая, но настолько важных, что они имеют свои собственные имена. А именно гамма, когда альфа
равно единиц, а 1 лямда. Это у нас называется показательное распределение, которое имеет
функцию плотности лямда на е в степени минус лямда х. Лямда х больше нуля. Ну,
одно из немногих распределений, не то что немногих, но иногда не часто встречается,
можем выписать функцию распределения. Функция распределения этой случайной личины равна 1
минус лямда на е в степени минус лямда х. Ну, по-разному. Можно проинтегрировать,
можно вот это продиференцировать. Ну, и давайте чуть-чуть по это ассоциативное мышление включим.
Значит, вероятность того, что эксп, что показательная распределенная случайная личина с параметром
лямда будет больше некого t, равна чему? Ой, извините, ошибочка. Лямда не должно быть здесь,
поправьте, пожалуйста. Равно чему вот эта вероятность больше t? Ну, коллеги, вот это по
определению вероятность того, что она меньше х, а вот это больше t. Значит, это е в степени минус
лямда х, лямда t. Я специально тут t ввел, чтобы у вас возник какие-то ассоциации. Так,
что такое показательная случайная личина? Мы с вами уже с такими... Черт, не слышу еще раз.
Да, ну в смысле можно и так сказать, но если говорить в терминах того, что мы с вами изучали,
это вероятность того, что за время t в простейшем пуласоновском потоке не произойдет ни одного
события. Можно это интерпретировать как время свободного пробега? Действительно. Вот, значит,
это первый частный случай, и второй частный случай гамма распределения, который именной,
это когда α равно n пополам, а лямда равно 1 и 2. Вот это распределение называется х квадрат
с n степенями свободы. Х квадрат с n степенями свободы. Пожалуйста, это себе пометьте,
потому что с этим распределением вы столкнетесь с математической статистики. Пока интерпретации
не будут давать, но они у нас будут. Мы разберемся, что ж такое х квадрат с n степенями свободы.
Так, ну и еще продолжим с непрерывными распределениями. Вот тут себе позволю я стереть.
Так, никто меня не поправил. Минус чего? Минус t. Так, значит,
еще одна случайная величина, которую надо знать, и тоже широкий достаточно класс с точки
зрения приложений, это так называемое бета-распределение. Имеет два параметра,
альфа и бета. Альфа, бета больше нуля. Это вот это? Это бета. Вы это спрашивали?
Значит, бета-распределение, зададим его функции плотности, гамма от альфа плюс бета делить на гамма
от альфа умножить на гамма от бета. Х в степени альфа минус один, единица минус х в степени
бета минус один. Но х здесь от нуля до единицы. Ну, можно равно, наверное, оставить от нуля до единицы.
То есть, это случайная величина, определенная на 0.1. Что для нее как бы является мысленным
экспериментом? Где можно получить такую случайную величину? Ну, на самом деле,
это случайная величина, которая связана с так называемыми ранговыми статистиками. Но для
понимания давайте сделаем вот что. Возьмем отрезок 0.1 и на удачу бросим сюда альфа плюс бета
минус одну точку. Вот сюда на этот отрезок. Какое-то какое-то значение будет альф,
по величине назовут так. И оно даже имеет специальное обозначение. Там каты по величине,
это индекс в круглых скобочках. Обратите внимание, традиционно вы этим будете
пользоваться. Вот этот альф ты по величине наш случайный бросок, вот он как раз имеет
вот такое бета распределение. Вот так. И последнее из непрерывных, ну и, собственно,
последнее из тех, которые по курсу нам надо знать. Ну, давайте помещу здесь, на этой доске.
Что? Ну, тогда отрицательней будет. Вот это, да? Нет, это я сказал интерпретацию, когда альфа и
бета натуральные. Я сказал бросить альфа плюс бета минус одну точку. Моя интерпретация распределения
относится, когда альфа и бета натуральные. Ну, может, надо было там м и н взять, чтобы не путаться.
Вот, значит, ну, кстати, натолкнули меня на мысль, что вот так давайте уберем, если уж мы будем
рассматривать отрицательные степени. Вот, значит, ну и последнее распределение из непрерывных,
которым надо познакомиться, это распределение каши. Ну, его иногда по-французски каши, такое длинное
получается слово, мы просто к будем обозначать. Оно имеет тоже два параметра, а и сигма. Похоже,
как бы в этом смысле, на нормальное. И задается оно своей функцией плотности, это распределение.
Единицы делить на пи сигма. Единица плюс х минус а делить на сигма в квадрате. И вот это,
собственно, знаменатель. Распределение каши. У него есть свойства, ради которого всегда
поминают. Мы еще пока не знаем, что такое мотожидание, но у этого распределения нет
мотожидания. Это мы на следующей лекции подготовимся. А с точки зрения эксперимента две... А,
еще вот здесь пометьте, пожалуйста. Для нормального распределения отдельно выделяют вот такое
распределение с нулевым от ожиданиям единичной дисперсии, и его называют стандартным нормальным
распределением. Это тоже термин. Стандартное нормальное распределение. Ну вот, отношение
двух стандартных нормальных случайных величин имеет стандартное распределение каши, когда
sigma равно единице, а равно нулю. В отличие от нормального распределения, где вот
это m называется мат-ожиданием, а на мат-ожиданием не называется, потому что его
нет, называется параметром сдвига, а sigma называется
параметром масштаба. Но вот чуть-чуть забегая вперед, просто по терминам, здесь
у нас мат-ожидание и дисперсия мы это назвали, потому что это две вполне
конкретных величины, которые мы определим на следующей лекции, а у распределения
коши не отнимат ожидания, не дисперсии, но два параметра есть, поэтому называются
они по-другому. Параметры сдвига и параметры масштаба.
Так, ну вот на этом мы знакомство с распределениями стандартными, которые вам
нужно знать. Заканчиваем и давайте двинемся дальше.
Собственно, что нам еще нужно сделать, чтобы уж двинуться в другую тему
несколько. Значит, мы с вами в прошлый раз установили, ну не мы установили, скорее
Лебек установил, что функция распределения разлагается на две
составляющих. Это дискретная функция, которую мы определили, дискретная
составляющая, непрерывная составляющая и теоретически есть сингулярная
составляющая, мы ей пренебрегли, так считаем, что ее нет, поэтому непрерывная
составляющая это абсолютно непрерывная, то есть существует вот такая функция,
ядро, так сказать, интегральное, которое носит специальное название, функция плотности
вероятности или функция плотности, надо сокращать. Вот, ну теперь надо понять, как
же замешать непрерывное дискретное распределение, ну так сказать, с
практической точки зрения. Мы к этому вопросу подойдем в таком общий
подход, просто рассмотрим понятие смеси, понятие смеси. Давайте введем вот такую
функцию, мы ее авансом буквы f большое обозначим, вот тут я поставлю мне такой
индекс mix, напишу, которая представляет из себя следующая сумма
p житая f житая от x, g от единицы до некого k, где сумма всех p житых от единицы до
k равна единице, все p житые больше нуля, ну равно нулю не берем, потому что просто
нет соответствующего слаганного, а f ж от x это на самом деле функция распределения
некой случайной величины, просто чтобы трехэтажный индекс не таскать, то есть
есть у нас случайные величины, x1, xk, вот так обозначимая функцию распределения.
Вот смотрите, ввожу вот такую функцию, ну некую линейную комбинацию функций
распределения, только не вообще на линейном пространстве, а вот на таких
коэффициентах, там такой положительный типа симплекс получается.
Что я про эту функцию хочу сказать, эта функция удовлетворяет всем четырем
свойствам, которые мы для функции распределения называли, это она от нуля
до единицы, в плюс бесконечности она равна единице, в минус бесконечности она
равна нулю и она непрерывно слева. Пока никаких ограничений на вот эти
функции нет, это могут быть и непрерывные, дискретные, там часть непрерывных, часть
дискретных, все дискретные как бы не имеют значения. Вот, так значит эта
функция fmix удовлетворяет всем свойствам функции распределения,
случайной величины. Я вам в свое время говорил, что эти свойства
характеристические, то есть если у меня задана функция с этими
свойствами, то я вообще говоря могу построить вероятностное пространство
отображения такое, чтобы получалась случайная величина с наперед заданной
функцией. Ну давайте мы вот в этом случае, ну можно сказать это и проделаем, а именно
опишем мысленный эксперимент, который приводит к вот такой функции распределения.
Для этого давайте представим, что у нас есть, ну некая случайная величина,
дискретная, которая принимает конечное число значений, ну определимую там какая-нибудь
это равная g равно pg, ка значение она принимает, там кубик, например, монета, все что угодно.
Это те же самые pg? Ну пока это не важно. Ну там индекс, можно поставить и другой
индекс, но давайте считать, что намекаю, что это они и есть. Значит, рассмотрим вот
такую случайную величину и представим такой мысленный эксперимент. Сначала в
результате некоего эксперимента я получаю значение вот этой случайной величины,
например, подбрасываю кубик и получаю 1, 2, 3, 4, 5, 6, а потом взяв этот номер уже,
число, беру x, сжитую случайную величину и вот с такой функцией распределения и
получаю результат случайного эксперимента. Ну, например, там фантазирую, как бы,
к реальной жизни особо значение не имеет. Давайте я поступлю так, я бросаю кубик,
если у меня на кубике выпало k, то я бросаю точку на удачу, на отрезок от k до k плюс 1, к примеру.
То есть непрерывные величины это равномерные, их распределение зависит от k, k я получаю в
результате, так сказать, случайного эксперимента. Так вот, в результате случайного эксперимента,
ну, я там, как бы, получаю некую случайную величину. Ну и давайте посмотрим, какое она
имеет распределение. Давайте я рассмотрю событие, что вот это ксимикс, я ее так назову, меньше
некоторого х. Что это за событие? Оно представляется в виде объединения неприсекающихся событий в результате
первого эксперимента единица и х из распределения и кси из распределения номер один. В результате
случайного эксперимента двойка и х, ну вот и так далее. Конечное число мы рассматриваем вот этих
слагаемых, и поэтому эта вероятность есть сумма вероятностей того, что это равно g, то есть как раз
по g, на вероятность того, что случайная величина с номером g окажется меньше х, а это функция
распределения fg от х. Вот, то есть таким образом построенная смесь действительно имеет вот такое
заданное нами распределение. Ну, собственно, мы закрыли класс тех распределений, которые мы
рассматриваем. Мы рассматриваем чисто непрерывные распределения, чисто дискретные распределения и
вот все, что мы в нашем курсе, с чем в нашем курсе будем иметь дело. Так, все по этому вопросу. И
давайте перейдем к следующей теме. Начну я вот здесь. Следующий объект, который мы с вами рассмотрим,
это случайный вектор, случайный вектор. Давайте рассмотрим отображение из омега в некое rk,
камерное пространство. Значит, если k равно единицы, то это у нас случайная величина,
а если k не равно единицы, а больше, то это у нас случайный вектор. Значит, когда мы определяли
случайную величину, мы наложили некоторые требования на вот это вот отображение, на свойство
отображения, а именно измеримость. Здесь мы поступим попроще. Мы напишем, что случайный
вектор x от омега это просто k штук случайных величин, определенных, естественно, на одном
вероятном пространстве, которое, ну, всегда предполагается, не говорю об этом, всегда предполагается.
Просто берем k штук случайных величин, как говорится, в описываемых столбиках,
вот этот объект получился случайный вектор. Это действительно отображение из омега в rk. С
какими свойствами? Ну, вот с таким свойством, которого нам будет достаточно. Омега такие,
что x от омега меньше x, и это для всех компонент. Вот это множество, очевидно,
принадлежит f измеримо. Понятно, да, почему? Вот это каждое измеримо, потому что мы договорили,
что это случайная величина x, ну и пресечение конечного числа измеримых множеств.
Это элементарный исход в исходном вероятном пространстве. А это стандартное распределение,
в смысле стандартное обозначение. Вы первый раз пришли или как?
На семинарах? Между семинарами и лекциями вы хотите сказать, или что?
Не, меня просто смущает, что вы там на шестой лекции не знаете, что такое омега.
Ну, исход формально тоже событие. Ладно, значит,
двинемся дальше. Имеет место вот такое свойство, то есть измеримость в таком смысле. Ну,
и поэтому нам ничего не мешает по аналогии определить функцию распределения случайного вектора.
Это такая функция от k переменных, от размерности вектора. Ну, давайте вот это как-нибудь обозначим bx.
Это собственно вероятность bx вот этого. x вектора, правда, здесь.
Ну, в значительной степени по аналогии вводим в функцию распределения случайного вектора.
Какие свойства есть у этой функции? Ну, первые четыре свойства аналогичны.
Функции распределения случайно влечены, там часть из них тривиальна. Я, ну, когда буду,
когда не буду, писать здесь ксид, ну, поскольку имеем в виду, что с одной случайной влечены
работаем. Значит, функция распределения от этого вектора x меньше равна единице,
больше равна в нуля. Это звонок, да? Ну, давайте отдыхайте и продолжим.
Коллеги, давайте я свойства функции распределения случайного вектора вот на этой доске выпишу,
чтобы они у нас были немножко перед глазами. Значит, второе свойство тоже совершенно аналогичное,
просто по-компонентное. Для любого g функция распределения x1 xg' xk меньше или равно f x1 xg 2' xk
для любого xg' меньше xg 2'. Свойства по-компонентной монотонности аналогичны,
свойства функции распределения случайно влечены и, собственно, доказывается аналогично,
просто индексов побольше. Третье свойство немножко отличается, но, по сути дела, логика та же.
Придел, для любого g, предел, когда x, сжитая от n, стремится к минус бесконечности, убывая,
этот предел равен нулю, а вот второй, как бы аналогичный, предел, который равен единице,
немножко отличается. Здесь уже все x, сжитые от n, должны стремиться к плюс бесконечности.
Вот этот предел равен единице. Отличия просто из-за размерности возникают, а так, по сути дела,
то же самое свойство. Четвертое свойство тоже аналогичное, это по-компонентной непрерывности
слева для любого g. Можно я не буду так подробно расписывать, напишу f x1, так далее, x g минус 0 x kt равно
f x1 x g x kt. По-компонентной непрерывности слева аналогично, но у функций распределения
случайные векторы выделяют еще одно свойство. Пятое, которое выглядит так. Для любого g предел,
когда x, сжитые от n, возрастая, сходится к плюс бесконечности. То есть, когда какая-нибудь
компонента стремится к бесконечности, x1 x g минус 1 x g от n x g плюс 1, так далее, x kt равно,
равно f x1, так далее, x g минус 1 x g плюс 1, так далее, x kt. Вот такое вот свойство. Все понятно?
Ждал то вопроса. Хороший вопрос.
Значит, вообще говоря, что здесь написано? Написано, что если мы ограниченные функции с n
переменными одну компоненту стремим к 0, получим функцию с n минус 1 переменной. Ну как бы и чего?
Стоило ли это того, чтобы это выписывать? Тут вот какая вещь. Это не просто какая-то функция с n
минус 1 переменной или k минус 1 переменной. Это функция распределения случайного вектора,
который состоит, ну как бы выглядит как этот, но у которого выброшена житая компонента. И именно
поэтому это свойство называется свойством согласованности. Свойством согласованности
распределений. То есть это не тривиальный с точки зрения мотонализа факт, а это, ну, факт как бы
содержательный. То есть если вы какую-то компоненту функции распределения устремите к бесконечности,
то вы получите функцию распределения. Не чего-то, не какую-то функцию с k минус 1 переменной, а функцию
распределения вектора, который составлен из тех же случайных величин, но нету ксиджитого. Вот поэтому
я вот здесь давайте, чтобы это отметить, здесь напишу кси, а здесь напишу кси, давайте с волной
поставлю, чтобы было понятно, что это нечто другое. Конечно, получите единицу из права и слева.
Вы задаете какие-то вопросы такие. Вообще-то говоря, у нас есть такая случайная величина вырожденная,
которая равна константе с вероятностью единица. Не смущает вас-то? У вас пробел какой-то?
Вот, ну давайте, но мысль правильная, мысль хорошая. Действительно, устремив группу
компонент к бесконечности, чуть-чуть забегая вперед, мы получим функцию распределения любого
подножства компонент. Мы этим сегодня воспользуемся. Так, ну давайте пятое свойство
покажем, хотя, как бы так сказать, ничего в нем такого-то нету. Значит,
функция распределения x1 x g-1, а давайте докажем для g равного k, просто чтобы, ну,
сложных сумм не строить, g равно k. Понятно, что доказательство от этого не изменится. x1 xk от n,
это вероятность того, что xi gt меньше xg, когда g принимает значение от единицы до k-1,
и xi kt меньше xk от n. По и икс каты у нас возрастая стремится к плюс бесконечности. По индексу n вот
эти множества монотонно расширяющиеся, да, вот эти множества. Поэтому мы можем, если мы возьмем
предел, перейдем к пределу, то вот так напишу стремиться, чтобы много не переписывать.
Придел вот этой вероятности под знаком предела стоят расширяющееся множество. Значит, это будет
чего? Это будет вероятность, здесь, грубо говоря, общий множитель, а здесь будет объединение
xk меньше xk от n, объединение по n. Вот так вот, да. Ну, если уж так как-то уж красивее писать. Вот так
пересечение. Вот так вот, да. Вот это что за множество? Мы перешли к пределу, предел вероятности по теореме
непрерывности вероятности, если здесь стоят расширяющиеся множества, это вероятность счетного
объединения этих множеств. Припоминаете, да? Одна, ну, там одна из форм теоремы непрерывности
вероятности. Вот это что за множество в исходном вероятности пространстве? Пусть.
Это Омега. Потому что, какой бы вы ни взяли Омега, поскольку xn стремится к бесконечности, а xk от
Омега это всегда число, хоть и сколько угодно большое, то найдутся такие индексы, что xk станет
меньше, найдется такой n, что xk станет меньше xk от n для любого Омега. Поэтому вот это на самом
деле Омега. Ну а что угодно с Омега пересекай, это оно и получается. А вот это, собственно, и есть
функция распределения, так его ксис волной обозначили, да, от x1, так далее, xk-1. Вот такое
вот свойство. Значит, итак, функция распределения случайного вектора, мы выделяем пять свойств,
не четыре, как было функция распределения случайно-чинной, а пять. Но даже эти пять
свойств не делают их характеристическими. То есть функция, удовлетворяющая вот этим
свойствам, может не быть функцией распределения случайного вектора. В отличие от случайной
величины, для которой функция вот с этими четырьмя свойствами является функцией распределения
какой-то случайной величины, которую мы даже можем конструктивно построить. Вот, значит, для того,
чтобы это подтвердить свое утверждение, я могу или должен привести пример, я его приведу чуть
попозже. Мы не ищем легких путей, мы сначала получим такую сложную формулу, не сложную,
такую громоздкую, а потом уже, так сказать, вернемся к этому вопросу. Так, с вашего позволения, вот отстираю.
Сейчас мы докажем формулу, которую тоже иногда называют формулой включений-исключений для
случайных векторов. Докажем ее сначала в несколько диковинном виде. Значит, есть у нас
ка штук случайных величин или н штук, ксиджитое меньше некого бжитого больше или равно ажитое,
пересекаем это по g от единицы до n, здесь букву используем, k на другое используем, то есть это
многомерный такой параллепипед, да, в инмерном пространстве. Вот, и еще здесь это пересечем с
некоторым множеством d, с множеством d, который принадлежит исходной сигма-алгебре, тогда для того,
чтобы не было путаницы, давайте здесь добавим омега, как бы поработаем чуть-чуть в исходном
вероятном пространстве. То есть вот это множество, это параллепипед в пространстве случайных
величин, но какое-то там другое сложное множество в исходном вероятном пространстве, и мы его пересекаем
с произвольным множеством, но единственные сигма-алгебры. Так вот, я утверждаю, что эта вероятность равна вот такой
штуке, минус 1 в степени сумма k житых, k житые это такие штуки k1, k, n, они просто наборы из нулей единиц.
Сумма, вероятность объединения событий кси житые меньше х житые в степени k житые,
ну немножко некрасиво, извините, пересечение с д, и х житые в степени k житые, это некий специальный индекс,
я просто напишу, что он равен, как он определяется, х житые в степени 0, он в двух степенях, 0 и 1
может быть, это просто b житые, а и житые в степени 1 это а житые, просто вот ввели такие обозначения,
не более того, на самом деле здесь стоят всевозможные события типа кси меньше а или кси меньше б, вот,
и сумма по всем вот таким вот наборам из нулей единиц, формула понятна сама, да, вот, ну давайте ее
докажем, перво-наперво давайте ее для случая, доказывать будем по индукции, поэтому начнем
со случая n равно 1, здесь выпишу такое тривиальное утверждение, если a влечет b, мы даже пару раз
сегодня, может быть, попользуемся, то pb минус pa равно pb не а, вот так вот, ну и давайте, значит, рассматриваем
случай n равно 1, что этой формуле будет, ну раз единица, значит k житые, ну только 1 индекс, k1 будет,
у нас будет вероятность того, что кси 1 меньше b 1 пересечение с d, это когда k1 равно 0, минус вероятность
того, что кси 1 меньше a 1 пересечение с d, ну вот так это, давайте события поставим, события, ну, собственно,
для чего формула писал, вот это b, вот это a, ну, когда я так пишу, конечно, предполагаю, что a меньше b, да, вот,
значит, это b, это a, пользуемся вон той немудрённой формулой и получаем, что это равно вероятности того, что кси 1 меньше b,
больше b 1, больше или равно a 1 пересечение с d, правильно? Ну, а это вот оно и есть, то есть, для случая n равно 1,
ну, предполагаем, что верна для n минус 1 и доказываем для n.
Ведём обозначение, b n равно пересечение a g t меньше или равно кси 1,
c g t меньше b g t, пересечение по g от 1 до n. Ну, и, собственно, нам нужно получить выражение для b n d,
перепишем его в вероятность, значит, a n меньше или равно кси n меньше b n,
на b n минус 1 d. Ну, вот это некая новая d, поэтому можно воспользоваться вот уже полученным результатом и написать, что это равно
вероятности того, что кси n меньше b n и одновременно с этим b n минус 1 d,
минус вероятность того, что кси 1 меньше a 1 пересечение b n минус 1 d равно.
Ну, перепишу, хотя просто для визуализации так-то всё очевидно, b n минус 1 пересечение кси n меньше b n d
минус b n минус 1 пересечение кси n меньше a n
d.
Так, чего бы стереть-то? Ну, вот с вашего позволения вот это тогда сотру.
Так, равно. По предположению индукции для b n у нас формула есть, поэтому мы пишем сумма минус 1,
сумма к житые, k 1, так далее, k n минус 1 принадлежит 0,1, то есть на наборе индексов n минус 1,
на вероятность того, что кси n, на вероятность того, что кси житая меньше х житая в степени k житая,
g от 1 до n минус 1 на как бы новое d, которое у нас теперь кси n меньше b n, d минус,
минус сумма минус 1, сумма к житая, k 1, k n минус 1. На этих наборах рассматриваем на вероятность того, что кси житая меньше х житая в степени k житая,
g от 1 до n минус 1 и, собственно, то же самое, кси n меньше, а n на d.
Так, ну, лень, времени нет по 10 раз переписывать, надеюсь, что вы меня поймете. Смотрите, вот это b n, это на самом деле x n в степени 0,
а вот это x n в степени 1. Если я здесь подставлю x n в степени 0, ничего не изменится, а если я сюда подставлю x n в степени 1,
то надо поменять знак, потому что вот эта единица здесь его поменяет, как только я а n заменю на x n в степени 1.
Поэтому этот искомый результат просто представлен разбитым на две суммы, когда х житая равно 0 и когда k житая равно 0 и k житая равно 1.
Ну, понятно так более-менее. Ну вот, значит, это, собственно, и завершает доказательство.
Тут надо сказать, что формула весьма диковинная и на самом деле редко, когда нужна, но мы ее доказали именно в таком виде,
потому что доказательство получается простое. А на самом-то деле нас будет интересовать, по сути, единственный частный случай,
когда d здесь на равно ω, тогда вот это сотру, подставьте d равно ω, тогда мы получим вот такую формулу.
Вероятность теперь уже будет чисто параллепипид.
Так, пониже чуть-чуть. Сумма по k 1 к n из 0,1 минус единица сумма k житых ж равно от 1 до n, функция распределения в точке x 1 к 1, так далее, x n к n.
Если вот это d равно ω, то это на самом деле просто функция распределения. Вот получили вот такую формулу.
Чаще всего в таком виде она встречается, ну, с точностью до там индексов или обозначений.
И, собственно, она, ну, такой некий аналог формулы включений-исключений для функции распределения.
Я встречал такое название, ну, не знаю, насколько оно, так сказать, там удачное.
Ну, можно никак не называть. В принципе, так сказать, хоть как назовите, хоть горшком назовите, не ставьте в печь.
Так что вот такую формулу получили. Давайте мы чуть-чуть ее один раз используем, просто понять, как она устроена,
для того чтобы показать, что свойства 1 к 5 не являются характеристическими.
Вот это стираю.
Давайте рассмотрим вот такой двумерный вектор.
Давайте рассмотрим вот такой двумерный вектор, ну, точнее говоря, двумерную функцию распределения для двумерного вектора.
Давайте рассмотрим вот такой двумерный вектор, ну, точнее говоря, двумерную функцию распределения для двумерного вектора.
Давайте рассмотрим вот такой двумерный вектор, ну, точнее говоря, двумерную функцию распределения для двумерного вектора,
1, 1, вот здесь она равна 1, а здесь равна 0.
Ну, если вы как бы, ну, и непрерывно там слева или снизу, как бы по второй, по первой компоненте.
Вот, ну, если вы так посмотрите, вы увидите, что она вот этим свойствам 1,5 удовлетворяет.
И давайте найдем вероятность попадания случайной величины вот в такой квадратик.
Сторона 1,3 до 1.
Ну, святое дело воспользуется нашей формулой.
Получим искомую вероятность, не буду как бы писать, то есть вероятность попадания вот в этот квадрат.
Давайте по формуле смотреть, что сюда войдет.
Значит, сюда войдет f в точке 1,1, оба правых конца, значит, с плюсом.
Ну, посмотрите, просто мы это в том числе делаем для того, чтобы понять, как эта формула устроена.
А вот я вот ее нарисовал со стороной 1,3 и 1 по обеим осям.
Ну, вот посмотрите, вот эта формула, вот ее применил для конкретной ситуации.
Ну и смотрим теперь на вот эту как бы функцию распределения.
Вот эта единица, вот эта единица, вот эта единица, вот эта ноль.
Получается равно минус один.
Вероятность у нас отрицательной быть не может.
Отсюда вывод.
Данная функция, несмотря на то, что она удовлетворяет написанным свойством вот здесь,
функция распределения не является.
Просто, так сказать, отложите у себя в памяти этот факт.
Для случайной величины четыре свойства характеристические.
Для случайного вектора мы их выписываем, но характеристическими они не являются.
Так, ну теперь мы должны с вами сделать весьма важный шаг
и ввести понятие независимых случайных величин.
У нас были независимые события, и там у нас вот были попарно независимые, в совокупности независимые.
Вот.
Мы должны нечто аналогичное сделать и для случайных величин.
Сначала определение.
Кси-один, кси-ен.
Случайные величины, кси-один, случайные величины.
Кси-один, кси-ен называются независимыми.
Никаких других слов.
Просто независимыми.
Если вероятность того, что ксиджитэ принадлежит некому множеству изборелевской алгебры,
а так до n, равно произведению вероятностей.
Понятное определение, да?
Бежит элементы алгебры.
А скажите, пожалуйста, что я взял алгебру, а не симма-алгебру?
Другие мысли?
Конечное число включает величины.
Вы меня извините, я немножко глуховат.
Говорите погромче.
Конечное число включает величины.
И что?
Мы же для конечного числа событий вводили независимость совокупности.
Точнее говоря, вводили понятие независимости.
Смотрите, я припоминаю, видимо, вы уже забыли.
Мы с вами доказывали такой красивый очень результат, что свойство независимости
можно продлить по непрерывности с алгебры на симма-алгебру.
То есть если вы имеете независимые алгебры, а это не что иное, как определение независимых алгебр,
то вы можете то же самое утверждать и про элементы симма-алгебры.
Вспоминаете?
Поэтому вот это назовем формулировкой 1.
Аналогичная ей формулировка Bgt принадлежит симма-минимальная от Барелийской алгебры,
собственно, как мы определяли Барелийскую симма-алгебру.
То есть и то, и другое определение эквивалентное.
Но мы взяли алгебру.
Но на самом деле я сразу скажу, мы в этом убедимся, что на самом деле Bgt может иметь вид,
некая Agt, Bgt полуинтервал.
Можно даже так взять.
Это чуть-чуть забегая вперед.
Но просто я хочу сказать, что любое из этих определений независимости эквивалентно.
Можно определить на таких полуинтервалах, можно определить на элементах алгебры,
можно определить на элементах симма-алгебры.
Это эквивалентные определения.
Теперь давайте попробуем с этим поразбираться.
Да что ж такое?
Это элемент алгебры.
Именно ксижитое там просто подкопает?
Ксижитое, ксижитое.
Там подкопает?
А, принадлежит, принадлежит.
Просто вы проходите то, что мы давно уже прошли.
В том смысле, что я коллегам сказал, что я эти значки путаю,
поскольку считаю их там по сути эквивалентными.
Из содержания обсуждения понятно, что имеется в виду.
Вот, ну пусть будет, ну так да, так правильно.
Вот, ну давайте тогда уж и здесь тогда.
Вот, значит, что первое, давайте на что первое обратим внимание.
Ну возьмем, например, определение номер один.
И в качестве бжитого, там же мы любые можем брать,
возьмем элемент минус бесконечность, там x житая.
Тогда во что превратится это определение?
Функция распределения x1, xn, мы взяли индекс,
равно произведению f, ну тут может обозначить, давайте,
здесь вектор, а здесь компонента, x житая от x житого.
То есть, если случайные величины независимы вот в этом смысле,
то тогда их функция произведения разлагается вот в произведение,
то их функция распределения разлагается в произведение,
в функции распределения компонента.
Вот такое свойство, из независимости следует.
Сейчас мы с вами покажем, поймем, мы, собственно,
уже там все результаты практически получили для этого,
просто надо в кучку их собрать.
Сейчас мы поймем, что верно и обратно.
Если функция распределения представима вот в таком виде,
то случайные величины независимы в этом смысле.
Вот, значит, и когда мы это сделаем,
ну, точнее говоря, чуть забегая вперед, мы это сделаем,
скажу сразу, что вот то свойство, на которое я обращал внимание,
когда речь шла о независимости алгебр, а не случайных величин,
здесь у нас отпадает необходимость вводить понятие типа независимости в совокупности,
потому что устремив их житое плюс бесконечности нужные нам компоненты,
мы получим, так его называют иногда, маргинальным распределением,
предельным распределением некой группы, для которой будет верно вот это же свойство.
То есть из вот этого свойства следует аналогичное свойство
для любой подгруппы компонент вектора.
Поэтому, просто повторюсь, я уже об этом говорил,
утверждение о независимости случайных величин в совокупности нам просто не нужно,
оно следует изходного.
Так, значит, прям мало времени.
Значит, давайте сначала рассмотрим ситуацию, когда мы имеем дело с вероятностью параллепипеда.
По нашей формуле включение-исключение, это вот такая штука,
где определили, знаем, что это такое.
Вот смотрите, если верно вот такое свойство,
то тогда это есть произведение f из житых степени К житых g от единицы до n.
Вот так. И я сейчас напишу, и надеюсь, вы меня поймете,
ну точнее говоря, увидите.
Это на самом деле f b gt минус f a gt g от единицы до n.
Смотрите, вот из чего состоят вот эти наборы.
Это f от a и f от b, всевозможные комбинации,
и знак минус возникает тогда, когда взято нечетное число f от a.
Ну и посмотрите это тоже самое.
Когда вы начнете скобки раскрывать, будут абсолютно всевозможные наборы,
и отрицательный знак будут иметь те, где f от a вы возьмете в нечетном числе, когда будете раскрывать.
То есть это вот так сворачивается.
А вот это мы знаем, что такое с вами.
Мы такое свойство с вами выводили,
ну обращали на него внимание, выводили сильно сказано.
Это на самом деле вероятность того, что x gt меньше b gt больше равно a gt.
Согласны?
И мы с вами доказали, что если в качестве множества b gt взять вот такие множества,
то вот это равно вот этому.
То есть на таких множествах свойство выполнено независимости.
Теперь нам нужно сделать еще один шаг.
Я прошу, может на минуту задержаться, чтобы не начинать с начала,
и вы забудете через неделю.
Так я схематично быстро, но надеюсь понятно.
Теперь давайте покажем, что из вот этого свойства,
то есть определение такого типа, следует вот это.
Мы с вами знаем, что Борелевское множество в общем виде
представляет из себя сумму множеств a gt, b gt,
не пересекающихся в конечном числе.
Вот общий вид Борелевской алгебры.
В свое время мы это получали.
Теперь смотрите, у нас вот таких вот множеств будет для каждого из b gt.
Вот множество такого типа.
Обратите внимание, что эти множества между собой не пересекаются несовместно.
И в то же время любое множество для какого-нибудь b первого
независимо от такого же множества b kt.
Ну собственно так сказать, потому что это Борелевские множества.
То есть мы с вами имеем...
Так, тут какой индекс поставить?
Давайте я тут поставлю какой-нибудь l.
Мы с вами имеем веро...
Что?
Вот это?
Ну это объединение, ну я же как бы...
Объединение, сумма, произведение, точка.
То есть точнее как пересечение, точка.
Ну и когда вы писали общий вид Борельского множества, я так и писал, по-моему.
Вот, значит тогда у нас тут...
Я почему сейчас, ну как бы написал сумму, потому что мы результат получали соответствующий.
Тут мы должны написать...
Ну давайте напишу сумма b l.
Точнее говоря, тут как раз произведение будет.
Смотрите, что за структура.
B l t представляет из себя объединение непересекающихся множеств.
Каждое множество для различных b l t независимы.
Вот эти события, что ксиприн лежит вот этому.
И я напоминаю вам результат.
Мы с вами получали, что для множества такой структуры они независимы между собой.
Мы его правда получали для случая двух величин, но как бы по индукции продолжается.
Припоминаете такой результат?
Он выглядел так. Мы писали a равно сумма a k t, b равно сумма b l t,
k на a m равно пустому множеству.
Для любых l и k, вероятность a k b l равно вероятности a k b l.
Припоминаете?
Смотрите записи.
Мы с вами получали такой результат, когда мы получали свойства независимости,
множеств, которые не являются независимыми в совокупности.
Мы в частном случае вот такую штуку с вами получили.
Это когда мы с вами доказывали, что если система множеств независима, то и любые элементы алгебры в ней независимы.
Здесь то же самое, только тут было 2, а тут n.
Значит, вот эти множества все независимы.
Это просто произведение вероятностей b l t.
То есть xy принадлежит xy, l t принадлежит b l t.
Извините задержал вас, но чтобы не начинать сначала.
Итак, кратко итог.
Мы с вами доказали свойства из того, что функция распределения распадается в такое произведение.
Следует свойство независимости для множества такого типа.
А потом доказали, что если верно для множества такого типа, то верно для множества такого типа,
то есть из Борельской алгебры.
И по теореме о продолжении непрерывности то же самое верно и для элементов сигма алгебры.
Ну вот это некая логическая точка.
Все, спасибо.
