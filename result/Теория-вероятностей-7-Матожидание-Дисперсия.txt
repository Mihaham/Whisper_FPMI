вот звонок да так давайте начнем с того чего не успели в прошлый раз давайте вот какой
рассмотрим вопрос значит мы с вами в свое время установили что сумма случайных величин
то есть можно их складывать вопрос как складывать это же там не 2 плюс 2 прибавить
получившееся случайная величина собственно что нам про нее неизвестно случайно величина
это элемент ну такого специального вероятностного пространства множество
исходов известная это r1 сигма алгебра известная это барелевская неизвестна только функции
распределения то есть для того чтобы определить сумму случайных величин нужно определить ее
функцию распределения давайте это рассмотрим но сначала общая как бы да соображение пусть
это равно кси 1 плюс кси 2 функция распределения это в точке у это вероятность того что кси 1
плюс кси 2 меньше у а вот дальше давайте предположим что кси 1 и кси 2 непрерывные
случайные величины это собственно самый ну что называется важный случай то есть
у них есть совместная плотность тогда вот эта вероятность представима в виде двойного
интеграла по области x 1 плюс x 2 меньше у f кси 1 кси 2 x 1 x 2 d x 1 d x 2 через функцию плотности
вероятности да распишем ну и давайте сделаем замену переменных y 1 равно x 1 y 2 равно x 1
плюс x 2 модуль и кабиана такого преобразования чему равен единица как видоизменяются области
изначальная область интегрирования x 1 x 2 вот она превращается и грек один и грек два
вот в такую поэтому делаем замену переменных получаем интеграл по y 2 от минус бесконечности
до у интеграл f кси 1 кси 2 x 1 x 2 д ой прошу прощения x 1 это y 1 а вот x 2 это y 2
минус x 1 то есть y 2 минус y 1 y 2 минус y 1 d y 1 и берется ну да в области написал здесь от
минус бесконечности до бесконечности минус бесконечности до бесконечности
д д y 2 вот дальше это функция распределения давайте функцию плотности посчитаем для
этого возьмем производную по у слева получим f это от у а справа получим интегрирование
по верхнему пределу интеграл минус бесконечности до бесконечности f кси 1 кси 2 y 1 у минус
y 1 d y 1 ну и чисто для красоты y 1 заменим на z на другую букву просто ну и получим
вот такую формулу я ее вот здесь напишу пусть у нас здесь побудет f кси 1 плюс кси 2 от у равно
интеграл от минус бесконечности до бесконечности f кси 1 кси 2 а нет z у минус z по d z
ну вот это вообще формула свертки так она в целом вам знакомы должна быть да
это функция плотности вот этого вектора кси 1 кси 2 значит если у нас абсолютно непрерывное
распределение то функция плотности случайного вектора это производные его функции распределения
dx 1 dx к но это очевидно по моему вот значит вот эта функция свертки пусть пока повисит хорошим
примером на использование этой функции является решение такой задачи пусть у вас есть n штук
независимых случайных величин независимых случайных величин да про независимость
мы уже говорили все из нормального распределения все из равномерного распределения 0 1 все из
равномерного распределения 0 1 тогда вероятность того что ксе 1 плюс так далее плюс кси n окажется
меньше некого x равно x в степени n делить на n факториал формула верна для x от нуля до единицы
ну а это что такое это объем энмерного симплекса с ребром x да что симплекс это множество точек
вида x1 плюс и так далее плюс xn меньше некого у ну x1 и так далее xn больше равно нуля ну
можно больше такой в трехмерном случае пирамида в четырехмерном вот симплекс что не незнакомое
слово ну вот я там я его то на него сослался потому что думал что вы знаете объем симплекса но если
вы его не знаете тогда как бы вам этот результат ни о чем не говорит но тем не менее канонический
пример использования функции формулы свертки но вот один такой который всегда приводится так это
значит по поводу распределение суммы так ну мы с вами на прошлой лекции так подробно разобрали
подробно разобрали функцию распределения случайного вектора но определение дали
понятное определили функцию распределения свойство ее из учили ну теперь надо хоть
какую-нибудь одну хоть какой-нибудь один случайный вектор так себе для примеров вести да ну и давайте
в качестве примера мы с вами из случайных векторов рассмотрим два это так называемое
полиномиальное распределение и нормальное распределение нормальный случайный вектор давайте
Давайте начнём с полинамиального распределения.
Оно определяется такими параметрами k штук положительных
чисел п-житая и числом n, причём сумма всех п-житых
равна единице.
Это полинаминальное распределение для k-мерного вектора.
x1, xk дискретные случайные величины, принимающие значение
из натурального ряда, и 0 ещё могут принимать.
Вот такой это область определения, так сказать.
И определяется это дискретный случайный вектор следующими
вероятностями.
Вероятность того, что k-житая равно некому n-житому, g
равно от единицы до k, равно n-факториал, n1-факториал,
так далее, nk-факториал, умножить на p1 в степени n1, умножить
и так далее, на pk в степени nk, где сумма всех nk равно
0, это определение.
Для дискретной случайной величины определили вероятность
того, что случайный вектор принимает именно такое
значение.
В принципе, как бы всё понятно, но мы когда какой-то
вводим случайную величину, а я произнёс, но не написал.
Нет, конечно, p-житая строго больше нуля.
Но мы когда вводим какую-то случайную величину, я привожу
некий эксперимент, мысленный эксперимент, который ей
соответствует.
Здесь давайте поступим следующим образом.
Возьмём отрезок 0,1 и разобьём его на отрезочки.
Один длины p1, второй длины p2, последние длины pk.
И начнём на удачу бросать точку на этот отрезок 0,1.
Бросаем точку на удачу.
Делаем это n раз незавихимо, значит эта точка может куда-то
попадать, n раз мы это делаем, и сколько-то точек попадут,
назову это вот в этот ящик, это n1, вот столько во второй
ящик n2, в кат и ящик nk точек попадёт.
Вот этот набор и представляет из себя случайную величину,
имеющую полинаминальное распределение.
Ну это один из, можно рассматривать ящики и бросать шарики,
можно бросать точки на отрезок специальным образом
поделённый.
Вот такому мысленному эксперименту соответствует полинаминальная
случайная величина, вероятность вектора с компонентами n1, n2, nk
задаётся вот такой формулой.
Мы знаем случайную величину, которая является частным
случаем полинаминального распределения.
Кто подскажет, что из-за случайной величины?
Полинаминальное распределение соответствует k равно 2, если
взять k равно 2, то полинаминальное распределение превращается
в бинаминальное распределение.
Так, ну вот давайте мы этот пример как бы отложим
в памяти.
Это пример дискретного случайного вектора.
Следующий объект, с которым нам надо познакомиться,
это условные функции распределения для случайного вектора.
Но сначала чуть-чуть напомню, к чему мы пришли в конце
прошлой лекции.
Мы определили свойство независимости k штук случайных величин
компонент вектора.
Таким образом, функция распределения распадается
в произведение функции распределения k, от 1 до k.
Распадается в произведение функции распределения
И, что не менее важно, это то же самое, как, или точнее
говоря, это свойствие эквивалентно вот такому.
Вероятность того, что ксиджитэ принадлежит некому боджитому
g равно от 1 до k, равно произведению вероятности
того, что ксиджитэ принадлежит боджитому.
А вот в качестве боджитого, напомню, это важно, боджитая
это может быть.
И все это эквивалентное определение.
Полуинтервал от житая боджитая, элемент бареллевской
алгебры, элемент бареллевской сигма алгебры.
Всякое свойство с любым из этих элементов, если
оно выглядит так, означает независимость и означает
вот это свойство.
Вот на этом мы вчера закончили.
Ну теперь в практической плоскости давайте поймем,
ну просто запишем один раз, не будем к этому возвращаться.
Для дискретных случайных величин DSV, свойство независимости
можно записать в таком виде, ксиджитэ равно x с джитому
одновременно для всех компонент.
Эта вероятность равна произведению вероятности.
А для непрерывных случайных величин это можно записать
в виде.
Функция плотности вектора x1, xкт распадается в произведение
функций плотностей, ксиджитэ, xджитэ, g равно от единицы до
k.
Практически так можно и таким пользоваться определением.
Это следствие вот этих определений.
Эквивалентное.
Так, ну и теперь давайте еще рассмотрим один объект
в части функции распределения.
Это так называемая условная функция распределения.
Ну по названию догадываетесь, что это связано с условными
вероятностями, но так и есть.
Напомню, что для случайной величины кси функция распределения
вероятность того, что кси меньше х, ну можно рассмотреть
и условную функцию распределения.
Значит, вот здесь напишу чуть подробнее, хотя мы уже
так не делаем, но может быть сейчас это будет полезно.
Это вероятностная мера тех омега, что кси от омега
меньше х.
Ну и можно ввести какую-нибудь условную вероятность относительно
события.
Условную функцию.
Это будет условная вероятность омега таких, что кси от омега
меньше х при условии, что омега принадлежит некому
а событию из сигма-алгебры.
Условная вероятность – это вероятность со всеми свойствами,
поэтому условная функция распределения – это полноценная
функция распределения.
Чему это равно?
По формуле условной вероятности это равно вероятности таких
омега, что, во-первых, кси от омега меньше х, и одновременно
с этим омега принадлежит а, и поделить это на вероятность
того, что омега принадлежит а.
Значит, собственно, и всё.
Если знаменатель не равен нулю, то никаких проблем
ни методологически ни в использовании нету.
Можно пользоваться условной функцией распределения
так же, как любой другой.
Более того, иногда эти формулы вполне так презентабельно
выглядят, например, f кси при условии это, х при условии
у.
Если мы под этим будем понимать вероятность того, что кси
меньше х при условии, что это меньше у, это две случайные
личины кси и это, то, воспользуясь формулой полной вероятности,
мы это можем переписать в виде.
Функция распределения вектора кси это делить на функцию
распределения это.
Ну, конечно, для тех у, где знаменатель не равен нулю.
Вот такая вполне красивая формула.
Ну, и они могут быть всякие другие.
Но, как сказать, практика привела к тому, что необходимо
создать какую-то интерпретацию в случае, когда вероятность
вот этого события ара равна нулю, вероятность события
ара равна нулю, ну, что приходит в голову.
Так, вот здесь сотру.
Надо какой-то предельный переход сделать.
Например, построить систему вложенных множеств, вероятность
каждого из которых не равна нулю, так, чтобы их пересечение
в счетном числе равнялось а, да, то есть, давайте попробуем
обойти эту проблему, построим вот такую вложенную систему
множеств, такую, что p, a, n равно a.
То есть, каждого из a, n не равна нулю, и тогда вот,
ну, не буду всю формулу, наверное, переписывать,
просто напишу, а нет, пожалуй, придется.
Значит, вот это xi, х при условии a, n, точнее говоря, при условии
a мы запишем как предел, когда n стремится к бесконечности,
вероятности ω такие, что xi от ω меньше х и одновременно
с этим ω принадлежит a, n, делит на вероятность ω принадлежит
a, n.
Ну, если такой предел существует, то мы, собственно, и назовем
это вот условной вероятностью, когда вероятность а равна
нулю.
Ну, выглядит разумно, нет, идея неплохая, но проблема
в том, что, к сожалению, этот предел зависит от того,
как мы построим вот эти множества.
То есть вот так не пройдет.
Что же нам делать?
Ну, мы должны обрисовать какие-то частные случаи,
в которых этот предельный переход корректен.
Идея та же, но только, грубо говоря, надо множество задать,
явно, вот эти а, n, и тогда предел не будет зависеть,
или мы стремимся к тому, чтобы он не зависел, и тогда
можно считать, что мы определили условную функцию
распределения.
Ну, и давайте это для, собственно, того случая, когда это не
получается.
Что я имею в виду?
Если вот эта, например, дискретная случайная уличина,
то, в принципе, все получается, потому что нет смысла брать
это, вероятность которых равна нулю.
То есть вероятность этих событий не равно нулю, и
если условие задано на дискретной случайной величине,
то тогда там все работает.
То есть тот случай, когда не получается заведомо,
это когда, как это сказать, случайная величина задающая
условия непрерывна, тогда вероятность того, что она
равна какому-то значению, всегда равна нулю, то есть
никак не обойдешь.
Поэтому давайте мы пройдем этот путь, считая, что
кси и это непрерывные случайные величины, то есть у них есть
совместная плотность.
Ну и давайте выпишем вот, обозначим так же, потому
что тут обозначения, как сказать, нет такого стандартизированного.
Таким, ну не похожим, а совпадающим с тем, но только по-другому
теперь определим.
Это есть у нас вероятность того, что кси меньше х, одновременно
с этим это равно y, вот события нулевой меры, делить на
вероятность того, что это равно y.
Должно так быть, но здесь деление на 0, поэтому давайте
сделаем предельный переход, вот таким образом.
Это предел, при n, стремящемся к бесконечности, вероятности
того, что кси меньше х, а это принадлежит некому d
дельта n, делить на вероятность того, что это принадлежит
дельта n.
А дельта n, это у нас вот такой полуинтервалчик
а n, bn такой, что а n возрастая сходится к y, а bn убывая сходится
к y.
Вот такой переход рассмотрим.
Давайте распишем, что это такое через плотности.
Это предел, при n, стремящемся к бесконечности, ну и могу
так записать.
Интеграл по дельта n, по dy, интеграл от минус бесконечности
до х, f, кси, это, ну в, возьму, в, y, по dv.
Вероятность вот такого события, а в знаменателе
стоит интеграл по дельта n, f, это от y dy.
Вот этот переход уже можно сделать корректно.
Вот сюда напишу.
Я напишу сразу ответ, надеюсь, что вас не затруднит.
Это интеграл от минус бесконечности до х, f, кси, это в, y, делить,
это все под интегралом, делить на f, это y dv.
Ну согласны, да?
Вот этот интеграл, как функция y, представим значение
на, там, в точке в этом интервале, на длину плюсу малой длины
интервала, в общем, переходим к пределу, получаем такую
штуку.
Ну и теперь сравниваем.
Это функция распределения, это ее представление через
интеграл.
Это что означает, что эта функция абсолютно непрерывна,
раз имеет такое представление, и поэтому можно получить,
я это вот здесь запишу, функцию плотности.
Продиференцировав обе стороны по х, мы получим функцию плотности,
или ту функцию, с которой формально можно поступать
как с условной функцией плотности.
Вот эта вот функция плотности означает, что, означает
вероятность того, что случайная величина кси попадет в
какой-то дифференциал в окрестности точки х при
условии, что случайная величина это равна y.
Вот с этой функцией, которая, ну как бы так сказать, строго
говоря, там не определена, поскольку условие имеет
нулевую вероятностную меру, но с ней можно оперировать,
если в качестве ее взять вот такую вот функцию.
И вот эта вот вещь, которой как бы все пользуются, условная
функция распределения.
Так, про функции распределения вектора вроде все, и мы тогда
переходим к другой, ну такой фундаментальной, можно
сказать, теме.
Ну, наверное, и так, и так можно вас поймут.
Значит, ну, функция плотности вероятности, если полное
название, условная функция плотности вероятности.
Ну, собственно, мы изначально называли вот эту f, которая
ядро интеграла от минус бесконечности до x, f dx равно функции распределения,
мы называли функцией плотности вероятности, но я тогда
сказал, что иногда говорят, просто функция плотности,
понимают, что речь идет о вероятности, а не о материале
каком-то, да, так все, там тоже есть функция плотности,
РО, да, называется.
Вот, значит, ну, а как это, перестановки здесь слов для,
ну, наверное, так сказать, там ничего не меняют, по
разному можно, лишь бы вас понимали, о чем вы говорите.
Так, значит, следующий, ну, прямо трудно переоценить,
по важности объект, который мы с вами введем, это
математическое ожидание, случайные величины, это
числовая характеристика, обозначается, ну, традиционно,
екси, математическое ожидание, ну, экспект, ожидаемая величина,
и по определению, это есть интеграл Либега по множеству
элементарных исходов.
Скажите вам, как привычней, pdОмега или dpОмега, а, ну,
неважно как бы, нет, просто иногда пишут dp в скобочках
Омега, а иногда п в скобочках dОмега, ну, если вам все равно,
я буду так писать.
Значит, вот, математическое ожидание екси, еще для математического
ожидания используют обозначение мкси, это ровно тот же объект,
тоже математическое ожидание, но называют его mкси.
Вот здесь я хочу сказать, что это тот случай, когда
это не просто два названия эквивалентных, на самом деле
это не случайно, что один екси, а второй мкси, это
мы поймем в конце лекции, и, собственно, это и покажет
нам, так сказать, важность этой числовой характеристики,
то есть это эквивалентные названия, я напишу вот так
mкси равно екси, в том смысле, что это одно и то же, ну,
и должен вам сказать так это, пафосно, что это, по
сути дела, второй закон Ньютона теории вероятности.
mкси равно екси, тут, конечно, определенный художественный
образ, но к концу лекции вы поймете, что я имею в виду.
Вот, значит, вот такой вот объект, математическое
ожидание.
Ну, что мы про это можем сказать?
Во-первых, это число, это уже не случайная влечина,
это число.
Как любой интеграл Либега, у него есть некие универсальные
свойства.
Ну, давайте первое, пусть у нас кси от омега тождесть
на равно с, то есть константа, выраженная случайно влечена.
Чему равном от ожидания такой случайной влечины?
A?
C?
Ну, собственно, сюда поставьте C.
Значит, второе свойство, которое есть, пусть, ну,
или можно в первом же свойстве, речь идет о каких-то
конкретных случайных величинах.
Давайте пусть кси от омега у нас, это индикаторная
функция множества A.
То есть функция, которая равна единице, когда омега
принадлежит A и нулю, когда омега не принадлежит A.
Математическое ожидание такой случайной влечины,
чему равно?
Мера множества A, которую мы в теории вероятности
обозначаем вот так.
В общей теории меры мю или лямбда, мы обозначаем
Вот, значит, следующее свойство
случая интеграла Либега.
Математическое ожидание A кси, A константа, чему равно?
Во-первых, математическое ожидание кси плюс это,
чему равно?
Математическому ожиданию кси плюс математическое
ожидание это.
Свойства линейности интеграла Либега.
Интеграл Либега такими свойствами обладает,
поэтому и мат ожидания, которая есть интеграл Либега,
тоже ими обладает.
Так, следующее свойство, которое мы отметим.
Давайте рассмотрим две случайные величины кси1 и кси2
вот с такими свойствами.
Вероятностная мера Омега таких, что кси1 от Омега
равно кси2 от Омега равна единице.
Вербально это говорят, кси1 равно кси2 с вероятностью
единица, или кси1 равно кси2 почти, наверное.
В функциональном анализе употребляется почти всюду,
а в теории вероятности почти, наверное, поскольку мы
здесь имеем дело то ли да, то ли нет, случайное событие,
поэтому не почти всюду, а почти, наверное.
В общем, либо говорят, что эти величины различаются
на множестве меры ноль, естественно.
И если кси1 и кси2 совпадают с друг с другом,
почти, наверное, то вот эти два числа равны.
Е кси1 равно е кси2.
Это следствие того, что подинтегральная функция
в интеграле Либега, будучи изменена на множестве меры ноль,
не изменяет интеграл Либега.
Еще одно свойство ответимо интеграла Либега.
Пусть у нас теперь две функции, но только вот такие.
Кси1 от Омега меньше ли равно кси2 от Омега?
Равно единице.
То есть почти, наверное, случайная величина кси2
мажорирует случайную величину кси1.
Тогда по свойствам интеграла Либега
математическое ожидание кси1,
число вот это, меньше числа математическое ожидание кси2.
Вот, кстати, где свойство линейности,
допишите еще вот такое свойство.
Математическое ожидание кси,
минус мат ожидания кси, чему равно?
Нулю.
Вот я вот тут вот, вот так вот.
Нулю.
Просто мы такой конструкцией частенько будем пользоваться.
Давайте запомним, что, кстати, она равна нулю.
Значит, такие вот свойства,
это все как бы такие,
совсем пока все просто.
Ну и наконец,
еще одно свойство интеграла Либега,
которое мы уже как-то так
позволит нам продвинуться дальше.
Давайте рассмотрим
конечную систему множеств.
ajt j равно от 1 до n.
Это покрытие, то есть
объединение всех ajt равно
ω,
а it ajt пересечения равно пустому множеству.
Ну да, и все.
Тогда
введем вот такую
функцию,
Sn атомига,
которая равна сумме
какие-то xjt
на индикаторную функцию ajt.
g равно от 1 до n.
Ну, давайте, так сказать,
для строгости
напишем, что все xjt больше нуля.
Должна быть знакомая вам конструкция.
Это что такое?
В терминах интеграла Либега.
Это простая функция.
В терминах интеграла Либега
это простая функция.
И в теории Либега
математическое ожидание такой функции
задается аксиоматически.
А именно, математическое ожидание
Sn
больше 0,
чем
а именно, математическое ожидание Sn
равно сумме
xjt
на вероятность ajt.
g равно от 1 до n.
Правильно, да?
Но давайте посмотрим,
это важный методологический такой момент.
Давайте посмотрим, что это за функция
с точки зрения
ну, нашей теории.
С точки зрения случайных величин.
Какая это случайная величина?
Это дискретная случайная величина,
потому что она принимает
ну, вот эти значения xjt
с вероятностями ajt.
Но
для того, чтобы случайная величина
приняла значение xjt,
значит, у нас должно произойти
событие с вероятностью ajt.
И вот я сейчас напишу
и поясню.
Я перепишу так,
xjt
на вероятность того,
что Sn
равно xjt.
Правильно, да?
Если Sn
равно xjt,
значит, вот эта равна 1,
она только одна может равна 1.
Ну и значит,
что вероятность ajt
это вероятность того, что Sn
равно xjt. Правильно?
Ну и что получается?
Получается, что
математическое ожидание дискретной
случайной величины
может быть нами выражено
только
на основании, ну скажем так,
функции распределения этой случайной
величины, да?
Смотрите, здесь нет омега, здесь нет
исходно вероятностного пространства.
Все удачно срослось.
Интеграл либега,
который, вообще говоря, берется
по исходному вероятностному пространству,
ну, по крайней мере, для дискретных
случайных величин, оказалось,
что он выражается через функцию
распределения этой дискретной случайной величины.
Нам не нужно исходное
вероятностное пространство. И это
революционный скачок для нас.
Так, отдыхайте и продолжим.
Продолжаем.
Итак,
у нас все так удачно срослось,
что мы можем теперь
вычислять математические ожидания
дискретных
случайных величин,
как бы,
зная только
вероятности того, что
случайная величина приняла какое-то
конкретное значение.
Вот набор вот этих вероятностей,
которые, ну, естественно, так сказать,
и создают функцию распределения,
с функцией распределения.
Давайте
теперь этим воспользуемся
и найдем
математическое ожидание
такой дискретной случайной
величины, как Бернулевская.
У нее, как мы помним, параметр P.
Чему оно равно?
Мат ожидания.
Мы должны вот по этой формуле взять
значение, которое она принимает,
и множеная вероятность.
Бернулевская случайная величина
принимает значение 0
с вероятностью Q
и значение 1
с вероятностью P.
То есть получается P.
Математическое ожидание
Бернулевской случайной величины равно P.
Ну, на самом деле
это еще следует
вот отсюда. Мы уже это, собственно,
сделали, потому что индикаторная
функция, это
там, Бернулевская случайная
величина.
Только заданная еще через исходное
вероятностное пространство.
А теперь давайте поймем,
чему равно математическое
ожидание
биномиальной случайной величины,
у которой два параметра
N и P. Согласно
нашей формуле, это равно
сумма
значения, которое принимает
случайная величина K,
на вероятность того, что она примет это значение,
это C из N по K,
P в степени K,
Q в степени N минус K.
K изменяется
от нуля до N.
Вот
чему это равно, с одной стороны.
С другой стороны,
это равно математическому
ожиданию
суммы в количестве
N штук, каких случайных
величин?
Бернулевских.
Помните, да,
когда мы вводили
биномиальную случайную величину,
мы говорили, что это на самом деле сумма
Бернулевских. Мат ожидания
суммы равно сумме мат ожиданий,
и получается,
что это равно N на P.
То есть,
вот эта вот сумма
равна N,
П.
Обошлись без суммирования,
воспользовались свойством линейности.
Ну, надо сказать,
что все наши канонические
дискретные случайные величины,
они все положительные,
и поэтому вот это условие
выполняется автоматически.
Но формула верна, конечно,
не только для случая,
когда exit больше нуля,
потому что, как вы помните,
в теории Лебега просто не такая
логика. Сначала вводится для положительных
функций, потом произвольная
функция разбивается на сумму
положительный и отрицательный.
Отрицательный берется с минусом,
получается положительная,
считаются два интеграла Лебега,
и один вычитается из другого.
Поэтому это не принципиально,
просто не буду это все проделывать.
То есть, математическое ожидание
дискретной случайной величины
всегда определяется вот такой формулой,
независимо от того
положительные вот эти exit
или отрицательные.
Нет вопросов, все понятно.
Ну давайте теперь
давайте теперь
ну чего-то
попробуем получить
с этими мат ожиданиями
какой-то прок извлечь.
По крайней мере, может быть, понять к чему это все,
как они связаны,
что из чего следует.
Для этого давайте рассмотрим
вот такую конструкцию
математическое ожидание
КС минус А в степени К.
Вот такое мат ожидание называется
кратым моментом
случайной величины КС
относительно А.
Числа А.
Кратым моментом
случайной величины КС
относительно числа А.
Значит,
ну, это
что называется, так сказать, общий вид,
рассматриваются два частных случая.
А равно нулю
и тогда это
ЕКСИ-катая
и называется
кратым начальным моментом.
Вот это уже расхожий термин.
Катый начальный момент.
И второй случай, который, так сказать,
рассматривается, это
А равно мат ожидания КС.
Тогда это
получается КС минус мат ожидания
КС в степени К.
И вот такое мат ожидание
называется катым
центральным моментом.
Вот это катый начальный момент,
катый центральный момент.
Первый начальный момент
это что в наших терминах?
Это, собственно, мат ожидания ЕКСИ.
Первый центральный
момент чему равен?
Нулю.
А вот для второго центрального момента
есть свое название
и называется это дисперсии
случайной увеличены КС.
Ну, еще традиционно
используют обозначение
Сигма квадрат и тогда Сигма
называется средне квадратичным
отклонением. Средне квадратичное
отклонение.
Ну, просто
обращу внимание.
Мы тут берем
мат ожидания, применяем к некой
ну, другой случайной
увеличении КС, да?
Ну и просто надо понять, определение
как-нибудь меняется. Ну нет, определение
конечно не меняется.
Мат ожидания ФИ от КС,
если ФИ баррельская функция, то есть
случайно увеличена. Но это тот же самый
интеграл Лебега, только будет
ФИ КСИ от
Омега ПДОмега.
Здесь с определением
все понятно.
Вот.
Значит,
теперь давайте
чего сделаем?
Давайте, поскольку мы ввели дисперсию,
мы получим ее некоторые
свойства.
Некоторые свойства дисперсии.
Ну первое свойство,
математическое ожидание
дисперсии,
то есть дисперсия равна
математическому ожиданию КС
квадрат, минус мат ожидания
КС в квадрате.
Не надо выводить, да?
Вы знаете.
Так, значит,
второе свойство дисперсии,
дисперсия
АКСИ плюс
В, ну давайте
коротенько
сделаем один раз.
Математическое ожидание АКСИ
плюс В,
минус мат ожидания
АКСИ плюс В
в квадрате
равно.
По линейности раскрываем
В сокращается, А выносится
за скобки. Получается
математическое ожидание
А,
вот тут вот КСИ
центрированное.
Это обозначение, которое
рекомендую вам знать.
Случайная влечина с кружочком сверху,
это случайная
влечина минус ее мат ожидания.
Центрированная случайная влечина
называют. Значит,
АКСИ
центрированная в квадрате
по свойству мат ожидания это равно
А квадрат,
а мат ожидания
центрированной случайной влечины
в квадрате это, собственно, дисперсия есть.
А квадрат дисперсия КСИ.
Значит, вот такое свойство.
Дисперсия АКСИ плюс В
равно А квадрат дисперсии КСИ.
Давайте пока
эти два свойства
возьмем.
Думаю, тут уже можно стирать.
Вот только второй закон Ньютона
ставлю здесь.
Значит, следующий
объект,
который мы введем,
используя понятие математического ожидания,
это кавариация
двух случайных величин.
Кавариация
АКСИ это
по определению
это есть
математическая
влечина.
Кавариация АКСИ
это по определению
это есть математическое ожидание
КСИ
минус мат ожидания КСИ
умножить на это
минус мат ожидания это.
Ну, пока не очень понятно, зачем она нам.
Ну, дальше станет понятно.
А пока просто давайте отметим такие
свойства. Первое свойство
кавариация
КСИ это
равна
математическому ожиданию КСИ
умножить на это
минус мат ожидания КСИ
умножить на мат ожидания это.
Ну,
не делаю, собственно,
просто раскрыть скобки, воспользоваться
линейностью.
Второе,
вот второе уже специфичное, как бы,
для нашей теории,
кавариация случайной величины
сама с собой, чему равна?
На
определение смотрим.
Дисперсия.
То есть кавариация сама с собой
это дисперсия.
И третье свойство, которое
мы сейчас выделим,
значит,
вот, выпишу его,
кавариация КСИ это
по определению
этот интеграл
КСИ от Омега минус ЕКСИ
умножить на это
от Омега
минус ЕЭто
и ПДОмега.
Вот здесь поставлю квадрат,
тогда вот это все в квадрате.
И по неравенству к ошибке
Буниковского, это меньше
или равно,
чем интеграл
КСИ от Омега
минус ЕКСИ
в квадрате
ПДОмега
умножить
на интеграл
ЭТО от Омега
минус
мат ожидания
ЭТО в квадрате
ПДОмега.
То есть равно дисперсии
КСИ умножить
на дисперсию ЭТО.
Вот это свойство, которое
мы как бы
положим в копилку.
Ковариация в квадрате
случайных величин
меньше или равно произведению их дисперсии.
Дальше, что еще мы можем
получить?
Давайте определим класс
случайных величин
с вероятностью 1
больше 0,
больше равно 0.
А если мы
определим класс
случайных величин
в квадрате
ПДОмега,
то мы можем
определить класс
случайных величин
с вероятностью 1
или равно нуля? Ну, таким естественным образом. То есть рассмотрим случайные
величины с вероятностью единицы не отрицательные. Тогда для таких случайных
величин имеет место такое неравенство.
кси меньше или равно епсилон, больше или равно епсилон, кси больше или равно
епсилон, меньше или равно математическому ожиданию кси делить на
епсилон. Знакома вам такая формула? Ну, в каком-то виде, да, так сказать, вы
там ее получали. Как она называется? Неравенство Маркова, да. Я почему
уточняю, потому что иногда называют неравенством Чебышева. И, в принципе, может
это отчасти справедливо, поскольку Марков ученик Чебышева, они как бы так
перепутаны у них работой, и там не поймешь, так сказать, там кто. Вот, но вроде бы вот
так вот, вот это конкретно неравенство, правильно называть неравенством Маркова.
Ну, давайте его докажем. Вероятностные меры омега такие, что кси от омега больше
равно епсилон, это на самом деле вероятность индикаторного события кси от
омега больше равно епсилон. Поэтому это интеграл, индикаторная функция по
множеству кси от омега больше равно епсилон от омега, pd омега. Ну а теперь заметим,
что для любого омега кси от омега делить на
епсилон больше или равно индикаторной функции соответствующей. Согласны, да? Там, где
индикаторная функция равна единице при тех омега, значит при тех омега кси от
омега больше равна епсилон, но отношение, соответственно, больше единицы. А там, где
индикаторная функция равна нулю, кси-то от омега положительная, не отрицательная,
поэтому эта штука не отрицательная. Ну а дальше, значит, меньше или равно по
свойствам интеграла Либега единица на епсилон, интеграл по омега, кси от омега, pd омега. То есть
мат ожидания кси делить на епсилон. Вот такое немудренное доказательство. Ну и какой-то
содержательный первый вывод, который из него можно сделать, состоит в следующем.
А, ну, кстати, неравенство Маркова строгое в том смысле, что можно привести пример,
когда именно больше или равно, именно равно мат ожидания кси на епсилон. То есть неулучаемая,
так вообще говоря. Вот, давайте в качестве положительной случайной величины возьмем
случайную величину кси минус мат ожидания кси в квадрате. Ну она, понятное дело, больше равна нуля.
И для нее неравенство Маркова кси минус мат ожидания кси в квадрате. Больше ли равно
епсилон? Ну мы возьмем епсилон в квадрат, имеем право. С одной стороны, это вероятность того,
что модуль кси минус мат ожидания кси больше или равно епсилон. А с другой стороны, по неравенству
Маркова меньше или равно мат ожидания вот этого выражения, которое из дисперсии кси делить на
епсилон квадрат. Я когда говорил о дисперсии, забыл сказать очевидный факт, что для константы
дисперсия равна нулю. Это так сказать очевидный факт. Вот из этого неравенства следует и в обратную
сторону. Если дисперсия какой-то случайной величины равна нулю, то она совпадает со своим мат ожиданием,
поскольку это для любого епсилона верно. Ну и, собственно, вот это, этот факт, или точнее говоря,
вот это неравенство, вот это неравенство уже называют неравенством Чебышева бывает. Вот это
неравенство устанавливает связь между мерой отклонения случайной величины от ее мат ожидания
и дисперсией. Если дисперсия очень маленькая, то с очень большой вероятностью случайная величина
сконцентрирована в окрестности своего мат ожидания. Ну а если дисперсия равна нулю, значит случайная
величина просто с вероятностью единицы равна своему мат ожиданию. Является константой. Вот, значит,
ну вот как бы первое какое-то понимание, для чего нам нужны вот эти числовые характеристики.
Теперь мы должны двинуться дальше.
Ну ладно, вернусь потом.
На чем мы остановились? Мы остановились на том, что для дискретных случайных величин мы умеем
вычислять мат ожидания на основании функции распределения, ну и дальше с этими от ожиданиями
делать, ну, то, чего там у нас получается. Но у нас остался вопрос, что делать с непрерывными
случайными величинами. Для того, чтобы на него ответить, давайте вернемся к функции СН и от
Омега, но только мы ее чуть-чуть видоизменим так. Х житая, а индикаторная функция будет
не какого-то произвольного множества житая, а вот такое. Омега такие что, кси от Омега,
то есть мы взяли какую-то случайную величину кси от Омега, вот она у нас есть, и для нее
строим вот такой класс функций. Меньше х жи плюс один, больше ли равно х житого.
Ну, ж равно от единицы пусть будет до n минус один. То есть, это частный случай вот тех простых
функций, которые мы с вами ввели, для которых определено мат ожидания, частный в том смысле,
что мы вот так специфичным образом, так сказать, взяли эти множества аитые. Вот таким образом.
Ну, честно говоря, это она пока не до конца определена. Не понятно, чему она равна,
когда Омега такие, когда кси от Омега меньше х один и больше равно х жи плюс один. Мы можем
определить, значит, сн от Омега равно нулю, если кси от Омега меньше х один и сн от Омега равно
х н, если кси от Омега больше равно х н. Так вот, чтобы была определена эта функция. Это тоже
простая функция в терминах интеграла Либега. Ну, еще раз просто скажу, мы, понимая, как с этим
поступить, не говорим, что все х т больше нуля. Но единственное, что мы их здесь упорядочим. Ну,
чтобы вот это было корректно. Они у нас х один меньше х и х два, так далее, меньше х. Ведем вот такой
класс функций. Это тоже простые функции. Но, как в теории Либега доказывается, для любой измеримой
функции кси от Омега, вот в этом классе существует последовательность функций сн от Омега, которые,
возрастая, поточечно сходится кси от Омега. Был такой результат у вас? В этом классе мы можем
найти вот такую последовательность. Еще у нас есть теорема Леви, которая говорит, что интеграл Либега,
то бишь, математическое ожидание кси, которое равно интегралу Либега кси от Омега, ПДОмега,
Омега, которое равно предел сн от Омега. Ну, поскольку мы так подобрали сн от Омега,
что ее предел равен кси от Омега. Значит, ПДОмега, Омега. И, собственно, это пока жонглирование
определениями. А, собственно, содержание теоремы, вот оно, это равно пределу, когда n стремится к
бесконечности. Интеграл Либега сн от Омега, ПДОмега. Теорема Леви. В современной теории,
когда интеграл Либега вводят, там вводят интеграл от произвольной функции как супремум по всем
функциям меньше. И тогда, и тогда теорема, вот этот результат является теоремой Леви. Но сам Либег
вот так водил свой интеграл. Это у него было определение. Ну, просто как бы со временем более
технологично, так как делают сейчас. Но, тем не менее, такой результат есть. Что отсюда следует
для нас, помня о том, что сн от Омега это дискретная случайная величина. Во-первых, мы получили алгоритм,
механизм, как мы можем посчитать математическое ожидание произвольной случайной величины кси. Вот
таким образом. Потому что вот это в наших терминах это математическое ожидание сн. Надо взять
пределы сн, предел дискретных случайных величин, ну, правильным образом построенных. И тогда мы
получим математическое ожидание произвольной случайной величины. Вот. Это первое, что, значит,
мы отсюда извлечем. И второй такой, как бы сказать, методологический факт. Большинство свойств
мат ожиданий, которые верны для дискретных случайных величин, будут верны и для непрерывных
случайных величин. То, что можно сделать предельным переходом. Почти все можно. Ну, какие-то есть
случаи, когда нельзя. И мы, кстати, с ними столкнемся с одним случаем. Но, в принципе,
большинство свойств можно как бы доказать только для дискретных случайных величин. А для
непрерывных это будет следовать из предельного перехода. Значит, вот. Следующим шагом. А,
ну, собственно, да. Вот мы получили, что мот ожидания кси это есть предел вот таких сн. Или,
точнее говоря, предел мот ожиданий сн. А что представляет из себя мот ожиданий сн?
Что представляет из себя мот ожиданий сн? А мот ожиданий сн
равно сумма хж на вероятность вот этого множества. А вероятность этого множества что такое?
Просто по какому-то счастливейшему для нас течению обстоятельств это f кси от хg плюс 1
минус f кси от хg. Правильно? Оказывается, что математическое ожидание той дискретной случайной
величины, предел которой даст нам математическое ожидание непрерывной случайной величины,
мы его можем тоже вычислить исходя только из его функции распределения. Только из его
функции распределения. Ну, и если мы там n устремляем к нулю, то, как мы уже с вами остановились,
с одной стороны это сходится к мот ожиданию кси. Ну, это так как схематическое, да. А с другой
стороны это сходится, ну, точнее говоря, к мат ожиданию кси. Но поскольку вот это на что похоже
так сильно? На конечную интегральную сумму, да. То вот эту штуку мы будем обозначать,
вводим обозначение х df кси от х уже по области х от минус бесконечности до бесконечности. Вот
этот вот интеграл называется интегралом Либега Стилтиса. Интеграл Либега Стилтиса.
Вообще-то или Стилтьеса. Вообще-то Стилтьес этот интеграл вводил как бы из других неких
соображений, но тут он хорошо прижился. Никакой особой как бы он там глубокого смысла не несет,
это тот же самый интеграл Либега. Ну, просто, так сказать, мера, на которой производится интегрирование,
задается функцией распределения. И его такая практическая ценность состоит в том, что для
дискретных случайных величин он превращается в сумму икджита на вероятность того, что кси равно
икджита. А для непрерывных случайных величин, глядя вот на эту формулу до перехода,
он превращается в интеграл х, плотность, функция плотности f кси от х dx минус бесконечности до
бесконечности. Вот удобный формализм, который позволяет не говорить, сделаем ли дискретного,
сделаем ли непрерывного, сделаем ли интеграла Стилтьеса, Либега Стилтьеса. Вот это вот в свой
багаж, так сказать, положите. Давайте я вот здесь вот эту выпишу формулу общую, что мат ожидания кси равно
х df кси от х. Тоже нам полезно знать. Так, ну ни у кого нет какого-то ощущения такой незаконченности.
Ну иногда мне студенты задают правильный вопрос. Они говорят, вот если мат ожидания кси вот
представляется в виде интеграла Стилтьеса, все понятно. А давайте рассмотрим случайную
личину это, которая есть фи от кси. Тогда мат ожидания это как бы по аналогии это фи от х df кси от х,
но с другой стороны у случайной личины это своя же функция распределения и абсолютно по
определению мат ожидания это равно интегралу у df это от у. А эти величины вообще совпадают.
Корректно ли наше определение? Ну честно говоря, конечно, ну я бы был очень удивлен,
если бы получались разные результаты, потому что ну здесь как бы такие довольно, так сказать,
там безобидные переходы. Вот и негде спрятаться. Но тем не менее формально вопрос такой возникает.
Ну и давайте мы это один раз сделаем. Для дискретных случайных величин.
Или другими словами, для простых функций в смысле интеграла Либега. Ну давайте пишем,
значит пусть это у нас случайная величина, которая определяется набором вот таких вероятностей,
это равно у gt, а кси случайная величина дискретная, которая определяется набором вероятностей,
кси равно хк. Ну в счетном количестве в общем случае. Ну и давайте напишем мат ожидания это.
По определению это сумма у gt на вероятность того, что это равна у gt. Сумма по g равно сумма по g,
у gt. А вот эту вероятность мы представим вот в таком виде. Сумма вероятностей того,
что кси равно хк, где суммирование по таким индексам k, что фи от хк равно у gt. Правильно,
да? Это равняется у gt, этот это на самом деле фи от кси. Для того, чтобы она равнялась у gt,
вот эти хк каким-то значением должны равняться. Может одному, может несколько. Вот значит равно
сумма по g, а здесь я напишу сумму пока вот по таким же самым фи от хк равно у gt, фи от хк
на вероятность того, что кси равно хк. Правильно, да? Вот это у gt вношу в эту сумму,
поскольку оно для этих слагаемых всегда одно и то же. Ну и заменяю на фи хк,
которое внутри этой суммы равно у gt. Ну и видно, что это просто перестановка членов вот такого ряда.
Сумма фи хк на вероятность того, что кси равно хк или в наших обозначениях математическое ожидание
фи от кси. Математическое ожидание фи от кси. Я напомню вам, что интеграл Лебега обладает тем
свойством, что интеграл от функции и интеграл от модуля функции одновременно существует или
не существует. Поэтому те ряды, то есть если мат ожидания существует, это означает, что соответствующие
ряды для дискретных случайных величин не просто сходятся, а сходятся абсолютно. А в абсолютно
сходящемся ряде можно как угодно переставлять его члены. Вот, собственно, чем мы воспользовались.
Значит, корректность мы подтвердили. Значит, следующий важный факт. Правильно, я стер второй
закон нитона. Мы до него не дойдем сегодня. Вот, значит, следующий важный факт. Это нам надо понять.
Значит, мат ожидания суммы равно сумме мат ожиданий всегда. А вот мат ожидания произведения,
когда равно мат ожиданию кси умножить на мат ожидания это. Ну, на самом деле вопрос как не совсем,
как это, многогранный. Но, тем не менее, мы сейчас докажем, что это свойство выполнено для независимых
случайных величин. Независимых случайных величин. И сделаем это тоже для дискретных случайных
величин. Значит, кси определяется вероятностями кси равно хкт. Это определяется вероятностями
это равно ygt. И z, которая есть кси на это случайная величина, она определяется какими-то вероятностями
z равно zlt. Ну и давайте писать. Мат ожидания z равно сумма zlt на вероятность того, что z
равно zlt. Сумма по l. Слушайте, я вот опущу, надеюсь, что, ну, напишу и как-то там поясню на
словах, если будет непонятно. На самом деле это ничто иное, как двойная сумма по k и по i, по g,
хкт на ygt на вероятность того, что кси равно хкт и одновременно с этим это равно ygt. Вот это понятно?
То есть, ну, если какой-то g, точнее, какой-то z, значит он представим в виде суммы. Ну вот,
по той же логике мы можем выбрать все такие пары, записать вот эту вероятность как сумму
вероятностей, внести сюда, в общем, ну, пройти ту же логику и получить вот такую штуку. Но поскольку
кси и это независимо, то вот эта вероятность распадается в произведение вероятностей. Это
свойство, на которое мы обращали внимание. И тогда все это просто распадается в произведение двух
сумм хкт на вероятность того, что кси равно хкт, умножить на сумму ygt на вероятность того,
что это равно ygt. То есть, математическое ожидание кси умножить на математическое ожидание это.
Вот такое, ну, важное свойство. То есть, математическое ожидание произведения
случайных величин, независимых случайных величин равно произведению математических ожиданий.
Ну и давайте тут некий промежуточный итог подведем, связанный с независимостью.
Ну, во-первых, напоминаю, что кавариация двух случайных величин равна мат ожидания кси
это минус мат ожидания кси умножить на мат ожидания это. Смотрим вот сюда. И тогда получается,
что возникают вот такие связи. Кси это независимо. Тогда математическое ожидание кси на это равно
математическому ожиданию кси умножить на мат ожидания это. Это утверждение в обе стороны
эквивалентно тому, что кавариация кси это равно нулю. Ну и если кси это независимое,
то кавариация, опять же, так сказать, равна нулю. Обратное не верно. То есть, если кавариация равна
нулю, то не следует независимость кси и это. Но есть один чрезвычайно важный истерический
с практической точки зрения пример, когда из некоррелированности компонент случайного вектора
следует их независимость. Это нормальный случайный вектор. Мы не успеем сегодня им заняться,
но там продолжим в следующий раз. Ну и в следующий раз докажем второй закон Ньютона
для теории вероятности. Все коллеги, давайте отдыхайте. Спасибо.
