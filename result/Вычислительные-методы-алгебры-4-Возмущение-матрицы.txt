Вот такой вопрос. Значит, вот есть такая вот матрица. Я рисовал такую матрицу и в прошлый раз,
но зачем скобки поставил непонятно. Значит, вот этот вектор столбец У имеет длину,
эвкалидовую длину единица. Значит, вот эта матрица называется матрица отражения.
Ну почему? Вот если вы на У умножаете ее, то что получается? Давайте я буквой П обозначу.
Вот ПУ это что такое? Ну ответ скажите. У минус 2У это что получится? Минус У. Вот,
а если возьмете любой вектор, ахтагональный У, то что будет ПВ?
Вот девушка, вы отвлеклись. От вас ответ ожидаю. Вот на эту матрицу умножили. Ну,
звездой на У это что такое? Единица, правильно? Поскольку У имеет длину единицы. Ну вот девушка
сказала У минус 2У получается. Это минус У. А вот теперь возьмем вектор В, ахтагональный У.
А что так долго думаете? Ну ладно, хоть правильно сказали. Думали долго и сказали неправильно.
Ребят, вы к автомату точно не готовы. Ну может быть, а вы что, гадаете или увидели, что ноль?
Ну правильно. У со звездой на В это что такое будет, раз они ахтагональны у В? Ну дальше В плюс ноль это что будет?
Значит ПВ это будет что такое? В, а не ноль. Все-таки В. Поэтому и называется матрица отражения.
Потому что вот множество таких В это что такое? Это гиперплоска, правильно? Да я не помню, что вы сказали.
Значит гиперплоскость. Ну вот и получается, что все векторы на этой гиперплоскости остаются на месте.
Вот здесь вот я нолик нарисую. Ноль принадлежит, конечно. Все векторы на этой гиперплоске остаются на
месте, а все векторы, которые не... Что можно сделать? Каждый можно разложить. Значит проекция
артагональная на этой гиперплоскости плюс перпендикуляр. Такая проекция останется на месте, правильно,
при действии П, а перпендикуляр перейдет в минус. То есть вот этот вектор отразится симметрично относительно
этой гиперплоскости, потому что размер всего на единичку меньше. Понятно, да? Геометрическое действие.
Понятно. Значит я вот утверждаю, что вот эта матрица является какой? Что о ней можно сказать? Интересно.
Она является ванитарной. Она еще, кстати, является эрмитовой. Она и эрмитовая является тоже.
То есть она является эрмитовой и она является... Ну, эрмитовая очевидна, да? Самое сопряжение.
Но она и к тому же еще является унитарной. Вот это, я думаю, для вас сложная задача. Проверить унитарно.
Чего смеетесь?
Ах, даже вот это у вас. Она комплексная, с комплексным сопряжением. Ну, давайте, вот как
берется, вот П со звездой. То есть даже это надо... Давайте посчитаем. Да, молодцы. Вот дальше двоечка.
А дальше вот это вот будет... Ну да, накладываем. Значит это будет У со звездой. Получилось? Получилось то же самое.
Эрмитовость. Ну, эрмитовость означает, кстати говоря, что все собственные значения вещественные на любой эрмитовой матрице.
Ну, кстати, а мы уже собственные значения... Вот еще вам один вопрос. Какие собственные значения этой матрицы?
Идинечки, минус идинечки. Идинечка какой кратности? 1. Н минус 1. А минус единичка кратности 1.
Все ясно. Даже и собственные векторы понятны. Какие? Где они? Вот на этой гиперплоскости нюлевые векторы.
Это собственные векторы, которые отвечают собственному значению единицы. А вот ортогональный вектор, нормаль в гиперплоскости,
Собственный вектор для собственного вращения минус 1.
Ну ладно, это хорошо, но эта массовица еще и унитарная, а как унитарность-то проверить?
Ну надо взять и П умножить на П со звездой, правильно?
Ну мы уже знаем, что со звездой это П.
Выполнить вот такое вот вычисление.
Так, и что?
Ну считать надо.
1 минус 4 у со звездой, правильно?
Сейчас, ну минус 2, минус 2, 4 и плюс 4 у со звездой, да?
Потому что у со звездой, у на у со звездой, у на у со звездой.
Вот здесь вот скобочки мы поставим в серединке.
У со звездой на у даст число единицы.
Увидели?
Все увидели.
Кто-нибудь не увидел?
Ну тот, кто не увидел, может просто идти домой сразу.
Единица получилась.
Но это шутка какая, шутка какая, добрая шутка.
Ничего злого я не хочу.
Вам предлагаю.
Вот.
Нет, ну физтеха-то классно, но и за пределами физтеха жизни много.
Так, ладно.
А вот теперь.
Я как-то задержался на этом и хотел спросить вас совсем на другом.
Вот мы в конце прошлой лекции
обсуждали вот проблему с применением метода Гаусса.
Проблема, да?
Рост элементов возможен.
Если ведущий элемент маленький, то
будет рост элементов, а большой рост элементов
влечет за собой неприятные ошибки округления
и погрешности в ответе.
И значит я вам сказал, что можно рост элементов избежать
в принципе, если исключение проводить
с помощью унитарных преобразований.
То есть умножать на унитарную матрицу специального вида.
В веществном случае это мог быть матрица вращения.
В общем случае можно и матрицу отражения применять.
То есть с помощью...
Что ж такое?
Это тоже вот так вот сделаем.
С помощью матрицы отражения
тоже можно получать нули.
Ну как получать нули с помощью матрицы отражения?
Ну вот как я могу один вектор перевести другой
с помощью матрицы отражения?
Ну, наверное, надо провести вот такую гиперплоску.
И сделать так, чтобы нормалью было вот как раз вот это направление.
Поэтому я один вектор в другой.
Вообще говоря, могу переводить с помощью отражения.
А вот теперь вопрос.
Могу ли я подобрать матрицу отражения?
Ну, после вот с такой ситуацией.
Вот здесь вот 1, 1, 1.
А здесь 1, 0, 0.
Значит вот.
Существует ли такая матрица отражения?
Вот вам вопрос.
Отличный ответ.
Молодцы.
Ну слушайте, ну я просто счастлив.
Дело в том, это такая существенная вещь.
Она у нас уже возникала вроде бы.
При умножении на матрицу унитарную сохраняется длина.
Вот сохраняется длина.
Поэтому вот если я здесь корень из трех поставлю,
такой матрица отражения найти можно.
Ну и кстати вам задача, как реально ее выписать.
Геометрическую картинку я нарисовал.
Вот подумайте, как реально это делать.
И вот действительно, посмотрите.
Внимательно уже сами.
С помощью матрицы отражения можно в первом столбце получить нули.
Так же, как вот метод Гауса действовал.
Но только это делать с помощью выбора вот этого вектора О.
Ну а если вы умножаете на матрицу отражения,
рост элементов принципиально отсутствует.
Потому что длина сохраняется.
То есть есть существенные ограничения.
Ну а мы с вами дальше пойдем.
Значит вот мы поняли, что ошибки,
по крайней мере ошибки округления,
влекут за собой погрешности в ответе.
Вот.
Но не только ошибки округления.
Ведь еще и такая может быть ситуация.
Вот матрица и правая часть пришли к нам
из каких-нибудь измерений или вычислений.
А значит они на самом деле тоже неточны.
И вот эта неточность в исходных данных
будет означать, что мы, ответ,
даже если мы точно получим решение системы,
для той задачи, для которой эта система появлялась,
это будет уже ответ с погрешностью.
То есть о чем же здесь идет речь?
Речь о возмущениях.
Прежде всего, малых возмущениях.
Как влияют малые возмущения на ответ?
Этот вопрос важен при решении любых задач,
безусловно.
Ну и, конечно, для задач вычислительной алкебры
важно разобраться в этом.
Вот давайте мы попробуем ровно этим позаниматься.
Значит, вот есть, будем считать,
невырожденная матрица А, есть правая часть В,
вектор Х решения, однозначно определенная в данном случае.
И вот возмутилась матрица,
а затем возмутилась правая часть или одновременно.
Значит, вместо А нам дали матрицу А плюс дельта А,
вместо В дали матрицу В плюс дельта В,
и мы начали решать систему,
и получили возмущенное решение.
Кое-что можно сразу сказать.
Если возмущение малы для матрицы,
то возмущенная система тоже будет иметь единственное решение.
Правильно, из непрерывности определителя.
Действительно, определитель был не нулевой при малых возмущениях,
он таким останется, поэтому матрица А плюс дельта
останется невырожденной, а нас интересуют малые возмущения.
Значит, вот здесь дельта Х будет определено однозначно.
Но нас интересует, насколько большим может быть дельта Х.
На языке математического анализа
речь идет о том, чтобы взять производные.
Вот первого порядка возмущения,
чтобы их влияние оценить в анализе производной.
Фактически это бы надо сделать, но мы не будем использовать
никакие дифференцирования здесь.
Вот это есть уравнение для дельта Х, конечно же.
Ну давайте напишем, что здесь получается.
А умножить на дельта Х.
Аа умножить на дельта Х.
Это есть минус А.
Минус, извините, дельта А.
Ясно, что АХ и Б сократить можно.
Я это с удовольствием сделаю.
Есть минус дельта А умножить на Х.
Здесь есть дельта В.
И здесь еще будет минус дельта А умножить на дельта Х.
Правильно?
Матрица не вырожденная,
поэтому можем дельта Х отсюда получить.
То есть минус А в минус 1.
Дельта А.
Чего?
Ну есть и что.
Ну есть пока.
Ничего страшного.
Это верное равенство, правда же.
Пока я на Х, да?
Плюс А в минус 1 на дельта В.
Минус А в минус 1 на дельта А.
На дельта Х.
Все честно пока.
Ну я не намерен дальше обманывать, но всякое может случиться. Вы следите.
Так.
Давайте норму возьмем.
А про норму вы знаете, есть неравенство треугольника.
Норма суммы меньше или равна сумма нормы.
Вот мы это неравенство употребим.
Значит меньше или равно.
Здесь норма А в минус 1.
Норма дельта А.
Вы поймете зачем.
Вот такое число я выделю.
А здесь напишу дельта А поделить на норму Х.
Это я пока вот с первым членом в этой сумме.
Его норму оценил сверху.
Дальше.
Второй член. Значит вот с этим справились.
Смотрите, что я сделаю.
Я напишу вот так вот.
Дальше я напишу.
Дельта В поделить на норму В.
Ну поделил, раз поделил, надо и умножить.
Ну что такое В?
А В это АХ.
Значит вот так вот.
Ну чтобы было так хорошо.
Я здесь напишу. А сюда поставлю.
Здесь тоже скобочку.
В общем.
Как-то все ухудшается.
Да.
Ну норма произведения сверху оценивается.
Мы пишем не нравится.
Вот так вот. И это мы расправились со вторым членом.
Ну есть еще вот один.
А минус первый.
Ну здесь мы тоже вот так вот напишем.
Вот так вот.
И здесь напишем норму Дельта Х.
Нормально?
А вот вы знаете, что
Не, не буду так писать.
Не нравится мне так.
Ну я написал все правильно.
Ну я так передумал.
Передумал.
Напишем. Вот как.
Напишем здесь просто норму.
А я напишу.
Вообще не буду мудрить.
Нормально?
Все правильно.
Отсюда сразу возникает
результат.
Норма Дельта Х поделить на норму Х.
А это есть относительное возмущение решения.
Меньше или равна.
Чем вот это произведение.
Вот.
Его надо поделить еще.
А минус. Норма А минус первый на Дельта А.
Вот отсюда.
Увидели?
Ну если Дельта А маленькая, то и вот эта норма маленькая.
Ну при достаточно малых норме возмущения матрицы
от единички будет вычитаться что-то малое.
А здесь есть
относительное возмущение матрицы
плюс относительное возмущение
правой части.
Вот такая чудесная формула получилась.
То есть мы для невырожденной матрицы
оценили относительную погрешность
возмущенного решения через относительные погрешности
возмущения матрицы и правой части.
Вот коэффициент. Ну знаменатель при малых возмущениях
можно считать близким к единице.
Значит главную здесь роль играет вот этот самый
коэффициент. Он имеет название.
Называется число об условленности
матрицы А.
Матрицы А.
Встречалась вам? Нет?
Ещё появилась у нас такая числа
число об условности матрицы А. Но мы видим, что зависит оно
ещё от нормы. Не только от матрицы, но и от той нормы,
в которую мы применяем.
Норма требовалась. Ну вот такая мультипликативность требовалась.
Это должна быть норма. Норма произведения матрицы
должна быть меньше или равна произведению норм. Вот это требовалось.
А больше вот ничего нам не нужно от нормы.
То есть любую такую норму можно применять. То есть это может быть норма спектральная.
Вот это может быть
норма ещё какая-нибудь.
Всё правильно.
Что можно сказать о числе об условленности? Оно больше или равно чего?
Оно больше или равно единицы?
Любой матричный норма, оно больше или равно единицы. Так вот, принято
говорить, если число об условленности большое, ну, большое это дело
вкуса, конечно. Хотя вкуса.
Вот посмотрите. Вот у вас, допустим,
возбуждение с точностью 10 в минус 12 на машине выполняется.
А число об условленности, например, 10 в 12.
Вывод какой?
Да. То есть чтобы
в ответе было хоть что-то
в возбуждённом решении было хоть что-то
от искового решения нужно, чтобы
возбуждения были очень малые, даже меньше, чем машинные возбуждения.
Вот проблемка, кстати.
Проблемка.
Так что довольно такая важная
оценка. Значит,
если вы знаете сингулярное разложение матрицы А,
то число об условности в данном случае
говорят о спектральном числе об условленности.
Спектральное число об условности – это число об условности, которое вычисляется
со спектральной нормой.
Значит, как связано с сингулярными числами?
Спектральное число
об условенности.
Ну, вот мы так обозначаем.
Ну, чему равно-то?
Правильно, максимальное сингулярное число
в матрице поделить на минимальное?
Ну, потому что для обратной матрицы
сингулярное число – это обратное.
Где-то должно быть. А вот где? А всё равно где, правда же?
Значит, вот
заметим, что есть связь с сингулярным разложением.
И что я приглашаю вас сделать?
Вот эта оценка, которой мы получились,
её улучшить нельзя.
Её улучшить нельзя.
Ну что, значит,
вот для любой матрицы можно подобрать правую часть и возмущение,
так, что будет достигаться.
Ну, возмущение уровня, возмущение задачи,
а вот сами возмущения матрицы и вектор
можно подобрать так, что будет достигаться.
То, что здесь написано. Всё, вот такой вот результат.
Правую часть и возмущение подобрать так, чтобы что было?
Чтобы здесь равенство было.
Вместе с занимателем или без занимателем?
Вместе, вместе.
Ну, в принципе, вы даже можете лишь правую часть возмущить.
Подобрать, ну, сказать, пусть, да, равенство.
Вы можете подобрать правую часть и возмущение правой части так, что получится равенство.
Так это означает,
что улучшить её так вот на всём классе возможности нельзя.
В отдельных частных случаях, да.
Ну, это какие-то должны возникать дополнительные предположения
относительно матрицы и правой части.
Вот.
Ну, давайте, раз уж начали говорить о теории возмущения,
ну, давайте продолжим в этом направлении сегодня разговор.
Понятно, что это важная вещь, уметь оценивать влияние возмущения.
Вот мы понимаем, что будет происходить с решением системы.
Вот это единичная матрица, да.
И давайте прибавим что-то маленькое.
Матрица останется обратимой, если достаточно малое возмущение.
Можно ли формулу написать?
Можно. Можно. Вот смотрите как.
Давайте я вот что сделаю. Вот эту матрицу.
Ну, вы правильно говорите.
Формулу написать можно.
Вот такую единица, минус f, плюс f в квадрате,
минус f в кубе, ряд.
Значит, ряд, ну, можно
написать ряд, пока от 0 до бесконечности,
минус f в степени k.
Вы спросите, что такое ряд?
Ну, что такое числовой ряд, скорее всего, вы уже знаете.
А ряд из матрицы.
Ну, вот ряд из матрицы тоже не вызывает проблем.
Надо взять частичную сумму и требовать, чтобы был предел частичных сумм.
Вот. Прекрасно. Значит, я вот утверждаю,
что если
матричная норма f строго меньше единицы,
даже не обязательно очень мала, но строго меньше единицы,
то при таком возмущении
вот этот ряд сходится и будет иметь формула для обратной матрицы,
такая, как написано.
Ряд этот имеет название.
Называется он ряд Неймана.
Утверждение степа таких почти очевидных.
Проведается очень легко. Ну, что надо сделать?
Давайте частичную сумму рассмотрим.
Ну, до m, да?
И умножим ее.
И умножим ее
вот на такую матрицу.
Ну, не знаю.
Чуть-чуть жизнь проще.
Или не надо тут ничего.
Вот что будет минус.
То есть, когда вы честно перемножите,
у вас много чего сократится,
останется только самый первый и самый последний
члены, которые не сократятся.
А дальше что понятно? Что вот эта матрица стремится к единичной.
Эта матрица стремится к единичной,
ну и отсюда понятно, что этот ряд сходится
и сходится к обратной матрице.
Вот и все. Рассуждение.
Значит, вот это очень полезная вещь, говорят Неймана,
при работе, при исследовании малых возмущений.
Да, надо стирать.
Это очень полезная вещь, говорят Неймана,
при работе, при исследовании малых возмущений.
Это очень полезная вещь, говорят Неймана,
при работе, при исследовании малых возмущений.
Это очень полезная вещь, говорят Неймана,
при работе, при исследовании малых возмущений.
На всякий случай их здесь, думаю, сотру.
Да, пожалуйста.
Мы уже проверили.
Взяли частичную слугу.
Умножили на вагон.
Умножили на вагон.
Умножили на матрицу.
Получили единичные матрицы минус f в степени.
И все, а дальше, как угадали,
мы написали этот ряд и проверили.
Отсюда возникает сходимость. И, собственно, и формула.
Теперь давайте еще про собственные значения,
что с ними происходит при малых возмущениях.
Вот этот вопрос под ними.
Ну, я начну вот с чего.
Знаете или его нет, но знать это полезно.
Один из результатов вычислительной линейной алгебры,
знаменитый, совершенно простой, кстати.
В 30-х годах прошлого века полученный.
Значит, вот матрица
с элементами
вот такими.
И рассмотрим вот такие круги
на комплексной плоскости.
Значит, модуль z минус a и i
это диагональный элемент в позиции,
в этой позиции, на главной диагонали.
Это центр, значит, будет этого круга.
Радиус будет сумма.
Радиус будет сумма
элементов в этой строке,
модуля элементов этой строки, кроме диагонального.
Это будет радиус.
Значит, сколько-то здесь вот
образуется n кругов. Вот таких вот.
Значит, эти круги называются кругами Гершгорина.
Круги Гершгорина.
Это наш ленинградский математик,
который оставил обессмерта
своими кругами, и это было признано
во всем мире удивительно в 30-е годы.
И умер очень молодым, к сожалению.
Значит, круги Гершгорина.
А чем они интересны?
Теорема Гершгорина.
Все собственные значения
матрицы, все они
принадлежат объединению кругов Гершгорина.
Вот такой вот област.
Все собственные значения матрицы принадлежат объединению кругов Гершгорина.
Значит, доказывается, это довольно просто.
Вот.
Значит, если лямбда собственное значение,
то это что значит? Значит, есть и собственный вектор.
Вот a1,1 минус лямбда
на x1 плюс a1,2
на x2 плюс и так далее
a1,1. Это b1.
Это 0, да?
То есть есть не нулевой вектор, который...
Вот такие вот соотношения. Здесь a1,1
a1,2 на x2
плюс a1,1 минус лямбда
на x1. Это 0.
Собственный вектор является решением однородной системы такого вида,
нетривиального решения.
А матрица коэффициентов должна быть выращена.
Ну, давайте возьмем здесь
вот вектор среди координат собственного вектора,
возьмем максимальную по модулю.
Пусть она будет i,t.
Вот i,t, пусть она будет максимальная.
Максимальная.
И возьмем i,t-уравнение.
Возьмем i,t-уравнение.
Но i,t-уравнение как можно переписать?
a i,t минус лямбда
на x i,t равняется минус сумма
и i,t равняется минус сумма
Вот так вот.
Вот перейдем к модулям
и применим неравенство треугольника.
Здесь будет модуль комплексного числа
вот такого на модуль.
Вот здесь 2i категорически не надо было писать.
Один из них надо уничтожить.
x i,t.
Ну а здесь, поскольку неравенство треугольника
здесь я должен написать
модуль x i,t.
У x i,t меньше, чем у x i,t по модуле.
А сейчас здесь x i,t и напишу, и на x i,t сокращу.
И получилось что? То, что нужно.
Получилось, что лямбда принадлежит этому кругу.
Вот и все доказательство.
Это эффективно.
Легко применять.
Ну мы же не знаем какому i,t ему.
Чтобы это понять, надо найти собственный вектор, взять максимальную компонент.
Может быть оно не одному кругу Герсгорина принадлежит, а несколькому.
Хороший вопрос.
Мы сейчас доказали это. Иногда называют первой теоремой Герсгорина.
Ну если есть первая теорема, то логично, что есть и вторая.
А можно их в одну теорему объединить.
Вот смотрите, вторая теорема Герсгорина вот какая.
Если какие-то круги Герсгорина
изолированы от остальных кругов Герсгорина.
Вот допустим, если s кругов Герсгорина изолирована
от оставшихся минус s кругов Герсгорина,
то вот это объединение s кругов Герсгорина содержит
ровно s собственных значений. Ну и, конечно, оставшиеся
областью содержат n минус s собственных значений, с учетом кратности.
С учетом кратности еще. Вот это есть вторая теорема Герсгорина.
Не знаю, вы на слуху восприняли.
Что значит изолированная круга?
Две области не пересекаются.
Две области не пересекаются. Ну давайте и вот эту вторую
теорему Герсгорина тоже докажем. Она важная,
потому что если, допустим, вот вы видите матрицу,
вот у нее на диагонали какие-то числа,
а в строчках меньшее число.
И так получилось, что действительно круги
n не пересекающихся кругов Герсгорина.
Тогда из второй теоремы Герсгорина сразу следует, что есть n
собственных значений, да, попарно различных.
Каждый в своем круге Герсгорина.
Но это содержание уже второй теоремы. Более тонкая.
Ну, давайте.
Можно.
Так, значит, вторая теорема Герсгорина.
Вот пусть давайте
введу две области.
Вот пусть s кругов. Для определенности,
какая разница, пусть в первой круге Герсгорина.
Вот, а гамма-штрих, скажем,
это оставшиеся.
И предположим, что гамма
и гамма-штрих
написал ровно не то, что хотел
сказать, да.
То есть через пустое множество.
Тогда
гамма содержит ровно
s собственных значений матрицы.
Собственных значений матрицы. С учетом карты.
Ну, а гамма-штрих, естественно, н минусы.
Потому что для гамма-штрих то же самое уверено, что и для гамма.
Значит, вот такая теорема.
Вот, ну, она немножко уже посложнее.
Она немножко посложнее.
Доказывается вот как.
Давайте через d обозначим
главную диагональ матрица. То есть это
матрица такого же размера как а.
Ну, в ней только одна главная диагональ
заимствованного матрица, основной элемент нулевый.
Вот d диагональный матриц.
Вот. И рассмотрим вот такое семейство
матриц. А от t это будет
d плюс t умножить
на а минус d.
t будет меняться от нуля до единицы.
Такая интересная идея.
Значит, от нуля это что такое?
А от единицы?
А от единицы.
Значит,
значит,
для матрицы d утверждение очевидно.
Правда же?
Для матрицы d утверждение очевидно.
Вот.
И вот каким-то образом вот можно
из вот этого
наблюдая за этим семейством от t и опираясь
на некоторую непрерывность. Вот что это за непрерывность?
Вот можно показать, что
и для всех матрица от t это утверждение будет верным.
Ну, давайте посмотрим, какие круги Гержгорина.
Ну, естественно, здесь вот возникает гамма ита от t.
Очевидно.
То, что я сейчас написал. Или не очевидно?
Ну, очевидно.
Конечно, там t меньше единицы.
Когда t равно единицам, большой радиус получается.
А центр-то те же самые.
Вот это мы имеем. Значит, мы можем рассмотреть теперь
гамма от t как раз объединение
кругов для матрицы от t
и гамма штрих от t
ну, по-прежнему перечтение пустое.
Правильно? Для каждого t.
Вот. А теперь такой факт, который полезен
знать относительно корней многочлена.
Относительно корней многочлена.
Теорема
о непрерывной зависимости
корней многочлена
от коэффициентов.
Еще вот, рассмотрим
некоторый многочлен.
Многочлен со старшим коэффициентом единицы.
Такими нарочами называю приведенными.
В западной литературе хорошие слова есть
«моник». Ну, а как его перевести?
«Монический».
Ну, нет такого в русском языке слова. Нормированные
разные бывают.
Приведенными. То есть это всего лишь означает
я написал x, да? Ну, пускай
x в n степени
плюс
а n-1 на x
так n-1 плюс a0.
И рассмотрим
семейству приведенных многочленов.
Тоже в степени n.
Здесь k надо ставить.
Что?
А, да, да.
И предположим,
что f' от x сходится к f от x.
Для каждого x. Но если для каждого x это что означает?
Значит, коэффициенты соответствующие сходятся.
То есть для каждой последствия коэффициентов
при степени какой-то сходится
коэффициенту многочлена f от x при той же степени.
Вот что означает последствия многочленов приведенных,
сходится к приведенному многочлену степени.
Заранее скажем, что степени одинаковые.
И вот тогда
корни...
Вот что сделать. Выберем произвольную нумерацию корней
предельного многочлена.
Это, вообще говоря, комплексные числа.
Но можно их нумеровать произвольно.
Я могу с учетом этой нумерации
сразу и написать
вот такую форму.
То есть x ты и фиксировали для f от x.
А дальше я вот утверждаю.
Для каждого k существует нумерация корней.
Такая, что
будут иметь вот место, такие предельные соотношения.
То есть корни многочленов и последствия
для каждого своя нумерация можно перенумеровать так, что
корни будут сходиться к корням приведенного многочлена.
Вот это одно из выражений факта непрерывной зависимости
корней многочлена от коэффициентов.
Комплексного многочлена. Наверное, вам сообщали об основной теории
на алгебре.
Нет, вы хотите сказать, что это очевидное утверждение?
Оно, кстати, не сложное.
Кстати, не сложное, но все-таки доказательство требуется.
Нет, сходится в обычном смысле, как вас учили.
Последователь комплексных чисел сходится к какому-то комплексному числу.
Значит, разность, модуль разности сходится к нему.
Ну, как эта теорема доказывается?
Хотите?
А факт фундаментальный.
Многочлены встречаются в жизни практически.
И корни.
Да?
Естественно, к.
Нет, для любого к вы выбираете нумерацию.
И это определяет у вас сходность.
Ну, как это?
Для любого к вы выбираете нумерацию.
И это определяет у вас...
Ну, корни предназначены, но нумеровать их можно по-разному.
Вот.
Если приказ сходится бесконечно.
Ну, как тут рассуждать?
Вот.
Вот.
Давайте я не знаю, какие там корни.
Сейчас я напишу вот так вот.
Вот я для конкретного к взял
многочлены и считаю, что это корни
затытые к корне катового многочлена.
Как-то занумерованные.
Пока все равно как.
Вот, и возьму какой-нибудь корень эксытый.
Эксытый корень предельного многочлена.
Значит, что будет?
Экситая минус ZYT.
Правильно?
Очевидно.
Подождите, подождите.
Вот, а теперь возьмем модуль.
А модуль произведения есть произведение модуля.
Спасибо.
Это начинала глупость получаться.
Нет, это фиксировано.
Конечно, один мы корень взяли какой-то.
Корень Альфа, да?
И значит, здесь...
Вот.
И значит, здесь X Альфа.
И это есть произведение вот этих модулей.
Но если мы здесь самый маленький модуль возьмем.
То есть найдем Z такое, что
X Альфа минус Z самый маленький.
Тогда получится нерадость. Правильно?
Вот такое.
Вот здесь я извлеку коренную степень.
Здесь будет X Альфа минус...
Вот какой-то Z.
Среди ZYT это такой Z,
что модуль X Альфа минус Z самый маленький.
Тогда возник вот такой нерадость. Правильно?
Значит, именно этот корень...
Ну, тут...
А зачем я взял, кстати, Альфа, да?
Зачем я взял Альфа-то?
Я возьму единичку. Первый корень.
Чтобы я так начал мудрее. Первый корень.
Да.
Вот. А вот пусть Альфа это тот самый номер
для Z.
И я теперь... Вот принцип мой. Вот что я поставлю в соответствии
первому корню. То есть вот этот корень Z Альфа
будет у меня
X к...
А наоборот у меня, да?
X1 к будет.
Будет у меня первый корень.
Да.
Ближайший к X1.
То есть вот я знаю, какой принцип здесь.
Я не выбрал номерацию для остальных корней пока.
Но вот здесь... Первый корень я точно
выбрал. Пусть вот он всегда такой.
Теперь устремляем как в бесконечности.
Устремиться к нулю. Что и нужно, да?
Что и нужно.
Вот. То есть я могу теперь сказать...
Вот мы что доказали с вами. Есть номерация такая, что
X1 стремится к первому корню. X1 к стремится
к X1. Это есть.
А дальше что делать? А дальше рассмотреть
вот такой многочлен.
Это многочлен.
И вот такие многочлены.
1 к, да?
И это многочлены.
И заметим...
То есть по-прежнему приведенные многочлены.
Но степень на единичку меньше.
И вот теперь мы для второго корня выберем ему
соответствующий. И так далее.
Вот так доказывается такой вариант теоремы
о непрерывной зависимости корней многочлена от коэффициентов.
Есть и другие выражения
непрерывной зависимости корней.
Вот. В теории функции комплексной переменной
в комплексном анализе есть некоторые замечательные теоремы
на этот счет. Вот.
Можно поднапрячься и показать, что вот корни они на непрерывных кривых
на самом-то деле. Вот когда вы меняете, если предположить, что коэффициенты
зависят от параметра, ну вот как в нашем случае от параметра t, да?
То можно сказать, что и той корень будет на и той непрерывной кривой
с параметром t. На комплексной плоскости
какая-то непрерывная кривая. И вот они так вот по этим непрерывным
кривым двигаются.
Но то, что строго мы с вами имеем,
вот что имеем, то на доске и есть.
Нам этого достаточно.
Вот. Ну а теперь
давайте рассмотрим вот такую функцию.
С от t.
С от t это будет
число
ну вот так вот. Число собственных значений
лямда этой, которые попали
в гамма от t.
Ну s от нуля это s.
Вот такая функция s от t.
Число корней. Что?
Ну вот этот вроде как диез.
Вот математическая литература довольно часто используется
как знак число, что-то подсчитать.
А что подсчитать? Число собственных значений
ну естественно от t зависящих.
Не исходные матрицы, а матрицы от t.
Которые попали вот в эту область гамма от t.
В объединении первых s кругов Герсгорина
матрица от t.
Просто гамма.
Потому что через гамму у меня обозначено вот здесь объединение,
а здесь гамма от t.
Что?
Ну потому что они как-то там.
Ну а дальше что понятно? Мы же можем
занумеровать. Предположим, что там
t стремится к t0.
t стремится к t0.
И тогда вот как-то занумеруем собственные значения
для t0, для матрицы от t0.
Мы будем считать, что первые... Нет, просто занумеруем.
Как-то так, чтобы первые s лежали
в s от t0.
Правильно? Ну а дальше
что нам теорема непрерывной зависимости корней многочисленной говорит?
И для каждого t, ну давайте считать, что tk стремится к t0.
Для каждого k мы можем найти нумерацию,
так что будут соответствующие предельные соотношения.
Но отсюда понятно, что и число корней,
что s от tk
будет стремиться к s от t0.
Потому что вот эта функция с от t непрерывная.
И значения продевает. Ну целые.
Значит, s от 0 это s.
s от t равняется s при всех t.
Значит, s равна единице. Вот всё в суде.
Нет, ну если корень кратный,
то там x1 равно x2.
Вы просто два раза пишете,
два раза считаете его. И будет x1 меньше или равно,
в нумерации меньше или равно знак.
Ну в случае равенства, если вы представляете две одинаковые вещи,
но внешне ничего не меняется.
Вот и всё здесь рассуждение, связанное со второй теоремой Гершгорина.
Но есть ещё, так сказать,
более эзотерическое знание,
если хотите,
допослещённое. Если хотите, могу вам об этом сказать.
Ну тоже вот как задача.
А вот если, вот такая картина,
а если собственное значение оказалось
на границе области Гершгорина, то есть область Гершгорина – это объединение всех кругов.
Вот если там собственное значение.
И если при этом элементы матрицы все не нулевые,
то можно доказать,
что это собственное значение принадлежит каждому кругу Гершгорина.
Вот он задача.
Ещё раз. Пусть некоторые собственные значения находятся
на границе области Гершгорина.
То есть хотя бы одному. Ну более того, не то что хотя бы одному,
оно на границе. Ровно на границе.
То есть оно не находится внутри какого-нибудь круга Гершгорина.
Нет. Оно находится на границе области Гершгорина.
И если при этом матрица имеет все не нулевые элементы,
то это собственное значение принадлежит границе каждого круга Гершгорина.
То есть все они пересекаются в этой точке.
Вот такое эзотерическое знание. Ну тут даже некоторое обобщение есть.
Ну попробуйте поразмышлять.
Так. Дальше двигаемся.
Вот. Я всё ждал. Не вызовется ли кто-то.
Сейчас как раз тот момент.
Потому что мы сейчас готовы к тому, чтобы понять,
что происходит при возмущении сотовых значений.
И зачем нам для этого
нужны круги Гершгорина, мы сейчас увидим.
Чудесный инструмент. Совершенно замечательный.
И красивый, кстати. Согласитесь.
Постой, красивый.
Нет. Ну областей разных
есть некоторое количество других
результатов локализации сотных значений не только круги Гершгорина.
То есть есть такая деятельность.
Вот.
Ну я кое-что ещё скажу.
Я вот к чему хочу перейти.
Вот как бы понять, что с сотными значениями происходит.
А давайте предположим, что сотные значения
попарно различны.
Вот такой вот случай.
Интересный.
И вот матрица А
подобна.
То есть матрица П состоит из собственных векторов.
А здесь получается
диагональная матрица
лямбда.
С попарно различными собственными значениями.
Вот. И дальше
эта матрица возмущается.
Возмущение считаем малое.
Возмущение.
Что произойдёт с собственными значениями при возмущении матрицы?
Это уже хорошее наблюдение. Можете объяснить почему?
Да. В силу теоремы о непрерывности,
о непрерывной зависимости королей многочлена
уже это.
Но есть ещё один ход мысли.
Есть ещё один ход мысли. Правда,
всё равно этот факт непрерывности,
непрерывной зависимости корней. Ну вот смотрите.
Вот это что за матрица будет?
Это лямбда
плюс П в минус 1 и Ф. Спасибо большое.
То есть смотрите. Матрица А плюс Ф
подобна вот такой матрице. Лямбда плюс что-то.
А при всех достаточно малых Ф
круги Герскорина для матрицы лямбда плюс что-то
не пересекаются.
Лямбда, Папарда различны. Правда же?
Вот.
Да, конечно.
Центры сдвигаются, но не сильно.
И радиусы мало. Всё правильно.
Вот. Ну а теорему можно написать.
Значит вот давайте я обозначу
возмущённое это собственное значение.
То есть для матрицы А плюс Ф.
Для него такая формула.
Значит лямбда и Т для матрицы А.
Исходные лямбда и Т. Плюс.
Вот здесь очень интересно.
Вот так некоторый элемент,
диагональный элемент вот этой матрицы.
Ну можно сказать, что мы эту задачу сводим
к задаче о возмущении диагональной матрицы.
Ну возмущается она так, что
то есть матрица А плюс П минус 1 ФП уже не диагональная.
Но я не всё написал.
Плюс по большое
от нормы Ф в квадрат.
Да.
То есть вот тут главный член
возмущения собственного значения.
То есть надо в матрице П минус 1 ФП
взять диагональный элемент.
Как мы понимаем какое собственное значение И?
Как мы выбираем нумерации? Нет, нумерации в исходной матрице выбраны.
Как-то они занумерованы.
А дальше мы же знаем, что при малых возмущениях
возмущённая матрица тоже будет иметь
Н различных собственных значений.
Значит вот
с ИТом будет связано ровно такое собственное значение.
Ровно одно, ровно такое.
Интересно тем, что она показывает, а что будет главным членом возмущения.
Значит как это доказывается?
Как это доказывается?
Здесь техника.
Ну это вот мы обсуждаем со мной классику.
Учислительные линейные алгебры.
Пока ещё классику.
Давайте запишем так Ф.
Запишем в виде
Эпсила, ну скажем на Фи.
Ну почему бы нет?
Эпсон положительное число.
То есть фактически
ну ладно, просто запись.
Просто запись, и вот я ещё введу обозначение
давайте Омега.
Вот такая матрица П минус первая.
Фи, ФиП.
Значит если мы на Эпсилу умножим, то будет в точности вот эта матрица
П минус первая.
Ну тут я могу так как бы мыслить, что
вот если я Фи зафиксирую, а Эпсилу будет параметром,
Эпсилу будет указывать величину возмущения.
Ну тогда у нас будет возмущение направленное вдоль
направления матрицы Фи.
Вот эта фиксированная матрица Фи будет задавать направление
возмущения.
Вот, а теперь я хочу вот что сделать.
Я хочу подобрать
две матрицы.
Х и В.
Это пока для меня неизвестные матрицы, я хочу
выбрать так, чтобы кое-что интересное получалось.
Ну, значит, начинаю выбирать.
Значит лямбда, а это
будет Эпсилу Омега.
Здесь напишу
единичное плюс
Эпсилу на Х.
Здесь
напишу вот так вот.
Здесь напишу вот так вот.
И обозначу
это через Z.
Например.
Если бы
Z равнялась нулю,
это обозначало, что матрица лямбда плюс Эпсилу на Мега подобна
этой матрице лямбда плюс Д.
Но Z
не обязательно равняется нулю.
Давайте посчитаем. Раскроем скобочки.
Раскроем скобочки.
Вот здесь лямбда и здесь лямбда сокращают.
Видели? Ну и прекрасно.
Теперь здесь будет Эпсилу.
Вот все, что будет Эпсилу, будет Эпсилу в квадрате.
Вот. Значит,
какая матрица умножается на Эпсилу?
Теперь что еще?
Плюс лямбда и экс.
Минус
х лямбда.
Ну.
Сейчас.
Да.
Давайте поставим.
Давайте поставим.
Тогда еще будет
здесь Д.
Только с минусом, да?
А то правильно сказали, я, собственно,
именно об этом и думал.
Что там нет эксилу.
Вот дальше плюс
х лямбда.
Дальше плюс Эпсилу в квадрате.
Ну Эпсилу в квадрате
Омега х минус хв.
А теперь вот что
давайте заметим. Как х и d можно выбрать?
Заведомо их можно выбрать.
Так, чтобы здесь получилась нулевая матрица.
Теперь Омега.
Теперь смотрите.
Как мы
d как выберем?
Нет, нет.
Смотрите как.
То есть сделаем d вообще диагональной.
И пусть это будет главная диагональ матрицы Омега.
Главная диагональ
матрицы Омега. Это будет d.
То есть когда мы из Омега вычтем d, на главной диагонали
матрица Омега минус d будут нули.
А теперь
а дальше вот так вот.
Давайте
потребуем следующее, чтобы
элемент вот такой матрицы
равнялся нулю.
Ну если так, то тогда.
Если мы такой выбор сможем реализовать,
то тогда в скобочке действительно получится нулевая матрица.
А реализовать мы его сможем. Почему? Ну что это означает?
Вот это равенство.
Омега и житое плюс
лямбда и итое умножить
на х и житое элемент матрицы х, да?
Минус х и житое умножить на лямбда и житое
равняется нулю. Значит надо х и житое как выбрать?
Омега и житое поделить
на лямбда и житое минус лямбда итое. Вот выбор.
Особные значения попарны различны по предположению.
Вот правильно. А тоже смотри, что получилось.
Мы с вами
получили, что z есть при таком выборе.
Значит z имеет элементы вот такие.
Ну понятно, что норма х ограничена. То есть вот эта матрица
некой ограниченной нормы, то есть действительно
порядка e в квадрате.
Порядка e в квадрате.
Ну а теперь, что же за соотношение у нас есть?
Значит из того, что мы получили, мы можем
так теперь написать.
Матрица вот эта при достаточно малых e навратима.
Значит обратно умножим.
Здесь лямбда плюс
амегда. Здесь
что было. И это есть что такое?
Это есть лямбда плюс
эпсилон d, да уже диагональная матрица.
Ну по выбору. Плюс матрица элементы,
которые есть. Ну потому что если мы матрицу с
такими элементами умножим на обратную k плюс
то это будет матрица с элементами порядка
вот e в квадрате. Почему? Потому что
ну вот можно скажем так
вот эта матрица
ну по спектральной норме например. Вот такая
оценка.
То есть понятно, что
при малых эпсилонах вообще ограничено, останутся элементы порядка вот
эпсилон в квадрате. А вот теперь в замечательной круге Гершгорина
опять смотрим, вот где диагональные элементы.
Вот они. Круги не пересекаются.
Радиус порядка эпсилон в квадрате.
Теорема доказывает.
Теорема доказывает.
А d это как раз и есть.
То есть вот это все вместе
это и есть
вот этот самый элемент.
Почему теорема доказывает?
Потому что эпсилон на d это вот в точности вот тот самый элемент.
D это матрица?
Что? D это диагональная матрица.
Ну извините.
D диагональная матрица.
То есть ее диагональный элемент в точности и диагональный элемент матрицы
p-1fp.
По построению.
Значит вот смотрите. Вот этот член есть. Вот эпсилон в квадрате.
Матрица с таким. И умножаем мы ее на какую матрицу?
Идеичная плюс эпсилон х в минус 1.
Вот оценка для норма.
На того, на что мы умножаем. Значит останется матрица с элементами вот эпсилон в квадрате.
Вот и все.
Вот и все. Вот теперь сюда смотрим.
Применяем теорему Гершгорина напрямую.
Значит вот центры, вот радиусы.
И возникает вот таким образом оценка.
Ну что? Время подошло к концу.
Время подошло к концу.
Ну на самом деле, вот тут можно и понять,
что это за величины-то такие будут.
Что это за величины такие будут?
Вот эти величины определяют чувствительность собственного значения к малому возмущению.
То есть для каждого собственного значения есть свой коэффициент,
свое число об условленности можно так сказать.
Число об условленности собственного значения.
Ну на самом-то деле, вот можно сказать, что это есть в точности,
Вот если возьмете собственный вектор для собственного значения λt,
ну и ты столбец матрицы собственных векторов, возьмете обратную матрицу,
и там и ту строчку возьмете. Вот произведение норм этой.
А в строчке будут так называемые левые собственные значения,
левые собственные векторы.
Ну это собственный вектор конспонированной матрицы.
То есть норма правого собственного вектора умножить на норму левого,
это и будет вот эта самая d и t.
Вот то, что удалось получить.
Ну ладно, теперь давайте остановимся.
