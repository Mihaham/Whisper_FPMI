Добрый день, мы продолжаем разбираться с тем, какие свойства есть у инварианта подпространств.
Напоминаю на всякий случай, что если у вас есть линейный оператор, давайте определение напомним,
то подпространства инварианта это означает, что вверху содержится ванку.
И вот такие подпространства мы с вами изучаем.
И вот утверждение, которое нам в важном, частном случае в последствии окажется очень полезным такое.
Так пусть у нас есть на сей раз два линейных оператора phi и psi на одном и том же пространстве v,
два линейных для образования этого пространства, причем эти операторы галнукируют.
То есть их композиция не зависит от порядка, в котором мы ее берем.
Phi-Psi это то же самое, что Psi-Phi.
Тогда оказывается, что образ Psi и ядро Psi второго оператора инвариантное относительно phi.
То есть если вы для оператора phi найдете какой-то Psi, который с ним коммутирует,
то его образ и ядро окажутся обязательно инвариантными относительно нашего phi.
Таким образом мы можем пополнять запас инвариантных относительно phi пространств.
В каком важном частном случае нам это в последствии придется применять я скажу чуть попозже,
а пока давайте мы докажем вот это вот общее утверждение.
Ну что нам нужно проверить, давайте смотреть.
Давайте разбираться с образом Psi.
Нам нужно проверить следующий факт, что если вектор U лежит в образе Psi,
то phi от него тоже лежит в этом самом образе, правильно?
Давайте мы возьмем какой-нибудь вектор из образа.
Ну что означает, что он лежит в образе?
Это означает, что U это Psi от какого-то другого вектора, ну может быть другого вектора A,
из нашего пространства.
Ну давайте смотреть, что тогда такое будет phi от U.
Нас интересует, чтобы он тоже попал в образ Psi.
Ну а phi от U это есть, соответственно, phi от Psi от V.
И коль скоро нам сказали, что вектораты коммутируют,
ну здесь же у нас как раз и написано, композиция phi и psi, примененная к V, правильно?
Это означает, что phi и psi мы можем переставить.
Получается, что это Psi от phi.
Ну а раз это так, то этот вектор несомненно лежит в образе Psi,
мы видим, что он есть Psi от кого-то, правильно?
Это нам и нужно было открыть.
Все, мы выяснили, что если U лежит в образе Psi,
то и phi от U тоже лежит в образе Psi,
а значит он инвалид относительно phi.
Ну ситуация с ядром не намного сложнее.
Если мы разбираемся с ядром Psi,
то опять же давайте выберем произвольный вектор из ядра.
Ну это означает, что Psi от U – это нулевой вектор.
Нас интересует, что такое phi от U, правда ли, что оно лежит в ядре Psi?
Давайте смотреть, что такое Psi от phi от U.
Нам бы хотелось, чтобы это был 0.
Ну опять же такие, поскольку наши операторы перестановочные,
они коммутируют, мы можем переставить phi и Psi местами
и написать, что это phi от Psi от U.
Но Psi от U – это 0,
поэтому у нас здесь написано phi от 0,
и хоть скоро phi – это линейный оператор,
phi от 0 обязательно есть 0.
И того мы поняли, что Psi обнуляет phi от U,
но то есть действительно phi от U лежит в ядре Psi,
и оно тоже следовательно инвариантно относительно.
Таким образом, наше утверждение уже доказано,
и в первую очередь нам будет важно вот какое следствие.
Давайте мы возьмем произвольный навяжение над нашим полем.
Поле F – это то поле, над которое наше пространство W естественно существует.
Тогда мы можем, давайте так скажем,
боевого линейного оператора,
мы можем взять многочлен от этого оператора,
мы с вами уже говорили, что такое понятие определено,
ну и естественно этот многочлен от оператора
будет коммутировать самим оператором,
потому что и то, и другое – это значение на нашем операторе многочлена X умножить на D.
Многочлены же X и P от X коммутируют друг с другом,
значит и вот эти вот тоже будут коммутировать.
Ну и значит, как следствие мы получаем,
что ядро P от Phi и образ P от Phi
в любом многочлене от нашего Phi
инвариантно относительно Phi
к нашему предыдущему.
Давайте я сделаю сразу одно замечание,
у этого следствия самая простая ситуация,
самая простая версия будет, когда я возьму в качестве нашего многочлена
X минус какое-то ляно.
В этом случае P от Phi это будет Phi минус ляно,
и кстати давайте я сразу немножко спрошу,
а что такое Phi минус ляно?
Как я из линейного преобразования вычитаю констант?
Ну из матрицы я же тоже не умею вычитать скаля.
Ну естественно, ляно имеется в виду,
когда мы берем многочлен, скажем, от оператора
или от какого-нибудь другого объекта,
когда мы берем значение многочлена на каком-то элементе алгебры,
у нас там возникает свободный член,
который стоит воспринимать как свободный член умноженный на единицу.
То есть Phi минус ляно это Phi минус ляно умноженное на дождевственный операт.
Если я хочу вот этот же многочлен,
P от X равный X минус ляно,
применить какую-нибудь квадратную матрицу,
то P от A это будет A минус ляно умножить на то,
что исполняет роль единицы в алгебре-матрице,
а что исполняет роль единицы в алгебре-матрице?
Единичная матрица.
Значит, я и должен написать A минус ляно умножить на них.
В таком смысле, понимается, у нас всегда значение многочлена на матрице или, скажем, на оператора.
Мы умножаем на единицу нашей алгебры.
Это вполне согласуется с обычными обозначениями,
потому что, видите, если я наш линейный оператор Phi минус ляно
буду применять к произвольному вектору V,
что это будет означать?
Это означает, что я должен из Phi от V вычесть лямбда от V,
то есть лямбда на дождевственный оператор от V,
иначе, говоря просто, я должен вычитать минус лямбда V.
Вычитать лямбда.
То есть вот таким образом скобки нам тоже можно раскрывать в подобной ситуации.
Мы видим, что для вот такого оператора
наши соображения тоже работают, то есть ядро его и образ его тоже эмбриатны относительно Phi.
Ну вот про этот оператор стоит сказать чуть поподробнее.
Давайте я добавлю еще следующие два утверждения.
Первое утверждение говорит следующую очень простую вещь.
Если у нас Phi – это линейный оператор,
то его ядро… Нет, извините, неправду говорю,
точнее правду говорю, но я хочу сказать более сильную вещь.
Любое подпространство в его ядре
и любое надпространство его образа, то есть любое подпространство содержащее его образ
инвариантны относительно Phi.
То, что его ядро и его образ инвариантны относительно Phi,
это просто выяснить, но это следует из предыдущего утверждения,
потому что хотя бы Phi коммутирует сам с собой.
Я делаю чуть более сильное утверждение, оно тоже простое,
но стоит его обозначить для того, чтобы в дальнейшем мы уже могли свободно этим пользоваться.
Доказательство очень простое.
Еще раз, если у – это подпространство в ядре Phi,
то что такое Phi от u?
Все ядро переходит в ноль, поэтому и Phi от u, я могу сказать так,
что это подмножство Phi от ядра Phi, а это ноль.
Нулевое подпространство, ну и нулевое подпространство, естественно, содержится в u.
Оно содержится в любом подпространстве.
Значит, u – инвариант.
Наоборот, если w содержит образ Phi, то что мы можем сказать про Phi от w?
Phi от w уж точно содержится в Phi от всего v, от всего нашего пространства, правильно?
А это и есть образ Phi, который содержится в w.
Значит, Phi от w содержится в w, и оно тоже является инвариантом.
Ну и последнее утверждение на эту тему.
Как раз про оператор Phi – λ, оно нам говорит вот что.
Итак, пусть Phi – это линейный оператор на w,
λ – это какой-то скаля, ну а u – это какое-то подпространство uv.
Тогда u – инвариантно относительно Phi в том и только в том случае,
когда u – инвариантно относительно Phi – линейный оператор.
То есть запас инвариантовых пространств для Phi и для Phi – линейного оператора – один и тот же.
Доказательства давайте мы докажем в одну сторону.
Пусть u – инвариантно относительно Phi, то есть Phi от u содержится в q.
Что это означает?
Что если я возьму любой вектор из нашего инвариантного пространства
и применю к нему Phi – λ, то что же я получу?
Я уже эту формулу описал.
Это Phi от u – λу.
По нашему предположению, Phi от u содержится в q.
Лямда u тоже содержится в q, поскольку оно просто подпространство, правильно?
Ну и, значит, разностей тоже содержится в q.
То есть я доказал, что u – инвариантно и относительно Phi – линейный оператор.
Если есть какое-либо пространство инвариантное относительно Phi, то оно инвариантное относительно Phi – линейного оператора.
Ну а в обратную сторону можно либо повторить доказательства, либо просто заметить,
что Phi получается из Phi – лямды с добавлением лямды, то есть вычитанием – лямды, правильно?
И, значит, мы можем повторить то же самое рассуждение,
можем повторить тот же самый факт для оператора Phi – лямды и константа – лямды.
И получить то же самое, правильно?
Если есть подпространство инвариантное относительно Phi – лямды, то оно будет инвариантное и относительно этого оператора тоже.
То есть такая вот замена сводит кровь к первому факту.
И таким образом наше утверждение уже доказано.
Но вот этим фактом, особенно в сочетании с предыдущим, мы через некоторое время будем пользоваться.
Обращаю внимание, что связка этих двух фактов нам говорит, что предыдущие утверждения работали не только для ядра и образа Phi,
но и для ядра и образа Phi – лямда тоже, правильно?
Они будут инвариантные относительно Phi – лямды, а, значит, любое подпространство здесь и на пространство здесь будет инвариантное относительно Phi – лямды, а, значит, и относительно этого.
Вот как мы вскоре увидим, это нам будет очень полезно.
Ну и вот давайте мы начнем разбираться с той теорией, в которой это оказывается очень полезно.
Так, следующая наша тема называется собственные векторы и собственные значения.
И источник вот этого понятия очень простой.
Давайте мы разберемся, если у нас есть какой-то линейный оператор, что означает, что у него есть какое-то одномерное инвариантное подпространство.
У – инвариантное относительно Phi, и размерность У равна единице.
Что это означает? Это означает, что У порождено каким-то не нулевым вектором, и при чем Phi от этого вектора содержится в У.
Ну, это означает, что Phi от этого вектора просто пропорционально этому.
И вот такой вектор и называется собственным для нашего преобразования Phi.
То есть в определении у нас звучит так.
Пусть Phi – это линейный оператор, тогда не нулевой вектор В, естественно, из нашего пространства,
называется собственным вектором оператора Phi.
Если для родового таскаля лямда Phi от В есть лямда В.
Так, это понятие мы будем употреблять так часто, что давайте мы его будем сокращать до СВ.
Собственный вектор.
Вот в таком случае, как я сейчас написал, мы будем говорить, что собственный вектор В соответствует скаляру лямда.
И вот такие скаляры лямда, для которых найдется соответствующий им собственный вектор, называются собственными значениями нашего оператора.
Итак, скаляра лямда называется собственным значением.
Это мы будем сокращать для СВ, оператора Phi, если ему соответствует хоть один собственный вектор.
Если существует такой, еще раз подчеркиваю, не нулевой вектор В, что Phi от него – это лямда В.
Вот оказывается, что это очень важное понятие линейной алгебры.
Просто потому, что если у оператора найдется достаточно много собственных векторов, то окажется, что с этим оператором достаточно просто и приятно работать.
Скоро вы это увидите.
Ну давайте разбираться.
Что означает, что В – это собственный вектор с собственным значением лямда.
Это означает, что Phi от В равно лямда В.
Я могу все это перенести в левую часть и записать, что Phi от В минус лямда В – это ноль.
Здесь у нас выражение, о котором мы сегодня уже пользовались.
Здесь написано, что Phi минус лямда, примененное к В – это ноль.
Лямда воспринимается как лямдонатождественный оператор.
А это в свою очередь означает что?
Что означает, что оператор Phi минус лямда обнуляет В?
Это по-другому у нас можно назвать.
В Л лежит в ядре этого самого Phi минус лямда.
То есть, по сути дела, вот это вот самое ядро и состоит из всех собственных векторов, соответствующих данному собственному значению лямда.
Оно имеет тоже специальное название.
Пусть лямда, если лямда – это собственное значение оператора Phi,
тогда подпространство, которое мы чаще всего будем обозначать в В с нижним индексом лямда, то есть ядро вот этого самого Phi минус лямда называется собственным подпространством.
Ну и естественно соответствующее собственному значению лямда.
Итак, у нас появились собственные векторы, собственное значение и собственное подпространство.
Здесь нужно сделать маленькую уговорку.
Конечно же собственное подпространство состоит почти только из собственных векторов соответствующих лямда,
потому что там еще есть ноль, правильно? Он не собственный вектор.
Ну собственно все не нулевые векторы в этом собственном подпространстве – это и есть в точности все векторы,
ну все собственные векторы собственным значением лямда.
Итак, вот на таком языке мы это с вами тоже переформулируем.
Так, ну и первым делом давайте мы с вами докажем один теоретический факт, а потом перейдем к практическим вопросам.
Ну вот здесь возникает вопрос, оправда ли, что таких лямд таких собственных значений может быть много у одного оператора.
Ну и вот сейчас мы несколькими разными способами ответим на этот вопрос, что на самом деле,
если у нас есть оператор на каком-то данном линейном пространстве,
то мы, не зная ничего об этом операторе, уже можем заранее ограничить количество его собственных значений.
То есть таких лямд у нас будет не очень много для данного оператора Фига.
Прежде чем искать собственные векторы давайте мы докажем вот такой полезный факт.
Итак, пусть Фи это у нас линейный оператор на пространстве В.
Напоминаю на всякий случай, что пока что в рамках нашего разговора все пространства считаются конечно верными.
И пусть лямда 1, лямда 2 и так далее, лямда kt это некоторые различные собственные значения оператора Фига.
В принципе можно эту теорию применять и не ко всем собственным значениям, а лишь некоторыми, если хочется.
Тогда у нас для каждого из этих собственных значений возникает собственное подпространство В лямда 1, В лямда 2 и так далее, В лямда kt.
И наша теория утверждает, что сумма этих подпространств обязательно является прямой суммой.
Я это так напишу.
Сумма этих подпространств – это прямая сумма этих подпространств.
Ну и отсюда давайте я уже сразу замечу. Мы это сами потом еще явным образом увидим из других собраний.
Но уже и отсюда следует, что собственных значений у нас может быть не очень много.
Если уж у вас есть собственное значение, это означает, что для него есть какой-то собственный вектор, то есть это подпространство хотя бы одномерно.
Ну и не может быть у нас слишком много подпространств размерности хотя бы один, сумма которых прямая.
Размерность этой суммы напоминает сумму их размерностей.
Итак, давайте доказывать нашу теорию.
Ну и для этого мы воспользуемся одним из простых критериев того, что сумма подпространств прямая.
Сумма подпространств в Эль-Антаиде прямая, напоминаю.
По определению это означает, что любой вектор из этой суммы однозначно раскладывается на слагаемое, каждое из которых лежит в соответствующем подпространстве.
А критерии заключаются в том, что нулевой вектор однозначно раскладывается в такую сумму.
Ну и существует единственный набор векторов ВИИТа, каждый из которых лежит в Эль-Антаиде, такой, что нулик это сумма этих критерий.
Ну и этот единственный набор как он будет выглядеть? Одни нули, правильно?
И с каждым от пространства мы должны выбрать ноль. Такое представление у нуля, напоминаю, уже точно есть.
И вот нам нужно доказать, что другого нет.
Давайте предположим, что это не так, что нулик разложился в сумму таких векторов.
ВИИТ лежат в наших подпространствах, и не все ВИИТ нули.
Ну, во-первых, давайте мы сразу скажем в этом случае, что можно считать, что все ВИИТ отлично от нуля.
Просто если у нас в этой сумме есть какое-то нулевое слагаемое, давайте забудем про него и давайте изключим это подпространство из рассмотрения.
Будем разбираться с остальными собственными значениями.
То есть мы можем считать, выкинув из этой суммы нули и выкинув из рассмотрения соответствующие подпространства, что все ВИИТы не нули.
Более того, давайте мы будем считать, ну вот у нас норма, по сути дела, разложился в сумму к не нулевых собственных векторов, соответствующих разным собственным значениям.
И мы будем также считать, что к наименьшее возможно.
Ну, то есть сумма к-1 не нулевого собственного вектора, соответствующих разным собственным значениям, уже обязательно не нулевого.
Ну, просто мы выбили минимальную лекарь, для которого этого звуки.
Давайте тогда смотреть, что это означает.
Во-первых, 0 это сумма в 1 и так далее и в экатах.
С другой стороны, мы с вами знаем, что фе от нуля это тоже 0.
Фе от нуля это сумма фе от в1 и так далее плюс фе от в экатого.
И мы знаем, кто все эти слагаемые, потому что ВИИТы это собственные векторы.
То есть фе от V1 это лянда первая на V1 и так далее, фе от V экатого это лянда катая на V экат.
Скажите, у вас сколько написано нулевая сумма?
Сумма к-1 и нулевого собственного вектора с различными собственными значениями уже обязательно будет не нулевая.
Просто если у нас найдется такой к-1 вектор, то мы возьмем их.
Мы выбрали набор из не меньшего количества собственных векторов с разными собственными значениями, которые равны нулу.
Какой-то такой набор есть, мы из всех таких наборов выбрали набор из минимального количества векторов.
Для начала, наверное, я должен был сказать, давайте мы сразу заметим, что k больше единицы.
Потому что если бы k было равно единице, то у меня здесь было бы написано 0 равно V1, а V1 не нулевой.
Иначе 0 равен V1, который не нулевой это быть не может.
И там k больше единицы.
Ну и давайте мы теперь из той суммы, которая у нас получилась нулевой, вычтем исходную сумму, умноженную на лямбда 1.
У нас есть сумма лямбда 1 V1, плюс лямбда k, а из нее я вычитаю лямбда 1.
Давайте на лямбда k выучьем.
Вычитаю лямбда k умножить на V1, плюс и так далее, плюс Vk.
Я из нуля вычил 0 и, естественно, получил 0.
А что это такое?
Лямбда 1 минус лямбда k на V1, плюс и так далее, лямбда k минус 1 минус лямбда k на Vk.
На Vk минус k, естественно.
Ну и давайте смотреть, что же у нас получилось.
Все эти векторы, катая слагаемая у нас сократилась, лямбда катая Vk сократилась, лямбда катая Vk.
У нас получилась сумма из k минус 1 слагаемая.
Все эти векторы не долевые.
Все эти векторы по-прежнему собственные векторы с собственными значениями лямбда 1 и лямбда k минус 1.
Ну потому что они получились из собственных векторов умножением на констант.
Да, я не пояснил, наверное, что они не работают, потому что векторы выменили или выменили?
И умножаем мы их на не 0. У нас лямбдаитые все различные.
Итак, мы получили, что 0 – это сумма k минус 1 слагаемого,
каждая из которых не долевой вектор, причем он собственный с собственным значением лямбда 1.
Но это противоречит нашему выбору, это противоречит минимальности нашего k.
Противоречие с минимальностью k.
Мы нашли сумму k минус 1, не долевого собственного вектора с различными собственными значениями, которая долева.
Ну и значит наша теорема уже доказана.
Потому что они разные формулировки теоремы.
Где у меня тут формулировка теоремы?
Вот она, лямбда 1 и лямбда k, и я предположу, что это различные собственные значения.
Если бы лямбда 1 было равно лямбда 2, то здесь у нас в сумме 2 раза было бы одно и то же собственное подпространство.
Естественно сумма бы прямой тогда не была, правильно?
Но мы считаем, что у нас лямбда различные, и вот тогда все эти подпространства образуют прямую сумму.
Итого наша теорема доказана. Продолжим после перерыва.
Итак, давайте двигаться дальше.
Я обещал, что мы разберемся с тем, как искать эти самые собственные значения.
Ну и на самом деле алгоритм поиска здесь очень простой.
Как искать собственные значения, но и собственные векторы.
Главный здесь вопрос, естественно, собственные значения, потому что если мы найдем собственные значения лямбда,
то кто такие собственные векторы, мы уже знаем.
Географ k-d.
Вот пусть у нас, если нам оператор дам в ощущениях, он нам чаще всего запомнит какой-то матрицей,
пусть у нас E это базис В,
phi это по-прежнему линейное преобразование нашего В,
и phi имеет базис E, некоторую матрицу А.
И тогда давайте смотреть, как мы можем отловить наше собственное значение.
Что означает, что лямбда, скаля, это собственное значение phi.
Это означает в точности, что существует не нулевой вектор,
такой, что phi-лямбда, примененная к этому вектору, это ноль.
Вот я на всякий случай подробно это дело расписываю.
Это означает, в свою очередь, что ядро phi-лямбда отлично от нуля,
или по-другому сказать, что существует не нулевое решение того же самого уравнения, записанного в матричном виде.
А как это уравнение будет записано в матричном виде?
Вот у нас матрица у оператора phi-лямбда.
Матрица phi мы ее обозначили через А, матрица лямбда это естественно лямбда E,
потому что лямбда это лямбда на тождественный оператор, матрица тождественного оператора естественная линейная матрица E.
Итак, вот такая вот система уравнений имеет не нулевое решение, поскольку матрица а-лямбда E квадратная,
это происходит тогда и только тогда, когда матрица а-минус лямбда E вынуждена,
а это означает, что ее определение не нулевое.
Итого, лямбда является собственным значением нашего оператора phi тогда и только тогда,
когда определитель матрица а-лямбда E равен нулю.
Давайте поймем, что это в свою очередь значит.
Если матрица А имеет элементы А и Ж, как обычно, то определитель матрицы а-лямбда E,
нам для этого нужно просто выписать эту матрицу, чтобы на нее посмотреть, давайте мы это сделаем,
мы к этой формуле еще будем сейчас в некоторое время обращаться.
Что я должен сделать с матрицей А?
Я должен из диагональных элементов вычесть по лямбде.
Здесь будет А1-1 минус лямбда, А2-2 минус лямбда, вот такие вот элементы будут стоять по диагонали,
остальные элементы останутся такими же, как были и в нашей матрице.
Вот такой у нас определитель.
Ну и если мы посмотрим на него как на выражение, зависище от лямбды,
то мы немедленно видим, что это многочлен, зависище от лямбды.
Ну хотя бы по формуле полного разложения определителя.
Это у нас сумма N-факториал произведений, каждое произведение это многочлен от лямбды, правильно?
Значит и все это дело, это многочлен от лямбды.
Он носит специальное название.
Так если у нас А это, внимание, квадратная матрица над полем F,
тогда вот буква Хи греческая отвечает за это.
Вот такой вот многочлен.
Хи с индексом А от х, это определитель А-хЕ.
Это многочлен от нашего поля F.
Вот этот многочлен называется характеристическим многочленом матрицы А.
Ну и таким образом, вкупе с предыдущим рассуждением, мы с вами получаем, что мы уже доказали следующее утверждение.
Пусть Фи это линейный оператор на пространстве В, ну и в некотором базе Фи имеет матрицу А.
Когда лямбда скаля из поля является собственным значением Фи, в том же только в том случае, когда лямбда это корень характеристического многочлена нашего матрицы этого оператора.
Пока что это характеристический многочлен матрицы.
Ну тут, наверное, стоит сразу сказать одну полезную вещь.
В принципе, у нас же есть много базисов в нашем пространстве В, и у Фи мы могли взять матрицу в любом из этих базисов, получить разные матрицы, и вроде как мы могли даже получить разные характеристические многочлены.
Но на самом деле нет полезного утверждения говорить по сути, что характеристические многочлены матрицы оператора не зависят от того, в каком базисе мы эту матрицу записываем.
Ну то есть формально давайте я скажу так, пусть E и E' это базисы В, пусть у нас есть линейное преобразование пространства В, которое в базисе E имеет матрицу А, в базисе E' имеет матрицу H'.
Тогда характеристические многочлены этих матриц совпадают.
Будя доказательства, давайте вспомним, как связаны матрицы одного и того же оператора в разных базисах.
Если E' получается из E до продолжения на матрицу перехода С, то как бы мы помним, H' это С минус 1 на А на С.
Ну и давайте мы воспользуемся этим знанием для того, чтобы понять, кто такой характеристический многочлен матрицы H'.
Это определитель H'-X на E, просто по определению нашего характеристического многочлена.
H' я могу выразить как С минус 1 на А на С, ну и сделаю я всего лишь одну хитрость, вместо E я тоже напишу С минус 1 на E на С.
Я имею право это делать, это произведение, естественно, равно H'.
Ну теперь вот в этой разности я вполне себе имею право вынести С минус 1 за скобку слева, а С за скобку справа.
Ну и дальше мы с вами знаем, что определитель произведения матриц это произведение определителей.
И значит здесь у нас написано определитель S минус 1 на определитель A минус XE на определитель S.
Но определители S минус 1 и S естественно взаимно обратны друг к другу, потому что произведение этих матриц это E.
И значит у нас получился определитель A минус XE, то есть характеристический многочлен матрицы H'.
Таким образом наше утверждение доказано.
И теперь мы уже можем определить не только характеристический многочлен матрицы, но и характеристический многочлен оператора.
Пусть phi это линейный оператор на пространстве V, тогда ему характеристический многочлен, который будет обозначаться his index of phi за X.
Это характеристический многочлен любой его матрицы.
Мы с вами видим, что он независит от того, в каком именно базе эту матрицу брать, то есть это понятие коллектного определения.
Давайте в этот момент мы немножко плотнее посмотрим на нашу формулу для характеристического многочлена матрицы и выясним некоторые его коэффициенты.
Тут стоит сразу дать еще одно определение.
Пусть A это квадратная матрица над полем F с элементами Aежли, тогда след матрицы A определяется следующим образом.
Она обозначается от A под слово trace, и это сумма всех ее диагональных элементов.
Так вот давайте мы выясним, как выясним некоторые коэффициенты характеристического многочлена матрицы A.
Давайте я сразу поясню, зачем я это делаю.
Мы с вами поняли, что если мы взяли любые две матрицы нашего линейного оператора, то у них характеристический многочлен один и тот же.
Это значит, что все соответствующие коэффициенты характеристических многочленов A и H3 совпадают.
И если мы выясним смысл этих коэффициентов, то мы выясним, какие это сходства матриц A и H3.
Это то, чем мы сейчас собираемся заняться.
Ну давайте разбираться.
Первым делом характеристический многочлен, давайте я еще раз напишу его.
Как я уже говорил, эта сумма по формуле полного разложения определителя,
эта сумма N факториал слагаемых, каждая из которых произведение N элементов нашей матрицы из разных строк и разных столбцов.
Какая стихия будет у нашего многочлена?
Каждый из этих сомножителей это либо константы, если он стоит на диагонали, либо линейный многочлен, если он стоит на диагонали.
Поэтому степень нашего многочлена не может превосходить R размера нашей матрицы.
Ну и более того, мы непосредственно видим, что у нас в нашем многочлене есть единственное место,
из которого может получиться именно mn степени, именно xn.
Это если мы будем перемножать N линейных сомножителей, которые стоят по диагонали.
Значит, у нас появляется единственный член степени R, он не сильно сократится.
И значит, вот этот xn у нас обязательно в нашем многочлене будет.
Степень характеристического многочлена это именно N.
И какой прием будет козицина, давайте смотреть.
Еще раз, xv вылезет только из произведения вот этих диагональных сомножителей.
a1n-x, a2n-x, a1n-x.
То есть в каждой скобке он имеет элицент x-1, значит, элицент будет именно –1v.
Давайте двигаться дальше.
Вот, видимо, стоит двигаться на соседнюю доску, чтобы далеко не уходить.
Итак, откуда характеристическое многочлене нашей матрицы
может взяться слагаемая степень N-1.
Давайте мы с вами вылезем.
Из диагонали, то есть из произведения диагональных элементов.
И внимание только оттуда, только из произведения диагональных элементов.
Потому что, гляньте, для того чтобы у нас получился член степени N-1,
в нашем произведении N-1 члены должны быть линейными.
То есть N-1 член должен быть взят с диагонали.
Ну а тогда и N-ый член методом исключения,
мы же берем произведение N элементов из разных строк и разных столцов.
Если мы N-1 из них взяли с диагонали, то и оставшийся определяется однозначно,
он тоже будет с диагонали.
То есть из А1-1-х, далее АНМ-х.
Но в этом-то произведении мы знаем, какой коэффициент при ХВ-1.
Здесь у нас будет минус 1 в N на ХВ, по-прежнему, плюс ХВ-1.
Откуда он у нас возьмется?
Мы должны из N-1 скобки взять минус х, правильно?
И поэтому у нас наберется коэффициент минус 1 в N-1.
А из оставшейся скобки взять константу А с индексом ИИ.
И так мы можем сделать с любой скобкой.
Поэтому у нас здесь будет сумма по И на И.
Злые плюсы и так далее, плюс члены меньшего порядка.
Итого, в нашем характеристическом многочлене мы уже знаем следующий член.
Следующий член будет минус 1 в степени R-1.
На след матрицы А, потому что вот это выражение, это и есть след матрицы А.
На х в N-1.
Сейчас я еще раз эту формулу, когда я вычислю еще один коэффициент, сейчас я еще раз ее перебью.
И так, ну и наконец, давайте подберемся с другого кра.
Каким будет свободный член этого многочлена?
Ну это совсем просто.
Свободный член характеристического многочлена, свободный член любого многочлена, это его значение в нуле.
Ну а значение характеристического многочлена в нуле.
Это определение А минус 0 на N, то есть определение А.
Итого, мы с вами получили следующее утверждение.
Характеристический многочлен матрицы А имеет следующий вид.
Минус 1 в N на х в N.
Плюс минус 1 в N-1.
На след матрицы А на х в N-1.
Плюс члены меньшего порядка.
И в качестве свободного члена у нас стоит определение А.
Ну и как немедленное следствие этой формулы
Мы получаем следующее.
Если оператор имеет в двух разных базисах матрицы А и А',
то у этих матриц совпадают следы и совпадают определения.
Ну просто потому что они умноженные на минус 1 в соответствующей степени
есть коэффициенты характеристических многочленов этих матриц,
а характеристические многочлены у них совпадают.
И вот это утверждение у нас уже тоже доказано.
Это соображение порой бывает очень полезным.
Мы через некоторое время еще увидим, как оно бывает, что работает.
Ну а пока что, коль скоро эти понятия, независимо от того,
в каком базисе мы записываем матрицу нашего линейного оператора,
это означает, что эти понятия связаны только с самим оператором.
И мы можем дать, аналогично тому, как мы дали определение характеристического многочлена оператора,
мы можем дать такое определение.
Пусть phi, это линейное преобразование пространства В,
тогда его след trace phi, это след любой его матрицы,
а его определитель, давайте лучше мы будем писать det phi, это определитель любой комнаты.
Это мы только что доказали, что эти понятия не зависят от того,
в каком базисе мы будем эту матрицу записывать,
и поэтому мы имеем право такое определение дать.
Прежде чем верится дальше, я хочу оставить парочку упражнений,
связанных с теми коэффициентами, которые вы с вами уже нашли, а также, которые еще не нашли.
Первое упражнение, просто для того, чтобы немножко поработать со следом,
я предлагаю доказать, что если A и B две квадратных матрицы,
то след их произведения не зависит от того, в каком порядке мы это произведение берем.
Ну и на самом деле я могу сказать, что это упражнение верно даже в более общей постановке.
Если мы даже возьмем не квадратные, а прямоугольные матрицы,
так чтобы их можно было перемножать в порядке,
а это как раз будет означать, что эти произведения оба квадратные будут разными.
Даже если мы возьмем прямоугольные матрицы так, чтобы следы были определены, то они тоже будут равны.
Упражнение второе, желающее осознать, как выглядят остальные коэффициенты характеристического умногочля,
приглашается это сделать.
Найдите формулы для остальных коэффициентов характеристического умногочлена матрицы A,
скажу через что выражать, выразив их через миноры матрицы A,
миноры, напоминаю, это определители под матриц, в матрице A.
Все эти коэффициенты выражаются через миноры матрицы A, но в качестве небольшой подсказки
я скажу, что в нашей формуле все именно так и происходит.
Что такое след матрицы A?
Это сумма некоторых ее миноров размера 1 на 1, определитель под матриц размера 1 на 1, стоящих на диагонали.
Что такое определитель матрицы A?
Это 1 минор определитель всей матрицы NI.
Соответственно остальные коэффициенты будут выражаться через миноры других порядков,
и я предлагаю всем желающим понять, как именно это происходит.
Ну а мы с вами двигаемся дальше.
Поиск собственных значений мы с вами, по сути дела, уже осветили, мы знаем как их искать,
и мы переходим к тому, зачем это все надо.
И вот давайте прежде чем разбираться с общим случаем,
давайте мы сначала разберем некоторый частный случай,
из которого будет видно к чему мы стремимся.
Первым делом давайте сделаем небольшое замечание.
Если размерность В равна N, это как мы с вами видели уже означает,
что степень характеристического многочлена равна N,
и это означает, что у этого характеристического многочлена не более N корней.
Даже с учетом кратности, но давайте пока без кратности.
И вот я утверждаю, что если так вышло, что их корней равна N различных,
то мы сразу можем описать наш линейный оператор, предъявив для него очень хорошие базы.
Теорема, которую мы через некоторое время обобщим, но давайте пока начнем с нее.
Пусть Фи линейный оператор на пространстве В, размерность которого равна N,
и пусть у Фи есть N различных собственных значений.
Давайте мы их сразу обозначим λ1 и так далее.
Но я сразу напоминаю, N различных собственных значений это в точности означает,
что у характеристического многочлена есть N различных корней.
Такая у нас связь, и больше их быть не может.
Тогда в В существует базис, состоящий из собственных векторов оператора Фи.
Давайте мы сначала докажем теорему, а потом осознаем, чем хороша такая базис.
Доказательства? Ну просто давайте вспомним, что мы с вами уже знаем.
Для каждого I от 1 до N мы знаем, что λi,t это собственное значение,
значит у него есть соответствующее собственное подпространство V с индексом λi,t
и размерность этого собственного подпространства, хотя бы единиц,
но поскольку хотя бы один собственный вектор для этого λi,t есть.
Давайте посмотрим на сумму этих подпространств.
Размерность суммы этих подпространств понята на O до N.
Во-первых, она конечно же не больше, чем N, потому что это подпространство в нашем В.
С другой стороны, эта же сумма прямая,
это сумма прямая, а мы с вами знаем, что размерность прямой суммы это сумма размерностей слагаемой.
Ну а значит, она уже как минимум сумма R единиц, то есть N.
Что мы с вами получили? Мы с вами получили неравенство, в котором слева и справа стоят N,
а это значит, что все эти неравенства обращаются в равенство.
Итак, значит, все неравенства обращаются в равенство.
Ну то есть, для ясности давайте я сразу скажу, что размерность каждого собственного подпространства
получилась равной единице, иначе бы здесь неравенство было бы уже строгим.
И размерность вот этой самой прямой суммы равна нему.
Ну а это означает, что В и есть эта самая прямая сумма. У нас В есть только одно пространство размерности N.
Ну а тогда выброс в каждом из наших пространств не нулевой вектор E и T,
но по совместительству я сразу обращаю внимание, этот вектор и будет образовывать базис нашего одноперного подпространства, правильно?
Мы получаем уже базис всего пространства W. Мы с вами знаем, что если пространство есть прямая сумма нескольких подпространств,
то конкотинация их базисов это базис В. E1, E2 и так далее, En это как раз базис в пространстве W.
Ну и он требуемый, потому что он состоит из собственных векторов нашего преобразования W.
Теорему мы таким образом доказали, базис из собственных векторов мы построили, осталось понять, зачем это нужно.
А вот зачем. Давайте мы посмотрим с вами на то, какой вид имеет матрица нашего оператора в этом базисе.
Построенным базисом матрица оператора Fin имеет следующий вид. Давайте смотреть. E1 это собственный вектор собственным значением λ1.
Иначе говоря, Fiat E, ну давайте я сразу, Fiat E1 мы с вами знаем. Это лямбда E1.
А в нашу адресу мы должны записать, скажем, в первом столце разложение Fiat E1 по вот одному базису.
И это разложение выглядит очень просто. Fiat E1 будет иметь координаты лямбда 1 и дальше 0.
Fiat E2, то есть лямбда 2, E2, будет иметь координаты 0, лямбда 2, 0 и так далее.
Ну и так далее. У нас по диагонали нашей матрицы будут написаны лямбда 1 и так далее, лямбда n.
Во всех остальных местах будут 0. То есть матрица нашего оператора в этом базисе просто диагональна.
С одной стороны, с этой матрицы очень просто работать. А с другой стороны, мы можем описать еще и геометрический смысл нашего оператора.
Как он устроит? Вот у нас есть базис E1 и так далее E2, и оператор каждый из этих E-шек доножает на какую-то лямбда, правильно?
То есть в последнее дело растягивают вдоль вот этой вот итой оси в лямбда итой раз.
То есть геометрический смысл нашего оператора Фин, это просто, если мы его записываем вот в этом базисе собственных векторов,
это растяжение я вдоль итой оси в лямбда итой раз.
И так просто устроен наш оператор в случае нашей теории.
Ну и вот после перерыва мы с вами разберемся, а когда еще мы можем матрицу оператора привести вот к такому диагональному мету, ну и получить вот такой же геометрический смысл.
А пока перерыв.
Так, давайте мы продолжим.
Ну вот мы увидели, что в нашем частном случае, в случае этой теории, можно предъявить базис, в котором матрица оператора имеет диагональный вид.
Такой оператор имеет специальное название.
Так, пусть Фин, линейный оператор, линейное преобразование пространства В, тогда Фин называется геометризуемым,
если, ну как раз существует базис Е в пространстве В.
Такой, что матрица Фин в этом базисе диагональна.
Ну то есть это означает, что все элементы кроме диагональных равны нуле. На диагонали тоже в принципе могут стремиться нули, но главное, что кроме диагонали все нули.
Ну и на всякий случай давайте мы сразу дадим соответствующее определение для матрицы.
Аналогично, матрица А, квадратная матрица на поле Ф называется геометризуемой.
Если, ну по сути, если она является матрицей диагонализуемого оператора, то есть если ее можно привести к диагональному виду, вот той вот самой заменой базиса, которую мы уже вели.
На матричном языке это означает, если она подобна диагональной матрице.
Ну то есть давайте расшифруем на всякий случай.
Если существует матрица перехода, то есть невыраздленная матрица МН, такая, что НС минус 1 на АНС ядовна.
И наша ближайшая цель выяснить при каких условиях оператор Ф действительно будет диагонализуем.
С этой целью нам придется дать еще несколько определений, которые на самом деле тесно связаны с теми необходимыми и достаточными условиями, которые у нас сейчас возникли.
Так, первое определение такое, даже несвязанное с оператором.
Пусть П это многочлен над полем Ф, но для определенности давайте будем считать, что степень П хотя бы единица.
Этот многочлен называется линейно-факторизуемым, если он раскладывается на линейное содножие.
На содножителе степени 1.
Ну иначе говоря, если в том самом существенно единственном разложении его негативные содножители, это разложение настолько длинное, насколько возможно, оно состоит из N линейных содножителей, если степень многочлена равна N.
Это определение, мы скоро увидим, что необходимые условия того, чтобы Ф был диагонализуемым, это то, что его характеристический повышен именно что линейно-факторизуем.
Но это не единственное условие.
Давайте двигаться дальше.
Ну вот давайте на минутку.
Слушайте, давайте мы сейчас его сразу убьем.
Давайте мы сделаем такое замечание, прежде чем двигаться дальше, чтобы объяснить смысл этого определения.
Если оператор диагонализуем, то есть в некотором базе E, его матрица имеет диагональный вид.
Давайте я сразу по диагонали поставлю лямбда 1 и так далее лямбда N.
Это уже не обязательно различная скаляра, но какие-то скаляры должны быть.
Давайте мы посмотрим, что же тогда такое его характеристические многочлены.
Это то же самое, что характеристические многочлены.
Матрица A, то есть определитель вот такой вот по-прежнему диагональной матрицы.
Ну а это есть не что ли, но как произведение ее диагональных элементов.
Определитель диагональной матрицы мы с вами хорошо знаем.
То есть он действительно линейно факторизуем.
То есть линейная факторизуемость характеристического многочлена, это действительно не обходимое условие того, чтобы ФИ был диагонализуем, но не достаточно.
Как оно может быть недостаточным?
Если все лямбда 1 и вот здесь вот произведение различные, то мы с вами уже доказали.
В этом случае оператор действительно диагонализуем, правильно?
Мы нашли такой базис, в котором его матрица диагональна.
И это значит, что единственная проблема вот в такой ситуации может быть, если некоторые из лямбда 1 вот в таком вот разложении совпадают.
То есть если у характеристического многочлена появляются кратные курсы.
И вот эта ситуация, которую мы сейчас с вами и собираемся изучить.
С этой целью нам нужны еще два важных понятия.
Итак, усть ФИ линейный оператор, усть лямбда это корень его характеристического многочлена.
Ну то есть то же самое, что его собственное значение.
Тогда алгебравическая кратность собственного значения лямбда.
Это кратность корня лямбда в характеристическом многочлене нашего оператора.
Давайте я на всякий случай сразу напомню.
То есть если характеристический многочлен представляется в виде лямбда минус х в степени какой-то альфа умножить на q.
Где лямбда уже не корень q, то алгебравическая кратность лямбды равна альфе.
Вот я на всякий случай напомнил, расшифровал это определение.
Кроме этого есть геометрическая кратность.
Геометрической кратностью собственного значения лямбда называется просто-напросто размерность собственного подпространства соответствующего этой лямбде.
То есть напоминаю, размерность гидравфия минус х.
Вот такие две кратности у нашего собственного значения возникают.
И мы сейчас выясним, что они друг с другом связаны.
Они не обязательно совпадают, забегая вперед я скажу, но связь между ними есть.
И чтобы прояснить эту связь, давайте я сначала докажу чуть более общее утверждение, чем нам нужно именно сейчас.
Чуть более общее утверждение выглядит так.
Пусть фи, это линейное преобразование пространства В, и пусть у него есть инвариатное подпространство У.
В этом случае мы можем взять ограничение фи на У и рассмотреть его как линейное преобразование пространства У.
Ну и таким образом у нас есть два линейных преобразования, фи и псих, разных пространств.
И у каждого есть характеристический многочлен.
Такое утверждение заключается в том, что характеристический многочлен ограничения на инвариантное подпространство
делит характеристический многочлен самого фи.
Доказательства не очень сложные. Мы с вами характеристический многочлен умеем по нормальному определять через матрицу, правильно?
Ну а мы с вами помним, какая у нас матричная запись того, что У это инвариантное подпространство.
Давайте мы выберем тот самый базис В, согласованный с Ум.
Выберем базис Е1 и т.д. в пространстве В.
Такой, что некоторые его префиксы Е1 и т.д. это базис У.
Тогда, как мы с вами знаем, фи в базисе Е имеет блочно-треугольную матрицу, то есть матрицу вот такого вот вида, с углом 0.
Причем матрица А, как мы с вами уже говорили, это не что иное, как матрица ФС.
Вот в этом самом базисе, в префиксе ФС, в префиксе Е1 и т.д. имеет в точности матрицу А.
Ну а значит, теперь мы можем выписать характеристический многошлем нашего фи при помощи вот этой самой матрицы.
Тогда характеристический многошлем фи это определитель этой матрицы, из которой по диагонали выучили х.
Ну давайте сразу вспомним, что у нас здесь матрица А имеет размер k на k, матрица С имеет размер l-k на l-k, то есть эти матрицы квадратные.
И соответственно, когда я вычитаю х по диагонали этой матрицы, я по сути дела вычитаю х из диагонали матрицы А и из диагонали матрицы С.
То есть в этом определителе она стоит следующая.
A-XE в левом нижнем углу, когда эти вот х вышли как раз из диагонали матрицы А.
C-XE в правом нижнем углу, аналогично.
Матрица В и нулевая подматрица остались метод.
Ну а тогда у нас по-прежнему написан определитель с углом 0, и значит по-прежнему определитель этой матрицы это произведение определителей вот этих вот квадратных матриц.
Обделитель А-XE на определитель целью XE.
Ну а определитель А-XE, коль скоро А это была матрица нашего С, это есть не что иное как характеристический нарешитель С.
Ну и мы с вами победили, мы доказали, что характеристический нарешитель Фи есть характеристический нарешитель Си умножить на какой-то многочлен.
Ну собственно говоря на характеристический нарешитель матрицы С.
Это и означает, что характеристический нарешитель Си делит характеристический нарешитель Фи.
Вот оно частное в этом многочлене.
Как следствие мы получаем следующее.
Пусть лямбда это собственное значение оператора Фи.
Ну и пусть давайте его сразу обозначим, альфа и бета это его алгебраическая и геометрическая кратность в соответствии.
Тогда альфа не меньше чем бета. То есть алгебралическая кратность любого собственного значения не меньше, чем его геометрическая кратность.
Это доказательство. Давайте вспомним, что такое собственное подпространство, соответствующее лямбде.
Собственное подпространство в лямбде это, как мы с вами знаем, ядро Фи-лямбда.
Ну и вот согласно тем фактам, которые мы с вами доказывали в начале сегодняшней лекции, это ядро инвариантно относительно Фи.
Значит, если мы положим в Си ограничение Фи на это самое в лямбда,
то характеристический нагрешлен Си будет делить характеристический нагрешлен Фи.
Но что такое Си? Си, значит, еще раз мы их рассматриваем как линейное преобразование нашего подпространства в лямбде.
Что такое Си? Каждый вектор, который мы ему скармливаем, собственный вектор собственного значения в лямбде.
Значит, Си каждый вектор умножает на лямбда.
Си любой вектор умножает на лямбда.
Ну, для любого вектора из нашего собственного подпространства.
То есть, по сути дела, Си это и есть оператор умножения на лямбда.
Мы рассматриваем только на нашем собственном подпространстве Си и есть оператор умножения на лямбда.
Но тогда в любом базе, какой бы мы ни выбрали в нашем пространстве в лямбда,
матрица Си это лямбда умноженная на е.
Каждый вектор умножается на лямбда, значит там просто по диагонали стоят ямы.
Ну и значит, давайте я все-таки вот сюда, наверное, перейду.
Раз у меня там места немного не хватило.
Значит, характеристический наличлен Си это есть определитель матрица лямбда е-хе.
То есть просто набраться лямбда-е-х в степени бета, разумеется, правильно?
У нас наше пространство в лямбда размерности бета,
геометрическая кратность у нас так и определяется, правильно?
Это ровно лямбда-х в степени бета.
И мы с вами знаем, только что доказали,
что этот самый характеристический наличлен делит характеристический наличлен всего Фи.
Ну, мы с вами видим, что в характеристический наличлен Фи
сомножитель лямбда-х входит хотя бы в беттной степени, правильно?
Это и означает, что альфа хотя бы бета.
Что кратность этого корня лямбда в нашем характеристическом наличлении хотя бы бета.
Контрольный вопрос. Откуда может появиться строгое неравенство?
Вот мы видели, как происходит эта делимость. Откуда может появиться строгое неравенство?
У второй матрицы, вот у этой матрицы С, тоже может оказаться собственное значение лямбда, правильно?
Вот у этого определителя тоже может лямбда оказаться корнем.
И в этом случае неравенство может оказаться строго.
Именно так.
Итого, наше следствие уже доказано.
И мы переходим с вами к основной теореме.
Будем надеяться, что успеем ее доказать.
Итак, мы с вами переходим к следующей теореме,
которая дает нам уже критерии диагонализуемости оператора Ф.
Ну так пусть Ф, но некоторые критерии будут совсем тривиальны.
По сути дела мы это уже проговорили.
Но для полноты я их тоже запишу.
Итак, пусть Ф это линейный оператор, тогда равносильны следующие условия.
Условие первое, к чему мы стремимся.
Ф диагонализуем.
Условие второе, самое полезное для практического использования.
Характеристический многошвед Фи.
Линейно факторизуем, то есть раскладывается на линейные совножики.
И у каждого собственного значения нашего оператора Фи
алгебраическая и геометрическая кратности совпадают.
Ну и мы видели, что всегда алгебраическая не меньше, чем геометрическая.
Для того, чтобы он был диагонализован, нам нужно, чтобы они совпадали.
Третье условие, все пространство В раскладывается в прямую сумму собственных подпространств.
Где лямбда 1 и так далее, лямбда ката, это все различные собственные значения оператора Фи.
Ну и четвертое, практически равносильное первому, как мы уже видели, В, существует базис из собственных векторов операторов.
Вот такие вот четыре условия оказываются, равносильными.
И давайте мы это будем доказывать.
Ну как обычно, доказательство идет по циклу.
Утверждение из первого окружения вытекает второе.
Если Фи диагонализуем, то есть для некоторого базиса Е, Фи имеет матрицу диагональную.
Я обращаю внимание, что здесь на диагонали могут встречаться совпадающие собственные значения.
То, давайте понимать.
Во-первых, характеристики на вершине, как мы уже видели, это произведение х, извините, лямбда ита минус х.
То есть он линейно фонаризует.
Во-вторых, если лямбда это собственное значение нашего оператора Фи, то что такое ее алгебрическая кратность?
То, сколько раз она встретится на диагонали, столько множителей вида лямбда минус х и встретится в этом произведении.
Правильно? Его алгебрическая кратность это количество таких i, что лямбда ита равно i.
Ну и пусть это индексы i1 и так далее и альфа.
Пусть i1 и так далее и альфа, это индексы такие, что лямбда ита равно лямбда.
Тогда из виду нашей матрицы мы получаем, что е с вот этими индексами это собственные векторы с собственным значением лямбда.
Этот вектор при применении нашего оператора просто умножается на лямбда.
Это означает, что в нашем собственном подпространстве уж во всяком случае содержится линейная оборужка этих векторов.
И это означает, что в нем содержится каждая из этих векторов, а значит и вся линейная оболочка.
Поскольку они линейно-независимые, это же векторы базис, это означает, что размерность лямбда, то есть геометрическая кратность, уж не меньше, чем алгебрическая кратность.
Ну а поэтому эта размерность равна альфа, ибо раньше мы доказали, что превосходить она не может.
Ну и таким образом мы проверили оба наши подтверждения.
Характеристические многочлены линейно факторизуем, у каждого собственного значения совпали геометрическое и геометрическое.
Дальше пойдет легче.
Давайте заказывать 2 в 3.
Ну а что мы уже знаем?
Нам сказали, что характеристические многочлены линейно факторизуем, и если λ1, тогда и λк это все различные собственные значения, то это просто означает, что он представляется вот в таком виде.
Это произведение, извините, неправильно написал, лямдониты минус х в степени альфаит.
Во всяком случае, хоть скоро он линейно факторизуем, то он пропорционален вот этому вот произведению, правильно, там все скобки у нас будут линейные.
Но старший инфекцент в этом произведении ровно такой, какой нужно, минус 1 в степени n, поэтому на самом деле они совпадают.
Ну а это означает, что алгебравическая кратность лямдонитова есть альфаит, а это означает, по нашему второму свойству, что и геолитрическая кратность лямдонитова, то есть размеры собственного подпространства, тоже равна альфаитову.
Далее, мы с вами уже знаем, что все собственные подпространства в лямдонитве образуют прямую сумму, и это означает, что размерность этой прямой суммы,
хоть скоро сумма прямая, это опять же, как и сумма размерной степени, слагаемых, она равна сумме альфаитов, ну а сумма альфаитов это степень нашего характеристического маневерства,
равна степени характеристического маневерства, то есть равна размерности пространства. Это мы знаем, что всегда так.
Итого, мы поняли, что наша прямая сумма лежит в В, и ее размерности совпадают с размерностью В, это и означает, что вот эта прямая сумма в лямдонитах совпадает с В,
и наш переход из второго в третью доказан. И с третьего в четвертый переход еще проще, как и раньше.
Выберем в каждом в лямдонитах базис, если мы предположили, что В раскладывается в прямую сумму собственных подпространств, в каждом в лямдонитах мы выберем базис,
и тогда их конкатенация это базис в В. Причем требуемый. Мы выбрали этот базис только из собственных подпространств,
то есть все элементы этого базиса это собственные вещества. Ну и наконец мы выберем базис в В.
Мы выбрали базис в В, и тогда их конкатенация это базис в В.
Ну и наконец, из четвертого свойства В, переход мы по сути дела уже делали, давайте сделаем в всякий случай еще раз.
Если Е, Р, В и так далее Е, это базис из собственных факторов, ну то есть ФИ от ЕИТОВА, это я на ЕИТО и она ЕИТО,
то мы выберем, помадрится ФИ ровно в этом базисе диагонально с лямдами на диагонали. Просто это выникает непосредственно из вот этой вот санэкспрессии.
Таким образом круг мы завершили, и наш критерий вы доказали.
Еще раз я в заключение обращаю ваше внимание, свойство диагонализуемости оператора оно приятное тем, что во-первых с диагональной матрицей работать приятно,
во-вторых тем, что мы понимаем ясный геометрический смысл такого оператора.
Это просто растяжение вдоль оси, ну теперь уже возможно совпадающими факторами, совпадающими капицентными растяжениями, ну какая.
И вот мы сами знаем, что если характеристические многочлены линейно факторизуют и кратности корней совпадают, то автоматически ровно диагонализуют.
Ну в частности, если мы будем работать, например, над полем комплексных чисел, то первое условие выполнится естественно автоматически.
Правильно, мы знаем, что капель многочленов на Ц расправдывается на линейные совножения, и нужно будет проверять только второе дократных кратностей.
Вот на этом на сегодня все, в следующий раз мы поговорим о том, чего можно добиться, мы начнем разговор.
Если хотя бы характеристические многочлены линейно факторизуем, но оператор уже не делан.
На сегодня все.
Спасибо.
