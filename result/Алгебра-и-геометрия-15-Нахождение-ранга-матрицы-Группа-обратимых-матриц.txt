Так, добрый день, прошу прощения за опоздание. Давайте мы с вами будем продолжать. Мы закончили в прошлый раз
на том, что доказали теорему ранги матрицы и определили таким образом ранг матрицы.
Сегодня мы выясним, давайте все-таки это сниму, пока я далеко от вас, сегодня мы выясним каким
образом этот ранг искать, но перед этим хочется еще одну характеризацию ранга сообщить. Для этого нам
потребуется небольшое определение. Матрица A размера n на n, обратите внимание, я говорю про квадратную
матрицу, называется невырожденной, если ранг этой матрицы равен n. Больше чем n он, естественно,
быть не может, потому что в ней всего лишь навсего n строк или n столбцов, правильно? Когда он
достигает максимального возможного значения, матрица называется невырожденной. Сразу хочу сказать,
это понятие реже применяется к прямоугольным матрицам, если применяется, то имеется в виду,
конечно же, что матрица невырождена, когда она максимального возможного ранга для этого размера,
то есть сколько это будет, если это будет n на k? Минимум из n и k, правильно? Потому что ранг
все равно в любом случае не больше чем n и не больше чем k, когда он достигает,
тогда иногда тоже говорят, что матрица невырождена максимального возможного ранга.
Итак, значит теорема о базисном миноре. Что такое базисный минор, я сейчас скажу. Итак,
пусть A это некоторая матрица, не обязательно квадратная, возможно прямоугольная, ранга R,
тогда в A есть невырожденная подматрица размера R на R.
Давайте мы сразу оставим небольшое замечание, чтобы стало понятно, почему именно это факт нам
интересен. Естественно, если мы из матрицы выкинем строчку, строчный ранг этой матрицы не может
увеличиться, он может только уменьшиться, правильно? То же самое со столбцовым рангом
при выкидывании из столбца, ну а ранг у нас один и тот же, значит что строчный, что столбцовый.
В результате очевидное замечание при выкидывании строк из столбцов ранг не увеличивается, правильно?
Ранг не увеличивается, если матрица была ранга R, то при выкидывании из нее строки столбцов ее
ранг не может стать больше, чем R, то есть невырожденной матрице размера R плюс 1 вы уже точно не
получите, правильно? Потому что тогда у нее ранг был бы R плюс 1, а это невозможно. То есть вот этот
теоретическим наибольший ранг, который можно получить выкидыванием строки столбцов, и вот нам
говорят, что оказывается, матрица R на R обязательно найдется. Значит, невырожденной под матрице R плюс 1
на R плюс 1 не найдется. Ну вот я сформулировал теорему о базисном миноре в том виде, в котором
ее очень часто формулируют, на самом деле мы докажем несколько более сильный факт. Давайте я
его даже сформулирую, потому что иногда полезно пользоваться именно им. Что значит, что A это
матрица ранга R? Это значит, что в ней найдется система из R строк, которая будет линейно-независимой,
правильно? И найдется R столбцов, образующих линейно-независимую систему. Вот оказывается,
если вы такие найдете, R строк и R столбцов, то на них пересечение обязательно будет та матрица,
которая нам нужна. В этом и состоит усиление. Значит, еще раз, в матрице ранга R на пересечении R
линейно-независимых строк, давайте я формулирую кратко, но мы понимаем, что формально это означает R
строк, образующих линейно-независимую систему. И R линейно-независимых столбцов обязательно,
в пересечении, да, грамотно говорить, в пересечении R линейно-независимых строк и R линейно-независимых
столбцов обязательно образуется невырожденная подматрица. Вот я еще раз, я это подчеркнул на
доске, давайте я еще раз это словами скажу, условие, что ранга R важно. Если вы возьмете не R,
а, скажем, R-1 линейно-независимую строку и R-1 линейно-независимый столбец, вам никто
не гарантирует, что подматрица на пересечении будет невырожденной, только когда мы берем максимально
возможное количество. И, естественно, этим мы с вами сейчас будем пользоваться. Мы можем взять R-1
независимую строку и R-1 независимый столбец, на пересечение не обязана получиться невырожденная
подматрица. Там может получиться матрица меньшего ранга, чем R-1. А вот если мы берем именно столько,
каков ранг матрицы, вот тогда обязательно это будет. Вот, доказательства. Ну вот давайте я
доказательства оформлю на несколько формальном языке матриц, но я объясню, что за ним скрывается.
Значит, давайте мы ведем обозначение. А это наша матрица. Вот я рисую всю матрицу А. В ней есть
какие-то R-линейно-независимых строк. Давайте мы обозначим через B подматрицу из R-линейно-независимых
строк. Грубо говоря, вот у нас B. Эти строки могут идти не подряд, но давайте я схематично это буду
рисовать. C это подматрица из R-линейно-независимых столбцов. Вот у нас C. Ну а D это на их пересечении
та самая подматрица R на R, про которую нам нужно доказать, что она не вырождена. Их пересечение. Нам
хочется доказать, что D не вырожденная подматрица. Значит, давайте разбираться вот с чем. Как мы будем
пользоваться тем, что строк у нас именно R, а никак не меньше. Очень просто. Мы с вами берем R-линейно-независимых
строк. Если мы к этим R-строкам добавим еще одну строку матрицы A, получится уже зависимая система,
правильно? Потому что мы выбрали ранг именно строк. Это означает, что через строки B, мы с вами это
уже говорили, выражаются все строки матрицы A. Как это нам записать? Мы уже говорили, чтобы нам записать,
что строки A выражаются через строки B, мы можем написать, что A это матрица B, умноженная на какую-то
матрицу с какой стороны? Слева, правильно? Дайте я L умножить на B скажу. Когда я матрицу L умножаю на
строки на матрицу B, у меня получаются в полученной матрице линейные комбинации строк матрицы B. И,
естественно, как мы с вами в прошлый раз уже говорили, любые такие линейные комбинации мы
получить можем, то, что строки A выражаются через строки B, записывается ровно вот таким вот образом.
Аналогично, мы с вами знаем, что через столбцы матрицы C выражаются все столбцы матрицы A, то есть мы
можем написать A равно C умножить на какую-то другую матрицу, правильно? Значит, давайте я еще раз
напомню интуиции. В строках матрицы L что стоит? Коэффициенты, с которыми выражаются строки A через
вот эти вот базерсные строки, правильно? Мы говорим, что строка A это строка L умножить на матрицу B. То есть мы
взяли строки матрицы B с коэффициентами из строчки L. Вот здесь вот стоят те самые коэффициенты,
с помощью которых мы выражаем строки A через строки B. Аналогично в столбцах R стоят ровно
такие вот коэффициенты. Ну а теперь глядите, что мы можем сказать. Мы можем сказать, что если строки A
выражаются через строки B с какими-то коэффициентами, то, естественно, строки матрицы C будут выражаться
через строки матрицы D с теми же самыми коэффициентами, правильно? Строки матрицы C это
же просто части строк матрицы A, под строки, как бы, правильно? Естественно, они с теми же коэффициентами
будут выражаться через строчки D. Отсюда я могу написать, что строки C выражаются с теми же коэффициентами
через строки D. Я объяснил смысл эти коэффициентов из L, и поэтому вот то, что я написал, и значит с теми
же коэффициентами. Так, и так, строки C выражаются через строки D, а значит, здесь я могу заменить C на L, D.
Извините, равно просто, правильно? Здесь вот равно. Матрица A это L на D на R. Но мы с вами доказывали в
прошлый раз, что когда я буду брать ранг произведения матриц, он не превосходит ранга любого из
совмножителей, правильно? И значит, ранг A не превосходит ранга любого из этих трех
совмножителей, меня интересует ранг D. Но D это под матрица A. Мы с вами говорили, что ранг D не может
превосходить ранга A, правда? Ну, значит, ранг D равен рангу A, что мы и хотели доказать.
А, можно на правую, да, спасибо. Вот, значит, наша теорема уже доказана. Еще раз, смысл этой теоремы,
давайте я смысл доказательств еще раз вкратце намечу. Мы из матрицы D можем получить матрицу
A вот каким образом. Сначала мы получаем C, беря линейные комбинации строчек D, правильно? От этого
ранг не меняется, не добавляется. После этого мы добавляем столб C, беря линейные комбинации
столбцов C. При всех этих операциях ранг матрицы не увеличивается. Ну, значит, ранг A равен рангу D.
Можно вот это доказательство сформулировать еще и таким образом. Так, ну что ж, давайте двигаться
дальше. Следующий вопрос, разумеется, практически как найти ранг матрицы. Ответ на этот вопрос дают
следующие два утверждения. Утверждение первое. Я опять же таки сначала сформулирую не совсем
полную версию, потом я его уточню, потому что уточнение тоже очень полезно. Итак, ранг матрицы
не меняется при элементарных преобразованиях строк. Разумеется из столбцов тоже, правильно?
Поскольку строки из столбцы у нас аналогичны, если я буду брать элементарные преобразования строк,
или если я буду делать элементарные преобразования столбцов, ранг матрицы не меняется. Значит,
более точно давайте я сформулирую вот что. При элементарных преобразованиях строк
не меняются, внимание, линейные зависимости столбцов. Что это означает? Если в матрице А какие-то
столбцы были зависимы с какими-то коэффициентами, то есть можно было взять их линейную комбинацию с
коэф и получить ноль, то после элементарного преобразования эти же столбцы будут зависимы
с теми же самыми коэффициентами. Но естественно, из вот этого более точного утверждения следует
первое, если столбцы были линейно зависимы, они после элементарного преобразования останутся
линейно зависимыми. Если столбцы были линейно независимы, они остаются линейно независимыми
после преобразования, потому что линейные зависимости не меняются, они остаются, не исчезают и не появляются.
Ну и значит, если было R линейных независимых столбцов, то и останется R линейных независимых столбцов, но не больше.
Значит, первое утверждение следует из второго. Давайте мы это запишем, да?
Из второго сразу, но сказать это стоит. А второе доказать уже очень просто.
Значит, пусть столбцы A зависимы с какими-то коэффициентами.
Давайте мы все эти коэффициенты запишем в один столбец. Гамма – это столбец коэффициента.
Как нам это вкратце записать?
Что столбцы матрицы A линейно-зависимы, столбец коэффициентов – это гамма.
Что значит взять линейную комбинацию столбцов A с коэффициентами гамма?
Взять эти столбцы, умножить каждый на какую-то гамму И, сложить. Долго объясняем, да?
Проще говоря, если я A умножу на гамму, это же и есть взять линейную комбинацию столбцов A с коэффициентами из гаммы.
Получится нулевой столбец.
Ну пусть теперь S – это какая-то матрица элементарного преобразования.
То есть мы матрицу A, применяя элементарное преобразование, заменяем на матрицу S на A.
Но раз A гамма было равно нулю, то и SA на гамму тоже равно нулю, правда?
Это и означает, что линейная зависимость осталась той же самой.
То есть линейная зависимость сохранилась.
Все линейные зависимости сохранились, почему не появилось новых? Ровно так же.
Если у преобразованной матрицы есть какая-то линейная зависимость столбцов,
то есть если мы можем SA умножить на какой-то столбец гамму и получить ноль,
то мы можем совершить обратное элементарное преобразование.
Мы знаем, что все элементарные преобразования обратимы, все их матрицы тоже обратимы, правильно?
Мы можем домножить на S-1.
А это есть A гамма.
Таким образом мы понимаем, что если линейная зависимость столбцов сейчас есть,
то она и до преобразования тоже была.
А значит, линейные зависимости сохраняются.
Итак, линейные зависимости сохраняются, ранг матрицы сохраняется,
поэтому мы вполне можем применить к матрице метод гауса
и привести ее хотя бы к ступенчатому виду, дальше не надо.
А дальше вступает в силу второе утверждение,
что ранг ступенчатой матрицы равен числу ее ступенек.
То есть числу не нулевых строх, правильно?
Ну и после этого утверждения алгоритм нахождения ранга матрицы становится уже ясен.
Берем произвольную матрицу, приводим ее к ступенчатому виду, количество ступенек – это ответ, правильно?
Давайте мы это на всякий случай запишем.
Значит, приведя матрицу к ступенчатому виду,
элементарными преобразованиями строк, естественно, найдем ее ранг.
Обратите еще раз внимание, к упрощенному виду приводить не надо достаточно к ступенчатому, правильно?
Осталось доказать утверждение.
А когда у матрицы ранг равен количеству не нулевых строк ее?
Когда они все линейно независимы?
Ранг же – это наибольший размер независимой системы, которую мы можем выбрать.
Больше чем не нулевых строк мы не можем выбрать независимых строк, правильно?
Значит, нам нужно просто доказать, что эти строки линейно независимы.
Итак, давайте мы введем какие-нибудь обозначения.
Пусть у нас А – это ступенчатая матрица.
Давайте мы как-нибудь ступеньки обозначим.
Здесь А – первая строка, и столбец с номером G1.
Во второй строке главный элемент имеет номер G2.
И так далее.
В пятой строке главный элемент имеет номер G с индексом K.
Нам надо доказать, давайте мы это запишем,
что все не нулевые строки линейно независимы.
Давайте мы предположим, что это не так, и существует линейная зависимость.
Давайте я ее запишу следующим образом.
Сумма по И от 1 до K.
Гамма Ит – это коэффициент зависимости, умножается на Ит-ую строчку матрицы А.
Напоминаю, что Ит-ая строчка мы договаривались обозначать вот так вот, и со звездочкой.
Предположим, что они линейно зависимы, то есть эта линейная комбинация равна нулевой строке.
0 – это, естественно, нулевая строка.
И не все Гамма Ит нули.
Мы предположили, что у нас есть зависимость, то есть эта линейная комбинация нетривиальна.
Но тогда можно выбрать самые первые, не ноль.
Выберем наименьшее.
И такое, что Гамма Ит не ноль.
Ну давайте вот на рисунке, пусть у меня это И будет двойкой для порядка.
Мы знаем, что если я возьму линейную комбинацию элементов вот этого столбца, столбца с номером G2 в данном случае,
то есть G Ит-ая в нашем в общем случае.
Если я возьму линейную комбинацию вот этих вот элементов с коэффициентными Гаммами, Гамма Итами, то я получу ноль, правильно?
Потому что я линейную комбинацию всех строк беру, получаю ноль.
А как это будет выглядеть?
Первые элементы будут умножаться на Гамма с номерами меньшими, чем И, то есть теми, которые нули, правда?
Этот не нулевой элемент умножится на Гамма Ит, который не ноль и даст нам не ноль.
Следующие элементы здесь равны нулю, потому что у нас матрица ступенечная.
Давайте мы запишем это формально.
В столбце с номером G Ит-ая получим следующую вещь.
Значит, что ноль
Эта сумма по Слушайте, И плохо, да?
Давайте я сумму буду писать не по И, а по какому-нибудь Т.
Т от одного до К, Гамма Ит-ая, Гамма Т-ая, А с индексом Т, G Ит-ая.
Именно, да, я беру столбец с номером G Ит.
Ну, формально я могу написать так. Сумма по Т от единицы до И минус одного вот этих вот товарищей.
Плюс Гамма Ит на А и G Ит, да?
И плюс сумма по Т от И плюс одного до К того же самого.
Это вот я как раз разбил сумму на верхнюю часть, вот этот элемент и нижнюю часть, правильно?
Первая сумма равна нулю, потому что Гаммы равны нулю, по нашему выбору.
Последняя сумма равна нулю, потому что Ашки равны нулю.
Вот этот вот товарищ не равен нулю.
Мы выбрали И, так что Гамма Ит-ая не ноль, и А и G Ит-ая это главный элемент в еды строке, то есть он тоже не ноль.
Значит, вся эта сумма отлична от нуля. Противоречие.
Можно было бы и так, но и так, по-моему, достаточно просто, правильно?
В принципе, да, можно было бы и так с упрощенным видом, доказательство бы еще упростилось.
Но то он и упрощенный.
Замечательно, и мы с вами ранг матрицы умеем искать.
Более того, заметьте, пожалуйста, что наш алгоритм, вот глядите, нам говорят, что если ранг матрицы равен R,
то существует система, ну, существует линейно-независимая система из R столбцов.
И на самом деле мы ее этим алгоритмом тоже найдем.
То есть мы найдем не только ранг матрицы, но и то, какие именно столбцы в исходной матрице будут линейно-независимыми.
Мы сможем указать эти R линейно-независимых столбцов.
А именно это будут главные столбцы ступенчатой матрицы.
Если мы возьмем ступенчатую матрицу и возьмем ее главные столбцы, почему они будут образовывать линейно-независимую систему?
Потому что они по-прежнему будут образовывать ступенчатую матрицу, правильно?
Они будут образовывать ступенчатую матрицу с R ступеньками, и поэтому они будут по-прежнему линейно-независимыми.
Эта матрица будет иметь ранг R.
А в матрице A какие столбцы мы можем указать?
Столбцы с теми же самыми номерами, потому что мы знаем, что линейные зависимости столбцов не меняются, правильно?
Раз в полученной, в приведенной к ступенчатому виду матрице A, столбцы с такими номерами линейно-независимы, то и в исходной матрице A столбцы с теми же самыми номерами были линейно-независимыми.
И столбцы означат столбцы с теми же номерами в матрице A.
В частности, если угодно, это способ искать базисные столбцы в любой матрице.
В частности, если вам заданы, например, несколько векторов в пространстве своими координатами,
то базис своих линейной оболочки вы можете найти тем же самым способом.
Это вы просто можете записать их координаты в одну матрицу и найти ее базисные столбцы.
В частности, если у вас есть, давайте я сюда даже перейду, v1 и так далее, vm,
заданы вам, если вам заданы несколько векторов своими координатами в базисе,
скажем, e умножить на s, но это я и говорю, что эти векторы заданы координатами в каком-то базисе,
потому что каждый столбец матрицы s даст нам координатный столбец одного из этих векторов, правильно?
То базис линейной оболочки v1 и так далее vm образуют векторы, давайте мы это проговорим,
координатные столбцы которых будут базисными в s, то есть если мы возьмем матрицу s,
возьмем ее ранг, он естественно будет равен, напоминаю на всякий случай,
ранг s равен размерности линейной оболочки столбцов s,
ну то есть размерности линейной оболочки соответствующих векторов,
если мы возьмем столько независимых столбцов матрицы s,
соответствующие векторы будут образовывать базис вот этой вот линейной оболочки,
ну а такие столбцы в s мы только что искать научились,
знаете, вот подобный класс практических задач у нас с вами уже решается.
Давайте уж немножко дополним нашу теорию линейных уравнений,
теперь мы с вами можем сформулировать несколько теоретических утверждений,
связанных с этими системами,
дополнение про системы линейных уравнений, как ранг матрицы может прилагаться туда,
ну например, вот так, теорема, пусть у нас есть однородная система линейных уравнений,
мы ее записываем в матричном виде, как ax равно нулю, с n переменными,
ну то есть столбец x имеет длину n, мы с вами знаем, что тогда ее решения образуют
под пространство, в пространстве всех столбцов, давайте мы его обозначим через u,
u это пространство ее решений,
тогда размерность этого пространства это n-ранг A,
количество переменных минус ранг матрицы A,
доказательства, ну давайте мы сформулируем, что же такое размерность u,
размерность u равно количеству столбцов,
ну, количеству базисных векторов в базисе, правильно,
а базисные вектора это точности столбцы фундаментальной матрицы,
правильно, мы говорили, что фундаментальная матрица, как раз ее столбцы это базис пространства решений,
количество столбцов фундаментальной матрицы,
что такое количество столбцов фундаментальной матрицы, сколько их там будет,
вот в терминах нашего решения системы линейных уравнений,
спасибо, это мы только что уже написали, как его выразить через ступенчатый вид нашей матрицы,
неправда, количество свободных переменных, правильно,
количество столбцов фундаментальной матрицы это количество свободных переменных,
и мы знаем, что через свободные переменные все переменные выражаются правильно в решении,
ровно однозначно, и у нас там в матрице даже единичная матрица стояла на местах свободных переменных,
поэтому, конечно же, количество столбцов фундаментальной матрицы,
это то же самое, что количество свободных переменных,
количество это, естественно, n, главных переменных,
ну а главных переменных у нас по одной на ступеньку,
поэтому количество главных переменных это количество ступеней,
в ступенчатом виде нашей матрицы А, здесь у нас получается n минус количество ступенек,
в ступенчатом виде матрицы А, то есть в той ступенчатой матрице,
которой мы А приведем. Ну а мы с вами знаем, что количество ступенек – это ранг А.
Здесь у нас получается n-ранг А.
Размерность вот этого самого пространства мы с вами знаем.
Продолжаем разговор. Ещё одна важная, хотя и сейчас для нас уже простая, теорема.
Первая теорема была о однородных системах, сейчас будет о неоднородных.
Теорема носит имена двух математиков – Кроникер и Капелли.
Часто называют ее теорема Кроникер и Капелли, это два разных человека.
Если мы рассмотрим неоднородную систему, то иногда она будет совместна и иногда нет.
Теорема не в этом. Теорема о том, когда она совместна.
Система АХ равно B совместна тогда и только тогда, когда ранг матрицы системы, то есть матрица А,
равен рангу расширенной матрицы системы, то есть матрицы А с приписанной к ней столбцом B.
Доказательства можно вести на разных языках, но давайте я даже на языке системы линейных уравнений.
Давайте мы приведем расширенную матрицу нашей системы к ступенчатому виду.
Элементарными преобразованиями строк, естественно.
Если мы эту матрицу приведем к ступенчатому виду, то и матрица А тоже приведется к ступенчатому виду автоматически, правильно?
Тогда А тоже приведется к ступенчатому виду.
Ну и что тогда это значит?
Тогда ранг А равен рангу расширенной матрицы.
Как это условие понять?
Это означает, что в матрице А будет столько же ступенек, сколько в расширенной матрице.
Точнее, ступенчатом виде матрицы А будет столько же ступенек, сколько в ступенчатом виде расширенной матрицы.
А значит новые ступеньки в столбце свободных членов не появятся, правильно?
Нет ступеньки в столбце свободных членов.
Ну а это, как мы с вами говорили, в точности означает, что система совместна, потому что мы с вами говорили, что вот единственное противоречие, которое у нас может возникнуть, это когда мы получаем уравнение 0 равно не нулевой константе, то есть как раз ступеньку в столце свободных шлемов.
И таким образом наша теорема уже доказана.
На всякий случай давайте я скажу, что другое доказательство этой теоремы можно получить из более глубокого смысла системы уравнений.
Что означает решить эту систему? Это означает найти, как столбец В выражается через столбцы матрицы А.
Желающие могут довести это до другого доказательства теоремы Кроники Ракапелли.
Так, ну давайте мы продолжим.
Про ранг матрицы мы более-менее наверное сказали все, что хотели.
И в общем теперь мы про ранг, про систему линейных уравнений, в общем про метод Гаусса скорее даже.
Знаем достаточно, чтобы разобраться с еще одним вопросом.
Давайте мы выясним, какие матрицы, у каких матриц существует обратное, то есть какие матрицы обратимы.
Итак, мы выясняем, какие матрицы обратимы.
Говоря научным языком, давайте я заодно напомню это обозначение.
Иначе говоря, мы сейчас с вами ищем, знаете что, мы с вами ищем кольце матриц размера N на N.
Мы знаем, что это кольцо, их можно складывать, вычитать и перенажать друг с другом, правильно?
Кольце матриц мы ищем группу обратимых элементов. Да, это квадратные матрицы, только квадратные матрицы бывают обратимыми.
Сейчас я даже это напомню. Что значит, что матрица обратима?
Это значит, что матрица A обратима, это значит, что существует A в минус 1 такая, что их произведение в любом порядке равно E.
Но если матрица A будет не квадратной, то вот такие матрицы не могут иметь даже одного и того же размера.
Поэтому уж если матрица обратима вот в этом смысле, а это стандартный смысл, то она обязана быть квадратной.
Итак, мы с вами ищем вот такую вот группу. Давайте я сразу веду обозначение для нее стандартное.
Стандартное обозначение для этой группы выглядит вот так вот.
F это наше поле, N это размер наших матриц, буквы же L стоят для следующих двух слов, которые вы можете считать английскими, хотя изначально, насколько я понимаю, они все-таки считались французскими.
Как мы скоро с вами поймем, это общее линейное преобразование n-мерного пространства.
Оттуда берутся эти слова.
Вот пока что g, l, n, t в стандартное обозначение для группы обратимых матриц размера n на n.
Ну и мы хотим его, мы хотим элементы этой группы описать, и вот вам сразу несколько таких описаний.
Пусть A это матрица размера n на n над полем F, тогда равносильны следующие условия.
Первое условие A не вырождено, но, напоминаю, это означает, что ранг A равен вот тому самому n.
Второе условие, матрица A элементарными преобразованиями строк приводится к единичной матрице.
Можно совершить элементарные преобразования строк с матрицей A, получив единичную.
Третье условие, матрица A, есть произведение нескольких элементарных матриц.
Ну и четвертое и пятое условие, до которых мы как раз и хотели добраться.
Четвертое условие, матрица A обратима, и пятое условие, матрица A обратима слева или справа.
Что это означает? Обратимость матрицы слева означает, что существует матрица B, такая, чтобы A равно E.
Обратимость справа означала бы, что существует матрица B, такая, чтобы AB равно E.
Все эти 5 условий равносильны. В частности, я обращу внимание на несколько полезных равносильностей.
A обратима тогда и только тогда, когда A не вырождено, тогда и только тогда, когда A произведение элементарных матриц.
Любую матрицу можно разложить в произведении элементарных.
Ну и вот пятый пункт тоже полезен. Он говорит нам, что если вы выяснили для матрицы квадратной, что она обратима с одной стороны,
то автоматически тот самый обратный будет обратным с обеих сторон к этой матрице. Это тоже порой полезно.
Ну давайте доказывать на самом деле с высот той теории, с которой мы с вами уже познакомились.
Сейчас все шаги будут достаточно простыми. Мы сейчас быстренько пройдем по циклу.
То есть скажем, что из каждого условия следует следующее, а из пятого следует первое.
Мы с вами говорили, что в любом кольце группа обратимых элементов – это группа, а не пустая она, потому что там есть нейтральный элемент.
Тогда же и говорили, собственно. Правильно?
Вот так. Как у нас из первого свойства следует второе? Пусть матрица не вырождена.
Ранг A равен N. Приведем ее к упрощенному виду.
Ну естественно, как обычно, когда мы это говорим, мы подразумеваем, что мы это делаем элементарными преобразованиями строк.
А что такое этот упрощенный вид? У нас и ранг матрицы равен N. Это значит, что у нас будет N-ступенник, правильно?
И N главных переменных. Главных переменных, ну то есть главных столбцов.
N, то есть все столбцы главные, правильно? И они выглядят как столбцы единичной матрицы.
Ну значит у нас и получилась единичная матрица. Этот упрощенный вид – это E.
Просто каждый главный столбец у нас. Мы знаем, как выглядит в упрощенном виде.
А кроме главных столбцов у нас ни на что места и не осталось.
Таким образом, этот переход у нас уже доказан.
Так, доказываем из 2-го пунктов 3-ти. Пусть мы A каким угодно способом привели к виду E – элементарными преобразованиями строк.
Что это означает? Что означает применить к матрице элементарные преобразования строк?
Это нужно ножить ее слева, а не вверх.
Строк.
Что это означает? Что означает применить к матрице элементарные преобразования строк?
Это нужно ножить ее слева на элементарную матрицу, правильно?
Значит, если мы A привели единичные матрицы элементарными преобразованиями строк,
это значит, что мы A домножили на какие-то элементарные матрицы.
S1, потом на S2, потом и так далее, потом на SKT.
Так, чтобы получилось е.
Но мы с вами знаем, что все элементарные матрицы обратимы.
И поэтому это равенство мы сейчас можем домножить на обратное к ним.
В каком порядке мы будем это делать?
Сначала на SKT в минус 1 домножим, правильно?
Потом на SKT в минус 1 домножим и так далее.
И когда мы это все домножим, мы получим, что A есть.
S1 в минус 1, S2 в минус 1 и так далее, SKT в минус 1.
Но мы с вами знаем не только то, что элементарные матрицы обратимы, а что обратные тоже элементарны.
Поэтому третий пункт мы с вами уже доказали.
Все это элементарные матрицы.
Так, да, я там тоже должен был поставить такой пустой треугольничек, что этот пункт мы доказали.
Так, из третьего в четвертое.
Но мы снова пользуемся тем, что элементарные матрицы обратимы, правильно?
Если A это произведение каких-то элементарных матриц, то конечно же A в минус 1 это будет произведение их обратных.
В каком порядке? В обратном, правильно?
Мы с вами уже говорили.
S1 в минус 1.
Эти все, можно было так сказать, что раз эти все товарищи лежат в нашей группе, то естественно их произведение тоже лежит.
Часть доказательства того, что это группа.
Иначе говоря, мы это с вами получили из того, что мультипликативная группа кольца – это группа.
Так, самая сложная импликация.
Очевидно, правильно?
Уж если матрица обратима, то она обратима и слева, и справа.
И справа.
Наконец последний переход, который нам сейчас замкнет весь этот цикл.
Если мы с вами знаем, что скажем BA равно E, для обратимости справа рассуждение будет естественно аналогично,
то мы можем применить неравенство о рангах для произведения матриц.
Мы с вами знаем, что ранг E не превосходит ранга каждого из совножителей.
В частности, ранга A.
Но ранг E естественно равен N, а ранг A естественно не превосходит N.
Значит ранг A равен N.
Если матрица обратима хотя бы с одной стороны, это уже означает, что она не вырождена.
Для AB равна E будет то же самое.
Все, мы с вами доказали, что эти пять пунктов равносильны, и можем этим свободно пользоваться.
Поскольку был такой вопрос, да если бы его и не было, то я бы все равно оставил.
Давайте я оставлю такое упражнение.
Давайте мы предположим, что матрица A прямоугольная, типа обратима с левой и справа.
То есть пусть для этой матрицы существуют матрицы B и C, сейчас станет понятно в каких размерах,
такие что B это обратная матрица для A слева, C это обратная матрица для A справа.
Обратите, пожалуйста, внимание, я не пишу, что все это равно одному и тому же,
потому что здесь у меня написаны единичные матрицы разных размеров.
Здесь у меня размеры какие? У матрицы A каст толпцов, вот у этой матрицы тоже будет каст толпцов.
Значит, е, это е размера k на k, вот это е будет размера n на n.
Даже в таком случае это возможно только когда матрица квадрат.
Ну а разговор о обратимых матрицах стоит, конечно же, закончить алгоритмом для нахождения обратной матрицы.
Ещё раз, мы с вами знаем давным-давно, что если у матрицы, если у элемента группы есть левый обратный и правый обратный, то они совпадают.
Раз B это левый обратный, то она же будет и правая.
То есть, если вы нашли левую обратную, то AB тоже будет равно е.
Это вот так, для квадратных матриц, естественно.
Ну и давайте поймём, как, исходя из всего этого великолепия, находить A в минус 1.
На самом деле, вот здесь вот этот алгоритм уже написан.
Для ясности давайте мы его сформулируем вот как.
Давайте мы возьмём матрицу A и запишем вот какую матрицу A с приписанной к ней матрицей E.
И затем эту матрицу элементарными преобразованиями строк.
Если A в минус 1 существует, то значит, мы эту матрицу элементарными преобразованиями строк можем привести к такой, в которой в левой половине стоит E, правильно?
Это вот наш второй пункт. Приведём к матрице E.
Левую часть, правая часть приведётся к какой-то матрице B.
Тогда, на самом деле, B это A в минус 1.
Потому что, глядите, давайте посмотрим просто на наше доказательство.
Мы сказали, что A привелась к матрице E какими-то элементарными преобразованиями, домножением на какие-то элементарные матрицы.
Тогда A это произведение их обратных, а A в минус 1 у нас стоит ровно здесь, правильно?
Но давайте мы это проговорим.
Если мы применили какие-то элементарные преобразования к матрице A, получили E, то вот то, на что мы её домножили, это, разумеется, A в минус 1 хотя бы потому что левая обратная к A, правильно?
Как мы с вами только что говорили.
Ну а, что это означает?
Когда мы применяли элементарные преобразования к вот этой вот матрице, S1, когда мы применяем это к этой матрице, мы, по сути дела, применяем их и к матрице A, и к матрице E.
То есть, в первой половинке у нас получилось E, а в правой половинке у нас как раз получилось то, что будет из E. Получится из E применение вот этих вот матриц.
То есть, просто это произведение, правильно?
Вот таким образом вот этот метод нам даёт обратную матрицу.
Желающие могут на этот метод посмотреть и с другой стороны, вот разные взгляды на эти процессы бывают полезными, поэтому давайте я объясню этот же процесс чуть с другой стороны.
Мы справа от черты приписывали с вами столбцы свободных членов, правильно?
Можно рассмотреть этот процесс как решение систем нескольких линейных уравнений.
A на X равно первому столбцу единичной матрицы, A на X равно второму столбцу единичной матрицы и так далее.
И когда мы A приводим к единичному виду, то здесь стоят как раз решения этих систем, которые и образуют матрицу A-1.
Можно воспринять это вот в таком вот ключе.
Так, наверное, на этом про обратные матрицы я уже сказал всё, что хотел, и мы с вами переходим к новой теме.
Снова от матриц мы переходим к более абстрактным понятиям, к понятиям линейных пространств.
И следующая наша тема – сумма и пересечение подпространств.
Если у нас есть, давайте я опишу глобальную ситуацию, в которой мы находимся.
Если у нас есть какое-то V, это пространство, линейное пространство над полем F,
и пусть U1 и U2 – это два его подпространства.
Мы с вами будем сейчас по сути дела выяснять какие-то факты относительно того, как эти подпространства расположены друг относительно друга.
И первый шаг в этом – это если у нас есть два подпространства в одном и том же пространстве V, мы можем построить два новых подпространства.
Утверждение первое – если мы их пересечем, то тоже получим подпространство V.
Доказательства. Давайте мы, напоминаю, нам всегда нужно проверять, если у нас есть подпространство.
Первым делом нам нужно проверить, что оно не пусто, если мы хотим, чтобы у нас получилось подпространство.
Это пересечение, разумеется, не пусто, поскольку в нем есть 0, правильно?
Ну и дальше нам нужно проверить, напоминаю, что оно замкнуто относительно операций.
Ну и эта проверка, разумеется, непосредственна, правильно?
Если A и B лежат в пересечении, это значит, что они лежат в каждом из наших пространств.
A и B лежат в U1 и лежат в U2.
Ну это значит, что сумма этих векторов лежит тоже в U1 и лежит в U2.
Ну то есть эта сумма лежит в их пересечении.
Естественно, аналогично, если мы возьмем произвольный скаляр и произвольный вектор из пересечения,
то альфа на А тоже будет лежать в первом пространстве и во втором, а значит, и в их пересечении.
Итак, любые два подпространства можно пересечь и получить новое подпространство.
Мы с вами привыкли к тому, что к пересечению существует двойственная дополнительная операция, которая называется объединение.
Но объединение подпространств подпространством будет очень редко.
Желающие могут подумать когда и только.
Вот это вот и стоит проверить.
Поэтому вместо объединения у нас возникает другая операция.
Давайте я даже напишу определение, хотя в принципе это определение мы уже давали.
Пусть у1 и у2 это подпространство В, тогда их сумма это их сумма.
Ну то есть, напоминаю, мы с вами вот так вот договорились обозначать множество всех сумм элемента отсюда и элемента отсюда, правильно?
У1 лежит в У2.
Ну и естественно, определение это я дал, стоит доказать, что сумма двух подпространств также является подпространством В.
Ну давайте мы сразу докажем, то, что оно не пусто, очевидно, правильно?
Почему очевидно? Потому что ноль это сумма нуля и нуля, правда?
Опять же таки, проверяем замутность относительно операций.
Давайте мы возьмем два вектора в У1 плюс У2, давайте я вот так вот напишу сразу, и сразу распишу их по компонентам.
Если вектор А лежит в этой сумме, это значит, что он представляется в виде А1 плюс А2, где каждый из слагаемых лежит в соответствующем подпространстве, правильно?
И вектор В, лежащий там, также раскладывается вот в таком вот случае, в таком вот виде.
То есть если у нас в У1 плюс У2 лежат вот такие вот векторы, где АИТ и БИТ лежат естественно у ИТ, то сумма этих векторов мы ее можем перегруппировать следующим образом А1 плюс Б1 и плюс А2 плюс Б2.
Ну и разумеется, поскольку У1 было подпространством, то вот эта вот сумма лежит в У1, поскольку У2 было подпространством, то вот эта вот сумма лежит в У2. То есть это тоже лежит в сумме.
Естественно, совершенно аналогично проверяется, даже проще, проверяется замутность относительно умножения на скаляр.
Если я А1 плюс А2 умножу на скаляр, это будет А1 плюс А2. Этот товарищ лежит в У1, этот товарищ лежит в У2.
И мы наше утверждение догадали.
Итак, мы с вами ввели два понятия суммы и пересечения.
Ну, стоит, наверное, все-таки заметить.
Пересечение мы можем брать нескольких подпространств, и понятное дело, что это не зависит ни от чего.
Но давайте я на всякий случай все-таки скажу, что сумма подпространств – это операция ассоциативная, ну и коммутативная, естественно.
То есть если я буду складывать, например, три подпространства, то мне можно не ставить здесь скобки, потому что все равно это будет множеством всех сумм вот таких вот троек векторов.
И значит, как я здесь скобки не расставляю, все равно получится вот такое вот множество.
Поскольку сложение векторов ассоциативно, то и сложение подпространств тоже.
Это, кстати, вот общее свойство, которое часто стоит замечать.
Если у нас есть какие-то свойства операции с векторами, то они очень часто наследуются операциями с множествами векторов, вот такими как здесь.
Давайте я на самом деле это оформлю в качестве утверждения.
Другая характеризация суммы. Давайте я немножко по-другому опишу, что такое сумма.
Пусть у1 это подпространство, порожденное каким-то множеством s1, у2 это подпространство, порожденное каким-то множеством s2.
Ну, s1, s2 это какие-то подмножества в, разумеется, правильно?
Тогда сумма наших двух подпространств, можно сказать, что это линейная оболочка объединения, чтобы связать уж наконец сумму с тем объединением, о котором мы говорили,
или что то же самое, это линейная оболочка объединения вот этих вот порождающих множеств.
Доказательство очень простое.
Напоминаю, что такое линейная оболочка какого-то множества. Это самое маленькое подпространство, которое содержит это множество, правильно?
А с другой стороны, это набор, это множество всех линейных комбинаций элементов вот того, что у нас тут написано, правда?
Вот, из всего этого должно быть очевидно следующее. Во-первых, эта линейная оболочка лежит в этой линейной оболочке,
просто потому что мы сюда добавили еще каких-то векторов, правильно?
S1 содержится в U1, S2 содержится в U2. Дальше, вторая линейная оболочка содержится в сумме наших U1 и U2. Почему?
Потому что в сумме U1 и U2 содержится U1. Это правда?
Как нам получить любой вектор из U1? Прибавить к нему 0, правда? И содержится U2.
Это подпространство, содержащее вот это множество, правильно? А значит, содержит его линейную оболочку просто по определению нашей линейной оболочки.
Линейная оболочка – самое маленькое подпространство. Это содержится в U1 плюс U2.
Ну а с другой стороны, U1 плюс U2 содержится вот в такой вот линейной оболочке,
ибо векторы вот эти вот – линейная комбинация элементов S1 и S2, правда?
Векторы из U1 – это линейная комбинация элементов из S1. Векторы из U2 – это линейная комбинация элементов U2.
Значит, векторы из суммы – это линейная комбинация всего вот этого вот объединения.
Векторы U1 – это линейная комбинация элементов…
Так, векторы из U1 – это линейная комбинация элементов из S1.
Ну и все. Из этих включений, разумеется, следует, что все они равны.
Так, ну что ж, сумму мы с вами определили и даже описали ее свойства.
Естественно, ну давайте я в качестве следствия это напишу.
Если у Иты это линейная оболочка S1, то, разумеется, и сумма наших комбинаций,
то, разумеется, и сумма наших К, скажем, подпространств – это будет линейная оболочка объединения этих множеств.
Его следствие следует оттуда, поэтому я даже, наверное, не буду этого доказывать.
А следствие отсюда заключается в том, что размерность суммы мы можем оценить как сумму размерностей у Итых.
Как это следует оттуда? Мы можем в качестве S1 взять самое маленькое множество, которое порождает у Иты, то есть базис у Итым.
Если в качестве S1 взять базис у Итым, в любом подпространстве есть базис,
то мы с вами получим, что сумма наших подпространств U1 и т.д. плюс УКТ.
Так, давайте я вот это, то, что у меня написано справа, обозначу через D, например.
D U1 и т.д. плюс D UKT. Мы получим, что сумма наших подпространств порождена D векторами.
Ну а раз подпространство порождено D векторами, то его размерность не больше, чем D.
Хотя бы потому, что из этих векторов можно выбрать базис в этом пространстве.
Значит, размерность U1 и т.д. плюс UKT не превосходит D.
Так, продолжаем разговор.
А это мы сейчас как раз будем выяснять, ну точнее не сейчас, а больше на следующей лекции.
Этот вопрос мы как раз очень подробно выясним.
Если в этом неравенстве достигается равенство, это специальное понятие, о котором мы будем сейчас достаточно много говорить.
Но перед тем, как к нему ровно перейти, я сделаю замечательнее.
Если сумма U1 и U2 совпадает с суммой U1 и U3, разумеется, из этого внимания не следует, что U2 равно U3.
Давайте придумаем какой-нибудь простой пример.
Давайте возьмем двумерную плоскость и возьмем на ней три одномерных подпространства.
Подпространство в двумерной плоскости это прямая, проходящая через ноль, по сути дела, правильно?
Сумма любых двух разных прямых, это будет вся плоскость, потому что она будет спорождаться вот такими вот двумя векторами, правильно?
Здесь U1 плюс U2 и U1 плюс U3 и U2 плюс U3, все это будет вся наша плоскость.
Это все V2. В то же время эти подпространства, естественно, разные.
Ну и давайте я все-таки, особенно раз меня спросили, дам определение и начнем с этого, с этим работать понятием, но основная работа с тем понятием, которое я определю, конечно, будет завтра.
Итак, определение. Пусть U1 и так далее, Укатая, это подпространство В.
Мы хотим взять их сумму. И вот их сумма называется, вот давайте я сейчас избыточность немножко в речи скажу.
Я мог бы сказать, их сумма называется прямой, но у нас бывает слово прямая в другом смысле.
Поэтому давайте я скажу, их сумма называется прямой суммой, если выполнено вот какое свойство.
Глядите, мы с вами уже знаем, что любой вектор из суммы этих подпространств представляется в виде суммы k-векторов по одному из этих подпространств, правильно?
Так вот, сумма прямая, если такое представление для каждого вектора из их суммы единственное.
То есть для любого вектора V из этой суммы существует единственный набор U1 из U1, U2 из U2 и так далее, Укатая из Укатая, сумма которых равна V.
Таких, что V это U1 плюс и так далее плюс Укатая.
Значит, обозначение для этой прямой суммы, если сумма подпространств прямая,
то она записывается следующим образом.
То есть, по сути дела, когда я пишу вот такое вот выражение, я говорю, что мы рассматриваем сумму этих подпространств, и мы уже знаем, что она прямая.
Естественно, вот так вот ее записать тоже можно, но вот эта зависть подчеркивает, что эта сумма не простая, а прямая.
Ну и давайте, чтобы на определении не заканчивать, у нас еще одна минута есть вроде как, да? Нету? Есть.
Что докажем утверждение? Сумма подпространств прямая тогда и только тогда, когда существует единственный набор векторов из подпространств уитых, дающий в сумме нулевой вектор.
Иначе говоря, нам говорят, что любой вектор должен представляться единственным образом, а утверждение говорит, что это достаточно проверить для нулевого вектора, правильно?
Если нулевой вектор представляется единственным образом вот в таком вот виде, то и любой вектор представляется единственным образом.
Слева направо. Следствие очевидно, правильно? Раз уж любой вектор представляется, то и нулевой тоже.
Справа налево. Если какой-то вектор представился двумя способами, давайте вот я напишу эти два способа.
У1 пишет и т.д. плюс укатая и У1 штрих плюс и т.д. плюс укатая штрих. Естественно, каждый из слагаемых лежит в соответствующем подпространстве.
Вот это вот лежит в У1, это лежит в У1 тоже. То нам достаточно вычесть одно из этих представлений из другого.
Давайте мы вычтем правое из левого и получим, что У1 минус У1 штрих плюс У2 минус У2 штрих плюс и т.д. плюс укатая минус укатая штрих.
Это ноль. Если мы предположили, что ноль представляется единственным способом, то что же это за способ?
Это все нули, правильно? Вот этот вот единственный способ, это представление в виде суммы нескольких нулей, потому что нулитов уитых точно есть, правда?
Ну и мы с вами получили, что уитая минус уитая штрих это ноль, поскольку мы предполагаем, что ноль представляется единственным способом, естественно все эти слагаемые лежат в соответствующих подпространствах.
Ну а это значит, что уитая равно уитому штриху. Вот мы и проверили, что эти представления совпадают.
Утверждение доказано, более глубокие свойства прямой суммы. Следующий раз на сегодня все.
