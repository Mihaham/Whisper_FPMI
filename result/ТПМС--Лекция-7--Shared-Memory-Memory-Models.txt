так ладно давайте начинать анонс у нас сегодня три часа полтора часа и полтора часа и мы
собираемся поговорить про одну тему и то только наполовину поэтому пожалуйста это морально
подготовьтесь к этому и давайте я вас предупрежу и попрошу что ну во первых я предупрежу о том
что рассказ длинный и сложный и там возникает много наверное новых понятий вот оперативная
память всем элементах переполнится поэтому пожалуйста если у вас есть вопрос если вы
чего-то не понимаете то не думайте что дальше станет понятнее станет хуже поэтому вот сразу
задавайте вопросы иначе вся лекция пропадет итак давайте начинать наш тему сегодня наконец
модели согласованности памяти они у нас как-то появлялись в курсе так очень косвенно в некоторых
задачах на них ссылались иногда что про это говорил вы сами видели в документации про том
что там есть какие-то memory order в параметрах операций вот сегодня мы к этому немного прикоснемся
но начнем мы издалека вот смотрите узнаете ли вы эту штуку мы демонстрацию не видим вы не
видите демонстрацию это чертовски обидно если вы видите это в первый раз то тут уже поздно
это реализация мютокса которая была по ссылке задачи мютокс ну как там была скопирована
реализация скопирована она была из статьи которая называется фюдокса сатрики это статья одного
из мейнтейнеров ядра который пишет про то как пользоваться фюдоксами а именно как можно из
фюдокса смастерить взаимные исключения тут есть три версии одна лучше другой но вот это одна из
них и почему я ее показываю потому что она достаточно нетривиально но вот на прошлом семинаре
своем я разбирал если что есть запись этого семинара вы можете посмотреть но тут есть много
кассов они называются компресс чейнч это не важно совершенно есть атомик атомарный декремент
есть фюдокс и разобраться почему да и это реализация лока на трех состояниях 0 свободен 1
захвачен без контеншина 2 захвачен и есть ждущие потоки и вот в этой реализации есть некоторые
довольно тонкие моменты когда мы захватываем лог из нуля сразу состояние 2 но вот про это я
рассказывал сейчас не это важно сейчас важно что реализация нетривиальная и если вы пытаетесь в
ней разобраться возможно вы решая домашку пытались в ней разобраться то вы наверное
представляете что это делать сложно потому что тут много строчек довольно и вот сложно
перебрать в уме все их интерливинги все возможные переключения комбинации там все возможные
достижимые состояния ну сложно но все же возможно то есть что вы делаете у меня вы берете этот
мютокс этот код как будто бы его в голове там три раза копии там несколько раз копируете а потом
ходите курсором программы по вот этим копиям переключаясь с одной на другую вот так вы
моделируете исполнение программы вот пытаетесь в уме перебрать все возможные ее состояние
пришла пора поговорить о том что так делать нельзя что вот так на самом деле компьютер не
работает что вот так рассуждать об исполнении многопоточного кода несколько наивно ну почему
наивно давайте про разные моменты поговорим вот во первых у вас есть представление что вот
есть некоторая ячейка памяти разделяемая с которой вы работаете вот если разобраться как компьютер
устроен то окажется что вот ячейка это некоторая абстракция вот вы запускаете такой тест у вас
есть много ядер и вы пишете на разных ядрах один раз в одну ячейку свой номер а потом просто в
цикле читаете и вот какую картины вы наблюдаете вот разные разные ядра читают из одной и той же
ячейки в разные моменты времени в одни и те же моменты времени разные значения тут на самом
деле некоторая структура есть мы к этому вернемся но вот ячейка памяти это уже более сложный
объект чем мы наверное привыкли считать почему она такая сложная ну потому что есть гирянт почему
потому что есть киши потому что логическая ячейка воплощена в нескольких физических
представлениях нескольких копиях там кишей памяти и значение там могут вообще говоря разным есть
еще store buffer про них тоже поговорим в общем ячейка памяти не так проста дальше ну вот возьмем
такой наивный код а равно б плюс 1 б равно 1 компелируем его ну давайте я прямо покажу
во что мы его компелируем не в этом goodball все стер проклятие
ну не знаю давайте напишем его раз он все стер мне то
и что мы хотим написать вот такой вот код и скомпилируем его скажем gcc
ну вот смотрите что нетривиального здесь произошло вот у нас есть программа в которой
есть строчка а равно б плюс 1 запись в ячейку а запись в ячейку б а потом мы компелируем этот
код и что мы видим мы во первых загружаем значение из ячейки памяти б в регистр потом
мы сразу пишем в ячейку памяти б потом мы инкрементируем содержимое регистров которые
почитали значение б изначально потом мы пишем ячейку памяти а ну то есть вот у нас есть две
записи между ними есть точка запятой которая казалось бы определяет порядок следовании этих
записях но в память запись происходит в другом порядке довольно странно но тут смотрите компилятор
можно понять он действует довольно разумно он не нарушает наблюдаемое поведение однопоточной
программы но при этом если программа была многопоточная если две эти записи были
где-то скажем в циклическом буфере который в прошлый раз разбирали то если вдруг компилятор
решит переставить местами запись буфер и запись в атомик то что мы получаем мы получаем разломанную
синхронизацию вот еще один пример того что реальность отличается от наших ожиданий
дальше у нас есть процессор простите я слушаю эхо у кого-то в зале выключите пожалуйста
оператор возможно у тебя эхо и оно
но может потише сделать звук потому что немного мешает
значит смотрите во первых у нас есть немного сложный ячейка ячейка памяти
сложнее чем они думаем у нас есть компилятор который может в принципе приорды переставить
местами две записи программе кроме того у нас есть процессор который вот я вам явно в своей
документации говорить что есть некоторые программы которые ведут себя странно эта
программа мы уже разбирали здесь одно ядро пишет в икс читает из игрек а другое ядро пишет в
игре читает язык с асимметрично и в итоге программа наблюдает два нуля что в общем не объясняется
никаким разумным исполнением вот почему так получается но давайте как-то мотивируем такой
сценарий ну теперь уже это можно сделать смотрите мы знаем что в процессоре есть кэша что у каждого
ядра есть собственный кэш эти кэши нужно синхронизировать через некоторую шину памяти
через интерконнект что значит синхронизировать мы поддерживаем в кэшах следующие варианты что
у нас либо кэшли не актуальные совпадают с памятью и тогда она может находиться Safety
от содержимого памяти и тогда на может находиться только в одном ядре но такой эксклюзивное владение
разделяем стебель не эксклюзивное владение и для того чтобы эти варианты поддерживать
про ядром процессора нужно друг с другом коммуницировать по этой шине памяти если
мы пишем ячейку памяти, мы должны убедиться, что в других кышах нет ее копий. Поэтому что мы
делаем? Мы отправляем другим кышам сообщение инвалидации и ждем, пока нам ответят. В течение
этого времени процессор ядро простаивает. И вот почему образуется такое исполнение? Потому
что процессор хочет в таком сценарии сэкономить время простое. Каким образом? Он берет и помещает,
ну как бы не он процессор, инженеры помещают между ядром процессора и кышом storebuffer. И если ядро
хочет сделать запись в ячейку памяти и оказывается, что в кэше данного ядра кэш линий для этой ячейки
нет, потому что она находится у соседа, то мы запись помещаем в этот самый storebuffer. До протоколок
герентости она не доходит еще. А дальше мы читаем следующие инструкции, но инструкция как будто бы
завершает исполнение. Дальше мы читаем из другой ячейки памяти, и оказывается, что кэш линия с этой
ячейки у нас уже есть. И вот мы записали х, никому об этом не сказав на самом деле, другим ядрам
не сказав, и прочитали ноль из у. Ну а другое ядро поступает точно так же. Оно пишет в у,
которого у него нет, то есть кладет в свой storebuffer эту запись и читает из х ноль. Ну и вот мы получили
два нуля. То есть все довольно разумно, оптимизация работает, но правда порождает довольно странные
исполнения. В принципе ничего необычного, так примерно вот система контроля версии работает.
У вас есть ремут общий, но вы с ним, вы в него пока ничего не отправляете, вы делаете какие-то
модификации локальные и в итоге наблюдаете несколько несогласованную картину мира. Ну как
для вас это выглядит? Как будто бы в этой программе лот обогнал, опередил предшествующий ему
store. Вот вроде было бы написано запись, потом чтение, а на самом деле случилось как будто бы
чтение, а потом запись. Но вот этим можно было бы объяснить исполнение с двумя нулями. Но мы это
назовем так условно reordering, но на самом деле вы видите, что не то чтобы что-то местами переставилось,
каждое ядро исполняли инструкции по очереди, просто был вот этот самый store buffer. Почему вот такие
reordering нас волнует? Ну потому что, не знаю, мы рассматривали лок-петерсы не то чтобы самые
полезные программы на свете, но один из самых древних протоколов взаимного исключения. И довольно
обидно, что он не работает. Вот если мы рассмотрим ядро этого алгоритма, то у нас есть свой флажок,
есть флажок нашего конкурента, и мы пишем свой и читаем конкурента. И вот без дополнительных
усилий этот код ломается на нашем процессоре. Ну с другой стороны вы скажете, что пример довольно
странный, кому нужен лок-петерсон. Ну вот на этот случай у меня припустены два примера. Первый
это runtime языка Go. Вот просто мы открываем Go on Go на гитхабе, идем в runtime и смотрим, что вот
нам говорят, что на самом деле в runtime Go возникает ровно такой сценарий. Возникает он в сборке
мусора конкурентной. Если вы знаете про язык Go, то там есть сборка мусора, которое не ставит на
паузу исполнения вашей программы. Ну почти. То есть поток, который собирает мусор в памяти,
он, ну, горутина. Она работает конкурентно с горутинами, которые вы сами написали. Вот горутина
сборки мусора и горутина называют их мутаторы в вашей программе. Мутаторы модифицируют граф
ссылок в ваш, там, ссылок между вашими объектами. Коллектор собирает, обходит этот граф и красит
его там в три цвета. И возможен такой сценарий, когда мутатор, переставляя ссылку... Если мутатор
переставляет ссылки в графе, а коллектор обходит этот граф, то мутатор должен коллектору сообщать,
что граф изменился, что, там, какая-то ссылка переставилась. И вот может случиться такой
сценарий, что мутатор переставил ссылку, но не смог уведомить об этом коллектор, то есть коллектор
это не обнаружил эту измененную ссылку. Покрасил объект как обойденный, и вот по новой ссылке не
сходило. В итоге у вас, ну, не то чтобы утечка, вы не обошли живой объект, вы его потеряли. Это довольно
сложный сценарий, я сейчас не хочу его подробно разбирать, но вот суть такая. Граф поменялся,
коллектор этого не заметил, упустил живой объект. Память покорапчена. Другой пример, где возникает
вот такой вот сценарий, который мы называем store buffering, у него есть собственное имя, это реализация
фьютекса. Если вы ходили по ссылкам из условий домашней работы, ходили, читали комментарии в
там есть это не он, то опять же там об этом сообщают. Вот мы пишем ячейку с фьютекса,
с состоянием лока, у нас есть ячейка со счетчиком ждущих потоков, и вот если мы такую оптимизацию
делаем для фьютекса, то у нас получается ровный, например, store buffering, и если он не работает,
то наша взаимная блокировка подвисает. То есть лок освобождают, но при этом поток, который его
ждет, засыпает и не просыпается. То есть опять проблема ненадуманная, проблема действительно
влияет на синхронизацию, причем влияет на какие-то сложные системы. Но представьте, что у вас
разломался код в ядре линукса или разломался код в runtime go. Последствия будут очень серьезными.
И это всего лишь один сценарий reordering, когда последующий load обогнал, в кавычках,
предшествующий store. Это на самом деле единственный плохой сценарий, который на вашем интеле
реализуется. Но есть и другие архитектуры процессоров, и там гораздо больше сценариев, возможно.
Жить в таком мире, кажется, довольно сложно. Вот посмотрим на ARM. Вот на ARM можно написать
такую программу. У вас есть две ячейки памяти x и y, изначально равные нулю. На одном ядре вы
пишете в x единицу, на другом ядре вы читаете значение из x в регистр, а потом пишете прочитанные
значения в y. В третьем потоке вы читаете сначала из y, потом из x. И что вы ожидаете,
что если вы увидели в игре единицу, то в x вы уж точно ее увидите. Разумное же ожидание. Вот.
Но ARM говорит, что нет, не стоит такого ждать, потому что... Почему сейчас объясним? Не потому,
что он что-то местами переставил, а потому что оказывается, что в процессоре у разных ядер
иногда бывают общие storebuffers. И в итоге ваша запись одному ядру может быть видна,
а другого может быть не видна. И вот одни и те же записи, они могут быть видны разным ядром в
разном порядке. Довольно сложная ситуация. Вот. Смотрите. Совершенно непонятно, как в таком мире
жить. У нас есть процессор, который может переставить две записи в память. У нас есть
ячейка памяти, в которой много значений. У нас есть процессор, который во время исполнения что-то
странное с программой делает. Как-то инструкции переставляет, помещает их в storebuffer, скрывает
протокол гигиентности. На что вообще в таком мире можно опереться? И этот вопрос вот еще раз
непраздный. Вот представьте, что вы пишете ядро линукса, и вам нужно написать код, который будет
работать там на 30 разных архитектурах. А у вас каждая из этих архитектур с какими-то причудами.
Вот чертовски сложно. Ну ладно, мы здесь все-таки не пишем линукс, но в любом случае вы, как
разработчик, вряд ли хотите думать, когда вы пишете многопоточный код, о том, какой процессор
под вами находится. Как он именно там что-то риордерит, оптимизирует. Вы хотите, чтобы ваша
программа как-то предсказуемо исполнялась на любом процессоре. Это не значит одинаково, но все же
вы хотите иметь в голове какую-то модель исполнения вашей программы. Ну вот так мы
приходим к понятию о модели памяти. В зуме кто-то шумит, простите. Сейчас мы кого-то забаним.
Секундочку. Там есть кнопочка замутить. А я сейчас еще кого замутить? Алекс полигональный. Прощай.
Алекс. Все, шум пропал. Отлично, мы продолжаем. Итак, значит, мы понимаем, что мир устроен
сложно, что жить в нем непонятно как, поэтому мы хотим найти какую-то опору в этом мире. И эта
опора называется модель памяти или модель согласованности памяти, если быть совсем аккуратным.
Модель согласованности памяти в языке программирования — это просто составляющая
семантики языка. Она определяет смысл многопоточных программ. Что мы понимаем под исполнением
программы? Какой в ней вообще есть смысл? Вот формально говоря, до C++11 у многопоточных программ
на C++ не было семантики, не было смысла. Писать их кроссплатформенно было невозможно.
Как нам помогает модель памяти? Вот она задает семантику программ. Можно было бы считать так
наивно, что модель памяти говорит нам, в каком порядке выполняются чтения и записи в разделяемые
ячейки памяти из разных потоков при исполнении программы. Но так говорить не совсем корректно,
потому что сама постановка вопроса подразумевает, что вот есть некоторый порядок, в котором все
происходит. Можно чуть аккуратнее сказать, что модель памяти описывает все возможные исполнения
многопоточной программы. Это уже будет точнее, ближе к сути. Но, смотрите, вы, как наблюдатель
внешний, все равно вы не можете увидеть, как именно процессор что-то исполняет. В конце концов,
процессор устроен дико сложно. Все, что вы можете наблюдать на самом деле про исполнение программы,
это результаты чтений. Поэтому мы скажем, что модель памяти отвечает на такой вопрос. Какую
запись увидит конкретное чтение вашей программе? Какую запись оно вообще может увидеть? Это будет
еще аккуратнее. Ну, а если подойти с точки зрения практики, то вряд ли мы прям совсем угадываем,
что же увидит чтение. Мы пишем какой-то код синхронизации, пишем канал, например, для потоков
или для файберов. И вот мы ожидаем, что если один поток вызвал сент, а потом, нужно аккуратнее,
конечно, объяснить, а потом другой поток, другой файбер вызывает ресив, то мы, наверное, ожидаем,
что этот ресив увидит этот самый X, записанный в буфер канала. Поэтому совсем точно будет сказать,
что модель памяти объясняет нам, как гарантировать, что чтение в программе увидит какую-то запись
программе, какую-то запись, нужную этому чтению. Как гарантировать, что вот этот ресив, будучи
упорядочен во времени с сентом причинностью, увидит эту запись, этот сент XA? Вот это значит
семантика многопоточной программы, это значит модель памяти. Вот модель памяти нужна для того,
чтобы на такие вопросы отвечать. В принципе, на любой из них. Давайте я еще раз прокомментирую,
что в этой постановке значит нужную. Вот мы пишем спинлок, например. Вот чтение увидит нужную
запись для спинлока может означать следующее, что как гарантировать, что чтение в последующих
критических секциях увидит записи из предшествующих критических секций. Гарантия вот абсолютно
очевидная, да, но вот мы это принимаем как данность просто. Но вот еще раз, как данность
принимать больше ничего нельзя, потому что мы видим, что компьютер работает сложнее, поэтому
даже такие базовые очевидные гарантии мы с этого момента должны обеспечивать как-то,
понимать, откуда они именно берутся. Вот этим мы сегодня и займемся, а пока вот просто
некоторый перечень моделей памяти, с которыми вы можете столкнуться в жизни. Вот кажется,
что первый язык промышленный, в котором появилась модель памяти, который решил все-таки формально
описать семантику многопоточных программ, это была Джава. И вот смотрите, мы читаем модель памяти
Джавы, и тут написано, что вот о чем она. Модель памяти Джавы описывает все возможные исполнения
многопоточных программ. На всякий случай, вот давайте я покажу вам ее. Вот она, почему я начинаю
именно с нее, потому что мне кажется, что если вы решили изучить модель памяти, то модель памяти
Джавы — это, мне кажется, очень хороший первый шаг. Эта модель памяти, вообще говоря, она сложная,
но база ее, вот какая-то базовая часть, которую мы сегодня разберем, она очень простая и она очень
хорошо, очень компактно описана. Вот мне кажется, что если вы вот хотите изучить какую-то модель памяти,
то с Джавой очень неплохо было бы начать. Другой пример — язык ГО. Мы о нем часто вспоминаем,
потому что мы в этом курсе пишем файберы, которые грутины. Ну и вот смотрите, модель памяти ГО,
и тут написано, что. Модель памяти ГО описывает условия, при которых чтение переменной в одной
грутине гарантированно увидит запись значения, записанная в другой грутине. То есть как
гарантировать, что некоторое чтение увидит некоторую запись? Вот модель памяти ГО нужна для этого.
Но мы говорим вообще-то не только про языки программирования. Вот еще раз вспоминал, что
представим себе, что мы пишем Linux, под нами десятки разных архитектур, на всех мы должны
предсказуемо работать, поэтому и ядру Линукса нужна собственная модель памяти. Причем эта модель
памяти весьма и весьма сложная. Вот начинать с нее не стоит, конечно, но вообще-то это очень
хороший источник для того, чтобы понять, как модели памяти декларативные устроены. Но документация
сама огромная, просто посмотрите на размер ползунка здесь. Вот в ней, в этой документации очень-очень
много параграфов. Каждый из них описывает какую-то часть модели памяти. Короче, это сложно.
Ну двигаемся дальше по примерам. Linux C++. Ну вот C++ это с одной стороны самая продвинутая модель
памяти, а с другой стороны разбираться в ней чудовищно сложно, потому что она сильно размазана
по стандарту языка. Вот если в Java можно читать сверху вниз документацию и все будет ясно,
то C++ она как-то образом разрезана на части, разбросана по разным там параграфам главам
стандарта. Она сильно опфусцирована оптимизациями, удачными и неудачными. А кроме того, очень большая
беда с описанием этой модели в том, что в описании модели памяти нет мотивации, почему все именно так,
какие цели мы преследуем. Так что модели памяти C++, ну вот именно формально по стандарту,
скорее всего следует изучать в последнюю очередь, когда вы уже с какими-то более простыми примерами
разобрались. Ну вот как понять, что вы работаете с C++ с модели памяти? Ну вот вы пишете что-нибудь
такое, вы наверное уже так пробовали делать, но сегодня мы вообще говоря будем этого избегать.
Другой пример RAST. Вот с ним все довольно неожиданно, потому что в документации RAST написано,
что в RAST нет пока модели памяти. Это довольно странно, потому что RAST это система язык
программирования, которая нацелена на то, чтобы писать какой-то инфраструктурный код. Разумеется,
на нем нужно писать конкарнси, более того язык в какой-то степени создан для того, чтобы не
писать конкарнси, но при этом вот в языке модели памяти почему-то пока не хватает. Ну на самом деле
тут дело сложнее естественно. На самом деле RAST говорит, что он просто по умолчанию наследует
модели памяти из C++20. Но не потому что она особенно хороша, не потому что она проста и вообще
известно, что в ней дыры есть. Но дыры есть не только в модели памяти C++, а просто в любой модели
памяти, которая сейчас существует где-либо. В принципе, в самом подходе есть некоторые изъяны.
Поэтому в RAST пока используют по умолчанию модели памяти C++20, а потом однажды, если человечество
найдет какое-то более удачное решение, то RAST его задумывает. Почему есть вот некоторые проблемы в
модели памяти? Почему все там pretty bad? Потому что модели памяти C++ не справляется с некоторыми
странными частными случаями, которые можно прямо в стандарте найти. Там, не знаю, самое сбывающееся
пророчество, значение, возникающее из воздуха. Но это, кажется, тема для семинаров. В общем,
есть странные программы, для которых модели памяти ничего разумного сказать не может,
к сожалению. И вот они прямо в тексте стандарта, так захардкожен такие сценарии. Давайте я прямо
покажу это. Вот просто запрещаем такие программы, говорит нам стандарт. Довольно странно это выглядит,
но проблема не в C++, проблема бы фундаментально в подходе. Есть LVM. В конце концов, много языков
компилируются в LVM. Ему тоже нужна модель памяти, тоже нужна семантика для многопоточного кода,
ну и вот опять те же самые идеи, что и в C++ мы считаем. Ну и вот тут появляется Рома и рассказывает,
что есть еще и графические процессоры, и Рома. Да, я появляюсь. Ну да, помимо ЦПУ у нас есть ГПУ,
и как те, кто играет в игры, наверное, знают, у них тоже есть своя оперативная память,
видеопамять. И тоже есть свои кыши и свои причуды. Причуды эти на самом деле еще сложнее, чем даже
ARM. Ну конечно, чтобы со всем этим как-то работать, пиша программы для ГПУ, ну любому API нужна какая-то
модель памяти. Вот, как, например, тут Vulkan есть, у него, по-моему, более-менее хорошо в документации
это описано, но, конечно, у всего остального оно тоже есть. CUDA, если вы про нее слышали, ну те,
кто занимаются машинным обучением, скорее всего, слышали. OpenCL, ну и еще много у кого. Вот, и
сложность там состоит в том, что вот, надеюсь, все здесь уже решили задачу Spinlock, и там мы заметили,
что по умолчанию в C++ Memory Order стоит секция СТ. Это, собственно, то, что мы будем обсуждать на этой
лекции. Но вот GPU устроено гораздо сложнее, и там просто нету этого секции СТ, вот этого понятного,
приятного дефолта, который работает достаточно хорошо. И приходится каждый раз думать, когда
пишешь код. Это мало того, там еще и нету протокола когерентности кашей, но вот каши просто
некогерентные. А еще каши бывают в нескольких разных видов для разных данных. Совсем независимые
каши для разных видов данных. Ну, это что-то совсем взрывающее мозг. Вот тут, если сделать CTRL-F по visible,
вот Availability и Visibility. То есть, в принципе, эта модель памяти такая же, как в плюсах,
но из нее выкинули секцию СТ и добавили вот эти два понятия, которые как раз про управление
некогерентными кашами. Вот, в общем, тоже зверь страшный, сложный, и если вы планируете писать
какой-то, ну, достаточно сложный код для GPU, то тоже приходится знать. Вот, у меня все.
Спасибо, Рома. Рома нас, кажется, еще больше напугал. Но, смотрите, все не так плохо. Все не так
плохо говорит нам язык ГО, потому что он говорит нам следующее, что вообще-то можно даже не думать
про модели памяти. Ну вот, если вы не пишете сложные программы, если вы не пишете там какие-то
memory-order у Atomic, если вы используете просто там Mutex и Atomic как-то вот просто в лоб, то, ну,
можно не думать про все эти эффекты. Можно пользоваться моделью чередования. Вот, не умничайте
говорить нам язык ГО. И все плюс-плюс, это самая история. Ну, в самом деле, мы с вами решаем задачи,
в курсе пользуемся Atomic и работаем в модели чередования. Это вообще-то легально? Ну вот,
документация говорит нам, что да, легально. Что до тех пор, пока вы просто используете Mutex и
Atomic с memory-order sequential consistent, то вы можете думать об исполнении программы, как будто бы все
потоки, они просто вот переключаются друг на друга. И, в принципе, весь этот курс можно пройти целиком,
решить все задачи, не зная про модели памяти, не пользуясь memory-order и при этом код у вас будет
получаться корректный. Он, может быть, будет не самый оптимальный на свете, но, тем не менее,
оно будет корректным. Ну, и если вы все-таки решаете писать в memory-orders что-то другое,
то вот вам придется знать гораздо больше, чем сейчас. Собственно, про это лекция и там
последующие семинары. Ну, хорошо, значит, мы поговорили, какие проблемы возникают в процессорах,
в компиляторах, в графических процессорах. Мы поговорили, как модели памяти собирается эти
проблемы решать, точнее, не как, а вот как она собирается описывать семантику программ,
которые исполняются на таких процессорах. Ну, а теперь поговорим, как именно эта семантика будет
изложена в модели памяти. Есть, ну, я бы сказал, что два основных подхода. Есть операционный и
декларативный. Операционный про то, как программа исполняется, а декларативный про то,
как мы наблюдаем эти исполнения. Вот операционный подход. В чем он состоит? У вас есть какой-то
сложный процессор. Там какие-то, не знаю, сколько, миллиарды, сколько там транзисторов, какое-то
несметное число. Из них собраны какие-то сложные юниты. Там какие-то конвейеры сложные,
бранч-предикторы, кэши, синхронизация, конгелентность. Мы пытаемся обо всем этом не думать,
мы заменяем сложный процессор на абстрактную машину, которая строена гораздо проще, но которая
порождает те же самые исполнения, что и настоящий процессор. Подход очень естественный, если вы
вообще знаете про язык C++, потому что семантика всего C++ операционная. Вам говорят, вот некоторая
абстрактная машина, там есть там память, стеки, выравнивание, размеры, там все вот это. Вам как бы
говорят о том, как исполняется ваша программа. А дальше уже компилиатор работает над тем, чтобы
эта абстрактная машина, ну как бы гарантии этой абстрактной машины соблюдались на каждой конкретной
физической машине. Вот мы используем такой же подход только для многоточных программ. И вот
пример того, как может выглядеть операционный модель памяти для процессора Intel. У нас есть
разделяемая память, у нас есть ядра, и между ядром и памятью на запись стоит StoreBuffer. Когда
мы пишем, мы пишем в него. Потом и в n-шале он флажется в память. Когда мы читаем, мы читаем из
памяти или из StoreBuffer, где значение свежее. Вот эта схема вообще игнорирует наличие кэшей. И вот
протоколка герентности. Потому что протоколка герентности, он для нас, ну вот с точки зрения
memory, с точки зрения упорядочивания обращений к памяти, этот протокол прозрачен, кэши прозрачны.
Можно о них не думать. Проблему создают только StoreBuffer. Вот, но это очень простая операционная
модель. Потому что сам по себе процессор Intel дает довольно сильные гарантии на упорядочивание.
Но вот с ARM не так, с ARM сложнее, и модель памяти у ARM операционная совсем другая. Нам говорят,
что как будто вот представьте себе, что вот ядра вашего процессора организованы в некоторую
иерархию, в некоторое дерево. В корне этого дерева, ну вот внизу на картинке лежит память. В листьях
находится вот ядра с кэшами. И когда мы пишем что-то, то мы отправляем запись по этой иерархии вверх
плыть, ну или вниз по картинке. Вот она стекает вниз до корня. Когда мы читаем что-то, мы тоже
отправляем чтение, и оно пытается достичь корня, ну либо встречает по пути другую запись. И вот
можно этот пример с записями и чтениями разобрать вот так, чтобы здесь получилось 1.0. Как это может
получиться? Мы делаем запись на первом ядре, и она попадает сюда, вот в этот перекресток. Потом мы
делаем чтение на втором ядре, оно отправляется отсюда, встречает запись, читает единицу. Отлично.
Потом мы пишем что-то в Y, пишем эту самую единицу, которую мы прочли. Она отправляется отсюда. И вот
теперь здесь лежат и запись X, и запись Y. А потом мы с этого ядра читаем Y. Ну так получилось, что Y
долез до корня, спустился до корня раньше, чем запись X. И вот чтение Y увидело единицу, а
чтение X не увидело, потому что запись X находится все еще здесь. Ну разумеется, не то чтобы прямо по...
это некоторая модель, она упрощает работу реального процессора. Но вот эта модель порождает те же самые
исполнения, те же самые результаты, которые порождает настоящий процессор. И вот эти модели, они сильно
отличаются для Intel и для ARM. И в этом их проблема. Эти модели свои для каждого процессора, просто
исторически. Кроме того, вряд ли они нам бы пригодились для повседневного использования,
потому что они очень неинтуитивны, они порождают сложные исполнения, которые мы бы не хотели в
своих программах иметь. Так что если мы говорим про язык программирования, то операционный подход
нам вряд ли подойдет. Мы будем использовать другой подход, декларативный, который говорит не про то,
как программа исполняется, не про то, какие там возникают реордеринги, какие там есть store
buffer в процессоре. Декларативный подход говорит про порядки, про то, что хорошего в исполнении есть,
про гарантии, которые там точно соблюдаются. И вот этот подход, он на самом деле гораздо интуитивнее.
На практике нет. Мы сталкиваемся с некоторым сопротивлением ему. Но на самом деле,
если вы разберетесь, преодолете это сопротивление, то вы увидите, что этот подход гораздо естественнее,
но он выизвучивает естественно. Порядки – это положительные гарантии. В декларативном подходе мы
не думаем, как программа исполняется. Мы исполнение представляем себе в виде графа. Вот нужно сразу это
зафиксировать в себе уме. Исполнение – это граф. Его вершины – это обращение к памяти. Его дуги – это
те частичные порядки, которые в исполнении возникают. Вот те самые гарантии, которые были,
все упорядочивания, отношения, про которые здесь идет речь. Вот исполнение – это граф.
Дуги – это порядки. И чтобы вы мне поверили, исполнение в модели памяти C++ образовано вот
такими вот отношениями и порядками. Многопоточное исполнение программы в C++ – это совокупность
таких частичных порядков. Это не один поток сделал что-то, а потом другой поток сделал что-то. Это
граф. Звучит сложно, но так и должно быть. И более того, сложность появляется еще из-за того,
что большая часть языка использует операционную семантику. Вот вам стандарт описывает, как
программа исполняется. Вот некоторые машины абстрактные. А потом внезапно для некоторой
части языка, для многопоточных программ. Стиль изложения семантики резко меняется,
и мы теперь говорим про графы, а не про абстрактные машины. Вот ровно поэтому изучать модели памяти
сложно. Они непривычны, они не вписываются в то, как мы думаем про исполнение. Но ничего не
поделать. Такова жизнь, она вот видите сложная, то есть программы исполняются сложным на реальном
железе и описываются, исполнять их программ тоже сложно. Но если вы откроете модели памяти для
любого современного языка, то то, что вы там увидите будет гораздо проще выглядеть. Что вы
там увидите? Вы увидите следующее, что исполнение, какую гарантию вам дает модель памяти языка чаще
всего. Оно вам не говорит, что вот графы сразу, там какие-нибудь порядки, риордеринги,
стурбафер нет. Вам говорят, что исполнение программы неотличимо от некоторого последовательного
исполнения, в котором обращение к памяти из каждого потока выполняются в порядке их следования
в тексте программы. То есть вам говорят, модель чередования. Лесли Лэмпорт, вы его наблюдаете,
потому что это ему именно принадлежит термин sequential consistency. Вот это определение,
определение sequential consistency. Прокомментирую это определение. Что значит исполнение программы
неотличимо от некоторого последовательного? Это означает, что он наблюдает результаты
и только по ним может косвенно судить о порядке. Так вот, неотличимо означает следующее,
что чтение в исполнении увидит те же значения, что и при некотором последовательном исполнении.
При этом это не означает, что язык программирования обещает вам исполнять программу
последовательно. Нет, он наоборот этого не хочет, но хочет, чтобы у вас была простая модель
чередования в голове. Собственно, я вам показывал это выше, когда говорил про не умничайте. Вот,
модель памяти C++ вам это и сообщает, что если вы используете просто mutex и memory order
sequential consistency, то вы получаете модель чередования. Вот ровно то, что нам говорит Лесли Лэмпорт.
Но беда в том, что компьютеры так не работают. Поэтому возникает разумный вопрос, а как же
согласовать не sequential и consistent компьютеры, процессоры, и sequential и consistent модель памяти?
И для того, чтобы можно было получить сильные гарантии на процессоре со слабыми гарантиями,
процессор вам выдает специальные инструкции, которые называются memory barriers или memory fences,
барьеры памяти. У каждого процессора они свои, но суть их примерно одинаковая. Если очень грубо
говорить, то барьеры запрещают некоторые типы орденгов. Реальность сильно сложнее. Семантика
барьеров специфична для процессора, и нужно читать конкретные мануалы. Ну вот, скажем, на x86
барьер памяти — это mfence. Вот мы компилируем такую программу, компилируем ее там на GCC в какой-то
версии, получаем запись move для записи, потом mfence, потом move для чтения. И вот этот mfence,
он запрещает реордерить условно две инструкции. Ну, фактически он сбрасывает storebuffer в память,
в киши, в протокол к гириантности. В общем случае рассуждать про барьеры памяти сложно. В линуксе
есть отличная документация про барьеры памяти, она вот тоже гигантская. Тут еще много графики. В общем,
это сложно. Это сложно, причем сами разработчики хедра этого не отрицают, потому что они пишут,
что вот этой инструкцией можно пугать детей. Ну, хорошо. Может быть, по-другому скажу. Барьеры
памяти есть, они действительно сложны. И в конце концов, с помощью барьеров памяти, язык
программирования, компилятор собирается обеспечить нам вот такую гарантию sequential
consistency на не sequentially consistent процессоре. Но возникает вопрос, а как именно он,
собственно, эту гарантию собирается обеспечить? Компилятор. Потому что, если он просто будет
расставлять барьеры повсюду, то он слишком сильно замедлит нашу программу. Он должен действовать
как-то умнее. И вот здесь возникает главный трейдов в моделях памяти. Смотрите, чего мы хотим.
С одной стороны, мы хотим иметь очень простую семантику для программ многопоточных, sequential
consistency, исполнение неотличимо от последовательного. Но мы при этом также хотим, чтобы программа
исполнялась быстро. То есть, чтобы и процессор реордерил инструкции, и компилятор что-то переставлял
при компиляции. И вот эти цели, они выглядят плохо совместимыми, они противоположны и просто.
Простая семантика – это отсутствие реордерингов. Оптимизация – это реордеринги. Вот. И возникает
потребность чем-то пожертвовать, потому что цели, ну, вот, противоположны. И вопрос, вот чем мы
собираемся жертвовать? Либо семантикой простой, либо оптимизациями. Ну, ответ, на самом деле,
хитрее. Он называется sequential consistency для datarace-free programs, для программ свободных отгонок,
и в этой модели мы собираемся жертвовать не оптимизациями и не простой семантикой,
мы собираемся жертвовать программами. Мы говорим, что очень накладно гарантировать sequential
consistency для любой программы, которую можно написать. Мы будем гарантировать sequential
consistency только для разумных программ. Программ, в которых написана корректная синхронизация.
Ну, это пока неформально очень, непонятно, что значит корректная. Вот, формальное определение
у нас будет звучать так. Корректная программа – программа без гонок, без dataraces. Ну, вот,
чтобы определить datarace, нужно будет приложить усилия еще. Ну, вот, интуиция за вот таким вот
ограничением, за сужением класса программ. Вот, оказывается, что корректно синхронизированные
программы, в них есть некоторые паттерны. Обращение с памятью. И эти паттерны устроены так,
что если компилятор с помощью разработчика про них узнает, то он сможет расставить в программе
довольно небольшое количество барьеров. И, с одной стороны, программист получит простую семантику,
а, с другой стороны, у процессора останется возможность ордерить инструкции. Просто за счет
того, что мы ограничили класс программ. Вот, значит, гарантия модели памяти,
которая называется sequential consistency для программ свободных отгонок. Если в программе нет гонок,
то она допускает только последовательно согласованные исполнения. Вот это наша цель.
И вот такова гарантия модели памяти любого современного языка. Java, Go, C++, что угодно.
Правда, пока мы не можем определить гонку, мы пока скажем не строго, что гонку образуют два
неупорядочных синхронизации обращения к ячейке памяти, среди которых, по крайней мере, одно
обращение — это запись. Ну и, на всякий случай, вот подтверждение того, что C++ ровно это вам
обещает. Он говорит, что если вы используете Mutex и Atomic с дефолтным Memory Order, то вы получаете
sequential consistency, то есть простой интерливинг потоков, но только если в вашей программе нет гонок.
Это важно. То есть вы, как бы, реализуя синхронизацию, на самом деле заключаете
некоторый контракт с компилятором и процессором. Вот вы обещаете компилятору написать корректно
синхронизированный код. А компилятор и процессор обязуются выполнить, со своей стороны обязуются
выполнить ваш корректный код таким образом, что вы не заметите никаких риордрингов в компиляторе
и в процессоре, собственно. И вот это соглашение между вами и компилятором и процессором фиксируется
в стандарте языка. Вот оно. Но если вдруг вы свою сторону контракта нарушите, свое обещание нарушите,
то во время исполнения никто ничего проверять не будет. Если у вас есть датарейсы, то вы лишаетесь
всех гарантий, вы получаете уб. Ну это довольно разумно. Undefined Behaviour — это вот такая
оптимизация для компилятора, которая позволяет ему не делать все возможные проверки. Все-таки
что-то компилятор не проверяет, значит, на это работает программа быстрее. Ну вот здесь компилятор
не будет проверять, что... компилятор не будет гениливать проверки, которые убеждаются, что
действительно вы пишете корректно синхронизированный код. Ну а что значит УБЭА? Что же на самом деле
произойдет? Ну, в принципе, по стандарту непонятно, что произойдет. А в реальности произойдет то,
что вы станете наблюдать риордерники, которые возникают в процессоре. Ну то есть вы потеряете
гарантию и будете наблюдать, скажем, два нуля в программе. Собственно, я показывал вам этот
пример. Мы пишем программу на C++, пишем там две чеки памяти, пишем в одну читаемую с другой. И вот
очевидно, в этой программе есть датарейсы. Вот эта запись гоняется с этим чтением. И вот мы запускаем
эту программу и в ней undefined behavior, в ней датарейсы. Ну и что же происходит? Рано или поздно эта
программа ломается, потому что она порождает два нуля. Ну то есть мы потеряли разумную гарантию,
мы потеряли модель переключений, модель чередования. Вот УБЭА примерно в этом состоит.
Ну что ж, давайте теперь поговорим. Все оставшееся время мы будем говорить о том,
как вот эту гарантию обеспечить. Это и есть наша сегодняшняя цель. Есть вопросы пока? Все понятно.
Ну хорошо. Как устроена такая модель памяти? Ну давайте сначала перечислим всех действующих
лиц. Вот кто участвует во всем этом процессе. Смотрите, у нас есть, во-первых, разработчик,
во-вторых, процессор, а в-третьих, между ними есть модель памяти, ну вот компилятор, разработчик
модели памяти, разработчик языка. И вот вы разработчик языка и с одной стороны вы от процессора
получаете через какие-то мануалы операционную модель памяти, то есть риордеринги, которые процессор
может выполнять, барьеры, которые можно в этом процессоре вставить. А с другой стороны вы от
программиста, который пишет код, получаете некоторые ожидания, на какие гарантии в своей
программе он все-таки хочет рассчитывать. Ну скажем, он ожидает, что если он сделал запись в ячейку памяти
в критической секции, то он потом в следующей секции эту запись увидит. Довольно разумное
требование. И вот мы от программистов получаем требования от модели памяти, от процессоров,
от инженеров, которые строят процессоры, мы получаем, как бы, описание реальности. Какие
риордеринги есть, какие барьеры есть. А дальше мы выдаем программисту какие-то декларативные
гарантии в собственном модели памяти, то есть некоторые гарантии видимости, выраженные через
частичные порядки. На что в исполнении программы программист может полагаться в виде стандарта
языка. А в сторону компилятора мы отправляем, не так, а через компилятор мы, разработчики
языкопрограммирования, эти гарантии реализуем на конкретных процессорах. То есть мы пишем компилятор
для данного процессора, который вот эти декларативные гарантии реализуют через барьеры.
Хорошо. Что же мы будем делать сегодня? Мы будем придумывать вот такие гарантии. Вот мы подумаем
про наши программы, подумаем про код, который мы пишем, и попытаемся из этих программ извлечь
некоторые паттерны, некоторые гарантии, которые мы там может быть неявно ожидаем при исполнении
программы. И эти гарантии должны быть сформулированы, должны быть формулизованы в виде частичных
порядков на обращениях к памяти, в виде частичных порядков, которые будут ограничивать чтение. Ну,
то есть мы потребуем, чтобы чтение в программе были согласованы с этими порядками. То есть,
если в программе реализовался некоторый порядок частичный, в нашем уме как бы реализовался,
то чтение не может пойти с ним в разрез. Ну, а дальше мы потребуем, чтобы компилятор каким-то
образом эти гарантии, которые мы придумаем, обеспечил на процессоре с помощью барьеров.
Конечно, непонятно, почему у него это получится сделать, но я в конце смогу объяснить, наверное,
интуитивно, почему получится. Ну и смотрите, какие цели мы будем преследовать, выдумывая гарантии.
С одной стороны, мы должны придумать такие требования, такие частичные порядки, чтобы
их было достаточно, чтобы они в совокупности давали видимость прямо последовательного исполнения.
Но с другой стороны, чем меньше стрелок в графе исполнения мы нарисуем,
чем меньше стрелок, которые будут фиксировать порядки между обращениями памяти, мы вставим
в исполнение, тем интуитивно больше реордерингов мы дадим процессору при исполнении.
Ну и где-то во всем этом процессе придумывания таких гарантий, таких порядков, мы должны
воспользоваться тем, что мы ограничили себя только программами свободными от гонок.
Ну что ж, теперь можно начать. Если все вступление длинное понятно,
что мы хотим сделать, то можно переходить к сути, а именно вот к выдумыванию таких гарантий.
Мы сегодня будем эти гарантии иллюстрировать на двух примерах, на моделях памяти двух языков,
C++ и Java. Они во многом похожи. На всякий случай и та, и другая модель памяти сложнее, чем то,
что будет изложено сегодня. Сегодня будет такой общий знаменатель, но при этом я вас не обману.
Это общая идея, она реализуется и в одном, и в другом языке. Ну а может быть, я сейчас кого-то
разочарую, но вот сегодня мы говорим только про Memory Order of Sequential Consistency. Нам бы с ним
разобраться. Более слабые Memory Order мы пока отложим, но в конце лекции я объясню,
как они устроены. Вот буквально за один слайд. Но почти все время я буду говорить только про
дефолтный Memory Order. Итак, как для нас разработчиков модели памяти выглядит программа? Программа
оперирует разделяемыми ячейками памяти. Ну и в программе есть некоторый поток управления,
циклы, условия и так далее. Мы пока игнорируем запуск join потоков, примитивы синхронизации,
какие-то сложные атомарные операции. В C++ еще есть отдельные операции барьеры. То есть мы это все
учтем в модели памяти, но потом, когда будет для этого возможность. Пока думаем только про самые
простые программы. И в этих программах многопоточных потоки обращаются к разделяемым
ячейкам памяти. И эти обращения иногда конфликтуют. Мы скажем, что два обращения к памяти конфликтуют,
если они обращаются к одной ячейке памяти и, по крайней мере, одно из этих обращений — это
запись. То есть конфликтует запись и запись, конфликтует запись и чтение, чтение и чтение не
конфликтует. Ну и вот примеры определения конфликтов в двух моделях памяти — в C++ и в Java. Конфликт
довольно фундаментальное понятие для всех моделей памяти. А дальше на основе понятия конфликта мы
разделим ячейки в корректно синхронизированных программах на два класса. Есть разделяемые ячейки,
которые используются для синхронизации. Ну скажем, ячейка locked спинлоки. Вот конфликтующие обращения
к ней в программе не упорядочены. Ну естественно, потому что мы с помощью нее и упорядочиваем
остальные обращения. А вот если мы посмотрим, скажем, на какую-нибудь ячейку памяти в, там,
я не знаю, в односвязном списке, который мы защищаем спинлоком, то конфликтующие обращения
на вот голове этого списка, они уже будут упорядочены. Будут упорядочены самим спинлоком.
Идея понятна? Как мы разделяем два типа ячеек? Вот. Нет. Ну смотри, у тебя поток сначала пишет,
а потом читает. Два этих обращения не конфликтует, но не упорядочены самим потоком.
Ты взял Mutex, записал в ячейку X, потом ты взял Mutex, прочитал из ячейки X. Запись в X и
чтение из X конфликтует, но гонки нет, потому что они упорядочены Mutex. Да? Вот, собственно,
в этом и разница. Вот флажок locked в спинлоке к нему обращаются неупорядоченно, а к ячейке,
которая защищена спинлоком, обращаются уже упорядочно. И смотрите, мы поделим все разделяемые
ячейки в программе на два класса, и ячейки первого класса, которые используются для синхронизации,
мы явно в программе аннотируем. Мы скажем, что это не просто Bool или Int, это Atomic Bool или Atomic Int.
В компьютере и Atomic Bool и Bool представляются одинаково, одним машинным словом. Но вот нам
такая аннотация нужна, тем не менее. Если говорить про Java, то вот такие Atomic в Java выглядит
как Volatile. Но, пожалуйста, в C++ у Volatile такой семантики нет. В C++ у Volatile уже практически
не нужен. Вам в Volatile он не нужен почти что. Concurrency он не имеет никакого отношения в C++,
а в Java это синоним Atomic. Зачем нам нужно явно аннотировать вот такие вот ячейки памяти,
для которых конфликтующие обращения неупорядочены? Спойлер, именно вокруг этих
Atomic компилятор и собирается ставить барьеры. Вот еще раз наша цель – ставить в программе как
можно меньше барьеров. Вот барьеры будут только рядом с Atomic. Ну а теперь давайте выдумывать
требования, гарантии, частичные порядки, которые мы ожидаем от ячеек памяти в исполнении,
от исполнения. Гарантии будет три у нас. Вот мы делаем первый шаг, первую гарантию,
придумываем первый порядок. Итак, смотрим на ячейку памяти. Я сказал, что она устроена
сложнее, чем мы думаем. У ячейки памяти логической может быть несколько физических воплощений,
одно воплощение в памяти, непосредственно другие в кышах. И вот мы пишем тест. У нас много ядер,
каждый ядро пишет сначала в ячейку памяти свое значение, а потом эти значения читает.
Потом значения читает в цикле. И вот какие значения мы наблюдаем. С одной стороны, довольно
сложно, потому что один поток, одно ядро думает, что в ячейке 2, а другой думает,
что 3, а другой думает, что 10, а другой думает, что 9, и другой думает, что 12. Но все же картинка
не совсем произвольная. Ну вот можно заметить, что, смотрите, тут есть такие пары, да? Откуда
эти пары берутся, понимаете вы или нет? Ну вот это соседний ядра с общим буфером, вероятно. А
еще в этой картинке есть некоторая структура, некоторая гарантия в ней видна сразу. Можете ли
вы ее обнаружить? Ну то есть, смотрите, каждое ядро читает какую-то свою историю изменения,
но эти истории, они в некотором смысле согласованы. Но в конце мы приходим к одному значению,
но это еще не все. Вот смотрите, чего мы ожидаем? Мы ожидаем на самом деле, что на каждом отдельном
атомике есть некоторый сквозной порядок модификаций. У каждого атомика есть история изменений,
и каждый поток читает некоторую монотонную подысторию этой одной сквозной истории. Понятно?
Вот эту историю записей в пределах каждого отдельного внимания атомика мы назовем
modification order. Это первый частичный порядок, который возникает в исполнении для нас.
Вот мы хотим придумывать гарантии частичных порядков. Давайте я к этому вернусь. Вот,
и первый из них это modification order. Но внимание, modification order не означает, что есть какой-то
сквозной порядок на разных атомиках. Вот, скажем, modification order не противоречит примеру store
buffering, где мы читали два нуля. В примере store buffering мы пишем в X, читаем из Y, пишем в Y,
читаем из X, получаем два нуля. У каждой ячейки есть modification order. Правда, не атомики. Смотрите,
тут сложно проиллюстрировать на программе, потому что мы пока говорим про такой C++,
который мы строим сами. Но вот store buffering в этот пример не противоречит modification order.
В store buffering у атомика сначала было значение ноль, потом стало единица. И каждый поток прочел ноль.
Это подыстория истории ноль и единица. Так что modification order — это sequentially consistent ячейка
памяти, но совокупность атомиков sequentially consistent уже не будет. Это понятно?
Понятно? Да. Хорошо, давайте сделаем перерыв сейчас. Мы простую часть закончили, а дальше будет уже
чуть сложнее. Встретимся через 10 минут. Ну что, мы продолжаем. И, кажется, у нас есть какие-то
вопросы в перерыве были, да, у кого-то? Нет? Вопрос откатили? Ну что ж, обидно. Тогда,
ещё раз, на чем мы остановились? Мы готовим модель памяти. Мы хотим получить вот такую гарантию,
что если в программе нет гонок, то она допускает только последовательно согласованные исполнения,
то есть ее исполнение неотличимо от некоторого последовательного. И мы эту гарантию хотим
обеспечить, выдумав какое-то количество частичных порядков, которые будут ограничивать допустимые
чтения в программе. Вот модель памяти должна отвечать на вопрос, что увидит каждое чтение.
Вот мы с помощью частичных порядков ограничиваем, что может увидеть каждое чтение. И мы
вот придумали первое ограничение. Да, и вот эти ограничения должны быть такими, что с одной
стороны, они в сумме, в совокупности должны нам дать вот эту простую семантику последовательного
исполнения, а с другой стороны, они должны быть все-таки частичными, чтобы допустить какие-то
реордеринги во время исполнения. И вот первое. Мы дали понятие конфликта, разделили чеки на два
класса, сказали, что вот есть атомики, и первая гарантия, первый частичный порядок, он был на
записях в каждый отдельный атомик. Мы сказали, что у каждого отдельного атомика есть история
записей, и что все потоки наблюдают некоторые подысторию этой записи. И тут отмечено, что вот
каждый атомик – это sequential и consistent ячейка в памяти, в том смысле, что modification order – он,
конечно же, уважает порядок записи в атомик из каждого отдельного потока. То есть, если поток
пишет один раз, потом другой раз, то, конечно же, в modification order эти записи будут идти именно в
таком порядке. Вот. И все это вместе, при этом, не складывается в некоторый глобальный порядок,
это важно. Ну вот такое ожидание, оно довольно естественное. Вот почему мы можем такие картинки
наблюдать? Потому что store buffer есть. Но с другой стороны, store buffer сами по себе вот такую
гарантию не ломают. Так что она довольно естественная. Довольно естественно ее потребовать,
потому что процессоры ее, вот, очевидно, будут соблюдать так, уж они устроены. Следующая гарантия,
ну, вернее, ожидание. Вот посмотрим на псевдокод. Тут есть поток T и T', producer и consumer. И что
делает producer? Он пишет в некоторый буфер какие-то данные, там, неатомарные. А потом ставит флажок.
Что вот данные готовы. Consumer читает этот флажок, и если он видит, что в этом флажке написано true,
то он читает из буфера. И, конечно же, когда мы смотрим на такой код, то очень естественно ожидать,
что чтение из буфера в потоке T', непременно увидит запись в буфер, сделанный в потоке T'.
Почему мы этого ожидаем? Ну, смотрите, вот мы читаем из буфера. Как мы вообще до этого дошли?
Видимо, мы перед этим прочли значение из флажка и прошли там true. А почему мы там прочли true? Откуда
там взялась эта true? Ну, видимо, здесь другой поток T' записал вот этот флажок что-то. Но,
судя по коду, перед тем, как он записал флажок, поток T' должен был записать в буфер.
И вот такими рассуждениями мы приходим к выводу о том, что, видимо, запись в буфер
предшествовала чтению из буфера. Произошла до чтения из буфера. Разумное ожидание. Но оно выглядит
совершенно тривиально, но, с другой стороны, мы выяснили, что даже самых простых вещей ожидать
не стоит просто так. Так что мы должны каким-то образом... Ну, то есть что мы хотим сейчас? Мы
хотим вот это ожидание как-то формализовать. Ну, сейчас давайте к этому придем. Где такой паттерн
реализуется? Вот в прошлый раз мы смотрели на циклический буфер для двух потоков. Одного
продюсера, одного консюмера. И вот один поток писал в буфер и двигал вперед tail. Другой поток
читал head и tail. И если видел, что tail впереди head, очередь не пустая, то читал из head. Ну вот,
это ровно такой сценарий. Если мы дошли сюда и читаем из слота 42, потому что мы увидели tail,
по крайней мере, 43, то, видимо, мы уверены, что другой поток, продюсер, уже в слот 42 что-то
написал. Вот такой сценарий, который мы назовем message pressing. Передача сообщения. Ну вот,
здесь он как бы совсем в лоб выражен. Но, скажем, вот посмотрите на spin lock. Видите ли вы message
pressing в spin lock? Смотри, у нас message pressing про неатомарные обращения к памяти. Вот неатомарные
обращения к памяти, вот неатомарные. А где здесь неатомарные обращения к памяти? Ну вот да,
смотрите, мы читаем что-то под spin lock. Ну вот мы, не знаю, берем spin lock и видим, что у нас буфер,
не знаю, какой-нибудь список не пуст. Что это означает? Видимо, мы ожидаем, что другой поток
в предшествующей критической секции, в этот список что-то положил и отпустил lock. Отпустил
lock, то есть записал во флажок false. А другой поток, раз он в критической секции сейчас читает этот
список, он должен был перед этим прочесть из флажка этот false. Ну плюс, атомарно перезаписать,
и вот, извините, прочесть. Вот здесь мы записали, а здесь мы прочли. И вот мы ожидаем теперь, что мы
увидим запись, сделанную в предшествующей секции. Разумно? Разумно. Причем это тот же самый
сценарий message passing. И вот мы хотим его формализовать. Нам нужно как-то строго описать в модели памяти
языка, что вот есть такая гарантия, что здесь мы увидим то, что было написано в предшествующей
секции. Что здесь мы увидим то, что было написано здесь. Нам нужно просто формальные правила,
некоторый частичный порядок, и он называется happens before. В чем замысел? Ну, happens before – это
понятие, которое берется, вообще говоря, в распределённых системах, оно там появилось,
и с помощью этого понятия люди описывают отношения событий, ну, во времени или скорее в смысле
причинности. Ну вот, смотрите, распределённая система состоит из узлов, вот у каждого из них
свой таймлайн, и эти узлы обмениваются сообщениями, отправляют, получают. И мы вот хотели бы какие-то
два события сравнить между собой, что было раньше, а что позже. Вот есть некоторая фундаментальная беда,
с этого начнётся следующий курс про распределённые системы, что в распределённой системе нельзя
синхронизировать часы, невозможно это сделать. Поэтому на время на часы полагаться нельзя. Так
что мы рассуждение о времени заменяем рассуждением о причинности. Вот мы вводим понятие happens
before на событиях, частичный порядок на событиях в распределённой системе. Мы скажем, что если у
нас событие A предшествовало событию B в пределах одного узла, ну, то есть узел сначала сделал A,
потом сделал B, то, разумеется, A happens before B, А случилось до B. Кажется, это сомнений не вызывает.
Вот вы зашли в аудиторию до того, как вы сели на стул в аудитории. Это очень естественно. Дальше,
если A — это событие отправки сообщения, а B — это получение сообщения другим узлом. Ну,
в смысле, вы отправили сообщение, а B, потом другой узел получил это сообщение, то мы снова скажем,
что A happens before B. Разумеется, сообщение не может идти во времени назад. Ну, а дальше мы вот эти
два частных случая замыкаем по транзитивности. И вот транзитивное замыкание — это и есть
транзитивное замыкание этих двух случаев, и есть определение happens before. Определение happens
before — оно отражает причины событий. Вот смотрите, у нас есть вот это событие и вот это событие. Что мы
можем про них сказать? Что это событие могло стать причиной этого события. Ну, потому что вот как-то
вот так вот повлиял. Ну, или, не знаю, вот так вот повлиял. Или это событие могло стать причиной этого
события, потому что вот так вот. Это на самом деле очень напоминает аналогии из теории относительности.
Прям очень сильно. Ну, мы говорим про время и про причинность, еще бы оно не упоминало. Смотрите,
а вот есть такое событие и вот такое событие. Ну, вот с одной стороны, это событие во времени
предшествует этому. Ну, вот я потому что-то картинку нарисовал. Я знаю. Но узлы этого сами понять
не могут. И с точки зрения happens before, эти события, они конкурентны, они неупорядочены. Одно не может
зависеть от другого. Ну, просто вот эта причина, эта связь, она нигде не… она не выражена в передаче
сообщения, она не могла возникнуть. Определение понятно? Тогда мы сейчас, вот это happens before
произошло до вот это определение хотим перенести на модель разделяемой памяти и сказать, что если
вот запись в буфер произошла до happens before, чтение из буфера, то чтение из буфера непременно увидит
эту запись. Но вот чтобы так сделать, нужно понять, а как переформулировать happens before для модели
разделяемой памяти, где у нас есть ячейки и потоки. Вот что такое локальный шаг узла потока и что
такое отправка получения сообщения. Вот что мы сейчас хотим сделать. Что такое локальный шаг
узла? Это очень простой вопрос. Ну, вот поток, не знаю, взял spin lock, потом он, не знаю,
алоцировал новый узел, прицепил его к началу списка, поменял голову, потом отпустил spin lock.
Вот мы скажем, что между этими операциями, конечно, между этими обращениями памяти есть
happens before, но чуть конкретнее есть program order. Порядок, который описывает, но порядок,
который фиксирует порядок обращений к памяти в каждом отдельном потоке. Вот у нас был
modification order, это порядок записи в Atomic из разных потоков. И у каждого потока есть program order,
просто порядок, в котором этот поток, порядок, в котором в этом потоке написаны все обращения
к памяти. В C++ он называется sequence of before. Ну и смотрите, что важно, что program order — это
не порядок, в котором обращения к памяти исполняются. Это просто порядок, который вот в тексте
программы есть. Исполняться инструкция могут быть в другом порядке. Ну, вот я показывал вам пример,
вот запись в A, запись в A, запись в B. Вот запись в A предшествует в program order записи в B,
просто потому что первая строчка написана в программе до второй строчки. Но исполняться эти
записи могут в другом порядке, тут противоречия никакого нет. Согласны? Этот пример мы видели,
program order до этого не видели. Вот, и мой point в том, что program order, он не требует от, ни от кого не
требует, в общем, исполнять обращение в каком-то порядке. Это просто некоторая фиксация порядка,
который заложен в тексте программы. Это не порядок во времени, это порядок в тексте программы.
Дальше у нас есть вторая половина определения happens before — это отправка сообщения. Ну и вот
вопрос, как выглядит отправка сообщения в многопоточной программе? Что такое сообщение,
что такое отправка, что такое получение? Ну вот, сообщение — это будет значение,
которое мы пишем в атоме. Когда мы отправляем значение, значит, что мы пишем в атоме. Когда
поток читает это значение, записанное ранее стором, то он его получает, сообщение доставляется. Вот
сообщение, вот его отправка — стор, вот его получение — лот. Может быть сложнее. Вот если мы
говорим про спинлок, то смотрите, у нас здесь поток, который отпускает спинлок, говорит стор там 0,
а поток, который захватывает спинлок, говорит exchange 1. Вот exchange — это сложная операция,
она и читает, и пишет. Но в данном случае она в том числе читает, и вот в этом чтении оно
получает сообщение, которое отправил он в лот. Согласны? И вот, мы теперь введем еще одну
конструкцию вспомогательную — отношение synchronize the Swiss. Мы скажем, что, пусть мы скажем сначала,
что A — это некоторая запись в атомик, а пусть B — это чтение в другом потоке из этого атомика.
И мы скажем, что запись в атомик A синхронизировалась с чтением из атомика B,
если B прочитала значение, записанное A. Ну вот это чтение получило эту запись.
Возникла синхронизация Swiss. Разумеется, одно и то же сообщение, вот можно отправить сообщение один
раз, а получить его несколько раз. Правда? Ну вот тогда у нас одна запись станет началом
сразу нескольких красных вот таких вот дуг. Ну, с последней записям в modification order.
Это мы пропустим. Как различать их? Ну вот program order — это частичный порядок на обращениях
памяти в пределах одного потока и порядок вообще на обращениях в тексте программы.
SYNCHRONIZATION Swiss — это отношение на парах запись чтения из разных поток. И вот мы, в общем-то,
получили две составляющих happens before. А теперь мы просто замыкаем их по транзитивности. Вот пусть
поток T пишет в ячейку памяти, потом взводит атомарный флажок, потом другой поток читает из
этого флажка и видит записанное значение true, и тогда между этой записью и этим чтением возникает
happens before. Вот это еще один частичный порядок. То есть стрелька SYNCHRONIZATION Swiss идут от
стора ко всем лодам из этого атомика. Нет, не ко всем лодам из этого атомика. Мы соединяем
пару стор и лод, если лод прочитал значение, записанное вот этим стором. Должен прочитать.
Он не должен никому. Вот я в одном потоке написал стор, в другом написал лод. Лод может увидеть
запись из стора, а может не увидеть. В одном случае возникнет отношение, в другом не возникнет.
То есть мы уже определяем после исполнения программы?
Ну, после исполнения реализуется, и вот в нем возникают такие стрелки или не возникают?
А, я думаю, мы их проводим по ходу.
Ну, это… Смотри, я же говорил, что если чтение B прочитало записи, сделанную A. В смысле,
если чтение B прочитало значение, записанное A, вот тогда и возникает. Откуда мы знаем,
что она прочитала на самом деле? Пока программу не запустим, не узнаем. Вот мы запускаем программу,
и в ней реализуется некоторый модификацион ордер. В ней реализуется некоторая… ну,
некоторые пары синхроназисуис, какие именно зависят конкретного запуска, конкретного исполнения.
То есть можно я на минутку влезу и скажу, что, ну да, действительно можно вот очень по тупому
представить, что мы запустили программу, как-то волшебным образом всю историю,
что происходило в компьютере, записали, и смотря на эту историю, рисуем все вот эти вот графы,
порядки… Ром, я против, потому что нет некой истории, в этом беда.
Ну нету, да. Поэтому волшебная. Хорошо вы.
А как мы тогда можем провести несколько стрелочек из одной вершины?
Ну, один поток записал в ячейку true, а потом много потоков прочитало это значение.
А, то есть нам не важно… Тут нам уже не важно, в каком порядке они прочитали.
Еще раз, тут вообще не про пары, речь пары. Вот у тебя есть запись в программе,
у тебя есть чтение в Atomic, и если чтение прочитало значение, записанное записью,
то возниклась синхроназисуис между двумя обращениями к Atomic. Вот,
определение про пару. Таких пар может быть много.
Да, хорошо, понял. Вот. И не знаю, почему вы так
зацепились за текст программы. Текст программы был только в одном определении,
пока в программ-ордере. Больше нигде его не было и не будет. Все остальное мы говорим
про исполнение. Ну, в смысле, про то, что реализуется во время исполнения.
Если есть еще один поток, который положил true, как мы сделаем, что это сделаем?
Ну, еще раз, у каждого Atomic есть modification order. Вот то значение, в смысле,
ту запись, в которой чтение прочлось, той оно и синхронизируется.
Ты не понимаешь, какая это будет запись, ну и неважно, какая это из двух.
Тут просто очень сложно говорить про какие-то искусственные синтетические
примеры. Вот в разумных программах всегда можно объяснить, что происходит.
Поэтому лучше на каком-то разумном коде это все показывать. В смысле,
вопросы такие, да. Ну, короче, вот какая запись была последней
модификацион ордере, тут ты ее увидишь. Ну, в смысле, стоит и синхронизируешься.
И вот транзитивно замкнули, получили happens before, да. Вот это еще одна гарантия.
Мы требуем, чтобы чтение из ячеек памяти были бы согласованы с happens before.
Сейчас к этому вернусь. Сначала, определение happens before, которое вы можете найти в модели
памяти. Ну, вот мы открываем модели памяти Джавы, и вот happens before тут буквально...
Так не работает. Буквально это и видим. Все плывет. Вот, у нас есть два обращения к памяти.
x и y называются здесь экшенами. Мы скажем, что у нас реализуется частичный порядок.
Частичный порядок связывает x и y. Если x и y – это действие одного потока, и x предшествует y
просто в программ-ордере, в тексте программы, мы скажем, что a happens before, b... Ну, пропустим
этот странный пункт. x синхронизируется с y, если... Я соберусь. Если есть между x и y
программ-ордер, то это happens before. Если между x и y есть синхронизация с y, то это happens before.
Ну, и если транзитивность, то happens before. Вот, ровно определение из модели памяти Джавы.
В C++ все очень сложно, и там... Ну, я покажу один раз, а потом, может быть, нам посчастливится на
семинаре посмотреть. А может быть, и обойдется, кто знает. В C++ определение happens before абсолютно
душераздирающее, к нему есть длинные комментарии, которые объясняют, почему так получилось. Но из
него все равно мало, чтобы будет понятно. Короче, в определенных предположениях можно считать,
что в C++ тоже так. Но в C++ есть некоторые тонкости, которые, вообще говоря, уже можно даже и не знать,
и если эти тонкости, как бы, забыть про них, то определение будет таким. Так что я вас немного
обманываю формально, но по существу не обманываю. То есть вы можете жить с таким определением всю
жизнь и, скорее всего, не пострадать. Ну и что мы, собственно, говорим под тем, что чтение согласован
из happens before? Мы говорим, что если мы читаем вот здесь, вот из ячейки дата, и это чтение упорядочено
через happens before с записью в ячейку дата, не атомную, не атомик, то это чтение обязано увидеть эту
запись. Довольно разумное ожидание. Собственно, мы к этому и шли. Мы хотели его формализовать,
вот мы формализовали. Согласны? Вот как можно это нагрядно себя представлять? Если вы что-то писали в
одном потоке, потом поставили флажок, а потом в другом потоке вы из этого флажка не прочли вот
это значение, вам так случилось, что прочли его, то вот эти записи, они как будто бы перетекают по
вот этому ребру Synchronize the Swiss в другой поток, и там становятся видны. Ну и вот примеры опять из
модели памяти C++ Java, где вот гарантируется, что там сайд-эффекты или записи будут видны через
happens before. Опять давайте я на Java покажу. Вот, если у вас два обращения к памяти упорядочились
через happens before, то первое обращение видно второму обращению. Видно, в смысле, чтению видно.
Ну и как мы собираемся использовать это в спинлоке? Ну, собственно, всё уже в успех. Мы в критической
секции сделали записи в разделяемой ячейке, потом мы отпустили спинлок и записали туда 0,
ячейку locked, потом другой поток Exchange прочитал из этой ячейки 0, когда он прочитал из ячейки 0
и записал туда 1, то вот здесь возникла Synchronize the Swiss, между предшествующей секцией и последующей
возникла happens before, и вот следующая секция, она благополучно читает записи, сделанные предыдущей
секцией. Вот мы теперь способны объяснить, почему взаимное исключение работает, почему Mutex работает.
Правда, вот во всём этом есть некоторый баг, мы кое-что упустили. Вот такое требование, оно
оно не учитывает один случай. Требование неволидно пока. Смотрите, мы требуем, чтобы
чтение увидело последнюю предшествующую в happens before запись, да? Но happens before – это же частичный
порядок, и ничто не запрещает какому-то чтению в программе иметь две разные ветки happens before,
которые в него входят, и тогда непонятно, какая запись была последней предшествующей в happens
before. Что делать? Мы запрещаем такие программы, мы говорим, что они неправильные, они не
вписываются в наши ожидания, они не синхронизируют некоторые обращения. Вот у нас есть пара записей,
которые друг с другом не упорядочились. Если бы они были упорядочены, то одно бы из них стало
последним, а другое перестало бы быть последним. А пока они оба последние, между ними есть гонка.
Ну и вот мы говорили, что давным-давно, час назад, что мы придумываем порядки, мы придумываем
требования к программе, и где-то мы должны учесть, что мы сужаем класс программ до программ свободных
от гонок. Вот чтобы сформулировать, что чтение согласован из happens before, мы вот ровно в этом
месте и пользуемся тем, что в программах наших гонок не бывает, что мы их запретили. Ну и да,
раз уж мы здесь, можно теперь определить понятие о гонке, собственно. Вот у нас было определение
конфликта, что два обращения к памяти конфликтуют, если они обращаются к одной и той же ячейке,
по крайней мере, одной из этих обращений — запись. И мы скажем, что гонка — это два конфликтующих,
ни от амарных, ни через anatомик, то есть обращения, которые неупорядочены через
happens before. Вот это уже строгое определение гонки. Вот, пожалуйста, определение из C++ и из Java.
Ну давайте опять найдем. Вот два конфликтующих обращения, которые ну просто так же неупорядочно
через happens before образуют гонку. В C++, ну надеюсь, что тоже простое будет написано. Исполнение
программы содержит гонку, видите, очень аккуратно. Исполнение содержит гонку, может и не содержать,
в принципе, для одной и той же программы, если она содержит два конфликтующих,
упорядоченных, конфликтующих конкурентных обращения, по крайней мере, о господи,
одно из которых не anatomic, и которые неупорядочно через happens before. Дальше не хочу читать дальше.
Вот. Ну опять, в C++ много всего происходит, поэтому много всего нужно, строго говоря, упомянуть. Но
суть остается такой же. Два конфликтующих, неатомарных обращения к памяти, неупорядоченные через
happens before. И если вы пользуетесь в курсе thread sanitizer, а вы пользуетесь им против своей воли,
то вот thread sanitizer ищет в вашем исполнении гонки вот буквально по определению. Он ищет обращения,
пары обращений, которые неупорядочены через happens before. Ну и пара замечаний про
happens before. Опять, happens before не требует, чтобы обращения к памяти прямо исполнялись в таком
порядке. Вот у вас есть программа, в ней A пишем в A, пишем в B. Между этими обращениями есть
программ order, то есть есть happens before, но исполняться они могут в другом порядке. Это не проблема.
Мы не требуем, чтобы вот happens before всё исполнялось в таком порядке. Мы требуем,
чтобы чтения были согласованы с ним. Это некоторое более слабое требование. Ну и смотрите ещё что,
что happens before оторвано от времени. Если вы записали в атомик, ой, вне атомика что-то,
а потом через полчаса прочли из него, но без синхронизации, то это всё равно датарейс.
Happens before всё равно нет. То есть произошло до, но happens before нет. Ну в смысле произошло до
времени, но причинности не реализовалось, поэтому happens before нет. Итак, мы придумали две гарантии,
два частичных порядка. Modification order — это порядок записи в каждый атомик, и мы потребовали,
чтобы чтение атомика читали монотонную подысторию modification order. И мы придумали
happens before — актризитивное замыкание программ order и синхронизации Swiss, и потребовали,
чтобы чтение были согласованы с happens before. И вопрос, достаточно ли этого? Вот у нас есть
программа с двумя атомиками, и в любом исполнении этой программы гарантируются гарантии, простите,
modification order и happens before. Вопрос, возможен ли исход 00? Ну как бы в рамках тех требований,
которые мы придумали? Ты прав, но ты ничему не научился. Но смотрите, у нас есть требования,
которые что-то требуют, да? Что-то запрещают, в частности. Ну вот, запрещен ли исход 00? Ну вот,
modification order — он вообще про отдельные атомики. У отдельного атомика здесь есть modification order.
Сначала в атомике 0, а потом единица. И вот чтение прочло подысторию 0. Нормальная подыстория,
нормальная. Монотонная, монотонная. Ну трудно быть не монотонной историей из одного значения.
А happens before — он про то, что если возникло синхронизация Swiss и happens before, то значит там
какие-то ограничения следуют. А здесь возникло синхронизация Swiss? Здесь мы записали единицу,
а прочли 0. Синхронизация Swiss не возник. Значит, все, happens before тоже не удел. Так что у нас есть
две гарантии, но при этом они никак не запрещают в этом исполнении получить два нуля. А я напомню,
что такая программа нас беспокоит, потому что она возникает в runtime.gov сборке мусора,
она возникает в реализации фьютекса в линуксе. Короче, сценарий довольно важный. Поэтому мы
требуем еще одного. Мы требуем достаточно сильной гарантии, что все вызовы store и load и других
методов атомика на всех атомиках глобально упорядочено в исполнении. То есть все обращения
ко всем атомикам выстраиваются в некоторый сквозной единый порядок, который мы называем
Synchronization Order. Ну, смотри, мы глобально хотим, чтобы об исполнении программы можно было бы
рассуждать, как будто бы все обращения памяти происходили в каком-то порядке. Вот, но мы не
требуем, чтобы все так происходило, но мы требуем, чтобы на атомиках так все происходило. Вот, но мы
надеемся, что в нашей программе атомиков будет гораздо меньше, чем неатомарных ячеек памяти.
Кажется, что это тоже довольно разумно ожидать. Да? Ну, опять, смотрим примеры. Смотрим модель
памяти Java. Вот он, так и называется Synchronization Order. Это Total Order на всех Synchronization Actions,
которые там записи в атомик, чтение из атомиков, локи-анлоки, короче, еще есть
некоторые специальные случаи. Но суть такая. Total Order Overall Synchronization Actions. В C++ Synchronization
Order называется совершенно альтернативным, он называется Total Order S. Вот как бы нигде в модели памяти
больше нет таких буквенных сокращений, именований, вот почему-то только одно оно. Ну, вот есть и есть,
с этим уже придется. Значит, это вот опять общий порядок на всех обращениях к атомикам
с Memory Order Sequential Consistency, то есть дефолтный Memory Order. Ну, и вот этот общий порядок S,
Synchronization, он же Synchronization Order, запрещает вот в этой программе такое исполнение. Потому что
Synchronization Order, конечно же, тоже согласован с порядком следования обращения к памяти в каждом
потоке. Вот такое требование, такая гарантия. Ну, и что теперь читает каждый атомик? Каждый
атомик читает последнюю запись Synchronization Order, можно так сказать про него. Ну что, я бы сказал,
что мы построили все необходимые частичные порядки. Synchronization Order в первую очередь и Happens
Before. Вот давайте еще раз соберем их вместе. Вот в первую очередь мы придумали Modification Order.
Это порядок записей в каждый отдельный атомик. Дальше мы придумали Happens Before, как транзитивное
замыкание Program Order, то есть порядок следования обращения к памяти в тексте программы для каждого
потока. И Synchronizes With – это уже не порядок, это отношение, которое связывает атомарные записи и
атомарные чтения, которые увидели значение этих записей. И вот Happens Before – транзитивное
замыкание, которое фиксирует возникающую в исполнении причинность, реализующуюся причинность.
И Synchronization Order – это сквозной порядок на всех обращениях ко всем атомикам. Вот те гарантии,
которые мы навыдумывали. И вот в совокупности все эти гарантии и образуют исполнение. Мы говорим,
что в модели памяти C++ исполнение – это согласованная реализация вот этих вот порядков.
Согласованная, в смысле, если мы все это объединив вместе, то мы получим эцикличный граф.
Ну и вот само исполнение – это и есть граф, как было обещано когда-то. Вершины – это обращение
к памяти, дуги – это какие-то порядки отношения. Вот в джаве, пожалуйста, определение исполнения,
вот оно такое. Опять идем в документ, идем в execution. Вот. Исполнение – это набор обращений к
памяти, program order, synchronization order, synchronizes with, happens before. Тут еще какие-то специальные
штуки. Сейчас они не очень важны. Спомогательное определение. Вот это и есть исполнение. Вот когда
мы говорим в модели памяти про исполнение, мы представляем себе вот такой вот граф. Это единственный
честный способ, которым можно себе исполнение представлять. Вот оно такое. Вы запускаете программу,
и вот рождается некоторый граф с частичными порядками. В C++ этих порядков еще больше,
когда-то давно показывал. Давайте я найду. В C++ вот тут тоже достаточно много их.
Ну и есть определение датарейса, которое там по пути возникает. Два конфликтующих,
неатомарных, неопределеченных через happens before обращений. И вот теперь мы можем сказать,
что увидит чтение. Вот чтение, такой фундаментальный вопрос модели памяти. Что увидит чтение? Вот
чтение согласовано с нашими частичными порядками. Синхронизейшн ордером на атомиках is happens
before. Если мы читаем что-то из атомика, то мы видим просто последнюю предшествующую запись
в синхронизейшн ордере, ну или в модификейшн ордере, который под множество, под история
модификейшн синхронизейшн ордера, если вы понимаете, о чем я. Но если мы читаем не атомик, то,
видимо, мы читаем последнюю предшествующую в happens before запись. В предположении, конечно,
что в программе нет гонок, потому что иначе такое определение неволидно. Вот мы придумали
частичные порядки, которые ограничивают, которые задают правила чтений. Но смотрите-то,
что мы хотели? Мы же хотели не этого, мы хотели глобального порядка. Мы хотели sequential consistency.
Мы хотели, чтобы исполнение программы было неотличимо от некоторого последовательного. Меньше
всего нам хочется думать про графы какие-то. Так вот, утверждается, что если исполнение программы
соблюдает вот требования, которые порождаются этими частичными порядками, то пользователь не
сможет отличить исполнение от некоторого последователя. От какого «некоторого»? Но вот посмотрите,
мы сейчас построим то самое исполнение, от которого неотличимо наше. Вот мы возьмем
synchronization order, возьмем happens before, объединим их. Мы считаем, что влагаем, что в них, что циклов
в убедение не получится. Такова наша аксемума. А дальше мы получившийся граф топологически
отсортируем и порядочим. Получим некоторый линейный порядок TEN на всех обращениях к памяти.
И вот мы хотим показать следующее, что наше исполнение, которое на самом деле вот такое,
оно неотличимо от пользователя, от исполнения всех обращений к памяти в порядке T, в котором
просто каждое чтение читает последнюю предшествующую запись. Ну что значит неотличимо?
Смотрите, в T мы читаем какую запись? Просто вот у нас есть чтение в T, оно читает последнюю
запись в ту же ячейку памяти. Но в исполнении чтение читает не просто последнюю, оно читает
последнюю happens before. И что если, вот получилась такая картинка, что у нас есть две записи W
и W', и W', она последняя в T, предшествующая R, но не последняя в happens before. Тогда кажется,
что обман происходит. Но такого не бывает, потому что посмотрим, пусть такое реализовалось от
противного, пусть так случилось. Посмотрим на пару W и W'. Может ли между ними быть happens
before? Не быть happens before. Не может быть, потому что это две записи, они конфликтуют, значит они
должны быть упорядочены. Могут ли они быть упорядочены в обратную сторону? Не могут,
потому что мы же топологическую социировку строили, тогда был бы другой порядок. Так что
happens before есть и в таком порядке непременно, отсюда-сюда. Теперь смотрим на эту пару,
W' и R', опять конфликтующие обращения, опять между ними должно быть happens before, опять по тем
же самым причинам в обратную сторону его не может быть. Значит, есть W'. Ну и все, значит,
отсюда happens before. Значит, предположение наше неверное, потому что W' это просто не последняя в
happens before запись, а последняя W'. И мы должны прочесть ее. Ну то есть, если в исполнении,
если исполнение это вот такие частичные порядки, которые ограничивают чтение в программе,
то существует некоторое исполнение... То есть, если исполнение вот такое, на самом деле, то
существует некоторый глобальный порядок на всех обращениях к памяти, который не отличим вот от
этого исполнения графа. Так что вот наших требований трёх, modification order, synchronization order,
happens before, этих частичных порядков достаточно, чтобы получить видимость последовательного исполнения.
Да, можно.
Возможно. Давайте я докажу исполнением в коде. Как ты к этому отнесешься?
Ну ладно, не веришь тебе плюс-плюс. Компериатор не соблюдает модель. Давай.
Не, не должны никакие стрелочки идти.
У тебя две гарантии. У тебя два частичных порядка, modification order и happens before.
Modification order говорит, у тебя есть на каждом атомике история изменений. Вот для атомика X и для
атомика Y история одинаковая. Сначала был ноль, потом стал один. И modification order говорит,
каждое чтение в программе, каждый поток читает монотонную подысторию. Каждый поток прочитал по
нурю. Монотонная подыстория. Всё честно, да? Happens before говорит, что если вот happens before
реализовалось, то чтение увидит запись. Здесь не реализовалось happens before. Тут не нужно думать,
как такое получилось. Вопрос такой чисто теоретический могло, если какие-то требования, какие-то
гарантии, которые ограничивают существование такого исполнения. Вот их нет. Поэтому в модели памяти,
построенной нами к этому моменту, в которой есть только modification order и happens before, такое
исполнение возможно. Как именно оно случилось на процессоре, это вообще посторонний вопрос.
Потому что мы рассуждаем вот декларатив.
Сейчас, подожди, ты приговорил все мои слова, кажется. Ну, я не знаю. Я не могу определение еще
третий раз повторить, наверное. Ещё раз, modification order состоит из двух записей. Одна запись
это инициализация, ноль. Вторая запись, вот она. История, ноль-один. Чтение каждое, вот это вот,
и вот это вот читает под историю. История, ноль-один, читает ноль. Ноль – это под история, ноль-один.
Поэтому как бы требование, требованию, которое следует из modification order, это чтение ноля не
противоречит. Happens before здесь тоже не возникает. Вот поэтому по таким сугубо формальным причинам
исполнение ноль-ноль допускается. И вот в этом беда наших формальных требований. Поэтому мы эти
требования усиливаем, добавляем еще одно, требуем, чтобы все обращения ко всем атомикам были
глобально упорядоченные. Причем согласованы с порядком обращения в каждом потоке.
Ну что ж, тогда, значит, мы сказали, что всего этого достаточно, вот этих вот synchronization order
и happens before. Если мы через них ограничим чтение, то мы получим видимость некоторого
глобального порядка на всех обращениях к памяти. И мы можем дальше не думать про то,
как… про все вот эти графы и стрелки и happens before. В общем, можем не думать в какой-то степени.
Но мы не пользовались, потому что мы смотрели нетривиальный случай. Тривиальный случай,
когда у нас два атомика. Вот здесь мы говорим про чтение не атомика. Чтение
атомика, оно как бы читало последнюю запись synchronization order, и оно читает до сих пор.
А тут как бы… Нет, непонятно. Это просто тривиальный случай был. Ну, во втором случае,
который здесь не рассмотрено, когда R – это чтение атомика. Вот, он просто опущен как тривиальный.
Если нужно пояснить что-то там. Ну вот, смотри, у тебя были в графе обращения, у тебя был атомик,
были все обращения к нему. Они уже были упорядочены. И в топологической сортировке они будут в таком же
порядке находиться, поэтому там ничего нового не возникнет. А тут все-таки был частичный порядок,
и мы вот как-то там что-то могли перепутать. Но не перепутали. Ну, смотрите, вообще говоря,
этого мало. Потому что… Ну, то есть, я вас обманываю немного, потому что я говорю вам,
что если мы потребуем от исполнения, соблюдения гарантий синхронизейшн ордера и Happens
Before, и в программе нет гонок, то вы можете не думать про вот эти частичные порядки.
В чем подвох? Где обман?
А откуда вы знаете, что в вашей программе нет гонок? Потому что чтобы определить,
там гонки или нет, нужно все графы представить себе. Вот. Ну, это как бы рассуждение в обратную сторону.
И модель памяти поддерживает следующую гарантию, которую также нужно доказывать.
Гарантия звучит так, что если все последовательно согласованные исполнения программы не содержат
гонок, то все исполнения программы будут последовательно согласованы. Сейчас не получилось, да?
То есть, как протестировать программу на наличие гонок? Не нужно строить графа. Нужно просто перебрать
все возможные интерливинги. И если во всех таких вот в таком подклассе исполнений гонок не возникает,
то значит, про гонки можно не думать и можно вообще думать, и можно после этого считать,
что для программы другие исполнения в принципе невозможны. Да.
Ты поднимаешь очень сложный вопрос, про который нужно час говорить. Ну, во-первых,
промышленный… А можешь, пожалуйста, повторить вопрос для тех, кто взамен? Спрашивают… Мне кажется,
вопрос упрощу сейчас. Как тестируют код в продакшене на наличие гонок? Похоже на твой вопрос?
Ну, похоже, да. Ладно. Если я не отвечу, то уточни еще раз. Если у тебя большой промышленный код,
то ты берешь и запускаешь его стредсанитайзером, и он пытается обнаружить гонки. Он не гарантирует,
что в программе гонок нет. Он тестирует конкретное исполнение, а не программу, во-первых. Во-вторых,
он даже в этом конкретном исполнении может что-то пропустить. Вот. Но если он что-то нашел,
то у него точно гонка есть, и он тебе ее нарисует в виде там stacktrace. Дальше. Если ты тестируешь код,
дальше, если ты тестируешь какие-то отдельные примитивы синхронизации, то для них, вообще говоря,
в некоторой степени можно даже и перебрать. Даже вот такие, ну, условно, графы перебрать. Ну,
тут тонко, но вот перебор в определенной степени возможен, да. Но вообще, почти весь промышленный
код написан с memory-ордерами, которые слабее, чем sequential consistency. А судя по слайду,
который у нас был, сейчас давайте я его найду. Можно ли не думать про memory-ордеры? Там говорилось,
что если вы используете только mutex и default memory-order, то вы думаете про interleaving. Вы
пользуетесь interleaving. В промышленном коде используют не sequential consistency. И там уже,
ну, просто теряется всякая interleaving модель. Пользоваться ей в продакшене нельзя. С другой
стороны, разумному, довольно высокоуровневому коду, который не оперирует там mutex и mecon
дварами, оперирует там, не знаю, каналами, фьючами, передачей сообщений, interleaving модели не
нужна. Но это довольно сложная интуиция. Я скорее, не знаю, могу в конце курса к этому вернуться и
ответить на твой вопрос еще раз. И тогда будет, ну, как бы тебе самому понятнее, что я имею в виду.
Ты все пытаешься сломать тот пример, а с ним все в порядке. Но я повторю. Значит, у тебя есть два
обращения к одному и тому же атомику, атомику записи чтения. И если чтение читает значение,
которое записала эта запись, то между ними возникает отношение synchronize this with. Просто
пара такая. А дальше оно участвует в образовании частичного порядка happens before.
Давай остановимся. Не хочу сейчас к этому возвращаться. Итак, значит, если гонок нет,
то про исполнение можно думать в модели чередования. А чтобы проверить, что гонок нет,
можно перебрать только исполнение в модели чередования. Если там гонок не возникнет,
значит, беспокоиться нам ни о чем не нужно. Так что мы достигли с одной стороны успеха. То есть
мы хотели получить видимость последовательного исполнения, и мы ее получили, выдумав какие-то
частичные порядки. Но это только половина истории, не по времени, а по целям нашим.
Зачем так сложно было все? Ради чего все это было? Ради реордерингов. Мы хотели не просто получить
видимость последовательного исполнения, мы хотели, чтобы у процессора осталась возможность для
каких-то оптимизаций. И мы эту возможность заложили, потому что мы все время оперировали
частичными порядками. Ну ладно, мы там атомики жестко провязали, но мы не требуем, чтобы все
обращения к памяти прямо исполнялись по порядку. И вот сейчас мы этим воспользуемся для того,
чтобы построить очень простой класс допустимых реордерингов. Вот смотрите, есть у вас программа,
тут есть поток T и T штрих, и поток T он пишет, пишет, пишет, пишет, а потом пишет в атомик,
а другой поток читает из этого атомика, потом и синхронизируется с. Вот смотрите, пусть в программе
нет гонок. Собственно, может я откачусь далеко назад и прокомментирую один момент.
Будь здоров. Мы говорим, что модель памяти это контракт, и пользователь, он, если он соблюдает свою
часть контракта, то есть он пишет коллекционно синхронизированный код, то компилятор и процессор
дадут ему видимость по следовательному исполнению. И вот сейчас мы на месте процессора,
где мы были, на месте процессора и компилятора мы сейчас полагаем, что программист не накосячил,
и в программе нет гонок. Тогда посмотрим на поток T штрих. Вот когда он может увидеть одну из
записей W вот этих вот? Только тогда, когда он же в другом потоке находится. В смысле, T штрих,
другой поток, он может эти записи увидеть неатомарные только если реализуется happens
before, иначе будет датарейс. Чтобы реализовался happens before, нужно, чтобы реализовался
synchronizes with. То есть поток T штрих сможет увидеть эти записи только после того,
как он синхронизируется через атомик. Но когда он это сделает просто по свойствам видимости
записей через чтение, видимости записи через happens before, этому потоку доступны все записи.
Вот здесь вот. Понимаете? То есть он их получает разом. Когда он их может читать,
он должен видеть уже все записи. Это означает, что он не может наблюдать их относительный порядок.
А это означает, что компилятор и процессор вот эти записи между обращениями к атомику может
приордерить. Код программа без гонок не сможет наблюдать относительный порядок этих записей.
Это мы знаем просто из заключенного контракта. Так мы договорились с самого начала. И это супер
важно, потому что, смотрите, процессор, ну, представьте себе, у вас есть сложная программа,
какие-то потоки запускаются на разных ядрах. А процессор, когда он молотит инструкции,
он видит, не знаю, только маленькое окошко этих инструкций. Он не знает, как перестановка двух
инструкций повлияет на вашу программу. Понятия не имеет. И компилятор, когда он компилирует ваш код,
он же компилирует его независимо для разных единиц трансляции и не понимает, как потоки будут
по ним бегать. Так вот, в силу вот такого вот построения, в силу наших гарантий, компилятор
и процессор могут выполнять свои оптимизации локально. Вот процессор может риордерить
инструкции в окрестности просто не переходя через барьеры. И он знает, что он глобально не нарушит
никаких свойств. Это очень важно, потому что мало что-то придумать. Нужно придумать то,
что потом можно воплотить в реальной жизни. Вот наши гарантии получились хорошими, они вот очень
просто воплощаются в жизни. Запись в Atomic, видимо, будет снабжена барьером, и процессор не захочет
через этот барьер риордерить эти записи. Но это все только, конечно, для программ, в которых нет
гонок. Для других мы никаких гарантий не даем. Ну и все это очень похоже на Atomic на самом деле,
на Atomic и на Mutex. Вот точно так же, как, не знаю, компилятор или процессор не могут выкидывать
записи из критической секции, это было бы странно. Также мы не можем выкинуть, передвинуть эти записи
до или после этой записи или до этого чтения. До этого чтения не знаю. Ну короче, критические секции
и фрагменты кода между чтениями и записями в Atomic — это очень похожие сущности. И, скажем,
памяти Java примерно одинаково их рассматривает. А что я вас этому убираю? Давайте покажу.
Вот Synchronize the Swiss в Java, оно возникает между записью в volatile Atomic и чтением этого Atomic,
который видит эту запись, или между Unlock и последующим Lock. В общем, вещи довольно похожи,
трактуется одинаково. Ну вот и все. Смотрите, что мы получили. Что мы, программисты, пишем
корректно синхронизированную программу, программу без гонок. Мы аннотируем переменные,
через которые синхронизируются потоки с помощью Atomic, а дальше компилятор в соответствии с
этими аннотациями, зная, что вот Atomic — это ячейки памяти, через которые будет
выполняться синхронизация, генерирует в машинном коде, ставит в генерируемом
машинном коде барьеры. А дальше процессор реордерит инструкции, но аккуратно,
не выходя за границы этих самых барьеров. И вот если никто не ошибся, то мы получаем видимость
последовательного исполнения и получаем реордеринги. И вот это наша цель, которую мы
пытались достичь. Да? Но вы же пришли сюда не за этим. Я же знаю, зачем вы пришли. Вы
хотите писать memory order в программе. Я напомню, что лучше не умничать, как говорит нам Го. То есть
если вы не пишете memory order, то с вами плохого не случится никогда ничего. Вы не ошибетесь.
Точнее ошибиться гораздо сложнее становится. Но, допустим, вы профессионал и вот хотите написать
какой-то memory order. Какие у вас есть варианты? Ну, у вас есть sequential consistency и у вас есть более
слабые, там более-менее три ступени, три с половиной. Sequential consistency — release plus
acquire или relax. И вот когда вы хотя бы в одном месте программы сбавляете memory order,
делаете его слабее, чем sequential consistency, то вы попадаете в дивный мир слабых модели памяти.
Модели памяти мы называем слабой, если она допускает не sequential consistency исполнение. То
есть если вы хотя бы в одном месте выбрали более слабый memory order, то вы больше не можете
пользоваться моделью чередований. Нет, вы можете, конечно, пользоваться, но это будет неправильно.
Но с другой стороны, вы даете процессору гораздо больше свободы для reordering. В этом и мотивация
более слабых моделей памяти. Это, конечно, хорошо, что у процессора больше возможностей для
reordering. Но как вам-то жить с этим всем? Вам нужны какие-то разумные гарантии. И зачем я в
лекции про деталь реализации sequential consistency рассказывал? Потому что все, что мы придумали,
дальше используется в определении гарантий вот этих самых memory orders. Если мы говорим про
sequential consistency атомики, то мы получаем synchronization order на них plus happens before. Плюс они участвуют
в возникновении happens before. Если мы используем пару release plus acquire, release в записях,
acquire в чтениях, то мы лишаемся глобального порядка на атомиках, его больше нет. Давайте покажу.
Вот программа, которая работает корректно. Это storebuffering k5. Два атомика, пишем, читаем,
запускаем. Она сломается, потому что это не та программа. Запускаем, и она не ломается. Ну, в смысле,
это нужно проверить в конечное время, но она не сломается. Три, два, один, хватит. А теперь мы
поставим memory order, который минимально слабее, чем то, что было, и запустим. И довольно
быстро сломалось. Ну вот, мы лишили synchronization order, но при этом на каждом атомике по-прежнему есть
modification order, и по-прежнему release, запись и acquire чтения участвуют в образовании отношения
synchronizes with, то есть happens before. Но если мы говорим про relax, то там только modification order,
то есть мы по чтению relax атомика вообще не можем судить о состоянии других ячеек
памяти в программе. То есть мы только знаем про историю одного атомика, одной ячейки памяти.
И тут вот теперь, кажется, мы готовы решить задачу минуток spin lock, наконец. Настал тот
момент. Вот теперь, если вы задаете задачу spin lock с этого момента, то от вас ожидается знание
ответов на оба вопроса. А именно, какой memory order вы написали и какой будет оптимарин.
И смотрите, тут очень важный момент есть, что вот почему оптимарин выделен нажирным,
потому что зачем в модели памяти C++ есть слабые memory order, слабее, чем default,
sequential consistency, чтобы вы могли оптимизировать программу. Ну вот вы оптимизируете программу
в декларативной модели, то есть вы выбираете просто наиболее слабые memory order, то есть memory
order, которые порождают наименьшее количество ограничений стрелочек. И вот модель хорошая,
если она хорошо описывает реальность. То есть задумка слабых моделей вот этих memory
order в C++ такова, что если вы оптимизируете программу в декларативной модели, то,
скомпилировав ее на конкретном процессоре, конкретным компилиатором, вы получаете,
видимо, оптимальное решение в смысле барьеров. Ну, по крайней мере, такая задумка. Вот реализуется
она не всегда, но люди над этим работают условно. Это такой совместный процесс, должны и разработчики
модели памяти, и разработчики процессоров друг на встречу другу идти. Правда, у этих слабых
моделей памяти есть довольно любопытные… Ну, как это назвать? Короче, когда вы в модели
памяти встраиваете вот такие слабые memory order, то вместе с ними в модели памяти проникают довольно
странные программы. Вот смотрите программы. Читаем из XA с релаксом, а потом, если прочли 42,
то пишем в Y42. Поток второй читает из Y значение с помощью memory order relaxed, а потом, если прочел
42, то пишет 42. Было бы странно от этой программы… И пусть вначале нули в программе. Было бы странно
ожидать исполнения, которое породит нам два чтения 42. Вот. Ну, это такое самозбывающееся пророчество,
так и называется этот сценарий. И как и любое… Ну, то есть самозбывающееся пророчество – это такое
общее понятие, и оно сбивает с толку, потому что оно бессмысленно. И вот здесь оно бессмысленно,
и в этом проблема. Но, к сожалению, гарантий формальных моделей памяти оказывается недостаточно,
чтобы такую программу запретить, такое исполнение запретить. И поэтому в стандарте просто захардкожено,
что вот таких исполнений… Таких исполнений, говорят, не бывает. Ну, представьте, что про каждую
программу был бы пункт стандарта. Это было бы довольно утомительно. Кажется, мы запрещаем
исполнение с помощью порядков частичных. Но вот их не хватает, чтобы такую программу запретить.
Ну, точнее, тут сложная история. Я на семинаре однажды расскажу про это. Но в этом беда. И эта
беда, она не решается. Ну, то есть вот просто есть фундаментальная проблема, такой барьер,
который, кажется, не преодолеть в рамках текущего подхода к моделям памяти.
Там можно решить несуществующую в реальности проблему, замедляв существующую в реальности
программы. Так делать не будут. А теоретически запретить нельзя, потому что запрещать нужно
программы о модели памяти запрещает исполнение. Вот она работает на другом масштабе. Поэтому там
вот беда. Там нужно придумать другую модель памяти совсем. Там не чинится релаксными. По
поводу реализации. Вот мы придумали все это, а теперь нужно эти гарантии воплотить в реальности.
Кто этим занимается? Этим занимается компериатор в схеме компериации. Вот мы идем в Godbolt,
который мне сегодня все стер, и то, что он не стер, смотрим. Вот разные варианты записи,
sequential consistency, release, relaxed, и можно посмотреть, во что они компилируются. Собственно,
так и предлагалась задачу спинлог решать. Правда, вы тут видите странные вещи, что,
скажем, release и relaxed компилируются в один и тот же простой мув, но из этого, конечно,
не следует, что можно их заменить друг на друга. Уж у них гарантии разные. Просто на конкретном
процессоре реализации совпали, но другом могут не совпасть. Ну, давайте я сейчас не буду проверять,
это точно так, вы можете выбрать в какой-нибудь ARM посмотреть. И вот обратите внимание, атомики,
я на первой лекции, кажется, про это говорил, атомики на первый взгляд про то, чтобы получить
доступ к каким-то более сложным атомарным операциям, типа exchange, compare-exchange,
fetch-add, fetch-sub. Вот атомики в C++ нужны не только для этого, а еще и для того, чтобы служить
аннотацией для компилиратора, такой подсказкой ему, что вот в этом месте происходит синхронизация,
и вот где-то в этом месте нужно расставить барьер. Вот мы подсказываем компилиратору,
где нужно ставить барьер. То есть представление атомика и обычные ячейки в памяти одно и то же.
Но не это важно, а то, какие барьеры памяти, какие специальные инструкции вокруг этих обращений
разместит компилиратор. Ну ладно, все, последние слова, такое напутствие на будущее, очень важное
для меня. Вот мораль этой лекции большая, что есть соблазн, когда вы думаете про исполнение со
слабыми моделями памяти, думать про уреордеринге. Что может там с чем переупорядочиться? Где что
застяло в сторбафере? Вот, пожалуйста, не рассуждайте так. Декларативная модель дает вам
правильный подходящий инструмент. Она оперирует порядками, положительными гарантиями. Вот лучше
быть оптимистом, чем пессимистом. Лучше верить, что что-то хорошее случается, чем ждать чего-то
плохого от исполнения. К тому же все эти урдеринги, они свои для каждой архитектуры. А вот частичные
порядки, которые зафиксированы в модели памяти, они для любой архитектуры, то есть они в стандарте
языка. Вам не нужно думать про железо, которое под вами. Вот не думайте про барьеры, думайте
про Happens Before. Это на первых парах вызывает некоторое сопротивление, но как только вы
почувствуете, как этим пользоваться, то станет хорошо. А как именно нужно этим пользоваться? Ну,
нужно просто добиваться Happens Before. Вот если у вас вы делаете запись в ячейку памяти в программе,
пишите в буфер что-то, а потом из буфера читаете. Вот гарантируйте с помощью, собственно,
описанных гарантий, что между записью и чтением в исполнении обязательно возникнет Happens Before.
Если у вас есть конфликтующее обращение к неатомарным переменным, то гарантируйте,
что в исполнении возникнет Happens Before. Прям гарантируйте это. Если вы гарантируете это,
то все, вот вы получите предсказуемо работающую программу, предсказуемо работающую на любом
железе. Но всегда можно это забить и не писать memory order и все будет еще проще. Так что если вы
профессионал, то вы можете пробовать. Но тогда вы обязаны пользоваться вот этими гарантиями. Если
вы ставите где-то Release и Acquire, то объясните мне, как возникает Happens Before и там, что с чем
вы собираетесь упорядочивать. Какие неатомарные записи и какие неатомарные чтения. И вот только
после этого можно верить, что вы поставили memory order разумно. Ну или можно вот их не ставить и
жить в простой модели чередования. Это, в общем, тоже нормально. Ну и самое последнее. Что после этого
всего можно почитать. Давайте в порядку. Я бы начал со статьи, которая не про то, как обо всем
этом думать, а как раз про барьеры и риордеринги. Но я это на семинаре постараюсь еще объяснить. Но
вот тут интуитивно объясняют на таком выдуманном не существующем процессоре с кэшами, какие
оптимизации можно в протоколе когерентности делать над протоколом когерентности и как это приведет к
риордерингам. И как появляются барьеры. То есть как возникает вся эта механика со store
buffer, invalidation queue, memory barriers, чтобы понять, с чем мы боремся и с какими инструментами.
И если вот эта железная реальность станет понятна, то дальше есть очень-очень хорошая статья. Вот это,
или давайте я даже скажу, что вот это. Ее одной, наверное, хватит. Это цикл статей, которые в
прошлом году написал Рассел Кокс, один разработчиков языка ГО. Он написал сначала про то, как... Ну,
про железные модели памяти, про то, что делают процессоры, почему они что-то риордерят и как
с этим жить. Какие там исполнения странные порождаются. А потом про то, как можно это все пытаться
скрыть с помощью модели памяти sequential consistency для программ свободных отгонок от прикладного
программиста, который не хочет знать про конкретные процессоры. И третья статья про то,
как потом выдумывали конкретные модели памяти в ГО. Очень хороший цикл статей, очень простой,
логичный, последовательный, прям как эта лекция, в смысле. Логика примерно такая же. Она такая же,
потому что она разумная. Мне кажется, что это хорошее место, чтобы так начать и довольно
глубоко можно закопаться. Там довольно сложно. Дальше мне кажется, что стоит посмотреть на модели
памяти Java, потому что там все определения, которые были сегодня есть, они написаны просто подряд на
одной страничке без всяких сложностей и вычурностей, как C++. Дальше, как это ни странно,
я бы, возможно, рекомендовал почитать документ про модель памяти в ядре линукса. Он чудовищно
сложный. Это не он вообще. Вот он. Он чудовищно сложный, чудовищно большой. Там этих частичных
порядков раз, два, три, четыре, пять, шесть, семь. Ну, короче, десятки. Но это очень хорошее
изложение, безумно хорошее. Оно совсем не про какие-то детали реализации, а именно про теорию. И
тут очень последовательно, очень аккуратно, очень строго описывают именно теоретические построения.
Как можно думать об исполнении в терминах каких-то порядков и аксиом, а не в терминах
вот этих самых реордерингов. Дальше я бы посоветовал почитать статью, которая описывает,
ну, скорее, состояние текущих моделей памяти, что с ними так и что с ними не так. Тоже довольно
дружелюбная статья. Она, конечно, сложная. Там с нее начинать не стоит, но, может быть, вот вы до нее
доберетесь. Там, в частности, есть пункт про то, почему возникает проблема вот с этими программами,
там, с самосбывающимися пророчествами и с значениями из воздуха возникающими. Вот разбирается
подробно, что идет не так, но мы на семинаре каком-то тоже об этом поговорим. И, наконец, после всего
этого можно прочесть модели памяти C++ просто чтобы знать, как формально она устроена. Вы
ничему не научитесь, вы скорее узнаете про какую-то страшную специфику C++. Это последнее место,
по которому можно учиться моделям памяти, несмотря на то, что это более-менее стандартный,
но стандартная модель для современных языков. Но в C++ она изложена душераздирающая, и вот я
сегодня попытался изложить ее суть, пожертвовав некоторыми тонкостями, которые возникают
и про которые, в общем-то, знать почти не нужно. Это, конечно, не совсем честно, но вот чтобы знать
честно, в конце концов нужно прочесть стандарт. Но можно счастливо жить, писать хорошие
оптимизированные программы и про некоторые тонкости, странности, не знать, пользоваться
простым определением Happens Before. Просто не пишите Consume в программе, тогда все мои слова будут
валидны. С одной стороны, да, с другой стороны, его просто нужно не писать не потому, что там
что-то устарело, а просто вот не нужно его писать никогда. Пиши Acquire вместо него. Есть все-таки не
совсем точный, но достаточно убедительный ответ, что ну просто не получилось ни одного автора
компилятора правильно реализовать Consume. Ну вот ни у кого в мире не получилось. То есть в теории его
придумали, в теории он такой классный и замечательный, там все написано в стандарте, а на практике он...
Но он не классный и замечательный, потому что он изуродовал семантику C++. Да, пришлось пожертвовать неким
некой простотой. Ну, Рома, да, он скрасил немного картину на мой вкус. Мне кажется, что модель памяти изуродована
просто, а не просто пожертвовать красотой. Ее перекосило все из-за этого Consume. Но, в общем,
может быть, это можно было пережить, если бы действительно из этого была польза, но польза не
вышла, а вред остался. Поэтому просто не пишем Consume и можно тогда не думать про вот некоторые
частные и очень уродливые случаи модели памяти C++. Может небольшой вопрос конкретно по C++.
Почему модели памяти передаются как аргументы, а не как шаблонные параметры? Шаблонный параметр
на чем? Ну, у лода и стора, допустим, можно сделать... у функции. У функции можно сделать шаблонные
параметры. Я не знаю, мне кажется, это не очень принципиально. Если кто-то знает, может потом
поделиться. Так исторически сложилось. Ну, вот да. Давайте считать, что так. Вы, смотрите,
есть проблема в том, что вы можете написать там, не знаю, load с aquire. Ой, это будет хорошо, разумно.
Вы можете написать load с release или store с aquire. Какие-то бессмысленные комбинации. Этот код скомпилируется,
будет работать как-то. Не ведомо мне образом. Я не писал такой код. Вот. Ну, это еще одно BFC++.
Хорошо бы, конечно, чтобы система типов запрещала вам делать неправильные вещи. Но не в этот раз.
Ладно, всё. Спасибо большое, что были с нами. Вот я вроде бы рассказал самые-самые основы.
Теперь с ними можно дальше жить, изучать детали. Мы на семинарах обсудим. Спасибо вам.
И вам тоже спасибо. До свидания.
