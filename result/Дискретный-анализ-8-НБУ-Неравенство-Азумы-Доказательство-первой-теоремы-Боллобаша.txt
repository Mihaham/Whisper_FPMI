Редактор субтитров Е.Воинова Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
С Mandy
а в квадрате минус квадратом от ожидания.
Квадрата значение один с вероятностью один, поэтому единица получается.
В общем, это будет n поделить на a в квадрате.
Ну и я всегда для примера просто говорю, давайте возьмём, скажем, n равное 10 в шестой, а a равное 10 в четвёртой.
То есть интерпретировать надо так, пьяница совершает миллион шагов.
Не трезви.
Даже если вы совершаете шаг в секунду, это, наверное, больше десяти суток без сна.
Ну, 86 400 секунд в сутках.
Вот, поэтому если он миллион шагов делает, это больше десяти суток без сна.
Так вот, вероятность того, что он уйдёт на расстояние всего лишь 10 тысяч вправо от кабака, сделав при этом миллион шагов.
Вероятность того, что он удалится на расстоянии 10 тысяч вправо, ну или влево, это неважно.
Она точно не больше, чем 10 в шестой поделить на 10 в восьмой, то есть односотая.
Мало?
Мало?
За миллион шагов уйти на расстояние 10 тысяч, вероятность меньше одной сотни.
Кажется, что это круто.
Но это не круто.
Круто вот это, потому что здесь же написано та же самая вероятность.
И, между прочим, а квадрат поделить на n, это как раз n поделённое на а в квадрате тут.
Ну, то есть 100.
Для нашего вот этого конкретного примера это 100.
Ну, правда, здесь вы 100 ещё пополам делите, будет 50.
Но это, я вот так пишу, Versus E в минус 50.
Пить вредно.
Вредно.
Настолько вредно, что вероятность не одна сотая, а E в минус 50 из 9.
А E в минус 50 степени.
Квадриллион километров человек прошёл, а удалился всего на чуть-чуть.
E в минус 50.
Вот, в этом пафос неравенства большого уклонения.
То есть оказывается, что для таких вот случайных величин, которые участвуют в случайном блуждании,
вероятность уйти далеко, получить большую сумму, гораздо меньше, оценивается гораздо лучше, чем с помощью общего неравенства Чебышова.
Вот, вывод такой.
Неравенство Чебышова работает абсолютно всегда.
А неравенство данного большого уклонения, оно работает, ну, например, на ситуации, когда у нас плюс-минус единички.
Конечно, не любые случайные величины, а какие-то очень специфические.
Понятно?
Пафос.
Сейчас докажу.
Доказательство очень красивое, если вы никогда его не слышали.
Оно проканает, потому что до него додуматься невозможно.
Догадаться, что будет E в степени минус а квадрат на 2n, можно, если знать хорошо курс теории вероятности,
в котором рассказывают центральную предельную теорию.
Но поскольку вы ещё до этих знаний не дошли, насколько я понимаю...
Не дошли.
Не доказывали и не будут?
Будем.
Это обязательно.
Я не знаю, в этом курсе или в следующем семестре.
Я, честно, не помню, когда это делают, но это точно сделают.
То есть CPT будет доказано и даже более общий убитель.
Значит, если у вас центральная предельная теория у кого-то была, вы, наверное, можете сообразить как с помощью неё догадаться, что ответ будет такой.
Хотя она предельная, то есть там надо всё-таки смотреть на сходимость, а тут всё написано для любых числовок.
То есть тут никакой асимптотики нет.
Это просто CPT не получить.
Хотя CPT это сложная вещь.
А, ну да, у вас должны были быть уже характеристические функции, мне Власнов говорил.
Да, так что...
Ладно.
Потоки-то разные.
Ну, потоки разные, да.
Вот тот, который математически сейчас углубился.
Ну, я просто...
Он вернётся к этому, никуда не денется.
Там, знаете, какие вещи ещё?
Ладно, всё, я доказываю.
Чего болтать?
Вам, может, на дрифтероядку что-то потом докажет.
Не важно, я сейчас докажу всё равно.
Хуже от повторения никогда не бывает.
Все по-разному немножко интерпретируют, доказывают.
Так, так, так.
Ну, доказать точек красительства.
Сейчас мы его приведём.
То есть возьмём пока какое-нибудь число лямто, большее нуля,
которое я даже знаю, чему стоит взять равным,
но я не скажу.
Пока мы возьмём просто положительное число лямто.
Напишу вот так.
Вероятность того, что кси один и так далее плюс кси n
больше либо равняется a, равна, очевидно, вероятности того,
что лямто на кси один плюс и так далее плюс кси n
больше либо равняется λ.
Умножили на одно и то же положительное число слева, справа.
Неравенство получилось то же самое.
Так, но это не то, до чего невозможно догадаться.
Следующий ход гениально.
Это знаете, чему равно?
Это равно вероятности того, что е в степени λ на сумму кси,
вот дальше уже понятно,
больше либо равняется е в степени λ.
Нет, но это очевидно правильно, е монотонная функция,
там какие вопросы, просто пойди додумайся,
что надо сделать такой, например, переход.
Дальше ещё будет много чего весёлого,
но это быстро закончится.
Доказательства несложные.
Красивые, но несложные.
Пользуемся неравенством Маркова.
Казалось бы банальным.
Опять вот неравенство Чебышёва, неравенство Маркова,
вещи похожие.
Ну что говорит неравенство Маркова?
Здесь встаёт не отрицатель, назначенная случайная величина,
ну значит можно применять,
а здесь какое-то число,
то есть она говорит вот так,
е в степени минус лямда а,
это то же самое, что поделить на число справа,
умножить на математическое ожидание вот этой вот экспоненты от суммы.
Мат ожидания поделить на правую часть,
но я вот это деление на правую часть написал как е в степени минус лямда.
Так, мат ожидания произведения независимых случайных величин,
это произведение их мат ожидания.
Тут перемножаются экспоненты, но они берутся от независимых величин,
значит они сами тоже независимые.
Получается вот так,
е в степени минус лямда а,
произведение по е от 1 до n,
мат ожидания от е в степени лямда ксиит.
Так, что такое мат ожидания от е в степени лямда ксиитая?
Коль скоро ксиитая принимает всего два значения,
плюс-минус один с вероятностью одна-вторая.
Но это вот такая вот функция,
е в степени лямда плюс е в степени минус лямда пополам,
она сама на себя умножается н раз,
то есть возводится это все в н и ст.
Что-то это напоминает.
Ну да, это называется чосинус лямда, или кошинус там, я не знаю.
Но я не знаю, если вы помните ряд Тейлора сразу,
это хорошо, я помню сразу только ряд Тейлора для экспоненты,
поэтому этим мы воспользуемся.
То есть если вы вдруг помните ряд Тейлора для чосинуса,
мы можем сразу написать.
Я его не помню.
Косинус это просто чотный отсинутый экспонент.
Ну вот-вот-вот.
То есть надо просто сократить слагаемые в обычных экспонентах,
экспоненты все знают, как пишутся.
Ну пишут вот так, сумма по к от нуля до бесконечности,
лямда вкатый на к факториал плюс,
сумма по к от нуля до бесконечности минус,
лямда вкатый на к факториал,
вкатый на к факториал, все это пополам,
все это в n-й стиле.
А?
А как мы получили, если лямда вкатый на к факториал?
Ксиитая у нас принимает всего два значения,
плюс и минус один с вероятностью одна-вторая.
Ну как считается, мат ожидания функция от случайной величины.
Надо подставить в эту функцию значение
и умножить на вероятность этого значения.
Вероятность одна-вторая, вот я умножил,
ну поделил награду, то же самое.
Вот теперь я расписал по Тейлору,
видно, что здесь слагаемые с нечетными номерами сокращаются,
а с четными удваиваются, сокращая двойку.
Отлично.
Да, мне тоже нравится.
Ладно, давайте пойдем сюда,
е в степени минус лямда а,
а тут получается сумма,
ну хотите по l для красоты от нуля до бесконечности,
лямда в степени два л,
поделить на два л факториала,
и это в н-ной степени.
Согласны?
Четные только слагаемые остались.
Так, теперь мы пишем, что это конечно не больше,
чем е в степени минус лямда а,
умножить на сумму по l от нуля до бесконечности,
лямда в степени два л,
поделить на l факториала,
и умножить на два в степени l,
все в н-ной.
Я просто тупо оценил два l факториала снизу,
как l факториал поможет на два вылета.
Нет, ну это очевидно.
Слабо.
Ну слабо, но достаточно.
Достаточно, на самом деле достаточно,
и лучше сильно не сделаешь.
Дальше это, знаете, вот так вот я обычно рисую.
Ты уже как-то показал в квадрате.
Ну, еще, да, я согласен,
но зато вот так получается,
а поскольку l достаточно большой,
это не так важно.
Так, слушайте, подождите, кто-то мне собрался звонить.
Ах, хорошо, потом я звоню.
Так, лямда в квадрат, поделить на два вл.
Понимаете для чего я рисовал?
А, я не то обвел, да?
Я не снул, ну то, конечно, но не совсем то.
Я вот так картил, вот так.
Чтобы l в степени была общей.
Лямда в квадрат пополам в этой степени поделить на l факториала.
То есть это снова вариант tail wrap.
Но для e вот лямда в квадрат пополам.
Вот так надо обвести, чтобы было видно.
Получается, e в степени минус лямда a
плюс лямда в квадрат пополам умножить на n.
E в степени лямда в квадрат пополам
через tail wrap и еще в n в степени, поэтому умножить на n.
Ну а теперь понятно, как надо было с самого начала
выбирать лямду, чтобы получилось получше.
В показателе экспонента стоит парабола по лямду.
Да?
Ну когда будет самая лучшая оценка?
Когда мы попадем в нижнюю точку этой параболы, да?
Ну все умеют продиференцировать квадрагичный квадрат от трех членов.
Со школы еще, может, помнят, что он там
минимум достигает точки минус b поделить на 2a.
Был такой, да.
Учили прямо так, что минус b поделить на 2a.
Ну вот тут, конечно, а играет немножко другую роль, но понятно.
В общем, надо взять лямда, равная a поделить на n.
Это просто точка, в которой производная зануляется.
Подставляется так, чтобы было видно, что
зануляется.
Подставляете такой лямд сюда, вот именно такой.
И получаете в аккурате, я встегну, минус a квадрат на 2a.
То самое, которое заявлялось, все, я доказал.
Я доказал теорию.
Даже в одну строчку.
Ну не в одну, там, в три строчки.
Ну очень простая теория, видите, я доказал.
Никакой ЦПД там вам страшный.
ЦПД, Центральная Придельная Теория, если вы не знаете.
Никакой страшной Центральной Придельной Теории.
Никаких пределов вообще.
А симптотика.
И как?
Ну нет, ну я нигде, понимаете, не грубин.
То есть все одно я доказал.
Их вообще претензий даже быть не может.
Додуматься до этого, да, наверное, помогает Центральная Придельная Теория.
А так вот, компактная, замкнутая в себе офигенная, совершенно доказательств.
Вот, для чего я это рассказывал.
Для того, чтобы сказать, что, конечно,
ну, помимо всего прочего, для чего я это рассказывал.
С точки зрения хроматических чисел, которые мы с вами сейчас пытаемся изучать,
я хотел сказать, что, конечно, мир блинов не сошелся на случайном блуждании.
Есть гораздо более общие последовательства случайных величин,
которые тоже подчиняются вот такой вот замечательной оценке уклонений.
На графах это выражается в виде следующего результата,
который я вынужден оставить без доказательства,
иначе я углублюсь в материал, который, конечно,
скорее за конец третьего курса, чем за сейчас.
Ну, что поделать, не все доказано.
Вот я обещал, что будет некоторая дырка,
но она вот на основе этой интуиции будет хотя бы понятна, откуда взялась.
Как ее заладить там в конечном счете.
Так, ну это я не буду стирать, а доказательства выдержу.
Пока так, достаточно.
Нас-то интересуют случайные графы, правильно?
Вот давайте вернемся к случайным графам.
Есть модель Эрбоширэнии, случайный граф Шеттенпэ,
который нас будет какой-то режим интересовать,
я его напомню, теорему напомню, конечно, Балабашевскую, все будет.
Пока давайте вот чего скажем.
Есть какая-нибудь функция, зависящая от графов.
Ну, естественно, это будет случайная величина,
потому что любая функция – это случайная величина.
Так, дорогие друзья, кто-то меня хочет поправить в утверждении,
что любая функция – это случайная величина?
Ну, да, конечно, любая изменимая функция,
но, слава Богу, граф наконечный,
и у нас все вообще возможные множества графов являются событиями,
поэтому относительно такой, извините, сигма-алгебры
любая функция изменима.
Ну, дискретная сигма-алгебра, она состоит просто из всех возможных подмножеств данного множества,
и, естественно, там любая функция будет изменена.
Поэтому, какую бы функцию мы не взяли, она, естественно, будет случайной величиной.
Вот давайте назовем ее Липшицевой.
Я в этом месте, ну, для смеха, конечно, пишу,
но я действительно так пишу почерк такой.
Подпись Липшицы.
Да, я думаю, что еще должно быть написано Шеншилла.
Да, Шеншилла очень хорошо так напишется, да.
Шеншилла пишется так же, практически, да.
Так, ну, в общем, Липшицева на слух-то восприняется.
Я могу постараться написать там И, В, и так далее.
Вот, функция на графах называется Липшицевой,
но сейчас скажу, тут будет два разных варианта.
Сначала давайте Липшицевой по ребрам, это попроще воспринимается.
Называется Липшицевой по ребрам.
Если модуль f от g минус f от g штрих не превосходит единицы,
коль скоро g и g штрих отличаются на одно ребро.
Они на одном и том же множестве вершин их, вот n, я здесь это написал,
n вершин, есть два графа на n вершина, g и g штрих.
И вот если они отличаются только в одном ребре,
то f должна отличаться не больше, чем на единицу.
Тогда она будет Липшицевой по ребрам.
Ну, число ребер, например, Липшицева по ребрам.
А вот число треугольников не является Липшицевым по ребрам.
Помните, мы обсуждали число треугольников?
Вот оно не является Липшицевым по ребрам,
потому что у вас может быть ребро,
на котором сидит такая кармона из огромного количества треугольников,
вы удаляете это ребро одно единственное, и все треугольники разом пропадают.
Понятно, да?
То есть число треугольников одни и не Липшицева.
Ну, число ребер Липшицева, давайте я скажу,
хроматическое число графа тоже, очевидно, Липшицева по ребрам,
потому что если добавить только одно ребро,
хроматическое число не может вырастить больше, чем на единицу, или уменьшится.
А там внизу написано, сколько же их штрих?
Отличаются на одно ребро друг от друга.
Ну, то есть был грам-Ш, к нему добавили одно ребро,
получился Ж3, и весь с него выкинули одно ребро,
получился Ж на них.
Вот если для любых двух таких графов разность значений F
тоже окликнет не больше единицы по модулю,
то мы говорим, что F Липшицева по ребрам.
Хроматическое число, конечно, Липшицева по ребрам.
Ну, можно много чего в себе придумывать, но не важно.
Так, сейчас я еще скажу, что значит Липшицева по вершинам.
Липшицева по вершинам.
Ну, на самом деле, писать-то надо то же самое.
Можно сказать, что отличаются на одной вершине.
Нет, на обрестности одной вершины.
Сейчас я скажу.
Скоро Ж и Ж' отличаются в окрестности одной вершины.
Число вершин у них все время одно и то же.
У них общее множество вершин в окрестности одной вершины.
У них N вершину обоих.
Ну, вот представьте себе, был какой-нибудь граф вот такой?
А можно пояснить, что значит отличаются в окрестности одной вершины?
Вот я пытаюсь объяснить.
Я хочу сказать, вот есть одна вершина, вот был такой граф.
Мы можем взять, удалить в окрестности этой вершины любые ребра.
И любое новое добавить или несколько.
Вот если Ж и Ж' друг из друга получаются с такой операцией,
то мы говорим, что они отличаются в окрестности одной вершины.
То есть мы как угодно можем испортить окрестность ровно одной вершины.
Ровно одной.
Ровно одной, да.
То есть мы можем больше ребер удалить, больше ребер добавить,
чем в случае Липшица-Востепарева.
Но это более мощное ограничение.
Мы больше свободы даем графам различаться,
а ДФ требуем, что даже при этой свободе она отличается не больше, чем на единичку.
Сейчас понятно, что я сказал?
Понятно, что хроматическое число Липшицева и по вершинам тоже.
Ну это вроде очевидно.
Мы красим же вершины.
Если мы испортим окрестность только одной вершины,
выкинем что-то, добавим что-то.
Но в крайнем случае эту вершину можно будет не докрасить или перекрасить.
Но ничего же другое не потребуется менять.
Поскольку только одна вершина поменяется,
то и Ф, то и Х поменяется не больше, чем на единичку.
Вот есть общая теорема.
Я не утверждаю, конечно, прямо частным случаем является нераненство в большом уклонении.
Смысл в другом.
Теорема, которую я сейчас сформулирую, она и по формулировке очень похожа,
и доказывается на самом деле похожим образом.
Но чтобы ее доказать, надо, например, знать, что такое Мартингал.
А это теория случайных процессов.
И довольно много всего про этот Мартингал еще доказать.
А в итоге получится вот это смешное рассуждение с экспонентом.
Ну не смешное, но симпатичное, что ли.
Мне кажется, хорошее.
В общем, теорема называется, наверное, ее стоит назвать нераненство Азумы.
Хотя нераненство Азумы это что-то немножко другое.
Но пусть будет называться так, чтобы вам просто легче запоминать.
Оно следует из нераненства Азумы.
А что такое нераненство Азумы, я даже говорю.
Потому что там Мартингал.
А это я сейчас сформулирую в терминах вот этих Липшицевых функций.
Значит, утверждается, что если f Липшицева по хребрам,
то вероятность, ну давайте я напишу как в Чебышове с модулем.
Но понятно, что без модуля будет, конечно, то же самое.
Того, что модуль f минус мат ожидания f больше либо равняется какого-то положительного числа a.
Ну здесь можно написать, как обычно, для любого a большего нуля.
Давайте уж напишу, чтобы было аккуратно.
Вероятность, с которой модуль разности больше либо равняется 2a не превосходит e в степени минус a квадрат поделить на,
сейчас скажу тут надо аккуратно, на 2c из n по 2.
Наверное, не очень видно.
Вот здесь в интеллигенте написано c из n по 2.
Но это число ребер случайно в графе, в полной графе, наверное, совершенно.
То есть там, вот если здесь монетка бросается n раз,
то тут, поскольку речь идет про случайный граф, монетка бросается столько раз, сколько есть ребер.
Поэтому это прямой, на самом деле, аналог того, что там, но вот так.
Минус a квадрат поделить на 20 из n по 2.
Если f липшится по вершинам, то вероятность, ну уже не буду писать для любого a, то же самое,
того, что f минус ef больше либо равняется a не превосходит e в степени минус a квадрат поделенное на 2n минус 1.
Ну, не буду пояснять, почему там f минус 1, а не, не важно.
Так, эта теория идет в курсе без доказательств.
Хоть что-то без доказательств.
Нет, ну вот я предпослал ей просто неравенство большого уклонения, чтобы было понятно,
что вот здесь оно в конечном чете как-то зажито.
Ну, кто захочет разобраться глубже, того я, конечно, направлю.
В литературе есть, например, просто моя книжка «Модель случайных графов»,
которая здесь есть в библиотеке, может, скачивается в интернете, я не знаю.
Там это все очень подробно изложено, и что такое мартингал на пальцах.
То есть это в принципе доступно, конечно, пониманию второго курсника.
Ничего там такого страшного сложного нет, ну нет времени так закапываться.
Вот в это надо будет сейчас в смысле поверить.
Ну, я написал, как я уже говорил, вот оба этих неравенства с модулями.
Да?
Усилили.
А, слушайте, с модулями я неправильно написал, кстати, вот так написать.
Двойка, двойка.
Ну, это, конечно, фигня, потому что главное это экспоненты, но все-таки надо писать правильно.
Я написал неправильно, надо умножить, я забыл, виноват.
Если модуль снять, то это будет неправильно.
Это неправильно, надо умножить, я забыл, виноват.
Если модуль снять, то эта двойка как раз пропадет.
Я сейчас стал думать, как снять модуль, и вспомнил, что двойку-то я забыл.
Вот, понятно, что можно написать вот так.
Ф минус ЕФ больше либо равняется А.
Что там такое опять?
С вероятностью не больше, чем просто Е в степени минус А квадрат,
на что-то в зависимости от того, по кому липшится ВТФ.
Ну, и то же самое написать, что ф минус ЕФ меньше либо равняется минус А,
и тут будет то же самое.
Уже без двойки.
Двойка складывается как сумма этих условий.
Да, кстати, вот это сильнее было.
А?
Ну, на самом деле, да, доказывается вот это, а отсюда уже следует вот это.
Вот так вот надо понимать.
Вот это верно, и отсюда следует вот это.
Ну, поскольку я не доказываю ни то, ни другое, то, конечно, вам не все.
Вот.
Так.
Последний вопрос перед перерывом, товарищи.
По-вашему, какое неравенство лучше?
То есть с какими случайными причинами лучше работать с точки зрения, ну, как Е в минус 50 там было?
Вот когда будет поплотнее концентрация ЭФ около своего среднего?
У верхнего, наверное, у нижнего.
У верхнего или у нижнего?
Нет, у нижнего тут минус, а делится на меньшее число, чем тут.
Тут Н квадрат, а тут Н.
Оно в знаменателе.
То есть само число без минуса вот здесь большое, а вот здесь маленькое.
Ну, значит, Е в минус этой степени маленькое, а Е в минус этой степени большое.
То есть если нам посчастливиться про какую-то функцию понять, что она липшится даже не по ребрам, а по вершинам,
а это более сильное свойство, как вы помните.
Если нам это посчастливится, например, с романтическим числом это так,
то получается, что очень высоко концентрируется, очень плотно концентрируется случайная гречена ЭФ около своего мат ожидания.
Помните это слово концентрация, которое я говорил, когда формулировал теорему Балабаши на прошлой лекции?
Вот это она, сам она и есть.
Но жизнь наша будет непростой.
Сейчас будет перерыв, а потом я буду пытаться сделать катарсис.
Перерыв, я предсказал правильную.
Напоминаю теорему, которую, прежде всего, хочется с помощью этой красоты доказать.
Теорема Балабаша номер один, она звучит так.
Пусть П равняется Э в степени минус альфа, где альфа от пяти шестых до единицы.
Когда существует У, которая зависит от Н и от Б, ну или от альфа, такая, что симпатически, наверное,
хи от Ж принадлежит У, У плюс один, У плюс два и У плюс три.
В точности так ведь было в прошлый раз, да?
Повторяю, писать здесь от Н альфы или от НП это одно и то же, потому что П однозначно задает с альфой.
Вот, давайте я сформулирую сначала техническую лему, которую, вероятно, я не успею сегодня доказать, но я ее докажу обязательно.
А может, успею, как дело пойти?
Я докажу теорему лучше, чтобы катарсис был, а лемма техническая, она тоже красивая, но ничего в ней такого особенного нет.
Катарсис будет, когда мы применим лему вместе с той теоремой Азумы и получим, собственно, результаты концентрации хром-числа.
В этом мой замысел, то есть замысел минимум на сегодня, это доказать теорему по модулю леммы, которая сейчас появится.
Значит, лему утверждает следующее.
Существует такое N нулевое, что для всех N больше не браных Н нулевого достаточно большой является следующая вероятность.
Это вероятность того, что для любого S из V, что такое V, я вот здесь напишу, V это просто множество вершин нашего случайного графа,
который мы всегда читаем совпадающим просто с начальным отрезком натурального варианта.
Так, у нас есть множество вершин случайного графа.
Я напишу, для любого под множество этого множества такого, что мощность S не превосходит, давайте, корень из N помножить на логариф МН,
но это непонятно, куда взялось, это надо доказывать.
Значит, для любого множества достаточно маленькой мощности, что выполнено?
Выполнено, что и от G, ограниченного на S, не превосходят дробики.
И вот эта вероятность достаточно велика, а именно, например, не меньше, чем один подредник на логариф МН.
Да, мы живем в G-NP, где B равно N в степени минус альфа.
Я, может быть, этого не сказал, но вот это все здесь повторяется.
То есть мы живем в G от NP так, как вы и есть в теореме Балабаша.
Я утверждаю, что при всех достаточно больших N, вероятность того, что каждая относительно маленькая множество вершин красится
всего лишь в три цвета.
Эта вероятность очень большая, она стремится к единице, причем вот таким вот контролируемым образом.
Так, друзья, смысл утверждения понятен?
Все поняли, что такое G, ограниченное на S?
Взяли множество вершин и посмотрели тот кусок графа, который им порождается.
Любой такой кусок можно покрасить в три цвета.
Это совершенно не означает, что весь граф можно покрасить в три цвета, в пять цветов.
Сам граф может краситься в очень большое количество цветов только лишь.
Но вот событие, состоящее в том, что каждый кусочек относительно маленького размера красится в три цвета,
оно по нашей мере очень близко к единице.
Не очень страшно?
Я это докажу, это как раз техническая вещь, она не требует никаких мартингалов или азумов.
Это простая вещь.
Но это я потом сделаю.
Давайте я лучше из этого и из азума попробую офигенно красиво вывести вот эту теорему.
А потом мы вернемся к ней, скорее всего в следующий раз.
Доказательства теории.
Ну, зафиксируем, наверное, N.
Уж во всяком случае больше либо равное N нулевого, чтобы можно было применять лему.
А может быть еще побольше, если там где-то потребуется.
Ну, пока хотя бы такое.
И какой-нибудь альфа, принадлежащая 5 шестых азимов.
Ну, то есть зафиксируем ИП тоже.
Зафиксируем.
Зафиксируем.
А, ну хорошо, зафиксируем альфу.
Правильно, согласен.
Зафиксируем сначала альфу и потом N.
N, который больше либо равное N в любом.
Согласен, да, правильно.
Да.
В обратной паре.
Что ж там все с маньянами-то и с маньянами.
Сообщений три.
Извините, да, сейчас я.
Нет, оно может зависеть.
То есть мы не знаем, от чего зависит эта скорость сходимости.
Оно может зависеть от альфы, да.
N нулевое может зависеть от альфы, да.
Поскольку я доказательства не приводил, то да, оно может зависеть от альфы.
Оно зависит от альфы, это я понял.
Вы правильно сказали, действительно лучше сначала зафиксировать альфа,
по нему фиксируется N нулевое,
а дальше берем любое N, которое больше либо равное N в любом.
Поскольку здесь утверждение асимптонически почти наверное,
а альфа фиксируется с самого начала, нам не важно, с какого N мы начинаем.
Главное, чтобы в пределе все получилось как надо.
Так, ну хорошо, это все фигня, это такой анализ математический.
Давайте я вам сейчас У сразу определю.
Ну, конечно, товарищи программисты на меня обидятся за такое определение.
У, потому что оно неэффективное, конечно.
Значит, давайте вот эту функцию У выберем следующим образом.
Вот, только что зафиксируем N, альфа.
Значит, У выбирается как минимальное число.
Такое, что вероятность, с которой хи аже.
Так, не превосходит У.
Больше либо равняется 1, минус тот же самый 1 на логарифмент, как и здесь.
Это я только для красоты, для лучшей запоминаемости.
На самом деле не важно, конечно.
Важно, чтобы это просто стремилось к единице.
Вот вы сразу для себя помейте, что я выбрал эту функцию не из каких-то мистических соображений,
а как любую, которая стремится к нулю, мне этого хватит в итоге для доказательства.
Мне просто кажется, что если везде написать одинаковые функции, то запоминать приятнее.
Но, в общем, это не важно.
Так, минимальное такое число У, сейчас надо еще понять, правильно я написал или нет.
Но, по-моему, правильно.
Смотрите, если я вот здесь вместо У напишу N, ну просто возьму и напишу вероятность того, что хи аже не превосходит N, то это будет 1, правильно?
А если я напишу вероятность того, что хи аже не превосходит 0, то это будет 0.
Ну, потому что хроматическое число лежит в пределах от единицы до N, правда же?
Я просто хочу сказать, что чем ниже я замещаюсь от N к нулю, чем меньше я беру эту верхнюю границу, тем меньше будет эта вероятность.
Ну, не больше, по крайней мере, то есть она монотонно не возрастает, правильно?
Поэтому, действительно, если я задаюсь вот такой границей для значения вероятности при моем конкретном методе, конкретное число,
то совершенно корректно говорите о выборе самого маленького У, при котором такое...
...будет даже то же самое.
А?
Это разум будет то же самое.
Ну, если с точки зрения 4.
Что-что?
Я сейчас однозначно задал некоторое У, я утверждаю, что да, это и будет то самое У.
Да, у нас же очень маловероятно, что цепь Р больше, чем экстремент, плюс один, а сетатические никогда.
Ну и что?
Нет, подождите, я не понимаю, о чем речь?
Нет, нет, нет, смотрите, конечно, отсюда следует...
Сначала У определено корректно, давайте с этого начальника.
Я объяснил, что оно определено корректно, да?
Ну, конечно, его искать непонятно как, это уже другой вопрос.
Но давайте, да, посмотрим.
Значит, вероятность того, что хиадже, я это и хочу сказать, не превосходит У минус один.
Это какая вероятность?
Меньшая, чем один, минус один на алгоритме.
Правильно?
Так?
Значит, вероятность того, что хиадже больше либо равняется У больше, чем один...
Ах ты!
Все, я...
Подождите.
Да, да, да, вот тут я ошибся.
Я понял, глупость написать.
Конечно, вот так надо писать, вот так.
Вот так надо писать.
Конечно, но все равно все корректно, конечно.
Да, здесь получается то, что надо, а не какая-то глупость.
Да, меньше, чем один поделить на алгоритм Н.
Сейчас.
Меньше, чем один, минус один поделить на алгоритм Н.
А вот интересующая нас вероятность больше, чем один, минус...
Да что ж это такое-то?
Ай-ай-ай, что-то не так.
Подождите.
Ой, извините, что же я путаюсь-то?
Здесь правильно написано, здесь написано правильно.
Сейчас написано правильно.
Теперь я пишу обратное неравенство.
Хиадже не превосходит У минус один.
И что я здесь пишу?
Ай-ай-ай, что ж я так пуплю-то?
Друзья, сейчас все нормально объясню, извините.
Еще раз, смотрите, У это самое маленькое число,
У это самое маленькое число, при котором все еще выполнено это неравенство.
Значит, вероятность того, что Хиадже не превосходит еще меньшего числа,
меньше либо равняется один на логарифме.
Или даже меньше, да?
Строго, чем один на логарифме.
Верно.
Теперь вроде верно, да.
А теперь я пишу действительно отрицание уже этого события,
и это больше, чем один минус один на логарифме.
Все.
Конечно, строго неравенство, то есть с помощью...
Так, ну слушайте, я запутал, конечно, сейчас вот, понятно?
Не надо больше повторять?
У это целое число.
У это целое число, да.
У это целое число.
Мы берем минимальное целое число в У,
в романтическое число целое, и У тоже целое.
Такое, что Хиадже не превосходит уз вероятности больше либо равняется один на логарифме.
Отрицание не должно having более либо равно.
Почему?
Почему?
Если вероятность события строго меньше,
вероятность его отрицания это один минус вероятность его,
значит она будет строго больше, чем один минус его вероятность.
Расто媒 About …
Вероятность A с чертой.
Это просто 1 минус вероятность А.
Если вероятность A чем-то меньше, то вероятность A совсем больше.
Вероятность A меньше чем 1 на логарифум...
Значит разность больше, чем 1 минус 1 на логарифум.
Это как раз просто.
Так, ну что, сейчас понятно, почему я брал у минимали?
Так, пока у меня получилось, извините, только вот от этого ограничивается.
Откуда у плюс три-то будет?
А у плюс три будет вот из этой тройки.
Вот это три, а это у плюс три.
Ладно, сейчас я все напишу. Пока понятно, как я его определил.
Пока понятно только, что есть вот такое событие, вероятность которого большая.
Это прекрасно. Но нам-то нужно, чтобы не настолько же большое, например, была вероятность события того, что хи не превосходит у плюс три.
А это мы пока ниоткуда не взяли.
Вот давайте сейчас возьмем некую величину.
Достаточно офигенно, ну не, негде писать.
Давайте вот тут сотрем эти рассуждения.
Напишем так.
У как же?
Это будет минимальная К.
Такое, что существует у из В мощности К.
И такое, что если мы...
Давайте не уманим, когда же будет прием.
С, чтобы было похоже на то, как в ленте.
Это оно самое.
Значит, минимальная К, такое, что существует под множество вершин мощности К.
Если g мы ограничим на v минус вот это s.
То будет не больше, чем...
Жуть какая-то абсолютно непонятная покажет.
Скоро будет понятно.
Не, ну да, это с новами совершенно понятно, о чем идет речь.
Вот у нас есть сортелька, которую мы обозначаем В, она состоит из N вершин.
Что такое у от графа?
Это размер самого маленького множества.
Такого, что если мы будем красить граф на вершинах, не принадлежащих этому множеству,
то есть вот тут, вот эту часть будем красить,
то нам хватит вот этих цветов, которые мы сейчас вот так определили.
Так, друзья, вот у вас сейчас будет предкатарсис.
Что?
Это v без s, v с от минус s.
У вас сейчас будет предкатарсис, вы поймете мысль мою.
Если вы поймете следующее.
Представьте себе, что мы сейчас докажем, что скорее всего y не превосходит корень из N на логориф m.
Вот допустим мы это доказали.
Вы просто послушайте пока, не пишите.
Можете написать, конечно, если хотите.
Но представьте себе, что мы вот это доказали.
Ну, согласитесь тогда, что поскольку согласно лемне,
любое множество вот такого размера красится в три цвета с высокой вероятностью,
а само это множество определено таким образом, что дополнение к нему
красятся в у цветов тоже с высокой вероятностью,
то получится у плюс три как раз, как обещано.
Знаете, если окажется, что y на случайном графе нашем
не превосходит такой веричины с вероятностью близко к единице,
ну, например, вот с такой, то мы и получим то, что нам нужно вместе с леммой.
Я потом это аккуратно все пропишу.
Мне хочется, чтобы идея была ясна сразу хотя бы большинству присутствующую.
Что, непонятно, что я сказал или нет?
У нас есть лемма, которая говорит, что любое маленькое множество красится в три цвета,
а здесь говорится, что существует.
Допустим, существует маленькое множество, которое красятся в у цветов.
Дополнение к которому красятся в у цветов.
Значит, мы дополнение покрасим в у цветов, а само множество в три цвета.
Итого будет у плюс три.
Вот такой замысел, но это просто замысел.
Сейчас мы его реализуем.
Где бы только его реализовать?
Вот это меня очень беспокоит.
А, ну, собственно, мне вот этого достаточно.
Мне достаточно того, чтобы листы справили.
Прежде всего, друзья, у, конечно, тикая по внешности своей случайно величина.
Не правда ли?
Смысл ее понятен, но как, например, посчитать ее математическое ожидание?
Я думаю, что никак.
Но вот этому-то сейчас поспособствует вот эта теория.
Не разница. Два зуда.
Это вот она сформулирована ровно так, как нам сейчас нужно.
Чтобы ее применить, давайте попробуем понять, по кому липшица у.
Минимальное число вершин, удаление которых приводит к раскраске в не более чем заданное количество цветов.
По вершинам совершенно верно.
Друзья, понимаете, что по вершинам?
Не, ну, вот вы берете одну вершину в графе и портите как угодно ее окрестность.
Что может произойти с тем минимальным множеством, которое выбиралось для предыдущего графа до и с порченными?
До вот этой порчи.
Что произойдет с этим минимальным множеством?
В крайнем случае оно уменьшится и увеличится ровно на одну эту вершину.
Больше ничего не искажено.
Если в старом графе достаточно было удалить какие-то к вершин, какие-то конкретные к вершин, чтобы все остальное красилось вот цветом,
то вот на одной вершинке испорченном графе в крайнем случае надо удалить еще ее, и тогда все равно, конечно, все будет по-прежнему краситься не более чем вот цветом.
То есть изменение величины ниврик произойдет как раз не больше чем на единицу.
Она липшица по вершинам.
Она липшица по вершинам, и мы помним, что это как раз круто, это дает самую высокую концентрацию.
Я вот здесь специально не писал, на что надо делить, но теперь я напишу, надо делить на дважды n-1, и здесь тоже напишу, на дважды n-1,
потому что я буду пользоваться липшицевостью по вершинам.
Так, понятно?
Так, если я написал, я буду пользоваться сейчас липшицевостью этого y по вершинам.
Давайте предположим...
А нет, секундочку.
Давайте теперь выберем a таким...
Что у нас было там написано?
А?
Отлическое число g ограниченное на что?
На v без s.
А, v без s.
На v минус s, и вот эта теоретика множественная разница.
Так, давайте выберем такое a, чтобы e в степени минус a квадрат на дважды n-1 было строго меньше, чем 1 поделительно логариф men.
Ну каким надо взять a?
Ну, наверное, можно взять его равным корень из 2, n-1, повторный логариф men.
Этого чуть-чуть не хватит, потому что, когда вы возведете в квадрат и разделите на 2, n-1, у вас останется повторный логариф, это будет в точности 1 логариф men.
А нам нужно, чтобы строго было меньше, да?
Господи, ну хотите я 3?
Это будет точно строго меньше.
Так, друзья, вы слеживаете за этим? Вы умели, это трудно.
Ну, елки-палки, вот это надо возвести в квадрат, поделить пополам, и на n-1, n-1 сокращается.
Это 1,5 повторных логариф men, e в степени повторный логариф men это логариф men, но он еще в степени 1,5.
Конечно, это меньше, чем 1 на логариф men.
Так, ну просто, вот наша n зафиксирована конкретно, взяли а вот такой, это какое-то конкретное число, так оно получит.
Теперь смотрите, предположим, что математическое ожидание нашего у меньше либо равняется вот это 2.
Вот сейчас ждите катарсис, товарищи, вот если вы еще не отрубились, то сейчас ждите катарсис.
Вот очень скоро.
Вы понимаете, что вот сейчас, что происходит, мы выбрали u, вот взяли такой y, поняли, что он липшится в предрешинам,
подобрали какое-то а, пока не понятно зачем, вот сейчас будет понятно, зачем такое подобрали,
и вместе с этим будет катарсис, друзья, слушайтесь, в эту музыку.
Вот давайте предположим, что мат ожидания у не больше, чем а, казалось бы, откуда взять мат ожидания.
Вот предположим, что оно не больше, чем а.
Посмотрим вот на этот вариант неравенства зубов, на второй, вот сюда посмотрим.
Предполагаю, что u не больше, чем а.
Вот так перепишем, у меньше либо равно u минус а, и мы предположили, что u не больше, чем а.
Чем а, да?
А, то есть надо было, это хрень.
Я сегодня в ударе просто.
Кохнуло ты.
Кохнуло, да, уже меня кохнуло, сейчас.
Дурость, конечно, так, сейчас, секунду, сейчас, секунду буквально.
А, все, все, все, все.
Давайте, конечно, наоборот, да.
Да, да, да, я просто уже решил для себя проверить.
Да, предположим, что u больше не равняется а, конечно.
Смотрим сюда, u минус а, тогда больше не равна 0, правильно?
Тогда это, конечно, больше либо равняется, чем вероятность, с которой u не превосходит 0.
Это вот если так предположим, то получается вот это.
Согласны?
У не превосходит чего-то, вообще говоря, большего 0, и у не превосходит 0.
Так, что можно сказать про эту величину?
Она не больше, чем e в степени минус а квадрат на 2n минус 1.
А у нас а подобрана таким образом, чтобы это было меньше, чем 1 на логарифуме, правильно?
Так, это вроде очевидно.
Неужели никто еще не понял?
Смотрите, что такое y не превосходит 0?
Это значит, что y равно 0.
Но что значит, что y равно 0?
Значит, ничего не надо удалять из графа, чтобы он красился в u цветов.
То есть, вот это вот, это в точности вероятность того, что хиаджи не превосходит u.
Вообще ничего не надо удалять, сам граф красится в u цветов.
Правильно?
Так, а теперь идем сюда.
Идем к нашему определению u.
С какой вероятностью хиаджи не превосходит u?
Больше либо равный 1 поделить на логарифмен?
Постойте, а даже меньше, чем 1 поделить на логарифмен?
Противоречие.
Противоречие.
По-моему, это очень круто.
Ну да, я тут, конечно, постарался немножко против себя, перепутал неравенство.
Ну ладно, следовательно, u на самом деле меньше, чем а.
Мы неправильно предположили, у, конечно, меньше, чем а.
Это еще не все.
Давайте воспользуемся первым вариантом этого неравенства зума.
Теперь первым вариантом воспользуемся.
Что мы знаем?
Мы знаем, что вероятность того, что у не превосходит u, это я вот сюда переношу.
Опять, меньше, чем 1 поделить на логарифмен.
Я не переписываю, но это меньше, чем 1 поделить на логарифмен.
Так.
Поскольку мы теперь знаем, что у меньше, чем а, строго.
Ну, строго, не строго, не важно.
То, что мы можем сказать?
Мы можем вот сюда продолжить неравенство и написать вероятность того, что у не превосходит 2а.
Вот так.
Вероятность, которой у не превосходит 2а, поскольку а больше, чем не у, конечно, не больше, чем вероятность вот этого.
Ну, и значит, меньше, чем 1 поделить на логарифмен.
Что?
Вроде в обратную сторону.
Вроде в обратную.
А больше, чем не у, значит, 2а больше, чем у плюс а.
То есть, мы смотрим на вероятность того, что у не превосходит 2а.
Что это такое?
Что ж меня так ложают?
Что ж меня так ложают?
Извините, пожалуйста, да.
Да-да-да, здесь, конечно, больше либо равно, здесь больше либо равно, здесь больше либо равно.
Кошмар.
Чего-то я сегодня много глупых ошибок напускаю.
Конечно-конечно, я переписал вот это, но перепутал неравенство почему-то.
Как я его мог перепутать?
Хрен знает.
Ну, в общем, в эту сторону.
А теперь все правильно, да?
Виноват, чего-то я не знаю, почему сразу спеваюсь немножко.
Так, ну, не забыл пока никого.
Нормально?
Извините, да.
Так, ну, чего у нас получилось?
Давайте суммируем, что у нас имеется на данном этапе.
Ну, вот левую нельзя стирать, она нужна.
А теоремски я могу стирить.
Значит, что у нас имеется?
У нас имеется, давайте вот это вот событие огромное-преогромное.
Назовем его A1.
У нас имеется вот это вот событие, назовем его A2.
И у нас имеется вот это вот событие, нет, не вот это, а его отрицание.
Давайте вот его перепишем.
Вероятность того, что у меньше чем 2а, это 2 на форене с 3, n-1 в логарифе повторный n.
Так, эта вероятность у нас больше, чем опять 1-1 на логарифе.
Все, это будет у нас событие А3.
Так, понятно, определил 3 события, сейчас не наложал, нигде в неравенствах.
Я очень постараюсь больше не наложать, времени осталось немного, наверное, у меня есть шанс.
Вроде нормально. Теперь смотрите, я просто хочу теперь доказать.
Давайте так, возьмем граф Ш, преднадлежащий А1, пересеченная с А2, пересеченная с А3.
Возьмем любой граф, который обладает сразу тремя свойствами.
И вот этим, и вот этим, и вот этим.
Что про этот граф можно сказать?
Ну, во-первых, самое очевидное, у этого графа хроматическое число больше не поравняется у правых,
потому что он удовлетворяет свойству А2.
Так, что еще можно сказать?
Можно сказать за счет свойства А1, что у него красится любое множество вот такой мощности в три цвета, в не более чем три цвета.
Так?
А за счет свойства А3, что можно сказать?
Что самое маленькое множество, дополнение к которому красится в у цветов, имеет размер с запасом меньше, чем вот эта величина.
Ну, если считать, что N больше, чем N0, то по-моему корень из повторного логарифма и логарифма, это такой большой запас.
При больших N, мне кажется, что запас довольно приличный.
Ну, я, конечно, здесь тоже мог бы писать корень из повторного логарифма, но с логарифмом проще просто, короче, записывается.
Так, друзья, понятно, что из того, что G принадлежит одновременно А1 и А3,
следует, что в нем каждое маленькое множество красятся в три цвета и что существует маленькое множество дополнения, к которому красится в у цветов.
Вот сейчас я понятно сказал, каждое маленькое красится в три цвета, и существует маленькое дополнение, к которому красится в у цветов.
по которому красятся вуд-светов.
Вот возьмем это маленькое, покрасим его в три цвета,
а все остальное вуд-светов.
Следует, что хиадже не превосходит у плюс три.
Любой граф, который одновременно обладает тремя свойствами,
таков, что он действительно имеет хроматическое число
в пределах отуда у плюс трех.
Нормально объяснил?
Так, друзья, мне кажется, всем же понятно,
что вероятность пересечения вот этих трех событий
стремится к единице или не всем.
У нас каждый из этих трех событий имеет вероятность
ограниченной снизу вот такой величиной.
Я могу явно написать, ладно, упражнение очевидное.
Вероятность А1 пересеченная СА2 пересеченная СА3
больше чем один, минус три поделить на логариф М.
Умоляю, только никакой независимости тут, конечно, нету.
То есть ни в коем случае не надо говорить,
что вероятность пересечения не меньше,
чем произведение вероятности.
Этого я не утверждаю.
Но очевидное упражнение, тем не менее,
что вероятность пересечения не меньше того, что я написал.
Кто-нибудь понимает, как решать упражнение?
Что, не понимаете, что ли?
Вот мой.
Ну вот так надо написать.
Пересечение это то же самое, что А1 с чертой,
объединенное СА2 с чертой, объединенное СА3 с чертой.
И все это с чертой.
Вот, по-моему, это уже должно достаточно понятно
объяснять, как решать упражнение.
Понятно, да?
Ну все.
Все, то есть я доказал по модулю леммы.
Следующую лекцию я начну с доказательства этой леммы.
И дальше пойдем ко второй теории мипалабаша,
которая про П равна 1 и 2.
Она другая, подумай.
Там своя липшица, в принципе.
Не такая.
Ну все тогда, на сегодня достаточно.
Спасибо.
