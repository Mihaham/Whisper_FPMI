Я считаю, что мы должны были работать с нормализованными данными.
В действительности, это не обязательно, потому что мы можем работать также с
начальством данных, в результате нормализации, но с нормализацией иногда это более
комфортно, и это один из способов, чтобы участвовать в нормализации.
И модель, которую я использовал, которую я представил, это был
модель, в котором вместо использования этих первоначальных данных, даже в нормализованной форме,
мы смещаем их к векторам деменциала,
меньше чем один, в сравнении с деменциалом
первоначальных данных, мы смещаем их к
векторам деменциала, к углу каждой части
деменциала.
И потом, эта работа была использована в многих сетях,
мы имеем несколько публикаций об этом,
включая одну публикацию с Борисом в журнале в России, но потом мы
конфронтировались с следующим проблемом, который был действительно очень серьезным
ситуацией, который был первый раз, когда я работал с большими данными,
когда нужно было делать это с миллионами сетей этого рода,
которые были, которые презентировали,
этот курс презентировал консумерное поведение очень большой ретейл
сетей. Я не могу сказать об этом открыто, потому что я подписал контракт с НДА, но
это было в Европе, и у нас были миллионы этих курсов,
и
здесь написано индекс 1, индекс 2, но это, например, продукты.
Ну,
Редактор субтитров Е.Воинова Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
Корректор А.Кулакова
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Важная часть этой истории
Благодарю про Brisbane прощения
Д般 scientifically
Д般 Physically
dismissed
Вы27
И you
У рожденияSe sec
Дского родного
Борис Григорьевич, как известно, имеет разнообразные научные интересы,
но, так сказать, на мой взгляд, может я ошибаюсь, он меня поправит,
что, конечно, основные интересы сосредоточены вокруг кластеризации,
поэтому я буду говорить сейчас исключительно о кластеризации.
И здесь, конечно, наверное, трудно чем-то удивить новым Борис Григорьевича,
поскольку я обычно своим студентам говорю, что когда возникает какой-то вопрос
ложный, связанный с кластеризацией, я говорю, у вас есть уникальная возможность
получить консультацию с первого хуста человека, который знает про кластеры все,
и направляю их к вам. Я не знаю, доходит ли они до вас, но я так делаю.
Нет, не доходит.
Да, ну вот так. Поэтому удивить как бы нечем тут в этом плане, я так думаю,
но можно удивить именно объектами кластеризации, что кластеризовать.
В этом смысле я хочу сейчас как раз рассказать о кластеризации таких объектов,
которые называются телами свидетельств. В рамках теории Демслера-Шефера
рассматриваются такие объекты, которые называются телами свидетельств.
Они имеют такую сложную структуру. Во-первых, это такие пары,
состоящие из наборов подможеств некоторого множества и связанных с ними
функциями массы. Сами подможества характеризуют степень уверенности,
то множество, которому может принадлежать истинная альтернатива,
а массы, частоты характеризуют степень уверенности, что истинная альтернатива
принадлежит тому или иному множеству. Вот эти тела свидетельств могут иметь
довольно сложную структуру. Да, сами вот эти подможества называют
фокальными элементами. Они могут иметь довольно сложную структуру, могут пересекаться,
могут вкладываться, могут не пересекаться и так далее и так далее.
И таких фокальных элементов может быть довольно много в реальных телах свидетельств.
Поэтому требуется их кластеризовать для того, чтобы решать, во-первых, задачу
аппроксимации, когда мы заменяем тело свидетельств из множества.
Заменим более простым тему свидетельств, состоящих из нескольких фокальных элементов,
но тем не менее, чтобы какая-то мера близости между этими объектами выполнялась.
Во-вторых, вычислительно-осложно.
Основные вычисления там связанные. Они носят экспоненциальный характер.
Поэтому чем меньше тел свидетельств, тем вычислительная сложность этих алгоритмов
связанных с обработкой таких объектов будет выше.
Это что касается мотивации исследований.
Пару слов скажу о самой этой теории Демпстера-Шефера, в рамках которой
рассматриваются эти объекты тела свидетельств.
Это довольно старая теория. Берет свое начало от двух таких работ,
пионерских Демпстера 1967 года и Шафера 1976 года.
Демпстер – это чистый статистик из Гарварда, сейчас очень приклонного возраста.
Недавно я даже видел его работу совсем свежую.
Шафер помоложе, значительно моложе и имеет такие разнообразные интересы.
В это время он был совсем молодым человеком, когда написал эту монографию.
Он как раз занимался развитием этой теории.
Эта монография, кстати, не потеряла актуальность даже в настоящее время.
Основные тут моменты такие, что рассматривается некоторое множество,
универсальное множество, как обычно Х, и на нем рассматривается какое-то
конечное подможество этого множества. Называют эти подможества фокальными элементами.
Так будем обозначать.
С этими подможествами связана функция масс.
Функция масс – это не отрицательная функция, удовлетворяющая условия нормировки,
что сумма всех масс равна единице.
Вот такая как раз пара из множества фокальных элементов и функций масс называется телом свидетельств.
Считается, что для каждого фокального элемента масса не нулевая.
Простейшим телом свидетельств является категоричная телосвидетельств,
состоящая всего из одного фокального элемента с единичной массой.
Любое телосвидетельство можно представить в виде выпуклой комбинации категоричных тел свидетельств
с коэффициентами равными массам.
Чуть посложнее, чем категоричная телосвидетельств.
Это такое свидетельство, называется простое.
Когда с каким-то коэффициентом мы берем категоричное телосвидетельство,
построенное на каком-то фокальном элементе,
а всю остальную массу относим к всему универсальному множеству Х.
Вот эта часть, второе слагаемое, она характеризует как бы степень нашего незнания
о принадлежности истинной альтернативы множеству А.
Степень нашего незнания.
С этим телом свидетельств связывают несколько таких функций.
Функции множеств, но самые популярные из них это функции доверия,
функции правдоподобия, которые вот так строятся,
и которые являются нижними и верхними оценками вероятности события того,
что истинная альтернатива принадлежит множеству А.
Значит, с такой с графовой точки зрения телосвидетельство можно считать
вот гиперграфом, вчера как раз этот термин уже вспоминался на конференции.
Можно считать, что это есть такой гиперграф, когда у нас элементы множества Х
это вершины этого гиперграфа, а гипердуги это как раз вот эти фокальные элементы.
Вот пример приведен, вот так можно в строчку это записать, как выпуклую комбинацию
категоричных телосвидетельств, построенных на фокальных элементах.
Вот здесь внизу фокальные элементы как раз перечислены нашего телосвидетельства.
Это масса их, а это вот такое гиперграфовое представление этого телосвидетельства.
Так вот, такие объекты надо кластеризовать. Что кластеризовать?
Кластеризовать, конечно, в первую очередь нужно вот эти фокальные элементы,
но с учетом их масс, конечно. Если там какой-то фокальный элемент имеет маленькую массу,
то он может быть для нас не такой важный. Если там большая масса,
то это более важные такие фокальные элементы, с учетом масс, конечно.
Причем вот здесь при кластеризации часто метрические характеристики не важны.
Не столь важны метрические характеристики. Сколько? Важны характеристики,
связанные с понятием конфликта между фокальными элементами,
между телами свидетельств, конфликта либо противоречия.
Что можно считать конфликтом и не конфликтами фокальные элементы?
Если сильно пересекаются, грубо говоря, сильно пересекаются два фокальных элемента,
то такую пару можно назвать парой не конфликтных фокальных элементов,
поскольку истинная альтернатива, один источник, например, принадлежит множеству A,
второй множеству B. Эти множества довольно близкие, и в этом случае
эти свидетельства от этих источников, они действительно воспринимаются не конфликтно.
Если они слабенько пересекаются, то вот здесь уже есть какой-то слабый конфликт.
Если они вообще не пересекаются, то здесь уже есть такой сильный конфликт
между этими фокальными элементами и соответствующими свидетельствами.
Если у нас есть тела свидетельств из множества таких пар построенных,
множество фокальных элементов, то можно по-разному мерить конфликт,
но вот такая белинейная форма, самая популярная для измерения конфликта
сумма произведений масс фокальных элементов, которая берется по парам фокальных элементов,
которые между собой не пересекаются. То есть тут учитывается только третья ситуация,
конфликтность. Средняя не учитывается, хотя можно ее учитывать,
вот здесь нужно просто вставить какой-то коэффициент, меру пересечения,
типа индекса Джакара или еще что-нибудь, и тогда можно и учитывать слабую ситуацию,
но не суть, не в этом суть. Что касается кластеризации,
то тут есть несколько подходов, которые я сейчас коротко охарактеризую.
Первый подход – это такая иерархическая кластеризация.
Она была предложена лет 20 назад Дено, Тири Дено,
и в некоторых еще работах она встречалась, даже более ранние работы есть,
и позже развивалась. Это такая вот, как бы мы сказали,
агломеративная иерархическая кластеризация. В этом случае строятся два тела свидетельств –
тело внутренней кластеризации и внешней кластеризации.
Строится так, это берутся, да, вот обозначено они F-, F+, тело внутренней кластеризации,
внешней кластеризации. Значит, тело свидетельств внутренней кластеризации
строится на пересечении некоторых множеств из исходного множества фокальных элементов,
а тело свидетельств внешней кластеризации на их объединение.
При этом и в том, и в другом случае массы суммируются.
Массы просто суммируются. Значит, какие пары выбирать для пересечений и для объединений,
но решается по-разному. Ну, например, можно построить,
использовать вот такой, например, функционал – функционал неточности тела свидетельств.
Значит, чем больше у нас тел свидетельств больших по мощности с большими массами,
тем более неточное у нас это свидетельство.
Так вот, можно выбирать такие пары, которые при объединении либо при пересечении
мало меняют вот этот функционал неточности. То есть в этом случае можно ожидать,
что какая-то мера близости у нас будет, выполняться мера близости,
между тем, что мы получим в результате этой иерархической кластеризации
и исходным телом свидетельств.
Но вот если расписать для пар этот функционал, то он при объединении пар примет такой вид,
а при пересечении такой вид. Ну и тогда, соответственно, выбираются те пары
для внутренней кластеризации, которая минимизирует этот функционал,
для внешней, которая минимизирует этот функционал.
На том же примере, который там был, у нас в середине тела свидетельств,
в результате применения этой внешней внутренней кластеризации мы получим такие результаты.
Вот будет такая внутренняя кластеризация и вот такая внешняя кластеризация.
То есть в этом случае число кластеров задается заранее,
на каком этапе мы хотим остановиться, сколько кластеров получить.
Ну вот здесь, например, два кластера дошли до двух кластеров.
Получается вот такая иерархистская кластеризация.
Другой класс кластеризации, он связан с оптимизацией конфликта,
вот о чем я как раз говорил. В этом случае по-разному поступает.
Например, можно выделить некоторое маленькое под множество фокальных элементов,
вот альфа штрих, которые из таких значимых фокальных элементов.
Что такое значимый, сейчас я поговорю об этом.
Ну и потом, после этого можно перераспределить остальные,
например, фокальные элементы, отнести вот к этим значимым,
мы получим тогда такие какие-то кластеры.
Либо можно использовать вот какой-то аналог алгоритма комбинц.
Ну вот что касается первого подхода, когда мы выделяем значимые элементы,
то вот в прошлом году как раз моим соавтором Андреем Бронеевичем вышла такая статья,
где в том числе, она не только этому посвящена,
в том числе был предложен такой алгоритм, основанный на так называемой функции плотности конфликта.
Плотность конфликта это такая функция, которая принимает большие значения в данном множестве,
если рядом с ним, грубо говоря, нет пересекающихся множеств,
либо нет сильно пересекающихся множеств.
В идеале функция равна единице, принимает максимальное значение, если таких вообще нет.
И наоборот, нулевое значение, если это множество пересекается со всеми другими множествами Иисра.
Множество фокальных элементов.
Ну третье условие – это условие линейности для простоты.
Так вот, есть ли такую функцию конфликта?
Да, можно несложно показать, что такая плотность, она будет как раз равна единице,
минус функция правдоподобия, о котором я говорил,
которая является верхней оценкой вероятности события.
Она тут будет так вычисляться.
Ну и кроме того, можно еще учесть массу своего фокального элемента.
То есть нас интересует только фокальный элемент, который,
когда мы говорим, тут будет такой довольно простой,
мы упорядчиваем все множество фокальных элементов по убыванию вот этой функции плотности конфликта.
И выбираем значимые конфликты элементы, начиная в соответствии с этим порядком.
Ну и кроме того, используем еще функцию расстояния так, чтобы рядом два фокальных элемента
из этой последовательности, находящейся рядом, чтобы они не попали в это множество h'.
То есть используем какую-то метрику.
Что касается метрики, можно использовать, конечно, метрику между фокальными элементами
как мощность симметрического разности множества,
либо, если это измеримое пространство, то это какая-то мера измеримого разности множества.
Если это метрическое пространство, можно использовать метрику Хауссдорфа.
Но вот чаще используют вот такую метрику, очень популярна вот в этой теории,
вот такая метрика, которая с индексами Джакарда, тут такая белинейная форма.
Это действительно метрика, можно доказать, что это настоящая метрика, вот она чаще всего используется.
Этот алгоритм, конечно, имеет свои аналоги, такие точечные.
Например, один из таких алгоритмов, я привел ссылку, но таких алгоритмов довольно точечных много.
Если тот же пример использовать, то в результате мы получим два вот таких кластера.
После этого можно, как говорят, решая задачу минимизации расхождения между исходным телом свидетель
и нашим телом свидетель с какими-то коэффициентами неизвестными, найти эти коэффициенты.
Мы в результате получим очень близкий результат к тому, что было у нас в эроргической кластеризации.
Очень близкий, там было 0.7, 0.3, но здесь масса чуть-чуть другая.
Можно в общем случае решать задачу перераспределения фокальных элементов по выбранным кластерам.
Решать ее следующим образом.
С каждым выбранным кластером можно связать свое тело свидетельство, которое строится вот таким образом.
Масса того элемента, который у нас был в исходном теле, совпадает с исходной массой.
Но тут тогда сумма всех этих масс внутри кластера не будет равна единице в общем случае.
Поэтому оставшуюся часть массы мы отнесем на массу всего множества.
Это то, что мы говорим, не знание массы всего множества.
Вот так можно, как говорят, натянуть на этот кластер тело свидетельство.
Тогда алгоритм перераспределения оставшихся фокальных элементов по выбранным кластерам h' будет следующим.
Следующий мы берем очередной фокальный элемент, присоединяем его к какому-то кластеру,
потом натягиваем на вот этот новый кластер соответствующий тело свидетельств
и считаем конфликт между новым вот этим телом свидетельств и всеми другими телами свидетельств.
Это будет внешний конфликт между кластерами.
И в том случае, когда мы получаем максимальный внешний конфликт между кластерами,
вот тому кластеру будем относить этот фокальный элемент.
Тут есть полная аналогия с принципом компактности.
Мы должны в один кластер поместить те элементы, которые близки друг к другу, в разные кластеры, которые далеки друг к другу.
Вот здесь вместо метрической характеристики близости используется конфликтность.
То есть в один кластер относим те фокальные элементы, которые мало конфликтны друг с другу, а в разные, которые сильно конфликтны друг с другом.
В результате такой кластеризации мы получим такую кластеризацию, которая цветом обозначена здесь как раз.
Это будет примерно соответствует тому, что было в иерархической кластеризации внешней кластеризации.
И наконец, комминс. Совсем коротко, я понимаю, времени у меня почти не осталось.
В этом случае рассматривается функционал минимизации суммарного внутреннего конфликта между каким-то центром кластера.
Сейчас я расскажу вам, что это такое. Центр кластера – это тоже телосвидетельство.
Что интересно, это не фокальный элемент какой-то, а это именно телосвидетельство, натянутое на какие-то фокальные элементы.
И телом свидетельств, натянутым на элемент этого кластера, вот такой функционал минимизируется.
Что касается того самого интересного, ситуация с центрами кластера.
Центр кластера, если искать его в таком виде, как линейная комбинация категоричных тел свидетельств из этого кластера, что естественно.
То тут не трудно доказать такую теорему, что вот этот функционал при фиксированном разбиении, но мы меняем центры кластеров.
При фиксированном разбиении будет достигать минимума, когда центры кластеров строятся следующим образом.
Строится по этой формуле, естественно, один, но в качестве множества тут выбираются такие множества, которые максимизируют вот такую функцию правдоподобия, суженную на этот кластер.
Сужение на кластер, функцию правдоподобия максимизируют.
В этом случае мы используем классический алгоритм Каминс с такой оговоркой.
Единственное, что тут сложное заключается в том, что вот эта теорема, что в отличие от метрической ситуации, как правило, возможно множество решений, множество коэффициентов будут удовлетворять условиям этой теоремы.
И множество центров кластеров мы получаем, не один центр кластера в этом случае.
Можно, в принципе, работать и с таким множеством, ничего страшного.
Но если мы хотим все-таки сузить, надеяться, чтобы там у нас был один центр кластера, то нужно использовать какие-то дополнительные процедуры, дополнительные условия.
Это могут быть разные условия, например, условия минимизации покрытия.
В общем случае мы получаем не разбиение, а покрытие по крайних элементах.
Можно использовать условия минимизации покрытия, то есть чтобы покрытие было близко к разбиению.
Например, вот такое условие нужно минимизировать, суммарную мощность кластеров.
Либо минимизировать какую-то меру неточности, например такую.
Либо минимизировать, ну в общем разные есть варианты дополнительных процедур, которые позволяют выделить из вот этого множества центров кластера, выделить в каждом кластере по одному центру.
Так, ну вот, например, на том же примере, если посмотреть, то получается, ну тот же самый, в общем-то, получается результат.
Так, ну вот, собственно говоря, и все, что я хотел рассказать.
Да, вот как дополнительный бонус можно использовать вот эту процедуру кластеризации для оценивания меры внутреннего конфликта кластеров, меры внутреннего конфликта тела свидетельств.
Вот когда мы кластеризацию получим, то посчитав внешний конфликт вот для тел свидетельств, натянутых на эти кластеры, мы получим меру внутреннего конфликта, которая вот в общем случае у нас считается как бы сложнее, чем мера внешнего конфликта между кластерами неоднозначной.
Поэтому вот это такой довольно важный момент.
Так, ну вот, пожалуй, и все, что я хотел сказать.
Happy birthday, Борис Григорьевич. Все. Если есть вопросы, я готов ответить.
Подходите к микрофону, заодно проверим микрофон.
Раз, два.
Да, Борис Григорьевич, конечно.
Ну да, мы с вами на двоих тогда будем говорить.
Значит, я не очень понимаю, где взять эти данные? Вот исходные данные для этого кластера. Как это получается?
Это могут быть, например, экспертные оценки.
Первое, что это экспертные оценки?
То есть мы, например, выбираем кого-то, какого-то руководителя выбираем, и опросили коллектив.
Столько-то человек сказали, что они могут, например, ответить так, что мы не можем выбрать кого-то одного.
Из пяти кандидатов я склоняюсь больше к первому, к второму.
Другой скажет, что я из пяти кандидатов склоняюсь ко второму, к третьему и так далее.
Мы получаем вот эти множества. Такая простая ситуация.
Либо это, например, если речь идет о прогнозировании каких-то...
Ну, например, прогнозирование стоимости акции, какая будет, например, через месяц.
То есть эксперт говорит о том, что стоимость акции будет в каком-то интервале лежать, например, от 40 до 50 единиц.
То есть вот это уже будет фокальный элемент.
Он не говорит, что стоимость акции будет 45 единиц ровно.
Точечное значение не дает. Он говорит множественное значение в виде интервалов.
Это уже будет какой-то фокальный элемент.
Либо он говорит, например, от 40 до 50 степень уверенности большая, где-то примерно 0,7.
Ну, может быть там от, допустим, от 48 до 55 со степенью уверенности 0,3.
Например, вот такого типа.
Спасибо. Я понял. Спасибо.
Сообщение посвящено управляемости треугольными системами со сменами фазового пространства.
В двух фазовых пространствах X и Y разной размерности.
Пространства могут иметь как одну размерность, так и разную.
Возможен переход как из пространства большей размерности в пространство меньшей размерности, так и наоборот.
В фазовых пространствах X и Y движения описываются следующими системами.
В пространстве X движения описываются с системой I на отрезке времени 0T.
В пространстве Y движения описываются с системой II на отрезке времени TaoT.
Интервалы времени Tao и Tт заданы.
Системы 1 и 2 были рассмотрены коробовым впервые.
и названы треугольными. В дальнейшем они тоже и рассматривались и также изучались, например,
задачах стабилизации каскадов систем. К подобного вида системам сводится ряд физических управляемых
процессов. Допустимыми управлениями являются непрерывные функции U и V со значениями в R1.
Также нам задано в пространстве X начальное множество гиперплоскость перехода, не пересекающий
с начальным множеством 0. Задано отображение Q, с помощью которого осуществляется переход
из одного пространства в другое. И в пространстве Y задано конечное множество m1,
не пересекающиеся с множеством Q от гамма. Движение объекта осуществляется по следующей
схеме. Пусть на отрезке времени 0 Tau объект движется из начального множества m0 в пространство
X по решениям системы X1. В момент времени Tau объект попадает на гамма и под действием отображения Q
происходит переход в пространство Y. Мы получаем точку Y от Tau, которая является начальной для
движения объектов в пространстве Y. Дальнейшее движение осуществляется на отрезке времени Tau
и большой по решениям системы 2 на множество m1. Причем Y от Tau не принадлежит m1, иначе задача
решена. Задача заключается в том, чтобы найти условия, при которых объект описываемый системой 1 и 2
будет управляемым на отрезке 0 Tau из начального множества m0 в пространство X в конечное множество
m1 в пространство Y. Объект описываемый системой 1 и 2 называется управляемым из m0 в m1, а если
существуют такие допустимые управления U и V, то соответствующим решениям систем
удовлетворяют ограниченным условиям. Следующая теорема дает достаточно условия управляемости данной
системы, и в ходе доказательства удается получить непосредственно траекторию, которая связывает
начальную точку в m0 и точку в m1. Если мы в пространстве X рассматриваем систему,
вводим замены переменных следующим образом, и через Zn плюс 1 обозначаем новое управление.
После такой замены система 1 приводится к линейной системе, которая к силу рангового
критерия Калмана является полностью управляемой за время Tau, а по определению полной управляемости
у нас существует управление, которое переводит объект изначального множества m0 в произвольную
точку гамма. Тогда мы новое управление можем выбрать в виде функции от времени T, таким образом,
чтобы за время Tau попасть из точки z0 в точку zeta Tau. Например, его можно выбрать вот в таком виде.
Далее, подставив в левую часть соотношения 1 и 5 и вместо переменных полученной функции и управления,
мы последовательно находим функции x1, xn и получаем траекторию, которая удовлетворяет
ограниченным условиям. Далее мы переходим в пространство y под действием отображения q и в y
рассматриваем аналогичное движение. Проводим аналогичные процедуры и получаем второй кусок
траектории, который соединяет точки уже в пространстве y и таким образом мы получаем
управляемость объекта из m0 в m1 и траекторию, которая соединяет начальное и коничное множество.
Я. Ряд ссылок на литературу и спасибо за внимание.
Спасибо. Борис Григорьевич, я бы хотела поздравить вас и желаю вам хорошего здоровья и здоровья.
Это немного жаль, что я говорю, я говорю никто, вместо вас, но я надеюсь, что вы слышите меня и
и Борис Миркин был моим учителем, моим учителем и учителями мы всегда любили
его учителя, наслаждались их, они были очень интересными, мы appreciate его
учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, у
учителя, учителя, учителя.
У нас есть группа индивидуалов, и они должны сделать коллективное решение, чтобы выбрать кандидата из группы возможных кандидатов.
И в этом фреймворке есть проблема, что кандидаты могут предпочитать свои предпочтения, чтобы получать более предпочитательный результат.
Это называется «манипуляционным проблемом в социальном выборе».
Так что, в некотором смысле, это естественно и логично, потому что, если кандидаты могут предпочитать результат выбора, то они имеют возможность, они имеют возможность предпочитать результат выбора,
и, в этом смысле, возможность манипуляции является последователем этого.
Так что, есть известный теорет «Гиберт-Сеттет-Вейт», который говорит, что вся природа, вся fair voting rule,
которая считает минимум три альтернатива как возможный результат, они можно манипулировать, и нандиктатуральные вибрации, они можно манипулировать.
Но, если все нандиктатуральные вибрации в социальном выборе можно манипулировать, то это интересно узнать, до какого уровня они можно манипулировать, они способны к манипуляции.
И очень широкая использовательная процедура для решения этого вопроса, это калкуляция probabilностей манипуляции.
Так что, калкуляция пропорции профилей, возможности ситуаций, где манипуляция возможна.
Так что, например, для «М» альтернатив и «Н» вибраций, есть «М» факториал, «Н» возможных профилей, возможных ситуаций,
и мы калкулируем пропорцию манипуляции.
Мы также считаем, что проблема манипуляции под инкомплитной информацией.
Так что мы добавляем эту ассумпцию, чтобы сделать модуль более реалистичным в некотором смысле.
Так что, вибрацы не знают все преференции других, они просто знают информацию о профиле преференции.
Если вибратор имеет инсцентив манипуляции в профиле «П», но это не означает, что манипуляция он успешна в этом профиле,
потому что он или она не знает преференции, они просто знают информацию.
И он или она, альтернатив, имеет инсцентив манипуляции, если в сете всех возможных ситуаций у него есть возможность улучшить его преференцию, в том числе и в некотором из них.
Так что, в простых словах, мы увидим это в деталях дальше.
Так что, я сейчас объясню фреймворк.
Позвольте, что N будет сетом манипуляций, и количество манипуляций означает маленький N.
X является сетом альтернатив.
Так что, кардинальность этого сета – M.
Pi – это нотация для преференции вибратора I, который является линией.
И P, вибратор P – это профиль преференции.
Мы рассматриваем правила агрегации в том числе.
Корреспонденция вибратора I – это правила, которая берет профиль преференции и, в результате, дает сету альтернатив.
Так что, если у нас есть какие-то сеты, альтернативы вибратора I, которые получаются по поводу этого процедуры,
мы используем правила агрегации вибратора I, чтобы выбрать уникальный победитель.
Эта правила считается алфабетикой, так что есть определенные правила.
И мы выбираем из сета а, один альтернатив, который не доминируется по этому правилу, который указан по правилам P.T.
И вибратор V – это правила, которая берет профиль преференции и, в результате, дает сету альтернативы.
И мы рассматриваем правила агрегации вибратора V, которые получаются по поводу этого процедуры.
Первое, профиль – это полная информация, когда мы знаем все о профиле преференции.
Так что, функция полной информации P – это функция для публичной информации.
Что мы знаем о профиле преференции P?
Ранк PIF – полная информация функция.
Это функция, которая вернует рейтинг альтернативы по этому правилу.
Правила также известна.
Вибратор PIF вернует…
Извините, что здесь должен быть C of P.
Вернует сету альтернатив, которые вернуют.
И вибратор Unique Winner PIF вернует Unique Winner после тайбреки.
Так что, есть четыре типа функций полной информации.
И что это означает для вибратора, чтобы иметь альтернативы к манипуляции?
У него есть информация-сет.
Так что, это сета всех возможных ситуаций или профилей преференции,
которые консистентны с его информацией.
С информацией, что он имеет из общественных средств.
Так что, это его мир, в некотором смысле.
Дефинирование манипуляции.
Если это коалиционная манипуляция…
Нет, это индивидуальная манипуляция.
Когда индивидуальный манипулирует.
Если в его информации-сете есть такой профиль преференции,
так что, поменяв свои преференции к P tilde,
он может получать что-то лучше,
и он не получит что-то хуже, как результат.
Так что, есть возможность улучшить результат вибраторного процедуры.
И нет шанса получать что-то хуже.
Проблемность индивидуальной манипуляции
демонстрирует индекс I
с небольшим индексом,
и в диалоге с профилем преференции,
есть хоть один votа,
который может манипулировать в этом роли.
Что значит манипуляция в коалиционной манипуляции?
Когда мы считаем манипуляцию в коалиционной манипуляции.
Each voter has a set of other voters, who have the same preferences, so his coalition,
co-minded people.
And if all his members in this coalition change their preferences the same way, and they can
achieve a better voting result, then they all have an incentive to manipulate.
And as in the previous definition, they don't have a chance to get something worse from their
manipulation.
So that's a way a voter can think about other voters' actions in the framework of incomplete
information.
So we consider several social choice correspondences, social choice rules.
Among them there is the most important class of scoring rules, which are defined by a scoring
vector.
And Sj in this vector denotes the score assigned to any alternative for its j-th position in
individual preferences.
So S1 denotes how many scores it gets for the top position, for the first position in preferences.
Sm denotes how many scores it gets from the bottom position.
And we sum these scores over all voters to get the total score of each alternative.
So the most popular rule is plurality, for example.
We assign exactly one score to each alternative for the top position.
And we assign zero, we give zero scores for any other positions.
So we count just the number of top positions for each alternative.
In Vitor rule, we minimize the number of bottom positions for alternatives.
And in this case, we need to give one score for each position, which is not bottom position,
to any alternative.
So we just give zero for the bottom and ones for every other position.
And Vitor rule is the following.
We give M-1 alternative score for the first position, and then we give M-2, M-3, etc.,
until zero for the bottom position.
So why I explain in such details these rules?
Because the main results of this research are about scoring rules.
For example, this one is the asymptotic behavior of manipulability index for individual manipulation,
so the probability of individual manipulation under the information, public information
about the unique winner for plurality rule, the most popular one.
When we use alphabetic tie-breaking, then when the number of voters approaches infinity,
goes to infinity, then this index, this probability tends to one.
So it means that in almost in every possible situation, you will have an individual, at
least one individual, who has an incentive to misrepresent his preferences.
So it couldn't be called protected from manipulation this rule, for example, under this very kind
of information.
However, when you change the type of information to winner, so it means that we know a set
of winners, then this value depends on the number of alternatives, this value, which this
index approaches to when the number of voters goes to infinity.
It is 1 minus 1 divided by m.
So we change the type of information and we immediately change the number of possible situations,
which are susceptible to manipulation.
This is coalitional manipulation.
When we switch from individuals to coalitions, then this index again is equal to 1 in asymptotic.
With alphabetic tie-breaking, almost in every situation, again, we'll have at least one
voter who has an incentive to manipulate, to vote strategically, insincerely.
And he thinks about his coalition members.
So when he feels some support from commended people.
That's the asymptotic behavior of border rule.
It's again 1 for coalitions.
And we prove that for any number of voters and any number of alternatives, the probability
of coalitional manipulation equals the probability of individual manipulation when we have information
about a single, a unique winner of the election for all scoring rules, for every scoring rule.
And we conducted some computational experiments just to view, to observe how these indices
behave and you may clearly observe it.
And compare the left-hand side graph illustrates individual manipulations, the probability
of individual manipulation, popularity rule and different kinds of public information.
And on the right-hand side, you can see coalitional manipulability index.
And you see that for individual manipulation, we see only one graph approaching one.
It's the graph, it's a line corresponding to the information which is the least perfect.
So it's information about the unique winner.
And this graph illustrates the first theorem in our slides.
And for coalitional manipulation, we see this tendency, I think, maybe even for all of these graphs,
this one approaching tendency.
And what else we could see?
The less information we have, the greater is the probability of manipulation.
So in more situations, at least one voter will have an incentive to manipulate it.
And it's the causes that information is not perfect, but it's useful that we have this here.
So just the same situation for border rule, I will not consider it.
And Vita rule is, we considered it, defined it.
And in some sense, it is an exceptional rule, because for when we restrict information,
when we give less information to voters, and when we switch to coalitional manipulation,
this index for this very rule is getting smaller, is getting less.
And for most kinds of information, it is almost zero or equals to zero in most cases.
So Vita rule is, in some sense, it is protected from manipulations of individuals and coalitions,
and from manipulations under incomplete information in such a way that in most situations,
the manipulation is impossible in this rule.
So these are the main points of my research.
Thank you very much for your attention.
I would be happy to answer your questions.
In fact, the sample space was the set of all preference profiles here.
And I just generated, created the set of all of them.
So that's why I conducted the experiment just for the number of voters up to 15.
And that was my limit for this.
Another question is that when you are adding the whole source to the final voting process,
as you mentioned, but previously you told that one voter may be averse to the other voter
option, and you can think about it.
So when you bring that in this case, then the voter might be influenced by the source
What is the difference between a voter who is independent and a voter who is not?
What is the difference between a voter who is independent and a voter who is not?
He just thinks that voters with the same preferences as he has, they are identical
to himself.
And in some sense, their incentives are identical too.
So all these voters of the same type have the same incentives, and they want the same candidate
to win.
So that's why they may misrepresent their preferences in the same way.
And this is what our manipulating voter takes into account.
Same thing that what if all my coalition members will also change preferences in this way,
and then we'll collectively achieve something better in this sense.
Yes, yes, yes, yes, of course.
Thank you.
Any other question?
Please.
Could you come here, I invite you personally.
The microphone.
You are the next speaker.
By the way.
So for online participants to hear the question.
Yes, please.
I want to ask about the population size.
Looking at these scales.
Your population size is limited.
Right, right.
And when you look at the scales, they are pretty converging.
Yes.
How representative is this finding?
Let's say, increase the value to 100, or 1,000.
So these experiments are conducted for the case with three alternatives, you see, and the
number of voters from 3 to 15 everywhere.
And for this case, we observe some tendency.
So it's just for illustration results, which we obtained for general M and N.
So you see, these results are for any number of alternatives.
When we have infinitely, we have a number of voters tending to infinity,
then this holds.
But I couldn't say something for sure for other kinds of public information, you see.
I haven't proved, for example, for rank function or score function.
So I couldn't say anything.
I couldn't say anything.
But the graphs show that it may also tend to 1 or 2 something.
So have I answered your question?
Yes.
Thank you.
Any more questions?
Okay.
Thank you very much.
Thank you.
The next speaker is the guide to Turkish.
Good afternoon, colleagues.
I shall apologize for my voice.
I think I could record.
My name is Tendai.
And I collaborate with Professor Boris Karangorin.
And I want to present pseudobullying polynomials for dimensionality reduction and image processing.
It's a celebration of Professor McKinsey.
So I shall start.
Now, the purpose of this talk is to showcase the usage of pseudobullying polynomials
for those shortlisted tasks.
It is a new formulation or a new technical approach to actually solving these tasks.
So the main one is invariant dimensionality reduction, which we then use for purposes of cluster analysis,
outlier detection, and feature selection.
Then the other task is dedicated to detecting edges and blobs in image data,
which we can use as well for image segmentation, as well as optical character recognition.
So I think I'm not going to explain how you formulate pseudobullying polynomials,
because I think you already realized yesterday from Professor Boris Karangorin.
I'll just go to the properties that we desire to use for these purposes.
So when we reduce a sample or an input matrix in pseudobullying formulation,
there are basically three properties that arise, which I think you realized yesterday.
There was P equivalent, there was P truncation, as well as compacting the initial data.
So now the compacting property is the one property that we want to use for invariant or lossless data compression.
And then P equivalent, we desire to use that for similarity comparison,
in the sense that a pseudobullying polynomial would be a low-dimensional embedding of the initial data.
And also there is gradient shift detection.
Like in an image, we understand that when there is a change of color in the image matrix, we want to detect that.
And by formulating the pseudobullying polynomials, we select some pitches of a given size,
and then we check the power or the order or the degree of the resulting pseudobullying polynomial.
If it is higher, it shows that the pitch is overlapping an edge.
If it is lower or equal to zero, that means that it's basically the same information, same color.
I will show in the following slides.
Why do we desire to use pseudobullying formulation for dimensionality reduction,
which we then proceed to use for clustering or unsupervised classification?
We noticed that the other alternative tools that are available, for example,
the t-distribute stochastic neighborhood embedding, t-SNE.
Yes, they work fine for a number of selected cases.
However, they have this nonconformity, this cost function involved.
So the results might differ by differing the input values that we initialize during the formulation of the dimensionality reduction task.
And this results in variance.
There's also the other limitation of dependence on the whole population of samples.
For example, using principal component analysis, we have to calculate some densities across each and every sample,
and then make a distance function to compare, and then determine that, okay, this is the lower dimensionality of this value.
And penalize those which have the smallest distance.
However, with pseudobullying polynomials then, we operate every sample independently, one at a time.
It does not involve any other information of any other sample in the population.
And there is no variance, because the only input data in the formulation is the data that is described in that sample.
There is nothing, no epsilon or whatsoever.
So now, when we reduce, let's say, a data structure, which is, let's say, four dimensions, five dimensions,
our desire is to reduce it to, let's say, three or two, because we can easily plot these dimensions on paper or on our computer screens.
And then, once we have this lower dimension, we can actually find some lines that separate samples just by plotting,
and then find the best separating line or the best separating plane in a Cartesian space.
I think usually, let's say, for example, this very popular data set, Iris flower data set,
is often used during the introduction to machine learning or data science, et cetera.
And we all know that it is four-dimensional data.
Why do we say four-dimensional data?
Because every sample is described by the shape or length and its width, as well as the petal length and its petal width.
Now, if we are to understand if there is any linear relationship between these particular values to the label that this flower depends on,
physical or citrus or virginal, we realize that it is difficult.
But now we decided that why don't we create an embedding that allows us to find an incidence of these particular dimensions,
whereas the physical feature, like the sample and the petal, they represent it as rows with incidence with their physical quantities of length and width.
And then looking at this, we realized that we already have a typical input to a formulation of suitable polynomials.
And I would like to outline in this scenario that, of course, our method is not universal,
because we require, we desire that our information is in matrix form.
And there is also, and the matrix form makes sense, like the sense that the incidence values, they are related.
Right. In this figure, I would like to highlight to you that each sample is reduced.
Let me go back to the previous slide. Each sample is reduced, if you can see.
Here, oops, it's not writing.
Right. This sample ID 1, when we process it through a pseudobooling polynomial, it reduces to this value, 6.0, 2.4Y2.
And all the other values, they also reduce into a characteristic like this.
And then this aggregation, when we take it and express it as Cartesian coordinates,
we can actually find some lines which separate these samples.
And we denote that there is a single outlier, which we looked at it and realized that it is a particular outlier.
And then there is also the other values, I think, here.
They are very close to each other.
We had to find some line that separated this.
But looking at this, we realized that just by finding these separator lines,
we can actually achieve a clustering after reducing this data into lower dimensions.
And then we would also like to show in a more practical scenario
the Wisconsin breast cancer diagnosis dataset.
In this dataset, we have 30 features that describe a certain sample.
And that is a very huge dimensionality.
So we find how best we can represent this as a matrix that can input to the pseudobooling polynomial.
In this scenario, I would also like to show that this is an example where we show the feature selection
or feature dropping technique that results from this formulation.
Now, this typical sample, for example, that you see here, it is reduced to this polynomial.
And this is the characteristic polynomial for each and every sample in the dataset of 159 samples.
And this automatically represents an XYZ vector, which we plot in the Cartesian space.
And looking at this, I think this aggregation, we managed to drop, I think, two or three features
so that we would find a line that best separates these samples.
And it's an accuracy of close to 95.4% linear clustering.
If we had taken this, we've also experimented by taking these reduced samples through an approximation technique
like support vector machine or k-means.
We actually can get even higher scores.
But another goal of our research is to remove these approximations
so that we can have invariant processing of our data.
Now we go to the image processing part.
Here we are particularly interested in our gradient shift that results by formulating pseudoboom polynomials.
The property that we want to exploit here is the degree property of the resulting polynomial.
And it allows us to detect whether a certain image that we have processed in the data is over an edge or it is over a blob region in the image data.
It is also helpful to us.
We want to also extend p-equivalents so that we can go into object detection actually.
It is an ongoing research.
Now the algorithm is that we take the image metrics and then we extract some windows, sliding windows, or rather a page of some literal size.
Let's say 3x3 is shown here, or we take 8x8.
It's just conditional. It's conditional to how much sensitive we want our edge detection to be.
Now let's say this region, the first region that I colored here, it has only five values.
These are constant values.
And since the pseudoboom formulation that we use here is plain-autopaste, all the other values will aggregate to zero because we are subtracting down the row.
And then summing the first row, we get 15.
And this means we have a zero degree.
There is no variable here.
But looking at the other metrics here, it is different values that we process.
And it results in a polynomial with the degree of 2.
This is the maximum degree.
Because it is happening due to the fact that the other rows are overlapping the data that is differing in color on the image metrics.
So we already indicate them as overlaying an edge.
Now, so practical examples that we did.
For example, here I show a comparison of this edge detection processing comparing with the Kearney method here.
You would see that the Kearney method allows us to just find the outward edges of this paper fruit in the input image here.
But using pseudoboom polynomials here, we can actually see the depth.
Because if you look at this 3D representation of this degrees, it shows that this region is power 2 or power 3 or power 0.
And you can have a projection actually in 3D while at the same time achieving the edges that you desire.
We also experimented in image segmentation task with the Dubai Satellite data set.
And I would like to highlight the preprocessing that we are doing here, a Gaussian filter and a pixel length threshold.
So that our input values are limited at least to a range of 0 to 10 or instead of 0 to 255.
And this is the result that we have.
Of course, we still need to go to the part where we have to detect that this region, it is a water body and this is a road.
We are still working on that.
But at the edge part of detecting it in segmentation, they are impressive results, I would say.
So in summary, I would like to say that our proposed methods, they are explainable and combinatorial.
I think in the medical sense, for example, in the Wisconsin data set for breast cancer,
somebody would desire that they have a diagnosis which was approximated by this method because it is explainable.
Instead of, let's say, a k-means vector machine algorithm.
And then also we have the invariance initialization of parameters and independence of sample population and dimensionality reduction.
And also very much controllable or flexible inputs to image segmentation or edge detection.
In the future, we propose to exploit the p-equivalence property for actual object detection.
We hope to use probably the resulting pseudobulding polynomials as lower dimensionality embeddings for the neural network, for example.
And also exploit this agent blob detection to optical character recognition and interpolation of 3D data from 2D image data.
If you desire to understand much about the formulation of pseudobulding polynomials,
I recommend this book, Data Aggregation for P-Medium Problems, by Obatoi and Professor Boris Konenguari.
There is also a series of information in industrial engineering.
It is a very good book to understand the whole process of pseudobulding polynomial formulation.
After this, I thank you for your attention. I can listen to your questions.
Thank you very much.
I would like to say thank you for your contributions to the episode book of the conference.
So many changes to your spaces and to really independently.
I really appreciate your contributions to this very, very frequently changed scale.
I apologize and thank you very much.
Maybe you have some questions. We have plenty of time.
You're welcome.
Yes.
The thing is, can you help me? I need to open the presentation of Professor Konenguari.
If you noticed from yesterday, the formulation of pseudobulding polynomial, we are subtracting the data.
We are trying to minimize the cost of initial matrix.
We are penalizing the least expensive feature or the previous one.
Can you open the presentation of Professor Konenguari?
That penalizing feature, when we apply it into image processing, we are now seeing that the previous image or the previous role in this page was less expensive or less expressive.
For example, if it is a color 10, it is close to black, but if it is 250, then it is close to white.
The 250 is more expressive, and it shows that there was a gradient shift from this value to that value.
Whenever there are values which are transitioning from a smaller to a higher value or from a higher value to a smaller value,
there is definitely going to be a variable attached to that monomial here.
If you look in this processing, here we have created our delta C matrix, and then we are utilizing the permutation matrix, and we are utilizing it to represent our variables.
When there is a difference between the previous value and the previous value, we are definitely going to have another y1 or y2 or y3.
That is indicative of a shift in values. That is why we decided that it should represent an edge.
This is the combinatorial combination.
This is the combinatorial combination, just after the numerical example.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
This is the combinatorial combination.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
We want to specify that our approach is indicative.
It's not a replacement of the neural network.
The improvement is the indicative nature of this approach.
We want to specify that our approach is indicative of this approach.
We want to specify that our approach is indicative of this approach.
We want to specify that our approach is indicative of this approach.
We want to specify that our approach is indicative of this approach.
We want to specify that our approach is indicative of this approach.
We want to specify that our approach is indicative of this approach.
We want to specify that our approach is indicative of this approach.
We want to specify that our approach is indicative of this approach.
We want to specify that our approach is indicative of this approach.
We want to specify that our approach is indicative of this approach.
Yes, I don't know whether you Id Hello?
We don't know what that is.
Сборная линия просто...
Да, мы просто найдем, какая у нас лучшая сборная линия.
И вы поднимаете эти два линии объективным функциям?
Да, это как в СВС.
Как вы видите, в этой объективной линии, если вы посмотрите,
в начале у меня было 10 разных колонн, но в этой объективной линии
я выбрал 7 колонн вместо всех остальных,
потому что в остальных колонн мы просто добавляем звуку.
Так что мы хотели показать, что наш процессор позволяет нам анализировать
эти multidimensional data и выделять эти функции, которые влияют на наш получение.
И тогда мы можем использовать эти колонны и, может быть,
тренироваться в нейронетворе и получать, вероятно, лучшую аккуратность.
У меня нет никаких предложений о вашем участии.
У вас есть комментарии о вашем участии?
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Да, у нас есть комментарии о вашем участии.
Так что, надеюсь, это было достаточно понятно.
Спасибо.
Корректор В. Кулакова
Но, конечно, в текстах, в артикуле, есть много, много...
Не много, но есть несколько линей,
несколько ссылок к другим, конечно, к другим опубликованиям,
к этому полку.
Что я могу сказать о этом полку?
О том, что это, на самом деле, эта презентация.
Просто один момент.
Это состоит из двух частей.
Двое партий обвиняют только в инфекционном проблеме.
Обвиняют только в декомпозиции.
И эта идея, очень старая идея для меня,
около 20 лет,
как я suggested firstly.
Я могу сказать, что я подумал об этом.
И это может быть...
Это имеет несколько веществ.
Например, в политических телах,
в образовом процессе,
и в...
в рынке.
Просто эта презентация связана
только с опубликованием в рынке.
Но, во-первых, я бы хотел показать
идею декомпозиции,
которая достаточно простая, но, конечно, достаточно сильная.
Я хочу сказать о себе.
Что означает декомпозиция?
Это понятно, что...
Если у вас есть граф,
я бы хотел...
чтобы создать...
чтобы найти какой-то сет...
сет его вертикал.
Так, что в...
в relatively few connections between these parts,
and relatively...
relatively many connections inside.
It's clear, it's not a formal definition, of course,
but it's clear what's the problem.
So...
So, however...
Just a moment, I can see oil.
It's very easy for me.
You will see the same.
One moment.
So, it's clear.
So, what is the part of this present...
of this part?
Notion definition, algorithm itself,
and numerical characteristics.
Perhaps...
Also, perhaps very...
sometimes useful.
What's partition?
First of all, from the advice,
I can say, advice of Mirkin,
give exact...
No, not exact, but give definition
of all the main notions.
So, partition is clear what's partition.
Graph decomposition is family of subgraphs,
and so on.
It's also clear what it is.
Graph dichotomy
is graph decomposition into two subgraphs.
And graph depth...
What?
Ah.
Another slide.
Ah, here. I understood.
Ah, it's possible without it.
Well, I see. Much easier.
Well.
Well, as next one,
graph decomposition, no.
Partition.
And especially graph depth,
it's a new characteristic of graph entanglement.
The plastic graph.
Calculate is a further described
algorithm of family of dichotomies contraction.
So, what about it?
Oh, like many other algorithms,
it consists of two parts.
Intellization stage and regular stage,
which is repeated several times.
It's also parameter.
First of all, what's the utilization?
Initial assignment necessary parameters.
Random value from 1 to 5, till 5.
It's...
5 is just one of parameter from the algorithm.
It can be 1 till 1, also possible.
1 till 10, it's not so important.
I define initial loading
in all the edge of the given graph.
What is name of loading?
Perhaps the most important,
very important notion in this report.
And it's really, it's a maximum,
it's really, it's a...
maximum...
Maximum of edge loading is defined
as initial maximum loading.
It will be described early,
and initial value D is 0,
and number execution of regular stage is T.
Well, the next one.
Initial assignments.
Ah, it already was.
At every execution of regular stage,
there are several input data,
some input data, graph itself never changes,
current value of loading in all the edges,
current value of maximum loading,
and maximum is getting taken over
over all the edges,
and current value of graph depth.
After every execution of the regular stage,
produced modified values of loading in all the edges,
modified value of graph depth,
modified value of depth,
current depth, lmax, and one dichotomy is constructed.
But every regular stage
produces one new dichotomy.
What's regular stage?
Perhaps this algorithm,
it will be illustrated by a picture,
but, however, now,
it's not so well-considered,
only main page,
main steps are described,
without I meet many details, of course.
Choose a random pair of different vertices
from the set of vertices.
v is clear,
not clear, it's not clear,
but it's the most important step here,
it's the second step.
Construct a minimum path,
connecting the two chosen vertices by Dijkstra algorithm.
But the length of an edge is its current loading,
the length of a path is equal to the length of its longest edge,
not the sum, but the maximum.
It's also very low notion,
and, of course, Dijkstra algorithm works in this situation also with maximum.
And what after we did deal?
After we selected, constructed, not we,
Dijkstra algorithm constructed one path,
it increased by one,
all the current loading in all the edges,
because this path just go along all these edges.
Loading is increased by one,
and increase by one the current value of graph depth.
It means any path increases value of depth of the graph by one.
And execute steps one to four,
till the maximum value of loading exceeds the current value Lmax.
Consider the initial graph with the loading just before we're finding this path.
The sets of edges whose loading is equal to Lmax
contain some cut.
This graph is sort of after that we can,
by deletion of all these edges,
we construct the number of components becomes more than one.
Perhaps not compulsory too, perhaps more.
And we construct two sub-graphs,
one with the maximum number of vertices,
that they union all the other component.
Of course, really it's described how to unite all the others and so on.
But really what's important,
it's all virtual operation, I can say,
because graph all the time is the same.
Now loading of edges of course changes,
the length also,
so-called depth of graph also changes,
but only increasing.
But graph all the time is the same.
I would like to show in picture,
because it's much easier to understand,
because it's the central path.
There are three cases of regular stages.
Case A, both lines are just edges with maximum load,
maximum loading.
In all the other edges loading is less.
If we do not form any cut,
we don't contain any cut,
so you can take arbitrary vertices A and B
and find the shortest path.
Of course, the shortest path,
because of its minimax definition.
It never goes along with edges with maximum loading,
because it tries to find a path
with minimal length.
A length of the path is the maximum value of length of any edges.
From this, it's possible to find.
Case B.
All these edges with maximum loading
do contain some cut of the graph,
but if vertices A and B from one side to this,
inside of one of components of connectivity,
connecting the component of the graph,
it's possible also to find this.
Let me show something here.
How to show something?
Do you have something to show?
Can you show something?
Here or there?
Can you show a place?
Where it is?
This one?
No, it's not so.
So.
There is no cursor here.
Ah, it's not working.
No, press and it will show.
Ah, well.
The most interesting case C was here.
The case where all the set of edges with maximum loading
do contain, like in case B,
do contain some cut of the graph,
but A and B are different components of this graph.
From this, any path, including shortest path,
must go through at least one,
but really a long one of these edges.
Because we increase every,
because we increase any loading by one,
we will increase maximum value, L maximum.
It also will increase by one.
And we go to the...
First of all, from this previous step,
we find some dichotomy.
Not find, it's clear, it's given after elimination,
even virtual with edges.
And so we can go to the next stage,
the next regular stage.
What will happen after all of them?
So, how to construct algorithm?
It's only dichotomy in two parts,
but how to construct dichotomy to many parts?
To many parts, it's very natural,
because the first is select some,
select one component, one sub-graph,
one sub-graph, and after apply the same.
But we select, with algorithm,
we select a sub-graph with maximum number of vertices.
And after that the same algorithm is used another time
for this sub-graph, the same algorithm, and so on.
Find dichotomy, and after that,
for all the pair of found sub-graphs,
select the one whose maximum number of vertices
in both sub-graphs is very minimal among all the pair.
And what I mean here?
Well, that's okay.
Replace selected sub-graph,
these two found, and the previous step,
and the previous step three,
and we find the composition into K plus one sub-graph.
So, we must, in the beginning,
we have some required number G of sub-graphs,
and we can construct some graph decomposition
into G sub-graphs.
What is necessary to say about all these constructions?
It's very simple construction, but it is effective.
Why? I can say.
Practically, I know, of course,
a lot of methods of qualification of graph decomposition,
and in any methods, the goal of any method
is to find some decomposition,
the best decomposition.
It's so possible, if a graph is simple,
a simple one, any, many, many, many others,
you'll find the same.
But if you have some more complicated situation,
I can say, perhaps, to sharp the best,
or not the best, the correct decomposition
simply does not exist, does not exist.
No, not at all.
You can construct, because I use random generator
always construction,
you can find many, many different decompositions.
Many different.
No, if I repeat this thousand times,
but typically 30 or 500 of vertices.
30, 40, 20, something like this.
Not 100, but a number of different dichotomies.
And after that, one dichotomy is selected.
Because you have a lot, you can select one.
In many cases, it's not necessary to select one.
It also exists.
But it's not in this work.
Some characteristic of the graph itself
that is defined following all these different decompositions.
It's called like entropy of this family of different decompositions.
Different dichotomies.
What is necessary to add?
All this construction needs only graph
because no metric information is used here.
But typically, many problems.
You have metric, you have distance between objects, between elements.
And so, of course, it's possible not only to construct graph.
Typically, I take four closest.
And so, consider the graph.
After that, find the composition of the graph.
But when you select one, the composition among many,
it's possible also use metric, distance between elements.
And from that, I use just in the stock market
because I have prices from some time.
And finally, I have distance between different objects.
Because it's time, it's prices during 15 days.
Also parameter, my parameter.
I will explain all parameter after that.
And so, it's possible to use not only graph characteristic itself.
Graph only, but also metric.
So, what I do, I find average distance between all elements in one sub-graph.
And in two selection, in two sub-graph of the composition, I select one.
I select pair one, the composition, one dichotomy,
where the maximum, where this number of vertices will be minimal among these two.
It will be minimum, maximum of two, maximum of two graph.
Maximum number of vertices in both graph, both part of dichotomy.
All thousand, perhaps of course less, but all thousand variant will be minimal.
It's, I can say, tend to situation excluding such that you have thousand,
you have 500 vertices, you have 495 and 5.
I try to exclude it if a normal uniform decomposition exists, it will be found by this algorithm.
But if also it's possible in this place use the second part.
The same algorithm, but not instead of number of element,
you can consider average distance between all the elements in this sub-graph.
It must be of course then less, then better.
Its distance must be maybe as close to one to other as possible.
The same, it's selected one of two, this has the worst case.
And afterwards all the pair, all the pair, it selects,
algorithm selects this one with maximum possible density.
Density is clear, it's something like distance, but when more, when better.
So, this is the end of the first part of my presentation.
Second part, concern.
Just a moment, I can do it.
So, the modified algorithm that I told just now of these things, add finally.
Second part of my presentation concern just market graphs for S&P 500.
It's a very popular object because 500 not a lot,
but of course it's 500 greatest, largest, greatest American companies.
And from that of course it's, I can say, behavior with market.
It's very typical for all the economic, not only the United States.
So, what's written? Some standard conditions.
So, I consider 15 days, L here 15.
Prices share, so consider for these days.
All the information is related to the last day, it's clear.
And also distance, it's clear.
Distance is defined by correlation coefficient, it's standard things.
This construction, I can say, very non-construction.
Only one thing, because sometimes not with some number closed,
but in many constructions of market graph, consider.
It's a level of correlation coefficient is given.
For instance, 0.6 and 0.7.
And as connected only with pair whose coefficient is more than this number.
But I prefer because sometimes it's not very, not uniform in a different part of this graph.
Distance scientifically be different.
I mean coefficient correlation.
From that I prefer take fixed number.
Why for? Like all the other parameters will be explained for all of them.
That's why graph is called the market graph.
It's very known notion for more than 20 years, perhaps even more.
I have, of course, a link to the first book about it.
General scheme of the daily trading algorithm.
What's so about?
Many people try to find, to predict big crisis.
I don't engage at all in this problem.
I think only about trading the next day.
Using information of the previous day.
Like not only me, a lot of publications concerning the same problem.
What to do the next day, which shares to buy, which shares to sell.
Of course, in this point of view it's standard things.
But how to do it?
Approach is very known, but how to do it is different things.
So the second point, it's a general scheme.
Building graph of share of the base of this analysis, which is advisable to trade the next day.
Or decide to skip trading the next day.
Sometimes also necessary to skip the next day if you feel, if you know, perhaps, bad results.
But pay attention, the item four, making decision about suspension of trading for a certain period, not for one day.
And not because it can be something bad.
Not because this decision depends on the result achieved during the previous period.
Result can be good, not only bad.
Good results and have bad results.
In both case we stop the trading up to end of period.
Period, connected period is one quarter.
About 62-63 working days.
So I considered 40, not 40, 21 years, 84 period, 84 quarters.
Between 1990 and 2010.
Big crisis just inside this period.
But it's not so important for me.
Big crisis is not so important.
I will explain what it means.
So, for the previous day.
Very simple idea here.
I consider, I consider market graph constructed for last day, for today, in the evening, and the previous day.
So in both graph I construct the composition into 15, into 12.
It's not so important in 12.
Also parameter.
In 12 some graphs I can say cluster and what is perhaps something new, not so new.
But I found the maximum intersection of the cluster.
Maximum number of elements.
So we have two clusters, the same set of course.
But with big intersection you have shares that have similar, because we are inside one cluster.
I can say similar behavior in last 15 days.
What does it mean?
The next choice is like, because after that the end here.
Fine subset.
So some other conditions.
So for M, if you say to yourself M, whose cost increased from yesterday and the note with M+, and here whose cost decreased from yesterday and the note M-.
So of course it's natural idea to suppose with shares the next day, the known day, next day.
Tomorrow you'll have the same behavior.
But of course it's not a fact.
Moreover, I think what to do is not so.
You will just know what's possible to do about it.
In many cases it's so, but not always.
I can say it's not always so.
Very simple recommendation of course for share from the group M-.
Of course the next day it's proposed to sell with shares at a price at the market opening, which is assumed to be close to the price at the closer time the day before.
And so buy at the market closer time the price, because it will be cheaper.
And the same M+, this time it's helpful to buy one share and sell it at the end of this day, in the morning to buy.
So because in this part price increases.
So it's a very natural idea.
But why it can work?
Because I used not only this fact from the last two days, but also from the previous 15 days.
From that it very often gives good results.
But not often.
But what after that?
What is really new thing I can say?
Stopping crew.
The considered elementary period is one quarter and S of t is a cumulative income after day t from the beginning of the considered quarter.
The first day is zero, but I use day zero, day one I use only to predict the next, not to predict to consider the next day and so on.
So what is the idea here?
I define two numbers.
Two terms hold.
One negative minus 25 and positive plus 50.
So I make a decision every day.
It's cumulative income.
It means from the beginning of the quarter up to this day.
It's good enough.
It's not good.
Also the trading is suspended till the end of the current quarter.
It's income more than 50.
When the trading is suspended, it's a good result.
So you can earn some money and so not to play more.
So otherwise the above exciting trading algorithm continues to work.
Of course this algorithm can be named, but it's really so caution algorithm.
I can say even truthfully.
That's all.
So I can tell the very known Russian expression in Russian, but explain this meaning.
Не зато отец сына бил, что тот играл, зато что отыгрался.
Main idea here you must be satisfied with not big, but positive result.
That's all.
It's also known idea.
By the way, this situation a bit similar, not a lot, but a bit similar to very known problem, secretary problem.
Because you also must finish, you don't know what will be after that.
But in this case you have probability, but here you know nothing.
However you can make reasonable decision.
Why reasonable?
After that I can present some table.
That's all.
Result of the stopping rule.
It's three period, three quarter.
Not up to the end, but it's clear what happened.
And the place where I stop.
Why not this place?
Something happened here.
Something happened here.
What we can see here?
Anyway it's possible to...
So what's clear from here?
Several, five several quarters between forty, between forty one, forty.
Forty, twenty years, twenty one years, eighty one.
Eighty one.
Well and we can what?
Here negative result we stop here.
Twenty nine minus.
Here also negative result and we stop just here.
Negative result and we stop here.
More than fifty.
The same is here.
Pay attention.
The same is here.
The same is here.
Pay attention here.
I know picture is spoiled, but I don't know why.
It's important.
From where the pay attention is just period before great crisis.
It's third quarter of 2008.
But I don't consider.
Here you can receive much more.
Here you can receive also.
No less.
Here you also can receive more.
Here and so on.
But I stop.
It's stopping cruel.
It's stopping cruel.
So what after that?
It's almost all.
I calculate with algorithm from twenty years, twenty one year.
You can hear annual income, sometimes negative.
Cumulative income.
You can see some increase anyway.
And it's possible to see better presentation here.
It's regression line.
It's results here.
Income here time.
You can see.
More I can say with the contract.
I presented.
I calculate many such.
Perhaps three or four such picture.
Some of them up to two thousand nineteen.
The character was the same.
Sometimes I change some not important details.
But anyway, it's all the same.
It's positive result.
What can be said about it?
Result itself not so good.
Very little sum.
But little sum.
For instance, two thousand dollars and so on for many years.
But first of all, I buy one.
I deal with one share.
Only one share.
If you do the same with hundred share.
We'll receive hundred times.
Because in thousand share you'll receive thousand times more.
When written here.
So it's not so bad result.
But of course.
What I would like only to.
To start to end.
Parameters.
We suggest algorithm is algorithm of data analysis.
And it is not an algorithm of stock market imitation.
No assumption about stock market behavior itself.
As well as about behavior of the actor.
No probabilistic.
No any assumption at all.
I consider data as a fixed number.
When I know.
And I don't suppose anything about them.
Anything.
It's only.
But when I produce.
I use probability like.
Because I use random.
Random standard data generation.
But something else.
Because in this case it's possible to use limit theorem and so on.
Not as possible to use.
To initial data.
That.
Absolutely unknown.
I think all of us understand the difference between.
What is unknown.
Uncertainty and.
Uncertainty and probability.
Very different things.
So.
I support only uncertainty.
Not probability at all.
And after that.
I use several.
Things how to improve this algorithm.
Of course there are many way to improve it.
I don't intend to.
Of course I would like to underline.
That's not.
The end of the work.
It's a beginning of the work.
Serious analysis of fund.
Because not only this.
Stock market.
Also the others.
But.
I can say it's necessary to understand.
Pay attention.
That.
Big crisis.
Don't.
I can say.
Don't trouble me.
Don't trouble me at all.
You receive plus even before this crisis.
And even after that.
Of course.
It's because.
Other idea.
Of course.
And the last.
The last picture.
Don't worry.
Is the last.
About great crash.
Some people can consider.
That is absolutely.
Monte Carlo.
Nothing to do.
Great crisis.
To 1929.
It's a citation of.
There is this edge.
My friends.
To sell.
Security.
Katolik.
Wisdom of 20.
Yes I didn't.
Pente.
So.
You must.
We need.
Ring.
The reason.
is.
A.
rush delivery was so.
High no.
We must.
低.
That.
Cisance no.
That's a point.
Vaccine Luis.
Massive and they can.
Но смысл прожечь он предовольен и точен. Я ничего не потерял. Мало того, сорвал, как бы, вероятно, выразились изрядный куш.
Я извиняюсь. Уже 15 минут.
Не, ну не 15. Да, то ж, наверное, часы. Не 15. 5 минут. 5. 5.
Ну держи 5.
5. 5.
Зачем?
Ветсул. Ветсул.
У вас есть вопросы?
Конечно.
У вас есть вопросы?
Конечно.
Индекс – это не результат.
Индекс – это параметр рынка.
Результат – это деньги, которые люди могут получать.
Нет, я не сравниваю с индексом.
Может быть. Много идей нужно попробовать.
Во-первых, я знаю несколько способов.
Кстати, я написал себе все программы.
И много технического работы здесь.
Понимаете? Здесь, на самом деле, 5 или 6 программ.
Но нет.
Есть много-много возможностей, чтобы улучшить результат.
Конечно, я видел предыдущие вещи.
Я могу сказать только одну вещь, но они все не стабильны, я могу сказать.
И они стабильны, действительно, в автоматическом смысле.
У вас есть метрика, чтобы измерить стабилизацию вашей стратегии?
Потому что я не могу делать это один раз.
Я действительно делал это пять раз, но, возможно, пятьдесят раз.
Потому что это скоро достаточно.
Это возможно сделать.
Но это не первое данное.
Это продукт.
Это результат процесса.
Результат – это действительно рандомное значение.
В автоматическом смысле.
Из этого вы можете использовать.
Конечно, некоторые дни могут быть негативными.
Но некоторые дни более позитивные.
И из этого вы получите хорошую сумму.
Позитивную сумму.
У меня есть вопрос.
Вы говорили об кассе или коде.
Как ваш алгоритм соответствует коде и коде алгоритма?
Конечно, я очень хорошо знаю.
Но, нет, нет, это не так.
Это не так.
Потому что я знаю, что с этой кассой, с этой кодой,
с этой кодой, я могу сказать, в любом случае.
Все параметры равны, максимально равны.
Все коды.
Мы имеем больше, но это содержит код.
Из этого я просто выключаю все это.
Не нужно это найти.
Мой алгоритм определяет все это код.
И то, что касса максимально равна коду.
И так я не нужно это найти, как и Форд Волкерсон.
Особенно найти этот код.
Это просто найдено самым алгоритмом.
Моим алгоритмом.
И после этого я просто выключаю.
Я могу сказать, выключаю виртуально.
За какое-то время.
Я не меняю кассу.
Я понял вашу вопросу.
Это не проблема.
Мы знаем эти коды.
Я делаю эти коды в один раз.
Это просто момент, когда они увеличиваются.
Максимальный код увеличивается в один раз.
Потому что это только калькуляция.
Ничего из-за кодов.
Я думаю, вы можете сказать, что ваш алгоритм кодов.
Нет.
Потому что я использую абсолютно другое.
Я использую идею, которую я нашел в виртуальности.
И дикстра.
Минимайсовый вариант дикстра.
Код найдет все, что необходимо.
Это, как я могу сказать, первая идея.
Много лет назад.
Но эта идея работает в политическом теле.
И в образовом процессе.
Много случаев.
Еще какие-то вопросы?
Спасибо большое.
Большое спасибо.
Наш следующий спонсор.
Тузана Наскиментова.
Тузана, слышишь меня?
Это Борис.
Слышишь меня, Тузана?
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Добрый вечер.
Пиши на презентацию, видеть твое лицо, а не презентацию.
О, извините, много спасибо, много спасибо.
Пожалуйста.
Это нормально сейчас?
Да.
Прошу прощения, я очень прощена, потому что, если вы позволите мне,
я буду жить и вернуться в сессию, потому что я не могу слышать себя.
Что я должна делать?
Я не могу слышать кого-то.
Мы можем слышать тебя.
А вы можете слушать?
Да, Варис.
Тизана, мы можем слышать тебя в сессии.
Просто продолжи.
Я вижу твое лицо, но это не ты.
Принеси и продолжи.
Окей, я не буду продолжать.
И я прощаюсь, прощаюсь за это.
Это не ты.
И они должны быть прощены, потому что...
Да, да, не волнуйтесь, не волнуйтесь.
Не волнуйтесь.
Окей, пока, пока.
Так, как я говорила,
мы пересмотрели, что каждое первое
оборудование сезона может быть
разделено в короткие периоды,
в которых оборудование в форме
более или менее постоянное.
Таким образом, мы предложили
три-стабилизованный оборудование.
Во-первых, мы сегментировали
оборудование с сейсовидной температурой,
дириженной от сателлита,
чтобы изменить оборудование в регионах оборудования.
Потом мы нашли оборудование в временах
стабилизации и, наконец,
мы нашли короткий оборудование
в этих временах.
Первый метод и модель для сегментирования
мы разработали несколько лет назад
с самым оборудованным оборудованием кластера.
Благодаря предпочтению СССР,
мы измерили температурные значения Aij
на каждом пикселе ij,
мы рассмотрели модель
по следованию модели оборудования кластера
в 1999-1996 году,
в таком смысле,
что каждый оборудованный температурный значение
может быть оборудованным,
как продукт оборудования кластерной интенсивности
и кластерной membership ij,
плюс резидуальный значение ij.
Чтобы оптимизировать этот модель,
мы рассмотрели критерию оборудования кластера
по следованию модели оборудования кластерной интенсивности
и кластерной membership ij.
И мы легко можем определить,
что интенсивности будут ничего другого
чем температуры оборудования кластера
по следованию пикселей.
Я не имею времени идти в детали
о дитературе,
мы оборудовали этот мета-модель,
но мы можем сказать,
что самодельная самодельная алгоритмка
встанет от популярности,
в росте оборудования кластера
по следованию оборудования кластера.
Кластерное критерии берут формат продукта
по повседневной molta разд瑰ли в несколько моментов.
Ferrari-баз discomfort
adhaptivity
outfit
Cluster
ell
Cluster
и
Так что в этих фиграх мы можем увидеть, что мы проявляем
то, как мы получаем результаты сегментации с алгоритмом СТСЕКС.
В случае Португалии, где у нас на левой стороне
образ с температурой СССР.
В середине этого образа, после предпочтения стажа,
мы проявляем зону оборудования моря
и на правой стороне бинарный метод,
полученный с алгоритмом СТСЕКС,
где оборудование зоны оборудовано зелёным.
И ещё один пример,
когда мы проявляем зону Атлантического океана Норвегии.
На втором этаже мы хотим найти временные рейтинги,
в течение СССР.
Так что, в действительности, оборудование не постепенно
развивается через время, но вместо этого
оно проявляет несколько раз сегменты,
в которых оборудование показывает подобные поведения.
Чтобы осуществить это, мы начали вытягивать 4 функции
из сегментов СТСЕКСа.
Тоталонная часть оборудования,
оборудование температуры на оборудовании,
максимум и минимум литературы оборудования.
И с этим мы хотим вытягивать последующие СССР.
Для этого мы адаптируем
итеративный аномалистический партнер-агритм,
пропущенный Миркин,
в первую очередь как интеллигентная
инициализация для популярного киминального алгоритма.
Итеративный аномалистический партнер-агритм
секвенционно вытягивает кластеры один за одним
и позволяет моделировать количество кластеров
в неисправной форме.
В нашем случае мы исследовали этот алгоритм
для неисправной сегментации СТСЕКС,
и так мы использовали EAP,
используя 4 функции,
вытягивающие из сегментов СТСЕКС,
и вытягивающие автоматически
в неисправной форме
моделировавшуюся стоп-кондицион,
количество времени.
В этой таблице мы проявили
проявление времени
на три независимых сезона Португалии.
И это очень интересно,
потому что количество времени
на каждом году,
между 3 и 5,
для обеих коллекций СТСЕКС
в разных регионах мира,
Португалии и Африки.
На последнем этапе
мы хотим найти кластер КОР-ШЕЛ,
чтобы представить временные рамки
как постоянный модель Пуэлла.
Для этого мы снова
собираем предпроцесс ССТ-грид A
как метрика АТ IJ
с температурными значениями IIJT.
Кластер КОР-ШЕЛ
У является секвенсором
Т-кластерных слайсов
R union St equal 1
до R union St equal T-капитал
с Т-капиталом,
previously derived from the
Iterative Anomalous Pattern algorithm
and with R a constant set,
the core, and S of T a variable set,
the shell at each moment T,
not overlapping R.
So a core-shell cluster slice
is represented by two non-overlapping sets,
R union S of T,
with binary values R IJ,
belonging to the core,
and S IJ of T belonging to the shell,
such that their product is equal to zero.
The model to represent an upwelling SST
at pixel IJ and moment T
is approximated by the sum
of the pixels belonging to the core
plus the pixels belonging to the shell
weighted by values
that correspond to the intensities
of the core and of the shells
and are to be found
plus a small residual value E IJ.
Again, the residual values
are minimized according to the least squares
clustering criterion,
defined by this equation 6,
and it's not difficult to derive
that the first order minimality conditions
of this function delta,
the clustering criterion at moment T,
lead to intensity values
for the core and the shells
that lambda and lambda plus mu,
that are nothing else
than the mean temperatures
of the pixels belonging to each part
of the core shell cluster.
Criterium delta can be rewritten
as the difference of a portion D
that is defined
as the total data scatter
and that is constant for our data,
and G that is the core shell cluster's
contribution to that
and is to be maximized.
And to maximize this portion G,
we proposed an iterative algorithm.
The input is a set,
a collection of T SST grids,
and the output is one core shell cluster
that is a sequence of T cluster slice
and the corresponding intensity values
lambda of T and lambda of T plus mu of T.
At the initialization of the algorithm,
we run the sequential self-tuning algorithm
over each SST grid AT
and let C1, C2 and CT
be the obtaining upwelling regions.
We calculate the initial core
as the intersection of those clusters
and the corresponding shells,
the set difference of the cluster
minus the core.
And then we define a set B
as the union of the core and the set of the shells
and another set F
defined by the grid points
forming a four-neighborhood
with the region defined by the core
and the collection of the shells.
At the iterative step of the algorithm,
for each pixel i, j belonging to set B,
we want to define, to decide
which scenario to take
or to make the point i, j
to belong to the core
or to make i, j to belong to any of the T shells
or to remove the point to any of them.
And we take the option
that makes the increase of criterion G.
And this process operates
until there is no improvement
in the criterion we are maximizing.
So in this figure
we illustrate the structure
of the core-shell clustering algorithm
for an example of a time range
for an example of a time range
forming by five consecutive
sea surface temperature maps
on the top after being pre-processed.
on the top after being pre-processed.
In the row in the middle
it's the result of having applied
the STSEC algorithm
and finding the upwelling regions
marked in green
and from there we defined
the initial core-shell clustering.
And at the end in the last row
we can see the core-shell clustering
result with the constant core
highlighted in yellow
and the dynamic part of the shells
in green.
So this is the entire architecture
of this three-stage clustering.
I'm not going into details on that.
And now moving to analysis
of the time series.
So we have taken two annual collections
of sea surface temperature reads
derived from the satellite images
corresponding to 16 years each 2004 to 2019
and covering the Portuguese coast
and the Atlantic Ocean of North Africa.
Each SCST grid
corresponds and is represented
to the average of eight days
of each.
So first we start accessing
the results of the core-shell clustering
segmentations. And for that
we are taking as ground truth
map.
These are the segmentations obtained
by the self-tuning set algorithm.
In fact, the segmentations obtained
by this algorithm constitute reliable
ground-tooth maps since they obtained
very good evaluation scores
when validated by a team of expert
oceanographers. Even so,
we are using the core-shell cluster
and ST-segmentation results.
And we obtain it for a relatively
diverse sample of images,
similarity scores higher or equal
0.98 out of one.
So to make the inter-annual time series
analysis, we consider
several features, the areas of the cores
and the areas of the shells forming the core-shell
clusters, the average temperature of each
of these structures that are nothing
else than the intensities deriving by the
core-shell clustering algorithm, and
the average temperature of the upwelling core
against the average temperature of the offshore
ocean waters.
To illustrate, we show in this graphic
the comparison of the average core
temperatures against the temperatures of the
offshore waters in the Portuguese coast
for the year 2015. And interestingly,
the maximum average temperature
of the core occurs at the middle
of the upwelling season, and the maximum
temperature of the difference between
the coastal upwelling and the offshore
waters is very close by. We obtain
confident results for all years, and
this shows that the upwelling events
tend to increase in the summer season,
where the coastal upwelling tend to have
its strongest activity.
Analyzing these results in the
inter-annual time series, we can see
that the core temperatures are
consistently lower than the offshore ones,
reflecting the permanent upwelling
regions close to the coast and captured
by the analyses of the core structures.
On the other hand, the annual cycle
of SES-T is observed both in the
cores and the offshores, but the differences
between the core and the offshore
temperatures are stronger again during
the summer months, that correspond in fact
to the peak of the upwelling and is
consistent with the upwelling regime.
Looking at the areas of the cores,
the shells, and the core-shell cluster
against the areas of the whole upwelling
regions obtained by the self-tuning
SEC, we again see that the core
are constant structures along each
of the four upwelling time ranges
previously determined, that in here are
in the number of four in the orange line,
and the shells in the green line
correspond to the evolving spatial
pattern of each of the four upwelling
regions obtained by the self-tuning
SEC.
This results in the evolving spatial
pattern strongly concordant with the
evolving areas of the whole upwelling
region of the original ST-SEC
Aldweed.
Now looking at the entire picture
of the inter-annual time series,
we can, along the 16 years, we can see
that the coastal areas occupied by the
coastal upwelling authors have been
increasing along those 16 years under
analysis, and the increased extent
of the surface signal of the upwelling
is in fact the manifestation of an
increase of the upwelling intensity
and or the increase of the
cyclonic wind stress curve along the
coast.
As a conclusion, a novel approach for
the automatic recognition of spatial
temporal analysis of coastal upwelling is
proposed. It consists of a three-stage
clustering based on Mirkin's data
recovering approach, the ST-SEC
clustering to segment the
upwelling grids at each
image, the iterative anomalous
pattern for an unsupervised
segmentation of the time series to find
time ranges, the core shell clustering
to determine the piecewise constant model
of the upwelling within those time
ranges. So these three clustering
models stand on the least squares
minimization of the corresponding
clustering criterion and allow to derive
key parameters of the models in an
automated way.
We have applied this framework to
real-world sea surface temperature data
covering two distinct regions of the
world, and the time series of the
upwelling features present consistent
regularities among several independent
upwelling seasons as validated by the
data recovery paradigm.
So, and I should say
thank you very much, Boris,
for having introduced me and my
colleagues here in Portugal to the
clustering within the data recovery
paradigm. Okay, thank you very much for
your attention.
Any questions?
We have a...
Just curious, how is this data
further used?
What are the results later on?
This is like very massive research.
Она, по-моему, не слышит.
Так что, Борис Григорьевич,
поблагодарите ее за замечательный
доклад,
потому что, ну, мы ничего не можем
сделать.
And I'm announcing the next speaker
is
Dr. Frollo.
Hello, everyone. My name is
Dmitry, and I would like to
present your three-step method for
audience extension in Internet
advertising using an industrial
technology. The work was prepared
by Dmitry Frollo, who is the
presenter, and Zina Taran.
The affiliations are, for me,
HSV University,
during the work
on this
direction.
First of all, I will
touch
programmatic digital advertising
overall. We will briefly
describe targeting strategies
and insufficient audience
problem. After that, move to
generalization and our method
to work with this issue
and describe our LUSP
method for audience extension.
After that, we will conclude the results.
First of all, I
would like to tell a bit about
programmatic digital advertising.
Now they see the common
tendency of moving advertising
from conventional formats such as
TV, radio and others to the
Internet, because this new
way allows
to have a lot of
advantages. First of all,
investigate potential audience
way better, create and control
the results,
because, for example, if you
consider TV advertising,
we have
a well-known issue
with controllability of this.
It's quite hard to
evaluate the results
of advertising, especially for small
audiences.
Programmatic is one of the most
popular modern approaches
based on buying user
contacts in a real-time auction
instead of buying some
places somewhere.
RDB, that is real-time bidding,
is a common
technique to implement this approach,
and it's based on
buying contacts with
users. Say, I have
a user visiting some site,
I can buy the opportunity to show
something to this user,
and typically to describe
users and segments
we have
user segments
that are user interests
determined from the
information that we know about
the user, such as visited websites,
open pages,
rich history and similar
things. And the same we have
for advertising campaigns,
they also can be described in terms of
segments.
Overall,
these things
can be referred as users
profiles. For example, here you can see one
such small profile
of a car's owner and businessman.
So,
there are also
common well-known issues with this
approach.
First of all,
this is insufficient
information about the user.
When it's difficult to
make decisions,
how should we show something to this user
or not?
The reason for that can be, for example,
we have only
restricted access to the user history.
For example, one page in
his history of
visits in the Internet, and of course it's very
hard to analyze user interests
and all that. The second thing is
extremely large volumes of data,
and this is especially
important for small
technological companies. Sometimes
instead of analyzing
the content of a web page,
companies analyze only
the URL of the page,
and of course it's very hard
to analyze each
individual page.
And due to that, of course,
we can have
issues with
quality of such kind of analysis.
Also,
the next thing is technical problems
with bidders.
It's very important to
respond quickly, because
the time when the user
is taking a look at the web page
is very limited, and
we should make
the bids, and we should make
decisions very quickly, as fast as possible.
Typically, the common limit
for client-server interaction
in these cases is
100 milliseconds. That means that
all the bidders behind
the hood for
auction systems should communicate and respond
in just 100 milliseconds.
Also, the important problem is bots
graphics. This is
a continuing fight of defense
and attack, and
there is a chance to pay for bots
instead of real users, and
companies
make many attempts
to develop
techniques how to defeat this problem.
The issue
that I would like to emphasize is
insufficient audience for some campaigns.
This is especially important for
small technological companies,
and I had some experience of
working in such a company,
and for some companies
the audience size
defined by initial segments
and initial user profiles is extremely
small. That means that if
they have a company that would like
to buy advertising,
in some cases
such companies are just
unavailable to cover these requirements,
to provide a sufficient amount
for users who
see the
advertisements and make some actions,
like
go to a website by
a click on advertising and
things like that.
Let me briefly
describe common techniques
targeting in
programmatic, typically
conventional approach.
I will
name it
CAS.
This is conventional selection
of a targeted audience,
and the rule is
for a given set of segments
provided by advertiser and user
profile. Just check
the profile has one or more
of advertisers' marketing segments.
So typically we
pre-specify some threshold,
some value, and
the user is
selected as a part of target audience
if at least one of these segments
has weights greater than
T, according to
this CAS
rule. And this is pretty
straightforward
technique. It requires, of course, that
we should pre-specify
user and derive
user segments for user
and obtain
belongings values for audience.
And the
issue here, of course, is small audience
and the
limited
opportunity to control the
size of the audience.
And the common way that can be used here is
just to lessen the
belongingness value, of course.
So we will definitely get more users
than initially, but of course
the quality of this new audience
can be significantly
lower than
quality of initial audience.
And the question here
is maybe we can invent more
efficient solution with these
segments. And
yes, we can. The idea
is to use industrial taxonomy
and I
will describe here
the most famous IAB
content taxonomy.
IAB is Internet Advertising Bureau.
This is a worldwide
organization that
specifies and supports
standards and protocols
in the area of internet advertising.
And they have
their own user interest
taxonomy that contains
more than 1000 different segments
arranged in the taxonomy tree.
And the idea
of our approach is to
generalize low-level user
segments to get
accurate, this is very important, high-level
user segments and use them for
targeting.
So the idea
I will describe here
the core thing is generalization
of user segments.
So in this context we
defined generalization as
appropriate lifting of topics
and here you can see a small
example, say we have the
initial set A1,
A2, A3, A4 and B1
and we can lift this
initial set of
list to higher
rank node A and in
this case B1 will be
regarded as offshoot.
And let us take a look
at this approach more closely.
We can
have different alternatives when we
consider generalization and
say we have
one more example, here you can see
the leaves that
colored as black
and the
option to
lift in this
segment of taxonomy 3 is
to lift the initial
set, these nodes,
to the root of the tree,
to the head subject A.
And in that case we will
also
color by our head subject
those leaves that
will not belong to the initial
set, but we still have them in the
new head subject.
This is the first option. And the second option is
just to lift the
initial set to the
root of the left
subtree and in this case
as you see we have one gap and one
offshoot. And how
to decide what option
will be better, our method is
lift to minimize
the penalty and
we assign the penalty for each
option as a weighted
sum of number of head subjects
plus lambda multiplied by
number of gaps plus
gamma multiplied by
number of offshoots.
And
this algorithm
was introduced by Boris
Krivovich-Mirkin
under his supervision
in 2018
and it was named
ParginFS. And
the algorithm performs
a parsimonious generalization
of a fuzzy leaf set
and the output
of this method will be the set of head
subjects and the penalty
function that we will have for
objective
function of this algorithm to minimize
is shown here.
So we have different values
of penalties for gap, for offshoot
and we have penalty equal
to one for each head subject.
So
we can
directly apply this algorithm to
get generalizations for
user segment profiles
and after that use them for targeting.
And you can see here
some interesting examples.
I took here
very small
user profiles and for the first
example where you see
initial segments for cloud computing,
web development, internet for beginners,
IT and internet support, social networking.
You can generalize all of these
and the second example is also quite
interesting. We see here
lens jewelry and watches,
lens businesswear, lens casualwear,
lens autowear. We can just generalize
all of these to lens fashion.
And similar for the
third example,
here we obtained two head subjects
and at the next
step of our algorithm we will use
this to define
corresponding set of
advertising campaigns appropriate for these users.
So the
three-step method will include the following.
So initially we still have to compute
membership values for
segments for user by some classifier.
This step
is always
present for each
approach in programmatic. We should define
user interests
to perform all next steps.
Second step is
performing generalization of those sets
and obtaining head segments.
This is the most important part of our method.
And the last step is to obtain
the list of appropriate
advertising campaigns for each user
that will correspond
not to initial
user segments,
but to high-ranked
segments that we obtained in step 2.
And this list
will be the set of appropriate campaigns.
And
we conducted
experiments
in the company
where I worked those times
in Automatica.
And we took three
real advertising
campaigns and
we compared
first of all conventional programmatic targeting,
the second approach
just decreasing
thresholds and the
new evented approach that is based
on generalize
lifting of these user
segments.
And the metrics to compare
your first was number of advertising
compressions. So this is the
core metric to calculate
the audience size, of course,
just to define
how we can show these
advertising campaigns.
And the second is
the quality of this audience.
Quality can be measured by a number of ways,
but here we will use just
so-called CTR, click through rate.
This is the ratio
of number of
clicks that is
B in the ratio and A is
the number of
impressions for each
advertisement.
And here you can see the
results for the first advertising
campaign. Campaign
was devoted to
control for children.
I emphasize here the duration
of this advertising campaign because
duration sometimes is very important.
Since in some cases
we have no enough information
about users
and about
some audience
parameters before the campaign starts.
So when campaign starts,
we sequentially
improve the quality of targeting.
And here you can see
also the
segments selected for this
campaign. For the campaigns usually
they
are assigned manually by some
account manager or the person who is
responsible to select the
audience
that is appropriate for the company
who buys
the advertisement.
And as you see,
we
initially we have quite a
restricted amount of impressions after
using
CASE and LUSP approaches.
Both of them
managed to significantly
increase the number of impressions.
But for
if you take a look at the quality
of this audience
or this extended audience
we see that LUSP
method that is based on extending
audience
by generalization of user profiles.
This method
has way better
quality of extended audience.
This is
clearly
if you take a look at the
CTR obtained for the
companies. Of course the initial
CTR was a bit better, but
for
straightforward method
CASE we obtained
lower CTR
that means that the
quality of audience
in this case was not so good.
And for
two more advertising campaigns
we see approximately the same results.
The second campaign was devoted to
frame houses for villages and
this company had very restricted
duration and here we again
see the quality
of LUSP method
is the same as
it was initially
and we managed to significantly
extend the number of advertising
impressions and as a consequence of course
we see
more clicks.
And for third advertising campaign
that was devoted to
language in a major Russian bank
we see pretty the same result.
Of course CTR
for LUSP method was a bit lower
than it was for initial audience,
but the amount of impressions that was
a very good result here.
So these results
prove that this approach
works indeed.
And we can
conclude that
the amount
of
clicks
by LUSP
was 74%.
So the
maximum amount
of clicks
for just
lessening of
belongingness thresholds was just
74%.
So that proves that the quality
of audience that we get
if we use generalized
using segments instead of just
lessening belongingness values
so this way
works way better.
So for the future plans
we will emphasize
further expanding
of tested advertising campaigns
because there are many different
campaigns with different duration and different
user segments assigned.
So we can have an opportunity
to check how this method works for very
long campaigns.
It works on quite short campaigns
where we have restricted duration, where we have
a restricted amount of
further
contacts with users
expressed in impressions.
And compare this LUSP
method with audience proximity lookalike
methods. Lookalike is
a family of the methods where we
instead of modifying
somehow targeting procedures we just
either buy a new audience
somewhere. This can be inappropriate
for small companies because it's technically
impossible sometimes but for
some medium sized companies this is quite
common way where the companies
share each other
audience and they
also try to
find similar audience
say by matching user profiles
by finding some
intersections between user profiles
and stuff like that. This is very wide
family of different methods.
And the second
is
developing
a strategy for parameters
fitting because currently we just used
fixed values of our
parameters of this algorithm and of course we can
think about how can we
make the selection
very automatic or
adjustable during the work of
this algorithm. That would be great.
Thank you for your attention.
Thank you.
What is
what are impressions?
How are they measured?
Impressions is the event
when some users see the
advertisement.
This is
can be either the banner
or the
video for example.
And the important issue here is
how to measure that because
different companies
have different approaches
to measure these contacts. For example
some companies just use
special JavaScript events
to measure that. So if
more than half of
picture of ads
is visible to user, I mean
it appeared on the visible
part of
the screen. This can be
impression. For other
companies they use
just loading of these ads.
In our case we tried to
follow the most strict definition of
impression. The first one
that I described, more than half
of picture of the advertising
should be visible at the
user's screen. And in that case that will
be impression. Thank you very much.
A long eye contact with
advertisement.
This is usually
most commonly this is
undefined but
some companies use
and we also follow this
it should be at least one
second.
Could you please explain
each advertisement
has a set
of keywords or tags,
how to define it?
Yeah, thank you for
this question. So yeah,
from the advertisement side most commonly
these segments are defined
manually by special
companies either on buyer side
or at the agency side.
And they are
fixed and for example
if we would like to
if we have
advertising campaign about
wall workers we can choose the
segments wall worker owner,
people who are going to buy
car.
We can also specify
some demographic
segments such as
age or gender
or some location
and these things
are defined manually in most cases.
Thank you very much.
Any more questions?
Online participants, no questions?
I have a question.
Dmitry, I have this question.
This approach,
is it possible to apply this
approach to building
recommender systems?
This is a very interesting
question. So yes,
I think this is possible because
there are many different kinds of
recommender systems.
Some of them are based on
different engines such as
collaborative filtering,
other use
some more
interpretable techniques
such as matching between
some things that are similar
to what we have in
internet advertising.
From my experience I can definitely say that
in some recommender systems
companies
with similar content taxonomies
very similar
to what we have in internet advertising
and
for these recommender
systems we will solve
pretty the same problem
where we have
restrict, for example,
some set of content
and users.
The issue will be
just to
choose appropriate
content for some users and
we will solve the same problem.
From my personal experience I can
tell about working in my
previous company where we worked with very large
content taxonomy that is at least
twice larger than
IAB taxonomy. The company had
its own content taxonomy
that contained
six or maybe even seven
layers of
different
segments.
In that case I think
this is a good
input data to develop
here
this
recommender engine based on
this generalization in taxonomies.
Let's start.
We can see the variation inequality problem.
On the slide you can see this
formulation in the unconstrained
setting. This problem is
written quite similar.
We just need to find
some point z star such that
operator f in this point z star
is equal to zero.
In the first glance this problem looks like
quite strange because we don't know
what is the operator but
to emphasize that
this problem is quite general
we can consider some particular examples
when this problem
arises. For example
the most typical and very popular
example is the minimization problem
when we try to minimize some function f
and if we put the operator
in the variation inequality as the gradient
of this function
we need to solve
the problem of
the search of the stationary point
function. In the convex setting it is equal
to the minimization and in the non-convex
just to search of the stationary point
but it's enough because
this is the best guarantees what we can do in theory
for non-convex setting. Another example
is saddle point problem. Here we have
not only minimization but here the
minimization and maximization here.
Here we
use the operator f
and we take
the gradient on variable x
the variable in what we minimize
and anti-gradient on variable y
the variable in what we
maximize and
it's easy to show that we try to find
stationary point not only on the gradient
x but in gradient y also.
And in the convex
concave setting this is equal
to find the saddle
point problem.
Also here we can consider the
fixed point problem. Here we have
operator tau
and we need to find some point z star
such that tau in
z star is equal to tau.
This is stationary point, fixed point of the
operator. And here we can
put f, the operator
and the variation in equality as
z minus tau z and we find
with this operator the fixed point of the
operator tau.
In our research we can see
the finite sum case
of the operator f
and we assume
that the operator f is some kind of average
sum of other operators fi.
This setting is common to machine learning
because typically for example
risk minimization is the sum
of losses of our
model in different data points.
We have weight of the model z
and model f.
We input
some point xi
and weight z to the model and
compare the output of the model with
the real label y, yi
and penalize the
difference between them.
If we speak about saddle point problems
in terms of machine learning here we can
give example of adversarial
training. It is close to the
original empirical risk minimization
on the slide, but here
we add some kind of adversarial noise delta i
to each of the samples.
Using this noise we make some kind
of
make our
training process more robust
because this noise also
train during the
process of training of the
model. These weights
make our data set more
adversarial to our training.
That's why we can avoid
the process of
overtraining and other bad examples.
It is also good to
save
against adversarial attacks.
If we use our model
with delta noise.
This is a practical example when
minimization and saddle point problems
arise in machine learning.
Next we give some assumptions on
our operators.
The general operator f and summons
f pi to make our
analysis.
Here we give two assumptions
cocoercivity and
strong monotonicity.
Cocoercivity is some kind of assumptions
like Lipschitzness of convex
function.
For minimization problems
Lipschitzness of the gradient
and cocoercivity is equivalent.
For saddle point problems
Lipschitzness of the gradient
and cocoercivity is not the same
and cocoercivity is more
restricted but also general.
One more assumption is strong
monotonicity of the general operator f.
For minimization problems
Lipschitzness of the saddle point problems
is equivalent to strong convexity
of target function of the minimization problem
and strong convexity of the target function
in the saddle point problem.
If we speak about
stochastic methods for our
finite sum problem.
The main problem of the finite sum
of commotion learning
it is too expensive to
collect, to compute the full gradient.
That's why we just compute
some gradients on small batches
and using these batches organize
the process of training.
Here on this slide you can see the
typical form of the
gradient method. We have some kind of
operator vk.
It can be for example in SGD we use
some, for example one
we can choose randomly one of the summons
and use it as a gradient
instead of the full gradient.
This is just the typical most common
SGD version of saddle point problems
but stochastic gradient
descent us because we not only
descend to the optimum but also
ascend to the maximization variant.
There are another version of methods
for finite sum problems, for example SVRG
methods. In SVRG methods
we don't only compute
the value of operator
fy in current point.k
but also make this
correction. This correction
here, correction in point wk.
Wk is some kind of
reference point
which we are
updated very rarely. For example
in one times per big number
of iterations. In this point wk
we compute the full operator
or full gradient. But because
we updated very rarely this
full gradient is also computed very rarely.
And we made some kind of correction
and this
using fi in point vk
and the full operator in point vk.
And near the solution
this wk
operator for SVRG
is a good approximation for the real gradient
for the real deterministic gradient
for the real deterministic operator.
Another approach is the SARA approach
the main approach of our research.
It is close to the
SVRG.
Ideas is common, but here
we update this operator vk
on the flight. We don't compute
we don't use the reference point like in SVRG
but modify this vk
using current point and previous point.
And experiments
of the show that
SARA is more robust
and has
smoother trajectory of the convergence
than SVRG.
And here we provide the full algorithms
of the SARA for stochastic concursive
variation inequalities.
There are two loops
the main loops on variable s
and the inner loop on variable k.
In the main loop we need to
update the full operator as this
v operator v0 operator.
Then on the inner loops we made SARA
updates.
And here you can see the convergence
of the algorithm.
And theorems says that
under our assumptions
we can guarantee that
one epoch, one outer iteration
our main iteration of our algorithm
can guarantee the norm of the
operator or norm of the gradients
became two times smaller.
And also we provide
corollary with the
oracle complexity of our algorithms.
You can also see
on the slide.
Then I will show
you experiments. We provide experiments
on small bilinear problems.
This is a settled point problems.
On the slide you can see how we can generate
the different parameters of these problems.
And here we use SVRG and SGD
from the previous slides as
competitors in our experiments.
And in plots you see
how SVRG,
SGD and SARA
works for this toy bilinear
problem.
And you can see that our method
outperforms the competitors from the
previous papers.
Okay, thank you. That's all.
Thank you for your presentation.
Thank you.
Any questions?
Any questions?
Thank you for your presentation.
I wanted to ask...
Excuse me.
Yes.
I wanted to ask
how your method compares
to the Nesterov method.
Or is it part of one of the...
How does it compare to yours?
Here the main problem
that variation inequalities is more general
problem than minimization.
Nesterov's method also works for minimization problem.
But for variation inequalities
and settled point problems
it can be proved that there is no
Nesterov acceleration.
We can accelerate
theoretically
this problem. That's why
in Nesterov's methods works the same
as original
methods for
settled point problems, for example.
And typically in practice
the situation is the same.
Alright, thank you.
Thank you very much again.
I invite the next speaker.
Thank you.
Are you here?
Hello, I'm here.
You're welcome.
Can you see my screen?
Yes.
Ok.
I developed a
parallel linear active set method.
My name is Doug Neumann.
I was successful
in this technology.
The goal was to
Мы нашли сложный форма-метод для минимизации конвертных функций под ограничениями линейных неисправностей.
И мы нашли один, в том числе и конвертный минимизационный метод для линейных
неисправностей, который называется сложный форма. Так что, что я имею в виду сложного форма? Это просто
алгоритм, который решит это в finite number, алгоритм, который найдет минимальную точку
конвертной функции в finite number of steps, что означает, что это не ответ на
epsilon ball и не ассоциативный алгоритм. Есть много сложных форм, линейные неисправности, конвертные
минимизационные методы, так что relying on the existence of one is not a waste of time.
Например, коммондная проекция, коммондная проекция функционанта на афианскую
площадь, а афианская площадь вместо линейных неисправностей, и мы решили это в н-кубе операция.
Больше всего, любую функцию, которую мы можем решить, в которой мы можем найти минимальную точку,
в неисправностей, это также что-то, что мы можем решить для линейных неисправностей,
при использовании изменения вариантов, так что там много их, и это полезно,
потому что мы relying on the existence of such a method. Мы называем этот метод, мы называем этот метод, который
решит минимальную точку конвертной функции на линейных неисправностях, мы просто называем это
наш Black Box Method, потому что это не важно, как это работает, мы просто нуждаем это работать.
И если наш Black Box Method не находится в закрытом форме, то наш алгоритм все еще работает,
это просто не закрытая форма, но это все еще классный алгоритм, и у нас есть очень классные
мультифорнированные характеристики. Для неисправностей, есть вопросы пока?
Для неисправностей, есть некоторые существующие работы с генерацией закрытой формы алгоритм,
есть проекционный метод для Hilbert Spaces, который имеет экспоненционную комплексию, и когда
мультифорнированы, он имеет кубичную комплексию, и это как функция количества
ограничений. Есть закрытые формы системы для каких-то квадратных объективных функций
на линейных неисправностях и укридианных спacerах, и список продолжается. Есть специфическая укридианская
проекционная функция, из которой мы строим наш метод, но мы смогли сделать несколько
улучшений на их методе, о которой я расскажу в конце. Мы используем N для
диаметрии, мы работаем на Hilbert Space, N является диаметрией
в Hilbert Space, и наш конвекс объективный функцион мы называем f. Мы используем c меньше
чем или equal для демонстрации наших р-инвалидных ограничений, и если позже р появляется и вы забыли, что
р должен был быть опять, просто спросите. Это номер инвалидных ограничений. Мы используем c equals
для количества, для корреспондентного инвалидного ограничения, так что мы берем
инвалидные ограничения и сваливаем инвалидные знаки с equal-sign, а затем мы имеем
инвалидные ограничения, и мы вернемся к этому тоже. Мы используем p для демонстрации
смартфона c меньше чем или equal для демонстрации инвалидных ограничений.
Несколько Definitions, которые нужны для алгоритма, чтобы сделать смысл.
Мы называем A афинской площадкой p, если это смартфонная площадка для каких-то
наших р-инвалидных ограничений, и афинская площадка p, если это смартфонная площадка для
единственного р-инвалидного ограничения. Естественно, вся афинская площадка p будет
интерсекцией количества р-инвалидных ограничений. Это важно, мы вернемся к этому.
Для каждой афинской площадки мы также строим кон,
потому что каждый афинский площадок это интерсекция,
каждый афинский площадок это интерсекция планов, так что если мы сваливаем эти планы с
половинками, мы берем интерсекцию этих половинок, мы получаем кон, поэтому афинская площадка
inequality constraints, кон корреспонден на inequality constraints. Например, если
афинская часть является интерсекцией зеленой линии и зеленой линии, а коня
этой афинской части является интерсекцией зеленой половинки и зеленой половинки.
Надеюсь, это довольно просто и смешно. Если кто-то зафиксируется,
он снова придет, так что спрашивайте сейчас. Хорошо, идем дальше. Один последний
Definition. Мы называем его медиатным суперспецом. Итак, если афинская часть является
интерсекцией зеленой линии, то медиатный суперспец будет интерсекцией
любого зеленого линии минус один из этих зеленых. И, например, если мы используем этот афинский
время, то интерсекция зеленой линии и зеленой линии это афинская часть,
то медиатные суперспецы просто зеленой линией или зеленой линией, потому что мы от chciaем
убрать один из этих проблем или чем-то. И интерсекция равновесия остальных
из них – это медиатный суперспец. Медиатный суперспец голого линии – просто
Хилберг-спасе, и нет немедленных суперспасов в Хилберг-спасе.
Попросы?
Так что у нас есть два слайда, в которых я представлю метод закрытой формы.
Во-первых, мы найдем минимальную точку закрытой формы через один из наших коней.
Так что, это рекурсивно.
Чтобы найти минимальную точку закрытой формы через кону Аппайн-спаса,
мы смотрим на все немедленные суперспасы А и найдем минимальную точку через их коны.
Если минимальная точка через любые их коны находится в коне А,
то это минимальная точка кона А.
И это как-то медиаторно, потому что суперконы...
Так что этот ПВ здесь содержит ПА.
Если это кон из немедленных суперспасов, то это содержит кон А.
Так что это очевидно.
Мы показали в книге, что если это не один из этих, то минимальная точка через кон А
равна минимальной точке через Аппайн-спас А.
И мы компютируем это с блоковым функцией.
Так что это закрытая форма для любого кона, любого полигейного кона,
и специфически любого кона П.
После того как мы смогли компютировать закрытую форму...
Есть ли вопросы об этом?
После того как мы смогли компютировать минимальную точку через кон А,
мы потом просто смотрим через все коны, и мы можем это сделать в определенном порядке.
Мы можем посмотреть через все коны и найти тот, который имеет право,
что оптимальная точка через кона равна оптимальной точке через Аппайн-спас,
который мы компютировали здесь.
И кон, который имеет право, если минимальная точка также находится в П, то мы это сделали.
И эта минимальная точка является минимальной точкой П.
Аргумент Ф на П равен аргументу Ф на Аппайн-спас.
Так что это закрытая форма.
Есть вопросы?
Хорошо.
Итак, мы можем организовать это в алгоритме.
Если мы просто выбираем вертикалы полиэтиленов,
если мы просто выбираем точек П, то это не организованно, и это будет бесполезно.
Но здесь есть немного организации.
Итак, прежде чем представить здесь оптимизацию или минимизацию метода,
я просто подсовывал это в том, чтобы решить проблему проекции здесь в R2, чтобы сделать это удобнее в ваших глазах.
Но этот метод подсовывает линь за линь оптимизацию метода в П,
которая является для генерального Хилберта-спаса и конвекс-функции.
Но здесь мы просто решим проекцию на наш пример.
Если вы не знаете, что проекция функции, то скажите, что вы не знаете, что проекция функции сейчас,
и я скажу вам, и это легко.
Хорошо, мы все знаем, что проекция функции.
Пожалуйста, остановите меня, если вы решите подниматься и сказать, что вы не знаете.
Итак, мы просто перейдем в первую очередь все Аппайн-спасы кодименции 0,
так что это интерсекция 0 планов, опять же, это наш Хилберт-спас.
И потом мы перейдем в все Аппайн-спасы кодименции 1, так что это наши планы.
И потом кодименции 2, интерсекция 92 планов, интерсекция 93 планов и так далее.
Так что это просто эти два лупа здесь.
И хорошая вещь в этом лупе, что, конечно,
посмотреть на один Аппайн-спас полностью независимо от того, что посмотреть на другой Аппайн-спас,
так что все это можно сделать в параллельном смысле, очень хорошо.
Итак, после того, как мы выбрали Аппайн-спас кодименции I,
мы посмотрели все оптимальные точки
через коны амидиатных суперспасов Аппайн-спаса.
И хорошая вещь в том, что мы уже посчитали все эти оптимальные точки, когда мы смотрели на i-1.
Так что мы знаем этот маленький πB здесь.
πB это проекция на код B.
Так что если есть πB, который находится в коне А,
то мы теперь знаем оптимальные точки через кону А,
и мы никогда не должны называть это метод Black Box.
И это является силой алгоритма, который мы создали.
Мы можем найти оптимальные точки через кону
без называния метода Black Box.
И если мы не имеем амидиатных суперспасов,
то мы называем этот метод Black Box
и проверяем, если эта проекция находится в коне P.
Если она находится в коне P, то мы закончили.
И вернули эту точку в коне P.
Если мы пройдем через все оптимальные точки,
и мы никогда не нашли,
то мы просто вернули оптимальные точки,
потому что аргумент оптимального полиэндрома
в действительности нет.
И это то, что оптимальная точка находится в коне P,
а также то, что оптимальная точка находится в коне B,
и нет ни минимума на этой точке.
В письмах мы также гарантируем,
что оптимальная точка находится в коне D.
И мы найдем ее.
Это алгоритмы.
Есть вопросы о том, что я писал здесь?
Спасибо, что ответили.
Так что, для проекции,
когда количество оборудований у нас гораздо больше,
чем N,
то наша комплекситетка является R to the N
X Rn ± N³,
которая является полиномиалом
в связи с количеством оборудований у нас.
Это очень интересно,
потому что у нас, конечно, большая дименциональность,
а полиномиал все еще у нас.
Но здесь интересная вещь.
Мы можем работать в целом в параллеле,
в параллеле в связи с количеством оборудований,
а потом комплекситетка является O of N⁴,
в связи с количеством оборудований R to the N±1.
Так что это может быть интересно иногда, я думаю.
Для более динамичной комплекситетки,
когда мы не смотрим только на проблему проекции,
или когда количество оборудований,
как в Хилбардспее,
есть infinитетное количество оборудований,
или есть просто много оборудований,
чем количество оборудований.
Так что, вот этот статус здесь,
комплекситетка,
где я использую эти бракеты,
чтобы указать комплекситетку,
делая что-то внутри их.
Так что у нас, что-то меньше,
R to the N или 2 to the R,
это значит, что если N³,
мы смотрим на 2 to the R,
которая является функцией N.
И если R³,
то мы смотрим на R to the N,
которая является полиномиалом.
И потом это просто
количество оборудований,
в связи с количеством оборудований,
как и как долго нужно делать интерпродукт,
плюс как долго нужно делать
«колор-блак-блок» метод.
Если мы имеем
много процессоров,
либо что-то меньше,
2 to the R или R to the N,
то это становится, что-то меньше,
N или R,
в связи с комплекситеткой
компетентного интерпродукта,
плюс комплекситеткой
компетентного «колор-блак-блок» метода.
В связи с тем,
что мы имеем полиномиал,
то, конечно, если R³ –
F · A –
это полиномиал,
то комплекситетка – это не полиномиал.
Также, если мы находимся
в Хилберте,
то обычно компетентный интерпродукт
в Хилберте
может иметь
ε-компонент
в комплекситете,
и
то это не
«колор-блак-блок»,
и комплекситетка
компетентного «колор-блак-блок»
имеет инфинитно-дименционный
пространство,
и это –
я не знаю,
«интерпродукты» или что-то такое.
Так что, это комплекситетка.
Эти улучшения
в связи с
«колор-блак-блак-блак» методом.
Первым
–
в связи с тем,
что
«колор-блак-блак-блак» метод
смотрит на все афинские спасы
и
Извините, кондицион на линии 3 означает больше и больше, и мы не должны называть метод Black Box.
Так что, как количество ограничений увеличивается, или также, как количество диаметров увеличивается, мы называем метод Black Box
менее приближающим к 0, как процент от количества ограничений или диаметров, которые мы смотрим.
Так что, это большой победитель. Также, предыдущий метод проверяет все спасы Афины,
и потом найдет, как раз, лучшие из них, или минимум результатов, когда мы называем метод Black Box,
метод Black Box на всех этих методах, и наш метод перестанет, когда мы получим правильную ответственность.
Мы это понимаем, и мы готовы. Так что, это хорошо.
Так, эти были преимущества нашего метода за предыдущим методом.
Спасибо. Вопросы?
Можно я?
Хорошо.
Вы говорите об алгоритме, и у вас есть начальник.
Вы говорите об алгоритме, и у вас есть начальник.
Вы говорите об алгоритме, и у вас есть начальник.
Вы говорите об алгоритме, и у вас есть начальник.
Вы говорите об алгоритме, и у вас есть начальник.
Вы говорите об алгоритме, и у вас есть начальник.
Вы говорите об алгоритме, и у вас есть начальник.
Вы говорите об алгоритме, и у вас есть начальник.
Вы говорите об алгоритме, и у вас есть начальник.
Вы говорите об алгоритме, и у вас есть начальник.
Вы говорите об алгоритме, и у вас есть начальник.
Вы говорите об алгоритме, и у вас есть начальник.
Да.
В первой линии у вас есть точка,
по которому подойдет H.
Хильберта Спейс, я думаю.
Моя вопроса,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которому подойдет Y,
по которему подойдет Y,
по которому подойдет Y,
по которому подойдет Y.
Again.
Да, я здесь, да, я здесь.
Окей.
Окей, привет всем.
Окей, и...
Я бы...
Меня зовут Ворис Ковалерчук, и я поговорю об интерпретации машинной линейки для самосовершенствования,
высокого риска решения.
Это джейн Ток, мой старший студент,
Чарльз Рекайдам.
Окей.
Во-первых, я хочу поздравить Бориса Григорьевича Мюркина с его 80 лет.
Мы познакомились давно, в 1971 году, или раньше, в Академии Городок.
И что он делал, в тот момент, он выявил мою мастерскую тезису
в массовом департаменте Новосибирска университета.
Много позже я выявил его докторную диссертацию.
И, конечно, мы поговорили о всех этих научных работах за много лет.
И я просто хочу отметить, что все его хорошие работы были сообщены в процедурах.
Но один проблем, который он решил в 2004 году, не был там.
Я называю это проблемой Мюркин-стрима.
И я бы хотел показать вам это, и вы увидите, как элегантно его решение было.
Нужно ли это быть в Springer Volume 2?
Это вопрос, который может быть разобранным.
Окей, я покажу вам его решение.
Да, я помню это.
Так что, надеюсь, все увидят, что он действительно решил проблему.
Окей, теперь мы идем к технической части.
Так что, я расскажу вам о координатах динамика, которые мы создали,
и как они могут решить проблему, который я просто выяснил в первой слайде.
Так что, во-первых, машинная участие больше и больше использована для высоких решений,
как машинной движения, диагностики канцер,
и, к сожалению, многие из этих моделей – черные коробки для конкурентов.
И, конечно, они не людьми интерпретированы, и для высоких решений это неудобно.
Так что, главный цель в очень активной исследовании сейчас –
как сделать эти модели более интерпретированы.
И это один из токсиков моей презентации.
Позвольте мне дать вам один notable example.
Хай-риск пациентам адмитированы в больнице,
и хай-риск пациентам тренируются как хай-пациенты.
Модель, в которой я рассказываю, показывает, что азома корреляет с хай-риск пациентом.
Этот продукт азома-трейтмента, который уничтожает риск пневмонии,
этот закон был интеллигентным, позволяющим его познавать и убрать этот опасный закон.
Но, конечно, если бы это был нейронетворный или глубинный нейронетворный,
то, конечно, это было бы невозможно.
И, конечно, это опасный бизнес.
Так что, первое проблема и объектив,
это, действительно, преодолеть азому корреляции,
чтобы они, по крайней мере, были грамотными или, идеально, transparent boxes.
Так что мы специфично говорим о двух моделях визуально интерпретированных самосервисных моделях,
чтобы распространить оборудование графичных машин.
Я бы хотел бы упомянуть слово «самосервисные модели»,
потому что создание моделей интерпретированных
предполагает, что пользователь согласует с ним.
Так что, это не только вопрос, как хорошо и как много формул,
мы будем писать, и сколько сериалов мы проверяем.
Пользователь должен согласовать с этим.
И, идеально, если пользователь будет участвовать,
то, или, на самом деле, создать модель,
то, вероятность придет с этим.
Не обязательно все время, но это может иметь больше шансов.
Другим проблемом является религиозность машинленических моделей
в сценариях высоких рисков.
К сожалению, как я покажу позже,
многие оборудования машинленических моделей
измениваются в их аккуратности,
что, опять же, неудобно для приложений с высокими рисками.
И, опять же, мы используем визуальный знаний-дискавертический подход
для изменивания и найдения визуальных знаний-дискавертических моделей
для обнаружения лучших алгоритм или моделей для лучших данных.
Это, в основном, концепция функционального функционала.
Теперь несколько слов о визуальных.
Вы можете видеть здесь длинную линию ученых,
которые утверждают, что визуальные играют
наиболее важную роль в их обнаружениях.
Альберт Айнстайн был очень очевиден об этом тоже.
Но проблема в том, как мы можем сделать визуальные обнаружения
в н-дименционных данных,
потому что мы живем в тридименционном мире,
и мы действительно не видим высоких дименционных данных для этого.
Таким образом, сегодняшние подходы, в основном,
основаны на двух причинах.
Несколько-дименционная редакция,
как принципа компонента анализов,
мультидименционного скалинирования
и целый бюджет других методов,
или распределение НД-даталей на два вида низеньких дименционных.
Первый, конечно, потеряет некоторую информацию,
а второй уничтожает интегритет НД-даталей.
Таким образом, наша первая практика,
что мы действительно должны идти от этой практики,
в которой мы пытаемся представить н-дименционные точки
как два-дименционные или три-дименционные точки,
но в действительности представить их как графы в 2D,
а не как точки.
Это как мы можем сохранить информацию НД.
Я покажу несколько примеров.
На левой стороне пример с параллельными координатами,
которые были разработаны более 100 лет назад
и полностью забрали,
пока Альберт Инзелберг в IBM их раздекорировал.
Таким образом, у нас есть 4-дименционные точки 8, 4, 7, 9,
и каждый координат находится вертикально,
и вы связаны с этими точками на каждом координате
как полилайна.
И эта полилайна как граф,
как граф,
однозначно, 1х1 сняли с 4-дименционными точками,
и, однозначно, это можно сделать для любых дименционных точек.
На правой стороне шифрованные координаты,
которые мы разработали.
Так что это не существует за 100 лет,
но это довольно просто.
Так что у нас есть два координата картижи,
шифрованные один за другим.
Так что первая пара значит 8, 4 в 1,
7, 9 в другом координате,
и мы просто связаны с ними
используя аромат.
Еще раз, очень простой граф.
Если сравнивать эти два графа,
вы можете увидеть, что параллельные координаты
требуют 4-дименционных точек и 3 линии,
но шифрованные координаты только 1 линия и 2 точки,
и обе из них неразборчивы,
представляющиеся полностью в 4-дименционных точках
и, однозначно, генерализованы для больших дименционных точек.
Далее у нас есть Лемма Джонсона Линдон-Страйлса.
Они доказали это в 1984 году,
и в 2000 году несколько версий
этого сериала появились без оценки.
Но, в принципе, что это сериал говорит нам,
это говорит нам фундаментальную лимитацию
нд-детей в 2-де.
Это просто означает, что ошибки,
которые мы получим в нижней дименционной точке,
будут очень значимыми.
Я пытаюсь оценивать много деталей,
но, в принципе, заключение очень очевидное.
Мы просто не имеем достаточно близких
с равномерными дистанциями в маленьком дименционном месте,
чтобы представить полностью нд-детей.
Это очень очевидно в бинарном кубе
в 10-дименционном точке,
где мы имеем более тысячи нод,
но в 2-дименционном точке в квадрате
мы имеем только 4 нода.
Что мы действительно делали в этом работе?
Мы изменили динамичные координаты,
визуализировали нд-детей в этих координатах,
без лезвия,
и улучшили распоряжение в классе.
И, опять же, мы нашли наиболее плохую ситуацию
нд-детей, используя эту технику.
Так что главный концепт здесь
это координаты генерала линии,
которые были представлены в 2014 году,
и в деталях это представлено в книге
в 2018 году.
Так что главная идея,
которую я уже выяснил,
это использовать графы вместо точек
для представления нд-детей.
И для многих типов,
мы уже делали в нашем команде,
этот работник,
и этот отдельный работник
работает с одним типом
генерала линии координат.
Хорошо, теперь я просто
иллюстрирую их визуально.
На левой стороне вы можете увидеть
параллельные координаты,
которые я уже объяснил в середине.
Вы можете увидеть модифицированные
параллельные координаты,
где мы позволяем линии
быть не только параллельными,
но в разных направлениях.
Тогда мы можем позволить
все координаты быть на линии,
в одной линии.
Мы можем позволить их быть
на краях нд-детей,
круглых, коверных, линейных.
В основном, у нас есть
огромное количество
возможных координатов генерала линии,
и все из них позволяют
нескольких представлений нд-детей
в контакте с традиционными
автогонными координатами
картижей,
которые только限или
по три размера.
Итак, основная идея,
что когда Декарт
создал его координаты
400 лет назад,
то идея была
описать физическое слово,
которое идеально
соответствует
автогонных три-дименционных координатов.
Но для данного научения
мы действительно должны
идти к этим типам координатов,
потому что они позволяют
представить мультидименционные данные.
Я иногда называю это
нд-детями.
Итак, у нас есть несколько
статностей о
координатах.
В основном, основная из них
то, что
симуляции графов
могут быть соответствованы
с дистанцией между
нд-детями.
Итак, сейчас мы поговорим
о проблемах, которые у нас
здесь.
Во-первых,
мультиплика методов
визуализации
приведет к эффекту,
что то же данные
с разными методами
визуализованы очень разнообразно.
И вы можете видеть
этот пример.
Тем более,
это то же данные,
как и оба атрибута
грамматических изменений визуализации.
Это не только трудно,
но и преимущественно,
потому что
это позволяет найти
визуализацию, где классы
визуализованы очень хорошо,
и, конечно же,
поверить пользователю,
что он или она может
верить в это.
Итак, теперь
еще одна
задача.
У нас здесь
ненавидимые
тридименционные
субсети,
но они не
визуализованы в 3D.
И есть множество примеров
похожих на ненавидимые данные,
но здесь
в визуализации в 2D
они не визуализованы,
они поверны,
и, конечно же,
это не очень полезно
поверить пользователю.
Итак, мы хотим решить этот проблем.
Проверим
еще один слайд.
Хорошо.
И, по какой-то причине,
это холодно
и не позволяет мне
визуализовать слайды.
И...
О, господи...
Ух, наконец-то двигается.
Теперь мне нужно объяснить,
как динамичные кавалерные координаты,
которые мы назвали
ДССР-дизайном.
Итак, мы сначала
добавляем данные
к параллельным координатам,
затем мы изменяем
направления параллельных координатам,
и затем
мы найдем векторы,
которые показаны как
зеленые векторы, которые
идут в каждые эти точки
в параллельных координатах.
И затем мы
подключим зеленые векторы
один за другим,
в основном, подсумевая их.
И теперь вы можете видеть
на правой стороне,
как эта очень нолинейная трансформация
превратила
эти данные
из параллельных координат
в ДССР-1.
И вы можете видеть, что
очень много
зеленых цветов
на них появляются.
Итак, это другая версия
динамичных координат
не основанных на параллельных координатах,
но в шифтных координатах.
В левой стороне вы можете видеть
данные, которые
в шифтных координатах.
Потом, для каждого
момента, в котором
в шифтных координатах
в шифтных координатах
И опять, мы собираем векторы, которые идут от оригинала системы координации к этими точками, и потом мы собираем эти векторы, омитируя первую вектору.
И в результате вы можете увидеть на правой стороне результат этой нолинейной трансформации.
И опять, классы собраны, но не так хорошо, как мы хотели.
Следующий этап, это, на самом деле, скалирование атрибутов.
Так что сейчас мы не просто используем пары координаций, которые были скалированы, но вторые и третьие пары маленькие.
И теперь вы можете увидеть, что с этим треком мы можем иметь гораздо лучшее распространение классов.
И более того, очень видимо, то место, где они перерываются.
Так что это создает базу, чтобы найти наиболее плохие данные ориентирования для алгоритмов.
Так что теперь вы можете увидеть, что мы хотим бороться с редакцией перерыва.
У нас есть несколько вариантов, которые мы в действительности используем.
Первый вариант.
Это создание гиперблоков и анализирование их используя решения-три или любые другие хорошие механизмные методы для хорошей распространения.
Конечно, используя дополнительные атрибуты, как принциповая компонентная анализация, используя их в дополнении к оригинальному атрибуту.
И используя, что сейчас стало популярным, Т-дистрибута, скракастик-набор-имбединг.
Теперь мы идем к следующему слайду.
Это челлендж, чтобы продолжить работать.
Это челлендж для меня.
Это челлендж для меня.
Да, я пытаюсь.
Окей, выглядит так.
Теперь вы можете увидеть два разных перерыва данных, которые мы хотим убрать.
И вы можете увидеть, что они имеют другую важность.
Один не очень влияет на классификацию, и другой влияет.
Так что мы должны быть смогли увидеть это.
Окей, сейчас я покажу технику.
Во-первых, я должен представить хайперблок-концепцию.
Это, в основном, генерализация ректангла в н-дименционном месте, называется н-ортотоп.
И что мы пытаемся сделать?
Мы создали решение-три и использовали самые информативные атрибуты решения-три,
как первые координаты, которые мы будем использовать в данных.
Итак, теперь вы можете увидеть другую данную с ее решением-три.
И вы знаете результат, используя метод, который я описал.
Когда атрибуты мы скалируем, и мы также можем использовать решение-три-гайданс.
И вы можете увидеть, что некоторые из самых плохих случаев являются очень видными для консервных решений.
Окей.
Теперь это похожие вещи для висконсианского брест-канцерного данного и решение-три.
И снова, это результат данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного
тан 10hip
...
...
...
...
...
...
...
...
...
...
...
и т.д. на 10-фолд-кросс-валидации данных на том же данном,
которое я показал вам раньше, и вы можете видеть, что на уровне 10-фолд-кросс-валидации
победитель является поддержательная веер-машина, но в худшем случае это рандомная леса,
и вы видите, разница очень драматична между 97% и 61,9% и мультилиниевая персептрон
была очень ужасная от 89% до 23%, так что для рискованных задач это было бы
действительно не satisfiable to use SVM, which in the worst case just shown 38%.
Similar for the cancer data, but different algorithm is a winner here, EKNN for
10-fault-cross-validation, but naive bias for worst case, and obviously cancer
case it's definitely a high-risk task, and now I can show how we try to work with
missed and written digits, which total data set contains 60,000 images, and on the left it's
smaller standard t-SNA visualization, and on the right with our additions, basically t-SNA
represents them as a single point, and we show as graphs, of course, it needs to be zoomed
multiple times to see details, so it provides more information for analysis.
So there are several other methods proposed in the literature. Most popular today it's LIME,
Local Interpretable Model Agnostic Explanations developed at the University of Washington.
What do they do? They use linear machine learning models to interpolate relations between
input and output at the local level, and assumption is that linear models are always interpretable.
We actually challenge this assumption, because for heterogeneous data like medicine,
where we have temperature, blood pressure, it is not so obvious, and we call them quasi-explainable.
But in contrast, hyperblocks as a generalization of decision trees are 100% interpretable.
So Charles obviously developed all this software, and with his skills he was just hired by machine
learning group at Amazon. And in conclusion, as you can see, those new visualization methods
are lossless and allow dual visualization, classification, and analysis of data.
And hyperblocks have advantages that they build more complex models than decision trees.
And teaching engineering, like adding additional features, I demonstrated as another way to improve
the situation. And again, worst case validation is doable in this visual way,
and convincing the user to trust or not to trust a particular method.
Future work obviously is going to more complex, larger data sets, and more efficient methods.
These are a few illustrations when we basically only visualize hyperblock centers,
similar to popular clustering approaches, which Boris Mirkin worked for years.
And on the right, another option. That's basically it in my talk.
Thank you for watching!
Yes, a good question. Yes, we have, of course, those algorithms too, and we actually compare it,
how competitive automatic algorithm is with the human, and in some cases humans were actually
better. But definitely you are right. And we used, one of the ideas was, of course,
because it's a two-dimensional image, we can scan this image and find at least pure areas.
In contrast to multidimensional space, it's quite an easy way. Another option was to use
a support vector machine. They support vectors and explore areas close to them,
because they are supposed to be close to the border, so guiding the human and automatic algorithm.
Theoretically, yes. But the problem is that for each algorithm the area is not the same.
So if you believe, for example, if we decide that a support vector machine is the best one
for, say, some other reason than pure accuracy, then, of course, we can pick up those areas
where it did not work well and use, say, K&N in those areas. Yeah, that's good.
Sure.
Yeah, sure. No problem. Basically, you need to ask Boris Grigorievich.
I don't have them. I have no these pictures. So, Boris, it's really quite beautiful pictures. I've never
seen them. That's it.
Thank you.
Thank you.
Which are alternatives that are the best alternative for at least one
person in a society and beds. Not alternatives that everybody hates, but alternatives that everybody
does not put on a top of preference profile, preference order. So we have goods which are
best alternative for at least one and beds which are not best alternative.
So, and I said structured preferences. So we have structured preference space, structured
alternative space, and a second significance, structured preference space. So the most
influential example is single pick preferences. So we have a line where we have alternatives and
agents ideal points. And the further alternative is from ideal points, the worse it is. So
we have different types of single pick preferences. So
general single pick preferences. We have a line and all alternatives on one line. We have
error single pick preferences. So we have single pick on each triple. We have a single picked on a
circle. So the same idea. So we have circle topology and we have so agents ideal points
and alternatives on the same circle. And fishbone domains where we mix single pickiness and single
deepness. So formally we can introduce single pick preferences as the following. So domain of
single pick preferences is defined by an axis. We have a linear order over x. This is an axis.
A preference profile pi is single picked with respect to an axis a. If for each agent the upper
countersets are connected according to this axis. So we do not define distance between
alternatives. We do not define distance between agents and alternatives. So we have the following
property there, ideal points. And we can order all alternatives to the left and order all alternatives
to the right. And we cannot compare alternatives from the left and from the light from ideal point.
And this property we have connected upper countersets are very useful in computer science.
So we have matrices with consecutive ones and we can utilize this property in algorithms
and many problems within single pick preferences becomes attractable
whenever in general some problems are NP-hard. So we can imagine any
preference model. So we can think that a society
sometimes people are clustered. So we have not all possible preference order in society but
some subset of preference orders. And this subset is called domain. And we can imagine a variety of domains.
And we need to think that these domains have some properties and we want to restrict our domains
to domains with good interpretable properties. And these are these properties. So
firstly, we want to have counterset domains. So within this domain every profile composed from
preferences from this domain has a cyclic majority relation. And in economics, political science,
computer science, first of all we study counterset domains. And these domains are
so leads to transitive majority relation, have graphical representation,
simplifies computationally hard problems and so on. And within these domains these domains are also
very different and not all of them are have good interpretation. So we have properties within
counterset domain. So counterset domain D is connected if every two orders from the domain can be
obtained from each other by a sequence of transposition of neighboring alternatives.
Such that the resulting order belongs to the domain at each step. So this means that we do not require
big shifts, big changes in preferences. So you can always find something close to your
current preference order. So maybe within only one swap of preferences. So a counterset domain has
maximal width if it contains a pair of completely reverse linear orders. So we allow diversity, we allow
really different opinions in our society. A counterset domain D is minimally rich if for each alternative
there is an order from the domain such that this order has alternative X as a top alternative.
So minimally richness reflects properties that all alternatives are good, that for each alternative
there is an agent, there is a preference order such that this alternative is a top alternative.
And in my paper I want to weaken this property to weak minimal richness.
So this alternative, each alternative is either top or bottom alternative in at least one preference
order. So we have if you have top alternative, so it is good alternative, if we have bottom alternative,
it is in some sense bad. And what we have? We have classic characterization of single peak domain.
So each single peak domain is connected and minimally rich. A counterset domain with maximal width
so and we have if and only if. So it is really characterization of single peak domain.
And if we weaken minimally richness to weak minimally richness, we get the class of GF domains.
So the definition would be here. So it is the following structure. We have a linear ordering of alternatives
A1AM and a subset A such that if a triple, so for each triple of alternatives
AI, AJ, AK, if the median of this number belongs to this set, so AJ belongs to set A, then this
triple is single dipped. If the median belongs to set X minus A, then this triple is single dipped.
So we can mix single peakness and single deepness. And so from first view it is strange, so we cannot
interpret this definition what the meaning of these preferences, but the following proposition
introduces a very good picture. So single peaked on a circle. So we have a circle with alternatives,
with ideal points, with the same meaning of single peakedness. And what is interesting, GF domain
is a subset of a spoke domain. So single peaked on a circle domain. So single peaked on a
circle domain is not a condensate domain. So single peaked on a circle domain is a very big domain. It
contains cycles, so the majority relation can be cyclic. And GF domain is the biggest condensate domain
within a single peaked on a circle domain. And we can introduce the following picture. So it's the main
picture of my talk. So we have a circle and we partition all alternatives on inside alternatives
and outside alternatives. So goods and bads. And what is the meaning of this inside and outside
alternatives? So we have two interpretations, at least two, so we can introduce many of them.
So there is a lake and a beach which occupies an interval of lake coast. All agents take a rest on
a beach. Alternatives are locations of ice cream stands. Some of them are inside. The beach,
inside alternatives, other outside. Some outside alternatives are better than some inside alternatives
for some agents, but there is no agent which has an outside alternative as the first choice.
So all people have a rest on a beach, so within this dotted area, and they can think that the closures
are better, and they can think, they can compare outside alternatives. So the place is outside the
beach, but all of them think that inside beach there are better alternatives than outside the beach.
So another interpretation is time or calendar circle. 24 hours circle has common working hours
interval. A video conference session should be proceeded every day at exactly the same time slot,
and all agents prefer to do it within working hours, but they can also compare outside alternatives.
So if we have calendar or 365 days circle has a common school holidays interval,
students are going to have a trip, and all agents prefer to do it within their holidays,
so students can discuss other options. So I generalize standard preference model
adding outside options. So preference model within inside options is
introduced earlier, single pick preferences, other examples, and if we add
outside alternatives, which are comparable, but not the best, we can think about more general
preference model, and this more general preference model can be transitive, so it is
Condorcet domain, and it is interpretable this picture. So we can also think about
some circle town, for example, Moscow, and we can think about airport outside Moscow. So nearby Moscow,
we can think that we should choose a point where we will have a new airport, and the same, so we have
some inside alternatives, so some possible points outside and so on.
So that's all for today. Thank you for your attention.
I am brave and that's all. Thank you very much.
I would like to thank everybody who participated in so many ways
that this conference became a reality, and I hope that we meet much more frequently, but for sure
for 90 years celebration of Boris Milton. Please, Boris, remember, you are responsible.
Any questions, especially online?
Yes, just from what I understand, you presented a model, but there are no theorems at this point, or lemmas, like...
by connectedness, by weak minimum richness, and mass knowledge. All right, thank you.
So again, happy birthday to you, Boris, and thank you again. Everybody, we
are going to complete and to start our preparation for the next conference.
Also, I use this opportunity to invite everybody who has not yet contributed to the book,
because I believe you have a couple of hours to submit your contributions. Thank you again.
Okay, see you next time.
