Всем доброго дня, мы с вами продолжаем наш курс по компиляторам. Сегодня у нас шестая лекция,
да, мы тут пытались посчитать какая у нас лекция, с учетом перерывов, но вроде справились. Значит,
сегодняшняя тема у нас интересная и, наверное, я так скажу, что если бы мы с вами проходили
полноценный курс по компиляторам, наверное, мы бы полноценно имеется в виду годовой или вообще бы
занимались компилятором, это был бы там, не знаю, отдельный полусемистровый или семистровый курс.
Да, тут как раз сидят люди с кафедрой Испрану, мы передаем вам привет. И сегодня как раз мы
познакомимся с этой темой. Я оставил некоторые блоки для того, чтобы просто было понимание,
куда в сторону оптимизации можно копать. Наша цель все-таки дойти до конца компилятора,
поэтому мы этот момент пропустим. Дополнительно мы с вами в прошлый раз говорили про оптимизацию
иара, да, то есть мы с вами построили дерево промежуточного представления, и мы сразу сказали,
что у нас это дерево промежуточного представления больше представлено именно для целочисленных
типов, то есть там по факту нету типа Bool, поэтому у нас там возникали некоторые веселые конструкции,
вот, и наша цель будет сегодня от них же избавиться. Опа, бах, перезагрузка случилась. Вот,
и поэтому нам нужно поговорить про кононизацию этого дерева, заодно вывести некоторые основные
понятия, которые так или иначе просто есть в современных языках промежуточного представления,
в том же самом LVM, поэтому нам нужно сегодня как раз привести все к виду кононизации дерева и
после этого уже все это разбирать. Мы находимся с вами сейчас на стадии оптимизации, то есть мы
потихоньку движемся в нашей цели. Напомню, что к концу семестра, на самом деле, я бы скажу так,
к середине к концу апреля хочется добежать до последней стадии. Хочется добежать до последней
стадии для того, чтобы мы с вами все детально разобрали. Посмотрим получится или нет, ну,
еще дополнительные темы тоже рассмотрим в нашем курсе. Итак, давайте вспомним, что у нас есть. У нас
с вами было в прошлый раз яр дерева, то есть мы с вами решили строить яр в виде дерева. У нас с
вами в этой конструкции есть следующие инструкции. У нас с вами есть expression, у нас с вами есть
statement и у нас есть expression list для вызова аргументов функции. Пока что у нас нету statement
листа и хотелось бы, как ни странно, взять список, у нас есть sequence, sequence, sequence, sequence,
хотелось бы привести его в линейный вид, то есть чтобы можно было положить statement list. Понятно,
что если мы строим современные яры, то там это просто так получается. Просто мы применяем
pattern строитель и при помощи применения pattern строитель мы как раз и получим statement list,
когда мы будем добавлять каждый statement последовательно. Итак, цель на сегодня
построить конструкцию яр дерева раз, во-вторых, понять, что такое basic block и разбить яр дерева
на составные части, которые называются basic block. После того, как мы с вами построим уже
наборы basic block, мы с вами попробуем провести оптимизацию этих деревьев. Итак, давайте вспомним,
какие у нас есть проблемы в яр дереве. У нас, значит, смотрите, у нас есть инструкция вида
e-sec. В чем она заключается? Она заключается в следующем, что у нас с вами нужно получить
некоторые expression. Как сложно. То есть у нас есть... Что это означает? Это означает, что на шаге 1
нам нужно вычислить значение statement, а после этого на шаге 2 вернуть expression. Что это дает нам в
точки зрения исполнения? Это нам дает нелинейность исполнения нашего алгоритма. То есть такие
инструкции парсить уже намного сложнее, потому что нам нужно вычислить side effect, возможно вычислять
side effect не сразу в нашем коде. То есть каким-то образом нужно будет преобразовать эти составные
части. Давайте проверим, может быть кто-то там в Zoom заходил. Просто в waiting room один человек
сидел, а теперь его нету. Да, наожидался. Мы слишком долго разбирали. Вот, и во-вторых, для того,
чтобы представить, решить эту проблему, нам нужно вынести e-sec на самый верхний уровень. Почему?
Потому что e-sec на самом верхнем уровне просто становится sequence. Мы его можем легко вынести и
предобработать сначала. То же самое, что мы делали в C-стандарте, когда мы сначала объявляем
переменные, а потом только с ними работаем. И дополнительно хотелось бы понять, как работает
conditional jump, потому что conditional jump это тоже веселье и нам нужно правильно выставить порядок этих
conditional jump. Итак, если мы с вами смотрите, посмотрим на вот этот код. Comparer dx 0, а дальше мы
говорим jump, если ответ да, то мы прыгаем в метку 7, а вывод если нет jump, то дальше должен сразу идти
false branch. Вот, то есть нам нужно каким-то образом наши jump правильно поставить. Дальше, значит,
если у нас есть какие-то колы, то мы должны прерываться с вами и мы должны тем самым
регламентировать порядок обхода нашего дерева. И вот смотрите, есть еще одна проблема. Представьте
себе, что у нас есть бинарная операция, а дальше идет call и call. У нас проблема в том, что нам
нужно сохранять регистры. То есть мы вызвали один call, нам нужно сохранить регистр сразу где-то,
и потом сразу вызовет второй call. То есть пока что этого нет. Хотелось бы от таких инструкций в
ER дереве отойти. Понятно, что call у нас возвращает expression, по идее нам нужно бы этот expression
сразу куда-то сохранить в памяти. То есть нам нужно решать будет вот такие вот проблемы.
Давайте сейчас поговорим следующее. О следующем, что образно говоря, каноническое ER дерево,
то есть дерево, которое в принципе уже можно каким-то образом представлять, работать с ним,
это дерево, в котором нет операции sec или esec. Мы должны избавиться от всех операций esec раз,
а все операции sec можно превратить просто в последовательский команд. То есть у нас
останется statement list. У нас получается код будет линейным. Потому что сейчас нам в ER никто не
запрещает делать нелинейный код. То есть у нас внутри sec много sec. И дальше смотрите, для того,
чтобы избавиться от бинарных вызовов, родителям каждого кола должен быть либо expression, либо
move tmp, то есть либо операция store. Потому что иначе у нас возникает проблема с вызовом инструкций.
Вот, давайте как раз решать эти проблемы. Проблемы, которые у нас есть. У нас могут
быть узлы, у которых имеется два ребенка кол, то есть тогда у нас есть проблема. Либо у нас есть
узлы с операцией esec и есть необходимость поднять секвенсы на самый верхний уровень.
Поехали решать. Значит, первое call. Вы не поверите. Так, давайте посмотрим на код. Что мы делаем? Вот
представьте, что у нас есть функция call, которая принимает на себе функцию и набор аргументов.
Тогда мы ее можем переписать вот в таком страшном виде. Я, блин, дайте я переводкну проектор. Я надеюсь,
что это поможет. Я в зоме пишу, если что. Я сделаю. Возможно, у меня проектор обладает
свойством антикоммунативности. Да, действительно, у меня проектор обладает свойством
антикоммунативности. А нет, обладает коммунативностью. Вот. Давайте разберем, что здесь же написано. Значит,
у нас есть функция call, которая вызывается некоторым аргументом. И что мы делаем в данном аспекте?
Давайте попытаемся понять, что здесь написано. Нет, у меня проектор обладает свойством коммунативности,
видимо. Что это означает? А? Ну, смотрите. Значит, мы пишем следующее, что у нас, значит,
T. Это call. F-args. И дальше что мы делаем? Возвращаем этот T. Да, то есть, как бы, мы получается
заранее операцию call, которая у нас есть, которая может быть сагрегирована с другим call. Мы сразу
ее оборачиваем в то, что, вот, выполни, пожалуйста, сохрани нам значение, пожалуйста, в определенном
регистре, а после этого верни этот регистр. Так, что у нас с оскобочным балансом? Да, да. Нет,
все нормально. Наоборот. Не, все нормально. То есть, вот такой хитрый вещь. Хитрая вещь. Но у нас
возникает проблема. Какая? У нас появляется новый e-sec. То есть, у нас появляется сайд-эффект.
Значит, нам нужно теперь каким-то образом взять вот этот e-sec, который есть, и от них избавиться.
Давайте как раз попробуем от них избавиться. И здесь начинается веселье. Значит, тут нам
нужно будет явно просто рисовать те команды, которые у нас есть. Первая операция заключается в
следующем. Представьте себе, да, сразу скажу, что если мы поднимем e-sec на самый верхний узел,
вот это важно, мы его можем превратить в операцию sequence. Значит, смотрите, представьте себе,
что у нас есть операция e-sec, здесь s1, здесь у нас s2 и expression. Но давайте подумаем,
что это означает. Это означает, что нам нужно сначала вычислить s1, после этого вычислить
s2, типа вот это наш сайд-эффект, а после этого вычислить e. Да, но мы в принципе можем в
сайд-эффекте последовательно вычислить s1 и s2, а после этого вернуть результат. То есть,
вот у нас сайд-эффект, а здесь мы последовательно вычисляем s1 и s2. Здесь нужно сказать следующее
вещь. Так, я тут применю для любителей формализмов и доказательств. Короче, будем упрощать эту
инструкцию, связанную с тем, что у нас будет метод спуска, так сказать, она противоположится
аналогу индукции, по количеству e-sec в нашем дереве, плюс суммарная высота этих e-sec. То есть,
здесь мы как количество e-sec уменьшили на 1, то есть, здесь было 2 e-sec, здесь был 1 e-sec. Да,
причем, если мы возьмем visitor, то это легко делается. То есть, мы просто проверяем,
что правый тип у нас e-sec, тогда мы переписываем правое под дерево налевое. Так, с этим разобрались?
Просто такая вот оптимизация. Так, дальше. Собственно, если у нас e-sec находится в какой-то
бинарной операции. Да, причем, смотрите, важно заключается в том, что как бы эта операция у нас
идет до нашего дерева. Значит, давайте рассмотрим аспекты. Значит, если у нас есть бинарная операция,
смотрите, здесь важно, что это первый оперант. Кстати, скажите, пожалуйста, как вы думаете,
почему важно, что в e-sec здесь пока рассматривается первый оперант и не второй?
Да, а теперь представьте, что у нас есть второй оперант, как бы он тоже создает сайд-эффект,
и, возможно, этот сайд-эффект повлияет на значение первого оператора.
Ну, e-sec говорит, да? Ну, то есть, сначала сайд-эффект, потом выражение. Вот, ну и смотрите,
главная суть такова, что если у нас есть какой-то сайд-эффект до выполнения либо унарных операторов,
либо операторов, которые есть бинарных, то в нем выражение состоит на первом месте.
Что у нас получается? Мы его можем просто вынести наверх. Логично? Да, то есть, как бы,
единственный момент нужно отслеживать. Типа, у нас эта операция какая? Типа,
можем ли мы ее сразу в sequence превратить или не можем сразу превратить в sequence? То есть,
если у нас на выходе expression, то, наверное, не можем. Если у нас какой-то statement,
то мы поднимаем наверх и переобразуем его в statement. Так, понятно? Все, хорошо. Что
делать со вторым оператором? А вот здесь уже приходится делать некоторые финты ушами,
да? Потому что нам нужно хранить результат нашего операнда. Представьте себе, что у нас
есть бинарная операция, дальше у нас есть operation, E1 и еще один E sec. Давайте это буду
рисовать, наверное, чтобы это было видно. Наверное, вот сюда. Я сразу приношу извинения всем тем,
у кого есть признаки эпилепсии, потому что я, честно, не знаю, из-за чего наш проектор
коррептить. Значит, смотрите, вот у нас здесь оперант и биноб, SE1. Вот у нас statement. То есть,
что у нас может быть? У нас statement может повлиять на значение выражения expression 1. Нам нужно от
этого избавиться. Ну как от этого можно избавиться? Давайте подумаем. Мы можем сохранить результат T в E1,
а после этого сделать операцию следующую. Мы вычисляем S, а после этого делаем бинарную
операцию, связанную с тем, что мы вызываем наш оператор T. То есть, то, что мы сохранили в
нашем промежуточном результате. То есть, нам так или иначе нужно какое-то промежуточное хранение.
Так, ну хорошо. Давайте подумаем, почему здесь у нас будет выполняться индукционный переход.
Вот это важно. Вот у нас вот это дерево, оно пишется вот так. То есть, смотрите,
мы сначала в T записываем E1, потом мы используем S, а после этого мы делаем биноб. Скажите,
пожалуйста, сколько ессеков у нас на самом деле здесь? Ну, кажется, что два. То есть,
тут было один, тут было два. Во-первых, давайте я спрошу, вот эта конструкция понятна? А теперь
смотрите трюк номер два. Мне кажется, мы это уже где-то умели делать. То есть, на самом деле,
вот тот вот ессек, который у нас есть вот здесь, на самом деле он уберется. Просто
последующий проход. То есть, мы это можем даже сделать in place. То есть, у нас, смотрите,
получается ессек поднялся на уровень вверх. То есть, у нас теперь наш дерево упрощается.
Вот, это значит следующее. А если у нас S не влияет на значение, то есть, смотрите, это если у нас S
влияло на значение выражения, нам надо сохранить в регистре. Если мы внезапно понимаем, что S никаким
образом не влияло на значение выражения E1, это в принципе можно сделать и посчитать. Ну, для этого
нужен life-анализ. Мы можем просто ессек поднять. Но на самом деле, если так внимательно подумать,
то можно вот это сразу не применять, а применять предыдущую операцию. Почему? Потому что мы
можем просто на следующей стадии оптимизации компилятора как раз убрать эти инструкции,
которые нам не нужны. Ну да, наша цель как раз сейчас, вот, у нас, короче, есть таракашка под
названием ессек. Нам надо эту таракашку убрать в как можно большем количестве. Кстати, если,
допустим, вам кажется, что это не очень полезная вещь, но это вообще тема связана с тем, что мы
убираем любые сайд-эффекты. То есть, образно говоря, если у нас надо что-то. Да, кстати,
в функциональном программировании это активно помогает. Так, ну и дальше тут есть некоторые
инструкции. Давайте подумаем, когда у нас S может не влиять на E1. Ну на самом деле, если E1 это
либо у нас константа, либо это название какой-то метки, либо S это эксп, а выражение в нем является
константом. То есть набор вариантов не очень большой, но в принципе его можно использовать. Так,
теперь смотрите, следующий момент заключается в том, что у нас ессек может находиться в экспрешен
листе для вызов аргументов. Ну тогда на самом деле все достаточно просто. Смотрите, здесь у нас
есть несколько вариантов. Собственно, зависит ли S от E1 или от E2, то есть влияет ли он на результаты.
Если не влияет, то мы просто сначала выполняем statement test, потом передаем аргументы. Если у
нас S влияет на E2, то нам нужно сохранить сначала все результаты во временную память, а потом
использовать темповые регистры. То есть у нас получается, что нужно T присвоить E1, T2 присвоить
E2, а потом уже вычислить значение, взять вот эти вот регистры, поднять их и как раз их передать
в аргументы. Вот, если допустим, ну в зависимости от того влияет аргумент или нет, у нас наша
инструкция будет либо больше, либо меньше. Вот, ну смотрите, поскольку у нас экспрешен лист
находится всегда сразу там в аргументах вызова функции, да, то есть у нас это все применяется
только в операции call, то мы как бы перед колом просто вставляем набор инструкций, которые у нас
есть. То есть у нас получается был кол, да, внутри него есть сек. Мы просто перед этим колом вставим
последствия операции и получаем наш результат. Да, значит, смотрите, утверждение, внутри есть сек,
не может стоять в левом ребенке есть сек. Ну понятно, потому что у нас, если бы у нас был какой-то
есть сек, а внутри него стоял есть сек, то это был бы экспрешен, а не statement. Есть сек это у нас
экспрешен. Почему мы это доказываем? Потому что мы утверждение, что мы разобрали все варианты в
нашем кейсе, потому что нам нужно сказать, что мы все утверждения перебрали, у нас количество
есть секов уменьшается и вывод после этого будет, точнее количество есть секов у нас не увеличивается,
а даже уменьшается. Вывод будет такой, что после всех оптимизаций у нас просто есть секов не
останется. Так, ну смотрите, здесь у нас все понятно. Дальше второй оператор заключается в том,
что если у нас родитель является есть секом, родитель есть сека экспорт, то это просто с. Да,
то есть мы просто вернули наш экспрешен, поэтому нам достаточно просто выполнить этот statement. Ну вот,
смотрите, значит, у нас есть сек в итоге останется ровно один, в конце концов он поднимется либо
до экспрешена, да, либо до какой-то нормальной операции. Вот, значит, и от него можно будет избавиться.
Все, есть секов у нас нет, мы их победили. Хорошо, так, этот сценарий понятен? Все, хорошо,
то есть такая... И вторая вещь, это линеризация. Собственно, заключается в том, что если у вас
внезапно sequence остался в какой-то левой части выражения, вдруг при построении яра, хотя такое
скорее всего не будет, то вы можете ее перенести в правую часть, то есть переподвешиваем в левую часть
направо. Вот, ну после этого все секвенсы можно будет убрать, вот, и у нас просто появится упорядоченный
набор команд. Вот эта стадия называется линеризация, дерево яра. То есть теперь у нас как раз с вами
есть линейный операнда, и это хорошо. Значит, и последняя вещь, которая заключается в том,
что если, допустим, нам нужно будет поставить правильный порядок операции, то, в принципе,
мы это тоже можем сделать. Да, если нам, допустим, не нужен jump в каком-то месте, то, в принципе,
вот такая вот инструкция есть. То есть переставим, можно всегда переставлять true метки и false метки
местами, потому что они как раз у нас не зависит друг с другом. Вот, и мы с вами после этого приходим
к вот такой вот вещи. Эта абстракция называется basic block. И не поверите, она как раз есть во всех
иарах. Даже, более того, скажу, если мы посмотрим LWM-овский иар, то там как раз используются активно
basic block. То есть мы прямо на предыдущем семинаре смотрели, как они создаются. Вот basic block create,
то есть у него есть... Что такое basic block? Значит, в чем она заключается? У нас с вами первая инструкция
всегда label. Последняя инструкция... Тут я, кстати, неверно писал, тут надо уточнить. Это либо jump,
либо conditional jump, либо... либо return, либо exit. Да, потому что у нас из функции можно вернуть
значение какое-то, либо просто завершить код нашему. Вот, и между первой и последней инструкцией нет
ни label, ни jump, ни cjump. Собственно, если внезапно у нас нет jump, то добавляем jump в следующую
метку. То есть если у нас, смотрите, оказалось следующее, что у нас есть, допустим, L1, L2, и здесь
ничего внезапно не было, да, ни jump, ни cjump, то мы просто делаем jump на метку L2.
Вот. Вот. И если у нас есть последняя метка, jump add down. Ну, собственно, мы создаем метку down,
либо мы делаем return инструкцию. В этом случае она работает. Вот. И в чем особенность именно
basic block или базовых блоков? А то, что поскольку у нас любое начало это метка, а любой конец это
прыжок в какую-то метку, то мы можем эти блоки менять местами в любом порядке. Вот. И это как раз полезно.
Так. Так, ребят, я сейчас на секунду буквально... Так, продолжаем, да, пришлось мне отличиться на
некоторое время. В общем, смотрите, что у нас такое basic block? Это у нас как раз инструкция, такой блок,
который мы самостоятельно можем переставлять в разные места для того, чтобы каждым блоком
оперировать независимо друг от друга. Итак, но на самом деле, когда мы будем транслировать все в
Assembler, тут небольшое забегание наперед, нам, опять же, эти инструкции нужно будет линеризовать в
каком-то определенном виде. Итак, еще у нас один небольшой перерыв. Значит, смотрите, у нас блоки
могут идти в случайном порядке, поэтому мы можем их использовать как отдельные единицы в графе
исполнения. Но все равно, когда вы читаете код на Assembler, он у нас плюс-минус тоже линейный. И важно,
что там jump обычно не в две метки происходит, а в одну метку. Вот. Поэтому нам нужно будет код объединить
снова. И как раз наша цель будет сделать такой код на Assembler с минимальным количеством швов. То есть
что значит швов? Швов это значит, что мы берем и делаем некоторый jump. Вот. И как раз для этого мы
можем сделать следующее. Организовать след. И это по сути блоков, которые соединены в виде цепочки.
Соответственно, если у нас есть какой-то jump, то мы как раз летаем с этой цепочки. Ну, тут я
хочу сказать следующее. У вас, наверное, не было курса по сложности вычислений, но... а? Есть. Был. Был.
Значит, для того, чтобы решить эту задачу оптимально и создать минимальное количество блоков, нужно
решить задачу coverset. Покрытие множества путями. Но эта задача НП полная. Так что... а? Ну, значит,
мы будем скорее всего использовать какой-нибудь а-ля жадный алгоритм с некоторыми небольшими
оптимизациями. Вот. Для того, чтобы построить блоки. Так. Значит, на самом деле, как строятся следы?
Значит, пока не все вершины покрыты, достаем вершину, идем по графу выполнения, доставляя
элементы в цепь. Для conditional jump преимущественно используем false ветку, потому что после false
ветки зачастую нету переходов. То есть мы сразу двигаемся дальше. Вот. То есть это такая простая
вещь. Значит, превращение AC jump в label от false. То есть, смотрите, если у нас был conditional jump в ветку
label true, label false, то мы можем с вами сделать следующее. Менять true и false местами, и все будет
замечательно. Ну, вот это приблизительно выглядит вот так. То есть, у нас есть какой-то conditional,
A, B. Дальше у нас label true. После этого, если у нас есть jump в X, то мы переставляем как раз,
ставим метку X, и после этого делаем jump в ветку с названием false. То есть это то, как мы переставляем
conditional jump в ветку false. Так. Ну и наконец-таки, мы с вами наконец-таки уже избавились от всех
блоков. Кстати, сразу скажу, что построение следов, трейсов идет после оптимизации. И наши
требования для оптимизации. Значит, давайте подумаем, что нам нужно потребовать от оптимизации.
Да. Да. Собственно, во-первых, безопасность. То есть, результат не должен меняться. Выгодность.
Это было бы неплохо, чтобы количество операций у нас все-таки уменьшилось. Ну да, мы можем память
уменьшать, можем увеличивать производительность. И третье, это взятие рисков. То есть, возможно,
что у нас увеличится число регистров, и после этого у нас будет регистр spilling. То есть,
мы скидываем их в оперативную память. Кстати, забавный момент. Рублика оптимизация. Знаете ли
вы следующий момент? Это небольшая отсылка к курсе по куде. Вы берете видеокарту, значит,
1080, запускаете на ней код. Какой это? X. Потом берете видеокарту, 3090, запускаете на ней тот же
самый код X. Ну, обычно это, кстати, к нейросетям относится. На 3090, понятно, нейросет работает
быстро. В сравнении с 1080. Код ровно такой же. Ну, как вы думаете, что происходит с потреблением памяти?
Ну, то есть, представьте себе, образно говоря, на 1080 у вас один гигабайт в рам съелся. Как вы
думаете, сколько в рам будет есть 3090 на той же самой сети? Больше. Там как раз больше процентов на
30, на 40 будет оно. Ну, за счет того, что как раз по факту микропроцессор видеокарты раскладывает
это все так, как ему надо, в памяти. За счет этого количество памяти увеличивается. Да-да-да-да. Да-да-да,
такие. Ага. Да-да-да, то есть, вот такая вот хитрая вещь, и ее нужно просто учитывать,
что за оптимизация Gnatsa можно количество оперативной памяти увеличить используемой. Так, ну,
давайте поговорим, какие у нас есть возможности для оптимизации. Первое, это уменьшение оверхеда
на имеющиеся абстракции, которые у нас есть. Значит, использование преимущества в специальных
случаях. Это, знаете, такая кейс, это статистический анализ данных. То есть, вы просто берете
какую-нибудь кодовую базу, скачиваете откуда-нибудь, с какого-нибудь GitHub. Ну, или еще... Ну, не, на самом
деле, есть, кстати, статья, я, кстати, когда готовился к оптимизации, статья, октября 23-го
года, использование LLM для оптимизации компиляторов. LLM — это большая языковая модель или отчет
ГПТ. Ну, почти, да.
Ну, да, да, то есть,
ну да, на самом деле, история такая, что, по идее, мы можем прогнать количество переходов условных,
замерить какой-то статистический анализ и дальше, как говорится, формула условного вероятности нам
в помощь, грубо говоря. Бывает такое, что в большом количестве инструкций у нас, грубо говоря,
мы обычно ожидаем, что в 60% случаев, ну, типа, мы думаем, что мы чаще после EFA прыгаем в ветку
связанную с true, да, или нет условия, да, либо там не false return. Да, ну, понятно, что, собственно,
если мы имеем просто, грубо говоря, матрицу вероятностных переходов, то мы можем действовать,
как, образно говоря, шахматисты и сами устанавливать порядок операции, который мы хотим.
Ну, да.
Ну да, это динамическая оптимизация. Кстати, более того, если так говорить не чисто про компилятор,
а вдруг кто-то внезапно зашел на этот ролик и вообще интересуется сетями, нейросетями, да, то на самом
деле, эта же идея есть и в нейросетях. Называется динамическая квантизация, то есть, когда нужно
уменьшить размер нейросети, вот, просто прогоняется, грубо говоря, большой сет, замеряется, в каких
диапазонах у нас есть веса моделей, ну, типа, максимальные значения, которые выходят в тензоры,
и под них как раз производится оптимизация. В итоге нейросети весят меньше. Ну, и здесь тоже, как бы,
мы прогоняем статистику, понимаем, по каким блокам мы чаще всего переходим или прыгаем, ну, собственно,
мы это можем сделать. Вот, ну, и последняя вещь — это связь между кодом и системными ресурсами. То
есть, в принципе, если даже сами компиляторы позволяют компилироваться под определенный набор
инструкций, такие как SSE, AVX и так далее. То есть, про них тоже не стоит забывать. Включать
векторную инструкцию. Итак, значит, что касается уровня локальности оптимизации, их обычно выделяют
четыре. Значит, первый уровень — это локальные оптимизации, они происходят внутри одного basic
блока. Дальше у нас есть региональные оптимизации, то есть, у нас по факту оптимизация идет на уровне
набора блоков, которые лежат, так сказать, в одном регионе относительно структурной операции. То
есть, это, грубо говоря, внутри FA, внутри Вайла и так далее. Потому что там как раз тоже есть
некоторое количество блоков, хотелось бы их тоже их разбирать. Глобальная оптимизация — это оптимизация
не всего кода, важно. Это оптимизация внутри процедуры, то есть внутри функции. И у нас
могут быть межпроцедурные оптимизации. Это оптимизация между процедурами. Да, есть еще
великая link time оптимизация. Ну, я не знаю, рассмотрим или нет. Собственно, давайте вопрос.
Inlining к какому уровню относится? Да, это межпроцедурная оптимизация. То есть, по-моему, в каких-то
компиляторах, кстати, в той же самой куде, по-моему, поддерживается Fragma Forum Sandline.
Да, да, да. То есть, как раз использовать inline, то есть, постановку аргументов. Значит, смотрите,
локальные оптимизации на самом деле достигаются за счет перестановок внутри одного блока. То есть,
блок — это как раз посредство инструкции, которое начинается одной меткой и заканчивается либо
условно, либо безусловным переходом. Вот. И, значит, какие бывают виды локальных оптимизаций? Тут
надо опять же сказать, почему это важно про локальные оптимизации. Потому что, как ни странно,
у нас, если внимательно посмотреть на наши инструкции, которые у нас есть в компьютере,
вот у нас есть обычно наш ассемлерные вставки. Но перед тем, как наш компилятор, наш код будет
исполняться, на самом деле ассемлерный код перегоняется в код микропроцессора. Вот. И нужно
понимать, что в микропроцессоре есть конвейерность, возможно, есть параллельные исполнения инструкции,
и так далее. Да, поэтому, возможно, ему стоит помочь в этом деле. И если у нас есть некоторый набор
регистров, которые могут считаться параллельно, как бы лучше это так и написать. Вот. Поэтому здесь
еще одна из оптимизаций заключается в том, что у нас возникает перебалансировка дерева. То есть,
опять же, у нас был sequence, мы его снова перегоняем в дерево и начинаем его балансировать. Да.
Значит, первый алгоритм, который здесь есть, я пока что начну с самого сложного алгоритма и потом
перейдем к более простым алгоритмам. Первый алгоритм называется local value numbering. Он на самом
деле как раз помогает найти разные сложные вещи, так сказать. Да, вот. Да, ты, Михаил.
Что, что, что? А, поэтому? Ну, господи. Понятно, у вас уже прямо курс по оптимизации, так сказать.
Господи. О, господи, бедная. Ладно. Давайте все-таки тему разберем. Значит, смотрите,
просмотрим следующий последствий с операцией. А стрелочка B плюс C, B стрелочка A минус D,
C стрелочка B плюс C, D стрелочка A минус D. Вопрос. Как это можно оптимизировать?
Нельзя. Ну да, D можно заменить на B. Да, потому что почему, кстати, C нельзя заменить на A? Да,
потому что B меняется. Да, соответственно, нам нужно это уметь считать каким-то образом. Ну и здесь
как раз веникает следующее, что для каждого набора переменных, ну или виртуальных регистров нам
нужно запоминать, когда у них все было установлено в определенном порядке. Так, кстати,
сразу скажу про ER. В этом случае с ER действует намного проще, потому что у нас там есть SSA,
статик Single Assignment, и вот там как раз на ленту этого не надо делать и вычислять. То есть сразу
понимаем, что оптимизация на уровне AST, возможно, это не очень хорошая затея. Все-таки лучше приводить
это все к дереву ER. Значит, это можно оптимизировать вот таким образом. И алгоритм. Да, тут я сейчас его
написал вот таким образом. Цель для каждой переменной виртуального регистров присвоить порядковый
номер версии этого виртуального регистров. Ну и цель дальше следующая. Нам нужно будет завести
хк таблицу с ключами вида операции EOPG, то есть, грубо говоря, переменная с историческим номером E
будет взаимодействовать с историческим оператором G. Значит, если у нас новая операция, собственно,
если у нас операция была, то мы ставим над результатом просто значение из хк таблицы, иначе мы
добавляем в нашу хк таблицу новый ключ. То есть, если у нас есть, допустим, третья версия плюс сложить
четвертую версию, то мы просто берем вот эту четвертую версию и вот эту ключ к таблице заменяем на то
значение, которое мы записывали. Так, давайте я покажу алгоритм. Собственно, вот, новой версии добавляется
хк. Вот представьте себе, вот у нас есть нумерация в правой верхней части слайда, у нас есть переменная
B, которая имеет нулевой версию, и переменная C, которая имеет нулевой версию. Значит, когда мы записываем
значение A, мы записываем вторую версию. После этого мы берем B, это A2-D3, то есть у нас появится
3D равное тройке, мы ее записываем. Получаем на выходе B4. Дальше у нас будет C5, это B4 плюс C1.
Не хватит видео, чтобы я это рассказывал. Вот у нас получается C5, а дальше смотрите,
следующее, что у нас происходит. Мы достаем значение A, это двойка, и достаем значение D,
это тройка. То есть, мы для каждой переменной храним номер версии, когда она была задействована в
последний раз. Вот, поставили 3, и смотрите, что у нас происходит. У нас есть A2-D3, то есть мы можем
как раз в хэштаблице заставить уже значение 2, 3 и минус, и понять, что это на самом деле B4,
поэтому здесь значение будет, во-первых, B, а во-вторых, результат будет иметь тот же самый номер
версии, то есть у нас по факту B и D будут разыменовывать один и тот же указатель. Точнее, не то,
что они будут разыменовывать один и тот же указатель, мы просто будем использовать одно и
тоже номер версии. Вот, это вот как раз алгоритм local value numbering. Контрольного мы по нему писать не
будем. Можно попробовать его просто использовать для своих задач. Так, понятна суть алгоритма? Хорошо,
значит, вторая вещь, которая совсем простая. Мы, значит, в local value numbering можем считать
следующее, что если операция является операцией с нейтральным элементом группы, все знают,
что такое группа. Ну да. Вот, то, в принципе, вот она табличка, которая здесь есть. Собственно,
коммутативная операция, кстати, про коммутативность операции, коммутативные операции тоже должны
видеть одинаковый хэш. Ну, логично. То есть, смена операции нам должна быть точно так же. То есть,
можно считать, что у коммутативных операций регистр с меньшим индексом идет раньше. Ну, в общем,
здесь несколько наборов инструкций, которые у нас есть. Значит, проблемы алгоритмов, которые у нас
есть, нужно аккуратно отлавливать, изменилось ли значение после замены. То есть, как бы здесь у
нас должен устанавливаться новый номер версии. Потому что иначе у нас алгоритм может пойти куда-то
не туда. То есть, когда обращаемся к значению переменной А, здесь это тройка, а когда обращаемся
А, здесь это четверка. Вот. И нужно, конечно же, аккуратно смотреть на неявные присвоения. То есть,
это всякие указатели, элементы массива и так далее. А то иначе возникнет проблема в том, что вы
объявляете, грубо говоря, в питоне. Какой там есть пример в питоне? Что-то вот такое можно написать.
А равно 0 умножить на 5. А давайте-ка, кстати, это. Может быть, возьмем, что-нибудь напишем.
Так, Python 3, да. Так? А, ненастроенные, да. Так. Да. А, они уже работают. В общем,
тут есть какие-то подводные камни, в которых... А, ну так имеется в виду?
О, да, да, да.
Да. Ну, то есть, он понял, что это не примитивный тип, он взял, просто указатель расплодил.
Ну, потому что... Ну, потому что int – это обертка над p-object.
Да, в питоне все объект, в том числе int, load и все такое. А int передается, на самом деле, по ссылке, просто, когда ты меняешь значение, ты его копируешь и потом меняешь. Ну, да.
А они создаются новую копию при изменении. Более того, я скажу следующее. Есть такая интересная, такой интересный язык, R называется. Наверное... А?
Да. Во третью. R, да. R. И там есть два оператора. Второй mutable. А? Да, а первый присваивание.
То есть, там явно есть mutable и mutable объекта. Вот. Ну, раз мы уже немножко отошли в сторону, как у нас обращение к полям класса обычно в любых языках программирования?
Ага. Значит, не поверите, в R настолько продвинутый язык, что это переменная. Да, да. Это как подчеркивание в других языках программирования.
А чтобы обратиться к полям, тут есть специальный символ доллар.
Да, более того, R, если говорить про язык, он вообще веселый.
Он заключается в том, что, вы не поверите, для интерпретатора он интерпретируемый, но если вы попытаетесь импортировать какой-то другой пакет и с ним работать...
Ну да, ну нет, типа вы подключаете какую-то внешнюю библиотеку. То есть, что в питоне удобен? Вы импортируете библиотеку, потом можете поменять код, образно говоря.
Зайти прям в код своей библиотеки, поменять что-то, там, допустим, прогресс-бар включить и запустить новую версию, у вас прогресс-бар будет работать.
В Ари не так. В Ари внешние модули, они компилируемые. То есть, вы, когда устанавливаете пакет, он у вас его компилирует.
Фитон, он, типа, тоже прикомпилирует, просто отслеживает, что если файл заменялся на декабилизатор.
Ну да. Не-не-не, а можно прямо, когда точка py-файл меняю, мы даже можем не переустанавливать пакет.
Когда точка py-файл импортите, он составляет файл.pyc, который не удаляет после окончания работы, чтобы в следующий раз переиспользовать.
А если файл.pyc поменялся, то он удаляет файл.pyc, она его компилирует и использует.
Кстати, вопрос тебе надо сыграть тогда. У вас есть программа, которая запускает сама себя, когда эта прошивка будет в питошке?
Ну, ты это рассказывал. Она отслеживает передатки самой себя и дает репуршен юроризм.
Ну да.
Ну нормально.
Вот как бы видно, что у нас, как говорится, нужно быть с указателями очень корректно и отслеживать явные изменения, в том числе и в исходном коде.
Так, это что касается local value numbering. А если у нас есть вот такое вот линейризованное дерево, то было бы неплохо использовать его в нормальную версию, не сбалансированную версию.
То есть как бы у нас, если дерево 8 операций, хотелось бы, чтобы оно выполнялось в 3 глубины, в 3 тактах.
Есть некоторые проблемы, потому что ладно-то одно дерево операции, а что будет, если у нас есть операция, которая должна находиться в разных узлах дерева?
То есть у нас есть узел 1, есть узел 2, они используют одну и ту же операцию.
Поэтому нам нужно каким-то более грамотным образом это все переподвешивать.
Более того, local value numbering умеет работать перед балансировкой.
И знаете, здесь вот, я не знаю, вы наверное чуть помоложе, чем я, но, не знаю, застали, это отсылка к определенному мему.
Значит, сколько деревьев вы видите на рисунке?
Знаете, были передачи где-то лет 10-15 назад по телевизору, где деньги предлагали.
Да, вот здесь точно так же. Сколько здесь?
Ну, как-то хочется спросить, что такое дерево в случае 1,2 грамма?
Скорость у нас вот так.
У нас три вершины, смотрите, вот так.
Вот так вот, три вершины, вот так вот.
Существуют вершины, из которых достижимы остальные?
Не, не весь граф.
Но главное, что здесь у дерева должны быть дочерние узлы, хотя бы один дочерний узел у корня.
Четыре здесь дерева.
С корнем Y, с корнем Z, корень T1 и корень T2.
Поэтому эту структуру нужно каким-то образом правильно расшифровывать.
Видно, что у нас здесь операции, они каким-то образом должны быть еще и подвешены грамотным образом.
Собственно, для этого нам нужно найти корни дерева, которые перевешивать так по факту нельзя.
У нас должна быть завязка на корень.
И мы говорим следующее, что у нас корень дерева, значит, если наш узел может быть корнем дерева,
если он как минимум два раза используется как определенный ребенок.
То есть вот этот узел T1 у нас используется два раза.
И второе, если T1 используется как ребенок еще в какой-то другой операции.
И с разным набором оперантов.
То есть у нас получается, что этот узел используется в разном наборе операций.
Это описание алгоритма.
По факту, смотрите, вот у нас есть дерево, у нас есть вот такой набор операций.
Да, это до сих пор мы находимся с вами в Basic блоке.
И вот мы нарисовали вот это дерево.
И здесь видно, что T3, T7 получается.
Да, T6 и T10 это корни нашего дерева.
То есть T11 и T10 это просто переменные, которые у нас требуют результат работы функции.
Это life variable на выходе.
И T3, оно у нас используется в двух местах.
Как выход T11 с операцией плюс и выход T10 с операцией умножить.
И дополнительно, что у нас, и T6 у нас просто сам тоже корень дерева.
То есть у нас есть переменные, так называемые life out.
То есть те переменные, которые у нас выходят из нашего Basic блок.
И используются в других Basic блоках.
Да, кстати, к вопросу о том, что при помощи этой штуки можно еще и находить dead code.
Elimination, если мы построим дерево, то, в принципе, если у нас T6 нигде не используется дальше,
то мы просто можем некоторое под дерево просто прибить.
И следующая его операция.
Вот такой вот код. Мы находим в нем деревья.
А дальше нам нужно делать именно перебалансировку.
То есть по факту мы перебалансировать, у нас же Zoom есть.
Знаете, какая главная фишка Zoom?
Что здесь можно рисовать.
Вот он dead code. Вот у нас одно дерево.
Дальше у нас есть второе дерево.
Вот оно.
Ну и остальные тут уже по мелочи.
Вот как раз вот эти деревья нам нужно перебалансировать.
Получаются, ну, самые такие нелинейные деревья.
Это деревья T11 и T3.
И давайте посмотрим, как они у нас с вами будут работать.
Ну, это да.
Ну, это зависит от архитектуры процессора.
Ну да, да, да.
Есть такое. Так, это алгоритм нахождения корней дерева.
Там можно поставить на паузу, почитать.
Вот я думаю, что это числа нет.
Значит, смотрите. А дальше делается следующее.
Корни дерева мы находим.
Причем для каждого корня дерева мы дополнительно записываем
еще следующую вещь.
То есть какое количество оперантов у нас есть.
И, собственно, дальше мы говорим следующее,
что давайте, значит, каждый узел, который у нас есть,
посмотрим просто, в каком порядке у нас идут они.
То есть, грубо говоря, делаем некоторый порядок.
То есть как бы получается, что, вот смотрите внимательно,
корни дерева T11-T1, то есть как бы оно под себе
не хранит никаких других детей, именно виртуальных.
Значит, T получается 7.
Это тоже один, он не использует.
А вот T10, он использует двух детей.
Поэтому мы его должны обработать в последнюю очередь.
Вот. И дальше делается следующее.
На самом деле для всех операций смотрим количество зависимости,
которое есть. Смотрите.
И здесь оказывается, что если их правильно добавлять в очередь,
то константы у нас отправятся в самое начало.
То есть у нас тут еще и получается constant folding.
То есть у нас есть 13, у нас есть 4.
Собственно, внутри этого дерева мы видим, что они находятся в одном блоке,
мы начинаем их разбирать, и оказывается, что опа,
типа мы с вами можем получить наш корректный результат.
То есть как бы тут еще и считается количество оперантов,
которые нам нужно задействовать.
И в итоге, значит, если внимательно провернуть этот алгоритм,
то вот у нас было вот такое вот дерево,
а в итоге оно может получиться вот таким.
То есть как бы дерево получается более приятным.
И операция T7, кстати, смотрите, куда у нас переехал T7.
Он у нас переехал вот сюда, потому что на самом деле,
если посмотреть T7, а T7 у нас был здесь,
T3 у нас теперь становится сюда, а T6 у нас находится здесь.
То есть небольшая перебалансировка дерева произошла.
То есть, в принципе, при желании, знаете, что?
За какое количество тактов у нас все посчитается?
Вот в таком коде.
Если все идеально.
Вот в правом дереве.
Знаете, я даже его увеличу.
Сколько тактов нужно посчитать, чтобы посчитать все эти значения?
Ну это да, я согласен.
Но если бы у нас были все одинаковые операции?
Получается 1, 2, 3, то есть T6 это 3.
Возможно, кстати, его параллельно куда-то можно вставить.
4, 5, 6.
То есть где-то там 6-7 операций у нас по сравнению с исходным кодом.
В исходном коде у нас было большое количество операций.
То есть как бы вот у нас есть конвейер, который мы с вами делаем.
То есть, в принципе, можно использовать это для
совершения своих собственных задач.
Ну и, собственно, здесь еще есть некоторый набор оптимизации.
Давайте так, спрошу, идея алгоритма ясна?
Да, то есть главное аккуратно находить кор.
Значит, дальше копия propagation тоже идея такая очень простая,
что если у вас есть присваивание какой-то переменной,
то и local value numbering это отслеживает,
то, в принципе, мы можем прокинуть эти переменные дальше.
Да, и есть вот такая вот вещь еще называется dead code elimination.
То есть, в принципе, мы можем найти те инструкции, которые нам не нужны.
Значит, я как раз тут взял некоторый пример,
который показывает, что вот у нас есть код на джаве, аля код на джаве.
И мы пытаемся как раз его, вот это у нас не очищенный яр, который есть.
И мы пытаемся как раз создать объект.
Tx равно new object.
Потом получается, вытаскиваем параметр 4, присваиваем значение.
В общем, видно, что здесь очень много лишнего кода.
И хотелось бы понять, используется переменная в дальнейшем или нет.
И вот оказывается, что переменная Tx в дальнейшем-то не используется,
потому что она прямо записывается в виртуальный регистр,
и дальше мы работаем с виртуальным регистром.
Поэтому нам нужно посмотреть, какие переменные у нас являются живыми.
Да, для этого как раз мы, наверное, в будущем будем,
когда мы будем говорить про live analysis, мы будем считать именно,
какие переменные живы и какие переменные не живы.
Нам это называется уравнение потока графов.
Control flow...
Да, data flow, да.
И в принципе, если посмотреть на этот код, то после применения
dot-code elimination у нас вот так вот он меняется у нас.
Так, это что касается локальных оптимизаций.
Скажите, понятно ли?
Ну да, в целом можно сделать.
Значит, теперь следующие оптимизации.
Переходим на уровень выше. Это региональные оптимизации.
Значит, первое super local value numbering.
То есть мы можем то же самое применять,
только еще нумеровать не только наши переменные,
но и операции между basic блоками.
Ну и вторая достаточно частая региональная оптимизация
это loop unrolling.
То есть если у нас есть какой-то цикл, то почему бы его руками не развернуть?
Значит, собственно, что делает региональная перенумерация?
Суть алгоритма будет обойти в DFS всем по расширенным блокам
и говорить следующее, что если у нас с вами есть какой-то набор блоков,
то нам как раз нужно провести эти манипуляции.
То есть важно именно здесь посмотреть, какие из них образуют дерево,
которые не являются зависимыми от двух ребенков.
И вот если посмотреть на количество блоков, которые у нас есть,
поток графов управления, то оказывается, что у нас есть переменные B0,
B1, B2, B3, B4, которые объединяются в одно дерево.
После этого к нему в дочерний узел спускается B5, и в конце у нас используется B6.
То есть в принципе мы можем как раз взять, применить local value numbering B0,
потом для B1, и добавить наш узел после этого.
То есть как раз идет оптимизация по определенному пути.
То есть как бы мы параллельно берем наш путь,
и внутри DFS как раз сохраняем наборы переменных по зависимости.
То есть получается, что у нас типа нумерация для B4 будет так после той,
которая у нас идет по B2.
А поскольку B3 и B4 между собой независимы,
то как бы у нас будет нумерация для B4 после того,
поскольку B3 и B4 между собой независимы,
то как бы мы их не оптимизируем.
То есть у нас получается как раз супер блок B0, B2, B4.
Это что касается оригинальной переноминации.
Если мы говорим про loop unrolling,
ну здесь на самом деле все просто.
Если мы можем посчитать значение нашей константы заранее
до того, как у нас есть какой-то код,
то мы в принципе можем как раз вместо одной инструкции цикла
поставить большое количество инструкций нашего цикла.
Более того, некоторые опции компиляции поддерживают прямо loop unrolling.
Я правда не знаю, есть ли в классическом C++ с прогом unroll?
Там по числу компиляторов какие-нибудь константы у циклы loop unrolling.
Но у них есть еще опция, типа aggresive loop unrolling.
Не, просто в той же самой куде, в компиляторе,
прямо есть прогма unroll.
Форсировать unroll?
Да, форсировать unroll.
Ну да, это некритично,
но иногда циклы не unroll-ятся напрямую.
Да, кстати, у меня кейс был как раз,
писал какой-то криптографический алгоритм,
и оказалось, что там типа for int i равно нулю
и имеет 16++i было в одном месте.
Работало, значит, со скоростью 5 мегабайт в секунду.
Перегоняло данные.
Первая оптимизация была, это просто 16 раз copy-paste этот цикл.
Работало не в 16 раз быстрее, но близко к тому.
Ну вот, поэтому с этим нужно быть аккуратнее
и смотреть, как это можно делать.
Значит, дальше поехали глобальные оптимизации.
Значит, это инструкция между блоками.
На следующих лекциях будем смотреть уравнение потока.
В общем, здесь тоже нужно отсеживать.
Или мы можем использовать профилировщик для построения следов,
как раз про тот статистический анализ, который я говорил.
То есть мы пропускаем, грубо говоря, профилировщик,
забираем время работы, понимаем, что что-то не так, перестраиваем его.
Ну и, наверное, это все на сегодня.
Собственно, мы что поняли?
Мы с вами сегодня построили каноническое арт-дерево,
научились понимать, что у нас есть basic блоки,
научились разбивать инструкции на блоки
и что из себя представляет оптимизация в целом.
Сейчас мы, наверное, побежим сразу дальше, чтобы...
Ну, на следующих лекциях побежим сразу дальше.
Это что будет означать?
Это будет означать, что мы перейдем сразу к low-level кодингу
и начнем рассматривать instruction-selection алгоритм.
То есть каким образом мы можем собирать наш построенный AR
с оптимизированной под определенные инструкции ассеблера.
Сразу скажу, что мы возьмем тоже определенный конкретный пример ассеблера
и его рассмотрим.
Здесь уже будет важна особенность архитектуры.
Потому что вы не поверите, компилятор на ARM написать в разы проще,
чем back-end на ARM написать намного проще, чем back-end на x86 архитектуре.
На x86 архитектуре.
А?
На x86 архитектуре.
Она имеет две инструкции того же типа.
Угу.
Ну, у ARM есть свои.
В этом плане.
То есть он есть.
А он, конечно, глобально удобный, но...
Ну да.
Нажимать его тоже.
Можно компилить его в бего-сендре.
Можно?
У ARM...
У них сатамарка все спеша, не все лечит.
Когда тебе надо такие...
Ну да.
Компилиатуры, в целом, расставлять...
Ну да, да.
Так.
На этом все тогда.
До следующего раза.
А на семинаре мы продолжим, так сказать,
рассматривать LVM YAR.
Если успеем сегодня, то посмотрим все-таки,
как таблица символов делается.
Так что жду.
