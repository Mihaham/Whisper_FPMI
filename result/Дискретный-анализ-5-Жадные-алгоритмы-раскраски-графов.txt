я еще напомню обозначение вот это у нас вот это у нас омега и вот это у нас айфа так чтобы уж
точно у всех в головах сидела вот но я говорил о том что если мы хотим посчитать для каких-то
больших графов то это задача неподъемная есть замечательный многостаночник в нашей фпм и
которого зовут даниил владимир мусатов он только что передо мной читал о ктч скоро я конечно возьму
от него эту эстафету вот но он же потом от меня примет эстафету и начнет читать сложность
вычислений и вы узнаете что такое пнп почему действительно вот эти задачи являются трудными
об этом пойдет речь свой час я как бы предвосхищу этот вопрос и скажу ну конечно на произвольном
графе не посчитать наверное есть какие-то конкретные примеры графов на которых посчитать
удается вот помните например граф друзья я хочу чтобы был максимальный контакт да помните
например граф который мы в прошлый раз использовали в качестве иллюстрации там были векторы с тремя
единицами и он минус тремя нулями было ну было что такое что такое было вы же помните что для
него альфа мы посчитали просто вот посчитать мы ее знаю но то есть бывают конечно классы графов
на которых что-то можно явно посчитать я сейчас не об этом я вообще плавно перехожу в тематике
случайных графа и мы довольно долго будем в ней ковыряться и с этих точек зрения источки зрения
каких-то других характеристик графа ну вот пафос того о чем я буду говорить что если взять
случайный граф то на нем эти характеристики быстро считаются даже с помощью жадного алгоритма
то есть банальный жадный алгоритм который многие из вас представляют на себе какое
можно было бы запустить оказывается на удивление хорошего но давайте я про это сейчас и буду
рассказывать что такое жадный алгоритм как я сегодня его буду понимать а вот интересно
поднимите руки кто по крайней мере догадывается по своему мнению что такое жадный алгоритм в этом
контексте вы проходили какие жадные алгоритмы что-то не очень много рук это удивительно чем
вот в этом фланге много а в том почти нет это к вопросу о том что не все случайно в этом мире да
ну хорошо значит можно конечно разные вещи понимать поджатным алгоритмом давайте наверное
сделаем жадный алгоритм раскраски вот у нас есть граф с множеством вершин и множеством рёбер
давайте считать что вершины это просто конкретные числа 1 2 и так далее n вот это множество вершин
мы будем считать зафиксированным временно но потом конечно мы будем устремлять бесконечности
чтобы получить нужные нам результат так чего нам нужно ну давайте хеатше например что такое
жадный алгоритм вот эту единицу красим в первый цвет я нарисовал стрелочку это значит вершину с
номером 1 я покрасил цвет с номером 1 дальше я перехожу к вершине с номером 2 и если она
соединена ребром с вершиной с номером 1 то я вынужден присвоить и второй цвет но это если она
соединена вот так а если нет этой связи я оставлю первый цвет ну то есть я и ту вершину крашу
цвет с минимальным номером если ну если такой цвет существует которому эта покраска не
противоречит с минимальным номером у их как бы это сказать цвет с минимальным номером который
не противоречит правилам раскраски давайте так драмат автомат который не противоречит
правилам раскраски то есть вот верши Loy officials с этим номером цвета куда бы шли ребра из
очередной этой вершины и не был не противоречит правилам раскраски не но это совершенно
ожидаем просто видите я специально просил поднять руки как тот не все это понимали
Ну, если мы не можем этого сделать, тогда мы её красим
в очередной новый цвет.
Ну, давайте я это тоже напишу, если не можем, то все цвета,
которые уже были использованы, противоречит правилам.
Если не можем, тогда новый цвет используем.
Тут надо очень чётко договориться, иначе мы потом теоремы
не докажем.
Так, друзья, ну всем понятно, жадный алгоритм очень простой.
И понимаешь, в чём он жадный, да?
Ну ладно.
Так, это жадный алгоритм раскраски, но вообще говоря,
из него сразу можно и альфу как-нибудь оценить, например.
Как оценить альфу, имея такой алгоритм?
Ну просто надо выбрать среди полученных цветов цвет
самой большой мощности.
Можно я это писать, не буду.
Среди полученных цветов выбираем цвет самой большой
мощности.
Давайте обозначим хи, ж, русское, адже, латинского,
альфа, ж, адже и омега, ж, адже те оценки чисел независимости
кликовых чисел и хроматических чисел, которые так получаются.
Контрольный вопрос, вы понимаете, как кликовое число
оценить, имея всё, что мы обсудили?
Да.
Один понимает, но может ещё кто-то понимает.
Граф надо просто инвертировать и на нём посчитать оценку
для числа независимости.
Это совершенно понятно, то есть для хроматического
числа чуть труднее доказывать ту теорему, которую я сейчас
сформулирую, а для числа независимости чуть проще.
Поэтому я её докажу для числа независимости, но
давайте я сформулирую для всех.
Для этого не буду отдельно, тут вообще всё одинаково.
Что говорится?
Говорится, что для любого епсилон большего нуля, да,
но давайте, ладно, хорошо, вероятность того, ну я как-то
с места в карьер вероятность начал говорить, может надо
было как-то предварительно словами про вероятность,
но я напишу сейчас, а потом прокомментирую.
Для любого епсилон большего нуля вероятность того, что
случайный граф на n вершинах, вот на тех вершинах, которые
мы занумеровали числами от единицы до n вершинах,
таков, что у нас больше.
Реальное число независимости больше, да, я вот так напишу,
альфа от g поделить на альфа жадное от g не превосходит
два плюс епсилон, вот эта вероятность стремится
к единице при n стремящемся к бесконечности.
Так, ещё раз, какая имеется в виду вероятность?
У нас пока никаких сложных вероятностей в этом курсе
не было, и сию минуты не будет, мы уже такую
обсуждали, помните, когда мы сравнивали классические
вот эти альфа от g и омега от g, и они получались там
два лог 2 х н, мы уже брали случайный граф по сути, просто
у нас есть два в степени c и z под два графов, и вот
из этой пучи графов мы выбираем один случай и с вероятностью
один поделить вот на эту величину.
Так, друзья, в этом темпе все успевают, всё нормально?
Ну, то есть, какой смысл в утверждении?
Представьте себе, что n это миллион, вот послушайте
просто, чтобы понимать насколько это на самом деле крутая
вещь, вот представьте себе, что n это миллион, и те
графы, с которыми вы работаете на практике, ну устроены
в каком-то смысле случайно, то есть они не обладают
какой-то предзаданной структурой, ну вы заранее не знаете,
кто на вас капает с неба, вам поступит на вход, на
компьютер там или куда-то, какой-то граф, один из вот
этих вот, вы заранее никакого априорного на них распределения
не имеете, вы считаете, что поступающий граф совершенно
случайный, может пустой, может полный, может содержат
треугольники, может не содержат треугольники, фиг знает, никакой
заранее заданной предрасположенности у вас к определенным графам
нет, ну вот капает на вас этот граф, вы пытаетесь
запустить какой-нибудь алгоритм, внимание миллион вершин,
но он будет работать за время типа два в сто тысячной
степени, капец, друзья, ну я серьезно говорю, это вот
если так подходить к вопросам, а мы говорим, да нет, он же
капает совершенно случайно, у него никакой заранее структуры
нет, давайте запустим на нем вот этот вот алгоритм,
за какое время он сработает на графе из миллиона вершин,
сколько, ну максимум миллион в квадрате, все ребра надо
просто перебрать, хуже чем 10 в двенадцатый не будет,
ну 10 в двенадцатый это вам не два в сто тысячный, правда,
это можно посчитать, это быстрый линейный по числу
ребер алгоритм, кажется, что он дурацкий, кажется,
что он дурацкий, а теорема говорит, нет, не совсем
дурацкий, потому что вероятность того, что вы ошибетесь больше
чем в два раза, ну тут больше поставить, почти что равна
нулю, n это миллион, ну я там выгладку буду писать,
вы увидите, что при n равном миллиону это настолько
близко к единице, что там можно вообще не париться,
я понятно объяснил пафос к теореме, дурацкий смешной
алгоритм работает очень хорошо на случайном графе,
конечно, если вы заранее знаете, что вам на вход поступит
какой-нибудь граф из прошлой лекции, для которого можно
посчитать число независимости с помощью линейной алгебры,
ну законные структуры предрасположены, обладают, тогда ни в коем случае
не надо использовать жадный алгоритм, но если у вас
нет априорного предпочтения к чему-то, то вот так очень неплохо,
но ошибется в два раза, ну на миллионе вершин, допустим,
реальное хроматическое число 5 тысяч, ну будет 10 тысяч,
ну это хорошая оценка, а на миллиарде вершин, допустим,
там 5 миллионов, ну будет 10 миллионов, это несмертельная ошибка,
достаточно хорошо, вот, ну точно так же формулируется
теорема для хроматического числа, но только надо перевернуть,
видимо, эту дробь, то есть хи жадное оно больше, конечно,
чем хи реальное, это верхняя оценка минимального числа цветов,
поэтому здесь вот так надо написать. Я вот эту вторую теорему
не буду доказывать, вы просто должны понимать, что она тоже верна,
никто с вас на экзамене, конечно, не спросит ее доказательства,
она чуть сложнее, я докажу теорему про число независимости.
Аккуратно, да?
Альгаритм построен по хроматическому числу, да, ну что значит оценено
через хроматическое число, что вы имеете в виду, что хроматическое число
можно оценить через число независимости, можно, кстати, обратную оценку, да,
но одно из другого не последнее, потому что это оцент в одну сторону, в какую-то
концентрацию, это мы потом будем доказывать, это важно, но это чуть позже, сложнее.
Давайте я еще кое-что прокомментирую, прежде чем перейду к доказательству.
Вот это epsilon мы не сможем убрать, подчеркните как-то для себя, это важный
момент. Вот сейчас я это проясню прямо в процессе доказательства, просто написать
меньше либо равно двойке мы не сможем. Доказательство устроено так, что нам важно
хоть что-то сюда прибавить, ну чем меньше мы прибавляем, тем медленнее
стремиться просто вероятно в киевицы. Вот это вы понимаете, в чем идея? То есть тут
для любого epsilon стоит перед значком вероятности, то есть мы фиксируем какой-то
epsilon и говорим, каким бы маленьким оно ни было вот это зафиксированное, стремление к
единице будет. Вопрос в том, как быстро к единице будет сходиться эта вероятность, чем
вы готовы пожертвовать. Если вы хотите ошибиться в три раза, ну очень быстро
будет сходиться, если вы не готовы в три раза, а в два, например, хотите в 2,1
миллионную, то наверное здесь сходимость будет похожа. Вы это тоже увидите прямо из
доказательства. Это правильный совершенно вопрос, я хотел этим как раз
продолжить. Значит, для жадных алгоритмов, насколько я понимаю, epsilon устранить в принципе
не удается, то есть можно доказать, что вот именно такой жадный алгоритм по
другому и не сработает. Но хуже того, товарищи, давайте я прежде чем доказывать
эту теорему, скажу страшную вещь. Значит, вот здесь и здесь epsilon можно устранить и epsilon
можно устранить. Заменив жадный алгоритм, жадным алгоритмом нельзя, а вот можно устранить,
заменив жадный алгоритм на более сложный, но все еще полиномиальный алгоритм, но все еще
полиномиальный по числу револьвера, ну или ревершины, это неважно. Насчет его сложности, то есть степени
полинома я сейчас не готов сказать, но все еще полиномиальный алгоритм, ну иными словами,
существует более сложный, нежели жадный, но все еще полиномиальный на всех графах алгоритм,
который вот если здесь вместо буквки gen рисовать соответствующую буквку a символизирующую этот
алгоритм, то вот тут без всякого epsilon он сработает. Так я понятно объяснил? Это просто замечание,
то есть я ничего доказывать не буду, но как-то чтобы вы просто в контексте были, насколько жадный
алгоритм в каком-то смысле хорош. Просто жадный алгоритм не умеет устранить epsilon, epsilon можно
устранить с помощью нежадного, но все еще полиномиального алгоритма. Пафста в чем? Дополнительно, что
гипотеза состоит в том, что не существует полиномиального алгоритма ни с каким полиномом даже
там не знаю n в 100 тысячной степени, которая бессмысленна с практической точки зрения,
не существует полиномиального алгоритма такого, что вероятность, с которой alpha j,
e j не важно, поделить на alpha a от j меньше либо равняется 1,3, стремилась бы к единице при
бесконечности. То есть какой бы полиномиальный алгоритм мы не запускали, даже не на всех графах,
а на случайных графах, вот такая вероятность не будет стремиться к единице. Ну я надеюсь вы
понимаете, что 1,3,9 я написал для примера, то же самое можно сделать с 1,009, но это гипотеза,
никто не может доказать. Получается, что если не крохоборствовать, не морочить себе голову
какими-то епселонами, то лучше жадного алгоритма ничего нет на случайных графах. Если хочется
устранить епселон, можно придумать более сложный алгоритм, чем жадный, но если хочется двойку
заменить на что-нибудь строго меньшее, чем двойка, то ничего не работает вообще. Понятно объяснить?
Ну все. Нет, нет, вот это утверждение реальное, я просто не умею это доказать сходу, я сходу просто
не помню этот алгоритм, просто у меня в голове он сейчас висит, но он существует в литературе,
его можно найти, я могу подсказать, где примерно искать. Это доказанная вещь, придуманные алгоритмы,
которые позволяют устранять епселон. Это доказанный факт, но они сложнее, чем жадные,
а гипотеза состоит в том, что никакие не сложные, не жадные алгоритмы не справятся вот с такой
задачей так, чтобы вероятность стремилась кидеться. Такое вот удивительное.
Все, я собираюсь доказать теорему один, так сказать, верхнюю теорему про число независимости.
Так, все, больше нет вопросов, доказываю. Так, но я бы не сказал, что оно прям коротенькое это
доказательство, хотя ничего из теории вероятностей знать в итоге не нужно, товарищи, кроме того,
что вероятность объединения событий не больше, чем сумма вероятностей этих событий. Так, друзья,
это вы знаете. Может быть, вы даже догадываетесь, что это то же самое, что неравенство Маркова,
но последнего вы можете не знать. Кстати, скажите мне, пожалуйста, вы уже встречались
с таким выражением? Пока не трогали. Не было, и Чебышова еще не было. Это сегодня не нужно,
но в крайнем случае я сам расскажу, если не успеют. Я сам расскажу, но сегодня это не нужно. Сегодня
вот мы будем пользоваться абсолютно банальной вещью. Так, давайте введем для доказательства вот
такую вот величину. Целая часть, а Дэн поделить на два, один плюс Эпсилон, лог двоичный. Это сразу
должно заставить загрустить некоторую часть аудитории. Мой богатейший опыт подсказывает,
что так обычно бывает. Люди видят такую бяку, они расстраиваются. Но чем-то похоже на неравенство
Чебышова для простых чисел. Какое неравенство? Точнее, не неравенство, а для Чебышова,
то, что мы доказывали, распределение простых чисел. Ну да, но это другое, конечно. Сейчас вы увидите,
тут очень... Логика тут достаточно простая. Если вы поймете логику, то все будет замечательно. Но
это просто параметр, который там можно в шпаргалку в экзамен включить. Это не так принципиально,
хотя он легко запоминается, если понять суть логики происходящей. Ну теперь мы нарисуем
сардельку, которая символизирует наше множество вершин. Сарделька это, как обычно, множество вершин
Граф А. Ну теперь граф случайный. Так, давайте обозначим А. Давайте вот еще что скажем,
прежде всего. Давайте прежде всего скажем, что про А мы кое-что уже знаем. Я сегодня об этом
напоминал. Мы уже знаем из предыдущих лекций, из позапрошлой, наверное, лекции, мы знаем,
что вероятность, с которой альфа от g не превосходит два лог двоичный n, стремится в единицы при n,
стремящемся к бесконечности. Так, товарищи, все понимают, что мы это знаем? Ой, все, утратил.
Нет, он такой маленький, что я уже не хочу его поднимать. Сейчас я его только немножко отгоню отсюда,
чтобы не раздавить. Лей нагибаться. Так, товарищи, мы знаем это, да? Это вот как раз рассуждение про то,
какая, в целом, числа лучше через альфу или через аминку. Это мы знаем. Ну, стало быть,
следовательно, нам достаточно доказать, что вероятность, с которой жадное число независимости,
так, где оно у нас в знаменателе, больше либо равняется 1-эпсилон на лог двоичный n,
стремится к единице при n, стремящемся к бесконечности. Так, этот момент, как осознается,
оно стоит в знаменателе. Мы уже знаем, что альфа не превосходит два лог двоичный n. Если мы
докажем, смотрите сюда, и мысленно представляете, тут два лог двоичный n, вот тут написано два лог
двоичный n. Если мы докажем, что знаменатель, опять же, с высокой вероятностью, больше либо равен
1-эпсилон на лог двоичный n, то вот тут лог-лог сократятся, останется 2 поделить на 1-эпсилон,
это есть 2 плюс-эпсилон. Быстро сказал? Неужели? Нет, ну еще раз, два лог двоичный, ладно,
нарисую, мысленно не можете. Вот это вот, два лог двоичный n, это мы уже знаем, что оно не больше,
чем вот оно, не больше, чем это, мы знаем. Вот, если мы еще сейчас будем знать, что вот это не меньше,
чем 1-эпсилон на лог двоичный n, а мы собираемся это узнать, мы говорим, что этого достаточно,
то шлеп-шлеп получается 2 поделить на 1-эпсилон, и это равняется 2 плюс-эпсилон. Но я, конечно,
издеваюсь, это равняется 2 плюс-эпсилон штрих, но поскольку во всех утверждениях
стоит квантор для любого, то какая разница, как обозначить? Сейчас понятно? Вот, все. Поэтому нам
действительно достаточно вот этот карты. Видите как? Прекрасно. Ошибся я. Вот тут минус. Но это не очень
сложный страницей. Конечно, вот это и стоит здесь в знаменателе. Так, ну давайте докажем в итоге
противоположное. Всегда удобнее оценивать и снизу, а сверху вероятности. Докажем, что вероятность,
с которой альфа g от g меньше, чем 1-эпсилон на лог двоичный n, стремится к ноль. Докажем все,
у нас теорем в кармане. Я написал отрицание событий, но вероятность должна стремиться к нолью.
Хотим вот это доказать. Вот здесь и будет сейчас стоять некоторое объединение событий, вероятность
которого мы будем оценивать сверху суммой вероятности этих событий. Я не знаю, я нормально
делаю, что предвосхищаю такие вещи. Спойлеры в каком-то смысле. Важно, чтобы вас это не
путало. Ну прекрасно. Вот нам это нужно доказать. Давайте это событие обозначим буквой а. Ну она,
конечно, от n зависит, но я не пишу эту зависимость явно. Вот это событие зависит от n. Так, сейчас я
нарисую еще одну картину. А, нет, картина там нормальная, но здесь ее придется разворачивать в виде
теста. В картине я сейчас кто-нибудь придуфлю. Здесь подготовлю почву. Сейчас будет очень громоздко
выглядеть, а суть будет очень простая. Я хочу сказать, что из а следует некоторое событие b,
которое я сейчас опишу. Что такое b, пока не понятно. b равно, сейчас будем писать в чем оно состоит.
Зачем я хочу это сказать? Ну понятно, что если из а следует какое-то b, вот так, если из a следует
какое-то b, то вероятность a точно не больше, чем вероятность b. Согласны, товарищи? Я надеюсь,
что согласны. А влечет b, это значит, что он является под множеством b, а значит его вероятность не больше,
чем b. Вот, поэтому я сейчас хочу какое-то следствие вывести. На картине я сейчас следствие нарисую.
Так, под сардельки появляются c1, c2, c, внимание, m, где m вот это самое. Пока это просто картина,
которую я сейчас здесь разверну в виде текста и буду всячески комментировать. Так, давайте я разверну ее в виде текста и
потом нарисую до конца. Так, существует числа a1 и так далее, ам, м, все то же самое. Такие, что для
любого i аi меньше, чем вот эта величина, 1-эпсилон на лог 2-ичли n. Дальше существует, сравнивайте с
картиной, c1 и так далее, cm, вот эти подсардельки, которые уже появились на рисунке. Так, такие, что для
любого i мощность саитова равняется аитому. Давайте я на картинке это нарисую, что вот здесь ам вершинок,
здесь а2 вершинки и здесь соответственно а1. Так, это далеко не все. Значит, существует под множество, множество
вершин, которые каждый имеет мощность вот этих вот величин. Так, для любых i и j, саитая пересеченная
с c житом густо, но на картине оно так и есть согласное. И самое главное, для любого x, которое не принадлежит
объединению c1 и так далее, cm, сейчас допишу и нарисую на картине, и для любого i от 1 до m существует y,
принадлежащий саитому, такой, что пара x и y образует ребро. О, какое огромное событие. Вот так вам надо взять в фигурные
скобки. О, какое событие. Мало не покажется. Так, чисто формально понятно, что написано? Ну так, чуть-чуть хотя бы, не очень страшно,
но многое написано. Давайте на картине нарисуем. Утверждается следующее, если мы возьмем любую вершину, которая не попала ни в одной из этих
попарно не пересекающихся множеств, и возьмем любое из этих множеств, каждое из этих множеств, то в каждом из них найдется хотя бы одна
вершина, соединенная мостиком с этой x. Если возьмем какой-то другой там x-трих, например, то тоже есть какая-то вершина и тут, и тут, может та же самая.
Не очень я переусложнил, переноситил картинку, понятно? Это вот то, что здесь написано. Ну, вообще вы можете сходу сказать, а почему есть такие
вершины x, которые находятся вне объединения, чисто формально? Можете такое спросить? Но смотрите, сумма мощностей c1 и так далее, ну я понял, что вы уже поняли,
давайте для всех скажу. Это, конечно, есть a1, плюс и так далее, плюс am. Это нам понадобится еще в дальнейшем. А это просто по определению меньше, чем m,
помножить на 1-эпсилон на лог 2 членов. Верно? Все вы следили? Ну вот, немножко проясняется, как выбран параметр male, даже полностью проясняется,
это меньше либо равно, чем n пополам. То есть вот таких x, про которые мы утверждаем вот в этой строчке, в этих двух строчках, их много, их как минимум n пополам,
ну половина от общего числа вершин. Ну не меньшая, по крайней мере, да. Ну большая даже, там, менее устроенная. Так, друзья, сейчас чисто формально понятно, что здесь написано?
Я еще должен объяснить, почему это следствие, конечно, я этого еще не сделал. Давайте я объясню. А секундочку, следствие так определяется или это b? Нет, это b так определяется,
а я хочу объяснить, почему и за такое b следует. Что-что? Это вот эти c1, cm, это те самые множество одноцветных вершин, которые в частности нашел жабный алгоритм,
абсолютная правда. Но не все, а мы специально обрываем этот процесс на некоторые части, чтобы тех вершин, которые мы не смогли добавить к этим цветам, было достаточно много,
и на этом можно было сыграть. Это я быстро сказал, сейчас я медленно скажу то же самое. А неравенство, которое снизу это мы докажем еще будет? Какое неравенство? Вот это или вот это?
Вот это. Нет, подождите, еще раз, смотрите, существует c1, cм мощности a и t. Какое тут неравенство? Мы говорим просто, что вершин x, которые не принадлежат вот этому объединению,
их много. Я просто сделал такое замечание, что тут доказывать. Вершин, которые принадлежат объединению не пересекающихся множеств, их столько, которые принадлежат вот этому объединению.
Их же столько? Да. Так, мощность каждого циитового это а и т, значит, равенство тоже верное, правильно? Да.
Теперь смотрите, а и т по определению меньше, чем вот эта выречена, просто по определению меньше, ну а это уже очевидно, потому что m не превосходит своего аргумента.
То есть неравенство я доказал, я считал, что доказал, но сейчас точно доказал. Я просто прокомментировал определение b, понимаете, я просто хотел сказать, что в b вот эта часть скоро будет очень важна,
потому что таких любых x, которые обладают вот этим свойством, нарисованным на картинке, их больше, чем половина от общего числа вершин. И это я уже доказал, конечно.
Так, возвращаемся к тому, почему из a следует b. Вот это надо пояснить, вы же все должны понимать, почему это так.
Ну смотрите, что такое a? Я попробую на словах, ладно? Это же все под запись еще идет. Я может что-то напишу, если вы попросите, я просто пока не понимаю, что.
Что такое a? Это значит, что когда мы красили вершины с помощью жадного алгоритма, мы же альфу оценивали как размер самого большого цвета.
Вот когда мы красили, жадный алгоритм не смог найти множество большего по размеру, чем вот эта величина. Все множество цветов, которые нашел наш жадный алгоритм, они имеют размер строго меньший вот этой величины.
Согласны ли? Ну вот он нашел какие-то множества. Все они маленькие, все они меньше, чем вот этот вот размер. Успеваете за этой мыслью?
Он нашел только такие вот маленькие независимые множества, то есть только такие маленькие цвета. Ну конечно, можно пытаться описать их все.
А я говорю, давайте опишем не все, давайте именно выведем следствие. Давайте скажем, что если все цвета, которые он нашел маленькие, но ясно, что этих цветов будет больше, чем n поделить на эту величину, правильно?
А я возьму не n поделить на эту величину, а примерно вдвое меньше. То есть я буду говорить не обо всех цветах, которые нашел жадный алгоритм, а только о мы из них.
То есть я говорю, что если все цвета, которые нашел жадный алгоритм, маленькие, то уж точно среди них есть m штук, которые тоже маленькие, правда?
Друзья, я очень стараюсь разжевать, понятно? Но очень не хочется вот это все писать на доске. Безумие такое, текст выписывать на доске.
Если нашлось просто много маленьких цветов, значит уж как следствие нашлось m маленьких цветов.
А дальше, почему жадный алгоритм смог найти вот эти m маленьких цветов и не смог их дорастить, то есть сделать большего размера?
Потому что каждая вершина, которая этим цветам не принадлежит, хотя бы с одной вершины внутри цвета соединена ребром.
Ее невозможно покрасить ни в один из этих цветов. Почему? Потому что она и тут в противоречии, и тут в противоречии, и тут в противоречии.
Мы взяли m первых цветов.
Ну фактически да.
А, там еще до любого есть существование.
При этом мы же не знаем какого они размера, поэтому надо написать квантор существования по размеру.
Мы не знаем какие они сами, поэтому надо вот так выписать, как здесь написано.
А вот это утверждение о том, что жадный алгоритм просто никакой из них, из этих цветов, пополнить уже не смог.
Ну звонок сейчас, продумайте пять минут, то что я говорю, будут вопросы обсудить.
Я тут на перерыве написал две фамилии, это авторы одной из статей, в которой обсуждается вот этот вопрос,
где, как можно лучше жадный алгоритм, что там можно сделать, и куча литературы в списке.
Если есть прям очень заинтересованные, поищите, я забыл название статьи, где она опубликована.
Если прям будет какой-то общий интерес, напишите мне просто по имейлу кто-нибудь делегированный от вас.
Я найду и пришлю.
Ну как бы есть, тут куда расти, интересная действительно тема.
Но я возвращаюсь к доказательствам.
Так, друзья, я смог объяснить, почему А влечет В или остались какие-то вопросы?
Вроде прям вот должно быть видно, но отлично.
Если мы это поняли, тогда осталась техническая вещь, оценить вероятность события В.
Давайте начнем с конца, вот с этой части.
Начнем с этой части.
То есть смотрите, мы оценим вероятность события В.
Давайте считать, что и чиселки вот эти сейчас зафиксированы, и множество зафиксированы.
Вот так вот, как здесь написано, они зафиксированы, чиселки зафиксированы.
И вот нам теперь надо посчитать вероятность, ну я напишу уже, того, что даже пусть И зафиксирован.
Пусть ИХ тоже зафиксирован, он тоже зафиксирован.
Нам нужно посчитать вероятность того, о господи, пусть ИХ.
Давайте посчитаем просто вероятность того, что существует Y, принадлежащий циитому.
Вот самый конец вот этот, Y, принадлежащий циитому, такой, что XY образует ребро.
Вот эта вероятность.
То есть мы все зафиксировали, все вот эти множества, ну естественно, со своими мощностями.
Зафиксировали X какой-то, который им не принадлежит.
И хотим, да, зафиксировали, например, C1.
И хотим посчитать, с какой вероятностью X отправляет ребро куда-то в C1.
Ну, товарищи, эта вероятность, эта единица, минус вероятность того, что для любого Y из циитов, из C1, XY не принадлежит Е.
Согласны? Написал просто отрицание.
Но с какой вероятностью ни одна вершина Y не зависит нас с X?
Абсолютно правильно, да. То есть это будет 1, давайте я вот так поднимусь.
Это будет 1-1 поделить на 2 в степени A и D.
На 2 в степени A и D.
Так, друзья, может быть кто-то этого чуть-чуть не осознает.
Еще раз, если мы взяли абсолютно случайный граф из кучи, это то же самое, что каждое ребро полного графа
независимо от остальных, проводить или не проводить с вероятностью 1-2.
Вот это, друзья, вы понимаете?
Взять случайный граф из кучи, в которой 2 в степени C и Z под 2 графов,
это то же самое, что каждое ребро полного графа на N вершинах
проводить или не проводить с вероятностью 1-2 независимо от остальных ребер.
Будете фиксировать это или понятно, очевидно?
Ну, если это очевидно, давайте я еще раз картину нарисую.
Вот у меня какой-то X, вот у меня какое-то C и T.
Вероятность того, что нет ни одного из этих ребер, нет ни одного из этих ребер,
это 1-2 вероятность отсутствия каждого отдельного ребра в степени количества этих ребер,
а это и есть мощность C и T.
Кое-что все-таки не очевидно.
А именно, мы с Аитой выбирали после того, как зафиксировали графы.
Нет-нет-нет, подождите, вот это хорошо бы не путать, подождите-подождите.
Сейчас, давайте я тогда еще подробнее скажу.
Значит, смотрите, когда мы пишем квантор существования,
это фактически то же самое, что нарисовать значок объединений.
События как A, так и B, это не какие-то общие слова, а это множество графов.
Как нас учат теории вероятностей, события это всегда набор элементарных исходов.
В нашем случае элементарным исходом является граф на N вершинах.
Друзья, вы это понимаете?
A это множество каких-то графов на N вершинах.
Мощность A конечно меньше, чем 2 в степени C из N по 2,
но наша цель доказать, что она сильно меньше, чем 2 в степени C из N по 2,
то есть вероятность A стремится к нулю.
Вот это наша цель.
Мы говорим, из A следует какое-то B, то есть A вложено в это B,
и B это тоже множество графов.
Какое это множество графов?
Давайте я потом сотру.
В теоретико-множественном смысле надо писать вот так.
Это объединение по всем A1, объединение по всем AM.
С вашего позволения, неравенства я здесь рисовать не буду,
но конечно неравенства вот так они предполагаются, те, которые там написаны.
Дальше идет объединение по всем, давайте я так напишу, C1 и так далее, CM.
Тут надо огромный значок объединения нарисовать таким, что...
И дальше идут вот эти условия.
Для любого И...
Может это кому-то полезно зафиксировать себе в тетрадку?
Посмотрите, это как раз важно.
Мощность ЦИТа выровняется АИТому,
и для любых ИЖИ ЦИТа пересеченная с ЦИТом пусто.
Зараза, кто-то хочет мне позвонить опять.
Долагаются.
О господи, я перезвоню, сейчас не могу.
Вот, а дальше происходят вот эти вот, товарищи.
Что значит для любого Х?
Это значит надо пересечь по всем ИКСАМ.
Ну, тут я пересечение отрисовать не хочу,
потому что я сейчас посчитаю все вот эти вероятности.
Но, в общем, вот так вот надо написать вероятность...
Ну, не вероятность, конечно.
Событие вот так вот для любого ИКС,
не принадлежащего и так далее.
Вот событие В, записанное в теоретика множественных термин.
То есть это множество тех графов,
которые обладают описанными в этом объединении свойствами.
Все-все-все графы в кучу свалины,
у которых есть вот такие вот наборы множеств,
ну, каких-то мощностей нужные, величины с вот этими свойствами.
И такие, что там дальше.
То есть это графы вот с этим свойством.
Мы их только их рассматриваем.
Сейчас понятно?
Это не те цииты, которые нашел наш жадный алгоритм.
Это любые цииты.
Да, когда я интуицию создавал, я объяснял,
что, конечно, речь идет про те цииты,
которые нашел жадный алгоритм в начале,
но мы дополняем это всем вообще,
чтобы ничем не заморачиваться.
Именно так.
Правильный вопрос, да.
Так, друзья, никого не запутал.
Все понимают, что квандра существования – это объединение,
а квандра для любого – это пересечение.
Все, отлично.
Могу я это стереть?
Да.
Потому что я хочу оценку продумать.
Так, ну все-таки, а вот это-то понятно?
Поднимите руки, кто это понял?
Ну, вроде массово.
Это хорошо.
Тогда не буду занудствовать.
Так, продолжаем.
Хорошо.
А вероятность того, что
для любого «и»,
вот я сюда смещаюсь,
влево,
влево,
влево,
влево,
я сюда смещаюсь, влево,
существует у,
принадлежащий цитому,
такой, что пара х, у
принадлежит е.
Что изменилось?
Изменилась, появился вот этот квандр.
То есть мы пересекаем вот эти события,
у каждого из которых такая вот вероятность.
Вероятность пересечения – это произведение,
правильно?
А почему произведение?
Независимое?
А почему они независимые?
Потому что множество не пересекается.
Друзья, все детали вот эти,
прочувствуете, да?
Множество не пересекаются,
поэтому по «и» вот эти события
независимые мы можем просто
перемножить вот эти вероятности.
Получается произведение по «и»
от единицы до «м»
один минус
один на два в степени аи.
Так, ну это можно
сразу оценить.
А «и» у нас,
смотрите сюда, меньше.
Значит дробь
будет больше.
А со знаком минус
снова меньше.
А нам то и нужно, нам сверху
надо оценивать. Значит это меньше
чем один
минус один поделить
на два в степени
один минус эпсалон лог двоичлен
вот так.
И все это в степени м.
У нас есть заготовка, по-моему.
А нет, заготовки нет.
Жалко.
Ну ладно, пока не будем ничего тогда делать,
все вот так оставим.
Ну это можно чуть подсократить,
можно вот так написать один минус
один поделить на н в степени
один минус эпсалон в степени м.
Вот так-то точно можно, да?
Я просто двойку в степени лог двоичный
превратил в н все.
Два в степени лог двоичный
на т.
Так, прекрасно.
Сдвигаемся еще влево, для любого
из умели справиться, теперь
для любого х.
Так, пишем. Вероятность
того, что для любого х не
принадлежащего объединению
c1, так далее
cm, заготовка про это как раз.
Ух, и для
любого из существует у
из циитова такое, что
пара х и у принадлежит е.
Опять пользуемся независимостью,
потому что вот
эти события
независимы по х.
Эти события,
каждая из них от х зависит,
но они независимы по х, ну смотрите просто
картинку, какая связь.
Вот эта вершина х с каждым
соединена, или вот эта вершина х
с каждым соединена.
Зависимости-то нет, правильно?
Понятно, почему нет?
Нет.
Ребра же все независимы друг от друга.
Вот, поэтому
это получается меньше
чем 1
минус 1, деленное
на n в степени 1 минус епсилон
в степени m
А помножить
на что?
На n пополам, правильно,
потому что таких вершин
больше,
чем n пополам, вот таких вершин
больше, чем n пополам.
Ну, если здесь написать просто их
количество, а потом оценить снизу,
то
итоговая оценка будет как раз
с оценкой сверху.
А почему столько больше?
Ну, столько больше, потому что
вот здесь знак строго меньше...
А, да! И здесь тоже
строго меньше... да, конечно, конечно!
Вот здесь же значок, тоже строго меньше.
Поэтому я отсюда строго меньше получаю
Это неважно, меньше
либо равно.
Хотите напишите меньше либо равно...
Уж не будет.
Просто показалось, что, естественно,
там меньше, тут меньше.
Так, по-моему, все хорошо, да? Давайте я теперь вот это еще перепишу в стандартном стиле.
Вот так перепишу. Это е в степени mn пополам на логариф натуральный от 1-1 девять на n в степени 1-f.
О, Господи, какой ужас! 102-ку сбросили, теперь обратно е подняли.
То у нас был логариф двоичный, теперь у нас логариф натуральный. А, какая прелесть!
Это удобно, потому что мы с вами знаем. Давайте вот такую врезочку сделаем. Мы уже это использовали неоднократно.
Это стандартное абсолютное неравенство, которое во всех комбинаторных аземптотиках используется на прополу. Привыкайте к нему.
То есть мы сейчас воспользуемся это не больше, чем е в степени минус mn пополам на 1, деленное на n в степени 1-f.
То есть дальше можно сократить, и у нас остается е в степени минус mn в степени f пополам.
Ну, видите, как все сокращается, да?
Слышите, нет? Вы еще со мной?
Еще, да.
Это хорошо. Ну, давайте m еще оценим. Ну, снизу оценить, да? Сверху-то понятно, как оценить.
Ну, давайте скажем, что m больше либо равняется n поделить на 2 лог двоичное. Я могу так сказать?
В целом, да.
Ну, наверное, не совсем, потому что это нижняя целая часть.
Ну, при больших n могу так сказать.
Мне все оценки нужны все равно при больших n.
Для фиксированного ε при больших n, абсолютно верно, да.
Мы зафиксировали с самого начала ε. Я могу считать, что это настолько велико, что имеет место такое неравенство.
Иначе мне придется выложить за собой вот эту биаку, но это совсем не хочется.
Так, n поделить на 2 лог двоичное. У меня тогда получается так.
e в степени минус n поделить на 2 лог двоичное n так и на n в степени епсилон пополам.
Ну, это наконец равно e в степени минус n в степени 1 плюс епсилон поделить на 4 лог двоичные.
Послушайте, ну биака биакой, ну очень уж громоздкая биака.
Можно пережить такую?
Ну, придется.
Ну, придется, да, точно. Придется такая-то точно.
Мне почему-то кажется, что можно, что это не очень страшно.
Все, нам осталось перейти теперь вот к этим двум объединениям, к двум кванторам существования.
Если нет вопросов по тому, как мы с кванторами всеобщности разобрались с пересечением.
Нет вопросов?
Так, сейчас сотру, может появится пока.
Чего тут тут стирать?
Мне все хочется. Это все мне хочется.
Как-то надо так вот по экономке поделить текст.
Ну, давайте считать зафиксированными чиселки a1,a,m.
Давайте их считать зафиксированными.
А вот это объединение оценивать.
То есть у нас получается вероятность того, что существуют c1, cm такие что?
Чего она не превосходит?
Суммы вероятностей.
Суммы вероятностей, да, я это много раз предвосхищал.
Конечно, суммы, но суммы каких вероятностей?
Каждый из которых вот так оценивается, да?
Ну, это от чего-нибудь зависит кроме n?
От ашек, от цешек.
Ведь не зависит же, правда?
Ну, я напишу, конечно, но сразу вынесу за скобку.
То есть я вот так напишу.
E в степени минус n в степени 1 плюс епсилон на 4 лов двоичный n.
Но я его вынесу сразу за знак суммирования.
А суммироваться будут, конечно, суммирование будет по всем c1 и так далее cm.
Таким, что для любого i мощность ci равняется i тому.
И для любых ij ci пересеченное с сжитым пусто единицы.
Суммироваться будут единицы.
Мы за скобку вытащили оценку каждой вероятности, которая в скобках стояла.
Сейчас вот тут я не разогнался.
На радостях единицы.
Такой вопрос?
Да.
А почему мы не оцениваем вот эту вероятность существования всех одновременно как сумму вероятности, когда существует один хитр.
То есть существуется и это такое, что вот это вот.
Просто мы прочитали вероятность без квантера существования.
Нет, подождите еще раз.
Это же объединение по всем c1 и cm.
Я написал таким жирным объединением.
Но нарисовать жирное объединение, давайте я еще раз нарисую.
Я нарисовал такое жирное объединение.
И тут дальше было написано все то же самое.
Тут какие-то события, да?
Как оценивается вероятность вот этого жирного объединения?
Она оценивается суммой по всем c1 и cm.
А что тут еще можно сказать?
Вот я не писал сумму.
Тут вероятность того и дальше вот этого всего, что мы уже оценили.
Понятно?
Конечно, нарисовать жирное объединение это в точности то же самое, что сказать объединение по c1, объединение по cm.
Но они связаны, поэтому лучше писать большое.
Что я вот так и не стал.
Но я в любом случае это сейчас уже и сотру.
Понятно это все, да?
Единицы, поскольку оценки этих вероятностей уже вытащены за скоб.
А суммировать единицы это значит просто посчитать количество вот этих товарищей.
Если суммируется единиц, нас интересует просто количество слагаемых.
Друзья, если что-то непонятно, очень прошу спрашивать.
Я максимально стараюсь сейчас держать вас под контролем.
Но это не больше или даже меньше строго, чем где в степени.
Повторяем вот эту бляку.
1 блюс эпсалон, 4 лог 2-ичные.
Никуда от нас не денется еще долго.
И дальше надо как-то оценить количество способов разрисовать вот эту большую сардельку маленькими.
Но как оценить?
Я оценю идиотски.
Ну цешками.
Конечно, это не идиотская оценка.
Всего у нас альбершим, правильно?
Я аккуратно напишу.
С из Н по А1 это количество способов построить С1.
Когда мы построили С1, остающееся количество способов вот такое для С2, правильно?
Давайте сразу полидомиальный.
Ну согласен, да.
Я сейчас еще хуже сделаю.
Я сейчас еще грубее отсюда.
Он не совсем полидомиальный, потому что мы же не все заполняем этими ашками.
Ну там еще остаются вот эти Н пополам вершины.
Повезло.
Вот, ну тут будет С из Н-А1-М-1 по АН.
Так, друзья, ну это понятно.
Я сейчас идиотскую оценку сделаю.
Все мы с вами знаем, я специально вас предготовлял там на первой лекции или на второй,
что С из Н пока не больше чем Н в степени К поделить на К факториал.
Привыкли к такой оценке уже?
С из Н пока не больше чем Н в каты на К факториал.
Идиотская вещь будет состоять в том, что я сейчас так скажу.
Просто С из Н пока меньше чем Н в каты.
Мне этого хватит.
Ну, так.
Но больше тому Н-А1 меньше чем Н, и вот это тоже меньше чем Н, товарищи.
Удобно.
Да, очень хорошо.
Смотри, детка, все меньше.
Ну, давайте я уже сюда понеду.
А, нет, сюда плохо ехать.
Ну, давайте я попробую тут, я не знаю, куда ехать.
Вот давайте сюда.
Привилеем сейчас Лу сотру.
То есть, чуть-чуть лишнее сотрешь, потом пойди восстанови.
Так, давайте вот так, меньше.
Вот отсюда пошел сюда.
Меньше чем.
Боже мой, господи, ну опять эту бяку надо рисовать.
На четыре лок двоичной Н.
Я говорю, она с нами навечно.
Ну, по крайней мере, до конца лекции.
Так, и все, и идиотская оценка.
Н в степени А1+, и так далее, плюс Н.
Ну, то есть, я каждую цешку оценил, как Н в степени соответствующая А.
Видите, что-то меньше, чем Н.
Ну, значит, произведение цешек меньше, чем Н в степени сумашек.
Друзья, успеваете, нет?
Так, ну сумашек-то мы заготовили, она меньше, чем Н пополам.
Значит, это меньше, чем Н в степени минус.
Н в степени А1+, на четыре лок двоичной Н.
И на Н в степени Н пополам.
Вам кажется, Н в степени Н пополам, это какое-то ужас, огромное число.
Можешь поделиться.
Нет, тут не в том дело.
С минусом-то стоит Н в степени А1+, а тут Н только на лог Н.
Но это если кто понял.
Я потом аккуратно напишу.
То есть, пока все стремится к нулю, то, что нам нужно, понимаете?
Но нам еще осталось объединить по А.
Давайте я вот здесь сотру.
Но это вообще фигня.
Кто это сходу не понимает, тот пока не научился считать комбинаторные асимптотики вообще асимптотики.
По А там просто фигня, сейчас вы увидите.
По А там просто фигня.
То есть, теперь итоговая вероятность В оценивается вот так.
Она не больше, чем сумма по А1 от единицы до вот этой величины.
До 1 минус Эфсилон на лог двоичной Н.
И так далее.
По АМ от единицы до 1 минус Эфсилон лог двоичной Н.
От единицы до 1 минус Эфсилон лог двоичной Н.
Ну вот этих вот величин.
Е в степени минус, Н в степени 1 плюс Эфсилон, деленное на 4 лог двоичной Н.
И давайте я тут напишу.
Плюс Н пополам на логариф натуральный Н.
Я загоню в общую экспоненту ту оценку вероятности, которая вот тут написана.
Н в степени Н пополам, это е в степени Н пополам логариф натуральный Н.
Так, увидели, да?
Как одно с другим соотносится.
Боже мой, это как же можно выяснить?
А сколько снова?
То есть, ну давайте это что-то меньшее, чем лог двоичной Н в степени М умножить на е в степени минус Н в степени 1 плюс Эфсилон,
поделить на 4 двоичных логарифма Н, плюс Н пополам логариф натуральный Н.
Так, вы поняли откуда взялся лог двоичной Н в этой степени?
Ну это просто количество слагаемых в этой сумме, оценено и без учета, что тут еще есть совмножитель 1 минус Эфсилон.
Конечно.
Перемножим количество, потому что независимая сумма.
Так, мы у нас, чего меньшее?
Уж точно оно меньшее, а что оно меньшее?
А, ну давайте Н на 1 минус, ну ладно, ну меньше, чем Н на 2 на 1 минус Эфсилон, ну ладно.
Все, сейчас мы напишем вот так, тяп-ляп, лог, не ну все аккуратно, тяп-ляп товарищи не воспринимайте так, как будто я пытаюсь вас обмануть где-то, все аккуратно.
Лог двоичной Н, а М оценивается, ну как Н пополам, там что там еще осталось.
Да ладно, вот прям честно вот так, 1 минус Эфсилон, ой ой какая.
Лог двоичной Н, да?
Меньше либо равно.
Так, ну на Е в степени я уже не буду переписывать, с вашего позволения, это вот здесь и вот здесь одно и то же.
Сейчас я еще вот эту хрень, извините, в Ешку загоню и будет вам кататься с аналитической.
А можно еще раз посадить, откуда у нас сверху стежки?
Суммы, ну еще раз, мы вот здесь, вот здесь разобрались вот с этой частью, вот отсюда.
Вот отсюда, что вероятность того, что существует С1СМ, заданной уже заранее, заданной мощности.
Теперь нам надо еще дополнительно объединить по всем способам, выбрать А1АМ.
Вероятность этого объединения снова оценивается суммами.
Сейчас вероятность уже по А1АМ, почему просто цешки нельзя отценивать?
Какой цешкой? А1АМ это просто числа, меньшие вот этой величины.
Это несколько чисел, никак друг с другом не связано.
Мы говорим, есть несколько чисел, mesh2.
Каждый из них меньше вот этой величины.
Дальше вот, допустим, мы их зафиксировали таким.
Мы только что оценили вероятность вот этого события с этими конкретными числами.
Она оказалась меньше вот этого числа.
Теперь мы объединяем обратно по вот этим числам.
Мы просто суммируем по А1, по АМ, ту оценку вероятности, которую мы при каждом наборе этих А1АМ получили.
А потом мы, как обычно, вот это все выносим за скобку.
Вот оно вынесено за скобку.
В скобках остается сумма единиц.
Сумма единиц – это количество слагаемых.
В первой сумме слагаемых сколько?
Но меньше, чем лог двоечная.
Я убрал один минус эксилон.
В последней сумме тоже меньше, чем лог двоечная?
А они независимые.
Ну, значит, надо в М2 и степи.
Ага.
Не-не, спрашивайте.
Я специально прошу, у меня время еще пока есть.
Ну так, не очень хорошо, конечно, но есть.
Нет, мы на самом деле все.
Мы эту теорему почти доказали.
Но давайте я честно напишу, какая тут дрянь получилась.
Значит, N поделить на 2, на 1 минус эксилон, на лог двоечный N.
Так, тут вот самая дрянь получилась.
Смотрите, логариф натуральный от логарифа двоичного.
Хе-хе.
Это умножить.
Ну, я загоняю все в показатель экспонента.
Мне приходится брать натуральный логариф от двоичного логарифа.
Ну и здесь давайте я прибавлю сначала N на 2 на логариф M
и вычту вот это.
N в степени 1 плюс эксилон на 4 лог двоечное.
Ну что, друзья, видите, что получилось?
Сейчас вопрос какой-то, нет?
Все понятно?
Вот у меня получилась такая экспонента.
Вот в показателе экспонента вся вот эта сумма двухслагаемых и одного читаемых.
Согласны, что она такая получилась?
Давайте.
Осталось осознать следующее.
Если бы, вот смотрите, если бы эксилон могло равняться нулю,
то тут получилась бы просто N в первой степени, правда?
Да еще деленное на логарифу двоичное N.
А тут было бы N умножить на логариф M.
И тут еще какое-то положительное слагаемое.
И тогда все это стремилось бы к плюс бесконечности.
А у нас-то какая цель?
У нас цель доказать, что вероятность B стремится к нулю.
То есть при епсилон равном нулю ни черта не получается, правда?
Как я и обещал.
Но если епсилон это даже одна, я не знаю, вентиленная там, одна, вугольная там, какая хотите?
Гугол.
Гугол знаете такое число?
Бывает и больше.
Гугол в степени гугол, гугол раз там, я не знаю.
Чего хотите?
Но если епсилон зафиксировано, зафиксированно, а N стремится к бесконечности.
Вы понимаете, что вот эта вот фигня, она становится, начиная с какого-то N, ну, например, больше, чем N в степени 1 прибавить епсилон пополам.
Плевать на четверку, плевать на логарифу.
Если епсилон фиксированное положительное число, то начиная с какого-то N, нулевого, например, у вас будет вот эта штука больше, чем N в степени 1 плюс что-то константное.
Но это растет медленнее.
Логарифм-то растет медленнее любой одной гугольной.
Но N в степени одна гугольная.
И тут та же история, смотрите сюда, тут вообще фигня.
Тут N умножается на повторный логарифм, а 9 на логарифм, это меньше N.
Вот эта вот вся страсть, она на самом деле вообще меньше, чем N.
На нее можно вообще было забить.
Вот это суммирование не играет никакой роли.
Оно дает вклад ничтожен.
Это могло бы побороться, если епсилон равняется нулю.
Но как только епсилон будет сколько-нибудь положительное, оно сдается тоже.
И вся эта вот итоговая разность стремится куда?
К трубу.
К минус бесконечности, нет, к яндексу, конечно.
К минус бесконечности.
А все вместе к нулю.
Я доказал теорию?
Все это стремится к нулю, потому что разность,
стоящая в показателе экспонента, стремится к минус бесконечности.
Я хочу сделать до конца лекции еще одно важное замечание.
Чтобы вы не думали, что жадный алгоритм это прямо панацея от всего,
и больше ничем заниматься не надо.
Вот стертое здесь Кривилевичеву они как раз обсуждают этот вопрос в своей работе.
Там действительно есть чем заниматься, несмотря на тот пафос, который я сумел навести.
Так, смотрите.
Ну, всем понятно, да?
Больше нет никаких вопросов по доказательству.
Все поняли, как произошло дело?
Если кто-то не понял, вынесите вот эту штуку, которая отведена вам за скобку.
Тут будет минус один, а в скобках останется что-то стремящееся к нулю,
и что-то стремящееся к нулю.
Если из чего-то стремящееся к нулю.
Вычесть единицу, то это будет заведомо, начиная с какого-то момента отрицательное число.
И еще за скобками вот эта фигня.
Ну, значит это стремится к минус бесконечности.
Ну, товарищи, доделайте это руками, чтоб, если уж там непонятно.
Я хочу другое сказать.
Я хочу сказать, вот с самого начала.
Послушайте меня внимательно, это важный момент.
Мы зафиксировали нумерацию вершин.
Вы согласны, чтобы ее зафиксировать?
Вот это даже здесь нарисовано.
Один, два и так далее.
Имеем право.
Но я даже удивлен, что никто не предложил как-то ее поварьировать.
А у нас по теме было гораздо сложнее.
Ну, это-то безусловно, что гораздо сложнее, но вот удивительным образом это не влияет никак.
То есть, с одной стороны, конечно, можно доказать следующий замечательный факт.
Может, не знаю, записывать, не записывать, как угодно.
Что, безусловно, существует нумерация.
Существует нумерация.
Для каждого графа существует нумерация, в которой жадный алгоритм найдет просто его настоящее хроматическое число.
Но мы просто не знаем, какая это нумерация.
А нумерация, извините, n-факториал.
И это еще хуже, чем экспоненты.
Это жесть какая-то.
А вот сформулировать я хочу следующий забавный результат.
А, я так и вспомнил.
Что говорите?
Это лучше, чем Эдвенный.
Ну, это лучше, чем Эдвенный, но не хуй, не сильно хуже, потому что там на Эдвенный надо тереть.
Потому что эти парады еще хотят решать уже по ответу, а не...
Нет, это кошмар.
Факториал это кошмар.
Когда-нибудь...
Да сейчас хуже, я вам сейчас хуже результат допишу.
Если поймете, ну поймете, я сейчас совсем его расшую, вы обалдеете.
Доказал ее товарищ по фамилии Бучера.
Время кокоса.
Она у нас в курсе идет без доказательства.
Я пишу BETRODE.
Это означает, как обычно, что мы ее в курсе не доказали.
Значит, утверждение такое.
Для любого Эпсилон большего нуля и для любого Дельта большего нуля,
и для любого Дельта большего нуля,
существует последовательность графов G с индексом N.
Ну N, понятно, от нуля единицы до бесконечности.
Да, существует какая-то бесконечная последовательность графов.
Такая, что...
Давайте я, наверное, так скажу.
Так, как же это сказать?
Количество терграфов...
Нет, неправильно.
Сейчас.
Сейчас, секунду, почему?
Почему посвятую?
Сейчас, сейчас.
Ой, ой, ой, ой, сейчас.
Ну давайте с N-вершинами все-таки.
Графов G N с N-вершинами.
Такая, что не количество терграфов виноват,
а количество тергперестановок...
Спеваю поговорить.
Множество 1, 2 и так далее N, которые служат вершинами этих графов G N,
количество тех перестановок, на которых...
Ух, ух, ух, ух, ух.
Жадный алкогитм находится.
Сейчас, кто там у нас больше-то?
Альфа от G поделить на альфа жадная от G.
Больше ли равняется N в степени 1 минус ефсилон?
N в степени 1 минус ефсилон, где ефсилон фиксировано заранее.
Это как надо промахнуться?
Промахнулся очень, промахнулся.
Количество тех перестановок...
Я допишу.
Это знак деления.
На 2 в степени... Нет, на N факториал.
Не на 2 в степени.
А, тут G N надо только нарисовать.
Вот здесь G N.
Сейчас вы офигеете.
Так.
Нет, не стремится, а больше чем 1 минус D.
Вот, все.
Вот.
Ну, наверное, тут надо так сказать.
Последность с эндершинами такая, что найдется N нулевое.
Такое, что для любого N большего, чем N нулевое.
И дальше вот так.
Вот это абсолютно аккуратная формулировка.
Так, давайте, товарищи, осознаем, что написано.
Извините, вероятность не видела.
ynthesis.
Возможно.
Мы сверху неравенство делим на факториала.
Нет, мы не неравенство делим на факториала, а вот это мы делим на факториала.
Количество тех перестановок среди N факториал возможных...
Виноват, товарищи.
Вот я в gdzie-то есть поставил, теперь понятно.
Да.
еле.
Смотрите, количество тех перестановок среди N факториала возможных,
на которых жадный алгоритм дичайШем образом ошибается...
А, ну да, больше чем один минус дельта.
Доля тех перестановок, на которых жадный алгоритм ошибается, близка к единице, заданной наперед точностью.
Смотрите, с одной стороны, теорема, которую мы доказали, утверждает, что почти любой граф жадным алгоритмом
красятся с ошибкой не более чем 2 плюс Эпсилон, но ведь это почти любой граф, не любой же.
Вы понимаете, что мы доказали теорему про почти любой граф?
Но есть масса графов, не попавших вот в эту вероятность.
И среди вот этой массы графов есть такие, что как почти что не переставляя их вершины
и потом запуская жадный алгоритм, ошибка будет не то, что меньше, чем 2 плюс Эпсилон,
а больше, чем ужас, как у Н в степени 1 минус Эпсилон.
Но почти всех ошибается не более чем вдвое, но бывают такие, на которых он не просто
в фиксированной нумерации ошибается больше, чем Н в степени 1 минус Эпсилон,
но почти во всех нумерациях ошибается не менее, чем в Н в степени 1 минус Эпсилон раз.
Подождите, ножи.
Жестко.
Жестко, да.
Непонятно, Скалов, все равно?
Я не понимаю, почему жадник может находиться меньше, чем действительно чувствование зависимости.
То есть жадный алгоритм на почти всех нумерациях для некоторых графов будет ошибаться вот
во столько раз в том числе?
Понятно?
Все, пора закончить.
