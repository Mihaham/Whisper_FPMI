Видно ли экран? Нормально ли видно? Да, видно. Спасибо. Так, значит, мы в прошлый раз не начали с
вами условным от ожидания, но я так коротко сказал о том, об интуиции этого понятия,
и сегодня мы с вами в общем про него начнём говорить. Так, тема сегодняшней лекции – это условное
математическое ожидание. Ну, как я в прошлый раз пояснял, интуиция следующая – что мы хотим не
просто найти среднее значение случайной величины, а понять, какое у него среднее в зависимости от
тех или иных исходов. То есть простейшая такая интуиция – это то, что у нас есть какой-то случайный
процесс, и у нас же есть некая история, то есть мы не в начальном моменте времени этого процесса
находимся, а вот уже какая-то история прошла, и в зависимости от того, какая история, средний может
быть разным. Вот, значит, как это дело формально определить? Ну, предположим, что у нас есть
случайная величина, которая задана, как обычно, на комнату верентосного пространства, то есть
есть верентосное пространство МегаФП, и есть случайная величина КСИ на нём.
Вот представьте, что у вас информация, которую вы можете использовать,
которую будет зависеть условно-математическое ожидание, она заключается в некоторой подсигмалгебре
F, то есть вы внутри F выбираете некоторую сигмалгебру, которая в ней содержится.
И мы хотим понять, что такое умоджедание КСИ при условии G. Давайте для удобства считать, что у КСИ
конечное математическое ожидание. Вот, что тогда такое условное умоджедание КСИ при условии G?
Это есть такая случайная величина, которая же измерима.
То есть представьте себе, что в G у вас лежат события, в зависимости от которых вы мерите
среднее случайное величина, и, соответственно, то или иное событие G произошло у вас то или иное
Поэтому это случайная величина должна быть же измерима.
И должно быть выполнено некоторое интегральное свойство, которое говорит о том, что это действительно
среднее значение. Значит, это же измеримая случайная величина такая, что для любого события A из G
мат ожидания КСИ умножить на индикатор A совпадает с мат ожиданием от условного мат ожидания КСИ при
условии G на индикатора. То есть это понятное свойство. То есть чем оно заключается?
Заключается в том, что если вы усредняете вашу случайную величину КСИ на любом событии из
вашей сигма алгебры G, в которой содержится известная вам информация, то это все равно,
что усреднить ваше среднее по этому событию. Поэтому это определение кажется вполне естественным.
Давайте мы сейчас на каком-то примере увидим то, что это определение дает нужное нам условное
математическое ожидание. А именно проще всего это понять, когда у вас сигма алгебры G порождена
разбиением. Давайте разберем такой пример. Пусть G это наименьшее сигма алгебры,
которая порождена каким-то разбиением. То есть у вас есть разбиение омега на не пересекающиеся
подножество. Их может быть конечное количество, может быть счетное бесконечное количество,
несуть важно. Давайте считать, что все эти множества из разбиения не тривиальные в том смысле,
что вероятность каждого положительная. И вот пусть наша сигма алгебра G порождена разбиением.
То есть это минимальная сигма алгебра, которая содержит все вот эти подножества 1, 2 и так далее.
И вот мы хотим понять, что же такое условное мы ожидание G при условии G. Давайте подумаем,
что нам подсказывает интуиция. Интуиция нам подсказывает, что когда мы думаем про условное
математическое ожидание, G это известная нам информация. То есть на самом деле у нас есть
эти элементарные подножества, из которых G состоит 1, 2 и так далее. И мы хотим на каждом из них
усреднить. То есть при каждом из этих событий мы хотим по-своему посчитать средний. Понятно,
что это средний, это будет просто мат ожидания кси умножить на индикатор Деитова. Если вы
захотите посчитать среднее на множестве Деитова, вы получите такое. Но когда вы считаете условное
мат ожидание, то вам еще нужно отнормировать. Потому что если вы просто посчитаете мат ожидания
кси на индикатор Деитова, то оно будет сильно меньше по сравнению с вашим условным мат ожиданием
из-за того, что вы не отнормировали на вероятность Деитова. То есть интуиция подсказывает,
что на множестве Деитова условное мат ожидания должно быть равно вот чему. И давайте мы с вами
докажем, что это действительно так. То есть докажем, что условное мат ожидания кси при условии G
это вот такая штука на множестве Деита. То есть умножить на индикатор Деита. Но еще надо написать
сумму по всем И. А можете, пожалуйста, объяснить еще? У нас есть какое условие? То есть если,
например, до этого мы проходили условия, было понятно, что произошло какое-то событие. А здесь
какое условие? Смотрите, мы хотим… Да, это очень хороший вопрос. Смотрите, в чем прикол. Здесь то же
самое. Давайте зафиксируем вообще Деитое, Д1, например, и предположим, что оно наступило. И при
этом условии посчитаем математическое ожидание. Потом зафиксируем Д2. Предположим, что оно наступило,
и при этом условии посчитаем математическое ожидание. И при каждом из этих условий у нас
будет получаться ровная тедра. Мат ожидания кси на индикатор Деита и подсказывает на вероятность
Деита. Это будет значение условного мат ожидания на событии Деита. Значит, когда вы говорите про вот
этот именно объект условного мат ожидания кси при условии Ж, вы подразумеваете, что вы одновременно
смотрите на все возможные значения вашего условного мат ожидания при условии наступлений разных
событий. То есть это, на самом деле, случайная величина. В зависимости от того, какое событие из
Деитах наступило, у вас будет то или иное значение условного среднего. Понятно?
Наверное, потом будет понятнее. Да, ну давайте вот какой-нибудь простой пример. Скажем,
подбросили, бросаете вы кубик, на грани, к которому написано число от 1 до 6. И давайте
рассмотрим два события. Одно событие, это то, что выпало нечетное число с либо единичкой либо
тройкой либо пятеркой. Другое событие, это то, что выпало чётное число – либо двоикалиб, четверк
либо шестерка. И, если вы будете считать среднее значение при условии первого события, при условии
того что выпало нечетное число, вы получите 3. Теперь если вы будете считать среднее значение при
условии того, что выпало чётное число, то получите 4. То есть у вас тем самым, у вас получается
случайная величина, которая принимает два значения. 3 и 4. это ваша условная средняя. она
принимает значение 3, если выпала нечётное число, и она принимает значение 4, если выпала нечётное число.
а, то есть вот эти вот а и б это как раз и есть элементы g? d1, d2 вы имеете ввиду. да, это элементы g,
конечно. это элементарные, ну как это сказать, это атомарные события g. это те события,
которые g порождают. ну понятно. окей, давайте докажем, что действительно так, что это просто
следует из нашего определения. ну, во-первых, уже измеримость. то есть мы хотим проверить,
что значит, что мы хотим доказать это утверждение. на самом деле, условным от ожидания, это не то,
чтобы какая-то одна конкретная величина. для пары случайная величина и сигма алгебры g,
условных от ожидания много. вы, грубо говоря, какое-то одно значение можете поменять на
элементарном исходе, вероятность которого равна нулю. и от этого случайная величина
останется такой же. ну то есть, имеется ввиду, что есть класс эквивалентности условных от
ожидания, который совпадает с вероятностью 1. и поэтому вот здесь, когда мы пишем равенство,
когда мы пишем, что условно от ожидания равно чему-то, мы просто подразумеваем,
что вот это представитель из класса эквивалентности всех условных от ожидания, да. так-то их вообще
много. но я об этом чуть позже поговорю. то есть знак равенства между условным от ожидания и
какой-то конкретной случайной величиной надо подразумевать как на самом деле принадлежность
этой случайной величины классу эквивалентности всех условных математических ожиданий. то есть
когда мы хотим проверить это равенство, мы на самом деле просто хотим проверить определение. то
то, что вот то, что стоит в правой части равенства, подходит под определение
в условном от ожидания. во-первых, мы хотим проверить g-измеримость, а во-вторых,
мы хотим проверить вот это интегральное равенство, что для любого a и g
среднее от xi умножительный индикатор раз вкладает со средним
это условном от ожидания множество индикатора. но уже измеримость, во-первых.
то есть, во-первых, почему вот эта вот штука, которая справа написана, сумма
по всем и от ожидания кси умножительный индикатор даито, определительно п от даито,
умножительный индикатор даито, это же измеримо.
но это очевидно, просто из вида, это случайные величины.
ну как это можно понять? ну во-первых, все индикаторы даито, конечно, измеримы,
потому что это даито, которые мы взяли из нашей сигмалы.
поэтому все индикаторы измеримы, то есть все эти идаиты же измеримы,
и поэтому их линейная комбинация тоже же измерима.
вот эти вот коэффициенты, просто числа, то есть, по сути, это какая-то линейная комбинация индикаторов,
поэтому она тоже будет же измерима.
понятно, что как конечная линейная комбинация измеримых функций является измеримой,
так и отсчетная линейная комбинация тоже является измериваем, просто потому
что мы знаем, что мы можем переходить к пределу.
предел последовательности измеримых функций является измеримой функцией.
Во-вторых, интегральное свойство, мы берем любое ASG и должны проверить это равенство,
которое написано в определении условного математического ожидания. Но смотрите,
что такое ASG? Можно ли в каком-то общем виде записать любое событие, которое ASG принадлежит?
Значит, J – это сигнал Юра, порожденное конечным или счетным разбиением. Если мы берем любое
множество ASG, то очевидно, что это есть просто объединение каких-то деитов. Если вы порождаете
из разбиения сигма-алгебру, то любое множество сигма-алгебры – это просто объединение атомарных
подмножеств. То есть, если А принадлежит J, то А равно объединению дезюнкному по всем и ину из
какого-то и большого деитов, для некоторого и большого. Значит, тогда давайте сразу правую
часть возьмем вот этого равенства, правую часть, и посмотрим, чему будет равно такое мат ожидания.
То есть, мы ищем мат ожидания от условного мат ожидания x при условии g умножить на индикатор
A. Так, сейчас, одну секундочку.
Прошу прощения. Значит, давайте найдем вот это математическое ожидание, которое у нас в правой
части интегрального равенства написано. То есть, подставим наше выражение вместо условного
мат ожидания. Сумма по всем и, мат ожидания x на индикатор деитое, поделить на p от деитое на
индикатор деитое и умножить на индикатор A. Ну, понятно, что, значит, еще раз, А – это объединение по
какому-то множеству и большое деитов. Если вы индикатор деитое умножаете на индикатор А,
у вас получается либо ноль, либо единица. Единица у вас получается в том и только в том случае.
Значит, вот это произведение равно единице, а это только тогда, когда и маленькое принадлежит и
большое. То есть, когда деитое – это под множество большое, иначе ноль. Поэтому, на самом деле,
это мат ожидания суммы по всем и из и большого. Сумма по всем и из и большого. Мат ожидания x на
индикатор деитое поделить на вероятность деитое и умножить на индикатор деитое.
Ну вот, по линейности математического ожидания у вас что тут написано? У вас написано какие-то
эти коэффициенты, которые умножаются на индикатор деитое. Если вы теперь мат ожидания внесете
внутрь суммы, вы получите сумму по всем и из и большого. Мат ожидания x на индикатор деитое
поделить на вероятность деитое и умножить на вероятность деитое. Вероятность деитое сократится,
останется просто сумма по всем и из и большое. Мат ожидания x на индикатор деитое. Снова по
линейности мат ожидания вы сумму можете внести внутрь и получите ровно мат ожидания x на индикатор
а. Что и требовалось. Да, это в точности наша ровность из определения мат ожидания,
значит все доказано. Есть ли какие-то вопросы? А мы столько раз индикатор деитое пишем,
чтобы потом перейти к вероятности от мат ожидания. Или как? Мы тут три раза написали индикатор
деитое в два раза подряд. Вы имеете в виду вот эти два индикатора? Да, да, да. Смотрите,
здесь под мат ожиданием стоит индикатор. Да, то есть мат ожидания это произведение,
x на индикатор деитое, это число. А следующий индикатор это случайная величина, то есть здесь
написан коэффициент, вот эта дробь это число и она умножается на индикатор деитое. Здесь тоже самое.
Окей? Ну да. А можно тогда уточнить? Условное мат ожидание, это значит функция? Да, причем важно,
что это случайная величина измеримо относительно сигнал гибра, который стоит в условиях. Это не
просто случайная величина, она мега fp, а некоторое сужение. Мы знаем, что все ее прообразы,
все параллельские множества меж RG. Так, окей, теперь давайте вернемся к тому, что я говорил
про существование единственности в условном мат ожидании. Да, оно существует и единственно,
но единственно в том смысле, что с точностью почти наверно. То есть условных мат ожиданий, конечно,
много. Это классы револидности, они все друг другу равны почти наверно. И когда мы пишем равенство,
мы имеем в виду просто принадлежность одному и тому же классу револидности. Давайте это утвердим,
но прежде чем это утвердить, мне понадобится теорема Радона-Никодима, которую, я так понимаю,
вам Иван Геннер, к сожалению, не рассказал. Очень важная теорема из теории меры,
но ее доказательство это, в общем, целый квест, и мы его опустим. Кому интересно,
вы можете заглянуть в любую книгу по теории меры и посмотреть. Значит,
Терема Радона-Никодима это как раз о том, что условным мат ожидания существует единственно,
но оно формулируется в терминах абсолютно непрерывных мер. Давайте я сначала расскажу,
что такое абсолютно непрерывные меры, еще расскажу, что такое заряд, а потом сформулирую теорему.
Заряд – это просто... Чем заряд отличается от меры? Заряд отличается от меры тем,
что он может принимать отрицательные значения. То есть, если у вас есть какая-то функция
NU, которая действует из сигма алгебры G в R, который является счетно-аддитивной,
то он называется зарядом.
Некоторые обобщения понятия меры, мера со знаком. Заряд будем называть
абсолютно непрерывным относительно вероятностной меры P.
Если существует плотность, если существует плотность, то есть это такая функция,
значит, такая функция G, которая действует из Омега в R,
которая является G-измеримой. Такая, что для любого A из G значение заряда на
множестве А совпадает с интегралом по А от G dp. Что такое dA? Что такое dA? Это NU.
Вот смотрите, мы когда говорили про абсолютную непрерывность, мы ее понимали в смысле
абсолютной непрерывности относительно классической меры Лебега. Когда мы говорили,
что распределение является абсолютно непрерывным, то мы имели в виду, что существует плотность,
то есть такая функция, что вероятность любого множества равна интегралу этой функции по
классической мере Лебега. Здесь у нас вместо классической меры Лебега произвольная конечная,
ну в нашем случае, вероятностная мера P. В принципе, то же самое можно определять и для
сигмаконечных мер, то есть для классической меры Лебега и для других сигмаконечных мер.
И вот понятие абсолютной непрерывности в общем смысле, это именно оно, именно то,
что здесь написано. То есть вот та абсолютная непрерывность, к которой мы привыкли, это на
самом деле просто, если классическая мера Лебега множество равна нулю, то и из этого следует,
что и вероятность этого множества тоже ноль. Это то же самое, что существование плотности.
Существование плотности равносильно тому, что мера абсолютно непрерывна, то есть для любого
множества классической меры Лебега, которого равна нулю, и вероятность этого множества тоже ноль.
Вот, и правильно абсолютно непрерывность воспринимать именно в этом смысле. Именно в том смысле,
что... Сейчас, что я тут написал? А, я вас немного запутал, прошу прощения. Значит, я уже теорию
родон Никодима формулировать, хотел сначала определить абсолютную непрерывность. Сейчас я
исправлюсь. Понятие абсолютной непрерывности – это то, (*.р.у.) чую сейчас объяснял, а это то,
что я написал ниже, это уже формулировка теории родон Никодима. Сейчас я исправлюсь,
прошу прощения. Значит, понятие абсолютной непрерывности следующее. Здесь у меня было
здесь у меня было понятие заряда, а здесь абсолютные непрерывности.
если из того, что для любого ASG из того, что
P от A равно 0, следует, что у него от A тоже равно 0. вот, понятие абсолютной непрерывности
нужно воспринимать именно вот так. меры ню, заряд ню абсолютно непрерывен
относительно меры P, если из того, что мера P равна 0, следует, что заряд равен 0. вот, и то же
самое касается и нашей привычной на абсолютную непрерывности, когда мы говорим про абсолютную
непрерывность распределения, мы говорим, что если классическая мера либега равна 0, то и тогда
распределение тоже равно 0. и по теореме радона никодима это то же самое, что существование
плотности. что теперь утверждает теорема радона никодима? теорема радона никодима утверждает,
что существует плотность, то есть существует такая измеримая функция. какое условие теоремы?
да, сейчас я все объясню. вот это условие теоремы. значит, мы говорим, что такой заряд, потом говорим,
что такой абсолютно непрерывный заряд. и после этого мы говорим следующее, что теорема радона
никодима утверждает, что если заряд является абсолютно непрерывным относительно p,
если nu абсолютно непрерывным относительно p, то существует плотность, то есть существует такая же
измеримая функция, что для любого события из g заряд на этом событии совпадает с интегралом от
плотности. то есть иными словами, но понятно, что в другую сторону это тоже верно. если у вас
существует плотность, то из этого будет следовать, что мера абсолютно непрерывна. потому что если вы
возьмете вот в этом равенстве, если вы вот в этом равенстве рассмотрите какое-то множество a такое,
что его мера равна нулю, то интеграл от любой функции по этой мере тоже будет равен нулю.
поэтому если существует плотность, то тогда верное определение абсолютно непрерывной, из того,
что p от равны нулю следует, что nu от равны нулю. поэтому это равносильные вещи, существование
плотности и определение абсолютной непрерывности. еще раз провожу параллель с известной нам
абсолютно непрерывностью вероятностной меры, которая говорит, что распреяние вероятности
является абсолютно непрерывным, если существует плотность. Здесь написано в
точности то же самое, но для более общего случая. Еще раз поясню, что можно
абсолютно непрерывность и вот в нашем обычном случае воспринимать точно так же.
Говорить, что мера абсолютно непрерывна, если из того, что классическая мера или
бега равна нулю, следует, что вероятность на меры равна нулю тоже.
Прошу прощения, что немного запутал, но надеюсь, что разобрались. Если какие-то
вопросы по определению заряда абсолютно непрерывности и по формулировке теоремы
Радона-Никодима.
Ну, в общем, из этого сразу следует, что существует условным от ожидания.
Более того, в теореме Радона-Никодима можно добавить единственность, то есть
можно здесь написать существует единственная функция g. И вот эта единственность, ее надо
воспринимать в смысле почти наверно. Единственность нули или почти всюду
единственной, в зависимости от того вероятностной меры у вас или нет. Вот здесь это почти
наверно. Единственность, то есть это единственность, единственность p почти
наверное. То есть, какие бы вы не взяли две функции g, которые являются плотностями,
вероятность того, что они совпадают, будет равна единице. Из этого сходу следует, что
условное от ожидания x при условии g существует и единственно p почти наверно. Во-первых, существует,
во-вторых, какие бы два вы условных от ожидания не взяли, они с вероятностью 1 будут совпадать.
Давайте увидим, что действительно это следствие стереомародона Никодима.
Рассмотрим заряд
NUATA, который определен следующим образом. NUATA совпадает с мотожданием ксина индикатора.
Счётная дитивность очевидна и залегийность математического ожидания.
Можно вопрос? А мотождание берётся у кси или у кси индикатора?
В определении математического ожидания то же самое.
Во-втором, случая пастелского. Смотрите, когда мы пишем мотождание произведения, например,
мы пишем мотождание произведения случайных величин x1, x2. Иногда пишем, иногда не пишем.
Вообще скобки можно опускать. Вот такая запись означает мотождание произведения
случайных величин. То есть это то же самое, что мотождание произведения.
В том случае, когда вы хотите умножить случайную величину на мотождание, вы обязаны писать вот так.
А если вы хотите взять мотождание произведения, то скобки ставить необязательно.
Поэтому, когда скобки не стоят, нужно воспринимать, как мотождание применённое к произведению
случайных величин. Итак, рассмотрим такую функцию NU, которая действует из JVR.
Издал следующим образом. На событии A она просто совпадает с мотожданием от произведения кси индикатора.
Понятно, что она является зарядом. Это сходу следует из линейности математического ожидания.
Это заряд.
Более того, этот заряд абсолютно непрерывен относительно P. Действительно, если P от R равно нулю,
то и мотождание кси индикатора тоже равно нулю.
А следовательно, по определению, NU абсолютно непрерывный заряд относительно вероятностной меры P.
Тогда по теории миродомника Дима существует единственная, опять единственность, напомню,
что подразумевает смысл P почти, наверное, функция J, которая действует из-за мега в R,
который является J измеримой. И такая, что для любого ASG NU от A, который в свою очередь совпадает
с мотожданием кси индикатора, по определению NU от A, равно интегралу по A от JDP.
Ну что такое интеграл от A по JDP? Это есть ничто иное, как мотождание от J на индикатора.
Да, J это случайная величина.
J это случайная величина, поэтому мы вправе здесь поставить просто математическое ожидание.
А это и есть в точности определение условного мотождания.
Да, J это действительно просто условно мотождание от кси при условии J.
По определению условного мотождания, должна быть J измеримая функция, такая, что для любого ASG выполнут
это равенством от ожидания от кси индикатора, равно от ожидания от этой функции на индикатора.
А знаете, J действительно условно мотождание, т.е. следствие доказано.
Есть какие-то вопросы?
А единственность?
Ну вот потеряемая радона никодима, это функция единственная.
Да, то есть, значит, еще раз, вот мы получили вот это равенство.
У нас существует единственная функция, такая, что выполнено вот это равенство.
Вот эта штука равно вот этой штуке.
Такая единственная. Это как раз ровно определение условного мотождания.
Так, хорошо, давайте теперь поговорим про свойства условного мотождания.
Значит, с существованием единственности мы разобрались, пример привели.
Есть некоторые специфичные свойства, которые мы для обычного математического ожидания не утверждали,
которые очень удобно используют для вычисления условного мотождания.
На семинарах будете делать, мы сейчас тоже пример разберем.
Но есть свойства, которые копируют свойства обычного мотождания.
Давайте в общем все в порядку.
Так, ну во-первых, что будет, если в качестве сигма-алгебры G выбрать саму сигма-алгебру F?
То есть, что будет, если посчитать мотождания от Xi при условии F?
Я напомню, что Xi это случайная величина, которая задана на сигма-алгебре F.
Отверждают, что это просто Xi.
И это совершенно естественно, вы берете всю полноту информации,
то есть вы вообще ни почему не усредняете.
Вы вот на какой сигма-алгебре у вас задана случайная величина, вы по той сигма-алгебре ее усредняете.
Поэтому должна остаться сама случайная величина.
Давайте это увидим, что это следует из определения.
Ну, во-первых, должна быть F-измеримость, раз вы мерите условные мотождания при условии сигма-алгебре F,
то должна быть F-измеримость, которая есть по определению Xi.
Xi F-измеримо, поэтому здесь все OK.
Значит, теперь нам нужно проверить, что для любого A из F
мотождание от нашего условного мотождания
совпадает с мотожданием от кси на индикатора.
Ну, это понятно, потому что просто проверяем, что условное мотождание от кси при условии F равно кси.
Мы ровно это и проверяем.
А значит, это равенство выполнено, что это ее, то есть это очевидно.
Хорошо, теперь что будет, если сигма-алгебра, которая стоит в условии, не зависит от F?
Значит, пусть G и F независимы.
Или давайте даже для общности пусть G не зависит от кси, то есть от сигма-алгебры,
порожденной случайно-величной кси.
Я напомню, что сигма-алгебра, порожденная случайно-величной кси, это есть минимальная сигма-алгебра,
которая содержит все… ну даже можно просто сигмы не писать, можно взять просто все прообразы,
баррельских множеств, и вы получите сигма-алгебру.
То есть просто система прообразов всех баррельских множеств, система прообразов всех баррельских множеств,
это сигма-алгебра и называется на Fx.
Так вот, если G не зависит от Fx, то тогда условное мотождание кси при условии G равно мотожданию кси.
Ну это может быть интуитивно, не настолько очевидно, хотя если задуматься, кажется,
что действительно должно быть так.
Да, если вы меряете условное мотождание при условии какой-то информации,
которая никак не зависит от кси, то кажется, что условное мотождание должно быть одинаковым
для всех событий из этого G.
Ну раз есть независимость, то оно не должно зависеть, то есть оно должно быть одинаковым.
Но если все мотождание целиком, если вы усоедините вообще по всей Омега,
совпадает с мотождание кси, то тогда это ровно должно быть вот это число,
которое одинаково для всех событий.
Да, то есть кажется, что это вполне логично, что так должно быть, давайте докажем.
Ну константы измеримы относительно любой сигма-алгебры, поэтому тут проверять нечего.
Мотождание кси является же измеримым.
Вот, теперь берем любое ASG и хотим проверить, что вот наше, то что мы подозреваем на роль
условного мотождания, если мы усредним его произведение на индикатора, то получим
просто мотождание кси на индикатора.
То есть хотим, чтобы мотождание от мотождания кси на индикатора совпадало с мотожданием
кси на индикатора.
Ну по линейности вы можете мотождание кси вынести и получите мотождание кси умножить
на мотождание от индикатора.
С другой стороны, в силу того, что кси и индикатора независимы,
мотождание произведения равно произведению мотождания, то есть это мотождание
произведения кси на индикатора, что и требовалось.
Да, получили то, что требовалось, а значит, действительно мотождание кси
константа подходит на роль условного мотождания.
Почему индикатор A и кси независимы?
Ну потому что G и F кси независимы.
Мы взяли A и G.
Значит, что означает, давайте вспомним, что означает независимость систем событий.
У нас есть две системы событий G и F кси.
Когда мы пишем, что G и F кси независимы, мы имеем в виду, что,
какие бы мы ни взяли два события из G и F кси,
один из G, а два из F кси.
Верно, что вероятность их пересечения равна произведению вероятностей.
Я утверждаю, что из этого следует, что кси не зависит от индикатора A.
Значит, кси не зависит от индикатора A.
Тогда и только тогда, что означает, что две случайные величины независимы.
Значит, какие бы вы ни взяли два баррельских множества,
вероятность попадания в эти баррельские множества двух случайных величин
равна произведению вероятностей.
Ну, попадание в баррельское множество индикатора – это, на самом деле, что-то тривиальное,
потому что индикатор равен либо единице, либо нулю.
Надо проверять для двух случаев.
Один – это когда индикатор равен единице, другой – равен нулю.
Давайте… Хорошо, я напишу для общности все здесь.
Значит, это тогда и только тогда, когда вероятность того, что кси принадлежит B…
И индикатор A равен единице, равно произведению вероятностей.
Ну и что то же самое, вероятность прообраза множества B,
то есть P от кси минус 1 от B, умножить на P от A.
И с другой стороны еще то же самое должно быть верно для индикатора A равно нулю.
Такая вероятность равна произведению прообраза множества B умножить на вероятность дополнения
А. И это должно быть верно для любого B-баррельюсского.
Но это очевидно верно, то есть вот из первой строчки следует вторая строчка.
Да, потому что в первой строчке написано, что вероятность пересечения любых двух множеств A1, A2 из fx, равна произведению вероятностей.
А A2 у нас уже попало в fx, то есть если вы посмотрите на кси принадлежит B, то есть не что иное, как кси минус 1 от B.
А если вы посмотрите на индикатор A равно нулю, то есть не что иное, как просто A-дополнение.
Поэтому здесь и в первой и второй строчке написано просто пересечение двух множеств.
Первое взятое из сигма алгебры g, второе взятое из сигма алгебры fx.
И вероятность их пересечения равна произведению вероятностей.
Из того, что g в x независима, следует в частности что x и индикатора независима.
Быле общonic у вас есть 2 сигма алгебры, которые независимы.
Это тоже самое, что случайная величина, для которой эти сигма алгебры появляются порожденными, является независимой.
То есть говорить про независимость случайных величин и говорить про независимость порожденных сигма альгебр – это равносильная вещь.
Так, есть еще какие-то вопросы. А вот еще вопрос по первому равенству в доказательстве. Разве тут мы
не используем то равенство, которое хотим доказать? Не, смотри, может быть не очень аккуратно написано,
смысл в общем. Мы проверяем, значит, интегральное равенство. Да, мы проверяем, что левая часть вот
этого вот этой длинной сфочки совпадает с правой. Я здесь имею в виду следующее. Я говорю, я говорю,
что возьмем на роль условного мат ожидания вот наше гипотетическое значение. Мы с вами
предполагаем, что условное мат ожидания совпадает с екси. И вот давайте попробуем проверить,
так ли это. И вот в этом мат ожидания подставим, давайте я не пишу вот это равенство, я имею в виду
подставим на роль условного мат ожидания подставим мат ожидания к��, просто мат ожидания кси и
проверим, правда ли что после этой подстановки у нас получится требуемое. То есть еще раз,
когда мы проверяем, что некоторая случайная величина подходит на роль условного engages,
что мы делаем? Мы сначала проверяем, что это случайная величина является же измеримой,
если это так, то после этого мы подставляем в наше интегральное равенство из определения
условного отжадания, подставляем вместо условного отжадания случайную величину и
проверяем то, что получилось в итоге отжадания ктиной индикатора.
Хорошо, спасибо. Вычислить это никак нельзя, можно только таким угадыванием.
Вы знаете, вот еще раз, когда мы в этом проекте свойствоговорим,
вычислять условным отжаданием мы скоро научимся, во многих ситуациях, не во всех, но во многих
научимся. Когда мы здесь говорим про свойства, эти свойства не на самом деле очевидны. То есть я
все время, когда пишу свойства, я говорю интуицию, почему должно получиться так, и в каком смысле это
угадывание. Но угадывание на слове довольно строгой интуиции. И потом мы, после того,
как мы угадали, мы проверяем, что это действительно так. Но у нас будут в дальнейшем некоторые общие
теоремы, которые позволят в довольно общих случаях в условном отжадании. Читать в частности,
когда мы говорили про пример, то мы научились читать условным от ожидания. Вот у нас есть
конкретная формула для всех ситуаций, когда сигма алгебра порождена разбиением.
Так, свойства 3.
Мат ожидания от условного мат ожидания совпадает с обычным от ожидания. Но опять же,
это свойство выглядит вполне естественно. То есть одно дело сразу усреднить случайную
величину и найти мат ожидания к себе. Другое дело сначала усреднить его по каким-то подсобытиям,
потом усреднить это усредненное значение. Должно получиться одно и то же. Давайте
проверим, что это действительно так. Давайте в определении условного мат ожидания возьмем
a равное амета. Есть у нас в определении условного мат ожидания это интегральное равенство,
которое говорит, что мат ожидания от условного мат ожидания, умноженного на индикатор a,
совпадает с мат ожидания мат ксин индикатора. Но если в качестве a поставить ω, в левой
части этого равенства вы получите мат ожидания от условного мат ожидания умножить на индикатор
ω. Индикатор ω это просто единица на всех элементарных исходах, поэтому его можно
просто выкинуть и получить мат ожидания от условного мат ожидания. Далее по свойству
никакого свойства. Теперь обращаемся к правой части этого равенства. В правой части этого равенства
написано мат ожидания ксин индикатор а. Опять а меняем на ω. Это просто единица,
значит получаем мат ожидания кси. Все, смотрите, в правой части равенства, в самой правой части
равенства стоит мат ожидания кси, а в самой левой части равенства стоит мат ожидания
от условного мат ожидания, и они действительно получились равные, что и требовалось.
То есть очевидное следствие определения условного мат ожидания, если в качестве a взять множество g.
Четвёртое свойство, так называемое телескопическое.
Телескопическое свойство. Это свойство о том, что будет, если усреднить сначала
по одной сигнал г, а потом по другой. Представьте, что вы уже нашли условного
мат ожидания, а потом вы его ещё раз захотели усреднить, но теперь по какому-то другому,
какой-то другой сигнал г. Давайте рассмотрим ситуацию, когда эти сигнал г вложены, то есть пусть
есть g1 и g2, это какие-то две под сигнал г в, которые ещё и вложены друг другу.
Тогда
условное мат ожидания от условного мат ожидания от кси при условии g1,
при условии g2 совпадает. Неважно в каком порядке считать,
вы можете сначала усреднить по g2, то есть написать условного мат ожидания от условного
мат ожидания при условии g2, при условии g1. Это на самом деле то же самое, что усреднить сразу
по самой маленькой. На самом деле видно, что пункт 3 это частный случай пункта 4. То есть,
если вы усредняете по тривиальной сигнал г, то есть в качестве g2 вы выберете g1,
в качестве самой маленькой сигмалы, выберете сигнал г, который состоит только из пустого множества
и омеги, то пункт 4 просто превратится в пункт 3. Давайте докажем, что верно вот это телескопическое
свойство для произвольных ложных сигналгебов g1 и g2. Ну смотрите, какое из этих равенств
очевидно. Давайте сообразим. Очевидно совпадение самой левой части равенства, самой правой части
то есть я хочу сказать, что очевидно, что
условным от ожидания от условного от ожидания кси при условии g1 при условии g2
совпадает с условным от ожиданиям кси при условии g1. Почему я считаю, что это очевидно?
Ну, например, это очевидно следует из свойства 1. Значит, я считаю, что это верно просто по
свойству 1. Давайте вспомним, что такое свойство 1. Если усреднить случайную величину относительно
сигналгебры, относительно которой это случайная величина измерима, то останется сама случайная
величина. Теперь возвращаемся к свойству 4. Смотрите, условным от ожидания кси при условии g1,
вот которая здесь вот написана, когда мы первый раз берем условным от ожидания,
оно является g1-измеримым по определению. Это g1-измеримая случайная величина.
А g2 содержит в себе g1. Ну, если измеримо относительно меньше сигналгебры,
то тогда измеримо относительно больше сигмала. Значит, g2-измеримо тоже.
И вы как раз берете условным от ожидания при условии g2. Ну, значит, оно не поменяет случайную
величину. У вас просто остается в ожидании кси при условии g1. Поэтому то, что левая часть равенства
совпадает с правой, это очевидно. Давайте докажем, что второе выражение совпадает с третьим.
В первом свойстве у нас же было, что случайная величина действует из f.
Она действует из omega w, f это сигмалгебра. Там прообразы не различают g1 от g2.
Прообразы не различают g1 от g2. Конечно, это вот условным от ожидания кси при условии g1,
оно g1-измеримо. А g2 содержит все множества, которые есть в g1, и содержит еще какие-то
дополнительные. Ну, и плевать на эти дополнительные множества. Если прообразы всех бареллерских
множеств принадлежат g1, значит, они и g2 тоже принадлежат.
Так, теперь проверим, что
условным от ожидания от кси при условии g2 при условии g1 совпадает с от ожиданием кси при условии g1.
Первое, что нам нужно для этого проверить, это измеримость.
Смотрите, что мы хотим сделать. Вот у нас здесь вот это внешнее условное от ожидания,
вот это внешнее. Мы хотим проверить именно его определение. То есть мы хотим проверить,
что на роль вот этого большого условного от ожидания можно взять то, что стоит в правой части
равенства. То есть, во-первых, мы хотим проверить измеримость правой части равенства, измеримость
относительно чего? Ну, относительно вот этой сигма алгебры. Но это по определению. От ожидания
кси при условии g1 является g1 измеримой, случайно величиной. Да, поэтому все OK. В смысле измеримости
все OK. Вот это внешнее условное от ожидания, которое стоит в левой части равенства,
является g1 измеримой. Теперь нам нужно проверить интегральное равенство. Осталось проверить,
что для любого ASG1. Значит, мат ожидания от того, что мы хотим взять на роль условного
мат ожидания, то есть вот мат ожидания кси при условии g1 умножить на индикатора,
совпадает с тем, что мы усредняем. А усредняем мы вот то, что у нас тут стоит в левой части равенства.
Вот эту штуку мы усредняем, то есть должна совпасть с мат ожиданием от условного
мат ожидания от кси при условии g2 на индикатора. Вот что мы хотим.
Ну смотрите, так как APRING g1, то по определению условного мат ожидания,
условного мат ожидания от кси при условии g1 на индикатора совпадает
с мат ожиданием кси на индикатора. Это просто определение условного мат ожидания при условии g1.
Но g1 вложено в g2. Значит, так как g1 вложено в g2, то а еще и g2 принадлежит. А следовательно,
по определению условного мат ожидания при условии g2, вот такое мат ожидание тоже совпадает
с мат ожиданием кси на индикатора. Ну все, мы получили знать, что эти вещи одинаковые, что и тревога.
Есть какие-то вопросы?
Движемся дальше. Эти все свойства были специфичны. Именно вот для обычного мат ожидания
нас ничего подобного не было. Теперь мы разберем несколько свойств, которые были точно такие же
для обычного мат ожидания. Во-первых, неравенство, сохранение неравенства. Если кси1 меньше
от кси2 почти наверное, то и мат ожидания кси1 при условии g меньше оно, чем мат ожидания кси2
при условии g почти наверное. А почему здесь почти наверное сохраняются? То есть мат ожидания
уже усередняет? Это же тоже случайная величина? Ну вы скажете, что мы когда писали про равенство,
то мы почти наверное не писали, а тут написали. Но смотрите еще раз, когда я писал про равенство,
то я на самом деле когда писал про равенство, я просто подразумевал принадлежность к классу
эквивалентности. То есть когда я пишу, что условно мат ожидания равно чему-то, я имею в виду,
что правая часть этого равенства принадлежит к классу эквивалентности, который называется
условно мат ожидания. Условно мат ожидания можно подразумевать как класс эквивалентности.
Здесь имеется в виду что если я возьму произвольного представителя и из одного
класса эквивалентности, возьму произвольного представителя и из другого класса эквивалентности,
то есть возьму какую-то случайную чему которая спадает с условным от ожиданиям кси1 при условии g,
и возьму другую случайную чему которая сtopодает с условным от ожиданиям кс 2 при условии g,
то окажется что это нерая совершенность веротstatности 1. Вот что здесь имеется в виду.
Так, ну как это доказать? Смотрите, вот эти две случайные величины, мотожидание x1 при условии g
и мотожидание x2 при условии g, они являются же измеримыми по определению, условному от ожидания.
Поэтому на самом деле для этого неравенства у нас такое свойство мотожидания было, из которого
это следует. Значит, для вот этого неравенства мотожидание x1 при условии g меньше, чем мотожидание
x2 при условии g почти, наверное. Достаточно,
достаточно, чтобы для любого ASG
мотожидание x1 при условии g на индикатор A и от этого все мотожидание.
Было меньше набрано, чем мотожидание от условного мотожидания x2 при условии g на индикатора.
Да, мы знаем, что если для двух случайных величин, которые являются же измеримыми,
справедливо такое неравенство, то есть какое бы ни взяли множество ASG, мотожидание от первого
на индикатора меньше, чем мотожидание второго на индикатора, из этого следует, что между
случайными величинами с вероятностью x1 такое же неравенство. Вот, ну давайте и собственно это докажем.
Давайте докажем последнее неравенство, то есть возьмем ASG
и прям проверим, то есть сначала напишем левую часть неравенства, мотожидание от
условного мотожидания x1 при условии g на индикатора.
По определению условного мотожидания, это есть мотожидание от x1 на индикатора.
Дальше, так как x1 меньше равно, чем x2, эта штука меньше набрано, чем от ожидания x2 на индикатора.
В свою очередь, по определению условного мотожидания от x2, последнее мотожидание
совпадает с мотожиданием от условного мотожидания x2 при условии g на индикатора.
Так, следующая линейность.
Линейность, значит мотожидание от c1 x1 плюс c2 x2 при условии g равно c1 на мотожидание x1 при условии g
плюс c2 на мотожидание x2 при условии g.
Ну, то есть, как мы проверяем подобные утверждения?
Мы хотим просто доказать, что то, что стоит в правой части равенства,
подходит под определение условного мотожидания случайно-вечной, которая стоит в левой части равенства.
Ну, же изменимость правой части очевидна по определению.
Значит, вот эта вот линейная комбинация c1 мотожидание x1 при условии g плюс c2 мотожидание x2 при условии g,
она является g измеримой, случайно-вечной.
Поскольку постольку мотожидание x1 при условии g и мотожидание x2 при условии g являются линейными измерениями,
значит их линейная комбинация является g измеримой.
Теперь нужно проявить равенство интегральное, то есть взять ASG
и посмотреть, что будет, если на роль условного мотожидания подставить правую часть равенства нашего,
то есть c1 на e x1 при условии g плюс c2 на мотожидание x2 при условии g.
И умножить это все дело на индикатора.
То есть мы хотим проверить, что действительно эта линейная комбинация подходит на роль условного мотожидания,
то есть проверить, что эта штука совпадет с мотожиданием от c1 к c1 плюс c2 к c2 на индикатора.
Ну, пользуемся обычной линейностью, обычным мотожиданием.
Получаем c1 на мотожидание от произведения условного мотожидания x1 при условии g на индикатора,
плюс c2 на мотожидание от произведения условного мотожидания x2 при условии g на индикатора.
Теперь в силу определения, условным от ожидания, первое
от ожидания совпадает с от ожиданиям от KC1 на индикатора,
второе от ожидания совпадает с от ожидания от KC2 на индикатора,
новое пользуясь линейностью, получаем от ожидания от
C1 к C1 плюс C2 к C2 на индикатор А, что и требовалось, да,
значит, что и свойство тоже доказано, есть ли какие-то
вопросы.
А вот индикатора попадает в от ожидания или нет?
Да-да, еще раз, когда мы пишем от ожиданий, дальше стоит
произведение случайных причин.
Так, далее, модуль, значит, от ожидания от модуля
к C при условии G меньше собрано, чем модуль от условного
от ожидания к C при условии, наоборот, больше собрано,
больше собрано, чем модуль от условного от ожидания
к C при условии G.
Ну, это свойство 5, да, то есть это очевидно следует
из свойства 5, где у нас были неравенства.
Значит, смотрите, к C лежит между модулем к C и минус
модулем к C, конечно, к C лежит между модулем к C и минус
Поэтому по свойству 5, правда же, 5, да, по свойству 5 из этого
следует, что от ожидания от минус модуля к C при условии
G меньше собрано, чем от ожидания от к C при условии G и меньше
собрано, чем от ожидания от модуля к C при условии G.
Теперь по свойству 6, в этой цепочке не равен самое
левое выражение, в нем минус можно вынести и получится
минус от ожидания от модуля к C при условии G меньше собрано,
чем от ожидания к C при условии G меньше собрано, чем от ожидания
от модуля к C при условии G.
Это есть именно то, что требуется, да, это в точности означает,
что модуль от ожидания меньше собрано, чем от ожидания
модуля.
Что это требуется?
Так, есть какие-то вопросы?
У нас было там почти, наверное, здесь, соответственно,
почти, наверное...
Здесь даже более сильное, да, здесь просто нерайство
верно для всех элементарных исходов без звучания.
То есть, в частности, почти, наверное.
Так, ну, кстати, не совсем я, правда, сказал.
Вот когда мы говорим, смотрите, про вот это нерайство,
про вот это нерайство, когда мы говорим, то вот это
нерайство, конечно, верно для всех элементарных исходов
без исключения.
Здесь давайте все-таки напишем в том, что мы утверждаем,
давайте напишем почти, наверное.
Поскольку, постольку еще раз напомню, что условным
от ожидания это класс эквивалентности.
Мы можем там на одном элементарном исходе попортить
левую часть или правую часть, каким нам хочется
образом, да, если возьмем какой-то элементарный
исход, которого есть, вероятность которого ноль,
то на нем мы можем что левую часть, что правую часть
задать как угодно, от этого они, для них останется
верным условным от ожидания, нерайство может в принципе
не быть.
Поэтому, да, правильно, вот в самом свойстве правильно
написать, конечно, почти, наверное.
Спасибо.
Так, теперь аналог тирем или бега, и мы жарим
исходимости.
Значит, если ксиен стремится кси почти, наверное, да,
то есть если вероятность того, что ксиен стремится
кси, равна единице, и что еще надо?
Все ксиенты по модуле не превосходят какой-то случайной
величины.
И мы от ожидания это конечна.
То тогда мы от ожидания ксиен при условии g стремится
к мы от ожидания кси при условии g.
Но доказательства в каком-то смысле аналогичны доказательств
тирем или бега, позвольте мне это оставить без доказательства.
Вместо этого мы восьмой пункт не будем никогда
использовать, в общем, он нам особо без надобности,
он нам единственное зачем нужно для того, чтобы доказать
девятый пункт.
Очень важное свойство, которое мы постоянно будем
использовать при учтении условного от ждания.
Оно следующее.
Если случайная величина g измерима,
то тогда условного от ожидания от произведения
кси это при условии g совпадает с это умножить на условном
от ожидания кси при условии g.
Я напоминаю, что когда мы говорим про условном от
ожидания, мы всегда считаем, что от ожидания обычное,
конечное.
То есть мы рассматриваем всю эту теорию только в
случае, когда случайная величина интегрирует,
то интеграл конечный.
То есть здесь, когда я пишу это равенство, я предположил,
что как от ожидания кси конечное, так и от ожидания произведения
кси, это конечное.
Самое сложное всех свойств, которые я тут написал,
давайте его за оставшиеся 10 минут попробуем доказать.
В общем-то, это последнее свойство, которое я хотел
сказать.
Значит, сперва докажем его для индикаторов.
То есть сперва докажем, что оно верно для это равное
индикатору множеству b, где b это некоторое баррелевское
множество.
В общем, баррелевское b принадлежит, давайте это
A будет.
A принадлежит G.
Да, то есть на множестве A единица случайная величина,
а вне множества A ноль.
Вот, хорошо.
В этом случае A не всегда баррелевское, правильно?
A это никакое не баррелевское множество, потому что A
это под множество Омега, а не R.
Я говорился.
Значит, забыл сказать, что я хочу проверять это исключительно
интегральное равенство.
G измеримость очевидна.
То есть еще раз, когда я хочу проверить, что условным
от ожидания чему-то равно, я просто проверяю, что правая
часть подходит под определение условного от ожидания.
Так вот эта правая часть, это умножительное от ожидания
x при условии G, она очевидно же измерима, потому что
это произведение двух же измеримых функций.
Поэтому, как обычно, измеримость проверять не нужно, проверяем
сразу интегральное равенство.
Для интегрального равенства сперва рассмотрим простейший
случай, когда случайная величина это индикатор
какого-то измеримого множества.
Тогда, что хотим проверить?
Хотим проверить, что какой бы мы не взяли A с валлой
из G,
должно быть выполнено интегральное равенство.
То есть подставляем на роль условного от ожидания
нашу правую часть.
То есть это нам от ожидания x при условии G,
умножаем это на индикатор A с валлой.
Нам нужно проверить, что это от ожидания совпадет
с от ожидания от x на это на индикатор A с валлой.
Тогда мы действительно докажем нашу равенство.
Я напоминаю, что это индикатор A.
По тому, как мы взяли это.
И вот тут внутри этого всего длинного произведения
есть индикатор A и индикатор A с валлой.
Когда их перемножаю, получаю индикатор пересечение.
В результате, это есть от ожидания от условного
от ожидания x при условии G,
индикатор пересечения.
И так как A и A с валлой принадлежат G,
то их пересечение тоже принадлежит G.
А значит, по определению условного от ожидания,
это в точности от ожидания от x на индикатор пересечения.
Это по определению условного от ожидания x при условии G.
Теперь снова эти два индикатора раскрываем.
То есть, вместо индикатора пересечения
напишем произведение индикаторов.
Индикатор A на индикатор A с валлой.
У нас индикатор A это в точности это.
Значит, мы получаем от ожидания от x на это,
на индикатор A с валлой, что и требуется.
Да, это в точности наше интегральное равенство.
Поэтому можем переходить к следующей ситуации,
когда случайно влечена эта простая.
То есть, эта равна сумме по i от 1 до n
с i t на индикатор i t,
для некоторых i t из G
и с i t из G.
Вот. Ну, линейность просто.
Значит, берем от ожидания от это
на от ожидания x при условии G
на индикатор A с валлой опять.
Значит, по линейности это совпадает,
по линейности от ожидания это совпадает
с суммой по i от 1 до n.
Целью, что мы получаем,
от ожидания от индикатора i t
на от ожидания x при условии G
на индикатор A с валлой.
Для вот этих вот индикаторов уже все доказано.
То есть, мы воспользуемся предыдущим пунктом
и получим просто сумму по i от 1 до n
с i t на от ожидания x
на индикатор i t и на индикатор A с валлой.
Снова по линейности.
Теперь заносим коэффициенты из суммы
внутри от ожидания.
Получаем требуемое.
То есть, мы от ожидания x
это на индикатор A с валлой.
Ну и наконец, последний пункт.
Это произвольное.
Что мы знаем?
Мы знаем, как мы определяли
обычное от ожидания.
Мы приближали простыми функциями.
Мы знаем, что произвольную
случайную величину можно приблизить
простыми функциями.
Значит, существует последовательность
это-энте, которая стремится к это.
Значит, все это-энты, они простые.
То есть, равны вот этим конечным
суммам из предыдущего пункта.
И к тому же, что мы делаем
из предыдущего пункта.
И к тому же, они все по модуле
не превосходят это.
Давайте это произвольное
и не отрицательное.
Давайте так.
Пусть модуль это-энты
не превосходит модуле это.
Вот так.
Вот так вот мы умеем делать.
Мы умеем приближать простыми
такие, что их модуль
не превосходит модуле это.
Вот, хорошо.
Хорошо.
Тогда патиоремия Либега,
точнее, не патиоремия Либега,
а по пункту 8.
По свойству 8.
Мы с вами знаем, что
мотожидание
кси на это-эн, при условии g,
стремится к мотожиданию
кси на это, при условии g.
Да, так как это-эн
стремятся к это,
то тоже самое верно
и для кси это-эн.
Да, мы знаем, что кси это...
Только, извините, у нас же
в условиях пункта 8
нужно, чтобы модуль это-эн
был меньше равен чем это.
Может быть, там все-таки стоит
это взять, не отрицательно.
Сейчас, подождите, смотрите.
Во-первых, у нас есть сходимость
почти наверно, и вот это.
Во-вторых, у нас есть, что модуль кси
на это-эн меньше либо равно,
чем модуль кси на это.
И в-третьих, у нас есть, что мы от
ожидания модуля кси это-эн меньше бесконечности.
Да, так сказал Уско.
Этого достаточно, чтобы делать
утверждение про сходимость модуля к модулю,
но для сходимости
самих величин к...
Вот я же говорю,
можете промотать вверх до условий
8-го звезда.
Там должно быть, чтобы модуль кси
это был меньше или равен самого это,
а не его модуле.
Что такое само это? Здесь это какая-то
случайная вещь. Наоборот, должно существовать.
Она никак не связана со всем, что
написано в остальных местах.
То есть, давайте вместо это
напишем большое...
Да, значит, хорошо.
Вот есть такая сходимость.
Теперь что? Теперь
по уже доказанному выше,
по предыдущему пункту мы знаем,
что мод ожидания кси
на это-эн при условии g
совпадает с это-эн
на мод ожидания кси при условии g.
Это мы в предыдущем пункте доказали.
С другой стороны, левая часть этого неравенства
стремится...
Здесь везде имеет в виду
почти наверно стремится.
Я вот набишу на стрелочкуinto здесь
почти наверно. То есть, имею в виду, что
вероятность этойiderman Rubies
стремится к единице.
Также здесь надо было написать...
Прошу прощения.
С вероятностью 1 стремится
или иными словами, вероятность
стремление равна единице здесь тоже самое.
Когда я пишу на стрелочке почти наверно,
я имею в виду, что вероятность этой
сходимости равна единице.
Левая часть этого неравенства почти наверно
стремится по моду от kslov custom
кроме того мы знаем что это n стремится к это мы так выбрали поэтому правой части равенства тоже
почти наверное даже без почти наверное вообще по точечно стремится к это нам от ожидания x при
условии g, ну а значит есть разница с вероятностью единицы да значит из этого сходу следует то что
нам нужно от ожидания x это при условии g совпадает с это умножить нам от ожидания x при условии g что и
требуется. Есть какие-то вопросы?
Так, ну вот это все свойства которые я хотел рассказать, хотел еще успеть разобрать пример
с применением всех этих свойств но уже разберем в следующий раз на ближайших семинарах не знаю у кого-то
там контрольная сперва у кого-то условным от ожидания сперва вы будете разбирать примеры на
применение этих свойств ну и мы на следующей лекции тоже такой пример разберем так если есть еще
Можно по прошлой лекции один вопросик? Да, пожалуйста. Можете открыть вот неравенство Маркова, по-моему? Да,
пожалуйста. Вот мы там когда считаем мат ожидания сейчас вот первое исследование вот у нас тут
получается типа переход от мат ожидания к вероятности? Да, это вот это равенство. А где мы
его вводили? Ну то есть мы писали типа барреливская функция, да? Ну было свойство для
барреливской функции, это оно? Вы спрашиваете почему это равенство верно? Ну я понимаю это у нас
вроде было во витме, но я просто не нашел где мы здесь это обозначали. Сейчас, подождите значит не
всем понимаю чего говорить про барреливские функции здесь очень простая мысль здесь берется мат
ожидания от случайной величины, которая понимает два значения 0 и а. То есть это простая функция. А,
ну да, окей. Ну хорошо. Окей? Да, да. Ага, еще какие-то вопросы? Можете еще раз я просто не всем
понял вначале, чем все-таки нужна нужна условная мат ожидания, то есть что она отражает вот как
случайная величина? Интуиция условного мат ожидания, да? Да. Ну вот помните я в конце прошлой лекции
пытался как-то это пояснить. Вот давайте представим себе такую ситуацию, что вы пытаетесь заработать на
каком-то финансовом инструменте, ну например на акциях. Вы торгуете, продаете, покупаете акции и
следите за тем, как изменяется цена акции во время. Вы естественно на основании ее изменения делать
какой-то прогноз. Ну например вы целый год следили за ее ценой и вот у вас есть эта история длиной в
год и вы там делаете прогноз, не знаю, на ближайшую неделю скажем. Вы говорите ну окей, значит у меня
есть вот эта вот история длиной в год. Я теперь скажу, что через неделю цена акции будет такой.
Получается, что ваш прогноз, какая цена акции будет через неделю, зависит от того какая была
история длиной в год. Если история такая, будет одна цена, если другая история, то будет другая
цена. Вы тем самым, вы усредняете, вы усредняете значение вашего актива через неделю при условии
того, что вы знаете, какое оно было за последний год. И получается, что цена вашего актива через неделю
это функция вот этой истории. История одна, средняя цена через неделю будет одна. История другая,
средняя цена через неделю будет другая. То есть вы получаете функцию от истории. Теперь если
вы считаете, что ваша история, все возможные истории, которые вообще бывают вот за один год,
это множество элементарных исходов, ваши элементарные исходы, это все возможные истории,
которые были через год. Вы тем самым, усредняете значение вашей случайной величины через неделю
при условии сигма-алгебры, порожденной вот этими всеми историями. И в зависимости от того, как та или
иная история, вы получаете разное функцию. Вы получаете новую случайную величину, которая равна
среднему значению вашей акции через неделю при условии того, какое было значение за последний год.
Сейчас, а мы же сигма-алгебру можем выбирать разную? Разную. Вот как выбор сигма-алгебры
соотносится с заданием последней истории? Значит, это сигма-алгебра, которая порождена всеми
возможными историями. Представьте, что ваша история – это случайный процесс. То есть,
у вас есть случайный процесс, который равен значению цены акции за последний год. И вы
рассматриваете сигма-алгебру, порожденную этим случайным процессом. То есть, вы рассматриваете
прообразы всех бареллевских множеств в смысле вашего случайного процесса. У нас понятий
случайных процессов не было, но если говорить формально, то есть у вас отрезок длиной в год.
У вас на этом отрезке задано значение случайного вашего процесса. Это значение акции. Время меняется
от 0 до единицы, в том смысле, что в течение года. Вы смотрите на самом деле в вашу сигму-алгебр
g. Это будут всевозможные прообразы. Вы будете брать x t1 в минус 1 от b1 пересечь x tn в минус 1
от bn по всем возможным моментам времени от 0 до единицы и по всем возможным бареллевским b1 bn,
еще и по всем возможным натуральным числам n. Вот это будет не что иное, как сигма-алгебра,
которая содержит всю вашу историю. То есть, это информация о том, какая у вас была цена
акции за последний год. Если вы относительно нее усредните, значение, теперь вы берете x t
плюс epsilon, это значение вашей акции через неделю относительно x1. Это значение вашей
акции через неделю после того, как прошел год, и усредняете ее относительно g. Вы получите в
точности, условным от ожидания при условии того, какая у вас была цена акции за последний год.
Вы знаете целиком значение график цены акции за последний год. Более на пальцах, то есть,
если не забегать к случайным процессам, вот я говорил сегодня про кубик. Представьте,
что вы сначала бросаете кубик, и вам говорят, вот вы сидите в одной комнате, а в другой комнате
человек бросает кубик. Этот человек очень честно бросает кубик, смотрит и говорит,
четное число выпало или нечетное. И вот это будет информация, которую вы обладаете,
четное или нечетное число выпало. Это будет ваш сигма алгебра, которая состоит из двух подножеств,
наименьше сигма алгебра, прошу прощения, которая порождена разбиением, состоящим из двух подножеств,
1,35 и 2,46. Если вы будете устранять значение, которое выбыл на кубике при условии сигма алгебра,
то получите 3 на индикатор нечетности плюс 4 на индикатор черности. Понятно более-менее?
Кажется, да. Получается, элементарный исход, который мы подставляем, чтобы получить
значение предсказания, это соответственно вот то, что последнее выпало, четное или нечетное?
Наверное правильнее говорить не элементарный исход. Мне тоже иногда говорили элементарный,
элементарный исход это вообще все, это 1,3,5,2,4,6. Это скорее атомарный исход. У нас есть атомы,
это множество, которые наш сигмал алгебру порождают, и тогда да, это либо нечетное выпадение
числа, либо нечетное выпадение числа. Ладно, хорошо, я, кажется, понял. Прекрасно. Спасибо.
Не за что. Какие еще вопросы? То есть в этом получается можем условным от ожидания посчитать
еще до того, как узнали, что выпало на кубике, четное или нечетное? Именно в этом и смысл.
То есть вы заранее рассчитываете условным от ожидания при условии всех возможных историй,
а потом уже в зависимости от того, какая история произошла, вы сразу говорите,
а окей, при вот таком значении истории будет вот такое вот значение среднего.
То есть вы заранее делаете прогноз при условии всех возможных событий, которые могли бы произойти.
Так, есть еще какие-то вопросы?
Вопросов нет? Прекрасно. Тогда до встречи следующего суббота. Всем присутствующим спасибо.
