Так, ну, на чем мы в прошлый раз остановились? Значит, ага, да, точно.
Такое, значит, функция распределения, мы с вами определили, что такое функция распределения,
и выяснили, что она однозначно задает распределение. Вот, давайте поговорим про ее свойства.
Дверь потом закройте, чтобы потише было, спасибо. Которые, ну, необходимые достаточные, да,
то есть эти свойства, с одной стороны, свойства функции распределения, с другой стороны,
если есть функция с такими свойствами, то она будет функцией распределения для некоторого
распределения вероятности. Значит, что это за свойства такие? Ну, они, вообще говоря,
практически очевидные, но дают некоторое наглядное представление о том, как выглядит
функция распределения. Значит, во-первых, она не убывает, во-вторых, она непрерывна справа,
и, в-третьих, предел в минус бесконечности равен нулю, а в плюс бесконечности единице.
Вот, давайте докажем, что действительно так сперва. Ну, неубывание понятно, да, это следует
из свойства вероятности, заключается в том, что если есть два множества, одно в другом содержится,
то вероятность первого не превосходит вероятности второго. И это как раз к нам относится, потому что
если мы возьмем два действительных числа х меньше чем у и посмотрим на f от у и на f от x,
то мы увидим, что f от у это есть вероятность интервала от минус бесконечности до у. Но в силу
того, что этот луч, он содержит в себе луч от минус бесконечности до х, то эта вероятность
больше чем равна, чем вероятность интервала от минус бесконечности до х, что есть f от х.
Да, то действительно мы получаем неубывание. Во-вторых, непрерывность справа. Ну, все предельные
свойства следует из непрерывности вероятности. Да, вы знаете, что если вы будете рассматривать
последовательность вложенных множеств и возьмете их пересечение, то вероятность этого пересечения
будет равным пределам вероятности. Это, в общем-то, и есть все вот эти вот и второе и третье свойства.
Ну почему так? Давайте непрерывность справа сперва. Смотрите, у нас функция не убывает,
поэтому нам достаточно взять любую последовательность. То есть я могу взять какую-то
последовательность xn, которая стремится к x справа, но я даже могу на самом деле взять ее вообще
не возрастающей. Да, то есть вот так вот я могу нарисовать, имея в виду, что вот эта последовательность
убывает. Убывает и стремится к x. То есть каждый следующий член, он меньше, чем предыдущий. Почему
достаточно такие последовательности рассматривать? То есть я сейчас хочу перейти к пределу. Да,
конечно, предел функции в точке xn равен значениям функции в точке x. Почему этого достаточно?
Потому что функции не убывают. Дальше, если я буду брать любую-другую последовательность,
то в силу монотонности функции у меня будет тот же самый предел.
Придел предыдущей мячности бесконечности f от xn. По определению, это есть предел вероятности.
Придел такой вероятности. И так у меня xn убывает, вот эти все, вот эти все лучи,
они вложены. Да, каждый следующий он меньше, чем предыдущий. И по непрерывности я могу перейти
к пределу и написать, что это есть вероятность пересечения всех этих лучей. То есть,
собственно, вероятность луча от бесконечности до x. Что есть f от x, что и требовалось. Понятно,
что такой же трюк с непрерывности слева не пройдет, потому что если вы возьмете,
наоборот, возрастающую последовательность и перейдете здесь к пределу,
у вас получится перейти к пределу, нет проблем, только будет вероятность объединения. У вас будет
лучи увеличиваться, и вы говорите, что тогда предел вероятности, это есть вероятность объединения.
Но вероятность объединения лучей вот этих вот замкнутых, это будет открытый интервал, то есть
точка x не будет включаться. То есть предел вероятности вот здесь будет равен вероятности
от бесконечности до x, не включая x. И если в точке x вероятность не нулевая, то это не будет равно f
от x, это будет строго меньше, чем f от x. Поэтому, в принципе, разрывы в каких-то точках могут быть.
Но мы об этом сегодня подробно еще поговорим про разрывы. Давайте третий пункт.
Ну, в принципе, аналогично. Например, чтобы доказать вот эту штуку, опять же, в силу монотонности f,
достаточно просто рассмотреть любую убывающую последовательность. То есть если я рассмотрю
последовательность, которая стремится к минус бесконечности и убывает, то по аналогичным
соображениям я получаю, что предел функции распления точке xn, это есть вероятность пересечения
всех этих лучей, это есть 0, это вероятность пустого множества. Они не пересекаются,
они вложены, но пересечение пустое множество. И то же самое с плюс бесконечности. Теперь,
если я рассмотрю возрастающую последовательность, то предел функции распления в точке xn, это есть
теперь вероятность объединения всех таких интервалов, а это вероятность всего r. То есть мы все такие
лучи объединим, мы получим все эти стыдные числа, и вероятность равна единице. Собственно,
все. Очевидные свойства, но вот несмотря на их очевидность, они являются важными, потому что они
говорят о том, что если мы возьмем произвольную функцию с такими свойствами, то она будет
функцией распления для некоторого распления вероятностей. Давайте это запишем.
Если у нас есть какая-то функция f, при этом можно сказать, что она пусть из r в r действует,
а не из r в 0,1, потому что за счет того, что она не убывает, есть третье свойство, она не может
выйти за границы отрезка 0,1, поэтому можно написать, что она действует в 0,1, можно написать в r,
это одно и то же. С точки зрения этой теоремы, если функция из r в r такова, что выполнено
свойство 1,3, то f является функцией распления для некоторого распления вероятностей.
Я не знаю, рассказывали ли вам в теории меры доказательств этой теоремы, но вам рассказывали
теорему о продолжении с меры с полукольца на кольцо, что-нибудь такое, на сигму алгебру, не суть.
Суть в том, что давайте просто положим, возьмем p и определим ее вот на этих лучах равной f
от x, это точно надо сделать, и увидим, что она после этого единственным образом продолжается,
но мы сначала ее сделаем конечно-аддитивной, в том смысле, что мы скажем, что вот у нас есть
конечное объединение интервалов, и вероятность их объединения будет равна сумме их вероятностей.
Я не хочу сейчас это аккуратно доказывать, чтобы не тратить время на такие технические вещи,
и сегодня будет еще ряд подобных утверждений, которые практически очевидны, то есть следует
из того, что вас было в курсе теории меры. Чтобы не тратить много времени, я просто буду
схематично объяснять, почему это так. Еще раз, мы говорим, что давайте вероятность, положим,
вероятность получает, есть f от x, определим вот так. Ну и дальше просто продолжим это на всю
сигму алгебру. Сначала мы увидим, что если мы возьмем любой интервал, так как вероятность должна
быть аддитивной, в котором b включается, а не включается, это будет f от b минус f от a.
Дальше мы скажем, ну хорошо, если у нас есть конечное объединение таких интервалов,
1b1 и так далее, akbk, я имею в виду, что эти интервалы не пересекаются,
то опять по аддитивности это должно будет быть равно сумме f от b и t, а минус f от a и t.
А дальше по теории о продолжении полукольца на кольцо мы продолжим нашу вероятность единственным
образом на всю сигму алгебру. Вот собственно и все, то есть понятно, что за счет того,
что вот эта штука не отрицательная, так у нас вероятность не убывает, то это определение будет
корректным. Вот, ну хорошо. Давайте теперь посмотрим на эти три свойства и поймем,
что они некоторым образом говорят о том, как может выглядеть график функции распределения,
ну как бы мы рисовали график такой функции, если мы его рисовали непрерывной, то он бы выглядел
вот так. Вот у нас есть единица, выше нее мы не уходим, мы приближаемся к нулю, а оттуда мы
приближаемся к единице, и функция должна не убывать. В принципе, ничто ей не мешает в какой-то
момент стать нулем, она не обязана прямо стремиться к нулю, она может в какой-то момент сравняться
с нулем и дальше просто быть равной нулю, а может и стремиться к нулю, может эта точка никогда не
достигать той же самой с единицей. Она не обязана быть разрывной, то есть в принципе мы можем где-нибудь ее
разорвать, нарисовать скажем вот так. Это тоже будет функция распределения. Вот, ну вот такие два
важных частных случая. Первый это непрерывный, а второй это когда у нее вообще нет никаких участков,
где бы у нее была производная не ноль, то есть я имею в виду когда она представляет в виде ступенек.
Первый случай это непрерывный, второй случай это дискретный. Давайте поговорим об этих двух случаях
отдельно. Начнем с дискретных распределений. Я сейчас поясню, почему это важный случай. Мы с ним
уже сталкивались, когда решали какие-то комбинаторные задачи. Значит, это случай, когда вся мера,
значит вся вероятность, она сосредоточена в не более чем счетном множестве точек. Ну например,
допустим, вы подбрасываете монетку десять раз, и у вас есть два в десятой степени разных исходов.
Выбрали все нули где-то в одном месте единичек, в двух местах единичек и так далее. Два в десятой
разных исходов. Ну вот такое распределение вероятности, там у каждого из этих два в десятой исходов будет
какая-то своя вероятность. Или подбросили кубик, или еще что-то произошло. Короче, допустим,
есть какое-то конечное количество исходов. Или оно может быть бесконечное, но счетное, и у вас
вероятности, они просто, то есть у вас есть атомы такие, в которых вероятность не нулевая,
а во всем остальном множество действительно числа 0. Вот это будет дискретное распределение
вероятности. Значит, пусть х не более чем счетное множество. Значит, распределение вероятности
P называется дискретным, если P от х равно единице. Вот, то есть, ну, правильно написать, наверное,
перенести вот это сюда. Здесь написать существует. Распределение дискретное, если для него найдется
какое-то множество не более чем счетного, не более чем счетное. Такая, что вся мера равна единице
на нем, а больше нигде нет ни по вероятности. Остальное имеет меру 0. Вот, ну давайте поймем,
как будет выглядеть функция распределения у дискретного распределения. Понятно, что нам
будет выглядеть вот так. Вот есть какие-то у вас точки, там пусик 5, скажем, в которых вероятность не
0. Во всех остальных точках вероятность 0. Что это значит? Ну, давайте еще раз посмотрим. А вот,
есть. Вот что такое функция распределения. Понятно, что если вот эта точка Y, она лежит левее всех
точек, где у вас вероятность не 0, то вероятность этого луча 0. То есть, чтобы вероятность была не
0, в него должны какие-то попасть точки, в которых она не 0. Поэтому вот до этой точки функция распределения
ведет себя вот так. Дальше, как только вы за эту точку заходите, то есть вы уже вот прямо смотрите
значение функции распределения в нем, уже одна точка в этот луч попала, в котором вероятность не 0.
У вас происходит прыжок. И если я назову эти точки X1, X2 и так далее, то высота вот этого скачка — это
в точности вероятность попадания в эту точку. Вот эта высота — это есть вероятность X1.
Какое-то множество, под множество действительно, действительно чисел счетные или конечные.
Вот у меня на рисунке здесь X большой состоит из пяти точек. X1, X2, X5. Да, то, где не 0 — вероятность
номера. Просто не 0, а вообще 1. То есть в каждой точке не 0, а в сумме 1. Дальше у вас понятно,
что до точки X2 опять идет просто горизонтальный отрезок, и в точке X2 происходит скачок ровно
на вероятность попасть вот именно в точку X2. То есть высота этого скачка — это вероятность X2.
Ну и так далее. И так далее. Если у вас точек всего 5, то в конечном итоге это станет единицей.
То есть это на уровне единицы идет. Это прямая. Куда будет вывели график пунктов распределения?
Понятно, что высота этих скачков может быть разная. Если вероятности разные, если эти
вероятности все одинаковые, то и все эти скачки тоже одинаковые. Ну и так, у вас
возможность X пусть состоит из каких-то действительных чисел X1, X2 и так далее.
И тогда ваше распределение однооднозначно задается вероятностью попадания в эти точки.
Ну с одной стороны понятно, что если вы знаете вероятность попадания в эти точки,
то вы однозначно рисуете функцию распределения, знаете вот эти прыжки и знаете эти значения —
знайте эти И или И. Поэтому вы однозначно рисуете функцию распределения,
сам Мы однозначно восстанавливаем все распределения вероятностей.
Ну на другой стороны — еще раз, если вы знаете вероятности всех этих точек,
вы можете просто восстановить вероятность любого множества.
Так, в какое бы баррельское множество ни взяли, вероятность попадания в него это
просто сумма вероятностей точек, вот этих X-ов, которые в этом множестве находятся.
Поэтому в случае дискретного расплетения еще более удобно смотреть на
вероятность этих точек, чем смотреть на функцию
распределения. Функция расплетения это функция, которая определена на
континуме точек, а тут будет просто последовательность, то есть счетная последовательность
задает однозначно расплетение вероятностей. Но давайте её как-нибудь
запишем. Пусть P от x и t это есть вероятность попадания в точку x и t. Ну и вот понятно,
что вот эта последовательность она просто однозначно задает распределение вероятностей.
Ну то есть, какой бы у вас ни было баррельовское множество, вы можете просто написать следующее.
Вероятность этого множества, это есть просто сумма вероятностей точек x и t,
которые в это множество попали. Сумма по всем i таким, что x и t попадает в P от x и t.
Ну и коль скоро у нас есть такая замечательная последовательность,
с помощью которой мы понимаем какое у нас распределение, давайте рассмотрим какие-то
примеры жизненные, в которых дискретное распределение возникает и будем их задавать
именно с помощью вот этих последовательностей.
Значит, примеры. Ну первое, что приходит в голову, это распределение Bernoulli,
первое, что мне приходит в голову, я имею ввиду. То есть подбрасывай мне одну монетку всего один раз.
Это распределение обозначается часто вот так. P это параметр распределения, какое-то число,
ну в отрезке или в интервале. Если 0 или 1 брать, то это получится тривиально какое-то распределение,
поэтому можно не брать. Будем считать, что P лежит в интервале от 0 до 1. И x это множество значений,
которые ваше спиление, в котором оно имеет нелёгую вероятность. Ну орёл или решка, или давайте 0 или 1.
0 или 1, вероятность единицы P, вероятность 0 или 1 минус P.
Ну понятно, как будет выглядеть функция распределения.
У вас будут две точки 0 и 1, в которых будет меняться значение. До 0 будет 0, а здесь станет 1 минус P,
а здесь станет 1. Есть какие-то вопросы? Хорошо.
Следующее на ум приходит равномерное распределение на любом конечном множестве.
Пусть ух это какое-то конечное множество под множество r, и распределение обозначается вот так.
У от х. Это обозначение равномерного распределения на множестве х. Что это за распределение такое?
Равномерное значит, что вероятности всех точек внутри х просто одинаковые. И отсюда понятно, в чём должно быть конечное.
Потому что если оно бесконечное, то получится вероятность всех точек просто 0, и тогда в своём будет 0.
Поэтому должно быть конечное. И как будет задаваться вероятность? Ну понятно, она должна быть одинаковая.
То есть единиц поедет на мощность х.
Но я не буду рисовать график, так понятно, что он будет выглядеть вот как-то так, и все вот эти вот скачки будут просто одинаковые.
Так, далее. Биномиальное распределение, у него два параметра n и p.
Что такое биномиальное распределение? Это просто количество решек, если вы n раз подбросили монетку.
Вот n раз подбросили, посмотрели сколько решек. У этого количества будет биномиальное распределение с параметрами n и p.
n – это какое-то натуральное число произвольное, это количество, сколько раз вы подбросили.
А p – это число 1 единицы, это вероятность решки при одном подбрасывании.
Что будет х носителем вашего распределения, где вероятности положительные?
Ну понятно, что это число от 0 до n, потому что у вас столько может быть решек, у вас не может быть их отрицательного количества, не может быть больше n.
И для любого х из их большого вероятность х – это что?
Да, c из n пока на p в степени k, на 1 – p в степени n – k.
Это я от c из n пока так написал, так тоже пишут.
Ну понятно, да, то есть это просто количество решек при n подбрасываниях монетки, если вероятность решки равна p.
Еще раз.
Да, спасибо, конечно.
Ну kx похоже, да, можно было и не заметить.
Да, вот так.
Хорошо, давайте еще.
Ну опять как-то вот так будет выглядеть, но уже будут вот эти вот скачки, они будут уже неодинаковые.
То есть у биномаильного распределения у него самая большая вероятность в середине.
То есть прыжок в середине будет большой, а к краям будут они все уменьшаться, уменьшаться, уменьшаться.
Ну схематично будет выглядеть, понятное дело, также функция распределения.
И теперь давайте еще раз берем пример какого-нибудь счетного носителя.
То есть здесь все ситуации были x-конечные, пусть теперь x-счетные.
Поговорим про Пуассоновское распределение.
Я сейчас сразу объясню откуда оно берется.
Вот, ну тут можно порассуждать на тему каких-то, какой-нибудь теорий массового обслуживания.
Там полезно оказывается Пуассоновское распределение.
Ну вот если есть очередь в Макдональдс, скажем, и там есть какие-нибудь кассы,
которые обслуживают, и там какой-то поток клиентов,
вот это такие задачи можно моделировать в вероятностных терминах
с помощью так называемой теории массового обслуживания.
И в общем, там где Пуассоновское распределение возникает.
Как правило, считается по некоторым причинам, что Пуассоновское распределение
это количество клиентов, которые заходят за какой-то промежуток времени.
То есть вы берете единицу времени, смотрите,
сколько за это время зашло клиентов, и оно будет иметь Пуассоновское распределение.
Предположительно.
Оказывается, эта модель часто хорошо работает.
Вот давайте я здесь о чем-то более строгом поговорю.
В какой еще ситуации возникает Пуассоновское распределение,
которое нам понятно.
Это в ситуации, когда в биомиальном распределении
вероятность обратно пропорционально количества подбрасываний.
То есть представьте себе, что вы миллион раз подбрасываете,
а вероятность решки 1 миллионная.
Но выглядит, наверное, немного искусственно,
но, например, в физике возникают всякие задачи про взаимодействующие частицы,
когда очень много частиц, между ними какие-то слабые взаимодействия.
И такие вещи хорошо моделируются с помощью вот этого Пуассоновского распределения.
Но с формальной точки зрения мы просто берем вероятность обратно
количество подбрасываний и устремляем n бесконечности и в пределе получим вот это.
Давайте это увидим.
Сначала напишу, что мы получим, потом увидим, что это действительно так.
Итак, что здесь?
Здесь x – это множество целых неотрясательных чисел.
И для любого x-а
его вероятность – это есть λ в степени x, e в степени минус λ,
поделить на x-факториал.
Ну, значит, я утверждаю, что на самом деле это то же самое,
что вот эту штуку, найти пределы этой штуки при n стремящемся бесконечности
и P равным λ поделить на n.
Давайте увидим, что это действительно так.
Такое утверждение докажем.
Что если P – это λ поделить на n,
то предел при n стремящемся бесконечности c из n по x
P в степени x на 1-P в степени n-x
это в точности λ в степени x
на e в степени минус λ поделить на x-факториал.
Так, ну что, просто пределы найдем, да?
Здесь имейте в виду, что x – это константа какая-то.
Мы же, мы здесь вероятность находим для любого конкретного x.
То есть мы фиксируем x, а потом устремляем n бесконечности.
То есть вот это x, оно от этого никак не зависит.
И поэтому c из n по x на P в степени x на 1-P в степени n-x
это есть симпатически.
Я пишу такую волну, я имею в виду симпатическое равенство.
То есть если я сейчас напишу здесь некоторые выражения
и составлю их отношения, то в пределе получится единица.
Вот что я имею в виду, когда я пишу волну.
Что если я поделю одно от другое,
я в пределе единицу.
Ну, я могу вместо c из n по x написать n в степени x
поделить на x факториал.
Ну, потому что что такое c из n по x?
Это произведение n на n-1, на n-2, x раз и делить на x факториал.
Так как x – это какое-то фиксированное число,
то понятно, что асимпатически я получаю такое выражение.
P в степени x – у меня P – это λ поделить на n.
Я подставлю.
Я получу λ в степени x поделить на n в степени x.
Ну и здесь просто второй замечательный предел.
Это 1 – λ поделить на n в степени n,
что в пределе равно e в степени – λ.
Ну прекрасно, n в степени x сокращается
и остается то, что мы хотели.
λ в степени x на e в степени – λ поделить на x факториал.
Пит, вопросы?
Вот!
Не понял.
Вопрос?
Ну это максимальная форма строгости,
максимально не бывает.
Что? Как это?
Как это?
Как это?
Как это?
Какое именно место я доказал нестрого, на мой взгляд?
Какой переход нестрогий?
Вот этот?
Вряд ли этот.
С этим, наверное, все в порядке.
Вот этот нестрогий.
Еще раз.
c из n по x.
Что значит эта волна?
Если я поделю вот эту штуку на вот эту,
я в пределе единицы получу.
Я вместо c из n по x написал n в степени x поделить на x факториал.
От n в степени x.
А знаете, стоит x факториал.
Поэтому вот эту штуку поделить на n в пределе 1.
Окей?
Строго или не очень?
Значит, здесь
p стремится к нулю.
Поэтому –x на предел не влияет.
То есть вместо 1 – λ поделить на n в степени n,
по второму замечательному пределу –
это e в степени – λ.
Это надо объяснять, почему 1 – λ поделить на n
и λ стремится к e в степени – λ.
Прям стремяще бесконечности.
Надо.
Ну то есть, конечно, если вас на экзамене это спросит,
вам придется это отвечать.
Но я надеюсь, что здесь все умеют
все-таки пределы считать.
Вот, значит, λ – это константа.
Поэтому, премяще бесконечности, вот эта штука
под степенью стремится к 1 делить на e.
И так как это тоже константа, то предел нас следует.
Значит, предел будет e в степени – л.
Но я не думаю, что экзаминаторы будут вас
такие вещи спрашивать. Они вам верят,
что вы умеете пределы считать.
Я бы назвал это не
степенью строгости.
Я бы это назвал просто подробностями.
Этих подробностей достаточно.
Но если вдруг экзаминатор вас начнет
дотошно спрашивать, как пределы считаются,
придется объяснять.
Так.
Хорошо, значит.
Ну, функция распределения,
в отличие от всех остальных случаев,
она никогда не достигнет 1.
Да, если
для всех предыдущих распределений
у нас носитель был конечный,
поэтому там вот конечное множество
иксов мы отмечали на оси абсцисс.
И после последнего икса
функция становится конечной.
После последнего икса функция
становится 1.
Здесь она никогда 1 не достигнет,
потому что у вас носитель бесконечный.
У вас существует сколько угодно большое икс,
для которого вероятность не нулевая.
Вот.
Какие-то вопросы?
Хорошо.
Тогда давайте поговорим теперь про
второй вид распределений.
Абсолютно непрерывный.
На самом деле нас интересует
чуть более сильное
свойство, чем непрерывность.
Абсолютная непрерывность.
Сейчас я поясню, что это такое.
Но вы, наверное, знаете.
На семинаре вы имеете в виду?
Или где?
Или что была за предыдущей парой?
А, сказали вам,
что такое абсолютно непрерывная функция.
А кто матан ведет?
Кто?
Вы поняли, что такое абсолютно непрерывная функция?
А какое определение?
Понятно.
Да, но
вы на матанализме
занимаетесь функциями.
Вы считаете, что у вас какая-нибудь
мера или бега,
и там все на R.
Вы можете обобщать на какие-то другие пространства,
другие меры.
То определение, которое вам дают,
очень универсальное.
Но одно и то же, если сконцентрируйтесь
только на тех функций, которые вы рассматриваете.
А более универсальное определение я сейчас формулирую.
Абсолютно непрерывная
является функцией распределения.
Если мы говорим, что функция
распределения не прерывна, то и само распределение.
Что это значит?
Распыление называется абсолютно неправильным, если у него есть плотность.
Что такое плотность?
Значит, если существует такая функция P, которая действует из r в r+, такая что
для любого x из r, f от x,
где f это пункция распления, которая соответствует вот этому расплению P,
это есть интеграл от минус бесконечности до x, P от t dt,
где вот этот интеграл, его надо воспринимать как интеграл Лебега.
Мы вообще все интегралы воспринимаем как интеграл Лебега, но повезло, что он считается как обычный интеграл Риммана,
но когда мы пишем интеграл, мы имеем в виду интеграл Лебега, это более общее понятие.
Ну и сама функция распления называется абсолютно непрерывной, и расприление P тоже называется абсолютно непрерывным.
Я сейчас поясню сакральный смысл этого понятия.
f это тоже абсолютно непрерывная функция.
Смотрите, давайте вспомним, у нас было определение дискретного распределения,
но вот появилась в нем вот эта вот буква P, и вот здесь тоже у меня есть буква P.
Только вот эта буква P, это есть последовательность, которая задана на множество x большое,
у нас есть какой-то носитель, и для каждого элемента этого носителя P от x положительное число какое-то.
Смотрите, если я попытаюсь как бы размазать, допустим, у меня есть равномерное распределение,
на отрезке от 0 до 1 с шагом 1n, то есть я беру числа 0, 1, 1, 1n, 2 поделить на n, 3 поделить на n и так далее.
И говорю, что вот дискретное распределение на отрезке от 0 до 1 равномерное.
И дальше начинаю n увеличивать, и у меня отрезок начинает дробиться.
Да, на нем все больше и больше и больше и больше точек возникает.
И вот есть у меня эта функция P, которая равна 1 поделить на n плюс 1, видимо, в каждой из этих точек.
Но понятно, что если я стремлю к бесконечности, эта функция стремится к нулю.
Да, но распределение, оно не устремится к нулю, оно станет равномерным на всем отрезке.
И тогда вместо функции P мы будем рассматривать другую функцию, вот эту.
Когда мы здесь считаем какую-то вероятность, она равна сумме вероятностей.
А когда мы здесь считаем вероятность, она равна интегралу.
То есть просто сумма превращается в интеграл.
В каком-то смысле вот эта функция P – это просто аналог вот этого P.
То есть это такая дискретная плотность, ее иногда называют дискретной плотностью.
А это плотность для в обычном смысле абсолютно неприливного распределения.
Но если вместо меры Либега рассмотреть так называемую считающую меру.
Что это такое?
Что такое мера Либега, вы знаете.
А считающая мера – это следующее.
Мы просто будем говорить, что мера любого множества – это количество целых чисел, которые в него попало.
Вот если мы возьмем такую меру, то вот эта штука – это будет плотность только относительно этой меры.
Да, вот эта плотность относительно меры Либега, а вот эта вот плотность относительно так называемой считающей меры.
То есть это на самом деле одно и то же, просто для разных мер.
Вот это вот для такой так называемой считающей меры, а это для меры Либега.
Но естественность вот этого распределения нужно воспринимать на мой взгляд именно так.
То есть давайте сначала возьмем дискретное распределение, например такое.
Будем дробить, дробить, дробить все сильнее, сильнее, сильнее.
И в пределе у нас получится абсолютно неприливное распределение.
И вот в некотором смысле вот эта штука превратится вот в эту штуку.
Вот, значит, давайте поговорим про свойства и про примеры, чтобы немного пощупать, чтобы немного пощупать это распределение.
Примеры сделают его естественным, чтобы увидеть, что возникают какие-то относительно жизненные ситуации,
в которых это распление возникает, а свойства помогут с ним проще работать, какие-то вероятности считать в частности.
По классическому меру Либега. Да, имеется в виду классическую меру Либега.
То есть когда мы просто пишем dt, когда мы не уточняем, какая мера, мы имеем в виду классическую меру Либега.
Так, свойства. Ну, во-первых, значит, функция P, все про нее можно сказать, она не отрицательна, она принимает неотрицательные значения.
И еще одна вещь. Интеграл от P равен единице.
Понятно, почему. Вот у нас есть функция распределения.
У нас есть свойства. Третье, что предел в плюс бесконечности равен 1.
То есть мы напишем здесь предел при стремящейся в плюс бесконечности мы получим 1.
Это и есть интеграл от минуса бесконечности до плюс бесконечности.
Во-вторых, вы можете считать не только функцию распределения с помощью плотности, вы можете считать вероятность любого множества.
Во-вторых, вы можете считать не только функцию распределения с помощью плотности, вы можете считать вероятность любого множества.
Какое бы вы ни взяли барреллерское множество, его вероятность будет равна интегралу по нему p от t до t.
Смотрите, еще раз, где я пишу формально доказательства, это значит, что я полностью что-то доказываю.
Вот эти свойства и много еще чего-то другое, просто за не менее времени я не хочу по-другому все доказательства писать, но я схематично буду это рассказывать.
На экзамене от вас требуется, конечно, то же самое.
Смотрите, почему второе свойство верно? Кто может объяснить?
Правильно.
Да, абсолютно верно.
Давайте подумаем, что это не p, а это хоть p с волной.
Определим так. Положим p с волной равно этой штуке.
Тогда это вероятность. По определению вероятности можно увидеть, что это счетно-адидитивная штука.
Интеграл ли бега, он счетно-адидитивен, поэтому это вероятностная мера.
Мы умеем единственным образом продолжать функцию распределения на распределение вероятности, поэтому она совпадает с p.
Ещё раз. Давайте возьмём какую-то...
Вот мы не знаем, что это p, что p от b равно этой штуке, мы не знаем, мы ещё не доказали.
Рассмотрим функцию p с волной, которая множеству b ставит в соответствии такой интеграл.
На лучах это совпадёт, то есть p с волной от минус бесконечности до x, оно совпадает с p от минус бесконечности до x.
Это по определению. Мы говорим, что наш функция распределения равна этой штуке.
Поэтому эти штуки на лучах совпадают, но при этом p с волной это тоже вероятность.
Интеграл является счетно-адидитивным. Если вы будете такие интегралы складывать по непересекающимся множеству,
вы получите интеграл по объединению этих множеств. Поэтому p с волной это вероятность.
А раз p с волной это вероятность, и p это вероятность, и они совпадают на лучах, значит они совпадают везде.
А значит p равно p с волной.
Теперь по поводу того, откуда эту плотность взять и в каких случаях она вообще существует.
Есть замечательное утверждение, что если функция f дифференцируема, то p это производ от неё.
Ну я думаю, это всем очевидно. Есть такая формула Ньютна-Лебница.
Давайте я это запишу.
Чего?
Ну доказали? Я не говорю, что формула Ньютна-Лебница очевидна. Я говорю, что из неё это очевидно следует.
Но вы её ещё не в полной общности доказали.
Вы доказали для абсолютно неприимных функций или для дифференции? А, для абсолютно неприимных. Прекрасно.
Прекрасно, да. Ну вообще замечательно.
Вообще замечательно. Да, значит утверждение. Вы это знаете.
Если f дифференцируемо, то сказать, что плотность равна производной, конечно, не совсем правильно.
Потому что это определение не предполагает единственности плотности.
Оно говорит, вот плотность это такая функция. Кстати, я не написал. Эта функция называется плотностью.
Определение такое, плотность это такая функция, что выпнут это равенство.
Ну понятно, что таких функций дофига. В частности, я могу взять и в одной точке изменить его значение.
От этого это никак на этот интеграл не повлияет.
Поэтому таких функций много, и формально надо говорить, что не тогда плотность равна, а в качестве плотности можно выбрать.
Но если я буду говорить, что плотность равна, я буду это иметь в виду.
То есть можно говорить, что есть у нас класс эквивалентности, что вот те плотности, которые подходят для одного и того же распиления, они образуют один класс эквивалентности.
Я беру любого представителя и равенство здесь воспринимаю именно как равенство классов эквивалентности.
И в этом смысле я могу говорить про равенство.
И я просто напишу, что плотность производного функции распиления.
Что, очевидно, следует из формулы Ньюта-Лебницы. Если вы сюда подставите производный функции распиления, вы получите верное равенство.
Еще одно утверждение, что вот было у нас утверждение, что если есть функция распиления, то бишь функция, которая обладает тремя свойствами, то она является функцией распиления для некоторого распиления вероятности.
То же самое можно сказать про плотность. Возьмем вообще произвольную функцию вот такую.
Тогда она единственным образом задает некоторое распиление вероятности.
Значит, пусть P действует из R в R+, и интеграл от P равен единице, тогда существует единственное распиление вероятности P.
Такое, что P маленькая это его плотность.
Ну тоже, в общем-то, несложно. Давайте это аккуратно докажем.
Ну смотрите, если мы однозначным образом восстановим функцию распределения, то мы, конечно, однозначным образом восстановим и распиление вероятности.
Ну давайте просто положим f от x равно интегралу от минус бесконечности до x пт dt.
Имеем право, так как у нас интеграл по всему R есть, и так как функция не отрицательна, то мы можем интегрировать по любому подмножисту по определению интеграла Либега.
Никаких проблем здесь нет. Поэтому такая функция, конечно, существует, мы можем ее определить.
Что осталось? Осталось проверить, что три свойства выполнены. Если выполнено три свойства функции распиления, то все доказано.
Свойства номер один говорит, что f не убывает.
Значит, если x меньше, чем y, то, ну понятно, разность этих интегралов, это в точности интеграл от x до y,
f от t до t. И так как p не отрицательно, то и интеграл тоже не отрицательный. Прекрасно. Значит, функция не убывает.
Еще что? Непрерывность справа.
Непрерывность справа. Что-что?
Непрерывность справа. Что-что?
Да. Сюда. Вместо p подставляем f'.
f от минус бесконечности это ноль по свойствам функции распиления.
Это не нагло, это дано. Если f функция распиления здесь имеет в виду, не просто оба какая функция дифференцируемая,
тогда это утверждение бессмысленное. Значит, утверждение такое, пусть есть распределение, у него есть функция распиления f,
которая дифференцируема, тогда плотность этого распиления можно найти как производная функция распиления.
Ну, вообще, здесь будет не просто непрерывность справа, здесь будет просто непрерывность. И слева, и справа везде.
Если вы считаете предел при х, стремящемся к x0, f от x, то бишь, предел при х, стремящемся к x0, интеграл от минус бесконечности
f от минус бесконечности до х, f от t dt, то по тереме Лебега это есть интеграл от минус бесконечности до x0,
f от t dt. По тереме Лебега вы можете менять местами пределы интегралов. Вот, что я и сделал, и это есть f от x0.
Что? Чем-то ограничиваясь сверху. Мы можем самой функции p ограничить.
Мы здесь берем функцию p не на всем r, и мы ее ограничим функцией p на всем r, который не отрицательный.
У нас за счет того, что p не отрицательный, нам не надо ничего ограничить. У нас там еще лемма фату есть и прочее, которые там говорят, что если у нас ограниченность снизу, то нам не надо ограничивать везде.
То есть, если у нас функция не отрицательная, то мы можем ее пользоваться. Если мы хотим прямо явно применять терема Лебега, мы ее можем ограничить самой вот этой функцией p от t, но на всем r.
Ну, формально смотрите, что у нас тут написано. Давайте чуть аккуратнее напишу, чтобы вы увидели, что это явно я применяю терема Лебега.
Можно левее применять, да. Но вот я все это не помню на самом деле, всех этих там лемм. То есть, если я сейчас сяду, я, конечно, докажу терема Лебега за какое-то ограниченное время.
Но я помню терема Лебега, и в принципе, можно там во многих ситуациях, конечно, к ней сводить, и вот здесь тоже можно. Вы правы, что можно без этого обойтись.
Но давайте я покажу на всякий случай, как это сводится к тереме Лебега.
Значит, давайте будем говорить про интеграл от меня за бесконечность до бесконечность.
Тогда вместо p-ми нужно написать p от t умножить на индикатор того, что t меньше 0, чем x.
Да, и вот у меня есть на самом деле последовательность таких функций по разным их сам.
И все они ограничены функцией p от t. Давай вот эта штука на меньше 0, чем p от t.
Я не должен никакой модуль ставить, она не отрицательна, тут все хорошо.
И интеграл p от t по условияр n единицы, поэтому я могу применять терема Лебега и заношу внутрь интеграла предел.
Ну, предел этой функции, это есть просто p от t умножить на индикатор того, что t меньше 0, чем x0.
А это есть искомый интеграл от минус бесконечности до x0, p от t до t, что и требуется.
Вот, но то же самое в минус бесконечности и в плюс бесконечности, вы просто применяете терема Лебега.
Ну, например, в плюс бесконечности.
Опять вы меняете местами интеграл и предел и получаете просто интеграл от минус бесконечности
до плюс бесконечности, что равно единице.
Ну и с нулем то же самое.
А это есть предел при x от минус бесконечности, интеграл от минус бесконечности до x, p от t до t.
Опять меняем местами интеграл и предел, получая 0.
Погейно, да. То есть я беру любую подпоследовательность на самом деле.
Имея это в виду в голове, я беру любую подпоследовательность, любую последовательность стремяческих с 0 и все это проделываю.
Но давайте не будем опускаться до полного формализма в этом плане.
Не так понятно, что теория Малибега о мажоривом исходимости обобщается не только на последовательности, но и на такие пределы просто из-за определения предела по геймерам.
Ну прекрасно. Смотрите, как здорово. Здорово что? Здорово то, что мы можем считать всякие вероятности, имея плотность.
Ну во-первых, если у нас есть плотность, она задает распределение вероятностей.
То есть вместо того, чтобы функцию распределения задавать, можно просто плотность задать.
Мы сейчас увидим, что это естественно и во многих ситуациях гораздо проще.
Чего? Единственное. Смотрите, что я доказал. Я доказал, что вот эта штука это функция распределения.
Давайте где-то допишу, да? Я положил вот это, и то, что я только что доказал.
Это то, что это функция распределения. Вот.
Функция распределения единственным образом восстанавливает распределение.
Она единственным образом восстанавливает распределение. То есть во-первых, вы единственным образом восстановили F.
F. По определению F должна быть такая, что вот такая должна быть F. Чтобы P была плотность,
F должна быть вот такой. И мы ее такой и взяли. Никакой другой F быть не может. Мы никакую другую
функцию распределения получить не могли. А из F P восстановились единственным образом,
ну значит оно действительно единственное. Да, что я там говорил? Я говорил, что ну прекрасно,
вот мы можем во-первых, теперь когда будем какие-то примеры разбирать, мы можем сказать,
а давайте возьмем такую плотность, и вот это будет какое-нибудь распределение с каким-то
красивым названием. Это первое, что мы можем делать. А второе, что мы можем делать, это вероятность.
С помощью вот этого свойства мы можем убирать с любого множества. Почитайте,
если у нас есть плотность. Давайте этим мы займемся. Ну, начну я с примера равномерного
распределения. Я не зря говорил про эту ситуацию, а давайте мы разобьем отрезок 0,1 на n под
отрезочков и будем менять бесконечности в пределе… Сначала у нас есть равномерное
распределение в этих точках, в пределе типа получим равномерное распределение на всем отрезке.
Вот давайте с равномерного распределения на отрезке начнем.
Начнем с равномерного распределения на отрезке от A до B. Ну, в принципе, вы можете в качестве,
вот этот отрезок – это параметр распределения, вы в качестве этого параметра можете брать не
только отрезок, вы можете взять, например, интервал. Или вы можете взять несколько отрезков,
не пересекающихся, объединить их, и на нем сдать равномерное распределение. Все по аналогии. Но я
здесь не пытаюсь какую-то общую картину показать, просто какие-то примеры, чтобы это было проще
почувствовать. Если я тут кучу интервалов сейчас напишу, будет сложнее это почувствовать. Что это такое?
Ну, распределение равномерное вполне естественно положить, что плотность просто одинакова во всех
точках этого отрезка. Что такое плотность? Ну, это как масло вы на хлеб мажете. Если вы
мажете масло на хлеб, то где-то масло мало, где-то масло много. Где там много масла, там у вас
больше вероятности. Где у вас мало масла, там у вас меньше вероятности. А плотность – это высота
вашего масла. Разрежьте посередине, посмотрите, а вот здесь вот большая высота, здесь много масла,
здесь меньше. И в любом месте вашего бутерброда у вас вероятность будет равна просто количеству
масла, которое у вас в этом месте намазано, и это будет интеграл от высоты этого масла. Поэтому
чем больше у вас плотность, тем у вас больше вероятность в этом месте. Если вы хотите сделать
равномерную вероятность, у вас плотность должна быть константой на всем вашем множестве. Как сделать
плотность константой на всем этом множестве. Но у вас интеграл должен быть единиц равен.
Да, надо единиц поделить на длину. Понятное дело, что рассуждение с маслом не является доказательством
вот этого равенства. Это я просто его, чтобы была интуиция, откуда это берется, это определение.
Это просто определение равномерного распиления на отрезке от A до B. И понятно, что если у вас будет
любое другое множество, на котором вы можете задать равномерное распиление, вы просто скажете,
что плотность это единиц поделить на меру этого множества, умножить на индикатор того,
что вы в это множество попадаете. Хорошо, какая будет функция распиления, давайте посчитаем для
упражнения. Ну, что надо делать по определению плотности? Надо проинтегрировать функцию распиления,
есть интеграл от минус бесконечности до x. Ну, во-первых, понятно, что там, где нет бутерброда,
там вероятность ноль. То есть, иными словами, если у вас эта точка х на левее чем А, туда отрезок
Аб не попала никакая его часть, и значит, будет просто интеграл равен нулю. Вот так. Теперь,
если попали, если ваш х попал в отрезок от A до B, вы просто интегрируете от A до х 1 поделить на
B-A dt при х от A до B. Ну, если вы попали правее точки B, то ваш отрезок попал целиком внутрь
интеграла, значит, будет единица при х больше чем B. Вот, но здесь, если посчитать, получится что?
Получится х-а поделить на B-а. Ну, то есть, получаем, что функция распиления на отрезке от А до B это отрезок
прямой, что естественно, раз у вас распределение является равномерным. У вас должна линейно
накапливаться вероятность с ростом х. Значит, до А это ноль, а в точке B это один, и дальше,
и между А и B это просто отрезок прямой. Вот, хочу обратить внимание, что эта функция не является
дифференцируемой. Да, у нее есть вот эта точка A и точка B, в которых она не дифференцируема, так что в явном
виде пункт один, вот это утверждение, извиняюсь, один, которое там слева в углу написано, его нельзя
прямо тут взять и прямо вот ни о чем не думая применить. То есть, я имею в виду, что если у вас такая
функция распиления есть, вы по этому утверждению не можете прямо сразу сказать, ага, ну, значит,
плотность равна вот этому. А давайте продиференцируем на этих участках. Но на самом деле, вы уже умные,
вы уже прекрасно знаете, что если у вас есть такая ситуация, когда у вас кусочно дифференцируемая
функция, у вас есть какие-то точки, в которых производа не существует, но в них функция непрерывна,
то все хорошо, можно на всех этих участках продиференцировать и вы все равно получите плотность.
То есть, на самом деле, можно продиференцировать на каждом из этих участков и получить плотность.
Так, это равномерное распределение. Ну, пояснять, наверное, нечего, естественная вещь, давайте
двинемся дальше. Нормальное распределение. Вот тут с ходу нормальность нормального распиления
не очевидна. Ну, и под нормальность я подразумеваю адекватность. Сейчас какая-то страшная формула будет,
но я объясню, откуда она берется, пока на пальцах, но в курсе у нас будет теорема, которая называется
центральная предельная теорема. У меня сейчас пока не хватает инструментов, чтобы ее доказать,
но они появятся. Вот, поэтому я просто объясню на пальцах, откуда это берется, а формулу мы пока
запомним. Формула для плотности, я имею в виду. Так, второе. Это буква N, если что. Значит, это
нормальное распиление с параметром a и sigma квадрат. Значит, почему sigma квадрат? Ну, потому что
второй параметр положительный. Значит, а это какое-то действительное число, а sigma квадрат это какое-то
положительное число. И это такое неразрывное определение sigma и сверху двоечка. Это просто
объединение, просто sigma не пишут. Если вы хотите корень из этого взять, ну, вы так пишете, корень и
sigma квадрат. Цельное обозначение. Значит, как дается плотность? Ну, плотность дается вот так.
Единиц поделить на корень из 2 pi sigma в квадрате, e в степени минус xt, t минус a в квадрате,
делить на 2 sigma в квадрате. Ну вот, да, такая вот странная формула плотности. Для начала нужно
поверить, что интеграл от него равен единице. Давайте поверим. Но я не знаю, вам доказывали,
а у вас комплексного анализа не было, да? Ну, не важно. В общем, есть инструменты, которые позволяют
доказать, что интеграл от этой штуки равен единице. В принципе, это несложное утверждение.
Интеграл Плассона, да. Или там еще как-нибудь по-разному называют. Ну понятно, да? И там всем известен,
что интеграл от e в степени минус x в квадрате пополам, это корень из 2 pi. Вот. Дальше надо там, ну,
заменку сделать. Получится, что интеграл от этой штуки это единица. Вот. Да, хорошо. Значит,
откуда берется это нормальное распределение? Давайте посмотрим. Во-первых, давайте сначала
нарисуем график этой плотности, чтобы это была не просто символная запись, чтобы мы это уже как
картинку себе представляли. Значит, график плотности выглядит вот так. Вот есть точка А, это очень важная
точка. Относительно вот такой прямой вертикальной наша плотность будет симметрична и будет
выглядеть она вот как-то так. Будет выглядеть она как-то так. Да, она симметрична относительно вот
этой прямой. И, значит, что такое А? Понятно, это точка, относительно которой симметрична. Что
значит, что такое симму квадрат? Симму квадрат отвечает за то, насколько сильно у вас плотность
прижата, насколько сильно она у вас прижата к А. Да, ну вот, смотрите, если я стигму начну
увеличивать, вот если я А равно нулю поставлю, я чего получу? Я получу 1, посмотрите, на корень из 2 pi
симму квадрат. Если я стигму начну увеличивать, эта штука начинает уменьшаться. То есть высота,
высота этого горбика, она начнет уменьшаться, а сам горбик начнет шире становиться. То есть если я
увеличиваю сигму, у меня эта штука становится ниже, а эта штука становится шире. Если я стигму уменьшаю,
у меня вот эта штука становится выше, а сам график становится ужин. Значит, то есть сигма отвечает
за разброс вероятности относительно этой прямой. Когда вы смотрите на плотность, вы понимаете,
что ну окей, это у меня бутерброд, у меня это бутерброд на масло, на хлеб намазано, вот здесь
дофига масла, а по краям мало. Да, поэтому чем у меня больше сигма, тем будет ровнее намазано
масло. Чем у меня меньше сигма, тем больше будет масла в одном месте. То есть сигма это разброс
относительно вот этого центра бутерброда, разброс вашей вероятности. Чем меньше сигмы, тем меньше разброс.
Хорошо, значит теперь откуда это берется? При стремлении сигмы к нулю, это штука, когда эта
функция сойдется. Сигма равно нулю. Сигма равно нулю, это вообще можно здесь написать сигму х2
большего нуля и воспринимать ситуацию, когда сигма равно нулю, как тоже нормальное распределение.
Нормальное распределение будет, на самом деле, просто одна точка, в которой вероятность равна
единице. То есть если вы устремите сигму к нулю, вы в пределе получите, что вероятность точки
А равно нулю равна единице. То есть это будет дискретное распределение, на самом деле всего с одним
атомом. Вот есть одна точка, вероятность которой один, константа короче. И есть утверждение о том,
что про сходимость распределения, что если у вас есть сходимость нормальных распределений,
вы в пределе снова нормальное распределение получите. Поэтому ответ на ваш вопрос да, и тут есть
некоторый смысл за этим, но мы об этом еще позже поговорим. Теперь откуда берется вот этого,
ну как оно выглядит понятно, откуда он взялось. Вот смотрите, какой интересный парадокс. Если
монетку много раз подбрасывать, ну вы знаете, что у вас теперь у авролаплаца была? Ну прекрасно,
а вы знаете откуда это берется? Что я объясняю? Ну короче, да, если вы монетку много раз подбрасываете,
то конечно примерно в половине случаев у вас будет решка. Короче, если вы миллион раз
подбросите, поделите количество решек на миллион, получится ну примерно одна вторая. Насколько
примерно? Насколько примерно отвечает на этот вопрос в частности т.е. мавролапласа? Я ее еще вам
сформулирую в курсе и докажу попозже. Сейчас давайте еще раз послушаем. Вот примерно в половине
случаев у вас будет решка. В том смысле, что если вы количество решек поделите на миллион,
то это будет примерно одна вторая. Насколько примерно? Ну вот получится там 0, 4, 9, 8 и что-нибудь
еще скажем. Получится какое-нибудь такое число. А может ли получиться не 9, здесь а 7? Вероятность
того, что что-нибудь такое получится, очень маленькое. С гораздо большей вероятностью здесь будет 9.
И связано это с тем, что выполна следующее утверждение, что если вы посмотрите на количество решек,
давайте назначим его за х, х это количество решек, миллион раз я подбросил, миллион раз я подбросил,
я должен вычесть из этого половину миллиона, т.е. 500 тысяч и поделить это дело на корень из
250 тысяч, т.е. на 500, то это будет примерно нормальная случайная величина. Что это значит? Это значит,
что если я посмотрю на вероятность того, что эта штука лежит между А и B, то это будет примерно.
Есть, я здесь не имею в виду ничего строго, когда я пишу это пример, на самом деле есть
прямо утверждение о том, насколько сильно мы здесь ошибаемся. Вот здесь можно нечто
точное написать вместо этого примерно. 1 поделить на корень из 2p интеграл, или давайте интеграл
слева напишем. Интеграл от A до B, 1 поделить на корень из 2p, e в 7-t в квадрате в половину dt.
Если вы посмотрите на это выражение, вместо sigma квадрат поставить единичку, а вместо
подставить 0, вы получите ровно вот эту функцию, которая здесь написана. Причем здесь вот эта
ошибка, но это на самом деле оно и есть. Я с помощью этого утверждения могу понять, насколько сильно я
здесь ошибаюсь. Если я понимаю, что если я здесь напишу минус 3, а здесь 3, то это будет
примерно 1. Да, это значит, что с очень большой вероятностью выполна вот это неравенство и
значит х у меня лежит между 500 тысяч минус полторы тысячи и 500 тысяч плюс полторы тысячи, и вот
отсюда у меня берется 0,498. Поэтому 4,47, вероятность этого крайне мала. Здесь должна быть девятка.
Отсюда берется нормальное распределение. Вообще есть, мы сейчас про монетки говорили,
но на самом деле центральная определенная теория, которую мы в курсе докажем, утверждает следующее,
что какие у вас вообще ни были ваши независимые эксперименты, монетки, чего-либо еще, на
значение температуры вы смотрите, то есть ваши случайные объекты могут непрерывно распределены
быть, как угодно еще. Если вы делаете эксперименты независимо, то получается то же самое. Если вы
считаете количество успехов или еще что-нибудь связанное с N независимым экспериментами,
вы получите тоже в пределе нормальный закон. Вот отсюда берется нормальное распределение.
Эта ситуация, когда А равна нулю аси мх единицы, это называется стандартное нормальное распределение.
Значит N01, стандартное нормальное распределение. Вот, что можно сказать про пункцию распределения.
Ну, что можно хорошенько сказать? Ну, это интеграл от плотности, ничего лучшего не скажешь,
ожидая интеграл, это штуки не берется. Но можно нарисовать график. Вот если плотность
выглядит вот так, то функция распределения выглядит следующим образом. Опять,
давайте отметим точку А и подумаем вот о чем. Значит у нас этот график симметричный, поэтому
слева от этой прямой и справа от этой прямой одинаковое количество вероятности. То есть раз
сумме должно быть единицы, значит здесь вот одна вторая, и здесь тоже одна вторая. Вероятность попа,
с иными словами, вероятность попасть в интервал от минус бесконечности до А,
совпадает с вероятностью попасть в интервал от А до плюс бесконечности. Ну,
а это и есть функция распределения в точке А. То есть значение функции распределения в точке А,
одна вторая. Вот, и дальше понятно, что график должен быть симметричен относительно этой точки.
Правда же? Ну, что я имею в виду? Я имею в виду, что если я возьму вот такую точку, отступлю от
а на какой-нибудь епсилон, влево и вправо, то площадь вот здесь будет совпадать с площадью
вот здесь. Да, то есть иными словами f от x и 1 минус, сейчас, f от a минус x и 1 минус f от a плюс x
это одно и то же. То есть эта функция, она будет выглядеть вот так. Сейчас. Значит, вот так. А здесь
она ломается как бы, да, потом идет вот так. Не ломается, а перегибается, правильнее сказать.
Вот так будет выглядеть функция распределения и понятность, за что будет отвечать sigma. За ту же
самую прижатость вот к этой прямой. Да, с одной стороны, вы можете прижиматься к этой прямой,
с другой стороны, вы можете от нее отдаляться. Вот. Чем у вас больше sigma, тем вы сильнее от нее
отдаляйтесь, чем она меньше, тем вы сильнее к ней прижимаетесь. Вот. Ну, давайте еще одно распределение
и на этом закончим. Ну, она есть. Неспроста я 3 написал, да. Так, экспоненциальное распределение.
Вот это распределение опять отсыл.. Здесь видите то же самое лямбда, что было в полусалонском
устранении, это неспроста. Это опять отсылка к этой теории массового обслуживания. И вот здесь я
уже не буду, будьте здоровы, и вот здесь я уже не буду какие-то строгие вещи доказывать, я просто
скажу, что вот есть некоторое свойство этого экспоненциального распределения о потере памяти,
и значит, оно за счет этого свойства хорошо моделируется вот те же самые системы массового
обслуживания, а именно за экспоненциальное распределение, за экспоненциальное распределение
отвечает вероятность того, что за заданный интервал времени кто-нибудь зайдет. Сейчас,
правильно? Нет, неправильно говорю. Значит, за экспоненциальное распределение отвечает момент
первого захода человека. Вот у вас дошел кто-нибудь в Макдональдс, и вы начинаете считать время,
когда следующий зайдет, и вот это время, оно имеет экспоненциальное распределение. Что это значит?
Значит, оно экспоненциально уменьшается с ростом времени, чем больше происходит времени,
тем меньше вероятность, и уменьшается она экспоненциально. То есть плотность вот такая,
ну, на индикаторе того, что t не отрицательна. Значит, у вас не может быть отрицательное время,
вот у вас один чувак зашел, вы смотрите, когда следующий зайдет, и время между ними,
оно, конечно, не отрицательное, поэтому здесь стоит этот индикатор. Этот параметр лямбда
нужен для того, чтобы распределение может быть разным. Нужен какой-то параметр, это просто скорость
экспоненциального убывания к нулю. А здесь лямбда возникает просто из-за того, чтобы интеграл
должен быть равен единице. Вы хотите эту штуку проинтегрировать, получить единицу, поэтому здесь лямба стоит.
Давайте найдем функцию распределения. Ну, функцию распределения, напомню, это интеграл от минус
бесконечности до x плотности, и это есть что? Это есть 1 минус e в степени минус лямбда x,
умножительный индикатор того, что x не отрицательна. Ну, можно график нарисовать,
значит, плотность будет выглядеть вот так, в точке 0 лямбда, и дальше она экспоненциально
убывает, это плотность, а функция распределения, значит, в нуле 0, до нуля тоже 0, а потом она вот
так себя ведет. Да, у нее есть излом в нуле, в нуле она формально не дифференцируема, вот дальше она
экспоненциально стремится к единице. Есть какие-то вопросы? Это плотность, это функция распределения.
Так, ну, в общем-то, времени осталось немного, на этом я, наверное, закончу, но напоследок пару слов
скажу про многомерное распределение, которым мы сейчас плавно перейдем. Я в прошлый раз о них
начал говорить, давайте я закончу на том же самом, на чем я в прошлый раз закончил, значит,
многомерное распределение тоже есть функция распределения. Давайте я это запишу и на этом закончу.
А то вы там на семинарах сейчас многомерное распределение начнете разбирать, чтобы у вас
осталось с лекцией интуиция того, что там происходит. Значит, все очень просто, потому что все
аналогично. Одномерное распределение, это просто частный случай многомерного распределения, да,
я напомню, что многомерное распределение это просто вероятностная мера на баррелиско-сигма
алгебре ВРН. Вот, это н-мерное распределение. У него тоже есть функция распределения,
и я сейчас определю и скажу, что он однозначно восстанавливает распределение, и на этом мы
закончим. Начнёт следующий объект. Это функция, которая действует из РН в 0,1. Следующим образом f
от x1 от далее xn, да, теперь у нас n аргументов, это есть вероятность декартового произведения
лучей от минус бесконечности dx1 и так далее от минус бесконечности dxn. Значит, утверждение,
что она однозначно соответствует распределению вероятностей, то есть если p1, p2 распределение
с функциями распределения f1, f2 и f1 совпадает с f2, то и p1 тоже совпадает с p2. Вот. И вот там
будет всё то же самое, дискретный, абсолютно непрерывный свойств, из которых всё однозначно
восстанавливается. Дальше будет всё аналогично, значит, ну и это мы обсудим в следующий раз.
Есть какие-то вопросы? Если вопросов нет, то всем спасибо, до следующей пятницы. Кубота.
