У нас с вами до этого на лекции был только map-reduce, и закончили мы на лекциях тем, что join in map-reduce это сильная боль.
Кто может вспомнить основную причину, почему join in map-reduce делать тяжело?
Из тех, кто был на прошлой лекции, я вижу, что здесь много людей, которые были.
Кто может вспомнить, почему join in map-reduce делать сложно?
Потому что у нас разные форматы на вход придут, надо как-то с этим бороться.
Да, то есть с одной стороны на map-reduce у нас есть mapper и user, то есть код, который обрабатывает все данные, которые пришли ему на вход.
А с другой стороны, есть два датасета, у которых разные структуры.
И надо как-то обрабатывать их одним и тем же кодом, и при этом не потерять данные о том, откуда пришли строки с первого или второго датасета.
В общем, сложно, поэтому это подтолкнуло сообщество к созданию нескольких движков, которые работают с SQL.
Можно посмотреть, что не только join вложится на map-reduce, а весь SQL можно переложить на map-reduce.
Давайте посмотрим на вот эти ключевые слова SQL, и подумаем, как можно переложить на map-reduce каждый из них.
Где будет только mapper, где будет только reducer или полная map-reduce джуба?
Давайте подумаем, select – это что в терминах map-reduce?
Map.
Map, да, потому что мы просто выделяем нужные столбцы, то есть нет зависимости между строками.
Where?
Map.
Тоже map, хорошо, а дальше?
Order by, sort by – это что процесс shuffling, sorting?
Ну вот, shuffling sort – да, но если у нас глобальная сортировка order by, то нам нужен reducer.
А sort by – это операция, которая делает сортировку внутри reducer, поэтому reducer тут тоже нужен.
Ну а group by?
Это непосредственно reducer, который у нас как ключи между собой группирует, как раз тесно его задача.
Точнее, это происходит перед подачей на reducer.
Да, это происходит тоже на shuffling sort.
А дальше, в зависимости от того, какая у нас функция агрегации после group by, сумма средняя, там еще что-нибудь, то это может быть либо reducer, либо еще счетчик.
Ну мы помним, что можно, если у нас, например, общая сумма, то есть, например, средняя или сумма по всему датасету, то мы можем счетчики использовать.
Вот, ну join – мы помним, что это полноценный map-reduce, а вот having – это что?
Having можно сделать на reducer, ну а можно сделать на следующем маппере, то есть, полноценный map-reduce с join или с group by.
И потом еще один мап, на котором будет что-то вроде where.
Да, все правильно, так и есть.
И вот то, что у нас SQL превращается в map-reduce, это привело к созданию нескольких движков SQL.
Сегодня мы посмотрим на Hive и работать будем в основном с Hive, но обзорно обсудим и остальные движки, которые у нас сейчас популярны.
Вот, в 2007 году Facebook появился Hive. Сразу следует понимать, что Hive – это не СУБД.
Вот на собеседованиях часто спрашивают, почему, потому что, по сути, здесь нет никаких требований к нормализации, то есть, просто обертка.
Под кодом у нас вычисления на том же map-reduce, хранение данных в том же HDFS, то есть, мы делаем тот же map-reduce код, только оборачиваем SQL.
Вот, ну и появляется одна проблема, что map-reduce мог работать с любыми данными, то есть, какие-то строки на вход приходят.
Мы их как-то парсим, получаем пары ключи значения, и больше нам ничего не надо. А SQL – это значит таблицы, то есть, нужна структура данных.
Вот, то есть, нужна какая-то схема данных, которую мы как-то зададим, и Hive это увидит.
Это такая возможность есть, я вам ее тоже покажу, как задавать схему данных.
Но основная особенность Hive в отличие от обычных релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиз...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиз...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиз...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиз...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
...релиза...
во время выполнения кода ParseException и все упадет.
Дальше симматический анализ.
Что это такое?
Это, как здесь сказано, разыменование звездочек.
Кто вообще помнит с SQL, что такое звездочка, что она
означает?
Все столбцы.
Да, все столбцы, и Hive именно превращает звездочку в перечисление
всех столбцов.
Это тоже важно понимать, потому что запросы типа
«посчитай количество строк», их можно сделать как каунд-звездочка,
а можно сделать как каунд по какому-то полю.
Вот лучше делать каунд по какому-то полю, и в домашних
мы прямо будем это явно указывать, если вы будете делать
каунд-звездочка, потому что каунд-звездочка работает
дольше.
Во-первых, ему надо звездочку эту превратить в список
полей, а во-вторых, прочитать весь этот список полей,
что долго, если у нас особенно формат данных какой-нибудь
колоночный.
То есть со строковым форматом данных проще, мы все равно
считаем всю строку, а вот с колоночным нам придется
считывать все колонки просто, чтобы посчитать каунд-звездочку.
Да, еще проверка типов данных.
Да, в хайве есть типы данных.
И, например, если мы сравниваем интеджер и биг-интеджер,
то все конвертнется неявно в биг-интеджер.
Дальше у нас идет построение логического плана запроса.
И здесь происходят некоторые оптимизации.
То есть, например, хайв автоматически умеет видеть,
что если у нас датасет маленький, то можно его поместить
в distributed cache, и у нас будет map-джойн.
Дальше объединить два джойна в map-редью задачу.
Чтобы было понятнее, давайте я открою предыдущую презентажку.
И мы посмотрим, как можно объединить два джойна.
Вот давайте посмотрим.
Если у нас на этой схеме появилась еще зеленая табличка C, например,
то давайте подумаем, есть ли какие-нибудь проблемы с тем,
чтобы это сделать точно так же за одну джобу, или это легко сделать.
И еще раз, можно вопрос, что за зеленая табличка, если появилась?
Ну, у нас появилась зеленая табличка,
и мы хотим сделать джойн теперь от трех таблиц,
то есть A, innerJoinB, innerJoinC.
Будут ли какие-то проблемы, и нужна ли нам вторая джоба здесь?
То есть, по умолчанию, если мы пишем в хайве A, joinB, joinC,
он это видит как две независимые джобы, то есть A, joinB до одна джоба,
потом все вместе, joinC. Можно ли это как-то оптимизировать?
Ну, давайте посмотрим на эту схему еще раз.
Что у нас, по сути, здесь делается в джойне?
На маты мы добавляем теги. На редьюсере все данные с одним ключом приходят на один редьюсер.
Что нам мешает сделать здесь еще C? У нас просто будет три тега A, B и C.
Но потом мы будем точно также сортировать по ключам, то есть по ключу, который есть и в таблице A, и в таблице B, и в таблице C.
То есть смотрите, если у нас во всех этих трех джойнах ключ один и тот же.
Можете, пожалуйста, напомнить, немножко вылетело из понимания, как мы, Джон, делаем, когда у нас каждый ключ в разных датасетах, видимо, как на этой ситуации.
То есть там ключ UserID есть и в датасете A, и в датасете B, и в датасете C, да, вот как-то так.
Ну да, да, вроде так, да.
Ну мы на мапере добавляем тег, то есть мапер же знает, откуда пришли данные, он это может определить как-нибудь по структуре.
Ну и вообще есть специальная возможность опика, когда можно указать, откуда пришли данные.
В общем, мы добавляем на мапере тег, мы потом лупируем по ключу, и у нас на reuse приходит вот такого типа пары.
Сейчас откроем.
У нас приходят пары типа k, а здесь тег и какие-нибудь еще значения.
Вот, ну и тег может быть и датасета A, и датасета B, и датасета C.
Все равно все пары с одинаковым ключом по определению мапредьюса, они придут на один редьюсер, и мы сможем здесь их поджоинить.
То есть неважно, сколько у нас датасетов, если у нас идет джоин по одному и тому же ключу, то мы можем сделать это за одну джогу.
Если ключи разные, то за несколько.
Сейчас стало понятнее, как можно оптимизировать?
У нас же в джоине мы джоиним две таблички по какому-то ключу.
Да.
И получается, что когда к нам на редьюсер придут один ключ на какой-то редьюсер придет с разным набором тегов,
Да.
то мы сможем как бы в этот момент между несколькими датасетами сопоставить эти ключи и сделать одну строчку у них, да?
Да, конечно, конечно.
А, окей.
Не важно, сколько датасетов, но мы же гарантируем, что все пары с k равно k, они придут на один редьюсер.
Ну и дальше, последняя стадия, с помощью которой мы превращаем sql в редьюс-код, это
построение физического плана запроса.
То есть вот как бы мы сформировали логический план, а теперь учитываем, где лежат данные, как они у нас разбросаны по блокам,
учитываем есть ли партийцы, и про партийцы я расскажу еще отдельно.
И на основе этого уже строим тот код, который будет выполняться вот этим вот execution engine.
Ну и давайте посмотрим, например, плана запроса.
Вот такие вот штуки строит Hive перед тем, как выполнять запрос.
Что мы тут видим?
Во-первых, мы видим, что у нас несколько jog есть.
Во-вторых, мы видим, что у нас вот на stage 1 есть
маппер, мы тут видим, мап, оператор 3.
На маппере происходит table scan, то есть мы делаем какой-то селект.
Есть predicate, то есть мы делаем какое-то where, сравнение чего-то с пятью миллионами, там стэмпа какого-то.
Вот дальше у нас есть шахмансорт, то есть тот аутпут, который подается на редьюсер,
и у нас указывается, как происходит сортировка.
Опять есть слово partition columns, мы к нему вернемся.
Указано, в каком порядке мы сортируем.
Дальше идет редьюсер, на редьюсере мы видим join, left outer join,
по каким ключам у нас join, вот все это мы видим.
То есть вот так у нас сконвертится SQL код map-reduce.
Можно вопрос? Вот эти reduce-output-операторы внутри мап-операторов, это что значит?
То есть мы же еще не приступили к reduce?
Да, это аутпут, то есть тот аутпут, который нам сгенерил маппер.
По сути это шахмансорт, такое не совсем очевидное название,
но если посмотреть на то, что у нас происходит, тут написано sort outer,
поэтому это вот стадия шахмансорт.
Окей, спасибо.
Ну и какие таблицы есть еще в хайве.
Дело в том, что в хайве у нас есть отдельно данные,
а отдельно вот этот самый метастор, который хранит информацию про то,
какая таблица, кем создана, когда создана, какая схема.
И вот в зависимости от того, как у нас хайв влияет на данные,
можно разделить два типа таблиц.
External это значит, что мы просто задаем путь к данным,
эти данные лежат в HDFS, и хайв с ними ничего не может сделать,
то есть это такое вот ридонли.
Мы можем делать всякие селекты, но мы не можем эти данные изменять,
и мы не можем их удалить.
Вот это то, что вы будете делать в домашке, то есть у вас будет везде,
кроме одной задачи, будет external таблица,
где вам нужно будет просто писать селекты,
так как у нас у всех один и тот же датасет, то вы его не сможете изменять.
И managed это как раз наоборот, когда мы явно указываем,
что вот наши данные, и мы их можем изменять.
То есть мы можем делать инсерты, всякие альтер тейбл и так далее.
Ну и по времени жизни у нас может быть база данных временная и постоянная,
тут как бы логично.
Хорошо, теперь давайте посмотрим на пример.
Вот у нас есть такие данные.
Давайте даже посмотрим на класты.
Ну вот есть маленький датасет, есть большой.
И в общем, как эти данные выглядят вообще? Давайте посмотрим.
Вот у нас есть два поля, ip-шник и маска под сети, в которой этот ip-шник относится.
Вот такая простенькая табличка.
И от нас требуется посчитать среднее количество адресов по маскам под сети.
То есть условно, сколько у нас в каждой сети адресов.
То есть что нам нужно сделать?
Пока у нас есть только данные в HDFS и больше ничего,
никакой код на Hive мы писать не можем.
Нам нужно сначала создать базу данных.
И давайте посмотрим, как это делается.
То есть мы создаем вот такую вот базу.
Давайте я сразу буду показывать, как это делать в Hive.
Сейчас я создам папку для нашего курса, потому что здесь таких файлов еще нет.
Я на семинарах более подробно покажу, как можно работать с Hive.
Но сейчас мы просто будем делать так.
Мы создадим файл со скейл-запросом.
И его будем выполнять, смотреть на планы запроса.
Сначала мы создаем базу данных.
И мы будем создавать файл с скейл-запросом.
И мы будем его выполнять, смотреть на планы запроса.
Сначала мы создаем базу данных.
Тут у меня название базы данных, оно может быть любое.
Например, вот так.
Здесь пишется полный путь к мета-стору, где у нас будет все метаданные храниться.
Ну и вот так давайте его назовем.
И все, вот у нас есть код.
Создание базы данных, location для мета-стор.
Выполним мы его вот так.
Все, база данных создалась.
Это легко проверить с помощью такой команды.
ShowDatabases и GrabAllActual.
Вот она у нас есть.
Все, следующий этап это создание таблицы.
Базу мы создали, теперь таблицу.
Поблизу мы создаем external, чтобы мы не могли менять данные.
И вот что у нас тут есть.
У нас есть два поля, как мы и говорили.
Дальше ключевые числа raw format delimited fields terminated by temp.
Это как раз такой простой случай, когда у нас просто есть колонки, разделенные табами.
Ну или каким-то другим разделителем, например, csv.
На семинарах мы будем смотреть на более сложные случаи.
Как задавать таблицу, если у нас есть какая-то помойка с данными, то есть формат непонятный.
Где-то есть табы, где-то пробелы, как на это все накатывать регулярки, чтобы это все парсить на лету.
Как хранить данные, если они, например, лежат в формате JSON, как JSON распознавать.
Ну пока самый простой случай, когда у нас данные, в принципе, уже готовы к работе с хаймом.
А external, это получается, можно вставлять строки, но они как бы immutable.
Или даже в строки нельзя вставлять?
В строки вставлять нельзя, то есть изменять данные нельзя.
То есть таблица формируется только один раз, получается, да?
Что у нас здесь остается?
Указываем нашу базу.
Дальше удаляем таблицу, если она уже есть, и создаем новую таблицу, в которой указываем, как мы парсим формат данных
с torr.txt-файл и где эти данные лежат.
Напомню, здесь у нас 7 гигов данных, то есть не очень мало.
И должен этот код, в принципе, работать не очень быстро, но мы сейчас увидим, что будет.
Что-то он тут не отработал, вместо этого запустилась оболочка хайма.
А, вот это вот.
А, вот это вот.
А, вот это вот.
А, вот это вот.
А, вот это вот.
А, я забыл минусы.
Все, создалось быстро.
Давайте вспомним из начала лекции, почему вот этот код так быстро отрабатывает.
Он же должен таблицу создать.
Все-таки 7 гигов это не 7 килобайтов, их надо по процессу.
Может он не создает?
Не создает таблицу?
В смысле, он не парсит данные.
А почему?
Он запоминает, что вот есть такая таблица, и когда уже операции будут, он еще раз парсит.
Да, именно потому что схема onRead.
То есть схему задали.
Мы, честно, задали, положили в Metastore.
Вот такую схему данных.
Но данные мы не проверяли.
Вдруг там вообще нет двух полей, а есть непонятно что.
Ну и теперь небольшое задание для вас.
Вот еще раз условия задачи.
Попробуйте написать вот этот код.
Попробуйте написать вот этот код.
Попробуйте написать вот этот код.
Попробуйте написать вот этот код.
На обычном SQL.
Тут Hive ничем не отличается от обычного SQL.
Просто для того, чтобы вспомнить.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
У всех есть возможность зайти из компана кластера.
Это не очень хорошо, как я уже говорил.
Это не очень хорошо, как я уже говорил.
И плюс нам еще надо среднее посчитать, а у тебя просто count.
И плюс нам еще надо среднее посчитать, а у тебя просто count.
И плюс нам еще надо среднее посчитать, а у тебя просто count.
И плюс нам еще надо среднее посчитать, а у тебя просто count.
И плюс нам еще надо среднее посчитать, а у тебя просто count.
И плюс нам еще надо среднее посчитать, а у тебя просто count.
И плюс нам еще надо среднее посчитать, а у тебя просто count.
И плюс нам еще надо среднее посчитать, а у тебя просто count.
И плюс нам еще надо среднее посчитать, а у тебя просто count.
И плюс нам еще надо среднее посчитать, а у тебя просто count.
То есть в принципе, начало правильное.
То есть в принципе, начало правильное.
Во-первых, звездочки, во-вторых, это половина запроса.
Во-первых, звездочки, во-вторых, это половина запроса.
То есть в принципе, начало правильное,
Во-первых, звездочка, во-вторых, это половина запроса.
Как называется база данных?
Можете свою создать, а можно посмотреть вот здесь.
Я скинул чат.
Сейчас.
Там не 0,9, там какой-то другой логин, по-моему, есть.
Сейчас, секунду.
Вот такой.
То есть 2021, а потом 2009.
А запустить есть возможность?
Вот еще Светослав прислал запрос.
Смотри, а что такое авг звездочка?
То есть тебе надо среднее количество, а ты считаешь среднее что?
Ну средняя маска это как-то странно.
Да.
Сейчас пароль.
Давайте посмотрим тогда на решение.
Вот у нас такой.
Такой юз.
Сейчас я посмотрю на название таблицы.
Что мы делаем? Мы сначала считаем общее количество айпишников по каждой маске.
Ну а потом усредняем.
Давайте выполним, убедимся, что этот квад работает.
Там я еще указал название джоба.
Можно не указывать, это просто для того, чтобы было удобнее видеть в джобхистори вашу джобу.
Потому что если мы ее никак не назвали, то называться она будет по началу нашего SQL кода.
Вы увидите название джоба и селектов.
Если у многих такие же запросы, то и будет непонятно, где чья джоба.
Вот видите, что у нас получилось. У нас получилось, что у нас две мапридио джобы, total jobs.
Видите, как уже интересно. На обычном мапридио джобе, чтобы написать две джобы, нам нужно было написать два мапера, два редьюсера, написать здоровенные раны Саш, какие-нибудь компараторы.
А тут вот такой вот несложный SQL код и у нас уже две джобы.
Я очень правильно понимаю, что иногда это помогает нам писать меньше кода.
И по факту вот оно там само две джобы делает, но иногда это будет делать менее оптимально, чем мы бы могли.
На семинарах мы посмотрим более подробно, как можно помогать хайво оптимизироваться.
Сейчас, почему-то ничего не выявило.
А, вот выявило одно число. Да.
Вот такое получилось у нас значение.
Давайте поставим тут explain.
Explain это значит, что мы вместо выполнения запроса пишем просто его план.
Вот сейчас он выполнится быстрее, потому что только план можно построить.
И мы видим, что у нас здесь три стейджа.
Почему джобы две, а стейдж три? Потому что последний стейдж это просто вычетка данных без мапридьюса.
То есть два стейджа у нас.
Это мапридьюс и мы видим, что у нас тут есть группировка по каунту.
Точнее, да, у нас тут есть просто каунт, IP в группировке.
Опять же сортировка.
На юсере второй джобы у нас есть AVD в группае.
Вот, и можете также увидеть здесь текст Input формат, Hive Ignore K Text Input формат.
То есть здесь Hive сам умеет указывать типы, ключа и значения.
Вот, кстати, Lazy Symbols RD.
RD это специальный такой пакет, который отвечает за сериализацию, децериализацию данных, за вычетку из HDFS и запись.
И он также отвечает за парсинг данных.
То есть на семинарах мы с вами будем разбирать код, когда данные хранятся, как я уже сказал, в каком-то не очень читабельном формате.
Их нужно будет, чтобы записать в таблицу, сначала поматчить регулярками.
Вот, и за эти регулярки отвечает как раз SRD.
А здесь вместо регулярок мы использовали вот этот таб.
И поэтому у нас получился Lazy Symbols RD.
То есть за вот эти табы, вообще за вот эти разделители, за парсинг датасетов с одинаковыми разделителями отвечает Lazy Symbols RD.
То есть регулярок нет, вместо этого такой простой парсинг.
Вот, разобрались с этой задачей, теперь давайте посмотрим на то, как можно оптимизировать наш код.
Ну и вообще какие есть возможности для оптимизации.
Хайв на джаве? Ну хайв вообще на SQL мы пишем на SQL, а внутри да, внутри на джаве.
И на семинарах мы также посмотрим примеры, когда нам нужно будет достраивать хайв определенным образом
и писать для этого джава-код, да еще на достаточно кривом опи.
Ну такое приходится делать редко. То есть когда мы в хайв встраиваем свои функции,
их, хотим создать такие функции, то их надо писать только на джаве.
Вот, по поводу оптимизации, у нас есть такие вот слова, и давайте разберем, что они обозначают.
И для этого давайте посмотрим на вот такой датасет.
У нас есть таблица, в которой есть страны, города, ну и дальше там жители, имя, фамилия и условно почта.
Вот, ну и наш датасет устроен так, что, ну наши запросы устроены так, что мы хотим делать разные фильтрации
по кантри, группировку по кантри.
Вот, можно ли как-то оптимизировать запросы, если у нас постоянно идет какая-то фильтрация по кантри?
То есть оптимизировать не запрос, а само хранение данных, можно ли как-то оптимизировать?
Ну можно какую-нибудь таблицу создать, в которую мы таблицами кантри чайные просчитаем.
А что именно просчитаем?
Ну зависит от того, что у нас там запрос фигурирует, что мы хотим кантри делать?
Ну у нас какой-то запрос, в котором есть group by по кантри, и второй запрос, в котором есть where
кантри, чего-нибудь там, Россия.
В SQL по-моему есть представления, и мы можем создать различные представления на те кантри, которые нам нужны.
А если мы заранее не знаем, какие кантри нам нужны, то мы просто знаем, что мы будем работать с кантри.
Ну про представление-то это близко, но есть более автоматический способ, если мы не знаем, сколько у нас кантри.
Есть так называемое партиционирование. То есть мы бьем нашу таблицу на части по кантри.
То есть вместо одной таблицы у нас по сути появляется таблица c равно 1, таблица c равно 2 и так далее.
То есть с точки зрения хайва это так и остается одна таблица.
Но с точки зрения хранения данных у нас создается специальная папка, которая называется DateWirehouse.
Туда копируются данные и они распределяются по папкам. То есть вот это вот первая папка в HDFS, это вторая папка в HDFS.
И в каждой папке будет храниться часть таблички с одним значением кантри.
И теперь если у нас есть, например, запрос c типа where равно кантри чему-то, то мы можем не делать full-scan таблицы, проходить всю таблицу и искать вот эти вот ключи.
Мы можем найти просто нужную нам партицию, то есть обойти не все записи таблицы, а обойти только список партиций.
Их будет намного меньше. И как бы выдать вот эту маленькую табличку.
Насколько сейчас понятная вещь про партиции?
Ещё раз, это как бы больше SQL-ная штука, которая в целом устроена в том, что он так делает, или же HIFE это как-то очень костыльно напрямую делает?
Это делает MapReduce. То есть у нас данные разбиваются на маппере, на вот эти папки.
То есть маппер создает папки и распихивает данные по ключу по этим папкам.
А почему очень костыльно?
Не-не, окей, я просто думал, что это может быть как...
А, но кем? У нас же всё равно никуда не получается, всё равно бы это всё MapReduce.
Да, у нас это ещё кто-то MapReduce делает.
Причём мы это делаем каждый раз, когда хотим выполнить такой запрос, да?
Нет, мы это делаем при создании таблицы.
А, при создании таблицы.
То есть мы один раз создали, я тоже сейчас это покажу на примере. Раскидали.
Так, одну секунду, мне нужно отойти срочный звонок. Сейчас я вернусь.
В общем, мы разобрались с вами с партициями, что у нас данные распихиваются по папкам.
Давайте я это тоже покажу в коде.
Сейчас.
Давайте я скопирую код, который у нас есть.
Вот, что у нас тут меняется?
Не видно сейчас экрана.
Ага, сейчас.
Надо делать одну настройку.
Вот, то есть у нас теперь будет немного другое создание таблицы.
Сейчас я покажу какое.
То есть здесь всё остаётся точно так же.
Единственное, что мы должны поставить вот этот ключик.
Что это значит? Это то, что партиции у нас создаются динамически.
То есть мы не знаем, сколько папок у нас будет вот этих.
Мы читаем данные, создаём таблицу и смотрим, вот у нас новая country пришла.
Значит, нужно новую папку создать, новую партиции.
И так далее.
Правда, тут у нас нету country, у нас есть маски под сети вместо этого.
Ну хорошо, у нас будут партиции в виде масок.
Как меняется синтаксис?
Вот у нас появится вторая таблица, она будет называться subnet-spart.
И синтаксис меняется так.
У нас остаётся здесь одно поле, а второе поле идёт в партиции.
То есть мы тут пишем partitioned by.
И здесь пишем шестовое поле mask-string.
Что нам теперь нужно сделать?
То есть вот мы создали такую таблицу.
И возьмём данные из той таблицы, которая у нас была до этого.
То есть у нас была таблица просто subnet, а теперь появилась subnet-spart.
Это делается вот так.
То есть у нас есть insert overwrite table.
Вот такая таблица, которую мы сделали.
partition.
Тут было partitioned, а тут partition.
И в partition мы указываем, по какому полю у нас partition.
То есть тут мы задаём, какие партиции будут.
А тут мы говорим именно, как мы их будем создавать.
По какому полю.
Ну и теперь select звёздочка from subnet.
А partitioned и partitioned – это именно хаймовые функции?
Или они в обычном стиле тоже присутствуют?
Хаймовые, да.
Ну вообще SQL в хайве и SQL обычные, они отличаются.
И даже SQL в хайве, он называется HiveQL.
То есть это всё-таки диалект такой.
Но в тех запросах, которые мы будем делать на семинарах и в домашних,
отличий практически не будет.
Вот давайте запустим этот код.
03 partitioned.
Вот у нас пошли работать жёбы.
Вот эти вот жёбы – это здесь идёт разделение по партициям.
Видите, у нас нигде нет редьюсера, есть только маппер.
Вот что у нас получилось.
Видите, у нас создалось вот столько партиций,
вот вообще сколько у нас получилось в итоге партиций?
Получается восемь.
Стоит по времени в сравнении с предыдущим запуском,
что-то вроде сорок четыре секунды в итоге вышло?
С предыдущим запуском каким?
Там, где мы считали среднее,
то есть по времени мы уже сделал 8 слоя.
в итоге вышло. С предыдущим запуском каким? Там, где мы считали среднее или там, где создавали таблицу?
Ну сейчас, а тут мы что считали? Я просто просил, я думал, что мы самую задачу другим способом решаем.
Смотри, тут как бы по времени сравнивать не очень корректно, потому что не с чем, потому что у нас есть вот такие вот запросы.
И в 0.2 query мы считали средние маски, в общем делали какую-то математику.
А здесь мы просто создаем таблицу, просто уже оптимизированную по партизе.
Поэтому сравнивать создание таблицы с вот этим вот запросом.
Я почему-то думал, что мы хотим в итоге другим способом ту же самую задачу решить.
Мы хотим в итоге другим способом задачу решить, просто я до этого дойду еще.
Сейчас, секунду, я возьму вот этот элемент.
Сейчас же по сути можно выполнить тот же самый запрос, и он должен быстрее отработать, потому что он теперь по партизам будет ходить.
Да, так и есть.
То есть, конечно, создание партизей дольше, чем создание просто таблицы, потому что создание таблицы ничего не делает.
Но теперь, когда мы создали такую оптимизированную таблицу, вот давайте еще раз проверим.
Сделаем query.
Query у нас по обычной таблице. Сколько времени оно будет работать?
У нас сейчас есть обычная таблица и партизионированные. Мы их обе храним и просто сравним по времени.
А вот когда мы разделили партизием и запустили SQL команду, где мы считаем количество, там разве лидиус не должен выполняться, как мы с помощью макера считаем количество?
Количество? Где эта команда?
Где мы считали count по подсетям?
Так все верно. Там, где мы считали count по подсетям, у нас тут и reducer есть.
Два разных запроса.
Первый запрос это создание таблицы с партизиями. Он у нас уже отработал, закончился, и вот мы создали партизии.
Можно даже посмотреть более подробно. Вот наш metastore subnets.part и что тут у нас есть.
Давайте сделаем так. Мы запомнили total map reduce CPU time. 8 минут 15 секунд.
И теперь давайте сделаем вот так. Я открою mux и мы запустим эту задачу только на другой таблице.
Subnets, добавим subnets.part. Ничего не меняя в запросе, просто сменили таблицу из обычной на партизированную.
И пошли выполнять еще раз. Пока будем выполнять, посмотрим сюда, что тут у нас было 8 минут.
И посмотрим на то, как хранятся наши партиции, пока выполняется код.
Вот у нас наши файлы с партициями. Давайте зайдем в одну папку, вот эту например.
Как я уже сказал, каждая партиция это папка.
И тут может быть много файлов, и эти файлы выглядят вот так.
То есть что у нас осталось от таблицы? Осталась одна колонка.
Первую колонку маски мы убрали под партиции, а внутри осталась только последняя колонка, вот айпишники.
И смотрите, у нас total map reduce CPU time spent уменьшился с 8 минут до 5 минут.
Уже вот такая оптимизация на треть.
Это без учета создания изначально таблицы?
Да, потому что таблицу мы создали один раз, а потом запросы будем исполнять часто.
Что еще есть? Какая есть еще оптимизация?
Что еще есть? Какая есть еще оптимизация? То есть вот мы разобрались с партиционированием.
Есть еще кластеризация или багетинг.
Он работает похожим образом, только обычно он работает в паре.
То есть вот мы кластеризовали по одному полю.
Партиционирование по одному полю и кластеризовали по другому.
Чем отличается кластеризация? В принципе, пара вещей.
Если у нас тут были папки, то у кластеризации будут не папки, а файлы.
И второе, что в одном файле у нас будет не для одного ключа значение все, а будут значения для хэша.
По сути, багетинг работает как партишнер в MapReduce, когда мы брали хэш от ключа и делили на количество r.
Правда, здесь будет на b, потому что мы будем здесь задавать количество багетов.
Можем и не задавать, тогда просто каждый хэш от k пойдет в свой файл.
На этой таблице мы уже с вами не будем пробовать, потому что у нас полей нет, у нас всего два поля.
Но в принципе, если в таблице полей больше, то мы можем кластеризовать по полю какому-то, а внутри еще и кластеризовать.
То есть еще более сделать тонкое разбиение.
Но так как считается, что партиции лучше использовать тогда, когда у нас мало значений в поле.
В Country у нас значений немного. Сколько у нас значений? Максимум стран на свете, по-моему, 289.
А городов у нас десятки тысяч, их гораздо больше.
Поэтому для полей, у которых много значений, лучше использовать багетинг еще и потому, что здесь хэш.
То есть в одном багете может быть много ключей.
А в случае с партией так не будет.
Если мы делаем партиции по полю, в котором много значений, мы разобьем табличку на большое количество блоков.
Ну и будет та же самая проблема, что у нас в HDFS хранятся маленькие файлы.
Вот, насколько сейчас понятно про кластеризацию?
Вроде понятно.
А то есть из-за того, что у нас хэширование, скорее всего коллизии.
Вряд ли мы ожидаем большое количество коллизий, поэтому у нас будет очень много файлов из-за этого.
Мы как раз коллизии здесь не боимся, но будут коллизии и будет меньше файлов.
Ну в плане, что большое количество объясняется тем, что хэш функция не по модулю, она разбросает все равномерно.
Да, но можно делать по модуле.
Тут зависит от нас.
Когда мы пишем запрос на кластеризацию, мы указываем там типа cluster by int столько-то багетов.
Вот мы сказали, что мы хотим 10 багетов, а у нас будет деление на 10.
Просто хэш без деления использовать не очень хорошо, потому что, да, как ты правильно сказал, у нас будет много уникальных хэшей и будет много маленьких файлов.
Проблема маленьких файлов в HDFS, она всегда над нами висит, потому что это загрузка на имноды.
Понятно.
Хорошо.
Что касается кластеринга, разобрались.
Что касается map-side-join, это мы более подробно посмотрим на семинарах.
То есть есть специальный синтаксис, можно Хайву специальные подсказки делать о том, что мы поджоиним две таблицы, но одна из них маленькая, сделаем map-side-join.
Не факт, что Хайву эту подсказку услышит.
То есть он может ее воспринять, а может по каким-то там внутренним таблицам.
Причинам ее проигнорировать, в зависимости от оптимизации.
Вот такая возможность есть указать map-side-join.
И сэмплирование.
Есть ключевое слово table-sample.
Table-sample нам нужно для того, что есть у нас, например, очень большая таблица, и мы хотим сделать примерный расчет на какой-то маленьком поддетасете,
аппроксимировать его на большой, ну и в общем оценить что-нибудь.
Поэтому есть возможность сделать сэмпл.
Взять часть таблицы.
И вот тут много возможностей, как мы эту часть берем.
Можно взять n родной таблицы.
То есть если мы будем делать сэмплирование, то мы будем делать сэмплирование,
то мы будем делать сэмплирование,
то мы будем делать сэмплирование,
то мы будем делать сэмплирование,
то мы будем делать сэмплирование,
то мы будем делать сэмплирование,
то мы будем делать сэмплирование,
то мы будем делать сэмплирование,
то мы будем делать сэмплирование,
то мы будем делать сэмплирование,
то мы будем делать сэмплирование,
то мы будем делать сэмплирование,
то мы будем делать сэмплирование,
то мы будем делать сэмплирование,
то мы будем делать сэмплирование,
то мы будем делать сэмплирование,
и мы указали 10%,
то мы возьмём всё равно 50%,
потому что два блока мы возьмём один.
Блоки – это сейчас в терминах HDFS мы говорим, да?
Да, да, да.
То есть удобно делать и сэмпли,
когда у нас есть бакет и есть партиции.
Есть ли какие-то ещё вопросы?
В принципе, на этом сейчас всё по хайву,
что я хотел рассказать.
Можно ещё добавить то,
что по этой таблице мы можем сделать партишнинг.
Да, ещё есть такая штука,
как несбалансированные данные.
То есть, конечно, всё это хорошо,
что мы покластеризовали,
попартиционировали,
но мы не будем делать сэмплирование,
то мы будем делать сэмплирование,
то мы будем делать сэмплирование,
то мы будем делать сэмплирование,
но если у нас в этом датасете
90% country – это Россия,
а здесь 80% city – это Москва.
Тут как бы разбивай, не разбивай,
у нас всё равно будет одна партиция
сильно больше других,
и поэтому у нас есть ключевое слово с cute by.
кода. В общем, чтобы не искать долго примеры
кода с QBuy, это возможность как бы подсаливать наши кластеры и партиции. То есть мы, по сути,
вот это country, большую партицию с России, мы разобьем еще по блокам. Там рандомно или
по какому-то значению. В общем, у нас появится две или три партиции вместо одной.
Это вот как бы борьба с несбалансированными данными. Это касается только партийцы или это...
И багетов. А, и багетов, окей. Так, вот, в следующий раз мы с вами обсудим всякие аналоги хайва,
которые тоже работают с SQL или с чем-то похожим на SQL, но это уже не хайв, это на лекции. А на
семинарах и домашних мы будем работать только с хайвом и больше ни с чем другим по этой части.
Ну а дальше у нас начнется уже Spark.
