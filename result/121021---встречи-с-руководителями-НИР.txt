значит смотрите у меня название темы я дал такой более общая там было написано про геометрию
топологию геометрической теории групп в целом большинство сюжетов которыми я занимаюсь они
покрываются немножко более частным названием тоже достаточно широким а геометрия арифметика и
динамика дискретных групп спецкурс вот с таким названием я читал в независимом университете в
прошлом семестре и в принципе если возникнет интерес можно как бы наверное в первую очередь
туда обратиться но вообще говоря есть уже в общем-то сюжеты которые в этот курс не вошли ну и
сейчас давайте я попытаюсь в кратце рассказать вообще что это такое и о чем речь значит как
правило я буду иметь дело значит какой-то группой ну пока условно назовемый дискретный
которая вот действует собственно дискретный или еще говорят вполне разрывно на каком-то
пространстве x вот это такая самая общая картина при этом это дело пространство x оно в общем-то
может быть много чем но если оно является каким-то хорошим там гладким риммановым многообразием в
частности если это многообразие является фактором до полной группы движений g по стабилизатору какой-то
точки к то есть по максимально компактной подгруппе то есть вот это x будет так называемым
однородным симметрическим пространством то в этом случае у нас интересными свойствами обладает
пространство орбит x по гамма в частности если группа гамма оказалось да дискретный подгруппой
соответственно нашей группы g дискретный подгруппы движений и она оказалась свободной откручения то
вот это m равная x по гамма на самом деле будет тоже риммановом многообразием причем проекция да вот
из этого пространства x в пространстве x по гамма оно там будет накрытием причем хорошим очень
накрытием более того это даже будет локальный изометрии если там есть элементы конечного
порядка то вообще говоря факторе не получится многообразие но получится тоже что-то довольно
симпатичное именно так называемый роби фолд в нашем случае x это как правило одно из трех таких
классических пространств то есть это либо пространство эвклида либо сфера либо пространство
башевского соответственно если мы рассматриваем пространство башевского там возникают так
называемые до всяких гиперболические структуры гиперболические многообразия и прочее вот все
это дело на языке римманова геометрия означает что мы живем в пространствах постоянной
отрицательной кривизны вот но на самом деле у нас вообще говоря вот действие какой-то группы
гамма может быть не связан да с каким-то именно риммановым гладким многообразием вот это вот
икс который здесь написал оно может быть на самом деле метрическим пространством вообще не
иметь никакой гладкой структуры это может быть что-то ну очень такое ну с точки зрения такой
гладкой геометрии специфической там типа я не знаю можно рассмотреть граф снабдить его метрикой да
то есть и вполне себе будут нас бодро действовать дискретные группы на таких вот графовых вещах
вот но там могут быть вообще разные пространства здесь там всякие вот комплексы еще что-то вот как
вообще говорю вот в таком вот в общем виде вот это и есть так называемая геометрическая теория
собственно тут возникает сразу много всего да есть я тут перечисляю области математики которые
вот по всем этом деле сходятся и в принципе с чем приходится иметь дело но во первых уход геометрии
в частности гладкая геометрия типа там основы дифференциальной геометрии основы риммановой
геометрии полезны знать потом топология опять же смотря в зависимости от того какие задачи
приходится решать иногда достаточно ну как бы часто вообще говоря достаточно какой-то такой более
менее базовой топологии там грубо говоря вплоть до понятия там фундаментальной группы гомотопии
и прочего да но в принципе бывает что для там решения каких-то более серьезных там геометрических
вопросов иногда приходится задействовать более сложные топологические методы там из всякой там
комбинаторной агебраической топологии в духе например там групп гомологии к гомологии далее здесь как
бы как я уже сказал возникает геометрическая теория групп вот вообще говоря вопросы которые
которыми я раньше в большей степени занимался они как бы геометрической теории групп относятся
некоторым боком но геометрическая теория групп для нее характерны наверное немножко другие все
таки группы и пространство то есть да они очень часто пилируют там с чем-то с гиперболичностью и
пространствами лобачевского этого как такие базовые там примеры и так далее но в целом они
изучают действия конечно порожденных групп на каких-то металлических пространствах и там
многие ударяются какие-то довольно специфические пространства и так далее но опять же там есть
понятие киперболичности погромову это вещь которая сильно обобщает действия там у компактных групп
в пространствах лобачевского далее здесь это все связано опять же да смотря какими задачами
заниматься все связано с дискретными подгруппами группы вот эти вот группы которые я называл
которые так вот хорошо действует дискретно до комнаты пространстве это часто оказывается от
группы такого вида там всякие слн от z и прочее про эти группы это как бы отдельная большая наука
дискретные подгруппы группы там довольно уже серьезные и причем довольно навороченные методы
есть как что доказывать есть классические результаты полученные там довольно давно и так
далее но опять же да вот это все связано с арифметическими дискретными группами потому
что многие дискретные подгруппы группы они определяются так называемым арифметическим способом
да арифметичность тут тесно связано с теорией чисел там возникают квадратичные формы группы
афтоморфизма в квадратичных форм кватерненые алгебры и там даже эрмитовы формы да построены
над кватерненными алгебрами и так далее вот мы в конце концов для получения у немногих крутых
результатов были применены так называемые динамические методы в частности это было
связано с органической теорией и в общем-то вот теоремы жесткости мостово знаменитые теоремы
маргулиса за которые он получил философскую премию еще там 70 вот они были основаны на
эргодической теории ну я здесь еще отдельным пунктом добавил гиперболические группы отражений
потому что в принципе некоторые вопросы есть которые ну как бы можно начинать с каких-то
вопросов которые живут в отдельно вот в этой теории группы отражений вопросы там есть довольно
сложные но при этом опять же это все очень важно в контексте общей теории дискретных групп и в
принципе там некоторые вопросы которые переносится на общие да теорию дискретных групп и ну то есть в
этом смысле очень удачная такая вещь что вы там делаете что-то в общем виде а можете группам
порожденным отражениями переходить как каким-то примером что-то там изучать вот давайте я
наверное попытаюсь в двух словах теперь объяснить собственно кто-таки что такое дискретность действий
вообще при чем тут все это вообще говоря смотрите я здесь бегаю по слайдам лекций до того самого
спецкурса который я называл и поэтому снова повторюсь что если будет интерес то можно это
все дело потом посмотреть там так а давайте я спрошу слушателей знакомство там с тем что такое
пространство лобачевского есть или лучше ну по крайней мере не знаю двух словах описать что это
такое так хорошо я так понимаю что я могу немножко больше да говорить потому что второй слот на
20 минут не ну не занят никем правильно да все правильно хорошо значит это это радует потому
что мне обычно времени никогда не хватает вот так сейчас я найду и вам тут расскажу
подробненько ну как не очень подробненько но насколько меня хватит
так вот про пространство лобачевского поскольку многие вещи которые мы делаем с ним так или иначе
связаны я давайте покажу общую векторную модель обычно я люблю начинать с нее значит пусть rn 1
это пространство минковского то есть n плюс одномерно вещественное пространство
которое снабжено стандартным скалярным умножением сигнатуры n 1 вот это значит что вот
выберете два вектора n плюс одномерных x и у да скалярное произведение задается как минус
произведение там x 0 и грех 0 плюс произведение оставшихся компонент то есть это задается по
сути матрицей вот такого вида диагональная матрица минус 1 и дальше все единицы значит чем
вообще это все примечательно тем что например группа которая сохраняет да вот это вот скалярное
произведение это вот так называемый дописев да артагональная группа сигнатуры тоже он 1 просто
группа матриц невырожденных сохраняющих наши скалярные произведения вообще говоря и должен
прям сразу заранее сказать что пространство лобачевского во многом так простите плохо
слышал в общем пространство лобачевского оно во многом сложнее чем ифклидова пространство
в общем в целом как правило всякие там разные структуры гораздо разнообразнее богачей ну в целом
надо понимать что как бы ифклидова пространство но такое одно до мир нефклидовых геометрии ну их
просто гораздо больше все геометрии практически нефклидова вот и вот но с другой стороны вот
группа он 1 отр она ну там с точностью до индекса 2 будет группой движений пространства
лобачевского и эта группа как раз проще чем группа движений ифклидового пространства вот
но об этом чуть позже итак как же задается пространство лобачевского значит мы можем взять
конус изотропных векторов то есть таких векторов которые скалярный квадрат равен нулю это будет
вот конус который здесь синим цветом выделен далее он распадается на две связанных компоненты
собственно 6 0 и больше нуля и х 0 меньше нуля так называемый там ну вообще обычно наверное конусом
будущего и конусом прошлого называют все-таки внутренность вот этого конуса вот и что тут
важно отметить что теперь мы можем взять гипербалоид 2 полосный hn да вот он внизу у меня
написан значит это все точки x из rn 1 такие что скалярный квадрат равен минус единицы а
x 0 попало ну их с 0 больше 0 то есть мы взяли верхнюю полу этого гипербалоида вот точки этого
гипербалоида мы называем точками пространства лобачевского всякие там под пространство пересекающие
до hn будут под пространствами пространство лобачевского более того вот можно задать метрику на этом
гипербалоиде дай следующей формулой гиперболический косинов с расстоянием между точками у нас
объявляется абсолютным значением до скалярного произведения между соответствующими векторами
для точек вот лежащих как бы внутри этого конуса будущего у нас получается что там скалярное
произведение на самом деле всегда отрицательно поэтому в данном случае этот модуль раскрывается
просто со знаком минус вот поэтому это верно для точек пространства лобачевского это верно
всегда и можно значит во первых отсюда показать даже упражнение 1 написано можно доказать что
вот группа фактор да по плюс-минус единицы вот группы он 1 от эры это будет группа движений
пространства лобачевского по крайней мере на сне это же доставляется а также можно показать что
вот в терминах вот этой вот нашей метрики если вы возьмете двумерные плоскости да пересечете
гиперболез вы получите одномерные линии на гиперболиде на самом деле это будут гиперболы так
вот можно показать что это и будут геодезические до в терминах римного геометрии то есть они
действительно будут коротчайшими линиями вот и что еще есть примечательного да с пространством
лобачевского например можно его пополнить бесконечно удаленными точками и собственно изотропные
векторы вот в этой модели то есть все такие векторы которые лежат на этом конусе изотропным x на x
равно нулю все вот эти точки называются бесконечно удаленными или точками на абсолюте и так далее
вот в частности я говорил про подпространство да в данном случае они тоже достаточно хорошо
устроены например гипер плоскости задаются просто вектором да вектором нормали если вы
помните может быть то в евклидовом пространстве гипер плоскости задаются условием да там x на
е на самом деле плюс какая-то константа t равно нулю вот потому что есть сдвиг здесь
никакого сдвига нету здесь просто их с на е равно нулю вот и каждая гипер плоскость вас
будет рассекать пространство лобачевского на две части полупространство которое можно задать
там условно до со знаком минуса знаком плюс но опять же это зависит от вектора и векторе ну
удобно нормировать взять его просто с нормой единицы то есть вот здесь вот на этой картинке векторе
я артагональны нашему нашей гипер плоскости будет смотреть куда-то наружу всего этого дела
гипер плоскость будет вот как-то так вот пересекать пространство вот я надеюсь что в общих чертах
это понятно есть дальше изометрием отражение относительно гипер плоскости аш-е но при данных
условиях его можно задать вот просто следующие формулы да мы как бы работаем с n плюс
одномерными векторами и думаем о них про как про точки пространство лобачевского и не трудно
проверить что такая да что такая просто изометрия такое отображение действительно является изометрией
то есть сохраняет расстояние ну в этом и правда легко убедиться вот но что интересно что выполнено
и другое например я не знаю может быть вы слышали про то что и в клидовом пространстве там и на
асфере всякое движения можно представить виде композиций там не более чем в плюс одного отражения
вот но во всяком случае с пространстве лобачевского этот факт тоже верен всякое движение 240 не можно
представить в виде композиции не более чем он плюс одного отражение относительно гипер плоскости
вот ну я не буду тут сильно заострять внимание но есть и другие модели пространство лобачевского
И опять же оно этим достаточно удобно тем, что вы иногда можете использовать разные картинки,
разные визуализации для чего-то, и для разных задач что-то бывает более подходящим.
Ну вот стандартная модель Кляйне — это модель в единичном шаре. Она получается из модели на
кипербалоиде, просто центральной проекции. Все точки кипербалоида стягиваются в единичный
шар, лежащий в карте x0 равно 1. Там, скажем, корочайшие линии становятся хордами. Там тоже
можно как-то считать метрику по каким-то формулам. Есть еще какая-то модель, например, модель
по НКР в шаре. Ну на самом деле есть две конформных модели. Модель по НКР в шаре и модель по НКР в верхнем
полупространстве. Вот модель по НКР в шаре, она там отличается, скажем, она характерна тем,
что там кеодезические это будут либо диаметры, либо это будут дуги окружностей перпендикулярной
абсолюты. Более того, вот это вот точки абсолюта, вот бесконечно доляные точки, они во всех этих
вот моделях в шаре, они попадают просто таки в границу шара. Вот таким образом пространство
Лобачевского оно как бы компактифицируется и у него есть граница, и эта граница топологически
эквивалентно сфере, N-одномерной сфере. Значит, пополненное пространство Лобачевского это,
по сути, топологически замкнутый шар. Единственная только проблема, что внутри у вас есть расстояние,
есть вот эта метрика, а на границу шара эта метрика уже никак, конечно, не переносится. То есть,
предел этих расстояний, которые там, если точки как-то, пределы точек такие расходятся там,
грубо говоря, есть две последовательности, сходящиеся к разным точкам на границе шара,
то у вас расстояние, конечно, там идет к бесконечности между ними. Вот, но опять же, да, то есть,
тут надо понимать, что там метрика есть внутри шара, на границе у нас просто, мы говорим про
какой-то топологический смысл. Так, ну, в общих чертах, что, наверное, еще можно сказать, что в
пространстве Лобачевского, там скажем, в верхнем полупространстве, вот в этой, во второй модели,
там, на самом деле, тоже будут геодезические либо вертикальные линии, либо такие полуокружности,
перпендикулярные абсолюты. Гиперплоскости в этих двух моделях могут быть либо такие полноценные
эвклидовые гиперплоскости, либо это будут такие сферические шапочки, и тоже они должны быть
перпендикулярны абсолютам. Вот, ну, наверное, как бы для деталей как-то уже времени мне не хватит,
поэтому давайте двинемся дальше. Основное, наверное, понятие, которое я хотел сказать,
это вот понятие дискретной группы и что такое фундаментальная область для дискретной группы.
Значит, вообще говоря, почему, в принципе, вот эти дискретные группы важны, интересны,
вообще, где они возникают? Но это, на самом деле, просто-таки самое, что ни на есть,
общее ситуация. Вот, вы взяли какое-то топологическое пространство X, и у вас есть какая-то группа
гомиоморфизмов этого топологического пространства. Эту группу, мы называем, эту группу, ну, точнее,
ее действия вполне разрывным, если, ну, давайте я найду какую-нибудь переформулировку, да, более,
скажем, подходящую там, в более-менее любом хорошем топологическом пространстве, это вполне разрывность
означает, что до любого компакта в X, у вас лишь конечное число копий этого компакта будет
пересекаться с ним самим, да, то есть нету какого-то накопления, то есть, вот, взяли какой-то компакт,
и только конечное число копий, его как-то так вот покрыли, ну, копий с точностью гомиоморфизма.
Все остальные уже ушли куда-то дальше. Вот. Извините, а можно вопрос? Да. Подскажите,
пожалуйста, вот, если писать, как бы, диплом по этой теме, то, в принципе, в какое направление
можно двигаться? То есть, вы можете ли вы какие-то вот темы предложить, например, или направления? Да,
вот, я сейчас как раз, собственно, хотел сформулировать определение, да, дискретный
групп подвижений и дальше обозначить, куда можно от всего этого отталкиваться.
Спасибо. Значит, вот опять же, да, откуда все это берется? Дело просто в том, что у любого,
вот, всякое линейно связанное, локально стягиваемое узор в фотоапологическое пространство,
оно есть фактор своего универсального накрытия по некоторой группе же, которые действуют
свободно и вполне разрывно. Собственно, если у вас, вы уже теперь имеете дело не просто с каким-то
топологическим пространством, а с каким-то геометрическим пространством, да, там, где есть
какая-то структура гладкого многообразия, то у вас уже эта группа же имеет какое-то, уже какие-то
имеет свойства не только топологические. Вот, в частности, например, возникают, да, такие вот вещи,
когда вы взяли какую-то римового многообразия, и оно у вас накрывается каким-то хорошим односвязанным
римовым многообразием, а ваша фундаментальная группа действует на накрывающем как дискретная
группа движений. Вот, дискретность группы движений, по сути, означает, что есть просто-таки какая-то
группа, которая действует, да, она действует движениями на каком-то пространстве, и все
орбиты дискретны, вот здесь у меня написано, а все стабилизаторы должны быть конечны. Ну, и там
простейшие примеры для вот этих вот дискретных групп движений. Так, я надеюсь, они у меня где-то
в этом слайде даже будут. Так, а может быть и нет, сейчас секундочку я найду. Вот, да, значит, вот,
в частности, скажем, группа Z квадрат, которая действует целочисленными параллельными переносами
на евкалидовой плоскости. Вот, вот эта группа, она действует дискретно, потому что орбита любой точки
это просто решетка, да, на плоскости. Стабилизаторы в данном случае вообще тривиальные. Более того,
в данном случае пространство орбит, фактор Е2 по гамма, это все равно, что взять фундаментальную
область, в данном случае можно выбрать, например, квадрат, и произвести, да, как бы склейку границ,
и в данном случае получится просто тор. Что такое фундаментальная область? Вот фундаментальная
область, это какая-то такая хорошая область, которая красивым образом замощает все пространство.
Красивость вот этого замощения, в частности, означает, что любые две копии могут пересекаться
только по граничным точкам этой замхнутой области. Внутренними точками разные копии этой фундаментальной
области не пересекаются. Вообще говоря, понятие фундаментальной области, это такая вещь не
однозначно определенная в том смысле, что объемы всех фундаментальных областей равны для дискретной
группы движений, но вообще выбрать ее можно разными способами, например, для той же группы z квадрат
можно взять, замостить такими параллелограммами или квадратами, в зависимости от того, как вы выбрали
базисные векторы для группы z квадрата, а можно взять, ограничить графиком функции, и получится
замощение в форме черепицы. Это будут все хорошие фундаментальные области. Вообще говоря, важная
теорема, которая здесь уже не сформулирована, но я назову ее в общем виде, что в хороших вот этих
пространствах, где есть там какая-то геометрия, фундаментальная область выглядит довольно хорошо,
ее можно выбрать как какой-то обобщенный выпуклый многогранник. В силу этого возникает сразу такая
связь, то есть есть дискретная группа движений, вот тут какая-то теория групп, с другой стороны,
фундаментальный многогранник, он на самом деле, это некоторые теоремы, он задает вот эту вашу
группу. Дальше там возникает какая-то геометрия и может быть комбинаторика у этого многогранника.
Помимо прочего, в факторе у вас получается х по гамма, это тоже будет какое-то интересное
многообразие, у него будут какие-то там свои геометрические, топологические свойства, вот,
и прочее-прочее. Вот, ну давайте в целом очертим круг задач, которыми можно заниматься. Вот,
как я говорил, там достаточно такой важный класс вот во всей этой науке, это так называемые группы
попрожденные отражениями, вот для них, например, для них фундаментальные многогранники определены
как раз однозначно с точностью до изометрии, это будут такие многогранники, у которых двугранные
углы между граничным гиперплоскостями имеют вид там п делить на целое число, скажем там это могут
быть 90 градусов, 45 градусов, 60 градусов и так далее. Там вот в этой теории возникает, в общем-то,
много вопросов и, например, ну я не знаю какие есть, ну я, к сожалению, сейчас как бы в состоянии сил,
что просто времени мало, назвать только такие сложные давние вопросы. Ну, например, вот Виндергам
было доказано, что компактные многогранники Кокстера существуют в пространствах Лобачевского,
могут существовать, точнее, только вплоть до размерности 30. Ну, точнее, им было показано,
что с размерности начиная 30 их не существует. Рекордный пример известен в размерности 8 и
ему уже там 30 лет. Вот можно пытаться понять, что происходит в этой ситуации. Ну, так вот,
за короткое время трудно, наверное, сформулировать больше конкретных вопросов, но это связано,
как я говорил, с арифметическими группами и, в частности, там с группами, например,
автоморфизмов, солочисленных квадратичных форм. Вот эти вещи, опять же, там, а это интересно,
там, для теоретика числовиков и так далее. Там другие вопросы стоят, но тоже связаны и с
группами, с многогранниками и прочее. Например, там стоят вопросы о классификации арифметических
групп или о том, как связана арифметика, то есть теория чисел, да, с геометрией топологии
соответствующих многообразий. А подскажите, такой вопрос еще можно? Да. Вот есть такая штука,
я не знаю русского термина, но по-английски геодезик regression называется, да, то есть просто
такой вопрос возникал, можно ли как-то будет это, ну, допустим, если писать диплом,
соединить это с машинным обучением, да, то есть, например, именно вот эта вот регрессия,
да, для предсказаний, допустим, расстояний, да, на поверхности, с, вот, риммоновским многообразием,
да, и, допустим, расписать как-нибудь там, допустим, градиентный спуск, оптимизацию,
как красиво сделать, это было бы интересно еще? Ну, как бы стандартная тема. Я думаю,
что это было бы любопытно, потому что, насколько я понимаю, многие такие вот, да, как бы вот эти
данные там имеют гиперболическую структуру, скажем, ну, мне было бы любопытно посмотреть,
что там можно поделать вокруг гиперболических пространств, вот. Ну, опять же, да, гиперболичные
структуры, в частности, подразумевают, что эти данные, ну, типа, можно вложить в пространство
Лобачевского, то есть, там, грубо говоря, у них там отрицательная клевезна, вот. Такими вещами,
ну, такими вещами, локально даже я занимаюсь сейчас, то есть, мы что-то делаем про там, ну,
мы, правда, немножко в другой теме, там, про, это самое, как это называется, graph-based nearest neighbor
search, но, в принципе, мне любопытно, то есть, я в этом заинтересован, но надо понимать, что,
все-таки, да, я в целом чисто математик, вот, поэтому... А, извините, не затруднит, вот я ссылку в чат
отправила, ну, может бегло, скажете вообще, имеет смысл или нет? Просто если, ну, как бы,
формат позволяет так спросить, если нет, то нет. Да, но я думаю, что, на самом деле, я более-менее
подошел к концу со своим рассказом, то есть, я в общих чертах описал, какого рода картинки
у меня происходят, вот. Так, мне сходу трудно понять, мне, видимо, надо будет более подробно
посмотреть, но выглядит красиво. То есть, теоретически можно как-то что-то... По крайней мере,
по крайней мере, можно обсудить, да, по крайней мере, можно обсудить, ну, то есть, надо понять
более конкретные формулировки, и я дальше скажу, что, если я там, все-таки, почувствую, что я совсем
буду мало этим заниматься, то тогда не стоит, а если я, все-таки, скажу, что я, прям, буду готов
в это погружаться, то... И такой вопрос, как вот будет разделение между математикой, ну, между
теорией и, как бы, имплементацией? То есть, ну, то есть, в какую сторону может быть диплом? То есть,
это может быть чистая математика, или это может быть, допустим, реализация, на том же питоне,
как бы, интересно. Ну, какая-нибудь библиотека может быть там... Не, в целом, мне интереснее,
конечно, чтобы это было. Ну, то есть, если мы будем что-то там показывать, доказывать про какие-то
алгоритмы полезные там для машинного обучения, то я думаю, что это может быть
любопытно и вам, и мне. Просто имплементации, но я за ней уже буду хуже следить,
честно говоря. То есть, как бы это... А, то есть, такой, типа, на стыке это интереснее? Да, на стыке это
интереснее. Вот, опять же, если мы что-то поделаем такой теоретической, и до этого
проведем эксперименты, это одно. Но если это будет чистая библиотека, то я просто
уже, ну, буду хуже до этого доходить. Вот в чем поинт. Понятно, спасибо. Вот. Так, а есть
еще какие-то вопросы?
Ну, в любом случае, я так понимаю, что вопросы или интересы могут возникнуть
потом, я готов писать. Но, в целом, я вот что хочу отметить, что все-таки, да, меня
интересует, конечно, как-то более-менее что-то связанное с пространствами, ну, с
римовыми многообразиями, как минимум, да, с какой-то геометрией. Потом, да, если что-то
делать такое прикладное, но, скажем, все-таки связанное, как бы, такое более
теоретическое. То есть, не просто сидеть, да, какие-то библиотеки делать. Ну, в большей
степени, меня, конечно, интересуют всякие вещи с отрицательной коревизной. Вот. То есть, там,
так или иначе, связанное с пространствами Лобачевского. Ну, и, насколько я знаю, что,
вот, в машинном обучении, в computer science, это там уже, как бы, к этим пространствам сильно
повышается интерес, там, в последние лет десять, наверное. Вот. Но, еще в большей степени, мне,
конечно, интересуют вот такие чисто и с фундаментальной математики вещи. Вот. И, в целом, если, вот,
вы хотите чем-то подобным заниматься, то, конечно, я, и я забыл, насколько я помню, здесь, в основном,
четвертый, пятый курс, кажется, собраны, да. В общем, меня, конечно, интересует, чтобы, если кто-то
ко мне приходит, то, все-таки, чтобы был какой-то достаточно серьезный бэкграунд, в духе, там,
знакомства с основами топологии, с основами дифференциальной геометрии, с основами, соответственно,
там, теории групп и, ну, я не знаю, хоть, там, какой-то совсем базовой теорией чисел. Там, ну, типа,
основы теории ГУЛА, например. Вот. Ну, вот, как-то так. Если есть вопросы, то пишите, мне можно написать
по почте. Я не знаю, наверное, оставить свой контакт стоит. А, можно в телеграмме написать. В
телеграмме меня можно найти вот так вот. НВ Богочев. Ну что ж. А подскажите, вот, графовые подходы,
вот, то, что вы делаете с соседями, это получается на нейрон, как вы делаете, или как другому? Да,
мы вообще просто, в принципе, анализируем алгоритмы и про, ну, грубо говоря, выясняем, там,
при каких режимах, что и как хорошо работает. Ага, понятно. Ну, у нас там были эксперименты, да,
но это, в общем, там, в основном, мы брали какие-то датасеттеры, равномерно распределенные, то есть,
там, где-нибудь в шаре, что-то такое. Все, наверное, я тогда отключаюсь.
Да. Ага.
Алексей Яковлевич, ну, наверное, можно начинать ваш доклад. Да-да-да, давайте, хорошо. Давайте,
я, вот, можно шерить скрин? Сейчас, давайте, шер скрин. Сейчас, одну секундочку. Сейчас,
одну секундочку, я просто, почему-то оно у меня, у меня не все в этом самом, одну секундочку. Я не
понимаю, почему оно то, что нужное мне не показывает. Сейчас, одну секундочку. А, вот, наконец-то. Все,
видно мой экран? Да, видно, все хорошо. Все, давайте, я сформулирую задачу. На самом деле, из некоторой
задачи следует куча проблем теории колец и алгебры, но я понимаю, я щипал задачу, сделав ее чисто
комбинаторной, но на самом деле из нее следует куча проблем, связанных с теорией колец. Вот
формулировка задачи. На ленте напечатаны цифры от 1 до 9, но это я делаю только для того, чтобы не
обсуждать идиотские вопросы, а что будет, если с нуля начинается. Докажите, что либо из нее можно
вырезать 10-100 значных чисел идущих в порядке убывания, либо какая-то комбинация букв повторится
10 раз подряд. Ну, соответственно, есть задача, другая версия этой задачи. На ленте напечатаны
цифры от 1 до 9. Докажите, что из нее можно вырезать либо K чисел в порядке убывания, либо какая-то комбинация букв
повторится N раз подряд. Я советую начать с того, чтобы решить эту задачу. Эта задача олимпиадная,
но на самом деле из этой олимпиадной задачи следовали классические результаты, которые являлись
решением проблем, стоявших десятилетиями. Ну, понятно, что трудно не только решить
это хорошая олимпиадная задача, сколько понять почему. И это придумал Шершов. Он, кстати,
научный руководитель философского лауреата Зельманова. Эта задача олимпиадная придумана.
Теперь вопрос. Если лента не бесконечна, то как оценить длину куска, на котором это выполняется?
То есть это выполняется не только на бесконечной ленте, но и на достаточно длинной. Кстати, задача,
почему, если это выполнено для бесконечной ленты, то это выполнено и для достаточно длинной.
Имеется экспоненциальная оценка и субэкспоненциальная. И я верю, что есть полиномерная.
Как получить субэкспоненциальную, я, конечно, говорить не буду за оставшиеся 15 минут,
но давайте я скажу такую вещь. Есть такой вопрос. Докажите, была задача московской олимпиады,
что число расстановок из n чисел, никаких k, из которых не идут по редке убывания,
не превосходит такой вот величины. k-1 в степени 2n. И еще вопрос. Это уж совсем не сложная олимпиадная
задача, но все-таки расставлено k и m плюс одно число. Тогда среди них найдется либо m плюс 1 в порядке
возрастания, либо k плюс 1 в порядке убывания. Теория Мудиловарса. Диаметр d частичного
порядочного множества. Есть максимальная антицепь. Докажите, что частично порядочное множество
разбивается на d цепи. Вопрос у меня такой. Кто-нибудь знает теория Мудиловарса? Сталкивался с ним?
Теперь вопрос про числа. k-m плюс одно число, либо m плюс 1 в порядке возрастания,
либо k плюс 1 в порядке убывания. На эту тему из олимпиады собралось 100 людоедов. Известно,
что из любых десяти один откушал другого. Доказать, что найдется цепочка из 12 вложенных
людоедов. Решение этой задачи сами можете сообразить, но я скажу, потому что оно забавное. Назовем
людоеда добрым, если он никого не ел. Добрых людоедов не более девяти. Из любых десяти один
откушал другого. Назовем людоеда добрым в первой степени, если он ел. По-английски
я бы употреблял место имени Хио-Щи. Ел только добрых людоедов. Соответственно,
в второй степени, если он ел, не является добрым в первой степени, но ел только добрых и добрых
первой степени людоедов. Соответственно, имеется двойственное доказательство,
что найдется людоеда живым, если он никого не съел. Если его никто не съел. Назовем людоеда живым
в первой степени, если его ели только живые людоеды. И вот теория Медиловерса, из этого следует
вопрос. Понятно, что когда у нас слова полилинейные, то есть каждая буква встречается один раз,
это про их структуру этот вопрос. Но есть убежденный, что игра инотеория Медиловерса можно
оценить. А как это оценивается? Был проект на летней конференции турнира городов. Ну, давайте,
я есть в 2012 году. Ну вот, я покажу, нужно же, я все-таки скажу, что это значит. Потому что,
когда все-таки выглядит как олимпиадная задача, это выглядит неосолимно. А вот,
когда из этого следуют результаты в теории корец, достаточно долго стоявшие, это и в том
числе и некоторый прорыв. Давайте я покажу. Это стоя в математическом сборнике, но из нее следует
слово называется н-разбиваемым, если из него можно вырезать n кусков, идущих в порядке убывания.
И вот на самом деле теория мышершового высоте, что если слово н-разбиваемое, то оно кусочно
периодично. То есть его можно разрезать на небольшое число кусков, и каждый кусок устроен как степень
некоторого слова, ныне выше. И это достаточно важная задача. Ну, я просто это показываю,
потому что народ любит умные слова, и что из этого следует в теории корец и высокой
математики. Но на самом-то деле и куча проблем, ну, какого ранга, например, из этих результатов,
доказав, что если в алгебриле, из этого следует, что если в алгебре есть тожество xw равно нулю,
то и образующих конечное число, то алгебра нерепотентна, то есть произведение достаточно
большого числа элементов равно нулю. Вопрос какого? А вот это вопрос про оценки. Зельманов получил
философскую премию, когда сделал аналогичную вещь для алгебрыли, и он пользовался в социативном
случае. Это соответствующая статья есть, но я говорю, что это имеет вполне не элементарные
последствия. Но мое дело вам, собственно, сказать, как оно выглядит, элементарную формулировку. То есть
бывает, что задача решается элементарно, но хотя задача, факт про комбинаторику слов, то тем не
менее, средства происходят в высокой науке. Но чтобы говорить о технике, я бы мог бы, давайте еще был
проект на летней конференции турнира городов на эту тему. И вот это был проект летней конференции
тургора. Давайте я сейчас кину ссылку на летнюю конференцию тургора в чате. Но на самом деле,
потому что народ же любит не элементарные слова. Сейчас, как кинуть в чате?
Сейчас, одну секундочку. Ну потом, давайте, как кинуть в чате? Сейчас шоу горит в виде, а можно
и вот чаты, давайте. To everyone. Вот я все справился с чатом, вот ссылка. Это можно посмотреть,
но реально это утверждение, я готов общаться, получилось у меня кинуть в чате или нет?
Да, получилось. Все, хорошо. Получилось. Тогда вот это просто, все это разбито на части, но какая
моя цель от этого проекта? Цель проекта, то есть у меня есть интуиция, но не хватает энергии,
что это, что оценку, ну вот вернемся вот в эту самую теорему, что вот у нас дана, то есть все
все эти последствия для теории колец, для алгебры, то есть это прорывные, для advances
in mathematics можно опубликовать. Все это, ну, наверное, за эти 10 минут я просто обозначил,
что есть алгебраические последствия и дезертация была Миша Харитонова защищена. Он
оказал оценку n в степени log n, что если длина число образующих на n в степени константа на
log n, какая, неважно, она ни о чем не говорит, но если можно сделать число, что если какая, если у
нас алфавит из к букв и тогда и слово не режется, нельзя вырезать n под слов, идущий в порядке
убывания, то это может, то тогда какая-то комбинация букв повторится n раз подряд, это найдется во
фрагменте ленты длины не выше, не n в степени log n, а я убежден, что n в степени некоторая константа,
есть некоторый набор утверждений, и вот это как раз имеет последствия для оценки индекса
нерепотентности радикала в алгебрах и в том числе в теории вариантов, и во всех это и в высшей
математике, но говорить о ней, ну вам было бы, ну зачем вас загружать, просто я обозначаю, а так,
для первого вопроса, на ленте напечатанной цифры сначала забьем на оценки, просто чтобы понять,
это олимпиадная задача, накажите, что либо вырезать k чисел идущих в порядке убывания,
либо какая-то комбинация букв повторяется k раз подряд, первый вопрос просто забить на оценку,
лишь бы как бы, а если лента не бесконечна, то как определить куску, ну сначала была оценка
рекурсивная, потом экспоненты от экспоненты, потом я придумал оценку связанную с экспонентой,
это все разрезано на части и дано в летней конференции, но если это интересно, я готов обсуждать
идеи соображения, связанные с тем, как получать оценку полинамиальную, но чтобы это обсуждать,
нужно самому решить или самой решить задачу про оценку длины куска ленты, это соответственно,
ну а про идея, если делать субэкспоненциальную оценку, она связана с тем, что мы берем большие,
что берем точку в слове, берем его хвост, правую часть слова, хвосты упорядующиеся лексикографически,
еще в порядке возрастания, дальше применяется теория Модинмарса, собственно, но естественно,
что при сдвигах возникают разного рода эффекты, которые стоит обсуждать и думать, но перед тем,
как это говорить, я просто призываю посмотреть основной вопрос. Сначала мы смотрим, забивая
на оценки, что вот на ленте напечатана цифра от 1 до 9, что либо из нее вырезается К чисел порядка
убывания, либо какая-то комбинация букв повторится К или Н раз подряд, что это чистый вопрос по
комбинаторике, но из этого вопроса по комбинаторике вытекает куча интересных вопросов по алкебре,
в том числе и полтерийные варианты, и всякое такое, которое возникает. Вот такого рода вещи возникает.
Сейчас я на лекции через пять минут смогу. Вот это то, что начинает наблюдаться у меня. То есть,
получая, мы берем хвосты от точки этой и дальше смотрим теория Модинмарса, это идея, и вот из нее
получается субэкспоненциальная оценка, потому что хвосты сравниваются лексикографически, а потом
по возрастанию. Естественно, что иногда хвосты совпадают. Иногда мы можем пользоваться тем,
что происходит. Вот это идея. Ну а вот как дальше этого делать? Это вот конкретный вопрос теории
колец, который мне кажется достаточно любопытным. У меня двадцатиминутное выступление. Собственно,
я такое и сделал. Но вообще, теория колец, причем тут тождество? Дело в том, что есть ли у нас,
что такое тождество в некоммунативном кольце? Это произведение слов равно линейной комбинации
слов в переставленном порядке. Поэтому, если подслова идут в порядке убывания, то если их
переставить не тождественно, то все слово уменьшится. Поэтому, если в алгебре есть тождество,
то мы приводим слово к линейной комбинации того же, к меньших слов. И если есть подслова,
идущие в порядке убывания, то она приводится. А если она не приводится, то таких слов нет. Ну тогда
она кусочна периодично. Вот причина в алгебре. Но, конечно, это утверждение, чистая комбинаторика
слов. Никакой алгебры нет, абсолютно элементарное утверждение, но из нее следует алгебраически
разного рода последствия, которые мне очень важны, достаточно интересны для всего сообщества. Ну,
например, из аналогичной комбинаторики для алгебрыли родилась Филсовская премия. А здесь мы,
мы здесь обсуждаем комбинаторику ассоциативных алгебр, но она сформулирована на элементарном
языке и полностью ощипанная. Соответственно, есть статья Миши Харитонова. Ну вот, я еще пролистаю
слайды. Вот это, вот Курш сформулировал проблему, что верно лишь, что конечная порожденная нель
алгебра, то есть степень элемента равна нулю нельпатентно, Капланский, Шершлов улучшил,
ну и довольно он учитель Зельманова. Соответственно, Зельманов, Филсовский лауреат,
задал вопрос о негнеэкспоненциальной. Ну и вот на самом деле она субэкспоненциальная. Хочется
сделать полиномиальное. Полиномиальное это будет вообще прорыв, но я убежден, что это делается и
осуществляется. Так что это вот, собственно, это слайды к диссертации Миши Харитонова.
Ну, я думаю, что успехи отстанет. В нельпе есть оценки, ну это, сейчас, в оценке высочного высоте.
Ну, подробно предстоит была аналитная конференция, старую задачу я сказал, если кому заинтересует,
готов общаться. У меня есть профайл на сайте Маслая труба, что-то с маслой перелеткой.
Вот это мой емейл, и я тогда смогу вам, давайте я кину. Сейчас как чат сделать. Сейчас чат сделаю.
Вот мой профайл, и там есть емейл. Спасибо, что прослушали. Понятно, что вообще комминаторика слов,
она интересна тем, ну там есть куча других задач, что с одной стороны это элементарно,
учиться много не нужно, результаты можно сразу получить, и она обслужит и теорию групп, и теорию колец,
и биоинформатику, и все на свете. А при этом знать ее много не нужно, чтобы получить первый результат,
и это не к тому, чтобы не учились вы вообще, но все-таки. И это интересно, например, есть в Люмени,
в Марсели, есть французская школа, просто во Франции снабировали все, что не евреичный геодоле,
но все-таки, например, геодоле в присутствии, говорили, что со временной Ристотили ничего
принципиально нового в логике не сделано, что просто абсурд. А потом, естественно, что возникла
все-таки страна большая, Франция нужна, чтобы была дискретна, и возник альтернативный мест,
центр, это Люмени, где комбинаторика слов. Там штаб-квартира французского математического общества,
то есть это в каком-то смысле то, что я говорю, мода французская, ну и я сказал про один аспект
комбинаторики слов, но есть и другие, например, внешний бильярд, бильярд из точки, и, кстати,
на эту тему был проект в Сириусе, вокруг комбинаторики слов и внешнего бильярда. Давайте я сейчас это,
тоже покажу, дам ссылку, потому что я не могу сразу много говорить, но давайте еще вот одну ссылочку я дам
совсем, чтобы, но на самом деле понятно, чтобы представляли какие задачи, естественно, что есть
продолжение. Это вот, сейчас вот я копирую, копировать адрес ссылки, еще дам ссылку, и вот это,
это вот кусочные в клитовую динамику. Поэтому, ну и, например, частично другая постановка задач,
я сейчас, где они бывают, давайте я еще одну ссылку своей обзорной статьи про это самое,
про это самое Banach Central Publications, архивную статью сейчас скажу еще раз.
Сейчас, сейчас, одну секундочку, сейчас, вот еще одну ссылку я кину, чтобы какое-то представление было,
но, ну и, наверное, я покажу еще одну ссылку, связанную с внешним бильярдом, тоже достаточно красивый факт,
и сейчас из тина. Вот это, сейчас покажу, одну секунду, я покажу еще одну довольно красивая вещь,
это в системе истины про внешний бильярд, там красивые картинки, но нет времени показывать.
Кстати, вот такая, ну это просто другие задачи, которыми я занимаюсь, а так за 20 минут,
такого рода Олимпия однозначности. Спасибо, если вам показаться забавным, эта задача решит первую задачу,
буду рад взаимодействовать по другим темам. Всего доброго, хорошо, спасибо.
Спасибо, Алексей Евгеньевич.
Константин Юрьевич, тут есть вопрос насчет звука, меня нормально слышно, потому что мне как бы то,
что Алексей Яковлевич говорил бы, иногда было с какими-то задержками, я хочу понять, это у меня
проблема, ну то есть сейчас вы меня будете плохо слышать или это проблема была у Алексея Яковлевича?
Ну вот вы меня сейчас нормально слышите, или вы очень хорошо слышите?
У меня тоже были задержки большие, но вот вас тоже, меня смущает то, что и вас плохо слышно.
Да, нормально слышали все, хорошо, да, отлично, отлично.
Ну то есть меня нормально слышно?
Все, тогда два слова.
Хорошо, все, всем благословение.
У меня есть телефон и дороги, я сейчас переподключусь, мне должно быть нормально.
Да, сейчас я тогда тоже.
Ладно.
Сейчас минутку.
Так, значит я тогда наверное сделаю так, что вы меня будете видеть соответственно с одного устройства,
а шарить экран я буду на другом, вот, и я хочу сделать доклад используя планшет, вот, и мы по идее вы
сейчас должны его видеть, правильно я понимаю, вы видите, да, мой планшет, так, ну хорошо, давайте начнем.
Значит, мы занимаемся, вот наша группа в фистехе занимается распределенной оптимизацией, просто оптимизацией.
В общем, задачи, которые мы можем предложить, это в основном задачи связанные с какими-то конкретными приложениями
или теоретически задачи, вот, оптимизация.
Ну, в качестве примера вот из таких, что можно совсем кратко и просто рассказать, например, можно такую задачу рассказать,
вот дана функция f от x, надо ее минимизировать по x, но, значит, к сожалению, градиент этой функции точно нам недоступен,
то есть нам дают какой-то неточный градиент вместо точного, ну, и дальше вот есть некоторые естественные условия,
которые часто имеют место на практике, что эта неточность, она как-то контролируется, допустим, настоящим градиентом, вот,
ну, то есть если настоящий градиент маленький, то и эта неточность маленькая, вот такая постановка задачи.
Что бы было, если бы эта функция, которую вот я сказал, была бы доступна с настоящим идеальным градиентом,
ну, тогда, наверное, бы мы могли эту функцию отоптимизировать как-то очень правильно, быстро, согласно теории,
ну, например, оптимальный метод, значит, выглядит он таким образом, это быстрый метод Нестерова.
Давайте я рассмотрю случай, когда функция μ сильно выпукла и имеет сильно выпукла и l гладкая, ну, что это означает?
Это означает, что λ-min на гессиан f от x больше либо равняется μ, а λ-max, ну, минимальное собственное значение гессиана
и максимальное собственное значение, вот они лежат в таком, вот они чему удовлетворяют, то есть, по сути, спектр гессиана лежит на отрезке μ-l,
μ минимальное значение, l максимальное, то есть я здесь даже могу на самом деле просто равенство написать по определению,
ну, естественно, min и max берутся по всем точкам, ну, то есть λ-min минимальное собственное значение для всех x, ну, понятно, давайте все-таки корректнее будет написать,
поэтому, так как я писал, вот что, вот так, вот, ну и тогда метод, который был предложен Нестеровым довольно давно, 20 лет, 30-40 лет назад,
плюс корень из l минус корень из μ на корень из l, плюс корень из μ, xk минус xk минус 1, он будет сходиться, соответственно,
он будет сходиться, и сейчас что-то меня тут laptop и минус 1, будет сходиться вот таким вот образом, значит, так, по порядку lr2 экспоненты,
я числовые константы не пишу, минус, тут тоже числового константа под экспоненты не пишу на N, вот он как-то так сходится.
Повторю, что это все с точностью до числовых константов, которые меня не сильно интересуют, то есть вот я сюда должен,
должен что-то написать и сюда. Какую-то числовую константу. Ну там два-три, одна-вторая. Вот что-то
должен написать. Вот я не буду это делать. Возникает вопрос, при каком альфа мы можем говорить о том,
чтобы вообще метод сходился так же, то есть практически неизменно. То есть то, что ему не дают
градиент, а дают не точно, градиент, это у него никак не сказывается на метод. Вот оказывается,
что это было, правда, было доказано немного для другого метода, но из той же линейки, что вот альфа
можно взять, если вот альфа меньше чем μ на л в степени 3 четвертых, то вот эта оценка скорости
сходимости, она практически никак не изменится. Она конечно ухудшится скорой сходимости, но все
останется приблизительно так же. Числовые константы немножко изменятся, но в принципе все останется
так же. Вот верно ли это при больших альфа? Открытый вопрос. Теперь вопрос, а зачем все это? Ну вот
какие-то, значит, такие постановки, где есть какая-то неточность, к чему это? Здесь какая-то мотивация.
На самом деле мотивации, она не одна, их очень много, и такого рода постановки возникают, в общем,
совершенно в разном контексте, начиная там от обратных задач, заканчивая современными приложениями
квантизации, raw compensation, распределенной оптимизацией. То есть иногда ошибка связана с тем, что вам
надо решить задачу, например, в каком-нибудь Гильбертовом пространстве, обратную задачу. И для того,
чтобы посчитать градиент этой функции, ну обратная задача, часто это просто задача вот такого
вида x-b, два норма в квадрате на минимум. Только а это какой-то дифференциальный оператор, ну то есть
чтобы посчитать от x надо решить краевую задачу. Это нельзя сделать аналитически,
потому что x это функция. Вы оптимизируете в пространстве функции. Более того, чтобы посчитать
градиент, вам еще надо сопряженную задачу решить, потому что градиент будет считаться по формуле вот
такой, и вам еще надо будет, соответственно, уметь считать сопряженную, градиент, значит,
сопряженный оператор. То есть сопряженную краевую задачу решать. И, в общем, это некоторые
накладывают ограничения на то, что, например, нам, в принципе, невозможно идеально посчитать
градиент, потому что, чтобы его посчитать, надо идеально решить начально краевую, или просто
краевую задачу. А это можно только численно делать. Вторая мотивация связана с тем, что,
например, считать градиент просто дорого, ну или он у огромного размера, а мы хотим использовать
вектор, который каким-то образом апроксимирует градиент, например, случайно выбранный
К-компонент. Ясно, что этот вектор как-то скоррелирован с настоящим градиентом, и он, по идее,
должен как-то отражать направление спуска. Но вот можно ли его использовать? Естественно, если
речь о коммуникации, то лучше передавать несколько там компонентов градиента, чем весь градиент,
это дешевле. Но вот расплата будет замедленнее. Ну вот, собственно, возникает много вопросов,
связанных с тем, что вообще, как бы, правильно делать в таких задачах. Ну вот, базовый сюжет
здесь, это вот исследовать, например, неточность, с которой эти задачи следует решать. Ну вот,
я просто что, вот, можно за пять минут, привел пример конкретной постановки задач, которую,
которую ответ этот получил Артем Васин. Он был на втором курсе, когда я так же, как сейчас,
рассказывал эту задачу. Сейчас он на третьем курсе. Вот, в прошлом году, где-то в это же время я эту
задачу рассказывал, он ее решил, и весной получил вот такой результат. Сейчас вот он готовится
стать об оптимизации, ну, в общем-то, журналку одеть. Вот. Так что, ну, как это происходит? Ну,
то есть, вот, есть какая-то мотивация, есть некоторая математика уже более-менее развита,
и хочется эту математику применить к, вот, к этой конкретной постановке, к какой-то другой постановке,
чтобы получить вот результат. В данном случае результатом является вот эта форма, что, значит,
сходимость не замедляется. Если вот, замечу, что это, на самом деле, совсем не тривиальное
наблюдение, потому что, если мы берем неускоренные методы, которые, вот так выглядит,
хк плюс 1 равняется хк, минус 1 на л, градиентов от хк, они сходятся, естественно, хуже, медленнее,
то есть, вот. Ну и для этих методов ситуация получается лучше. Медленнее они сходятся,
потому что здесь нет корня. Нет корня. Вот. А здесь корень есть. Смотрите, здесь вот корень есть,
а здесь корни нет, а это число маленькое. То есть, чем оно меньше, тем хуже, потому что это,
значит, соответственно, будет мешать экспоненте быть маленькой, что будет экспонент от нуля,
близко к нулю. Ну, за счет того, что он большой, оно, конечно, выйдет оттуда, но тем не менее. Вот. Это
просто один пример того, что, да, я забыл сказать, что, да, вот в этом случае альфа просто меньше единиц
условия. То есть, здесь, видите, как получается, что для неускоренных методов они намного рабасни,
но это потому что они сходятся медленнее, а когда сходимся быстро, они чувствительнее
оказываются. Ну вот, насколько этот порог можно отодвигать, это открытая задача, ответ на которую
мы не знаем. Вот. Сейчас популярно очень направление развития всяких вот методов. Сейчас, Константин
Юрьевич, сколько у меня времени? 20 минут данного выступления, приблизительно. Алё. Коллеги,
сколько тут приблизительно выступали предыдущие докладчики? Минут по 20, наверное, где-то. Да,
по 20 минут, но после вас никого нет, поэтому. Хоть потоп. Да-да-да, именно. Ладно, я понял. Ну,
хорошо. Значит, давайте какую-нибудь другую постановку задачи просмотрим, чтобы просто не было
такого ощущения, что всё как-то вот чисто такое теоретическое. Значит, у меня есть сейчас желание
сразу показать, просто давайте я временно остановлю расшаривание экрана, чтобы расшарить другой
экран, с которого вы меня видите. Это у меня сейчас ноутбук. Я здесь сделаю демонстрацию экрана и
покажу. Значит, ну вот это не то, что я хотел показать сейчас. Неудобно, метод Zoom мешается. Так,
давайте его закроем. Значит, смотрите, вот у нас достаточно большая активность есть. Вы можете
просто на архиве такой сайт, есть архив.org, вбить, допустим, мою фамилию, ну или фамилию, кто вам
интересен, и посмотреть, вот какие последние там на данный момент работы, то есть чем вот группа
это занимается. Это довольно удобный способ, или то же самое дело из Google Скаляря. То есть это вот,
если вы хотите выбрать там научного руководителя, как вариант вы можете вбивать его фамилию или
фамилию там, с кем он работает, и просто смотреть какие там у него статьи, там открываете профиль,
и, соответственно, смотрите по цитируемости, по погоду, какие есть публикации, ну как вот вам
удобно. И, в общем, по названию докладов смотрите, что как бы вам соответствует. Ну и я могу вот
просто пройтись, допустим, чем мы в этом году занимались. Ну вот, допустим, последняя статья,
это статья совместно с западным коллегой Питером Ректариком и коллегами из Яндекса,
Лискин и Рябинина, это из Яндекса. И, конечно, Саша Безносиков, который вот очень активен, он,
значит, как раз вот сейчас организует лабораторию Яндекса. Не организует, а, я бы так сказал,
придаёт ей какую-то новую жизнь. Вот, параллельно проходит мероприятие, оно уже заканчивается там.
Вот, эта статья посвящена тому, как решать седловые задачи, эволюционные неравенства, это вот ГАН,
например, обучение генеративных состязательных сетей с квантизацией, когда не огромных размеров,
и мы, естественно, распределённых обучаем, то передавать полные градиенты, я уже немножко об
этом упоминал, затратно, и стараются сжимать информацию при передаче. Насколько это замедляет
скорой сходимости такого типа исследования? Вот эта статья, наверное, мне про это отдельно надо
сказать, я поэтому вернусь к этой статье, потому что действительно сейчас очень важная и популярная,
она прошла на НИПС, вот, она написана вот Сашей Безносиковым, там Саша Рогозин и другим нашим коллегой
из Америки Альдис Кутария. Вот, ну в общем, да, вот предыдущая статья про персониозированный
федеративное обучение тоже сейчас очень, ну, технология Google уже лет пять, как она популярна,
и вот как, значит, соответственно, можно в данном случае получать новые оценки, то есть там,
до этого были в централизованном случае, вот у нас в децентрализованном случае, когда обучение еще
децентрализованное, вот нижние оценки, верхние оценки, то есть достигающие эти нижние оценки,
ну и так далее. Вот статья, которая тоже прошла, нет, это на другую конференцию прошла, значит,
соответственно, седловые задачи, это вот когда дроны летают и тоже там что-то состязательно,
как ансет, но он меняющихся графах, распределенная оптимизация на меняющихся графах, то есть нам
надо решать задачу, а коммуникационная сеть, она меняется со временем, это вот типично,
когда есть какие-то дроны, кто-то отваливается, куда-то улетает не туда, не в поле видимости,
и вычислительная сеть меняется со временем, это тоже очень популярное направление. В общем,
я могу продолжать, вот смотрите, тут просто только в этом году, и вот, значит, все это как бы,
я не буду, естественно, сейчас вам рассказывать про каждый из этих направлений, то есть понятно,
что большая группа, там 30 человек, я посчитал буквально перед этим мероприятием, сколько,
значит, у меня 25 студентов и 15 эсперантов, это конечно проблема с одной стороны, а с другой стороны,
это на самом деле создает очень такую конкурентную среду, вы, наверное, видите сейчас наш слаг,
да, ну слаг, видите, коллегия, вы что-нибудь видите или нет? Да, видно. Вот, ну вот, смотрите,
это каждый, как это делается, вот по каждому там проекту есть большое количество людей,
студент, аспирант, вот Павел Дуреченский, он доктор наука там из института Верштраса,
и сказать вот сейчас.
Так, какая-то проблема произошла, да, меня на время выкинуло, я правильно понимаю,
да, да, на время зависли. Да, давайте я вернусь в наше пространство слаг и постараюсь просто
рассказать, как это происходит, значит, так, да, все нормально, так вот, ну, соответственно,
есть какая-то задача, вот, например, там западный ученый Ролан Хильдебран, который сейчас активно
перебирается, у него же есть ученики здесь, она участвует в активных проекте ВТБ, ну вот он тоже
в одном из двух проектов Хуавей, вот он курирует там свою группу студентов, аспирантов и стехов,
очень хороший специалист по тоже оптимизации, вот, и в общем происходит, что Хуавей ставит
задачу, дает деньги, ну и группа студентов, аспирантов решает эту задачу, естественно,
там что-то программирует, но по ходу дела прокачиваясь в том, что изучают какие-то
методы оптимизации, которыми эту задачу надо решать, или даже, я бы сказал, не столько методы,
сколько какие-то технологии, подходы, ну есть, естественно, разные там у них направления,
вот сейчас два проекта, от Ляшева и Плотникова и Моисеева, они связаны с распределенной оптимизацией,
вот как раз это то, что сейчас очень популярно, вот, есть большое количество проектов непосредственно
завязанных на какие-то статьи, тут где-то 50 участников, ну, собственно, вы можете стать
потенциальной частью этой команды, где вот в такой конкурентной среде, активной среде, постараться
найти свое место, свою задачу и, в общем, идти по пути там сотрудничества, возможно, чисто
научного, возможно, с какими-то компаниями, там, БТБ, Хуавей, Яндекс, ну, с кем, так сказать, кто
предоставляет такие проекты, ну, то сам Хуавей, как раз в прелести надо сказать, вот, и, собственно,
возвращаясь теперь к, ну, уже к математике больше, я снова хочу поделиться экраном и продолжить
мотивировать, ну, вообще, зачем это все нужно, почему людям интересно, по-прежнему, вообще говоря,
чтобы оптимизации занимались, потому что может показаться, что все давным-давно сделано, вот,
давайте я один только сюжет расскажу, кто был сейчас на семинаре Яндекс, я буквально две минуты из того,
что сейчас буду рассказывать, тоже упоминал, но более полно я здесь расскажу. Значит, большинство задач
машинного обучения, они выглядят вот таким образом, то есть, у нас есть некоторая функция, известная нам,
как правило, эта функция есть, например, квадрат невязки, есть какая-то модель f от x и набор,
так сказать, выборка, ну, даже тут можно, ну, хорошо, обычно делают вот так как-то, x тут,
тут какой-то data set делают, y, значит, ну, обычно вообще машинного обучения параметр theta обзывают,
а x как-то, значит, это уже в оптимизации любят x, и поэтому давайте я поначалу буду писать
theta, чтобы было понятно, так сказать, вот, значит, у нас здесь theta, а здесь x, вот, и вот, значит,
обычно эта функция выглядит вот таким вот образом, то есть, есть какая-то модель нейронная сеть,
допустим, нейронная сеть, нейронная сеть, а эта нейронная сеть имеет веса-рёбер, вот веса-рёбер,
веса-рёбер, ну, а это входы, это метки, лейблы, которые там в конце нам, ну, обучающая выборка,
она состоит из пар, но это как бы, она состоит из пар, когда мы начинаем сэмплить, а вообще говоря,
мы верим в то, что есть какая-то такая вот модель, ну, наша модель, мы хотим, ну, нейронная сеть,
мы хотим явление, которое там описывает эта нейронная сеть, заточить нейронную сеть так,
чтобы она это явление описывала как можно лучше, то есть это стандартная постановка задачи,
и наша цель подобрать параметры так, чтобы мат ожидания по неизвестному закону распределения,
нам неизвестно по какому принципу обучающая выборка, состоящие из пар, x и y дается, ну,
так сказать, генерируется, но, тем не менее, вот нам эту задачу надо решать, то есть что мы можем
сделать? Ну, мы можем первое, что сделать, посчитать стахастический градиент всей этой функции,
напомним, мы эту функцию называли вот f от x, f от x, ну, значит, мы можем посчитать градиент вот от этой
штуки, мы можем посчитать конкретные точки, и эту информацию мы можем как-то использовать, ну, как
можно использовать, ну, например, организовав какой-нибудь метод, который называется sgd,
или какой-нибудь sgd с батчем, и, соответственно, возникают всякие вопросы, как там выбирать шаг,
как выбирать размер батча, там, делать ли это адаптивно, всякие начинают появляться adam,
adgrad и так далее, это сейчас не очень интересно, это все как бы хорошо, более-менее изучены онлайн
подходы, хотя тоже, тут много чего интересного есть, вот, что следовало бы сказать, но не буду
сейчас сюда уходить, а есть оффлайн подход, оффлайн подход заключается в том, что мы вот эту задачу
исходную, звездочка, не пытаемся решить как задачу сток оптимизации, а просто ее заменяем
задачей по принципу Монте-Карло минимизации выборочного среднего f от t кс и к, соответственно,
от 1 до m, вот, вот такая вот постановка, ну, ясно, что это разные постановки, но что важно,
что, соответственно, для выпуклой постановки, когда f функция выпукла по t, как функция от f
t кс, равномерно по кс и выпукло по t, то в этом случае число сэмплов, но число итераций n,
которое необходимо сделать обычным методом sgd, вот n, пропорционально 1 на epsilon квадрате,
если мы хотим, чтобы мат ожидания f от x, f, вот эта f функция, ну, мат ожидания, естественно, по кси и
по тета в данном случае, тета n, вот, тета n от кси минус f от, ну, тут в данном случае берется,
значит, вот так, минимум. Давайте мы еще для удобства ведем функцию f с чертой, мне так будет
удобнее писать, нежели писать вот f от t, это вся вот это, только это не минимум, а сейчас это будет вот
это f от t, вот это будет f от t, потому что тут я уже схлопнул по мат ожидания. Так вот, тогда мне не
надо будет писать такой, не надо городить такой город, я напишу проще, мат ожидания по, ну, в данном
случае тета n, ну, ему обычно не пишут, когда f от тета n, потому что оно выдается алгоритм,
использующим случайные величины, минус f от тета со звездой, это оптимальное значение, f с чертой только,
значит, меньше f, то есть вот столько сэмплов требуется, чтобы сделать вот этот результат для
выпуклых установки, но и оказывается, что столько же сэмплов надо взять вот здесь, при правильной
регулизации, там это, что сейчас не буду говорить, чтобы решение задач, идеальное решение вот этой
задачи, вот этой задачи было бы, имело такое же бы, такое же качество, то есть чтобы качество было
одинаковое, тут надо сделать такое количество шагов, а здесь надо взять вот такое число сэмплов,
ну, понятно, что это одинаково, оно и не удивительно, потому что у нас, надо сказать, как бы физика-то
одна и та же, мы используем одну и ту же выборку и, значит, оба подхода в каком-то смысле равнастейны
с точки зрения вытаскивания информации из выборки, онлайн и офлайн, просто онлайн подход,
он как бы, он не требует решения вспомогать на задачи и могут данные онлайн поступать, а офлайн
подход требует, и это дополнительные затраты, с другой стороны, есть возможность делать распределенно
все это дело, хранить там, но зато задачу надо решать, вот это обучение, и часто эти подходы
смешиваются, потому что начинают решать стахастическим градиентным спуском задачи минимизации
суммы и получается какая-то небольшая каша, то есть, вроде это онлайн подход, но это как бы онлайн подход,
он применяется уже к офлайн постановке задач, то есть, если вы допускаете обращение к той же выборке
еще раз, ну, к тому же к сикатому, то это уже не совсем честный онлайн подход, но так называемый
датасет можно пройти несколько раз, и это не будет сильно чувствоваться, вот если очень много раз
проходить, то это уже начинает чувствоваться, но речь сейчас не об этом, а о том, что вот эти
задачи, естественно, решать, уже пытаться распределенным образом, и здесь возникает очень
интересные, на мой взгляд, степени свободы, потому что, конечно, никто не хранит одну функцию на
одном узле, а хранят обычно несколько функций на одном узле, и обычно это несколько функций, довольно
много, то есть, не так уж и мало, вот, и вот эти функции, ну, тогда будет двойная индексация, потому что
сейчас два индекса, значит, вот это надо минимизировать, вот это, и вот это хранится все дело,
значит, на одном узле, вот это все на одном узле. Дальше возникает такой вопрос, вот как на эту
задачу правильно смотреть, редукция дисперсии, сейчас я скажу, что это такое дисперсии, или же,
или же, или же similarity, тоже скажу, что это такое, это уже современно, то есть, это уже не старая
оптимизация. Редукция дисперсии — это попытка учитывать структуру задачи общей, вот такой вид
суммы, в которой вот важно, что слагаемой не просто какая-то абстрактная функция от это,
ну, выпуклая, то есть, если у нас было просто fk от это, это одна история, а у нас fk от это с
такой структурой, это можно использовать, именно с точки зрения там, того, что можно случайно
выбирать слагаемо, то есть, использовать какую-то рандомизацию дополнительную, similarity, что это
такое, это означает, что функции один на корень и зер близкие, близость функции, то есть, это значит
и близость этих функций к исходной функции, чисто статистических соображений, то есть, если это
независимо одинаково распределенные случайные величины, то вы можете быть уверенными, ну, если
выпустили какие-то общие такие нормальные условия типа, более-менее, неближчивость, там, еще что-то,
ну, на самом деле, там, нужно правильно это формулировать, в каких терминах там нам это нужно
будет, ну, десиана, вот, что эти функции близки, как вот выпуклые функции, у них там близкие десианы,
это означает, что, ну, поскольку квадратичная опроксимация во многом характеризует свойства
оптимизационной задачи, то эти, ну, как бы, происходит минимизация суммы близких функций,
как это можно использовать. Вот сейчас научились, более-менее, не до конца, но вот это использовать,
но использовать по отдельности, то есть, использовать отдельную редукцию дисперсии,
то есть, структуру суммы, и отдельно similarity. Вот что-то промежуточного не дано, что хочется
в какой-то степени то, другое. Зачем это нужно в промежуточной степени? Ну, зависит от соотношения
параметров, зависит от того, какое R, какие свойства функции, и хочется по максимуму, значит,
это все дело как-то использовать, и понятно для чего. Я приведу один пример. Это наша совместная
работа с Yahoo. Я был сам сильно удивлен, потому что, когда все это начиналось, мы как-то не очень
так верили, что все это как-то может сильно выстрелить, но вот что оказалось. Нам дал Yahoo,
ну, вот мы стали с ними сотрудничать, компания Yahoo, дали такую постановку задачи. Вот
логистическая регрессия, то есть, это функции F специального вида, вот, это выпуклая постановка,
и M у них было 100 миллионов, по-моему, может быть, да где-то так, M 100 миллионов. Они решали эту
задачу центральным сервером, ну, то есть, в такой архитектуре, что, значит, один узел,
центральный узел, ну, и много слейвов, которые там могут подсумы считать. Какая была идея,
значит, вообще, в решении этой задачи? Ну, вообще, по-хорошему, идея решения задачи заключается в том,
что такое решить задачу F от X на минимум? Что такое шаг радиентного метода? Шаг радиентного метода
— это взять и заменить задачу ее моделью, параболическая аппроксимация. То есть, мы берем ряд
Тейлора, функции в точке XK, и вот эту квадратичную форму, которая, ну, я пишу ряд Тейлора со
статичным членом Фарма Милагранджа, вот, здесь будет одна-вторая, ну, и здесь какая-то квадратичная
форма X-XK, то, значит, соответственно, какой-то гисиан в промежуточной точке, это так напишу,
на X-XK. Вот такая вот задача. И вот эту штуку я оцениваю сверху, как пользуюсь тем,
что у меня есть лицевость градиента, вот таким образом. То есть, получается некий параболойд вращения.
Ясно, что это мажоранта. И идея очень простая, у меня есть моя исходная функция, и есть вот это
вот мажоранта, параболойд вращения, то есть вот этот параболойд вращения, это вот эта функция,
которая стоит вот здесь, вот здесь стоит. Ну, и я перехожу к минимуму модели, если я перехожу к
минимуму вот этой модели, которую легко находить, потому что в случае задачи безусловной оптимизации,
это просто будет XK минус 1 на L, градиенты F от XK. Это аналитическая формула, это есть шаг
градиентного спуска. Но это же не настоящая как бы функция, это модель ее, аппроксимация сверху,
то есть это красненькое, это то, что я нарисовал вот с этой вот штукой. Но я перехожу к минимуму модели,
я знаю, сколько я в модели выедаю, как минимум столько же я выедаю у своей функции, потому что это
мажоранта. То есть, понятно, что идея в том, что надо заменить целевую функцию, ну метод разделяю
властью, принцип разделяю властью. Я заменяю, ну вообще говоря, непонятную функцию, параболойдом
вращения, который просто минимизируется, и получаю, значит, вот такую вещь. Теперь проблема какая,
что у нас эта функция состоит вот из таких вот слагаемых, значит, мне надо, получается,
это все дело вот здесь посчитать и вот здесь посчитать, ну если я использую метод Ньютона,
допустим. Но, ну то есть, как бы это я сейчас говорил про, соответственно, шаг там метода первого
порядка, можно, например, использовать метод второго порядка. В методе Ньютона я просто
брал бы тогда здесь вот эту точку, заменял бы ее на xk. Вот это был бы метод Ньютона. Если бы я не
заменял, у меня бы получилась более точная модель, но тогда не было бы параболойда вращения, и тогда
бы все было сложнее, но и нет глобальной исходимости. Но в целом это все вот как бы лучше работает,
вот быстрее сходится. Вот смотрите, вот эти коммуникации, которые нам здесь надо осуществлять,
они, вообще говоря, что-то стоит, уж просто так коммуницировать не хочется. Посылать градиент,
это нормально, это размер типично, это нормально. Поэтому, в общем-то, если эту задачу центральный
узел будет решать, то вот это собрать ему не составляет труда, ну во всяком случае, так,
в нормальной постановке, он просто соберет градиенты от слагаемых и составит модель градиента
всей функции, потому что посчитать, собрать с них градиенты, градиент первые функции, там градиент
м той функции, ну чего делать, надо собрать, соберет в какой-то точке. А вот уже гессианы собрать
он не сможет, но ему и не надо это делать. Почему? Потому что если эти функции близки, то гессианы у
них, гессианы функции fk, соответственно, и функции там, допустим, исходные функции f, это, значит, два
норма, тут порождена векторная норма, но это в данном случае матрица. Значит, это будет по порядку 1 на
корень из r. Естественно, там будут ходить какие-то размерности матриц, но 1 на корень из r с ростом r это
уменьшается, числа слагаемых в узле. И мы получаем, что, ну, грубо говоря, центральный узел ставит сюда,
в эту модель свой гессиан, и этот гессиан достаточно близок к гессиану всей суммы. Такая идея. Но потому
что мы имеем близкие функции. Ну и давайте, соответственно, запускать метод, как бы, как бы Ньютона
с неточной гессианом. Я с чего начал? Говорил, что вот, значит, у нас там есть методы, интересно
анализировать, как они там сходятся, если их шевелить. Зачем нужно это шевеление? Ну, я говорю про
градиент. Пожалуйста, постановка задач оптимизационной, которая мотивирована современными
приложениями. То есть, вот она возникла не из пустого места, она как бы пришла из того, что хочется
побыстрее сходиться, меньше коммуницировать, использовать как-то специфику, которая идет из
анализа данных. Ну вот, как ее можно использовать. Что мы знаем, что у нас не оба какие слагаемые,
они с ними похожи друг на друга. Похоже за счет статистической природы и выборки, что мы считаем,
мы верим, что выборка более-менее из одного и того же распределения. Если это так, то тогда и
статистическая близость есть. А если статистическая близость есть, то мы берем часть выборки,
храним ее на сервере, причем это может быть не в равных пропорциях, можно разделить. И вот этого
оказывается достаточно, чтобы довольно быстро обучаться. Вот чего меня удивило, что такая
простая идея, естественно, она была более хитро выиграна, это в одной статье, вы можете там
посмотреть. Там авторы Цезару Рибе, Сумин Ли. Сумин Ли как раз в Яху работает, Эрик Арден. Ну,
я эту фамилию не произнесу точно, Эрик, в общем. Это вот, что это очень классно сработало. Ну,
неровная эта идея, некоторая, так сказать, вариация. И мы вот эту задачу очень быстро решили,
несмотря на то, что у нее переменных было огромное количество, там миллионы и слагаемых там сотни
миллионов. И метод был тензорный. То есть вот на вопрос, вообще, может ли методы типа Ньютона
решать задачи машинного обучения, ну, вот как бы кажется удивительным. Но тем не менее, вот такая
идея, она оказывается довольно плодотворной. И плодотворна она по двум причинам. Вот одну из
них я вам сказал, а вторая причина связана с тем, что, значит, если все-таки делать какую-то подсуму,
то есть все-таки считать гисян суммы, но не все части. То есть здесь можно заметить следующее. Ну,
нам в любом случае придется это делать, потому что вот, потому что в узле хранится, чтобы посчитать
гисян вот этой штуки на центральном узле, нам надо посчитать сумму гисянов. Но смотрите,
если r имеет ту же размерность, что и вектор θ, то получится, что посчитать гисян, надо сложить
гисяны вот этих вот, ну, то есть надо сложить r-матриц, сложить r-матриц. Каждая матрица n на n,
размерность n, то есть надо r на n в квадрате арифметических операций. С другой стороны,
чтобы посчитать обратный гисян, ну, это нужно для метода Ньютона и его подниму подобных,
нужно n в третий, ну, обратить матрицу. Естественно, вы скажете, что есть Штрассен, который быстрее
обращает, есть и, в общем, сейчас рекорд n в степени 2.30 чем-то, но это не практичный алгоритм,
Штрассен практичный, 2.70 чем-то. Ну, в общем, не помню точно, какая там показатель, но не суть.
В общем, n в кубе вот, то есть ясно, что если r порядка n, если r порядка n, то вы не заметите,
вы просто не почувствуете, что вам надо считать гисян. И это здорово. То есть, фактически,
как бы, все, что тратите, это как если бы задача была не суммой. Вот это нивелируется тем,
что надо обратную матрицу. Все равно, считать, она сильно ускоряет процедуру. Ну, вот такого
рода трюки, их большое количество, вроде как, простые, классические, они обрамляются в какие-то
современные постановки, в современной реалии, связанные с какими-то большими размерностями.
Ну, здесь я семилярити обыграл. То, что я вам говорил про статью на НИМС, там, где Безносик,
первого автора, это седла. Это вот для седил был предложен вот этот алгоритм семилярити. Ну,
то есть, более аккуратно это прорабатывается, там, где-то с привлечением каких-то тензорных идей,
где-то без привлечения. Вот, и в целом, ну, вообще, я исходил из того, что у меня будет 20 минут,
вот, поэтому я как бы, так сказать, и готовил на то, чтобы буквально, вот, немножко вас погрузить.
То есть, резюмируя, хотел сказать, что, ну, в общем, очень открытых задач, где требуется
определенная квалификация, прежде всего, математическая и программистская, и что довольно
много степеней свободы для реализации, и команда у нас достаточно дружная, большая, и очень много
разных людей, которые, вот, специалисты в разных областях, совершенно разных, но с оптимизацией
связанных. Вот, и мы активно сотрудничаем с западными коллегами, многие из которых русскоговорящие,
но, собственно, они русские, просто, так сказать, в Олистудии там оказались, ну, и с настоящими
иностранцами. Вот сейчас как раз часть ребят, с которыми мы работаем, трое, по-моему, а Мартина
Такача в Абу-Даби, вот, стажируются там два месяца, без носиков как раз, в Бурахмонсадеев, но Дима
Камзолов туда на поздог поехал, там очень хорошие зарплаты, да, ну, то есть, в общем, ну, он вернется,
мы с ним договорились, что он вернется, и всех я вообще призываю, то есть, если, как бы, цель куда-то
там побыстрее уехать или там, то нас, как бы, наоборот, у нас цель нашей группы, чтобы стараться,
все-таки, ну, если не задержаться в науке, то, как минимум, в общем-то, как-то, ну, стараться что-то
делать здесь, хотя это не дуально, то есть, в общем, тут тоже каких-то ограничений нет, но при прочих равных,
конечно, нам интереснее работать с ребятами, которые, в общем-то, нацелены жить и работать здесь,
в России, чтобы, ну, какое-то долгосрочное что-то получалось, но, тем не менее, вот, на поздог я многим
рекомендую съездить и получить этот опыт, и на стажировки ездить, естественно, это очень важная
вещь, то есть, ни в коем случае не, так сказать, не засиживаться вот в этом смысле на одном месте,
а периодически с разными людьми, с разными группами иметь взаимодействие в разных проектах. Ну,
вот, нормальный студент, а такой средний, обычный студент, вовлечен в один-два каких-то
индустриальных проекта и, в общем, пишет там по несколько статей в год, ну, старших курсах,
естественно, ну, собственно, вы и есть старший курс, там уже буквы в ряд. Четвертый-пятый, да, курс сейчас?
Анастасий Юрьевич, я правильно понимаю? Да, четвертый-пятый курс здесь. Ну,
может быть, кто-то и другой. В основном приглашали четвертый-пятый курс, конечно.
Александр Владимирович, что-то, наверное, пропал маленько сейчас.
Ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну, ну
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
Ну,
А
Алё 어
Да,
Меня слышно
Алё
Да
Алё
О, отлично
Написал свою почту, в какой момент я пропал?
Да минут на пять пропали.
Папа, папа.
Всё, сейчас вас слышно.
Сейчас, я пропал в какой?
Ну, то есть я что-то рисовал или не помню тебя?
Не, не, я что-то просто выкинул вас, не знаю почему.
Нет.
Ох, да, ну надо было, конечно, мне как-то это раньше распознать.
Я, к сожалению, не помню, когда меня выкинули.
На словах, когда я сказал, что пятый и четвёртый курс преимущественно здесь.
А, хорошо. Ну, собственно, в общем, я просто хотел оставить информацию.
А можно вопросы задать вообще или не получится?
Да, да, конечно, конечно.
Да, задавайте, никого нет после, Александр Владимирович, если он готов, то пожалуйста.
У меня несколько вопросов было.
Первый вопрос вот вы показывали по поводу saddle point, седловой точки.
То есть это вот для решения ганов использовалось или для какой-то другой цели?
Ну, если честно сказать, то с ганами всё сложно, потому что они не выпукло-вогнутые.
Мы умеем хорошо делать выпукло-вогнутые, но есть ганы, которые выпукло-невогнутые.
То есть по одной группе переменных они выпуклые, а по второй...
Что такое ганы? Ну, по сути, седловая задача.
Вот нам бы хотелось, чтобы была выпуклась по этому, а вогнутась по этому.
Вот если так, то тут мы как бы вообще очень много чего умеем делать, там всё хорошо.
Но проблема в том, что настоящие ганы не такие.
Ну и приходится как бы делать то, что часто называют эвристикими.
Мы говорим, что давайте сделаем хороший алгоритм для задачи выпукла-вогнутой,
а потом будем его применять как градиентный спуск.
Он же для выпуклой задач хорошие теории имеет.
Но потом будем применять его ганами и посмотрим, делаем эксперименты, как это работает.
Работает нормально.
То есть, грубо говоря, есть корреляция между хорошей теорией метода выпукла-вогнутом случае
и его работой в невыпукло-вогнутом случае.
Вот сейчас у нас есть проект с ребятами много, там 6 или 7 человек в этом проекте,
где по одной из групп переменах у нас нет выпуклости, а по второй есть вовны.
То есть это уже более правдоподобная постановка.
И здесь уже как бы мы приближаемся к ганам, но там и теория скромнее.
То есть чем мы ближе хотим быть к практике, к теории, тем у нас как-то всё печальней с теорией.
То есть практика как бы часто нас ограничивает возможностями что-то теоретического.
А подскажите, как вы считаете, вот тема, если про комбинаторную оптимизацию писать,
допустим, применение графовым нейронным сетям, то есть это было бы интересно или нет?
Честно скажу, что я на самом деле не очень хорошо разбираюсь в комбинаторную оптимизацию.
Я сейчас поясню почему.
Ну, я естественно знаю какие-то базовые вещи связанные с релаксациями, с емидейпимитными,
но в целом для меня эта наука на этом ограничивается.
Потому что в общем-то дальше там уже отчасти как бы отрицательные результаты переборные
завязаны на компьютерсайнс.
Естественно, я тоже знаю там всякие вопросы там неопроксимируемости и так далее, свадимости,
но как бы это скорее отрицательные для меня результаты.
Ну, в том смысле, что в принципе можно там задачу помнить там о рюкзаке.
Ну да, там можно, она тоже может пониматься как задача комбинаторной оптимизации,
но уже там как бы есть всякие вещи, когда там Антеп трудность, там еще что-то.
Ну да, там можно приближенно найти решения там с хорошей вероятностью,
если там выполняются некоторые условия.
Но все это уже немножко другая кухня, то есть это компьютерсайнс.
Это компьютерсайнс, а чистая оптимизация там возникает только вот во всяких полуопределенных релаксациях.
Нет, я просто спрашиваю в том плане, насколько человек ограничен в плане выбора тем,
то есть как у вас сделано.
То есть вы в принципе даете какой-то список ваших работ,
и говорите, допустим, по вот этому можно писать.
Или в принципе все равно есть какая-то более-менее свобода в выборе?
Ну, с учетом того, что у нас довольно много людей,
тот же Ролан Хильдебран, допустим,
то он бы вполне мог сейчас взять на комбинаторную оптимизацию,
с учетом того, что в проекте ВТБ студент второго куса за это 200 тысяч
получает в месяц такую зарплату.
Студент второго класса Пестиоха.
Я не буду деньгами разглашать, это неважно,
но суть в том, что в общем это вполне бывают денежные проекты.
Дело в том, что он просто пашет там как не как студент второго курса,
а как просто главный программист.
И там программист, который понимает математику,
он занимается более-менее целочисленной комбинаторной оптимизацией.
Так бывает далеко не всегда.
Обычно в проектах Huawei зарплаты поменьше, там, не знаю, тысяч по 70.
Ну, по-разному.
Кто-то, кто хорошо пашет по 130 получает, если проект позволяет.
Вопрос скорее в том, как бы вы идете на какую-то конкретную задачу,
с которой вы готовы, чтобы не вы сами придумали,
а, например, заказчик Huawei, а мы вам как-то помогаем решать,
и вы за это зарплату получаете.
Или вы сами выдумали задачу, говорите, я хочу ей заниматься.
Естественно, можно ей заниматься специалистом, который с этим связан,
но как бы финансирование под это не факт, что он сможет найти.
Ну, может и сможет, я не могу опряженно сказать.
И это надо как раз согласовывать.
То есть за что там где-то есть какое-то финансирование.
То же самое с грантами.
То есть в грантах прописаны какие-то направления.
Грант, который есть у ученых, с кем вы можете связаться.
Ну, это не только я, у нас группа Хильде Бранд, Вериченский.
Вот молодежь есть, у них тоже свои гранты уже появляются.
То есть в том числе у аспирантов есть какие-то свои первые активности.
Мы, естественно, всех стимулируем.
У нас, мне кажется, хорошо налаженная система такая, бюрократическая.
В том смысле, что мы помогаем всякие бюрократические вещи преодолевать.
У нас есть люди специально этим занимающиеся, которые консультируют,
куда лучше направлять заявки свои на гранты для молодых, какие-то стипендии.
Вот Андрей Михайлович очень здорово помогает ребятам,
молочу курсов, стипендию свою организует.
То есть в принципе это направление довольно сильно поддерживается.
И есть очень такая среда конкурентная.
Но в ней уже внутри надо действительно быть достаточно разборчивым,
чтобы понимать, что вы в большей степени не хотите зарплату получать,
делать что-то дешее, а может это будет совпадать.
Но конкретно по комбинатурной оптимизации сейчас только один проект ВТБ.
Он, наверное, самый большой, 30 миллионов в год.
Там большая группа.
Вот такой вот проект.
И там курирует это как раз Хиллибран с точки зрения науки.
А подскажите вообще процедуру, если я хочу писать по оптимизации
и по работе я связан с Data Science, то есть какие мои действия?
То есть я к вам пишу, предлагаю список тем, или вы мне сами даете список тем?
Ну по-разному бывает.
Я не знаю.
Часто студент просто говорит, что он хочет работать конкретно со мной,
с нашей группой или посоветовать.
Это один сценарий.
Естественно, в зависимости от того, что мы немножко пообщаемся,
вы говорите, к чему вы склонны.
Если, например, хотите комбинатурной оптимизации заниматься,
я, естественно, не буду сам вас брать, потому что не квалифицирован достаточно,
чтобы курировать, на мой взгляд.
Я просто посоветую Роланда.
С Роландом поговорю, пообщаетесь, понравитесь ему, он вас возьмет,
что-нибудь предложит, в том числе.
Вы больше на каких методах специализируетесь?
Да практически на всех, кроме как раз комбинатурных.
Дело в том, что комбинатурная оптимизация действительно хорошая наука,
но она немножко своя.
Она своя, там другая немножко математика.
И этим надо, если заниматься, то серьезно.
Я достаточно поверхностный этим.
Я знаком на каком-то уровне, чтобы, если что, можно было как-то использовать,
что-то там сослаться, но я думаю, что за год работы в этой области
вы уже будете больше меня знать.
А подскажите, я правильно понимаю, что, в принципе,
если магистратуру пишешь, получается, и дальше у вас, в принципе,
на базе вашей группы можно писать и докторскую, например, работать?
Сейчас, как раз, у меня вот недавно Дворический в прошлом году защитился,
а Эдуард Горбунов сейчас к кандидатству,
а через год он планирует докторскую, у него, скорее всего, наберется.
Он без носиков тоже на это идет, Саша.
То есть, вполне он на это.
То есть, я это очень приветствую.
Всяческие поддерживаемости.
Причем не просто защита, а очень быстрая.
Но, к слову сказать, я вспомнил, у нас же замечательный есть специалист,
во всяком случае, не знаю, я с ним так хорошо не знаком,
вот так, Борис Истакович Гальденгорин.
Он как раз занимается комбинатурной оптимизацией.
Он тоже в этом проекте ВТБ, поэтому, кроме Ефельда Бранда,
там есть еще Гальденгорин и Даньяк, Саша.
И мне кажется, что в этом смысле есть еще вот такие ребята,
которые, ну, в общем, я, правда, не знаю, насколько они доступны.
Ну, вот, Константин Юрьевич как-то сможет прокомментировать,
но мне кажется, что они вполне доступны с точки зрения научного руководства.
Я их видел как научных руководителей студентов школы УМИ.
Я ни в коем случае не отговариваю вас ко мне идти.
Я просто говорю, что у нас действительно в школе очень много интересных,
потенциальных научных руководителей.
И мне кажется, что, в общем, ну, как бы вы не выбрали,
скорее всего, все равно будет хорошо.
И получается, в принципе, это как бы можно и с работой совмещать.
То есть, не нужно это делать, допустим, в полтайме.
По-разному и по-разному. К сожалению, так вот, знаете, ну, ну,
сложно загадывать, потому что, ну, вот, что такое проект Huawei?
Ну, вот, выходит заказчик и говорит, давайте вот, делайте вот это.
Потом выходит другой заказчик, Huawei, много.
И вы говорите, что, во, мне это интересно, мне это близко, я готов участвовать.
А бывает так, что вот приходит Huawei, то что-то говорит,
он говорит, нет, мне это не интересно.
Потом другой Huawei тоже говорит, нет, мне это не интересно.
И у меня действительно как бы довольно много вокруг
есть возможности куда-то там в один с половиной Huawei вписать.
Поэтому я не думал, что их количество уменьшится.
Но обещать заранее, что вот вы найдете по душе что-то,
ну, я так априорно не могу.
Да, действительно, на нас выходят люди из Huawei, связанные,
с тем, что нас озадачивает оптимизационными постановками.
Поэтому, конечно, от оптимизации мы далеко уходить не будем,
но какая это будет оптимизация, по душе она вам будет или нет,
ну, мы не можем им сильно навязывать.
Мы можем корректировать их планы, иногда даже постановки задачи, такое тоже есть.
Но переродикулярно их разворачивать довольно сложно.
Вот поэтому тут все-таки есть какие-то, так сказать, ограничения,
ограничения, то есть совмещать хорошую заработку от индустрии с наукой, возможно, в случае
подстраивания под эту индустрию частично. Но есть, на самом деле, ребята, которые в основном
получают зарплату, тоже без носиков, ни за какой, ни за Huawei, а чисто за наук. Он пишет статьи на
НИПС, и там пристроен в разные места, в разные гранты, и Горбунов, и с отсчет всяких надвалок,
они там очень даже неплохо, ну, я не имею возможности как бы сейчас рассказывать сколько, но поверьте,
совсем даже неплохо для студентов-асперантов. Вот, ну, то есть какая-то уже личная информация. Но,
в общем, вполне, если вопрос материальный, то, думаю, что чисто быть хорошим ученым вполне
достаточно, чтобы не думать о том, где работать. В всяком случае, когда я был студентом, меня и
близко ничего не было по порядку такого, что сейчас, ну, точнее, вот в порядок ровно и отвечалась зарплата
нынешних студентов старших классов-асперантов, ну, топовых, от моей того времени. Вот, поэтому,
ну, вы в этом же возрасте. Ну, правда, это было там 20 лет назад. И еще такой вопрос, подскажите,
по поводу, допустим, работы, насколько будет важно, то есть, чтобы она была, допустим,
больше в математику, да, или же больше, допустим, в инфраструктуру, да, то есть, допустим, вот то,
что вы рассказывали про распределенные вычисления. То есть, или и то, и то, в принципе, можно.
Как правило, вот и то, и то. И более того, в зависимости от специфики, если вы больше
средоточены в статьях, там и то, и то, но больше науки теорем, там и так далее. Если вы больше в
индустрии, то там и то, и то, но больше деталей, которые, так сказать, читов каких-то практических,
которые там то сделать, то пошевелить. Это тоже интересный опыт. Но если вы им так сыты, то в
этом смысле он вас вряд ли будет как-то вдохновлять. Ну, может, просто такая обыденность в каком-то смысле,
что иногда это что-то рождает. То есть, иногда какие-то открытия тоже совершаются чисто,
вот как физика-экспериментатор. То есть, что-то опа классно заработала, ты думаешь, почему классно
заработала, а потом понимаешь, что вообще, на самом деле, это некоторый вот эффект, который можно
математически объяснить, и по сути рождается статья. И не то, что это редкость. То есть, такое бывает.
Спасибо. Да не за что. Ну, повторю, что вот у нас довольно большая команда. Я вам показывал слаг,
и я бы не хотел прям на себе все замыкать. То есть, мне кажется, что у нас достаточно сейчас потенциала
вот у группы в целом, чтобы как-то просто представлять группу. То есть, что вот вы
можете заниматься тем-то, тем-то, тем-то, и вы найдете себе квалифицированных коллабораторов.
И если не найдете здесь, то найдете уж точно среди тех людей, которых мы привлекаем из-за рубежа,
которые выступают нашими соавторами, нас консультируют. То есть, я думаю, что, в общем,
в этом смысле, что-то можно вам обещать, что мы вас как бы доведем до какого-то хорошего топа
уровня, попадания на топовые конференции. Ну, во всяком случае, такая претензия есть, типа ICML,
при условии, что вы сами должным образом будете работать. То есть, это же тоже некоторая,
довольно большая работа, характерное время выхода на это несколько лет. То есть, как раз,
если сейчас начать к аспирантуре, глядишь, начнут появляться такие вот результаты. Ну,
у кого-то быстрее, у кого-то за год получается. Да, хорошо, есть еще вопросы.
Так, да. Коллеги, ну, я, в общем, оставил в этом чате, насколько я понимаю, я все-таки смог это
сделать или не смог. В чате есть информация какая-то? Да. Да, ну, отлично. Ну, собственно,
все. В общем, я могу на другие вопросы ответить уже там, в личных сообщениях, если будут. Ну,
могу вас связывать. То есть, вы не обязательно можете писать мне только, если ко мне хотите идти.
Повторю, что это я могу выступать к неким бульферам или, как сказать, промежуточной станции,
сортировке, что ли, чтобы порекомендовать вас кому-то из коллег, в том числе тех коллег,
с кем мы вместе работаем. Ну, хорошо, хорошо. Тогда вы в общем контакте есть, если что, пишите.
Спасибо, Александр Владимирович. Да, спасибо. Ну, да, наверное, все. Я думаю,
все, кто заинтересовался, напишут, сгажутся с вами. Ну, Александр Владимирович, конечно,
пасхомничал, что-то. Там он не специалист, тут не специалист, но есть куча учеников,
куча защищенных уже кандидатских диссертаций под его руководством. Это большой специалист
по оптимизации, поэтому если кому-то заинтересует такая тема, то очень рекомендую Александру
Владимировичу обращаться. В любом случае, если сам вдруг он пасхомничает и скажет,
что он тут не специалист, он найдет того специалиста, кто сможет вас более консультировать. Вот так.
На этом все. Спасибо. Хороший доклад. Мне кажется, было всем интересно. Уважаемые студенты,
тогда к вам туда обращаю. Значит, у нас завтра следующая встреча запланирована. Вы следите
за расписанием, потому что доклады могут быть добавиться еще к нашей кану расписаний,
которую я вам прислал. Так что так вот вы периодически поглядывайте, что может завтра
что-то еще появится. Просто люди не все оперативно ответили, кто готов выступить. Так что будьте
будьте начку. На этом заканчиваем на сегодня нашу встречу. И до завтра. В общем, ждем вас завтра.
Записи будут потом очень доступны на сайте кафедры. Но я, собственно, тоже вам напишу всем,
что вот записи доступны. Все, всем спасибо. Александр Юрьевич, вопрос можно?
Касательно студентов индистрактуры. По окончании первого семестра, что ожидаете,
там на сколько процентов примерно нужно будет уже завершить? Давайте вы вначале начните работать.
Там, я думаю, мы больше... руководитель сочетет, как сказать, вашу работу и тот процент,
который вы выполнили. Кто-то скажет, знакомьтесь с пятью статьями. Так условно, да, говорю. Или,
может быть, кто-то скажет что-то посчитать. Индивидуальный подход. То есть кто, что планирует.
Некоторые говорят, вот он записался, пока разбирается, я ему авансом пока ставлю десятку.
Ну вот, не могу вам сказать, зависит от руководителя и чем вы раньше начнете какие-то движения в плане
своей научной работы, тем для вас лучше не в том плане, что вы сейчас там вам получить какую-то
оценку, я знаю, десятку или шестерку, а в плане того, что вам же будет проще дальше с дипломом,
с вашим исследованием, ну и со всеми вытекающими. То есть я не могу сказать процентов. То есть тут
все индивидуально. Кто как делает? Кто первый семестер дает чисто ознакомление? Вот вы вникаете
в задачу, в большую, и выбираете все под задачу. Кто-то уже ставит четко, говорит, да вот тут посчитай,
вот это сделай. Поэтому не могу ответить на вопрос, чтобы всех удовлетворить, что ли.
Ну все, наверное, да тогда. В общем, я думаю, в пятницу после окончания еще я отвечу на вопрос,
если у вас возникнут какие-то. Так что копите такие организационные вопросы к пятнице,
и после последнего доклада мы еще с вами поговорим. Хорошо? Ну, молчание – знак согласия.
Тогда всем спасибо, ждем вас завтра.
