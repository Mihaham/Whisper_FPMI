Всем доброго дня! Мы с вами продолжаем изучение компилятора, и сегодня у нас
случился некоторый форс-мажор, связанный с тем, что мы не могли долго подключить
проектор, точнее чтобы запись выводилась на проектор, поэтому сегодня лекция будет
короткой, но ничего страшного. План этой лекции был запланирован растянуться на две лекции,
поэтому будем считать, что здесь не лекция 0.2, а лекция 0.2-0.3. Еще один важный момент,
который у нас есть, там будут в некоторый момент выходные, вот подумаем, что с ними сделать. Там
причем из-за того, что год высокосный, как ни странно, там две лекции подряд выпадут в выходной
день на пятницу. Раньше, когда год не высокосный, получается обычно так, что все праздники,
которые есть, они ровно выбивают по одному дню в неделю. То есть, там один вылетает понедельник,
вторник, среда, четверть, пятница, суббот. Ну, сейчас не повезло, будет две пятницы.
Значит, давайте вспомним, где мы сейчас находимся. Мы в прошлый раз с вами обсудили то, каким образом
писать сканер, и сегодня мы с вами обсудим достаточно важную тему, но раскроем ее немного
с другой стороны по сравнению с курсом формальных языков. Наверное, вы помните, что на формальных
ППК был такой замечательный алгоритм под названием LL-алгоритм. Вот, но мы с вами посмотрим еще сегодня
другой тип алгоритма, который называется LL-алгоритм. То есть, он сейчас намного проще, во-первых,
в реализации, а во-вторых, почему мы его рассматриваем, потому что в библиотеке Ant-LR,
которую мы начали с вами рассматривать, в ней используется следующий алгоритм. Это алгоритм
LL со звездой. Как расшифровывается этот алгоритм? На самом деле, если говорить исторически,
то сначала появился LL-алгоритм, то есть появилось семейство алгоритмов вида LLK. После этого появился
язык parser LL со звездой, который учитывает контекст. И на самом деле, когда мы будем смотреть Ant-LR,
мы увидим, где этот контекст учитывается. То есть, в Ant-LR можно вносить семантический
смысл в правила грамматики. Вот, это важно. Вот, этим как раз занимается звездочка. А LL — это adaptive LL
со звездой. И вот сейчас, в последней версии как раз Ant-LR, который Ant-LR 4.13, используется алгоритм
parsing LL со звездой. И как пишут разработчики Ant-LR, он очень имеет похожий функционал на тоже
популярную вещь под названием PEC. Значит, PEC — это parsing expression grammar. Вот, он сейчас используется
в выпитоне, начиная с версии 3.10. И в версии 3.12 там уже есть веселые приколы, когда можно в
f-литералах скобочки внутри скобочек, кавычки писать внутри кавычек. Вот, это будет считаться
правильным выражением. Вот, то есть, это мы тоже можем посмотреть. Давайте все-таки поговорим про
теорию. Значит, цель лекции сегодня — это понять математическую сущность парсеров. Вообще определить,
что такое парсер. Дальше научиться представлять код в виде синтоксических структур, которые мы
дальше будем разбирать. После этого узнать алгоритм разбора кода на синтоксические структуры.
В деталях понять, чем отличаются восходящие парсеры и нисходящие парсеры. И на самом деле разобрать
реализацию не то чтобы восходящего подхода. Восходящий подход все, наверное, так или иначе
помнят, поскольку это было несколько месяцев назад. Ну, для кого-то там те, кто раньше сдавал,
те еще раньше помнят. Вот. Мы все-таки посмотрим сегодня нисходящий подход, который идет сверху вниз.
То есть, рассмотрим, как пишется алгоритм. Давайте вспомним, где мы сейчас находимся. У нас имеется
некоторый набор токенов. То есть, вспомните, мы с вами в прошлый раз в теме сканеров взяли произвольный
текст и разбили его на набор токенов. Кто может напомнить, что такое токен?
Да, это лексема со смыслом. То есть, у нас у токена обычно есть тип и внутри токена у нас может
скрываться определенное значение, которое называется лексемой. Вот. Значит, нам необходимо
теперь задать правила, которые разберут эти токены. Для того, чтобы мы построили дерево вывода,
так сказать. И есть классический пример с русским языком. Я не помню, приводил я его на лекциях по
формальным языкам или я его привожу на семинарах чисто. Представим себе, что у нас есть простое
предложение. В нем есть подлежащее и сказуемое. И к существительному может быть привязана именная
группа, дополнительное определение. А к глагольной группе мы можем привязать либо дополнение,
либо обстоятельства. Например, красное яблоко долго висело на дерево. Что мы здесь видим? Мы с
вами здесь видим, что у нас есть именная группа. Она состоит из определения сабджекта. Да, извините,
я должен был написать эджектеф или аналог английского слова. Плохо. Применяю транслитерацию.
Как называется? Транслитерацию, да? Да, транслитерацию применяю. Вот. И вторая часть это обстоятельства
определения дополнения. Ой, обстоятельства глагола дополнения. Понятно, что мы могли бы сказать,
что у нас есть предложение именная группа и глагольная группа. Вот. А глагольную группу разбить
дальше на вот эту вот составную часть обстоятельства определения. А почему его
определением называют глагол дополнения? Вот. Таким образом, одним из способов
простояния простого предложения является такое, что у нас простое предложение состоит из
определения существительного, точнее подлежащего обстоятельства глагола и сказуемого. Ой, как
называется? Это не глагол называется. Сказуемо. Все. Наполнение. Вот. То есть вот такой пример. И,
соответственно, да, тут немножко верстка поехала. Мы можем сказать, что на самом деле
члена предложения, в примере выше, это не терминальные символы в нашем контексте. Как вы думаете,
что будет в данном случае терминальными символами? Нет слова на самом деле, потому что от слов мы с
вами уже избавились. Там у нас были определения дополнения обстоятельства. А чем обычно выражаются
определения дополнения обстоятельства? Либо прилагательными, либо существительными, либо
предлогами. То есть у нас получается, смотрите, что у нас простое предложение. Это набор не терминальных
символов раскрывается. А дальше каждый из терминальных символов, допустим, мы видим, что здесь
у нас дополнение. Это, допустим, предлог и существительное. Конечно, лучше сказать,
что это обстоятельство, потому что обстоятельство обычно отвечает на вопрос «где». Допустим,
можно считать, что и дополнение таким образом можно выражать. Вот. И здесь, в данном случае,
simple sentence является стартовым символом. Он является не терминальным. То есть то,
от чего мы с вами будем порождать нашу грамматику. Вот. Поэтому мы можем с вами ввести
определение контекста свободной грамматики. И здесь только такие грамматики будут рассматриваться.
Первое – это множество не терминальных символов. Второе – это множество символов алфавита,
терминальных символов. Далее у нас есть множество прав от грамматики и есть стартовый не
терминальный символ. Все помнят это определение. Все, отлично. Тогда давайте рассмотрим пример
простой грамматики. Что он у нас с вами задает? Как это понять? Да, это работа с выражения не
числовыми. Причем, как мы видим с вами интересную вещь, что не все числовые выражения здесь
поддерживаются. Или все? Не, скобки есть. А, префиксная запись. Да, то есть видите, в принципе,
у нас есть с вами префиксная запись, которая это все раскрывает. Да, казалось, должны быть все. Вот.
И давайте рассмотрим как раз разбор этого выражения. Значит, я здесь сразу скажу, что a плюс b
умножить на c разбирается приблизительно вот таким образом. Важно, что в терминалах у нас
в данном случае будут находиться токены. То есть, видите, у нас есть токен плюс, собственно,
который скрывает, собственно, Алексеем плюс. И мы видим с вами здесь, что у нас имя a есть и имя b. То
есть, на самом деле, токен это не терминальный символ. Name.a, name.b. Вот. Поэтому, когда мы будем
говорить про грамматики, мы будем говорить, в первую свою очередь, про токены. И, значит, вот эта
вот последовательность действий, которая нам показывает все это в визуальном виде, а называется
деревом вывода. Да. Но, правильно, если мы говорим формально про дерево вывода, это последовательность того,
каким образом мы каждый не терминал раскрываем в левую часть правила, раскрываем в виде правой
части правила. Если мы говорим формально, то правосторонний дерево вывода — это такое дерево вывода,
в котором на каждом шаге раскрывается самый правый не терминал. Левосторонний дерево вывода — это дерево
вывода, в котором на каждом шаге раскрывается самый левый не терминал. Вот. Вопрос. Какое дерево вывода
было нарисовано на прошлом слайде? Вообще не угадывается. Потому что нам нужно порядок действий
проставить для того, чтобы понять, какое это дерево — правосторонний или левосторонний. Да, просто
дерево вывода — это картинка. Если мы официально отображаем, нам нужен порядок действий. Хорошо.
Давайте поймем следующее, что грамматика называется неоднозначной, если она имеет для какого-то
слова более одного левостороннего или правостороннего вывода. Замечание. Значит, в курсе формальных
языков у нас не было требования на вид дерева разбора. Да, то есть влевосторонний или правосторонний
дерево вывода. Важно следующее, что когда мы будем с вами работать в данном курсе, нам вид дерева
разбора не будет важным, потому что именно парсером будет задаваться вид разбора. Если мы говорим
про восходящие парсеры, которые будут разбирать слово снизу вверх, то вопрос на знание, какое у
нас дерево вывода будет, если мы идем снизу вверх, то будет правостороннее дерево вывода. Потому что
мы как раз берем наш набор нетерминалов и поднимаем его кверху. Значит, если у нас с вами дерево
вывода, если мы двигаемся слева сверху вниз, как вы думаете, какое дерево вывода будет у нас?
Левостороннее. Потому что мы будем с вами рассматривать первый нетерминал. Хорошо. Вот. И классический
пример, наверное, если вы с ним не сталкивались, то, пожалуйста, надо познакомиться с ним, что на
практике могут встречаться неоднозначные грамматики. Собственно, что у нас здесь? У нас есть здесь
раскрытие условных выражений, часть правила для раскрытия условных выражений. То есть мы говорим,
что у нас есть statement. Если у нас есть expression, то тогда мы выполняем statement, иначе выполняем
еще один statement. Или мы говорим, что у нас есть условие if, в котором есть if expression, then
statement. Либо какой-то другой оператор. Здесь, допустим, это оператор присваивания. И давайте
посмотрим на вот это, например, вот такого предложения. If expression 1, then if expression 2,
then assign 1, else assign 2. Давайте поймем, каким образом мы с вами его можем разобрать.
Да, как к первому и фу, так и ко второму и фу. Соответственно, каким образом это можно решать?
Это можно решать следующим образом. Либо мы добавляем фигурные скобки везде, то есть
меняем нашу грамматику. Либо мы пытаемся перевернуть этот вывод. Вот здесь будут два
дерева вывода. То есть что мы здесь видим? Здесь у нас if, then, кто раскрывается вот это выражение,
выполняется if export 2, if then else. То есть if then else здесь относится к первому выражению,
здесь if then else относится ко второму выражению. А в других языках программирования, каких же?
В Питоне даже есть правило, что есть специальный не терминал под названием elif. То есть он явно
нам покажет, какому не терминалу, какому правилу это все соотносится. Но и здесь на самом деле это
можно решить. Для этого нам нужно левый вывод распространить правый вывод. То есть что мы
говорим? Мы говорим, что сначала мы пытаемся раскрыть выражения, в которых нет else, а потом
раскрываем выражения, в которых будет else. То есть что мы говорим? То есть мы говорим if
expression, then statement. Потом мы говорим, либо if expression, then with else. То есть мы ожидаем,
что следующие выражения, которые внутри будут, они будут с else. Иначе сделаем statement. То есть
получается мы фиксируем с вами для выражения с else определенный прямо вид expression, определенный
не терминал. То есть иногда полезно будет в нашем правиле грамматики четко задавать вид не терминала
под то, что оно задает. На самом деле, если мы говорим про формальные языки, то в семинарах
по формальным языкам мы, конечно, строили не такие вещи, но мы все равно делали специальные
не терминалы, которые отвечали за определенные требования. Допустим, не терминал, в котором
количество буква равняется удвоенному количеству букв Б, или не терминал, в которых количество
буква там было на единичку на два больше, чем количество букв Б. Все помнят эти примеры.
Здесь мы будем их задавать для своих собственных целей. Хорошо, то есть это таким образом можно
разрешать неоднозначность. Здесь нам нужно наконец-таки вести такое понятие, как грамматический
парсер. Что такое парсер? Это алгоритм, который по входному предложению будет определять,
принадлежит ли предложение грамматике. Сразу я буду говорить, что я буду говорить не принадлежит
слово грамматики, а принадлежит предложение, то есть наша программа. И парсеру в процессе
разбора предложений ему необходимо будет, смотрите, что сделать. Ему необходимо будет построить дерево
разбора по способу построения дерева разбора. Они делятся как на нисходящие парсеры, топ-даун сверху-вниз,
или в восходящие, bottom-up парсеры. И мы с вами, наверное, сегодня успеем только рассмотреть
нисходящие парсеры, а восходящие будем исследовать на следующей лекции, сделаем часть нашего алгоритма.
Да, если холодно кому-то, можно это окошечко прикрыть. Вот, собственно, вот такая вещь. Но
давайте поймем с точки зрения задачи компиляции, достаточно ли нам будет ответить на вопрос да или
нет. Принадлежит ли наше предложение грамматики или не принадлежит? Ну все равно, если мы смотрим на
разные литеры, он пытается что-то сделать, любой компилятор, он пытается не только сказать,
скомпилируется ваша программа или нет, но представьте себе интерфейс, пишете там г, плюс, плюс что-то
там, где говорят, ой, у вас ошибка компиляции, а где, ну неважно, разбирайтесь сами. То есть никакого
визуального интерфейса, никаких валидаторов нету, вот давайте. Да, и корд дамп, причем непонятно,
что в этом ядре находится. Вот, и поэтому, во-первых, ладно, можно сделать так, но даже представьте,
мы найдем место, в котором есть ошибка компиляции. Одна. Ну что за ошибка, говорим, что за ошибка
компиляции. Все, да, во-первых, надо определить тип этой ошибки, а еще что-то необходимо, если,
допустим, ну совсем у нас с кодом беда. Да, наша цель за одну стадию компиляции найти, как можно
больше ошибок. Вот, и, соответственно, нам в парсере необходимо будет заложить опцию,
по каким образом исправлять ошибки компиляции, и это можно сделать прямо на этапе написания
парсера. Это важно, то есть, и вы не поверите, и в LL-алгоритме, который мы будем рассматривать,
и в LL-алгоритме есть подход, но правда, они разные. Вот. Весело будет.
Так, и, на самом деле, первый тупой алгоритм, который нужно рассмотреть, это алгоритм
экспоненциальный. Собственно, в чем, а? Да, это рекурсивный спуск. То есть, в чем суть? Мы пытаемся
спуститься сверху вниз и пытаемся перебрать все правила грамматики, которые могут присоединиться
к данному инди-терминалу. Ну, собственно, мы пытаемся присоединить правила. Если у нас правило
определенное не присоединяется, мы его отдираем шпателем, возвращаемся в предыдущее состояние.
То есть, здесь есть псевдокод. То есть, мы говорим, смотрим, какое у нас следующее слово, дальше делаем
wall-true. Фокус — это как раз текущая вершина, по которой мы хотим подвесить правила. Собственно,
перебираем следующее правило, подвешиваем наше правило к дереву. При этом мы храним стэк текущих
символов, которые у нас есть вот так сказать. Как это назвать? Кронодерево, текущая кронодерево.
То есть, у нас есть а. Вот, мы храним на стэке в порядке справа налево. Точнее, слева направо,
чтобы вынимать справа налево. Первый не терминал, который нам нужен. Дальше говорим, что если это у
нас внезапно не терминал, точнее, если терминальный символ, то мы, собственно, его обрабатываем,
кладем, двигаем указатель. Иначе, если при этом у нас больше символов нету, мы дошли до конца
слова и все принимается, то мы выдаем accept. Иначе, смотрите, здесь есть функция backtrack.
Собственно, что она должна сделать? Она должна отмотаться до того состояния, пока мы с вами не
будем готовы принимать этот символ. Подкольку у нас здесь есть функция backtrack, то время работы алгоритма
будет... Каким? Экспонициальным.
Да, нужно... Собственно... А?
Не-не-не-не. Ну, важно в следующее, чтобы у нас циклической зависимости тоже не было. Да, если у
нас нет циклической зависимости, то сложность будет экспоненциальной. Если у нас есть циклическая
зависимость, то, увы, сложность нашего алгоритма – бесконечность. То есть мы его разобрать не
можем. Значит, смотрите, а в каком случае это может возникать? Да, ну нет, бесконечный кейс.
Но смотрите, это означает следующее, когда у нас это может бесконечно быть, когда у нас из какого-то
ни терминала А может за какое-то количество шагов вывестись А альфа. То есть у нас тот же самый
ни терминал в левой части, а альф – это то, что находится в правой части. Ну, здесь за какое-то
количество шагов. Обычно штопором обозначается вывод за определенное количество шагов. Это я
рассказываю тем, кто не смотрел курс по формальным языкам. Я думаю, такие будут. Вот. И вот этот вот
контекст называется левой рекурсией, суть. То есть у нас есть ни терминал, в котором выводится тот
же самый левый ни терминал. Бывают два типа рекурсий. Бывает прямая рекурсия, явная рекурсия и бывает
неявной рекурсия. То есть когда у нас, допустим, из А выводится Б, из Б выводится С, из С выводится А. Вот.
Значит, смотрите следующая вещь. Вам с точки зрения написаний именно парсеров придется руками
избавляться от неявной левой рекурсии. То есть когда из А выводится Б, из Б выводится С, а тут есть
тряпка. Ну что, мне хочется все-таки писать на доске. Тряпка сухая.
Да, да, да. Нет, за один шаг причем. Это явное, да. То есть это когда у нас есть правило А, выводит А,
бета. Не явно. Это когда у нас из А выводится, допустим, Б альфа, а Б альфа дальше раскрывается в А,
а Б альфа. Собственно, у нас из А получается А за два шага. Вот такую рекурсию нам придется избавляться.
Руками причем. От этой рекурсии, сразу скажу, парсеры умеют избавляться автоматически, потому что там
правила для перестройки грамматики не очень сложные. Как раз мы сейчас это рассмотрим. Вопрос. Как
такой флешбек курсу формальных языков? В каком месте мы избавлялись с вами от левой рекурсии в курсе?
Не NFH, другая. Да, нормально в форме грейбах. Если мы рассмотрим нормальную форму грейбах не в том
термине, в котором мы смотрели, а просто чтобы выводится первый символ, который выводится, это
терминал, то там алгоритм, который не математический, который мы строили, он будет заключаться в том,
что нужно убирать левую рекурсию руками. Поэтому это важно. Смотрите, здесь есть пример грамматики
для разбора арифметики. Здесь есть операции плюс и умножить, а при этом здесь видно, что операции
плюс и умножить стоят в правильном порядке, то есть приоритет операции здесь зад. Сначала мы
пытаемся выполнить плюс вверху вниз. Соответственно, снизу вверх, когда мы будем раскрывать правила, то
правила умножить и поделить, они будут в первую очередь по сравнению с правилом плюс и минус.
Аскопки самые низкие, в самом низу, поэтому они имеют максимальный. Хороший вопрос. Давайте
расскажу. Обычно палочками, когда мы обозначали на семинаpekopat instability по формальным
языкам, это означает правила или или или. То есть у нас есть правила из экспрSl
в смысле, что это нормальная форма грамматика, это нормальная
форма записи этих грамматик, и это называется формальная
форма Б-кусонаура.
Да, то есть мы пишем обычно следующее, что у нас не
терминал А, допустим, у нас было правило какое-то
А выводится Альфа-Бета, А выводится Бета-Гамма и так
далее.
Мы их пишем так, А выводится Альфа-Бета, а дальше пишем
ИЛИ, чтобы показать, что это у нас идет перенос на
следующую строку.
Альфа-Гамма, Бета-Гамма, допустим, А вводит Эпсилон,
и в конце, чтобы закрыть это правило, обычно ставят
точку запятой.
То есть, вот это именно код, который можно написать
на практике.
Вот, дополнительно, какие здесь фишки бывают, здесь
обычно вставляют фигурные скобки и пишут, какой код
нужно вставить при случае совпадения этого правила.
То есть, если вы раскрываете это правило, то какой код
надо применять.
Ну, подробнее, наверное, мы это еще посмотрим.
Так, понятно, что эта запись обозначает.
Вот, поэтому приятнее писать это таким именно образом.
Ну, собственно, каким образом удалять можно левостроение
рекурсию?
Значит, мы уже ввели определение, и здесь мы видим неявную
левую рекурсию.
Из f выводится a, из a выводится s.
Хорошо.
А каким образом удаляется прямая левостроенная рекурсия?
Значит, представьте себе, что у вас есть в последовательности
цепочек вывода, и у вас есть нетерминал f, который
выводит f альфа, и из f выводится f бета.
Тогда что мы можем сделать?
Мы с вами можем посмотреть цепочку выводов, которые
из f выводят что-то, и потом из этого нетерминала мы
с вами выводим какой-то другой, то есть терминал.
Это, опять же, напоминает нам удаление epsilon правил
в грамматике.
Собственно, тогда смотрите внимательно на картинку,
что мы с вами можем сделать.
Тут, по-моему, кстати, количество нетерминалов, я ошибся,
или...
Нет, по-моему, не ошибся.
Мы берем и подвешиваем вот этот последний терминал,
который раскрылся у нас в другой символ, мы его
берем и подвешиваем за корень дерева.
Мы его подвешиваем за корень дерева, и получается у нас,
так сказать, вот эти все f-ки, которые были, уходят в правую
часть.
То есть у нас теперь из нетерминала f выводит другой
терминальный символ бета, это первый символ, и дальше
у нас вводится специальный новый нетерминал f-штрих,
который будет указывать, что мы раскрываем не стартовую
часть, а уже дополнительную часть нашего правила.
Сделаем из левой рекурсии правую рекурсию.
В итоге у нас уберется правило из f выводится f альфа, но
при этом у нас добавится новое правило из f выводится
b f-штрих, из f-штрих выводится альфа f-штрих, и из f-штрих
выводится епсел.
Доказывать я это не буду, потому что у нас практически
курс, можно подумать на досоке, почему это работает.
Понятно суть?
Нет, я тут решил прочитать про алгоритм ml звездочка,
первый раз я не осилил, потому что там каждый раздел это
введение нового определения, причем какого-то крайне
нетривиально.
Я боюсь, что произойдет, когда я буду читать алгоритм
ml со звездой, там еще один трактат на 10 страниц.
Ну сколько тысяч звезд у нас в антеллере?
Смотрите, каким образом грамматика превращается
после избавления левосторонней рекурсии, то есть у нас
появляется правило терм экспорт со звездой, экспорт
со звездой плюс терм экспорт со звездой и так далее,
и тут видно, что по каждому раскрытию правой части
мы можем однозначно восстановить, какая левая часть была
раскрыта.
То есть на самом деле антеллер тот же самый, он будет это
делать под капотом, не будет спрашивать нас.
Непрямую левостороннюю рекурсию он раскрыть ему
будет крайне сложно.
Так, вот такой пример, собственно, а каким образом убирать
непрямую левостороннюю рекурсию, давайте мы упорядочим
терминалы, а не терминалы по возрастанию и будем
искать следующую вещь.
Мы будем с вами сделать следующее, что если у нас
встречается правило с неправильным порядком, то есть у нас
из аитого выводится ажитое b, то мы будем делать следующее,
мы берем и подставляем правую часть правила ажитое все
возможные выводы ажитоа.
То есть в нашем случае, если мы с вами рассмотрим
наш пример, где у нас тут есть рекурсия, то есть у
нас было правило, так, а выводится b айфа, и что у нас
еще было, b выводится a бета, хочется избавиться от вот
этого правила, потому что b идет после а, что мы делаем,
мы делаем очень простую вещь, какую, мы берем и
подставляем все, что здесь было с а, мы вот это правило
стираем и добавляем правило из b выводится b альфа бета,
то есть для всех таких правил добавляем новое правило.
То есть у нас остается прямая левосторонняя рекурсия,
но при этом не остается непрямой левосторонней
рекурсии.
При этом можно заметить, что после каждого шага
у нас для аитоа, если мы индуктивно идем по аи, остаются только
прямые рекурсии.
Вот, хорошо.
Так, понятно суть?
Хорошо, так, хорошо.
Что-то я начал слишком много раз заговорить «хорошо».
Идеальным случаем, когда мы говорим, что у нас все
отлично, у нас нету состояния вида бэктрек, то есть нам
никогда не приходится отматываться назад, и вот наша цель
будет состоять в том, чтобы в предиктивных парсерах
максимально избавиться от бэктреков.
То есть надо предсказывать, в какой ветке пойдем, то
есть она подбросит курт нечего.
То есть надо прощать правильных ларон и не помнить, как
они это пропустят?
Ну, на самом деле, первый кейс, который достаточно
простой, это использовать те знания, которые были
у нас на курсе формальных языков, а именно постараться
предсказать, какая будет следующая буква.
То есть посмотреть правила грамматики на следующую
букву и понять, может быть, мы сможем каким-то образом
выявить правила в нашей грамматике.
Это называется LL как раз алгоритм, который это
будет делать, он называется LLK, то есть K это количество
символов, которые мы смотрим наперед.
Значит, сразу скажу, тут возникнет вопрос, что
такое LL со звездой.
Значит, как я предварительно понял, я еще буду это уточнять,
это алгоритм, в котором вместо просмотра на K букв
вперед мы пытаемся просмотреть контекст, который строится
в виде детерминированного конечного автомата.
То есть как бы мы пытаемся предсказать, по какой ветке
детерминированного конечного автомата мы дальше пойдем.
И в зависимости от этого принять решение о выводе
определенного правила.
Причем там суть в том, что алгоритм, который сейчас
мы будем изначально рассматривать, он линейный, а алгоритм
LL со звездой будет квадратичный.
Но при этом суть в том, что квадратичность будет зависеть
от того, сколько мы в этом контексте пробудем времени.
Обычно там получается, сложность будет не квадратичной,
а порядка в среднем 2-3n.
Потому что в контексте мы больше, чем на два символа
залезать не будем.
Это именно практические вычисления, то есть обычно
когда пишут такие компиляторы, парсеры, люди просто начинают
гонять их на разных языках.
Тем более, давайте практический вопрос.
Каким образом проверить сложность своего алгоритма
на практике?
А где кучу разных объектов взять?
Ну, если, по-моему, издание есть.
Ну, да.
Ну, на самом деле, делать все очень просто.
Открываем гитхаб и начинаем парсить примеры кодов
с разными языками.
То есть у нас есть определенная грамматика для определенного
языка программирования, мы идем в интернет, тыкаем
в какую-нибудь кнопочку trending или делаем поиск по репозиториям
и выкачиваем эти репозитории.
Вот, датал сет готов, остается запустить.
Вот, собственно, для того, чтобы просмотреть букву,
нам нужно ввести множество ферст.
Значит, ферст от терминала не терминала, напоминая,
это первый символ, который может быть выведен из раскрытия
нашего правила.
То есть, какой первый символ может быть цепочки выводов.
Вот, и, значит, здесь возникает еще одно понятие, оно называется
follow.
Что такое follow?
Follow определяется для не терминалов и это первый символ, который
может быть выведен с дерева разбора после определенного
не терминала.
То есть, давайте еще картинку нарисую.
Собственно, давайте я покажу, что такое ферст.
То есть, что у нас есть?
У нас не терминал А, собственно, если у нас первый символ,
который выводится, и это А, то это ферст от А.
Но при этом еще у нас А принадлежит ферст.
Вот самая буква А.
А вот follow определяется числением терминала.
Что такое follow?
Это у нас есть А, дальше мы выводим какое-то дерево,
нам не важно, и дальше смотрим на правую часть дерева вывода,
и здесь первый символ А, который мы выводим.
Тогда мы говорим, что...
А будет принадлежать follow от А.
Это первый символ, который может быть выведен из правила.
Соответственно, нам нужно учиться считать first и follow,
но здесь, на самом деле,
надо аккуратно пройтись BFS или DFS по не терминалу.
Для того, чтобы посчитать это first.
Ну и follow считается похожим образом.
То есть, это делается заранее перед шагом алгоритма.
Значит, дальше мы вводим следующую вещь.
Собственно, это множество first plus.
Это первый терминал, который может вывестись
начиная с нашей части правила.
И мы говорим, что first plus от правила A в стрелочка B
это либо first от B.
А если пустое слово не принадлежит first от B,
то это означает, что наш терминал раскрылся,
и дальше у него есть символ.
Либо у нас с вами это first от B и follow от A.
То есть, у нас из A может быть выведено пустое слово,
и дальше мы смотрим наш символ,
который у нас идет после этого.
И в итоге, по факту, говорится следующее,
что множество first plus
определяется для фиксированного правила.
И что это означает?
Это означает, что если мы начинаем подцеплять в алгоритме
нашим какое-то правило,
то, зная следующую букву,
мы можем оценить,
подходит это правило нам или нет.
И в итоге, говорится следующее,
что грамматика точно будет свободна от возвратов,
если множество first plus не пересекаются
ни для каких правых частей правил,
которые выводят из них терминала A.
То есть, они у нас, все эти множество first plus,
разбивают наше множество терминалов
на определенные подмножества.
То есть, мы явно можем понять по следующей букве,
какое у нас должно быть правило.
Вот эта мысль понятна?
Если что, спрашивайте.
То есть, у нас получается,
видим букву, сразу к нему делаем соответствующий first plus
или вводим ошибку.
То есть, у нас в цикле,
давайте тогда я все-таки промотаю,
вот он.
Видите, мы не начинаем смотреть
этот.
Что тут получается?
In focus or in non terminals
и смотреть, видите, тут есть rule,
равно next rule at focus.
Мы запрашиваем следующие правила,
а потом запрашиваем следующий терминал,
который у нас есть,
а потом и к него достаем правила,
которые мы дальше прицепляем.
То есть, порядок действий другой.
Хорошо.
Значит, это множество first plus.
Значит, сразу скажу,
что если оказывается,
что правила грамматики
изначально не принадлежит first plus,
ну, такое может быть вполне,
то нужно объединить в общий не терминал
в единый префикс.
То есть, мы вносим новый не терминал
для того, чтобы сделать дальнейшее раскрытие.
Потому что грамматика,
которая перечислена слева,
часть грамматики,
она явно не выводит пары символов.
То есть, явно видно,
что first plus
от правила a, стрелочка alpha b1
и a, стрелочка alpha b2
будут пересекаться.
Поэтому делаем такой контекст.
Вот, собственно,
здесь приведен пример того,
каким образом строится грамматика
по определенному правилу.
Тут ничего не видно на слайде,
но в презентации есть пример.
Если что, я могу его даже скинуть.
Он из книжки, которая была первая у нас.
Вот, тут...
Давайте, чтобы было на слайде видно.
Я сделаю вот так вот.
А ничего не видно на презентации, да?
Ай.
А?
Пал лучше, да.
Все-таки скриншоты надо делать лучше.
То есть, смотрите, здесь указывается,
что вот эта вот штука,
она разбирает правила
эксперт, звездочка, плюс терм
и минус терм.
И дальше вот как раз
идет разбор
вот этого правила.
Так, давайте я вернусь.
Здесь уже... а?
Ух, да.
Но при этом все работает за линию,
у нас нет никаких возврат.
Этим пользоваться невозможно,
поэтому люди придумали таблицу.
Мы говорим следующее,
что давайте составим таблицу,
она будет похожа на LR таблицу,
только это будет LL таблица.
Мы по строкам, мы с вами
пишем не терминал, а по столбцам
символы для просмотра вперед,
которые используются для этого
правила. И вот, смотрите,
здесь, допустим, есть правило
экспорт с штрих
выводят у нас плюс терм
экспорт.
То есть у нас экспорт штрих это плюс терм экспорт.
Значит, первый символ,
который у нас выводится для этого правила, это плюс,
и вот мы получаем на пересечении двойку.
Давайте посмотрим, что у нас
происходит для правила терм звездочка
эпсилон. Вот это, кстати, интересное.
Эпсилон это у нас
тое слово
собственно... где тут
кто-нибудь видеть восьмерку?
Вот они, да, видите, терм
штрих и эпсилон. То есть
восьмое правило грамматики.
Это у нас будет
ферст от
ферст от этого правила
будет либо конец слова,
либо закрывающая скобка.
Ну, собственно, почему так
происходит? Потому что у нас
терм на самом деле это операция
умножения,
когда нам уже не надо ничего
лишнего разбирать.
То есть у нас терм это для умножения,
фактор это
для скобочек.
Так, сейчас, секунду, я, кажется,
запутался.
А, не, фактор это для скобок.
Я запутался
в порядке операции.
Фактор это для умножения?
Угу.
Терм штрих это когда мы умножаем?
Да, да, да.
Да, терм штрих это когда мы умножаем
и когда у нас заканчивается умножение,
мы должны либо скобку закрыть, либо слово закрыть.
А вот
экспор
да, он таким же правилам соответствует.
То есть для экспор-штрих мы тоже
можем построить либо закрывающую скобку,
либо эпсилон.
Тут надо помедитировать, но главное
когда мы строим эту таблицу у нас нет пересечений.
Вот это важно.
То есть нет пересечений означает
мы можем явно смотреть на следующий
символ и двинуться в него.
Хорошо.
Теперь давайте рассмотрим
алгоритм разбора по таблице.
Сохраним стэк, вершину
этого стэка кладем
и стартовый символ.
И дальше у нас есть две ситуации.
Либо у нас вершина стэка это не терминал
и тогда мы смотрим на
ферст плюс от этого правила
для следующего символа и пытаемся его раскрыть.
Либо вершина стэка это терминал
и смотрим, собственно, совпадает ли
текущая буква, текущий токен
с тем, который мы хотим разобрать.
Если совпадаем, то все отлично.
Двигаем стэк, все снимаем.
Либо говорим, что у нас ошибка компиляции.
В тот момент
времени, когда мы не можем продвинуть
определенный терминал,
мы говорим, что у нас ошибка компиляции.
Важно, что ошибка компиляции
здесь детактируется по терминалам.
Вот это важно.
Если мы с вами читаем какой-то терминал
и
это означает, что мы знаем позицию
того места, где у нас
происходит ошибка компиляции.
То есть мы явно ее можем отследить.
Правда, здесь
для того, чтобы отхватить позицию этого символа
нам нужно понять, в каком правиле
какое правило мы хотим с вами разобрать.
Для того, чтобы
его вывести, так сказать.
Подсказку сделать,
правильно это мы делаем или нет.
Вот, значит, алгоритм
здесь будет выглядеть вот таким образом.
Собственно,
каким образом разбирается слово.
А у нас с вами есть выражение
A plus B умножить на C
как раз.
Мы сначала что делаем?
Смотрим. Следующий символ у нас
угол это name.
Нам нужно раскрыть верхнюю часть
по правилу 0.
Мы раскрываем, у нас кладется export на stack.
Потом, значит, что у нас происходит?
У нас export следующий
name. Куда мы двинемся с вами?
Что у нас на пересечении export name стоит?
Значит,
на пересечении export name у нас стоит
единичка. Это означает, что мы раскрываем
первое правило. Причем правило
кладем на stack в обратном порядке.
То есть сначала term, export.
Дальше term раскрываем единичку,
term и name.
Что у нас term и name? Это пятое
правило. Оно еще раз раскрывает.
Term и factor. И вот factor
еще раз раскроется в name.
То есть на пересечении factor и name у нас
11. И дальше у нас идет символ
name. Наконец-таки у нас с вами терминал.
Мы двигаем наш
указатель с совходного символа.
И повторяем до тех пор,
пока у нас весь вывод
не закончится.
Здесь можно поставить на паузу, посмотреть
и посидеть с бумажкой и порисовать.
Так, ну и наконец-таки
мы с вами должны посмотреть пример
ошибка компиляции.
Если у нас a++ умножить,
то вы правили
и следующий символ plus у нас term.
Term plus на пересечении
у нас ничего нету.
И мы понимаем тогда, что у нас ошибка компиляции
в том месте,
когда мы считываем plus.
И мы можем относительно понять,
в каком правиле грамматики мы зависли.
Мы с вами зависли в правиле грамматики
export plus term export.
То есть на обратном
отмотке,
поскольку это правило у нас
с удалением левосторонней рекурсии,
мы обратно возвращаем
эту рекурсию и восстанавливаем
исходное правило, в котором у нас была ошибка.
У нас есть соответствие
в каком моменте времени это произошло.
Хорошо, вопрос
теперь, который
я хочу задать,
пока мы не хотим его задать,
подумать на ним, наверное, стоит.
Мы построили с вами алгоритм, который
называется LL1 алгоритм.
И вы не поверите,
если сейчас действительно
задуматься и попытаться доказать
его корректность,
то я думаю его корректность
и его полнота
будет доказываться намного быстрее,
чем корректность и полнота LL1 алгоритма.
То есть на это реально
минут 10 понадобится.
Ну, не 10, но где-то пол пары
всего лишь.
Потому что мы явно увидели,
когда мы можем или не можем
спуститься.
Скорее всего, опять,
на грани очевидного,
мы потеряли.
Когда разобрали,
да,
да.
Но проблема в том,
что алгоритм LL1 намного
мало по сравнению с алгоритмом LR1.
И нам приходилось просто делать
модификации с разными грамматиками
для того, чтобы это работало.
То есть, как минимум, мы убрали левостороннюю рекурсию
в грамматике.
Ну, собственно, LL со звездой
как раз позволяет сильно расширить класс,
но при этом
лишая линейности этого алгоритма.
Вот.
Ну, и как раз давайте,
чтобы, собственно,
закончим наше занятие
на том, что рассмотрим
тот кейс, связанный с ошибками компиляции.
Значит, в ошибках компиляции
есть два сценария.
Первый сценарий — это мы можем
вставлять некоторые
правила грамматики, некоторые
ошибочные токены.
То есть, образно говоря, мы можем
написать, что у нас есть правила
из
export
там
допустим
name
и error.
То есть, мы вставляем специальный
error-токен, который мы просто
будем игнорировать
до того момента.
Прочтение этого токена будем игнорировать
до того момента, пока мы не дойдем
до закрывающей скобки.
То есть, в скобках написали,
да, начали писать какое-то выражение,
потом написали еще что-то, еще что-то, еще что-то.
И вот это еще что-то просто игнорируется.
Вот.
А второй способ делается следующим.
А давайте мы попробуем
удалять следующие символы, пока они
нам не подходят.
Да.
То есть, просто идет следующий символ,
давайте удалим его.
Как вы думаете, какой лучший подход
использовать для LL-парсеров?
Вставлять ошибочный токен в
правила? Или пытаться удалять
символы до тех пор, пока
мы не сможем продвинуться дальше?
Смотрите, так, кто
за первое?
Кто за вставку?
Кто за удаление?
Правильный ответ – это удаление.
Почему? Потому что, когда мы пытаемся
вставлять правила, да, то мы
двигаем указатель, который у нас есть.
В нашем случае мы сверху вниз
ставим, поэтому нам нужно сразу подцеплять те
правила, которые есть.
Практически в режиме рентайма.
Вот. А если
мы будем вставлять символы и не сможем
их разбирать, то это большая проблема.
Вот. Потому что, собственно,
интерцей может вызвать еще один кат разборов,
а здесь мы пропускаем символ до тех пор,
пока не нашли полу символ.
Как раз, если мы вспомним с вами
алгоритм перенос свертка, который
поднимается правило снизу наверх,
то в нем как раз удобно просто. Мы двигаем
следующий символ до тех пор, пока мы не найдем
символ, который нам раскрывает
правило, которое идет вверх.
Вот. Ну, наверное, мы про это уже
будем говорить в следующий раз.
Значит, давайте тогда план
на следующее занятие. Мы с вами
вкратце пробежимся по восходящим парсерам,
как они работают.
Это, собственно, LR-алгоритм.
Долго на нем заостряться не будем.
Наша цель – главное понять,
каким образом можно
переписывать грамматики
и каким образом можно
будет понимать то, что выводит
парсер на выводе
и уметь править эти ошибки.
Потому что наша цель
не написать алгоритм парсига,
а сделать так, чтобы
он правильно разобрал нашу грамматику.
То есть мы даем грамматику на вход,
наша цель – ее разобрать.
Вот. Давайте на этом, наверное, закончим.
Да, надеюсь, что следующими
лекциями у нас проблем не будет.
Всем спасибо и вопросы.
Есть вопросы?
Ну и хорошо.
