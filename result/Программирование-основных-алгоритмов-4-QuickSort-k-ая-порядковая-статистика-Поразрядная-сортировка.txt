Так, всем доброго утра. Давайте начнем. Мы с вами продолжаем сегодня заниматься сортировками.
И, надеюсь, мы сегодня закончим этим заниматься. И дальше пойдем уже к деревьям поиска, скорее всего.
Продолжение будет вылечено на сортировках.
И первый сюжет, о котором мы говорим, это будет про сортировку.
Точно ангрейтинг он не очень сложный. Давайте его быстренько и разберем.
Шаг первый. Выберем опорный элемент. Вот здесь сочетаем, что мы пока не говорим как именно. Мы его убираем как то. Его убираем. То есть вот ваш.
Допустим выбираем средний элемент. Шаг второй. Выполним так называемый partition.
То есть что такое partition? От массива Х.
То есть что этот шаг приводит к Ху, что мы выбираем упорный элемент, это Х. А partition от массива Х что он делает?
Все так, да. То есть это у вас 3 Х, то у вас здесь все меньше Х, здесь все больше Х.
У вас может быть много одинаковых элементов, поэтому давайте где-то равенство поставим.
Убор. То есть это вам индекс И так называется.
Перераспределили элементы.
Чтобы слева меньше Х, справа больше либо равенство.
Ну что тогда можно сказать? Можно сказать, что Х у нас стоит на нужном месте.
И нам надо сферовать эту часть и эту часть к курсиву. Потому что это был Х стоит на победном месте.
Где он должен стоять на цифровом массиве.
Шаг третий. Это вызвать крюксот от массива 0 и и крюксот от кого? От индекса И.
И плюс один. Ну это длина его.
Ну все, победа.
Главный алгоритм очень гениальный и простой. То есть если записать все доходом, то у вас будет выбирать пилот функция.
Ну пилот это опорный элемент.
Дальше будет партишн.
Дальше будет вызвать рикурсивно от левой и правой половины.
А, возникает вопрос. За сколько это дело работает?
Квадрат.
N лог N среди.
Ну вот давайте скажем следующее. Утверждение 1.
Партишн.
Можно сделать.
За отс N времени.
Пилот единицы до памяти.
Вот так вот можно сделать.
Тогда как выглядит рекуррент?
Рикуррент выглядит так, что здесь есть какой-то L, здесь есть какой-то R.
То есть в общем случае вот что это такое?
T от R.
Это T от I.
Плюс T от N минус I.
Плюс там.
Ну плюс линия на партишн.
С на N.
А оказалось бы, какое решение у этой рекурренты?
Ну не очевидно, на самом деле.
Ну что у нас зависит от I строк говоря.
Например.
Пусть I равно единичке.
Тогда T от N.
Это от N квадрат происходит.
Если уже от I порядка по.
То у вас в кратке получится то, что мы хотели.
Вот N было прям.
Ну то есть вот такие вот два корридии случая.
И оба выражаются в разной асимптотипе.
И непонятно от чего это зависит.
Ну в целом не понятно.
Зависит от того, кто выбирает церковный элемент.
И нам вот нужно этот вопрос в кратке с вами обсудить.
То есть как нужно выбирать первый шаг алгоритма.
Чтобы все было хорошо.
Для этого.
Сначала промулируем одну теорему.
Интересно.
И доказывать ее не будем.
Потому что бы это оказательно знать немножко теоргера.
Если выбирать опортные элементы независимо.
И равновероятно.
То что тогда?
То.
От ожидания.
Времени работы.
Составит.
От N.
Лог N.
Такая вот теорема.
Собственно, что здесь значит слово независимо.
Это значит, что каждый раз туда надо выбирать опорный элемент.
То есть вот здесь вот.
Потом когда рекурсивно запускать все этих половинок.
Они как бы друг от друга вообще не зависит.
Независимо.
То есть это должен быть абсолютно изолированный эксперимент.
Окей.
Что значит равновероятно?
Ну вы можете взять любой элемент из N.
Там один, два, три было у вас.
Индексам N.
Равновероятно.
То есть вы можете взять любой из них в качестве опорного.
И здесь в кратке равновероятно.
Равновероятно.
Это значит, что у вас вероятность выбрать каждый из них один, девять на N.
То есть абсолютно случайный.
Вот.
И что значит тогда от ожидания?
Ну представим, что у нас есть кубик, да?
Ну и грани.
Кубик от одного до шести.
Там шесть граний.
Там точка.
На каждой грани.
Там кто одна точка, кто две точки и так далее.
Тогда сколько в среднем у вас выпадет на кубике?
Вот вы подбрасываете кубик.
Сколько в среднем у вас выпадет?
Ну три с половиной.
Да, я понимаю.
Математика сложна.
Окей.
Так же и здесь, собственно говоря.
Какую бы вы перестановку не дали вашему алгоритму.
Перестановку от одного до N.
В среднем он будет работать за N.
Утверждается.
То есть там будет очень мало случаев, которые вырождаются в квадрат.
И они как бы очень редки.
То есть их вероятность очень мала.
Поэтому они входят туда с очень маленьким кладом.
В среднем N log N побеждают.
Вот.
Окей.
Хорошо, казалось бы круто, да?
Вот можно писать просто.
Выбери рандомно опорный элемент и побеждай.
Ну действительно.
Правда.
Однако мы с вами хотим, чтобы у нас алгоритмы были диссерминированы.
И не зависели от какой-то случайности.
Причем это случайность доказана лишь теоретически.
Энтерически-то у вас нет ничего случайного.
У вас компьютер не умеет делать случайные числа, неожиданно.
В нем конечно вставят алгоритмы генерации псевдослучайных чисел самые разные.
Но никто из них не может вам дать гарантию, что у вас есть четкая равноверенность и строгая независимость.
Ну может независимости есть, но про равноверенность очень сложно говорить.
Окей.
Так, с этим справились.
Ну вот, например, почему-то сложно.
Представьте, у вас есть игральный кубик, который от 1 до 6 выбрасывает.
Придумайте алгоритм, который вам будет выбирать с помощью него число от 1 до 31 равномерно.
Да, на вероятность его выдавать.
Вот какой-то алгоритм.
Вот у вас есть кубик.
Вы подбрасываете его несколько раз.
Ну сколько угодно.
Вот вам нужно получить как-то алгоритм, который вам возвращает равномерно от 1 до 31 числа.
Подбрасываем кубик два раза, у нас получается 36 результатов.
Если у нас какой-то результат от 1 до 31, то мы его оставляем.
Если больше, то мы снова подбрасываем кубик два раза.
Хорошо, докажите, что это конечное время будет длиться.
Оно не обязательно длится.
Вероятность того, что оно будет бесконечно длиться, равна нулю.
Это правда, что оно будет там, короче, воевывать будет постоянно.
Вероятность, с которой вы будете выкидывать, поставить числа.
Но суть в том, что раз придумать алгоритм, который однозначно выдаст равномерно от часа, то конечное время очень сложно.
Вообще не очевидно, как это делать.
Поэтому не очень любят, когда у вас есть некоторые недетерминированные алгоритмы.
Поэтому давайте изучим с вами такую вещь, как
алгоритм
медиан и медиан
В общем-то, у него он именной на самом деле.
Там пять авторов.
Поэтому будем считать его, что это алгоритм медиан и медиан.
Потому что все пяти даже с них в пол.
Как выглядит алгоритм?
Собственно, это алгоритм.
Как выбрать такой опорный элемент, чтобы у вас здесь гарантировано было нормальное разбиение?
Под нормальным мы тоже ставим, что это такое скоро.
Шаг первый.
Это
распилить
массив
на пятерке.
То есть, вот ваш массив.
Вот у вас здесь блок пять элементов.
Здесь блок пять элементов.
Здесь что-нибудь меньше либо равно пяти элементов.
Останется в конце в хвосте.
Шаг второй.
Найди медиан в каждом из них.
В каждом блоке.
Ну, например,
можно искать ее с помощью сортировки пузырьком.
Да, пузырек нам все-таки пригодился.
Потому что здесь у вас пять элементов все-таки в каждом блоке.
Пять квадратов это двадцать пять.
Но у вас типа N делить на пять.
Этих блок, поэтому сойдет.
За линию все еще будут работать.
Шаг третий.
Запустись.
Рекурсивно
от массива медиана.
Такая вот идея.
То есть, когда у вас остается там меньше пяти элементов,
ну или пять,
вы уже не можете разделить массив.
На пятерке у вас один блок.
Вы находите медиан, но это ваш ответ.
То есть, выход у вас вот здесь вот будет.
Так.
Окей.
Давайте с вами докажем.
Вообще посмотрим,
какое число можно получить тогда.
Ну, у вас есть массив.
Вы выделили в каждом из них медиану.
Раз, два, три.
И вот эта вот массива есть.
Раз, два, три.
Запустите.
Рекурсивно.
А почему это будет работать?
Что именно?
Во-первых, он ищет медиану.
Но он называет медиану медиану не потому,
что он ищет медиану,
а потому что он как бы вас берет медианы в маленьких блоках
и из них пытается найти медиану.
В конце концов, он медиану не найдет.
Это правда.
Но мы сейчас докажем, что он будет бить массив,
что найденный элемент будет нормально,
если это же не бить массив.
Не один к одному, но...
около того.
А почему еще раз это залинировали?
Мы еще это не говорили.
Подождите, мы сначала давайте обсудим,
что мы получим в результате.
Если мы получим что-то удобоваримое,
значит давайте докажем потом,
что это работает за нужное нам время.
Пока что мы искренне верим, что это работает,
но не знаем ни почему, ни за сколько.
Вот, а надо ответить на эти два вопроса.
А давайте посмотрим следующее.
Я нарисую матричку.
2, 2, A, A1.
Дальше здесь будет какой-нибудь A,
D5, A, D3, D4.
Я не знаю.
Я не знаю.
A, D5, D5.
Ну, у вас индексация такая странная.
В смысле странная?
Ну, я не знаю.
Как проиндексировалось, так проиндексировалось.
Вот, я смотрю такую матрицу.
Где A и D, это всегда элемент массива.
То есть вот это вот ваш первый блок.
Первый блок.
Вот, короче, вот этот.
Где мы делили массив на пятерке, это первый блок.
Это второй блок.
Ну и так далее.
Так как мы их сортировали,
у нас есть какое-то соотношение на них.
Согласны, что здесь выполнено вот такое вот неравенство?
Дальше.
Так как мы говорили, что мы берем все-таки,
типа рекурсивно запускаемся,
и сортировали эти массивы,
то мы утверждаем, что здесь вот такой вот вариант на них есть.
А где мы их сортировали?
Кого?
Нет, нет, у вас...
Смотрите.
Вы же что делали дальше?
Вы берете этот массив из пятерок.
Это медианы в каждой пятерке, согласны?
Вот этот вот ряд.
Вот, а что вы дальше делали?
Вы били его на пятерке и снова выбирали там медианы в каждом.
Поэтому здесь можно вот такие сравнения просто ставить.
В каждом блоке они тоже есть.
Давайте посмотрим, сколько элементов меньше, чем A и B3.
Ну, если это,
типа здесь у вас
N делик на 10 блоков,
и здесь N делик на 10 блоков.
То есть, смотрите, у вас здесь было
несколько элементов,
ну, N делик на 5.
Из них до середины
N делик на 10 блоков,
и после середины N делик на 10 блоков.
Тогда сколько элементов меньше либо равных, чем данные?
Три десятых.
Ну, сейчас, подождите.
Ну да, да, да, все, вот они.
Ну вот,
вот,
вот,
вот,
ну да, да, да, все, вот они.
Вот они, элементы меньше либо равные данного.
Вот в этом квадрате находятся.
Меньше либо равны, чем A
Здесь можно писать N делик на 10, 3.
А, то есть, знак меньше либо равно, это значит, что
медиана меньше либо равна?
Чего?
Сейчас, что такое вообще меньше либо равна?
Ну, ты берешь твою чиселку
и говоришь, меньше либо равна 1,
если выполняется какое-то соотношение N.
Х меньше либо равно Y,
это тогда, когда х минус Y меньше
либо равно U.
Ну, у нас тут 5 в ряд чиселок.
Да.
А, навременно к 5 всем применять?
Кто?
А этот третий применяется
к центральным числам,
вдоль ряда.
Ну, то есть, вот, вдоль этого ряда
вы применяете.
А почему вдоль ряда будет справедливо меньше равно?
Вдоль ряда?
Давайте подумаем.
Ну, окей, хорошо.
А ведь медиан и медиан все-таки ищут медиану
в этом массиве. То есть, вы, на самом деле,
будете найти, будто бы, медиану.
Да?
Утверждается, что если вы найдете медиану
в этом...
Если мы найдем медиану
в массиве вот этих вот пятерок,
то это будет верно. Согласны?
То есть, мы всегда берем центральный элемент
и их сравниваем?
Центральный ем?
Ну, мы всегда берем этот элемент, который...
Ну, будто бы данный массив явно не сортируется.
То есть, говорить медиан и медиан,
я говорю, что он ищет медиану,
он хочет ее найти.
И он ищет медиану массива пятерок.
Центральных элементов.
Окей.
Вот у вас есть блоки.
Каждым из них выделено медиану.
Средний ряд.
А, все, мы ж отсортовали массивы сначала, да?
Нет, конечно.
Мы нигде не сортировали его.
Вы... Вы вот в этом вот массиве
ищем
медиану.
Рекурсивно.
То есть, мы будто бы искали здесь медиану в исходном массиве.
Для этого мы подлили массив на пятерке
и запустились рекурсивно
от этого массива.
Ну, и допустим, вот вы вытащили
эту медиану как?
Тогда мы можем поставить вот этот столбец с ней сюда.
Все, что с левой будет меньше,
все, что с правой будет больше.
У нас, типа, нет такого расположения элементов.
Их просто удобно нарисовать, что они так есть.
Мы каждую из пятерок сортировали.
Нет, нет.
А можно соменить еще блоги.
Ну, не до этого блогов.
Но в общем, медианы
в этих блогах будут идти...
Конечно, нет, не обязательно.
Они, вроде, переставлены.
Ну, как бы, мы же здесь
не пересовывали таблицу.
Потому что все работа
с этой таблицей.
А, окей, хорошо, я понял.
Да, действительно, визуал так себе
получился. Но я думаю,
концепция понятна.
То есть, мы взяли эти пятерки и будто бы отсортировали
по вот этому элементу,
по третьему элементу.
Окей?
Вот, тогда утверждается, что у вас
тогда
найденный элемент,
найденный х таков,
что хотя бы
3n деленное на 10
элементов
меньше либо равны х.
То есть, мы не нашли с вами медиану.
Как видите.
Мы пытались ее искать каждый раз.
И, как бы, каждый раз мы к этому приближались,
но каждый раз вы не могли найти медиану.
Тут вот мы ее как-то нашли.
Вот.
3n.
3n.
3n делить на 10.
Ну, у вас 3n делить на 10 блоков,
здесь по три чиселки.
Окей, тогда...
То есть мы уже медиану
среди самих блоков
и там уже алгоритмов.
То есть она будет не ровно посередине,
а с 3n делить на 10
за 7n делить на 10.
И тогда у нас оттенка будет чуть меньше.
Все, 3n делить на 10.
Ну, окей, сейчас.
Я подумаю и на перерыве скажу тогда, если что. Хорошо?
Окей, здесь мы с этим справились.
И, соответственно, тогда мы получаем какой-то элемент,
который вот так вот соотносится.
Тогда что мы имеем право сказать здесь?
Вот в этой вот рекурренте.
Что у вас получается?
Что у нас получается?
Что у нас получается?
Что у нас получается?
Что у вас i равно...
хотя бы 3n делить на 10.
То есть у нас было с нами соотношение
плюс cn.
Да?
Ну что тогда можно сказать?
Что раз у вас i больше либо равно,
чем 3n делить на 10.
Ну, понятно дело, что у вас такой вот отрезок.
То есть у вас i какое-то такое.
Утверждается, что для таких i
t от n
равно от n лог n.
Ну,
это не очень смешно.
Ну,
это не очень трудно доказать,
на самом деле.
То есть вы берете рекуррент у вида
t от n
равно t от альпа n
плюс t от
альпа
1 минус альпа n
альпа из этого интервала.
Ну, из отрезка.
И дальше решайте ее.
И получайте, что у вас
действительно все хорошо будет.
Ну, ладно, давайте докажем это.
Вот у вас изначально был массив
длины n.
Дальше у вас алгоритм рекурсина
бьет его на две части.
Одна из них
альпа n, другая
1 минус альпа
на n.
Заметьте, что у нас
на каждом уровне
там будет n элементов.
Ну, порядка n, потому что 1 серийно
убирается.
Ну, будем считать, что их m.
Дальше. Здесь будет блок
альпа квадрат n.
Здесь будет блок
альпа альпа минус 1n.
Здесь будет блок
альпа альпа минус 1n.
Здесь будет блок
ой, 1 минус альпа.
Альпа квадрат n.
Ну, если просумировать,
получите снова n.
И так далее.
И так далее,
пока у вас тут не станут блоки
по одному элементу.
И там будет даже сам альпа
в третьей шаге.
Ну, хорошо.
Мы считаем, что альпа
просто какая-то коэффициент
этого интервала.
Вот из этого. Все.
Ну, какой-нибудь альпа 1 может быть.
Да, действительно.
Альпа на втором шаге, альпа на третьем шаге
могут быть разные. Да, конечно.
Нам главное, что они делятся в каком-то константном
соотношении.
Ну, действительно, да, здесь надо нормально
другие константы писать, но
мне их уже лень пойти здесь слишком.
Все равно это будет схематическое доказательство.
Такая вот выстава
от этого дерева рекурсия.
Ну, будто бы
ну, будто бы вы берете
говорите, что альпа в степи h
на n
должно быть чему равно?
Должно быть меньше, должно быть равно единичке.
Ну, меньше либо равно.
Сейчас.
Ну, да, да, да.
Чтобы какой-то либо этот блок, либо этот блок.
Ну, пускай вот так вот.
Тогда альпа в степени h меньше
либо равно 1 делить на n.
h меньше либо равно, чем логариф
по основанию. Альпа от 1 делить на n.
Что-то такое вот.
Так, получаем здесь что?
По-моему, можно вот так вот перейти
к другому основанию.
1 делить на h.
Вроде бы. Здесь можно так делать.
Но это не точно.
Можно, да? Супер.
То есть, ваш h равно
от
лог n.
И у вас на каждом шаге n действий.
Потому что у вас
нерекурсивная компонента.
Потому что у вас нерекурсивная компонента
она cn.
Здесь cn действий, здесь cn действий, здесь cn действий.
И так далее у вас уровни сила лог n.
Ну, все.
Можно так доказывать.
То есть, это вот называется метод рассмотреть дерево
рекурсия. Вот.
А как мы используем, что альпа прижит отрезку вот этому?
То, что альпа — это как констант.
Ну, а вот в том случае,
когда альпа от 1 до
от 0 до 1 мы тоже могли делать, получается.
В самом деле.
Совсем.
Вы должны зафиксировать альпа
не от 0 до 1.
Вы же должны как-то уметь
Смотрите, хорошо. У вас альпа
должно быть
строго больше 0,
но при этом какие-то адекватные числа.
Скажем так.
Смотрите, если у вас
альпа — это не констант, а какая-то функция
здесь у вас нельзя просто
так сказать, что здесь нельзя
просто перейти и снять основание.
Вдруг у вас альпа — это не констант?
Когда вы говорите,
что у вас альпа — это...
Здесь вот получается время
1, то альпа — это функция
так или иначе. И здесь нельзя
переходить к...
к тому, что здесь просто нельзя снимать
это основание, и нам тогда нормально
уже оценивать. Здесь альпа констант,
поэтому все можно делать, все легально.
Когда у вас альпа — это не констант, так сделать просто нельзя.
Вы можете повторить, откуда вы
получили альпу в степени N на N
или меньше, или ровно.
Ну, я оцениваю
какая будет высота дерева, если у меня
вот этот кусочек все время самый большой остается.
Да, в степени H.
То есть у вас размер этого блока
альпа, альпа квадрат, аж...
альпа N, альпа квадрат N,
альпа в степени H на N.
Вот, ну давайте мы будем считать
просто, что альпа... Ну да, у нас альпа меньше
одна и вторая, поэтому этот блок...
Непринципиально.
Хорошо, да.
Хорошо, мы здесь надо один
минус альпу везде написать, но
с точностью до замены перемены все будет корректно.
Все равно здесь алгоритм
тоже сам получится.
По поводу вот этой вот
штуки...
Давайте мы
до конца распишем эту идею все-таки.
Вот.
Потому что я здесь, да, забыл кое-что упомянуть
и нам надо об этом сказать с вами.
Собственно, понадобится еще один алгоритм.
Xselect.
Собственно, мы хотим найти
кат и упорядково.
Статистику.
Как он делается у вас?
Он делается следующим образом, что
вы берете какой-то элемент
опорным,
например, случайным,
дальше разделяете пополам,
ну, делаете partition
и смотрите, что получается.
То есть, вот ваш массивчик,
вот вы его поделили,
x и меньше x.
Можешь ли вы равны x, да?
То есть, шаг первый, это
выбрать
опорный элемент.
Шаг второй, когда вы
делаете пополам,
ну, делаете partition
и смотрите, где у вас элементов сколько.
Шаг второй, когда вы
выбрали опорный элемент, что вы делаете?
Вы делаете partition.
Шаг третий, осталось
разобраться с тем, как
искать кат и упорядково. Ну, давайте посмотрим,
что у нас может быть.
k меньше i.
То есть, например, у нас здесь десятый элемент,
и мы ищем какую-нибудь третью упорядковую.
И она где-то вот здесь вот находится, согласны?
Если вы отсортируете массивчик
и возьмете кат и элемент в нем,
то это кат и упорядка и статистика.
Вот.
Если у вас k меньше i,
значит у вас где-то в этой половине находится ваш
кат и элемент.
Вызываем quick select.
Quick select
от массива
0 и k.
Ну, 0 и это индексы,
это границы.
Второй вариант k равно равно i.
Ну, вы нашли кат и элементы, вас поздравляю.
Ретерн x.
В случае, когда k больше i,
что мы делаем?
Делаем quick select. От чего?
И смотрите,
у нас здесь есть
и смотрите,
если вы искали в этом вот
и, допустим, равно 10,
вы ищете 50-ю упорядковую статистику,
вы ищете в этом массиве,
тогда вы уже должны отбросить все вот эти вот
i плюс 1 элементов.
Поэтому здесь вы должны искать не k-ую упорядковую,
а вот такую вот
k минус i минус 1
статистику.
Окей?
Ну, потому что
если вы ищете 50-ю упорядковую
во всем этом массиве,
и вы знаете, что у вас
еще 10 элементов меньше вашего,
значит, в этом блоке вы ищете уже
50 минус 11
и эту упорядковую статистику.
Понятно?
Оно
делит
массив как-то,
чтобы было меньше x больше
либо равно x и сам x.
Как конечный элемент?
Если x минимальный?
Мы выбираем в себе
упорный элемент как-то,
получаем x, да.
Да.
Конечно.
Но его цель это переставить
элементы массива так, чтобы
слева было меньше x, справа было больше
x и x посередине.
Что среди меньших x
и среди больших x творится, никому не известно.
Вот.
Вот.
Смотрите.
Вот у вас есть массивчик.
Вы спрашиваете, что такое вторая
упорядковая?
Вы сортируете массив.
Ну, из зависимости от того, в какой индексации
вы берете либо в 1, либо в 0
индексации, второй элемент.
В этот момент
вы делаете массив
либо в ноль индексации второй элемент. Это четыре. Если вас просят третью порядковую,
вы берете третий элемент и так далее. Осознанно? Нет, конечно. Нет, если он сортирован,
верни просто катаэлемент. Чего мы здесь распинаемся? Как бы да, если мы здесь сортирован,
то непонятно, как катаэпорядку возвращать. А здесь, если нет, то вот такая вот идея. И,
казалось бы, проблема в том, что если вы берете случайный опорный элемент,
то тогда это будет работать в среднем за линию. Тоже утверждается, что если у вас,
давай теорема BD, если выбирать опорный элемент за случайно, ну здесь вот это вот должна быть
независимая равномерно то мотожидание времени работы отн. Утверждается, что в среднем он за линию
работает. Теперь нам нужно как-то связывать вот с этой вот штукой. Что? Будет, будет. Мы
сейчас будем комбинировать этого алгоритма, они будут друг друга поочередно вызывать. То есть,
как смотрите, у нас наша глобальная цель — это получить медиану массива. Согласны? Давайте теперь
будем вызывать их друг, короче говоря, они будут дергать сейчас друг друга эти алгоритмы. И давайте
мы сделаем вот как. У нас будет функция Quick Select. Ну или там int, неважно, что-то она вернет,
короче. Она будет принимать в себя ваш массив. Допустим, было индексы, да, там LR. Как же хочется
в такие моменты подписать на питоне? Там все так хорошо, не нужно ничего прописывать. Короче,
ладно, просто массив и pivot function. Ну собственно, она принимает в себя функцию. Как выбирать
этот опорный элемент? Опорный элемент — это pivot еще называется. Вот. И как устроен будет этот код?
А, ну и по умолчанию она будет типа random. У нас будет еще аргумент по умолчанию,
что это random просто, равно random. Что мы будем делать здесь? Для этого мы сами выбираем pivot
равно pivot function от array. Вот мы сами выбрали опорный элемент. Дальше сделан partition от массива
pivot. То есть вот его разбили. Это сам array, там типа на месте делается. Отлично. Теперь вы смотрите,
ну, соответственно, вы получаете этот вот i. Вот этот прекрасный i. Дальше теперь что вы делаете?
Типа if, if меньше, чем k, click select. И теперь надо понять функцию какую вы хотите сюда передать.
Что? Ну да.
Делать просто return r и ты. И последнее if и больше k. А, ну сюда еще типа надо k передавать.
Вот.
Ну что это такое? Ну да, мы здесь что-то return, поэтому делаем. Ну типа здесь мы должны
написать просто return и return к результату. Можно и плюс один, неважно. А теперь, собственно,
ну давайте хорошо с выпуском начнем. Вот. Теперь дальше займемся как писать саму медиану медиану.
Здесь я буду писать уже совсем псевдокодом. Ну, тоже видимо int возвращает у нас, не знаю.
Медиас. Короче, он там что-то попринимает. Напишем, что он там принимает, когда поймем, что нам нужно.
Что она сделает? Она будет типа делать split by 5 от массива. Ну, давайте нажимаем эти штуки там.
Не хватает места. Это грустно. Короче говоря, получим двумерный массив chunks. Вот этот вот массив
просто вот такого вот вида. Здесь 5 элементов, здесь 5 элементов, здесь 5 элементов. Такой двумерный
массив, где мы просто взяли этот наш исходный массив array по 5 блоки, по 5 вот так вот просто
поставили и все, матрицу такую получили. Дальше. Я напишу функцию гениальную. Сортируем пятерки chunks.
Пробегаетесь в форум и от каждого сорта вызываете. Баблсорт какой-нибудь. Теперь вы хотите дальше
medians равно. Что такое medians? Это где-то medians какой-нибудь. Чанк с вашего. То есть этот, который
вот форум пробегает по этим всем массивам, вытаскивает вам сердинные элементы. И что вы теперь делаете? Теперь вы
делаете гениальный контент вида quick select от array, от вашего массива medians только. Дальше. Вместо k вы
передаете n деленное на 10. Где n? Это длина массива. Здесь мы вытаскиваем medians. По дефолту мы считаем, что
random. Потому что заявили, что если вы будете делать просто medians medians каждый шаг, то у вас здесь 3n на 10,
но на следующем шаге вытащите здесь не medians, вытащите что-то, что снова 3 десятых только отсечет.
То есть если вы будете постоянно вызывать одно и то же, то у вас будет 3 десятых на 3 десятых на
3 десятых. И так далее элементов будет меньше только. И таким образом у вас получится, что это будет
нелагерифмическая высота. Так нет, мы сейчас возьмем самый интересный random.
Да, только смотрите, вы каждый раз вызываете здесь массив 5 раз меньше.
Он вам вернул медиану. Именно что он вернул медиану этого массива в пятерках. Вот тут он
вам вернет чистую медиану, потому что random вызывает. А если он вам вернет чистую медиану,
значит у вас выполнено соотношение 3n на 10. И вы получите тогда в исходном click
select вы получите нормальный пивот. Что? Ну это убийство сейчас будет. Здесь напишите
return click select. Вот смотрите, да, мы стремились избежать рандома, но здесь важно понимать,
что рандом только где у вас есть. Давайте посмотрим когда у вас появляется рандом. Вот здесь вот,
да. То есть вы вызвали рандом на пивот, сделали с ним партию, но потом-то вы делаете click select
с медианом и медианом. То есть по факту здесь рандома-то почти нет. И гарантируется, что при
любом рандоме все будет хорошо. Так она вызывает click select. То есть они друг друга дергают.
И что? Ну давайте оценим время работы, хорошо. Давайте время работы этой штуки оценим. Вот у вас
3n. Это что такое? Ну понятно ее, что это n. Вот здесь вот, да. Вот это вот с этим вот это n.
Плюс click select с медианом и медианом. То есть смотрите, что у вас здесь будет. У вас медиан и медиан
тоже работает за линию, согласны, да. Вот это вот линия, линия, линия. Плюс. Вы делаете все то же
самое, вызываете с рандомом. Только плюс t от n делить на 5, согласны? Ну у вас массив медиан с 5 раз меньше.
Окей? Вот вы вызвали эту штуку. Он вам вернул вот этот вот вызов. И дальше вы идете либо сюда,
либо сюда. Но мы с вами знаем, что медианная массива этих пятерок, она что такое? Она по сути
является чем? Она является медианом от массива пятерок, а значит у нее хотя бы 3n на 10 элементов
меньше нее. Значит у вас в обеих этих ветках не больше чем 7n делить на 10 может остаться здесь.
И поэтому вызываете то же самое время. Плюс t от 7n деленное на 10. Ну давайте я вот эти вот n-ки
зафиксирую просто как c умножить на n. Ну понятное дело, что у вас здесь типа вот это ничего не
дергается, если у вас просто 5 элементов, если у вас меньше 5 элементов здесь. А здесь вот у вас
выход из рекурсии есть. То есть вы каждый раз уменьшаете размер вашего массива, да, и при этом у вас
выход есть как? Когда у вас меньше 5 остаётся элементом, он просто выдаёт вам ответ. Давайте
докажем, как ведется этот рекуррент по времени. Ваши идеи. Какая мастерти арема? Она не подойдет,
потому что у нас здесь рекурсивный вызов Quick Select идёт дальше. Вы нашли, хорошо, у вас первая
итерация, когда вы кучу раз вызывали друг друга эти алгоритмы, вы нашли вот эту вот чиселку,
меньше которой 7n на 10, 3n на 10 элементов. Вы же ищете произвольную катую порядковую, а не какую-то.
То есть вы хотите, чтобы у вас вот эта вот штука, она вам вернёт вот этот вот элемент. А, и ты третий.
Окей? Естественно, дальше вы будете выбирать вот это вот всё дело.
Кого? Ещё раз. У вас этот чувак вернёт вам медиану массива Medians. Согласны? Вот этот
вот ряд – это массив Medians. И он вам утверждает, что он вам вернёт чистую медиану, которую вы
хотите от него. Не важно, чтобы внутри он там будет себя дёргать кучу всего. Вот здесь вам
гарантируется, что вам вернётся честная n делить на 10 порядковая статистика. Потому что у вас Quick
Select так устроен. Да, да, рано или поздно вы до него спуститесь. Просто как, смотрите, у вас Quick
Select дёргает медиану медиан, медиану медиану дёргает Quick Select с рандомом, тот дёргает
Quick Select с медианом и медианом, который дёргает медиану медиан. Да, они друг друга дёргают.
У вас кара равна n делить на 10, вот вы вызвались. Он ищет массив Median, n делить на 10 порядковую
статистику. Дальше он выбирает у вас тут случайно Pivot и вытаскивает от него Quick Select с медианом и
медианом. У вас уже длина массива маленькая, она у вас уже была типа n делить на n делить на 5
стала. Вот он t от n делить на 5. Кого? Пять раз меньше массив только, потому что у вас массив медиан
всё-таки остаётся. Смотрите, у вас будто бы запуск Quick Select лишь одной итерации вот этой
вот выбрать опорный элемент, она будет дёргать внутри себя Quick Select, медиану медиан, Quick Select,
медиану медиан поочерёдно. И вот он вам вернёт медиану, массиву медиан, а это и третий. И это
у вас закончится только вот этот вот шаг. Дальше он пойдёт сюда, здесь ничего рекурсивного не будет,
и дальше он пойдёт сюда и начнётся всё то же самое. Партишн у вас вообще ничего не вызывает
рекурсивно. Партишн всё время одинаковый, да. Ну короче говоря, вот вам рекомендую просто взять
этот код и просто представить как будут функции себя вызывать, какие в таком порядке. Это хорошее
упражнение на рекурсию. Так, давайте докажем, что это работает за линию. Смотрите, что мы делаем в
поиске кат и порядка в Quick Select? Мы вызываемся либо от левой части, либо от правой части. Мы
говорим себе, что меньше части хотя бы 3n на 10 элементов. Значит, в большей части не больше,
чем 7n на 10. Поэтому вот такая вот у вас оценка сверху. Что? Окей. Ну там в среднем n log n. Мы хотим
в худшем случае n log n. Смотрите, если злоумышленник знает ваш генератор случайных чисел, то он вам
построит массив, который за н квадрат будет работать. А теперь вы хотите так, чтобы никакой
злоумышленник не мог вам этим помешать. Он требует допамяти. Докажем по индукции, что t от n меньше
либо равно, чем 10 cn. Докажем по индукции, что t от n меньше либо равно, чем 10 cn.
Доказательство гениальное будет просто. Мы говорим тогда, что вот это вот все меньше
либо равно, чем cn плюс 10 cn делить на 5, плюс 7n делить на 10, на 10 cn.
Хипсорт не требует, да. Это классно, конечно. Ну, скажем так, хипсорт, конечно, допамяти у вас
особо не требует, да, но в целом чувак не очень быстрый. Там константик. Короче говоря, что? Да,
мы короче еще проведем сравнительные анализы. Вы не бегите вперед в паровоз. Вот t от n равно
10 cn, доказали. Откуда у вас следует, что t от n равно o от n? То есть мы с вами построили
детерминированный алгоритм поиска за o от n, катой порядка произвольной. Вот, а это значит,
что вы можете искать все гарантированно медиану каждый раз в быстрой сортировке, да. А медиан у вас
делит пополам массив обязательно. А если это так, значит вы умеете делать рекурренту t от n
равно 2t от n пополам плюс o от n. Все. Ну вот, у меня есть... Докажем по индукции, что это так. То есть
для любого k, t от k меньше либо равно, чем 10 ck. Докажем, что для любого k меньше n. Верно вот
это. Докажем, что t от n меньше либо равно, чем 10 cn. Ну окей, хорошо, берем рекурсивный раскрайм,
делить на 5 меньше, чем n. Логично, что меньше. Значит, мы имеем право применить вот это вот.
Аналогично с 7n на 10. Все. Окей. Да. Да. Ну если что, у вас есть такая задача в контесте написать-то
все. Но она бонусная. Там типа можно написать рандомный quicksort, тогда он 1 балл будет стоить.
А если напишете еще вот эту вот штуку, то будет 2 балла. Это 1 балл. А как вы собираетесь искать?
Нет. Требуется, чтобы... Ну если вы будете постоянно выбирать серединный элемент, это плохо.
Ну конечно зайдет, если... Ну невозможно на любую стратегию придумать контур-тест,
потому что тестов конечное количество, а стратегий чуть больше, чем тестов. Но на то она есть review,
чтобы... Рандом? Ну рандом нет, не детерминированный. Ну смотрите, у вас стоит... Здесь рандом,
да, действительно. Но у вас здесь медианы-медиан, которые нивелируют все это действие рандома. Вам
особо не важно, что здесь произойдет. Ну вроде бы да. Все равно здесь медианы-медиан все время вызываются.
Потому что по умолчанию вы не хотите писать медиану-медиану.
Ну окей, хорошо, давайте сделаем вот так вот. Сейчас.
Но здесь можно дергать просто-напросто ту же самую pivot функцию, писать медиан вместо медиан-медиан,
вызвать единожды с медианом-медианом, все будет все равно ок. Окей? Так,
давайте подумайте над всем этим делом пока что, а я расскажу, что хотел. Если останутся еще
вопросы, то давайте, тогда подойдете просто после лекции. Окей. Последнее,
про что я хотел сегодня рассказать, это по разрядной сортировке, ну или еще называть цифровой сортировке.
Пусть мы хотим сортировать числа, ну дать им числа, пусть хотим сортировать
объекты, которые принимают значение, принимают одно из к значений. Например,
мы хотим сортировать числа от 1 до 100. У вас массив, в нем все числа от 1 до 100. В плане,
что каждый аид, и он там от 1 до 100 где-то лежит. Вот натуральный и все, то есть у вас кар равно 100
здесь. Вот оказалось бы, можно что делать? Можно просто посчитать сколько у вас единичек, сколько
двоих, сколько троих и так далее, и дальше выписать столько раз, сколько и надо. Алгоритм 30 из 10,
я считаю. Давайте все-таки напишем теперь стабильную сортировку подсчетом. Так,
я не помню, давали определение стабильности или нет. Хорошо. Сортировка подсчетом.
Сортировка стабильная, определение. Сортировка стабильная, если она не меняет
место положения относительного, равных элементов. Ну, пример здесь такой. Вы хотите
отсортировать пары по первой компоненте. Вы их сортируете по верхней компоненте. Что
тогда будем делать? Понятное дело, первым мы должны писать минус 1,3. И дальше стабильная
сортировка, если у вас есть равные ключи, вот у вас ключ равный единичке, она не будет как-то
смотреть на второй элемент, а выпишет их именно в том порядке. То есть она пишет 1,2, 1,0, 1,2 и дальше
2,1 допишет. Это вот стабильная сортировка. Не стабильная, а как-то бы их потом перемешала
скорее всего. То есть нам не дают такой гарантии. Ну, где вы могли в жизни видеть стабильные
сортировки? Ну, в Google табличках, знаете, там можно отсортировать. Вот, например, у вас есть список людей по
баллам и их фио. Вот вы берете сначала, сортируете по фио, потом по баллам. Тогда у вас если баллы
одинаковые, то порядок по фио сохранится относительный. Потому что сортировка там
стабильная написана. Ну, тогда сразу скажем, что мерсорт является стабильной сортировкой,
квиксорт не является, хипсорт тоже не является. А стабильность — это прекрасные свойства,
которые многому хочется достичь. Окей, как будет теперь устроена такая цифровая сортировка,
чтобы она была стабильной? Пусть CNT — это массив. Такое, что CNT ИТ, сколько раз встречается ИТ
элемент? Раз, встречается ИТ элемент. Ну, элемент с ключом И. Тогда сделано вот так,
что преф от нулевой равен нулю, пор И и меньше, чем n-1, плюс-плюс И. Скажем, что преф ИТ равно преф
И-1, плюс CNT ИТ. То есть построить сам массив префиксных сумм CNT. И дальше я буду говорить
следующее тогда, что пор И равен нулю и меньше n. Сейчас. Здесь k. Потому что у вас k разных,
у вас же CNT будет длиной k, поэтому здесь будет до k цикл. Плюс-плюс И. Давайте посмотрим.
То есть вот у нас есть массив наших прекрасных пар. Давайте я здесь для красоты просто ноль напишу.
Вот давайте посмотрим сами, как у нас массив будет устроен. То есть у нас массив здесь,
если мы по ключам посмотрим 1, 0, 1, 2, 1. Дальше мы считаем массив CNT. 1, 3, 1. То есть вот у
вас по ключам 0, 1, 2, у вас три денечки, один нолик, одна двойка. Тогда массив преф чему равен? Он
имеет такой вот вид интересный. 0, 1, 4. Даже здесь давайте, видимо, вот так вот будет алгоритм,
чтобы по индексам все завпало. Массив преф и CNT только без последнего элемента. Смотрите,
в чем здесь суть. Это значит, что у вас элементы с ключом 0 пишутся на позицию 0. Дальше все элементы
с ключом 1 пишутся на позиции 1, 2, 3. Элемент с ключом 2 будет писаться по индексу 4. То есть вы
посчитали, сколько элементов меньше данного. То есть где должны начинаться эти элементы.
Теперь вы здесь говорите, что рез от преф, от а и ты. Балдеж. Вы получите так массив,
отсортированный в итоге. Давайте в качестве примера, что вы будете делать. Вот вы идете
циклом по массиву А, тот массив А ваш изначальный. Вы увидите 1, 2. Ключ берете равный 1. Смотрите,
что такое А1. А1 это ключ, это есть единичка. Дальше берем преф 1, это 1. Тогда результат
по первому индексу будет вот этой вот парой. То есть вы пишете именно индекс здесь, выбираете
нужный вам. А дальше увеличивайте. Говорят, что у вас свободное место теперь только с двойки
здесь. То есть вам нужно будет писать следующий элемент с ключом 1 по индексу 2. Дальше берете
этот элемент 0. Преф 0 это 0, поэтому он пишет его на 0 место и говорит, что здесь 1. Дальше берет
этот элемент. Ключ 1, преф 1 это 2, поэтому он пишет по второму индексу и соответственно
заменяй здесь на троечку. Ну понятно, да, как это работает. Итого время работы
от N плюс K, память от K. Потому что вот с Nt и преф этот массив длины K.
Собственно, а в чем это польза этих сортировок? Казалось бы, вообще бесполезная вещь.
Как теперь с помощью этой штуки сортировать произвольные числа?
Ну вспомним, что произвольные числа это набор байтов просто в памяти компьютера.
То есть у вас произвольное число это вот раз, два, ну давайте я int скажу, int это 4 байта.
Но если быть более точным, я хочу вот такие вот числа сортировать у int 32t. 4 байта.
Я же могу их стабильно отсортировать все числа по первому байту, согласны?
Если отсортирую все числа по первому байту по убыванию, а дальше по второму байту,
я что получу? Что у меня есть сортировка по второму байту, а по первому байту,
если вторые равны, они будут отсортированы все еще. Согласны? Да, именно так. То есть сортируем
стабильно по возрастанию, по байтово, от меньших к большим.
Эта сортировка еще называется вот так вот. List significant digit sort. Именно так.
Лекции, семинары, домашки, формула успеха на нашем курсе. Вот. Есть еще msd, если что.
Это когда вы наоборот не от младших байтов к большему сортируете, а наоборот от больших к младшему.
Вы научились сортировать числа вида у int 32t? Давайте посчитаем за сколько.
Просто две вариации существуют. Мы их разбирать не будем, мы только это будем смотреть.
Там что-то как-то умному делают, чтобы работало. То есть давайте посмотрим на время работы.
Это будет от 4 умножить на n плюс 2 в восьмой. Ну 2 в восьмой, потому что у вас здесь это сколько
бит, сколько у вас в байте может быть от 0 до 255 хранится, потому что это 8 бит. А четверка
это потому что у вас раз, два, три, четыре блока. Шок контент мы построили сортировку за линию.
Нам важно идти от меньших значащих байтов к большим значащим байтом. Другое в простом,
как они у вас записаны, что меньше это будет первые 8 или последние 8 бит. Ну есть такие вещи
и Little Endian и Big Endian. То есть заканчиваются на большие байты или на меньшие байты. Но это у вас
будет у кого-то на окосе, у кого-то видимо на паке, так этот курс сейчас называется, у второго курса.
Вам придется в системе узнать какой порядок Little Endian или Big Endian используется, потому что у вас
есть задача написать эту штуку. Что? Ну да, можно, можно. Короче да, вот так вот, мы придумали самим
сортировку за линию. И видите, мы здесь используем далеко не только то, что у нас есть 10, что у нас
есть меньше-больше. Мы используем еще очень сильная и наглая информация о внутреннем строении числа в
памяти компьютера. Поэтому эта сортировка не может являться сортировкой основанной на сравнениях.
Если вы очень нагло используете вот эти вот штуки, то что у вас байты какие-то конкретные и то,
что компьютер их именно так и представляет. Ну также вы можете строки сортировать по символам.
То есть вы сортируете от меньших к большим. Вот, окей. Теперь давайте быстренько подведем
анализ заключительный. HipSort. Сколько требует доп памяти HipSort?
Так вы можете делать Hippify на нужном месте, а Extract Min у вас просто свапывает, в конец же идет и все.
Доп память. Худшее время. Стабильность. Доп памяти HipSort у вас 100 единиц требует. На самом деле,
вы можете прям на том же массиве все посортить. Худшее время. Ну вот, M.Lugen. Стабильности нет,
HipSort нестабильен. Поэтому дело, что вы можете к каждому элементу добавить его ключ,
ну его индекс, типа создать пары элементов и их посортировать уже. Но это плохо закончится,
потому что доп памяти вот N требуется. Дальше MergeSort. Доп памяти MergeSort требует от N.
Худшее время MergeSort N.Lugen. И он будет являться стабильным. Дальше. Давайте QuickSort.
Без Median и Median. Какой у вас доп памяти требует QuickSort? А Stack Recursive кто хранить будет?
В среднем. В худшем случае OATM. Если у вас без Median и Median, в худшем случае все будет очень плохо.
В среднем OATM. В худшем OATM. Худшее время QuickSort. N квадрат. Стабильность. Нестабильная
сортировка. Теперь QuickSort с MM. Доп памяти. Ну да, действительно, здесь нам нужно хранить с вами
массив Median. Надо сохранить все-таки. Когда мы вырезали Recursive, у вас создается массив Median,
так или иначе, в котором вы ищете саму Median. Вот этот массив 5 у вас. Это вы можете делать in place,
но важно, что у вас этот массив вам нужно его отдельно сохранить, потому что вы его отдельно
пробрасываете функцию. Поэтому OATM доп памяти себя. Но здесь мы говорим, что OATM.Lugen. Зато худшее
время. И стабильности нет. Кто самый крутой? Так Merge вас требует OATM доп памяти. Так HipSort
нестабильно. Так оно не умеет сортировать произвольные объекты. Здесь нет идеала, да.
На QuickSort легко пишется на самом деле. Ну вот эта вот штука очень легко пишется.
Это серьезный недостаток, конечно. У него памяти в среднем, то он OATM.Lugen и памяти в среднем меньше
потребляют. Ну конечно, вы же можете себе выделить. Вот у вас был гигабайтный массив,
давайте еще гигабайтный массив бахну. Мне ж не жалко. Дело в масштабах. Вот N это не очень много,
но если N это гигабайт, то уже много. Вот. Короче говоря, вот так вот. То есть видите,
здесь нет идеальной сортировки. У нас ее не проходим. По-моему, где-то утверждается,
что существует какая-то идеальная сортировка, которая и стабильно, и OATM.Lugen в худшем времени,
и OATM.Lugen до памяти потребляют. Что? Я даже не вспомню. На Википедии можно открыть,
там есть огромная табличка сравнения сортировок. Вот там 50 штук. Вот найдете там идеал.
Короче вот. Вот так вот. И, собственно, главный вывод это то, что вам нужно использовать. Мы же
зачем изучаем разные сортировки? А затем, чтобы вы понимали в зависимости от задачи,
какую вам можно использовать. Если у вас нет много допамяти, вы вынуждены использовать
либо хипсорт, либо что-то еще. Если вам же нужна стабильность, то вы вынуждены использовать
нордсорт. Если у вас обычные чиселки, то вы можете использовать LSD. Если это строки,
тоже можете использовать LSD. Вот. В целом не надо использовать LSD. Вот. Так что в зависимости от
задачи выбирайте, какой инструмент вам полезнее. И в целом мы на курсе алгоритма будем проходить
много вещей, которые, казалось бы, похожи. Деревья поискают, мы будем несколько штук рассматривать,
и у каждого из них будут свои нюансы. Хотя, казалось бы, там все будут работать плюс-минус
алгоритм, там и что-то еще. Вот. Как-то так. Вопрос тогда остались. Ну тогда на следующем занятии мы
начинаем деревья поиска, вот, сортировка, и мы закончили.
