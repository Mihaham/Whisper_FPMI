Итак добрый день в прошлый раз напоминаю мы с вами разобрались с тем когда оператор у нас
диагонализуем ну и разобрались с геометрическим смыслом того что означает что оператор диагонализуем
с такими операторами работать легко и просто особенно в этом самом диагонализующем базисе
наш следующий вопрос посвящен тому а что если это не так да то есть что делать
с недиагонализуемыми операторами и до некоторой степени мы на этот вопрос ответим то есть мы
сумеем привести матрицу оператора заменой базиса к достаточно хорошему виду ну и по сути дела увидим
что вот этот вид уже однозначно определяется это вот наша светлая цель которой мы будем
стремиться есть одно граничное условие значит мы сейчас будем работать в основном я скажу когда
это будет не так с операторами у которых характеристический многочлен
линейно факторизуем ну то есть этот самый характеристический многочлен есть просто
произведение линейных сомножителей мы знаем что можно его представить даже вот в таком виде и
произведение именно вот таких вот линейных сомножителей ну и через некоторое время нам будет
важно в каких степенях эти сомножители входят в наш характеристический многочлен тогда мы это
равенство будем переписывать немножко в другом виде ну тогда лямбда будет нумероваться по-другому
вот и так вот в этом предположении мы как раз приведем матрицу нашего оператора
ну к самому видимо лучшему из возможных видов я тут сразу сделаю замечание что существуют
методы работы с оператором и в том случае когда такого разложения нет то есть когда у
характеристического многочлена есть неприводимые сомножители больших степеней мы их касаться не
будем но может быть в конце я пару слов скажу о том что делать в этих случаях но сейчас я просто
скажу что если это не так то методы тоже есть интересующиеся особенно вот после того как мы
разберемся с нашим случаем приглашаются например узнать что такое фробениусова нормальная форма
еще раз я о ней рассказывать не буду не буду но желающие могут это выяснить и так
давайте двигаться в эту сторону первым делом давайте я сразу напомню нам сейчас это будет
нужно я сразу напоминаю важный факт из того что мы с вами когда-то доказывали что под пространство
у инвариантно относительно фи относительно оператора фи тогда и только тогда когда оно
инвариантно относительно фи минус лямбда и лямбда это произвольный скаляр вот такой факт у нас
есть мы им сейчас будем пользоваться и значит наша первая цель это привести оператор может быть не
к лучшему виду но к тому виду который уже позволит нам что-то про него понять и этот вид это
просто верхнетреугольный мы сейчас выясним что у любого оператора с вот таким вот условием
существует базис в котором его матрица верхнетреугольная для этого нам потребуется
следующая небольшая лимма и так пусть у нас фи линейный оператор на пространстве в и пусть
у фи существует хотя бы одно собственное значение мы ослабляем вот это вот требование пока что до
такого у фи есть хотя бы одно собственное значение тогда если мы как обычно положим размерность
в равной n то у фи существует инвариантное подпространство у размерности n минус 1
или как говорят ко размерности 1 размерности всего на единичку меньше чем размерность в
доказательства
ну пусть лямбда это собственное значение какое-то собственное значение фи нам говорят что оно есть
тогда достаточно вот по этому предыдущему факту который я напомнил найти инвариантное
подпространство у оператора фи минус лямбда оно автоматически будет и инвариантным для фи
но что означает что лямбда это собственное значение это означает что фи минус лямбда давайте его
в скобках в скобке возьму вы рожденный оператор то есть необратимый правильно у него не нулевое
ядро а значит у него образ это не все пространство в то есть образ фи минус лямбда
это не в иначе бы ядро у него было нулевым ну и размерность этого образа соответственно не
превышает n минус 1 ну тогда нам достаточно взять любое подпространство которое содержит этот
образ взяв n минус одномерное подпространство у которое содержит этот образ если размерность
подпространства не больше чем n минус 1 то понятно и дело что его можно расширить до n минус одномерного
мы можем взять такое подпространство мы получим требуемое я напоминаю что мы также доказывали что
любое подпространство содержащие образ оператора инвариантно относительно него просто потому что
фи от у содержится вот здесь фи минус лямбда от у извините содержится вот здесь вот значит это
подпространство инвариантно относительно фи минус лямбда ну а таким образом оно инвариантно и
относительно фи тоже вот мы нашу лемму уже и доказали так это лемма теперь позволит нам
доказать следующую теорему пусть фи это линейный оператор на в и вот теперь уже
выполняется наше требование то есть его характеристический многочлен линейно факторизуем
тогда ну вот давайте я сформулирую это пока что в таком виде существует базис
я е 1 т далее е н в такой что для каждого к от одного до n подпространство порожденное
первыми к векторами этого базиса инвариантно относительно фи то есть е 1 порождает
инвариантное подпространство е 1 е 2 порождает инвариантное подпространство и так далее
доказательства давайте вести индукции по размерности нашего пространства она
естественно обозначается через n а уже это делает в условии теоремы правильно
наверное при n равном единице
что происходит при н равном единице нам нужно выбрать базис состоящие из вектора
е 1 такое что подпространство порожденное е 1 инвариантно но это все пространство правильно
оно конечно же инвариантно так что тут доказывать нечего любой базис годится
пусть теперь n больше единицы давайте доказывать переход база у нас уже есть
ну поскольку характеристический многочлен линейно факторизуем у него есть хотя бы один корень и
значит у фи есть собственное значение правильно так как характеристический многочлен линейно факторизуем
у фи есть собственное значение ну а значит по нашей лемме у него есть инвариантная подпространство
у размерности n минус 1 а значит
мы можем рассмотреть ограничение нашего фи на это инвариантное подпространство на то оно и
можно рассмотреть фи это фи ограниченный на у это будет линейное преобразование под пространство у
все очень хочется применить предположение индукции для этого нам нужно чтобы его характеристический
многочлен был линейно факторизуем правильно но мы с вами знаем что характеристический
многочлен ограничение на инвариантное подпространство вот этого самого фи в данном
случае делит характеристический многочлен всего оператора и поскольку это так и характеристический
многочлен фи раскладывается на линейные совмножители все его делители тоже раскладываются все его
делители это в точности произведение некоторых этих скобок ну на еще какую-нибудь константу
правильно значит поскольку он делит то характеристический многочлен
psi также линейно факторизуем и значит все можно применить предположение индукции
применяя предположение индукции найдем в у
базис е1 и так далее я н-1 такой что он удовлетворяет всем вот этим вот требованиям давайте посмотрим для
каких к е1 и так далее и к т инвариантно относительно си ну а раз относительно
си то и относительно фи тоже правильно потому что си и фи действует на у одинаково и относительно
фи при к от одного до n-1 при всех этих к мы это уже знаем но нам осталось дополнить
этого базиса дополнить этот базис до базиса всего пространства у нас есть n-1 вектор образующий
линией независимую систему его нужно дополнить еще одним вектором до базиса правильно дополняя
его до базиса уже е1 и так далее и н в в мы уже получаем требуемое все нетривиальные префиксы
порождают нашего базиса порождают инвариантные подпространства по тому самому предположении
индукции нам осталось проверить что весь он порождает инвариантное пространство это очевидно
потому что он порождает все пространство в ну и значит наш теорема уже доказано на первый взгляд
давайте сразу заметим на первый взгляд мы пользовались чем-то гораздо более
слабым чем линейной факторизуемостью правильно мы пользовались только существованием собственного
значения на самом деле это не так потому что у нас линейная факторизуемость тянулась по индукции
на подпространство правильно и нам нужно было вот у этого psi находить тоже собственное значение у
того оператора который получится после этого находить собственное значение и так далее правильно
сейчас мы на самом деле увидим что это линейная факторизуемость равносильно тому что такой базис
существует а именно мы это сразу увидим вот из какого следствия
пусть phi удовлетворяет тем же самым условиям характеристический многочлен линейно факторизуем
тогда существует базис и 1 и так далее я н в пространстве в давайте его тоже через я обозначим
такой что матрица phi в этом базисе
верхне треугольная
ну на самом деле просто вот тот самый базис который мы получили и подойдет
давайте мы это выясним вот в этом самом базисе у фи пусть есть какая-то матрица а
давайте взглянем плотнее на эту матрицу нам сказали что у нас есть куча инвариантных
пространств а каждый инвариантное пространство порожденное префиксом нашего базиса говорит
то что в соответствующей матрице есть угол 0 какие углы нулей у нас получились и 1 порождает
инвариантное пространство это значит что у нас получился угол нулей размера 1 на n минус 1
и и 1 и 2 порождают инвариантное подпространство это означает что у нас получился угол нулей 2 на
n-2, то есть в следующем столце n-2 нижних элементов нуля, правильно?
e1, e2, e3 даст нам n-3 нуля в следующем столце и так далее.
То есть как раз все элементы под главной диагональю у нас в нашем базе оказываются нулями.
Собственно говоря, давайте мы это оформим в виде замечания.
Теорема и следствие говорят об одном и том же.
Если у оператора в каком-то базисе матрица верхнетреугольная,
это как раз говорит о том, что все вот эти вот углы нулей, которые мы нарисовали в этой матрице есть, правильно?
А это означает, что все те подпространства, которые у нас выписаны в теореме, действительно будут инвариантными.
Поэтому базис удовлетворяет теореме ровно тогда, когда базис удовлетворяет к следствию.
Базис e удовлетворяет теореме, утверждению теоремы.
То есть все эти подпространства, порожденные префиксами базиса, инвариантны тогда и только тогда,
когда матрица phi в базисе e верхнетреугольна.
И давайте мы сразу посмотрим, что у нас в этом случае еще произойдет.
В этом случае давайте мы еще раз посмотрим на эту самую матрицу.
У нее под диагональю стоят нули, а элементы диагонали давайте мы на минутку обозначим через лямбда 1, лямбда 2 и так далее, лямбда n.
Над диагональю стоят все что угодно. Мы знаем только что под диагональю нули.
А какой же у нас будет в таком случае характеристический многочлен нашего phi?
Это то же самое, что характеристический многочлен матрицы A.
Ну и действительно, когда мы будем из A вычитать xe, мы будем брать определитель вот такой вот матрицы.
Сверху стоит все что угодно, а снизу ноль. Эта матрица осталась верхнетреугольной,
и поэтому ее определитель это просто-напросто произведение ее диагональных элементов.
Это произведение phi от 1 до n, лямбда итой минус x. То есть он оказался линейно факторизуем.
И все это значит на самом деле, что наша теорема может быть сформулирована даже в терминах равносильности.
Так что характеристический многочлен линейно факторизуем тогда и только тогда, когда существует вот такой вот базис.
Ну и значит тогда и только тогда когда у оператора существует верхнетреугольная матрица в каком-то базисе.
Потому что мы доказали, что если она верхнетреугольная, то тогда и Хар многочлен линейно факторизуем.
Давайте мы это тоже для себя отметим.
Итого, характеристический многочлен линейно факторизуем тогда и только тогда,
когда существует базис из теоремы, тогда и только тогда, когда матрица фи в некотором базисе в верхней треугольнице.
Ну и последнее замечание на эту тему мы с вами из вот этой же формулы непосредственно видим, что тогда элементы на диагонали этой матрицы это в точности собственные значения.
Причем встречаются они в каких количествах?
Альгебраическая кратность. Сколько раз какая-то лямба встретится на этой диагонали, столько со множителей лямбда минус х у нас будет в характеристическом многочлене.
И в этом случае на диагонали вот этой вот самой матрицы стоят собственные значения с их алгебраическими кратностями.
Сколько? Какова алгебраическая кратность собственного значения? Столько раз оно на диагонали и встречается.
Это мы с вами уже получили.
Так, ну и прежде чем двигаться дальше давайте я сразу еще одно полезное для практических применений порой следствие сформулирую.
Пусть Фи ровно такой же как и раньше, то есть характеристический многочлен его линейно факторизуем.
Пусть лямбда 1 и так далее, лямбда n это его собственные значения взятые с алгебраическими кратностями.
Ну и пусть А это матрица Фи в совершенно произвольном базе.
Базис Е произвольный, а не тот, который в теореме.
Тогда сумма всех этих собственных значений есть след нашей матрицы, а произведение всех собственных значений это определитель нашей матрицы.
Ну и для доказательства достаточно заметить, что след матрицы оператора не зависит от того в каком базисе мы будем ее записывать.
След матрицы А и определитель матрицы А аналогично не зависят от выбора базиса.
Ну а значит можно считать, что Е это базис из теоремы.
От того, что мы записали Фи в другом базисе ни след, ни определитель не изменились.
Ну а в этом случае утверждение очевидно. След этой матрицы это сумма лямб, определитель этой матрицы это произведение лямб.
В этом случае утверждение непосредственно вытекает из вида А.
Ну вот мы с вами привели уже матрицу оператора хоть какому-то более-менее приличному виду к треугольному.
В том случае, если характеристический многочлен линейно факторизуем.
И это нам уже позволяет доказать следующую важную теорему.
Эта теорема именная, она называется теоремой Гамильтона Келли.
По-английски они стоят наоборот, потому что Келли начинается с С.
Давайте я сформулирую ее в максимальной общности. Докажу потом, правда, не совсем в максимальной, но я сделаю некоторые замечания.
В быстрое время мы дойдем и до максимальной тоже.
Итак, теорема формулируется на удивление просто.
Пусть Фи это линейный оператор на пространстве В.
Если мы возьмем его характеристический многочлен и подставим в него Фи, то получится ноль.
Но когда я многочлен подставляю оператор, то получается тоже оператор, правильно, естественно.
И вот нам говорят, что получается оператор нуль любой.
Давайте мы сразу в качестве замечания сделаем эквивалентную переформулировку.
Если у нас есть квадратная матрица над полем, то характеристический многочлен от этой матрицы.
Если в него подставить матрицу саму, то получится ноль, в смысле, естественно, нулевая матрица N.
Разумеется, эти две формулировки эквивалентны, но если мы у Фи возьмем произвольную его матрицу, то мы непосредственно получим вот это вот утверждение.
Ну а если для матрицы мы возьмем любой оператор, матрицы которого она является, то мы вернемся обратно.
Вот такое вот утверждение.
Итак, как я и сказал, возникло некоторое оживление. Если что-то непонятно, то я могу прокомментировать.
Пока что все понятно.
Мы пока что доказываем это утверждение в случае, когда характеристический многочлен линейно факторизуем.
Давайте мы воспользуемся нашей предыдущей теоремой и найдем вот тот самый базис матрицы Фи, в котором верхняя треугольная.
То есть мы найдем базис Е1 и так далее ЕН такой, что Фи имеет в этом базисе верхнюю треугольную матрицу.
Ну и давайте мы сразу обозначим элементы на ее диагонали, лямбда 1, лямбда 2 и так далее, лямбда N.
Вот именно в том порядке, в котором они тут стоят. Нам совершенно не важно, в каком порядке они стоят.
И давайте мы обозначим все те подпространства, про которые мы уже знаем, что они инвариантны, через ВИТ.
То есть пусть ВИТ, это вот то самое подпространство, порожденное первыми И-базисными векторами нашего базиса, мы с вами знаем, что оно инвариантно относительно Фи.
Ну и теперь осталось для того, чтобы нам доказать теорему Гамильта на Кэле, нам почти что осталось доказать вот какое вспомогательное утверждение.
Если я применю подпространство ВИТ, оператор Фи минус лямбда ИТ, лямбда ИТ это ровно вот элемент на ИТ месте, соответствующий ЕИТ, то у меня получится подпространство уже ВИ-1.
Давайте докажем сначала утверждение, а потом из него уже очень быстро выведется наш теорем.
Итак, доказательство утверждения. Для этого давайте мы посмотрим, что такое ВИТ.
ВИТ порождено первыми И-базисными векторами, первые И минус один из них порождают ВИ-1.
Поэтому я могу сказать, что ВИТ порождено ВИ-1 и ЕИТ.
Однако, давайте посмотрим, как действует Фи на оба вот этих вот компонента.
Даже не Фи, а Фи минус лямбда ИТ.
Давайте я даже не буду этого писать. ВИ-1 мы с вами знаем, что инвариантно относительно Фи,
и значит относительно Фи минус лямбда ИТ оно тоже инвариантно.
То есть Фи минус лямбда И от ВИ-1 содержится ВИ-1.
Осталось посмотреть на то, что делает Фи с ЕИТ.
А что делает Фи с ЕИТ?
Вот у нас Фи от ЕИТ, координаты этого вектора, стоят в этом столце нашей матрицы.
И там сначала стоит непонятно что, на ИТ месте стоит лямбда ИТ, а дальше стоят нули.
То есть это означает, что Фи от ЕИТ это лямбда ИТ на ЕИТ.
Лямбда ИТ соответствует как раз вот этому слагаемому плюс какой-то вектор.
Линейная комбинация первых и минус одного вектора базиса, правильно?
ВИТ содержится ВИ-1.
Это линейная комбинация первых и минус одного вектора.
Значит, как действует Фи минус лямбда ИТ на ЕИТ?
Этого нужно лямбда ИТ и ЕИТ перенести в левую часть.
Мы получаем, что это просто-напросто ВИТ, то есть он содержится в ВИ-1.
И того, что мы получили? Фи от ВИ-1 содержится в ВИ-1.
Точнее Фи минус лямбда ИТ от ВИ-1 содержится в ВИ-1.
Фи минус лямбда ИТ от ЕИТ также содержится в ВИ-1.
Значит, Фи от линейной оболочки тоже содержится в ВИ-1.
Значит, Фи от линейной оболочки в ВИ-1 содержится в ВИ-1.
Ваше утверждение доказано.
Давайте мы сделаем перерыв на осознании, а потом завершим доказательство теории Мэгамельта на Келли.
Перерыв 5 минут.
Давайте продолжим.
Сейчас, может быть, я прокомментирую что-то по этому.
После того, как мы закончим доказательство.
Мне тут сообщили, что я допустил описку. Здесь, конечно, не Фи от ВИ-1, а Фи минус лямбда ИТ от ВИ-1.
Пожалуйста, исправьте, если вы не то переписали. Спасибо.
Так, давайте доказывать теперь теорему.
Она уже докажется более-менее автоматическим.
Итак, вернемся к теореме.
Что нам нужно?
Нам нужно понять, что если мы в характеристический многочлен Фи подставим Фи, то получится нулевой многочлен.
Что означает, что это нулевой многочлен?
То, что у него образ нулевой, правильно?
Если мы его применим ко всему В, то мы должны получить нулевое подпространство.
Давайте посмотрим, что это такое.
Что нам тут написали?
Нам тут написали характеристический многочлен, раскладываясь на линейные сомножители.
И мы эти линейные сомножители знаем, поскольку мы знаем элементы на диагонали.
То здесь у нас написано произведение.
По И от 1 до N, лямбда ИТ минус Фи.
И все это произведение мы применяем к В.
Здесь давайте я на всякий случай прокомментирую.
В принципе, мы написали произведение линейных операторов, правильно?
Каждый лямбда ИТ минус Фи – это какой-то линейный оператор.
И если мы пишем произведение нескольких операторов, то обычно принято указывать порядок, в котором мы их применяем.
Потому что результат может довести от этого порядка.
Но на самом деле все эти скобки – это многочлены от одного и того же оператора Фи.
А в таком случае они все друг с другом коммутируют.
И значит, это произведение неважно в каком порядке записывать.
Но мы его будем трактовать именно в порядке по И от 1 до N.
То есть первый сомножитель – это лямбда 1 минус Фи, второй лямбда 2 минус Фи и так далее.
Давайте я даже вот это вот так напишу.
Лямбда 1 минус Фи и так далее. Лямбда N минус Фи от В.
А точнее давайте я сразу скажу, что если я в каждом сомножителе изменю знак, умножу его на минус единицу, то естественно ничего не поменяется.
То есть оператор может быть сменит знак, но его образ на пространстве останется тем же самым под пространством, естественно.
Поэтому давайте уж я напишу, что здесь у меня написано Фи минус лямбда 1 и так далее на Фи минус лямбда N.
И все это примененное к В.
А В – это ВН. Линейная оболочка всех векторов базис.
Ну а теперь давайте пользоваться утверждением.
В конце у нас стоит Фи минус лямбда N от ВН.
Мы с вами знаем по утверждению, что это дело содержится в ВН минус 1.
Значит у нас уже написано Фи минус лямбда 1 и так далее Фи минус лямбда N минус 1, примененное к ВН минус 1.
Но вот это вот по тому же самому утверждению содержится уже в ВН минус 2.
И дальше мы можем таким же образом продолжать.
Пока мы наконец не дойдем до Фи минус лямбда 1 от В1.
Ну, формально мы можем сказать, что В0 к В это линейная оболочка нуля векторов, то есть нулевое подпространство.
Тогда вот это утверждение останется верным и доказательство его дословно останется верным.
То есть вот это вот дело по тому же самому утверждению содержится в В0, которое ноль.
Вот мы все и доказали. Мы доказали, что образ вот этого вот многочлена Хи Фи от Фи, образ этого оператора, это нулевое подпространство.
Ну, потому что он содержится в нулевом подпространстве, правильно?
Значит, этот оператор нулевой и наша теорема уже доказана.
Так, здесь хочется первым делом спросить, а надо ли было такое городгородить?
Неужели же такой простой факт не докажется гораздо короче?
Вот, например, пишу короче.
Хотим мы доказать, что характеристический многочлен матрицы А от А это ноль.
Но мы же с вами знаем, что характеристический многочлен матрицы А от Х это определитель А-ХЕ, правильно?
Ну и значит, если мы сюда вместо Ха подставим А,
что мы делали все это время?
Мы доказывали теорему Гамильта Накэлья, а это, к сожалению, не доказательство.
Обратите, пожалуйста, внимание, вот такие подобные формулы стоит писать с осторожностью.
В частности, здесь, естественно, написана в некотором смысле полная чушь.
Потому что давайте мы все-таки вспомним, что же у нас такое на самом деле характеристический многочлен.
Я это пока зачеркиваю, я сейчас объясню, почему так действовать нельзя.
Что ж такое характеристический многочлен от Х?
Это мы взяли нашу матрицу, из диагональных элементов вышли Х, остальные элементы оставили на месте,
и после этого взяли отсюда определитель, правильно?
И что нам здесь предлагают? Вот сюда вот подставить матрицу А?
Это не очень разумное действие, правильно?
Потому что сейчас нам приходится вот из скаляра, из А1, вычитать вот эту самую матрицу А.
И матрицу А сюда непосредственно не подставить.
Так что вот это вот рассуждение неверно.
Ну и косвенным свидетельством того, что подобная вещь не может быть верной,
сложит вот что. Если бы такие рассуждения можно было вести,
то мы бы доказали, что ХА не только на А обращается в ноль,
а на любой матрице В такое, что А-В вырожденное, правильно?
Это естественно неправда.
Что? Ещё раз, ну хотя бы правило 13-го удара, это позволяет доказать слишком много.
То есть вот если бы это было так, то для любых двух матриц таких, что их разность вырожденная,
следовало бы, что характеристически многошлен А от В равен нулю, правильно?
Это не может быть так. Мы через некоторое время это ещё лучше осознаем, почему это не может быть так.
Итак, вот это вот тоже сугубо неверное рассуждение.
Ну и вот этот вот тот частный случай, который здесь был, то естественно тоже неверен.
Так что вот на самом деле теорема Гамельта-накелли нуждается в нетривиальном доказательстве.
Ну и в некотором смысле это теперь, может быть, стало чуть более понятно, что это какой-то удивительный факт, правильно?
Вот мы взяли матрицу, взяли какой-то вот её характеристический многочлен.
В этот многочлен, как вот уже многочлен, подставили матрицу и удивительным образом получили ноль.
Вот это то, что нам говорят Гамельта-накелли на самом деле.
Вот что многочлен, который получился после раскрытия нашего определителя.
И теорему эту мы с вами доказали, но доказали мы её пока что, давайте я, как я обещал, прокомментирую.
Доказали мы её в случае, когда характеристический многочлен линейно факторизуем.
Давайте я прокомментирую, как можно было бы это доказать и в общем случае тоже.
Давайте доказывать, мы знаем уже, что утверждения для оператора и для матрицы эквивалентны.
Поэтому, чтобы доказать теорему Гамельта-накелли для матрицы А над каким-то полем F,
нам достаточно найти такое надполе K поля F, что характеристически многочлен матрицы А
линейно факторизуем уже над полем K.
Это характеристический многочлен над полем F, его коэффициенты лежат в поле F.
Если мы найдём такое большее поле K, то тогда мы сможем разложить такой, что вот этот многочлен, рассматриваемый как многочлен над полем K,
уже линейно факторизуем, то есть раскладывается на множители, у которых коэффициенты лежат уже в этом K, то мы победим.
Почему? Ну потому что в этом случае характеристический многочлен этой матрицы одинаков над K и над F.
Мы всё равно будем вычислять вот этот вот самый определитель, какой-то многочлен над полем F. Над полем K он будет вычисляться ровно тем же самым.
Ну и потому теорема Гамильтона Келли утверждает одно и то же для матрицы А как матрицы над F и для матрицы А как матрицы над K.
У нас будет один и тот же многочлен, мы в него будем подставлять одну и ту же матрицу, одно и то же вычисление нам должно дать один и тот же результат.
Но для этой матрицы мы его уже доказали. У оператора с такой матрицей уже над полем K характеристический многочлен линейно факторизуем, и значит наше доказательство пройдёт.
Таким образом мы видим, что для сведения общего случая к этому частному нам достаточно уметь находить вот такое вот над полем.
Это стандартный алгебраический факт. Прямо сейчас я его доказывать не буду, но надеюсь через некоторое время мы его таки докажем.
В любом случае по модулю этого факта мы уже понимаем, что теорема Гамильтона Келли верна всегда.
Так, а мы с вами двигаемся дальше. Наша цель-то привести ещё к более лучшему видео.
И для этого нам будет очень полезно исследовать, а какие же многочлены вообще обнуляют наш оператор.
Такие многочлены называются аннулирующими.
И следующий вопрос мы хотим разобраться с ними.
Итак, определение. Пусть Фи это линейный оператор на пространстве В. В естественно пространство над полем Ф.
И пусть П это какой-то многочлен над этим самым полем.
Тогда многочлен П называется аннулирующим для оператора Фи, если он его аннулирует.
То есть если П от Фи равно 0.
Таким образом теорема Гамильтона Келли говорит нам, что характеристический многочлен оператора является для него аннулирующим.
Таким образом характеристический многочлен Фи аннулирующий для Фи.
Давайте мы сразу сделаем для ясности короткое замечание.
Естественно, если П и Q это два аннулирующих многочлена для какого-то Фи, то и П плюс минус Q тоже будет аннулирующим.
Если П это аннулирующий многочлен, а Р это просто многочлен, то и П и Q тоже будет аннулирующим.
И ПР также аннулирующий.
Потому что ПР от Фи это не что иное, как П от Фи на Р от Фи.
Если мы этот многочлен, этот оператор применим ко всему пространству В, то сначала мы к нему применим Р от Фи, а потом применим нулевой оператор. Естественно будет 0.
То есть это равно 0.
На самом деле, говоря математическим языком, я не буду давать соответствующее определение, но то, что я сейчас сказал, означает в точностях, что аннулирующие для конкретного оператора Фи многочлены
образуют идеал в кольце всех многочленов.
Идеал это как раз означает, что наше множество аннулирующих многочленов замкнуто относительно сложения и вычитания, а также замкнуто относительно умножения не на аннулирующий, а на произвольный многочлен, на произвольный элемент нашего кольца.
Ну и давайте мы в этом конкретном случае разберемся, как устроен этот идеал, хотя в принципе это часть более общей.
Это можно было бы сказать и на более общем языке, но давайте мы разберемся в данном конкретном случае пока что.
Итак, определение следующее. На самом деле среди аннулирующих многочленов для данного оператора Фи есть один выделенный, которым они все задаются, и этот многочлен называется минимальным.
Итак, пусть Фи это линейный оператор на В, тогда его минимальный многочлен обычно обозначается через мю Фи.
Это не нулевой многочлен, аннулирующий Фи наименьшей возможной степени.
То есть мы берем все многочлены, которые аннулируют Фи, не нулевые, и среди них выбираем многочлен самой маленькой степени.
Он называется минимальным многочленом Фи.
Здесь можно задать вопрос, существуют ли эти аннулирующие многочлены? Если верить в теорему Гамильтона Келли в общем случае, то конечно они существуют, но даже если в теорему Гамильтона Келли не верить, то все равно нетрудно понять, что аннулирующие многочлены существуют.
Просто потому, что пространство линейных операторов на В конечномерно, оно имеет размерность N квадрат.
И значит, если мы возьмем все, если мы возьмем в степени Фи в количестве больше, чем N квадрат, то они будут линейно зависимы.
То есть между ними будет какая-то линейная зависимость, которая и даст нам этот самый аннулирующий многочлен.
Так что то, что аннулирующие вообще существуют, для этого не требуется большая теория типа теоремы Гамильтона Келли.
Это следует просто возле соображений конечности размерности.
Так, давайте двигаться дальше, все-таки уже в предположении, что мы знаем теорему Гамильтона Келли.
Итак, давайте выясним какие это свойства минимального многочлена.
Сейчас я, наверное, проконсультируюсь своими записями, чтобы начать с простых, а не со сложных.
Итак, первое утверждение.
Пусть Фи – это линейный оператор на В,
миу Фи – это его минимальный многочлен,
а П – это просто какой-то аннулирующий многочлен.
Тогда миу Фи делит П.
То есть на самом деле минимальный многочлен делит все аннулирующие многочлены.
Для доказательства давайте мы просто-напросто разделим П на миу с остатком.
То есть мы запишем П – это Q на миу Фи плюс R,
где степень R меньше, чем степень миу Фи.
Ну а теперь давайте в это равенство подставим наш оператор Фи.
Я напоминаю, мы уже несколько раз вспоминали, что если у нас есть такое равенство в кольце многочленов,
после подстановки произбольного элемента алгебры над F тоже получается верное равенство.
А что у нас тут получится?
П от Фи – это Q от Фи на миу от Фи плюс R от Фи.
Здесь у нас написано 0, потому что П – аннулирующий многочлен.
Этот весь, это все слагаемое тоже равно 0, потому что миу минимальный, а значит аннулирующий.
Но таким образом R от Фи – это 0, и R тоже аннулирующий.
Как это может быть? R – аннулирующий многочлен, степень которого меньше, чем степень минимального.
Он должен быть нулем, правильно? Если он не нулевой, это означает, что это противоречит просто-напросто определению минимального многочлена.
Единственная возможность для многочлена R в такой вот маленькой степени – это то, что R – нулевой многочлен.
Ну а это и означает, что миу Фи делит многочлен П.
Наше утверждение доказано.
Как непозжественное следствие, мы получаем, что минимальный многочлен оператора делит его характеристическим многочленом.
Потому что по теореме Гамильтона-Келли характеристический многочлен обнуляет Фи, то есть является аннулирующим.
Ну и значит для минимального многочлена остается уже не так много вариантов, правильно?
Это следствие первое.
Давайте на всякий случай скажем еще следствие второе.
Мы вот определили минимальный многочлен, но вдруг-то он такой не один, правильно? Правда ли, что он такой единственный?
Абсолютно верно, с точностью до ассоциированности.
Естественно, если мы его умножим на не нулевую константу, то тоже получится аннулирующий многочлен той же самой степени, правда?
Но это единственная возможность, то есть минимальный многочлен оператора Фи определен однозначно с точностью до ассоциированности.
То есть все минимальные многочлены Фи получаются из одного просто умножения на константу.
Ну просто потому что если μ1 и μ2 это два минимальных многочлена, то мы с вами только что получили, что μ1 делит μ2, а μ2 делит μ1, поскольку они оба аннулирующие, правильно?
Два многочлена, делящие друг друга, это в точности два ассоциированных многочлена, что и завершает доказательство.
Еще одно утверждение, прежде чем мы двигаемся дальше, еще одно утверждение чисто про минимальный многочлен.
Мы с вами знаем, что минимальный многочлен делит характеристический, на самом деле в некотором смысле минимальный из характеристического должен взять не так мало.
А именно, давайте еще одно утверждение докажем, пусть λ это собственное значение оператора Фи, тогда λ является корнем минимального многочлена.
То есть, во всяком случае, если в характеристическом многочлене есть делитель вида λ на минус х, то такой же делитель будет и у минимального тоже, но, возможно, степень вхождения этого делителя будет уже меньше, как мы вскоре увидим, это действительно будет происходить.
Доказательства. Ну, коль скоро у нас есть собственное значение, то для него есть и собственный вектор. Давайте мы его рассмотрим. Пусть В это собственный вектор, соответствующий собственному значению лямда. То есть, Фи от В это лямда на В.
Вот сейчас давайте мы обозначим коэффициенты нашего минимального многочлена, они нам потребуются. Пусть μФи выглядит так. Это Акт хк, плюс и так далее, плюс а0.
Тогда давайте посмотрим, как вот этот самый μФи с подставленным Фи действует на наш вектор В.
МюФи от Фи. Если мы этот оператор применим к вектору В, то что получится? Ну, простой ответ, конечно, получится ноль, потому что мюФи аннулирующий, правильно? Ну, любой оператор он всех переводит в ноль.
Но что это конкретно значит? Это означает, что мы многочлен с подставленным Фи, Акт и Фихк, плюс и так далее, плюс давайте я так допишу, А1Фи, плюс а0кв, применяем к вектору В.
Ну а что это означает? Что у нас тут такое происходит? Давайте я с конца начну. А0кв применяем к В, получаем, естественно, а0кв на В.
А1Фи применяем к В, получаем А1λв, правильно? Давайте я, может быть, еще один член выпишу. Когда мы применяем А2фкв, что получится? А2λкв на В, правильно?
Первые Фи применили, получили λв, применяем Фи второй раз, естественно, получаем λв, ну и все это еще должно умножиться на А2. Ну, значит, здесь будет Актλв, правильно?
Вот чему это все равно. Что же это такое? Это В, умноженное на какую-то константу, а конкретно эта константа, это μ от λ, правильно?
Умножить на В. Все эти коэффициенты собираются в точности в μФи от лямбда. Ну что ж, значит, если эта константа умножается на В, то получается ноль, а сам В, как собственный вектор по определению, не нулевой.
Это как раз и означает, что константа, на которую мы домножаем, нулевая. И на этом наше утверждение доказан.
Я сразу обращаю внимание, что, в принципе, вот все, что мы сейчас доказывали для аннулирующих многочленов, давайте я это даже отмечу,
вся теория про аннулирующие многочлены, которая была до сих пор и еще некоторое время позже,
до сих пор пока что написана, не требует линейной факторизуемости характеристического многочлена. То есть нам требуется только теория Магамельта Накэли, а в нее мы пока что верим.
Так что все эти соображения работают не только, когда хи линейно факторизуем, а и в произвольном случае.
Так, замечательно, про аннулирующие многочлены и про минимальный многочлен мы с вами поговорили. Давайте выясним, зачем они нужны.
Вот, наверное, одна из главных свойств, которая нам сейчас очень поможет, это следующая полезная теорема.
По сути дела она нам сейчас скажет, что если минимальный многочлен хорошо раскладывается на множители, то мы можем и пространство разложить в прямую сумму нескольких хороших инвариантных подпространств.
Так, я прошу прощения, давайте теорему я сейчас сформулирую, а перед этим я забыл дать упражнение.
Упражнение такое, мы с вами доказали, что если у нас лямбда собственное значение оператора phi, то лямбда это корень минимального многочлена.
По сути дела мы сказали следующее, что если многочлен лямбда минус х делит характеристический многочлен, то он же делит и минимальный многочлен.
И вот на самом деле этот факт верен в более общие постановки, а именно если многочлен п это неприводимый, это важно, делитель характеристического многочлена, то он же делит и минимальный.
Желающие могут попытаться это доказать, такой более общий факт тоже верен.
Итак, это упражнение к предыдущему вопросу, а сейчас вот важная теорема, которая нам скоро очень сильно поможет.
Итак, пусть как обычно phi, это линейный оператор на пространстве V, пусть у него есть некоторый аннулирующий многочлен,
причем P раскладывается в произведении двух других многочленов, P1 и P2 тоже естественно из f от x, и эти многочлены взаимно просты.
Это немедленно отражается на нашем пространстве следующим образом.
Тогда все пространство V есть прямая сумма, ядра P1 от phi и ядра P2 от phi.
Докажем мы теорему после перерыва, а пока я хочу сделать небольшое замечание.
Обратите внимание, эти ядра чем хороши? Они в частности хороши тем, что они инвариантное подпространство относительно phi, правильно?
Мы с вами уже говорили, что ядро и образ любого многочлена от phi инвариантно относительно него.
В таком случае мы немедленно раскладываем V в прямую сумму двух инвариантных подпространств и можем работать на каждом из них по отдельности.
Ядра P1 от phi, это они инвариантны относительно phi. Я пишу замечание, а на самом деле, конечно, напоминание.
Давайте мы сейчас сделаем перерыв, а после перерыва эту теорему докажем.
Давайте двигаться дальше.
Пока что я еще раз обращаю внимание, вот это общее утверждение, которое работает в любой ситуации, нам по-прежнему линейная факторизуемость не нужна.
Когда линейная факторизуемость будет нужна, я об этом сообщу. Это будет сразу после того, как мы обсудим вещи, связанные с этой теоремой.
Давайте сначала теорему докажем. Тут происходит некоторое волшебство, доказательство достаточно короткое, но вот, видимо, на него стоит посмотреть и в нем разобраться, чтобы понять, как оно работает.
Давайте мы его докажем. Перед тем, как мы его докажем, давайте мы сразу сделаем небольшое замечание, чтобы было понятно, что мы тут делаем, потому что сейчас мы подобными вещами будем пользоваться достаточно часто.
Если p и q это два многочлена над полем, phi это какой-то линейный оператор, хотя тут гораздо более общее утверждение, то операторы p от phi и q от phi коммутируют.
Неважно в каком порядке их применять, все равно получится одно и то же, потому что перемножая их в произвольном порядке, мы получим многочлен pq, в который мы подставили оператора phi.
Доказательство, в котором происходит некоторое волшебство, устроено так.
Давайте мы обозначим вот эти вот ядра, которые у нас тут есть, через v1 и v2. Пусть v1 это ядро p1 от phi, v2 это ядро p2 от phi.
Прежде чем двигаться дальше, давайте мы заметим сразу, что если мы возьмем образ p2 от phi, то он будет содержаться в v1.
Почему это так? Потому что мы с вами знаем, что если мы перемножим p1 от phi на p2 от phi, то мы получим p от phi, то есть ноль.
А это означает, что если мы применим p1 от phi к любому вектору вот такого вот вида, p2 от phi, примененное q, то мы получим нулевой вектор.
Ну то есть любой вектор вида p2 от phi, примененный q, лежит в ядре p1 от phi, то есть v1.
Ну и аналогично, естественно, образ p1 от phi содержится в v2.
А теперь главный крюк, который мы сейчас применим, заключается в следующем. Нам дано, что p1 и p2 это взаимно простые многочлены.
А это означает, что мы можем воспользоваться линейным представлением этого самого нот.
Из линейного представления нот мы получаем, что единица это p1 умножить на какой-то многочлен u1, плюс p2 умножить на какой-то многочлен u2.
Где u1 и u2, это тоже естественно многочлен над f.
Если мы сейчас в это многочленное равенство подставим phi, то мы получим что? Слева мы получим по-прежнему единицу, только эта единица уже что такое?
Это тождественный оператор. После того, как мы вот сюда подставляем phi, мы получаем равенство уже в алгебре операторов, и единица естественно воспринимается как тождественный оператор.
П1 от phi, у1 от phi, плюс p2 от phi, у2 от phi. Вот такое вот равенство мы с вами получаем.
Давайте мы вот эти слагаемые обозначим сразу через psi1 и psi2.
Ну и теперь вот в этот оператор единицу, которая psi1 плюс psi2, мы имеем право подставить произвольный вектор.
Любой вектор из В, мы можем подставить вот в это вот равенство и получить, слева у нас тождественный оператор, значит когда мы в него подставляем В, мы В и получаем, а справа у нас получается psi1 от В, плюс psi2 от В.
Давайте смотреть. Что такое psi1 от В?
Это, давайте я даже psi1 от В сразу напишу. Это p1 от phi, примененное q1 от phi от В, правильно?
То есть, это в любом случае элемент образа p1 от phi, который, как мы с вами знаем, под пространство В с другим индексом, ну то есть 3 минус i, правильно?
Что мы получили? Мы получили, что В разложился в сумму вектора из В2 и вектора из В1. Следовательно, наше пространство уже есть сумма В1 и В2.
Осталось нам доказать, что эта сумма прямая, правильно? То, что сумма уже получилась.
А для этого нам достаточно доказать, что пересечение этих подпространств тривиально.
С другой стороны, давайте вот это вот я через звездочку обозначу.
С другой стороны, если какой-то вектор лежит и в В1 и в В2, то мы опять же можем подставить его в звездочку.
И мы получаем слева опять же такие В, а справа давайте я напишу в обратном порядке.
У1 от Фи, П1 от Фи, применённый к В, плюс У2 от Фи, применённый к П2 от Фи, от В.
Ну и наш вектор В содержался в ядре П1 от Фи и содержался в ядре П2 от Фи, правильно?
Значит, вот здесь вот у нас в скобочках уже стоит нулевой вектор, и вот здесь вот у нас в скобочках уже стоит нулевой вектор.
Таким образом, наш вектор В оказался равным нулю.
То есть В1 пересекается с В2 только по нулю, и значит В уже разложилась в прямую сумму В1 и В2.
Теорема доказана.
Давайте мы, прежде чем двигаться дальше, немножко осознаем, что мы на самом деле доказали.
Доказали, что некоторые части можно даже усилить.
Замечание первое.
Что мы с вами сделали?
Мы с вами доказали, что В есть прямая сумма ядра П1 от Фи и ядра П2 от Фи.
Но еще, когда мы доказывали, что каждый вектор раскладывается в сумму элементов оттуда,
на самом деле мы с вами доказали, что каждый вектор раскладывается в сумму вектора из образа П1 от Фи и из образа П2 от Фи, правильно?
То есть все пространство В раскладывается в сумму образа П1 от Фи.
Давайте я так напишу. Образа П2 от Фи и образа П1 от Фи.
Однако, эти товарищи, как вы тоже доказывали, являются подпространствами верхних.
Вот тут прямой суммы у нас в принципе нет. У нас тут просто сумма, извините, пока что, в нижней строчке.
Но эти товарищи являются подпространствами верхних. Когда такое возможно?
Когда они только равны, правильно? Если одно из этих подпространств будет не совпадать с соответствующим ядром,
то тогда просто размерность этой нижней суммы будет уже слишком маленькой, правильно?
И поэтому на самом деле мы с вами поняли, что В1 это не только ядро П1 от Фи, но еще и образ П2 от Фи.
Ну и естественно В2 это ядро П2 от Фи и оно же образ П1 от Фи.
То есть из нашего доказательства непосредственно следует вот такая вот вещь.
Ну потому что именно это мы с вами и доказали. В представился как сумма Пси1 от В плюс Пси2 от В, а они лежат в образах.
Вот у нас вот это и было написано. Произвольный вектор так раскладывается.
Ну и замечание второе. На самом деле, если мы посмотрим на последнюю часть доказательства нашей теоремы,
то мы заодно увидим, что там все, чем мы пользовались, это то, что многочлены П1 и П2 взаимно просты,
никакой ничего связанного с аннуляторами там уже не использовалось.
Поэтому в последней части доказательства, по сути дела, доказана следующая вещь.
Если у нас есть просто два взаимно простых многочлена, то уже ядро П1 от Фи и ядро П2 от Фи пересекаются только по нулю.
Кроме этой взаимной простоты, в последней части доказательства ничего не используется.
Итак, мы немножко посмотрели на то, как работает это доказательство.
Я еще раз рекомендую на него еще раз дома посмотреть и осознать, как оно работает.
А пока что давайте я эту формулу, которая у нас тут ключевая.
А, но впрочем, она у нас вон там вот есть. Поэтому я ее затру.
Естественно, если такая теорема верна для двух сомножителей, то ее можно обобщить и на большее количество.
Как следствие, если у нас есть аннулирующий многочлен оператора Фи на пространстве В,
если он раскладывается на К сомножителей, любые два из которых взаимно просты,
то в такой ситуации наша теорема тоже работает.
То В раскладывается в прямую сумму ядер всех таких вот операторов.
Мы это быстренько докажем. Естественно, индукции ПК.
Ну, при К равном ДУМ это исходная теорема.
Ну, при К равном единице это, в принципе, тоже правда, правильно?
Потому что П-аннулирующий многочлен, П от Фи, это ноль, и его ядро это все пространство.
Пусть теперь К больше двойки.
Тогда что мы с вами знаем? Давайте смотреть. Вот у нас есть многочлен ПКТ, а есть все остальные многочлены.
Он взаимно прост с каждым из них, но это переформулируется, что если мы их разложим на неприводимые сомножители,
то у ПКТ и у остальных не будет общих неприводимых сомножителей, не будет ассоциированных сомножителей.
Ну, а это означает, что ПКТ взаимно прост и с их произведением тоже.
Но вот ПКТ и произведение всех остальных тоже равен единице.
И следовательно, мы можем воспользоваться нашей теоремой и записать, что В есть ядро произведения П1 от Фи и так далее, ПК-1 от Фи,
и плюс ядро ПКТ от Фи.
Давайте мы эти подпространства снова обозначим через В1, давайте так лучше, через У и через ВКТ.
Давайте заметим сразу, что если
И не больше, чем К-1, то ядро ПИТОВО от Фи содержится в У.
Ну, действительно.
Если какой-то вектор лежит в этом ядре, что это означает? Я к нему применяю ПИТОВО от Фи и получаю ноль.
То если я к нему применю весь вот этот вот оператор, то естественно тоже получится ноль.
Мы эти сомножители имеем право переставлять, как нам заблагородсудиться, правильно?
И поэтому, когда мы вот этот вот ужас П1 от Фи и так далее, ПК-1 от Фи, применяем к В, мы можем наш ПИТОВО от Фи вытащить в конец.
Равно какие-то там остальные операторы, примененные к ПИТОМУ от Фи, от В.
Ну, здесь произведение всех остальных сомножителей здесь, естественно, стоит.
Ну, а это означает, что мы применили какие-то линейные операторы к нулю, а значит получили ноль.
То есть ядро ПИТОВО от Фи содержится в У при всех И меньше, чем К.
Ну, а теперь осталось применить предположение индукции, поняв, к чему его применять.
Мы последние слагаемые уже выделили, правильно?
Поэтому нам нужно посмотреть на то, как наш оператор Фи действует на оставшемся подпространстве У.
Ну, как обычно, обозначим через ПСИ ограничение нашего Фи на выдаленное подпространство У.
Тогда давайте смотреть, что у нас получилось.
У – это есть ядро вот такого вот оператора, правильно?
Это означает, как обычно, ПСИ – это линейное преобразование уже подпространства У, правильно?
То, что у – это ядро вот такого оператора, означает, что если я возьму вот это произведение П1 и так далее, ПК минус первое,
и подставлю в него Фи, ПСИ, то я уже получу ноль.
Потому что, когда вот этот оператор действует на любой вектор из У, этот вектор в ядре, правильно?
Поэтому получается ноль, ибо у есть ядро.
П1 от Фи и так далее, ПК минус первого от Фи.
Ну, значит, П1 и так далее, ПК минус первый – это аннулирующий многочлен для ПСИ.
И, значит, У раскладывается в прямую сумму.
Давайте понимать кого. Ядра П1 от Фи, ядра П2 от Фи и так далее, ядра ПК минус первого от Фи.
Это по предположению индукции.
Но, на самом деле, нам осталось одно соображение – это тоже эти ядра ПИ от ПСИ.
Это то же самое, что ядра ПИ от Фи.
Почему это так? Почему эти два ядра равны?
Ну, а что вот это такое на самом деле? Давайте я это все-таки даже запишу.
В чем разница между верхним и нижним ядром?
Ну, а в чем разница между Фи и ПСИ?
Они действуют на разных пространствах. Фи действует на большем пространстве, правильно?
И поэтому в этом ядре, в нижнем, в принципе, могло бы оказаться еще какие-то векторы, не содержащиеся в У, правильно?
Но это не так, потому что мы сразу заметили, что ядро ПИ этого от Фи содержится в У.
То есть, на самом деле, что мы можем сказать?
Давайте вот напишем ИБ, и все-таки вот так можно это описать.
Ядро ПИ этого от ПСИ – это все векторы, которые ПИ это от Фи переводит в ноль, и которые одновременно с этим лежат в У.
Потому что ПСИ действует только на У, а не на все В, правильно?
Ну, а это и есть ядро ПИ этого от Фи, ибо мы с вами знаем, что оно содержится в У.
Ну все. Таким образом, У разложилась в прямую сумму вот этих вот ядер.
Ну а значит В, которое у нас разложено вот таким вот образом У плюс ядро ПК этого от Фи, оно же разложилось и в сумму всех К ядер,
в прямую сумму всех Х ядер, что мы и хотели доказать.
Итого, наше следствие уже доказано.
Ну вот на самом деле мы видим сейчас, как аннулирующие многочлены помогают осознать нам структуру нашего преобразования даже в общем случае.
Ну давайте теперь разбираться, что эта вся теория даст нам в случае, когда характеристический многочлен линейно факторизуем.
Итак, с этого момента на протяжении достаточно долгого времени мы считаем, что характеристический многочлен Фи линейно факторизуем.
И мы его будем записывать немного в другом виде, а именно мы сгруппируем одинаковые со множителем.
Чьи Фи от Х это будет произведение ПОЕ от одного до К, лямдоитые минус Х в каких-то степенях альфаитых.
Ну соответственно, где лямдо-1 и так далее лямдо-К это все различные, собственное значение оператора Фи, ну а альфаиты тогда будут естественно их алгебрическими кратностями.
Мы можем применить наше следствие к этой ситуации, потому что мы с вами знаем теорему Гамельтона Кэлли.
Так, прежде чем ее применять, давайте я сразу введу, мог бы и раньше ввести, некоторые обозначения, которые нам сократят записи.
Нам очень часто сейчас понадобится рассматривать оператор Фи минус лямдоитые, поэтому мы будем через Фи с индексом лямдо обозначать Фи минус лямдо.
Ну а если у нас есть матрица А этого оператора, то через А лямдо мы будем обозначать матрицу вот этого оператора, то есть А минус лямдо-1, где лямдо это какой-то элемент нашего поля.
Так вот такими обозначениями мы с вами будем пользоваться.
Итак, что мы с вами знаем про наш случай по теореме Гамельтона Кэлли, которую мы в этом случае уже доказали.
Характеристический многошрен Фи аннулирующий для Фи.
Ну а кроме того, вот все эти сомножители, которые мы написали, именно степени, они взаимно просты.
При естественно и неравном же.
Ну просто потому что мы знаем их разложение на неприводимые сомножители и эти неприводимые сомножители не ассоциируют.
Это означает, что мы можем применить наше следствие.
Вот у нас есть аннулирующий многочлен характеристический.
Вот он разложен на К попарно взаимно простых сомножителей.
И это означает, что все пространство раскладывается в прямую сумму следующих К пространств, которые давайте я сразу обозначу.
Я их обозначу вот каким образом. В с верхним индексом лямбда ИТ.
Где В лямбда ИТ, это соответственно ядро Фи минус лямбда ИТ в степени альфа ИТ.
Если мы применим наше следствие, то у нас здесь будут ядра вот такого многочлена, в которые вместо Х я должен подставить Фи.
Ну то есть в наших новых обозначениях здесь написано ядро Фи с индексом лямбда ИТ и все это в степени альфа ИТ.
Вот такое разложение в прямую сумму мы с вами получили.
И сейчас, наверное, самое время сформулировать то, к чему мы двигаемся.
Давайте я сначала дам название этим подпространствам.
Подпространство В с верхним индексом лямбда ИТ называется корневым подпространством, соответствующим собственному значению лямбда ИТ.
Нет, сформулировать, наверное, чуть попозже, сформулируем мы в начале следующей лекции.
А давайте сейчас пару свойств корневых подпространств попытаемся доказать.
Ну первое замечание, которое стоит сделать, как корневое подпространство соотносится с собственным подпространством.
Кто где содержится?
Корневое, конечно, содержит собственное. Давайте мы вспомним.
Собственное подпространство В с нижним индексом лямбда ИТ.
Это кто такое? Это ядро просто филя Амдаитова, правильно?
А корневое это ядро этого оператора в какой-то степени.
Ну то есть, по сути дела, этого оператора, умноженного еще на что-то, правильно?
И вот у нас уже была такая ситуация. Вот здесь мы ее как раз обрабатывали.
Отсюда следует, что ядро меньшего оператора содержится в ядре большего.
То есть, корневое подпространство содержит соответствующее собственное подпространство.
Ну вот давайте мы на этом тогда сегодня и завершим. Раз звонок прозвенел.
В следующий раз мы чуть-чуть поговорим про корневое подпространство.
И уже начнем разбираться с жардановой нормальной формой, к которой мы движемся.
На сегодня все. Спасибо за внимание. Если есть вопросы, задавайте.
