Отлично, у нас сегодня первая лекция, как я и обещал в прошлый раз, в прошлый раз я ничего не объяснял, а сегодня я обещаю, что я постараюсь объяснить, поэтому лекция будет очень простая и очень скучная.
Если вы не любите скучные лекции, то срочно покиньте аудиторию. Но нам сегодня важно понять некоторые азы, некоторую базу, без которой жить дальше невозможно.
Дальше мы будем говорить про какие-то более хитроумные вещи, а вот сегодня самый-самый простый класс для первой лекции.
Но прежде чем мы перейдем к этому, вот смотрите картинка, тут какие-то процессоры сражаются за ячеек памяти.
И о чем я хочу поговорить? Потому что я вижу эту картинку перед собой.
Я вспомнил, что эта картинка из слайдов, сделанных для курса по замечательной книжке, которая называется Art of Multiprocessor Programming.
Это книжка про concurrency, про то, как можно синхронизировать потоки и писать какие-то затеревы и структуры данных.
Это очень любопытно, это очень интересно, особенно если вы любите алгоритмы, но курс наш не про это.
Возможно, вы будете сожалеть, но вот чтобы вы не сожалели, вы можете открыть эту книжку и почитать ее.
Она очень классная, там всякие деревья, списки, хэштаблицы мастерятся.
Это увлекательно, но все-таки не совсем для промышленного программирования, поэтому мы это оставляем в стороне.
Но если вдруг вам интересно, то почитайте, пожалуйста, она будет прям великолепна.
Ну а мы говорим сегодня про более приземленные вещи, мы не будем сегодня делать лог-фри хэштаблицы, к сожалению.
Мы поговорим про задачу взаимного исключения.
У вас в первой домашней работе в задачах уже есть мьютексы, вы уже, возможно, учились пользоваться,
но мы сегодня проговорим, как именно мы это делаем.
И начнем мы с такого простого соображения.
На первом семинаре, надеюсь, вы поговорили про то, что такое исполнение.
У вас есть компьютер, там есть процессор, у него есть ядра, ядра работают с памятью,
я читаю через instruction pointer инструкцию, у них есть call stack, чтобы выходить по коду.
И за исполнение чего бы то ни было на этих ядрах отвечает операционная система.
Там есть некоторые компоненты планировщик, которые пока для нас выглядят довольно магически,
мы не понимаем, какой он устроен, мы до этого дойдем, а пока мы просто считаем,
что он планирует наши процессы, наши задачи.
В Linux можно корректно говорить task на эти самые ядра.
И, конечно же, у планировщика задача, чтобы все таски, чтобы все процессы в системе,
чтобы все потоки во всех процессах имели доступ к, собственно, процессору.
Поэтому их периодически нужно снимать, этого процессора, переключать друг на друга.
И с этим есть некоторая беда.
Вот точки переключения потоков, они нами не наблюдаются, нами в смысле разработчика,
нами в смысле программой. Это все происходит как-то скрыто через механизмы прерываний,
но вот вы, когда пишете код, не думайте о прерываниях никаких, вы пишете просто в предположении,
что у вас есть свой виртуальный процессор, который исполняет функцию main.
Это некоторая абстракция, которая для вас операционную систему поддерживает.
Но мы-то знаем, что это все немножко не так, что у нас нет своего процессора,
что мы делим его с другими. И если вдруг у нас есть конкуренция,
то мы понимаем, что потоки все-таки могут переключаться и перемешиваться.
Собственно, возникает ситуация конкуренции.
И в этой ситуации есть проблема, если эти потоки, если эти две операции,
вот красные и синие, работают с какими-то общими данными.
Пока может быть даже непонятно, что это за общие данные, но какой-то случай
вы можете представить себе уже сейчас, если вы вообще писали какую-то программу в своей жизни.
Вот представьте, что вы запускаете разные потоки, они что-то делают,
может быть даже разные, может быть даже не работают с какими-то вашими данными общими.
Но при этом у них есть все-таки некоторые общие данные, с которыми они работают,
некоторое общее состояние. Вот понимаете ли вы, о чем я говорю?
Вот может быть вы не сделали какую-то общую структуру данных,
в которой эти потоки ходят, но тем не менее у них есть некоторый сервис,
с которым они работают, который общий и внутри которого синхронизация
между этими потоками все же необходима.
Но это все же происходит внутри операционной…
Во-первых, я не понял, что ты имел в виду.
Какие-то структуры данных ядра, но они в ядре.
В ядре конечно конкаренности очень много.
В какой-то смысле очень правильный ответ, и можно закрыть тему.
Но вот в твоей программе.
Вот если твои потоки вообще алоцируют память динамическую,
то видимо они посещают один и тот же аллокатор.
Аллокаторы устроены, конечно, по-разному.
Не то чтобы все устроены одинаково, но в конце концов,
где-то в недрах аллокаторов все равно нужна синхронизация между потоками.
Вот можно себе представить хоть наивный аллокатор,
который выделяет разом себе арены памяти,
с помощью вызова мэп получает себе много страниц,
нарезает их на кусочки, и когда программа приходит в вызов new,
вы пишете new или malloc, то вы приходите в аллокатор,
и аллокатор вот из какой-то арена оторвает кусочек и дает его вам.
А потом вы говорите free или de-read, и этот кусочек от аллокатора возвращается.
Что делать с этими кусочками аллокатор?
Вот у него была большая арена памяти, она была разбита на маленькие фрагменты,
и теперь часть из них используется программой, а часть не используется.
Опять, аллокаторы действуют по-разному, в них много слоев,
может быть, мы на одной из лекций даже про это поговорим в контексте забавного лог-фри бага.
Но в первом приближении можно представить себе, что в аллокаторе, наверное,
где-то есть список свободных блоков, что вот есть список, и у него провязываются блоки.
И вы с этим списком работаете, ну, в смысле, вы потоки, которые обращаются к аллокатору за памятью.
Вот это уже место, где нужно делать синхронизацию.
Этим, конечно, занимаетесь не вы, а разработчики аллокаторов, тем не менее, синхронизация есть.
И вот есть этот общий список. Ну и давайте подумаем, что делать,
что будет происходить с этим списком, если к нему будут приходить разные потоки.
Пусть список даже самый элементарный, пусть он односвязный.
Вот у меня здесь какой-то код, я не знаю, видите его, хорошо видите?
Или нужно сделать крупнее?
Не стесняйтесь, пока есть возможность.
Давайте попробуем.
Ну, чуть-чуть лучше стало.
Вот список.
Ну, он такой абсолютно игрушечный, и в аллокаторе его не можно,
потому что в аллокаторе вы не можете использовать Нью,
потому что вы реализуете Нью, в конце концов.
Списки должны быть интрузивными, если вы знаете, что это.
Ну, вот просто пример односвязанного списка, в узлах которого ничего нет.
Мы просто умеем делать пуш, алоцировать новый узел, привязывать его к старой голове, менять голову.
И мы можем извлекать первый узел из этого списка, ударять его.
Ну, а теперь что мы делаем?
Мы проверяем, что он как-то работает, это не очень интересно.
А дальше мы запускаем потоки, которые на разных ядрах, может быть параллельно, может быть конкурентно,
будут с этим списком работать.
Они будут сто пятьсот раз добавлять в него узел, потом извлекать.
Ну, очевидно, что список никогда не бывает... никогда не бывает underflow в этом списке,
что мы никогда не извлекаем из пустого.
Так что тест, в общем, похож на корректный, да?
Ну, вот мы запустим эту программу.
Что с ней может пойти не так?
Ну, давайте запустим. Тут сборка с адрес-санитайзером.
Вот видите, heap-news of the free.
Вот возникла какая-то ошибка.
Вот. Давайте попробуем вытрясти другую ошибку.
Не знаю, когда это получится, может быть, никогда.
Может быть, меня будет бесконечно долго не вести.
Такое тоже возможно.
Ну, в конце концов, я брошу.
Ну, вдруг повезет.
О, смотрите, double free получился.
Вот видите, проблемы в этом коде есть, они разные.
И проблема, видимо, в том, что мы не синхронизируем доступ к этому объекту.
И вот что может случиться?
Ну, вот смотрите, давайте с push-а начнем.
Что может пойти не так с push-ем?
Вот пусть у нас два push-а конкурируют.
К чему это может привести?
Вот конкурирует, это означает, что, смотрите, у нас планировщик может снять нас поток
с ядра в любой момент.
Ну, то есть буквально между каждыми двумя строчками.
Ну, что такое атомарно, это интересный вопрос.
И мы, собственно, к этому хотим прийти рано или поздно.
Ну, вот пока можно считать, наверное, что вот это присваивание – это атомарная операция.
Вот никто не может наблюдать ее посередине.
У нас есть регистр, в котором уже прочитана, пусть голова списка,
мы пишем ее в какую-то память, в какой-то ячейку памяти,
но вот это происходит, допустим, атомарно.
Так я говорю, давайте два push-а возьмем.
Ну, вот у нас есть два push-а.
Они алоцировали два узла памяти.
И они оба выполняют вторую строчку этого push-а.
И вот так получилось, что сначала они выполнили первые строчки,
а потом они оба выполнили вторые строчки.
И в итоге оказалось, что вот так вот, что они теперь привязались к одной и той же голове.
Плохо это?
Ну, кажется, у нас утечка памяти.
То есть у нас узел, который теперь недостижим из головы.
Неприятно.
Давайте теперь подумаем, что может произойти с конкуренцией POP.
Вот, мы потеряли один из узлов.
Тут вообще уже разные варианты могут быть.
И вот те ошибки, которые у нас выпали, они вот выпали в разных сценариях.
То есть у нас проблема, конечно, не детерминированная,
но в зависимости от того, как именно не детерминированно
планировщик будет перевершать эти потоки,
реализуется либо одна проблема, либо другая.
Вот давайте какую-нибудь выберем.
Ну, вот опять похожая ситуация.
Выполнили по первой строчке, выполнили по второй строчке.
И что теперь получилось?
Два потока собираются удалить один и тот же первый узел.
Это вот ситуация как раз double free.
Мы вызываем на одной и той же памяти, дважды освобождаем одну и ту же память.
Ну, конечно, на C++, если вы просто соберете программу и там сделаете double free,
то никакой ошибки double free.
Вот с таким вот стеком у вас не будет, конечно.
Это специально инструментированный код,
который в runtime еще поддерживает какие-то структуры данных.
Это называется адрес санитайзера, общий санитайзер C++.
Необходимый для разработки инструмент.
Вот про него пойдет речь на одном из семинаров.
Поэтому, пожалуйста, не пропустите его.
Ну, вот он для нас показывает, что возникло double free.
Другая проблема.
Видите ли вы ее?
Она в какой-то степени похожа,
но вот все-таки
она не в локаторе, допустим, возникает.
Вот вызвали мы delete под хеда,
а потом в другом параллельном процессе пытаемся по этому же адресу.
Ну, чуть аккуратнее. Мы про потоки говорим здесь.
С процессами мы их не путаем.
Ну, вот один поток, первый поток прочел хед, второй прочел хед.
А дальше первый поток прошел весь поп до конца.
То есть он перекинул ссылку и удалил этот первый узел.
А теперь второй узел, второй поток идет и читает next
за старым хедом.
Вот эта память, в которой живет поле next,
в которой живет алоцированный ранее узел,
она уже отдана локатору.
Ну, это явно проблема, да?
То есть явно в программе баг.
Но довольно плохо, что если вы вот соберете
программу вашу без инструментации, без санитайзера,
то, скорее всего, бага у вас не будет. Почему?
Потому что когда вы...
Не то, что бага не будет, баг будет, разумеется.
Ошибки не будут во время исполнения,
потому что вы отдадите память локатору.
А что он с ней сделает?
Он же не отдаст ей операционной системе.
Он просто запомнит, что этот блок свободен
и потом выдаст его кому-то другому.
Вот. И вот вы прочитаете какой-то совершенно
мусорный адрес потом из этого блока.
И что, возможно, еще хуже.
Потому что у вас вот проблема распространяется
по вашей программе.
Какие из этого уроки?
Что нужно синхронизировать потоки,
и нужно падать как можно раньше.
Это только ошибка возникла, лучше сразу упасть.
Вот санитайзер здесь вам помогает.
Без санитайзера было бы довольно печально.
Ну и что же мы в такой ситуации можем сделать,
если мы хотим все-таки этот список заставить работать?
У нас для этого есть очень наивное,
очень простое решение.
Нам нужен Mutex.
Вот мы хотим, чтобы наши операции
были логически атомарными.
Вот чтобы случался push,
либо случался pop,
и как будто разом друг относительно друга.
Вот атомарность, я здесь говорю
не в каком-то строгом смысле.
На самом деле, атомарность слова можно формализовать
и можно формализовать по-разному.
И скажем, в курсе про сприлетные системы
я буду говорить очень четко,
очень сложные определения.
Но пока мы считаем,
что атомарность в каком-то таком
естественном смысле для нас
интуитивно понятном.
Но я сразу замечу, что атомарность
всегда относительно чего-то.
Вот нет абсолютно атомарности.
Вот мы, конечно же, не можем сделать
эти методы атомарными,
потому что там несколько инструкций процессора.
Тамолокатор вызывается.
Сложная логика.
Но мы хотим, чтобы относительно друга
эти операции выполнялись атомарно.
Это мы можем достичь.
Но всегда есть уровень ниже,
где атомарности уже, конечно, никакой нет.
Ну, я не знаю, насколько вообще в мире
много всего действительно атомарного,
и с какого уровня все начинается.
Ну, явно на уровне этого кода,
на уровне компьютера там ничего атомарного нет.
В конце концов, у тебя есть процессор,
он дико сложный,
там вот много всего происходит.
Конечно же, запись ячейки в памяти
это не атомарное действие,
в смысле физически не атомарное.
Там много всего задействовано.
Но вот мы хотим, чтобы
логически эти операции были атомарными.
И для этого у нас...
Ну, вот смотрите, что есть.
У нас есть mutex.
Что он позволяет нам сделать?
Он дает нам всего лишь два метода.
Log и Unlock.
То есть это
некоторый разделаемый объект,
ссылку на который держат оба потока,
которые обращаются с общими данными.
И перед тем, как обращаться
к разделяемым данным, мы говорим mutex log
или захватываем mutex.
А когда мы закончим
с разделяемыми данными, мы отпускаем
log.
Тот код, который оказался посередине, мы называем
критической секцией.
Да.
Ну, нужно, наверное, разобраться,
каких свойств мы от этих операций ожидаем.
Нас интересует в первую очередь наблюдаемое поведение,
а не как они реализованы.
А как они реализованы, ты напишешь
в домашней работе.
Так что всему свое время.
Как запустить поток?
Мы вроде бы
смотрели в прошлый раз.
Секундочку.
Давай я еще раз покажу.
Вот мы сконструировали поток,
он запустился.
Ну, как именно...
Что именно происходит,
когда мы запустим поток,
что именно происходит в этот момент,
это сложный вопрос. Мы откладываем его
на четвертую лекцию.
Пока,
можно считать, что мы пользуемся
такой магией, мы запускаем потоки
вот так, конструируя экземпляры std.red.
Но я
на следующей лекции уже объясню, как
на самом деле мы запускаем потоки, и что мы их запускать
вообще-то не хотим. Это
странная затея для наших целей, потому что я
на прошлой лекции объяснял, что
если мы запускаем много поток,
это что-то неэффективное, мы хотим не потоки
запускать. В общем, у нас будет
полпоток, там мы все это проговорим.
Пока достаточно какого-то
вот такого базового представления.
Конструируем std.red, передаем туда
функцию, лямбду, и она
исполняется независимо.
Это нам даже не
столько важно. Нам главное сейчас понимать,
что может быть на двух ядрах
или даже на одном, но
с вытеснением, с переключениями
контекста, два исполнения,
которые живут в одном и том же
виртуальном адресном пространстве, которые работают
с общими ящиками памяти.
Если это понятно, окажется, после
семинара это должно быть понятно, что
такое исполнение, то можно представить
себя, что их два, что память у них
общая, виртуальная,
и вот они обращаются к некоторой
структуре данных.
И она после этого ломается.
Ну вот,
вернемся к
Mutex.
В чем его замысел?
Mutex, почему он так называется? Взаимные исключения.
Видимо,
он пытается гарантировать следующее
простое свойство, что между
вызовами lock и unlock
может находиться только один поток.
Если какой-то поток сейчас
уже захватил Mutex, владеет
им, находится между этими
вызовами, то другой поток,
который пришел и вызвал lock,
будет ждать, пока первый не вызовет
unlock. Ну то есть, вот эти методы
lock и unlock, они как-то могут пересекаться
во времени, критические секции не могут.
Пока первый поток не отпустит Mutex, второй его захватить
не сможет. Он будет дожидаться.
Если вопросы есть, самые простые,
задавайте, пожалуйста.
Чтобы всем было понятно.
Ну и
стоит, наверное, лексику еще
прокомментировать, говорят часто, что Mutex
защищает разделяемый объект. Ну вот есть картинка,
где Mutex, вот этот дядька с ружьем,
он
короче,
контролирует ситуацию.
Здесь есть явно вот этот пренек,
это кто? Это поток,
вот эта кабинка, это критическая секция, там
то, что находится внутри, это видим разделяемые данные
какие-то, которым не нужно обращаться
именно. Вот это
Mutex. В общем, все очень понятно.
Ну и вот, еще раз прокомментирую,
лексика защищает, захватывает, отпускает.
Вот так люди говорят, и вы тоже
можете говорить. Ну и имеем
Mutex, мы можем любой
структуру данных сделать потока безопасной.
Каким образом?
Мы можем просто все операции, которые должны быть
атомарны, т.е. на друг друга, завернуть в критическую секцию.
Вот у нас есть Mutex,
у нас есть, точнее, вот голова,
у нас есть Mutex, который будет защищать
работу с этой головой,
ну и как бы наивно
можем поступить, написать вот такой вот код.
Так не надо делать,
но пока пусть так.
Помогло ли это нам?
Ну кажется, что помогло.
Но, конечно же, вот
прям так код писать не нужно.
Ну и, конечно,
мы можем
все операции, которые должны быть
атомарны, т.е. на друг друга,
ну и как бы наивно
мы можем просто
так код писать не нужно.
Вот совсем не стоит
так писать код. Почему?
Нет, вот, как раз
два разных Mutex не нужны.
Что?
Это
хорошее замечание, вот да,
давайте
вот можно написать так,
так будет лучше.
Ну и лучше не в этом смысле,
потому что это будет оптимальней.
Да, действительно, мы можем с локатором
работать параллельно. Если локатор хорошо написан,
он действительно вот распараллельно
два этих вызывания из разных поток,
потому что там какие-то радолокальные кэши.
Но я скорее про то,
как Mutex'ам пользоваться, в смысле,
лок и анлок вызывать.
Вот можно делать так наивно,
но это попирает все
идиомы языка C++,
а именно идиомы райя.
Захват ресурс, есть инициализация.
Вот знаете ли вы про умные указатели?
Вот они вам
позволяют выделить память и потом ее
освободить тогда, когда она больше не нужна.
Когда разрушится единственный веник
pointer или когда пропадет последняя разделяемая ссылка
в виде shared pointer на объект.
То есть мы связываем
время жизни некоторого объекта
и некоторые операции.
То есть мы
владеем ресурсом в течение некоторого времени
и это вот владение выражено в lifetime
какого-то объекта, lifetime объект разрушается
и ресурс освобождается.
Вот здесь у нас тоже есть
некоторые разделяемые...
некоторые ресурсы, мы хотим завладеть
доступом к некоторому объекту
и время нашего владения ограничено
вызовом функции, у нее есть какой-то
понятный scope. Что мы для этого делаем?
Мы используем рай, мы говорим...
Вот, код абсолютно эквивалентный.
Что здесь происходит? В конструкторе
этого объекта мы вызываем lock,
в деструкторе мы вызываем unlock.
В итоге mutex unlock вызывается
вот где-то
здесь.
Но это вы тоже, наверное, знаете, да?
Если вы решали первый раз
что-то делать, то это
будет очень сложно.
Но если вы решили второй раз, то это
будет очень сложно.
Ну, если вы решали первую домашню,
то вы вот что-то уже знаете.
Хорошо. Пожалуйста, обращаю
ваше внимание, что
вот нужно использовать
именно LockGuard, а не
Uniclock, который похож и который также
можно здесь написать.
И тоже все будет работать.
Вот если вы читали документацию
про Uniclock и про LockGuard,
скажите мне,
было такое?
А про Uniclock нет?
Ну, возможно и рано,
оно пригодится в следующий раз.
Есть два объекта, они оба в конструкторе
берут lock, в деструкторе освобождают lock.
Но вот LockGuard занимается
только этим.
Он ничего больше не умеет,
я надеюсь.
Почти, да?
Вроде не умеет.
Вот только этого нам сейчас
не хватало, если честно.
Есть конструктор и деструктор,
методов нет. Он создается,
захватывает lock, разрушается, отпускает lock.
Есть Uniclock, который делает то же самое,
но у него есть вот ручка,
чтобы отпустить lock.
И можно использовать, в принципе,
тот и другой, но не нужно.
Вот нужно использовать тот класс,
которого достаточно.
И у него есть
класс, которого достаточно.
Если вам нужно только залочить,
а в конце скопа разлочит Mutex,
то вы используете LockGuard.
А если вы используете Uniclock,
то помните, что вы пишете код
не для компьютера, не для компилятора,
а для коллеги вашего, который будет его читать.
Если он увидит у вас другой класс Uniclock,
а вы не пользуетесь его
какой-то избыточной функциональностью,
то он будет гадать, зачем же вы сделали именно так.
Ну, в зависимости от того,
как у тебя написан код,
если ты хочешь вот...
Если тебе нужно после этого блока
Mutex отпустить и сделать что-то
еще уже без Mutex,
то, конечно, тебе, наверное,
стоит написать вот такой вот код.
Но если здесь ничего нет,
вот просто здесь конец функции,
то зачем?
Ну...
Ну, смысловую нагрузку
это будет нести точно так же, как MutexLock
и MutexUnlock.
Ну, в смысле, это такой вариант,
но Uniclock, LockGuard
ровно это и делает.
Потому что это
идеоматичный C++.
Ну, вот, смотри.
Есть вот такой вот код.
Тут он, кажется, не дописан.
Вот.
Вот представьте себе,
что мы в этом коде
использовали бы MutexLock, MutexUnlock.
С какими проблемами вы бы столкнулись?
Ну, да.
Его нужно писать
перед каждым ретерном,
и это довольно хрупкий код,
потому что...
Ну, может быть, вы даже не забудете
это сделать.
Ну, да.
Ну, вот.
Вот.
Вы даже не забудете это сделать.
Ну, неприятно, что уже два раза нужно
повторяться.
Неприятно, что нужно быть аккуратным.
А еще есть такая проблема, что этот код сложнее
поддерживать. Кто-то будет его рефакторить,
переписывать, добавлять if, и вдруг забудет.
Потому что он от Mutex не писал.
Представьте, что этот код не из 10 строчек,
а из там... Ну, это не самый хороший код,
наверное, ну, там, из 200.
И вот можно легко
попасть в просак.
Ну, кроме того, это, наверное, не очень актуально
для Mutex все же, но исключение.
Если у вас полетает исключение,
разматывается стэк,
то если вы пишете он лог руками,
то он не вызовется. Если вы написали
log guard, то при размотке стэка будет
вызван деструктор, и
лог отпустится.
Ну что, вопросы есть?
А другие языки переняли?
Ага.
Ну вот, скажем, а я не знаю, мне кажется,
у меня пример с Go здесь был прям
готовый.
Вот.
Мы захватываем лог
и говорим, что в конце вызова
функций нужно вызвать Mutex.
Ну вот, в разных языках есть
какие-то разные способы, разные синтексы
для того, чтобы как-то связывать
скопы лексические
с какой-то логикой, с каким-то
владением ресурсов, но вот
это все довольно индивидуально. Все плюс-плюс,
есть рай, и мы обязаны им пользоваться.
Прежде чем перейти
к свойствам Mutex,
хотя это, наверное, может быть, самое важное
сейчас,
все-таки скажу про
еще кое-что про его использование.
Ну вот, мы можем вызывать lock-unlock, мы можем
использовать рай
для того, чтобы делать
это аккуратнее и безопаснее.
Но в домашней работе вы видели, что
можно поставить вопрос вообще несколько иначе.
Что у нас есть
Mutex и есть данные, которые
этим Mutex мы защищаются.
И вот в коде, скажем,
который мы пишем, эта связь,
она никак не выражена. Вот есть просто Mutex
и есть просто вот какое-то поле.
И, видимо, мы
написали код так, чтобы при обращении
к этим полям, к этим разделенным данным, мы
используем один и тот же Mutex, который изолирует
разные конкурирующие
операции. Но вот
в коде эта связь никак не выражена.
И это, вообще говоря, большая проблема,
потому что
это не помогает писать безопасный код.
Вообще, если вы следите за языками
программирования, за тем, которые развиваются сейчас,
то есть некоторый тренд на то, чтобы делать языки
безопасными.
Цель не только в том, чтобы сделать
код, чтобы код исполнялся эффективно,
а еще и в том, чтобы
сложнее было написать
некорректную программу.
И
в данном случае C++ нам никак
не помогает. Он никак не связывает
этот Mutex и эту голову.
Мы можем, конечно, написать комментарий здесь.
Вот. И это человек, который
читает код поможет.
Но оказывается, что можно сделать хитрее.
Смотрите, что, например,
умеет
Clang.
Вот в
Clang можно написать вот так вот.
GuardedBy.
Ну, почти что комментарий.
Вот давайте я
покажу этот пример.
Вот тут какой-то класс
банковский аккаунт. Он немного в другом
виде написан. Ничего не поделать.
Мы можем
положить деньги на счет, снять деньги
со счета. Мы можем перевести
с счета на счет.
Вот. Пример
абсолютно бесполезный, но
он здесь не для этого. Он для того, чтобы показать,
что вот есть состояние некоторое
и есть Mutex, который его защищает.
И мы можем сделать нечто лучшее,
чем просто написать комментарий.
Мы можем написать
с помощью некоторых специальной аннотации
для комператора, что вот эти данные
защищаются этим Mutex,
а потом мы можем
поставить на вызов функции
в его сигнатуру добавить некоторую аннотацию,
что для того, чтобы этот метод
можно было вызвать,
нужно Mutex'ом владеть.
И вот если это
свойство нарушается,
вот как, например, здесь
мы берем Mutex
для текущего аккаунта
и не берем Mutex для аккаунта,
с которого мы забираем деньги.
И вот в этом случае появляется
ворнинг,
но
если мы собираем программу
с флажком в эррор, то есть мы трактуем ворнинги
как ошибки,
а, я надеюсь,
в любом хорошем проекте так и происходит,
в конце концов, то эти ворнинги
превращаются в ошибки и ваш код не компилируется,
потому что вы вызываете метод
без лока.
Это вообще выглядит как будто
какая-то кастомная проверка
и действительно
в данном случае так оно и есть.
Но вообще это иллюстрация
некоторого общего метода, который называется
Reference Copabilities,
когда вы
можете статически анализировать
программу и присваивать
некоторым сущностям в ней некоторые свойства.
Короче говоря,
как вам коротко это объяснить,
это теория языков программирования,
теория типов довольно сложная,
там можно очень сложные вещи делать.
Вот можно
есть, посмотрите, такая
интуиция, что вообще говоря
можно думать о функциях
в языке программирования,
о сигнатурах, как о некоторых утверждениях,
а о теле функции,
как о доказательстве
этого утверждения. И вот это можно определённым
образом формализовать и научить компилятор
проверять, что действительно свойства
выполнены. Ну вот
Copabilities — это
некий такой механизм из вот этой
сложной теории.
И в Clang вот он частично реализован,
и он позволяет вам
какие-то наивные ошибки
не допускать. Вот в стандартной библиотеке C++
такие аннотации на Мютоксах, Кодварах есть.
Кажется, что в случае с работы
с Clang вы можете
в своём проекте такие аннотации
использовать.
Наверное, вы и без них
бы справились,
но с ними всё же приятнее, с ними всё-таки
безопаснее, особенно если кодовая база большая,
и с ней работает много людей.
Мне кажется, что
нет.
Ну и по поводу интерфейса
Мютокса, вы опять
в задаче видели, что можно
вообще-то интерфейс от Мютокса придумать
немного иной.
И вообще говоря,
связать просто Мютокс и данные.
Вот пример из языка
Rust. Там Мютокс имеет
другой IP. Вот у нас в домашней работе
была обёртка Mutex,
которая не позволяла обращаться к объекту,
пока вы Мютокса не захватили явно.
Но вот
в языке Rust, в стандартной библиотеке
Mutex, он только такой.
Вот он именно такой.
Чтобы обратиться к данным,
вы должны вызвать лог сначала.
И только тогда вы получите
мутабельную ссылку.
С Rust вообще интересная
ситуация, потому что там
некоторый радикальный подход к конкуренции,
который позволяет вам избегать
некоторых ошибок просто статически,
очень большого класса ошибок.
Но вот если вам интересно, вы можете
однажды это изучить.
Да, я кое-что
забыл, мне нужно, мне хочется это проговорить
обязательно. Вернёмся к этому примеру.
Вот ошибки, которые
здесь возникали, у них есть специальные названия,
и давайте мы их сразу запомним.
Вот в этом коде,
когда у нас происходила какая-то конкуренция,
потоки переключались,
они чередовали друг с другом на ядре,
и из-за этого чередования
мы нарушали какие-то инварианты структуры данных,
вот такой класс ошибок
называется RaceCondition.
Но дело
не только в нём. Вот если из этого кода
мютексы убрать, вернуть всё как было,
то проблема не только в том,
что потоки конкурируют,
и вот из-за интерливингов
возникают вот такие нарушения инвариантов
на уровне структуры данных.
Это не единственная проблема. Вторая проблема
называется DataRace.
Вот конкурентные
баги, они как правило, либо
RaceCondition, либо DataRace.
И вот
что такое RaceCondition, я могу вам неформально
объяснить, и это вот именно такое понятие
не строгое. Вот из-за конкуренции,
из-за чередования нарушаются ваши
инварианты. DataRace, напротив,
это очень конкретное понятие.
Вот если говорить совсем коротко,
оно про то, что два потока
без синхронизации
обращаются просто к одной и той
же ячейке памяти. И что важно,
одно из этих обращений — запись.
То есть две записи без синхронизации — это DataRace.
Запись и чтение без синхронизации —
это DataRace. Параллельное
чтение одной и той же ячейки — это
допустимо.
Так вот, здесь и то, и другое есть.
Но, пожалуйста, разделяйте
эти вещи. DataRace — это
проблема на уровне отдельной маленькой
ячейки. RaceCondition —
это проблема на уровне инвариантов
какого-то вашего кода.
И они могут сочетаться, могут
быть независимы друг от друга.
Чуть позже, когда мы поговорим про DataRace
в модели памяти, это отдельная сложная
тема, мы сможем строго
их различать.
Вот RaceCondition — это когда ты считаешь,
что у тебя каждая строчка атомарна,
но просто из-за того, что они как-то переплелись
на процессоре, у тебя там, не знаю,
дважды что-то удалилось.
Или потерялась вставка, она
недоступна теперь из головы.
Вот это RaceCondition.
А DataRace — это ситуация, когда у тебя есть
просто ячейка памяти, вот 64-битная,
на твоем современном
процессоре, и с ней работают
два потока без синхронизации, и, по крайней мере,
один из них пишет.
Это не строгое определение, потому что
нужно формализовать что такое без синхронизации.
Тут речь не только про мютоксы,
но пока можно думать
только про мютоксы, раз уж мы больше
ничего не знаем.
DataRace и RaceCondition независимы
друг от друга.
Ну, какие варианты мы нарушаем,
когда мы работаем с одной ячейкой из разных потоков
без синхронизации, непонятно.
Это разные вещи. DataRace про одну маленькую ячейку
и обращение без синхронизации и RaceCondition —
это какие-то переключения я,
очередования.
Ну, хорошо, давайте
пойдем дальше.
Чего мы от мютокса ожидаем? Мы пока говорим про то,
как им пользоваться,
не говорим, как он
реализован, но чего мы от него ждем?
Мы от него ждем двух свойств. Одно я уже озвучил.
Это взаимное исключение,
поэтому его название.
Между вызовами Lock и Unlock может находиться
только один поток.
Но есть второе свойство —
свобод от взаимной блокировки.
Вот эти два свойства, они проразны.
Смотрите, первое свойство про то,
что никогда не происходит ничего плохого.
Если два потока находятся
между Lock и Unlock одновременно,
то, видимо,
наши вызовы уже не одномарны друг относительно друга.
Но есть и
другая проблема, а именно
на нужен прогресс.
Вот если мютокс свободен сейчас,
из-за него соревнуются
несколько потоков, то, по крайней мере,
один из вызовов Lock должен завершиться.
Не может быть такого, что
все они вызвались и мешают друг другу,
и никто не завершается вечно.
Еще раз, это свойство safety,
свойство liveness. Ничего плохого
не происходит никогда, и когда-нибудь
происходит что-то хорошее. Нас, конечно,
волнует оба этих свойства.
Что значит, что поток
захватывает мюток?
Как можно мюток заходить?
Вызвать Lock и завершить этот вызов.
Ну вот, смотрите, тут был слайд с лексикой.
Поток захватывает мютокс, вызывая Lock.
Ну, поток исполняется, а мютокс
это объект. Видимо, поток захватывает
мютокс. В смысле, под.
Можно
интерпретировать по-разному. Как правильно
сказать, чтобы не было доусмысленности?
Мютокс захватывается
потоком, а поток
захватывает мютокс.
Все, получилось. Ура.
Ну вот, значит, такие свойства Safety Linus.
И мы с вами
в домашнем задании сталкиваемся
с двумя задачами, которые
моделируют нарушение
этих свойств.
Первая проблема, которая возникает
с свойством Safety, с свойством взаимноисключения,
это взаимная блокировка.
Что я говорю?
Мы говорим, конечно, про гарантии прогресса.
Вот, гарантии прогресса могут нарушаться
немного по-разному. Вот есть
взаимная блокировка,
deadlock и есть lifelock.
С deadlock мы уже столкнулись. Это ситуация,
когда потоки блокируют друг друга
и не могут больше ничего сделать.
Прогресса не бывает больше.
Вот потоки пришли
в какое-то терминальное состояние,
выйти из него они уже не могут.
И есть другая проблема, она называется
lifelock. Она про то, что
все же потоки могут выйти
из вот некоторые ситуации,
где ни один из них не совершает прогресса.
Но
случится это или нет? Точнее, когда это
случится, мы не знаем. Все зависит
от того, как потоки планируются планировщикам
на ядра, когда они именно
переключаются.
Нет, не может.
Ну, в смысле, тебя, наверное, смущают машинки, да?
Ну, я согласен.
Разница между этими картинками в том,
что здесь машины назад
двигаться не могут.
Ну, по крайней мере,
имелось авторами это в виду.
А здесь они могут отъехать и попробовать заново.
Но если они сделают это симметрично все,
ну, и там, неудачно в некотором смысле,
то снова они вот окажутся в той же ситуации
и вот продолжат так мучиться.
Ну, не представь себя, вот lifelock есть такое
очень простой жизненный пример. Два человека идут по коридору
навстречу друг к другу.
Им нужно разойтись. Что они делают?
Они идут в одну сторону сначала, отходят.
И снова мешают друг другу, потом в другую.
Ну, и так может продолжаться некоторое время.
Скорее всего, не вечно, но непредсказуемо долго.
Вот это lifelock.
А deadlock — это когда уже все.
Вот deadlock вы уже
симулировали в домашней работе,
поэтому вы понимаете, что вот из него выхода
уже никакого нет. Вы вызвали там
lock на разных mutex,
в разных потоках, и вот
они уже не завершатся.
Никогда.
Тут нужно уточнить,
что вот гарантия прогресса,
которую мы вот так определили,
она может быть
двух видов.
Вот здесь мы говорим, что
если несколько потоков вызвали mutex lock,
то кто-нибудь из них должен преуспеть.
Кто из них нам не важно.
Но может быть мы хотим
чуть более сильной гарантии, а именно
мы хотим, чтобы каждый вызов lock завершался.
Вот разница здесь
между гарантией глобального прогресса,
кто-то захватывает mutex,
по крайней мере кто-нибудь,
или каждый захватывает mutex.
Вот если какой-то поток может бесконечно
долго ждать, то мы говорим, что он голодает.
Ну и вот та задача,
которую вы увидели в домашней работе
про философов, она исходная как раз про голодание,
поэтому такая вот гастрономическая
ситуация у них там.
Они едят что-то вилками.
Мы эту задачу используем как демонстрацию
взаимной блокировки,
и вот ищем способ вывести
некоторое универсальное правило,
по которому можно захватывать блокировки,
не попадая в deadlock.
Но вот изначально задача посвящена
голоданию философу.
Такое техническое скорее замечание,
не знаю насколько оно нам прямо сейчас важно,
что
свойства сейфти
не зависят от поведения планировщика.
Вот как бы планировщик потоки не переключал,
вот все равно
два потока не могут, не должны
ни в коем случае оказаться в критической секции.
Когда мы говорим про лайвность,
то мы все-таки ожидаем кое-чего от планировщика,
что он,
то есть мы не можем, мы можем
гарантировать лайвность в своем коде только в предположении,
что сам планировщик действует
в некотором смысле честно и дает каждому
потоку время исполняться.
Зачем я сейчас
об этом говорю? Ну, потому что в будущем
некоторым мы будем говорить про гарантии
лог-фри,
и это очень ловкая, очень интересная
тема, и там вся соль будет в том,
чтобы обеспечить прогресс
операциям, но при этом не полагаться,
что планировщик будет исполнять каждый из потоков.
Это более сложно, нам придется
от мьютоксов потом избавиться,
для этого придется избавиться,
поэтому сейчас такое замечание.
Ну ладно, значит мы понимаем, что такое
мьютокс, мы понимаем примерно как им пользоваться,
что мы от них вообще хотим,
а теперь пора их сделать.
Вопрос только в том, из чего мы будем
их делать.
Ну вот, в конце концов,
под нами есть процессоры, ячейки памяти,
какие-то инструкции.
Мы сейчас будем из этого мастерить
реализацию мьютокса.
Достаточно наивно.
Но прежде чем к этому приступить,
нам нужно сделать еще одну оговорку,
очень важную.
Как мы вообще представляем себе работу
с памятью?
Вот как вы себе это представляете?
Ну в смысле, параллельную работу
процессора с разных ядер с общей разделяемой памятью?
Это правда,
но здесь
вопрос-то не о том,
как отдельное ядро работает
с памятью, это все правильно было сказано.
А нужно ли как-то учитывать, что
разные ядра физически
параллельно одновременно работают,
обращаются к одним и тем же общим ячейкам памяти?
Как мы можем
об этом думать?
Ну вот наивный способ об этом думать вот такой вот.
Он наивный, но он
такой интуитивный,
и если человека попросить
промоделировать в голове все исполнения
многоточной программы, то он, скорее всего,
будет рассуждать так, что
вроде бы потоков у него много,
ядер может быть много,
но все равно он делает шаги
с другими потоками по очереди.
Сначала первый поток походит, потом
еще раз первый, потом второй, потом еще раз второй,
потом снова первый, потом второй, потом третий
и так далее.
То есть у вас ядер много,
но вы как-то об этом не думаете,
вы все равно каким-то таким одним курсором
прыгаете по программе.
То есть как будто бы у вас
память как одно большое
целое атомарно,
и как будто бы мы с ней физически
параллельно не работаем.
Но эта модель хороша,
потому что она избавляет нас
от необходимости думать
про параллелизм.
Мы думаем только про переключение.
Нам нужно просчитать все возможные варианты,
когда мы переключаемся между разными потоками.
Но вообще-то, как мы скоро узнаем,
но я сегодня уже покажу,
а обсудим мы это на серьезном уровне
гораздо позже.
Вот такая модель, она просто несправедлива
в реальности. Вот реальность устроена не так.
Компьютер так не работает.
Вот люди так рассуждают
о его работе, но компьютер так сам по себе
не работает.
Поэтому мы сейчас будем делать
бьютэксе, но мы будем использовать не просто
ячейки памяти, ну там int
или bool, а мы будем
использовать вот такую вот обертку
atomic int, atomic bool, что-то подобное.
Какой-то atomic, шаблонный класс.
В прошлый раз спрашивали,
что такое atomic? Я говорил, ну это ячейка памяти,
с которой можно совершать атомарную операцию.
Поэтому она так и называется.
Ну и давайте посмотрим на методы атомика,
ну точнее на какой это метод атомика.
У него есть методы store и load.
Мы можем в атоме что-то записать,
простите, записать
и прочитать.
Ну как с ячейкой памяти.
Но вот оказывается,
что без этого атомика,
вот без
этого шаблона
мы не можем написать мьютэкс.
К этому мы чуть позже вернемся.
Но парадокс здесь
некоторый в том, что на уровне
представления,
то есть в компьютере в конце концов,
нет разницы между объектом
типа int и объектом
переменной типа int
и переменной типа atomic int.
То есть в конце концов в компьютере
они представлены абсолютно одинаково.
Это просто 64-битное слово.
Но при этом
без атомика мы жить не можем.
Где-то здесь есть подвох,
он действительно есть,
он действительно очень хитрый.
И вы, кстати,
можете этот подвох
вскоре увидеть,
прямо сегодня,
когда вы будете решать задачу,
которая называется спинлог.
Вот там вас как раз просят
написать свой атомик,
а не спинлог, как можно подумать.
Вы напишите атомик
и надеюсь лучше разберетесь,
что это на самом деле такое.
С одной стороны, а с другой стороны
у вас должно поселиться какое-то
сомнение глубокое.
Там для этого есть вопросы в условии.
Вот если вы на них ответите, подумаете,
то вас неизбежно они фрустрируют.
Вот это так и должно быть.
Ну вот, значит, пока опять какое-то
колдовство, какая-то магия,
пишем везде атомики, хотя это вроде бы те же самые ячейки памяти.
Ну да, я нигде не вру,
противоречия здесь нет.
Идем дальше.
Спасибо за вопрос.
Если мы работаем с мьютоксами,
то нам никакие атомики не нужны.
Атомики, грубо говоря,
для тех случаев,
когда у вас есть ячейка памяти
и с ней без синхронизации
работают разные потоки.
Вот если мы возьмем
список и обернем
эти методы в критические секции
с помощью мьютокса,
то таких ситуаций не будет.
Не бывает такого.
Этим полем
работают одновременно разные потоки.
Работает только один,
который владеет мьютоксом.
Но вот если мы хотим сделать
мьютокс сами,
то все-таки мы, видимо, должны работать
без синхронизации
одновременно с одними теми же ячейками,
одними теми же ячейками,
и для этого нам нужны атомики.
Вот они это позволяют.
Ну, разумеется,
потому что в конце концов мьютокс
же должен из чего-то быть сделан.
А что у нас здесь в компьютере?
Ячейки памяти и инструкции процессора.
Вот мы из этого сейчас и будем
мастерить блокировку.
Так нет никакого слова кэш.
Ну, то есть оно есть,
и в компьютере есть кэши, их много,
они сложно устроены, но это
не то, чем мы сейчас занимаемся, к сожалению.
Вот кэш — это такая штука,
которой можно не знать и не думать.
Конечно, в реальности нужно знать и думать,
и мы к этому придем,
но прям не то чтобы обязательно.
И мы сейчас этим пользуемся тем, что
не обязательно.
Мы считаем, что есть процессор,
есть память, и они
напрямую так соединены.
Ну ладно.
Так все это слишком сложно, чтобы сейчас
пояснять, потому что я не могу объяснить.
Мне потребуется на это 3 часа и только спустя
2 месяца, к сожалению.
Это сложная тема, это один из самых
сложных аспектов C++.
Вот я не знаю, правда это или нет.
С чем можно сравнить?
По сложности.
Ну в общем, это такая довольно
сложная математическая модель, которая касается
семантики языка,
которую мало кто понимает по-настоящему,
которая супер неинтуитивна для новичка,
и ее нужно объяснять
действительно 3 часа, а лучше 9,
и то после того, когда вы уже
какой-то опыт получите. Поэтому
пока я просто могу вам сказать, пожалуйста,
верьте в атомики, без атомиков нельзя.
Простите меня за это.
Ладно, давайте сделаем
мютекс наконец. Вот у нас есть...
Мы хотим сделать мютекс для двух потоков сначала.
Давайте ограничим
свои амбиции
и скажем, что мы просто хотим синхронизировать
два потока.
Ну давайте посмотрим
на какую-то заготовку, как можно было бы
это делать.
Вот смотрите, первая реализация.
У нас есть
два атомика
с индексами 0 и 1.
У нас есть два потока.
И у них есть пусть даже номера.
Это классическая задача, которая
непонятно зачем нужна,
потому что она не практичная абсолютно,
но все-таки мы на ее примере кое-что сможем увидеть.
У нас мютекс
с немного таким странным
API, метод лог принимает аргумент,
какой именно поток его захватывает,
либо нулевой, либо первый,
чтобы мютексу было проще.
Ну и вот смотрите реализацию
метода лог.
Мы ставим флажок, что мы текущий,
вот мы поток с индексом index
хотим получить лог,
а потом мы ждем,
если другой поток тоже хочет.
В методе unlock мы сбрасываем свой флажок.
Ну вот такая незатейливая реализация.
Что мы про нее скажем?
Нарушает ли эта реализация свойства
safety, взаимное исключение?
Какие потоки находятся между lock и unlock одновременно?
Нет, не могут,
потому что какой-то из потоков напишет
в want вторым,
ну в предположении, что мы живем
в такой модели чередования,
когда есть первый и второй всегда.
И тогда тот, кто записывал
вторым, обязан увидеть флажок первого.
Поэтому через этот while не пройдет.
Но здесь
нет прогресса, потому что
есть исполнение, где два потока
сначала пишут в своей флажке, потом
друг друга. Вот из этого
состояния они уже не выйдут по этому коду.
Можно сделать чуть лучше.
Не то, что лучше, по-другому можно
сделать.
У нас здесь только один atomic victim
и поток, когда приходит
в lock, говорит, что вот я жертва,
я жертвую собой в пользу другого.
Гарантирует ли эта реализация взаимное исключение?
Уже не очевидно, да?
Почему это?
Ну давай докажем, что
гарантирует.
Давай докажем, что гарантирует.
Вот здесь два потока, они находятся
между lock и unlock. Почему они находятся
между lock и unlock? Потому что они
увидели разные
диктимы, да?
Это же единственный способ пройти через
этот цикл?
Ну это будет удивительно, конечно.
Я бы не стал это тратить на это время,
честно говоря.
А причем тут safety?
Нет, то, что где-то кто-то зависнет,
это не гарантия safety. Safety это то, что
между lock и unlock двух потоков быть не может.
Вот если два потока между lock и unlock
находятся, то
среди них есть тот, кто написал
victim первым, и тот, кто написал
вторым. Ну так второй не пройдет дальше.
Так вот, еще раз, мы учимся разделять
два свойства safety и liveness.
Гарантия безопасности, гарантия прогресса.
Безопасность здесь снова есть,
прогресса снова нет.
Но прогресса нет в другом смысле.
Вот здесь прогресса не было, потому что
до потока могли друг другу помешать.
То есть, когда они находятся
между lock и lock,
то они находятся в другом смысле.
И вот здесь мы можем
определить, что это гарантия
safety и liveness.
То есть, когда они
блокировали друг друга, то они
в смысле потоки зависали,
когда их было двое.
Здесь же, когда потоков двое, один из них
точно не зависнет. Один из них точно пройдет.
Но если поток один, то он
захватить на Мютекс не сможет, что довольно тупо.
Вот, поэтому мы приходим
к Мютексу Петерсена, классическому,
самому старому протоколу взаимного
исключения, где совмещаются
два неправильных метода.
Мы выполняем и первую строчку, и вторую, и совмещаем
условия ожидания. То есть, мы ждем
другого, если другой тоже
хочет попасть в критическую секцию,
и при этом жертвует
о мы. То есть, мы пришли последними.
То есть, мы проходим
либо если мы не
пришли последними, либо
наш сосед не хочет, наш конкурент
не хочет захватить блокировку.
Ну и, конечно, это не универсальный
способ, в смысле совмещать два неправильных
решения, обычно это не работает. Но здесь
это работает.
Ну и давайте, я не знаю, подумаем, почему
это работает.
Ну, это
два флажка атомарных,
которые означают, что поток,
который в них что-то записал, желает захватить
блокировку. Смысл у них такой,
поэтому такое название.
Мы сбрасываем флажок
снова, что мы не хотим
больше.
Мы сбрасываем этот флажок, и если нас ждали,
то мы пробегаем, то другой пробегает вперед.
Один минус индекс
это наш конкурент. Ну, то есть, если
у нас номер индекс, а
load – это чтение ячейки памяти, чтение
атомика. Store и load – две операции.
Запись чтения.
Такое, конечно, может быть.
Но мы же перечитаем его здесь,
мы же в цикле крутимся.
Да?
Ну, давайте подумаем, почему это
работает.
Опять, пусть два потока нарушают
взаимные исключения, находятся между локом
и отлоком. Ну, давайте
среди них выберем тот, кто записал
виктим последним.
Тогда что происходит?
Ну, тогда, видимо, другой поток
обязан сейчас
аккуратно.
Нет, жертва через вайл не может пройти
как раз.
Все кроме жертвы могут пройти через вайл,
ну, в смысле, все другой поток.
Ну, вот.
Два потока.
Мы предполагаем, что если мы используем
атомики, то мы можем
рассуждать об исполнении этой
программы с помощью модели чередования.
То есть, как будто бы все шаги происходят
по одному. Ну, и что мы дальше
говорим? Посмотрим на поток, который записал
виктим вторым.
Предположение, что здесь первый и второй.
Не по индексам, а вот
по порядку записи в этой
ячейку памяти.
И он при этом между локом и отлоком.
Но что же он увидит в этом цикле?
Если он записал
виктим вторым, то, во-первых, он
видит здесь себя,
а еще он знает, что его...
Ну, не то, что он знает, он не знает, но мы знаем
по нашему предположению, что другой поток
уже сделал запись виктим,
а значит, он сделал запись в флажок want
в свою ячейку. И значит,
мы этот флажок видим, и снова он нам мешает
пройти. Нам и это правило мешает пройти,
и это правило мешает пройти, и тогда непонятно,
как же мы оказались, как же мы
завершили вызов лог.
Вот, то есть,
эта
реализация обеспечивает сейфти все еще,
но теперь она обеспечивает и лайвнес,
то есть, она обеспечивает прогресс, потому что
если поток один, то он уже не может бесконечно
кружиться в этом цикле, потому что у соседа не будет флажка вон.
Если же потоков двое, то они не смогут оба кружиться,
потому что для этого они должны видеть разные значения виктима.
Только тут двойной лог, он сработает, как если бы он был анлоком в некотором смысле.
Сейчас, я вот это не готов понимать.
Если в одном потоке вызвать лог два раза подряд...
то это получается undefined behavior.
В смысле, не делайте так, не рассуждайте так, что будет, если вызвать лог дважды,
или вызвать анлок без лока, это все все плюс-плюс неопределенное поведение.
В конкретной реализации будет что-то конкретное, а в общем случае никаких гарантий вам не дается.
Это просто неправильное использование мютокса.
У вас должны быть лог, потом анлок. Вот и все.
А это вообще, кстати говоря, хорошо, что вы просто постоянно в айле крутимся?
Это плохо, но до этого нужно еще дойти. Это вообще никуда не годится.
Так писать не нужно, только код нужно удалять сразу.
Но давайте пока маленькую логическую задачу решим.
Вот у нас есть мютокс для двух потоков. Как сделать мютокс для N потоков?
Опять же, мы живем в предположении, что у нас потоки пронумерованы, это нам сильно упрощает жизнь.
Вот есть потоки с номерами от 0 до N, минус 1, и нам нужно собрать мютокс для N потоков.
Вот такая вот бесполезная разминка для ума, ну почти бесполезная.
Делать логариф Максом мютокс?
Как-нибудь попроще объясни мне свою мысль, чтобы я понял.
Я хочу, чтобы у каждого мютокса был номер, и он представлялся в виде двоичной последовательности.
И вот мютокс на каждый разряд.
Ну это похоже, это можно описать гораздо проще. Можно дерево построить, вот ты же про это на самом деле говоришь.
И мы собираем такое вот дерево, Tournament Tree, из этих блоков мютоксов Петерсена,
и поток по нему взбирается, обыгрывая конкурентов, и в конце концов падает в критическую секцию.
В этом нет никакого смысла, вот просто забудьте это сейчас же.
И вот это почти что можно забыть.
Наша цель не в этом. Наша цель была вот сейчас в этом примере продемонстрировать,
ну вот этими примерами продемонстрировать две вещи.
Первая мысль. Видите, нам чтобы сделать взаимное исключение для n потоков,
нужно удобно знать их номера.
Ну мы не пытались иначе, я просто так условия задал, но это было удобно.
Но в Mutex Log и Mutex Unlock этого нет, никаких номеров в стандартной библиотеке.
А еще нам потребовалось много ячеек памяти.
Вот у нас здесь линейное количество Mutex,
и для этих Mutex по 3 ячейки внутри можно ли эффективнее сделать?
Ну или по-другому, можно ли сделать эффективнее, если использовать что-то кроме обычных операций Store и Load у Atomic?
Ну вот мы к этому и идем. Сейчас к тому, что в процессоре есть более эффективные операции,
чем Load и Store, просто чтение и запись.
Для синхронизации, возможно, можно придумать что-то эффективнее.
Но это вторая мысль, которую я хочу прийти и дальше продолжить.
А пока маленькая, ну то ли шутка, это не шутка, на самом деле, очень не смешно вообще то, что сейчас будет.
Вот смотрите, в теории у вас есть лог Петерсона, и мы вроде бы сейчас доказали, что он обеспечивает взаимные исключения.
Мы не должны в этом сомневаться, да?
Вы сомневаетесь, да?
Там вроде не в чем сомневаться, все слишком просто.
Но смотрите, я вам сейчас покажу некоторый код.
Вот две ячейки памяти X и Y, типа IN.
Два потока. Мы в первом потоке читаем, пишем в X единицу, сначала там ноль, потом читаем из Y, в свою локальную переменную.
То есть с этими ячейками работают оба потока, а второй поток делает симметрично.
Он пишет в Y и читает из X.
Вот R1 и R2 – это такие локальные ячейки памяти для потоков, с ними работает только T1 и T2.
X и Y – они разделяемые. Мы здесь пишем, вы здесь читаем из X.
Они не атомики.
Но смотрите, процессор вообще-то пишет в 64-битные слова выровненные, а компилятор, конечно, это выравнивает все.
Атомарно. Вот если вы пишете в INT из одного потока, а из другого вы читаете, то нет никаких шансов, что чтение будет половину записи, половину бит от старого значения, половину от нового.
Нет, так не будет.
Я же говорю, что атомик INT представляется в памяти как просто INT, они одинаково представлены, просто ячейка памяти.
И вот я написал такой код. Почему он мне интересен? На что он похож?
Вот мы только что делали мьютинг для двух потоков. Вот мы здесь, смотрите, пишем свой флажок, читаем из соседнего, из флажка соседа, конкурента нашего.
Вот здесь же тоже самое написано, правда? Пишем в X, читаем из Y, пишем в Y, читаем из X.
А потом проверяем, верно ли, что R1, R2 равны нулю оба. И если так, то наш процессор сломан.
Ну, потому что, ну как, у нас первые шаги в обоих потоках – это запись либо X, либо Y. Как же здесь можно прочесть оба нуля, спросите вы, да?
Ну, это такая вывернутая логика, так, надеюсь, люди не рассуждают. Вот если бы показать, не знаю, ребенку такой код, то что он подумает?
Может ли получиться два нуля? Конечно же, нет. Вот. Ну, давайте узнаем. Давайте.
Ну, вообще этот… Не, сломался. Вот тут очень сильно зависит от того, как он нагружен. Вот если не записывать видео и не открывать 10 приложений, то падает быстрее.
Ну, в общем, два нуля получились. Процессор сломан, и Mutex не работает, Петерсона. Это довольно печально.
Вот. Ну, то есть, можно сделать так, чтобы прямо Mutex с Петерсоном не работал. Можно его переписать на просто Bool и Insight, St, не важно.
А вы С0 собирали? Что? Вы С0 собирали или чем повыше? С0, ну он даже с 0 упал. Да, тут есть, на самом деле, некоторая тонкость, потому что все-таки тут еще кое-что нужно написать.
То есть, тут есть какой-то барьер для компилятора, чтобы было совсем честно. Но вот он есть, а все равно ломается. Это такая…
В аудитории появился очень хитрый студент, который забегает далеко вперед. Фенсы, заборы, вот эти барьеры памяти – это сложная история.
Это сложная история, и цель наших лекций про модели памяти, которая будет еще когда-то, состоит в том, чтобы вы не думали про барьеры памяти.
Это неправильный способ об этом рассуждать. Но да, если поставить барьер памяти, то, конечно, эта проблема исправится.
Собственно, для этого они и существуют в процессоре. Но вот сам по себе процессор, смотрите, он гарантирует, что работа с каждым отдельным интом атомарна,
действительно, каждый отдельный ячейк памяти атомарна, но почему-то об их совокупности больше нельзя рассуждать в модели чередования.
Вот вам об этом говорят прямо в документации процессора. На ARM еще веселее, там гораздо больше таких сценариев странных.
Вот почему так? Это сложный вопрос, но пока вот просто имейте в виду, что рассуждать об исполнении программы как вот о таком последовательном исполнении всех инструкций
с перепрыгиванием между потоками, вот эта модель, она в реальности не работает.
Ну, Мьютокс Петерсон, он в верных предположениях, что вот у нас модель чередования. Модель чередования прямо из коробки в процессоре не работает, не обеспечивается.
Чтобы она работала, чтобы ей можно было пользоваться, нужно соблюсти ряд довольно хитрых условий, которые невозможно сейчас объяснить, а в первом приближении нужно использовать атомики.
Ну ладно, перестанем о плохом говорить, поговорим о хорошем. Мы хотим все-таки сделать что-то, ну в смысле Мьютокс как-то эффективнее.
А с атомиками работает Мьютокс Петерсон?
Да, работает. Ну разумеется. Ну в смысле потому что атомики дают, я сказал, почти сами по себе дают модель чередования, а в модели чередования мы доказали, что Мьютокс корректен.
Ну Мьютокс Петерсон на самом по себе никому не нужен, он скорее нужен для демонстрации этого примера.
А вот то, что мы сейчас поговорим, очень полезно и полезно, например, в ядре. Линуксы используются повсюду.
Мы хотим сделать протокол взаимоскучения эффективнее в том смысле, что мы хотим использовать меньше ячеек памяти и сделать быстрый путь, когда, например, Мьютокс свободен гораздо эффективнее, чем подъем по этому странному дереву.
Для этого в процессоре, собственно, есть такая понятная задача сделать протокол взаимоскучения.
Раз уж процессор дал вам ядра, он вам дает и какие-то дополнительные механизмы, чтобы эту задачу эффективно решать.
Эти инструменты называются Read-Modify-Write-операция.
То есть вы можете в ячеек памяти не только записать что-то и прочесть, вы можете сделать что-то более хитрое из трех шагов.
Прочесть, как-то модифицировать, а потом записать и сделать это атомарно.
Ну и тут можно обратиться к документации, посмотреть на Atomic.
Вот тут есть какие-то вызовы Store, Load. Store, Load мы уже обсудили. Есть Exchange, есть Comperexchange.
Есть FetchAdd, FetchSub, какие-то разные Fetch что-то, что-нибудь.
Вот давайте коротко по ним прибежим. Store и Load – это понятно. Это записи, чтения, соответственно.
А вот есть FetchAdd. Это атомарная операция, которая читает значение ячеек памяти Atomic,
добавляет к нему аргумент и записывает результат обратного Atomic – ячеек памяти.
И все это происходит атомарно в том смысле, что другие операции, скажем, другие лоды не могут увидеть…
Два FetchAd не могут как-то странно пересечься. Они не могут, скажем, увидеть одно и то же исходное значение.
Если вы делаете FetchAdd единица, то вот оба FetchAd, двух потока, то оба FetchAd обязаны вернуть разные значения.
Они не могут вернуть одно и то же. Они атомарны друг относительно друга.
Есть операция xchange, которая про то, чтобы атомарно прочесть старое значение и записать новое значение.
Ну и что мы можем с ними делать? Мы можем с помощью этих операций делать так называемые спинлоги.
Вот давайте воспользуемся операцией xchange.
Это Read, а это Write. А это Modify.
Ну вот потому что они вот так вот называются.
Три шага. Здесь два шага, здесь по одному шагу.
Ну вот. Простейший спинлог.
Как сделать протокол взаимного исключения с помощью одного единственного AtomicBool,
по сути, логически одного бита, имея атомарную операцию xchange.
Атомарно прочесть и записать новое значение.
Ну вот так вот. Давайте посмотрим на нее несколько секунд и поймем, как она работает.
Ну вот. Тут единственное поле, Locked. Там написано, верно ли, что спинлог сейчас захвачен или он свободен.
Если True, то захвачен, если False, то свободен.
Если мы хотим его захватить, то мы атомарно пытаемся записать в него True.
И если мы записали True, а там был False, то мы захватили его, мы были первыми.
Если мы были не первыми, то мы записали True все же, но при этом и прочитали True.
И значит спинлог был захвачен кем-то другим уже. Мы попробуем снова.
Мы опять сейчас с Валей сидим.
Совершенно верно. Мы по-прежнему ничего хорошего здесь не написали.
Но наш код стал гораздо проще. Вот такой код освоит любой первоклассник.
Понятно ли он?
Хорошо. Есть ли в нем недостатки?
Кроме того, что он вращается в этом цикле, греет процессор.
Он не гарантирует, что поток, который зашел в Lock, когда-нибудь из него выйдет.
Прямо скажем, маловероятно, что кто-то будет постоянно проигрывать,
а другие будут его опережать бесконечно долго.
Но все же гарантии прогресса для каждого потока здесь нет.
Как обеспечить прогресс для каждого потока?
Поставить их в очередь.
Поставить их в очередь, да.
И для этого есть...
Для этого есть другая операция. Она называется...
Сейчас, по-другому немного.
Давайте откатимся на один шаг назад.
И прежде чем делать очередь с помощью другой атомарной операции,
поговорим, собственно, про эту атомарную операцию.
Вот фич ad.
Атомарно прочесть, увеличить или уменьшить, записать.
Новое значение.
Вот где такая операция может быть...
Уже могла быть вами использована, даже если вы об этом не знаете.
Оказывается, что shared pointer для счетчика ссылок
использует атомарные инкременты и декременты,
даже если это вам не нужно.
Это не заслуга shared pointer, это его изъян.
Но вот, тем не менее, счетчик ссылок там атомарен,
потому что с shared pointer в определенных границах
можно работать из разных потоков.
Так вот, фич это нужен, потому что сама по себе
операция инкремента не атомарна.
Мы сначала должны загрузить значение в регистр,
увеличить регистр на единицу, потом загрузить из регистр
обратно в память значение новое.
И вот точно так же, как со строчками в списке,
вот эти инструкции могут...
Эти три инструкции, исполняемые параллельно на двух ядрах,
могут переплетаться друг с другом.
И в итоге мы можем дважды загрузить одно и то же значение,
дважды его увеличить, потом дважды записать одно и то же.
И мы потеряем один инкремент.
Два инкремента исполнятся, но эффект будет как от одного.
Ну, если у нас есть все же операция,
которая умеет делать такой инкремент атомарно
и возвращать при этом старое значение,
то мы можем сделать из этой операции ticket log.
Вот буквально очередь, которую вы можете наблюдать,
не знаю, где-нибудь в Сбербанке.
Вы приходите, отрываете себе номерок,
то есть говорите фич add,
добавляете свой уникальный монотонный номер,
который не может повториться,
потому что все фич add атомарны, они стоят на друг друга.
А дальше просто смотрите на табло и ждете, когда ваш номер совпадет.
Итого вам нужно два атомика.
Один из них говорит, какой номерок будет следующим,
а второй атомик говорит, кто сейчас владеет блокировкой.
Ну и вот вы приходите, говорите с помощью фич add,
с помощью фич add получаете номерок,
а дальше ждете, пока он не сгорится на табло.
Кто двигает табло вперед, тот, кто вызывает анлок.
— А что делать, если мы дойдем до максимального значения?
— Мы никогда не дойдем до максимального значения N64.
Нет.
Но вы можете посчитать, взять свой процессор,
тактовую частоту, взять диапазон значений,
поделить, посмотреть, сколько лет потребуется.
Нет, этого не случится.
— Можно ли использовать N84?
— А?
— Можно ли использовать N84?
— Ну, чтобы стало хуже?
— Ну, тогда мы дойдем.
— Может быть не 128, вот не знаю.
— 128 вот можешь, но не везде.
Так, ну у нас заканчивается время,
а мы не поговорили про самое важное,
что нам так хотелось узнать.
Вот нас беспокоит, смотрите, что мы пишем вот такие спинлоки,
они очень простые, но при этом у нас здесь какая-то тупизна написана.
Мы крутимся в цикле, греем процессор.
Можно здесь написать что-то лучшее?
— Конечно, можно, да.
И вот смотрите, что можно сделать в первую очередь.
Ну, во-первых, вот то, что мы сделали,
называется busy weighting, и вот это называется спинлоки.
Вот спинлок — это когда вы крутитесь на процессоре,
то есть вы хотите получить блокировку,
но при этом вы верите, что надолго
и другие потоки не займут, поэтому вы лучше покрутитесь
и дождетесь прямо на процессоре, не снимаясь с него.
Ну вот, чтобы крутиться было приятнее процессору,
а не вам, у процессора есть специальная инструкция,
которая называется пауз.
Вот я сейчас открою документацию для нее.
Она про то, чтобы, ну грубо говоря,
логическое гиперядро, гипертрединг в смысле,
гиперпоток в процессоре,
встал на небольшую паузу,
отдал инструкции своему соседу,
другому гипертреду.
Ну, в общем, поменьше тратил,
уменьшил энергопотребление,
и отдал процессору возможность
исполнять сейчас что-то другое.
То есть вы говорите явно, то есть у вас есть хинт
для процессора, что вот вы буквально написали спинлок
и вы там ждете. Вот в процессоре для этого есть специальная
инструкция. Я поток, в спинлоке кручусь.
Можно как-то на меня тратить меньше ресурсов.
Можно не прогружать там конвейер.
Зачем мне конвейер?
Но если вы будете крутиться долго, все равно вы пожираете ядро,
вы занимаете место, которое могли бы занять другие.
Что у вас есть дальше?
В этом курсе не будет сигналов.
Давайте мы про них забудем сразу навсегда.
Есть вызов yield. Но yield вы уже наверное с ним познакомились
в другом контексте, но смысл тот же самый.
Вы говорите, я готов уступить ядро другому потоку,
потому что прямо сейчас мне делать нечего.
Я готов уйти с ядра.
Разумно на практике их комбинировать.
В смысле сначала некоторое время крутиться на ядре,
потом перепланироваться через планировщик.
Потом с ядра уходить. Делать это не сразу,
потому что если критическая секция короткая у другого потока,
если прямо сейчас почти мютекс спинлок освободится,
вы тут же его подхватите и начнете делать полезную работу.
Скажем, если вы пишете на языке,
на языке Rust, там есть библиотека, которая называется Crossbeam,
таких вот базовых примитивов для синхронизации, очень низкоуровневых.
И там есть объект, который называется Backoff,
который позволяет крутиться более эффективно.
Ну в смысле сначала адаптивно делать пауз,
потом переключаться на yield.
В домашних работах, пожалуйста, для этого используйте
вот такой вот класс, который делает то же самое.
Вы его создаете, вы его используете,
и крутитесь, вызывая вот оператор кругу из скобочки,
а он там делает то, что он считает разумным.
Это лучше, чем просто писать ничего.
Вот, но теперь последнее, самое главное.
Если же вы все-таки устали крутиться,
то что разумно сделать?
Ну все-таки покинуть ядро и не исполняться до тех пор,
пока не наступит событие.
Событие другого не исполняется.
Вот не исполняться и ожидать чего-то,
это то, что вы не можете сделать C++,
потому что, ну как и в случае с yield,
вы должны обратиться к планировщику,
только планировщик вам может помочь.
Поэтому у вас есть сискол,
который называется FUTEX.
Он очень сложный, но грубо говоря,
у него есть две операции,
которые в атомике тоже есть,
и выглядят они немного иначе.
Это операция wait и notify.
Симантика такая,
вы блокируете поток,
если в атомике прямо сейчас лежит значение,
которое равно вот этому.
Это очень странно, что вы почему-то сравниваете
с каким-то значением.
Вы видите, что это не странно,
что это очень естественно,
но для этого нужно как-то подумать.
И у вас есть парный вызов notify,
который будет поток, который ждет в wait.
Правда, wait потом просыпается и перепроверяет,
что значение изменилось.
Если не изменилось, то снова засыпает.
Вот это чуть больше, чем вызов FUTEX делает,
в домашке, вы там можете это все подробнее подсчитать.
И вот тогда вы получаете то,
что называется sleep lock или MUTOX.
MUTOX спят, спинлоки крутятся и не засыпают.
В этом разница.
Ну ладно, мы задержались, я кое-что не успеваю рассказать.
Давайте расскажу, зачем нам MUTOX
и как мы будем дальше с ними работать.
С помощью MUTOX мы будем делать синхронизацию,
в домашке вы попробуете написать свои MUTOX
и свои атомики, и вот неизбежно поймете, что это.
Ну а дальше у нас цель такая,
я вот обещал, что мы хотим написать свой маленький GO,
и там будут свои маленькие MUTOX.
И смысл всей этой конструкции в том, что они будут легковесными,
в смысле мы можем блокировать наш легковесный поток,
Fiber, при этом не погружаясь в ядро,
не спрашивая операционную систему,
а просто в очередь заснуть, подождать,
мы должны будем делать это сами в user space.
И вот вы сначала сделаете MUTOX сами для потоков,
поймете, как их делать с помощью FUTOX,
а потом когда-нибудь, когда вы дойдете до этого,
мы переизобретем FUTOX и напишем их сами,
и тогда получится уже runtime GO
прямо в user space, прямо вашими руками.
И второе направление, в котором мы улучшим MUTOX,
это спинлок, вот такой вот спинлок, совершенно примитивный.
Можно очень сильно оптимизировать,
если вы знаете, как устроен процессор и память,
как устроено их взаимодействие.
Это не просто процессор и память,
между ними много всего происходит еще сложного.
И если вы понимаете, как работает компьютер, как устроен процессор,
то вы можете буквально написать одну строчку или полторы строчки,
и эта конструкция станет гораздо-гораздо эффективней.
Спинлок, он, конечно же, никуда не годится.
Не пишите его никуда, на работе пока.
Ладно, все, спасибо большое.
До свидания всем.
