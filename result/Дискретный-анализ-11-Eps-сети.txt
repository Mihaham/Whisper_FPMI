Наверное, придется напомнить лему, как она у нас звучала.
Пусть размерность вапника и черванемки с какого транжированного
пространства равняется D, ну а мощность множества, из которого выбираются вот
эти вот рейнджи, она N. Тогда
мощность R не больше, чем ж от Nd,
которая представляет собой сумму, пока от 0 до D, с из N пока. Ну это я доказал,
индукции доказал, все вроде аккуратно сделал, я не знаю, все ли присутствующие были на прошлое,
нехуй, но вот мы это сделали. Знаете, я еще замечу, что вот это не превосходит N в степени D,
ну докажете сами, как бы то, что с из N пока не превосходит N в степени D, это очевидно,
с из N пока не превосходит N в степени D, поделить на D факториал, как известно. Ну там все-таки
сумма, но она не слишком накапливается, в общем, можно доказать, что это не больше, чем N в степени D.
В принципе, если вдруг кого-то не получится так, ну это не так существенно, можно чуть похуже
оценку написать, но мы это сейчас используем в некотором контексте. Следствия из этой леммы,
которая я не писал в прошлый раз, но которая, в общем, очевидна, пусть опять же дано какое-то
пространство размерности D, ну и, наверное, давайте считать, что тут уже неважно, какой X,
может быть, как в конечном, так и бесконечном. Давайте пусть A, это E, которая подножит мощность N,
тогда мощность проекции на A множество R не больше, чем G от N-D.
Ну вроде понятно, да? Мы просто рассматриваем такое подпространство A, запятая проекция на
множество R, это подпространство в исходном пространстве XR. Понятно, что размерность этой
штуки по-прежнему не больше, чем D, а мощность A у нас по условию N. Ну, лемма говорит о том,
что размер проекции, то есть вот эта вот система областей, действительно не больше, чем G.
Следствие является очень простым следствием из леммы, но сейчас вы увидите, что оно полезно,
как вам ключи. Так, давайте сформулируем еще одну лему. А, ну давайте я вот тут дам определение,
потом сформулирую лему. Вот если у нас есть какое-то число h больше либо равное двойке,
натурально, и есть наша система под множество R, ну какая-то система под множество на множество
X, то давайте через R с индексом h обозначим совокупность, состоящую из всевозможных
пересечений множеств R1, Rh, таких что каждая рытая является элементом исходной совокупности R.
Мы берем совокупность каких-то областей R и рассматриваем всевозможные, сейчас скажу такое
слово, по-h-ные пересечения. Ну если h равно 2, то по-парные, если h равно 3, то по-тройные.
Все возможные пересечения h каких-то под множество R. При этом я не говорю, что они обязаны быть
разными, то есть в том числе можно пересекать и совпадающие. Важно только, чтобы сами вот эти
вот результирующие множества получились разными, то есть R с индексом h это не мультимножество,
это именно совокупность различных множеств, которые получаются в результате тех или иных
пересечений. Называется эта штука h измельчений, ну просто для света, h измельчи. Чтобы вам не было
слишком абстрактно, жизни не казалось слишком абстрактной, не было грустно от этого. Давайте
вспомним затрафку, с которой все началось в прошлый раз. Помните, там были треугольники на плоскости?
Были? Вот помните, в то же время было такое ранжированное пространство Rn и h красивое
я нарисовал. Значит Rn это объемлющее множество x, а h красивое состояло из всех открытых
полупространств. Было так? Мы даже посчитали у него размерность, она оказалась равной n плюс 1,
помозли теория Мародона, которую я не доказывал, но которая не сложная. Мы доказали, что это n
плюс 8. Так, ну а теперь представьте себе, что я беру вот такое вот пространство h на плоскости,
пусть у меня R2 и h. Беру h маленькое равное 3 и рассматриваю h с индексом 3, ну вот в этом смысле.
Беру три измельчения множества полуплоскостей открытых, которые возникают на обычной плоскости.
Что из себя представляет такое три измельчения? Нет, мы рассматриваем, смотрите, вот здесь
содержатся полуплоскости. И вот мы их потройно пересекаем, каждые три из них пересекаем. В частности
получаются, конечно, все треугольники, но и в основном получаются треугольники, за исключением
множества, так сказать, меры ноль ситуации, когда две полуплоскости параллельны, тогда получается не
треугольник. Но если у вас и плоскости находятся в общем положении, картинка вот такая, возникает с
вероятностью 1, в обычном смысле слова, а такая с вероятностью ноль, то тут получается треугольник
на пересечении вакурато тот самый. Что? Ну или одна из этих частей. Да-да-да, я согласен. То есть,
если мы, например, обозначим через t с индексом 3 множество всех треугольников, именно треугольников
на плоскости, то, конечно, h3 будет просто содержать внутри себя вот этот t с индексом 3.
Что? h3 это множество всех пересечений трех полуплоскостей.
Ну это r3, да, но r у нас обозначается h, поэтому я к нему пририсовал троечку. Ну я вроде так и
сказал, да. То есть r у меня сейчас обозначена буквой h, поэтому r3 это h3, а t3 это множество
треугольников. Оно содержится в этом h3, не важно, что оно почти все и заполняет там,
по большому счету. Главное, что содержится. То есть это как-то пространство что-то. Так вот,
что говорит Лемма? Лемма говорит, что пусть размерность какого-то пространства xr равняется d,
пусть h больше не бы равняется двойке, тогда
размерность вот такого пространства не превосходит вот такой
размер. Ну, смотрите, я на самом деле не очень держусь именно за эту величину. Я не буду
аккуратно доказывать, что оценка получится именно такая. Принципиально, конечно, для меня,
что оценка есть. То есть если у нас дано пространство конечной размерности, то его
измельчение тоже имеет конечную размерность. Но это ожидаемо, конечно. Но почему это так,
я сейчас докажу. Понятно утверждение? Давайте докажем. Не, да просто. Ну,
давайте рассмотрим какое-нибудь множество, которое дробится. Пусть есть какое-то а из x
и а. А, сейчас, дробится чем? Дробится рh, да? Да, дробится рh.
Так, ну сейчас сообразим, что значит дробится рh, да? Дробится рh. Так, ну пусть
мощность а, это какое t? Пусть а, ну, мощность t и дробится с помощью системы, вот этой измельченной
системы областей r с индексом h. Так, с одной стороны, давайте я прям так напишу, с одной
стороны, мощность проекции на а в совокупности областей r с индексом h не больше, чем что.
Или давайте не так, давайте не больше, это, наверное, в ходу не очевидно. Давайте наоборот, равна.
Ну, равна-то она, конечно, во в степени n, что тут говорить. Если а дробится, значит,
мощность проекции это просто 2 венны, где n это мощность а. Дробится, значит, в проекции
находятся все возможные подмножения. По определению просто а дробится, если там находятся,
вот в этой проекции находится все возможные подмножения. А сейчас я с другой стороны это оценю сверху,
да, да, вот сейчас будет применено следствие из той ленты. С другой стороны, с другой стороны,
знаете, я вот как скажу, мощность проекции на а, давайте для начала исходного r. Так,
проще. Вот мощность проекции на а, исходного r. Она согласна следствию, ну, давайте я схожу
к этому следствию, чтобы камера туда повернулась. Вот, вот, следствие. Чего она не превосходит?
Тогда мощность проекции не больше, чем, ну, g от nd. Прям в точности g от nd это вот следствие нам
дает. Ну, и я просил вас доказать, что это не больше, чем n в степени d, но я повторю,
что именно такая величина оценки нужна, чтобы в конечном счете получить вот это неравенство,
а поскольку я его строго доказывать сейчас не хочу, ну, вы сейчас увидите до какой степени
строгости я дойду, то, в общем, не так важно, какую вы здесь оценку получите, можно и ухудшить.
Вот, ну, пусть будет n в степени d. Так, ну, отсюда следует, что мощность проекции на а измельчение,
аж измельчение, ну, я утверждаю, я не буду вас спрашивать, я сам скажу, не больше, чем n в степени d,
аж. Я, как бы, полагаю, что это очевидно, но я поясню. Ну, мы просто между собою пересекаем
любые аж штук множеств, которые к нами находятся в совокупности, мощность которой не больше,
чем n в степени d. То есть исходных множеств не больше, чем n в степени d, и мы их еще комбинируем
по аж штук по аж штук в каждом пересечении. Мы просто n в d и возводим еще в аж той степени.
Но она не то чтобы очень грубая, потому что, помните, я оговорился, что они совпадать могут.
Ну, я сказал, что вот в этих пересечениях разрешено, чтобы r1 аж совпадали. Видите,
вот здесь в определении не сказано, что они все попарно различные, сказано только, что каждый
из них находится в аж. Поэтому это, в общем, не то чтобы очень большое огрубление, хотя с точки
зрения задачи про треугольники можно было бы разрешить им быть разными, и тогда была бы немножко
грубая ажность. Ну, не важно. Ну, есть такая оценка. Ну, смотрите, что отсюда следует. Отсюда
следует, что если n в степени d меньше, чем 2 в степени n, то противоречие.
Ну, то есть не может дробиться множество, у которого n таково, что выполнено вот это неравенство. Если бы
мощность множества равнялась n и множество дробилось, то вот столько было бы элементов
проекции. Но мы точно знаем, что их не больше, чем столько. Поэтому если бы вдруг оказалось,
что эта верхняя граница, в свою очередь, строго и меньше, чем ожидаемая величина, то это бы
означало, что а не дробится. Все, что утверждает Лемма, Лемма утверждает, то если в качестве n взять
вот это 2dh и лог двоичный dh, ну там какую-нибудь верхнюю целую часть, нижнюю целую часть, если в
качестве n взять вот эту величину, то таки будет выполнено вот это неравенство.
Но отсюда и следует, что размер максимального дробящегося множества заведомо не превосходит
эту величину. Наверное, надо брать не верхнюю, а нижнюю целую часть, чтобы быть корректным
формулировками. Берем любое множество вот такой мощности и уже получаем, что выполнено вот это
неравенство. То, что оно рано или поздно будет выполнено, товарищи, я надеюсь, всем понятно,
dh это какая-то константа, то есть здесь стоит многочлен n в степени dh, а здесь стоит экспонент.
Ну ясно, что существует момент, начиная с которого это неравенство будет выполняться. Вот Лемма
утверждает, что момент находится в этой точке. Ну по крайней мере не выше нее уже случается вот
это переключение. Понятно? Вот я не буду требовать на экзамене, чтобы вы аккуратно проверяли,
что именно такой вот n подставим сюда, оно для всех вообще dh, какие возможно,
будут удовлетворять этому неравенству. Ну просто важно понимать, что вот как-то так будет.
Я внимаю, не? Сейчас будет ну такой как бы маленький катарсис, что ли. Вот, ну может быть,
но через какое-то время. Пока чего мы понимаем, смотрите, давайте посчитаем размерность пространства,
я доказал Лему, давайте посчитаем размерность пространства вот такого r2 и t3, но не посчитаем,
а оценим исходя из полученных результатов. Посчитать это можно на самом деле, она там какая-то
не очень большая, то есть нельзя сказать, что это тяжелая задача взять и явно посчитать вот эту
размерность. Но я из общей теории выведу какую-то может быть очень грубую оценку. Грубая оценка
получается как? Ну, она получается 2dh log2dh, где h равняется тройке, а d чему равняется?
Написано на доске, d тоже равняется тройке, вот написано на доске. t3 это под множество,
множество всех этих пересечений трех плоскостей в h3. t3 это под множество в h3.
Если вы возьмете r2 h3, ну просто r2 h3 будет 3, ну надо взять r2 h3, чтобы туда включилось вот
это вот пространство, где тоже равняется тройке. Смотрите, это равно 2 на 3 на 3 на log2dh 3d3. Так,
это 18 умножить на 2dh log2dh 9, который чуть-чуть больше чем 3. Давайте считать, что это меньше
60, потому что мне менее аккуратнее считать, но то, что это меньше 60 вроде очевидно. Ну вот,
это меньше 60, ну и хорошо. То есть это конечная разница, но на самом деле гораздо меньше 60 можно
руками посчитать, там будет гораздо меньше. Вот давайте запомним этот результат. Получили,
что меньше 60. Хорошо. Теперь я предлагаю обобщить теорему, сформулированную в прошлый раз,
на случай произвольного ранжированного пространства. В прошлый раз я формулировал
теорему про треугольники на плоскости, если помнить. Если мы берем систему представителей
для любой совокупности под множество, которое получается в результате пересечения исходного
множества с треугольниками, и при этом мы черпаем значимую долю от исходного множества точек,
то у нее удивительным образом всегда есть соп размера не больше, например, чем 10 тысяч,
если эпсилон доля. Это одна вторая. Ну я помню все наизусть, видите, из меня оно льется прямо. А вы
понимаете, чего я говорю, да? В чем там пафос-то был, что мы берем абсолютно любое множество
точек сколь угодно большой мощности на плоскости. Миллиард, там, квадриллион,
в 10 степени 10-10 тысяч раз. Не бесконечное, а конечное множество точек, любое, совершенно.
Дальше начинаем его пересекать с треугольниками и рассматриваем только такие пересечения,
которые содержат не меньше половины от общего числа точек. Но вот был их миллиард,
надо чтобы в каждом треугольнике, с которым мы пересекаем наше множество, содержалось 500
миллионов или больше точек. От миллиарда положить 500 миллионов, да? Вроде как их дофига этих под
множество, их много разных, вот они все мощности 500 миллионов и больше, если исходное множество
мощности миллиарда. И вот мы утверждаем, тем не менее, что всегда есть система общих представителей,
мощность которой не больше, чем 10 тысяч.
То еще раз. Здесь мы знаем только верхнюю оценку.
Нет, D это размерность исходного пространства, то есть вот этого без измельчений, до измельчения,
это пространство, состоящее просто из полуплоскостей. Вот у него в точности три размера.
Дальше мы его измельчаем в три раза, и вот в этом измельчении содержатся все треугольники.
Что тут? И D равно 3, и H равно 3. Конечно, я не исключаю, что можно треугольники получить как-то
иначе. И вообще, я не говорю, что размерность пространства треугольников это 60. Она гораздо
меньше, ее можно руками посчитать. Наверное, да. То есть если длинеет цепочку писать, то здесь
надо писать так. Vc от R2 T3 не больше, чем Vc от R2 H3, а она не больше, чем вот это вот произведение.
Конечно, конечно. Именно такая логика за этим была. Конечно. Я не утверждаю, что Vc от R2
и T3 это то же самое, что Vc от R2 и H3. Это, кстати, интересный вопрос. Я не думал об этом. Можете
подумать. Я утверждаю, что по-видимому и то, и другое можно посчитать явно не прибегая к
помощи общей теории. Но общая теория хороша, потому что представьте себе, что вы не треугольники
на плоскости рассматриваете, а в десятимерном пространстве берете пятидесятигранники. Ну
хрен вы уже там посчитаете явную размерность. А тут есть понятная оценка, которую можно
подставить. Да, она наверно завышенная, но зато она автоматом дает какой-то результат. Ладно,
давайте сформулируем общую теорему про систему представителей. Вот пусть у нас есть какое-то
XR, разъемное пространство. Рассмотрим A из X. Ну, дальше мы рассмотрим. Давайте рассмотрим
такое множество невозможных пересечений R и A, то R принадлежит R, и мощность R пересечена
с A больше либо равняется Epsilon на мощности A. Ну или можно обозначить мощность A буквы N,
тогда здесь будет Epsilon умножить на N. Ну, в общем, будем действовать так же точно, как мы действовали
с треугольниками на плоскости. Мы просто возьмем какое-то множество точек в X и будем его
пересекать со всевозможными областями, то есть это часть проекции R на A. Но это не вся проекция,
только проекция, состоящая из тех пересечений, которые черпают изрядную долю от исходного
множества. Понятно? Вот давайте назовем множество N из A, называется в этой науке Epsilon-сетью,
называется Epsilon-сетью, если оно является SOP для вот этой совокупности, если N это система
общих представителей для вот этой совокупности. Просто такой терм. Нас интересовала SOP,
но вот мы будем говорить Epsilon-сетью, потому что в этой науке так принято. Вот у нас есть A,
мы его пересекаем только со значимыми такими R, чтобы значимыми, в смысле, что они черпают
значимую часть от исходного A, вот эту Epsilon-часть, и хотим построить такую систему представителей,
она называется Epsilon-сетью. То самое у нас интересовало для треугольников, для тех же самых.
Вот теорема, доказанная вапникам и черванингисам, фактически доказанная ими. Они немножко в других,
как говорили, у них там были статистические оценки какие-то, я про это сейчас не буду. В
такой формулировке, как я сейчас ее даю, скорее она доказана двумя иностранцами, но, в общем,
это сейчас не так существенно. Давайте я фамилию напишу. Так вот их зовут, Faustler и Wenzel. Но это
фактически в общем вапник и черванингис, просто переписаны на соответствующем языке.
Значит, утверждение такое, если ВС-размерность пространства XR не больше какого-то D,
то для любого N и для любого A из X мощности N существует Epsilon-сеть,
но тут надо, видимо, было вставить для любого Epsilon 0.1. Забыл по Epsilon-Quantrum написать.
Для любого Epsilon, для любого N и для любого множества мощности N существует Epsilon-сеть
размера не больше чем 8D на Epsilon, лог двоичный от 8D на Epsilon. Ну, дайте я еще верхнюю целую
часть на всякий случай нарисую, чтобы точно было правильно. Ну, мини-катарсис обещан,
вот он сейчас будет, сию секунду. Вот у нас граница для размерности 3, 60. Вот умножьте ее на 8 и вы
получите 500 из прошлой лекции. Ну, я писал там, теорема была, что для треугольников оценка 500
поделить на Epsilon, лог двоичный 500 поделить на Epsilon. Для треугольников получаем как раз теорему,
сформулированную как затравка, на прошлой лекции. Получаем, на Epsilon, лог двоичный 480 на Epsilon,
но я в прошлый раз написал 500, потому что и так оценка завышена, ну подумаешь 2, прибавить для
ровного счета. Получилось 500. Ну, это, конечно, не полный катарсис, потому что теперь нам предстоит
доказывать эту теорию, но, по крайней мере, я объяснил, что она порождает это следствие за
счет грубости тех оценок, которые мы сейчас получили. Так, это я объяснил, понятно, да,
как получилось. Это действительно следствие отсюда, просто в общем случае. Все, ну теперь наша
цель доказать теорему ваплика Червоненкеса или Хауссера и Вельцля вот в этом виде. У нас есть
какое-то A, мощность его равна N. Давайте вот это обозначим буквой M, вот эту верхнюю целую часть,
которая послужит оценке размера SOP. Давайте ее обозначим M. Давайте построим, в кавычках построим,
выберем, наверное, лучше говорить случайное, мульти множество, ну или можно сказать размещение
с повторением. Наш стандарт. В терминологии построим случайное размещение с повторением
N, состоящее из элементов x1 и так далее, xn таких, что каждая x и t принадлежит нашему. Так,
ну что это значит? Это значит, что мы просто, есть еще один термин, делаем такую выборку с
возвращением. То есть мы берем и за случайные элементы, ну какой-то, x1. Он берется с вероятностью,
ой, тут не N, а M, конечно. Он берется с вероятностью 1 поделить на N. Это 1 поделить на N, на число
элементов. Просто выбираем на угад случайные элементы за. И возвращаем его на место,
после чего снова выбираем незавидимые. 1 от 2 там и так далее, элементы за. То есть они, в принципе,
все могут совпасть. Но я утверждаю, что с положительной вероятностью то, что мы
навыбираем, в общем и будет системой представителей. Не, ну идея-то тривиальная, стандартный
вероятностный метод. Давайте возьмем случайное множество и докажем, что оно такое, как нам нужно,
что оно таки образует соп. Заметьте, что идея здесь не такая, как в истории с сопами, которые были
общими. То есть там мы делали жадный алгоритм, случайность мы использовали совершенно для другого,
а вот в теореме в Африка черваненки со случайность как раз очень падит. Мы берем случайные элементы,
они могут совпасть, но понимаете, если они совпадут, ну мы их при желании отождествим,
просто совпадающий, но он такой только меньше станет. Нам-то нужно как можно меньшую соп построить.
Если какие-то совпадут, нам это только на руку. Вот. Так, понятно все, что происходит.
Ну очень хорошо. Давайте рассмотрим вредное событие.
Ну ладно, вредное событие, но событие, вероятность которого хотелось бы, чтобы было меньше единицы. То есть
мы посмотрим на ситуацию, когда случилось не то, чего мы хотели. Что из себя представляет такое
событие? Элементарными исходами в нашем вероятностном пространстве сейчас являются вот эти n большое.
Размещение с повторением. Каждое размещение с повторением это элементарное событие. Поэтому
вредное событие, давайте я его обозначу e1, там потом еще будет e2, готовьтесь. Значит вредное
событие e1 это множество таких размещений n, то есть множество таких элементарных исходов,
все корректно, все грамотно. Множество таких элементарных исходов, что существует r принадлежащее a,
такое, что r пересеченная с a имеет мощность больше либо равную epsilon n, но давайте я прямо
но напишу, чтобы было понятно в чем тут вредность, вредность этого события. Но r пересеченная с n большое,
пусто. Ну то есть n большое не оказалось системой представителей, не оказалось epsilon сетью.
А, r конечно не из a, да, rsr, да, извините. Спасибо, да, это опечатка, конечно, rsr большого. Найдется
такая область, которая пересекается с множеством a как нужно по значимой доле, по epsilon доле,
но тем не менее вот с n большое она-то не пересекается. Это вредное событие, если мы
докажем, что вероятность e1 меньше единицы, мы победим. Ну вот тут вот делается некий
опередной хитрый ход комбинаторно-веронятностный, до которого так вот сходу не додумаешься,
просто так оценить сложно. Делаем надстройку некую, некую вероятностную надстройку. Ну это
в каком смысле напоминает то, что мы в прошлом семестре делали, когда какие-то клики там
выбирали, когда красили граф случай, там дополнительную случайность добавляли. Сейчас
тоже добавим некую дополнительную случайность. А именно давайте теперь рассмотрим помимо n
большого еще t большое. Я его всегда обозначаю. Оно будет состоять из y1, yм и тут тоже y и t принадлежат
a. То есть это опять такое вот мультимножество размещения с повторениями, в котором элементы
могут совпадать. Каждый элемент выбирает вероятностью 1n. То есть t это то же самое,
что n. Просто еще одно такое вот случайное множество, построенное независимо от того,
каким было выбрано n большое. Оно может с ним совпасть, может быть вообще не пересекается,
ну как угодно. Возьмем дополнительное случайное мультимножество. Ну, конечно, я мог с самого
начала сказать, давайте его возьмем. E1 в этом случае как определяется? Это точно так же. Просто
элементарные вплоды это не n большое, а пары n большое и t большое. А дальше-то все то же самое.
От этого ничего не сказано. T любое. Не, ну E1 просто надо переинтерпретировать, потому что у нас
изменилось вероятностное пространство. Если сначала оно состояло просто из n, то теперь оно состоит
из пар. Нет, ну плохое событие. Давайте теперь вот здесь вот так напишем просто n и t такие же.
Никакого условия на t тут нет. Вот это вот плохое событие. Смотрите, ну недаром же я ввел t. Значит,
как я и обещал, будет некое событие, которое еще существенным образом будет зависеть от t. Но я
говорил, будет E2. Пишем E2. Ну это, естественно, снова множество пар mt. И начало будет прямо
идентичное тому, что написано в E1, то есть существует r. Такое, что r пересеченное с a,
но r пересеченное с n пусто. Давайте еще один союз добавим. Но r пересеченное с n пусто, а r пересеченное
с t имеет мощность больше-либо равную epsilon m пополам. m это вот ожидаемый размер 100 epsilon сетей.
Так, здесь r это союз, а r пересеченное с n пусто, а r пересеченное с t большое. Тут важнее не то,
что а это союз, а то, как понимать мощность r пересеченного с t. Вот это вот,
будьте очень внимательны, имеется в виду с учетом кратности. Нет, смотрите,
n по постранению содержит ровно mei элементов, которые могут совпадать, но от этого их только
меньше станет тогда. Оно по постранению того самого размера, какого мы и хотим. И наша цель
доказать, что с положительной вероятностью это и epsilon сеть просто, что нам mei хватит для того,
чтобы этого доказать. Вот мы взяли вредное событие, у которого вероятность хотелось бы,
чтобы было меньше единицы, тогда будет реализован наша цель. Мы добавили к нему некую дополнительную
рандомизацию, сделали еще одно вредное событие, в котором зачем-то добавили вот это t.
Но, сейчас вы поймете, чего это нужно, сейчас все будет понятно. Ну вот так вот написано,
я еще раз подчеркиваю, здесь модь понимается как сумма индикаторов. То есть, если очередной
элемент с t попадает в r, неважно, был уже он учтен ранее или не был, мы добавим единичку к сумме.
Учетом кратности, то есть, сколько раз там эти элементы попадают, столько раз посчитаем.
Ну, ключевая лемма, ну не ключевая, ключевая чуть позже, но ключевая для понимания,
как вот с этим е2 бороться. Значит, лемма утверждает, что, давайте так,
давайте вот как, смотрите, е2 и е1, как они соотносятся, что из чего следует.
Что? Е2 это подмножество е1, да? Е2 это подмножество е1. То есть, что из чего следует?
Из е2 следует е1. Ну вот, давайте так, вероятность е1 при условии е2, наверное, я так напишу,
больше либо равняется 5 шестых. Ну, 5 шестых это я просто так получу, сейчас я просто знаю,
что у меня получится 5 шестых, но могу, что? Плохо написал?
Наоборот, сейчас, я вот рассуждал, рассуждал, и из е2 следует, а, ну да, рассуждал, рассуждал,
и да, рассуждал, да, это правда, это один просто, да, хорошая лемма, это один. Нет, замечательно
другое, да, согласен, рассуждал, рассуждал, и все равно неправильно написал. Да, да, да,
меньшее событие при условии, большее, да, да. Мы уже знаем, что вот это выполнилось,
что вот это выполняется, вероятно, меньше 5 шестых. То есть, мы ввели вроде как дополнительную
случайность, и вот это вот событие, оно чем-то таким вот дополнительным, но вероятность не сильно
меняется, то есть, можно по-другому сказать, что мы возьмем вероятность е2 пересеченного с е1,
поделим на вероятность е1, получим больше либо равно 5 шестых, из этого следует, так вот,
следовательно, вероятность е2, которая является под множеством е1, больше либо равняется 5 шестых,
на вероятность е1, ну и читаем дальше в обратную сторону, то есть, что вероятность е1 не больше
чем 1,3 и множество на вероятность е2, иначе целью в конечном счете будет доказать вероятность
е2, ну скажем, меньше там, 1 и 2.
Из леммы следует, вот я сейчас написал, что достаточно теперь оценить сверху вероятность е2 чем-то,
ну хотя бы в одну целую две десятых раз меньше 1, ну там в два раза, это потом, а сейчас надо
лему доказать, ну вы поняли, зачем лему, то есть, вот мы вроде так оснастили событие чем-то дополнительным,
это поможет нам доказать потом вторую ключевую лему, но главное, что вот это оснащение не привело
к значительному изменению вероятности всего там 5 шестых, 6 пятых раз, ну смотрите, вот мы знаем,
что выполнилось событие е1, то есть, мы знаем, что найдется какое-то R, которое цепляет А,
как надо, и которое пусто пересекается с N. Про что нам говорит условная вероятность? Что,
тем не менее, T из этого R черпает много, я думаю, что надо вот здесь, прямо здесь эту картинку
нарисовать, чтобы было понятно, как жизнь устроена, есть X, объемлющее пространство, мы живем,
на самом деле, только внутри А, у нас ничего вне А не происходит. Так, все понимают, что все
находится внутри А, потому что элементы из N я беру из этого множества, но мощность N маленькая,
и я из него выбрал какие-то M-штук элементов, из него выбрал какие-то M-элементов, может быть,
совпадающих, вот они образуют N, не образуют N. Вот существует R, это R, которое вот здесь,
содержит хотя бы ε умножить на N элементов, и нам хочется посчитать, вот в этом месте,
вероятность того, что R, пересеченное с T, в упомянутом смысле, с учетом кратности,
не меньше, чем εM пополам. T выбирается независимо от M, мы считаем вероятность того,
что отсюда выбрано хотя бы εM пополам или нет. Так, я пишу, вероятность E2 при условии E1 равна,
я так не пишу, вероятность того, что R, пересеченное с T, больше либо равняется
εM пополам, где понятно, что такое R, то есть никаким квантера рисовать не нужно. Мы взяли
то самое R, которое существует и хотим, чтобы оно с T теперь пересекалось не меньше, чем по
εM пополам элементов. Так, я утверждаю, что это не меньше, чем вероятность того, что бином от
εM. Нет, не εM, неправильно. Сейчас, секунду, подождите. Бином, бином, бином, бином, конечно от N.
Бином, конечно, от N, а вот здесь вот ε больше либо равняется εM. Да ёлки-палки! Нет, нет, от M,
что-то я положаю малость вот так. Бином, сейчас поясню всё, просто написал неверно,
но сейчас всё поясню. Значит, бином что такое? Это биномиальная случайная величина с параметрами
M и ε. Нормально такое обозначение? Ну, конечно, строго говоря, я должен был написать там какое-то
кси, которое имеет такое распределение биномиальное, но я, с вашего позволения, напишу так.
Биномиальная величина какая-то, которая имеет вот такое биномиальное распределение, принимает
значение не меньше, чем εM пополам. Почему? Потому что смотрите, как T, большой элемент вот этого
T большого попадает сюда. Мы элементы вот этого T большого выбираем один за другим, независимо
друг от друга. Выбираем очередной, ну, например, первый элемент. Он либо сюда попадает, либо
не попадает. Попадает успех, не попадает неудача. И вот эта вот R, пересечённая с T мощность,
это число успехов в такой схеме испытаний. Бернули. Попал, не попал, попал, не попал. Испытаний,
конечно, M штук. Потому что мы раз выбираем элемент. Понятно? Испытаний M штук мы элементов
выбираем. А с какой вероятностью случается успех в очередном испытании? То есть с какой вероятностью
этот элемент попадает вот сюда? Не меньше, чем N ε, делить на N. То есть не меньше, чем ε. А я
написал в точности ε, поэтому знак неравенства сюда. Ну, тут вероятность успеха не меньше,
чем вероятность успеха здесь. Поэтому число успехов большое, с тем не меньше, так сказать,
вероятность. Ну, с тем больше, если хотите, вероятность. Понятно? Вот. Очень хорошо. Сейчас
применим неравенство Чебушкова. Так, ну вы знаете, конечно, мат ожидания этой штуки от
ε умножить на M. Давайте его вычтем слева и справа. Мы получим вероятность того, что бином наш,
от M ε, минус его мат ожидания, больше либо равняется, εM попало. Ну, на самом деле,
это надо вот так переписать. Это равно 1 минус вероятность того, что это же самый бином от M
ε, минус M ε. Ой, рана. Меньше либо равняется, минус εM попало. Еще раз? Ну, хотим, наверное. Я
уже в этом плане неаккуратен, но как бы смысл-то понятен. Я прошу прощения, да, но формально надо
поставить строгую. Ну, неважно. Неравенство Чебушкова работает всегда и со строгим неравенством,
и с нестрогим. Оно, конечно, верно. Смотрите, величина случайная уклоняет от своего среднего,
но в данном случае влево на какое-то расстояние. Вот там, как говорится, модуль разности,
случайная величина, ее мат ожидания. Давайте я напишу. Какая-то кси, минус екси, больше либо
равняется, либо больше строго, пусть хорошо, а не превосходит dc поделить на а в квадрате. Вот это
вот неравенство Чебушкова. Ну, его надо знать. Это такая вещь, совершенно стандартная. Вероятность
уклониться, уйти далеко маленькая. Ну, вот в терминах дисперсии. Ну, здесь мы говорим,
что не весь модуль ушел, а только в одну сторону она ушла. Ну, все равно она маленькая, даже не
больше вот это. Ну, значит, все больше либо равняется, нежели 1 минус дисперсия кси поделить на
епсилон м пополам в квадрате. А у нас это епсилон м пополам. Какая дисперсия у кси? Тоже извините.
Дисперсия это м на епсилон и на 1 минус епсилон. Ну, обычно люди помнят НПКУХ. НПКУХ все, по-моему,
полностью. Ну, тут вот П это епсилон. Дайте я тут напишу. Дисперсия кси, она не больше чем м
епсилон, потому что я просто хочу пренебречь разностью 1 минус епсилон. Она равна м епсилон 1
минус епсилон, значит, она не больше чем м епсилон. Продолжаем неравенство в нужную сторону. Получаем,
что это не меньше чем 1 минус м епсилон поделить на м епсилон пополам в квадрате и это равно 1 минус
4 поделить на м епсилон. В этом месте допускаем грубую совершенно оценку. Смотрите, м я хранил
бережно. Так, м епсилон, давайте я тут выпишу, м епсилон не превосходит. Нет, почему не
превосходит? Больше либо равно. Нам нужно больше либо равно, потому что дробь будет не больше, а со
знаком минут снова больше либо равно. Нам нужна оценка именно в эту сторону. Значит, м епсилон
больше либо равняется просто 8d на епсилон лог двоичный 8d на епсилон. Собственно, ради этого я
рисовал именно верхнюю целую часть. Так, хорошо, а это я сейчас по-дурацки оцениваю. Это знаете,
что больше либо равно? Это что? Хуже того, это больше либо равно 8 на лог двоичный 8. Ну да,
больше либо равно 1 епсилон меньше одного. В данном месте я действую очень грубо. Ну,
лог двоичный 8 это 3, 3х8 это 24. Получаем равно 1 епсилон на 24, это 5-6. Ну, я знал.
Ну, неважно, в общем, получили. Лемму победители несут. Ну и сейчас будет ключевая лемба,
которая фактически нам завершит доказательства по модулю какой-то скучной выкладки, которую я
пропущу и вам разрешу не производить на экзамен. Ну, она будет понятна совершенно, просто зачем
и как раз непонятно. Сейчас, чтобы нам стереть. Лемму давай. Лемма. Это еще одна лемма. Ну,
я что-то не стал их в этом году нумеровать. Какая разница? Один, два. Их всего четыре. Две уже
давно прошли. Сейчас вот две для теоремы. Одну доказали. Сейчас вот вторая. Ну, по сути,
ключевая, конечно, вот эта. Ключевая, говорит следующая, вероятность Е2 не больше, чем g от 2d.
Сейчас неправильно пишу. Спокойно, не коротимся. Так, g от чего? От 2m, наверное. Сейчас, сейчас,
сейчас. g это понятно, это вот та самая функция, которая сумма цешет, помните? Я сейчас соображу,
с какими параметрами она. Так, она n и d, то есть там должна быть некая мощность и размерность. Ну,
так размерность, это наша размерность какая-то еще может быть. Вот так. 2md на 2 в тепени минус
εm попало. Вот такая штука. Это вот ключевая лемма. Тут каким-то образом сейчас должна вылезти
размерность вапника-червоненкиса, которую мы нигде пока не используем. Вот понимаете, да, друзья,
что мы нигде пока размерность вапника-червоненкиса не используем. Вот она здесь вылезает. Но я считаю,
что все-таки именно эта лемма ключевая. Скоро она здесь вылезает. 2m и d на 2 в тепени минус
εm попало. Смотрите, давайте прежде чем доказывать эту лемму, поймем качественно, почему она решает
нашу задачу, то есть доказывает в итоге теорему, которая частично видна. Почему эта лемма ее,
по сути, доказывает? Ну, вы помните еще, наверное, что наша-то цель доказать, что вероятность E2 меньше
там, чем 5-6. Ну, чем одна-вторая. Не важно. Если вероятность E2 относительно маленькая,
то вероятность E1 вследствие предыдущей леммы тоже меньше единицы, и все хорошо. Ну, смотрите,
это же меньше, как мы знаем, чем 2m в тепени d, умножить на 2 в тепени минус εm попало. Ну,
и все. То есть вы не глядите воловьими очами, так сказать, на то, как выглядит вот это M сейчас.
Вот на него пока не глядите, а то это действительно будет только грусть и изумление вызывать. Ну,
сходу-то не очевидно. Вы глядите именно сюда, вот примерно как я доказывал вторую лему из
первой серии лемм, которая еще была до теоремы. Вот как я говорил, это степенная функция, а это
показательная. То есть эта функция это M в какой-то фиксированной степени, а эта функция это 2 в
тепени минус с точностью до константы M. Она убывает по M экспоненциально, ε нам дано,
оно зафиксировано. D тоже зафиксировано, это размерность нашего пространства. Но эта
функция растет по M, как степень, как 2m в степени D. Поэтому ясно, что начиная с какого-то момента,
который зависит только от D и от ε, эта штука будет меньше, чем одна вторая, чем что хотите.
Ну, в конечном счете с огромным. Просто вот эта вот функция, которая здесь выписана, 8d на
ε, лог 2-ичный 8d на ε, как раз подобрана таким образом, чтобы вот это произведение оказалось меньше одной
и второй. Но это можно проверить. Но это скучно. Не, ну это примерно понятно, почему она именно такого
вида, там можно прологрифмировать вот это выражение, посмотреть, когда D лог 2-ичный М,
это примерно εM попало, когда они примерно совпадают. Вот можно догадаться, что функция имеет тот самый.
Но формально, аккуратно проверять, что именно при подстановке тех вот логарифмов и прочее,
тут получится меньше одной и второй, это как бы чуть скучно. Поэтому я не буду это спрашивать на
экзамене и сам не хочу это рассказывать. В этом серьезной умной математики нет. Ну,
простой неравенец, надо прологрифмировать и посчитать. Поэтому все. Вот в этом месте
я считаю, что матеорему завершили доказывать. Почему функция именно того вида, это в шпаргалке,
будет написано, вам запоминать не нужно. Функция видна отсюда. Поэтому все, вот это пояснение
завершено, и как только мы докажем эту немму, матеорема будет автоматом доказать. Правильно?
Согласны? Потому что, я повторяю, я выкладку уже проводил. Надо доказать ключевой факт,
так вот это связано с размером. Так, слушайте, ну моя задача успеть доказательства. Я очень
надеюсь, что это получится. В крайнем случае, чуть-чуть задержу, постараюсь этого не делать.
Посмотрим, как пойдет. Я что-то, видимо, разжевываю. Но мне ужасно хочется, чтобы всем было понятно,
народу не очень много, но вроде как народ воспринимает то, что происходит. Поэтому разгоняться
тоже как-то не хочется. Так, все, величина М нам уже не нужна. Важна суть. Суть сейчас попробую
сказать какая, но, конечно, тут надо некий путь пройти. Так, Е2 у нас сохранилась, давайте введем
событие, где бы мне его ввести. Я вот тут, наверное, его введу. Вот это вот назовем Е с индексом 2,
запятая R. Ну, то есть, вот после квантора существования. Если мы зафиксировали как-нибудь
R маленькое, R большое, то вот все вот это вот событие называется Е2R. Понятно? Что такое Е2R? Так,
товарищи, вам понятно, что Е2 это просто объединение по всем R с R Е2R. Ну, потому что
квантор существования, мне кажется, вы должны привыкнуть. Это всегда объединение существует,
для какого-то хотя бы одного выполнено, значит, хотя бы одного. Значит, мы объединили. Верно? Но,
черт, могу не успеть, потому что, видите, пытаюсь хорошо рассказать. Давайте немножко, вот это вот
важно сейчас осознать, главное осознайте, поменяем схему выбора вот этой пары. Это очень важно
осознать этот тонкий момент. Ну, до сих пор, как мы действовали, мы выбирали N, потом выбирали T.
Друг от друга независимо. Я утверждаю, что то же самое вероятностное пространство можно получить
в результате следующей схемы. Выбираем U, Z1 и так далее. Как 2M? Сравнивайте 2M, 2M. Так,
то просто спокойнее было на душе, что дело идет к чему-то хорошему. Вот, выбираем случайное вот
это мультимножество или размещение с повторениями, состоящих из 2M элементов множества А. Точно так же,
то есть каждый элемент собирает все 1M. Это не будет парой N и T, это будет будущей парой. Как
выбрать, что здесь N, а что здесь T? Ну, нет, надо взять случайное под множество мощность M.
U это множество элементов А. Естественно, как и N это множество элементов А. Вот, смотрите сюда,
и T это множество элементов А. Все вот эти затытые, они естественно тоже принадлежат А. Вероятность
затытого, это снова 1 поделить на N, все как раньше. Но нам еще нужно разделить это на два куска. И вот
чтобы разделить это на два куска, давайте просто выберем случайную половинку. Случайную, внимание,
товарищи, уже в классическом смысле слова. Ну, тут C из 2M, по M половинок. Вот возьмем любую из них
с вероятностью 1 поделить на и назовем ее N. А оставшуюся назовем T. Нет, нет, мы еще раз,
мы запускаем схему выбора с возвращением, выбираем 2M. Некоторые из них могут совпадать,
это не возбраняется. После чего вот это мультимножество бьем пополам, чайным образом,
вот мультим такого распределения. Ну, то есть, если мультимножество состояло, например,
из элементов 1, 1, не знаю, 2, 2, оно было мощностью 4, для примера, чтобы вы понимали, то у нас и вот это
имеет вероятность одна шестая, и вот это имеет вероятность одна шестая, и вот это и так далее.
Среди них бывают совпадающие, ну, что ж поделать. Ну, вот это 1, 2 имеет вероятность одна шестая,
и вот это 1, 2 тоже имеет вероятность одна шестая. Мы каждую половинку берем с вероятностью одна
шестая. Любую такую половинку, уже выбранную, называем N большой. Понятно сейчас, как схема
устроена. Это будет то же самое, если сначала выбрать N, потом выбрать T. Это то же самое,
как сразу выбрать два M элемента, потом раздробить пополам. Ну, если вдруг не очевидно,
подумайте над этим. Это, в общем, такая вещь, которую надо осознать. У меня еще 10 минут есть,
может я успею, может нет, это челлендж такой. Но понимаете, да, чего происходит? Можете,
успеваете записать, как зафиксировать для себя, да? Отлично. Все, теперь смотрите,
давайте я сделаю вот как. Вероятность E2, это, конечно, сумма по всем У. Вероятность E2 при
условии У умножить на вероятность У. Называется то, что я написал формула полной вероякости.
Вот, прелестно. Допустим, мы доказали, докажем. Дм – это докажем. Докажем такое вот нерадство.
E2 при условии У не больше, чем 2 в степени минус Эпсалон М попало. Вот это мы докажем.
Я это как-то прям вот так вот подчеркну. Я пока это не доказал, но мы это докажем. В раннем случае
в следующий раз я не хочу комкать, но главное, чтобы было понятно, как логика устроена. Докажем,
что вот эта условная вероятность не больше этой величины. Тогда формула полной вероякости там,
что все вместе не больше, чем сумма по У. 2 в степени минус Эпсалон М пополам. А, правильное
слово, да? Нет! Эх! Эх! Эх! Вот тут вот надо поправить. А, вот так вот. Ж от 2м,
чего у нас там Д, да? Умножить, конечно. Да-да-да-да-да, извините. Е2 при условии
Забыл сомножить. Ну, то же самое. Тогда у нас тут будет Ж от 2м. Д – нет, все хорошо, все хорошо.
На вероятность У? Ну, все. Получится 2 в степени минус Эпсалон М пополам на Ж от 2м Д на
сумму по У вероятности У, которая равна и делится. То есть, если мы докажем такое неравенство,
которое я подчеркнул, то итоговое доказательство у нас в кармане.
Вроде понятно, да? Я предельно аккуратно. Так, давайте попробуем это доказать. Смотрите,
какой тут фокус. Вот сейчас главный катарсис, он содержится, конечно, тут. Условная вероятность
Вероятность П от Е2. Это, как мы понимаем, вероятность объединения по РСР Е2ртых при условии У. Вот от
сюда следствие. Е2 – это объединение Е2ртых. Просто переписал, что это объединение таких
обозначений больше ничего. Хорошо? И вот сейчас будет ключевой момент. Я утверждаю, что если У зафиксировано,
вот этот выбор мультимножистого из 2М элемента. Если мы зафиксируем, неважно какой, но зафиксировали
У. Внимание, товарищ, какой ключевой момент. Вот в этом объединении реально не столько элементов,
сколько всего элементов в Р большом. Ну, тут всего вроде как объединяется Р. Мощность Р
большое множество событий. Я утверждаю, что разных событий, разных множеств в этом объединении как раз
таки не больше, чем G от 2МД. А именно, я утверждаю следующее. Я утверждаю, что если, и это, по-моему,
сейчас будет очевидно. Смотрите, если R1 из R и R2 из R таковы, что R1 пересеченная су равно R2 пересеченная
су, то соответствующие события совпадают. E2R1 равно E2R2. Но надо какую-то филю нарисовать.
Все при условии У, да. Ну, да, да, да, вот эти вот события при условии У совпадают. Понятно,
говорю, нет? Смотрите, вот У, вот это У, оно там из 2М элементов, ну, неважно, оно из 2М,
оно мультимножество какое-то. Вот представьте себе, что я не казал, как она сойдет в другую
сторону, я уж не знаю. Ну, какие-то разные сардельки, вот одна такая, другая такая. Вот эта вот одна,
а вот это вот сердечко, это другая. Но они одинаково пересекаются с У. И У уже зафиксировано,
все, вот мы его забили тут гвоздями, оно выполнилось. Оно выполнилось. В чем стоит
соответствующее событие E с двумя индексами? Оно же состоит не вот в этом, оно состоит вот в
том, что тут написано, что R пересеченная с N пусто, а R пересеченная с T там, ну, большое в каком-то
смысле. Но N и T, они же оба выбираются внутри У. Какая разница, как устроены R снаружи? Важно,
как они устроены внутри, понимаете? Вопрос о том, пересекается R с N или не пересекается,
вопрос о том, насколько мощно пересекается R и T, это только вопрос о вот этом кусочке множества R.
И если этот кусочек один и тот же для разных R1, R2, то соответствующие события одинаковые.
Ну, не знаю, по-моему, нормально объяснил. То есть, что это означает? Это означает, что нам
надо доказать теперь, что E2R при условии U не превосходит 2 в степени минус Эпсилон М пополам,
еще раз это подчеркну, уже два раза от того было отличие от предыдущего подчеркивания. Вот нам
осталось доказать только это. Потому что если мы это доказываем, то всю вот эту вероятность мы
оцениваем суммой вот таких чисел, и в этой сумме участвуют не все R, а только те, для которых
вот эти пересечения Су разные. Не Су разные. Нет, все-таки Су разные. Су разные, да. Су разные,
да. А сколько их? Их столько, сколько в проекции R на U. Вот разных столько, какова мощность проекции
R на U. Так, все помните, что такое проекция R на U? Ну, это вот как раз вот эти пересечения,
сколько их раз. Вот столько разных событий в этом объединении присутствует. Вероятность объединения
не больше, чем сумма вероятностей, но, естественно, разных событий. Вот поэтому в сумме столько
слагаемых, величина каждого из которых окажется не больше, чем вот эта экспонента. Ну, а это
по лемме, которую мы сегодня, по следствию из леммы, с которой мы сегодня начали, это действительно
больше, чем R2md, потому что мы живем в проекции размерности D теоремы. Так,
формулирую таву 2m элементов. Это просто следствие из самой первой сегодняшней леммы.
Приняне, лемма даже была доказана в прошлый раз, а сегодня мы вот это следствие явно написали.
Слушайте, ну давайте в крайнем случае на несколько минут задержимся, вот это докажем. Осталось-то чуть
ну совсем чуть, но нелепо это переносить на следующий раз. Так, куда бы только его писать?
Так, ну картина даже есть. Вот это вот R пересеченное SU, и нас интересует вероятность
того, что R пересеченное SN пусто, а R пересеченное ST такое.
Смотрите, мы вот на это забьем вообще. В этом месте мы уберем вот это условие,
ну потому что вероятность пересечения всегда не больше, чем вероятность каждого. И будем смотреть
только сюда. То есть мы взяли вот этот вот кусочек R пересеченное SU и хотим, чтобы этот кусочек
SN не пересекался. А нет, это неправильно. Не, неправильно говорю, я тут немножко запутал.
Извините, наврал, наврал. А? Не-не-не, надо аккуратнее, сейчас надо аккуратнее. Смотрите,
сейчас, сейчас-сейчас-сейчас. Надо еще аккуратнее сказать. Вот давайте мощность R пересеченного SU,
ну что контрафис-то? Мощность R, вот это вот, размер вот этого куска. Знаете,
обозначим какой-нибудь буквой K. Пускай, это мощность этого куска. Смотрите, если, сейчас надо
аккуратнее, если K меньше, чем εM пополам, то интересующая нас вероятность равна нулю. Потому
что не может такого быть, чтобы R пересеченное ST было большим. ST выбирается как по классической
вероятности, понимаете, она не может быть большим. Сейчас почти закончил. Понимаете, да, вот она равна нулю.
Ну это конечно меньше, чем два в степени минус εM пополам. То есть ноль он вообще красит в этом
смысле. Поэтому давайте считать, можем считать, можем считать, что K больше либо равняется εM
пополам. И вот теперь пренебрежем этим условиям, а будем смотреть только сюда. Вот теперь,
оценивая нужную нам вероятность E2R при условии U. Забудем про это ограничение,
оно дает дополнительное усиление неравенства. Ну, плевать мне. С какой вероятностью R пересеченное
SN пусто. Нет, это совсем понятно. Это 2M минус K по M поделить на C из 2M по M. Понятно, да,
почему? Мы большое выбираем как кусок мощности M вот отсюда. Мы должны его выбрать вот откуда-то
отсюда. Вот эти M элементов должны не пересекаться с этими, а этих K штук. Ну,
то есть C из 2M минус K по M поделить на C. M по M это вероятность того, что оно не пересекается.
Вот здесь конечно не равно, а меньше либо равно, потому что, повторяю, мы пренебрегли вот этим
условиям. Строго говоря, меньше либо равно равенство столкнемся. Ну, неравенство в нужную сторону.
Осталось просто легкую выгоду провести, смотрите.
У нас получается 2M минус K факториал на M факториал на M минус K факториал. Так,
тут у нас будет 2M факториал на M факториал и на M факториал. По один мы кокнем, а дальше сделаем
вот так. Это сократим с этим, а это сократим с этим. Вот так, крест на крест. Значит, сверху у нас
вот тут останется M, M минус 1, M минус K плюс 1, а снизу у нас останется 2M, 2M минус 1,
2M минус K плюс 1. Согласны? Ну, это простая выгодка, тут вроде все видно. А теперь смотрите,
вот это 1,2. А это даже меньше, чем 1,2, потому что 2M минус 1 больше, чем 2M минус 2. Это меньше,
чем 1,2. Это тем более меньше, чем 1,2. То есть все это меньше, чем 1,2 в катой степени K
с множителями. Это равно 2 в минус катой, а K у нас больше либо равно epsilon M пополам,
поэтому это не больше, чем 2 в степени epsilon M пополам, и все, теорема доказана.
