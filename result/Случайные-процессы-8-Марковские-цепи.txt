Так, давайте начинать. Значит, мы с вами в прошлый раз закончили первое задание. Приступаем ко второму
заданию. Мы во втором задании будем изучать с вами очень важную тему, называется Марковские
случайные процессы. Это чрезвычайно важный класс процессов. На основе этих моделей,
то есть на основе них построены очень многие модели, которые встречаются, ну трудно назвать
области приложений, математики, где бы ни встречались марковские случайные процессы. Это тебе и физика
с матфизикой, это биология, химия, это экономика, финансовая математика, айти-технология, машинное
обучение построено, искусственный интеллект. Чрезвычайно важная вещь, будем это изучать
все оставшееся время до середины мая. Значит, мы с вами уже до этого изучили случайные процессы,
ну разные классы случайных процессов. Стационарные, эргодические, гауссовские процессы, крупные классы у
нас были, да, мы изучали их свойства. И чем по сути отличаются все эти классы? Классы отличаются тем,
как соотносятся между собой сечения. Вот у гауссовских процессов, у них сечение образует нормальные
векторы, вот такое как бы ограничение на сечение, да, там, эргодичность там одного, стационарности там
другое, как-то эти множества могут пересекаться между собой. Вот есть марковские случайные процессы,
здесь как, какая связь между сечениями придумана. Значит, марковские процессы это естественное
обобщение динамических систем на стахастику. Вот в динамических системах, если все детерминировано,
то у тебя начальное состояние полностью определяет будущую траекторию, которая часто описывается в
виде дифференциальных уравнений, ну там в частных или прямых производных. Случайные процессы, у них не
всегда состояние описывает однозначно будущее, но как правило это не так, потому что процесс случайный,
и зная настоящее ты не знаешь будущее. Так вот, марковские процессы это процессы, в которых
настоящее состояние, оно может быть и не определяет однозначно траекторию, но оно однозначно
определяет распределение будущего, то есть как поведет себя. То есть оно однозначно определяет
распределение будущей траектории, начиная от этого момента, то есть это однозначный детерминизм
на распределение не на поведение траектории, а на распределение ее поведения. Вот давайте мы перейдем
к некоторому определению. Он более формальным. Значит, определение первое, что случайный
процесс x от t, t из t большого, называется Марковским или процессом Маркова, если вероятность
x от t, n плюс 1 принадлежать к какому-то множеству, ну бареллевскому множеству, да, потому что
это событие должно быть измеримым. Например, здесь может стоять меньше x какого-то или принадлежность
к какому-то отрезку. Ну в общем случае бареллевское множество. x от t, n равняется x, n запятая и так далее,
x от t, 0 равна x, 0. Если вот эта вероятность условная равна вот такой, вероятности x, t, n
плюс 1 принадлежность к тому же самому b при условии x, t, n равняется x, n. Видите, ну там для
любых, для любых n, значит, больше либо равных, не знаю чего, единицы, наверное, или нуля, ну да,
содержательные единицы, для любых t1 и так далее, t, n из t, для любых b, бареллевское множество из r,
для которых вот эти условные вероятности определены. И смотрите, что эта формула нам, о чем она говорит.
Вероятность того, что в будущем процесс попадет в это множество при условии того, что в эти моменты
он побывал в этих состояниях, равно вероятности попасть туда же при условии, что в ближайший
к этому момент времени он побывал в этом состоянии. То есть мы игнорируем то, что мы называем прошлое,
вот это прошлое, это прошлое, это настоящее, это будущее. Вероятность в будущем попасть сюда при
известном настоящем и прошлом равна вероятности попасть сюда при известном настоящем. Прошлое
игнорируется. Вот не у всех процессов это так, но если это так, то процесс называется марковским.
Распределение в его будущем зависит только от настоящего, но не от будущего. Сразу предупреждаю,
что вот эти слова, будущее, прошлое, настоящее, это как бы наша интуиция, но нельзя трактовать эти
слова слишком вольно. Например, нельзя в этом определении вот сюда приписать принадлежность,
скажем, БН. Здесь стоит равно ХН конкретному какому-то состоянию. Здесь нельзя писать
принадлежность Б, потом это выкидывать и здесь оставлять принадлежность Б. То есть настоящая,
принадлежность процесса целому множеству. Это будет неравносильно этому и вообще неверно,
это не марковские процессы. Здесь стоит именно равно. То есть, вероятностная будущая процесса
определяется конкретным состоянием в этот момент времени. Если это выполнено для любых N,
для любых T, для любых B, процесс называется марковским. Вот такое вот обобщение. Как я сказал,
это чрезвычайно важная модель, она используется очень много где. По себе могу сказать, например,
что такая крупная область, как искусственный интеллект, по части принятия решений, теория
ихр, экономика. Вот они построены на этих моделях. Машины обучения с подкреплением вообще целиком и
полностью основывают свой фундамент на этой вещи. Так что тех из вас, кто будет заниматься машинным
обучением с подкреплением, принятием решением, искусственным интеллектом, это модель номер один.
С этого все начинается. Так что это очень важная вещь. Значит, сразу же напишем теорему у нас будет.
Без доказательства она пойдет. Она довольно техническая. Значит, всякий процесс независимыми
приращениями является марковским. Висимыми приращениями является марковским процессом.
Например, Винеровский процесс. Он марковский. Давайте сразу напишу. Винеровский, то есть
следовательно, Винеровский процесс, марковский. Плассоновский процесс, тоже марковский. Обратное,
вообще говоря, неверное. Не всякий марковский процесс имеет независимые приращения. Из того,
что процесс марковский не следует, что у него независимые приращения. Но у вас будет много задач
на марковские процессы. Там вы увидите, и эти примеры легко получаются. Там вы увидите,
когда процесс марковский, но у него приращения не являются независимыми. Но в эту сторону точно
верно. Этим вы можете пользоваться. Теорему даю вам без доказательства. Значит, как же
классифицируются марковские случайные процессы? То есть, оказывается, есть классификация. Очень
понятная, простая классификация марковских процессов. Дело в том, что вот эти состояния,
значения, которые принимает процесс, называются множеством состояний. И есть еще множество,
которое принимает время. И вот в зависимости от того, какие эти множества, состояния и времени,
различают несколько классов марковских процессов. То есть, пустес — это множество значений марковского
процесса X. T — это множество времен марковского процесса. Ну да, множество времен T. Множество
времен, на котором определен процесс. Первое. Если S дискретно, принимает какое-то конечное
или счетное число значений дискретно, и T дискретно, например, 0, 1, 2, да, вот так вот,
то тогда такие процессы называются дискретными цепями маркова, дискретные цепи маркова,
которые мы начнем изучать уже сегодня. Второе. Если S дискретно, T непрерывно — это называются
непрерывные цепи маркова. Мы их тоже будем изучать чуть позже. То есть цепи — это когда S множество
состояний дискретно. Вот это первое слово — дискретно-непрерывно — относится ко времени.
Третье. Бывает, когда S непрерывно, T дискретно. Вот. Такие процессы мы специально изучать не
будем, но примером являются, например, случайные блуждания. Пример случайные блуждания. То есть,
когда время дискретно, то есть 0, 1, 2, 3, и в каждый момент времени случайный процесс может принимать
значение прыгать на какую-то случайную величину с непрерывным распределением. Поэтому ты не по
дискретной какой-то сетке прыгаешь, а по непрерывной шкале. Так что это вот пример таких процессов.
Случайные блуждания. Помните, у нас на какой-то лекции было доказательство того, что случайные
блуждания определенного вида, они сходятся к Винеровскому процессу. Вот эти случайные
блуждания, они вот в этом ножице держатся. Вот. И четвертое, когда S непрерывно и T непрерывно. Вот.
Ну, такие, я не знаю, названия существуют для таких или нет. Я называю их просто непрерывные
марковские процессы или марковские функции. Все, когда непрерывно. Непрерывные марковские
процессы, функции. Такой класс мы будем с вами тоже изучать. Это будет последняя наша лекция в
этом курсе, случайные процессы. Мы ее целиком и полностью, скорее всего, посвятим вот этим вот
процессам марковским. Вот. Значит, мы приступаем к изучению дискретных цепей Маркова. Значит,
эта модель вам должна быть близкая, понятна. Она близка к модели конечного автомата. Помните,
что это такое? Такой граф с кружочками, стрелочками. Да, и мы перемещаемся по нему. Вот тут сейчас то
же самое начнется. Только все это в стахастике. Вот. Будем изучать как бы случайные прыжки по
таким графам и какими свойствами такие графы обладают. Вот. Значит, на основе марковских
цепей строится теория машинного обучения, динамическое программирование. Работают различные
алгоритмы. Очень полезный, например, алгоритм ранжирования страницы гуглом. Когда вы в поисков
вбиваете, он вам страницы ранжирует. Вот. То, как он это делает, мы будем это проходить на основе
закона больших чисел для дискретных цепей марков. У нас теория такая будет, мы ее доказывать будем.
Вот. На основе этого работает алгоритм гугла ранжирования. Об этом можно почитать, например,
в книжке под редакцией Гастинькова Александра. Ну, и там много авторов, нассоавторов. Лекции
по случайным процессам. Вот. Сейчас, кстати, вышло новое издание этой книжки буквально недели две
назад в издательстве в РСС. Вот. Ну, можно найти старую версию, которая была напечатана в РИО МФТИ.
Итак, тема. Начинаем дискретные
марковские цепи. Дискретные цепи маркова. Значит, первое, что мы сделаем, мы сформулируем для этого
класса марковских процессов эквивалентное определение, с которым просто проще работать и проще
исследовать. Во-первых, давайте мы будем считать для простоты, что t, так как множество t дискретно,
что t это 0, 1, 2 и так далее. Вот. Ну, натуральный число с нулем. Вот. И, по-моему, я тоже самое делаю
для s. Нет? А, нет, не обязательно. То есть, будем считать вот так. Так. Ну, хорошо. Значит,
определение давайте введем, что последовательность. Ведь если t дискретно, значит, процесс это
последовательность. Вспоминаем первую самую лекцию. Если t дискретно, значит, процесс это последовательность.
Значит, последовательность xn. Ну, то есть, там будет удобно писать xn. Не x, а t в скобочках n,
где t равно n, а xn, как последовательность мы обозначаем. Давайте от нуля. А, я тут от нуля
начинаю. Давайте от нуля. Спасибо. Значит, последовательность называется... Ну, я буду
сокращать дискретной Марковской цепью. Дискретной цепью Маркова. Если... Значит, тут такая вероятность
xmn... Сейчас. Мне бы как-нибудь... Нет. Давайте здесь. Или не важно. Ну ладно. Пусть будет mn. Поменьше
обозначения. Значит, x маленькое mn при условии, что xmn-1 равняется xmn-1, запятая и так далее,
x большое m0 равняется x0 равно... Ну, это вот наш момент, вот эти t, но так как они целые, поэтому я
использую буквы для целых чисел. mn. Вероятность xmn равняется xmn при условии, что xmn-1 равняется
xmn-1. Вот x большое это наш процесс, случайная величина, а x маленькое это значение этого x
большого, а не из множества состояний. Если вот это верно для любых n, каких там больше либо равно
2 получается для любых там x0 и так далее xmn из s множество состояний. Ну и для любых вот
этих вот времен, правда упорядоченных, естественно, m0 меньше либо равно m1 меньше либо равно и так далее
mn. Какие-то могут совпадать, но тогда, правда, x должны соответствующий совпадать. В принципе,
можно здесь и строгие неравенства написать, все эквивалентно. Вот для любых вот этих всех,
для которых вот эти условные вероятности существуют или определены. Дело в том,
что, в принципе, процесс не обязан в момент m0 проходить через x0. Может быть, он так хитро
устроен, что ни при каких условиях в момент m0 он не пройдет через это состояние. Ну, значит,
такого равенства для него не будет. То есть это равенство, но справедливо для всех случаев,
когда вот эти вероятности определены существуют. То есть реально, когда x может пройти через
эти состояния в эти моменты времени. Вот такая вот оговорка. Так, ну вот. Значит, вот эти m0,
m1 и так далее, они могут быть совершенно произвольными числами вот отсюда. Ну,
например, m0 может быть 5, m1 может быть 10, какая-нибудь mn-1-100, mn может быть там 200. Они
не обязательно упорядоченные, увеличиваются на единичку. Они могут быть просто вот произвольными,
лишь бы вот такими. Вот. И это определение, значит, если они вот произвольные и упорядоченные,
тогда это называется дискретной цепи Маркова. Это эквивалентно тому, что у нас было для общих
марковских процессов, но просто вот переформулированное для дискретной ситуации,
для дискретных цепей Маркова. Но на самом деле вот эта вещь, это можно показать, вот это
определение, оно эквивалентно другому определению. Это уже содержательное замечание, что последовательность
xn называется дискретной цепью Маркова, если вот что, смотрите, вероятность xn равно xn при
условии, что xn-1 равно xn-1 и так далее, x0 равняется x0, равно xn равняется xn при условии,
что xn-1 равняется xn-1, но там для любых n иксов, вот, для любых n иксов, для которых это все
определено. Но здесь, смотрите, моменты времени идут по порядку, 0, 1, 2 и так далее, а здесь,
то есть увеличиваются на единицу моменты времени, а здесь они не увеличиваются на единицу,
что m0 может быть 5, m1 может быть 100, вот здесь, а здесь идут по порядку. Вот это является частным
случаем вон того, так это очевидно, но вот оказывается, это можно доказать, и это будет
задачей в вашем втором задании, это легко доказать, что на самом деле, если выполнено вот это для
любых x и n, то тогда выполнено вон то, для любых вот этих вот штук, то есть отсюда следует вот это,
хотя вот это кажется как бы частным случаем того, но на самом деле это эквивалентно, если это выполнено
для любых n иксов, то выполнено и то определение, то есть определение штрих равносильно просто
определению, это задача из второго задания, вот это вы сами сделаете, вот, а мы когда как,
иногда нам будет удобно вот это считать, иногда нам будет удобно то считать, это мы уже будем сами
смотреть, как нам удобно, ну хорошо, мы сейчас дальше чем определение не продвинулись, какие же все-таки
есть свойства теперь, давайте их изучать, ну первое, что мы сделаем вообще, когда мы изучаем какие-то
случайные процессы, первое, что надо сделать, изучить семейство конечномерных распределений,
потому что это самая главная характеристика любого случайного процесса, знаешь семейство
распределений, знаешь все про процесс, вот мы давайте посмотрим, какова структура этих семейства
конечномерных распределений, то есть мы рассмотрим вот такую вероятность, вероятность того,
что xm0 равен x0, кстати еще говорят, что в момент m0 процесс находится в состоянии x0, такие слова еще
используются, xm1 равняется x1 и так далее, можно писать m0, можно писать 0, здесь кстати точно не важно,
ну x0, x1 они тут произвольны, xmn равняется xn, вот взяли произвольные сечения xm0, xm1, xmn,
для, ну без потери общности считаем, что m0 меньше чем m1, меньше чем mn, то есть они упорядочены,
вот чему будет равна такая вероятность, давайте поймем, значит, смотрите, что мы сделаем, мы вот так
запишем, то есть, ну а что у нас есть, у нас есть просто определение, ну что мы можем еще сделать,
нам нужно сводить к условным вероятностям и пользоваться определением, выкидывать прошлое,
оставляя только настоящее, ну давайте это будем делать, возьмем самый последний, самый последний
момент времени, сечение в самый последний момент времени, нарисуем черту, а все остальное выкинем в
условия, xmn-1 равно xn-1 и так далее, xm0 равно x0, вот и умножить на вероятность того, что мы в условия
выбросили, mn-1 равняется xn-1 и так далее, xm0 равно x0, вот, всем понятно, что я сделал, вероятность
A при условии B умножить на вероятность B, это есть вероятность их пересечения, то есть вероятность
того, что вот это все через запятую записано, понятно, это просто формула условной вероятности,
здесь записано, но смотрите, с чем фишка-то, в том, что так как процесс Марковский, вот это все прошлое,
мы отсюда выкидываем и вероятность не изменится, так что у нас будет вероятность xmn равно xn при
условии mn-1 равно xn-1 и все остальное, а все остальное это в общем-то то же самое, что у нас было,
но только на 1x меньше и мы для него можем то же самое сделать и получим вероятность xmn-1 равняется
xn-1 при условии, что xmn-2 равно xn-2 и у нас останется вероятность уже начиная от xmn-2 и вот так мы
будем продолжать до самого последнего p, а какой будет? вот такой, здесь уже не для чего черту рисовать,
мы на нем остановимся, вот мы с вами получили формулу для распределения произвольного вектора
из сечений и что мы видим по этой формуле, то что конечномерное распределение определяется
двумя вещами, это одномерным распределением и вероятностями перехода между состояниями в
различные моменты времени, вот как, но это логично, если у тебя все определяется настоящим,
тогда как находить вероятность того, что процесс куда-то попадет в будущее, ты берешь вероятность
того, что находится в таком-то настоящем, умножаешь его на вероятность перейти из этого настоящего в
какое-то новое настоящее, потом на вероятность перехода из этого настоящего в новое настоящее
и так далее и так далее, как бы по цепочке, поэтому цепи, вот, итак, конечномерные распределения
определяются двумя вещами, одномерными распределениями и вероятностями перехода,
и в связи с тем, что здесь возникает одномерное распределение вероятности перехода, мы с вами
введем два вспомогательных обозначения, значит, P и T G T от M N, значит, по определению будем считать,
что это вероятность того, что X в момент N равен G при условии, что в момент M он был равен I, вот,
то есть это вероятность перехода из состояния I в момент M в состояние G в момент N, вот, вот такую
вещь ведем, ну, соответственно, можно там тогда эту формулу написать вот в этих терминах, это понятно,
но главное то, что вот такая штука нам потребуется, еще мы ведем P и от N, это будет просто вероятность
того, что процесс в момент N находится в состоянии I, вот, вектор из этих P называется распределением
в момент N, потому что он будет содержать в себе несколько компонент, это будет вероятность того,
что он принимает значение 0 в момент N, состояние 1 в момент N, ну, и так далее, ну, какие там состояния,
если они 0, 1, 2 и так далее, то такие, вот, главное то, что как бы совокупность таких P для разных I,
для разных состояний, она определяет распределение на множество состояний в момент N, вот, а это
вероятность перехода, значит, мы будем с вами работать только с ситуациями, когда вот эти
вероятности условные, они существуют для всех M и N, ну, естественно, M меньше либо равно N,
или любых E и G, как я оговорился в самом начале, конечно, могут быть такие процессы, которые,
например, не могут в момент M проходить через I, но мы не будем с вами рассматривать такие ситуации,
хотя это никакое несодержательное препятствие на самом деле, то есть теоремы, которые мы будем
доказывать, они с небольшой оговоркой все равно остаются верны, но не хотелось бы сейчас вот
зацикливаться на этом техническом, на технической проблеме, давайте мы будем просто для простоты
считать, что в любой момент M мы можем быть в принципе в E, вот, ну, а если это для каких-то
процессов не так, то их можно рассмотреть отдельно и, в общем-то, все равно большинство
утверждений, которые мы сделаем, они будут все равно справедливыми, вот, а так рассматривать их
просто отдельно нужно. Хорошо, значит, мы вели вот эти обозначения, теперь смотрите,
P и T житое, вот я не зря так сделал, сразу что хочется делать? Матрицу составить, да? Что-то
и T житое, A и T житое, B и T житое, давайте матрицу составим вот из этих чисел, матрица P, это матрица
из P и T житых МН, но, видите, тут еще МН есть, поэтому эта матрица зависит от пары, то есть паре МН
сопоставляется матрица, которая содержит вот это для всех И и жи, вот, это матрица перехода,
от момента М к моменту Н, матрица перехода. Ну и сразу же ведем P от N как вектор,
вектор, значит, вектор P, ну там кто, если они занумерованы, вот эти И, скажем, 0, N, P1, N, если
S состояние тоже состоит из чисел 0, 1, 2 и так далее, вот так проще всего, это будет распределение
вероятностей на S в момент N, вектор P, значит, векторы по умолчанию считаем столбцами,
матрицами-столбцами, дальше у нас будут некие векторно-матричные вид принимать формулы,
не зря же я матрицу ввел, значит, где-то здесь уже линейная алгебра должна появиться,
так, ну давайте поизучаем эти вещи, как они взаимосвязаны, что это вообще такое, значит,
смотрите, вот это матрица, давайте посмотрим, что такое вообще, во-первых, ее компоненты это
вероятности, так, вероятности принадлежат значениям от 0 до 1, значит, все числа этой матрицы лежат
от 0 до 1, дальше, вот такая сумма вероятность того, что x в момент N равно g, по всем g из S,
при условии, что m равно i, вот эта вещь равна единице, согласны, что тут стоит вероятность, сумма
вероятностей событий, которые не пересекаются, либо ты в момент N находишься там, скажем, в нуле,
либо в единице, либо в двойке и так далее, сумма по всем это единица, ну где-то-то ты находишься
в момент N, правильно, где-то ты находишься, значит, вероятность равна единице, но это есть P и gt mn,
значит, получается сумма по всем g, P и gt равна единице, это означает, что сумма чисел в каждой строке равна
единице, сумма чисел в первой строке равна единице, во второй строке равна единице и так далее, вот такая
матрица, у нее все компоненты от 0 до 1 и сумма чисел в каждой строке равна единице, такие матрицы
с такими свойствами называются, ну или мы будем называть стахастическими матрицами, матрица
называется стахастической, если все ее компоненты от 0 до 1, включая, возможно, 0 и 1 и сумма компонентов
в каждой строке от 0 до 1, у нас может оказаться так, что счетное число состояний, ну матрица, вы понимаете,
будет такая бесконечная, бесконечная матрица, а вот эта сумма, это ряд тогда получается, ну вот он
обязательно сходится и его сумма равна единице, хорошо, дальше едем, теорема очень полезная,
которую мы будем пользоваться, значит для любых n больше либо равно k, больше либо равно m, верно,
что матрица вероятности перехода от момента n к моменту n, это есть произведение матрицы
перехода от момента m к моменту k умножить на матрицу перехода от момента k к моменту n,
вот какая формула интересная, вот так связаны вероятности перехода, значит доказательства,
доказательства, ну доказательства практически очевидные, давайте мы возьмем итоизжитую
компоненту вот этой матрицы слева, p, i, t, ж, t, m, n, что это такое по определению, это есть вероятность
xn равно g при условии что xm равно i, и давайте мы запишем формулу полной вероятности для этой вещи,
что условная вероятность это тоже вероятность, это тоже вероятность, а для всякой вероятности есть
формула полной вероятности, давайте мы ее запишем, значит сумма, значит как там, какую я букву
использую, l, пусть будет l, по всем l и z, вероятность того, что xn равняется g при условии xk равняется
l, на xm равняется и, и умножить, я дальше продолжаю вот сюда, и умножить на вероятность того,
что xk равно l, и не забываем, что эта вероятность при этом условии была, она никуда не пропадает,
условная вероятность это тоже вероятность, вот таким образом мы обусловили, как говорят,
по всем значениям вот этого промежуточного состояния между m и n, видите, k между m и n находится
в момент времени, вот это просто формула полной вероятности, но процесс-то марковский,
значит мы можем прошлое забыть, вот это прошлое в данном случае, и у нас получится,
видите, что условная вероятность отсюда-сюда, а там оттуда-туда, значит если мы перейдем к нашим
обозначениям, p и j, которые я сейчас стер, то мы получаем, значит что, ну давайте так,
следовательно, p и j от m и n равняется сумме l из s, вероятность, а нет, не надо вероятности,
в терминах значит p, откуда-куда, из, так-так-так-так-так, сейчас-сейчас, давайте вот с этой вероятностью
из i в l от момента m к моменту k умножить на вероятность, теперь вот этот множитель,
который здесь был первым, от l к j, от момента k к моменту n, получилось, ну а это и по формуле
матричного умножения то, что здесь написано, все, классная теорема, да, очень легко доказывается,
а таких в дискретных цепях и будет уйма, у нас будет мало таких вот больших сложных теорем здесь,
в основном вот, по крайней мере, начало вот из таких вот будет стоять, в общем-то, ну знаете,
основной инструмент это формула условной вероятности, формула полной вероятности и
марковское свойство, ну вот это то, что можно прошлое выкидывать, все, если ты не знаешь,
как решать задачу, ты берешь вот эти три вещи и комбинаторишь их там между собой,
пока не доберешься до ответа, ну как бы, ну реально, вот все доказывается только с
помощью этих трех, трех вещей, по большому счету, так, хорошо, значит, это мы доказали,
так, да, значит, вот эта равенство, оно, конечно же, носит название, называется уравнением
Колмогорова-Чепмана. Уравнением оно называется потому, что оно и может использоваться для
нахождения вот этой вот матрицы вероятности перехода между произвольными m и n, если известны
вероятности перехода перед более близкими по времени событиями, видите, mk и kn, то есть она
используется для нахождения p, то есть это как бы формула, как бы, функциональное уравнение, если хотите, на p.
Так, что из него следует, во-первых, смотрите, то, что вероятность, что вероятности перехода от
нулевого к n-тому моменту времени, сейчас я напишу и будет перерыв, это есть, что такое, это есть p от 0-1,
потом p-1-2, и так далее, p-n-1-n. Так что, если ты знаешь матрицы перехода от момента 0 к 1, от 1 к 2,
и так далее, n-1-n, это могут быть разные матрицы, то тогда ты их перемножаешь в этом порядке и находишь
матрицу перехода от момента 0 к моменту n. Вот эта формула, она, понимаете, чрезвычайно важна для
практики, ну потому что, представляете, вот допустим, вам дали задачу, вам дали цепь маркового, как-то ее
описали, неважно, там, может, в виде графа или чего-то, и вам задают вопрос, вот в момент нулевой было
такое это распределение, или даже вам говорят, в каком конкретном состоянии была цепь, а потом
спрашивают, а вот в момент n, который там, скажем, не 1 или 2, а 100, в каком состоянии будет находиться цепь,
или какого будет распределение, где она будет находиться, ну и как вы себе представляете такую
задачу, значит, вы такое говорите, ага, в начальный момент она была в нуле, в следующий момент она может
оказаться в нуле, в единице, в двое, там, в тройке, значит, потому что есть переходы из 0 в 1 в 2 и в 3,
а, скажем, из состояния 1 есть переход в состоянии 0, 2 и 3, ну короче, вот если вы начнете вот рисовать
все эти переходы, то для простейших случаев вы что-то напишете, но для немножечко более сложной
ситуации, когда n не 2, 3, а, скажем, 10, вот следить за всеми этими переходами и вероятностями и
перемножать эти вероятности, вы умрете, короче, ну что можно сделать, можно записать матрицы
перехода за один шаг, матрица перехода за один шаг, это простая вещь, и просто перемножить эти
матрицы, перемножить их можно не обязательно вручную, а на компьютере, вы получите какую-то
матрицу, вот она будет показывать вероятность перехода между либо ими состояниями от момента 0
к моменту n, то есть вы одна формула и при этом вы находите вероятности всех переходов между
этими моментами времени, вот, то есть для практики это великая вещь, вот то, что здесь написано,
значит это было то, как связаны матрицы перехода, а как это все связано с распределением вероятностей,
ведь допустим мы хотим знать, с какой вероятностью система будет находиться в том или ином состоянии по
прошествии какого-то времени, для этого есть у нас другая теорема, которая вот какая, вероятность,
вектор вероятности в этот момент времени, это есть п транспонированная переход от n-1 к n на p
n-1, то есть если тебе известно распределение в этот момент времени и матрица перехода, то тогда
вот так умножай с транспонированием здесь и ты получишь вектор в этот момент времени,
доказательство, тоже доказательство практически очевидное, значит мы записываем то, что стоит справа,
p и t от n, и ту компоненту берем, что это такое, это есть вероятность того, что xn равно i, дальше
пользуемся формулой полной вероятности, сумма по всем g из s, обуславливаем по всем настояниям,
вероятность xn равно i при условии, что xn-1 равно g, вот и умножаем на вероятность того, что xn-1
равно g, вот, а это есть, что такое, это есть сумма, g принадлежит s, p значит it gt n-1 n умножить
на p gt от n-1, вот, а нет, подождите, не i g, а g i, да, получается, на первом месте идет то,
откуда куда, вот, g i, ну и видите, здесь мы пробегаемся не по второму индексу, как матрица,
а по первому, как будто мы ее транспонировали, и умножаем уже вот так, но все, отсюда следует вот эта вещь.
Так, хорошо, хорошо, ну, соответственно, если нас интересует p от n, то, а мы знаем распределение в
начальном момент времени, то можно вот так написать, это p транспонированная n-1 n на p
транспонированная n-2 n-1 и так далее, до b транспонированная, так, нет, сейчас, а, ну да,
0, 1, p, 0, вот, потому что если вы знаете распределение в начальном момент времени,
то вы, умножая на матрице перехода за один шаг, вот так вот, получаете распределение в конечном
момент времени. Вот, хорошо, теперь мы с вами ограничимся только некоторым под классом, под
классом цепей Маркова дискретных, однородными цепями Маркова мы ограничиваемся. Определение,
значит, если p m, n равняется p, давайте так, m плюс k, n плюс k, вот, ну, для любых, для любых m,
n, k, m плюс k, n плюс k, больше либо равных нуля, вот, ну, понятно для каких, для любых m, n, k, так я короче
просто напишу, то дискретную цепь Маркова называют однородной. Ну, то есть, вероятность перейти из
нулевого в первого состояния, не так, вероятность перейти из нуля сегодня в единицу завтра точно такая же,
как перейти из нуля завтра в единицу послезавтра. Вероятности перехода, они не зависят от абсолютных
значений вот этих вот m и n моментов времен, только от их относительного зависит. Такая вот однородность
по времени. Тогда, кстати говоря, много всего упрощается в однородных цепях, тогда вероятность
перейти из 0 в 1 на самом первом шаге точно такая же, как перейти из 0 в 1 на втором шаге, на третьем
шаге и так далее. И в однородных цепях все вот эти вероятности становятся одинаковыми. То есть,
в однородных цепях, цепях P01 равняется P12, вот, равняется и так далее, равняется Pn-1n. Вот,
что еще можно сказать? Вообще P0n равняется P1n-1, равняется, так далее, равняется P, скажем там,
k, n плюс k. Вот, еще что можно написать? Ну, я по максимуму пишу, просто чтобы у вас
при глазами были все эти формулы, мы будем им пользоваться, например, 0n-m. Вот. Мы будем дальше
работать только с однородными цепями. Тогда, как все упрощается в однородных цепях, давайте посмотрим.
Теперь конкретно для однородных цепей. В однородных цепях вот эта формула, это что получается? Pn
равняется P, транспонированная от нуля до единицы в степени n на P0. Вот. Потому что все матрицы
становятся одинаковыми, они все совпадают с P01. Вот такая вот формула справедлива.
По этому поводу, кстати, мы можем вести даже обозначение, просто P, просто, без всяких скобок,
просто P. Мы будем это считать P01, вероятность перехода за один шаг. Вот. Значит, распределение
в произвольный момент времени, оно зависит только от распределения в начальный момент времени и матрица
перехода за один шаг. Дальше, что еще можно сказать? Значит, не помню, это теорема или не теорема? Нет,
не теорема. Значит, у нас есть формула Калмогорова-Чепмана. Давайте я вам напомню. Mn равняется
Pmk на Pkn. Это у нас в любых цепях, в том числе и в однородных. Но для однородных мы можем это
упростить. Что мы получаем? 0n-m равняется P0k-m на P0n-k. Вот. Если мне так вообще надо.
Или мне эта формула не нужна. Сейчас, секундочку. Pn равно Pn-1. А, ну в принципе можно и так, да.
Ну вот. В однородных цепях. Ну и если мы вместо m подставим 0, если m равно нулю. Ну да, пусть так
будет, например. Пусть 0. Тогда P0n равняется P0k на P0n-k. Видите, у нас здесь получается матрица P0 что-то.
Вот очень хочется какое-то обозначение вести, да. Потому что раз все, все сводится к ней. Давайте мы
обозначим P от n по определению. Вот тут там тоже определение. P0n. Вот такое будем использовать. То есть
P от единицы это просто P. А P от n это вот эта вещь. Тогда вот эта штука переписывается. То есть в
однородных цепях тогда P от n равняется P от k на P от n-k. Значит так, хорошо. И это для любого
k. Видите, здесь слева есть k. Точнее слева нет k, а справа есть. Как это разрешить? Это для любого
k справедливо. И для k равного 0, 1, 2, 3 и так далее. Вот это справедливо. То есть это справедливо
для любых k и n. Ну n больше либо равно k. Ну да, здесь вот столько всяких следствий получается.
Да, значит вот это первое следствие. Мы вводим вот эти два обозначения. Получаем вот эту формулу.
Давайте я даже выделю здесь главные формулы. То есть вот эту формулу можете выделить в рамочку.
Основные формулы какие? Вот это. Значит следствие той Pn равняется P транспонированное в степени n
P от 0. Вот это еще одна выделяете. Так, дальше. Следствие вот этой формулы, что отсюда можно
получить. Смотрите. P от n это есть P от n1, P от n2 и так далее. P от nk, где k произвольно, а n1
плюс и так далее, плюс nk равно n. Вот. То есть вот эта n это сумма вот этих n здесь. Это прямое
следствие вот этой формулы. Ну потому что ты берешь, например, k равное n1. Здесь получаешь n
минус n1. Потом вот эту формулу применяешь вот к этой P. Там n2 умножить на P от n минус n1 минус n2
и так далее. Вот. Но P от 0 это единичная матрица. P от 0 это единичная матрица. Потому что что это
такое? Ее элемент это перейти из i в g от момента 0 в момент 0. Вот. То есть это есть вероятность того,
что x0 равняется g при условии, что x0 равняется i. Видите, здесь один и тот же момент времени. Так что
если i равно g, то эта вероятность равна единице. А если i не равно g, эта вероятность равна 0. Вот
почему вот эта штука это есть единичная матрица. Но здесь это тоже используется. Вот это тоже выделите.
Вот это тоже важная формула в однородных цепях. Мы будем ей пользоваться. И если вот эту вещь мы
распишем, ну в терминах сумм, смотрите, что мы получим. Там будет очень важная формула для нас.
Если мы вот эту формулу распишем в виде сумм, получается, что P i t j t от n, ну то есть 0 n мы
будем обозначать просто P i t j t от n. По определению. По определению. То есть что такое? Это здесь
произведение стоит. Здесь много-много разных сумм. То есть это суммы. Какие? P значит i t, ну какая-то
l единица. За сколько шагов? За n один шаг. Потом P l 1 l 2 за n два шага и так далее. До P l не
знаю сколько. K минус один что ли. А последний кто? Это j. Значит от n k. Правильно?
Или что-то не так. Здесь должен был бы стоять l k и n k. А здесь суммы идут по l 1 из s и так далее,
l k минус 1 из s. Ну короче говоря, я просто расписал произведение k матрицы в виде вот таких
сумм. И важное следствие отсюда. Вот какое. То что P i t j t от n. Вероятность перейти из i в j за n шагов.
Она больше либо равна, чем вероятность перейти из i в какой-то l 1 за n один шаг. Из этого l 1 в
какой-то l 2 за n два шага и так далее. l k минус 1 j за n k шагов. Для любых l 1 l 2 и так далее.
Любых l 1 l 2 и так далее. l k минус 1 из s. Вот эту формулу тоже выделите. Очень много у нас будет
теорем, которые опираются на эту формулу. Много задач решается с помощью этой формулы. В общем,
очень много раз мы будем прям ссылаться на нее. Это очень важная вещь. Потому что P i t j t это сумма
по всем вот этим l 1 l 2 и так далее. Вот таких произведений. Это сумма по ним всем. Но все они
не отрицательны. Значит она больше либо равна каждого слагаемого здесь. Может быть иногда даже равна
в каком-то выраженном случае. Но вообще говоря она больше либо равна. Вероятность перейти. Ни в коем случае
здесь в общем случае нельзя ставить равенство. А то вы так можете придумать. Ага, нам надо попасть из
i в j за n шагов. Какова будет эта вероятность? И вы такой начинаете. Ага, я могу попасть из
i в l 1 за столько шагов, из l 1 в l 2 за столько шагов. Вы такое равенство пишете? Произведение
вероятности нет. Потому что попасть из i в j вы можете разными путями. Не только вдоль этого конкретного
пути, но разными путями. Вот. Но разными путями. Так что так. Такая формула. Так что у нас там еще?
И еще какое можно сделать следствие? Смотрите. Следствие вот этой формулы еще одно. Если мы возьмем k
равно n, n1 равно 1, n2 равно 1 и так далее. Тогда получается что p от n это p от 1 умножить на p от 1,
на p от 1 и так далее n раз. То есть отсюда также следует что p от n это есть p от 1 в степени n. То
есть просто p в степени n по нашим обозначениям. Значит, матрица перехода за n шагов это есть
n степень матрица за один шаг. Вы как? Получается интересно. Вот эту формулу тоже можете выделить.
Ну да, я понимаю формула много, но когда вы начнете решать задачи, то вы к этим формулам быстро
привыкнете и на самом деле ничего сверх такого за этим не стоит. Мы будем в основном работать с
однородными цепями. Вот. Так что придется эти формулы запомнить. Ну они все очень легко выводятся,
потому что даже если вы какие-то формулы не знаете, а будете применять формулу полной вероятности,
марковское свойство и формулу условной вероятности, вы будете сами за один шаг, за один-два шага к этим
формулам сами приходить в конце концов, кстати говоря. Потому что видите все вот эти теоремы,
которые сейчас были, они все доказываются элементарно. Ну и эту лекцию я закончу
некими интерпретациями на графах. Очень удобно вводить вот такие графы. Кстати,
может быть даже с этого и начать надо было. Вот представьте себе такой граф. Допустим у нас
С это тоже состоит из 0, 1, 2 и так далее. Может быть конечное, может бесконечное число. И Т у нас
тоже равно 0, 1, 2 и так далее. Тогда вот какой должен быть у вас образ в голове о цепи? Это вот такой
граф. Есть нольковое состояние, есть состояние единичка, есть состояние двойка, там ну состояние
тройка. Допустим вот такой нам далее. Значит, если П и Т житое за один шаг больше нуля, то мы рисуем
между ними стрелочку. И над стрелочкой рисуем вероятность перехода за один шаг. Потому что в
однородных цепях все определяется вероятностью перехода за один шаг. Только матрицы П. Видите,
П от Н это есть П за один шаг в степени Н. Значит это любого Н. Мы знаем вероятность перехода за
любой шаг. Все, зная вероятность перехода за один шаг. То есть вообще однородные дискретные цепи
Маркова определяются двумя вещами. Это начальным распределением, начальный момент времени и
вероятностью перехода за один шаг. Все. То есть вектором и матрицей. Ну допустим вот такую ситуацию
рассмотрим. Что мы можем попасть из 0 в 1 за один шаг с вероятностью 1-2. Либо попасть вот сюда с
вероятностью 1-2. Ну как бы сумма вероятности выхода должна быть единицей. Куда ты деваешься? Ты
можешь как бы обратно вернуться. Например, давайте здесь нарисуем. Когда ты в единице,
ты можешь попасть в себя с вероятностью 1-2. Ну допустим вот в 3 тоже с вероятностью 1-2. Ну и
какой-нибудь нетривиальный давайте рассмотрим. Допустим из 3 в 1 с вероятностью 1 треть, из 3 2 в
состоянии 2 третье. Так и двойку надо рассмотреть. А 2 в себя с вероятностью 1. Вот такие графы
называются стахастическими графами. То есть у них вершины это обозначение для состояний. В данной цепи
4 состояния 0 1 2 3. Стрелочки означают, что вероятность перехода за один шаг не нулевая. Вот.
Например, из 0 в 3 нет стрелочки. Значит за один шаг из 0 в 3 не попасть. Хотя можно попасть за два
шага. Видите? Вот. А над стрелочкой мы рисуем вероятность перехода за один шаг. Вот давайте
мы для этой ситуации все нарисуем и распишем. Что здесь будет? Что такое? Вероятность. Давайте
начнем. Вероятность перехода за один шаг. Значит это будет матрица 4 на 4. Значит вот здесь будет
стоять P00. Попасть из 0 в 0. Нельзя за один шаг. Вероятность 0. Дальше идем по строчке. Вероятность
попасть из 0 в 1. 1 вторая. Значит вот сюда рисуем 1 вторую. Дальше из 0 в 2 попасть. Тоже вероятность
1 вторая. Здесь рисуем 1 вторую. А из 0 в 3 за один шаг не попасть. Значит здесь рисуем 0. Вот мы первую
строчку заполнили. Смотрите сумма чисел в первой строке равна единице. Я вас не обманул. Дальше едем.
Теперь осматриваем единичку. Из единички в нолик мы не попадем. Нолик. Из единички в единичку мы
попадем. Одна вторая. Из единички в двойку мы не попадем. Нолик. Из единички в тройку мы попадем.
Одна вторая. Вот. Теперь осматриваем двойку. В нолик не попасть. Вот. Из 2 в 1 не попасть.
Из 2 в 2 попасть с вероятностью единица. Из 2 в 3 не попасть. Ну когда я говорю не попасть, я имею
в виду за один шаг естественно. Мы пишем матрицу за один шаг перехода. Вот теперь вероятность для
третьего состояния. Из 3 в 0 не попасть за один шаг. Из 3 в 1 мы попадем с вероятностью одна треть.
Из 3 в 2 с вероятностью две трети. Из 3 в 3 нет пути. Вот. Это матрица перехода за один шаг.
Все очень просто. Начальное распределение может быть какое угодно. Например, можно вот такое
начальное распределение задать. Что ты находишься с вероятностью одна вторая в состоянии 0,
с вероятностью одна вторая в состоянии 1, а в других тогда с вероятностью 0 ты находишься. Вот
просто пример. Пример начального распределения. Это порождает одну цепь Маркова. Вот такую вот.
Если будет какое-то другое начальное распределение это другая цепь Маркова. Формально говоря,
другая цепь Маркова будет. Потому что цепь Маркова это две вещи. Однародный цепь Маркова
это две вещи. Начальное распределение и вероятность перехода за один шаг. Если что-то из этого меняется,
значит цепь меняется. То есть последовательности ее вероятностные свойства они меняются. Ну,
может быть так что в начальный момент времени мы стартуем с какого-то состояния, например мы
стартуем из 0. В этом случае распределение будет такое 1, 0, 0, 0. Вот это означает,
что мы как бы детерминированно стартуем из 0 в начальном момент времени. Но в следующий
момент времени мы попадем куда-то, это уже будут какие-то случайные числа. То есть вот в этом
случае у нас это означает, что x0 для нашей случайной последовательности это как бы тождественная
единица. То есть выраженная такая случайная величина, которая с вероятностью 1 принимает значение,
ой, принимает значение 0, принимает значение 0, с вероятностью 1. А вот x1, x2 и так далее,
это уже будут какие-то случайные величины. Ну как найти распределение в следующий момент
времени? Допустим, вот для этой ситуации. Давайте мы вот эту ситуацию простейшую рассмотрим,
и допустим я хочу найти распределение над вероятностями состояний в следующий момент времени,
в единичку. Допустим, я вообще ничего не знаю про эту науку. Вот чисто и здравого смысла. Что бы
я здесь должен был написать? Но если я нахожусь в нуле, то на следующем шаге я либо буду в единице
с вероятностью 1, 2, либо в двойке с вероятностью 1, 2. В нуле и в тройке я точно быть не могу на
следующем шаге. Так что, в принципе, я могу сразу написать, значит, 0, 1, 2, 1, 2, 0. А на втором шаге,
опять же, если бы я не знал всю эту науку, а вот тут хитрее. Смотрите, ведь я здесь с вероятностью 1,
2 и здесь с вероятностью 1, 2. Значит, на втором шаге с какой вероятностью я буду в нуле? Ну,
если я ушел в двойку или в единичку, я уже обратно не вернусь. Поэтому, в принципе, я могу здесь сразу
написать 0. Вот. Если я попал в двойку, а нет, в единичку, тогда на следующем шаге я обратно
не вернусь, но я могу здесь остаться с вероятностью 1, 2, либо пойти в 3 с вероятностью 1, 2. Поэтому,
ну, чувствуете, да, что начинается? Какая-то комбинаторика начинается. Я должен рассматривать все
вот эти всевозможные случаи. Одна вторая, одна вторая, там, короче, это все. Вот, знаете,
здесь я уже все. Вот чуть-чуть о чем-то задумался, о, снежок пошел, и все. И у тебя обнулилась память.
И ты опять напрягаешься. То есть даже, знаете, для простейших ситуаций вот этот вот анализ
стрелочек без этой науки и ты все, и ты закопался, ты ничего не сделаешь. Какую-нибудь стрелочку,
знаете, обратно нарисовать, все, сразу же все усложняется. Но у нас есть формула. Что нам
голову ломать? У нас есть формула, что π от n, это есть p транспонированная в степени n, p от 0.
Так? Значит, получается, что распределение в произвольный момент времени мы можем получить
таким образом. Например, p, давайте от единицы начнем. Как бы по науке, по науке, как мы должны
делать? p от единицы равно. Это p транспонированная на p от нуля. Значит, мы транспонируем вот эту
матрицу. Это в принципе легко сделать. Это не такое напряжение ума. Вычислений-то нет. Просто
переставить что-то местами. И умножить на p ноликовое. p ноликовое это один и все нули. То есть,
по сути, нам нужно вытащить первый столбец вот этой матрицы. А первая столбец этой матрицы
первая строка этой матрицы. Ноль, одна вторая, одна вторая ноль. Опа. Видите? Что происходит-то?
Ноль, одна вторая, одна вторая ноль. Вот это мы получили вообще бесплатно. Без всякого анализа.
А теперь p2. Это что такое? Это p1. Ну, можно так, смотрите, можно вот так написать, а можно
вот так написать. p транспонированная умножить на p1. Так? Значит, нам надо просто взять вот эту
матрицу и умножить на p1. Ну транспонировать и умножить на p1. Вот. Тогда эта операция сводится
к умножению, к транспонированию. Давайте так. Ноль, одна вторая, одна вторая ноль. Ноль, одна
вторая. Ноль, одна вторая. Ноль, ноль, один ноль. И ноль, одна треть, две трети, ноль. Вот. И это мы умножаем на
ноль, одна вторая, одна вторая ноль. Всё. И дальше мы умножаем. Здесь будет ноль, и мы действительно могли это...
Видите, мы здесь вот этот ноль написали. Это действительно так. А здесь, смотрите, что получается, ноль, одна четвертая,
ноль, ноль, одна четвертая. Здесь ноль, ноль, одна вторая, ноль, одна четвертая. Всё. Спинным мозгом просто
посчитал. Понимаете? Как всё резко упростилось. И я не ломал себе голову с этими стрелочками,
куда мы там, по каким путям пойдём. Так что, пользуйтесь этими формулами. Мы можем также считать p3 и так далее.
Ну вручную, конечно, тяжело считать, но компьютер есть для этого. Компьютер-то может умножить матрицу на вектор.
Очень быстро. Вот так вот всё делается. Мы можем находить распределение в произвольном момент времени.
Вот. Так. Ещё замечание, какое можно сделать. Как видите, распределение подчиняется некоторому
уравнению. p от n равняется p транспонированное n p0. И вот то, чему будет равен p и n, и его асимпатические
характеристики, когда n стремится к бесконечности, это будет определяться собственными значениями матрицы p,
матрица перехода. Вот такой вот подход к изучению свойств дискретных цепей через собственные значения
матрицы перехода. Он имеет место быть, этот подход. Известны даже какие-то содержательные результаты
этого подхода, но он очень ненаглядный. И некоторые утверждения, которые позволяют получить труднопроверяемые
эти свойства, то есть надо собственные числа искать. Если матрица большая, там миллион на миллион, p,
то непонятно, например, непонятно, как находить эти собственные числа с большой вероятностью там,
с большой точностью. В общем, этот подход довольно неудобный. Вместе с тем в приложениях встречаются
большие p. Например, представьте себе интернет или какую-то локальную сеть. Много компьютеров,
это много вершин. Пользователи, когда приходят в эту систему, он заходит на какой-то сайт,
потом перемещается, кликая куда-то на другой сайт и так далее. То есть пользователь, как марковская
цепь, перемещается между сайтами с какой-то вероятностью. И много пользователей перемещается.
Интернет большой. И допустим, тебе хочется понять, как вся эта ситуация устаканится в пределе,
когда ты запустишь много пользователей или когда один пользователь будет очень долго перемещаться,
на каких сайтах он будет, в какие сайты он будет приходить чаще, чем другие. А тебе это может быть,
например, нужно как раз для ранжирования страниц. Если человек вбивает что-то в поиск,
нужно праранжировать по вероятности того, что человек будет посещать те или иные сайты.
То есть тебе нужно как-то сопоставить вероятность посещения каждому сайту. Для этого тебе нужно
асимпатические свойства исследовать. То есть как бы запустить такого виртуального человека,
позволить ему бесконечное раз перемещаться, потом посчитать в среднем, где он бывает,
и частоты праранжировать. И тогда выдавать сайты в соответствии с этими частотами,
которые получились. Но для того, чтобы так делать, ты должен понимать асимпатические свойства марковских
цепей. Когда ты увеличиваешь время, что происходит с цепью, как вообще формируется это предельное
распределение. Так вот я и говорю, что если матрица P большая, а ты пытаешься найти ее собственные числа,
то это тяжело. Ты должен находить собственные числа с большой точностью. Ты должен возводить P в большую
степень N. Что там будет проходить? Какие ошибки? Это будет совершенно ненаглядно. Но что если я вам
скажу, что на самом деле ничего это не надо делать? На самом деле мы с вами научимся на следующей уже
лекции просто посмотрев, ну даже не на следующей, а еще через лекцию, просто посмотрев на картинку,
сразу про нее все сказать, что будет в пределе. Ничего не вычисляя вообще, просто посмотрев на
картинку. Никакие умножения матриц на вектор, никакие собственные числа, ничего этого. Просто
посмотрев, сразу можно сказать, что будет. Вот. Но для того, чтобы уметь это делать, нам нужно будет
классифицировать состояние. Оказывается, состояния дискретной цепи обладают разными свойствами.
Бывают существенные и несущественные состояния, нулевые и ненулевые, возвратные и невозвратные,
эргодические, периодические. Вот на следующей лекции мы с вами классифицируем эти состояния.
Это будет как бы тот инструментарий, который нам позволит анализировать цепи и потом говорить
сразу же, посмотрев на цепь, что в ней будет происходить в пределе при стремящемся к
бесконечности. Вот. Это суперважная наука. Вот. Очень легко, удобная. И мы будем с вами учить это
следующего раза. Всё. У меня на сегодня всё.
