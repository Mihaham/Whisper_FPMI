Что у нас было на прошлой лекции? На чем мы с вами закончили? Минимальная основная дерево и алгоритм
прима. Было такое? Было чудесно. Вот смотрите, сегодня мы будем с вами с этим продолжать.
Но перед тем, как пойти дальше, на семинарах почти, наверное, вам что-то сказали, что существует
какой-то алгоритм краскала, крускала, как его только не называют, бедолагу. Вот. И для того,
чтобы к нему перейти, необходимо сначала поговорить про систему непересекающихся множеств. Это
достаточно важная и интересная тема сама по себе. Что такое система непересекающихся множеств?
Представьте следующее. У вас есть некоторая такая задача в том, что у вас есть n элементов,
они как-то перечислены, и вот вы присваиваете им номера. И они могут быть разбиты на
непересекающиеся множества. Вот здесь вот представлено А1, А2 и какое там АКТ. А1 это 024,
А2 это 1.6, АК опять. Например. Вот. Требуется построить какую-то эффективную структуру данных,
которая будет поддерживать три операции. Это make set. Это создать новое одноэлементное множество,
то есть я могу вводить новые элементы и давать им новые номера. Find set. Он возвращает некоторый
идентификатор множества, то есть к какому множеству оно относится. Ну не знаю. Эти все вершины,
там вершины или какие-то элементы, они там красные, грубо говоря. Вот find set может возвращать вот это
вот понимание, к какому именно множеству мы относимся. То есть в данном случае там, не знаю,
А1, А2, А3 и так далее АКТ. К какому-то из них. И мы будем считать, что два множества лежат,
ой, два элемента лежат в одном множестве, когда у них find set как раз таки одинаковые. Вот. И последнее,
что нам нужно еще union. Union это когда мы хотим объединить два множества. Make set ничего не подается,
он просто увеличивает на один количество элементов, создает новое множество из одного
элемента. Из какого элемента? Вот мы говорим, что у нас точно мы знаем, что у нас n элемента,
значит из n плюс первого. Вот. То есть оно вот так вот увеличивается итеративно. Можно это
прописать внутри make set, а здесь как удобнее, но в данном случае мы будем делать так. А что здесь
есть? Какие есть идеи? Идея номер один. Давайте с вами организуем следующую структуру. У нас
будут множество, у каждого из множества будет некий представитель. Представителем множества будет
являться один из элементов этого множества. Мы скажем просто вот ты главный и все. Вот. Ну,
у вас так старость выбирали, да скорее всего. Вот ты главный типа все, делай что хочешь. А это
является представителем множества и все ссылаются на него. Все элементы, которые у нас есть в этом
множестве, когда мы будем вызывать find set, они будут указывать на этого представителя. Вот здесь вот у
нас с вами нарисовано 2, 0, 8, 5, 4, 7 и смотрите 0 и 5 они указывают на 2 и 8 тоже. И они говорят,
что я ссылаюсь на представителя. 4 и 7 ссылаются на 8, а 8 ссылается на 2. То есть мы будем вот так
вот и итеративно ходить до того момента, пока мы не дойдем до какого-то элемента, который ни на
что не ссылается. Благодаря этому всему мы с вами построим такой вот лес непересекающихся множеств.
В этом лесу непересекающихся множеств мы с вами как раз таки и будем говорить, что мы можем находить
представители. Представители будут эти корни, на которые ссылаются. Вот и все. Понятно, что
происходит. Понятно, как это выглядит между собой. Сама по себе структура несложная, правда? Вот.
Как написать find set, представляете здесь? Как? Да, то есть просто идем вверх и складываем. А вот если
мы захотим объединить эти множества, что мы сделаем? Да, да. То есть один корень возьмем,
переподвесим и покажем, что он будет теперь указывать на какой-то другой корень. В действительности
все достаточно просто. Find set можно написать while, а можно написать рекурсивно. Но как бы здесь как
вам удобнее. Но фактически find set будет делать вот такую вот вещь. Он будет while идти до тех пор,
пока x не равен parent x, то есть пока он сам на себя не указывает, и подниматься по parent. Как только
он дойдет до этого момента, он вернет сам x. То есть вот это тот представитель, который у нас
является данного множества. Что важно понимать? Важно понимать, что у нас время работы find set
будет зависеть от высоты. Какая может быть максимальная высота? N. Неприкольно и с этим
работать неинтересно. Вот это первый момент, который мы должны понять, что с этим делать. Нам
надо подумать. Второй union мы объединяем наше множество. По факту мы просто переподвешиваем,
у x находим, кто является представителем, у y находим, кто является представителем, и говорим,
что parent x становится y. Вот, то есть x это вот то самое множество, с которым мы работаем. Здесь
все понятно, все просто звучит. Хорошо. Вся проблема именно в этом выражении, в том,
что у нас будет работать все за o от n. Это неприкольно, это не круто. Что же делать? Какие есть идеи?
Бинарная, ой-ой-ой, сбалансировать его еще, вот это вот все не хочу. Учитывая, что их
переподвешивать будет неудобно друг к дружке. Кучу сделать тоже неприкольно, потому что мы потом
должны как-то переподвесить их друг к другу, а они могут элементами расходиться. Давайте,
я в вас верю. Много разных деревьев, но такого еще не было. Много разных деревьев проходили,
это правда. Смотрите, давайте начнем с простой мысли. Вот у меня есть
вот такое дерево и такое дерево. Какое подвесить к какому лучше? Правое к левому, почему? Чтобы
высота не росла. Вот, хорошо, и вот сделать и сделать указатель вот таким вот образом. Правильно? То есть
я могу так их взять и объединить. И в действительности это называется ранговый евристикой. То есть
подвесивать менее глубокое дерево к более глубокому. А в этом случае что у нас происходит,
когда мы подвешиваем менее глубоко к более глубокому? Высота не растет сама по себе. Согласны? Как это
оценить? Мы сейчас будем с вами оценивать, к чему это приведет. Но в действительности, когда мы так
объединяем, то у нас все хорошо. Единственный случай, когда у нас высота может возрасти,
это только тот случай, когда у нас одинаковая высота. У обоих этих множеств. В этом случае
высота вырастет на один. И неважно, какое мы к какому подвесим. Согласны? Вот, поэтому union
будет выглядеть так. Рангом выступает здесь глубина дерева. Это называется ранговый евристикой. Это
улучшение того же того процесса, который у нас есть. Мы сначала находим представителя у х,
представителя у у. Говорим, что теперь х и у это представители. Дальше мы сравниваем ранг у х и
ранг у у. Если какой-то из них меньше, то меньше подвешиваем к большему. Если одинаково, тогда нам
здесь без разницы. Мы их подвешиваем одно к другому. Например, здесь у меня подвешен х к у. И мы
увеличиваем ранг у на один, потому что мы знаем, что у них высота одинаковая. Значит, высота
увеличилась на один. Согласны? Вот, это первый момент, который у нас есть. Сколько это работает и
почему это хорошо? В действительности утверждение следующее. При использовании ранговой евристики
размер дерева с корнем в х будет равен 2 в степени ранг х. Больше ли бы равен? Количество вершин, да.
Количество вершин в нашем множестве. Вот утверждение такое. Как будем доказывать?
Но это можно, но это сложно. По индукции, да, в действительности легче всего по индукции сделать.
Почему бы нам не попробовать это сделать? Смотрите, в начальный момент времени, когда у нас один
элементик, мы говорим, что у нас высота дерева ноль согласна с тем, что один больше либо равно
одному. Правда? Логично, чудесно. Значит, это база индукции сделана. Теперь, когда мы говорим с вами
о продолжении этого всего, у нас есть два поддерева, для которых выполнено данное условие,
что size х больше либо равно, чем 2 ранга х, 2 в степени ранг х, и size y больше либо равен,
чем 2 в степени ранг y. Отлично. Какие есть два варианта без ограничения общности? Если с
ограничением, то три варианта. Но будем считать, что у нас ранг х либо больше, либо равен. То есть,
меньше аналогично вот первому случаю, который был. Мы говорим, что если у нас ранг х больше,
чем ранг y, то в этом случае я y подвешиваю к x. Размер моего x будет равен size x плюс size y.
Согласны? Ну, как бы, я соединил все вершины, получил два размера. Это больше либо равно,
чем 2 в степени ранг x, плюс 2 в степени ранг y. Правильно? Правильно. Из утверждения,
которое было выше, то, что мы предположили. Чудесно. Могу я выкинуть два ранга y? 2 в степени
ранг y? Ну, могу. Ничего не изменится. Отлично. Я говорю, больше либо равно, чем 2 в степени ранг x.
А теперь смотрите, ранг x и ранг штрих x, это вот, когда мы добавили вершины, они одинаковы или нет?
Ранги. В этом случае да. Почему? Потому что высота не изменилась. Согласны? Задайте вопросы. А то вы
смотрите, читаете, либо не понимаете, либо понимаете. Понятно, что происходит? Как этот
случай выглядит? Он выглядит вот так. Только здесь x, здесь y. Высота не изменилась, ранги не
изменились, поэтому ранг у x и у нового x одинаковые. Все чудесно. Мы доказали для этого случая. Теперь
вопрос встает, когда у нас одинаковые ранги, у нас увеличивается высота. Давайте смотреть,
что у нас происходит. Мы говорим, что size штрих, ну, то есть вот новый, который у нас есть размер,
ну, он, естественно, складывается из двух size, что логично. Вот. А это раз. Дальше мы говорим,
что, по предположению нашей индукции, это 2 в степени ранг x плюс 2 в степени ранг y.
Смотрите, ранг x и ранг y равны? Равны. Значит, 2 в степени ранг x плюс 1. Да? Ну, а ранг x плюс 1
это высота моего нового дерева? Это тот самый новый ранг x. Поэтому это 2 в степени ранг 3x.
Логика простая. Окей. Принято. Чудесно. Какое из этого следствие, из этого следствие,
что высота нашего вот этого дерева, которое есть, оно не больше, чем логарифм?
Ну, смотрите. Высота. У нас меньше ранга, ранг меньше чего? Под рангом высоту. А, я понял. Смотрите,
а мы говорим о том, что у нас здесь немножко в другую сторону меньше либо равно должно идти.
Высота это и есть ранг. Все верно. Тут равно должно быть. История. Ошибочка.
Еще раз.
Ну, для нулевого элемента, да, типа, ну, как бы это не сильно считается.
Не совсем так. Ашат-х. А, ты имеешь в виду, что вот здесь ашат-х, вот здесь разная ашат-х.
Смотрите, я беру максимальное ашат-х и говорю высота с самого дерева. Вот. Ну,
в действительности, как бы берем логарифмируем, получаем логарифм. Окей. То есть,
у меня уже логарифмическая здесь сложность, и она лучше, чем вот уже хорошо. Что-то мы с вами
сделаем. Как еще могу улучшить? Как вы думаете? А? Ну, не-не-не-не. Это перебор. А? Зачем? Зачем
штаблица? Да. Давайте еще. Смотрите. Вопрос следующий. Предположим, что у этой вершины я вызываю...
Скажите мне, вот я вот поднимаюсь, прихожу к своей вершине X, которая является представителем.
А нелогично, что пока я поднимаюсь, вот это, ну, не знаю, давай, 0, 1, 2, 3. Почему бы мне не
сделать так, чтобы в следующие вызовы я не поднимался больше так долго и сделать вот так.
Ну, нет-нет-нет. Я поднимаю вот именно каждую из вершинок. То есть, я смотрю, ага, один указывает
на X. Ну, отлично. Два, давайте вот я подниму тоже выше. Ну, как бы зачем я буду еще раз ходить? Я
же файнсетом все равно буду спускаться вниз и искать это, точнее, идти вверх и находить представителя.
Почему бы сразу все это не переподвешивать? Но здесь я буду делать это рекурсивно. То есть,
смотрите, я спускаюсь сюда, спускаюсь сюда, спускаюсь сюда, нахожу, грубо говоря, что мне
нужно, а потом поднимаюсь обратно. То есть, раскручивается так я буду. Ну, точнее, вот так, да.
Нахожу представителя и в обратную сторону говорю, что один подвешивается к X,
parent 2 становится X, parent 3 становится X. Почему бы так не сделать? Как вы думаете,
как называется такая ивристика? А? Мы до этого дойдем. Нет, не будет. А в действительности это
просто называется сжатие путей. Это ивристика сжатия путей. То есть, смотрите, как ее добиться?
Ну, достаточно просто. Мы делаем файнсет от какого-то X и говорим, что если X равен parent X,
то возвращаем X. Ну, то есть, сам корень нашли. А если нет, то мы говорим, что parent X равен
файнсету от parent X. Что здесь означает? Вот у меня есть некоторая вершина. Некоторая вершина здесь.
Я говорю, parent этой тройки равен файнсету от parent этой двойки. Ну, вот от этой двойки смотрю.
Теперь от нее я смотрю на единичку и такой. Ну вот, parent у двойки равен файнсету от единички.
И поднимаюсь. Дальше, когда я дошел до конца, то есть дошел до окончания своей рекурсии,
я раскручиваюсь назад. 1 становится X, 2 указывает на X, 3 указывает на X.
С точки зрения написания кода, изменили мы ровным счетом почти ничего. То есть,
не сильно много у нас здесь вернулось. Согласна? Но вот с точки зрения ивристики у нас появилась
хорошая вещь. Что нам это само по себе дает? Это утверждение без доказательства. Звучит оно так.
Если вы используете ивристику сжатия путей плюс ранговую ивристику одновременно, то в этом случае
файнсет работает за O от обратной функции Акермана. Как вы видите, здесь обратная функция Акермана,
альфа от единички, ноль, альфа от трех, один, альфа от семи, два, альфа от шестидесяти одного, три.
Как вы думаете, какое следующее, чтобы было четыре? Все правильно. 2 в степени 2, в степени 2,
65536. Минус три. Это будет четыре. Очевидно, что все правильно. Смотрите, обратная функция Акермана
растет крайне медленно. Она, конечно, растет, но очень медленно. Поэтому в этом случае мы говорим,
что это почти константа. Понятно? Вот. Ну, чтобы нам не надо было это все доказать,
поэтому вас теряем без доказательства. Ура. Вот. Кроме того, вы периодически, если где-нибудь будете
читать про систему непересекающихся множеств, в виде ранга можете увидеть не высоту, а можете
увидеть количество элементов. И вот просто к менее кучному, назову так, дереву вы подвешиваете,
тем более кучно, подвешиваете к менее кучному. Вот. Так тоже можно. Такое тоже будет работать,
и тоже работать с функцией Акермана, если немножко другой констант, но суть-то останется такая же.
И как бы все хорошо. Кроме того, задачка всем наподумать, я попрошу семинаристов, может быть,
с вами подумать. Я подумаю об этом, чтобы предложить это семинаристам. Почему ивристика сжатия
путей одна сама по себе тоже будет давать логарифм. Вот. В общем, вот такие вот приколы.
Прикольная структура данных. Откуда это появилось? Здесь, к сожалению,
без четкого доказательства не сказать, потому что сначала поговорить про функцию Акермана,
а потом брать обратную функцию Акермана. То есть здесь чуть больше от этого всего. Но если очень
хочется, можно почитать странички, наверное, четыре доказательства в Курмане, если не ошибаюсь. Вот.
Ну как бы четыре странички в Курмане, это много для доказательств, на самом деле. Но такое есть. Есть
еще вопросы. Понятно? А теперь смотрите. Как вы думаете, зачем я вам это все рассказал сейчас?
Для Миностовы. Зачем в Миностове? Я так сказал. Хорошо. Есть еще варианты. Вот давайте. Кроме этого.
Угу. Смотрите. Помните лему о безопасном ребре? Был такой. Мы сейчас немножко, немножко уйдем в
сторону. По сути, будем говорить о том же. Представьте, что у меня есть некоторый граф.
Какой-нибудь такой. Мне нужен Миностов отсюда. Давайте представим каждую вершину как какое-то
свое множество. Какое ребро лучше всего добавить сюда, чтобы оно было минимально остовным деревом? Самое
маленькое. Логично? Логично. И причем это ребро должно соединять два разных множества. Иначе,
если оно уже в одном множестве, вершины находятся, зачем их соединять? Согласна? То есть, ну давайте
здесь чиселки мне придумайте. Семь, двенадцать, один, три, пять. Хорошо. Вот. Смотрите. Грубо говоря,
представьте, у него разукрашены там разные цвета какие-то. Вот вы берете самое минимальное
ребро из своего графа и говорите, ага, проведу его. Теперь вот эти вершины разукрашены одинаково.
Фактически, они будут ну, не знаю, нулевого цвета какого-нибудь. Вот это там будет один,
два, три. Что я делаю дальше? Я смотрю с вами и говорю, ага, следующее ребро три. Оно соединяет
множество ноль с множеством три. Оно соединяет разные множества. Нам их все равно нужно соединить
в конце концов, поэтому давайте я их соединю. И тогда тройка станет нулевым множеством, например.
Пойдем дальше. Три. Теперь у меня четыре. Четыре будет соединять первое со вторым множеством.
Разные множества. Разные. Давайте соединю и пусть это множество станет единичкой. Теперь у меня
осталось два множества. Осталось как-то соединить. Давайте смотреть. Вот у нас уже использовано это
ребро, это ребро, это ребро и все пока. Сталось пять. Следующая пять. Пять соединяет первое и нулевое
множество. Давайте это соединим и теперь все множество единичек станет нулевым. У нас все
соединилось. Но мы должны рассмотреть ребра, потому что так алгоритм будет работать. Мало ли,
последнее ребро будет самое нужное, к примеру. Вот. Дальше мы смотрим на семь. Семь будет соединять
множество ноль с множеством ноль. Нам такое ребро не нужно, мы его пропустим. Аналогично для восемь,
аналогично для двенадцати. Прошлись по всем ребрам, выбрали минимальное, добавили их в свое
дерево, получили миностов. Прикольно? Вот. И для того, чтобы поддерживать вот эту раскраску некоторую,
нам и понадобится система не пересекающихся множеств. Мы именно с ней и будем с вами работать.
Вот. Ну как бы, как работает данный алгоритм? Ну, к сожалению, вам ребра не всегда в отсортированном
списке даются. Поэтому нужно сначала считать ребра, потом по весу их отсортировать. Это самая
сложная операция здесь, которая есть, и работает она за Е лог В. Е лог Е, как угодно. Одно и то же
будет лог Е и лог В. Ну а дальше проходимся по всем ребрам. Создаем сначала N представителей,
сколько у нас есть вершин. Дальше мы проходимся по всем ребрам и соединяем наше множество. Делаем
если у них разные представители. Итак, мы понимаем, какие ребра мы вкладываем, какие нет миностов.
Понятно? Вот так работает данный алгоритм сам по себе. Вот. Нет ничего сложного.
Я помню, когда... Какой вопросик? Можешь задать? Вы можете задать вопрос.
Мы ищем ребра.
Ну, не обязательно. Минимальное основное дерево это то, где мы оставляем все вершины,
и граф должны получить связанным, добавив с минимальным суммарным весом. То есть граф должен
быть связан просто. Вот. Что, есть вопросы? Нету. Вот. Расскажу поучительную историю относительно
поучительную. Это, получается, мой был то ли первый курс, то ли второй. Я уже не помню,
когда был этот алгоритм. Вот. Я решил, что типа на итоговом контесте я напишу сначала алгоритм
примы. Он мне не заходил. Вот. Ну, просто категорически не заходил. После этого я взял,
все переписал на алгоритм краскала, и все получилось. Такая вот маленькая история. Причем,
ну, как бы алгоритм примы, я причем помнил, как он пишется. Он у меня был написанный. Даже вот так
получилось, что он оказался у меня написанным. Но он не работал, понимаете? Вот. То есть такие вот
ситуации тоже бывают. Осторожнее с этим. Лучше понимать алгоритм, потому что алгоритм краскала,
я просто помнил основные концепции и идеи. Вот. Алгоритм примы мне никогда не нравился,
но так уж получилось. Сейчас я отношусь к нему, назову это так, толерантно. Окей. Последний
алгоритм праминостовы. Это алгоритм барувки. Алгоритм барувки в действительности соединяет
в себе какую-то часть из примы, какую-то часть из краскала. Каким образом алгоритм барувки работает?
Я лишь объясню сутивую его часть. Покажу код, мы с вами его разберем, но вот прям сильно-сильно
погружаться вы, если что, на семинарах это сделайте. Смотрите, у вас все так же существует множество
деревьев в самом начале. Вот вы, одноэлементных вот этих вот деревьев, которые есть. А для каждого
отдельного дерева вы ищите минимальное ребро, которое из него исходит, и оно должно связывать
его с другим каким-то представителем. Вы связываете их, после чего добавляете эти
ребра в ваш миностов и обновляем эти деревья. То есть обновляем вот это вот множество деревьев,
которые у нас есть. В системе не пересекаются их все множество. И повторяем это до тех пор,
пока у нас количество деревьев больше одного. Почему это работать должно быстрее? Да, мы каждый
раз можем уменьшать почти в два раза. Мы не будем это сильно много доказывать с алгоритмом барувки.
Вот, но просто в том суть, что да, если в краскале вы идете по одному ребру каждый раз,
то в этом случае вы просто смотрите минимально на каждом шаге для каждого из элементов и
пытаетесь их связать. Понятно? Смотрите, краскал что делает? Он смотрит конкретное
ребро и смотрит, что здесь происходит. Что делает барувка? Давайте на этом же примере.
Что у нас тут? Ну, давайте смотреть. Я беру вот это вот элементик. Какие
минимальные ребра, какие ребра из него выходят? 4,12,7. Какое для меня выгодно? 4,
отлично. Иду дальше. Смотрю в этом. Какое для меня выгодно ребро минимальное? Какое
ребро для меня выгодно? 4,5,8. 4 опять. Ничего не происходит. Хорошо. Поехали дальше. В этой
вершине 7,1. Всё. 1. В этом, в этой вершине 1,12,5,3. 1. Оставляю также. Здесь смотрю 8,3. 3.
Смотрите. Видите, после первого обхода я уже соединил вот так. Алгоритм же краскала в самом
начале провел мне лишь вот это ребро. Понятно? То есть мы здесь идем итеративно, добавляя по
одному ребру и проверяем и сделаем от всеми писькающих множеств. Здесь же наоборот. Мы с
вами раз хлопнули. И теперь смотрите, что мне осталось. У меня появилось два вот таких вот множества.
Давайте теперь их соединим минимальным ребром. Можем? Можем. Получится вот так.
Откуда узнаем минимальное ребро? Мы можем пройтись по всем вершинам. Мы можем хранить эти
минимальные ребра и смотреть как... Ну то есть мы можем ходить в вершинку и смотреть, что там
происходит в принципе. Вот. Можем делать похоже на примо. Помните, у нас был разрез, мы обновляли,
вот это все такое. Вот. Можно делать здесь разными вещами. Но как выглядит вообще весь этот код?
Смотрите. Мы с вами строим вот эту систему неприсекающихся множеств с самого начала. И дальше
мы говорим, что пока у нас множество не одно, мы повторяем один и тот же код. Какой код? Мы
смотрим минимальное ребро. Ну вот у нас минимальные ребра. Мы будем сохранять их как раз таки в нашем
массивчике. Дальше проходимся по всем ребрам, которые у меня есть. Я говорю, что у меня есть
компонент В, есть компонент У. Смотрю, в разные ли компоненты это смотрят. В разные, тогда буду
их соединять. Не в разные, не буду их соединять. Ну то есть если в одной тоже компоненты это смотрит.
То есть я прохожусь просто по всем ребрам. И благодаря тому, что я прохожусь, сколько раз я
пройдусь, ну я прохожусь Е раз. Мне нужно пройтись по всем ребрам, чтобы проверить в самом начале.
А дальше вот сколько раз вот это вот все будет объединяться друг к дружку. Ну где-то логорифт на
самом деле. Поэтому это будет Е лог. Ну вопрос константа. Это чуть быстрее будет. Вот так что так.
Понятно, что делает алгоритм Барувки? Вот он просто некоторые вот части оттуда,
части отсюда. Вот оно так получилось. Ну больше всего на краскала, конечно, похоже.
Вопросы остались к минимальным основным деревьям? Нет. Тогда переходим к одной
из самых интересных тем. Называется кратчайшие пути. Что помните про кратчайшие пути?
Зря. Все ее любят. Особенности на собеседование. Потому что все ее почему-то на самом деле кратчайшие
пути запоминаются. Вот то есть как бы у этого есть максимальное практическое применение. Вот.
Потому что представьте следующую картину. Вот у вас есть, вот любите вы играть, не знаю,
на мини-карте тыкаете, и вот вам нужно дойти до какого-то места. И он же вам как-то ее прокладывает
по минимальному пути. А вот. А навигатор. Ну как бы сейчас это чуть более интеллектуальная вещь,
тем просто типа от точки до точки посчитать километры. Но опять же, вот он у вас как-то
строит этот некоторый граф, как вам пройти. Но там уже учитываются пробки и так далее. Крутили,
навертели. Но суть все равно остается такая же. И так далее. То есть это кратчайшие пути это
одно из самых применимых, что есть. И пока что вы знали только один алгоритм поиска. BFS. Был
такое. И 0K BFS был. Был такое. Отлично. Теперь давайте говорить про кратчайшие пути в принципе.
Смотрите. Представьте, что у нас как бы не целые числа могут выступать для нашего графа весами
наших ребер. А вообще любые действительные числа. То есть существует некоторая весовая функция из
ребра в какое-то множество положительных пока чисел. Ну не отрицательных. Окей? Не отрицательных
чисел. И вот у нас есть некоторая вершина S. И вот из нее нужно найти кратчайшие пути до остальных
вершин. То есть вот откуда, как я должен ходить из моей вершины S в остальные вершинки. За сколько
минимальное количество времени я могу дойти. То есть это конкретная вершина до всех остальных.
Вот такая вот построение задачи. Понятная задача. Задача как бы изучить несложно. И первое,
что здесь есть, это алгоритм Dijkstra. Смотрите, алгоритм Dijkstra очень похож на алгоритм Прима.
Вы не поверите. Это вот почти что одна и та же сущность будет. А алгоритм Dijkstra... Прима же,
я же не ошибся. Да, вот. В действительности мы будем говорить с вами следующее. В любой
момент времени мы будем поддерживать два каких-то множества. Множество вершин,
которые мы уже прошли и нашли там кратчайшие пути, и множество непокрытых вершин еще. Это
будет два непересекающихся множества. И у них есть разрез. Ну это разрез просто нашего графа.
Правильно? Вот. И что будет делать алгоритм Dijkstra? Он будет находить минимальное ребро из этого разреза.
Между этими разрезами. И говорит, вот пойду по нему. И тогда мы будем находить расстояние до наших вершин.
Вот. А мы будем поддерживать это все в массиве некотором Dist. Ну D здесь. D, где мы будем хранить
сам этот кратчайший путь. И в зависимости от него куда-то идти. То есть мы будем вот так вот расширяться,
расширяться, расширяться и смотреть, что у нас происходит. Вот. Ну то есть давайте опять
нарисуем какой-нибудь граф. Вот так хочу. Представим, что я хочу из этой вершины пойти. Вот у меня есть
так, так, так, ребро. Вот так. Вот. Я буду выбирать минимальные ребра из этих. И дальше по ним ходить. Как
вы думаете, это будет работать вообще? Будто бы нет. Как будто бы да. Непонятно. Так мы же смотрим по
разрезам. То есть представьте, что мы вот добавили вот эти все вершины. Мы же пойдем во все остальные. Они
как-то связаны с другими. Ну либо граф не связан. Как выглядит сам алгоритм Dijkstra в этом случае? Ну
смотрите, мы все также говорим, что у нас есть одна вершина и есть другое множество вершин. Мы говорим,
как мы будем отличать множество одно от других? Мы будем говорить, что в одном будет лежать
бесконечность. Ну вот размер, который у нас есть. В другом какое-то число. То есть если мы можем
дойти до вершины, у нас будет там уже какое-то число. Вот. В этом массиве D мы будем с вами
поддерживать следующее. Что расстояние до вершины S нулевое. Почему? Потому что мы из нее стартуем.
Правильно? Поэтому там размер все такой же. До всех остальных вершинок мы говорим, что если у нас
есть ребро от S, то мы сделаем это расстояние ровно нашим весам. Ага. То есть давайте, ну не знаю,
назовите мне еще числа. Мы с вами проделаем весь алгоритм до extra. Будет понятней, я думаю.
Три. Один. Пять. Десять. Кто-то очень любит нечетные числа. Дальше. Да, после этого сразу
учетные. Хорошо. Два. Одиннадцать и тринадцать. Я услышал тринадцать. Хотите 32 сделаю? Пусть будет
тринадцать. Окей. Чуть-чуть несчастье не помешает. В общем-то, а что мы с вами делаем? Мы говорим,
что у нас в S хранится вот эта вот нулевая вершина в начале. Стрелочки поставим?
Хорошо. Я ставлю максимально рандомно. Он для всех работает. Пойдет такие стрелочки? Все вроде
связано. Ну могу здесь в обратную сторону. Поинтереснее. Окей? Окей. Хорошо. Значит, смотрите.
Первоначально мой массив D, он какой? Вот в моем множестве S хранится только вот эта вершинка. Да?
Массив D, он следующий. Значит, у нас там ноль. До вершины один я дойти не могу. До вершины два.
Где у меня два-то? Вот это два. До вершины два я дойти могу и там три. Дальше до вершины три я
могу и здесь один. Потом четыре не могу, пять не могу. Логично? Что я дальше делаю? Я говорю,
ага, давайте найдем здесь минимальная чиселка. Ну нет, S не считаем. Для всех вершин без S. Один.
Такой. Хорошо. В этом случае я расширяю свое множество S и говорю, что вот оно.
Окей? И вот эти вот. Ой, ой-ой-ой, сори, не в туда посмотрел. Вот это множество S. Правильно?
Сори, не могу выделять красиво. А вот ноль и три у меня получается. Правильно? Вот это и вот это
теперь лежит в моем множестве. Могу ли я из нулевой вершины все еще куда-то попасть? То есть
что-то, что я не учел среди этих чисел? Вроде нет. Значит, давайте мы обновим массив D уже для этой
тройки. То есть тройка только может куда-то увеличить или уменьшить или что-то с этим сделать.
Правильно? Давайте смотреть. Мы с вами говорим, что у нас, чтобы дойти из этой нулевой вершины
в любую другую, нам нужно пройти через три и куда-нибудь еще. Согласны? Расстояние до
этой вершины нужно учитывать. Потому что я же хочу смотреть на расстояние от своей нулевой вершины.
Согласны? Поэтому массив D у меня будет обновляться примерно следующим образом. Здесь все будет ноль
и единица. Это уже зафиксировано. Смотрим. До второй вершины я могу добраться. А, кстати,
сейчас. До первой вершины. До первой вершины я все еще не могу добраться. Согласны? Поэтому
тут остается бесконечно. Теперь смотрим на вторую вершину. У меня было три. А если я пойду через третью
вершину, то у меня будет один плюс десять. Одиннадцать. Кажется, невыгодно. Правильно? Поэтому
мы оставляем все также тройку. До четырех. Чтобы дойти до четырех, я должен вот это расстояние один
и прибавить еще шесть. Получаю семь. Ну и до пяти у меня будет восемь. Теперь, смотрите, я вот это и вот это,
оно у меня зафиксировано. Я смотрю на все остальные вершины. Какая у меня самая минимальная? Три. Это у нас
вершина номер два. Согласны? Теперь моим множеством S становится вот эта вот штука.
То есть у меня фиксируется теперь ноль, три, один. Давайте смотреть от двойки. От двойки я могу хоть
куда-нибудь попасть. Никуда. Поэтому у меня остается бесконечность семь, восемь. Какое минимум из них? Семь.
Смотрим дальше. Семь у меня относится к четырем. У меня вот так еще добавляется. Окей. Поехали. У нас
будет ноль, три, один, семь уже зафиксировано. Теперь я смотрю просто расстояние до первой вершины
и до пятой вершины. Правильно? Правильно. Из четырех в пятую вершину попасть никак не могу,
ничего не происходит. А вот в единичку могу. И у меня будет семь плюс два. Согласны? Это расстояние
семь до четырех плюс два. Здесь будет девять. Ну и пятерка у меня остается восемь. Смотрите,
чтобы было какое-нибудь интрига, мы можем добавить еще одну ребро вот так. Какое хотите число? Нельзя. Мы
пока говорим про не отрицательное. Ну давайте, а давайте четыре. Сейчас подождите, я подумаю,
четыре. Нет, четыре не прикольно. Давайте ноль. Хорошо? Не отрицательное. Вот. Смотрите,
у меня зафиксировано ноль, три, один, семь. Восемь фиктирую. Восемь это последний элемент. Правильно?
Мы смотрим до первого элемента, чтобы обновить. Что мы смотрим? Ага. У меня здесь было девять,
а я могу пойти через нулевое ребро, и тогда у меня от восьми будет восемь опять. Получается,
я делаю ноль, восемь, три, один, семь, восемь. Вот это, вот это, вот это, вот это зафиксировано,
вот это остается. Ну как бы от него никакие ребра уже не идут, мы уже все рассмотрели. Понятно?
Как работает алгоритм Dijkstra? На что похоже? Или на что не похоже? На прям похоже? Ну по сути
у нас есть вот эти некоторые разрезы, мы берем минимальное ребро, впихиваем его и смотрим. Здесь
по сути такое же алгоритм, почти что. Просто смотрим на минимальное расстояние уже. Вот,
здесь тоже был пример, но чуть более сложный. Я думаю, я боюсь его вам долго расписывать. Вот.
Корректность. Тот, кто сомневался, что Dijkstra работает. Давайте докажем корректность. Если мы
говорим, что ребра у нас, у графа не отрицательны, то по завершению работы алгоритма у нас будет все
корректно. То есть расстояние, то, которое мы найдем, будет минимальным расстоянием. Как это
все доказывается? Мы будем доказывать индукции по числу итераций. Смотрите, ну база индукции,
нулевое, нулевая вершина, нулевое расстояние, оно минимально. Согласны? У меня нет отрицательных,
отрицательных ребер, отрицательных циклов, значит, не может быть, значит, все хорошо. Окей? Вот.
Теперь давайте про переход. Смотрите. Мы говорим, что для любой вершины V из S,
то есть вот, вот, которая у меня уже находится в моем множестве S, оно вертно. То есть вот это
наше предположение индукции. Окей? Окей. А рассмотрим кратчайший путь из S до U. Что такое U? Что такое S?
Ну, смотрите, ну как бы, S это что-то из множества, которое у нас уже верное,
U это другой разрез. Какой-нибудь S, S это то самое начальное число, а вот U тут какая-то вершинка.
Окей? Этот кратчайший путь должен пересекать данный разрез, правда? По какому-то ребру. Ну,
вот здесь еще может продолжаться путь, но когда-нибудь он придет. Вот. У нас есть то есть
некоторая вершина X и некоторая вершина Y. Вот он, этот путь. Тогда, ой, ой, ой, ой. Тогда мы
точно с вами знаем, что вот если мы рассмотрим весь этот наш путь, который у нас есть, до вершины,
например, Y по этому кратчайшему пути, согласны, что другого кратчайшего пути в принципе не
должно быть? То есть, если у меня кратчайший путь проходит через Y, то этот кратчайший путь будет
до Y тоже? Или нет? Или да? Да. Вот. А чему у меня равен, равно вот этот вот кратчайший путь до
нашей вершины Y? От S до Y. Ну, он складывается из rho SX плюс вес нашего ребра XY. Согласны? Правда?
Правда. Теперь, смотрите, по нашему предположению индукции в S все корректно. Поэтому rho SX это то
же самое, что dx. Согласны? Согласны. Вот. И получается, у нас к этому dx добавляется вес нашего
ребра XY. Отлично. У нас все это получилось. Теперь вопрос, что мы можем здесь еще дополнительно
к этому всему сказать? Что мы должны как-то вычислить вот этот dy и сказать, что он равен тому,
что нам необходимо. dy как вычисляется? dy вычисляется из старого какого-то значения,
либо из dx плюс xy. Вес этого xy. Хорошо. Все нормально здесь, с одной стороны. Но,
когда мы на это все смотрим, то в действительности мы получаем, что у нас будет равенство уже,
что dy у меня будет равен dx плюс вес xy. Почему? Потому что у нас это расстояние d,
оно явно всегда больше либо равно, чем минимальное расстояние. Согласны? Вот. Из-за этого dy не
может быть меньше, чем dx плюс вес xy. С точки зрения реализации. Реализация бывает с
поиском минимума пирамиды, с помощью минимума наивного, с помощью минимума фибоначевой пирамиды.
Все ровно то же самое, что было у вас где? В Риме. Аналогично ровно тому, что происходило. То есть,
вы можете делать за e локве, за e плюс v локве и так далее. Оно происходит аналогично. Если
просто искать минимум, то это e плюс v квадрат. Когда что лучше делать в dx, то здесь уже думать
вам самостоятельно. Здесь ровно то, что мы с вами когда-то говорили еще в Риме, что в разреженных
графах можно и нужно использовать бинарные пирамиды, в плотных графах использовать массивы сами
по себе. Окей? Принято. Вот. Теперь представьте следующее. У нас существует отрицательный
ребр. Отрицательный ребр — это беда. Почему не будет работать dx? Да, вся проблема будет в
отрицательных циклах. Если у вас есть некоторый цикл и даже не то что цикл, у вас может быть путь
просто отрицательный. Например, вот такое. У вас сюда расстояние там 7, сюда расстояние 10, а вот
здесь будет расстояние там минус 100. Нет, вот так. Цикла не будет. То есть до этой вершины минус 90,
вообще кратчайшее расстояние. Алгоритм же dx сам по себе работает на основе же одного алгоритма. То
есть он берет минимальное ребро и забирает его себе, забирает эту вершину. Именно из-за этого это так
работает. Поэтому с отрицательными ребрами здесь нужно всегда быть аккуратным. Если мы с вами
говорим, что есть отрицательные ребра, то дэкстра начинает не работать.
Мы уже зафиксируем же, да. У меня будет 0, 7, 10. 7 фиксирую. Говорю, что сюда расстояние 7.
И больше я не обновляю это. Вот. В этом всем проблема. И если бы мы с вами в действительности искали
даже простые кратчайшие пути, то это была бы проблема с НП полными задачами. Ой, с НП полной задачи,
то есть мы не решали бы быстро хоть за какое-то нормальное время. Решали бы за какой-то дикий
поляном. Это не круто, это не прикольно. И в этом вся проблема. В действительности задача поиска
кратчайшего пути хоть как-то корректна, если в графе нет отрицательных циклов. Логично,
логично. Если мы попытаемся с вами добавить отрицательный цикл, у нас совсем все ломается.
Там минус бесконечность есть везде. Мы сколько хотим, можем пройтись по этому всему. Поэтому
здесь у нас есть некоторые вещи, которые мы должны с вами понимать, что эти отрицательные циклы мы
должны фиксировать. Если они вдруг есть, мы говорим, что ничего не работает. Потому что у нас просто
отрицательные веса эти есть. Алгоритм Dijkstra не подходит, мы с вами обсудили почему. Вот. Если
вдруг вас просят на экзамене, вы говорите, ну алгоритм жадный, не учитывает чуть-чуть побольше
пути. Все, а это конец. И с алгоритмом Dijkstra, к сожалению, нужно придумывать, что делать. Что?
Нет. А какой потенциал вершины? Придумаешь, скажешь. Да, мы такую задачу рассмотрим. Если
потенциалы прибавлять, то да. Ну если ввести потенциал вообще, в принципе. Вот. Но прибавить
ко всем какое-то число не получится. У тебя путь может состоять из пяти вершин или из одной.
Из пяти ребер или из одного. Из-за этого у тебя будет разница. Вот этих плюсов. Вот. Ну в общем
случае пока что мы с вами говорим про алгоритм Форда Белмана. Что это такое вообще за чудо?
Смотрите. Пусть у нас будут найдены какие-то пути из S в. У нас есть Dist V и есть Dist U. И мы
будем с вами брать и делать релаксацию ребер. Что такое релаксация ребер сама по себе? Ну вот у
нас есть вершина V, есть вершина U. Я говорю, что у меня из V в U есть ребро. Давайте с вами проверим,
что расстояние в U будет не больше, чем Dist от V, плюс вот это ребро, которое мы делаем. То есть
смотрите. У нас есть некоторые вершины V, некоторые вершины U и вот какое-то ребро. Ну не знаю там,
с весом Омега. Релаксация. Я говорю, что сюда расстояние D от U, сюда расстояние D от V. Я говорю,
что, ага, проверим, если у меня D у будет больше, больше, чем D от V, плюс это Омега, тогда я сделаю
релаксацию ребер и скажу, что расстояние до моей U равно вот этому. Логично? Логично. То есть я говорю,
что да, бесконечность была, давайте сейчас что-нибудь с этим сделаем. И вот это называется
релаксация ребер. И алгоритм Форда Белмана говорит нам следующее. Согласны ли вы с тем,
что любой кратчайший путь, если у меня нет отрицательных циклов, например, он состоит не
более чем из V-1 ребра? Согласны? Ну как бы максимально вот развернем, получим такой путь.
Поэтому для нахождения всех путей достаточно V-1 раз отрелаксировать все ребра.
Ну смотрите, у меня есть в начале вот эта вот нулевая вершинка. Да? Я запускаю релаксацию
ребер и все вершины, до которых оно достает, с расстоянием 1, ну вот расстоянием, я имею в виду
количество ребер, оно отрелаксирует корректно. Согласны? То есть у меня станет уже вот так,
в начале было вот такое, а теперь вот так. Дальше, когда я начну еще одну релаксацию,
согласны, что вот это отрелаксирует корректно путь до всех вершин, которые находятся на расстоянии 1 от
вот этих. А? Там не было кода. А, релаксация? True или false? Была релаксация или нет? Ну что
делает этот код? Он проверяет вот это, если это действительно так, и у меня расстояния до У больше,
то так. Окей. Вот, ну то есть смотрите, мы прорелаксировали раз ребра, расстояние 1 нашли
корректно. Согласны? Прорелаксировали еще раз, уже в расстоянии 2 зашли. Ну в такую эпоху 2,
я не знаю, как лучше назвать вам. Ага. И так далее. То есть мы вот это вот все продолжаем и делаем,
и все становится чудесно. А так как у меня максимальный путь V-1, ребро, то V-1 раз я
прорелаксирую все ребра, получу свой ответ. Ага. Есть вопросы? Вот. Поэтому в действительности
алгоритма Форда Белмена выглядит вот так. Еще раз смотрите, мы не решаем проблему цикла,
мы решаем проблему отрицательных ребер. Если есть отрицательное ребро, не означает,
что будет цикл. С точки зрения отрицательных ребер представим следующую вот, опять же,
вот эту картину. У меня первая это 0, что там? Ну бесконечность, к примеру, бесконечность.
Я делаю релаксацию, я релаксирую вот от этого ребра ко всем остальным. У меня получается 0, 7,
10. Ага. Я запускаю еще одну релаксацию, потому что у меня V-1 раз должно быть, 2 раза хотя бы.
0 остается нулем. До 7 вот здесь до первого элемента, у меня здесь 7, а здесь у меня получится 10 минус
100. Поэтому будет минус 90. Ну а до двойки 10 так было, так и осталось. Вот проблема решена.
Поэтому алгоритм Форд Белман вот такой. Сложность у него V-e. То есть в плотных графах
работает ZV-куп. Не круто, но как есть. Ага. Есть тут вопросы? Нету вопроса. Чудно. Вот. Давайте
докажем корректность. Почему, если у нас в графе отсутствуют отрицательные циклы,
то по завершению алгоритма у нас будет все правильно. Ну смотрите. Рассмотрим какую-то
произвольную вершину V и кратчайший путь до нее. Вот этот кратчайший путь он состоит из вершинки
S самой начальной, а до этой вершины V. Окей? Ну как бы обозначение понятное. Он состоит из
нескольких вершинок. Покажем, что после каты итерации, но вот здесь вот сейчас. Ну да. А после
каты итерации нам нужно доказать, что вот то, что я говорил, что мы вот ходим по вот этим вот уровням
и оно становится корректно. Это будет минимальный путь. И тогда это будет все правда. Ну как бы как
это можно сделать? Ну по индукции. Для базы у нас понятно. Теперь мы смотрим на переход. Пусть у нас
на k-1 итерации все корректно. Предполагаем, предполагаем. Отлично. Значит, на каты, на каты
самой итерации у нас будет релаксироваться ребро vk-1, vk-2. Правильно? Если оно релаксируется,
то у нас вот это расстояние будет правильное, потому что оно входит в кратчайший путь все еще.
Согласны? Вот. А значит у нас все правильно. Ну вот как-то так. Ну то есть вот это вот то,
что написано, что дист от vk равно дист от vk-1 плюс омега k-1 vk. То есть оно отрелаксировалось.
Так как оно входит в кратчайший путь, то все хорошо. Мы говорим, что rho от s vk-1. Это как
раз минимальный кратчайший путь. Точнее d от s до vk-1. Плюс вот это вот, вот это наше ребро. И
мы получаем, что мы находим этот самый кратчайший путь. Все. Форт Белман очень легко доказывается.
А вот теперь смотрите. А как нам определить, что у нас есть цикл читательного веса?
С помощью алгоритма Форда Белмана. Подряд? Да. Давайте сделаем на одну релаксацию больше.
v-1 это максимальный простой путь. Его длина согласны. Давайте запустим еще раз релаксацию
всех ребер. И в случае, если эта релаксация произошла, то у нас есть цикл отрицательного веса.
Вот и все. Вот. Поэтому мы просто делаем таким вот моментом. Просто вот этот кусок, надеюсь,
что вам достаточно понятен и прост должен быть. Окей? Океюшки. Ну как бы, а то, что алгоритм
действительно найдет кратчайший путь корректно, ну а если у нас нет кратчайшего пути, ой, если у
нас нет цикла отрицательного веса, то все понятно, мы с вами доказали корректность. Только что он
вернет правильно. Вот если у нас есть отрицательный цикл какой-то, ну тогда это делается аналогично
тому, что мы делали с вами ранее. Мы строим вот этот путь, смотрим, что у нас там происходит и
смотрим, ага, что у нас расстояние будет по какой-то сумме отрицательное. Почему? Потому что мы еще
раз прорелаксировались и сделали какой-то путь больше, чем k-1, чем v-1. Тогда вам задачка
наподумать, а что нам сделать с отрицательными ребрами так, чтобы мы могли запустить дейкстру.
Задача сразу скажу не тривиальная. Тогда, в принципе, все. Хорошего вам вечера. Пока-пока.
