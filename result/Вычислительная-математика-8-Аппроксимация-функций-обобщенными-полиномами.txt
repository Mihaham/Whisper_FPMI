Так, значит, сегодняшняя лекция посвящена той же теме «опроксимация функций в функциональных».
Сегодня мы будем говорить о интерполяции функций, обобщенной париномом.
Эта тема несколько отличается от той темы, о которой мы говорили в прошлой лекции.
Так, давайте сначала сделаем постановку задачи для функций одной переменной,
чтобы было понятно, о чем идет речь. Пусть у нас будет тетка ωm,
как мы ее обычно назначаем tn, то есть ntau, nм меняется от 0 до nбольшого,
ttau – шаг в сетке. Давайте возьмем для простоты равномерный шаг, но это не обязательно.
Шаг может быть и неравномерным. Далее t0 равняется a, и tn равняется b. Вот такая сетка.
Шаг может быть и неравномерным. Далее у нас есть функция fat, определенная на отрезке ab.
Пока для простоты она будет одномерной, то есть и функция одной переменной.
Мы эту функцию проецируем на нашу сетку и получаем таблицу.
Делаем это с помощью оператора, который называется оператор ограничения или restriction,
английское название. Я здесь короткое замечание сделаю, что сетка в одномерном случае строится
всегда просто. Вообще говоря, например, в трехмерном случае построение сетки является очень непростой
задачей, особенно в таких областях. В кубе это построить прямоугольники просто, а в общем-то
есть области, в которые строить ее очень непросто, по таким методам построения сеток,
даже международные конференции проводятся. Давайте коротко будем обозначать таблицу tn, f, fn.
Мы получили таблицу fn, tn, tt, ft. Вот такую таблицу мы получили.
И вот теперь, имея таблицу fn, мы строим, получили таблицы метовую функцию f от t,
которая называется интерполирующей функцией или коротко интерполянтом.
Интерполянт. Пока я не говорю о функциях, о свойствах этих функций, чуть позже я об этом скажу.
И так у нас получается такая схема. Есть функция f от t, мы с помощью оператора
получаем таблицу fn и по ней строим некую функцию, которую называем интерполянтом
с помощью оператора интерполяции. Иногда используют такие слова, как восстановление функции
или восполнение функции. Восполнение функции соответствует действительно ситуации. Восстановление
это не совсем так. Поскольку мы ее не восстанавливаем, мы ее именно восполняем.
Ну, либо проксимируем, либо проксимируем. И, разумеется, эти функции должны совпадать в узлах.
f от t ката должно быть равно f ката от 0 до n. Но между узлами они вообще-то совпадать не обязаны.
Вот в чем проблема. Поэтому встает вопрос следующий. Как отличаются эти две функции на нашем отрезке АВ?
Действительно, можно представить себе, что есть несколько точек заданных. Функция f от t какая-то такая.
Мы ее спроецировали на наши узлы. Я их поставил. А функция f от t может быть какой-нибудь вот такой,
например. То есть функции не обязаны между узлами совпадать. А вот отличия мы их должны уметь
оценивать. Отличия интерполянта и интерполируемой функции. Чтобы знать, что происходит. Чуть позже вы узнаете,
я вам расскажу, что это очень важно. Оценивать вот эту... Ну, вообще говоря, я здесь поставил модуль,
ну, вообще говоря, здесь лучше поставить норм. В более общем случае лучше поставить норм. Разность.
Так. Ну и теперь, как я обычно это делаю, давайте я приведу какой-нибудь очень простой пример.
Самый простой, чтобы было все понятно. Начнем с простых примеров. Потом будем усложнять ситуацию,
и вы увидите, что задача интерполяции на самом деле очень-очень непростая. Это не проведение. Пора было
через три точки. Это гораздо все сложнее. И задача, конечно, имеет огромное количество приложений.
Во всех областях. И физики, механики, инженерии, экономики и так далее. Давайте построим функцию
на отрезке Tn, Tn плюс один с задными значениями в этих двух узлах. Tfn и fn plus 1. Это значение функции
в этих двух узлах. То есть самая простая задача, которую я мог придумать. Вот интерполянт f от t.
Так мы обозначаем в выгоде следующим образом. Ну, вы без труда и без меня, конечно, можете написать.
Ну, давайте я напишу один раз этот интерполянт. Так, здесь у нас fn, tn плюс 1 минус t. И делим на tn плюс 1 минус t.
Эта разница обычно обозначается как tau n, значит шаг в сетке. То есть это линейный интерполянт.
Мы приблизили нашу функцию. Вот такой линейный простенькой функции. А вот теперь давайте ответим
вот для этого простейшего случая. Ради этого я это и пишу. Оценим разность между интерполянтом
и интерполированной функцией. Там в простом случае. Потом, конечно, мы будем переходить к более сложным,
более сложным случаям. Ну, пока давайте вот простейший случай оценим. Для этого докажем
такую небольшую тему. Пусть функция f от x липшится непрерывно. То есть f от x минус f от y меньше или равно
t на x минус y. Ну, помогли все, конечно. То есть пока только вот одно условие. Липшица непрерывности.
Больше мы пока о гладкости этой функции не говорим. Потом, разумеется, будем говорить. Но чуть позже.
Так, в этом случае. В этом случае модуль разности интерполянта и интерполированных функций.
Вот это вот линейный. Меньше или равно t на tau пополам. То есть вот такая оценка
разности. Норма разности или модуля разности между интерполянтом и интерполированной функцией.
Если у нас имеет место быть линейная интерполяция по двум точкам, то здесь у нас интерполянт линейный.
Так, то давайте доказательства проведем. Оно несложное. Давайте его один раз делаем. Оно нам в
дальнейшем пригодится. Итак, вот модуль f от t минус f малое от t. Давайте сделаем так, для удобства.
Функцию f от t интерполянт мы представим, поскольку она линейная, в таком виде.
Альфа разумеется меняется от нуля до единицы. То есть такой весовой коэффициент.
Вот так мы ее представим, альфа плюс единица минус альфа.
И у нас функция f от t. Функцию f от t мы для удобства представим в аналогичном виде.
Альфа f от t плюс единица минус альфа тоже на f от t. Просто удобно для дальнейших выкладок.
Здесь глубокого смысла нет в таком представлении. Смысл в одном, чтобы так быстро и аккуратно сделать выкладки.
Дальнейший. Получить результат. Функцию f от t представим. Теперь я пишу функцию f малое.
Это альфа f от t и минус единица минус альфа тоже на f от t. По модулю меньше и равняется.
Теперь давайте вот меньше и равняется. Здесь у нас модуль альфа. f малое от n плюс 1 я представляю понятным образом.
Это будет fn плюс tau. Это есть tn плюс 1. Теперь единица минус альфа на fn.
Это f от tn. Дальше единица минус альфа. Вот альфа на f от t. А вот t я представлю в следующем виде.
Для меня удобно. tn плюс альфа tau. Альфа тоже от 0 до 1. f от tn плюс альфа tau.
Единица минус альфа и тоже f от t. f от t плюс альфа tau. Меньше или равно.
Здесь я объединил слагаемые с альфа и соединился минус альфа.
Для альфа у меня будет следующая альфа.
Теперь давайте вот так сделаем в последующем. f от tn плюс tau минус f от tn плюс альфа tau.
Это слагаемые с альфа и здесь единица минус tau слагаемая так.
Здесь не перепутать. Здесь у нас будет f от tn минус f от tn плюс альфа tau.
Меньше или равно. А теперь мы используем липчатую непрерывность функции f малая.
Здесь будет альфа, коэффициент липчатся. Разница аргументов это будет у нас tau на единицы минус альфа.
Следующая слагаемая тоже мы используем условия липчатся. Единица минус альфа на коэффициент липчатся и на альфа tau.
В конечном итоге мы получили 2 c tau на альфа на единицы минус альфа.
Это будет перевернутая парабола. Вы найдете максимум. Это будет c tau пополам.
Если мы простейшую интерполяцию делаем линейную, то мы имеем интерполяцию первого порядка.
У большой от tau, то есть tau в первой степени, интерполяция первого порядка.
Это самый простейший случай. Я говорю простейший случай, но на самом деле вот этот простейший случай линейной интерполяции очень активно используется в одном из самых известных честных методов, которые сейчас работают.
Причем и для обыкновенных дифференциальных уровней, и для частных производных, и т.д. метод конечных объемов.
В этом методе интерполян представляется вот в таком виде, fn на fn от t, сумма по n от 0 до n, fn это значение функции, а fn это так называемые функции крышки.
Они имеют вот такой вид. Это линейные функции крышки. Вот такой вид имеют, типа модула lix, плюс что-то.
И вот такое представление решения оказывается очень-очень успешным.
Этой идеей предложил этого метода более 100 лет назад русский математик Галеркин.
Вот Рябинький Виктор Самовыч, профессор, который на футболке читал лекции почти 20 лет, не использовал фразу метод конечных элементов, он говорил метод Галеркина.
Что верно, но на самом деле здесь его немного американцы видоизменили, чуть-чуть, и назвали методом конечных элементов.
Получился прекрасный метод. Впрочем, Галеркин взял свое, сейчас один из самых полярных честных методов, как называемый разрывный метод Галеркина, который также основывается на аналогичных представлениях.
Теперь мы перейдем к интерполяции более высоких порядков.
То есть вот с линейной интерполяцией в общем особых проблем у нас никаких нет, но еще линейная интерполяция используется как кусочная линейная интерполяция.
То есть когда мы просто соединяем узлы, сетки прямыми отрезками, это тоже иногда используется, такая так называемая кусочная линейная интерполяция.
Обычно в более сложных случаях используется тоже обобщенный полиног, то есть наш интерполян представляется в виде обобщенного полинога ОН на φн от t.
Ну Н малая, как всегда меняется от 0 до 2 большого, значит ОН коэффициент, который нужно каким-то образом вычислить, ну каким мы в этом будем с вами говорить.
А фен это система базисных линейно-независимых функций, это все слова здесь важны, базисные линейно-независимые функции.
Они могут быть степенные, они могут быть экспоненциальные, в ранее физике скажем используются комплексные экспоненты, региометрические функции, используются часто и успешно, но часто используются и степенные функции.
Актуальная физики там для опроксимации коэффициентов, уравнений состояния и так далее, ну и разумеется в экономике тоже степенные функции используются как правило.
Ну вот, поэтому мы имеем вот такой интерполянт, и этот интерполянт в соответствии с условиями интерполяции должен в узлах нашей сетки совпадать с развлечениями нашей функции.
Вот что мы имеем, других условий мы никаких не имеем, только равенство в узлах интерполянта и интерполирующей функции.
Ну или это можно записать следующим образом.
Ну и давайте в скалебном виде распишем, он нам будет нужен.
Ну плюс многоточие.
Это первое уравнение в нашей системе, то есть это я написал, в самом деле, систему уравнений.
Второе уравнение будет выглядеть аналогично.
Т1 плюс многоточие УН и Н, Т1 равняется f1, ну и так далее до Н-го уравнения У0, Т0, ТН, плюс, давайте коротко записываем, многоточие УН, ТН и Н.
N равняется fN.
То есть вот такая система получилась.
Ну в отличие от метода на меньше квадратах, вы видите, что матрица у этой системы квадратная.
То есть нам не нужно, хочется использовать какие-то другие методы, нам достаточно этой системы.
Ну а теперь давайте посмотрим на матрицу вектора.
Ну вектор U и f, f вектор правых частей, вектор U это вектор наших коэффициентов, нашего общенного повинного.
Ну, разумеется, они принадлежат n-мерному линейному векторному пространству.
Вот, матрица A имеет размерность N на N и имеет вот такой вид.
Давайте ее вид напишем, он важен.
Так это у нас что?
phi0 на T0, phi1 на T0, многоточие phiN на T0.
Ну дальше там phi0 на T1, я уже все переписывать не буду, сокращенно буду писать.
Так здесь phiN тоже на T1.
Ну и последняя строка матрицы phi0 на Tn, многоточие phiN на Tn.
Ну вот такая матрица.
Ну в линейной алгебре, вы наверное помните, доказывается теорема.
Осуществование единственности, решение такой системы линейных уравнений.
Помните, что для этого требуется?
Чтобы такая система уравнений, которую мы получили,
а у равняется f, имела единственное решение.
Почти.
Ну чтобы система функций f-катах была линейно-независима.
Все что требуется.
Система Байснер-Кутца должна быть линейно-независима.
То есть линейная независимость системы функций.
При этом мы получаем единственное решение данной системы.
То есть здесь все хорошо.
Фактически мы сейчас доказали теорему о существовании единственности,
решение задачи интерполяции.
Вот.
Часто так и облекаю.
То, что я сейчас вам показал в виде теоремы.
Теорема существования единственности.
Вот.
Но давайте еще вот сделаем небольшое замечание.
С помощью опять же той же симметризации по гауссу,
эту задачу можно упростить.
Правда, не всегда это удается.
Но иногда удается.
Я, помните, вам рассказывал о системе ортогональных функций.
Здесь ее тоже, оказывается, можно использовать, если, конечно, это возможно.
Просто в реальных задачах не всегда возможно их использовать.
Но есть задачи, в которых их вполне можно использовать.
Вот.
Давайте проведем симметризацию нашей системы уравнений по гауссу.
У вас озвездует сопряженная матрица.
Ну, в честном случае это просто транспанированная матрица.
Транспанированная матрица.
Ну вот.
С одной стороны, мы, конечно, задачу усложнили.
Но если я обозначу на дм произведения вот этих двух матриц,
то что у меня получится?
Элементой матриц будут являться кадровные произведения
фи и на фи ж и и и ж от 0 до n.
Ну, чтобы знакомое.
Но на всякий случай напомню, что под кадровые произведения
фи и на фи ж вы понимали тумму фи и т от t.
Пятое на фи ж и т от t.
Пятое.
Вот так это.
Тумму фука.
То есть эта матрица состоит из кадровных произведений.
Это матрица грамма.
То есть мы опять пришли к нашей любимой матрице грамма.
Она, конечно, очень хороша тем, что она положительно
определенная, симметричная и так далее.
Но есть некоторые детали.
Дело в том, что если матрица плохо обусловлена,
то произведение двух плохо обусловленных матриц
даст еще более плохо обусловленную матрицу.
Это вот такой подводный камешек имеется в этом деле.
Но что здесь хорошо или ради чего я все-таки
симметризацию по гауссу привел?
А хорошо вот что.
Если мы выбираем систему ортогональных функций,
ортогональные функции, в этом случае будет
кадровное произведение.
Это есть тело кронекера.
Если нам удастся использовать
ортогональные функции, например,
ортогональные пальновые.
Лаграджа, Лежандра, Рамиточи, Вышова.
То мы получим единичную матрицу.
То есть решать ничего не нужно.
Решение будет выписано.
Уровняется асо звездой.
Иногда это удается сделать.
Но в радиофизике это используется очень часто,
поскольку в качестве байсных функций
радиофизики используют комплекс экспонента
либо тригонометрические функции.
И там это удается.
Удается это сделать тогда,
когда можно использовать ортогональные полиномы,
типа Лаграджа, Лежандра.
К сожалению, это не всегда удается делать,
но когда удается, то же мы получаем
довольно простое решение.
Но что делать, когда нам
нужно решать систему и вычислять?
Нам нужно решать систему линейных
логибрических уравнений.
Ну хорошо, если система невысокого порядка,
два, три, четыре и так далее,
вы ее просто решаете на руках, на коленке, как говорят.
Плохо, если она имеет высокий порядок.
Высокий порядок тогда.
Ну, во-первых, нужно ее решать численно,
но численно решать тоже, так сказать,
в среднем порядке, ничего страшного.
Нет метод гаусс, это рассудный метод.
Мы с вами говорили.
Но какие здесь могут быть, опять же,
проблемы?
Проблема есть одна.
Давайте положим, что
система базисных функций у нас
это степенные функции.
Это степенные функции.
И там будет все хорошо понятно.
То есть
phi n
это есть x в степени n.
Что мы при этом получим?
Какую систему уравнений мы получим?
Которую я выписал.
Мы получим следующую систему уравнений.
u0
u1 на t0
u2 t0
SN square
н
plus многоточие
здесь уn
t0 в степени n
равняется f0
второе уравнение ux1
first t1
plus u2
first t1
IB
u1
first c1
t1
У1tn плюс, давайте многоточки поставлю, Уntn в степени n равняется fn.
Вот такая система уравнений у нас получилась, но обратите внимание на матрису.
У нас опять же получилась система уравнения а уравняется f, у f это вектора н-мерного пространства,
а у матрицы n на n, и вовлекто на следующем образом.
1t0t0 в квадрате многоточия, t0 в степени n, 1t1t1 в квадрате, t1 в степени n, 1tntn в квадрате, tn в степени n.
Вот такая у нас матрица нашей линейной системы по гибридическому уравнению.
Посмотрите на нее внимательно, что незнакомое есть в ней.
Встречали такую матрицу? Громче? Конечно, да.
Как вычисляется определить вандормонты этой матрицы вы прекрасно знаете.
Детиминант этой матрицы это, если что иное, как произведение t и t-t, gt и g, от 0 до n по i неравного g.
То есть опять же матрица получилась хорошей.
Она не выражена, и поэтому мы опять всегда можем утверждать, что у нас есть решение и решение единственное.
Это фактически тоже некое следствие теории, которую мы только что доказали.
А теперь посмотрите повнимательнее чуть-чуть, какие могут встретиться проблемы в решении этой системы уравнений,
если n у нас не 2, а 3, а какой-нибудь большой.
Например, 20, 30 и так далее.
Подсказка. Пусть, давайте мы отмасштабируем нашу матрицу, пусть t лежит от 0 до 1.
Посмотрите, пожалуйста, на последний столбец. Чему он будет равен?
Если n у нас будет большой, он будет близок к 0, то есть матрица будет близка к вырождению,
либо просто выродится с машиной точностью.
Вот что проблема. То есть мы опять встречаемся с плохо обусловленной системой единых уравнений.
То есть вот от природы не уйдешь.
То есть мы хотим решить задачу опроксимации, мы ее решаем частично.
Для невысоких степеней интерпозиционного полинома она решается прекрасно.
Но если говорить о таком усредненном опыте, то где-то обычно степенные полиномы до пятой,
но может быть максимум семой степени используются.
Дальше там начинаются проблемы. Сейчас мы об этих проблемах будем говорить.
А может быть и при меньшей степенях проблемы могут начаться.
Именно по этой причине. Из-за плохой обусловленности матрицы.
Ну, разумеется, вы помните имя Гильберта, который привел пример самой плохой обусловленной матрице.
Ну, наверное, можно еще более плохую матрицу провести.
Еще более плохо обусловленную, но так, чтобы это имело смысл.
Гильберта привел матрицу, которая имеет смысл.
Но над этой проблемой начали думать два великих ума.
Лагранш и Ньютон. На самом деле гораздо больше математиков думали над эту тему.
Но первыми, видимо, начали над этой темой думать Лагранш и Эльдер.
И вот что они предложили. Действительно, задачу эту ситуацию существенно упростили.
Но когда математики начали исследовать их решение, оказалось, что природу все-таки не обманет.
Но решение задачи резко упростилось. Сейчас мы об этом поговорим.
Очень красиво решение предложили Лагранш и Ньютон. После них тоже были предложения.
Самое красивое, забегай вперед, скажу, что самый красивый интерполиционный полином.
Но красивый не в смысле красоты какой-то внешне, а в смысле эффективности работы.
Предложил наш математик Пафнут Львович Чебышов.
Об этом историческом полиноме, разумеется, я расскажу.
Математики французские XIX века называли полином изюминкой математического анализа.
Он действительно поразительный по своим свойствам.
Причем Чебышов получил его, решая совсем другую задачу.
Ну вот так бывает. Теория групп тоже возникла при решении других задач.
Ну как кто-то сказал, из математиков искали нефть, нашли газ.
Ну вот, давайте теперь поговорим о том решении, которое предложил Лагранш.
Потом о предложении Ньютона.
Лагранш предложил искать обобщенный полином.
Этот полином по имени Лагранша традиционно так и пишут.
В виде разложения по базительным функциям Лагранш.
Чтобы обойти решение системы линейных уравнений.
То есть выписать сразу решение.
И он его выписал. Вот что получилось.
Сумма fn на phi н большой.
Сумма по н от 0 до n.
Причем f малое – это значение нашей функции в узлах.
А phi н – это некие базисные функции.
То есть у нас что должно получиться?
Во всех узлах fк так должно быть равно fк.
К от 0 до n меняется.
То есть значение полинома в некой точке k должно быть равно значению функции в этой точке.
Причем в этом случае базисная функция должна быть четко равна 1.
А в других точках базисная функция должна быть равна 0.
То есть если это написать просто, то получается, что наша функция fn от k это просто должно быть символ кронейкера.
Ну можете несколько секунд подумать, придумать такую функцию.
Легко ее придумать или нет?
Потом они получили название базисной функции Лагранш.
Полинома Лагранша – это за ними забито название интерполюционных полиновок, а это базисные функции.
Ну, я вам подскажу.
В качестве базисной функции Лагранш предложил полиному вот такого вида.
t-tk-t, tn-tk-t.
t от 0 до n.
Звонка не было?
Здесь плохо за ног слышно.
Так, вот базисные функции Лагранш. Они удовлетворяют тем требованиям, о которых я только что говорил.
В этом случае значения интерполянта в наших узлах точно совпадают с значениями функции в этих же узлах.
То есть задача в общем-то с первого взгляда решена.
Она действительно вроде бы решена.
Ну, как всегда, в учительной математике имеются всегда какие-то подводы декаде.
Решение красивое, простое и так далее.
Ну, можно написать полиновый Лагранш в полной виде fn на произведение t-tk-tn-tk-t.
Произведение по k, сумма по n.
Ну, давайте я тоже приведу какой-нибудь простой пример.
Например, полиновый Лагранш первого порядка.
Линейный полиновый Лагранш.
l1 от t.
Что это будет? Это будет следующее.
f1 t2-t t2-t.
t1, простите, t2, плюс f.
Это подвод точек, я имею в виду.
У нас здесь две точки t1 t2.
И значения функции в этих точках f1 и f2.
Вот я выписываю полиновый Лагранш.
f2 здесь t1-t, t2-t-t1.
Полиновый Лагранш в таком виде первого порядка.
Ну, к недостаткам вот этой записи полинового формы Лагранш обычно относят то,
что если мы захотим перенумеровать точки, то нам придется перестраивать весь полиновый раз.
И во-вторых, если мы, скажем, из полинового первого порядка захотим получить полинового второго порядка,
нам тоже придется перестраивать весь полиновый.
Интересно то, что вот этого недостатка лишен полинового, который выписывал Ньютон.
Он называется интерпольсионный полином в форме Ньютона.
Прежде чем только выписывать, нам придется ввести одно важное понятие, которое нам пригодится в течение всего курса.
Ввести понятие разделенных разностей.
Разделенных разностей.
Оно было введено Эллером в XVII веке, но вот мне китаеведы подарили книгу китайских математиков.
Оказалось, что китайские математики его ввели еще в XIV века.
Как и формулу Еруна.
Вот давайте, что это такое.
Разделенная радость нулевого порядка в точке Tn.
Вот это есть просто значение функции в точке Tn.
Разделенная радность первого порядка Ftn Tn и Tn плюс один.
Она вот так обозначается.
Это есть вот что.
Значит, в числителе Ftn плюс один минус Ftn делим на Tn плюс один минус Tn.
Разделенная радость первого порядка.
Чуть позже я объясню, зачем их вводим.
Разделенная радость давайте второго порядка ввешем.
Ftn Tn плюс один Tn плюс два.
Это будет разность первых разделенных разностей.
Ftn плюс один Tn плюс два.
Это первая разделенная разность и минус тоже первая разделенная разность.
Раздельная разность Ftn Tn плюс один.
Это, опять же, числитель.
Ознаменитый стоит разность Tn плюс два минус Tn.
Ну, если повнимательнее посмотрите, можете догадаться, чему я веду.
Что они будут означать.
Ну и так далее.
Дальше я могу ввести разделенную разность третьего, четвертого порядка и так далее.
Ну, давайте напишем разделенную разность в каком порядке.
Ftn Tn плюс один многоточие Tn плюс к.
Это будет разность от двух разностей.
Ftn плюс один многоточие Tn плюс к.
Минус Ftn многоточие Tn плюс к и минус единица.
Это числитель.
Ну и знаменатель разности Tn плюс к минус Tn.
Это разделенная разность N порядка.
Ну, для того, чтобы их вычислять, была придумана вот такая простая табличка.
F0, F1, F2.
Это вот разделенная разность N порядка.
Ну, можно и дальше продолжить.
F3, F4.
Я просто, чтобы не терять время, только 3 обозначил.
По этим двум разностям мы находим разность первого порядка.
Две разности первого порядка.
Ft0 T1 и Ft1 T2.
И по разделенным разностям первого порядка мы находим разделенную разность второго порядка.
Ft0 T1 T2.
Это чисто такая удобная табличка.
Вы в нее ставите числа и вот рекуррентным образом находите разделенную разность в виде чисел.
Это чисто, можно программку сделать и так далее.
Ну и я здесь 3 обозначил числа.
Можно обозначить их много и найти разделенную разность N порядка.
В общем-то есть формула общая для них.
Но я ее не пишу, поскольку она тяжелая и она не очень нужна.
Поскольку они рассчитываются с помощью этой таблички проще.
Так, и теперь главный вопрос.
Зачем я вам все это рассказываю?
Про разделенные разности.
Рассказываю я вот зачем.
Пока не догадались еще, на что похожи эти разделенные разности.
На практимацию чего?
Я скажу так.
Не догадались, да?
Смотрите, если я умножу разделенную разность катого порядка на K факториал.
Ну здесь у нас будет Tn.
Tn плюс K.
Это разделенная разность катого порядка.
Катого порядка я могу ей приблизить к производную катого порядка на отрезке.
На отрезке Tn.
Tn плюс K.
То есть это будет ничто иное, как апоксимация производной на этом отрезке.
Правда, доказывается еще более удивительная теория.
Оказывается, есть точка на этом отрезке Xi такова, что приближенная равенство можно заменить на точное равенство.
Существует на отрезке Tn. Tn плюс K точка Xi, когда вот это выполняется точное равенство.
K факториал на разделенную разность равняется катой производной.
Громче-громче спрашивайте.
Почему K факториал появился?
Скажу так, это доказывается, разумеется, теорема.
Теорема, которую я не хочу доказывать, потому что у нас очень много времени уйдет на доказательство.
Кстати говоря, можете сами эту теорему доказать в качестве алгебраической задачи.
Существует такая точка на отрезке Tn. Tn плюс K, Xi, что K факториал на разделенную разность это есть лишь что-нибудь как производная точка Xi.
Можете доказать эту теорему совсостоятельно.
Это типичная теорема математического анализа.
То есть мы с помощью разделенных разностей аппроксимируем производные.
Вот их главное предназначение.
Еще я приведу пример так называемых конечных разностей.
Они тоже нам очень будут нужны.
Разделенные разности это объекты, которые я показал.
Есть еще такие объекты как конечные разности.
Они также используются для аппроксимации производных.
Давайте я тоже их покажу.
Конечная разность первого порядка.
Это есть разность fn плюс 1 минус fn.
Ее еще называют правой разностью, она может быть и левой.
Какую разность называют левой разницей.
Их называют конечной разностью.
Это конечная разность первого порядка.
Конечная разность второго порядка.
дельта 2 fn, это есть разность двух конечных разностей первого порядка
дельта fn плюс 1 минус дельта fn ну и если мы сюда поставим значение этих
конечных разностей первого порядка мы получим fn плюс 2 минус 2 fn плюс 1 и плюс
fn и плюс fn конечная разность третьего порядка это разность двух конечных
разностей второго порядка дельта 2 fn плюс 1 минус дельта 2 fn ну это равняется fn
плюс 3 минус 3 то сюда если мы все это все поставим эти значение конечных
разностей второго порядка то я просто окончательный ответ пишу в этом можете
сделать и без меня разумеется плюс 3 fn плюс 1 и минус fn и минус fn это конечная
разность третьего порядка но нам еще потребуется через какое-то время конечные
разности четвертого порядка не на этом ограничить это будет разность опять двух
разностей уже третьего порядка дельта 3 fn плюс 1 и дельта 3 fn если их поставить и раскрыть то
получится следующее fn плюс 4 минус 4 fn плюс 3 плюс 6 fn плюс 2 минус fn плюс 1 и плюс fn ну кстати
говоря на коэффициенты можете посмотреть я могу разность 5 шестого написать но не буду
это уже делать если нужно будет сделать уже сами коэффициенты ни о чем не говорят этих этих
разложений конечных разностей ни на что ничего не напоминают конечно конечно бином ньютона это
биномиальные коэффициенты поэтому конечные разности тоже выписывают через биномиальные
коэффициенты в общей виде но тоже формула там достаточно сложная и то сказать не очень нужна
не очень нужна чуть позже объясню что существует тоже схема эйкина эйкина типа вот той схемы для
разделенных разности которые позволяет строить такие удобные таблицы вычислить ну вот теперь
значит зачем я рассказал про конечную разность вот зачем оказывается если я возьму конечную
разность картового порядка и разделю ее на степени к тав это тн плюс 1 минус тн будем
считать что шаг у нас здесь постоянно для простоты в случае разделенных разностей я его не полагал
постоянно здесь я положил его постоянно то есть тау везде одинаково оказывается это есть
приближает карту производную на том же отрезке тн тн плюс к и опять же существует точка ксих
где приближенное раненство можно заменить на точное раненство как и в случае разделенных разностей
поэтому и конечная разность и разделенные разности используется в первую очередь для
для опроксимации производных это тоже про опроксимацию функции функциональных пространств только с
помощью интерполянтов интерполянтов которые вот предложили наши математики так теперь вот я
могу переходить к полиному в форме который предложил дюйма полином в форме дюйма
тогда решили были очень популярные задачи небесной механики когда работали лагран шедер лакласс
небесная механика была была такой перекладной важнейшей областью которые очень любили
математики потом появилась гидродинамика механика сплошных сред уравнений частно производных и
появилась еще одна прикладная важнейшая область для вычислительной математики но тогда
компьютеров не было приходилось больше думать так теперь поле нов в форме ньютона вот как он
записывается в общей виде но опять же всего уважение к великому дюйму по ином за поляном
ньютона вот забит вот такой название и большой поэтому я пишу малая гнезду по ином ньютона
давайте чтобы меньше писать и проще я нумерацию веду в соединечке разделенная разность нулевого
порядка точке ты один это просто значение функции интерполируем точка п 1 плюс разделенная разность
первого порядка 1 минус плюс разделенная разность второго порядка f от 1 t 2 t 3 на t минус
t 1 и минус t и минус 2 ну и плюс многоточие как вы догадываетесь здесь многоточие будет
следовать разделенная разность но порядка т 1 и на т и минус t 1 ну поляном будет здесь и минус
вот это будет по ином форме ньютона но посмотреть на него внимательно вспомните что разделенная
разность это что есть это есть опроксимация производная делить на ка факториал да то здесь
можно поставить приближено значение производной делить на ка факториал ничего не напоминает вот
этот частично сумма никакого ряда не напоминает хорошо известный да более вам известный и лора
да это действительно вот интерполюционный поле но мьютон очень похож на ряд тейлора но интересно
что вот были попытки вот как раз назвать интерполюционный поле но мьютона дискретно
опроксимация ряда тейлора но как-то не прижилось не прижились не прижились хотя он очень похож
действительно на ряда тейлора точнее на частичную сумму ряда тейлора что в нем удобств какие в нем
удобства вот вы видите но смотрите например если я напишу по ином мьютона первого порядка это что
будет valor с разделенной разность первого порядка но давайте ты два минуты один минус
до это будет по ином ньютона первого порядка то есть прямой вот теперь я захочу написать по ином
ньютона второго порядка это что будет это будет по ином не утон vídeos как потому
плюс разделенная разность второго порядка, t3-t1, а здесь будет f3-f2, t3-t2-f2-f1 на t2-t1.
То есть вы видите, что мне не приходится перестраивать полиновый, если я буду переходить к полиновому более высокого порядка.
Я просто добавляю еще одно слагаемое.
Конкретно это разделенная разность, умноженная на полином t-t1, и так далее. Я его вам выписал.
Это вот удобство. Полином идет, но и второе удобство связано с разделенными разностями.
То есть я вам сказал, что если я перенумирую точки, то значение разделенной разности от этого не поменяется.
Это тоже определенное удобство.
Поэтому в практике полином Ньютона чаще используется, чем полином Лагранжа.
Точнее говорить, форма полинома.
Это два абсолютно одинаковых полинома.
И полином Лагранжа, и полином Ньютона.
Но записаны в разных формах.
Потом появились еще и формы записи интерпозиционных полиновов.
Но основные вот эти. Я пока буду говорить об этих.
Хотя у нас еще будет полином.
Ну и, казалось бы, все здорово.
Задача решена. Можно закрывать тело.
Ну не такова вычислительная математика.
Теперь вот о чем нужно поговорить.
Появился такой вот очень внимательный французский математик Лебек,
который решил проверить, исследовать такую задачу.
А что если нам значение функций интерполируют данные с некой погрешностью?
Как эта погрешность будет меняться в зависимости от изменения степени полинома?
И он представил полином Лагранжа вот в таком виде.
Полином Лагранжа – это есть сумма Fn на базисные функции Лагранжа.
Сумма Pn. Не буду писать плюс.
Вот такая сумма Dfn на Cnn.
То есть давайте обозначим так.
То есть погрешность интерполяции относительно ошибок входных данных.
Но входные данные, вы прекрасно знаете, всегда имеют погрешность.
Когда вы работаете с компьютерами, там ну как минимум машинная ошибка.
Ну вот давайте модуль этой погрешности.
Это будет что у нас? Это будет модуль суммы Dfn на Cnn.
Меньше или равно? Меньше или равно максимума модуля Dfn по нашему отрезку.
Ну давайте сюда перейдем.
На нижнюю строчку, на максимум тоже по отрезку вот этой суммы Pn.
Н большой.
Сумма Pn.
Что касается максимума погрешности, мы его можем оценить сверху.
Например, написать, что он меньше или равен дельта ноль.
Это некая константа.
А вот эту максимум функцию обозначили как Ln и назвали постоянная Лебега.
Она у нас не константа.
Она у нас в зависимости от степени полинома может меняться и, к сожалению, даже расти.
Вот это значит въедливый Лебег заметил.
Что оказывается, вот эта составляющая погрешности для расчетных сеток с постоянным шагом растет.
И не просто растет, а растет очень хорошо.
Это вот исследовали Лебега к этому приюбе.
Оказалось, ну это опять же я доказывать не буду, я поведу результат Лебега.
Что N, что постоянная Лебега для равномерной сетки растет пропорционально 2 в степени N.
То степенную рост дает.
Что это означает?
Это означает, что в узлах там мы действительно добились решением задачи интерполяции совпадения.
Интерполянта и значение интерполянта и интерполирующая функция.
Между узлами вот что творится.
Между узлами наш интерполянт начинает увеличивать свою амплитуду.
Это нам конечно же нравится не может.
И вот здесь вспомните, ну я вам говорил, что если мы решаем систему линейных уравнений, решая задачи интерполяции,
мы приходим к плохо обусловленной системе уравнений.
Лагранш пытался обойти эту правилебу, частично они ее обошли, но только частично.
Но они вот встретились с другой проблемой.
Эту проблему Лебек назвал неустойчивостью интерполяционного процесса.
То есть интерполяционный процесс для высоких степеней интерполяции оказывается неустойчивым.
Вот это для высоких степеней интерполяции.
И вот эту проблему практически решил повкнуть Львович Чебушов.
То есть он нашел такое расположение условий интерполяции, я забегаю вперед, я говорю,
что постоянно Лебега оказалась пропорционально всего лишь логарифом не степенной степени, а логарифом N.
Это для сетки, правильно вы сказали, для неравномерной сетки.
Какой сейчас, скажем, я чуть-чуть вперед забежал, поскольку результат Чебушова был действительно удивительный.
Удивил математический мир, когда он это получил.
Хотя сейчас, конечно, то, что было гениально 200 лет назад, кажется, просто ясно.
Тогда это было не совсем ясно.
Ну вот, в чем здесь дело?
Давайте сначала поговорим о погрешности интерполяции.
Или, как говорят, получим вид остаточного члена интерполяции.
Ну или погрешности интерполяции.
И потом перейдем к неравномерным сеткам, что они могут дать.
Ну вот, погрешность интерполяции или традиционное его название остатки члена интерполяции обозначается вот следующим образом.
Ну и покажем следующую теорию.
Пусть интерполированная функция FRP имеет n плюс 1 непрерывную производную на отрезке AB.
То есть принадлежит пространству n плюс 1 раз непрерывно дифференцируемой функции.
Это пространство функции еще называют Чебушовским пространством.
В этом случае остатки члена интерполяции RNOT определяется как n плюс 1 производная в некоторой точке x отрезка интерполяции.
Делим на n плюс 1 факториал.
И здесь умножаем на поле t минус t0, t минус t1, многоточие t минус tn.
Ну если t0, то здесь t минус 1 будет.
Вот так выглядит погрешность интерполяции.
Давайте эту тюрему докажем, тем более что она доказывается довольно просто.
Доказательство такое быстрое и простое предложил Раид Петрович Федеренко, который многие годы читал дексы у нас по учительной математике.
Построим следующую функцию, phi от t равняется f от x минус по линому Lagrange.
Ну интерполяционный по линому тоже от x, а здесь остаток член, который зависит от t.
И вот такая функция в числителе x минус t0, x минус t1, x минус tn, а в знаменателе по линому t минус t0, t минус t1, t минус t, t минус tn.
Вот построим такую функцию. Почему она понравилась?
Но если внимательно посмотрите, то увидите, что она имеет n плюс 2 нуля.
Какие-то нули. Это точки x, kt равняются t, kt.
Это есть погрешность интерполяции либо остаток член интерполяции.
То есть погрешность интерполяции называют остаток членом интерполяции.
Вот она погрешность. Сейчас вы увидите, что это есть погрешность.
Сейчас мы ее получим.
Это n плюс 1 нуль и x равняется t, n плюс 2 нуль.
Почему это так? Проверьте. Проверяется просто.
Между каждыми двумя нулями функции обязательно находится ноль ее производной.
То есть какую-то экстрему. Поэтому производная функция имеет n плюс 1 нуль.
Вторая производная соответственно имеет n нулей. Ну и так далее.
Если мы будем количество нулей уменьшать и продеференцируем эту функцию n плюс 1 раз, то мы получим 1 единица ноль.
То есть мы получим, что в некой точке x производной этой функции x равняется 0.
Теперь нам осталось ее продеференцировать эту функцию.
Тогда вы поймете, зачем мы эту функцию строили.
Сразу получим вид остаточного члена интерполяции.
Давайте продеференцируем эту функцию.
Н плюс 1 раз.
Ну соответственно здесь будет n плюс 1 производной это ноль.
Здесь будет n плюс 1 производной нашей функции.
n плюс 1 производной интерполяционного паренома это ноль.
А здесь будет что у нас? Rn от t.
Производное от вот такого произведения скобок.
Как по-вашему? Чего равно, если продеференцировать вот n скобок?
Точнее n плюс 1 скобка сверху.
Что это будет?
Если например выписать этот пареном в ряд.
Это производной будет n плюс 1 факториал.
Проверьте, что это так.
А внизу пареном t и минус.
t и n малое.
Производное произведение по n.
Вот что получилось.
Ну и отсюда мы легко определяем, что такое Rn.
Что такое остаточный член интерполяции?
Что такое остаточный член интерполяции?
Это есть Rn от t.
n плюс 1 производная.
В некой точке кси на отрезке интерполирования.
n плюс 1 факториал.
И на произведении t минус tкт кат 0 до n.
Вот что это такое.
Теперь посмотрите на эту погрешность интерполяции.
С одной стороны вроде бы простое выражение.
Где здесь есть какая-то неприятность?
В этой погрешности.
n плюс 1 производная.
То есть вообще говоря, если мы хотим аппроксимировать функцию пареного высокого порядка,
то эта функция должна иметь n плюс 1 непрерывную производную.
Это не всегда бывает.
Возьмите какую-нибудь функцию.
Я вам только что рисовал функцию крышка.
Типа модуль х.
Его первого производного уже нет.
Но бывают конечно функции париномернообразные.
Типа sin x и так далее.
У которых есть необходимое количество производных.
Тогда хорошо.
Но далеко не все функции имеют большое количество производных.
И причина того, что интерпольсионный процесс может оказаться неустойчивым.
И вот на это обратил внимание как раз Чебышов.
Где-то в середине XIX века.
И стал думать над задачей, как минимизировать погрешность интерполяции.
Как можно ее минимизировать?
Посмотрите.
Плюс первого производного есть, плюс первого производного.
Мы ее оцениваем по максимуму.
И соответственно по максимуму оцениваем погрешность интерполяции.
Но n плюс 1 факториал это просто констант.
То есть у нас остается только одно.
Парином.
Что мы можем сделать с парином, чтобы уменьшить его значение по модулю.
И можем ли мы что-нибудь сделать?
Казалось, с парином и с парином.
Да что с ним можно сделать?
Можно поменять расположение узлов.
Все.
Это все, что мы можем сделать.
Этим и занялся.
И занялся пафнуть Любовь Чебышов.
Он поставил следующую задачу.
В дальнейшем он поставил целый ряд важнейших задач у аппроксимации функций.
И решил.
А здесь он действительно нашел совершенно поразительный полином.
Он предложил следующую задачу.
Давайте минимизируем наш полином по системе узлов.
То есть найдем минимум от баксибуба по отрезку AB модуля P на P минус T.
Ка от 0 до n.
То есть по другому T системе узлов Tn.
Это есть аргумент.
Минимум по узлам максимума модуля полинома.
И минус T.
От 0 до n.
Вот какую задачу поставил Чебышов.
Вот чтобы решить эту задачу он как раз исследовал как от расположения узлов зависит значение полинома.
В результате пришел вот такому полиному.
Которое сначала представляется некой тригонометрической функцией.
Косинус под n арккосинусов T.
Или его выписывают так.
Косинус под n арккосинус обозначает T.
Это и есть арккосинус.
Арккосинус T.
Сразу видно что T0 это есть единица.
T1 это есть T.
А вот чтобы определить T2, T3 и так далее остальные полиномы.
Нам нужно предложить некую рекламную формулу.
Как ее предложить?
Поскольку видите что это полинома и тригонометрическая функция.
И степенной полином получается.
Мы используем формулу, известную вам кодисума косинусов.
Tn-1 от T сложим Tn-1 от T это что будет?
Это будет сумма косинусов.
Косинус n-1θ плюс косинус n-1θ.
И если вы сумму косинусов выпишете по известной школьной формуле.
Вы получите что это есть 2T на Tn.
Вот вам рекламная формула Tn-1 плюс Tn-1.
Это есть 2T на Tn от T.
Сложите косинус и получите.
А если это так, то мы можем выписать полином T2.
Полином T2 это будет 2T в кубе минус 1.
T3 это будет полином T4 T в кубе минус 3.
Ну и так далее.
Можно выписывать дальнейшие полиномы.
А также Чебышов вел так называемый нормированный полином.
С чертой его обозначает обычно 1 на 2 в степени n на полином Чебышова.
То есть мы коэффициент при члене со старшую степенью делаем единичный.
То есть он как бы нормированный. Его так и называют нормированный полином Чебышова.
Нормированный полином Чебышова.
В нем его особенность относительно других полиномов.
Но Чебышов доказал замечательную тюрему.
Я доказывать не буду, но приведу.
Среди всех полиномов в степени n больше или равной единице
коэффициентом при члене со старшей степенью n равном единице
наименее уклоняется от нуля полином, о котором сейчас шла вещь.
Сейчас мы его называем полином Чебышовым.
Но когда Чебышов доказывал тюрему, он еще не назывался полиномом Чебышовым.
И максимум вот этого нормированного полинома t на отрезке всегда будет меньше
максимума любого другого полинома на этом же отрезке.
Вот что означает полином наименее уклоняется от нуля.
Его максимум всегда меньше максимума любого другого полинома.
Этой же степени, какого бы ни взяли.
Ну это вот один результат.
Далее следует...
Так, что еще здесь надо сказать?
А, вот еще важный момент.
Нули полинома Чебышова tm.
Вы просто берете и вот с этого функции полином Чебышова прибавляет к нулю.
Получаете cos2m-1 на 2np.
Ну m номер корня 1 от 1 до n меняется.
Это нули полинома Чебышова.
Зачем они нужны?
Если мы их сделаем узлами нашего интерполюционного полинома,
то мы получим интерполюционный полином наименее уклоняющийся от нуля.
То есть минимальный по модулю полином.
Это очень важно.
То есть погрешность его будет меньше всегда, чем погрешность любого другого полинома.
Она тоже оценена.
Я об этом тоже разумеется скажу.
Ну вот уже советская математика Бридштейн,
который, так сказать, это вторая половина 20 века,
доказал тюрему о замечательном свойстве полинома Чебышова.
Вот из тюремы Бридштейна следует,
что постоянно либега меньше или равна 8 плюс 4 делить на π в логарифме n плюс 1.
Это вот Иоанна Бридштейна.
То есть погрешность 4 делить на π.
То есть та погрешность, та постоянная либега,
которая растет степенным образом для равномерной сетки,
для сетки Чебышовской, она вот всего лишь как логарифм растет.
Результат сам по себе очень впечатляющий.
Очень впечатляющий.
Это раз.
Далее для функции f равняется модуль t.
Тоже Бридштейн показал, что предел модуля полинома,
например, на n минус эта функция, модуль,
стремится к бесконечности при m, стремящемся к бесконечности.
Эта функция не имеющая первой производной.
И показал, что для сетки Чебышова это не так.
Это не выполняется.
То есть если мы возьмем сетку на Чебышова,
то вот эта разность не будет стремиться к бесконечности.
Тоже результат совершенно замечательный.
То есть функция не имеет даже первой производной.
Производные стоят в остаточном члене,
но тем не менее погрешность не стремится к 0.
Результат тоже совершенно замечательный.
На самом деле, в ваших лабораторных вы будете делать
такую интерполяцию на Чебышовской сетке и увидите,
что результат там просто бросается в глаза.
Блестящий результат.
Как меняется свойство интерполяционного полинома,
если вместо равномерности сетки будем брать Чебышовскую сетку.
То есть узлы полиного Чебышова.
Ну и если брать РН, то есть остаточный член оценивать,
как Берштейн этим задачами занимался,
то на отрезке минус 1.1
остаточный член для функции Чебышова
будет оцениваться следующим образом.
Здесь будет стоять максимум.
Давайте я его как новую возьму.
Н плюс 1 производной делим на N плюс 1 факториал.
А здесь единица делить на 2 степени N.
Но, разумеется, при наличии N плюс 1 производной.
То есть погрешность интерполяционного полинома Чебышова,
ну вы видите, в разъединятеле стоит N факториал и 2 степени N.
То есть убывает с огромной скоростью.
Ну и если сравнить равномерно с сеткой,
то, конечно, сравнение очень-очень впечатляет.
Очень впечатляет.
Так, у нас время осталось еще или нет?
Пять минут осталось?
А, все уже, да.
Ну ладно, озвонок тогда.
На сегодня мы закончим.
