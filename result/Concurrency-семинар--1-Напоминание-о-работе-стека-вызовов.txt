Итак, наша цель сегодня разобраться с тем, что такое потоки.
Мы весь курс говорим про потоки, собираемся говорить про потоки,
на самом деле нет, я сказал уже, что про файберы, а не про потоки.
Но в первом приближении, в названии курса они есть,
в первой домашке потоки тоже есть, и вы должны их там завести в дедлог.
Так что полезно понимать, что это.
Вот наша цель сегодня разобраться, что такое поток,
чтобы вы представляли это чуть лучше себе.
Не то что какая-то магия запускается, что-то происходит, вот что именно происходит.
Вот по-честному до конца мы разберемся с этим на четвертой лекции,
начинающей с единицы, которая называется механика потоков, кажется, в плане.
Вот там поговорим, не то что поговорим, мы там код посмотрим,
который реализует потоки, и тогда уже все должно быть понятно,
в смысле как все работает.
Вот вы понимаете что-то, когда вы можете это написать на C++,
а то, что не можете написать на C++, пишите на Assembler.
Вот мы до такой степени должны с вами до лекции дойти.
Сегодня мы хотим приблизиться к этому, то есть подготовить себя к этой лекции.
Ну и просто представить, что мы понимаем конкретно под вычислением,
под потоками, как мы это себе представляем.
Это разговор про операционные системы, про архитектуру компьютера в первую очередь.
Ну вот у вас уже был про это курс, вы что-то уже определенно знаете.
Наверное не все, но что-то.
И вот мы сейчас это проверим и по пути выйдем к нашей цели.
Смотрите, есть такая вот мета-рекомендация ко всему курсу.
Называется она xv6.
Это учебная операционная система, которая была написана в MIT,
и которой в MIT учат, собственно, операционные системы писать.
Вы в первую очередь сейчас учились их использовать,
то есть есть эсколов, можете их вызывать, можете по сети общаться,
можете что-то еще делать.
Вот это учебная операционная система для того, чтобы учиться писать операционные системы.
Вам дают очень простой код на очень простом, аккуратном C,
где все очень неэффективно, но есть все разумные компоненты операционной системы.
А где чего-то не хватает, вы должны дописать их сами просто в домашней работе.
Ну вот, не то чтобы я ожидал, чтобы вы будете проходить курс параллельно
и писать код в xv6, это сложная задача.
Но вместе с исходниками этой системы, они довольно маленькие,
есть замечательная книжка, написанная преподавателями MIT,
про Ассулон Коксом, который в том числе разработчик языка ГО.
Внезапно это тот же человек.
И вот книжка занимает всего 100 страниц довольно крупным шрифтом,
с картинками, со схемами, с примерами кода.
И мне кажется, что это замечательное место для того, чтобы изучать внутренность.
После этой книжки можно даже не читать никакие другие учебные книжки,
можно сразу идти и разбираться, как Linux устроено,
и переходить на следующий уровень.
А какая книжка называется?
Можно загуглить xv6-book.
Там будет много ревизий ПДФок, но какой-то постарше возьми.
Там 18-е, 20-е, какие-то такие числа.
Может быть, уже посвежее есть.
И там фрагменты кода, комментарии, диаграммы.
Все очень здорово, по ней можно научиться.
Ну и там 100 страниц вы можете их прочесть за какое-то очень разумное время.
Еще одна рекомендация вслед за этой.
Если вы пойдете в ШАД учиться, многие пойдут,
то в ШАД есть курс АКОС, который как раз использует xv6,
и там вы сможете все это по-честному написать.
Ну вот если вы знаете, что виртуальная память,
мы сейчас вспомним, что такое механизм Copy-on-Write.
Слышали про это?
Ну вот там скажем, Домашка, напишите Copy-on-Write.
Это гораздо лучше, чем читать про Copy-on-Write в учебниках,
или на слайдах, или что-то такое.
В конце концов, вы же инженер, да?
Вы учитесь для того, чтобы программировать.
Просто люди приходят разные, кто-то учится в математике, машинном обучении.
В первую очередь, у вас специальность про программирование.
Ну вот я ожидаю, что вы должны ожидать от себя,
что вы знаете что-то, когда вы умеете это сделать руками.
Так что в XF6 вам придется делать руками все,
и в нашем курсе мы тоже все, что изучаем,
все абстракции, сущности, все мы пишем сами.
Ну хорошо, наша цель сегодня поговорить про исполнение,
начать с операционных систем.
Давайте начнем.
В вашем понимании, для чего нужна операционная система?
Какие задачи она решает?
Для того, чтобы пользователю было легче делать что-то с помощью электронного устройства.
Пользователю? Кто такой пользователь?
Человек.
Человек?
Абстрактно можно представить.
Мне кажется, что операционная система в первую очередь для разработчика.
Вот смотри, у тебя есть компьютер, и вот в компьютере у тебя есть...
Ну ладно, во-первых, операционная система для того,
чтобы программа могла с нижним миром взаимодействовать.
Ты не можешь погами на C++ с помощью ассемблянных инструкций отправлять данные в сеть.
Тебе нужен драйвер, сетевая карточка, и нужно как-то с ним общаться.
Для этого у тебя есть какие-то сисколы, которые ядро перехватывает
и умеет с помощью этого драйвера с каким-то конкретным устройством работать,
и вот ты умеешь общаться с другой машиной в дата-центре.
Хорошо, это первая задача, общение с нижним миром.
А вот есть вторая важная задача, это виртуализация.
Вот у вас есть конкретный компьютер, там есть процессор,
может быть, не слишком эффективный, с одним ядром, допустим.
Вот он может запускать только одну программу.
А у вас программ много, у вас мультизадачность.
У вас открываете браузер, и там 50 вкладок, они все должны рисоваться.
А кроме того, вы делите общий процессор.
Кроме того, вы делите общую память, и она тоже небольшая.
Но о каждой программе нужна своя память.
И вот будет очень плохо, если разработчик программы будет думать о том,
что он использует память, а ее использует еще кто-то другой.
Но это неудобно, это, конечно, небезопасно.
Нам нужна изоляция.
Мы хотим, чтобы мы привыкли к тому, что мы запускаем программу,
давайте напишем какую-то программу, с которой мы будем работать сегодня.
Вот такая очень условная.
Мы там создадим вектор.
Положим туда что-нибудь, потом вызовем какую-то функцию.
Ну а функция foo, допустим, написана здесь.
И она тоже ничего полезного особо не делает, она вызывает функцию bar.
Функция bar поместится сюда.
Пусть она даже ничего не делает.
Ну вот такая вот не слишком полезная программа.
Какая это?
Можем такую написать, скомплировать, надеюсь, запустить.
Вот, эта программа запускается, и смотрите, что она ожидает.
Во-первых, она ожидает, что ей дадут как будто бы виртуальный процессор.
Вот вы запускаете функцию main, которая делает что-то бессмысленное,
или она решает какую-то более полезную вам задачу.
Но так или иначе вы не думаете о том, как эта программа пойдет на ядро, на процессор.
Ну то есть она там попадет, начнет работать, а в какой-то момент
операционная система может ее взять, с ядра снять и поставить на ядро другую программу, другой процесс.
Ну программу не стоит говорить, конечно.
Вот мы написали программу, скомплировали ее, вот она лежит на диске, мы нажимаем enter в Shelly,
и вот запускается процесс, и вот он уже исполняется.
Ну вот, этот процесс встал на ядро, работает, работает, работает,
а дальше операционная система решила, что вот квант времени этого процесса истек.
То есть нужно делиться с другими, мы с ядра этот процесс сняли, мы операционную систему планировщик
выбрали следующий процесс, поставили его на ядро, он тоже поработал потом,
через какое-то время мы вернулись к нашему процессу, вернули его обратно, он продолжил работать.
Ну вот это то, что происходило на самом деле.
Но вы же об этом не думаете, вы просто пишете main и считаете, что вы будете выполнять сверху вниз.
Вы не наблюдаете вот этих разрывов, этих пауз, и у вас даже нет способа никакого их пронаблюдать.
То есть вы можете по каким-то косвенным признакам догадываться, что у вас вытеснились ядра,
но вообще говоря, для вас исполнение вот так вот непрерывно.
Вам как будто бы дали виртуальный процессор, и вот операционная система дает каждому процессу
виртуальный процессор, чтобы там исполняться.
А еще этой программе полагается большая память.
Вот она тоже виртуальная, и она так и называется, виртуальная память.
У нас есть такой большой и непрерывный массив байт.
Насколько большой?
Как они кончатся?
Ну так вот я и спрашиваю, когда он кончится.
Сколько байт вы можете адресовать в программе?
Это зависит от ситуации.
Нет, не зависит от ситуации. Ну в смысле, зависит, конечно, но что значит от ситуации?
Это не слишком строгий термин.
Ну то есть если памяти меньше, то в этом же есть мысло абстракции,
что абстракция, она как бы отрывает тебя от конкретных лимитов железа.
Все разумеется, ты не сможешь себе выделить бесконечно много памяти,
потому что физическая память 8 гигабайт, допустим,
но ты не должен об этом беспокоиться, когда пишешь программу.
Давайте подумаем, вот память массив байт, вы можете эти байты адресовать.
У вас в программе бывают указатели.
Ну вот сколько бит в этих указателях?
Вы заводите переменную, у вас односвязанный список,
в структуре листа находится нод-звездочка,
поинтер на очередной узел.
Видимо, вы можете адресовать столько памяти, сколько у вас бит в этом поинтере, в этом указателе.
Ну то есть в конечном итоге мы зависим от процессора,
какими машинами слаймы он оперирует, какова их разрядность.
Вот какова разрядность современного процессора?
64-битные.
Значит, у нас бывают 64-битные указатели.
Видимо, мы можем адресовать вот столько памяти.
Довольно много.
Какие-то экзобайты.
У нас, конечно, столько нет.
У нас все еще какие-то единицы гигабайт,
на каком-нибудь домашнем ноутбуке, но адресовать мы можем столько же.
Разумеется, мы не можем всю эту виртуальную память заполнить.
Мы не можем ее заполнить, потому что у нас столько физической памяти нет.
Поэтому мы можем заполнить только ее часть.
И какой-то механизм появляется для того, чтобы это уметь делать.
То есть мы можем пользоваться памятью, но при этом мы не можем заполнить всю-всю.
Вот как операционная система с ней справляется?
Надо управлять виртуальную, физическую.
Вот. А как это происходит?
Какой механизм там используется?
У нас есть виртуальная память и есть физическая память.
И она довольно маленькая.
По крайней мере гораздо-гораздо меньше, чем эта виртуальная.
В каком масштабе происходит отображение? На каком уровне?
Гранулярность это отображение.
Мы говорим для каждого байтика, какому байтику физическая память соответствует?
Вот это называется paging, страница.
Вот мы делим виртуальную память на блоке размера.
Обычно 4 096.
Да. 4 килобайта.
Но в системе можно это изменить?
Это можно изменить, но вот такой стан...
Это не так, ну в смысле...
Это не настолько гибкая настройка, все-таки она...
Думаю, у Виктора Вадимовича говорят, что там легко.
Просто пара команд это сделать.
При размене нового места.
В общем, дефолт такой.
Давай сейчас его придерживаться, потому что я пытаюсь объяснить,
где он окажется дальше, где он будет использоваться.
Ну вот страница.
И мы делим виртуальные адреса на такие вот страницы.
И физическую память мы делим на такие страницы.
И, разумеется, мы не рассчитываем, что каждая виртуальная страница
соответствует физическую.
Каким-то соответствует, каким-то нет.
У нас есть эта страница.
Она в физической памяти находится здесь.
Есть и эта виртуальная страница.
Она находится пусть вот здесь.
Штриховка в другую сторону получилась.
Разумеется, непрерывность тут никакая не нужна.
Здесь страницы могут идти подряд.
Они могут идти далеко друг от друга.
Ну и бухер вектора может разорвать его на две части,
если он границу пересекает.
В этом ничего страшного нет.
А теперь мы пишем программу.
И в ней мы написали вот такой код.
Мы хотим интервироваться по односвязанному списку.
Говорим, но стрелочка next.
Это означает, что процессор исполняет инструкции.
Тут написано какое-то move, видимо.
И процессор должен взять вот этот pointer на узел
и по этому указателю прочесть какие-то байты из памяти с каким-то offset.
У этого поля есть offset внутри класса.
Вот нужно взять указатель, прибавить к нему этот offset
и прочесть из памяти значения.
Этим должен заниматься процессор.
Так вот, откуда же процессор знает,
как виртуальные страницы соответствуют физическим?
Очевидно, это соответствие поддерживается операционной системой.
Процессор не будет ходить к операционной системе
каждый раз что-то сложное спрашивать.
Ему нужно прямо сейчас узнать,
как транслировать виртуальный адрес физически.
И вот виртуальный адрес у нас занимает...
Мы выяснили, что 64 бита.
Вот смотрите, 64 бита.
Что если адрес как число,
вот как индекс в этом гигантском массиве байт,
что если взять остаток отделения этого числа на 4096?
Какой вот его смысл?
Ну да, мы получим отступ от начала страницы.
Вот если мы поделим на 4096, мы получим индекс страницы.
Вот нулевая страница, первая, вторая, третья.
Остаток отделения, то есть младший 12 бит,
ну потому что вот 2 в 12,
младший 12 бит этого указателя,
это просто отступ внутри страницы.
Вот его транслировать не нужно.
Он сохраняется.
Нам нужно как-то взять номер страницы,
вот эти старшие биты,
и транслировать их в номер физической страницы.
Вот операционная система нам должна,
нам, процессору, должна подготовить какую-то структуру данных,
которые можно использовать для отображения.
Ну вот как вы храните отображение обычно?
Сомневаюсь, вы, наверное, СТД-мэп пишете,
или СТД Нордэдмэп?
Вот.
Нет никакой надежды сделать то же самое здесь,
потому что здесь вот это отображение строит операционная система,
ходит по нему процессор,
и логика процессора выложена просто вот на нем.
Это не какой-то код.
Это вот то, что прямо в процессоре на схеме выложено.
Поэтому логика должна быть какая-то простая,
и вот там не может быть, наверное,
не стоит писать какие-то бесконечные циклы,
в смысле не бесконечные какие-то циклы с непредсказуемыми переходами.
Должно быть все очень понятно, быть очень просто.
Поэтому вот мы сейчас должны выяснить,
каким же именно образом это отображение поддерживается.
Но перед тем, как мы это сделаем,
заменим следующее.
А где это отображение вообще будет храниться?
Вот какая-то структура данных должна быть,
в которой указано, как вот одни большие числа
отображаются в другие большие числа,
одни там виртуальные адреса физические.
Вот где это будет храниться?
Какой-нибудь кэша процессор?
Нет, в кэше у нас все постоянно куда-то девается.
Мы пока про кэши не говорили,
но это можно любым момент потерять,
поэтому его смысл.
Поэтому мы там хранить, конечно, ничего не можем.
В смысле только там хранить не можем.
Это не является основным местом хранения.
Вот где же нам хранить отображение?
У нас есть память, ничего другого у нас нет.
Причем вот это отображение typicallyி Executoq,
из виртуальных адресов физически,
оно же будет для каждого процесса свое,
потому что у нас есть один виртуальный адрес,
но вот эта одна виртуальная страница,
может в одном процессе отображаться в одно физическое,
в другом процессе — в другую физическую.
этого можно ожидать. Иногда бывает так, что страница общая,
например, потому что там лежит общая библиотека. В этом у вас есть Lipsy,
зачем Lipsy дублировать физическую память? Она одна общая и просто на нее все
ссылаются. В общем случае, страницы разные, таблицы страниц разные,
поэтому для каждого процесса своей структуры данных у нас ничего нет,
кроме памяти. Ну, в смысле, кроме вот этой памяти физической.
А эта физическая память, она разделена на страницы. И вот мы скажем,
что среди этих страниц есть страницы, которые хранят данные ваших программ,
ваших процессов, а есть страницы, которые хранят, скажем, методанные,
то есть служебные данные, которые нужны операционной системе для того,
чтобы ваши программы работали. Так что вот мы здесь будем использовать
физические страницы. И вот ровно поэтому я написал, что 4096.
Смотрите, как именно организовано отображение. Это не хэштаблица,
это не дерево сбалансированное, конечно же, это структура, которая называется,
я не знаю, как вы ее называете, я могу тремя способами называть,
try, bore, прихистное дерево. Что вам ближе? Бор. В чем идея, напомню?
У нас есть... Мы храним отображение из строчек куда-то. Как мы это делаем?
Вот если у нас строчка ABC есть, мы храним... Мы строим вот такой вот деревце,
такую веточку. Если мы туда добавляем в эту структуру строчку ABD,
то мы вот здесь префикс разделяем и добавляем еще один лист.
Если мы добавляем строчку AD, то у нас появляется вот такой вот лист.
И вот эта структура кодирует нам 4 пути от корня до листа,
то есть 4 строчки.
Он не сжатый.
Нет, конечно же, это было бы убийственно, но не эффективно.
Сейчас давай постепенно. Мы собираемся хранить отображение
из виртуальных адресов физически в виде такого вот bore, да, я забыл?
В виде такого bore. Но правда алхалит у нас будет немножко побольше.
Здесь он 26, а у нас мощность алхавита будет 2 в 9.
То есть мы рассматриваем вот эту часть адреса как строчку
с довольно толстыми символами. Вот он берен...
Давайте чуть покомпактнее. 9 бит, 9 бит, 9 бит, 9 бит.
И вот это символы нашей строчки, которую мы собираемся искать в этом bore.
Почему 9 бит? Почему мы берем вот такие блоки в нашем адресе?
Понятно это или нет? Непонятно.
Ну смотрите, вот мы собираемся спускаться по этому bore.
У нас теперь в каждом узле побольше развилок становится.
Здесь их 26 максимально, а сейчас у нас сколько развилок может быть?
Почему в смысле 2 в 9? Мне же это интересно.
Вот у нас каждый узел будет представлен в виде отдельной страницы.
Вот у нас есть корень bore, это страница памяти размером 4096.
А что такое ссылка? Ну вот стрелочка.
Это адрес другой физической страницы. Сколько он занимает? Ну 8 байт.
У нас 4096 байт есть, да, в 12.
И нам нужно в этом массиве уложить ссылки, стрелочки размером 8 байт.
Сколько у нас их поместится?
Ну 2 в 9.
Поэтому мы и выбираем блоки по 9 бит, такой алфавит берем,
потому что вот так мы можем насытить этот блок, эту страницу памяти.
И что мы делаем в итоге? Мы берем, кажется, вот старшие 9 бит.
Да, у нас еще остается сколько? 12 плюс 36, 48. Остается еще 16 бит.
Так вот, 16 бит они не используются для адресации.
То есть на самом деле у нас не столько памяти,
мы можем адресовать, а 2 в 48. Чуть поменьше.
Это можно дорастить, в смысле у нас процессор позволяет использовать больше бит для адресации,
но пока мы используем чуть меньше, и сейчас будет видно, почему.
Вот мы, кажется, берем сначала старшие вот эти биты.
Получается у нас некоторое число от 0 до 2 в 9 минус 1.
И вот мы просто используем это число как индекс в массиве,
где каждая запись занимает 8 байт. Вот попадаем куда-то сюда.
И здесь написана ссылка на другую страницу, где находится следующий узел нашего бора.
Там мы берем уже синие биты и снова попадаем куда-то.
Снова куда-то переходим.
Тут у нас будут черные биты.
Так, я помещаюсь даже.
Ну и наконец мы берем последний символ этого большого алфавита.
И он указывает нам куда.
Вот сюда.
Вот теперь мы наконец знаем, что нам нужно прочитать. Мы процессор.
Правда, непонятно, как мы вообще корень нашли этого дерева.
Откуда он?
Ну как, что значит в определенных местах? Для каждого процесса эта таблица своя.
Так что операционная система, когда она ставит процесс, исполняется на процессор,
то в специальный регистр, я, честно говоря, не помню, как он называется.
CR3, да, совершенно очевидно.
Операционная система пишет указатель, по сути, на корневую страничку с метаданами.
А дальше уже, когда вы пишете node next, процессор что делает?
Он по этой ссылке идет сюда, бьет эти 9 бит, переходит глубже, глубже, глубже.
И в итоге вместо того, чтобы просто один раз прочтить из памяти, он читает раз, два, три, четыре раза,
и потом пятый еще наконец. Выглядит довольно безумно.
Мы вместо одного, на месте одного логического чтения делаем пять физических чтений.
А учитывая то, что чтение из памяти примерно в сто раз медленнее, чем операции над регистрами,
это все выглядит очень печально.
Поэтому в процессоре есть то, что называется TLB.
Это кэш, это наслаждаемо касаемый buffer, то есть кэш, который просто в процессоре запоминает
самые горячие страницы, которые чаще всего вы используете, и просто напрямую хранит отображение.
Не читая много раз в памяти.
Ну вот такой механизм называется page table, page directory.
Вот вы, конечно, все это знали.
Хорошо, мы процессор научились читать.
Глубина этого дерева может быть...
Нет, глубина не то, что может быть, она фиксирована, она четыре.
То есть процессор ожидает, что он сделает четыре чтения, тогда берется до страницы нужной.
Смысл этих 16 бит в том, что процессоры оставили себе возможность адресовать больше памяти,
но пока делать этого не хотят, потому что текущей памяти хватает вот такой вот.
Но если мы захотим поддержать больше, мы поддержим, добавим еще 9 бит,
но правда замедлим трансляцию, потому что появится еще один лишний уровень.
Вот текущим процессорам четырехуровневые таблицы страниц достаточно.
Вот 16 бит пока свободны, но не то чтобы они произвольные, они не произвольные,
но они такой нагрузки существенные, они не несут себе ничего полезного.
Вот то есть если страница есть, если в отображении есть такая стрелочка,
может быть и нет ее. Вот если есть, то ты проходишь через четыре ура.
Ну хорошо, мы научились читать память, уже неплохо.
Ну а теперь подумаем, что в этой памяти вообще лежит.
Ну смотрите, процессор начал исполнять нашу программу, он движется по ее инструкциям.
Откуда он их берет?
Он, конечно, берет их с памяти, потому что брать их из диска было бы примерно миллион раз медленнее.
У нас будет лекция про это, там есть смешные аналогии, не хочу их сейчас спойлерить.
Ну в общем, это много-много порядков, но кажется примерно миллион раз.
То есть чтение с диска это миллисекунды, чтение с памяти это сотни на секунду.
Ну с SSD может быть чуть меньше, но все равно это...
Ну очень много процессоров, но примерно в сто раз медленнее, чем ты работаешь с регистрами.
Но намного быстрее, чем ты работаешь, скажем, с диском, который вращается и там вот эта рука ездит.
В общем, мы загружаем текст программы в память, конечно, он где-то находится.
Вот давайте его где-то здесь изобразим. Где-то здесь находится текст.
И в процессоре, чтобы исполнять вашу программу, есть регистр, который мы называем как?
Как мы называем его? Мы называем RIP, Instruction Pointer.
А Instruction Pointer, который указывает на что?
На следующую инструкцию, которую мы собираемся исполнить.
Вот он куда-то указывает.
Ну и если все идет как обнудно, в зависимости от того, какие инструкции процессор встречает,
этот Instruction Pointer передвигается либо в следующей инструкции, которая следствует за текущей идет,
либо может быть прыгнет куда-то в другое место.
Вот что может заставить процессор перепрыгнуть в другую точку текст программы?
Ну, например, вы написали там GoTo, не дай бог.
Ну, кажется, вы так не делали. Умные люди давно научились не использовать GoTo и получат от этого массу выгод.
Ну скажем, если вы не используете GoTo, то у вас получаются вызовы, образуют такую иерархию,
поэтому у вас работает рай, и это все очень удобно.
И это такой глубокий инсайт нам в будущее про одну из последних лекций.
Ну, в общем, ты можешь написать GoTo все еще, никто тебя не остановит.
И тогда в коде будет какой-то джамп по какому-то адресу, то есть такой безусловный прыжок.
Может быть ты написал цикл или условие, вот написал и в какое-то условие,
то код A не пишите так, это не по код стайлу LCB.
И тогда компилятор выложит там подряд, допустим, A и B и напишет, что если условие выполнилось, то пойти дальше,
а иначе перепрыгнуть A и исполнять B. Ну, какие-то там метки расставит, будет по ним прыгать.
В общем, понятно, куда мы прыгаем.
А есть, скажем, вызов функции. Вот вызов функции он чуть интереснее устроен.
Вот если на месте GoTo мы напишем какой-нибудь джамп, или на месте if мы там напишем снова какой-то джамп условный уже,
то есть прыгнуть если больше или прыгнуть если меньше, что-нибудь такое,
то что компилятор напишет здесь? Какую инструкцию? Он напишет инструкцию call.
И здесь напишет адрес, куда нужно прыгнуть.
Ну, адрес все еще известен, хотя это уже менее очевидный нюанс, потому что, скажем, вы компилируете программу,
и там вот функция foo вызывает функцию bar. И может быть так, что функция foo находится в одном cpp-файле,
а функция bar находится в другом cpp-файле. В смысле, реализация функции bar находится в другом cpp-файле.
И компиляторы, говорят, компилируют их независимо. Это называется единица трансляции.
Компилятор берет cpp-файл, включает в него все заголовки, которые в этом заинклузере,
и вот собирает код, собирает объектный файл. Правда, компилятору в этот момент неизвестно,
куда же прыгать, когда мы вызываем из foo bar, потому что в текущем скопе компилятору неизвестно реализация функции bar,
код непонятно где находится. Ну, кажется, на стадии построения объектных файлов это не страшно,
но с этим же все не заканчивается при компиляции, что дальше происходит.
Ну вот дальше мы связываем вот эти все объектные файлы и понимаем, куда мы собираемся прыгать.
И в итоге, когда у нас есть текст программы, так условно, и в нем можно выделить main, bar foo,
у нас еще bus был, да? Вот, и программа начинает исполняться.
Там компилятор расставил эти самые call с адресами, и вот мы исполняем функцию main,
прыгаем в вызов функции foo, она прыгает в bar, bar прыгает в bus. Все вроде понятно пока, да?
Непонятно только, возможно, почему мы вместо инструкции jump используем инструкцию call.
Зачем нам отдельные инструкции?
Ну вот, да, смотрите, у нас есть проблема, когда мы доходим до конца функции bus,
и вот в этот момент непонятно, что делать процессору, потому что он должен переместиться куда.
Вот сюда он должен переместиться. Но в момент компиляции компилятору, конечно же,
непонятно в какое место нужно вернуться из функции bus, потому что можно вернуться вообще,
куда угодно. Может быть, это библиотека, и кто угодно может ей пользоваться.
Так что статический адрес неизвестен, поэтому чтобы процессор мог вызывать функции,
чтобы он мог вызывать эти foo, bar, bus, возвращаться из них, нужно в runtime поддерживать еще одну структуру.
Вот у нас уже в runtime есть вот этот page table для трансляции адресов,
а у нас есть еще одна структура, она называется...
Увереннее говорите. Она называется call stack, stack вызов.
И что именно делает инструкция call?
Когда мы говорим call, мы с одной стороны прыгаем в начало той функции, которую мы собираемся вызвать,
а еще этот stack живет где-то в памяти. Давайте нарисуем его сразу.
Вот где-то у нас появился stack.
И нужно добавить кое-что в процессор. Нужно добавить еще один регистр, который называется...
Называли уже. Rsp, который указывает на вершину stack.
Давайте нарисуем.
Оказывает на вершину stack. И когда мы говорим call, то мы вершину stack сдвигаем вниз по адресам
и помещаем в stack адрес возврата.
То есть инструкцию, в которую нужно прыгнуть после того, как функция bar завершится.
Ну и в конце теперь функции bar мы используем инструкцию call.
Здесь мы помещаем инструкцию red, которая поступает симметрично.
Она снимает со stack адрес возврата. Она ожидает, что к этому моменту stack pointer находится в этом месте.
Мы снимаем со stack RIP, возвращаем его вот сюда, ну и прыгаем по этому адресу.
То есть мы помимо того, что прыгаем, мы еще и с stack немножко манипулируем,
восстанавливаем RIP или запоминаем RIP.
Что?
Что значит просто в stack?
Сейчас я...
Это не то, чтобы в call stack живут только RIP, разумеется.
Но он в первую очередь для этого нужен.
Не только, не знаю, в первую очередь, не в первую, но он называется call stack,
потому что с помощью него можно перемещаться по вызовам.
Но, конечно же, это еще не все, потому что, скажем, нам нужно передавать аргумент функциям иногда.
И вот что мы делаем здесь?
Мы вызываем функцию bar с двумя аргументами. Как мы их передаем?
Через регистр, а не через stack. Здесь stack нам не нужен.
Здесь мы передаем через RDI, здесь мы через RSI, не ошибаюсь.
Вот тут правильно говорят, это называется соглашение о вызовах.
Вот мы в процессореоперационной системе должны зафиксировать, как функции общаются друг с другом.
Потому что, в самом деле, вы вызываете функцию, вы ожидаете, что вы...
То есть вы, компилятор, вы вызываете функцию, вы ожидаете, что функция как-то будет разумно себя вести.
Ну, например, представьте себе, что вы были функцией foo, и в вас был написан очень сложный код.
И вы, компилятор, этот код скомпилировали, этот код разложил текущие данные по регистрам.
Вот регистр в процессоре, и вот там сейчас лежат ваши текущие вычисления.
И вот вы вызываете функцию bar, а ее компилировал кто-то отдельно вообще.
Ну и bar, функция bar написана как-то, она что-то делает тоже с регистрами, видимо.
И вот было бы очень печально, если бы функция foo вызвала эту функцию bar.
Функция bar внутри переписала бы все эти регистры, вернула бы управление функцией foo,
а функция foo, что ей делать теперь? Все данные стерли.
Поэтому, что фиксирует соглашение о вызвах?
Это называется calling conventions. Вы знаете, да, это?
С одной стороны, они фиксируют, как возвращать результаты, как передавать аргументы,
а с другой, эти соглашения делят регистры на caller saved и caller esaved.
И вот есть набор регистров, которые функция bar, она может их перезаписать,
но перед возвратом функции foo она должна их восстановить.
То есть часть регистров после вызова bar останутся в том же виде, которые были перед вызовом bar.
Остальные можно стереть. И вот компилятор, когда он компилирует функцию foo,
он пишет код таким образом, чтобы этот код не зависел от того,
что будет в других регистрах, кроме call esaved после вызова foo.
Давайте вспомним call esaved регистр на всякий случай. Не то, что на всякий случай.
Это нам потребуется. R12-15, это опять для Linux, для x86 и x4, rbx, rbpr, rsp.
Объясните мне, почему вы помните вот это, хотя зачем это помнить?
Это должен помнить компилятор. И не помните вот это, и не знаете вот это.
Вы как-то неправильно распределяете свои усилия.
Вообще, кстати, я рассказываю это для баловства на самом деле.
Нам это прямо не нужно. Сейчас смотрите, я объясню, что имею в виду.
Все, что я рассказываю, рассказываю с какой-то целью.
То есть почти все, что я говорю, понадобится нам, кроме вот этого.
Потому что, смотрите, я сейчас все объясню. На курсе конкарнсии прямо это не пригодится.
Но я рассказываю курс конкарнсии с таким намерением хитрым, чтобы на самом деле
найти людей, которые послужат курсом по распределенным системам.
И все для этого на самом деле. На половину я шучу, конечно, но на другую половину это правда.
И вот там действительно сложные вещи, и вот там мы конкарнсии пользуемся в полный рост.
Так вот, оказывается, что если вы понимаете, как работает трансляция адресов
в операционной системе, то внезапно вы можете, отталкиваясь от этой идеи,
придумать, как масштабировать дизайн распределенного кивели у хранилища,
который хранит все ваши письма. Вот система Google Bigtable, которая используется в Google
для хранения, которая живет Gmail. Вот там ключевая идея для ее масштабирования,
она не то чтобы напоминает, она вот однозначно соответствует этой конструкции.
С кэшами там есть TLB, там есть этот регистр, там все это есть.
Это, конечно, очень трудно увидеть, когда вы читаете статью.
Но если вы подумаете, как на самом деле это выглядит и как это придумали,
то окажется, что просто была переиспользована идея из дизайна операционных систем.
Чем больше пользователей у Gmail, тем медленнее у каждого конкретного оно будет работать?
Ну, разумеется. Система масштабируется.
В смысле, она не может работать одинаково быстро и вот расти бесконечно.
Где-то вот накапливается аверхед из-за этого.
Ну, ты очень верно заметил. В общем, это тоже мне пригодится.
Но в какой-то очень отдаленной перспективе, когда это вы забудете,
а я напомню, вы такие, ага. Ну вот, а все остальное нам нужно.
И вот скажем, зачем я говорю про соглашения о вызовах?
Ну, вот они нам пригодятся, когда мы будем потоки переключать.
Ну, удивительно, что это вы запомните, конечно.
Ладно.
Так, хорошо. Значит, до начала мы остановились.
Мы научились вызывать функцию foo, вызывать функцию bar с аргументами.
А теперь мы поговорим про calling convention, про stack.
Давайте еще про stack кое-что вспомним.
Ну, что еще у нас таки лежит, кроме аргументов иногда и вот адресов возврата?
Вот есть вектор. Из чего он состоит?
Причисляйте поля.
Ну, название скорее.
Вот есть pointer на буфер с данными, который живет, кстати, где? В хипе, да?
У нас хипанина нарисована.
Ну, хип.
Есть размер вектора и есть capacity, размер буфера.
Вот где это все лежит?
Сайти и capacity на stack все-таки.
А дата?
И указатель тоже на stack.
То есть если мы вызываем какой-нибудь main, то вот этот вектор будет где-то здесь лежать.
Тремя своими полями.
Ну, или есть какой-то локальный, может в регистр, я не знаю, могут его в регистр положить.
Ну ладно.
В общем, на stack тоже может что-то жить.
То есть call stack не только для того, чтобы сохранить RIP, но вот все-таки это основная его задача.
Хорошо, значит, мы научились ходить по вызову, вглубью возвращаться оттуда.
Мы научились читать из памяти что-то. Мы умеем прыгать с помощью джампов, колов и ретов.
Что еще осталось обсудить?
Ну, вот куча есть.
Мы где собираемся здесь с кучей работать?
Видимо, когда мы вызываем pushback.
Видимо, пустой вектор не алоцирует динамическую память.
И когда мы говорим pushback 7, то алоцируется какой-то небольшой буфер.
Но не из одного все-таки элемента. Из какого?
Ну, понимаю, да. Я просто не знаю, мне любопытно.
Я 8 писал, когда мы...
Извините.
Все же не про тебя спрашиваю. Я скорее про Estelle, про какую-нибудь из реализации. Не помните, да?
Ну, не больше 10, скорее всего.
Все же это локация динамической памяти. Вы там зовете какой-то молок.
Вот понимаете ли вы, что делает молок?
Да.
Хорошо, идем дальше.
Давайте развернем.
О чем я говорю сейчас? О том, что у нас есть память.
И есть единственный способ алоцировать эту память.
В смысле, есть виртуальное адресное пространство.
И вот есть вот эти блоки виртуальные, странички.
И за ними может лежать клиническая память, а может не лежать.
То есть может быть в page table этом нет записи вот для этой страницы.
Может быть, она вот пустая.
Вот эта, пусть.
Может быть, там вот нет записи.
Процессор по ней пойдет и встретит sigfold.
Так вот, как же нам получить в процессе новую страничку памяти?
Как ее алоцировать, собственно?
Ну, вот мы не можем этого сами сделать, разумеется, на C++.
Мы можем только просить операционную систему.
Для этого у нас есть вызов системный, который называется MMAP.
Который про memory mapping, собственно, он и занимается отображением памяти.
Мы говорим ему, например, там есть много вариантов, что мы можем ему сказать.
Ну, допустим, мы говорим, выдели, пожалуйста, мне, ну, не знаю, 100 страниц абы где.
И он нам их выделяет, возвращает pointer на первую страницу.
И мы знаем, что 100 следующих к ним можно обращаться.
Может быть, они еще не выделены на самом деле, но там случится page fold и операционная система.
Все-таки по мере необходимости, если заставят, выделит.
А что делает malloc тогда?
Ну, вот смотри, мы вызываем здесь, видимо, malloc в конце концов, да?
И вот мы у него просим 10 умножить на size of t.
Ну, довольно мало.
Что он будет делать?
Он же не будет к операционной системе ходить.
Это же было бы безумием, если мы на каждую аллокацию ходили бы, переключались бы в ядро.
Ну, вот аллокатор, он обычный память не аллоцирует.
Он аллоцирует как-нибудь заранее, ну или иногда большими аренами.
Просит через мэп много-много памяти.
Но обычно аллокаторы делают так современные.
Они делят все локации на классы.
Вот до 32 бит.
32, там, не знаю, 16, 8 байт иногда.
16 байт, 32, 64.
Если вы просите 51 байт, то он округляет до 64.
И аллоцирует 64.
Вот такие вот классы есть.
И для каждого класса аллокатор аллоцирует арену, то есть зовет мэп,
и просто нарезает их на равные кусочки.
И вот когда вы просите очередной блок размера 64 байта,
то он просто, аллокатор помнит, что вот есть такая арена для этого класса аллокаций,
и что мы уже использовали какое-то количество этих кусочков P64.
Возьмем следующий, отдадим на него поинтер.
То есть просто он обращается к метаданным и понимает, какой кусочек сейчас не используется.
И отдает поинтер на него.
Ну вот, хорошо.
У нас есть хип.
У нас есть хип.
Мы там можем выделить динамическую память.
А стэк, чем отличается он от кучи?
В смысле, странный вопрос, чем он отличается.
Он для другого совсем.
Но на каком-то уровне все это страница.
И вот на самом деле стэк-то не сильно отличается от кучи.
И это не какая-то особенная память.
Если мы собираемся писать свои потоки,
а мы собираемся писать свои потоки,
то нам нужно выделять для них стэки.
Потому что без стэка исполняться вообще невозможно.
Просто ходить по коду невозможно.
Так что нам нужно будет выделить стэк.
Никто не помешает нам выделить стэк через malloc, скажем.
Вот стэк это просто какой-то фрагмент памяти,
на который в процессоре есть поинтеры,
которые используются для того, чтобы там запоминать адреса возврата,
иногда передавать аргументы,
иногда хранить какие-то локальные переменные небольшие.
Ну вот, я почти готов закончить.
Только еще маленький кусочек.
Про сисколы давайте вспомним.
Но сисколы мы не будем вспоминать,
вспомним какие-то.
Давайте подумаем,
какие вы знаете сисколы, которые, конечно,
отличаются от вызовов функций обычных,
потому что они могут быть обслужены только ядром.
Значит, нужно перевести процессор в другой режим
и вообще уйти с этого стэка,
потому что его можно покарабтить для операционной системы.
Короче, какие сисколы вы знаете,
которые работают с планировщиком?
Что?
Я так и не настолько хорош.
Еще раз поясню вопрос.
Вот сисколы бывают разные,
и нас интересуют только те, которые работают,
которые касаются исполнения.
То есть если мы говорим Bright,
то мы работаем с сокетами, с каким-то устройством.
Вот какие сисколы обращаются к планировщику?
Ты с козырей начинаешь сразу.
Давай что-нибудь попроще.
Вот есть сискол, который знает каждый школьник.
Который обращается к планировщику.
Ну это какой-то специальный школьник все-таки.
Не самый простой.
Какой-то специально обученный.
А вот прям чтобы каждый школьник.
Ретроит он разве к планировщику обращается?
Не похоже.
То есть мы говорим,
мы хотим что-то сделать с исполнением,
но то, что мы сами не можем
написать.
Очень простой сискол.
Но это не то, чтобы сискол
можно назвать библиотечную функцию.
Проще, проще.
Ну слип, конечно.
Вот смотрите, вы можете
исполнять что угодно.
Вы можете исполнять инструкцию, я ничего не делаю.
Я просто там
стараюсь не тратить много энергии.
Но вы все равно исполняете инструкции.
Но вы не можете не исполнять инструкции в коде.
Вот вы не можете уйти с ядра сами.
Своими инструкциями.
Вы можете просить ядро, чтобы вас сняли.
Ну вот слип, он позволяет вам уйти с ядра
и
отдать это место кому-то другому.
Ну вот чуть посложнее вызов.
Он называется шид-илд.
Ну я коротко иилд напишу.
У него семантика такая. Вы исполняете, потом говорите
с темы, что я вообще-то готов
уступить ядро. Если есть другие желающие,
которым больше надо, чем мне,
то можно нас переключить.
Вот довольно странная ситуация,
что мы вроде бы хотим использовать ядро,
а потом мы отказываемся от этого сами.
Ну вот в субботу мы увидим какой-то код простой,
который этим будет заниматься.
Это, конечно, еще не все, но на сегодня
хватит, в смысле, сисколов.
И давайте перейдем к заключению, зачем все это было.
Что я хотел вам рассказать.
Во-первых, я хотел вам сказать следующее,
что вот посмотрите на эту картинку.
Вот тут нарисовано ядро процессора,
и оно исполняет какой-то код.
Ну, возможно, это поток.
Вот вы создали studio.red,
и вот он выглядит так вот.
У него есть какой-то свой стэк,
он исполняет какие-то инструкции,
но он живет в адресном пространстве
какого-то процесса.
Но вот само ядро на этой картинке
оно ничего про std.red не знает,
в смысле про thread вообще ничего не знает.
Вот у ядра есть просто stack pointer,
у ядра есть instruction pointer,
у интра есть корень, таблица,
страницы.
И вот в данном случае
мы эту картинку рисовали в предположении,
что мы скомпилировали программу, запустили процесс,
и вот операционная система сама это настроила все.
Вот она создала единственный
для вашей программы поток,
который исполняет мы.
Но мы с вами
собираемся исполнять свои потоки.
Так вот,
что мы должны будем сделать, получается?
Получается, мы сами
должны будем установить instruction pointer,
установить stack pointer,
видимо, латировать stack.
Это делать не нужно, потому что все потоки
живут и так в адресном пространстве процесса,
это уже все готово.
То есть мы должны будем настроить
процессор так, чтобы он исполнял нашу программу
на нашем стеке.
И вот мы тогда создадим поток.
В смысле, о чем я говорю?
О том, что с точки зрения процессора вообще
нет никакой разницы между потоками, файберами,
как бы мы это ни называли.
Вот мы исполняем в Гога routine сейчас
или в C++ исполняем поток.
Да какая разница
процессора? Вот у него есть регистр,
он с этим всем работает.
Кто поставил эти регистры,
runtime языка, ваша библиотека,
операционная система, не важно.
На таком уровне мы говорим просто
про исполнение.
Откуда это исполнение взялось,
это вопрос уже, который решается уровнем выше.
Это нас должно обнадеживать.
А есть одна деталь,
которая должна нас немного сбивать с толку.
Вот мы же
хотим реализовать потоки
без операционной системы.
То есть мы хотим сделать легковесные потоки в пространстве пользователя.
Это значит, что мы должны
уметь делать slip и yield.
А теперь смотрите,
какая штука.
Вот у нас есть
процессор.
Он умеет двигаться
по коду с помощью джампов, но они нам не интересны,
с помощью колов и ред.
И вот когда вы пишете такой код,
структурное программирование называется,
у вас есть такое свойство,
что любые два вызова они
либо не пересекаются, либо вложены.
Вот у вас есть вызов main,
там вы зовете pushback, а потом зовете
фу.
А внутри фу вы зовете бар, а внутри бар
вы там еще что-то зовете.
Вот такая иерархия получается.
Вот вы вначале вызовете кол, углубляетесь,
потом говорите ред, возвращаетесь на уровень выше.
А теперь посмотрите,
что происходит, когда вы делаете yield.
В первой домашке вы там уже работаете с файберами,
и мы их
собираемся написать,
а у них тоже есть
эта функция yield.
И если мы запускаем, скажем, два файбера,
сначала красный, вот он начинает исполняться.
Исполняется, исполняется, потом говорит yield.
Это значит, что мы
готовы уступить, исполняя синему.
Вот он запустился,
и исполняется теперь, вот он.
Потом он сказал yield,
и продолжил исполняться
красный. Закончил,
наш поток виртуального ядра
освободилась, и продолжил синий,
и вот тоже завершился.
И вот мы запускали в потоках
файберах две лямды,
две функции какие-нибудь.
Но вот у них теперь интервалы пересекаются.
Вот мы поломали это свойство.
Вот мы каким-то образом
должны научиться исполнять
код так вот,
переключаясь, чередуя
внутри вызовов.
При этом
ничего другого, кроме
тех инструкций, которые мы обсудили, у нас нет.
У нас есть колы реты, и вот нам нужно
будет как-то выкрутиться, есть у них
такую семантику реализовать.
То есть это не то чтобы
препятствие, но вот это некоторые
неочевидные моменты, которые
нам придется обходить,
и вот окажется, что компилятор нам здесь
не поможет. В смысле, компилятор не умеет.
Компилятор расставляет колы реты вот так вот.
А мы хотим чего-то более экзотического.
Ну вот если мы это сможем
сделать, то вот все остальное мы тоже
сможем сделать.
Ну что, надеюсь, я примерно объяснил,
что такой поток.
Ну по крайней мере, как его видит процессор.
Кажется, мы
поверили, что мы сможем такое же сделать,
без походов в ядро. Нужно вот
может быть только вот этот момент
придумать. Он называется
переключением контекста, но обычно этим ядро занимается,
там прерывание прилетает по таймеру, у нас
вытесняет, ну а может быть мы сможем
это сделать
сами.
Ну вот такая история. На сегодня
тогда все.
Это было повторение, надеюсь, вы все
это знали.
Большая часть.
Тогда через неделю мы продолжим.
