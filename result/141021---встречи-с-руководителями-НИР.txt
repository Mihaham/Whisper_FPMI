Давайте начнём. Так, ну, как вы знаете, наверное, меня зовут Сагдей Форсенин,
и сегодня я вам расскажу о задачах геометрической теории Рамсея.
Сначала давайте дадим такое относительно общее определение.
Вот у вас есть пространство R, P, N, где N — это какое-то натуральное число.
А P — это число от одного до бесконечности.
Что это такое? Это обычное пространство Rm,
но с несколько нестандартно определённой метрикой.
То есть, не с невкредевой, как вы, наверное, обычно привыкли, а с метрикой KLP.
То есть, расстояние между точками X и Y — это корень по этой степени суммы,
по этой степени разности координат.
Ну вот, например, если P равно 2, то это обычное липидовое метрико,
обычное пространство, которым вы привыкли.
Вот. Теперь у нас есть какое-то ещё m — конечное множество точек.
Что можно определить, имея эти две сущности?
Можно определить хроматическое число, пространство R, P, N,
с запрещённым одноцветным m.
Что это такое?
Это минимальное количество цветов,
которые можно покрасить наше пространство R, P, N так,
что ни одна копия m не оказалась бы полностью одноцветной.
Ну, что такое копия?
Копия имеется в виду в метрическом смысле.
То есть, у вас вот m — это какое-то конечное множество точек,
и между любыми двумя из них вы умеете там мерить расстояние.
Ну, и между какими-то точками вот вашего пространства R, P, N
вы тоже умеете мерить расстояние.
Соответственно, вы говорите, что вот множество точек в R, P, N — это копия m,
если там между ними есть биекция, которая сохраняет все расстояния.
Вот. И вы хотите, чтобы каждая копия накрывала хотя бы два цвета,
и количество цветов было бы как можно меньше.
Вот. Тут еще...
Ну ладно, давайте, конечно, что-то дальше определять.
Обратимся к примеру.
Давайте, вот у нас P равно P N.
В этом случае вы, наверное, знаете
как бы обычное определение хоматического числа мерного пространства.
Вот. В этих терминах эта величина равна
P от R2N и пары точек в единичном расстоянии.
То есть, это как бы минимальное число цветов, которые мы хотим...
в котором мы хотим раскрывать пространство RN так, что
никакая копия вот этой вот штучки,
то есть, никакая пара точек в единичном расстоянии,
которая была там минутой повернута,
не была окрашена полностью в один цвет.
Даже для плоскости неизвестна,
чему равна эта величина,
а когда на страницах бесконечности
известны только относительно далекие друг от друга синтетические оценки.
То есть, сверху мы знаем, что это превосходит 3 в N,
а снизу мы знаем, что это не меньше, чем 1, 2, 3, 9.
Это не N, это, кстати, нижняя оценка
журнитара на Деймкалче Ригеровского.
Вот. То есть, так или иначе,
эта величина страницы бесконечности
с ростом N, более того, это будет потенциально,
но точное основание экспонента мы не знаем.
И теперь, имея эту мотивацию,
я дам еще определение.
Я скажу, что M промсеевская,
и, соответственно, M экспоненциально
промсеевская,
тогда и только тогда, когда
величина Хи от РПН
M стремится
в бесконечность с ростом N,
либо экспоненциально быстро
стремится в бесконечность.
То есть, тут какая-то константа,
большая единица такая, что вот это вот Хи
от РПН M
больше или бы равно, чем
С. Замечательно.
Вот мы, например, видели с вами, что
пара точек — это экспоненциально
ромсейтское множество.
В любом случае, про довольно маленький
класс множеств мы знаем, каковы они.
И, например, мы видим, что
мы знаем, каковы они ромсейтские,
они экспоненциально ромсейтские или не ромсейтские.
Ну вот, например, мы знаем, что
любой симплекс
экспоненциально
ромсейтский.
И для каких-то конкретных симплексов
у нас есть даже какие-то конкретные
нижние оценки, как бы устроена эта величина
и оценить бесконечность. Например, вот
для правильного трюгольника
до недавнего времени лучшая оценка
была у Наслюнда.
Было известно, что это хотя бы 1.0.140
венный. Но мне кажется, что
мы недавно со авторами могли показать, что это
лучше 1.0.750 венный, правда, еще
не опубликовали.
Ну ладно. А вот если
у вас, например, есть не правильный
симплекс, а тупоугольный трюгольник,
точнее, не правильный трюгольник, а тупоугольный трюгольник,
то никто пока не занимался вопросом о том,
каковы тут могут быть нижние оценки, которые
может получиться. Первая проблема
была найти
C больше 1. Такое, что
хроматическое число R2n
с тупоугольным трюгольником
больше либо равно, чем CVn.
Ну, наверное, это C как-то будет зависеть от трюгольника,
от того, насколько тупой это тупой угол,
но что-то можно сделать. Это, в общем-то, не очень
идейно сложная задача, а она скорее сложная технически.
Нужно разобраться с несколькими
довольно объемными теоремами,
чтобы к ней приступить.
Так, ну что тут еще можно сказать?
Еще можно сказать, что
вместо какого-нибудь симплекса
конечной размерности, например, вот,
двумерного симплекса, то есть правильного трюгольника, или там
трехмерного симплекса, правильного тетрайдера, можно
решить величину, например, когда вы в нерном
пространстве запрещаете одноцветность
нерного симплекса.
Такого прям полноразмерного, изм. одной точки
стоящего. В общем,
тут этим вопросом мало кто занимался
до этого, мне кажется, что никто.
И самый естественный вопрос,
который тут можно задать, но который, тем не менее,
ответ, по-моему, не очень очевиден,
по крайней мере, мне, это стремится или
это величина бесконечности
с роста m? Непонятно.
Так, хорошо.
Давайте теперь перейдем к случаю
общему, когда
p не равно 2, а
p от одного до бесконечности.
Ну, на самом деле,
это такие довольно не очень
понятные как устроенные пространства, rpn в общем
случае, поэтому мы будем
не для многих
запрещенных множеств выключать вот эту вот
величину, потому что если не
пространство непонятно, как устроено, и множество
сложное, то маловероятно, что
может быть какого-то результата.
Так что будем пытаться
только для таких максимально простых.
Максимально простое, на мой взгляд, это
арифметическая прогрессия, то есть
пусть у нас вот bk
это множество из
k плюс одной точки,
0, 1 и так далее k.
В дисклинном случае, например, известно, что
хроматическое число
х от r2n
b2
не превосходит 4, то есть
сравните, когда вы запрещаете
пару точек в увеличенном расстоянии, у вас
эта величина стремитель бесконечности экскрементально
быстро, а если вы, например, запрещаете
три точки, вот такие,
то у вас уже не то, что нет экскрементально
быстрого стремления бесконечности, у вас вообще нет
стремления бесконечности, эта штука ограничена
всех у четвертых.
Ну и как бы кажется,
что примерно аналогично,
аналогичное поведение должно быть и при других
методах QN, но это не удается показать.
Не очень просто.
Мы вот, например, знаем,
что хроматическое число
r
n4
b4 не превосходит
16.
Соответственно, раз для b4, вот это хром число
не принято бесконечности, то и там для
5, 6 и так далее уж тем более, потому что
избавиться от одноцветных длинных прогрессий
намного проще, чем избавиться от одноцветных коротких.
Но, тем не менее, мы не знаем,
что происходит, если вот тут вот оставить
b4, а тут, например,
рассмотреться b3 или b2.
Следующая проблема
это стремится ли в бесконечности
эти две величины?
Ну и наконец,
если у нас тут, например,
будет f равно не 4, а 3,
казалось бы, тоже должно быть не очень сложно,
мы вообще не умеем понимать, правда ли,
что хоть для какого-то х эта величина
не стремится в бесконечность. То есть как бы интуиция
тут подсказывает, что уже для х равного 2 это должно быть
верно, но не получается доказать ни для какого
пока что.
Такое, что
h4n пока
не стремится в бесконечность.
Внечательно. Давайте переходим
к последней группе
многочисленных результатов и проблем.
Это случай p
равная бесконечность. Это такой отдельно
сложный случай. В нём как бы на первый взгляд
всё намного проще, но на самом деле своих сложных
вопросов тоже хватает,
по случаю Чебушовской метрики.
Что про этот случай известно?
Известно, что на самом деле
любое m является
конечно
любое конечное.
Экспоненциально
французский.
То есть как бы какой вы сложенный запрет на вести
вам всё равно, чтобы все такие конфигурации
запрещенные сделать не монохроматическими,
понадобится конечный цветов, которые будут
экстремициально расти с ростом m.
Но как именно оно будет расти, более подробно
всяких характеров этого роста, это
зачастую не очень просто.
Например, вот для множеств bk с предыдущего сфальта
мы знаем, что
хроматическое число r
и бесконечность n в k
оно с одной стороны не меньше, чем
k плюс 1 на k в степени n,
а с другой стороны не больше, чем
lnk умножить на m умножить на
k плюс 1 на k в степени n.
То есть грубо говоря, мы всё знаем про эту величину,
мы знаем, что она стремится к бесконечности
экспоненциально при каждом фиксированном k
но, тем не менее, между верхней и нижней
оценкой есть хоть и
субэкспоненциальный, но всё равно дозор,
этот дозор под людьми m и
естественно, задаться вопросом
уменьшить
этот дозор.
Далее.
Далее.
Ну, ещё, например,
мы довольно неплохо себе представляем,
как ведёт себя основание вот это вот
экспоненты, когда у вас тут
не bk запрещено, а вот
такой вот мугольничек запрещён
со сторонами 1 и 2.
Мы знаем, что оно не превосходит 2-веный,
ну, вроде можно там даже 2-веный и 1-веный,
и не меньше, чем
чем 2-веный
соответственно, та же самая ситуация.
Основание экспоненты
известно, но, тем не менее, хотелось бы уменьшить
этот дозор.
В некоторых случаях мы даже не знаем
точное основание экспонента.
Вот, например,
про хроматическое число r
бесконечность n
с запрещенным вот таким вот
треугольником,
у которого стороны равны 2, 3
и 4,
есть оценка 1,75-веный,
а снизу есть оценка 1,5-веный.
То есть вы видите, что тут
дозор как бы не пыленомерный, как бы он был до этого,
он аж экспон.
И хотелось бы найти
точное основание.
Хорошо.
Что еще?
Еще можно изучать случаи, когда у нас
запрещенное множество бесконечное.
Вот, например,
если у вас m
было бесконечным,
то в епидовой метрике вы знаете,
что хроматическое число r
rn2 запрещенным m,
оно всегда не больше 2.
То есть вы можете раскрасить всего лишь два цвета,
так чтобы любому заранее заданному бесконечному множеству
запретить одноцветным.
Если метрика едет к лидово.
А вот если метрика у вас не лидово-очебышовская,
то ничего лучше,
чем n плюс 1 вы не сделаете.
Можно доказать n плюс 1,
но в то же время для
геометрических прогрессий,
так называемых вот таких вот множеств,
вот у вас расстояние 1,
вот у вас расстояние q,
вот у вас расстояние q квадрат и так далее,
давай всю эту штуку бесконечную, конечно,
ну как бы у нее конечная длина,
она стоит без бесконечных числа точек,
назовем вот эту вот штуку g от q,
и тогда известно, что
у любого n существует q такое,
что автоматическое число
rn бесконечность g от q,
прочность равно n плюс 1.
Ну и такой вопрос вот можно ставить.
Сколько у нас там проблем дает?
7, 8.
Найти
зависимость
q под n.
Ну то есть в идеале хотелось бы показать на самом деле, что нет никакой зависимости,
что можно тут взять, возможно,
ну я не знаю, мне так кажется, может это и не правда,
какое-нибудь довольно маленькое q,
например, равно 1 и 2,
и будет, что вот для любого n,
вот этот автоматический число или q равно 1 и 2,
ну как бы непонятно, правда, это или нет,
доказать пока не получается.
Пока тут зависимость довольно сладенькая.
Для данного n нужно брать примерно 1 на 2 bq,
на самом деле можно там постараться и сделать лучше,
пока еще никто не старался.
И наконец финальная проблема, это можно
изучить
ситуацию
с другими
бесконечными
множествами.
Пока мы занимались только вот такими
диаметрическими прогрессиями,
а можно же
множество, у которых, скажем,
две предельные точки.
Например, у вас есть вот такая диаметрическая прогрессия,
но она растет в обе стороны,
для такого множества, что происходит.
Или, допустим, у вас есть
какая-то вот прогрессия такая,
она вот тут почему-то растет,
и с другой стороны к этой же самой точке
растет еще одна такая прогрессия.
Вот, это предельная точка,
предельная для обоих прогрессий.
Для таких множеств, что может там
автоматическое число быть не равно 2,
а быть равным чему-то большему.
Что-то, мне кажется, что не факт.
Надо посмотреть. Возможно,
такими запретами можно всегда покрасить два цвета.
В общем, много тут есть всяких естественных
бесконечных множеств, таких довольно простеньких,
похожих на диаметрические прогрессии, которые еще не кончено делали,
и не знают, что там происходит.
Так, ну, наверное, это все. Это все проблемы,
которые мы будем сегодня рассказать.
Может, у кого-то есть какие-то вопросы?
Извините, а может быть, вы говорили,
а вот какое вот применение вот таких ценок?
Нет, никакого. Чисто теоретический вопрос.
А, прикол как бы. Ну, ладно, понятно. Спасибо.
Ну, как и...
И даже больше.
Так, ну, если больше вопросов нет,
Константин Юрьевич, я, наверное, закончил.
Василий Олегович?
Да, я здесь, но тут нет возможности включить камеру.
Я не знаю, в чем дело.
Я попрошу тогда Константину Юрьевича продемонстрировать.
Ну, вот камера не работает.
Я попробую, конечно, ее включить.
Но тогда, я думаю, правильнее просто запустить мою запись
в предзаписанное...
предзаписанное наступление.
Оно...
предзаписанное наступление.
Оно было опубликовано на Яндекс.Диске.
И давайте сейчас запишем.
Давайте сейчас мой голос слышим,
а запись включим оттуда.
Коль скоро нет возможности включить видео.
Так, давайте посмотрим.
Вот Яндекс.Диск. Сейчас я вам пришлю ссылку, пожалуйста.
А, может быть, я включу экран. Одну секундочку.
Аппарат с экрана, я надеюсь, можно? Вот так.
Видно ли теперь мой экран?
Коллеги?
Да, ваше право.
Прекрасно. Вот тогда я здесь.
Я готов на все вопросы отвечать.
Пожалуйста, вот мое предзаписанное видео.
Дорогие коллеги, я сегодня хочу поговорить
о кабардизмах рук и картинках.
Я хочу рассказать о том, что очень часто
инверианты со значениями в свободных группах
или со значениями в картинках
играют очень важную роль
в топологии, в алгебре
и во многих других науке.
Что я имею в виду
под инвериантами со значениями в свободных группах
и под инвериантами со значениями в картинках?
Давайте рассмотрим самый простой пример.
это свободную группу, скажем, с несколькими образующими.
Простите, меня слышно?
В этой свободной группе мы можем
рассмотреть образующие А1 и так далее АМ
без соотношений. То есть все соотношения, которые есть,
это фактически соотношения, что мы можем зачеркивать
рядом стоящие образующую и обратную к ней.
То есть АИ на АИ в минус первое объединиться.
Давайте мы для таких групп осмотрим следующее.
Пусть у нас имеется какое-то формальное слово.
Пусть скажем А1, А2, А3 и так далее.
А2, А2 в минус первой, А1, А3 в кубе.
Ну не знаю, А1
в минус первой, А1, А3 и так далее.
Вот это слово и видим. Ага, вот здесь у нас есть А2, А2 в минус первой.
Это можно сократить и получить какое-то слово.
Допустим, как на месте А1, мы получим какое-то слово
А1, А2, А3, А1. Здесь мы сократили А3.
Извините, А1, А3 в кубе.
А1 в минус первой, А1, А3 и так далее.
Вот, но с другой стороны мы можем сократить слово здесь.
И получить что-нибудь такого вида.
А1, А3 в кубе и так далее, А3.
Вот, мы получаем два слова. Мы можем сокращать дальше.
Например, вот здесь мы можем найти слово А1
в минус первой, А1, а здесь мы можем найти слово
А2, А2 в минус первой. Ну и в общем понятно, здесь более-менее
очевидно, что если мы сократим в первом слове
А1 в минус первой, А1, а во втором А2, А2 в минус первой,
то в итоге мы перейдем к этому слову.
И на самом деле, вот этот локальный объект, он имеет
место также и глобальных. То есть мы можем взять произвольное слово,
не приведенное, не редуцированное.
В этом слове мы можем делать такие простейшие сокращения.
И вот легкое упражнение, проверьте его сами,
что минимальный представитель, редуцированное слово,
отличающее данному элементу группы,
оно как раз единственно и представляет собой,
ну так сказать, инвариант данного элемента свободной группы.
На самом деле, благодаря этому, легко решается проблема слов
в свободной группе и легко решается проблема сопряженности
в свободной группе.
И можно еще сказать так, что вот если у нас есть два слова
в свободной группе, и они эквивалентны,
у и в, то тогда для того, чтобы проверить их эквивалентность,
достаточно просто спуститься до минимального представителя
и проверить одинаковую эту представитель,
или они различаются.
И то же самое для проблемы сопряженности,
только там надо рассматривать не обычные слова,
а так сказать, слова сопряженности.
Хорошо. Вопрос, а верно ли это произвольной группе?
В произвольной группе. А это, конечно, нет,
потому что уже давно известно, что в произвольной, конечно, поразенной группе
нет алгоритмического решения ни проблемы слов,
ни проблемы сопряженности и так далее.
А вот, допустим, нам хочется приблизительно таким образом
решать какие-то другие проблемы в алгетической топологии.
Другой ответ. Давайте рассмотрим кривые на двумя поверхностях.
Вот такой поверхность рисуемый, вот есть такие кривые.
На самом деле можно для такой кривой пытаться
изменять в гонотопической группе формально,
с точки зрения топологии, ведь идет о классах сопряженности
на поверхности с ручками. То есть вот можно рассмотреть
фундаментальную группу поверхностей с ручками,
и можно задать вопрос о проблеме сопряженности.
Тут дело такое. Можно, конечно, эту группу записывать буквой.
Но на самом деле для таких кривых, для классов гонотопских кривых
или для классов сопряженности элементов в такой группе
правильнее рассматривать не слова от букв,
а правильнее рассматривать вот такие диаграммы с точки.
И для диаграмм с точки тоже есть некоторые простеньшие сокращения.
А именно, если мы где-то видим двухугольник, вот такой,
то его можно сократить, убрав вот такую, вот эти две вершины.
Или если мы где-то видим пятерку, можно ее сократить вот таким образом.
Возникает вопрос, если мы так сокращаем, будет ли минимальный присалитель единственный?
Ответ – нет, потому что на самом деле правильные сокращения
это некоторые гораздо более общие преобразования,
которые тоже можно пощупать руками, а именно нужно рассматривать не просто
двухугольники пустые, а можно рассматривать двухугольники,
внутри которых есть какая-то такая плоская часть.
Вот это двухугольник, его внутренность, она лежит на плоскости.
И тоже самое для пяти.
И в этом случае мы можем провести такое глобальное движение,
вот здесь мы разводим вот так, а здесь мы разводим как-то так.
На самом деле тут мы забыли упомянуть про еще одно движение,
которое называется в теории углов 30 движением Рейдемайстера,
который состоит в следующем.
А вот если у нас есть какой-то треугольник,
то можно это преобразование, можно объявить вот такое преобразование.
Вот есть два, две линии, у них здесь какой-то перекресток,
есть третья линия. Можно эту третью линию как бы провести через перекресток.
Вот это третье движение Рейдемайстера, оно играет ключевую
и важнейшую роль в теории углов.
Но заметьте, если вот те преобразования, которые я изобразил выше,
а именно первое движение с удалением петельки и второе движение с удалением перекрестка,
они, так сказать, из меня уменьшают сложность, то есть уменьшают количество перекрестков,
то это преобразование не меняет сложности.
И на самом деле, если мы хотим решать какие-то проблемы,
проблемы дождевства, проблемы сопряженности или вообще какие угодно там секционные проблемы,
то для нас важно, когда мы сравниваем, допустим, две диаграммы,
у одной из которых N-перекрестки, а у другой N-перекрестки,
то для нас важно, можем ли мы от диаграммы с N-перекрестками
дойти до диаграммы с N-перекрестками, не сильно увеличивая количество перекрестков.
Это очень важная задача. Вот давайте так я зарисую.
И вопрос такой, можем ли мы пройти от одной диаграммы к другой,
не увеличивая количество перекрестков.
А если бы это всегда можно было сделать, то был бы такой ответ.
Так что все это все проблемы алгоритмически разрешим.
Если говорить абсолютно грубо и только с формальной точки зрения решения проблем,
мы можем сказать, давайте переберем все диаграммы с меньшим количеством перекрестков
и посмотрим, можем ли мы как-то двигаться вот здесь.
И на самом деле, если рассматривать движения не только уменьшающие,
но и такие, которые не меняют сложности, то тогда все наши проблемы эквивалентности
будут разрешены почти.
Здесь мы не доказали одну теорему, а именно мы не доказали теорему
о единственности минимального представителя.
Поскольку есть такое движение, ну например, мы рассматриваем диаграммы
в поверхности с ручками, то когда это движение есть, то минимальный представитель
не совсем единственный, на что мы можем надеяться,
это то, что он будет единственным в свойстве до таких движений.
Вот я хочу сказать, что это почти верно, а именно это может быть неверно
только в случае зацепления с кратными компонентами.
Ну грубо говоря, если мы живем на торе, то можно нарисовать одну картинку,
где мы проходим, например, по вот такому меридиану три раза,
а здесь мы проходим по меридиану, скажем, два раза,
и можно эту диаграмму перетащить в диаграмму, где мы здесь проходим два раза.
Коллеги, как я понял, этот кусок картинки не виден сразу,
я тут имел в виду следующее.
Предположим, что у нас есть тор, который склеивается из квадрата, вот так,
и мы можем нарисовать, скажем, картинку вот такую,
а в одном месте мы идем, например, так, а в другом месте мы идем, например, так.
Теперь вопрос такой, вот, допустим, вот есть вот эта кривая,
и мы ее можем протащить сквозь вот эту кривую.
Ну как протащить? Это значит, что сначала сделать второе движение Рэдемайстера,
тут возникнут какие-то перекрестки, вот, например, здесь,
и возникнет большее число пересечений, потом мы дальше тянем вот сюда-сюда,
здесь возникает все больше и больше пересечений,
и уже потом мы сможем протягивать туда дальше.
То есть получается так, что можно нарисовать две диаграммы,
у которых одно и то же количество пересечений,
но чтобы перейти от одной к другой, нам нужно количество пересечений увеличить.
То есть тут на самом деле минимальный представитель не единственный,
но это скорее так исключение из правил, то есть здесь почти всегда единственный
с точностью до вот таких вот примеров.
Итак, давайте продолжим.
Здесь проходим три ратора, то есть как бы одну через другую,
одну несвязанную компоненту, одну связанную компоненту, извините,
мне не нужна окошко, вот это я имел, одну связанную компоненту
и с тремя перекрестками можно перевести в другую связанную компоненту
с двумя перекрестками, ну для этого придется, когда мы протаскиваем,
здесь создавать какие-то увеличивающие движения, ну что-то такого рода.
Вот была какая-то картинка, другая картинка, и чтобы одну протащить
сквозь другую, нам понадобится, нам понадобится здесь делать
увеличивающие движения рейдомассы.
То есть помодули некоторые мелочи, здесь тоже разрешима проблема тождества,
проблема сопряженности.
Далее меня интересует следующее.
Вот есть такая общая лемма, очень простая, очень легко доказывающаяся.
Лемма одиамальти, даймонд-лемма, она выглядит следующим образом.
Вот, допустим, мы хотим уменьшающими движениями достичь
некоторого единственного представителя, единственного минимального представителя,
ну как, например, в группах, свободных группах, вот в таких диаграммах,
с картинками и так далее.
То есть у нас есть какая-то картинка или какое-то слово,
или какой-то представитель элемента, который мы рассматриваем
как класс эквивалентности.
Ну, например, слово в группе задает элемент в группе, но не однозначно.
Мы хотим, так сказать, спускаться, спускаться, спускаться,
и вот таким методом градиентного спуска свести все дело к единственному минимальному представителю.
На самом деле есть даймонд-лемма, которая говорит о следующем.
Если вот в таких цепочках спуска цепочки не могут быть бесконечной длины,
и кроме того, кроме того, если выполняются следующие условия, замечательные условия,
условия ромба или диаманта, то тогда минимально представитель будет единственным,
я могу сказать так, единственным в каждой связанной компанице.
Если группу говоря, у нас есть какие-то, ну, можно на примере группы сказать,
что, допустим, у нас есть разные элементы группы,
каждый из них имеет свои слова, ну и понятное дело, что, понятное дело,
что если элементы не равны, то они будут в каждом представителе.
Так что вот здесь, допустим, имеется одно слово, один элемент группы, здесь другой элемент группы,
и если они не равны, то у них минимально представители будут различны.
Так вот, значит, в чем состоит условие диаманта?
Оно состоит в том, что если у нас есть какой-то элемент А,
и мы его упростим до элемента В и до элемента С, то тогда, вот одним шагом,
то тогда у этих В и С обязательно найдутся какие-то упрощения, может быть, не одношаговые,
которые сводят все к некоторому одному и тому же элементу Д.
Я не говорю, что это единственное, но если это выполняется, если нет бесконечных спусков,
то тогда все будет идти.
И тогда все проблемы будут решаться минимальным градиентным спуском.
И я хочу сказать, что это позволяет и решать многие проблемы в теории групп,
и решать многие проблемы в топологии,
и в частности, например, проблема минимизации кривых надуверных поверхностей
с точностью до минимизации по количеству перекрестков,
эта проблема эквивалентна в каком-то смысле.
То есть она очень близко стоит с проблемой минимизации длины.
То есть мы пытаемся рассмотреть кривую, и мы можем, так сказать,
с помощью градиентного спуска, вот здесь уже непрерывного градиентного спуска,
а не дискретного, пытаться уменьшить длину этой кривой.
И пытаясь уменьшить длину этой кривой, мы с одной стороны уменьшаем длину,
а с другой стороны, при таком процессе не может возникнуть увеличение числа перекрестков.
И на самом деле эта вещь связана с работами Камильтона и связана с потоками Риги.
Та поводи, наверное, знают, что именно с помощью потоков Риги
была решена Камильтона и, в конце, Перельманом,
трехмерная гипотеза планкара.
О том, что грубо говоря, мы пытаемся взять серу,
взять некоторое многообразие, и если у нее нет каких-то препятствий,
ну там, гонтактический груб, то ее можно в каком-то смысле округлять,
округлять и сделать грубо.
Вот это округление, это минимизация чего-то.
Но можно пытаться в более простой задаче минимизировать длину.
И вот этот ингредиентный спуск тесно связан с леммой абиамантией.
А теперь я хочу поговорить о картинках.
Это то, чем мы занимаемся в последние несколько лет.
У нас есть семинары на эту тему.
Идея состоит следующая.
Представим себе, что у нас есть какая-то картинка,
ну, например, диаграмма УВА на какой-то поверхность.
Я не буду рисовать картинку в общем случае с двальными перекрестками,
я ее нарисую условно, вот так.
Допустим, эта картинка является локально минимальной.
Что значит локально минимальная?
Это значит, что к ней нельзя применить одно уменьшающее движение.
То есть, например, если у диаграммы есть такой двуугольник,
то эта диаграмма не локально минимальная.
Как и неприведенное слово в свободной группе.
Вот у этого двуугольника мы можем делать вот такое преобразование.
И вот я хочу сказать, что в примере второго флора
локальная минимальность летит глобально минимально.
Мы такое уже видели в свободных группах.
И мы такое уже видели для кривых на немерных поверхностях.
Из локальной минимальности следует глобальная минимальность.
Так вот, на самом деле, тут есть очень два разных момента принципиально разных.
Один момент – это то, что мы можем строить алгоритм распознавания.
То есть у нас есть объекты, диаграммы, картинки и так далее с точностью движения.
Движения преобразований, каких-то изотопий, демотопий.
Одно дело – у нас есть алгоритм.
Ну, грубо говоря, мы сводим все к минимальной диаграмме и сравниваем все.
А другое дело – у нас есть инвариант.
Может быть, полный, может быть, неполный, который говорит,
вот у нас есть минимальная…
Вот у нас есть диаграммы, мы их что-то сопоставляем.
То есть алгоритм, в случае групп, например, это некоторое сокращение a в минус 1, b в минус 1, b и так далее.
Вот это алгоритм, он приводит к минимальному представителю.
А инвариант – это группа, которая, когда мы говорим, ага, вот у нас есть такое слово,
мы в нем все посекращали, скажем, было zc-1, мы посекращали все, насколько можно.
И вот это минимальное слово, оно уже является единственным минимальным представителем, так сказать, инварианта.
А вот на самом деле я не люблю большие формулы.
Но я хочу сказать, что для таких картинок и для теории узлов,
для многих задач теории узлов можно найти вот такие инварианты.
Можно найти инварианты, для которых верна вот такая замечательная формула.
Скопка ака равно ка. Что это значит?
Это значит, что я беру некоторые диаграммы нашего объекта.
Ну, узла, кривойной поверхности и так далее.
И каким-то другим способом их суммирую. Сейчас я покажу каким.
И когда я суммирую, то инвариант оказывается, мы получаем инвариант.
Что это значит? Это значит, что вот здесь я беру ка как одну диаграмму,
которая представляет элемент класса сопряженности.
Ой, извиняюсь, которая представляет элемент своего класса эквивалентности.
А здесь ка. Это просто диаграмма ка с концентром 1.
Будет что-то не быть голословным. Давайте я напишу формулу.
Все это можно посмотреть в наших более общих докладах, в статьях и так далее.
Значит, давайте рассмотрим такую диаграмму.
Допустим, здесь она локально минимальная, то есть ее за один шаг уменьшить нельзя.
Но ее за один шаг можно увеличить.
Например, можно здесь сделать вот такой вот шаг, где добавится планолог перекрестка.
И на этой диаграмме, где есть два лишних перекрестка, мы можем рассматривать все так называемые разведения.
Это часто используется в теории узлов. Разведения вот такие.
Вот есть два перекрестка, и каждый перекресток можно разводить либо так, либо так.
И дальше суммируем по разведению.
И тогда, значит, если мы эти два перекрестка разведем двумя способами, то у нас получится вот такое вот разведение.
Вот такое разведение, вот такое разведение, вот такое разведение, и вот такое разведение.
Если мы очень ленивые и хотим все рассмотреть над z2 и считать, что плюс единица и то же самое, что минус единица,
то мы можем сказать, что вот эти две картинки одинаковые, мы их сокращаем.
А вот эта картинка, она, ну, в конце концов, это просто та картинка, которая была дорогостью.
А дальше мы говорим, что если у картинки важны два лишних компонента, вот пись, то мы эту диаграмму просто не учим.
То есть, получается, некоторая сумма, где мы берем коэффициенты z2, все довольно просто.
И что в итоге получается?
В итоге получается, что сумма, которая получается для этой диаграммы, в принципе, равна сумме, которая получается для этой диаграммы,
ну, так сказать, в каком-то формальном модуле над z.
Ну, и практически получается вот такая замечательная форма.
То есть, смотрите, то, что слева, это как бы динамический объект плацэквивалентности диаграмм по движению,
а то, что справа, это одна единственная диаграмма.
То есть, получается, что каждый вопрос по классах эквивалентности можно отыковать с помощью рассмотрения одной единственной диаграммы.
Например, пусть диаграмма k' эквивалентна диаграмме k.
Тогда из того, что эта скобка является вариантом, мы получаем, что скобка от k' эквивалентна скобке от k.
А если мы знаем, что k в каком-то хорошем смысле минимально, и скобка от k равна k,
тогда означает, что скобка от k' равна k.
А это означает, что внутри диаграммы k' сидит диаграмма k.
Что это значит? Это значит, что мы сделали вот такую диаграмму узла.
И для такой диаграммы узла мы сделали простенькое движение, извините, простенькое движение вот такое.
И тогда по построению нашей скобки, скобка строится под следствием каких-то упрощений.
Мы можем сказать, вот здесь возникли два перекрёстка.
Вот тогда какое-то из разведений, а именно вот такое, да этих двух перекрёсток,
ну здесь мы сделали какое-то фотоувеличение, вот эта диаграмма, она будет просто совпадать с нашей диаграммой k.
Не правда ли красиво? То есть мы вот смотрим на такого арахата с хвостком и говорим, что чтобы мы с ним не делали,
обязательно внутри вот этой новой диаграммы мы старую увидим.
То есть наш вариант это будет не просто какое-то число там или многочлены или что-то ещё,
а это будет очень такой явный вариант, который говорит, что внутри любой диаграммы это минимально сидит.
Ну как в свободных группах?
Итак, у меня остается очень мало времени, я хочу сказать пару слов по поводу кабардизма.
Кабардизма – это вот такие объекты. У нас здесь может быть некоторое многообразие M, есть некоторое многообразие N.
И возникает вопрос, а можем ли мы от этого многообразия M к многообразию M пойти, затягивать это дело в плёнку?
На самом деле вопрос о том, существует ли кабардизм между чем-то и чем-то,
это вопрос, который занимал центральное место в топологии XX века.
Ну и теорема Смейла об аж кабардизме, которая решила все проблемы у Анкаре в старших размерностях.
И теорема Фридмана, которая решила всё в размерности 4, но правда негладко.
И многие другие замечательные теоремы, они именно связаны с кабардизмом.
Но на самом деле, когда мы строим кабардизм, можно приблизительно посмотреть на ситуацию с таким опытом.
Можно попытаться в этих многообразиях M найти какие-то перекрёстки.
Не важно перекрёстки, чего, может быть, это причине в домологиях, может быть, что это что-то ещё.
И в каком-то смысле нам надо попытаться устроить такое соответствие.
То есть перекрёстки мы соединяем, и каждый перекрёсток либо сокращается с чем-то, что было внизу, либо соединяется с чем-то, что было вверху.
Вот такие вот картики.
Многие препятствия в кабардизмах, они, грубо говоря, считают перекрёстки с какими-то знаками, может быть, ещё.
И говорят, что можно что-то сверху соединить с чем-то, что с ним.
Если соединить нельзя, то тогда кабардизма нет.
Так вот, подход, который предлагаем мысль, состоит из предыдущих следов.
Мы рассматриваем кабардизм.
Мы хотим сформулировать вот такую теорию.
Во многих случаях, если есть кабардизм, то есть если что-то, можно затянуть плёнкой.
Может быть, между двумя разными объектами, двумя разными углами, или можно затянуть плёнкой между, так сказать, углом и высоким множеством.
То есть просто затянуть вот такой плёнкой.
Если есть кабардизм, то есть элементарные кабардики.
Что это значит?
Самый простейший пример, который здесь может быть...
Ну, конечно, пример трёхусловия.
Надо их будет уточнить, но на это времени нет.
Самый простейший пример, можно понимать так.
Вот у нас есть кривая, сам пересечение.
И мы хотим эту кривую затянуть диском трёхмерным пространством.
А даже не для этого трёхмерного процесса, а просто формальным комплексом, который, вот так сказать, представляет собой диск с особенностью.
Вот есть одна теория, что при некоторых условиях, если существует вот такой диск, то существует диск почти без особенности, то есть диск, у которого нет внутри тройных точек самопересечения.
Если смотреть диск с особенностью необщего положения в трёхмерном пространстве, в каком-то трёхмерном многообразии, то у него могут быть двойные линии, тройные точки или так называемые клювы, касты.
Но теория, которая у нас есть и которая работает во многих случаях, говорит следующее, что если мы можем затянуть кривую диском, то её можно затянуть диском без тройных точек и без кастов.
То есть фактически можно сказать, что на этом диске все особенности будут представлять собой двойные линии.
То есть, допустим, надо будет как бы спарить вот эту точку с вот этой, спарить какую-то другую точку с ещё одной, то есть фактически вопрос сложный топологический сводится к простому вопросу перебора.
Какую точку с какой другой точкой можно спарить? И на самом деле это походами куча приложений в разных задачах топологии, и в алгебе, и в других науках.
Вот, пожалуйста, несколько ссылок на наши статьи. И, кроме того, я приглашаю всех, посмотрев наши курсы, вот несколько первых лекций записанных.
Один курс «Теория возглоб» и другой курс «Теория четырёхмерных многообразий». И, кроме того, в весеннем весне мы будем читать курс оба варианта какодинка, который в точности посвящён вот этому.
А этот курс в языке русский, английский, то, что было в прошлом году, мы записывали. И всё это имеется на наших занятиях. Спасибо.
Мне кажется, что теперь я виден живьём. А, значит, по поводу ссылок, пишите мне, я все ссылки пришлю. Пожалуйста, ваши вопросы.
Видно ли меня и слышно ли меня?
Да, вас видно и слышно.
Да, ну, я готов, вот у нас есть парочка минут, сказать какие-нибудь слова по поводу какой-нибудь из этого.
Так, ну, если вопросов нет, то, наверное, это всё на сегодня. Значит, у нас есть некоторые расписания самых разных мероприятий.
Вот у нас есть семинары по понедельникам и по средам.
Значит, официально, топологически, но реально там бывают докладанные любые темы. В частности, понедельник у нас выступает Сергей Константинович Ландо.
Там и графы, и раскраски, и вытка, что угодно.
И вот, по-втореньку, я считаю, что это всё на сегодня.
Хорошо, коллега, спасибо за внимание.
Спасибо.
Здравствуйте, Борис Исакович, вы можете начинать?
Добрый вечер. Спасибо.
Скажите, мой экран выкинул?
Да, вас видно, слышно, всё хорошо.
Спасибо.
Ну, я сразу хочу сказать, что я все темы решил не рассказывать.
Извиняюсь.
Выбрал такую одну большую тему.
Она относится к прерываемым расписаниям на одной машине.
Это такая задача, в которой прогресса почти нет с точки зрения нахождения точного решения.
Для задач, скажем, больше там, чем с 20 работами.
В реальных ситуациях бывает и 100, и больше работ.
Давайте я попробую начать с постановки задачи.
Значит, мы рассмотрим сейчас пример.
Такой небольшой.
Вот рассмотрим три работы, которые нужно выполнить на одной машине.
Вот в этой табличке указаны номера работ с первой строчки.
Вот один, два, три.
Время их выполнения.
Вот процессинг тайн.
Тут оно разное.
Для первой работы это две единицы.
Для второй – три.
Для третьей опять две.
Приоритет работы или ее вес.
Соответственно, два, восемь и десять.
Момент появления работы, когда она становится доступной для выполнения.
Вот здесь они.
Для первой – первой и так далее.
Для третьей – третьей.
Release day, по-английски.
Ну и в том случае, когда мы будем рассматривать другие модели.
Например, минимизирующие суммарное взвешенное запаздывание.
Тогда еще есть due date, который не надо путать с deadline.
Due date – это то, что можно нарушать.
Но когда мы это нарушаем, за это есть штраф.
И, собственно, расписание состоит из чего?
Нужно найти такую последовательность выполнения работ
с учетом их появления, приоритетов.
Ну и, возможно, сроков завершения.
Так, чтобы, например, суммарное взвешенное время выполнения всех работ
было минимально.
Или суммарное взвешенное запаздывание было минимально.
Эту задачу вот очень легко свести,
я это все пропущу, к задаче о назначении.
Для тех, кто не знает, что такое задача о назначении,
я очень коротко расскажу.
Предположим, вот строчки соответствуют машинам,
на которых мы хотим выполнять какие-то работы.
Здесь написано совсем другое.
Просто первая строка, первая машина, вторая, вторая и так далее.
Двенадцатая, двенадцатая работа.
И мы имеем работы, которые перечислены номерами столбцов.
Вот их тоже здесь двенадцать.
И задача о назначении, она формулируется очень просто.
Нужно так назначить каждую машину точно,
я слово точно подчеркиваю, на одну работу,
и каждую работу точно на одну машину,
так чтобы суммарное время выполнения всех работ,
а это вот время.
Понятно, там где стоит бесконечность,
значит нельзя назначать эту машину на эту работу.
Было минимально.
Здесь цифры такие странные, очень много бесконечности.
Это связано с той задачей, которую я сейчас расскажу.
Вот я только сейчас рассказал задачу с разными временами выполнения,
как мы говорим, arbitrary processing times.
А вот я рассмотрел пример, когда они одинаковы.
И тут же хочу показать, как просто построить эквивалентную матрицу
задачи о назначении в случае,
когда все работы имеют одинаковое время выполнения.
Здесь у меня указан горизонт планирования,
так как у нас три работы, то понятно,
больше, чем двенадцать временных интервалов нам не надо.
А здесь просто для каждой работы, для первой,
указана ее первая часть, вторая, третья, четвертая.
Точно так же для второй и для третьей.
И вот здесь сквозная нумерация,
с первой части по двенадцатую часть,
независимо от того, какая работа.
Как мы это делаем?
Мы смотрим внимательно на момент появления.
Мы видим, что первая работа появляется в первый момент.
Ее первая часть, она состоит из четырех частей.
Здесь предполагается, что мы не можем выполнять вторую часть,
пока мы не выполнили первую.
Не можем выполнять третью,
пока мы не выполнили и первую, и вторую, и так далее.
То есть такой линейный порядок.
Это все очень естественно.
Достаточно иметь в образе строительство дома.
Но никто не ставит крышу, пока не поставил фундамент.
Никто не ставит стены, опять, пока нет фундамента и так далее.
То есть есть какая-то естественная упорядоченность работ.
В этом смысле и в нашей модели мы рассматриваем работы,
которые нам надо выполнять.
Первая часть работы никаких вкладов в целевую функцию не вносит,
потому что мы рассматриваем критерии взвешенного
суммарного времени выполнения работы.
Это так называемые три поля кодирования любой задачи, расписания.
Первое поле показывает, сколько машин.
Вот у нас здесь стоит одна.
Потом вертикально отделяет первое поле от второго.
PMTN это означает, что прерывания допускаются.
Дальше сказано, что все processing time одинаковые.
Ну и что у нас есть произвольный релиз date.
Вот если там чего-то нет, значит это там все в первый момент.
А это критерии оптимальности.
Суммарная, давайте скажем, вес это, я говорил, приоритет.
Вес это время выполнения работы, по-английски completion time,
житой работы.
Так вот, completion time это тот момент времени, когда мы закончили работу.
Вот на этой картинке видно, что первую работу мы закончим
в последний момент времени, в оптимальном решении.
А вообще можем закончить когда? Самым ранним образом.
Ну когда выполнены три предыдущие части линейного порядка,
отсюда понятен смысл этих бесконечностей.
Почему здесь бесконечности?
Ну нельзя слишком поздно начинать выполнение первой части, первой работы.
Если мы начнем в десятый момент, то у нас получится, забыл по-русски,
idle interval, сейчас подумаю, пустой интервал.
Интервал, когда машина простаивает.
Это не допускается в этих расписаниях.
Ну собственно говоря, я все объяснил, то же самое со второй частью.
Понятно, что нельзя ее слишком поздно начинать, и третью.
И вот как только мы посчитали, когда в наиболее раннее время
выполнение первой работы, это вот четвертый момент при условии,
что мы выполнили все.
Ну вес тут сколько у нас единичка, значит время будет равным четырем,
вес единицы, вот мы могли бы получить вклад целевую функцию 4.
Ну и дальше, собственно говоря, что мы говорим?
Нужно так назначить, чтобы точно каждую часть работы назначить
на один временной интервал.
А вот они у нас здесь перечислены, чтобы суммарное время назначения
было бы минимально.
Ну это релаксированная задача, потому что в задаче назначения
нет вот той упорядоченности, о которой я говорил.
Значит, поэтому если мы решим задачу, нам не гарантировано,
что тот порядок, который нам нужен, будет выполнен.
И вот хорошо видно, для первой работы все в порядке, для второй тоже.
А вот для последней работы у меня тут какое-то окно всплывает.
Я надеюсь, видно сейчас.
Видите, что произошло?
Третья часть работы будет выполнена в оптимальном расписании
релаксированной задачи.
Я когда говорю релаксация, я не веду, это упрощена исходная задача.
Здесь не выполнено условие, что третья часть работы не может
выполняться последней, то есть после завершающей.
А завершающая, видите, выполняется в момент 10, а здесь в 11.
Вот, собственно говоря, это такая очень простая постановка задачи.
Что умеют делать на сегодня?
На сегодня точно умеют решать такие задачи,
ну не более там вот такие с одинаковыми, по-моему, 12 работ.
Теперь я перехожу к тому, что я ожидаю от вас и почему это все реально.
Я просто покажу какую-нибудь статью, которая опубликована
по этой теме буквально всего недавно.
Давайте я покажу название, чтобы знать, о чем она.
Это вот такая онлайн-евристика для прерываемых расписаний
на одной машине, которая минимизирует суммарное взвешенное время запаздывание.
Это вот мой бывший студент, он сейчас профессор, забыл где, в Польше где-то.
Я хочу обратить ваше внимание на время.
Статью мы подали в июне 2020 года и уже в декабре, то есть 7 месяцев она была опубликована.
Это топ-журнал, вот то, что называется Q1.
Я вам гарантирую, что если вы захотите, например, делать экспериментальную,
здесь просто описана евристика, а вот более подробный анализ.
Он сделал вот Романюк, сейчас я скажу где, вот она.
Этот журнал, я не знаю какой у него там Айчинбекс, но точно больше, чем 120.
А вот этот второй, который экспериментальный журнал, сейчас я покажу, как он называется.
Экспертная система, у него за 200. Это очень высокий рейтинг журнала.
Обычно хороший журнал имеет Q1 где-то 60-80 индекс цитирования, понимаете, 200 это очень.
Ну что здесь есть? Да ничего здесь нет, запрограммировано все.
Ну понятно, объясняется постановка задачи, показывается как это все работает, очень подробно.
Это самое главное мое требование.
Я размещаю инструкцию для тех, кто хочет писать дипломную работу вместе,
но под моим руководством, что самое главное, показать маленький пример,
где вы четко рассказываете постановку задачи, цели исследования,
потом проводите вычислительный эксперимент.
Конечно, это невозможно сделать, вот эти, видите, все эти картинки,
если вы не умеете программировать, организовать, посмотрите, что здесь делается.
То есть я думаю, что он это все очень много проводил, экспериментов.
Тем не менее, вот все это вот.
То есть это такая, я бы сказал, экспериментальная работа,
в которой вы хорошо понимаете постановку задачи.
Давайте я вернусь к другим моделям, которые возможны здесь.
В одной из статей тоже с моими студентами, сейчас я вспомню, из Низнего Нового города,
вот мы доказали для случая, когда одинаковые времена выполнения,
вот та же самая задача, о которой я сейчас говорил, вот такую оценку снизу
или вот такую, сейчас покажу, оценку сверху.
Вот лучше, конечно, смотреть вот на эту развернутую формулу.
Посмотрите, когда время выполнения у всех работ одинаково и равно 2,
то хорошо видно, что эта оценка, ну, при этом стремяемся к бесконечности,
ну, примерно половину дает от точного значения, оптимального решения,
при условии AP, это Assignment Assignment Assignment Assignment,
что мы используем вот нижнюю оценку, вот буквально то, что я рассказывал 5 минут назад.
Что нужно сделать в дипломной работе?
Нужно оценить, правда ли это, ответить на вопрос, что она всего лишь дает половину.
Я думаю, что она дает гораздо лучше в экспериментах.
С чем нужно проводить эксперименты?
У нас опубликован тестовый набор задач,
который построен студентом МФТ и Фамины.
Сейчас я тоже это покажу, где его найти и как он выглядит.
Где-то ссылка должна быть.
А вот, вот здесь это все подводно.
Вот здесь это все подробно описано, как устроен генератор, там есть точные решения всех задач.
Задачи там размером, я скажу так, произведение processing time на количество работ,
по-моему, ограничено восьмьюстами.
Ну, то есть вы можете себе представить, что если P равно 2, сколько там?
Ну, до 400 работ может находить.
Вот он находит точное решение, Фамин.
Как дела у Фамина, тоже могу сказать.
Статья находится на лицензии.
Вот сейчас мы вот отправили, он отправил вторую версию.
Статья, ну, где исправляются там замечания.
И один из лицензентов попросил больше теорий.
Почему теории?
Ну, потому что у него статья, сейчас я посмотрю о чем, о прерываемых расписаниях.
Да, он показывает, что свойство в total-dual-integrality, сейчас не соображу,
как это сказать, вполне двойственной целочисленности не выполняется,
как в гипотезе другого одного из моих студентов из Гронингена,
из Нидерландов, Баума.
И поэтому там иногда есть ошибка.
Вот он это исправил, провел тоже вычислительный эксперимент.
Ну, и я думаю, что в целом, по крайней мере, один лицензент рекомендовал статью,
а второй вот просит вот ответить на те вопросы,
как ведет себя вычислительный эксперимент в случае,
когда условие total-dual-integrality не выполняется.
Что здесь можно еще сказать по этой теме?
Ну, я думаю, что очень интересным является следующий вопрос,
насколько эффективно можно решать с произвольными временами.
И здесь как теоретический вопрос, так и экспериментальный.
Чтобы как-то развеять, что вот когда я говорю слова теоретически,
люди могут подумать, что это как-то очень сложно.
Давайте я посмотрю, у меня есть эта статья.
Вот она.
Вот дети оценки доказываются.
Вот они в основном были доказаны Павел Сухов и Михаил Бацин.
Я сейчас уже не помню, кто какую оценку.
Вот просто посмотрите, как это все просто делается.
Это все та же модель.
Вот формулировка теоремы.
То есть вот посмотрите.
Просто люди умеют преобразовывать неравенство и упрощать их.
Вот с дробями умеют хорошо работать.
Больше ничего.
То есть я что хочу сказать?
Самое главное в тех исследованиях, которые я предлагаю,
они сами по себе простые, но и методы их анализа тоже простые.
Что трудно здесь?
Трудно иметь очень четкую и ясную картину постановки задачи.
Поэтому я всегда и прошу, и требую.
Нечего мне писать какие-то отчеты с какими-то формулами.
Я это ничего не понимаю.
Я могу понять, когда есть маленький пример, не знаю, 2, 3, 4 работы.
И вы подробно в начале на примере объясняете, в чем задача.
Как их?
Значит, можно решать, например, полным перебором.
Или с помощью задачи и назначений, какие нужно добавить дополнительные ограничения.
Значит, что здесь нового будет?
А новой будет произвольная процессия и тайм.
Ну, например, четная.
Произвольная, но четная.
А почему четная?
Ну, потому что понятно, что когда у нас все четные, мы можем их заменить работами.
Это, как сказать, дамми джобс.
Фиктивными работами, длительностью.
Ну, давайте пример посмотрим.
Пусть у нас какая-то работа имеет длительность 6 временных интервалов.
Мы ее заменяем на 3 работы.
Понятно, если у нее момент появления был один,
то первая часть, которую мы же разбили на 3 работы.
То есть первая часть, она появилась в первый момент.
И вторая часть, во второй момент, может начать выполняться, если она не была прервана.
А вот искусственно введенная вторая работа, это все та же вторая часть, но четная.
С двумя интервалами.
Вот это единственные работы, у которой всего 6 интервалов.
У нее релиз-дэйт, теперь будет момент времени 3.
То есть нельзя раньше выполнять.
Вот и все.
Ничего хитрого.
За счет чего это?
Только за счет того, что мы понимаем, что мы хотим свести решение одной задачи к другой.
Это опять отдельная тема.
Там можно опять доказывать теоремы вот такого типа, с такими же дробями.
Я думаю, оценки будут получше, чем половинка и полтора, не для оценки сверху и снизу.
Ну и наконец общий случай, когда произвольные.
Мы так просто и из заголовок статьи готовы.
Потому что все те работы, которые имеют четную длительность, они точно будут смоделированы.
А те, которые нечетную, ну так там, что будет две оценки опять снизу и сверху.
Когда четная, например, если у нас нечетная 7, мы берем четную 6 и вторую четную 8.
Все мы с обеих сторон решили и ту и другую.
Мы нашли оценки.
Также и в теоретическом анализе все эти преобразования выполняются.
И мы находим оценки снизу и сверху.
Мне кажется, я уже злоупотребляю.
Все другие темы выложены на сайте кафедры.
И я готов ответить на вопросы.
Ну, если кто-то успел посмотреть другие темы, я готов и по другим темам.
Но я рекомендую заниматься этим. Почему?
Ну, потому что уже несколько студентов работают над этим.
В данный момент, по-моему, три или даже четыре.
Кто-то уже завершил статью, кто-то делает.
Я еще раз хочу вам прорекламировать.
Публикация в коодинжурнале означает, что работодатели выстраиваются за вами в очередь.
Потому что все конвейеры, все это работает реально.
А вы показываете, что вы не просто умеете программировать,
а вы умеете еще теоретический анализ проводить
и представлять результаты таким образом,
что их оценивают высоко те высокорейтинги ГВ и журналы,
куда вы подадите свои результаты своих дипломных или курсовых работ.
Я закончил, слушаю вопросы.
Если нет вопросов, я жду мой имейл.
Голден Горин, вот как пишется моя фамилия сейчас.
Собачка, gmail.com.
Я просто никого не слышу.
Вообще меня слышно или нет?
Да, да, слышно.
Я всем желаю хорошего вечера.
Буду рад, если вы подпишитесь на мой канал.
А если вы не подпишитесь на мой канал,
да, да, слышно.
Я всем желаю хорошего вечера.
Буду рад, если вы захотите заниматься со мной.
Я еще забыл сказать.
Я одновременно преподаю такой курс.
Вот именно о расписаниях я буду рассказывать.
Может быть, начну уже даже в эту субботу.
Это в 4 часа.
Там на кафедре все это известно, где и как это происходит.
Или мне пишите, если я вам пришлю этот клип.
Значит, курс происходит онлайн.
По субботам с 4 до 6.
Болит так, спасибо большое.
Значит, у нас сейчас еще маленько задерживается.
Я готов отвечать на вопросы, если есть вопросы.
Причем вопросы можно не только по прерываемым расписаниям на одной машине.
Там, я не помню сколько, 10 или 20 тем я выложил.
Я могу о них сейчас кое-что сказать.
Одна большая тема это относится к машинному обучению.
Это совершенно новое направление.
Я его придумал.
Никакого отношения к вероятности и к вероятностным методам не имеет.
Это чисто алгебрический подход.
И там вы можете, например, доказывать, что такое оптимальная выборка для нейронной сети, например, в ДНН.
Я извиняюсь, что я говорю этими аббревиатурами.
Для тех, кто этим хочет заниматься.
Другое направление в машинном обучении это теория и алгоритмы субмодулярных, супермодулярных функций.
Зависит от минимизации или максимизации.
Опять достаточно брать мою статью в журнале European Journal of War.
Она так и называется Maximization of Submodular Functions.
Я думаю Theory and Algorithms.
И посмотрите, сколько там написано алгоритмов.
На Западе все делают то, что сделал в 1977 году Фишер, Немхаузер и Уолси.
Такие аппроксимации.
Я предлагаю делать все точно.
Я развиваю то, что делал наш, я считаю, выдающийся профессор и человек.
Как математика и замечательный.
Виктор Павлович Еренин.
Ныне покойный.
Это сотрудник вычислительного центра.
Он все это придумал сразу после войны Великой Отечественной в 45-47 году.
Вот он фактически является моим непрямым учителем.
Я учился на его статьях.
И могу сказать, что на Западе кроме моей статьи, еще одной из двух публикаций, эти работы почти неизвестны.
Те результаты, которые у них есть, они просто очень слабенькие по сравнению с теми фундаментальными результатами, которые получил Черей.
Что еще там у меня было в темах?
Я, конечно, сразу все не могу вспомнить.
С вероятностями я, конечно, дружу.
Например, можно точно решать задачи методом битвы и границ.
Я не останавливаюсь.
Предполагаю, что вы слышали, потому что времени сейчас не очень много.
Но вот применение теоремы Гнибенко, или то, что в западной литературе называется теоремой Фишера, типит Гнибенко.
Это об экстремальных статистиках.
Это когда оценки снизу, типа тех, которые я указывал, набираются как статистика, и они проверяются на тяготение к одной из экстремальных статистик.
Типа Вибула, несколько их, всего три типа.
Это Борис Владимирович Гнибенко доказал.
Заведующий бывший кафедровым был, теория вероятностей.
Ныне тоже, к сожалению, покойные.
Это тоже очень большое направление.
Какую задачу? Да любую.
Берите задачу, чем она труднее решается.
Например, задача квадратичного назначения.
40 на 40 матрица.
Это все, что умеет.
Вот с вероятностным подходом, я думаю, вы будете решать и 100 на 100, а может быть даже и 1000 на 1000.
Что невероятно, потому что в комбинаторной оптимизации каждая единичка, добавленная в размерности решений и задачи,
уже есть существенный успех, потому что экспоненциально растут вычислительные сложности.
Кто слушал курс, что-нибудь связанное с NP-hardness или NP-completeness,
как это называется, computational interactable problems, вычислительно трудно решаемые задачи.
Тоже вы можете сделать существенный прогресс.
Что надо знать?
Ну, элементарную теорию вероятностей, которую вам преподают, здесь просто шикарно.
У нас такие, я считаю, крупные специалисты.
Да и сами вы можете, там ничего такого нет.
Два вечера выучите теорему Гиденко, разберете с этими экстремальными статистиками и все.
А дальше что? Программируете метод любви и границ, проводите эксперимент.
Ну, философия необычная. Обычно говорят, я нашел оптимальное решение.
Никто не говорит, я нашел оптимальное решение с вероятностью 0,99 и доверительным интервалом очень маленьким.
Это да, это такая немножко другая философия.
Насколько она известна? Да, она известна.
Есть около 4-5 статей, в основном две задачи, насколько я помню.
Это задачи кальвивого ажора и задачи размещения, по-моему, простейшие.
Ну, это очень мало. Вот берите расписание, решайте большие задачи и показывайте, насколько полезна
вот эта теория экстремальных статистик в остановке вычислительного процесса
и получении высококачественных решений с высокой вероятностью.
Ну, и потом это же можно всегда опять экспериментально проверять.
Делайте теоретические такие оценки, останавливайте раньше.
Ну, у вас есть всегда тестовые примеры с заранее известными точными ответами.
Вы сравниваете и увидите, что вероятность 0,99 это не в сказке, это в реальности.
То есть трудно будет построить контрпример, когда с вероятностью 0,99
вы не найдете точное решение. Это почти невозможно.
Мне неизвестны такие примеры. Не знаю, что еще сказать.
Спрашивайте, мне, конечно, проще отвечать на вопросы, чем рассказывать опять о тех темах, которые перечислены.
Если вопросов нет.
А можно попросить ссылку? Ну, вот субботу, вы сказали, будет сеномар.
Ссылку, конечно. Давайте я сейчас... Тут же у нас есть чат, правильно?
Сейчас я просто зайду туда, вот где это происходит.
Это осень, 21-й год. Сейчас я найду аннотация курса. Не знаю, аннотации вряд ли.
В лекциях может быть час. Я сейчас найду ссылку.
Другая сторона, она в EMAIL-ах есть.
Ну, во всяком случае, давайте посмотрим, вдруг она здесь есть.
Да, вот ссылка есть. Сейчас я ее скопирую.
Да, это она, я думаю.
Спасибо за ваш вопрос.
Так, где у нас тут чат? Вот это наш чат, да?
Давайте попробуем.
Смотрите, там работает это. Увидели вы?
По крайней мере, тот, кто спрашивал.
Да, пришла. Спасибо большое.
Вам спасибо. Приходите, будем рады. У нас там мало людей, очень такая творческая обстановка, насколько я понимаю.
Может, еще кто-то задаст такой вопрос, как предыдущий, очень практический и полезный.
Я хотел сказать, что на сайте «Кафедры» вообще лежит информация обо всех факультативных курсах.
Ну да.
Борис Исаакович, так что периодически можно туда заглядывать.
Я тоже ссылочку прислал.
Спасибо.
Просто на сайт «Кафедры», и вот в новостях у нас уже идут, конечно, курсы, но имейте в виду...
Мы далеко не ушли.
Можно присоединиться еще.
Ну как раз разбираемся с задачей о назначении. Я говорю о своем курсе.
И в основном смотрим теорему Пенига Эггервари, насколько там все это максимальное покрытие.
Я не буду сейчас в детали. Приходите, получите удовольствие.
Я предполагаю, что там многое интересное.
Но самое главное, это все практическое.
Это не какие-то теоремы, которые непонятно там, как они работают, в каких пространствах.
Кто-то чуть-чуть умеет, а кто-то не умеет программировать и не хочет.
Я вот привел примеры. Есть замечательные теоретические задачи.
Ну конечно надо на школьном уровне, там восьмой класс, примерно алгебра, уметь преобразовывать дроби.
И самое главное, не терять неформальный смысл на каждом шаге.
У нас самое главное понимать, в чем состоит неформальная постановка задачи.
Если есть еще вопросы, задавайте. Я просто жду, когда придет следующий константин.
Да, Данил Владимирович, просто маленько задержится. Он написал на пять минут, что девять, девятнадцать, тридцать пять.
У меня нет никаких ограничений. Я готов рассказывать дальше.
Я думаю, может мне открыть там эти все темы дальше рассказывать.
Ну, я так вам скажу, но большого смысла нет.
Я видел, что я еще вчера должен был выступать, и там была ссылка, по-моему, на какую-то презентацию.
Да, на видео на ваше.
Там, я думаю, я немножко пошире рассказывал, что…
Ну, я еще раз говорю, я не знаю как, у других руководителей.
Я вам гарантирую, при серьезной работе вы напишите хорошую статью, и я помогу ее опубликовать в хорошем журнале.
Не беспокойтесь, некоторые там начинают говорить, это понятно, что вы учитесь, что правила это все.
Это мы все пройдем, и в этом курсе я очень подробно на этом останавливаюсь.
Как писать, что такое обзор, на что обращают внимание рецензенты, на что вы сами,
как вы должны отразить последние достижения по конкретной задаче, как найти это,
как осуществлять поиск, через какие базы, куда надо смотреть, что такое архив, ну или и так далее.
Я сейчас не буду очень даваться, но приходите, будем работать и выберите тему.
Я думаю, все будет хорошо.
Причем я не знаю, кто пришел, но уровень может быть любой.
Я думаю, от бакалавров до, как у нас называется, кандидатов наук до пьедитей.
Да и пожалуйста, и докторские можно писать, диссертации.
У меня есть там проблемы, которые очень серьезные.
Не знаю, что еще сказать.
Давайте я посмотрю на сам курс, может быть я тут что-то увижу интересное.
Курс фактически про те задачи, не можно сделать прогресс.
Вот я вспомнил другую задачу.
Наши студенты делали в прошлом, по-моему, семестре с Хуавэем.
Это битвины с централити.
Я так коротко скажу, в чем смысл.
Это задан, давайте скажем, даже невзвешенный пусть будет граф.
И мы считаем расстояние между парой вершин просто как количество пройденных ребер.
Понятно, что граф не обязательно полный, он случайный.
Считайте, что это граф телефонных звонков какой-то крупной сети.
Не знаю, кто у нас там, МТС или кто.
Главный Белай, может быть, не знаю, кто в России главный.
То есть, ну это может быть сотни тысяч вершин.
И надежность вот такой сети или качество ее работы одним из показателей
является вот насколько устойчиво работают ретрансляторы,
расположенные в том месте, где максимальное количество кратчайших путей пересекается одновременно.
Сразу для всех пользователей.
Это вот по-английски называется битвины с централити.
Ее решают, ну стандартно решают, через задачу о кратчайшем пути со всякими там, скажем, структурами данных.
Я не буду в подробности.
Я предложил совершенно другой подход.
Он так и не был реализован.
Ну просто заказчик сказал нам и так хорошо.
А здесь есть и научная составляющая.
Вот решать ее с помощью задачи, которую я тоже рассказываю в этом курсе о максимальном потоке и минимальном разрезе.
Посмотрите, в чем прелесть и какое это это задача имеет отношение к битвины с централити.
Потому что когда вы решили эту задачу, вы находите так называемый минимальный разрез.
И дуги, давайте не ориентируем ребра, которые там есть, они как раз, их концы находятся по разные стороны этого разреза.
Ну и первое такое утверждение, почти очевидное, что одна из точек как точного, так и приближенных решений,
вот задача битвины с централити, она находится либо по одну, либо по другую сторону от решения задачи Макс Лоу Минка.
А вот само значение Макс Лоу, это и есть значение, ну скажем, того максимального количества путей, которые пересекают какую-то вершину.
Ну в чем здесь прелесть, мы находим не одну вершину, а сразу много таких вершин.
И здесь можно делать всякие очень интересные вариации этой задачи исходной битвины с централити.
Это больше интерпретации будут в этих терминах.
Конечно там появятся свои структуры данных, свои методы, как сказать, adjustment.
Ну вот как вы будете адаптировать все эти расчеты к этой задаче.
Можно заниматься чемпионатом мира по задаче Камивая Жура.
Вот мои студенты и докторанты в Германии, сколько мы, в 2006 году мы стали чемпионами мира по этой задаче.
И только в 2017, я хочу это слово подчеркнуть, не год, там 11 лет это само по себе, знаете, это как невозможно в вычислениях так долго быть чемпионом мира.
Но интересно не это, интересно, что кто нас не побил, а просто подтвердил, что да, что мы находим точные решения, потому что они же не верят.
Это группа американских ученых на распределенной сети, ну скажем, содержащей 200, по-моему, сеть в Америке, суперкомпьютеров.
А мы это считали на обычном лэптопе.
Ну они там это все посчитали, по-моему, больше чем за два дня, в то время как у нас это считалось там, ну может быть, я говорю о каком-то конкретном примере.
Не помню, ну точно не больше чем два-три часа, вы понимаете, да?
За счет чего? За счет хорошей теории. Я ее излагаю вот в этом курсе.
Это теория допусков, это аналог, ну скажем, дифференциального исчисления для дискретных задач, то есть для недифференцированных задач.
То есть допуски, это вот такие дифференциалы, и одна из красивейших и простых теорем, что, например, решение, релаксированная задача.
Я вам сегодня в начале привел пример. Есть, да, второй доклад следующий?
Да, Данил Владимирович, подошел как раз.
Все тогда, я извиняюсь, что я заговорил вас. Хорошего вечера всем.
Спасибо.
Большое спасибо.
До свидания.
Данил Владимирович.
Так, да, добрый день, мы тут вместе, на самом деле.
Сейчас вместе и расскажем.
Да, сейчас мы уже вместе и рассказать.
Дань, куда мы начинаем?
Нет.
Банкет же идем?
Да, да.
Тут микрофон включен уже.
Так, да, давайте я тогда начну.
У меня вообще довольно много задач, которые разным образом связаны с теорией игр.
В частности, есть такая экономическая модель, связанная с расселением и разбегением на какие-то юрисдикции, регионы и так далее.
Давайте я сейчас прямо в чат скину статью, обзорную, который я недавно написал.
Там примерно 11 разных конкретных задач.
Вот там, соответственно, можно ее почитать.
А дальше я расскажу про разные другие темы.
Так, сейчас, одну секунду, я найду.
Она еще не вышла, выйдет в начале следующего года.
Так, вот.
Да, у меня написано правильный успешный файл.
Я еще расскажу про несколько других вещей, которыми я занимаюсь.
Так, а тут можно доску включить?
А, наверное, я должен сделать демонстрацию доской.
Ага.
Есть такая большая тема, называется Справедливый дележ.
И там очень много разных конкретных задач.
Например, есть такая классическая задача у дележа пирога.
Есть вот такой пирог в форме отрезка.
И есть разные участники, 1, 2 и так далее.
И у них есть разные представления о том, какая часть этого пирога самая вкусная.
То есть первый может считать, что там левая половина вкусная, а правая не очень вкусная.
Второй считает, что в нескольких местах там вкусные кусочки.
Ну и так далее. У них какие-то там разные такие функции.
И дальше возникает вопрос, как разделить этот пирог на части так, чтобы, например, никто никому не завидовал.
То есть мы дальше каким-то образом делим этот пирог.
Например, там будет одна часть, и мы ее дадим первым.
А вторая часть будет из такого кусочка и такого кусочка, и мы дадим второму.
Что-то еще третьему и так далее.
И тогда получается, что первый считает, что ему ценный кусочек достался, а второй считает, что ему.
И может делать так, чтобы каждый считал, что кусочек самый хороший, который ему достался.
Вот это классическая задача держа без зависти, которая недавно была решена.
Но дальше есть много разных, очень много разных других вариаций.
Например, может быть задача дискретная, что это не отрез, который мы как угодно делим, а это отдельная часть, которую мы как-то распределяем.
Или, может быть, там есть какие-то взаимозависимости.
Или, может быть, этот пирог на самом деле не что-то хорошее, а что-то плохое.
И, соответственно, в рот каждый хочет как можно меньшую часть получить.
Или, может быть, это вообще не пирог, а бюджет, который тратится на какие-то общественно полезные дела, но одни дела более полезны для одних, а другие для других.
И мы ищем какую-то вот такую устойчивую структуру.
В общем, это вторая как бы группа задач.
А еще есть надстройка над этим видом графов и гиперграфов.
Например, между этими участниками еще есть там какой-то граф.
Там они какие-то там друг другу соединены.
И мы смотрим только на соотношение внутри вот этих вот связей.
В общем, тоже есть огромная область со многими разными задачами.
Соответственно, тут, к сожалению, у меня нет пока вот такого вот прям списка, чтобы можно было выбирать.
Но если вас это заинтересует, то пишите.
Да, давайте я на всякий случай емейл напишу.
Данное жмем. Многие знают, но пусть будет.
Вот. Ну, вот это вторая область.
То есть первая область – это разбиение на устойчивую юридицию, что довольно хорошо написано в отчете.
Так что, в общем, лучше, чем я сейчас расскажу быстренько.
Вот. Вторая область – это воспределивый дележ, где очень много разных подзадач.
Соответственно, если интересует, то пишите. Придумаем конкретно.
Значит, третья есть область – это разного рода игры на графах.
И игры, где возникает какой-то граф. Игры в формировании графов.
Ну, тут можно сказать так, что если, например, смотреть на социальные сети как явление,
то в очень разных сетях возникают некоторые общие закономерности.
Ну, а сети социальные, но даже не только социальные.
Ну, например, что такое социальная сеть?
Ну, может быть, просто онлайн-сеть, Facebook или еще что-нибудь,
где узлы – это, да, юзеры, связи – это какие-то, ну, просто кто с кем, кто у кого в друзьях, да, или кто на кого подписан.
Вот. Может быть, сеть, например, значит, может быть, сеть соавторства.
Да, значит, где узлы – это ученые, да, значит, а ребра – это, соответственно, означает, что ученые вместе с статью написали.
Вот. И тут же, естественно, образом возникает не только сеть, но и гиперсеть,
значит, которая, в принципе, бывает и в онлайн-соцсетях, да, где кроме вот таких вот отношений дружбы или подписки,
да, значит, могут быть и те или иные сообщества.
Да, многие соцсети такой функционал предоставляют.
Соответственно, кроме таких двухсторонних связей возникает еще и многосторонняя связя.
Вот. Точно так же и в соавторстве, где они, на самом деле, изначально многосторонние.
Да, то есть у статьи есть несколько авторов.
Вот. И, в принципе, изначально это гиперграф, а дальше можно рассматривать его проекцию,
ну, а можно рассматривать что-то более сложное, да, как бы гиперграф в целом.
Вот. Ну и, например, можно тут, может быть, чисто практическое исследование, да,
вот у нас недавно вышла статья как раз про гиперграфс-авторство.
Вот. А можно взять какой-нибудь другой гиперграф.
Вот. Ну, тут еще вопрос откуда брать данные.
Ну, например, есть спортивный ЧГК, и там есть протоколы игр, как бы кто в какой команде участвовал,
да, и там тоже можно что-то изучать.
Ну, значит, у нас есть некоторые работы, которые изучал маленькую,
не работа даже, а там пост на хабре, который изучал маленькую компоненту этого графа.
Вот. И там что-то выявил.
Вот. Можно просто что-то там целиком изучить.
Есть еще, значит, еще одна такая база данных, которую я могу просить доступ.
Это база участников бегущего города.
Значит, там тоже 90 тысяч учетных данных и, соответственно, команды,
которые в основном не больше четырех, но иногда и больше.
Вот. И тоже можно пытаться смотреть, как эта сеть или гиперсеть устроена.
Вот. Можно, наверное, пытаться найти данные по какому-нибудь спорту, да,
какие-нибудь составы футбольных команд, тоже как они там куда перетекали
и тоже как вся эта сеть или гиперсеть устроена.
Вот. Соответственно, могут быть такие практические исследования.
Ну, а можно строить разного рода модели, да, например,
по каким законам строится такая сеть, чтобы повторять закономерности,
которые найдены на реальных сетях.
Да, вот я с этого начал, так этого не вернулся.
Значит, есть классические закономерности.
В общем, их несколько.
Первая закономерность – это малый диаметр.
Это так называемое правило шестируко пожатий,
что можно от любого человека до любого другого по личным знакомствам
дойти не больше, чем за шесть рукопожатий,
то есть не больше, чем пять посредников должно быть.
Но это, видимо, почти правда.
Значит, если смотреть на онлайн-сети, то там диаметры немножко больше
получается, но в средние расстояние даже там четыре получается.
Да, там была даже такая статья называлась, это вообще по-английски
Six Degrees of Separation.
Там была статья, которая называлась Four Degrees of Separation,
которая изучала там какой-то Facebook там или что-то еще,
и там в средние четыре получалось.
Во, значит, второе, значит, второе свойство так называемое
Scale-freeness.
Это безнаштарность часто переводят.
Ну или можно это говорить, что это тяжелые хвосты распределения степеней.
Значит, это следующее, что вот если у вас нормальное распределение
и, например, в среднем там у каждого 200 друзей,
то тогда ну будет там 150, там 250 часто будет, там 350 уже редко,
а чтобы 600 было, это вот почти никогда, если нормальное распределение.
Вот, а в реальности это такой легкий хвост.
А в реальности получается по-другому, да, тяжелый хвост,
что может быть там и 300, и 400, и 800, и 2000,
и это все вполне достаточно часто встречается.
Вот, ну без масштабности это некоторая конкретная,
конкретно степной закон, который тоже в определенной степени
выполняется.
Так, значит, ой, так, не четыре, а три.
Третье, собственно, пластеризация,
что на самом деле как раз это из-за гиперсети идет,
что и настоящая социальная сеть часто берется из-за узких компаний,
клубов и так далее, в которых более-менее все всех знают.
Вот, ну это тоже можно измерить там через качество реугольных и так далее.
Ну и там можно еще разного рода закономерности выводить,
там какая-нибудь ассортативность, там еще что-нибудь.
Вот, ну а соответственно общий вопрос –
это как построить модель образования сети,
которая всем этим свойством будет удовлетворять.
Вот, ну и тут есть вероятностные модели,
которые как определенного рода случайные графы работают.
Вот, ну а есть теоретико-игровые, которыми в том числе я занимаюсь.
Вот, и это вот вполне актуальная задача –
построить теоретико- вариантованную модель,
в которой хотя бы часть из этого будет выполняться.
Она частично решена, и тут вполне можно на эту тему сделать работу.
Вот, ну вот, соответственно, вот это разного рода тема,
которая связана с теорией игр и теорией графов.
Ну и в принципе есть еще у меня некоторые темы отдельно
связанные со сложностью учислений,
которые в принципе можно применять и вот к предыдущим,
и тоже у меня есть ученики, которые этим занимаются.
Ну, можно сказать так.
Да, это вот сложность поиска равновесий.
Вот, допустим, мы какую-нибудь модель построили.
И, допустим, даже доказали, что РНС получается с нужными нам свойствами.
Просто как это РНС найти?
Вот, есть ли там какие-то алгоритмы, которые это ищут,
или, наоборот, есть какие-то нижние оценки,
что эта задача сложная в каком-то смысле.
Вот, ну, соответственно, вот это измерение, в принципе,
можно ко всем этим темам добавить.
Да, значит, и алгоритмы поиска справедливо дележа
в каком-то из определений,
или, наоборот, оценки на сложность,
и алгоритмы поиска устойчивых разбиений
по тому файлу, который я отправлял,
и алгоритмы поиска вот этих равновесий.
Значит, это все возможные постановки,
которые можно изучать, соответственно, с двух сторон.
Либо это будет какая-то нижняя оценка,
например, что задача будет полна в каком-то сложностном классе.
Или, может быть, наоборот, может быть,
в каком-то частном случае возникает
тот или иной эффективный алгоритм.
Или, может быть, даже не очень эффективный,
в случае с справедливо дележа общего вида,
значит, даже экспоненциальные алгоритмы
вполне могут быть большим достижением.
Так, ну ладно.
Значит, вот это вот такое общее описание,
к каким задачам я занимаюсь.
Может, какие-нибудь вопросы есть?
Так, видимо, нет.
Тогда передаю слово Андрею Владимировичу.
Большое спасибо.
Ребята, я буду рад,
потому что я сегодня уже сделал два доклада,
и язык ворочается с трудом.
И, кроме того, давайте я коротко опишу темы.
Первая тема – это тоже игры на графах,
но это в основном игры на графах.
Денис Владимирович тоже такими занимается,
но мы занимаемся играми на графах,
у которых есть какие-то параллели в физике,
чтобы сравнивать соответствующие равновесия
с оптимизационными задачами.
И вот есть класс вопросов,
которые здесь рассматриваются.
Это первая группа задач.
Вторая группа задач – это задачи на стыке
эволюционной теории игр и обучения с подкреплением.
И здесь некая особенность момента
состоит в том, что уже много дипломников над этим работают,
и поэтому не очень понятно,
можно ли прямо быстро найти содержательно сейчас задачу.
Но если будет очень горячее желание,
то можно попробовать.
И, наконец, новый тип задач,
который я сейчас хочу предложить желающим,
это рассмотрение качественных свойств
глубоких нейронных сетей,
то есть послойный анализ того, что в них происходит.
В частности, хотелось бы посмотреть на то,
как можно веевлеты использовать для анализа того,
как передается информация из слоя в слой.
Слой – это первое.
И второе – это посмотреть на то,
каким образом происходит,
может быть, не веевлетным, а в каком-то другом виде,
как происходит сжатие информации.
Попробовать поиграть с этим
и обобщить результаты, которые потихонечку
в этой сфере накапливаются.
Имейл я вам сейчас напишу.
Вот он у вас перед вами.
Пишите мне, встретимся и обсудим.
Спасибо.
Так, ну, вопрос какие-нибудь?
Вы в чат скидывали файл, я его не вижу.
Такое ощущение, что он не дошел.
А, это бывает такое в зуме.
Слушайте, давайте я его сейчас
через Dropbox расшарю быстренько.
А кому-нибудь пришел или вообще никому не пришел?
Мне пришел.
Пришел, пришел.
А, вот, как это называется?
Не, файл-то пришел, у меня есть.
Ну, если что, может быть, напишут мне,
я перешлю кому надо.
А, ну, хорошо.
Где Владимировичу?
Ну, да, да, ладно, тогда я, если надо, то...
Вот, да, эта статья уже принята,
но еще не вышедшая в журнале
«Новая экономическая ассоциация».
Вот, поэтому там еще и много чего написано
про всякие экономические предпочтения,
которые у нас есть,
которые у нас есть,
написано про всякие экономические приложения,
но можно чисто математические задачи решать.
А можно и что-то экономическое делать.
Так, ну ладно тогда.
Все, что ли?
Ну, если вопросов нет, наверное, да.
Спасибо большое за уделенное время.
Ребята, у того вопроса есть, значит,
пишите вот почта Андрея Владимировича,
почта Даниила Владимировича,
если как кто заинтересовался.
Ну, если кто-то не успел записать, значит,
со мной свяжетесь,
я переадресую ваш запрос.
А можно вопрос Андрея Владимировича?
Ой, а он ушел уже.
Ушел?
Ладно, напишу на то, что...
Да, теперь на почту.
Так, ну тогда все.
На сегодня у нас
руководитель...
Доклад руководителя исчерпан.
