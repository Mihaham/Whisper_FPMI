Итак, добрый день, давайте начинать. Со звуку у нас там всё в порядке, правильно, на сей раз? И со всем
остальным всё в порядке. Я напоминаю, на чём мы остановились. Мы с вами изучаем собственные
значения, собственные векторы оператора, и в частности мы хотим понять, когда
оператор диагонализуем, то есть у него есть, для него есть базис, в котором его матрица имеет
диагональный вид. Ну вот мы говорили, что тогда у него достаточно простой геометрический смысл,
и вроде как мы в прошлый раз сформулировали, но не доказали теорему. Правильно я помню? Давайте
я её вкратце напишу уже. Для оператора ФИ равносильны следующие утверждения. Во-первых,
ФИ диагонализуем. Во-вторых, в В есть базис из собственных векторов нашего
преобразования ФИ. Третье условие, что В есть прямая сумма собственных подпространств. Ну и четвёртое,
самое длинное условие, но зато наиболее, возможно, полезное на практике, это то, что характеристический
многочлен раскладывается на линейное сомножителе, произведение там лямбда ИТ минус Х в каких-то
степенях. Вот давайте я даже так напишу. Раз у нас К собственных значений, то характеристический
многочлен раскладывается, у характеристического многочлена корнями служат лямбда 1 и так далее,
лямбда К, я их всех различных перечислил. И тогда, если он раскладывается на линейные
сомножители, то линейные сомножители должны быть именно вот такими. И при этом алгебраическая
кратность каждого собственного значения равна его геометрической кратности. Но я на всякий случай
напомню, что алгебрическая кратность собственного значения лямбда ИТ, это в точности вот что это
такое в терминологию, которая уже на доске введена? Что? Альфа ИТ, конечно, правильно. Это как раз кратность
корня в характеристическом многочлене. В четвертом пункте нам говорят, что геометрическая кратность
лямбда ИТ есть альфа ИТ. Ну и давайте мы докажем, что все эти четыре утверждения равносильны. На самом
деле у нас как-то немножко необычно, потому что на самом деле нам сейчас будет удобнее не как
всегда мы доказывали по циклу, а просто доказать равносильность сначала первых трех по отдельности,
а затем понять, что происходит с четвертым. Почему первое условие равносильно второму? Потому
что на самом деле, вот что означает, что фи диагонализуем, это означает, что есть первое
условие, означает, что есть базис Е такой, что фи в этом базисе имеет диагональную матрицу. Давайте
я ради ясности другие числа поставлю, мио 1, мио 2 и так далее, мио n. Ну а это вот просто для
базиса Е то, что фи имеет в этом базисе такую матрицу. Давайте я этот базис, элементы этого
базиса обозначу через Е, 1 и так далее, Е, n. Вот то, что в этом базисе, в каком-то фиксированном,
фи имеет диагональную матрицу равносильно тому, что фи от ЕИТ есть что такое. В ИТ столце у нас
стоит мио ИТ на ИТ месте, правильно? Поэтому это есть мио ИТ на ЕИТ при И от 1 до n. Ну то есть
равносильно тому, что ЕИТ это собственный вектор с собственным значением мио ИТ. Ну и что у нас
получается? То, что фи диагонализуем, равносильно существованию вот такого вот базиса. Ну а базис
такой ровно тогда, когда он состоит из собственных векторов. Поэтому если мы диагонализовали наш
оператор, то мы автоматически нашли базис собственных векторов, и наоборот, если мы нашли базис
собственных векторов, то в этом самом базисе фи имеет диагональный вид. Так что первое, два
два утверждения, очевидно, равносильны. Значит, второе и третье утверждения
равносильны. Вот по каким причинам. Давайте я сразу напомню. Мы с вами
доказывали в прошлый раз, что сумма V лямбда первого плюс и так далее плюс V
лямбда Катова прямая всегда. Какой бы я ни взял оператор phi, для него сумма
собственных подпространств прямая, ну и соответственно нам нужно доказать только,
что есть базис из собственных векторов тогда и только тогда, когда эта прямая сумма совпадает
совсем V. То есть, видимо, если этого базиса не будет, то эта прямая сумма будет давать
нам в итоге меньше, чем всё пространство, правильно? Ну и давайте мы это будем доказывать. Значит,
если V есть прямая сумма наших собственных подпространств, то мы с вами помним, что если
мы выберем базис в каждом из прямых слагаемых и объединим их, то есть возьмем контакт нацию этих
базисов, то получим базис всей суммы, то есть базис пространства, правильно? Значит, объединяя
базисы в V лямбда 1 и так далее V лямбда Катая, мы получим базис в прямой сумме, раз она прямая,
это вот у нас был один из критериев прямой суммы, напоминаю. Мы получим базис в пространстве V,
ну и поскольку мы элементы базисов брали из собственных подпространств, то все эти элементы
собственные векторы, правильно? Его элементы являются собственными векторами. Наоборот,
если в V существует базис E, состоящий из собственных векторов, то, глядите,
что происходит. Каждый вектор в этом базисе собственный, поэтому он лежит в каком-то из наших
прямых слагаемых, правильно? А коль скоро так, то он лежит и в их сумме. Значит, E содержится в сумме
этих собственных подпространств, правильно? Ну а это означает, что эта сумма совпадает,
давайте так скажу, в этой сумме содержится и линейная оболочка нашего базиса, то есть V. Ну в итоге
мы получили, что наша сумма, во-первых, прямая, это мы знаем всегда, а во-вторых, эта сумма
совпадает с V, потому что больше, чем V она дать нам не может, конечно же, правильно? Здесь? Если в V
существует базис из собственных векторов, что такое собственный вектор? Каждый собственный вектор
лежит в одном из вот этих вот собственных подпространств, правильно? Ну значит, каждый вектор
нашего базиса лежит в этой сумме. Все, значит, конечно же, поскольку сумма это подпространство,
то и линейная оболочка нашего базиса тоже там лежит, а это все V. Ну и поэтому V есть сумма всех
этих подпространств, ну и более того, прямая сумма, потому что их сумма прямая всегда. Так,
здесь у нас уже все было доказано, здесь у нас тоже доказано. Значит, давайте мы теперь выясним,
почему у нас, например, из первого пункта следует четвертый, давайте мы поймем, что это так. Значит,
если phi диагонализуем, то есть в некотором базе C и E его матрица имеет вид μ1 и так далее,
μn, давайте мы эту матрицу обозначим через A, то характеристический многочлен нашего phi это
просто-напросто характеристический многочлен этой матрицы, ну а он понятно, как выглядит,
правильно? Это просто μ1-x, μ2-x и так далее, μn-x. Напоминаю, что характеристический многочлен
это определитель A-xE, правда? Мы берем просто-напросто определитель диагональной матрицы,
разумеется, он раскладывается на линейные сомножители. Ну и давайте я сразу скажу,
что мы можем, вот все эти μиты, конечно же, являются собственными значениями, то есть они являются
кем-то из λ, лямбда первого и так далее до лямбда катова, взятых соответствующее количество раз,
правильно? Если у нас лямбда первая, скажем, встречается на этой диагонали альфа первое раз,
то она, то вот соответствующий множитель и входит в характеристический многочлен в степени альфа
первое. Ну и давайте мы сразу скажем, что мы можем эти μиты переставить так, чтобы сначала шли все
лямбда первое, потом шли все лямбда второе, потом все лямбда третий и так далее. Что означает переставить
эти миты? Что нужно сделать с базисом, чтобы миты переставились? Векторы базиса просто переставить
местами, правильно? Сначала в нашем базисе собрать все векторы собственным значением лямбда первое,
потом все векторы собственным значением лямбда второе и так далее. Переставляя
элементы базиса, нам ничего не нужно сделать, кроме как переставить их местами, правильно? Мы считаем,
что наша матрица А выглядит так. Сначала там идут по диагонали, давайте лучше это запишу с
использованием обозначения, которые мы уже ввели. А это диагональная матрица, у которой по диагонали
идут сначала лямбда первая, потом лямбда вторая и так далее. При этом, еще раз обращаю внимание,
если мы считаем, что характеристический многочлен выглядит вот таким вот образом, то это означает,
что лямбда первая здесь будет встречаться как раз а1, потому что в нашем многочлене будет
а1 вот таких вот сомножителей лямбда 1-х. Лямбда вторая будет встречаться а2 раз, ну и так далее.
Что это в свою очередь означает? Тогда, например, для первого собственного значения, если я возьму
первые а1 векторов нашего базиса, в котором мы эту матрицу записали, они все будут соответствовать
собственному значению лямбда 1, правильно? То есть они все будут лежать в В лямбда первом. Ну и они,
естественно, линейно независимы. Следовательно, размерность В лямбда первого больше или равна,
чем а1. Мы в ней нашли а1 в линейне независимых векторов, правильно? С другой стороны,
эта размерность В лямбда первого, это и есть геометрическая кратность нашего корня лямбда 1,
не превосходит алгебравической кратности всегда. Следовательно, геометрическая кратность лямбда
первого равна алгебравической кратности лямбда первого. Мы проверили наши условия для лямбда
первого, но для остальных оно, естественно, проверяется точно так же. Просто нужно взять
соответствующую группу векторов из нашего базы. Ну и таким образом мы с вами доказали,
что из первого утверждения следует четвертое. Давайте мы из четвертого выведем, например,
третье. И этим мы уже завершим все доказательство. Как из четвертого вывести третье?
Значит, если у нас выполнено вот это первое условие, если характеристический многочлен
раскладывается на линейное сомножитель, то мы знаем сумму степеней этих сомножителей,
правильно? Мы знаем сумму кратностей наших корней, алгебравических кратностей. Поскольку
характеристический многочлен раскладывается на линейные сомножители, мы понимаем, что сумма
альфаитых равна n. Ну, через n мы, как обычно, обозначаем размерность пространства. Ну а это значит,
что если мы возьмем прямую сумму наших собственных подпространств, мы, напоминаю, еще раз, знаем,
что она всегда прямая, правильно? Размерность прямой суммы всегда равна сумме размерности прямых
слагаемых, а они являются геометрическими кратностями наших собственных значений. Ну и значит,
они совпадают с алгебравическими кратностями. Мы предполагаем, что четвертое условие выполнено,
правильно? То есть, эта сумма размерностей, это то же самое, что сумма просто-напросто альфаитых,
здесь мы воспользовались тем, что алгебравические кратности совпадают с геометрическими, а здесь
мы пользуемся тем, что характеристически многочлен раскладывается на линейные сомножители,
правильно? Мы этим уже воспользовались здесь. Значит, эта сумма равна размерности v. Ну что мы
получили? Мы получили, что вот эта прямая сумма – это подпространство v размерности той же,
что и v. Это и означает, что эта прямая сумма равна всему нашему пространству. Итак, v – это
прямая сумма, и мы третий пункт таким образом доказали. Ну и критерии диагонализуемости
оператора мы тоже уже полностью доказали. Ну и, наверное, на этом все, что мы могли сказать про
диагонализуемый оператор. Еще раз напоминаю, что если оператор диагонализуем, то выбрав этот
собственный базис, вы получаете очень простую картинку. Оператор есть просто растяжение вдоль
соответствующих осей в соответствующее количество рас, лямбда ит. То есть его
геометрический смысл простой и работать с ним очень просто. Осталось нам разобраться с тем,
что происходит, когда вот эти вот четвертые условия, в частности, не выполняются. Что в
такой ситуации можно делать с оператором. Мы уже приводили примеры, которые показывают,
что эти четвертые условия могут не выполняться. Ну точнее, давайте я сразу сделаю некоторое замечание.
Любое из условий в пункте 4 может не выполниться. У нас мы всегда
помним, что алгебрическая кратность не меньше геометрической. И мы уже приводили пример того,
что алгебрическая кратность может оказаться больше геометрической кратности какого-то лямбда.
И в таком случае понятное дело, что диагонализуемости у нас не будет. Итак, алгебрическая кратность
бывает больше, чем геометрическая кратность. Это мы уже видели. Ну и, естественно,
характеристический многочлен может оказаться, что у него он не раскладывается на линейные
смножители. Может оказаться даже, что у него нет корней совсем у, скажем, поворота двумерного
вещественного пространства на угол альфа, ну скажем, строго от нуля до пим. Давайте мы
посмотрим на этот поворот. Напоминаю, что матрица его в ортонормированном базе имеют вот такой
вот вид. Ну и, соответственно, если вы характеристически многочлен, ее посчитаете,
то у вас получится... Давайте мы его посчитаем. Мне нужно по диагонали вычесть из диагональных
элементов х, то есть косинус альфа минус х в квадрате и добавить синус квадрат альфа. Получится х
квадрат минус 2 косинус альфа плюс один, потому что здесь будет косинус квадрат альфа и будет
синус квадрат альфа. У него вещественных корней нет, ну и это согласуется с нашей геометрической
интуиции, потому что мы с вами знаем, что если мы поворачиваем плоскость на угол альфа, вот такое
то каждый вектор переходит в неколинярное себе, собственных векторов нет. Однако вот такая ситуация
еще не очень плохая, потому что, глядите, у этого многочлена нету вещественных корней, зато у него
есть корни комплексные. У любого, скажем, вещественного многочлена мы с вами знаем, есть
обязательно комплексные корни, то есть такой многочлен разложится на линейные сомножители над
полем С. Однако у него есть комплексные корни, ну и в такой ситуации они даже имеют свое название,
они обычно называются характеристическими числами оператора. Ну и в такой ситуации,
что можно сделать? Если вы хотите хорошо описать такой оператор, ну этот-то еще достаточно простой,
а в более сложной ситуации может оказаться, что он выглядит ужасно, в такой ситуации можно сделать
следующее, можно формально рассмотреть оператор на двумерном комплексном пространстве с той же
самой матрицей, правильно? Тогда можно рассмотреть оператор на двумерном комплексном пространстве
с той же матрицей. И для него то самое первое условие из нашего четвертого пункта окажется
уже выполненным, характеристически многочлен будет раскладываться на линейные сомножители. В нашем
случае, например, он даже окажется диагонализуемым. То есть у него как бы будут два собственных вектора,
правда, с комплексными координатами в обычном базисе, в том базисе, в котором оператор задан этой
матрицей. Тем не менее с ним тоже может быть удобно работать. Он может быть, не всегда, конечно же,
даже будет диагонализуемым. То есть вот мораль этой истории заключается в том, что если у
характеристического многочлена нету n корней с учетом кратности, если он не раскладывается на
линейные сомножители, то можно попытаться перейти к большему полю и найти корни в этом самом большем
поле. Как мы через некоторое время выясним, такой процесс возможен всегда. Всегда, если у вас есть
поле, если у вас есть многочлен над этим полем, то всегда можно это поле расширить так, чтобы
многочлен над уже расширенным полем разложился на линейные сомножители. Так что вот эта проблема
у нас может решиться подобной заменой. А другая проблема, которая заключается в том, что
алгебраическая кратность больше геометрической, такой заменой решиться, конечно же, не может.
Почему? Ну хотя бы потому, что если вы будете вычислять алгебраическую кратность, то есть находить
кратность корня в многочлене, и если вы будете вычислять геометрическую кратность, то есть искать
собственное подпространство, решать систему кратности не совпадают с геометрическими.
Ну вот, непосредственно к этому вопросу мы подставимся чуть попозже. Сначала нам придется
выяснить некоторые дополнительные сведения. Ну и я вот после того, как небольшое замечание
сделал, говорю вот что. Значит, с этого момента мы считаем, что вот описанной проблемы здесь,
про то, что характеристический многочлен не раскладывается на множители, нету. То есть мы
всегда считаем, что у нашего оператора характеристический многочлен раскладывается на
линейные сомноживатели. Ну и даже мы с вами ввели сразу определение, правильно? То есть мы говорим,
что лямбда 1 и так далее, лямбда каты, это собственное значение нашего оператора фи, а альфаиты их
алгебраические кратности. Ну опять же, через некоторое время мы поговорим про то, что делать,
то есть как можно работать, если это не так. Ну вот вкратце я уже сказал. С этого момента мы
пока считаем, что мы находимся вот в этой ситуации. В частности, если мы работаем в линейном
пространстве над полем комплексных чисел, то мы всегда находимся в этой ситуации. Любой
линейный оператор на комплексном пространстве, он именно такой, как у нас сейчас написано. Так,
ну давайте разбираться, к какому виду, то есть наша главная цель, конечно же, выяснить,
какому виду можно привести матрицу линейного оператора, если он вот этому условию удовлетворяет,
но он при этом не диагонализуем. И первым делом мы дойдем не до самого конца, а просто увидим,
что хоть какому-то удобному виду его привести можно. С этой целью давайте мы докажем вот какую
лему, точнее давайте мы сначала докажем следующее вспомогательное утверждение,
затем лему, а затем приведем к нужному виду. Утверждение такое, пусть, значит,
какой буквы у нас еще не было, бета, это некоторый скаляр, а фи, это как мы уже привыкли,
линейный оператор на пространстве В. Тогда под пространство В инвариантно относительно фи,
тогда и только тогда, когда оно инвариантно относительно фи минус бета. То есть если я из
оператора вычитаю скаляр, ну я напоминаю, что означает скаляр. Скаляр это бета умножить на
тождественный оператор, правда ведь? Если я из оператора вычитаю скаляр, то инвариантное
подпространство, набор инвариантных подпространств не меняется. Доказательство очень простое, пусть
у нас, естественно, я докажу только слева направо, потому что этого достаточно. Что будет,
если я докажу слева направо? Если я докажу, что если уинвариантно относительно фи, то уинвариантно
относительно фи минус бета. Почему и наоборот тоже будет выполняться? Потому что можно вычесть
минус бета, правильно? Вот этот оператор получается из этого добавлением бета, то есть ровно такой
же операции, правильно? Просто обратное утверждение будет аналогично. Итак, ну пусть у уинвариантно
относительно фи, давайте докажем, что оно инвариантно относительно фи минус бета. Очень просто,
если мы взяли какой-то вектор у маленькой из нашего пространства, это означает, что фи от у
лежит в у большом, поскольку у большое инвариантно. Ну а тогда, если я из фи от у, давайте я так скажу
лучше. Если я применю к нашему у фи минус бета, то что это означает? Это у нас здесь должно быть
написано фи от у минус бета, умноженное на у. Ну и оба этих товарища у нас лежат в у, правильно?
Фи от у по нашему условию, бета на у, потому что у лежит в у, правда? Значит, оба этих товарища
лежат в у большом, а значит их разность тоже лежит в у большом. Мы доказали то, что нам нужно,
если какой-то вектор лежит в у большом, то и фи минус бета от этого вектора тоже лежит в у
большом. Таким образом утверждение у нас уже доказано. Это утверждение нам пригодится для
доказательства вот какой леммы.
Плохой мел.
Пусть фи, вот на самом деле сейчас я противоречу сам себе, для этой лему мне не нужно условия,
что характеристически многошлен раскладывается на линейные с обножителя. Мне важно, что это
произвольный, давайте я на всякий случай это напишу, произвольный оператор, у которого есть
собственный вектор. Тогда, ну если мы как обычно обозначим через n размерность v, то у нашего фи есть
n-одномерное инвариантное подпространство. То есть подпространство размерности на единичку меньше,
чем размерность v, еще принято говорить, что это подпространство ко размерности 1. Сразу я хочу
оставить предостережение. Очень бы хотелось, вот если я вижу такую лему и хочу ее доказывать,
очень бы хотелось доказать ее вот каким образом. Если v это тот самый собственный вектор у фи,
который есть, то очень бы хотелось искать это n-одномерное инвариантное подпространство,
как какое-то прямое дополнение к линейной оболочке v, правильно? Хотелось бы искать такое
инвариантное подпространство u, как прямое дополнение к линейной оболочке v. Так вот,
предостережение. Этот путь ведет в тупик. Это, возможно, не всегда. Это, возможно,
не всегда. Ну и примером служит та же самая матрица, которую мы с вами уже рисовали,
которая носит название жардановой клетки размера 2. Потому что если мы взяли оператор с вот такой
вот матрицей, то e1 это собственный вектор. Ну e1 это первый вектор базиса, в котором оператор имеет
такую матрицу, правильно? Значит, тогда e1 будет собственным вектором, но не существует такого
собственного вектора e2, чтобы их линейные оболочки образовывали прямую сумму. Если бы мы хотели
найти вот это вот подпространство, как прямое дополнение, я понимаю, что в этой ситуации у нас
уже есть инвинус одномерный. Но если бы мы хотели его искать как прямое дополнение, то оно должно
было быть тоже одномерным, то есть тоже порождаться собственным вектором. А вот такого вектора здесь
нет. Здесь все собственные векторы пропорциональны e1. Так что таким образом эту лему не доказать,
и мы ее докажем немного более хитрым образом, пойдем в обход. Итак, доказываем лему. Нам главное,
на самом деле, не то, что у phi есть собственный вектор. Если есть у phi собственный вектор,
то у него есть и собственное значение, правильно? Давайте я быстренько это доказательство скажу.
Возьмем собственное значение нашего оператора phi. Что это означает? Это означает, что phi-λ вырожденный
оператор, в частности, размерность его образа меньше, чем n. Ну а раз меньше, чем n, то мы можем
выбрать подпространство u. Такое, что оно, во-первых, содержит этот самый образ, а во-вторых,
что его размерность равна n-1. Ну просто будем, например, добавлять по одному. Вот есть у нас
какой-то этот образ. Будем добавлять туда новый вектор и брать линейную оболочку. От этого размерность
будет увеличиваться на единичку, правильно? Когда-нибудь она доберется до n-1. Мы с вами уже
доказывали, что не только образ оператора инвариантен относительно него, но и все,
что содержит образ тоже инвариантно относительно этого оператора. Поскольку u содержит образ phi-λ,
ну и естественно является подпространством, то u будет инвариантным относительно phi-λ. Ну а по
нашему утверждению, тогда u инвариантно и относительно phi. Все, мы завершили наше доказательство.
Размерность u оказалась равной n-1, и оно инвариантно относительно phi. Лемма доказана,
что из леммы следует. Давайте увидим после 5-ти минутного перерыва. Разумеется, если есть
вопросы, то задавайте. Давайте я сначала докажу один и тот же факт на двух разных языках. Ну,
точнее, сначала докажу на одном, потом переведу на другой. Итак, теорема. Пусть phi это линейный
оператор, ну и давайте мы, это вот наше условие того, что характеристически многошленно раскладывается
на линейные сомножители, обратно включим. Удовлетворяющий звездочка, конечно же. Тогда
в существует вот какой хороший базис. Существует базис e1 и так далее, en такой, что при всех k от 1 до n
линейная оболочка префикса этого базиса, то есть линейная оболочка первых k элементов этого базиса
инвариантно относительно phi. То есть линейная оболочка первого вектора инвариантно,
линейная оболочка первых двух векторов инвариантно и так далее. Что это значит для матрицы нашего оператора,
мы поймем чуть попозже. Давайте сначала докажем. Доказательства очень простое. Теперь уже после того,
как мы лему сделали, оно идет индукцией по n, то есть по, естественно, размерности v, как обычно,
правильно? Для базы, если n равно 1, то доказывать нечего, правильно? Нам нужен просто любой базис,
потому что нам нужно, чтобы линейная оболочка первого вектора, то есть все пространство,
был инвариант. Любой базис годится. Пусть теперь n больше единицы. Глядите, что мы можем сказать.
Наш характеристический многошлен раскладывается на линейные совножители. В частности, у него есть
хотя бы один корень, правильно? А значит, есть хотя бы одно собственное значение. В общем,
в любом случае, согласно Лемме, у нас есть подпространство у размерности n-1
инвариантное относительно phi. Давайте мы рассмотрим ограничение phi на это подпространство,
обозначим его через psi. Это уже линейное преобразование подпространства у. И давайте я сразу
замечу, что характеристический многочлен psi, мы с вами знаем, характеристический многочлен
ограничения на инвариантное подпространство, делит характеристический многочлен исходного
оператора, правильно? Характеристический многочлен psi делит характеристический многочлен phi.
И следовательно, характеристический многочлен psi тоже раскладывается на линейные
совмножители. Мы с вами знаем, что характеристический многочлен phi раскладывается на линейные
совмножители, ну а тогда из основной теоремы арифметики, из единственности разложения на
совмножители, мы знаем, что любой его делитель, это тоже произведение некоторых из этих скобок,
правильно? Поэтому любой его делитель тоже раскладывается на линейные совмножители,
и поэтому к psi мы можем применить предположение индукции.
psi уже действует на n-одномерном подпространстве, правильно? К нему предположение применять можно.
Применяя предположение индукции psi, находим базис E1, и так далее,
E n-1 в U, какой надо. То есть такой, что любой его префикс порождает инвариантное подпространство.
Но для того, чтобы сделать то, что нам нужно, достаточно его дополнить до базиса V как угодно.
Мы уже получаем требуемое, потому что вот в этом вот списке подпространств,
про которые нам нужно потребовать, чтобы они были инвариантными, там первый E n-1 подпространство
уже инвариантный, потому что мы их так построили, правильно, по предположению индукции. Ну а n-ное
подпространство, которое линейная оболочка всех векторов, оно все V, оно конечно же инвариантное,
правильно? Так что вот если мы в U такой базис построили, то дополняем его как угодно и уже
получаем то, что нам нужно. Итак, теорема наша с помощью леммы уже доказана, вследствие это просто
переформулировка этой теоремы на другой язык. Если наш линейный оператор удовлетворяет нашему
условию, то есть его характеристический многочлен раскладывается на линейные сомножители, то существует
базис E в пространстве V такой, что матрица phi в этом базисе верхне треугольная. Давайте я напишу,
скажем, μ1 и так далее, μn стоят на диагонали, сверху может стоять все что угодно, снизу стоят,
снизу от диагонали стоят нули. То есть это верхняя треугольная матрица. Ну, тут все очень просто,
просто тот самый базис, который мы нашли в теореме и годится.
Итак, доказательства. Базис E из теоремы годится. Почему это так? Давайте поймем.
Если мы возьмем произвольный вектор из этого базиса, скажем, екатый, что мы знаем? Что phi от
екатого лежит в линейной оболочке первых K базисных векторов, правильно? Просто потому,
что эта линейная оболочка это инвариантное подпространство, а екатый там лежит. Ну,
значит и phi от екатого тоже там лежит. Ну, а коль скоро это так, то значит, когда мы будем строить
матрицу нашего оператора, мы же в катом столбце будем писать как раз образ катого вектора,
екатого, разложенного по этому же самому базису. И это значит, что здесь первые K координат могут
быть какими угодно, а вот дальше уже точно пойдут нули. Раз phi от екатого выражается только через
первые K базисных векторов, правильно? Ну и поскольку это случится для любого K одновременно,
то у нас как раз и получится вот эта вот главная диагональ, образуя нам ступеньки, ниже которой
точно будут стоять нули. Ну а сверху будет стоять все что угодно. То есть на самом деле, обратите
внимание, матрица оператора в каком-то базисе верхне треугольна тогда и только тогда, когда
этот базис удовлетворяет вот этим вот условиям, когда все подпространства инвариантны. Другое
объяснение этому факту можно сказать следующим образом. Что означает, что подпространство,
порожденное E1, инвариантно? Согласно нашему критерию, это означает, что вот здесь в матрице есть
угол нулей, правильно? Размера 1, точнее n-1 на 1. Что означает, что подпространство E1, E2,
порожденное E1, E2, инвариантно? Это означает, что у нас здесь есть вот такой вот угол нулей и так
далее. Эти углы нулей как раз и замастят нам все пространство под главной диагональ. Поэтому
инвариантность этих подпространств равносильна тому, что базис удовлетворяет условиям теории.
Так, мюиты мне, которые я там написал, не потребовались, но я их ввел для того,
чтобы сейчас сделать небольшое замечание. Разумеется, характеристический многочлен phi — это
характеристический многочлен вот ровно той самой матрицы, которую мы построили. Давайте мы ее обозначим
через А. А характеристический многочлен верхней треугольной матрицы считается настолько же
просто, насколько и характеристический многочлен диагональной матрицы, потому что мы знаем,
что определитель верхней треугольной матрицы — это просто произведение ее диагональных
элементов. То есть это будет произведение u, g от 1 до n, u, g – x. То есть, если мы, наш оператор привели
в некотором базисе к верхней треугольному виду, если мы выбрали базис, в котором матрица
верхней треугольная, то на диагонали этой матрицы обязаны стоять никто иные как собственное значение,
корню характеристического многочлена. Причем не просто собственное значение, а еще и с нужными
кратностями. Если собственное значение кратности альфа, то и на этой диагонали она встретится ровно
альфа раз, потому что такой смножитель должен встретиться в характеристическом многочлене ровно альфа раз.
На диагонали нашей верхней треугольной матрицы
стоят просто-напросто собственное значение фи в количествах,
равных их алгебраическим кратностям. Ну и более того, хочется еще заодно заметить,
если мы для какого-то оператора нашли базис, в котором его матрица верхней треугольная, то тогда
характеристический многочлен его обязательно раскладывается на линейные смножители. Поэтому
на самом деле вот это следствие можно было бы сформулировать так, что если я взял произвольный
оператор, то его можно привести к верхней треугольному виду, то есть можно найти базис,
в котором его матрица верхней треугольная, тогда и только тогда, когда его характеристический
многочлен раскладывается на линейные смножители. Более того, утверждение теоремы выполняется
тогда и только тогда, когда фи удовлетворяет нашей звездочке, то есть когда харм многочлен
раскладывается на линейные смножители. Так, замечательно, с этим мы разобрались. Глядите,
если не получается привести к диагональному виду, то уж хоть к верхней треугольному виду,
у нас привести точно получилось. А из этого мы сейчас немедленно выведем еще одно очень
интересное утверждение. Теорема, которая по-русски называется теоремой Гамельтона Келли, а по-английски
их переставляют местами, потому что алфавитный порядок такой. Давайте я сделаю так, я сейчас делаю
небольшую небрежность, но через некоторое время я ее поправлю. То есть я сейчас сформулирую теорему
Гамельтона Келли в полной общности, а докажу сейчас в частном случае, а в полной общности
докажу чуть-чуть попозже. Итак, в полной общности теорема Гамельтона Келли говорит вот что. Пусть
phi это оператор на каком-то пространстве v, тогда если я в его характеристический многочлен подставлю
его, мы же умеем в многочлене подставлять оператор, правильно? Вот мы его и подставили, то получится 0.
Удивительное утверждение, потому что мы какой-то взяли определитель, что-то там такое,
сделали, а потом вот в этот многочлен, который получился из определителя, внезапно подставляем
снова характеристический многочлен. То есть снова наш оператор и мистическим образом получаем 0.
Доказательства я сейчас расскажу, но перед тем как я расскажу доказательства, давайте я
расскажу неверное доказательство. Что такое характеристический многочлен? На самом деле,
вот глядите, извините, давайте я сделаю сразу замечание, прежде чем рассказывать неверное
доказательство. Как по-другому можно сформулировать вот это? Естественно, если мы подставляем
характеристический многочлен оператора, если мы подставляем в какой-то многочлен
оператор, если мы подставляем в какой-то многочлен матрицу этого оператора, то,
в результате, естественно и получается какой-то новый оператор, и его матрица в том же самом
базе. Правильно? Потому что мы знаем, что когда мы делаем операции с операторами, то соответствующие
эти операции проделываются и с их матрицами.
Поэтому равносильная форма
теоремы Гамильтона Кэля говорит нам, что если я возьму матрицу размера n на n
над произвольным полем f, то, подставив
ее в ее характеристический многочлен, я получу 0, правда?
Так вот неверное доказательство, давайте я вот этот факт и докажу.
Но мы же с вами знаем, что такое характеристический многочлен матрицы.
Я должен взять определитель a-х на g.
Подставить сюда матрицу a проще простого.
Получится нулевая матрица, естественно, этот определитель равен 0, правильно?
Конец доказательства.
Естественно, упражнение для каждого.
Объясните, почему это доказательство в корне неверно.
Разумеется, доказывать так нельзя, но почему
каждый может ответить самостоятельно,
в частности, спросив, что такое вот этот 0.
Теперь давайте верное доказательство все-таки выясним.
Итак, еще раз говорю, сейчас я доказываю
теорему Гамильта Накэли, в частном случае, то есть при нашем условии,
которое мы с вами ввели. Мы считаем, что характеристический многочлен
раскладывается на линейные сомножечия.
Коль скоро это так, коль скоро характеристический многочлен раскладывается
на линейные сомножители, то в нашем пространстве V
существует тот самый базис E1, и так далее, E, N.
Такой, что все подпространения, которые мы делаем,
они раскладываются на линейные сомножители.
Такой, что все подпространства,
давайте я еще раз это повторяю, чтобы обозначить эти пространства,
все подпространства вида VKT, линейная оболочка первых K
векторов базиса, инвариантная относительно K.
Мне даже сейчас не нужен в явном виде
треугольный вид матрицы, я скорее буду работать с...
А нет, нужен мне в явном виде
треугольный вид, извините, пожалуйста, лучше все-таки с ним.
Можно бы было без него, но давайте все-таки с ним.
Потому что я хочу сказать,
что в этом базисе
phi имеет верхнетреугольную матрицу
с какими-то скалярами на главной диагонали,
и мы знаем с вами, что характеристический многочлен
его это в точности произведения
аµg-x
по g от 1 до m.
Так вот давайте я и буду пользоваться тем,
что наш характеристический многочлен имеет такой вид.
Я докажу следующее несложное утверждение.
Если я...
Извините, я сразу скажу.
Чем нам это хорошо?
Это будет наш оператор phi.
И мы можем сказать, что характеристический многочлен phi,
если я в него подставлю phi, это будет произведение
по g от 1 до n µg-phi.
Теперь обратите внимание, у нас µg-t резко сменила свою роль.
Это кто?
Это оператор умножения каждого вектора на µg-t.
Мы с вами знаем, что как раз если мы многочлен подставляем
любой элемент произвольной алгебры, то все такие равенства остаются верными.
И вот это для нас ключевой факт.
Это формально не очень хорошая вещь.
Мы с вами знаем, что операторы это не коммутируют.
Вот я здесь написал произведение. В каком порядке я должен их писать?
Фи сам с собой коммутирует и с константами тоже.
Поэтому на самом деле здесь все саммножители тоже коммутируют друг с другом.
Поэтому мы можем их писать в произвольном порядке.
Когда мы характеристически многочлены раскладывали на саммножители,
мы могли как для многочлена написать их в произвольном порядке.
В любое такое разложение мы могли бы подставить фи
и получить верное равенство.
Это еще одно объяснение, почему в каком порядке мы эти саммножители не напишем.
Все равно будет правда в произвольном порядке.
Это мы еще доказывали, когда мы с многочленами работали.
Мы говорили, что такое значение многочлена в алгебре.
Мы можем фи подставить в этот многочлен.
Давайте я еще раз очень вкратце объясню, что означает это равенство.
Это равенство означает, что если мы раскроем все скобки,
то с левой и с правой получим одну и ту же многочлен,
одну и ту же запись этого многочлена через степени х.
Все скобки, скобки мы здесь умеем раскрывать,
все сколяры коммутируются с любым фи,
то мы получим ровно такие же записи, в которых вместо х подставлено фи.
На идеологическом уровне это вот так.
С многочленами от оператора мы такие фокусы умеем производить
и мы этим еще неоднократно будем пользоваться,
потому что в равномногочлене мы уже много чего выяснили.
Теперь я говорю несложное утверждение, из которого очень быстро все у вас последует.
Если я μжитое минус фи применю к подпространству вожитое,
то есть к линейной оболочке префикса sg векторов,
то мы попадем в sg минус 1.
Давайте понимать, почему это так.
Для этого нам достаточно выяснить,
почему если я применю мюжитое минус фи
к базисному вектору в выжитом,
то образ попадет в sg минус 1.
Это достаточно проверить для базиса нашего выжитого,
то есть для векторов e1 и т.д. e житое.
Если я возьму какой-то вектор с меньшим номером,
то мюжитое минус фи от какого-то еитого
вот этого вот еитого с меньшим номером,
это у нас мюжитое еитое, какое-то кратное ему,
минус фи от еитого.
И это все лежит в инвариантном от пространства v и t.
v и t, линейная оболочка первых i векторов, у нас была инвариантным,
поэтому фи от еитого туда попадает.
Ну и вот этот товарищ тоже туда, конечно, попадает, правильно?
Поэтому для всех i меньше g мы автоматом попадаем в e1,
т.е. и в g минус 1 тоже попадаем.
Осталось нам понять, что будет такое фи от ежитого,
если мы посмотрим на нашу матрицу.
Координаты фи от ежитого написаны в житом столбце матрицы, правильно?
И это будет сколько-то e1 плюс сколько-то e2,
вот я беру элементы из этого столбца, плюс и так далее,
и когда я доберусь до ежитого, я его должен умножить на мюжитое.
Ну а значит, если я как раз мюжитое минус фи применю к ежитому,
то это у меня будет мюжитое ежитое минус фи от ежитого,
и как раз ежитое у меня сократится, правильно?
Останутся только векторы от e1 до eg-1.
Поэтому это дело лежит в g-1.
Утверждение у нас доказано,
ну а теперь уже и теорему доказать не так сложным.
Итак, мы вернемся к теорему.
Что означает?
Что это значит?
Что это значит?
Это значит, что мы уже перемещаемся к теорему.
Что означает, что какой-то многочлен от phi равен нулю?
Это означает просто, что если я вот этот оператор
применю к всему пространству v,
то получим ноль, правильно? Все векторы должны перейти в ноль.
Давайте понимать, что это такое. Если я характеристический многочлен от phi
применяю к v, записываем наше произведение, давайте я его
вот так вот запишу. Я первый n-1-ый сомножитель оставлю на месте в нашей формуле,
а последний сомножитель выделю отдельно и применю это дело к v, то есть к vn.
По нашему утверждению, вот этот вот товарищ содержится в n-1, правда?
Ну а значит, если я после этого к нему еще применю все остальные операторы, то у меня
получится, что все это дело содержится вот в таком вот безобразии.
Вот vn-1, ну и здесь мы можем сделать тот же самый финтушами, отделяем
последний сомножитель. Извините, mu n-1-и от vn-1. Опять же, применяем утверждение,
получаем, что когда мы применяем к vn-1 вот этот сомножитель, мы попадаем в vn-2.
Ну и так далее. В самом конце мы получим, что мы применяем mu n-1-и
к подпространству v1. По нашему утверждению, мы его к g равному единице
тоже можем применить, только у нас получится v0-е. Кто такое v0-е должно быть?
Это 0, правильно? Потому что мы просто проверим, что фи от е1-го. Смотрите внимательно на матрицу,
фи от е1-го это просто mu 1-е на е1-е, правильно? И значит, mu 1-е минус фи от него будет 0.
Соединяется v0-е, v0-е это 0. Все, мы наше утверждение доказали. Еще раз, суть того,
что произошло здесь, заключается вот в чем. Я беру все наше пространство, применяю к нему сначала
mu n-е минус фи, попадаю внутрь подпространства vn-1, правильно? Применяю к нему mu n-1-е минус
фи, попадаю уже в vn-2 и так далее. Когда я применю все n-сомножителей, я уже обязан попасть в 0.
Таким образом, теорема Гамильтона Келли доказана. Ну и давайте я сразу сделаю замечание, которое
объясняет, почему можно пока поверить в то, что теорема Гамильтона Келли работает не только
при условии, когда характеристические многошления раскладываются на линейные
смножители, но и в любом случае. Замечание, значит, для произвольного оператора,
то есть теорему можно доказать так. Если мы хотим доказать, что его характеристический
многошлен, примененный к нему, равен нулю, это равносильно тому, что характеристический
многошлен его матрицы, примененный к этой матрице, равен нулю, а это матрица фи в каком-то базе.
А это матрица n на n над нашим полем f. И теперь, вот как я уже говорил, но мы пока что еще не
доказали. Вот я использую факт. Существует, так говорят, расширение, или по-другому можно сказать,
над полем k поля f. Мы можем поле f расширить до какого-то нового поля k такое, чтобы характеристический
многошлен этой матрицы раскладывался на линейные смножители над k. То есть,
глядите, у нас А это матрица с элементами из f. Характеристический многочлен ее это,
естественно, многочлен с коэффициентами из f. Но все многочлены с коэффициентами из f являются
также многочленами с коэффициентами из k, правильно? И матрицу А мы тоже можем воспринимать как матрицу
с элементами из k, поскольку поле f вложено в k, правда? Ну, наконец, естественно, вот это стоит
заметить. Если мы начнем ее характеристический многочлен искать над k, то это будет тот же самый
характеристический многошлен, потому что мы будем проделывать те же самые действия, и в наших
вычислениях мы за рамки поля f не выйдем, правда? Ее характеристический многочлен не зависит
рассматривать ее как матрицу над f или как матрицу над k. Но над k-то уже наше утверждение верно,
но над k мы с вами уже знаем, что характеристический многочлен этой матрицы, примененный к ней, дает 0.
Ну и наконец, что у нас тут такое написано? У нас здесь написана какая-то алгебрическая выкладка,
у которой все коэффициенты, все скаляры, которые здесь встречаются из поля f,
значит, это выкладка и в поле f тоже. Для доказательства этого утверждения, обратите,
пожалуйста, внимание, вот для того, чтобы вся вот эта вот машинирия прошла, нам приходится выходить из
поля f, но в результате формула, которую мы докажем, все элементы этой формулы содержатся в поле f,
и значит, она в поле f тоже верна. Вот такой вот финтушами можно провернуть,
и такие рассуждения на самом деле весьма популярны в алгебре. Все, что для него нам нужно, это...
Чего нам не хватает, чтобы мы уметь находить вот этот надполе. Нам нужен вот этот факт,
все остальное мы на самом деле уже сказали. То есть вот теперь наша вера в теорему Гамильтона Кэли
сводится к вере во вполне конкретный факт, более простой, который мы на самом деле через некоторое
время еще и докажем. Ну а пока что теорему мы доказали, как раз пора идти на перерыв.
Так, значит, мы с вами доказали теорему Гамильтона Кэли, и она открывает нам какие-то новые возможности
в исследовании нашего оператора. Оказывается, вот сейчас мы об этом еще немножко поговорим,
оказывается, на то, что происходит с оператором, важное влияние оказывает то, какие многочлены
этот оператор обнуляет. И вот давайте мы немного о подобных многочленах поговорим,
они называются аннулирующими многочленами. Итак, определение. Пусть у нас фи произвольный оператор
на В. Многочлен, ну скажем, П, естественно, над полем, над которым у нас пространство В, да,
вот это всегда полем, над которым пространство В называется аннулирующим для фи, для оператора фи,
если, понятное дело, П от фи равно нулю. Ну, то есть давайте я сделаю замечание, значит, если мы верим в теорему
Гамильта Накэли, то мы получаем, что характеристический многочлен Фи аннулирующий для фи. Но даже если в Гамильта Накэли не верить,
мы пока не знаем, ну, формально мы не знаем полного доказательства для случая, когда многочлены
раскладываются на линейные со множители, правильно? Даже если в теорему Гамильта Накэли не верить,
все равно нетрудно понять, что такой многочлен у нас существует. Даже без теоремы ясно, что такие
не нулевые, естественно, многочлены найдутся. Это можно понять просто из соображений размерности.
Вот, глядите, размерность пространства линейных операторов на В, это то же самое, что размерность
пространства матриц размера n на n, но n естественная размерность В, правильно? То есть эта размерность равна
n квадрат, естественно. Ну а значит, если мы возьмем в этом пространстве следующие n квадрат плюс
один элемент, а именно один, фи, фи квадрат и так далее, фи в степени n квадрат, то эти вот
n квадрат элементов окажутся линейно зависимыми. Ну то есть система из вот этих вот n квадрат
из одного элемента формально, да, линейно зависима. Но если мы эту линейную зависимость запишем,
то мы получим аннулирующий многочлен, правильно? Запись этой линейной зависимости и дает
аннулирующий многочлен. Если мы запишем эту линейную зависимость, то мы скажем, что просто сумма
pi от 0 до n квадрата, правильно? Каких-то альфаитых на фи витый равно нулю. Ну значит,
вот сумма альфаита х витый и есть аннулирующий. Так что без теории Мегамельта Накэлья мы понимаем,
что есть аннулирующий многочлен в степени не выше чего? n квадрата, правильно? А если использовать
теорию Мегамельта Накэлья, то, конечно же, мы с вами найдем аннулирующий многочлен в степени n,
правильно? Потому что характеристический многочлен у нас имеет степень n. Так что даже
аннулирующий многочлен в степени n у нас на самом деле есть, хотя пока что мы это доказали только
для частного случая немного. Еще одно определение. Мы с вами увидели, что аннулирующий многочлен
уж точно есть. Опять же таки пусть фи, это линейный оператор, его минимальный многочлен
это не нулевой аннулирующий многочлен на и меньшей степени. То есть берем все
не нулевые аннулирующие многочлены для нашего фи, выбираем из них многочлен на и меньшей степени.
Давайте мы чуть-чуть сразу этот минимальный многочлен поисследуем. На самом деле для того,
чтобы понять, кто такие аннулирующие многочлены у нашего фи, нам достаточно знать только его
минимальный многочлен. И это мы сейчас первым делом и докажем. Только сначала давайте мы его обозначим.
Обозначается он, раз он минимальный, мюфи. Ну это естественно какой-то многочлен. Еще раз подчеркиваю
минимальный многочлен, конечно же не нулевой. Мы выбираем его из не нулевых многочленов.
Полезное утверждение, пусть фи это произвольный оператор, мюфи его минимальный многочлен,
а п это какой-то его аннулирующий многочлен. Тогда минимальный многочлен делит п. Ну я бы мог
сразу сформулировать. Давайте в качестве замечания скажу, что наоборот, конечно, тоже верно.
Обратное тоже верно. Если многочлен п это мюфи умножить на какой-то ку, то разумеется,
поставив сюда фи, я получаю, что п от фи это мюфи от фи на ку от фи. А этот оператор уже нулевой,
раз мюфи минимальный, то есть аннулирующий. То есть это будет ноль. То есть на самом деле мы
можем сказать, что многочлен является аннулирующим тогда и только тогда, когда он делится на мюфи.
Доказательство этого очень простое. Давайте мы разделим п на мюфи с остатком. Напоминаю,
что мы умеем делить на любой ненулевой многочлен. П это ку умножить на мюфи плюс р,
где степень р строго меньше, чем степень мюфи. Давайте в это равенство опять же таки подставим
фи. Мы опять же таки делаем тот же самый трюк. Мы берем равенство каких-то многочленов,
а потом вот в это равенство в каждый многочлен по отдельности подставляем фи. И вот мы уже говорили,
что тоже должно получиться верное равенство. Это все было у нас зашито в утверждении о том,
как именно мы считаем значение многочленов в свое время. П от фи это будет ку от фи на мюфи
от фи плюс р от фи. Давайте смотреть, что у нас тут написано. П от фи это 0, потому что
п аннулирующий. Мюфи от фи это тоже 0, ну а значит и все вот это вот это тоже 0, правда?
Значит, мы получаем, что r от фи это 0. Как это может быть? r многочлен степени меньше,
чем мюфи, а мю был многочленом минимальной степени, который обнулял наше фи. Мы получили
противоречие с исключением одного случая, когда r равен нулю, правильно? Потому что мы же выбирали
многочлен в минимальной степени из не нулевых аннулирующих. r тоже аннулирующий, r в степени
меньше, чем мю, извините. Значит, r это нулевой многочлен. Ну а это и есть то, что нам было нужно.
Мы поняли, что p делится на мю, потому что остаток у нас нулевой. Это из минимальности мю.
Как следствие, ну как нулевое следствие, вот я уже сказал, многочлен аннулирующий тогда и только
тогда, когда он делится на минимальный. Как следствие, мы можем сказать, что минимальный
многочлен всегда делит характеристический многочлен. Ну во всяком случае, для всех фид,
для которых мы знаем теорему Гаметана Келли, правильно, как обычно? Поскольку характеристически
тогда будет об нулять. А второе следствие, которое хочется сказать, что в принципе у нас в определении
была некоторая неточность. Дело в том, что таких многочленов может быть много. Многочленов
минимальной степени, которые обнуляют фи. Но естественно, на самом деле, все эти многочлены
ассоциированы друг с другом, то есть получаются друг из друга умножением на ненулевой скаляр.
Если мю1 и мю2 это минимальные многочлены для оператора фи, то они ассоциированы. То есть мю1,
это мю2 на какую-то альфу, где альфа не нулевой скаляр. Но это так просто потому, что давайте
быстренько докажем, потому что раз они оба минимальные, то их степени, конечно же, равны,
и при этом один делит другой, правильно? Этот минимальный, этот аннулирующий, значит первый
делит второй. Но если многочлен делит другой многочлен той же самой степени,
то в частном получается как раз константа, правильно? Поэтому минимальный многочлен определен,
но вот так же, как и нот двух многочленов. Он определен однозначной с точностью до ассоциированности,
правильно? Ну и мы обычно через мюфе обозначаем любой из них. Нам не важно какой, главное,
что мы вот его один раз зафиксировали и после этого это обозначение используем.
Так, значит, глядите, что мы с вами поняли? Мы с вами поняли, что минимальный многочлен,
в частности, делит характеристический, то есть, скажем, если наш характеристический
раскладывается на линейные сомножители, то в минимальные многочлены войдут некоторые из них,
правильно? Некоторые из них, и если там те входили в каких-то степенях, то в минимальные они могут
войти в меньших степенях, правильно? Однако давайте заметим, что эта степень не может уменьшиться до нуля.
Давайте мы докажем вот какое утверждение. Пусть у нас есть произвольный оператор и пусть лямбда
это его собственное значение. Тогда лямбда это корень минимального многочлена. То есть,
если какой-то сомножитель вида лямбда минус х сидел в характеристическом многочлене, то и в
минимальном он тоже обязательно будет сидеть, возможно, в меньшей степени, но в не нулевой обязательно.
Доказательства не очень сложные опять же таким. Давайте мы наоборот теперь по собственному
значению выберем собственный вектор. Пусть v это собственный вектор с собственным значением лямбда.
Мы знаем, что каждое собственное значение это ровно то, для которого есть собственный вектор,
но и я напоминаю, что он не нулевой, правильно? Давайте мы ради ясности распишем наш минимальный
многочлен. Пусть это будет альфа катая на х в катой, плюс и так далее, плюс альфа нулевой.
Тогда глядите, какая ситуация у нас получается. Давайте мы вот что сделаем. Может быть,
расписал я это зря. А давайте я лучше, как и раньше, разделю на сей раз уже мюфитое на х минус лямбда.
Напоминаю, что мы при доказательстве теоремы безу уже говорили, что у нас получится мюфитое есть,
какое-то неполное частное на х минус лямбда и плюс какой-то остаток. Но на самом деле,
что такое остаток? Во-первых, он скаляр, правильно? Поскольку мы делим на линейные многочлены,
мы получаем многочлен в меньшей степени, то есть скаляр. А на самом деле, мы знаем,
кто это такой. Это значение нашего многочлена в этой самой лямбде. Просто подставив сюда
лямбду, мы получим то, что тут написано. Это какой-то скаляр. Ну а теперь давайте мы подставим
вот в этого травенства, давайте я для ясности опять же таки напишу, что мы имеем дело с
многочленами от х, а здесь у нас многочленов от х нет, это просто скаляр. И вот сюда теперь
подставим фи. И более того, мы подставим фи сюда, получим какой-то оператор. Хотя давайте сначала
по очереди. Сначала подставим фи, получим, естественно, что мюфи от фи, то есть ноль,
есть какой-то код фи на фи минус лямбда плюс скаляр мюфи от лямбда. А вот теперь этот оператор,
давайте мы применим к нашему собственному вектору В. Если я этот оператор применяю к В,
то с одной стороны применяю к В нулевой оператор и, следовательно, должен получить нулевой вектор.
А с другой стороны я применяю вот этот оператор, код фи, фи минус лямбда, все это от В, плюс скаляр мюфи от лямбда, умноженный на В.
Ну что означает это произведение? Что я к В применяю сначала один оператор, потом другой,
и уже когда я применяю первый оператор, у меня получается нулевой вектор. В, собственно,
и с собственным значением лямбда, это в точности означает, что фи минус лямбда его обнуляют. Вот это
вот уже ноль. Если я к нулю применю произвольный линейный оператор, то, естественно, тоже получу
ноль правильной. Значит, здесь у меня написано ноль плюс мюфи от лямбда на В. Значит, вот этот
товарищ равен нулю, это может случиться только тогда, когда мюфи от лямбда равно нулю.
Ровно потому, напоминаю, что, согласно нашему определению, собственный вектор всегда не нулевой.
Всё, мы наше утверждение доказали. Ну и как следствие, давайте уж мы сразу это дело проговорим.
Как следствие, если выполняется наша любимая формула, если характеристический многошлен фи
раскладывается на линейные сомножители лямбда ИТ минус Х в степени альфа ИТ? Нет. Почему мюфи Т
не обязательно тот же самый? Это не Х, это Хи. Корни могут повторяться в другое количество раз,
правильно? Значит, глядите, если мы с вами знаем, что минимальный многочлен делит характеристически,
делители у вот такого многочлена мы прекрасно знаем. Это произведение всех вот этих вот скобок в
каких-то может быть других степенях, правильно? Меньших, чем альфа ИТ. Так вот, мюфи Т это у нас
будет произведение по И от 1 до К. Этих же самых скобок в каких-то других степенях бета ИТ,
где давайте понимать, что мы знаем про бета ИТ. Бета ИТ, во-первых, не больше, чем альфа ИТ,
чтобы мю делил Хи, правильно? Но с другой стороны, бета ИТ никак не меньше, чем единица. Это вот то
самое утверждение, которое мы с вами только что доказали. Если эта скобка в какой-то степени здесь
была, то она обязана быть и здесь, но, возможно, в меньшей степени, не нулевой. Вот такое важное
утверждение мы с вами получили. Так, замечательно, мы с вами немножко поговорили про аннулирующие
многочлены. Давайте мы сейчас увидим, что они достаточно сильно, что они еще сильнее, чем нам
казалось раньше, влияют на то, как ведет себя наш оператор. Так, успеем мы это, не знаю, успеем ли
доказать самую полезную теорему, но давайте к ней хотя бы будем стремиться. Давайте для начала докажем
вот какое утверждение. Значит, пусть П и Ку.
Одну минутку.
Буквально одну минутку. Да, конечно. Пусть П и Ку это многочлены над нашим полем F, и они взаимно
просты. Ну, то есть их нот равен единице. Ну и пусть Фи, это линейный оператор на каком-то
пространстве В, естественно, над полем F. Тогда вот если эти многочлены взаимно просты, то внимание,
ядра вот таких вот операторов П от Фи и Ку от Фи пересекаются только по нулю. То есть эти два
ядра образуют прямую сумму. Доказательства, ну давайте мы вспомним, что означает, что нот двух
многочленов равен единице. Мы с вами знаем, что если у нас есть нот двух многочленов, то мы его можем
линейно выразить через эти многочлены, правильно? То есть мы можем написать, что это П на С плюс Ку на Т,
где С и Т это какие-то многочлены над нашим полем. Ну и подставив Фи, мы теперь получаем,
что единица есть, давайте я лучше переставлю наши многочлены, С от Фи П от Фи плюс Т от Фи Ку от Фи,
разумеется, правильно? Здесь единица это уже, разумеется, тождественный оператор, правильно?
Ну что у нас равенство в алгебре операторов. Ну а теперь пусть какой-то вектор В лежит и в ядре П от Фи и в ядре Ку от Фи.
Тогда давайте мы применим вот этот оператор, тождественный к нашему вектору В. В левой части раз единица это тождественный оператор,
то мы получим В. А здесь мы получим С от Фи П от Фи, применённый к В, плюс Т от Фи на Ку от Фи,
применённый к В. Ну как и раньше, П от Фи, применённый к В, это уже ноль, потому что вылежит в ядре П от Фи.
Значит здесь у нас получился ноль уже, правильно? В первом слагаемом. И во втором слагаемом у нас тоже получился ноль.
И наше утверждение уже доказано. Ну и давайте я сформулирую следующую уже теорему. Если не успеем доказать,
то докажем в следующий раз, а может даже и успеем. Не так её долго и доказывать.
Итак, теорема. Вот там у нас по ИК были произвольные многочлены. Ну в частности вполне могло быть,
что вот эти вот ядра просто тривиальные, правильные. Утверждение не очень интересное для таких ядер могло
получиться. А вот теперь пойдёт уже интереснее. Ну там тоже интересно, да? Ядра-то могли быть не нулевыми.
Итак, пусть Фи – это линейный оператор, П – это какой-то его аннулирующий многочлен. Мне не важно,
минимальный он или нет. А ИП представляется в виде произведения двух многочленов, которые взаимно просты.
Тогда у меня тут В представляется в виде прямой суммы следующих двух подпространств.
Извините. Разумеется, если нот равен единице, то будет что-то не так. Разумеется, нот равен единице, они взаимно просты.
Тогда В раскладывается в прямую сумму двух ядер, вот таких вот операторов, ну и естественно ВИТ, оба этих ВИТ инвариантны относительно Фи.
Это будет у нас очевидно, но тем не менее. То есть, глядите, что у нас получается, если мы сейчас эту теорему докажем.
Мы с вами взяли какой-то оператор Фи, взяли его аннулирующий многочлен, разложили его на два взаимно простых сомножителя.
Тогда мы пространство В можем разложить в прямую сумму двух инвариантных. Это мы с вами видели уже очень здорово.
Причем, глядите, что получается. Если я возьму, скажем, Фи ограничено ВИТ, то есть Пси первое от ограничения Фи на инвариантное подпространство ВИП,
а Пси второе ограничение на инвариантное подпространство В второе, то что у нас будет?
Мы видим, что если ПИТ от Фи подействует на ВИТ, на любой вектор ВИТ, то получится ноль.
То есть, П первое от Пси первого, это будет уже нулевой оператор.
Просто потому, что ПсиИТ это ограничение Фи на вот такое вот ядро, но и, естественно, П второе от Пси второго тоже будет ноль.
То есть, мы с вами при помощи этой теории, мы что можем сделать?
Мы можем вместо того, чтобы исследовать действия Фи на все пространство В,
теперь изучать действия на два меньших подпространства, на которых у нас есть меньше аннулирующие многочлены,
многочлены меньшей степени, правильно? И они должны быть устроены проще.
Вот в этом прелесть этой теоремы.
Давайте мы ее сейчас докажем.
То, что ВИТ инвариантное, это, извините, не очевидно, а уже было доказано.
Мы с вами доказывали, что если есть два коммутирующих многочлена, Фи и Пси, то ядро Пси инвариантное относительно Фи.
Здесь у нас Фи коммутирует с ПИТом от Фи, правильно?
И поэтому ядро вот этого ПИТого от Фи является инвариантным относительно Фи.
Это, конечно же, понятно.
Более того, по нашему утверждению, которое мы уже доказали,
сумма В1 и В2 является прямой суммой.
Значит, нам осталось доказать, что эта сумма совпадает со всем В.
А для этого давайте мы опять запишем
представление нода П1 и П2, линейное представление вот этого нода.
И применим вот этот оператор теперь к произвольному вектору из нашего В.
Если В это элемент нашего пространства,
то применяя вот это вот самое равенство,
получаем вот что.
Что В есть П1.
А, применяем, потому что не это равенство, а равенство с подставленным ФИ, разумеется, правильно?
То есть мы, как и раньше, подставляем в это равенство Фи,
получаем здесь тождественный оператор.
Даже вот здесь я могу написать от ФИ, от ФИ, от ФИ и от ФИ.
Вот теперь подставляем В, получаем вот это вот плюс П2 от ФИ на Т от ФИ от В.
Давайте я обозначу эти векторы через В1 и В2.
Что я утверждаю?
Я утверждаю, что если применить П2 от ФИ к В1, то что у меня получится?
П2 от ФИ, П1 от ФИ, С от ФИ от В, правда?
Здесь у меня написано не что иное, как П от ФИ.
А П от ФИ это нулевой многочлен.
То есть нулевой оператор, извините, потому что П был аннулирующим многочленом.
Значит, здесь у меня написано не что иное, как ноль.
То есть В1 лежит в ядре П2 от ФИ, то есть В2.
Извините за такую путаницу в обозначениях.
Аналогично В2 лежит в В1.
Итак, что мы с вами доказали?
Мы с вами доказали, что произвольный вектор из нашего пространства В лежит в прямой сумме В1 и В2.
Сумма прямая, это мы доказали.
Каждый вектор там лежит, потому что вот мы его разложили в сумму двух векторов оттуда.
Значит, В1 в прямой сумме с В2 дает В.
Наши утверждения уже доказаны.
Давайте я закончу сегодняшнюю лекцию.
Давайте я оставлю следующее упражнение.
Мы с вами в этой теореме охарактеризовали В и Т как ядра П и Т от ФИ.
На самом деле можно их охарактеризовать и по-другому.
В1 это не только ядро П1 от ФИ, но еще и образ П2 от ФИ.
В2 это будет образ П1 от ФИ.
В качестве подсказки я хочу сразу сказать.
Посмотрите сюда.
Когда мы раскладывали произвольный вектор В по векторам из В2 и В1,
вот этот вектор, который мы получили, лежит в образе П1 от ФИ.
Потому что это П1 от ФИ, примененный к чему-то еще.
А вот этот вектор лежит в образе П2 от ФИ.
Если на это грамотно посмотреть, то это упражнение сразу получается.
Давайте я сформулирую следствие.
А докажем его уже в следующий раз, потому что сейчас звонок произведет.
То же самое верно разумеется и для разложения на несколько совножителей,
если П в тех же самых условиях.
ФИ это линейный оператор, П его аннулирующий многочлен.
Если П раскладывается в произведении нескольких многочленов,
причем нот ПИ и ПЖ это единица при I не равном G,
то есть если эти многочлены попарно взаимно просты,
то тогда пространство раскладывается в прямую сумму ядер соответствующих многочленов.
То есть ядро П1 от ФИ, прямая сумма ядро П2 от ФИ,
прямая сумма и так далее, ядро ПК от ФИ.
Ну и давайте уж я заодно наполню или введу обозначение.
Вот такая вещь кратко обозначается вот таким вот образом.
Следствие докажем в следующий раз.
Здесь еще нужно один небольшой шажок сделать, поэтому нельзя сказать,
что оно сразу очевидно.
А на сегодня все, если есть вопросы задавайте.
Спасибо за внимание.
