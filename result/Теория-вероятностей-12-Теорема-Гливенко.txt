Так, коллеги, напомню, значит, на чем мы остановились в прошлый раз. Мы остановились на теореме
Линберга-Леве. Вот я написал в двух формулировках, чтобы была перед глазами в терминах серии
случайных величин. Вот условия Линберга, следствие, ну, я одно написал, асимпатическая
нормальность. И вот я написал, как я это назвал, в ретро-форме, как она, собственно, была предложена
изначально Линбергам. Ну, следствие тоже. Просто немножко по-другому записывается та величина,
которая симпатически стремится к N01. Это сумма ксикатых минус акатых. Акаты – это мы от ожидания.
Делить на BN. BN в квадрате – это сумма дисперсии. Вот это мы сами в прошлый раз установили. Но тут же
нам, можно сказать, таким призом бесплатным достается следующий факт. Значит, как мы знаем,
сходимость по распределению – это поточечная сходимость во всех точках непрерывности предельной
функции. Поскольку функция распределения N01 непрерывна, это значит, что в данном случае
сходимость по распределению означает сходимость поточечна во всех точках. Причем, обращаю ваше
внимание, что сходимость у нас происходит к функции, которая ограничена и монотонно убывающая.
Вообще говоря, это означает, что сходимость у нас будет равномерная. То есть мы получаем равномерную
сходимость к функции распределения N01 в функции распределения вот этой вот случайной величины.
Функция распределения этой случайной величины при любом N, это же функция распределения, она тоже
ограничена и не убывающая. Последительность ограниченных не убывающих функций, сходящихся поточечно,
сходится в равномерной метрике. Вот этот факт мы дополнительно получаем и еще сегодня про него
вспомним. Но, кстати, то же самое верно и на всюду плотном множестве. Если у нас на всюду плотном
множестве имеет место поточная сходимость, то у нас и равномерная сходимость тоже имеет место на этом
же всюду плотном множестве. Если речь идет о сходимости не убывающих, еще раз повторю, ограниченных
функций, потому что в противном случае это не так. Контр-примеры в мотоналисе существуют.
Вот, ну теперь давайте несколько важных частных случаев. Значит, первый, можно сказать,
хрестоматийный частный случай из теоремы Линберга-Леви, это так называемая центральная
предельная теорема. ЦПТ сокращенно. Центральная предельная теорема. Значит, пусть у нас есть
последовательность ксиенная независимых, но теперь одинаково распределенных случайных величин,
таких что дисперсия кси с одной стороны меньше бесконечности, но с другой стороны строго больше
нуля. Тогда асимпатическая нормальность, то есть выполнение вот этого свойства. Асимпатическая
нормальность. Вот, значит, мы с вами уже с частным случаем этой теоремы в курсе сталкивались. Напомните
мне, пожалуйста, что за теорема у нас была про асимпатическую нормальность еще достаточно
там несколько лекций назад. Давайте как-то общую картину формируем. Какую мы теорему с вами доказывали?
Муаврова пласа. Она относилась к асимпатической нормальности последствия независимых одинаково
распределенных случайных величин, но конкретного распределения. Ксиенная имели какое распределение?
Бернули. Вот. Вот как бы более-более общий случай. Его, кстати, тоже можно доказать с использованием
аппарата характеристических функций, как мы доказывали с вами теорему Мауэрла пласа. Ну,
уж раз у нас есть условия Линдберга, ну давайте просто его проверим для вот такой ситуации.
Воспользуюсь, так сказать, ретроформой вот этой. Так, значит, для независимых одинаково
распределенных случайных величин bn в квадрате это n на дисперсию Сигма. Ну, а мат ожиданий у
не всех одинаковые равно к там некому а, да? Ну, давайте вот перепишем bn в квадрате n дисперсия
кси. Здесь все будут интегралы одинаковые, то есть это n штук. Вот таких интегралов х минус а,
нет индекса, потому что одинаковые мат ожиданий у всех в квадрате. На d f кси от x. Тут индекс
тоже пропадает, потому что они все одинаково распределены. И область интегрирования у них
у всех одинаково. Ну, смотрите, n сокращается, остается вот такой интеграл, что мы про него
знаем. Что если у него бы были бы пределы интегрирования от минус бесконечности до бесконечности,
то чему бы равнялся интеграл? Что это такое по определению? А? Дисперсия. Случайно увлечена
минус мат ожидания в квадрате и ее мат ожиданий. Это была бы дисперсия, которая по условию конечна.
Поэтому если мы интегрируем ее на хвости, как так сказать, да, при bn. А, извините,
здесь уже можно написать явно, прошу прощения, для большей ясности это будет корень из n, корень
из дисперсии кси. Подставлю сразу. Ну и тут видно, что когда для любого tau больше 0a стремится к
бесконечности, интеграл остается только вот хвостиков. Сам полностью интеграл конечен,
потому что равен дисперсии, значит, стремится к нулю. Париан стремяющийся к бесконечности.
И мы получаем, что в частном случае независимых одинаково распределенных случайных величин
выправлено условия Линдберга, следовательно, имеет место асимпатическая нормальность. Вот это,
пожалуй, самая известная теорема, связанная с асимпатической нормальностью. Центральная
предельная теорема. Она ничего ими не носит, поскольку разными, независимо, в разное время,
разными способами доказывалась как некий фундаментальный факт. Вот. Но факт действительно,
во-первых, фундаментальный, а во-вторых, естественно, научный. Я думаю, что, по крайней мере,
когда я был студентом, нам на первом курсе по физике показывали такой опыт. Такая доска с
гвоздями, закрытой стеклом, и туда сыплются шарики. Вам показывают такой опыт? И получается кривая
гауса, нормальное распределение. Это, собственно, демонстрация того, что сумма большого числа
случайных возмущений, каждая из которых небольшая, приводит к асимпатической нормальности. Есть,
как бы, более поэтичные примеры. Вот если взять какую-нибудь средневековую Европу, такую глубокую,
где есть какие-нибудь мраморные или гранитные ступеньки, то вот если на них посмотреть,
то они стерты вот таким образом. Вот это тоже кривая гауса. Сотни лет терли, отклонение всегда
как бы случайное, небольшое, накладывалось. Вот получилась кривая гауса. То есть асимпатическая
нормальность, я еще раз хочу сказать, это не абстрактный математический факт, это объективный
закон, проявляющийся в природе, как любой другой объективный закон. Там, условно говоря, при
увеличении температуры, газ расширяется. Так и вот это вот. Если вы будете накапливать независимые
факторы, каждая из которых не играет решающей роли, это именно условия пренебрежимой малости,
то вы получите в результате нормальное распределение. Броновское движение является тоже таким классическим
примером нормального распределения, точнее говоря, асимпатически нормального распределения.
Вот, значит, центральная предельная теорема. Еще одно важное и полезное следствие, то есть это
достаточно условия асимпатической нормальности. Еще одно важное, с практической точки зрения важное,
с теоретической точки зрения важное, достаточно условие. Это так называемое условие Липунова.
Условие Липунова. Значит, достаточно условия в форме Липунова. Пусть у нас есть такое число,
дельта больше нуля, со следующими свойствами. Сумма математических ожиданий кси КТ минус а КТ в
степени 2 плюс дельта, К от единицы до n, делить на bn в степени 2 плюс дельта, стремится к нулю,
прям стремяющих к бесконечности. Вот, предположим, мы нашли такое дельта, то тогда асимпатическая
нормальность имеет место. Ну, не сказал явно, но здесь укажу. Ксиенная, как обычно, независимые
случайные величины. Независимые случайные величины. Ну и подразумевается, конечно,
что моменты вот этого порядка абсолютно и существуют. Давайте это условие докажем,
тоже опираясь на условия Линдберга, как я говорю, в ретрофор. Давайте его собственно запишем,
еще раз перепишем, чтобы удобно было.
И давайте, ой, извините, что это меня на верхние индексы потянуло. И давайте обратим внимание на
то, что в области интегрирования х минус а КТ по модулю делить на тау бн больше единицы. Поэтому
я могу смело написать, что это меньше или равно единица на бн в квадрате, сумма КТ единица до
н интеграл. Здесь напишу х минус а КТ по модулю в степени 2 плюс дельта, а здесь напишу тау в
степени дельта, бн в степени дельта. Понятно, да? Здесь сносочку х минус а КТ по модулю делить на
тау бн в степени дельта, которая больше нуля, больше единицы, ну может равно. Вот так вот, да? Равно,
а область интегрирования здесь важна, она у нас еще пока вот такая. Так, ну напишу,
меньше или равно, меньше или равно. Под интегральное что-то теряю. Под интегральное
выражение не отрицательное, поэтому если мы расширим область интегрирования до всей оси,
интеграл только увеличится, поэтому меньше или равно. Тут сразу сделаю такие преобразования.
А здесь останется сумма интегралов х минус а КТ в степени 2 плюс дельта по модулю по всей
области df КТ от х, КТ единицы dn. Правильно, да? Вот это что по определению? Ну вот же оно.
Правильно? Математическое ожидание кси КТ минус а КТ в степени 2 плюс дельта. Ну и поэтому
пишу единица на тау в степени дельта, которая ни на что не влияет, и, собственно, условия Липунова.
Если вот это стремится к нулю, то выполнено условие Линдберга и, следовательно,
имеет место симпатичная нормальность. Значит, первое, зачем мы про это помним, так сказать,
и еще такое именное имеет значение. С точки зрения практических вычислений, вычисления вот этой дроби
Липунова, так называемой, оказывается проще, чем проверка условия Линдберга. Это техническая
составляющая, но есть еще глубокая теоретическая составляющая. Вот для случая дельта равно одному,
вот эту, собственно, вот это называют дробью Липунова, которая имеет просто вид такой ксикатая
минус аккатая в третий, а в знаменателе будет сумма дисперсий ксикатых в степени 3 вторых.
Ну вот, если вот это стремится к нулю, то, во-первых, асимпатическая нормальность,
вот эту дробь Липунова, прям у нее специально есть обозначение L3. Зачем оно нужно? Оказывается,
что имеет место вот такое довольно сильное неравенство, что в равномерной метрике f это
n от x отклонится от f 0.1 от x supremo по x на величину, не превышающую некую константу на L3.
Ну, когда у нас n увеличивается, мы знаем, что имеет место поточная сходимость. Более того,
мы знаем, что имеет место равномерная сходимость, то есть сходимость такой метрики имеет место.
Но какова скорость этой сходимости? Вот результат. Кстати, константа c меньше единицы, типа 0,8.
Она тоже вычислена. Ну и дальше вот какое замечание. По странному стечению обстоятельств,
вот этот результат Липунова как-то не очень популярен, в учебниках не поминается, в том числе
и как бы таких больших. Но его частный случай, когда x независимо одинаково распределенные
случайные величины, очень даже популярен в этом случае, как нетрудно убедиться. L3 равно,
принимает вид. Все одинаково распределены, значит здесь n штук математических ожиданий,
кси центрированных по модулю в кубе. Дисперсии тоже все равны, это значит n корень из n,
дисперсия кси в степени 3 вторых. Вот этот n сокращается, ну и остается, собственно,
вот такая величина со скоростью единицы на корень из n, стремяющаяся к нулю. Это когда кси n
независимо одинаково распределенные величины. И вот неравенство для независимо одинаково
распределенных величин, вот с такой величиной L3, называется неравенством Берри Эссона.
Берри Эссона, хотя является частным случаем неравенства Липунова и появилось лет на 50 позже.
Ну, тем не менее, вот это в большинстве учебников есть, а вот собственно исходника в большинстве
учебников нет. Ну, тем не менее, это такое лирическое отступление. Условие Липунова
для симпатической нормальности выглядит вот так. Практически используется в большинстве случаев,
когда дельта равна единице, и тогда выглядит вот так. Ну и скорость вот этой равномерной исходимости,
которая так здесь имеет место, вот она имеет порядок единицы на корень из n для независимых
одинаково распределенных случайных величин. Пошли дальше. Наверное, я теперь тут почти
все могу стереть. Ну, здесь несколько слов надо сказать. Значит, смотрите,
мы с вами установили, получили достаточно фундаментальные законы симпатической нормальности
для серий случайных величин, но еще на прошлой лекции мы с вами получали другое предельное
распределение. Какое? Теорема у нас была соответствующая, ненормальная, так сказать.
Какое было у нас предельное распределение? Пуассона. То есть мы с вами доказали сходимость
неких серий к распределению пуассона. Ну, теперь возникает вопрос. В распределении пуассона мы
тоже брали серию Бернульских случайных величин. С одной стороны, Бернульские случайные величины
асимпатически нормальные. Это теорема маврового пласа или, так сказать, центральная предельная
теорема. С другой стороны, так сказать, те же Бернульские случайные величины асимпатически
имеют распределение пуассона. В чем дело? Как так? Весь вопрос в том, как мы переходили
к пределу. Для асимпатической нормальности характерная форма вот. Вы берете, например,
одинаково распределенные случайные величины и определенным образом их нормируете. А в распределении
пуассона, если вы посмотрите по условию, у нас с ростом n менялось распределение вот этих секатах.
Вероятность успеха становилась еще меньше и меньше таким образом, что n умножить на pn
стремилась к лямдо. Разные предельные переходы получились разное распределение. То есть никакого
здесь противоречия или парадокса нет. Причем надо сказать, что и нормальное распределение,
распределение пуассона это довольно часто встречающиеся в жизни. Про примеры
нормального распределения я вам сказал, а про распределение пуассона приведете мне
какой-нибудь пример. Какой физический эксперимент, ну там мы описываем, мы это хорошо теоретически
подтверждается, описывается распределением пуассона. Знаете какой-нибудь?
Длина свободного пробега имеет показательное распределение, экспоненциальное. А пуассонское
распределение имеет количество частиц, зарегистрированный счетчиком Гейгера. Это
вот классический, так сказать, физический процесс, который и описывается моделью пуассонское
распределение и очень хорошо и соответствует. И, грубо говоря, имеется теоретические основания,
чтобы это распределение было именно такое. Вот так, значит сейчас я вернусь немножко назад, за мной
был должок вторая теорема Колмогорова усиленного закона больших чисел. Мы это сделаем, потому что
он нам сегодня понадобится для дальнейшего. Итак, значит вторая теорема Колмогорова.
Напоминаю, значит, если ксиен средняя, значит ксиенная теперь это независимо одинаково
распределенные случайные величины. Во второй теореме Колмогоров, в первой теореме это просто
независимые случайные величины, во второй это независимо одинаково распределенные. Значит,
если ксиенная сходится к А почти на верное или для того, чтобы необходимой достаточно существование
математического ожидания кси равного А. Если среднее значение к чему-то сходится, то это и есть
мат ожидания, но, разумеется, независимо одинаково распределенных случайных величин. И если у вас
есть мат ожидания, то ксиенная средняя сходится к нему. Вот, собственно, утверждение о теореме
Колмогорова. Есть более слабый, как аналог этой теоремы, относящийся к другому типу сходимости и
только в одну сторону достаточно условия. Что это за теорема? Коллеги, я вас спрашиваю, чтобы как-то
побудить у вас некую целостную картину сформировать. Это была теорема Хинчина,
которая утверждала, что для системы независимо одинаково распределенных случайных величин
существование мат ожидания является достаточным условием выполнения закона больших чисел,
не усиленного, а просто закона больших чисел. Надо сказать, что теорема Хинчина, частный случай
теоремы Колмогорова, в том числе и потому, что из сходимости почти, наверное, следует сходимость
по вероятности. Но, как сказать, она нам сегодня сослужит некую добрую службу, упростит некие
наши рассуждения, поэтому вспомним про нее. Итак, ну давайте-то, кстати, начнем. Так, первое,
существует математическое ожидание кси меньше бесконечности. Первое утверждение, которое я отсюда
делаю или напоминаю вам, что и мат ожидания модуль кси существует и меньше бесконечности,
правильно? Поскольку в интеграле ли бега, модуль и сама функция одновременно либо интегрируемы,
либо не интегрируемы. То есть, это мы уже начали доказательств, это не условие, это я напомнил. Так,
ну и вот, собственно, теперь можно сказать ключевая идея доказательства, принадлежащая Колмогорову и
введенному им понятию усеченных случайных величин. Ведем случайные величины ксиенная со
звездочкой по следующему правилу. Ксиенная со звездочкой в точности равно ксиен, если
ксиен по модулю меньше n и нулю иначе. Ну, то есть, ксиенная по модулю больше равно n.
Вот, вот как-то ключевая идея доказательства. Что мы сейчас сделаем? Мы сейчас с вами докажем,
опираясь на первую теорему Колмогорова, что вот для таких случайных величин выполнен усиленный
закон больших чисел. Обращаю ваше внимание, что они уже не одинаково распределены, вот эти случайные
величины, но остались независимы, разумеется. Так, для этого давайте возьмем дисперсию кси n со
звездочкой. Эта дисперсия, конечно, меньше от ожидания ксиен со звездочкой в квадрате,
а этом от ожидания есть интеграл от x квадрат df кси от x, взятый по области x по модулю меньше n.
Правильно? Ну вот здесь вот прием, которым мы будем сегодня неоднократно пользоваться,
мы разобьем этот интеграл на сумму интегралов такого вида x по модулю меньше k плюс 1,
больше или равно k, k от 0 до n минус 1, x квадрат df кси от x. Понятно, почему здесь n пропало,
кстати? Здесь было, здесь не стало. Ну понятно, значит хорошо. Так, разобьем на такую сумму и вот
дальше напишем следующее. Меньше или равно k равно 0, n минус 1, k плюс 1 в квадрате по свойствам
интеграла Либега на df кси от x, x меньше k плюс 1, больше или равно k. Вот этот интеграл,
вот этот интеграл, это же на самом деле вероятность того, что случайная уличина
кси меньше k плюс 1, больше равно k. Правильно, да? Нам сегодня много раз надо будет с этим,
как бы, такими интегралами работать в разных эпостасиях, поэтому я введу для него короткое
обозначение. Вот так вот k, k плюс 1. Слева закрыт интервал, справа открыт. Видите, да? То есть
вот этот интеграл, вероятность такого события, я буду просто вот так обозначать. Это чисто
обозначение, чтобы чуть-чуть сократить записи. Ну и таким образом просто перепишу, чего у нас
получилось. У нас получилось, что дисперсия ксиенного созвездочка меньше или равна сумме k от 0
до n минус 1, k плюс 1 в квадрате, k, k плюс 1. Вот. Так, перехожу сюда.
Теперь рассмотрим вот такую сумму. Дисперсия кси n созвездочкой делить на n квадрат.
И что такое? К чему это мне? Это от чего условия? Ну вот такой ряд появляется. Где? Ой, коллеги,
что-то у вас как-то как стирается все к следующей лекции. Это первая тярема Колмогорова. Если такой
ряд сходится, то последность ксиенная почти, наверное, сходится. Для него выполнен усиленный
закон больших чисел. Ну, пишу, меньше или равно единица на n квадрат, а вместо дисперсии ксиенного
вот напишут эту штуку. k равен 0 до n минус 1, k плюс 1 в квадрате, k, k плюс 1. Вот. Значит,
вот получили некий ряд. Все его члены не отрицательные. То есть, если он сходится,
то он сходится абсолютно. Если сходится, если ряд сходится абсолютно, то в нем можно как угодно
переставлять члены. От этого сумма ряда не изменяется. Ну и таким образом, если после
перестановки членов мы получим сходящийся ряд, это как раз и будет означать, что вот этот ряд
тоже сходится. После произвольной как нам удобно перестановки членов. Значит, давайте я вот здесь
вот чуть подробнее напишу, чтобы как бы так не в голове все прокручивать такие крокодилы. Значит,
n равно 1. Давайте посмотрим, что получается. Получается 1 на 1 в квадрате. Когда n равно 1,
k принимает только одно значение 0. Значит, это будет 0,1. Теперь, если n равно 2, то будет 1 на 2 в
квадрате. Первая слагаемая вот в этой сумме тоже будет, ну так напишу здесь, 1 в квадрате. Там
все-таки k плюс 1 в квадрате. Значит, 1 в квадрате 0,1 плюс, когда n равно 2,
еще член появляется 1, это значит будет 2 в квадрате на 1, 2. Вот так. И так далее.
Ну, теперь хочу вот так перепаковать. Давайте я сейчас запишу и мы посмотрим, прав ли я.
Сумма k равно от 0 до бесконечности, k плюс 1 в квадрате k, k плюс 1 на сумму 1 на n квадрат,
вот тут главное правильно начать. n равно k плюс 1 до бесконечности. Посмотрите, пожалуйста,
правильно, да? Сделал я все. Вот этот ряд вот так перепаковал. Здесь начнется 1 в квадрате 0,1 и
квадраты, обратные квадраты начиная с единицы. Следующий ряд начнется 2 в квадрате на 1, 2 и
обратные квадраты уже с 2. То есть то, что у нас k плюс 1. Вот с k плюс 1 обратные квадраты пошли.
Так, теперь вот такая немудренная аналитика. Выделим член k равно 0. Тогда это будет значит 0,1,
0,1. А вот здесь будет ряд единицы на n квадрат от единицы до бесконечности. Чему такой ряд равен?
Совершенно справедливо. Но на самом деле нам даже не сильно надо, но как бы хорошо,
что помните. Ну и плюс то, что осталось k от единицы до бесконечности, k плюс 1 в квадрате,
к, к плюс 1, сумма единицы на n квадрат, n равно k плюс 1 до бесконечности. Ну теперь первый ряд
будет начинаться с двойки. Так, значит смотрите, простенькая картиночка. Единица на n квадрат,
на x квадрат, единица на x квадрат. Ну вот, например, когда вот k, а вот k плюс 1. Вот нам
нужно k плюс 1 в квадрате. Это вот такой столбик. Дальше пошло так далее. Ну и собственно видно,
что вот этот ряд, когда k начинается с двойки, он, ну напишу, меньше или равен,
перепишу. Так, π квадрат на 6 я заменю на тройку, поймете почему. На тройку заменил,
на большую величину. Вот, значит здесь остается k от 1 до бесконечности, k плюс 1 в квадрате,
k, k плюс 1. А вот здесь это будет интеграл от k до бесконечности dx на x квадрат. Согласны? Вот.
Так, так, так, наверное. Не знаю, куда переместиться. Можно сюда? Мы уже использовали то, что нам нужно здесь.
Так, значит меньше или равно, напишу здесь. Ну или сейчас пока, ну да, меньше или равно. Меньше или
равно 3 на вот этот наш объект 0,1 плюс сумма k от 1 до бесконечности, k плюс 1 в квадрате делить на k и умножить на k,
k плюс 1. Понятно, да, откуда единица на k взялась? Потому что это интеграл в районе единицы на k.
k больше единицы у нас. Ну, кстати, как, если мы даже не помнили, что сумма обратных квадратов это
пи квадрат делить на 6, то мы знаем, что ряд, который начинается с 2, он меньше единицы. Ну и первый
член этого ряда единица, то есть вот это как бы двойка заведома. Мы заменили на тройку. Так,
это звонок, да? Ну давайте вот на этом месте остановимся. И так, значит, мы с вами получили,
что вот этот ряд с учетом вот этого свойства и вот этой вот оценки, которую мы как бы нарисовали,
он имеет вот такой вид. Отдохните. Так, коллеги, чтобы двинуться дальше, вот такое напишу тривиальное
утверждение, что k плюс 1 в квадрате делить на k меньше или равно k плюс 3. Для любого k больше
или равно единицы. Поэтому воспользуюсь здесь этим и напишу, меньше или равно. Эту троечку
сразу вытащу. Меньше или равно 3 суммы вот этих наших множеств типа k, k плюс 1, k от нуля до
бесконечности, плюс k, k плюс 1, k от единицы до бесконечности. Вот эта сумма чему равна?
Единицы. Да, значит, это вероятность того, что модуль нашей случайной величины попадет или от нуля
до единицы, это одного до двойки, от двойки до тройки, это единицы. Вот поэтому пишу это пока
напишу равно. Тройка плюс, а вот здесь напишу сумма k. Вернусь, что это такое. Это dfc от x по области
x меньше k плюс 1 больше или равно k. И знаете, пожалуй, чтобы два раза не переписывать...
Нет, нет, нет. Было k плюс 1 в квадрате делить на k, мы заменили на k плюс 3.
Прошу прощения. Конечно, прошу прощения. Так вот, чтобы два раза не переписывать,
я все-таки здесь поставлю меньше или равно, а здесь напишу с k равного нуля. Можно было и равно,
потому что с k равным нулю это 0. Ну ладно. А теперь пишу следующее. Меньше или равно
3 плюс сумма k от нуля до бесконечности, интеграл, модуль x, dfc от x, x по модулю меньше k плюс 1
больше или равно k. А вот это что такое? Совершенно справедливо. Это математическое ожидание модуля
psi, который у нас существует и меньше бесконечности. Таким образом, мы с вами показали,
что вот это вот, вот это вот, начали мы отсюда. Вот эта сумма меньше бесконечности при условии,
что существует мат ожидания. И тогда по первой теореме Колмогорова мы можем утверждать следующее.
Сотру вот, вот это могу стереть, да? Думаю.
Вот в такую форме запишу первую теорему Колмогорова.
psi n со звездочкой средняя минус математическое ожидание psi n со звездочкой средняя,
сходится к нулю почти, наверное, при n, стремящемся к бесконечности. Вот факт,
который мы с вами сейчас доказали. Так, а теперь давайте исследуем вот такой ряд. Вероятность того,
что psi n со звездочкой не равно psi n. n от единицы до бесконечности. И исследуем его на счет
сходимости. Вот вопрос в этом. Вот это? Это вероятность того, что случайная величина
принадлежит от минус бесконечности до бесконечности. Потому что вот это вот,
одна из форм этой записи, это вероятность того, что psi меньше k плюс 1 больше равно k. Ответил наш
вопрос. Так, значит, кто мне скажет, зачем, вот почему меня это заинтересовало? Такая сумма. Отвечу. Если
такой ряд сходится, то по Lemme-Barrelli-Cantelli это означает, что psi n со звездочкой не равно
конечное число раз с вероятностью единицы. Припоминайте Lemme-Barrelli-Cantelli. Если я это докажу,
то я могу утверждать, что с вероятностью единицы ряды psi n со звездочкой и просто psi n отличаются
лишь на конечном числе членов. А это вообще означает, что у них одинаковое среднее
арифметическое. При этом стремясь к бесконечности. Вот, поэтому вот этот факт мне сильно поможет.
Давайте я с ним разберусь. Так, значит, вероятность того, что psi n со звездочкой не равно psi n, это на самом
деле вероятность того, что кси по модулю будет больше или равна n. Правильно, да? Здесь я тоже
воспользуюсь разбиением на вот такие блоки. Нет, именно кси. Потому что все независимые одинаково
распределены. Я могу поставить кси n, но в исходные последствия. А зависимость от n неявная. Вот она.
Кси n со звездочкой это зависит от n, поэтому как-то это должно зависеть от n, так это зависит от n через
вот эту. Так, это тогда будет сумма. Тут просто мне не ошибиться. Значит, вот этот наш объект очень
удобный для записи k, k плюс 1, k равно от n до бесконечности. Правильно, да? n, n плюс 1, n плюс 1, n плюс 2 и так далее.
Кси больше или равно n. Вот. Так, ну и тогда, собственно, давайте ряд теперь из этого составим.
Кси n это равно ряд n равно 1 до бесконечности. Сумма k, k плюс 1, k равно n до бесконечности. Ну,
вот тут вот тоже картинку нарисую. При n равном единице это будет 1, 2, плюс 2, 3, плюс и так далее.
Это n равно 1. n равно 2. Это будет вот 2, 3, плюс и так далее. То есть это на самом деле сумма n равно
1 до бесконечности или k равно 1 до плюс бесконечности. Вот давайте как-то привыкли к этому индексу,
который разбивает у нас случайно в личину k. k от 1 до бесконечности, k на k, k плюс 1.
Да? Правильно? И вот сюда смотрим, мы уже такую штуку делали. Вот она,
то же самая сумма, поэтому все это меньше, ну пусть или равно, в от ожидания модуль кси. Правильно?
Нет вопросов. Так, ну вот собственно существенный факт. Ну а теперь немножко, как говорится,
поднапряжемся. Вот это теперь можно уже стирать. Мы получили, чего хотели.
Ну может просто чтобы было понятно, я вот здесь внизу напишу, вероятность номера омега таких,
что кси n со звездой от омега не равно кси n от омега, конечное число раз, вот здесь,
раз, равна единице. Вот словами там или как-то полусловами записано утверждение
Лемма-Борреля-Кантелли. Вот. Ну и значит смотрите, берем омега из вот этого множества единичной
меры и что нам известно, что кси n со звездочкой от омега сходится к, точнее говоря, не сходится,
минус, минус математическое ожидание кси n со звездочкой, среднее, среднее вот здесь,
среднее, сходится почти, наверное, к нулю. Правильно, да? Для всех омега из вот этого
множества единичной меры, это сходимость почти, наверное. Кси n со звездочкой, средняя и просто
кси n от омега имеют один и тот же предел, поэтому кси n средняя для этого же омега,
минус вот эту штуку тоже сходится к нулю, почти, наверное, до приема стремящейся к бесконечности.
Ну, можно повозиться и поискать вот этот предел приема стремящейся к бесконечности, вот этот вот.
Математическое ожидание у средненных случайных величин одинаково распределенных. Но здесь мы
можем поступить и по-другому, воспользовавшись теоремой Хинчина. По теореме Хинчина мы знаем,
что независимые одинаково распределенные случайные величины, если существует мат ожидания,
сходится по вероятности мат ожиданию кси. Значит, вот эта штука не может сходиться ни к чему другому,
как к мат ожиданию кси, которая равно а, правильно? Потому что, если бы она сходилась к чему-то другому,
то у нас кси n средняя сходилась бы к некому числу, отличному от мат ожидания, почти,
наверное, а значит, сходилась бы к этому же числу и по вероятности. А по вероятности она сходится к мат
ожиданию кси этой теоремы Хинчина. Поэтому кси n средняя, почти, наверное, сходится к числу а,
которая равно мат ожиданию, почти, наверное. Итак, если существует мат ожидания, то последствия
независимо одинаково распределенных случайных величин сходится к некому числу, сходится к своему
мат ожиданию. Теперь давайте предположим, что нам известно, что кси n сходится к некоему
числу а, который мы не знаем, равно мат ожиданию, неравном мат ожиданию, и мы, так сказать, поймем,
к чему она может сходиться. Так, ну давайте, так вот буду по модулю два так вытирать все.
Пусть нам известно теперь, что кси n средняя сходится почти, наверное, к некоему числу а.
Ну тогда я вот так напишу. Кси n делить на n равно сумма ксикатых k от 1 до n делить на n
минус сумма ксикатых k от 1 делить на k от 1 до n минус 1 делить на n. Вот что это такое.
Ну еще вот это второе, как это, вычитаемое, умножу на n минус 1 делить на n минус 1, то есть на
единицу. Значит, смотрите, вот эта штука по условию сходится к а, почти, наверное. Вот это
выражение сумма n минус 1 член делить на n минус 1 тоже сходится к а, почти, наверное,
при n стремящейся к бесконечности. Ну и остается множитель n минус 1 делить на n,
который при n стремящейся к бесконечности стремится к единице. Поэтому вот кси n делить на n сходится
к нулю, почти, наверное. Правильно, да? А теперь вот такое утверждение. Если кси n делить на n сходится
к нулю, почти, наверное, то вот такой ряд меньше бесконечности. Откуда это следует?
Это вторая часть Lema-Barrelli-Cantelli или теоремы. Поскольку кси n все независимы, то если бы этот
ряд расходился, то это бы означало, что событие кси n делить на n больше единицы встречается
бесконечное число раз с вероятностью единицы. Но если кси n делить на n с вероятностью единицы
сходится к нулю, то у нее не могут встречаться члены сколь угодно далеко, которые больше единицы.
Согласны? Таким образом, из того, что кси n делить на n почти, наверное, сходится к нулю и кси n
независимой, следует сходимость вот такого ряда. Ну теперь я делаю следующее. Пишу бесконечность
больше. Такой чисто формальный член вероятность того, что кси по модулю больше равно нулю, это единица,
просто единичку. Ну и плюс вот этот сходящийся ряд n равно единицы до бесконечности, вероятность того,
что кси n по модулю больше или равно n. Но теперь мне будет удобно загнать все под общую сумму n от
нуля до бесконечности, вероятность того, что кси по модулю, индекс n здесь убрал, больше или равно n.
Понятно, да? Почему индекс убрал? Так, мы уже такую штуку делали, вот она, она, только будет немножко
здесь по-другому, поскольку n с нуля будет начинаться, здесь будет 0, 1 плюс, здесь будет 1, 2 плюс и
так далее. То есть это, если я все перепакую, то это будет сумма k плюс 1, k, k плюс 1, k от нуля до
бесконечности. Посмотрите так. Так, да? Вот. Ну а теперь уже, честно говоря, стандартный прием k от нуля до
бесконечности, k плюс 1, интеграл х по модулю меньше k плюс 1, больше или равно k, df кси от x,
больше или равно сумма k от нуля до бесконечности, интеграл модуль х, df кси х, область интегрирования
х меньше k плюс 1, больше или равно k. Так, это мы уже с вами, с таким объектом сталкивались, это чего?
Это математическое ожидание модуль кси. Видите, да? Вот. Итак, если к чему-нибудь,
к какому-то числу сходится, почти, наверное, последствия независимых одинаково распространённых
случайных величин, то обязательно существует мат ожидания. Ну и опять, так сказать, тот же фокус
с теоремой Хинчина. Итак, ксиенная средняя сходится к а, почти, наверное. Ксиенная средняя по теореме Хинчина,
раз есть мат ожидания, мы это доказали, сходится по вероятности в мат ожидания кси. Ну и отсюда
следует, что а равно кси, мат ожидания кси. Вот теорема Калмагорова. Вторая. Завершили доказательства.
Нет вопросов. Ну, что скажешь, немножко длинновато и где-то нудновато. Ну вот,
тем не менее, вот такое красивое доказательство с использованием, ещё раз повторю, введённой
Калмагоровым специального, так сказать, приёма усечённыхся случайных величин. Вот,
так сказать, получили ответ. Всё. Тогда, значит, я стираю всё и мы двигаемся дальше. Собственно,
нам осталось не так уж и много. Так, следующая лекция 10-го числа у нас последняя, как и планировали.
Ну, точнее говоря, не как планировали, а как распорядилась судьба. Вот. Так,
ну это пока оставлю. Может быть, так сказать, кто-то ещё смотрит, размышляет и записывает. Так,
значит, следующая наша цель – это доказательства теоремы Глевенко. Это тоже фундаментальная
теорема теории вероятностей. Глевенко – наш соотечественник, выпускник Московского
университета. К сожалению, умер там в раннем возрасте, в сорок с небольшим лет. Но оставил
после себя две именные теоремы. Одну в теории вероятностей, а вторая в теории, как-то назвать,
а там логики исчислимости, вычислимости и исчислимости. Вот. Значит, то есть в разных
областях две именно теоремы. Ну, прямо скажем так сказать, грассмейстерский результат. Вот. Но
до теоремы Глевенко нам нужно изучить ещё один очень, как бы, такой важный объект, с которым вы
там неоднократно столкнетесь в последующем. И я, может, где-то так сказать, ну, по крайней мере,
на уровне терминов дам намётки. Значит, напомню, как мы вводили случайную последовательность.
Каждое Омега мы ставили в соответствие кси-н от Омега. Каждой такой последовательности мы можем
поставить в соответствие такие серии. Кси-один от Омега. Первая серия. Вторая кси-один от Омега.
Кси-два от Омега. И, наконец, там какой-нибудь кси-к от Омега. Ой, кси-один от Омега. Так далее кси-к от Омега.
То есть, если есть Омега, то вот ставим в соответствие такие серии. Через случайную последовательность.
И каждой такой серии мы можем поставить в соответствие некую функцию. Это будет f1 от x. Вот здесь будет f2 от x. А вот здесь будет fk от x.
Некую функцию. По следующему правилу. fn от x равно 1n сумма. А, прошу прощения, это важный факт. Вот мы говорим
о последствиях независимых одинаково распределенных случайных величин. Пометьте, это важно. Независимые одинаково распределенные случайные величины.
Функция fn строится по правилу. 1n индикаторная функция события. x kt меньше x. Ну и k от единицы до n. Я ее прям обведу в рамочку.
Несмотря на такую простоту, это очень важный объект. Принципиально важный для математической статистики. Понятно, да, как он строится?
Есть Омега, получается последовательность. Из этой последовательности строим серии. Вот такие по правилу, так сказать, треугольника.
И каждой такой серии ставим соответствия уже функцию от x. Вот последующему правилу.
Значит, эта функция называется империческая функция распределения. Это термин. Империческая функция распределения.
И она обладает рядом замечательных свойств. Одной из этих свойств составляет содержание теоремы Гливенко, к которой мы, так сказать, подойдем.
А пока давайте вот на что обратим внимание. Давайте посмотрим. Вот зафиксируем x, любой, для любого x, но зафиксируем.
Давайте найдем предел, почти, наверное, fn от x.
Есть идея?
Ну, смотрите, все каты одинаково распределены, поэтому вот эти все индикаторные функции, это тоже случайные величины, одинаково распределенные.
Значит, и мы имеем с вами дело среднеарифметическое одинаково распределенных случайных величин.
Значит, по второй теореме Колмогорова, если это к чему исходится, то к чему? К мотожиданию вот этой индикаторной функции.
А это что такое? А это вероятность того, что x меньше x. А это что такое?
Это функция распределения.
И вот первое удивительное для такой простой функции свойство.
Эта функция для каждого фиксированного x, почти, наверное, сходится к функции распределения, которая, может быть, нам неизвестна.
Мы с вами, когда говорили о всяких физических законах, связанных с концентрацией меры, мы там говорили, что средние значения вокруг мотожидания.
То есть у нас есть как бы экспериментальный способ найти мотожидание.
Там нормированные какие-то величины тем или иным способом концентрируются вокруг соответствующего закона распределения по асоновского или нормального.
Но вообще говоря, случайная величина в нашей теории отождествляется всего функцией распределения.
Таким образом, империческая функция распределения представляет нам экспериментальную базу для того, чтобы найти функцию распределения неизвестной нам случайной величины.
Вот какое-то явление природное может быть описано случайной величиной.
Причем, возвращаясь, грубо говоря, к самому началу нашего курса, есть, особенно в квантовой физике, вещи, которые принципиально так описываются.
Это не модель, они как бы по сути такие.
И у нас просто есть механизм. Мы ничего не знаем, какая распределена случайная величина.
Но если у нас есть экспериментальные данные, они независимы, одинаково распределены, это, кстати, из одного и того же природного явления, или эксперименты их черпаем,
то мы можем почти, наверное, с вероятностью единица построить оценку функции распределения, которую называют в данном случае гипотетической.
Империческая функция распределения для любого х почти, наверное, сходится к гипотетической функции распределения.
Вот такой вот крайне важный факт, который открывает нам возможность экспериментального описания случайной величины.
Повторюсь еще раз, ведь случайная величина – это не число, это ее функция распределения. Если вы знаете функцию распределения, вы все знаете о случайной величине.
Но это не все свойства этой случайной величины.
Следующая.
Ну, например, у вас есть там показания счетчика Гейгера, там, не знаю, 100 у вас счетчиков или 200, и они там, грубо говоря, стоят в соседних комнатах.
Вы получаете значение, вы знаете модель, что это случайная величина, количество частиц зарегистрированное.
Вы берете эти числа и по такой формуле для каждого х, с каким-то шагом, строите эту функцию.
Я ответил наш вопрос?
То есть если это рассматривать как экспериментальные данные, а не случайные величины, ну вот это и дает нам, грубо говоря, модель эксперимента.
Мы считаем, что мы наблюдаем некие случайные величины, ну исходим из того, да, и хотим знать функцию распределения, а наблюдаем мы, ну, просто, так сказать, какие-то, ну, разрозленные числа, грубо говоря.
И если мы вот по такой схеме их соберем, вот такую функцию, то при достаточно большой мэн мы получим достаточно хорошее, пока не говорю в каком смысле, приближение неизвестной нам функции распределения.
А эта функция получается в каждый раз для отдельного эксперимента своя? Ну, то есть в каком смысле она даже случайная оказывается?
Она оказывается случайная, но вот это почти наверно означает, что при настремляющей бесконечности вы получите функцию, сходящуюся в обычном смысле, как, ну, числовая последовательность.
В этом же смысл сходимости почти наверно.
Что вероятность таких наборов случайных величин, что вот этой сходимости не будет, равна нулю.
То есть, ну, как и любое явление с вероятностью ноль, оно существует в теоретической модели, но никогда не встречается в практике, да.
Как условно говоря, есть некая вероятность нулевая или там очень маленькая, что все молекулы в этой комнате соберутся в той половине, и мы все задохнемся.
Но ни одного такого факта неизвестно, это не происходит никогда, потому что вероятность этого события ноль.
Хотя, как математическое событие в вероятностном пространстве, оно существует.
Вот, поэтому она не случайная все-таки.
Ну, вот вы, когда считаете численным методом что-то, получаете решение, сходящее с итерационно к истинному, да.
Если у вас просто известно, что имеет место сходимость, вы же не знаете в какой момент остановиться, да.
Вы уже достигли предела, или сейчас вокруг какой-то кривой концентрируется, потом все опять разлетится, а потом, кстати, опять начнет сходиться.
В этом смысле и детерминированный эксперимент тоже случайен, да.
Вот в этом смысле, если речь о предельных соотношениях.
Ну, сходимость почти наверно, это она и есть.
То есть, если вы будете увеличивать тен, то вы получите последовательность,
которая как обычная числовая последовательность для некоторых х, будет сходиться вот к этой величине.
И в этом смысле она не хуже и не лучше численного метода или какого-то приближения.
Приближения же тоже они асимпатические все.
Ну, значит, следующее свойство этой функции,
которая собственно и составляет содержание теоремы Гливенко, выглядит так.
Значит, supremum по х fn от х
минус fx от х сходится к нулю
почти наверно, при н-стриме и бесконечности.
То есть, сходимость не только точечная, а в метрике равномерной сходимости.
Эта функция сходится равномерно к функции распределения.
На самом деле мы об этом, наверное, немножко догадываемся,
потому что fn, это формально функция распределения,
она неубывающая, ограниченная и сходится она к некой функции, пусть непрерывной.
Ну, тогда из поточной сходимости следует сходимость в равномерной метрике,
но нам нужно будет немножко повозиться там, как бы аккуратными быть в этом смысле.
Значит, ну, а теперь тоже об некой исторической справедливости.
Вот эта теорема в большинстве учебников называется теоремой Гливенко-Кантелли.
Теорема Гливенко-Кантелли.
И с этим связана такая, ну, не совсем прозрачная история, как мне кажется.
Дело в том, значит, эта теорема была опубликована в 1933 году,
а это был такой исторический период, когда, как бы,
ну, было такое выражение, статистика, буржуазная наука и так далее.
То есть некоторые выдающиеся работы наших соотечественников
опубликовались в зарубежных журналах.
Вот.
Значит, ну, кстати, работа Колмогорова, тоже связанная с империческим функцией распределения,
тоже была опубликована, так сказать, там во французском журнале,
как говорится, теперь и концов не найдешь.
Вот.
Но, тем не менее, вот, значит, Гливенко сформулировал эту теорему
для непрерывных случайных величин.
То есть когда f от xi непрерывный случайный, и доказал.
Ну и, собственно, так сказать, опубликовал.
Ну и вот каким-то странным образом именно в этом же журнале, там, в том же 1933 году
Контель опубликовал свою работу, обобщающую теорему Гливенко
на случай произвольных распределений.
То есть, там, ну, за исключением там сингулярных, которые мы не рассматриваем.
Вот.
Идея доказательства, собственно, была такая же, как и Гливенко,
только, ну, требуется более тщательная возня с точками разрыва,
непрерывные слева, которые у нас, как функции распределения.
Поэтому, ну, с точки зрения приоритетов, эта теорема называется
теоремой Гливенко-Контелли, но, учитывая, что доказательства Контелли
идейно, еще раз повторю, было такое же, как и у Гливенко,
просто он там тщательно повозился там с точками разрыва.
Ну вот, наверное, все-таки так, наверное, не зря в названии теоремы
Гливенко стоит первый, а Контелли второй, хотя, вроде бы, более общий случай.
Вот.
Значит, вот эта вот теорема Гливенко, Гливенко-Контелли.
Значит, ну, давайте начнем чуть-чуть, как бы так сказать, и идейно подведем.
Давайте вот это обозначим так, некое дн-ное, просто обозначение пока, дн-ное.
И давайте посмотрим, что означает дн-ное сходится к нулю почти наверно.
Это, вообще-то говоря, означает, что дн-ное случайная величина, да?
Потому что мы эти определения давали исходя из того, что имеем дело
с случайными величинами.
Ну, посмотрите, здесь Супремум берется по несчетному множеству.
И наша теория, такие объекты, ну, как бы они автоматически в нее не включаются.
Но, как бывает, в частности, там, в теории случайных процессов,
которые вы будете изучать в следующем году, там, события
на континуальном множестве, ну, специальным образом, в каких-то задачах,
сводятся к событию там на счетном множестве.
Но, в частности, в данном случае, вот, что я имею в виду?
Что, ну, не буду два раза переписывать, а напишу так.
Дн, на самом деле, можно представить в виде Супремум по х-катам,
которые принадлежат рациональным числам,
ФН от х-кат, минус Фкси от х-кат.
Согласны?
Ну, если здесь есть Супремум, значит, существует какая-то последовательность
из х, которая сходится к той точке Г-экстремум.
Ну, поскольку это всю доплотное множество, то мы и из рациональных чисел
можем построить последовательность, сходящуюся ровно туда.
Ну, кстати, обратите внимание, Супремум не достигается в точке плюс-минус бесконечность,
потому что в точке плюс-минус бесконечность все функции распределения,
и ФН, и Фкси произвольные, равны нулю бесконечности.
Ноль получается.
Поэтому точка Супремума, она где-то внутри.
Вот. И тогда, естественно, так сказать, можно воспользоваться фактом того,
что множество рациональных чисел всюду плотно,
и, так сказать, получить, что ДН можно представить не в таком, а в таком виде.
А это уже Супремум счетного числа вот таких случайных величин,
и это случайная величина, для которой вполне конкретно,
вполне корректно определить понятие сходимости почти наверно.
Понятно, да, до этого места?
Нам осталось совсем немного, ну и в следующий раз мы закончим.
Это тоже, как сказать, очень красивая теорема в том смысле,
что она очень глубокая, но совсем несложная,
ну идея доказательства очень несложная.
Все, коллеги, тогда давайте до следующего раза. Спасибо.
