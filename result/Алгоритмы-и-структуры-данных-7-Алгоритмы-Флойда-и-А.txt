У меня остался долг с Форд Белманом. Давайте мы все добьем. Что там было? Я сделал n-1 или n-этераций,
ну n-этераций в случае, когда мы хотим работать с отрицательными циклами. Давайте еще раз
напишу утверждение, что если c это отрицательный цикл, то есть цикл отрицательного веса, то на
него обязательно существует по крайней мере одна вершина, для которой dp уменьшилось с n-1 до
n-этераций. dp в n-е строго меньше, чем dp в n-1. Вот, доказательства. Ну пусть не так, пусть оно
осталось как было. Понятно, что больше оно стать не могло, потому что dp в этой k плюс 1, в частности,
расширится как минимум из dp в этой k и чего-то там, поэтому оно увеличиться точно не могло,
поэтому тут везде равенства стоят. А то есть для любой v из c тут равенство. dp в этой n-е равно
dp в этой n-1. Хорошо, что это значит? Давайте нарисуем наш цикл c. Вот такой цикл, большой цикл c.
Он состоит из вершин v1, v2, v3 и так далее. Ну пусть будет k, не страшно. И тут есть веса-рёбер.
Давайте я их обозначу c1, c2, c3 и так далее, ck. Что значит, что у меня dp не изменилось при
переходе от n-ой сферы в слою к n-ому? Давайте распишем это для какой-нибудь вершины vi плюс 1.
Значит, как у меня вообще считается dp vi плюс 1-ая n-ая? Там в частности рассматривается вот это вот
ребро из цикла, веса ci ведущая из вершины vi. То есть я рассматриваю такое ребро и обновляю,
пытаюсь обновить эту штуку через dp vi n-1 плюс ci. То есть я вот эту величину просто по формуле
пересчета динамики, в частности пытаюсь обновить через dp vi n-1 плюс ci. Потому что я мог сначала
дойти досюда, используя n-1 ребро, потом еще одно ребро, веса ci сюда добавить и получить путь из n-рёбер.
Но поскольку здесь было равенство, значит это обновление не дало выигрыша. То есть вот эта
штука, она больше равна, чем то, что и так лежало в этой дпшке. То есть я могу написать такое
неравенство. dp vi n-1 плюс ci больше равно, чем вот это, чем dp vi плюс 1 n-1. Раз у меня дпшка
не изменилась, значит все попытки обновить бесполезны. То есть они не лучше, чем то,
что там и так лежало. А здесь лежало изначально как раз вот dp vi и плюс 1 и минус 1. То есть все
возможные обновления с помощью входящих ребер, они бесполезны, они не улучшают ответ. Значит в
частности вот эти все обновления по ребрам из цикла тоже не улучшают ответ, не улучшают дпшку.
Вот. Ну все, теперь мы суммируем это все по всем i. Значит это превратится в сумму по всем
вершинам цикла dp vi и минус 1. Это то же самое, только со сдвигом. Да, это одна и та же сумма,
только со сдвигом на 1. Получается тогда они сократятся и останется сумма ci больше 0,
противоречие. Нормально? Вот. То есть противоречие с тем, что цикл отрицательный. То есть если цикл
отрицательный, то не может быть такого, что все эти dpшки остаются на месте при применении очередной
итерации. По крайней мере одна должна упасть, иначе цикл должен был быть не отрицательным по весу.
Вот. Все. Значит это первое. Первое, что нам нужно. Ну и второе тривиальное замечание. Замечание,
если v такова, что dp в это n меньше, чем dp в это n минус 1, то существует отрицательный цикл,
достижимый из s и из которого достижимо v. Опять нарисую картинку. Существует отрицательный
ц, такой, что из s можно дойти до c, и из c можно дойти до v. Вот так давайте нарисую. Можно дойти до v.
Ну вроде понятно, потому что если таких нет, то у меня очевидно dp не меняется при переходе
с n минус 1 слоя на n, потому что, раз оно уменьшилось, значит есть какой-то путь длины n, точнее из n
ребер, но не из-за минус одного ребра, который имеет меньше вес. Ну а если там n ребер, то там
обязательно есть на пути отрицательный цикл. Иначе его можно было бы отбросить и вес стал бы
только лучше. Тем самым вот эти два факта, утверждение и замечание, в совокупности означают
следующее, что вершины, для которых уменьшилась dp с n минус 1 слоя до n, то есть вот такие или такие,
это вершины отрицательных циклов или что-то, что из них достижимо. И при этом каждый отрицательный
цикл даст себя хотя бы одну вершину. То есть каждого цикла отрицательным будет хотя бы одна вершина,
а все вершины, для которых это верно, это либо вершины из циклов, либо что-то, что достижимо из цикла.
Поэтому если я после этого запущу dfs из всех таких вершин, то я в точности посещу все вершины
вот такого типа. То есть все вершины, которые достижимы из какого отрицательного цикла,
которые в свою очередь достижимы из s. Поэтому то, что я в конце прошлой лекции говорил,
что мы сначала вот эти вот все вершины сохраним, то есть я создам множество вершин, для которых
уменьшилась dp, из них потом запущу dfs, и все, что dfs посетил, на самом деле для них dist равно
минус бесконечности. А все, что не посетил для них dist, это то, что в dp лежит. Тем самым как раз мы
показали, что все вершины с этим dist мы правильно обработали, мы их все нашли и с помощью dfs туда
проставили эти dist. А все остальные, которые недостижимы, понятно, что для них dp-шка уже
найдена еще на n-1-ом слое. Как-то так. Вопросы? Ну, хорошо. Тогда получается, что мы в этот
момент научились полностью решать задачу поиска кратчайших расстояний от одной вершины до всех,
от s до всех, во все возможных постановках, когда у меня граф невзвешенный, взвешенный с маленькими
весами, это 0kbfs, взвешенный с неотрицательными ребрами и взвешенный с произвольными ребрами,
и даже, возможно, в присутствии отрицательных циклов. Эту задачу мы полностью решили.
Вот, есть еще другая задача. Давайте напишу сразу алгоритм Флойда. Он решает задачу поиска
кратчайших путей от всех вершин до всех, то есть все попарные кратчайшие расстояния он
находит. Поиск всех попарных кратчайших путей. То есть если раньше мы рассматривали кратчайшие
пути от одной до всех, то здесь от всех до всех. У меня нет какого-то фиксированного
истока, фиксированного начала, я могу от любой до любой идти. То есть по факту я нахожу все
дисты и t и g для всех пар i и g. Вот, значит, ну здесь для удобства я скажу, что отрицательных циклов нет,
но могут быть отрицательные ребра.
Вот, на самом деле Флойд работает даже в присутствии отрицательных циклов. Там ничего менять не надо,
надо просто там чуть-чуть-чуть аккуратнее все повторить. Это будет задачка на семинар,
что делать в присутствии отрицательных циклов во Флойде. Мы рассмотрим на лекции только без
отрицательных циклов. Значит, опять динамика, как ни странно. Ведем следующую dp. dp i t, j t, k t это
следующая величина. Значит, это длина, минимальная длина пути от i до j такого, что, то есть я рассматриваю
только такие пути, которые в качестве промежуточных вершин содержат вершины с номерами не больше
k. Минимальная длина пути такого, что все промежуточные вершины, то есть вершины отличные от стартовой
конечной. Все промежуточные вершины имеют номера не больше чем k. Такое странное условие. То есть я
позволяю себе по дороге посещать только вершины с номерами небольшими, не больше чем k. То есть есть
i и есть j. Без них мы уж не справимся, они обязательно есть в пути между ними. А по дороге все
вот эти вот промежуточные вершины имеют номера не больше чем k. Такое условие. Как считать такую
динамику? Ну, база очень простая. Когда k равно нулю, я считаю, что я живу сейчас в 1 индексации,
и dp i t, j t, 0 это когда я вообще не могу использовать промежуточных вершин. Если у меня 1 индексация,
то получается, что у меня требование, что все вершины здесь имеют номера не больше чем 0, а таких
вершин вообще нет. Поэтому единственный путь из ив-жи, если и есть, это ребро из ив-жи просто.
И поэтому его длина, это просто вес этого ребра. Я тогда могу здесь написать, что эта штука равна
в точности кост и жи, где кост и жи это длина ребра из ив-жи, либо плюс бесконечность, если
такого ребра нет. Давайте это отметим, что может быть плюс бесконечность. Ну, потому что понятно,
что если ребра между вершинами нет, то от того, что я вставлю туда ребро веса плюс бесконечность,
у меня ничего не изменится. Добавление ребра бесконечного веса не влияет на кратчайшие пути.
Поэтому я могу смело сказать следующее, если между вершинами нет ребра, то я его туда вставляю,
но говорю, что у меня бесконечно большой вес. Тогда эта штука просто в точности равна вот этой
матрице костов. Возможно только в матрице кост есть бесконечный бесконечный числ.
Так, дальше. Переходим к следующему слою динамики. Вот я хочу перейти от слоя номер к,
к к к inform, к к к к, к к к к к к к, к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к кк к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к К к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к к
используют вершины с номерами не большим k плюс 1.
Но тут есть, как обычно, два варианта.
Либо мы используем не просто меньше или равное k плюс 1,
а меньше или равное k.
То есть тогда, в частности, вот здесь я могу написать
dp it kt.
То есть у меня все промежуточные номера не только меньше
или равно k плюс 1, но еще и меньше или равно k.
Тогда это просто такая динамика, уже насчитанная нами.
dp it kt.
Иначе получается, что я использую номера больше, чем k,
но меньше чем k плюс 1.
Значит, я в частности использую в точности k плюс 1.
То есть у меня на этом пути где-то по дороге есть вершины
с номером k плюс 1.
Но при этом все остальные имеют номер не больше,
чем k плюс 1.
Дальше.
Очевидно, что нет смысла использовать k плюс 1
больше, чем один раз.
То есть не может быть такого, что у меня здесь k плюс 1
и здесь k плюс 1.
потому что иначе получается, что мы обходим какой-то цикл,
то есть раз мы возвращаемся в ту же вершину, где мы уже побывали,
а я предполагаю, что нет отрезательных циклов.
Поэтому циклы нам бесполезны, их не нужно посещать.
Чтобы попасть из И в Ж, используя минимальный вес, циклы мне посещать нельзя.
Значит, вершина k плюс 1 на этом пути, если встречается, то максимум один раз.
Ну а значит, все остальные вершины имеют номер максимум k, не больше чем k.
Значит, мне нужно рассмотреть путь из И в k плюс 1,
использующий вершину с номерами, не больше чем k,
и потом путь из k плюс 1 в Ж, использующий вершину с номерами, не больше чем k.
Поэтому вторая опция для нашего значения dp,
это dp иt k плюс 1 kt, плюс dp k плюс 1 Ж kt.
Вроде здесь простое рассуждение.
Еще раз давайте проговорю.
Если мне доступны только вершины с номерами, не больше чем k плюс 1,
то либо там нет даже k плюс 1 и значит все не больше чем k,
это первый случай, либо там есть вершина номера k плюс 1,
тогда она точно ровно одна, и значит от начала до нее промежуточные не больше чем k имеют вес,
и от нее до конца опять промежуточные имеют вес номера не больше чем k.
Поэтому мне нужно взять сумму этих dp-шек,
и они уже пощитны, потому что я считаю, что k иt пощитны, я перехожу k плюс 1.
Вся dp-шка.
Очевидно, что это работает за куб времени.
Извините, я забыл сказать, что ответ это всегда dp иt Ж тн.
Надо это проговорить, конечно, всегда.
Ответ это dp иt Ж тн.
Потому что такая динамика, это что такое?
Это кратчайший путь из и в Ж, который в качестве промежуточных
использует вершины с номерами не больше чем n.
То есть просто какие угодно вершины.
А вот это условие означает, что нет условия.
То есть по факту все промежуточные вершины, какие угодно,
это в точности то самый дист, который нам нужно.
Дист из и в Ж.
Поэтому такая динамика реально нам дает ответ за время кубическое.
Потому что у меня трехслойная динамика,
все три параметра, пробегая значения от 1 до n,
от 0 до n, возможно, и пересчет у меня за единицу.
Каждое значение dp иt Ж тк плюс 1 я вычисляю за единицу.
Поэтому суммарной будет куб.
Согласны?
Чудно.
Так, ну тут вопрос еще с памятью на самом деле.
Некоторые есть.
Потому что пока что память у меня кубическая.
Динамика трехслойная, память тоже кубическая.
Во-первых, как обычно, можем заметить, что у меня k
плюс первый слой вычисляется через катый.
Значит, мне достаточно хранить два слоя динамики.
Поэтому память уже у нас получилась квадратичная.
Если я храню только предыдущий слой и следующий,
то мне достаточно от n квадрат ячеек памяти.
На самом деле это можно реализовать еще более компактно.
Следующим алгоритмом.
Давайте я скажу, что пусть значения dp
хранятся в массиве g.
Хранятся в массиве g.
Тогда алгоритм Флойда можно написать следующим образом.
По всем k от 1 до n,
по всем i от 1 до n,
по всем g от 1 до n,
g i, t i, g t
равно минимум из того, что там уже лежит.
И суммы g i, t i, k, t i, plus g k, t i, g t.
Конец.
После этого я утверждаю, после этих трех форов
g i, t i, g t – это дист.
Дист и g.
То есть мне не просто можно избавиться от n слоев
и хранить только два слоя,
но на самом деле я могу оба слоя хранить
на одной и той же памяти в каком-то смысле.
Я завожу g i, t i, t i – это dp i, t i, t i, k, t i.
То есть это значение на очередном слое динамики.
Я его сам через себя пересчитываю.
Я применяю вот эту формулу пересчета прямо на месте.
Не использую два слоя динамики, а только один.
Вот это само житое-ожитое само через себя пересчитывается.
И оказывается, что это тоже будет корректно по счёт динамики.
Почему?
Я утверждаю, что после выполнения ката-итерации
самого внешнего цикла,
после ката-итерации внешнего цикла
g i, t i, t i в точности равно dp i, t i, k, t i.
То есть как раз у меня массив g хранит, собственно, массив dp.
Ну, слой dp.
Почему?
Значит, смотрите, какая на самом деле тут проблема есть единственная?
Проблема в том, что я два слоя склеил в один.
То есть мне бы в идеале хранить два слоя динамики k и k плюс 1.
И следующий k плюс первый считать через k.
А здесь они как бы одно и то же.
Я пересчитываю слой сам через себя.
То есть я как бы не разделяю k и k плюс первый слой,
а вот прям всё делаю на месте.
И тут как бы непонятно, почему тогда работает.
Что такое вот это g тогда вообще, если оно...
Это какое dp, если я его само через себя пересчитываю?
Непонятно.
Ну, смотрите, я вот ожидаю тогда следующее.
Заметим, что на...
Сейчас, одну секунду.
Ну да, что на ката-итерации
g, it, kt...
Давайте не так напишу.
g, какое угодно kt и g, kt, какое угодно, не меняются.
То есть если я нарисую табличку для нашего g,
то у меня kt строка и kt столбец,
они не меняются в течение выполнения ката-итерации.
Ну, потому что, смотрите, если у меня вот здесь, скажем, i равно k,
то представьте, что я сюда поставил k.
А вот я уже говорю, что g, kt, gt никогда не поменяются.
Что такое g, kt, gt?
Это либо старое значение, либо g, kt, kt, то есть i равно k,
плюс g, kt, gt.
Ну, g, kt, kt это ноль,
потому что путь из вершины в нее саму имеет вес ноль всегда.
А здесь то же самое dp, kt, gt.
То есть у меня dp, kt, gt не изменилось.
Наоборот, если у меня здесь i, а здесь k,
что такое g, it, kt, как я его обновляю?
Либо то, что там уже и так лежит, либо g, it, kt, плюс g, kt, kt.
Потому что k равно g.
Опять то же самое, здесь нулевое слагаемое,
поэтому у меня g, it, kt не изменилось вообще.
Таким образом, у меня вот в этой моей матрице g,
kt строка и kt столбец вообще не меняются в течение kт и итерации.
Но смотрите, вот эти значения,
это как раз вот эти самые строка и столбец,
g, it, kt и g, kt, gt.
Получается, что то, с помощью чего я обновляю все остальные g,
у меня фиксировано не изменяется.
И то есть если вот это были правильные значения как бы с прошлого слоя,
то я обновляю следующий слой и использую значения с предыдущего слоя.
И все хорошо.
То есть вот эти вот значения у меня не меняются,
и по факту они равны ну чему-то там dp, it, gt, k-1, видимо.
То есть у меня вот эти значения сохранились, не меняются,
и я обновляю dp, it, gt, kt на следующем слое через предыдущий.
Ну и тогда получается все хорошо.
У меня нет вот этого конфликта, что я только что посчитанные значения
использую для насчета самих себя же.
Потому что я обновляю g, it,
gt только через то, что стабильно с прошлого слоя.
Все, показали.
Так, вопросики есть?
Чудно.
Вот.
Ну и последнее тут замечание.
Это про восстановление ответа.
Ответа, то есть восстановление пути.
Вот.
Я научился находить длину, длину кратчайшего пути.
А как сам путь восстановить?
То есть я знаю, что в конце вот этого вот выполнения
g, it, gt это кратчайшее расстояние.
То есть длина кратчайшего пути.
Вот вопрос, а как сам этот путь восстановить?
Если я хочу вывести посредство вершин на пути от it, g.
Как ее получить?
Ну,
смотрите, тут можно сделать следующее.
Каждый раз, когда у меня вот эта g обновляется
через что-то, то есть вот это g, it, gt обновляется через вот это.
У меня получается что?
У меня получается, что чтобы попасть из it в g,
мне нужно сначала попасть из it в k, а потом из k в g.
То есть у меня оптимальный путь выглядит как-то вот так.
То есть если происходит обновление,
то оптимальный путь выглядит как-то вот так.
Сначала я попадаю в k,
а потом дохожу до конца.
Но давайте тогда в момент,
когда у меня происходит это обновление,
я укажу, что
оптимальный путь из it в g, который я нашел,
проходит в центре
через вершин номер k.
Давайте в момент обновления,
в момент обновления
g, it, gt,
укажем
p, it, gt равно k.
То есть если вот здесь вот
это значение меньше, чем старое значение,
то я ж переприсваиваю
и говорю, что p, it, gt равно k.
По факту это означает,
что чтобы попасть из it в g,
мне нужно сначала дойти от it до k,
и потом от k до g.
И тогда в самом конце оптимальный путь,
давайте напишем, что путь
g,
это что такое?
Это мы сначала доходим
от i до p, it, gt,
то есть вот как раз до
этой центральной вершины.
Потом я печатаю само это p, it, gt,
потом
дохожу от него
p, it, gt,
до g,
ну и в конце печатаю g.
Нет, не буду печатать g.
Сначала понятен, я сначала дошел сюда,
как бы рекурсивно попросил
найти вот этот путь оптимальный
из i до k, потом напечатал k,
и потом от k ищу оптимальный путь
до g.
Значит смысл у этого k на самом деле такой,
что это вершина с максимальным номером
на кратчайшем пути,
потому что у меня вот эти обновления происходят
до тех пор, пока, то есть у меня вот это gt,
gt уменьшается, уменьшается,
потому что он уменьшилось
для вершины с максимальным номером
среди всех на этом пути.
То есть по факту p, it, gt это всегда
максимальный номер вершины
на кратчайшем пути от i до g.
Ну и тогда соответственно мне нужно
в середине напечатать где-то там по центру,
и соответственно решить задачу
на первой половинке, на второй половинке
рекурсивно.
Вот такое простое замечание нам
позволяет восстановить ответ
целиком.
Еще раз?
Ну зависит от реализации,
то есть смотрите у меня сейчас получается
что он рекурсивно
выводит путь
где i включительно,
а g не включительно, вот так.
Тогда это напечатало все
от i до p и g, кроме
p и g, потом p и g.
Так, плохо, да?
Тогда давайте вот это можно зачеркнуть.
Ой, неприятно.
В смысле не включая ни и ни и g?
Так, это интереснее,
давайте подумаем.
Не включая ни и ни и g, тогда здесь
да, и в конце еще напечатать и в начале
и в конце. Да, вы правы, можно так?
Да, действительно. Так, наверное, проще всего.
Чтобы у нас вершины не дублировались как раз,
включать границы не очень хочется.
Ну потому что смотрите,
когда у нас в последний раз присвоилось
p и t житое,
то есть у меня g и t житое, оно несколько раз обновлялось
на разных итерациях k.
И в последний раз оно
обновится на какой-то конкретной итерации k,
это означает,
что чтобы попасть из i в g,
мне нужно сначала из i попасть в k,
потом из k в g. Но при этом
вот это что такое? Это же dp,
dp и t житое kt.
А dp это как раз
мне можно использовать только
не больше чем k. И k есть, поэтому это максимально.
Мы, получается, решили задачу про
все попарные крайнейшие расстояния.
Хорошо.
И теперь переходим к последней
популярной постановке.
Это поиск корочайшей пути
от s до t.
Это будет у нас алгоритм a звездочка,
а звездочка
поиск
dist st.
То есть у меня фиксировано и начало,
и конец. Другая крайность.
Если до этого у меня начало-конец были любые,
то есть мне нужно для каждой пары
определить, то здесь нужно
для конкретного начала и конкретного конца
найти корочайшее расстояние.
st фиксирован.
Еще будем делать.
Ну, тут на самом деле
опять мне нужно, чтобы все ребра были не отрицательные.
А весовая функция
бьет в ноль плюс бесконечность.
Своя функция не отрицательна у меня.
И во многом алгоритм будет очень похож
на dx.
Интуиция здесь такая, смотрите.
Вот раньше в dx мы делали
примерно следующее. Мы находили
из исходной вершины s
оценки на корочайшей
оцене до всех вершин.
Там были всякие вершинки v.
Мы вводили, давайте я это обозначу
g от v, это оценка
на корочайшее расстояние от s до v.
Оценка сверху.
Это длина одного из путей, и дальше
мы находили вершину с минимальным g от v,
которая еще не использована, объявляли, что это
и есть настоящее расстояние,
и потом что-то раскрывали.
А звездочка делает чуть похитрее.
Он не только использует
длину вот этого пути
от s до v,
он еще и откуда-то пытается оценить
длину пути от v до t.
И если g от v это длина
вот этого пути, ну оценка на
этот путь, то h от v
я буду обозначать оценку на длину
вот этого пути.
То есть я буду считывать не только,
поскольку у меня есть некая
цель, некий t, куда я хочу добраться,
я могу еще оптимизировать
наш алгоритм так, чтобы он использовал
какую-то оценку
на то, сколько осталось до конца.
Вот, и если я обозначу f от v
через, ну точнее,
как g от v плюс h от v,
то, грубо говоря, а звездочка
это dx
на функции f.
То есть у меня, я буду в кучу
складывать вершины,
которые упорядочены по значению
функции f. И в каком-то смысле
я буду доставать вершины из кучи,
то есть у меня там куча была в dx-ре,
вот я буду доставать вершины из кучи
в порядке возрастания f. То есть я буду их
сравнивать не по вот этому вот пути,
не по длине, пути, которые я уже нашел,
а суммарный путь
от s до v и от v до t, где путь
от v до t это какая-то оценка, какая-то функция h
волшебная.
Вот. И вот если я
все вершины буду сравнивать
по значению этой функции f,
тогда я, в принципе, могу добиться того, чтобы
это работало еще, короче, чуть эффективнее,
чем до икстра,
в каких-то случаях оно работает чуть-чуть быстрее.
Перерыв, потом продолжим про звездочку.
Последний рывок.
Давайте я расшифрую то, что я
тут сказал на таком высоком уровне,
как у нас работает та звездочка конкретно.
Вот функция h, повторю, это какая-то
оценка на расстояние
от s до t. Я буду называть
эвристика.
h, эвристика.
Значит, самый приятный
пример, как можно про это думать,
представьте себе, что наш весь граф
он лежит на плоскости.
То есть у меня вершины это точки на плоскости,
а ребра, ну это какие-то вот,
вот я там картинку рисовал,
ребра это прямолинейные отрезки между ними,
прямолинейные векторы между ними.
Тогда смотрите, какой может быть,
длина ребра это просто длина
отрезка. Такая простая геометрическая
интерпретация.
Тогда в качестве h от v
можно взять
расстояние на плоскости
между v и t.
Потому что понятно, что любой путь от v до t
имеет расстояние хотя бы вот эта вот
евкелидовая длина вот этого отрезка.
Потому что если какие-то ребра, то есть возможно
вот так надо идти, понятно, что это
больше либо равно, чем
этот отрезок.
h это в каком-то смысле приближение
на ответ.
Даже абсолютно не зная, как именно устроен граф,
скорее зная,
как устроена задача.
Все точки на плоскости или там,
все это, это какая-нибудь головоломка.
Если вершина это состояние
головоломки, то мы можем
как-нибудь уметь оценивать
расстояние между двумя состояниями головоломки.
Например, если у нас есть какой-нибудь кубик Рубика,
или вот в контесте будет задача про пятнашки,
если есть два состояния таблички
или два состояния кубика,
то мы можем как-нибудь оценить расстояние между ними.
Понимаем, что они сильно различаются.
Чем больше они различаются,
тем больше надо сделать действия, чтобы определить их одно в другое.
И вот в каком-то смысле нужна функция,
пытающаяся оценивать непохожесть вершин.
На плоскости, например,
эффективного расстояния, в головоломках
это зависит от того, какая головоломка,
насколько непохоже состояние.
Вот это надо как-то измерять, уметь.
Это эвристика, давайте напишу,
насколько непохоже ВИТ.
Если h правильно, то да.
Я еще соролирую теорему.
При достаточно простом условии на h
он не хуже, чем dx.
То есть он работает немедленно
и всегда вызывает правильный ответ.
Так что это не бесполезно.
А g от v,
это как обычно,
g от v
это
текущая найденная
текущая
найденная длина пути вот s до v.
Тогда как работает алгоритм?
Я считаю, что вектор
давайте double,
на всякий случай, раз уж я
заговорил про расстояние на плоскости.
Пусть у меня вектор double g есть,
он изначально заполнен плюс бесконечностями,
а h такая-то функция.
Напоминаю, что h
она не зависит от того,
что ваш алгоритм поделал.
Она не зависит от того, какие вершины вы рассмотрели,
что раскрыли и так далее.
h это просто какая-то функция,
которая по двум положениям v и t
говорит, ну, возвращать какое-то число.
Поэтому я ее не буду хранить в качестве массива,
будет отдельная функция,
которая там, когда надо, буду дергать.
Значит, вектор g
и вектор f
Изначально, да, начало,
это когда g от s равно 0,
а f от s
равно h от s.
Потому что если я ищу пути
из s, то, собственно, длина пути
от s до s равно 0,
а f от s как сумма g и h,
напоминаю, вот у меня формула,
f это сумма g плюс h.
g нулевая, поэтому мне нужно просто h здесь написать,
h от s.
h это какая-то оценка на расстоянии от s до t.
Вот.
Ну и все, нужна какая-то куча,
куда я добавлю вершину s
вот с этим значением f.
Давайте я словами напишу,
нужна какая-то куча,
куча q,
где хранятся вершины,
упорядоченные по f,
по значению f.
Ну, скорее не упорядоченные,
а сравниваемые,
сравниваемые по f,
по значению f.
То есть, если раньше у меня куча была на g,
по факту у меня ключом
выступало найденное расстояние
до вершины,
то теперь ключом будет f,
то есть не только g,
но g плюс h скорее.
Вот.
Значит, дальше, пока куча не пустая,
куча не пустая,
ну тут все просто,
значит, давайте напишу q,
точка экстракт мин.
Дальше раскрытие вершины,
как мы любим.
То есть, я перебираю все ребра.
Так, ну здесь у меня g уже занято,
давайте я граф назову.
Граф vt.
Раскрытие.
Ну раскрытие вершины влияет только на g.
То есть, я по факту
нахожу какое-то расстояние
до вершины e.tu,
и мне нужно, если что, обновить значение g,
и, если надо, значение f,
если g изменилось.
Ну давайте я напишу x равно
g вот v
плюс e.cost,
если x
меньшим g вот e.tu,
то есть, если до e.tu я нашел
более короткий путь,
то я его обновляю,
наставлю на x,
соответственно, обновляю f,
как x плюс h
вот e.tu.
Ну и здесь нужно еще
сказать, что у вершины e.tu
есть значение f,
то есть, у вершины e.tu
сказать, что у вершины e.tu
изменился ключ.
То есть, если раньше у нее было какое-то свое значение f,
то теперь у нее значение f уменьшилось
и стало вот таким.
И значит, мне в куче надо сделать decrease key.
Ну, либо decrease key, если она там уже есть,
либо, если нет, нужно сделать инферт.
Соответственно, здесь нужно вставить
e.tu в кучу
q, или сделать
decrease key.
Или сделать decrease key.
Decrease key.
Потому что у меня могло быть такое,
что ее в куче не было, я туда просто добавляю
с таким вот ключом f,
значение f.
Либо же она там уже была,
с другим значением f, со старым значением f.
Вот я ее обновляю, я уменьшил у нее f,
а значит, мне нужно сделать decrease key у нее.
У нее изменился параметр,
по которому они сравниваются.
Ну и все, раскрытие, как обычно.
Так, скобка, скобка, скобка.
Все, конец.
Только здесь я еще вставлю
одну строчку.
Если выравну t,
break.
Я не работаю дальше,
если я нашел t в нашей
куче.
Вот такой странный алгоритм.
То есть по факту это dx,
которая еще, то есть она учитывает
не только найденное расстояние, но еще и
плюс оценка до конца.
Плюс плюс h от v,
где h такая-то оценка
на расстояние от v до t.
Значит, теперь, насколько это все
адекватно?
Когда это работает?
Это определение.
Эвристика h
называется допустимой
если
если эта оценка снизу надист.
Ну вот, когда я рисовал там
картинку на плоскости, я говорю, что
можно расстояние оценить, как
расстояние на плоскости.
Можно расстояние оценить, как
настоящие вклиды в расстоянии между точками.
Понятно, что меньше быть нельзя.
То есть наша настоящая дист
было больше либо равно, чем h от v.
Больше либо равно, чем
какая-то вот эта нижняя оценка, как
самый короткий потенциально возможный путь.
Значит, тогда такая эвристика допустимая.
Дальше эвристика называется
монотонной.
Называется монотонной
если
во-первых, h от t равно 0,
во-вторых, выполняется неравенство треугольника.
Выполняется неравенство треугольника.
Значит, что это за неравенство?
Это такое неравенство.
Если есть ребро из u в v,
то h от u
больше, чем h от v,
плюс кост ребра у v.
Почему неравенство треугольника?
Потому что h от v это оценка длины пути
от v до t,
а h от u это оценка длины пути
от u до t.
И вот я говорю, что этот путь
не больше, чем вот этот путь.
Неравенство треугольника.
Добраться от u до t точно
будет не больше времени, чем от v до t
плюс от u до v.
Неравенство треугольника в чистом виде.
Вот тогда, видите, называется монотонной.
Ну, в частности, пример, когда я приводил
Евклидову плоскость,
равную расстоянию Евклидову от v до t,
это даже монотонная еврестика.
Не просто допустимая, но еще и монотонная.
Ну, потому что понятно, что расстояние
от t до t равно 0, и понятно, что
Евклидовое расстояние подчиняется неравенству треугольника.
Значит, замечание.
Монотонная еврестика является допустимой.
Монотонная еврестика является допустимой.
То есть, если верно вот это,
то верно вот это вот.
Ну, это вроде просто.
Давайте мы с конца пройдем.
Значит, ht равно 0. То есть, я доказываю, что если верно вот это,
то верно вот это. Значит, я знаю, что ht равно 0.
Понятно, что тогда ht не больше
чем d100t до t. Они все нули.
Давайте рассмотрим все входящие сюда ребра.
По неравенству треугольника я знаю,
что h везде вот здесь
не больше, чем длина этого ребра.
Поэтому h везде
вот здесь не больше, чем настоящий дист.
Дальше провожу вот эти все ребра.
Ну и аналогично, получается,
что немедленно с помощью неравенства треугольника
я получаю, что h вот отсюда
точно не больше, чем дист.
То есть, если есть какое-то настоящее расстояние
по неравенству треугольника,
то по неравенству треугольника
h вот здесь точно не больше, чем
это самое кратчаше расстояние.
Если не поняли, то и фиг с ним.
Теорема.
Если еврестика монотонна,
то вот то, что я говорил,
алгоритм всегда корректен
и всегда работает не хуже, чем dx.
Если h монотонная,
то
а звездочка
всегда находит правильный ответ.
И более того, каждую вершину
раскрывает не более одного раза.
И раскрывает
напомню, что раскрытие
это вот этот цикл по всем исходящим ребрам.
И раскрывает каждую вершину
не больше одного раза.
Ну, значит, это не хуже, чем dx.
Ответ правильный,
ну а симптотика тоже
имлоген получается.
Потому что каждая вершина раскроется максимум один раз,
значит, каждый ребро рассмотрится максимум один раз.
Ну и дальше куча, как обычно.
Второе. Если еврестика только допустима,
но не обязательно монотонна,
то ответ-то тоже правильный будет.
Но, возможно, симптотика сломается.
Если h всего лишь допустимая,
то а звездочка
всегда находит правильный ответ.
Но, возможно, за экспоненциально долгое время.
Но, возможно,
за экспоненциальное время.
Вот. И третий пункт.
Если h недопустимая,
то а звездочка
всегда находит правильный ответ.
То все плохо.
В том плане, что
нет гарантии ни на то, ни на другое,
нет гарантии ни на правильность ответа,
ни на какое-то быстрое время работы.
Но,
тут как бы некая магия есть,
в зависимости от задачи,
может быть такое, что h обеспечивает
довольно хорошее приближение на ответ
и работает довольно быстро.
Давайте я так и напишу,
что это значит, не буду раскрывать.
Значит, то
а звездочка
может найти
довольно хорошее приближение
к ответу.
Ну, то есть, скажем, если настоящий дист
это 100%,
то, например, вот эта штука найдет
путь длины не больше 110%.
То есть, там небольшая погрешность будет.
Не обязательно правильный ответ,
но близко к оптимуму.
С точностью до какой-нибудь погрешности.
За довольно хорошее время.
Ну, как бы близко к д-экстре.
Да, конечно.
Ну, это утверждение я пишу в качестве
обзорного, понятно, что я его не могу
сформулировать корректно, потому что
можете его не писать на экзамене.
Это просто для формирования
какого-то понимания, что здесь происходит.
То есть, на самом деле, еще раз,
если h недопустимое, то
а звездочка может вернуть неправильный ответ
и работать при этом экспенсально долго.
То есть, с теоретической точки зрения
вот это содержательное,
с практической точки зрения
иногда бывают такие h,
что на конкретных задачах
находит достаточно хорошее приближение
достаточно быстро.
То есть, это уже вопрос чисто практический.
Если вы пришли на работу,
очень долго работаете с одним и тем же графом,
и замечаете в нем какие-то закономерности,
соответственно, соответственным образом
как-то обновляете h.
Что-то там делаете, как-то читаете эту ювелистику.
Возможно, вы ее сможете так подхачивать,
чтобы она делала вот это вот.
Достаточно хорошо, достаточно быстро.
Но это тут как бы только практика.
То есть, у вас может получиться так,
что она реально довольно хорошо работает,
довольно быстро, но при этом как бы это
свойство графа,
а не задача в целом.
Естественно, третий пункт
я доказывать не буду.
И второй тоже не буду,
потому что там сложно и не очень интересно.
У нас на самом деле основные ювелистики
они монотонные всегда,
потому что я сказал, что из монотонности следует допустимость,
но на самом деле
добиться того, что выполнялось
не нравится треугольник, это не очень сложно.
Поэтому на самом деле большинство ювелистик
будет монотонные всегда.
Сейчас будем доказывать первое.
Утверждение.
Пусть h монотонная.
Тогда.
Последователь значений f
у извлекаемых из кучи вершин
не убывает.
Напоминаю.
Как работает?
Она имеет некую кучу,
там вершины упорядочены по f,
точнее сравниваются по f,
ключами выступает значение f.
Мы каждый раз извлекаем минимум.
Взяли минимум, взяли минимум и так далее.
Минимум по f каждый раз берем.
И каждую вершину, когда я извлекаю из кучи,
я ее раскрываю.
То есть обновляю f к куче.
И когда я извлекаю ее из кучи,
я ее раскрываю.
То есть обновляю f для всех вершин,
которые из нее достижимы.
Когда я извлекаю f,
я ее раскрываю,
обновляю g, обновляю f для всех этих вершин.
И вот я утверждаю,
что когда я поочередно
всю кучу исчерпываю,
забираю оттуда вершины одна за другой,
у меня f только возрастает.
Не может быть такого,
что я извлек v с каким-то значением f,
потом что-то поделал
и извлек вершину с меньшим значением f.
Это f не может.
После последовательной извлечения из кучи,
они могут только увеличивать f.
Либо оставлять таким же, как было,
либо только увеличивать.
Доказательство простое.
Давайте рассмотрим конкретное v.
Пусть v извлекается из кучи.
Что это значит?
Это значит, что к моменту,
когда она извлекается,
ее f минимально возможный.
То есть у всех остальных f только больше.
f от x, f от u,
больше равно f от v для всех u.
Пока что нету f меньше,
чем f от v.
Теперь я ее раскрываю.
Раскрываем v.
Я давайте рассмотрю
какое-то ребро из v в 2.
Что я могу сказать?
Я могу сказать, что вот здесь
я нашел новый кратчайший путь.
И если здесь был какой-то путь
веса g от v,
то есть путь из начала до v
веса g от v,
то теперь досюда появился
путь веса g от v плюс
вот этот кост.
Давайте его назову c, плюс c.
Плюс c.
Тем самым я могу обновить f от 2
через вот эту вот штуку,
плюс еще h от 2.
То есть
f от 2
может стать равным,
может стать равным,
может стать равным
g от v
плюс c,
плюс h от 2.
Потому что f
это у меня всегда g плюс h,
h я написал, а g это
если я реально делаю обновление,
релаксацию значения g,
то g от 2 это g от v плюс c.
Я хочу показать, что эта штука
всегда больше равна,
чем f от v.
Вот если мы докажем,
то мы на самом деле победили.
Получается, что все раскрытия у меня
сохраняют вот это неравенство,
и у всех вершин f больше равно, чем у текущей.
Значит, после каждого извлечения
у меня как бы выполняется,
что у всех остальных все равно f будет больше
равно, чем текущая, и значит оно никогда не уменьшится.
У извлекаемой вершины не может быть
f меньше, чем у какой-либо из предыдущих.
Ну почему это верно? Давайте это напишем.
Что такое f от v?
f от v, это g от v,
плюс h от v.
Это просто неравенство треугольника.
То, что здесь осталось,
это мне нужно показать,
что h от v,
ну то есть это под вопросом, я хочу это доказать,
правда ли, что h от v
не больше, чем h от t,
плюс c.
Это следует из определения,
из неравенства треугольника.
Вот.
Чудесно.
То есть получается, если h монотонно,
то
это реально похоже на dx.
Я вот когда вершины исчерпываю из кучи,
достаю из кучи одна с другой,
у меня f возрастает, то есть расстояние до них все увеличивается и увеличивается,
если под расстоянием понимать f.
Но смотрите, это работает только
в случае монотонности,
и здесь как бы существенно требуется
неравенство треугольника.
Значит, если бы у меня выясник была не монотонная, а только допустимая,
без неравенства треугольника,
то это могло быть неверно.
Потому что f-ки увеличиваются.
Когда я исчерпываю кучу,
извлекаю вершины одна с другой,
f могли падать, могли уменьшаться,
потому что если неравенство треугольника
не выполняется на h только допустимо,
но не монотонно, то f могли уменьшаться.
Проблема этого в том, что мы тогда
некоторые вершины могли несколько раз посещать.
Потому что мы могли, скажем,
добавить v в кучу каким-то образом,
потом что-то здесь найти,
найти еще некоторый путь
и уменьшить f от v.
То есть мы могли здесь найти
новый более оптимальный путь,
уменьшающий f от v по сравнению со старым его значением.
Тогда v заново добавляется в кучу,
и я ее заново обрабатываю.
То есть у меня вершина раскрывается несколько раз одна и та же,
но уже с разными значениями f.
Отсюда как раз получается
в худшем случае компонента.
Вершина может несколько раз рассматриваться,
несколько раз раскрываться,
и поэтому, собственно,
время летит к черту.
Так, значит, теперь
что делаем с этим утверждением?
Как из утверждения следует
пункт 1?
Значит, доказательства теоремы.
Доказательства теоремы
пункт 1.
Почему мы сляжем монотонную,
то всегда найдем правильный ответ
и раскроем каждую вещь не больше одного раза.
Ну, начнем
со второго вопроса.
Каждая вершина очевидно раскроется не больше
одного раза, потому что f не убывают.
Смысл
раскрывать вершину больше одного раза
есть только в случае, когда мы нашли более
оптимальный путь,
то есть мы нашли меньше f, чем было раньше.
Значит, за счет утверждения
нет смысла
раскрывать вершину
раскрывать вершину больше одного раза.
Потому что если вершина раскрывается больше одного раза,
это может произойти только если мы нашли до нее более короткий путь, чем раньше нашли до этого.
То есть мы извлекли кучу в какой-то момент, там было какое-то f,
потом я ее еще раз добавил с меньшим f, и потом еще раз извлек.
Только в случае уменьшения f я мог ее заново добавить в кучу.
Ну а такого не бывает по утверждению.
Второе утверждение, вот это вот.
Мы пояснили, почему всегда правильный ответ находится.
Ну а почему всегда найдется правильный ответ?
Ну, давайте скажем следующее.
Давайте я мой алгоритм немножко изменю.
Смотрите, я вот там в самом конце, когда описывал звездочку, сказал следующее.
Когда из кучи извлекается t, я сразу алгоритм завершаю.
Как только у меня извлекается из кучи t, то есть я как бы говорю,
что до нее уже найдено прошедшее состояние, я завершаюсь, больше ничего не рассматриваю.
Так вот, давайте мы предположим, что это не так, пусть не так.
И давайте мы тогда изменим наш алгоритм, разрешим ему продолжаться, пока куча не опустеет.
То есть я отменяю строчку, вот эту вот, если выравнивать эту, break.
Просто говорю, что пока куча не пустая, мы раскрываем экстракт-мин.
Корень кучи раскрываем.
И вот, если мы откроем эту строчку, то это будет как-то так.
И вот, если мы откроем эту строчку, то это будет как-то так.
А пока мы раскрываем экстракт-мин, корень кучи раскрываем.
Что тогда? Я тогда утверждал, что такой алгоритм без вот этого break в случае находения t в первый раз точно найдет правильный ответ.
Ну потому что, смотрите, есть же у нас какой-то настоящий кратчайший путь из s в t.
Вот есть какой-то такой кратчайший путь.
Понятно, в какой-то момент мы раскроем s, но в самом начале мы раскрыли s.
Тогда я знаю кратчайшее состояние до сюда.
В какой-то момент я раскрою эту вершину, найду кратчайшее состояние до суда.
В какой-то момент раскрою ее, узнаю до сюда. Раскрою ее, узнаю до сюда.
примерно так. Тут, на самом деле, надо немножко поаккуратнее искать, потому что они не обязательно в этом порядке раскрываются.
На самом деле, возможно, есть другой путь, кратчайший, скажем, вот такой, но тоже кратчайший.
Тогда, возможно, у меня вот эта вершина раскроется раньше этой, но все равно я утверждаю, что...
То есть я утверждаю следующее, что вот эта вот вершина в какой-то момент раскроется, при этом до нее будет найден вот такой вот кратчайший путь.
То есть до нее найдено корректное кратчайшее расстояние.
Но это просто делается по индукции, значит, если...
Ну, индукция по количеству ребер в этом кратчайшем пути.
Вот если одно ребро, то, очевидно, до нее найдется правильный путь, потому что одно ребро обработается при раскрытии этой вершины.
Если на кратчайшем пути там несколько ребер, скажем, K, то у меня эта вершина рано или поздно обработается, да, рано или поздно раскроется,
а до нее уже ребер на кратчайшем пути меньше, K-1.
Поэтому это раскроется, либо это раскроется до, и тогда я найду здесь правильный ответ, либо я найду еще какой-то другой,
возможно, более короткий путь до нее, и значит, ну, опять-таки здесь ребер меньше, чем K, и это успеет раскрыться.
То есть я утверждаю, что к моменту времени обработки каждой вершины, по крайней мере, один из кратчайших пути до нее уже будет рассмотрен.
Ну, понятно, да, то есть хотя бы одна из этих вершин должна будет обработана быть.
Значит, если я отменяю это условие про то, что if выровнуто break, тогда у меня кратчайший путь от s до t точно обработается,
и у меня найдется правильное расстояние g от t.
Но, смотрите, тогда получается, мне нужно моему алгоритму разрешить делать еще лишние итерации, чтобы он нашел правильный путь.
То есть он найдет какое-то более правильное g от t, он нашел сначала какое-то расстояние, да, потом удалил t, что-то сделал,
потом ему сказал, окей, работай дальше, он взял еще, нашел какой-то более короткий путь до t, такого быть не может, потому что у меня f увеличивается.
А я что сказал? Я сказал, что я нашел какой-то путь до t, ее удалил, обработал, раскрыл, и потом нашел более короткий путь до нее же.
И потом ее раскрыл, обработал. Но такого не бывает, потому что у меня f только не убывает.
Значит, если я в какой-то момент обработал t и потом еще обработал t, извлек из кучи, то у меня f могло только вырастить для нее.
Противоречие, да, то есть если у меня кратчайший путь нашелся когда-то потом, то он должен был найти в самом начале.
В самый первый раз, когда я впервые извлекаю t из кучи, у меня должен был найти правильный путь.
Вот, собственно, поэтому, когда я извлекаю t из кучи, для нее уже все насчитано.
Давайте что-нибудь напишем. В конце, в конце, истинный кратчайший путь, истинный кратчайший путь из s в t гарантированно обработается.
Следовательно, получим f от t равное dist t.
Ну, для t, я, наверное, это уже замечал, для t у меня g и f это одно и то же, потому что h равно 0.
В случае, по крайней мере, монотонной велистики h от t равно 0, поэтому g и f это одно и то же.
Так вот, если я разрешаю алгоритму работать дальше, то у меня точно рано или поздно получится, что f это равно dist t.
И если до этого f извлекалось, то там было еще меньшее значение f противоречия.
Если t до этого уже извлекалось из кучи, то в ней было f от t меньше либо равно dist t.
Потому что, опять-таки, по утверждению, последовательность f, какую-то извлекаемую, только возрастает.
Поэтому если t извлекается дважды, то на предыдущем шаге там было только меньше либо равное значение f.
Вот, вроде такая вот штука.
Так, что еще хочу сказать? Примерчики давайте какие-нибудь посмотрим.
Примеры. Пример первый. Когда h это тождественный 0.
Если у меня эвристика очень глупая и всегда равна 0, то я утверждаю, что a звездочка вырождается в dx просто, что они просто делают одно и то же.
Вырождается в dx.
Ну, вроде понятно, если h всегда равно 0, то оно не влияет на g и f, это всегда одно и то же.
Поэтому просто a звездочка в точность делает то же самое, что и dx.
Поэтому в таком вот самом простом случае мы получили в точности dx.
То есть, по крайней мере, не хуже, чем dx.
Да, между конкретной s и конкретной t.
Ну да, да, вы правы. То есть, по факту это такая дейстра ограниченная, что не от s до всех, а от s до t.
Да, это важное замечание. Я имею в виду, что сейчас я рассматриваю только задачу поиска от s до t.
Вторая крайность абсолютно сказочная. Пусть каким-то образом удалось вот такую эвристическую функцию придумать.
Что h от v в точности равна d100.
Тогда a звездочка неформально рассмотрит только кратчайший путь от s до t.
Рассмотрит, давайте я напишу в кавычках, только кратчайший путь от s до t.
На самом деле мы рассмотрим не только кратчайший путь, а все кратчайшие пути и все соседние вершины с ними.
Примерно так. Пример, да, как это работает.
Вот давайте я рассмотрю евклидовую мою... так, евклида неинтересна. Давайте рассмотрим Манхэттенскую метрику.
Давайте я скажу, что расстояние между точками x1 и y1 и x2 и y2 равно сумме модулей разности.
Пусть у меня не евклидовая плоскость, а такая Манхэттенская. То есть я могу двигаться только вдоль x или вдоль y параллельно одной из двух осей.
Тогда расстояние определяется не как корень из суммы квадратов, а как сумма модулей разности.
Так вот, давайте я начну какую-нибудь картинку. У меня есть такая плоскость, есть стартовая точка, есть конечная точка.
Ну и там какие-то препятствия. Это по факту очень похоже на какой-нибудь игрушечный мир.
Есть какие-то две точки, надо там человечкой перенаправить отсюда-досюда, и там есть какие-то препятствия.
Деревья, какие-нибудь стены, ну что-нибудь такое. Какой-нибудь такой простой мир.
И у вас там все... короче, вы умеете только на VASD нажимать, и у вас получается четыре направления движения.
Вот так вот. Вот отличная задача для звездочки. Есть очень простой граф.
Есть очень естественная эвристика, которая здесь подойдет.
Ну и тогда что у вас делает... как у вас работает та звездочка?
В самом деле, в случае, когда эта штука на самом деле равна DIST, вы найдете в каком-то смысле только вот этот вот кратчайший путь.
Ну там один из них. Почему это верно? Смотрите. Давайте рассмотрим, как работает та звездочка.
Мы сначала раскрываем... давайте рассмотрим еще любой кратчайший путь от SDT. Вот он.
И если h равно DIST, то я утверждаю, что для них для всех f одинаковые.
Для всех вершин на кратчайшем пути f одно и то же. То есть f от s равно f здесь, равно f здесь, равно и так далее, равно f от t.
Ну потому что что такое f? Что такое f для вершинки? Это длина вот этой вот пути, это g.
Плюс вот этот путь, это h. Ну понятно, что эта сумма, это всегда просто длина пути.
Поэтому у них у всех одно и то же значение f. Это длина пути от s до v и от v до t.
Вот в случае этом нереальном, когда h равно DIST. То есть у меня получается, что если это выполняется, то у меня все f-ки у них одинаковые.
Ну а значит, просто как у меня работает DXTRA? Она сваливает в кучу все вершины и извлекает минимальное значение f.
Ну покуда там есть значение f, вот то самое, что было для f от s, мы обрабатываем только вершины вот с этим вот f.
У них у всех будет одно и то же значение f, и они все извлекутся в таком порядке.
Получается, что мы сразу рассматриваем только кратчайший путь.
Ну да, естественно мы рассматриваем все вот эти вот ребра, исходящие из этих вершин.
Ну как бы, от этого никуда не денешься.
Но по факту у нас как бы сразу есть вот эта вот цепочка, которая ведет нас из начала в конец по вершинам, для которых одно и то же значение f.
Да, единственная тонкость, что возможно, если у нас путей таких несколько кратчайших, скажем вот такой и вот такой есть.
Ну для них тоже, для второго кратчайшего пути, здесь тоже все f одинаковые.
И у меня как бы, а звездочка, он не знает, какой из них выбирать, он ну скорее как-то вот так параллельно по ним идет, по обоим.
И в какой-то момент один из них закончится, и тогда вот я сразу завершаю.
Вот, то есть в этом случае у меня а звездочка рассматривает как бы только кратчайшие пути, и больше ничего не рассматривает.
Это я погорячился, да, это конечно не верно, это конечно не верно.
Но вот в случае, если здесь есть какой-то путь, ладно, давайте вот так сделаю.
Если нет препятствий, тогда это верно.
Вот, гениально, да?
Ну, тяжело, тяжело просто придумать пример, когда у вас эвристика была бы еще равна дисту.
Только вот какие-то графы без, без препятствий скорее.
Так, ну сейчас давайте еще там две формулы напишу, значит какие бывают популярные эвристики на плоскости, значит на плоскости.
Это, как я уже написал, Манхэттен, если можно ходить только в четыре стороны.
Это Чебушовская метрика.
Если можно ходить еще и по диагоналям.
Вот, ну и это Евклидовская метрика, Евклидова метрика.
Если можно ходить в любом направлении.
Соответственно, в зависимости от того, как у вас определяется расстояние на плоскости,
то есть как можно вашему человечку ходить на плоскости,
соответствующая эвристика H подойдет лучше всего.
Ну как бы для них все понятно, это монотонные эвристики.
Понятно, что расстояние от T до T равно нулю.
Выполняется на районе треугольника тривиально, потому что это метрики.
Ну и все.
Получается, что если вы вместо дэекстры вот в таких графах будете пускать азвездочку, то точно хуже вам от этого не будет.
Но возможно будет сильно лучше, потому что вот, например, на графах без, без препятствий,
вы будете посещать почти только коротчайший путь и, в общем-то, не будете уходить во все остальные вершины.
Потому что, например, там DFS или дэекстра работали бы скорее вот так.
Мы нашли все вершины на расстоянии ноль, потом все вершины на расстоянии один, два, три, четыре и так далее.
То есть дэекстры и BFS они бы как-то во все стороны бы шли.
А за счет H азвездочка понимает, что надо идти туда.
Идет как бы только туда. Не обходится.
Не обходит вообще во все стороны граф, а только как бы идет в правильное направление.
Вот в этом как бы такое манемоническая выгода от азвездочки.
Спасибо.
