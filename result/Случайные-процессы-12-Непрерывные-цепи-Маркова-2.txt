значит я напоминаю что в прошлый раз мы начали с вами тему непрерывные цепи маркова это марковские
процессы у которых время непрерывно множество состояний дискретно но у нас уже есть опыт какой-то
анализа дискретных цепей маркова и мы частично его перенесли на непрерывные цепи там какие-то
быстрые следствия получили но для того чтобы дальше науку это развивать получать какие-то
содержательные результаты нам понадобилось сделать некоторые предположения процессах вот и можно по
разному эти предположения базовые как бы вводить класс выделять и я решил вести класс непрерывных
справа процесс вот потому что это как бы физически понятно что это такое проверяемо и
мы благодаря этому получили множество целое множество следствий которые там справедливая
конечных цепях ну и там может быть некоторыми оговорками переносится на счетный тоже случай
мы с вами точно также выяснили что непрерывные цепи как они себя ведут вот ты допустим если
стартуешь не ты в смысле а цепь если стартует из некоторого состояния она живет в нем показательное
время потом она скачет и вот то сколько она живет в этом состоянии это случайно лично у
нее показательное распределение обязательно и другого распределения времени жизни в состоянии
у непрерывных цепи марков быть не может кроме показательного вот ну при прочих равных
предположениях там однородность непрерывной справа траектории вот значит живет показательное
время и то какие вероятности перехода в момент скачка все это короче говоря определяется матрица
интенсивности q вот это то что мы с вами прошлый раз посмотрели сегодня мы продолжаем изучать
непрерывные цепи маркова посмотрим их некоторые особенности ну сначала закроем вот эту вот
тему аналогии с дискретными цепями поговорим об органичности непрерывных цепей
органичности
непрерывных цепей маркова здесь все очень очень похоже будет на часть для органично для дискретных
цепей мы с вами выяснили что распределение состояние в моменте п это вектор он для
каждого состояния вот стоит и с компонент для каждого состояния распределение это есть п
транспонированное т на п от нуля где это есть матрица перехода на интервале времени от 0 до
t да мы рассматриваем однородный с вами цепи а это начальное распределение и распределение в
произвольный момент времени определяется по этой формуле, ну либо из
дифференциального равнения, либо из этой формулы, если вы знаете P от T.
Можем вести определение стационарного распределения, то есть то распределение,
которое от времени не зависит, оно удовлетворяет этому равнению P0, я его
обозначу, P от транспонированного от T равняется P0. Вот если распределение P0
обладает вот таким свойством для любых T, то тогда оно называется
стационарным распределением. Ну в общем-то такие как бы интуитивно-понятные
логичные определения. Так, дальше к чему сходится P от T? Вот таким вопросом зададимся
или к чему сходится P от T? Ну как мы на этот вопрос отвечали в дискретных цепях? Мы
вели классификацию состояния, да, и вот сформулировали теорему органичности. Ну здесь
мы тоже можем ввести, можем классифицировать состояние. В общем, мы будем говорить, что из
И следует Ж, если P и Ж от T больше нуля для некоторого Т. Вот, да, мы будем говорить, что они
сообщаются, если P и Ж, Т больше нуля и P и Ж для какого-то может быть другого Т тоже больше нуля.
Вот, так что вот эти вот вещи как следование, сообщаемость, существенность, нулевость,
все это то же самое как здесь, просто мы там писали N, а здесь будет T. Ведь в этих
определениях существенности там, сообщаемости, мы нигде не пользовались тем, что время дискретно,
на самом деле, если вы посмотрите. Мы просто букву N ее обозначали, но заменить ее на букву T,
вообще ничего не поменяется, реально, вы можете сами это проверить. Ну я говорил на прошлой лекции,
что, в принципе, мы могли бы про цепи рассказывать как бы в едином стиле, как бы рисовать
Нью-Ку букву, но она может быть дискретно, может быть непрерывно, ну где-то какие-то оговорки
делать, где-то нет. Ну единственное может быть, что здесь какие вот, что напрямую не переносится,
это возвратность, там похитрее формула, но она нам, кстати, не потребуется, нам не потребуется
возвратность, не будем мы с ней работать в непрерывных цепях. И вообще нет периодичности,
ну периодичность, да, там вот существенно мы пользуемся тем, что время дискретно. Помните
там, что такое периодичность? Это наибольший участник чисел, на которых там P и T и T больше нуля,
да, но предполагается, что это множество, оно дискретное, время дискретно, здесь время непрерывное,
что такое нот для дискретных, непонятно, но не вводится, периодичность состояния для непрерывных
цепей не вводится. Все остальные вводятся, возвратность нам не нужна будет, а остальные там вот
эти вот сообщаемые следования нулевость, все это у нас остается без изменений, просто букву N,
букву M надо заменить на T, T, там, непрерывное время. Так, ну что, какая там, наверное уже пора тяему
сформулировать, да? А, вот тут еще добавьте, значит, что национальное распределение, оно, если вот это
все продиференцировать, ну в конечной цепи мы можем это точно делать, если вот это мы все
продиференцируем, то мы получим тогда Q транспонированная P0 равно нулю, ну это как бы вот
откуда мы можем это стационарное распределение искать, то есть либо ты его ищешь как собственный
вектор, нормированный на единицу, отвечающий собственному значению лямбда равный единице для
любых T вот здесь, ну тогда тебе надо знать вот эту матрицу, либо ты ищешь P0 как собственный вектор,
нормированный на единицу, отвечающий собственному значению равную ноль вот здесь, ну вот так вот обычно
это и дело. Вот, а мы с вами сформулируем теорему, теорему органичности для непрерывных цепей,
которая говорит следующее, что для того чтобы непрерывная цепь Маркова, ну чтобы конечная
непрерывная цепь Маркова была органической, то есть P и житая от T сходилась к P и житому больше,
но это одно из тех свойств, которые мы сохраняем при переходе к непрерывному времени, при T стремящемся
к бесконечности, чтобы вот это было выполнено для любых и жи. Необходимо и достаточно, чтобы
она была неразложимая. Все состояния сообщаются. Вот, то есть здесь нам не нужна периодичность,
периодичность она не вводится в непрерывных цепях, помните в дискретных неразложимая и
непериодическая. Здесь вот периодическое, непериодическое, это все не вводится. Ну,
доказательства я прям вот совсем полностью писать не буду, потому что оно по большому счету
вообще не отличается от доказательства для дискретных цепей. Вот, ну давайте так вот,
просто на словах хотя бы посмотрим. Первая необходимость, необходимость, почему она должна
быть неразложимая. Смотрите, если у нас P и T житая от T сходится к P и житому больше нуля, это значит
найдется момент времени, когда P и T жита будет положительным. Ну, а так как цепь конечная,
то максимум просто берете по всем этим временам, для всех E и G и получаете, что в некоторый момент
времени все P и T житые больше нуля, потому что они обязательно сходятся к чему-то, что больше нуля,
значит в какой-то момент они будут отделены от нуля по определению предела. Вот, так что P и T
житая от T сходится к P и житому больше нуля, следовательно, найдется T такой же для любых E и G,
P и G от T больше нуля для любых T, больше либо равных T. Вот, ну в общем-то это то же самое,
что мы писали тогда в доказательстве этой теоремы для дискретного случая. А то, что они для любых
E и G больше нуля, означает, что они, в том числе и для соподавающих тоже, это означает, что цепь
неразложимая. Вот, следовательно, неразложимая. Вот. Второе, ну то-то в обратную сторону,
если неразложимая, то вот это, тут все аналогично как там, вы берете просто доказательство,
которое у нас было для дискретного случая, выкидываете оттуда все, что связано с периодичностью,
что нам нужно? Логика здесь та же самая. Сначала мы доказываем, что P и T, G от T,
начиная с некоторого номера, больше нуля. Вот, то есть существует T такой, что P и T, G от T,
для любых E и G, что вот эта штука больше нуля для любых T, больше либо равных T. Вот. А потом
повторяем, доказав, что начиная с некоторого номера, они все больше нуля, мы там, помните,
вводим M маленькую, M большую, везде заменяете эти N, M на какие-нибудь T и T, все. Мы там нигде
реально не пользуемся тем, что они дискретные N и M. Вот. Так что вы можете найти N и M, которые у нас
там смотреть как на непрерывные моменты времени. То есть единственное все отличие, это то, что нам
не нужна теперь лемма, которую мы вводили. Помните там о том, что любое число представляется в виде
линейной комбинации взаимопростых чисел. Это нам не нужно, периодически все убираем. И единственное
отличие здесь будет вот в этом утверждении. Но на самом деле в непрерывных цепях оно очевидно,
потому что, ну, например, смотрите, мы знаем, что наша цепь, как она себя ведет, она живет в состоянии
показательное время, а потом скачет дальше. Если у вас состояния соединены, да, вот как-то,
ну, это все состояния какие-то, то всегда существует какая-то ненулевая вероятность за любое конечное
время попасть отсюда-сюда. Потому что у вас всегда есть какая-то ненулевая вероятность в конечное
время побывать здесь, потом побывать здесь, а потом перейти сюда. Вот. Потому что время пребывания в
этих состояниях, оно показательное, имеет непрерывное распределение. Так что, если вы хотите попасть из
нулевого момента времени отсюда в момент времени ты-сюда, то у вас всегда есть ненулевая вероятность
за время t пополам перейти отсюда-сюда. Для этого вы должны жить здесь время t пополам. Ну, и сколько там,
допустим, время t треть жить здесь, потом перейти время t треть здесь жить и здесь жить. Ну, в общем,
там t на треть либо t пополам, неважно. Вот. Ну, главное то, что в силу того, что распределение непрерывное,
от нуля, значит, оно может быть сколь угодно маленьким, так что вы можете попасть отсюда-сюда
для любого t сколь угодно малого. Так что, на самом деле, вот в этом втором пункте не просто t существует,
t равное нулю существует. Ну, и тогда вот тут вот так вот сделать. То есть, в любой следующий момент
времени у тебя p и t сжитое, а t будет больше нуля. Вот такая вот особенность непрерывных цепей.
Просто потому что живешь в непрерывное время в каждом состоянии. И ты можешь всегда сделать так,
что рассмотреть случаи, когда ты живешь там мало. Ну, пусть мало, но конечное время и вероятность
этого не нулевая вполне себе нормальная. Вот. Ну, а потом уже после того, как мы показали,
что все p и t сжитое t больше нуля, причем для любого t больше нуля получается в непрерывной цепи.
Дальше мы возим вот эти наши m, маленькая m, большая, зажимаем p и t сжитое между ними,
ну и так далее. Вот. Там мы уже никак не пользуемся тем, что наша цепь дискретная. Вот. Мы пользовались
только здесь, но в непрерывной цепи у нас есть кое-что попроще. Мы опираемся на то, что вот в этом
пункте, что мы живем в непрерывное время. Ну, в принципе, если хотите, вы можете на это даже не
опираться, а вот повторить выкладки, какие у нас были там для p и t и t, то, что она больше там
чего-то, что больше нуля для любого t. Ну, мне кажется, что это в принципе ни к чему. Мы можем
здесь вполне опираться на то, что мы уже знаем, что мы живем в показательное время. Вот и все. Так
что это нормально. Вот. Так что вот такая вот теорема эргодичности. Значит, у нас там еще было
куча свойств после теоремы эргодичности следствия. Все они тоже живут без изменений. Мы нигде не
пользуемся дискретностью, кроме, может быть, там какого-то свойства. Я не помню, где мы про
периодичность говорим, где мы отремуем. То свойство у нас неверно. Оно, его здесь просто нет. Вот.
Теорема о предельном распределении переносится. А, ну, у нас, кстати, там, по-моему, и не было
никаких при периодичности ничего. То есть, о чем она говорит? Что вот эти p и g, которые здесь,
это не просто какие-то числа. Они, если мы проварьируем g, образуют распределение. Оно
стационарное, вот в этом смысле. То есть, оно стационарное в этом смысле, но вы дифференцируете,
получаете вот это. То есть, оно стационарное, вот это распределение стационарное, по-житому сходится к
нему. И вот это p от, каким бы ни было начальное распределение, при t, стремящемся к бесконечности,
сойдется к этому стационарному распределению, которое, опять же, единственно. Все то же самое,
абсолютно. Все то же самое. Ну и последнее, что я напишу, это аналог вот этой теоремы
о связи между средним временным и средним по пространству, по исходам. Как эта теорема обобщается?
Значит, теорема нападет со звездочкой в конечной однородной непрерывной цепи Маркова. Ну там
непрерывными право траекториями. Ну это у нас так всегда. Что у нас справедливо? Ну там у нас
был ряд, потому что время было дискретно, теперь время непрерывно, у нас интеграл. Индикатора того,
что x, наш процесс, t равно g, равно g dt, да, вот это сходится к p-житому, который является
пределом p-житых от t для любого i, при t, стремящемся к бесконечности. Вот это наше временное среднее,
вот это наше пространственное среднее, потому что это вероятность, вероятность это некое
мотожидание. Вот по исходам некоторые там Бернольско случайные величины, поэтому это говорят
среднее по пространству, по вероятностям пространства, по пространству исходов. Вот, а это
среднее временное, видите, как у нас мы можем быть в этом состоянии g, можем не быть, в какие-то
моменты времени мы там есть, в какие-то мы там, нас там нет. Ну вот берем интеграл, как бы регистрируем
все случаи, когда мы пребываем в этом состоянии, но еще делим на t, потому что нам среднее нужно,
но оказывается, что вот эта вещь сходится вот сюда, но это мы берем без доказательств. Просто такой
аналог, что и в непрерывных цепях тоже такая тярема есть. Вот. А, да, нужно, конечно, в конечной
оргодической. Спасибо. В неоргодических цепях вот это может не быть, поэтому, да, спасибо. Хорошо.
Ну вот это было все, что как бы мы получаем, как в дискретных цепях, аналоги в непрерывном случае.
Теперь движемся дальше. Будем переходить к случаям, которые особенные для непрерывных цепей. Ну,
а сначала я веду определение процессы гибели и рождения из биологии пришло. Значит, вот такой
процесс. Значит, 0, 1, 2, n-1. У меня будет верхой и внизу стрелки. Значит, стрелка мы обозначаем
возможный переход, а над стрелкой мы рисуем интенсивность перехода. Лямда 1, по-моему, я ее обозначаю сейчас.
Лямда 2, здесь будет лямда минус 1, лямда n. Так, а здесь мил n. Здесь мил n, мил 3, мил 2, мил 1.
Все лямды имеют интенсивности переходов. n меньше либо равно бесконечности, натуральное число. То есть, в принципе,
может быть цепь бесконечная. Вот. Значит, вот такая цепь Маркова таким графом, она называется процессом
гибели и рождения. Просто можете написать. Процессы такого вида называются процессами гибели и рождения.
Лямды называются интенсивностями рождения. Они могут быть все одинаковыми, могут быть равными. Какие-то из них
они могут быть равны нулю. То есть, где-то перехода может не быть. Вот. Интенсивности рождения,
интенсивности гибели. Ну, откуда это берется? Вот. Иногда вводят в биологии где-то такие модели,
что ты рассматриваешь размер популяции некоторой. Вот. Популяция, то есть, сколько у тебя видов
существует. Ну, не видов, а, как это назвать, экземпляров твоего вида существует в рассматриваемой
системе. Это процесс некоторый, да, непрерывно зависящий от времени. И вот это сколько их,
короче говоря. И вот есть такие модели, процессы гибели и рождения, которые описывают эволюцию числа
экземпляров некоторого вида. Ну, это вот самая общая такая, самый общий вид принимают. Такие модели
рассматриваются. Допустим, у тебя никого, допустим, ну да, вот конечно странно, как из нуля может
получиться единица, из единицы получится кто-то, да, ну понятно, что там можно начинать, есть интенсивность
здесь нулями там расставить, да, там в одну только сторону. Если ты сюда пришел, то, например, из нуля в
единицы у тебя не может быть, поэтому и 1 равно нулю. Из одного 2 тоже не может быть, если тогда
и 1 и 2 равно нулю. А здесь вот, допустим, у тебя было два, кто-то умер, стал один, кто-то умер,
стал ноль и все, и дальше уже стрелка никуда не идет, ну либо ты рисуешь ее как бы на себя. Вот, то есть
вот эта вот модель для, в биологии, для эволюции количества экземпляров вида. Это лямбда интенсивности
рождения, мил интенсивности гибели. Лямбда ит, мил ит, они больше либо равны нуля. Вот, n меньше либо равно
бесконечности. Но здесь одну теорему я сформулирую без доказательства. Стационарное распределение
вот в такой цепи, то есть если n меньше бесконечности, то стационарное распределение мы можем записать,
пи 0 это вектор. Вот с такими вот компонентами. Значит, пи gt 0, это есть лямбда g разделить на мю,
на пи g-1. Для g больше равных единицы, то есть пи первое, пи второе и так далее до конца. И нам здесь
не хватает только пи 0 определить. А пи 0 определяется так, чтобы сумма всех пи была равна единице. Так что
пи 0, ну там большая формула такая. Я ее напишу, значит 1 плюс лямда 1 мю 1 плюс лямда 1 лямда 2
разделить на мю 1 мю 2 плюс и так далее плюс лямда 1 лямда n разделить на мю 1 мю n в минус первой
степени. Эта формула, сумма всех них должна быть равна единице.
Поэтому пи 0 должен быть вот таким. Ну без доказательства, хотя там по большому счету
ничего сложного нет. То есть если вы эту формулу не запомните, тогда вы ее всегда можете вывести.
Вы просто пишете матрицу Q для вот этой вещи и ищете пи 0 такой, что Q транспонированная пи 0 равна 0.
Ну и там, когда вы посмотрите, вы просто увидите, что эти пи должны быть вот такими, а пи 0
должны быть таким, чтобы сумма их всех была равна единице. Вот и все. Вот.
Если все мю равны 0, а лямда не 0, это называется процессом рождения или процессом чистого рождения.
Если все лямда равны 0, мю не равны 0, это процесс чистой гибели. Бывают там разные варианты,
как вы расставите мю. Мю и лямда могут быть одинаковыми, могут быть разными, какими угодно.
Вот этот процесс гибели рождения. Хорошо. Это понятие мы вели. Дальше идем.
Поговорим про взрывные марковские цепи. Такого нет в дескретных цепях.
Значит, еще раз вспоминаем, как ведет себя типичная цепь маркова. Вот я нарисую ось
времени. Допустим, здесь 0. Если мы стартуем из какого-то состояния, мы живем в нем показательное
время. Когда это время проходит, мы куда-то скачем. Пусть это момент времени t1. Вот. Когда мы куда-то
скакнули, мы там тоже живем показательное время. И оттуда мы тоже скакнем в какой-то другой момент
времени t2. Потом какой-то момент времени t3 и так далее. Пусть вот эта последовательность t это
момент времени скачков. Вот к чему сходится эта последовательность? Таким вопросом зададимся.
Вседалее она идет в бесконечность. Может ли она дойти до некоторого предела? В дескретных цепях это
невозможно. Вот. А в непрерывных цепях, смотрите, ведь мы живем какое-то время показательно распределенное
сначала интенсивности лямбда 1. Вот здесь. Здесь мы живем, вот давайте я тут напишу, лямбда 1, здесь
лямбда 2 и так далее. Вот эта лямбда — это интенсивность. И за что она отвечает? 1 делить на лямбду — это
среднее время для t1. Помните, математическое ожидание такой случайной величины — это 1 делить на
лямбда 1, что называется интенсивностью, потому что обратная к ней величина — это среднее время,
среднее время получается. Если t — это время, тогда 1 делить на лямбда — это среднее время, то есть
среднее значение того, сколько мы будем жить в каждом состоянии. Так вот, если здесь какая-то
лямбда 1, здесь лямбда 2, которая получается больше, чем лямбда 1, а значит 1 делить на лямбда 2
меньше, время жизни меньше. Лямбда 2 больше, время жизни меньше. И допустим, что здесь лямбда 1,
здесь лямбда 2, здесь лямбда 3, и так далее. И вот эта лямбда n, она очень быстро уменьшается.
Может ли получится так, что у тебя за конечное время произойдет бесконечное множество переходов?
вот оказывается может такие цепи называются взрывными вот это они характеризуются тем что
это лямбда она очень быстро очень быстро увеличивается соответственно 1 делить на лямбда
очень быстро уменьшается и у тебя как бы вот это время жизни в каждом состоянии оно очень
очень быстро уменьшается и на самом деле цепь производит бесконечную множество переходов за
конечное время но давайте поймем как как как так получается и каковы условия когда так получается
значит мы будем называть цепь взрывной значит цепь маркова x отт назовем взрывной если вероятность
того что тн стремится к бесконечности равна единице вот то есть вероятность множество
исходов на которых тн сходится к бесконечности а господи нет не бесконечности а какому-то
извините это ноль меньше бесконечности вот ноль кстати тоже плохо да а т ноль у нас нет у нас
мы начинаем от единицы ну допустим вот если она равна единице кстати равносильно тому если
для любого состояния и у тебя вероятность тн сходится к т ноль при условии что в начальном
момент времени это стартовал из и если вот эта вещь равна единице но этот формул следует из
этой по формуле полной вероятности вот называется взрывной если но иначе она не взрывная вот иначе
она не взрывная если если вероятность вот этого меньше единицы да
чего мысли нет ну почему она может стремиться к бесконечности это типичный случай когда она
стремится к бесконечности обычно она стремится к бесконечности вот мы рассматриваем такой
интересный случай когда она стремится не бесконечности какому-то числу вот не взрывная
когда это вероятность меньше единицы она не обязательно равно нулю принципе как бы какая-то
мера возможно но я не знаю если там теорема о том что это вероятность может быть только либо
0 либо 1, ну взрывные определяют, когда эта вероятность равна единице. Вот, когда почти все
траектории, они как бы заканчиваются за конечное время. Сформулирую теорему из теории вероятности и
докажу ее, которая поможет определять, является ли цепь взрывного или нет.
Значит, теорема. Значит, пусть КСН от Единства Бесконечности это независимые случайные
величины с показательным распределением СИТ. Распределено показательно, как лямбда и Т. Лямбда могут
быть разными, могут быть одинаковыми. Вот. Пусть. Тогда. Как независимость. Да, это обязательно.
Тогда. Значит, если вот такой ряд, если такой ряд сходится, то тогда вероятность сумма КСН меньше
бесконечности равно единице. Вот. Тогда вон тот ряд почти наверное сходится. Если этот ряд расходится,
то тогда и вот этот ряд расходится. Ну вот. Давайте доказывать теорему.
То есть эта теорема как раз следует, как сильно должны увеличиваться лямбды. Как быстро. Доказательства
очень простой в этой теоремы. Начнем с первого пункта. То есть пусть сумма сходится. Тогда мы
рассмотрим вот такой ряд и математическое ожидание его. Это есть как раз, мы можем
математическое ожидание носить внутрь. Это мат. ожидание КСН, а это как раз 1 делит ноль
Вот. Ну сходится. По этому предположению. Значит, математическое ожидание вот этой величины
конечно. Значит, у нас вероятность единицы принимает конечные значения. То есть вероятность того,
что сумма КСН меньше бесконечности равна 1. Потому что если бы была не нулевая вероятность,
что она принимает бесконечное значение, то мат. ожидание было бы бесконечным. Правильно? Понятно
это? Значение умножить на вероятность. И там среди слагаемых будет значение бесконечность умножить
на вероятность, которая не ноль. Значит бесконечность. А мы показали, что мат.
ожидания конечна. Все значит с вероятностью единицы она принимает конечные значения. Отлично.
Вот. Теперь вон тот случай. Ну немножечко похитрее. Немножечко похитрее. Не знаю,
где писать. Давайте здесь попробую уместить. Значит пусть теперь вот эта сумма равна бесконечности.
Рассмотрим как бы невзначай математическое ожидание экспоненты от минус суммы бесконечность КСН.
По-моему такое. Да. Рассмотрим. Ну экспоненты суммы есть произведение экспонент, так как они
независимые, то мат. ожидания произведения экспонент будет равна произведению мат. ожидания. Так?
У нас так всегда было. Значит что мы получаем? Произведение математических ожиданий экспонент
минус КСН в силу независимости. Ну мы знаем распределение КСН. Мы можем вычислить мат.
ожидания экспонента минус КСН. Ну я сразу же напишу чему это равно. Ну просто взять некий
интеграл. Получается это элементарно. Получается там 1 разделить на 1 плюс лям ДН в степени минус 1.
Вот. Ну просто честно взять интеграл, там почитать на мат. ожидания, получится вот такая вещь.
Вот. Ну вот оказывается, что вот это произведение равно нулю. И здесь существенно то, что вот этот ряд
расходится. А понять это можно так, что мы докажем, что произведение равно нулю, если логарифм вот этой
вещи равен минус бесконечности. Ну либо минус логарифм этой вещи равен плюс бесконечности. Вот.
А это означает минус, значит сумма, ну логарифм произведения равно сумме логарифмов. Да. Да.
Я это. 1 плюс 1 разделить на лям ДН. Вот. Ну а этот ряд, он сходится и расходится тогда же,
когда и вот этот ряд. Ну, например, там по признаку сравнения, да. Вот. Ну здесь мы
пользуемся тем, что это положительные величины. Вот. Здесь все хорошо с этим. Там никакие незнаки
чередующиеся. Здесь все знака постоянная. Вот. Так что этот расходится, значит этот ряд расходится.
С минусом он равен минус бесконечности. Потенцируем обратно. Значит получается,
что это произведение равно экспоненте от минус бесконечности. То есть то. Вот. То есть получается,
что математическое ожидание не отрицательной величины экспонента равна нулю. Ну никуда не
деться, значит она должна быть равна нулю почти всюду. Вот эта экспонента, вот эта сумма,
минус суммы. Экспонента равна нулю. Значит, минус сумма равна минус бесконечности. Значит,
сумма равна бесконечности. Почти всюду. Вот и все. А это нам и нужно было доказать.
Итак, мотожидание неотрицательной величины равно нулю. Тогда и только тогда, когда эта величина
почти всюду равна нулю. Это означает, что... а это возможно тогда и только тогда, когда почти
всюду вот эта сумма равна плюс бесконечности. С минусом будет минус бесконечности, экспонент
минус бесконечности ноль. Вот. Вот такая интересная теорема. Она никак не использует случайный
процесс здесь. Это такая теорема из теории вероятности, но она очень такая красивая,
поэтому я ее здесь привожу. Ну и мгновенное следствие отсюда. Если вы рассматриваете процесс
чистого рождения, то тогда скачки как раз происходят в эти моменты времени,
которые равны суммам вот этих кси, где кси показательно распределенные. Так что если процесс
чистого рождения, то он взрывной тогда и только тогда, когда вот этот ряд расходится. Процесс
чистого рождения взрывной тогда и только тогда, когда ряд вот этот расходится. По-осонненский
процесс. Это процесс чистого рождения. У него какой? Граф ноль, один, два и так далее. И здесь стоит
лямда везде. Все лямды одинаковые. Так. И ряд один разделить на лямда расходится для по-осонненского
процесса. Значит, у нас вот этот случай. Значит, по-осонненский процесс не взрывной.
По-осонненского процесса это невозможно. Вот. По-осонненского процесса это невозможно.
Чтобы процесс был взрывным, интенсивности должны расти достаточно быстро. Они у него вообще не
растут. Так. Следующая тема сегодняшней лекции — потоки событий. Не можем обойти стороной
эту тему, потому что она очень прямо и непосредственно связана с непрерывными цепями Маркова. Значит,
потоком событий называется последовательность одинаковых событий, которые происходит как-то во
времени. Вот здесь числовая ось. Ось времени. И здесь как-то происходят события в какие-то
моменты времени. Вот здесь произошло события. Здесь произошло, здесь произошло, здесь произошло,
здесь, здесь, ну и так далее. Вот они как-то проходят последовательности одинаковых событий
называются потоком — поток событий. Вот давайте немножечко изучим вероятностные свойства таких
потоков событий при некоторых предположениях. Первое, что мы сделаем, мы ведем случайную
величину n t1 t2. Это сколько произошло событий на интервале времени t1 t2? Это число событий
на интервале t1, но там формально надо справа открыто держать, чтобы все было
корректно потом. Число событий на t1 t2. Какие мы сделаем предположения? Во-первых, рассмотрим
однородный поток событий. Пусть n t1 plus h, t2 plus h и n t1 t2 имеют одинаковое распределение.
Пусть они одинаково распределены. Тогда поток называется, как вы уже могли бы догадаться,
однородным или стационарным. Сколько событий произойдет, зависит только длина интервала,
но не зависит от того, где ты рассматриваешь этот интервал. Бывают, конечно, не однородные
потоки событий. Мы пока поговорим про однородные потоки событий. Еще одно предположение ведем.
Сколько событий происходит здесь, пусть не зависит от того, сколько событий происходит здесь,
то есть на непересекающихся интервалах. Пусть kt есть n tk tk plus 1, где там 0 t1 t2 и так далее.
Вот такие вот моменты времени. Пусть kt такие и пусть они независимы в совокупности для любых
вот этих вот ткатах. Их может быть конечное, бесконечное множество, счетное. Пусть они все
независимы в совокупности. Сколько здесь, сколько здесь происходит, пусть они независимы. Кстати,
это напоминает то, когда я вводил полосуновский процесс, помните? Тут все взаимосвязано,
абсолютно. Тогда такой поток называется потоком безпоследействия. Такая терминология
сформировалась. А вот теперь давайте мы применим наши знания о непрерывных маркетических
цепях и изучим вот эту величину n, число событий на интервале времени. Но мы будем говорить только
про однородные потоки безпоследействия. И тогда нам неважно рассматривать, где вот эту n,
где ее локализовать. Давайте мы для определенности возьмем t1 равный 0, например, и будем рассматривать
n0t, то есть это n0t, число событий на интервале от 0 до t. Это процесс. Вот давайте мы его изучим.
Что это за процесс такой? Сколько событий произошло на интервале времени от 0 до t. Смотрите.
Время непрерывно. Множество состояний дискретно 0, 1, 2 и так далее. Что напрашивает сразу? Не
является ли это маркетским процессом, причем непрерывной цепью Маркова? Но является ли он
марковским? Он безпоследействия. Значит все вот эти независимые совокупности. А что это такое? Это же
есть приращение икса на вот этих интервалах времени. Так? n tk n tk плюс 1 это есть n от tk минус n
плюс 1 минус n tk. Вот. Тогда получается, что если они независимы в совокупности, то приращение этого
процесса на непересекающихся интервалах независимо в совокупности. А как это называется?
Если процесс имеет независимые... Как это называется? Если дан процесс независимыми приращениями,
то он марковский. Это процесс независимым приращениями. Да, вы совершенно правильно
вспомнили. У нас была теорема. Следовательно, x от t это процесс независимыми приращениями.
Следовательно, он марковский. Вот. Была у нас такая теорема. Так что марковский процесс с непрерывным
временем и дискретно множеством состояний. Следовательно, это n от t или x от t или n от t это
одно и то же. Это непрерывная цепь маркова. Дальше. Для того, чтобы нам как бы подключить
всю эту библиотеку знаний, говоря на языке программирования, а непрерывных цепях и просто
применить ее к этому. Нам чего не хватает? Самое важное. Что нам? Я вас, я к вам подводил сегодня в
начале лекции. Что нам нужно, чтобы вот эту всю науку, которую мы развили на прошлой лекции,
применить к этому процессу? Какое? Что нам нужно еще пожелать от этого процесса? Не-не-не-не-не. Еще
раньше. Самое первое. Без чего бы мы бы ничего не получили. Главное наше предположение о процессах.
Не-не-не-не. Еще самое. Еще. Еще важное. Непрерывность права траекторий. Это ключевая вещь. В этом смысле,
непрерывность справа. Это значит, что когда какое-то событие потока произошло, обязательно есть
какой-то конечный интервал, пусть и малый, когда больше никаких событий не происходило. Нет такого,
что какой бы ты маленькую окрестность не брал, там все равно будут какие-то события. Смотрите,
как это. События, как это. Всюду плотно. Такие вот нефизические ситуации мы не будем рассматривать.
Так что, да, сделаем дополнительное предположение о том, что когда какое-то событие происходит,
обязательно есть какое-то конечное, пусть и малое, но конечное время, когда больше никаких событий
не происходит. То есть, пусть между событиями проходит конечное время. Но тогда это будет
значить, что вот этот процесс С на Т или Х от Т, он имеет непрерывные справа траектории. Все.
Отсюда мы мгновенно получаем всю науку. Всю оставшуюся науку. О существовании, о том,
что П непрерывные, дифференцируемые, о том, что матрица Q, о том, что мы живем в каждом состоянии
и показательное время и так далее. Мгновенно следует отсюда. Каковы же интенсивности этих переходов?
Значит, во-первых, давайте мы так посмотрим. Что нам надо? Граф этой цепи, как он выглядит?
Из 0, 1, 2 и так далее. Если мы рассмотрим вероятность перехода из И в И плюс 1 на
конечном интервале времени, то это будет означать вероятность того, что N в момент H,
ну или так вот, Т плюс H, равняется И плюс 1 при условии, что N, ну для любого Т, потому что процесс
однородный. N на T равно I. Вот. И теперь, если мы знаем, что N на T равно I, мы от этой части вычтем N на T,
а из этой вычтем I. Они же равны. Тогда мы получим вероятность N. Да, и так как процесс однородный,
мы уберем вот эту T. Тогда получается, что NH, как бы тут лучше поступить. NH минус N0, но N0 равно 0.
Хотя, если N0 начинать не от 0, то тоже все нормально. Ну ладно, может быть, я пока оставлю T. Давайте
попробуем так. N на T равно 1 при условии, что N на T равно I. Вот. Так, вы видите, здесь И пропало. Это тоже
важно. И пропало. Но процесс имеет независимые приращения. Вот это приращение не зависит от
этого NT минус N0. Поэтому это мы убираем. У нас остается вот это. Вот. А это означает вероятность N
ATT плюс H равно 1. Вот. А это означает в силу однородности N0H равно 1. То есть вероятность NH равно 1.
Вероятность того, что на интервале 0H произошло одно событие. Это с одной стороны. С другой стороны,
мы знаем, что у этой вещи существует производное. Что Pi плюс 1H разделить на H
сходится к некоей лямбде. Причем так как вот эта штука убралась, и она от И не зависит, то она от
И не зависит. То есть Pi запятая I плюс 1 от H разделить на H сходится к лямбде. И лямба от И не
зависит, потому что здесь мы убрали ее. Она убирается. Вот. Это где лямбда и интенсивность
перехода. Получается, что они все имеют одинаковую интенсивность перехода. Вот так. А отсюда следует,
что если ты теперь рассмотришь И и плюс два, то у тебя там будет порядка H квадрата, и она уже
сюда, и такой стрелочки уже нет. Вот. Потому что переход отсюда сидал, но уже порядка H квадрата.
Вероятность перехода от H, как H квадрат. Вот. Значит, достаточно, значит, граб действительно такой.
Значит, граб действительно такой. Ну вот. Вот эта лямбда называется интенсивностью потока. Она
одинаковой у однородного процесса. Мы могли вводить не однородный процесс, тогда она бы зависела от
времени. Ну просто потому, что мы бы тогда не смогли вот здесь избавиться от Т. То мы ее убираем,
и у нас получается число. Видите? Независище от И, не от времени, от Т, ни от чего независище. А так,
если бы процесс был не однородным, мы бы просто не смогли убрать вот это. Все выкладки бы оставались,
мы просто не смогли бы убрать вот это. Ну, лямба тогда бы зависела от Т. Была бы лямда от Т. Она не
зависела бы от И. То есть, везде вот здесь была бы не просто лямда, а лямда от Т. Вот. Для не однородного
потока. Ну, мы для простоты однородным пока ограничимся. Вот. Так что отношение вот этих
вероятностей лямбда. И, а эта вероятность, есть вот эта. Значит, получается, что вероятность nH
равно единице, это есть лямбда H плюс умалая от H при H, стремящемся к нулю. А вероятность,
ну, из этих же выкладок, если мы рассмотрим переход из 0 в 2, мы можем доказать, что вот
эта вещь, она тоже умалая от H при H, стремящемся к нулю. Ну, и отсюда следует, что вероятность nH равна
нулю. Это есть единица минус лямбда H плюс умалая от H при H, стремящемся к нулю. Вот. Такие формулы.
Вообще, потоки, которые обладают вот этими свойствами, которые здесь выписаны, они еще
называются ординарными потоками. Нарный поток. Это свойство ординарности, то, что я там написал.
Это свойство ординарности. Ну вот. Так что теперь мы все понимаем про нашу цепь. Здесь она стартует
из нуля. Она живет в состоянии показательное время интенсивности лямбда. Вот. Потом скачет в единицу.
Потом живет в этом состоянии показательное время с лямбдой. И скачет дальше. И так далее. Вот. А это
есть не что иное, как полусоновский процесс. Вот. То есть получается, что nT в этих предположениях,
которые мы сделали, это полусоновский процесс. Вот мы к нему пришли. Получается, что а соответствующий
поток при этих предположениях называется простейшим полусоновским потоком событий. То есть это поток,
который однородный, без последствия. Вот. И, например, с непрерывными траекториями вот здесь,
или такой, что они не могут быть бесконечно близки, два события. Либо можно без этого,
а говорить сразу про ординарность. Вообще, я бы хотел сейчас поговорить с вами вот все оставшееся
время, потратить на эквивалентные определения. Если вы откроете разные книжки, вы увидите,
что все эти понятия по-разному и всеми вводятся. Вот. Часто сначала вводятся потоки, а потом на их
основе вводится определение непрерывных цепей Маркова. Иногда наоборот. Как я поступил? Я
сначала ввел вам определение непрерывных цепей Маркова, а потом мы рассмотрели потоки,
примитивные свойства, и разобрали эти потоки с точки зрения непрерывных цепей. И мы увидели,
что nT это непрерывная цепь с такими-то свойствами, и при этих свойствах она даже совпала с
полусоновским потоком. Так. Это вот один путь. Путь номер два. Очень распространенный в учебниках.
Цепи потом. Сначала потоки. Дан поток событий, однородностью назовем вот это,
без последействия вот это, и ведем ординарность вот таким вот образом. Тогда можно доказать,
что nT это полусоновский процесс. Но при таком подходе ты пастулируешь вот это. А откуда это
берется? Вот понимаете, это то, что мне не нравится всегда. Не физические предположения. Ну что такое
вероятность того, что nT равна единице? Вероятность того, что на интервале 0H произойдет одно событие,
если лямбда H плюс ума латаш. Откуда вообще это берется? Что это такое? Почему мы такое предположение
унимаем? Зачем нам эта дифференцированность? Что она дает? Откуда она и берется? Ну непонятно. Вот.
Но для простоты, тем не менее, такой ход делают. А я же вам по-другому веду. Я сначала вел непрерывные
цепи, и мы разобрались с вами, что такое интенсивность? Откуда вообще это появляется? Откуда это
интенсивность появляется? Потому что вероятность перехода вот этой житоатаж, она дифференцируема.
Она еще так же и непрерывна. Откуда следует непрерывность? Потому что по траектории справа
непрерывные. Понимаете, эти все связи вы должны обязательно проследить, и на экзамене должны эти
знания показать, как это все взаимосвязано между собой. Что являются причиной для чего? Мы
предположили, то есть фундаментальная вещь на самом деле, это то, что между событиями происходит
конечное время. Это помогает нам всю эту науку связать с непрерывными цепями Маркового,
которая очень глубоко проработана. Я хочу, чтобы вы это понимали. Просто так это аксиоматизирует,
непонятно откуда это берется. Но сейчас я вам показал, как это выводится на самом деле. Выводится
из более-более каких-то базовых предположений. Непрерывность траекторий или то, что события не
могут происходить, как бы между событиями обязательно проходит какое-то время. Вот,
когда уже следует вот это. И то, что цепь живет показательное время, это тоже мы получили как
следствие того, что существуют вот эти интенсивности, а эти интенсивности есть производная этих
вероятностей. Вот, и эти интенсивности есть время пребывания. Если ты сразу постулируешь
ординарность, тогда ты не понимаешь физический смысл лямб. Откуда они взялись? У нас лямб
появились как производные П, и мы доказываем, что эти производные П являются временем, ну,
интенсивностью для времени пребывания. То есть ты знаешь физический смысл. Здесь, когда ты
сразу вводишь эти лямбды, ты не понимаешь физического их смысла. Ты должен воспользоваться этим и вывести
отсюда, что ты будешь показательное время жить в состоянии. В принципе, это тоже возможно,
если немножечко напрячься. Но строгих каких-то выкладок по этому поводу я, кстати, не видел. Вот
то, как я вам доказывал, вот это вот максимально строго, строгий подход. Помните, мы там всю
плотную множество брали, строили, вот это вот. Ну, некий формализм навели, но тем не менее. Как
здесь быть? Ну, так вот прям сходу не очевидно. Может быть, только если... Что значит, что время
пребывания больше t? Значит, у нас на интервале от t ничего не происходит. Значит, вот это и это у
нас в любой точке. Тогда мы должны взять вот это в скобочках и в степени порядка того, сколько
точек, порядок один разделить на h. Тогда при h стремящимся к нулю это стремится к экспоненте от
минус лямбда. Может быть, может быть, как-то вот так вот. Может быть, как-то так. Но вы должны
быть готовы к тому, что если вы открываете произвольный учебник, то вы будете увидеть там
совершенно разные способы определить непрерывные цепи Маркова и потоки. Кто-то начинает с одного,
потом другой. Кто-то так, кто-то сяк. Ну, вот я решил вот такой подход устроить. Потому что
иначе то там, то сям будут утверждения, которые мы интуитивно понимаем, но доказать не можем,
потому что нет строгей науки. Для инженерных, для книжек, для инженеров это нормально. Вот,
например, есть очень хорошая на самом деле книжка Венцель, которая ЕС, Венцель Елена
Сергеевна. Знаете, она еще книжки детские писала. Замечательные книжки она пишет. И вот у нее подход,
по-моему, там изначально через потоки. Вот она там не везде, вот формально может быть строго,
но там как-то вот у нее очень удачно построено рассуждение, что ты все интуитивно понимаешь,
и в принципе тебе этого достаточно. Вот, так что можете эту книжку посмотреть, может быть кому-то
она очень понравится, но я здесь все-таки пытаюсь некоторую и формальную науку тоже построить,
хоть какую-никакую. Поэтому мне вот этой книжки недостаточно, к сожалению. Так что мне приходится
искать какой-то другой путь и идти через непрерывные цепи Маркова. Так вот, хорошо,
это про связь потоков и непрерывных цепей. Теперь про плацсоновский поток. Как видите,
мы здесь пришли к плацсоновскому потоку. На самом деле, плацсоновскому процессу, на самом деле,
плацсоновский процесс можно определять через плацсоновский поток. Ну типа, мы ввели поток
с такими-то свойствами, тогда назовем плацсоновским процессом n от t. Он будет
обладать теми же свойствами, как если бы вводили плацсоновский процесс иначе. Вообще,
плацсоновский процесс можно ввести множеством различных способов. Давайте мы их все вместе
соберем. Первый способ, как я изначально сделал, аксиоматический. k от 0 равно 0, независимые
приращения, приращение k, плацсоновская величина от лямбды. Это один способ. Второй способ,
ввести его как процесс восстановления. Ну помните там, supremum n больше нуля, сумма меньше или больше,
меньше по-моему t. Мы доказывали, что они эквивалентные. Можно так ввести плацсоновский
процесс, как пример, как частный случай процесса восстановления. Третье, можно ввести плацсоновский
процесс, как непрерывную цепь Маркова. Вот таким графом, который в нулевом момент времени стартует из нуля,
все интенсивности одинаковые, равные лямбде. Это третий способ ввести плацсоновский процесс. И
четвертый способ ввести плацсоновский процесс. Ввести потоки, значит, ординарные, без последействия,
однородные. Поток ввести, он называется простейший плацсоновский процесс, тогда n от t для него,
это плацсоновский процесс. Вот четыре способа ввести плацсоновский процесс. Вот это запомните,
потому что это будет на экзамене билет такой, значит, рассказать об эквивалентных определениях
плацсоновского процесса. Это важная вещь, потому что они соединяют весь наш курс. Вот плацсоновский
процесс, мы о нем начали говорить когда еще там, на второй лекции. Смотрите, у нас сегодня предпоследняя
лекция, да, мы все еще говорим о плацсоновском процессе. Вообще, как бы, наука, она не про
определения отдельные, да, не про массив определений, массив теорем, а про то, что связывает все эти
определения и понятия. Вот вы должны это знать, вы должны это понимать. Вы должны, когда работаете,
значит, регистрировать для себя все вот эти связи между понятиями, потому что это и есть знание,
что вот для себя все отметим. Как связаны между собой непрерывные марковские процессы с
однородными потоками, что можно по-всякому вводить и так, и так. Вот я выбрал один из таких путей,
потому что мне хочется начинать с чего-то более фундаментального и потом уже практические вещи,
такие как потоки, описывать вот в этих фундаментальных терминах, то есть вести
некую математику такую очень может быть абстрактную, а потом уже рассмотреть какие-то
приложения этого. Вот есть поток, как распределено n от t, число событий, а вот мы применяем наш багаж
знаний, который у нас уже накоплен, и просто применяем к этому, и получаем сразу же кучу
следствий. То, что другие аксиоматизируют, они выводят. Понимаете? А почему они это аксиоматизируют?
Потому что они не хотят раскрывать все детали, потому что это очень много. Видите, у нас целая лекция
же на это ушла. Такая сложная, прошлая, нетривиальная. Вот эти все доказательства,
вот эти все теоремы. Вот, поэтому они аксиоматизируют. Ну а мы не аксиоматизировали,
мы вывели эти свойства. Вот. Ну, все тогда. Наверное, это все, что я хотел рассказать о непрерывных
цепях Маркова. И на следующей лекции вы посмотрите непрерывные марковские процессы. Это когда время
непрерывно и множество состояний непрерывно. Вот там много чего, но что, на мой взгляд,
вот ключевые вещи, какие вы должны оттуда вынести, это то, что марковские процессы с
непрерывным временем и множеством состояний, они тоже не могут быть всякими. И там тоже есть
вероятности переходов, и они тоже определенным образом, на них тоже есть уравнения. У нас было
уравнение для дискретных цепей, рекуррентного виде некоторое записанное. У нас было уравнение для
непрерывных цепей в виде системы обыкновенных дифференциальных уравнений написанных. А вот в
марковских цепях там уравнение в частных производных. Вот уравнение в частных производных,
которые имеют вид уравнений теплопроводности, кстати говоря. Вот вы можете помыть там, ну не то
что прям совсем произвольные, но довольно широкий класс марковских процессов, с которыми обычно
имеют дело. Вот у них матрица перехода и там плотности перехода тоже вы увидите, они удовлетворяют
уравнениям в частных производных, которые оказываются диффузионными уравнениями или уравнениями
теплопроводностями, смотря как ты это интерпретируешь. Вот как. А раз это диффузионные процессы, то это как-то
связано с процессом Винровским, что Винровский процесс, процесс Бронновского движения, чувствуете,
что есть такое? Вот там вы это посмотрите и почитаете у меня. Так что есть тоже некие уравнения,
тоже прямые обратные уравнения Калмогорова, какие-то я там, наверное, доказываю, какие-то я просто
пишу. Вот. Но главное, что они не могут быть всякими и оказывается, что вот они описываются в частных
производных, причем именно уравнения теплопроводности или диффузии. Вот. Что вот интересно. И вот,
например, в дискретных цепях все определяется матрицей перехода за один шаг. В непрерывных цепях
все определяется матрицей Q, производными. Так вот и там тоже есть некоторые, правда уже,
функции. Не матрицы, там какие-то, не числа, а именно функции, которые определяют процесс,
однозначно весь. Причем это свойства локальные. Обратите внимание, вероятность перехода за один
шаг определяет вероятность перехода за любое число шагов. Матрица Q это производная, причем в
начальный момент времени, производная P в начальный момент времени, локальная характеристика,
она определяет процесс всюду через диффур. Так и там вводятся некие матричные там функции,
значит A и B, которые тоже локальные, но оказывается, что они определяют весь процесс всюду. Вот это
тоже вы должны понимать. Это тоже такие ключевые моменты. Ну а все остальное, это уже технические
вещи. Будут тоже теоремы со своими условиями, там предположения там будут определенные вводиться,
но это я думаю, что вы почитаете. Все.
