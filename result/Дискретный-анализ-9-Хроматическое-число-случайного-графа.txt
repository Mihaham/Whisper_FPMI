Мы продолжаем, товарищи, заниматься хроматическим числом случайного графа,
и мы дошли до момента, когда у нас p равняется c поделить на n. С этим моментом мы подробно в
прошлый раз разбирались. Вот сейчас я сформулирую совершенно замечательный результат, который
доказан уже для случая, когда p все еще стремится к нулю, но стремится к нулю медленнее, чем c поделить
на n. Теорема, наверное, в самом лучшем, который известен сейчас в своем виде, она звучит так.
Пусть p как функция от n, p это вероятность ребра, естественно, по-прежнему, это есть n в степени
минус альфа, где альфа принадлежит вот такому вот интервалу от 1 и 2 до единицы. Ну, то есть альфа
строго меньше единицы, это означает, что n в степени минус альфа, если не стремится к нулю,
конечно, стремится к нулю, то во всяком случае медленнее, чем единица поделить на n. Но все-таки
альфа это не ноль. Альфа больше 1 и 2, это стремится к нулю с достаточно большой скоростью. Так вот,
тогда существует такая у, которая зависит от n и от альфа. Ну, некоторая функция t и от альфы
для каждого альфа своя, то асимпатически почти, наверное, хроматическое число случайного
графа, здесь g, это g от n, p, случайный граф, принадлежит вот такому вот множеству. Ну, я в прошлый
раз очень старательно давил на то, что хроматическое число плотно концентрируется. Помните, я много раз
произносил такие слова. Но тогда оно концентрировалось в одном значении вообще. То есть, сначала оно
равнялось единице асимпатически почти, наверное, потом двойке, потом тройке. Оказывается, что если
перескочить через вот этот вот порог c поделить на n и отправиться к нулю по вероятности ребра
медленнее, то возникает уже некая функция. Эта функция на самом деле стремится к бесконечности,
при n стремящемся к бесконечности. Но тем не менее, несмотря на то, что она растет из множества всех
значений, какие могло бы принимать хроматическое число, а их n штук, оно выбирает почти всегда
только эти два. Тоже высочайшая плотность концентрации, но чуть-чуть более низкая в двух значениях. И это
по делу, там действительно два значения. То есть концентрации в одном значении там нет. Это тяжелая
теорема. В такой формулировке я не буду ее доказывать. Я докажу более простой, тоже совершенно
нетривиально. Тоже может быть опущу некоторые детали, но там очень красиво, там очень важная
идея с концентрацией меры. Я докажу вариант, когда а больше чем две третих, то есть слабее не
больше, чем одна вторая, а больше, чем две третьих. Более узкий интервал будет. И я докажу,
что концентрация в четырех значениях имеет место, а не в двух, как мы сейчас знаем. Четырех.
Но это слабее, но все равно круто, потому что не растет множество значений, не стремится к
бесконечности. Значения самого У при разных Н разные. Они растут, стремятся к бесконечности. Но
множество значений самого хроматического числа все время остается мощности 4 или даже меньше. Вот мы
знаем, что два, но два не докажем. Докажем 4. Но это мы, боюсь, не сегодня докажем, хотя черт его знает,
может повезет. Это непростой результат. Тут нужно будет сделать некоторое количество лирических
отступлений, но не совсем лирических, конечно, а математических. Вот мы с вами пользовались чем? Мы
с вами пользовались неравенством Чебышова до сих пор. Когда мы доказывали концентрацию меры,
что с вероятностью стремящести к единице что-то там тесно очень принимает значение около своего
среднего, мы пользовались неравенством Чебышова. Вот сейчас я как раз хочу доказать эту теорему,
показав, что неравенство Чебышова в ней не сработает. То есть это такой результат, который не может быть
получен с помощью неравенства Чебышова. Там потребуется более сильная оценка концентрации меры.
Вот я обращусь к слушателям. Было ли у вас в курсе теории вероятности что-нибудь кроме неравенства
Чебышова? Оценки уклонений какие-нибудь или еще что-то? Это иногда бывает рассказано.
Случайные блуждания. Но тогда я расскажу. Я люблю это рассказывать. Нам это все равно потребуется
еще потом, когда раскрасками, другими там для гиперграфов будем заниматься. В общем, там много
для чего это нужно. История начинается со случайного блуждания.
Напрямую.
Что имеется в виду? Очень простой процесс. Есть обычная бесконечная прямая. На ней имеются целые
числа, целые точки. Ну, в шуточной интерпретации можно сказать так, что вот здесь в начале координат
находится кабак. Из этого кабака выходит пьяница, который настолько пьян, что ему уже, в общем,
совершенно без разницы идти направо или идти налево. Ну, соответственно, с вероятностью 1,
2 он отправляется в точку 1. С вероятностью 1, 2 он перемещается в точку минус 1. Дальше в
соответствующей точке, куда он отправился, чуть-чуть покачался. И снова, по независящим ни от чего,
ну как сказать, обстоятельствам, в общем, принял решение идти куда-то дальше. Например, пришел
сюда сначала, покачался, пошел обратно. Или нет, может быть, пошел сюда. И так каждый раз с
вероятностью 1, 2 он смещается то ли направо, то ли налево. Ну, можно, конечно, обобщать эту
ситуацию. Представить себе, например, что дорога не стопроцентно ровная, как здесь нарисована,
а какая-нибудь вот такая. Тогда он с большей вероятностью покатится вниз, чем станет
подниматься наверх. Ну, то есть, можно заменить 1, 2, 1, 2 на какие-то пояку. Фактически мы будем
иметь дело со схемой испытаний Бернуль. Вот. Ну, или можно так описать этот процесс. Есть кси1,
так далее, ксен, независимые случайные величины, независимые в совокупности, то есть,
взаимно независимые, не попарно там, взаимно независимые. Вот. Которые устроены следующим
образом. Кси1 равняется плюс 1 с вероятностью 1, 2 и минус 1 тоже с вероятностью 1, 2.
Тогда это с индексом n равное кси1, плюс и так далее, плюс ксен, это положение пьяницы в момент
времени, точка, в которую он пришел. Вот пафос, который я всегда сюда вкладываю. Ну, то ли почему
пить меньше надо, то ли почему алкоголизм случается. Дело в том, что этот процесс устроен
следующим образом. Крайне мала вероятность, с которой пьяница далеко уйдет от кабака. А вот
насколько она мала, действительно, вот очень естественный вопрос. Мы хотим посчитать вероятность,
которой это n больше какого-то, или может быть, больше либо равняется. Ну, первое,
что приходит в голову, это использовать неравенство Чебышова. Написать, давайте,
как написать? А вот так написать. Минус мат ожидания это n больше, чем а минус мат ожидания это n.
Ну, просто тупо вычитаем мат ожидания слева справа, правильно? Неравенство. Но
чему равно мат ожидания это n? Нулю, конечно, да. Ну, потому что мат ожидания линейна, а тут они еще
и независимая, но она всегда линейна. То есть, мат ожидания каждой это 0, очевидно, сумма нулей это
тоже 0. Ну, то есть, фактически, это можно вот так написать вероятность того, что это n. Здесь 0 не
писать, а вычесть все-таки мат ожидания, а справа убрать мат ожидания, вспомнив, что оно равно нулю.
Вот тогда это предельно похоже на неравенство Чебышова. То есть, это получается не больше,
чем вероятность, с которой модуль этой разности больше, чем а, а это по неравенству Чебышова не
больше, чем d это n, n поделить на а в квадрате. Так, дисперсия этой n какая? Они независимы,
поэтому дисперсия суммы это сумма дисперсий. Ну, какая дисперсия у каждой из них? Мат ожидания
0, а мат ожидания квадрата, то есть, второй момент один же, но из-за единицы вычитаем 0, получаем
единицу и складываем n таких единиц. То есть, будет n поделить на а в квадрате. Ну, вроде неплохо,
то есть, вероятность удалиться на расстояние больше, чем корень из n по порядку, она уже стремится к нулю.
Так, а я утверждаю, это теория, то вероятность, которой это n больше, чем а, она не превосходит
куда-как меньшей величины, а именно вот такой. Я в степени минуса квадрат поделить на двое.
Ну, это узнаваемо в принципе, то есть, у вас видимо была какая-нибудь там предельная теория
или не было? Не было, да? Ну, не важно. Ну, вы знаете, нормальное распределение, там оно как-то вот так
выглядит, е в степени минус х квадрат пополам. То есть, что-то такое узнаваемое, но почему это просто
несопоставимо меньше, чем то, что нам дает неравенство Чебышова. С точки зрения, понимаете, той границы,
начиная с которой вероятность стремится к нулю, ничего нового не случилось. Как здесь а должно
быть больше-больше, чем корень из n. Так и здесь, конечно, а должно быть больше-больше, чем корень из n.
Иначе стремления к нулю не будет. Но здесь оно как бы сверхэкспоненциальное, а здесь оно полином.
Ну, можно просто явный пример привести. Представьте себе, что n это 10 в шестой, а это 10 в четвертый.
То есть, пьянице предоставлено время порядка 12 суток, если он каждую секунду перемещается в каждую
Ну, делает очередной шаг. Если он делает очередной шаг раз в секунду, то это 12 суток нетрезвения.
Какой ужас. С какой вероятностью, спрашивается, за миллион шагов он отойдет от кабака хотя бы на расстоянии 10 в четвертый.
Но неравенство Чебышова нам говорит, давайте разделим 10 в шестой на 10 в восьмой и получим одну сотую.
Ну, это, в общем, маленькая вероятность. А неравенство, которое я утверждаю, что на самом деле верно и уже почти не улучшаемо.
Это теорема близка к точной. Это е в степени минус 50. Ну, потому что здесь стоит то же самое.
10 в восьмой поделить на 10 в шестой. Это 100, но пополам еще 50. Это е в минус 50 степени.
То есть, если глядя на это, пьяница может сказать, ну дайте мне 120 дней, я 100 раз напьюсь и каждый раз по 12 дней буду ходить.
Не трезвее, да? Ну, какой-то шанс уже есть, что вероятность может приблизиться к единице того, что я уйду на расстоянии 10 тысяч.
Но когда мы ему показываем вот это, он понимает, что это все. Это уже, знаете, есть такая история про квадриллион километров.
Это все. Это он никогда не пройдет. Ну или когда-нибудь пройдет. Тот-то прошел, может этот пройдет, но немножко грустно.
Да. Вот. Сейчас я это докажу. Доказывается очень красиво, очень просто, но неожиданно.
То есть, ты не придумаешь сам такое, если не знаешь ответ. В каком-то смысле ответ подсказывает, как нужно доказывать.
Но тоже, конечно, это круто.
Так, доказываем. Надо как-то... А, сейчас затру. Отделяем. Уже не нужно.
Так, доказательства.
Ну, вероятность того, что это n больше, чем a, это разумеется вероятность того, что лямбда это n больше, чем лямбда a, если лямбда это какая-то положительная величина любая.
Просто взял и домножил на положительное число.
Но тот ход, до которого трудно додуматься, это, конечно, мистика некая. Давайте возьмем экспоненту от каждой из частей неравенства.
Ну, экспонентом анатонная функция, поэтому это корректное действие. E в степени лямбда это n больше, чем E в степени лямбда. Это тоже правильно.
А тут применим неравенство банальное, Чебышовское по сути, неравенство Маркова. То есть Чебышова же применим, но вот к такой хитрой штуке.
Ну, не совсем Чебышова, прототип Чебышова, прообраз Маркова. Это же положительно значная случайная величина, это положительное число.
Значит, можно применить неравенство Маркова. У нас получится E в степени минус лямбда А на математическое ожидание E в степени лямбда это n.
Это же неравенство Маркова. Ну, мы берем мат ожидания того, что здесь, и делим на то, что справа.
Но поделить на E в степени лямбда это умножить на E в степени минус лямбда.
Так, ну здесь вот все замечательно и просто, потому что E в степени лямбда это n.
Это E в степени сумма кси один кси n. А кси один кси n независимы, и тут важно уже, что совокупности.
Потому что E в степени суммы это произведение.
E в степени минус лямбда А на произведение по E от единицы до n E в степени лямбда кси. Вот так.
Ой, мат ожидания потерялась. Вот так.
А мат ожидания произведения независимых случайных величин.
Ну, очевидно, что если кси это независимо, то и экспоненты от лямбда кси это тоже независимые величины.
Мат ожидания именно произведения независимых совокупностей величин, это произведение мат ожидания.
То есть мы можем вот так переписать E в степени минус лямбда А на произведение по E от единицы до n.
Ожидание E в степени лямбда кси.
Какое же математическое ожидание у E в степени лямбда кси?
Ну, кси это принимает всего два значения, плюс-минус один.
Каждая с вероятностью одна-вторая. То есть мы просто подставляем сюда единичку, делим пополам, и плюс подставляем сюда минус единичку, делим пополам.
Вообще сумма, которая получится, называется чосинус.
Ну, E в степени минус лямбда плюс E в степени лямбда, и все пополам.
Ну, нам не так важно. Давайте я лучше распишу, потому что я лично не помню наизусть ряд Тейлора для чосинуса.
А для каждой из экспонентов, которые получится, я помню.
И как он свернется, ну, вот так и будет для чосинуса.
Сейчас нам это понадобится. E в степени минус лямбда А.
Произведение по E от единицы до n.
Так, E в степени лямбда плюс E в степени минус лямбда пополам.
Ну, и вообще говоря, перемножается-то одно и то же.
Поэтому давайте я вот так припишу. E в степени минус лямбда А.
E в степени лямбда плюс E в степени минус лямбда пополам в n.
Так, ну, давайте считать в каком-то смысле в уме.
Я вспоминаю, ну, в уме не в уме.
Сумма по k от нуля до бесконечности лямбда вкатый на k факториал.
Это экспоненты E в степени лямбда по Тейлору.
А если брать E в степени минус лямбда, то будет так вот.
Ну, то есть при нечетных k они друг друга убивают,
а при четных складываются, удваиваются и потом делятся пополам.
То есть у нас получается вот так.
E в степени минус лямбда А.
Сумма по k от нуля до бесконечности лямбда в степени 2k.
Поделить на 2k факториал.
И все это в n.
Только четные слагаемые остаются вот здесь вот.
Так, оцениваем это замечательно следующим образом.
E в степени минус лямбда А, оно все время за нами ходит.
Так, пойду-ка я сюда, то не влезет.
Так, а здесь напишу сумма по k от нуля до бесконечности лямбда в 2к
на 2к на k факториал в n.
Но я абсолютно тривиально оценил снизу удвоенный k факториал,
2k факториал величиной 2к на k факториал.
Хуже некуда, казалось бы.
Но надо вот так вот это изображать.
Всегда такое орешек арахис получается.
Ну или хотите сарделька.
Я имею ввиду лямбда квадрат поделить на 2 и все это в катой степени.
Видно же, да?
Лямбда квадрат пополам в катой степени.
То есть это снова ряд Тейлова.
Только для E в степени лямбда квадрат пополам.
Тут что-то появилось.
А куда двойков знаменатели делать?
Какая двойка знаменателя? Вот эта.
А я же сказал, если мы складываем с нечетным k, то они кок друг друга.
А если кочетная, они складываются и удваиваются, после чего делятся пополам.
То есть эта двойка просто сократилась с той двойкой,
которая могла бы возникнуть в числителе, но не возникла.
Никакой двойки в знаменателе уже нет.
Ну, я, конечно, могу сказать, что это меньше либо равно, чем двойка в знаменателе,
но на самом деле она честно сократилась.
То есть тут никаких огрублений нет.
Действительно сократилась.
То есть у нас получается E в степени минус лямбда вот отсюда.
И давайте я прям вот тут, в одной и той же экспоненте, напишу лямбда квадрат пополам умножить на n.
Лямбда квадрат пополам умножить на n.
Это все в показателе экспонента.
Согласны?
Но это верно для любого лямбда положительного.
Это такой параметр оптимизации, если хотите.
Мы вольны выбрать лямбда так, чтобы нам было лучше всего.
Когда нам лучше всего?
Когда минимально выражение, стоящее в показателе экспонента.
Нам нужна верхняя оценка, и она тем лучше, чем меньше выражение, стоящее в показателе.
Такая-то парабола.
Вот такая.
Где она минимальна?
При каком лямбда?
Ну, там есть такая замечательная мандра.
Называется минус b поделить на 2a.
Но минус b здесь это a виноват.
А 2a это n. То есть надо брать a поделить на n.
В общем, точку, где производная зануляется.
Понятное дело.
Но если мы возьмем в качестве лямбда вот именно эту самую точку, где достигается минимум, то получится, товарищи.
Но можете посчитать в аккурат вот это.
Ну, все.
Ну, не знаю, видно же, да.
a квадрат поделить на n с минусом.
А тут a квадрат поделить на 2n с плюсом.
Поэтому все-таки будет с минусом, но на 2a.
Вот такая вот замечательная совершенно теорема, которая говорит, что на самом деле мера гораздо плотнее концентрируется около среднего,
чем то гарантирует неравенство Чебышова в некоторых специальных ситуациях.
Это же очень специальная ситуация.
Это случайное блуждание.
Мы складываем независимые такие вот простые индикаторы.
Плюс-минус единица.
Ну, не совсем индикаторы, понятно.
Ну, вот такие функтуации.
Да, туда-обратно.
Конечно, если случайная величина устроена гораздо сложнее, она может и лучше, чем Чебышов, не оцениваться.
Но вот здесь получилось очень круто.
Очень высокая плотная концентрация мира.
Но это в каком-то смысле так, чтобы, может, нагляднее было.
Может, знаете, что почти весь объем апельсина сконцентрирован в его корке.
Слышали такое утверждение?
Это вот оно же.
Что объем шара – это тонкий слой на его поверхности.
Это весь объем шара.
И вот далеко идущее обобщение – это все вот про это.
Так, ну ладно.
Это, конечно, прекрасно.
Но к чему бы я это?
Мне нужно как-то на самом деле обобщить эту историю со случайным блужданием так, чтобы она помогала работать со случайными графами.
Но со случайными графами это уже посложнее.
Я в последние годы вот так рассказываю, как сейчас буду рассказывать, во всей полноте.
Я не готов давать доказательства, потому что это займет много времени и вас кокнет.
Но, может, и не кокнет.
Я могу, конечно, дать.
Но вот я не знаю, нужно это делать или нет, потому что все-таки второй курс.
Но, в принципе, ничего такого технически прямо сложного там нет.
Тем не менее, я много довольно нетривиальных вещей рассказываю.
Значит, как для случайного графа в каком-то смысле обобщается эта история?
Ну, это просто придется поверить пока что, потому что доказательства здесь я дал, а там давать не буду.
Так, смотрите.
Это обобщение для случайного графа.
Обобщение плотной концентрации меры, скажем так.
Для случайного графа.
Ну, я еще подумаю, может, я и успею рассказать.
Посмотрим.
История такая.
Вот есть множество всех графов на n-вершинах.
Можно, конечно, его интерпретировать, как мы, собственно, и делаем в нашей науке.
Интерпретировать его как, собственно, пространство элементарных событий.
Все графы на n-вершинах это элементарные события.
Поэтому, если мы задаем на этом множестве какую-то функцию,
то при желании мы, конечно, можем говорить, что это случайная величина.
Любая функция на множестве элементарных событий, если она измерима, называется случайной величиной.
Но она измерима, потому что ω конечная, и мы рассматриваем все множества в ω как события.
Вопросов с измеримостью не возникает.
Любая функция может расцениваться как случайная величина,
а можно просто говорить функция на графике.
Число ревер, число вершин, но это константа.
Число треугольников, хроматическое число, кликовое число и так далее.
Любая функция может быть рассмотрена.
Теперь, смотрите, давайте назовем эту функцию липшицовой.
Ну, или случайную величину.
Назовем липшицовой.
Я, конечно, могу расстараться и написать липшицово нормально.
Я всегда так пишу, потому что я так пишу.
Конечно, я могу очень постараться написать вот так.
Но это вот как подпись.
Назовем ее липшицовой не в том смысле, в каком это обычно понимается в курсе аналогии,
в курсе анализов. У вас, наверное, было такое понятие, да, в слове липшица?
Ну, может, на дифурах. Не знаю, как здесь построено в этом смысле.
Не вникал в такие детали, где обычно это рассказывают.
Ну, это такой вот аналог гладкости, только чуть более слабый.
Да, а здесь это комбинаторное же определение. Тут гладкости никакой нет.
Значит, мы будем говорить, что F липшицово по ребрам
и отдельно по вершинам.
Два варианта липшицовости бывают. Бывает по ребрам, бывает по вершинам.
Вот если в первом случае...
Ну, давайте даже и в первом, и во втором.
Модуль F от G минус F от G штрих не превосходит единице.
Но что такое G и G штрих?
Вот здесь лучше сопетую поставить и писать что-нибудь, типа, коль скоро.
Коль скоро G и G штрих отличаются
тут вот в одном ребре.
Это когда мы говорим липшицово по ребрам.
В окрестности одной вершины.
Это когда мы говорим, что липшицово по вершинам.
А, ну это какая-то известный ход.
Пошло дело. Я говорю, в зуме лучше.
Если только туда кто-нибудь тоже не проникнет, у нас был тут случай ужасный совершенно просто.
Я думал, я провалюсь сквозь землю.
Что там было?
Да, вот видите как.
Ну, что значит в одном ребре?
То есть мы взяли граф G, у них одинаковое количество вершин, множество всех графов на N вершинах.
Теперь вот мы взяли какой-то граф G на N вершинах и одно ребро из него выкинули.
Получился G штрих.
Или наоборот, взяли и одно ребро добавили.
Ну понятно, это все симметрично.
Получился G штрих. Вот не больше единицы.
То есть если увеличение или уменьшение идет не больше чем на единицу,
то мы говорим, что это липшицово по ребрам случайная величина F.
А что значит в окрестности одной вершины?
Ну это значит, что мы взяли какую-то одну вершину.
Вот в графе G была такая окрестность, например.
Мы можем какие-то ребра удалить, а какие-то новые добавить.
Вот что бы такое мы не сделали, но только в окрестности одной вершины.
Как бы мы ее не попортили, часть ребер удалив, часть ребер добавив,
мы получим все равно отличие не больше чем на единицу.
Но я вот сейчас пояснил, что значит разняться в одной вершине.
У нас просто задержка идет в YouTube всегда.
Это мне неудобно, я понимаю, что студентам удобнее смотреть в YouTube,
а мне неудобно, потому что идет задержка,
и вопрос появляется, когда я на него уже ответил.
Вот.
Ну примеры вроде бы совершенно очевидные.
Липшицовость по ребрам – это, например, множество числа,
Да?
Да, конечно.
Нет, ну ладно, можно взять какое-нибудь хроматическое число Графа,
оно, заметьте, и по вершинам Липшиццева, и по ребрам.
Если только в окрестности одной вершины покоцать,
то хроматическое число в крайнем случае изменится только на цвет этой вершины.
Тем более, если покоцать только на вершины шелка Все Area,
этой вершины, на один. Тем более, если покоцать только в одном ребре. Ясно, что
хроматическое число больше, чем на единице, не вырастет или не уменьшится.
Вот, ну и можно массу других примеров приводить. А вот, скажем, число
треугольников не является липшитом, но потому что вы можете вот такую корону
иметь. Извините за плохие ассоциации, иметь корону. Вот иметь такую корону,
извините. Вот, убрали одно ребро и куча треугольников долой. Ну и с вершинами
то же самое. Там будет не корона, там будет орден такой. Удалили одну вершину,
пропали все треугольники. То есть не все, конечно, функции липшитцевые. Бывают
липшитцевые только по ребрам, но не по вершинам, ну и так далее. Вот, оказывается,
что если f такая, то она в некотором смысле хорошо концентрируется, а именно
имеет место сразу ну два утверждения, потому что для липшитцевых по ребрам одно, а по вершинам
другое. Ну давайте я назову это теория М1 и 2. Неважно, пусть
f липшитцево по ребрам, тогда вероятность того, что модуль f-ef больше либровняется a,
ну это, конечно, любого а больше нуля, вероятность уклонения не больше, чем не в степени, а нет,
давайте здесь, наверное, дважды, не в степени минуса квадрат на 2. Так, липшитцево по ребрам,
здесь будет c из n по 2. c из n по 2 это количество ребра полного графа. Ну вот оно здесь вылез.
Так, если удалось одну вершину, то удалить одну вершину, то окрестность других вершин изменится.
Нет, мы не вершину удаляем. Смотрите, вот Эрнес спрашивает, мы не вершину удаляем, вершина-то
остается. В определении липшитцевости по вершинам мы не трогаем вершину. Граф по-прежнему на n вершинах,
мы трогаем ребра, находящиеся в ее окрестности. Мы какие-то из этих ребер можем удалить,
а новые ребра, которых не было раньше, можем добавить в любом количестве, но вершина при этом
сохраняется. Вершин все время n. У нас зафиксирована омега, но я думаю, что я ответил. Вот, не буду ждать,
когда задержка закончится. Такое вот утверждение о концентрации меры значений липшитцевых функций
на случайных графах около своих средних значений. Теорема 2. Точно такая же, только для липшитцевости по вершинам.
Липшитцева по вершинам. Тогда для любого а больше 0 вероятность того, что модуль f-ef
больше либо равняется a, не превосходит 2, на f в степени минус a квадрат на дважды n-1.
Ну, почему именно n-1? Это я вряд ли сейчас поясню. Но она по вершинам. Вершин всего n.
n-1 это примерно n. По ребрам тут c из n по 2. Ну, я же не доказываю пока эти утверждения. В них пока
предлагается просто поверить, что вот есть такие удивительные, интересные, далеко идущие обобщения
концентрации меры в духе теоремы об уклонении случайного блуждания от кабака, но на графах для
липшитцевых функций. Да, хочу еще заметить, что если, понятное дело, если модуль снять, то вот эта
двойка пропадет. Я могу каждую из этих теорем еще переформулировать отдельно для случая f-ef
больше a и случая f-ef меньше, чем минус a. Отклониться вправо далеко и отклониться влево далеко
симметрично маловероятно. Двойка пропадает в оценке вероятности, а для модуля это как раз
происходит сложение до двойки. И здесь то же самое. Давайте осознаем, какое из двух утверждений
мощнее с точки зрения плотности концентрации? Ну, где правая часть меньше? Первый? А по-моему,
второй. Во-второй, потому что знаменатель у нее меньше, чем у этой, стало быть дробь больше,
а она со знаком минус в показателе экспонента. Поэтому здесь получается большое отрицательное
число, большое по модулю отрицательное число. Ну, это и соответствует нашей интуиции, потому что,
конечно, если случайная величина липшитцевого по вершинам, то она тем более липшитцевого по
ребрам. А вот, наоборот, неверно. Бывают такие, которые липшитцевого по ребрам и при этом не
липшитцевого по вершинам. Поэтому если нам посчастливилось найти такую случайную величину,
которая еще и по вершинам липшитцевого, она даст офигенную концентрацию. Если не посчастливилось,
ну тоже будет ничего. И пользоваться можно и тем, и другим. И мы будем в дальнейшем пользоваться
и тем, и другим. Но пока я не хочу это доказывать. Так, если в целом это понятно, тогда давайте,
наверное, вернемся к теореме. Кстати, я забыл сказать важную вещь. Теорема, которая была вот
здесь написана и на месте которой появились эти вот концентрационные неравенства, она предлежит
Балабашу в том случае, который мы сейчас собираемся доказывать, то есть четырьмя значениями. Автор
Болло Баш, один из классиков теории случайных графов, неоднократно бывавший в нашей стране,
причем в первый раз в году, в 69-м, а в последующие разы по нашим приглашениям. То есть он еще в
69-м году приезжал в Россию, в Советскую, и тут учился. Он в Венгаро по происхождению учился,
стажировался скорее в институте, по-моему, в стекловке. Причем у математика Гильфанда, который,
может вы слышали там линейный алгебра учебник есть, ну такой великий известный математик,
никакими графами не занимавшийся. И он занимался, и по сью пору занимается, Балабаш, я имею в виду,
и функциональным анализом, и случайными графами. Но в случайных графах он очень знаменит. И в
частности он доказал ту теорему, которую мы по модулю вот этих результатов, которые я сформулировал,
но не доказываю. Собираемся полностью доказать. Так, ну ладно, липшица вести я сотру. У нас
прозвенел звонок, но я как-то не очень понимаю, нужно ли нам устраивать перерыв, когда здесь народ
не сидит. Какой смысл-то? Ну из ютубов все равно можно всегда ненадолго отойти, я не знаю.
Ой, уронил. Так. Пишется, кстати, Балабаш вот так.
По-венгерски он считается как Ше, но живет он в Англии в основном, в Кембридже. Так,
чего начать? Начнем с леммы, потому что она проясняет структуру дальнейшего рассуждения.
Так, что утверждает лемма? Лемма утверждает следующее. Ну, конечно, пусть P равняется n в
степени минус альфа, альфа больше, чем две третих. На самом деле, не обязательно меньше единицы,
просто больше, чем две третих и все. Тогда существует n нулевое такое, что для любого n,
больше либо равного n нулевого, вероятность которой выполнена следующее событие больше,
чем один минус один поделить н-логариф n. Ладно, сейчас допишем событие. Для любого s,
являющегося под множеством вершин нашего случайного графа, и имеющего мощность не большую,
чем корень z-н-логариф n, то есть относительно маленькую по сравнению с количеством всех вершин,
для любого достаточно маленького в некотором смысле множества вершин. Что выполнено? Выполнено
и от графа, индуцированного этим множеством вершин, так, меньше либо равняется тройке. Вот так,
меньше либо равняется тройке. Вот эта вероятность больше либо равна, как я уже сказал, один минус один
делить на логариф m. Ну, я мог бы сказать, асимптотически, почти наверно, выполняется вот это
событие, стоящее в скобках. Но мне важно не просто, что асимптотика единица, а прям вот явно
оценить хоть как-нибудь, пусть начиная с некоторого n. То есть асимптотика-то единичная,
начиная с некоторого n и ладно. Но вот мне хочется явную оценку получить. Она грубая,
тут ничего страшного. То есть утверждение такое, каждое относительно маленькое множество можно
покрасить в три цвета. Изначально это ничего не значит про раскраску всех n вершин. Мало ли,
что каждый кусочек можно покрасить в три цвета правильным образом. А может быть на весь граф
потребуется три цвета на один кусочек, три цвета на другой кусочек, и там суммарно получится три
корни из n поделить на алгоритм n. То есть офигенно много. Мы не знаем, но каждый маленький кусочек
красятся в какие-то три цвета. С очень высокой вероятностью. Доказательства оно не потребует всей
вот этой техники. Это такая лемма, которая на самом деле объясняет, зачем нам нужно, чтобы альфа
было больше двух третей. Для концентрации мира нужно другое. Она не совсем тривиальная, но она
техническая. То есть мне ничего такого сильно умного нет. Я, как обычно, буду доказывать
противоположное неравенство. То есть напишу отрицание вот этого события, оценю сверху единицы
поделить на алгоритм. Так, я пишу вероятность того, что существует s мощности. Я уже не буду писать
откуда, но понятно, что отсюда мощности больше, чем корень. Чем больше? Меньше либо равно. Здесь-то
зачем отрицать? Глупость написал. Да, такое, что и от g на s больше либо равняется четверке. Так,
это надо отделить вот так вот. Разучился отрицание событий писать. Конечно, для любого s какой-то
мощности, отрицание существует и с такой же мощностью. Так, я надеюсь, никого не смущает.
Теперь я хочу это оценить сверху, но давайте я пока напишу точное равенство. Я напишу вероятность того,
ну, во-первых, совсем напишу тривиальную вещь, то существует s, у которого мощность лежит вот в
таких пределах и такое, что g на s больше либо равняется четверке. Но я думаю, это совсем понятно,
почему в таких пределах вряд ли хроматическое число графа, имеющее не больше трех вершин,
может оказаться четверкой выше. Поэтому, конечно, s точно не менее четырех вершин имеет,
тут уж явно деваться некуда. Ну, на самом деле нам бы для выкладки хватило, что мощность s
больше либо равняется даже единицы, наверное, ну да бог с ним. Но двойки, во всяком случае,
единицы вряд ли, а вот двойки, двойки хватит. Ну, неважно. Вот, это неинтересно, это понятно.
Чуть-чуть более нетривиальное утверждение, которое простое, но почему-то ряд людей на нем
спотыкаются. Я могу даже написать, ну ладно, я буду, ну хорошо, давайте s. Существует s,
мощность которого лежит в уже известных пределах, я вот так напишу, многоточие это вот. Так, такое,
что и от g на s больше либо равняется 4, но для любого x принадлежащего s и от g ограниченного
на s без этого x все-таки меньше либо равно трех. Вот так. Длинное такое условие немножко
не полезно, но видно, да? На экране видно тоже нормально. Вот. Ну, что утверждается?
Утверждается просто, что если мы можем найти хоть какое-то s, которое не красятся в три цвета,
то можно из множества таких s выбрать минимальное. То есть здесь стоит объединение каких-то событий,
здесь стоит объединение формально других событий, но эти объединения очевидно совпадают. Потому что
если вы нашли такое s, ну значит какое-то s вы нашли. Если вы нашли какое-то s, последовательно
просто убираете из него лишние вершины и получаете вот такое минимальное, с точки зрения свойства не
красятся в три цвета. Минимальное по включению. То есть вот оно в три цвета еще не красятся,
но любое его собственное подмужство уже красятся. Понятно? Сейчас вы поймете, для чего мне нужно было так сделать.
Ой, картину, что ли, нарисовать. Вот картина. Так, ладно, это вершин нашего случайного графа.
Вот мы взяли какое-то s, мы знаем, что у него хроматическое число не меньше четырех, у него в смысле
вот этого индуцированного под графа. Но мы знаем, что если взять любую вершинку х, принадлежащую
этому множеству, то у оставшейся части вот этой хроматическое число не больше тройки. Знаем,
причем для любой х. Что можно сказать про степень вершины х, тем самым? Про степень не
внутри всего графа, а внутри этого множества s. Сколько ребер внутри множества s может выходить
из х? Может выходить два ребра? Нет, потому что если из х выходит только два ребра,
то смотрите, мы вот эту часть-то в три цвета покрасили, а тут только два ребра. Ну так возьмите
и покрасьте эту вершину в третий цвет, и опять получится не больше трех, вопреки тому, что мы считаем,
что не меньше четырех. То есть следствием из вот этого кошмарного подлиннее, казалось бы,
нетривиальности утверждения, следствие из вот этого всего, я не буду переписывать,
следствие состоит в том, что существует s, мощность которого принадлежит, понятно,
от четверки до корени Зэмла Гарриф Мэн, тут все как было. Такое, что, а я вот так напишу,
количество ребер в графе g на s больше либо равняется трижды мощность s пополам.
Ну гораздо более простое условие, чем то, которое было написано с хроматическими числами,
то есть следствие вот этой минимальности по включению, что все красятся минимум в четыре цвета,
но при удалении одной вершины остается раскраска в три цвета, является тот факт, что у каждой
вершины внутри s есть как минимум три соседки, а значит суммарное количество ребер в этом графе g,
ограниченном на s, не меньше, чем трижды мощности s пополам. Сумма степеней вершин,
а то удвоенное количество ребер. Ну или можно еще знаете, как написать, существует s маленькая,
принадлежащая от 4 до корень из n на логариф mn, существует s большое мощности, s маленькая такое,
что количество ребер уже на s большом не меньше, чем 3s маленькая пополам. Вот так тоже можно написать
чуть более подробно. А тогда вероятность, которую мы хотим оценить, как вы, наверное, еще помните,
сверху, вот эта вероятность, мы хотим ее оценить сверху, как один поделитель на логариф mn. Она,
конечно, оценивается сверху, вот я так перетащу сюда, оценивается сверху, вероятностью вот этого
события. Если из одного события следует другое, то его вероятность не больше, чем вероятность
следствия. Так, ну, как обычно, если стоят квантеры существования, это значит, речь идет про
объединение, и мы просто оцениваем вероятность, как сумму. Это не больше, чем сумма, то есть
технически это простая лемма со стандартными идеями, которые у нас не раз уже бывали. Сумма
по s от четверки до корени z на логариф mn, сумма по s большим мощности, s маленькая. Так, а здесь
стоит вероятность того, что e, ограниченное на g, e, g, ограниченного на s, больше либо равняется
3s маленькая попало. Вот так. Так, до сюда понятно? Харе, а вот эта вероятность как оценить? У
всего графа n вершин, но у этого s. Мы уже ограничились на кусочек размера s маленькая. С какой
вероятностью в этом кусочке не менее, чем столько рёдер? Ну, вы мне сейчас скажете, давайте писать
сумму страшную, но я сверху хочу оценить. Число рёбер не меньше, чем 3s пополам. Но знаете,
как можно сказать, существуют 3s пополам рёбер, правильно? Вот это вот, это в g на s существуют
3s пополам рёбер. Это в точности то самое событие. Если количество рёбер не меньше, чем 3s пополам,
то в графе найдутся 3s пополам рёбер. Ну, поборники аккуратности могут мне сказать, что здесь надо
нарисовать целую часть, потому что мало ли вдруг s на 2 не делится. Но имейте в виду, что кто-нибудь
может, но суть это не поменяет, а я не хочу громоздкие выкладки делать. Там очень легко все
преобразует, если нарисовать целую часть, но просто писать будет гораздо больше, а смысла никакого нет.
Так, существует 3s пополам рёбер, но как оценить вероятность того, что существует 3s пополам рёбер?
Это опять объединение по всем способам выбрать 3s пополам рёбер, какие могут возникнуть на множестве
и засвершить. Ну, короче, я сейчас напишу, а вы мне скажете, понятно или нет. Маленькая четвёрка,
там даже понятно, корень из n, сумма по s большая. Так, а я напишу вот так, c из c из s по 2 по 3s
пополам на p в степени 3s пополам.
Существуют 3s пополам рёбер. Его рёбер у полного графа c из s по 2. Вот мы из них выбираем какие-то 3s пополам,
в объединении будет столько множеств. И вероятность каждого отдельного события, это просто вероятность
того, что именно эти конкретные 3s пополам рёбер реализовались, но это по f в степени 3s пополам.
Вот. Ну, как видите, от внутреннего суммирования, от его переменной, вот эта величина никак не зависит,
это мощность с большого. Слушайте, а можно я вот так сделаю?
Ну, я убрал это суммирование, потому что в нём складываются одинаковые величины, а количество этих величин равно
просто количеству способов зафиксировать сардельку из-за маленькой элементов в большой сардельке мощности n.
Это c из n по n. Вот дальше мы грубости пока таких не будем допускать, мы сейчас оценим каждую c.
Оценим мы её, используя стандартное неравенство c из a по b не больше чем ea поделить на b в степени b.
Узнаётся такое? Может, не узнаётся. Ладно, c из a по b, то узнаётся не больше чем a в степени b поделить на b факториал.
Это точно узнаётся. Но b факториал, конечно, не меньше, и это я тоже говорил, по индукции доказывается,
b поделить на e в степени b. Подставляем это в знаменатель и получаем то, что я написал.
e это число e.
Так, мне кажется, я могу вот эту часть стереть, чтобы не переходить на другую доску.
Оставить только вот это, а верхнюю часть стереть.
Давайте это меньше либо равно, и поехали сюда. Сумма с маленькому от четвёрки до чего-то будет e n поделить на s в степени s.
Это я применил вот это неравенство c из n по s, а c из s по 2 по 3s пополам, оно применяется вот так.
e на c из s по 2 поделить на 3s пополам в степени 3s пополам. Правильно?
Так, тут появился, скажите, какой-то вопрос.
А, нет, всё то же самое. Тут показалось, что больше строчек. Ну и слава богу.
Я стараюсь медленно, по в степени 3s пополам.
Но мы же крутые, значит, мы можем не совсем медленно.
Так, ну тут много всякой бяки, я сейчас её в уме посчитаю, ладно.
c из s по 2 меньше, чем s квадрат пополам.
А тут тоже пополам, значит, пополам сократилось.
Тут s квадрат пополам и тут пополам.
И s сократилось.
В общем, вот это всё, это s. Ну, меньше, чем s.
Меньше, чем s, e поделить на 3 меньше 1, ну давайте считать, что всё меньше, чем s.
Я пишу это меньше, чем summa по s в понятных пределах.
e n на s в s-тый, а здесь s в степени 3s пополам и p в степени 3s пополам.
Ну и давайте я теперь то, что стоит под знаком суммирования,
занесу в одну такую здоровую скобку, а к северо-востоку
от этой скобки будет стоять буквка s.
Ну, то есть всё под степень s занесу.
Значит, это будет равно, по-прежнему, summa по нашим s вот этим.
Вот будет вот так, e n поделить на s, умножить на s в степени 3 вторых
и это в степени s. Загнал под одну общую степень s.
Ну, тут у нас вот так вот сократилось s в степени 3 вторых на s.
И в итоге a. И давайте я вот это s в степени 1 вторая,
которая осталась в скобках, вот именно этот корень из s,
оценю как корень из самого большого значения,
какое может принимать s в рамках суммирования.
То есть это меньше либо равно summa по s.
А здесь e n, вот это оно вышло, e умножить на n.
А корень из s заменяем на корень из вот этого выражения.
То есть будет n в степени 1 четверть на корень из логарифма n.
Так, и на p в степени 3 вторых, которые давайте я заменю.
p, у нас n в степени минус альфа, это кто-то еще помнит,
ну значит минус 3 вторых альфа и все это в степени s.
Вот это вот, это n в степени 5 четвертых,
а здесь смотрите, 5 четвертых – минус 3 вторых альфа.
Вот 5 четвертых – минус 3 вторых альфа.
минус 3 вторых альфа. Я 2 третьих написал, я чушь написал. Не две третих, виноват,
хуже. Не две третих, 5 шестых. 5 шестых мы будем доказывать. Это у меня какой-то
сбой случился, виноват. Еще хуже будем доказывать. Не две третих, а 5 шестых,
товарищи, виноват. Во всех формулировках, которые мы будем доказывать, там не две
третих, а 5 шестых. К сожалению, ну ничего. Конечно, да, если сюда подставить 5 шестых,
это будет меньше нулю. Ну равно нулю, а если альфа больше, чем 5 шестых, то это меньше нуля.
То есть у нас вот в этих скобках появилось выражение n в какой-то степени, фиксированной
альфа мы задали раз и навсегда. n в какой-то фиксированной степени, которая строго меньше нуля.
Ну давайте я это нормально напишу, а то трудно воспринимать все-таки на слух.
У нас получилось, что это равно
сумма по s. Ну давайте здесь напишу от четверки до корени z-логарифа n. Тут e на n, давайте в степени
минус бета. Где бета? Это вот это. Ну вот это минус бета. Виноват. Вот эта вот разность, это
минус бета. А бета сама положительная. Я просто хочу подчеркнуть, что вот такая штука стремится
к нулю, как n в какой-то фиксированной степени, фиксированной отрицательной степени. Дальше у меня
еще живет корень из логарифма n, дурацкий, и это все в степени s. Ну что я могу сказать? Понятно же,
что n в степени минус бета, как бы близко изначально альфа ни было к 5 шестым, n в степени минус бета,
пусть даже бета очень маленькая, очень близкая к нулю, n в степени минус бета, начиная с какого-то
момента, сколько угодно хорошо укокивает вот этот корень из логарифма. То есть, например, можно
сказать, что это меньше, чем сумма в тех же пределах. Она укокивает не только корень из логарифма,
тем более она укокивает вот эту несчастную ешку, которая все-таки выжила. Вот. Можно вот так написать n
в степени минус бета пополам степени s. Ну и здесь, конечно, n, начиная с какого-то n первого. Вот
верно, начиная с какого-то n первого. Я просто хочу сказать, что n в степени бета пополам точно больше,
чем корень из логарифма n на е, начиная с какого-то момента. Вроде ничего сложного нет. А эта сумма
геометрической прогрессии в очередной раз стартующая с четверки. То есть, это, ну давайте, меньше
либо равняется. Подставляем s равное четверке. Получаем n в степени минус 2 бета. Это подставили
просто. Первый член. Ну а дальше, если хотите, можно написать 1 поделить на 1 минус n в степени
минус бета пополам. Ну то есть, как обычно, мне больше нравится оценить сумму конечной геометрической
прогрессии, суммой бесконечной. Но это же правильно. Это примерно единица при больших n. Вот это.
Что это стремится к нулю? К единице, к единице. Ну а это-то меньше, чем 1 поделить на логарифм n. Это же n в степени
минус 2 бета. Ну тоже может быть не сразу, а начиная там с какого-то n нулевого. Но мы же это и заявляли
вот здесь. Начиная с n нулевого. Это конечно меньше, чем 1 поделить на логарифм n, начиная с какого-то n нулевого.
Конечно, n нулевое зависит от альфы. Ну и здесь также надо читать. Пусть p равняется n в степени
минус альфа. Альфа фиксирована больше 5 шестых. Тогда найдется n нулевое. Естественно,
зависящее от альфа такое что. Но альфа у нас фиксирована, поэтому нам не страшно. Вот такую
лемму доказали. Как у меня осталось времени? 15 минут, да? Ну за 15 минут можно что-то успеть.
Все, не успеем. Так, лемму я точно оставлю, а вот эти я не хочу стирать. Хотя, может,
я их не успею применить, но это уж как повезет, тут я не знаю.
Я начну доказывать теорию. У нас есть лемма, и нам где-то должно понадобиться это суперружье
концентрации мира. Доказательства теории. Ну давайте фиксируем альфа больше 5 шестых,
фиксируем какое-то n. Ну оно точно больше либо равное n нулевого, иначе мы не сможем применить
лему. Ну может быть и там еще больше, неважно, фиксируем n нулевое штрих. Подразумевает,
что просто n достаточно большое, в частности больше чем n нулевое, но может быть потребуется
его взять еще большим для каких-то целей. Это мы потом проясним. Понятно? Теория у нас
асимпатическая, поэтому мы можем считать, что работаем с достаточно большим n. Мы лишь говорим,
что нечто выполняется асимпатически почти наверно, но это не значит, что при маленьких n оно
должно иметь высокую вероятность. То есть если мы докажем все, что нам нужно при больших n,
то при маленьких n нам плевать, как оценивается вероятность, потому что все равно стремление
к единице будет. Ну чуть-чуть непрактичный, конечно, в этом смысл, но я не хочу ковыряться в
конкретных оценках, для чего бы нам это было. Главная идея понять, а поковыряться это уже каждый
сможет при необходимости. Вот, считаем, что n достаточно велико. Так, теперь давайте определим,
найдем u. Ну оно, конечно, окажется, зависящим от n и от альфа, но мы n и альфа зафиксировали,
в общем, неважно, что оно от них зависит. Вот, определим u следующим образом. Это минимальная
число натуральная. Такое, что вероятность, которой хроматическое число случайного графа в нашей
ситуации. Так, сейчас не ошибиться, наверное, не превосходит. Сейчас разберемся. Вероятностью
больше, чем один поделитель на логарифумы. Но абсолютно неявное, конечно, определение,
но поскольку n и альфа зафиксированы, то в каком-то смысле полным перебором уже ищется. Ну просто
тупо посчитать вероятность вот этого события, складывая все вероятности графов, которые этому
неравенству удовлетворяют. Это пойди, сделай чисто алгоритмически, но формально же вещь, не вещь,
а величина корректно определена, правда? Минимальное натуральное число такое, что вероятность вот
этого события все еще больше чего-то. Это корректно или нет? Ну смотрите, если бы здесь стояло не у, а n. Вот
представьте себе, что здесь не у, а n стоит. Число вершин. Тогда вероятность этого события это просто
один. Вероятность того, что хроматическое число не больше n. У всех графов хроматическое число не
больше, чем n. Но вероятность этого события один. Мы начинаем потихоньку уменьшать это число,
и вероятность начинает падать, когда n превращается, ну я не знаю, там в ноль, например. Вероятность того,
что хроматическое число не больше нуля, это ноль. Потому что не бывает графов с хроматическим числом
ноль, кроме пустых. Но у нас n-вершина, n-натуральная, в нормальном смысле слова. То есть, ну, не придерешься.
То есть, эта вероятность монотонно убывает от единицы к нулю. Но, значит, есть такой граничный момент,
до которого вероятность, до которого включительна, вероятность все еще больше, чем один на логариф МН,
но как только мы спрыгиваем ниже, она становится меньше либо равна. Согласны? Да, вроде все корректно.
Ну, смотрите, значит, тогда действительно вероятность того, что... Я утверждаю, что вот это то
самое у, которое нам нужно в теореме. То есть, такое, что у, у плюс один, у плюс два, у плюс три,
это те самые четыре значения, в которые хи от g попадает с вероятностью стремящейся к единице.
Понятно? В теореме заявлено, что если альфа больше, чем 5 шестых, то асимптатически почти,
наверное, хи принимает значение от какого-то у до у плюс четырех. Я утверждаю, что вот это хитро
определенное у есть то самое. Сейчас. Ну, в теореме, которое в самом начале было, там говорилось о
концентрации в двух значениях, но потом я сказал, что мы будем доказывать теорему Балабаша о
концентрации в четырех. Вот это то самое у, около которого в четырех точно концентрируется. Может
и в двух, но мы докажем, что в четырех. Понятно? Нет, почему это так? И понятно абсолютно. Я утверждаю,
что мы нашли это у, а почему сейчас буду доказывать? И сейчас, и в следующий раз. Но сейчас я кое-что
скажу. Ясно, что и от g не превосходит у минус один с вероятностью меньше либо равной один на логариф
мэн, потому что у было минимальным, я это прям явно проговаривал. Последнее такое значение, что
вероятность все еще больше. Взяли на единичку меньше и вероятность уже не превосходит. Дальше. Ну,
значит, вероятность того, что хиадже больше либо равняется у, то есть я пишу отрицание вот этого
события. Хиадже целое число, у тоже целое число. Она не меньше, чем один минус один на логариф мэн.
Я стараюсь просто для красоты унифицировать оценки. Смотрите, и тут один минус один на
логариф. Мы тут один минус один на логариф. Это не обязательно, но это создает большую запоминаемость
рассуждения. У меня уже есть два события, у которых у обоих вероятность очень близка к единице,
причем в одних и тех же терминах. В терминах величины один поделитель на логариф мэн. Но это
пока тоже ничего не понятно. Понятно только то, что хиадже не меньше, чем у. Но нам-то хотелось бы
доказать, что оно еще и не больше, чем у плюс четыре, и тоже как бы с вероятностью стремящейся к единице.
Вот как это доказать? Вот для этого нужна концентрация и время. А времени нет. Поэтому
я сейчас что-нибудь напишу, а дальше мы продолжим в следующий раз.
Ну, что ж я напишу. Ну давайте я дам определение, веду такую случайную величину y-адже.
В следующий раз, видимо, придется напоминать ее определение, но ничего страшного. Это будет
минимальное такое, какую бы букву K, то существует S под множество множества вершин случайного
графа, имеющая мощность K, и такое, что хроматическое число графа G, ограниченного на 1, 2, N, без вот этого S,
не превосходит U. Так, надо нарисовать картину. Вот дан какой-то конкретный граф на N вершинах,
да? Что такое y от этого графа? Пункция просто на этом графе какое значение принимает, что мы ищем? Мы
хотим найти самое маленькое по мощности множество вершин, удаление которого из графа,
удаление которого из графа, удаление, видите, да? Оставляет, вот граф, вот этот G на удаленном,
вот я его закрасил, отставляет под граф, который красится в не более чем у цветов.
Но оно жутковатое в том смысле, что если вы задумаете как-нибудь, например, с помощью,
не дай бог, линейности, посчитать мат ожиданий у, то вы обломитесь на первом же вздохе, так сказать,
потому что какая тут линейность? Вообще ничего не понятно, это же не количество чего-то, это минимум
какой-то сложный, согласна, да? Но смысл этой величины очень понятный. Мы берем и у каждого
графа ищем самый маленький кусочек, удаление которого оставляет красящийся вуд цветов под
граф. Я ж так написал, да? Минимальная мощность множество, удаление которого, и получили
как раскраску вуд цветов, но не больше, чем у. Уму это вот то самое. Теперь, смотрите, я не буду
ничего больше считать, даже не буду рассуждать про Липшицева, хотя Y Липшицева, это надо подумать,
вот, но это ладно. Я другое хочу сказать, я хочу сказать идею дальнейших рассуждений, которые мы
провернем через чуть больше недели. У нас же что случилось? У нас случилось, что четвертое неожиданно
перестало быть праздником. То есть, с одной стороны, мы имеем нерабочие дни, в которые надо
беречься от коронавируса, но с другой стороны, мы имеем эти дни учебными, но только в дистанте.
Соответственно, прежний приказ юридически утратил силу, и четвертое не является праздником,
а является таким же нерабочим, но учебным днем. И теоретически, я мог бы четвертого читать эту
лекцию, как сегодня, но я уже там запланировал другое мероприятие давно, поэтому я читать
четвертого не буду. А читать я буду в понедельник восьмого, если ничего не сломается по дороге.
Но это уже забронировано. То есть, я считал, что у меня четвертое пропадает, я считал, что у меня
восемнадцатое пропадает. Там праздник был тоже некий, 75-летие фистеха. А сейчас непонятно,
может, ничего не пропадает, но я восьмого все равно прочитаю, а четвертого не буду. Соответственно,
следующая встреча будет в понедельник восьмого числа. Большая вероятность такая же, но я не знаю
пока. Может быть, все-таки выпустят. Так вот, смотрите, какая замечательная идея. Предположим,
нам удалось доказать, предположим, нам удалось доказать, вот восьмому мы это сделаем, что у,
вот этот, от g, с высокой вероятностью не больше, чем корень из n на логариф mn. Ну, то есть,
вот, например, нам удалось доказать вот такое неравенство. Это, конечно, совершенно непонятно,
пока откуда следует, но вдруг нам удалось доказать такое неравенство. Опять, с такой же правой частью,
как везде, для красоты слога. Что бы это означало? Это бы означало, что с высокой вероятностью из
графа можно удалить всего лишь столько вершин, чтобы оставшаяся часть красилась в у цветов,
но мы же знаем, что любые столько вершин, любые столько вершин, красятся в три цвета. Опять же,
с высокой вероятностью. Ну, значит, пересекая вот это событие, вот это, какое там, вот это
событие и вот это событие, ну, мы увидим, что это пересечение, конечно, тоже имеет высокую вероятность,
мы получим графы, которые одновременно не красятся меньше, чем в у цветов и такие,
что значимая их часть красятся в у цветов, а оставшаяся в три и будет у плюс три.
Смог объяснить, нет идеи. Мы берем граф, который одновременно обладает вот этим
свойством, вот этим свойством и вот этим свойством. Ну, тогда у него точно хиаджи не меньше, чем у. Это
я потом повторю в следующий раз все подробно. У него точно хиаджи не меньше, чем у, потому что он
обладает этим свойством. С другой стороны, у него каждое множество из стольких вершин красятся в
три цветов какие-то, и есть множество не более, чем такой мощности, удаление которого оставляет
раскраску в у цветов. То есть мы удаляем это множество, красим в у цветов, это множество
берем, оно же три цвета красятся, все, значит у плюс три получается. Вот такая идея. Но как вот это
доказать? Это, конечно, вызов. Вот чтобы это доказать, нужно воспользоваться теориям 1 и 2,
этого проделаем в следующий раз. Но вроде вопросов там больше не было, может я правда всех кокнул,
да и множество тех, кого надо было кокнуть, я боюсь, было не очень большим. А, 14, это хорошо.
Ну ладно, друзья, тогда до встречи. Видимо, надеюсь, в понедельник, но не этот, а восьмой.
