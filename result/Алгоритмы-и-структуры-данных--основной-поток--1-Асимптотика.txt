Шестой сегодня, да? Кажется. Вот. Меня зовут Илья Данилович. Мы начинаем курс лекции
основного потока. Если вы внезапно не основной поток, то вы не там, короче. Вот. Давайте немножко
сначала про структуру курса, про оценивание и все такое, потом перейдем к содержательной части.
Значит, у нас будет три семестра. Все оцениваются независимо, все более-менее как бы из независимых
каких-то кусков, независимый набор тем. Значит, в этом семестре у нас будут по темам в основном
структуры данных. То есть у нас там какой-то префикс просто введения, потом из содержательного кучи
хэштаблицы, дерево поиска и дерево отрезков. Ну, такие классические стандартные структуры данных,
которые нам понадобятся на протяжении остальных двух семестров. Вот. Я решил как бы вынести такую
подготовительную базу в первый семестр, чтобы потом это использовать. У нас в каждом семестре
будет и зачет, и экзамен. Оценка за зачет ставится по работе в семестре. У нас будут теоретические
домашки и контесты, где надо будет писать решение задач. Вот. Соответственно это проверяют ваши
семинаристы и ассистенты помогают с проверком домашек. Они вам расскажут про то, как именно вы
их сдаете. То есть там я буду выкладывать ссылку на контест, они вам расскажут как писать код,
будут рассказывать про код стайл, будут проверять ваш код, будут проверять ваши домашки и ставить
оценки в табличку, которая считает как-то формулу по тому, насколько успешно вы все
зарешали. Значит, у каждой задачи будет просто какая-то стоимость и будут какие-то пороги на
каждую оценку. Чем больше баллов наберете, тем больше будет итоговая оценка. Вот. Это зачет.
Давайте я напишу, что зачет от работы в семестре. И здесь, значит, это теоретические домашки,
теоретические задачи, которые вы будете сдавать либо уст на семинаристу, либо, ну там, на бумажке
напишите решение. То есть теоретически это в смысле, что вам не нужно кодить, вам нужно описать
алгоритм, доказать, что он работает, доказать, что он работает за правильную симптотику. Ну, короче,
все кроме кода сделать. Вот. И, соответственно, наоборот, практические задачи, где вам, наоборот,
нужно только код написать и сделать так, чтобы оно проходило тесты. Все у каждой задачи свой вес
и сумма считается как итоговая оценка. Так. И, соответственно, будет экзамен. Ну, там просто
эта независимая оценка, она не зависит от работы в семестре. И просто вот пришли на экзамен,
как ответили, такая оценка ставится. Неважно, что вы получили в течение семестра, не влияет на то,
что вы работали на экзамене. Кажется, по оцене более-менее все. Есть какие-то вопросы концептуальные?
Ну, две отдельные оценки. У вас есть ДИВ-зачет, это одна оценка за, соответственно,
за четную неделю ставится, и отдельная оценка за экзамен в экзаменационную сессию, там,
декабрь и январь. Вот, просто две оценки будут разные. Хорошо.
Окей, давайте тогда переходить к содержательной части, поговорим про асимптотики быстренько.
Что мы хотим? Мы хотим вообще сначала договориться о том, что мы будем считать
сложностью работы алгоритма. Скажем, для решения одной какой-то конкретной задачи может быть
предложено несколько алгоритмов ее решающих, несколько программ, которые отвечают на тот запрос,
который в задаче задается. Вот, мы хотим их научиться сравнить между собой, говорить какие более
эффективные, какие менее эффективные, и сказать, между какими мы, по крайней мере, с теоретической
точки зрения, различия проводить не будем на те, которые для нас примерно одинаково хорошо работают.
Вот, и для этого мы вводим следующее определение. Значит, ну давайте я, во-первых, договорюсь,
что я сегодня в качестве n большого использую натуральные числа, начиная с 1. Значит,
пусть f и g это две функции из n в n, то есть принимают натуральные аргументы,
выучают натуральное число. Тогда пишем, что f равно o от g, если, так, давайте сначала словами,
существует положительная константа c, такая, что существует n большое, такое, что для любого n
маленького больше н большого выполняется следующее соотношение. f от n не превосходит c умножить на g от n.
Значит, какой смысл? Смотрите, существует какая-то константа c больше 0, а просто какое число? 10,
500, что-то такое. Какое число? Такое, что для всех n, начиная с какого-то, больших и равных
какого-то n большого, первая функция не больше, чем вторая умножена константу, где вот эта вот
константа как раз в самом начале у нас определено c. f равно o от g, да, o большое. Большая буква o.
Мораль. Для всех достаточно больших n, то есть нам вообще говоря не очень интересно, что происходит
на каком-то начальном отрезке вот этих маленьких натуральных аргументов. Если n маленькое меньше,
чем n большое, то нам на самом деле не очень интересно, как функция между собой взаимодействует,
кто больше, кто меньше, потому что на маленьких аргументах всегда, если что, можно задачу как бы
заевать. То есть вы можете себе представить, что n это длина входа. Представьте, у вас есть задача,
n это длина входа, то есть сколько чисел подается на вход, например. Понятно, что если у вас вход
небольшой, n меньше, чем n большое, то, наверное, можно как-нибудь там просто написать программу,
которая все случаи перебирает и что-нибудь возвращает. Поэтому нам на самом деле интересно
поведение только для больших n, для всех начиная с какого-то, грубо говоря, на бесконечности. И вот
собственно для всех этих n, начиная с какого-то, мне нужно, чтобы одна функция была не большим,
другая умножена константу. Вот. Ну и мы тогда будем говорить, что, скажем, если есть два алгоритма,
решающих задачу, один за время f от n, другой за время g от n, причем f это у большого g, то f как бы
более выгодный алгоритм, потому что он для всех содержательных n не больше, чем g, но, возможно,
умноженный констант. Давайте это замечание сделаем. Да. Может быть никто не мешает. Еще раз.
Тогда она еще, тогда она прям супер крутая, она сильно лучше, чем g. Как раз, если она больше единицы,
тогда... Не понял вопрос, короче. Но, тем не менее, между ними соотношение будет какая-то константа.
И вот как раз, то есть да, с точки зрения константы, возможно, g будет как бы лучше, но с точки зрения
порядка роста они будут одинаковые. Если вот тот случай, который вы имеете в виду, то они как раз
будут примерно одинаковые. И мы именно не хотим делать различия между ними, если они отличаются
всего лишь в константу раз. Чуть-чуть позже, значит, тоже запишу. Замечание, если f равно у
большой вот g, и есть два алгоритма, решающих какую-то задачу. Значит, один за время f от n,
другой за время g от n, тот первый считается эффективнее второго. Вот именно потому, что для
всех содержательных n, для всех n, начиная с некоторого, функция f не больше, чем g на константу.
Вот. И мы для себя считаем, что вот это вот отличие в константу раз для нас несущественно. То есть,
если f не больше, чем c на g, тогда f уже нормальная, хорошая, не хуже, чем g.
С большой не можем упустить? Ну, поменять всегда определение. Мы хотим именно так, чтобы было. То
есть, я хочу, чтобы два... Сейчас, секунду, вот отвечая на ваш вопрос конкретно, я хочу,
например, чтобы 100n было от n квадрат. Если я не позволяю себе содержательную константу c,
то вот это будет неверно. Потому что, например, при n равно 1, 100... Так, ну, начиная с какого-то,
это верно, конечно, да? Я понимаю, да. Окей. Да, я понял, хорошо. Ну, смотрите, это работает,
только если действительно первая функция меньше, чем вторая, симпатически. Ну, то есть, там,
предел отношения ноль. Если первая, то мало от второй, на самом деле. Вот. Но тогда это не
работает на функциях одного порядка. Мы хотим на функциях одного порядка тоже, чтобы они вот так
соотносились. Окей. Да. Это нормально. Вот. Сейчас как раз мораль. Почему нам нормально,
если две функции отличаются в константу раз, даже если константа большая? Тут есть много
объяснений. То есть, смотрите, мы считаем, грубо говоря, вот у нас есть два алгоритма. Например,
давайте посмотрим. Есть одна функция, работающая, скажем, за 10n. Есть вторая, работающая, скажем,
за 200n. Да, с точки зрения нашего определения, во-первых, f – это у большой от g. Так,
значит, с точки зрения нашего определения f – это у большой от g. Ну, потому что, например,
можно взять даже ц равную единице просто. У нас всегда 10n не больше чем 1 на 200n. С другой стороны,
g – это у от f. Потому что можно, скажем, положить константу 20, и тогда будет верно, что 200n не
больше чем 20 на 10 от n. Вот, вроде пока не обманываю. Вот это. Ну, смотрите, здесь написано
примерно следующее. Вот представьте, есть два алгоритма, решающие одну и ту же задачу. Один
работает за столько, другой за столько. Ну вот, что такое n? n – это, грубо говоря,
параметр входа. Представьте себе задачу. У вас есть? Да. Да, одну и ту же задачу решают. Вот,
написано же. Нет, просто не совсем понятно. Грубо говоря, в одном моменте мы можем понимать,
что f меньше или равно с учетом константы, а в другом моменте… Нет, просто f меньше или
равно, чем g с учетом константы. Просто всегда. Для всех n, начиная с некоторого.
Так они же имеют одинаковость. Нет, это здесь нигде не написано. Вот,
определение. Здесь неравенство не строгое. Здесь не написано, что они имеют одинаковость
в сем точках. Здесь написано, что f имеет сем точку не больше, чем g, потому что неравенство.
Да, например. Значит так, смотрите. Так вот, почему можно здесь брать, действительно, любую
положительную константу? Почему я себе это позволяю? Потому что я хочу не различать такие функции. Вот
функции одного порядка роста я не хочу различать между собой. Потому что, во-первых, очень многое вот
в этой константе, вот этих десять или двести, зависит от конкретной архитектуры компьютера. Потому
что когда мы оцениваем реальное время работы алгоритма, мы на самом деле многое игнорируем. Мы
игнорируем то, за сколько обращается, например, происходит доступ в память. То есть представьте,
у вас есть какой-то длинный массив, и мы обращаемся к какому-то и тому его элементу. Мы считаем,
чтобы работать за единицу. Просто одна итерация. Взять число в какой-то ячейке массива или там
просто где-то в памяти, из памяти что-то достать. Мы считаем, как бы в нашей неформальной модели
вычислений, что это единица по времени. Одна элементарная операция. На самом деле, конечно,
время работы такой операции может варьироваться. Потому что у вас есть на самом деле какие-то там
указатели, которые показывают куда-то в вашу память, и вам нужно это указатель куда-то передвинуть и
посмотреть, что вот здесь вот лежит. Это, наверное, зависит от того, какое расстояние нужно этому
указателю пройти. Если у вас есть какая-то большая память, вам нужно как-то по ней сначала походить,
чтобы достать вот этот самый элемент. А мы всегда говорим, что это единица. Один элементарный такт.
Поэтому уже эти константы не очень прочные. Потому что зависит от того, какие на самом деле
элементарные операции. Дальше мы, например, будем считать, что сложение и умножение это тоже
элементарная операция, которая работает за единицу, за один элементарный такт. Вот есть там два числа,
будем считать, что команда x плюс y и x умножить на y работает за один такт. Я не говорю за одну
наносекунду, за один такт работает процессор. На самом деле, конечно, это тоже не так. Понятно,
что умножение более сложно операции, чем сложение. Не говоря про деление и взятие по модулю. Чтобы
над этим не заморачиваться, чтобы не думать о том, какие конкретные операции у меня внутри алгоритма,
и чтобы вот это все считать за одну операцию, я как раз позволяю себе, чтобы мои функции были равны
с точностью домножения на константу. И сравнивать их я буду тоже с точностью домножения на константу.
Это первый аргумент. Почему константа перед основным множителем не очень важна? Потому что
мы ее на самом деле не можем очень хорошо оценивать. Точнее, как бы можем, но тогда это прям отдельная
область, где нам нужно аккуратно разбираться во всем коде, что такое взять какой-то элемент массива,
за сколько работает сложение, деление и так далее. Это было бы совсем другое описание всех алгоритмов.
Нам нужно было бы формализовывать модель, как у нас устроен компьютер. Мы не хотим это делать,
по крайней мере, не в этом курсе. Вторая причина, например, в том, что компьютеры все время довольно
быстро ускоряются и ускоряются. Постоянно появляются новые процессоры, которые умеют выполнять все
больше и больше элементарных операций в секунду. Поэтому даже если у нас есть вот такой алгоритм,
то лет через 15 они будут отрабатывать за такое же время, как вот эти алгоритмы. Поэтому с точки
зрения вечной теории нам опять-таки не важно, какая там константа, потому что если сейчас это долго,
то через 10 лет это будет быстро. Но это более-менее как минимум две причины, по которым действительно
эта константа перед национальным ножетелем не важна, и значит я могу себе позволить здесь отличие
в любую положительную константу раз. Так, убедил хоть чуть-чуть? Никто не сказал да,
ну вроде нормально. Е-е-е, спасибо. Ну вот, все, мы будем с этой штукой работать. Нам нужны ее
небольшие свойства. Утверждение f равно о большой от g, если и только если существует
положительная константа, давайте назову ее c с крышкой, такая что для любого n, давайте
подчеркну натурального, f не больше, чем c с крышкой на g. Отличие очень простое, я выкинул
ограничение на n большое. Я сказал, что то, что написано на второй доске, равносильно тому,
что просто для любого n это неравенство верно. Да, там написано для всех, начиная с некоторого,
например, с тысячи или с двух тысяч. А здесь вообще всегда, я говорю, но возможно с другой
константой. Да, именно так. Мы сейчас как раз докажем, что если вот ту константу c чуть-чуть
увеличить, то это неравенство будет верно вообще всегда. C с крышечкой. Просто число. Вот это как
обозначать c1, c2, то то же самое c с крышкой, это какое число просто? Могу написать здесь d.
Есть, сейчас докажем. Вопрос. Ну, потому что кто-то их еще не знает. Я с какого-то момента
начну. Хорошо, значит с какого-то момента в виду, не бойтесь. Доказательства слева направо давайте.
Скажите, пожалуйста, какое c с крышкой надо взять, чтобы это было верно. Давайте запишу,
пусть. Ну, хорошо, если вы просто в квантрах, давайте напишем. Для всех, начиная с какого-то,
на f не больше, чем c на g от n. Так, это убило кого-то? Значит, все уже умеете, да? Не, пусть я не буду,
извините, это точно не commonplace так писать. Так, что дальше? Да.
Да, все правильно. Давайте я только не буду умничать про верхнюю грань, потому что нам
это даже не нужно. Мне достаточно это сделать только на первых n больших натуральных числах. Все,
что происходит для n больше, мне не интересно. Так вот, давайте я положу c с крышкой таким,
максимум из c вот этого самого и всех дробей вида f поделить на g для маленьких натуральных
аргументов, вплоть до n большого. Вот. Значит, в качестве c с крышкой возьму максимальное из
вот этих вот чисел. Тогда я утверждаю, что для этого конкретного c с крышкой будет верно это
неравенство. Ну почему? Давайте докажем, давайте докажем, что это реально верно всегда. Докажем,
что для любого натурального n f не больше, чем c с крышкой на g.
Давайте рассмотрим два случая. Случай первый. Пусть n не больше, чем n большое. Ну тогда мы знаем,
что c с крышкой точно больше или равно, чем f от n маленькой, делить на g от n маленькой. Просто по
определению c с крышкой мы c с крышкой специально взяли таким, чтобы c с крышкой было больше всех
таких дробей для маленьких n маленьких. А если n маленькой не больше, чем n большое, то c с крышкой
точно больше равно такой дроби. Ну а значит, просто если я домножу обе части на g, то немедленно
получу, что f от n не больше, чем c с крышкой на g от n. Победа. В этом случае все доказали.
Сейчас второй случай просто. Проблемы нет просто, их надо аккуратно все разобрать.
В случае n больше, чем n большое я вот это неравенство не могу сходу написать. Ну по крайней
мере не знаю. Здесь то немедленно следует из определения. Вот смотрите, c с крышкой это максимум
из c всех таких дробей. В частности там где-то есть, вот давайте здесь напишу, там f от n маленькая,
делить на g от n маленькая. Да, конечно. А в этом случае мы знаем, что c с крышкой больше равно, чем c.
Потому что опять-таки c с крышкой определится как максимум чего-то там, в чем в частности участвует
c. И еще мы знаем, что для таких n f не больше, чем c на g от n. Ну значит подавно не больше,
чем c с крышкой на g от n. Кажется доказали. Опросы? Вот это почему? А вот же, вот же,
прямо написано. Для всех n больше, чем n большое, верно, вот это неравенство. Я его просто там
использую. Просто для всех n, начиная с n большого. Это следует, это просто определение того, что f это у
большого g. Да? Можем, конечно, да. Например, n это o мало, это n квадрат. Да, ничему не противоречит.
Нет, в смысле, ну можем. А в чем вопрос? Еще раз? Нет, это нормально, это как раз хорошо. Мы хотим,
чтобы o отражало, что одна функция не хуже, чем другая. Ну понятно, что n не хуже, чем квадрат.
Если у вас есть два алгоритма, один работает за n, другой за n квадрат, то понятно, вы предпочитаете
вот этот, потому что это меньше, чем это. Это ровно смысл o большого. Вот этот алгоритм лучше, чем этот.
Это ровно смысл ложки. Это доказательство, конечно, вот началось доказательство. Я доказываю слева
направо. Я расписал, что такое f это o а g. Вот оно, вот это вот, это вот это просто. Нет, почему же? Что
такое доказательство слева направо? Значит, если это верно, то верно вот это. Вот я это, значит,
переписываю просто. Вот это верно. Конечно. Можно. Вы торопитесь опять. Давайте я сначала начну,
я сначала докажу, а потом вы спросите, в чем смысл. Давайте его докажем сначала. Где? Нет,
без крышки. Вот я просто переписал вот это определение туда. Не понял вопрос. Из
определения o большого. Вот я еще раз. Что я хочу доказать? Я хочу доказать, что если вот это,
то вот это. Но что такое вот это? Вот у меня здесь написано. Что такое f равно o
большого g? Я просто переписал и все. Так, я продолжаю. Давайте еще раз сосредоточимся. Идем справа
налево. Скажите, пожалуйста, что нужно здесь сделать. Доказательство справа налево. Да, все верно.
Значит, просто положим n большой равно единице. Но если мы знаем, что f всегда не больше, чем c с крышкой
на g, то значит, в частности, для всех, начиная с единицы, это верно. Доказали то, что хотели.
Потому что что? У меня известно вот это всегда, а я хочу доказать, что это выполняется для всех,
начиная с некоторого. Вот пусть то самое некоторое, это будет единица.
Ну потому что мне что нужно? Мне нужно, чтобы вот это вот выполнялось. А, ну еще надо сказать,
что, видимо, c это c с крышкой. Вот. Ну все. А мне что нужно? Мне нужно, чтобы для всех,
начиная с n большого, выполнялось f не больше, чем c на g. Но если n большой это единица,
это верно всегда, то это тоже получается верно. Потому что c с крышкой равно c. Профит.
Вопросы? Давайте. Давайте еще раз. Смотрите, мне известно вот это. Вот это верно всегда. Я
доказываю справа налево, то есть, смотрите внимательно, вот это верно всегда. Что мне
нужно? Мне нужно вот это вот записать, что для всех n существует какое-то n большое,
что для всех n маленьких большое n большое, верно вот это, еще для кого-то c. Ну давайте я
определю вот такое c, вот такое n большое, и тогда это будет тривиально верно. Да. Я их просто подобрал,
и вот это будет верно по определению. Ничем можно взять тысячу, можно взять какое угодно,
но оно тоже существует, все равно. Но этого достаточно. Можно так. Так, едем дальше.
Значит опять, давайте я скажу, зачем мы это сделали. Почему мы определили тому большое,
для всех n, начиная с некоторого, и доказали эквивалентность тому, что просто для всех n?
Ну потому что иногда алгоритм удобно анализировать для всех n, начиная с некоторого. То есть,
представьте, у вас алгоритм делает что-нибудь для больших n, а маленький n он как-нибудь
отдельно перебирает. Там, например, он отдельно говорит, что если n равно единица, делай то-то,
если n равно двойки, делай то-то, а там бла-бла-бла, а вот с десятки начинает уже какой-то там большой
алгоритм. Тогда можно вообще не анализировать то, что происходит на маленьких n, там один,
два и так далее, там десять, можно не анализировать. Ну потому что мы доказали
эквивалентность, что анализ какого-то n, это в общем-то эквивалентно с точностью до вот этой
константы, эквивалентно тому, что просто всегда одна функция лучше, чем другая. Поэтому мы себе
позволили анализировать алгоритм не всегда, а только для достаточно больших n. Но если вдруг надо будет,
то можно будет делать так. Так, едем дальше. Значит опять, сейчас будет просто не равнится
в другую сторону. Пусть у меня есть две функции из n в n, пишем, что f это омега от g, если, ну давайте
теперь в кванторах напишу. Существует положительное c, существует n большое, такое,
что для любого n, начиная с n большого, f это хотя бы c на g. Это символ омега большое. Это не то,
что это в худшем случае, это основная ка снизу, если раньше было сверху, то это снизу. Да,
да. Простое замечание, f равно омега от g, если и только если g равно от f. Вот это? Это все
натуральные числа, 1, 2 и так далее. Ну, у меня сегодня ноль ненатуральная. Если кто-то уже привык,
что ноль натуральная, у меня сегодня ноль ненатуральная. Это неважно. Смотрите, f не лучше,
чем g. То есть время работы f-ки больше равно, чем g на константу. То есть тут, наоборот,
если у меня раньше было f лучше, чем g, то теперь оценка в другую сторону f хуже. Время работы f
больше, чем g на константу. Ну, просто оценка в другую сторону. Если раньше у меня было меньше,
теперь больше. Так, вот это верно почему? Да, да, можно просто обратить вот эту константу. Ну,
давайте я коротко это объясню. Если f это омега от g, значит f больше равно c на g, а значит,
ну, тут можно на самом деле эквалентность написать. g не больше, чем 1ц на f. Ну, а это в
точности вот это. Ну, просто я вместо c взял 1ц, и все. А мне же не важно, какое именно c. Просто вот
оно какое-то существует. Поскольку c больше нуля, я имею право так сделать. Это будет положительное
число опять-таки. Ну, и вот получили, что эти две штуки эквалентны.
Так, ну и опять-таки утверждение симметричное предыдущему, что одна функция это омега,
другой. Если это неравенство, можно написать просто всегда. Не для всех,
начиная с некоторого, а просто всегда. Ну, просто вот это вот с точностью до знака неравенства. Да,
ну доказывать не буду, доказывать точно так же. Давайте напишу доказательство аналогично.
Да, ну я опять-таки просто отбросил вот этот вот ограничитель. Если раньше было для всех,
а начиная с некоторого, то теперь просто для всех. Вот это вот я отбросил. Так, ну и последнее
определение. Значит, вновь пусть есть две функции из n в n. Пишем, что, так, ну да, да,
все правильно. Пишем, что f это θ, вот g, она греческая большая буква θ. Если существует,
давайте так напишу, c1, c2 больше нуля, существует n большое, такое, что для любого n больше,
верно, следующая цепочка неравенств. Вот, то есть g у меня оказалась заперта, и снизу она больше
чем f на константу, и сверху меньше чем f на константу. Да, вот это именно то самое одного
порядка. Это ограничение снизу, это ограничение сверху. Если, ну на самом деле, да, наоборот,
это неважно, это симметричное определение. Давайте я для красоты здесь поменяю, это неважно,
конечно. Да, то есть вот эта функция заперта с обеих сторон другой на константу. Ну они,
конечно, разные, скажем, здесь может быть c1 равно 1 сотая, а здесь c2 это 100 просто. Но,
тем не менее, это нормально. Если g больше чем f поделить на 100 и меньше чем f умножить на 100,
то это хорошо. Мы считаем, что не одного порядка. Ну не о, только θ. Да, n уже не равно θ от n
квадрат. Равно только o. А я вот это проговорил, что мы можем не анализировать поведение алгоритма
на маленьких входах. Потому что алгоритм может работать так. Если n маленькое, делай что-нибудь,
там, не знаю, перебирай, например, все варианты ответа и выведи из них то, что на самом деле ответ.
А вот для всех n, начиная с какого-то, он действует там определенным образом. Вот это маленькое начало,
когда n маленькое, n меньше чем. Там был вопрос еще. Диапазон чего? Граждане,
можно не мешать, пожалуйста, мешайте, я даже не слышу вопрос человека. Не-не, все нормально,
сейчас давайте, например, еще это пощупаем. Давайте тоже это запишем, что f равно θ от g
равносильно тому, что одновременно верно f это от g и f это омега от g. Мы считаем, что они одинаковые.
Вот, значит, это почему, ну, смотрите, я говорю, что f это θ от g, если верно и то, и то, и ошка,
и омега. Но потому что одна из них, это вот это вот неравенство, другой это вот это. Их
объединение, ну, точнее, их как бы пересечение, их совокупность и есть оценка с точки зрения тетты.
Так, ну, смотрите, я не буду повторять определение, которое я записывал уже на доске. Вот это вот f равно
от g, значит, что f меньше равно чем c на g. Омега, значит, f больше равно чем c на g,
ну, для какой-то возможно другой c. И это здесь ровно и написано, что с одной стороны f не больше
чем g на константу, с другой стороны f больше чем g на константу. Возможно, для разных константов.
И если верно и то, и то, совокупность, значит, выполняется и то, и то. Ну, это в точности то,
что здесь написано в определении тетты. Они считаются одинаковыми. Если они равны с точки
зрения тетты, то мы считаем, что это одинаковая поэффективность алгоритмы. Да.
Тетта. Вот это то же самое тетта. Кружочек и буква n такая маленькая внутри. Если вы техаете,
то это backslash тетта. Примеры. Давайте считать, что a и b это константы какие-то. Рассмотрим
две функции, n в степени a и n в степени b. Как это называется, степенные функции или наоборот?
Я не шарю. Ну, короче, вот такие функции посмотрим. Скажите, пожалуйста, когда верна вот такая вот
запись? Верна вот такая вот запись. Да, когда a меньше или равно b. Ну, там я считаю, давайте на всякий
случай скажу, что они положительные. Потому что если отрицательные, то, конечно, наоборот. У нас
такого не будет. Понятно, что если вот эта вот степень меньше, чем вот эта, меньше либо равна,
то просто эта функция меньше, чем вот эта функция. Значит, этот алгоритм эффективнее вот этого. Ну,
вот как раз ровно o большое и это и отражает, что одна функция растет не быстрее, чем другая. Вот если
a меньше, чем b, например, n в степени полтора, это o большое от n в степени 1 и 7. То есть, если
вдруг у меня есть два алгоритма, один работающий за такую симптотику, другой за такую, то я предпочитаю
вот этот. Ну, просто потому что он меньше. Да. Сильно легче стало вам? Ну, на самом деле замечание
справедливое, но мы зачастую не будем вот это вот делать. То есть, да, на самом деле мне нужно
было бы всегда вот говорить, что у меня там значения целые, всегда. Ну, потому что это на самом
деле количество тактов работы. Наверное, количество тактов работы процессора не может быть там
дробным каким-то. Вот. Но на самом деле мы это будем зачастую опускать. И вот там округление вниз и вверх
всегда с точки зрения симпатического анализа будет несущественное, и я буду всегда себе позволять
этого не делать. То есть, округление вниз. Да. Так, едем дальше.
Да. У отф это не функция, это семейство функций на самом деле.
Можно было бы писать, но так никто не делает. Ну, как бы, с точки зрения теории, возможно,
формально было бы это правильно делать, но так никто не делает. Так, пример. Второй. Опять-таки,
пусть есть какие-то константы. Давайте вот это считать, что больше одного. Давайте рассмотрим
две вот такие вот функции. Логарифмы по разным основаниям. Например, логарифмы по основанию 2,
логарифмы по основанию 100. Да, ну, конечно, то есть, формально это f от n, это g от n. Это значит,
какой значок я должен написать? TET. Все правильно. Причем независимо от того,
какие здесь именно константы стоят. Почему? Ну, потому что переход к другому основанию
логарифма это умножение на константу. Я сейчас напишу формулу, вы меня, возможно,
подправите, потому что я в этом не уверен. Вроде бы верно следующее. Супер, значит,
я закончил старшую школу. Смотрите, вот функция f, вот функция g. Они отличаются ровно в константу
раз. Вот он лог a по основанию b. Это константа. Раз а и b какие-то конкретные числа, то это
конкретное число. Если две функции отличаются просто умножением на константу, ну, понятно дело,
они одного порядка. Можно просто вот эту константу взять в качестве вот этих вот как раз зажимающих
c1, c2. Согласны? Чудно. Дальше. Давайте считать, что а и b константы. А больше одного, b больше нуля.
Нет, просто вот функция f вот так вот определена. Вот функция g вот так определена.
Ещё раз? Можем, можем. Ну, я просто одно из них написал. На самом деле, конечно же, то есть смотрите,
я написал, что f это ttg. Но на самом деле, верные и обратные всегда. Это тоже очень легко доказать.
То есть я здесь написал, что f это ttg. Конечно, верные и обратные, что g это ttf. Потому что, ну,
просто если вот в этих неравенствах там вот это поделить на c1, это поделить на c2, то у меня
получится, что, наоборот, f с обеих сторон заключена между там ж. Вот давайте, давайте,
давайте я поделю. Вот здесь на c1 получится, что f не больше, чем 1 c1, g вот n. Здесь будет
больше и равно, вот если я это поделю на c2, получится 1 c2 на g вот n. Вот. Мы получили ровно того
же вида утверждения, что функция 1 заключена между другой, умноженной на разные какие-то константы.
Ну как же, вот. По факту при всех, по крайней мере, при всех начинается некоторого. Вот. Значит,
это на самом деле всегда, просто если есть одно, то есть другое, а не одного порядка роста.
Так, еду дальше. Значит, смотрите, теперь следующие две функции. Логарифом. А, ну так вот,
вот я это не договорил. Из этого следует, на самом деле, что я могу впредь не уточнять основание
логарифма. Потому что, если я меняю одно основание логарифма на другое, то у меня время работы
отличается всего лишь в константу раз, а с точки зрения вот этих всех наших значков, что омега,
что о, что тетты, это безразлично. Поэтому я могу основание логарифма никогда не писать. Вот,
я впредь это почти никогда делать не буду. Значит, давайте я здесь напишу. Ну, то есть, я там
подразумеваю, что логарифм по основанию два, но этого не пишу. Итак, значит, одна функция это
логарифм в степени а от n, другая функция это n в степени b. Что можно между ними написать?
Да, f это от g. Это верно, а в другую сторону неверно. Ну, да, да, да, да. Нет, это логарифм в степени
а основание, вот я проговорю, что основание можно считать, что по основанию два, но я его не пишу
никогда. Пример v вроде бы еще. Да, всегда, если есть вот это, то значит есть симметрично
противоположное g это омега т. Ну, почему это верно, там, я доказывать не буду, но интуитивно
логарифм, в какой бы вы степени не взяли, он растет медленнее, чем n в любой положительной степени.
Да, ну это вот, собственно, то же самое, только после логарифмирования, получается. А можете
просто это упражнением доказать, если интересно? Да. Так, вопрос? Вот это? Не, не, это оценка
сверху, вспоминайте, f не больше, чем c на g. Это снизу, g больше или равно, чем c на f. Тут как раз вот
ровно это, а вот это больше, чем вот это. Так, последний пример, давайте такие две функции рассмотрим,
но опять для какой-то константы а положительных. А давайте даже вот так вот сделаю, чтобы
поинтереснее было. Вот тут очевидно уже, нет? Почему? Что получается? Да, нет. Да, g это у от f.
Давайте я не буду брать логарифм, давайте я оставлю функции в своем хорошем виде. Просто я вот это вот
запишу в виде 2 на n логарифм n. Ну просто потому что 2 в степени логарифма это как раз n, и оно еще в
степени n возведется. Ну и тогда понятно, что вот эта вот штука больше, чем вот это, а значит
после потенцирования 2 в этой степени больше, чем 2 в этой степени. Ну по крайней мере для всех
начиная с некоторого. Значит я могу написать, что вот эта штука меньше, чем вот это. Ну в терминах
асимптотики g это у от f. Ну и соответственно верно обратное f это омега g. Ну хорошо, давайте
докажем, что 2 в степени n больше и равно, чем. Так, ну это конечно я, ну давайте попробуем.
Верно ли это всегда? Наверное давайте попробуем доказать, что это всегда верно. Давайте
про логарифмируем по основанию 2. Будет вот это. Тут вроде уже понятно почему. Тут
линейная, а тут там сумма логарифмов каких-то. Вот. Ну как бы я надеюсь, что где-то на мотоне вы
вот эти функции хорошенько пощупаете и будете сразу понимать, что одна больше, чем вторая. Там
если надо, вот какие-то такие штуки можно логарифмировать. Говори, что линейная больше,
чем логарифм. Ну там до всех начиная с некоторого и так далее. Так, ну хорошо. Что по времени? Полчаса
есть. Хорошо. Значит все, смотрите, мы теперь получается на самом деле разобрались с тем,
как сравнивать по крайней мере два алгоритма. Если у нас есть один алгоритм рабочий за какую-то
асимптотику, другой за другую, мы хоть немножко пощупали то, как сравнить функции между собой и
какой алгоритм выбирать, если есть несколько. Так, последнее, что скажу вот в этой части,
это когда у меня функции от многих аргументов. Функции многих аргументов. Ну здесь на самом деле
все очень просто. Значит давайте я сразу на конкретном примере буду писать. Я говорю,
что функция f зависит от переменных n и q. Это o. Вот g, которая зависит от переменных n и q. Ну если
просто-напросто существует положительная константа, такая что, либо для всех n и q начиная
с некоторым, либо как мы знаем просто всегда, f не больше, чем c на g. Нет, мы вводим для функции
многих аргументов понятие o. То есть раньше у меня было o только для функции одного аргумента,
то теперь для нескольких. Ну на самом деле все то же самое. Просто 1 это o от другой,
если 1 не больше, чем c на другую, где c какая-то константа. Ну вот пусть функция f это функция
двух аргументов. Ну то есть формально надо было написать, что f и g из n квадрата в n действуют.
Логика такая же просто. 1 функция это o от другой, если эта функция не больше, чем c на другую.
Да, все правильно. Так, ну теперь наконец давайте какую-нибудь задачу решим. Задача. Представьте
себе, что у вас есть массив из n целых чисел. И поступают запросы. Вам нужно по индексам l и r
найти сумму чисел с l и r. Это база. Это правда. Да, ну не верю. А если у вас q запросов? Замечательно.
Давайте его напишем. Решение 1. Время работы будет n на q. Ну на самом деле нельзя здесь писать
t, то давайте только o напишем. Потому что, ну мало ли, а все-таки может эти границы всегда маленькие,
это будет именно на самом деле o, а не t. Я буду сейчас только o писать. Ну очень просто в ответ
на каждый запрос я прохожусь по этому отрезку, складываю все числа. На просто цикл там по всем
и от l до r сложить вот эти элементы. А какая разница? Поэтому написано решение 1, чтобы 8.сравнить.
Это понятное решение? Ну просто в тупую для каждого запроса проходимся по вот этому отрезку,
складываем все числа. В худшем случае длина этого отрезка n. Ну там может быть n пополам,
может быть там n на 3, но точно не больше, чем n. На каждый запрос я делаю максимум n операций,
поэтому время работы это от n на q. Опять вот я здесь как раз я игнорирую то, что у меня, как
именно внутри устроены там операции сложения, операция пробегания по памяти, я считаю, что все
этой элементарной операции, вот эта сумма находится за вот это. Да, куза просов у меня.
Дерево отрезки футовый веркил, конечно. Сейчас будет. Рефиксная сумма называется,
очень сложный алгоритм. Работает так. Давайте шум погасим, пожалуйста. Кому не интересно,
можете, пожалуйста, выйти, я никого здесь не держу, но мешать не надо, окей? Да, спасибо,
хоть так. Значит, рефиксная сумма. Давайте заведем следующий нехитрый массив. Давайте для каждого
и посчитаем сумму элементов с первого по итой и сохраним это в памяти. Ну, это сделать вроде не
очень сложно. Можно сказать, что преф нулевой это ноль, потому что сумма нуля элементов это ноль,
а дальше для каждого следующего можно заметить, что преф и плюс первая, это преф предыдущая,
плюс а и плюс первая. Значит, можно просто за линейное время пройтись по этому массиву,
насчитать вот эти префы по вот этой формуле и тем самым мы будем знать сумму на всех префиксах.
Ну, поэтому я и написал префиксную сумму. Вот у меня есть такой мой массив, а1, а2 и так далее,
аn. Я вот на всех таких вот кусочках могу посчитать сумму и более того сохранил ее в массиве. И дальше,
чтобы мне ответить на запрос суммы с l-th элемента по r-th, я могу просто вывести преф r-th
минус преф l-1. Нельзя, конечно, да. Объяснение очень простое. Вот представьте себе отрезок с
l-th элемента по r-th, вам нужно найти сумму элементов здесь, а вы взяли вот это и вычли вот это. Осталось
ровно то, что нужно. Да? Ну, супер. А симптотика вот такая. Потому что сначала я трачу линейное
время на считывание массива и предподсчет массива префиксных сумм. То есть там две линии, там 2n,
но извините, я не пишу 2, потому что у меня O и она все константы сразу съедает. Поэтому считывание
массива и насчет префиксных сумм у меня будет n, O от n. А дальше на каждый запрос я отвечаю за одну
операцию вычитания и две операции обращения к массиву. Но поскольку я считаю, что обращение
к массиву и вычитание это элементарные операции, я говорю, что это просто Q. Поэтому время работы
будет n плюс Q. Да. Здесь можно, здесь можно. Вот здесь нельзя было, потому что у меня длинные отрезков
могли варьироваться, и n это только оценка сверху. Да, то есть, возможно, вот если здесь длинные
отрезков маленькие, то это, возможно, было бы просто от Q. Представьте, что в каждом запросе l и r
очень близки. Тогда мы примерно за единицу бы отвечали. Можно, но все равно нельзя сказать,
что этот алгоритм работает за t от nQ, потому что на некоторых входах работает быстрее.
Но вот я не буду так делать, то есть в общем случае нельзя написать, что алгоритм работает за t. То есть
на конкретных входах работает, но не всегда. Да, но вот я хочу различать, что то есть на каких-то,
то есть эта штука работает по-разному на разных входах. Она не всегда такая, она иногда Q,
иногда nQ. Я не хочу себе здесь ставить t и говорить, что она всегда nQ. В худшем случае nQ действительно,
но не всегда nQ. Я вот здесь не пишу. То есть там в разных структурах данных, типа, бывают там вот
это вот конкретное подразумение в лучшем случае за столько, в худшем за столько. И ну как бы нельзя
это в t обезвинить, потому что это это всегда зажатие между вот, просто по определению, да,
если бы я написал здесь t, то у меня получилось бы, что этот алгоритм всегда на любом входе работает
хотя бы c на nQ. Это неверно. Ну на каких-то входах да, но не всегда. Я вот именно себе не запрещаю
работать быстрее. Окей? Так, вроде все. Теперь вопрос, какой из этих двух алгоритмов надо выбрать?
Ну, наверное второй, да, потому что, наверное, сумма меньше, чем произведение. Хорошо.
Ну, еще сложная задача очень. Представьте себе, что у вас есть отсортированный массив.
Числа в нем идут в порядке возрастания. Ну давайте я задам себе такой вопрос. Значит,
запрос, есть ли в этом массиве число x. Ну и опять таких пусть будет ку штук.
Опять первое решение работает наивным образом. Давайте просто при поступлении запроса о поиске
числа x пройдем полностью по этому массиву и проверим каждое число на равенство x. Если хотя
бы один раз нашли x, то значит оно там есть. Если не разумеется, то нет. Давайте я напишу просто
наивный, ну наивный поиск пусть будет, наивный поиск. Значит, это работает опять-таки, в худшем
случае за n-ку, но иногда быстрее, потому что на каких-то конкретных входах, скажем, если x всегда
какой-нибудь супермаленькая, то мне там нет смысла идти дальше, чем a1. Ну или, например, если x это
всегда a1, то я всегда сразу его вижу и возвращаю, что оно там есть. Но в худшем случае мне придется
на каждом из кузапросов пройти весь массив за линейное время, за n. Понятно? Ничего хитрого.
Решение второе называется бинарный поиск. Давайте немножко поменяю задачу. Давайте я буду вместо
проверки существования там x искать, ну скажем, наименьшее число больше либо равно x. Будем искать
наименьшее число, которое есть в нашем массиве, больше либо равно x. Ну и если это самое наименьшее
число больше или равно x равно x, то значит x там есть, иначе его нет. Если я найду такое число,
наименьшее больше или равно x, если оно равно x, значит победа, если оно не равно, значит поражение,
потому что если даже наименьшее больше или равно x больше, чем x, значит x нет. Поэтому это число
найти достаточно. Знаю его, я знаю, есть ли x в нашем массиве. Как это делать? Сейчас, одну секунду.
Давайте я сделаю вот так, правильно? Сейчас, полминутки. Ну да.
Давайте я веду себе следующее предположение, l равно n. Давайте сразу выполню проверку,
что если у меня, а давайте просто n плюс 1 вот так. И я неявно сейчас себе в голове пририсую сюда
число плюс бесконечность. То есть я могу вот сюда вот приписать, что a n плюс первое равно плюс
бесконечность. И соответственно, если что, то есть если вот это вычислом меньше, чем x, то если что,
вот это можно считать ответом. Наименьшее больше на x будет вот это. То есть я могу дополнить каким-то
большим числом. Дальше, ввожу такие границы и сам с собой договариваюсь, что то, что я ищу,
лежит в полуинтервале от l до r. Причем r включительно, l не включительно.
Почему? Все нормально, все нормально. Как раз нулевого у меня нету, а r, если что, n плюс 1.
То есть сейчас ответ точно не потерял. Нет, ну как, надо включать, потому что если все эти числа
меньше, чем x, а это больше, то надо r вернуть. Все нормально. Вот. Значит еще раз, почему в самом
начале такое верно? Почему я могу считать, что то самое число, которое я ищу, лежит в полуинтервале
от l до r включительно. Но потому что r это вот это, и если что, это число точно больше, чем x. Ну а l вот
здесь, вот этот вообще не существующий элемент, то есть по факту я ищу ответ во всем массиве, но он
где-то есть, понятное дело. А пока я себе ответ точно не потерял. Дальше делаю следующее. Пока у меня
длина полуинтервала какая-то содержательная, если полуинтервал большой, я делаю следующее. Смотрите,
вот есть у меня мой большой интервал от l до r. Давайте возьмем его середину, ну там примерно
центральный левой элемент. Мы посчитаем его по формуле l плюс r пополам с округлением вниз и
сравним ам с х. Сравним ам с х. Два случая. Если ам больше или равно х, тогда что можно смело
сделать? Какую? Неправильно, правую. Можно перейти к полуинтервалу от l до m включительно,
потому что еще раз, что я делаю, я ищу самое маленькое число, которое больше равно, чем x. Но при
этом я знаю, что вот здесь вот стоит число больше или равно, чем x. Поэтому самое маленькое точно
где-то вот здесь. Оно неправее, чем m. Потому что вот больше либо равно, а я ищу самое левое
больше либо равно. То есть оно где-то вот здесь. Ну поэтому я имею право перейти к такому полуинтервалу.
Согласны? Вот это больше либо равно, чем х, а я ищу самое левое больше либо равно х, потому что у меня
всё идет порядка возрастания. Наименьшее больше либо равно х, то же самое, что самое левое больше
Если так получится, что нам нужно будет найти первый элемент, вы же L не включили.
А смотрите, у меня L какое? А индексация 1.
Как раз у меня здесь в этом массиве, то есть в самом начале, я ничего не выкинул.
У меня границы корректные, у меня ответ точно здесь в самом начале.
Еще раз, почему больше, а не больше?
А ничего страшного, это вы предлагаете оптимизацию, а я говорю, что и так работает.
Мне лень думать, я утверждаю, что и так работает.
И соответственно, второй случай симметричный.
Если ам меньше, чем х, то я имею право, наоборот, перейти к правой половине отрезка.
Можно перейти к полуинтервалу от m до r.
И опять-таки этот переход будет корректный, потому что, смотрите, если вот это число меньше, чем х,
вот это число меньше, чем х, то понятно, что все, что слева, тоже меньше, чем х.
Потому что у меня идет все в порядке возрастания, если это меньше, чем х, то все левее тоже меньше, чем х.
Значит, ответ, если где-то и лежит, то точно вот здесь вот, причем не включая m.
Это число меньше, чем х, значит, ответ точно правее.
Поэтому левую границу здесь можно выкинуть.
Но правой остается, я знаю, что ответ где-то здесь.
Справедливо?
Ну, вроде верно.
Я утверждаю, что в самом конце у меня получится полуинтервал, содержащий ровно одну точку, являющуюся ответом.
Пока r-l большое, я это делаю.
То есть, по факту, просто разбивая отрезок на две половинки,
перехожу в какую-то из них, либо влево, либо вправо, в зависимости от знака неравенства.
В самом конце, после того, как это закончилось, после этого цикла, имеем r-l равно единице.
То есть, мы имеем на самом деле полуинтервал, вида l, l плюс 1, где левая не включена, а правая включена.
Ну, это, собственно, то же самое, что r.
Значит, а r – это то самое искомое число.
Ну, а если его нет, то r равно n плюс 1.
Ну, в любом случае, мы получили индекс наименьшего числа, больше равного, чем x.
Возможно, r будет равно n плюс 1, но тогда это значит, что все числа здесь были меньше, чем x.
И первое большее равное – это вот это.
Ну, тоже как-нибудь несложно это обработать.
В конце проверяем.
Ну, давайте напишем.
Давайте если r меньше равного, чем n, а r равно x, то тогда x присутствует в массиве.
Иначе не присутствует.
Победа.
Вопросы есть по алгоритму?
Хорошо.
Значит, если кто-то из вас внезапно привык писать бинарный поиск на отрезках,
то чем лучше то, что я рассказал, чем лучший поиск на полуинтервалах,
тем, что вам в конце не нужно два значения проверять.
Вот у меня сразу в конце полуинтервал содержит только одну точку, являющуюся ответом.
Вам не нужно проверять и aL, и aR на равенство x.
У вас всегда ответ, если есть, то это только aR.
Вам достаточно только одну точку проверить.
Он работает?
Он же за алгоритмом работает, да?
Да. Сейчас мы как раз проанализируем симптотику.
Я утверждаю, что эта штука работает за следующее время.
O от n плюс кулог n.
Почему?
Значит, n понятно откуда взялось.
Это время, необходимое на считывание массива.
То есть я сначала считываю все мои n чисел в память, располагаю в массиве.
Это вот первая n операция.
А дальше я говорю, что каждый запрос обрабатывается примерно за алгоритмическое время.
Опять, я не пишу основание алгоритма, потому что какое бы я основание здесь не написал,
то с точки зрения O большого это будет одно и то же.
Я не пишу, здесь осознанно основание алгоритма.
Какое бы ни написал, с точки зрения O все будет одно и то же.
Надо понять, нам остается понять.
А почему в симптотику алгоритма входит ассистентка, за которую он считывает данные?
Можно не учитывать, зависит от постановки.
На практике то, что вы будете делать в течение трех семестров, у вас будет работать так.
В контест, какие задачи вы будете сдавать дан массив чисел, надо с ним что-то сделать.
Вам же надо считать его сначала.
Поэтому я полностью анализирую все действия, которые потенциально надо сделать.
Конечно, иногда это можно дропать, если вам сказано, что массив расположен уже в памяти.
Но в общем случае нельзя это дропать.
Я хочу понять, почему ответ на запрос работает за отлог N.
Тут вроде не хитро.
Идея в том, что мой полуинтервал всегда делится примерно пополам.
Потому что у меня изначально был полуинтервал длины n плюс один.
На каждом шаге я считаю его середину и перехожу либо влево, либо вправо.
Понятно, что если m – это их полусумма, то количество элементов здесь примерно равно
количество элементов здесь примерно равно длине пополам.
На каждом шаге я делю мой отрезок примерно вдвое.
Ну а сколько раз можно n поделить на 2, пока он больше чем один?
Понятно, алгоритмическое количество раз.
Давайте это запишем.
На каждой итерации цикла
длина полуинтервала LR
делится примерно вдвое,
делится примерно
на два.
На самом деле, примерно, потому что в зависимости отчетности, возможно,
но там не пополам поделилось, а пополам с округлением вверх.
Например, если здесь было 9 элементов, вы поделили пополам в одной части 4, в другой 5.
Но все равно примерно пополам.
Каждый шаг примерно пополам.
А количество раз,
которое можно поделить n на 2,
которое можно поделить
n на 2,
пока число больше чем 1,
есть как раз логарифм.
В данном случае двоичный логарифм n.
Логарифм так работает, что
можно было представить в обратную сторону.
Вот если я начинаю с числа 1,
то сколько раз его можно умножить на 2, чтобы достигнуть n?
Примерно логарифмическое.
Получается, что у меня ответ на запрос за логарифм.
Да, здесь можно.
Считывание всегда работает ровно за n,
потому что мне нужно n элементов считать.
Как ни крути, это будет n.
Это правда.
Но если бы я здесь ставил какую-нибудь умную подхачку,
как мне предлагали, что если текущее число равно x,
то сразу прерывай цикл и принт yes.
Тогда уже нельзя было бы.
Если бы я внезапно на каком-то шаге нашел x,
то я бы этот цикл мой забросил сразу же
и из него вышел и пришел к следующему запросу.
Тогда было бы только o от логарифма.
Здесь можно писать это туда.
Потому что у меня задача распадается на 2.
Я сначала считываю весь мой массив.
Это занимает n времени.
А потом я на каждый запрос трачу вот столько времени.
Я заказываю, что время ответа на запрос логарифмическое.
Дальше у меня q запросов.
Поэтому суммарное время ответа на запрос это q log n.
Еще плюс n на время считывания.
Я здесь анализирую одну часть алгоритма, а здесь сумма всего.
Сумма всего, что делает мой алгоритм.
Еще раз, потому что я здесь отвечаю на один конкретный запрос.
Вот один запрос работает столько,
но q запросов столько.
Я это проговаривал, что там 2 n операции,
но 2 с точки зрения o можно убить.
Есть еще вопросы?
Ну окей, раз все хотят уйти, то давайте уйдем.
Спасибо, до следующего раза.
