Ну ладно, тогда давайте тихонько начинать. Запись там пошла. Звук есть, дёргается. Огонь. Если
будут какие-то проблемы, пожалуйста, говорите. Итак, ребят, лучший технический вуз, как вы
понимаете. Техника работает как надо. Итак, сначала пара организационных моментов. Спасибо,
что большинство из вас записались на курс. Там сейчас 321 анкета. Собственно,
касательно семинарский групп. Там, как и предполагалось, половина хочет ходить чисто в
лекционную аудиторию на семинары после лекции. Вопросов нет. Это абсолютно рабочий вариант.
Семинарский групп, собственно, семинарские занятия предполагаются по вторникам и средам,
в 18-30 вечером, очные. То есть туда можно записаться. Мы скинем опросик, чтобы понимать,
кто куда, когда пойдет. Уже маленький, просто в чатике. Пожалуйста, отметись.
Онлайн занятия, скорее всего, будут в районе пятницы, потому что так сложилось. То есть на них
тоже можно прийти. Вопрос. А кто хочет сегодня ходить в другую семинарскую группу? А вы точно
на нее ходить будете? Если да, то можно. Просто ранее получалось так, что ставили семинары
параллельно с лекционным потоком. Туда приходило два человека. В итоге они просто-напросто
переставали работать. Если есть необходимость, можно поставить в понедельник. Прошу. Сюда ходить
можно всем по умолчанию. Вопрос в том, кто-то будет в 18-30 по понедельникам ходить не сюда.
Тоже и черни. Смотрите, все семинары по умолчанию будут в 18-30, если не оговорено обратно. Потому
что все, как правило, преподаватели – это действующие специалисты, которые работают,
и они все это делают после работы. Так, здесь какие-то вопросы есть? Окей, смотрите. Тогда еще
пара организационных моментов. В репозитории появилась, соответственно, информация про все
плюс-минус, что необходимо. Там появилась примерная программа экзамена, там появилась табличка,
где будут лежать все записи лекций. Запись первой лекции там доступна. Второй пока обрабатывается,
потому что мы нанимаем нового монтажера, но появится на канале буквально сегодня-завтра,
я надеюсь. Там же есть список необходимых знаний, скажем так, необытимых фактов,
пререквизитов для курса. Короче, списочек из формата прочитать и понять, знаете ли вы из
этого списка все или нет. Намек, все, что без звездочки знать должны, наверное, все вот прям совсем,
и причем сходу в 3 часа ночи разбуди, чтобы вы это помнили. Поэтому, пожалуйста, проверьте сами себя.
Вот. И что еще? Там же появилось первое домашнее задание, его можно решать. Оно максимально простое
прямолинейное, там все описано. Сама проверяющая система сейчас подымется, мне надо деньги закинуть
на ту виртуалку, в которой она крутится. Чтобы сдать домашку, вам достаточно будет, собственно,
загрузить домашку, так как указано в инструкции, в проверяющую систему, она вам скажет, сколько у
вас баллов. Один, это сто процентов. Короче, вероятность единицы, то есть вы все решили. Один,
значит, полный балл. Ноль, значит, не полный балл, нулевой балл. Ноль пять, значит, половина решили,
какие тесты у вас не прошли, вам напишут. Вопросы, пожелания, комментарии есть?
Окей, надо открыть, видимо, надо будет написать, видимо, более явную инструкцию. Короче, там,
как правило, всегда есть в папке ноутбук, который называется Assignment, вот это ваша домашка. Все
остальное, вспомогательные файлы, внутри ноутбука Assignment написано, вся инструкция, что надо делать.
Конкретно в данном случае у вас есть ноутбук Assignment, там, по сути, какие-то вопросы, что-то,
что вам необходимо сделать. По факту, вам необходимо что? Реализовать класс кнн в
а чтобы у вас проверяющая система отработала и дала вам, скажем так, развернутый комментарий,
пока что это немного на костылях, но вам нужно весь текст этого файла, когда все работает,
запихнуть в template и сдать его. Там инструкция написана. Не спать. И вы и ноутбук. Пока нет
дедлайна, да, после дедлайна можете доздавать, но учитываться будет то, что вы получили до дедлайна.
Да, ну то есть все, что... А? Да, да, да, да. Там написано, чем нельзя пользоваться, то есть словом,
вам говорят написать кнн, использовать кнн за скалерно нельзя, вам надо его написать. Ну и так
далее. Ну оно там ограничено каким-то здоровым числом, пока что за всю историю никто его не
перебрал. Ну то есть там нельзя сделать, полностью не ограничить, там какой-то констант стоит, то ли
тысяча, короче, у вас раза с пятого, я думаю, зайдет. Ну если не идет там, например, четвертая
домашняя сложная, она раз с пятнадцатым может зайти. Это нормально, она примерно, это просто то,
что сдавали люди весной 21 года, поэтому она примерно. Смотрите, то, что вам написал бот,
я прошу прощения, это мой ассистент закинул разболовку раньше, чем мы ее согласовали,
на это пока не смотрите, я ее сейчас удалю. То, что там написано, это то, что было год назад. Оно
сейчас немножко поменялось, поэтому то, что там написано, это неактуально. Ну что ж, еще вопрос,
комментарии есть? Окей, смотрите, я на всякий случай напоминаю вот про этот файлик пререквизитов,
я про него еще раз в чате напишу, но по сути это то, что вам хорошо бы знать, это то, что мы с вас
спросим где-то в районе 19 сентября, в районе 3 октября мы скорее всего с вас спросим вот эти
факты. То есть хорошо бы их вспомнить, запомнить, заботать и так далее. Вы из них большинство
знаете, но опыт показывает, что многие эти вещи, что такое финное преобразование, далеко не сразу
люди помнят. Да, то есть ну представьте себе, что это какой-то потоковый экзамен, кстати,
если будет соответственно переполнение, такое может быть, мы просто еще одну аудиторию возьмем,
типа 123 ГК и туда часть выгрузим, ну чтобы не сажать тут людей прям совсем как сосиски. Это будет на
семинар, то есть лекция пройдет как обычно, потом кусочек семинара мы обсудим то, что необходимо,
там коротенький семинар специально сделан, а потом где-то час будет на вот эту контрольную.
Ну соответственно на нее явка плюс-минус обязательно, то есть неявка в формате заболел-уехал,
заболел-уехало принимается, но это надо тогда отдельно согласовывать. То есть в принципе у нас
посещение прям так по желанию, но на контрольную, как вы понимаете, надо прийти. Не, погодите,
вот там это будет конкретно просто в этот день контрольная, грубо говоря. Можете считать,
что она фиксированная для всех, это к семинарской группе не имеет отношения.
Решим. Просто я изначально предполагал, что в понедельникам нет других семинаров,
поэтому сейчас вы меня немного поставили в тупик. Хорошо. Так, окей, еще вопросы есть?
Ну ладно, тогда собственно вспоминаем, что у нас было в прошлый раз. Мы с вами чуть-чуть поговорили
про линейную алгебру, вспомнили какие-то базовые понятия, что-то починили, что-то разобрали,
где-то вы меня даже поправили. Большое спасибо, поправляйте меня абсолютно свободно. Сегодня нам
это дело пригодится, мы с вами поговорим про ужас линейную регрессию. Но те, у кого была статистика,
прекрасно понимают, что это такое. Те, кто ходили на лабо по общей физу, тоже прекрасно понимают,
что это такое. В принципе штука максимально простая, но при этом и очень красивая. Итак,
сегодня в меню. Во-первых, мы с вами поговорим о том, что такое линейная модель. В принципе,
как они работают, зачем они нужны и почему они используются повсеместно. Во-вторых,
мы поговорим о том, какие именно подходы к регрессии с точки зрения линейных моделей есть,
и какие есть подходы для получения аналитического решения и, собственно, какого, агрегентного
решения. Вот. Потом поговорим про теорему Гаусса Маркова. Классная теорема, одна из немногих
теорем машинного обучения, поэтому, пожалуйста, не забивайте на вот те там 3-4 теоремы, которые у
нас есть. Теорема Экрата Янга, теорема Гаусса Маркова и так далее. Штука классная. Да,
на экзамене это тоже понадобится и, в принципе, это понадобится, чтобы понимать. То есть вот,
если я говорю, обратите внимание на теорему, да, ее лучше заботать. Причем заботать не формально
о траторике, а понять то, что регулярно люди не понимают чуть такое. Потом поговорим про
регуляризацию. По сути, первый раз в таком более-менее явном виде. Сегодня у нас будет
регуляризация по-тихому, но на самом деле она много где еще применяется и называется
по-разному Way Decay и так далее. И поговорим про то, как понять, что ваша модель нехорошая.
Сказала бы по-другому, но мы все-таки в университете. Итак, если вопрос есть,
задавайте. Рук поднимаете, задаете. Поехали. На предыдущей лекции, предыдущей, которая не по
линалу, были разговоры у нас про что? Про понятие в машинном обучении, про то, что такое наивный
байсский классификатор, про теорему байса. Коротенько мы поговорили про КНН на прошлом занятии. Это
все, в принципе, работало. На всякий случай эта камера точно меня видит, а то он куда-то
спорит. Хорошо, спасибо. Вот. И сегодня мы переходим к линейным моделям. Как вы уже помните,
линейная модель это так, кто разводит линейное отображение из пространства параметров,
ой, признаков в пространство ответа. Вот то, что мы с вами на прошлые недели разбирали, как линейные,
по сути, отображения с почвы матричек, это, по сути, все есть линейная модель. Все,
что можно представить в виде линейной комбинации наших признаков, является линейной моделью и
так далее. Бывают линейные модели в регрессии, понятное дело, есть точки, провели палку. Бывают
в классификации, есть точки, разделили палкой. Бывают линейные модели даже там, где у нас не
стоит задача обучения с учителем, например, в задаче снижения размеров. Это unsupervised. Задача,
но на самом деле переходим в супервайс режим, то есть наша задача, у нас есть данные в размерности
25, мы хотим использовать не 25 признаков, а 3 признака. Как нам понить размеров, потеряв наименьшее
количество информации. Понятное дело, полностью мы не сможем сохранить информацию, потому что
нас размер с 25 на 3 не отображается, если не выражено. Но, тем не менее. Сегодня мы с вами поговорим
про регрессию классификации, это следующая лекция, а снижение размерности это через одну лекцию,
там поговорим про PCA. Но, я думаю, про метод главных компонентов тоже из вас многие слышали,
правильно? Кто слышал? Понял, не многие слышали. А что такое сингулярное разложение? Может,
больше слышали? Хорошо, а что такое разложение по собственным векторам? Может, больше слышали?
О, вот. Ну, по сути, почти все одно и то же. То есть, из разложений по собственным векторам можно дойти
до PCA, причем достаточно быстро. Ну, что ж. И также стоит сказать про линейной модели, что это
крайне важная штуковина по двум причинам. Первая. Наверное, в доброй половине задач,
которые решается машинным обучением, вам достачена линейная модель. Вот серьезно. Вам не нужны
Uber, Neuron, огромные бустинги и так далее. Вы берете линейную модель, вставляете ее, она быстрая,
устойченная, интерпретируемая, легко реализуется, короче, дешевая, сплошные плюсы. И дает хорошее
качество. Второе. Без понимания того, как работают линейные модели, понять, как работают все эти
новомодные нейронки, ну, в принципе, нельзя. То, что нейронки — это такие линейные модели на
стероидах. В них понапихали нелинейные функции активации, придумали какие-то, скажем так,
обоснованные некоторыми свойствами наших данных и какими-то мыслями о симметрии в наших данных
преобразованиях. Например, свертки — это, по сути, тоже в некотором смысле линейное преобразование,
его можно так представить и так далее. Поэтому понимание линейных моделей — это вообще
кругольный, наверное, камень понимания двух третей всего машинного обучения. Поэтому,
пожалуйста, не пренебрегайте им. И начнем мы с линейной регрессии. Что такое линейная
регрессия? Это задача регрессии. В данном случае будем рассматривать одномерную, то есть мы просто
напросто предсказываем одну чиселку. Также есть векторная регрессия, линейная регрессия, где мы
предсказываем много чиселок. То есть мы отображаем наши признаки в одно число. По сути,
у нас есть датсет, пара x и y, x и y — наши объекты, y — целевые переменные, y приходят из R. Если у нас,
в общем, в случае это будет векторная регрессия, то из R, как из RK, где RK — это какая-то камерная
векторная штуковина. И, соответственно, наша задача — найти некоторую линейную комбинацию наших
признаков, найти наши признаки, чтобы получить ответ. Ну или можно записать вот в таком виде
ω0, это наш свободный член, плюс взвешенная сумма всех x, xкатый — это именно катый признак,
не ката-объект на всякий случай, но ωk, где у нас всего p признаков. Или что то же самое,
так как математики, народ, скажем так, который любит писать все коротко и понятно, очень часто
переписывают вот в таком формате. xу, скажем так, виртуально добавляют вот нашему, каждому признаку,
каждому объекту добавляют пективный признак на первое место, который всегда равен единиц.
Ну тогда у нас, соответственно, вектор x — это 1, а потом x1, 2, 3, та-та-та. Зачем это надо? Ну,
потому что тогда мы можем с вами записать экспонированная ω, вот наша с вами линейная
модель. Не надо никого в плюс b и так далее, все максимально красиво, понятно записано. Хорошо?
Но еще раз обращай внимание, это чисто для удобства записи, потому что, когда мы начнем
говорить про регуляризацию, вот здесь объявится большая проблема, и об нее можно споткнуться.
ω — наш вектор весов, ω0 — свободный член, соответственно, он может его в себя включить,
или же мы можем просто добавить со всей матрицы объект-признак, столбец из единичек, и тогда у
нас только будет ω-вектор весов, где ω0 — это краски свободных членов. С ним вроде все понятно.
И задача оптимизации, которую мы решаем, это минимизация какого-то функционала, например,
функции ошибки, например, средней квадратичной, где у нас есть наши y и есть наша оценка y,
то есть предсказание нашей модели. Мы можем с вами минимизировать средние квадратичные
отклонения, можем минимизировать средние абсолютные, можете придумать там какую-нибудь
квантильную функцию, что придумаете, то и будет, и это от вас зависит. На всякий случай. Вот это
конкретная постановка задачи МНК методом на меньше квадратов она решается. Тут вопросы есть,
все понятно? 3, 2, 1, хорошо. Ну и, соответственно, с этой задачей можно работать максимально
почему? Потому что это один из единственных случаев, где в машинном обучении у нас есть
аналитическое решение. Не какая-то там попытка аппроксимировать непонятно что, непонятно как
градиатными методами, а просто получить аналитическое решение. На всякий случай вот этот вывод тоже
хорошо бы уметь делать, потому что, во-первых, хорошо бы уметь матрички дифференцировать, во-вторых,
на экзамене тоже спросим. Смотрите, вот наша функция, наш функционал, средней квадратичной
ошибки, правильно? Ну или, как вы еще можете назвать, наша функция эмпирического риска может
быть записана таким образом. Это квадрат отклонений, правильно? Ну или что то же самое,
мы пытаемся посчитать вектор отклонений и посчитать квадрат его второй нормы. Согласны? Тогда можем
это переписать в каком виде? Собственно, как мы с вами на прошлой неделе разбирали, y-xω транспонированный
на y-xω. Или что же самое, вторая норма вектора отклонений в квадрате. Почему, кстати, в квадрате,
как вы думаете, почему бы это еще под квадратный корень не засунуть? Да, так проще считать. А решение
задачи оптимизации поменяется, если под корень засунем? Нет, все это понимают. Все помнят, что корень
у нас, как бы, какая величина функция точнее, а везде монотонная. Молодцы, на области определения.
Потому что, если вы будете корень от отрицательного числа доставать, то бескомплексная плоскость
как-то будет печальна. Хорошо. Все, соответственно, вот наш x. На всякий случай здесь сектами абсолютно
все равно, или у нас не свободная члена, или мы сюда вот включили наш столбец из единичек,
поэтому у нас свободный член сидит в матрице весов. Пока все нормально. Ну и замечательно то,
что мы с вами знаем, что в точке у оптима у нас производная равна нулю. Вообще говоря,
квадратичная функция потерь парабол у нас выпуклая. Правильно? Минимум там один. Поэтому мы с
вами можем найти решение для данного, для данной оптимизационной задачи. Приравниваем нулю, знаем,
что у нас там минимум равна нулю, и получается простенький вывод, что омега это x транспонировано x
минус 1, x транспонировано y. На всякий случай еще раз проверьте себя вот сейчас визуально,
какие размерности должны быть у x и у y. Вот я поэтому и говорю, сейчас, пожалуйста, внимательно
проверьте размерности. Давайте вот сейчас все 10 секунд подумать, я пока горло смочу. А потом,
соответственно, мы с вами скажем, что да как. Нет, размерность в смысле матрицы. Вот матрица
x у нас в какой размерности? Матрица y и матрица омега, соответственно, которую мы проравниваем. Это
просто, чтобы вы в уме это все проверили и поняли, что здесь нигде ошибки нет. Потому что, когда вы
начнете это руками вводить, у третьей, наверное, появятся проблемы с тем, что краски и ничего не
сходится. Да? Ну, смотрите, здесь как раз-таки вот вопрос, если она выраженная. Вопрос. Пока считаем,
что x транспонирован на y, не выраженная, все в порядке. Ну, давайте, хорошо. Собственно,
матрица x, какая у нее сейчас здесь размерности? Ну, что такое m, что такое n? Объектов? А p,
количество признаков. Хорошо, тогда это у нас n на p, тогда x транспонирован на x, размерность какая
будет? p на p. Все согласны? Эта матрица вам, кстати, ничего не напоминает? Ну, вопрос к тем, кто статистику
изучал. Хорошо, тогда потом про это. Хорошо, предполагаем, что она у нас не выраженная, мы ее можем
обратить. Потом опять x транспонирован на y, p на p, на p на n. Правильно? То есть, здесь получается p на n
итоговая матрица. А y у нас в какой размерности? y это наша целевые переменные. По сути, это матрица
n на 1. Получается, размерность какая остается? p на n на n на 1. Вот наш вектор весов получился.
Все правильно, все сошлось, ничего не перепутали. Я почему на это обращаю внимание, когда это начнете
в коде писать, а вы начнете это в коде писать, это будет во второй домашке, можно перепутать
матрицу, допустим, и транспонировать, тогда размерность матрицы весов окажется какая-то
неправильная и так далее. И плюс, собственно, ваш вопрос, а что делать, если у нас свободный
член добавился? А нам вообще все равно у нас размерность y зависит от размера обучающей выборки.
Размерность x это p на n, n на p точнее, где n это количество объектов, а p количество признаков
с фиктивным, без фиктивного. Вы можете туда хоть еще 10 добавить, он все равно склопится. Уловили?
Все поняли. И заметьте, мы с вами получили аналитическое решение для задачи линейной
регрессии со средней квадратической функцией потерь. Все, вот оно у нас есть, на самом деле,
можете его запомнить. Просто полезно его помнить, чтобы резко кому-нибудь ответить на собеседование,
вам скажут, ух ты, классно. Вывести тоже можно за 20 секунд, так что выводить тоже полезно.
Но, собственно, вопрос на экране. А что делать, если матрица x транспонирована x выраженная? Что
такое выраженная матрица? Все помнят, я надеюсь. Правильно? Обратить мы ее не можем, если она прям
выраженная, но, на самом деле, даже если она плохо обусловленная, то есть ее детерминат близок к
нулю, то у нас с обращением будут большие проблемы. Потому что, если на детерминат близок к нулю,
то, когда мы с вами будем пытаться посчитать обратную матрицу, нам придется делить на
определитель, это деление на очень маленькое число, это увеличение вычислительной ошибки и так далее,
так далее, так далее. С этим все понятно. Хорошо, что делать? А главное, ладно, что делать, я вам скажу,
а в каком случае это может возникнуть? Так, линии независимых элементов. Хорошо.
Признаков или объектов? Ну вот, признаков или объектов повторяющихся? То есть, у нас, на самом
деле, система, как правило, переопределенная, если все хорошо, то есть, у нас больше объектов,
чем признаков, то есть, у нас больше ограничений, чем наших свободных переменных. На самом деле,
ответ правильный. Если наши признаки линией независимые, то вот в этой матрице появится,
опять же, линия независимости X transponable X. Вы посмотрите, как она получается. Когда мы с вами
считаем X transponable X, по сути что? Мы берем и, по сути, transponable X, мы говорим, вот этот признак
равен вот таким величинам у этих объектов, правильно? И другой признак равен таким-то
величинам у этих объектов. Если у нас два признака, ну для простоты, например, одинаковые или они
пропорциональны друг к другу, то получается, что для всех объектов признак 1 будет равен 0,4,2,7,5,
а признак 2, который с ним линией независим, например, будет ровно всегда в два раза больше.
Согласны? Соответственно, мы умножаем эти строки сами на себя, и получается что? Что у нас,
как раз таки, два признака линии независимые, у нас получается матрица выраженная, потому что
у нее теперь строки, ну или столбцы, потому что она, вообще говоря, квадратная линия независимая,
и у нас проблем с этим. Обратить мы ее не можем. Тобственно, когда у нас появляются с вами
зависимые признаки, мы не можем найти решения. Но тут, на самом деле, на это можно посмотреть
и с точки зрения просто физического смысла. Смотрите, предположим, у нас с вами есть два
признака, которые зависимы друг с другом, например, для самого выраженного случая, но просто с ним
проще, мне не надо в уме какие-то преобразования делать. Представим себе, что у нас в выборке два
признака, вес 1 и вес 2. Это абсолютно один и тот же признак. Окей? И мы, на самом деле, знаем,
что вес человека влияет на солевую переменную, допустим, с коэффициентом 5. Вот омега для веса,
где она тут, вот здесь, будет равна 5. Но у нас с вами два раза вес присутствует. Значит, соответственно,
первый элемент и второй элемент веса суммарно должны делать склад равной 5. Согласны? Но потому
что первая половинка делает там вклад какой-то, вторая кое-то, вместе они влияют как 5, потому что
вес-то один, просто он почему-то был продублирован. А теперь внимание, проблема. Если я возьму веса,
да, веса, параметр значения, омега 1 для веса 1 будет равно 10, а омега 2 для веса 2 будет равно
минус 5, в сумме у них что получится? 5, 6 и минус 1, 7 и минус 2. У вас получается континуальное
множество решений, у вас континум решений, вы можете любую пару чисел, которые в сумме дают вам
5, взять и получить абсолютно тот же самый ответ. Так что то, что мы здесь не можем на самом деле
найти аналитическое решение, а у нас оно в любом случае не единственное. Так что это на самом деле
нормально и физическая обоснованность тоже имеет. Улавливаете пока? То есть линейные зависимые
признаки аналитической решения мы найти не можем, плюс мы не можем найти единственное решение, в принципе,
его не существует. Классный вопрос и классное предложение, если признаки линейных зависимых,
их можно выкинуть. Если мы об этом знаем, конечно надо выкинуть. Но проблема в том,
что я вам привел пример совсем игрушечный, а на практике нам абсолютно неважно, у нас
линейная зависимость, два признака равно друг другу или признак номер 328 это линейная комбинация
предыдущих 327. Плюс у нас есть шум, плюс признаков может быть там 10 тысяч. Так что найти
какие из них линейные зависимые друг с другом может быть большой большой проблемой. Просто
дорого и мы просто мы не можем этого явно увидеть. Поэтому выкинуть в общем случае нам
плузновато. Окей, с этой проблемой разобрались? Ну что ж, давайте тогда пытаться это чинить.
Вы имеете для одного и того же признаков описание два разных ответа? Ну окей.
Ну как бывает. Например, есть понятие выброса, где у вас для нормального объекта абсолютно
неправильный ответ, например. Или у объекта в принципе неправильные признаки описания.
С этим придется работать, так как мы если мы не можем их отфильтровать, значит придется
строить такие модели, которые устойчивы к наличию выбросов. Правильно тоже поговорим. То есть в
общем случае, смотрите, когда мы решаем с вами оптимизационную задачу, вот методом оптимизации
в принципе оптимизируем функционалу абсолютно по барабану, что у нас там с данными. Грязное,
нечистое. Мы засунули на вход выборку, по сути мы засунули систему линейных уравнений,
ответов по сути ограничения мы дали. Оно нашло ответ. Всё. Так что если у нас плохие данные,
это наши с вами проблемы. Мы с этим будем жить. На самом деле принцип, его обычно по-английски
называют garbage in, garbage out, он работает почти везде. Если у вас плохие данные,
у вас могут быть хоть идеальные модели, у вас будет плохое предсказание. Так что нам придется
как-то чистить данные, строить более устойчивые модели и вообще оценивать, насколько плохие у
нас данные. Ответил наш вопрос? Супер. Ладно, матрица может быть выраженной. Давайте я вам на примере
как раз покажу. Вот собственно ситуация, где у нас два признака или там несколько признаков, короче,
зависимые между собой, в простейшем случае два признака линейне зависимы. Матрица x и x соответственно
выраженная. Вот у нас есть истинное значение ω true, мы с вами на семинаре сегодня ровно проделаем,
это оттуда скриншоты. Допустим вот 268, минус 0.52, минус 1.12. Второй и третий признаки между
собой зависимы, то есть это почти один и тот же признак источницы, дам до какого-то маленького-маленького
шума. То есть мы все еще можем обратить матрицу x и x, но ошибка у нас большая. Вот аналитическое
решение, которое мы получаем буквально формулой за пистом. x и x минус 1 и x и y и так далее. Смотрите,
первый член абсолютно правильно определен, с точностью до того, что у нас присутствует небольшой
шум данных, то есть 268, два знака после запятой правильно. Второй и третий член, минус 186, 184,
ровно то, о чем я вам говорил. Но обратите внимание, сложите второй и третий признаки,
ну веса точнее их. Получится примерно минус 0.6, минус 1.6, согласны? Здесь сложите. Получится
то же самое. У нас одно ограничение, потому что у нас по сути признак один, но он дважды
продублирован. У нас одно ограничение, поэтому на их сумму у нас ограничение есть. На каждой
подельности у нас ограничений нет, у нас любая комбинация может этому быть равна. Ну, собственно,
возникает вопрос, а что с этим делать? Там уже маленький спойлер был, где-то полсекунды.
Что делать, если мы с вами не можем эту матрицу обратить? Что делать с матрицей, если она не
обратима? Пошуметь? Классно, зашуметь. Мы с вами зашумели матрицу, но мы с вами при этом потеряли
достаточно много информации из-за этого, потому что мы шум добавили прямо явно туда. А чем больше
у нас, грубо говоря, чтобы у нас матрица была точно не выраженная, шум должен быть достаточно
большой. Потому что если у нас шум будет крайне маленький, то он мало повлияет на определитель,
и соответственно у вас матрица все еще будет очень близка к выраженной. Что еще можно сделать?
Убрать скоррелированные признаки можно, но если мы их знаем. Если у нас там 10 тысяч признаков
и у них зависимости крайне сложные, то сложновато их убрать. Что еще можно сделать?
Классный вопрос. А в чем вообще беда? У нас получилось два признака, они в сумме дают что-то
там правильное. Они же все равно правильную сумму-то дают. А ответ на самом деле простой. У нас данные на
самом деле всегда содержат в себе шум. И, во-первых, у нас вот эти параметры конкретно, значения
параметров подобраны под шум в обучающей выборке. И, как правило, очень часто у нас будут получаться
значения, которые почти противоположны друг другу. Потому что они как раз подстраиваются под шум,
характерное значение шума маленькое относительно признаков, поэтому пытаются настроиться именно
на шум, поэтому эти значения большие. Но на новых данных, которых мы не видели на этапе обучения,
шум будет другой. Потому что он случайный, он каждый раз случайно генерируется. И у нас может
казаться, что вот на этот признак условно прилетело значение шума 0.1, а вот на это не прилетело. И у
вас целевая переменная завышена на 186,0 на 10. Потому что мы вот за счет вот этих вот
величин начинаем переобучаться под обучающую выборку. Потому что у нас два параметра для того,
чтобы запомнить только одно значение. Соответственно у нас по сути один параметр есть, чтобы запомнить
что-то специфичное только обучающей выборке. Абсолютное значение не надо уменьшить. Классное
замечание. Собственно, мы к нему сейчас придем. Коллеги, смотрите, на это очень полезно смотреть,
и я неспроста вот так медленно это все разжевываю. Я хочу, чтобы вы до этого прямо сами додумались,
а не просто я вам это сказал. Мы с вами изначально сказали, у нас проблем в чем? У нас с вами решений,
множество, вообще континуум. У нас не единственное решение, правильно? Если у нас не единственное
решение, вы бы хотели все-таки одно решение как-то получить. Согласны? Решать другую задачу. Классно.
Какую? Смещенную. Ну классно, вы понимаете о чем речь. Супер. Давайте тогда наложим какое-то
дополнительное ограничение на наш вектор весов. Вот тут было классное предложение. Раз у нас
присутствует шум, шум случайный, особенно на тестовых данных, тогда давайте потребуем, чтобы,
например, этот вектор был наименьший по какой-нибудь норме. Ну, например, тогда если у вектора маленькая
норма, значит у него все члены тоже маленькие. Согласны? Но норма это все равно, если ограничиваем
норму, ограничим значение членов. Я с этим согласен. Можно это посмотреть, на самом деле, с другой
стороны. Можно посмотреть вот на эту матрицу. На самом деле, как из выраженной матрицы сделать
невыраженную. Вот проще, чем зашумить. Мысль более детерминирована. Ну, например, прибавить
единичную. Она явно диагональная, тогда у нас получится явно невыраженная матрица. Заметьте,
эта матрица квадратная всегда. Согласны? Так что, если мы добавим к ней диагональную матрицу,
то мы получим невыраженную матрицу. На самом деле, то, что мы сказали, это плюс-минус одно и то же,
и это, по сути, называется регуляризация по-тихнему. Мы можем с вами всегда добавить единичную матрицу,
ну, домноженную коэффициент лямбда. И на самом деле, тогда вот эта матричка у нас явно будет
невыраженная. Ее всегда можно обратить. Согласны? И это у нас будет решением вот такой задачи
оптимизации. Вот этот вывод мы вас сейчас попросим сделать самостоятельно. Это можно вывести на
семинаре, но практика, он отличается от этого на две строчки, поэтому я вас прошу сделать
самостоятельно. Окей? Можете считать частью домашней. Собственно, вот наш функционал,
и теперь мы помимо средней квадратической ошибки минимизируем вторую норму вектора весов в квадрате
с коэффициентом лямбда. Вот, что такое лямбда? Лямбда, по сути, это гиперпараметр, который говорит
нам, насколько важно для нас, чтобы норма вектора весов была маленькая. То, что мы теперь, по сути,
два функционала минимизируем. У нас вот этот функционал хочет лямбду как можно более подходящей,
чтобы ошибка на выборке обучающей была минимальной. А этот функционал говорит, что не, слушай,
давай-ка Омега у нас будет как можно меньше, потому что иначе штраф большой. По сути, мы пытаемся
с вами решить две задачи, которые в разные стороны нас на самом деле тянут. Но здесь на самом деле есть
еще один большой плюс. Если у нас ситуация невыраженная и все хорошо, то у нас вот эта задача имеет
единственное решение. Все прекрасно. Если у нас решение здесь не единственное, у нас вот эта задача
минимизации все равно имеет единственное решение. То есть среди всего континуума значений, которые
заставляют одинаковые значения функций потерь, только одна пара даст нам, не одна пара, одно
подможество значений весов даст нам минимальное значение функции ошибки. Но почему? Что такое вторая
норма квадрата? Это сумма квадрата. Это выпуклый функционал. Согласны? Согласны.
Тишина. У пара был один минимум. Точно?
Ну короче, мы делаем задачу выпуклой, грубо говоря, за счет этой регуляризации. И собственно отсюда и
появляется вообще у нас в курсе термин регуляризация. На самом деле регуляризацию называют, опять же,
от английского языка regularize, ограничивать. Мы по сути дополняем нашу задачу некоторыми ограничениями,
потому что мы не можем решить исходную задачу единственным образом или таким образом, чтобы это
удовлетворяло нашим интересам. Мы не знаем, какое именно решение выбрать, поэтому мы дополнительное
ограничение кладем. Например, накладываем, чтобы у нас норма вектора весов была минимальна, тогда
решение единственное, плюс мы уже знаем, какие свойства ожидать от нормы нашего вектора весов.
И от вектора весов соответственно. Смотрите, почему такая функция потерь? Ровно потому, что у нас
просто по сути добавляется вторая норма вектора весов. Что второй нормой вторая норма вектора весов,
а лямбда это просто коэффициент, в котором мы ее вкладываем. По сути это коэффициент регуляризации.
Чем больше лямбда? Ну, предположим, мы лямбду стремили в бесконечность. Там где-то вот она очень
большое число. Тогда для решения задачи оптимизации, какое решение будет оптимальным? Ну, примерно да,
нулевые веса, потому что у нас клад вот этого члена будет много больше, чем вклад вот этого члена.
Если лямбда близка к нулю, то какое решение оптимально? То, которое позволяет переобучиться под
этот функционал. Лямбда это просто наш, грубо говоря, регулятор, насколько важно нам получить
невыраженное решение. Это схема работает всегда, потому что если вы к невыраженной матрице добавить
диагонально, она выраженной не станет. О, кстати, кстати, кстати, кстати, кстати, вот тут квадрат не хватает.
Ну, в смысле, лямбда должна быть положительная. В такой формулировке, вот, прошу прощения,
с опечатком. Ну, тут или ограничение, что лямбда больше или равна нулю, или соответственно здесь
надо везде квадрат писать, окей, чтобы вас не запутать.
Не, смотрите, мы реальное значение с вами уже никогда не узнаем почему,
потому что если у нас с вами два признака, грубо говоря, дублируют друг друга, то вот у вас 2,
вес 1, вес 2. Вы только знаете, что вклад вес 1 и вес 2 вместе равен 1. Нет никакого
правильного значения признака веса для веса 1 и вес 2. Поэтому мы с вами собственно и разрешаем
эту неопределенность, говоря, окей, выберем тот, который доставляет на меньшую норму векторовесов.
Если лямбда больше или равна нуля, матрица не станет выраженной. Почему?
Смотрите, что у нас здесь стоит? X транспонированное x. На диагонали что стоит?
Что? Это что вообще? X транспонированное x, что задается в точке верения там аналита или налог?
Вам слово квадратичная форма что-нибудь говорит? Ну, смотрите, у нас собственно здесь на диагонали
будут стоять квадраты х. Мы к ним добавляем строг не отрицательную диагональ все остальной нули.
Невыраженная она будет. Так, хорошо. Собственно, еще раз повторяю. Какую? Смотрите, тут можно зайти
с двух сторон, собственно они на самом деле эквивалентны. Мы можем сказать, эта матрица
выраженная, сделаем ее невыраженной как? Добавим к ней диагональную матрицу. Ну, например, лямбда,
опять же, здесь лямбда не отрицательная, здесь тогда квадрат по-хорошему надо добавить, это опечатка.
Тогда матрица невыраженная. Но это эквивалентное решение вот такой задачи. На самом деле я не уверен,
как было изначально, то есть можно просто добавить ограничение на нашу норму векторовесов и получится,
что есть аналитическое решение, которое ровно такой формат имеет. То есть с двух сторон приходим к
одному и тому же. Вот. Ладно. И почему это называется еще раз регуляризация? Ограничение,
которое мы наложили. На всякий случай, вот эта вот норма вторая вектора версов, это далеко не единственный
способ регуляризации, мы с вами их десятки увидим. Можно ограничивать количество признаков модели,
можно ограничивать ее структуру в нейронках, глубину дерева в деревьях, другую норму взять,
что угодно. Любое ваше априорное предположение, которое вы накладываете на решение задачи, это
ваше ограничение, ваше регуляризация. И с регуляризацией, как и со всеми предположениями,
работает какое правило? Если у вас хорошее предположение, которое подходит под решение
для задачи, вы получаете хороший результат. Если ваши решения противоречат задачи, то от них
станет хуже. Поэтому нет такого правила, что с регуляризацией всегда лучше. Окей? Да. Лямду
выбирать из соображений того, что у вас есть... Это гиперпараметры, гиперпараметры, как правило,
подбираются на кросс-валидации. Про кросс-валидацию мы в конце лекции как раз поговорим. То есть гиперпараметры
мы не можем автоматически подобрать, мы их выбираем, например, по качеству поведения нашей модели на
валидирующей выборке, то есть на отложенной выборке. Хорошо, еще вопросы тут есть? Окей,
я тогда сразу маленький спойлер делаю. Я думаю, многим из вас очевидно, что вторая норма, это далеко
не единственная норма, которая здесь может стоять. Согласны? С второй нормой есть только одно
важное замечание. Для второй нормы у нас есть аналитическое решение, что с регуляризацией,
что без регуляризации. Это, наверное, единственный случай, где в линейной регрессии есть аналитическое
решение. Вы можете сюда первую норму подставить, решаться это будет, но только градиентным методами
аналитического решения уже не будет. И вторая важная вещь про вторую норму. Теориям Гаусс Маркова.
Теория Гаусс Маркова дает нам очень важные гарантии, на самом деле, и это та причина,
почему среднюю квадратичную ошибку вообще любят, в том числе. Вот у нас есть наша целевая
переменная. Заметьте, это уже не наша оценка, это вот наше предположение, что есть целевая
переменная, которая зависит от икса линейным образом, но в наличии также какой-то шум. Идет?
Все согласны. Так, на всякий случай, а кто вообще знает теорию Гаусс Маркова? Никто. Классно. Не,
ладно, бывает. Поэтому мы ее разбираем. Еще раз, ε это у нас случайно величины, это наш шум.
В данных присутствует шум. Всем окей это, правильно? Наше предположение, во-первых, эти у нас
величины независимы, на самом деле, в идеальном случае, когда мы хотим. То есть в идеале наш
шум должен быть независимый. Почему? Потому что если наш шум зависимый, то, в смысле, у нас
переменная как-то там зависит от иксов, например, то что-то это на шум не похоже, на самом деле. Но
теория Гаусс Маркова делает на самом деле три очень маленьких и простых предположения. Во-
первых, у нас шум не смещенный, то есть мат ожидания каждого ε равно нулю, то есть мы можем как
завысить наше предсказание, так и занизить. Хорошо? Целевой пример. Во-вторых, у нас есть какая-то
дисперсия, которая конечна, то есть у нас нету случайных величин здесь, которые имеют бесконечную
дисперсию. Мы не можем получить, как бы, с какой-то значимой вероятностью там отклонения в десятки
миллионов. Да? Да, конечно. Хорошо. И третье, собственно, у нас для всех и не равно 0, ковриация между
ними равна нулю. Шутка ковриации все помнят? Хорошо. Вар дисперсия варианс. Ну можно еще написать вот
такую д, но лотех в ней не умеет. Поэтому написано вот так. Вот, три условия. Все условия понятны, правильно?
Еще раз, у нас все ошибки не смещенные относительно нуля, у нас есть конечная дисперсия и ковриация
наших ошибок равна нулю. Да, в данном случае давайте будем считать, что просто фиксированная дисперсия,
окей? Которая конечная, главное. На самом деле можно пойти на какие-то обобщения, чтобы даже
были разные дисперсии, лишь бы они были все конечные, но пока вот просто равно сигн. Хорошо.
И, собственно, в этих предположениях вот это решение, которое мы с вами только что видели,
омега транспанированная х, у х транспанированной х-1, у х транспанированной у, то есть решение
задачи на меньше квадратов является оптимальным среди несмещенных. Говоря по-русски или по-английски,
best linear unbiased estimator. Наилучшей среди несмещенных. Вопрос, собственно, такой. Во-первых,
что значит несмещенных? Без лямбда. Хорошо, а на практике что значит? В мат ожидании кого?
Бинго. Наша оценка является несмещенной, у нас же омега с крышкой, что будет? Она же у нас зависит
от каких-то случайных величин, правильно? Вот у нас тэпсилоны сидят, так что это, по сути,
тоже случайная величина. Мат ожидания омеги с крышкой равно омеги. Это значит, что наша
оценка несмещенная. Вот, это решение заставляет нам несмещенную оценку. Это раз. Просто обращаю
ваше внимание, потому что иногда начинают говорить, что у нас несмещенная оценка у. Тоже вариант,
но в данном случае теорема гласит именно обоим. На что значит все это наилучшее?
Ладно, что такое линейное, понятно? А что про эффективную говорили? Окей, что такое эффективная
оценка? Да, на самом деле. Можете еще рассказать? Опять же, наименьшую дисперсию имеет кто? Бинго.
Смотрите, наилучшая или оптимальна в средине смещенная. Омега с крышкой, во-первых, несмещенная,
то есть мат ожидания омеги, равно омега с крышкой. И у нее наименьшая дисперсия, опять же, у омеги с
крышкой. Не у какой-то там ошибки, у чего-то. Окей? Собственно, у нас есть гарантия. Эта теорема,
на самом деле, оказывается в три строчки. Можем доказать или на семинаре, или сделаю самостоятельно.
Опять же, на лекцию я стараюсь доказательств теорем не вытаскивать. Это решение у нас является
оптимальным в средине смещенных. Окей? Не, как раз-таки мы-то на практике с вами не знаем реальное
значение, но мы с вами знаем выборку. У нас есть выборка. И мы можем получить оценку наших параметров
на основании выборки. Вот, с такими предположениями, тремя, оценка, которую мы получаем вот отсюда,
будет оптимальна средина смещения. Вот как раз-таки это очень хороший вопрос. Здесь мы предполагаем,
конечно, что она обратима. Если она не обратима, то мы это просто посчитать не можем. И вторая
проблема, если она, скажем так, обратима, но почти выражена, тут возникает другая проблема,
что у нас вычислительная точность наших машин конечна. Поэтому чем ближе она к сингулярной,
тем больше у нас здесь будет вычислительная ошибка. То есть это, конечно, работа, когда мы можем
посчитать омегу. Если у нас матрица выраженная, то у нас вообще не существует такой оценки,
потому что она не единственная. Окей? Хорошо. Ну и теперь, собственно, пара замечаний. Смотрите,
возвращаемся назад. Вот у нас с вами минимизация среднего третичной ошибки. Задача линейной
регрессии. Теория Магауса Маркова работает? Предположение о тех свойствах шумов наших данных.
Ещё раз. Минимизируем вот эту функцию ошибки. Теория Магауса Маркова работает,
если эти три предположения выполняются? Да, классно. Минимизируем вот такую, вот
такой функциональный амперический риск. Теория Магауса Маркова работает? Почему? Ага, классно.
А решение у нас какое? Бинго. Ребят, ещё раз. Теория Магауса Маркова гласит, что вот это решение
является оптимальным решением для задачи на меньше квадратов. То есть для минимизации среднего
третичной функции ошибки только. Всё. Если вы добавляете вот сюда любую другую функцию,
любой другой функционал, если у вас не прост среднего третичной ошибка, у вас уже посылка
теоремы неправильно. Вы не задачи на меньше квадратов рассматриваете. Поэтому теорема Магауса
Маркова работает тогда только, когда у вас минимизируется среднего третичной функции ошибки.
В данном случае у вас уже появился второй член, и здесь на самом деле можно увидеть ещё одну вещь.
У вас оценка будет априори смещенной. Почему? Потому что для минимизации среднего третичной
функции ошибки вы явно не хотите минимизировать норму вектора весов. У нас добавление регуляризации
как правило даёт нам смещенное решение, потому что теперь относительно изначального оптимума
нашего функционала мы ищем другой оптимум, который обладает заданными нами свойствами.
Нет. А как? Мы с вами сделали по сути что? У нас была изначальная оптимизационная задача. Мы
сказали, что мы не можем её решить либо технически, либо у неё не единственное решение. Мы придумали
по сути как поставить новую оптимизационную задачу. Вот она теперь, вот её мы решаем. И
собственно для этой оптимизационной задачи найти решение. Вот её мы решили. Мы не решали другую
оптимизационную задачу. Мы не знаем какое у неё решение. У нас нет обратного хода. Мы решили ту
задачу, которую мы поставили. Да? Да. Там В с крышкой был набор случайных величин в кеории, так как у вас
Х то в общем случае это всегда реализация, как и Y реализация случайной величины. Вы получили
точно так же оценку. Это набор чисел. Конечно. Смотрите, вы собственно и получаете на самом деле,
собственно когда вы средний квадрат ошибки минимизируете, вы считаете в краске мат ожидания
вот этой величины. Всё правильно. Вот. Добавляя по одному признаку. Да, смотрите, вы предлагаете
замечательный комментарий. Собственно, коллега ваш предложил отфильтровать признаки, то есть отобрать
только те, которые образуют некоторые линии независимые под выборку. Да, так можно делать.
Такие подходы тоже есть отбора признаков, итеративные. Минус в том, что когда у нас опять же очень много
признаков, например там десятки тысяч, это очень дорого вычислительно. Вам для каждого надо всё
равно тогда решить оптимизационную задачу. Причем для каждого под множество выбрать оптимальный,
повторить, это просто дорого. Вот. Собственно, а с регуляризацией плюс в чём? Да, мы получаем
смещённое решение. Но, во-первых, у нас от лямбда зависит, собственно, насколько сильно оно будет
смещённым. Чем меньше лямбда, тем меньше у нас смещение. Во-вторых, решение вы всё равно получаете,
которое обладает заданными вами свойствами. Даже если там есть краски зависимые признаки,
вы точно знаете, что их суммарный вес будет ближе к оптимальному, а каждый вес подельности будет
вообще минимально из возможных. То, что начав в квадрате, он сразу будет выше. Вот и всё. Так,
понятно? Ещё раз, что такое оптимальная средина смещённых, понятно? Обладает наименьшей дисперсией.
То есть любую другую оценку вашей матрицы весов вы можете сделать, но дисперсия вот этой
случайной величины это случайный вектор, потому что он зависит от случайных величин. У неё дисперсия
будет выше. Настолько, насколько подходит линейный модель для вашей задачи. То есть если вы
пытаетесь, условно, параболу линейной моделью описать, то у вас в принципе не очень подходящий
класс моделей используется для решения задач. Ещё раз, это теоретический результат. То есть это
обосновывает нам, что в хорошем признаковом описании у нас решение задач наименьших квадратов
обладает хорошими свойствами, что это оптимальная оценка средней смещённых. Всё. Нет, смотрите, вот,
речь только про линейные модели. Всё, вот изначальная постановка. Если у нас зависимость не линейной
модели, не линейной, никаких опять же договорённостей у нас нет, у нас условия теремы не выполняются.
Вот. Хорошо. Да. И да, и нет. Смотрите, ещё раз. А теперь, собственно, когда брать какую норму.
Давайте сейчас покажу, что бывает, например, первая норма, что вы понимаете и сами, но какие у неё
есть свойства. Но, во-вторых, норм можно брать раз. Собственно, здесь мы подходим с вами опять к
очень важным факту. Так, вам видно там справа? Я не сгораживаю. Смотрите, если модель смещённая,
значит она решает не ту задачу, которая у вас, вот, тогда она решает, например, не минимизацию,
как бы, той функции ошибки. Короче, если у вас модель смещённая, значит она не минимизирует
чистой функции ошибки. Что такое? Давайте я ещё пару тогда этих терминов веду. Вот есть функция
ошибки. Её, на самом деле, очень часто путают в интернете друг с другом. Давайте называть так.
Функция ошибки — это именно вот ошибка предсказательной нашей модели. То есть, насколько мы ошибаемся,
предсказывая целевую величину, вот будет эта функция ошибки. Хорошо? Вот всё вместе можно назвать там,
например, функционал имперического риска. Потому что это ошибка плюс какая-то регулиризация. Это
ровно тот функционал, который мы с вами минимизируем. Не смещённая у нас оценка тогда, когда минимизируем
чистую ошибку. Если мы минимизируем что-то там ещё, то к правилам получаем смещённую, потому что на
этом можно на самом деле посмотреть абсолютно банально со второй стороны. Смотрите. Вот у вас раз функционал,
два функционал, да? Те же помнят, что градиент можно посчитать. И мы на самом деле сейчас про это
говорим, можем градиентными методами найти оптимальное значение матрицы Омега, ну или вектор Омега
в данном случае. У вас градиент, производная сумма чему равна? В сумме производных. Поэтому у вас
для Омеги будет отсюда идти градиент, который тянет её в сторону оптимальной оценки краски. И отсюда
будет идти градиент, который тянет её в ноль. Вот откуда у вас появляется смещение. У вас оценка
Омеги по сути съезжает в сторону вот этого градиента. Это совсем на пальцах, если.
Ну так это и есть то же самое. У вас то, что Омега с крышкой теперь тянется в сторону нуля,
это смещает её относительно мат ожидания. Потому что иначе бы она к краске была в мат ожиданиях,
которая вот эту штуку минимизирует. Окей, так на всякий случай это тогда тоже можно проделать
дополнительно. Так коллеги, давайте так. Вот что такое оценка максимального правдоподобия? Кто
помнит вообще знает? Понял, тогда про это можно прямо отдельно допсеминар провести собственно.
О чем речь? Мы с вами на самом деле, ну вот как раз, когда обсудите, мы здесь на семинаре тоже
можем обсудить. По сути, когда мы с вами минимизируем среднюю квадратичную ошибку,
мы по сути ищем оценку максимального правдоподобия для средней квадратичной ошибки.
Когда минимизируем среднюю квадратичную ошибку, мы ищем оценку максимального правдоподобия
в предположении, что у нас краски и ошибки нормально распределены. Вот и все. Эта краска будет средняя.
Нет, это на статистике прямо отдельно выводится где-то полсеминара. Я поэтому и говорю, кто знает,
мы это можем на допсеминаре провести, потому что сейчас у меня записи нет, я это буду изымал
вводить минут 20, наверное. Извините. Да? А, это да, сейчас я его потрогаю. Вот, хорошо. Собственно,
нормы у нас бывают разные. И возвращаясь к вопросу, а правильно ли, чтобы всегда брать вторую норму
и не выпендриваться? Вообще говоря, нет. Потому что выбор того функционала, который вы будете
минимизировать, опять же, зависит от вас. Это, на самом деле, одна из самых важных частей в любой
задаче машинного обучения. Не уметь там строить классные нейронки, деревья и так далее, ансамбли.
Умение правильно из неформальной задачи, ну, например, вон там научрук говорит, что надо сделать
то-то. Или на работе вам говорит, не знаю, там менеджер, надо сделать что-то другое. Короче, как это
обычно говорят, из бизнес задачи, ну или из научной задачи, сформулировать уже математическую
оптимационную задачу. Выбор функционала, который вы будете оптимизировать, это вообще краеугольный
камень. Потому что неправильно выбранный функционал, неправильно поставленная задача,
будет по-любому давать неправильное решение. Все, конец. Если вы неправильную задачу поставили,
вы не то получили. Собственно, поэтому функционал, который вы минимизируете,
должен исходить именно из того, что вы хотите получить. Вообще, я пока просто декларативно
скажу. Минимизация квадратичной ошибки дает нам среднее, минимизация абсолютной ошибки,
то есть, например, первой нормы, будет давать нам медиану. Как-то доказать краски можем с вами
сделать сегодня, например, после там семинара в конце. И, собственно, нормы бывают разные. На
практике, как правило, в дозаче регрессии применяют в основном две. Ну ладно, три. Первая — это
квадратичная ошибка, это, наверное, 70% всех случаев. Вторая — это средняя абсолютная ошибка,
или же их называют МСК и МАЕ, на том, что mean squared error, mean absolute error. МАЕ — это сумма
модулей отклонений, и, соответственно, для нее мы точно также можем все посчитать, но для нее нет
аналитического решения. Градиентная, хотя все еще присутствует. И, собственно, третья функция
ошибки, которую часто еще используют, это так называемая квантильная функция ошибки. Короче,
там у вас в зависимости от того, какой у вас квантиль важен, например, вам сильно важнее там
не завышать, чем не занижать, у вас может функция ошибки иметь какой-нибудь вид, типа вот такая
галочка, здесь она плавно, растется здесь быстро. Но все понимают, что у нас для модуля график, как
отклонения. Причем с углом 90 градусов. У вас угол, на самом деле, может быть другой. Такой
функция ошибки тоже можно подобрать, она иногда тоже подходит. Причем этот угол даже является
гиперпараметром, он там можно подбирать и так далее. Вот. Все. Вот у нас есть раз-два именно для
функций ошибок. Но также у нас есть регуляризация, которую точно также можно использовать со второй
нормой, с первой, с четвертой, если вам вдруг захотелось. На практике обычно используют. И так
далее. И на всякий случай, только вот этот случай МСЕ без регуляризации работает с теориями
Гаусса-Маркова. То, что он в условии теориями Гаусса-Маркова стоит. Мы решаем задачи на
меньше квадрат. Все. Линейная модель. Все остальное, как бы, это что-то там другое. Так что, если вы
добавили регуляризацию, вы добавили свои ограничения на задачу, но вы ушли от изначальной задачи
найти оптимальную оценку, чтобы минимизировать ошибку. Вы что-то другое уже решаете. Поэтому оценку
у вас априори совмещенная, вы другую задачу решаете. За это вы получаете какие-то хорошие
свойства. Например, она у вас более устойчивая. Устойчивые краски под устойчивостью будем
понимать следующее. Это такое, так сказать, определение. Оценку будем называть устойчивой,
если малое изменение обучающей выбраки приводит к малому изменению вектора параметров. То есть,
если условно мы на Эпсилон, грубо говоря, изменили выбраку, ну там шум чуть-чуть поменяли, у нас
матрица весов тоже поменялась не больше, чем на Эпсилон, например. Потому что, если у нас,
например, наша ситуация выраженная, наша матрица выраженная регуляризации нет, вы можете чуть-чуть
шум поменять, мы это с вами на семинаре опять же сделаем, здесь может оказаться 50-50, например.
Видите, шум там будет меняться на 10-1, 10-2, 10-2, а здесь будет меняться на 10-2. Вот, значит,
оценка неустойчивая. Поняли? Согласились? Ловили? Вопросы? Комментарии? Ну, собственно,
как это происходит? Во-первых, если у вас есть возможность на некоторых, на различных выбраках
ее посчитать, ну, например, у вас там есть две выбраки, вы можете посчитать оценку на первой
выбраке и на второй, если у вас какие-то признаки получать сильно разные веса, скорее всего у вас
оценка неустойчивая или у вас очень разные выбраки. То есть, надо или надо проверять распределение
у этих выборок по признакам или, значит, у вас оценка неустойчивая. Второе, если вы, сейчас мы
дойдем до градиентов краски, до градиентов меттов, если у вас для каких-то признаков градиенты, для весов
признаков градиенты здоровые и они постоянно туда-сюда меняются, это тоже проблема. Вот. Так, на всякий
случай, там звук работает, он не сел еще. Супер. Если он вдруг перестанет, вы, пожалуйста, это
голосуйте. Хорошо? Вот. Ну и, собственно, вот наши сравнения, наши параболы замечательные и наши
галки. На всякий случай, внимание, вопрос. А у нас же модуль, функция вроде как в нуле не дифференцируемая.
А что делать? Как мы вообще можем его оптимизировать? Да, то, что у вас вроде как эта функция не совсем
дифференцируемая, на практике нас абсолютно не волнует. Почему? У нас производная слева от нуля
минус один, производная справа от нуля один, производную в нуле доопределяем нулем и радуемся.
Если ошибка ноль, никакого градиента нам не надо. Все. Все счастливы, все работает. Соответственно,
MSE дает нам Blue Best Linear Ambiance Estimator, оптимально средний смещен к оценку, работает с теориями
Гаустамарковой, соответственно, дифференцируемо и она чувствительна к шуму. Потому что, если у
вас, например, шум достаточно большой, то есть у вас Y, это краски, истинный сигнал, плюс какой-то
шум. Чем больше у вас отклонения, парабола вам еще и в квадрат возведет это самое отклонение.
Ошибка будет большая. А чем больше ошибка, уже с точки зрения, например, градиентных методов,
вы давайте сюда внимательно посмотрим. Градиент у вас здесь слева будет что? Минус два х, а справа
2х. Согласны? Но если минус два модули х, а справа 2х. Вот. Короче, у вас х там присутствует.
То есть, чем больше у вас отклонения, тем больше у вас будет градиент, тем больше у вас каждый
объект будет влиять на решение. Она чувствительна к шуму поэтому. Моя, собственно, у нее что?
Отклонения слева дают нам градиент минус один, справа плюс один. Абсолютно все равно сильная
там ошибка, слабая. У нас просто не попали точно в цель. Поэтому она гораздо менее чувствительна
к шумам. Улавливаете почему, правильно? Все, классно. Тут всем тоже понятно. Что? Еще раз,
она не дифференцируема с точки зрения вот мотона. Нам не нужно, чтобы она была дифференцирована
всюду. Она дифференцируема на r+, то, что там всегда производная плюс один, на r-, а в нуле
просто определяем производную нулем и все. То, что у нее производная как бы не является гладкой
функцией, а нам не нужна гладкость. Нам надо, чтобы мы в каждой точке могли посчитать производную.
Мы можем. И, соответственно, с регуляризацией. С регуляризацией тоже любопытная вещь. Во-первых,
L2-регуляризация это тот случай, когда у нас есть аналитическое решение. Все замечательно. Она
дает нам более устойчивое решение, потому что у нас теперь есть единственный вектор,
который минимизирует норму вектора весов. Устойчивый, значит, при малом изменении нашей выборки
у нас будет мало изменения нашего вектора весов. А вот L1-регуляризация. Она не дифференцируема,
но нам опять же все равно абсолютно, потому что доопределяем в нуле нулем. То, что она не является
гладкой, нам это не требуется. Типа того, когда мы в функции ошибки добавляем норму вектора весов.
Можем взять вторую норму, можем взять первую норму. Все, собственно. Как вы понимаете, третью
норму брать немножко странновато, потому что она может быть отрицательной. Нам это вообще не надо.
Окей? Ой, простите, третью норму, господи, третью. Ладно, вы меня поняли. Да. В смысле,
с функции ошибки третьей степени не надо брать, я договорился. Да. Значение весов или значение параметров?
Да. Смотрите, я сейчас на ваш вопрос отвечу, как бы предполагаю. Так, смотрите, собственно, L2-регуляризация,
как вы понимаете, работает и с МСЕ, и с МОЕ, верно? Если бы и другой функции ошибки на самом деле.
Например, на следующей неделе мы поговорим про задачи классификации, там у нас будет
log-loss, логистическая функция потери. Туда точно также можно запекать вторую норму вектор весов,
ничего не поменять, все хорошо. Возникает вопрос, зачем нам L1-регуляризация? Во-первых,
она дает нам чуть другие свойства, потому что, например, она отбирает признаки. Что это значит,
я сейчас скажу. Во-вторых, у нас не всегда есть требования получить наименьшее значение вектор
весов, это зависит опять же от ваших предположений. А касательно того, что у вас нет аналитической
формулы, а нам все равно, даже если считать градиентное решение, у вас будет решение,
грубо говоря, не единственное, все равно вы сойдетесь согласно шуму к какому-то решению,
если вы используете выраженную матрицу, просто градиентным методом, но она у вас, собственно,
получится тоже каким-то непонятным, каким-то вот таким может получиться и любым другим,
потому что вы под шум переобучитесь. То, что шум у вас все равно в данных присутствует. А когда вы
используете L2-регуляризацию, вы все равно получите решение, которое гораздо ближе вот сюда. Но не вот
сюда. Тут будет примерно минус 0.7, 0.8 и минус 0.8. Они будут гораздо ближе друг к другу. Да, это
с L2. С L1 примерно то же самое. Заметьте, это тоже функция, по сути, выпуклая. Поэтому она все равно
дает вам какое-то единственное решение. Но оно работает чуть по-другому. И здесь обычно начинаются
какая-то очень странные разговоры. К сожалению, анимашка почему-то померла. Может, на нее можно
посмотреть. Нет, нельзя. Ладно, потом покажу. Ну, тут просто это все должно ездить. Я вам лучше сейчас
на пальцах объясню. Смотрите, L1 отбирает признаки. Вот это очень такая нестандартная вещь. От нее,
к правилу, все начинают немножко зависать. Что значит L1 отбирает признаки? Я вам давайте сейчас
даже попробую это нарисовать. Благо, у нас есть доска. Пока она загружается, собственно, что сделаем?
Что значит L1 отбирает признаки? Давайте пока что подумаем. Вот мы с вами, когда решаем
оптимизационную задачу, нам нужно найти решение, которое минимизирует сумму квадратов отклонений,
например, в СМСЕ. Но при этом мы хотим еще и минимизировать первую норму вектор весов.
Правильно? Давайте на это посмотрим с точки зрения градентных методов.
Что? Рисовать на черном фоне классно, мне нравится. По-моему, так даже лучше видно. Итак, смотрите.
Вот у нас с вами есть, собственно, первая норма, вектор омега. То есть это у нас получается сумма
омега итой по модулю. Согласны? Давайте мы теперь попробуем эту штуку минимизировать.
Причем градентный метод? Когда у нас получается d омега первая норма по d омега и будет чему равна?
Ну по факту это будет плюс один, если омега и больше нуля, ноль если омега равна нулю и
минус один, если омега и. Нет. Если омега и меньше нуля. Или, что на самом деле эквивалентно,
так просто проще записать, это просто сигнум омега и. Хорошо? О, спасибо. Современные
технологии. Ладно, с этим все согласны. А теперь давайте посмотрим, как он. Предположим,
что у нас какой-то признак, например, вообще не влияет на решение. То есть он не нужен,
он шумовой. Он неважно, там положительный, отрицательный вес имеет, он на решение влияет.
Тогда что мы получим? У нас, когда мы с вами пытаемся минимизировать нашу функцию имперического
риска, q от омега, которая в общем случае равна l, это наша функция потерь. Что с тобой не так?
Залепло, наверное. У нас есть l, это именно функция ошибки, ошибка предсказания нашей
целевопеременной. Плюс первая норма, вектор весов. Согласны, когда мы с вами считаем производную,
у нас получается dq по d омега. Это что? Это у нас dl по d омега плюс d omega 1 по d омега.
С этим все согласны? Вот. Давайте добавлю лямду. Я сейчас показываю именно тот факт,
почему при лямду равной 1 или лямду равной 0,5 ничего не поменяется. Если у нас какой-то
признак не влияет на функцию ошибки. Что значит будет с этой производной? Она будет равна 0,
потому что она от нее не зависит. Ну или в среднем равна 0, потому что у нас есть шум, одни объекты
будут тянуть наверх, другие вниз, чтобы не засыпали и так далее. Да что с ними не так сегодня?
Ой, ладно. Короче, довки устали. Короче, эта штука примерно равна нулю.
Все, да ладно, мы почти закончили. Короче, все согласны, я надеюсь, что вот эта штуковина,
она примерно равна нулю, если признак не зависит. Что у нас когда остается от градиента? У нас
вот этот вклад, а когда вот этот вклад будет нулевым. То есть когда у нас градиент не будет тянуть
данный вес признака куда-нибудь, когда он равен нулю. Потому что всегда когда у нас
признак больше нуля, у нас градиент плюс 1. Соответственно антиградиент будет минус 1.
Всегда когда признак меньше нуля, антиградиент будет плюс 1, то есть у нас градиент будет
всегда толкать значение нашего веса в 0? Да и вы меня
достали, господи. Не вы в смысле о доске. Соответственно,
всегда когда значение нашего признака не равно 0, веса
нашего признака не равно 0, если он неважен, то, соответственно,
он будет просто загнан в 0. Потому что вот эта штука
компенсировать это не будет, а эта штука будет его толкать
в 0. Собственно, ровно поэтому и говорят, что L1 регуляризация
отбирает признаки в смысле того, что если у вас какой-то
признак неважен, он получит на любой вес в конце кону.
Его просто, собственно, первая норма загонит в 0. Более того,
на самом деле тут даже что можно сказать? Если у вас
вот этот коэффициент регуляризации достаточно большой, то
есть признак все равно имеет там какой-то мизерный
градиент, то есть очень маленький градиент, он возможно
как-то очень мало значен для решения задачи, а здесь
коэффициент лямбда большой, то получается, что вот этот
он же всегда как бы пропорционален единице, потому что лямбде
лямбда на единице, потому что здесь или плюс или минус
один. Поэтому если у вас какой-то признак мало влияет
на решение, допустим, там есть какая-то связь между
признаком и целевой переменной, но она крайне маленькая,
допустим, там влияет на нее в четвертом знаке после
запятой. У вас L1 регуляризация с лямбдой больше, чем 10-4,
все равно загонит его в 0, потому что отсюда у вас
градиент будет порядка 10-4, отсюда порядка 1. Уловили?
Все уловили? Картиночка? Ну, визуализировать, так я
собственно и пытался вам это визуализировать. Смотрите,
вот вам картиночка. У вас получается, что производная
здесь всегда плюс 1, минус 1 здесь плюс 1. Если у вас
производная от функции потери меньше, чем вот эта штука,
она ее доминирует, значит, она загоняет 0. То, что если
она вышла из 0, она сразу получает пинка в сторону
0 силой 1, а функция потери силы меньше 1. Все, она зайдет
именно туда, где минимум. Все, он нам больше не нужен.
Ага. А теперь посмотрим на L2. Смотрите, L2 у нас какую
производную будет давать? 2 Омега. Поэтому если Омега
около 0, то у нее градиент становится уже меньше, чем
вот этот самый условно Эпсилон, который нам дает функция
потерь, поэтому она просто загоняет их близко к нулю,
но не ровно в 0. L1, собственно, за счет вот этой ступеньки
у нас производная, либо минус 1, 0, 1. У нас ступенька
резкий переход. За счет этого он ровно в 0 загоняет,
а у L2 плавно убывает производная. Чем ближе к нулю, тем меньше
производная. Поэтому он их просто догоняет примерно
до 0, но не выкидывает полностью. Именно в этом смысле говорят,
что L1 регуляризация отбирает признаки. На всякий случай,
когда вы используете L1 регуляризации, вы просто
в векторе весов можете получить некоторые нулевые
элементы, но вектор весов будет точно такой же размеренский.
Это частая ошибка на самом начале работы с машинным
обучением, когда ожидают, что вы применили L1 регуляризацию
и у вас почему-то вектор весов стал меньше. Нет,
конечно, у вас просто такие члены будут равны нулю.
Все. И именно их мы считаем выкинутыми признаками,
но после этого, как правило, есть еще подход, что после
этого вы перезапускаете вашу модель, оптимизацию
выкинув эти признаки из обучающей выбраки, можете
даже после этого уже L2 регуляризацию взять и уже оставшиеся признаки
просто подогнать поближе к нулю. Вопросы, пожелания,
комментарии? Те поняли, что L1 делает с признаками,
с весами? Тут тоже. Зануляет, если они не важны для решения
задачи. То есть, если они достаточно не важны относительно
коэффициента лямбда. И, собственно, здесь коэффициент лямбда
как раз явно видно, что делает. Если лямбда большая,
то если наш признак влияет на ошибку, на градиент
ошибки меньше, чем на лямбду, то он будет выкинут. Если
больше, чем на лямбду, то он не будет выкинут. Все.
Вот. И это, на самом деле, штука, я ее потом подвигаю.
Это второе объяснение, собственно, что это такое. Это шар,
но во второй норме. Это шар в первой норме. Заметьте,
у вас вот это, по сути, что здесь, я потом, она подвигается,
на пальцах, опять же, покажу. Собственно, что вот это за
эллипс такой? Это линии уровня квадратичной функции
потерь. То есть, линии уровня, это эквипотенциальная
поверхность. То есть, на линии уровня у вас одинаковые
значения функции ошибки. Оптимальное решение у нас
где-то вот в этой точке. Мы именно в нее хотим попасть.
Но когда мы, например, говорим, что рассмотрим все решения,
у которых норма вектор весов первая равна единице,
у нас в среднем вот эта точка, вот эти точки, так как они
у нас по первой норме на шаре лежат, по сути, они в вершинах
нашего четырехугольника, они в среднем будут ближе
к центру, чем те, которые лежат между ними. Опять
же, это можно формально доказать, эта штука по-хорошему
должна двигаться. Ладно, давайте я вам ее покажу. Я
надеюсь, ссылка еще работает. Во! Да понятно, она сейчас
откроется. Вот, давайте посмотрим, скажем так
за этим, как его. Глядите за нахождением желтой точки.
Видите, здесь она ездит совершенно свободно. Она находится
всегда на окружности радиуса единицы от центра, и абсолютно
все равно у нас есть центральная симметрия. Здесь точка почти
всегда находится в вершинах. А это ровно есть та ситуация,
когда у вас один из весов от собственно оси, ω1, ω2,
один из весов равен нулю. Понимаете, потому что его
вклад в качестве ошибки вот здесь гораздо меньше,
чем его вклад в качестве регуляризации здесь. Только
и всего. Это такая визуальная картинка. Мне, честно говоря,
вот это объяснение было непонятно, наверное, первые
года три, как я на него смотрел, с градиентами было гораздо
проще понять. Но кому-то возможно так понять. Окей, тут вопрос
есть? Ну почему? У вас производная тогда чему равна? 2 ω всегда.
Так, ребят, сейчас дайте мне еще пять минут, пожалуйста.
Мы тут чуть позже начали, поэтому мы не до конца уложились.
Что? Да, да. Ну ровно поэтому, чем ближе вы к нулю, тем меньше
у вас вклад регуляризации в решение. Ну да. Я вас
плохо слышу, тут уже пошел, давайте в перерыве тогда
отвечу. Хорошо. Ладно, ребят, собственно, бывают различные
еще способы по мере качества в регрессии не только
МСЕ и МАЕ. Например, есть коэффициент детерминации
есть МОПЕ, средняя абсолютная процентная ошибка, есть
самопе симметричная, на них проще на семинаре посмотреть
и не в принципе. Это все мое МСЕ, только чуть-чуть
преобразованное. Ну и последняя, но тем не менее очень важная
вещь, потому что уже второе занятие, скажем так, чисто
по машинке, у нас была еще лекция по линалу. И чтобы
все модели строить, надо уметь оценивать их качество.
И как сказал очень умный, талантливый человек, вы
ровно настолько можете доверять своей модели, насколько
вы доверяете своему пайплайну валидации. Вот шутку валидации
я сейчас скажу. Давайте скажем, что у нас есть выборка.
Мы можем решать задачу регрессии, можем задачу
бинарной классификации, абсолютно неважно. У нас
есть некоторая модель, которая предсказывает значение
целевой перемены для каждого объекта. Наша задача – минимизировать
вот эту самую функцию имперического риска, ну или функцию потери.
Опять же, на практике ее просто всегда называют
функцией потерь, главное понимать, что вы в это
вкладываете. Включает она в себя регуляризацию
или нет. И у нас может быть три ситуации. Недо обучения
модель слишком простая для решения задач. Линейная
модель, например, пытается, мы пытаемся ее использовать
в явно нелинейной задаче. Тогда все плохо. Может быть
хорошая модель, вот то, что мы всегда хотим, может
быть переобучение, когда модель по сути запомнила
ответ на каждом объекте и явно вот такая поверхность
решений как-то больно сложной выглядит для такой задачи.
Что такое оптимальная сложность модели, на самом деле можно
долго говорить, и это зависит от того, что мы сформулируем
как оптимальная модель. Но есть вот эта классная
картинка из книжки Гудфеллу и Бенджоу, и Арен Курвилла,
она у нас вторая в списке рекомендованной литературы.
Собственно, здесь у нас по оси х ошибка, по оси у
у нас сложность модели, то есть количество степеней
свободы модели, грубо говоря. Можете очень грубо это
оценить как количество параметров модели. Хорошо?
В двух данных она может запомнить. И, собственно,
у нас есть две ошибки. Тиненькая, это ошибка на обучающей
выборке, она у нас снижается примерно к нулю, она может
достичь нуля, если у нас нету явно шума в наших данных,
она не может его достичь, если у нас, например, два
объекта одинаковых с разными предсказаниями, тогда
не сможешь ничего сделать. А вот у нас ошибка обобщающая,
ошибка обобщения или Generalization Error, или ошибка на отложенных
данных. Как видите, она до какого-то момента снижается
вместе с ним, а потом начинает краски расти. Это, собственно,
как можно сделать переобучением, когда наша модель переобучается
под обучающую выборку, то есть запоминает специфичные
вещи только для обучающей выборки. Но это красивая
теория. Тут, на самом деле, есть еще у этой картинки
продолжение, о нем говорят последние годы, и все еще
идут научные изыскания, непонятно, что происходит.
Называется она Double Decay. В некоторых случаях вот эта
штука может начать расти, а потом опять начать падать.
Но как бы это вот конец второго семестра, возможно,
про это поговорим, если будет именно как это обосновать,
потому что есть просто несколько работ на эту тему научную,
которые говорят, ну, вообще так бывает. Вот, собственно,
недообучение и переобучение. Проблем в чем? Если вы модель
сделанной слишком простой, усложнить ее вы всегда
можете. Если слишком сложной, можете ее всегда упростить.
Но, собственно, как понять, насколько ваша модель
переобучена? Что она недообучена, в принципе, можно понять
достаточно легко. У вас просто качество в модели недостаточно
хорошее. У вас либо данные плохие, либо модель недообучается.
Именно на обучающей выборке. Что делать, если модель
переобучается? Вы для этого сначала должны обнаружить
переобучение, потому что вы не знаете, как ваша модель
себя ведет. Где-то, кроме обучающей выборки, покажут.
Поэтому можно использовать, скажем так, метод отложенной
выборки. И я не рекомендую его использовать сейчас,
когда мы будем говорить про какие-то крупные нейронки.
У нас не будет выбора другого. Но, тем не менее. Как правило,
вот есть такое понятие обучающей выборке, train, тестовой выборке,
test. И я сразу скажу, что есть, собственно, валидационная
выборка еще, чтобы вас сразу не консьюдить, скажем так, не запутывать.
Собственно, в хорошей нотации тестовая выборка — это то, что у вас вообще вот
лежит где-то вне, и вы к нему либо никогда не получите доступа, либо вы
получите к нему доступа, грубо говоря, пройдя точку невозврата. Ну, словно вот
тестовая выборка — это как будто вы сдали работу преподавателю на экзамене, и
уже преподаватель вам говорит ответ, хорошо вы решили экзамен или нет. Вот это
ваш тестовая выборка. Вы не можете сказать преподавателю, а, я здесь ошибся, дайте
перепишу и опять ему сдать. Некоторые пытаются, как правило, от нее работать.
Валидационная выборка — это все то, что вы делаете у себя локально, это ваши
локальные тесты на ваш код где-нибудь там на проге, это ваша проверка своей
домашки или попытка соседа попросить проверить вашу домашку и так далее. То
есть валидационная выборка — это то, что вы сами используете. Поэтому у нас есть
собственно train validation test framework. Train — это то, на чем вы настраиваете параметры
вашей модели. Вот именно параметр. Валидация — это то, на чем вы выбираете
гиперпараметры и то, на чем вы проверяете качество вашей модели. Обращаю ваше внимание,
если вы подбираете параметры на валидационной выборке, вы уже
посредством взаимодействия самостоятельно с параметрами, гиперпараметрами точнее,
переобучаетесь под валидационную выборку. И вы можете под нее переобучиться, если будете
долго это делать. То, что у вас по сути утечка данных идет через вас в вашу гиперпараметру.
Если достаточно долго будете делать, вы подберете оптимально для вашей валидационной выборки,
но не факт для всего распределения, откуда приходят данные. Что можно делать? Варианты,
где вы просто от Рейна отрубили тест один раз, на нем проверились — идея плохая. Почему? Потому
что как минимум вы можете случайно выбрать плохую под выборку, на которую будете тестироваться.
Например, у вас сюда попали только объекты класса 1. Тогда если у вас абсолютно тупой классикатор,
который умеет предсказывать только объекты класса 1, у вас 100% accuracy, у вас все правильно,
а по факту ваш классикатор — мусор. Или у вас здесь просто класс не сбалансированный. Или здесь у вас
только студента, например, у вас задача предсказания среднего дохода, и у вас несколько социальных
групп. Короче, как дробить данные, там будет различная процедура стратисикации, нормализация,
и так далее. Про это мы тоже поговорим. Как делать, пока у вас маленькие модели? Это примерно до
восьмого занятия нашего курса, пока мы делаем так. Мысли так делают всегда, когда маленькие модели,
когда не слишком много данных, когда можно себе это позволить. Можно, собственно, или разделить
выборку на train, validation и test. Вы можете либо выбрать валидацию очень хорошо, проверить все
статистики. Классно. Пока выборка маленькая, можно сделать сильно проще. Можно использовать cross
валидацию. А именно, вы сразу имеете какую-то отложенную выборку. Вот тест — это то, что у вас или
вам вообще недоступно, или вы изначально ее отложили. Как правило, тест у вас… Короче, вы, как
правило, тест себе не выделяете. То есть тест — это либо то, что вы будете сдавать в контест, либо то,
что вы издаете на соревнования, либо то, что вы завтра тестируетесь на работе, на проде и так далее.
Если все упадет — плохо. Что делать с validation? У вас есть все ваши данные обучающие. Вы их можете
побить на различные чанки, кусочки, и повторить много раз процедуру. Выбираем все фолды, кроме
одного, фолд, краски в данном случае. Все куски, на котором побили, на них обучаемся, на последнем
валидируемся. На всякий случай тут написано test fault. Я когда-нибудь это все-таки перепишу.
Валидационный фолд. На последнем проверяемся. И повторяем так, чтобы в качестве валидационного
использовался каждый из фолдов, который был. То есть, по сути, мы, если у нас 10 фолдов,
10 раз обучаем нашу модель на различных подвыборках. 10 раз тестируем на, опять же, различных подвыборках
валидационных. У нас получается на самом деле 10 моделей. И 10 раз мы посчитали ошибку. Потом
можем усреднить. И вот эта усредненная ошибка есть наиболее, наверное, качественная оценка качества
нашей модели. Да, это, конечно, все умеет. Мы вас будем явно просить делать именно так,
потому что один раз побить пополам – плохая идея. Плюс это вам позволяет экономить на самом деле
данные, потому что теперь вы, по сути, пробежались, протестировались на все обучающие выборки,
и вы обучились на все обучающие выборки. Тут маленькое замечание. Что делать, когда у вас
получил здесь модели на выходе, ведь у вас здесь, здесь, здесь и здесь, получил здесь разных моделей.
Тут есть два варианта. Первая – модель линейная. Допустим, это линейная регрессия. Можете банально
усреднить их веса и все. Долго не думая. Вторая – модели какие-то сложные, например, это какие-то
деревья. Тогда потом одиннадцатый раз обучаете модель с нужными вам гиперпараметрами. Гиперпараметры
вы тоже можете подбирать по кросс-валидации. Просто в качестве скоров вы выбираете усредненность.
И тогда, собственно, вы просто-напросто потом берете всю обучающую выборку, нужные вам гиперпараметры,
обучаете модель целиком. Еще раз, но уже с теми гиперпараметрами, которые у вас были. А как обнаружить
переобучение? Нет, две вещи. Первое – вы можете так посмотреть. Вы подкрутили гиперпараметры,
посмотрели на кросс-валидации, как поменялся скор. Стало лучше или хуже на отложенных данных. Второе – вы
тем самым детектируете переобучение. Если у вас начинает резко расходиться качество на обучающей
выборке и на валидационной, то тут два варианта. Либо валидационная выборка плохая, сильно хуже,
чем обучающая, либо вы переобучаете. Кросс-валидация вас, по сути, спасает от того, что вы
переобучаетесь, от того, что она плохая, потому что вы пробежались по всем под выборком. Если на
всех стало хуже, значит вы переобучились под обучающую выборку. Да, конечно. То есть по-хорошему,
если вы смотрите просто на отклонения, на значение ошибки, вы смотрите на его средние. По-хорошему,
посмотрите именно на статистики ошибки, возможно, у вас на каких-то классах ошибка большая и так далее.
Анализировать ошибку более глубоко – абсолютно верно. Но, по крайней мере, вот базовая вещь – вы
по кросс-валидации можете выбрать себе, скажем так, не выбрать, а заметить, что у вас на отложенной
выборке всегда ошибка сильно выше, чем на тройновой, на обучающей. Значит, скорее всего,
у вас слишком сложная модель, она просто-напросто переобучается под ваши данные, и вы находитесь
где-то вот здесь. Надо делать модель попроще. И так далее. Вот. Десять – это просто количество
фолдов. Это, скажем так, чем больше, тем лучше, но чем больше, тем дороже. У вас сложность линейно
растет с увеличением количества фолдов. Ранее, вот совсем давным-давно, когда данные были маленькие,
а трава зеленая, даже был отдельно называемый метод LOO, leave one out. Короче, оставь один. То есть
там, в качестве трест, обучающий выборке использовал вся выборка с заключением одного объекта,
соответственно, на одном объект тестировались. Но если у вас выборка размером там миллион, то
миллион раз обучаете вашу модель, и вы замучаетесь. Поэтому, условно, обычно будет там на 5-10-20 фолдов,
в зависимости от сложности. То есть, грубо говоря, сколько вы можете себе подволить. И именно поэтому
кросс-валидация с каким-то uber-неронками не используется, потому что обычно там одна
модель обучается месяца так два, так кластеры из ГПУ. Если вы будете это 5 раз делать, то это
почти год. Дорого, просто дорого. Вот. Поэтому, когда мы дойдем до сложных моделей, мы краски
поговорим еще раз, как нам выбирать уже хорошую одну валидационную выборку. Там должны совпадать
распределение по классам или каким-то категориальным переменным, по ошибкам, короче, по всему. Они
должны визуально выглядеть как выборки из одной и той же, из одного и того же распределения. Тогда
все хорошо. Ну что ж, а на этом мы подходим к финалу нашей лекции. Собственно, линейные модели — это
замечательные модели, которые работают в половине случаев. И как говорит мой, например, научный
руководитель, это так называемый метод палки и веревки. Он очень простой, он не может не работать.
Он может не работать, только если у вас слишком сложная задача для линейной модели. Там ломаться
нечем. Понимание линейных моделей позволит вам работать и с нейронными сетями, и на самом деле
с деревьями, потому что, как мы с вами увидим, деревья — это тоже в некотором смысле линейные модели,
просто над очень странными признаками. И, собственно, стройте валидацию так, чтобы вы могли и доверять.
Если вы не уверены в вашей валидации, значит, ровно настолько не уверены в том, что ваша модель
вообще делает нефигню. То есть вот валидация и постановка задач и оптимизация — это, наверное,
два таких кругольных камня, вокруг которых строится все остальное. Если у вас ошибка там или здесь,
все остальное бесполезно. Вот. Ну, на этом лекция завершается. Перерыв 15 минут. Дальше семинар.
