Так, давайте начинать.
Я сегодня про деревья немножко поговорю, там видимо в контесте
есть задача про лица, вот давайте с лица начнём.
Так, нет, рано, определение.
Значит, что такое дерево?
Сложный конечно вопрос, дерево это неориентированный
граф без циклов.
Так, определим, граф без циклов, тогда же называется
деревом.
Да, так, что-то я сегодня, связный, да, неориентированный
связный граф без циклов, достаточно вроде бы.
Ну, какие свойства у деревьев есть?
Значит, во-первых, ребер у них всегда на один меньшим
вершин, вот, и это можно, например, аргументировать
тем, что, ну, смотрите, давайте скажем, что граф изначально
пустой, то есть там нет ребер, и вот каждая вершинка
сама по себе.
У меня получается есть n, ну, то есть мощность v компонент
связности.
И дальше я хочу, чтобы каждое ребро стягивало какие-то
две новые компоненты связанности, которые раньше были не
связанные, а теперь вот я провел ребро, они стали
связанные.
Ну и понятно, что если у меня изначально n компонент
связанности, а в конце должна быть одна, то мне нужно провести
хотя бы n-1 ребро, чтобы все стянуть в одну.
Вот.
Ну и вот как раз дерево, это где никаких других
ребер нету, то есть каждое проводимое ребро, оно стягивает
как раз две какие-то компоненты.
Вот.
Ну, во-вторых, например, известно, что в дереве
между любыми двумя вершинками есть ровно один путь простой.
Значит между любыми двумя вершинами есть ровно один
простой путь.
Вот.
То есть, если фиксировать любые две вершинки у и
в, то существует ровно одна последовательность ребер,
нужно пройти, чтобы из одной попасть в другую.
Ну интуитивно, значит, почему это может быть так.
Ну понятно, раз граф связан, то путь обязательно есть
между любыми двумя вершинами.
Почему он единственный?
Ну пусть есть какие-то два пути из УВ.
Вот есть какой-то такой путь, есть какой-то другой
путь, да, там как-то от него отличающийся.
Вот, ну тогда цикл есть обязательно, да, типа на картинке видно,
что вот как раз вот это будет циклом.
Ну и формально тоже можно наказать, можно, если, скажем,
рассмотреть вот все ребра, используемые в первом пути,
все ребра, используемые во втором пути, и если взять
их симметрическую разность, то есть оставить только
те, которые присутствуют ровно в одном из двух путей,
то у нас получится, ну там, вот в этом случае получится
просто вот такой вот цикл, в общем случае получится
несколько циклов, что противоречит как раз определению дерева.
Да, но почему это так, ну скажем, что такое путь вообще?
Вот если рассмотреть путь как граф, то это граф, в котором
каждая вишина имеет степень 1 или 2, вот, у нас есть два
таких графа, путь первый, путь второй, если рассмотреть
симметрическую разность, то я утверждаю, что у каждой
вишины будет степень максимум 2 как раз.
Это неправда, да, сейчас, да, неправда, кстати, потому
что, например, есть вот такой вот и вот такой вот, да,
то есть разность как раз, хорошо, обманул, ну окей,
да, так это не доказывается, но в любом случае понятно,
что если у вас есть два маршрута отсюда до сюда, то, ну понятно,
можно поверить же, не-не-не, не надо, не надо, может, скажем,
там рассмотреть, вот первый момент времени, когда пути
расходятся, вот, можно так рассмотреть, пусть первый
момент времени, когда они расходятся, посмотрим,
и потом первый момент, когда они сходятся, тогда
все вот эти вот вершины попарно различные и, значит, тут
есть цикл, ну может так, например, вот, но мы это
используем как просто вот, как данность более-менее,
ну вот, хорошо, дерево это вот такой граф, да, связанный
без циклов, я буду часто говорить про ориентированное
дерево, ну или оно же корневое, да, давайте буду говорить
лучше, корневое, корневое дерево, это когда в моем
дереве выделено некая корневая вершинка R, и все ребра как
будто бы ориентированы сверху вниз от этого корня R, ну,
то есть вот что-то такое, где ребра как будто бы
сверху вниз ориентированы, вот, корневое дерево, это
дерево, где выделено некая фиксированная вершинка
корень R, вот, и по умолчанию считается, что все ребра
идут сверху вниз, то есть от, ну, по факту ориентированы
на путях от R до всех вершин, вот, как бы вот в ту сторону
от R, вот, ну и, соответственно, вот в таком корневом дереве
при фиксации какого-то корня я буду говорить об LCA, значит,
он же то ли lowest, то ли least, давайте скажем lowest common
ancestor, а по-русски наименьший общепредок, наименьший
общепредок.
Значит, следующая штука, вот представьте, у вас
есть две вершины какие-то у и в, ну, давайте рассмотрим
путь между ними, мы знаем, что путь единствен, вот,
ну, он тут как бы не совсем согласован с ориентацией
этих ребер, потому что ему там иногда надо придется,
надо идти вверх, то есть как бы против движения,
против направлений ребер, ну, не важно, у меня же граф
на самом деле не ориентированный, вот такой путь я рассмотрю
между ними, вот, и давайте самую высокую вершинку
на этом пути я как раз назову LCA, LCA для вершин у и в, вот,
ну и вообще любой путь в дереве у меня это сначала
подъем до LCA, потом спуск до второй вершинки, ну, почему
это так, вот, не знаю, у меня есть корень, у меня есть
другая вершина, есть другая вершина, можно построить
путь от U до R, да, это какая-то послед существиробер,
можно построить путь от V до R, это вновь какая-то
последствитель�ер, которая рано или поздно сольется
вот с этой вот последств Eine стрибер от У до R,
то есть, либо они там где-то пересекутся и потом пойдут
вместе, либо оно там полностью будет по другой ветке chicken
ну, так или иначе, пути от U до Korn и от V до Korn що рано
или поздно пересекутся в одной точке, и вот
точка, где они пересекаются, и будет их Lца.
Либо альтернативно, просто по определению, что такое
Lца.
Это такая самая низкая вершина, которая тем не менее является
их общим предком.
То есть такая самая низкая в дереве вершина, что тем
не менее она является предком U и она является предком V.
Предком в том смысле, что они обе из нее достижимы
при движении вниз.
Вот такие эквивалентные характеристики Lца.
Вопрос, как можно было бы этот Lца находить довольно
быстро.
Как можно находить Lца быстро?
Так, ну есть много способов.
Давайте самый простой, давайте алгоритм 1.
Это через двоичные подъемы.
Значит, смотрите.
Вот пусть у меня фиксирован какой-то корень R.
У меня есть корневое дерево с корнем R.
Давайте я запущу DFS из этого корня.
Чем хорошо дерево, тем что, смотрите, в дереве у нас
все пути как бы однозначно определены.
Между любыми двумя вершинами есть ровно один путь.
И поэтому в частности эти пути являются кратчайшими.
Поскольку путь единственный, то тот самый единственный
путь, это есть кратчайший путь.
И поэтому, когда я запускаю DFS, он мне не только
находит компонент связанности, но еще и все кратчайшие
расстояния находит.
От корня находит все расстояния до всех вершин.
Поэтому если просто запустить DFS от корня, то он что сделает?
Он упорядочит, найдет всех детей как соседей R,
потом будут все соседей R, точнее соседей-соседей и так далее.
То есть у меня все вершины упорядочатся по уровням.
То есть так как было бы в BFS, но прямо внутри DFS,
потому что пути однозначно определены, можно просто
идти по графу, и это сразу расстояние считается.
Ну и давайте я сразу разобью все вершины по вот этим
уровням, по глубине.
Что здесь глубина равна единице у всех этих вершин,
здесь глубина равна двойке, ну и так далее.
И прямо сразу в DFS я могу эту глубину насчитывать.
Каждый раз, когда я перехожу вниз, я уменьшаю глубину на 1,
поднимаюсь наверх и наоборот.
Ну, короче, вы поняли.
Спускаюсь вниз, у меня будет плюс глубина,
поднимаясь с рекурсии наверх, будет минус глубина.
Вот.
Ну хорошо.
И заодно, кстати, я посчитал, могу предпочитать
для каждой вершины ее родителя.
При вот таком спуске сверху вниз, при проходе из вершинки
в ее сына, я могу записать, что родителем этого сына
является вот эта вершина.
То есть я не только глубины знаю, но и родителей всех вершин.
Вот.
А дальше идея следующая.
Значит, как работают двоичные подъемы.
Сначала я давайте введу такой массив,
лифтс, да, binary-лифтс,
который для каждого k и для каждой вершинки v
находит предка вершины v в поколении с номером 2 в k.
Значит, предок вершины v
в 2 в k-том поколении.
То есть что будет, если я встану v и 2 в k-то раз
пропрыгаю наверх, то есть поднимусь в родителя.
Вот.
В частности, лифтс нулевой от v.
Это просто родитель.
То есть родитель в первом поколении просто родитель.
То есть если вот это v, то вот это лифтс нулевой от v.
Лифтс первого от v это получается дедушка,
то есть родители родителя.
Лифтс второго это как бы прапрадедушка,
то есть дедушка дедушки, ну и так далее.
По степням двойки.
Значит, это либо предок в 2 в k-том поколении,
если он существует, да, ну либо просто корень,
если нет такого высокого предка.
То есть если я пытаюсь куда-то прыгнуть слишком высоко,
то я ограничиваюсь, обрываюсь r-кой.
Либо корень, если такого нет.
Либо r, если предка нет.
Так, давайте сначала скажем, как это находить,
как эти двойственные подъемы найти.
Ну, во-первых, лифтс нулевой заполняется очень просто.
Это просто родителя.
Ну, родитель, если он есть, либо единственная вершина,
у которой нет родителя, это сам корень,
тогда можно просто сказать, что лифтс от корня это корень.
Давайте я просто буду считать, что parent от r это r.
Если родителям корневой вершины считать сам корень,
то все сходится.
Ну а если родителям корневой вершины считать сам корень,
ну а дальше давайте считать,
что пусть у меня известны все подъемы вплоть до катого уровня,
пусть известны лифтс катая для всех вершин,
хочу посчитать лифтс k плюс 1.
То есть пойду по слоям по значению k.
Ну, идея здесь на самом деле такая же, как в sparse table более-менее.
Ну а именно следующее, чтобы получить предков 2 в k плюс 1 поколении,
это значит, что мне нужно прыгнуть вверх на 2 в степени k плюс 1.
Давайте я сначала прыгну на 2 в катой,
потом еще раз прыгну на 2 в катой.
В сумме как раз получится 2 в k плюс 1.
Но узнавать предков поколений 2 в катой я умею.
Это как раз лифтс прошлого слоя.
Поэтому если вот эта вершинка, скажем, х, то у это ответ.
Согласны?
Ну и вот как раз, если где-то я пытаюсь прыгнуть выше головы,
выше корня дерева, то это просто обрубится и будет корнем.
То есть можно написать следующую.
Можно написать такую мерзкую формулу.
Я для экономии места напишу ее.
Что такое предков 2 в k плюс 1?
Это предок в катом поколении, предка в катом поколении.
Точнее в 2 в катом поколении.
Кат и предок катома предка.
Правда же?
Ну все, очень простой пересчет.
Прям думать не надо почти.
Тогда утверждается, что на подсчет двоичных подъемов
мне нужно столько времени и памяти.
И вот я думаю, что я еще не готов.
Я не буду думать.
Все эти пересчеты на 2 в катом поколении,
на 1 в катом поколении,
на 1 в катом поколении,
на 1 в катом поколении,
подъемов, мне нужно вот столько времени и памяти.
Ну потому что понятно, k нет смысла брать больше, чем логарифм,
потому что если k больше, чем логарифм, то 2 вкаты больше, чем n, и я прям в небо
прыгаю, я явно выше корня, поэтому k брать больше логарифма смысла не имеет,
но если k не больше логарифма, то у меня первый аргумент в моем массиве
принимает лог значений, второй n значений, ну и отсюда как раз и лог получается.
Вот. Ну хорошо, теперь давайте считать, что двоичный подъем я насчитал.
Что дальше? Как теперь находить lca?
Вот из вершин в дереве я хочу найти их lca. Давайте его как-нибудь уже изображу.
Я сделаю следующее, возможно не самый интуитивный способ, но работающий.
Значит, давайте я вместо того, чтобы искать lca, я найду вот это вот сына lca,
то есть ребенок w, лежащий вот на ветке между w и u, вот первая вершина вот на этом пути.
Я хочу вот эту штуку найти. Как это сделать? Можно сказать так, что эта вершина это самый
высокий предок u, не являющийся предком v. Давайте скажем, что это будет у меня p.
Да, тогда p это самый высокий предок u, не являющийся предком v.
Ну и тогда ответ это просто p rent от p.
Хорошо. Во-первых, мне нужна вот подпроцедурка коротенькая,
которая проверяет, является вершинопредком или нет в дереве. Делается это очень просто.
Давайте в DFS насчитывать не только вот все, что я здесь уже насчитал, но еще и давайте
ставить наши любимые меточки tint и out. Время входа, время выхода из вершины. Когда захожу в вершину,
то есть у меня есть какой-то глобальный таймер, который считает количество шагов,
которые я сделал. Захожу в вершину, поставил tint, увеличил таймер, выхожу, то есть хочу
завершить рекурсию, подняться наверх, ставлю tout и увеличиваю таймер, поднимаюсь наверх.
Так же, как в самом обычном DFS, я расставляю меточки tint и out. Значит, тогда можно проверить,
что одна вершина это предок другой следующим образом. Бульевская функция является или предком
там не знаю, вершина x, вершина y. Это просто следующие две проверки. Чтобы x была предком y,
у нее должен быть меньше tint и больше tout. Ну не строго все. Вот эта штука проверяет,
что x это предок y. Вот, я утверждаю, что x это предок y, если и только если у них вот так
соотносятся tint и tout. Ну хорошо, давайте дерево какое-то рассмотрим. Пусть есть дерево большое,
пусть тут есть x. Давайте в одну, в простую сторону. Пусть x это предок y. Что это значит?
Если x предок y, значит я сначала от корня дошел до x, потом где-то внизу нашел y. Тогда понятно,
что у меня DFS сначала нашел x, потом нашел y, потом вышел из y и только потом вышел из x.
Значит у меня как раз выполняется такие неравенства, что я сначала вошел в x,
потом после этого вошел в y, обнаружил его где-то снизу, потом вышел из него и только потом,
поднявшись наверх и все еще обойдя, вышел из x. Значит все вот эти неравенства выполняются.
Ну а вот если x не является предком y, то это будет неверно. Я имею в виду неравенство не
строгие, то есть я считаю, что вершина является предком самой себя. То есть если скормить туда
две одинаковые вершинки, то будет считать, что она является предком самой себя. Понятно,
если поменяю местами y и x, то у меня конечно не будет выполняться вот это вот неравенство.
А если они вообще лежат в каких-то разных поддеревьях, скажем вот здесь вот x,
а вот здесь вот y, в каких-то там не пересекаешься поддеревьях, ну тогда понятно, что я сначала
выйду из x, а потом обнаружу y. А вот здесь как раз вот, давайте так нарисую, как раз вот эти
неравенства означают, что засечки установлены во времени следующим образом, что я сначала вошел в x,
потом вошел в y, потом вышел из y, потом вышел из x. А если они вот так вот как бы не пересекаются,
деревья затрагивают, то я сначала вышел из x, а потом вошел в y, и вот это вот вложение уже будет
неверно. Так, сойдет? Ну вот. Все, проверять предыдущность мы умеем, то есть мы умеем
проверять, что одна вершина предка другой. Теперь я хочу вот найти самого высокого предка,
не являющегося предком v. Ну сейчас сделаем. Значит, процедура LCA. Давайте вот так напишу.
LCA принимает две вершинки u и v, работает следующим образом. Ну, во-первых, если u это предок v,
то можно сразу ее вернуть, ничего находить больше не нужно. Вернуть u. Если одна вершина предка
другой, то она и есть LCA, выше не нужно прыгать. Вот, а иначе как раз вот такая вот картинка какая-то,
и я могу найти вот этот вот p, который является вот самым высоким предком u, не являющимся предком v.
И это идет следующим образом. Ну пусть будет p равно u. Значит, по всем k, начиная с какого-нибудь
k-max до нуля, я пытаюсь поднять p на два степеника вверх, если при этом выполняется условие,
что p это не предок v. Если неверно, что k и предок p являются предком v, то есть если я
могу спокойно прыгнуть из p на 2 в k вверх, и при этом я все еще не окажусь предком v. То есть я
прыгаю на 2 в k спокойно, не оказываюсь при этом предком v. Тогда я могу прыгнуть. Тогда просто
вместо p беру лифтс k-t-p-t. Вот, значит вот так жадно прыгаю по степням двойки, по всем позволяющим
мне прыгать вверх. И дальше я утверждаю, что в конце p это вот ровно то самое p, которое мне
нужно. И в качестве ответа я удушаю просто parent от p. Ретерн parent от p. Просто что? Ну, можно,
да. Ну, как бы можно, но я думаю, что это особо не даст вам выигрыша. То есть здесь можно проверить,
действительно, что если наоборот, если v предок, то можно вернуть v сразу. Ну, тут как бы на любителя.
С одной стороны больше кода на целую строчку, с другой стороны чуть быстрее. Ну, не знаю, в общем
случае, если вам дали две случайные вершины, то они обычно как раз не соотносятся друг с другом,
то есть ни одна не предок другой. Поэтому я так обычно не делал. Вот, значит, почему это работает?
То есть я утверждаю, что по окончании вот этого цикла p это реально самая высокая возможная вершина,
при этом не являешься предком v. Вот. Ну, почему это так? Потому что, смотрите, вот можно представить
вот это вот расстояние между u и настоящим p как степень двойки. И по факту я вот как раз иду
по вот этой вот битовой записи. То есть я представляю вот это расстояние в длительности
имуществления, иду справа налево от старших битых к младшим и каждую возможную днику пропрыгиваю.
А то есть, ну там не знаю, если на 16 вверх прыгнуть нельзя, то я не прыгаю, а если на 8 можно, то я
прыгаю. Как раз вот это вот число я представляю в длительности имуществления, оно задает мне те
возможные прыжки, которые надо сделать, я их прыгаю в том порядке от больших к меньшим. Вот. И в конце
как раз я пропрыгаю все возможные степени двойки. То есть, ну там не знаю, 8 плюс 4, ну там плюс 2,
например. Все возможные пропрыгал, выше нельзя. Так. Поэтому вот p будет вот ровно вот эта точка.
Понятно? Ну все, кайф. Значит, тогда получилось что? У нас получился предподсчет n log n на то, чтобы
посчитать вот эти глубины, t in и t out и двойчные подъемы. А после этого на запрос я отвечаю
за логарифм всего лишь. Да, потому что вот он код, он за логарифм работает. Вот. Это был первый способ.
Способ второй. Значит, через Эллеров обход.
Значит, смотри, что такое Эллеров обход на примере. Давайте кунь дерева нарисую.
Переборщил. Ну ладно. Как-нибудь они зонумерованы. Значит, Эллеров обход работает так. Мы встаем в
корень, начинаем обходить все наше дерево, ну как обычно по DFS, там вверх-вниз проходим по
ребрам, и каждый раз, когда заходим очередной раз в вершину, мы ее печатаем. Значит, тогда на этом
примере что это будет такое? Сначала 1 в корне начал, потом перехожу в вершину номер 12,
спускаюсь в номер 11. Ну я из нее сразу выхожу, поднимаюсь в 12, еще раз ее печатаю, несмотря на
то, что она уже была, я ее еще раз напечатал, спускаюсь в 9. Значит, дальше 10, подъем в 9,
спуск в 8, подъем 5 в 9, 12, 1, ну и так далее. То есть каждый раз, когда я наступаю в вершинку,
там будь это снизу или сверху, я ее печатаю. Это называется Эллеров обход дерева. Значит,
тогда утверждается следующее. Вот у меня есть какая-то последовательств вершин. Последовательств
вершин у нее длина примерно 2n будет. Ну потому что по сути я каждое ребро прошел один раз сверху
вниз, один раз снизу вверх, и каждое прохождение ребра дает мне печатание конца этого ребра. Я
спустился сверху вниз, напечатал конец ребра, поднялся снизу вверх, напечатал опять-таки конец
ребра. Ну и поскольку ребер у меня в два раза больше, pardon, ребер столько же сколько вершин
примерно, и каждое ребро я печатаю, каждый ребро раздваивается сверху вниз, снизу вверх, то здесь
вершин будет примерно в два раза больше, чем в исходном графе. То есть суммарно будет 2n вершин
вот этой последовательств. Тогда утверждается, что верно следующее. Чтобы найти LCA каких-то двух
вершин, скажем 11 и 8, мне нужно в этом Эллеровом обходе найти вхождение 11 и 8,
и найти просто на отрезке между ними вершину с наименьшей глубиной. Я ищу вершину с наименьшей
глубиной. Ну вот в нашем случае понятно, LCA это 12, ну и вот как раз на этом отрезке 12 это самое
высокое. В общем случае, чтобы найти LCA каких-то двух вершин у и в, я нахожу, где они встречаются в
моем Эллеровом обходе, скажем, на позициях L и R, и дальше в этом отрезке, на этом отрезке,
я нахожу минимальную глубину, нахожу вершину с минимальной глубиной. Это неважно, можно взять
любое вхождение U, любое вхождение V, и на отрезке между этими вхождениями найти вершину минимальной
глубины. Вот, почему это верно? Почему минимальная глубина на отрезке это LCA? Ну потому что что
такое вот это посредство вершин? Что такое Эллеров обход? По факту это некий путь в графе,
да, и каждые вот как бы любые две соседние вершинки, они как раз ребром соединены. У меня так работает,
что вот я прошел по ребру, напечатал вот конец, прошел, напечатал. То есть по факту у меня вот это
некий путь в графе, так что любые два соседа соедены ребром. И значит, если я рассмотрю отрезок от U до V,
то вот между ними какой-то путь от U до V, то есть это там какие-то ребра. Ну возможно не путь напрямую,
как например вот в этом случае от 11 до 8, я добираюсь вот так. Я сначала захожу в 10,
потом выхожу и спускаюсь в 8. То есть это какой-то путь с отменами, возможно. Я могу заходить в какие-то
лишние ветки, но так или иначе я дохожу до конца от U до V. Ну и тогда понятно, что раз я дохожу,
то на этом пути должен быть LCA. Я понимаю, что у меня любой путь этот LCA содержит. Ну а выше я
никуда не перепрыгну, потому что если я поднимаюсь выше LCA, то значит я прошел все, что было ниже.
Если я поднимаюсь вверх на какой-то вершинке, значит все по дереву я уже обошел. Ну поэтому
действительно просто минимальная глубина здесь, это LCA. Понятно? Ну вот, хорошо. Получается,
как работает алгоритм. Мы сначала строим error обход, это понятно за линию делается,
потому что это просто DFS по сути. Дальше я для каждой вершинки запоминаю произвольное ее вхождение
в этот массив на позицию вхождения. Повторю, мне неважно, если скажем 12 несколько раз встречается,
мне неважно какое иное из вхождения брать, потому что какое бы я не взял, все равно любой путь
там будет содержаться. Я запоминаю любое из вхождений, и чтобы найти потом LCA двух вершин,
я нахожу вот эти два вхождения этих двух вершин и нахожу минимум на отрезке. Как искать
минимум на отрезке? Спарстейблом, конечно. Поскольку у меня массив этот статичен,
и он меняться не будет, структура дерева у меня один раз зафиксирована, и глубины меняться не
будут, то я могу вместо дерева отрезков напевать спарстейбл. У меня статический массив элементов,
мне нужно на отрезке находить минимум. Формально не минимум, а вершину с наименьшей глубиной. Поэтому
скорее я должен не вот такой массив выписать, а массив пар глубина V, запятая V. И уже вот на
таком массиве строить спарстейбл. Тогда как раз у меня пары сравниваются сначала по первому
аргументу, и если я выбираю минимум из нескольких пар, то это будет как раз вершина с минимальной
глубиной. То есть я построил такой массив вот с такими вот парами, построил error обход, где
каждая вершина в пару превратилась, потом построил на этом спарстейбл и нахожу минимум на отрезке уже
за единицу. Потому что в спарстейбле запрос за единицу обрабатывается. Получился алгоритм за n log n
опять-таки на предподсчет, потому что спарстейбл требует n log n времени на предподсчет, а потом уже
единичка на запрос. Вот. Похоже на правду? Супер. Ну то есть это чуть лучше, чем предыдущая,
потому что тут на запрос всего лишь единичка входит, а не логариф. Так, ну и наконец третий
алгоритм называется алгоритм Фарах Колтона Бендера. Два чувака, один чувак это Фарах Колтон, другой
это Бендер. Поэтому тут дефис, а там тебе. Значит, сейчас вот магия. Смотрите, я остаюсь в этой парадигме того,
что я рассматриваю эйлеров обход. Давайте я посмотрю в этом эйлеровом обходе на массив глубин.
То есть у меня вот каждая вершина ассоциирована с какой-то глубиной. Давайте посмотрим на глубины,
на последовательность глубин этих вершин. Понятно, что поскольку две соседние вершинки в обходе
всегда с одной ребром, то глубины у меня при переходе к следующему элементу отличаются
на плюс-минус один всегда. То есть когда я перехожу от одного элемента к следующему,
у меня глубина либо на плюс один, либо на минус один изменяется. Но давайте скажу,
что пусть n это длина эйлерового обхода. Давайте я введу вот такой параметр, половину логарифма.
Ну там двоичный логарифм округленный куда-нибудь, неважно. И разобью весь мой обход на блоке длины k.
Вот у меня был большой обход длины n, я его посплитил на блоке длины k. Ну если целиком не
вошло, то как-нибудь вот так считаю, что там какие-то фиктивные элементы, неважно. Давайте я для
простых считаю, что n делится на k. Вот. И дальше смотрите, каждый блок на самом деле, каждый маленький
вот такой блок, может быть охарактеризован двумя числами. Значит, во-первых, это число х,
которое написано в начале этого блока, а во-вторых, это последовательность из плюс-минус
единичек, которые говорят мне про разность между соседями. То есть если в начале стоит х,
то дальше, чтобы описать целиком этот блок, мне нужно всего лишь знать, насколько отличаются эти
два элемента, эти два, эти два, эти два и так далее. То есть по факту каждый блок характеризуется х и
маской длины k-1. Маска длины k-1. Ну давайте там скажем, что, не знаю, 1 соответствует единичке,
а минус 1 соответствует нулю. Тогда как раз последовательность плюс-минус единичек это
какая-то просто битовая маска длины k-1. Вот, и если у меня зафиксировано первый
элемент пары и битовая маска, то я точно знаю, как выглядят все элементы этого массива. Понятно?
Еще раз? Нет, это число, смотрите, смотрите. Давайте так, давайте вот в этом массиве я считаю,
что написано только глубины. Я забываю про вершины, я здесь написал только массив глубин. А дальше,
если я узнаю позицию, ну, дальше по позиции, и я знаю, что было в этой позиции исходного массива,
значит я могу восстанить вершинку. Если я здесь нахожу минимум и где он находится, то я знаю,
какая вершина ему соответствует. Я перешел к постановке. Задача такая. У меня просто есть
массив глубин. Мне нужно здесь искать минимум на отрезке, ну и узнавать, где он. Если я узнаю,
где он, то я знаю, какая вершина ему соответственно вейлером обходит, значит я знаю LCA.
Смотрите, вот я в этом массиве буду находить не только минимум, но и позицию минимума.
То есть я нахожу, где находится минимальная глубина d, точнее значение, но еще и позицию, где находится i, ну индекс.
То есть я расширяю задачу, мне нужно будет на отрезке искать минимум и его позицию.
Мне кажется, что такая задача была то ли в листочке, то ли в контесте на спарстейбл,
что если нужно не только минимум находить, но и где он находится, можно просто внутри спарстейбла хранить минимум и его позицию.
Тогда если вы знаете, ну как обычно, если у вас есть там 2 в бетой, 2 в бетой размеры блоков,
если вы знаете минимум и его позицию здесь, то где минимум и его позиция во всем массиве?
Ну понятно, либо это, либо это. Вот тут тоже самое будет сейчас.
Ну так вот, давайте вернусь сюда.
Каждый блок у меня, каждый блок как массив глубин, характеризуется числом х, начальным числом, и маской.
Причем масок всего, возможных масок 2 в степени k-1, что если оно специально такое подобрано,
k специально так подобрано, что это было бы от корни из n.
Ну короче, сильно меньше н что-то.
Хорошо. То есть получается, что всего различных блоков, ну вот с поправкой на x,
по факту x это какое-то смещение. Вот у меня по факту блок определяется однозначно маской
и каким-то смещением, что все элементы ко всем элементам надо прибавить x.
Вот, если x считать нулевым, то по факту у меня всего различных блоков вот столько, по количеству масок.
То есть у меня есть какие-то аддитивные сдвиги, в смысле ко всем элементам надо прибавить плюс x.
То есть можно сказать, что всего блоков, давайте напишу так,
всего нормализованных блоков, то есть тех у которых x0,
нормализованных блоков, вот корни из n, различных.
Всего различных блоков мало.
Давайте тогда предпочитаем всевозможные ответы для всех блоков.
Ну а раз их мало, давайте их все перед тем, как отвечать на запросы,
давайте их все возможные все переберем, вот все корни из n их переберем,
и на всех возможных их подотресках найдем минимум.
Поскольку их мало и они маленькой длины, то можно за время типа корень из n умножить на лог квадрат
для каждого блока и для каждого подотреска внутри блока предпочитать ответ, предпочитать минимум на отрезке.
Значит, за корень из n на лог квадрат n предпочитаем минимумы на всех подотресках
всех нормализованных блоков.
Потому что отрезков, подотресков как квадрат, внутри отрезка.
То есть я рассматриваю блок длины k, в нем k квадрат подотресков.
То есть таким образом вот за такое время я могу создать такой массив какой-нибудь,
дп от маски и lr, это информация о том, чему равен минимум в блоке,
если блок характеризуется маской маск, и минимум нужен на отрезке с lpr.
То есть я взял блок, взял подотреск с lpr, и дп хранит мне минимум.
Ну точнее не только минимум, но еще и позицию.
Раз я расширил задачу и хочу знать не только минимум, но и его позицию,
то как раз дп хранит мне позицию в этом массиве и чему он равен.
И так для всех возможных блоков вообще.
Ну вот, все, а дальше идея такая, смотрите.
То есть по факту у меня вот здесь блоков-то очень много.
Блоков у меня примерно n под директным алгорифом, то есть блоков самих по себе много,
а блоков из них различных после нормализации мало.
Значит, тогда что я сделаю? Давайте я покажу, как находить минимум на отрезке.
Пусть у меня есть много блоков.
Значит, как найти минимум на отрезке, скажем, вот отсюда, вот до сюда?
От i до j.
Ну смотрите, я, во-первых, могу взять вот этот блок
и найти минимум на этом отрезке, то есть на суффиксе.
Это понятно как. То есть я знаю, что это за блок, я знаю, какая у него маска,
и я знаю, насколько он недонормализован.
То есть если здесь стоит x, то по факту это нормализованный блок, плюс x.
Но если я все эти числа знаю, то я же предпочитал минимум на этом отрезке для всех блоков.
И дальше просто плюс x надо будет добавить, и все.
То же самое здесь. Я рассматриваю блок, где лежит крайняя граница моя правая,
мне нужно минимум вот на этом отрезке. То же самое.
Я знаю, что это за блок, я знаю, какая маска ему соответствует,
я знаю, насколько он сдвинут, какой здесь стоит y.
Но поскольку у меня для всех нормализованных блоков я знаю, где лежит минимум,
то минимум здесь лежит тут же, только он на y еще увеличен.
Потому что там ко всем элементам прибавлен один тот же y.
Получается, что я знаю минимум на этом кусочке и на этом кусочке.
А дальше у меня подряд несколько блоков.
Мне нужно минимум еще вот здесь взять.
Но это сделаю опять спарстейблом.
Но спарстейблом уже не на n элементах, а на n делить на k элементах.
Теперь я блоки воспринимаю, чтобы найти минимум на таком отрезке,
я блоки воспринимаю неделимыми и строю на них спарстейбл.
Дальше я строю спарстейбл на неделимых блоках.
Опять же, я на каждом блоке сначала независимо предпочитал минимум и где он находится.
Затем сжал все эти блоки в одно число, минимум и где он находится.
А дальше на всем этом построил спарстейбл, чтобы находить минимум на отрезке между блоками.
И за сколько работает тогда спарстейбл? Он строится за время вот такое.
Давайте просто Бизону пишу.
n делить на k он может на логариф, n делить на k.
Потому что у меня вот столько блоков, и спарстейбл получается строится вот в такое время.
Но если подставить, то получится n просто.
Ну что это такое? Это n делить на k лог n,
минус там что-то там, то есть минус n делить на k лог k.
Но минус я отброшу, что будет не больше, чем n делить на k лог n.
Но k это как раз логарифм пополам.
Поэтому здесь будет 2n.
Потому что k это половина логарифма, логарифмы сократились, половина вылезла в числитель.
Будет 2n.
Получается, что время необходимое для построения спарстейбла на вот этих блоках,
если я блоки сжал до одной точки,
то мне нужно всего лишь линейное время, чтобы построить спарстейбл.
И значит я на запрос отвечаю за единичку.
То есть у меня получился алгоритм такой, у меня будет линейный предподсчет,
и единичка на запрос.
То есть пафос такой, что я вот в этой симптомике перешел вот к этой,
и дальше вот к этой.
Ну где n это то же самое, что n маленькое.
Значит еще раз, почему у меня получилась такая симптомика.
Смотрите, давайте сначала предподсчет.
Суммарно, что входит в предподсчет до того, как я начинаю отвечать на запросы,
и что я делаю с деревом.
Значит сначала я сделал эйлеров обход, записал массив глубин,
посплитил его на блоке длины k,
и понял, что у меня нормализованных блоков всего вот примерно корень и z.
То есть теперь у меня каждый блок моего вот этого вот массива,
это какой-то один из нормализованных, плюс аддитивный язык, плюс x.
То есть все элементы надо увеличить на какой-то x.
Хорошо, значит дальше.
Я для каждого возможного нормализованного блока, коих корень и z,
и для каждого подотреска внутри этого блока,
предподсчитываю минимум, где он тут находится.
То есть буквально запоминаю для каждого возможного нормализованного блока,
для каждого подотреска lr, где находится минимум,
его значение и где он находится.
Это вот за такое время, что, понятно, делаем меньше, чем у от n.
На корень данного угла меньше, чем у от n.
Это первый шаг.
Второй шаг предподсчета – это построение спарстейбла на сжатых блоках.
То есть теперь я в каждом блоке нахожу минимум.
Да, вот там не знаю какой это там,
минимум 1, минимум 2, минимум 3 и так далее.
И дальше на вот этих минимумах строю спарстейбл.
Который строится вот за такое время,
за n делить на k, log n делить на k,
потому что у меня вот столько блоков,
и спарстейбл как раз строится за количество элементов,
множество логарифм этого количества.
Это будет опять-таки у от n.
Получается, я за линейное время еще вот такой спарстейбл на этих м-ках построил.
Все, предподсчет закончился.
Такой двухфазный, сначала нормализованные блоки,
затем спарстейбл на настоящих блоках.
Это вот линейное время на предподсчет.
Теперь, чтобы давить на запрос,
я делаю следующее, в общем случае.
Мне нужно минимум на отрезке между i и j.
Я нахожу минимум вот здесь, вот как?
Обращаюсь к dp-шке, потому что я знаю, что это за блок,
я знаю, как его нормализовать,
мне нужно вычесть x из всех элементов.
Значит, я знаю маску этого блока.
Я знаю, как отчитан минимум вот на этом отрезке.
Потому что на всех подотресках каждого нормализованного блока я знаю ответ.
То же самое здесь.
Это какой-то подотрезок нормализованного отрезка,
я знаю минимум здесь и где он лежит.
А дальше мне нужно взять некий отрезок блоков
и на нем найти минимум.
Но это запрос к спарстейблу,
который тоже за единицу работает.
Вот отсюда получается как раз единичка на каждый запрос.
Вот.
Такой прикол.
Так.
Вопросы есть?
Тогда давайте пережив.
Чуть-чуть, пять минуточек.
Дальше пойдем.
Давайте дальше.
Смотрите, я сейчас вот эту конструкцию хочу обобщить
и приложить ее к старой нашей задаче, так называемой RMQ.
Именно.
Range Minimum Query.
Вот эта задача,
Промиум на статистическом уровне.
И вот эта задача,
Промиум на статистическом уровне.
И вот эта задача,
Промиум на статистическом уровне.
И вот эта задача,
Промиум на статистическом массиве.
То есть есть у меня массив какой-то,
а1, а2 и так далее, аn.
Он не меняется.
И поступают только запросы.
Найдите, пожалуйста, минимум на отрезке.
Вот.
Это то, что мы решали спарстейблом
за n log n предпочет и единичку на запрос.
Теперь, вот вооружившись этим аппаратом
с Фарах Колтона,
можно решить ее тоже
за линейный предпочет и единицу на запрос.
То есть раньше мы имели только
за n log n предпочета.
Теперь можно сделать за линейный предпочет.
Значит, решение-то будет такое.
На, давайте, алгоритм будет такой.
Значит, давайте мы
построим
дикартово дерево
на точках и запятая аито.
То есть у меня ключами
будут выступать просто индексы,
а приоритетами ашки.
Вот те самые значения а.
Вот.
Ну, еще раз, да, то есть
по умолчанию в дикартовом дереве,
ну, в алгоритме построения
мы брали приоритеты случайными.
А вот здесь я не беру случайные,
беру вот ровно те, которые мне нужны.
Значит, с одной стороны, это плохо тем,
что у меня тогда глубина будет не алгоритмическая,
а произвольная какая-то.
Ну, мне тут это и не важно, мне глубина этого дерева не важна.
Как, собственно, и в предыдущей задаче,
я про глубину дерева нигде особо не рассуждал.
Вот.
Ну, хорошо, построили такое дикартово дерево.
Мы это вроде умеем делать, у меня ключи отсортированы
по i, то есть по ключам.
Тогда мы знаем, что это можно сделать
за линейное время. Вот это можно сделать
за o от n. Там просто хранить
текущее дикартово дерево,
хранить вот эту текущую правую веточку,
самую ветку, идущую направо, в стеке.
И тогда, когда приходит новая точка,
мне нужно несколько последних элементов из стека удалить,
а последнюю добавить.
И вот так вот перенаправить указатель.
Разбирали когда-то такое.
Что может дикартово дерево построить за линию,
если ключи отсортированы. А это у нас так и есть.
Вот. Ну и все.
А дальше тут ожидается следующее,
что чтобы найти минимум на отрезке
с l по r,
мне нужно просто взять lca вот этих вот вершин,
которые соответствуют этим элементам.
И это и будет минимум.
Ну, то есть, значит, если
там m,
am,
это есть lca,
вершин
lal,
prar,
то
am-то это как раз
минимум на отрезке с l по r.
Значит, am-то это минимум среди чисел
с al-того
по ar-того.
Вот.
То есть, чтобы найти минимум,
достаточно найти lca. То есть, мы свели задачу
поиска минимума
к задаче поиска lca, а lca мы искать умеем.
За быстро.
За линией предпочета, единичка на запрос.
Значит, почему вот это верно? Почему
чтобы найти минимум, достаточно найти lca?
Ну, давайте
картинку нарисую. Вот пусть я нашел lca.
Вот, m, am.
Это lca вот этих двух вершин.
Ну, поскольку это lca,
во-первых, можно сказать сразу, что
тогда l и r лежат
по разные стороны
от этой точки.
Потому что, ну, там, скажем, если бы они лежали оба
в левом поддереве, то это какой-то фиговый lca,
потому что эта штука тоже тогда их общий корень,
общий предок.
Если обе вот эти вершинки лежат слева,
то эта вершина тоже общий предок,
но при этом более низкий.
Значит, это неверно. Получается, что у меня l и r
лежат по разные стороны.
То есть где-то вот здесь вот l,
где-то вот здесь вот r.
То есть тогда действительно понятно,
что m на отрезке между ними лежит,
по крайней мере.
Ну и все. А дальше
пользуемся тем, что
декартовое дерево – это куча
по приоритетам. Это значит, что
вот это am меньше, чем
все возможные приоритеты в поддереве.
В частности, здесь есть все
элементы от l до r.
Значит, am –
это минимальность среди элементов,
в частности, с alt по ar.
Там есть еще какие-то, возможно,
туда идущие, туда идущие.
Такое, что тоже am меньше, чем все они.
Но, по крайней мере, все элементы
с alt по r точно лежат в этом поддереве.
И получается, что am-то
это самые маленькие приоритеты
среди всех вот этих на этом отрезке.
Значит, am-то – это минимум.
Окей?
Ну вот, все.
Значит, чтобы находить минимум на отрезке,
в нашей старой задачке
RMQ,
нужно построить декартовое дерево
за линию, потом
за линейное время весь предпочет
сделать, разбить это дерево,
то есть аэрово обойти его,
разбить на блоки, посчитать нормализованные блоки,
построить sports table,
ну а дальше просто
там, как раньше,
за единичку на запрос отвечать.
Понятная идея?
Ну все.
Так, хорошо.
Тогда с этим закончили.
Все, тогда с LCA закончили.
Давайте последний сюжет на сегодня
это про
изоморфизмы,
изоморфизмы деревьев.
Ну постепенно буду сюда подбираться.
Сначала такое определение.
Вершина V называется центроидом дерева,
если после ее удаления
все компоненты связанности
имеют размер,
как максимум, N пополам.
Значит, если
в графе после удаления
вершинки V
все компоненты связанности
по размеру N пополам,
то есть если в графе
после удаления вершинки V
связанности
имеют размер
не больше, чем N пополам.
Ну, где N как обычное число вершин.
Вот.
То есть это такая вершина,
что если ее из графа удалить,
то все, что останется, разобьется
и все компоненты маленькие, в том смысле,
что они, по крайней мере, в два раза меньше,
чем исходный граф.
То есть не больше половины вершин
каждый из них содержит.
Вот. Это центроид.
Утверждение...
Давайте, наверное, без доказательства.
Оно элементарное, но времени не остается,
поэтому без доказательства.
Утверждение...
В любом дереве...
Есть центроид...
Причем...
Значит, он либо единствен...
То есть он всего один,
всего одна вершина является центроидом.
Либо их два,
и они с одной ребром.
Значит, либо их два,
они с одной ребром.
Ну вот, например,
такую картинку можно рассмотреть.
Вот. Если такое дерево нарисовать,
то вот эти две штуки являются центроидами.
Потому что всего вершин восемь.
А если вот это удалить,
то здесь будет...
Ну, короче, любую из них удали,
получится в одной компонент четыре,
остальные даже еще меньше будут.
Вот.
Ну, либо он вообще один.
Ну, вот это я доказывать не буду.
Я докажу, что он есть.
Алгоритм как его найти.
Алгоритм как найти центроид очень простой.
Значит, давайте запустимся как обычно.
Давайте подвесим дерево за какую-нибудь вершинку
произвольную, R.
Запустим DFS.
И давайте еще посчастливее.
Ну, вот.
И давайте еще посчитаем
новую характеристику.
Размер поддерева.
Sub3 вот V.
Это то, сколько вершин
вот в этом поддереве V, включая V.
Количество вершин в поддереве V.
Количество вершин
в поддереве V.
Сколько вот здесь суммарных вершин.
Значит, тогда понятно, что
в корне, понятное дело,
Sub3 вот R.
Это просто N,
потому что все вершины лежат
в поддереве корня.
И дальше, чтобы найти
центроид,
можно сделать следующее.
Смотрите, вот давайте я встал в корень.
Я знаю, что в корне
Sub3 равен N.
Дальше давайте переходить вниз.
Если есть ребенок
Sub3, у которого хотя бы N пополам.
Если есть ребенок, у которого
Sub3 хотя бы N пополам,
то я в него перехожу.
И так делаю дальше.
Если у этой штуки есть куда спуститься,
сохраняя свойство, что Sub3 хотя бы N пополам,
то я спускаюсь.
И так далее.
Вот я так спускаюсь, спускаюсь.
До тех пор, пока не обнаружится
вершина, такая, что
вот здесь, в ее поддереве,
вершина хотя бы N пополам,
но в каждом из поддеревьев
для дочерних вершин
там уже меньше, чем N пополам.
То есть вот здесь вот суммарно хотя бы,
а здесь меньше, чем N пополам.
Тогда вот эта штука
это центроид.
Потому что
какие появляются компоненты связанности
после удаления этой вершинки С?
Во-первых, все вот эти поддеревья,
я знаю, что их размеры маленькие.
Во-вторых, все остальное,
но размер этой штуки
не больше N пополам,
потому что размер вот этой штуки хотя бы N пополам.
А суммарно они N дают.
Ну все, значит, это центроид.
И того, получается, я встал в корень,
ну понятно, что в корне
у меня выполняется вот это вот свойство,
что размер хотя бы N пополам.
И дальше просто иду в любой сыновей,
пока есть сын, размер которого хотя бы N пополам,
я туда иду, спускаюсь,
и вот этот вариант.
В последний раз, когда это выполняется,
это и есть центроид.
Ну и можно доказать тогда,
что второй обязательно это либо вот этот,
либо его родитель,
это просто,
но давайте пропустим.
Да.
Да, да, да, все так.
Вот.
Да, что теперь хочу?
Вот центроиды вели, смотрите,
прикол в том, что в дереве
центроид определен либо однозначно,
либо есть два кандидата, есть две вершины,
которые являются центроидами.
Из аморфизма.
Что это определение?
Ну что такое вообще из аморфизм графов?
Возможно вы знаете, но на всякий случай напомню.
Пусть у меня есть два графа GH,
значит тогда из аморфизм
это такая функция из вершин одного графа
в вершину другого,
если выполняются два условия.
Во-первых, феет объекция,
во-вторых, она ребра
переводит в ребра,
а не ребра вне ребра.
Да, давайте напишу так,
что для любой пары УВ
значит УВ
это ребро графа
Г,
только если феет УФИ
от В,
это ребро графа H.
А вот так.
То есть произвольная пара вершин,
давайте рассмотрим произвольную пару вершин УВ,
в исходном графе это какая-то пара вершин УВ,
в новом графе, после отображения
фи, это пара фиу-фи-в.
Отверждается, что
точнее, мне нужно, чтобы эта пара была ребром,
если только эта пара ребро в новом графе.
Если это ребро, то это ребро,
и наоборот, если это ребро, то это ребро.
Тогда вот это изоморфизм.
Но по сути, это просто перенумерация
графа.
Есть там какой-нибудь вот такой
граф,
где вершины как-то занумерованы.
И есть другой граф, который там
как-то по-другому нарисован,
вершины как-то по-другому
занумерованы,
и спрашивается, это изоморфинная графа или нет.
На маленьких картинках понятно,
что это не изоморфинная графа,
там можно вот это 1 отобразить в 3,
3 в 2, ну и так далее.
Можно сопоставить однозначные вершинки так,
чтобы ребра сохранились,
и ничего нового не появилось.
Но в общем случае,
если у вас есть два просто произвольных больших графа,
и вас спрашивают, они изоморфинные или нет,
то пока что
никто быстро решать эту задачу не умеет.
К сожалению.
Там есть какие-то
квазиполиномиальные алгоритмы,
даже не N в степени log N,
но это все равно сверхполином,
это не N в степени константа даже,
даже не N в пятый.
Так что вообще говоря, в произвольном случае
эта задача пока что считается трудной,
про нее непонятно, насколько она простая,
можно ли ее за полином разрешать.
По двум графам понять, они изоморфны или нет.
А про деревья это можно сделать
и довольно просто.
Вот.
Хотим теперь два дерева проверить на изоморфность.
Давайте начнем с корневых деревьев.
Проверка корневых деревьев
на изоморфность.
Пока мне будет удобно жить в мире,
что у меня фиксированы корни
обоих деревьев
и мне нужно чтобы корень
пережило в корень, дети корни перешли в детей,
ну и так далее.
Вот две вот такие картинки.
Мне нужно чтобы корень перешел в корень,
дети в каком-то порядке пришли в детей,
то есть у меня проблема в том,
что у меня дети не зонумерованы,
у меня есть список детей, корня.
И здесь список детей, корня.
Я не знаю, в какую именно порядку их нужно переставить,
И вот вопрос, можно ли их так переставить? Если да, то как?
Ну и так далее.
Хорошо. Давайте сделаем очень амбициозную штуку.
Давайте мы просто рассмотрим все возможные поддеревья любого дерева
и захашируем их.
В том смысле, что занумируем все поддеревья так, чтобы touching
одинаковым поддеревьем, а разным разным.
Мы хотим каждому подделеву поставить соответствую
какое-то число c, такое, что, если поддеревье изоморфенное,
то им соответственно одинаковые числа, а если не изоморфное,
то разные. Определить класс эквалентности
по изоморфизму в каком-то смысле.
что я хочу сделать, чтобы каждое поддерево теперь ассоциировано было с числом.
Ну хорошо. Давайте начнем с самых простых поддеревьев.
С поддеревьев листа, то есть вершинки без детей.
Вот если у вершин нет детей, то давайте для определенности скажем тогда,
что это поддерево соответствует нулю. Ну или это самое простое дерево без детей.
Просто одна вершина, один корень, одна точка.
Ну давайте считать, что я запустил на моем дереве какой-то ДФС,
какой-то обход, который вот так вот рекурсивно пытается всем поддеревьям
назначить какой-то число, какой-то классик эволюционности.
Давайте считать следующее, что вот есть вершина В, и для детей я уже знаю
номера классов. Там не знаю, скажем, 0, 1, 3, 0, там еще что-нибудь,
какой-нибудь 4, ну и так далее. Давайте так будет.
То есть пусть я для детей, для дочерних поддеревьев уже вычислил номер класса.
Теперь я хочу понять, какой номер класса будет у вот этого вот дерева,
у вот этого вот всего дерева вот с этими поддеревьями.
Вот. Ну идея здесь такая, что вот это поддерево однозначно характеризуется
мультимножеством вот этих вот классов детей.
То есть если я рассмотрю мультимножество 0, 1, 3, 0, 4,
то два вот таких вот дерева изоморфны, только если у них равны вот эти вот мультимножества.
Ну потому что понятно, детей можно как угодно между собой переставлять,
от этого структура дерева не изменится.
Но при этом понятно, скажем, что если у меня есть какое-нибудь другое поддерево,
где написано 0, 1, 3, 0, 4, а скажем 0, 2, 3, 0, 4, то понятно, что они не изоморфны.
Потому что, ну скажем, я обязан В отобразить на У, я обязан 0-ое отобразить на 0-ое,
ну скажем, вот это на это или вот на это.
Но второе я никуда не отображу.
И если эти мультимножества отличаются, то понятно, что изоморфизма нет.
Я не могу отобразить то, какое-то дерево будет обязательно без пары вот здесь вот.
Поэтому получается, что как бы класс эквивалентности под дерево
однозначно определен мультимножеством классов детей.
Ну давайте вот это закодируем.
Скажем, что вот это 5, новое число какое-то.
И все.
Вот.
Значит мне нужно просто теперь кодировать мультимножество.
Ну давайте я от мультимножества перейду просто к упорядоченным массивам.
Просто посорчу.
Тогда понятно, что мультимножества равны, только если их отсортированные версии равны.
То есть я от мультимножества перехожу к упорядоченному массиву отсортированному.
Ну и дальше просто говорю, что если у меня появился какой-то отсортированный массив,
то я ставлю ему соответственно какое-то новое число.
Если я такого еще не видел, то это новый класс эквивалентности с номером 5.
И все.
Вот так вот иду снизу вверх по дереву, определяю классы детей, сорчу.
Смотрю, видел ли я такой класс где-то или нет.
Если не видел, то это новый класс.
Я ему присваиваю новый номер.
И так у меня для каждой вершинки будет посчитан класс.
Давайте код напишу.
Во-первых, мне нужен будет какой-нибудь способ хранить все эти векторы.
Давайте я скажу, что это будет какой-нибудь мап из векторов в int.
Я хочу для каждого сортированного вектора хранить его номер в этой классификации.
Дальше классов изначально 0.
Как работает DFS от вершинки v?
Он сначала заводит пустой список.
Дальше проходится по детям.
Запускает DFS от ребенка.
В A добавляет класс ребенка.
Какой-нибудь там C от tu.
После этого в A валяются в каком-то порядке классы всех детей.
Дальше я ассортирую по возрастанию.
Теперь мне нужно сказать, что у меня появился новый класс к эвалентности, определяемый h.
Если это A уже есть в num, то все хорошо.
Тут нужно просто num отвернуть.
А если A нет в num, то я говорю, что num от A это класс и класс увеличен на единичку.
И после этого просто C от v это num от A.
Еще раз, я запускаюсь в вершинке.
Сначала спускаюсь в детей, узнаю у них классы.
C от tu это номер класса эквивалентности для ребенка.
Сваливаю классы всех детей в один список A.
Дальше ассортирую по возрастанию.
И говорю, что у меня появился новый класс эквивалентности, задаваемый вектором A.
Дальше просто проверяю.
Если его раньше не было в num, то есть я впервые встретил такой класс эквивалентности,
то я его завожу, говорю, что num от A это новый класс эквивалентности, равный класс UCL.
И все, в любом случае теперь у меня num от A это корректный номер класса.
И я говорю, что класс вершинки это num от A просто.
Ну и все, тогда алгоритм такой.
У меня есть два дерева, я запускаю с DFS по вот этому вот,
насчитываю здесь все классы эквивалентности.
Потом запускаю DFS вот по этому дереву,
и здесь тоже все классы эквивалентности.
И в конце просто сравниваю, правда ли, что C вот здесь равен C вот здесь.
Если они равны, то значит деревья изоморфны, если нет, то не изоморфны.
Потому что как раз я их так занумеровал все,
что изоморфным деревьям соответствует одинаковая класса,
не изоморфным разные.
Вот, значит, а сколько это работает?
Еще раз?
Да, да, да.
Мапа num, она общая для обоих деревьев, да, это правда.
Значит, а сколько работает?
Я отужаю, что один вот такой DFS по всему дереву работает суммарно за n log n.
Ну почему?
Значит, давайте поймем.
То есть тут на самом деле понятно, что какие-то сортировки, понятно,
что это работает, за какой это работает.
Тут на самом деле вопрос про то, как работают обращения к num
в условиях того, что a это вектор, а не число.
То есть у меня раньше скорее в мапах лежали какие-то числа,
какие-то простые объекты, теперь вектор лежат.
Ну тогда, соответственно, запрос к мапе будет работать не за логарифом,
а за логарифом множество время сравнения.
Потому что в мапе я как обычно как-то спускаюсь по дереву,
у меня есть ключ, я сравню его с ключом в корне,
если он больше иду туда, если меньше, то иду туда.
Поэтому у меня на самом деле время запроса к мапе,
оно пропорционально логарифму n умножить на время сравнения вектора с вектором.
Ну понятно тогда, что время работы будет вот таким вот примерно.
Лог n это глубина мапы, глубина дерева, в смысле структуры мои,
красно-черного дерева, скажем.
А a это по факту время работы сравнения,
потому что если у вас есть вектор a, вы его сравните с другим,
то время сравнения максимум вот такое.
То есть у вас есть маленький вектор a и какой-то большой вектор b,
ну понятно, чтобы их сравнить, вы все эти элементы сравниваете вот за столько,
и однозначно понимаете, кто больше, кто меньше.
Поэтому все вот эти вот запросы NUMATA работают вот за такую асимптотику.
Ну каждый конкретно работает вот за столько.
Вот дальше надо просто просуммировать все,
мне нужно просуммировать по всем вершинкам,
какая у меня будет асимптотика.
У меня будет там линия от всяких тривиальных действий, типа рекурсии,
потом у меня будет сумма по вершинам a log n,
это из-за обращений к мапе,
и плюс, видимо, a log a из-за сортировки,
потому что здесь еще сортировка, которая работает за a log a.
Ну понятно, что это доминируется этим,
я могу это просто вычеркнуть, потому что логарифм N больше, чем логарифм A.
Ну а сумма ашек, это как раз будет просто N,
потому что это сумма количеств детей у всех вершин.
Это просто N.
Поэтому сумма N log N получилась.
Ну как?
Ну ладно.
Вот, сначала был случай корневых деревьев.
А что делать с некорневыми?
Что?
Ну произвольно не подойдет, да?
Мне же нужно как бы угадать.
Да, лучше центроид.
Вот смотрите, не зря же мы центроиды ввели.
Мы знаем, что у меня есть два дерева какие-то,
то есть у них корни не обозначены,
я не знаю, куда приходит каждая вершина.
Точнее, я не знаю, что корень должен быть в корень,
у меня нет корней.
Ну давайте я переберу центроид.
Я знаю, что их здесь максимум 2, а здесь максимум 2.
Давайте я переберу центроид здесь и центроид здесь.
Подвешу за них и скажу, что я ищу изоморфизм корневых деревьев,
точнее проверяю наизоморфность два корневых дерева,
где в первом корень это C1, в другом корень это C2.
Вот, ну и все.
Корневые я умею проверять наизоморфность.
И понятно, что центроид обязан перейти в центроид.
Я не знаю, в какой именно из двух,
то есть здесь есть два центроида,
я не знаю, в какой именно из двух.
Давайте переберем, давайте угадаем,
как образится вот этот чувак, в этого или в этого.
Два варианта переберем.
Если хотя бы в одном сработало,
если нашелся изоморфизм, то значит деревья изоморфны.
А если нет, то значит этот центроид некуда отображать,
его невозможно отобразить в центроид,
сохранив изоморфизм.
Значит и вообще изоморфизма нет.
Потому что понятно, что...
Еще раз?
Но если их два в обоих,
если их по два в обоих деревьях, то наверное да.
Сейчас, сейчас, погодите, склеить...
Нет, я его все-таки не стал склеивать.
Потому что...
Ну то есть смотрите, если они разные какие-нибудь, да...
То есть вот, смотрите,
вот представьте, что у вас вот какая-то такая картинка,
ну и там что-то вот здесь еще подвешено.
Тогда если вы их склеите, то они станут изоморфны.
А если не склеивать, то они изоморфны.
Поэтому лучше не склеивать, мне кажется.
Вот.
Вопрос есть?
Тогда все. Всем спасибо.
