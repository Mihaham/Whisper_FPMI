Всем доброго вечера! Вот мы снова встретились, я не знаю, в какой раз уже. На сегодня и вообще
за любое время. Мы с вами сегодня будем говорить про куду. Это как раз, вы не поверите, из тех
историй, которые я у вас веду, это наиболее приближенные, кто лучше на работе занимается,
наконец-таки в какой-то веке. И у нас будут четыре блока занятий, четыре занятия, будут четыре лекции,
четыре семинара. Сегодня мы с вами поймем, почему люди пишут на видеокартах, а на практике мы с
вами уже будем рассматривать какие-то решения именно задач. Возможно, кстати, что задачи можно
будет писать как на плюсах, так и на питоне. Это будет некоторым большим преимуществом.
Что, там все в порядке? А, просто камера кодит, не то смотреть. Господи, как же странно она. Ну ладно.
В общем, давайте вопрос такой. Кто-нибудь пытался хоть когда-нибудь разбираться с тем,
как работает код на видеокарте? Соусов, да? То есть, было такое. Ну вот, ну мы с вами все-таки научимся
немножко пробовать на видеокарте, плюс, возможно, успеем посмотреть какие-то дополнительные библиотеки,
то есть, если мы на лекциях будем двигаться достаточно быстро, возможно, я принесу даже
что-то интересное. Значит, что мы узнаем сегодня? Чем процессоры отличаются от видеокарт? Тема
нашей сегодняшней вещи. Дальше. Знаете такую вещь под названием закон Мура? Вот. Поймем,
как он преобразовался для видеокарт. То есть, вот. И дальше мы поймем, как ускорять программу
на видеокарте так, чтобы они работали быстрее. И последняя вещь, которую мы знаем из всего того,
что происходит, как использовать всю мощность на видеокарте. Я сразу скажу, что всю мощность на
видеокарте тяжело использовать, если особенно вы не понимаете, как устроена архитектура
видеокарты. То есть, если вы можете писать на обычных процессорах код и не задумываться,
как там все устроено, хотя все равно выравнивание так или иначе нужно, то для видеокарты нужно
разбираться, как это все работает. Вот. То есть, это очень важно. Вот. Это наш блог. Значит, и мы с вами,
мы этим занимаемся 4 недели. Так. Давайте начнем с того, что поймем, что такое GPU. Кто может
попробовать сформулировать? Да. Ну, замечательно. Аббревиатуру мы умеем расшифровывать. Что это такое?
Да, гениально вообще. Теперь посуществует. Да, процессор, отвечающий за графику, если грубо
говорить. Давайте сначала сформулировать определение центра Processing Unit. Это электронная
схема, разработанная для определения операций в произвольной компьютерной программе. То есть,
это процессор общего назначения. Что такое GPU? Это Graphic Processing Unit. Это специальная
электронная схема, разработанная для выводов изображений на экран преимущественно. Так
называемый рендеринг. Вот. В компьютерах за вывод информации на экран занимается отдельное
устройство. Как мы обычно его называем? Огромче. Да, молодцы. Видеокарта. Или по-другому еще ее
называют видюхой. Или GPU. Вот. Ну, давайте поймем, с чего все началось. Сейчас будут первые
вычисления. Не переживайте. Разберемся с ними. Значит, с чего все началось? 2D отрисовка объектов
занимает немного ресурсов. То есть, представьте себе, вы пишете инди-игрушку в 2D. Давайте
поймем, почему отрисовка 2D графики не очень тяжелая задача и может быть выполнена на центральном
процессоре. Давайте прикинем это. Да, давайте посчитаем. Количество пикселей по каждому, по каждой
измеренности, это о большое отн. Наверное, все согласны. То есть, всего количество пикселей у нас
о отн квадрат. Давайте посчитаем количество памяти, которое нам необходимо перегонять на
видеокарте. Ну, за единицу времени. За одну секунду. И поймем, соотносится это с высшительной
мощностью процесса. Значит, все это началось в 80-х годах. Вы, возможно, слышали, есть такая
приставка Nintendo Entertainment System. Она уже у нас называется Dendy. Так вот, если мы с вами говорим про
Dendy, то разрешение экрана, которое она позволяет выводить, это 320 на 240. То есть, тогда такие
мониторы были. Это сейчас у нас уже вот эти вот устройства имеют разрешение 1920 на 1080. А вот тогда
еще не было такого. Ну и, в общем, давайте считать. У нас с вами 320 на 240. Хорошо. Это количество
пикселей. Дальше нам нужно посчитать, что нам необходимо посчитать, чтобы оценить объем памяти,
который нам нужно перегонять за одну секунду. А что это такое? Это сейчас так. Это сейчас так.
Смотрите, у нас сейчас каждый цвет, это по факту RGB, он занимает 8 бит или 1 байт. Тогда процессоры
были такие, что они максимально умели отображать 256 цветов. То есть, на самом деле у нас здесь 8 бит.
То есть, это у нас с вами получается, да, 256 цветов я напишу. Так, дальше. Ну, что еще умножить надо?
Да, на частоту. Как вы думаете, частота какая? Вы не поверите. Ну, сколько FPS? Ну, зависит от
экрана. Ну, вообще, не поверите. Не поверите, в те времена тоже было 60 FPS. I'm believable. Просто там
каждый второй кадр пропускался. Да, да, да. Ну, что? Давайте считать. Рубрика калькулятор. В уме мы не
будем считать. Ну да, как раз с этим и связано, что нам нужно было отрисовывать экран. То есть, у него
была передняя стенка и у него есть задняя стенка. То есть, пока за один кадр отображается, на заднем
кадре рецентризуется изображение. Только VGA, экран первый, который появился в 87-м году, у него было
разрешение 640 на 480. Так, блин, короче, это все было сделано для одного курса, поэтому давайте
посчитаем. 320 на 240. На сколько? На 60. Получаем 4608. Мегабайт в секунду. Это биты,
если что. Я в биты перевел сразу. Ну, что? 4 мегабайта в секунду. 80-е годы. Так, вопрос, какой мне запрос
Google отдать, чтобы понять, нормально это или нет. Не, все просто. Процессор деньги.
Частота процессора. Да, мы приблизительно в этих объемах работаем. В целом, говорим, что один байт
за такта перегонять мы сможем. То есть, в принципе, получаются одинаковые числа по порядку. То есть,
возможно, где-то лагает. Ну, наверное, если тут вместо 60 поставить 24, у нас приблизительно
сойдется. Но, опять же, не надо воспринимать это как истинно в последней инстанции. Не, ну,
просто мы отрисовку делаем в 24 кадра в секунду. То есть, мы здесь положили все в 60. Все, отлично.
Но. Тут есть одно но. Это было 80-е годы. Переходим в 90-е. Что у нас появилось в 90-х? Ну, ладно,
геймбой. Плейстейшн появилась. Сега появилась в 87-м, 80-м. Появились Плейстейшн 1. Значит,
всякие замечательные приставки, которые. Ну, у нас же мощный процессор. Давайте в 3D. Ну,
что? Давайте в 3D. Как у нас с объектов 3D отрисовываются? У нас есть сфера. Как
она отрисовывается? Полигон треугольничками. То есть, нам нужно покрыть всю сферу треугольничками
маленькой частоты. Ну, чтобы сферу отрисовать. И представьте себе, что эта сфера у нас во весь
экран. То есть, нам нужно для каждой точки сферы определить, трисуется она или нет. То есть,
нам нужно переднюю половину сферы отрисовать, а заднюю половину сферы убрать. А? Ой,
рейтрейсинг сейчас появился только в современных видеокартах. До этого рейтрейсинг это вообще была
неподъемная задача. То есть, она алгоритмически была сложно разрешена. Ну вот, смотрите, что у
нас получается. У нас получается следующая вещь, что нам нужно отрисовать площадь сферы,
приблизительно пикселей. Площадь сферы чему равняется? Четыре пер квадрата.
Сделаем мысленную замену. Сфера у нас весь экран зафигаичен. То есть, каждый пиксель должен
отрисовывать это всем изображением. Ну давайте считать, что у нас получается. У нас с вами еще
происходит фазовый переход на то, что мы все-таки хотим играть с вами на VGA экранах. То есть,
у нас получается 640 на 480. Процессоры у нас какие с вами? Восьми битные или какая частота битности?
Здесь уже 32-битные процессоры появились. Сега 16-битная. Умножаем на 60 кадров в секунду.
А, еще на 4, на 3, на 3,14 надо умножить, потому что мы хотим отрисовывать эти объекты. Так,
ну что, считаем. 640 на 480, на 4, на сколько?
Почти гигабайт. Так, ну чего, что делать? Так, какой запрос нам нужно задать в интернете для того,
чтобы... Так, еще один запрос. Зайдем в PDWQ.
34 МГц. Упс. Ну, смотрите, зато хоть что-то
у нас совпало. Видите, пропускная способность шины. Ну, в мегабитах, правда, здесь мы в мегабайтах
посчитали. Поэтому, как вы думаете, я, к сожалению, не знаю, видно тут сверху или нет, как выглядят
первые 3D-игры. Так, контент... Да, ну, то есть вот так вот выгляделы раньше игры. Не поверьте,
я даже играл в нее, в детстве, когда был. Да, то есть нам нужно какое-то отдельное устройство,
которое отрисовывает все на экран. Трехмерные модели. Это, смотрите, это мы еще не считали все
по вокселям. Там порядка куба получается. Нам надо сделать проекцию в 2D, хотим 32-битную систему.
Да, видите, тут еще разрешение экрана 320 на 240. А так бы нам надо было все гонять это все на таких
экранах. Вы не поверите, кстати, у Кармака в 2001 году уже был FullHD-экран. Ну, у создателя DOOM или Quake,
я не помню. Ну, вот известный. А? А, да. У него был реально FullHD-экран с электронной трубкой в 2001 году,
на котором XP стояла. Да, то есть тогда уже такие мониторы были. И, соответственно, мы понимаем с
вами, что у нас возникают проблемы, и нам нужны графические ускорители, то есть отдельные
программы, которые вычисляют мощность нашего процессора. Вот, значит, и тут возникает следующая
вещь, что возникает такая популярная видеокарта, называется графический ускоритель, который ставился
отдельно под ПК. И этот ускоритель называется, по-моему, Voodoo оно называется. Я точно всегда забываю.
Типа 3DFix это компания или видеокарта. По-моему, 3DFix это компания, да. 3DFix компания. Значит,
я не знаю, вижу на слева, значит, на экране изображена игра Need for Speed.HotPirates 3. Это по факту
первая игра NTS, в которой появились копы. До этого их не было. Вот. И из-за того, что эта игра появилась,
она сделала небольшой фурор. И вот смотрите, как выглядит слева картинка без видеокарты,
без использования этого чипа, а справа то, как она выглядит с использованием чипа. Найдите 10 отличий.
Это, да, это один и тот же кадр, просто слева левая половина без ускорителя, справа с ускорителем.
Освещение лучше, видите, модельки более прозрачные, деревья лучше отрисованы и так далее.
Да, к сожалению, плохо видно. Давайте я в чат скину презентацию после, там можно будет
увидеть более детально картинку. Тут, видимо, из-за того, что экран светит, и возможно,
это плохо видно. Мы, конечно, можем поправить экран, но свет, освещение...
Видите, прямо явная разница между этими. Я тоже, как сказать, обалдел,
когда это все поставилось. Правда, у меня эта игра уже была в 2006 году или 2007, не помню. И тогда
там реально был патч, но суть в том, что тогда центральные процессоры уже были достаточно мощны,
и уже можно было на каких-то дискретных видеокартах это гонять. Ну, не дискретно,
но в встроенных видеокартах. Ну, я, типа, когда я поставил этот патч, увидел, такой, вау,
оказывается, эта игра такая крутая, а не полигональная, заговаривающая, извините. В общем,
компания 3dfx была очень популярной. Вот, чтобы вы понимали это, представьте себе, что если бы
сейчас на рынке видеокарт был бы еще один игрок, крупный игрок. Ну, и сейчас у нас два крупных игрока
на видеорынке. Значит, конкуренты догоняли, появилась компания, такая называется NVIDIA. Она
придумала механизм шейдеров. Что такое шейдер? Это программированные модули на видеокарте. Модуль
для вычтения света и цвета. Вот. И была другая компания, Silicon Graphics. Возможно,
кто-то из нее, принес, слышал. Никто не слышал? Ага, Пелевина читали? Ага, оно самое. На, в поколении
EP прочитайте, там очень большой опус, ну, небольшой там такой, есть опус про Silicon Graphics. Это стандарт
OpenGL, Open Graphical Language. В общем, они дали API для доступа к функциям рендеринга к GPU. То есть,
раньше можно было написать код на OpenGL и все начало работать. Ну, в общем, появились два крупных
конкурента, которые в итоге вытеснили эту компанию на рынке, потому что они начали по факту
предоставлять аналог Open Source решений, а 3dfx начала выпускать карточку Voodoo, Voodoo 2, Voodoo 3,
а дальше они решили, что-то у них пошло не так. Да, а еще какое время на рынке было? Это было
начало нулевых годов. Экскурс в историю. Что было в начале нулевых годов? Да, Crack.com был.
Собственно, это кризис, который был вызван тем, что компании, которые были на рынке, на финансовом,
и пузырились тогда. То есть, любой сайт с тем номинованием dot.com там поднимал капитализацию
вашей компании очень сильно. В итоге понятно, что за этим мало что стояло. Там были финансовые
скандалы и так далее. В итоге финансирование резко сократилось. Собственно, понятно,
что такой проект уже был неинтересен, когда вырастали другие гиганты. Кстати, такой тоже
экскурс в историю. Как вы думаете, NVIDIA на чем зарабатывает сейчас? Большую часть своей прибыли?
Нет. Это есть. Просто они сейчас уже ушли в другую сферу тоже. Они пытаются прорабатывать именно
решение для искусственного интеллекта. За этим, скорее всего, будущее. Вот как ни странно,
год назад я еще не мог такого сказать, когда я вел занятия, но, сами понимаете,
развитие современных технологий сильно изменил этот тренд. То есть, видели,
то есть, там, ЧАД-GPT появился модель. Дальше появился всякие диффузионные модели,
которые красиво рисуют изображения. Да, они самые. И они очень сильно сбустонули этот рынок.
То есть, реально сейчас генерация изображений по факту уходит уже на это дело. Вы сейчас можете
видеть уже, что некоторые обложки и так далее генерируются уже при помощи нейросетей на видео.
Вот. Так что, видите, уход в другое направление сильно активно развивает. Ну, в итоге 3D
Fx Mankrot, ну, это как бы часть истории, при помощи которой появились вот эти графические
ускорители. То есть, у нас есть две компании, NVIDIA и Echelon Graphics, OpenGL. И здесь мы должны
немножко поговорить про компьютерную графику. Совсем немного. Это процедура рендеринга экранов
в OpenGL, в первом примитивном формате. То есть, у нас, смотрите, подается набор вершин треугольника
для того, чтобы отрендерить их. То есть, нам нужно карту нормальной понять и отрисовать по факту
поверхность треугольника таким образом, чтобы поверхность фигуры, чтобы она отрисовывалась.
Вот. Дальше, после того, как мы определяем это все дело, смотрите, здесь синий слайд на экране. Он
говорит о том, что этот модуль программируемый. То есть, мы можем написать код на языке шейдеров,
который сделает у нас всю эту процедуру. Дальше у нас возникает растеризатор. Он по факту,
у вас вот эта вот градица фигуры, вы берете и примените заливку черным цветом. После этого у вас
есть фрагментный процессор, который говорит, что для каждого кусочка этого пикселя вы можете
либо наклеить свой цвет какой-то, либо наклеить какую-то текстуру. И это вы делаете руками.
А после этого вы берете эти фрагменты и проецируете на 2D картинку с определенным
кропом. Вот такая процедура. То есть, у нас есть два модуля, которые позволяют выполнять какие-то
операции. При этом программируемый модуль работает с матрицами 4х4. Почему это так? Я не знаю,
насколько у вас был масштабный курс по геометрии. Знакомы ли вы с таким понятием,
как проективная геометрия? Небольшой экскурс. Мы работаем с вами в оптической среде. У нас
экскурс кольную физику. Так, узнаете тему? Что с этими? Они попадут в одну точку.
Это собственно линза. Мы знаем, что параллельные лучи, которые идут в прямую, при перещении линзы
попадает фокус. Это фокальная прямая. Нам нужна тип геометрии, которая умеет справляться с этими
всякими преобразованиями. Нам нужно сделать так, чтобы параллельные прямые все-таки пересекались.
Желательно, чтобы еще одни пересекались в одной точке. И этим занимается как раз проективная
геометрия, которая говорит некоторые постулаты, что все прямые пересекаются между собой. При этом
существует, если у нас есть пучок параллельных прямых и в клидовой геометрии, то они пересекаются
в одной точке. Обязательно. Зачем нам нужна проективная геометрия? А вот он пример. У нас
параллельные прямые пересекаются в одной точке. Чтобы у нас
картинка слева была отождественна с картинкой, которая справа. При этом важно, что все параллельные
прямые пересекаются на... смотрите. Где вот эти лучи пересекутся? Ну, давайте я не буду проводить.
В общем, они тоже пересекутся на фокус. То есть любые два пучка параллельных прямых, точки перещения
всех параллельных прямых, лежат тоже на одной прямой. И вот эта прямая здесь называется покальной.
А вот эта прямая, с другой стороны, называется бесконечно удаленная прямая.
Вот. И оказывается интересное свойство, что вот эта геометрия с этими двумя постулатами,
их на самом деле может быть больше, ультворяет следующее свойство, что преобразование в этой
геометрии можно задать четверкой. Здесь она, вот она. Вот. То есть это вот такая вот набор четверки
координат, где они эквивалентны следующим свойствам. Альфа х, альфа у, альфа з, альфа т. Ну, если мы
говорим про тракт нервную плоскость. То есть количество координат здесь будет в 4, а не 3. Вот. Я,
честно, не помню, вот сейчас вылетел из головы, t равное нулю или t неравное нулю отвечает за бесконечно
удаленную прямую. Но она здесь есть. То есть здесь как раз два случая, t равняется нулю и t не равняется нулю.
Да. Да, да, да. Все, я как раз вы задали вопрос, я вспомнил. Смотрите, значит t неравное нулю это
обычно Евклидова, а t равное нулю это бесконечно удаленное. Да, это по факту флаг. Смотрите,
почему не наоборот, потому что мы можем домножить всегда на такой коэффициент, чтобы вот эта штука
равняется единице. То есть когда мы фиксируем канонический вид этой точки, то здесь единичка и здесь
у нас получаются координаты. Вот. А иначе, если мы t равное нулю, ну, типа эти, получается, бесконечно
удаленные прямые будут находиться на плоскости. То есть там будет кодироваться бесконечно удаленная
плоскость. Ладно, не суть важна, это просто экшверт геометрию. Мы с вами понимаем, что любое
линейное преобразование в Евклидовой геометрии, в Евклидовом пространстве, это матрица 3 на 3.
Перемножение на матрицу 3 на 3. В проективном пространстве это будет перемножение на матрицу 4 на 4.
А? Это коэффициент, типа, который позволяет нам показать, мы переходим в бесконечно удаленную
прямую или не бесконечно удаленную прямую? Или что? А? Ну, там ломается немного геометрия, то есть там
нужен относительный эффект. Ну, можно воспринимать как вот такой флаг, типа, t равное единица это
бесконечно удаленная, t равное нулю бесконечно удаленная. Наоборот, t равное единица это не бесконечно
удаленная, t равное нулю бесконечно удаленная. Просто там точки будут соотноситься, то есть на
бесконечно удаленную прямую точка 0,1,4,0 это будет привязать такая же точка, как 0,2,8,0. Вот и все. То есть это
будут равные точки по координатам. Ну, а как бы, а что у нас происходит? Мы изображение снимаем в камере.
Дальше нам нужно то, что мы сняли на камеру, образно говоря, отрендерить на экран.
Ну, вот. Ну, камера собрала, то есть она снимает какое-то пространство, и дальше нам
нужно его спроецировать на плоскость для того, чтобы вывести его на экран.
В смысле? Ну, мы же через камеру это все попускаем.
Ну да, вот пример. Кубик. Вот они, пучки параллельных прямых.
Здесь мы их проецируем на плоскости. Вот мы получаем вот этот кубик. Так-то там прямые параллельные,
а здесь они вот не параллельные. Вот, смотрите, поставим сюда сериент по физике. Ставим пульт.
Хотим пульт отрендерить на экран. Ну, с небольшим поворотом. Да, что у нас происходит? Мы берем,
и вот эти вот лучи, вот у нас тут источник света, вот тот камера, которая стоит, и вот этот источник
света у нас проецирует все на экран. Вот, это проективное преобразование, которое выполнит
проекцию на доску. Собственно, вот этот луч, пучок параллельных прямых, который проходит,
он должен пройти как раз вот с этими параллельными, грамотно обработать параллельные прямые для
того, чтобы у нас было записано преобразование. Опять же, я рассказываю это немножко на
дилетантском уровне, возможно. Там за деталями нужно идти на курс компьютерной графики. Там про это
детали расскажут. Ну да. Сейчас. Вскречу все время хороший вопрос. Надо почитать,
что с ними происходит. Возможно, это, как эти прямые называются, которые в одной плоскости лежат?
Забыл. А, компланарные, да? Ну, по крайней мере, можно попросить, что любые две компланарные
прямые пересекаются. Ну вот, скречу все, это хороший вопрос, кстати, его можно задать даже
Google. Там, я думаю, ответить на этот вопрос. А? Так, ладно, смотрите, то есть мы поняли,
что у нас преобразование это матрица четыре на четыре. Более того, смотрите, как можно использовать
матрицу. Здесь пайплайн преобразования этого всего. То есть мы снимаем объект на камеру,
точнее, мы располагаем объект на плоскости в какой-то точке, да? При этом у нас есть какая-то
камера, которая находится здесь. Что мы делаем? Мы с вами обращаем объект, после этого мы располагаем
камеру на экране, и нам нужно перевести наш кубик из пространства локального в пространство глобальное,
в общую систему координат. Это некоторое проективное преобразование, которое записывается матрицей четыре на
четыре. Дальше, что у нас происходит? У нас мы должны переключиться в пространство, в начало координат
камеры. Это еще одна матрица четыре на четыре. Дальше мы должны сделать проекцию, и это тоже матрица
четыре на четыре. Ну и дальше мы делаем кроп нашего изображения, который оставляет нам наш объект.
Кажется. Зачем я это рассказываю? Включаем смекалку.
Ну да, ну центр камеры, то есть у нас камера направлена вот на меня. Мы переходим в пространство
координат камеры, которая сейчас меня снимает. Вот и дальше вот сейчас что-то там показывается.
А? Да, для наших целей. Да, перемножение матрицы долго, но видеокарты сделаны так,
что эти матрицы быстро перемножаются. То есть у нас с вами была, ну я надеюсь, что была,
классификация по флину. Было такое? Это буковки с, и, э, м, д.
Так, instruction
data. Было? Ой. Так, смотрите. Кто где находится? Вот сразу давайте еще раз уточним. Здесь
находится цепу однопоточная. А кто находится в multiple instruction single data?
Много инструкций на один источник данных.
Ну, я бы так сказал, это Critical Runtime OS. То есть точки, в которых нужно, это операционный
системы реального времени, в которых событие должно приходить по расписанию. То есть этих
команд может быть много, они должны приходить сюда. Так, что относится к multiple instruction,
multiple data? По стеку технологий? А? Нет. А? Да, так, вопрос. Почему дедлайн? В какой домашке у
нас дедлайн? Ага, M5 сюда нах... Кадуб сюда идет. Ну и, в общем, все, что происходит здесь. Вопрос,
где видеокарта? Угу. Видеокарта находится здесь. Мы можем взять набор треугольничков маленьких и
параллельно перемножать их. А? Все, хорошо. А теперь рубрика смекалка. Она заключается в том,
как мы это можем использовать в наших целях. Видеокарта умеет быстро перемножать матрицы.
Да, если нам нужно перемножить матрицы, давайте выводить пиксели на экраны, ну, грубо говоря,
флоты на экраны. Положим огромный болт на то, что у нас будет выводиться на экране, зато матрицы
посчитаются. А? Кто поможет перемножить? Ну, есть, просто... Сколько у нас процессоров обычно? Ядер?
8, да? Так, кто знает какую-нибудь видеокарту? Хорошо, РТХ 4090, number of course.
Мне кажется, я ответил на вопрос. Ага. Да, мы, кстати, будем считать максимальную пропускную
способность видеокарты, но это не сегодня. Так, сейчас звонок пойдет. Так, ну, собственно, до этой идеи мы
догадались. Давайте ничего не изображать, а использовать матрицы для вычислений. Ну, как говорится,
сим для нас есть как раз. Эта одна векторная инструкция выполняется на векторе значений в один
такт времени. Когда мы будем смотреть архитектуре видеокарты, мы прямо это увидим. Так, ну, сказано,
сделано, как говорится. Появилась специальная обездка, она называлась в свое время Bruck,
которая позволяет выполнять векторные операции. Даже если мы с вами опять же перемотаем, есть
специальная статья даже. Кстати, вы умеете искать? Да. Давайте даже Сколер Гугл откроем.
Это специальный сайт для поиска статей.
Сейчас, я надеюсь тут.
Что, нас в Гугле забанили?
Мы ищем статью оригинальную. Ну, про этот инструмент. Да, нас в Гугле забанили.
Вот оно.
Bruck for GPU. Ну, и здесь можно почитать, как это все делалось и как выглядит код.
Что выдает нам, что это обертка над графической памятью?
Смотрите, тип, который используется. Float 4. Да, да, да, как раз. И видите,
сколько тогда уже можно было сделать гигафлопсов. Это количество операций в секунду.
Ну, кажется, что сейчас 4 ГБ это не очень много, ой, 4 ГГц. Но статья была написана в 2002 году, ну или 2003 году.
Да, а тогда процессоры, ну, по-моему, у нас в семье был Intel 3 Pentium, у которого частота была 566 МГц.
А тут выдают 4 ГФлопса. Ну, и как бы здесь вот бенчмарки получаются с ИЦПУ,
которые выдаются. То есть видите, на каких-то, даже на матричных перемножениях, типа в полтора,
в два раза есть ускорение. Ну и что, как вы думаете? Дальше все поперло после этого. Значит,
Брук это программируемый интерфейс. И как он выглядел в свое время, это был аналогичный
компилятор а-ля MPICC. Все, я надеюсь, с ним уже все познакомились. Ну и, как говорится, закон Мура
изменился. Значит, раньше количество схемов транзисторы увеличилось в два раза. Ну, то есть,
и это работало до Pentium-ов четвертых, по-моему. То, что частота процессора увеличилась в два раза
за 24 месяца. А сейчас частота процессоров меняется или нет? Практически не меняется,
все пошли многоядерность. Так вот, для видеокарт закон Мура до сих пор еще выполняется по скорости
вычислений. Возможно, что скоро это изменится. Вот в бенчмарке, пожалуйста, количество операций
перемножений в секунду, как менялась эта динамика для CPU, для Pentium A4, как это менялось для видеокарты
вида ATY и как это менялось для видеокарты NVIDIA в свое время. Кто знает, что такое ATY?
Да, который выкупил AMD. Молодцы, историю знаю. Вот, и здесь понятно, что у нас появился фреймворк,
который позволяет быстро вычислять все это дело. А компания NVIDIA подсуетилась и решила,
а почему бы нам не сделать это все как задачу общего назначения. Давайте сделаем это все как
задачу общего назначения. Первая модель данных у нас была в том, что у нас были с вами наборы
входных регистров и была фрагментная программа Shader, который вычислял этот цвет для изображения.
Еще на него вход подавался. На него подавались на вход текстура, константы и регистры. На выходе
мы выдавали некоторые выходные регистры. Ну, как эту модель можно изменить? Давайте скажем,
что вообще входные регистры нам не особо важны, нам важны передать элементы массива. И для каждого
элемента массива у нас должен быть свой индекс. Сделали. Значит, у нас появился на вход,
каждый программе приходит номер потока. Номер потока вам это что-нибудь напоминает? В MPI rank
процессор. Здесь такой же механизм, поточная программа. Ну, дальше понимаем, что нам нужно
куда-то выводить всю память, поэтому давайте мы вместо выходных регистров напишем здесь
глобальную память, то есть создадим память видеокарты, в которой мы будем скидывать массивы. При этом
выходные регистры, тут есть обратная совместимость для того, чтобы отрисовывать графику. При этом мы с
вами понимаем, что некоторые опции, которые нам нужны, они должны отрисовывать какие-то
локальные участки памяти, то есть вычислять локальную операцию, например, сложение соседних
элементов или вычисление произвонок. Производно это взять себя, вычесть, как сказать, и следующего
момента времени, вычесть текущий момент времени, поделить на время. То есть нам нужно соблюдать
свойство локальности, что если мы берем данные из соседнего куска, то они должны браться намного
быстрее, чем из текущего. Вот для этого возник механизм разделяемой памяти. Так сказать, не путать
с разделяемой памяти в курсе операционных систем. Это немножко другая вещь. Вот, и в итоге вот
такая архитектура нам позволила соорудить куда. То есть вот как раз вот в такой парадигме мы с
вами будем работать. В нашем курсе, правда, мы не будем рассматривать текстуры. Наша цель все-таки
для вычисления это все использовать, но в целом можно загружать текстуру. В итоге у нас появилась
куда. Расшифровывается это как Compute Unified Device Architecture. То есть это архитектура процессоров,
как сказать, унифицированная архитектура для задач общего назначения. То есть мы говорим
следующее, что это архитектура, которая позволяет использовать графические процессоры, как а
процессоры общего назначения. Вот первая версия куда вышла в 2007 году. То есть эта технология уже
16 лет. Тут можно узнать последняя версия. Ой, извините, это не то. Куда Latest Version.
Последняя версия куда 12.2. Вот, 12.2. При этом максимальная версия куда зависит от драйвера
видеокарты, который у вас стоит. То есть ставите драйвер видеокарты. Если у вас там драйвер не слишком
новый, то новую версию куда вы не поставите. Последняя версия куда 12. Она вышла в 2002 году для
поддержки карт а-ля RTX 40 что-то там. Понятно, что у них есть Compute Capability, то есть архитектура
пронумерована ID-шниками. Вот, сейчас последний Compute Capability, который есть, это 8.9. То есть тоже
можно открыть это все дело, посмотреть. То есть 8.9 это Latest, 8.6 это Ампер. Архитектура Ампер,
которая 30.90. Ну и так далее. То есть у них вот это Compute Capability есть разные свойства,
которые можно отслеживать. Вот. И в зависимости от этого некоторые алгоритмы, кстати, будут меняться
на практике. Реализация алгоритм будет меняться на практике. Сейчас секунду, я достану зарядник,
чтобы у нас тут презентация не накрылась. Пока можно вопросы задать какие-нибудь.
Хороший вопрос, но на видеокарте нельзя все вычислять. То есть там вычисляются непроизвольные
действия, грубо говоря. Вот то, что я сейчас мышкой навел на определенную часть экрана, допустим,
сломал проектов. Ну как? Как это не значит, что совсем точно. Она будет эмулировать большую
часть операций. То есть вы не поверите, что если использовать CUDA как процессор общего
назначения, вот прямо как есть, то скорость будет в 20 раз медленнее, чем на обычной CPU. То есть мы
делаем достаточно большое количество маленьких ядер, которые вместе дают кумулятивный эффект,
а не один. Процессор дает такой эффект. Вы же не пишете код на конкарнте каждый раз?
Ну вы же не пишете код, учитывая то, что у вас куча ядер сразу параллельно будет запускать его?
Ну он там не слишком сильно оптимизирует.
Ну вот, значит это не дает профита. То есть это специфичные задачи. То есть это векторные
преимущественные задачи. Вот вам надо два массива сложить. Вот, пожалуйста, пишите на видеокарте,
это будет в разы быстрее. Ну как в разы быстрее? Вам нужно будет еще скопировать, правда, память
центрального процессора в память видеокарты. Ну это уже такая тяжелая операция. Так,
так, мы выяснили про CUDA. Давайте теперь поговорим про базовое понятие, которое есть в CUDA.
То есть у нас есть память. И тут сразу нужно некоторые терминологи вводить, потому что она
на самом деле есть в коде. Значит первое понятие это host. Host память это run. Это оперативная память
процессора. Она именно называется host память. Два, device memory это память видеокарты.
То есть когда вы видите вот такое понятие D to H или device to host, куда мы копируем информацию?
Из видеокарты в оперативную память. Host to device либо H to D это у нас рама на видеокарту.
Понятно, да? Просто вот вы прямо увидите, что образно говоря есть в коде CUDA memcpy. То есть
есть вот такая вот константа, которая говорит, куда именно копировать память.
Янам, так сказать. Потоки. Вот с потоками тут вообще интересно. Значит давайте поговорим
следующее. Тут на самом деле не точное определение. Я буду немножечко разносить это все дело тоже
на слайде. Значит есть логическая абстракция, есть физическая абстракция. Значит первое,
что есть это CUDA ядро. Иногда еще называют их CUDA попугаями, потому что не понятно,
что это такое. Это одна единичка, которая может вычислять что-то. Что такое поток? Это абстракция,
которая лежит логически за вот этой железкой. То есть это одни и те же понятия. Значит дальше
с точки зрения физики мы движемся дальше. Возникает такое понятие, как ворб. Вот это самая
важная вещь, которую на самом деле нужно понимать, которую нет в классических процессорах.
Что такое ворб? Это физическая сущность, которая выполняет несколько потоков как одно целое.
То есть что это означает? Это означает, что вы на одну команду, на некоторый набор потоков,
которые у вас есть, посылаете одну регистровую команду одновременно. То есть вы посылаете,
если вы посылаете команду в ассемблерную команду, в видеокарту, вы посылаете на самом деле ее не
одному потоку, а сразу 32. Вот в одном ворпе 32 CUDA-ядра в вытекущих архитектурах. То есть если вы
берете пятый элемент массива, то одновременно вы делаете ту же самую операцию на уровне регистров
из 10, из 25 и с пятым регистром. Вот, поэтому IF с нависанием на одно на одно ядро, это не очень
хорошая затея. Потому что у вас один поток будет выполнять задачу, а остальные 30 его будут ждать.
Вот, а они потом приходят в барьерную точку. Значит, стриминг, мультипроцессор, это аналог нашего
классического ядра. Вот, это вот такая вот абстракция, которая здесь есть. То есть,
по факту, когда у нас говорят 4 ядра, 8 потоков, это по факту такой же аналог, как 4 стриминга
мультипроцессора и так далее. Вот. Стриминг мультипроцессора стоит CUDA-ядер, способный
выполнять инструкции параллельно. И при этом один стриминг мультипроцессор содержит несколько варпу.
Да. Да. Не, это CUDA-ядра называется. А вот это называется стриминг мультипроцессор. То есть,
аналог вот этого в CPU это ядро. Просто у нас в ядре может быть несколько поток на CPU.
Обычно два. Хайпертренинг это называется. Так, ну что, давайте решим задачу. Да,
правда задачу надо уже обновлять, потому что одну GTX 1080 Паша уже сдал. А? Одна, одна еще осталась.
Итак, у Паши есть GTX 1080. Он прочитал, что в нем находится 2560 CUDA-ядер. В общем, сидел,
разбирался. Он узнал, что в этой видеокарте 20 стриминг мультипроцессоров, а размер варпа
равняется 32. Вопрос, который задается в этой задаче. Сколько варпов находится в одном стриминг
мультипроцессора? Да. Смотрите, здесь у нас получается 2560. Здесь у нас получается стриминг
мультипроцессоров 32. Варпов 32. В варпе получается 32 CUDA-ядра, поэтому у нас получается что?
Не, мы получим сколько варпов?
Сколько будет 2560 на 32? 80, да. Вот. И оказывается, что в одном SM 4 варпа.
И вот это уже на самом деле ограничение. Причем очень жесткое. Представьте себе,
что вы готовите какой-нибудь, я не знаю, ужин, либо еще что-то. И вот у вас есть сковородка.
На сковороде помещаются четыре котлета. Да. Это видеокарта ограничения, то есть это архитектурно
так выглядит. То есть больше оно не переваривает. Сейчас картинка будет просто. Вот такая вот картинка,
я не знаю, видно ее или нет. Это один стриминг мультипроцессор. То есть, видите, вот они
четыре слота. В каждом из них находится вот такая инструкция под названием ворпшедулер.
Собственно, что такое ворпшедулер? Это вот эта вот такая штука, забыл уже, 8 часов вечера.
Юнит, давайте назовем так, которая раскидывает задачи на все потоки внутри варпа одновременно.
Вот там оранжевая-оранжевая прослойка есть. А вот это вот это кудоядр и кудоядр. При этом сейчас,
помимо классических ядер, есть еще и тензорные ядра, которые умеют блюстроматрицу перемножить.
Сейчас современные сети, они гоняются на тензорных ядрах, но это появилось только в
недавних версиях. При этом здесь есть кудоядра, которая умеет работать с числами с одинарной
точностью флотами, а есть те, кто работает с даблами. И запомните, если вы будете работать в даблах,
а не в флотах, ваша скорость программы уменьшится не в два раза, а в 64.
Флотами. Пользуются только флотами на видеокартах. Ну потому что особенности архитектуры такие.
Короче, про даблы забываем.
У нас по куде контроля не будет.
Да. Как-то я не любитель устраивать контрольные по практически предметам.
Вот, ладно. Теперь давайте по физике понятно процессы, что у нас происходит.
Теперь по логике. Почему нам важна логика? Потому что в логике программы будем писать.
Логическая абстракция. Значит, ворб это набор потоков, которые физически отрабатывают за один так
времени. А здесь возникает другая абстракция, которая называется блок. И она состоит из набора
потоков. Причем, смотрите, тут именно важно по высоте. То есть ворб, блок обычно бьется на несколько ворпов.
Логики, да. Но когда логика перекладывается на физику, блок будет
развиваться на наборы ворпов. То есть у нас, грубо говоря, есть массив размера 256, значит его будут выполнять за 8 тактов.
За первый такт обработается первый ворп, за второй такт второй ворп, третий, четвертый и так далее.
То есть у нас в размере блока 256 элементов. У нас вот этот выполнится за один такт времени,
вот этот пойдет на второй такт времени, вот этот пойдет на третий, на четвертый и так далее на восьмой.
Да, тут одна ассемлерная инструкция пришлется на вот эти 32 элемента сразу.
Потому что есть регистры, есть память и там еще модели управления памяти будут. Ну про это мы
в следующий раз уже будем говорить. Там сложные модели управления памятью. Вот,
значит при этом это блок. Блоки делятся на ворпы в физическом исполнении, как мы с вами сказали.
И дальше возникает еще одно понятие. Грит это набор из блоков. И грит находится обычно где-то здесь.
То есть грит состоит из блоков. При этом один из блоков выполняется на одном стриме в мультипроцессоре.
Это чисто логическая абстракция, чтобы самому не распределять задачи по этим всем вещам.
То есть вы даете, грубо говоря, набору плашек, а она самостоятельно будет
распределять их по стриме в мультипроцессор. Ну да, чтобы ручками не занимать это все дело,
и чтобы вы, грубо говоря, сказали, что у вас в процессоре 20 стримов мультипроцессоров,
поэтому объем на 40. Вы переходите на другую архитектуру. У вас там не 20 стримов мультипроцессоров,
а 86. И у вас вся логика ломается. То есть вы планировали свою программу на 20 стримов мультипроцессоров,
а у вас 86. В итоге у вас просто видеокарта будет простаивать по три четверти своих ресурсов.
Да-да, то есть когда мы задаем грит, мы задаем количество блоков, которые мы. Их можно сделать
сильно больше, чем количество стримов мультипроцессоров. И он самостоятельно будет их раскидывать.
Я не знаю, вы смотрели, видимо, вы смотрели примеры с MMP, где, ой, с OpenMP, где был параллел-4?
Где есть опция «Шедуль», и в зависимости от того, какую опцию «Шедуль» вы поставите,
у вас там перфоманс будет сильно скакать. Там можно «Шедул» поставить статик, можно поставить динамик,
поставить гайдят и так далее. Если их попереключать, то там видно, что в максимальном режиме намного
быстрее работать, чем в статике. Потому что статик вы вручную алоцируете задачи. Поэтому вручную
локацию задач не занимаемся. При этом, в логическом исполнении у нас с вами всегда для блока задается
блок IDX, а для грита задается, для потока создается thread IDX. То есть у вас каждый по факту,
вы запускаете программу, следующая вещь, вы запускаете количество блоков, количество потоков,
вы передаете это в параметры. И тогда у вас по факту создается количество юнитов,
которое равняется количеству блоков и количеству потоков. Вот это характеризуется блок IDX,
вот это характеризуется thread IDX.
Нет, мы с физикой не хотим работать, мы хотим просто понимать, что она есть.
Но кудо-ядро это железка, которая вот это все вычисляет. Ну один к одному можно сказать.
Нет, потоков у нас сильно больше. Один к одному это означает, что когда у нас есть кудо-поток,
то он потом в какое-то время попадает на какой-то кудо-ядро и вычисляется.
Да, потоков сильно больше, чем кудо-ядер.
Грит настраивается, это типа у нас есть несколько блоков.
Ну за распределение, то есть у нас каждый блок вычисляется на стриме в мультипроцессоре,
чтобы мы сами не занимались вот этим вот распределением, мы даем вот такую огромную
пачку, говорю, на раскидай сам. Да, количество блоков, количество потоков. Вот,
это вот грит. Грит состоит из наборов блоков. Да, мы по факту считаем, что у нас с вами один грит,
ну это вот все, все наше вот железо, так сказать. И по факту, ну не железо, а вот наше вот огромное
по факту сетка для вычислений. Да, и мы говорим, что в этой сетке у нас будет по факту сколько-то блоков,
то есть вот это у нас блокс, а вот это у нас третс. И каждый квадратик здесь будет отвечать за определенное
вычисление. Да, да, то есть у нас возникнет ID-шник вот здесь вот для вот этого элемента,
который мы можем использовать в программе. Ну, на разных стримах и процессорах, конечно же.
Нет, это вот, это вот весь этот квадрат. Нет, вот количество блоков здесь много.
Нет, вот это вот все, вот это вот это грит все. Грит состоит из набора блоков, то есть блок это вот этот вот,
вот этот вот прямоугольчик. Вот это блок. Так, здесь перечеркнули один блок. Так, моя любимая.
Собственно, давайте на примере огорода разберемся, как вот это вот все связано с огородом.
Да. Да. Да, Винга. Да, да, да. Так, вопрос. Что здесь стримит в мультипроцессор?
Блин, да вы, да вы гений, я скажу. На ростении от рэд, ряд в грядке, плюс-минус, можно считать за форб,
потому что мы будем проливать их. Ну, если кто поливал, там типа, линейно происходит. Грядка это блок,
ряд из грядок. Ну, собственно, весь огород наш, это грит. Так, кто играет тролля Сэма и ворпшедулера?
Ну, собственно, вот он вам стримит мультипроцессор. Ассинизатор. Вот, отлично. Да, некоторое характерное
число стримит мультипроцессоров на видеокарте и максимальную мощность вычислений,
которое можно достичь на них. Много, но. Ну, 10-12 операции в секунду. Да, с плавающими точками флота.
Лотинг операции в секунду. Ну что, 10-14. Можно выжать. Стримит мультипроцессор и блоки. Один блок
выполняется на одном стриминг мультипроцессоре. То есть, стриминг мультипроцессор на вход берет блок
и вычисляет на нем все. Ну, пожалуйста, мы вычисляем их параллельно. Вот у нас есть 86 стримок мультипроцессора,
мы можем выполнять 82 блока одновременно. Ну да, пока ждут. То есть, они по факту в очередь кладутся на
исполнение. Ну да, потоки запакованы в блоке. То есть, у нас блок идет в очередь, в которой у нас есть стриминг
мультипроцессора. Ну, типа вот задачу. Сборку на CMake вспоминаю. Что у нас там? У нас есть очередь
компиляции линковки файлов. У нас есть с вами четыре блоковые исполнения. Мы выполняем по четыре. Возможно,
у кого есть понятие threadpool. Знакомое такое? Ну, по факту у вас есть аналог threadpool, в котором
есть 82 по факту воркера. Каждый воркер умеет обрабатывать один блок. Вот. Так, последнее,
значит, что я хочу сказать? Есть ли аналог CUDA в аналоге а-ля OpenGL? Есть. OpenCL,
Open Compute Language называется. Он работает на мобилках, на CPU, на AMD-шных видеокартах. CUDA – это
все-таки анвидиевская технология. Ну и напоследок я оставлю этот слайд. И если кому будет интересно,
вот аналогия всех соответствий, которые здесь есть. Это память видеокарты вся. Вы массивки
даете в видеокарту? Вот он. А shared мы будем говорить. Это кусок, который, это на самом деле память,
которая видна внутри одного блока. Про это мы тоже будем говорить. Да, есть такое.
Ну мы про это в следующий раз уже будем говорить. На этом все. Давайте вопросы, наверное.
Потому что у нас есть ворпы, у нас есть локальность данных, которые необходимо учитывать. Тут я, наверное,
скажу, что нужно, когда мы будем говорить в следующий раз про shared memory, давайте детальнее
как раз остановимся на этот момент и посмотрим на самом деле, как, зачем вот эта вот вся абстракция
нужна. Потому что сейчас я не смогу в двух словах ответить. Но образно говоря, от модели данных просто
все будет зависеть. Вулкан – это ниже уровня OpenGL. Это низкоуровневый аналог OpenGL. Metal – это,
по факту, отдельный framework, параллельно с кудой, которая позволяет вычислять на iOS
устройствах. То есть это, по факту, та же самая вещь, только вот оптимизированная под iOS. Ну или
Abacost и так далее. То есть вот эти, вот у них там своя архитектура processing unit в ГРЭ.
Ну, наверное, да, если вы почитаете код библиотеки TensorFlow Lite, то вы увидите прекрасно, что,
собственно, там есть огромный EFIG, точнее, огромный набор Define, который определяет,
что вы делаете. OpenCL, OpenGL и так далее. Да, конечно же, все то же самое, только название второе. То
есть это второй столбец, по факту. Ну что? Ну тогда все, наверное, это. Спасибо большое.
Вроде бы все разобрали. Все отлично.
