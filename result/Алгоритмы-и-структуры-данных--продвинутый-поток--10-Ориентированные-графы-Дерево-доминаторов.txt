В прошлый раз мы с вами занимались тем, что придумывали метод Тарьяна и применяли его для некоторых задач.
В частности, в неориентированном графе мы с вами что сумели сделать?
Мы сумели найти компоненты реберной вершины двухсвязности,
ну а в качестве бесплатного довеска получились мосты точного сочленения.
Было дело, да?
Все это делалось по какой-то единой стандартной технологии.
Сегодня мы попробуем повысить планочку и найти этой же технологией, внимание, компоненты сильной связности.
Для начала тут возникает вопрос. Что же такое компонент сильной связности?
Казалось бы, тут все легко.
Потому что в прошлый раз приходилось с вами что-то страдать, доказывать, что компоненты вершины двухсвязности это оправданное словосочетание.
Что это действительно какая-то связность.
А в нашем случае что мы видим?
В нашем случае мы видим, что определение, внимание, сегодня мы живем в ориентированном графе.
И мы много будем сегодня жить в ориентированном графе.
В ориентированном графе, то есть вершины у и в, давайте так их назовем, сильно связаны.
Хочется написать слово цикл, но мы все-таки напишем, от у до в есть путь.
И от в до у есть путь.
Аж в одну строчку вместилось.
Так, а видно вообще?
А, камера вообще не работает.
А, окей.
Так, так видно вообще?
А, или в принципе так очевидно, что там должно быть написано.
Ну да.
Нет, ну понятно, определение-то известно.
Но самое приятное в нем, что то, что это отношение эквивалентности, в данном случае абсолютно очевидно.
Потому что в данном случае у нас нет никаких непересекающихся...
Потому что в данном случае у нас нет никаких ограничений на то, пересекаются ли эти пути вообще по вершинам, по ребрам, как угодно.
То есть в принципе да, могут они спокойно по ребрам пересекаться, это не принципиально.
То есть там в принципе можно даже привозить какой-нибудь пример в духе вот такого.
Вот.
То есть здесь мы заметим, что тут вы между У и В даже не выберете два ребер, даже ребер, не пересекающихся пути.
Ну вот.
Нет, ну почему жаль.
То есть как бы это нехорошо и неплохо, это просто такая особенность.
Вот.
Да, казалось бы, да, уже хорошо.
Ну собственно теперь хочется искать компоненты сильной связности.
Но как же их искать теперь?
Ну давайте вспоминать, что у нас говорит наша стандартная технология.
Стандартная технология говорит следующее.
Мы запускаем ДФС.
Мы запускаем ДФС.
Мы запускаем ДФС.
У нас образуется дерево ДФС.
Вот.
Некоторые вершины становятся, скажем, первыми в своей компоненте.
Некоторые не становятся.
И вот эти первые мы объявляем корнями под деревья в своих компонентах.
То есть скажем, если вот компоненты, то есть такими вот первыми оказались вот эта вершина, вот это допустим, вот это, ну и конечно вот это, куда же без нее.
Тут всякое может быть.
Давайте вот я тут еще чуть-чуть порисую.
Вот.
То тогда...
Ну давайте еще допустим вот так вот сделаем.
То тогда мы автоматически заявляем, что то есть компонентами у нас является вот эта, скажем, вот эта штука, вот эта штука, вот эта штука.
Вот эта штука, вот эта штука, ну и конечно вот это вот.
Вот так вот.
Вот.
Помните технологию, да?
Ну правда для того, чтобы ее применить, остается только две вещи.
Вещь номер раз.
А верно ли, что действительно внутри компоненты сильной связности будет действительно вот какой-то корень, и все остальные вершины будут именно напрямую на нем висеть?
Вот.
Но на самом деле достаточно легко показать, что да, это так.
Ну потому что действительно рассмотрим компонент усильной связности.
Жил-был ДФС.
Вот.
Ну правда да.
На самом деле надо было сделать маленькую оговорочку, что в ориентированном графе почти наверное мы не будем говорить о дереве ДФС, а будем говорить о чем.
Как вы думаете?
Не ориентированно.
Ну и направление цикличество.
Не, не, не, не, не в этом смысле.
Ну я имею в виду мы будем говорить о лесе ДФС.
Ну просто если раньше мы могли предполагать, что у нас есть компоненты связности и в каждом меже мы абсолютно независимы, здесь мы такого предполагать не можем.
Тут к сожалению все будет, то есть тут это будет лес, причем сколько в нем будет деревьев, будет даже зависеть от того, в каком порядке мы запускаем ДФС.
Потому что может быть так, что действительно мы тут запустили ДФС, а потом мы запустили ДФС от этой вершины и получилось вот, ну это не совсем то.
То есть получилось вот как-то так, а если бы ДФС запустили из этой вершины, мы бы обошли все и было бы одно дерево.
Что?
А, ну тем более, да, спасибо.
Вот.
А, ну да, такие ребра мы рисуем зеленым, да.
Ну как повезет, сейчас оно зеленое, а если бы запускали ДФС, оно было бы черным.
Вот.
Но, тем не менее, если ДФС зашел в какую-то компоненту сильной связности, вот эта вот первая вершина, то я ответу, то очевидно, что в поддеревье этой вершины будут все эти вершины.
Ну просто по лиме белых путях, правда?
Вот.
Но, но, но.
Но если только возникает вопрос, они будут идти подряд или может так произойти, что там будет какой-то, в поддеревье там мы в какой-то момент выйдем, а потом войдем обратно?
Ну нет, потому что эти вершины тоже лежат в компенсильной связности.
Совершенно верно, да.
То есть действительно, так как от этой вершины можно дойти до этой по определению компенсильной связности, то и эти, получается, тоже мы вынуждены будем к ней прицеплять.
Да, совершенно верно.
Такое может быть, конечно.
Но имейте в виду, что если вы идете из вершины в поддерево и вышли из ее компоненты сильной связности, то вы там дальше просто в нее не вернетесь.
Да.
Да, конечно же такое быть может, безусловно, да.
Ну просто тогда это будет означать, что это тоже будет первая вершина в своей компоненте, и мы там тоже ее будем аккуратно нашей технологией поддерживать.
Итак, внимание, вопрос теперь.
То есть теперь для нас самое интересное.
А как же находить?
То есть нам теперь нужно просто для каждой вершины уметь говорить, она является первой в своей компоненте сильной связности или нет?
Вот такая вот задачка.
Вот является ли она первой в своей компоненте?
Как же это понять?
Ну, казалось бы, для этого у нас есть технология тоже.
Что нам технология говорит?
Технология говорит, что мы вводим такое понятие как uptime.
А вот теперь давайте с вами.
Так вот, жалко у нас рыжего маркера нет, но есть красный.
Ну вот, значит, поэтому внимание.
Что такое uptime?
Да нет, не путать.
Нет, uptime.
Да, у нас, конечно же, обязательно есть такая штука как time.
Да, это время входа.
Ну, теоретически есть timeout, но нам он не нужен.
Теперь давайте внимательно.
Определение uptime давайте даже запишем, потому что нам это придется внимательно думать.
Что такое uptime от В?
Что такое попасть?
Что такое попасть?
Так, да.
То есть минимальный таймин такой вершины.
Ну, в начале так.
Ну, у нас было так.
Таймин от W такое, что UW это обратное ребро.
Сейчас напишу.
Вот, а у лежит, да.
Или можно еще написать так, чтобы еще короче было UW, да.
Вот.
Такая вот красота.
Ну, вот такой uptime.
То есть мы действительно можем такое uptime насчитать без труда.
Остается только внимание вопроса.
Как с помощью uptime понять, какая вершина первая?
Вот как это понять.
Ну, если есть больше наверх, то uptime от W меньше, чем time от W.
Ну, да.
Действительно.
Да, совершенно верно.
То есть если у нас действительно uptime от W меньше, чем таймы на W, собственно,
то это означало, что тут мы можем спуститься от вершины W до какой-то вершины U
и пойти куда-то выше.
Вот.
А это означает, что вершина эта точно не первая,
потому что вот вместе с ней в ее компонентной связности лежит и вот это вот все.
Ну, и вот это вот все.
Да.
Поэтому очень, конечно...
Ну, вот поэтому...
Ну, вот перенот.
Поэтому, да.
То есть мы описываем технологию.
И технология говорит, что мы говорим, что вершина W первая в своей компоненте сильной связности, так сказать.
Ну, вот тогда и только тогда, когда time in от W оказался строго, строго больше.
Такие наоборот.
Ну, строго больше.
Нет, наоборот, наоборот, наоборот.
Чтобы она была первая...
Чтобы она первая, оказалось, что таймы от W должны оказаться меньше либо равен uptime.
Вот так.
Может быть, наоборот было написать.
Так что uptime больше либо равен.
Вот.
А если uptime строго больше, то разве у нас будет компонента сильной связности?
А чего бы нет?
Ну, она-то точно лежит в своей компонентной связи.
Ну, самое главное, что она первая в своей компоненте.
Нет, понятно, что у нас рассчитано то, что да, она первая в своей компоненте,
но понятно, что в ее под дереве тоже могут быть вершины с таким свойством,
и они... и просто это будет означать, что у нас есть компоненты,
которые висят другие компоненты.
Вот. То есть после этого мы там достаем эту нашу технологию с этим стеком, этим всем достаем и так далее.
Вот у нас даже нарисовки были.
Чего?
У нас вот...
Ну да, вот совершенно верно.
Да, да, да.
В этом вот идея.
Но кто-то из вас, наверное, уже увидел, что конкретно в данном случае эта технология может дать немножко маху.
Да?
Да.
Да, потому что причина фундаментальна.
Где... чем отличается ориентированный граф от неориентированного?
Потому что в неориентированном графе у нас действительно кроме...
О, господи, на весь коридор это все кричу, да?
Так.
Так.
А то прям эхо.
Вот.
Это обратное ребро.
Просто кроме ребер дерева DFS и обратных ребер, помним, что в неориентированном графе, а других, собственно, и нет.
А вот в ориентированном графе есть.
Потому что в ориентированном графе есть перекрестные ребра.
Вот.
То есть действительно...
Ну вот.
Но к чему это нас приводит?
А приводит нас вот к чему.
С одной стороны, если вершина V первая в своей компоненте, то действительно uptime больше либо равен таймына.
Но мы уже доказали, что если uptime меньше таймына, то V точно не первая, да?
То есть в одну сторону это будет верно.
Вот.
То есть, соответственно, если она первая, то сработает.
То есть как бы все первые вершины мы идентифицируем.
Но может так получиться, что мы помимо них идентифицируем еще кого-то.
Будут ложные срабатывания.
Как это может быть?
Да, очень просто.
Компонента...
Вот просто можно нарисовать такой пример.
Вот, допустим, у нас компонента устроена так.
Вот такие у нас перекрестные ребра, допустим, есть?
Или даже вот такие?
Или даже вот такие?
И вот такая добивочка.
Тогда мы заметим, то есть я утверждаю, что так как у нас тут в определении прописано обратное ребро, да?
Видите, да?
Обратное ребро, обратное ребро.
Вот.
То получается, что у этой вершины оптайм будет равен чему?
По такому определению плюс бесконечность.
Плюс бесконечность.
Ну да, по тому, как это обычно пишут на Олимпиадах, конечно, оно оптайм будет равен таймы, но да.
Но по нашему определению это плюс бесконечность.
Да, просто потому, что из-под дерева этой вершины не торчит обратных ребер от слова вообще.
Но как выясняется, если раньше у нас доказательство базировалось на том, что выйти из-под дерева вы сможете только по обратному ребру, то здесь это неверно.
Вот здесь это неверно, потому что можно из-под дерева выйти еще по перекрестному ребру.
Так, что делать?
БФС.
Ну да, только там все еще хуже будет.
У нас хоть это все перекрестные ребра влево хотя бы ведут, а там они будут и влево, и вправо, и туда, и сюда.
И можно кначитать суммцы, которые показывают, насколько вверх можно подняться.
Осталось только это понять.
Если можно свою идею продолжить.
Чего можно продолжить?
Короче, устроим дерево ДФС, в нем запускаем БФС из корни.
БФС из корни нам дает послойное прохождение дерева, и мы для каждого слоя выше знаем уже посчитанный аптайм.
Ну БФС лучше давайте сразу его откинем.
Например, по той причине, что если в ДФС у нас хотя бы один корень в каждой компоненте, то в БФС мы как раз можем с десяти сторон зайти в одну и ту же компоненту.
Так что давайте лучше без этого.
Нет, на самом деле хочется вот действительно все-таки тут вот где-то вот, где-то вот и стены рядом как-то.
Ну то есть как ее можно допилить?
Ну ладно, если так обратно нельзя, ну хорошо, давайте напишем обратные или перекрестные.
Ну давайте думать.
Давайте думать.
А вдруг нет.
Как говорится, мы же программисты, мы можем потестить разные варианты.
Вот.
Ну нет, ну почему?
Нет, ну статью пишут, когда все-таки есть строгое доказательство.
Но я в данном случае бы математик.
К сожалению, да, по программированию кто-то, как мы уже говорили, угнал.
Почему-то.
Нет, ну почему-почему?
Ну что не произносит?
В прошлый раз у вас было две лекции.
Чего?
Почему?
Да потому что у нас может...
Потому что нам важно то, что можно снизить не тот перекрестный мировой, а что потом оттуда можно добраться вверх.
Да, причем, причем имя да-да, что важно до предка.
А именно так, тайминг, именно вот вершины, именно сам перекрестный, не важно.
То есть нам по сути нужен какой-то путь из нескольких перекрестных прямых и одного наверх.
Ну это-то нет, ага.
И в чем куда-то, чтоб гарантировано наверх.
Потому что, да, основная подлость, конечно, в этом случае это вот такое ребро.
Нет, ну то есть теперь мы можем заметить теперь следующее, что ложных срабатываний теперь не будет.
Да, то есть теперь будет ситуация наоборот.
Да, что вот эти все вершины точно не сработают, да.
А вот, например, ну, просто если мы перекрестили игру, то вот у той вершинки слева тайминг меньше, чем у нашей.
Да, вот именно, да.
Это вообще вообще ужасно получается.
Ну да, не ужасно, нет, просто как бы ложных срабатываний нет, но как бы, как говорится, и некоторые истинные зависятся.
Ну да, не ужасно, нет, просто как бы ложных срабатываний нет, но как бы, как говорится, и некоторые истины зависают.
Да, действительно такая проблема, ну вот.
То есть действительно такая проблема у нас действительно есть.
Правда возникает один такой маленький чит.
Дело в том, что если бы так запускали DFS по этой логике, мы заметим, что эта компонента, она бы уже была идентифицирована и записана, правда?
Вот.
Но это означает, что мы бы уже по-любому сказали, что эта вершина первая, да.
Ну и стержа.
Ну и стержа.
Вот.
Это вершина первая, поэтому все на ней висящее мы бы идентифицировали как компоненту сильной связности.
Вот.
Ну вот, то есть, ну в принципе идентифицировали, что да, что у нас есть под дерево, и из него вы никуда не выйдете уж точно.
Поэтому мы понимаем, что это компоненты сильной связности.
Ну или, по крайней мере, набор компонентов сильной связности, конечно, слету не будем сейчас утверждать.
Нет, хотя нет, ложных срабатываний у нас нету, напоминаю, да.
Вот.
А хотя, да, тут могли бы пропасть какие-то истинные.
Но, по крайней мере, тем не менее, мы знаем следующее, что, по крайней мере, вот эта вот штука это какой-то набор компонентов сильной связности, но мы ничего к нему уже не присоединим, потому что оттуда нельзя выйти.
Вот.
И в результате, ну вот, и в результате оказывается тут весьма неожиданный чит.
В DFS-е вводим четвертый цвет.
То есть у нас в DFS-е теперь белый, серый, черный и фиолетовый.
Вопрос к Тарьяну, почему фиолетовый.
Ну вот, но почему-то фиолетовый.
То есть технология в итоге предлагает следующее.
То есть мы, ну понятно, белый цвет, когда в DFS не вошел в вершину.
Серый цвет, когда он в него вошел, но еще не вышел.
Черный, когда он вышел.
И фиолетовый, когда вершина оказалась в своей компоненте сильной связности.
Ну вот.
Значит, смотрите.
Потому что у нас код теперь будет выглядеть примерно следующим образом.
Ну я сейчас не буду прописывать там все эти массивы типа таймы, наптаймы, прочие стэки с компонентами.
То есть я напишу так.
То есть вы делали void, значит DFS, как всегда.
На этот раз int v.
На этот раз int v.
То есть на этот раз мне абсолютно незачем писать, по какому ребру я пришел, потому что обратно по нему я не пройду.
Вот.
Значит, поехали.
Так, как у нас этот массив юзет назывался с цветами?
House?
Логично, да.
Как называется массив с цветами?
Наверное, цвета, да.
Так, да, так и пишем.
Е, DFS, gray.
Вот такая красота была.
Так.
Что мы там еще делали?
А, ну конечно, всякие эти таймы мы делали, да.
Таймы на v.
Там равно, как всегда, current time++.
Так, что там у нас еще было?
Uptime от v равно плюс бесконечность.
И, конечно же, запихнуть вершину в stack.
Вот такая красота.
Так, ничего не забыл.
Ну ладно, давайте оставим тут пару строчек, может что-то и забыл.
А дальше начинается самое интересное.
For int nv, там, соответственно, граф от v перебираем.
Так, и вот тут начиналось, ну вот.
И тут начиналось самое интересное.
Значит, смотрите, как это будет работать.
Ну, во-первых, так.
Если оказывалось, что colors от nv равно E, DFS, white.
То есть это означает, что это какое ребро?
Да.
То есть это vnv, ребро, white.
Да, то есть это vnv, ребро, vdfs.
И что мы в этом случае делаем?
В этом случае мы...
Ну да, ну в этом случае мы просто запускаем DFS от вершины nv.
И, конечно же, не забываем обновить uptime.
uptime от nv, min равно...
Вот, как хорошо писать на доске.
А, наоборот, да-да-да.
Да, uptime от nv.
Так, ну вроде кайф.
Так.
Ну что еще бывает?
Значит, если...
Ну вот.
Значит, если оказалось, что это ребро обратное,
colors от nv, E, DFS, grey.
То есть, так сказать, vnv обратное.
То что мы тогда делаем?
Ну да, так и пишем.
uptime от v, min равно...
Правда, на этот раз не uptime от nv, а time in.
Все-таки.
Вот.
Так, что же дальше?
Чего?
Ну, пока у нас такое определение.
Пока у нас определение.
То есть потом мы код, может быть, чуть-чуть поправим.
Пользуясь тем, что у нас доска.
Доска.
Далее.
Ну что, какие у нас еще ребры бывают?
Чего-чего-чего?
Ну черт, да.
Может быть чертая.
Но тут я просто думаю, каким цветом мне это писать?
Потому что...
Да, действительно, хорошо.
Оставшийся вариант, это если мы ведем...
Если у нас черная.
Пока мы фиолетовую не ввели.
Ну вот.
Но на самом деле, не обязательно зеленый.
На самом деле, если мы видим черную вершину,
ребро может оказаться как перекрестным, так и прямым.
Вот.
Прямое, которое соединяет предка с потомком.
То есть вот какое-то вот такое.
Вот.
Но по умолчанию оно, конечно, перекрестное.
Но впрочем, нам на самом деле, сейчас по барабану,
потому что, действительно, мы можем...
Потому что изначально мы хотели бы сказать, что...
Казалось бы, да.
В противном случае, просто пишем...
Оптайм тоже от В.
Мин равно таймин.
От НВ.
Тоже хотелось бы сказать.
Но тут комментарии пишем, что ВНВ это перекрестное...
Или прямое.
Но, да, можно было бы даже в явном виде идентифицировать,
отличить одно от другого.
Но нам нет смысла это делать,
потому что таймы на ТНВ, по-любому, будет больше,
чем таймы на ТВ, правда?
Если это ребро прямое.
Поэтому можно было бы не расписывать.
Вот, казалось бы, так.
Вот.
Ну и, наверное, вот.
То есть эта исходная технология бы так это и говорила.
То есть после этого мы, соответственно, торжественно заявляем, что...
Ну вот.
Значит, теперь что дальше?
Значит, так вот у нас фор закончился.
Даже мы хотим все-таки в начале оптайма ТВ делать таймином от В.
Да не, не обязательно.
Ну можно, но без разницы.
На самом деле.
То есть, конечно...
То есть, конечно, так.
Ладно, если оптайм так дописывать,
то, конечно, стоит тут, конечно, все-таки какой-нибудь ifчик вставить.
То есть, скажем, if там вот так написать.
То есть, if таймин от НВ
там действительно оказался меньше, чем таймин от В.
Вот.
Тогда это мы вообще убираем.
То есть, добавив этот if, мы теперь говорим,
ребро теперь железо-бетонно-перекрестное, а прямые ребра нас не интересуют.
То есть, мы даже этот случай не рассматриваем,
просто в знак того, что если мы уберем из графа все прямые ребра,
то компоненты сильной связности от этого не поменяются от слова никак.
Вы понимаете, почему, да?
Конечно.
Ну и что нам теперь говорит технология, да?
Ну теперь говорим, что...
Что, значит, калакс у нас теперь от В становится черным.
E, D, F, S, black.
Вот.
И дальше теперь, что мы говорим...
И дальше говорим, неожиданно, что если оказалось, что uptime от В
больше либо равен таймин от В,
то надо было тренажный оператор писать.
Что?
Нет.
Где тут тренажный оператор писать?
Калакс от В равно uptime от В больше равно таймин.
А, не, если бы, если бы, не получится.
Ну вот.
Ну и сейчас бы, потому что нам же еще вершины из стека доставать.
То есть, по-хорошему надо написать.
По-хорошему надо написать.
Vector int comb.
Да.
То есть, допустим int u.
И там do, какой-нибудь там u равно st.top.
Там st.pop.
U.
Там это comp.push от u.
Ну вот, и делаем мы все это.
Вот так вот.
И делаем мы все это.
While что?
While u не равно v, мы это делаем.
Ну вот.
Ну и там.
Так, это как-то чуть-чуть кончилось.
Ну вот.
Вот так я пишу.
Comp.pushback.
Comp.
Ну и все.
Вот, примерно так хотелось бы сделать.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Сделать.
Но как вы убежали, что это не совсем работает?
Ну, потому что это фактически отвечает вот тому, что там написано.
Но мы уже выяснили, что это не работает.
А как сделать так, чтобы это работало?
Как же было сказано?
Сейчас мы введем четвертый цвет в DFS.
Как мы его введем?
Да очень просто.
Смотрите.
Внимание.
Вот сюда.
Вот.
Прямо вот в это вот место кода.
Вот я тут даже.
Ну давайте представим, что синий это еще и чуть-чуть фиолетовый.
Значит, мы скажем, что colors
от u
равно
внимание
e DFS purple.
О.
То есть это будет знак того, что эта вершина уже в найденной компании.
Но сама по себе, конечно, сама по себе эта штука нам бы никак не помогла.
Потому что пока как бы ничего принципиально не поменялось.
Мы просто тут это, то есть фактически какую-то там галочку поставили.
Как же сделать так, чтобы она повлияла на логаритм?
А вот как.
Дело в том, что у нас есть один логаритм.
А у нас есть один логаритм.
А у нас есть один логаритм.
Дело в том, что мы не будем учитывать перекрестные ребра, которые ведут в фиолетовые вершины.
То есть когда у нас будет перекрестное ребро, мы будем проверять, а вершина-то у нас фиолетовая или не фиолетовая.
И тогда это поможет следующим образом, что с одной стороны вот эти ребра учтутся, а вот это ребро нет.
Потому что эта компонента будет уже фиолетовая.
Такова идея. Естественно, это пока не доказательство.
Сейчас мы будем это аккуратно доказывать.
Но вот смысл такой.
Сейчас мы возьмем губочку и напишем, что на самом деле, то есть тут будет иметь смысл написать.
То есть видите, не вот этот вот ИВ писать, но вот.
А важно тут будет написать именно ЛЗ.
То есть вот этот дотоптайм, то есть учитывать нужно только если colors от nv равно edfs black.
То есть можно было на самом деле вот сюда написать, если цвет серый или черный.
Ну короче не фиолетовый.
Вот такая идея.
Так вот, алгоритм понятен?
Именно как алгоритм.
А понятно, что в этом коде написано.
А то скопипастить можно, и при этом вообще не понимать, что это такое.
Проблема?
Проблема была, что предыдущие варианты не работали.
Потому что в одном из этих вариантов у нас были ложные срабатывания на первую вершину, а в другом варианте наоборот.
Ложных срабатываний не было, но и некоторые истинные не работали.
Поэтому я утверждаю, что вот в этом варианте сработают ровно те и только те, которые надо.
Вот в чем проблема. Вот была проблема, и вот сейчас мы ее пытаемся героически решить.
Первая вершина в своей компоненте стильной саженности, это по таймингу первая?
Ну да.
Она же корень.
Значит поехали. Что же делать?
Как же это сделать? То есть как же это теперь доказывать?
Ну я утверждаю следующее.
Значит смотрите, как у нас устроены, вот давайте думать.
Как у нас устроены компоненты?
Вот рассмотрим какую-нибудь компоненту и ее дерево.
Ну понятно, что у каждой компоненты будет корень дерева, вне зависимости от того, идентифицируем мы его или нет.
Вот допустим там какое-то дерево, дерево, дерево.
Ну тут еще какие-то ребра есть, будем их по мере необходимости рисовать.
Ну и конечно из какого-то корня, то есть ДФС, мы сюда вообще пришли.
Может быть тут еще кто-то был, вот так вот.
Ну а теперь давайте вот что заметим.
Значит по каким ребрам можно отсюда выйти?
Докажем для начала, что эта вершина будет идентифицирована как первая.
То есть докажем, что для нее аптайм больше либо равен таймэйну.
Ну смотрите, вот у нас жила была компонент сильной связности.
Да, нам надо доказать для нее две вещи.
Во-первых, что для ее корня аптайм больше либо равен таймэйна.
А второе мы даже докажем, что для этих всех вершин вот это неверно.
То есть аптайм меньше таймэйна.
Но на самом деле ладно, проще даже для этих вершин доказать, что аптайм меньше таймэйна.
Почему?
Ну потому что мы замечаем вот что.
То есть рассмотрим, скажем, под дерево каждой вершины.
Заметим, что из этого под деревом можно выйти, внимание, не выходя за пределы компоненты сильной связности.
Ну потому что из этой части можно попасть в этот корень.
Причем не выходя за пределы компоненты сильной связности.
То есть значит из нее торчит какое-то ребро, которое ведет в какие-то другие вершины, но той же самой компонентой сильной связности.
Но что это может быть?
То есть вот из этого под дерева.
Это может быть обратное ребро, и тогда аптайм этой вершины становится с точно меньше таймэйна.
Либо это может быть перекрестное ребро.
Это может быть перекрестное ребро вот куда-то в соседнее под дерево.
Да, эти вершины не фиолетовые, потому что мы можем, мы просто вот аккуратненько по индукции доказываем,
по таймэйну там сначала для этой, потом это, это и так далее, что эти все вершины фиолетовые,
то есть эти все вершины для этих всех вершин аптайм меньше, чем таймэйн, поэтому фиолетовые они пока еще не стали.
Ну да, помните, перекрестное ребро у нас ведет всегда в вершины с меньшими таймэйнами.
Так что поэтому как бы вот это ребро уже у этой вершины таймэйн заведомо меньше, чем у этой.
Ну смотрите, мы обходим вершины этой компоненты по очереди, да, в порядке таймэйна.
Давайте вот просто мы в порядке этой очереди докажем, что для каждой из этих вершин аптайм будет меньше, чем таймэйн.
Аптайм меньше, чем таймэйн, да.
Нет, ну как, ну наша цель доказать, что аптайм меньше, чем таймэйн, то есть что на них ложного срабатывания не будет.
Логично, да? Доказываем мы это так.
Доказываем мы это так. Доказываем мы это в порядке по очереди происхождения таймэйн.
Допустим, вот для всех вот этих вершин мы доказали, что ложных срабатываний здесь не будет.
И дошли до этой вершины. Рассмотрим ее под дерево.
То есть теперь доказываем, идем. То есть тут какое-то под дерево, мы его рассматриваем полностью.
И теперь думаем, из него мы должны как умеем, из него торчит хотя бы одно ребро внутрь этой же компоненты сильной связности.
Это ребро, либо обратное, либо, то есть либо оно, либо перекрестное.
Если оно обратное, то оно ведет в предка этой вершины, да, и тогда аптайм меньше таймэйна, ура.
В hä polarization у нас перекрестное, потому что мы сортировали.
В перекрестном, во-первых, просто есть свойство что перекрестное всегда, ну перекрестное оно всегда ведет в вершину с меньшим таймэйном.
В зависимости от наше сортировки он как-то где-то не completieht.
Нет, почему таймэйн устроен так что перекрестовое ребро всегда ведет из вершин с большим таймэйном
ну как минимум у нас было на прошлом лекции такое свойство.
А у нас сейчас аптаймы вообще имеют какой-то более общий смысл, чем величина, которая считается вот так вот?
Ну сложно сказать. Ну потому что смысл у него, как всегда, можно ли из-под дерева выйти? Желательно не выходя из компонента.
А, ну на самом деле, да. Заметим, что, конечно, это доказательств еще не совсем полно, потому что в аптаймы участвуют еще всякие, то есть потому что тут же еще всякие компоненты висят.
То есть тут вообще тут еще что-то висит. Вон целая под дерево компонент.
Чего? Вориентированно. Ну конечно, сильная связность бывает только вориентированно.
Ну вот. Ну то есть теоретически из этих компонент тоже может вести куда-то какие-то перекрестные игры, правда?
Но правда интересующая нас, если тут они между компонентами отсюда-сюда, то это нас не интересует, потому что у всех этих вершин таймин больше, чем таймин этой вершины.
Но с другой стороны, заметим теперь следующее. Ну вот. А, впрочем, стоп, а какая нам разница?
А, на самом деле бесполезно это рассматривать, потому что мы уже исходя из этого под дерево уже доказали, что аптайм этой вершины будет меньше, чем ее таймин. Все.
То есть может быть даже если тут что-то лишнее будет, на самом деле нет, но это мы чуть позже поймем. То есть таким образом мы поняли, что ложных срабатываний не будет.
Вот, понятно? А будет ли истинное срабатывание? А будут ли все истинные срабатывания?
То есть не может ли быть так, что вот эту вершину мы так жественно проигнорируем? На радость.
Да, совершенно верно. Откуда мог взять саптайм меньше? Обратных ребер конечно нет, потому что если бы они были, то тогда эта вершина оказалась бы в одной компоненте сильной связности с этой.
И первой бы не была. Ну а теперь думаем. Хорошо. А какие у нас в ее под дереве есть обратные ребра? Перекрестные.
Ну есть перекрестные, ну могли бы быть в принципе, наш код дает апдейты по прямым ребрам, но прямые нам неинтересны, потому что прямые ведут ребра вниз.
То есть вершины у которых таймин больше, чем у этой вершины.
Так, рассматриваем перекрестные ребра. Ну теперь мы думаем вот о чем. Так, перекрестные ребра, если они не выходят за пределы под дерево, то они нас тоже не интересуют, правда?
То есть они по крайней мере таймин будут, то есть аптайм меньше, чем таймин, не сделают. Но могут быть перекрестные ребра, которые в принципе выходят откуда-то, вот еще куда-то влево.
Но они выходят в соседнее под дерево, правда? То есть вот как-то это вот так происходит.
Но заметим мы тогда следующее.
Ну вот тут не совсем так, тут надо аккуратно. Потому что тут мы заметим следующее.
Тут как бы могло быть два варианта. То есть у нас действительно.
Либо у нас тут вот после ответвления появляются новые компоненты, то есть вот как-то это вот так происходит.
И тогда мы, то есть тогда тут как-то вот так это все начинается.
И тогда мы замечаем, что это ребро мы не учитывали, потому что эта компонента уже была учтена ранее.
Да, мы опять тут доказываем все по индукции, тоже по таймину.
Но как бы получается мы ее обошли. Вот понимаете, да?
Но это верно, но могло быть так, что на самом деле тут, то есть это верно только что если компоненты сильной связности этой вершины не дотягиваются вот до ДЛЦА.
Ну она же могла дотянуться.
То есть здесь.
Ну вот смотрите, то есть рассуждение такое, что вот жила была ЛЦА, вот жил был путь в эту вершину.
Вот эта вершина лежит в какой-то компоненте сильной связности.
И она лежит в одной компоненте с этой вершины, с этой, с этой и так далее вот до какой-то.
И вот это какая-то, она где?
Она либо ниже ЛЦА-шки, либо не ниже.
Если ниже, то тогда эта компонента уже была идентифицирована ранее, просто по индукции.
Теперь, а если, ну вот, ну вот, нет, а если ЛЦА, то есть компонента устроена как-то там условно вот, как-то вот так вот.
На самом деле, да?
Что мы тогда? То тогда мы получаем просто противоречие.
Потому что, если у нас так получилось, то мы замечаем, что у нас есть компонента сильной связности,
из которой можно вот выйти через ЛЦА-шку в наш, сюда, прийти сюда и вернуться.
То есть это означает, что все вот это вот, весь этот путь лежит в этой компоненте, и эта вершина первой реально не была.
Ну вот все, доказательство завершено.
Так что вот такое вот фиолетового цвета действительно позволяет нам найти еще и компоненты сильной связности.
Абсолютно тема. То есть технология вот абсолютно такая же.
Причем, как видим, код, в общем-то, даже не усложнился на самом деле.
То есть подлянка может быть только в том, что, конечно, надо помнить. Надо помнить о том, что конкретно.
Но с другой стороны, тут, как всегда, если вы помните, из каких соображений берется, то как бы восстановить,
где тут фиолетовый цвет и где тут какие-то именно надо проверять, вы там сделаете без труда.
Вот. Ну вот. Ну да, почему-то, да, на Олимпиаде этот алгоритм почему-то популярным не является.
Ну проще. Ну проще писать.
Ну, конденсация. Нет, конденсация. Вопрос решаемый, пожалуйста.
Берете, конденсируете. Вот потому что вы тут, вот компоненты, в явном виде делаете, что хотите.
Причем она тоже будет как в соседнем. А ну давайте, конечно, мы не можем не рассмотреть и соседний алгоритм, собственно,
так сказать, конкурента. Да, в котором два ДФСа, но которые пишутся короче, чем этот один.
Ну. Ну как сказать.
Вот так. Ну вот.
Хотя еще посмотрим, кого, кстати, проще доказать.
Хотя.
Болезненно. Ну посмотрим, сейчас посмотрим, посмотрим.
Так.
Вот.
Так сейчас мы это все убираем.
Ну вот. Ну потому что да. Какой у нас есть конкурирующий алгоритм?
Да, конкурирующий алгоритм предполагает вообще никаких этих фиолетовых цветов не писать.
Собственно, не заморачиваться, а вместо этого сказать следующее.
Давайте запустим один ДФС.
И просто выпишем вершины в порядке, только на этот раз не таймына, а таймалта.
Вот.
Вот выпишем вершины в порядке таймалта.
То есть в порядке выхода.
То есть можно таймалт даже не хранить, а можно просто там запустить тупо, самый тупой ДФС вообще ни с чем не заморачиваться, просто в конце пушбекнуть его в соответствующий вектор.
Значит это первый ДФС, выписываем вершины.
А потом после этого мы торжественно заявляем, что мы идем, то есть второй ДФС идет наоборот по этому списочку в порядке убывания таймына, таймалта точнее.
Из каждой вершины запускается ДФС и утверждается, что в каждой вершине все, что ДФС обошел, это и есть компоненты сильной связности.
Вот такой был алгоритм.
Да.
Ну-ка внимание и вопрос, дорогие олимпиадники, что я забыл?
Да, а еще важный момент.
Да, перед тем как запустить второй ДФС в сериал-правкрафе надо развернуть.
До этого произошло следующее.
Значит ДФС 1.
Значит мы завели вот такой вектор.
Ну вот, то есть допустим там назовем его LST и мы записываем в него все вершины в порядке убывания таймалта.
То есть как бы да.
Ну давайте, вот напишем.
То есть ДФС 1.
ИНТВ.
Ну как всегда.
Тут вообще не заворачивается, можно юзет прямо писать.
А не эти вот.
Там FOR.
Там INT.
NW.
Пум-пум.
Горят В.
IF.
Ну вот IF не юзет от NW.
То что-то там.
Ну вот от ДФС 1.
От NW.
И в самом конце LST.Pushback от В.
Не, ну если спрашивать, что произошло, то вот.
То есть произошло вот это.
То есть вот так мы создали вид.
Ну понятно, что ДФС запускался, типа прибираемся по всем вершинам, если она еще не юзит, пускаем ДФС.
Поехали, хорошо.
Теперь второй ДФС.
Второй ДФС говорит так.
Во-первых, мы работаем теперь не с графом, а с развернутым графом.
То есть когда все ребра.
То есть когда у нас все, когда у нас.
То есть теперь вместо каждого ребра мы рассматриваем вот что-то такое.
И говорим, запускаем ДФС в том порядке, в котором они записаны в LST, только вот справа налево.
То есть в обратном порядке.
И в каждом ДФСе говорим, что мы запустили ДФС от вершины.
Все, что он обошел конкретно этот ДФС, это компоненты сильной связности.
Вот такая идея.
Да, это собственно алгоритм Косараю называется.
Вот.
Но внимание, вопрос.
Что вдруг?
Да, почему же это?
Почему то, что ищет алгоритм имеет какое-то отношение к компонентам сильной связности?
Ну, давайте смотреть.
Значит, что можно сказать про эти компоненты?
Значит, что можно сказать про эти компоненты?
Ну, заметьте, вот с точки зрения первого ДФСа.
Вот давайте теперь представим, что мы будем записывать эти вершины не слева направо, а снизу вверх.
Вот можем себе такое представить, да?
Тогда смотрите, ведь у каждой компоненты, как всегда, есть первая вершина, как мы уже выясняли, и висящая на ней под деревом.
Ну, так или иначе, правда?
Смотрите.
Заметим.
И заметим мы теперь следующее.
Значит, что можно заметить?
Заметим, что в принципе эти компоненты теоретически можно записать тоже так вот.
Ну, давайте запишем эти компоненты в том порядке, в котором мы из них выходили.
Выходили.
Вот тут деревец какой-то.
Вот так.
Ну, теперь заметим следующее.
Ну, тут еще что-нибудь там по мелочи нарисуем.
Ну, теперь заметим следующее.
Что если рассмотрим ребра, которые соединяют разные компоненты, то я утверждаю,
я утверждаю, что все эти ребра ведут строго сверху вниз.
Ну, снизу вверх вести, ну, вот.
Ну, потому что действительно.
Давайте, я утверждаю, что только вот так.
Так, вот, вот так, вот как-то.
Может быть еще вот так вот, вот так вот.
Вот так вот как-нибудь.
Но и наоборот.
Напоминаю, мы написали эти компоненты, то есть мы для каждой компоненты рассмотрели первую вершину,
тайм-аут, и выписали вершины вот в порядке возрастания тайм-аута снизу вверх.
Видите, да?
Видите, да.
Вот, теперь думаем, ну, давайте поймем, почему не может быть какого-нибудь вот такого ребра, например.
Да, ну, давайте подумаем, что мы...
Ну, не совсем так. Нет же гарантии, что из этой компоненты в эту есть путь.
Ну, да.
Но теперь, да, заметим следующее, что тогда заметим, что...
Нет, ну, не совсем так.
Смотрите, то есть мы жил-был ДФС.
Ну, вот, и когда мы были в этой вершине, мы смотрели на это ребро.
Мы по нему либо пошли, либо нет.
Но если мы по нему пошли, то тогда мы бы вошли в эту компоненту и из нее бы вышли раньше, чем из этой.
Логично, да?
Вот.
Мужская нота.
То есть там нужно быть ниже.
Ну, вот, да.
Но тогда это означает, что она уже была обойдена.
Но это означает, что мы, видимо, из нее уже...
Нет, хотя не совсем так.
Она могла быть серой.
Нет, на самом деле еще может быть так, что мы в нее вошли, эту компоненту, но еще не обошли.
Еще такое могло быть.
Но тогда это будет означать, что это ее потомок.
Да, а это значит цикл, да.
Тут, конечно, надо аккуратно рассматривать, потому что...
Почему мы не пошли?
Потому что либо эта вершина уже...
То есть либо мы эту компоненту уже полностью обошли, и тогда она была ниже.
Либо мы ее еще не полностью обошли.
Значит, тут какие-то вершины серые.
Не обязательно это вершина серая, но какие-то вершины серые.
Но это все равно будет означать цикл.
Так что получается, да, таких ребер не бывает.
Но заметим, что самое приятное.
Хорошо, компоненты действительно у нас в этом смысле так упорядочены.
Но самое главное, что в каждой компоненте верно, что если мы в какую-то вершину зашли первой в компоненте, то мы из нее вышли последние, правда?
Поэтому когда мы будем идти тут справа налево, для каждой компоненты мы сначала наткнемся на ее вот этот корень относительно первой DFS.
Видите, да?
К чему же нас это приведет?
А приведет нас это вот к чему?
То есть тогда получается, что у нас компоненты вот упорядочились в таком порядке, и теперь вот мы идем и попадаем теперь вот в эту вершину.
Но если мы разворачиваем ребра теперь, то вот эту компоненту мы все равно обойдем.
Ну да, потому что по определению скорее, по сильной связности.
То есть до этих вершин мы можем дойти как по прямым ребрам, так и по, так сказать, наоборот.
Но с другой стороны, выйти из нее больше нельзя, потому что ни одно ребро в эту компоненту не входило.
То есть только выходили.
Тогда поэтому когда мы развернули ребра теперь только все входят, но никто не выходит.
Поэтому самый первый DFS тупо возьмет эту вершину, то есть это нот, и просто обойдет ровно ее компонент.
Потом дальше мы получается попадем просто в эту вот вершину, и аналогичным образом обойдем ровно ее.
Ну и так далее.
То есть заодно еще и получается, что мы не просто обойдем компоненты, но еще и в порядке топологической сортировки.
Топологическая сортировка для этого.
Ну да.
Но правда с другой стороны, тут это не то чтобы преимущество,
потому что я утверждаю, что здесь у нас тоже получится топологическая сортировка на самом деле.
Это еще надо доказать.
Да.
Ну я утверждаю действительно, что мы тут компоненты обошли в каком-то порядке.
Так вот, я утверждаю в данном случае, что все ребра между компонентами будут вести из позже обойденной компоненты в ранее обойденную компонент.
Почему?
Ну потому что если мы рассмотрим конденсацию с точки зрения DFS, то есть вот у нас конденсация.
Внутри мы подразумеваем, что это компоненты сильной связности.
То какие ребра из компонент могут выходить?
Обратных выходить не может.
Потому что тогда это просто цикл одна компонента ай-ай-ай.
Но тогда бывают только какие еще ребра бывают?
Перекрестные могут быть?
Тогда смотрите, какие могут быть ребра.
Могут быть прямые ребра, которые соединяют предка с потомком.
И могут быть еще перекрестные ребра.
Но перекрестные ребра, они во-первых, идут из позже обойденных в ранее обойденную.
Вот понимаете, да?
Ну вот, это уже само по себе.
А прямое, а тоже заметим, что эту компоненту мы идентифицировали позже, чем вот эту.
Так что получается, что здесь тоже как бы топологическая циклировка тоже найдена.
Так что само по себе это не преимущество.
Ну вот, то есть и так, то есть в общем-то тут и так, и так.
То есть дальше уже там на ваше усмотрение, как вам удобнее написать два коротких ДФСа или один вот там умный.
Вот.
Нет, ну, нет, практика здесь не показывает никак.
Нет, практика тут не показывает никак, потому что, понимаете, тут просто все зависит от того, как сложилось.
Так сложилось, что в олимпиаде программирования как-то принято рассказывать вот этот алгоритм.
Ну, принято потому, что он тупо проще.
Вот он тупо проще, чаще его рассказывают не в одной лекции с, скажем, мостами точного сочленения.
Да, поэтому, ну вот, а этот алгоритм, если независимо его рассматривать, он тупо проще пишет.
Ну вот.
Ну а если еще вспомнить, что там во всяких ЛКШ далеко не всегда заморачиваются об строгие доказательства.
Или всегда заморачиваются?
Ну там, нет, ну по ситуации, насколько там ЛКШ всякое бывает, ЛКШ иногда и там, и всякие там теоретические занятия устраивает.
Ну вот. Ну, впрочем, не суть.
Так что пора.
Так что вот получается такая красота.
Так, ну это вот все, что я хотел сказать про сильную связь.
Здесь есть ли тут вопросы?
Ну вот. Ну, чем, да, только если у этих алгоритмов есть такая подлянка, что нам приходится запускать DFS,
что там в зависимости от того, из каких вершин мы запускаем DFS в каком порядке, у нас будет еще сколько у нас деревьев DFS.
А ближайшие несколько алгоритмов мы будем говорить о графах специального вида.
Вот. Мы будем говорить о графах, у которых есть так называемый корень, то есть вершина, из которой DFS, из которой достижимы все.
Вот. Это, более того, даже тут опять появляется такой термин, который вот не очень...
Да, и более того, мы ее знаем и из нее будем запускать DFS.
Более того, в тех задачах, которые мы сейчас будем рассматривать, ну вот, а мы будем на самом деле и дерево доминаторов строить, и начнем мы с миностола ориентированного.
То есть нам будет принципиально, что да, такая вершина есть, мы ее знаем, это вершина R.
Вот. Да.
Это будет, то есть фактически так, это будет даже называться flow graph.
То есть он создается G и R.
То есть, где, значит, G равно VE, значит, это ориентированный граф, там R вершина, из R достижимы все вершины в множестве V.
Нет, как это ни странно, нет. Нет, никакого отношения к потокам это все не имеет.
Ну, знаете, тут сейчас посмотрим, у меня почему-то сейчас, у меня вообще уже возникло ощущение, что мы к ним близки на самом деле.
Нет, не сейчас, то, что мы сейчас будем обсуждать, мы к потокам вообще никакого отношения не имеем, кроме слова flow.
Но это не тот поток, но это, если подозревать, что не совсем тот поток.
Ну, здесь правда есть, то есть здесь, как бы тут, тут какой-то вроде перевод есть, это обычно называют, там кто-то перевел как graph потока управления.
Вот я запах, то есть, видимо, в каком-то переводе Аха Хопковта Ульмана, по-моему, или Аха Ульмана, там вот что-то такое.
В какой-то из этих книж на что-то подобное наталкивал.
То есть вот такое, но на самом деле в английской литературе есть термин flow graph, это вот означает вот это, то есть к потокам, в потоках там будет понятие network скорее.
То есть там будет сеть, там будут эти все истоки, стоки, там остаточные сети и прочая страшная терминология, на самом деле нет, собственно, которую мы чувствуем, скоро будем изучать.
Да, хоть и да, ну, то есть как по умолчанию программа третьего семестра.
Да, да, именно.
Ну, тут посмотрим много чего, нет, тут нет, потоки на самом деле тоже на самом деле стоят того, чтобы их изучать, никуда не торопясь, потому что это на самом деле отдельная, большая и очень красивая теория, собственно, как мы с вами убедимся.
Это что?
Си, си, си, си, си, ой, ну там, там другое.
Нет, ну, не совсем, нет, да, ну, поток это не об этом, поток это все-таки как воду через этот провод пускать, ну или более, или может быть где-то более жизненно как машины по дорогам пускать еще.
Там разные, разные задачи на эту тему, а может просто как искать разрез, как искать разрезу графии на самом деле.
Ой, ну там, ну да.
Так, да, на всякий случай мы с вами про сочетания не проходили, я надеюсь.
Ну да, все, я с ума не сошел, конечно.
Нет, могли бы мы их пройти, но на самом деле их надо проходить именно внутри потоков, собственно, увидите почему.
Да, их можно проходить отдельно, но на самом деле все доказательства, которые вам рассказывают, это просто так, это немножко калька и упрощение просто из теории потоков на самом деле.
Прикламировал, короче, будущие лекции.
А пока, пока же мы этим всем не занимаемся.
Пока же у нас есть вот ориентированный граф и вот есть вершина, из которой можно адекватно запустить DFS.
И теперь, значит, ну для, для разминочки порешаем такую задачу.
Ну даже не для разминочки, а просто порешаем такую задачу.
Значит, есть, есть вот этот вот ориентированный граф.
И на этот раз он взвешенный.
Там минус восемь, там какие-нибудь вот, что-нибудь такое.
Да, он не обязательно ациклический, боже упаси.
То есть он тут, он тут вполне может быть чем угодно.
Пожалуйста, там все, все, все, все, что угодно, любой каприз, как говорится, и так далее.
Вот.
Там два, один, минус восемь, два, четыре, шесть, пять, два, три, четыре.
Там один, минус восемь, два, четыре, шесть, пять, два, три.
Ну я абсолютно тут от балды пишу, естественно.
Два, один, семь.
А нижняя рубрика не забыла?
Ну забыл.
Вот.
Я хочу построить на этом графе минус сто.
Но что такое ас сто в ориентированном графе?
Ну вот, ну в данном случае все очень просто.
Я хочу построить ориентированное дерево, покрывающее все вершины, с корнем в вершине R.
Что значит ориентированное дерево?
Я хочу, чтобы каждое ребро было ориентировано от родителя к ребеночку.
Хорошо.
Во.
Ну вот, например, вот такое.
Ну я от балды тут что-нибудь такое рисую.
Так вот.
Ну вот, например, вот это вот.
Если я...
Забыл, забыл, забыл, забыл.
Ну давайте вот сюда подвесим.
Поярче.
Ладно.
Побольше красного.
Ну теперь видно точно.
Ну да, он говорила мне, мама красный и черный, где контрастируют.
Ну ладно, это говорила не мама, это учитель рисования во втором классе говорил.
Ну как сказать, они может и не должны сильно контрастить.
Ну как сказать, красный красному розень, понимаете, вот помните у нас на слайдах-то красный в общем-то был ярко-красный, а этот такой темно-красный с примесью черного.
А еще, а еще вот это, вот это мелочи.
Вот это мелочи.
Нет, это я вижу.
Вот.
Ну, например, вот это может быть остов.
Ну то есть это я показывал, что такое остов.
Если в графе есть циклы, да даже если их и нет, остовов может быть, ну вот, собственно, как, скажем, Дэн Браун до шиша.
Вот.
Но наша цель построить, естественно, такой остов минимального веса.
Значит, остов.
Ну, это подвешенные, ну, набор ребр, которые образуют подвешенное дерево.
То есть дерево с корнем в R, которое покрывает все вершины.
И причем ребра ориентированы, каждое ребро ориентировано от родителя к ребенку.
Вот так.
Ну то есть, или что то же самое.
То есть под граф из N минус одного ребра, в котором все еще из вершины R можно добраться до всех остальных.
Тоже эквивалентное определение.
Ну и, естественно, нам очень хочется построить остов минимального веса.
И вот на этот раз.
Так, и вот сразу возникает вопрос.
Ну-ка, а нас, вот для разминочки.
Вот у меня тут нарисованы отрицательные ребра.
А можем ли мы от них избавиться?
Точнее от отрицательностей в них.
Ну вот.
Ну да, заметим, что сами по себе отрицательности ничего не дадут.
Потому что, как и ранее, помните, когда мы искали минус 100 в неориентированном графе.
Вот, кстати, мы его так и не доискали.
А то, что мы с вами только алгоритм Прима знаем.
Потому что мы с вами не обсуждали SNM.
Вот, и надо еще не забыть, потому что нам обязательно нужно пообсуждать алгоритм Барувки.
Но я думаю, мы это сегодня пообсуждаем в какой-то момент.
Вот.
Ну то есть его важно будет пообсуждать, потому что во всяких теориях он нам потом будет очень важен.
А, ой, погодите, нам же еще это, ой, Кизеля надо обсуждать, наверное.
Ну этот алгоритм, типа, зачем мы софтхип учили?
Учили.
Нет, учили.
Выучили, насколько выучили, это другой вопрос.
Ну, скажем так, то, чтобы его учили.
Ну, как бы мы его учили.
Ну это да.
Ну, скажем так, честно, я пока алгоритма-то не знаю.
Кизеля, вот как это узнаю, расскажу.
Ну как бы я знаю только, что алгоритм по объему статья называется такого же объема, как статья по СССР.
Но я не знаю, как это будет.
Ну, как бы это будет?
А так?
скажу, но как бы я знаю только что как бы алгоритм по объему статья называется
такого же объема как статья по софт хипу того же автора, так что наверное
ну почему, софт хип мы за четыре пары уложились, помнится, успели, так что вот
ладно, также давайте что-нибудь попроще, значит смотрите, значит здесь на самом
деле в ориентированном, значит да, тут опять работает, что так как у нас ребер n-1,
то мы можем ко всем ребрам вообще прибавить константу и минус 100 останется
минус 100, потому что вес любого 100 увеличится на эту константу умножить на
n-1, но более того в ориентированном графе на самом деле можно сделать еще круче,
дело в том, что в ориентированном графе я могу даже не ко всем ребрам
прибавлять константу, а могу рассмотреть вершину, не корень конечно, рассмотреть все
ребра идущие в нее или все входящие ребра и ко всем им прибавить константу не трогая остальные
ребра, да, то есть дело в том, что заметим, что остов устроен так, что в каждую вершину кроме корня
входит ровно одно ребро, потому что по сути, что такое найти минус 100 в таком графе, по сути
для каждой вершины кроме корня надо выбрать ровно одно входящее ребро, если вы выбрали ровно
одно входящее ребро, то получился остов, так не успел сказать найдите ошибку, да, действительно,
просто выбрать ребро это недостаточно, потому что если вы просто для каждой вершины выберете
входящее ребро какое-нибудь, да, как-нибудь, то вы можете выбрать, то есть до чего-то из
вы дойдете, а все остальное может быть разбито вот на циклы. Нет, нет, я говорю, нет, ну тут две мысли
немножко перемешались, значит, вторая мысль была такая, что нам нужно, чтобы выбрать минус 100,
хочется сказать, что для этого достаточно для каждой вершины выбрать входящее ребро, но мы
обнаружили, что этого недостаточно, потому что если вы выберете от балды как-нибудь, то может
оказаться, что у вас есть дерево плюс циклы, поэтому выбирать надо как-то чуть более аккуратно,
это была вторая мысль. А первая мысль была такая, что, тем не менее, если мы рассмотрим все ребра
входящие и увеличим их на одну и ту же константу, то минус 100 останется минус 100, потому что в
любом минус 100, то есть в любом 100, в любое 100 в эту вершину входит ровно одно ребро, то есть это
необходимые условия, недостаточные, но необходимые. Если мы возьмем и все ребра входящие в вершину и увеличим на одну и ту же константу.
Одну вершину, но все ребра входящие. Вот. Тогда просто веса всех остовов увеличится на одну и ту же константу.
Вот. И, собственно, мы этим можем воспользоваться и добиться того, что у нас ни одного отрицательного
ребра нет. Понимаете, да? Вот. Более того, заметим, может даже сразу заметить, что если давайте пробежимся из-за, вот,
по крайней мере, базовым алгоритмом двух китайцев, давайте просто пробежимся, например, за О от Е, это честно сделаем.
Тогда заметим следующее. Ну В плюс Е, хорошо. Заметим, что в данном случае В плюс Е это О от Е. Почему? Потому что Е это не менее чем В минус 1, в противном случае
В минус 1 не существует. Поэтому В плюс Е здесь это О от Е. Вот. Вот. Ну теперь, тогда утверждаю следующее.
Такой тупой тюнинг. Если после этого окажется, что вы можете дойти от вершины Р до всех остальных по нулевым ребрам, то поздравляю,
что В минус 1 вы нашли. Есть такое ощущение, да? Вот. Но с другой стороны есть, конечно, И. Вот еще. Но, конечно, нам так повезет не всегда.
Но смотрите, что можно сделать. Можно добиться того, что за В плюс Е, за Е, можно добиться того, что в каждую вершину, кроме корня, будет входить хотя бы одно нулевое ребро, и при этом все ребра будут не отрицательны.
Да, сейчас умная формулировка. Можно добиться того, что все ребра будут не отрицательны, но при этом в каждую вершину будет входить хотя бы одно нулевое ребро.
Да, то есть просто в некоторых вершинах надо не только прибавлять, но и вычитать. Да, это тоже будет работать. Вот.
Вот тогда рассмотрим, что у нас тогда представляет собой, давайте вот отдельно нарисуем, что у нас тогда будет представлять собой нулевые ребра.
Ну, рассмотрим какую-нибудь вершину, в нее входит нулевое ребро. Теперь в каждую вершину входит хотя бы одно нулевое ребро. Приятно, да? Вот.
Ну, а теперь давайте думать, что может произойти. Значит, смотрим эту вершину, видите, да? В нее тоже входит хотя бы одно нулевое ребро.
Ну, вот и в эту входит. Ну и так, идем, идем, идем. Ну и чем это может закончиться? Ну, тут в принципе два варианта.
Либо мы в какой-то момент неожиданно упремся в корень, либо зациклимся. Ну, логично, если из каждой вершины мы идем по какому-то входящему ребру.
И оно всегда есть. Значит, как бы либо у нас начнут вершины повторяться, либо мы уткнемся в вершину, из которой мы пойти не можем. Тут, в общем, на самом деле никакой умной мысли тут даже особо не стоит.
Вот. То есть, может быть, цикл. Но это если даже предполагать, что у нас, как всегда, там давайте, то есть, и в общем-то так и будет. То есть, на самом деле это будет какой-то.
То есть, если предположить, что в каждую вершину уходит ровно одно нулевое ребро, а так и будет, если, например, мы будем рассматривать наш любимый случай, когда все ребра попарно различны по весу.
То будет, то так и будет получаться. То есть, будет получаться, что у нас есть какое-то. Вот. То есть, будет дерево подвешенное на корне и какие-то циклы.
Это если все ребра попарно различны. Если нет, то, конечно, тут могут быть какие-то более нетривиальные конструкции. То есть, там всякие какие-то вот такие.
Тут внутри еще какая-то вот такая гадость там может быть. Вот тут все что угодно. Ну, как бы, то есть, по сути, получится все равно дерево.
Ну, может быть, там дерево с каким-то безобразием внутри. Вот тут даже вот так как-то будет. Ну, и так далее. И какие-то. Ну, и какие-то. То есть, будет такое вот дерево.
Ну, дерево. Ну, в общем, короче, дерево в том плане, что ладно. То есть, тоже из-за достижима. То есть, как бы есть дерево и какое-то лишнее безобразие.
И какие-то еще отдельно компоненты сильной связности.
Ну, кактус. Ну, не обязательно это именно кактус. В классическом понимании это слово кактус, конечно.
Это как угодно. Вот это не кактус, например.
Нет, если одинаковые ребра бывают, то такое бывает.
Ну, не совсем. На самом деле мы добивались того, что в каждую вершину входит хотя бы одно нулевое ребро. В общем, все неотрицательные.
И рассматриваем, как выглядят теперь нулевые ребра.
То есть, нет, если бы мы ровно одно выбирали, то тут были бы только циклы не шоу кроме. То есть, было только голое дерево, голые циклы и все.
Кактусы?
Нет, кактусы. Если имеется в виду зацепленные циклы, то такого бы быть не могло, потому что в эту вершину бы и входило.
А, да, пожалуй, вы правы. Действительно, неправда. На самом деле, действительно согласен, да. Может быть, на самом деле еще вот такая ситуация, да, что действительно цикл, на котором что-то подвешен.
То есть, все висит либо на цикле, либо на корне. Вот так. То есть, несколько таких подвешенных безобразий.
Ой, в другую сторону. Да, такое может быть, да, согласен, согласен, согласен, согласен.
Да, хорошо. Вот. Но может быть так, а может быть, ну, может быть, нет смысла рассматривать, может быть, я вот отдельный компонент сильной связности.
Вот. Так вот, что предлагается с этим всем делать? Предлагается сделать неожиданный финт ушами.
Утверждается, что с точки зрения весов, на самом деле, можно и это дерево, и эти компоненты сжать в одну вершину, прям сконденсировать и повторить операцию капсу.
Вот. И так вот, именно ее, то есть, и повторять ее, повторять, повторять до тех пор, пока мы не сожмемся в единую вершину, и тогда утверждать, что мы победили.
По крайней мере, с точки зрения поиска веса. Ну, до победы, конечно. То есть, как идейная победа может где-то и есть, но это будет похоже на, да, скорее.
То есть, это будет как в том анекдоте, когда человек, когда при пожаре математик вышел в коридор, увидел огнетушитель, понял, что решение есть и пошел спать дальше.
Вот. То есть, тут прям вот максимально подходит. Потому что, на самом деле, надо еще, потому что, как бы, проблемы уже начнутся, если вы просто вздумаете, а как, собственно, строить сам мостов?
Тут вот очень аккуратно это надо делать, потому что, знаете, как-то я, потому что, хорошо, давайте внимательно, а то, знаете, а то, знаете, хрустная ситуация была, это я потом прочитал опять.
Вот я приводил пример, на самом деле, по-моему, скорее всего, рассказывал историю. Вот, на самом деле, с этим алгоритмом было. Я потом на себе отзыв читал так.
И там было такое, что это было, было последние занятия, что-то там вот этот алгоритм, мы там до конца разобрать не успели.
Вот. А в доказательстве, на экзамене выяснилось, что в вики-конспектах на доказательстве была ошибка. Арухович это пропалил и требовал правильного доказательства.
Вот. На самом деле, я, по-моему, почти наверно рассказывал уже эту байку. Так вот, она была про этот алгоритм.
Вот. Ну, слава богу, у нас и не конец семестра и времени у нас еще много, поэтому.
У нас, ну. Ну, не корень, а цикл у нас есть.
Ну да. Ну, мистическое что-то тогда.
Не обязательно. Но сжимаем мы только компоненты из нулевых ребер.
То есть, либо, во-первых, сжимаем компоненты из нулевых ребер, а во-вторых, ну и сжимаем, конечно, вот это дерево.
Ну вот. Как восстанавливать? Ну, значит, как минимум, по умолчанию придется это делать рекурсивно.
А именно. Значит, утверждается, что восстанавливать будет так.
Значит, смотрите. Значит, давайте я все это сотру и покажу.
Так. Плохая тряпочка. Так.
О, хорошая тряпочка.
Вот. Значит, смотрите.
То есть, вот у вас будет какой-то, значит, то есть, идея будет такая.
То есть, идея будет такая.
Жил, был.
Вот.
То есть, вот у вас сжались вот какие-то компоненты.
Вы построили минимальный остов на вот сжатом графе.
Значит, восстанавливать ответ предлагается так.
Вот, допустим, у вас там дерево оказалось, но я тут не буду сильно будрить.
Вот какое-то такое. Вот такое, такое, вот такое.
То есть, заметьте, вы берете, смотрите вершину, в которой это произошло.
Это не обязан быть корень, который вы какой-то как-то там ранее нашли.
Ну, да, то есть, тут все что угодно могло быть.
Вот так вот.
Вот.
Но это не корень. Ну, там то, что вы могли считать корнем, могла оказаться совершенно другая вершина.
Ну, мы знаем, что тут компонента сжалась, хотя компонентой могла быть одна вершина.
То есть, видите, вот в этом примере, этот пример показывает, что на самом деле,
то есть, у вас там, то есть, на самом деле, ну, что-то обязательно сожмется, да.
То есть, хотя бы там, то есть, потому что цикл хотя бы длины 2 найдется обязательно.
Но может быть, он будет один, и там, и вообще поэтому количество вершин на следующий итерация уменьшится вообще на одну.
Поэтому алгоритм на самом деле не за такую крутую симптомику, как мечталось бы.
Но, тем не менее.
Каждый компонент в одну вершину сожмется.
Да, но не компонент, а вот.
Только проблема в том, что вот в этом вот случае, как вы же и предлагали, сожмется только этот цикл, а не все дерево.
А, мы сжимаем только, сейчас мы сжимаем компонент в сильной связности.
Да, мы сжимаем компонент в сильной связности.
Для чего мы это делаем?
А делаем это ровно для того, чтобы сказать, что если у нас тут есть какое-то дерево, то как бы внутри мы сжимаем так, мы объявляем это корнем.
Объявляем это корнем.
Значит, запускаем, ну вот, запускаем ДФС.
Там вот запускаем ДФС и объявляем, что, ну вот, и вот остов обхода ДФС и объявляем, что это часть остова.
То есть, но важно, что именно из этой вершины мы это делаем.
Понимаете, да?
Вот, то есть вот так мы это восстанавливаем.
Это компоненты сильной связности.
Да, это вот.
Нет, и более того, это важно.
То есть, на самом деле, хорошо, что вы задали вопрос, именно поэтому мы сжимаем не все вот это дерево, а только компонент в сильной связности.
Вот ровно из-за того, что действительно, чтобы действительно мы все обошли.
Правильно, правильно.
Да, именно, именно.
Это важно, это важно.
Вот, так что вот такой вот механизм.
По крайней мере, остов он нам построит.
Но пока вовсе не очевидно, почему это действительно минимальный остов.
Ну, как сказать?
Что по индукции?
И что по индукции?
Что мы по индукции докажем?
И что?
Само по себе это ничего не знаю.
И что?
Мы тут сказали, что давайте вот гарантировать, что вот это вот, вот тут у нас компоненты сильной связности.
Давайте гарантировать, что у нас будет такое нулевое под дерево, которое тут всю эту компоненту обходит.
То есть, и тут тоже будет, и тут тоже.
И еще и в корне мы утверждаем, что тут по нулевым ребрам мы должны до всех вершин доходить.
Мы можем просто взять любой остов и перестроить так, чтобы...
Да.
Да, только да, вот, да.
Ну да, вот тут-то, собственно, да.
Вот тут-то, собственно, жалобы в отзывах и начинаются.
Потому что не так-то просто это делать, как кажется.
Да, то есть просто, ну как это у нас сейчас будет?
Надо это сделать аккуратно.
Да, это не очень сложно.
Но, да, потому что совершенно верно, да.
То есть, ну пока я говорю так, что как минимум это надо доказать.
Что так можно.
То есть для этого действительно докажем, что существует минимальный остов вот такого формата.
Как же это доказать?
Ну давайте начнем с простого.
Начнем с корня.
Вот утверждается, что если мы тут можем вот так как-то дойти, то утверждается, что можно действительно искать миностов среди тех остов, частью которых является конкретно это дерево из нулевых ребров.
Как это доказать?
А вот как.
То есть метод, как уже было озвучено.
Действительно.
Рассмотрим реальный минимальный остов.
Ну или какой-нибудь, да.
Вот.
Теперь.
Есть какой-нибудь там минимальный остов, с этим вот всем никак не связан.
То есть тут вообще что угодно там как-то вот.
Страдания, страдания, страдания, там боль, боль, боль, там вот это все.
Ну не знаю.
Нет, просто по моим воспоминаниям как-то, не знаю, мне как-то.
Нет, я просто помню, у меня, я вторую свою вторую сещу как-то на отлы как раз закрыл, в отличие от первой, поэтому.
Поэтому там как раз ничего страшного не было.
Почему?
Вот, значит, смотрите.
Давайте теперь вот идея такая, да.
Вот рассмотрим, вот давайте рассматриваем вот эти ребра в порядке внимания БФС.
Да.
А можно и ДФС.
Ну впрочем, главное вот аккуратно, главное чтобы.
Ну чтобы в паре сверху вниз, так сказать.
Значит, но нет, но тут важно в каком порядке, сейчас увидите почему.
Потому что идея такая, вот рассмотрим вот это ребро.
Оно реально, в реальности оно нас ведет куда-то, ну например, вот сюда.
Ну тогда идея очень простая.
Ладно, а давайте вот это ребро в дерево добавим, а вот это отпилим.
Это реально.
Это реально.
Это реально.
Это реально.
Это реально.
Вот тот остов, который нам тут это подсунули за минимальный.
В компоненте сильный запас.
Нет, ну вообще.
То есть мы хотим доказать, что существует минимальный остов, то есть можно рассматривать только минимальные остовы,
частью которых является конкретно вот эта штука.
Вот что мы хотим.
А мы же вот здесь оставили только нулевые ребра, правильно?
Тут все ребра нулевые.
Ну зеленые, только нулевые.
А синий я не знаю.
А вот эти вот между компоненты.
А, все, все.
Да, но важно, что, но сейчас мы будем важно пользоваться тем, что они не отрицательны.
Где мы этим пользуемся?
А мы этим пользуемся, когда вот заменяем вот это ребро на это,
то есть от того, что мы заменили, вес ребра не увеличился.
Да, кстати, вот это ребро теортически тоже, могло быть зеленым.
А может и нет, я не знаю.
Но самое главное для нас, почему мы, как бы, чем мы, ой.
Ну, а вот точно зеленый значит.
Круто.
Чего мы, так, чего говорите?
А вот точно тоже зеленый, тоже нулевой.
Ну, можно и так сказать, да.
Ну, что бы, ну, самоимечательно.
Если бы мы, ну, новое нулевое ребро хребетия удалили бы не нулевое,
если бы мы, ну, новое нулевое ребро хребетия удалили бы не нулевое.
Ну, да.
Ну, согласен, да.
Да, просто.
Или, можно сказать, да.
Нет, или, да.
Ну, тут по-разному можно доказать.
Можно доказать просто.
Пусть это миностов, да.
И тогда заметим, что да, то есть можно это ребро заменить на это, и хуже не стало.
А можно просто говорить, рассмотрим произвольный остов,
и давайте его там превращать в остов такого вида,
и доказывать попутно, что хуже от этого не стало.
То есть тут это уже вкусовщина, а суть одна.
Но самое главное, заметим, что почему тут нужна аккуратность.
Но сейчас вот увидите какая, что как бы, что от того, что мы так заменили вот это ребро,
остов остался остовом, обратите внимание.
Значит, что дальше?
Потому что дальше мы сделаем, теперь сделаем то же самое с вот этим ребром.
Тоже его там.
То есть где-то тут подвесим, вот сюда, а вот это вот удалим.
Тоже остов пока остался остовом.
Значит, соответственно, что у нас тут дальше теперь?
Вот. Ну вот.
Ну вот.
Ну вот. Ну, значит, дальше у нас теперь происходит.
Теперь то же самое делаем с вот этими ребрами.
То есть кажется, что тут вот могут быть какие-то проблемы.
То есть, видите, если там вот основные проблемы были с тем, что если вы просто
отболдываете в каком-то порядке, заменяете ребра, то может так случиться,
что остов в какой-то момент тупо перестанет быть остовом.
Да, но если это делать именно в порядке БФС, то никаких проблем не будет.
Почему проблем не будет?
Потому что на этот раз вот эта вершина не может оказаться предком этой вершины,
потому что в противном случае она была бы уже в нашем вот этом зеленом остове.
Нет, но имеется в виду следующее, что в каждый момент времени у нас происходит следующее.
То есть у вас есть вот, то есть у вас уже тут построена какая-то часть вот этого зеленого остова,
и на ней там еще какие-то красные висят, в том числе, кстати, и на корне. Почему нет?
Но заметим и здесь синие ребра, кстати, отметим на всякий случай, что они тут тоже на самом деле могут
и вот таким вот образом идти. Почему нет?
Да, но это нам не сильно принципиально.
И вот нам очень хочется какое-нибудь тут следующее ребро зеленое вот тоже в БФС добавить.
То есть ну тут, конечно, тут какое-то тут безобразие, безобразие, безобразие, безобразие, безобразие, безобразие.
И вот неожиданно у нас тут потребовалось, чтобы следующее ребро было ввело вот сюда.
Но заметим, что никаких проблем с тем, что вот добавить вот это ребро от пилитета у нас нет.
То есть единственная проблема, которая могла быть, когда мы заменяем ребро на ребро, чтобы остов остался остовом.
Но мы заметили, что до этой вершины мы как могли дойти от корня, так и можем.
Ну вот, просто черезо зеленое, поэтому все в порядке.
Но если бы такое ребро было бы брать предка, которое мы добавили.
Ну да, но потому что, смотри, какая была бы ситуация.
Вот если вот совсем от балды, то могло бы сказать так, что мы хотим в остов добавить вот такое ребро.
Вот мы говорим, так, ну давайте вот это вот добавим, это добавим.
Но тогда бах-бах, у нас тут цикл образовался.
Да, поэтому надо, вот поэтому наша задача просто следить за тем, чтобы такого не было.
Но конкретно в этом случае мы вот просто, если мы эти ребра в порядке БФС обходим.
Ну да, по большому счету можно было и ДФС обходить.
Но самое главное, чтобы каждое ребро рассматривалось после всех своих предков.
Этого хватит.
Ну конкретно в этом случае.
Итак, мы, значит, добились того, что эту штуку действительно можно сжать, а потом, собственно, так жественно предъявить как ответ.
Вот, понимаете, да?
Вот.
Значит, что у нас происходит теперь?
Значит, что у нас происходит теперь?
Ну да, нет, но это означает, что конкретно вот компонент, то есть вот это вот то, что мы можем по нулевым выборам дойти от корня.
То есть мы действительно это можем сжать и искать минус 100 вот в предположении, что у нас внутри дерево будет такое.
То есть вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Теперь чуть более сложная.
Теперь чуть-чуть, но чуть.
Теперь вот заметим, вот рассмотрим вот эти все компоненты.
Вот мы хотим показать, что действительно можно искать минус 100 в предположении, что каждая компонента будет образовывать связанное, так сказать, под дерево.
Ну под дерево там с отпиленными пустиками, так сказать.
Ну в том же смысле, в котором у нас были компоненты.
Ну то есть что у нас там будет, что у нас там условно в этом будет вот какое-то дерево.
Ну вот. И что любое там, и что наша компонента будет образовывать какое-то под дерево вот такого вида.
Ну подвешенное.
Ну вот, нет, а мы хотим доказать, что обязательно стоит искать именно так, чтобы оно таким и было.
Значит как это доказывать?
Ну доказывать ровно так же.
Ну да, поэтому.
Ну да, тут идея будет в том, что в этом дереве надо просто из этих всех вершин выбрать самую высокую.
Ну то есть выбрать самую высокую, чтобы у нее там предков среди этих вершин не было.
И после этого действительно строить стол, то есть там запустить из нее, то есть там соответственно будет запустить из нее вот это она, вот это она.
Строить из нее, запустить из нее тут тоже построить вот это вот дерево внутри компоненты и построить его просто в этом столе.
Вот такая вот будет идея.
То есть тут тоже аккуратно с этими всеми отпилами и так далее и тому подобное.
Да, получается, да, но правда я боюсь, у этого доказательства есть один маленький изъян.
Потому что изъян заключается в следующем.
Да, мы доказали, что существует минус 100, в котором можно сжать эту компоненту.
Но на самом деле нам же требуется доказать больше, чтобы все одновременно.
Ну по сути да, ну тут на самом деле да, то есть будет это из цикла, как сжимать компоненты, очень просто, рассмотрим все эти компоненты.
Ну то есть так, сначала сожмем корень, это мы все сажали, все хорошо.
Но на самом деле после этого делаем так, рассматриваем компоненты, в каждой находим вершину, которая выше всех и из них выбираем компоненту, в которой самая высокая вершина находится совсем-совсем выше всех.
Вот сжимаем ее.
Ну вот, но потом заметим, что эти компоненты могли переподвеситься там все.
Вот понимаете, да?
Поэтому кто-то оказался выше, кто-то ниже, поэтому каждый раз нам придется заново выбирать, кто выше, кто ниже.
Вот тогда это если вот так уже действительно уже аккуратно довести, то тогда действительно вот это уже победой будет.
Все совсем больно?
Ну тебе-то да.
А Данил что-то страдает.
Компоненты.
Постовы.
Более.
Ну да.
Да.
Почему, если мы в случайном порядке, у нас может нарушиться эта структура? Мы же никогда не будем выдерживать вершину из компонентов в районе рассмотания.
Ну там.
Ну по-по-по-по-по-по.
А основной код припадет, конечно.
Ну вот да, там просто.
Хотя.
Нет, ну просто.
Нет, ну как бы нам что надо сделать.
Вот мы тут построили вот это дерево.
Допустим оно висит, вот с ним все хорошо, да.
Теперь вот думаем.
А если мы возьмем вот эти.
А теперь давайте будем пытаться не трогая это под дерево припадвесить вот это.
Ну просто какими мы делаем операцию, мы добавляем вот одно ребро, удаляем другое.
Но ведь мы никогда не будем делать вершины из того под деревом, это будет вершина только из новой компоненты.
Поэтому с другой компоненты бороться не будет.
Мы ни одно ребро не удалим.
А, ну получается да.
Ну и все, когда оно даже не в порядке.
Ну да, получается да.
Так, хотя.
Или что-то все-таки порочисто.
Ну давай.
А, ну хотя ладно.
Ну тут получится так.
Самое главное, что да.
То есть утверждается, что вот эта компонента при перепадвешивании уже не пострадает никогда.
То есть она может переподвеситься.
Нет, она уже не переподвесится, потому что мы эту вершину трогать никогда не будем.
Ну, ее родители где-то все-таки могут.
Ну да, нет.
Да, у какого-то ее родителя может замениться ребро, но это лишь означает, что само это дерево переподвесится.
Да, но заметим, что у этих вершин ребра мы больше никогда не поменяем, поэтому структура останется.
А мы всегда аккуратно следим, что у нас при каждой замене дерево остается деревом.
А, ну да, вроде ладно все.
У страха глаза велики.
На самом деле все нормально.
Ладно.
Значит в самом начале делаем мы следующее.
Мы, значит во-первых, значит каждая фаза алгоритма говорит нам следующее.
Значит у нас есть граф.
Да, взвешенный.
Мы, во-первых, за е, за от е добиваемся того, что нету отрицательных ребр.
Но в каждую вершину кроме корня входит хотя бы одно нулевое.
Значит на этих нулевых ребрах мы делаем две вещи.
Во-первых.
Ну, в моей интерпретации.
Ну, нулевых ребров.
Да, вот рассмотрим только нулевые ребра.
Нулевые ребра.
Вот я когда зеленый рисую.
Нулевые ребра.
Во-первых, есть так, по не нулевым ребрам из эра мы некоторые вершины достижимы.
Это во-первых.
Вот.
А также у нас еще есть какие-то компоненты сильной связности.
На этих нулевых ребрах.
Абсолютно.
Ну, на этих нулевых ребрах тут еще какие-то безобразия могут быть.
То есть входящие, тут висящие.
Вот так вот.
Нулевые как бы создали и все остальные просто забили.
Почему из корня будет хотя бы одна вершина достижима?
Ответ.
Не почему.
Это не обязательно.
Нет.
Ну, что-то будет достижимо.
Хотя бы сама.
Будет ли что-то большее?
Не знаю.
Более того, как бы если вы думаете, что там граф обязательно сожмется хотя бы в два раза, это вообще неверно.
Потому что может быть вообще такая грустная ситуация, когда вот.
Это вообще неверно.
Потому что может быть, потому что может образоваться вот вообще вот такая грустная ситуация.
Да, но для начала давайте обсудим, а что такое сжать.
А сжать мы теперь говорим так.
Значит, смотрите.
То, что, до чего мы изр по нулевым ребрам дошли, мы сжимаем.
А также сжимаем все найденные компоненты сильной связности.
На графе с нулевыми ребрами?
Да.
Значит, мы сжимаем вершину.
Вершина.
У нас образовался граф.
С меньшим числом вершин.
Насколько меньшим?
Возможно на одну вершину.
Меньшим вот как в этом тесте.
На этом новом графе мы повторяем.
Мы рекурсивно находим миностов.
Вот.
И тогда и разжимаем эти компоненты.
Что значит разжимаем?
Это означает, что, во-первых, мы как бы вместо этой вершины добавляем корень и вот этот вот остов, по которому мы тут прошлись.
Да.
Да, напоминаю, исходно тут, конечно, вот это могла быть и вот такая история какая-то, в принципе.
Поэтому надо оставить только остов.
А в каждой компоненте мы, ну значит, мы для каждой вершины смотрим, по какому ребру мы в нее нашли в этом миностове.
По какому-то вот такому ребру мы дошли.
Всякое бывает.
И из него, можно сказать, запускаем DFS.
Вот так вот.
Вот.
Аккуратненько запускаем.
И все.
И после этого мы говорим, что мы победили.
И говорим, что, собственно, полученное это и есть миностов.
Вот так устроен алгоритм.
Все остальное обсуждение, это аккуратные попытки доказать, что это вообще правда.
Не-не-не.
Ну оставили, естественно, только ребра, которые соединяли разные.
То есть то, что было внутри, оно сжалось.
Вот.
Значит, на оставшемся, на полученном графе мы тоже нашли миностов.
Рекурсивно.
А теперь разжимаем.
Каждая вершина разжалась.
Каждая вершина, то есть у нас была бы жирная вершина.
Но в ней осталось какое-то входящее ребро и куча исходящего.
Но когда мы разжимаем, нам ее нужно заменить на какое-то зеленое поддерево.
Ну мы просто смотрим, что это ребро на самом деле, оно входило в какую-то вершину.
Да, мы вершину запускаем DFS.
Да, мы знаем, что из этой вершины достижимы все, потому что это компоненты сильной связности.
Ну вот.
Поэтому, то есть это вот тут аккуратненько теперь превращается внутри себя вот в такую красоту.
Конечно.
Да.
Ну сжатие проблема.
Ну здесь сжатием никаких проблем нет.
Более того, кстати, нет, сразу сжатием проблема вот в этих компонентах.
Потому что непонятно, кто из них корень компоненты будет.
Да, но это мы выясним потом, когда это дерево рекурсивно будет найдено.
То есть заранее мы это предсказать не можем.
Вот.
И не должны.
Вот, да.
Ну сжали, да.
Нет, проблема в том, чтобы аккуратно описать, как мы корень компоненты.
Ну сжали, да.
Нет, проблема в том, чтобы аккуратно описать, как мы приводим рожатие.
Да, если для вас это не проблема, то ну и хорошо.
Нет, мы не только корень.
Нет, не путайте, корень просто тут видимо.
Под этими словами может подмениваться несколько смыслов.
Да, но мы все метавершины разжимаем.
Ну по одной.
Ну в данном случае да.
Но пока это говорит нам только о том, что мы построили остов.
Ну вот.
Да, то есть дальнейшее мучение это то, почему он вообще минимальный.
И что?
И что?
Нет, понимаете, мы, да, ну и что?
А кто сказал, что обязательно там по нулевым ребрам надо бегать?
Может вместо этого надо было просто?
Да, почему мы?
Почему обязательно?
Может тут надо это как-то подразбить?
Это там, это отдельно, это отдельно.
Будут конечно куча положительных ребер, но суммарно они будут меньше, чем то, что получилось, если мы сказали, что мы это жестко сжимаем.
Нет, мы же разрешили ставим, кажется, все и то, что у нас минастовы растут на одинаковую константу.
Ну, как сказать, ну как бы от одного этого лайхака до вот этих сжатий все-таки тут еще доказывать и доказывать.
Потому что мало ли, то есть пока это какая-то конструкция, она выглядит оптимально, но как бы одно дело выглядит, другое дело доказывать.
А то у нас сегодня компоненты сильной связности конструкция тоже выглядела оптимально, но если копнуть, то выясняется, что она валится достаточно быстро, поэтому пришлось фиолетовый цвет выводить.
Ну даже не что-то вроде, а она. Да, то есть этот алгоритм пока работает за ОАТВЕ по причине вот таких вот безобразных тестов.
Так, нет, а что кратенько? Я думаю, тут и заново можно. Значит, алгоритм повторили, так, поняли алгоритм?
Значит, теперь нам надо аккуратно доказать, что это действительно работает. Вот, что нам нужно доказать?
Нам нужно доказать, что существует действительно минимальный остов, в котором действительно все эти найденные компоненты не разрывны.
Ну в том плане, что, ну вот в этом смысле, что у каждой компоненты будет один корень и несколько потомков, в общем, идущих так сказать подряд, то есть не будет такого, что вот это вот, то есть не будет так, что это не в этой компоненте, а эти из этой компоненты. Такого не будет.
Ну нам надо доказать, что если, что у нас в нашем остове, в минимальном, что можно сказать, что существует минимальный остов, в котором для каждой компоненты сильной связности вот этой нулевой, да, если мы рассмотрим ребра, лежащие строго внутри этой компоненты, то они будут образовывать подвешенные деревья.
Подвешенный остов этой компоненты. Так это, так это как раз и есть переформулировка того, что мы действительно имеем право потом просто сжать эти компоненты в одну вершину и потом искать ответ рекурсивно.
Причем все одновременно сжать, что важно. Нет, можно, конечно, на том уровне доказательства, которые у нас было, мы можем сжать одну компоненту искать рекурсивно дальше, этим точкой, кстати, будет та же.
Почему у нас должно быть вот это непрерывным под деревом, чтобы это соответствовало сжатию?
Ну, потому что когда мы будем разжимать, оно же будет непрерывным под деревом.
Ну, поэтому как бы да. Если вы сказали, что существует миностов, в котором действительно будет сжимать, мы не знаем, кто кормит, то тогда значит мы тогда действительно сжимаем и ищем.
Соответственно какой-то миностов. Потому что потом в будущем какой подвешенный не важно, потому что там все ребра все равно нулевые.
Вот, собственно, чем мы и пользуемся. Теперь как выйдет доказательство? Доказательство будет такое, мы все это сжатые, делаем так.
То есть мы берем какой-нибудь минимальный остов или просто какой-нибудь остов и аккуратно начинаем заменять какие-то ребра на нулевые ребра.
Причем так, чтобы в этот остов вошли сначала вот эти все ребра.
Подождите, мы же сжимали курсивно.
Да.
Тогда у вас же здесь какие компоненты вы рассматриваете при последней интерации разжатия?
Нет, мы что сделали?
Смотри, мы нашли компоненты, как алгоритм устроен, мы нашли компоненты, сжали, нашли шо-то рекурсивно, разжали.
Ну вот, то есть мы доказываем, что мы имеем право сжимать. То есть что значит сжимать? Это означает, что мы ищем миностов?
У нас есть какой-то граф, мы в нем находим эти компоненты.
Значит, у нас известно, что на этом изначальном графе есть какой-то миностов.
И типа мы хотим показать, что все работает хорошо.
Да, что когда мы разжмем этот там?
Сейчас когда мы сажмем начальник, сейчас надо лучше сажать. Это важно.
Но нет, что мы имеем право сжимать. То есть мы имеем право искать миностов среди таких остовов, в которых в каждой компоненты индуцируют понтирила.
Осталось только придумать. Как-то, видимо, надо переформулировать.
В общем, проблема в том, что здесь очень много, здесь в общем 10 минут и заодно пытаются.
Да нет, вроде.
То есть мы сейчас итерационно доказываем.
Да нет, ну по сути по индукции доказываем.
Ну да.
Хорошо, тогда у нас есть на каждой итерации, когда мы спускаемся вниз по алгоритму.
Ну да.
У нас на данную итерацию есть какой-то граф.
Ну да.
Там какие-то вершины, они на самом деле мета-вершины, но мы это как бы не знаем.
Ну.
Вот.
Значит, мы вот на этом графе знаем, что есть какой-то миностов.
И в тоже время строим эти, ну, ищем компоненты сильной связости.
Вот в этом графе.
Этот это какой?
Это который в данной итерации.
Угу.
То есть вот для данной итерации у нас есть какой-то граф, для которого мы, ну, теоретически знаем миностов, что он есть.
И еще на нем строим компонент сильной связости.
Ну, на нулевых ребрах.
Мы еще напоминаем, ребра висающие и подгоняем.
Это самое начало, оно сделано.
Нет.
Просто завернем, что мы в рекурсии-то тоже это будем делать.
Зачем?
Они же у нас...
Потому что там вот эта вершина сожмется и, возможно, в эту компоненту не входит ни одного зеленого ребра.
Ну, мы же...
Поэтому там будет абсолютно фактически, поэтому там веса еще поменяются.
Тогда я уже опять не понял, как это.
Мне казалось, что мы, типа, вначале в самом...
Нет, смотри, да.
Смотри, нет.
Да, в начале мы все...
Да, мы в начале добились того, что...
Добились того, что у нас есть нулевые ребра и все...
Да, в каждую вершину, кроме корня, входит ровно...
Входит хотя бы одно нулевое ребро.
Мы на них построили компоненты.
На нулевых?
Да.
Сильной связости.
Да.
Построили компоненты сильной связности.
Да.
Сжали их в одну вершину, сконденсировали.
На, получившимся в сжатом графе, мы рекурсивно нашли миностов.
В сжатом графе ребра у него какие вот у сжатого графа?
Мы добавляем обратно те, которые остались не нулевыми?
Да.
И которые будут между компонентами еще нулевыми?
Да, конечно.
Вот тогда окей.
Да, конечно, будет нет.
Потому что на этих нулевых ребрах, возможно, тупостого не существует.
Ну, знаете...
Нет, ну то есть так сказать, если существует, то вообще алгоритм на этом закончен,
потому что все доступное из ЭР по нулевым ребрам это победа.
Поэтому как бы...
Хорошо, вот теперь все.
Вот, да, старые ребра мы добавили.
Ну вот, возвращаем на место.
Да, теперь аккуратненько доказываем, значит.
Почему сжимать можно?
Почему вот так действительно все эти компоненты одновременно можно сжать?
Ну, просто мы берем любой остов и аккуратно начинаем подменять ему ребра.
То есть на каждом шаге мы там заменяем одно входящее ребро в вершину на другое.
Так что остов остается остовом.
Но при этом мы заменяем там какое-то условно...
То есть какое-то ребро на зеленое ребро.
При этом, что самое важное, старые зеленые ребра не убираем.
Потому что наша цель добиться того, чтобы внутри каждой компоненты было остовное под дерево истины на зеленых ребрах.
Пока вроде да.
Ну вот.
Ну, самое легкое.
Ну, то есть будем делать это...
Ну, начиная вот с этой вершины.
То есть ребра будем перебирать в порядке БФСа, скажем.
Ну вот.
Ну, почему в порядке БФСа?
То есть для того, чтобы убеждаться, что когда вы тут подменяете ребро на другое,
у вас тут не получилось цикла какого-то.
Ну или что то же самое.
Нам нужно...
Мы контролируем, что когда мы подменяем одно ребро на другое, у нас все еще доступно от корня.
Вот.
Да, на зеленом.
То есть сначала вот эти ребра.
Мы их можем добавить, потому что они ведут прямо из корня.
Поэтому, что было доступно из корня, то и будет доступно из корня.
То есть, ну, самое главное, вот эта вершина будет доступна из корня.
Значит, все ее под дерево тоже будет доступно.
Сейчас.
Нет, красный это...
Ну, просто произвольный какой-то остов.
Можно даже не обязательно минимальный.
Ну, если хотите, можно минимальный.
Это неважно, мы этим не пользуемся.
Нет, мы доказываем тем, что мы можем подменить у него ребра на ребра так,
чтобы они как бы образовывали вот эти компоненты под деревья.
И при этом то, что получилось не больше, чем красный.
Не хуже.
То есть это будет так.
Для любого остова существует остов хорошего, то есть хорошего вида, который не хуже.
Это и будет означать, что минимальный остов можно искать среди остовов там вот такого вида.
Такого вида.
Значит, сначала мы туда аккуратненько имплантируем вот это дерево.
Потом из этих компонент у нас получился какое-то дерево.
Заметьте, у нас тут под деревья переподвешивались только так.
Поэтому после этого мы смотрим вот эти компоненты.
В них находим самую высокую вершину.
Вообще самую высокую.
Допустим, какая-нибудь там вот она, скажем.
Самая высокая вершина, да.
И мы ту же операцию проворачиваем.
Ну, то есть находим внутри этой компоненты сильной связисти под деревом, сколько именно в этой вершине.
То есть старая, которая у нас жарит?
Нет.
Ну, я пока еще...
Компонент сильной связисти это вообще пиздерит.
Да, но компонент сильной связисти, опять же, что это такое?
Это такой граф, в котором можно взять любую вершину и запустить DFS и построить астоп с корнем в ней.
Мы из этих вершин выберем самую высокую вершину.
Потому что у нас сейчас есть вот наше дерево, которое мы тут переделываем.
Причем прямо сейчас.
В момент, когда мы уже разобрались.
То есть когда мы уже с этой разобрались, она уже есть.
Все, мы это дерево больше трогать не будем.
Теперь возьмем самую высокую вершину из этих вот всех.
Вот пусть она вот в этой компоненте, вот она.
Рассмотрим ее вот зеленое под дерево с корнем в ней.
Ну, какое-нибудь.
Зеленое под дерево с корнем в ней?
Внутри этой компоненты.
Хорошо рассмотрим.
Вот тогда аккуратненько имплантируем его в наше дерево тем же методом.
А очень просто.
Значит давайте еще раз.
Мы перебираем эти ребра в порядке BFS здесь.
И каждый ребро говорим, что если это ребро уже есть в дереве, то все хорошо.
Если нет, то мы его добавляем в дерево.
И удаляем входящее ребро вот в эту вершину.
Ну вот.
То есть делая это в порядке BFS мы гарантируем, что на каждом шаге дерево остается деревом.
Ну вот.
Ну нет.
Дерево осталось деревом.
Ну как бы, если мы одно ребро добавили, одно удалили и все еще доступно искоре, значит это и остов.
Причем хуже он не стал, потому что мы заменили какое-то ребро на нулевое ребро.
Конечно.
У нас все подвешено за R.
Вот здесь в общем-то тоже мы примерно то же самое делаем.
Здесь конечно уже хитрее, потому что эта вершина уже не совсем R.
Но мы знаем, что она самая высокая.
Поэтому окажется, что у нас до этой вершины на самом деле есть теперь какой-то вот такой вот путь.
Но когда мы будем вот это дерево строить, то мы вот эти вершины трогать не будем.
Понимаете, да?
И вообще мы ни одной вершины, ни одной из этих компонент, кстати, тоже не тронем.
Обратите внимание.
Ну вот.
Ну хотя нет, теоретически тронем в каком плане входящие ребра в них.
Исходящие, то есть может быть нам придется, может быть тут на самом деле у нас в дереве было вот какое-то вот такое ребро.
Мы его сейчас удалим для того, чтобы добавить вот это.
Но ничего страшного само по себе это не делает.
Потому что мы замечаем, что эта вершина, она была доступна из R и осталась доступна из R.
Мы вот аккуратно проследили.
Потому что, видите, когда мы заменяем ребро, единственное, почему может произойти, что эта вершина перестала быть доступна,
это то, что, допустим, она была, то есть это то, что, скажем, она была доступна только, скажем, по этому ребру.
Вот, то есть она вот, то есть может быть откуда-то отсюда шли.
Но это возможно только при зацикливании.
Ну, потому что в реальное красное дерево могло быть устроено вообще как угодно. Вот как-то вот так вот оно могло быть устроено.
Какое-то вот такое безобразие.
А что такое?
На скорень был, была та вершина, в которой входит ребро.
А, ну это я, ну я, я выбрал самое, ну там дерево могло быть так, что в эту компоненту пока входят и два, и три, и четыре ребра.
То есть да, в какой-то момент, кстати, да, вот это вот там тоже придется отпилить на самом деле, но это я от балды нарисовал.
Да, то есть надо было, может, правильнее вот эту красную там куда-нибудь сюда, но не важно.
Ну да.
Так что, ну вот.
Ну вот.
Так что, да, то есть главное следить, то есть главное аккуратно следить, да, что когда вы тут ставите ребро, что эта вершина не была потомком этой вершины.
Вот, а потомком она не была, потому что мы, собственно, ну здесь она не была, потому что эту вершину мы самой высокой выбирали, да, втровно для того, чтобы избежать этой ситуации.
Вот, тогда сначала построили вот эти ребра, потом автоматически понимаем, что там эта вершина не может быть теперь в новом дереве потомком, скажем, вот этой вершины.
Ну вот.
Ну, потому что если эта вершина предок этой вершины, то она и предок этой вершины, а такого у нас не бывает.
Потому что у нас все происходит ниже этой вершины, и вот эта компонента построена.
Теперь мы аккуратненько действительно потом из оставшихся вершин тоже выбираем там самую высокую, ну и так далее.
То есть мы аккуратно убеждаемся, то есть аккуратно, то есть важно, что с этими компонентами ничего не произойдет, они там нигде не отсекутся.
Ну хотя это, ну вот.
То есть они не отсекутся, потому что заметим, что вот эти вот, конечно, вот эти вот под деревья их мы уже трогать не будем.
Потому что мы не будем, потому что мы для этих вершин не будем подменять входящие в них ребра.
Следовательно, под дерево останется.
И тогда аккуратно разобрались здесь, ну вот, дальше аккуратно разобрались там со следующей компонентой, со следующей, ну и так далее по очереди.
И таким образом мы доказали, что сжимать действительно можно все вершины.
Вот, понимаете, да?
То есть все вот эти найденные компоненты сильной связности реально можно.
Сжимать.
То есть таким образом алгоритм доказан.
Его корректность.
Но правда маленькая проблема, работает он CVE.
Ну как проблема.
Да, на самом деле, честно скажем, что...
Так, вот да, теперь начинается самое интересное, потому что сейчас опять будет новинка.
Вот.
Ну вот, потому что до прошлого года включительно, в общем-то, мы бы на этом и остановились.
Да.
Но, как всегда, да.
Ну вот, а теперь задача.
Теперь задача вот такая, что...
А теперь утверждается, что можно это реализовать за E лог В.
Использовав магическое словосочетание, сливаемые кучи.
Внимание, вопрос.
Как?
Вот действительно, как вы думаете?
Как же мы могли бы действительно тут это все забабахать?
Ну да, что такое сливаемые кучи, да?
То есть это кучи, у которых есть операция возьми две кучи и объеди.
Ну и понятно, Ирина, ну и как это?
И объедини.
Ну и понятно, Ирина, ну и как всегда, со старыми интерфейсами типа добавь элемент в кучу, там достань минимум, там посмотри минимум, достань минимум.
Ну, собственно, и так далее и тому подобное.
Ну вот, вот теперь давайте думать.
Вот как вы думаете, вот как вы думаете, где здесь можно выковырить, собственно, E лог В?
Вот как вы думаете, где здесь его можно выковырить?
Ну действительно, в первую очередь, с одной стороны рекурсивно, да, но с другой стороны, смотрите, можно сделать так, вот мы говорим нулевые ребра, нулевые ребра математически, да?
Но в реальности, на самом деле, мы говорим, что мы можем сказать, назовем ребро зеленым, если оно обладает минимальным весом среди всех ребр, входящих в эту вершину, правда?
По факту-то, да?
И работаем мы именно на этих зеленых ребрах.
Вот, соответственно, вот, ну вот, поэтому, да, то есть, возникает действительно идея, что искать, действительно, эти минимальные ребра, действительно, можно было бы, вот, по принципу, что, то есть, давайте для каждой вершины все входящие ребра храним в какой-нибудь куче.
Ну да, достаем оттуда минимум, а когда там у нас какие-то вершины сжимаются в компонент, мы эти кучи такжественно сжимаем.
Ну сливаем, да.
Ну вот, ну, да, сливаем, да.
Сливаем, да.
Вот.
Ну, правда, то есть, вот, на уровне идеи, да, то есть, действительно, если мы, то есть, если бы мы за быстро как-нибудь умели находить, а что надо сливать, вот какой-нибудь вот такой циклик находить хотя бы, да?
Вот хотя бы циклик. Ведь, на самом деле, заметим, тут даже можно ослабить доказательства, потому что мы могли бы работать по принципу, построим, то есть, допустим, у нас есть зеленые ребра, да?
Если у нас эти ребра образуют какой-нибудь циклик, то мы этот циклик сжимаем и дальше запускаемся типа рекурсивно, да?
А на самом деле мы сжимаем так, мы сжимаем циклик, да, обновляем понятие зеленые ребра, потому что когда мы сжали циклик, да, теперь нам нужно находить минимальные ребра, которые входят вот в целые четыре вершины вот эти.
Ну в данном случае, четыре или сколько там их в цикле.
Вот. Но для этого, как раз, мы делаем кучу сливаемыми, то есть мы сливаем четыре кучи, они достаем минимуме, причем аккуратно следим, что если у нас какое-то ребро сейчас лежит уже внутри одной компоненты, то мы его типа игнорируем.
То есть лишних таких операций, так как каждое ребро будет выкинуто не более чем один раз, поэтому там больше чем ЕЛОКВМ и на это не потратим.
Вот.
Ну и теперь остается только интересный вопрос. А как же нам аккуратно следить?
Как же нам вот аккуратно находить, а что вообще надо сжимать?
Как бы мы могли это сделать?
Вот давайте внимательно подумаем.
Вот даже, даже вот дам чуть-чуть подумать.
Компонент сильно связан с опытом.
Вот.
Забыстро. Задолго. Ну В плюс Е, да.
Потому что он, не знаю, не искрает сильно связанности, а и только циклики.
Да, да, поэтому да. То есть действительно искать течение, что можно искать напрямую циклики, это было бы удобно.
Более того, я вам даже больше скажу.
На самом деле мы всегда можем предположить, что ребра у нас все попарно различны.
Ну потому что даже если они попарно не различны, да, ну мы же можем мысленно эти эпсилоны навесить, помните?
Ну там, ну идея такая, что даже если они различны, то давайте рассмотрим какой-нибудь очень-очень-очень-очень-очень-очень-очень маленький эпсилон.
Вот прям очень маленький.
И прибавим к каждому ребру там, допустим, эпсилон умножить на два в степени его номер.
Да, чтобы, ну во-первых, мы сделали их разными, то есть разными настолько, что как бы,
то есть теперь, ну теперь заметим, теперь я просто могу гарантировать следующее.
Что мало того, то есть я так гарантирую так, мало того, что у нас все ребра теперь попарно различны.
Так еще и я утверждаю, что веса всех этих ребр тоже, веса всех остовов тоже стали теперь попарно различны.
Но самое главное, что я утверждаю, что вес каждого остову увеличился не более, чем эпсилон умножить на два в степени количества ребр, правда?
И еще умножить на два.
Да, логично.
Вот, но соответственно теперь, если, ну если предположить без особого ограничения в обществе, что все веса у нас целые, например,
но вот, то тогда окажется, что все веса, то есть как бы, если эпсилон взять достаточно маленьким,
то тогда окажется, что если были два остова и один был меньше другого, то так и осталось.
Потому что разность между ними была один, а увеличились основы не более, чем на, там, эпсилон на два в степени, там, что-то там, и эпсилон, если взять очень маленький.
То есть поэтому на уровне идеи, то есть можно, на самом деле, не заморачиваться об случае, то есть считать, что все веса попарно различны.
То есть с точки зрения реализации это будет выглядеть как, что просто вы считаете, что если ребра по весу равны, вы их сравниваете тупо по ID-шкику.
Вот, понимаете, да?
Вот, понимаете?
Отлично. Вот, топилича.
Но тогда, что это нам дает? Это нам, тогда, чем нам приятен случай, когда у нас все ребра парно различны?
Он нам приятен тем, что в каждую ребро, в каждую вершину, кроме корня, будет входить ровно одно ребро, правда?
Понимаете, да?
Ну вот, там скажем, ровно одно ребро.
Но тогда давайте посмотрим, как же у нас выглядит, как же у нас выглядит граф, в котором в каждую вершину, кроме корня, входит ровно одно ребро.
Ну вот.
Ну да, то есть действительно, заметим.
Ну да.
То есть действительно, то есть заметим следующее, да?
Ну давайте, как в этом убедиться? Просто мысленно в этом всегда убеждаться.
Ну это, думаю, там это...
А, или это так скучно, что все уже в телефонах?
Нет? Ну мало ли.
Нет, я понимаю, что нет, просто боюсь, что то, что я сейчас рассказываю мне на уровне ощущений, просто многие олимпиадники придумывают на олимпиаде сами.
Ну просто тут идея такая, как выглядит граф, в котором в каждую вершину входит ровно одно ребро.
Ну вот, для этого рассмотрим вершину, рассмотрим входящее в нее ребро.
Вот оно пришло откуда-то.
Сюда тоже входит какое-то ребро.
Вот.
И сюда входит.
И будем так идти.
Ну как бы уже сказали, мы либо упремся в наш корень, да?
Да?
Ну вот.
Либо у нас это рано или поздно зациклится.
То есть из этого будет следовать, что каждая вершина доступна либо из какого-то цикла, либо из корня.
Кстати, с этой точки зрения можем просто даже для удобства считать, что просто корень это такая вершина, у которой есть ребро ведущее в себя.
То есть все доступно.
Но тогда заметим, что так как в каждую вершину входит ровно одно ребро, то получается, что если мы рассмотрим, что доступно из цикла, то получается, что есть цикл, в него ничего не входит больше.
Но из него выходят вот какие-то подвешенные деревья.
Кажется, чуть-чуть там сломались ребра.
Цикл не цикл.
Не цикличный цикл.
Да, действительно.
Да, действительно.
Ну ничего.
Не эти.
Эти, эти, эти.
Если бы я вот эти разворачивал, было бы два исходящих.
То есть получается вот такой вот граф, именуемый среди мирного населения Солнышко.
Вот такой может быть.
Иногда Солнышко с щупальцами.
Ну это уже.
Ну я не знаю.
Как бы этот граф именуемый не считается.
Ну вот.
Ну как бы да, в Олипиадах там на всех ростах бывали задачи на самом деле наподобные.
На графы вот на этом.
Там такого вида.
Ну правда, может наоборот.
Там чаще бывает структура, когда наоборот из каждой вершины исходит ровно одно ребро.
Да.
Вот.
Ну и так далее.
Так вот.
Значит тогда у нас вот есть такие штуки.
То есть вот так граф устроен.
И нам нужно находить оперативно циклы и их сжимать.
Вот там как это надо.
И желательно находить их быстро.
То есть в чем доказали мы эту структуру, используя вот это вот просто.
Вот это вот просто взяв одну вершину и жадно начиная из нее идти.
Понимаете, да?
Ну так вот.
На самом деле я утверждаю, что алгоритм использует сливаемые кучи.
То есть в каждой вершине мы храним сливаемую кучу из ребер, входящих в нее.
И зеленым ребром оказывается просто ребро минимальное по весу.
То есть то, которое нам куча вытвердит.
Так вот, алгоритм оказывается неожиданно простым.
Ну или вы сейчас меня завалите.
В принципе оба варианта будут веселыми.
Смотрите, давайте просто применим, будем применять этот же жадник.
Берем первую попавшуюся вершину.
Рассмотрим, будем строить вот такую последовательность, такую цепочку.
То есть берем зеленое ребро, то есть минимальное ребро, входящее в нее.
Вот, берем эту вершину.
Смотрим, берем ее зеленое ребро и так далее.
Идем, идем, идем и строим прям в явном виде эту цепочку.
В какой-то момент счастье закончится.
В какой-то момент счастье закончится.
Но чем оно закончится?
Ну тут два варианта.
Вариант номер раз.
В какой-то момент может закончиться тем, что...
Ну давайте предположим, что в какой-то момент неожиданно обнаружилось, что в какую-то вершину мы вошли второй раз.
Тогда что же у нас получится?
Что же у нас получится?
Ну тогда этот цикл мы можем за от...
Ну тогда мы понятно там где-нибудь в массиве юзид же мы наверно...
В массиве юзид наверно можем хранить, что эта вершина у нас уже была.
Ну понятно вот.
И тогда раз мы находим эту вершину, то значит мы тогда за от длины этого цикла восстанавливаем сам этот цикл.
Мы же все это записываем.
И значит тогда просто сжимаем его.
То есть у нас теперь цепочка.
И вот эту вот новую вершину мы также теперь объявляем единой.
