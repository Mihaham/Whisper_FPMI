Сегодня с вами мы начнем второй раздел, собственно первый это был всякие основы основ, там мы
вспоминали бинпоиски, префиксные суммы, линейный контейнер, теперь мы с вами поговорим о такой
вещи как сортировки, у нас раздел два, это будут сортировки и куча, вот чем будем с вами заниматься
ближайшие две, может чуть больше лекций, и начнем мы с главного и основного, да вообще что такое
сортировка, которая именно нас интересует, определение, а сортировка основанная на сравнениях
это такая сортировка, что в ней можно только сравнивать элементы вау, то есть вы не знаете как
внутри устроены эти элементы, например проинты вы знаете там что это 4 байта, да можно с ними что-то
делать, простроки вы знаете что это там какие-то там набор букв, последовательность, вот конечно,
а здесь мы будем уметь лишь сравнивать элементы, все, то есть это может быть там не знаю, ну что мы
умеем сравнивать, например мы людей мы не умеем сравнивать, но как-то вы допустим определили как
вы сравниваете людей, вот тогда это будет сортировка основанная на сравнениях, потому что больше
ничего с ними не можете, который можно только сравнивать элементы, вот, ну и давайте мы докажем
теорему, теорема звучит так, сортировка n элементов основанная на сравнениях,
работает за вот такую вот интересную величину, работает за оногатый n луган времени, то есть
он требуется хотя бы n луган там на какую-то константу, быстрее нельзя, вот один из тех
немногих примеров когда мы будем доказывать что что-то будет связанное с омегой, ну давайте
докажем, а для этого нам понадобится лемма, она звучит так, луган факториал это θ от n луган,
ну здесь есть доказательство в одну строчку, это если знать формулу стирлинга, ну давайте хоть раз
в жизни притворимся что мы ее не знаем, ну докажем наверное в одну сторону, ну сначала что это будет,
давайте оценим луган факториал вообще, что это такое, ну это сумма по k от 1 до n логарифма в k,
ну очевидно что это меньше либо равно, чем вот такая вот сумма, то есть я k заменяю на n верхним
значением и ограничиваю, но это равно n луган, вот, в эту сторону было легко, теперь надо оценить снизу,
ждем, ну пока напишу очевидно, вот так вот, ну то же самое что и сверху, теперь давайте я откушу от этой
суммы хвост, ну так как села грифма я считаю положительной, ну давайте чтобы здесь эти основания
все-таки, чтобы было корректно с математической точки зрения, возьмем везде двоичный,
ну тогда я могу сделать вот такую вот интересную штуку, то есть опустить первую половину ряда,
ну первую половину суммы, в плане того, что я меняю при делу суммирования и забываю про то,
что там k от 1 до n пополам было у нас, он окей, теперь я могу сделать тогда еще ход дальше,
я ограничу это вот такой вот штукой, то есть я все кашки заменил наименьшим значением,
ну это понятно, уже равно n пополам, логарифм двоичный, это n пополам, вот, ну Леон доказали
с вами, что конкретно, ну логарифм произведения, это сумма логарифмов, отлично, n факториал это
1 умножить на 2, умножить на 3 и так далее, ну я вместо k поставил n, я же сверху оцениваю, все,
логарифма антонная функция, где тета, нет, я просто неравенство выписываю, если не выписываю симптотики,
где нет, это когда есть тета, нет, там будет омега. Ну да, здесь видите, как логарифм пополам,
ну смотрите, окей, я могу сказать больше, ну что это больше либо равно чего, давайте подумаю с
вами, ну как это можно оценить, ну что такое n пополам, а в логарифме 2 n пополам, это n пополам,
вот такая вот штука, да, окей, то есть это n пополам, уберите по основанию 2 от n,
минус n пополам, ну давайте мы сделаем вот как, я утверждаю, что начиная с какого-то n,
эта штука будет больше либо равна что-нибудь типа такого, ну как-то можно доказать, найти минимальный
n, для которого это верно, ну просто решить это неравенство, оно явно или поздно решится,
ну давайте его решим, от n, окей, ну переносим это сюда, это сюда, что мы получаем, получаем,
что у нас здесь n, зеленая натрия, логарифм по основанию 2 от n, больше либо равен чем n пополам,
n сокращаем, этого следует, что логарифм по основанию 2 от n, больше либо равен чем 3 вторых,
ну видимо n больше либо равен чем 2 степени 3 вторых, то есть начиная с таких n, у вас вот
эта вот оценка выполняется, окей, ну для меньших n там нам не очень интересно, 2 степени 3 вторых,
это не очень много, это 2 корни из 2, это что такое, это меньше 3 вообще, с n равны тройке,
у вас все здесь верно, можно здесь строже оценку выбрать, и n на 4 какие-нибудь, и все вообще будет
красиво, вот теперь доказать левму, а теперь будем доказывать саму теорему,
вот здесь будет немножко такое эзотерическое доказательство, помимо того, что оно будет
не математическое, вам придется думать, смотрите, что значит, что вы умеете сравнивать элементы,
и только это делать, у вас, грубо говоря, есть какой-то оракул, у которого вы можете задать вопрос,
правда ли, что x меньше y, и он вам ответит, да, нет, это все, что вы умеете делать,
и причем у вас на вход передается какая-то перестановка, ну там, допустим, мы сортируем
массив от 1 до n, и вам придется просто из чисел от 1 до n такая-то перестановка из этих чисел,
то есть у вас на вход какая-то перестановка, и вы умеете спрашивать, правда ли, что x меньше y,
если да, то я буду менять эти два числа местами, если не это надо, то есть вот ваш массив,
вот у вас здесь где-то x, здесь где-то y, и вы спрашиваете, правда ли, что x меньше y,
если да, то вы такие, окей, хорошо, здесь у нас все устраивало, буду там про что-нибудь другое
спрашивать, если же наоборот, у вас там x больше y казалось, а мне надо поменять их, и дальше про
что-то спрашивать, и того у нас что получается, у нас есть что-то на вход, и дальше у нас есть два
варианта пути, и здесь мы получаем какие-то другие перестановки, снова два варианта,
снова какие-то другие перестановки, и так далее, и так далее, и так далее, вот, ну, после кучи
таких-то раций у нас получится такое вот огромное-огромное дерево, в котором листьям
будут выступать все возможные варианты перестановок, потому что у вас дерево должно
уметь отрабатывать для всех возможных перестановок на входе и выдавать верно отсортированную версию,
это как-таки то, что вы хотите сделать, то есть у вас получается полное бинарное дерево, у которого
n-факториал листьев, потому что перестановок n-факториал, давайте это как-то сформулируем теперь
формально, вообще, такая штука называется решающим деревом, где вы спрашиваете какие-то вопросы,
в зависимости от этого идёте в какие-то ветки, построим решающее дерево,
где в узлах можно спрашивать x меньше y или нет, вот такие от нас вопросы будут,
вот построить такое решающее дерево, тогда у него должно быть n-факториал листьев,
давайте оценим высоту такого дерева, то есть пускай у нас высота дерева h,
сколько у него тогда листьев будет, давайте подумаем с вами, ну да, у вас здесь два в нулевой,
два в первый, два в второй, тогда или два в степня h, откуда вас следует, что его высота
алгоритма двоичная, там факториал, ну это это это Эмбоген, вот он, Полемми. Ну понятное
дело, что алгоритмы не так работают, то есть вы не строите нигде никогда в вашем коде решающее
дерево сортировки и не спрашивайте, правда ли, что x и y должен менять местами, это просто такая
теоретическая модель, в которой мы будем доказывать, что быстрее нельзя, ну и действительно,
мы с вами показали с точки зрения вообще необходимого минимума действий, что нам нужно хотя бы
это от Эмбоген действий, ну значит тогда у нас любая сортировка работает хотя бы за такое время,
за Омега, потому что понятное дело, вы можете построить сортировку, которая будет работать дольше,
но быстрее нельзя, быстрее, чем за этот Эмбоген нельзя.
Доказали? Вопросы? Потому что вам нужно все возможные перестановки собрать. Ну конечно,
например, у вас массив был для двух элементов, да? Вот у вас 1, 3, 2 массив. Ну давайте в индексах это
будет 0, 1, 2. Тогда исходная перестановка, какая будет? Что у вас на первом месте стоит
элемент с 0 индексом, на втором месте стоит элемент с индексом 2 и на третьем месте
стоит элемент с индексом 1. То есть вот ваша искомая перестановка. И как бы я здесь не
переставил элементы, я получу 7 факториал разных ответов. Потому что мы считаем,
что у нас высота это сколько нам операции надо сделать, чтобы спуститься от корня до листа.
То есть у нас есть какой-то вход, и дальше мы должны вот хотя бы Эмбоген спусков вниз
делать, чтобы дойти до ответа. Ну это, смотрите, решающее дерево, да, это такая штука, где вы
спрашиваете, правда ли, что там. Например, здесь вопрос, а ИТ меньше, чем ОЖИТОЕ? И в зависимости
от этого вы идете дальше туда или туда? Кого с кем сравниваете? Я еще раз говорю, что мы доказали в
теоретической модели, что нельзя быстрее, что хотя бы Эмбоген нам потребуется. Ну и стед исследует
Омега большая так-то. Понятно, что вы можете алгоритм медленнее написать. Но мы как бы доказали такую
теоретическую оценку, что лучше нельзя. Вот. Но пока что мы еще не привели ни одного алгоритма,
чтобы от Эмбоген работающего, чтобы можно было строго за это оценивать. Вот. Окей, а теперь что?
Ну давайте построим такой алгоритм. Следующий раздел — это сортировка слиянием.
Просьба предупредить, когда там перерыв будет. Вот. Окей, что такое сортировка слиянием? Устроено
очень просто на самом деле. Психотокод у нее примерно такой. Ну мерч что-то сливать,
поэтому мерч-сорт. Не знаю. От А. Просто А. Ну этот психотокод здесь можно вообще типа не писать.
Вот. Что мы будем здесь делать? Будем вызывать рекурсивно мерч-сорт от А0. Давайте АН сюда
передадим. Н как размер. Н пополам. То есть вот такая вот строка у нас будет. То есть мы будем
вызывать мерч-сорт от левой половины массива. Дальше будет мерч-сорт от правой половины массива.
А ну давайте LR. Даже не так. Ну может здесь LR пойдет по названиям. У нас правда N не
определено. Давайте я напишу твой здесь типа. N равно R-L. Ну я думаю понятно, короче говоря,
что хочу сделать. Вот. И дальше у нас идет следующая процедура. Мерч от A0 N пополам N.
Такая вот интересная сортировка. Ну это все, если что. В чем ее смысл? То есть мы рекурсивно. Сначала
объясню, что такое вообще смысл. Сначала вы разбиваете массив на две половинки. Каждую из них
будто бы сортируете. А дальше вы здесь делаете мерч. Это вы сливаете два массива от сортированных.
Давайте подумаем, то есть как это будет выглядеть. Вот допустим у вас там один массив. И вот допустим у
вас другой массив. Тогда итоговый результат по действию мерч. Это будет 1, 2, 3, 4, 5, 6. То есть
это вот такая процедура. То есть грубый вариант на вход у вас принимает массив 1, 3, 6, 2, 4, 5 и знает,
что у вас здесь граница. То есть это 0, это N, это N пополам. Вот 0, N пополам N. И дальше выполняем
такое вот слияние. То есть два сортированных массива сливают в один. Ну база рекурсии здесь
понятна. Когда у вас один элемент, он отсортирован. Очень концептуальная база. Вот.
Потому что мы хотим отсортированный массив получить в конце концов. То есть смотрите,
мы гарантируем, что после вызова мерч-сорт массив, от которого мы вызвали, или его кусок,
он будет отсортирован. Ну вот. Потому что у нас вот один кусок от 0 до N пополам,
вот второй кусок от N пополам до N. Видите, здесь граница. Вот он отсортирован и он отсортирован.
Но вместе, если вдвоем их сконцентрировать, они отсортированы. Как раз мерч их и сортирует.
Ну должны, конечно. Но это псевдокод и здесь как бы чисто идейная вещь. Вот детали. Ну здесь
понятно, нужно базу прописать сюда. Нормальные аргументы назвать и все такое. Вот. По-хорошему
надо здесь запускаться от L до L плюс R минус L пополам. Вот. Здесь там тоже как-то
называть верно границе и здесь тоже верно назвать границу. Вот. Здесь у нас просто псевдокод.
Окей, давайте, ну это понятно, это рекурсивные вызовы. Теперь надо обсудить с операцией мерч.
Что это такое? Давайте посмотрим, как реализовывать мерч. Сначала идейно. Вот ваши два массива. Это будет
И и это будет G. Вы смотрите, правда ли, что элемент под этим указателем, короче, вот этот вот
элемент под буквой И, правда ли, что он меньше, чем элемент связан с буквой G? Если да, то пишите
его первым. Потому что понятное дело, что минимум вот этого массива, то минимум из этих двух. Потому
что они оба отсортированы. Выписали единичку и сдвинули соответствующий индекс вперед. Дальше
смотрите, кто круче. И лежи. Нужит элемент круче. Выписывайте двойку. Круче в плане меньше. Издвигаете
указатель на один вперед. Дальше здесь три-четыре. Ну три меньше, поэтому выписываем три. Да, если что,
мы все это пишем в отдельный массив. Мы не пишем их как-то на месте, не перезаписываем ничего. То есть
мы здесь до памяти будем выделять. Дальше здесь четыре, здесь пять и шесть. За сколько это работает?
Ну если размеры массивов N и M, то за о-от их сумма. Вот так вот скажем. На это пишем код.
А, Н, Б. Ну псевдокод, конечно. Типа А и Б это что-нибудь типа вектор НТОВ. А Н и М это их там размеры.
Сначала мы говорим, там res равно вектор int там вот N плюс M ноль. Ну что-нибудь такое.
Это же все на уровне псевдокода. Папапам. Ну говорим и ж равно нулю. Теперь делаем while и меньше N,
ж меньше M. Ну и ж меньше M. И начинается, что если А и ты меньше чем B, ж и ты, то что тогда мы делаем?
Ну говорим res и plus j равно а и ты. Ну плюс плюсы. Там иначе. Мы делаем почти все то же самое.
То есть у нас теперь момент, когда один из указателей дошел до конца своего массива. Например, это вот такая вот стадия.
Собственно, здесь вам нужно, вы здесь понимаете уже, что у вас один из массивов закончился. Здесь нужно
описать просто еще два while будет внизу. Который будет в while доводить один массив до конца и while доводить другой массив до конца.
Потому что если вывели все уже элементы в одном массиве, значит все элементы дальше в этом, если бы они тут еще были,
они были бы все строго больше, чем этот. А так этот массив отсортирован, их можно просто подряд все выписывать.
Ну, например, у вас здесь была бы еще семерка впереди. Что-нибудь такое. Вот тогда выписали бы 6, 7, 9 просто вперед идя.
Ну, естественно, здесь вторая часть кода будет что-то типа такого. While и меньше n. Если t plus j равно aity, плюс-плюс и.
И здесь будет еще такое же while, только для второго массива. Причем, заметьте, что while только один всегда запустится, один из двух,
потому что по одному массиву были обязаны дойти до конца.
Ну, там дальше я не знаю, что вы с этим массивом будете делать. Возвращать этот рез или что-нибудь еще там делать.
Это уже, скажем так, не моя забота, как вы это будете реализовывать внутри. Но сама идея слияния, она вот такая вот.
Круто, да? Скоростном времени. Так, окей. Давайте подумаем, за сколько времени работает эта штука.
Ну, как будут идеи, как ценят время работы?
Ну, это хорошо. Да что вы, какой-то мастер терем пользы. Вы помните формулировку?
То есть у нас вот такая вот какая-то с вами рекуррента. Это у нас будет наш мерч, он же за линию работает.
А это будут два рекурсивных вызова мерч сорта. Ну, понятное дело, что вы имеете здесь право оценивать через мастер терему.
У меня что-то так лень. Я лучше оценю как-нибудь вот так вот. Ну, как здесь можно оценить? Что это 4t от n на 4.
Плюс что? То есть я здесь раскрываю. 2t от n пополам. Тра-та-та. Ну, что-то типа 2t от n пополам. Плюс от n.
Ну, давайте я напишу здесь, чтобы без ошек было. Я напишу, что это плюс какая-то константа нож на c. То есть мерч выполняется в время константа на c.
Это константа c. Вот, чтобы избежать потом всяких проблем. Здесь тоже лишнее. То есть 4t от n на 4 плюс 2c от n.
Ну, здесь двойка сокращается. cn плюс cn складывается. Получается 2cm. Ну, вы не поверите, но если я сделаю сейчас третий шаг.
Ну, я сделал катой. 2 в катой. t от n делить на 2 в катой. Плюс k на c на m.
Ну, если вы сделаете здесь еще один шаг, вы поймете, что у вас сюда прибавится 4t от n делить на 4 и все. Что равно?
k равно логарифм на 2c на n. Ну, давайте скажем так, что просто без целой части. Получим, что это просто-напросто c на n на логарифм на 2c на n.
Вот такое. Ну, здесь можно верхнюю часть оценить через плюс один, но здесь нам не очень важно принципиальный порядок.
То есть здесь рекуррента легкая на самом деле. Она не требует никаких специальных знаний. Вот. Ну да, получаем cn лог n. То есть время работы.
Вот. Это один из тех немногих алгоритмов, где мы можем сказать, что это действительно будет t от n лог n.
Во-первых, потому что работает 2o от n лог n. Во-вторых, можно сказать, что быстрее нельзя. Вот как-то так. Да.
Ну, чтобы у нас часть под, то есть чтобы у нас здесь вышел что-то меньше единицы. Ну, конечно.
Ну, потому что у нас t от гамма, где гамма меньше единицы, это ноль. Мы договаривались с вами. Потому что мы не умеем делать там операцию с половинкой элемента.
Так, окей. То есть мы с вами вот построили сортировку, которая работает за t от n лог n. Мы сами молодцы.
Окей. Так.
Так.
Давайте мы сделаем вот как. Сейчас мы начнем немножко другую тему. Если у нас останется время на лекции, то я докажу пару интересных фактов про мерш.
Ну, если не останется, значит не будет на следующей лекции просто-напросто.
Вот. А вам, чтобы задачу решать, нужна сейчас немного другая тема.
Давайте там сотрем.
Собственно, тема называется «бинарная куча». В общем, в целом, что такое куча? Мы с вами обсудим.
Почему? Помершь? Да.
А второй меньше, чем бы первый?
Чего-нибудь типа такого?
Ну, вот вы выписали один.
Сдвинули указатель сюда.
Дальше выписали два. Сдвинули указатель сюда. Выписали семь.
Ну, вот вы выписали один. Сдвинули указатель сюда.
Дальше выписали два. Сдвинули указатель сюда. Выписали семь.
Окей.
Так.
Куча.
Бинарная куча.
Окей. Собственно, куча, что это такое?
Куча – это нечто, что позволяет вам делать следующие операции.
А именно, ставка,
insert,
извлечение минимума.
То есть это нечто, куда можно добавлять элементы и дальше извлекать из нее минимумы.
Ну, в плане извлекать с удалением. То есть у вас там лежали один, два, три, четыре, пять.
Вы говорите, извлеки минимум, а она такая, окей, у тебя осталось два, три, четыре, пять в куче.
И так далее.
Вот. Мы хотим построить такую структуру, которую мы будем делать это и это.
Ну, в частности, мы будем делать это и это.
Ну, в частности, мы будем строить бинарную.
Есть еще другие кучи, есть всякие бидмяльные.
Там фибоначевы,
эливацкие, косы и так далее.
Куча очень много, вот.
И у них там всех разные вещи, у них там разные оценки на время этих операций.
И некоторые из них еще умеют делать мерш.
То есть они умеют как бы две кучи взять и превратить в одну большую кучу.
Вот.
Со сливаемыми кучами я особо на практике не сталкивался.
Но вот с бинарной кучей периодически бывает, да.
Окей.
Что мы будем делать?
Давайте мы просто определим бинарную кучу как что.
То есть бинарная куча.
Это у нас будет полное бинарное дерево.
Полное бинарное дерево,
для которого элемент всегда меньше своих детей.
Вот эта вот фраза, элемент меньше своих детей,
она как раз таки обозначает свойства кучи, инвариант, кучи это еще называют.
Окей, какое дерево называют бинарным?
Дерево бинарное, если оно подвешенное, то есть у него есть какой-то корень,
оно там растет в какую-то сторону.
То есть, например, что-нибудь такое.
Сейчас так вот.
Перед вами бинарное дерево.
То есть каждого узла не больше двух детей.
Вот.
Окей.
Что значит полное?
Полное это значит, что у вас почти все узлы двухдетные.
Ну, как-то понимать.
Вот пример полного бинарного дерева.
Причем, если у узла только один ребенок, то это левый ребенок,
которых слева мы рисуем.
Вот.
Это, например, полное бинарное дерево на сколько?
Шесть элементов.
Вот это вот на трех.
Это на четырех полное бинарное.
Вот.
И при этом мы знаем, что элемент в узле всегда больше двух детей.
Вот.
И при этом мы знаем, что элемент в узле всегда меньше, чем его дети.
Ну, давайте не больше скажем.
То есть у нас выполнено вот такие вот соотношения здесь везде на ребрах.
Ну, тогда понятно, где у вас лежит минимум.
Где минимум лежит такой куча?
Да, в корне.
Вот.
Осталось научиться в нее вставлять элементы.
И удалять элемент, удалять корень.
Ну, полное бинарное дерево, смотрите.
Это дерево, которое...
Вот вы рисуете дерево бинарное,
вы заполните все его слои вот так вот сверху, вниз, слева, направо.
Пока у вас есть элементы.
То есть у вас не может быть вот такой вот ситуации.
Вы можете этот элемент сюда перекинуть.
Теория детей тоже меньше дам?
Ну, для всех детей да меньше, Любровна.
Нет, нет, это деревья поиска будут.
Когда, если вы будете больше здесь писать.
А вы сколько хотите?
Вот. Докажите, что обе эти операции нельзя сделать золоть единицы.
Не такое упражнение, но подумать.
Используя теорему, которую мы сегодня доказали.
Ну, понятно, что если вы возьмете, вставите n раз элементы,
а дальше n раз извлечете минимум все пол от единицы,
вау, вы ассортировали массив.
За отn.
А куча как гнуло.
Мы так не умеем делать, а куча умеет только сравнивать элементы,
мы от нее больше ничего не требуем.
Окей.
Собственно, как...
Ну, за счет чего она будет поддерживать свои свойства,
свойства кучи, так называемые.
Для этого куча имеет две операции со своими элементами.
Одна из них поднять вверх, другая утопить.
Вот.
Ну, или еще просеивание, вверх-низ они называются.
Давайте рассмотрим ситуацию.
Чего-нибудь типа такого.
Вот.
Вот у вас дерево с нарушенным свойством кучи,
у вас для этого узла не выполнено,
что здесь меньше либо равно, здесь меньше либо равно.
Вот. Что происходит.
Эта штука сплапывает с наименьшим из детей.
Просеивание вниз, так сказать.
Просеивание вниз.
Она свапывает с ребенком значение, с наименьшим
причем.
Типа while, типа пока можем, не знаю, давайте по-русски
напишу.
Пока свойство куча нарушено, свапни, ну, обменяем местами
элемент с меньшим сыном.
То есть вот она здесь 10 и 5 свапнула, смотрит, блин,
тут снова свойство кучи нарушено, есть сын, который
меньше меня.
И свойство кучи восстановлено, ура.
Ну, предположим пока что, что мы по элементу можем
знать его родителя и его двух детей.
Пока что это великое знание, которое нам неизвестно,
потом мы придумаем как это сделать.
Допустим, у нас есть этот функционал.
Ну и там будет понятно, зачем нам полнота беременного
нужно.
Собственно просевание вверх, это наоборот, если здесь
вы топили элемент как можно дальше вниз, то здесь
наоборот он будет у вас всплывать.
Чего-нибудь такого сейчас.
Вот такая вот ситуация, и вот вам нужно, чтобы один
всплыл наверх.
То есть у вас здесь нарушено свойство кучи.
Например, можно либо тройку просеять вниз, либо наоборот
единичку поднять вверх, здесь как вам удобнее это все
принимать.
Вот просеивание вверх.
В английском это shift down, здесь это будет shift up.
То есть пока нарушено свойство кучи, меняй элемент с родителем.
Ну и все, это вот две операции, которые вам будут нужны
дальше, мы через них будем все остальное выражать.
Окей, давайте поговорим про выразимость операции
через просеивание.
Давайте обсудим, как будет делаться инсерт.
Ну и давайте какую-нибудь кучу нарисуем для примера.
Вот тут отмена, здесь 3, здесь давайте 2, здесь 5, здесь 6.
Вот что-нибудь такое, вот куча, и тут я говорю, давайте
здесь 4 сделаем.
Вот, я говорю, инсерт 3, что мы тогда делаем, ну конечно,
здесь можно.
Что?
Только как левым ревенком четверки мы его записываем.
Ну это правда, да, и делайте shift up.
То есть будто бы добавляйте ее в дерево, крайним листом,
назовем это так.
Так сказать, спойлерну, потом это будет не дерево,
это будет массив.
Вот.
Мы будем ее в массиве хранить, а не в дерево, там будет
все понятно.
Вот.
Поэтому, конечно, не пугайтесь, что я такими запутанными
фразами говорю.
Добавим элемент крайним листом, сделаем shift up, потому
что свойство кучи может быть нарушено, когда мы
добавили этот элемент.
То есть здесь все было стабильно, и тут стабильность разрушена.
Тогда нужно поднять добавленный элемент вверх, то есть здесь
их свапнуть.
Тогда у нас здесь будет тройка здесь сидится, и свойство
кучи не нарушено выше, и дальше просеивать не нужно.
Следовательно, экстракт мин как делается тогда?
Экстракт мин делается следующим образом.
Вот у меня происходит экстракт мин, происходит страшное.
Шаг первый – это обменять корень с крайним листом,
потому что вырезать корень – это как вырезать голову
всего этого семейства, это слишком жестоко, потому
что тогда непонятно, что с ним вообще делать.
То есть мы в этом меняем их сначала местами.
Здесь будет 4, здесь один.
Дальше, мы говорим, второй шаг – это отрезать крайний
лист, то есть забыть его.
Все, больше нет этого чувака.
Последнее вам нужно, единственное дело, где у вас могло нарушиться
свойство кучи – это в корне, нужно делать сивдаун от корни.
Ну все, давайте подумаем, за сколько это работает.
Так у вас n элементов, то высота бинарного дерева
на n элементах какая?
Log n.
Значит, все за от log n делается.
Обе операции.
За от h, высота куча, равно от log n.
Окей, теперь следующее, чем мы займемся, это как
хранить кучу.
Да.
Какие?
Сивдаун и сифтап?
Ну, свап вы типа берете, ну сейчас мы поймем как-то
сделать так, чтобы это можно было делать мгновенно.
Хранение кучи.
Давайте выпишем снова прекрасное дерево.
Что-нибудь такое.
И давайте выпишем в таком порядке.
Вот так вот.
Раз, два, три.
То есть такого змейка будем выписывать в массив.
То есть сначала один на верхнем уровне, дальше два, три,
дальше четыре, семь, пять.
Нарисуем, что это будто бы массив.
Победа.
То есть мы храним кучу теперь как массив.
Вот, давайте выясним по индексу, где находятся его
левые и правые дети.
Храним в массиве, пусть и это индекс элемента.
Тогда индексы родителя левого сына, правого сына.
Здесь ноль, один, два, три, четыре, пять.
Я утверждаю, что индекс левого сына это два на и.
Плюс один у правого сына два на и, плюс два.
А у родителя это будет что-то типа, сейчас соображу, что-то
типа и минус один пополам.
Так мы с нуля номируем.
Ну, если единицы номировать, то все проще, у вас массив
этого будете с нуля номировать, когда вы будете писать код.
Ну, имеется в виду, что здесь нижняя часть.
Такое вот округление.
Ну, вроде бы сходится по формулам, пять минус один
это четыре пополам, это два.
Четыре минус один, это три пополам, полтора округляем
вниз один.
Вроде по формулам сходится, но строгое, чтобы доказать
вам, нужно понять, что элементов вот здесь столько же сколько
элементов было до него на самом деле.
Ну, просто порисовать деревья и посчитать, и это все получится
у вас.
Я в вас верю.
Окей.
Ну, тогда понятно, что такое крайний лист, по сути.
Вы просто добавляете, будто бы пушбэк в векторе делаете,
то есть добавляете в конец элементов и все.
Вот что скрывается этой загадочной фразой с крайним
листом.
То есть, вот это вот операция, вы делаете пушбэк в вектор,
здесь вы делаете сифтап от последнего элемента.
Сифтап вы с помощью индексов детей и родителей можете
делать.
Экстракт-мин, вы меняете нулевой элемент с последним,
дальше делаете поп-бэк, дальше сифт-даун от нулевого
элемента.
Все.
Поэтому теперь мы умеем делать все это очень быстро.
Вот.
Давайте мы сразу здесь вот такой вот маленький раздел
напишем.
Сортировка кучей или hip-сорт.
Ну как это сортировать с помощью кучи?
For i равное 0, i меньше n, plus, plus i.
Делайте hip.insert.
А i ты какой-нибудь, i это исходный массив, который
надо отсортировать.
Дальше делайте следующую штуку.
For i равное 0, i меньше n, plus, plus i, не знаю, что-нибудь
типа сиаута, сиаут.
Hip.extract-min.
Все.
Можно.
Можно, можно, да, это мы сейчас обсудим с вами.
Ну кажется, у вас эта часть будет занимать на луген
времени все равно.
Здесь-то вы не умеете быстрее делать.
Здесь у вас луген на операцию, n штук, n луген на операцию.
Время от n луген.
Соответственно, у вас здесь появляется такое понятие
как доп-память.
Потому что вам нужно создать хипу, отдельный массив.
Ну наш шорт тоже требовал доп-память, чтобы вы слили
в отдельный массив.
Вот.
Он есть, по-моему, он за лог квадрат работает,
на n лог квадрат.
In place-овский.
Нет, я утверждаю, что есть сортировка, которая не
требует доп-памяти, работает за n луген.
Это правда.
Мы ее проходить не будем, если что.
Потому что это нечто очень страшное, скажем так.
Я даже не вспомню, там на back какое-то у нее название.
Black sort, что ли, по-моему.
Вот.
Окей.
А теперь, да, здесь действительно нам говорят из зрительного
зала, верно, что здесь можно делать это оптимальный
hip insert.
Процедура hipify будет называться.
Давайте рассмотрим наш массив.
И будем делать shift down от каждого элемента.
Начиная с конца.
То есть вот вы пытаетесь про shift down 4, 7, 5, дальше
shift down 2, 3, дальше единичку shift down.
Вот алгоритм.
For.
Окей.
Ой.
Sorry, да.
Это уже n больше либо ровно нуля, минус, минус и.
Такой это алгоритм будет, да.
Вы с конца просеиваете, чтобы корень в конце у вас
опустился.
Вот.
Упражнение вам надо подумать, почему этот алгоритм корректен.
Ну у вас будет на семинаре задача, там будут вариации
разные, типа от нуля до nt, shift up делать или shift down,
и вот у вас будет парочка вариаций.
Вы поймете, что они неверные.
Там контрпримеры придумываются, а здесь все будет верным.
Вот.
Ну да, да.
N минус 1.
Давайте оценим время работы этой штуки.
Хочется сказать n лог n, потому что shift down занимает
лог n времени каждый.
Ну давайте теперь применим немножко смекалочки.
Вот у вас первое.
Давайте я буду для справедливости полагать, что у меня тут
полное дерево.
Ну просто, чтобы было проще жить.
Тогда первое.
Тогда первое.
Как здесь будет?
Ну почти n пополам элементов.
Ну без одного.
Точнее, ну да.
Сколько действий будет совершено с этими чуваками,
когда мы shift down от них вызовем, от самых нижних?
Ноль действий.
Когда мы будем работать с этими?
Одно действие, один обмен может быть максимум.
То есть давайте оценим, что у нас
на высоте h от корня
два степени h элементов, да,
и действие с ними.
Сколько с ними действий?
n минус h.
Точнее, n минус h.
Высота всей кучи, короче.
Давайте оценим h большая, это высота кучи.
h минус h.
Это высота кучи.
То есть у нас получается что такое?
Мы получаем какую-то сумму,
да, страшную.
Сумма по h от
чего до чего?
От нуля
до лог 2h на n.
2 в степени h
на h
минус h маленькое.
Вот.
Надо оценить этот ряд.
Сейчас, мне кажется, он не очень оценивается.
Ну ладно.
До лог 2n.
2 в степени h маленькое на h большое.
Минус сумма по h равной нулю до лог 2n.
2 в степени h на h маленькое.
Давайте вынесем здесь за скобку h
и посчитаем это как сумма геометрической прогрессии.
Что это будет?
Что будет тогда?
2 в степени лог 2h на n.
Минус 1 делить на 2 минус 1.
Что-то такое в формуле.
Вроде так там геометрическая прогрессия будет хлопываться.
Минус сумма
до лог 2n
h на 2 в степени h.
Ну.
Что это h в скобочках n-1.
Что-то такое здесь.
Минус вот эту вот сумму.
Единственная проблема то, что мы не умеем считать такие ряды.
Так нет, если вы говорите, что у вас будет n лог n,
вам нужно точное значение.
Так нет, если вы ограничите у вас debut n лог n,
вам нужно точное значение суммы.
В этом проблема.
Вы не умеете интеграл награничивать сверху.
То есть вы скажете, что это больше либо равно, чем что-то.
Вам нужно, наоборот, оценка сверху.
Кого? Эту штуку?
У интегралов сверху ограничить эту штуку.
У вас минус ограничение сверху.
То есть вы ограничиваете снизу тогда.
А мы хотим...
Вы умеете дифференцировать ряды.
Я не знаю, что вы это умеете делать.
Ну это понятно.
Ну можно продиференцировать и проинтегрировать, да.
Хорошо.
Давайте посчитаем, что...
Что это такое будет?
Не, ладно, мне лень брать производные.
Сейчас, я подумал, как по-другому это просто оценить.
Сейчас.
Короче, я знаю способ, как оценить.
Это без дифференцирования рядов.
Сейчас я попробую вспомнить.
Нет, конечно.
Так у вас аж там меняется постоянно.
Ну и чтобы ограничить, у вас будет сумма лог квадрат.
Вам нужно выжить что-то порядка n лог n.
Чтобы у вас осталось что-то порядка o от n.
Ладно, сейчас давайте я подумаю быстренько.
Где?
Здесь?
Аж, аж. Здесь ведь аж маленькие стоят.
Так.
Сейчас.
Давайте пробуем по-другому, наверное, пойти.
Ну, понятно, способ этот рабочий, но я не помню, как эту сумму считать.
Точнее, могу посчитать, но, допустим, чтобы ее не умеем считать.
Сейчас.
Ну, давайте скажем так, что у нас есть куда интереснее вещи.
А оставим без доказательств, что это o от n.
Вот.
Так будет проще всего поступить.
Что эта сумма o от n.
Вставляет
теорема
BD
сумма выше
составляет
o от n по времени.
Вот.
Та-та-та-та-та-та.
Сейчас мы лучше поговорим про другое с вами.
Мы лучше с вами поговорим про
оптимальный мерч,
так сказать.
Почему у нас там была аж, минус аж операция?
Потому что у вас,
если у вас элемент на высоте 3,
ну, в высоте 1, да, а у вас высота кучи 2,
то у вас всего 1 обмен будет.
Ну, хорошо, а у меня высота кучи была аж маленькая.
Нет, аж большая.
Ну, аж большая.
Да.
Аж маленькая.
Вы должны опускать элемент.
Опустить вниз.
Вы не можете опустить больше, чем наш большой,
минус аж маленькая.
Функция hipify?
Hipify функция, да.
Что делает функция hipify?
Она берет произвольный массив и делает из него кучу.
То есть, чтобы у вас были верны соотношения
по индексам родителей ребенка.
Вот. В чем ее суть.
То есть, надо как бы вам на месте
строить кучу из массива.
Да.
Да.
Ну, вы извлекайте минимум.
Этот шаг можно на hipify заменить будет потом.
Ну, уже сейчас можно сделать, вот.
Я хочу поговорить про нечто более концептуальное.
А именно, поговорить про такую штуку, как merge.
Все-таки вернуться к нему.
Merge как много в этом слово.
Мы с вами построили алгоритм за от n плюс m.
Ну, если n и m это размеры массивов.
Соответственно, да.
Хорошо.
Давайте я буду считать, что n много меньше, чем m.
Пусть n много меньше, чем m.
За это вас следует, что
классический алгоритм
за от m, понятное дело, тогда работает.
Но возникает вопрос.
А почему за от m?
Если нам достаточно лишь понять,
а в какие места нужно вставить элементы.
Вот эти вот очень мало n штук.
Можно же тогда за n плюс m сделать.
Просто определить позицию, куда вставить.
Согласны?
Ну, я хочу сказать, что
согласны.
То есть вот ваш массив большой.
И вот ваш маленький массивчик.
Тогда вы понимаете, что этот надо сюда вставить.
Этот сюда.
И этот вот сюда.
Вот.
Алгоритм с Бинпольском.
Сколько работает алгоритм с Бинпольском?
Ну, здесь понятно.
От n лог m.
Так вопрос, что оптимальнее?
Потому что если у вас n равно m,
тогда эта штука превращается в n лог m,
а здесь все от n.
Вот как оптимально действовать?
Ну, если у вас n равно m,
тогда эта штука превращается в n лог m,
а здесь все от n.
Вот как оптимально действовать?
Может, вы скажете что-нибудь типа такого?
Ну, давайте считать, что...
Окей.
Считаем, что это односвязанные списки.
Вы же умеете ходить вперед по ним?
Все, вот так вот давайте сделаем.
Тогда вы умеете вставлять за его единицу.
То есть это нечто техническое,
что не очень для мерджа нам важно здесь.
Что?
Ну, окей, хорошо.
Сейчас.
Мы представим, что мы живем в теории,
мы просто хотим для каждого элемента определить,
куда его вставить там потом.
Понятное дело, что потом вы будете выписывать все это в один большой массив,
и это все будет суммарно выписываться за линию от длины.
Вот.
Давайте покажем, что я просто хочу для каждого элемента определить позицию, куда он встанет.
Вот такая вот задача.
То есть не до конца надо делать слияние,
а именно понять для каждого элемента, куда ему надо встать.
То есть после кого элемента он будет идти?
Что?
Первое лучше.
Ну, я говорю, опять же, если у вас n много меньше, чем m,
то у вас классический алгоритм за такую штуку.
А этот за такую будет работать.
То есть вопрос, существует ли нечто универсальное, работающее во всех случаях?
Ну, вот у нас есть log m.
Ну, тогда если у вас n равно m, то это n log n, а это o от n.
Ну, то есть o от minimum, да, по-вашему?
Хорошо.
А если я вам скажу вот такую вот классную штуку?
Ой, ну у нас n много меньше, чем m.
Давайте наоборот.
Здесь n, здесь m, и здесь n.
Давайте посмотрим экстремальный случай, когда n очень маленькая.
То есть если у нас n много меньше, чем m,
то что тогда это будет?
Ну, почему это будет?
Нет, у нас n хотя бы единица.
То есть log m, по сути, здесь будет, да?
То есть это будет n log m около того.
То есть вот он первый случай.
Второй случай m сравнимо с n.
Ну, тогда он получим o от n.
Ну, все, победа.
То есть мы получили алгоритм, который в двух крайних случаях,
когда мы получим o от n, мы получим o от m.
Ну, все, победа.
То есть мы получили алгоритм, который в двух крайних случаях,
когда равенство и когда огромное неравенство вырождается в обе эти асимптотики.
Ну, как получили?
Я вам формулу лишь написал.
Давайте докажем, что быстрее нельзя.
Я вам обещал лекцию по дискретной математике сегодня.
Вот она и наступила.
Как мы с вами доказывали до сортировок, что быстрее нельзя?
Давайте здесь построим решающее дерево.
Давайте построим решающее дерево.
Вообще теорема звучит так.
Пусть n меньше либо равно, чем 2m.
Наоборот, только все поставим.
m больше, чем 2m.
Тогда оптимальное время мержа.
Время мержа.
Какое оно будет у нас?
Это будет ω от...
И сейчас я скажу, от чего именно будет.
n log m делить на n.
Вроде бы так.
Но это доказывать.
Это размеры двух массивов.
У нас же массив можно неравную размеров сливать.
В общем случае-то.
Делается следующее.
Построим решающее дерево.
Делаем решающее дерево с вопросом аиты меньше, чем божиты.
Это те вопросы, которые мы задавали с вами, когда здесь был код мержа написан.
Мы с вами делали while и спрашивали, если аиты меньше божитого, то пиши аиты, иначе пиши божиты.
Давайте подумаем, сколько у нас всего вариантов есть.
Сколько должно быть листьев?
То есть у вас будут два любых массива, сколько у вас возможных вариантов их смёржить?
Что-то сложно. Можно как-то комбинаторное обоснование?
Но обоснование здесь следующее.
У вас всего m плюс m позиций в итоговом массиве будет.
Вам нужно зафиксировать позиции для m элементов из них.
Тогда остальные m очевидно сразу восстанавливаются, потому что у вас массивы ассортированные.
Всего листьев должно быть.
С из n плюс m по n.
С из n плюс m по n, да.
Окей.
Что тогда можно дальше заявлять?
У вас результатирующим массивом ассортированного объекта, который у вас есть,
окей.
Ну что тогда можно дальше заявлять?
Ну смотрите, у вас в результатирующем массиве сколько места?
Если вы расставите n элементов из одного массива, правда ли, что вы однозначно зададите места для второго массива?
Всё.
Ну теперь вспоминаем, мы говорили с вами, что глубина дерева, порядка логарифма, да?
Ну, осталось оценить вот эту вот штучку.
Поверите, что это вот такая вот омега, tn лог m делить, наверное, или доказать?
Ну, вспоминаем тогда, что такое формула цешечки.
Ну, вспоминаем тогда, что такое формула цешечки.
Логарифм по основанию 2, от чего здесь будет?
Сейчас.
Чего-нибудь n плюс m факториал, 9 на k факториал, m факториал, m факториал.
Лог 2 от c из цешки.
Из вот этой вот.
Окей.
Ну что тогда можно дальше сказать?
А формула стирлинга,
которая нам здесь понадобится,
она стоит в следующем, что
сейчас,
n факториал очень близок вот такой вот штуке.
Да.
В плане?
В плане.
Нет-нет, у вас же два массива отсортированных.
Если зафиксировали места, вы, очевидно, восстанавливаете оба массива.
Это не стремиться, это эквивалентин.
Корень из 2 пен,
умножить на n делить на e, и все это встепенируем.
Это формула стирлинга. Не спрашивайте, какой он выводил.
Вот, возможно, он на мотонею выведут.
Ну давайте выпишем вот этот вот, вот этот вот кошмар сюда.
E.
Число Эйлера.
Которая 2, 7, 1, 8, 2, 8, бла-бла-бла.
Проблема в том, что там на логарифм n факториал точная оценка.
На n факториал нам нужна будет более точная оценка, чем у стайлема получить.
Скажем так, там нам тетлы то и не хватит.
Нам здесь нужно что-то более точное.
Ну давайте выписывать.
Логарифм по основанию 2 от
Оринис 2 пи n плюс m,
умножить на n плюс m делить на e,
в степени n плюс m.
Делить на корень из 2 пи n
на n делить на e в степени n.
На корень из 2 пи m
на m делить на e в степени m.
Красота же, да?
Давайте сгруппируем слагаемые.
Ну множители здесь точнее будут.
Что это такое?
Это
корень из
n плюс m делить на 2 пи nm.
Это я корни объединил отдельно все.
Плюс
логарифм по основанию 2 от
n плюс m
в степени n плюс m умножить на 1 делить на e
в степени n плюс m
делить на n в степени n
на m в степени m
на e в степени
деленное на e в степени n плюс m.
Ну я просто взял
скобки будто бы раскрыл, типа a делить на b в степени c,
а в степени c делить на b в степени c.
У меня здесь 2 пи есть.
Ну
понятное дело, что эта штука стремится к нулю
с ростом n и m.
Это мне очень интересно вообще, что это такое.
Вот.
Ну давайте скажем, что она там чем-то ограничена.
Мы знаем, что у нас
2m меньше либо равно, чем m.
Тогда
знаменатель меньше либо равен, чем
больше либо равен, чем 3n
числитель, а здесь знаменатель там
что-нибудь типа 4m квадрат будет.
Здесь.
Ну короче, все сократится, все прекрасно.
Поехали дальше расписывать эту фигню.
Давайте я обозначу это выражение за p
от nm.
Потом мы с ним разберемся.
Плюс
логариф по основанию 2 от
e сокращаются.
И здесь я возьму и распишу вот так вот.
Вот.
n плюс m
в степени n
умножить на n плюс m
в степени m
делить на n в степени n
на m в степени m.
Тогда что это такое?
Давайте перейдем на эту доску.
Окей.
Равно
p от nm
плюс
логариф по основанию 2 от
n плюс m деленное на n в степени n
плюс логариф по основанию 2 от
n плюс m деленное на n в степени n
плюс логариф по основанию 2 от
n плюс m деленное на m в степени m.
Уже красиво выражается.
Равно p от nm
плюс
n логариф по основанию 2 от
1 плюс m делить на n
плюс логариф
плюс... не так.
Сейчас степень вынесем.
Логариф по основанию 2 от
1 плюс
n деленное на m.
Давайте распишем.
Что это такое все будет?
p от nm.
Это у нас
одна-вторая
логарифа по основанию 2 от
давайте напишем в скобках
1 делить на 2p умножить на
1 деленное на n плюс
1 деленное на m.
Очевидно, что это к нулю стремится.
Что n увеличивать, что n увеличивать, оно стремится к нулю.
Поэтому p от nm нам здесь вообще никак не влияет
на асимптотику.
Дальше смотрим.
2n меньше либо равно, чем m.
Но откуда вас следует, что
n делить на m
меньше либо равно, чем 1-вторая?
Логично?
Логично.
То есть это какая-то константа,
которая может быть
ограничена константой.
Поэтому запишем это вот так вот на самом деле.
Ну не равно, а теперь эквивалентно запишем.
Эквивалентно чему?
n лог
двоичное от 1 плюс m деленное на n
плюс m на логариф по основанию 2 от
1 деленное на m
плюс m
на логариф по основанию 2 от
1 плюс 1-вторая.
Ну вот сейчас все, почти.
На самом-то деле.
Ну то есть вот мы получили сам вот эту вот штуку.
Это вот это вот.
Вот.
А вот эта вот штука, она нужна,
чтобы этот длинный массив m все-таки, видимо, как-то прочитать.
Потому что он все-таки будет у вас.
Вот.
Ну окей.
Может мне от нее избавиться?
Что?
Ну вот нет.
Что это равно?
Мы заявили, что оно к нулю стремится.
Поэтому оно вообще не влияет на асимптотику.
Но мы вывели.
Нам дано, что 2n меньше леворочим m.
Из этого следует это соотношение.
Мы его подставляем вот сюда вот.
Это от n логарифма.
От m деленное на n.
Ну понятно, что вы сюда 1 прибавите вообще особо не влияет.
Вот.
Давайте скажем так, что это эквивалентно
к m стремящимся к бесконечности.
То есть мы считаем, что у нас один басив.
Нет, это плохо.
Ладно, не будем никого стремить к бесконечности.
Просто так оставим.
Вот эта вот штука.
Ну плюс m.
Вот.
Ну m, да, там действительно будет по времени.
Поэтому как-то вот так вот.
Да.
Кто к нулю стремится?
m делить на n вот это вот?
Нет, нет, на выше.
Это?
Ну.
Окей, хорошо.
Но здесь немножко не так сказано, что к нулю стремится.
Если лучше сказать так, что это просто какая-то константа,
которая очень мала по сравнению с линейным ростом этих штук.
Поэтому мне можно благополучно опустить ее в наших числениях.
Так будет корректнее сказать, вы правы.
Что она не стремится к нулю, конечно же.
А что она просто крайне мала.
2p от этой штуки.
Да, что она просто крайне мала.
Мала.
Ну то есть у нее порядок роста никакой, она вообще не растет.
Она убывает.
А у этих штук линейный порядок роста.
Ну чуть более, чем линейный.
Поэтому константу можно опустить.
Ну ее можно типа сверху ограничить чем-то и сказать, что она не важна.
Вот так вот.
Ну все, вот такое вот доказательство, что нельзя.
Да, да.
Почему это лучше, чем M plus M?
Не, подождите, вот M plus M.
Вот здесь вот 3 вот этих маленьких.
У вас там вот эта вот M берется за то, чтобы надо краски от массива прочитать.
Она всегда будет. Если массива не надо было читать, то она бы там ее не было, грубо говоря.
Вот.
А, ну все, вот и время подошло к концу.
И теорию мы сами доказали.
