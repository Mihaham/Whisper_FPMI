Всем доброго дня, вы потихонечку, ребят, подходят. Сегодня мы продолжаем с вами говорить про контекст свободной грамматики.
Точнее, мы с вами должны изначально закрыть тех долг, которые у нас остался с прошлого раза.
Мы доказывали, почему кс-грамматики эквалентна mp-автомата.
Напоминаю, mp-автомат, вкратце, это нетерминированный, конечно, автомат, которому еще с боку припеку приделан стэк.
И этот стэк нам позволяет делать всякие интересные возможности.
Если у вас уже были семинары по mp-автоматам, то вы видели, что при помощи mp-автомата можно эмулировать неотрицательные целые числа.
При помощи mp-автомата и двух стэковых символов вообще можно моделировать целых чисел.
То есть у нас появляется какая-то достаточно простая арифметика, которую мы с вами можем отслеживать.
И мы потихонечку с вами начали доказывать, что mp-автомата эквалентна кс-грамматика.
Каким образом мы это сделали? Мы сначала идем из кс-грамматики, из mp-автомата строим кс-грамматику.
Каким образом? Мы с вами заметили, что если у нас на стэке кладется какая-то буква в переходе,
да, мы говорим, что у нас правила такие, что у нас на стэке либо кладется буква, либо вынимается буква.
Мы специально привели кс-грамматику в виду.
И мы заметили, что на самом деле, как только мы положили в стэк какую-то букву, то мы можем выложить ее в какой-то момент времени.
Это важно. Ну и вообще, если посмотреть на всю длину пути, то есть на максимальное количество того, что происходит в действии,
посмотреть на все операции добавления и удаления стэка, то это будет правильная скобочная последовательность.
Это такое интересное замечание, которое, возможно, нам где-то еще понадобится.
И мы с вами строили переходы такие. Напоминаю, как мы строили с вами грамматику.
Значит, мы сказали, что давайте мы состояние, точнее не терминал, но у грамматики, это будут пары состояний,
и в котором мы говорим следующее, что если у нас мы находимся в паре одно состояние, то же самое состояние,
то мы можем выводить epsilon, и из стартового состояния мы выводим a из q0 куджита,
где куджита и принт gtf. Напоминаю, что эти пары состояний такие, что мы можем выводить что-то на пути между этими двумя вершинами,
при этом не меняя стэк. Это важно. То есть стэк какой был, такой и остается после.
И сказали, что если у нас с вами есть такая картинка, что мы сначала написали какую-то букву a, потом мы сняли эту же букву a,
здесь мы находились в состоянии куетом, вышли здесь кутетом, здесь куэртом куэстом, а здесь у нас кутетой и куджитой.
Ищем первый момент, когда мы пробили, вернули стэк на тот же уровень.
Тогда между куэртом и куэстом мы стэк не меняем, и между кутетом и куджитом мы тоже стэк не меняем.
Поэтому мы можем написать правила. Из a и g, от e до g, в котором мы стэк не меняли, мы кладем букву a, которая была в правиле.
Но заметьте, что тут могла быть не только буква a, здесь могло быть пустое слово.
Дальше мы, не меняя стэк, идем от этой, от вершины r до s, это a-r-s, потом мы снимаем букву, которая была, или опять же пустое слово.
И потом у нас кладется туджитая, которая не меняет нам стэк.
Такие вот свойства у нас были, и мы с вами в прошлый раз формулировали лему.
Сказали, что вот этого свойства неизменность стэка.
То есть, если у нас из a и g выводится слово в грамматике g, тогда и только тогда, когда, по сути, от куитова до куджитова мы можем прочитать слово, не изменяя стэк.
Мы с вами доказали лему в одну сторону, и показали, как из лемы будет следовать утверждение теоремы.
Мы в прошлый раз это в конце сделали.
Итак, давайте теперь, это напоминание предыдущей серии.
В текущей серии мы начнем с того, чтобы покажем действительно, что то, что мы с вами тут написали, это право.
То есть, со стороны, из права влево.
И опять же, нам придется использовать такое слово как индукция.
Давайте поймем индукцию, по какому параметру у нас тут будет идти.
Почему у нас индукция будет с вами идти сейчас?
Количество правил?
Да, по количеству переходов.
Каких еще раз переходов?
По переходу в автомате.
У нас есть Qt, W, ε.
И мы перешли в...
Давайте тут напишу количество шагов k.
За k шагов в грамматике m мы перешли в состояние Qt, ε, ε.
То есть, за k шагов мы переходим отсюда.
И нам нужно будет показать, что если мы за k шагов это умеем делать,
то мы можем его из a и g, мы можем выводить W.
База индукции. Давайте поговорим по базу индукции.
Чему у нас с вами k будет равно в базовом случае?
Мы же уже по грамматике научились строить автомат.
Нет, нет, мы еще не научились. Мы еще будем учиться строить.
За сколько шагов мы можем с вами от одного состояния перейти?
От одной конфигурации перейти к другой конфигурации?
Можете еще раз повторить, что мы доказываем?
Мы доказываем следующий факт.
Вот он.
Мы доказываем, что если мы из Qt доходим до Qgt,
не меняя при этом стэк и прочитывая слово W,
то из правила грамматики a и g мы можем вывести слово W.
Мы сейчас доказываем к нему справедливость,
и мы можем вывести слово W.
То есть с правил грамматики a и g мы можем вывести слово W.
Мы сейчас доказываем к нему справо налево индукции
по количеству шагов вот здесь.
Ну давайте посмотрим.
За один переход сначала базы?
Можно сказать за один.
можно еще сказать проще, за ноль. Да, это значит, что мы просто в той же самой конфигурации остались.
Давайте напишу, куда же.
Ну, мы можем, у нас что пар позволяет? Оно наименьше рефлексивное трагитивное отношение,
то есть рефлексивное, значит, оно само из себя тоже выводит.
Поэтому тогда мы понимаем, что если мы из куитового по дубль В по Эпсилон за ноль шагов вывели QGT Эпсилон на Эпсилон,
то, во-первых, у нас В равно Эпсилон, а во-вторых, QIT равно QGT.
А что нам надо показать? Нам надо показать, что из А и QGT мы выводим W, и в нашем случае
получается, что это из А и И выводится Эпсилон. А можем мы сейчас из А и И вывести Эпсилон из нашей грамматики?
Тут надо на слайде посмотреть. Ну да, потому что у нас есть правило.
Вот, то есть базу мы доказали, с вами индукты. Теперь переход.
Предположим, что мы с вами из куитового по дубль В Эпсилон за ка шагов переходим в QGT Эпсилон на Эпсилон.
Тогда нам надо посмотреть, каким образом мы это могли сделать.
Поскольку стэк пустой, давайте посмотрим, что у нас происходит за один переход.
Тогда мы из куитового в Эпсилон за один шаг переходим в состояние какой-то QRT.
Здесь у нас что с вами получается? Давайте мы обозначим это слово У, а здесь, смотрите, у нас будет А.
Почему здесь точно будет А?
Мы обязательно что-то делаем на карточке.
Давайте, существует А, так как мы либо кладем на стэк, либо снимаем со стэка.
А второй вариант невозможно, потому что у нас стэк и так пустой.
Давайте я буду невозможным случаем обозначать буквой F.
Тогда у нас есть какое-то А.
Пусть QS, какой-то переход в QT, это первый момент, когда мы А сняли со стэка.
Мы его должны были снять.
Тогда смотрите, что у нас получается.
Давайте я вот тут буду выделять.
Мы дошли до состояния QS, при этом у нас с вами стэк не поменялся.
Потому что следующим шагом мы за один переход с вами снимаем эту Т со стэка.
Давайте мы тут обозначим слово V, а здесь мы обозначим это слово за X.
И потом за какое-то количество шагов мы с вами, и с этой штуки мы должны перейдем в QG,
Эпсилон, Эпсилон.
Нам не важно какое количество шагов, нам важно, что здесь за один шаг мы что-то делаем.
Теперь давайте пазл собирать.
А из вот этой штуки, давайте я буду ее подчеркивать.
Из вот этого перехода, что мы можем сказать?
Давайте я буду помечать это зеленым.
Что мы с вами можем из Куитова взять какой-то символ A, сняв со стэка Эпсилон, перейти в состояние QR и положить A на стэк.
Это у нас принадлежит правиле грамматики.
Причем мы с вами понимаем, что из этого соотношения следует, что W равняется A на U, потому что мы эту букву A должны были прочитать.
Раз.
Теперь смотрите на красную картину.
Теперь давайте посмотрим с вами на красный переход.
Из красного перехода мы с вами можем сказать, что у нас QR U A переходит в QS V A, не меняя стэк.
Значит, существует такое, давайте я его назову U', такое, что U равно U' V.
А что важно нам сказать, что QR U' A выводит QS A.
И что мы здесь можем применить до вот этого факта?
Индукцию, предположение индукции.
Индукцию, да.
Конечно же, тогда по предположению индукции мы получаем, что S A R S у нас выводится U'.
Так, теперь давайте еще каким другим цветом обозначим.
Давайте теперь синий возьмем.
Объясним себе вот этот переход.
Из этого перехода мы можем сказать, что у нас из QS по какой-то букве B, снимая со стэка A, мы переходим в состояние QT, получаем и на стэк кладем Epsilon.
Оно будет лежать к правилам грамматики, причем, замечу, что у нас V равно BX будет.
Сразу скажу, что B, A этому, либо буквы, либо пустые слова.
И теперь давайте объясним еще какой-нибудь, еще один переход, который у нас с вами остался, давайте его обозначу серым цветом.
Серый переход.
Здесь все-таки аналогично на самом деле, получается, что QT X Epsilon выводит QG Epsilon Epsilon, следовательно, опять же, по предположению индукции,
мы получаем, что из S A T житого у нас с вами выводится слово X, потому что это делает за меньшее количество шагов.
Теперь давайте собирать все, что у нас с вами получается.
Давайте я обведу, давайте я подчеркну, наверное, что-нибудь голубым цветом.
Смотрите теперь внимательно, что у нас с вами есть.
У нас есть вот такое правило, раз, есть такая штука, есть такая штука, есть такая штука.
Теперь давайте сравним с тем, что у нас происходит справа.
Из Q E Epsilon Q R A, из Q S B Epsilon у нас Q T Epsilon.
Да, я напомню, что тут баг в правиле был.
Из A T житого выводится X.
Ну вот, четыре этих правила.
Вот я, кажется, их писал в прошлый раз?
Писал ли я их или нет?
Вот они у нас Q E Epsilon Q R A, Q S B A Q T Epsilon.
Ну и дальше у нас получается A T житого выводит какое-то слово, и A R S выводит это же слово.
Что это нам дает? Это нам дает следующее.
У нас получается с вами, сейчас, секунду.
Давайте я буду вот так обозначать важные вкладки.
Из этого у нас получается, что у нас, так как у нас есть правила A и G T, выводится A.
Ну поскольку мы стэк опустошаем, сейчас покажу, где мы это делаем.
Вот, Q E T V Epsilon Q G Epsilon, поэтому мы A и G T.
И теперь смотрим, что у нас происходит.
У нас есть A, дальше у нас есть какое-то A R S, вот оно.
Дальше у нас с вами есть B, которое мы сняли со стэка.
А здесь у нас получается A T житое.
И это у нас есть такая правила грамматики.
То мы получаем с вами, что из A и G T мы с вами выводим A A R S B A T житое.
Причем смотрите, из A и R S мы выводим A, у штрих.
Здесь мы выводим B, а здесь мы выводим X.
Тогда, поскольку у нас B X это V, то получаем A U' V.
Дальше, давайте я буду равенство уже писать.
Здесь U' V равно U, а A U у нас W.
Предположение доказано.
То есть надо просто аккуратненько собрать все блоки воедино.
Я пытаюсь теперь это все цветами обозначать.
Как цветовая гамма помогает лучше воспринимать информацию?
Вообще благодаря этим цветам прекраснее.
Да и смотреть как бы там немножко так удобнее.
Ну да, давайте тогда я буду какие-то основные факты цветами расписывать.
Благо у нас теперь онлайн-доска.
В ней есть не только один цвет, а есть и общий набор цветов.
Понятен этот переход.
Вот эта лемма.
То есть по сути мы с вами лему в обратную сторону доказали.
Вот и из леммы мы с вами потом выводили теорему.
Мы это мы с вами в прошлый раз обсуждали.
Давайте я теперь сейчас вот так вот сделаю магию.
Давайте я после лекции эту магию сделаю.
Я сделаю пасту вот сюда, вот куда-нибудь.
В доску.
Мы сейчас доказали, что одно под множество другого.
Да, мы сейчас доказали, что любой МП-автомат распознает СКС-громатикой.
Теперь нам надо сделать обратный переход из СКС-громатики, построить МП-автомат.
Давайте я здесь место оставлю, потому что вот сюда мы будем вставлять доказательство теоремы.
Даже чуть-чуть больше.
Давайте теперь тогда мы поговорим с вами о переходах из СКС-громатики в МП-автомат.
На самом деле здесь все интуитивно проще.
Опять же тут будет леммы две, точнее одна.
Но правило намного проще.
Смотрите, идея очень простая.
Она заключается в том, что давайте вот у нас есть СКС-громатика.
По сути, что каждая правила говорит, что у нас есть какая-то левая часть,
которая раскрывается в некоторую правую часть.
Но на самом деле это не что иное, как эмуляция стека.
Вы берете, вынимаете со стека символ с левой частью правила
и добавляете то, что у вас находится в правой части правила.
Сейчас я поясню это формальнее.
Вот смотрите.
Давайте обозначим.
Опять же у нас есть МП-автомат с вами.
Точнее у нас есть СКС-громатика.
Пусть у нас G это NСПС.
И мы с вами говорим, давайте заведем два состояния.
Q0 и Q1.
Я сейчас картинку перерисую.
Значит здесь у нас с вами будет правило такое.
Мы читаем букву ε, снимаем со стека ε.
А здесь мы с вами будем делать вот такую вещь.
То есть мы добавляем стартовый символ.
По сути, это такой маркер того, что мы начали разбор громатики.
Если допустим, у нас с вами в громатике было правило САСБС.
С-эпсилон это громатика для ПСП, напомню.
У нас с вами для правильных кубочных последовательностей.
То мы сделаем очень простую вещь.
Давайте добавим правила здесь.
Во-первых, если у нас с вами мы читаем букву А.
В том случае, если у нас на стеке находится эта буква А.
Здесь важная особенность, что стековый алфавит у нас является подморством основного.
Здесь, если у нас со стека идет B, то даем вот так.
То есть если мы на стеке встречаем терминал, то мы его считываем, пишем букву.
Если не так, то увы.
И здесь мы еще добавляем интересное правило.
Для этого случая оно будет такое.
Мы берем, читаем пустое слово и по сути пользуемся раскрытием правила.
Здесь важно только история в том, что правило здесь читается в обратном порядке.
Видите, у нас здесь называется ASBS.
Поскольку у нас по сути слова читаются в порядке очереди.
То есть у нас символы читаются по порядку.
А стек работает немножко в обратном порядке.
То есть если у нас чтение слова это LFO, last in, first out.
Нет, стоп.
Очередь это FIFA.
First in, first out.
Но стек это у нас наоборот LFO, last in, first out.
За счет этого нам нужно по сути сделать перевод с порядка справа налево.
Вот такая у нас грамматика с вами будет получаться.
И теперь смотрите, что мы будем доказывать с вами.
Давайте я опять же выпишу.
Нам опять же нужно будет с вами показать LEM-у.
Которая говорит, что из a мы выводим слово w тогда и только тогда,
когда из q1 va мы можем вывести q1 епсилон-эпсилон.
Опять же LEM-а будут оказываться в обе стороны.
Прежде чем мы поговорим с этим, давайте поймем, как из LEM-а мы выведем наш теорем.
Что такое a?
А, это какой-то не терминал.
Вы грамматики.
Да, просто у нас по сути говорим, что вот у нас есть какое-то слово.
Мы можем по сути сделать следующее.
Вот у нас на стеке лежит буква a, мы можем это.
Здесь выводим как грамматики, а здесь при помощи того, что оно лежит на стеке,
мы попытаемся прочитать это слово целиком.
Но давайте теперь из LEM-а мы с вами попробуем теорему соорудить.
Значит, что такое у нас в LEM-е лежит к языку, задаваемой грамматикой?
Тогда и только тогда, когда у нас из s мы выводим какое-то слово w.
И, пользуясь LEM-ой, что мы получаем?
Мы получаем, что из q1 w,s мы можем прочитать q1, epsilon, epsilon.
Давайте я как раз подчеркну его красным цветом.
И переход тоже обозначу красным цветом.
Это значит, что он появился у нас из LEM-а.
Ну, смотрите, как мы можем добраться в q1, epsilon, epsilon.
Из q1 w,s.
Давайте соединим это двумя вещами.
Я сейчас такую перемычку мы с вами сделаем.
Итак, теперь смотрите, важно, из q0, давайте нет,
если у нас w лежит в языке, задаваемым mp-автоматом,
тогда и только тогда.
Когда у нас из q0 w, epsilon мы можем с вами прочесть...
Кстати, забыл сказать, что вот это состояние у нас будет завершающее.
q1, epsilon, epsilon.
Давайте посмотрим на первый переход.
Что у нас за один переход с вами осуществляется?
Мы берем, используем правила q0, epsilon, epsilon, q1, s.
Это значит, что за один раз у нас с вами здесь ничего не меняется,
а здесь у нас меняется вот так.
Вот такая транзитивность у нас с вами появляется.
Ну а теперь обратим внимание, что у нас с вами в нижней части,
и что у нас с вами в верхней части.
Мы на стэк положили s.
Потому что у нас никакого другого правила нет,
то есть это первое правило, которое у нас есть для того,
чтобы с q0 вообще как-то выйти.
Нам нужно из старта в стэнк дойти за завершающего.
Да, ну один переход есть, поэтому мы этот s должны положить на стэк.
Вот, ну мы видим, что вот эти два факта ровно одинаковые.
Вот, а вот этот вот переход у нас появляется так как...
Давайте тоже подпишу.
Надо дойти до конца.
Только один.
Вот, из левым мы с вами доказали теорему.
Теперь давайте...
Если вопросы по лемме, если нет вопросов по лемме,
то мы с вами сейчас будем доказывать ее.
Еще раз, почему мы доказали теорему?
Можете, пожалуйста, повторить.
Почему мы доказали теорему?
Еще раз, если у нас слово лежит в языке,
задаваем грамматика тогда и только тогда,
когда из s выводится w.
Из леммы мы получаем, что вот это вот по факту...
Давайте... Не так написал.
Сейчас давайте сотру немножечко тут.
Красное сотру.
Я понял.
Вот, тогда вот этот переход у нас обеспечивается леммой.
Да, из s выводится w, тогда и только тогда,
когда из q1v и s выводится q1εn.
С другой стороны, у нас v лежит в языке, задаваемым автоматом,
тогда и только тогда, когда из q0vεn вводится q1εn.
Но поскольку мы должны совершить один переход,
и он обязательный, то, по сути,
принадлежность языка автомату эквалиптует к тому,
что обведено в голубой рамочке.
Да, смотрим на то, что в голубой рамочке снизу,
а то, что в голубой с рамочки сверху.
Понимаем, что это одно и то же.
Поэтому у нас с вами тут тоже появляется вот такой переход.
А вот то, что на доске написано справа,
эти правила мы и добавляем, да?
Да, да, да.
То есть вот такие правила перехода у нас в автомате.
Теперь давайте докажем лему.
Опять же, давайте в обе стороны начнем.
Я не помню, тут написал, есть ли индукция или нет.
Нет индукции.
Первый факт, которым мы так будем доказывать,
что если из A вводится W,
то из этого будет вводиться,
что из Q1BA у нас выводится Q1εε.
Давайте поймем, каким образом это мы с вами сможем сделать.
На самом деле это делается индукцией по длине дерева вывода.
А у дерева вывода есть длина?
Да, у дерева вывода есть длина.
А у дерева вывода есть длина?
Да, напоминаю, что дерево вывода
это последовательность выводов из одного терминала какое-то слово.
Да, если это представлять,
давайте напишу количество ребер в дереве.
Каждое ребро – это переход по раскрытию по правилам грамматики.
Итак, давайте с базой начнем.
Тут можно K поставить, и это параметр будет K.
Итак, давайте начнем с базы.
С базы начнем.
Тут можно K поставить, и это параметр будет K.
База.
K равняется единице.
Тогда у нас из A за один шаг выводится слово W.
Ну что такое слово W? Давайте его обозначим.
Пусть W – это у нас W1, W2 и так далее Wnt.
Тогда давайте собирать этот переход.
Что у нас получается? У нас получается, что из Q1 в A мы…
Какое у нас правило получается?
У нас получается правило…
Тут очень важно. Смотрите, Q1, W…
И у нас слова разворачиваются.
Wn, Wn-1, тогда далее W1.
Так как A у нас с вами выводит W1, Wn,
и у нас в итоге есть правило, которое говорит,
что из Q1, A мы кладем на stack…
Q1 и на stack мы кладем слово W, Wnt.
Вот, это нам важно. То есть мы берем, переворачиваем слово.
И тогда мы начинаем эти буковки снимать с вами.
Снимаем по одной букве.
Сначала снимается первая буква.
Wn, W… Так, сейчас.
Wn, W-1 и так далее W2.
Потом еще раз снимаем букву.
Q1, W3. Ну понятно, что если букв у нас меньше будет, то…
W3. Ну и так повторяем.
У нас получается Q1, Wn, W…
И после этого у нас получается Q1, A.
Вас доказали?
Да.
Теперь переход.
Давайте посмотрим на первое раскрытие.
Что это значит? Смотрите, у нас A.
Давайте посмотрим, за первую шагу оно вывелось в какое-то альфа.
А потом за какое-то другое количество слов вывелось W.
Тогда давайте посмотрим, что у нас может быть.
Пусть у нас альфа, это альфа1 и так далее какое-то альфаn.
Причем важно, модуль альфаiT у нас с вами будет лежать в объединении n и σ.
То есть это либо терминал, либо нетерминал.
А мы будем использовать альфа1, альфа2.
А альфа3 у нас будет лежать в объединении n и σ.
То есть это либо терминал, либо нетерминал.
Тогда из Q1, W, A мы с вами можем вывести следующую вещь.
Так, сейчас, секунду.
Q1, W.
И дальше у нас идет последовательность этих символов в обратном порядке.
Давайте я сейчас немножечко такую страшную вещь делаю, чтобы было упрощение перебора случаев.
Понимаете ли вы, что здесь можно поставить...
Нет, давайте не будем так делать.
Давайте я на одном примере покажу.
Если у нас альфаnT принадлежит n, то тогда мы можем воспользоваться предположением индукции.
Альфаn выводит некоторая Wn.
И из этого будет следовать, что у нас с вами Q1, альфаn, точнее наоборот,
Wn, альфаn будет выводить какой-то Q1, епсилон, епсилон.
И это все будет работать по предположению индукции.
А если у нас альфаn принадлежит сигма, то тогда у нас Q1.
Давайте я тоже напишу вот так вот.
Все-таки это соотношение у нас транзитивное, поэтому мы можем сказать, что альфаv, n тоже выводит некоторую Wn.
Но при этом смотрите, у нас альфа... Нет, так?
Сейчас, давайте подумаем, можем ли мы так сказать.
Если у нас с вами правила грамматики...
В принципе, да, мы можем сказать вот так, потому что штопор – это наименьшее транзитивное соотношение, которое определяется для всех правил.
Поэтому мы так тоже можем писать, нам этого никто не мешал.
И тогда у нас получается Q1 Wn, альфа, давайте я обозначу Wn, выводит Q1, епсилон, епсилон, так как это у нас с вами правила грамматики.
Вот. Единственное, тут надо сказать, что вот у нас альфа...
Давайте вот тут я напишу, вот такой зумин сделаем, что из альфа это равно альфа1 и так далее, альфаn, каждый из которых у нас выводит W1 и так далее, Wnt, которое равно епсилон.
То есть это нам просто надо будет сказать.
Вот, теперь смотрите, продолжаем вот эту картинку.
Что равно епсилон? Можете еще раз повторить?
Ой, я молодец, конечно. Нет, W1 Wn равно W, вот этому слову.
Вот так вот.
Да, то есть у нас получается из альфа ВЦВ, но как? Каждый из них терминалов у нас...
Альфа это набор не терминалов или терминалов альфаитых, а из каждого альфаитого у нас выводятся какие-то Wитые.
Вот, поэтому W это у нас набор слов.
Ну, набор слов W1 и так далее W.
Вот, и тогда смотрите, вот то, что мы написали с вами, что у нас получается?
У нас получается с вами, что из Q1 Wn альфа n в Вольт с Q1 епсилон епсилон.
Как мы бы не рассмотрели буква, это была бы или не буква.
Тогда у нас получается, что мы можем с вами по сути...
Давайте я напишу вот так.
W1 и так далее Wn альфа n и так далее альфа 1.
Но это можно сделать для любого альфаитного, то есть для любого слагаемого.
Тут можно везде альфа n заменить и любое k.
Получаем, что из этого выводится Q1 W2 Wn.
Здесь у нас получается альфа с едаем.
Получается альфа n и так далее альфа 2.
И делая так какое-то количество раз, мы получим с вами в последний раз Q1 Wn альфа nt,
который выводит Q1 епсилон епсилон.
Да, который выводит Q1 епсилон епсилон.
Поэтому мы доказали этот факт с вами.
То есть переход.
Тут надо аккуратненько рассмотреть важный поэнт.
Надо рассмотреть два случая.
Когда у нас в стеке лежит не терминал и когда в стеке лежит терминал.
Когда в стеке лежит не терминал, мы его раскрываем по правилам грамматики и по предположениям индукции.
Когда у нас с вами терминал, буква, мы просто снимаем ее со стека и кладем, прочитываем слово.
То есть они почти друг от друга ничем не отличаются, да, с помощью трюка?
Да-да, они именно ничем не отличаются.
Вот, смотрите, идея простая, формально чуть-чуть сложно пишется.
Это был переход в одну, это было доказательство в одну сторону.
И теперь давайте доказательства в другую сторону.
Значит, смотрите, теперь мы показываем, что если у нас Q1 в A выводится Q1 епсилон епсилон, то из A выводится W.
Опять же, индукция по количеству переходов.
Ну, давайте скажем базу.
Давайте подумаем, какая тут база у нас с вами будет.
Море может быть.
Давайте я напишу вот так вот.
A принадлежит N объединить с Сигмой.
Но все равно это будет выполнено.
Тогда мы за ноль это сделать не сможем, да, потому что нам нужно A со стека освободить.
Но за один переход мы можем сделать это.
Один переход.
Тогда у нас с учетом одного перехода из этого будет следовать, что у нас A...
Так, секунду.
А принадлежит Сигма.
Тогда, поскольку мы делаем это за один переход, то у нас получается Q1 в A за один переход мы переходим в Q1 епсилон епсилон.
А, извините.
Да, угу.
Ну, как мы делаем это за один переход, то у нас получается Q1 в A за один переход мы переходим в Q1 епсилон епсилон.
Ну, извините.
Да, угу. А, все окей, да?
Вот, тогда у нас получается мы из Q1 в A переходим в епсилон епсилон.
Ну, это делается за одно правило.
За одно правило мы можем это сделать только по правилу Q1 A A равняется Q1...
Из Q1 A A мы выводим Q1 епсилон.
Следовательно, W равно A.
И из A мы можем вывести W, так как штопор это у нас рефлексивное отношение.
Ну вот, это база.
Теперь переход.
Пусть у нас с вами из Q1 W A за K переходов Q1 епсилон епсилон.
Вот с Q1 епсилон епсилон.
Причем K больше единицы.
Тогда можно показать, что A будет принадлежать не терминалам.
Почему? Потому что если бы A был бы терминалом, то мы бы его сняли первым правилом со стека, а дальше бы мы никуда не продвинулись.
Вот, я подчеркну.
Значит, за один раз у нас если A, у нас есть правило α1 и т.д., αn, где у нас αk... так, k было у нас.
αmt принадлежит объединению n с сигмой, то мы с вами можем сделать вот такую вот интересную вещь.
Расписать, собственно, у1 W A за один шаг у нас с вами получается следующая вещь.
у1 W и стек в обратном порядке, αn и т.д., α1.
Да, мы перевернули стек.
Вот, по второму правилу.
А теперь нам нужно с вами аккуратненько вот эту вот штучку разобрать.
То есть у нас здесь получается, что мы из этой штуки выводим у1 епсилон епсилон.
Важно.
За один шаг мы снимаем что-то со стека.
Один элемент со стека.
Из этого на самом деле мы можем сказать, что α1 будет выводить некоторое в W1.
α2 будет выводить какое-то W2 и т.д.
αn будет выводить Wn.
Ой, нет, стоп.
Сейчас, мы снимаем ровно один элемент со стека. Всегда.
Почему снимаем? Второе правило, оно же кладет на стек.
Не-не-не, ну всегда мы должны заплатить на вход.
Да, смотрите, тут я немножко неаккуратно написал, давайте я сотру.
Что у нас получается? У нас есть α1, а2 и т.д. аn.
Какие у нас возможности могут быть?
То есть, либо это терминалы, либо это не терминалы.
Ну, с терминалами вроде бы все понятно.
Тут важно сказать, вот тут есть одна важная особенность.
То, что давайте
пусть это у нас вводится в какое-то β1,
вот это вводится в какое-то β2,
а вот это вводится в какое-то βn.
Если причем у нас αi и σ, элементы алфавита,
то мы, в принципе, можем снимать ровно один элемент,
в принципе, можем сказать, что это один и тот же символ.
Давайте я просто покажу, вот по аналогии, чтобы вы поняли.
Пусть у нас α1 и β1, причем у нас α1 у нас принадлежит n.
Тогда как у нас будет стек с вами меняться?
У нас было q1, w, αn и так далее, α1.
За один шаг у нас что проходит?
У нас получается q1, w, тут αn и так далее, α2,
а здесь у нас стоит β1 перевернутое.
И тут давайте я напишу важный момент.
Дождемся, пока на стеке останется αn и так далее, α2.
То есть будем ждать специально такого момента,
когда у нас останется только αn, а2.
Почему такой момент произойдет?
Потому что в конце мы слово выведем.
Да, так как в конце стек пустой.
Стек пустой.
И мы снимаем ровно один символ всегда.
Вот, и тогда мы при обработке этого α1
мы должны прочитать какое-то слово w1.
Да, в этом моменте у нас будет получаться, смотрите, q1,
здесь какой-то w', а здесь у нас будет αn и так далее, α2.
Давайте я вот тут тоже сделаю вот такой вот небольшой флешбэк.
Аккуратненько сделаем.
Вот этот вот красный штопор, он приведет вот такому красному штопору.
Да, вот я показываю, очень важно.
Тогда из этого мы можем сказать, что существует такое u,
что v равно uv', и важно, что из этого важно,
что из q1 uα1, давайте я его специально обозначу это u,
пусть у нас будет v1.
Из q1 v1 α1 у нас будет выводиться q1 εε.
Из этого будет следовать, что α1 выводится w1.
Да, тут очень тонкий момент, что нам нужно разгрести вот этот вот стак.
Почему из q1 α1 выводится εε?
Давайте посмотрим внимательно.
Получается, что из q1 v αn α1 получается q1 v' αn α2.
Что это получается? У нас α1 со стека улетел? Улетел.
При этом мы взяли за этот момент какое-то слово w1.
То есть у нас получается, что w это w1 w', мы w1 прочитали, остается w'.
Давайте я напишу по аналогии.
αnt выводит wnt.
Любого n равное 1 и так далее n.
То есть тут аккуратненько надо воспользоваться предположениями индукций.
То есть вот это вот у нас предположение индукции, если что сработало.
Ну и тогда смотрите, что у нас получается.
Итого.
У нас, смотрите, a выводил α1 и так далее αn.
При этом αкт выводит w... так.
Вот так вот.
αmt выводит wmt.
А v1 и так далее vmt, которое мы съедаем, оно будет равнять слово w,
потому что в конце концов мы должны были стэк опустошить.
И из этого у нас выходит, что из а мы можем вывести слово w1 и так далее wm.
А это равняет слово w.
Давайте я еще раз прочитаю.
Давайте я еще раз просуммирую, чтобы было понятно, что произошло.
Мы на самом деле доказали с вами теорему.
Теперь вкратце по шагам.
Давайте, чтобы у нас с вами осталась фиксация, как это доказывается.
Значит, мы построили ПКС грамматики mp-автомат.
Каким образом?
Мы сказали, что если у нас встречается какой-то не терминал,
то мы берем левую часть этого правила, закидываем на стэк в обратном порядке те элементы, которые находились в правой части правила.
Ну и делаем аккуратненько.
Значит, в одну сторону, как мы это доказываем.
Мы посмотрим.
Мы смотрим с вами, раскрываем α как последность не терминалов.
Да, и понимаем.
Т.е. мы говорили следующее, что если из α у нас выводится табуль V, то почему-то у нас такое правило грамматики есть.
school.
Так, сейчас.
Вот тогда мы из α вывели какое-то правило.
То есть у нас из α рассматриваем первые правила, которые выводят не терминал.
И показываем, что, по сути, мы можем этот не терминал составлять, а потом выводить первый прав不会 быть у нас не терминалов.
Это же вопрос.
По сути, мы можем это не терминал со стека снять, а при этом забрав какой-то кусочек.
Вот, и в этом мы делаем предположение индукции.
А здесь мы делаем немножко другую интересную вещь, в обратную сторону.
Мы говорим, окей, пусть у нас находится не терминал, давайте мы его положим на стэк то, что у нас происходит,
и дождемся первого раза момента, когда у нас все вот этот символ,
и с учетом того, что он еще породил, выкинется из стека.
Такой момент у нас наступит, потому что стэк мы послушаем по одному элементу,
и в конце у нас получается стэк пустой.
Вот, дожидаемся ровно вот этого момента, вот, видите, он красным цветом тут подчеркнут,
и пользуемся предположением индукции.
Вот, как говорится, идея простая, доказательства формальные.
Формальные и неприятные.
Давайте поймем, в первом приближении понятно, какая техника тут используется?
Понятно.
Да, тут тонко главная идея простая.
Хорошо, в итоге мы с вами вроде более-менее доказали,
что все каэсгроматики порождаются некоторыми mp-автоматами, и наоборот.
То есть теперь от класса этих языков у нас совпадают.
Чем мы, собственно, с вами будем пользоваться?
А теперь давайте перейдем к следующей теме.
Я думаю, сегодня дам, так сказать, вводную,
а в следующий раз мы с вами уже посмотрим более детально по применению.
Точнее, начнем доказывать эту историю.
Значит, сегодня наша цель построить еще один более общий парсер, который у нас был.
Так, давайте сейчас сделаю.
Fit into page, вот так.
Вот, значит, идея.
Идея.
Давайте мы с вами будем сейчас строить парсер,
который позволяет каким-то эффективным образом,
не то что эффективным, а хоть каким-то способом определить принадлежность слова грамматики.
Давайте вспоминать, какой алгоритм у нас уже с вами был до этого,
который позволяет проверить принадлежность слова грамматики.
Из семи шагов вроде.
Это мы использовали грамматику,
которая нужна была для того, чтобы прийти к такого вида грамматики.
Значит, у нас был алгоритм кока-янгера-косами до этого.
А он требовал грамматику в нормальной форме хомского.
Ну а грамматику в нормальной форме хомского сама приводится
за какое-то дикое количество операций порядка куба,
что не есть эффективно.
Поэтому нам нужно с вами придумать каким-то образом
какой-то алгоритм, который позволит работать с грамматикой в любом виде.
Вот, и давайте в качестве примера рассмотрим как раз нашу грамматику.
Давайте в качестве примера рассмотрим как раз нашу грамматику.
И давайте рассмотрим слово.
w равно a, b.
Давайте сначала слово a, b, a, b.
Как оно у нас раскидывается в виде дерева разбора?
Оно у нас раскидывается в виде дерева вывода каким-то таким образом.
То есть мы из s выводим a, s, b, s.
Потом из этого s у нас выводится епсилон.
А здесь у нас из s будет выводиться a, s, b, s и вводится епсилон.
Вот такой у нас дерево разбора получается для этого слова.
И давайте возьмем какое-нибудь слово, которое не принадлежит этой грамматике.
Слово a, b, a.
Идея такая, алгоритма, которая мы с вами будем делать.
Мы с вами попытаемся делать разбор для всех возможных префиксов.
Да, то есть пытаемся по префиксу найти в обходе дерева b, f.
Ну, давайте начнем.
Вот смотрите, мы типа говорим из s, ok.
Что мы можем сделать?
Ну, у нас есть только правило a, s, b, s.
Первую букву прочитали? Отлично.
Потом что мы можем сделать?
Какие варианты у нас есть возможные разобрать?
Давайте я буду их рисовать.
Первый вариант у нас, который будет, это у нас, возможно, a, s, b, s вот сюда прикрепляется.
Но почему этот вариант нам с вами не подходит?
Две буквы a в начале?
Да, две буквы a в начале.
То есть в итоге, когда, вот смотрите, представьте себе, что у нас есть слово a, b, a.
Мы начинаем идти в порядке с левой направо, в ходе дерева разбора.
И в итоге в какой-то момент времени мы натыкаемся на проблему,
что у нас вторая буква b, а мы должны прочитать букву a.
Тут такая история.
История.
Давайте вот попытаемся подвесить все деревья, то есть пытаемся подвесить все что угодно.
А если у нас что-то не проходит, мы будем сдирать это шпателем.
Ну да, представьте, в общаге клеите обои.
Хреновастико обои наклеили, фигак, шпателем обрубили.
Поехали дальше.
То есть у нас шпатель, вот этот шпатель, когда он, по сути, поймет, что ему нужно прочитать букву b,
у нас этот шпатель обрежет вот это вот дерево.
Вот. Он поймет, что здесь можно поставить правила, из s выводится епсилум.
Хорошо, то есть у нас теперь один кандидат отлетел.
То есть у нас теперь кандидат s, a, s, b, s.
Из s раскрывается епсилум, двигаемся дальше.
Двигаемся дальше.
A, B, A.
Это OK.
Это у нас тоже OK.
Дальше что?
Дальше у нас идет s.
Тут два варианта есть.
Первый вариант вот такой, вот a, s, b, s.
А второй вариант у нас такой.
A, S, B, S, S, ε, ε.
Вопрос.
В какой случае почему отлететь?
Вот у нас вот сейчас два варианта есть.
Давайте разберемся, почему правое отлетит.
Потому что закончилось слово.
Да, потому что мы на самом деле, вот смотрите как мы обходим дерево.
Мы обходим дерево в порядке DFS.
То есть вот такой порядок, потом идем вниз, поднимаемся по дереву вверх,
поднимаемся вниз, поднимаемся вверх, поднимаемся вверх.
И по сути, когда мы уже хотим прочитать букву A, вот это вот.
Мы находимся в дереве разбора здесь.
И нам вправо уже двинуться никак невозможно.
А нам нужно двинуться вправо.
То есть запоминаем, у нас есть три порядка обхода.
Это в дереве разбора.
Спуститься вниз, проскрыться по интерминалу.
Вправо и подняться наверх.
Теперь во втором случае.
Смотрите, что у нас в втором случае происходит.
У нас мы идем в A.
Тут даже гипотетически, если у нас с вами получается Epsilon.
Да, то есть мы пытаемся прикрепить нашу вершинку Epsilon.
Окей, вроде закрепили даже.
Вроде идем, идем, идем, идем, идем.
Прикрепляем Epsilon.
Вроде идем, идем, идем, идем, идем.
Прикрепляем Epsilon.
А дальше-то что?
А дальше нам надо букву B прочитать.
То есть наша цель уже подняться наверх.
Мы хотим подняться наверх, а мы должны двигаться куда-то дальше.
То есть хотим куда-то сюда.
Ну а вот тут нам мешает вот эта вот фигня.
Поэтому мы с вами, у нас ничего не получается.
То есть идея такая, о которой хочу вам сказать.
Давайте мы попытаемся по всем префиксам держать все возможные гипотетические дерево разбора, которые подходят этому префиксу.
Деревывода.
Давайте только поймем.
Вот сейчас текущая реанкарнация алгоритма, который я вам говорю.
Это сложно делается?
Какая у нас пока гипотетическая сложность?
Асимптотика.
Мы каждый раз все правила перебираем.
Ну да, каждый раз все правила перебираем.
Пока что экспоненты какая-то дикое выглядят.
Ну а давайте поймем, какие у нас три операции есть.
Мы на самом деле используем три операции.
Используем три операции.
Операция 1.
Давайте я их буду стрелочками обозначать.
Это спуск вниз.
Где у меня эта доска?
Давайте я немножко перенесу.
Операция 1. Спуск вниз.
На 1.
Вторая операция.
Это сдвиг вправо на 1.
Причем тут важно сказать, что мы сдвигаемся на 1 терминал.
Здесь мы упираемся.
Уперлись вне терминала.
Есть третья операция.
Давайте я его обозначу зелененьким цветом.
Поднимаемся вверх.
Поднимаемся вверх на единичку.
Все.
Закончилась.
Ветвь.
То есть у нас получается три таких операции.
И теперь давайте подумаем, нужно ли нам хранить все дерево целиком разбором?
Для этого надо вспомнить, как DFS реализовывается.
Вроде как не нужно. Нужно хранить только суффикс слова.
И все.
Ну да.
Я даже скажу в том, что когда вы идете в вершины в порядке DFS,
либо вы это делаете рекурсивным способом, либо вы DFS реализовывается через стэк.
Для того, чтобы у вас стэк работал, вам нужно знать только,
где мы находимся на уровне выше.
То есть из DFS как раз следует то, что нам нужно, по сути, хранить,
где мы находимся на текущем уровне и куда нам вернуться на уровень выше.
И давайте мы будем с вами это отсекать при помощи инструмента под названием точка.
Вот давайте я сейчас как раз на этом правиле, вам покажу, на этом дереве покажу.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Угу.
Смотрите, только тут единственные финтушами, которые нужно, чтобы это работало,
нам нужно добавить одно правило грамматики, чтобы все было точнее.
Смотрите, добавляем новое правило грамматики и за штрих выводят S.
Вот оно важно.
И теперь смотреть, что мы делаем.
Ставим точку сюда.
Я буду таймстэмп поставить.
Вот это точка в нулевом таймстэмпе.
Потом мы идем при помощи красной операции,
напоминаю, что мы поддерживаем все деревья разбора.
Да, мы идем сюда.
У нас вот эта точка в таймстэмпе один.
Потом мы двигаемся вправо на единичку.
Так, давайте я...
Так, это не вправо.
Вправо на единичку.
Таймстэмп двойка.
И давайте я еще дополнительно для этого сделаю проекцию всего слова.
A, B, A, B.
Вот смотрите, давайте посмотрим, где у нас точки находятся.
У себя и у родителя.
То есть вот это таймстэмп два.
Значит, в таймстэмпе один.
Родительская точка у нас...
Давайте я буду обозначать красным цветом.
Родительская точка находится здесь,
в оппозиции слова,
а наша точка находится тоже здесь.
Это позиция ноль.
Вторая история, которая...
Во втором таймстэмпе скажите,
где будет находиться родительская точка,
а где будет находиться текущая точка?
Родительская слева, текущая после буквы A.
Так, таймстэмп три.
Таймстэмп три.
Таймстэмп три, точка у нас будет находиться здесь.
Но если что, через Epsilon мы не перескакиваем.
Где у нас здесь положение будет?
Родительская относительно текущая и текущая.
После маленькой буквы A.
Да?
Четвертый момент времени.
Точка будет находиться вот здесь вот.
Опять же, называем себя родительскую.
После B, своя родительская,
а родительская между A и B.
Наша находится между A и B.
А родительская находится до A.
И смотрите, какая закономерность с вами.
На самом деле, у нас уже чуть-чуть прослеживается.
Почему родительская?
Нет, смотрите, родительская точка,
мы смотрим точку в дереве вывода у родителя,
где она находится.
Нам же нужно хранить этот инвариат.
И смотрите, что мы с вами замечаем.
Первое замечание такое, что когда мы спускаемся вниз,
у нас красная точка с зеленой синхронизируется.
Красная точка с черной, наш с родительской.
А здесь они немножечко рассинхрон идут.
Когда у нас идет сдвиг вправо,
у нас точка справа двигается.
Наша точка двигается.
А когда поднимается наверх,
тут чуть-чуть сложнее, мы это разберем.
Давайте пятый момент времени.
Где точки у нас с вами будут находиться?
После B,
а родительская до А.
Так, шестой момент времени мы спускаемся с вами.
И получается, поскольку мы спускаемся,
у нас красная точка и черная синхронизируется.
Красная это родительская.
Черная это наша.
В седьмой момент времени мы идем по букве А.
Поэтому у нас с вами черная точка,
и черная точка с черной синхронизируется.
Поэтому у нас с вами черная здесь,
красная здесь.
Дальше момент восемь, мы опять же спускаемся.
Давайте буду нумеровать.
6, 7, 8,
потом мы поднимемся вверх, это 9,
10, 11, 12
и 13.
Следите за махинациями.
Значит тут зеленая, тут красная, тут.
Давайте я справа буду писать.
В девятой точке у нас
красная тут,
черная тут, красная у нас
получается будет после В.
Потом в десятый момент времени
у нас получается А, В,
А, В, красная тут,
точнее черная тут, красная тут.
Тут еще важно, что мы забыли
нарисовать еще один шаг.
Получаем 10,5.
В котором мы опять же должны синхронизировать
красную точку и черную точку.
Шаг 11.
А, В, А, В,
черная тут,
красная тут,
вот 11, черная тут, красная тут.
В двенадцатом шаге,
смотрите, что у нас происходит,
интересная вещь.
А, В, А, В,
черная тут,
красная тут,
черная остается на месте,
а красная поднимается сюда.
Видите, черная остается здесь,
а красная она тут.
И в тринадцатом шаге
у нас получается А, В,
А, В,
вот смотрите, тут черная,
черная точка.
Ну, а родительскую давайте пометим вот сюда.
Смотрите, что у нас получается,
то есть при помощи точек, да,
причем очень важно заметить,
что есть некоторая закономерность,
которую мы можем заметить.
Давайте двенадцатое правило посмотрим,
каким образом мы его получили.
Двенадцатое
у нас получилось из одиннадцатого,
да, вот из вот этого вот.
То есть мы двенадцатую подняли,
и посмотрим еще пятую.
Пятую.
Пятую позицию.
Давайте заметим общую закономерность
у одиннадцатого состояния
и у пятого состояния.
Кто видит общности?
Там типы отделяют на одинаковые слова.
Не-не-не, но это случайное совпадение.
Давайте посмотрим позиции точек.
В одиннадцатом, смотрите, где совпадение идет.
В одиннадцатом, смотрите, где совпадение идет.
Смотрите, где совпадение идет у нас.
У одиннадцатого, у пятого.
В середине?
Да, смотрите, в середине у одиннадцатого красная точка
совпадает с пятого черной точкой.
И это не случайность.
У пятого и у двенадцатого красные...
С пятого на двенадцатый переносится красная точка,
а с одиннадцатого на двенадцатый переносится черная точка.
И на самом деле это не случайность, это закономерность.
В следующий раз мы с вами построим правила,
которые у нас есть.
Мы ведем такое понятие.
На самом деле вот эта история, давайте пятая,
мы сможем закодировать вот таким образом.
С точки B, S.
Здесь мы указываем красную точку.
Давайте для этого я напишу ноль.
А здесь мы будем писать черную точку.
Принадлежит D2.
D2 это значит, что красная точка стоит на второй оппозиции.
Ноль это значит, что красная точка стоит на нулевой оппозиции.
А одиннадцатое состояние у нас перепишется так.
S, A, B.
Точнее, смотрим, где у нас одиннадцатое правило находится.
Это у нас, смотрите, A, S.
A, S. B, S. точка.
Точку черную пишем.
Дальше смотрим, красная точка находится у нас с вами в позиции 2.
А здесь у нас идет принадлежность D4.
Вот. И при помощи как раз вот этого механизма,
то есть вот это механизм, оно основывается на каком-то дереве,
а здесь у нас состоится зависимость только от правил.
Вот. В следующий раз мы с вами запишем правила
и начнем, собственно, при помощи этих правил манипулировать.
Там как раз будет три операции.
Опуститься, передвинуться и подняться.
Вот. Извините, что я чуть-чуть задержал.
Давайте задавайте вопросы, потому что мне кажется,
что есть, могут быть вполне непонятные вещи, которые у нас сегодня были.
Что-то все взяли просто вышки.
Ладно, тогда всем хорошего дня, вот, не болейте, всем здоровья.
А, что мы хотим в итоге сделать?
А мы в итоге хотим слово разобрать.
Мы хотим проверить, что слово лежит в грамматике,
если не лежит, то какое дерево вывода у него.
Вот. Мы сейчас на одном примере разобрали,
как гипотетические дерево разборы разложить в последность правил.
