так ну сегодня добрый день во-первых сегодня я помню что я не завершил доказательства там
надо сумму оценить аккуратненько осталось чуть так друзья на вы помните для чего сумма то
оценивается и помните чего мы доказываем мы доказывали теорему о том что жадный алгоритм
асимпатически почти наверное если ошибается то не больше чем в два плюс и эпсалон раз но ладно
раз вы это забыли я просто формулировку теорема напишу то асимпатически почти наверное
альфа ну так написать на случайном графе жадная одна вторая если вы ее разделите на жадную альфу
на том самым случайном графе то вы получите не больше чем два плюс эпсалон вот тут надо
добавить еще для любого эпсалон большего нуля асимпатически почти наверное выполнено вот это
так друзья ну сейчас я надеюсь вы вспомните но нам идейно не надо уже помнить и что такое
жадный алгоритм ничего мы дошли до некоторые выкладки то есть мы доказали что вот это вероят
вернее вероятность отрицания мы доказали что вероятность с которой вот это вот бяка больше
чем два плюс эпсалон вот это вероятность она маленькая она не превосходит не в степени минус
а вот тут мне надо напомнить на 8 по моему у меня получилось они на 4 а потому что и ну но
я просто целую нет но ну как 4 хватит ну хватит конечно просто начиная с какого тен точно
хватит начиная с какого тен можно написать 4 я имел ввиду что целая часть x вообще всегда не
меньше чем x пополам и отсюда возникла дополнительная половинка но это изысканная
конечно оценка но целая часть x не меньше чем x минус 1 на самом деле а поскольку x растущая
пункция то да вы читать из нее единицу да еще делить на 1 минус эпсалон это правда можно было
так сделать ну я не знаю поскольку многие запомнили там 8 давайте я оставлю 8 но это
правда не имеет ни малейшего значения 8 или 4 хоть 100 а логарифм двоичный да не не оно нет
слушайте если я так буду читать я точно кокну нет нет я стараюсь все-таки все аккуратно да
логарифм был конечно двоичный правильно правильно логарифм двоичный дальше было
суммирование по а 1 от единицы до 1 минус эпсалон на тот же самый двоичный логарифм n по а м
чего а я помню друзья у кого-нибудь есть суммирование или вы только слушаете но не
записывать я думаю что я правильно пишу так что там надо писать что цитая цежитая пусто
и что мощность цитого равняется аиту вот такое вот суммирование а тут просто единицы но там
были вот эти отрицательные экспоненты я их вынес за скоб суммирование бралось из того что
там было написано вот здесь как сейчас помню огромное огромное событие и там
стали квантеры существования существует а 1 а м вот в этих пределах и существует
один целый вот с этими условиями а дальше было после квантеров существование некоторое
событие зависящие от всех этих параметров а 1 а м ц 1 ц м но вот его вероятность мы сумели
оценить так что она уже не зависит от этих параметров поэтому мы свели кисах суммирование
единиц но суммирование потому что квантер существование это фактические объединение что
хоть да мы оцениваем вероятность объединения суммой но это вроде понятно да так ну давайте
считать сколько тут слагаемых я напишу идиотскую оценку потому что она все равно сработает так
но тут придется переписывать никуда не денешься тут тоже давайте один я напишу а м а вот для ц
1 ц я напишу дурацкую оценку но сколькими способами можно выбрать м множество если известны мощности
этих множеств ну например можно вот так написать ц и зен по а 1 умножить и так далее умножить на ц
и зен по а м дурацкая она потому что я не пытаюсь учитывать что они не пересекаются но можно было
бы написать более громоздкую оценку тут ц и зен по 1 потом ц и зен минуса 1 по 2 там и так далее да мне
плевать это такая мелочь все эти один они логарифмические друзья но когда логарифом
вычитается и зен от этого ничего симпатически не меняется то есть напрягаться писать более
тонкие оценки нелепо сейчас мы это тоже нелепо оценим тут е в степени ой как противно это переписывать
8 лог двоичный n а тут напишем так значит сумма по а 1 сумма по а м n в степени а 1 плюс
и так далее плюс а м но то есть я оцежку оцениваю просто как n в степени соответствующие а и т
но не делю на а и т факториал потому что опять же факториал логарифма это ерунда по сравнению с
n в степени так по идее это надо ц и зен пока как оценивать как n в кат и поделить на к
факториал но я на к факториал тоже забил на а и т факториал я забил они не повлияют не помогут
так ну и чего такое а 1 плюс а м но надо вспомнить что тут было вот так мы это проходили конечно
прошлый раз сумма вот этих а и т х она меньше чем n попала не больше чем n попала но потому что
каждый из них не больше чем вот это каждый из них не больше чем вот это ну значит когда
вы их суммируете и умножаете на м в итоге то у нас получается не больше чем n попала получается
вот так так 8 лог двоичный n и умножить на n в степени н пополам а потом на сумму по
а 1 и так далее сумму по а вот ну единиц ушен степени н пополам опять выносится скупка
такая нудная но очень по моему простая выкладка выкладка сама простая потому что не надо напрягаться
я пляп грубо оцениваем все равно сейчас все получится так ну это мы тоже оценим как максимально грубо
ну и давайте все загоним под одну экспоненту и во первых у нас есть вот это бяка но она не
бяка потому что на самом деле она очень коротенько дальше будет плюс вот тут как раз натуральный
логарифм потому что все находится под экспоненты с основанием е н в степени н пополам представил
просто как е в степени н пополам налога а лог натуральный ну а слагаемых тут меньше чем что
ну чем двоичный логарифм n да в каждом суммировании меньше чем двоичный логарифм n слагаемый ну значит все это
будет вот так на двоичный логарифм в м той степени
но это я посчитал сколько слагаемых в кратной сумме сколько единиц но это тривиально ну и в последний раз
переписываю тут n в степени 1 плюс епсилон 8 лог двоичный n плюс n пополам логарифм натуральный
n и плюс о боже мой давайте знаете как меньше либо равно тут чтобы целую часть просто снять я
вот сам сниму целую часть не буду рисовать целую часть я напишу n поделить на дважды 1
минус епсилон на лог двоичный n это я м оценил сверху просто сняв целую часть и дальше мне
это надо умножить на смешно сказать на натуральный логарифм от двоичного логарифма не оно как
но я просто гоняю все под одно общую е степени поэтому я беру от логарифма двоичного натурального
я успеваем
не надо какие-то грубые выкладки очень идут все уже кульминация наступила не знаю можно ли
эту кульминацию нас считать считать катарсисом ну потому что ничего такого тут восторга то не
вызывает уже все смысл весь понятен но смотрите поскольку епсилон больше нуля у нас заранее
зафиксирован епсилон это может быть очень маленькое число но оно от н не зависит оно
зафиксировано с самого начала то тут у нас стоит n в какой-то степени которая строго больше
единицы и делится на логарифм то есть это все равно n в какой-то степени строго больше единицы
но оценивается снизу скажем так то есть со знаком минус стоит функция которая растет ну
по крайней мере как n в степени 1 плюс епсилон пополам там я не знаю ну как n в степени 1 плюс
что-то а здесь стоит со знаком плюс и он умноженная на функцию которая растет медленнее любой степени
поэтому вот эта разность стремится очевидно к минус бесконечности или не очевидно но здесь-то
еще хуже здесь повторный логарифм делится на логарифм то есть вот эта функция она даже мала
по сравнению с n то есть это слагаемое оно еще меньше значит чем вот это поэтому все это на самом
деле с огромным свистом отправляется в ноль таким прям знаете как у соловья разбойник показатель
экспонента стремится к минус бесконечности ну значит сама экспонента стремится к нулю вот такая
вот история но заметьте что если я здесь запишу epsilon равная нулю как я обещал в прошлый раз
ничего не получится потому что будет n поделить на логарифм n а тут будет n умножить на логарифм
и сразу все сломается поэтому epsilon больше нуля точно нужно ну скажем так по крайней мере в
этом доказательстве но я утверждаю что вообще ну как бы это подел можно нижнюю оценку написать
на действительно требует epsilon положительно но с вас этого никто не попросит победители не
судят epsilon больше нуля все получилось epsilon равно нулю в этом рассуждении уже все ломается так
я традиционно в этом месте немножко понижаю пафос значит с одной стороны я очень много говорил
еще в прошлый раз и сейчас готов это подтвердить что если у вас в вашей если хотите практической
задачи возникают графы которые вы можете считать случайными но вот в этом смысле случайные то есть
вы считаете что у них нет какой-то предрасположенности формировать определенную структуру знаете как вот
интернет например он подчиняется законам природы которые говорят о том что в нем точно
ребра появляются невзаимно независимо с вероятностью одна вторая каждая а как-то более хитрым образом вот
если у вас ситуация не такая а вы можете считать что все графы равно возможны тогда жадный алгоритм
от шикарная вещь потому что имеем миллиарды вершин вы еще имеете какие-то шансы посчитать за
n в квадрате операции ну 10 и 18 это что-то обозримое ну да наверное вы ошибетесь в два раза но слушайте
на миллиардах вершин ошибиться в два раза для такой задачи как покраска графа это в общем не страшно
а вот следующая теорема которую я сформулирую но не буду доказывать она говорит о том что если
не дай бог вы то же самое запускаете внимание ситуация когда структура какая-то есть все-таки
граф не совершенно случайно то вы можете нарваться на такую хрень что мало не покажется значит теорема
звучит следующим образом прежде чем ее формулировать надо сделать такое понятное замечание что вопрос
какой-то нет значит смотрите прежде чем я сформулирую теорема я сделаю понятное замечание в истории
про жадную раскраску мы говорили о том что нам плевать какая была первоначальная номерация вершин
помните мы говорим что ну пусть дана какая-то номерация вершины мы будем красить жад но вообще
говоря наверное вы понимаете что если перебрать все номерации вершин то в одной из них жадная
раскраска даст правильный понятно да но просто номерации н факториал это плохо это хуже чем
экспонента правда вот n факториал это сквер вот поэтому перебрать все номерации мы конечно не
можем мы не в силах это сделать но кажется что по идее могло бы помочь ну хотя бы частичное
перебирание частичный перебор хотя бы частичный перебор номерации если бы мы могли хоть немножко
себе как-то вот разбавить жить разными номерациями то может быть у нас покрасилось бы лучше и число
независимости может оценилось лучше вот теорема который я сейчас формулирую говорит о том что
бывает совсем плохо вот настолько плохо насколько это возможно значит теорема звучит следующим
образ существует последовательно сейчас надо для любого сначала написать тороплюсь для любого
и эпсилон большего нуля прям мотан сейчас будет но я шучу и для любого дельта большего нуля мотан
смысле количества кванторов на доске для любого эпсилона для любого дельта большего нуля существует
последовательность графов но можно считать что это просто число вершин gn можно считать что
n это число вершин я сейчас напишу слушайте а может быть я не буду писать терминах вероятности
потому что комментировать дольше давайте как-нибудь я по-другому напишу сейчас соображу значит я
напишу вот так знаменатель я напишу n факториал это количество всех способов
занумеровать вершины графа gs индекс мн n факториал количество способов занумеровать
все вершины графа gs индекс мн потому что мы считаем что их n штук ну то есть я хочу написать
вероятность некую но просто чтобы не объяснять относительно чего берется вероятность я ее пишу
прям явным образом знаменатели количества всех способов нумерации вершин а в числителе
количества каких-то про которые сейчас скажу как я значит число нумерации
вершин gn ну естественно мне места не хватило потому что числитель длинный за того что я
пишу слова число нумерации вершин gn которых о хохонюшки хохо так альфа от gn поделить на
альфа жадная от gn больше либо равняется n в степени 1 минус эпселон о все хватит хватит вот
это больше либо равняется 1 минус дельта о но все равно мне не получилось существует н нулевое такое
что для любого n больше либо равного 0 но я не могу эти квантры выписать нормально сходы это
мне тяжело для любого эпселон для любого дельта существует бесконечная последность графов такая
что начиная с некоторого номера доля то есть вероятность того что взяв случайную нумерацию
вершины вы получите что-то отвратительное близка к единице то есть вместо того чтобы получить не
больше чем 2 плюс эпселон как нам давал жадный алгоритм на случайном графе вот на этих специально
подобранных гадостях это будет наоборот не меньше чем почти n и при том что вам придется
сделать перебор номерации почти пол понятно объяснил да доказал эту теорему товарищ по
фамилии кучера похоже на нашего кучеренка да но вот знаете я про это рассказываю уже давно
демид к нам присоединился не так давно я был бы счастлив если бы демид доказал
какую-нибудь такую теорему но к сожалению этого он не хочет вот я даже думаю что он может но не
хочет вот на этом история про жадный алгоритм и заканчивается и давайте я наверное перейду к
рассказу о том как ведет себя что да да да это без доказательства извините виноват да
эту теорему я не доказывать она интересная тоже но не влезает она у меня в курс красивая вещь
просто для сведения что вот с одной стороны жадный алгоритм это круто с другой стороны
надо смотреть на чем вы работаете если граф случайный то круто если граф не очень случайный то
чертова знает что будет да да да это просто для свете свините вот теперь я буду рассказывать
про то как устроено хроматическое число случайного графа это кульминация этой истории про
хроматические числа и за сегодня она не завершится это довольно длинная история очень красивая но
очень я считаю важная потому что с одной стороны она иллюстрирует как работают разные неравенство
плотной концентрации меры комбинаторики в дискретном анализе это прямо такая очень серьезная
современная тема это повсюду используется и в оптимизации сейчас и в статистике но вот
комбинаторики тоже я считаю важным чтобы это как-то вот до вас дошло и потом может вы это
применяли даже не к дискретному анализу а каким-то другим историям ну а вообще вы понимаете почему
важно изучать хроматическое число случайного графа видите вот тут какие-то возникают результаты
которые зависит от того как типичный граф красятся или какие у типичного графа большие независимые
множество так я понятно говорю я очень стараюсь объяснить мотивация а то вы скажете ой как
сложно сейчас нас кокнет но это очень важно это очень содержательный при этом красиво но красоту
почувствует тот кто будет напрягаться иначе катарсиса не будет давайте я даже
тему назову хроматическое число случайного графа и это будет какое-то время у нас
такой вот сквозной линии
ну разумеется мы будем работать только с такими случайными графами с которыми умеем то есть это
эрда шрэни это биномиальная схема мы работаем с графами g от np но вот это p может быть строго
говоря какой угодно функции от н и почему это важно мы тоже знаем помните пороговые вероятности
для связности там для гигантской компоненты и так далее это все какие-то функции зависящие от
вовсе не обязательно констант вот поэтому хочется понять как ведет себя хроматическое число
случайного графа в зависимости от того какую функцию вероятности ребра мы берем как она себя ведет
давайте начнем с чего-то совсем простого я всегда естественно начинаю самого простого вот пусть
например п от н такова что если n умножить на п от н ой n квадрат умножить на п это то даже
это будет стремиться к нулю ну естественно при н стремящимся к бесконечности n квадрат
умножаем на п от н и все равно это стремится к нулю как вы думаете дорогие товарищи какое
будет хроматическое число у такого графа один правильно чудеса какие да я утверждаю мы уже
вдвоем как минимум утверждаем что а симпатически почти наверное хиат случайного графа но я не пишу
же от нп но понятное я от случайного графа равно единицы ребер просто нет почти наверняка
нет ни одного ребра я так понимаю что это даже доказывать не нужно не понимают как это объяснить
вот ну значит можем теперь предположить что n квадрат на п от н стремится к плюс бесконечности
но это опять вот история про то как применять дисперсию до неравенства чебышова для того чтобы
доказать что ребро есть с вашего позволения это делать тоже не буду в этом случае ребра есть то
есть понятно что в этом случае симпатически почти наверное хиат же больше либо равняется двойке
но потому что есть ребро значит надо как минимум два цвета
нормальный темп ну я считаю что это уже упражнение про дисперсию посчитать разделить
на квадрат мат ожидания там все получится ну или как-то по-другому доказывать там в принципе одно
ребро найти это вам не треугольник поискать ребро это легко вот ну давайте все-таки как-нибудь
более содержательно пусть n квадрат а ну и как же вы можете спросить а что будет если
n квадрат умноженное на п от н стремится не к нулю и не к плюс бесконечности а константе но это
первый год когда вы сами можете на этот вопрос ответить но помните я вам рассказывал формулу
формула обращение как через пактериальные моменты посчитать вероятность короче я не буду
писать ответ хотите подумайте сами на экзамен я тоже в обязательном порядке никого спрашивать
не собираюсь ну как мне ну как некая задача которая может там десятку дать или выправить
какое-то положение это вполне нормально так давайте считать что это все еще стремится плюс
бесконечность даже не все еще конечно уже стремится плюс бесконечности но при этом
скажем так не слишком быстро то есть если n без квадрата умножить на п то все еще будет стремиться к
нулю ну какая-то функция типа 1 поделить на n в степени 3 вторых умножаем на n в квадрате
бесконечности умножаем на n к нулю или там на n лог n так но можно догоняться какой я хочу
здесь написать ответ будет ровно 2 я утверждаю что в этом случае хроматическое число не
превосходит двойке ну и стало быть ей равно граф 2 долин симпатически почти наверное в
этой ситуации граф 2 долин так это я сейчас докажу конечно это тоже можно расценивать как
упражнений но надо что-то доказывать ну-ка
ну мы с вами знаем критерий в удольности то есть в каком случае граф красится в два цвета когда
в нем нет нечетных простых циклов правильно правильно
круто да можно может нет но я хочу сказать так что здесь-то сейчас окажется что циклов нет
вообще ну то есть граф является лесом ну естественно симпатически почти наверх
просто вероятность настолько маленькая что циклы просто не образуют так ну давайте это поймем пусть
икса это число простых циклов же сал циклов ну имеется в виду простых число простых циклов
же тогда математическое ожидание x по линейности вычисляется так это сумма по
r от тройки до n ну слушайте я не знаю я подробно не комментирую потому что мне кажется мы такое
делали много раз по r от тройки до n дальше я фиксирую r вершин для цикла упорядочиваю цикл одним
из вот стольких способов ну все это было и дальше пишу на п в р так нормально вот это все тоже у
нас такое было оцениваем как n в этой степени это было буквально на прошлой лекции когда мы
занимались обхватом графа я ровно такую же оценку писал только там было суммирование до l а сейчас
оно до n в этом принципиальная разница суммировать до l до константы или суммировать по всем r вообще
поэтому тут приходится как бы заново это все писать но в любом случае получается меньше чем
сумма по r от тройки до n n п в этой степени и вот опять же в отличие от того что было на прошлой
лекции там n п было больше единицы и поэтому последнее слагаемое было самым большим а здесь
n п стремится к нулю поэтому мы можем оценить вот эту сумму как сумму геометрической прогрессии у
которой знаменатель убывает ну я очень люблю писать сумму бесконечной прогрессии может быть
вы за мной заметили этот грешок потому что мне кажется что формула для нее чуть
более компактная но в общем вы можете писать и конечную я не знаю как вам удобнее это конечно
получается n п в кубе на 1 минус n п ну еще раз пользуемся тем что n п стремится к нулю получаем
что это стремится к нулю раз мат ожидания числа циклов стремится к нулю значит по неравенству
маркова вероятность наличия хотя бы одного цикла не больше чем мат ожидания то есть и она
стремится к нулю а значит вероятность отсутствия циклов стремится к единице ну то есть а симпатически
на почти наверное граф представляет собой лес если вы еще вспомните историю про компоненты
которые у нас когда-то была там был вот такой порог и меньше единицы ц больше единицы мы говорили
о том что если ц меньше единицы то а симпатически почти наверное все компоненты имеют логеритмический
размер по числу вершин а если ц больше единиц то уже есть гигантская компонент я не слишком
быстро говорю нормально я просто напоминаю что нас была такая история про компоненты вот если
ц меньше единицы и п вот такое то а симпатически почти наверное каждая компоненты имеет размер
ограниченный логарифму ну там константы умноженные на логарифм а сейчас мы доказали что если
nps стремится к нулю то граф представляет собой скорее всего лес то есть вкупе вот с этим
результатом мы понимаем что граф представляет собой лес в котором каждое дерево имеет не более
чем логеритмическое количество вершин согласны такой вот лесок из маленьких компонентов такой
как бы назвать-то даже не знаю много отдельных таких рощиц так ну ладно пункт четыре я не буду
возиться с доказательством с вас тоже его не потребую опять же это там на десятку на
управление ситуации я это обычно не доказываю давайте пусть np от n стремится к константе и
ц меньше одного но то есть мы находимся вот ровно в этой ситуации когда у нас все компоненты все еще
не более чем логеритмического размера но при этом np уже не стремится к нулю а стремится какой-то
константе положительной которой меньше единицы фактически мы вот в этой ситуации
ну я напишу как бы со звездочки в том смысле что я его не доказываю тогда можно доказать
что все компоненты
случайного графа ну давайте я честно пишу а симпатически почти наверное конечно
почти наверное все компоненты случайного графа это либо деревья
как в случае когда здесь стремление к нулю
либо унициклические графы
причем хотя бы один нечетный цикл есть
но это возня со симптотикой числа унициклических графов которую мы в начале семестра разбирали
помните там корень из пи на 8 в общем если повозиться вот с тем знанием оно ровно здесь
нужно то можно понять что компоненты по прежнему очень похоже на деревья но вот часть из них все
таки не деревья а унициклы а раз там есть еще и цикл нечетной длины но это означает как следствие
что а симпатически почти наверное хроматическое число такого случайного графа в точность равняется
есть цикла нечетной длины значит не меньше трех а то что все распадается на кусочки в каждом из
которых либо хром число 2 либо хром число 3 но все значит оно не больше трех тоже но это я не
доказываю потому что тут много такой технической возни но я утверждаю что вот наше знание полученное
в начале семестра про симптотику числа унициклических графов оно достаточно для того чтобы
доказать такой ну немножко продвинутая может упражнения но оно решает не обязательно ни в коем
случае не пугает так вот то что я там прогон какой-то нес по поводу неравенств плотной
концентрации мира это то к чему мы сейчас через какое-то время перейдем следующий следующий
режим в котором в рамках этого курса я рассказываю как себя ведет хроматическое число вы его услышите
через пять минут какой у меня получается пятый пункт да значит 5 значит друзья ну мы с вами все
таки как называется знакомимся достаточно глубоко с дискретным анализом я абсолютно точно знаю что
это курс уникальный такого по насыщенности вы больше нигде не услышите так что может и гордиться
вот но все-таки я хочу сказать что он не аспирантский а для второго курса поэтому я
рассказываю не все режимы в которых может находиться вероятность ребра а только те которые
успеваю рассказать но они как бы создают некую общую картину того как может быть устроена жизнь то
есть не ждите от меня полностью исчерпывающего рассказа о том как оно бывает поэтому вот пока
он был как бы исчерпывающим мы шли очень последовательно ну как бы да а вот сейчас я прыгну резко то есть
я не скажу вот пусть она стремится к с и ц больше единицы там тоже можно разобраться но я про это
говорить не буду а прыгну резко и скажу пусть теперь п отн идет тебя вот так это некий конечно
частный случай возможного поведения но он полезный и поэтому я про него рассказ где ну альфа уже
больше нет меньше единицы вот альфы меньше единицы то есть мы сильно подпрыгнули по вероятности ребра
по отношению к ц поделить на 1 1 поделить на n в степени например 0.9 это функция которая стремится
к нулю сильно медленнее чем ц поделенная на n с которой мы имеем дело в пункте 4 пункте 4
п это примерно ц поделить а здесь речь идет обн поделить об 1 поделить на например n в степени
0.9 ну не важно а нет альфы меньше одного это 0.9 например
да 1 разделить на корень и зен хорошо подходит данную 0.9 это я приблизился к единице но
можем цать один поделить на корень и зена тоже подходит это еще медленнее стремится к нулю мы
идем от очень быстро стремящихся к нулю функции когда вообще ребер нету вообще говоря
к по равному 1 2 вот к тому самому с которым мы работали например в истории про жадный алгоритм
по равно 1 2 на нем мир клином не сошелся потому что вон какие бывают эффекты тут всякие гигантские
компоненты и прочее но мы потихоньку приближаемся по равному константе просто сначала шли совсем
аккуратненько последовательными такими переходами а тут подскочили ну потому что
какая-нибудь функция типа логариф мэн поделить на n в этом случае явно вообще не рассмотрено
на константу я это не умножаю ни на что не умножаю беру от ровно n в степени минус альфа и то уже
будет такая красотища и сложность что давайте это преодолеем и получим катарсис вот ладно все
были просто смешные примеры значит смотрите известно но мы этого не докажем но это вот
достижение прямо последних самых 20 лет известно что если альфа все-таки не слишком маленькая
больше 1 2 но то есть это не один на корень и зона вот именно один на н степень 0 8 там 0 9 то
существует такое у но оно естественно зависит от того какой альфа мы зафиксировали существует
такое ум а но знаете не только от альфы зависит на кэша тэн еще зависит да важно отметить существует
некоторая функция зависящая от н от альфа такая что а симпатически почти наверное у не превосходит
хиадже не превосходит у плюс один то есть хроматическое число случайного графа сконцентрировано
всего в двух значений не ну слушайте не то чтобы это прям вот мега пафосно смотрите вот здесь
в одном значении сконцентрирует и здесь оно вообще в одном значении и здесь оно в одном значении да я
утверждаю что вот мы подняли вероятность ребра и как бы разнообразие того что возникает с высокой
вероятностью оно повысилось но повысилась все еще очень не сильно то есть по прежнему
концентрация значений хроматического числа очень плотная, очень высокая.
Теоретически граф имеет хроматическое число в пределах от 1 до n, если он
на n-вершинах. Оказывается, что типичный граф при относительно малой вероятности
ребра предпочитает принимать всего два различных значений. Из вот этих n
возможно. Прочувствуете, да? Вот если у вас вероятностная мера на множестве
графов задается маленькой вероятностью ребра, то у типичного графа по этой
вероятностной мере хроматическое число одно из двух, а не из n. Скорее всего.
Понимаете, да? Пафос вот этого утверждения дополнительной в том, что это зависит от n.
То есть тут у нас была константа все время. 3, 2, 1. А вот эта функция, которая
стремится к бесконечности. Значит, упражнение... Друзья, вот прямо упражнение.
Нет, ну это теорема без доказательства, а упражнений нет, но не доказать эту
теорему. Да, упражнение докажите для любого альфа от 1, 2 до единицы, и от g
стремится к бесконечности асимпатически почти, наверное. Но то есть, что вот эта
функция у, это не одно фиксированное число, как в предыдущих пунктах, а оно
зависит от n реально, она стремится к бесконечности.
Это вполне посильно. Тут надо просто использовать вот такое неравенство,
которое вы прекрасно знаете. Тут n, и надо просто доказать, что альфа от g, ну,
в растущее число раз меньше, чем n. Я вам подсказку даже даю. Что? В растущее число раз.
Нам нужно, чтобы g стремилась к бесконечности. Это простое упражнение,
тут ничего такого нет. Я не говорю, что оно какое-то там обязательно, что его с каждого
спросят, но если вы хотите понять, как жизнь устроена, решите это упражнение,
оно решаемое. Так, вы поняли, в чем оно состоит? Ну, поняли, конечно. То есть, вот
пятый пункт, он отличается от предыдущих четырех не тем главным, что тут повысилось
разнообразие значений, что там было по одному, а тут два, а тем, что эти два
значения меняются со изменением числа вершин. Но их все время два. Так, а мы
докажем теорему, с которой эта вся история началась. Эту теорему мы в такой
точной формулировке не докажем, а мы докажем теорему, которую доказал
замечательный математик по фамилии Болло Баш. Такой вот классик в теории
случайных графов. Я не помню, я уже упоминал его фамилию, да? А где, в каком
контексте? А, просто книжку упоминал, да, случайные графы. Да-да-да, вот у него
книжка есть, случайные графы. Вот он классик, ему в этом году 80 лет, но
выдающийся человек совершенно. В Кембридже сейчас работает, он родился в
Генгрии в 1969 году, стажировался в стекловке. Знаете, что такое стекловка, да?
Математический институт у Гельфанда, то есть он занимался вообще функциональным
анализом поначалу, а потом вот в некотором контексте занялся случайными графами
и стал классиком в этой области. Ну и как-то сбежал из социалистического лагеря,
в итоге оказался в Кембридже и сейчас там занимает мегапочетную должность
какого-то, пеллоу, профессор этого, Тринити колледжа, в общем, большой человек.
Вот, но мы с ним очень хороших отношений, он сюда приезжал неоднократно, пока это
было вот легко и возможно. Я к нему приезжал, у нас даже совместные работы с ним есть.
Вот, Палабаш начал эту историю, то есть вот режим, когда p равняется n в степени
минус альфа, он первым изучил, это было начало 80-х годов прошлого века. Он доказал,
что если альфа больше, чем две третьих, то есть чуть-чуть послабее, не одна вторая,
две третьих, большее, более сильное ограничение, то тоже существует у, естественно, тоже растущая,
тут деваться-то некуда, упражнение никто не отменял. Вот такое, что асимпатически почти,
наверное, хиадже находится в множестве от у до у плюс три. Ну, то есть оно сконцентрировано в
четырех значениях, это опять же чуть слабее, чем то, что известно. Ну, известно, что в двух,
а мы докажем, что в четырех. Нет, но еще раз, это хуже, это хуже во всех отношениях, альфа больше
двух третьей, это большее ограничение, чем альфа больше одной второй. Вот, а четыре значения,
это опять же больше, чем два, но пафос суть-то не меняется от этого, понимаете, то есть все равно,
как бы ситуация та же самая, и концентрация по-прежнему высокая в константном числе значений.
Вот это мы докажем. Так, товарищи, давайте, наверное, начинать доказывать, только проблема в том,
что мы, конечно, сегодня это не докажем, а там будет целая история. Я не буду дальше пока рассказывать,
что будет, то есть дальше я потом расскажу. Мы вот запнулись на этом случае, и сейчас мы на этом
случае проведем довольно много времени нашей жизни. Вот, когда мы вырвемся из цепки хлоп этого
случая, тогда мы продолжим изучать, а что же будет, если п еще больше. Значит, друзья, в доказательстве
этой теоремы будет использовано некоторое неравенство плотной концентрации меры. Сейчас я
поясню, о чем я говорю. Значит, это неравенство в полной мере, извините за коломбур, мы не докажем,
а вот используем в полной мере, но некоторую интуицию я создам. Поэтому, смотрите, вот не
воспринимайте то, что я сейчас рассказываю, именно как начало доказательства. Это пока некое
отступление, которое позволит нам потом провести доказательства. Итак, во-первых, я напоминаю вам,
давайте я вот тут напомню. У нас была такая еще теорема про пьяницу. Была у нас теорема про
пьяницу. То есть, теорема про пьяницу говорила вот что, если кси1, что легко спится, почему легко
спится, потому что ты не можешь уйти от своего кабака, тебя тянет назад, причем тянет с очень
высокой вероятностью. Вот, если кси1, ксен, это независимые случайные величины, которые принимают
значения плюс и минус один с вероятностью одна вторая, независимые совокупности, и принимают
значения плюс-минус один с вероятностью одна вторая, то вероятность того, что их сумма больше
либо равняется какого-то а, меньше либо равняется е в степени минуса квадрат поделить на 2.
Так, было у нас ведь такое? Ну точно было. Что, забыли что ли? Нет, вы уж проверьте, пожалуйста,
вдруг я как-то это иначе промулировал, потом вам будет трудно установить биекцию. Ой, мне кажется,
что это было, если этого не было, я сейчас докажу, но это точно было. Это было где-то еще,
наверное, до формулы обращения, то есть до факториальных моментов, а может последние.
Ну где-нибудь там, да. А, слушайте, это использовалось в том числе, когда мы доказывали теорему про
гигантскую компоненту в одну сторону. Вот там это использовалось, поэтому это было непосредственно
перед этим, наверное. Что, нашли, нет? Но мне кажется, что оно было прямо в точности так
сформулировано. Ну, может там буковки были другие, это 1 отn, это уж, я думаю, не так важно. Прямо даже
кси один ксен, да. Ну, не ню, наверное, а это все-таки. Это, это. Вот это, это, а вот это называется ню. Вот такая
буква называется ню, а такая буква называется это. А что такое за горючка в другую сторону?
Это я не умею такую букву, я не знаю, что имеется в виду, но есть мю, это мю. Вот так? Такую не знаю.
Я думаю, что это тоже это, просто я по-разному, ну немножко по-разному пишу. Но я пишу вот так, а можно
писать, наверное, вот так. Но это не ню, вот ню. Вот это ню. Да. Ну ладно, это такой чисто про греческий
алфавит. Слушайте, ну друзья, все, вот эта вот теорема была. И она говорила о том, что вот пьяница
вообще некуда деваться, он не уйдет от цепки хлапа алкоголизма и своего кабака, который этот алкоголизм
порождает. Вот я утверждаю, что в истории со случайными графами есть такая же концентрация,
граф кое-что не может уйти в каком-то смысле. Значит, помните, вот здесь, по-моему, даже на прошлой
лекции был написан такой красивый вензель с многими и. Липшицевость, да, вот сейчас она
появится. Значит, вот давайте скажем, что такое функция неслучайная величина на графе Липшицева.
Ну видите, недавно было. Так, друзья, давайте продолжим, я про Липшицевость расскажу. Значит,
функция f, вот так напишу, на графе называется, ну вы понимаете, что если мы определяем функцию на
множестве графов, мы можем считать ее случайной величиной, потому что множество графов снабжено
вероятностей. Значит, функция f называется Липшицевой. Я буду выпендриваться снова. Не, я могу
постараться нормально написать, но мне нравится вот этот вензель, такая плотность. Липшиц. Называется
Липшицевой. По ребрам. Называется Липшицевой по ребрам, если выполнено вот такое неравенство,
но для любых g и g штрих, которые отличаются не более чем на одно ребро, которые отличаются на одно
ребро. Ну то есть взяли граф g, удалили из него ровно одно ребро, или наоборот добавили ровно одно
ребро. Только внимание, они оба считаются на одном множестве вершин. Мы считаем, что g и g штрих
находятся на одном множестве вершин, то есть добавление ребра означает добавление ребра именно
между существующими вершинами. Новых вершин не появляется. Ну, какой самый простой пример
Липшицевой функции? Количество ребер, да, гениально. Не, ну, конечно, можно сказать количество вершин,
это идиотский пример, потому что количество вершин это константа. Константа, конечно, Липшицева,
потому что она вообще не меняется. Ну, мы все-таки не добавляем случайности помимо той,
которая есть на графах, поэтому я бы тут рандом никакой не применял. А вот не Липшицева, друзья,
вот это важный момент, это для нас будет очень важно в последствии. Не Липшицева, это, например,
число треугольников, с которым мы боролись. Потому что, представьте себе, у вас была вот такая вот
корона, тут могло быть куча вообще вершин к одному ребру прилепленных. Вы вот это ребро кокнули,
у вас пропала куча треугольников. Так, друзья, понятно, да? Но, кстати,
хроматическое число, оно Липшицева по ребрам. Понятно, да? Одно ребро заменяем, но хроматическое
число не может увеличиться или уменьшиться больше, чем на единицу. Так, и давайте,
если бывает Липшицева по ребрам, то бывают Липшицевы по вершинам. Даю второе определение,
оно называется Липшицевы по вершинам, это другое определение. Если тут все то же самое,
то есть разность не превосходит единицей, а вот тут не то же самое. Так, которые отличаются на любое
количество ребер, любое допустимое, на любое количество ребер, сейчас поймете, такое допустимое,
на любое количество ребер в окрестности одной вершины, которая инцидентна на одной вершине или
еще не инцидентна, то есть у вас есть какая-то вершина в графе, вы ее одну выбираете, вот из нее
там в этом графе, ну да, выходили были ей инцидентны какие-то ребра. Значит, вы можете любые из этих
ребер удалить и любые не бывшие там добавить. То есть вы можете как угодно перестроить окрестность
одной вершины, но только одной. И вот если для любых двух графов, которые получаются друг из друга
такой перестройкой, модуль разности не превосходит единицы, то f называется липшицевой по вершине.
Хочу заметить, товарищи, что хроматическое число липшицевого по вершину. Если вы испортите
окрестность только одной вершины, то вы в крайнем случае ее вынуждены будете покрасить в дополнительный
цвет или наоборот не красить в дополнительный цвет. Согласны? Хроматическое число липшицево и по
вершинам тоже. Ну а число треугольников, оно не липшицево ни в каком смысле, конечно, по вершинам
оно тоже не липшицево. Так вот имеет место замечательный аналог теоремы про пьяницу.
Аналог теоремы про пьяницу пойдет у нас без доказательства, потому что на доказательство
этой теоремы ушло бы еще пара лекций. И куча понятий, которые мне кажется рано давать в третьем
семестре, вам достаточно просто понимать вот ту интуицию, которая здесь возникает, больше ничего.
Там надо определять, например, что такое условная мат ожидания и что такое мартингал. А это материал
скорее четвертого семестра, если не пятого. Поэтому я в такие дебри не полезу, эта теорема
будет без доказательства, но вы сейчас увидите, насколько она похожа на теорему про пьяницу.
Значит, давайте она будет состоять как бы из двух частей. Если f липтатого по ребрам, то вероятность
который f уклонится от своего кабака, извините, имеется в виду на случайном графе, причем не важно
каком, g, n, p. Тут не важно g, n, 1, 2, g, n, p, p любое. Ну я пишу аналог прямо вот этого, сейчас модуля мы
тоже нарисуем. Но здесь видите, я же не пишу. Понятно, что если написать вот так, то оценка будет такая же.
А модулем соответственно будет двойка. Вот это вот и здесь тоже верно. Главное, что если липтатого по
ребрам, то получится вот такая штука. Не в степени минус a квадрат на 2m, где m равняется c из n по 2,
но она липтатого по ребрам в полном графе на n вершинах c из n по 2 ребер, поэтому там шашков больше,
чем пьяница делает n шагов, а она делает c из n по 2 шагов. Но как она там их делает,
что там происходит, как устроено доказательство, это я не буду рассказывать, это сложно.
Если кому-то интересно, то абсолютно полное доказательство дается в моей книжке модели
случайных графов. Вот абсолютно полное. Я не знаю, скачивается она из интернета или нет,
но она точно есть в нашей библиотеке, мы ее закупали. Только не путайте с моделями интернета,
модели случайных графов. Вот там это тоже доказательство. Ну давайте в это поверим. Так,
а если... Слушайте, ну давайте, уж раз вопрос возник, я допишу, что, конечно,
имеет место и вот такое неравенство, просто симметричное, и что если мы хотим нарисовать
модуль, тогда надо экспонент удвоить. Так, а второй пункт, что если f липшится по вершинам,
то вероятность того, что f-ef больше либо равняется a, не превосходит e в степени
минус a квадрат на 2n минус 1. Ну где n? Это число вершины. Тут 2 умножить на n без единицы,
минус 1. Маленький минус получился, да? Сейчас увеличим. О, смотрите, какой большой. Это все
в знаменателе, конечно. 2n-1. Так, друзья, вопрос на понимание, чтобы как-то осознали,
какой из двух неравенств сильнее? Что лучше применять, липшицевость по ребрам или липшицевость
по вершинам? По вершинам, конечно. Потому что здесь вы a квадрат делите на n примерно, а здесь
на n квадрат. И потом берете со знаком минус. То есть эта дробь маленькая, а эта дробь большая,
поэтому со знаком минус ее брать выгоднее. Показатели, экспоненты. Сейчас, друзья, понятно
говорю? В каком смысле выгоднее? Вот хроматическое число, например, мы сказали оно липшицево и по
вершинам и по ребрам. То есть если f это хроматическое число, тогда гораздо более сильное утверждение дает
пункт 2. Но если вы возьмете какую-нибудь функцию, которая будет липшицева только по ребрам, то,
естественно, пункт 2 к ней не будет применимо. Вам придется довольствоваться вот этим неравенствам.
А, кстати, какую-нибудь можете привести пример пункции, которая липшицева по ребрам, но не липшицева
по вершинам? Число компонент связности. Да, хорошее дело, да. Согласен. Не, друзья, то есть, конечно,
если пункт обладает только этим свойством, ну куда деваться? Придется, конечно, использовать только
это более слабое неравенство. Но если она обладает липшицевостью в обоих смыслах,
то надо использовать второе, оно сильнее. Так, поняли, да? Все, вот это без доказательства. Еще
раз повторяю, желающие могут найти в моей книжке. Но это если время, силы, желания есть.
Так, ну, некоторая трагедия состоит в том, что у меня осталось 10 минут. Правильно,
что у меня осталось 10 минут? Ой-ой-ой. Какое горе, я не понимаю, что я могу успеть до 11 минут.
Значит, мы хотим доказать теорему Балабаша. Наша цель, если вы помните, доказать теорему
о концентрации хроматического числа в четырех значениях. Помните, да? Вот, вопрос в том,
чего я успею. Я, похоже, только успею сформулировать чего-то и, может быть, начать доказывать. Значит,
есть лемма техническая, которую я сейчас точно успею сформулировать. Но ее в любом случае в
следующий раз придется повторять, потому что вы, как обычно, все забудете. Значит, пусть альфа,
как и у Балабаша, находится в пределах от двух третей до единицы, тогда имеет место вот такая вот
штука. Вероятность того, что для любого s из v... Ну, давайте я хотя бы как следует прокомментирую
лему сегодня, а в следующий раз просто напишу формулировку. Значит, что такое v? v это множество
вершин. v это множество вершин g от np. А p у нас равно n в степени минус альфа. Давайте добавлю. p
равно n в степени минус альфа. Тогда вероятность того, что для любого множества вершин, мощность
которого не превосходит корень из n на логариф m, такая вот интересная пункция, хроматическое число g,
ограниченного на это множество вершин, не превосходит тройке, больше ли б равна 1-1 на логариф
m при n, начиная с некоторого. Но это техническая лемма, которая на самом деле и есть то самое место
теоремы, где используется, что альфа больше двух третей. Вот эта штука будет использоваться в ином контексте.
Это чисто техническая лемма. Ну что утверждается? Давайте, друзья,
поймем просто в чем смысл этого утверждения. У нас есть сарделька, которую мы называем v,
которая состоит из n вершин. Мы берем любую в ней подсардельку достаточно, ну скажем так,
маленького размера. Это подсарделька s, размер которой не больше, чем корень из n на логариф m.
Пытаемся ее покрасить. Так, понимаешь, что такое g, ограниченное на s, но просто взяли
в качестве множества вершин s и сохранили все ребра, оба конца которых находятся в s.
Значит, вот пытаемся покрасить только этот кусочек графа, и о чудо нам удается покрасить
три цвета. Любой кусочек, каждый кусочек нам удается покрасить три цвета. Это ничего не
говорит о глобальной покраске. Общее количество цветов, но вы помните упражнение стремится к
бесконечности. Вот в этой ситуации упражнение состоит в том, что общее количество цветов точно
стремится к бесконечности. Тем не менее утверждается, что каждый кусочек относительно
маленького размера, если не брать в рассмотрение все остальное, красятся в три цвета. Понятно,
да, Пафос? Но важно, что квантор для любого стоит под знаком вероятности. Это как бы
усложняет жизнь. Я не пишу снаружи для любого конкретного множества вероятность того,
что оно красятся в три цвета, стремится к единице, а я пишу наоборот, что вероятность того,
что каждое множество красятся, вот эта вероятность стремится к единице. Это
же более сильное, более мощное утверждение. Ну за 6 минут я его не докажу, конечно. Значит,
что я буду делать? Я, естественно, переверну, напишу отрицание и буду доказывать, что вероятность
отрицания достаточно маленькая. Ну а что делать? Давайте уж в следующий раз, 5 минут придется
пожертвовать. Отдыхайте. Это буду доказывать в следующий раз.
