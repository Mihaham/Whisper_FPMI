Тема сегодняшней лекции – это многопоточность, вообще на самом деле все, что связано с потоками,
синхронизацией, мьютексы, блокировки, файберы. Все это вас расскажется в отдельном курсе,
поэтому в окосе про это упоминается совсем немного, только те вещи, которые связаны
непосредственно с низкого уровня взаимодействия на уровне операционных систем. То есть никакой
большой теории про разные синхронизации у вас не будет, будет именно использование инструментов
POSIX. Итак, потоки. На самом деле слово «потоки» – оно очень плохое и правильнее называть преды.
Ангалицизм, конечно, но хорошего перевода на русский язык до сих пор не придумано,
потому что слово «поток» уже занято это слово «стрим», «потоки» бывают очень разные. В принципе,
еще где-то вот у мгушников используется терминология нити, достаточно странная. Еще
используется терминология «легковесные процессы», но тоже не очень так хорошо. В общем,
просто thread – это thread. Давайте их называть так. Что такое thread? Трэды – это просто какие-то
задачи, которые выполняются процессорами, либо несколькими процессорами. На самом деле любой
многоядерный процессор с точки зрения логической организации и с точки зрения операционной системы –
это просто несколько процессоров одинаковых, даже несмотря на то, что они находятся все на одном
кристалле. И что есть у каждого трэда? У каждого трэда есть свое состояние процессора, т.е. текущая
выполняемая инструкция, набор регистров, состояние процессора, находится ли он в привилегированном
режиме или нет, набор флагов. Но еще плюс у каждого трэда есть своя небольшая область
памяти, которая называется stack. Каждый трэд – это отдельная задача, они выполняются независимо
друг от друга, могут выполнять какие-то функции. Соответственно, для выполнения функций нам нужно
где-то хранить адрес возврата, и для этого как раз нужен stack, но опять же функции могут быть
локальные переменные. И вот в чем принципиальное отличие трэдов от процессов? Когда мы говорили
про процессы, то я постоянно упоминал о том, что это что-то самодостаточное, изолированное,
и между собой процессы могут общаться только посредством игра. Вот с потоками это немножко не
так, потому что все потоки в рамках одного процесса, они разделяют одно и то же адресное
пространство, у них могут быть общие файловые дискрипторы, ну и все атрибуты процесса распространяются,
в том числе и на потоке. Вот когда мы запускаем какой-то процесс, то мы уже запускаем одну задачу,
это самый первый поток, который у нас выполняется. Он начинает выполнять функцию подчеркивания start,
которая в свою очередь начинает выполнять сишную функцию main, либо плюсовую функцию main,
либо ни то ни другое, если у вас программа на паскали. Вот есть некая точка входа подчеркивания
start, которая начинает выполнять именно самый первый поток. При этом этот самый первый поток может
создавать новые потоки программы. В свою очередь каждый вновь созданный поток тоже может создавать
еще какие-то потоки. И получается, что вроде как что-то похоже на организацию нескольких процессов,
но тут есть одно важное принципиальное отличие. Когда мы говорим про процессы, мы можем посмотреть
на дерево процессов, кто для кого является родителем. В случае смерти какого-то узла в дереве процессов,
у нас его дочерние процессы переподвешиваются на корневой процесс, а вот с трэдами это все не так.
У нас конечно запускается какой-то трэд при запуске процесса, но этот трэд совершенно
равноправен со всеми остальными трэдами, которые он запустил. И в принципе возможность ситуации,
когда главный тред завершился, но программа еще не завершилась. И между трэдами в отличие от
процессов нет такого понятия, как один тред является родителем другого. Они все являются
равнозначными и вытворять могут все что угодно. Когда вы завершаете работу программы с помощью
системного вызова exit либо функции exit, есть еще системный вызов под названием exit group,
если вы посмотрите вывод команды strace на какую-нибудь программу, которая завершает
корректную свою работу, то иногда вместо системного вызова используя экзит group,
который завершает работу всех трэдов, то у вас завершается работа сразу всех поток. Есть
аналогичные функции, которые называются pit-thread и exit, которые завершают работу только
текущего потока. Давайте посмотрим, что будет, если мы запустим какие-то трэды,
заодно посмотрим на API для их создания и потом завершим какую-то их работу. Итак,
как у нас вообще выглядит создание трэдов? Трэд должен выполнять какую-то функцию. Стандартная
сигнатура для функций в POSIX это функция, которая принимает единственный аргумент по размеру с
машиной слова void-звездочка. Это может быть либо указатель на какой-то контекст, с которым должен
работать трэд, либо просто какое-то произвольное число по размеру, не превышающее размер
машинного слова. Ну и функция трэд возвращает опять же что-то по размеру, не превышающий,
чем размер машинного слова. Просто функция, которая принимает ровно один вход и имеет ровно один
вих. И эту функцию нужно скормить функцией pit-thread-create, которая создает новый поток
выполнения, к которому выполняется та функция, которую мы ему передали. В курсе липовского вы,
наверное, на плюсах пишите. Так, у вас там std-thread используется или самописное что-то. В общем,
на std-thread все то же самое, только это все запускается через конструкцию. POSIX-thread. В общем,
создание это просто создание потока с какой-то функцией, ничего сверхъестественного здесь нет.
Ну и мы можем сделать такую вещь, что мы запускаем какую-то программку очень простую, в которой каждый
thread что делает. Он просто выводит свой номер и спит одну секунду, потом все повторяет. Просто
демонстрация того, что thread действительно работает. Итак, компилируем это все. Так,
я это компилирую под маком, поэтому здесь опция командной стройки немножко нестандартная. Под
linux тут надо еще написать хорошему опцию minus p thread. Под маком и под std она просто
игнорируется. Так, вот мы хотим запустить 10 потоков. Запускаем. Что мы получаем в выводе?
Запускается поток 0.1.2.3. Так, и все. Запускаем еще раз. Уже лучше. 0.1.2.3.4.5.6.7.8.9. Давайте еще
раз попробуем. 0.3. Кто-нибудь может объяснить этот эффект? Вот что у нас происходит с созданием
thread. Здесь у нас, я не просто так закомментировал строчку, мы запускаем 10 thread. Thread начинает
работать независимо друг от друга с разной скоростью. Все, мы уже не можем гарантировать
строгий порядок вывода, который у нас получается. От каких условий зависит, с какой скоростью
выполняются треды? Условий очень много. У нас программа, она, как правило, в Unix, в многозначной
системе живет не сама по себе. Есть еще куча других процессов. Тот же Zoom сейчас делает
видеозапись. Иногда, когда я мало говорю, он, наверное, мало ресурсов расходит. Когда много
говорю, расходует много ресурсов. И это тоже влияет на все треды внутри программы. У нас
есть никакой гарантии, что треды будут работать хоть с какой-то одинаковой скоростью и с каким-то
предсказуемым поведением, если не использовать их синхронизацию. Почему у нас все завершается?
Давайте посмотрим на функцию, которая возвращает целочисленное значение. Даже несмотря на то,
что я не написал никакой return, есть исключение в стандартах C и C++, когда функция может не
возвращать значение, даже если это объявлено сигнатурой. Это в том случае, если функция
называется мы. В этом случае комператор здесь подставляет явным образом значение return 0,
то есть вернуться с кодом возврата 0. И после того, как запущено несколько тредов, которые
начали независимо друг от друга что-то выполнять, и мы видим результат их работы,
тот тред, который запустил все эти треды, то есть самый первый, он доходит до конца функции main,
потом результат работы функции main передается, обрабатывается из функции подчеркивания start и
вызывается системный вызов exit, который в свою очередь завершает работу сразу всех тредов
внутри нашего процесса. Если я хочу просто запустить какое-то количество потоков и завершить
функцию main, есть легальный способ это сделать. Мы можем внутри любой функции, внутри любого треда
завершить его работу двумя способами. Либо дойти до конца выполнения и вернуть какой-то
результат, либо по аналогии с функцией exit мы можем просто из любого места нашей функции,
либо из любого места любой другой функции, которая вызывается из функции обработчика треда,
вызвать некоторые аналог функцию exit, но уже не для процесса целиком, не для программы,
а именно для конкретного треда, который завершит только текущий поток. В том числе это применимо и
к главному треду, который выполняет нашу функцию main. Если я раскомментирую строчку petread exit в самом конце,
теперь у меня функция main завершит свой поток, но все остальные запущенные потоки продолжают
работать. Если какой-нибудь из потоков вызовет теперь системный вызов exit, тогда работа программы
завершится. Либо точно так же я могу просто послать обычный сигнал. Этот сигнал дальше
обрабатывается случайным образом в одном из тредов и приводит к завершению работы всего процесса.
У всех тредов есть общее адресное пространство. Напомню, что в классическом случае у нас в самой
нижней части адресного пространства есть небольшой участок, заполненный нулями. Дальше
располагается сама программа, которая состоит из секции кода, секции константа, секции данных.
Дальше снизу вверх растет куча, если она нужна. Где-то в верхней части адресного пространства у
нас располагается, если считать только пространство пользователя, а не пространство ядра, это разделяемые
библиотеки, как минимум стандартная сибиблиотека для большинства программ. А дальше сверху вниз
растет стек. Причем размер стека у нас обычно фиксирован и память уже считается выделенной.
До начала работы функции подчеркиваемых стак. Тем не менее у каждого треда, который работает в
рамках одного процесса, есть свой стек. И где эти стеки находятся? Они располагаются тоже в верхней
части адресного пространства, но особенность в том, что мы можем запускать новые треды в произвольный
момент времени. А еще мы в произвольный момент времени можем загружать какие-то дополнительные
динамические библиотеки. То есть совершенно необязательно наша программа должна быть скомпонована
с кем-то библиотеками, чтобы их использовать. Классический пример это, к слову, питон вас не
должен смущать, у вас поединок будет. Слово Python, интерпретатор Python, который загружает какие-то
дополнительные модули, эти модули в свою очередь могут использовать под не только написанный
на Python, но и на языке AC, ну или вообще любая система плагинов. И соответственно они тоже
динамически в произвольный момент времени подгружают какие-то библиотеки. И в общем случае,
что у нас находится в верхней части адресного пространства, считается неопределенным,
потому что стеки разных потоков могут чередоваться с разными динамическими
подгруженными библиотеками. Да, кстати, напоминаю, что вот картинка, которую сейчас
провожу на этом слайде, это классическое размещение процесса в виртуальном адресном
пространстве. Потому что у нас еще бывает Ubuntu, Debian, в чем особенности дистрибутивы, кто помнит?
Да, там всякие не скучные обои разноцветные, а еще, ну не совсем насыщенные, там по умолчанию
работает разномизация размещения процесса в адресном пространстве. То есть, на самом деле,
ядро Linux уже очень давно поддерживает эту технологию, когда можно процесс разместить не
по фиксированному адресу, а выбрать случайное место в памяти при запуске и разместить
исполняемый файл туда. То же самое можно, в принципе, делать для библиотек. Но для того,
чтобы любая программа могла быть размещена в произвольном месте, она должна быть скомпилирована
с поддержкой позиционно-независимого кода. И в некоторых дистрибутивах программы
компилируются без поддержки позиционно-независимого кода. В некоторых дистрибутивах, например,
Debian и Ubuntu, они по умолчанию собраны с поддержкой позиционно-независимого кода. То есть,
это фактически опция компиляции и поэтому размещаются случайным образом. Так, вот давайте
чуть более крупным планом рассмотрим, что у нас у себя представляет верхняя часть адресного
пространства там, где стэк. У нас есть стэк самого первого трэда, совпадающий со стэком программы.
Обычно по умолчанию его размер 8 мегабайт. На самом деле, вы можете это настроить до запуска
программы, используя команду u-limit, и размер стэка вы можете варьировать. На самом деле,
8 мегабайт очень много для стэка. Я не помню, показывал вам или нет. В своей группе, наверное,
показывал точно, при каких размерах стэка у нас система остается работоспособной. На самом деле,
если уменьшить размер стэка до 256 килобайт, то можно даже продолжать успешно запускать Firefox.
Google Chrome уже не хочет. На самом деле, 8 мегабайт это более чем достаточно. Вообще, стэк можно
увеличить достаточно сильно, только непонятно, зачем это нужно. Очень редкие ситуации, когда это
может понадобиться. В отличие от кучи, стэк всегда у нас считается выделенным в начальном моменте
времени. Когда мы запускаем новый трэд в рамках одного процесса, у нас появляется еще один новый
стэк. По умолчанию его размер равен размеру стэка для основного трэда. Хотя это можно, конечно,
понимать. Есть еще одна маленькая особенность, что между стэками, которые стоят рядом,
размещаются небольшие участки памяти минимально возможного размера. Минимально возможный
адресуемый участок памяти, который может иметь какие-то обособленные атрибуты, это одна страница.
Размер страницы в большинстве архитектур 4 килограмма, которые называются защитными страницами. Еще
иногда их называют канарейками. Зачем нужны канарейки? Кто вообще слышал слово канарейка?
Применительно койти. Причем здесь птичка. Птичка это при том, что канарейки существуют очень нежные,
и поэтому они когда-то очень активно использовались в качестве расходного материала в угольных шахтах.
Садят клетки с канарейками, если вдруг возникает загазованность, повышенный уровень метана,
что происходит с птичками? Они отправляются куда-то там к своим праптичкам. И это хорошо заметно,
поэтому это индикатор. То есть до тех пор, пока не изобрели электронные газоанализаторы,
очень активно в шахтах использовали вот эти вот птички. Какое это отношение имеет койти?
Имеет отношение следующее. У нас могут быть ситуации, когда переполнение стека, выход за
границу чего-нибудь, случайно потерли нету память. И что мы можем сделать? Мы можем в определенной
участке памяти неиспользуемый прописывать некоторые целочисленные значения. Например,
заранее известные случайные значения, либо посчитанный хэш для определенной структуры.
В общем, какие-то осмысленные данные небольшого размера. Для того, чтобы периодически проверять
целостные данные. И в случае, если данные перестали быть целостными, считать, что что-то у нас пошло не так,
и целостность программы нарушена. Так вот, в ядре реализована поддержка механизма,
похожего немножко на канарейки, только немножко более жесткой ситуации. Между стеками выделяется
небольшая область памяти размером с одной страницей, которая недоступна вообще. То есть,
область памяти для стека имеет атрибуты страниц доступ на чтение и доступ на запись,
а защитные страницы не имеют вообще никаких прав. То есть, любая попытка прочитать данные,
записать данные, либо пытаться их выполнить, приведет к ошибке нарушение сегментации.
Для чего это нужно? После ситуации, что у вас какая-то функция, запущенная в одном из потоков,
начинает рекурсивно сама себя вызывать. Что у вас произойдет? Stack Overflow – известная ошибка.
Если у вас программа однопоточная, ну, казалось бы, Stack Overflow, да, вы просто добрались до границы
стека, все, вас прибили. В случае, если у вас программа многопоточная, то ситуация переполнения
стека может привести к неопределенному поведению, потому что вы можете добраться не до того,
что стек закончился, а задеть память другого потока. И если система на это никак не отреагирует,
то что будет происходить с другим потоком, память, которую вы попортили – это загадка природы.
И защитная страница – это некоторый простейший и фактически бесплатный механизм для того,
чтобы преотвращать ситуацию с переполнением стека. Понятно, что это все-таки не полноценная такая
панацея защита. Можно придумать ситуацию, когда вы просто объявляете какой-то огромный массив на
стеке, дальше обращаетесь к очень большим индексам этого массива, который просто задевает
память другого потока, но не попадает на защитную страницу, и такой механизм, такая канарейка,
вас не спасет. Вот размеры стеков, какие у вас возможны. Стек не бывает до него размер. Максимальный
его размер – 8 мегабайт. Не максимальный, а стандартный – 8 мегабайт. Можно делать 32. Граница
снизу – она достаточно четко обозначена. В линуксе 116 384 байта. Никого не смущает,
что такое странное число. Это почти 16 килобайт. То есть примерно 4 страницы памяти за вычетом 128
мегабайт, которые для архитектуры x8664 считаются гарантированной зоной, куда не будет попадать
стек обработчика 7. В отличие от стека, защитную страницу можно все-таки полностью убрать,
сделать их на его размер. Давайте подытожим. У нас есть процесс. В рамках процесса вы запускаете
какое-то количество трэдов. Они же потоки, они же нити, они же просто трэды. И все это у нас работает
либо на одном процессоре, либо на нескольких процессорах. И между разными задачами планировщик
заданий периодически переключается. То есть у нас есть приоритеты как у процессов, так и у всех
трэдов, которые в рамках этого процесса выполняются. И если вам не нужно делать осмысленных действий,
например, вы ждете, пока появится что-нибудь в другом трейде. Вы можете принудительно передать
управление другому трэду с помощью системы вызова Shared Yield. Вы уже, наверное, сталкивались с ним раньше,
когда писали что-то для процессов, для того чтобы передать управление другому процессу. Так вот,
на самом деле, Shared Yield работает не только между процессами, а между задачами в целом. А это могут
быть как процессы, так и трэды. Естественно, трэдов может стать очень много. Планировщику задача
поплохеет, система будет сильно нагружена, и надо как-то уметь это лимитировать. Если количество
процессов мы худобедно умеем лимитировать с помощью команды Ulimit, то с трэдами, на самом
деле, примерно все то же самое. Но тут есть одна очень важная особенность. Есть некоторая путаница,
которая нигде не прописана. Не в мане на Ulimit, хотя в мане может, конечно, и прописана,
но в Help точно нет. Что именно он ограничен? Ulimit позволяет установить ограничение на максимальное
количество процессов для одного пользователя в текущий момент времени. По крайней мере,
так написано во всех классических UNIX учетах. На самом деле, это не количество процессов,
а суммарное количество трэдов во всех процессах. Для однопоточных программ у нас есть строгое
соответствие, что один процесс – это один трэд, но, опять же, внутри процесса у некоторых программ
могут быть несколько трэдов, их может быть много. Более современный способ как-то ограничивать
количество трэдов – это использовать контрольные группы. И если первая версия, если группа была
достаточно замороченная, то вторая достаточно приятная уже. Там есть ограничения немножко разные,
они могут быть как на количество процесс ID, так можно и прописать отдельное максимальное
количество задач. И с C-групп, опять же, вы можете более тонко настраивать поведение вашей программы,
какие у вас лимиты могут быть, по умолчанию. Так, вообще кто-нибудь помнит, что это контрольная
группа C-групп? Это такая древовидная файловая система, где процессы объединяются в группы,
внутри каждого процесса есть в файловой системе куча файликов, куда можно прописывать разные
ограничения. Когда вы создаете дочерние процессы, они находятся в той же самой группе и могут при
этом создавать подгруппы, объединяться. В общем, появляется такая иерархическая система ресурсов.
Так вот, по умолчанию трэды находятся все в одной группе того процесса, в котором они работают,
но это можно перенастроить файлик, C-групп type, прописать трэвис вместо думаем, и так вы можете
на каждый трэд создавать отдельное поддерево файловой системе и для каждого трэда ID прописывать
свои отдельные ограничения по памяти, по использованию процессов времени и так далее.
Процессы это что-то, что полностью изолировано друг от друга, в то же время трэды работают в
едином адресном пространстве. Вот и процессы, и трэды часто используют как механизм для того,
чтобы распараллелить выполнение какой-то задачи. Например, у вас есть огромный кусок данных,
зачем нам может наладиться несколько трэдов или несколько процессов? Просто для того,
чтобы использовать полноценно ваш процессор, в котором меньше двух ядер,
но вряд ли вы уже где-то встретите, даже в мобильных телефонов. И для того, чтобы задействовать все ядра
или все логические процессоры, вам нужно программу раскладать либо на процессы,
либо на трэды, в общем, на разные задачи. Вот с процессами их назначение основное это понятно,
это запуск отдельных программ, которые не мешают, но с точки зрения распараллеливания
они уже становятся неудобными. Потому что если у вас под задачи не являются полностью независимыми
друг от друга, то между ними нужно как-то организовывать взаимодействие. И есть разные
способы межпроцессного взаимодействия, разделяемая память, пайпы и все остальное. Но опять же,
это лишние затраты, как с точки зрения труда-пограммиста, особенно по части отладки,
потому что отлаживать и бажить межпроцессное взаимодействие – это удовольствие неисприятных.
Во-вторых, все это взаимодействие обычно еще требует участия ядра, и это уже дополнительно
к вам не расходит. В то же время трэды работают, поскольку в едином адресном пространстве вы можете
творить все что угодно. Это происходит достаточно дешево, но, опять же, это не дается совсем
бесплатно. И если какой-нибудь хотя бы один тред в рамках процесса сделает что-нибудь нехорошее,
попытается разыменовать, например, нулевой указатель, что у нас произойдет? У нас грохнется
просто весь процесс телекон. Как этот механизм работает? Что значит процесс грохнется,
когда попытается разыменовать нулевой указатель? Знаете, что ядро пошлет ему сигнал нарушению
сегментации. Этот сигнал придет не конкретному процессу, не конкретному потоку, он придет
всему процессу, ну и результат предсказуем. Так, что есть общего у всех трэдов? Поскольку они
работают в рамках одного процесса, у трэдов общий process ID, parent ID, у всех трэдов общий
текущий каталог. То есть если вы напишите две функции, которые работают в разных потоках,
и какая одна из функций делает change directory, а другая функция пытается найти файл по относительному
имени, а не по абсолютному, то ничего хорошего из этого очевидно не выйдет. Файлы в дескрипторе
тоже общие, то есть вы можете открыть какой-то файл в дескриптор в одном файле, в одном трэде,
использовать в другом. Этот эффект, например, может быть использован для того, чтобы создать либо
pipe, либо socket pair, для того чтобы организовать какое-то последовательное общение данными
между разными потоками. В то же время у каждого трэда есть по аналогии с process ID свой уникальный
thread ID, это целое число, свой стэк и, как ни странно, есть еще свой отдельный стэк для обработки сигналов.
Зачем это нужно? Ну потому что к нам, когда прилетает сигнал, он обрабатывается все-таки не в каком-то
там абстрактном месте, он обрабатывается одним из трэдов. И тут уже возникают некоторые проблемы,
связанные с тем, что весь EPA UNIX-систем проектировался еще тогда, когда не было
никаких многоядерных процессоров. В частности, одна из проблем, это глобальная переменная верну,
которая хранит код ошибки последней неуспешной выполненной операции. Большинство системных
вызов позикс возвращает просто значение минус один как признак ошибки, а что именно за ошибка,
это как раз верну. Так вот, на самом деле, это никакая не глобальная переменная. Если посмотреть на
реализацию из Gleap C, что такое верно, это просто оформленный в виде переменной, чтобы без скобочек
можно было вызывать макрос, который просто вызывает некоторую внутреннюю функцию,
которая, в свою очередь, для каждого из трэдов возвращает свое уникальное значение кода ошибки.
Потому что трэды выполняются независимо друг от друга, могут дополнять какие-то системные вызовы,
и ошибки могут быть разными в разных трэдах. Как создаются потоки? Одним из двух способов. Есть
белая сторона, это позикс. Причем неважно, мак, линукс, vzd. Там API для работы с трэдами одинаковый.
Называется позикс трэдс. Поэтому называется функция, вот вы спрашивали, чтобы p означает,
это как раз слово позикс. Есть еще и темная сторона, это кое-где позикс трэдс не поддерживается,
там нужно использовать всякие функции вида createthread, подключать файл заголовочной окошки.h,
в общем, не будем это обсуждать. Винопи это вообще столько всего интересного. С одной стороны,
казалось бы, оно было логичным в 90-е годы, и можно понять логику, но сейчас можно почитать,
зайти на docs.microsoft.org и посмеяться. Про это я сейчас чуть позже скажу, сигналами там отдельнее
заморышка. Насчет позикс. Когда я показывал вам, как скомпилировать код, я сделал уговорку,
что я это компилирую на маке, и по-честному под линукс надо писать еще одну опцию. Тут есть одна
особенность, что под линукс есть API для работы с позикс, он реализован в отдельной библиотеке,
которая называется list-thread.iso, валяется где-нибудь там в slashlib, либо slashlib, еще куча там префиксов,
типа i386 там подкатал. В общем, ищется поиском в разных дистрибутивах по-разному. Это библиотека,
которая содержит все функции для работы с потоками, но и не только с потоками, а также с разными
примитивами для синхронизации, например, CYMOFOG и MUTUX. И list-thread.create это на самом деле никакой
не системный вызов, это всего лишь функция оболочка, которая вызывает системный вызов
clone с кучей разных аргументов. Вот слово clone вы уже, наверное, стучали, например, в контрольной,
в конце пришлось и местный. Тогда система вызов clone отображался, использовался как
системный вызов для создания новых процессов. На самом деле он универсальный, у него куча
параметров, можно создавать не только новые процессы, но и новые thread. Поэтому, если вы,
например, исследуете поведение вашей программы с помощью команды estrace, которая отображает список
системных вызовов, которые выполняются в вашей программе, не удивляйтесь, если вы часто будете
встречать это слово, потому что clone используется не только аналог форка, но и если у вас создаются
треды, то косвенно вызывается из функции piss.redKey. Еще одна особенность Linux, связанная с тем,
что функциональность работы с потоками реализована в user space, а не в ядре, это сигналы
реального времени. А именно, я как-то уже говорил, что в Linux константа Sigr2bin начинается с 34,
а не с 32, как в других UNIX-системах. Хотя сигналы с номерами 32 и 33, они также являются полноценными
сигналами реального времени. Из-за чего такое происходит? Потому что два сигнала реального времени
используются как раз библиотекой piss.red для внутренней координации потоков между собой,
например, для отправки запроса на стану. У нас есть библиотека в Linux, и в macOS либо в FreeBSD
эту библиотеку не нужно подключать, хотя насчет FreeBSD я уже не помню, в Mac точно не нужно.
Казалось бы под Linux, как у нас линкуется все с библиотекой. Minus L маленькая, и название библиотеки
без префиксолит, без уфикса.iso. При этом чаще используется немножко другая запись, просто
минус piss.red, это отдельный флаг специальный для компиляторов RSC и SILAN, который означает,
что в некоторых архитектурах, например, Linux, в некоторых операционных системах Linux нужно
отдельно линковать библиотеку Pozix threads, в некоторых других операционных системах, например,
macOS. Этого делать не нужно. Это некоторые опциональные параметры. Если абстрагироваться от
Pozix API и все-таки думать о том, что у нас бывает система под названием Windows, не только
Pozix системы, и под них как-то тоже хочется писать многопроточные приложения, то тут у нас есть
стандарты языков C и C++, и, например, в C++, начиная с стандарта 11 года, появился такой стандартный
класс SDS thread, который вы все знаете, там в конструктор можно передать функцию плюс параметры,
и именно в момент вызова конструктора, странная логика, конечно, но тем не менее, у вас начинает
выполняться новый thread. И эта штука работает везде одинаково на всех платформах, где гарантируется
поддержка стандарта C++ 11 и выше. Почему вы не используете всегда просто эту функциональность?
Зачем вам нужно знать какие-то там Pozix threads и все остальное? Потому что язык C++ у нас изобилует
всякими абстракциями. И что такое thread на языке C++? Это просто некоторая абстракция, чтобы удобно,
легко и просто запускать новые задачи, но при этом запускать одинаково хорошо на разных
операционных системах, и поэтому функционально это содержит только самый минимум, который
поддерживается всеми операционными системами. То есть, если используя Pozix threads, вы можете
тонко настроить, например, размер стека, размер guard page, то на плюсах вы это сделать в принципе не
можете. У вас есть только дефолтный std thread, и все, ничего тут вы не поделаете. Есть еще язык C,
и в стандарте языка C 11 года тоже появился класс, ну не класс, точнее, а модуль для работы
и стредами. И что удивительно, сейчас уже 2022 год наступил, стандарты 19 года. До сих пор в компиляторах
эта функциональность не реализована. Одной простой причине, она никому не нужна. Когда у вас есть
Pozix threads, зачем нам еще придумать какой-то новый язык? Так, и в потоках вы можете делать все
что угодно, они равнозначные, но когда у вас программа многопоточная, иногда надо думать не
только о синхронизации, но и о том, что нужно аккуратно пользоваться какими-то другими
системными вызовами, которые тоже что-то порождают. В частности, есть известная проблема, связанная
Форком. А именно, что делает Форк? Он создает копию процесса, но что именно считать копией?
Он создает копию адресного пространства, и вот когда проектировали систему Unix в 70-е годы,
опять же, не задумывались о том, что когда-нибудь появится поток. Поэтому Форк, после того как он
скопирует виртуальное адресное пространство, начинает выполнение новой задачи, одной задачи,
даже если в исходном процессе у вас было много тредов. Что при этом происходит? Мы скопировали
память всех тредов, процесс как бы находится в том же замороженном состоянии, и текущий тред,
который вызвал Форк, продолжает выполняться, но тут могут возникнуть какие проблемы. Например,
у вас могут быть какие-то мьютексы, либо семафоры, которые уже были залочены в предыдущем
процессе каким-то другим потоком, и в новом процессе они никогда не будут разблокированы,
потому что других потоков просто нет. Осталась их память и всё, но не более того.
Да, после Форка работает только один тред, который его вызвал. Какая тут ещё возможна проблема,
которая приводит к deadlock? Например, у вас могут быть какие-то пайпы, socket payers,
каналы, если говорить про язык Go, из которых вы тоже можете попытаться что-то прочитать после
Форка, но опять же никто вам не запишет, вы получите deadlock. Например, вы могли сделать пайп,
использовать пайп между двумя тредами, и соответственно после Форка, то есть в нормальной
истории использования пайпов, есть два треда, один читает, другой пишет. Вы из того треда,
который занимается чтением, сделали Форк, потом пытаетесь прочитать что-то из пайпа,
никто вам уже ничего не пишет, и вы получите deadlock. Такие ситуации могут проводить к deadlock,
и на самом деле к этим deadlock могут проводить в весьма неочевидных ситуациях, особенно когда
кодовая база у вас большая, особенно если это плюсы с кучей абстракций. Например, вы можете
вызывать какой-то метод банальный getter какого-то класса, ни о чем не подозревая, что внутри этого
класса у вас может быть попытка заблокировать какой-нибудь mutex, который был уже заблокирован.
Поэтому что можно безопасно делать после Форка? Вот самое безопасное после Форка сразу же сделать
exit. Тогда мы просто грохнем все адресное пространство, которое у нас было, забудем про все
блокировки и заменим наш процесс на какую-то другую программу. Вот, кстати, по этой причине,
да, есть разные языки программирования хорошие, Python, Golang, Dart, в конце концов, и у многих
современных языков программирования есть какой-нибудь модуль в стандартной библиотеке,
который содержит функции для работы с операционной системой почти в полном составе,
как это присмотрен стандартом POSIX. Так вот, нигде вы не найдете аналогов в ускоренных языках
программирования. Просто по одной причине, что если у вас есть какой-то runtime какого-то языка
программирования, то, скорее всего, там будет как-то задействована многопоточность под что-нибудь,
и использование Форка это опасно и чревато всякими хорошими Zlock. И вместо Форка обычно есть
что-нибудь типа запустить новую программу с кучей параметров по Windows. И, кстати, не только
другим языкам программирования, но и к разным фреймворкам на C и на plus. Теперь немножко про
сигналы. Вот, как я уже говорил, у каждого трэда есть свой стэк для обработки сигналов. И что у нас
происходит, когда прилетает сигнал? У каждого процесса есть маска сигналов, ожидающих доставки,
у каждого процесса, но не у трэда. В то же время есть еще такое понятие, как маска сигналов,
то есть, фактически, это некоторый фильтр, который блокирует доставку определенных сигналов,
которые нам могут послать. Так вот, в отличие от маски сигналов, ожидающих доставки, маски
сигналов, которые выполняют роль фильтрации, они могут быть разными у разных трэда. И что происходит,
когда к нам прилетает какой-то сигнал, который никакой маской не перехвачен? Этот сигнал
начинает обрабатываться в этом процессе и в каком-то из трэдах. А вот кому повезло,
кто-то начал его выполнять. То есть, как у нас работает обработка сигналов на низком уровне?
Планирующий к заданию выбирает очередной процесс. Внутри процесса есть какой-нибудь текущий поток,
который нужно выбрать. Он его выбирает, дальше смотрит на маску сигналов, ожидающие доставки.
Если у нас есть сигналы не обработанные, то в том же трэде, который планирующий к заданию выбрал,
начинается обработка доработчика сигналов. В общем случае, в каком из трэдов у вас будет
выполняться, это не предсказуемо. Тем не менее, вы на каждый трэд можете навешивать свою маску
сигналов, и это бывает полезно для того, чтобы, например, в своем приложении с огромной логикой
разрушить, выделить просто отдельный трэд, который будет заниматься только обработкой сигналов и
больше ничем. Как это сделать? На все трэды навешивать маски сигналов, которые все блокируют,
на один из трэдов навесить маску, которая разрешает и ставку сигналов. До этого трэда
все равно будет доходить исполнение, и поскольку он единственный, кто может принимать сигналы,
то он и будет обрабатывать все сигналы. Не будет мешать при этом другим трэдам.
Вот трэды у нас можно запустить. В какой-то момент трэды заканчиваются, могут выполнять
какие-то побочные действия, хулиганить, мешать друг другу. И по-хорошему вообще любой запущенный
трэд самостоятельно должен завершиться. То есть нужно предусмотреть в своей многопоточенной
программе какой-то легальный способ, чтобы дать трэду это возможное. Что будет, если все-таки нам
нужно принудительно прибить какой-то трэд, который уже выполняется. Например, сделать аналог кил.
Системный вызов кил или команда кил, она прибивает процесс целиком. И процесс, например, который стал
всем мешать, он больше никому не мешает. Что-то похожее есть и у трэдов. Вы можете не всегда,
конечно, достаточно часто остановить трэд, хотя это плохо. Но представьте себе, что у вас есть
многоядерный процессор. И одно ядро процессора начинает тупо выполнять инструкции, джамп,
что-нибудь. Все. Как вы можете его остановить? Можно ли это сделать?
Но только выполнить какое-то прерывание. Поэтому ситуация с остановкой какой-то произвольного
трэда, она вообще говоря не гарантирует, что как только вы нажавали на красную кнопку,
трэд тут же завершится. Трэды могут завершаться в одном из двух случаях. Я имею ввиду, что завершаться
не добровольно. Либо они наступили на какую-то точку под названием точка останова. Вот если
открыть седьмой раздел Man в Linux, в Mac его кажется нет, то который описывает всю технологию связанную
с Pozix Threads. Тут есть интересный список функций. Фактически это почти все системные вызовы,
которые называются cancellation points. Как у нас вообще работает cancellation points? Фактически у нас какой-то
поток начинает выполнять какой-нибудь системный вызов. И первым делом, что происходит, проверяется,
нужно ли вообще дальше этот поток выполнять или нет. И если не нужно выполнять, поток тут завершает
свою работу. Может быть ситуация, когда поток просто что-то делает и никогда не вызывает
системный вызов. Это более сложная ситуация. Тут поток остановить уже сложнее. То есть мы не
можем другому ядру процессора просто приказать перестать выполнять этот поток. Здесь можно
прервать только сигналом, поскольку у нас есть аппаратное прервание по таймеру, которое периодически
получает процессор. И соответственно перед тем, как продолжить выполнение, нужно проверить,
а действительно нужно выполнять. Фактически у нас механизм сигналов так работает. И второй
способ как раз позволяет, хотя опять же не мгновенно, все-таки поток остановить. То есть,
если вы хотите остановить поток, есть два способа. Способ по умолчанию. Это дать возможность потоку
остановиться на некоторый cancellation point. Либо, если поток разрешил, да, есть два системных вызова.
Один указывает, можно ли поток завершать или нельзя. Второй, каким образом это работает либо
через точки останова, либо принудительно по умолчанию работать через точки останова. Все-таки это
можно сделать для того, чтобы иметь возможность, например, отменить какую-то длительную операцию.
Открывайте фотошоп и файлы на 4 гигабайта. Что у вас происходит? Открытие. Вы можете
комментировать cancel, если вам надоело ждать. Хотя лучше это сделать совершенно по-другому.
Да, cancel это принудительная остановка. Лучше это делать все-таки непринудительно. Например,
иметь какой-то boolean flag, который из вашего потока отдельного, этот флаг, например, проверяется.
Почему очень плохо принудительно завершать работу какого-то потока? Потому что у вас могут
остаться какие-то не освобожденные ресурсы. И это может быть не только утечки памяти.
Более страшно, что при многопоточном программировании вы наверняка будете
активно использовать какие-то объекты синхронизации, мьютексы и симмофоры.
И если утечка памяти хорошо имеет свойство накапливаться, хорошо расходовать память,
тем более что курс доллара у нас резко подскочил и оперативка подорожала. С мьютексами и
симмофорами тут еще сложнее. Потому что если вы не освободите ресурс, связанный с блокировкой
какого-то участка памяти, то вы можете застопорить все остальные треки. И первое правило, надо забыть
про принудительную остановку. Это крайне аварийный случай. Но все-таки, если вам приходится к нему
прибегать, можно зарегистрировать в каждом треде обработчик, функция обработчик, который будет
выполняться при остановке треда и, например, принудительно освобождать все ресурсы,
разблокировать все мьютексы, закрывать ненужные файловые дескрипторы, ну и так далее.
Так, что еще надо знать про многопоточные программиеры? У нас бывают всякие разные
функции, которые могут быть thread-safe, то есть потока безопасными, могут быть функции async
signal-safe, это функции, которые можно использовать в обработчиках сигналов. И вообще говоря,
эти два класса функций у нас не совпадают. Классический пример. Функция print, put, scan и так
далее. То есть функции, которые взаимодействуют с какими-то глобальными объектами, например,
буфер водо-вывода, ну стандартно водо-вывода, sdout, sdv и sdv. Какие здесь возможные проблемы?
Функции форматного ввода, вообще стандартные функции водо-вывода в CE, они являются потока
безопасными. Почему они сделаны в thread-safe без всякой реализации дополнительной? Ну потому,
что было очень много кода написано на старом Lego CC, и когда начали портировать на многопоточное
окружение, то в самый простой способ. Почему в thread-safe функции не являются функциями,
которые можно использовать в обработчиках сигналов? Потому, что они активно используют
объекты блокировки для того, чтобы не было гонки данных за разделяемые ресурсы. А все-таки обработка
сигналов у нас происходит не в отдельном потоке. И это чревато тем, что вы можете просто налететь
на какой-нибудь deadlock из обработчика сигнала, если будете использовать thread-safe функции. Хотя
чисто некоторые thread-safe функции, которые, например, просто не используют по глобальным
состояниям и не приводят к проблеме гонки данных, их использовать из обработчиков сигнала можно
вполне спокойно. Если сигнала безопасная, то тоже не факт. Хотя в большинстве случаев,
асинхроны сигнала безопасные, они обычно являются потока безопасными, но я навряд ли сейчас
смогу это доказать. Скорее просто я не смогу вспомнить примеров, когда бы это было не так.
То есть системные вызовы, они как правило являются не только асинхронно безопасными,
но и потоком безопасными. И вот есть еще некоторый способ локализовать какие-то глобальные
переменные. Это ключевые слова thread-local C++ и C, просто некоторые дополнительные
модификаторы перед именем переменной, которые фактически превращают какие-то глобальные
переменные в локальные, но которые локальные с точки зрения потока. То есть они существуют
по одному экземпляру на каждый thread, хотя обращаться к ним можно из любого места программы. Просто
некоторые другие удобные способы обращения. Но где реальной жизни в проде такое используется,
опять же, я практически не встречал. Так, и вот тут мы уже начинаем вспоминать эту проблему,
что у нас есть огромное количество старого нетрадсейв кода, который нужно как-то портировать
хотя бы левой ногой для возможности выполнения на многопоточных системах. И почему вообще
эта проблема возникла? Потому что, вообще говоря, самый первый процессор, который начал массово
распространяться и при этом содержал больше одного ядра, появился только в 2006 году. На самом деле,
до этого были многопроцессорные системы. Они появились давно, если говорить про
микропроцессорные системы, но это еще в 80-е годы. Только они стоили жутко дорого,
были очень узкоспециализированными и мало распространенными. И поэтому даже
многозадачные системы, которые существовали в 90-е годы, в начале бытовых, они фактически
использовали только один процессор, только одно ядро. И жесткой проблемы того, что у нас могут
возникать какие-то блокировки, ее просто нет. Даже если они были, они были настолько маловероятными,
просто потому что у вас некому конкурировать за какие-то ресурсы. Процессор один, у вас, да,
много процессов. Внутри процессов можно создавать многопотоков, но все они все-таки выполнялись
последним. Более того, даже когда появились двухпроцессорные, ну, двухядерные процессоры,
то некоторый софт просто начал работать глючно, потому что он никогда до этого не тестировался в
реальной поточной среде. Так вот, в 2006 году появляется массовый процессор Intel Core Duo. Все,
везде все стало многоядерным, многопроцессорным, а в то же время код, который нормально
проектировался под параллельное выполнение и реально был протестирован, его фактически отсутствовал,
и много где ставили заплатки. Какую заплатку вы можете поставить, чтобы программа, которая была
написана без поддержки многопоточности, вдруг стала безопасной для многопоточного исполнения.
Ну, поднаставить везде мьютоксов и все. Вот так много где сделали, в том числе в стандартном
себе библиотеке. Так, ну и к чему это привело? Ну, классическая проблема — язык Python, в котором
есть такое понятие, как Global Interpreter Log. Откуда эта проблема вообще растет? Проблема корнями растет
оттуда, что интерпретатор Python изначально проектировался не для многопроцессованного
выполнения. Потом уже в нем появилась функциональность для поддержки многопоточности,
но тем не менее у нас, да, что такое многопоточность в Python? Она там очень честная, то есть,
действительно, когда вы создаете новый thread в Python, у вас честно создается новый stack,
у вас честно создается новый thread ID, в общем, обычный перестраит create, который действительно
отдельно выполняется на отдельном виде процессора, как отдельная задача, как все легально. В чем проблема?
В том, что у нас есть ровно один экземпляр интерпретатора, который интерпретирует bytecode
Python. То есть Python у нас сначала текст преобразует bytecode, хранит его в памяти, кэширует,
потом вот bytecode выполняет. Так вот, интерпретатор существует ровно в одном экземпляре, у него
единое глобальное состояние. И сколько у нас одновременно может выполняться тогда потоков?
Естественно, одно. Один поток выполняется, выполняется только одна программа, даже несмотря на то,
что порождено много остальных трэдов. Все остальные трэды просто тупо висят на Utex и ждут,
пока Utex разблокируется, они смогут выполняться. И фактически многопоточная программа на Python
превращается в однопоточный. На самом деле, здесь есть некоторые исключения, когда можно
освободить Global Interpreter Log. Как правило, это что-то, что реализовано внутри сишных модулей на Python,
либо на длительных операциях ввода-вывода. То есть есть небольшие оптимизации, что, например,
когда вы читаете какие-то данные из файла и это длительный блокирующий ввод-вывод, то временно
освобождается блокировка интерпретатора, но опять же это единичный случай. В целом, Python нельзя
назвать многопоточным языком программируемого. Модуль Multi-Processing там существует скорее для того,
чтобы учить студентов и школьников многопоточного программирования, не более того. Если вам
действительно нужна параллельная обработка данных по Python, то есть похожий по программу
интерфейс-модуль, который называется Multi-Processing, который честно форкает кучу новых процессов,
организует межпроцессные взаимодействия, хотя делается, конечно, на Python. Тем не менее,
хоть как-то оно запускается параллельно. Еще один известный программный продукт, который тоже
исходно проектировался без поддержки многопоточности. Потом его все-таки запихали
многопоточность. Это, как ни странно, ядро операционной системы. Причем не только Linux,
многие операционные системы тут пострадали. Зачем вообще ядру многопоточность? Во-первых,
вы можете внутри ядра отдельные подсистемы, особенно медленные, которые работают с медленными
устройствами, выносить в обработку отдельными потоками. Вторая задача, зачем может потребоваться
многопоточность внутри ядра, потому что у вас выполняются разные процессы, в результате процессов
разные пользовательские потоки, и одновременно разным процессом может потребоваться системный
вызов. Но процессы должны ждать, пока с ядром пообщается другой процесс. Зачем? Тоже можно
сделать многопоточную обработку. И есть такая проблема, как большая блокировка ядра.
В Genk.rln.ru еще иногда встречается тема Object-BigKernelLog. Очень страшная штука, потому что если у вас
процессор одноядерный, то ладно, это не страшно, если у вас хотя бы два ядра, это сильная просадка
производительства. В опенсорсных системах FreeBSD и Linux эту проблему решили еще 10 лет назад. Откуда
вообще корни проблемой Genk.rln.ru появляются? Корни проблемы, как правило, лежат в каком-нибудь
не очень качестве на написанном коде, который изобиливают использованием глобальных переменных,
статических переменных и так далее. В основном это были всякие драйверы старинных, уже может быть
даже неподдерживаемых устройств. То есть частично эти проблемы были решены переписыванием, частично
выкидыванием лишнего. Тем не менее в Linux и FreeBSD этой проблемы уже нет. Насчет MacOS не знаю. Этой
информации я не нашел нигде в открытой доступе. Самое последнее упоминание про какие-то проблемы
с глобальной блокировкой ядра относится к OS Tiger 10.4. Ну это достаточно старое уже ядро. Возможно
просто Apple старается про это не рассказывать, если какие-то проблемы действительно есть.
На самом деле непонятно зачем, учитывая, что если в open-source 2009-й год, казалось FreeBSD уже все
решили, тут же проблемы даже не только в ядре операционной системы, а в разных подсистемах,
там файловая система, еще что-нибудь. То есть если у вас есть хотя бы один модуль ядра,
который немногопоточный, то он может стать слабым местом в производительности. Захватывайте
не блокировки. И вообще говоря, если немножко вернуться в историю, то на десктопах многопроцессорные
системы уже существовали. В 90-е годы был товарищ из компании Apple, который решил свалить из
компании Apple и основал свою компанию под названием BIBOX, которая делала десктопные компьютеры с
достаточно симпатичной операционной системой под названием BIOS. В чем особенности компов? Это
были фактически первые доступные десктопные системы с двумя процессами, а не с одним,
как тогда это было принято. И естественно операционная система уже by design исходно
была спроектирована с прицелом на многопоточность. Но в какой-то момент ни компания BIBOX, ни
операционная система BIOS уже не стала царствием небесное. Зато у нас есть open source, в котором
много чего живет. И есть такая операционная система под названием Haiku, тоже достаточно симпатичная с точки
зрения пользовательского интерфейса, которого является дальнейшим развитием идей BIOS и даже
гарантирует совместимость со в том, этой самой BIOS хотя бы тому, он сейчас нужен,
где исходной этой проблемы не было вообще с глобальной блокировкой ядра. И более того,
если вы поставите себе виртуалку, например, операционную систему, чтобы поиграться,
залезете в список процессов, то внутри каждого процесса, не только внутри каждого процесса,
в самом ядре вы увидите огромное количество потоков, которые доступны отдельным процессам.
Так, ну и на этой радостной ноте мы видим многопоточность от бота,
бруда или от сбер. Это означает, что лекция закончилась.
