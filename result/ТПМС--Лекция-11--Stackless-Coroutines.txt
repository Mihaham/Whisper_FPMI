Приветствую всех, собравшихся в Zoom и собравшихся здесь на нашем воскресном занятии. Сегодня мы
хотим продолжить нашу историю про конкарнси, а чуть точнее историю про средство выражения
конкарнси в коде. Как именно мы в коде хотим описывать какие-то обработчики запросов,
ну или любые активности, которые чередуются друг с другом, которые соперничают за ядра процессора,
которые выполняют вот вывод, ждут каких-то таймеров, общаются друг с другом через каналы,
блокируют общий mutex и так далее. У нас было два больших механизма, один из них мы сейчас уже
почти целиком написали, это файберы, другой механизм был это фьючи, и мы этим займемся в
самом ближайшем будущем, в смысле, напишем их. Сегодня нас ждет еще один механизм,
который называется stackful-крутины. Ну и чтобы мотивировать их возникновение, давайте вспомним,
точнее даже не вспомним, посмотрим на файберы перед нами. А расширил ли я экран в Zoom?
Да, совершенно верно. Вот, теперь мы на месте. Итак, смотрим на файберы, которые мы сейчас пишем,
которые мы уже может быть написали, они умеют запускаться, они умеют синхронизироваться через
mutex и через weight-группы, они скоро научатся, у кого-то научатся, у кого-то нет, синхронизироваться
через каналы, блокироваться на селектах в ожидании сообщения одного из каналов. И мы сейчас,
на прошлой лекции, мы говорили про то, как устроен планировщик для Groot-In-Go, и у нас
появилось домашнее задание, где нужно написать для вот этих файберов хороший планировщик,
который шардирован, в котором мало синхронизации, мало коммуникации между ядрами, где каждый
ядро, каждый поток worker на своем ядре по умолчанию старается работать со своей локальной очередью.
За счет этого у нас получается физически гораздо больше параллелизма, ну и файберы
исполняются эффективно, потому что файберы – короткие задачи, им хороший планировщик
необходим, а обычного предпола недостаточно. Но это долгая история, мы в прошлый раз про нее
поговорили, а сейчас смотрим именно на файберы с их примитивами синхронизации и думаем, на чем
вся эта конструкция вообще держится. Ну вот эти файберы, они в конце концов где-то исполняются,
исполняются они в некотором планировщике, как было сказано. Этот планировщик – это threadpool,
но сами файберы про threadpool ничего не знают, про конкретный threadpool ничего не знают, да и вообще
наверное про threadpool, потому что они умеют запускаться в произвольном экзекутере.
Что это за экзекутер – совершенно неважно. Этот экзекутер умеет исполнять задачи.
Эти задачи, ну в новой задачи про планировщик, вот этот шаблон уже был опубликован, это
интрузивные задачи, которые реализуют интерфейс itask, умеют запускаться, ну либо отбрасываться,
потому что планировщик решил быстро остановить работу. И эти задачи, они интрузивные, то есть в них
интегрируются указатели, которые позволяют задачам связываться в какие-то структуры данных,
ну и вот просто встраиваться без лишних локаций во внутренности планировщика. Вот это про runtime,
про то, где исполняются файберы, исполняются не в виде задач. А дальше, с другой стороны,
нужно вспомнить, как устроены файберы над планировщиком, то есть как устроены все эти
мютоксы, вейт-группы, каналы, ну про каналы мы еще не знаем. В конце концов, все вот эти файберы
превращаются на уровне планировщиков задачи. И как эти задачи устроены? Ну вернее, как устроено
исполнение файбера? Он бежит, бежит, бежит, встречает какой-нибудь мютокс и пытается его
захватить. Если этот мютокс свободен, он захватывает этот файбер, его и бежит дальше. Если же мютокс
уже оказывается захвачен, то файбер должен остановиться. Он добавляет себя в очередь мютокса
и останавливается. Что значит останавливается? Ну вот мы говорили, как эту остановку реализовать.
Нам нужен примитив, который называется корутина или сопрограмма. Это такой волшебный вызов функции,
который может запуститься, а потом в середине сказать «я останавливаюсь», сказать suspend. Вот давайте
вспомним про корутина немного. Вот корутина, которая делала первый шаг, ну тут второй шаг,
но для нее первый. Говорила корутина suspend и останавливала свое выполнение. Мы запускали эту
корутину с помощью вызова резюм. Она делала первый шаг, говорила suspend. Этот suspend возвращал
управление вот этот резюм. Резюм завершался. Вот потом мы говорили второй резюм, и корутина
возобновлялась с той точки, где она остановилась ранее. Ну то есть корутина – это был такой механизм,
который позволял, который обобщал сам по себе понятие обычных функций, сопрограмма, подпрограмма,
если переводить дословно и параллельно обозначать. И мы эти сопрограммы, корутины,
использовали для реализации файберов. В нашем экзекьюторе, какой бы сложный он ни был,
задача для файберов – это задача, которая резюмит корутину файбера. И в этой корутине
исполняется какой-то код пользователя. Этот код пользователя встречает mutex. На mutex мы
добавляемся в очередь и останавливаем корутину. И шаг файбера завершается, задача завершается,
и файбер когда-нибудь будет запланирован снова, когда другой файбер достанет его, достанет что-то
из очереди, и наш файбер разбудит, то есть запланирует резюм корутины в трэдпул. Так? Это мы
все вроде понимаем. Но тут много слов, довольно сложно, хуже звучит, но к этой стадии курса,
кажется, мы уже должны это в голове аккумулировать. Теперь нужно сделать еще один шаг и подумать,
вот на чем. Что такое корутина? Ну, вернее, не что такое корутина, а как она реализована. Вот пока
может быть в нашем понимании корутина как-то связана неразрывно с понятием переключения контекста.
Когда мы говорим резюм, мы активируем некоторый контекст заранее подготовленный, где на своем
собственном стэке запускается какая-то пользовательская функция. Потом эта пользовательская
функция выполняется, встречает корутин suspend, ну и что там происходит? Там мы сохраняем текущий
контекст в поле класса, в поле корутины, и активируем контекст того кода, который корутина вызывал,
резюмил ее. Вот я сегодня предлагаю подумать, вот на чем. Что такая связь корутина и переключение
контекста? Она совершенно нефундаментальная, и понятие корутины, оно гораздо более общее и более
универсальное, чем механизм переключения контекста. Переключение контекста для корутины,
ну, корутина вполне может быть реализована без механизма переключения контекста. И мы сегодня
поговорим как раз про другой тип корутин, который этот механизм не использует. Это stackless
корутины, которые вы, наверное, видели в C++. Ну, вот смотрите, тут написано coroutines as stackless,
а наша корутина stackful. Вот в самом основании всех наших файберов лежит понятие корутины,
и вот сейчас мы хотим это понятие корутины по-другому реализовать. Это наш план на сегодня.
И разобраться, как, собственно, этот механизм работает в языке C++, потому что язык C++ вам
приносит вот эти самые stackless корутины. И это важно, что это происходит именно на уровне языка. Ну,
вот это то, к чему мы сегодня придем. Итак, давайте подумаем, в чем разница stackful, разберемся,
в чем разница stackful корутины stackless корутины. Разница очень простая. Вот посмотрим на пример,
например, с итератором, который у нас был. У нас было дерево, у нас был итератор по дереву,
мы говорили move to next, и этот итератор двигался по узлам. Мы тогда, когда это обсуждали, говорили,
что удобно итерироваться по дереву рекурсивно, но, правда, тогда не напишешь линейный итератор.
Как же написать линейный итератор, который бы внутри был реализован как рекурсивная функция? Ну,
видимо, нужно воспользоваться корутинами. Видимо, нужно запустить рекурсивную функцию, а когда мы
хотим, когда мы доходим до очередного узла, просто корутину остановить, вызвать здесь коротень
саспенд, выпрыгнуть, и вот здесь мы будем, мы, получается, встали в рекурсии в новый узел
дерева, и нужно вернуть пользователю данные из этого узла. Вот stackful корутины — это корутина,
которая... Этот пример иллюстрирует stackfulness корутины. Ну, давайте сразу сделаю замечание.
Stackful корутины и stackless корутины не означают, что у корутины есть stack или нет stack. У любого
кода, любому коду, чтобы исполняться, нужен stack. В смысле, процессору, чтобы исполнить код,
нужен stack. Это никуда не денется. Разница в том, что как по отношению к stack вызовов ведет себя
к рутина, которая останавливается. Вот разница в этом. Stackful корутина, когда останавливается,
останавливает не только вот свой вызов, вот этот вот вызов, текущий триволк, в смысле, самый глубокий,
а останавливает все вызовы по stack выше. То есть замораживает весь stack и выпрыгивает куда-то
в колер, который снаружи вызвал резюм, где-то здесь. Stackless корутина, наоборот, когда она
останавливается, она останавливает только саму себя, то есть только самый вложенный вызов. То,
что выше по stack живет своей жизни дальше. Это, может быть, пока не очень понятно,
но чтобы это почувствовать, нужно разобраться в механике корутина, stackless корутина. И как можно
было бы поступить? Можно было бы взять stackless корутина C++ и разбираться, как они устроены. Мы
к этому придем, но начнем мы совершенно с другого. Мы попробуем сами реализовать stackless корутины,
просто руками их написать. Я объясню, почему это не самая очевидная вещь, но чуть позже, наверное.
Вот смотрите, давайте рассмотрим такой абстрактный пример. У нас есть функция foo, у нас есть
функция bar, у нас есть функция baz, и у нас есть некоторая корутина. Функция, которая принимает
аргумент, вызывает функцию foo, потом останавливается, потом вызывает функцию bar от результата функции foo,
вызова функции foo, потом снова останавливается, потом вызывает функцию baz, куда передает
вычисленные ранее a, b и аргумент x, потом вводит получившийся на экран. Оно закомментировано,
потому что это некоторые псевдокод. Это наше намерение. Мы хотим в языке нашем, в программе
C++ выразить такую корутину. Что мы можем сделать? Ну, мы можем воспользоваться stackful корутинами,
которые у нас уже есть, которые мы с вами писали. Вот мы пишем там вызов foo, потом мы останавливаем
корутины, потом вызов bar, потом останавливаем корутины, потом вызов baz, печатаем на экран. И
вот мы запускаем этот код, и он делает три шага, разумеется, и выводит ответ. Ну, я не стану проверять,
наверное, он правильный. Вот мы такую корутину выразились помощью stackful реализации. Как она
устроена, мы тоже хорошо знаем. Там переключение контекста, локация и стэков, вся эта история.
А теперь мы хотим написать альтернативную реализацию корутины, альтернативную реализацию,
которая была бы stackless. Причем эта реализация, которую мы сейчас напишем,
она будет реализацией конкретно этой корутины. Вот наш класс stackful корутин или просто корутин,
это был такой универсальный класс, в котором мы передавали лямбду, и эта лямбда работала
как корутина. Сейчас мы хотим написать корутину прям голыми руками и конкретно эту. Но, возможно,
мы сможем сделать это эффективнее. Вот давайте подумаем, как выглядела бы реализация идеальная,
вот конкретно этой корутины. Она получится не общей, очень конкретной, но вот конкретно для
этой корутины можно было написать этот класс. Ну, прямо так, да, но это уж прям совсем конкретно,
нужно чуть более общую схему наметить. Итак, нам нужен вызов резюм, и этот вызов резюм запускает
очередной шаг, потом корутина доходит до точки остановки и останавливается. Давайте подумаем,
как выглядит, как можно описать наиболее компактно состояние вот такой вот остановленной корутины,
вот конкретно этой корутины, как можно было писать ее состояние.
Ну, у нас есть локальные переменные, они потом используются, видимо, состояние остановленной
корутины, это состояние локальных переменных, там A, B, C. A, B, C это локальные переменные,
ну, соптимизировал бы у меня, возможно, сейчас к этому придем. У нас еще есть аргумент,
который тоже нужно запоминать, чтобы потом функцию bus вызвать, ну, и видимо, в вызове резюм нужно
помнить, какой шаг мы сейчас выполняем. Итого, у нас состояние такой корутины, чем образовано? Во-первых,
это локальные переменные, ну ладно, в нулевых это аргументы, во-первых, это локальные переменные,
и во-вторых, это, ну, напишем так, instruction pointer. Ну, instruction pointer тут, конечно, не буквально
нужно понимать, а вот некоторые абстакты, instruction pointer, который указывает на номер
очередного шага. Вот давайте мы такую корутину сейчас и напишем. У нее есть аргументы,
у нее есть локальные переменные, и у нее есть instruction pointer, который будет выглядеть
несколько проще, просто вот так. Ассоциация корутины строится, она получает аргумент,
давайте мы его запомним в поле. А дальше мы хотим эту корутину утерировать в резюм. Ну,
и что мы здесь напишем? Посмотрим, какой шаг нам сейчас нужно сделать. Если это нулевой шаг,
первый шаг логически, мы вызовем функцию foo, а потом мы должны остановиться. Как мы остановимся?
Просто return напишем. Это и есть наш suspend. Да, ну нужно, чтобы в следующем резюме мы
продолжили работать с правильного места, поэтому перед тем, как мы остановимся, мы
продвинем label вперед. А дальше, если нас запустили второй раз, то мы проверим, что,
если label теперь единица, то мы вызовем, видимо, вызов bar, сделаем вызов bar,
снова продвинем label и остановимся. Ну, и наконец, мы здесь вызовем bus от a, b, x,
ну вот, похоже на корутину, да? И можно теперь ее запустить и посмотреть, что результат не
поменялся. Ну, если мы нигде не ошиблись, разумеется. Не поменялся. Ну вот, мы написали ту же самую
корутину по-другому. Беда в том, что класс этот переиспользовать нельзя, он какой-то очень
конкретный, но зато, кажется, он реализован оптимально. Правда? Вот, и это реализация,
это stackless реализация, вот такой вот корутина. А теперь нужно увидеть некоторую общую
конструкцию. Как может быть реализована корутина, которая, останавливаясь, останавливает только себя?
Ну, она, эта корутина, этот вызов функции, он теперь имеет некоторое состояние в
установленном виде. Это состояние мы описываем в виде класса. Вот, для нашей корутины нужен state.
Что в этом state будет? Будут аргументы, будут локальные переменные. Ну вот, кстати, локальные
перемены здесь можно было бы и немного сэкономить, потому что зачем делать с полем класса, можно же
просто оставить буквально локальный перемен, потому что между разными шагами она не используется.
И нужен такой instruction pointer в виде просто лейбла, который указывает, вот какой шаг сейчас происходит.
Ну, если у нас есть цикл этот лейбл, он, конечно, немного сложнее меняется, но не суть.
Вот, в общем виде реализация stackless корутины. CarRoutingState, у которого есть в полях аргументы,
локальные переменные и лейбл. Проблема пока в том, что мы сгенерировали такой класс руками. Вот у нас
такая крафтовая корутина получилась конкретно для вот этого примера. Каждый раз писать мы,
наверное, так не хотим, но с другой стороны, вот преобразование из этого условного псевдокода,
из этого не существующего в C++ синтаксе со спендами, в такой класс преобразование может выполнить,
скажем, сам компедиатор абсолютно механически. Вот в этом идее, в том, чтобы научить компедиатор
преобразовывать специально описанные функции с некоторыми специальными маркерами, которые указывают
компедиатору, что это необычная функция корутина, вот такой вот класс, который дальше можно было бы
запускать и который бы мог в своем вызове остановиться. Я бы сказал, что, во-первых, шаблоны
это отдельная история, не нужно ее сюда привязывать, это скорее похоже на лямбды,
потому что у нас есть на поверхности языка вот эти самые анонимные функции, а компедиатор
просто их переписывает на функции, тоже на классы. Ну вот здесь мы берем какую-то функцию специальную и
переписываем ее в виде класса. Ну пока вручную, а хотели бы делегировать это компедиатором. Вот.
Реализация получается всегда такой и простой, потому что нам не нужно думать о том, что будет
с вызовами выше по стеку. Нас всегда беспокоит только конкретный наш вызов. Один и единственный.
Итак, с этим разбрались, да? Этот пример понятен. Что происходит, тоже понятно. Но единственное,
что нужно сделать, это указать компедиатору каким-то образом, где именно корутина будет
останавливаться, чтобы он мог вот разбить ее тело на вот такие фрагменты. Но, прямо скажем, вот
корутины с таким интерфейсом нам не особенно полезны. Кажется, что мы в курсе не особенно
занимались тем, что корутины итерировали вот резюмами. Ну то есть как? Мы в конце концов это
делали где-то в недрах наших файберов. Но вообще-то файберы, вообще-то для конкуренции, а нам все-таки
корутины нужны не абстрактно, а для конкуренции. Нам нужен был немного, нам нужна была немного
другая логика. Вот допустим, давайте посмотрим на какой-нибудь пример и посмотрим на пример сейчас.
Например, в файберах. Ну вот, мы файберы, мы отправляем сообщение в канал, мы получаем сообщение из
канала. Вот здесь мы блокируемся. Вот когда мы говорим про файберы и мы понимаем, что за ними
стоят корутины, нас, как правило, не интересуют отдельные резюмы. Нас интересует такая логика. Мы
хотим остановиться и запланировать свое возобновление. Иначе говоря, мы хотим чего-то дождаться. Вот дождаться
каким образом? Остановившись и запланировав возобновление. Когда мы встречаем ресив на канале,
или когда мы встречаем, ну, например, вейт на вейт-группе. Вот пусть вейт на вейт-группе. Мы хотим
остановиться и так, чтобы нас потом разбудили, когда счетчик вейт-группы опустится до нуля. Дождаться
некоторого события мы хотим. Или, скажем, мы хотим заблокироваться до тех пор, когда пока не
выполнится фьюча с тайм-аутом. У нас есть фьюча Void. Она наполняется Void, когда проходит тайм-аут
250 миллисекунд. И мы хотим заблокировать файбер на 250 миллисекунд. Дождаться, пока во фьюче
появится значение. Остановиться и подписаться на нее. Опять. Некоторое событие. Вот мы хотим сейчас
для наших stackless корутин такую же логику. Мы не хотим для них вот этот ручной резьюм делать. Мы
хотим, чтобы эти корутины могли запускаться и останавливаться, дожидаясь некоторого события.
Иначе, говорю, мы хотим на них конкарнции писать. Вот давайте я покажу пример, чего мы хотим. Вот мы
запускаем корутины. Вот у них есть свои собственные... Ну, смотрите. Тут префикс гор – это горрутины.
Давайте я поясню, что имею в виду. Это уже не корутины. Ну, это корутины C++. Но мы их здесь называем,
пожалуйста, это шутка. Горрутины, потому что корутины C++, вот stackless корутины, принес горнешанов.
Он, кажется, то ли на аватарке, то ли на... На аватарке то ли канала, то ли чата. Канала. Вот этот
человек, который драйвил, проповзал stackless корутин C++. Вот этот самый дизайн, который мы
сегодня изучаем. Вот это его работа. И мы в честь него, значит, говорим про горрутины. То есть это
такие корутины, которые используются в конкарнсе. Для конкарнсии. Они конкурируют между собой. Мы их
запускаем. И они борются за мьютексы. Они лочат мьютексы, блокируют друг друга. Ну, блокируют, в смысле,
останавливают друг друга. А другие корутины, горрутины продолжают исполняться. Вот код похож на
файберы. Только у нас здесь написано ключевое слово coawait.mutex.log. Вот это тот синтаксис,
который мы на самом деле хотим вместо suspend. Нам suspend не нужен. Нам нужен await. Остановить
корутину до тех пор, пока не реализуется некоторое событие. Пока не освободится мьютекс. Понятен
замысел? Вот. Так что на самом деле мы хотим, чтобы компилятор переписывал... Тут нужно прыгать
между репозиториями. Простите. Чтобы компилятор не такие функции переписывал. Вот в такие классы.
А чтобы он переписывал вот такие функции. Вот у нас была функция корутина. Она получила
аргументом threadpool. Она в своем теле вызвала функцию asyncvia. Asyncvia — это очень простая
функция. Она взяла threadpool, взяла лямбду. Построила promise и future и бросила в threadpool задачу,
где запустила вот это вычисление, а потом его результат положила в promise. А пользователь отдала
future. Понятно? Ну то есть мы запускаем функции asyncvia, асинхронное вычисление в threadpool и
отдаем пользователю future. А пользователь — это корутина. И вот она хочет этой future дождаться с
помощью coawate. И распаковать эту future, этот future int, просто в int. Давайте я опять пример покажу.
Кажется, он у меня под боком должен… Ну это future get, только future get блокирует поток. Сейчас,
где я нахожусь? Да, вот. Future get блокирует поток, а мы не хотим блокировать поток. Мы хотим остановить
текущую корутину. Вот это причина, по которой корутина на самом деле хочет остановиться. Она
хочет дождаться события. Вот этот пример. coawate future. Вот у нас есть future int. Мы можем, конечно,
вызвать здесь get и заблокироваться, но мы не хотим. Мы хотим написать coawate future. И вот этот
coawate остановит текущую корутину, только ее, не заблокировав поток. А когда future реализуется,
когда там появится значение, то корутина возобновит свое исполнение. Вот мы хотим,
чтобы компилятор переписывал для нас в некоторые автоматы вот такой вот код. Ну и давайте теперь
снова поработаем за компилятором. Посмотрите, ну, смотрите, как устроена наша лекция. Мы не просто…
Я бы мог рассказать, как… я бы мог рассказать, как… какой код напишет здесь компилятор. Но этот код
мы не видим. Все-таки он где-то в недрах компилятора написан, он сложный. Поэтому мы сейчас сделаем
следующее. Мы вернемся к нашим примерам и сами вручную попробуем поработать за компилятор и
переписать вот эту функцию в автомат голыми руками. Опять как мы сделали здесь, но только уже для кода
с фьючами. Ну, давайте думать, что тут должно быть. Опять, когда корутина переписывается,
стеклос корутина переписывается в автомат, нужно запомнить в полях этого автомата аргумент и
локальные перемены. Но аргумент тут, в данном случае, трэдпул.
Итак, что сделать корутина на первом своем шаге?
Ну, она вызывает функцию AsyncVIA. Да, у нас немного пробилось форматирование. Ну,
pull это теперь не аргумент, это локальные перемены, это поле класса. Мы получили фьючу. Давайте
вот так напишем. У нас было значение V, которое мы хотим в конце концов вычислить, а у нас пока есть
просто будущее значение в фьюче. Что нам с ним дальше делать? Ну, что значит дождаться?
А? Мы хотим дождаться этой фьючи. Но смысл корутины в том, что вот когда мы дожидаемся чего-то,
мы останавливаем только корутину. Так вот, вопрос, что мне делать дальше? Вот я в прошлом
примере, ну, у меня просто корутина останавливалась, потом она возобновлялась снаружи.
Пользователь ему так вот, безусловно, руками. А теперь мы хотим, чтобы резюмка
корутины был вызван автоматически, когда во фьюче появится значение. Ну, вот std фьюча,
она не умеет, она здесь ничего не поможет, а вот наш фьюч, хороший, который мы все еще не написали,
но вот займемся этим скоро-скоро-скоро, она умеет subscribe. То есть, мы можем подвесить на нее callback,
который будет вызван, когда во фьюче появится значение. То есть, когда в трэдпуле закончится
вычисление. Поэтому, что сделаем? Что мы сделаем? Мы скажем, что вот where future subscribe и тогда мы
передаем callback, который получает result. Result это контейнер, который содержит либо значение типа
t, либо int, либо ошибку. И что же мы напишем в этом subscribe? Что мы напишем в callback,
который будет вызван, когда в трэдпуле закончится вычисление. Ну, мы должны, видимо,
зарезюмить корутину, да, вот себя просто. И будет вызван снова этот, будет вызов продолжен,
но мы должны к нему подготовиться. Видимо, мы хотим уже сейчас обновить лейбл, да. Вот у нас
первый шаг корутины, вот второй шаг корутины. И если мы, ну, subscribe, он же подписывается на
фьючу, а вычисление может быть вызвано, может быть, может завершиться очень быстро, поэтому
резюм может случиться очень быстро. Поэтому мы должны уже к этому моменту подготовить лейбл.
Вот. Ну и после этого можно будет написать return. Только нужно после этого самого резюма как-то
вот здесь получить значение. Как нам это сделать? Ну, видимо, нужно завести, ну, это в конце концов
локальная переменная, да, локальная переменная должна стать полем класса, поэтому мы пишем здесь
v и перед возобновлением распаковываем результат. Ну, вообще говоря, там ошибка может быть,
если на исключение игнорирую, ошибки игнорирую, считаю, что все хорошо. Не делайте так, ну, для
наших целей подойдет. Ну что, а теперь можно вывести результат, да, наверное. Если мы нигде не
ошиблись, то все должно работать. Ну, давайте проверим, что она работает. Вот. И к рутину нужно,
ну, мы не будем ее резюмить, скорее, это операция start более уместно, которая делает резюм. И мы
к рутину стартуем. Работает, да? Ну, давайте убедимся, что точно работает. Вот, код должен
повисеть три секунды сейчас. Вот, никакого блокирующего ожидания в этом коде нет. Видно,
да? Вопрос, где выполнится первый шаг к рутине? Ну, здесь, да? Внутри вызова start. А где вызовется
второй шаг к рутине? Выполнится второй шаг к рутине, вот этот вот. Он в thread pool выполнится,
потому что в thread pool мы запустим вычисления, в thread pool эта задача добежит, выполнит фьючу,
у фьюча вызовется callback, а в этом callback к рутине продолжится. Ну, вообще-то, это должно
подплакнуть к такому выводу, что вот этот код, возможно, не очень хорош. Ну, точнее, мы к рутину
все еще не дописали. Но у меня код собран с адрес санитайзера, мы получили stack user
scope. Почему? Потому что вот мы сделали здесь первый шаг, подписались на фьючу, вышли из этого вызова,
а потом, ну, случилось понятно что. К рутине разрушилась, а потом в thread pool выполнилась
задача, она нас зарезюмила, а зарезюмить, ну, записала в поле, а писать в поле уже нельзя,
потому что никакого поля нет, потому что объекта уже давно нет. Поэтому мы пишем здесь что. Да,
нам нужно прибрать за собой, вот мы где-то, да, и вот, видимо, этот код мы забываем и говорим следующее.
Вот это уже более разумно, и сейчас код должен работать, и память не должна не карабтиться,
не утекать. Ну вот, мы говорим про крутины, не просто про крутины, которые запускаются и
ничего полезного не делают, мы говорим про крутины, которые работают с синхронностью,
которые останавливаются, потому что они чего-то ждут. И в этом случае время жизни таких крутин
становится динамическим. Мы не знаем сколько оно проживет, потому что мы не знаем когда закончатся
операции это синхронные там в поле потоков или когда пройдет время или что угодно. Поэтому,
естественно, что стейт крутины начинает алоцироваться в динамической памяти.
Что еще мы можем заметить любопытного здесь? Что... ну вот, зачем я вам это показываю? Потому что,
потому что, потому что вот здесь происходит нечто такое же, ну должно происходить,
потому что а что иначе здесь может еще быть написано? Вот мы пытаемся разобраться,
как устроена такая строчка. Вот кажется, что она должна быть устроена вот каким-то таким... ну то
есть эта функция должна развернуться в какой-то подобный код. Что еще тут интересного? Вот писали
ли вы файберные фьючи, файберные мютоксы? Вот, и вы там даже в слепфоре еще и в мютоксе уж точно
сталкивались с проблемой, что если вы запланируете возобновление файбера до остановки крутины,
то может получиться неприятность. Вы активируете контекст в другом потоке, который еще не сохранен,
и поэтому вам нужно было сначала аккуратно остановить крутину и только потом подписаться,
ну запланировать ее возобновление. Смотрите, у нас здесь крутина устроена проще. Suspend
stackless крутины, это просто return. Так? Вот, и нормально, если в другом потоке крутина зарезюмится,
когда в первом потоке она еще не остановилась. Потому что что такое suspend? Просто return. Что
такое resume? Просто call. Вы можете в другом потоке вызвать функцию, которая еще не завершилась в
другом потоке. Ну вот, да, нужно сначала аккуратно обновить лейбл, сохранить все нужные поля,
а потом уже не нужно волноваться, что resume может произойти до suspenda, потому что suspend
return, resume это call, слишком простые инструкции, там нечему ломаться уже. Чувствуете разницу,
да? Вот потому что, ну вот, здесь никакого переключения контекста нет, здесь просто то,
что у нас было переключением контекста, сохранением контекста, активации контекста,
теперь стало просто call и return. Но правда, как это достигается? Это достигается вот генерации
такого кода, пока вручную голыми руками. Но мы бы хотели, чтобы в конечном итоге этот код сгенерировал
для нас комперятор. Но абсолютно же невозможно, чтобы он по такой функции сгенерировал вот такой
вот код. Правда? Смотрите, он вообще-то может сгенерировать много кода здесь. То есть понятно,
что он, увидев кое вейт, поймет, что это не просто функция, это корутина, что нужно переписать ее
на автомат, что нужно для локальной переменной завести поле, что нужно для аргумента завести
поле, что нужно завести лейбл, что нужно написать resume, что нужно алоцировать, может быть,
стоит на куче, что нужно вызвать асинквиа, что он не сможет сам написать. Но он не понимает,
это же комперятор, в конце концов, откуда он знает про то, как нужно дожидаться future, откуда же он
знает, когда именно нужно резюмить корутину. Вот никакого subscriba вот в этом коде не написано.
Поэтому мы хотим, чтобы в конце концов в Core State Machine в этом классе был написан такой код,
который компилятор сам в состоянии написать. Ну, с некоторыми подсказками, но минимальными. Вот,
и это наш следующий шаг. Давайте этот код попытаемся немного иначе структурировать,
так чтобы вот в самом, в самом классе Core State Machine не было ничего специфичного именно для наших future.
Так, это тот же самый пример,
это тот же самый код, ну, почти. Беда в том, что здесь написан subscrib, про который компилятор
ничего понимать не может. Давайте подумаем, как можно избавить компилятор от знания про
это subscrib. Ну, что вообще происходит? Смотрите, у нас есть в корутине строчка, там некоторое
значение равно co-await некоторые вызов, некоторые expression. Вот у expression один тип, future от int,
у вот этого значения другой тип, просто int. И мы написали между ними co-await, то есть мы хотим
остановиться и каким-то образом возглавить корутину позже, а потом и распаковать значение. Вот эту
логику должен, эту логику, как именно это сделать, может предоставить только сам пользователь. Компилятор
про нее ничего не знает. Поэтому мы хотим, чтобы эта логика, она была как-то инкапсулирована в
некоторую стратегию, которую компилятор мог бы использовать. Эта стратегия называется avator.
Avator — это сущность, стратегия, которая говорит, как же именно нужно дожидаться некоторого значения,
как именно, имея future, дождаться из нее int. Вот давайте мы сейчас напишем класс future avator,
который инициализируется, который получает future
и помогает компилятору, ну или нам, написать тело нашей корутины.
Итак, у нас есть future. Вот мы хотим это значение v заменить на future avator.
Причем он будет ленивый инициализироваться, когда появляется future.
Вот, компилятор вызвал код, получил future, а теперь он должен как-то трансформировать ее в int,
ну дождавшись, когда там этот int появится. Компилятор не знает, как это делать, поэтому он
говорит, вот avator, разбирайся с этим, вот тебе future значение, а теперь, пожалуйста, avator запланируй
меня, когда можно будет. Кого это меня? Ну, корутину некоторую.
Вот так вот, да, но не сработало, потому что не заплатили.
Ну, avator нас возобновит здесь с помощью avatesuspend, ну, точнее, запланирует возобновление,
и нам после возобновления нужно откуда-то взять v. Откуда мы его возьмем? Ну, опять спросим у
avator, раз уж ты нас разбудил, то, пожалуйста, скажи нам, какое значение нужно взять.
То есть, вот avator получал future t, а отдает нам теперь t. Каким образом? Ну, пусть он его в поле
сохранит. Да, тут опять этот результат конструируется лениво.
А, да, простите. И здесь мы распаковываем раз,
распаковываем два. Первая звездочка это, чтобы из optional распаковать, вторая, чтобы изрезал
это значение. Распаковать. Я здесь снова благополучно игнорирую ошибки. Что?
Возможно, да. Нет. Зачем?
Ну вот. Вот мы избавили класс корутина от конкретных деталей, как именно нужно дожидаться
возобновления и откуда именно брать значение. Мы строим avator, передаем ему то, что было справа
от коэвейта. Вызываем await suspend, и этот await suspend должен запланировать возобновление корутина,
когда вот она будет готова, когда реализуется future в данном случае. И когда корутина запустится,
мы можем с помощью await resume из avator достать то значение, которое мы хотели. Сейчас оно уже
готово. Давайте проверим, что мы ничего не разломали здесь. Раз, два, три. Работает.
Ну что скажете? Ну, во-первых, только что состоялся разбор задачи fiber mutex,
потому что там нужно писать avatars, и вот avatars должны делать как раз... Ну, avatars должны быть вот
как-то так устроены. И у нас тоже был fiber handle, у нас тоже были avatars, там тоже должен быть await
suspend, который планирует возобновление. Вот это абсолютно общий механизм, который интегрируется
с корутинами stackless или корутинами stackful. Вот совершенно неважно, как именно корутина
устроена. Так что вот ожидайте, но рассчитывайте, что у вас должен быть вот этот await suspend.
Ну, await resume там пока не нужен, потому что в нашем... в mutex ничего не возвращают после пробуждения,
да. Но в общем случае await resume, наверное, нужен. Почему названия такие await suspend и await resume?
Ну, потому что этот код вызывается в точке, когда корутина останавливается, а этот код вызывается,
когда корутина возобновляется. А await, потому что включилось слово await.
Ну вот, мы написали теперь то, что на самом деле сгенерирует компилятор, вот для... сложно. Вот
для такой функции. Хороший вопрос. Откуда компилятор вообще поймет, что нужно взять... вот нужно
использовать awaiter, вот такой конкретный. Откуда возьмет этот тип? Ну, мы сейчас... то есть нужно
некоторое правило, которое позволяет компилятору по future получить future awaiter. Ну, давайте посмотрим.
Хоба. Ну, мы сейчас перемещаемся уже, мы прекращаем там на время писать корутину собственными руками и
переходим к тому, как работает корутина C++, stackless корутина C++. Вот если... если вы в своем коде
stackless корутины пишете coawait и некоторый объект, то вы должны для этого... ну, для этого типа,
в данном случае это future, реализовать оператор coawait, который возвращает awaiter. И этот awaiter,
смотрите, что... как он устроен, вот он устроен вот ровно так же. Этот код уже не игрушечный, ну не
в смысле игрушечный, и тот был не особенно игрушечный, но это уже код, который интегрирован с корутинами
C++. Когда в коде написан coawait вот такой вот, то компилятор его разворачивает. Давайте я покажу
сейчас во что. Это блок Льюиса Бейкера, еще одного из авторов корутин C++, у него есть такое очень
подробная серия постов про то, как корутины устроены. И вот второй пост про оператор coawait. Что же
компилятор вставляет вместо coawait? Ну, тут не слишком понятно. Слишком непонятно, возможно. Есть
coawait expression. Вот, по этому expression, вот по value, в котором вычисляется этот expression,
нужно каким-то образом получить awaiter. Ну, в частности, с помощью оператора coawait. Вот,
компилятор знал value, знал его тип, получил awaiter по этому типу. И что он сделал? Сначала
он спросил await ready. Await ready возвращает true, если корутина, корутине вообще не нужно ничего ждать,
если она готова запуститься сразу. Может быть, мы ждали future, она сразу готова. Ну, мы в нашем коде
говорим, что нет, будем ждать. Ну, тут тоже можно некоторую оптимизацию сделать, но мы ленивые. Так вот,
если все-таки future не готова, то есть awaiter говорит, что нет, нужно ждать, то дальше мы вызываем
await suspend до awaiter и передаем туда объект, который называется coroutine handle. Coroutine handle
зависит от того, где вы живете. Если вы живете в более-менее современном мире с современной
стандартной библиотекой компилятором, то там это уже не experimental, а у меня на маке это experimental.
Coroutine handle у него, ну, я бы сказал, что один метод, по сути, важный, но для нас сейчас это
resume. Ладно, я вру не один, конечно, и другие тоже важны, на самом деле, но вот прямо сейчас
resume. Возвновить корутину. Вот fiber handle вы уже видели в домашке, и fiber handle в домашке
ровно по мотивам вот этого дизайна. Смысл точно такой же. Мы в await suspend, в awaiter получаем
coroutine handle, и когда событие реализуется, во future появится значение, мы на этом handle скажем
resume, и корутина вот здесь прямо возобновится и продолжит бежать. Она стартует, и давайте вернемся
в псевдокод. Она стартует, и из await resume возьмет значение. Вот, это уже абсолютно честный код,
и вот этот пример, ну, давайте его запустим. Он так работает. Ну вот, спустя некоторое время
напечаталось 42. Вот, и это уже настоящий компилятор C++, вот вместе, переписал эту функцию вот так вот,
и вот awaiter у нас точно такой же получился. Вот awaiter наш ручной, для нашей ручной корутины,
и вот awaiter, который мы написали, чтобы корутина C++ работала. Вот, разницы никакой
нет, только тут coroutine handle, который прячет от нас конкретный класс корутины. Так же,
как и в нашей домашке, fiber handle прячет от нас, от пользователя конкретный класс файбера.
Ну вот, мне кажется, что вот с помощью этого примера мы разобрались, как именно работает
компилятор, когда он компилирует корутины. Вот, можно было бы по документации это изучать,
по этой документации, или еще хуже, по вот этой документации, но я не уверен, что это закончится
хорошо. Вот, а с другой стороны, если написать все голыми руками, ну, такой игрушечный пример,
но голыми руками зато, то вот вся скрытая механика становится явной. Вот этого кода,
вот этого кода нигде не увидеть, потому что этот код пишет компилятор во время компиляции. У вас
есть в языке вот такой синтаксис на поверхности языка, а дальше компилятор его переписывает вот в
такой вот класс. Вот, мы это, к сожалению, наблюдать не способны, это не часть библиотеки,
это часть компилятора, но мы способны это воспроизвести вот в таком примере.
Он выделяет память на старте корутины, когда мы ее вызываем. Ну вот мы... Смотри,
я пока немного жульничаю, я рассказываю, что происходит, когда корутина зовет коэвейт,
а есть отдельная история, что происходит, когда корутина стартует, и что происходит,
когда она завершается. Вот, и это еще одно из мерений сложности, про это вторая половина занятия.
А пока мы говорим просто про сам коэвейт. И вот коэвейт, мы, кажется, разобрали, и я обращаю
внимание, что вот эта вся трансформация, которую делает компилятор, она вот чисто механическая,
собственно, поэтому мы компилятору и доверяем ее. Он может сделать это бездумно. Во-вторых,
компилятор, когда он компилирует вот этот код, вот в такой код, ну переписывает вернее, то он же
совершенно не понимает, чем корутина занимается. Он не знает ничего про фьючее, про мютоксе, вот
в этом примере. Корутины C++ — это, внимание, фича языка. Она полностью декомпозирована
от какого-то не было конкретного применения. В смысле, от там фьюч, мютоксов, там event loop'ов
каких-то. Ну вот это просто некоторая механическая трансформация кода. Компилятор видит коэвейт и
переписывает функцию в класс. А чего именно эта корутина дожидается, каких там событий, как она
там конкурирует с другими корутинами в каком-то тредпуле — этого всего нет в языке C++. Этого
даже нет в стандартной библиотеке до сих пор, никакого готового фреймворка. И вот корутины C++ — они
интегрируются абсолютно с любым фреймворком. В частности, с нашим, который мы пишем. Почему бы
их не интегрировать туда? Там же есть тредпул, в котором корутины выполняются. Ну не корутины,
а задачи выполняются. Вот наш тредпул будет признан хорошим, если в нем можно выполнять и корутины.
Разумно звучит? Ну вот, давайте посмотрим. Давайте посмотрим на еще один пример.
А давайте сначала ASIO посмотрим. Вот ASIO. Какой-то runtime, event loop у нас есть. Вот есть его контекст.
Вот я запускаю корутину. Вот эта корутина строит таймер,
заводит его на две секунды и говорит co-await таймер. Что бы в этом месте хотели? Видимо,
чтобы корутина остановилась на две секунды. Ну для этого нужно написать оператор co-await для таймера.
Давайте его напишем. Вот, пожалуйста, контролируйте, что вы понимаете, что я пишу и что вообще
происходит. Если не понимаете, то нужно срочно спрашивать. А? Ссылка, да. Вот. Awaiter — это класс,
который реализует контракт Awaiter. Три метода. Await Ready, Await Suspend, Await Resume. Await Ready.
Что нужно вернуть? Ну, я не знаю, есть ли у таймера что-нибудь готовое?
Ну нет, не видно, да, ничего? Ну мы его здесь завели. Ну ладно, false так false. В домашке у вас
все равно будет повод написать не true здесь и не false. Что-то более нетривиальное. Нужно останавливаться.
Пишем Await Suspend. Получаем здесь CarRoutingHandle на корутину. Когда мы ее возобновим? Когда
пройдет таймер? Когда он закончится? Ну можно подписаться на него. Handle — это очень легкий
объект. Он внутри держит pointer на некоторую реализацию конкретную, но этот тип мы не знаем,
так же как мы не знаем в C++ тип лямбды, тип функтора, который генерируется для лямбды. Но нам это и не важно,
у нас есть Handle и мы здесь говорим, да, мы игнорируем ошибку снова.
Видимо так. Await Resume, он, кажется, ничего не возвращает, потому что Quay Await ничего не возвращает.
Ну, давайте посмотрим.
Начинается. Ну ладно, давайте... Сейчас не получилось, я в перерыве попробую это починить,
все же сложно с ASIO. Не используйте header-only библиотеки. Ну, это мое личное мнение. Ну потому
что ошибки не отложиваются. Ладно, давайте по-другому. Давайте по-другому. Давайте вернемся
к трэдпулу. И вот мы решили связать карутины C++ с нашим трэдпулом, который мы делали. И сейчас
у нас есть такая задача. Вот карутина здесь запускается. Запускается карутина, ну вот она
запускается в том же самом смысле, как она запускалась вот здесь. То есть выполняется первый шаг.
Выполняется первый шаг всегда в том же потоке, который карутину первый раз вызвал, карутину
сконструировал. Так что вот эта карутина, она запускается в трэде, который выполняет функцию main.
А дальше мы хотим, чтобы эта карутина переехала в трэдпул. Каким образом это можно сделать? Ну вот
вызывать какой-то метод там submit или execute, как он там у нас называется, неважно, мы все же не
хотим. Потому что ну submit и execute работают с какими-то задачами абстрактными, а у нас все же карутина. Вот
идеоматичный способ сказать ко эвэйт телепорту и оказаться в пуле. А телепорту должен вернуть
эвэйтер, который и должен запланировать карутину как задачу в трэдпул.
А в эвэйтерэйде здесь точно false, карутина должна остановиться, потому что она должна оказаться в трэдпуле.
И вот здесь, что мы напишем?
Ну у нас нет никакого submit, у нас executor давно в курсе.
Вот. Мы хотим запланировать, ну пока мы напишем очень неэффективно, а я объясню, что мы хотим сделать,
что мы хотим сделать следующим шагом. У нас есть handle, и мы его захватим в лямбду и лямбду бросим в пул.
И уже в этой лямбде мы скажем handle resume.
Вот. А в эвэйтер резьем мы снова ничего не делаем, потому что ко эвэйт не должен ничего возвращать.
Вот. То есть карутина стартовала в мейне, потом переехала в пул, в поток пула.
Видите ли вы в этом коде некоторую неоптимальность?
Вот, кстати, можно я еще замечание сделаю? Я показывал вам код с грутинами, горрутинами,
которые... Вот они становились грутинами, когда они переехали как раз в планировщик. Вот с этого они и
начинались. Они сначала перепланируются в планировщик, планировщик — это пул потоков, а дальше уже там
сражаются за общий мюдекс.
Окей. Где я? Нужно вернуться сюда. Давайте подумаем, есть ли здесь некоторая неоптимальность.
Что? Мы просто подождем 5 секунд. А что должно измениться? Не очень понимаю.
Ну все хорошо вроде. Вот мы здесь были в мейне, этот код исполняется в мейне, этот код исполняется уже в пуле поток.
Вот здесь мы в пуле поток.
Видите ли вы неоптимальность в этом коде? Ну зависит, конечно, от того, насколько вы
продвинулись в реализации интуизивных задач в пуле потоков. Смотрите. Вернемся
в экзекьюторы. Вернемся в задачи. И говорим, что задачи — это наследники класса, наследники
интерфейса itask, которые умеют запускаться. Наследники, которые умеют запускаться. Ну и еще
они в себя интегрируют указатель для того, чтобы связываться с другими задачами в какие-то
структуры внутри самого планировщика. Почему интрузивность разумна? Ну, во-первых, файберы,
они лоцируются на куче, и файберы запускаются. Вот почему бы файберу не унаследоваться от задачи,
не реализовать в себе метатран, и там не резюмить корутины? И при планировании бросать просто
поинтер на себя в тредпул самому быть задачей. Тогда не нужна будет аллокация при сабмите,
при экзекюте, и не нужна будет аллокация внутри тредпула, потому что мы там будем какие-то
односвязанные списки мастерить и всего этого. А дальше вспомним про корутины. Вот в частности
вспомним вот этот пример. Чему он нас научил? Что корутина, стейт корутины тоже должен
лоцироваться на куче, потому что лайфтайм корутины какой-то вот непредсказуемый динамический. И вот
корутина лоцируется на куче один раз, а потом много раз возобновляется. На каждом коэвейте
она перепланируется. Ну, видимо, та же самая история должна быть. Видимо, мы должны иметь
возможность планировать ее в тредпул без лишних аллокаций, потому что в корутине уже есть аллокация.
Давайте посмотрим на код, на библиотеку Сипипикора. Она на самом деле уже мертва,
но она не... не настолько. Она не поддерживается. Просто она писалась с Льюисом Бейкером, одним
из авторов корутин, в качестве вот такого... доказательства того, что корутины работают,
что их можно принести в C++. То есть это был ронтайм для корутин. Вот в языке делают фичу,
и для этих... для этой фичи пишут ронтайм для конкурентных корутин. И вот можно проверить,
что все в совокупности работает, что задача решается. И в этой библиотеке был тредпул.
Этот тредпул был, смотрите, ну что с ним можно было делать? В него можно было планировать корутины.
Причем это был тредпул, специальный тредпул для корутин. То есть когда мы вызывали Shadow,
к корутине возвращалась... возвращался авейтор ShadowOperation, и дальше уже корутина звала на нем
CoAwait. Смотрите, как устроен этот ShadowOperation. В нем есть поле CarRoutingHandle корутина,
есть поле Next на другой ShadowOperation. И что происходит, когда мы зовем CoAwait? Ну,
вызывается оператор await... вызывается метод awaitSuspend на авейторе, на ShadowOperation.
Давайте найдем ShadowOperation, awaitSuspend. Понятно ли, что мы сейчас делаем? Мы сейчас просто
смотрим, как работает тредпул, специально заточенный под исполнение в нем корутина. Вот,
он в методе Shadow возвращает нам ShadowOperation, на котором корутина назовет CoAwait, ShadowOperation,
на котором назовет awaitSuspend. И этот awaitSuspend, во-первых, запоминает в поле ShadowOperation
Handle корутины вот здесь вот. А во-вторых, делает что? Shadow Impulse this. А здесь уже,
вы, кажется, можете углядеть некоторый знакомый вам код, потому что здесь, смотрите, если текущий
поток — это поток тредпула, то мы кладем ShadowOperation в локальную очередь, иначе мы кладем в
remoting, в глобальную очередь. То есть, у нас тут появляется планировщик с локальными глобальными
очередями, и мы планируем ShadowOperation, мы просто ShadowOperation как узел списка добавляем вот в
глобальную очередь планировщика. Тут какой-то лог-фри простое написано, какой-то лог-фристек или
что-то в этом духе. Понимаете, что произошло или нет? Давайте, вот я еще раз проговорю, а потом
картинку покажу, и, может быть, станет понятнее. Вот у вас был тредпул, у вас была корутина.
Тредпул в методе Shadow вернул корутине объект ShadowOperation. Это Awaiter. Это вот теперь локальная
переменная в корутине. Ну, потому что CoAwaitExpression это разворачивается. Появляется локальная
переменная Awaiter, и на этом Awaiter-е зовется AwaitSuspend. Этот AwaitSuspend записывает в этот Awaiter,
в этот ShadowOperation pointer на корутину, на саму себя, и этот ShadowOperation бросает как такой
интрузивный узел в планировщик, а планировщик там дальше его провязывает с какими-то другими узлами,
с другими задачами, которые нужно выполнить. Почему ShadowOperation все еще жив? Вот мы здесь с ним
работаем, а он же на стейке живет. ShadowOperation — это Awaiter. Awaiter — это локальная переменная в
корутине, а локальная переменная в корутине превращается в поле класса, CoroutineState. Так что,
а CoroutineState алоцируется на куче. Итого, у нас есть корутина, она алоцировалась на куче в виде
CoroutineState, и у нее есть поле ShadowOperation теперь, и в нем написан pointer на другие ShadowOperation.
Давайте, вот пришло время для картинки, а браузер не хочет сворачиваться. Ну вот, на самом деле,
все работает так. Вот у вас есть три корутины, они разные толщины, потому что, ну, в конце концов,
корутины могут быть разные, там может быть разное количество полей, разное количество
аргументов, локальных переменных. Это вот три разные корутины, и все они решили запланироваться
в пул потоков. Каждая из них получила Awaiter, ShadowOperation, запомнила там себя,
и через поле Next связалась с другими корутинами. А в ThreadPool, в глобальной его очереди, есть,
в конце концов, какая-нибудь переменная Head или Tail, ну, неважно, и вот она держит ссылку
на ShadowOperation. И вот так вот мы построили, по сути, интрузивный список из корутин.
Вот тут много скрытой механики, тут это должно быть понятно, да, потому что вот, ну, в ThreadPool
нет никаких корутин, ShadowOperation нет никаких корутин-стейтов, это все тоже скрыто компилятором
от нас. Но вот если все это в голове развернуть, то появляется такая конструкция, появляется
такой неявный интрузивный список. Вот, но мы должны сделать домашки еще лучше, потому что, ну,
почему мы должны сделать лучше? Потому что здесь ThreadPool вот прямо конкретно с корутинами работает,
он возвращает нам ShadowOperation, Awaiter. А мы хотим написать все еще вот такие максимально абстрактные
экзекутеры с максимально абстрактными задачами и сделать так, чтобы корутины без всякого
оверхеда в них тоже можно было бы планировать. И вот это будет служить доказательством того,
что наш дизайн, вот наши экзекутеры, наши интрузивные задачи, это хороший дизайн,
потому что вот они подходят для файберов с одной стороны, а с другой стороны они одинаково,
оптимально подходят для стеклоскорутина C++. Совершенно другого механизма реализованного,
там не в библиотеке, не нами, а вообще в компиляторе, но при этом в силу того,
что мы подобрали правильные абстракции, правильные интерфейсы, мы получим интеграцию, причем
интеграцию оптимальную, без каких-то дополнительных накладных расходов на ненужные аллокации. Вот,
в очередной задаче вы сможете это попробовать сделать. Ну, то есть вы должны в задачи экзекутера
все-таки докрутить интрузивность, а потом взять тредпул оттуда и вот встроить, интегрировать его
с корутиными. Ну, а в конце концов у нас получится, вы, наверное, чувствуете, что происходит,
что все задачи собираются вместе, потому что вот все аккуратно, аккуратно продумано,
все совсем сочетается. Вопрос. Ну, потому что нечего исключения бросать. Мы говорим,
что задача сама должна разобраться, если там прошли исключения, она пусть сама думает,
как с ним работать, потому что, ну вот, необработанные исключения в файбере — это
проблема файбера, необработанные исключения там в крути. Ну, короче, это проблема того кода,
тех сущностей, которые исполняются в тредпуле. Тредпул не может адекватно реагировать на это,
и он может только разломаться. Ну, разломать в смысле вообще все, если пользователь не аккуратен.
Ну, потому что мне хватает одного поинтера Next. Зачем мне Next и Pref? Я не собираюсь писать
двусвязанные лукфри списки, это забава. Ну, короче, так все равно не выйдет. Вот, в общем,
мне достаточно для всех моих целей. И для Strand достаточно, и для этот пула хорошего достаточно.
Вот, ну и в этом коде тоже, в общем, один поинтер Next. Односвязанных списков хватает.
Ну что, давайте сейчас зафиксируем наш прогресс. Мы разобрали, мы вроде бы понимаем,
что такое stackless-крутина. Теперь крутина, которая останавливается только вот в своем
вызове, не трогая вызова выше по stack, и которая умеет через оператор CoEv8 остановиться и
запланировать свое возобновление с помощью специальной сущности овейтера. Ну, всю эту механику,
всю механику крутина реализована, по сути, в компеляторе. Компелятор переписывает тело крутина
в некоторый служебный класс, алоцирует его на куче, подставляет в CoEv8 вызов овейтеров,
которые берет через оператор CoEv8, ну а дальше вы, реализовывая овейтеры для своих типов,
кастомизируете поведение вот вашей конкретной крутины, которая работает с вашими конкретными
объектами. Там таймер мизайсио, тредпулами, фьючами, мьютоксами, чем угодно. Вот после перерыва
мы поговорим про вторую половину нашей проблемы, а именно про то, как крутину стартовать, завершить
и как вернуть из нее какое-то значение. Давайте через 10 минут продолжим. Продолжаем, и за время
перерыва мы починили ASIO, раздуманную часть ООН, а не наш код с крутинами. Вот, теперь все работает,
теперь таймерам можно дожидаться. Вот таймер овейтер, вот мы, еще один пример, как можно дожидаться
чего-то, в частности таймера, мы подписываемся в овейтерспенде на таймер, в колбеке мы резюмим
крутину через короутинг-хэндл. И вот теперь можно запустить этот код, он скомпилируется,
он поспит и напечатает привет через две секунды. Почему этот пример важен? Ну, важен не он,
не пример, не ASIO, в смысле, не ASIO с таймером, вот таким вот с клипом, а пример чуть более общий,
с которого и начинается, собственно, документация, референс про крутины C++. Это пример эхо-сервера
на сокетах, на асинхронных сокетах с кое овейтами. Это код, который выглядит абсолютно как
синхронный, но давайте разберемся, как он работает. Вот мы здесь видим сокет асинкрицам,
но давайте я покажу это вот здесь, вот у нас где-то здесь будет такой же класс,
он называется HandleClient, здесь мы в цикле, у нас есть локальные переменные, буфер, мы в цикле
читаем из сокета с помощью операции асинкрицам и перед этим ставим кое овейт, а потом пишем
сокет, тоже перед этим ставим кое овейт. Код выглядит как синхронный, код выглядит как
блокирующий эхо-сервер, написанный на том же ASIO, разве что появляются вот эти самые кое овейт.
Но мы знаем, что кое овейт — это как раз место, где прячется асинхронность, где мы останавливаем
корутину, а потом ее возобновляем, поэтому нужно посмотреть, как ведет себя овейтер,
который возвращает операция асинкрицам. Овейтер этот устроен каким-то очень предсказуемым образом,
он связан с сокетом, с сокетом, буфером, и мы из сокета стартуем, для сокета стартуем асинхронную
операцию чтения в буфер и подвешиваем кулбэк, в котором мы резюмим корутину. Корутина останавливается
при вызове кое овейт от асинкрицам, возобновляется, когда в ивентлупе из епола будет
достанут сокет с этим клиентом, он будет готов к чтению, из него прочитают, вызовут обработчик,
в этом обработчике будет вызван handle резюм, и корутина продолжит свое исполнение вот с этого места.
Вот мы опять с помощью нашего примитива, ну вот в данном случае стекл с корутина,
ну мы и со стекл корутиной делали то же самое, мы трансформировали асинхронный код в асинхронный,
так же, как мы делали в slip4, в одноименной задачи. Но смотрите, что важно, вот возьмем,
например, наши стекл с корутиной и возьмем пример с мьютоксами и запустим его,
посмотрим, где он тратит время. Ну вот мы на Flame Graph в прошлый раз смотрели уже,
нет, это не он. Это workload с мьютоксами, ну мы на прошлой лекции про планировщик смотрели,
насколько быстро работает код, где там 13 групп потоков по 100 штук, соревнуются за свои мьютоксы.
В общем, мы видели, что в хорошем планировщике большую часть времени тратится на код пользователя,
и вот какое-то время тратится на код планировщика самого, на процедуру планирования в Worker,
и из самого кода пользователя еще есть обращение к runtime, и тут они тоже вот где-то торчат.
Увижу ли я здесь то, что я хочу, или здесь слишком мелко все это? Ну вот тут он нашелся,
он какой-то короткий, но тут меньше процента. В общем, есть вот какой-то overhead, который вносит
сами корутины, вот наши stackful корутины, я имею в виду, реализованные через механизм переключения
контекста. А давайте подумаем, какой overhead вносит stackful корутины вот в такую реализацию.
Относительно вот оптимальной реализации, которая написана вот непосредственно на
асинхронных операциях в ASIO. Мы ее разбирали, сейчас подробно разбирать не буду. Там,
я напомню, у нас была функция session в синхронном коде, и она переписывалась в class session, в котором
был start, там был дурид, дурид планировал первую асинхронную операцию чтения, в колбеке
планировал, в колбеке запускал следующую асинхронную операцию записи, и так вот по циклам
эти задачки запускались в event loop, и исполнение бежало вперед, обрабатывался клиент. Что же
происходит при исполнении вот такого кода? Даже не то что про исполнение, вот при компериации
этого кода. Вот мы написали такую функцию handleClient или session, если вам так угодно,
чтобы больше соответствует. И дальше мы написали в ней coawait. Компиратор увидел этот coawait,
он понял, что перед ним корутина. Это означает, что ее нужно переписать на автомат, то есть нужно
для нее завести класс, в котором полями будут локальные переменные этой корутины. И вот,
у нас появляется класс, у которого полем будет буфер дата. Вот пока все это очень похоже на то,
что есть в этом примере. У нас здесь был class session, и у него есть локальные из поля дата для буфера.
Класс этот алоцируется на куче, потому что вот непонятно, сколько клиентов мы будем обслуживать,
lifetime динамический. Что происходит с корутиной? Опять, корутина свой state алоцирует на куче,
потому что lifetime динамический. Что написано, что происходит с вызовом coawait при чтении сокета?
Но вот он разворачивается вот в такой код, то есть появляется awaiter в качестве локальной
переменной. Awaiter, который выглядит вот так. У него есть await ready, но он возвращает false.
Этот await ready, он просто inline-ится в тело корутины. Ну и раз в теле корутины есть строчка if not false,
то, видимо, этот if вообще просто стирается и остается только то, что написано вот здесь,
просто вызов await suspend. А что написано в await suspend? Он ведь тоже inline-ится. Тут написано
socket asyncretesum и handle-resue. Итого, у нас появляется класс для этой функции, у него полем служит,
буфер служит полем этого класса, а в функции, ну условно resume, в этом классе методе resume,
у нас есть код, где мы вызываем на сокете сразу же socket asyncretesum и в кулбеке планируем возобновление.
Вот смотрите, буквально если трансформировать этот код в state-машину, которую пишет комператор,
если заинлайнить все вызовы, которые мы не прятали в другие единицы трансляции, то комператор,
в конце концов, напишет за нас вот просто буквально эту программу. То есть он увидит эту
программу, а напишет вот эту в итоге и скомпилирует вот эту. И это очень неплохо, потому что кажется,
что это решение оптимально, потому что вот ничего лучше, чем event-loop с кулбеками придумать нельзя.
Вот так устроена операционная система, она дает асинхронные API для сокетов, и хорошее
масштабируемое решение используют этот API. Мы его используем в виде библиотеки ASIO,
но вот в таком виде писать код нам не очень удобно, поэтому мы придумываем абстракцию
к routine, которые с помощью co-events вправляют поток управления обратно, делают исполнение как будто
бы синхронным, но только на поверхности языка оно синхронное. А под капотом уже вот компилируется код,
который получен переписыванием этого кода на автоматы, и компилируется код вот этот вот,
то есть оптимальный асинхронный. Мы пишем код простой синхронный, а компилируем код оптимальный
асинхронный. И вот вся абстракция co-routine в этом примере стирается на стадии компиляции. Вот наши
co-routines, они stackful, они присутствуют в исполнении, там элоцируются стэки, там переключаются контексты,
сохраняются, намазываются регистры, это все никуда не девается. Здесь же от co-routines следов не остается,
ну потому что они существуют только на поверхности языка, что кажется довольно неплохо. То есть это,
stackless co-routines, это решение, которое предлагает C++ для реализации асинхронного, для программирования
асинхронности. Это абстракция, которая позволяет комбинироваться с произвольным рантаймом,
с произвольными там фьючами, планировщиками, вводом-выводом. И при этом абстракция,
которая при компиляции просто стирается, избавляет пользователя от всякого оверхеда.
Но если, конечно, пользователь позаботился и аккуратно все написал. То есть co-routines могут
быть бесплатными здесь. У нас остаются только аллокации самих co-routines, а это, кажется,
вот вещь неизбежная, потому что у нас появляются какие-то операции конкурентные, которые,
неизвестно сколько будут работать, у них динамическое время жизни.
Хорошо. Значит, это все по-прежнему co-awaits, длинная история про co-awaits. А теперь давайте
посмотрим, например, с пулом потоков, который был немного сложнее. Вот мы здесь написали
оператор, здесь написали awaiter, который перепланировал co-routines в threadpool. Она
начинала снаружи исполняться, потом прыгала в threadpool и бежала уже там. Но в конце есть еще
одна примечательная конструкция, co-return. Мы пишем co-routines, но это как будто бы функция,
из функции можно вернуть значение. В чем сложность? В том, что co-routines вот здесь,
запускаясь, сразу что-то возвращает. Но вот этот вызов co-routines, это же не... он же не блокирует
поток, пока co-routines завершится. Вызов co-routines, это всего лишь первый шаг co-routines до точки остановки.
Вот. И эта co-routines вообще планирует спать, ну давайте в пять секунд и берем все же. Секунду
собирается спать. Она не может сразу вернуть вот этот сейм пользователю. Она синхронная. Но при
этом вызов сам по себе что-то возвращает. Итого, смотрите, у co-routines есть два возвращаемых
значения. Одно, ну как бы, не знаю, настоящее как это назвать. Одно, которое она вернет в конце концов,
которое она вычисляет, это сейм. А есть некоторое значение, которое она должна вернуть сразу
пользователю. Ну и здесь, на самом деле, вот этот пример, он почти что не отличается от
вернемся к примерам, к co-routines, от AsyncVIA. AsyncVIA это такая асинхронная функция, которая
что-то вычисляет в фоне там в тредполе. Она вычисляет срок 2, она возвращает future от int,
вместо int. Потому что сам int еще не готов. Видимо, похожая история должна быть с co-routines,
потому что здесь co-routines такая же асинхронная операция, только она уже умеет останавливаться
внутри себя во время своего исполнения. Но нам снова нужно разделить вот итоговое значение и
некоторые типы этого значения int и мгновенный результат, который вернет co-routines при запуске. И
что нужно выбрать, что можно выбрать, но кажется, что разумно выбрать future. Потому что future это
представление для будущего значения. Мы, вызывая функцию, сразу получаем future, а потом мы блокируемся
до тех пор, пока co-routine не завершится, в эту future не положат значения, и мы его здесь не прочитаем,
не разблокируем поток. Отлично. Теперь осталось разобраться, как это все работает. И теперь мы
возвращаемся снова к нашим примерам, где мы в рукопашную писали все эти co-routines. Мы хотим,
видимо, наш пример еще немного доработать. Ну вот давайте посмотрим. Тут все написано уже,
дела. Ну тогда придется прочитать. Писать не будем. Что должна сделать co-routine при запуске? Наша,
наша игрушечная, ручная co-routine, она должна вернуть v пользователю, но v вычисляется асинхронно,
поэтому она возвращает future от v. Это означает, что при старте co-routine, ну вот как обычно,
она алоцирует свое состояние на куче. Это первый шаг при запуске. Дальше co-routine стартует,
но перед этим мы из co-routines забираем return object. Это объект, который представляет собой,
ну как бы, представление будущего результата. И в данном случае return object это future. Вот future
мы получаем отсюда. А дальше, когда co-routine завершается, вот в точке, где в коде написано
co-return v plus 1, мы должны в эту future положить значение, ну в промес этой future положить значение.
Вот появляется такая логика. Нужно при старте co-routines построить некоторый объект
будущего значения, ну я условно говорю, это не обязательно future, а при завершении co-routines
нужно передать пользователю вот итоговый ответ. Это отдельная часть логики, и понятно,
что она снова для co-routines кастомизируется снаружи. Потому что co-routine, еще раз повторяю,
это языковая фича, она не может зависеть от каких-то там std future или чего-то подобного. Сам
пользователь решает, какую семантику co-routine имеет. Вот в случае co-await пользователь кастомизирует
поведение с помощью сущности avator. Он там для своих future, для своих mutex пишет свои avatars,
и компаниятор их использует, вызывает их методы. С вызовом и возвратом значения та же самая
история. Должна быть некоторая внешняя стратегия, в которой описано, как мы представляем будущий
результат, и как мы пробрасываем в этот будущий результат значение итоговое. И этот объект,
эта сущность для co-routines называется promise type, promise object. У каждой co-routines есть promise
object, и в наших игрушечных co-routines, в наших ручных co-routines, это два метода. GetReturnObject
и ReturnValue. GetReturnObject вызывается при старте co-routines, и он возвращает тот объект,
который должен быть отдан пользователю на старте. А ReturnValue вызывается из самой co-routines в
точке, где пользователем был написан co-return. Коррутина подошла к концу, хочет завершиться и
возвращает ответ, но поскольку ответ асинхронный, нужна какая-то логика, которая пробросит его
пользователю. Но в данном случае это promise, мы его в GetReturnObject построили, пару promise future,
promise запомнили, future отдали, а здесь мы в promise, в ReturnValue положили значение. И вот как уже
выглядит наша co-routine. Вот уже более полный код. Это автомат, плюс это запуск. Вот когда мы пишем в
вот здесь кора от пула, то под капотом происходит вот просто такая механика. Вот написано разбор,
как бы развертка всего этого кода, который сгенерирует комператор. Алоцировали на куче state.
В state есть promise type. Мы из него взяли GetReturnObject, то есть future, вернули пользователю,
стартовали co-routine. Когда co-routine добежала до конца, то есть в конце первого шага,
мы написали promise type ReturnValue v plus 1, и в этом ReturnValue записали значение в promise. Оно
полетело пользователю во future, и пользователь вот здесь его дождался. Ну как? Понятно?
То есть это еще одна точка кастомизации, а вейтер указывает, как именно дожидаться конкретного
объекта, конкретного события там таймером utux future, а promise type говорит, как co-routine
взаимодействует с вызывающим ее кодом. Нет, это работает не так. То есть вопрос, звучит так,
как именно компилятор связывает конкретную co-routine с конкретным типом promise type. В случае
овейтеров у нас был оператор co-avait для типа. В случае promise type… Ну вообще, чем определяется
promise type? Вот есть co-routine, вот оно написано. Ну или давайте посмотрим прямо на настоящую co-routine,
вот написано… Вот написана настоящая co-routine. Правда, она возвращает, черт и что еще? Ничего не
возвращает даже, черт возьми. Давайте тогда смотреть все же сюда. Она возвращает вот future,
внутри вызывает async via, получает future, дожидается ее, co-routine 2.1. От чего отталкивается компилятор,
когда он ищет promise type? Нет. Сейчас аккуратнее скажи. Я просто двумя способами тебя понял. Да,
компилятор смотрит, какой тип вы возвращаете, и по нему находит уже promise type. Как именно… Ну вот
давайте я здесь покажу, если вроде бы было. У меня есть future, и вот co-routine возвращает future. Это значит,
что должен быть promise type, реализованный для std future. Вот он. И есть специализация
co-routine traits для std future. Вот если мы хотим поддержать некоторый тип в качестве возвращаемого
значения для co-routine, мы должны написать специализацию co-routine traits и там указать,
что promise type для вот этой future будет служить вот этот класс, в котором будут методы,
но в котором будет promise в данном случае, getReturnObject будет строить по нему future,
а return value будет… ну вот это для void специализация, для произвольного t, а в return value мы
будем просто в promise класть значение. Но правда, co-routine может разными способами закончиться,
может быть exception брошен, может быть… может быть брошен exception, и тогда тоже нужно какой-то
способ, которым можно exception прокинуть, вернуть пользователю. Поэтому promise type, он помимо
getReturnObject и return value может реализовать еще вот setException, unhandledException. Почему называется
promise type? Ну потому что такой очевидный результирующий тип для future и для co-routine это future,
вот. А promise type для co-routine, который возвращает future, будет просто promise. Поэтому… ну это странный
выбор, потому что мы как будто бы связываем co-routine с… co-routine с синхронностью, хотя в общем случае это
делать не обязательно. Ну я подозреваю, что название promise object, promise type выбрано именно
по этой причине. Ну вот давайте посмотрим сущности, которые участвуют. У нас здесь promise object,
co-routine handle, co-routine state. Вот все эти сущности вроде бы проговорили, которые участвуют в
механике, задействованные в механике co-routine. Понятно, да? Да, вообще говоря, promise type зависит
от всей сигнатуры, то есть еще и от аргументов. Но в данном случае не зависит. То есть для всех типов,
ну для всех аргументов, если возвращаем его из значения future, то promise type будет служить вот
такой код, то есть по сути… по сути это promise. Ну потому что там нет set value с аргументом,
и там return void, а не return value вызывается. Ну void – это специальный тип. Void – это беда для
шаблонов. Вот есть… смотри, есть типы населенные многими значениями, есть тип void без значений,
а есть тип unit с одним значением. Вот. И ну в этом большая неудача, что у нас здесь не… что мы future,
которые ничего не возвращают, а возвращают void, а не unit. Ну или функции, которые не возвращают,
возвращают void, а не unit. Если бы не возвращали unit, было бы гораздо приятнее всем. Ну это…
Я вообще-то серьезно отвечаю, как вот хорошие языки это делают. Вот хорошие языки… На самом
деле, сложный вопрос, он про дизайн языков, он не про то, что там какой-нибудь костыль приделать. Вот
в разумных языках функции, которые ничего не возвращают, возвращают unit на самом деле,
потому что unit может быть… ну короче, это с expression хорошо матчится. В общем, там можно дальше
композицию функций делать. Отдельная история. В шаблонах C++ void – это всегда большая боль,
потому что он сильно отличается от остальных синтактически, его обработка сильно отличается,
поэтому приходится специализация. Вот поэтому здесь отдельная специализация для void. Ну и
return void вместо return value. Итак, вот promise object, и он в механике вот используется так. Он
является… становится полем картины при старте. Мы из него достаем return object, возвращаем его,
а при завершении мы через return value прокидываем ответ пользователя. А теперь еще немного глубже
погружаемся в реальность и узнаем. Ну например, из стандарта C++, что на самом деле, когда вы
компилируете коррутину, комп vest компилирует не тело вашей коррутины. Ну то есть не только тело
вашей коррутины, не прямо тело вашей коррутины трансформирует в автомат. А на самом деле берет
тело вашей коррутины, оборачивает ее в некоторый служебный код и уже ее трансформирует в автомат.
Ну и в частности, тут появляется локальная переменная promise object, и она становится полем
класса. То есть это не какое-то специальное правило, просто мы сделали ее полем, поэтому вот здесь
оно есть, как любая другая локальная переменная. А что еще интересно, здесь появляются две
дополнительные точки остановки, два новых коэвейта. То есть плюс ко всем вашим в крутине есть еще два
служебных коэвейта, initial suspend и final suspend. То есть крутина может остановиться еще до запуска
вот, в общем, вашего кода, который вы написали, и может зачем-то остановиться в самом конце перед
завершением. И когда мы пишем promise, ну вот у нас здесь этого не было, он был упрощенный,
этот самый promise. Когда мы пишем настоящий promise, то мы должны указать, но мы должны вернуть
какие-то овейтеры из initial suspend и final suspend. У нас есть две дополнительные функции, которые
решают, которые определяют, как именно крутина будет действовать в точке начальной остановки и в
точке финальной остановки. И здесь мы возвращаем такой готовый овейтер suspend never, который в
await ready говорит всегда true. Ну просто крутина игнорирует эти точки старта и финальной остановки.
То есть как будто бы их нет. Но на самом деле тут можно что-то более умное написать, и мы чуть
позже разберемся, что именно. Это нетривиально. А давайте разбираться, собственно. Давайте поговорим
про нечто совершенно другое. Забудем про всякие сейчас future promises. Поговорим про stackless природу
крутина. Мы как-то, ну, сказали, что вот крутина останавливает только свой вызов, не тормозит stack
вызовов над собой, а дальше начали их писать, и все упрощается, потому что состояние остановленной
крутины — это всего лишь состояние вот одного stack-ового фрейма. Поэтому нам не нужно
close stack держать. Но с другой стороны, смотрите, в чем есть некоторая сложность. Предположим,
что у нас есть функция bar, которая является крутиной, и функция foo вызывает функцию bar.
Когда у вас в функции bar может быть написан кое вейт какой-нибудь. В чем подвох? В чем сложность?
Ну, в случае stackful крутин никакой проблемы не было. Если вы вызывали функцию, она... та вызывала
функцию, та вызывала функцию, и в конце концов где-то в недрах этого stack вызова был написан suspend,
то просто исполнение останавливалось, stack замораживалось, и мы выпрыгивали куда-то наверх.
А теперь представьте, что вы вызываете функцию, а это не функция крутина на самом деле. И она
стартует, а потом решает остановиться в середине. Она останавливается, а вы-то нет? То есть когда вы
вызываете крутину в своем коде, вот я говорил уже об этом здесь, то синхронно выполняется только
первый ее шаг до первого кое вейта, на котором крутина становится. Вот, мы здесь вызвали, и все,
исполнение побежало дальше. Но, может быть, мы к этому не готовы, может быть, мы хотим все-таки
вызвать крутину, и мы вызываем функцию, а она крутиной вдруг оказалась. Как нам быть?
Вот, если вы пока не поняли, о чем я говорю, давайте я вам посоветую одну отличную статью
чудесного человека с чудесным блогом, который написал книжку crafting interpreters про то,
как писать интерпретаторы и ратуальные машины великолепны. Вот, читайте ее сегодня же. У него
есть очень известная, очень старая статья What color is your function? Пожалуйста, непременно с ней
знакомьтесь, если вы работаете с крутинами. В любом языке, неважно, какой. Смотрите. Утверждается,
что в вашем языке, в нашем языке C++ есть разноцветные функции. Есть функции красные,
есть функции синие. И правила вызова красных и синих функций отличаются. Ну, пока не страшно,
дальше начинаются уже трудности, что если у вас функция красная, то из нее можно звать синию
функцию. А если функция синия, то красную звать уже нельзя. Это чем-то плохим закончится. И вообще,
красные звать как-то больно, больнее, чем обычные функции. Что-то затрудняет их вызов. Вот мир в таких
языках, да, но вот и библиотеки, вот работать с библиотеками и некоторые функции, в них красные.
Вот статья про такое общее наблюдение. Что такое красные и синие функции? О чем идет речь?
Это функции синхронные и асинхронные. Вот у вас есть функция синхронная, вы вызвали вызов,
завершился всё. Операция завершена какая-то, логическая. А есть функции асинхронные,
которые у нас представлены в языке крутинами. Мы их вызываем, они стартуют, а потом останавливаются,
и потом где-то асинхронно продолжают работать. Но прямо сейчас нам колеру сообщают, что вызов
завершился как будто бы. Вот, ну и разумеется, вы можете в крутине позвать некрутинную функцию,
обычную. И там стэк будет наращиваться. В этом проблемы никакой нет. Stackless крутина может
вызывать другие функции и копить стэк, разумеется. Но в какой-то момент она захочет остановиться,
и таким образом она создаст некоторую проблему колеру. Вот обычная функция не может вызвать
асинхронную. Тогда как быть обычной функцией? Ну, видимо, ей придется тоже стать асинхронной.
То есть, если она вызывает крутину, то видимо, она сама должна быть крутиной тоже. Потому что
вызываемая крутина может остановиться, а значит, нужно остановиться и ей колеру. И вот так начинает
распространяться синтактическое заражение этими co-awaitами. Вот у вас где-то появился co-return,
и вы в функции foo вызывали этот бар, и этот бар тоже становится крутиной. И функция,
которая вызывает эту foo, тоже становится крутиной. И тоже должна дожидаться каждую вызываемую
функцию. Проблема в том, что наверху этого стека находится main, а main — это синяя функция,
разумеется, не асинхронная. Поэтому где-то вы должны провести черту. Вот. Ну и тут ничего
неожиданного, и вот здесь мы используем для всей этой композиции future. Future, для которой поддержан
оператор co-await. Вот с этим самым future-авейтором, который делает subscribe и резюмит крутину в колбеке.
Мы вызываем крутину, она возвращает future — потенциально асинхронная операция. Если мы вызываем
функцию bar и хотим дождаться ее синхронно, то мы говорим co-await и сами блокируемся до тех пор,
пока в этой future не появится значение. А если мы хотим, ну и вот так все происходит по стеку выше,
все это тоже крутины красные, а в какой-то момент мы вызываем из main вот функцию,
которая не хочет быть крутиной, и она уже вот здесь блокируется, честно. Мы здесь проводим
границу между синей функцией и красной функцией. Мы говорим, хватит, будем ждать, блокируемся на
future. Вот поэтому возвращаемое значение нам должно позволять выполнять две вот эти операции.
С одной стороны, дождаться с помощью co-await, блокируя крутину, а с другой стороны, блокировать
поток, чтобы ну просто провести черту между красным и синим миром, между синем и красным,
чтобы это заражение остановить. Понятно? Ну а теперь перейдем к сложным вещам.
Смотрите, утверждается, что вот так можно делать, в смысле можно использовать future в качестве
возвращаемого значения для крутин. Также утверждается, что это очень неэффективно.
Почему? Причины много. Ну причины в дизайне future. Что такое future? Ну future, она в паре с
промессом. И задумка какая? У вас асинхронная операция, ну есть два потока. Один консюмер,
другой продюсер. И вот в этом потоке что-то вычисляется, этот поток что-то ждет. Ну не то,
что вычисляется, может быть там вот вывод делается, может быть вычисляется, может быть таймер
какой-нибудь. Ну в общем, есть два потока, и где-то здесь происходит событие, а здесь его ждут.
И поэтому мы строим между ними канал, здесь promise, здесь future, и можно из промесса future
передать какую-то информацию, результат, ошибку или без значения. Как устроены future, точнее как
устроены API, которые работают с future? Устроены они обычно так. Возвращаемся к примеру с
гаррутинами. Вот мы здесь получаем future, когда мы стартуем асинхронную операцию. И если у нас
уже есть future, то это означает, что где-то уже стартовала асинхронная операция, есть какой-то
другой поток, возможно у которого есть promise, и мы уже с ним гоняемся. Мы можем вот здесь подвешивать
кулбэк к future, а из пола потоков могут вкладить значение в эту future, ну в shared state между ними.
Вот есть уже гонка. И если вы решали уже самую простую, хотя бы future, а другую еще не могли, то
вы знаете, что этот shared state лоцируется на куче, потому что динамический lifetime, потому что непонятно,
кто раньше умрет. В общем, есть shared state, динамическая локация. На него держатся сильные ссылки,
shared pointers с атомик счетчиками. И просто внутри shared state есть синхронизация между
продюсером и консюмером. А локация, подсчет ссылок, синхронизация. А теперь смотрим на этот
пример, не на этот, на этот пример. У нас здесь есть функция foo, она вызывает функцию bar. Вообще-то,
здесь время жизни функцию foo покрывает время жизни функции bar. Время исполнения функции foo
покрывает время исполнения функции bar. Нужна динамическая локация? Не нужна. Нужен подсчет
ссылок, кто раньше умрет? Не нужен. Нужна синхронизация? Ну, на самом деле, тоже нет.
Что такое co-await bar? Мы резюмим к рутину, но перед этим подписываемся на... Мы останавливаем
текущую к рутину foo и подписываемся на future, который возвращает нам bar.
Bar как будто бы уже может исполняться в этот момент. Ну, давайте не будем так делать просто.
Давайте мы не будем исполнять foo до тех пор, пока мы в этом co-await не подвесили callback к future.
То есть, смотрите, вот... Какова семантика? Мы вызываем асинхронную функцию, а мы вызываем
в асинхронную функцию другую асинхронную функцию и хотим дождаться завершения функции bar. Как это
было бы оптимально сделать? Оптимально было бы получить future каким-то образом, без синхронизации
спокойно повесить на нее callback, что когда future готова, нужно запустить текущую к рутину,
а после этого уже зарезюмить к рутину bar, чтобы она начала бежать. Вот future это все не делают,
потому что future... Ну, в них уже есть shared state, есть уже локация, еще чехсылок, синхронизация,
поэтому нам нужна не future. Нам нужен некоторый другой класс, который мы назовем task. Он по
смыслу похож, то есть он представляет из себя будущее значение, но он вот прям для к рутин создан.
Вот я здесь пишу пример, я вызываю в цикле к рутину и блокируюсь до тех пор, пока она не завершится,
но опять представим себе, что она асинхронная. Что сделает этот task? Ну вот, он должен работать
вот так, как я говорю. То есть, когда мы вызываем subwork, сама к рутину не должна стартовать,
она должна только возвращать task, не начиная исполняться, потому что, когда начнут исполняться,
она уже может куда-то убежать в другие потоки. Вот мы хотим сначала получить от этого вложенного
вызова task, подписаться, что мы хотим себя возобновить, когда в task появится значение,
а потом стартовать дочернюю к рутину, которая уже начнет исполняться, и потом этот task заполнит
значение. Понятно, чего я хочу? Вот, а теперь начинается реализация этого. Ну это сложная
часть, давайте попробуем, по крайней мере, не отрубиться. Ну нужно сейчас вот собрать
все вместе, все, чтобы он на занятии, все в кучу собрать. И знания и про фьюч, и про асинхронности,
и про таски, и про промиссы, и про вейтеры, про все это вместе. Я боюсь, что я не смогу 5 минут
сейчас повторять еще раз. Но я хочу получить композицию к рутин, избавившись от накладных расходов
фьюч. А именно, мне не нужна динамическая локация shared state для фьюча, мне не нужна...
Еще раз, понятно, что все это лишнее. Вот, я хочу все этого избежать. И я объяснил даже,
как. По смыслу это тоже представление для будущего значения. Но как его извлечь это
будущее значение? Вызвать кое вейт. А кое вейт на таске должен запустить под задачу, должен
сначала подписать нашу коррутину на появление значения и вызвать под задачу. При этом никаких
shared state делать не нужно, потому что... Ну просто у нас lifetime и коррутин вложены друг в друга,
bar вложен foo. В общем, в случае с фьючами это не так, поэтому там динамическая локация есть здесь,
у нас она не нужна. Ну вот, смотрите, когда мы вызываем кое вейт sub work, мы вызываем кое вейт
на таске. И хотим, видимо, в этом кое вейт от таски остановить текущую коррутину до тех пор,
пока не будет завершена эта коррутина. Но мы хотим сначала подписаться на возобновления,
а потом уже стартовать дочернюю коррутину. И вот тут мы вспоминаем, что у коррутин не просто так,
есть initial suspend. Вот если мы пишем task, если мы пишем task, то вот у него есть promise type.
И у него есть initial suspend. И он suspend always. То есть коррутина просто всегда останавливается при
своем вызове. Вот если коррутина возвращает таску, то она при запуске останавливается в точке initial
suspend. То есть вообще не доходит до исполнения кода пользователя. Но зато сразу отдаёт пользователю
объект task, отдаёт колеру объект task. Это понятно? То есть вызывая sub work, мы на самом деле останавливаем
коррутину до ещё выполнения этого тела, но уже отдаём колеру task. А колера вызывает на этом
task co-await. И что происходит дальше? Ну, видимо, нужно смотреть, как реализован авейтер для таски.
Да, давайте только посмотрим, как именно таска получается. Вот у нас есть task promise,
и у него есть у него есть initial suspend, который останавливает под задачу всегда.
А ещё есть get return object, который отдаёт что-то пользователю. Вот смотрите, что мы отдаём. Мы
отдаём пользователю task, собственно, в котором мы запоминаем handle вот себя. То есть пользователю
отдаётся task, у которого есть поле. Давайте мы сейчас его будем искать. Вот task. У него есть поле
coroutine handle. Это sub work, и вот он остановился в initial suspend перед запуском, но вернул пользователю
object task, внутри которого лежит handle вот этой коррутины. То есть work может возобновить через этот
handle sub work. И, наверное, мы это и делаем в co-await. Смотрим теперь на авейтер для класса task. Вот у
нас есть class task, у него есть авейтер, и у него есть await suspend. Но я расскажу сейчас не его,
а на самом деле, что бы мы хотели там написать. Давайте подумаем, что бы мы там хотели написать,
на самом деле. Вот у нас, смотрите, у нас есть, вот в этом месте компилятор запустил sub work,
остановил sub work перед первой строчкой вашего кода и вернул наверх объект task, в котором лежит
coroutine handle для sub work. А теперь вы work, вызываете co-await на объекте, на авейтере для task.
Ну вот что вы сделаете в co-await для task? Давайте логически рассуждать. Что вы хотите? Вы хотите
остановиться сами, вот вы текущая коррутина work, хотите остановиться и возобновиться тогда,
когда закончится sub work, но он даже не запустился еще. Поэтому, видимо, мы должны sub work сказать,
что «пожалуйста, вот я, коррутина work, вот мой handle, когда ты завершишься, запусти меня после
этого. Я пока засыпаю, а ты возобновляйся». То есть мы сначала говорим sub work, чтобы он запомнил
handle на нас, у нас его handle есть, и мы через него говорим sub work, чтобы он нас возобновил в конце,
а сами засыпаем. Вот. Вот видите, у нас есть awaiting, coroutine, это collar, это work, это то,
что снаружи, и мы засыпаем, и мы resume sub work, дочернюю коррутину. Но почему-то написан код
задом наперед. Почему-то мы сначала возобновляем ребенка, а потом мы к нему подвешиваем себя,
хотя могли бы сделать наоборот. Это тайна, которая останется на время домашней, до домашней,
окутанной мраком, потому что ответ смешной. Я дам вам возможность насладиться им самостоятельно,
он для тех, кто решит. Давайте думать, ну, можно написать, как я сказал, сначала подвешиваем,
потом резюмим. Увидите, чем это закончится. Что происходит, ну, ребенок запускается, sub work
запускается, он работает, работает, работает, а потом приходит в final suspend. Что происходит в
final suspend? В final suspend мы возвращаем final awaitable, еще один awaiter, и как он устроен?
Ну, во-первых, коррутина дочерне резюмит коррутину родительскую. Это был план. Sub work завершился,
и теперь sub work пришел в final suspend, а теперь резюмит колера work, вот здесь вот. Тут есть
какой-то еще exchange, опять не думайте о нем. И при этом sub work засыпает, засыпает вот здесь,
в final suspend, он не выходит оттуда. Он мог бы завершиться, написать дредзис, но он так не делает.
Почему он так не делает? Ответ очень хитрый, и мне кажется, очень важный для понимания эффективности
коррутины, почему вот дизайн такой навороченный. Смотрите, даже если мы вот написали хороший таск,
я вроде бы там объяснил, как он работает, если вы отрубились, ну, ничего страшного,
это сложно сходу понимать, я бы не понял точно. Смотрите, в чем еще есть проблема. Что такое запуск
коррутины? Вот мы с вами писали развертку, и вот здесь мы видим, что запуск коррутины любой,
это аллокация стейта на куче, возврат значений, но аллокация стейта. И вот у нас есть
вызов сабворка в цикле, и вроде бы вложенная функция, вложенная функция — это вызов коррутины,
вот этот вызов — это вызов коррутины, это значит аллокация, по идее, ее стекового фрейма на куче,
динамическая аллокация. Но с другой стороны, тут же динамические аллокации вроде как не нужны,
потому что все друг друга вложено логически, ну, то есть у нас такое структурное программирование,
вложенные вызовы, вызовы вложены друг к другу, образуют иерархию такую. Поэтому зачем нужен final
suspend? Когда на самом деле коррутина сабворк разрушается, вот в этом примере, в реализации
таска, она разрушается в деструктуре таска. Когда таск разрушается, тогда вызывается дестроид
для коррутины. И вот это важно к империатору. Почему? Потому что, смотрите, при вызове сабворк
компилиатор понимает, что нужно алоцировать state для дочерней коррутины, а при разрушении объекта
таск, локальной переменной, компилиатор понимает, что коррутина, что дочерняя коррутина разрушается.
Ну, как бы сам таск позаботился, чтобы это было корректно. И все, теперь компилиатор знает,
что lifetime вложенной коррутины покрывается lifetime-ом нашей коррутины. Вот за счет того,
что мы это явно написали своими руками в деструктуре. Явно вызвали destroy, не the read this,
который для компилиатора плохо предсказуем, а вот прямо destroy нашими руками, нашими в смысле
родительской коррутины. Понимаете, о чем я? То есть, есть цикл, в нем есть внутри аллокация state,
а потом разрушение state. И компилиатор понимает, что на самом деле lifetime вложены, и поэтому за счет
этого он inline state дочерней коррутины в родительскую коррутину. И в итоге у вас как бы есть цепочка
вызовов. Ну, вот такая тут цепочка из одного вызова, а может быть вот такая вот. И компилиатор,
если в коде с тасками, знает, что все эти вызовы образуют иерархию вложенной друг друга, и поэтому не
нужно алоцировать state для коррутины каждый раз новый. Нужно просто zinline-ить все в один. И в итоге
у нас получается такой большой коррутин state для родительской коррутины, в которой вложены,
по сути, стейты всех дочерних коррутин. Ну и там еще компилиатор, это может как-то пооптимизировать.
Он понимает, потому что мы пишем не future, а мы пишем task, а в task есть destroy, и этот destroy
появляется как бы в скопе родительской функции. Ну, видимо, компилиаторы понимают,
что mkRouting все-таки инициализирована, потому что если она не инициализирована,
в общем, компилиатору будет ясно, что в mkRouting что-то есть. Вот за счет того, что компилиатор знает,
что lifetime вложены, потому что мы воспользовались вот этим final suspend, то он может применить вот
эту иуристику с вкладыванием стейтов и избежать динамических локаций. И в итоге в этом синхронном
коде, написанном на тасках, в этом коде написанном на тасках динамических локаций не будет вообще.
Вот, и это хорошо. Ну а если они нужны, если мы все-таки синхронный код пишем, то там локации
уже будут, потому что lifetime уже не будут вложены друг в друга. Ну, например, не будут вложены.
Вот. С другой стороны, есть некоторая проблема, что решение о том, алоцировать ли динамический
память или нет, то есть где размещать коротин стейт на стеке текущего вызова или динамической
памяти, решает сам компилиатор. И мы, разработчики, этим не управляем. А мы в C++ к такому не привыкли.
Мы привыкли, что мы всем управляем. Где байтики скопируются, где память алоцируется, где сторож каждого
объекта. Вот для крутины мы такую возможность теряем, и это одна из причин, почему этот дизайн
критикуют. Потому что мы доверяем оптимизации компилиатора, мы не можем управлять этим сами. Ну,
вообще говоря, это проблема в хорошем дизайне. Здесь вот он такой. То есть, возможно, я вам только
что объяснял какие-то кастыри полчаса. Ну, так тоже на это можно смотреть в каком-то смысле. Вот.
Но, тем не менее, в C++ у нас вот такая вот механика. Вот есть эти промесы, есть вот эти таски,
которые к крутиным должны обязательно быть, и с помощью них можно крутины комбинировать.
Ну, runtime нужен, вот вся эта история. Может быть, последнее замечание такое лирическое отступление
совсем про другое, чтобы вы почувствовали связь. На лекции про future мы делали future, и мы их
связывали в цепочке с помощью зэнов. А еще мы говорили, что вот есть обработка ошибок, есть
result, или есть там expected C++, каким он будет. И для него, в общем, тоже нужно... секунду...
Мне нужен expected. А у меня нет expected, да? С другой стороны, есть обработка ошибок.
И expected или result и future, они друг на друга похожи. Потому что есть операция связывания,
есть контейнер для значения, resultT или futureT, и есть функция, которая ожидает распакованного
значения. Просто T на входе. И в случае с future мы используем комбинатор Zen специальный. В случае
с result мы проверяем, что в result, в expected здесь нет ошибки, и вот передаем распакованные значения.
Ну, так или иначе, возникает такая логика связывания. И вот для result ее тоже можно переписать
в таком вот виде, с помощью опять зэнов. Ну, map and zen, там есть некоторая тонкая разница. Давайте
сейчас не будем подробностей. Важно, что вот и result и future — это представители вот одного
некоторого такого класса, общего класса монады, который описывает контейнер, ну и определенные
правила связывания. А теперь вспомним следующее, что... Ну, я когда говорил про то, где монады
появились, говорил про то, что они появились... У меня их аскера здесь нет, что ли? Не может быть.
Кто готовил эту реакцию? Ну, допустим, что-нибудь найдется хорошее, да? Ну, что-то мне хотелось бы
более оформленное. Да, для монад в хаскере есть удобный синтактический сахар до нотации,
где вот делаются такие как будто бы императивные шаги последовательные, а на самом деле есть
функциональная композиция, которая просто скрыта от пользователя. Вот, то есть есть удобный синтаксис
общий для произвольных монад, то есть для типов, которые там реализуют некоторый контракт. Так вот,
смотрите, future — это монада, и result — это монада, и есть некоторый синтаксис у нас, который позволяет,
скажем, подождать future. И я говорю, что этот синтаксис коэвейт, он реализован на уровне, ну вот
коэвейт — это языковая фича, которая от конкретной семантики избавлена, то есть просто овейтерам задается
поведение корутины в точке коэвейта. Ну, видимо, можно через коэвейт, в коэвейте поддержать не
только какие-то примитивы для асинхронности, а еще и вот тот же самый result или тот же самый
expected и писать код. Ну, это у меня точно есть. Вот так вот. Смотрите, у нас есть функция f1,
она возвращает значение int или ошибку. Есть функция f2, которая ожидает просто int. И вот нам
нужно их связать. Что здесь происходит? f1 возвращает expected. А что делает коэвейт? Он либо
распаковывает expected в int, либо просто корутину останавливает, завершает ее. И здесь уже мы
вызываем f2 от x, где x — это int. Получаем expected, распаковываем его с помощью коэвейта. Короче,
коэвейт — он называется коэвейт, но ko потому что обратная совместимость, все такое, а вейт
потому что как будто бы чего-то ждем. Это, понятно, про асинхронность, мы чего-то ждем. Но на самом деле
коэвейт абсолютно свободен от такой семантики ожидания, и можно вложить в нее другое поведение
и реализовать вот такую поддержку для обработки ошибок, чтобы не писать вот эти if. То есть вместо
вот этого кода и вместо этого кода можно писать еще и вот такой код. Так они спрятаны в этом и
смысл. Их здесь, в этом коде ошибок нет. В этом коде нет expected. То есть expected появляется после
вызова из функции f1, и он разворачивается с помощью коэвейта в просто значение типа x. Здесь интересно,
что вот этот коэвейт — это вот механизм для манипуляции потоком управления. Мы в коэвейте для
фьючей останавливали корутину и потом возобновляли ее где-то в каком-то пуле потоков. Здесь мы
останавливаем корутину, либо сразу же ее продолжаем. То есть коэвейт на expected, где в котором
содержится значение, просто в await ready говорит true. А в await suspend, видимо, корутину нужно просто
разрушить. Потому что все, вот мы вышли из корутины. Ошибка. Вот, так что механизм на самом деле более
общий. Нужно видеть, что вот если вы видите монады, если вы видите синтез, из которой похож на донотацию,
видимо, можно это все в голове совместить и поддержать. Обобщить коэвейт на... и произвольные монады
тоже на result можно обобщить. На result, на expect. Ну что ж, пожалуй, на этом все. Спасибо вам.
Ну можно на вопросы задавать еще, если они у вас есть, конечно.
Ну что ты делаешь, когда ты увидишь ошибку в функции? Ты из нее выходишь, покидаешь эту функцию. Она проклята. Ну вот.
Ну я не знаю. Ты пишешь ассинхронный эхо-сервер. Там есть async-write. А async-write может в цикле звать
async-write-sum. Ну потому что не бывает write в сокет неограниченного размера. Может быть write
какой-то частичный. Ну вот, например. Ну это не значит, что это лучшая реализация, но это вот какая-то реализация.
Ну или просто у тебя функция, которая там обращается к пяти подряд микросервисом. К первому,
ко второму, к третьему. Ты любишь микросервисы. А потом ты вот пишешь еще какую-то логику сверху,
но в общем, все это. Можно декомпозировать и выделять функции. Поэтому такая задача возникает.
Задача, в смысле, вызывать синхронные функции. Ну и там появляется таск, и вот вся эта история.
Проблема какая?
Ну почему он не нужен? Ну какая разница? У нас ошибка, то есть optional или expect. Проблема тут
скорее в другом. Она в том, что очень сложно в одном коде жить. Смотрите, у нас есть future,
в чем подвох. У нас есть future, мы дожидаемся ее, распаковываем ваш табл result. А теперь нужно
распаковывать result. Что сделано в Rust? В Rust нет универсального такого монодического синтаксиса,
там есть для... ну ладно, опять я проиграл. В Rust есть оператор вопросик. Сейчас мы его найдем.
Вот, мы открываем файл, и Бог знает, чем это может завершиться. Файла может не быть,
файл может быть на сетевом устройстве, у нас сейчас нет интернета, но ошибка может возникнуть,
поэтому нам возвращает result. Если ошибка возникла, то мы, может быть, не хотим продолжать эту
функцию, мы хотим вернуть ее наверх. Но мы не хотим писать return голыми руками, поэтому нам нужна
некоторая поддержка, то есть поддержка вот такого control flow. Ну вот C++ мы бы написали уродливый
макрос, оборачивающий весь этот вызов, и это совершенно непригодно для жизни. Вот в Rust
сделали специальный оператор вопрос, который, получая result, распаковывает его в том смысле,
что если в result была ошибка, то мы пробрасываем ее на уровень вверх, выходим из текущей функции.
А для future там есть await, и он очень любопытный, есть ли здесь await, кстати. Ну что ж.
Ну я хочу более интересный пример.
Я хочу await со знаком вопроса.
Я не сомневаюсь.
Ладно. Смотрите, что... Ну я попытаюсь сейчас найти еще. Смотрите, что интересно. Await — это
ключевое слово, да? Ну то есть с помощью него, с помощью такого синтактического маркера компилятор
понимает, что перед ним не просто функция, а какая-то особенная функция, асинхронная,
которая умеет останавливаться и нужно ее переписать в автомат. И в большинстве языков,
которые поддерживают вот такую асинхронность из теклос корутины — это ключевое слово await,
и оно ставится перед выражением C++, оно еще изуродовано вот этим ко, но бог с ним.
Суть не меняется. В расти поступили очень интересно, там ключевое слово await с точки
начинается и постфиксное. Это, кажется, первый такой мейнстрим язык, который взял и сделал себе
ключевое слово, начиная с точки и постфиксное, похожее на вызов метода. Там очень долго на это
решались, там полгода думали, обсуждали, писали просто обсуждения на форумах, но в конце концов
решились. И почему? Потому что у них была проблема, что, ну вот смотрите, у нас есть await,
который распаковывает future, а есть вопросик, который распаковывает result, а future распаковывается
в result обычно. И как написать асинхронную функцию, которая распаковывает сначала future, а потом result?
Вот писать await, потом скобочки, потом вопросик — это совершенно мучительно. Вот поэтому они
решили сделать постфиксный вызов, чтобы это все хорошо чейнилось. Это совершенно блестящая идея,
абсолютно безумная на первый взгляд, ну в смысле делать такое ключевое слово. Но вот они решили,
что у языка любого есть такой бюджет на странности, его тратить очень нужно осторожно, чтобы люди не
отпугнуть от своего языка. Но вот в этом месте нужно его потратить, потому что это самое лучшее
решение. Довольно смелый дизайн, но вот он в итоге реализовался. Я вот хотел найти await с вопросиком,
но почему-то мне примеры не показывают. Вот, то есть один универсальный синтаксис, возможно,
это не самая лучшая идея, то есть она не решает всех проблем. Это скорее, ну вот это скорее,
конечно, баловство, чем... Нет, expect — это не баловство, это очень серьезно. Вот это скорее
баловство. Но если это баловство так серьезно обдумать, то можно получить другой немного синтаксис,
но при этом смысл будет тот же самый. Мы вот реализуем такую специальную нотацию,
которая распаковывает контейнеры, которые делают связывания вот для мэн. Еще, может быть, вопрос?
Мы про... Я не знаю, может быть, задачку сделаем про него, а может быть, может быть, нет. Ну,
в C++ много всего интересного. Мы все-таки фокусируемся на ассинхронных применениях.
— А койоут? — Ну койоут — это ж про генераторы история.
Ну, питон тут ни при чем. Питон — это всего лишь язык, в котором есть стеклоскрутина. То есть,
в смысле он здесь ничем не отличается. Можно сказать, что питон в C++ можно говорить теперь.
Вот. Ну, это иронично, конечно. То есть, не то чтобы вот как в питоне. Питон — это просто
иллюстрация вот одного общего подхода — стеклосподхода до корутина.
Ну что, если вопросы закончились, то можно я последнее покажу вам, если сейчас найду быстро.
Документация буста. Ну ладно, сойдет. Вдруг мне… Короче, ну такой спойлер. Я надеюсь,
что про это сделаю задачку, не обещаю, но очень постараюсь. Это скорее в мае случится,
когда уже можно баллостом заниматься. Можно написать на C++ стеклоскрутина на макросах. Ну,
как бы, стеклоскрутина — это же преобразование вот… Ну кодогенерация, по сути, мы берем вот одно
описание, встроим другое описание. Как делается кодогенерация на C++? Макросы. Для этого макросы
и нужны C++, чтобы код писать автоматически. Ну вот, можно написать такие хитрые макросы,
чтобы код был… выглядел бы как вот корутиный, написать там свои авейты, и в итоге получится
корутина. И кажется, что ASIO то ли поддерживал, то ли поддерживает вот такой API на вот этих своих
макросных корутинах для библиотеки. Я не думаю, что им сейчас это нужно, потому что зачем уже есть
плюсовые корутины, нужно использовать их. Ну… Нет, по-моему, это… Ну ладно, я не буду врать. Ну в
общем, так можно, и можно ради любопытств попробовать переписать это все своими руками. Там очень
любопытные вещи возникают. Как можно… Это даже не макрос, это макрос, это давдевайс. Там расширяет
сознание, если можно так сказать. Ну в общем, если получится, мы это попробуем сделать. А так вот,
по плану, я думаю, что совсем скоро, в ближайшие дни даже, я выложу задачу про то, чтобы сделать вот…
Потерялся. Вот такие корутины, у которых есть… Ну, «гор-рутина», в смысле, корутины имени Гора
Нишанова, в которых есть мютексы, в которых есть вейт-группы, которые умеют работать с нашим
пулом потоков, с нашим, ну в смысле, нашим плохим и вашим будущим хорошим. Вот, с произвольными
экзекьюторами. И к ним мы отдельной задачкой напишем класс-таск, а потом все это можно вместе
собрать, и потом вместе можно создать вообще большую библиотеку, где будет все, и все будет
друг с другом сочетаться. Так что, пожалуйста, попробуйте это сделать. У нас осталось не очень
много времени, к сожалению, но вот то, что можно сделать, можно сделать еще очень много и очень
сложно, поэтому вот, не знаю, выберите, что вам по вкусу. Я все еще рекомендую делать планировщик
прямо сейчас, потому что, ну, это же огромная радость пооптимизировать вот весь этот код,
который мы пишем сейчас. Все наши файбер. Все, закругляемся.
