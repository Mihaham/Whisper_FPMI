И на самом деле вот так решается любая задача из контрольной.
Очень просто.
Абсолютно таким образом. Не беспокойтесь, все будет нормально.
А теперь давайте перейдем к лекции.
Сегодня мы продолжим обсуждать задачи RMQ и RSQ.
Но перед этим нам необходимо поговорить про бинарные деревья поиска.
В принципе, я мог воспользоваться вашими текущими знаниями и сказать,
что в прошлом семестре вы изучали бинарные деревья поиска.
Например, AVL дерево, Splay дерево.
Но я поступлю по-другому. Сегодня я рассмотрю еще одно дерево поиска.
По нескольким причинам. С одной стороны, по педагогическим.
Потому что в прошлом семестре вы изучали AVL дерево.
Напомню, что AVL дерево дает строгую гарантию того,
что у вас любая операция, ставки, удаление поиска занимает логарифмическое время.
Потом вы изучали Splay дерево.
Splay дерево уже не гарантирует, что каждая операция будет занимать логарифмическое время.
Но она, скажем так, дает амортизационную логарифмическую стоимость каждой операции.
То есть это означает, что какое бы количество операций вы ни сделали,
если вы просуммируете их время работы, то в сумме это будет неотличимо от того,
как бы каждая операция выполнялась за логарифм.
Соответственно, у нас есть дерево, которое работает в худшем случае за логарифм.
Есть дерево, которое работает в амортизированном случае.
В случае амортизационного анализа за логарифм.
И есть еще одна ипостась анализа алгоритмов.
Какую мы еще не рассматривали.
Сложность бывает в худшем случае, в амортизированном смысле и в среднем.
Если у вас в алгоритме есть какая-то рандомизация,
то мы можем говорить о том, что алгоритм работает за такое-то время в среднем.
Если мы несколько раз запустим алгоритм и потом в среднем все это время работает,
то мы получим определенную величину.
Давайте рассмотрим пример такого дерева.
Если вы в прошлом семестре не писали бинарные деревья поиска,
то сейчас мы изучим еще одно дерево поиска, которое, на мой взгляд, гораздо более простое,
чем те, которые изучали до этого.
Если вы до этого дерева поиска не писали, то хороший повод начать.
Сегодня мы говорим про дикартовое дерево.
Начнем с определения.
Дикартовое дерево – это структура данных в виде бинарного дерева,
которая хранит пары.
Как правило, первый элемент пары называют ключом.
Пары ключ и у называют приоритетом.
Структура данных, которая хранит пары x, y,
является бинарным деревом поиска по x.
То есть по ключам эта структура данных является бинарным деревом поиска.
А по y – бинарной кучей или пирамидой.
То есть можно сказать, что дикартовое дерево – это структура данных,
которая является два в одном.
То есть она одновременно и бинарное дерево поиска, и куча по минимуму.
Иногда из-за этого ее называют в англоязычной литературе «trip»
от слова «tree» плюс «hip».
Ну, в розыскоязычной, как только не коверкают,
в общем, дуча, дирамида, курева и так далее.
Давайте привезем пример того, что мы на самом деле ввели,
что это такая структура данных.
Давайте рассмотрим какое-нибудь дерево.
Вот это бинарное дерево.
Ну и давайте напишем какие-нибудь значения в узлах этого дерева.
Значит, что мы знаем?
Мы знаем, что эта структура данных является деревом поиска по x.
То есть давайте напишем какие-нибудь значения.
То есть тут один, тут два, тут нет, тут два.
Дальше пусть четыре, пять, семь, восемь, девять, десять, одиннадцать.
Ну, кажется так.
То есть в каждом узле, точнее говоря, в каждом подделье
дерево выполняется свойство бинарного дерева поиска.
Ну и давайте напишем приоритеты.
Ну, давайте для общности считать, что у нас эта структура данных
является кучей и по минимуму.
То есть в корне всегда хранится минимум.
Ну, давайте нуль, один, пять, восемь, десять, одиннадцать.
Два, три, четыре.
Вот.
Соответственно, вот эта структура данных, которая хранит в себе пары
один, пять, два, один, пять, восемь, четыре, десять, семь,
одиннадцать, десять, четыре, одиннадцать, три и так далее.
Вот пример. То есть по x, по первому элементу пар
она является бинарным деревом поиска, по второму элементу пар
она является бинарной пирамидой с минимумом в корне.
Вот.
Давайте, ну, не докажем, а просто
я расскажу некоторые утверждения про дикартовое дерево,
которое нам еще поможет.
Значит, пусть x и не равно y и y и не равно y и g
для любых пар i и g,
тогда дикартовое дерево
по парам x и y и
строится единственным образом.
Ну, короче, если вам даны пары,
и там все ключи уникальные, плюс все приоритеты уникальные,
то в этом случае у вас дикартовое дерево,
ну, то есть его сразу можно восстановить,
то есть оно имеет единственный вид.
Ну, доказательств не доказательств, давайте просто
поймем это геометрически и заодно
наконец разберемся, почему дикартовое дерево
называют дикартовым деревом.
Давайте на координатной плоскости отложим
наши элементы, то есть наши пары,
ну, непосредственно вот на картинке.
Ну, давайте вот, получится этот пример.
Ну, давайте прямо этот пример.
Значит, у нас есть...
Давайте пусть y вниз растет.
Ну, давайте примерно хотя бы 8, 0,
где-то здесь,
значит, где-то здесь одна вершина,
здесь другая вершина.
Значит, 5,
и, и, и.
Ну, как-то так.
Вот, и что мы сделаем?
Давайте возьмем все эти пары и просто набросаем
на координатную плоскость, окей?
Вот.
Изобразили так.
Значит, вопрос.
И мы из этой картинки хотим сейчас построить
дикартовое дерево.
Знаем ли мы, какая вершина
будет корнем этого дерева?
Какая?
Да, у которой наименьший приоритет.
То есть мы знаем, что так как
дикартовое дерево является кучей по минимуму,
то есть бинарной пирамидой по минимуму,
то значит, что в корне обязательно должен стоять
элемент с минимальным приоритетом,
то есть с минимальным y. То есть у нас корень
дерева восстанавливается однозначно.
Так.
А что можно сказать дальше?
Что можно сказать про остальные точки?
А остальные точки разобьются
строго на две группы.
Давайте проведем здесь
вот такую вертикальную линию.
То есть мы знаем, что так как наша структура данных
должна являться бинарным деревом поиска,
то есть знать, что все элементы больше вот этого
x-а должны пойти вправо,
а все элементы меньше x-а должны пойти
влево. Согласны?
То есть мы однозначно, во-первых,
останавливаем корень, а во-вторых, однозначно
отправляем элементы направо и отправляем элементы налево.
Окей?
А что мы делаем дальше?
Да, ну а дальше просто рекурсивно применяемся к левой части
и правой части. Окей?
То есть здесь вершина
с минимальным приоритетом,
она является левым сыном.
Здесь вершина с минимальным приоритетом,
поэтому строится так.
Ну и аналогично.
Здесь разделяем на лево и право по дереву,
налево и право, и так далее.
Ну давайте, восстановим здесь так,
здесь так, здесь так,
вот так.
То есть корень каждого по дереву мы
определяем однозначно.
И плюс элементы относятся либо к левой части
с правой часть, тоже однозначно. Соответственно, дерево тоже однозначно
останавливается по всем парам x и y. Но, естественно, если ключи уй, то для уникальных clues.
На самом деле, если они rabbits, тоым ă убеждение верно и
нужно определиться с тем, что делать, если у вас одинаковые y&y.
Какую вершину вы будете отправить к правому дереву, либо будут行uks
равные элементы влево по дереву и так далее. Ясно, да? Окей. Так, ну и чего? Ну, смотрите, вроде как, вроде как
мы, то есть в начале лекции я сказал, что мы хотим построить некоторое бинарное дерево поиска.
Ну, построили нечто большее, да, то есть мы построили вроде бинарное дерево поиска и плюс там
некоторую кучу. Да, то есть что, если мне хочется там только бинарное дерево поиска? Зачем мне, ну то есть
откуда мне брать приоритеты? Зачем они мне нужны? Так вот, приоритеты на самом деле сейчас мне будут
гарантировать, что у меня дерево в среднем будет хорошим. То есть приоритеты, они на самом деле
будут балансировать мое дерево. Давайте докажем следующую теорему. Значит, откуда тут в зекартовом
деле возьмется случайность? А вот отсюда. Значит, пусть у сгенерированы случайно и независимо
друг от друга и иксов. Что это значит? Это значит, что мне приходит какой-то икс и я просто для каждого
у подбрасываю монетку. Какое-то из значения, да, просто генеру абсолютно рандомное число, которое
вообще никак не зависит от того, какие у меня до этого были иксы сгенерированы и вообще никак не
зависит от того, какие у меня вообще есть иксы. То есть у абсолютно случайны, окей? Что тогда? Ну,
давайте еще одно условие напишем, формально оно, наверное, тут нужно, что вероятность того, что y
и равен y g, ну при и условии, что и не равны g должна быть равна нулю. Ну, просто чтобы не заморачиваться с
одинаковыми приоритетами, скажем, что приоритеты сгенерированы случайно, они не равны друг другу. Так вот
оказывается, что тогда средняя для любого икс, средняя глубина икса, вот что такое dx? Давайте поясним.
Вот у меня где-то есть икс, и вот dx это вот, это вот расстояние от корня до этой самой вершины. Ну,
то есть глубина, на которой находится икс, окей? Тогда средняя глубина для любой вершины икс,
ее средняя глубина будет являться о большим, вот логарифма n. Ну, где n, естественно, это
общее количество элементов в нашей структуре данных. Вот. Значит, прежде чем перейдем к доказательству,
я хочу, чтобы все понимали, в чем состоит условие данной теоремы. Вопрос, верно ли,
что эта теорема утверждает, что у вас средняя глубина дерева логарифмическая?
Правда или нет? Можно ли на основании теоремы сделать вывод, что, там, если вы построите дерево
со случайными приоритетами, то есть выберете эти приоритеты случайно, то у вас средняя
глубина дерева всегда будет логарифмической. Ну, вообще говоря, неправда. И это важный момент. То
есть эта теорема это не утверждает. То есть из этой теоремы не следует то, что если вы сгенирируете
кучу деревьев и потом усредните все глубины этих деревьев, то есть максимальную глубину этих
деревьев, то вы получите логарифм. Это неправда. Ну, почему? Давайте просто сгенирием кучу деревьев,
то есть контрпример, да? Можно сгенить кучу деревьев и посмотреть, куда попадает x. То есть x может
попасть сюда, сюда, сюда, ну и там какой-то один момент здесь. То есть средняя глубина x вроде
как, средняя глубина x вроде нормальная, да? Но при этом у вас каждое дерево, в свою очередь,
оно глубокое, да? Понятно? То есть x, то есть когда мы берем dx, мы берем глубину конкретного элемента.
Когда мы считаем глубину дерева, мы должны здесь формально написать максимум среди всех x dx, да?
То есть согласны, что это разные функции. Взять какой-то произвольный x и взять его среднее,
или взять среднее среди максимумов. Естественно, среднее максимумов оно будет больше. Ну, забегая
вперед, скажу, что на самом деле для глубины это верно. Вот, просто доказать чуть более сложное,
и оно нам не понадобится, то есть нам будет достаточно вот этого утверждения. Так, давайте перейдем к
доказательству. Блин, я забыл посмотреть, как вы в прошлом семестре доказывали быструю сортировку.
Просто эту теорию можно доказать в одну строчку, просто сведя ее к быстрой сортировке. Вы доказывали,
что средняя глубина рекурсии логарифмы или как-то по-другому?
Ладно, все, я понял. Ладно, давайте докажем честно. Доказать следующее. Смотрите, доказывать будем так.
Назовем узел, ну или корень под дерево. Каждый узел, ну, я надеюсь, вы понимаете,
каждый узел является корнем некоторого под дерева. То есть вот этот узел является корнем вот этого под
дерева и так далее. Назовем узел или корень под дерева хорошим, если размеры его под деревьев,
отличаются не более чем в три раза. Ну, что это означает? Это означает, что вот у меня есть какой-то
узел, вот тут есть одно под дерево и есть другое под деревом. Давайте скажем, что общее количество
элементов здесь N. Так вот, узел вот это будем называть хорошим, если у вас здесь больше чем N на 4
элемента и тут больше чем N на 4 элемента. Ну то есть у вас могут быть плохие разбиения, то есть у вас
может быть плохое разбиение, что вот тут один узел, а тут целое огромное под дерево. Вот этот плохой узел,
он не сильно хорошо разбил нам наши элементы. А вот если тут хотя бы N на 4 элементы, а тут 3 N
на 4, то все нормально, окей? Вот, теперь вопрос вам. Пусть в под дереве N элементов с какой
вероятностью корень хороший? Ну вот вы берете произвольное, вы смотрите на произвольное под
дерево. Почему? Так, ответ был с вероятностью на второе, почему? Ну да, смотрите, вот давайте просто
рассмотрим вот элементы под дерево. Ну вот пусть они упорядочены по возрастанию. Значит, какие элементы
какие элементы в качестве корня меня устраивают? Как сделать так, чтобы у меня соотношение было хотя
бы один к трем? То есть устраивает ли меня вот этот элемент? Ну нет, он какой-то плохой, да, он
разобьет вот этот маленький кусок и все остальное. А какие элементы меня устраивают? Ну на самом деле
меня устраивают элементы, которые расположены на расстоянии как раз таки N на 4 отсюда и N на 4 отсюда,
согласны? То есть если я возьму любой элемент из середины размер N пополам, то то есть я беру
допустим этот элемент, то у меня как раз таки получается так, что я беру вот эти элементы,
то есть размер этого под дерево больше чем N на 4 и вот это под дерево, размер которого тоже больше
чем N на 4. То есть меня устраивают только вот эти центральные элементы. А теперь вопрос, с какой
вероятностью у меня корнем под дерево будет один из этих элементов? Сверять сюда вторая, почему?
Ну ровно половина, ну а почему не может быть такого, что у меня вот эти элементы будут
браться с большей вероятностью, чем эти? Ну потому что я приоритет генерирую случайно, да, то есть за
корень дерева всегда отвечает только на имение приоритетный элемент. То есть определить то,
является элемент корнем или нет, мы можем только исходя вот его приоритета. А так приоритетами
генерируем случайно, то есть знать, что вообще произвольный элемент с равной вероятностью может
стать корнем. Согласны? Давайте зафиксируем. Любой элемент может быть корнем с равной...
Этот тезис понятен или пояснить еще раз? Так мы приоритет выбираем случайно, ну а за корень
нас отвечает только приоритет, только приоритет у нас выбирает корень. Приоритет мы выбираем
абсолютно случайно и независимо, поэтому абсолютно любой элемент с равной вероятостью может стать
корнем. Из этого следует, что корень хороший с вероятностью... Давайте напишем примерно 1 вторая.
Почему примерно? Потому что тут может нацело не разделиться и так далее, но на это забиваем.
Давайте просто напишем 1 вторая. Вот, ну все. Значит вероятно все 1 вторая, у нас узел хороший.
Ну а теперь давайте просто возьмем и посмотрим на глубину элемента х. Значит вот у меня есть
какое-то дерево, в нем есть где-то элемент х. Чтобы добраться до х, мы должны проделать какой-то путь.
Из чего состоит этот путь? Он состоит из хороших узлов и из плохих узлов, согласны?
То есть это D плюс х плюс D минус х. Ну это вот хорошие, а это плохие.
Вот. Что мы можем сказать про среднее значение хороших узлов? Вот на пути от корня до вершины х.
Сколько в среднем у нас... Точнее не сколько, а вот что можно сказать про количество в среднем
хороших узлов? Ну не то, что 1 вторая, а их примерно столько же, сколько и плохих. Согласны? То есть
во-первых, можно сказать вот так. Ну потому что с вероятностью 1 вторая я встречаю хороший узел и
с вероятностью 1 вторая я встречаю плохой узел. Поэтому на этом пути у меня примерно одинаково
количество и хороших, и плохих узлов. Ну точнее в среднем строгое равенство. Вот. А что еще
можем сказать? Можем ли мы как-то ограничить количество хороших узлов сверху? Вот. Может ли
быть такое, что вот я иду от корня до х и у меня встречается прямо очень-очень много хороших
узлов? То есть верно ли, что хорошего может быть много? К сожалению, нет. Почему? Ну их нет пополам,
их гораздо меньше на самом деле. Ну смотрите, что происходит, когда я нахожусь, вот давайте я
нахожусь в корне. Точнее давайте так. Вот я нахожусь в хорошем узле. Всего элементов у меня изначально
n. Я попадаю вот из хорошего узла в какое-то поддерево. Что я могу сказать про его размер?
Ну он точно меньше либо равен чем 3n на 4. Согласны? Так как размер у меня каждого поддерева больше
равен чем n на 4, значит размер каждого поддерева меньше равен чем 3n на 4. Согласны? Хорошо. Дальше. Я
где-то здесь снова встречаю хороший узел. Что можно сказать про размер поддерева, в который я попадаю?
Да, но он снова уменьшается в четыре третьих раза. Согласны? То есть если я иду из хорошего
узла в какое-то поддерево, то я размер моего дерева уменьшаю как минимум в четыре третьих
раза. Согласны? А много ли я так могу раз сделать? Вот у меня есть число n. Могу ли я бесконечный
количество раз его уменьшать в четыре третьих раза? Ну нет, в какой-то момент я паду в отдельную вершину.
Да? То есть на самом деле количество хороших шагов сколько? Да, не более чем логарифм. Ну давайте
напишем четыре третьих от n. Ну кажется все. Остался последний штрих. Как раз таки давайте
посчитаем чему равен средняя длина пути от корня до х. Ну это просто равняется двум.
D плюс от х. Понятно почему, да? Ну мы берем средние от этой, средние от этой штуки, но средние эти равны,
поэтому просто вдваем эту штуку. А что можно сказать про средние от D плюс? Ну так как сам D плюс не
больше чем логарифм, то и средние от D плюса тоже не больше чем логарифм. Да? Поэтому это очень не
более чем логарифм n. Ну все, доказали. Вопросы? Все понятно. Ну и на самом деле,
давайте замечания напишем.
Верно и то,
что средняя глубина декартового дерева вычисляется вот так. Есть и большое от логарифма n. Но доказательство
чуть более сложное и в общем оно нам не надо. Ну то есть план использования декартового дерева на
самом деле очень прост. Если вам нужно бинарное дерево поиска, то вы делаете следующую вещь. Ну вот
у вас есть х, то есть вам х уже даны, и вы просто для каждого х случайно генерируете y. И дальше на
основе этих пар x и y строите декартовое дерево. И декартовое дерево заодно как раз вам построит
бинарное дерево поиска, которое ищет по иксам. Ну и осталось самое главное это разобраться как
с этим декартом дерева работать. Как туда вставлять элементы, как оттуда удалять элементы и так далее.
Ну в общем хорошая новость заключается в том, что строго говоря нам понадобится всего две операции,
через которые мы выведем вообще все-все-все, что нам понадобится на сегодняшней лекции. И этих
операций две. Операции merge и split. Про что сначала поговорим? Давайте про merge. Что делает эта
операция? Значит merge принимает два декартовых дерева, ну или два корня декартовых дерева,
таких что все ключи одного дерева строго меньше ключей второго. То есть она принимает два декартовых
дерева и объединяет их в одно декартовое дерево. То есть у вас есть два декартовых дерева,
одно второе. Известно, что все ключи здесь строго меньше, чем все ключи здесь, и вы можете к ним
применить операцию merge и получить одно большое декартовое дерево. Давайте разбираться как это
работает. С алгоритм простой и рекурсивный merge от t1 и t2. Ну давайте изобразим. Вот есть t1,
есть t2, одно дерево, второе, одно, второе. Все ключи здесь, допустим, меньше, чем все ключи в t2.
Так, вопрос вам. Ну то есть алгоритм я сказал рекурсивный. С чего мы начинаем любой рекурсивный
алгоритм? Да, условия выхода из рекурсии. Значит давайте так. Вот самый простой вариант. Какие два
дерева очень легко слить? Пустые, это слишком просто. Давайте что-нибудь посложнее. Что? Это сложно,
давайте что-нибудь попроще. Два единичных, сложно. Давайте чуть-чуть усложним два пустых дерева. Одно
пустое, отлично. Ну понимаете, что делать если у вас одно пустое дерево? Вернуть второе просто,
в качестве ответа. Ну как слить пустое дерево с каким-то другим? Просто вернуть другое. Давайте этим
займемся. Если t1 0, то просто return t2. Аналогично, если t2 0, то return t1. Все. Так, халява закончилась,
теперь давайте что-то делать. Известно, что после этих двух ифов у нас два дерева не пустых. Что делать?
Давайте просто возьмем и выберем корень. Что будет корнем общего дерева? Понятно, что это будет
либо t1, либо вот этот элемент, либо вот этот элемент. А вот кто из них, как понять? Как понять,
что будет корнем дерева? Нам достаточно всего лишь посмотреть на приоритеты. Нам не важно,
каким там ключи, просто достаточно посмотреть на приоритеты. Какой приоритет меньше, тот и будет
корнем. Давайте так и напишем. Значит, если t1 y меньше, чем t2 y, давайте изобразим. Вот есть t1,
у него приоритет меньше, то есть он как бы выше находится. То есть картина какая-то вот такая.
Т1, т2. То что нужно сделать? Ну, во-первых, мы понимаем, что t1 будет корнем дерева. Что будет
слева вот этого корня? Что будет левым сыном этого дерева? Его левый сын. Верно ли, что вот эти
элементы вообще не смогут попасть к нему влево? Ну, понятно, да. Потому что все эти элементы строго
больше, чем t1, и вот эти элементы тоже по условию строго больше, чем t1. Поэтому половину дерева мы уже
знаем. Согласны? А что делать с этими поддеревьями? Да, алгоритм-рекурсивный. Давайте просто наоборот
возьмем и рекурсивно смерджим вот эти части и подвесим в качестве правого поддерева. Согласны?
Ну, давайте так и сделаем. Напишем t1 right. То есть что подвесим в качестве правого поддерева t1?
Просто результат мерджа от t1 right, то есть правое поддерево, смерджим с t2. Ну, давайте еще
будем отдельно хранить родителей. Для каждого узла будем хранить родителей левого сына и
правого сына. Это нам еще понадобится. Вот. И это равно t1. Вот. Ну, казалось бы, все. И просто return t1.
Что мы сделали? Мы поняли, что корнем общего дерева будет вот этот вот узел t1. Вот. И что мы
делаем? Ну, в качестве левого сына оставляем левого сына. В качестве правого сына просто делаем
результат слияния его правого поддерева и t2. Все. В результате этого слияния нам мердж вернул
какое-то поддерево, в котором все ключи строго больше, чем t1. Ну и, соответственно, это дерево мы
можем уже подвесить в качестве правого сына t1. Ну, ровно это здесь мы и делаем. Да? Ну, и в
качестве результировающего дерева, естественно, возвращаем t1. Потому что это корень. Так, ну и давайте,
чтобы закрепить успех, симметричный случай рассмотрим. Что если у меня все-таки у дерева t2 меньше
приоритет t2, чем у t1? Что в этом случае надо делать? Во-первых, вот с этой веткой ничего делать не надо.
То есть мы знаем, что t2 будет корнем дерева, да? И его правым поддерем останется его правым поддерем.
А что будет выступать у него в качестве левого поддерева? Результат слияния вот этих вот двух деревьев.
Все. То есть t2 left равно merge от t1 и t2 left. У t2 left нужно обновить родителя,
ровно t2. Ну и вернуть в качестве ответа t2. Вот и все. Вот и весь рекуртивный merge.
Ну и в среднем он работает за логарифом по теореме или по замечанию. Ну почему за логарифом?
Потому что на каждом шаге что мы делаем? На каждом шаге мы берем и уменьшаем глубину
дерева на единицу. Согласны? Ну на единицу уменьшаем глубину одного из деревьев. Вот и все.
Ну ладно, ставим. Так, с merge разобрались. Вопросы есть? Вроде нет. Ну и давайте разберемся с плитом.
Уже всю работу почти сделаем. Так, что такое split? Split принимает дикартовое дерево t и ключ x.
x0 давайте. Split принимает и разбивает t, разбивает дерево t на t1 и t2.
Ну такие, что все ключи в t1 будут меньше x, а все ключи в t2 больше равны x.
Ну то есть неформально split просто берет дерево и разрезает его по элементу x0.
То есть мы берем и разрезаем просто по ключу x0 и получаем два дерева t1 и t2.
Здесь все элементы меньше x, а тут все элементы больше равны x0.
Вот реализация тоже и крутивная и простая.
Так, split tx0. Так, алгоритм будет рекурсивный, условия выхода из рекурсии.
Какое дерево проще всего разрубить? То дерево, которого нет. Отлично.
Если t это null, то что мы должны вернуть? Пару из null и null.
Ну, split у нас возвращает два дерева t1 и t2, поэтому возвращаем пару.
Теперь давайте разбираться с тем, что делать.
Значит, вот у меня есть какое-то дерево t, тут какой-то элемент x, и мне нужно разрубить его по ключу x0.
Давайте сначала эти идеи обсудим, а мы на первый пойдем.
Значит, смотрите, что делать? Что мне делать, если x0?
Ну, получилось так, что x0 больше, чем x.
Что если линия, так скажем, проруба, линия разделения должна происходить как-то вот так?
Ну, не совсем.
Что мне, если x находится здесь?
Ну, разрубить я должен дерево как-то вот справа.
То есть представьте себе дерево, я вот рулю вот так.
Да, да, то есть смотрите, если у меня линия разруба проходит справа, то есть x0 больше, чем x,
то я должен рекурсивно разрубить правое под дерево,
а потом вот левый кусочек прикрепить сюда, а правый кусочек отпустить в свободное плавание.
Согласны?
Ну вот, по сути, и все.
То есть это сейчас после перерыва мы напишем и, собственно, весь алгоритм.
Операция сплит.
Значит, как обсудили, алгоритм простой.
Значит, как разрубить дерево?
Ну, нужно разрубить либо правое под дерево, либо левое под дерево.
Все, то есть рекурсивно.
Давайте условия здесь...
Значит, если в Merge мы там сравнивали приоритеты, то здесь теперь мы будем сравнивать ключи.
То есть если tx меньше, чем x0, то есть если элемент, по которому нам нужно разрубить находится где-то справа,
то что мы должны сделать?
Мы должны, во-первых, разрубить правое под дерево, то есть split t right по x0.
Вот что в итоге получим.
Значит, когда мы разрубили правое под дерево, у нас получается следующая картина.
Значит, есть какое-то левое под дерево, есть какое-то правое под дерево.
При этом известно, что тут все элементы меньше, чем x0, тут все элементы больше, либо разные, чем x0.
Ну, естественно, здесь тоже все элементы меньше, чем x0.
Соответственно, что нужно сделать?
Как собрать ответ? Как собрать t1 и t2?
Ну, Merge слишком сильно, можно проще.
Да, ну просто можно вот это вот дерево подвесить к t в исходном.
Давайте так и сделаем. t right равно l.
Ну и давайте так, если l не равно 0, то l parent равно t.
Ну, просто так могло получиться, что l оказался пустым деревом,
поэтому у него как бы некомильфо брать стрелочку, но тут мы это проверяем.
Так, хорошо, подвесили l к t.
То есть вот такую связь, вот такую связь.
Так, ну у r, ну у r на самом деле мог остаться какой-то фантомный родитель,
поэтому давайте просто-напросто пустим его в свободное плавание.
То есть скажем, что если r не равен 0, то r parent равно 0.
То есть у него нет родителя.
Ну все, и дальше делаем return t и r.
То есть отдельно возвращаем дерево t и дерево r.
Ну и аналогично поступаем с левым под деревом, то есть иначе.
Ну что значит в данном контексте иначе?
Это означает, что у меня есть в корне x, тут какое-то правое под дерево,
тут левое под дерево, и x0 на самом деле должен проходить где-то здесь.
Ну что я в этом случае должен сделать?
Я должен разрубить левое под дерево.
То есть lr равно split t left по x0.
Вот разрубил это под дерево на l и r.
Ну и аналогично r подвешиваю к t, а l отпускаю, ну вот, пусть сам по себе живет.
То есть t left равно r.
Давайте напишем, если r, то r parent равно t.
Если l, то l parent равно 0.
Ну и в этом случае возвращаем пару из l и t.
Здесь tr, там lt.
Ну вот.
Нет, если l.
То есть если l не пуст, то у него есть родители, я могу присовывать ему 0.
Если l 0, то я не могу стрелочку применить.
Ну собственно вот, две основные операции merge и split.
И в основном мы будем работать с ними.
Ну прежде чем идти дальше, давайте собственно обсудим.
Ну хорошо, есть операция split, есть операция merge.
Причем тут вообще бинарные деревья поиска.
То есть родители как бинарные деревья поиска нам обещают, что они умеют делать поиск, умеют делать ставку, умеют делать удаление.
Причем тут merge и split.
Ну про поиск я, думаю, говорить не буду.
Как делать поиск в бинарных деревьях поиска, я думаю, все понимают.
То есть там никаких новшеств нет.
То есть просто идете от корня либо влево, либо вправо.
Давайте обсудим, как делать insert и erase в адекартовом дереве.
Значит, хорошая новость заключается в том, что insert и erase выражается полностью через split и merge.
Давайте поговорим.
Сразу insert, t, x.
У меня есть дерево t, давайте здесь изобразим, есть какое-то дерево t,
и я хочу в него вставить новый элемент x.
Как бы мне это сделать?
Как мне вставить элемент x внутрь дерева t?
Так не получится, смотрите.
Приложение было следующее.
Взять дерево t, построить одно элементное дерево x и смержить их.
Так не получится, потому что merge хочет, чтобы у него два дерева были...
Круг говоря, одно дерево было строго меньше, чем второе.
А вообще говоря, x может быть где-то посередине.
Место x может быть где-то посередине.
Давайте проведем хирургическую операцию.
Сначала разрежем дерево t пополам, а потом и в середину вставим x.
И потом их смержем.
Естественно, предполагаем, что...
Давайте отдельно напишем, что x не принадлежит t.
То есть ключи у нас уникальны.
То есть если у нас x не принадлежит t, то что мы можем сделать?
Ну действительно, давайте разобьем его на левое и правое дерево.
Давайте как-то разумных назовем.
Давайте так t меньше x и t больше x равно split tx.
Вот.
Давайте сразу иллюстрировать.
У меня есть t меньше x, у меня есть t больше x.
Все, и теперь я могу взять x, ну действительно взять вершину x.
Давайте еще один аргумент добавим, x и y.
У меня все-таки дерево хранит пары, поэтому мы вставляем пару x и y.
Ну то есть что я могу сделать?
Я могу теперь смержусь x и t меньше x.
И потом результат смержусь с t больше x.
Все условия для смержа у меня выполняются.
Давайте так и поступим.
Давайте просто напишем так.
return merge от t меньше x и x и y.
Ну предполагается, что это узел.
Я создал узел с x и y.
Ну и потом результат этого мерджа снова смерживаю с t больше x.
Ну то есть собираю обратно сначала, допустим, вот эти элементы.
Получаю какое-то t меньше либо равно x.
И потом мержу вот эти два дерева, получаю финальное дерево.
Ну вот.
Все ясно?
Ну смотрите, зачем нужны это ограничения?
Значит, если у меня x был в исходном дереве, то он бы разделил у меня на дерево меньше x.
И дерево больше или равно x.
И когда бы я мержил, это если я мержу x, то я получаю дерево меньше либо равно x.
И после этого я должен мержить дерево,
в котором все элементы меньше либо равно x,
с элементом, в котором все элементы больше либо равно x.
И вот если и там и там есть элементы,
то вообще говоря ситуация для мерджа, она не выполняется.
Мердж очень строгое неравенство.
Ну то есть это можно починить, но я не хочу в этих деталях углубляться.
В общем, это можно починить.
что все элементы равные x должны уходить в правое под дерево и соответствующим образом изменить лип нам мердж и вставку.
Нам достаточно сета, а не мульти-сета.
Так, ну и удаление erase из дерева t нужно удалить элемент x.
Ну вот снова есть у меня t. Вот тут, кстати, не важно есть у меня x за дереве или нет, тут алгоритм нормально сработает.
Ну, представь себе, что у меня где-то есть в этом дереве x. Вот он где-то лежит в середине. Что нужно сделать?
Давайте так, первый пункт. Предлагаю посплитить по x. Давайте посплитим по x, что мы в итоге получим.
Получим дерево, в котором все элементы меньше x, получим элементы, в котором все элементы больше равные x.
Так, что дальше? Что мержусь? x мы не извлекли. Что можно всплитить?
Можно рекурсивно вызвать erase с права. А условия выхода из рекурсии?
Нет, ну это понятно, что x обязательно будет, x где-то обязательно будет.
Можно, но я хочу просто все выразить через split и merge. То есть так тоже можно.
Ты об этом может в конце поговорим, но давайте это дерево тоже посплитим.
Давайте просто применим к нему split от upper bound от x.
А upper bound от x это первый элемент, который больше x.
Давайте просто-напросто так сделаем, и что в итоге получим?
Здесь получим все элементы, которые строго меньше, чем верхняя граница x.
Но это ровно один элемент x. Так у нас все элементы уникальны.
И получим дерево, в котором все элементы больше x.
А потом просто смержем вот это дерево и вот это дерево. Идея понятна?
Это дерево поиска.
У вас задача в задании есть, как найти upper bound?
Задайте этим вопросам.
Ну upper bound естественно как и lower bound, как и любой элемент,
ищется за алгоритмическое время в дереве поиска.
И это мы делаем с помощью гранитопорядочных элементов.
Что мы делаем сначала?
Мы делим на дерево, в котором все элементы меньше x,
все элементы, которые больше upper bound x, делаем это с помощью сплита дерева t по x.
Дальше нам нужно из вот этого дерева извлечь x.
У нас есть tx, t больше x.
И это мы делаем с помощью сплита t и upper bound от x.
Ну на самом деле, если у вас целые числа, вы вместо upper bound можете взять x плюс 1.
Но если целое число.
Тут я предполагаю, что у вас все-таки дерево произвольное,
то есть оно хребет произвольные ключи, поэтому пишу так.
То есть вы взяли вот это дерево, в котором все элементы больше равны x,
и разбили его на элемент x, и все элементы больше равны x.
Что делаем дальше? Дальше, собственно, можем сделать delete tx,
то есть удалить этот узел,
и в качестве ответа вернуть merge от дерева, в котором все элементы меньше x,
и дерева, в котором все элементы больше x.
t меньше x, t больше x.
Ну вот.
И merge и split у нас работают с средним залогарифом.
Инсерт и рейс мы выразили через сплиты и мержи,
соответственно, они тоже работают с средним залогарифом.
Ну то есть, что такое инсерт?
Инсерт это сплиты два мержа, и рейс это два сплита и мерж.
Каждый сплит и мерж работает с средним залогарифом,
поэтому и общая сложность с средним тоже логарифом.
Все ясно?
Так, ну и последний пункт, который касается такого чистого декартового дерева.
Дальше перейдем к задачам RMQ, RSQ.
И вообще при чем тут декартовое дерево и деревья поиска?
Прежде чем перейти, давайте обсудим проблему построения.
Последний пункт здесь.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Построение декартового дерева.
Значит, в чем проблема построения?
Вот смотрите, допустим, вам изначально даны какие-то ключи.
То есть вам даны какие-то ключи, вам даны возможно приоритеты.
И вам нужно из этого набора пар ключ значения построить декартовое дерево.
Ну, казалось бы, ну чего?
Можно просто взять и...
Там for x, y и a.
Ну где a это там какой-то ваш массив.
Мы просто делаем...
То есть так t равно insert t, x, y.
Ну, казалось бы, в чем проблема?
А в чем тут может быть проблема?
Отлично.
Значит, в среднем...
В среднем действительно работает zn log n.
Ну, не то чтобы это само по себе плохо, но...
В целом, наверное...
Ну, наверное, неприятно.
А проблема-то в чем?
Ну, смотрите, мы сказали, что insert в среднем работает за алгорифом.
А за сколько он работает в худшем случае?
Да, вот в худшем случае нам вообще говоря...
Ну, худший случай нам вообще говоря никто не гарантировал.
Понятно, что в худшем случае insert может работать за линию.
Ну, опять же, легко придумать пример, когда у вас, скажем,
emergency split будут работать за линейное время.
Ну, скажем, вы генерируете там приоритеты случайно,
блабла и так далее, но при этом вы же не застрахованы от такой ситуации.
Ну, вы поняли.
То есть теоретически это...
Ну, то есть на практике, естественно, наверное, это как бы маловероятно,
но теоретически никто вам не гарантирует, что так будет.
Вот, более того, если у вас там в контесте будет задача,
в которой вам будут давать там свои пары ключ-значения,
ой, свои пары ключ-приоритет, вот они те, которые будете генерировать вы,
то такая ситуация возможна.
Вот, поэтому данное построение в худшем случае, worst-case,
работает за n квадрат.
И вот это прям совсем плохо.
Наверное, должен быть способ, который бы позволял из набора ключей
и приоритетов построить дикартовое дерево, ну, как-то быстро, да,
ну, скажем, за линейное время.
И это действительно возможно.
Давайте рассмотрим алгоритм построения дикартового дерева
за линейное время.
Значит, важный момент здесь заключается в том, что...
что мы будем предполагать, что массив A, ну, массив пар,
массив пар x, y отсортирован по x.
Ну, если вот этот массив пар отсортирован по x,
тогда можно построить за линейное время.
Если он не отсортирован, то вы можете отсортировать
за лагарив за n log n.
Там любой сортировок, который гарантирует вам, собственно,
сортировку за n log n, и дальше строить его за линейное время.
То есть в любом случае вы n квадрат не получаете.
Если массив отсортирован, то всё отлично,
и если массив не отсортирован, то сначала его сортируете,
а потом строите дикартового дерева.
Так, как мы будем строить дикартового дерева?
build от a.
Будем делать следующую вещь.
Во-первых, в качестве декартового дерева мы вернем корень этого самого дерева,
и в любой момент времени мы будем поддерживать следующую величину,
точнее следующий указатель.
Последний вставленный элемент.
Давайте обсудим идею.
Обсудим идею, что вообще говоря будет делать наш алгоритм.
Пусть уже какое-то декартовое дерево построено.
Вот это какое-то декартовое дерево.
Я буду просто последовательный тип элементов от меньшего к большему
и вставлять элементы в это дерево.
Из этой картинки, понятно ли вам какой элемент был вставлен последним?
Если я иду от меньшего к большему и последовательно вставляю сначала минимальный элемент,
потом следующий, следующий и так далее,
какой элемент был вставлен последним?
Да, самый правый, то есть вот этот. То есть вот этот элемент, это как раз-таки тот самый last-inserted.
Указатель, на который я буду поддерживать. Ну, вот это корень root.
Так, ко мне приходит новый друг, скажем, не знаю, давайте тут, просто last, и он находится где-то здесь.
Приходит новый элемент, который нужно вставить.
Соответственно, так как я обрабатываю все мои элементы в порядке взрастания, то этот элемент больше, чем все остальные.
Что мне нужно с ним сделать?
Как бы мне его вставить в дерево так, чтобы оно было как можно более просто?
Понятно ли вам, ну давайте предположим, что у него приоритет находится на таком уровне, ну и по вертикали, точнее по ключу он больше всех остальных.
Понятно ли вам, как нужно исправить дерево так, чтобы этот элемент встал на свое место?
Ну, я предлагаю сделать такую вещь. Вот так и вот так. Как вам? Разумно?
Этот элемент больше, чем корень, ну априори, да, и плюс этот элемент больше, чем все остальные вот эти элементы.
Все, поэтому вот этот элемент я отправляю в правое под дерево вот этого элемента, а вот это все под дерево отправляю в левую часть.
Ну и плюс, так как у него приоритет находится между вот этими элементами, то, соответственно, он тоже стоит на своем месте.
Ну, вот план такой, я буду делать, соответственно, вот такую вещь.
Давайте изобразим. То есть вот у меня есть последний добавленный элемент, и что мне нужно найти?
Мне нужно просто найти то место, куда мне нужно вставить вот этот элемент.
Давайте сделаем. То есть for x, y, a, то есть в цикле я перебираю все элементы в массиве a, и пишу следующую вещь.
Значит, inserted.
То есть я возьму самый правый элемент и просто буду подниматься все выше и выше, до тех пор, пока я не найду место, куда мне вставить этот элемент.
Как мне определить, куда этот элемент должен встать?
Ну, я просто должен проверить верно лишь, что cur y меньше, чем рассматриваемый y.
Нет, наоборот.
Вот так. То есть я нахожусь в этом элементе, и я понимаю, что приоритет вот этого элемента, он, в смысле, он должен вставить выше, чем этот элемент.
Поэтому я должен подняться чуть выше. Ну и так далее я поднимаюсь, пока я не найду вот до этого элемента.
Все, я дошел до этого элемента, и я понимаю, что приоритет, что это первая вершина, приоритет которой меньше, чем у этой вершины.
Ну, соответственно, ее я должен подсоединить сюда, а это сюда.
Поэтому пока у меня выполняется такое условие, то есть пока я не дошел до самого конца, то есть пока я не дошел там до абстрактного нуля,
и пока у меня приоритет, приоритет новой вершины меньше, чем приоритет той вершины, которой я сейчас нахожусь, я поднимаюсь выше и выше.
То есть я делаю cur равно cur стрелочка parent.
Вот.
Ну и дальше я должен проверить, что я должен проверить.
Ну, вот это хороший случай, давайте его оставим на потолке, у меня может быть плохой случай.
Я поднимался выше и выше, и так не нашел ни одного элемента, который бы приоритету был бы меньше, чем мой элемент.
То есть, грубо говоря, мой элемент находится где-то вот здесь.
Что это означает?
Вот если приоритет вот этого элемента меньше, чем все приоритеты вот на этом пути.
Да, ну во-первых, мой cur это nullptr, то есть если cur равно равно null, что я должен сделать в этом случае?
Да, я должен вот этот элемент просто взять и сделать корнем.
Давайте так и поступим.
Ну, во-первых, я говорю x, y, left равно корень, да, то есть я добавляю вот такую вот связь.
Ну, опять же, да, если есть корень, то я корню говорю, что у него родитель это новый элемент x, y.
Ну и, собственно, сам x, y я должен сделать корнем, то есть root равен x, y.
Вот.
То есть еще раз, вот мне пришел новый элемент, я хочу понять, куда его вставить.
Вот я поднимаюсь выше-выше, я понимаю, что я дошел до самого верха,
и при этом все эти элементы имеют больше приоритет, чем вот этот элемент.
То есть вот этот элемент должен стать в качестве корня.
Ну и, соответственно, все, я делаю этот элемент корнем.
Все эти элементы, все построенное дерево должно пойти в качестве левого сына.
Вот. x, y, left равно root, то есть root это вот этот элемент.
Вот. Если корень не нулевой, то я должен еще дополнительно добавить вот такую вот связь.
Вот. Ну и просто-напросто перевесить указатель корня вот сюда.
Ну давайте вот.
То есть ситуация у меня вот такая. Понятно?
Вот. Ну и теперь давайте вернемся к нормальной ситуации,
то есть ситуации, когда у меня элемент все-таки должен стать куда-то вот сюда.
То есть вот пришел новый элемент, вот.
Это root. Вот.
И я понимаю, что вот мой элемент должен лежать где-то в промежутке между этим элементом и этим элементом.
Да?
Ну а здесь мы, кажется, обсудили, что надо делать.
Что нужно сделать?
Нужно к этому элементу подвесить вот этот элемент.
Ага, нет, не так. В другом порядке.
Что вот этого не потерять.
Давайте наоборот сделаем. Давайте сначала вот это поддерево подвесим к новому элементу.
То есть понятно, да, почему они должны стоять слева?
Во-первых, они все меньше, чем этот элемент.
А во-вторых, этот элемент имеет больше приоритет, чем все вот эти остальные.
Поэтому этот элемент теперь должен стать новым корнем для вот этого поддерева.
То есть else я делаю x, y left равно cur right.
То есть вот этот элемент, который я нашел, и его правое поддерево должно стоять слева.
Ну и, как обычно, если правое дерево не нулевое, то есть если вот это дерево не нулевое,
то это я у него еще должен обновить родителя parent равно x, y.
Все, то есть я вот эту связь провязал.
Ну и теперь осталось только добавить вот эту связь.
Делать это так. Не root, а cur right равно x, y.
Ну x, y parent равно cur.
Ну и после вот этих двух условий, if else, что я должен в конце сделать?
Обновить last inserted равно x, y.
После того, как у меня цикл while завершится, я должен в конце просто сделать return root.
Вот такой алгоритм.
Ну давайте пример какую-нибудь приведем, чтобы стало понятно, что происходит.
Давайте какие-нибудь пары вставим.
1, 2, 3, 4, 5, 6. Ну и какие-нибудь приоритеты.
5, 4, 6, 3, 7, 2.
Ну попробуем вставить вот эти элементы.
Так, ну рассмотрим первый элемент.
Это 1, 5. То есть у нас root это 0.
То есть root указывает никуда, last указывает никуда.
Соответственно, мне подниматься некуда, то есть тут везде у меня 0.
Соответственно, я попадаю в ветку, когда у меня текущий элемент равен 0.
Соответственно, что я должен сказать?
Я должен сказать, что я создаю вершину 1, 5.
Я говорю, что ее левый ребенок это root.
То есть левый ребенок это 0, поэтому ничего не делаем.
Если root, то есть корня пока нет, поэтому пропускаем.
И говорим, что новый корень, теперь вот этот новый элемент x, y.
root указывает вот сюда.
Ну и соответственно, последний вставленный элемент это тоже этот элемент.
Окей, идем дальше. Следующий элемент это 2, 4.
Начинаем с последнего вставленного элемента и поднимаемся наверх.
Значит, смотрим на этот элемент и спрашиваем, верно ли, что приоритет у этой вершины меньше, чем приоритет у этой вершины.
То есть вот элемент 2, 4.
То есть верно ли, что ее приоритет меньше, чем приоритет этой вершины?
Да, верно.
Поэтому мы поднимаемся выше.
Из этой вершины мы поднимаемся наверх, подниматься некуда, поэтому мы падаем в 0.
Все, как только мы падаем в 0, мы завершаем работу над пол awak hari, и снова попадаем в эту ветку.
Т.е. вершина, которую мы нашли, это 0.
Ну, это никакая вершина.
Поэтому начинаем работать здесь.
То есть, что мы должны сказать?
Мы должны сказать, что левым сыном новую вершину должен стать корень.
Корень сейчас у нас 15, поэтому добавляем вот такую связь.
Дальше у корня провязываем родителя, и дальше говорим, что новый корень – это новая вершина.
Заменяем корень, вставляем сюда.
Ну и в самом конце говорим, что последняя вставленная вершина – это та вершина, которую мы вставили.
Пока понятно, да?
Идем дальше.
Вершина 3,6.
Давайте что-нибудь интересное попробуем придумать.
3,6 станет туда.
Давайте так. Давайте тут сделаем 4,8.
Будет 4,6,8.
Тут будет 5.
Давайте так сделаем, чтобы пример интересный получился.
Дальше вставляем элемент 3,6.
Что делаем? Мы стартуем отсюда, то есть вот эта текущая вершина.
И вершина 3,6 должна встать вот здесь.
Стравим мы приоритет этой вершины и приоритет этой вершины.
Что мы видим? Верно ли что приоритет этой вершины меньше, чем приоритет текущей вершины?
Нет. Не верно.
Поэтому цикл заканчиваем. workout.com pops'ourstands
Мы становились вот в этой вершине.
Верно ли что эта вершина 0? Нет, не верно, поэтому мы идем вот по этой ветке.
То есть эта вершина 0, поэтому мы должны что сделать?
Мы должны сказать, что в качестве левого сына подвешиваем,
подвешиваем правого сына иную эту вершину, но
у него ничего нет, оставляем как есть.
Следующий оBooks как раз нужно 38 в ooh,
его пр quintake 1976 lk AND 우
В качестве правой вершины это такой штука,
чтобы стать новый элемент,
соответственно добавляем такую связь.
Ну иày Stanley тоже добавляем.
Все, корень не изменился
последний вставленный элемент,
это вот этот элемент.
Вот.
Ну, давайте один шаг пропустим, то есть 4,8 на самом деле станет точно так же,
то есть будет вот так. Ну и последний вставленный 4,8. Давайте перейдем вот сюда,
вот тут интересный момент, значит 5,5. Что мы делаем? Значит, вот в этом цикле,
мы ищем первый элемент, у которого приоритет меньше, чем у
вставляемого элемента. То есть 5,5, он должен встать где-то вот здесь.
Начинаем 4,8, поднимаемся наверх, поднимаемся наверх, вот снова эта вершина.
Это вершина, это первая вершина вот на этом пути, у которой приоритет меньше, чем
5,5. Поэтому в качестве кучи вершин и берем эту вершину. Что мы делаем? Во-первых, мы
говорим, что в качестве левого поддерева у новой вершины вот этой, в качестве левого
поддерева, должно выступать правое поддерево вот этой вершины. То есть мы должны
мы можем взять все вот этого поддерево и пристанить его слева вот сюда.
Ну а далее, в качестве правого сына, вот для этой вершины, которую мы нашли,
делаем новую вершину.
Ну, предполагаем, что нет. Ну, формально могут, но давайте предполагать, что нет.
Ну, тут ни на что это не повлияло. Ну, давайте, не знаю, пять половин. Нормально?
Ну, на практике, как генерировать приоритеты? Вы просто генерируете приоритеты из какого-то большого множества.
И там вероятность того, что какие-то приоритеты случайно совпадут, она очень маленькая.
Поэтому этого достаточно. То есть, на самом деле, равные приоритеты, они ничего почти не портят, поэтому можно забить.
Ну, давайте, ладно. Пусть так. Ну и теперь мы вставляем 6,2. Ну, в качестве 6,2 мы должны...
То есть, что мы делаем? У нас root не изменился, последний вставленный элемент – это вот этот элемент.
Когда мы будем вставлять 6,2, что мы будем делать? Мы будем подниматься наверх, отсюда поднимемся наверх,
отсюда поднимемся наверх. То есть, мы не найдем ни одной вершины, у которой приоритет был бы меньше,
у которой приоритет был бы меньше. Поэтому мы вставляем сюда 6,2, ну и действуем согласно этой ветке.
То есть, мы не нашли ни одной вершины, qr. qr – это вершина, у которой приоритет меньше, чем у вставляемой вершины.
Мы не нашли ни одной вершины, у которой приоритет был бы меньше, поэтому мы 6,2 делаем корнем.
То есть, на самом деле делается просто вот так. Вот так и сюда root.
Все. Вот таким образом мы построили дикартовое дерево.
Ну и главный вопрос – почему, вообще говоря, это работает за линейное время?
Ну смотрите, вот в этом алгоритме есть один цикл, и внутри этого цикла есть аж целый цикл здесь.
То есть, если у вас есть цикл внутри цикла, при этом, причем вот этот цикл – это линейный цикл,
а вот этот цикл – это, вообще говоря, теоретически тоже линейный цикл.
Ну почему? Потому что у вас может быть такая ситуация, что у вас могла возникнуть вот такая цепочка,
ну то есть не совсем цепочка, но вот такая картина.
И, в принципе, когда вы оставляете новый элемент, ну, допустим, вот этот,
в принципе, вы должны пройти достаточно большой путь, чтобы добраться до нужного места.
То есть, в принципе, как вот этот цикл может быть большим, ну так и этот цикл, он априори большой,
потому что он занимает линейное время.
А почему суммарно это все занимает линейное время? Понимаете вы или нет?
То есть почему, несмотря на то, что у меня вот такие вот пути могут быть большими,
то есть несмотря на то, что у меня file в принципе может работать долго, почему суммарно это линейное время?
А почему я еще раз не буду проходить по этому пути?
Что мне мешает?
То есть тезис-то правильный, вопрос, почему это так?
Что произойдет с этими вершинами, когда я буду вставлять вот этот элемент вот сюда?
Ну не совсем.
Ну то есть у меня, то есть в чем проблема? У меня теоретически может быть длинный правый путь,
то есть путь, который вот идет строго по правым элементам.
И вот утверждение это состоит в следующем, что вот если я по этим элементам,
по этому правому пути как-то поднялся наверх, то вот по этим элементам я уже никогда не пройду.
Да, именно, потому что что происходит, когда я вставляю новый элемент?
Я делаю вот так и вот так. Все, все эти элементы у меня ушли в левое поддерево нового вершины.
Все, вправо они никогда не вернутся. Все, мы их как бы замели.
Все, теперь у меня новый правый путь, это вот такой путь. Согласны?
То есть почему вот это?
Значит, на каждой икарации for,
давайте так, правый путь, ну или правая цепочка, ну давайте правый путь.
Ну под правым путем я понимаю вот этот путь, да?
От последнего вставленного до там самого корня.
Правый путь увеличивается на один. Ну почему на один?
Ну потому что за счет вставляемого элемента, да?
То есть если я вставляю элемент, то он обязательно идет вправо,
то путь как-то увеличится на один.
За счет вставляемого элемента.
Вот. Но цикл while, что делает while?
後 это stolчевое ваше disproportionate.
То есть кор behaviors надо jaws.
То есть у меня правый путь, он увеличивается за счет новых элементов.
То есть я вставляю все новые и новые элементы.
Но при этом этот же самый путь в какие-то моменты уменьшается.
А за счет чего он уменьшается?
То есть как мы обсудили, это за счет цикла while,
путь на одну вершину здесь, но при этом уменьшил на целую группу вершин здесь,
окей? Поэтому, ну а цикл while уменьшает его на, ну давайте напишем ki, ну ki это вот
общее количество итераций циклов while. Давайте тут еще пояснее напишем, так как все
пройденные вершины уйдут в левое под дерево новой вершины. Ну а теперь смотрите, что у меня
происходит. У меня размер, у меня длина правого пути за 1, ну за одну итерацию цикла for может
максимум увеличиться на 1 и уменьшится на ki. Вот чума равна сумму вообще всех уменьшений, ну не
более чем n. Согласны ли вы, что вот количество уменьшений не может быть больше чем n, ну потому
что у меня всего элементов n, то есть я не могу этот путь уменьшать бесконечно. То есть так у меня
суммарно всего элементов n, то я уменьшать этот путь буду максимум n раз, то есть общее количество
итераций цикла while не больше чем n. Ну вот, ну все, из этого следует o от n, то есть общее число итераций
цикла while не более чем n. Ну и соответственно, общее число итераций цикла while у меня не больше чем n, здесь
я выполняю какую-то работу за 1, ну и вот сумма, ну и сам цикл for занимает линейное время. Все. Поэтому
получается, что алгоритм работает за o от n. Да, но напомню, что при предположении, что у меня массив
отсортирован по иксам. Так, значит, теперь давайте, наконец, перейдем к решению задачи RMQ-RSQ и
попробуем понять, причем тут вообще бинарные деревья поиска. Значит, сформулируем задачу следующим
образом. Представьте себе, что у вас есть некоторый ассоциативный массив. Давайте пункт назовем
RSQ. Вот так. Значит, пусть у нас есть ассоциативный массив.
Ну или в народе MAP. То есть вам просто дана некоторая структура данных, которая осуществляет
отображение ключей и значения. То есть, грубо говоря, у вас есть ключи, есть ключи, есть значения.
Вот. Значит, до этого мы формулировали задачи поиска минимума, максимума, суммы и тому подобное на
обычных массивах. То есть у нас есть обычный массив, ноль индексации, и мы, соответственно,
на определенных отрезках пытаемся найти результат некоторой операции. Теперь мы сформулируем
ту же самую задачу, но в терминах ассоциативного массива. Пусть данный ассоциативный массив
необходимо отвечать на запросы вида кьюри, ну все те же самые LR. Но уже этот запрос выглядит следующим
образом. Нам нужно найти результат некоторой ассоциативной операции на следующем интервале.
K меньше R, а вот K. Ну это просто там некоторый знак суммирования, да, то есть некоторые операции.
Найти минимум, найти максимум, найти сумму, что угодно. Вот. То есть чьем отличие? Раньше у нас
были обычные индексы, да, то есть если нам нужно было найти сумму на отрезке от 2 до 4,
то мы брали элементы 2, 3, 4 и считали там сумму. Здесь у нас другая ситуация. Здесь мы не
привязываемся конкретно к числовым индексам. Здесь, вообще говоря, мы говорим, что у нас ключ
может быть произвольным, то есть, например, строки, да, то есть у вас могут быть там, не знаю, какое
отображение, там, не знаю, имена и там возраст. Вот вы можете выбрать там все ключи, которые
вытворяют там, не знаю, у всех ВАС, нужно посчитать средний возраст, да, или у всех ВАС
нужно посчитать максимальный возраст. То есть вот вы берете там определенный промежуток и
выполняете на нем некоторую операцию. Задача понятна? То есть ключ
произвольным. Как можно решить эту задачу? Ну, тут нам очень сильно помогут бинарные
деревья поиска. Давайте делаем следующую вещь. Давайте для начала нарисуем какой-нибудь бинарное
дерево поиска, ну, точнее, нарисуем какой-нибудь ассоциативный массив, который представляется в
виде бинарного дерева поиска. Ну, например, как-то вот так. Ну, изобразим тут какие-то
значения. Давайте тут один, три, четыре, пять, семь, восемь, десять, двенадцать, двадцать. Это ключи.
Вот, то есть, заметьте, что, ну, да, тут ключи числовые, но при этом они все идут не подряд, да, то есть
тут нет ноль, тут нет нуля, тут нет двойки и так далее. Ну, и напишем там некоторые значения. Не знаю, пять, семь,
минус три, два, шесть, десять, один, ноль, пять. Ну, давайте какую-нибудь операцию придумаем. Какую операцию
будем использовать? Минимум, максимум, сумму, что хотите. Давайте минимум, ладно. А в общем, идея такая,
то есть, необходимо уметь отвечать на запросы вида, не знаю, там найти минимум на полуинтервале от пяти до,
не знаю, десяти. Вот, что я делаю? Я ищу ключи, которые удовлетворяют этому критерию, да, то есть,
это элемент вот этот, этот, этот. Десятку не включаем, то есть, соответственно, вот в данном конкретном примере,
в этом астративном массиве у меня три ключа удовлетворяют этому условию, да, то есть, они лежат в пределах от пяти до
десяти невключительно, вот. Ну, и, соответственно, среди этих элементов я должен найти минимум, в данном случае
ответ два. Задача понятна, да. Как мы ее будем решать? Значит, идея такая, идея. Будем в каждом узле, значит, идея очень
похожа на идею деревоотресков. То есть, если деревоотреска, ну, деревоотреска, по сути, тоже дерево, тоже
бинарное дерево, ну, то есть, ну, там все значения хранились, ну, в последнем уровне, да, то есть, в
листовых вершинах. А здесь у нас бинарное дерево поиска и сами значения у нас хранятся непосредственно в узлах.
То есть, если в декартом, то есть, если в деревеотресках у нас вот во внутренних узлах хранились только
результаты, то здесь у нас во внутренних узлах, вообще говоря, хранятся и сами значения. Но ровно как и в деревеотресках,
давайте в каждом узле хранить и результат операции тоже. Но при этом будем хранить результат операции не на каком-то
отрезке, а в самом поддереве. То есть, скажем, возьмем этот узел и будем хранить результат операции во всем
поддереве сразу, окей? То есть, будем в каждом поддереве хранить результат
операции на элементах поддерева. Ну, то есть, мы как бы в случае декартов в дереве не обсуждали, но вообще говоря,
я думаю, понятно, что у вас узел представляется в виде некоторой структуры, что у вас хранится в узле. То есть, у вас хранится
ключ, возможно хранится приоритет, давайте х, мы обозначали х, возможно хранится у. Опять же, я не настаиваю, но если вы используете
в качестве бинарного дерева поиска декартового дерева, то вы еще храните дополнительные приоритеты. Плюс вы храните
собственное значение, то есть, так у вас ассоциативный массив, вы храните пары ключа значения. Ну, там понятно,
всякие указатели left, right, возможно parent, если надо, и дополнительно храните result. То есть, в одном узле вы храните
ключ значения, понятное дело указатель на левостен, указатель на правостен, возможно указатель на родителя, и храните
результат применения операции ко всему поддереву. Ну, давайте здесь посмотрим, что мы будем хранить, будем красного цвета обозначать.
Значит, здесь хранится пятерка, здесь храниться семерка, то есть, напоминаю, операция минимум, здесь хранится
минус тройка. Почему, потому что во всем этом поддереве результат операции минус 3. Здесь 6, здесь 0, здесь 5.
Здесь во всем этом поддереве результат операции ноль, поэтому пишем 0. Во всем этом поддереве результат операции
это минус 3, поэтому храним минус 3. Во всем дереве целиком результат операции минус 3.
То есть в принципе все очень похоже на дерево отрезков. То есть дерево отрезков тоже хранило
результатом целой операции на каком-то подотреске. То есть единственное отличие заключается в том,
что мы здесь помимо самого результата храним еще некоторые значения тоже. В дереве отрезков
у нас эти значения хранились только в листовых вершинах. Вот, отлично. Ну, я думаю, построить вот
эти вот значения result не составляет никакого труда. То есть мы тоже это можем сделать рекурсивно,
грубо говоря. То есть спуститься в левый сын, спуститься в рамовый сын, посчитать тут результат,
посчитать тут результат, написать Русат здесь, ну и так далее. Вопрос заключается в другом. А как
эту структуру поддерживать? То есть у меня же, вообще говоря, бинарное дерево поиска,
оно может как бы менять свою структуру. То есть в чем отличие от исходной задачи RSQR и RMQ? Здесь у
меня появляются дополнительные запросы вида вставить новый элемент или удалить элемент.
Согласны? То есть если на массиве, наверное, не имеет смысла говорить о операциях вставки,
удаления, потому что они занимают линейное время, и в принципе сложно это организовать,
то в бинарном дереве поиска в принципе вы можете задаться вопросом, а что если я хочу
дополнительно вставлять сюда дополнительные элементы, и плюс чтобы у меня поддерживались вот
эти вот все инварианты, то есть все вот эти результаты. Нормальный вопрос. Давайте попробуем
понять, как поддерживать все эти операции. Ну точнее, вот мне приходит новый элемент,
я вставляю новый элемент, что мне нужно сделать, чтобы все корректно работало. Вот здесь мне
пригодится, здесь мне пригодится одна операция, которую давайте назовем
починка вершин, будем называть FixedNode. Смотрите, в какой момент мне может понадобиться
починить вершины? В какой момент мне может понадобиться изменить, скажем так, изменить
результат операции? Что может произойти, что мне там необходимо было? Ну MergeSplit это как бы частный
случай, вот если в общем говорить. Ну MergeSplit это конкретно там для декартового дерева. Да,
мы посмотрим там, что надо делать, вот если в общем говорить. За счет чего у меня может
измениться здесь значение? Да, что есть у меня появится какое-то, ну допустим, если у меня
появится какое-то левое поддерево, или правое поддерево, ну или в принципе, если меня изменяет
левое или правое поддерево, да, то мне нужно починить вершину. Ну почему? Потому что если у меня
левое сын или правое сын изменился, то это значит, что результат операции в принципе теоретически
вызывается при изменении левого или правого сына.
Что в этом случае нужно сделать?
Давайте на всякий случай добавим проверку.
Мы фиксируем не нулевую вершину.
Если вершина не нулевая, то что значит пофиксить ее результат?
Что нужно сделать?
Нужно просто взять и сказать, что node.result это что?
Давайте еще какое-то место пропустим.
Давайте дополнительную функцию заведем.
result от node.
Чтобы не возиться с проверками, давайте так сделаем.
Если вершина node не нулевая, то будем возвращать node по C++.
Если вершина не нулевая, то возвращаем node.result.
А иначе возвращаем некоторый нейтральный элемент.
Если я попросил результат от нормальной вершины, то я должен обратиться к result.
Если я попросил результат от пустой вершины, то я возвращаю нейтральный элемент.
Как тогда обновить результат в вершине?
Нужно просто взять результат из левого сына node.left.
Заметьте, что я тут проверок теперь не пишу, потому что я проверку вынес в отдельную функцию.
Смотрю результат в левой вершине, добавляю значение в текущей вершине.
Почему значение? Потому что меня интересует то, что в ней сейчас находится.
Ну и плюс, не знаю, минимум, максимум от result, от write.
Все довольно просто.
Общая идея простая. Мы храним в каждой вершине отдельное поле result, которое хранит результат в некоторой операции на всем поддереве.
Если у вас изменилось вот это значение или изменился левый сын или правый сын, вы вызываете функцию fixNode, которая фиксит значение здесь.
Вообще говоря, при необходимости нужно рекурсивно вызывать.
Сейчас мы поймем, что на самом деле в случае декартового дерева это нам не нужно.
Все примеры я буду привозить в парадигме декартового дерева.
Еще раз повторюсь, что это все можно сделать и для любого бинарного дерева поиска, но вот сегодня мы разбираем конкретно декартового дерева.
Мы в декартово дерево или в наше бинарное дерево поиска добавили соответственно новые значения и добавили хранение некоторых результатов операции.
Вопрос вам, много ли операций декартового дерева нужно изменить, чтобы подружить его с этой всей структурой?
Оказывается, нет. Через какие операции у нас выражается вообще все в декартовом дереве?
Мерш и сплит. Вы согласны, что если я добавлю поддержку фиксноута сплит и мерж, то у меня автоматически инсерты и рейсы заработают.
Давайте посмотрим, что нужно изменить в мерже и сплите, чтобы это все заработало.
Давайте я тут буду, напишу мерч и сплит и больше стирать не буду, чтобы перед глазами был.
Давайте восстановим, что у нас было мерч.
Т1, Т2. Напомню, что все ключи в Т1 строго меньше, чем все ключи в Т2.
Условия выхода из рекурсии. Если Т1 нул, то return Т2. Если Т2 равно равно нул, то return Т1.
Что мы проверяем в мерже? Когда мы склеиваем два дерева, нам нужно выбрать корень.
Поэтому мы сравниваем лево под дерево приоритет правого под дерево.
Если это выполняется, то в качестве правого под дерево я сохраняю результат мержа от Т1 right.
Вы и следите, согласуете ли это всем, что мы до этого писали.
В качестве правого под дерево здесь. Дальше, Т1 right parent равно Т1. И все. Return Т1.
Аналогично else. Вот здесь. Что мерж принимает в качестве своих аргументов?
В качестве своих аргументов предполагаем, что он принимает корректное дерево Т1 и корректное дерево Т2.
В процессе своей работы он как-то эти деревья модифицирует.
В частности, тут видно, что есть правое под дерево, он это правое под дерево меняет.
Вопрос. В какой момент не нужно вызывать fixNode и для каких вершин?
Куда здесь нужно вставить fixNode?
Не так уж много вариантов, на самом деле.
Можно ли вставить куда-нибудь сюда?
Нет, здесь никаких изменений не произошло. Мы тут возвращаем дерево Т2 как оно было, Т1 как оно было.
Где мы портим деревья?
Вообще говоря, вот здесь это единственная строчка, где мы испортили дерево.
В частности, тут испортили правое под дерево.
Тут было какое-то раньшее старое под дерево, мы заменили его на результат мержа.
Естественно, по предположению индукции предполагаем, что мерж от меньших деревьев возвращает корректный результат.
То есть мерж нам вернул корректное дерево, в котором все посчитано.
Мы сказали, что у Т1 изменилось правое дерево.
Соответственно, какую вершину мы должны пофиксить?
Собственно, Т1.
Единственная строчка, которую тут нужно добавить, это fixNodeT1.
И после этого сделать returnT1.
Вопрос на понимание.
Смотрите, я вызвал fixNode от Т1, но при этом у Т1 же есть еще какие-то родители.
Вот это родители, вот это родители.
И в принципе, если изменился Т1, то должны были измениться его родители, родители родителей и так далее.
Нужно ли это как-то эту ситуацию обрабатывать отдельно или нет?
Варианты? Да, нет, тут всего два ответа.
Самый простой ответ какой?
Нет, ничего не надо делать.
Ничего не надо делать. Почему?
Потому что мы все операции реализовали рекурсивно, у нас как раз таки рекурсивно все и решится.
То есть как работает рекурсия?
Рекурсия спускается вниз до тех пор, пока мы не встретим пустое дерево.
После того, как мы встретили пустое дерево, рекурсия раскручивается обратно.
То есть мы вернулись обратно, пофиксили здесь.
Дальше, после того, как вот этот мерж завершился, мерж поднялся куда-то наверх, пофиксил здесь и так далее.
То есть рекурсия все сделает за нас.
Что делает мерж? Мерж рекурсивно вызывает сам себя.
Все места, где у нас потенциально меняется дерево, мы пофиксили.
Соответственно, в мерже все хорошо.
Логика понятна?
Поэтому все, на этом достаточно.
То есть добавили всего лишь одну строчку, и теперь у нас все вот это заработало в случае мержа.
Теперь давайте сделаем так, что все работало и для сплита.
Сплит дерево t по x0.
Снова предполагаем, что дерево t там хорошее, то есть там все почти нормально.
Если t это null, то просто делаем return пару null-null.
Ну и в случае сплита мы проверяем, верно ли что x меньше, чем x0.
Если это так, то мы должны распилить правое под дерево.
Lr равно split t right x0.
Дальше что мы делали?
Распилили право под дерево. Дальше сказали, что t right ght равно l.
Ну и если l, то l parent.
Ну даже не интересно, если l, если r, тоже бла-бла.
Ну и делаем return, пилили правое, поэтому lt.
Ну else аналогично.
Давайте подумаем, куда сюда нужно вставить fixed node.
Нет, split же у нас делит на два дерева.
А, да, мы пилили правое, да, tl.
Мы пилили правое, тогда tr.
А до этого мы правильно писали?
У нас было дерево t, мы его правое под дерево распилили,
поэтому мы возвращаем t и вот этот кусочек r.
Ну так чего?
Ну, давайте рассуждаем как математики по индукции.
Сплит у нас рекурсивная функция, то есть по сути это такая математическая индукция.
То есть мы свели исходную задачу в задачу поменьше.
Предположим, что маленькие задачи мы умеем решать корректно.
Вот допустим, сплит нам вернул два корректных дерева.
lr корректные, что у нас тут портится, где нужно вызывать fix?
Единственное дерево, которое у нас портится, это t.
То есть мы у t меняем правое под дерево.
Так что результат самой вершине t мог измениться.
Поэтому здесь то же самое. Перед самым ретерном мы должны вызвать fix?node от t.
Ну и return?tr. Все.
Снова почему это корректно работает?
Потому что сплит тоже работает рекурсивно.
То есть если у вас есть какое-то исходное дерево,
то вы в нем спускаетесь до тех пор, пока вы не встретите нулевую вершину,
а дальше у вас рекурсия разгонит обратно.
То есть вы дальше будете идти по одной вершине, по родителю и так далее.
И когда вы будете подниматься от листа к родителю,
вы будете последовательно вызывать fix?node.
Соответственно так вы от самой низкой вершины до самой верхней обновите все вершины.
С помощью fix?node.
Ну или если хотите по индукции.
У нас маленький сплит, предполагаем, что работает корректно.
Но сплит тоже работает корректно, потому что мы там везде, где надо fix?node вызвали.
Все понятно?
Вот и теперь, смотрите, мы починили merge, мы починили сплит.
То есть теперь и merge, и сплит у нас умеют восстанавливать справедливость.
То есть они умеют восстанавливать корректный результат здесь.
Ну а соответственно из этого следует, что теперь и insert, и erase тоже работают корректно.
То есть что мы сейчас научились делать?
Мы научились поддерживать бинарное дерево поиска, в котором у нас сохраняются результаты некоторых операций на поддеревьях.
И плюс они будут сохраняться и при всяких вставках, удалениях и тому подобное.
Остался на самом деле один несущественный вопрос.
А как найти минимум на 5-10?
Ну хорошо, вот мы где-то в поддеревьях что-то сохранили.
А ответ как считать?
Все умеем делать, insert умеем, erase умеем, в поддеревьях умеем там корректно считать.
Вот если был запрос на поддеревья, то все отлично, мы все умеем делать.
А вот тут минимум на 5-10 у нас результат не на поддеревья.
Ну то есть результат операции вот на этом участке нигде в какой-то конкретной вершине не хранится, согласны?
Что делать?
Ответ вас шокирует.
Давайте, что делать?
Я в самом начале лекции обещал, что...
В общем, я что-то обещал.
Как посчитать результат операции на произвольном куске дерева?
Ну обход...
Ну с обходами тоже все сложно, потому что у нас нет обходов.
С обходами тоже все сложно, потому что...
Ну в принципе у вас запрос может быть произвольным, то есть произвольная сложность.
Запрос может быть каким-то вот таким.
Тогда это совсем не обход.
Да, вот смотрите, вот вообще плохая ситуация.
Вот если меня попросили на 5-11,
то тогда мне нужно взять вот эти вершины и плюс кусочек вот этого поддерева.
То есть мне нужно отдельно выделить вот эту вершину, потом взять там какие-то вершины отсюда.
В общем, не очень ситуация, согласна.
Как мы берем...
Что он означает?
Он означает, что мы должны выбрать все элементы дерева
с ключами от 5 до 11 не включительно.
В данном случае это 5, 7, 8, 10.
11 тут нет, но мы его не включаем.
Выбираем вот эти 4 узла.
Выбираем минимум вот на значениях.
Ну, грубо говоря, это ассоциативный массив.
Только вместо индексов у нас вот ключи.
Короче, я обещал, что все операции, которые мы сегодня будем изучать,
они будут сводиться к операции merge и split.
Соответственно запрос тоже можно сделать с помощью merge и split.
Вопрос, как посчитать результат операции здесь?
Давайте общую идею.
Что нужно сделать?
Давайте просто возьмем и вырежем это дерево.
Просто возьмем и вот это дерево с помощью сплитов вырежем из всего под дерево.
Получим вот такое вот маленькое под дерево, в котором хранятся только вот эти ключи.
И где будет храниться ответ у такого дерева?
Просто в корне.
Все? Гениально?
Давайте напишем операцию запроса.
Операцию запроса.
Кьюри от L...
Ну давайте я так буду писать, чтобы подчеркнуть, что правая граница не включается.
Кьюри от L до R. Видно или плохо?
Давайте поменяем.
В 3D лекция пошла.
Давайте разобьемся с кьюри и потом перерыв.
Все очень просто.
Если я хочу посчитать результат операции на произвольной части ключей,
я должен все эти ключи вырезать из дерева.
Давайте сделаем так.
Во-первых, давайте отрежем всю часть, которая относится к L.
Все, что L справа.
Разрежем дерево так, чтобы все ключи, которые меньше L, остались в одном дереве.
Все ключи, которые больше набраны, чем L, остались в другом дереве.
Делаем это с помощью сплита.
Тут еще дерево T.
Работаем над деревом T.
Сплитим исходное дерево T по ключу L.
Как работает сплит, но ровно так он работает.
Получаем дерево, в котором все ключи меньше L и все ключи, в котором больше набраны L.
Что теперь нужно сделать?
Теперь из этого дерева нужно вырезать все значения, которые удовлетворяют, которые меньше, чем R.
Как это сделать?
Дерево от L до R.
Дерево, в котором все ключи больше R.
Это просто сплит вот этого дерева по R.
За два сплита мне удалось вырезать нужное мне дерево.
Все, ну и я сохраняю результат в какую-то отдельную переменную.
Не знаю, result.
Это result от T и R.
Почему я использую функцию?
Потому что теоретически у меня в этом диапазоне может совсем никакой вершины не оказалось.
Поэтому там result возвращает в этом случае нейтральный элемент.
И что я должен после этого сделать?
Вернуть все обратно.
Как будто ничего и не было.
Ну давайте склеим все обратно.
T равно merge.
Так, как мы склеиваем?
Ну, например, так.
T меньше L.
T L R.
В любом порядке можно склеивать, неважно.
Вот так и T больше R.
Больше ли равно R?
Тут больше ли равно должно быть?
Все элементы меньше R здесь.
Все элементы больше равные R здесь.
Ну все, собрали обратно.
Возвращаем ответ result.
Все, что получилось?
Результат мы посчитали.
Дерево исходное не изменилось.
То есть мы его как расклеили, так и склеили обратно.
Продолжим обсуждать дружбу между бинарными деревьями поиска и RMQ-RSQ.
В общем-то запрос мы делать научились.
Мы храним результат операции в корне дерева.
Соответственно, если хотим получить результат на определенном диапазоне ключей,
то мы просто нужное поддерево вырезаем.
За счет того, что мы исправили операции MergeSplit,
нам теперь гарантируется, что в вырезанном дереве в корне будет храниться нужный результат.
Точнее результат операции, примененный ко всему этому поддереву.
Соответственно, мы смотрим на корень этого поддерева и получаем результат.
После этого склеиваем все обратно и работаем дальше.
Еще один короткий пункт, который тут нужно обсудить.
Что если мне хочется выполнять групповые обновления?
Как мы это делали в дереве отрезков?
Помимо того, что мы хотим узнавать результат,
мы хотим выполнять групповые обновления.
А add на отрезке от 5 до 10 прибавить 5.
Снова я хочу взять все эти элементы и ко всем value,
то есть 6, 0, 2, 10, ко всем ним прибавить 5.
Как это можно сделать?
На самом деле, идея тут точно такая же, как и в дереве отрезков.
Что мы делали, когда мы делали групповые обновления?
Мы хранили обещание.
На самом деле, спускать обещание или обновлять со значения долго.
Давайте просто возьмем поддерево, в котором хранятся все эти элементы,
и в корне этого поддерева сохраним нужное нам обещание.
Есть правда проблема, которая заключается в том,
что все эти элементы лежат в разных поддеревьях.
Как эта проблема решается?
Давайте снова просто вырежем все эти элементы,
в корне добавим обещание, и потом склеим все обратно.
Давайте сначала идея групповых обновлений.
В корне дерева храним промисс.
Заводим дополнительное поле.
Помимо value, parent, result и так далее, пишем еще промисс.
Тогда update на интервале от L до R, delta, выглядит следующим образом.
На самом деле, можно просто переписать все то же самое.
Давайте делаем так.
То есть вставим все сюда, все то же самое.
Единственное отличие вот в этой строчке,
заменим эту строчку на что?
T, L, R, промисс.
Обновим его обещание на дельту.
Логика понятна.
Вырезаем нужное нам под дерево,
в его корне сохраняем обещание,
дальше склеиваем все обратно.
Вот весь апдейт.
Как правильно заметили, раз мы храним обещание,
нам, наверное, эти обещания нужно выполнять.
В данном случае, как выглядит push?
Пушноут, ну это давайте выполнение обещания.
Выполнение обещания.
Что мы должны сделать?
Если у нас совершенно не пусто,
то выполнение обещания выглядит следующим образом.
Во-первых, node value может равно на node promise.
В первую очередь мы обновляем само вот это значение.
Потом спускаем.
Или давайте не спускаем, а давайте так сделаем.
node result равно на node promise.
Раньше в result у нас хранился результат без учета обещания,
а теперь мы это обещание просто напоследобавляем.
Теперь promise спускаем влево и право сына.
node left promise умножить.
Давайте просто напишу promise.
node стрелочка promise и node.
И здесь еще надо не забыть, я сейчас писать не буду,
проверить, что они существуют.
В смысле дети.
Понятно, что если node left нет, то спрашивать в него promise не имеет смысла.
То же самое с write.
node right promise умножить равно node promise.
В самом конце говорим, что node promise равно ничему.
Короче говоря, то же самое, только вот эта строчка добавилась по сравнению с деревом отрезков.
Почему первой строчки не было в дереве отрезков?
Потому что дерево отрезков хранит только результаты.
Здесь у нас по миру результат хранит сами значения.
Я это не проговорил, но требования на операции все те же самые.
Потому что алгоритм по сути такой же, как и в дереве отрезков.
Требования на результат запроса это ассоциативность.
Требования на результат обновления это ассоциативность плюс дистрибутивность.
Я понял, почему я это не говорил, потому что в тесте это было.
Последний вопрос в этом пункте.
В какой момент вызвать push?
Все операции, и update, и query, и insert, и erase выражены через merger-split.
Поэтому единственные две операции, которые нам нужно исправить, это merger-split.
Давайте на них посмотрим.
Где тут нужно вызвать push?
Давайте вспомним. В дереве отрезков.
В какой момент вызвали push?
В общем случае.
В какой момент мы должны выполнить обещание?
Когда не полный отрезок или когда мы что делали?
Когда мы спускались в детей?
Если нам нужно спускаться в детей, то дети должны узнать об обещаниях.
В какой момент мы спускаемся в детей?
В какой момент мы спускаемся либо к правому сыну, либо к левому сыну?
Вообще говоря, здесь и здесь.
Но если мы хотим написать здесь и здесь, то нам придется и в lc тоже написать.
А это дублирование кода. Давайте просто возьмем и напишем перед if.
Согласны?
Если у нас нетривиальный случай, то это значит, что мы должны спуститься в левую или правую сыну.
А собственно в этот момент мы сделаем push.
Здесь мы делаем push от...
Ну давайте тут сделаем сразу push от t1 и push от t2.
Хуже не будет.
Но в принципе можете здесь отдельно сделать push для t1, а в lc push для t2.
Как вам угодно.
А вот здесь достаточно всего лишь одного общего push от t.
Логика простая.
Push выполняем до рекурсивного вызова, а fix выполняем после рекурсивного вызова.
Почему push выполняем до рекурсивного вызова?
Потому что до того, как делать рекурсивный вызов, нам нужно спустить обещание в детей.
Почему мы fix вызываем после рекурсивного вызова?
Ну чтобы после того, как все у нас сработало, чтобы мы все починили, чтобы все вернулось на круги свое.
Вот.
На самом деле все, что касается темы rsq и rmq применительно к бинарным деревьям поиска.
Есть вопрос.
То есть теперь мы в некотором смысле обобщили решение задачи rsq и rmq
на произвольной ассоциативной массивы.
И кроме того научились поддерживать операции вставки и удаления.
То есть мы теперь поддерживаем все те же самые операции, что и до этого, но дополнительно умеем делать insert и erase.
Причем все за логарифмическое время.
Ну в случае декартового дерева там за логарифмическое время в среднем.
Если вы там как-то пропатчите сплей дерева или овел дерева, то там в худшем случае или в амортизированном смысле.
Вот.
И последний пункт на сегодня.
Сколько у нас времени?
Достаточно.
Последний пункт на сегодня.
Деревья по неявному ключу.
Давайте, давайте, давайте.
Так.
Так.
Вернемся к старой доброй задачи rmq rsq.
То есть мы работаем не с ассоциативным массивом, а с обычными массивами.
Индексация там 0, 1, 2 и так далее.
Давайте я заведу дерево и сделаю страшную вещь.
Уберу ключи.
Много информации о дереве мы потеряли.
Например, вопрос.
Я возьму вот эту вершину и эту вершину.
Понимаете ли вы какой из этихistinct больше?
Да.
Да, то есть смотрите, сами значения ключей вам на самом деле не нужны.
Если вы хотите определить относительный порядок элементов друг от друга,
то к próxima ключи нам не нужны.
Согласны? То есть в принципе мы понимаем, что вот этот элемент...
Сотрут, это нижняя. В принципе я понимаю, что если я, например,
спровицирую все элементы на горизонтальную ось, вот так, вот так, вот так,
то я понимаю, что вот этот элемент имеет индекс 0.
Этот элемент имеет индекс 1, этот 2, этот 3, этот 4, этот 5, этот 6,
этот 7, этот 8. Согласны? То есть в принципе,
если я храню мои данные в виде бинарного дерева, то в принципе я понимаю
относительный порядок элементов друг относительно друга.
Что вот этот элемент левее, чем этот элемент, да, и так далее.
То есть в принципе вы не отличите ситуацию, когда у вас это дерево совсем не имеет ключей,
когда у вас это дерево имеет ключ, там 0, 1, 2, 3 и так далее. Согласны?
И вот собственно в этом и заключается смысл деревьев поиска по неявному ключу.
То есть даже в отсутствии ключей мы понимаем относительный порядок элементов.
Друг относительно друга. Хорошо. Давайте зададимся следующим вопросом.
А как мне понять, допустим, вот у меня есть какое-то бинарное дерево поиска,
я хочу найти пятый элемент в этом дереве. Ну или скажем, найти пятую порядковую статистику.
Значит, пункт поиск порядковой статистики.
Вот нет, но произвольное бинарное дерево поиска.
Я хочу в нем найти десятый элемент сначала. Как мне это сделать?
Но вот в таком виде, к сожалению, никак.
Ну, чего мне не хватает? Какой информации?
Ну смотрите, вот я нахожусь здесь и я хочу найти, допустим, пятый элемент.
Какой мне информации не хватает, чтобы понять, куда мне нужно идти, влево или вправо?
Да, мне не хватает размера под деревьев.
То есть, скажем, смотрите, если бы я понимал, что вот в этом под дереве у меня 5 элементов,
то я бы сразу понял, что вот этот элемент это пятый элемент.
Почему? Потому что слева все элементы, которые меньше него, и меньше него 5 элементов.
Но это значит, что вот этот элемент стоит на пятой позиции, ну в ноль индексации.
Поэтому давайте просто возьмем и добавим дополнительную информацию size.
Добавим size в node.
Так, мы добавили size в node.
К сожалению, стер. Давайте...
Смотрите, size, по сути, это тоже некоторая величина, которую нужно постоянно обновлять,
которую нужно поддерживать. Согласны?
Скажем, я добавил новый элемент, у меня сайза все изменились.
Я, скажем, разделил дерево на две части, у меня сайз левой части и правой части, они изменились.
Поэтому мне нужно как-то уметь исправлять size.
Ну давайте это сделаем тоже в том же самом FixedNode.
Как это делать? Ну просто FixedNode нуждается строчку следующего вида.
node size равно 1, плюс size of left, плюс size of right.
Ну то есть, если у меня изменился левый сын или изменился правый сын,
то я просто должен пересчитать значение size в самой вершине.
Ну а значение size в самой вершине – это размер левого по дереву,
размер правого по дереву, плюс сама эта вершинка.
Все, то есть мы добавили одну строчку FixedNode, все остальное продолжает работать.
FixedNode мы вызываем в правильном месте, здесь тоже FixedNode мы вызываем в правильном месте.
Значит, этот пункт сделали.
Ну и теперь давайте напишем процедуру caveElement от дерева T и K.
Хочу найти катую порядку и статистику в дереве.
Теперь у меня в каждом дереве дополнительно хранится и размер.
Давайте так 1, 1, 3, 1, 5, тут 1, тут 1, тут 3, тут 9.
Вот, допустим я хочу найти, не знаю, шестой элемент.
Я нахожусь вначально в корне. Что мне нужно сделать?
Как мне понять, где мне продолжать искать, в левом или в правом по дереве?
Давайте так, если size от T left меньше, чем K, то что это означает?
Это значит, что нужно искать в правом по дереве.
Вот здесь суммарно, в корне и в левом по дереве, мне не хватает элементов, чтобы добить до K.
Ну точнее так, если у меня размер левого по дереву равен K-1,
то с учетом корня у меня всего элементов, у меня K.
Но чтобы найти K от элемента, мне нужно К плюс первый элемент, потому что у меня ноль индексации.
Поэтому я должен продолжить поиск справа. Согласны?
Вот, в этом случае я просто говорю, что T равно T right.
Так, дальше else, if, значит иначе.
Так, тут на самом деле не все. Что забыли?
Смотрите, что я делал. Я находился раньше здесь, я ищу шестой элемент.
Я вижу, что размер левого по дереву равен пяти.
То есть я понимаю, что мне нужно поиск продолжить в правом по дереве.
Я спускаюсь в правом по дереве, и на самом деле я здесь еще не шестой элемент.
А какой элемент? Да, я теперь ищу нулевой.
То есть мне нужно обновить K.
То есть я ищу вправо по дереве, и вправо по дереве я должен искать теперь элемент с номером size от...
Так, поменяем местами.
А, нет, стоп.
По-другому.
Значит, сначала K минус равно size от T left.
А потом T равно T стрелочка right.
Только тут еще плюс один.
Потому что мы пропускаем size вот этих элементов и плюс вот этот элемент.
Ну, иначе, если... Какая у меня еще может быть ситуация?
Ситуация может быть, что, наоборот, K меньше, чем size от T left.
Согласны?
То есть, наоборот, размер этого поддерева больше, чем тот K, который я ищу.
Но это означает, что этот элемент ровно находится в этом поддереве.
Поэтому я просто запускаю T равно T left.
При этом никакой K я не обновляю. Почему?
Потому что если мне нужно найти, скажем, третий элемент во всем поддереве, то это то же самое, что искать третий элемент и здесь.
То есть в левом поддереве я ничего не пропускаю.
Ну и последний давайте здесь напишем.
Смотрите, если у меня ни это условие не выполняется, ни это условие не выполняется, то что это означает?
Все, я нашел нужный элемент. Значит, нужный элемент уже находится в корне.
В этом случае я просто делаю return.
Давайте T. То есть возвращаю тот самый узел, в котором находится нужный элемент.
Ну и после всего цикла while, если цикл while так и не нашел нужный мне элемент, то я просто могу вернуть null.
Таким образом я могу найти произвольный элемент.
Так, к чему я это все?
Я утверждаю, что мы сделали довольно дерзкую вещь.
Мы построили массив, который устроен как бинарное дерево поиска.
Ну, или еще раз смотрите.
Вот у меня какое-то дерево.
Какое-то дерево.
Для каждого элемента я понимаю, какой элемент находится в нулевой позиции,
какой элемент находится в первой позиции, какой элемент находится во второй позиции.
Да то есть доступ к любому элементу я могу получить с помощью такой процедуры.
Согласны?
То есть это ровная процедура, которая дает мне элемент по индексу.
Взять нулевой элемент, взять первый элемент и так далее.
Так, ключи я теперь не храню.
Но мне они не нужны, по сути.
То есть, что у меня получается?
Нет, у меня есть бинарное дерево поисков, в котором хранятся значения и доступ к каждому элементу я осуществляю по индексу.
Но чем это не массив?
Массив, который просто организован в виде бинарного дерева поиска. Согласны?
Поддержите как-то.
Да, это проблема.
Это не совсем массив, но это массив с точки зрения того, что у него точно такой же интерфейс.
Да, то есть мы можем делать pushback за алгорифом.
Но зато мы можем вставлять элемент в произвольную позицию тоже за алгорифом.
Вставлять элементы в начало за алгорифом.
Получать доступ к элементу за алгорифом.
И плюс все те же самые операции с RMQ и RSQ, которые мы до этого обсудили. Согласны?
То есть мы что получили?
Мы получили структуру данных,
которая работает с массивами
и которая умеет осуществлять ставку за алгорифом,
которая умеет осуществлять поиск суммы за алгорифом,
поиск минимума за алгорифом,
всякие запросы на отрезках, обновления на отрезках и так далее.
Мы пропатчили нашу предыдущую структуру данных до того,
что мы теперь в массив можем осуществлять дополнительно еще и вставки удаления.
И при этом поддерживать все необходимые операции RMQ и RSQ.
Понятно?
Тут возникает некоторая проблема.
Точнее так, давайте сначала нет проблем.
И на самом деле проблем никаких нет пока.
Давайте посмотрим на мердж.
Сильно ли пострадал мердж от того, что мы избавились от ключей?
Да он вообще не пострадал. Смотрите, где мы тут используем ключи?
Нигде. То есть мерджу вообще ключи не нужны.
То есть вы что ни подсунете мерджу, он все схавает.
В том смысле, что у вас есть два массива,
которые вы по какой-то причине представляете в виде бинарного дерева поиска.
Вы подсовываете эти два массива мерджу,
и мердж их вам склеивает за логарифмическое время.
То есть из-за того, что мы избавились сейчас от ключей,
мердж вообще никак не пострадал.
А что со сплитом?
Со сплитом проблема. Вроде как сплит хочет нам ключи.
Давайте исправим сплит так, чтобы он требовал не ключи,
а требовал индексы.
Скажем, мы хотим распилить дерево так, чтобы у нас там...
Хотим распилить наше дерево по пятому индексу.
Чтобы все элементы с индексами меньше чем пять оказались в одном дереве,
чтобы все элементы с индексом больше либо рано чем пять оказались в правом под дереве.
Мы избавились от ключей, но при этом вот эти самые значения 0, 1, 2, 3 у нас остались в неярном виде.
Давайте просто возьмем и изменим сплит с х, то есть с ключей, на к.
То есть сплит у нас теперь работает так.
Я делаю сплит к, и он мне возвращает два массива.
Массив, в котором k элементов, и в котором n-k элементов.
Но при этом порядок элементов остается тем же самым.
И заменить мне нужно всего лишь одну строчку, вот тут.
На какое условие мне тут нужно заменить?
Ну, смотрите, я нахожусь в корне.
Чему равен индекс этого корня?
Да, смотрите, индекс корня всегда совпадает с размером левого под дерево.
Давайте, не знаю, это может не очевидно, но давайте так.
Индекс корня, ну или ключ, давайте так, ключ корня,
всегда равен размеру левого под дерево.
То есть теперь вместо t стрелочка x, мне достаточно использовать size от t стрелочка left.
Ну а вместо x0 я использую k.
Вот и все.
Давайте еще раз.
Идея такая.
Я хочу решать задачу RMQ RSQ на массивах.
Но при этом так, чтобы моя структура данных позволяла мне выяснить,
что у меня есть код рамки, у меня есть код код кодов и так далее.
И это будет очень важно.
Но это не будет иначе.
Я хочу решать задачу rmq-rsq на массивах, но при этом так, чтобы моя структура данных
позволяла осуществлять еще и логарифмические вставки и удаление из массива.
Казалось бы, задача нерешаемая, потому что как бы вставлять и удалять элементы из массива
можно только за линейное время. А я предлагаю следующую вещь.
Я предлагаю, давайте я возьму все элементы и упорядочу их в виде, допустим,
дикартового дерева, ну или вообще любого бинарного дерева поиска.
Ну просто вместо ключей, то есть не буду использовать ключи, а буду использовать
ну кату порядковую статистику, окей? То есть вот по структуре дерева я всегда
могу понять, какой элемент у меня стоит на седьмом месте, какой у меня элемент стоит на третьем месте.
Вот, я организую их вот в такую структуру. Ага. Как я этого добьюсь? Ну, очень просто.
Я как бы буду реализовывать дикартовое дерево. С мерджом все в порядке, да?
Мердж как у меня был, так он и остался. Сприт я просто немного изменю, ну просто заменю там ключ
х на индекс к, и вместо там ключа х буду использовать размер левого поддерева. Вот и все.
Ну давайте для примера, не знаю, посмотрим, как должна работать операция вставки.
Вставка в произвольную позицию массива.
Insert. Я хочу вставить элемент, допустим, в позицию k. Элемент со значением value.
Ну и массив a. Ну давайте t. Массив у меня представляется в виде вот такого бинарного дерева.
Что я должен сделать? Ну как и раньше, да? Я должен сделать split.
То есть у меня был массив размера n, я разбил его на два массива. В одном количество элементов k, во втором n-k.
Ну и все. И теперь я сюда вот между ними вставляю новый элемент v. И он как раз таки будет иметь индекс равный k. Согласны?
Вот тут элементы в k, и этот элемент k. Ну то есть, как и раньше, return merge t меньше, чем k. Merge v, и t больше либо равно, чем k.
Мерджу, вообще говоря, плевать на ключи, поэтому я просто говорю, что сначала должен идти массив t меньше k, потом должен идти массив, который получается в результате конкотинации элемента v и массива t больше либо равно, чем k. Вот и все.
Как делать erase тоже понятно. Абсолютно точно так же. Просто вместо ключа в сплети используем порядковую статистику.
Сдайте какой-нибудь вопрос, что непонятно осталось.
Давайте пример приведем.
Если вам дан некоторый массив, скажем, 5, 4, 1, 2, 0, то вы из этого массива можете построить какое-нибудь декартовое дерево.
То есть вы генерируете приоритеты. Какой-нибудь приоритет здесь, какой-нибудь приоритет здесь, приоритет здесь, приоритет здесь.
И дальше, собственно, в цикле вставляете элементы в нужную позицию.
И у вас получается в итоге вот такое вот бинарное дерево. Ну, как пример.
Может получиться другое. 5, 4, 1, 2, 0. Ой, неправильно. 5, 4, 1, 0.
То есть на нулевой позиции у вас стоит 5, на первой позиции у вас стоит 4, на второй позиции стоит 1, на третьей 2, на четвертой 0.
Ну, ровно то, как мы и хотели.
Все, и теперь вот над этой структурой вы можете издеваться как угодно.
Ну, снова, вы можете сделать запрос на отрезки. То есть вы хотите сделать запрос на отрезки от, скажем, от единицы до трех.
Ну, тогда в терминах бинарного дерева поиска вы должны сделать запрос на отрезки, точнее, на полуинтерминале от единицы до четырех.
Ну, ровно то, что мы делали раньше. Разрезаем сначала по единице, потом разрезаем по четверке.
Смотрим результат там и так далее.
Если вы хотите выполнить апдейт, то же самое. Вырезаете нужное вам дерево, ставите промец корень, и дальше дерево собирается обратно.
Все. То есть по сути мы решили ту же самую задачу с помощью кода бинарного дерева поиска.
Но, дополнительно у нас появилась следующая возможность.
Мы можем вставить элемент в нашу структуру данных.
То есть, допустим, я хочу вот сюда вставить минус единицу.
Ну, очень просто. Вызываю вот этот инсерт.
Теперь у меня, ну скажем, курс дат может получиться.
Вот так пойдет? Нет, не пойдет.
Ну, вот так, например. Да? Нормально?
Ну, я не знаю, как там сделать декартовое дерево, но, например, как-то так.
Все. То есть за логарифмическое время вы вставили элемент, и все значения там всяких сумм, минимум, максимум, все, что вам нужно, оно пересчиталось.
Тоже за логарифм. Все. То есть мы теперь умеем выполнять операции на массивах, на их подотресках за логарифмическое время.
При этом со всякими вставками удаления.
Еще. То есть что еще мы умеем делать? На самом деле это еще более мощная структура данных, чем деревоотресков. Почему?
Дело в том, что я могу выполнить такую операцию, как, ну, например, ротейт.
Знаете, что делает ротейт? Ну, C++ в стандартной билетеке.
Ну, ротейт, короче говоря, принимает массив и два его подмассива.
И ротейт просто-напросто берет и меняет эти куски местами.
В общем, в качестве упражнения подумайте, как это можно сделать за линейное время.
Ротейт можно выполнить за линейное время.
Но я утверждаю, что если вы организуете ваши данные в виде декартового дерева или в виде бинарного дерева поиска, то ротейт вы можете выполнить за логарифмическое время.
Как?
На две достаточно.
Да, то есть вы сплитите дерево на две части, а дальше мержите в обратном порядке.
Круто.
То есть ротейт в случае, это просто сплит, плюс мерж в обратном порядке.
И на это все еще навесили rsq и rmq.
То есть вы решаете задачу rsq и rmq с запросами вида, там, не знаю, обновить там сумму на отрезке на плюс десять и поменять местами там два куска массива.
Еще одна операция.
Что еще можно выполнить?
Короче говоря, на самом деле кажется, что сложно придумать, что нельзя сделать с помощью структуры данных.
Но, например, можно еще сделать следующую вещь.
Вы решаете там ту же самую задачу rmq и rsq со всякими суммами на подотрезке, обновления на подотрезке.
И плюс иногда поступают запросы вида развернуть какой-то подотрезок.
Вот вам дан насиль, и вам нужно взять вот этот подотрезок и развернуть его.
То есть делать реверс.
Как это сделать с помощью дерева отрезков, ну, вообще говоря, непонятно.
А с помощью декартового дерева это можно сделать.
Как?
Как можно развернуть...
Умножить на минус один, что это значит?
Приоритеты на минус...
Нет, приоритеты, вообще говоря, сложно менять.
Нет, это не сработает.
Приоритеты у вас считаются фиксированными.
Вообще говоря, сплит и мерч не ожидают, что у вас в какой-то момент приоритеты меняются.
Поэтому это, вообще говоря, тяжело.
Но идея, на самом деле, правильная.
Давайте вырежем нужный нам кусок дерева.
То есть получили какую-то часть массива, которая отвечает за левую часть, которая не вошла,
за правую часть, которая не вошла, и вот за центральный кусок, который нам нужно зареверсить.
А давайте сделаем следующую вещь.
Давайте не будем переворачивать, вообще говоря, массив долго, согласны?
Переворачиваем с массива за линейное время.
Давайте его не будем переворачивать, давайте сохраним обещание, что мы его когда-нибудь перевернем.
То есть это будет такой отложенный переворот.
То есть здесь мы сохраним промисс равно реверс.
То есть мы не будем его переворачивать, мы сохраним обещание.
Ну и склеим обратно.
Вопрос. Как выполнять обещание переворота?
Вот у меня есть вершина, которая говорит, что она реверст.
И у нее есть два сына.
Которые не знают, что они реверст.
И вот в какой-то момент я делаю пуш, то есть говорю, что вот ты должен выполнить свое обещание.
В чем заключается выполнение обещания в этом случае?
Да. Всем понятно? Где? Кто украл?
Всем понятно, в чем заключается пуш?
Как выполнить обещание здесь?
Нужно поменять лево и право с иными местами.
Теперь это R, теперь это L.
И дальше сказать, что вы перевернуты.
И вот здесь.
Теперь это R, теперь это L.
И дальше сказать, что вы перевернуты.
Реверст, реверст.
А ты не реверст.
Дальше, когда уже у детей попросят пуш, они в свою очередь будут что-то менять и так далее.
Видимо пора заканчивать, но в общем резюме.
Тут есть такая идея, которая называется деревья по неявному ключу.
То есть вы избавляетесь от ключей и вместо ключей просто используете порядковые статистики.
Что это вам дает? Это вам дает на самом деле функционал обычного массива.
То есть вы каждому элементу теперь по ключу обратиться не можете, потому что вы ключи сами не храните.
Но зато вы можете обращаться к элементам по их индексу.
То есть, по сути, вы любой массив можете сохранить в виде бинарного дерева поиска.
Что это нам дает? С одной стороны, это дает нам обращение к каждому элементу за алгорифм.
Это дает нам...
Вставку в конец за алгорифм, все то, что в обычном массиве вроде как делается за единицу, мы теперь делаем за алгорифм.
Но верное и обратное. Все то, что мы делали до этого за линейное время, мы теперь можем делать за алгорифмическое.
В частности делать вставку произвольное место массива.
Удаление из произвольного места массива.
всякие операции наподобие rotate, то есть поменять там два куска массива местами,
или даже reverse, то есть взять какой-то кусок массива и перевернуть его за логарифмическое время.
Данная структура данных значительно расширяет функционал и возможности применения массива к задачам RMQ-RSQ.
На сегодня все.
В следующий раз, напоминаю, в следующий раз у нас контрольная,
видимо на второй половине, примерно в 4 часа начнем, в 5 закончим контрольную лекцию.
В общем, будет контрольная по всем тем, которые мы обсуждали на лекциях.
В следующий раз мы, скажем так, все, что касается последнего четвертого задания, мы обсудили.
В принципе, никакого нового семинарского материала не будет.
Этот семинар предстоящий и следующий семинар вы полностью обсуждаете,
дикартово дерево и все остальное, все, что вы не успели обсудить.
В следующий раз мы рассмотрим...
Вообще говоря, я хотел задать вам вопрос, что нужно рассматривать,
но потом я когда сюда шел, я уже сам принял решение.
В следующий раз мы будем рассматривать задачу, которая тесно связана с RMQ-RSQ,
но она как бы имеет такой, больше, наверное, теоретический смысл,
чем практический.
Просто рассмотрим, что еще можно в этой теме сделать,
какие есть алгоритмы и так далее,
без какого-то практического применения в контестах и так далее.
Все, всем спасибо.
