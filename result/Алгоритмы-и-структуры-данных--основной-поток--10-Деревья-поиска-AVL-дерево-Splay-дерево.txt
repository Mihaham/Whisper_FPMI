Мы переходим к блоку про деревья поиска, посмотрим
много всяких разных реализаций, ну и посравниваем, какие
бывают выгоднее, когда какие лучше использовать.
Дерево поиска, как следует из названия, позволяет
нам в каком-то смысле искать элементы в множестве.
Мы будем хранить множество элементов и наконец-то
научимся решать задачу о поиске элементов в множестве.
Ну поиск тоже самое, проверка наличия или в каком-то смысле
узнавание, где конкретный элемент лежит.
Ну давайте формализуем.
Мы хотим хранить, ну давайте напишем, что деревья поиска,
значит мы хотим создать такую структуру данных,
которая бы хранила множество s, к которому поступают следующие
запросы.
Ну первый самый простой, это как раз поиск, проверка
наличия элементов в множестве, значит find x, это просто сказать
да или нет, есть ли x в множестве, ответить на вопрос, есть
ли x в множестве s.
Ну и соответственно, если есть запросы поиска, то
наверное надо как-то наше множество уметь изменять.
Ну вот к множеству будут поступать запросы двух типов.
Это insert, добавить x в s, ну то есть если его там не было,
то положить, значит давайте считать, что у нас хранится
именно множество, а не мульти множество, и дубликаты мы
как бы игнорируем, если у нас два раза добавляется
одно и то же число, там insert x, insert x, то мы второй
insert будем игнорировать, ну потому что в множестве
у меня дубликатов, дубликаты отсутствуют.
Если надо, мы можем потом спокойно это модифицировать
так, чтобы хранить именно мульти множество, ну например
можно просто с каждым x хранить ассоциированное
число раз, в которое он входит, и там сколько раз
пришел insert, можно рядом с этим x всегда хранить сколько
раз он в нашу структуру входит.
Ну пока давайте считать, что это множество, дубликатов
не бывает.
Ну и обратная операция, это erase, это соответственно
удалить xss, вот, значит это основные три операции,
которые должны уметь поддерживать дерево поиска, есть еще
опциональные, которые ну нужно не всегда и не все реализации
дерево поиска с этими операциями хорошо справляются, значит
это merge, похоже на то, что у нас уже было, когда мы
про кучи говорили, мы вот раньше объединяли кучи,
теперь то, что самое объединить нужно будет деревья, то есть
представьте, у вас есть два множества с 1 и с 2, каждая
из которых хранится в каком-то дереве поиска, ну вы хотите
просто их склеить, объединить, вы хотите построить одно
новое дерево поиска на объединении двух множества с 1 и с 2.
Ну и обратная процедура, это разделение, split множество
давайте s по ключу k, значит это процедура разделения
множества s на 2 под множество, на те ключи, которые меньше
либо равны k и на те ключи, которые больше, чем k, ну то
есть вот если у нас были все элементы в s, мы их грубо
говоря посортировали, все не большие k отнесли в
лево, все большие k отнесли вправо, то есть здесь ну
давайте я так напишу, мне нужно разбить, мне нужно
найти все такие x из s, которые были меньше либо равны k,
это будет первое множество, второе это все такие x из
s, которые были больше, чем k, ну соответственно в каком
смысле процедура обратная к merge, наоборот расплитить,
разбить одно множество на два под множество по какому-то
значению, по ключу k, можно, да, но хешмапы мы ближе
к концу разберем, хешмапы они в каком-то смысле, давайте
пока, это будет потом, сейчас у нас будут алгоритмы, которые
честно работают без хеширования, честно отвечают на все
эти операции, будет зал алгоритм, вот, это во многих
ситуациях лучше хешмапы, давайте вот когда до хешмапа
подойдем, тогда обсудим в чем отличие, вот, значит
вообще говоря мы обычно будем в качестве s хранить
множество целых чисел, ну там int или long, с точки зрения
теории это важно только тем, что мы умеем элементы
сравнивать между собой за единицу, скажем если
у вас есть два целых числа, храняющиеся в каких-то
стандартных типах данных, то вы можете их за одно
действие, за значок меньше и больше, сравнить, узнать
какой из них больше, но грубо говоря тогда понятно,
что вот эти операции меньше равно больше, они легкие.
Вообще говоря, можно в дереве поиска хранить более или
менее любые, какие угодно объекты, также как на самом
деле во всех предыдущих, в куче можно было их хранить,
объекты любых типов, главное чтобы на них были определены
вот эти операции больше и меньше, ну и желательно
чтобы они за какое-то адекватное время подсчитывались, administrative
, можно довольно легко понять какой из них больше,
Я буду почти всегда неявно предполагать, что множество у меня хранятся числа, хотя на самом деле эта теория более общая и, конечно, можно хранить там более-менее что угодно, что можно сравнить между собой.
Например, с их помощью можно хранить всякие базы данных, например, у вас есть какой-нибудь сайт, на котором вам надо хранить логин-пароли пользователей.
Ну вот, соответственно, у вас есть множество с, множество пар, грубо говоря, какой пользователь, какой у него пароль.
И тогда, когда потом приходит новый пользователь и пытается залогиниться в вашу систему, вам надо проверить, правильна ли у него пароль,
ну вы просто смотрите на find, есть ли такой пользователь с таким паролем в системе.
Ну и, соответственно, там говорите, что у вас либо ошибка в пароле, либо в логине, ну а иначе вы пользователя опускаете и говорите, вот он залогинился.
Ну и, соответственно, erase, insert – это процедура, скажем, удаления аккаунта, это процедура добавления нового аккаунта на сайте.
Так что вполне такая полезная штука есть.
Merge, split – они такие с точки зрения практики более абстрактные, но в каких-то, опять же, в каких-то конкретных задачах, где дерево поиска используется как подзадача, они бывают очень нужны, мы тоже потом это посмотрим.
Давайте сначала посмотрим на наивное дерево поиска.
Это самая простая попытка реализовать все вот эти вот запросы.
Мы будем хранить все наши элементы в виде бинарного корневого дерева.
У нас будет некий корень, у каждой вершины будет максимум два сына.
Ну давайте я вот что-нибудь такое нарисую.
И мы, соответственно, будем различать левого и правого сына.
Левый сын и правый сын – это именно разные вещи.
Может быть, левый может не быть правого, может быть, наоборот, может быть, правый не быть левого, могут быть оба, может не быть никого.
Ну вот, например, вот это корректно бинарное дерево.
В каждой вершине у меня будут храниться элементы множества.
То есть, по факту я на всех элементах S ввожу вот такую деревовидную структуру, подвешиваю за какой-то корень,
и вот оно, соответственно, у меня ориентировано сверху вниз,
то есть, тут такие стрелочки на самом деле стоят, ор assassin у меня сверху вниз,
в каждой вершине лежат элементы, соответственно, вершин ровно столько же, сколько элементов.
Вот здесь у меня вершин 1, 2, 3, 4, 5, 6, 7, 8, 9, 10.
Это дерево, представляющее какое-то десятиэлементное
множество.
Давайте я как-нибудь пример приведу, как оно может быть
заполнено.
Ну пусть здесь какое-нибудь число типа 20 состоит.
Ну, например, что-то такое.
Соответственно, S – это просто все вот эти числа, которые
я записал в вершину.
Значит, они здесь расположены не случайно, они расположены
по следующему правилу.
Смотрите, что если в вершине написано какое-то число
X, то в дереве поиска у меня обязательно все, что находится
в левом поддереве, все элементы, которые получаются
в левом поддереве при спуске в левого сына.
Вот здесь все числа всегда строго меньше, чем X.
А справа, наоборот, если я спускаюсь в правое ребенко,
то у меня, наоборот, здесь все числа строго больше,
чем X.
Ну вот на картинке вроде это как раз выполняется.
Смотрите, вот, например, в корне у меня число 20.
Давайте посмотрим на все левое поддерево корня.
Тут какие числа?
10, 5, 15, 3, 7, 14, 9.
Эти все числа меньше, чем 20, поэтому они имеют право
находиться в левом поддереве корня.
Справа, наоборот, справа у меня 21, 23 – это числа
больше, чем 20, они имеют право находиться справа.
Наоборот, 15 вот сюда я поместить бы не мог, потому что здесь
числа обязательно должны быть больше, чем 20.
И более того, вот это правило про то, что слева меньше
и справа больше, оно выполняется не только для корни, но
и для всех вершин.
Например, вот для этой десятки слева во всем левом поддереве
числа могут быть только меньше, чем 10.
Ну и здесь вроде у меня это верно.
3, 5, 7, 9 – это все числа только меньше, чем 10.
А в правом поддереве числа только больше, чем 10.
14, 15 числа больше, чем 10.
Вот, кстати говоря, вот на это дерево у меня накладывается
как минимум два ограничения.
Смотрите, они с одной стороны больше, чем 10, потому что
лежат в правом поддереве десятки, с другой стороны
все меньше, чем 20, потому что они лежат в левом поддереве
двадцатки.
Вообще говоря, каждое такое поддерево, оно в каком-то
смысле ограничено и слева, и справа какими-то своими
предками.
Ограничено слева десятка, и справа двадцатка.
Все значения в этом поддереве между десяткой и двадцаткой
расположены.
Ну, соответственно, тем самым, что такое дерево
поиска?
Дерево поиска – это бинарное корневое дерево.
Ну, давайте я скажу удовлетворяющее вот этому свойству для
любой вершины.
Удовлетворяющее вот этому вот свойству для всех вершин.
Вот, значит, это определение дерева поиска, определение,
что такое дерево поиска.
Вот, хорошо, значит, я утверждаю, что вот такая вот структура
на элементах моего множества дает мне весьма большие
преимущества.
Ну, давайте, например, поймем, как реализовывать процедуру
find x.
Подсказывайте.
Если х меньше, то спускаем снизу.
Да, да, да.
Абсолютно верно.
Значит, давайте, вот у меня есть какое число х, давайте
посмотрим на корень моего дерева.
Корень.
Ну, во-первых, понятно, что если здесь написано
число х, то мы нашли число х.
Вот оно вот здесь вот лежит, мы победили х в дереве.
Даже более того, мы знаем, где конкретно оно лежит.
Какая конкретная вершина соответствует числу х.
А иначе мы однозначно понимаем, в какой из двух поддельев
надо спускаться.
Либо влево, либо вправо.
Потому что, скажем, если здесь лежит число у, то
по знаку сравнения х и у мы понимаем, куда надо
идти.
Да, если х меньше, чем у, то нам нужно в любом случае
идти влево, потому что справа чисто только больше, чем
у, и х там находиться точно не может.
Х, если где-то и лежит, то только слева.
Ну и наоборот, если х больше, чем у, то он обязан находиться
справа, если где-то и находится, то он обязан находиться
справа, потому что слева только числа меньше, чем
у, а значит меньше, чем х.
Поэтому их там искать бесполезно.
Ну вот, и тем самым мы понимаем, в какую из двух веточек
всегда нужно идти.
У нас нет смысла раздваиваться идти и туда, и туда, как это
было в дереве отрезков.
Мы всегда понимаем, что мы, скажем, идем либо влево,
либо вправо.
Только в одно из двух направлений.
Вот.
Поэтому такой очень простой алгоритм поиска, мы понимаем,
куда надо идти.
И время работы будет очевидно от h, где h – это глубина
Ну, потому что в худшем случае я просто от корня
спускаюсь до какого-то листа.
А если, скажем, х в дереве нет, то я иду-иду-иду, его
ищу, в конце концов дохожу до такой вершины, откуда
идти больше некуда.
Это в точности лист.
Лист – это вершина без детей.
Ну и как раз h – это глубина, это максимальное расстояние
от корня до какого-либо листа.
Да, понятно же?
Хорошо.
Так, ну давайте тогда insert скажем, как можно реализовать.
Insert x.
Ну, во-первых, давайте сначала запустим процедуру find, и
если х уже в дереве есть, то, наверное, его добавлять
не нужно.
А, значит, давайте я здесь буду считать, что х в дереве
отсутствовал.
Потому что, если что, можно предварительно проверить,
есть он там или нет с помощью find, и если есть, то ничего
не делать.
Теперь считаем, что его нету.
Ну, давайте тогда найдем место, куда было бы его
логично разместить.
Давайте будем спускаться аналогично find в поисках
х.
То есть, окей, мы считаем, что х нет, но давайте попробуем
пойти по тому пути, где он как бы должен был бы
быть.
Делается точно так же.
Если мы знаем, как х сравнивается с текущим значением вершины,
то мы понимаем, в какого из двух сыновей идти – в
левую или в правую.
Ну, давайте так как-то пойдем.
Найдем до листа, то есть вершины без детей.
По идее, как бы вот куда-то сюда надо подвесить х.
Ну, давайте тогда просто подвесим х в качестве соответствующего
сына слева или справа к этому листу.
Давайте, если здесь было написано число z, то подвесим
х слева, если х меньше, чем z, ну и справа иначе.
Давайте я нарисую картинку для х меньше z, и отдельно
для х больше, чем z.
Простите, пожалуйста, не логичнее запускать поиск,
а сразу...
Ну, на самом деле я ровно это и делаю.
То есть я встаю в корень, сравниваю пошагово х с текущим
значением вершины, куда-то спускаюсь.
Рано или поздно я либо дошел до вершины равной х, тогда
можно завершиться и ничего не делать, либо я дохожу
до листа и подвешиваю с одной из двух сторон.
А, это дерево может быть линейным.
Да.
Именно поэтому это наивное дерево поиск.
Пока что я...
Ну, то есть я это рассказываю затем, потому что мы это
будем делать почти везде, просто обычно после того,
как мы, скажем, подвесили куда-то х, мы будем запускать
какую-то процедуру балансировки, чтобы дерево не разрасталось
в длинную колбасу, чтобы оно было не очень глубокое.
То есть я хочу поддерживать глубину не очень большую,
чтобы файн быстро работал.
Но пока давайте в тупую делать, просто хранить какое-то
корректное дерево.
Так, понятно, что такая процедура, инсерт корректно
работает.
Но она сохраняет все свойства дерева, потому что мы подвешиваем
х туда, куда можно.
Ещё раз, мы запускаем типа find, идём куда-то по какой-то
ветке, всегда сравним х с текущим значением, понимаем,
куда надо идти влево или вправо.
Рано или поздно мы либо дойдём до х, и тогда ничего добавлять
не нужно.
Либо мы дойдём до вершины без детей, то есть до листа.
И тогда надо подвесить х на то пустое место, как
он соотносится с z.
А если мы вставляем, например, в то дерево число 11?
Вставляем в то дерево число 11.
Ну, смотрите, давайте вставим 11, очень просто.
11 меньше, чем 20 идём налево.
11 больше, чем 10 идём направо.
11 меньше, чем 15 идём налево.
11 меньше, чем 14 идём налево.
Поэтому 11 должно быть вот здесь, вот левее, чем 14.
Вот.
Ну всё, получается, что инсерт мы тоже реализовали
за олаташ.
Так, хорошо.
Ну и последнее, надо сказать, как работает erase.
Erase х.
Ну, давайте опять считать, что х на этот раз, наоборот,
в дереве присутствует, потому что иначе надо удалить
элемент, которого нету в дереве, можно ничего не
делать просто.
Давайте считать, что х в дереве присутствует.
Вот.
Давайте сначала его в дереве локализуем.
Найдём, где он лежит.
Спустимся от корня, найдём его позицию в дереве х.
Значит, тут есть один простой случай.
Значит, если х – это лист, или, скажем, у него есть всего
один из двух детей.
Ну, например, ну не знаю, давайте правый сын у него
есть.
Вот у него есть правый сын, и там что-то ещё в его
поддереве что-то находится.
А левого сына, например, нету.
Ну тогда можно сделать очень простую вещь.
Можно просто вот то, что было в поддереве, скажем,
всё правое поддерево х, просто взять и переподвесить
на место х.
То есть я х высекаю из моего дерева, и на его место подвешиваю
то, что лежало ниже него.
То есть я вот этот путь сохраняю, и дальше вместо х подвешиваю
целиком всё это под дерево t.
Вот на место х я просто по факту всё это поднимаю
вместо х.
Вот, значит, например, здесь…
Так, ну тут…
Ну, например, если меня просят удалить 15, я могу
просто 14 поднять вот сюда вот, и забыть про существование
14.
Ну то есть, на самом деле, я забыл сначала про 15,
на его место поднимаю 14, у меня будет просто 10 стрелка
14.
А вот этого всего уже нет, потому что я это поднял.
Значит, это простой случай.
Если у меня было 0 детей или 1 сын.
Если 0 детей, то можно просто х удалить, и дерево останется
хорошим.
Значит, это случай, когда у меня не больше, чем 1 ребёнок.
Вот.
Значит, что делать, если у меня 2 сына?
Представьте, я нашёл х в дереве, и у него, к несчастью,
есть оба сына, левый и правый.
2 под дерево, левый и правый.
Значит, здесь я сделаю следующее.
Например, я могу сделать такую вещь.
Давайте мы в этом правом под дереве, в праве х всё,
что находится, и ниже, давайте найдём в этом под дереве самое
маленькое число, самый маленький элемент.
Давайте я его назову какой-нибудь m.
Пусть m это минимум в правом под дереве х.
Во-первых, как найти минимум?
Давайте, если я сюда вот встал, как найти в этом под дереве
минимальное число, минимальное элемент?
Да, надо просто идти влево, пока есть левый сын.
Потому что мы знаем, что при спуске влево, то есть в сторону,
на этой картинке влево я когда иду, у меня всегда значение
уменьшается, а если я иду направо, то увеличивается.
Поэтому единственный способ уменьшать текущее значение,
это идти влево.
Так вот, давайте из этой вершины будем просто идти влево, влево, влево,
пока левый сын есть, до тех пор, пока не найдется вершина,
у которой нет левого сына.
Вот я отужаю, что она обязательно будет минимальной.
Ну понятно, потому что если я в какой-то момент отсветляюсь направо,
то я увеличиваю свое значение по сравнению с предыдущим значением.
Поэтому минимум может быть только вот этой вот вершиной,
которая получается, когда мы шли все время влево.
Вот, значит, хорошо.
Давайте я дерево так нарисую.
Мы нашли вершину m, минимальную вершину в правом под дереве,
и у нее в частности нет левого сына.
Потому что, будь у нее левый сын, она была бы не минимальной,
можно было бы спуститься и получить значение еще поменьше.
Значит, у m нет левого сына.
У m нет левого сына.
Тогда я могу сделать пример на следующий.
Я могу сделать erase m,
и значение m написать вместо x.
Ну смотрите, erase m я делать уже умею,
потому что раз у m нет левого сына,
то мне нужно просто все правое под дерево m-ки
переподвесить на место m.
То есть давайте виртуально сделаем erase m.
Erase m я делать умею.
Я нахожу m, вот она у меня, вершина m.
Левого сына нет, а правое возможно есть,
я все это правое под дерево вершины m подвешу на место m,
а m как бы оттуда высекаю.
А потом давайте вот то m, который я высек,
давайте я его поставлю на место x.
Тогда с одной стороны я избавлюсь от x
и реализую тот самый erase x.
С другой стороны у меня сохранится вариант дерева поиска.
Потому что, ну вот представьте,
по факту что я сделал, я просто вместо x написал здесь m,
и вот это правое под дерево поднял на место m.
Я утверждаю, что это корректное дерево поиска теперь будет.
Ну почему? Потому что все, что было левее, оно было меньше x,
einem было больше x, значит тем более меньше, чем m,
потому что поскольку m лежало в правом под деревье x,
то, конечно же, м больше, чем x,
потому что m лежало в правом под дереве x.
Тут был x, тут m, m больше, чем x.
Поэтому, когда я его сюда поднимаю,
левое под дерево будет по прежнему меньше, чем m,
здесь все будет хорошо,
и с правым, под деревом тоже неравность в ней нарушится,
потому что я отсюда взял специально самый маленький элемент,
поднял его сюда, значит он об Lang
меньше, чем все остальные,
потому что он был там самый маленький,
вот туда поднял, значит, этот элемент меньше, чем все, что осталось здесь.
Ну давайте я схематично напишу, что я как бы делаю erase m и заменяю x на m.
Замена x на m. Вот.
Так мы будем делать в случае, когда у удаляемой вершины x два ребенка.
То есть по факту я свел случай двух детей к одному ребенку.
Вот как раз я нахожу вершину m, у которого один ребенок,
поднимаю этого одного ребенка на его место, и m поднимаю на место удаляемой вершины x.
Вот. Все. Да.
А мы можем аналогично взять из левого потерянного?
Да. Абсолютно аналогично.
Можно было бы сделать то же самое.
Можно было бы в левом сыне найти максимальный элемент.
Этот самый максимальный элемент как бы удалить,
потому что у него нет правого сына, значит, его можно удалить с помощью вот этой процедуры.
И этот максимальный элемент поднять на место x.
Можно делать то же самое.
То же самое неважно.
Если у вас есть оба сына, можно делать и то, и то.
Окей?
Сейчас мы потихоньку будем переходить к тому, как делать по-человечески.
Значит, это корректно, но это долго.
Как минимум потому, что давайте представим, как у нас будет работать последователь операций
insert 1, insert 2, insert 3 и так далее.
Если я вставляю числа в порядке возрастания.
Но по факту у меня просто будут они вставляться вот в такую правую ветку.
Сначала 1 будет корнем, потом 2 подвержется справа, 3 справа, 4 справа и так далее.
У меня будет такая ветка правых детей вниз.
Окей.
Давайте тогда перейдем к более осмысленной структуре.
Это называется AVL-дерево.
AVL это просто фамилия авторов.
Там нет какой-то тайны, что это такое.
И давайте мы попробуем что-то сделать с нашим деревом так, чтобы оно не вырождалось
в такую длинную петлю направо.
Ну или там какую-либо.
Мы хотим, чтобы оно было сбалансированным.
Дерево поиска.
Сбалансированное значит, что у него будет глубина всегда порядка логарифма.
Глубина будет всегда порядка логарифма.
Вот.
Ну определение.
Значит, бинарное дерево поиска.
Называется AVL-дерево.
Если для любой вершины В выполняется следующее соотношение.
Значит, вот есть вершина В.
Есть у нее левый сын, левое поддерево и правое поддерево.
Давайте я их обозначу буквами L и R.
Так вот, мне необходимо, чтобы разность глубин деревьев L и R была не очень большой.
А именно, модуль разности h от L минус h от R должен не предстоить единицу.
На где h от T, это глубина дерева T.
Ну вот скажите, пожалуйста, например, вот это AVL-дерево или нет?
Почему?
Ну да, потому что, смотрите, если мы в качестве В возьмем корень, то у меня левое поддерево имеет глубину 1, 2, 3, 4.
Вот он самый длинный путь в левом поддереве.
4, а здесь 2. 4а2 отличается больше чем на единицу, это не AVL-дерево.
Но кажется, если бы я стер вот эту девятку и рассмотрел такое дерево, то это похоже на AVL, потому что здесь глубина становится 3 и здесь 2, это нормально.
Для этой вершины условие выполнено.
Также, мне нужно не только для кор CopyW dice, но вообще для всех вершин дерева проверить.
Давайте и здесь проверим, здесь вообще хорошо. Здесь и с левого глубина 2, а и с правого глубина 2.
Поэтому для этой вершины вообще все отлично.
Для этой вершины тоже нормально, потому что с левой глубины 0.
нормально, потому что слева глубина 0, левого сына нету, здесь глубина 0,
но справа 1. 0 и 1 отличаются не больше на 1, здесь все хорошо. Вот, ну и здесь тоже
тривиально, здесь вообще одинаковые глубины, здесь отличаются на 1. Короче, все
хорошо. Это вот это уже овель-дерево. Мне нужно, чтобы у каждой вершины, для каждого
вы, обратите внимание, для каждой вершины, не только для корни, а вообще для всех,
для всех вершин разность глубин левого и правого по деревьев
здесь отличается максимум на 1. Вот. Хорошо. Значит, вот такое странное с неба взявшееся
условие. Оказывается, что при нем глубина обязательно будет логарифмической. Это
во-первых. Во-вторых, это свойство не очень сложно поддерживать при ответе на
все вот эти запросы типа insert и erase. То есть нам нужно сделать две вещи. Нам
нужно, во-первых, доказать, что в таком определении глубина будет небольшая,
всегда логарифмическая на самом деле. Во-вторых, показать, как поддерживать вот эти
вот условия про разность глубин детей при вставке и удалении вершин. Потому что,
понятно, когда мы что-то вставляем, у меня глубины могут испортиться. Ну, если я вот
здесь, например, девятку добавлю просто, обратно добавлю ее, тогда у меня вот для
этой вершины что-то сломается, надо что-то делать, потому что это уже не корректно
в L-дерево. Вот. Но надо понять, как с этим жить. Ну что, давайте для начала докажем,
что L-дерево на N-вершинах имеет глубину от логарифма N.
Доказательства. Давайте, так же, как мы уже когда-то делали, ведем обратную функцию и, наоборот,
для каждого h, для каждой глубины h, посчитаем минимальное количество вершин в правильном
овл-дереве глубины h. Значит, s от h – это минимальное количество вершин в овл-дереве глубины h.
Глубины h. Так, ну, s0, я считаю, что это 0. Я считаю, что дерево глубины 0 – это пустое дерево без
вершин. Пустое дерево является корректным овл-деревом, здесь нет вершин, поэтому оставляется 0.
s от единицы – это 1, потому что просто одна вершина, тут пустое дерево, здесь просто дерево из одной
вершины. Это корректный овл-дерево. У него глубина 1. Ну и вроде все хорошо. А дальше давайте построим
какое-нибудь рекуррентное соотношение на то, как вот эти s растут с ростом h.
Ну давайте нарисуем. Вот пусть у меня есть какой-то овл-дерево глубины h. У него есть какие-то дети –
левая и правая. Ну, смотрите, если все дерево имеет глубину h, то у меня дети точно имеют глубину
не больше, чем h-1. Ну потому что если здесь h, то здесь глубина, она на единичку поменьше, потому что
у меня одна вершина отрезалась. Более того, хотя бы один из сыновей обязательно должен иметь
глубину h-1. Потому что раз здесь глубина h, то есть есть какой-то путь длины h, после отрезания первой
вершины у меня остается путь длины h-1 в поддереве. Поэтому хотя бы один сын глубины h-1 точно быть
должен. Ну тогда у нас на самом деле есть понимание, к какой минимальной глубины должен быть другой сын.
Какой? h-2. Потому что мы знаем, что глубины отличаются максимум на 1, значит здесь не может быть
меньше, чем h-2, потому что иначе было бы некорректно овл-дерево. Все. Отсюда автоматически можно
написать, что sh-то больше либо равно, на самом деле просто равно, потому что такую картинку можно
всегда нарисовать, просто равно 1 плюс s от h-2 плюс s от h-1. Я всегда могу нарисовать, я всегда могу
здесь нарисовать дерево глубины h-1, здесь дерево глубины h-2, правильный корректный вл-дереве,
вот так вот их склеить, получится дерево глубины h. Ну вот, а что-то такое мы уже с вами видели. Да,
линейные рекурренты, причем сумма двух предыдущих по факту здесь написана. Но они растет как чисто
фиба начи. Давайте напишем несколько первых слагаемых, поэтому убедимся. Значит s-2 это 1
плюс сумма двух предыдущих, то есть 2. s-3 это 1 плюс сумма двух предыдущих, то есть 4. Ну не
совсем чисто фиба начи, но что-то похожее. Значит s-4 7, s-5 12, 20. Да, да, это видимо чисто
фиба начи минус 1. Давайте вспомним, что f-0 это 0, f-1 это 1, а f-n это сумма двух предыдущих,
чисто фиба начи. Вот, ну тогда видимо можно заметить, что s-h это... Так, сейчас, я порефлексирую
секунду. Быстрее. Но это, не, мне все-таки хочется точно, ну как бы чтобы доказать,
что они как-то соотносятся, мне нужно точную оценку, потом уже можно сказать, что они быстрее. Сейчас
пол секунды. 0, 1, 1, 2, 3, 5, 5.
Давайте ведем последовательность типа f-r равно s-h-1. Заметим, что f-r это число фиба начи. Заметим,
что s-h растет не медленнее, чем какая-то показательная функция. Ну это сложно. Заметим,
что? Надо доказать, откуда мы это заметим? Все, вот, короче, я утверждаю, что вот это вот будет
решением нашей рекурренты. Вот. Значит, почему? Давайте докажем. Я утверждаю, что если у меня
s-0, s-1 вот такие, s-h-t равно вот такому, то я утверждаю, что s-h-t это вот такое всегда. Но для
любого h хотя бы ноль. Значит, ну, то есть, смотрите, мы знаем уже про s много чего, мы знаем два стартовых
значений, мы знаем ее вооружение через два предыдущих. Давайте докажем индукции по h,
чтобы выполнять такое соотношение, где f это число фиба начи. Значит, почему? Ну, давайте, давайте
индукции. h равно 0, h равно 1. Вроде понятно, потому что h, когда h равно 0, 2 число фиба начи
как раз 1, 1-1 будет, ну давайте, h равно 0, f2 это 1, 1-1 как раз будет 0, h равно 1, 3 число
фиба начи это 2, 2-1 как раз будет 1. База сошлась, но переход тривиален. Что давайте я сотру.
Если я знаю, что s-h-t это 1 плюс два предыдущих, дальше по предположению индукции расписываю вот
эти две s-ки как f-ки. Значит, это будет f-h-t минус 1, это будет f-h плюс 1 минус 1. Две f-ки склеились
в одну f-h плюс вторую и минус 1-ки сократились до минус 1-ки. Вот так прям супер точно. Все,
ну а мораль такая, как бы это я формализм навел просто, мораль такая, что s растут так же быстро,
как число фиба начи, ну там, на двойку сдвинутым индексом, неважно. Значит, они растут экспоненциально
быстро. Мы помним, что n-ное число фиба начи это примерно phi в степени n, где phi это золотое
сечение. На самом деле, просто экспоненциально быстро растет. То есть, можно написать, что s-h-t равно
с точки зрения t-t просто phi в степени h, где phi это золотое сечение. Там 1, то, скорее всего,
и пополам. Вот. Ну, на самом деле, мы знаем, что мы доказали исходное утверждение. Мы хотели
доказать, что максимальная глубина в дереве на n-вершинах, она логарифмическая. Но если мы
доказали, что чтобы в дереве была глубина h, в ней должно быть хотя бы столько вершин, значит,
наоборот, если у меня n-вершин, то глубина максимум логарифм по основанию phi от n. То есть,
отсюда следует, что глубина дерева на n-вершинах не больше, чем o от логарифма n, по основанию phi
уже напишу, растут экспоненты по основанию phi, то здесь логарифм будет по основанию phi. То есть,
если минимальный размер дерева по глубине растет экспоненциально, то глубина по размеру,
наоборот, логарифмическая. Потому что это обратная функция. Вот. Доказали? Норм?
Хорошо. Так, ну теперь нам осталось научиться как-то это поддерживать. Как-то понять, как можно в
наивном дереве поиска так все подкрутить, чтобы у меня всегда было верно вот это условие про
глубины двух детей, что левый и правый по дереву отличается максимум на единичку по глубине. Хорошо.
Значит, для этого мне нужно будет такая простая вспомогательная процедура, которая называется
вращение. Давайте картинку нарисуем. Представьте себе такое дерево. Вот там сверху что-то находится,
там где-то сверху корень, вот как-то, грубо говоря, мы дошли там, может он где-то там,
короче, как-то от корня дошли до вершины П. Пусть у него есть сын Х. Что такое вращение вдоль этого
ребра? Давайте еще вот эти поддеревья как-нибудь назову, А, Б, С. Тогда вращение это следующий
прикол. Вот представьте буквально, что у вас здесь стоят какие-то шарнирщики, и вы берете,
и вот это вот ребро вот так вот прокручиваете. Вот в направлении стрелки вот так вот берете
и поворачиваете. В частности, у вас Х поднимется наверх, а П спустится вниз. И тогда мы на самом
деле получаем следующее дерево. У нас Х становится новым корнем этого всего поддерева, П переходит
вправо, то есть вот это вот ребро я прокрутил, и оно стало вот таким вот, а оставшиеся поддеревья
подвешиваются вот единственным естественным образом. Здесь А, здесь Б, здесь С. Вот,
что поменялось? Ну, Х стало корнем, Х поднялось на единичку вверх. Ну, там мы повозимся еще с этим.
Когда будем применять, да, здесь что-то происходит за глубиной, то есть на самом деле в
каком-то смысле, смотрите, если у меня А было очень глубокое, то я чуть-чуть его поднял. То есть я
поднял головину А на единичку, ну и А тоже на один соответственно поднялось. Ну, там С как-то опустилось,
но неважно, будем еще разбираться с этим. Вот, но главное здесь, что надо понять, это то, что у меня
сохраняются все инварианты. Что если это было деревом поиска, то это тоже остается деревом поиска.
Значит, надо просто помедитировать, понять почему это так. Что все неравенства у меня сохраняются.
Ну, например, смотрите, что такое В. В лежала вправее Ха, но левее П. То есть он должен быть больше
чем Х но меньше чем П. Где оно здесь? Оно вправее Ха, левее П. Больше Ха, меньше чем П. Х лежала
левее П, то есть Х меньше чем П. Здесь X левее чем П, Х меньше чем П, все хорошо. Короче, если вы на все
объекты посмотрите, посмотрите как они здесь относились, как highlighter здесь, то у drugs
Enlightenment останутся такими же, как были здесь вот. Поэтому, значит, инвариант дерева поиска
сохраняется. Давайте. Какое? Авэль строится. Ну можно Зейн-Луген построить. Быстрее, наверное,
нельзя, потому что сортировка нужна. Да, ну Зейн-Луген можно. Так, ладно, давайте это сотру уже. Вот.
Значит, это было вращение направо. Ну, симметрично можно рисовать вращение налево. Давайте здесь
попробуем меститься. Представьте, что у вас была п, у него еще все-таки. Была вершина п, у него был
правый сын х. Значит, что такое вращение влево? Ну, то же самое. Представьте, что здесь шарнирчик. Вы вот
так вот вращаете его по направлению стрелки. У вас х поднимается, становится новым корнем этого
дерева, п спускается влево, ну и все под деревья подвешиваются единственным возможным способом.
Вот. Значит, это правая вращение. Наоборот, левая, да? У меня проблемы с ориентацией. Ну, как бы,
короче, что вращение левого ребра? Это вращение как бы правого ребра налево. Неважно. Вот. Ну,
тоже можно заметить, что все неранее сохраняются. Если то было деревом поиска, то это тоже остается.
Это можно поверить? Хорошо. Ну ладно. Тогда давайте теперь разберемся, как с помощью этих вращений
мы можем добиться того, чтобы у меня всегда было вл дерева. Ну вот, первый шаг такой. Там,
пусть пришла операция инцет или рейс. Давайте мы сначала ее сделаем так, как выполняла бы эту
операцию обычная наивная дерево поиска. То есть там дойдем докуда-то, подвесим или что-то удалим,
ну кроме того же самое, что было раньше. Значит, теперь у меня что-то может сломаться. А именно,
давайте я обозначу, что вот если у меня была вершина В, у нее были под деревья LR, давайте я
через дельту от V обозначу h левая минус h правая. Вот. Та самая разность между глубинами детей.
hL-hR. Правильные значения для дельты это минус 1, 0 и 1. Вот если дельта всегда в
этом диапазоне, то у меня все хорошо. Проблема, когда она вылезает из этого диапазона. Можно
легко заметить, что когда мы делаем инцет или рейс, у меня на самом деле дельта изменяется
максимум на единичку. Она может выпасть из этого диапазона только либо на минус 1 сюда,
либо на плюс 1 сюда. Ну скажем, что в инцерте происходит. По факту вы просто идете по пути и
к какому-то листу довешиваете еще одну вершину. Ну у нее дельта максимум на 1 увеличилась. Из-за
того, что у вас глубина одного из сыновей увеличилась на 1, у вас дельта здесь увеличилась
максимум на 1 или там уменьшилась на 1. То же самое с рейсом. Там была какая-то такая картинка,
вы вместо m подвесили вот этого правого сына. Ну тогда здесь глубина уменьшилась на 1, потому
что я высек m и на его место подвесил правое под дерево. Глубина уменьшилась на 1, ну значит дельты
все тоже изменились максимум на 1. Это когда я вместо вершины высекаю m и подвесил правое
под дерево. Это и рейс. Поэтому мне достаточно починить ситуации, когда дельта это плюс или
минус 2. Плохие ситуации. Дельта равно плюс-минус 2. Тройка она никогда не будет, потому что дельта
всегда изменяется максимум на 1. Если у меня было корректное well дерево, потом я одну вершину
вставил или удалил, теперь неправильно дельта только плюс-минус 2. Мы все будем вращать. Тут будет
много вращений на самом деле. Давайте мы из симметрии, поскольку у меня, ну там можно было
бы всегда поменять местами l и r, и собственно у меня вот эти штуки тоже симметричны, левые правые
вращения. Давайте рассмотрим только случай, когда дельта от какой-то вершины равно минус 2. Давайте
поймем, что делать, если мы нашли какую-то вершину с дельты равно минус 2. Что это значит? Значит,
что скажем, в ее дереве что-то такое произошло. Например, из левого под дерева кто-то удалился,
что глубина левого под дерева уменьшилась, а дельта и так была равна минус 1, стала минус 2.
Ну короче, в общем, дельта испортилась. Вот это а. Вот было какое-то левое под дерево, было какое-то
правое под дерево, причем правое оно именно сильно глубже, чем левое, хотя бы на 2 глубже,
чем левое. На картинка какая-то такая, у меня перекос вправо, левое минус правое минус 2,
у меня перекос вправо. Давайте разберем какой-нибудь случай, чему равно дельта от
b. Например, пусть дельта от b равно 0. Нам придется повращать. Смотрите, пусть здесь глубина была h,
то есть глубина вот этого всего под дерева это h. Тогда я утверждаю, что здесь h-1, здесь h-3. Ну тут h-1,
потому что оно не больше, чем h-1, но должно быть хотя бы h-1, потому что должен быть
поделенный h. Поэтому здесь обязательно h-1. Здесь на 2 меньше, здесь h-3. И здесь,
если здесь h-1 и дельта здесь нулевая, то здесь глубина h-2, h-2.
Давайте тогда, ну смотрите, в h у меня проблема. Я знаю, что в a у меня дельта равно минус 2,
мне надо что-то здесь починить. Давайте вот так вот провращаем. Давайте вызовем вращение вот этого
ребра a, b. Посмотрим, что произойдет с глубинами. Так, давайте я их опять как-то назову a, b, c. Ну я
просто пересовываю вот эту картинку, вращение вот этого вот правого ребра налево. И выставляю
обратно все высоты. Значит у a большого была глубина h-3, у b h-2, у c h-2. Значит какая теперь
глубина у a? Ну раз у него 2 сына h-3, h-2, то здесь глубина h-1, потому что нужно выбрать максимум
и добавить 1. Здесь h-1, h-2, поэтому здесь глубина h. И более того, я починил все дельты в этом поддереве,
потому что для этой вершины дельта стала равна минус 1, вот эти отличаются на 1. И для этой вершины
дельта стала равна 1, потому что это отличается от этого на 1. Значит я починил дельту в этой
точке. Правда? Ну вот. Это уже хорошо. Еще раз? Не, мы будем наверх подниматься. Чуть позже скажу.
Значит давайте сначала все случаи здесь разберем. Это было дельта равно нулю справа, теперь пусть
будет дельта от b равно минус 1. Ну там на самом деле то же самое будет. Так, тут h, здесь по-прежнему
h-3, h-1. И раз дельта от b равно минус 1, то есть правый глубже на 1, поэтому здесь вот такие вот глубины.
Опять делаю то же самое вращение того же самого ребра, и даже при этом предположении,
что дельта равно минус 1, у меня все равно все получится.
Ну вроде реально получилось. Я здесь аккуратно проставил все высоты. После поворота я тоже эти
высоты все написал. Здесь поскольку у меня a большое, b большое было глубиной h-3, они остались,
c большое было глубиной h-2. Дальше я считаю глубины a маленького. a маленького у него два сына глубины
h-3, поэтому здесь h-2. b у него два сына h-2, h-2, поэтому здесь глубина h-1. Все, получается я опять,
я в этом подделье починил все дельты. И здесь, и здесь дельта стала нулевой, все хорошо.
Остался последний противный случай, когда у меня дельта от b равно 1.
Вы имеете в виду как насчитывать правильно значение дельты?
Ну смотрите, не по каждой, потому что вот в этих трех, вот в этих деревьях ничего не меняется.
У нас дельта, ну как бы у нас здесь высоты не поменялись, поэтому и дельты там не поменялись.
У нас дельты меняются только в a и b, но если мы знаем ашки в каждой точке,
то мы и дельты можем за единицу посчитать.
Так, ну последний противный случай, когда дельта от b равно единице.
Значит смотрите, если дельта от b равно единице, то у меня перекос влево идет в этом поддельве,
в поддельве b. Причем оно глубина 1 побольше. Тут есть какая-то высина c.
Вот, значит тогда тут придется сделать два вращения. Значит сначала вот это вот первое,
потом вот это второе. Если их аккуратненько произвести, то в конце получится такая картина.
Здесь будет c, оно туда уходит. И здесь будет b. Вот, значит я утверждаю, что если сделать два таких
вращения, вот этого ребра вправо, вот этого ребра влево, то получится ровно такая картинка.
Ну потому что здесь c вылезет в корень вот этого поддельма, c будет сверху,
потом оно поднимется еще в корень, вытеснет a, а спутится влево. Ну как раз c в корне,
а слева b справа. Ну и под деревья как-то вот эти a, b, c большие тоже как-то подвесились.
Вот, давайте опять с высотами разбираться. Если здесь была h, то по-прежнему слева h-3,
справа h-1, потому что у меня перекос вправо на 2. Значит тут h-1. Дальше, дельта от b равно единице,
значит у меня максимум достигается слева h-2, а справа на 1 меньше h-3. Вот, ну у b и c глубины
непонятно какие, но смотрите, если у c все было хорошо с дельтой, если у утверждения все было
хорошо с дельтой, она была плюс-минус 1 или 0, тогда обе вот эти глубины обязательно h-3 или h-4.
Причем хотя бы одна из них обязательно h-3, чтобы здесь была глубина h-2.
Так, хорошо, здесь h-3, здесь h-3 или h-4, здесь h-3 или h-4, здесь h-3. Ну тогда у этой h-ки глубина
обязательно h-2, потому что неважно какая глубина здесь, максимально из них плюс-один,
все равно h-2. Тут тоже самая глубина будет h-2, отсюда придет и здесь будет глубина h-1.
И опять победа, у меня все дельты починились. У меня здесь дельты отличаются максимум на единицу,
в худшем случае здесь h-3, здесь h-4, здесь то же самое, максимум на единицу они отличаются,
для c вообще эти глубины равны обоих сыновей, поэтому здесь будет дельта нулевая.
Вот, ну можно проверить, что скажем, одного вот такого поворота мне бы не хватило,
то есть мне реально здесь надо два поворота сделать, одного поворота вот этого ребра a b
мне бы уже не хватило в этом случае, поэтому здесь придется чуть больше повозиться.
Смотрите, потому что у c h-2, вот эта вершина h-2, откуда она берется, значит,
что в каком-то из детей хотя бы h-3. Ну чтобы здесь было h-2, мне нужно построить путь глубины
h-3 в одном из детей и плюс-один сделать, поэтому хотя бы где-то h-3. Но если хотя бы где-то h-3,
а здесь дельта была правильная, то есть я считаю, что у меня вот в этом по дереве все дельты были
правильные, плюс-минус один или ноль, кроме этой вершины, значит здесь дельта была плюс-минус
один или ноль, но если один из них h-3, то какое может быть другое? Ну тоже либо h-3, либо h-4,
потому что нельзя быть больше, чем h-3, вот, и нельзя быть меньше, чем h-4, потому что они отличаются
максимумом на единицу. Вот, и того опять все равно победа я смог так или иначе сделать так,
чтобы все дельты у меня починились, стали маленькими по модулю. Да, понятно? Все, значит мы научились
чинить дельту в случае, если она была минус двойкой, мы разобрали три разных случая, сказали, что нужно
повернуть так, чтобы все починить. Причем, заметьте, вращение всегда от одного, здесь вообще одно вращение,
но здесь два вращения, не очень страшно. Аналогично абсолютно симметричная картинка в случае дельты
равно двойке, там, наоборот, перекос был влево, ну, я буду вращать там какое-то левое ребро, чтобы все починить.
Еще раз? Только один сын, но смотрите, если у него дельта равно минус двойке, то это обязательно правый сын.
И, окей, это не страшно, а большое может быть пустым, это нормально, тогда оно просто пустое,
и везде h-3 равно нулю, и это ничему не мешает. Вот, все, значит мы научились чинить дельты равные плюс-минус двойке.
Ну а дальше, смотрите, как, да? Хорошо вопрос. Ну, примерно так же, как можно хранить, скажем,
неявное дерево отрезков. У нас есть вершина, она ссылается на левого сына, на правого сына.
Она хранит указатели на левого сына, на правого сына. Ну и информацию о том, что лежит в этой вершине о числе х.
Вот, ну, видимо, нужны еще вот эти вот технические вспомогательные штуки, типа какая h в этой вершине и
какая дельта в этой вершине. Вот, чтобы их потом так можно было хорошо пересчитывать и понимать,
какой из там трех случаев у нас реализовался. Но основное это ссылки на левого правого сына и значения,
остальное техническое. На все листья? На листья не нужны ссылки. Сейчас вот я как раз это скажу.
Значит, смотрите, мы научились чинить одну вершину. Теперь как починить все дерево? Вот представьте,
у вас была корректная вельдерева, вы как-то его испортили, что-то там к нему подвесив, скажем,
ну или что-то удалив. Например, подвесили вершинку с помощью инсерта. Тогда как теперь починить?
Ну, смотрите, сломаться мог только вот этот вот путь. Путь от той вершины, которую вы сейчас
там добавили или удалили, и только на этом пути что-то поменялось в поддеревьях, могли поменяться
глубины поддеревьев. Тогда давайте сделаем так, давайте просто по этому пути пойдем снизу вверх и
будем чинить все дельты, пока не починится. Вот иду снизу вверх, вижу плохую дельту, то есть
равную двойке или минус двойке, ну поверну там как надо, оно починится все. То есть я иду снизу
вверх, чиню все, что плохо. Когда я чиню, у меня все это по дереву сразу становится хорошим, в нем все
дельты становятся нужными. Поднимаюсь наверх, если тут плохо, опять что-то вращаю, от единицы
вращения делаю, у меня опять все по дереву чинится, ну и так далее. Поднимаюсь наверх,
каждый раз, когда встречаю дельту равную плюс двойке или минус двойке, делаю вращение и чиню.
Поэтому, окей, поэтому надо хранить еще ссылку на родителя, видимо, чтобы уметь подниматься вверх,
то есть я, скажем, вот эту вершину добавил, теперь надо подняться к родителю и понять,
а вот у него дельта какая, плохая или неплохая, если плохая, надо что-то поворочать. То есть после
того, как я сделал insert или сделал erase, я от вот той вершины, в которой что-то поменялось, просто
поднимаюсь наверх вплоть до корня и каждый раз, когда встречаю плохую дельту, выполняю повороты так,
чтобы все починилось. В итоге я поднялся до корня, все починил, у меня все по дереву стало правильным
овл-деревом и, значит, у него глубиналогарифмическая победа. Кайф. Почему что? Ну, давайте подумаем
вот на этой картинке, что такое вращение. Да, по факту мне надо свопнуть какие-то указатели,
потому что раньше, ну, давайте, что такое дети p, дети p, левый сын был a, правый сын был x, теперь надо
у него левый сына ставить, а в правый, конечно, правый сын написать b, это там при присвоении указателя.
Что такое дети x, а? Слева был b, справа c. Надо теперь b в качестве правого сына подвесить,
а, наоборот, надо b удалить, надо вместо b поставить p, c оставить на месте. Опять перенаправление
указателя. Раньше показывали на b, теперь надо показывать на p. Все. То есть по факту все,
что мы делаем, это перенаправление каких-то стрелочек. Это, конечно, вот единица, потому что
здесь объектов от единицы. Все. А в L дерево кончилось. Ну, то есть поддерживая это свойство,
мы можем на все запросы отвечать за логарифм. Да.
Вы придумали новую структуру. Давайте обсудим. Я думаю, что там у вас что-то скорее всего не
работает. Иначе как раз не было бы так сложно. Так, есть вопросы еще, Павел?
Окей, давайте тогда еще одно дерево посмотрим. У нас в ближайшие три лекции будет обзор просто
разных возможностей реализации как раз этого самого дерева поиска. Их бывает много разных,
и они как раз полезны в разных обстоятельствах. Про это еще поговорим, когда какой лучше использовать.
Сейчас давайте посмотрим сплей дерева. Так. Ну, давайте тоже определение, наверное, дадим.
Сплей дерева это тоже бинарное дерево поиска. Такое что? Элемент, к которому последним приходил
запрос, то есть, элемент, который мы последним запрашивали, находится в корне дерева.
Последний в плане, ну, типа вот в каждом моменте времени. То есть, у меня пришел запрос, скажем,
find x. Так, вот после этого запроса x должен вынестся в корень, подняться в корень дерева.
Пришел запрос insert y, после этого запроса y в корне. Пришел запрос Eraser z. Ну, там какой-то
элемент рядом z, он должен подняться в корень. То есть, я вот z удаляю,
на его место стоит кто-то m, и я этот m поднимаю в корень. Вот тот элемент, который последним вот
после очередного запроса потрогался в дереве, добавился или нашелся в дереве, я его должен
поднять в корень. После каждого запроса
элемент должен быть в корне.
Вот.
Да, мы ровно так будем делать.
Мы сейчас каждый элемент с помощью
поворотов таких научимся поднимать
в корень.
Для этого есть три
вспомогательные процедуры, которые
называются очень глупо, но как-то вот так
привычно, типа, исторически сложилось,
не спрашивайте.
Есть процедура зиг,
которая работает
для х,
которая работает в случае, если х
это корень корня. Извините,
сын корня. Сын корня.
х это сын корня.
И это просто правильный поворот
в правильную сторону.
Если х был левым сыном корня,
то это просто вот такой вот правый поворот,
в результате которого х становится
новым корнем. Ну, мы рисовали уже такие
повороты, у меня как раз шарничек вращается,
х поднимается наверх, а становится
новым корнем. Значит, это случай,
если х был левым сыном. В случае,
если х был правым сыном корня,
то все аналогично, только вращение идет
наоборот направо.
Сорри, налево, да, и х поднимается
вверх.
Значит, это зиг, когда у меня
х был сыном корня.
Теперь зиг-зиг.
Опять для вершины х.
Это когда х уже
не сын корня, то есть у него
есть хотя бы два предка, есть
родитель и есть дедушка.
И зиг-зиг работает в том случае,
когда родитель и дедушка находятся
по одну сторону
от своих родителей.
Ну, вот такая картинка,
у меня есть дедушка G,
у меня есть родитель P,
у меня есть вершина Х.
Вот они именно что по
одну сторону, они оба либо влево,
либо вправо, картинка будет симметрична.
Значит, тогда здесь вращение такое,
сначала вот это вот ребро, потом
вот это вот.
Так.
После первого у меня
P станет корнем,
после второго х станет
корнем, P станет его правым сыном.
А здесь останется G справа.
Ну опять, мы все эти процедуры
нацелены на то, чтобы х, заданный,
поднимать все выше и выше.
Вот сейчас мы подняли его сразу на два уровня
вверх. Мы поменяли его с родителем
и с дедушкой, мы сразу его на
две единицы вверх подняли.
Так, значит, это зиг-зиг, но остался зиг-заг.
Это когда наоборот
у меня, ну вот как бы
P и х
по разные стороны от своих родителей.
То есть здесь было налево-налево, сейчас
будет там налево-направо, например.
Значит, зиг-заг
от х.
А это случай, когда
P и х находятся по разные
стороны от своих родителей.
Здесь были по одну, оба влево, или оба вправо,
картинка была бы симметричная. Здесь
скажем налево-направо.
Так, ну здесь тоже.
Здесь снизу, да, наоборот.
Здесь сначала вот это, потом вот это.
Так.
Цель та же самая. Я х поднимаю вверх
ближе к корню, опять на два уровня вверх поднял.
Вот, значит, это три вспомогательные
процедуры, которые у меня используются.
Значит, они используются в
одной большой процедуре сплей.
Сплей от х.
Это комбинация
вот этих самых зиг-зигов, зиг-загов и,
возможно, одного зига.
Значит,
зиг-зиг
и зиг-заг.
Комбинация. Ну, в общем, как надо,
какие надо операции, такие и делаем.
То есть смотрим на х родителя и дедушку,
если не по одну сторону запускаем зиг-зиг,
иначе, если по-разному, запускаем зиг-заг.
И в конце, возможно, максимум один зиг.
В случае, если вот
после этих операций у меня х не корень,
возможно, нужно сделать еще один зиг,
и он поднимется в корень.
Да?
Вот это сплей. Он поднимает
х в корень с помощью вот этих странных операций.
Вот.
Ну, извините, пожалуйста.
Вот оно так...
Я сам клинжую.
Вот.
Хорошо.
Все. Вот такой сплей.
Это просто какая-то реализация подъема
х в корень с помощью каких-то
поворотов.
Теперь...
Зачем нам это?
Теперь
все операции
будут сопровождаться в конце
вызовом сплая, потому что я хочу,
у меня по определению мне нужно вот тот х,
к которому только что произошел
доступ, я его хочу поднять в корень.
Соответственно, у меня все процедуры
переписываются так. Вот был у меня файнд х.
Как работает файнд х? Он работает так же,
как в наивном дереве поиска.
Мы идем и ищем х.
И вот та последняя
вершина, которую мы потрогали,
это х в случае, если он там нашелся,
ну или какой-то лист, из которого мы
попробовали найти х, но его не было.
Вот та самая последняя вершина, которую
мы потрогали, в которой мы оказались,
вот от нее вызываем сплей.
После отработки файнда,
после того, как он нашел ответ, там,
true или false, есть х или нет,
после этого вызываем сплей
от самой низкой потроганной вершины.
Значит, сплей
от
самой
низкой
посещенной вершины.
В случае, если х был
в дереве, то я его сначала нашел, потом
его поднял в корень.
В случае, если его не было,
то я дохожу до какой-то вершинки, понимаю, что х нет,
но все равно сплей давайте вызовем
от той вершины, где я понял, что х нет,
то есть мне кого-то же надо поднять в корень,
вот ту самую последнюю посещенную вершину я поднимаю в корень.
Ну, аналогично
для инсерта и
рейза,
я после них вызываю сплей
от последней посещенной вершины,
то же самое абсолютно.
Ау?
Для чего?
А,
чтобы работало быстро.
Да,
наверное, я пропустил момент мотивации.
Почему это может быть естественно?
Это может быть полезно,
если у вас, ну, не знаю,
вы пишете какой-то сервер,
которым какие-то люди пользуются
очень часто, и вам хотелось бы, чтобы
запросы от них обрабатывались быстро.
А какие-то приходят очень редко,
не знаю, раз в год, и вам, в принципе,
не очень важно, насколько быстро вы их обслуживаете,
насколько быстро обрабатываются их запросы.
Тогда вам хотелось бы, чтобы вот те запросы,
которые были недавно, как бы, от пользователей,
которые часто делают запросы,
чтобы они были повыше к корню. Потому что
на самом деле время ответа на запрос,
ну, не всегда глубина дерева,
возможно, просто расстояние от корня до х.
Если х близко к корню, то вы быстро ответите
на запрос. Там, если, не знаю, х на втором уровне,
то вы его найдете за два шага всего.
Поэтому, как бы, если у вас есть
какие-то золотые пользователи,
которые часто делают запросы,
вы хотите их быстро обслуживать,
то вам хотелось бы, чтобы вот эти объекты,
к которым они обращаются, лежали ближе к корню.
Ну, вот ровно это мы и делаем. Вот те, которые
последние использованы, они всегда будут
очень высоко.
И оказывается, оказывается,
суждение, которое мы сейчас
будем доказывать,
что теперь
учетное время всех этих
операций будет тоже логарифм.
Значит, амортизированное
время
обработки
каждого запроса
есть
от логарифма.
Ну, звездочка, например, значит, как раз
амортизированная.
Амортизированная, как обычно, значит,
что каждая конкретная может работать и долго,
но суммарно они работают так,
как если бы каждый работал за логарифм по времени.
Вот.
Сейчас будем доказывать.
Так.
Скажите, пожалуйста, мета потенциалов
на семинарах разбирался?
Хорошо.
Давайте быстренько скажу, что это.
Значит, у нас был метод
бухучета
для оценки как раз амортизированных
стоимости. Это очень похожая вещь,
чуть более формализованная.
Значит, давайте скажем, что у меня есть в каждом
моменте времени какой-то потенциал
от текущего состояния структуры.
Вот какой-то потенциал Фи.
Это какая-то функция
от внутреннего состояния, да, от внутренней жизни
структуры.
С каждым запросом этот потенциал как-то меняется.
Что-то переподвешивается, что-то добавляется,
как-то меняется внутренняя структура дерева.
Соответственно, как-то меняется его потенциал.
Как бы мы его там не определяли.
Значит, пусть,
ну давайте скажем, что ФиИТ
это потенциал после ИТ-го запроса.
Потенциал после
после
ИТ-го запроса.
Ну и давайте, как обычно,
ТИТ это реальное время выполнения
ИТ-го запроса.
Значит, реальное
время
выполнения
ИТ-го запроса.
Значит, тогда
если я вот таким вот образом
веду учетные стоимости А
как
реальное время работы
плюс потенциал
после ИТ-го запроса
минус потенциал до этого запроса,
то есть на предыдущем шаге.
Так вот, тогда такие штуки можно считать
учетными стоимостьми. Учетные они же
амортизированные.
Учетная
slash амортизированная
стоимость.
Вот. Ну и утверждение
формально, если это
хочется.
Следующее, что
если у вас потенциал в начале 0,
если у вас
потенциал всегда не отрицателен,
то тогда А
определяемой вот такой формулой
является учетными стоимостьми.
Вот такой вот А.
Давайте я напишу так. Т плюс дельта фи.
То есть Т плюс изменение потенциала структуры
конечная минус начальная.
Фи после шага, минус предыдущая.
Это учетные стоимости.
Доказательства проводятся ровно так же, как было
в методе монеток. Что такое учетные
стоимости? Учетные стоимости это такие,
что их сумма сверху ограничивает
сумму Т.
Ну давайте посчитаем сумму аитых.
Сумма аитых, по определению,
это сумма теитых,
плюс сумма фиитых, минус сумму
фи минус первых. Давайте я сразу
сокращу. Фи первое
минус фи первое, фи второе минус фи второе.
Останется у меня фи последнее
минус фи нулевое.
Ну вот, а это уже сразу
больше собравно, чем сумма теитых.
Вот. Мораль.
Если я придумываю какой-то потенциал
фи для моей структуры,
если он удовлетворяет вот этим свойствам,
что он в начале ноль и в конце
и всегда не отрицателен,
тогда вот такое вот
обозначение для
учетных стоимости, для ашек,
является корректными учетными стоимости.
Это реально можно рассматривать как вот
то самое о звездочке.
Вот.
Ну и мы такой сейчас потенциал ведем
и будем с ним работать.
Так, понятная идея.
Это как метамонеток,
ну типа вот здесь вот сколько монеток
положили, минус сколько сняли.
Почти то же самое, только в других терминах, скажем так.
Вот. Хорошо.
Хорошо.
Ну давайте доказывать вот то утверждение.
Вот то вот.
Давайте ведем следующий потенциал.
Значит, сначала для каждой вершины
X.
S от X пусть будет размер его под дерево.
Размер под дерево
вершин X.
Вершин X.
Вершины X.
То есть это сколько вершин
находится в его под дереве, включая X.
То есть вот X и все его дети,
все что в под дереве, их количество
равно S от X.
Вот. А потенциал это сумма логарифмов...
Sorry. Сначала я веду R
как двоичный логарифм S.
Вот. И после этого phi это
сумма рангов по всем вершинам.
Значит, сумма вот этих R по всем вершинам.
Сумма двоичных логарифмов
размеров всех под деревьев
по всем вершинам.
Опять.
Взялось с потолка.
С этим, вот с таким потенциалом,
докажем, что все работает.
Ну то есть понятно, что phi в нуле это ноль,
потому что изначально дерево пустое, вершин нет,
сумма пустая. Всегда не отрицательно,
потому что все S всегда, ну как бы,
присутствующие в сумме слагаемые,
все S хотя бы один, потому что
X есть в своем под дереве, поэтому это всегда один.
Логарифм, значит, всегда не отрицательный,
phi всегда не отрицательный.
И вот если с этим потенциалом не получится доказать,
что A определяемое по такому соотношению
всегда от логарифма,
то мы победим.
А можно считать, что учетные стоимости логарифмические.
Вот.
Хорошо.
Ну, смотрите, как бы мы поняли,
что в каком-то смысле у меня все операции,
find, erase и insert,
сводятся к splu. То есть мы в любом случае
после каждой нормальной операции вызываем
вот наш spli, который поднимает X в корень.
Давайте сначала проанализируем время работы
splia. Давайте поймем,
чему равно учетное время работы процедуры
spli.
Учетное, вот в том самом смысле, реальное время
плюс разных потенциалов. Чему равно
учетное время работы spli.
Ну, что такое spli? Мы знаем, это комбинация
вот этих вот стрёмных трех процедур.
Давайте с ними по очереди разбираться.
Так.
Ну, давайте, давайте.
Lemma я, наверное, это назову.
Lemma.
Давайте так.
A от spli от X
равно
не больше чем
Я это сформулирую.
Потом мы это будем доказывать.
R' от X
минус R от X.
То есть, если spli вызвался
от вершины X, то учетное время
я утверждаю этой процедуры
splia работает за
один плюс утройная разность рангов
это конечный ранг. Вот это ранг
X после spli.
Это ранг X до выполнения spli.
То есть, это R' от X в исходном дереве.
Это R' от X, новый ранг
в дереве после выполнения spli. Это конечный
этот начальный ранг.
Вот я утверждаю, что spli всегда вот такой.
Чего?
Еще раз, еще раз.
Какой ранг у листа, скажите, пожалуйста?
S от X
1.
Мы считаем, что
вершина X сама в свое поддерево
входит.
То есть, вот есть X, вот есть его какие-то
левое правое поддерево,
все вот в этом списке входит в S от X.
В частности, X.
Поэтому я написал, что S всегда хотя бы 1.
То есть, X входит в свое поддерево.
Так, ну хорошо.
Давайте доказывать.
Давайте начнем
с процедуры zig. Она самая простая.
Давайте поймем,
что такое учетное время процедуры zig.
Надо мне
восстановить картинку.
Jig, напоминаю, работает в случае,
когда X это сын корня.
Я делаю одно вращение,
и X становится новым корнем.
Так.
Хорошо. Давайте посчитаем
учетное время такой процедуры
в терминах метода потенциалов.
Учетное время это реальное время,
плюс разность потенциалов.
Что такое реальное время?
Давайте я для удобства буду считать,
что время равно числу поворотов.
Ну, на самом деле,
это надо написать от единицы,
потому что мы понимаем, что каждый поворот
это от единицы переприсвоения указателей.
Ну, тогда мне надо было бы
вот здесь написать,
если там 5 переприсвоения указателей,
то здесь вылезла бы константа 5.
Это бы ни на что не повлияло,
но для простоты я считаю,
что один поворот работает за один такт,
ну, короче, за одну операцию.
Процессоры, грубо говоря.
Поворот – это один реального времени.
Вот.
Теперь надо понять, что происходит с рангами,
с потенциалом точнее.
Ну, потенциал – это сумма рангов по всем вершинам.
Как у меня меняются ранги
всех вершин?
Ну, смотрите, в под деревьях A, B, C ничего не произошло,
их структура осталась так же, как была.
Поэтому в них все размеры под деревья
все ранги сохранились,
поэтому A, B, C остались такими, как были.
Поменялись только ранги у икса
и у пешки.
Значит, поэтому я пишу
плюс r штрих от x минус r от x
плюс r штрих от p
минус r от p.
r штрих – это новый ранг
после поворота,
r – это старый ранг до поворота.
Хорошо.
Будьте здоровы.
Я хочу заметить,
что r штрих от p
меньше ли равно
наоборот
Да, не, все правильно.
r штрих от p меньше ли равно r от p.
Все правильно, все правильно написал.
Меньше r от p.
Почему? Ну, очень просто.
Что такое r штрих от p?
Это двоичный logarithm вот этого вот размера.
Вот это вот это r штрих от p.
А r от p – это двоичный logarithm вот этого вот всего.
Вот это r от p.
Ясно, что это меньше, чем это.
Потому что здесь было
вообще все дерево,
а здесь только вот это его часть.
На самом деле, здесь даже строго неравенство,
но, бог с ним, мне не строго хватит.
Значит, r штрих для p
не больше, чем r от p.
Поэтому я могу вот здесь неравенство продолжить
и написать, что это не больше, чем
1 плюс, то есть я вот это могу оценить нулем,
потому что это меньше, чем это,
они с разными знаками сокращаются.
Остается r штрих от x
минус r от x.
Ну, еще давайте я
для красоты сверху вот таким вот
неинтеллектуальным выражением оценю.
Просто тройку сверху накину.
Вот к этой разности
сверху накину тройку.
Вот.
Ну, так можно сделать, потому что
тут выполняется наоборот
отношение, что r штрих от x
больше или равно r от x.
То есть вот это вот слагаемое
не отрицательно, поэтому при умножении его
на тройку значение может только вырасти,
поэтому это неравенство верное.
Ну, r штрих от x больше, но r от x опять
по тем же причинам, потому что r штрих от x
это двоичный грифом всего дерева,
а r от x это двоичный грифом только вот этого
маленького по дереву x, a и b.
Поэтому верно вот это, и соответственно
верна вот эта оценочка.
Согласны?
Так, ну все, времени больше не остается.
В следующей
лекции мы разберемся с остальными
операциями, зиг-зиг-зигзаг,
сложим и как раз получим вот такую оценку,
поймем, почему это логарифм. Спасибо.
