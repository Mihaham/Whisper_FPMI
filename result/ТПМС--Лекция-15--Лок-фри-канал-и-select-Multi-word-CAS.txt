Рад всех приветствовать на этой нелегальной лекции подпольной. Я злоупотребляю вашим вниманием,
спасибо большое, что вы пришли. Сегодня я расскажу вам про последнюю тему,
которую мы не успели коснуться. В смысле, тему, некоторый инструмент для выражения
коммуникации между какими-то конкурентными активностями, связи их. Мы с вами говорили
про Fiber и Mutex, мы говорили про альтернативу Fiber, ну, по сути, такую же, построенную на другом
механизме, на стеклоскорутинах против стеклоскорутина, собственно, про корутины,
мы говорили с вами про Future, которые с помощью комбинаторов связывают задачи в некоторые графы,
и сегодня мы поговорим про подход, который используется в Go, это message passing и это каналы
e-select. Ну, у нас есть задача, и я сегодня расскажу частично ее решение, частично расскажу,
как можно было бы написать решение лучше, чем это вас требует, ну, и заодно там возникнет
некоторая интересная и тривиальная задача, связанная с look-free. Ну, мы до нее доберемся,
ладно, давайте начнем с простых соображений, о чем вообще мы говорим. Мы говорим сегодня про
Fiber или про корутины, не очень важно, наверное, и мы говорим о том, как они между собой синхронизируются.
Понятно, что они могут синхронизироваться через разделяемую память, для этого у вас есть
какие-то Mutex, которые вы писали, Mutex могут быть очень хорошими, ну, вот принцип, что вы работаете,
вы координируете работу разных Fiber'ов, разных корутин через разделяемые ячейки памяти. В Go вам
предлагают использовать другой подход, вместо того, чтобы Fiber'ы, корутины коммуницировали через
разделяемые ячейки, они наоборот, они поступают наоборот, они разделяют память через коммуникацию,
через каналы, то есть, если вы хотите поговорить с другим Fiber'ом, с другой корутиной, вы отправляете
ей сообщение через канал, а с другой стороны, так, корутины сообщение получают, ну, и как-то его
обрабатывают. Принцип понятен, и, наверное, должны быть понятны, почему мы хотим делать именно так,
то есть, мы хотим Share Memory by Communicating, а не наоборот, потому что, ну, вот я говорю про этот
принцип, который лежит, в том числе, в основе дизайна Go. Этот принцип очень разумный, потому что
он поощряет паттерн передачи сообщений, который, как мы знаем из лекции про модели памяти, более
подпочтительны для процессора, чем обращение к разделяемым ячейкам непосредственно. И в домашней
работе вас, во-первых, просят реализовать вот такой вот канал, с помощью которого можно одному
файберу отправить сообщение, а другому файберу дождаться его получения, остановиться до тех пор,
пока сообщение не появится. В принципе, задача не сложная, но когда вы ее будете решать, если вы
ее будете решать, то обратите внимание, что вот на данном этапе нашего курса, ну, он уже закончился,
но, тем не менее, на данном этапе, работая с файберами и реализуя какой-то новый примитив
синхронизации, вы уже не должны ни в коем случае, конечно, думать про там какие-нибудь фьютексы,
кондвары, мьютексы, нечто подобное. Мы с вами прошли длинный путь для того, чтобы понять, что файберам
ничего, кроме suspend, не нужно. Ну и, глядя на дизайн карутин, вы там видите, что никакого фьютекса
там нет, и быть, кажется, и не может в принципе, в силу некоторых особенностей API. У вас есть
просто Awaiter и его операция AwaitSuspend. Ну, также и в нашем случае нет никакой разницы между там
или stackless карутином, тут stackful карутины. Вот на данном уровне разницы никакой нет в реализации
примитива синхронизации. Мы используем просто suspend, останавливаемся один раз на каждую операцию
send, один раз на каждую операцию receive, просыпаемся и там, просыпаемся, когда операция уже завершена.
У нас будет только в таком случае. Сама реализация довольно прямолинейная, тут никакой особой
сложности нет, скорее такая техническая рутина. Но, тем не менее, нужно с чего-то начать. И я еще
пропагандирую и решать вам эту задачу, потому что вот после этой задачи можно гораздо более
разнообразные ворклоды строить для хорошего планировщика, который, наверное, многие здесь
написали. Здесь будет опять LFO-планирование, здесь будет придача сообщений, здесь одни файберы
будет других, и более разнообразным способом они это могут делать, нежели чем работая просто с
мютаксами. Поэтому можно гораздо больше сценариев написать и их профилировать, и лучше понять, как
планировщик себя ведет. А ведет он себя довольно сложно, потому что сценарии могут быть самыми
разнообразными. Но это первый этап задачи. А дальше вы переходите к более нетривиальному,
ну, впрочем, не такому же сложному, но все же нетривиальному инструменту — это Select,
который позволяет вам заблокироваться в ожидании сообщения одного из двух каналов. То есть,
вы остановите... Я говорю «заблокироваться», я каждый раз говорю «неаккуратно», и вообще,
мне кажется, я в курсе очень неаккуратно говорил. А стоило поступать так. Если вернуться в прошлое,
говорить слово «заблокируется» только в контексте потоков, а в контексте файберов,
говорите «останавливается». Это как-то более правильно, чтобы мы не путали два этих понятия.
Вот так вот, «станавливать» — это вызывающий Select Fiber до тех пор, пока либо в XS,
либо в YS не появится сообщение. На что это похоже? Это похоже на некоторый комбинатор для Future,
и я бы сказал чуть шире — это похоже на инструмент для параллельной композиции.
Когда мы говорили с вами на лекции про Future, что вот есть композиция последовательная и
параллельная, ну и в задачах я об этом писал в условии, я обращал внимание, что да, вы можете
описывать цепочки каких-то шагов осинхронных через комбинатор Zen или какие-то подобные,
но с другой стороны, гораздо естественнее делать это с помощью блокирующего API,
просто писать вызов, точку с запятой, и это синхронного API, и внутри этого вызова,
там, не знаю, карутина становится. Это гораздо удобнее, чем вот Zen и писать,
и обработчики на них вешать. Но с другой стороны, есть другие сценарии, когда мы
распараллеливаем какие-нибудь, не знаю, запросы в какие-то сервисы, и потом хотим дождаться всех,
дождаться первого, дождаться Quorum'а какие-то. Разные варианты можно себе представить.
И в таком сценарии синхронный API, где там файбер или карутина, или карутина, останавливаются,
не очень-то удобно писать. Вот как с синхронным API дождаться первого? Нужен какой-то
вспомогательный инструмент, и тут появлялись фьючи и там комбинаторы, которые позволяли
из nfuge построить одну с какой-то семантикой. Да? И вспомните, что мы еще говорили про эти
фьючи, про то, что на лекции про structured concurrency мы говорили, что в эти фьючи и вот в эти
как бы развилки логические можно встроить поддержку обработки ошибок и асинхронные отмены так, чтобы
если из одного по дереву приходит ошибка, то в другое по дереву спускалась отмена. Вот очень
разумно. Select — это некоторая альтернатива для решения той же задачи, но вот в императивном
языке. Мы здесь не занимаем, мы здесь не используем никакие сложные комбинаторы, мы не выстраиваем
какие-то там цепочки, по которым текут значения. Вместо этого мы пишем императивный код, где есть
грутины, по сути, неотличимые для пользователей от потоков, и они вот останавливаются в... ну, в год.
Нет, не вызов Select там, вот конструкция языка, у нас это вызов. Но в общем, Fiber останавливается в
Select, дожидается. И это вот опять какая-то такая императивная семантика, что именно происходит.
И если вы посмотрите... да, и продолжая эту аналогию, я хочу обратить внимание, что Select,
Select Go — это очень выразительный инструмент, который позволяет решать вот все подобные задачи,
которые решали комбинаторы фьюч. Ну, правда, менее выразительно, но тем не менее. Вот в Go,
вы знаете, есть каналы. И каналы поддержаны на уровне синтаксиса. Ну, давайте, я...
Я хочу, конечно, сразу... сразу найти Select.
Вот, есть Select, и это, по сути, комбинатор First-off. Что, если, скажем, вы хотите... да,
каналы... вот API для каналов в смысле, простите. Каналы поддержаны на уровне языка, на уровне
синтаксиса. Вот у вас есть конструкция отправить что-то в канал, достать что-то из канала. А теперь
предположим, что вы хотите реализовать... ну, эта операция, она останавливает грудину до тех пор,
пока там сообщения в канале не появятся. Так вот, если мы хотим для каналов, которые поддержаны на
уровне синтаксиса, скажем, иметь операцию не блокирующей... не блокирующего чтения из канала.
То есть, мы хотим попробовать прочесть сообщение, если оно там есть. А если нет,
то готовы пойти дальше. Останавливаться не хотим. Вот Select, он решает в том числе и такую задачу.
У вас есть вариация Select с кейсом Default, и этот кейс срабатывает, если в этом канале нет
сейчас значения. Вам не нужно добавлять... ну, у вас в каналах нет такого метода не блокирующего
чтения, у вас есть Select, который просто не блокируется при отсутствии сообщения в каналах.
Или, скажем, другая задача. Вот вы пишете на C++ и вы смотрите там какой-нибудь API Condition Variable.
Давайте посмотрим. И видите, там разные вариации вейта с тайм-аутами. Вот вы хотите ждать события
или стечение тайм-аута. И вот вы поладите такое сложное, избыточное API. С помощью
в ГО вы решаете эту проблему очень эрегантно. Если вы хотите чего-то дождаться, но с некоторым
тайм-аутом, то вы строите такой специальный канал тикер, куда падают такие сообщения тики. И если
ваше ожидание не должно быть бесконечным, то вы берете Select над и вашим каналом с данными,
и этим тикером, ну и в зависимости от того, что происходит раньше. Либо тайм-аут срабатывает,
либо вы дожидаетесь сообщения. Или, скажем, другой сценарий. Вы пишете какую-то операцию,
вы пишете какую-то операцию, которая, скажем, выполняет какую-то полезную работу, но она готова,
она должна поддерживать отмену. Потому что это часть обработки запроса, а ответ на запрос уже не
нужен, потому что пользователь, ну не знаю, отчаялся, у него там сработал глобальный тайм-аут, и он уже
получил ответ с другой ветки. В общем, у вас есть операция, которая должна уметь останавливаться
по сигналу отмены. И опять Select для вас эту проблему решает. Вы можете из контекста,
который мы обсуждали на одном занятии, по сути является стоп-токеном, в том числе является
стоп-токеном, получить такой специальный канал и заблокироваться, остановить гарутину до тех пор,
пока либо мы не получим сигнал отмены, либо мы там не получим очередную порцию данных, ну или там
какой-то прогресс не настанет. Короче, Select в Go — это инструмент для параллельной композиции,
с помощью которого можно решать самые-самые разные задачи. И вот, не знаю, чувствуете вы или нет,
этот дизайн, эта декомпозиция, она очень аккуратная, очень точная, потому что один вот тот же Select,
он используется в разных вариациях для решения разных задач и везде подходит. То есть сам язык
задизайнен так, что вот стоп-токен — это канал, или тайм-аут — это канал. Ну, то есть тут, в принципе,
можно углядеть такую аналогию, что вот каналы — это некоторая такая аналогия с фьючами, ну,
просто императивная и декларативная, а Select — это такой универсальный инструмент для того,
чтобы можно было сооружать какие-то комбинаторы опять в императивной манере. Менее выразительно,
ну как, в общем, для языка это идиоматичный подход. Так что инструмент чрезвычайно полезный,
и дизайн Go, в общем, построен, вот вся синхронизация в Go построена на каналах и Select-ах. Много что
является с каналом, и у вас есть универсальный Select, с помощью которого можно дальше решать
очень разные задачи. Вот это чертовски разумный дизайн, и мы в задаче про канал хотим этот Select
повторить. Ну, правда, в очень ограниченной манере, потому что мы хотим повторить Select
только для двух каналов, но просто потому что так нам проще будет писать, нам меньше нужно будет
думать про всякий в ряде шаблоны и больше про содержание задач, то есть синхронизацию. А кроме
того, мы себя дополнительно ограничиваем, мы говорим, что на Select мы только читаем. Но если
вы используете Select в Go, то вы, конечно, хотите иметь Select такой смешанный, где один кейс может
записывать сообщения, а другой может получать. Ну, например, потому что вы опять поддерживаете
отмену. Вы отправляете сообщение в канал, он может быть переполнен, там может быть забит буфер,
но вы не хотите ждать вещь на появление свободного места там, потому что вас просто могут отменить
по тайм-ауту, и вот вы читаете из канала контекста и пишете там какой-то канал с данными. И что случится
раньше? Ну вот, мы тоже себе немного задачу упрощаем, но мы себе оставляем такую вариацию,
как Tri-Select, почему-то она представляется нам неочевидной. Там есть некоторая тонкость,
ну, про которую я сегодня расскажу, я надеялся, что вы сами ее встретите, но поскольку я рассказываю
вам раньше, чем вы решаете, то, значит, мне придется раскрыть нюанс. Ну, сначала давайте
начнем с канала, просто подумаем, как он может быть реализован. Канал — это очень простая штука,
тут очень сложно реализовать его по-разному. Ну, я сейчас покажу какой-то код, он не пресендует
название самого лучшего. Да, почему здесь тут написано? Ну, написано. Это буфер с данными,
это спинлок, который защищает этот буфер, и это две очереди — сендеры и ресиверы, то есть файберы,
которые остановились и ждут сообщения или ждут свободного слота в буфере. Вот, сендеры и ресиверы —
это, ну, это опять некоторые узлы интрузивного списка. Короче, опять вы, наверное, представляете,
если вы писали в Utex и писали там Utex, это какие-то овейтеры, и файбер, который хочет остановиться,
он, файбер, который хочет остановиться, скажем, в ресиве, он реализует такого овейтера,
который в Await Suspension отпускает спинлок этого канала и ожидает получить значение от некоторого
продюсера. Вот, когда он его получает, файбер готов возобновиться, и вот мы его отправляем в
планировщик, и причем говорим ему, что он может проснуться следующим, потому что, ну вот, мы
хотим использовать лифо-планирование. В общем, понятная конструкция, да? Ничего сложного. Но
нам сразу пригодится такое замечание, оно нам упростит дальше разговор про лог-фри канал. В
канале не бывает одновременно и сендеров, и ресиверов. Ну, для простоты можно буфер опустить,
можно говорить про небуферизирован канал, и если там кто-то ждет, то, видимо, остановленных
отправляющих нет. А если кто-то остановился, потому что не может отправить, то, видимо,
у них нет получателей. Вот, так что есть либо сендеры, либо ресиверы, и вот этот код можно
было бы упростить, сделав один список некоторых вейтеров, которые могут быть либо сендерами
все, либо ресиверами. А сам вейтер — это такая простая структура. Что там будет храниться в этом
вейтере? Ну, файбер-хэндл, который должен проснуться, и слот для значения. Если это продюсер,
сендер, то там лежит значение, которое нужно отправить, которое он хочет отправить, а если это
ресивер, то это просто слот для значения, в который другой сендер должен что-то положить и разбудить
этот файбер, ждущий. Вот, так что тут есть такая вот симметрия сильная, и можно ее будет дальше
эксплуатировать. Ну, а дальше я, наверное, перестану показывать код и буду показывать картинки,
потому что мы хотим поговорить про канал. Ой, про Select, простите. Все сползло. Итак,
что, как поддержать в каналах Select? Чем они отличаются? Думали ли вы над этим? Давайте так.
На самом деле, опять, задача очень техническая, в ней ничего сложного нет. Вот эти списки,
которые нарисованы, это списки, ну, либо сендеров, либо ресиверов. В данном случае у нас два канала,
и на них зависли некоторые ресиверы. Каналы тут нарисованы небуферизированные, то есть есть
либо сендеры, либо ресиверы, буфера нет. Вот канал XS, в нем ресиверы, которые хотят что-то
получить. И эти ресиверы, какие они бывают? Это может быть файбер. Вот я, собственно, его и показал
вам уже. Файбер-ресивер — это объект, у которого есть файбер-хэндл, у которого есть слот для
значения, который этот файбер хочет дождаться. И когда-то мы кладем в этот слот значения мы сендер
и будем файбер. Вот это один из возможных ресиверов в канале. А как бы мог, как бы можно было в эту
конструкцию встроить Select? Ну вот Select — это значит встать, как бы по семантике, дождаться сообщения
из одного из двух каналов. То есть фактически стать ресивером в каждом канале. Ну вот мы добавим себя
в каждый канал. Вот тут красный Select есть, и вот он добавил два своих объекта, два узла в инкрузивные
списки ресиверов. Но это такой особенный ресивер, потому что Select представлен в двух каналах,
но при этом может получить только одно значение, а от второго он должен отказаться. Вот, поэтому мы
устраиваем между ними такой консенс, если вы знаете о чем я, но вы и не знаете, потому что я не
прочитал эту реакцию в этот раз. Действительно, Select представлен двумя ресиверами в двух разных
каналах, но при этом два этих ресивера, они не то чтобы готовы получить значение оба, они вместо
этого ссылаются на некоторый общий объект, где лежит переменная, ну вот Winner или State. Давайте я
назову это State. Тут можно немного по-разному писать. И этот State, он кодирует состояние Select. Получил ли
он значение или еще нет. И вот, допустим, я Send, я прихожу, и вот у меня есть фиолетовый кружок,
я готов его кому-то отдать. Я предлагаю его этому ресиверу. Вот Fiber ресивер, чем он хорош? Он
никогда не отказывается. Он принимает значение, просыпается и вот использует его, он дождался его.
А вот Select ресивер, он может быть привередливым, то есть он может получить значение и принять его,
если это первое значение, которое ему предлагают. И тогда он там переключится в состояние единицы,
скажем, да, и получит этот фиолетовый кружочек. А потом в другой канал придут два Send, и вот
второй Send достанет из очереди красный ресивер, соответствующий Select, предложит ему значение,
оранжевый кружок, а этот красный Select от него уже откажется, потому что у него уже заполнен State.
Но у него уже установлен State, что он переключился в состояние выбран. Ну вот именно поэтому ресивер,
он не просто, у него есть ресив, у него есть Maybe ресив, потому что вот он может отказаться от того,
что его предлагают, потому что это может быть Select. Тут можно немного по-другому написать,
совершенно не принципиально. Принцип понятен, да? Все довольно просто. Вот такая задача,
довольно техническая. Вопрос, а зачем же в задаче есть не только Select, а Tri-Select? Какую
проблему он демонстрирует? На самом деле, тут есть тонкость, которую я, честно, сам не понимаю,
ну то есть я понимаю, но наполовину. Тонкость следующая. Вот представьте себе, да, давайте
подумаем про Tri-Select, как бы он мог быть реализован. Вот семантика Tri-Select, попробовать все каналы,
если нигде ничего нет, то вот сказать, что везде пусто. Вот просто по очереди. То есть казалось бы,
операция вообще выражается через цикл с там, если у нас в канале есть операция Tri-Receive,
а она у нас кажется по условию есть, да? Если у нас Tri-Receive. Да, то кажется, что вообще зачем
Tri-Select должен существовать? Потому что мы пройдемся по каналам, спросим у каждого Tri-Receive,
если получим, то хорошо, если не получим, то скажем, что все каналы пусты. Вот оказывается,
что так не работает и Tri-Select он, ну в каком-то смысле, в каком-то смысле его лучше сделать частным
случаем обычного Select. А сценарий такой, смотрите, он довольно хитрый. Вот он в тестах есть, он
проверяет ровно то, что вот вы это заметили. Вот представим себе, что у нас есть два канала,
X и Y. И мы сначала в Y положим единицу, в Y положим единицу. Вот у нас канал один пустой,
ну такой слот нарисован пустой, а здесь уже единица лежит. А дальше мы запустим два файбера. Один
из них вызовет Tri-Select и, ну что он получит, мы увидим чуть позже. А другой файбер запустит
две операции. Он в X отправит значение, а потом будет получать сообщение из Y.
А мы вот во втором файбере вызываем Tri-Select, который реализован как. Мы идем по циклу,
проверяем каналы. Ну и какое себе исполнение можно представить? Вот у нас канал в таком состоянии
изначально, вот перед запуском файберов. Мы в Tri-Select проверили канал X, он пуст. Идем дальше.
Но перед тем, как мы успели проверить канал Y, файбер F1 положил значение в X и достал значение
из Y. После этого мы проверили канал Y и увидели пустое значение. И это какой-то очень сомнительный
сценарий, потому что, как мы будем говорить осенью, эта история, она не линеризуется. Ну,
то есть, вот такое исполнение невозможно объяснить никаким последовательным, где все операции
происходят по порядку. Вот если бы канал был атомарным и если бы Tri-Select был атомарным,
в таком обывательском смысле, да, мы могли бы думать, что вот сейчас случилась эта операция,
потом случилась эта операция, потом случилась та операция. Я не знаю, что... Смотри, мы хотим
сейчас не про Mutex говорить, мы хотим сейчас говорить про семантику. Какова семантика операции
Tri-Select? Вот утверждается, что у Tri-Select текущего, как бы он там ни был, с такой реализацией,
Tri-Select нарушает семантику свою, потому что вот этот результат, этот вызов с пустым ответом невозможно
вписать в эту историю из трёх подряд идущих вызовов. То есть, если бы все было атомарно,
где бы мог выполнить Tri-Select? Между этими вызовами, между этими вызовами или после этого вызова?
Ну, потому что на то это инициализация, что она выполняется до запуска двух файберов.
Вот. Так что места этому Tri-Select нет. Невозможно адекватно объяснить такое исполнение. Но вот наша
реализация его порождает. Вот, возможно, наша реализация реализует неатомарный Tri-Select,
и, наверное, это довольно печально. Да, ну, вариант простой. В нашем исполнении никогда не было момента,
когда оба канала были пустые. Сначала был один не пуст, потом два не пустых, потом снова один,
но другой уже был не пуст. И ответ, что два канала оказались пустые, ну, вот это просто не
соответствует реальности. Мы понимаем это. Мы просто написали такой сценарий, мы знаем,
что такого не может быть, и получаем ответ пуст. Ситуация сомнительная. Что делать?
Нужно сказать аккуратнее. Нужно прибегнуть к нашему опыту и вспомнить, что мы не просто так в курсе
решаем задачи. У нас была задача очень важная в начале курса. Она называлась «Задача про обедающих
философов». И это была такая очень затяжная шутка. Вот сейчас эта задача, эта задача можно
воспользоваться. Чтобы проверить атомарно два канала, нужно два этих канала заблокировать.
Нужно взять разом два мьютокса. Ну или N мьютоксов, если у вас N каналов. И, как вы,
наверное, знаете из «Задачи про философы», это сделать не совсем тривиально, но есть некоторый
общий рецепт, а именно нужно вести некоторый порядок на всех блокировках и гарантированно
брать их в одном и том же порядке. Во всех селектах, да? Ну вот тогда операция станет атомарной.
Ну вот троиселект так и нужно сделать. Нужно взять блоки, а потом проверить каналы. Чего я не
понимаю, нужно ли так делать в блокирующем селекте? Вот я, честно, не понимаю. Если кто-то подумает
за меня, я буду очень благодарен. Вот можно написать решение, где мы будем брать локи по одному,
потому что это, видимо, эффективнее. Мы взяли блокировку на канал, положили туда селектор,
отпустили блокировку. Потом взяли блокировку на другой канал, положили туда селектор,
отпустили блокировку. Пока мы это делаем, в этом канале уже могло появиться значение, его сюда
написали. Тут как бы загорелся стейт, там как бы сработал консенсус, выбрал победителя. Да,
мне нравится победитель, мне нравится слово консенсус. И в этом случае, ну я, по крайней
мере, такого простого сценария, на котором бы нарушались какие-то очевидные варианты,
которые выстрел пользователь не нахожу. С другой стороны, немного странно получается,
что у нас есть, скажем, две операции селлект, скажем, три канала, ну две операции селлект,
два канала, и две операции селлект по-разному оказались упорядочены в двух каналах.
То есть их ресиверы легли в разном порядке, в два канала, да? Ну как-то неаккуратно выглядит. Вот
я, честно, не знаю, поломается ли от этого, ну то есть можно ли как-то на это положиться,
в смысле на тамарность блокирующего селлекта, и из такой реализации разломать себе какой-то
иный вариант. Об этом интересно подумать. Но вот очевидного нет, а для трай-селлекта,
не блокирующего, такой сценарий есть, он очень простой, и вот в тестах мы это проверяем.
Ну что ж, это такое затяжное вступление про то, почему мы хотим делать селлекты,
про то, почему нам нужны каналы. Ну вот селлект, потому что это инструмент для параллельной
композиции, это такой императивный заменитель комбинаторов фьюч. Канал — это эффективный для
компьютера паттерн коммуникации между конкурентными активностями. Ну и вот мы, наверное, представляем себе,
как можно было это сделать на основе спинлока и используя API Fiber, в которой мы так долго с вами
разрабатывали. Про тамарность тоже поговорили. Да, не поговорили, откуда взять порядок на мютаксах,
но это, в общем, такое дело техническое, вы решая задачу сами это легко придумаете. А теперь мы
хотим пойти дальше и улучшить нашу реализацию канала, а именно мы хотим избавиться от спинлока,
который этот канал защищает, потому что это может быть нагруженным местом, ну и тут можно было
бы улучшить себе гарантию в смысле прогресса, чтобы поток, который вытеснили под спинлоком,
не мог помешать другим потокам, другим фиберам на других потоках с каналом работать. И вот мы
сейчас будем говорить про то, как реализовать лог-фри канал. Первое наблюдение. Ну вот давайте
не думать про сендеры и ресиверы, давайте думать про объекты вейтера. Вот вейтер — это объект,
у которого есть поле корутина и объект... есть поле, элемент, в котором лежит ссылка на значение
некоторое. Я сейчас буду рассказывать про статью, которая написана для Kotlin,
авторами-разработчиками Kotlin, так что у меня будут корутины и ссылки на элементы, как в
Kotlin, но тут, в принципе, никакой специфики практически не будет. То есть это всё можно
написать и на C++, кажется, без каких-то особенных сложностей. Ну вот, у нас здесь в статье есть
вейтер — это корутина и элемент, вот мы его нарисовали. Что из себя будет представлять лог-фри
канал? Да, я забыл сказать важное ограничение — мы делаем канал не буферизированным. То есть у нас
буфера нет, если в канал приходит сендер, то он встаёт в очередь, когда приходит ресивер,
он достаёт сендера из очереди, забирает у него значение, и вот они расходятся, случается рандеву.
Но нам нужно поддерживать очередь — либо сендеров, либо ресиверов, либо то, либо другое. Вот мы эту
очередь будем строить в виде такого бесконечного массива. У нас будет такая абстракция пока —
бесконечный массив со сквозной номерацией, вот он нарисован. И в нём находятся какие-то вейтеры,
но в данном случае находятся три вейтера сендера. Они пришли, они хотят отправить значение, но у них
не получается, потому что просто очередь уже скопилась, нужно встать в эту очередь. И в этой
очереди есть два индекса. Есть индекс DQ-индекс и NQ-индекс, будьте здоровы. DQ-индекс указывает на
первый занятый слот, на вейтера, который там находится, видимо. NQ-индекс указывает на
первый свободный слот, куда можно встать в очередь. Пока схема понятна, вроде ничего сложного пока нет.
Как бы мы могли такую предположение, что у нас есть некий бесконечный массив волшебный,
мы пока не заботимся о том, как он устроен. Если он у нас есть, как можно было бы дальше построить
канал? Предлагается сделать очень просто. Вот вы — ресивер. Вы приходите в канал и читаете DQ-индекс.
Вообще-то для начала вам хорошо бы понять, в каком состоянии находится канал. То есть там
сендеры живут или ресиверы сейчас? Потому что если там живут, скажем, сендеры, то нужно взять и
первого извлечь, и забрать у него элемент и отпустить его, рандеву сделать. Если же там живут
ресиверы, то нужно встать в конец очереди. Ну вот одно из двух. Ну вот предположим, что мы приходим,
смотрим на содержимое по индексу DQ и обнаруживаем там сендера. То есть мы понимаем, что есть сендеры,
они ждут своих ресиверов, и вот мы пришли. Значит, нужно этого сендера себе забрать,
забрать у него значение и отпустить. Ну что значит забрать сендера? Потому что мы же ресивер — один
из многих ресиверов. Так что нам нужно конкурировать с другими. Ну вот у нас тут массив с индексами. Да,
массив с индексами — это я все следую статье. Вот у нас есть структура канал, и у нее есть
поля NQ-индекс и DQ-индекс. Это нас пока не должно волновать все остальное. Что мы сделаем? Мы
попытаемся кассом захватить себе индекс для извлечения. То есть мы сделаем касс,
попытаемся атомарно передвинуть DQ-индекс на единицу вперед. Если мы смогли это сделать,
то мы захватили слот, и можно из этого слота пойти вот к соответствующему вейтеру и забрать оттуда
элемент. Да? Если же касс провалился, то мы ретраемся, перечитываем DQ-индекс, пробуем заново.
Если мы добавляем значение, мы send. То есть если мы send, и мы приходим в канал и видим,
что в DQ-индекс сейчас находятся сендеры, то это означает, что мы должны по NQ-индексу добавить
себя. И что мы делаем? Мы опять захватываем слот, инкриментируя с помощью кассы NQ-индекс,
и записываем этот слот себя. Вот, ну либо полностью симметричная ситуация, когда в массиве
находятся сейчас ресиверы, и вот просто всё переворачивается. Ресиверы добавляются в конец,
сендеры достают из начала. В предположении, что у нас есть бесконечный массив, всё довольно просто.
Да? Или нет? Или есть подвох? Ну тут прям атомарно. А что сложного-то? Ну в содержимом ячейке можно
как-то закодировать, кто там лежит, сендеры или ресиверы. Мне кажется, что это скорее техническая
сложность тут. Проблема в другом. Ну оно могло всё поменять. Да, это хороший вопрос, но на самом деле
нет. Потому что вот ты прочёл DQ-индекс NQ-индекс, да? И ты вот посмотрел, что очередь состоит из
сендеров, а ты сендер нужно встать в конец. Могло ли так получиться, что ты встал в конец в очереди
ресиверы уже? На самом деле нет, потому что ты же сейчас вот смотришь в этот слот, а чтобы очередь
переключилась в другой режим, ей нужно, чтобы всех достали и положили ещё ресиверы. Так что твой
касс просто поломается, потому что DQ-индекс просто уже сдвинулся вперёд. То есть если очередь
режим переключила, то ты это заметишь через проваленный касс. И ты перечитаешь DQ-индекс,
посмотришь голову и узнаешь, что тебе теперь нужно делать.
Ну не обязательно, что-то может разойтись, тут можно аккуратно сделать, чтобы... Кажется,
что если ты сначала читаешь NQ, а потом DQ, то ты тоже действуешь безопасно.
Секунду. Ну вот, сначала ты читаешь NQ, а потом DQ. Видимо, не просто так.
Вернёмся сюда. В Валгритме пока есть белое пятно большое. Я вроде бы рассказал,
но так написать нельзя. Вот ещё раз, смотрите, я сэндер, я прихожу, смотрю на голову очереди,
узнаю, что там сэнды, я пытаюсь встать в 14-й слот. А для этого что мне нужно сделать?
Сначала этот слот захватить, сдвинув NQ-индекс вперёд кассом, а потом записаться туда.
Вот кто видит проблему? Да, у нас есть два шага. Мы захватываем слот, то есть двигаем вперёд NQ-индекс,
а вторым шагом мы пишем себя в слот. И теперь легко представить сценарий вот такой вот. У нас
был сэндер, он пришёл вставать в очередь, он передвинул NQ-индекс вперёд, вот с 11-го слота на 12-й,
да, NQ-индекс передвинул с 11-го на 12-й, вот, но не успел записаться в слот. Ну или допустим даже
так, было немного иначе. У нас был там 10-й слот, там был сэндер, мы хотим встать в 11-й слот,
мы его застолбили за собой, но ещё не успели записать туда содержимое, то есть себя,
сослаться на себя, ну вот на объект вейтер. А дальше в очередь встали ещё какие-то сэндеры,
а потом NQ-индекс, потом какой-то ресивер достал содержимое 10-го слота, потом перешёл к 11-му
слоту, и вот, ну то есть приходит ресивер, NQ-индекс сейчас указывает на 11-й слот,
сэндер там до сих пор не сделал второй шаг, то есть он не записал туда ссылку на вейтера,
на вейтера своего. И ресивер в замешательстве, он не понимает, что происходит, он не понимает,
в каком состоянии очередь, и что ему сейчас сделать. Ну, вариант такой, я бы сказал,
относительно практичный, наверное, подождать можно, да, потому что вряд ли мы заснули на
бесконечное время всё же, но формально это получится не лог-фри, уже подождать нельзя,
и можно поступить как-то разумнее. Вот если у вас идеи, как можно поступить разумнее.
Вот, можно отравить слот, чтобы сэнд уже не думал в него что-то писать. Вот смотрите,
мы пришли в этот слот, и тут пока пустое место, это некоторое препятствие, такой родблок для нас,
мы не можем двигаться дальше, никто не может двигаться дальше. Ну вот нужно
от этого препятствия избавиться. Мы не хотим дожидаться сэндера, мы просто хотим ему сказать,
что «Сэндер, ты свой шанс упустил занять этот слот». То есть ты попробовал, но на втором шаге ты
слишком долго спал, и пока ты спал, мы в этот слот записали специальное, ну вот там могла быть
ссылка на объект Waiter, а мы туда записали специальную ссылку, вот такой Poison. Мы отравили
слот. И теперь вот сэндер, он действует чуть более сложно. Когда он захватывает слот,
двигая DQ Index, он не просто пишет в этот слот что-то с тором, он пишет туда кассом. Он пытается,
ну тут ладно, в коде, который мы будем смотреть, там не ссылка на Waiter, там прямо Waiter, у которого
есть полик, рутина и ссылка на элемент, и этот элемент либо ссылка, либо специальная ссылка на
отравленное значение. И вот мы в Receive'е кассом пытаемся переставить эту ссылку на отравленную,
а сэнд пытается переставить эту ссылку изначально null на свое значение. Ну и в зависимости от того,
кто раньше успел, тем все и завершилось. Если раньше успел сэндер, то он положит в слот
значение, ссылку на значение, мы его достанем и разбудим сэндера. Если же мы раньше успели отравить
слот, то сэндер попытается сделать касс перезаписи слота, проиграет, ну и откатится на самое начало,
снова перечитает NQ Index, DQ Index, и видимо уже будет работать с этим слотом, то есть откатится вот сюда.
Понятно?
Ну тут у тебя очередь всегда в каком-то одном режиме. Там либо...
Да, это следующий пункт нашего плана. Нужно заметить, что тут есть LiveLog.
Вот, предположим, что очередь пустая сейчас. Приходит сэндер и ресивер.
Ну и ладно, даже не пустая. В общем, есть сэндер, и он хочет записаться в слот.
Есть ресивер, который видит там пустой слот, и кто-то хочет записаться, он двигает вперед NQ Index,
другой конкурент его читает этот... Двигает вперед NQ Index, очередь становится не пустой,
другая картина пытается по DQ Index прочитать что-то, видит, что там пусто, и отравляет слот.
После этого тот, кто хотел записаться в слот, не может этого сделать, он проигрывает и сдвигается
вперед на шаг. Пытается положить следующий слот. Снова двигает NQ Index, очередь оказывается не
пустой, и его соперник, конкурент симметричный видит, что слот снова пустой, отравляет этот слот.
И вот они так, ну в таком LiveLog просто двигаются по этой бесконечной очереди, бесконечную вперед.
Ну, к счастью, очередь бесконечная, поэтому они это могут делать, но это не то, что мы хотим,
наверное. То есть прогресс у нас как будто бы снова нет. Но с LiveLog все-таки бороться немного
проще, и мы с ним поборемся очень остроумным способом. Ну, это можно по-разному было бы рассказывать,
но в общем мы поборемся с ним, придумав реализацию бесконечного массива сначала. Вот
мы каким-то образом придумаем бесконечный массив, как сделать log-free, а потом мы на основе этого
массива, пользуясь алгоритмом, который реализует этот массив, как-то автоматически решим проблему
с LiveLog между sender и receiver. Ну, давайте думать, как можно сделать бесконечно растущий массив.
Если у вас идея. Ну, от этого же он бесконечно-то не станет. То есть мы не просто двигаемся по
индексам, мы же еще добавляем туда файберы. Ну, да, вот это сделать расширяющийся массив log-free.
Ну, да, вот мы расширяющийся циклический буфер. А давай просто не расширяющийся сделаем.
В смысле не циклический, прости, а расширяющийся. То есть ты предлагаешь что-то более сложную задачу,
чем я. Ну, видимо, зависит от того, как ты сделаешь. Не понимаете меня. Вы предлагаете какие-то очень...
Вы говорите какие-то слова, но вы не представляете, как это написать. Просто вы говорите, что надо
это сделать. А вот придумайте, как вы понимаете, как сделать. А то я такие версии могу генерировать
долго. Нет? Смотрите, а мы же с вами делали уже log-free... Ну, мы на лекции разбирали с вами
log-free очередь. Мы же, по сути, делаем очередь бесконечно, да? Вот мы же делали log-free очередь.
Это называлось у нас очередь Майкла Скотта. Это был односвязанный список, который был
ориентирован от головы к хвосту. И когда мы добавляли... Когда мы хотели добавить новый
элемент в эту очередь, мы алоцировали узел, пытались его прицепить к хвосту с помощью касса.
И если это получалось, то мы двигали pointer tail вперёд. Но опять два шага, мы между ними могли
заснуть, поэтому если мы приходим, смотрим на хвост и видим, что этот хвост на самом деле не хвост,
то есть за ним есть продолжение, то мы помогали другому потоку, потому что он мог остановиться.
Это была техника хелпинг, и мы двигали его... Мы двигали tail на шаг вперёд. Но мы это делали кассом,
потому что многие потоки могли разом помогать друг другу. Но кто-то помогал, и в итоге прогресс
совершал, в любом случае. То есть сам пуш мог провалить свой касс, потому что ему уже помогли,
но это его, в общем, устраивало. А если мы говорили про операцию по извлечению из очереди, то с этой
стороны очередь выглядит как stack, и там, в общем, помодули только некоторого нюанса с фиктивным узлом,
это всё выглядело как обычное извлечение из stack. Мы читали голову и пытались подвинуть её на шаг
вперёд. Какое отношение имеет очередь к нашему массиву? Ну или можно вообще по-другому подойти
к этой проблеме, можно спросить так. А вот можно ли как-то сделать очередь Майкла Скотта более
эффективной, снизить накладные расходы на добавление нового элемента? А то мы просто каждый раз...
Интрузивность ни при чём. Можно ли снизить накладные расходы на добавление одного нового элемента?
Вот просто в таком... вот в такой схеме. Ну смотри, что я имею в виду. Вот у тебя есть узел, да,
и в нём лежит один элемент и один pointer next. А что если положить сюда два элемента? Три элемента.
Ка элементов. Ну то есть сделать то, что называется сегментированная очередь Майкла Скотта,
то есть очередь, в котором каждый узел представляет собой не одно значение, а некоторое фиксированное
количество значений сегмента. Да? Тогда мы будем реже выполнять какие-то сложные операции, может быть,
тогда мы будем чаще работать просто внутри одного узла. Ну так можно уменьшить количество
локаций. Собственно, ты же, когда пишешь контейнеры, ты же что делаешь? Ты не всегда довольствующийся
обычным эстадаристом. Ты можешь сказать, что вот у тебя есть дек, и это же тоже список, да, только он
выполняет меньше локаций, потому что в каждом узле сразу много слотов. Вот мы получим такой
локфри дек, можно сказать. Ну как бы не дек, конечно, то есть мы с одного конца добавляем,
из другого достаем, но вот такие вот чанки с данными в каждом узле хранятся, они по одному
значению. Да? Ну вот это такой разговор, как можно было бы пооптимизировать учёть Майкла Скотта. А теперь,
если посмотреть на всю эту конструкцию как-то вот немного под другим углом, то что получится? Мы же
сделали расширяющийся массив. У нас есть узлы, в которых есть чанки, давайте просто введём на них
сквозную нумерацию. У каждого узла будет индекс, в каждом узле будет некоторое фиксированное
количество слотов, и вот тогда очередь Майкла Скотта станет для нас просто-напросто таким вот
бесконечно растущим массивом. Ну, сам по себе такой компонент не является, конечно же, тривиальным,
то есть нужно подумать о том, управлять памятью в нём, как оба избегать Hazard Pointer и вот вся эта
история, которую мы вот в этом году не написали всё же, к моему великому сожалению, но идея должна
быть понятна, мне кажется. Вот смотрите, это узел, вот это реализация этого бесконечно растущего
массива. В каждом узле есть массив вейтерс, где каждый вейтер — это там хэндлка рутины и элемент,
ссылка на элемент. Ну, потому что мы говорим про язык поверх JV. У нас есть ячейка ID, это просто
порядковый номер этого блока. Ну, то есть, если у нас размер сегмента 4 и ID 3, то это значит,
третий блок, значит, индексы начинаются вот с 8 и по 11, если я, конечно, нигде ничего не напутал,
да. В четвёртом, в блоке с четвёртым ID индекс 12-15. И в каждом узле есть ссылка next на следующий
узел, большой такой. Это мы продвигаемся по статье. Вот у нас этот узел, есть ID, есть какое-то
количество вейтеров и есть ссылка на следующий узел. И вот эти два индекса — это индексы,
такие вот логические в нашем массиве, да, начало и конец очереди ожидания. А есть head
and tail — это уже детали реализации этого массива. Ну как, справляемся, да? Хорошо, теперь можно
просто прочесть ход. Он занимает всего лишь страницу, но страница локфрикода — невеликая
сложность. Кажется, что все компоненты нам понятны сейчас. Нужно просто пробраться через какие-то
технические подробности, но это вот такое типичная локфри. Смотрите, тут изображена на этой странице
только одна операция send, потому что send и receive полностью симметричны. Ну то есть там поменяется
в одном месте проверка головы, и вот если там мы проверяем голову и видим там, мы в сэнде проверяем
и ожидаем, что если увидели receive, то там одно, иначе другое. В receive будет все просто то же самое,
только вот в этом месте перевернут немного. Так что мы разбираем только операцию send, а если
очень в другой режим, то для нее там такая же логика. Итак, мы читаем сначала NQ, потом DQ.
Ну вот почему в таком порядке? Мы, кажется, тоже уже обсудили. Это может быть принципиально. Но
могло так получиться, что NQ оказалось меньше DQ, потому что мы прочли NQ. Да, это все в цикле
while находится. То есть это такая попытка сделать операцию send. Если напровалится, то мы повторим.
Но может так получиться, что NQ индекс оказался меньше DQ индекса. Почему? Ну потому что мы
прочитали NQ, а потом с очередью много всего произошло, и все уехало там вперед по индексам.
Поэтому мы вполне могли получить такую несогласованную пару. Ну, значит, мы точно отстали
от жизни, и нужно просто перечитать все заново. Отправляемся в начало итерации. Что если DQ индекс
равен NQ индекс? Ну, отлично. Мы стали свидетелями пустой очереди. Пытаемся в него добавиться. И
если получилось, а опять могло не получиться, потому что мы с кем-то конкурировали и нас тут
обогнал. Вот если получилось, то мы запарковали карутину текущую. Тут у нас стеклос карутины,
поэтому мы можем запарковаться уже после того, как нас разбудили, потому что это просто ред
эко. Но это история про стеклос карутины, вы, наверное, это усвоили, что там гонки никакой нет
между установкой и возобновлением. Если не получилось, то опять произошло что-то непонятное,
и мы пробуем заново. Хорошо. Значит, у нас теперь есть пара NQ индекс DQ индекс, которые похожи на
не противоречащие друг другу. Что нужно дальше сделать? Нужно понять, в каком состоянии сейчас
находится канал, да? То есть, кто находится в голове, либо sender, либо receiver. Наша задача
прочесть содержимое NQ индекса. А где он находится физически? Он находится в некотором узле. Вероятно,
который указывает head. Поэтому мы читаем head. А теперь верно ли, что сегмент, то есть узел,
на который указывает head, содержит в себе сегмент, в котором есть нужный индекс? Вот мы это проверяем.
Вот узел, в котором находится нужный нам индекс, находится в... имеет ID вот такой вот. А мы смотрим
вот такой. На узел с таким ID. Если... простите. Если ожидаемый ID узла оказался меньше,
чем актуальный, то это означает, что мы снова отстали от жизни, что head уже убежал вперёд,
что наш DQ индекс больше не актуален, и нужно перечитывать всё заново. Да? Но просто пока
разбор случаев, мы пытаемся получить такой согласованный снапшот состояния канала. А что,
если DQ индекс... что если ID сегмента, в котором находится DQ индекс, оказался больше, чем head ID?
Это означает, что просто head ID отстал. Ну, то есть какой-то другой поток добавил новый узел,
а почему-то head ID не поправили ещё. Ну, тогда мы пытаемся подтянуть head вперёд и пробуем заново.
Ну, это вот некоторое хелпинг. И вот наконец-то, наконец-то мы справились. У нас есть DQ индекс,
и у нас есть ссылка на узел, в котором лежит ячейка с этим DQ индексом. И мы наконец можем
прочитать содержимое. Ну, вот как мы читаем, разбираемся. У нас есть узел N, у нас там есть
индекс E внутри этого узла, и мы должны прочесть эту ячейку. Ну, кажется, кстати, тут... да, мы
передаём туда индекс уже внутри сегмента. Вот, мы берём узел, берём его вейтеров и смотрим на
элемент. Элемент — это не данные, это вот ссылка. Ну, представьте себе язык, вот какой-нибудь там
Java, Kotlin, что-то подобное. У вас есть ссылка, и вы читаете эту ссылку. Если там написано не Null,
то вот, значит, слот уже как бы зафиксировал своё состояние. Он либо отравлен, либо там значение
лежит, либо туда кто-то встал уже. А если он оказался пуст, то вы хотели что-то прочесть из него,
да? А вы не можете, он пуст. И вы не хотите ждать. Поэтому вы отравляете этот слот, чтобы идти дальше.
Вы делаете касс. Вы пытаетесь переставить Null на Broken. Если получилось, то уходите и
возвращайтесь от Broken. Если не вышло, то, видимо, почему ваш касс провалился? Потому что там уже
что-то было не Null. Поэтому вы вернули то, что там сейчас есть. Ну и вот, вы вот с такими небольшими
усилиями прочли содержимое DQ-индекса, наконец. Ну, ячейки по индексу DQ-индекс. И теперь смотрите,
если слот был отравлен, то нужно его пропустить. Нужно сдвинуть DQ-индекс вперёд. Пробуйте и
ретравитесь. Почему вы пробуете кассом? Потому что на него один можете так делать. Вот, а если
вы видите ресивера, вот там находится ресивер. Что это означает? А вы же операция Ascent? Ну вот,
значит, случилось rendezvous, да? То есть вы застолбили себе индекс? Нет, вы не застолбили ещё
индекс. Вы просто увидели ресивера. Вы знаете, что в очереди сейчас ресивер, а вы sender. Так что
нужно разбудить этого ресивера, дать ему значение. И вот вы попадаете в Resume Waiter. Вы sender,
который готов разбудить этого в текущем узле ресивера. Ну, для этого вы пытаетесь захватить
его внимание. Инкрементируете DQ-индекс с помощью кассы. Если получилось, то он ваш,
вы его будете. Кладёте ему значение, берёте, да, вы берёте этого вейтера и будете его,
отдавай ему значение с помощью вот такого API. Ну, это уже какие-то нюансы, не очень важно,
как это написано. Вот, но главное, что вы захватили слот, там был ресивер, и касс, поскольку он
завершился, вы уверены, что в этом слоте по-прежнему есть ресивер, никуда он не денется оттуда. У вас
стоит машина такая, ну, либо в отравленное состояние, либо в ждущего sender-ресивера.
Разбудили. Если не получилось, если касс провалился, то не беда, вы опять откатываетесь
с самого начала цикла while, делаете новую итерацию, пытаетесь всё заново. В Kotlin не сомневаюсь.
Да, не нужно применять C++ к Kotlin, пожалуйста.
Не, ну, подожди, вот ты написал некорректное освобождение памяти и говоришь, что...
Если ты освобождаешь память, которую ещё используют, то у тебя некорректная программа. Давай так.
Ну, во-первых, мы не управляем памятью, во-вторых, вот просто такой код писать не стоит, да, который
читает память, которую вы уже освободили. Это какое-то странное желание немного. Это похоже на
наших разработчиков просто. Итак, разбудили, а если там был не ресивер, то мы пытаемся что сделать.
Мы пытаемся... Если мы прочли DQ-индекс и там оказался sender, а мы sender, то мы пытаемся встать в
конец очереди. Ну, это развилка, что мы делаем, либо одним, либо другим способом. А теперь нам нужно
сильно ускориться. У нас следующая пара, и она, кажется, здесь будет или не будет.
В этой аудитории. А сейчас зачетная неделя, поэтому всякое бывает. Ну ладно, тогда... Ладно,
я не смогу ускориться, если что, перейдем просто в 425. Значит, с этой веткой мы разобрались. То есть,
когда случается рандевуй, когда мы кого-то будем. А сейчас мы увидели, что очередь, что в очереди спят,
крутины, которые выполняют ту же роль, что и мы, то есть sender, и мы хотим встать в очередь.
Ну, для этого мы хотим попасть в какой-то слот. И тут у нас есть такая развилка. Мы берем узел,
ну и снова проверяем, верно ли, что наш... что tail указывает на узел, в котором есть
нужный индекс. Такая же история. Если нет, то откатываемся. А если индекс наш нулевой,
то пропускаем вообще этот индекс. В смысле, нулевой внутри сегмента. Мы его пропускаем об этом чуть
позже. А дальше у нас есть два варианта. Либо мы переполняем слот, либо мы переполняем сегмент,
либо мы не переполняем сегмент. Если мы не переполняем сегмент, то все очень просто. Мы опять
пытаемся увеличить NQ-индекс и просто записать себя вот в ячейку. Ну вот это явная опечатка,
да? Потому что тут не может быть... это глобальная индексация, а нам нужна относительно внутри
сегмента. Но все равно все мы понимаем, что это имелось в виду. Мы пытаемся захватить... мы
пытаемся встать в первый свободный слот текущего сегмента. Если это не получилось,
ну попробуем заново, как обычно. Ну и тут опять два шага. Мы захватываем сначала слот,
если это получилось, мы должны записать туда элемент. Но это может не получиться, потому что
мы конкурируем с читающим, который слоты отравляет. Вот здесь вот. Поэтому у нас здесь тоже касс.
Отлично. А что если у нас чанк переполнился? То нужно алоцировать новый чанк. И это уже просто
добавление в очередь Майкла Скотта. То есть мы добавляем новый узел, мы кладем сюда себя в
нулевую позицию и пытаемся прицепить... ну вернее мы... сейчас, аккуратно. Мы создаем новый узел,
мы пытаемся положить себя в нулевую позицию и мы пытаемся прицепить себя к хвосту очереди Майкла
Скотта. Ну вот так. Типичный для очереди Майкла Скотта касс. Ну иногда мы можем помогать кому-то.
Вдруг мы увидели уже tail next, он оказался не нул, тогда нужно передвинуть tail вперед.
А теперь вопрос на внимание. Мы решили лайфлог сейчас. Лайфлог у нас больше нет. Мы вроде бы
специально ничего не делали, но его больше не существует в нашем коде, в нашей реализации. Вот
когда у нас был бесконечный массив, лайфлог был. Когда у нас есть вот такой вот массив специальный,
у нас лайфлога уже нет. Почему? Вспомним, как он вообще появлялся. То есть у нас была пустая
очередь и мы приходили и вот увеличивали NQ индекс, отравляли слот, потом проваливали запись,
пробовали дальше пойти, да? Ну то есть один поток, одна корутина увеличивала NQ индекс и занимала
слот, делала его не пустым, ну как бы наполовину не пустым, предпустым, да? А другая корутина,
она видела все-таки, что не полон еще стакан и как бы она пессимист, половина отравляла его и
шла вперед. Так вот, на массиве это может работать бесконечно, а на таком массиве из чан,
она списки из чанков не может. Почему? Потому что мы вот так можем этим лайфлогом идти вперед
по массиву до тех пор, пока мы не упремся в границу сегмента. И потом уже сендер,
который увеличивает NQ индекс, что он сделает? Он не просто индекс увеличит, он, чтобы продолжать
движение вперед свое бессмысленное, он должен алоцировать новый чанк. А когда он алоцирует
новый чанк, новый узел, то он там занимает нулевой место сразу успешно. И вместе с публикацией этого
чанка он там уже сразу есть. То есть он два шага делает в другом порядке, теперь атомарно,
получается, для ресивера. Понимаете? Вот, и на границе чанка этот лайфлог обязательно разломается,
ну в смысле, он разрешится. Вот, довольно ловко, да, получилось. Ну то есть этот лайфлог есть,
он очень простой алгоритм, там есть лайфлог, но за счет того, что мы вот таким образом сделали,
сделали очередь, мы можем... мы от лайфлога вот так автоматически избавились. Ну да, нулевые
слоты, поэтому мы скипаем, потому что они всегда не пусты, потому что если сегменты публикованы,
в нем уже есть нулевой... карутина вейтер в нулевом слоте. Довольно простой алгоритм. Вот, в принципе,
весь лог-3-канал написан. Можно его написать и сравнить его с блокирующимся каналом. Мне очень
любопытно, если кто-то попробует сделать, даже без управления памятью, то есть вот мы не освобождаем
память, допустим, для простоты, и вот посмотрим, насколько будет велика разница. Потому что в
профиле у вас там будет торчать спинлог, если вы напишите канал и будете это исследовать. А теперь
мы как бы идем на следующий уровень, и там становится все интереснее, потому что мы хотим
поддержать в этом канале селекты. И селекты, они должны быть... селекты ну и для сендов, и для
ресивов. И смотрите, какая ситуация возможна теперь. Вот, предположим, у вас есть канал, и там
есть... там есть сендеры, и эти сендеры являются селектами. Ну, некоторые сендеры могут являться
селектами. Вот вы приходите с ресивер, вы видите, что в очереди сендеры, значит, нужно захватить
тебе первый слот свобод... первый слот из очереди, и зарезюмить сендеры. Да? Сейчас.
Сейчас я придумаю, что я хочу.
Я хочу, наверное, селект...
Я хочу, наверное, селект, который пишет, и я ресивер, который я хочу.
Сейчас, мне нужен... мне нужен нетривиальный... нетривиальный случай.
Нет, все нормально, в очереди сенды.
А я селект. Я прихожу в канал, и что я делаю? Я хочу забрать оттуда первый слот.
То есть, я посмотрел, там сенды лежат, мне нужны сенды, я увеличил DQ-индекс, достал сендера,
ну, захватил сендера себе, все, он мой. Но я же селект. И я могу... я привередливый, я могу от
значения отказаться иногда. Потому что, ну, вот просто в мой селектор, вот в этот консенсус,
уже кто-то что-то написал. То есть, просто другой канал меня заполнил уже значению. И в итоге
проблема появляется. Я сендер, я селект ресив, пришел в канал забирать значения, захватил себе
слот, там был сендер, которого я вроде бы как бы захватил себе. Но воспользоваться я не могу.
То есть, я хотел бы сделать следующее. Я хотел бы достать из очереди сендера,
только если мой консенсус еще не установлен. Да? То есть, если в одной ячейке что-то, то есть,
я бы хотел посмотреть на две ячейки, и потом эти две ячейки поменять. Если вот у меня консенсус
еще не установлен, и если в DQ индекс указывает... DQ индекс указывает на сендера, то я бы хотел,
там, поглотить этот DQ индекс и установить флажок, что я селектор получил значение. И вот мы
приходим к операции, где мы к потребности для лог-фри канала с селектом иметь лог-фри касс,
который можно выполнить на двух произвольных ячейках памяти. А теперь представим себе,
что сендер в канале, которого мы хотим достать, это не просто сендер, это сендер из селекта. То
есть, у нас был селект с как бы... был селект с ресивом и селект с ресивом и тайм-аутом с одной стороны,
а с другой стороны селект с сендом и тайм-аутом. Вот, и как бы в нашем канале с данными лежит селект
для отправки, мы приходим селект для получения, и нам нужно еще более сложное рандеву, потому что
мы хотим сэнд селект на получение, хочет поглотить узел, ячейку, очереди, только если сам этот...
только если селект текущего ресива еще не заполнился значением, там отмена из другого канала контекста,
и сэндер из селекта на отправку тоже еще не заполнился значением, и селект сэндера,
который уже находится в очереди, еще не заполнился значением. Понимаете меня тут?
Очень путанно говорю. Но вот у нас есть два селекта, и нам нужно и состояние очереди поменять,
условно, и два селекта заполнить, если они пустые до сих пор. Вот, это уже касс на трех ячейках. Вот, и так
мы приходим очень естественно к задаче иметь, как выразился Миша вчера, многословный касс,
который умеет переключить n ячеек памяти, если в них находятся некоторые ожидаемые значения.
Ячейки памяти должны быть произвольными. В смысле, вот у нас, мы знаем, в некоторых процессорах есть
инструкция Compere Exchange 16b, то есть она может посмотреть на два машинных слова, соседних памяти,
и переставить их на новые значения. Ну, то есть касс просто двойной ширины. Вот дело сейчас не в
ширине ячеек, а в том, что это просто разные ячейки, произвольные ячейки. Мы не управляем тем,
где они находятся. Алгоритм работает с произвольными ячейками. И вот мы хотим такую операцию иметь,
Multi-World-Cass, который, Multi-World-Cass, который оперирует сразу несколькими ячейками памяти.
И вот его научились делать, научились делать его, ну вот я поговорю про реализацию, которая даже не
совсем... Это некоторый затейливый алгоритм. Мне он кажется очень симпатичным, очень ловким,
но в то же время вот он используется, используется, в частности, в реализации
корутин в котлене. Вот вы можете посмотреть на статью, на доклад Романа Ивизарова,
кажется, 19-го года, где он рассказывает, как там на основе замороченного двусвязанного
лог-фри списка и вот от такого сиректа можно построить лог-фри каналы сиректа для котлина.
Ну вот, так что то, что мы говорим, это в каком-то смысле даже практично. Ну вот так,
прямо скажем, не многие делают. Это очень-очень сложно, и вопрос даже в том, нужно ли так настолько
хорошо делать. Вот ГО, скажем, находится без этого. В ГО там блокировки. Ну вы можете видеть это,
открыв ссылку в задачу. Итак, наша задача построить мульти ворд касс, который сравнивает
N-ячеек, сравнивает содержимое N-ячеек. Если во всех из них лежит одинаковое значение, то,
не одинаковое, простите, а ожидаемое значение, то переставляет их какие-то новые значения. И это
должен быть алгоритмический мульти касс, то есть аппаратной поддержки у нас нет. У нас есть ячейки
памяти, которые работают, на которых есть все атомарные операции, которые у нас есть,
оперируют отдельными ячейками памяти. Так что мы должны обходиться простыми атомарными операциями,
и, наверное, вы догадываетесь, с помощью чего мы будем решать эту задачу. Мы будем решать ее с
помощью обычной операции Compare Exchange. Но опять же, вы этого не знаете, но у вас наверняка есть уже
интуиция по этому поводу, что, видимо, из всех операций, которые у нас в процессоре есть,
которые есть в атомиках, операция Compare Exchange, она наиболее выразительна, наиболее полезна. Ну,
потому что, хотя бы потому, что с помощью нее можно было бы выразить все остальные, все другие
операции, да, это реально. Вот, у нас есть такой однословный касс, лаконичный касс, и мы с помощью
него хотим реализовать мультиворд касс, который должен быть сам по себе лог-фри алгоритмом. Вот,
мы начнем решать эту задачу с помощью очень странного вспомогательного шага, а именно мы
построим операцию с очень неинтуитивной, на первый взгляд, семантикой, которая называется restricted
double-word single-swap. Семантика такая, у нас есть ячейка A1, ячейка A2, есть ожидаемые значения O1 и O2,
и есть целевое значение N2. И мы хотим, если в A1 находится O1 и в A2 находится O2, записать в A2
N2. Ну, то есть, это такой, мы хотим сделать, по сути, касс на ячейке A2 из O2 в N2, но только если в
ячейке A1 находится O1. Такой дважды условный касс. То есть, даже операция слабее, чем касс 2. Нас не
интересует успех или поражение, нам операция возвращает только то, что было написано в A2,
и все. И операция не перезаписывает A1. Ну вот, если мы решим такую задачу, то мы с помощью нее
можем уже довольно просто построить мультиворд касс. Как мы решим такую задачу? Нам нужно прочесть...
Семантика понятна? Нам нужно каким-то образом прочесть атомарно две ячейки памяти и одну из них
перезаписать, если в двух ячейках ожидаемые значения. Ну, разумеется, мы не можем прочесть
атомарно две ячейки памяти разные. Можем только по очереди прочесть. И вот мы прочли первую,
допустим, A2. Она совпала с O2. Дело идет хорошо. Как теперь прочесть A1? Точнее, как прочесть?
Понятно. Как не потерять гарантию, что ячейка A2 к этому моменту не изменилась? Ну, очень просто,
взять блокировку на ячейку A1. То есть, мы берем блокировку на A1, читаем ее значение, если там все
хорошо, то смотрим на A2. И пока мы не прочитали A2 и не приняли решения, мы блокировку на
пока мы не прочли A1, мы блокировку на A2 не отпустим. А значит, наша проверка не инвалидируется.
Замысел понятен? То, что это не лок-фри, наверное, комментировать не нужно. Вот мы хотим, чтобы
алгоритм стал лок-фри. Поэтому мы хотим некоторую специальную блокировку, которую можно снять за
нас. Ну, потому что если другой поток увидит, что там лежит наша блокировка, то он должен
избавиться, потому что она ему мешает. Но если бы он просто у нас блокировку отнимал, это было бы
странно, потому что какая-то блокировка. Поэтому вместо того, чтобы снимать блокировку, он
может ее снять, только если он помог нам. Он не хочет инвалидировать, он хочет помогать. И смотрите,
что мы сделаем. Мы скажем, что у нас операция вот эта вот restricted double word, double compare,
single swap получает аргументом, получает свои аргументы, не видя там вот A1, O1, вот все
этой пятерки. Она получает некоторый дескриптор. Объект, в котором в полях находятся все аргументы,
адреса, аргументы. Откуда взялся этот дескриптор, операцию не волнует. Ну, то есть нам авторы статьи
намекают, что лучше писать на языке автоматической сборкой мусора здесь. Вот, и это правда. Ну,
то есть писать на C++ — это добавлять себе огромную сложность, перпендикулярный алгоритм, а именно
управление памятью. Вот мы считаем, что у нас дескриптор есть, и вот он... можно хранить на него
указатели, и вот пока указатели живы, объект не разрушается. Такое очень сильное предположение,
предположение, что у нас есть сборка мусора какая-то. Мы на это закрываем глаза сейчас. Так вот,
что мы делаем? Мы сначала читаем ячейку A2 и сразу же автоматически берем на него блокировку,
если содержимое совпало с ожидаемым. Это выражено так. Мы делаем CAS на ячейке A2. Если там лежит
дескриптор O2, то мы туда пишем вместо значения дескриптор, то есть pointer на дескриптор. Вот,
и теперь любая другая операция, которая пришла читать ячейку памяти, если она видит там дескриптор,
то она может пройти по нему и узнать аргументы, собственно, этой операции RDCSS, потому что в ней
все аргументы написаны. Ну вот, смотрите, что происходит. Мы читаем ячейку A2, сравниваем
содержимое этой ячейки с O2, и если совпало, то устанавливаем дескриптор, такую блокировку.
А дальше нам операция CAS возвращает то, что она прочитала из O2. Может быть, значение,
которое там было, являлось ссылкой на дескриптор. Как это понять? Ну, вы там младший битик в адресе
взведете, чтобы отличить просто произвольный pointer от дескриптора. Вот. Ну, это такой неприятный
случай. А может быть, вы сразу прочли O2. Но если вы прочли O2, то вы знаете,
что вы записали дескриптор, и вот первый шаг состоялся. Вы сравнили A2 с O2, совпало,
и вы взяли блокировку. И вы дальше спокойно читаете A1, выполняете шаг COMPLETE.
Читаете A1. И если вы видите в A1 O1, то вы завершаете успешно вашу операцию RDCSS. Вы
переключаете ячейку A2 с D на N2. Понятен принцип? То есть, вы делаете такую цепочку состояния,
у вас A2 сначала указывает на O2, потом на дескриптор, а потом на N2.
Что? Ну, тут можно многие параллели углядели, да. Ну да, но мне сейчас, наверное, не очень полезно,
в смысле, проводить параллели с чем-то другим. Идея понятна? У меня она кажется довольно ловкой.
Ну а если вы прочитаете дескриптор, то что вы делаете? Вам он мешает выполнить вашу операцию.
Вы просто читаете ячейку памяти, а там написан дескриптор другой операции. Вы даже не можете
понять, в каком ячейке состояние. Оно в межуточном состоянии. Оно не определилось еще. То есть,
то ли она переходит в новостей, то ли она не переходит. Поэтому вы просто помогаете завершить
операцию другому потоку. Вызываете complete. Так что complete можно вызвать дважды. Ну и вот поэтому,
когда вы видите в ячейке A1, O1, то вы не просто переводите A2 в N2 слепо, перезаписывая содержимые
ячейки, а вы делаете CAS, потому что в ячейке уже может быть не дескриптор, потому что вам помог
другой поток. Ну, собственно, вот это и называется хелпингом. Есть вопросы?
Вы выглядите так, как будто непонятно ничего, а все, на самом деле, очень просто.
Ну вот рисунок, который, в общем, мне кажется, я не знаю, что проиллюстрировать еще. У тебя было
две ячейки памяти. Ты хотел переключить Y с B на C при условии, что в X находится A. Вот у тебя был
объект, который эту операцию описывал. И вот первым делом, ты переключил CAS в ячейку Y с B на
дескриптор. Вот, а дальше ты уснул. Но не страшно, любой другой поток может прийти, и если он здесь
увидит дескриптор вместо значения, то он пойдет по нему, увидит все аргументы и сможет перевести
либо Y в C, если тут лежит в X все еще A, либо, если он видит в X A, то сбросит дескриптор обратно
в B, потому что в дескрипторе есть второе значение. То есть мы можем как и накатить, и откатить.
Так не страшно, ты всегда делаешь CAS. То есть у тебя есть, смотри, в этом, в этой операции ты делаешь
всего одну мутацию одной ячейки Y, ну то есть A2 из старого в новое. И ты сначала делаешь такую
промежуточную мутацию из старого значения в дескриптор, а потом ты либо откатываешь, либо
накатываешь, при условии, что дескриптор все еще стоит. Вот, ты читаешь A1, принимаешь решение,
а дальше ты либо накатываешь, либо откатываешь, но делаешь это с условием, что до сих пор в ячейке
A2 лежит дескриптор. Если вдруг что-то изменилось, то просто ты не доделаешь свою операцию. Ну,
в смысле она потеряла актуальность, кто-то другой тебе помог уже. Очень просто. Ну,
такой просто двухфазный, двухфазная перезапись. Ну, это вот мы накатываем новое значение, тут мы
убедились, что в A1 лежит не O1, и мы откатываем старое значение. Но мы и накатываем, и откатываем,
только если у нас все еще в ячейке A2 находится указатель на дескриптор. Вот, ну этот комплит мы
выполняем либо сами, либо мы выполняем, либо мы помогаем другому. Не, абсолютно. Тут всего одна,
одна перезапись, по сути. Вот, а теперь, имея такую операцию, очень просто сделать алгоритм для
сразу N ячеек. И он тут написан довольно, выглядит как будто неаккуратный какой-то псевдокод, написанный
на чем-то C подобном. Но идея очень простая. У вас есть теперь N ячеек разных, и вам нужно сравнить
все и все переставить в новое значение. Как вы это сделаете? Вы сделаете это в две фазы. Вы сначала
все ячейки сравните и залочите по очереди, а потом, если вы на все ячейки собрали блокировки и
проверили их содержимое, то вы уверены, что, ну вот, во-первых, вы зафиксировали состояние,
в котором все ячейки совпадают с ожидаемыми значениями, а во-вторых, вы повесили на них
дескрипторы, которые являются, по сути, блокировками, которые мешают другим потоком эти ячейки менять,
не завершив вашу операцию. Поэтому вы действуете в две фазы. Вы накапливаете блокировки, вешаете
дескрипторы на все ячейки, которые вы трогаете, и если операция, если вы на все навесили дескрипторы,
и везде все совпало, то вы на второй фазе просто перезаписываете, ну, либо накатываете значения
новые, либо откатываете старые. Подожди, это пока только общая идея. Ну вот, накатываем и откатываем,
тут уже видно здесь. Вот мы идем по N ячейкам дескриптора, тут снова есть такой магический
дескриптор, который содержит все записи. Вот, у нас есть адрес для каждой записи, и мы смотрим,
если в ячейке все еще дескриптор, то мы накатываем, если у нас операция в целом завершилась успешно,
то мы накатываем новое значение, иначе откатываем старое значение. Ну а теперь чуть подробнее. Вот с
чего мы начинаем? Мы операция CAS N. У нас есть некоторый статус, в котором мы фиксируем. Мы успешны
или мы провалились? Это такая, это локальные переменные пока. Вот наш прогресс. Идем по ячейкам,
ну и пока операция успешна. Если операция провалилась, то зачем идти по остальным? Идем по ячейкам,
берем текущие, идем по ячейкам, берем текущую, которая нас интересует, и вот с помощью такой
операции, то есть пока с помощью CAS можно считать. Пытаемся переключить ячейку с адресом вот таким
вот, с старого значения, с ожидаемого значения, на дескриптор. Если получилось, то идем дальше.
Вернее как, мы пытаемся переключить и смотрим, что в ячейке было до. Вот если, скажем, там было
что-то другое, постороннее, не то, что мы ожидали, то мы операцию фейлим. Просто там было какое-то
странное значение. А может быть, там был дескриптор? Тут есть разные варианты. Возможно,
это дескриптор чужой. Было бы естественно, да? Мы лочили ячейки, увидели чужой дескриптор,
чужой лог. Что делать? Ну, нужно помочь. Мы просто запускаем его CAS. Просто сначала,
с чистого листа. И у нас есть все аргументы. Это просто сам дескриптор. Мы просто стартуем,
ну, продолжаем. Не то, что продолжаем. Мы вот начинаем параллельно чужую операцию.
С первой фазы. По очереди берем все блокировки. А что, если это наш дескриптор? Что? А почему,
вообще, наш дескриптор оказался там? То есть, мы пытались в ячейку записать свой дескриптор,
а там уже наш дескриптор. Но может быть, у нас было пять ячейек. Мы поставили в первые две там
свои дескрипторы. Мы пересеклись по ячейкам с какой-то другой операцией CAS и ей помешали,
и она начала вам помогать и прошла дальше нас. И вот мы увидели, как бы, что нам, мы уже забежали
вперед. Так что такое тоже могло быть, но это, кажется, не беда. Нас то устраивает.
И, допустим, мы доходим до конца этого цикла успешно. Ну, либо с провалом, либо с успехом,
либо мы доходим до конца с успехом. То есть, мы сравнили все ячейки, повесили все локи. Либо
мы где-то провалились. Ну, тогда выходим раньше. И вот момент истины. Мы должны зафиксировать в
дескрипторе статус операции. Но почему-то мы делаем это с помощью CAS. То есть, мы пишем в
дескриптор статус, текущий свой статус, как мы его понимаем. Но CAS, то есть, видимо, возможно
такой сценарий, когда один поток хочет записать в дескриптор одной операции успех, а другое
поражение. Может такое быть? Ну, ответ может, да, я же об этом и говорю. Почему такое может быть?
Ну, вот допустим, у вас было пять ячеек в CAS, и вот у вас было два потока, которые делали этот CAS.
Ну, то есть, один делал, а другой помогал. И вот они прошли по первым четырем ячейкам успешно. И вот
есть пятая ячейка. И поток V, который начал эту операцию, читает, выполняет CAS на последней пятой
ячейке. Ожидает там старое значение, хочет туда поставить блокировку, дескриптор. Но нет, в ячейке
другое значение, неправильное. И этот поток принимает решение, что операция должна зафейлиться.
После этого запускается помощник, он тоже смотрит на пятую ячейку, но когда он на нее смотрит,
ячейка уже поменялась и стала правильной. Ну и все, у второго потока помощника есть момент времени,
когда он видел все пять ячеек в правильном состоянии. И он туда инсталирует дескриптор и хочет
автомарно переключиться теперь, и хочет признать CAS успешно. Ну, то есть, у нас есть как бы две
точки зрения на успешность одной и той же операции CAS. У первого потока есть свидетельство того,
что одна ячейка была в неправильном состоянии, и CAS провален, а другой поток считает, что его
все устраивает, нужно, ну как бы он залучил все ячейки, можно переключиться на успех. И вот просто
они соревнуются, то есть они оба правы, то есть оба ответа валидные, просто в разные моменты
времени. И они с помощью CAS, с помощью консенсуса, про который мы не говорили, решают, кто победит из них,
чье решение будет, чье решение войдет в историю в итоге. Вот они это делают, а потом читают этот
статус и вот узнают, кто же победил. А дальше идут просто по ячейкам на второй фазе и либо накатывают,
либо откатывают. То есть они опираются не на свое решение, а на вот решение консенсуса.
Да, ну у нас была просто локальная переменная, а вот теперь они смотрят на глобальную перемену,
которую писали, это важно. Мы сначала сюда пытаемся записать условно, если еще не записано,
а потом смотрим на принятое решение. Вот, вопрос, а почему не бывает такого, что у нас поток
повесил все локи, успешно установил CAS, заснул на месяц, просыпается и начинает писать что-то в ячейке?
А? Ну нет, это не страшно, он не сможет, потому что дискриптора там уже не будет, я вру. Давайте
по-другому. Вот у нас поток делал CAS, он ставил дискрипторы на ячейке, поставил три из пяти,
и вот тогда заснул на месяц. Просыпается, идет по остальным ячейкам, четвертый, пятый, и вот все
уже давно не валидно, да? А он пытается поставить на них дискрипторы. Ерунда получится. Почему он
считал, что... что? Почему он сферится? Он не сферится. Он посмотрит на четвертую и на пятую, спустя месяц
у них будут правильные значения, он запишет два дискриптора. Ну не важно, но какая разница? Он
увидит здесь успешный... он сделает здесь CAS, увидит в дискрипторе успех и перезапишет ячейки,
которые уже давно перезаписаны. Ну там первые три он не тронет, потому что уже нет дискрипторов,
а вот четвертую и пятую перезапишет. Хотя это бессмыслится. Нет, когда он пошел спать,
он еще даже не посмотрел на две ячейки. У нас было пять ячейок, там ожидали нули. Вот он взял
локи на первые три, заснул на месяц. За это время кто-то увидел эти локи, докатил операцию до конца,
перезаписал все нули на все единицы, а потом какой-то другой CAS откатил обратно единицы в нули. И вот мы
просыпаемся через месяц и читаем четвертую ячейку, там ноль, читаем пятую ячейку, там ноль. Ну то есть
локи там вешаем, дискрипторы вешаем, получаем две блокировки, выполняем CAS на статусе, получаем
успех, потому что там уже был успех, и четвертую и пятую ячейку перезаписываем в ноль. Ой, в единицу,
простите. Понятно проблема? Ответ такой, а где мы использовали CSS? Просто было бы странно,
что мы... Вот мы используем его ровно здесь. Мы не просто CAS делаем, я говорю CAS, потому что так
проще, но мы делаем условный CAS, то есть мы вешаем дискриптор на ячейку с адресом addr, не только если
там старые значения, а если еще статус не установлен. И вот нам вот поэтому нужна была вторая
вспомогательная операция. Нам нужно сделать CAS дважды условной, с одной стороны, по содержимому
ячейки текущей, а с другой стороны, по статусу операции. То есть если хотя бы один поток дошел
до этой строчки и выполнил ее, и может находиться на второй фазе, на первой фазе уже ни одного дискриптора
не повесит. И это очень важно. Вот только вот на этом все и держится, вот на этом restrict double
compare single swap. Ну что, мне кажется, что мы отрубились, да? Это все очень просто. У нас есть контрольный
флажок, который говорит, операция CAS успешна или нет, и мы идем вешаем дискрипторы, а если CAS уже
завершился каким-то потоком, то мы дискрипторы перестанем вешать, потому что они могут быть уже
невалидны. Что? Ну нам пришлось сделать управление памятью.
Дискриптор на куче хранится, почему у нас теки-то?
Повтори, пожалуйста, еще раз.
Никакой поток не сможет повесить ни одного дискриптора, да. Потому что это уже может быть не актуально,
операция могла уже завершиться. Это точка коммита. И на самом деле, ну это вот сейчас, на самом деле,
реклама осеннего курса, потому что вот этот алгоритм, это что по сути? Ну вот я рассказал вам,
все, конец. Ну тут еще есть операция read, потому что когда у нас в яче как дискрипторы, это просто так
читать чеку нельзя уже. Нужно от дискриптов тоже избавляться. Поэтому у нас иногда операция
чтения делает CASN, а под капотом вот эта операция иногда делает, ну короче, ладно. Это все, какая-то
уже машинерия мелкая начинается. Вот двухфазный алгоритм. Сначала вешаем все локи, а потом, ну вешаем
локи, которые можно снять и докатить или откатить. И потом, если повесили все вот такие локи, то можем
выполнить вторую фазу. И вот здесь есть, и с одной стороны, да, вот мы закончили эту историю про локфри канал
и селектор, для которого требовался мультикасс, а с другой стороны, вот совершенно не связан,
например, эта история, но очень в тему. Есть такая распределенная система Bigtable называется. Ее
придумали, написали в Google, начали в 2000-х. Это такое масштабируемое, согласованное киеволью
хранилище. Такое огромное, огромное отображение исключения значения. Автоматически шардируемое,
то есть оно может расширяться по машинам бесконечно, ну да. Представляется себе такую таблицу,
но без особых, без особо сложной функциональности. В частности, это не база данных, потому что в
Bigtable нет транзакций. В Bigtable есть только транзакции однострочные, то есть можно
атомарно посмотреть на поля, на колонки одной строчки, там что-то поменять, но нельзя атомарно
потрогать строчки для разных ключей. Так вот, почему я об этом говорю? Потому что вот этот алгоритм,
это по сути, вот этот алгоритм, это по сути транзакция. Такой ограниченный,
некоторая специальная транзакция. У нас есть n ячеек, и мы сравнили их с ожидаемыми значениями и
перезаписали. Ну транзакции — это более общее явление. Мы хотим просто атомарно посмотреть на какие-то
строчки таблиц на какие-то ячеек памяти и там что-то с ними сделать произвольным образом.
Ну вот в интере пытались сделать аппаратные транзакции, кажется сейчас отказываются от этой
идеи. Это была хорошая идея, вроде бы красивая, простая, но вот почему-то не получилось. Так вот,
в распределённых системах и в распределённых данных частности транзакции — это очень важное
явление. И вот про транзакции поверх Bigtable есть отдельная статья, которую мы осенью разберём,
наверное. И там мотивация такая. Вот мы пишем такой поисковый паук, который обходит интернет,
и он в Bigtable фиксирует, во-первых, документы, ну вот урлы, которые он обходил. Во-вторых,
он для некоторых урлов фиксирует... Ну, у нас есть документы, они адресуются урлам,
и может быть два урла на один тот же документ, и нужно вообще находить дубликаты. Вот мы вычислим
хэш и можем для каждого, для хэша иметь некоторые канонические урлы. Ну, нам не нужны остальные,
грубо говоря. Короче, неважно, забудьте это всё. Мы обходим интернет, и мы хотим на, там,
тысячах, десятках тысяч машин обновлять вот такую большую таблицу, где трогать одновременно
записи, что вот есть такой урл с таким документом, с таким хэшом, и есть и отображение обратное из
хэшей в, там, урлы. Ну, то есть трогать несколько ячеек, несколько строчек гигантские таблицы. Вот.
А, к сожалению, бектейвл, с которым мы работаем, такого API не даёт нам. У него есть только транзакции
на одной строчке. А транзакции на одной строчке — это что-то нечто похожее на касс. И вот мы хотим
выполнить транзакции над разными строчками, имея только транзакции на одной строчке. Причём в
системе транзакций нет, поэтому мы хотим, чтобы делал клиент. А клиент же, он может отказать,
то есть машина, которая делает транзакции, может разломаться. И на что это похоже? Это похоже на
лог-фри. Ну, точнее, не это похоже на лог-фри, а лог-фри — это просто отказоустойчивость,
которую перенесли в shared memory, в компьютер. И вот Google, значит, изобретает протокол, который
выполняет client-site лог-фри транзакции. И вот смотрите, она здесь в комите транзакций,
двухфазный комит. Мы сначала трогаем n ячеек, берём на них локи, потом атомарно трогаем одну из них,
это вот, собственно, вот этот шаг. А потом либо накатываем, либо откатываем. Ну, то есть стираем
локи и пишем значение. Вот одна и та же задача, один и тот же алгоритм, по сути. Но никакой связи
между статями нет. Просто два разных мира. Google, который строит гигантские распределённые системы,
и люди, которые выдумывают странные лог-фри алгоритмы. Но задача одна и та же, поэтому вот люди в
разных местах выдумали одно и то же абсолютно. И вот кому-то касс, такой мульти-касс пригодился
для того, чтобы сделать селект на лог-фри каналах, лог-фри селект на лог-фри каналах, кому-то
пригодился для того, чтобы обходить интернет. Но вот в обоих случаях алгоритм, в общем, довольно
полезный оказался. Хоть и выглядит довольно, ну, таким азотерически. Ну что ж, на этой торжественной,
грустной и радостной ноте мы, наверное, подводим к концу наше занятие, наш семестр. Да. Да, можно.
Да. А результат просто содержимый ячейки А2. Нам не важен результат.
То есть нам не важно, была ли запись. Вообще не важно. Ну потому что вот, смотри, мы пытаемся
повесить дескриптор. Если статус установили, то все операции будут неуспешными. Нужно ли нам
об этом знать прямо сейчас от Амарны? Не особо. Просто если статус установлен уже в дескрипторе,
то ни один RDCSS, то есть ни один CAS, не навесит на ячейку дескриптор. Вот и все. Ну про
ее самой, говорить очень сложно, потому что она не имеет самостоятельного смысла большого. Но давай
еще раз спроси. Вот мы не пытаемся понять, была ли операция успешной. Мы выполняем эту операцию,
и если в А2 была О2, а в А1 была О1, то значение будет перезаписано. И операция вернет то,
что она прочитала из А2. И вот мы только это и используем в мультикасе. Вот такая странная
операция, но вот такой мультикасу достаточно. Мне кажется, в ней ничего такого сложного нет,
она очень прямолинейная и такая странная. Вот рассматривать ее в изоляции сложно,
потому что хочется увидеть, как она работает в общем алгоритме. А там она работает, ну по сути,
как CAS. То есть это такой обычный CAS, как будто бы, который вешает на ячейку с адресом other
дескриптор при условии, что там лежит значение alt сейчас, но только если никакой поток не
дошел до сюда. Вот и все. Вот ее назначение. Не знаю. Не понимаю. Нет, не получилось объяснить?
Как реализован что? Мы повесили, смотри, вот мы находимся в состоянии, вот картинка. Вот мы
в таком состоянии. Это означает, что в ячейке Y было ожидаемое значение. Какое? Смотри здесь,
по ссылке. В ячейке X находится A бы что, и задача complete из этого состояния перейти либо сюда
записать C, либо сюда записать B. То есть либо докатить операцию, либо откатить. Сравнив содержимое
ячейки X с ожидаемым. И вот мы повесили дескриптор. Если повесился, то значит в ячейке Y было
B. А дальше мы спокойно читаем ячейку X, потому что мы знаем, что вот так просто дескриптор не
выбросит. Так просто ячейку Y не поменяют. Мы читаем ячейку X, сравниваем его с A, содержимое
с A. Если совпало, то переключаем Y с дескриптора на C. Если не совпало, то переключаем Y с дескриптора
на B. Вот код. Вот он. У нас есть фаза. То есть мы берем блокировку по сути на ячейку A2,
а потом спокойно смотрим на A1 и принимаем решение. Ну как?
Ну тогда уже тут не будет дескриптора. Мы же докатываем относительно D. То есть мы
пишем N2 в A2, только если там до сих пор был дескриптор, то есть другой поток операцию завершить
не мог в это время. То есть ячейка была замороженная. У нас в дескрипторе есть все операции, есть все
нужное, все необходимое, чтобы операцию завершить, в том числе чужую.
Здесь? Так. Могут поменять, но это неважно. Мы знаем, что был момент, когда в ячейке A2
находилось O2, а в ячейке A1 находился O1. Нам неважно, что нам может поменяться. Нам важно,
что был момент, когда операция могла примениться. Понимаешь? То есть просто был момент и все.
Посмотрели как будто бы атомарно на две ячейки. То есть мы посмотрели не атомарно, мы сначала
посмотрели на A2, потом мы сначала посмотрели на A2, потом посмотрели на A1, а потом, если между
чтением A2 и A1 не было других записей, а мы это поняли вот так вот с помощью этого касса, то мы
переключили A2 в новое значение. То есть вот эта проверка, как будто бы, по сути, проверка
атомарности чтений. Все, один больше не нужно, да. Вот. Ну, эта операция, еще раз повторю, она имеет
довольно странную семантику, не интуитивную, потому что она нужна вот в таком алгоритме.
Сделать касс обычный с дополнительным условием, если вся операция еще не завершена. Чтобы там
у нас какой-то заснувший надолго поток не мог делать первую фазу, когда другие делают вторую фазу.
Или уже сделали вторую фазу. То есть фазы не пересекаются во времени уж точно. Ну, в смысле,
не пересекаются по своим эффектам. Если кто-то делает записи на второй фазе, то на первой
фазе записи быть уже не может. Хватит с нашего мультикасса. Ну, кажется, бонусный уровень был.
Я не рассчитываю, конечно, что кто-то напишет мультикасс в селекции, хотя это было бы впечатляюще.
Было бы крайне впечатляюще. Но если вернуться к каналу, то мне кажется, что канал-то вот
локфри можно написать. Это такое упражнение на очередь Майкла Скотта. Не сильно сложное. Но вот
в самом деле тут псевдокод на страницу, и он довольно… он очень прямолинейный. То есть, в общем,
тут очень простые и ловкие идеи, а всё остальное это просто проверки аккуратные, что мы находимся… мы
понимаем сами, что происходит сейчас. Так что это можно написать, и можно это протестировать,
и можно посмотреть, насколько это сделает ваш… ваши каналы, ваши файберы с хорошим планировщиком
быстрее. Ну всё, спасибо большое, что пришли. Я очень рад, что вы захотели это послушать.
