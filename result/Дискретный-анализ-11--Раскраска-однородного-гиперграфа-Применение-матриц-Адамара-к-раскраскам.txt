Так, значит, начало тут должно быть неопутанным.
Я сейчас еще немножко пооцениваю величину m от n.
Итак, мы в прошлый раз с вами что получили, что
m от n не превосходит 1 плюс омалые от единицы ела-гориф
натуральной двойки на 4n квадрат 2 в степени n?
Ну, конечно, надо еще вспомнить, что такое m от n, товарищи.
Так, что такое m от n? Давайте я все-таки напишу.
Не жалко, m от n это минимальное количество рёбер в однородном гиперграфе.
Так, давайте я буду писать и говорить синхронно все-таки.
Минимальное m такое, что существует однородный гиперграф с c-м рёбрами.
Неважно, сколькими вершинами и хроматическим числом большим двойке.
Вот такая вот величина, которая, как я начал на прошлой лекции говорить,
красной нитью проходила, можно сказать, через все два года нашего с вами
изучения комбинаторики дискретного анализа.
Вот мы установили такую верхнюю оценку.
Она означает, что существует действительно n-однородный гиперграф
с таким количеством рёбер, который нельзя покрасить в два цвета.
С другой стороны, мы сначала просто вспомнили оценку 2 в n-1 степени.
Ну, вспомнили, потому что это фактически обобщение результата первого семестра,
первой лекции, вернее, КТЧ. Кроме того, я это упоминал уже, когда Ловаса доказывал.
В общем, это понятно совсем. Но, кажется, мы сделали еще кое-что.
У нас был такой вот подход, когда здесь получилось c на корень 4 степени из n на 2 в степени n.
Там я рассказывал про случайные нумерации. Были случайные нумерации?
Вот, прекрасно. Сейчас я еще улучшу эту оценку, больше я улучшать ее не буду.
Значит, теорема, которую я сейчас докажу, тоже такая очень методологически содержательная,
как вероятностные методы применяются в комбинаторике.
Придумал это Бек, такой математик венгерского происхождения, в 70-е годы.
Он доказал, что m от n больше либо равняется 1 вторая на корень кубический из n делить на логариф m,
и на 2, наверное, в n-1. Но я так это напишу, потому что мне просто будет удобно так записывать доказательства.
Я, конечно, могу написать 1 четверть корень кубический на 2 в n, но у меня так будет все формулироваться,
оно красиво сократится и будет хорошо. Самый лучший результат, который сейчас известен,
чтобы вы понимали, это все-таки не вот это. Если верхняя оценка не улучшена до сих пор даже в этой
Константе, не на йоту, то вот эта нижняя оценка была улучшена сначала в начале двухтысячных,
и потом передоказана примерно в 2014 году одним из моих таких вот очень способных учеников.
Есть такой Данила Черкашин, он же лось. Прозвище у него такое. Сейчас известно,
что это больше либо равно Константа на корень из n на логариф m на 2 в n. Константу я не помню,
это неважно. А корень удалось сделать квадратный. Ну так, довольно забавно,
корень четвертой степени, корень кубический, корень квадратный. Вот корень квадратный,
это уже рекорд. Сейчас в этой науке есть зазор между нижней оценкой такой вот величины и верхней
оценкой с n квадрат. Ну вот это я доказывать не буду, а Бека сейчас докажу. Это очень красиво
и, по-моему, содержательно. Значит, давайте ведем букву м, которая будет вот так вот прожаться,
х на 2 в n-1. Мы будем рассматривать произвольный гиперграф, у которого столько ребер. У нас есть
какой-то гиперграф h с каким-то множеством вершин, и нам плевать на количество этих вершин. А вот
мощность e у него равняется m. Так, друзья, вы согласны, что если я делаю оценку снизу, то мне
дан гиперграф n-однородный с вот этим количеством ребер, но я пока его вот так обозначу. Конечно,
моя цель получить х равным вот тому, что здесь написано. Но пока я так обозначу, вот я беру
произвольный гиперграф n-однородный с мэриопрами и хочу доказать, что он красится в два цвета.
То есть даже можно вот так написать. Строго больше, что это минимальное число ребер у
контрпримера, а мы говорим, что если ребер столько, то контрпримера точно не будет. Раскраска в два
цвета есть. Пока вроде четко говорю. Не запутал никого? Так, ну давайте брать случайную раскраску.
Но она же, как известно, не сработала. Она дала х равные единице. То есть вот просто случайная
раскраска дает вот этот результат. С х равным единице. Тем не менее, мы сейчас ее запустим,
но только скажем, что это шаг один того алгоритма, алгоритм, который нам в конечном счете даст
действительно нужную оценку. Шаг один. Мы просто случайно покрасим вершины, где случайность
понимается в обычном смысле этого слова. Покрасим В. Ой, какое В. Вот это В. Русское В
начал писать. Все, крыша поехала. Вот здесь начал писать русское В. Покрасим вершины.
Плучайно покрасим вершины в красные и синие цвета. Ну то есть с вероятностью одна вторая,
независимо друг от друга, красим в красный или синий цвет каждую вершину. Это вроде ничего не
дает, кроме х равного единицы. Но мы скажем так. Давайте после того, как осуществлена вот эта вот
случайная покраска в красной и синие цвета, рассмотрим множество вершин,
которые определяются следующим... Это случайное множество, потому что мы же осуществили случайную
раскраску. Вот рассмотрим случайное множество вершин, которое получается так. Мы берем каждое
ребро вот этого гиперграфа, которое вот в этой покраске оказалось одноцветным. И если хотя бы
одна вершина принадлежит хотя бы одному такому ребруту, отправляем ее в Д. То есть фактически
берем просто объединение ребер, которые получились одноцветными в результате шага 1. И вот это
объединение обозначаем буквой D. Но это скверные вершины, которые повредили нам в каком-то смысле.
Мы же хотели покрасить так, чтобы каждое ребро было не одноцветным. Вот мы сюда в кучу свалили все
ребра, которые одноцветны, и хотим что-то с этими вершинами сделать. На шаге два мы будем исправлять
косяки Эрдаша, скажем так. Почему косяки Эрдаша? Потому что обычная вот эта случайная покраска,
которая дает оценку 2 в n-1, это я наверняка говорил, ее еще Эрдаш придумал. Ну вот Эрдаш в 1961 году
предложил просто случайно покрасить, и у него получилась оценка 2 в n-1 степени. Ну естественно,
эта оценка никак не учитывает специфику гиперграфа взаимного расположения ребер. Ничего, мы просто тупо
подряд красим, и все. На гиперграф мы не смотрим. Вот Бек говорит, давайте исправим косяки, которые
допускает топорная раскраска. Как исправим? Возьмем плохое множество вершин, возьмем некую монету,
ну это как обычно, схема Бернули, конечно, будет, но только теперь у нее не одна вторая вероятность
решки, одна вторая вероятность орла, а p это вероятность решки, и соответственно 1 минус p,
вероятность решки, 1 минус p, вероятность орла. Где p? А можно угадать, какое p? По-моему,
нет. Ну сходу можно угадать, какое здесь взять p. Вы знали. Нет, ну LNN, подождите, это вот так?
А, один где? Не-не-не, это неправильно, на самом деле, не переживайся. Ну логарифм там, правда,
есть? Да, логарифм там есть, но всему свое время у вас будет катарсис, когда вы увидите топ p,
который оптимальный, который даст нам в итоге результат Бека. Заранее, конечно, невозможно знать,
во многих вот этих ситуациях мы с этим часто сталкивались. Мы сначала берем какую-то чиселку,
не зная, чему она будет равной, а потом формулируем, как я это обычно называю, компьютерное,
компьютерный результат. То есть подберем такое, при котором существует p, а потом конкретизируем это
p аналитически, разумеется, получая не оптимальный, но близкий к оптимальному результату. То есть вот
эта константа там точно будет неоптимальной. Ну и наплевать, одна-вторая или две-третьих, сейчас
это не так важно. Главный порядок роста функций. То есть пока мы не знаем, что такое p, но дальше мы
его выберем оптимально. Для чего нам это p? Мы сделаем так, мы тупо тоже пройдем по всем вершинам из множества d,
и у каждой из них, независимо от остальных, поменяем цвет с вероятностью p. То есть p это
невероятность красного или синего цвета, а это вероятность смены цвета на противоположные.
Идем по вот этим вершинам из d. Если вершина красная, то она имеет шанс перекраситься в синий, но этот
шанс вероятности p. 1 минус p, это она останется красной, несмотря на попытку, которую сделали с
помощью подбрасывания монетки. Так, можно ничего больше не писать. Понятно, как устроена процедура?
Это вот перекраска осуществляется. Некая попытка исправить косяки Эрдаша. Он совсем тупо действовал,
а тут мы собрали вершины из как-то там взаимодействующих между собой ребер и
попробуем их перекрасить. Все, вот после двух шагов на выходе получается раскраска, больше мы
этот алгоритм никак не запускаем. Два шага всего. Но обычно в науке такие алгоритмы называются
рандомизированными, потому что мы действуем как-то рандомно на каждом шаге. Соответственно они
называются рандомизированными. Есть огромная наука про рандомизированные алгоритмы, но вот это
один из красивых примеров, как такие вещи работают. Так, ну давайте попробуем понять,
о чем мы вообще хотим. Мы хотим доказать, что с положительной вероятностью после этих двух шагов
все ребра будут не одноцветными, правда же? Ну то есть с вероятностью меньше единицы,
наоборот, найдется одноцветное ребро. Вот есть у нас какое-то ребро Е. По какой причине оно
может оказаться одноцветным? Какие вообще ситуации бывают? Как оно может оказаться
одноцветным в результате двух шагов? Абсолютно верно, да. Шикарно, прям вот вообще. Ну ладно,
давайте я сначала не настолько подробно скажу, что пересекалось абсолютно правильно, это вы так
прям забежали вперед. Ну давайте я А с индексом Е обозначу событие, то есть множество раскрасок.
Состоящее в том, что Е, например, красное после первого шага и красное после шага два. Разумеется,
есть симметричное событие, когда Е синее после первого шага и Е синее после шага два.
Но у них одинаковые вероятности, я даже не знаю. Хотите, я вот это назову АЕ1, а АЕ2,
это когда вот здесь красный в обоих случаях заменяется на синий. Соответственно, какую бы
букву Б не хочу использовать, С пока тоже не хочу. Ладно, я напишу, ой, как же писать,
А с волной Е1 и такое же А с волной Е2. Значит, это просто когда все перекрасились, Е красное
после первого шага и целиком синее такой перелет, Е синее после шага два. То есть тут абсолютный
недолет, сколько раз не бросали монетку, ничего не получилось, тут абсолютный перелет, сколько раз
не бросали монетку, слишком получилось, все получилось и оно стало целиком синим. И действительно
есть вот совсем обидное событие ЦЕ, в котором вот Тихон уже сказал, что надо делать, но смысл-то в
чем, что Е было хорошее, оно было не одноцветное, оно было не одноцветное, ну и давайте для
определенности стало красным. Было это, в смысле после шага один было одноцветное, а стало после
шага два целиком красным. Ну и там пусть ЦЕ1, а ЦЕ2, это что оно стало целиком синим, но вероятность
естественно та же самая. То есть вероятность того, что покраска не удалась, что существует
одноцветное ребро, покраска не удалась, не удалось сделать так, чтобы все ребра были не одноцветными,
не больше чем удвоенная сумма по всем Е из Е большого, вероятность АЕ1 плюс вероятность АЕ с волной
1 плюс, да что ж такое, плюс вероятность ЦЕ1, вот так вот. Товарищи, понятно? Не понял, еще раз, значит АЕ1 это
событие, что Е красное после шага с номером 1, Эрдошн окосячил, а Бек не помог ему. То есть сколько раз
Бек не бросал монетку, а она все время ложилась орлом кверху. Соответственно с волной это событие,
что Бек настолько помог, что перестарался, все вершины перекрасились, были все красные, стали все
синие, но все равно плохо. А ЦЕ1, это самое обидное, уже все было на мази да Жердыш не накосячил, а Бек
постарался и испортил. Оно стало целиком красное, но могло стать целиком синим, отсюда умножение на
двойку всегда, что еще раз П это вероятность именно смены цвета, а не какого-то конкретного цвета.
Так, вы чего, сейчас понятно? Ну тут многое понятно. Тут понятно, что вероятность АЕ1 чему равна?
Что красное после шага 1 и красным осталось?
Совершенно верно, да, вот так. В множестве D есть все вершины ребра Е, потому что оно оказалось
одноцветным. По определению в D они все присутствуют. На шаге 1 оно целиком красное с вероятностью 2 в
степени минус N. Оно любое с вероятностью 2 в степени минус N, но в частности оно целиком красное
с такой вероятностью. А это то, что ни разу монетка не легла к верху решка, все N раз она легла орлом.
Важно то, что все N раз мы ее бросали, и каждый раз она ложилась орлом, поэтому надо честно умножать
на 1 минус П в N степени, а вероятность соответственно АЕ1 с волной точно также 2 в минус N,
но на П в N, и все. А вот СЕ действительно сложно считать, и посчитать в точности мы не
сможем. И вот абсолютно верно нам Тихон-то и предложил. Давайте скажем, что раз такое несчастье
случилось, то почему оно случилось? Оно же случилось не потому, что Е своими вершинами целиком
насыпалось вот в это неприятное множество Д. Е же было хорошим после Эрдошевской раскраски,
а случилось это потому, что СЕ пересекалось какое-то другое ребро, которое таки было одноцветным
в Эрдошевской раскраске, на шаге 1. В чем понятно, какого цвета? Какого оно было цвета? Почему изначально
неодноцветное ребро стало целиком красным, потому что оно пересекалось с каким-то ребром, которое было
целиком синим? Понимаете, да? То есть из СЕ1 следует, именно следует, это неравносильность ни в коем случае,
что существует, ну, тут может быть даже в этом месте еще пока равносильность, что существует
F из Е. Такое, что Е пересеченное с F не пусто, и такое, что дальше, можно сказать, выполнено такое
событие B,E,F. Это событие состоит в том, что, я много двоеточий понаписал здесь, запятую лучше, значит,
событие B,E,F состоит в том, что, значит, чего мы знаем? Е неодноцветное на шаге 1, это я повторю,
это ничего нового. Главное, это вот, что F синее целиком, F синее на шаге 1. И еще мы знаем,
что Е пересеченное с F красное на шаге 2. Так, верно, да? Ну, Тихон это предвидел, поэтому я, Тихон,
вот не обращаюсь, в первую очередь, я обращаюсь к остальным. Правильно, да, вот существует,
существует такое ребро, которое Е как-то пересекает, и что с ним выполнено вот это событие,
состоящее из раскрасок, которые вот так вот себя ведут. Так, ну тогда вероятность С,E1,
она же вероятность С,E2, не превосходит суммы по всем F из E, которые не пусто пересекаются с E маленьким,
вероятность из событий B,E,F. Согласны? Давайте оценим B,E,F. Вероятность B,E,F. Вот оно здесь написано,
начиная отсюда. Ну, чего мы можем сказать? F синее на шаге 1, это вероятность легко считается,
но я напишу сразу меньше либо равно, потому что в конечном счете это все-таки будет верхняя
оценка, но первые саммножители, которые я тут буду выписывать, они будут прямо точными значениями,
то есть будет казаться, зачем я нарисовал меньше, когда там можно равно написать. Но вы ждите,
все будет. Значит, конечно, самый первый саммножитель это 2 в минус n-ной степени,
так и надо было написать, ну ладно. 1,2 в n-ной, это то, что F синее на шаге 1. Так, следующий
очевидный саммножитель, тоже дающий просто равенство, казалось бы, что вершины из E пересеченного
с F поменяли свой цвет с синего на красный. E же стало красным, F было синему. А сколько их?
Ну давайте введем обозначение h для мощности пересечения E и F. То есть это будет, соответственно,
P в степени n-h, да? А нет, просто h. P в степени просто h, конечно, но это вот сколько было вершин
пересечения, они все поменяли цвет. Меняли они цвет с вероятностью P, вот получаем P в степени h.
Теперь, вот я все-таки нарисую, вот это ребро E, вот это ребро F, две сардельки, как-то они пересекаются,
вот тут у нас общих вершин h штук. Все услеживают за происходящим, да? Вот, давайте, знаете,
на что посмотрим? Вот на эту часть, на E без F, на E минус F. Вот тут равенства не будет,
потому что ничего не понятно. Тем не менее кое-что можно сказать. Мы же знаем, что E неодноцветная,
вот здесь еще надо добавить, E красная на шаге два. Вот так. Это я забыл сказать, мы тоже знаем,
вот лучше вот в таком порядке. E неодноцветная на шаге один, E красная на шаге два. Ну вот,
в частности, мы вот это учли, но я как-то хочу это учесть вот на этой части тоже. Не запутал? На
пересечении мы это учли вот здесь, здесь все очевидно, это просто P ваше. А я еще как-то хочу вот тот
факт, что E все-таки стало красным на шаге два, учесть вот на этой части E минус F тоже. Знаете,
посмотрим на любую вершину, конкретную вершину, их всего, вот как раз N минус h штук, да? Возьмем любую
вершину. Давайте подумаем, что с ней могло сделаться, чтобы она стала красной в итоге?
В общем, тут много вариантов. Давайте я лучше попроще скажу. Значит, смотрите, либо она была
красной, и тогда на самом деле неизвестно, почему она осталась красной. Понимаете, неизвестно,
почему она осталась красной. Потому что она могла попадать еще в какое-то ребро,
которое целиком красное, и пытаться перекрашиваться, но не суметь этого сделать,
но монетка легла орлом кверху. Она могла не попасть ни в какое целиком красное множество,
вообще не пытаться перекрашиваться, а просто спокойно остаться красной. Вот это один такой
большой содержательный вариант. Она была красной, а дальше черт его знает, что происходило. Другой
более простой вариант. Она была синей, таки поменяла свой цвет. Потому что, если она была
синей, там точно еще какое-то ребро было, которое заставило ее цвет поменять. Я пишу просто формулу
полной вероятности вот такого вот виду. Давайте она была синей, с вероятностью 1 вторая, и поменяла
свой цвет. Либо это исключительная, либо она была красная. Это, естественно, тоже с вероятностью 1
вторая. А дальше мы не понимаем, чего происходит, но вероятность этого точно не больше единицы. Вот
отсюда неравенство, в чем кажется, что довольно грубое, но совершенно непонятно, как вот тут
улучшать. Ну и это все в n-а степени, потому что это верно для каждой отдельной вершины.
Так, вот еще раз поясняю, да, или понятно? Но это формула полной вероятности. Мы условную
вероятность умножаем на вероятность условия. Вернее, наоборот, вот вероятность условия,
вот условная вероятность, вот вероятность условия, а вот условная вероятность. Мы не можем ее посчитать,
потому что понятия не имеем, как устроен агиперграф в этом месте. Мы умрем здесь что-то
конкретизировать. Поэтому мы просто говорим, что любая вероятность, в том числе условная,
не превосходит единице. Вот если она синяя, то она точно стала красной, потому что пыталась
перекраситься, поэтому условная вероятность P. А если она была красной, то условная вероятность
вероятность непонятна, но она уж точно не больше единицы. Так, ну поехали куда-нибудь сюда.
Сейчас у меня, по-моему, совсем иссохла тряпка, но есть еще одна. Ну вот это она можно стирать.
Так-так-так.
Ну давайте я вот это вот перепишу, чему это равно. Ну надо двойку в какую-то общую степень загнать.
В какой степени будет двойка у нас? h-2n, да? h-2n. p будет в h-той степени и 1 плюс p в n-h-той.
Согласны? Но это вроде совсем простая выкладка, лишь бы не перепутать чего. Да, все верно. Я утверждаю,
друзья, можно я это не буду проверять, но уж это просто стыдно. Я утверждаю, что максимум вот
этого значения достигается при h равном единице. Ну просто эта функция монотонно убывающая по h при
фиксированном n. Мы не знаем, чему равно вот этот h. Мы не знаем, как пересекаются лебра e и f. Я беру на
их худший случай. Они точно пересекаются h больше либо равно единицы. Я утверждаю, что на их худший
случай, когда h равно единице, потому что повторяю, эта функция просто монотонно убывающая по h.
То есть вот это все не превосходит 2 в степени 1 минус 2n на p на 1 плюс p в n минус 1. К сожалению,
тоже в этом месте ничего не понятно. Вполне может так случиться, что у гиперграфы просто в сереобро
пересекаются ровно по одной вершине, и тогда h равно единице. Ну согласны, да? Ну если кто-то там в уме
не понимает, как это проверить, разделить просто h плюс первое на h, и все, и посмотреть, что будет.
Вот сюда поставьте h плюс 1 и h, и одно на другое разделите. Будет видно, что стало меньше единицы.
Вот. Ну вот так. Все, а таж избавились. Соответственно, можем писать вот эту всю оценку. Давайте я напишу
меньше либо равно. Очередная звездочка, которая пошла сюда, в тертую часть. Значит, звездочка. Это
что такое? Это 2 на сумму по е из е. Так. Вероятность ae первого, вот она, 2 в минус n на 1 минус p в n.
Дальше 2 в минус n на p в n. А дальше идет сумма по всем f, которые с е не пусто пересекаются.
Вероятности, которые мы только что оценили вот таким выражением. Но от f они же не зависят
теперь эти выражения, правильно? Поэтому сумма, это просто количество таких f умножить вот на эту
величину. Сколько таких f? Да черт их знает, но точно не больше, чем m. Ну просто я возьму и количество
слагаемых вот в этой сумме оценю количеством всех ретр. Буквой м. Я так и пишу. Я же сказал,
они могут все пересекаться попарно по одной вершине, и тогда это никакое неогрубление. На 1 минус вот так,
2 в степени 1 минус 2n, p1 плюс p в n минус 1. И скобка закрывается. Сейчас вы увидите, в чем был,
так сказать, гениальный чисто эстетический замысел того, чтобы писать м в таком виде. Ну может,
все уже видят, я не знаю, или кто-то видит. Ну а что происходит? Видите, тут где-нибудь зависимость
от e. Нету ее. Опять говорим, что в этом суммировании просто мы слагаемых. То есть мы получаем вот так,
еще эту двойку заносим. Смотрите, 2 на 2 в минус n. Это же 2 в 1 минус n. Потом 1 минус p в n. Ну и на m.
Потом 2 в 1 минус n на p в n на m. А тут будет m квадрат 2 в степени 2 минус 2n. Снова вот эту двойку
умножили на эту двойку. Получилось 2 минус 2n, p на 1 плюс p в n минус 1 степени. Так, вроде все собрал.
И нигде не запутался, да? Есть вопросы? Ну, видите, какая красота. m это x на 2 в n минус 1. Смотрите,
m это x на 2 в n минус 1. То есть мы делаем так, чпок-чпок, и тут появляется x. Тут делаем чпок-чпок,
и тоже появляется x. Но главное, что мы и тут делаем чпок-чпок, и появляется x квадрат. Видите,
как красиво. Ой, все пропали. Мы так специально записали mesh, чтобы все сократилось, остались
только x. В итоге у нас получается такое выражение x на 1 минус p в n, плюс x на p в n и плюс x квадрат
на p и на 1 плюс p в n минус 1. Так, это оценка сверху для вероятности того, что покраска не
удалась. То есть существует одноцветное ребро. Ну, то есть какая компьютерная теорема здесь
получается? Скажем так, теорема штрих это всегда называлась. Утверждение такое, что пусть для данного
n, которое вам поступило на вход, для данного n число x таково, что найдется p, с которым
p естественно из отрезка 0 и 1, потому что это вероятность решки. Найдется p из отрезка 0 и 1,
с которым вот вся эта хреновина, я так напишу, меньше единицы, с которым вся вот эта хреновина
меньше единицы. Тогда m от n больше, чем x на 2 в n минус 1. Ну и вы бежите в цикле по x,
выискиваете самое большое x, при котором все еще такое p существует. То есть чисто вот компьютерное
решение такое. Вам дано там, я не знаю, m от 5. Мы говорили про m от 5 в прошлый раз? Что там с 17 до
26 поднимается. Вот на самом деле забавно, что асимпатически здесь лучший результат. Для m от 5 он хуже.
Больше того, первые значения n, при которых наша вот эта теорема начинает давать результаты
лучшие, чем случайная нумерация из прошлой лекции, порядка 85 тысяч. Корень кубический больше,
чем корень четвертой степени. Ну вот так вот. Ну от n делить налог, потом там константа одна,
вторая, другая. В общем, ну вот так. То есть с практической точки зрения это, ну конечно,
не супер, а идентина вот так. Ну все, осталось проверить, что в качестве x можно взять действительно
одну вторую на корень кубический из n на лог n. Правильно? Что двигаясь вот в этом цикле до вот
такой итерации, вы точно дойдете. Но только надо сказать, при каком p получится. Справедливым вот
это неравенство. Ну вот это у нас была уже, тут какая-то гипотеза, она даже до сих пор видна,
она неправильная, но логарифм там есть. Она выглядит гораздо более круто, и результат получается
очень забавно. Нет, ну никакого тут, конечно, нету, как бы это сказать, колдовства, что ли. То есть
это вполне стандартные оптимизационные соображения дают, но тем не менее выглядит,
конечно, впечатляюще. Сейчас я сотру и поясню. Так, это мы торжественно
придаем забвению и пишем, чтобы вот такое x вместе с каким-то p дало меньше единицы,
надо в качестве p взять вот такую функцию. 1 на треть логарифм от n деленного на логарифм n,
и все это поделить на... Значит, впечатляет здесь даже не наличие логарифмов, а то,
что вот под этим логарифмом стоит такая тонкая вещь. Но вы понимаете, логарифм от дроби,
в которой написано n поделить на логарифм n, это же разность логарифм n и повторного логарифм n.
Тем не менее это важно. Ну давайте сейчас пять минут перерыв, потом я подставлю,
вы увидите, как оно все чпок-чпок-чпок и сойдется. Так, ну чего, давайте подставим.
Ничего особенного в выглотке нет, но симпатично получается. Итак, смотрите,
x это одна вторая, n на логарифм n в степени одна треть. Это я переписываю вот это выражение,
которое должно оказаться меньше единицы. Давайте я даже сразу напишу, что оно меньше. Вот это вот
выражение. Оно меньше либо равно чего? Ну мы же с вами знаем, что e в степени минус pn,
ой да, что e в степени минус pn оценивает такую штуку. 1 минус p в н и не больше, чем e в степени
минус pn. 100 раз проходили, вот я это и напишу. На e в степени минус p. Дальше у нас идет тот же
самый x, то есть одна вторая, n на логарифм n в степени одна треть. Ну на p в н, давайте я в этом
месте p грубо оценю, я напишу, ну давайте напишу одна треть, ну как грубо, ну вот так напишу,
например. Плевать, что тут под логарифмом стоит, это важно для подстановки под экспоненту, а внизу
это неважно. Так, ну и плюс там x квадрат, это одна четверть, n на логарифм n в степени две третьих,
и 1 плюс p в n минус первой оценю как e в степени pn. Ну можно e в степени p на n минус 1, но я,
не важно, 1 плюс p в степени там какой-то меньше, чем e в степени p на эту степень. Так, ну главное
теперь сюда p подставить вот это. Под экспоненты важно, что логарифм берется от n делить на
логарифм n, что у нас получается вот так, что это равно 1 вторая n, что? Где, вот здесь нет, здесь у
нас 1 плюс p в n и поэтому e в степени pn. Логарифм от 1 плюс p не больше чем p, логарифм от 1 минус p не
больше чем минус p. За счет x квадрата, естественно. Вот x квадрат. Что опять не так?
А, p я потерял, конечно. Я ж на p не умножил, спасибо. Да, вот я забыл вот здесь умножить на p,
за счет этого. Да, забыл умножить на p, конечно. Тут еще одна треть. Ну и p тоже оцениваем как бы
грубо, логарифм n поделить на n. Да, потому что вот здесь первая степень перевернутой дроби,
а тут она только две третьих и тут сейчас будет одна треть как раз. Они прям друг друга скушают под
завязку. Так, e в степени минус pn, ну давайте я здесь честно напишу, это будет минус одна треть,
логарифм вот от этой дроби n делить на логарифм n. Дальше здесь будет, ну давайте меньше либо равно,
меньше либо равно. Смотрим сюда на второе слагаемое, но вообще очевидно, что логарифм,
поделенный на 3n, да еще в n степени, это какая-то фигня. Но это очень быстро убывающая к нулю функция.
Можно, конечно, попробовать прямо там подставлять какие-нибудь конкретные n и посмотреть,
что будет получаться. Ну скажем взять и подставить вместо n какое-нибудь число, для которого мы
м от n не знаем, ну 4, м от 3 мы знаем, это упражнение. Вот если мы подставим сюда 4, что будет? Ну я не знаю,
что будет, не считал никогда, но мало будет. Тут будет одна двенадцатая от логарифма четырех,
да. Господи, два логарифма двух, это меньше чем полтора, полтора поделить на двенадцать,
это что-то такое? Полтора поделить на двенадцать, одна восьмая? Ну хорошо, пусть будет одна восьмая,
одна восьмая в четвертой степени, но понимаете, да? Даже если мы на это умножим. В общем, я напишу
здесь какую-нибудь одну, не знаю, двадцатую, мне ее точно хватит, но это при каждом n верно, конечно.
Ну можно одну десятую, мне кажется, ее тоже хватит. В общем, вот эта штука, она при всех n,
которые нам интересны, оценивается чем-то очень маленьким. Одну двадцатую написал на обум лазаря,
одну десятую, можно одну тридцатую, сотую даже. Это не очень интересно, а вот это вот интереснее.
Тут одна двенадцатая, но тоже это с запасом, конечно. Дальше n на логарифм n в степени две третих,
и тут e в степени одна треть логарифм от n делить на логарифм n. И еще на логарифм n деленный на n,
который я был потерял, но теперь он нашелся. Ну вот, смотрите, какая красота. Что такое e в степени
вот этот логарифм? Это то, что стоит под знаком логарифма. e в степени вот этот логарифм,
это n поделить на логарифм, да? Но поскольку со знаком минус, то это логарифм n поделить на n.
То есть вот это все, это логарифм n поделить на n, и еще в степени одна треть, вот эту одну треть надо учесть.
Чпок, чпок, видите как? И не было как будто бы, как не бывало. И здесь та же самая история,
e в степени вот этот логарифм, это n поделить на логарифм n, и еще в степени одна треть.
Это на это перевернутое вот это. Чпок, чпок, чпок. Ну осталось там какая-то одна вторая,
одна двадцатая и одна двенадцатая. Это, конечно, меньше единицы. Все получилось.
Хорошо? Вот все. Это то, что касается m от n. Как бы я считаю, что теперь эта тема,
которая красной нитью-то проходила, она закрыта. То есть мы все про m от n поняли. Не 15 множеств,
там каких-то пяти элементных из 30, а вот произвольное n нам дано, не обязательно пятерки,
и получается вот такие вот результаты. Но это не все, что мы изучали, красная нить на этом не
обрывается. Там еще было уклонение, задача об уклонении, которая решалась, ну я сейчас напомню,
в чем она состоит, решалась она с помощью матрицы Адамара, но решалась не целиком. А именно,
давайте все-таки напомню, что это такое. Тоже есть гиперграф. Там он не обязательно даже
однородный, но тоже мы его красим в два цвета, красный и синий. И не просто хотим добиться того,
чтобы каждое ребро было не одноцветным, а еще пытаемся так сбалансировать эту раскраску,
чтобы в каждом ребре по возможности красных и синих вершин было поровну. Это наша идеальная мечта
добиться не просто того, чтобы каждое ребро было не одноцветным, а чтобы там не сильно различались
количество красных и синих вершин. И вот матрица Адамара, она как раз послужила примером того,
что бывают все-таки непреодолимые препятствия к тому, чтобы получить совсем хорошую в этом
смысле раскраску. Сейчас я напомню то утверждение, которое нам давала матрица Адамара.
Ну ладно, пока больше не буду. Значит, матрица Адамара нам дала такую теорему.
Ну не было такого слова гиперграф тогда, но фактически речь шла про гиперграф. Я надеюсь,
что вы уже понимаете, как одно с другим сочетать. Пусть h это гиперграф,
не обязательно он однородный, у которого мощность v равняется n и мощность e тоже равняется n.
А я думаю, что я не очень хорошо, потому что я же не для любого гиперграфа это хочу.
Давайте я лучше так скажу, чтобы это получше звучало. Давайте пока это будет не теорема,
а вот так вот. Пусть h это гиперграф, у которого количество вершин и количество рёбер совпадает,
размер ребра при этом никак не оговаривается. Это не обязательно однородный гиперграф,
не путайтесь, у него именно число вершин n и число рёбер n. Так вот, теорема говорит следующее,
что если n это порядок матрицы Адамара, ну мы конечно верим, что любой n делящийся на 4 является
порядком матрицы Адамара, но мы же не знаем, поэтому мы формулируем в таком условном ключе.
Доказательства-то нет. Вот если n это все-таки доказанный порядок матрицы Адамара, точно известно,
что такая матрица Адамара существует, то существует вот такой гиперграф, ну он легко строится по
матрице Адамара, такой гиперграф с одинаковым количеством вершин и рёбер, что при любой его
раскраске, то есть при любой раскраске его вершин, при любой раскраске v в красный и синий цвета,
найдется ребро из E, ну то есть ребро этого гиперграфа, в котором разность числа красных и числа синих вершин
и числа синих вершин больше либо равна корень из n пополам. Вот такую теорему мы доказывали
в позапрошлом семестре. Вспоминаете, да? Если порядок матрицы доказан, если n является порядком
матрицы Адамара, то можно построить гиперграф с таким числом рёбер и вершин равным n, он легко очень
строится по матрице, мы просто берем строчку вот эту из нулей единиц и ребро, это номера позиций,
на которых стоят единицы. Ну грубо говоря, там вот матрица Адамара в нормальной форме, добавляем
к ней матрицу из сплошных единиц и делим пополам. Вот то, что получается, берем по строчкам и это будут
рёбра. Я просто напоминаю, как строился гиперграф в этой теореме, чтобы вам как-то немножко вспомнить,
но это не нужно для сегодняшней лекции, это нужно просто, чтобы вы немножко вспомнили. Формально,
для сегодняшней лекции не важно, как строился гиперграф в этой теореме. Значит, сейчас я, давайте,
это я словами написал смысл происходящего, разное числа, красных и числа, ну по модулю,
наверное, не меньше, чем корень и zen пополам, потому что я не знаю, каких там больше красных
или синих, по модулю не меньше, чем корень и zen пополам. Ну модуль разности. Ну это не важно,
потому что это было во втором семестре, если вы почему-либо во втором семестре этого не слышали,
а вас не было во втором семестре, да, это не страшно, потому что нам для сегодняшней лекции это
вообще не важно, это я напоминаю людям, которые это слушали. Ну давайте я скажу, это очень интересный
объект, можете посмотреть записи ОКТЧ, это очень красивая тема. Значит, матрица Адамара это матрица
из плюс-минус единиц, размера n умножить на n, у которой в каждой две строчки артагональна.
Такой вот замечательный объект, у него есть следствие вот для этой задачи, для кодирования,
там есть точные границы, некая граница плотки надостигается, в общем, можете посмотреть записи
лекции, там это тема есть, но для сегодняшней лекции знание того, что такое матрица Адамара,
не принципиально, просто хотел людям напомнить. Вот, я на самом деле сегодня, ну или может быть в
начале следующей лекции хочу доказать, что эта оценка почти не улучшает, но сейчас я докажу более
простой результат. Только для того, чтобы доказать, давайте я немножко формулизую вот это вот гуманитарно
описанная формулировка, а не гуманитарно сейчас формулизую. Ну что такое число красных вершин,
как это математически сформулировать, если не писать словами. Можно считать, что красный цвет
это присвоение плюс единицы вершине, а синий цвет это присвоение минус единицы, то есть можно
считать, что раскраска в красные и синие цвета это просто такой вот вектор из плюс-минус единиц,
который мы образуем в зависимости от множества вершин. И тогда давайте так, вот пусть ребра скажем
М1 и так далее М, ну даже в общем случае с индексом М, просто здесь М равно Н. Вот в этой формулировке
количество ребер такое же, как количество вершин, но в общем случае ребер может быть сколько угодно,
может быть Н, а может быть и Н. Так вот, мы просто можем сказать, что хи от митого по
определению это сумма по жи, принадлежащим митому хи от жи. Я точно помню, что я каждый раз в наукотече
оправдываюсь, что у меня буквой хи, обозначенный цвет вершины и цвет множества, но как бы функция
определена на разного типа объектах. Есть цвет, который плюс или минус единицы, а есть сумма вот этих
плюс-минус единиц, которая отвечает как раз за разность числа красных и числа синих вершин. Вот
эта хи от митого, это и есть разность, написанная тут. Вот эта хи от митого, это разность числа красных
вершин и числа синих вершин в ребре МИТ. То есть в этих терминах теорема утверждает, что существует
х такой, что для любой раскраски найдется и такое, что хи от митого по модулю больше либо равняется
Вот так вот, если вы убрать все слова, вот теорема так формулируется. Согласны? Это вот теорема из
окоточе. Вот это вот, это она прямо в точности, в таких вот обозначениях. Несложная теорема, которую
я сейчас докажу, она не говорит, что это вот оценка, полученная наукотече, не улучшаема. Она говорит,
что она не сильно улучшаема, если улучшаема. Она говорит так, что для любого h равного ve такого,
что мощность v равняется n, а мощность e равняется m. Неважно, какое может быть и ни-не, какое-то другое.
Так, сейчас, сейчас, сейчас. Существует такая раскраска, что для любого и модуль хи от митого
не превосходит. Вот сейчас я, конечно, перепутаю что-нибудь, но я вот так напишу с запасом. Вот так.
Вот такой величины. Так, вы понимаете, что формулировка, как здесь она дана, это просто отрицание утверждения,
написанного сверху и соответствующего вот этому результату. То есть, не существует гиперграф,
который невозможно слишком равномерно покрасить. А любой гиперграф можно достаточно равномерно
покрасить. Понятно, говорю, нет? На самом деле, любой гиперграф можно достаточно равномерно
покрасить в том смысле, что уклонение числа красных от числа синих вершин на каждом ребре
будет точно не превосходить вот такой величины. Но сейчас мы посмотрим, может где-то двойка лишняя,
а может нигде и не лишняя. Сейчас мы напишем простое доказательство. Что странно? Ещё раз? Почему все?
Нет, нет, m не равно n-1 пополам. m это просто обозначение для количества ребр. А когда оно было равно n-1?
Нет, давайте так. Если m равно n, она отличается от нашей оценки прошлого года всего лишь в корень из
логарифа n раз. Ну так это ерунда. У нас всего n вершин, понимаете? Поэтому корень из n, даже корень из n
log n, эта величина сильно маленькая по сравнению с числом вершин. И если, например, наши ребра все-таки
одинаковые мощности, как, кстати, в случае с вот этим вот гиперграфом, они же почти все одинаковые
мощности. Все строчки, кроме первой, состоят из половины нулей, половины единиц по построению.
Поэтому если у нас, например, все ребра мощности n пополам, то получается, что раскраска отклоняется
от идеальной на величину сильно маленькую по сравнению с мощностью каждого ребра. Если мощность
каждого ребра n пополам, а уклонение корень из n log n, ну это не так плохо. То есть фактически сравнивать
надо именно как бы предполагая, что все ребра имеют мощность сопоставимую с n. Тогда результат
наиболее впечатляющий. Вот эта вот матрица Адамара показывает, что нельзя сделать слишком хорошим
уклонение. Бывает вот такая ситуация, когда хоть на каком-то ребре при любой раскраске хоть на
каком-то ребре да уклонится. Но при этом, наоборот, мы всегда можем так покрасить и вот этот гиперграф и
любой другой, чтобы уклонение точно не превосходило вот этой величины. Сейчас понятно, почему это круто?
Или я плохо объяснил? Если n вершин, то ребра, ну они же будут не одноэлементными, наверное, n пополам
элементными, вот как здесь, или еще какими-то, n на три элементными, я не знаю. Но если у вас всего n на три
вершины в ребре и количество красных вершин в нем отличается от количества синих всего лишь на
корень zn log n, это, наверное, очень неплохо. Но сильно улучшить это нельзя, о чем свидетельствует теорема
прошлого года. Значит, доказательства. Ну что, фиксируем гиперграф, фиксируем h и пытаемся его
покрасить. Красим, естественно, случайным образом. В чем тривиально, просто присваивая каждый цвет
с вероятностью одна-вторая. Тривиальным, случайным образом. С вероятностью одна-вторая,
каждую вершину, независимо от остальных, красим в красный или синий цвет. Так, но чего? Вероятность того,
что модуль hi от mit больше, ну давайте какое-нибудь а для начала напишем, но, конечно, в качестве а мы
возьмем в итоге вот эту величину. Это просто по определению вероятность того, что сумма пожи из
митого хиаджи больше чем а. Теперь что такое хиаджи? Хиаджи, давайте я явно напишу, чтобы было
совсем понятно, это плюс один с вероятностью одна-вторая и минус один с вероятностью одна-вторая. И вот
мы складываем некоторое количество вот таких независимых штуковин. Ну а какое количество? Сколько
есть вершин в множестве а мытое? Это же пьяница, помните? Который гуляет у кабака. Помните,
случайное блуждание? Это оно в точности. Пьяница делает столько шагов, сколько есть вершин в ребре
а мытое. И просто мы спрашиваем, как обычно, а с какой вероятностью он уклонится от своего
кабака больше чем на а. Помните оценку? Мы ее доказывали, но это был прошлый семестр, но это было точно,
можете найти. Вот это, конечно, вот так два на е в степени минус два, нет, минус, почему два,
минус а квадрат поделить на два мощности а мытое. Вот так, строго говоря, вот так. Но мощности а мытое
это сколько шагов сделал пьяница, поэтому здесь не n, не m, а именно мощность а мытое.
Ну я не думаю, что надо напоминать тот результат прям, но это прям в точности он. Так, мощность а мытое
точно не больше чем n, правильно? Ну у нас n вершин всего, мощность а мытое, конечно, не больше чем n
вершин. Причем знаете как, вот у одного она еще может совпадать с ценой, а у всех остальных будет
строго меньше, поэтому я давайте напишу меньше либо равно, а на самом деле в скобках меньше,
но для почти всех, кроме быть может одного. Почему меньше либо равно? Потому что здесь он в знаменателе
стоит, оценивается сверху, переворачиваем, получаем оценку снизу и снова берем минус,
оценка сохраняется в эту сторону. Значит у нас получается 2 на e в степени минус,
дать a в квадрат возведем, все, я подставляю a, логарифм 2m, вот так, это я в квадрат
возвел и делю на 2n, потому что я мытое оценил величиной n. Чпок, чпок, получаем, чего получаем?
Получаем 2 поделить на 2m, это 1mt, ну все товарищи, вероятность того, что существует такое и,
что модуль хи от м и т больше чем а, меньше, строго, чем м поделить на м. Ишек у нас,
м штук, вот, ишек у нас этих, м штук, ребер, м штук, я тупо оцениваю вероятность объединения
суммы вероятностей, при этом почти все вероятности, входящие в сумму, строго меньше, чем 1mt,
поэтому и вся сумма строго меньше, чем м поделить на м, то есть 1. Ура, да, потому что с положительной
вероятностью выполнено отрицание для любого и хи от м и т, меньше либо равняется а, что и утверждалось,
нет, я даже тут не ошибся, тут не запутался. 2m и 2m, все, все поделал. Я боялся, что 2 какая-то
где-то лишняя, но нет, все поделал. Очень простая теорема, как видите, но она использует вот это
сильная, сильную оценку уклонения, то есть Чебышов тут никак не прокатит, как я когда-то объяснял.
Так, ну чего, у нас нет, конечно, времени доказать лучший результат, но сформулировать я его,
конечно, сформулирую. Значит, смотрите, теорема новая, теорема, ну теорема и теорема, она вот так
вот меняется. Ой, что я сделал, я м превратил в н, ну прям вот как здесь, да, вот как в теореме с матрицами
одомора. Вот я утверждаю, что для любого гиперграфа, у которого вершин и ребер одинаковое
количество, найдется раскраска такая, что в любом ребре, в каждом ребре уклонение будет не больше,
но здесь надо стереть, чем ну давайте 20 корней из н. Ну сейчас лучшее, что известно, это вроде 5
корней из н или типа того, ну 20 корней из н с запасом получится. Кое-что я, конечно, успею, но я это не
докажу. Смотрите, результат про матрица одомора из второго семестра, это утверждение о том, что
оценку, которую мы сейчас докажем, невозможно улучшить более чем в 40 раз, ну то есть чем в
константу раз. То есть и этот результат, по сути, не улучшаемый, и годовой давности результат тоже,
по сути, не улучшаем. Вот, ну я успею только ввести понятие энтропии и, наверное, доказать нужное мне
неравенство, которое будет использоваться при решении вот этой задачи, при доказательстве теоремы.
Такая вот интересная деятельность. В следующий раз мы точно завершим, сегодня успеем только энтропию.
Я вообще этот термин упоминал в начале года, когда мы с вами делали вот такие вот оценки,
помните? Было такое? Да-да-да, но это вот так. Получалось один поделить на альфа в степени альфа,
один минус альфа в степени один минус альфа, плюс о малой от единицы в н-й, ну или по-другому,
это можно вот так написать. Два в степени минус альфа лог двоичная альфа, минус один минус альфа
лог двоичная, один минус альфа, ну тут где-то надо еще малой от единицы добавить, наверное, и все это в н-ую степень возвести.
Вот эта штука, вот эта штука, это частный случай энтропии, вот так можно обозначить.
Но это я просто напоминаю, что у нас такое тоже было. Как бы сейчас я дам чуть-чуть другое определение,
ну, фактически в частном случае совпадающее с тем, что здесь написано. И, кстати, вот это воспоминание
будет полезно на следующей лекции. Это тоже свою роль сыграть. Значит, слушайте, у нас есть какая-то
случайная величина, которая, неважно на каком там пространстве Омега, принимает некоторые значения,
скажем, из множества s. Ну, s под множество r. И тогда мы ее энтропию, обозначаемую тоже естественно r,
определим вот так. Это будет минус сумма по всем s маленькое из s большое. Так, вероятностей того,
что x равняется s на логарифм двоичный, ну, можно брать и натуральный, но вот как принт двоичный,
на логарифм двоичный вероятности того, что x равняется s. Это называется энтропия. Ну,
действительно, если случайная величина принимает всего два значения, одно с вероятностью альфы,
другое, соответственно, с вероятностью 1 минус альфа, то то, что я здесь написал,
это как раз энтропия такой случайной величины. Согласны? Вот. Такое определение, чтобы это не
значило, вот такое определение энтропии. Можно дать определение не только для одной случайной
величины, но и для случайного вектора. Например, если у вас есть две случайных величины, образующих
такой двумерный случайный вектор, ну, тогда энтропия это будет минус сумма по s из s, по t из t
вероятностей того, что x равняется s, у равняется t на лог двоичной той же самой совместной вероятности.
Разумеется, дорогие товарищи, вы понимаете, что я говорю только о ситуациях, когда случайные
величины принимают конечное множество значений. То есть я предполагаю, что вот эта s имеет мощность
меньше бесконечности, никаких, конечно, абсолютно непрерывных случайных величин тут нет и в помине,
иначе какие были бы вероятности конкретных их значений. Ну, наверное, можно эту всю теорию построить
для бесконечных, но я даже не хочу думать об этом. Давайте пусть будет все конечное, неважно. Вот.
Единственное свойство энтропии, которое нам потребуется, это ее вот такое свойство h от x и y не больше,
чем h от x плюс h от y. Я попробую успеть сейчас это доказать, но, возможно, это кончится таким же
фиаско, как сегодняшнего КТЧ. Я хотел посчитать сумму Гауса, но после путаницы,
которая была перед ней, большинство народу грустно взглянуло и сказал, давайте начнем с нее следующую лекцию.
Так что тут может тоже так же получиться. Ну, такой красивый ход. Давайте вот так напишем h от x
плюс h от y минус h от x и y. Я утверждаю, что это, конечно, равняется сумма по s маленькому из s большого,
сумма по t из t большого. Вот так будет p, x равняется s, y равняется t. Лог двоичный от дроби
p от x равняется s, y равняется t. На p от x равняется s умножить на p от y равняется t. Ни в коем случае.
Вот я хотел сказать, но вы меня опередили. Может быть и независимая, но если независимая,
тогда это логарифм единицы, это неинтересно. Это верно всегда. То есть я не предполагаю,
что x и y независимы. Если они независимы, там все очевидно. Вот интересно, что это верно всегда.
Так, откуда следует такая прекрасная формула, которую я сейчас написал? Можете это в уме осознать?
Нет? Ну, смотрите, вот если мы вот этот логарифм оставляем только от числителя, но вы согласны,
что это и есть h от x и y со знаком минус? Вот тут написано, что такое h от x и y. Если его взять
со знаком минус, то получится ровно то, что написано. А вот то, что находится в знаменателе,
это действительно два выражения со знаком минус. Я утверждаю, что одно из них это h от x,
другое h от y. Почему? Потому что в одном случае мы на вероятность пишем логарифм двоичный
от вероятности того, что x равно s. А никакого t нет. Сумма по t дает просто вероятность того,
что x равно s. Ну вот так. Давайте я напишу. Сумма по s маленькая из s большая, сумма по t маленькая
из t большая. p от x равно s, y равно t на лог двоичный вероятности того, что x равно s. Это все равно,
что вы независящие от y, от вот этого t, выносите вот сюда, потом суммируете по t вот эту вероятность
при фиксированном s и вы просто получаете вероятность того, что x равно s. Формула полной вероятности.
Да нет. Причем здесь условно? Ну можно писать условно. Это вероятность пересечения здесь написано.
Нет, формула полной вероятности это когда вы что-то фиксируете и по всем возможным исходам
другого суммируете, перебираете случаи. Вот у вас есть событие x равно s и вы его пересекаете с
событиями y равняется t, по всем возможным t. Когда вы складываете по всем возможным t вы просто
получаете вероятность того, что x равно s. Из этого следует та формула полной вероятности,
которую вы помните, но потому что вероятность пересечения это условная вероятность умножить на
вероятность условия. Сейчас я понятно объяснил или нет? Запятая это пересечение, конечно. Запятая всегда
означает, что мы пересекаем события, это и да. Ну и здесь конечно запятая это и. Что вектор принимает
вот именно такое значение, что одновременно x равно s и y равно t. Сейчас плохо объяснил или понятно?
Ну что начинать в следующий раз с этого что ли? Я могу, но потому что осталось две-три минуты я
видимо уже не успею. Я не пойму почему вот это вызывает сложности, это ну реально. Формула полной
вероятности она вот так пишется. Вот у нас омега разбита на какие-то события b1 и так далее bn. Есть
еще какое-то событие, которое a. Вероятность a это просто сумма по всем i от единицы до n. Вероятность a
пересеченного с b i. Потом уже мы говорим, что это вероятность пересечения это на самом деле
условная вероятность умножить на вероятность условия. Но в принципе это-то самый базовый вариант
формулы полной вероятности без всякого условия. Это-то верно? Вот ровно это здесь сейчас написано,
что a это вот это событие, что x равно s и мы его пересекаем просто со всеми y равняется t. То есть
с разбиением исходного омега по слоям, по вот этим уровням, какие значения принимает y. Да,
конечно-конечно. Но мне хочется, чтобы было понятно. Я очень всегда стараюсь добиться не
только катарсис, но чтобы не кокснуло, чтобы действительно было понятно, что происходит. Могу
я стирать эти пояснения? Так, теперь смотрите, вот это-то как раз просто, а сейчас будет хитрый ход.
Давайте, не, ну хитрость, конечно, такая, знаете, смешная, но все равно. Давайте вот эту штуковину,
вот эту всю обозначим z с индексом s и t. Ну, она зависит от s, от t, вот так обозначим. Я сейчас
вот так это напишу. Что-то равно сумма по s маленькая, сумма по t маленькая, ну понятно,
в каких пределах. Значит, вероятность того, что x равняется s, одновременно y равняется t,
так zs t лог двоичный zs t, но правда ли это? Это неправда, конечно, да ведь? Потому что реально
здесь стоит вот эта вероятность, вот она же, лог двоичный zs t здесь тоже стоит, а я еще втемяшил
сюда zs t. Я добавил сюда множитель, которого здесь нету. Но что надо сделать, чтобы он пропал?
Не, ну в степень возвести это сильно, просто умножить, поделить на него же. Давайте поделим
просто на него же. Давайте, да, поделим вот это на него же, вот это вот поделим. Очень гениальный
ход. Пока это фигня все, то что я делаю, сейчас вы увидите в чем гениальность. Что такое вот эта
вероятность поделить на вот эту дробь? Смотрите, какое счастье, тут вот кое-что сокращается. Вам не
кажется, что то, что вот тут написано, это на самом деле вероятность того, что x равно s, умножить на
вероятность того, что y равно t? Ну кажется, наверное, да, переверните. Самую малость, нет? Да видно,
конечно, я тоже, я смотрю, я уже не знаю, что там видно, что не видно. Так, ну хорошо, смотрите,
какой гениальный ход, гениальный ход. Смотрите, функция z, лог двоичный z. Знаете, какая функция?
Давайте ее обозначим f от z. Какая она? А еще какая? Выпуклая. Это выпуклая функция,
значения которой сейчас складываются с коэффициентами, сумма которых равна единице. Вот эти чиселки,
когда вы просуммируете их по всем s и t, они же в сумме дадут единицу, и вы складываете значение
выпуклой функции с весами, сумма которых равна единице. Ну что нам говорит неравенство выпуклости?
Оно говорит, что это больше либо равно, куда бы это написать, больше либо равно, вот сюда пошло,
больше либо равно, нежели f от сумма по s, сумма по t. Так, а здесь у нас чего? Вероятность x равна,
ну сейчас я заканчиваю, x равняется s, у равняется t, умножить на zst. Вот так. Сумма с весами
значений f от zst не меньше, чем f от суммы, в которую подставили zst, потому что f выпуклая. Не знаете
такого неравенства? Ну подумайте над ним, это можно, конечно, обсудить, но это вроде
стандартное неравенство выпуклости. Ну а теперь смотрите, zst, вот же оно, у нас опять вот этот
знаменатель с этой штукой. Ой, как так вышло? Где я ошибся? Где переписал неправильно?
Я вот не то переписал, вот же надо, обязательно надо было все-таки хоть в конце, но ошибиться. Да-да-да,
переписал неправильно. Конечно, наше произведение вероятности, тогда действительно умножение на
zst, вот это произведение кокает. Видите, да? zst, умножаем на это произведение знаменатель вот с
этим произведением, сокращается. У нас вот тут остается вероятность того, что x равно s и
одновременно y равно t. Мы опять же суммируем это по всем возможным s и t, неважно, суммируем мы
произведение вероятности или вероятность совместную, но получаем же мы единицу, то есть получается f от
единицы, а знаете, что такое f от единицы? Но это вы знаете, это ноль. Какой логарифм пропал?
Не-не-не, смотрите еще раз, я обозначил функцию z log2z как f от z, и я сказал, что неравенство
звучит так, сумма по s, сумма по t, вот эта вот штуковина, умножить на f от zst, больше либо
равняется, чем f от суммы, сумма то же самое на zst. Взвешенная сумма значений не меньше, чем f от
взвешенной суммы, примененной к аргументу. Это выпукло? Получился ноль, то есть у нас вот это вот
выражение, стоящее слева, не меньше, чем ноль, но это ровно то, что мы утверждали, вот вот эта разность
туда перекинули не меньше, чем ноль. Ну так вот, да, вот концовка красивая. Ладно, все.
