Ну вроде бы уже время начинать. Давайте начнем. Я напомню, что в прошлый раз я начал рассказывать про
задачу восстановления информации и даже успел сформулировать задачу построения корректирующих
кодов комбинаторно. Но сейчас я это напомню, потому что дальше мы с ней будем иметь дело.
Я напомню, как устроено блокчное кодирование. Мы берем сообщение, какую-то строку двоичной длины
K, отправляем ее в некоторое устройство, которое называется кодером, и на выходе получаем,
вообще говоря, более длинную строку из n-битов. Кодер это просто функция, которая по уса поставляет
вот какое-то такое значение. И вот эта вот более длинная строка отправляется в канал связи,
на выходе из которого получается нечто. В канале возможны ошибки. Я сразу зафиксирую модель
ошибок. Возможны только инвертирование битов, и их количество ограничено. То есть y это тоже
некоторая строка длины n. И наша цель состоит в том, чтобы по этому y понять, что передавалось.
Поэтому мы отправляем эту строку в устройство, которое называется декодер, и оно выдает нечто,
х'. Значит, основное определение, которое нам нужно, код исправляет
r ошибок. Если x' равняется x для всех y, которые отличаются от x,
не более чем r-битах. Ну то есть, если у нас в канале случилась какая-то катастрофа,
испортилось очень много битов, мы не гарантируем правильного восстановления. Но если выполнены
условия, которые у нас есть в модели ошибок, что случилось не больше r-инвертирования битов,
то мы на выходе декодера получаем то сообщение, которое было передано. Ну это немножко неформально.
В частности, я говорю про код, но а что во всей этой схеме код, а что не код? Давайте я сейчас
дам более формальные определения, и посмотрим вначале вообще на всю эту комбинаторную ситуацию.
Код это просто-напросто у нас будет любое подмножество двоичных строк длины n. n будет
называться длина кода. Размерность кода. Почему используется слово размерность, станет ясно
чуть позже. Оно тут не случайно. Но по определению размерность это просто двоичный логарифм количества
элементов в коде. То есть если в коде 2 в степени k элементов, то это в точности размерность k.
Значит k размерность. Ну понятно, как это пристроить к этой схеме. Смотрите, если у нас есть код,
это то, что получается на выходе из кодера. Но мы можем себе представить какую-то схему,
как к битов закодировать вот этими словами. Нам их хватит. Отдельная история, насколько
легок алгоритм кодирования, я чуть позже про это скажу, но вот так. Теперь третий основной
параметр для кода, это кодовое расстояние. И тут мне нужно ввести расстояние, которое я буду
использовать на двоичных словах. Это расстояние называется расстояние Хэминга. И определено оно
очень просто. Значит x и y это какие-то двоичные слова. Ну давайте длины n. И расстояние это
количество тех позиций, в которых слова различаются. Ну вот, например, давайте возьмем
x 1 0 1 0 1 0 1, а y 1 0 0 0 1 1 1. Какое расстояние между этими словами? Ну надо отметить различающиеся
позиции. Вот первая различающаяся позиция, и вот вторая различающаяся позиция. Во всех остальных
позициях стоят одни и те же биты. Поэтому расстояние в данном случае равно 2. Слово расстояние здесь
совершенно не случайно. Это нам будет важно, и я сейчас докажу очень простую лему, которая называется
неравенство треугольника. Это главное свойство для функции, которая претендует называться расстоянием.
Ну, строго говоря, расстояние или метрика это такая не отрицательная функция, что выполняет
с неравенства треугольника, что она симметрична, если она равна 0 и x равен y. Это уже строгое
определение метрики. Для расстояния Хэминга это все выполнено, потому что если нет различающихся
позиций, то конечно слова совпадают, а расстояние не отрицательно, естественно оно симметрично,
потому что мы считаем позиции, которые различаются. Единственное, что нетривиально, это проверить
неравенство треугольника. Но это тоже очень просто. Вот давайте посмотрим на множество позиций от 1 до n.
Пусть a это множество позиций, в которых различаются x и y. Я рисую его сплошняком, но это совершенно
не обязательно сплошь, это как вот здесь могут быть какие-то разобранные части. Мне просто удобнее
рисовать сплошняком. В доказательстве я этого использовать не буду, что это интервал. B это множество
позиций, в которых y отличается от z. Заметьте, что вне объединения множества a и b у нас x и t равняется
y и тому, а y и t равняется z и тому. То есть в частности x и t равняется z и тому. Значит, если я определю множество
позиций, в которых различаются x и z, то какой вывод мы можем сделать? Оно находится где-то вот здесь,
то есть это множество лежит в объединении a и b. Ну а теперь это неравенство становится очевидным.
Сколько у нас элементов в объединении a и b? Не больше, чем сумма количества элементов a и
количества элементов b, а c лежит внутри, то есть там тоже еще не больше. Поэтому получаем вот это
вот самое неравенство. И теперь я возвращаюсь к определению кодового расстояния. Это по
определению минимум по словам, принадлежащим коду, но различный. Расстояние между x и y.
Сейчас я объясню, какое отношение кодовое расстояние имеет к исправлению ошибок. Пока вот три параметра.
И основная задача теории корректирующих кодов. Даны три числа n, k, d. Существует ли код двоичный?
На самом деле рассматривается не только двоичные коды, я для простоты буду говорить только о
двоичных кодах. Нам интересно, существует ли код длины n, размерности k и кодового расстояния d.
Ну все тройки нам не интересны, конечно мы хотим, чтобы k и d были побольше. Почему мы хотим,
чтобы d было побольше? Сейчас я докажу на этот счет лему. Давайте, наверное, где-нибудь вот
здесь. Мне пока ничего из этого стирать не хочется. Пусть d больше, чем 2r, то есть не меньше,
чем 2r плюс 1. Тогда c исправляет r ошибок. Как это доказать? Смотрите, нам понадобится понятие
шара. Шар радиуса r, ну, с центром какой-то точки a. Это множество таких точек, что расстояние от a до x не
превосходит r. Совершенно обычное определение шара. Так шары определяются в любом метрическом
пространстве, в обычном эвкалидовом пространстве они также определяются. Ну и вот в случае метрики
Хэминга на двоичных словах, определение такое же. Что существенно. Смотрите, если у меня есть два
разных слова, вот это вот условие на кодовое расстояние говорит, что из кода. Говорит,
что шары соответствующего радиуса не пересекаются. Почему? Ну, смотрите, возьмем любую точку в шаре
с центром в x. Вот тут расстояние не больше, чем r по определению шара. Вот тут расстояние не меньше,
чем 2r плюс 1. Что мы можем сказать про третью сторону треугольника? У нас должно выполняться
неравенство. Вот это плюс вот это не меньше, чем вот это. Но тут не больше, чем r, а должно
получиться число, которое не меньше, чем 2r плюс 1. Значит вот здесь заведомо больше либо равно r
плюс 1. То есть больше r. Значит, если я взял точку в одном шаре, то до другого шара, то в другой
шар она не попадет. То есть про каждую точку мы знаем, что она либо вообще не попадает ни в один
шар с центрами в кодовых словах радиуса r, либо попадает ровно в 1. И давайте теперь смотреть на
картинку декодирования. Я ее после этого сотру. Вот мы получили, мы передаем вначале какое-то
слово u, потом какое-то слово v. У нас тут получились кодовые слова какие-то. И когда мы их передали
по каналу, получились какие-то слова. Но мы точно знаем, что слова лежат в шаре. Потому что,
смотрите, что значит, что расстояние не больше, чем r? По определению расстояния, это означает как
раз в точности, что слова различаются не больше, чем в r-позициях. А у нас модель ошибок такая,
что инвертирование случилось не больше, чем в r-позициях. Значит, из того слова, которое мы
передавали, может получиться только слово, которое лежит в шаре радиуса. Собственно,
вот это понятие хэмингового расстояния, оно фиксирует свойства нашей модели ошибок.
Ну и теперь уже алгоритм декодирования понятен. Если мы получили какое-то слово,
мы смотрим в шар с центром в какой кодовой точке оно попадает, и выдаем этот центр. Если
слово не попало, не выделилось шаров, мы можем выдать просто сообщение об ошибке, можем выдать
любое кодовое слово. Нас это не интересует, потому что слова вне объединения этих шаров в нашей
модели получиться не могут. Мы рассматриваем только ошибки вида, когда происходит не больше r-инвертирования
битов. Конечно, для реальной жизни это немножко искусная модель, и если у вас есть такой код,
который вы используете, все равно может так случиться, что пришла какая-то ерунда. И там есть
отдельная история, это отдельная задача, теория кодирования очень большая. Я, конечно, даже самое
начало не успею рассказать, я только несколько конструкций смогу вам показать, чтобы стало
вообще понятно, почему что-то интересное здесь может быть. Ну, если говорить о реальных алгоритмах
декодирования, в этом случае декодирование происходит по максимуму правдоподобия,
что бы это ни значило. В общем, есть некоторые средства, как для конкретных кодов, как указывать.
Но там, чтобы что-то доказывать, нужна какая-то более сложная модель ошибок, например, вероятностная,
это я все пропускаю. То есть, в нашем случае я хочу заметить, что у меня модель ошибок вот она. То
есть, меня вообще не интересуют случаи, когда ошибок случилось больше r, и тогда этот код исправляет
эти r ошибок, если шары не пересекаются. Ну, это такой вот пересказ, пересказ вот этой вот конструкции в
виде комбинаторной задачи. Вот она комбинаторная задача. Теперь понятно, почему я хочу, чтобы d
было побольше. Чем больше d, тем больше ошибок код исправляет. Но понятное дело, что k и d
увеличивать одновременно затруднительно. Это противоречивое требование, чтобы точек было побольше,
а шары с центрами в этих точках не пересекались. Давайте рассмотрим два простых случая. Первый
простой случай. Код повторения. Это просто-напросто два двоичных слова. Одно состоит только из нулей,
другое только из единиц. Ну n у нас, вот оно написано. Чему равна размерность? Слов 2, значит,
размерность равна единице. Код повторения позволяет кодировать один бит. Ну понятно, каким способом.
Если мы хотим передать 0, мы передаем n нулей. Хотим передать единицу, передаем n единиц.
А расстояние кодовое очень хорошее. n. Потому что, если я возьму n нулей, n единиц, они различаются
во всех позициях. Код совершенно замечательен с точки зрения исправления ошибок, но он совершенно
плох с точки зрения экономии ресурса. Чтобы передать один бит, мы передаем n битов. Вот это называется
скорость передачи. Значит, я особо не буду злоупотреблять этим термином.
Смысл совершенно понятен. Мы хотим уже передавать вот эти информационные, как говорят, биты, а передаем кодовые.
Если, вот как в этом случае, k равно единице, то чтобы передать сколько-то информационных битов,
мы должны передать в n раз больше кодовых. Получается так, что плата за то, что мы исправляем примерно n пополам ошибок,
очень большая. Мы платим падением скорости в n раз. И возникает вопрос, обязательно ли такое падение необходимо.
Я сразу скажу, что не обязательно. На самом деле, есть гораздо более экономные коды. Некоторые примеры появятся.
Ну, второй код тривиальный. Это просто-напросто все двоичные слова длины n. Тут с размерностью все хорошо,
но с кодовым расстоянием все плохо. Он исправляет ноль ошибок. Ну, это понятно почему, потому что если вы
передаете слово никак, то есть просто все информационные биты прямо посылаете в канал,
если у вас что-то испортилось, то вы уже это не сможете восстановить. У вас получится снова кодовая слуха.
То есть вы видите из этих двух примеров, что k и d, они в каком-то смысле противоположны. То есть если мы
хотим k взять побольше, то d совсем маленьким взять нельзя. И наоборот, возникает вопрос,
каковы же более-менее оптимальные соотношения между k и d. Мы сейчас его обсудим. Последнее,
что я хочу сказать, прежде чем стереть вот эту вот доску с базовой задачей исправления ошибок,
я хочу заметить, что вот я вот так вот зафиксировал свою главную задачу, при каких n, k и d существует
код. Но на самом деле, конечно, нам хочется больше. Чего нам хочется? Давайте посмотрим на эту картинку.
Мы хотим, чтобы у нас был достаточно эффективный кодер и достаточно эффективный декодер. Сейчас,
конечно, есть компьютеры, вы можете кодер реализовать в виде процессора, который будет вычислять какую-то
очень сложную функцию. Но нужно понимать, что то, что я сейчас рассказываю, это, в общем-то,
очень старая история. Она происходила в конце сороковых, в начале 50-х годов прошлого века. То есть
радио уже было, компьютеров не было, и были радиолампы. И вот на радиолампах вы могли собрать какое-нибудь
устройство, напоминающее компьютер, которое могло что-то вычислить. Но чем больше лампы использовали,
тем менее надежным оно становилось. Поэтому, если учесть, что заказчиками к тому же были в основном
военные, им хотелось, чтобы все это работало надежно, если это состоит в машине, которая едет
где-то по бездорожью, а лампы обладают таким свойством, что у них нити накаливания рвутся и
так далее. Хотелось как можно проще реализовывать и вот эту, и вот эту вот часть, и кодер, и декодер.
Я буду обсуждать только проблему кодирования. Проблема декодирования, она труднее, на самом деле.
Для тех кодов, про которые я рассказываю, есть хорошие алгоритмы декодирования, но в общем случае их
нет. То есть можно придумать замечательный код, хороший там в разных отношениях, но который вы не
сможете декодировать эффективно. Эффективно даже в современном смысле, то есть у вас будет там длина
кода 10 тысяч, и вы не сможете восстановить сообщение просто потому, что алгоритм восстановления
слишком сложный. Но про декодирование я говорить не буду. Это все очень похоже на то, что я буду
рассказывать, но требует просто у меня времени на это нет. Моя цель показать, как можно кодировать.
Причем не просто вот что существует код, а существует код, который достаточно легко задать. То есть
вот это меня заботить будет, чтобы задать код было достаточно легко. Но прежде чем задавать код каким-то
эффективным способом, давайте посмотрим какие вообще есть комбинаторные ограничения. Вот в духе вот
этого вопроса. Если забыть о конструктивности, то ответ далекий от окончательного. Окончательный
ответ не получен до сих пор, и это считается очень трудной задачей. Там время от времени происходит
продвижение, но они с течением времени становятся все более и более загадочными. Последние продвижения
я вам даже не смогу сформулировать. Я, честно говоря, их до конца и не понимаю. Там уже утверждение
формулируется на очень сложном математическом языке, хотя вроде бы речь идет о комбинаторике.
Но я расскажу два базовых факта, которые очень простые, которые люди сразу сообразили, когда
начали интересоваться корректирующими кодами, и которые, по сути дела, лежат в основе всех
дальнейших построений. Они задают некоторые естественные границы. Вот у нас есть два примера,
но они не очень показательные на самом деле. Показательные будут другие оценки. Первая оценка
называется по традиции «граница хэминга». Тут слово «граница» нужно понимать как слово «оценка».
Просто по-английски это «haming bound» все равно, а по-русски в какой-то момент это перевели как
«граница», но так и прижилось. Пусть у нас есть код с параметрами n, k, 2r плюс 1. Тогда
2 в степени k, то есть количество кодовых слов, не превосходит 2 в степени n разделить на
нечто такое слегка загадочное, на сумму биномиальных коэффициентов. Биномиальные коэффициенты
из n по i, где i пробегает значение от 0 до r. Чтобы это стало менее загадочным, давайте я,
ну вот эту лему я уже доказал, я здесь оставлю, чтобы это было полезно иметь перед глазами. Вот
давайте посмотрим. Значит, ясно, что количество точек в шаре радиуса r не зависит от, давайте я
вот просто напишу br, это у меня brn. Это будет количество точек в шаре радиуса r с центром,
ну пусть будет в нуле, но на самом деле в любой точке. Понятно, почему не зависит, потому что если
я, ну сейчас мы посчитаем и давайте тут, ну давайте я напишу 0, а потом объясню просто,
что счет от этого не зависит. Это как раз вот та самая сумма биномиальных коэффициентов,
которая написана. Откуда она берется? Ну давайте я еще раз нарисую этот шар. Вот у нас есть центр,
пусть нулевая точка. Что входит в этот шар? Входят такие x, что количество единиц не больше,
чем r. Значит, вот норма x, это по определению расстояние от нуля до x. Еще такое обозначение
используется, норма. Хеминговая норма. А сколько же здесь точек? Ну смотрите, если у нас единиц и,
сколько у нас точек из нулей единиц, которых и единиц. Ну как раз биномиальный коэффициент по
определению. И дальше мы должны взять сумму. Нас устраивает любое значение и от нуля до r.
Теперь почему это не зависит от центра? Мне удобнее было считать от нуля, но представьте,
что я считаю от какой-то точки. Тогда все, что мне нужно сделать, это считать, смотреть,
сколько у меня позиций, в которых центр и данная точка различаются ровно в и-позициях. Это будет,
опять-таки, под множество размера и n элемент на множество. То есть их тоже биномиальный коэффициент.
Ну чуть позже у нас даже появится более веское объяснение, вот такой вот формуле. Ну сейчас,
что не зависит точнее от положения центра, но сейчас этого достаточно. То есть фактически я
напишу вот теперь, тут у меня граница Хэминга написана, я напишу ее теперь вот так. И теперь
она становится практически очевидной. Ну вспомним лемма, которая у меня была. Шары
радиуса r не пересекаются. Если у меня есть код, это точки из кода, шары радиуса r с центрами
в этих точках не пересекаются. Ну что это означает? Это означает, что если я возьму и
посчитаю количество точек в этих шарах, в каждом шаре одинаковое количество точек, вот та самая
сумма биномиальных коэффициентов. У меня не может получиться больше, чем 2 в степени n,
потому что 2 в степени n это общее количество двоичных слов, длины n. А шары не пересекаются. Я
каждую точку могу посчитать не больше, чем по разуму. Но это и есть та оценка, которая написана. То
есть мы видим, что код не может быть очень большим. Вот это ограничение. С другой стороны,
если сравнивать вот с этими крайними случаями, то он существенно лучше, чем эти крайние случаи,
вот эта оценка. Смотрите, что у меня есть. Допустим, я хочу исправлять константу ошибок,
ну там не знаю, две. Тогда brn это примерно n квадрат. Это означает о большое и омега большое. То
есть точно сюда констант и это n квадрат. Ну и теперь смотрите, нас же интересует логарифм. То
есть k получается такая величина n минус там удвоенный логарифм n. Посмотрите на то,
что у нас написано. Я исправляю две ошибки, это не тривиально. И при этом плачу очень низкую цену.
Вот тут у меня в тривиальном коде k равнялась n, а теперь у меня k чуть меньше. Но меньше
намножитель, который логарифмичный по n. То есть я плачу логарифмическую цену за то,
чтобы исправлять две ошибки. Чуть более сложные подсчеты, которые я пропущу, желающие могут их
найти в книжках или сделать самостоятельно, если вы знаете формулу Стирлинга, это вы можете написать
самостоятельно. Говорят следующее, что даже если количество исправляемых ошибок линейно по n,
у нас вот эта величина скорость передачи, она все равно будет, ее можно сделать константной,
если мы достигли границы Хэминга. Граница Хэминга, вот если здесь считать, что r это там,
не знаю, одна сотая от n, мы хотим исправлять один процент ошибок. То есть нам разрешается в одном
проценте позиции, чтобы случиться ошибка. Ну тогда k будет, уже конечно мы не логарифмическую цену
должны платить, а линейную, и она будет какая-то константа на n. Какая это вот там некоторые
вычисления, которые я пропускаю? То есть граница Хэминга на самом деле очень оптимистическая,
но она верхняя. Давайте я сразу напишу сюда список. Это не конкретный пример, это определение.
Бывают коды, которые достигают границы Хэминга. Такие коды называются совершенными. То есть вот эта
вот оценка достигается. Бывают такие коды, в которых достигается. Что это, кстати, означает,
если у нас здесь равенство? Посмотрите на доказательства. Это означает, что кодовые шары,
шары радиуса r, не просто не пересекаются, задают разбиение, у нас ничего лишнего. Мы все
двоичные слова длины n утилизируем, они все используются как возможные результаты передачи
информации. Вопрос, существуют ли совершенные коды с данными параметрами, довольно сложный,
но ответ на него известен, в отличие от этой общей задачи. Совершенные коды, ответ известен.
Их не очень много. Если говорить о двоичных кодах, о которых я только говорю, это будет серия,
которая у меня сейчас появится через некоторое время, и еще один код, который я надеюсь в следующий
раз рассказать. Я не буду вам доказывать, что других совершенных кодов нет. Это требует довольно
кропотливого анализа, доказательства не очень простые, но все примеры совершенных кодов я вам
надеюсь продемонстрировать. И все они укладываются в некоторую общую идеологию, которую я хочу
рассказать. Но вот, к сожалению, бесконечная серия исправляет одну ошибку, просто при разных длинах
передачи, а единственный конечный код исправляет три ошибки. То есть, если вы хотите исправлять хотя
бы четыре ошибки, на совершенные коды уже надежды нет. А на что же надежда есть? Ну давайте тут,
ну давайте ладно, я оставлю, это все-таки очень важное определение. Может быть, стоило переписать
куда-то в бок, чтобы не стирать, ну пусть будет. Есть другая оценка, которая называется граница
Варшамова Гилберта. Гилберта. Тут я, честно говоря, даже не помню, как он пишется по-английски,
но по-русски его без мягкого знака. Есть великий немецкий математик Гильберт, а есть вот этот
Гилберт, который американский математик, и он пишется точно не так, потому что первая буква J,
а у знаменитого немецкого Гилберта первая буква H, но не важно. Значит, что я хочу сказать? Я хочу
сказать, что существует код с параметрами n, k и 2r плюс 1, для которого 2 в степени k по-прежнему,
то есть количество кодовых слов, не меньше, чем 2 в степени n поделить, а вот тут написано немножко
другое число. Там у меня в верхней оценке было написано радиус r, а здесь написано радиус 2r.
Это тоже очень хорошо, потому что, ну скажем, если r константа, то у меня все равно получается
объем шара полиномиальный, и те же самые оценки показывают, что мы можем заплатить только
алгоритмическую цену. Как доказать? Это очень хорошая оценка. Как ее доказать? Доказывается
на самом деле очень просто. Доказательство состоит в том, что я буду просто постепенно строить
кодовые слова, поддерживая такой вариант цикла, что x и t не принадлежит объединению шаров радиуса
2r с центрами в остальных точках. То есть вот представьте, первую точку я могу взять произвольно,
вторую точку я должен взять так, чтобы она не попадала в шар радиуса 2r с центром первой точки,
и так далее. То есть если у меня уже построено k точек, и вот это вот объединение шаров еще не
покрыло все двоичные слова, я просто могу добавить следующую точку. Инвариант сохранится,
потому что эта точка лежит вне объединения всех шаров радиуса 2r, ну и это будет выполняться для
всех предыдущих точек, расстояние же симметрично. Сколько же мы можем так проработать? Ну понятно,
если у меня m, ну вот k точнее, k у меня, давайте я тут m напишу, потому что k у меня же параметр
кода. Если m умножить на объем шара 2r меньше, чем 2 в степени n, то вот я могу добавить следующую
точку. Потому что в таком количестве шаров радиуса 2r вот столько всего точек, если это меньше,
чем общее количество двоичных слов, то у меня есть запас. Ну и очевидно, что полученный код,
то есть точки x и t, имеет кодовое расстояние больше, чем 2r, потому что между кодовыми словами мы
специально контролируем, чтобы расстояние было больше, чем 2r. Ну в общем и все. И возникает
вопрос, а зачем вообще нужно какое-то продолжение? Мы доказали хорошую оценку. Как я сказал,
она нас почти что устраивает. То есть разница между этими двумя границами не очень большая,
и уже 70 лет люди сражаются за то, чтобы как-то ее улучшить. Улучшения там происходят очень небольшие,
сложные, не при всех значениях параметров. Но это две базовые оценки. И в сущности,
если мы достигаем оценки Варшамова-Гилберта, это считается хорошо. И скажете, а зачем тогда
что-то еще делать? Ну вот мы доказали. Проблема в том, что эта конструкция неявная, хотя она
описана алгоритмом. Но смотрите, вот мне дали параметры 32, кодовое расстояние должно быть 5,
и вот мне надо ка побольше. Ну вот отсюда я получу какое-то ка. Но чтобы построить соответствующий
код, я должен взять 32-мерный шар, то есть миллиард точек, даже не миллиард, а 4 миллиарда,
и строить вот эту вот конструкцию. Пять таки скажете вы, ну что такое 4 миллиарда? Это как-то
сейчас даже не то, что в оперативную память помещается, в кэш-память помещается. То есть это
немного по нынешним временам. Но я напомню, что вся эта история развивалась тогда, когда для 32 битов
нужно было 32 лампы, и они могли сгореть в любой момент, то есть все было очень плохо. И вот такой
вот способ реализовать инженеры просто не брались, потому что формально мы можем написать такой
алгоритм, но чтобы его реализовать нужно было устройство, которое просто нереально было
реализовать. Даже в конце 50-х годов, когда появились компьютеры, где в принципе такое
реализовать было можно, но и было ясно, что эти компьютеры занимали гигантскую площадь. Воткнуть
в любое устройство, которое передает и принимает, было явно невозможно. То есть вот это вот,
с точки зрения техники, нехорошо. Хотелось бы каких-то явных конструкций, но хотя бы чтобы
мы кодировать могли достаточно просто, чтобы мы могли кодовые слова как-то очень легко. То есть
вот мы хотим передавать какие-то биты, чтобы мы могли предъявлять, какое слово мы передаем. Ну и
декодировать тоже хотелось. Понятно, что если мы не сможем просто кодировать, то даже если очень
хороший алгоритм декодирования, это нас не спасет. И здесь, возможно, впервые, я не поручусь, это надо
историю математики более внимательно изучить, но, возможно, впервые возникла ситуация, которая за
эти 70 лет повторялась многократно. Ситуация такая. Мы из некоторых компенаторных соображений,
либо мощностных, вот как здесь, либо вероятностных каких-то, доказываем, что есть некий объект. В данном
случае хороший код. Иногда какой-нибудь хороший граф, иногда еще что-нибудь хорошее. Но мы не
имеем примера этого графа. У нас просто есть голая теорема существования. А нам хочется,
хочется иметь какой-то явный пример. По самым разным причинам хочется. В фундаментальной науке
тоже есть задачи такого же типа, где мы можем доказать, что что-то существует, но ни одного
явного примера построить не можем, и это фундаментальнейшая проблема теоретической
информатики. А что делать? Вот все успешные примеры, ну почти все, я извиняюсь, почти все
успешные примеры такого рода, основаны, как ни странно, на такой идее. Нужно из комбинаторной
задачи сделать алгебрическую. Вот зачем нам нужна алгебра? Если у нас есть, мы уже знаем,
что что-то существует, но мы хотим увидеть это явно. Вот для того, чтобы увидеть что-то явно,
нам нужна алгебра. Иногда более сложная, иногда менее сложная. То есть, вот скажем, я говорил про
графы, есть такие графы-экспандеры, там в начале доказательства использовали очень сложную алгебру.
И не только алгебру, теорию модулярных форм, с помощью которой гипотезу Ферма доказали, а потом
была придумана очень практичная схема, более комбинаторная, но в основе которой все равно лежит
алгебра, только линейная алгебра. Но там довольно нетривиальные рассуждения, связанные с линейной
алгеброй, собственными числами, и так далее. То есть, совсем от алгебры не избавиться, а как минимум
нужна линейная алгебра. Но иногда нужны вот конечные поля. Ну вот я начну тоже с линейной алгебры,
но давайте, наверное, в этот момент я сделаю перерыв, как раз сейчас самое время, давайте прервемся
на 5 минут, и после перерыва я начну реализовывать эту ивристику. То есть, мы хотим более явные
конструкции для кода, и я буду постепенно подливать алгебру, чтобы конструкции становились полов.
Да, ну давайте начинать. Постепенно рассаживайтесь. Звонков я как-то не слышу. Итак, пока вы
рассаживайтесь, я напомню, ничем я остановился. Я остановился на той идее, что нужно для построения
явных хороших кодов, хороших, которые достигают границы Варшавма-Гилдерта или вообще садятся на
границу Хэминга. Это уж не просто хорошие, а совершенные коды. Нам нужна алгебра. И первый шаг
состоит в том, чтобы использовать линейную алгебру. И возникает то, что называется линейные коды.
У нас есть такая объекция между словами длины n двоичными и координатным векторным пространством
над полем из двух элементов. Ведь что такое координатное векторное пространство над полем из
двух элементов? Два элемента это как раз 0,1. И нам нужно, чтобы у нас есть вектор размерности n,
то есть у нас фиксирован базис, координатное пространство. И вот на каждой позиции написан 0 или 1,
но это и получается двоичное слово. И код называется линейным, если он под пространство.
Смотрите, мы странным образом себя связываем руки. Из комбинаторных соображений можно
рассматривать любое множество. Мы говорим, давайте мы будем рассматривать только под пространство.
Но это лишние условия. Тем не менее, эти лишние условия нам позволяют легче строить явные конструкции,
и вообще всякие улучшения сделать в той комбинаторной картине, которая у меня есть.
И тогда заметьте, что слово размерность приобретает очень естественный смысл. Потому что сколько в
подпространстве точек? Ну, количество элементов поля в степени размерность пространства. То есть два в
степени как, как раз. Поэтому и слово размерность, дело в том, что большую часть теории корректирующих
кодов составляет изучение именно линейных кодов, потому что у них есть разные достоинства и
конструкций много. А с нелинейными кодами все гораздо сложнее. Ну, в общем, линейные коды – это
основная часть этой теории. Какие возникают упрощения? Во-первых, кодовое расстояние. Для него
теперь можно написать более простую формулу. Я напомню, что норма х – это количество единиц в
х. И кодовое расстояние линейного кода – это просто минимум нормы по всем ненулевым векторам.
Ну, фактически это здесь вот написано. Дело в том, что давайте я прям здесь это напишу. Что такое
расстояние от х до у? Это норма разности. Смотрите, если я возьму разность, ну, по модулю 2, что разность
у суммы – это одно и то же, конечно. Но что у меня в разности останется? Где будут стоять единицы? Там,
где х и у различаются. Там, где х и у одинаковые, будут стоять нули. Поэтому количество позиций,
в которых различаются х и у – это количество позиций, в которых в их разности, ну, или сумме,
как вам угодно, стоят единицы. Ну, а дальше понятно. Если код линейный, то из того, что х принадлежит
С, следует, что х-у тоже принадлежит С. Поэтому, если у меня минимум достигается на какой-то паре,
он обязательно будет достигаться на паре 0 и этот х. Это, кстати, и объясняет, почему радиус,
в смысле, объем шара радиуса r не зависит от центра, потому что у нас, ну, есть вот такое вот сдвиг
в линейном пространстве. Мы просто добавим вектор из нуля в точку а. И это будет биекция,
которая сохраняет расстояние. Ну, это мелкое техническое упрощение. Я просто дальше,
когда буду говорить про кодовое расстояние, буду все время его измерять вот таким вот способом.
Вольная существенная вещь – задание кода. Есть два важных способа задания кода.
Я думаю, что, поскольку вы линейную алгебру учите,
ну, пусть над r, но, как я уже говорил, до некоторого момента линейная алгебра над любым полем одинакова,
как задать подпространство? Первый способ, самый важный для линейной алгебры подпространство
задается как множество решений системы однородных линейных уравнений. Вот я их написал. У меня есть
некоторая матрица h, и множество решений системы уравнений hх равняется нулю. Это подпространство.
Это легко проверить, потому что если h от x равно нулю, h от y равно нулю, h от x плюс y тоже равно нулю
из обычных свойств матричного умножения. Но есть другой способ. Мы можем задать подпространство
базисом. Этот базис будет задаваться тем, что называется порождающая матрица. Обычно мы считаем тогда,
что у нас кодовые векторы являются строками, и вот мы выписываем этот базис как строки некоторой
матрицы. Она называется порождающая. Переход от проверочной к порождающей матрицы осуществляется
обычными алгоритмами линейной алгебры, то есть решение системы линейных уравнений. Там все над
любым полем одинаково. Всключение гауса, все будет работать. Какие-то более экзотические алгоритмы
может работать не будут, но стандартные, которые вам рассказывали, все будут работать. Чем удобна
такая вещь? Теперь у нас появляется очень простой алгоритм кодирования. Все, что нам нужно, это
создать вот эту порождающую матрицу. Если мы хотим передать ка битов, мы должны просто взять сумму
по модулю 2 соответствующих базисных векторов, умножить на порождающую матрицу и вот сунуть в
канал то, что получилось. И вот это уже даже в теплые ламповые времена было технически посильно.
То есть инженеры могли, если им говорили, что вот у нас будет передаваться там, не знаю, 11 битов,
а кодовых битов 15, они брались сделать соответствующую схему, которая будет реализовывать
вот такое умножение на матрицу. Умножение на матрицу это все-таки очень простая операция. Поэтому
ее выполнение было разумно. То есть с самого начала было ясно, что вот такие проверки,
они хорошие. То есть такие коды, они хорошие. И проверять их легко. То есть смотрите, если мы
на выходе получили точку не из кода, у нас hx, то есть когда у нас есть проверочная матрица,
она будет не ноль. То, что получается, называется синдромом. И все алгоритмы декодирования линейных
кодов так или иначе завязаны на работу в синдром. Другое дело, что в общем случае задача декодирования
линейного кода очень трудна. Вот кодировать все хорошо, а декодировать уже плохо. Но про декодирование
я практически ничего говорить не буду. Я буду говорить про кодирование. И вот теперь первый
нетривиальный пример кода. Пока я про совершенные коды только сказал, но это по сути дела и будет.
Пример из этой области.
Это знаменитый код Хэмин. Он конечно не только используется в задачах передачи и восстановления
информации, но поскольку конструкция очень простая и изящная, у него есть много приложений и в
комбинаторике, в теоретической информатике. Что такое код Хэмин? Параметры у него такие. Длина кода
N. Степень двойки без единицы. Размерность еще на S меньше. То есть вот у нас N это 2 в степени S-1,
а размерность это 2 в степени S-1-S. И я сейчас задам порождающую матрицу для этого кода. Он
линейный. Конечно код Хэминга можно задавать очень по-разному, как все по-настоящему интересные
конструкции. Он допускает много описаний, но я вот выберу то, которое мне наиболее удобно.
Значит смотрите, как устроена порождающая матрица. Она имеет квадратный блок размера 2 в степени S-1-S,
состоящий из единичной матрицы. И добавочку, она прямоугольная, потому что смотрите,
мне нужно, чтобы у меня было K-строк и N-столбцов. Добавочка состоит из всех векторов двоичных
длины S, у которых хотя бы две единицы. Сколько таких векторов? Ну проще посчитать дополнение,
сколько векторов, которых не больше одной единицы. Но это как раз Хэминга в шар радиуса 1. То есть
одна точка, и еще N, это биномиальный квитцент из N по единице. То есть вот здесь у нас получится
всего у нас два в степени S минус, ну вот это вот самое, то есть это объем шара радиуса,
S-мерного шара радиуса 1. И это ровно столько, сколько нам нужно, это и есть наш параметр K. Вот из
чего состоит код Хэминга. Он состоит из S-слов, двоичных слов длины N, которые являются стуммами
строк этой матрицы. То есть мы можем взять произвольное под множество строк этой матрицы,
взять сумму по модулю 2 и послать. Это и будет код соответствующего сигнала. То есть если у меня
здесь есть какое-то сообщение, то мне надо вот просто взять сумму вот этих вот.
Строк, сложить их по модулю 2, и это и будет элемент кода Хэминга. Давайте я его сразу вот так вот
отошел. Ну я еще не определил кодовое расстояние. Какое кодовое расстояние у кода Хэминга?
Утверждается, что оно равно 3. То есть код Хэминга исправляет одну ошибку при любом N. То есть если N
поменьше, то цена одной ошибки, она как бы выше. Если N совсем большое, то платим мы совсем мало,
заметьте, у нас K и N отличаются на вагарифм N. Платим мы совсем мало, но и исправляем не очень
много. Но на самом деле код Хэминга очень хорош. Давайте я докажу сейчас, что D равно 3, а потом
обсудим насколько хорош код Хэминга. Ну смотрите, любое кодовое слово, что мне нужно доказать?
Мне нужно доказать, что в любом ненулевом кодовом слове хотя бы 3 едини. Любое кодовое слово
сумма ну каких-то Q строк. Давайте смотреть, если Q равно единицы, тогда по построению в каждой
строке не меньше трех единиц. Смотрите, есть единица в том блоке, который отвечает единичной
матрице, а вот здесь в каждой строке я специально выбрал только те слова двоичные, в которых хотя
бы две единицы. Значит здесь больше либо равно 3. Теперь если Q равно 2, тогда смотрите, вот я взял
две какие-то строки. У меня в этой части, когда я беру сумму по модулю 2, здесь же стоит единица,
здесь ноль, здесь единица, здесь ноль. У меня две единицы уже будут. А в правой части будет хотя бы
одна единица. Почему? Потому что здесь написаны разные двоичные слова. Дума по модулю 2,
два разных слов не может равняться нулю. Поэтому у меня получается, что единиц не меньше чем 2
плюс 1. Ну и наконец, если я беру сумму больше чем трех строк, то у меня вот в левой части уже
будет хотя бы три единицы. Всё, я доказал, что кодовое расстояние 3, но оно реализуется, естественно,
потому что у меня просто есть строки, в которых всего три единицы. То есть я сразу вижу из порождающей
матрицы, что больше чем 3 кодовое расстояние быть не может. Ну и меньше оно быть не может,
как вот я сейчас показал. И теперь смотрите, я где-нибудь здесь напишу. Давайте сравним с границей
Хемминга. Значит у меня вот столько кодовых слов, а с другой стороны граница Хемминга говорит мне,
что их не больше, чем два степенен поделить на b, ну у меня r равно единице n, то есть на самом деле
здесь написано n плюс 1. Давайте подставим n, который у меня есть. Это получается 2 в степени 2 в степени s
минус 1 поделить, n это 2 в степени s минус 1, плюс 1 это 2 в степени s. Ну смотрите, это то же самое,
2 в степени 2 в степени s минус 1, да еще поделить на 2 в степени s. Это 2 в степени s минус 1 минус s.
Это и есть количество слов коди Хемминга. Значит мы получили пример совершенного кода,
причем бесконечно много примеров.
Но при фиксированном кодовом расстоянии, то есть примеров бесконечно много, но все они дают нам только исправление одной ошибки.
Зато лучше не бывает, то есть мы достигли максимума возможного. Код Хемминга дает нам разбиение
соответствующего булева куба на шары радиуса 1. Ну а если нам хочется исправлять больше ошибок,
две, три, пять, десять, код Хемминга нам не поможет. Ну вот если три ошибки исправлять,
это знаменитый код Галлея, я в следующий раз о нем скажу, но у него фиксированные значения параметра.
N 23, 11 или 12, по-моему все-таки 11. Тут я могу ошибиться, может быть 12, а D7. Но это мы в следующий раз проверим.
Тут исправляются три ошибки, но при конкретном значении блочной длины. Для техники это не так плохо,
потому что обычно и нужна какая-то фиксированная длина. В частности, код Галлея использовался реально при
кодировании информации на компакт-дисках. Других совершенных кодов двоичных нет, вот это весь список.
Теорема, я говорю, она довольно трудная, я не буду ее доказывать, но это так. А если хотите
справлять другое количество ошибок или на другой длине, что делать? Тут нужно больше алгебр.
Нам не хватит только линейные алгебры. На самом деле, точнее так, бывают конструкции линейных кодов,
основанные уже на линейной алгебре и некоторой нетривиальной комбинаторике, которая не требует
больше алгебры в том смысле, в который я в это вкладываю. Там нужна только линейная алгебра.
Но линейная алгебра нужна нетривиально, это те самые графы и экспандеры, о которых я упоминал.
Я про эти коды рассказывать не буду, опять-таки, за недостатком времени. Это очень остроумная
конструкция, но там надо вначале объяснить, что такое экспандеры, иначе ничего не понятно.
А я расскажу по сути дела примеры кодов, в частности, там будет код Галлея среди этих примеров,
но там будут коды, которые почти достигают границы хемминга, если количество ошибок фиксировано.
Блочная длина большая, а количество ошибок фиксировано. То есть, скажем, n стремится к
бесконечности, а количество ошибок фиксировано. Тогда эти коды очень хороши. Но это я в следующий
раз буду обсуждать, пока я хочу сделать следующий шаг. Что такое координатное векторное пространство?
Его можно отождествить с кольцом вычета. Я буду такое кольцо называть циклическим,
для краткости. Это вычеты кольцам многочленов с коэффициентами в поле из двух элементов по
модулю многочлена х в степени n без единицы. И из чего оно состоит? Мы знаем, что в каждом
классе вычетов есть ровно один многочлен в степени меньше n. То есть, фактически у нас
базисом будут вот такие вычеты, содержащие степени х до n-1. Это общее явление, тут пока я
не использую вот то, что у меня многочлен вот такой. И у нас получается координатное пространство.
То есть, когда я буду говорить о этом кольце, в принципе, это векторное пространство над полем из
двух элементов, там может быть много базисов, но в контексте кодирования мне нужно зафиксировать
базис. И фиксировать я его буду всегда именно вот так. То есть, у меня базис это просто степень х.
Самый естественный базис. Но зачем мне нужна эта структура? Смотрите, тут я связал себе руки не
очень сильно. Я потребовал только, чтобы код был в линейном пространстве. Это недостаточно сильно.
Нужно еще кляв в рот воткнуть или там, я не знаю, приковать кандалы на ноги. Нужно потребовать,
чтобы код был идеалом в этом кольце. И будет нам счастье. То есть, я хочу подчеркнуть, что это на
самом деле некоторая общая евристика. То есть, когда вы строите явную алгебрическую конструкцию,
нужно догадаться до того, какие условия нужно дополнительно наложить на вашу комбинаторику.
Комбинаторика слишком рыхлая. Там с одной стороны все есть, с другой стороны непонятно, как строить.
А если вы добавляете какие-то жесткие алгебрические условия, у вас остается меньше свободы. И если вы
угадали, если вы правильно добавили условия, у вас все получается. Но вот тут вся хитрость состоит в том,
что нужно правильно добавить. То есть, циклическим кодом я буду называть идеал. Идеал, конечно,
подпространство. Это мы знаем. Это подгруппа аддитивной гуглы. Но замкнуто еще относительно
умножения. И слово циклический связано с тем, что вот это свойство быть идеалом имеет еще
другую интерпретацию. Давайте рассмотрим сдвиг на нашем базисе. S это оператор сдвига. То есть,
если у меня есть вектор 0, 1, 1, 0, скажем, то S на него подействует так. Это будет 0, 0, 1, 1. Смотрите,
я х нулевой отправляю в х1. Это вот это вот. х1 в х2, х2 в х3, х3 в нулевую, потому что у меня
код имеет длину n. Так вот, лемма.
Подпространство я называю циклическим, если оно замкнуто относительно оператора сдвига. То есть,
если у вас есть вектор из пространства, то сдвигая его координаты, вы снова получаете вектор из этого
же пространства. Так вот, идеал вот в этом циклическом кольце, это в точности циклическое
пространство. То есть, пока мы могли бы обойтись линейной алгеброй, просто используя оператор
сдвига. Его же можно просто определить без всяких вычетов. Ну вот, у меня есть координаты там 0, 1,
там n-1. Оператор сдвига переносит эту координату в плюс первую пазису. Дальше мне, конечно,
алгебра будет существенно нужна. Но давайте докажем эту лему. Она нам будет полезна.
В доказательстве этой леммы я фактически использую ровно одно соображение. Как действует оператор
сдвига на произвольный вектор в нашем пространстве? Он умножает на x его. И это достаточно очевидно.
Смотрите, произвольный вектор – это сумма вот таких степеней. Если я действую оператором сдвига,
он линейный, значит, я каждую степень сдвигаю на единицу, координаты не меняются. Поэтому
это получается умножение на x. Отсюда что следует? Если у меня есть идеал. Пусть у меня это идеал.
Давайте рассмотрим, подействуем до f какой-то элемент этого идеала. Давайте подействуем
оператором сдвига на f. Это получится x на f от x. И это снова принадлежит идеалу,
потому что оператор сдвига – это умножение на x. А мы знаем, что идеал замкнут относительно
умножения на любой элемент кольца. Но я доказал включение, а у меня там равенство.
Это следует просто из того, что s-1 обратимо. Если у меня есть сдвиг вправо, то у меня есть
сдвиг влево, который i-ую координату переводит v-1, то есть i-ую степень v-1. И понятно,
что эти два оператора взаимно обратны. А раз они взаимно обратны, то смотрите,
я отправил, у меня получилось, что s-j лежит в j, но раз s-1 обратимый оператор, то размерность
этого пространства совпадает с размерностью j, значит они должны совпадать. Не может быть
строгого включения пространства одинаковой размерности. Ну хотя бы потому, что количество
точек – это два в степени размерности. Таким образом мы получаем, отсюда мы получаем уже
строгая равенство. Ну и наоборот, если у меня есть равенство, то отсюда сразу следует, что x
умножить, значит если у меня есть элемент циклического пространства, x умножить на f,
тоже принадлежит этому пространству. Ну а тогда, если я умножаю на какой-то многочлен, который
является суммой степеней x, то понятно, что получится. У меня получится сумма, когда я умножаю на x
степени i, это я то же самое, что применяю оператор с двига и раз. Поэтому у меня каждый раз будет
сохраняться вектор в этом пространстве, потом я возьму сумму, сумма векторов из-под пространства
тоже лежит под пространстве, поэтому мы получаем, что умножение на любой элемент кольца оставляет
нас внутри этого кольца, значит мы получаем в обратную сторону включение. Итак, мы доказали вот
такое интересное свойство. Причем, заметьте, что я на самом деле специфику модуля 2 здесь не
использовал. То есть, если вас интересует, представьте, что вас интересует над r под
пространство, 9-мерного пространства, которое замкнуто относительно циклических сдвигов. То есть,
если входит вот x1, x2, x9, то x2, x3, x9, x1 тоже входят. Это обязательно должен быть идеал только и того,
что у вас вот здесь будет не поле из двух элементов, а поле действительных чисел. И алгебрические
свойства у таких колец будут разными, потому что многочлен один и тот же x степени n без единицы,
но в разных, над разными полями он будет раскладываться по-разному. Но, в принципе,
циклические пространства иногда бывают нужны и для r, они ищутся примерно таким же способом.
Таким образом, мы видим, что то, что нас интересует, вот это такая довольно симметричная
конструкция, но теперь я хотел бы немножко конкретизировать, какие вообще бывают циклические
коды. Первое замечание, давайте я его где-нибудь здесь напишу, rn кольцо главных идеалов. Это не
столь очевидно, потому что оно не является эвклидовым кольцом, но у нас есть сюръективный
гаммарфизм. Канонический гаммарфизм, это же кольцо вычетов, есть канонический гаммарфизм из кольцам
многочленов с коэффициентами из поля из двух элементов наших, кольцо rn. Он сюръективный,
если у меня здесь есть какой-то идеал, ну давайте я его как-нибудь фи обозначу, прообраз этого идеала
тоже идеал, и он порожден каким-то одним многочленом, и тогда уже нетрудно доказать,
что g, поскольку это сюръективный гаммарфизм, порожден образом этого многочлена. Это легко
проверяется обычными вычислениями. Таким образом, первое наблюдение, которое можно сделать,
циклический код еще лучше, чем просто линейный. Линейный код мы матрицей должны задавать,
а здесь мы можем задать, я сейчас попробую правильно написать, но если не получится,
я поправлю в следующий раз. Смотрите, как я думаю, что вот я написал двоичное слово длины 15. Оно
задает некоторый циклический код. Каким способом? Ну понятно каким. Я буду брать просто все циклические
сдвиги этого вектора и их сумму. Другими словами, я могу сказать так, у меня есть многочлен единица
плюс 1, 2, 3, 4, x4, x5, x7, x8. И я порождаю этим многочленам, точнее классам вычетов в кольце
вычета, вот таком циклическом кольце, когда x15 равняется единице, я порождаю идеал. То есть
беру все кратные этого многочлена в этом кольце вычета. Не в кольце многочена, в этом кольце
вычета. И это то же самое, как я только что показал, что суммы циклических сдвигов такого кольца,
такого вектора. То есть совсем хорошо. У нас порождающая матрица совсем простая. Она вот,
она вообще задается даже не матрицей, а вот одной строкой. Это инженеров вообще приводило
в бешеный восторг, потому что нужно еще меньше радиоламп. Но, конечно, совершенно непонятно,
какая размерность и какое кодовое расстояние у такого кода. Вот это тут нужна еще математика.
И для начала давайте докажем такую лемму. Если у меня есть идеал в кольце Rn, то существует
делитель многочлена х-1 такой, что он порождает тот же самый идеал. То есть когда эта лемма очень
ограничивает нас в количестве разных циклических кодов, в сущности мы должны посмотреть, какие есть
делители у многочлена х-1. Вот только они порождают, могут порождать какие-то разные коды. Все остальные
многочлены будут порождать что-то то же самое. Ну, доказательство на самом деле очень простое.
Смотрите, давайте возьмем наибольший общий делитель fх в n-1-1.
И тогда f делится на g с тильдой и дополнительный делитель как раз вот тот самый g. Почему? Потому
что я хочу сказать, что g с тильдой обратим в нашем циклическом кольце. Почему он обратим?
Потому что он взаимнопрост с x в степени n-1. Ой, только тут все-таки g, да, я извиняюсь,
а вот g с тильдой тогда взаимнопрост. То есть я беру наибольший общий делитель xn-1 f,
а g с тильдой это дополнительный делитель. И вот дополнительный делитель взаимнопрост
с x в n-1. Почему? Потому что, ну, смотрите, f это g с тильдой g, а x в n-1 это что-то то же g,
но тут что-то написано, какой-то h. Вот это вот должны быть взаимнопростые,
потому что g это наибольший общий делитель. Ну, значит g с тильдой будет
взаимнопрост с xn-1. Непонятно, да? Это тонкое место, давайте его сейчас обсудим более аккуратно.
Значит, вот смотрите, я нашел наибольший общий делитель fxn-1-1. Тогда, вот если я смотрю на g с тильдой,
предположим, что g с тильдой xn-1-1 имеют общий делитель, но тогда g не будет наибольшим
общим делителем, потому что этот делитель могу убрать, добавить в g. Значит, они должны быть
взаимнопросты. Но вот это вот означает, что, вот как раз вот это, что g с тильдой обратим. Это общее
свойство, раз с g с тильдой взаимнопросто, мы это уже много раз разбирались, тогда у нас есть
какой-то многочлен h1, умноженный на g с тильдой, плюс xn-1 умножить на h2, так что это равняется
единице, и мы видим, что по модулю многочлена xn, xvent и минус 1, g с тильдой имеет обратный. Но
общая наука, которую мы изучали, говорит, что f отличается от g на обратимый элемент кольца,
но тогда идеалы, которые порождают, совпадают. Умножение на обратимый элемент не меняет
идеала, мы это обсуждали. Ну и все, мы получили вот это вот утверждение. Оно мало того, что
ограничивает репертуар циклических кодов, но оно и позволяет очень быстро найти размерность
циклического кода. Вот пусть у меня есть теперь делитель какой-то, то есть если я циклический
код представляю не просто идеалом каким-то, а идеалом, порожденным делителем xvent и минус 1,
предыдущая лемма гарантирует, что так всегда можно сделать. Тогда, значит, вот у нас код,
он порожден этим делителем, когда размерность равна n минус степень вот этого вот самого
делителя. И это тоже очень легко. Ну смотрите, я опять рассматриваю дополнительный множитель,
вот это вот, это на самом деле степень дополнительного множителя. По обычному
свойству степени. Тут степень n, тут степень g, плюс степень g с тильдой. Предположим,
что у меня есть два разных многочлена, таких что их степени меньше, чем степень g с тильдой.
Тогда давайте посмотрим на соответствующие элементы идеала. Я утверждаю, что они не равны.
Ну почему? Предположим, что они равны. Это бы означало, что h1 минус h2 умножить на g нулевой
идеал. То есть в кольце многочлена в это бы означало, что h1 минус h2 умножить на g делится на
x в n-t минус 1. Это g означает, что это нулевой. Но вот здесь степень меньше, чем степень
дополнительного множителя. Ну а здесь степень это степень g. А в сумме вот тут равно n. То есть
тут степень n, а тут степень меньше. Пришли к противоречию. Таким образом, я уже нашел ну вот
там два в степени n минус степень g различных элементов в моем идеале. Нужно доказать,
что больше не бывает. Это совсем легко. Предположим, что у меня есть какой-то
элемент из идеала. То есть кратный g с f. Я f могу поделить на g стильной состатком.
И тогда смотрите f g будет равняться q на g g с тильдой плюс r g. Но вот это g g с тильдой
это x в n-t минус 1. Это ноль в нашем циклическом кольце, потому что вот это произведение это
уже x в n-t минус 1. А у нас мы рассматриваем вычеты по модулю этого многочлена. Значит в кольце rn это
просто-напросто r g. То есть это ровно те многочлены, которые я перед этим построил, потому что нулевой или
в многочлен степени меньше, чем g стиль. Таким образом, вот это равенство доказано. Значит,
ну у меня время вышло, я подведу итог. Значит циклические коды мы с ними довольно хорошо разобрались.
Во-первых, чтобы их строить нам нужно знать, какие бывают делители у x в n-t минус 1. Во-вторых,
если мы это знаем, мы уже знаем размерность. Третий параметр, самый интересный, кодовое расстояние.
Вот с ним сложно. Общего хорошего способа найти кодовое расстояние для произвольного циклического
кода. Вот выписали мне вектор и говорите, а какое будет кодовое расстояние? Его нету. То есть вот такое
вот порождающее найти легко, потому что вы видите, нам нужно просто приймать алгоритмы вклида,
чтобы найти. Размерность находится быстро, а кодовое расстояние нет. Но в некоторых случаях
его удается найти. И вот про это я буду рассказывать в следующий раз. На сегодня все.
