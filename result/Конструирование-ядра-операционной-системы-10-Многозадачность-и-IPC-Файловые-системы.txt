Ну, у вас, почти у всех, я уже заработал user space, поэтому
мы продолжаем нашу тематику многозадачности и сегодня
у нас три небольшие темы.
В частности, мы помним, что из третьей лекции, что
ядро обычно запускает какой-то начальный поток, начальный
процесс, соответственно, это процесс init, например,
в линуксе, launch.de, например, в маке, ну и так далее.
Но это что касается первого запускаемого процесса,
у которого пит единичка, спецнур ядра, пит нолик,
но все остальные процессы должны быть как-то порождены
уже в рамках работы этого процесса init, поэтому мы
поговорим о том, как, собственно, порождаются новые процессы
в операционных системах и немножко поговорим про
такой механизм под названием fork.exe.
Затем мы поговорим о том, как процессы могут общаться
друг с другом, ну потому что системные вызовы у
вас уже работают, то есть процессы могут общаться
с ядром, но довольно часто мы хотим, чтобы процессы
могли общаться и между собой, поэтому речь пойдет
об IPC, ну или Interprocess Communication, как он может быть организован,
и мы приведем какие-то простые примеры, которые
будут понятны.
Соответственно, также после этого мы доберемся до
тех вещей, которые можно организовать поверх IPC,
и поговорим немножко о файловых системах, потому
что там буквально в следующей лабораторной работе у
вас будет, соответственно, реализована файловая
система в Neuterspace'е, поверх того IPC, который вы реализуете.
Это будет все, что будет в файловом системе, или будет
то, что будет в IPC?
Все.
То есть, ну, по операционным системам у вас, по идее,
курс обязанных систем должен быть.
Ну, так, что касается создания процессов?
Ну, я думаю, что про механизм fork.exec особо объяснять
там ничего не нужно, но все знают, как работает fork.exec.
Ну, на всякий случай как бы напомню какие-то там
вещи, то есть у вас есть некоторые там родители,
соответственно, этот родитель имеет там два системных
вызова, ну, соответственно, точнее, гидрой имеет два
системных вызова.
Родитель вызывает системный вызов fork, ну, понятно,
что он вызывает некоторую там функцию из стандартной
библиотеки, а эта стандартная библиотека уже там, через
сколько-то там подфункций, вызывает уже системный
вызов, задача которого сходит в том, чтобы породить
новый процесс, то есть процесс ребенка, который
будет отображать тот же самый контекст, что и процесс
родителя.
При этом, когда вы в родители вызовите fork, он вам вернет,
соответственно, PID того процесса, который вы породили,
то есть PID ребенка, а в ребенке он, соответственно,
вернет нолик.
Так вы можете отличить в своей программе, собственно,
кто вы после вызова fork, ребенок или родитель.
После того, как вы вызвали, соответственно, fork и оказались
в ребенке, вы можете заменить свое тело с помощью системного
вызова exec, в который вы передаете, соответственно,
путь к некоторому другому исполняемому файлу, и ваш,
соответственно, процесс заменяется на тот исполняемый
файл, который вы передали в аргумент exec.
Вы можете подождать в родителе завершения работы ребенка
с помощью системного вызова wait или wait PID, то есть когда
у вас много детей, то вы можете ждать какого-то конкретного.
Так же вы ребенка можете завершить или послать ему
сигнал с помощью системного вызова kill и в дальнейшем
управлять. Понятно, что exec при такой схеме вызывать
в целом не обязательно, то есть вы можете fork-нуть
родительский процесс и продолжить исполняться с тем
же состоянием, что и ваш родительский процесс.
Например, так могут работать некоторые песочники в
разном программном обеспечении.
Но, тем не менее, наиболее частый механизм реализации
схемы fork-exec, когда сразу после вызова fork возникает
вызов exec. Вопрос. Вот представьте, что у вас есть ядерный
вызов fork и вам предлагают написать exec в user space
самостоятельно. Как вы думаете, можно ли это сделать
и что для этого может понадобиться?
У вас есть системный вызов fork и вам предлагается
сделать вызов exec целиком реализовать user space
без поддержки идра.
Например, вам дадут вызов mmap или вызов mprotect.
То есть mprotect меняет permission, mmap мапит данные.
У нас есть истаграмма, мап мапит все фигменты.
Единственное, что нам нужно хранить тот код, который
это делает где-то в памяти. То есть, может быть,
попросить уйдра нового региона себе с правами сначала
на запись, потом поменять на выполнение. Перемешать
туда, даже в какой-то мантудово все это делать.
Переместить себя на лету, наверное, не очень получится.
Потому что там relocate придется обновлять, а у вас их нет.
Или переместить новый код.
Заланцировать новый кусок кода, сначала writable,
записать туда какую-нибудь функцию.
Но это если он position-independent.
Который это будет делать.
Ведь код своей программы более часть времени работает
по нормальному по своему интересу.
Вы имеете в виду, что взять некоторый трамплин,
разместить его в новом адресном пространстве,
и после этого этот трамплин будет копировать уже адресное пространство
целевого процесса. Ну да, можно, это действительно один
из сценариев. Второй сценарий просто задействовать islr.
То есть с помощью islr разместить новый процесс так, чтобы он просто не пересекался.
Ну если при этом новый процесс не position-independent?
Да, если новый процесс не position-independent, то да,
нужна схема с трамплинами.
Ну действительно, да, суть именно такая.
Поэтому, в принципе, exec вполне реализуется в user space,
но никто так не делает, потому что с органи удобно долго.
Можно вопрос все-таки?
Да.
Понятно, что сам по себе орг, в принципе, зачастую полезно использовать по идее,
но все-таки, если орг экземпляр, это такая частая инфляция,
почему в Linux это разбито на фрае, нет общего?
Как раз следующую фразу, которую я хотел сказать,
вот да, это замечательно, но так сейчас никто не делает.
Ну, формально на самом деле, формально child вот здесь, child вот здесь,
это клон parent, соответственно, формально определяет, что запускать parent.
Но это примерно та же схема программирования, что у вас есть, например, setJump,
longJump.
То есть, знаете же, вызовы в C там, setJump, longJump, они тоже возвращают разные
соответственно коды в зависимости от того, что произошло там.
Вы вернулись в эту точку или, соответственно, там вот сейчас
сохранили состояние.
И так, да, с памятью.
Правильно.
Соответственно, почему так никто не делает?
Вот сразу.
То есть первое, грубо говоря, после того, как вы поняли, что да,
это с одной стороны действительно очень удобно, делает там безумную гибкость
в вашей операционной системе, но это дорого.
Поэтому первое, что, собственно, предложили, это использовать механизм copyonwrite.
То есть, механизм copyonwrite, встраиваясь в fork.exe,
работает по следующему принципу, что вот у вас есть адресное пространство
там родителя.
То есть там какое-то адресное пространство там родителя.
И мы порождаем адресное пространство ребенка.
При этом, соответственно, все права на запись, вот в момент вот этого порождения,
они отбираются и, соответственно, у родителя, и у ребенка.
То есть любое, соответственно, обращение на запись в память,
грубо говоря, ребенка или родителя, произойдет к пейчфолту.
То есть write это пейчфолт.
И в момент возникновения пейчфолта произойдет ленивое копирование.
То есть продублируется, соответственно, эта страничка.
И, к примеру, ребенка будет своя память, а у родителя своя.
Таким образом, в условиях, если ребенок мало изменяет память,
а это действительно так, то есть у нас часто очень используется сразу exec после вызова forks,
то такая схема достаточно неплохо позволяет ускорить, соответственно, процесс,
что у вас нет копирования, и позволяет уменьшить потребление оперативной памяти.
У родителя тоже отбираются права на запись.
Если на старой странице родителя, соответственно, окончится мусор,
окончится ничьи.
Почему ничьи имеют?
Если и родители копируют при записях, и ребенок копирует при записях.
Ну, у вас есть refcount.
Ну, да, можно сделать там...
Ну, нет, то есть они что-нибудь соберутся, чтобы на этой странице дальше уже ничьи.
Нет, нормальная реализация.
Если refcount, грубо говоря, copyonwrite страницы равен единичке,
то, соответственно, что-то копируют, просто изменили права на запись на эту страничку, и все.
Ну, как бы там, подсчет ссылок он всю жизнь работал.
Да, но, соответственно, родителю в момент, если ребенок заместил себя,
возвращаются его законные права, потому что refcount этих страниц стал, соответственно, единичкой,
потому что ребенок в этих страницах уже не владеет.
Но как мы, соответственно, видим, это с одной стороны действительно нам ускоряет процесс,
потому что нет вот этого безумного копирования всего адресного пространства,
но все еще есть накладные расходы, связанные с ссылками, есть накладные расходы, связанные с обработкой исключений.
Поэтому сейчас один из основных механизмов – это использование AVForg.
Там должно быть два прота. Есть prot shared, есть prot copyonwrite, что касается именно самого джосса.
Shared – это общая страничка в памяти, в которую имеет право обращаться в два разных процесса.
Это, соответственно, для обеспечения межпроцессных коммуникаций.
А prot copyonwrite – это, соответственно, как раз copyonwrite в момент, когда происходят записи в стране.
Возможно, лэзи. Ну, код refactorits, там все уже вспомнить.
Минус weight в смысле, как это, изменили этот rv битик, поставили туда 0.
Ну да, present, но, соответственно, не writable. Вспомним пейчфолтовский 14-й вектор на x86.
То есть нулевой битик у вас present. Первый битик – это запись.
Второй битик, по-моему, user. Еще один битик exec.
Возможно, порядок перекутал битов, но у вас, соответственно, есть такая штука, как error code.
И в error code у вас устанавливаются четыре основных битика.
Презент или непрезент. Была запись или не была запись, то есть чтение.
Соответственно, страницы обращались из пользователя или из ядра.
Ну, соответственно, здесь единичка, если user. И было ли instruction fetch.
Ну, я написал здесь е, но, по-моему, оно там вот так вот af написано.
Было ли исполнение страницы или это была операция чтения или записи.
И, соответственно, в коде пейчфолта у вас будет установлена такая вот маска.
И в дополнение к регистру CR2 я очень часто рекомендую смотреть,
какой у вас error code в пейчфолте, потому что он нам позволяет понять,
а что вообще произошло с операционной системой.
Что?
General protection – это, например, если вы вызвали какую-то инструкцию,
которую вы не имели права вызывать с текущим уровнем привилегий.
То есть, ну, немножко разные, грубо говоря, ректора и исключения.
Они схожи, но вот разные действия приводят к разному.
В принципе, есть процессоры, где используется одно и то же исключение
и в том, и в другом случае. Поэтому читайте даташит на свой процессор,
к которому вы работаете. Там будут приняты свои соглашения.
Соответственно, сейчас Copy&Write – это прекрасно, но есть более хорошее решение.
Есть, например, механизм VFork. Слышали когда-нибудь про VFork?
Отлично. Ну, если вы откроете стандарт POSIX, то сможете это найти.
И VFork отличается от FORK тем, что в момент, когда вы делаете, соответственно,
вызов VFork, формально поведение программы ровно такое же.
То есть, вам возвращают PIT вашего ребенка, в ребенке типа возвращается, соответственно,
в ребенке возвращается нолик, но по факту у вас не происходит никакого клонирования адресного пространства.
То есть, у вас просто есть полный доступ в адресное пространство родителей,
единственные стэки отличаются. И все, что вы можете сделать после вызова VFork,
это выполнить exec. Таким образом, не нужно реализовывать там ни механизм Copy&Write,
в общем-то, формально даже не нужно клонировать адресное пространство и порождать его в момент вызова VFork.
То есть, у вас на самом деле даже ребенок может быть порожден чуть позднее.
Соответственно, именно за счет VFork...
Нет, VFork работает точно так же, как FORK. Единственное отличие VFork от FORK заключается в том,
что любое обращение к глобальным переменным на запись является неопределенным поведением.
Да. По-моему, возможно, даже там есть ограничение на чтение.
Дальше должен быть сразу exec.
А строка?
На стэк, например, положите. Или, соответственно, по-моему,
на том все-таки можно на чтение к динамической памяти обращаться.
Можно перечитать. Перечитайте стандарт POSIX. Я сейчас не хочу вас просто обмануть,
а комплектную формулировку не воспроизведу.
Кстати, я на слайдах как раз не может быть изменено ребенком.
Скорее, с учтением все-таки доступно.
Соответственно, после VFork должен следовать сразу exec,
и тем самым мы можем не копировать адресное пространство водителя.
Замечательно. Но это не все.
Поэтому сейчас есть еще более хороший механизм, называется POSIX Spawn.
POSIX Spawn это примерно как в Индии.
Просто передали в качестве аргумента исполняемый файл, который надо создать,
и вам просто вернули PID того процесса, который создался,
и он сразу начинает пополняться.
Это самое простое и интуитивное решение, но к нему пришли не сразу,
потому что не было очевидно, что fork.exec как пара будет использоваться очень часто.
На тот момент, когда fork.exec проектировались, а это были еще до юниксовские времена,
Соответственно, оперативной памяти было не так много,
и не было понимания, что сразу после fork кто-то будет exec делать.
То есть вполне нормально было, что после fork выполнялся и другой процесс,
потому что это можно было использовать для генерации новых трендов.
Что?
POSIX Spawn?
Нет, это системный вызов.
На современных, соответственно, в маке, например, есть POSIX Spawn.
Должен быть.
Но, возможно, в линуксе реализован через fork.exec.
Но не хочу это же врать, потому что...
Может быть.
На маке системно.
Но формально standard POSIX не заставляет вас делать и то, и другое системным вызовом.
Достаточно просто реализовать то поведение, которое описано в стандарте.
И если это будет просто какая-то функция в системной библиотеке,
которая будет вести себя ровно так же, то вы выполнили это требование.
Хорошо.
Вот из этой картинки видно, что в отличие от последних двух,
у первого механизма copy-on-write еще дополнительно экономится память.
Да, она экономится исключительно на момент порождения пользовательского процесса клона родителя.
Но в целом экономия оперативной памяти – это достаточно серьезная боль,
которая есть при разработке библиотек.
Поэтому я, пользуясь этим случаем, все-таки напомню, что у вас в операционной системе
при порождении и при планировании процессов все-таки есть много механизмов
по оптимизации доступа к оперативной памяти, которые регулярно используются.
Про sloping мы, соответственно, помним.
Есть алгоритмы планирования третьего уровня,
которые дампят память на диск, когда реже используемый процесс не обращается к своей памяти,
а физическая память у вас закончилась.
Следственно, удаление копирования, подсчет ссылок.
Если мы действительно используем какие-то общие ресурсы, то регулярно используются техники риф-каунтинга,
которые, если объекты не изменяются, они могут вполне честно использовать общую память.
Например, сейчас это очень часто используется, например, в файловых системах.
Все современные файловые системы используют механизм copy-on-write.
То есть, когда сектор у вас дублируется только в тот момент, когда реально происходит запись,
из-за чего копирование файлов стало очень быстрым, но запись может стать в отдельных случаях более медленной.
Есть сжатие страниц.
Кстати, есть индивидуальное задание в джосе реализовать поддержку сжатия страниц, так же, как и sloping.
Соответственно, те страницы, которые используются реже, они могут сжиматься с определенным успехом.
Причем, если, например, известно, что страница там однородная, например, содержит только нули или только там эвки,
то, соответственно, можно просто использовать механизм удаления.
Копирование необязательно использует сжатие.
Например, в джосе есть такая оптимизация, то есть нулевые страницы, они копируются лениво только в тот момент, когда в них что-то записывается.
Точно так же с страницами, полностью забитыми единичными битами, например, shadow-память.
Про адрес Annotizer же помним. Есть, соответственно, теневая память.
В теневой памяти, если она poison, то там записаны все единички, все бит.
Точно так же можно, например, дарить копирование для такой памяти и тем самым сделать дополнительную оптимизацию.
Здесь, соответственно, кэши библиотек.
Ну, мы помним, что традиционными способами кэширования там все-таки являются два направления.
То есть это library, caching.
То есть когда кэшируется там некоторый набор системных библиотек.
И, соответственно, какие-нибудь системные вызовы.
Например, когда у вас отображаются какие-либо функции, например,
функции получения времени прямо в user space, например, через общую память с ядром.
Или какая-то информация о вашей платформе, например,
количество ядер, модель процессора и так далее, чтобы вам не нужно было за этим лезть.
Например, в маковском ядре это называется com.page.
В линуксовом раньше оно называлось com.vdso.
Сейчас как-то по-другому переименовали, но суть та же.
При этом мы, соответственно, помним, что вот эти вот вещи могут
приводить к негативным последствиям безопасности.
Помним, каким и почему.
Не только.
Можно риторически делать.
Нет, это проблема адресного пространства,
которое есть чисто в Винде, потому что там библиотеки по именам ищутся не по полным путям.
В том направлении говорите, хотя немножко не точно, но я на всякий случай напомню.
Когда мы делаем cache-библиотек общий для нескольких разных процессов,
то чтобы он, соответственно, мог быть общим,
потому что не весь код position-independent без релокаций,
чаще всего у вас там будут какие-то релокации,
то код придется размещать по одному и тому же адресу.
Ну простой пример, если у вас здесь, например, указатель,
который содержит указатель, например, на другую переменную,
то просто так отобразить в одном процессе эти данные по одному адресу,
а в другом процессе по другому адресу не получится, потому что указатель будет неверный.
То есть его нужно пропатчить, то есть исправить ему смещение.
А если его пропатчить, то не получится сэкономить оперативную память.
Поэтому, действительно, кэш-библиотек должен располагаться по одному и тому же адресу в процессе.
Ну с некоторыми оговорками, но в целом такая реальность.
И, например, в свое время, опять же, в макии,
когда с этой проблемой столкнулись, решили, ну окей,
мы возьмем и будем располагать кэш-библиотек по разному адресу каждую перезагрузку.
Отлично, то есть в каждой перезагрузке, соответственно, разные адреса.
И они, в принципе, эту проблему решили и до того момента как появилось что?
Как думаете?
Что?
Вот что у вас практически у всех есть либо на столе, либо в кармане?
Мобильник, правильно.
Очень все просто. Смотрите, когда вы переружаете свой мобильник, насколько часто?
Раз в месяц.
Соответственно, если я буду активно проверять в течение месяца какой-то адрес,
ну вот, грубо говоря, в течение месяца 30 раз у меня какое-то приложение упадет,
вполне есть шанс, что вы за эти 30 несчастных падений,
во-первых, половину этих падений не распознаете, подумаете, что операционка убила
просто из-за того, что там памяти не хватает, например.
А даже если и заметите, то вполне возможно, что вы это приложение не удалите.
А я, соответственно, на какой-нибудь 30 раз таки угадаю с адресом
и после этого, соответственно, смогу выполнить код на вашем устройстве.
Дестопные операционные системы перегружают достаточно чаще,
поэтому проблемы с тем, что, грубо говоря, устройства не перезагружают,
она есть, в принципе, и на десктопах, но не столь серьезно.
Догадываетесь, как можно обойти?
Обойти, потому что они не выгружают перед того, что перезагружают.
Обойти проблему, что система становится небезопасной при использовании шаред-кэша.
Ну, уменьшает кэши.
Дорого, очень дорого. Оперативной памяти не хватит.
Перезагружать насильно?
Перезагружать насильно, да. На самом деле, уже вчера предлагали насильно
перезагружать в 3 часа ночи, как винда устанавливает обновления,
после этого пользователь достает свой мобильный телефон,
у него там вкладочка была в браузере, которая закрылась,
у него там был какой-то любимый фильм, он тоже закрылся с потерей
там таймкодов, где он смотрел, и юзабилити от этого...
Да было бы дело в перезагрузке.
Ну как неявная перезагрузка? Вам придется...
Можно просто перезагрузить кэши библиотет, не все есть тема.
Да, но у вас процессы не смогут работать, вы не сможете...
Как грабочек электро в Java? Поставить систему на паузу, сделать что-то другое,
сделать грязное дело, разобновить процессы.
В Android, конечно, можно попытаться, но я вас уверяю, что даже в Android
огромное количество приложений, которые используют NDK, то есть
нативные, грубо говоря, куски кода, и даже для них все очень плачевно.
Даже для тех, которые NDK не используют, все очень плачевно там.
Сейчас у них увеличены указатели, что ли?
Ну в Java runtime куча указателей, и все их пропатчить я практически невозможно.
А можно сделать те страницы, на которых раньше был этот кэш,
специальными, ну, ловушечными, чтобы page vault, когда ловят по ним обращение,
он некоторое время менял указатели на правильные...
А какой указатель?
Ну не основание, page vault сейчас ловили под гунды instruction pointer
с таким-то этим, он лазит в тот код, и там батчит что-то.
Оно будет, во-первых, безумно тормозить, а во-вторых, пользователь выкинет телефон.
Потому что у него все-таки рандомно до что-то падает.
Нет, решение есть гораздо более простое.
Соответственно, поиск ISLR-смещения, то есть поиск смещения кэша-библиотек,
это фактически какая-то стохастическая атака.
То есть вы либо угадаете, либо нет.
То есть вы пробуете один раз, второй раз, третий раз, четвертый, пятый, шестой,
седьмой, восьмой, девятый, десятый.
О, на какой-нибудь пятидесятый попали.
Может даже быстрее, если у вас достаточно значный эксплуат.
Поэтому во всех случаях, когда вы будете обращаться к этому адресу,
у вас система будет падать.
Не система, а, соответственно, ваш процесс будет крашиться,
потому что вы обратились по неволидному указателю.
Как вы, наверное, догадались уже сами, что это не очень нормально,
что процесс за короткий промежуток времени регулярно падает.
Ну окей, соответственно, сделаем не один кэш-библиотек, а, например, два или три.
Соответственно, в нормальной ситуации используется один кэш-библиотек.
Если какой-то процесс начинает аномально падать, причем,
например, более пяти раз он упал, ну окей, взяли ему, перемапили кэш.
Да, этот конкретно один процесс будет тормозить,
потому что у него будет в момент его запуска создаваться кэш-библиотек.
Да, при этом увеличится, грубо говоря, в полтора раза потребление памяти.
Но конкретно этот процесс пострадает.
А как под знать, что это конкретно этот процесс?
Покрашим.
Не, ну в смысле процесс палта, чтобы он перезапустился, перезапустится,
может уже перезапуститься, может...
Ну если просто тот же типус моего палта,
то можно автоматически переменовывать.
То есть вы можете делать загрузки.
Нет, ну смотрите, как вы будете переменовывать приложения в Sandbox,
там iOS-устройство, например,
там у вас приложения устанавливаются по случайно сгенерированному пути
системой.
И соответственно они в этом своем контейнере ничего не могут поменять,
потому что их там изначально цифровой подписью всех зажали
и не дают запускать произвольно исполняемые файлы никакие вообще.
И возможностей проверить, ну типа без падения проверить
можно обязательно...
Нет.
Они не могут соответственно без отладчика
устанавливать хендлеры...
В Mac есть механизм там типа
официальных там IPC, которые позволяют вам делать
локальный отладчик внутри своего процесса.
И как раз соответственно недавно эту дыру закрыли,
в том числе из-за того, чтобы защитить вот этот механизм клонирования
соответственно адресного пространства.
Но как результат, соответственно пользователи сейчас в интернете воют,
что вот, вот, все плохо, Apple у них украл джеты.
А на самом деле Apple закрывал дыру в безопасности.
То есть про дескопные системы есть?
Ну дескопные системы перезагружают чаще.
То есть соответственно как бы там вектор атак немножко другой.
Что?
JIT, Injustice Time компиляция.
Ну он как бы всегда был там очень условно доступен,
но там были варианты типа там через хитрый entitlement его получить.
И они как бы у легальных пользователей там до сих пор есть.
А соответственно там вот пользователи там каких-нибудь там, не знаю там,
эмуляторов, например, они очень страдали,
потому что они там всякими хитрыми способами пытались сделать вид,
что они запускают локальный отладчик
и использовали там механизм типа установки брейкпоинтов
для того, чтобы делать себе джиты.
Ну как это, полагались на недокументированное поведение системы,
в ходе момента она перестала работать.
В браузере?
В браузере? Ну в браузере JIT есть, да.
Что?
Ну, например, какой-нибудь эмулятор, консоли.
То есть очень часто на мобильных телефонах там запускают какие-нибудь там эмуляторы там старых приставок.
То есть, да, эмулятор существовал в эмуляторе.
Да, например, сейчас даже существует, у меня даже на Эпаде стоит.
А можно еще раз, ну, во-первых,
в библиотеке, вот когда библиотеки начинаются,
он начинается по адресам кэшивать.
А Митя когда вызывает, вызывает эти код, ну да, он, конечно, да, выполняется.
А что, в чем вопрос?
Ну, при этом, если пользователь, ну, если программа кэшитает свою библиотеку, то она только подобрается кэш?
Нет, конечно, только системные. Понятно, что те библиотеки, которые представляют
использователям, они, соответственно, там по случайным адресам располагаются в момент запуска.
В этом как бы...
Сейчас, ну, вызов пункции библиотечной, например, он же должен быть как-то дойти до библиотечного кода.
В чем проблема дать возможность, ну, в чем проблема библиотечного кода?
Не от того защищаетесь, то есть тот человек, который пытается вас атаковать,
он не имеет полноценного контроля над, соответственно, вашим кодом.
То есть он получает там управление в виде там returner и end of programming.
Он не знает, где находятся какие функции и так далее.
То есть защищается не от тех, у кого там полноценная программа, которая может себя исполнять.
Вы договорились в сэндбоксе?
Ну, в сэндбоксе.
Я думал, что в сэндбоксе в плане, что может быть все приложение, в сэндбоксе весь процесс,
автору процесса доверия нет и все такое.
Ну, автору процесса доверия нет и все такое, но как бы от авторов в данном случае.
Вот конкретно этот mitigation, он не от автора приложения.
Нет, просто газетина не вполне понятна.
Понятно негодование пользователей по поводу того, что это закрыли, потому что закрыли,
а вектор атаки для требующей уже наличия уязвимости в другом месте.
Ну, так это всегда так.
Нельзя защититься от конкретных уязвимостей, которые еще не публиковали и о них не сообщили.
Но можно закрывать классы атак, а посредством добавления mitigation.
Ну, в смысле не прям закрывать на 100%, но, грубо говоря, усложнять их эксплуатацию.
Ну, именно, что это кого-то решают реальные печи, которые они используют,
ради такого вероятностного усиления защиты.
Да, и на самом деле оно все так.
Усиление многих пользователей, это может быть не такое.
Они могут быть негде.
Ну, некоторые пользователи, да, но чаще всего в таких ситуациях
недовольных пользователей меньше доли и процентов.
То есть, как бы, ну, сколько есть пользователей, у которых есть developer ID,
которые, соответственно, там запускают какие-то там собственно собранные программы.
Ну, это всегда третий вопрос.
Поэтому главная задача не добавлять что-то новое и небезопасное.
Для этого, как раз, собственно, и есть в командах архитекторы
по информационной безопасности.
Они там в первую очередь должны оценить, собственно, то, что фича,
которая реализуется там в каком-то конкретном целевом продукте,
она не нарушает безопасность, собственно, всех этих целевой платформ.
То есть, ну, вот как раз вы только что назвали одну из служебных обязанностей
собственно, безопасников в команде разработки.
Кстати, вот то, что приложение пользовательские, наверное,
на иконе могут вызвать, вот, куда-то их...
Да.
Вот в нем будет JIT или не будет?
Будет.
А как?
Ну, специальные там entitlements или там специальные сервисы для этого есть.
Ну, это же как бы какие-то там устроения для приложений или он...
Нет, он как в шаре-то там кэша находится, там феймворк.
А, и он как бы...
Нет, ну, JIT никому не запрещают использовать.
Если вы там, грубо говоря, сказали, что вам нужен, грубо говоря, вот кит,
то, соответственно, у вас внутри вот кита будет JIT.
Ну, при этом, если я там использую JIT, то, соответственно,
у вас внутри есть entitlement?
Нет, да, если у вас есть entitlement.
Там есть специальные entitlements на JIT.
Что?
До сих пор?
Да, до сих пор, до сих пор.
И да, это как перемышление?
Что?
И да, это как перемышление?
Типа того, да.
Вот.
Другое дело, то, что просто у вас может ревью не пройти приложение,
грубо говоря, вы используете JIT не по назначению.
Типа нельзя его использовать, кроме как...
Но вот там браузер, например, можно.
Вот.
То есть тут как бы все достаточно.
Не очень хорошо сделано.
Не очень надежно, точнее.
Так.
Ну, соответственно, мы немножко отвлеклись, но
в целом
поняли, как
нуждаются, соответственно, современные процессы.
И в дальнейшем как бы наша задачка
понять, как вообще эти процессы
могут общаться.
Ну, соответственно, там
простой пример,
как реализовать там
коммуникации между двумя процессами.
Ну, представьте, что там у вас есть
процесс, грубо говоря, там
P1
и процесс P2.
И они хотят
передать друг другу какое-нибудь сообщение.
Ну, например, там строчку
размером 256 бай.
Мы знаем, что
там над нами
есть
некоторый kernel.
То есть ядро, находящееся на нулевом
уровне привилегий.
И мы с ним можем, соответственно,
общаться в помощи системных выборов.
Ответственно, простейший
пример, там
реализация APC
может выглядеть как.
То есть добавляем некоторый системный вызов
в ядро.
Ну, например, тут
send,
тут receive.
В разных операционных системах
по-разному, не так важно.
И, соответственно,
передаем сюда
какие-то данные.
А вот здесь эти данные получаем.
Ну, как это может выглядеть?
Соответственно, здесь будет
некоторое копирование
в
ядерную память.
И, соответственно, здесь
копирование
еще одно
в
целевой процесс.
А если P2 вызов принять эти данные?
Ну, он вызов
receive.
Если он не вызывает вызов receive,
то, соответственно, хорошая реализация
будет делать тайм-аут.
На пасуху.
То есть вы можете сказать, что
P2 не готов, и, соответственно,
если он не готов в течение какого-то тайм-аута,
то просто вернуть управление
отправки
с некоторым сообщением.
А какой имитет делает этот тайм-аут?
Ну, то есть от задачи.
Ну, зависит от задачи.
В плане доставки
вызывающего процесса.
Ну да.
Обычно это вообще синхронно делается,
поэтому как бы отправили,
и, соответственно, дальше смотрите, ждете или нет.
То есть это как бы там вот
крутейшая демонстрация, она типа блокирующая.
На деле, соответственно, отправили,
и дальше потом ждете, получили или не получили.
Ну, в случае, например,
там real-time операционных систем, у вас есть расписание,
соответственно, вы знаете, что он будет готов принять.
В случае там
операционных систем общего назначения,
ну, там
с долей вероятности обслуживающий сервер,
соответственно, у него будет время
служить в ваш процесс. Например, там
простой пример IPC,
ну, у вас какой-нибудь графический сервер.
То есть у вас графика, например, работает
на линуксе или на маке, соответственно,
у вас есть меркоплята шейдеров какой-нибудь
внешний.
Соответственно, вы ему отправляете IPC запросы,
чтобы он там собрал вам шейдеры.
Например.
И, в принципе, ну,
гарантируется, что
он будет достаточно быстрым, потому что у вас
интерфейс не очень тормозит.
А при этом многие ковы Uber,
там Uber в ABC не бывает?
Почему? Бывают.
То есть вот здесь, в ядре, например,
может быть память.
Нет, то есть можно быть спокойной реализацией
без стейм-аунта, что просто отправил,
и дальше все, и игнорируешь это, а она лежит в буфере
до сих пор, пока не закончится очередь.
Ну, то есть, например,
вот то, что вы сейчас описываете,
например, это так работает,
с чем,
как говорится, работает, с тем могу назвать,
например, так работает портуярник 153
в авианике.
И в очереди гарантируется
некоторый буфер
определенной длины, который, соответственно,
записывается в конфигурации,
соответственно, под него резервируется память
и любой
участвующий в
передаче, соответственно,
клиент, ну, то есть, грубо говоря,
может в этот буфер положить сколько-то данных
до того момента, когда этот буфер не заполнится.
Соответственно, если буфер заполнился,
то ему скажут, что, извини, места нет.
А, соответственно, как только
для этого буфера что-то прочтут,
то можно будет класть еще.
Ну, простой пример, то есть, как бы такой тоже есть.
Это такой
самый простейший пример
IPC и
ну да, то есть, действительно
в каких-то там
операционных системах, даже, по-моему, в Android
какое-то время так делали.
Именно так и было, но в целом
в принципе сейчас
так опять же никто не делает,
потому что, ну, вот здесь как раз есть хороший
тезис, что
IPC должны быть быстрыми.
Ну, понятно, что скорость там
IPC, она там в целом
может быть описана
ну, давайте, тремя тезисами.
Соответственно, первый тезис
это минимальное
количество копирования.
То есть, вот мы видим, что здесь копируются данные
в ядро, после этого копируется обратно
user space.
Это дорого.
Зачем делать две копии?
Чаще всего еще вот тут будет копирование,
потому что тут еще упаковка будет какая-нибудь.
Соответственно,
второй тезис
это
минимальное
переключение, собственно,
контекстов.
То есть, ну, вот в данном
случае
представьте, что у вас
ядро тупое,
и оно может там, грубо говоря,
находиться либо в адресном пространстве
процесса P1,
либо в адресном пространстве
процесса P2.
Если вот ядро действительно настолько тупое,
то вы не можете
просто взять, например,
и сразу скопировать данные
в P2. Вам придется в еды иметь промежуточный
буфер.
Вы представляете, какие-то накладные расходы будут?
Нет, ну, просто представьте,
для того чтобы передавать группу гребайт вам
нужно делать contact switch.
К этому мы сейчас
подбираемся.
То есть, примерно так
действительно делают
современные перезвоночные системы.
И, соответственно,
там третий момент
это
быстрые сисковые.
Ну, то есть, помним предыдущую лекцию, действительно, там
существуют во многих процессорах аппаратные
возможности по ускорению системных вызовов,
и если они есть, то их неплохо
применять, потому что они, соответственно,
ускоряют сам процесс
перехода туда-сюда.
Сюда же я, соответственно,
еще не добавил. То есть, кроме переключений
контекста, вам еще,
соответственно, нужен
ну, желательно, скажем так,
быстрое
перемапливание, соответственно, изменение
отображения, если,
соответственно, оно используется
при реализации системных вызовов.
Ну, это уже одна из этапов.
Как,
собственно,
делают это в реальности?
Ну, там, например, одна из оптимизаций,
которая, ну,
вы уже начали про нее догадываться,
связана с тем,
чтобы
второму процессу просто
отдать ту память, которую вы, собственно,
хотите ему отправить.
То есть, представьте, что у вас вот есть некоторая страничка
с данными,
там,
буквера messageM,
и
вы хотите ее передать
P2.
Мы помним, что в случае, там, ну,
например, с страничными ММУ,
такими, как используется в x86
или в арме, у нас достаточно
просто переделать
отображение виртуальной памяти.
Соответственно, мы можем
просто, например, взять
вот эту самую страничку
с данными, которые хотим отправить,
и отобразить ее
в адресное пространство
P2. Ну, понятно, что вот это ядро
делает.
Правильно.
Далеко не всегда.
И именно поэтому, например, в Android
очень страдают с IPC,
потому что они не могут сделать оптимизации
вот такого рода.
То есть, там все равно возникает копирование.
Но
в целом есть
как бы некоторые особенности
в том плане, что когда
вы передаете вот какие-то данные,
то это вот сейчас я сказал,
что мы хотим передать строчку, там, 256 байт.
На деле,
когда вы хотите передать какие-то
данные, это может быть какой-то более сложный объект.
Потому что вашим
программам,
вашим, соответственно, приложениям
чаще всего хочется
передавать не голые байты, это мы привыкли
писать на C, то есть мы
как системные программисты мыслим, грубо говоря,
в байках. А
условно там
какой-нибудь прикладной программист будет,
ну вот я хочу передать текстуру.
Или там я нарисовал какой-нибудь
виджет, я его
хочу туда передать. То есть это какие-то
сложные, соответственно, объекты.
И поэтому
вот в момент, грубо говоря,
вызова там вот этого IPC
у вас еще будет там некоторая
сериализация,
то есть или упаковка, собственно,
того объекта, который вы хотите передать,
чтобы его можно было передать вот
через механизм. И, соответственно, вот
эта упаковка уже как раз она может быть
механизирована так, чтобы размещать
объект
в какой-то выровненной памяти
и тем самым, соответственно, сделать его удобным
для передачи.
Здесь есть
некоторый нюанс, например,
связанный
с тем, что вот мы сейчас
сделали отображение вот этого
объекта сюда.
И
если у вас процессор там
многоядерный, например,
или просто пройдет достаточное количество времени
и мы снова переключимся на P1,
то, например, P1
будет продолжать иметь доступ к этому объекту
и может, например, его изменить.
А P2 будет его в этот момент
читать.
Да, но тут как бы, в принципе, два пути.
Ну, там один путь — это, соответственно,
например, копию онрайна делать.
То есть он возьмет, просто продублируется.
Соответственно, второй путь — это можно
просто взять и отобрать.
Ну, то есть
передать вот это владение
этой страничкой, собственно, к тому
процессу, который P2.
Ну, например.
Ну, с другой стороны, вы упаковали
и зачем вам эта страница?
Как обычно, да.
Ну, там же в OpenGL
это обретовывается постоянно, там,
16 секунд, наверное,
то передавали бутерброд.
В OpenGL
все еще зависит
от того, какая у вас архитектура
GPU. У вас же там
может быть
передача в видеопамять
GPU,
а может быть Unified Memory.
И GPU может просто там
получить прямой доступ.
А еще у вас там DMA есть.
Ну,
как это, драйвера
GPUшек достаточно
сложные, достаточно
закрытые.
Я вам, наверное, я не являюсь
перспектом по драйверам GPU
и, наверное,
хорошо ответить на ваш вопрос не смогу.
Вот это будет, наверное,
такое наиболее честное.
Но
в принципе в GPUшках
просто разные модели памяти используют
и там оптимизации
могут быть достаточно
там дичайшие
в зависимости от того,
какой там API используется.
Вот.
Вот.
Так.
Мы, кажется, немножко откатились.
Вот.
Соответственно в JOS
используется там очень простенький
механизм IPC.
То есть, который
работает ну вот
по принципу обеспечения
общей памяти. То есть
в случае с JOS
у нас нет тайм-аута.
Соответственно и нету многопроцессности.
Поэтому решается проблема то, что
тот, кто отправил, может сообщение
изменить до того, как, собственно, его прочитает
процесс, который
его, собственно, принят.
Но
в целом там механизм довольно простой.
Выделяется
некоторая страница общей памяти.
В эту страницу копируются какие-то данные.
И в дальнейшем
между процессами происходит обмен.
Ну, такой компромиссный и простой
вариант организации IPC,
который в целом там близок
к тому, что можно встретить
в других системах, ну если
в очень упрощенном виде.
Соответственно там недостатки, которые очевидно там
решены в
взрослых системах, это там нет
тайм-аутов и, соответственно, там
размер ограничен одной страницей.
Но в рамках индивидуальных заданий
это случается.
Вот.
Что касается
IPC,
то это вот там
такой механизм, который я описывал,
это лишь там один из способов IPC.
То есть, ну, вот один из там способов, который
организуется через там оперативную память.
То есть, на рамках там
стандартов там того же
POSIX у вас там есть, например,
там ITC через файловую
систему, там всякие именованные
каналы, неименованные каналы, там
сетевой стэк, там те же
колокиты, вот, там
очереди сообщений, сигналы,
то есть, в общем-то, выше
крыши. То есть, вы используете те
механизмы IPC,
которые вам, собственно,
удобнее для конкретной
задачи.
В принципе,
как это главное, наверное,
там вот, что можно
провести как бы черту над всеми этими
способами IPC,
это
в том, что они как бы
должны быть
как бы, ну, либо legit,
либо там, наверное,
вот так вот, типа
authenticated, в смысле
авторизованные. Потому что
если
у вас два процесса
могут общаться друг
с другом, то, соответственно, там
целевая платформа или целевая операционная
система должна об этом, по крайней мере,
знать и, соответственно, выдать на это
разрешение. Ну, там, как
пример,
можно, например, организовывать IPC
спекулятивной атаки,
ну, или через микроархитектурные баги.
И вот
такие виды IPC, они
чаще всего
не являются способами IPC по назначению.
Простой пример,
недавно
вышел же M1,
в М1 обнаружили один
из регистров, который там не чистится
при переключении контекстов.
В результате два произвольных процесса
могут класть в этот регистр, он
записываемый прямо из юзерспейса,
могут записывать какие-то данные
и, соответственно, другой процесс
может эти данные считывать.
Вполне себе неплохо работает.
Да, это
про регистр, грубо говоря, просто забыли.
То есть, ну, так случается.
Можете
загуглить там
CVS.
Я конкретно имени не назову,
но там, по-моему, какая-то статистика просто
накапливалась процессором.
Да,
то есть там вполне себе можно было
использовать какие-то циклические коды, которые
вам гарантированно позволяли
убедиться, что данные, которые
вы туда записали, они не повредились.
И достаточно такой быстренький канал
обмена данных.
Насколько я помню, сейчас уже все починили.
То есть, ну, просто надо было
убрать доступ
от операционной системы.
И сейчас
уже, в принципе, все хорошо. Но, как пример,
то есть, если у вас
есть какие-то баги
либо в ядре, либо
в
собственно, в вашей
микроакферитуре, в оборудовании,
все эти вещи могут быть использованы в ротифаз.
И, соответственно, если будут общаться
процессы, которые там
не должны друг другом общаться, то станет
неплохо. Ну, представьте
такой пример. Есть
какое-нибудь там приложение
вредоносное, которое запускается в песочнице.
Соответственно,
с счет того, что оно запускается в песочнице,
соответственно, у него нет возможности
навредить вашему целевому
устройству. То есть, например, оно своровало
какие-то секреты, но оно их не может никуда передать.
А есть, например, другое приложение, например,
браузер, который может общаться там
с интернетом. И
в браузере, например, есть специальный
бэкдор, который там
готов по каким-то скрытым каналам
принимать сообщения
и их передавать в
сеть по нужному адресу.
При этом сам браузер не занимается
никаким воровством, потому что у него
на это прав.
Поэтому такие атаки вполне себе используются,
и вас, как разработчик
операционной системы, нужно грамотно
достаточно там
любиться в том, что грамотно организована архитектура.
Да, по-моему, это мы исправили уже.
Там она и должна чистить.
Я не уверен, что там...
Нет, там вполне
возможно, что данные под
что-то просто используются, но, по-моему,
мы уже исправили.
Можно будет подробнее почитать.
То есть бывают ситуации,
когда действительно там
записать какие-то данные нельзя
без
повреждения каких-то там
внутренних структур, но это не в данной
ситуации. Там, скорее всего,
были не очень приятные
последствия для производительности.
И, как бы, видимо,
авторы посчитали, что на эти
жертвы производительности никто не пойдет.
А там, по-моему, просто нормально
все и никаких проблем в производительности не было.
Соответственно, что касается
IPC, то
в нашем случае мы будем использовать
IPC для
организации доступа к
файловой системе.
Ну, по идее, как
выглядит классическая файловая
система, вы там плюс-минус
должны знать. Я, как понимаю,
не вполне знаете, поэтому
мы, наверное, немножко здесь остановимся.
Ну, соответственно, здесь
есть классическая
схемка, когда
у вас здесь может быть какой-то
физический носитель, например,
MVME диск какой-нибудь,
SATA диск,
флешка,
неважно. То есть фактически некоторые устройства,
которые являются
накопителем данных, может быть даже
оперативной памяти.
Соответственно, далее
от этого устройства
до пользователя,
который является потребителем
файловой системы, то есть является
человеком, который
будет с ней взаимодействовать,
есть чаще всего
цепочка, как минимум, из трех
оплов, то есть из трех драйверов,
которые
от каждой отвечают за свою
знаменность. Ну, вот как пример,
первое, что она встречается,
это некоторый блокчный драйвер.
Представляете, как работает блокчный драйвер?
Наверное, он как-то оставляет доступ к носителю
в каком-то ладжу уровня. Правильно.
Соответственно, действительно,
у блокчного драйвера
задача предоставить
интерфейс, вида
чтения, соответственно,
запись к
нашему носителю.
Соответственно,
блокчный драйвер
на той и собственной блокчинке работает блоками,
потому что каждый отдельно
взятый носитель, он может
не иметь
возможности писать, например,
по одному байту.
То есть стандартные, грубо говоря, особенностью
каждого носителя это
сектор размером.
Ну, это
типичные значения, которые
можно встретить.
То есть 512-4996 бай.
И именно примерно с такой гранулярностью
вы можете выполнять
атомарные операции с вашим
физическим носителем.
Ну, хорошо если атомарными,
потому что
здесь, например, может быть какой-нибудь кэш,
и этот кэш окажется
энергозависимым.
Выключили питание и выяснили, что
те данные, которые вы записали, они
остались в кэше.
Отключение питания, соответственно,
от кэша, собственно,
эти данные потерял, и у вас оказалась
файловая система в каком-то неконсистентном
состоянии.
Ну, это там сильно... Что?
Ну, для ускорения.
Да.
На самом деле, все достаточно
не так плохо.
Хотя, как бы, на 100%
быть уверенным,
что у вас такой проблемы нет, можно только отриверсить
прошивку своего SSD, например.
А это довольно долго.
Ну, я здесь могу
сказать, что просто
некоторые проблемы
можно решать на разных уровнях.
То есть, мы как это... Помним про
закон сохранения боли.
Вот, соответственно, боль можно передвинуть
из одного места в другое место.
Например, там, не знаю, ups поставить.
Как в свое
время
был у нас студент, его, собственно,
на защите спрашивали,
а вот если у компьютера
отключится питание, то что надо делать?
Подумал, подумал,
ups надо поставить.
А если
отключится питание,
его там долго не будет.
Побольше ups надо будет поставить.
А если
прям совсем долго не будет,
ну, еще больше ups
нужно будет поставить с дизельными
генераторами.
А там
штуки-реакты, короче, маломощные,
которые поддерживаются
абсолютно долгое время,
можно такое поставить. Можно такое
производство ракетом
как раз.
Здесь, скорее, просто
суть в том, что
не нужно ограничивать
свою фантазию
в рамках применения
единого, некоторого архитектурного
паттерна при решении какой-то конкретный
проблем.
Соответственно, на том мы как бы здесь
и сидим, что
даже одну и ту же проблему
можно решать разными способами
и при этом достигать там разной эффективности.
Соответственно,
блокчный драйвер вам предоставляет
чаще всего там по-секторное,
атомарное. Если там
брать там современные системы,
то там побайтовое, не атомарное
обращение к
вашему физическому носителю.
И
на самом деле, вот здесь
нарисован один блокчный драйвер,
но нередко
у вас их больше.
Догадываетесь, почему?
Нет, нет, нет.
В смысле один в рамках одной цепочки.
То есть понятно, что вот это описан
какой-то некоторый инстанс.
То есть грубо говоря, там
один физический носитель,
такая цепочка, то есть понятно, что
в блокчных драйверах для разных
носителей может быть больше.
Нет, это просто
примеры популярных размеров
секторов на диске.
Не нужно брать, что
блокчный драйвер может
работать вот только с такими размерами
и не с какими больше.
То есть тут на самом деле
просто вот некоторый пример чисел.
Вот это уже ближе.
Для чего?
Потому что
блокчный драйвер
вот это уже ближе.
Для чего это может использоваться?
Нет, быстрее не будет у вас стерилизации.
Разные разделы.
Соответственно у вас диск может
избиваться на разделы там, ну или на
контейнеры, и соответственно в зависимости
от того, как именно
устроена геометрия вашего носителя,
соответственно может быть там
еще несколько, грубо говоря,
блокчных драйверов.
Соответственно каждый
свой раздел
жёсткого диска,
твердотельного накопителя, неважно,
который фактически занимается
тем, что транслирует
координаты, транслирует геометрию,
то есть
добавляет необходимое
смещение к
этим запросам и обращается
к родительскому драйверу.
Это сильно упрощает
написание некоторого кода
для того же драйвера файловой системы,
потому что вам не нужно
постоянно держать в уме, что вот мой раздел
от SIG до SIG достаточно считать,
что у вас там
мои данные от нулевого там, грубо говоря,
сектора до такого-то, просто этот нулевой сектор
он на самом деле вертолетний.
Вот.
Это что касается блокчного драйвера.
После блокчного драйвера чаще всего
то есть у вас идет
сам непосредственно драйвер файловой системы,
и драйвер файловой системы там
реализуется поверх
классических там, грубо говоря,
интерфейсов блокчного драйвера
и представляют уже там такие
соответственно там
сервисы соответственно, как там
типа open
ну в смысле
там для директории
соответственно там
read,
write, ну в смысле в рамках там
некоторого файла, там соответственно
может быть там какой-нибудь лист,
то есть грубо говоря
прочитать содержимое директории
и так далее.
Соответственно
этот интерфейс
он определяется
некоторым
компонентом, который называется
виртуальная файловая система, или иначе
VFS. Слышали
про VFS, я думаю.
Ну то есть
в операционной системе присутствует
такой компент, как
виртуальная файловая система,
к которой подключаются
соответственно различные драйверы
файловых систем.
Ну например там может быть драйвер
какой-нибудь там X4, там NTFS
и так далее. И каждый соответственно
драйвер, он может реализовывать
там некоторый понятный
набор системных вызовов и
дерг, ну не системных вызовов,
оговорился, соответственно, ну
понятный набор интерфейсов,
который
может использовать виртуальная файловая система
для того, чтобы
соответственно
самостоятельно уже обеспечить
там некоторый доступ к файловой системе
для пользователя
через там отдельно взятые
стенные вызовы.
Для чего это нужно? Ну это нужно
в первую очередь для юнификации,
то есть ну например мы все знаем,
что там в Unix
файловая система там, она выглядит
как некоторое там дерево
фактически. То есть есть некоторый корень
там, а здесь там может быть
там, грубо говоря,
разные директории,
при этом соответственно эти директории могут быть
реально
подмонтированными другими разделами
собственно другими файловыми системами.
То есть
иерархичное представление.
Для VFS это в целом
не важно, потому что VFS может
по-разному маппить вас
к драйверам
файловой системы.
Но в целом это такой наглядный пример,
от чего
нужен VFS.
Кроме этого соответственно здесь могут быть
различные кэшей,
соответственно там всяких
high-node и прочих
вещей, которые
вам позволяют там
ускорить поиск, ускорить соответственно
чтение. Любая там
файловая система, она
характеризуется фактически
некоторыми там лимитами,
то есть там лимит вложенности, например,
лимит длины пути.
И соответственно
вот тут
и тут
эти лимиты должны
быть согласованы,
потому что
есть лимиты, которые устанавливает
там операционная система, есть
лимиты, которые там
дополнительно возникают
при доступе
к файловой системе, соответственно нужно
эффективно взять наименьшие из них.
Что вот в этой
классической схеме
скажем так не очень хорошо?
Есть мысли?
Вот эта вот красненькая
это то, что
чаще всего вот это все находится в ядре.
И как раз вот это
на самом деле это не очень хорошо.
Не очень хорошо, потому
что мы крайне
увеличиваем соответственно
поверхность атаки,
то есть крайне увеличиваем
объем кода в ядерном пространстве
и за счет этого увеличиваем соответственно
поверхность атаки на
операционную систему. Фактически
каждый, грубо говоря, там добавленный
драйвер файловой системы, он там
снижает нашу безопасность
и это скажем так
не очень хорошо.
Да. Соответственно
если у вас микроядерная архитектура
операционной системы, то
действительно
вот эти вот вещи
они там по максимуму
выносятся в user space.
Но на самом деле даже если у вас
монолитная архитектура операционной
системы, то
далеко не все вот это вот
может находиться в user space.
Можете привести какие-нибудь такие примеры?
Физический носитель
это в смысле черненькое, потому что
это оборудование.
Да, вот здесь
на самом деле еще может быть
несколько драйверов, типа драйвер
шины там.
Это RAM.
То есть в нашем
случае это все еще
физическое устройство,
не находящееся в ядре, потому что это
оперативная память.
Но это не означает то, что
грубо говоря
код ядра действительно находится в оперативной
памяти, но оперативная память не является кодом ядра.
Ну по крайней мере у нас сейчас
не курс какой-нибудь по ПЛИСу, поэтому
Так вот, в случае
с системами общего назначения, догадывайтесь
в каком случае это
может быть не так?
Да-да-да-да, ладно, хорошо.
Тогда вопрос
Вы этим пользуетесь?
Как вы думаете?
Ну раз вы спрашиваете, наверное давно
не знал об этом.
Так, хорошо.
Ну вот это уже возможно, да.
То есть, например, там самый простой пример
это какой-нибудь там драйвер NTFS
в линуксе, пока его
замергили в каком-то виде ядро.
То есть был такой пакет,
назывался NTFS 3G.
Вот NTFS 3G действительно работал
через фьюз. Там всякие были вещи
типа SSHFS, то есть когда
можно подмонтировать удаленную файловую
систему прямо через SSH протокол.
Ну вот, соответственно, тоже использует
фьюз. Идея
File System in User Space
заключается в следующем, что
мы оставляем вот это
вот это в ядре,
но при этом
пишем маленький-маленький
драйвер.
Соответственно,
в данном случае это драйвер
Fuse, который
собственно и
обеспечивает там некоторый набор системных
вызовов для другого
процесса,
соответственно, уже для непосредственного
драйвера файловой системы.
Фактически
вот этому драйверу файловой системы
предоставляется доступ
к блочному драйверу, то есть он может
читать, соответственно, писать
на раздел, который, собственно,
предоставляет доступ.
И ему, соответственно, предлагается
реализовать, собственно, вызовы
чтения, поиска,
записи, создание файлов
для виртуальной файловой
системы. В случае
этого драйвер Fuse является некоторым подобием
Proxy, который, соответственно,
пробрасывает набор
интерфейсов
виртуальной файловой системы и блочного
драйвера, как
некоторый набор системных вызовов для
драйвера файловой системы.
В данном случае это хорошо,
потому что
программисту становится сильно
легче писать
драйвера файловых систем,
так как
они могут использовать там
обычные языки программирования,
полноценные системные библиотеки.
Им не надо опасаться
того, что они обрушат
всю систему тем,
что где-то ошибутся,
соответственно,
и приведут,
например, к падению ядра.
То есть
механизм действительно
довольно хороший для безопасности,
потому что, еще и более того, драйвер
Fuse гораздо меньше, чем любой драйвер
файловой системы.
Ну, не прям чтобы любой, но практически любой.
Что?
Ну, системные вызовы.
Откройте LipFuse
и увидите интерфейс.
Вам проще всего будет.
Ну, смотрите,
вам
нужны права,
то есть вот этот вот процесс должен быть
запущен под рутом,
чтобы, соответственно,
иметь доступ и как бы пользователей
это аутентифицировать, соответственно,
могут быть дополнительные политики, которые
разрешают или запрещают,
соответственно,
отдельно взятому процессу
реализовывать, соответственно,
файловую систему в рамках какого-то
устройства.
Поэтому насчет
вируса Пети, ну, честно говоря,
если вы можете
скомпрометировать вот этот процесс,
ну, то есть завладеть им каким-то образом,
то действительно вы сможете
соответственно скомпрометировать ту
файловую систему, которую этот процесс
соответственно управляет.
Хорошо или это
или плохо? Вопрос, потому что
вы сможете скомпрометировать файловую систему,
вы сможете скомпрометировать ядро.
Поэтому вот
здесь как-то там
палочка о двух концах, потому что даже если вы
получите какие-то привилегии, у вас эти привилегии
будут ниже, чем соответственно
привилегии ядра.
Ну, понятно, что здесь
есть определенная боль там
связанная с корневой
файловой системой, ее из ядра
гораздо тяжелее вытащить,
потому что проблема курицы и яйца,
вам нужно как-то запустить начальный
процесс, а у вас
файловая система оказывается в юзерспейсе,
поэтому соответственно
в случае, по крайней мере,
с UNIX системами
Fuse используется только для дополнительных
файловых систем. В случае
с
микроядерными архитектурами,
где
где
картинка выглядит примерно так,
то есть
в
некоторый пользовательский процесс
маппится, грубо говоря, регистры
физического носителя,
и он соответственно предоставляет некоторую интерфейс
блокчиного драйвера,
драйвер-файловая система и так далее.
У вас есть
некоторая маленькая файловая система,
которая доступна из ядра,
чаще всего там Redonly, а
полноценная файловая система
уже доступна
в рамках какого-то запущенного процесса.
Не обязательно
разных. То есть
если у вас, грубо говоря, есть конструкция,
это вовсе не означает, что
это все должны быть разные процессы.
Да, могут быть
разных процессов для облегчения
изоляции. Могут не быть.
В зависимости от того
какой-то рэдов между соответственно
предварительностью и соответственно безопасностью.
А как они будут общаться друг с другом через файловую
систему?
Ну, через IPC, например.
IPC мы вот только что разобрали.
Ну, было бы смешно.
Итак, ну, в целом
здесь как бы действительно все
достаточно просто.
Поэтому в Джосе
вот у вас
в десятой лабораторной работе будет
именно такая картинка.
И вам, соответственно, нужно будет реализовать простейшую
файловую систему, где вы как раз познакомитесь
с интерфейсом файловой системы.
Микро. Да.
Получается, что процесс файловой системы
просто сразу
виснет в прожигании
сообщения
Ну, на самом деле не совсем так.
Потому что, ну, смотрите,
вот если обрабатывать цикли
он будет однопоточным.
А там клиентов может быть несколько.
Другое одно дело там, грубо говоря.
Если
у вас обращение к носителю
надо реализовывать.
То есть как раз вот эта вот
часть. То есть любой
в другом
драйвер файловой системы
или на уровне VFS
или на уровне драйвера файловой системы
должен обеспечивать сериализацию.
Ну то есть некоторую по сути очередь
чтений, записей.
Причем
сериализацию и на уровне операций
и на уровне
микроопераций.
Грубо говоря, у вас микрооперация это там запись чтения сектора
которое там артное.
А соответственно операция это то в рамках
то есть, некоторая последовательность микроопераций, в рамках которых, грубо говоря, у вас происходит изменение файловой системы, например, создание файла,
соответственно, изменение. Например, ну вот, грубо говоря, когда вы там создаете файл, то вы там можете сначала записать файл,
а после этого добавить его в, соответственно, дерево для того, чтобы у вас файловая система на всех стадиях микрооперации оставалась консистентной.
Ну то есть, если у вас резко отключат питание, чтобы, соответственно, файловая система осталась консистентной.
И, соответственно, возвращаясь к этому вопросу, то даже с учетом того, что вам нужно обеспечивать сериализацию,
у вас все равно есть некоторые накладные расходы на обеспечение процесса доступа к файлам, у вас есть кэш, например.
Во многих случаях вам не нужно обращаться к диску для того, чтобы ответить, например, какие файлы лежат в директории,
для того, чтобы прочитать какой-то файл, у вас может быть кэш файлов. Например, в джосе у вас будет простейший кэш,
где прочитанные файлы будут кэшироваться в оперативной памяти, соответственно, к ним не придется обращаться повторно.
Вот.
Ну, из двух функций это в максимально простом виде. То есть, как бы в джосе, ну как бы простой пример, да,
когда там действительно однопоточный файловый сервер, там ничего сверхумного действительно нет.
Но в нормальных, соответственно, операционных системах у вас там есть набор воркеров, которые там могут разным образом
алоцироваться. Если, например, Hard real-time, то они могут резервироваться еще на статике. То есть, например,
на статике определяется, сколько процессов могут иметь доступ к файловой системе, соответственно,
под них выделяются ресурсы, соответственно, выделяется процессорное время, выделяется, соответственно, память
и обеспечивается там возможность обращения.
Я вам говорю, что у вас может быть кэширование, у вас могут быть накладные расходы. И, соответственно,
если обращение к жесткому диску действительно надо стереализовать, хотя и там, на самом деле, есть очереди,
и там современные контроллеры, они позволяют там читать, например, из разных мест параллельно.
В NVMe спецификацию почитайте, вам будет интересно.
Соответственно, но даже если бы этого не было, то, например, в кэше, то есть многие операции к файлам системы
вам не обязательно лезть к диску, у вас может быть просто обращение по кэшу.
И в этом случае, как бы, там, воркеры они неплохо ускоряют средний доступ.
Худший не ускоряют. Ну, точнее как, ускоряют, но в отдельных ситуациях, опять же.
Не, ну, зависит от. То есть тут как бы нельзя дать такой однозначно хороший ответ.
Вот. Плюс, соответственно, там, любая файловая система там должна ограничивать, соответственно, там,
количество, там, одновременно открытых файлов, потому что, ну, это ресурсы, там, либо на уровне VFS-а,
либо на уровне и VFS-а, и там, драйвера, там, количество одновременных операций, которые могут выполнять
процессы к файловым системам. Размер транзакций. То есть мы, например, там, привыкли, что
в рамках, там, позикса, можем, например, записать произвольное количество байт, там, файлов.
Ну, при условии, что диска хватит. Соответственно, если там какой-нибудь hard real time, то у вас на уровне, там, API
будет сказано, что, например, там нельзя одновременно, там, в рамках одной операции, писать вот больше, там,
столько-то байт. Потому что, там, гарантируется, там, временно и худшего ответа файловой системы.
Что, например, файловая система ответит, там, ну, вот за столько, например, микросекунд или, там, миллисекунд.
И как это можно достичь? Ну, вот, соответственно, посредством добавления, там, тех или иных ограничений.
Ну, на этом, в принципе, у меня все. Всем спасибо.
