Так, ну что, окей, начинаем. Сегодня мы переходим тоже к одному из таком последнему разделу в
нашем курсе. Это статистическая оптимизация. До этого мы с вами рассматривали задачи,
где все вычисления, которые мы делали, были детерманистическими, честный градиент,
честное значение функции, честный гисиан. Сейчас, соответственно, мы от этого оттолкнемся.
Такую задачку, соответственно, рассматривали. Теперь давайте эту формулировку чуть-чуть
модифицируем и запишем нашу целевую функцию вот в таком вот виде. Пусть у нас целевая функция,
это некоторое математическое ожидание, какой-то случайный величины кси по распределению d.
Нашу целевую функцию теперь зависит от двух аргументов, от x и от x. Но вообще в таком формате,
конечно, непонятно, что тут записано, откуда такие проблемы вообще возникают. Поэтому давайте
самый популярный пример – это машинное обучение, где у нас такого рода задачки возникают прям на
каждом шагу. С машинным обучением, я так понимаю, судя по вчерашнему семинару с Сашей, вы знакомы,
частично, хоть как-то. Соответственно, что у вас там в машинном обучении есть? Ну, или в домашнем
задании вы тоже это чуть-чуть проделывали. Что вы там обучаете? Моделька. А что у этой модели есть?
Что она может принимать на вход? Данные. В чем суть? У вас есть некоторая модель – это какой-то
черный ящик. Может быть не черный, но может быть какая-нибудь совсем простая линейная модель,
которая у вас там была в домашнем задании, то есть просто линейная зависимость. А может быть какая-то
нейросеть, которая состоит из кучи блоков. Суть такая, что вы на вход этой нейросети можете
подать некоторый объект X, ксет X. Это может быть картинка, текст или просто какой-то вектор признаков,
в том числе описание грибов, с которым вы три задания подряд работали. В этой модели можно
подкручивать веса, настраивать модель, чтобы она, получая объект на вход, выдавала какой-то
предсказание. Настоящее предсказание у вас, соответственно, обозначается как xy. Ну и что мы
делаем? Мы делаем и штрафуем нашу модель, ее предсказание, если они сильно отличаются,
ну или просто отличаются от реального значения метки xy. Ну не угадал, например, модель ваш,
что изображено на картинке, не угадал, не угадал модель ваш тональность текста, там есть отрицательный
отзыв или положительный, вы, соответственно, как-то ее за это все безобразие штрафуйки. В домашнем
задании, соответственно, у нас в первом задании были квадратичные штрафы, здесь у нас, соответственно,
во втором задании, третьем, четвертом сигмойная функция, логистическая функция штрафа. Ну в общем-то,
в любом случае, задачи формулируются вот таким вот образом. Откуда здесь берется математическое
ожидание? Но у вас есть некоторая природа, откуда приходят данные. Эта природа обозначается в данном
случае распределением d. Ну из этой природы вы сэмплите какие-то объекты, то есть это вот картинки
ваши и что на них изображено, то есть пара xy и xx. Вы хотите что сделать? Вы хотите, чтобы ваша модель
была в некотором смысле хорошим аппроксиматором вот той природы, которая наблюдается в этой
задачке, которая генерируется из d. Поэтому вы хотите, чтобы ожидание, то есть некоторое взвешенное,
среднее по всем сэмплам из этой природы, качество аппроксимации этой модели было минимальным.
Вся суть. Машинное обучение подстроится под вот эту природу d и минимизировать вот это ожидание.
Минимизировать вот это ожидание. Здесь понятно, да? Все супер. Хорошо, вот это мы только что обсудили,
аппроксимировать зависимость между xy и xxa. Какие проблемы вы видите вот в такой формулировке,
которую я вам рассказал? Тяжело считать, а часто вообще невозможно, потому что суть машинного
обучения это подстроится под распределение d, которое вы скорее всего просто не знаете. Вот,
либо оно действительно просто, ну как-то сложно считается. Ну какое распределение на картинках? Ну оно
формально есть какое-то. Какое распределение на текстах? Оно тоже какое-то есть, но нужно его в
некотором смысле просто аппроксимировать. Даже люди не особо задумывают, чтобы его искать. Его нужно
просто в некотором смысле хорошо повторить. Повторить с помощью каких-то простых блоков,
ну и модели, собранные из этих простых блоков. Распределение f вы не знаете, поэтому в реальности
вот этот интеграл, который у вас в математическом ожидании зашит, его невозможно посчитать часто.
То есть и значение функции, и значение интеграла, это вещи в данном случае не берущиеся. Поэтому
хочется как-то отстолкнуться от той постановки, что у нас есть, и разрешить в методах использовать
не честные градиенты, честные значения функций, честные значения гессианов, а их стокастические
версии. В чем суть? Ну, например, поступает нам какой-то сэмпл из природы данных, ну по-другому
никак, если у нас никаких данных не будет из этой природы, как мы что-то под нее будем подстраивать.
Поступил сэмпл, мы в онлайн режиме можем посчитать соответственно функцию потери уже конкретно на
этом сэмпле. Просто как раз взять эту функцию потери, взять модель, продеференцировать, получить
конкретный градиент, но это будет не тот градиент честный, а то как на конкретном сэмпле кси, который
мы с вами получили. Вот. Единственное хорошее предположение, которое мы можем сделать в данном
случае, это сказать то, что у нас вот тот стокастический градиент на сэмпле конкретном,
который к нам прилетел, он будет не смещенным. Ну понятно, потому что объекты нам прилетают из
природы, поэтому в среднем мы действительно будем иметь честный градиент. Понятно, что какие-то
более сложные случаи, когда у нас вдруг возникает какой-то байс при сэмплировании, рассматривать,
ну просто слишком сложно, потому что если есть байс, то кажется нарушается какая-то природа,
и вы сэмплируете просто не из этого распределения, из какого-то другого. Поэтому здесь понятно
предполагаем, что из этого распределения нам прилетают такие объекты, и мы по ним считаем
градиенты. Вот. Окей. Но часто в вашем машинном обучении, в том числе в вашем, в домашних заданиях вы
сталкивались вот с такой постановкой, то есть там не было интегралов, там была какая-то конечная
сумма. Вот такого вида, что та же самая функция потерь, та же самая модель, те же самые веса,
и вот объекты некоторые из этого распределения D, которые вам уже были изначально даны. Вот.
Такая постановка называется off-line постановкой, потому что в онлайн варианте вы как бы начинаете
абсолютно с нуля, а у вас нет ничего, у вас нет никаких данных, вам просто говорят, ну сейчас
начну данные поступать, давай в режиме реального времени начнем их обрабатывать, обучать нашу модель.
Такие постановки бывают, и это довольно общие постановки, когда вы предполагаете, что у вас
просто ничего нет. В онлайн постановке вам соответственно уже дана какая-то выборка довольно
большого размера часто из нужного вам распределения D. Но возникает вопрос, а как вот такая постановка,
которая записана здесь, вообще связана с изначальной постановкой. Изначальная постановка,
которая была в виде математического ожидания. Да, все тут-тут почти правильно, потому что на самом деле,
как вы знаете, интеграл можно считать нечестно. Нечестно, не знаю, не знаете, не знаете, не знаете,
там самые простые способы. Те суммы дарбу, которые вы считали, это один из вариантов. А можно,
например, считать интегралы с помощью сэмплирования. И всякого рода подходы рандомизированные,
основанные на сэмплировании, называются Монте-Карло подходами. Ну, например, какой-нибудь примерчик
сейчас. Монте-Карло подходы на самом деле разные бывают, я какой-нибудь простенький приведу,
чтобы было понятно. Ну вот есть у меня какой-то интеграл, я хочу посчитать его плотно, площадь под
графиком получается. Но я начну сэмплировать в этот квадратик, ну и как часто у меня будет попадать
под кривую. В таком процентном соотношении у меня значение, ну частоты попадания под кривую
будут стремиться к интегралу. Ну площадь получается площадь вот этой кривой, площадь интегралов,
которые находятся под графиком, можно будет найти как отношение, умножив просто на площадь
того квадрата, в который я сэмплирую. Вот. Монте-Карло подход. Здесь то же самое. Вы сэмплируете
данные из распределения, довольно большое количество. И говорите, что насэмплировав
вот из этого распределения, усреднив вот эти потери по всем точкам, которые я наделал,
у меня это будет неплохо так опроксимировать реальный интеграл. Вариант-вариант действительно
можно показать, что при большом n и при некоторых условиях на функцию потери на модель это всё
безобразие действительно будет неплохо опроксимировать исходную задачу. Вот. Поэтому часто действительно
на практике, да и не только задачу обучения подменяют, ну вот общую задачу обучения,
которую мы видели сами до этого, подменяют вот такую вот задачу вида конечной суммы, уходят
от интеграла. Вот, это мы с вами обсудили. Вот, у меня такой вопрос тогда возникает. Кажется,
что теперь в офлайн-постановке мы полный градиент вроде как считать можем. Вот, но почему мы это не
делаем? То есть машинное обучение, думаю, вы знаете, что полные градиенты люди часто не считают. Почему?
Дорого, дорого и долго. Дорого и долго. На самом деле, это первая проблема, почему это не делают.
Выборка большая, посчитать полный градиент, даже распределено то, что вам вчера рассказывал на
семинарию, это очень дорого. То есть даже в распределенном сетапе мы считаем стахастические
градиенты, то есть по куску данных. То как выбираем какой-то случайный кусочек данных,
ну или не случайный, вот, и по ним считаем градиент. Даже там, используя 100 вычислителей,
мы полный градиент не считаем. Вот. Ну, этого есть на самом деле и не только какие-то подходы с
точки зрения дороговизны, с точки зрения машинного обучения. Иногда вот такой подход стахастически
добавляет вам рабасности, потому что стахастик это в любом случае какие-то асцеляции, которые мы
увидим, которые добавляют случайность в ваш процесс обучения. Чтобы не переобучиться,
а с точки зрения именно машинного обучения это важно, с точки зрения оптимизации как раз
переобучение это всё хорошо, это вы нашли точный минимум задачи, которые вы ставили. А,
с точки зрения машинного обучения это не очень хорошо, поэтому стахастика может быть даже
играть какую-то хорошую роль с точки зрения именно машинного обучения, но не оптимизации.
Вот, окей, поэтому вот сегодня мы с вами будем рассматривать вот такой вот сетап,
когда у нас вместо полного градиента будет вычисляться градиент по случайному
сэмплу xe, который независимо и равномерно генерируется вот из нашего вот этого
распределения. Либо из D, прямо говорим, что он генерируется, какой-то сэмпл D,
либо, если мы уже говорим про finite самопостановку, то он будет генерироваться просто равномерно из тех
индексов, которые у нас есть. Тогда нам уже не нужно ждать, что придет что-то из распределения,
мы просто из того, что есть, будем минимизировать. Вот, окей, здесь постановка понятна. Все, супер,
тогда идем дальше. Опять же, очень просто модифицируется метод, с которым мы с вами
работали. Самый первый метод, который у нас есть – градиентный спуск. Пожалуйста, в прошлый раз мы
добавили в него субградиенты, разрешили считать субградиенты вместо честных градиентов и
минимизировать негладкие задачи. Здесь мы говорим, что теперь давайте вместо полного градиента,
честного детерминистического, я буду использовать какую-то его стахастическую версию. Каждый раз,
ну, для простоты здесь, соответственно, предполагается, что мы генерируем случайность
независимо. Ну и, как на прошлом слайде было сказано, как-то равномерно. То есть, это приходит
либо из D равномерно, либо приходит из номеров от 1 до N тоже равномерно. Вот, получается вот такой
вот метод. Ничего такого сверхъестественного у него нет. Давайте попробуем подоказывать его
сходимость. Но перед тем подоказывать его сходимость, ведем вспомогательный объект,
который называется условным математическим ожиданием. Работали с ним на тервере, супер,
вводили его, водится не так тривиально. Здесь, поэтому, я надеюсь, вы понимаете его суть. И по факту,
здесь просто нужно понимать, что, чтобы анализировать поведение метода на текущей
итерации, я буду фиксировать всю случайность, которая у меня произошла до этой итерации. Вот,
то есть, я вот это условно-математическое ожидание порождаю сигма-алгеброй, которая,
соответственно, сама порождается, начальная точка, которая может выбираться как-то рандомизированно,
плюс теми случайностями, которые у меня произошли до этого, до текущей итерации в этом методе. То есть,
те кси-иты, которые я генерировал в ходе работы метода. Вот, эту случайность я фиксирую,
как вы понимаете, в условно-математическом ожидании. На время, понятно. И, соответственно,
все это безобразие начинает ожидать только по той случайности, которая у меня произойдет на этой
итерации. Вот. Ну, и у меня к вам вопрос просто на такое вот понимание. Вот это условно-математическое
ожидание, что, какого рода объект возвращает? Детерминистический или случайный? Случайный.
Потому что, как только вы выходите за пределы этого математического ожидания, вы его посчитали,
у вас то, что вылезло на наружу, теперь зависит от вот этих всех случайных величин,
поэтому это случайный объект. Чтобы это сделать, соответственно, не случайным, тут нужно просто
это все приравнять каким-то значением конкретным. Тогда это у вас уже будет какая-то детерминистическая
функция, зависящая от этих объектов, но это можно и не делать. Это, скорее, такие формальные вещи,
которые вам объясняли, когда вы эти все объекты вводили сами по себе. Там вы, скорее всего, вводили
сначала от ожидания относительно разбиения условное, потом относительно сигма-алгебры,
потом относительно случайной величины. Здесь сигма-алгебра просто нужна, но главное понимать
суть, что мы фиксируем всю предысторию и говорим, что пока мы будем смотреть на только ту случайность,
которая у нас была до этого. Не, это в жизни у вас может возникать, то есть если мы не говорим про
постановку, когда вы просто можете строчки в матрице выбирать, которые соответствуют сэмплу.
Ну вот в Reinforcement Learning, про которые будет сегодня рассказывать Никита, онлайн-постановки
супер популярны, потому что там у вас никакой выборки нет, вы взаимодействуете со средой. Среда,
с которой вы можете делать какие-то действия. Это просто игра. То есть вы можете выбирать какое-то
действие и говорить, давайте я попробую вот это действие. Что мне выдаст среда? Даст какой-то бонус
или скажет, что я, например, сделал неправильно и она меня оштрафует. И в среде, понятно, зашита
какая-то случайность. И там вы конкретно взаимодействуете просто со случайными объектами.
И никакой выборки у вас нет. Более того, ждать, когда вы накопите эту полную выборку, просто
бессмысленно. Вам нужно уже подстраивать алгоритм в режиме реального времени. Копить эту выборку
может уходить дни, потому что среда может быть разная в Reinforcement Learning, она может вам день
отвечать. Это могут быть какие-то отклики клиентов на конкретный ваш. Вы там подобрали им какую-то
выборку музыки, они вам дали отклик. Поставили эти оценки, понятно, которые зависят от их настроения,
зависят от их конкретного текущего состояния. Они случайные. При этом, понятно, отклик вам
приходит немгновенно. И вам нужно это адаптировать в реальном времени. Поэтому здесь вот все эти игрушки
Reinforcement Learning это все онлайн постановки. Понятно, что часто возникают и оффлайн постановки,
когда выборка есть. Там, понятно, случайность просто генерируется, вы случайно выбираете индекс.
В вашем случае, там вот эта матрица, датасета грибы, берете строчку, которая соответствует конкретному
грибу, и по ней считаете градиент вместо полной матрицы. Вот, так, случайная величина. И вот такое
еще свойство, так называемое Tower Property, не знаю, с ним знакомились или нет, то что у вас полное
математическое ожидание сжирает просто условное математическое ожидание. Знакомо, да, с ним?
Супер. Это прям хорошо, обычно его приходится объяснять. Вот. Тоже, на самом деле, супер естественное
свойство, потому что случайная величина y, ну, можно ее рассматривать как в некотором смысле
параметризацию случайной величины x, и вы сначала берете ожидание по y, потом берете уже условное
ожидание по y, потом уже берете, то есть из x вы как бы уходите, потом берете ожидание по y,
это по факту эквивалентно, потому что вы берете по x. Не знаю, мне какой-то пример нравится в духе того,
что вы считаете условно-математическое ожидание, ну, например, считаете средний вес всего населения
Земли, предполагая, что это некоторая случайная величина. Вот. Ну, и вот это просто изначально вот
такое значение, а потом вы говорите, что давайте, я еще знаю случайную величину, такую как рост
человека. Понятно, что x и y, при этом это коррелированные случайные величины. Понятно,
что если человек выше, то средний его вес, скорее всего, просто больше, чем у человека,
который просто пониже. Вот. Ну, и вы сначала говорите, что давайте я посчитаю условно-
математическое ожидание, когда у меня есть вот вес при условии какого-то y, но когда вы потом
это заново просуммируете уже, возьмете полно-математическое ожидание, получится ровно то же самое. То есть,
тут неважно, как считать средний вес. Просто средний вес или сначала с учетом роста, а потом уже
и эту зависимость от роста поглотить еще одним математическим ожиданием. Вот. От физика тут очень
понятно этого всего безобразия, поэтому идем дальше. Давайте подоказываем сходимость. Что хочется
предположить? Опять же, первое предположение, это у нас стандартное наше предположение, то, что у
нас стахастический градиент несмещенный, обговорили, что понятно, без него будет жить очень сложно.
Без него будет жить очень сложно, и за пределы выходить не хочется. Второе предположение, то, что у меня
дисперсия стахастического градиента ограничена. Не самое часто физичное свойство, но давайте пока
оставим ее, она такая базовая, почему бы его не рассматривать. Окей, дальше я делаю ровно все те же
манипуляции. Первая манипуляция, она очень простая. Так, градиент воспуска, подставил, расписал квадрат.
Дальше, соответственно, нужно уже что-то делать, потому что до этого мы с вами, мы знаем только то,
что у меня функция f гладкая и мюсильно выпуклая. Но здесь у нас функции f так-таковой нету, поэтому ее
нужно сначала добыть из того, что у нас написано. Но чтобы добыть ее, давайте возьмем условное
математическое ожидание, я же не зря его вводил. Относительно давайте как раз x, фиксирую всю
случайность, которая у меня происходила до текущей итерации. Что тогда из выражения выше будет
случайными величинами? Относительно такое. xк плюс 1 будет случайной величиной, супер, что еще?
Градиент вот этот будет случайной величиной, так, и вот этот, да? Что-то еще? Нет, xк мы как раз
фиксируем, то есть то, что та случайность, которая xк, посчитана с помощью xк-1, ну и так далее,
там всех остальных. Это мы все зафиксировали. Ну гамма-каты, давайте все же брать детерминистические
шаги, которые не зависят в случайности. Понятно, что можно, конечно, поизвращаться, там адаптивность какую-то
добавить и сказать, что давайте подобираем. Вот вся командами тоже так делают. У вас там как раз шаг,
ну даже матрица шкалирования, она зависит от градиента стихистического. Но здесь мы сделаем попроще,
и давайте берем тогда это условно-математическое ожидание от того безобразия, что у нас написано.
Я его сразу буду оставлять только там, где у меня величины случайные, вот, а все, что, ну,
относительно этого математического ожидания. А все остальное я буду просто оставлять без него.
Так, ну что, тогда давайте смотреть, что теперь нам дают эти все замечательные вещи,
которые я написал. Про это что можем сказать? Чему будет равно? Это условно-математическое ожидание от градиента.
Да, просто честному градиенту ровно вот из этого предположения, потому что я здесь
ожидаю только по кси, а это на самом деле оно и есть, потому что та случайность, которая осталась
после того, как мы все зафиксировали, это только кси. Только кси, поэтому вот то, что у меня здесь
записано, просто вырождается в честный градиент. И это хорошо, потому что сейчас мы приходим к тому,
что вот даже скалярное произведение в итоге оказалось таким, которое у нас было в детерминистическом методе.
Вопрос теперь к дисперсии. Вопрос теперь к дисперсии. Давайте я перелесну на слайд. Вот,
на следующий. Здесь я вот про вот это как раз написал. Да, смотрите, то есть у вас здесь вот
случайность, которая здесь есть, математическое ожидание берется по случайной величине кси. А здесь
в условном математическом ожидании вы фиксируете все, что происходило до этого. То есть вы фиксируете
х0, вы фиксируете все ксишки до притекущей. По факту вся случайность, которая действует сейчас вот
на этот вектор, это кси кт. Больше никакой случайности нет, все остальное фиксировано. Поэтому вот это
условно-математическое ожидание, оно эквивалентно тому, что вы просто берете от ожидания по кси.
Вот, теперь давайте разберемся с дисперсией. С дисперсией просто поинтереснее.
Точнее не с дисперсией со вторым моментом, вот. Окей, предположение у нас было только на дисперсию,
поэтому нужно сделать умный ноль и добавить и вычесть в скобочках дисперсию. Не дисперсию, а честный
градиент, чтобы дальше уже можно было это все безобразие использовать. Так,
вот. Хорошо, дальше я это, давайте, выражение под ожиданием раскрою, вот эти квадраты, и у меня
сначала получится как раз дисперсия. Так, дисперсия, плюс еще удвоенный просто градиент. Смотрите,
с градиента я сразу сниму условно-математическое ожидание, потому что эта величина будет
не случайной. С нормы градиента я сразу снял условно-математическое ожидание. Согласны,
что я могу снять его, да? xk, это у меня вещь не случайная относительно этого условно-математического
ожидания, поэтому я его снял. Так, дальше остается у меня что-то вот такое. Скалярное произведение xk,
xk, xk. Так, и здесь f от xk градиент. Так, и это условно-математическое ожидание. Хорошо, с первым
кусочком понятно как разбираться. Ограниченная дисперсия, опять же, по предположению все делается.
Хорошо, здесь возникает просто sigma в квадрате. Sigma в квадрате. Дальше второй кусочек, опять же,
остается, он у нас возникал и в сходимости обычного градиентного метода. Что делать с последним,
кто быстренько понимает, что там будет происходить? Ноль. Почему ноль? Да, смотрите,
у вас, опять же, с точки зрения условно-математического ожидания случайным является только вот это
выражение. Даже точнее так, вот только вот этот конкретный градиент стахастический. Поэтому вы
условно-матоматическое ожидание можете занести под скалярное произведение, промотождать вот это
все безобразие. Он вам даст, опять же, по нашему предположению, честный градиент, поэтому честный
градиент минус честный градиент это просто ноль. Все, поэтому здесь у вас получается вот такое вот выражение.
Согласны? Все, супер. Так, окей, здесь мы промотожидали, занесли, выразили, все. Дальше у
нас получилось вот такое вот безобразие. Первое доказали, второе доказали, но первое, то, с чего
мы начинали, верхняя строчка. Поэтому это все можно объединить и получится вот такое вот. То есть,
кажется, что вообще все хорошо, все выглядит очень похоже на то, что у нас было в обычном градиентном
спуске. Единственное, что болтается вот этот кусочек гамма-к в квадрате на сигма в квадрате,
гамма-к в квадрате на сигма в квадрате. Дальше, поэтому делаются абсолютно те же самые шаги,
которые мы с вами делали. Применяли сильную выпуклость для скалярного произведения и
применяли гладкость для нормы. То есть, здесь нужно было вычесть сначала умный ноль,
значение градиента в оптимуме, потом применить гладкость именно для выпуклых функций. У вас там
это расписывается через разность функций точки xk и x звездой. Это здесь сделано и поэтому вот
раз у вас получается так, это у вас просто использована гладкость и сильная выпуклость.
Дальше слагаемые сгруппированы, и получился опять же тот же самый результат. Единственное,
что только болтается вот этот сигма в квадрате на гамма-к в квадрате. Ну окей, болтается и болтается.
Дальше опять же выбираем гамма так, чтобы у вас все было хорошо с точки зрения вот,
чтобы убить вот этот кусочек. Чтобы убить этот кусочек, вы выбираете гамма меньше,
чем 1 делить на L, и получается вот такая вот сходимость. Вот такая вот сходимость.
Да, как-то вот так. Возникает вопрос, что с этой сходимостью можно поделать. Будет ли это
такая же сходимость, как у градиентного спуска? Будьте здоровы. Сигма мешает, сигма мешает. Ну давайте
попробуем даже с постоянным шагом что-нибудь поделать. Я уберу вот эти к здесь, уберу здесь эти к. Во-первых,
у меня возникает вопрос. Градиент на спуске, чтобы получить сходимость, мы запускали рекурсию.
У нас справа стояло какое-то выражение, слева. Здесь я могу сразу же запустить рекурсию.
Да, у нас слева с мотожданием стоит, а справа без мотождания стоит. Поэтому как бы, там же суть
рекурсии то, что у меня была всегда оценка на выражение справа еще. Спасибо. Вот, на выражение
справа была оценка. Я его оценивал по рекурсии и дальше мне это все схлопалось. Пум-пум-пум-пум. Здесь у
меня мотождание стоит и поэтому оценка на xk минус x звездой в подрати у меня тоже будет только
по мотожданию. Вот, условному. Поэтому что-то нужно сделать. Сделать тут все довольно просто. Так как
нужно мотождание, давайте возьмем полное мотождание. Вот, набросим полное мотождание на обе части,
тогда оно нам сожрет условным от ожидания, а здесь возникнет как раз полное мотождание. Все. И вот в
таком виде рекурсию уже запускать можно. В таком виде рекурсию уже запускать можно. Когда вы возьмете
полное мотождание, рекурсия уже запускается. Ну и давайте запустим. Давайте запустим. Тогда у меня
что здесь будет? 1 минус гамма мю в квадрате xk минус 1 x звездой плюс гамма в квадрате сигма в
квадрате плюс то, что у меня вылезло еще после того, как я подставил xk минус x звездой. А здесь у меня
вылезет гамма мю гамма в квадрате сигма в квадрате. Согласны? Вот. Запускаю, запускаю дальше,
дальше, дальше. И я в какой-то момент приду, соответственно, понятно, в нулевую точку.
Мотождание только забыл. Мотождание нулевой точки. Вот так вот. Но здесь у меня будет болтаться
вот этот гамма, который я насуммировал. Гамма в квадрате сигма в квадрате, который у меня
вот суммируется. Здесь что будет? И от нуля до ка 1 минус гамма мю в степени и. Согласны, да,
что так получится? То есть, когда я подставлю еще раз, у меня здесь вылезет k минус 2. Ну и,
соответственно, гамма в квадрате сигма в квадрате со степенью 1 минус гамма мю в квадрате. Ну и вот эти
степени у меня здесь и будут постоянно вылезать, вылезать, вылезать. Как теперь можно оценить вот этот
второй член? Как можно? Геометрическая прогрессия. То есть, здесь она усеченная. Но можно загрубить и
сказать, что здесь давайте я поставлю бесконечность. И тогда вот эта сумма будет равна как 1 делить на
гамма мю. Вот. И в итоге получается результат. Результат получается вот такого духа. 1 минус гамма
мю х нулевого х звездой в квадрате. От ожидания можно поставить. Вот. Плюс гамма сигма в квадрате
делить на мю. Вот. Чего забыл? А, k плюс 1, да. Вот. То есть получается по факту что-то очень похоже. Если
сигма равно нулю, то это вообще сходимость просто градиентного спуска, честно. Сигма не равна нулю.
Получается что у вас? У вас опять же есть линейная сходимость. Пока у вас первый член мажорирует
второй у вас есть линейная сходимость. Как только они начинают быть одного порядка,
та оценка, которую мы получили говорит о том, что ну вы можете достигнуть какой-то точности. Но
глобально вот это вам говорит, что вот это какая-то достижимая константа, ниже которой вы не опуститесь.
Вот это может быть меньше, меньше, меньше, меньше. Но вот это у вас некоторый барьер. Ну не тот,
который мы проходили, а просто какой-то барьер сходимости, который вам говорит о том, что ну какая-то
константа, дальше которой никаких гарантий нету. Никаких гарантий нету, это просто константа,
она не уменьшается. Если у вас шаг фиксирован, сигма фиксирована, мю фиксирована, то есть никак
вы не играетесь шагом, а сигма и мю тут поиграться как-то сложно. Вот. То у вас будет про факту сначала
линейная сходимость. Линейная сходимость пока вы далеко от решения, вы действительно падаете к
нему, а потом начинаются асцеляции. И это на практике наблюдается. То есть, ну метод просто
не сходится. То есть сначала есть линейной сходимости, потом начинаются просто колебания
вокруг оптимума из-за того, что вот есть эта дисперсия, которая не компенсируется. И понятно,
что степень этих, ну как бы, высота этих колебаний, то есть на графике это обычно выглядит вот так.
Вот те графики, которые вы строите. Сначала линейная сходимость, потом начинается вот так. Вот.
Глубина того, насколько вы погружаетесь вот здесь зависит, понятно, от гаммы, от сигмы, от мю.
Меньше шаг, соответственно, медленнее сходимость, но глубже погружение.
Вот. Понятно, дисперсия тоже, на самом деле, можно поиграть, это мы сейчас обсудим.
Вот. Но пока вот такой вот эффект, то, что у вас есть эта окрестность, которая не улучшаема.
Не улучшаема, и это как бы проблема метода SGD, и здесь у нас у меня все это, да, вот это мы с вами уже выбили,
оценили через геометрическую прогрессию, получили вот такую сходимость.
Линейная сходимость к решению, второй кусочек, это вот та осцилляция, которая у вас будет в любом случае.
Вот. Обсудим, как это можно решать. Первый вариант, это то, что я сказал, это просто уменьшение шага.
Но опять же, уменьшение шага, если шаг фиксирован, он вам не дает точную сходимость,
в любом случае опускаетесь к решению и в какой-то момент вы начинаете осциллировать.
Да, глубже, да, дальше. То есть, медленнее сходитесь линейно, но, соответственно, глубже с точки зрения качества решения.
Вот. Есть еще один вариант, это брать, например, уменьшающийся шаг, 1 делить на k или 1 делить на корень из k плюс 1.
Это то, к чему обычно прибегает машинное обучение, когда у вас шаг уменьшается, выставляют всякие шуделеры, выставляют или просто прописывают их уменьшающимися шаги,
чтобы как раз бороться с тахастикой. Чтобы бороться с тахастикой, чтобы у вас как раз эта окрестность становилась еще ниже, ниже, ниже.
Но этого всего безобразия, я думаю, уже понятен и плюс, и минус. Окрестность глубже, то есть вы даже вот здесь можете достигнуть точного решения, это доказуемо.
Но в силу того, что ваш шаг становится непостоянным, вы теряете линейную сходимость на начальных итерациях, вы теряете линейную сходимость.
Ну вот такие вот плюсы, соответственно, можно как бы на практике стараются и линейную сходимость, то есть наибыстрейшую, которая возможна для данной задачи, не терять,
и при этом выгребать качество с точки зрения точности, поэтому вот эти шаг уменьшаются как-то поэтапно. То есть сначала берут какой-то постоянный, до какого-то момента его держат,
потом опять же его начинают переключать, через эпоху или через несколько эпох его переключают, делают чуть меньше.
Вот, и таким вот образом как бы у вас получается сходимость не сильно портится, вот, и при этом как бы стахастика начинает по чуть-чуть убиваться, по чуть-чуть убиваться за счет уменьшения шага.
Вопрос, на самом деле с сигмой тоже можно поиграться, тоже ее сделать меньше, вот, ну как?
Сигма, а пожалуйста.
Вот, правильно, то есть есть у меня некоторая, в некотором смысле реализация случайной величины,
вот, я с помощью этой реализации говорю, что я пытаюсь опроксимировать реальный градиент.
Говорю, что у меня стахастический градиент, возможно похож на реальный градиент, но есть дисперсия, то есть по мотожданию там вообще не смещенная оценка,
ну а есть какая-то дисперсия, которую, ну, мне бы хотелось побороться.
Как побороться? Ну, это вы все знаете, еще есть Тиар Вера, всякие предельные Тиаремы.
Как уменьшить дисперсию?
У Красном Борис уже сказал, взять побольше сэмплов.
Особенно, если у нас сэмплы между собой, что? Независимы.
Если вы берете, соответственно, давайте, так называемый batch сэмплов.
Batch сэмплов.
Машинное учение, это ровно так и называется, batch.
Так, тут же, xij, вот.
То вот такой градиент, утверждается, будет лучше опроксимировать с точки зрения дисперсии.
Здесь мощность s, b, то есть вы сэмплируете b индексов, вы сэмплируете b индексов,
и все индексы из s сэмплируются независимо, и там, не знаю, из xi равномерно, из xd равномерно, либо берется там равномерно из z.
Понятно, что это дороже, потому что тогда у нас стахистический градиент,
нужно считать просто по большему числу данных, вместо одной точки у вас там нужно брать b точек.
В самом деле, часто так и делают, потому что одна точка, это, конечно, слишком агрессивно,
она может быть очень так, слишком большая дисперсия будет у стахистического градиента.
Ну и тоже, когда вы говорите про какую-то природу, можно подождать пару сэмплов,
хотя не во всех задачах так можно.
Ну и, как верно подметили, то есть здесь у вас вот эту дисперсию, которая у вас получается, можно оценить вот так.
Понятно, что по математическому ожиданию здесь будет все хорошо,
вы просто промотожидаете и скажете, что в силу линейности вы заносите математическое ожидание под сумму,
каждый отдельный сэмпл в среднем это у вас действительно честный градиент,
и получается в среднем это тоже честный градиент.
Дисперсии чуть посложнее, но тоже несложно.
Добавлю сюда, соответственно, вот этот честный градиент,
который нам обычно нужно было вычитать при оценке дисперсии.
Ну и что здесь получается?
У меня под знаком суммы стоит, что я могу сказать про эти случайные величины?
Они независимы, да?
Получается у меня сумма считается дисперсия независимых случайных величин.
Для них мы знаем, что дисперсия суммы равна сумме дисперсий.
Бэшку вынес за норму, получилось b², дальше выношу сумму дисперсии.
Здесь у меня возникает эта сумма, точнее разность градиент стахистического и честного,
ну и я ее оцениваю как сигмой, и у меня получается сигма в квадрате делить на b.
Потому что вот здесь вот этот оценил сигмой, суммирование сожрет одну бэшку, одна бэшка останется.
Тут важно то, что мы берем все это безобразие независимо друг от друга, и получается вот такой вот батч-эффект.
Больше сэмплируете, меньше дисперсии.
То есть можно бороться за сходимость не только шагом, но можно вот таким вот способом
с помощью увеличения количества данных, которые вы используете в стахистическом градиенте.
Что значит большим количеством индексов?
Здесь мы предполагаем, что у нас вот один сэмпл – это просто один индекс, это конкретная точка данных.
Понятно, что можно уже изначально всю эту задачу, которая видит суммы, разбить на бачи.
Обычно так и сразу и делается.
Понятно, что именно с вычислительной точки зрения до какого-то момента это все неравномерно считается.
График не совсем равномерный. С увеличением бача подсчет градиента растет не так.
Вот здесь есть какие-то эффекты, типа наитонициализацию и так далее,
что подсчет какого-то небольшого бача в принципе имеет место.
И он стоит столько же, сколько и подсчет бача по одному сэмплу.
Поэтому можно изначально выборку, понятно, разделить на кусочки.
То есть не обязательно один сэмпл – это вот один, он у меня пойдет в бач.
Бач можно изначально задать, а потом уже делать бачи из бачей.
Тоже вариант.
Понятно здесь идея.
Окей, это мы с вами обсудили.
Так, это тоже обсудили.
А, ну и давайте как раз этот сюжет с вами закончим.
В итоге.
Так, это что?
А нет, тут корня этого нет.
Это для SGD.
Сначала для SGD.
Оценка вот такая вот без корня.
Получается, вот можно так вот сделать.
Первое – это ровно то, что мы имели для градиентного спуска.
Линейная сходимость – показателем уделить на L.
Второй кусочек, соответственно, стахастический.
Тут такой результат немного искусственный,
потому что здесь нужно подбирать шаг довольно хитро.
То есть его от номера итерации не только там уменьшать,
но иногда брать постоянным, равным 1 делить на L,
потом на более поздних итерациях уменьшать.
Тут надо знать свойства функций.
Но в теории вот такой вот результат можно получить,
как бы линейная сходимость к решению,
плюс сублинейная сходимость из-за стахастики.
Понятно, стахастики нет, у вас просто градиентный спуск.
Стахастика есть, у вас проявляется эффект сублинейности в какой-то момент.
То есть у вас будет как раз сначала линейная сходимость,
а потом сублинейная сходимость.
В зависимости, опять же, как соотносится расстояние изначального до решения
и как получается, какого размера у вас сигма.
Сигма большая, понятно, сразу начнется с сублинейной сходимости.
Да-да-да, но там очень хитро подбирается.
То есть изначально на начальных итерациях оно берется 1 на L.
Дальше говорится, давайте начнем уменьшать его.
Ну там необычный вариант.
То есть там не так просто такой результат получить.
То есть там не просто надо брать уменьшающийся шаг.
Там чтобы как раз вот это была линейная сходимость,
в оценке нужно изначально брать правильный шаг.
1 делить на L.
Оказывается, что этот результат еще и ускоряется.
То есть понятно, к градиентному спуску мы можем применить нестерва.
К стахастическому градиентному спуску это тоже безобразие делается.
При этом можно заметить, что 1 кусочек, который отвечал за терминетистическую сходимость,
он ускоряется, как в принципе и в случае, когда вообще стахастики никакой не было.
А 2 кусочек нет.
Оказывается вот этот шумовой эффект, который возникает из-за того,
что стахастический градиент имеет какую-то дисперсию ограниченную.
Он не ускоряется, у вас в любом случае получится сублинейная сходимость.
1 делить на K.
Тут как работа не работа, и вот эта оценка не улучшаема.
То есть это доказуемо не улучшаемо.
Есть нижние оценки на то, что вот этот кусок такой и есть.
То есть у вас есть линейная сходимость, плюс сублинейная сходимость,
причем ровно такая же сублинейная, как у градиентного спуска.
То есть стахастика в этом плане враждебна к ускорению.
В принципе, это в некотором смысле ожидаемый эффект,
потому что в негладком случае нету тоже ускорения.
А стахастик – это ограниченная дисперсия, чем-то похожа на ограниченность субградиента.
Поэтому если в негладком случае нет ускорения, то и здесь ожидаемого его тоже нет.
Оно есть пока у вас свою роль не начнет играть стахастика,
но потом, когда вы дойдете до того момента, что у вас сигма,
вот эта слагаемость сравняется примерно вот с этим, в какой-то момент работа алгоритма,
то у вас сигма уже будет играть роль, и тогда получится линейная сходимость,
которая не отличается от градиентного спуска.
Можем, можем, можем. Нет, такая сходимость уже не получится.
Просто кажется, что 1 делить на k в квадрате уже не особо выгодно брать.
То есть правильные оценки, да и на практике 1 на k работает нормально,
1 на k в квадрате слишком медленно, он слишком быстро убывает.
Да, вы будете, может быть, в итоге в какой-то асимптотике получать хорошее решение,
потому что шаг еще меньше, поэтому сойдетесь еще глубже.
Но просто потому что шаг убывает слишком быстро, эта асимптотика слишком плохая.
Когда вы дойдете до этой бесконечности, 1 на k достаточно, 1 на корень из k достаточно часто.
Поэтому, конечно, можно брать супермаленькие шаги, но не рекомендуется.
Вот здесь такая идея.
Вот первая часть лекции, все, вопросы?
Здесь корня нету.
Первая для градиентного спуска, первая для градиентного спуска, я зачем-то его бахну в лобби.
Почему?
Ну, смотрите, mu на l, это меньше единицы, например, 1 сотая.
Здесь получается, в скобочке, что?
0,99 степени k.
А здесь что будет получаться, если я корень возьму?
0,9 степени k.
Что быстрее убывает?
Второе быстрее убывает.
Понятно, что этого становится сильно меньше.
Через 10 итераций, то есть 0,9 степени 10, это супермало уже.
А 0,99 степени 10.
Ну так, по-моему, он как раз до 0,9 и дойдет.
Поэтому градиентный спуск тут медленнее, понятно.
Это тот же самый результат, что у нас и был.
Вот, по первой части все.
Дальше пойдем уже к лобби.
К дополнительным техникам, что можно делать в стокастическом случае.
Вопросы?
Ну вот мы как раз это и обсудим.
Обсудим обзорно.
Катя вам, конечно, больше рассказала.
В том числе частично с доказательствами.
Вот, я скорее просто идейно это обсужу.
Нет, мы сейчас посмотрим.
Посмотрим, потому что, например,
Те результаты, которые дает SGD, они не улучшаем.
Потому что, опять же, выборки нет.
Ничего нет лучше, чем просто ждать сэмпл и считать по нему 100 градиентов.
Вот.
Но, когда и выборка есть, появляются альтернативы.
Вот.
Окей, тогда перерыв и возвращаемся.
И как раз разбираемся с Variance Reduction.
Все, все, продолжаем.
Давайте разбираться, что там у нас происходит дальше.
Вот.
Так, эти мы способы с вами обговорили.
Пам-пам-пам.
Так.
Почему работает градиентный спуск,
и почему не до конца сходится SGD?
То есть, кажется, что на начальном этапе
происходит ровно то, что обычно происходило с градиентным спуском.
То есть, в итоге X стремится как-то к X звездой.
Процесс как-то сходится к решению.
Но потом начинаются вдруг асцеляции,
хотя у градиентного спуска они не наблюдались.
Какая проблема появилась в физике метода?
Потому что градиент стокастически не объясняет до конца физику.
Вот в чем может быть конкретная проблема?
Почему один сходится и, начиная там просто в одной точке,
задерживается до конца?
А второй, ну, скачет между разными точками.
Причем примерно с одинакового размера шагами.
Почему так происходит?
Особенно вот интересно с точки зрения машинного обучения.
А почему он слишком сильный?
Вот у градиентного спуска он не сильный.
Вроде бы размер шага один на L и там и там.
Вроде бы размер шага один на L и там и там.
Градиентному спуску норм.
Это описывает то, что происходит.
Почему градиентный спуск начинает в решении задерживаться?
Почему он там остается?
Потому что у вас, когда X стремится к X звездой,
у вас и градиент, который вы используете,
стремится к нулю.
То есть шаги у вас уменьшаются за счет того, что
не сам степ-сайз становится меньше,
а просто потому что, приближаясь к решению,
у вас градиент приближается к нулю, а значит,
оттуда он и не выходит.
А что происходит в случае, когда вы используете SGD?
Вы можете сказать про градиент, даже несмотря на то,
что вы стремитесь к X звездой, вы это можете предположить,
например, сказать, что да, я стремлюсь к X звездой.
Будет ли градиент на каком-то сэмпле равен нулю?
Не обязательно. Не обязательно, потому что
в этом в том числе и суть машинного обучения,
потому что один сэмпл – это одна точка данных,
либо какой-то кусочек данных небольшой.
Градиент отражает функцию потерь модели
А большой градиент отражает функцию потерь
на всех данных. И то, что
итоговая модель, которая у вас получилась,
которая X звездой, которая нам нужна,
это потери для всех данных,
они могут быть не очень хорошими для конкретного кусочка данных,
потому что, опять же, когда мы говорим про линейную модель,
например, у вас набросаны какие-то точки
на плоскость, и вы говорите, что да,
я там построил линейную модель для этих всех точек,
вот она вот так выглядит. Но потом вам говорят,
окей, давай мы что-нибудь попробуем сказать
про вот эти точки. Стахастический градиент
посчитаем для этих точек. Но тогда вы говорите,
кажется, синяя модель не очень для него,
потому что вот такая модель будет лучше.
Она прямо по этим точкам пройдется.
Ровно через них пройдет. Поэтому
оптимум, который дает синяя модель,
синяя модель вам дает X звездой.
Он не является оптимумом для конкретного боча,
конкретного боча. Поэтому даже несмотря на то,
что вы дошли до оптимума,
ну или приближаетесь к нему, вам никто не гарантирует,
что на конкретном сэмпле этот оптимум будет стремиться к нулю.
Просто потому, что так устроено машинное обучение,
общая функция потери, она может быть неравна,
teachings, параметры модели μанимируя общую функцию,
параметры модели, которые минимизируют общую функцию comparing
модели, которые минимизируют общую функцию, потерь, они
могут быть неравны параметрам, которые минимизируют
какую-то выборку. При этом на самом деле часто наблюдается
эффект, ну не часто, но иногда наблюдается эффект,
когда вы все же можете гарантировать, что у вас модель,
которая получена, altenna вас минимизирует
и частную выборку, и общую.
Как мне построить модель, которая минимизирует и все потери, и которая
минимизирует частные потери?
Да, можно, например, построить что-то вот такое.
Вот. Почему нет? Ну, а почему нет? Может быть, реально, жизнь такая. Вы дальше
сейчас точки будете напихивать, и они вам будут попадать ровно в эту кривую.
Понятно, что, конечно, это в порядке бреда, и, скорее всего, вам в каком-нибудь машинном
обучении рассказывали, что это просто называется переобучением. Вот. Вы сделали
слишком жесткую модель, задали ее слишком большим числом параметров, в том числе
в данном случае эти параметры отвечают за коэффициенты полинома. Вот. И этот
полином в итоге у вас подстроился так, что вот тупо в точки и попали. Вот. Когда
начнете накидывать новые точки, ну, полином просто окажется не совсем
корректным. Вот. Такое бывает, соответственно, такая вещь называется
оверпараметризацией. И в каких-то простых случаях, ну, то есть, параметров слишком
много, что вы можете подстроиться под любую выборку, которая у вас есть, даже
под выборку, которая у вас есть. Причем, на самом деле, для простых моделей
какие-то это говорят, что это плохо, ну, как-то вот показывают, это как пример того,
что вы выбрали слишком сложную модель и нужно упрощать ее, вы по факту просто
переобучаетесь. Но в нейронках эффект оверпараметризации часто довольно
хороший, на самом деле. То есть, там этих весов слишком много и даже вот эта
слишком большая модель для конкретного датасета может быть давать и хороший
результат. То есть, там может быть ситуация лучше, чем вот это я нарисовал.
Поэтому вот эта физика, почему SGD вообще перестает сходиться. Потому что у вас то,
что вы используете в качестве градиента, ну, то, почему вы делаете шаг, он к нулю не
стремится, он к нулю не стремится. Вот, и поэтому начинаются эти асцеляции и они,
соответственно, пропорциональны тому, насколько у вас градиент по конкретному
сэмплу в оптимальной точке для всей выборки не равен нулю, насколько он там
большим будет. Вот, соответственно, возникает идея, если я хочу использовать
что-то, получить хорошую сходимость, мне нужно, получается, в SGD использовать
какой-то стахастический градиент, который будет стремиться к нулю. Вот, я хочу
потребовать вот это. Если у меня x стремится к x звездой, ну, вот так вот у меня устроен
процесс обучения, там решение задачи оптимизации, я могу предположить, что у меня x
стремится к x звездой. Я бы хотел, чтобы у меня есть стахастический градиент,
стремился к реальному градиенту, который в оптимуме просто равен нулю, в оптимуме
равен нулю. Ну, и дополнительно там можно потребовать какие-то вещи в духе того,
чтобы у меня в среднем это был честный градиент, либо просто в среднем по полному
математическому ожиданию, либо даже по условному математическому ожиданию, понятно,
что. Тут еще только вот так надо вбахать, потому что xk тоже случайная величина. Вот,
как-то вот так вот можно сделать. Попробовать сосконструировать такой метод. Ну, и давайте
попробуем это сделать. Единственное, что сразу нужно отговорить то, что, ну, как я говорил,
в онлайн-сеттинге, когда у вас нет никакой выборки, вам просто поступают сэмплы, вы ничего не можете
копить, вы тупо можете обрабатывать текущий сэмпл и шагать по нему. Ну, там не получается что-то
как-то вот с редукцией дисперсии полностью устранить эту сигму. Полностью устранить. Да,
там можно сделать чуть-чуть эффективнее, но сигма полностью не устраняется. Вот. А вот в случае,
когда у вас задача, целевая функция в задаче уже представляет собой вид суммы, вот такой вот,
ну, то есть сказать loss функция просто по каждому из отдельных сэмплов, там уже появляются интересные
эффекты, которые мы сейчас с вами и пою следом. Катя вам про это рассказывала. Я расскажу просто
интуицию, физику, ну, и те методы, которые она не упомянула. Она скорее-то пошла вглубь, вот. А я
скорее-то в ширь немного про это, поэтому всему безобразию пройдусь. Вот. Здесь мы, соответственно,
в этих методах будем предполагать, что стахастика будет как раз исходить от индекса. И вот эта
ксиката, это будет эквивалентно тому, что я просто выбираю случайный индекс из того, из того набора
FIT, который у меня есть. Вот. Понятно, да, идея? Чего? Ну, это индекс, я же здесь его и обозначил,
здесь тоже и, ну, просто с к. Он мне сэмплируется равномерно из от 1 до n. Вот, каждую итерацию.
Да-да-да, ну, то есть, вот, я просто вот это обозначение, до этого я обводил ксишку, ксишку,
потому что, ну, кси могла быть из d, кси могла быть как раз этим индексом. А здесь я честно говорю,
что у меня кси отвечает за этот индекс. Вот. Вот, потому что теперь я уже ограничился только вот этим
сетапом конечной суммы. Да. Еще раз, ровно потому, как мы начинали с вами, с примера с машинного
обучения. Вот, у вас, пожалуйста, представляет собой вот функция сумма потерян на всех сэмплах,
которые у вас есть в выборке. Вот. Ну, вы же можете посчитать градиенты. Чем хорошо, опять же, то,
что вам вчера рассказывал Саша. Ну, Ёж, то, что у вас по факту вот процесс подсчета полного градиента
вот этого всего безобразия, он делится. Потому что вы к одному даете один кусочек, к другому даете
другой кусочек, и каждый считает градиент по своему куску данных. Просумировали, получили полный
градиент. Вот. Поэтому здесь я могу просто посчитать кусок по куску данных градиент, и в среднем,
потому что я выбираю этот кусок данных равномерно, у меня это будет честный градиент. Вот. Вся суть. Так.
Вот. Первый метод, ну, он исторически тоже первым появился, метод называется saga. Метод называется
saga. Вот. И идея у него довольно естественная и понятная. Смотрите, в чем суть. В силу того,
что я на каждой итерации считаю какой-то стахастический градиент по какому-то индексу И,
и к этому случайному. Вот. Получается, ну, в SGD я просто забываю, что я считал этот стахастический
градиент по этому индексу. Вот. А saga говорит, окей, если я считал этот градиент, то давайте я его просто
запомню. Вот. У меня есть некоторый набор переменных y, которые тоже размерности градиента. Вот.
Размерности градиента. Вот. И в каждую y я изначально записываю нолики. Ничего там нет.
Пусть на текущей итерации, на текущей итерации, я посчитал градиент f и kt. Вот. Тогда, смотрите,
что я делаю. Я его запишу в соответствующий y. То есть вот я знаю, что для этого индекса я
посчитал, я посчитал градиент. Я его записываю. В y запоминается тот градиент, который я считал.
Вот. Остальные y остаются неизменными. Вот. И получается, что тогда вот изначально понятно,
что у меня здесь ничего нет, у y вообще все нули. Я просто делаю что-то типа в духе SGD. Вот. У меня
просто градиент по конкретному f и тому и kt выбирается. Окей. Но потом со временем, когда я
повыбираю множество разных индексов, у меня вот в этой сумме будет в некотором смысле, так,
лениво, что ли, с задержкой копится градиент. То есть когда я уже повыбираю все индексы,
у меня реально все y будут не нулевыми. Будут не нулевыми. И там будет лежать какой-то градиент
для конкретной функции fg. Fg. Единственная проблема, то что тут точка будет какая-то, ну, явно не текущая.
Явно не текущая, а какая-то другая. Вот. Может быть значительно позже, значительно раньше, чем
текущая точка, то есть дальше от решения. Вот. Но суть такая, то что у меня y в некотором смысле так вот
лениво, заторможенно, запоздало копят себе градиент. Полный градиент, он будет нечестный, он будет
такой вот немного покореженный, но это будет градиент. Какой-то похожий на правду. Вот. Ну и в чем
идея? В чем идея? Ну, можно доказать, что там в силу того, что вы выбираете индекс независимо и
равномерно, у вас вот g будет равномерно. По мотожданию равен этому честному градиенту. Ну,
давайте проверим. Вот. Если вы индекс выбираете равномерно, то у вас вот здесь вот берется
мотождание по и-катому. Тогда что здесь получается? 1 на n сумма f и тых, x-катых. Это я просто
выписал определение математического ожидания для первого слагаемого. Каждая из слагаемых я
выбираю с вероятностью 1 на n. 1 на n я просто вынес за пределы этой вероятности. Вот. Ну и
аналогично с y. С y там будет 1 на n сумма y. Ну и сумма y между собой сократятся. Она вот здесь есть и
здесь есть. Все, они между собой сократятся, а вот эта сумма это же просто честный градиент. Вот.
Поэтому здесь получается по мотожданию честный градиент. При этом вот опять же,
как я сказал, y это запоздалая версия. Вот. При этом что можно сказать? Что здесь хорошего можно
сказать? Когда у меня x стремится к, как со звездой, ну я предполагаю, что это так. Это можно, конечно,
доказать отдельно. То есть мы не будем доказывать уже сходимость этих всех алгоритмов. Вот. Просто
смотрим на физику. Вот. У меня в y тоже будут в итоге, через много-много итераций, когда я обновлюсь,
обновлюсь, обновлюсь несколько раз, градиент стремится к градиенту в точке x со звездой. Да,
мы знаем, что этот градиент не равен нулю. Не равен нулю. Но в тумме-то это будет стремиться к
полному градиенту. Поэтому вот то, что у меня хранится в сумме y, это 0. То, что у меня хранится в
сумме y, это 0. При этом, что я еще знаю, вот это будет стремиться к 0, вот это будет стремиться
к градиенту f и kT x со звездой, и это будет тоже стремиться к градиенту f и kT x со звездой,
потому что x kT
что по мотоожиданию равно несмещённой оценке градиента,
то есть несмещённая оценка градиента G,
просто нашего целого градиента,
но при этом будет стремиться к нулю при исходимости к оптимуму.
То есть SGD тоже давал несмещённую оценку,
но у него дисперсия была некомпенсируема,
она давала ассоциации.
Тут, в связи с тем, что дисперсия будет в итоге стремиться к нулю,
потому что у меня G-кат стремится к реальному градиенту,
я и буду получать эффект, который называется редукция дисперсии,
то есть уменьшение и устранение дисперсии.
Вот вся физика.
SGD, соответственно, такой вот метод, который первый это сделал.
Минус, понятный тоже, это лишняя память.
В силу того, что вам нужно для каждого индекса хранить свой Y, это дорого.
Понятно, что если задача машинного обучения довольно большая,
ну там какие-то регрессии, то есть какие-то маршрумсы, которые вы обучаете,
это всё, конечно, просто.
Там это можно ещё хранить.
Но когда вы обучаете неровную сетку,
лишняя память размера количества сэмплов умножить на размер сетки,
это всё замечательно.
То, что вам рассказывала Ёж про миллиарды, это правда.
Даже если у вас там количество бачей, которые вы используете,
ну десятки тысяч, то есть десятки тысяч на миллиарды,
это прям огромное число, это невозможно хранить.
Поэтому появляется ещё одна модификация,
ну друг у друга просто подход,
так называемый SVRG,
Stochastic Variance Reduction Gradient,
ну в честь него как раз редукция дисперсии,
ну появилось вот это понятие редукция дисперсии.
Вот.
Тут подход следующий.
Давайте я скажу так.
У меня есть некоторая референсная точка V.
Это то, что вам рассказывала Катя, должна была рассказывать вчера.
Вот.
Вы в этой референсной точке считаете полный градиент.
Вот.
А дальше суть следующая.
Вы опроксимацию градиента делаете с помощью этой референсной точки.
Вы как бы из полного градиента вычленяете тот кусочек,
который соответствует текущему бачу,
ну текущему индексу, который вы выбрали,
и заменяете его на тот градиент,
по этому индексу, который посчитан в текущей точке.
Вот.
Вот такая вот идея.
То есть тут вот все завязывается на референсную точку.
Вы очень редко считаете полный градиент.
А дальше с помощью этого градиента в некотором смысле апроксимируете,
апроксимируете полный градиент.
То есть по-хорошему вам бы хотелось, конечно, считать вот что-то вот такое.
Вот.
Но здесь вы видите как бы из-за того, что вы здесь берете разность,
вы можете в некотором смысле сказать,
что вы сюда привнесли какой-то клад от реально текущей точки,
ну и они могут быть действительно похожи.
Более того, если вы, мы так вот просто порассуждаем,
если у меня x-кате стремится к x звездой,
тогда у меня и v тоже будет стремиться к x звездой.
А получается то, что и g будут стремиться к x звездой.
Почему?
Потому что вот это стремится у меня к f, it, kt, x звездой,
и это у меня стремится к f, it, kt, x звездой,
что не ноль, но хорошо, без разницы, это не страшно, они друг друга сейчас убьют.
А это у меня будет стремиться к нулю,
потому что v стремится к x звездой, а полный градиент будет стремиться к нулю.
Вот.
Здесь вот такая вот идея.
Полный градиент через вот эту разность,
через такую-такую разность, через референсную точку.
Вот.
И здесь уже никакой памяти лишней не нужно,
как это было в сага.
Вот.
Здесь вы просто вот, к сожалению,
это тоже минус, вы сейчас считаете полный градиент,
потому что вроде как мы вообще начинали делать SGD,
чтобы не считать полный градиент, потому что дорого.
Вот.
Здесь вас заставляют делать,
ну, как раз в некотором смысле это минус этого подхода,
то есть в одном случае у вас память страдает,
в другом случае вычислительные ресурсы,
потому что полный градиент дороговато.
Так, это мы с вами обсудили.
Опять же, можно доказать, что по математическому ожиданию это будет честный градиент.
Сходимость к нулю.
Ну и вот из минусов, опять же, полный градиент.
Плюс, каждую турацию вам нужно считать два раза градиент
по текущему бачу.
В точке, соответственно, XK
и в референционной точке V.
Вот.
Ну, что, в принципе, тоже чуть-чуть
удорожает ваш метод.
Удорожает метод.
Вот. Окей.
Со SWRG разобрались.
И третий метод, который тоже является популярным
и, на самом деле, наверное, самым таким рабастым,
ну, и с точки зрения сходимости пантовым,
это SARA.
Вот.
Здесь суть похожа на SWRG.
Вам тоже нужно в некотором смысле иногда считать какое-то референсное значение.
Референсное значение, полный градиент.
Но здесь, соответственно,
авторы предлагают сделать
update чуть мягче.
Чуть мягче, потому что
там вам предлагали всегда отсылаться
к этой референсной точке.
Всегда говорить, окей, я буду считать значение,
иметь градиент референсной точки,
который я сохранил.
Вот.
И, соответственно, считать стахастический градиент в этой референсной точке
и вычислять эту аппроксимацию.
Здесь они говорят, окей,
давайте сделаем чуть помягче
и будем сдвигать
вот этот референсный градиент.
То есть, там он фиксирован вместе с точкой.
А здесь он обновляется следующим образом.
То есть, вот у вас референсный градиент,
вы из него считаете значение...
Тут плюс.
Вы вычитаете значение
по текущему бачу в предыдущей точке.
Вот.
И добавляете опять же значение градиента
по текущему бачу в текущей точке.
И вот у вас этот референсный градиент
в некотором смысле
вот так вот обновляется.
Чем-то похоже и на SVRG,
потому что есть референсная точка.
Чем-то похоже и на
SAGA, потому что у вас
здесь
есть какой-то эффект
сохранения, но при этом нет вот этой
большой памяти.
Но при этом вы как-то перезаписываете
значение градиента
по текущему бачу.
То есть, вот такая вот идея.
Чуть более мягкая, чем SVRG.
И действительно, на практике
по траектории исходимости у SAR
она более плавненькая получается,
потому что референсная точка может быть
очень далеко, особенно на начальных
итерациях.
Поэтому градиент, который вы там считаете,
довольно неприятный становится.
А здесь
с силой того, что вы вот так вот
J пересчитываете итеративно,
референсный градиент становится более плавным.
Исходится это лучше.
Названо, кстати, в честь ребенка.
Это вот у
сейчас помню.
У вьетнамца
Лама, дочка SAR маленькая,
родилась, когда он придумал этот метод.
Кстати, парень заканчивал аспирантуру МГУ.
Нет, магистратуру МГУ.
А потом поехал в Америку
учиться там на PHD.
Сейчас он, по-моему, работает.
Толь в Sony, по-моему,
он работает.
Учился он у Мартина Такача,
у профессора,
к которому я часто езжу, поэтому знаю
историю этого метода.
SVRG, соответственно, про него
тоже более плавненько.
Там уже нет
не смещенности по условным отожданию,
но есть смещенность по
полным отожданию.
Идея ровно такая же.
Почему это стремится
к чему-то хорошему?
Потому что у вас разность стремится к нулю.
Потому что если X стремится к
X звездой, то вот это стремится к X звездой.
Значит, разность стремится к нулю.
Но при этом получается,
что ZHK у вас стремится все же
к константе.
SVRG вроде как было получше.
Здесь у вас в рамках
одной эпохи
ZHK просто застопорится.
То есть в вашем методе вы его запустите,
инициализируете как-то ZHK.
Дальше он у вас пойдет, пойдет, пойдет,
и ZHK в итоге станет какой-то константой,
потому что не меняется.
Но в силу того, что вы делаете этот апдейт,
вы обновляете ZHK,
то она у вас в итоге
становится, тоже будет стремиться
к нулю, потому что здесь
вот точка, которая в итоге встает сюда,
она же стремится к X звездой.
Поэтому и ZHK будет стремиться к X звездой.
В рамках одной эпохи константов.
Ну и давайте кратенько вывод
по тому, что здесь происходило.
Методы редукции диспетчер
вообще хорошая альтернатива, особенно для задач
конечной суммы. Сходимость
будет, тут соответственно, доказана линейная.
То есть тут нет никаких эффектов
от того, что у вас есть стахастика
в градиенте. Более того,
чем классна сходимость всех этих трех методов
в сильно выпуклом случае,
выпуклом она уже отличается, и вне выпуклом
тоже. Но в сильно выпуклом случае
итерационная сложность
общая, то есть учитывая
и внутренние, и внешние циклы, она
будет вот такая вот. На какую
итерационную сложность она похожа?
Какой это метод? Если
N-ку особенно отсюда уберу.
Обычный градиентный спуск, правда?
Вот. А то
какая сложность у градиентного спуска?
У него стоит одна итерация.
Он должен посчитать полный градиент,
а это будет в N раз
дороже, чем здесь.
То есть здесь итерация стоит, условно, единицу,
потому что нужно посчитать только один
сэппл, ну либо два, вот единицы, будем так
говорить. Вот.
Ну и на эту N-ку вообще можно забить, то есть
там у градиента спуска оценка будет вот такая
вообще, на сложность именно
если мы не говорим не на итерационную
сложность, а именно сложность по количеству сэмплов,
то тут будет сложность вот такая. Понятно, что
на эту N-ку L на μ это у вас больше единицы,
поэтому на эту N-ку можно вообще
не смотреть. Вот.
Получается, что он в N раз дешевле,
а делает столько же итераций,
теории. Но это супер.
На самом деле получается, вы за бесплатно
имеете метод, который
сходится значительно
так же, но дешевле. Но дешевле,
поэтому
welcome. Но проблема в том, что
опять же
есть свои недостатки, во-первых,
это память,
усаги, подсчет полного градиента
УСВРГ и Сары.
С этим пока не понятно,
как иметь дело.
Community не знает на это ответ.
Нет такого метода, который
эти недостатки полностью уничтожает.
Но, в принципе, рабочие варианты
для задачи именно суммы,
задачи минимизации
имперического риска. Есть ускоренные версии,
Катя вам про них рассказывала.
В том числе называется
Катюша. Придумала, кстати, китаец
из Майкрософта. Что-то у него не знаю, но
женские имена его тянет.
У него есть Наташа, есть Катюша,
что-то у него еще есть.
Получается, что для ускоренной методы
свои оценки, понятно, они похожи
на нести русские. Вот такая вот идея.
Все, спасибо, у нас как раз время
произошло к танцу.
