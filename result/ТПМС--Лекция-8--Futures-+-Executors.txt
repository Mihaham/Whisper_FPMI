Ну что, мы готовы начать? Давайте начнем сегодня с пулопотоков, которые мы хорошо уже, надеюсь,
знаем, которые мы давно уже написали, и вспомним про его метод Submit, который, я напомню, занимался
тем, что планировал задачу на исполнение в одном из потоков Worker. И когда мы обсуждали этот
Submit, я сразу заметил, что мы вот ничего сложного от него не хотим. Мы хотим, чтобы он просто
исполнил рано или поздно задачу. Но мы не хотим усложнять этот метод какой-то дополнительной
функциональностью. Ну, что я имею в виду? Вот мы бросаем в ThreadPool задачи, а потом можем дождаться,
пока все задачи выполнятся. Для этого у нас есть метод WaitIdle. Ну а скажем, у нас нет возможности,
имея просто базовый ThreadPool, каким-то образом дождаться исполнения конкретной задачи. Или
получить из нее результат. Вот ThreadPool нам такой возможности не дает, и более того, я говорю,
что мы от ThreadPool такой функциональности не хотим даже. Почему не хотим? Потому что оказывается,
что вот эту задачу можно решить отдельно от ThreadPool, независимо от ThreadPool, а потом в
ThreadPool некоторые инструменты использовать. И решение в нашем курсе, в задаче про future называлось
Para-Future-Promise. А закрывайте, пожалуйста, двери за собой, когда вы заходите в аудиторию.
Итак, как это решение выглядело? Мы строили такой односторонне направленный одноразовый канал
в виде пары promise и future. Promise – это конец канала на запись. В него можно было поместить значение.
Future – это конец канала на чтение. Оттуда значение, ну или ошибку, которая с другой стороны возникла,
можно было получить. Мы создавали вот эту пару или так, можно сказать, что контракт мы создавали
promise и потом из него строили future. И конец канала на запись promise отдавали потоку условно продюсеру,
который генерировал данные, который, скажем, вычислял что-то в ThreadPool, а другой конец – future,
канал для чтения, мы выдавали клиенту, который задачу дожидался. И вот мы этот канал прокидывали
между task в ThreadPool и клиентом и получали возможность заблокироваться до тех пор,
пока задача не завершится. Ну и из нее получить значение или ошибку получить. При этом future и
promise в ThreadPool ничего не знали, разумеется. Они были полезны и разумны сами по себе,
но будучи скомбинированными с полом потоков, мы вот решали задачу, которая у нас была в пуле
потоков – дождаться завершения задачи конкретной. Так что вот такой сам по себе разумный инструмент.
Но в задаче сразу говорится, что мы делаем такие, очень упрощенные future, мы делаем аналог
STD future, но на самом деле вот сегодня лекция про то, что future и promise – это инструмент гораздо
более общий, гораздо более сложный, гораздо более интересный и выразительный, чем то,
что мы имеем в этой задаче. И сегодня мы поговорим про хорошие future, а не про STD future,
которых future на самом деле отношения никакого не имеет. Итак, что мы понимаем под хорошими
future? Ну давайте я начну с таких довольно синтактических изменений, которые пока не
отражают сути, но уже делают future чуть-чуть аккуратнее. Вот давайте подумаем, что вы могли,
если вы решали задачу, что вы могли заметить, чем future не очень удобно вот эти. Ну, например,
у STD future, у STD promise вернее есть метод, который называется make future, который строит future по
promise. И вот в этом API уже кроется некоторая хрупкость, некоторая уязвимость инструмента,
потому что логически у нас такой одноразовый канал, конец на запись, конец на чтение. И
продолжаем. Тут просто есть некоторая опасность, что у нас прервется запись
скринкаста, когда миграет проектор. Итак, есть логически такой одноразовый канал,
при этом у promise есть метод make future, который в принципе неаккуратно невнимательные пользователи
может позвать дважды. Это было бы странно, это не имеет никакого смысла. У future и promise есть
возможность предыдущего одного значения. Значение можно получить только один раз,
потому что в общем случае оно move only. Так что вызвать метод make future дважды смысла не имеет.
У нас проблема с проектором. Будем аккуратно, не будем совершать резких движений. Ну вот. Так что,
во-первых, мы от этого make future избавимся и скажем, что у наших future promise будет просто функция,
которая называется make contract, которая параметризуется типом, и эта функция сразу
возвращает нам пару future и promise. Мы строим оба конца канала разом, потому что логически
этот канал contract так возникает. Дальше. Смотрите. В наших future для того, чтобы позвать на promise set
value или на future get result, но здесь называется get result, а не get, разницу объясню чуть
позже. Мы используем вот такую вот форму. Мы говорим set the move promise set value. Зачем мы так делаем?
Ну вот логически, физически мы здесь никакой promise, никакую future не перемещаем в памяти. Но
с другой стороны, set the move сам по себе тоже ничего не перемещает. Это всего лишь преобразование типа,
ссылки. Так вот. Что я здесь хочу таким кодом сказать? Я говорю, что методы set value или get
result симметрично на future, они, их можно вызывать только на объекте rvalue. Для того, что и такое
определение требует, чтобы мы сгставали ссылку там lvalue к этому самому rvalue, и таким образом я
хочу сказать читателю этого кода, что метод ну условно потребляет future значение, которое там
было. Или ну так тратит, использует одноразово promise. Ну то есть, если вы пишете в коде move,
если вы перемещаете объект в памяти, то, вероятно, объект, из которого вы переместили,
он уже для пользователей недоступен. Но его неразумно использовать, потому что там уже
ничего нет. Он в каком-то непредсказуемом странном состоянии. Ну вот такой код, он эту мыс, эту идею и
выражает. После того, как мы сделали set value на promise, его использовать нельзя. Идея понятна? Вот так мы
говорим читателю, ну или в общем случае линтеру, который может автоматически это проверить,
что мы, что к promise больше обращаться не надо, что мы его и стратили. Ну и симметрично для future
тоже самое. Третье отличие. Что происходило, когда в promise, точнее, когда в продюсере
возникало исключение, возникала какая-то ошибка. Мы ее прообразовали через shared state в
консьюмера. И консьюмер вызывает get, получал это исключение, оттуда оно вылетало. Вот мы хотим
сегодня несколько обобщить механизм обработки ошибок во future и promise и скажем, что когда
пользователь вызывает на future метод блокирующий get, то он получает не значение или исключение,
он получает результат. Результат, он вот буквально представлен классом result. Result t,
который представляет себя или значение типа t или некоторую ошибку, упакованную в специальный
контейнер. И эта ошибка, это либо исключение, либо exception pointer, либо это error code. И пользователь
уже сам имеет этот result, решает как именно, в каком стиле он собирается с ошибками работать. Он
хочет работать с исключениями или он хочет работать с кодами ошибок. Для этого у него есть свобода.
Ну вот, скажем, он получает из функции результат типа int и может проверить, верно ли, что в
результате есть значение, что оно не пустое. Что там не ошибка, вернее. Ну и там ее как-то
обработать. Что важно, главный такой правил обработки ошибок, их нельзя игнорировать. И
инструмент не должен позволять игнорировать ошибки. Ну вот, скажем, у вас есть функция foo,
которая возвращает result int. Тут у нас такой статический конструктор именованный, который
упаковывает значение в этот самый контейнер result. И вот если мы напишем такой код, то он
компилироваться, надеюсь, не должен. Почему? Ну потому что result no discard. Он говорит, что значение типа
result должно быть обработано. И мы его можем обработать в данном случае двумя способами. Мы
можем вызвать throw if error на result. И он нам либо значение распакует, либо бросит exception,
если там была внутри ошибка. Или мы можем сказать, что expect value or и некоторый текст. Это assert. Ну
или там мы удостоверяемся, что ошибки точно не было. Вот мы считаем, что в этом месте не должно
быть ошибки. Не знаю, мы пишем базу данных, добавляем запись в write a headlock, и если ошибка
случилась при записи в write a headlock, то у нас нет никакого разумного способа это обработать. Мы
просто должны упасть. Вот этот способ сказать, что мы ожидаем здесь успешного завершения, и вот
продолжить не готово, если возникла ошибка. Короче говоря, вот у вас есть инструмент, который позволяет
работать с ошибками в разном стиле, и чуть позже станет понятно, почему он здесь просто необходим.
Ну вот, значит, это еще одно отличие наших фьюч пока от std-future. Мы возвращаем такой вот
контейнер, который содержит либо значение, либо ошибку, но не может быть пустым. Но, конечно,
это все пока изменения довольно незначительные. Мы хотим чего-то более основательного, и сейчас
мы разберемся, а чем же по-настоящему отличаются фьючи от вот наших детских игрушечных фьюч,
которые мы писали в домашней работе пока. Они отличаются тем, как фьючу можно, как значение,
ну или результат, который попадает во фьючу, можно использовать, можно потребить. Вот для этого,
до этого у нас был только блокирующий такой синхронный способ. Заблокировать поток, дождаться,
пока значение или ошибка не появится. К нему мы добавляем сейчас асинхронный способ, а именно мы
добавляем возможность истратить фьючу асинхронно, повесить на нее обработчик callback.
Вот у нас есть контракт, ну здесь он на самом деле скрыт от вас. Мы здесь используем функцию
async via, которая берет threadpool, берет лямбду и запускает эту лямбду в пуле потоков, вот в этом
вот. Сразу передает задачи в promise, а нам возвращает фьючу. То есть мы превращаем такую
синхронную функцию в асинхронную, которая исполняется в пуле и сразу получаем фьючу,
которая представляет вот этот самый асинхронный результат вычисления. А дальше мы на нее вешаем
обработчик, который будет вызван, когда задача в пуле завершится. И снова мы говорим stdmove
subscribe, потому что мы тратим фьючу, после этого ее использовать нельзя. Потратить фьючу можно
только один раз. Вот здесь мы используем асинхронные аппелли, то есть subscribe завершается мигом без
ожидания и когда асинхронная задача в пуле потоков завершится, в promise попадет значение,
на фьючу вызовется обработчик callback и вот он получит результат своим аргументом. И вот тут
сразу понятно, что без резалта, в общем-то, жить было нельзя, потому что... Но вот здесь callback,
он не может получить аргументом, там, не знаю, исключения, это было бы странно. Исключения он
должен разворачивать стэк. Здесь у нас никакого стэка нет, здесь просто какой-то асинхронный
вызов и поэтому вот здесь неизбежно возникает необходимость как-то ошибку представить в виде
объекта. Ну, вспомните ASIO, про который мы говорили, который сейчас у вас задача slip4, там тоже все
callback принимают аргументом ошибку, потому что никакого другого механизма здесь представить
невозможно. Ну что ж, идем дальше. Subscribe это первый шаг в сторону разумных фьюч. В разумных
фьючах всегда есть способы обработать ошибку синхронный и асинхронный. Ну более того, я даже
скажу, что на самом деле, имея вот такой асинхронный способ использовать результат, который подает во
фьюч, можно от синхронного вызова get, асинхронного метода get во фьюч избавиться, он вообще-то там
не нужен. Если у вас есть subscribe, то вы можете get выразить снаружи, просто как свободную функцию.
Ну, возможно у вас еще повод представиться в домашней работе. Ну, а пока мы продолжаем. И вот
сейчас с помощью метода subscribe мы можем подойти как раз к... Давайте прежде чем мы подойдем к
самой сути. Такое маленькое синтактическое замечание. Если у нас вдруг есть API, которая
построена на кулбеках, то всегда можно преобразовать его в API, которая использует фьюч. То есть,
если у вас есть какая-то библиотека и там асинхронные операции, и они вызывают кулбеки,
то вы всегда можете это API переписать на фьюч, так чтобы у вас код был достаточно однородным. Ну,
вот точно так же бросаете в кулбек promise, там вы комплите, и с другой стороны из фьюча достаёте
результат. И имея кулбеки, дальше вы можете... Имея кулбеки и такой вот асинхронный subscribe,
дальше вы можете добиться... Дальше вы можете выражать с помощью фьюч свои асинхронные мысли,
асинхронные обработчики гораздо более декларативно, чем бы вы делали это с помощью кулбек. Ну,
представьте себе такую проблему. У вас есть... Давайте я покажу пример из библиотеки Folly. Согласен.
Представьте, что у вас есть некоторая асинхронная API. Функции, которые принимают некоторый вход,
и вы передаете кулбек, который будет вызван, когда асинхронная функция завершится. А дальше у
вас задача. Вы можете... Вы хотите вот эти асинхронные действия выполнить последовательно.
Ну, как вы такой код пишете? Вы строите такую пирамиду. Вы пишете вызов первой функции и в
обработчик передаете. И в качестве обработчика помещаете код, который вызывает вторую асинхронную
функцию. А в качестве обработчика второй асинхронной функции вы вставляете лямбду,
которая вызывает третью асинхронную функцию, и вложенность растет. Ну, и у вас получается вот
какая-то такая картинка. То есть, в общем случае, пирамида, она такая достаточно глубокая.
Фьючи позволяют, трансформируя, ну, избавившись в API от кулбеков, решить такую задачу очень
эрегантно. Как запланировать цепочку асинхронных последовательных действий? Ну, вот для того,
чтобы понять, как это делается, нужно немного обобщить в своем уме понятие фьючи и промеса,
и отказаться от вот той интерпретации, что промес и фьюча — это такой одноразовый канал. Вот не
нужно так об этом думать, потому что вы сразу можете задуматься над вопросом, а зачем канал
у два конца отдельных, почему не сделать один класс вот всей этой истории. Нет, про фьюч нужно
думать иначе. Вот у вас может быть вызов функции обычной в коде, и он возвращает вам некоторое
значение. А теперь у вас функции бывают асинхронные, которые исполняются где-то когда-то.
И у этих funkций тоже есть результат, только он асинхронный, только он из будущего. И вот
это будущее представление, точнее, представление будущего результата и называется фьюч. И вот это
значение будущее, оно вот, операция только началась, а вы уже получили это будущее, это
представление будущего результата, зачем оно вам? Затем, что им уже сразу можно воспользоваться,
а именно, передать в следующий вызов, который ожидает этого самого значения.
Правда, не будущего, а обычного. Но, тем не менее, вот смотрите, пусть у вас было это
самое будущее значение, и пусть у вас была функция, которая ожидала этого
будущего значения. Но, правда, не в виде фьючера, разумеется, а в виде резалта. То есть,
либо значение, либо ошибка. И возвращал какое-то свое значение другого типа.
И вот мы хотим это будущее значение передать в эту функцию. Но, разумеется,
мы буквально это не можем сделать, поэтому мы пишем такой специальный комбинатор,
который называется Zen. Вот этот такой способ передать будущее значение в функцию.
У нас была первая фьючер, которая занималась каким-то асинхронным
вычислением в пуля потоков. И мы к ней вешаем, это называется продолжение,
обработчик будущего значения с помощью Zen. И получаем следующую фьючер, в которой уже
будет значение, вот которое будет вычислено здесь, когда вот это значение,
когда в этой фьюче появится свое значение. Понимаете, что происходит? Вот мы, по сути,
запланировали такой маленький конвейер из двух последовательных задач. А дальше мы можем
заблокироваться, ну и дождаться, пока значение там появится. Не знаю, давайте примеры запускать,
а то что я вам рассказываю и ничего не показываю. Немного странно.
Терпение.
Ну, 42, 43. Вот мы заблокировались и вычислили это самое 43. Вот здесь, по смыслу, еще раз,
мы передали асинхронный результат в следующую функцию. Для этого нам нужно было иметь просто
некоторую материализацию представления этого будущего результата. И вот фьючер, она про это и есть.
А дальше вы можете делать вещи чуть более сложные, а именно выстраивать прямо конвейеры из таких вот
шагов. Вот у нас есть некоторое вычисление, потом умножение на 2, потом плюс 1. Короче,
какой-то конвейер. И вот мы делаем первый асинхронный шаг, а потом мы планируем цепочку действий,
которые за ним последуют. И вот весь этот код, он исполняется мгновенно, он ничего пока не делает,
он просто планирует работу. А потом, по мере готовности вот этого результата, запускается вот
этот обработчик, потом следующий, следующий, следующий. Вот эта цепочка задач выполняется.
Выполняется. Ну, кстати, вот мы не поговорили и вы не спросили, что довольно невнимательно было
со всех наших сторон. Смотрите, вот код, мы подвесили обработчик. Вот давайте задумываемся,
где он вообще выполнится, в каком потоке. Ну, у нас есть с фьючерами и промесами работают два
потока. Один продюсер, другой консюмер. Один делает сетвейли, другой делает сабскрайп. Ну,
и очевидно, чтобы обработчик кулбэк вызвался, нужно иметь и кулбэк, и значение, и результат.
Поэтому кулбэк может вызваться тогда, когда случится вот рандеву продюсера и консюмера,
когда они оба придут. Вот. Ну, и тогда вот неизбежно возникает ответ. Обработчик будет вызван в том
потоке, который придет вторым в shared state. Ну, вы знаете, как фьючи реализованы. Между фьючей и
промесом есть shared state, на котором есть синхронизация. И вот тот поток, который придет в него вторым и
положит либо кулбэк, либо значение, или там результат, то есть вот тот поток обработчик и вызовет.
Ну, вот если мы говорим здесь про зен, то вероятно, что вычисление, оно запланируется быстро, и поэтому
вся эта работа будет выполняться в конце концов в пуле потоков. Ну, а где именно она будет выполняться,
мы поговорим чуть позже. Это очень важный момент для нас. Но смотрите, что я хочу сейчас показать вам.
Что вот мы запланировали такую цепочку работы. И вот такая цепочка из фактически таких маленьких
задачек должна у вас вызывать уже достаточно многочисленные ассоциации. Ну, потому что,
смотрите, мы говорили про... Мы делаем файбер прямо сейчас, да? И, кстати, сегодня у вас будет
очередная задача про файбер. Так вот, файбер — это же, по сути, цепочка задач. Каждая отдельная задача — это
такая... Это запуск карутины в пуле потоков. Это очередной такой не блокирующий шаг файбера.
Когда он решает остановиться, перепланироваться или заснуть, он карутину останавливает свою. Ну,
и вот так вот цепочка задач, они друг друга планируют. Каждая очередная задача, она планирует
следующую, то есть продолжение. Ну, и вот так вот файбер бежит. Ну, вот здесь мы, по сути, выразили
нечто похожее, тоже цепочку задач. Ну, или мы говорили с вами про ASIO, про Event Loop, про эхо-сервер,
и там же тоже был... Там уже была, правда, не цепочка, там был цикл задач — асинхронное
чтение, потом E-Poll, потом асинхронная запись, потом E-Poll. Но, в конце концов, вот снова задачи,
которые планируют следующую задачу. Так что все это очень похоже, все это про одно и то же,
и вот эти мы воспользуемся, ну, уже ближе к концу занятия. Вы должны понимать, что мы,
видимо, решаем одну и ту же задачу, но разными способами. К этому я чуть позже приду. Ну, пока
мы здесь, я хочу обратить внимание еще вот на что. Ну, на, собственно, самый Zen. Вот я утверждаю,
что это не какой-то новый метод Fruge, это всего лишь некоторая обертка над Subscribe. Ну, вот,
имея Subscribe, можно делать все остальное в сегодняшней лекции. Вот давайте представим себе,
как может быть устроен этот Zen. Что он должен делать? Ну, во-первых, у нас была одна фьюча,
вот F1. Ей отвечал некоторый Promise, который клал значение, там, shared status. А дальше мы говорим
Zen и передаем продолжение. И мы хотим, видимо, получить новую фьючу, в которой появится результат
второй задачи. Ну, видимо, нам нужно построить новый канал, да? Новую пару Promise,
фьючу, новый контракт, вернее. Ну, хорошо, а что теперь сделает Zen? Ну, давайте вот порассуждать
кто-нибудь. К новой фьюча? Ну, это было бы странно. Которую делает что? Так у нас оно и так уже было,
зачем передавать через лишних уп. И где здесь запуск продолжения главное? Ну, смотрите,
нам нужно вызвать продолжение, когда во фьюче F1 появится результат. Видимо, это Subscribe. Вот этот
Subscribe, он получит что? Результат. Вот здесь вот, да? Он получит Result Future F1. Сможет вызвать
продолжение. Вот эту функцию, вот эту вот функцию. Ну, правда, не Result от Т от Т принимается,
но разберемся. Он вызовет эту функцию, а что он дальше должен сделать? Он должен теперь передать
значение вот второму, ну, второе фьючу, которое мы построили заранее. Так что этот обработчик,
который мы вешаем на F1, будет вызывать продолжение и класть значение во второй
Promise. А вторую фьючу от этого второго контракта мы сразу отдадим пользователю. Ну, то есть в этом
Zen вызывается фактически один Subscribe со специально подготовленным Callback, и вот это весь код работает
без ожидания, без блокировок. Сразу возвращает нам новую фьючу, а первую фьючу тратит, потому что
он вешает на нее асинхронный обработчик. Ну, все, больше использовать нельзя. Поэтому здесь также Move.
И теперь легко понять, кажется, как работает этот код. Вот очередная задача завершается. Она
Completed Promise. В результате запускается какой-то обработчик, который вызывает следующую задачу,
которая в конце Completed Promise. Ну, и вот так вот получается задачи. Выполняются одна за другой,
триггерят одна другую. Вот та же самая ситуация, как у нас была Fiber, как у нас была Vassio. Мы просто,
по сути, сейчас меняем средства выразительности. Как именно мы в коде вот такую цепочку задач
описываем? Хорошо. Ну ладно, у вас уже, на самом деле, если вы внимательно слушаете,
может возникнуть разумный вопрос, а зачем вообще мы все это делаем? Ну, в смысле, зачем мы именно так
это делаем? Но прежде чем мы на него ответим, я прокомментирую еще один нюанс важный. Смотрите,
вот здесь все шаги, каждый последующий шаг ожидает значения предыдущего шага. Но что,
если на предыдущем шаге возникла ошибка? Ну, вот мы пишем какой-то код. Простите,
давайте вот здесь. Пишем какой-то код. Снова выстраиваем конвейер, а потом говорим, ну вот,
не получилось. Не, давайте сначала получилось. Давайте с хорошего начнем. Смотрите, задача. Мы
хотим обрабатывать ошибки. Если мы пишем синхронный последовательный код, то мы обрабатываем ошибки,
ну скажем, с помощью исключений. Пишем здесь блок try-catch, в нем три вызова. Ну, если в каком-то
возникла ошибка, то вызовется вот этот fallback. Мы бы хотели уметь перекладывать такой вот синхронный
код с обработкой ошибок через исключение на вот асинхронный framework наш. Для этого нам
нужен какой-то инструмент, который бы заменял нам этот самый catch. Нет. Дело не в том, чтобы
передавать его по конвейеру, а в том, чтобы описывать логику удобно. Вот у тебя есть три
вызова, они про ошибки не думают, но в этом же смысл этого кода. Ты пишешь этот код, игнорируя ошибки,
и обрабатываешь их только здесь. Ты вот отделил одно от другого обработку ошибок, вот обработки
хорошего сценария удачного. Ну вот, у нас есть, помимо Зена, который связывает два вычисления подряд,
не ожидая там ошибки, есть recover, который получает на вход callback, который принимает на вход уже не
значение, а именно только ошибку, и возвращает значение. Его задача восстановить цепочку задач
после ошибки. И вот если ошибок никаких нет, то в этом коде будет вызван produce, multiply,
increment, и в конце концов эта цепочка терминируется callback-ом subscribe. Ну вот,
давайте запустим и посмотрим, что напечатается.
Ну вот, то есть здесь хороший сценарий, этот обработчик вообще не был вызван,
потому что ошибок не возникало. А теперь мы вот здесь бросим исключение.
Вот, increment не был вызван, multiply вообще сломался, и мы сразу прыгнули, ну не то что сразу
прыгнули, но в конце концов оказались здесь. Ну то есть вот мы придумали асинхронные API,
на которые можно описывать цепочки асинхронных действий и асинхронные обработчики ошибок.
Кажется довольно разумно. Ну я еще не сказал, мы можем делать даже чуть больше, у нас Зен,
он не только может связывать синхронные действия, он может связывать асинхронные действия. То есть,
у нас есть первый вызов, который асинхронный, а за ним мы делаем второй асинхронный вызов,
который тоже, который даже не увозращает основы фьючу от у, и нужно их связать,
такую цепочку. Ну где это может понадобиться? Вообще, откуда берутся фьючи в коде? Давайте
так подумаем. Вот есть очень естественный пример, он довольно сложен, и не то чтобы я сейчас
планирую его вам полностью объяснить, но очень естественное место, откуда берутся в коде фьючи,
это RPC вызовы. Ну вот представим, что у вас есть, давайте другой пример, у вас есть некоторый ваш
сервис, который, не знаю, калькулятор, вот он реализует, по сути, такой интерфейс, есть методы
логические multiply, add, и вот это некоторый код, запущенный на машине, там стоит, не знаю, какой-нибудь
сервер, в котором запускают, который получает запросы по сети и вызывает вот эти вот логические
операции, умножая числа, складывая числа. И вы хотите на своей машине иметь некоторое локальное
представление этого удаленного сервиса. Вот где-то на сервере находится код, который удовлетворяет
этому интерфейсу, вот он называется RPC сервисом, и в нем есть такие обработчики, и у вас есть клиент,
который находится на другой машине, который делает запросы по сети, и вот он хочет послать два
своих числа по сети, для этого он должен их серилизовать в байты, потом отправить там по
комнате CP, дождаться ответа, декодировать его, десерилизовать, в общем какая-то сложная механика.
Вместо этого клиент хочет, чтобы он на своей стороне работал с некоторым, ну это называется
стап, некоторым представлением этого удаленного сервиса. И когда он, этот стап тоже реализует
интерфейс этого самого сервиса, но когда мы говорим о нем multiply 3.7, то что происходит? Мы
делаем RPC вызов, мы вот асинхронно мы посылаем сетевой запрос, в котором лежат имя сервиса,
имя методы, которые мы вызываем, аргументы сервизованные, и дожидаемся ответа. Дело не
быстрое, разумеется. Вообще говорят, там машина, которой мы отправляем запрос, может вообще уже
перезагрузилась, может быть и там некоторое время будет наступно, может быть это вообще выключено,
потому что на дата-центр разломался весь. Так что мы получаем от этого вызова представление будущего
результата. Его пока нет, дожидаться мы его не можем синхронно, поэтому мы получаем фьючу. Ну а
дальше, ну ладно, тут мы можем синхронно ее дождаться, ну в смысле можем, можем так сделать,
а можем и не делать. Ну вот в общем, фьючи, RPC вызовы, это RPC просто, удаленный вызов удаленных
процедур, кажется так правильно. Это очень естественное место, откуда фьючи в коде
прикладном берутся. Ну если вы пойдете осенью слушать спецкурс распределенной системы, то вот
распределенные системы состоят из узлов, которые общаются друг с другом как раз по RPC. Ну вот очень
частое явление. Практически все так и делают. Это механизм общения узлов в сети. Более
выскоуровневый, чем просто такие синхронные сообщения не типизированные. Ну не язык, давай раз уж,
я отвечу на твой вопрос просто чуть позже, давай. Не язык, фреймворк. Еще одно, не знаю, насколько вам
этот пример покажется близок, пока может быть не очень. Еще одно место, еще один способ получить
фьючи, еще один такой источник фьючи, это тайм-ауты. Тоже довольно естественно. Представлять тайм-ауты в
своем коде в виде фьючи. Вот. Правда вы получаете уже никакой результат от Т, вы получаете статус
и результат от Void, то есть ну никакого значения вы не получаете от таймера, разумеется. Ну вот,
callback, будучи подвешен к такому тайм-ауту, сработает тогда, когда вот пройдет нужное время,
полторы секунды. И смотрите, что еще, что еще интересно. Ну вот в коде с RPC мы получаем просто
фьючо. Но у нас нигде нет промесов. Или скажем, посмотрите на пример, который я вам показывал с
Xenomys, то есть с продолжениями с таким конвейером и синхронным. Сколько здесь промесов в коде? Вот
здесь нет промесов. Я не помню, спрашивал или кто-то, или я бы хотел, чтобы меня, чтобы кто-нибудь
спросил об этом. Но вот возникает вообще разумный вопрос, когда вы видите фьючи и промесы, и вам
говорят, что это канал для передачи значения. Зачем канал у два конца отдельных? Ну это логично,
потому что у них разные интерфейс и потоки, которые работают с одним концом и с другим,
они в разных ролях. Но еще один повод разделить промесы фьючо, просто потому, что в прикладном
коде промесов нет. Все промесы спрятаны. Они спрятаны в реализации RPC клиента, там каналы,
по которому придается значение. Они спрятаны вот в сервисе, который строит таймауты. Вот где-то
здесь. В конце концов, сам zen, вот тут же каждый zen, он приводит к тому, что появляется новая пара
фьючо-промес, новый контракт. И вот все эти промесы, которые обслуживают вот эту цепочку,
они тоже скрыты от вас. Так что довольно разумно ожидать, что промесов в вашем коде не будет,
поэтому мы отделим фьючо. И вот тогда фьючо уже становится действительно не концом канала,
которого вообще не видите, а вот они следует думать просто как о будущем значении. Это самая
подходящая для нее интерпретация, для фьючо. Да. Ну выше, в смысле ранее, по конвейеру.
Ну вот, с помощью фьюч можно и такое сделать, но смотрите, может возникнуть довольно разумный
вопрос. Вообще зачем такой, ну зачем так код писать? То есть смотрите, у вас есть некоторые
асинхронные действия, некоторые асинхронные шаги, и вы хотите выполнить их последовательно.
И вот у вас таких вот асинхронных как бы цепочек шагов в программе, допустим,
много для каждого клиента, у вас там свои шаги нужно пройти. Вот как бы вы последовательные
действия композировали в своем коде, как бы вы их выразили в коде, с помощью какого инструмента?
Ну вот удобно, когда вы вызывает, если у вас шаги последовательные, это удобно разделить их
точкой с запятой. Вот пишете, вот ставите точку с запятой, это значит, что вот одно происходит до
другого. Но у вас шаги асинхронные, правда, у вас там возникают какие-то фьючи. Но это вообще,
говорю, не проблема, потому что, ну что вы делаете в таком случае? Вы говорите, вот у меня был один
запрос, вот у меня был другой запрос, давайте я просто сделаю блокирующую операцию, она здесь
называется Await, и вот заблокирую Fiber до тех пор, пока в фьюче не появится значение, заблокирую только Fiber.
Ну можно даже код запустить и посмотреть, что он работает. Он, правда, много всего выведет,
но это отдельный интересный топик, я надеюсь, про него сегодня успею поговорить. Ну вот,
у меня первое, у меня есть два сервиса ударенных, который один speed 2 секунды возвращает bar,
другой, ну это второй, первый speed 3 секунды возвращает foo, тест почему-то работает в нулевое время,
что может показаться странным, но это никакого обмана. Но вот два шага происходят по очереди. Ну и вот,
у меня было два асинхронных действия, я мог бы их запланировать через Zen, а мог бы просто написать
точку с запятой, вот я написал точку с запятой и все. Просто я дожидаюсь фьюч в фиберах. Заблокировал
Fiber, остановил Fiber до тех пор, пока в фьюче не появилось значение. Вот, ну и возникает вопрос,
а зачем мы пишем инструмент, у которого есть вот асинхронные аналоги там для точки с запятой,
для try catch, когда можно просто пользоваться вот, собственно, точкой с запятой и try catch,
и фиберами. И фиберов тоже можно запускать много. Ну ответа здесь никакого положительного нет,
потому что, возможно, это не самое полезное применение фьюч. Ну, по крайней мере, не то место,
где они подходят лучше всего. Вот эти Zen-ы это последовательная композиция каких-то асинхронных
шагов. Вот мы их исполняем друг за другом. Но кажется, что бывает и по-другому, когда мы исполняем
шаги параллельно. Ну вот представим себе такую задачу. Мы пишем базу данных. Вот она просто,
не знаю, она шардирована. В смысле, в ней хранится много ключей там значений, много строчек, и вот мы
на разные машины поместили разные наборы, потому что в одну машину все не помещается. И нам приходит
какой-то запрос, в котором нужно агрегировать очень много данных. Это означает, что, видимо,
нужно сделать какую-то агрегацию, может быть, и какую-то предобработку, в зависимости от того,
как там план запроса построится, оптимизируется, отдельно на разных машинах. И вот мы посылаем три
запроса параллельно в разные машины, в разные шарды, а потом собираем все результаты. Ну опять,
можно вызвать три запроса, потом в цикле вызвать, в цикле последовательно их дождаться. Ну вот пока
опять можно было бы обойтись файберами, но давайте я сразу покажу, что фьючи умеют тоже это делать,
и умеют делать это, я бы сказал, более элегантно. Смотрите, что они умеют делать. Вот мы отправили
два запроса, а потом написали комбинатор, который называется all. Он получил две фьючи и из них
сделал одну фьючу. Это тоже фьючи. Но только здесь каждый из фьюч возвращала, в каждой фьюче
должен быть result от стринг, а здесь мы получили фьючу, которая... что возвращает? Result от... ну тут
не tuple, тут для простоты вектор, потому что фьюч однородный, можно и tuple было бы себе представить,
не важно, действительно. Ну all. All, все. Логично. Что? Ну сейчас any, не понятно, что такое any,
как бы нужно чуть конкретнее. Вот смотрите, вот значит, во-первых, all, да, у нас были фьючи от
int, а стало фьюча от вектора от int после комбинатора all. Ну и, что важно, этот комбинатор, он опять
никого не дожидается, он просто строит фьюч вот моментально. Там что-то... кто-то на что-то
подписывается, там какая-то магия происходит, получается такая одна фьюч. Другой пример. Мы
пишем там, не знаю, поиск, сервис поиска, нам приходит запрос пользователя, он должен быть быстро
обработан, он отправляется на какой-то back-end, где там какие-то инвертированные индексы сканируются.
А теперь представим, что запрос попал на машину, на машину, вот наш back-end поиска, которая тормозит,
ну вот там диск просто стал в 10 раз медленнее, и вот пользователь страдает. Как там быть? Ну,
от медленной машины мы не можем защититься, просто сбои возникают, они возникают неизбежно,
так что нужно не пытаться их избежать, а нужно просто сглаживать вот эти проблемы. Ну вот, мы
как бы, мы готовы пожертвовать, ну то есть мы готовы взять на себя двойную нагрузку, но зато улучшить
опыт пользователя. Мы получаем запрос и отправляем ее на два разных, его на два разных back-end,
и просто дожидаемся ответа первого, самого быстрого. То есть там нам не очень подходит,
в смысле any по семантике это какой-то, а нам не нужен any, нам нужен первый. Поэтому у нас есть еще
один комбинатор для параллельной композиции, он называется first-off. И вот у нас здесь были две
фьючи, одна из них отправляла запрос первому сервису, который спал три секунды, другой спал две
секунды, и вот если сейчас взять две фьючи и скомбинировать их через first-off и дождаться этого
самого first-off, то мы получим, видимо, я забыл, снова кто из них самый быстрый, кто медленный,
второй быстрее, да? Тогда навернется bar. А если мы подправим здесь время работы,
то видимо теперь будет foo.
Это хороший вопрос. Давай чуть позже на него отвечу, если не забуду, конечно. Я уже и так один
вопрос должен. Итак, что я хотел всем этим показать? Что есть сценарии, где комбинирование
вычисления комбинируется параллельно непоследовательно. И вот first-off означает,
что мы запускаем параллельно два запроса, делаем два запроса удаленных и дожидаемся вот первого,
кто закончится раньше. И вот кажется, что адекватно такая логика, ну не то что адекватно, удобно,
лаконично, ясно, вот такая логика через файберы не выражается. Не находите ли вы? Вот, ну ладно,
я сейчас к этому еще вернусь перед тем, как сравнивать файберы и фьючи. Замечание, что вот
мы с помощью фьюч научились два типа композиции делать. С одной стороны выполнять действия
последовательно, планировать их последовательно. С другой стороны, иногда что-то распараллеливать,
если нужно, с помощью all или first-off. First-off и all. И вот теперь мы можем планировать не только
цепочки задач, теперь мы можем планировать, вообще говоря, графы задач. Какая-нибудь картинка
подходящая, ну вот. И давайте я вам порекомендую просто замечательную, совершенно великолепную
статью, которая называется e-server-the-function. Эта статья написана, ну, давным-давно уже на
самом деле, но кажется, что она не сильно устояла. Это статья инженера твиттера про то, как они пишут
всю свою логику. Вот они используют микросервисную архитектуру, и у них каждый сервис написан на
фреймворке с фьючами, который называется finagle. И если что, вы можете пойти и посмотреть его,
он, кажется, написан на скале. Там много всего, то есть, конечно же, там не только фьючие и
промесы. Там много всякой инфраструктуры вокруг них, там метрики, трейсинг, логирование, контекста,
ну вот, если вы знаете, что это. Но не суть. Они говорят, что вот у них вся, весь инфраструктурный
код, он декомпозируется очень модульно на три сущности. Вот они говорят, что у них есть фьючи,
которые представляют будущие результаты каких-то асинхронных конкурентных действий. У них есть
сервисы, и у них есть фильтры. И вот что такое, значит, ну что такое фьючие, мы уже понимаем. Это
результат некоторой асинхронной работы. Что такое сервис? Сервис — это асинхронная функция, оно,
собственно, в сервисы порождают фьючие. Это локальное представление удаленного endpoint. Ну вот,
стабы в RPC, то есть некоторое локальное представление какого-то удаленного компьютера с каким-то
набором методов. И у нас есть фильтры, которые позволяют каким-то образом декорировать вот эти
асинхронные операции. Там добавлять трейсинг, логирование, что-то, какой-то сбор статистики. Самые
разные вещи. И вот вы, комбинируя все вот эти вещи, можете описывать какие-то графы, которые
обрабатывают запросы, вызывают там какие-то цепочки вложенных RPC, собирают результаты,
там дожидаются первого, еще чего-то такое делает. И при этом вы имеете очень модульный фреймворк из
таких вот довольно артагональных, хорошо комбинируемых сущностей. Вот вы в этом фреймворке
можете выразить всю свою логику. Я, кажется, ответил на вопрос, который был раньше, да, я забыл. Вот,
то есть на фьючах, в принципе, можно все написать. И так некоторые делают. Эта статья еще очень
хороша, потому что здесь есть интересные металонаблюдения. Вот одно из них следующее,
мне кажется, что оно очень крутое. Смотрите, вот как можно сравнить фьюча и файберы? Ну,
с одной стороны, это разные механизмы, да? Синхронный и асинхронный. Ну, просто API разная,
то есть под капотом все примерно про одно и то же, про то, чтобы задачки запускать по событию,
по мере готовности. Вот, но выглядит они очень по-разному, синхронный и асинхронный. Так вот,
говоря про фьюча, автор статьи утверждает, что этот фреймворк, ну, в смысле этот подход,
это средство выразительности, оно гораздо более декларативное. Ну, и вообще оно должно напоминать
функциональное программирование, функциональный подход. Почему? Потому что, когда вы пишете,
ну, вот смотрите, мы вот в этом коде сделали два вызова асинхронных, а потом дождались первого.
Где в этом коде синхронизация написана? Ну, в этом коде вообще нету. Она внутри фреймворка,
она внутри RPC, она внутри вот этих комбинаторов first-off. Вот в этом коде нет синхронизации. В этом
коде только написано то, что мы хотим делать, то, что мы хотим получить. Мы не думаем, вот,
утверждение. Если мы пишем на файберах то же самое, то мы думаем про control flow,
про поток управления, про то, как файберы запускаются, как там по ним двигаются курсоры,
как там они синхронизируются друг с другом. Вот, а в этом коде мы от control flow переходим
к data flow, то есть мы думаем про то, как данные, ответы текут по графу. Вот у нас есть некоторый
граф запросов, и по нему текут ответы. Собираются там, отбрасываются, что запускается там дальше. Мы
не думаем про то, как это синхронизируется, мы не думаем там про какие-то мютексы, колбэки,
там какие-то атомики для синхронизации. Ну короче, у нас все этой внутренней машинели здесь нет.
Есть только то, что мы хотим сделать. Все эти, вот, все промесы, вся синхронизация, все shared
state и все это от нас спятано. Кроме того, ну, future сама по себе, future и Zen, это же, ну,
очень функционально. Вот если в императивном программировании мы говорим про мутацию
состояния и в файберах мы говорим про мут разделяемое состояние, которое меняется разными потоками, то
что происходит здесь? Здесь у нас read-only future, и мы как бы передаем одну future на выход, на вход
следующей функции, и она получает нам, она дает другу следующую future. Это вот ровно функциональный
способ выражать последовательные действия. Понимаете, о чем я? Вот, мне кажется, что это
очень, ну, это очень хорошая, очень содержательная аналогия, и вот она, собственно, подчеркивает
сильную сторону future. Но, с другой стороны, некоторые действия все же удобно выражать,
ну, разделять точкой запятой, просто потому что они по логике последовательные. Поэтому, в общем
случае, я бы сказал так, что есть future, есть файберы, и это просто два разных инструмента,
которые не нужно друг другу противопоставлять. Нужно просто их использовать в комбинации,
использовать сильные стороны одного и другого. Если у нас действия происходят подряд, асинхронные,
ну вот, используйте файбер, точку запятой пишите, блокируйте, останавливайте его. Если у вас
композиция параллельная, если вы там отправляете три запроса, дожидаетесь первого или там первых
двух, что бывает часто в определенных системах, то вам удобно использовать future и комбинаторы.
Вот что вам по смыслу задачи больше подходит, то используйте. Ну и вот осенью мы будем писать там,
скажем, алгоритм Paxos на распределённых системах, и там алгоритм с фазами, то есть одно сделать,
а потом другое сделать. А внутри фазы параллельная работа. И вот в одном месте нам нужны файберы,
нам удобно файберы использовать, в другом месте нам использовать удобно future. Просто мы комбинируем
оба подхода в зависимости от того, какой из них в данный момент больше подходит. Теперь к вопросу
про first-off и про... То есть ты отправил два запроса, получил первый ответ, второй тебе не нужен. Вот это
на самом деле очень тонкая, очень сложная тема, потому что я говорю вам, что вот future позволяет
собрать граф в вычислении, по которому текут данные, и у вас здесь есть некоторое такое врожденное
ограничение, что данные текут по стрелочкам в одном направлении, от продюсера к консюмеру. Но
вообще говоря, вам иногда хочется передать какой-то сигнал в обратную сторону от консюмера к
продюсеру. И вот тут уже future в таком вот голом виде вам не помогают. А вам хочется сделать такое,
вы отправили два запроса, дождались первого, и вам уже второй не нужен. И вам нужно как-то отменить
работу, которая синхронно происходит. Что значит сигнал? У нас действие работает вообще на разных
машинах, у нас стек вызовов по разным машинам распределен. Какой сигнал, о чем ты? Если рассуждать
на таком низком уровне абстракции, то, конечно, у нас есть инструкции процессора и пакеты в сети,
но мы здесь занимаемся действием немного другом масштабе, мы изучаем средства выразительности.
И короче, я даже не знаю, как ответить на твой вопрос, я воздержусь пока что. Нам нужен какой-то
адекватный инструмент для того, чтобы выражать поток каких-то действий в обратном направлении,
против того, как мы передаем от промесов к future. И вот этот сложный вопрос, он называется
cancellation, то есть отмена действий асинхронных. Ну вот если все сложится для нас удачно,
то мы в конце курса, может быть, в самом конце поговорим про это, про то, как такое писать. Но
это очень сложная тема, она вот, мне кажется, не так давно начала развиваться, не так она хорошо
развита, как сами вот эти инструменты типа fiber of future. Ладно, к этому мы еще придем. Проблема такая есть.
Нет, ну в каком-то смысле да. Контекст, он вообще, можно по-разному его интерпретировать,
он достаточно общий, но в том числе для этого. Для того, чтобы представить себе полную картину,
вот честную, нужно понимать не только concurrency, нужно понимать RPC, как это все, и там вот и трейсинг
распределенный, и как это все друг с другом интегрируется, комбинируется, это сложная задача.
Но это скорее про осенье разговор, где мы эти инструменты будем изучать. Пока я просто обозначаю
проблему, что нужно передавать данные в обратном направлении, для этого нужно иметь какие-то
адекватные высокоуровневые выразительные средства. Вот future нам здесь, нас ограничивают. Ну что,
если я объяснил про вот такие вот комбинаторы для последовательной параллельной композиции,
про то, как что-то выражать в фьючах, я бы хотел в оставшееся время посвятить не тому,
как что-то на фьючах, ну в смысле, как пользоваться фьючами, а тому немного про
реализацию поговорить. Вообще говоря, реализация ложится на ваши плечи, ну поскольку домашняя будет
про это. Но есть один нюанс, который нужно необходимо разобрать прямо сейчас. Вот вернемся к
Subscriber. Значит, у нас есть Threadpool, у нас есть Future Promise, мы кидаем Promise в задачу в Threadpool,
и Completing Future отправляем через Promise Set Value. В потоке снаружи Threadpoolа мы подписываемся
на результат, вешаем обработчик. И возникает вопрос, а в каком потоке этот обработчик будет
вызван? Ну, мы уже, кажется, выяснили, что он может быть вызван либо в одном потоке, либо в другом. Вот
давайте это продемонстрируем. Вот у нас есть Threadpool, у нас есть поток, который, ну Main,
который вешает обработчик, и вот мы печатаем Thread ID в основном потоке, в потоке, который
выполняет Future, и в потоке, который вызывает Callback. Вот что мы ожидаем от этого примера? В
каком потоке будет вызван Callback? В этом или в этом? Что значит непонятно? Понятно.
Тут вопрос нигде мы хотим, вопрос, где он будет вызван. Вот перед вами код.
А можешь рассуждение привести, потому что... Сейчас подожди, мы снова ничего не понимаем. Мы
выяснили, когда вызывается Subscribe? Когда будет и Callback, ну, в смысле, когда вызывается
обработчик? Когда будет и Callback в SharedState, и значение? То есть кто придет вторым? Кто придет
вторым SharedState? Ну, скорее всего, Setfairy, потому что там задача положится в очередь,
потому что нужно достать, запустить, а мы пока все это происходит, мы просто вешаем Subscribe
довольно быстро. Ну, то есть понятно, что ответы недетерминированы, то есть непонятно,
что произойдет быстрее. Но можно... Что? Спасибо. Ну вот, Callback вызвался в том же потоке,
где был вызван Setfairy, то есть Streadpool, потому что задача выполнилась, видимо, позже, чем
мы подвесили Callback. Вот. А теперь, что я сделаю? Я раскоммунитирую Slip4. Ну и, видимо, за секунду
задача в Streadpool все-таки выполнится, поставить Setvalue, запускать Callback она не сможет, потому что
его еще нет, а потом я вызову Subscribe здесь, и вот случится рандеву в SharedState, там встретится
и продюсер... Ну, в смысле, знач... Консюмер встретится там со значением, с результатом от продюсера,
и, видимо, сейчас Callback поменяется на... Threadedit поменяется на Subscribe.
Ну, то есть теперь Subscribe был вызван прямо в этом потоке синхронно. Да? Понятно всем? Ну вот,
это проблема, потому что мы не понимаем, где будет выполняться вычисление. Это довольно неприятно,
когда мы что-то не контролируем. Но, в конце концов, зачем мы пишем на C++, чтобы контролировать,
там, не знаю, сколько байт объект занимает, сколько там у нас аллокаций в коде, а тут мы даже не
понимаем, в каком потоке код будет вызван. Это вообще-то проблема, потому что, ну, представьте
себе, вы используете там какую-то стороннюю библиотеку, которая делает там асинхронный
вот-вывод в одном потоке своем, а вы хотите к ней подвесить обработчик, который, не знаю,
там, прочитанные данные возьмет и там будет разжимать какую-то тяжелую операцию делать,
вычислительную. И вот в зависимости от того, как там выстроится планета, у вас этот обработчик
может быть вызван прямо в коде библиотеки, которая однопоточная, а вы какую-то тяжелую работу там
хотите выполнять. И вот все, у вас все застрянет. Ну, представьте, что вы планируете в колбеке ASIO
однопоточного, допустим, какое-то тяжелое вычисление, явно не там они должны выполняться. Поэтому
нам нужен какой-то адекватный механизм, ну, в смысле, адекватный инструмент для управления тем,
где будет вызван обработчик. Поэтому смотрите, что мы сделаем. Мы потребуем, чтобы у Future,
помимо методов subscribe и производных ZenRecover, был метод, который называется via. Мы могли бы
сделать вот так. Мы говорим, что мы потребляем Future здесь, тратим ее значение, но колбек должен
непременно быть вызван вот в этом пуле поток. И вот сейчас обработчик вешается на Future строго
после того, ну, не строго, конечно, но скорее всего после того, как задача в пуле потока выполнится.
Но при этом сейчас трат не будет совпадать с subscribe. Запускаем и проверяем.
Вот вообще эта проблема, вот этот недотерминизм, который я показал, это такая врожденная проблема
Future, хродовая травма. Вот откуда у вас в коде берется Future? Откуда она у вас появляется? Потому
что вы вызвали какую-то асинхронную операцию. Вот если у вас появилась Future на руках, значит,
асинхронная операция уже стартовала. Значит, она там в другом потоке что-то делает, возможно. Значит,
вы уже гоняетесь с продюсером. Значит, непонятно, кто из вас вызовет, кто предыдущий раз стоит первым,
кто вторым. Значит, у вас уже, вот если вы имеете на руках Future, у вас уже недотерминизм появляется.
Где будет вызван callback? Поэтому эту проблему нужно решать. Мы ее решаем с помощью via. Но тут остается
некоторое пространство для неаккуратного применения, потому что можно его и не написать,
и тогда непонятно, чем дело закончится. Но вот скажем, если мы говорим про Future, который написан
на библиотеке Folly, это библиотека общих компонентов Фейсбука, то в их Future два типа, на самом деле.
Вот, там есть semi-future и future. Вот semi-future – это такой объект, который такой… недозрелый,
а future, на которую вы не можете вешать callback. Просто нельзя, нет такого метода у нее.
А метод via, он связывает Future с executioner, стредпулом, допустим, пока, условно. И только после того,
как вы связали Future с некоторым контекстом исполнения… по тонкому льду хожу. Вот только
после этого вы получаете возможность подвесить продолжение. То есть пока вы не укажете,
где будет вызван callback, вы не можете вешать асинхронные продолжения для задач, для Future.
Это называется type-state-correctness, ну, то есть такая игра с аккуратным… когда мы на уровне системы
типов форсируем переходы только между… переходы между правильными разумными состояниями объекта.
Просто система типов проверяет это за нас. Ну, вот мы это делаем, вводя дополнительный класс,
что довольно неэффективно с точки зрения программирования, но все-таки позволяет получить
более безопасное API. То есть если вы пишете библиотеку для продакшена, то она должна
вот заставлять пользователя делать все аккуратно. Поэтому такое разделение разумно. Понятно ли это?
Ну и дальше можно сказать, что via можно в цепочке постоянно перенастраивать, то есть мы исполняемся
то в одном тредпуле, то в другом тредпуле, а вернее даже не в тредпуле. Вот смотрите,
вернемся в прошлое. Мы с вами говорим, что вот здесь вот, что мы можем запланировать цепочку задач,
и она где-то будет выполнена. Ну, там где-то мы подозреваем пул потоков какой-то, пока условно.
С файберами та же самая история. Мы их исполняем в каком-то пуле потоков.
А теперь, ну, то есть в конце концов, вся конкурентность – это исполнение цепочек
задач в некотором тредпуле. А теперь подумаем, а чего же ожидают от тредпула, ну, то есть
какой функциональности? Функциональности ожидают от тредпула и фьюча с их продолжениями,
и там файберы с их синхронными операциями. Но и тот инструмент, и другой – это всего лишь
вот способ выразить конкурентные активности, а исполняются они, в конце концов, в тредпуле,
который умеет единственную операцию Submit. То есть где-то в каком-то потоке когда-то,
когда появится возможность запустить очередную задачу. Вот больше ничего и фьюча, и файберы
про тредпул не знают. Вот они пользуются очень простой гарантией. И вот тут-то можно подумать,
а зачем вообще мы и фьюча, и файберы привязываем к вот некоторому конкретному тредпулу? Принципы
говорят нам, что нужно зависеть от абстракции, не от конкретных классов. Поэтому давайте просто
абстрагируем тот сервис, который запускает задачи. Пусть это будет не тредпул, пусть мы назовем его
экзекьютором. Тут будет некоторый спойлер, но ничего страшного. Экзекьютор – это интерфейс,
у которого есть один метод Execute, который исполняет просто задачи. Думайте о нем вот так вот.
У меня по-другому написано, потому что я чуть-чуть аккуратнее сделал. Но суть вот такая. Все,
что нужно знать и файберам, и фьючам про среду исполнения – это то, что она умеет запускать
задачи. И вот мы эту среду исполнения абстрагируем от конкретных средств выразительности через
такого интерфейса. Гарантия, которую он дает, что вот где-то когда-то задача будет исполнена. Как
именно? Ни фьючам, ни файберам не интересно, не важно. Они не должны для этого зависеть.
Понимаете идею? Мы просто вот проводим такую границу. Мы отделяем runtime среду исполнения от
выразительности. Они теперь полностью развязаны. Граница между ними – это вот такой очень простой
интерфейс. И простые интерфейсы – это всегда хорошо, потому что простые интерфейсы говорят,
что декомпозиция разумная, что вещи не связаны друг с другом почти. Ну а теперь давайте подумаем,
а какие Executers можно было бы представить вот в этом месте. Ну, первое, что приходит в голову –
мы запускаем и файберы в threadpool, и callback, и фьюч в threadpool. Можно представить себе что-то
другое. Вот Executor, который делает следующее. Он, получив задачу, просто сразу ее исполняет.
Ну опять, давайте я напишу вот такой код. Это уже будет вам понятнее. Какой прок в таком Executor?
Ну, непонятно. Вот представьте, что вы пишете фьюча, и мы говорим, что у фьюч… я где-то здесь был…
что у фьюч есть subscribe. Ну, есть метод via, который указывает, в каком Executor будет
вызван callback. Ну а что, если я ничего не написал? Где должен быть вызван callback? Ну, в том потоке,
который пришел вторым. Но я же не хочу специально для этого код писать по дефолту. Я хочу просто
подставить default на Executor. Вот inline Executor, который запускает задачу просто в том потоке,
который вызовут Executor, это и есть дефолтное поведение для фьюч, в которых не указано via.
Вот поток, который пришел вторым, он запланирует задачу, вот этот callback,
на исполнение в inline Executor и просто запустит. Задача получается сам тут же. Ясно? Ну, тут вроде
ничего сложного нет. Гораздо интереснее устроен другой Executor, который называется manual,
ручной. Но он так называется, потому что задача в нем нужно выполнять вручную. Давайте я покажу вам
пример. Очень просто. Встроим Executor, бросаем в него задачу, бросаем вторую задачу. Пока
ничего не выполняется, потому что в Executor вообще нет потоков. Вот к этому моменту ни одной задачи
не выполнена еще. А потом мы говорим, давайте запустим следующую задачу. И вот здесь мы ее
исполняем. То есть этот Executor — это просто очередь задач. А здесь мы достаем задачу из очереди
и исполняем ее. Ну, тут, ладно, сложный какой-то код, не хочу. Вот ровно взяли из очереди одну
задачу и синхронно исполнили ее в этом потоке. Потом положили третью задачу, потом взяли и
исполнили еще три. Ну вот давайте убедимся, что это работает. Ну, начинается.
Вот видите, я запланировал две задачи, они пока не исполнялись. Вот как только я сказал Run next
task, она выполнилась первая. То есть я достал из очереди код и запустил его. Вопрос — зачем это
нужно? Какой толк от такого Executor? Вдруг мы хотим писать тесты для программ? Гораздо более
естественное желание. Мы хотим тестировать код. И мы знаем, что хорошие тесты — это детерминированные
тесты. А еще с нашими задачами проблема, потому что наши задачи — они про конкурентность. Мы
пишем файберы, а они сами по себе, в смысле задумка их, недетерминированно исполняться. Но мы хотим
каким-то образом написать unit-тесты для файберов. Скажем, unit-тесты для yield. Проверить поведение,
что yield работает. Как мы это сделаем? Но мне кажется, что идея очень красивая. И вот мне кажется,
что это может быть даже самое ценное в этом, в этой лекции. Смотрите, что мы можем сделать. Мы
можем запустить файбер. Смотрите, мы запускаем файберы в планировщике. Вот давайте вы в вашем коде
мысленно исправите конкретный shadular, который type alias для tradpool, на интерфейс. Но в самом деле
ничего не поменяется. И будем запускать файберы в manual-executor. Вот мы запустим первые файберы. Тут
нужно Go представить себе. Немного по-другому называется функция. Запускаем первый файбер,
который делает yield. Запускаем второй файбер. И вот к этому моменту никто еще не исполняется,
потому что executor ручной. А дальше мы говорим. Запускаем одну задачу. Эта задача — это шаг
первого файбера. Вот он напечатает step1. А потом мы остановимся, потому что он сделал yield. Но
если он сделал yield, если все правильно написано, то он остановился. А дальше мы напечатаем, что вот
первый шаг сделан. Потом мы запустим еще один шаг. И что будет дальше? Видимо, если у нас код
правильно написан, то дальше выполнится второй файбер. Сделайте свой второй шаг. В смысле свой
первый шаг. Ну и давайте проверим, что это так. Ну вот, мы получили yield-test для файбера. По-моему,
это впечатляюще. А дальше вы можете пойти совсем далеко. Вот про это я расскажу осенью для тех,
кому интересно. Но мне кажется, что это совершенно грандиозная идея, что можно, в принципе,
весь код ваш, прям вот весь продакшн написать поверх вот таких вот абстракций. И дальше
детерминированно, однопоточно симулировать исполнение вот настоящего сложного кода. Вы
пишете RPC framework, вы пишете framework с concurrency. Там очень много кода. Всякие каналы,
future, синхронизация там, ну в смысле каналы RPC и такие, там синхронизация, всякие ритра и сервисы,
огромное количество инфраструктуры. А потом вы пишете код и запускаете его. И вот он работает
в VDE моментально и эмулирует работу двух компьютеров. Детерминированно. Вот почему я здесь запускаю
код, который спит три секунды, а тест выполняется моментно, а пример исполняется моментально? Ну,
потому что у меня все файберы в этом коде, которых там достаточно много, исполняются в
manual executor. И я вот здесь, запуская вот этот код, просто кручу этот цикл руками. А когда у меня
работы нет, то я просто двигаю вперед время. Вот у меня файбер заснул на три секунды, три секунды
ничего не происходит. Я взял, просто часы перевел. Вот. И вот у меня код работает за нулевое время,
в смысле эмулируется здесь за нулевое время. И вот все воспроизводимо и все детерминированно.
Это прям вот, ну и так люди пишут, отдельные люди, которые много сил в это вложили, пишут прям
production. Вот то есть можно написать какой-то очень сложный, очень конкурентный, очень отказоустойчивый
код, а потом его тестировать вот с помощью такой детерминированной симуляции. Это прям безумно
мощная идея. В нее нужно вложить очень много сил. Так делают очень немного людей в мире. Ну вот,
мы, возможно, осенью сделаем прям совсем хорошо. В смысле, мы этим уже пользуемся осенью, а дальше,
ну короче, я расскажу. Через полгода расскажу, кому захочется. Это, в общем, очень-очень такой
большой, сложный, интересный план. Ну ладно, и последний. Я отниму еще три минутки. Это такое,
как бы... То есть это все последствие того, что мы абстрагировали среду исполнения от конкретных
средств выразительности. Вот мы можем их тестировать детерминированно. А теперь такой посторонний,
очень клевый сюжет, мне кажется. Вот смотрите, у нас есть примеры фьюч, и в этих примерах
возникает класс, который называется result. Что это? Что это? Result. Или ошибка, или значение,
или ошибка. Вот есть нечто, что и result, и future объединяет. Вот смотрите, в C++ в стандартной
библиотеке result нет. Но есть... Но он появится в каком-то виде в будущем, и вероятно, он будет
называться expected. Это шаблон, у которого есть значение, ну, первый параметр значения,
второй это тип ошибки, ну и либо одно, либо другое. И зачем этот класс? Ну, вы пишете какое-то
конвейер, который берет картинку и делает из нее милого котика. Мы там сначала кропаем котика,
потом мы там добавляем ему бабочку, потом мы каким-нибудь звездочки добавляем, вот какие-то шаги. И
каждый шаг может завершиться либо успешно, либо ошибкой. Ну, потому что там на картинке, там,
не знаю, тефтерия, а не кот. И в этом случае нам вернется ошибка. Если кот нашелся, нам вернется
вот кусочек с котиком. А дальше мы организуем вот такой конвейер вот этих шагов. И кот пишется,
ну вот как-то, не очень красиво, да? К чему это аналогия? К тому, что вот этот кот с фьючами,
ой, с асинхронными операциями тоже выглядел не очень красиво. Ну, какая-то слабая связь,
конечно, но я объясню, к чему я веду. А дальше смотрите, что можно сделать. А дальше можно
сказать вот так вот, что давайте мы в expected добавим такие вот методы end-to-end. В чем смысл? Вот у
вас предшествующая функция crypto-cat возвращала или значение, или картинку, или ошибку. А следующая
функция ожидает именно картинку, просто картинку, без ошибок всяких. И вот этот комбинатор end-to-end,
он бы пробрасывает значение или скипывает следующий шаг, если была ошибка. Ну, то есть такая
еще один способ последовательно композировать вычисления. Вот map – это вызов, который композирует
функцию, которая может сама вернуть, которая ожидает ошибку и может сама вернуть дальше. Ну, в общем,
вы можете написать это вот так вот. Да? То есть, понимаете, общая задача, что у нас во фьючах есть
zen, что здесь есть zen, и там, и там он возникает не потому, что это какая-то случайность,
потому что это одна общая задача. У нас есть отдельные шаги, и нужно их связывать друг с другом.
Почему это сложно? Потому что предшествующая функция возвращает некоторые не просто значения,
а контейнер, result или future, то есть, будущее значение, или значение, либо ошибку. А следующая
функция, следующий шаг, ожидает просто значения. И вот мы в этом зене прячем логику связывания.
Вот тут можно сказать следующее, что и result, и future – это представление некоторой общей идеи,
которая называется Monado. Слышали про это что-нибудь? Вот Monado, она как раз инкапсулирует в себе
логику связывания. У вас есть некоторый контейнер, у вас есть некоторая функция,
которая ожидает развернутой из контейнера значения, и вы должны определить логику, как функция,
которая ожидает значения, обработает контейнер значения. Контейнер либо result, либо там future,
либо что-то еще. Ну, к сожалению, в C++ нет какого-то адекватного инструмента, чтобы такую абстракцию
выразить в языке, ну, просто в системе типов. Мне кажется, что нет разумного инструмента,
по крайней мере, никто так не пишет. А в хаскере для этого есть инструменты, и… Ну вот, все съехало.
У вас есть этот самый Monado, у которой огромное количество примеров, в смысле, разные объекты,
с которыми вы хорошо знакомы, можно, видимо, надо представить. Ну и зачем я вам рассказываю про это?
Ну, во-первых, про то, что вот все… И future, и result, и можно погрузить некоторый общий
framework, а еще… Ну, зачем я вам это рассказываю? Затем, что… Да, вот как выглядит на хаскере,
то есть в функциональном языке, где… в котором можно было бы жить без Monado, как бы выглядел
код, который экваленствовал этой горе if-ов. Ну, вот в функциональном языке у вас не if,
и у вас pattern matching. И вот как бы выглядел этот код, если бы вы писали его на функциональном
языке. Вот как бы такая странная, развесистая конструкция. А вместо этого вы, спрятав логику
связывания в Monado, можете написать вот такой код. Но все еще не очень понятно, что это такое,
в смысле, не очень понятно. Ну это просто Monado, какая разница? Вот, это, в смысле, еще один
пример, maybe, optional, тоже Monado. Тут про это и речь. Я про то говорю, что хочется иметь в языке какую-то
синтоксическую поддержку для Monado. Чтобы не писать вот эти n-zene, вот здесь не писать zene,
и здесь не писать zene. А чтобы просто сам язык как-то это делал, ну, в смысле, как-то выражал эту
мысль за вас. Ну, в Хаскере это особенно актуально, потому что, ну, собственно, Monado в Хаскере — это
некоторый способ внести императивность в функциональный язык. Собственно, задумка такая изначальная была
в тех самых Monado. И вот в Хаскере есть специальная донотация. Это синтоксическая поддержка Monado. Вот
за ней прячется вызов вот этой процедуры связывания вычислений, которая скрыта в конкретной Monado. В данном
случае maybe. То есть в ней спрятано вот этот самый pattern matching. Так вот, C++, оказывается, тоже
нечто подобное есть, и мы про это поговорим с вами, ну, где-то в апреле, во второй половине, вероятно.
Так что, в принципе, от знания про Monado пользы некоторые имеются. Даже в C++ они в некотором
виде поддержены. Ну что ж, на сегодня все. Спасибо вам большое.
