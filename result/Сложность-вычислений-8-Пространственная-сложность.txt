Смотрите, мы обсудили все, что связано с полимональным временем для разных вычислительных моделей,
детерминированных машин, недетерминированных и альтернирующих.
Но с альтернирующими у нас было ограничение, как получалась полимональная аархия,
что число перемен метки на состоянии не больше, чем некоторая константа к, независящая от длины х.
Что будет, если мы снимем это ограничение, и перемен может быть сколько угодно.
Этот класс будет называться ap, альтернирующая машина, полимональное время.
И на самом деле это будет то же самое, что ap-space означает полимональная память.
Соответственно, мы плавно перетекаем от измерения времени к измерению памяти.
Это утверждение на самом деле теорема. В какой-то момент можно обсудить, почему это так.
Но начну я с того, что мы обсудим, как вообще измерять использованную память.
Пока нет, не определяли. Чтобы определить ap-space, нужно сначала сказать, как вообще измеряется память.
Смотрите, у машины теоринга есть элементарная ячейка памяти.
Это ячейка на ленте. Ячейка на ленте.
Ячейка на ленте это единица используемой памяти.
Вообще в начале чуть-чуть обсудить, почему нас вообще интересует используемая память.
Может быть несколько причин. Во-первых, за память надо платить.
Особенно это было верно 50 лет назад. 50 лет назад память просто по цене составляла подавляющую часть компьютера.
То есть если вам нужен был компьютер с в два раза больше памяти, то почти в два раза больше и нужно было за него заплатить.
Поэтому чтобы потратить меньше, а вычислить больше, надо придумывать алгоритмы, которые используют мало памяти.
Даже если будет некоторый прогресс по времени.
Эта причина сейчас гораздо менее важна, но все равно остается вторая причина.
Как устроена память в реальном компьютере? Есть несколько уровней.
Есть регистры процессора, несколько уровней кэша, есть оперативная память, есть жесткий диск, есть какое-нибудь облако.
И каждый раз на каждом следующем уровне будет больше памяти, но дольше обращение к этой памяти.
Получается, что если вся программа уменьшается в более маленькую память, то получается более быстрое обращение к этой памяти.
И поэтому программа работает быстрее. Даже если шагов будет там немножко больше, но за счет того, что каждый элементарный шаг будет более быстрым,
за счет более близкой памяти, в общее время будет меньше.
Так что так или иначе память связана со временем и со стоимостью.
Дальше у нас есть второй вопрос. А что нужно измерять? Какие ячейки?
Простой ответ, что все куда указывает, то и измеряем.
Но представьте, что у вас программа это поиск какого-то слова в текстовых файлах.
И пусть у вас весь диск забит этими текстовыми файлами, и вам нужно какое-то слово там найти.
Во-первых, в процессе поиска этого слова нельзя эти файлы менять.
Если вход это все эти файлы, то в процессе поиска нужного слова нельзя там ничего редактировать.
Это будет неправильная программа, если она так будет делать.
Во-вторых, если у вас уже почти весь диск забит этими файлами,
то используемая память должна быть сильно меньше, чем сам массив, которым вы ищете.
Вот отсюда получается концепция, во-первых, неизменяемого входа.
Ключевые аспекты определения это, во-первых, неизменяемый вход.
Во-вторых, считаются дополнительные ячейки памяти по сравнению со входом.
Считаются дополнительные ячейки памяти.
Те ячейки, в которых записан вход, не редактируются.
Проще всего это моделировать через две ленты.
Есть одна лента, которая только для чтения, read-only.
И вторая лента для чтения и записи.
Рабочая лента.
Давайте я условно напишу work.
И, как всегда, управляющая машина имеет два указателя.
На ячейку здесь и на ячейку здесь.
По первой ленте будем бегать туда-сюда.
Но это же влияет только на время работы.
А на память это совсем не влияет, тем более, если эта лента входная и неизменяемая.
На самом деле, если это PSPACE, то это неважно.
Но бывают модели со сверхмалой памятью.
Когда здесь логарифмическая память, типичная ситуация.
Здесь длина A, а здесь длина логарифмы.
Тогда очень важно, что вход неизменяемый, что считаем только дополнительную память.
Это позволяет обредить класс SPACE от S от N.
Это получается класс языков распознаваемых на памяти.
Я явно напишу на дополнительной памяти O от S от N.
Распознаваемых означает, что всегда будет правильный ответ.
Если х лежит в языке, то будет ответ «да», если х не лежит, то будет ответ «нет».
Тогда число дополнительных ячеек вот такое.
Какая-то константа на S от длины х.
Ну хорошо.
Тут лучше буквку D добавить.
Можно и так, D, чтобы подчеркнуть, что машины детерминированы.
Бывает N SPACE от S от N.
Но это тоже самое аналогично, но на недетерминированной машине.
Сейчас немножко обсудим, что это значит.
На недетерминированной машине.
Что это означает?
Это означает, что функция перехода неоднозначна.
Но все равно на всех ветвях будет дополнительной памяти не больше, чем у большой от S от N.
Ну и определение, как обычно. Если есть ветка, приводящая к единицу, то общий ответ – единица.
Если все ветви приводят к ноль, то общий ответ – ноль.
Так, хорошо.
Дальше можно разные конкретные функции подставлять, и некоторые классы будут получаться.
Будет класс L. L – это D SPACE от logarithm N.
Дополнительная память – логарифмическая.
Дальше есть N L. Это N SPACE от logarithm N.
Кстати, фишка вот этих обозначений в том, что не нужно описать, по какому основанию логарифм.
Если будет другое основание, то будет другая константа. В большом логарифме останется.
Дальше есть класс poly L. Это D SPACE от полинома от логарифма.
Можно, в принципе, посмотреть N poly L, но это вообще никто не пишет.
Дальше есть P SPACE.
P SPACE – это D SPACE от полинома от N.
Это обычно записывается, это объединение по всем степеням D SPACE от N в такой степени.
N P SPACE.
Это N SPACE от полинома.
Еще бывает EXP SPACE.
Это, соответственно, D SPACE от экспонента.
Дайте я напишу 2 в степени полинома от N.
Наверное, может быть и E SPACE, где 2 в степеньом большой от N.
На самом деле, если для времени был важнейший вопрос, равны ли P и N P, то здесь вопроса про P SPACE и N P SPACE нет.
Они будут равны. Мы это сейчас скоро докажем.
И также и для экспоненты, и для линейной экспоненты, и даже для полилогарифма, и только для L ENL.
Это вопрос открыт.
Аналогом вопроса про P и N P для пространственной сложности будет вопрос про L ENL.
Сейчас мы с этим разберемся.
Давайте сначала посмотрим на простые вложения.
Есть магистральная линия вложений.
Давайте начнем с совсем простых вещей.
Утверждение 1, что L вложено в P, и аналогично P SPACE вложено в эксп.
Ну а там эксп SPACE будет в E эксп, но это уж ладно. Все аналогично делается.
Смотрите, это фактически по принципу Дерехлей делается.
Потому что надо посчитать общее число конфигураций.
Общее число конфигураций машины Тьюринга. Какое?
Давайте для простоты считать, что на этой входной ленте еще и нельзя за пределы входа выходить.
Если можно, все равно будет верно, но там уже какие-то полигические случаи рассматривать.
Если мы будем считать, что нельзя за пределы входной ленты выходить,
то, наверное, нужно переделать программу, которая выходит, в какую-то программу, которая не выходит.
Потому что если она ушла слишком далеко, то там ничего...
Ну вообще интуитивно, ясно, что не зачем дотуда выходить, там все равно ничего записать нельзя.
И мы знаем, что там будет.
Наверное, нужно будет сказать, что если мы уходим, то вместо этого мы забудем счетчик, который показывает, насколько мы ушли.
Если бы назад возвращались, счетчик скручиваем обратно, там что-нибудь такое надо придумать.
Вот.
Считаем те, которые посетили на рабочей ленте.
Либо можно сказать, что если мы на лишнюю ячейку на входной пришли, то мы ее тоже считаем в память.
Это все какие-то усложнения технические.
Скажем по-простому, что мы просто не выходим за пределы входа на входной ленте.
УБР.
Чего?
УБР.
В смысле?
Нехорректная программа.
Ну ладно.
Ладно.
Какое будет число конфигураций?
Значит, у нас будет...
И дай считать, что вот эсатен это прямо в точности, сколько мы используем ячеек.
Во-первых, у нас есть содержимые рабочей ленты.
И сигма или сейчас гамма, наверное.
Обычно сигма это алфавит входа, а гамма это алфавит на ленте.
Соответственно, может быть, размер гамма разных символов в каждой ячейке.
Соответственно, эта гамма нужно возвести в степени эсатен.
Вот это число вариантов заполнения рабочей ленты.
Значит, умножить на число состояний, умножить на число положения указателя на первой ленте
и умножить на число положения указателя на второй ленте.
Понятно, да?
У нас рабочая лента ровно одна.
Да, дай считать, что ровно одна рабочая лента, и ровно эсатен ячеек мы там используем, чтобы не усложнять.
N это число положений указателей на первой ленте.
Первой ленту мы не изменяем, но мы можем по ней двигаться туда-сюда.
N это значит, что это размер хода.
N размер хода, да.
N размер хода, а эсатен это размер памяти выделенной, дополнительной.
Два указателя состояния и слова на рабочей ленте.
Соответственно, число шагов будет не больше, чем это число конфигураций.
Значит, число шагов не больше, чем число конфигураций.
Ну а дальше нужно увидеть, что если эсатен от логарифм, тогда это штука полином.
Если эсатен от полином, тогда это штука от экспонента.
А это по принципу Дерехлия, что если конфигурация повторилась, то все, машина зациклилась и никогда не остановится.
Ну вот все и получается.
Если эсатен это большой от логарифма, то тогда получается вот это вот число конфигураций полином от N.
И время соответственно тоже.
А гамма это рабочий алфавит?
Да, гамма это ленточный алфавит машины Тьюринга.
Если эсатен полином, то тогда здесь будет экспонента.
Ну и отсюда это и получается.
Так, хорошо.
Значит, утверждение 2. NL тоже вложено в P.
Тут уже так просто не получится. Нужно некоторые рассуждения.
Смотрите, мы рассмотрим конфигурационный граф.
Именно вершины будут всей конфигурации, а ребрами корректные переходы.
В случае детерминированной машины это будет такое обратное дерево, что раздвоиться не может, а сойтись могут.
Из каждой вершины одна стрелка и точно нет циклов.
Входящее дерево это называется.
Ну точнее лес, если все раз рассмотреть, то они не обязательно все в одну сойдутся.
В общем, входящее лес такое получается.
Если это произвольная нетерминированная машина, то они могут раздвоиваться.
Но все-таки давайте считать, что она не зацикливается никогда.
Все-таки на каждой ветве есть ответ.
Зациклов могут быть, главное, чтобы был дыхатель.
Да, считать, что не будет.
Но это правильно, что можно рассматривать циклы тоже.
Давайте для простыды считать, что вообще не будет циклов.
Там могут вылезти какие-то сюрпризы.
А если есть цикл, то существует бесконечный столб?
Если есть цикл, то есть бесконечная ветка, и не понятно, что с ней делать.
А если есть бесконечный столб, то это уже происходящее?
Ну нет, это время будет бесконечное, а память будет конечная за счет зацикл.
А, нет, тогда она не смогла быть ответной.
Мы уже договорились, что в конце каждой ветки лежит либо один, либо ноль.
Если там не лежит ответ, то мы, видимо, не можем посчитать определенные изменения.
На самом деле, это зациклевание можно отслеживать.
Можно вести счетчик, сколько мы шагов сделали.
И этот счетчик нам удвоит память.
Но если он превысит нужный порог, то мы поймем, что мы зацикливались
и директивно прекратим учление с ответом ноль.
Будем считать, что ничего не зацикливается.
Да, давайте считать, что на каждой ветке есть ответ.
Если на одной ветке нет ответа, то у всей машины нет ответа.
Но дальше можно любую машину преобразовать новую,
где ответ будет на каждой ветке, и все единицы сохранятся.
Мы рассматриваем конфигурационный граф.
Вершины – это конфигурация.
Ребра – это корректные переходы.
И добавим в него еще одну виртуальную вершину,
универсальную принимающую вершину.
Если машина закончила работу в принимающем состоянии,
то еще одно ребро вот в эту универсальную принимающую вершину.
Плюс универсальная принимающая вершина.
И тогда что получается?
Вопрос о том, будет ли ответ принимающим,
то есть m от x равно единице,
если есть ориентированный путь
из стартовой конфигурации.
Вот в эту универсальную принимающую.
А дальше смотрите, если память логарифмическая,
то в графе поляном вершин.
Ну а для поляного графа эту задачу вы умеете решать наверняка.
Это задача о поиске пути в орграфе.
Получаем, что если s от n, то большая от логарифма...
Нет, сейчас нет.
Нет, если мы решили логариф памяти,
то мы можем доказать, что n или равно l.
Но это никто не умеет.
Мы доказываем, что можно решить по логарифму памяти.
Но если мы решим по логарифму памяти,
то на самом деле это очень интересная вещь.
Потому что достижение уже XXI века,
что если у вас неориентированный граф,
то там задачу о достижимости можно решать с логарифмической памяти.
Но если мы решим по логарифму памяти,
то мы не сможем решить по логарифму памяти.
Но если мы решим по логарифму памяти,
то на месте можно решать с логарифмической памятью.
Если бы для ориентированного можно было, тогда бы l равнялся nl.
Но это пока никто не умеет.
Нет, ну подождите. Если логарифмическая память,
то поляном времени автоматически.
Так, давайте я запишу.
Мы решим граф поляномиального размера,
и путь можно найти
за поляномальное время.
Ну вот, значит nl получается тоже
вложено в P.
Аналогично, конечно, может сказать, что там NPSP,
вложено в EXP и так далее.
Так, хорошо.
Значит, если также склеить
с тем, что мы уже раньше знаем,
то получается такая
магистральная цепочка вложений.
Глобальное утверждение 3 получается,
что l вложено в nl,
это вложено в P,
это вложено в np,
это вложено в ph,
а сейчас это мы, наверное, не знаем еще, сейчас обсудим.
Это вложено в pspace, дальше это вложено в npspace,
значит, это дальше вложено в exp,
это в nxp,
значит, это в expspace
и так далее. Тут еще, в принципе, экспедициональная иерархия
тоже есть, но эту мы сейчас не будем обсуждать.
Так, значит,
первое, чего мы не знаем, это вот это вот.
Значит, почему ph вложено в pspace?
Так, дайте что-нибудь попроще.
Почему np вложено в pspace?
Значит, почему np вложено в pspace?
Не просто за экспедиционное время
можно все перебрать, а на понимание памяти.
Но потому что в чем вообще фишка памяти, что ее можно освободить и переиспользовать.
В этом ее отличие от времени. Время нельзя переиспользовать, оно ушло, и все.
А память можно очистить и использовать заново.
Ну и тогда тут получается
что нужно вычислить память под перебор y
и дальше выделить память
под вычисление v от x и y.
Вот. И дальше как организована работа?
Что вот у нас есть какой-то первый y, так сказать, из всех нулей.
Для этого y мы вычисляем v от x и y.
Вот. И дальше как организована работа?
Для этого y мы вычисляем v от x и y.
Если подошло, то останавливаемся ответом 1.
Если не подошло, то вот эту память освобождаем
и здесь приходим к следующему. Все нули, а последние единицы.
И дальше на той же самой памяти вычисляем v от x и y.
Ну и так далее. Каждый раз на одной и той же памяти
вот это вычисление происходит, а здесь итерируется y.
Ну и так получается, что если в какой-то момент
тут получилась единица, то мы останавливаемся ответом 1.
А если дошли до последнего y и все нули, то останавливаемся ответом 0.
Ну и память вот такая вот и получается.
Так.
Ну чего, понятно?
Но с pH более-менее так же, только вложенный такой перебор будет.
Значит, как получается, что pH...
Почему pH вложено в p-space?
Ну тут примерно так же, только тут перебор
y1, дальше перебор
y2.
Сейчас.
Сейчас обсудим. Значит, перебор y.
И дальше соответственно вычисление
v от x, y1 и так далее.
Значит, смотрите, на самом деле
можно считать, что длина вот этих вот y
она... Некоторые фиксированы полиновой длиной x,
и определяются вот этим вот алгоритмом v.
Но потому что уж как... Уж по крайней мере эта длина
будет не больше, чем время работы этого v.
Вот, количество y... Значит, смотрите, в pH
количество фиксировано.
То есть полимиальная иерархия означает, что у нас k фиксировано.
Может быть, сколько год нам большое, но фиксировано не зависит от x.
Но на самом деле, если мы сделаем,
что число этих k растущее
и полимиально растущее, то это как раз ровно
в p-space получится.
А если фиксированы, то pH, которое вложено в p-space.
Ну вот, организована работа
примерно так же, как бы рекурсивно.
Мы здесь перебираем для фиксированного y1, запускаем рекурсивно
вот эту штуку, и значит, 2 кванторов на единицу меньше.
Y2 и так далее. И дальше там,
если был квантор всеобщности, то нужно
дождаться до конца, проверить, что все единицы.
А если хотя бы одна ноль, то остановить с ответом ноль.
Вместо вызова.
Вместо вызова, откуда вызвали это под программу.
А если в кратном существовании, как в NP, то тогда наоборот.
Если дошли до конца все нули, тогда ноль, а если где-то единицы,
то отправляем единицу наверх.
Главное, что каждый раз
y-каты для, скажем, всех предыдущих
фиксированных на одной той же памяти итерируется.
Когда будет следующий y-1, то y-каты начинают снова со всех нулей.
Нам еще нужно хранить результаты предыдущих участвений.
Ну, конечно, да, там еще небольшая служебная память
нужна, чтобы все это организовать.
Хорошо, значит, ph положено в p-space, это
положено в np-space.
Остальное все из предыдущего получается.
Ну, скажем, l положено в nl, просто потому что
детерминированный, в частном случае, не детерминированный.
Значит, p-space, np-space тоже.
Прирыв надо делать? Или не обязательно?
Не обязательно.
Сейчас будет следующая теорема, что вот здесь
на самом деле равенства.
Я уже анонсировал ее, что p-space равняется np-space.
Это называется теорема Сейвича.
Теорема совершенно классическая еще с 70-х годов.
Ей теорема довольно простая.
И она еще более общая, более общая, чем
просто то, что p-space равно np-space.
Она вообще про связь детерминированной и нетерминированной модели
в случае измерения памяти.
А именно, что переход от недетерминированной модели
к детерминированной памяти возводит в квадрат.
Ну и как следствие получается, что квадрат полином
и это полином.
Полилогарифм и это полилогарифм.
Поэтому n-полиэль это то же самое, что полиэль.
А квадрат логарифма и квадрат логарифма.
Поэтому про l и n-эль тут не получается.
Вот теорема Сейвича,
Уолтера Сейвича
заключает в следующем, что если s от n, хотя бы логарифм,
ну совсем сверхмалые
ограничения на памяти повторного логарифма
они дают просто автомат на языке.
Да, тоже конечный автомат распознается.
Но это если повторный логарифм, а если там какой-нибудь корень
из логарифма, то там не понятно, что получится.
В общем, если s от n больше того, что логарифм n,
то получается, что n-space
от s от n будет вложена
в d-space
от s от n в квадрате.
Соответственно получаем следствие,
что n-эль вложена в полиэль,
да, квадрат логарифма
это полином от логарифма.
Ну а n-p-space равно p-space.
Ну и во всех прочих тоже нет
никакого смысла.
Н-эксп-спейс это тоже эксп-спейс и так далее.
Так, хорошо. Значит, как этот теремм доказывается?
Это через конфигурационный граф.
Все ту же самую задачу достижимости нам нужно решать,
но мы ее будем решать,
использовав немножко побольше памяти, именно квадрат.
Доказательство теоремы
заключается в том,
что на вот этой памяти
значит, на памяти
от s от n в квадрате
можно...
что сделать?
Можно решить задачу достижимости.
То есть можно проверить наличие пути.
Значит, наличие пути из s в t.
Значит, смотрите, прям в целиком граф
мы построить не можем,
потому что у него будет как раз экспонент от s от n размера.
То есть нам его нужно как-то строить так на лету.
Мы не можем его прям весь сразу выписать,
но можем какие-то отдельные фрагменты все время подсматривать, потом забывать про них.
Если нужно, то заново вычислять.
Все-таки обычные
поиски ширину в глубину, они подразумевают какие-то метки
на вершинах.
Вот здесь в некотором смысле
будет такой двоичный поиск.
Потому что, смотрите, даже если бы мы разрешили циклы,
то все равно, если был бы путь, то был бы простой путь.
И в простом пути вершин не больше, чем вершин в графе.
Да, совершенно верно.
Перебирать среднюю и рекурсивно искать два пути от начальной до средней,
от средней до конечной.
Значит, тут получается
пусть n в графе,
n в графе,
и здесь н в графе,
н в графе,
тогда получается есть путь
длины
не больше, чем n.
Дальше получается, что есть путь
из s в t.
N большое
это та формула,
это вот это вот.
N большое это число конфигурации.
То есть, грубо говоря, это экспонент s от n.
И даже тут видно, зачем оно, чтобы s от n было больше логарифма.
Потому что если бы s от n было меньше логарифма, то главным множителем стал бы вот этот вот.
Так что в принципе можно обобщить теорему,
подставив вот сюда вместо s от n, подставив максимум из s от n и логарифма.
Тогда это уже будет всегда верно.
Конечно, это техническое требование.
Вот.
В общем, смотрите, что получается.
Давайте я это обозначу как предикат.
Reach, s, t, n. То есть есть достижимость.
Есть путь из s в t длины не больше n.
Это равносильно тому, что существует
какая-то промежуточная вершина x.
Да, значит, где будет reach от s, x и n пополам.
И reach от x, t и n пополам.
Вот такое как бы рекурсивное правило.
Вот. А если n равно 1,
ну не 1, а третий параметр.
Reach от u, v, 1.
Это означает, что либо у равно v, то есть путь длины 0,
либо есть одно ребро.
То есть это равносильно тому, что u равно v,
или есть корректный переход
из u в v.
Это можем проверить просто по программе для машины тюринга.
Но там еще какое-то котирование нужно.
Что это конфигурация, что там, где записано.
В общем, переход за один шаг означает, что почти ничего не изменилось.
И только в районе указателя все произошло согласно программе машины тюринга.
Так.
Хорошо.
Теперь надо из этой формулы организовать программу,
которая все вычислит, используя такую память.
Вот.
Вот получается рекурсия.
Что нам нужна память на перебор XA,
и потом память на рекурсивный запуск.
То есть тут получается...
Перебор XA.
А здесь получается рекурсивный запуск.
Рич от двух аргументов n пополам.
Вот.
Получается, что перебор XA нам нужен порядка s от n этих самых ячеек.
Что большое, это s от n ячеек.
И, соответственно, нам нужна память на перебор XA.
Вот.
Вот.
И, соответственно, каждое уменьшение n в два раза
нам будет добавлять еще столько же ячеек.
Вот. Ну а сколько раз нужно уменьшать n в два раза, чтобы получить константу?
Ну как раз тоже s от n.
То есть глубина рекурсия
тоже большое, это s от n.
Значит, базу рекурсии мы как-нибудь вычислим за небольшую память.
Ну да.
Что за один шаг можно перейти.
В детали нужно лезть, но явно это много не потребует дополнительной памяти.
Но, до сих пор, нужно умножить глубину на дополнительную память на каждом уровне
и получим как раз s от n в квадрате.
Ну да, но это совсем мелочь.
Нам как бы один бит нужно хранить еще.
Вот. Соответственно, получаем, что произведение
большое вот s от n в квадрате.
Вот так. Ну все, доказали Теремсовича.
Киньте вопросы.
Так.
Так.
Да, значит, здесь будет равно.
Вот, теперь, значит,
что здесь известно в плане строгости вложений?
Значит, идея тут такая, что если у нас один и тот же ресурс,
то чем больше ресурса, тем шире класс.
Это называется терема об иерархии.
Мы ее, наверное, не будем доказывать, или на семинаре вы доказывали.
Звучит очевидно.
Ну, то есть там p не равно exp, или l не равно pspace.
Это все из теремы об иерархии. Или там np не равно nexp.
И это все разные теремы об иерархии.
Для детерминированных вычислений, для вычислений с ограничениями на память,
для нетерминированных, для нетерминированных на память.
Ну, это не интересно, потому что они там почти сразу схлопываются.
Но, скажем, nl тоже строго вложено в pspace,
потому что nl вложено в полиэль, а полилогриф меньше, чем полином,
поэтому полиэль уже строго вложено в pspace.
Если касается ресурсов разной природы,
то тут не известно, в общем-то, ничего.
И в частности, открытый вопрос,
это равны ли p и pspace?
Не только равны ли p и np, мы не знаем, хотя верим, что не равны,
но даже мы не знаем, равны ли p и pspace.
Хотя кажется, что это очень странно,
что явно pspace гораздо больше,
мы не только отдельный перебор можем сделать, но и какой-то вложный перебор,
и еще и глубина вложенности может быть даже полиномом.
И, тем не менее, это открытый вопрос.
Так, ну ладно.
Сейчас обсудим, какие вообще задачи
лежат в pspace.
Как на это можно смотреть?
Кроме ph, что там еще лежит?
На самом деле, то, что я стираю,
это характеризация с произвольным члом кванторов,
и это очень похоже на альтернирующие машины,
и это, собственно, равно pspace.
Где еще возникают вот такие
меняющиеся кванторы?
Конечно, да.
Что такое выигрышная стратегия?
В игре, где двое ходят по очереди,
это такой хороший ход, что как бы соперник не ответил,
будет все равно хороший ход, что как бы он не ответил,
что в итоге мы победим.
Но, соответственно, многие pspace задачи
формулируются через игры.
Например, крестики-нолики.
Крестики-нолики можно так формулировать.
Пусть у нас есть какая-то конечная доска,
и там уже какие-то крестики-нолики стоят.
И тогда вопрос, кто выиграет при правильной игре.
Но это игра, где пять вряд.
Уже какие-то крестики-нолики есть, ходят крестики,
и вопрос, у какой стороны есть выигрышная стратегия
из такого начала.
Начальная ситуация нужна, чтобы много было возможных
начальных ситуаций.
И вопрос, кто просто выигрывает на пустой доске m на n.
Но даже если вы скажете какие-нибудь более сложные правила,
то все равно главное, что если у вас только два числа,
то запись входа это будет просто логарифм от n.
А решаться это будет напоминать памяти от n.
Ну, можно в мунарной записи, да,
но это можно, конечно, так делать.
Ну вот, соответственно, если уже начальная позиция есть,
то получается,
как минимум, там экспоненционально, что разные входы длины n,
а не полиномиальная.
Так, хорошо.
Повторим.
Повторим.
А почему это на полиномиальной памяти решается?
Да потому что будет такая же рекурсия,
только тут будет полиномиальная вложенность,
и на каждом уровне будет полиномиальный перебор,
то есть перебор следующего хода.
Перебор следующего хода будет полиномиальный,
это число оставшихся пустых мест на доске,
а глубина вложенности – это число пустых мест с самого начала.
Ну и дальше это точно так же можно все вычислить.
Даже почти как здесь, только тут будет место одной конъюнкции,
да, либо большая конъюнкция, либо большая дезюнкция.
Так, ну что, понятно, да?
Ну, конечно, возникает вопрос про разные другие игры,
например, шахматы.
Но чтобы говорить про шахматы, нужно очень аккуратно,
нужно, во-первых, распространить на доску произвольного размера,
что уже нетривиальное дело.
Сколько там должно быть фигур, где они должны стоять?
Ну хорошо, где они стоят?
Допустим, тоже вход.
В принципе, можно даже сказать так, что сколько угодно разных фигур.
Только про короля надо сказать, он один или их много.
Ну, можно новый тип фигур сводить.
Но главное,
что нужно расширить всякие специальные правила,
типа повторения позиции.
Потому что, смотрите,
просто повторение позиции нас вообще не спасет,
потому что позиций может быть специально много.
И даже если мы говорим, что каждая позиция повторяется не больше трех раз,
то все равно может быть экспедиционно долгая игра.
Вот, соответственно,
возникает вопрос, есть ли у нас правил 50 ходов,
и если есть, то во что превращается число 50,
когда у нас доска N на N.
Значит, если это будет
тоже там константа 50
или какой-то полином,
то тогда сразу игра пойдет в PSPACE,
потому что тогда игра будет длиться не больше полинома ходов,
и работает такой же перебор.
Если это 50 заменить на что-нибудь больше полинома,
то уже непонятно, будет это в PSPACE или не будет,
по крайней мере прямой перебор всех вариантов займет слишком много.
Это я, к сожалению, не знаю правил.
Но в целом знание некоторых принципов
заменяет знание некоторых фактов.
Если у вас любая ветка длится не больше полинома,
то сразу это будет PSPACE.
Если могут быть сверхполиномиальные ветви, то тогда начинаются вопросы.
Либо есть какой-то тонкий анализ, либо это будет больше, чем полином.
Зачем нам нужны были NP-полные задачи?
Затем, что если мы умеем решать NP-полную задачу,
то мы умеем решать все NP.
То есть это самые сложные задачи в NP
с водимости из P.
PSPACE-полная задача тоже самая.
PSPACE-полные тоже самые сложные в PSPACE,
но с точки зрения сводимости в P.
Определение, что B
это PSPACE-полная задача,
или PSPACE-полный язык,
значит, если верно следующее.
Если B лежит в PSPACE,
и для любого A из PSPACE
у нас выполнено, что A
сходится к B
в смысле с водимости по карпу,
понимали, по времени.
У нас интересует разделение P и PSPACE,
поэтому берем сводимость из нижнего класса.
Ну и дальше какая-то вопрос,
какие задачи будут PSPACE-полными, какие нет.
Здесь есть некоторый аналог
всех задач и выполнимости.
Аналог всяких сад,
тавтологий,
сигмакасад, и пикасад.
Это задача TQBF.
TQBF,
true quantified Boolean formula,
то есть истинные boolean formulas с кванторами.
Иногда на русском BFK
используют аббревиатуру boolean formulas с кванторами.
Тут, соответственно,
дана формула phi,
это распространение этого сигмакасад.
Но теперь нам не нужно экономить число альтернирований,
и мы можем просто сказать,
что у нас по каждой переменной свой квантор и они чередуются.
Потому что phi таких, что
существует x1 для любого x2, существует x3,
и так далее.
Можно даже считать, что у ка отчетная для любого xk,
phi от x1, x2,
и так далее xk.
Это отдельные переменные, можно считать, что это блоки переменных,
и это все совершенно неважно будет.
Это будет TQBF.
Важно только, что тут полиномиальничало кванторов,
но их полиномиальны, потому что они все просто записаны как переменные в формуле phi.
Мы считаем, что phi записаны явно,
прям текстом все переменные явно прописаны без каких-то сокращений.
Вот.
Значит, это лежит в PSPACE, но по той же причине рекурсия.
То есть это
лежит в PSPACE
так как рекурсивный алгоритм.
Вот.
Почему же она PSPACE полная?
На самом деле тут будет
похожая штука, но чуть-чуть другая.
Значит, если вы хорошо помните тему выразимости
из логики с прошлого года, там тоже были похожие формулы,
и там мы заменяли двойное упоминание
вот этого предиката на одинартное.
Это ровно то, что нужно, чтобы получить вот такую штуку.
Ну, типа того, да.
Значит,
как мы а сводим в TQBF?
Да, вообще, в принципе, можно
рассмотреть промежуточную задачу, которая будет как раз про
про достижимость в графе.
Только граф нужно сдавать неявно.
Задание графа неявно означает, что мы по каждой паре вершин
можем понять, есть там ребро или нет там ребра,
и как-то довольно быстро.
Это ровно то, что вот здесь происходит,
что мы можем
если нам дано описание одной конфигурации, описание другой конфигурации,
мы можем быстро понять, есть между ними ребро или нет.
Ну ладно, значит,
я, наверное, не буду подробно на то издаче останавливать,
сразу для этой напишу, что у нас получается,
что по X
не fill же с PSPS, а TQBF же с PSPS.
Множество всех. Смотрите, PSPS это класс, то есть это второго уровня.
Вот нет.
Смотрите, в чем отличие?
В чем отличие от сигмак осад? В том, что в сигмак осад
K фиксированный не зависит вообще от входа.
А здесь K определяется входом, то есть K это число переменных формуля.
То есть чем формула длиннее, тем больше может быть K.
А в сигмак осад у нас K фиксированный для всех входов.
Вот в этом отличие.
Так, ну да, это важно, давайте я это подчеркну,
что K растет
с ростом phi.
То есть вместо константы мы получаем растущую функцию.
Не, ну можно считать, что там прям символ,
это X с индексами.
Не, сейчас, переменные булевские остаются.
Переменные булевые, но формуле они прямо записываются.
Нет, тут точно так же было. Сейчас, смотрите,
у нас есть кое-какая формула.
Вот, вот, вот.
Нет, тут точно так же было. Сейчас, смотрите, в сигмак осад
у нас вот эти X и T могли быть не одной переменной, а блоком переменных.
А здесь, как хотите, можно считать, что тоже блок, а можно считать, что прямо по одной переменной.
Вот, хорошо.
Значит, по X мы строим граф.
Да, значит, мы считаем,
что пусть A лежит в P-спейс,
значит, A лежит в P-спейс,
то есть распознается
алгоритмом V
на памяти
полинома A.
Вот, соответственно,
по X мы строим граф.
Мы строим граф конфигурации.
Значит, граф конфигурации
вот этой самой V от X.
Вот, и, соответственно, нас интересует задача достижимости.
Значит, вопрос
достижима ли
принимающая вершина
из стартовой.
Значит, получается,
что в общем то же самое, что здесь работает,
что если достижима,
то получается, что есть путь длины
и не больше n,
а n в данном случае будет экспонентой,
потому что у нас s это полином,
так что число конфигурации будет экспонента.
Вот, и вот это вот переход тоже остается,
но проблема в том, что если мы теперь на это смотрим не как на инструкцию по вычислению,
а как на формулу, то получается, что здесь параметр уменьшился вдвое,
но и длина увеличилась вдвое.
Ну, как мы делали, чтобы длина увеличилась не вдвое, а на константу?
Ну, давайте распишем.
Reach от s, t, n
это равносильно тому, что существует x,
такой, что reach
от s, x, n пополам
и reach от x, t
и n пополам.
Значит, а это равносильно тому, что
существует x потом для любого u, для любого v.
Значит, если
u равно s
и v равно x,
или u равно x
и v равно t,
то тогда reach
от u, v и n пополам.
И вот получилось, что если мы написали формулу для этого,
для n пополам,
то получается увеличением длины вот настолько.
Соответственно получается, что общая длина будет порядка логарифма n большого,
то есть порядка полинома.
Общая длина формулы
это логарифма n большое,
то есть это будет полином от n маленького.
Ещё база нужна.
База у нас та же самая, что и там.
Либо u равно v, либо достижим за один шаг.
Соответственно тут тоже есть алгоритм,
машина тюринга.
Переход за один шаг, можем проверить.
Это тоже нужно ещё преобразовать формулу,
но это тоже технический вопрос.
Мы фактически уже делали
в теории Кукулевина и в теории полноции Сигмакасад.
Там, правда, нужно переделать,
потому что в Сигме лента не одна и будет более сложная зависимость.
Но всё равно как-нибудь сделаем.
Что? Вот это выражение верно.
Нет.
Да, по всем примерам расставили квантеры.
Всё свободное записывается
прямо внутрь формулы Фи.
Все свободные переменные это будет часть формулы Фи.
Ну, если там откуда-то она взялась,
то мы, во-первых, фиксируем её значение,
во-вторых, считаем частью формулы Фи.
Ну, грубо говоря, да.
И тогда можно спрашивать,
будет ли лежать это в ТКБФ или не будет.
Так, ну вот.
Так, вроде получилось, да? Или какие-то вопросы ещё остались?
Когда мы записываем Фи,
мы не должны ещё записывать...
Сейчас, да, подождите, да, не совсем получилось.
Во-первых, когда рекурсивно это строим,
то у нас квантеры вот тут будут.
И их нужно вытащить вперёд,
как когда мы приводили к предыдурем нормальной форме.
Это мы умеем, да, это просто механически надо взять.
Ну, конечно, просто берём и переносим.
Там, конечно, нужно позаботиться о том,
чтобы все перемены были разными,
чтобы имена всех переменных были разными.
Ну и тогда из заключения импликации можно просто переносить в начало,
ничего не меняя, вообще не меняя квантеры и не меняя переменных.
Ну а дальше, да, тут, конечно, будут блоки,
блоки переменных.
Захотеть, чтобы прям перемены чередовались,
но нож просто бы эффективные переменные,
от которых на самом деле ФИ не будет зависеть,
ну или они могут даже текстуально встречаться, но так что от них ничего не зависит.
Берём ещё там конъюнкция, ещё А или не А, да.
Вот.
Так.
Ну хорошо.
Знаешь что, можно ещё сказать про PSPACE.
А, наверное, можно вернуться к тому, с чем мы начали.
Да, вообще, есть ещё всякие другие PSPACE полные задачи,
но я бы хотел сказать, что у нас есть ещё какие-то
другие PSPACE полные задачи.
Их не так много, как NP полных,
но всё равно достаточно много, и многие игры являются PSPACE полными.
То есть многие игры настолько же сложны,
насколько любая задача с PSPACE.
Вот. Так.
А, можно ещё обсудить, что можно считать...
Да, сейчас давайте за оставшееся время обсудим вот что.
Во-первых, можно считать, что это ФИ это 3 KNF.
Почему? Потому что если вспомнить, как мы в NP сводили
SAT к 3 SAT,
то мы просто добавляли кванторы существования ещё.
Да, ну мы добавим сюда кванторы существования в конец.
Мы добавляем немножко больше кванторов, но всё ещё поленальное число.
А ФИ преобразует в 3 KNF.
Так.
Можно считать,
что ФИ это 3 KNF.
Ну и так же отсюда получается,
что AP равно PSPACE.
Значит, почему?
В одну сторону. Почему AP вложено в PSPACE?
Так, что такое AP? Это значит, что у нас альтернирующая машина,
поленальное время, но не фиксирует число альтернирований.
Но то, что это в PSPACE,
это точно так же, как все наши рекурсивные вычисления.
Если мы умеем по дереву вычисления рекурсивной альтернирующей машины,
понимать, какой ответ,
мы рекурсивно перебираем все ветки, на каждой из них определяем ответ,
и берём конъюнцию или дезюнцию.
Ну, практически, да.
Ну и как следствие, PSPACE тоже вложено в AP,
потому что PQBF, PSPACE полная, и аналгерит в AP тоже здесь буквально.
Мы альтернированием выбираем все вот эти иксы,
потом в детерминированном вычислении вычисляем вот это вот.
То есть любая задача из PSPACE
сначала сводится к TQBF,
и потом решается альтернирующей машиной, которая вот это вот делает.
То есть альтернирующей машине надо только смотреть, какую именно формулу ФИ взять
из той задачи, которую мы сводили.
Ну вот такой ещё взгляд
на PSPACE.
Так.
Сейчас дайте я что ли анонсирую. Есть одна красивая игра,
про которую не очень сложно доказать, что она PSPACE полная.
Значит, это
называется GG,
это аббревиатура Generalize Geography,
то есть обобщенная игра в города.
Игру в города вы, наверное, знаете.
Один игрок, там Алиса, называет город, Боб называет город,
начинающий на последнюю букву города Алиса, потом снова Алиса,
называет на последнюю букву города Боба и так далее.
И важно, что нельзя повторяться. Нельзя повторяться, и кто не может придумать новый город, тот проиграл.
На практике это такая игра на эрундицию,
чтобы выиграть, нужно больше городов знать.
Но в теории, и на практике среди сильных игроков,
надо
на практике среди сильных игроков
смотреть какую-нибудь букву, на которую кончается сильно больше городов, чем начинается,
и пытаются именно на неё называть, чтобы на эту букву у соперника быстрее кончились города.
Да, соответственно, если это игра в теории,
или двух игроков с одинаковым словарем,
то да, начинаешь нужно смотреть четность,
а дальше, какие города нужно называть, чтобы не получить там нет учетности,
или вынудить назвать что-нибудь вот так.
Тем не менее, в обычной игре в города есть очень важная особенность.
Если после этого города можно назвать вот этот,
а еще можно назвать вот этот,
а после этого города можно назвать вот этот,
то автоматически вот такое ребро тоже есть.
то автоматически вот такое вот ребро тоже есть. То есть ребро означает, что после данного города
можно назвать вот тот. Так вот, значит, генеральность географии, это то же самое,
только без этого правила. То есть есть просто какой-то граф ориентированный, и тут еще,
давайте считать, что есть начальная вершина. Граф есть начальная вершина, и дальше просто
Алиса и Боб по очереди двигают фишку с начальной вершины по ребрам. И нельзя повторяться,
значит, нельзя перемещать фишку на ту вершину, где она уже была. Кто не может делать ход, тот проиграл.
Нет, это да. Сейчас, но эта игра в города только без вот этого условия. Сейчас, нет, чего? Обычной
игре тоже не можно повторять вершины. А, в смысле, я понял, что можно повторять вершины,
но нужно загнать в тупик. В общем, это PSP-исполненная игра. Ну, я думаю, что сейчас нужно заканчивать.
В следующий раз я расскажу, почему она PSP-исполненная, и обсудим про логографическую память,
значит, про L и, наверное, NL немножко обсудим. Вот, тогда на сегодня все. Спасибо за внимание.
