у меня первый долг это штурвагнер я там не доказал давайте восстановим утверждение пусть
а это активная вершина тогда есть вот такого разреза не больше чем стоимость
разреза если пересечь с аи и пересечь с аи также было в прошлый раз проверьте
пожалуйста что я пока нигде не обманываю насчет жизни такое там мы его
оставляем доказательства также индукция и база у нас остаётся если там какой-нибудь
ожито это первая активная то для нем уже все доказали индукция база уже доказана
так теперь переход пусть есть две последовательные активные вершины ауя в
две последовательно активные вершины так я нарисую нарисую вот такую картинку совсем чуть-чуть
отличаешься от того что было значит тут я нарисовал вот это вот маленькая облачка это
с пересечь с ау большой это с пересечь с ав то же самое здесь это т пересечь с ау это
т пересечь с ав отличие от предыдущего только в том что тут ау а не у-1 вот ну и значит чем
отличаются что происходит при переходе от ау к ав через все промежуточные значит ну у меня
добавилось вот здесь где-то ав а поскольку ав это активно и до нее активных не было то все
предыдущие вплоть до ау-то лежали вот этой вот противоположной долей где-то есть ав а все
предыдущие до нее лежат в другой доле значит здесь у меня есть все с ау-1 до ав-1 ну где-то
вот здесь еще будет ау лежать потому что ау было активное значит все следующие не активные то
есть все следующие были в одной той же доле что и ау а потом только ав помещается в другую скажем
если эти все в т то те то ав т пришла в с вот ну и тогда мы можем написать следующее что увеличена
вот такого разреза она равна величине разреза ав и ау-1 плюс ав и ну все оставшие то есть отсюда
но не отсюда тоже у нас было это точно также оцениваем сначала пол по выбору ау в нашем
алгоритме мы знаем что это не больше чем ц ау ау-1 потому что ау когда выбиралась на нашем шаге
алгоритма для него вот эта штука максимально возможно значит это больше но чем это по
предположению индукции это не больше чем с пересечь с ау и пересечь с ау
значит это мы делали в тот раз и остается с этой штук разобраться вот но я утверждаю что вот
эта вещь она меньше либо равна чем разность вот таких у двух разрезов
значит почему это так да я я в общем-то рассматриваю как раз ровно вот эти вот два
разреза с пересечь с ау и пересечь с ау это первый разрез и второй с пересечь с ау и пересечь с ау вот
почему при переходе вот скажем вот этого меньшего разреза к большему то есть когда я добавляю
новые вершинки начиная с у плюс 1 вплоть до в этой почему у меня разрез увеличивается хотя бы
настолько но потому что видно что все вот эти вот ребра их раньше здесь не было а теперь они
здесь появились поэтому величина увеличилась хотя бы на сумму весов всех этих ребер потому что
что что-то такое раньше было с пересечь с ау и пересечь с ау это ну вот все вот это вот эти два
маленьких кружочка а теперь чтобы перейти отсюда сюда я добавляю здесь одну вершину а в а здесь
вот эти все вершины с у плюс 1 вплоть в минус 1 поэтому как минимум все вот эти ребра точно добавятся
но еще там какие-то тоже добавятся не знаю вот такие какие не добавятся вот вот такой ребра добавится
но это все они все не отрицательная да у них у всех капаси не отрицательная поэтому это точно
нижняя оценка на разность наших разрезов а дальше вот эти сократились и осталось то что нужно
ну закращается вот и получили переход индукции тоже сделали
вопросы короче мы в прошлый раз все хорошо сделали кроме вот того что тут надо было
рассматривать именно разрез ау не ау минус один как в прошлый раз я рисовал а именно ау и тогда
здесь все все сойдет хорошо тогда мы переходим сегодня к деревьям сколько успеем столько
успеем деревья у нас много раз уже не явно встречались там я говорил что-нибудь типа дерево
обхода dfs и так далее и так далее вот давайте определим пусть же это неориентированный граф
если вы связаны есть и не содержит циклов то это дерево
то есть замечание такие что если у нас есть дерево то во-первых мы знаем как соотносится
число ребер число вершин если же это дерево то мощность множества ребер на один меньше мощности
множество вершин ну там я надеюсь что у вас там был какой-нибудь курс а-ля комминаторики вот где
вы такое движение должны были доказывать но давайте я на пальцах поясню что вот есть у нас
н-вершин давайте я скажу что вот это вот н почему это верно есть н-вершин и какой-то граф на них
связанный при этом без циклов давайте значит сначала нарисуем все эти н-вершин на плоскости
будем по одному добавлять ребра в граф что-нибудь одно провели, другое, третье, четвертое и так далее
и поскольку мы ни разу не образуем цикла то есть вот так вот такого не бывает то на самом деле мы
обязательно каждый раз тягиваем компоненты связанности да я провожу ребро между разными
компонентами связанности объединяю их ну и тем самым уменьшаю число компонент соответственно 1
ну и поскольку у меня изначально было n компонент а в конце одна компонента значит число раз
который я это сделал ровно на минус 1 значит мы знаем всегда что 1 меньше чем вершин ну и второе
замечание что если же это дерево то между любой парой вершин есть ровно один путь ровно один
простой путь давайте так и для любых ув существует единственный простой путь между у и в
но это например можно пояснить так что если есть какие-то два пути между у и в
какой-нибудь такой какой-нибудь такой то оно по сути не обрадует цикл да более формально
чтобы понять как здесь выглядит цикл нужно взять скажем симметрическую разность множеств
ребер которые входят в первый путь и во второй то есть у вас один путь есть второй group если
вы возьмете ех симметрически разность то получите множество которая обязательно является объединения
объединений нескольких циклов причем тамmail что будет не пусто потому что это различные пути
да ну то есть мы предположим что есть два различных взяли их симметрическую разность вот это
гарантированно будет объединив нескольких путей сори циклов объединив нескольких циклов вот и в них
ДФ есть ребра, значит хотя бы один цикл в исходном графе был.
Как всегда до этого мы деревья рассматривали просто как часть какой-то алгоритмы,
типа вот если мы пустим ДФС на графе какому-нибудь ориентированному,
то он по сути создает дерево обхода ДФС, вот есть какой-то куринь,
как-то там он все обойдет, это будет дерево.
Ну здесь будет подвешенное дерево, ориентированное в каком порядке мы все ребра проходили сверху вниз.
Ну вот теперь можно на сами деревья непосредственно посмотреть, как отдельный класс графов.
Вот вообще деревья это очень простые графы, и на них многие задачи, которые являются трудными в общем случае,
они решаются гораздо проще.
Ну например помним, что есть несколько задач, которые мы решать нормально на графах не умеем,
только за всякие экспоненты.
Например там поиск максимальной клики.
Вот скажите пожалуйста, если у вас есть дерево, то какая может быть в нем максимальная клика?
Конечно да, не больше чем два, потому что если есть три, то есть цикл.
Вопрос про независимо на что чуть сложнее, но его тоже может нашить какой-нибудь динамикой по дереву.
Давайте запишем, что клика на дереве в дереве содержит не больше двух вершин.
Независимо на что чуть похитрее, но можно решать с помощью динамического программирования например.
Следующим образом, ну вот смотрите, давайте мы подвесим все дерево за какую-то вершинку, назначим какую-то вершинку корнем.
И ведем следующую динамическую величину.
Во-первых, вот представьте, что я как-то решил задачу для поддерева.
То есть я например знаю в этом поддереве как выиграть максимально независимо множество.
Тогда что мне нужно от него знать, чтобы перейти наверх, чтобы объединить ответ отсюда с ответом из другого поддерева.
По сути нам нужно только знать взята вот этот вот корневая вершина или нет.
Потому что если взята, то есть ограничение, что нельзя брать вот это,
то я могу взять максимальное такое независимое, а если не взята, то соответственно я могу в остальных местах делать что угодно.
То есть если эта вершина не присутствует в независимом множестве, то я могу здесь взять максимальное такое независимое.
И дальше объединить с чем угодно, потому что на это ребро нет ограничений.
Иначе она взята и значит нельзя брать вот это.
Поэтому я введу две DP.
DP0 от V это скажем размер максимального независимого множества под дереве V.
Если саму V брать нельзя.
Брать в независимом множестве нельзя.
А DP1 тогда наоборот я ее насильно должен взять.
DP1 от V нужно взять.
Ну и тогда, например, если у меня для какой-то вершины, точнее для всех детей какой-то вершины посчитаны вот эти DP,
то как посчитать DP для самой вершины?
Вот есть какая-то U, есть у нее куча детей, там V1 и так далее, VK.
Как найти скажем DP0 от U?
DP0 значит я не могу взять U, но в под деревьях я могу делать что угодно.
При этом независимо друг от друга.
Это несвязанные между собой графы.
Я знаю, что эту вершинку я не беру, потому что здесь я написал нолик.
Значит мне нужно просто здесь делать что угодно, набрать какое угодно независимое множество.
Здесь какое угодно и так далее.
Поэтому это будет просто сумма по всем детям от первого докатыва максимум из DP0 DP1.
Это случая, если я U не беру.
Если я U беру, то значит мне нельзя брать вот эти вот корневые вершинки детей,
а кроме этого можно делать что угодно.
Если U взято, то вот эти нельзя брать, а все остальные можно брать, причем независимо в под деревьях.
Поэтому DP1 от U это единица плюс сумма по всем детям DP0 VAT.
Потому что само VAT брать нельзя, а в под деревьях можно делать что угодно.
Точнее любое независимо можно брать.
И если меня интересует максимальная во всем вот этом под деревьях вершинки U,
то значит мне нужно максимально в каждом из них взять с помощью DP.
Вот такая динамика под деревья.
Под деревом мы просто идем снизу вверх, насчитываем ее.
И в конце DP0 от R или DP1 от R это есть ответ.
Ответ максимум из DP0 от R, DP1 от R.
То есть получается линейный алгоритм нахождения максимального независимого множества.
И так многие задачи решаются на деревьях быстрее, чем в общем случае.
Вот еще один из таких интересных примеров, что можно на деревьях решать быстрее, чем в общем случае,
это проверка деревьев на изоморфизм, значит изоморфность графов.
Определение.
Пусть есть два графа, но же один, же два.
Если есть функция из множества вершин первого графа в множество вершин второго графа,
то первая графа такая что?
Если она такова что?
Во-первых, это биекция.
Во-вторых, каждую пару вершин, которые соединили ребром в исходном графе, она переводит в пару вершин, которые соединили ребром во втором графе.
И наоборот, если две вершины были не соединились здесь, то они будут не соединились здесь.
Для любой пары УВ являешься ребром первого графа.
Пара Фиату и Фиат В это ребро второго графа.
И наоборот, для любой пары не являешься ребром первого графа.
Пара образов не является ребром второго графа.
То есть, ребра в ребра, не ребра в не ребра.
А тогда, если все это верно, то Фиизоморфизм графов же один, же два.
Физоморфизм графов же один, же два.
Так, с точки зрения рисуночка, это значит, что просто графы одинаковые, только как-то перенумерованы по-разному.
Что-нибудь такое я нарисую.
Вот такой граф.
Ну и вот такой граф.
Это же один, же два.
И тут произвольно номирать вершины.
1, 2, 3, 4, 5.
1, 2, 3, 4, 5.
Они изоморфны, а можно вот эту двойку привести в эту единицу, эту четверку в эту двойку, ну и так далее.
Видно, что графы как бы одинаковые структуры, их можно правильно перенумеровать.
И, собственно, из определения, видно, что они одинаковы, просто отличаются перенумерацией вершин.
Что я могу так перенумерать вершины первого графа, чтобы получить вершины второго графа,
при этом сохранятся все свойства, то есть все ребра перебивают в ребра, а отсутствие ребра придет в отсутствие ребра.
И в общем случае, если у вас есть произвольные два графа какие-то, то есть понятно, да,
вот если у вас есть какие-то произвольные два графа, то вам надо проверить они изоморфны или нет,
как бы это одна и та же картинка или разная, или в них есть какое-то отличие.
Можно делать всякие простые проверки.
Ну конечно, там можно проверить, что у них одинаковый число вершин.
Можно перег 코�ись одинаковой число ребер.
Не знаю, можно проверить еще что-нибудь, да.
Вы можете проверить какие-то характеристики, проверить что они одинаковые,
это как бы необходимые условия на том, что они изоморфны, но недостаточно.
вы можете там еще что-нибудь проверить, хоть не знаю,
посчитать максимальное просчитание в боеграфах, если не заморфины, то соответственно
максимальное просчитание тоже должно быть одинаковое. Но не в обратную сторону. Вот. И в общем
случае, опять, пока никому не известно, как это делать заполином. Пока вот эта задача не решается
заполином. Значит, проверка произвольных графов на изоморфизм, на изоморфность,
на изоморфность, пока не решается заполином. Я не пишу, что она, наверное, трудная, потому что
про нее этого не известно. То есть это в каком-то смысле задача проще, чем вот эти вот всякие
макс клика, максимально здесь все множество и так далее, но пока еще сложнее, чем все полиномиальные.
То есть это какая-то промежуточная задача, которую пока не заполином решать не умеют, не умеют доказать,
что она достаточно сложная, чтобы решить какой-нибудь трясат или макс клику. То есть она такая совсем
подвешенная, с ней вообще ничего не понятно. То есть она вроде как и не сложная, и при этом не простая,
что заполином пока никто не умеет решать. Ну а на деревьях это можно сделать довольно быстро.
Мы сейчас сделаем ZenLogin. Проверка деревьев на изоморфизм. Проверка деревьев на изоморфность.
Так, ну что мы сделаем? Во-первых, давайте мы научимся работать с ориентированными деревьями,
ну то есть с подвешенными какими-то. Пусть деревья подвешенные. Пусть деревья подвешенные.
То есть есть какие-то выделенные корни, у них там R1, R2, и вот как-то так и не выглядит. Давайте я прям
стрелочкой даже нарисую, чтобы понять направление обхода всего дерева. Вот, и надо понять,
одно это дерево или нет. Можно ли перенумеровать вершинки, чтобы все было хорошо. Ну понятно,
что корень должен перейти в корень, дети корни должны перейти в детей корня, но непонятно в
каком порядке. Например, если вот здесь вот есть два ребенка, которые локально выглядят как одинаково,
вот этих двух вершин исходящей степень 2, и вот этих двух вершин исходящей степень 2,
тогда непонятно, как вот эти две вершины отобразить вот на эти две. Их надо оставить так же или свопнуть.
Это можем только узнать, если мы найдем где-то различия между ними где-то ниже. Вот скажем,
вот здесь вот я там найду такую штуку, которая есть только здесь. Значит, вот эту вершинку,
а, надо отобразить в эту вершинку h'. Соответственно, эту надо отобразить вот в эту. И никак иначе.
Чтобы понять, кого можно куда отобразить, нужно куда-то ниже идти и что-то там такое более
хитрое делать. Нельзя просто сказать, что там смотрим на исходящую степень, и вершины одной
степени друг в другом отраздействуем. Надо действовать хитрее. Мы сделаем следующее. Мы
каждой вершине поставим соответственно какое-то число такое, что вот есть какая-то вершина,
есть ее под дерево. Я этому под дерево ставлю соответственно какое-то число. Давайте напишу это
cv. Это класс эквивалентности под дерево вершины v. Класс эквивалентности под дерево v. Ну и мы
хотим, чтобы изоморфные деревья были в одном классе, а не изоморфные в разных.
Хотим, изоморфные, изоморфные под деревья
имеют один тоже класс эквивалентности. Один класс неизоморфный, соответственно,
как-то нужно дать номер каждому дереву, чтобы одинаковые под дерево имели один тот же номер,
а разные под деревья имели разные номера. Ну начнем снизу дерева от листиков. Если вершина это
лист, да если у нас есть много листьев, то понятно, что под деревьями листьев они все
одинаковые, потому что это просто под дереве за одной вершиной, таким образом, всегда когда мы
видим лист, мы всем вот этим под деревьями из-под одной вершины, да, под дерево листа должны
дать соответствup européя один тот же класс, что вот это класс, который описывает ber
Вот так это и есть, а это, скажем, класс № 0.
Если в поддереве одна вершина, то это класс № 0.
Это мы сделаем для листьев.
А дальше у нас будет следующее действие.
Для произвольной вершины В пусть мы знаем классы всех ее детей.
То есть у меня есть много детей, я знаю класс вот этого чувака, класс вот этого чувака, класс вот этого и класс вот этого.
Тогда понятное дело, что класс В однозначно задается мультимножеством номеров класса всех его детей.
Потому что, во-первых, я знаю размер этого множества, то я знаю количество детей у В.
Во-вторых, если я знаю какие именно здесь классы, то я могу их как угодно перемешать.
Я могу переставлять детей как угодно.
Получится одно и то же поддерево с точностью изоморфизма.
Ну и, значит, если я знаю само мультимножество, какие здесь классы, то я целиком знаю, как выглядит дерево.
Я знаю, что у меня есть четыре ребенка, здесь там класс номер один, класс номер два, класс номер три, класс номер четыре.
Я знаю, как выглядит это дерево, то есть однозначно знаю весь этот класс, однозначно знаю все это по дереву и так далее.
То есть, по сути, чтобы задать класс эквивалентности одной вершинки, мне нужно знать класс вот этих вот всех его детей.
Поэтому давайте мы напишем...
Ну, давайте я пример сначала допишу этот.
Что если, например, я вот, ну, например, да, я решу, что все эти вершинки имеют класс ноль,
то тогда я для вершинки В сначала эти четыре нуля как бы складываю вектор и говорю, что это описание класса вершины В.
То есть вершина В, это такая вершина, что у нее список детей образует вот такой набор классов.
И буду говорить, что это соответствует классу номер один.
То есть теперь у меня число один соответствует вот такому вот дереву В, ну, точнее, вершинки, у которой ровно четыре ребенка каждая из которых является листом.
Ну, например, вот так мы задумировали.
Дальше, если у меня есть там какая-то другая вершина У, у которой есть сын В и там еще что-то,
то опять я знаю, что это класс номер один, знаю какие это классы, складываю все эти числа в вектор
и говорю, что, собственно, содержимое этого вектора и задаю однозначно мне класс, класс эквивалентности для текущей вершины.
Только чтобы у меня было все в порядке с, в порядком, я сказал, что это как бы по сути мультимножество, потому что я могу как угодно свопать детей,
то мне нужно на самом деле здесь делать, ну, например, сортировку по возрастанию всех вот этих классов,
потому что если мы применим 1.0.0, то давайте я напишу 0.0.1, чтобы, ну, в общем, я буду хранить это все в виде вектора,
чтобы все однозначно хорошо, ну, как бы, чтобы вот это вот было по сути равно там 0.1.0 и было равно 1.0.0.
Да, потому что неважно, какой именно из этих детей имеет класс номер один, потому что я их все равно всегда могу как бы перенумеровать,
так что все вот эти три вектора надо отрождествовать. Ну, для этого я просто строю такой вектор 1.0.0, сортирую в порядке возрастания и получаю новый вектор,
который у меня еще нигде не встречался, говорю, что это класс номер два. Вот, ну и так далее.
Просто иду по дереву снизу вверх, записываю номера классов детей в вектор, сортирую, и это новый тип класса.
Вот, ну и в конце там понятно, что надо будет просто посмотреть на класс R1, класс R2, если не одинаковый, то это изоморфный деревьев, если не одинаковый, то неизоморфный.
Вот, ну давайте код напишем.
Значит, во-первых, мне нужен будет мап из векторов int, чтобы по вот этому вектору определять какой-то номер класса.
Давайте так назову его номер. Ну, по вектору как бы детей понять какой-то номер класса.
Дальше нужен вектор int c, да, вот тот самый номер класса для каждой вершины.
Ну, видимо, еще нужна переменная penta, давайте я назову.
Сколько классов мы нашли?
Ну, вот, вот, вот.
Penta, давайте я назову.
Сколько классов мы нашли?
Тогда наш алгоритм, который по сути просто обходит дерево, может работать так.
Вот он стоит в вершинке v.
Дальше.
А, ну да.
Заводит список классов эквалентности детей.
Давайте я его назову a, потому что мне лень писать больше букв.
Дальше, проходимся по всем детям.
Давайте я пишу так u, это сын v.
Значит, сначала запуститься рекурсивно от этого самого сына.
Дальше, по завершении этой рекурсии, по завершении dfs atu.
Я считаю, что у меня c atu уже посчитано, то есть после этого c atu известно.
И я это c atu просто pushback в массив a.
То есть я нашел номер класса эквалентности ребенка, этот класс запихал в вектор a,
ну и так делаю для каждого ребенка.
То есть a pushback, pushback, класс, вершинки номера u.
Сделали.
Дальше, сочетировка вектора a.
Ну и все, теперь вот этот вот сам вектор a является описанием класса эквалентности вершины v.
И мне нужно посмотреть, если a уже присутствует в мапе num,
то тогда надо просто написать, что c от v это num от a.
Если не присутствует, то нужно его сначала вставить, сказать, что это новый класс эквалентности,
и для вершинки c от v тоже поставить тому, чему было равно knt.
Давайте я дальше словами напишу.
Если a принадлежит num, то есть если у меня уже в этой мапе есть соответствие такому вектору чему-то,
то мне нужно сделать c от v равно просто num от a.
Потому что уже когда-то раньше в дереве я нашел такую вершину, как бы класс, который относится к векторам a.
Я знаю, к какому номеру это соответствует, что это за номер класса эквалентности.
Ну вот я, собственно, его просто переназначаю для вершинки v.
Иначе, я напишу так, c от v равно knt.
То есть я завожу новый класс эквалентности с номером knt, говорю, что вершинка v имеет такой класс.
И, видимо, num от a равно knt++.
То есть я в мою мапу вставляю этот вектор с номером knt, при этом knt еще увеличу ничку.
Хорошо.
Да, сколько у нас закрыть?
Ну все, вес алгоритм. То есть если нам нужно теперь два каких-то дерева проверить на изоморфность,
то я запускаю dfs от первого корня, dfs от второго корня, на одной и той же памяти, как бы вот этот вот c.
И тогда нужно просто проверить, что в конце c от r1 равно c от r2.
Если равны, то изоморфны, если не равны, то не изоморфны.
Вот это, собственно, следует просто из нашего алгоритма, что...
Как это пояснить?
Ну, вот, собственно, мы там рисовали, что у нас выполняется вот это вот свойство,
что изоморфенные деревья это один класс, а они изоморфенные-то разные классы.
Собственно, мы так построили алгоритм, что это выполняется, что, как бы, если у меня известен список классов детей,
да, и если они одинаковые эти списки, то, значит, у меня получается изоморфные по деревья,
если разные списки, то не изоморфные по деревьям. Ну, собственно, собственно и все.
Поэтому r1, r2 нужно просто будет проверить, правда ли, что c от r1 равно c от r2,
если да, то изоморфны, если нет, то не изоморфны.
Так, теперь асимптотика алгоритма, асимптотика будет на самом деле n log n,
где n – это число вершин в... Ну, пусть в каждом дереве поровну вершин, иначе нет смысла проверять незаморфность,
по n в каждом дереве, где n – число вершин в обоих деревьях.
Почему это работает за n log n? Ну, во-первых, понятно, что что-то такое должно быть, потому что у меня сортировка векторов,
у меня n раз будет сортировка. Суммарно, размер всех вот этих ашек – это от n, потому что каждая вершина,
точнее, видимо, ну да, даже не больше, чем n, потому что каждая вершина побывает в а только один раз,
в а для своего родителя, поэтому суммарно размер всех вот этих векторов – это линейное что-то,
да, ну и я вызываю сортировку нескольких массивов в суммарной линии длины. Это работает за n log n.
Остается разобраться с мапой, да, почему это работает быстро, то есть я как бы обращаюсь к мапе по индексу равному вектору.
Ну, надо вспомнить, что если у нас есть мап, и он хранит векторы, то за сколько вообще происходит любая операция?
За сколько я, скажем, проверяю вхождение или там достаю значение по номеру?
Давайте напишем, что время запроса, время обработки запроса
мап, есть длина а умножить на логарифм размера. Ну, так log n и напишем, видимо.
Ну, потому что, смотрите, вот понятно, что логарифм, он как бы, то есть если бы у меня вот здесь был не вектор,
а какие-нибудь инты, то понятно, что да, ну, все в мапе работает за log n, потому что у меня всего в мапе будет максимум n элементов,
значит, все запросы работают за логарифм, да, и поиск, и вставка, и извлечение значения работают за логарифм.
Но теперь, поскольку у меня ключи – это не числа, а векторы, у меня еще какое-то время тратится на сравнение элементов.
Ну, вот представьте, у нас есть какое-нибудь дерево, не знаю, там, АВ или красно-черный, или какое-нибудь.
В корне лежит какой-то вектор, и вам нужно понять, куда идти. Вот есть какой-то корень, и вам пришел какой-то вектор А.
Вам надо сравнить, кто из них больше, и пойти либо влево, либо вправо, ну, либо понять, что они одинаковы.
Эта проверка выполняется вот за такое время, но не большим за такое, потому что есть два вектора.
Как проверить, кто из них больше, кто меньше? Ну, вы просто так идете слева направо, охотите первое различие, да,
если тут больше, то спускаете вправо, если тут больше, то спускаете влево.
Это работает не большим длина вот этого массива, ну, и не большим длина вот этого.
Давайте я выберу одну из этих оценок.
То есть все сравнения работают максимум за длину А, где А – это текущий мой вектор.
И таких сравнений будет логарифмическое количество.
Значит, суммарно время работы есть сумма, большая сумма по всем нашим массивам А, аналог М.
Ну, а сумму А мы уже оценили, мы сказали, что это от М.
Потому что суммарно каждая вершина попадет в свой вектор А максимум один раз.
Каждая вершина У попадет в вектор только один раз от того, когда В – это ее родитель.
Тогда У является сыном В, и оно попадет в вектор А.
Значит, это все линейное количество, ну и вот получили N log N.
То есть у меня вот эта штука работает суммарно за N log N.
И все операции с Мапой тоже работают суммарно за N log N, вот мы здесь это показали.
Все остальное линейное. Ужбеки там всякие и так далее.
Согласны?
Вот, ну отлично.
Вот так мы научились проверять корневые деревья на изоморхность.
Дальше нужно сделать то же самое с некорневыми деревьями,
то есть когда у нас нет вот этого вот однозначно заданной вершинки R1, R2.
То есть здесь там как бы было просто, что мы знали, что R1 точно в R2 должно перейти,
потому что это единственная вершина, в которой никто не входит.
И это тоже единственная вершина, в которой нет входящих ребер.
Они должны друг к другу перейти.
А если это не так?
Если у нас нет выделенных корней, то нужно их как-то сначала найти.
Вот вопрос у меня к вам, знаете ли вы какие-нибудь такие вершины в дереве,
которые почти однозначно определяются?
Есть какая-нибудь такая характеристика, типа вершинная,
что вот в любом дереве ровно одна такая-то вершина.
Тогда если вот такая вершина ровно одна, то я могу за нее подвесить,
и тут подвесить, и они должны быть одинаковыми.
Да, можно и то, и то. Вы говорите про центроид, вы говорите про центроид.
Можно взять и то, и то.
Так, давайте, наверное, я про центроид, потому что с центром чуть дольше все доказывать,
как там его искать и так далее.
Второй этап – это проверка вершины.
Значит определенные…
…вершина называется центроидом.
Вершина V называется центроидом дерева.
E Jacobsiteço – это 2018哦не.
Опять же ver.
Если после ее удаления все компоненты связанности, оставшиеся, имеют размер максимум n пополам, то есть она такая, что ее удаление как бы разбивает граф на компоненты хотя бы два раза меньшего размера, чем исходный граф был.
Пусть g дерево,
n от числа вершин.
Вершина v называется центроидом.
А после ее удаления все компоненты имеют размер максимум n пополам.
Какой-нибудь пример.
Так, вот такое страшное дерево.
Раз, два, три, четыре, пять, шесть, семь, восемь.
Вершин.
Ну и кажется, вот это вот центроид будет.
Да, потому что после удаления этой вершинки у меня будет компоненты связанности размера три, размера один и размера три.
Каждая из чисел не превосходит в четверки, значит это будет действительно центроид.
И, видимо, других нету, потому что если, скажем, удалить вот эту, то будет 5 вершин.
Вот здесь это слишком много.
Но здесь то же самое нельзя удалить, потому что здесь будет 5, это будет много.
Короче, здесь один центроид.
Утверждение.
В любом дереве центроид либо единствен, либо их ровно два, при этом они соединяются ребром.
В любом дереве.
В любом дереве либо центроид ровно один,
центроид ровно один,
либо их два, они соединяются ребром.
Так, сначала давайте предъявим алгоритм поиска какого-нибудь центроида.
Чтобы доказать, что их не больше, чем два, давайте докажем, что он хотя бы один.
Алгоритм поиска центроида.
Поиска произвольного центроида.
Алгоритм следующий.
Давайте мы подвесим наше дерево за произвольную вершинку,
за произвольный корень R.
И у каждого по дереву посчитаем размер.
Для каждого по дереву посчитаем sub3 от V,
sub3 от D,
sub3 от V,
sub3 от D,
sub3 от D,
sub3 от D,
sub3 от D,
sub3 от D,
в это размер под дерево с корнем в размер под дерево
в и тогда смотрите как можно искать центроид но мы знаем
что саптриот r это n потому что под дереве корня есть
все вершины как тогда выглядит центроид это такая вершина
вот если мы ее удалим что останется останутся ее
и останется нам дерева бы preguntила whole rates
мне нужно чтобы здесь был небось чем пополам здесь здесь и вот здесь
но то что в над дереве небось чем n пополам это тоже самое что в под дереве хотя бы m пополам
То, что сверху не больше ни пополам, равносильно тому, что снизу хотя бы, наоборот, н пополам.
Н минус н пополам, это н пополам. То есть мне нужно найти такую вершину С, что у нее САП3 это хотя бы н пополам, а у всех детей не больше ни пополам.
Давайте это напишем. Ищем вершину С, такую, что САП3 вот С, САП3 вот С, больше с обравнованием пополам, а у всех детей, наоборот, меньше с обравнованием пополам.
У всех детей С, наоборот, САП3 меньше с обравнованием пополам.
Вот, ну, это, собственно, критерии того, что нас центроет, что после удаления во всех ее, ну, как бы, по деревьях снизу будет не больше н пополам вершин, а также сверху тоже не больше н пополам, потому что у нас снизу хотя бы н пополам.
Тогда алгоритм будет такой. Давайте мы встанем в корень и будем идти вниз в ту вершину, пока она существует, в которой САП3 хотя бы н пополам.
Вот мы встанем в R, видим, ага, у этой вершинки САП3 хотя бы н пополам. Ну, просто сюда перейдем.
Потому что это условие точно выполняется. Давайте просто тогда будем искать, ну, самую глубокую вершину с таким свойством.
Стоим здесь, видим, ага, вот опять есть вершина с САП3 хотя бы н пополам, перешли сюда, а здесь уже ни одного такого нету.
То есть у вершинки В, скажем, все дети имеют размер меньше, чем н пополам.
Тогда в этот центроет, потому что для него выполняется вот это, а для всех детей выполняется вот это.
Алгоритм очень простой. Насчитали САП3, размеры под деревьев, а дальше просто идем от корня сверху вниз и спускаемся в произвольную вершину с САП3 хотя бы н пополам.
Последний раз, когда мы это смогли сделать, это и есть наш центроет, потому что ниже все имеют размер меньше, мы пополам, значит спускаться ниже нельзя, и это есть тот самый центроет.
Так, ну вот такой алгоритм, он конечно работает, конечно завершается, потому что мы не можем спускаться бесконечно долго, потому что для листиков точно вот это уже неверно.
Вот это неверно для листиков, если там н хотя бы 3 видимо, если н хотя бы 3, то для листиков это неверно, значит наш алгоритм точно завершится на каком-то этапе.
То есть он будет так идти-идти-идти, когда-то он завершится, и это собственно и будет наш центроет.
Поэтому центроет всегда есть.
Почему их не больше, чем два? Значит он всегда есть, он либо ровно один, либо их хотя бы два.
Вот что делать, если их два? Ну давайте нарисуем какую-нибудь картинку.
Предположим, что есть два центроида, которые не соединены ребром.
Пусть есть два центроида, не соединенные ребром.
Тогда давайте нарисуем путь между ними.
Есть первый центроид, есть второй центроид, при этом на пути есть хоть что-то.
Есть хотя бы одна промежуточная вершинка.
Есть второй центроид, при этом на пути есть хоть что-то, есть хотя бы одна промежуточная вершинка.
Ну тогда смотрите.
Сейчас, секунду.
Что-что?
Да, да, я понял. Сейчас давайте попробуем сделать.
Да, это хорошая идея, действительно.
Давайте возьмем любую промежуточную пути и назначим ее корнем.
Тогда смотрите, с одной стороны, поскольку после удаления C1 все распадается на компоненты максимума N пополам,
то давайте нарисую, что остается после удаления C1.
Есть какие-то компоненты вот такие, и есть соответственно все вот это вот.
В частности, это имеет размер не больше N пополам, поэтому это все имеет размер хотя бы N пополам.
Значит, если я подвешу за R, то sub3 вот C1 больше равно, чем N пополам.
Потому что кроме нее есть вот это вот размер меньше равно, чем N пополам, поэтому вот это хотя бы N пополам.
То же самое с C2. У него есть здесь какие-то деревья.
После удаления C2 они все имеют размер максимума N пополам, но также вот это вот все, все что как бы левее вот этого C2,
тоже имеет размер максимума N пополам.
Значит, sub3 вот C2 имеет размер хотя бы N пополам.
Ну и тогда у меня есть получается вот это вот хотя бы N пополам, вот это хотя бы N пополам,
еще есть хотя бы один корень, поэтому в дереве больше N вершин противоречия.
Ну все, мы получили, что центроидов максимум два и мы соответственно можем их легко находить,
можно найти легко один ну и дальше там не знаю, можно проверить у всех соседей ну там дальше как угодно.
Можно там либо этот алгоритм модифицировать так, чтобы находил оба центроида, а не только один.
Ну потому что по сути у меня здесь критерий на центроиды, надо просто проверить для каждого шны выполняет это или нет,
либо мы там находим один центроид какой-то, дальше перебираем всех его соседей
всех его соседей, проверяем выполняется ли это свойство для соседей первого центроида.
Тем самым найдем все центроиды.
Так вот.
Теперь, если мы умеем искать центроиды, если мы знаем, что их мало,
то мы понимаем, что центроид одного дерева должен обязательно перейти в центроид другого,
если мы ищем изоморфизм.
Если мы ищем изоморфизм, то, ну там, понятное дело, просто перенумерация вершин,
phrases must go to the centered one,
let's just look at which center of the second tree this center of the first tree will go.
there must give two confirmed centers,
in this case, say C1 and C2.
Let's look at islo- iso- on the iso- on the isomorphism difference
between this center-new one and this center-new one C1.
можно просто подвесить первое дерево за c, второе за c1, и проверить, что они изоморфаны как корневые деревья.
Потому что если я фиксировал, что вот это переходит в это, то это то же самое, что если я их поднял в корень,
подвесил, и тем самым фиксировал, что c переходит в c1. А все остальное у меня есть уже алгоритм проверки корневых
деревьев на изоморфанность. Если не получилось, то значит пробуем c преобразовать в c2. То есть то же самое,
подвесим первое дерево за c, второе за c2. Проверяем изоморфаны они или нет, как корневые деревья.
Если хотя бы один раз получилось, значит деревья изоморфаны, и мы даже знаем, какой центрой куда отображается.
Если ни разу не получилось, значит мы не смогли этот центрой никуда преобразовать, никуда отобразить,
поэтому деревья не изоморфаны. То здесь получается поиск центроидов,
поиск центроидов, плюс не больше чем два, не больше две проверки на изоморфанность ориентированных деревьев,
не больше двух проверок на изоморфанность корневых деревьев.
Ну это все по-прежнему NLGN.
Вот такая прелесть. Получается, что в случае деревьев мы можем вот работать как с корневыми, так и с некорневыми,
из-за, например, того, что вот центроидов всегда не очень много. Да, значит альтернативно можно вместо
центроида брать так называемый центр, это середина диаметра. Диаметр, как вы сказали, самый длинный путь.
Точнее, это среди всех возможных хорошейших расстояний самое длинное. То есть мы по всем парам вершинам считаем
хорошейшее расстояние, находим среди всех пар максимальное такое, это будет диаметр. Самое большое минимальное расстояние, это диаметр.
Дальше на этом диаметре там однозначно определяется центр, как середина диаметра.
Ну если, если здесь там четное число ребер, то центр это просто середина. Если их там нечетное число ребер, то у нас есть два центра,
собственно так же, как было с центроидами. Потому что центры тоже либо один, либо их два.
И тогда то же самое, надо просто попробовать отобразить центр первого дерева в центр второго дерева,
и проверить, что они заморщены как корневые деревья. Тут же самое, что нам важно лишь, что есть какая-то такая характеристика вершинная,
что есть какая-то такая вершина в дереве, что их немного, один или две их, одна или две, и они, ну понятно дело, сохраняются после заморфизма.
Потому что деревья как бы отличаются просто перенумерацией вершин, значит там свойство для вершин должно сохраняться, потому что оно не зависит от нумерации.
Значит центр приходит в центр, центроид в центр, и так далее.
Окей, так теперь поговорим про LCA, Lowest Common Ancestor.
Ну и меньше общепредок.
Тут опять картинка на изоморфном дереве, на корневом дереве. Дерево корневое, за что-то подвешенное.
И есть какие-то две вершинки в нем У и В. Тогда LCA это их общепредок наименьше в том смысле, что он наиболее низко расположен.
Вот если мы так подвесили, то он находится ниже всех остальных общих предков.
То есть это такая вершина, которая является их общим предком, то есть от которой можно дойти до У и до В по ребрам сверху вниз.
При этом среди всех таких она самая низкая.
Ну собственно тут как бы название Self-Descriptive, что это общепредок, при этом наименьше в том смысле, что он как бы на максимальной глубине, ниже всех остальных находится.
Зачем это нужно? Ну, например, за тем, что если у меня все-таки, я в общем так могу понимать, как выглядит путь между У и В.
Вот если я подвешу запрозвольную вершинку R, и я научусь находить LCA двух вершин У и В, то я знаю, если дерево было неориентированным, я знаю, как выглядит путь от У до В.
Нужно сначала от У дойти до LCA, потом от LCA до В. Путь обязательно устроен ровно так, потому что как-то же он устроен, и на этом пути обязательно присутствует вершина,
то есть на этом пути можно выбрать вершину минимальной глубины, то есть расположены ближе всего к корню. Это будет собственно LCA, потому что идти вот так вот мы не будем, это уже будет путь непростой.
То есть мы можем подняться до LCA, пойти куда-то наверх, и потом обратно спускаться вниз. Но это бред, да, потому что тогда путь будет непростой.
Самый короткий путь, и собственно единственный простой путь, это подняться от У до LCA, и потом от LCA вниз.
Ну как можно LCA находить?
Так, давайте попробуем успеть два способа.
Первый способ находения LCA. Первый – это двоечные подъемы.
Во-первых, нужна будет такая митра процедура, которая вроде как была даже когда-то в контесте. По дереву проверить, что одна вершина – это предок другой.
Пишется она очень просто. Проверка того, что одна вершина X является предком вершины Y. У них нужно сравнить T in и T out просто.
Значит, мы должны были, чтобы X был предком Y, нужно чтобы мы вошли в X раньше, чем в Y, а вышли позже.
Ну мы что-то делали такое, когда про DFS просто говорили, да, потому что когда мы обходим дерево DFS, мы у каждой вершинки там можем посчитать время входа, время выхода T in, T out.
Мы знаем, что для любых двух вершин T in, T out они либо вложены как отрезки, либо не пересекаются.
Любые два отрезка они либо вложены, либо не пересекаются. Так любой DFS работает, что если он зашел в вершину, потом какой-то другой дошел,
то нам нужно сначала ее целиком войти, выйти из нее, и только потом можем дойти обратно и выйти из нее.
Если мы вошли в одну, то мы сначала должны из нее выйти, потом выйти из исходной.
А если мы вышли из первой, то есть не может быть такого, что я зашел в одну, вышел в второй и вышел в той самой одной.
Они не могут пересекаться, могут быть только вложены.
Значит, чтобы это проверить, надо просто проверить, что вот такая картинка, это вот Z с такими двумя нераненствами.
Теперь с помощью этой процедуры и, собственно, двоичных подъемов мы найдем LCA.
Что такое двоичные подъемы?
Так, давайте назову их лифтс.
Лифт для числа K и вершинки V это предок V поколений двафкатой.
То есть где я окажусь, если из вершины V двафкатой раз поднимусь в родителя?
Предок в первом поколении это родитель, предок во втором это дедушка, ну и так далее.
Где я окажусь, если двафкатой раз возьму родителю?
Считается очень просто.
Лифтс нулевой V это просто parent от V, потому что это предок в поколении двафнулевой, то есть один.
А дальше, если я знаю лифтс какой-то KT от V, пусть это будет U, то я знаю лифтс K плюс первое от V.
Это нужно применить вот это вот самое к U.
Лифтс KT U, потому что чтобы прыгнуть на двафкатой плюс один вверх, достаточно один раз прыгнуть на двафкатой, а потом еще раз на двафкатой.
Картинка такая, что вот есть V, я сначала на двафкатой вверх прыгнул, попал в U, потом еще на двафкатой попал в предка на расстоянии двафкатой плюс один.
Давайте договоримся, что если там нет предка с таким нормом, то есть если мы не можем прыгать так высоко, то скажем, где-то здесь находится корень, то мы считаем, что в корне у меня стоит петля,
и я бесконечно в этом подкорне могу в корень подниматься сколько угодно раз.
То есть тут не минус один, скажем, а именно указатель в корень.
То есть если мы пытаемся пойти выше, то тут будет просто корень вместо несуществующей вершины.
Вот тогда вот так очень просто насчитываются эти бинарные подъемы.
Ну потому что понятно, что K не имеет смысла брать сильно больше, чем логарифм N.
Если я вот здесь вместо K возьму лог N и буду искать предков по колене 2 в степени там больше, чем лог N, то это всегда будет просто корень, это бесполезно.
Я пытаюсь подняться на что-то больше, чем глубина дерева заведомо, значит это будет всегда корень, это не интересно.
Значит K достаточно брать типа там до логарифма, ну давайте напишу там лог N плюс 2, на всякий случай, чтобы с запасом было.
Ну и W, все остальные вершины, в смысле просто все вершины.
Теперь как искать LCA, если мы знаем вот эти две процедурки, то есть если у нас есть подъемы 2-ичные и есть процедура проверки на прерывочность.
Ну я пишу так, есть две вершины У и В.
Во-первых, если У это предок В, то У это ответ.
Если одна вершина предок другой, то собственно это и есть тот самый их наименьший общий предок.
Потому что выше прыгать бесполезно, а ниже нельзя, потому что тогда мы перестанем уйметь в качестве потомка.
То есть картинка будет такая.
Иначе я сделаю следующее, то есть теперь У это не предок В, и картинка какая-то такая.
Ну я вот так вот нарисую.
Я сейчас найду вот эту вот вершину, предпоследнюю на пути от У дольца, и потом возьму от нее один раз parent, это будет ответ.
К от К max до нуля.
Если, значит смотрите, я стою у и пытаюсь прыгнуть на 2 вкатый.
Если я при этом не попадаю в предка В, то я делаю такой прыжок.
Если попадаю, то я не делаю такой прыжок.
То есть если этот прыжок оставляет меня вот на этом вот пути как бы, не выводит меня в предке В, тогда я делаю такой прыжок.
Иначе не делаю.
Если неверно, что консестра лифтс Кт Ут запятая В, тогда У равно лифтс Ку.
Вот ну и в конце все просто return лифтс 0 от У.
Да, давайте вот эту картинку побольше нарисую.
Вот есть У где есть там В.
Я хочу как бы подниматься вот по этому пути так, чтобы вот в Ильца не попасть.
То есть вот это Ильца, есть там еще какие-то более высокие вершины, я хочу закончиться вот здесь, в шине Ильца со стороны У.
Вот здесь хочу закончиться, тогда ответ это как раз родитель этой самой вершинки.
Я вот так поднимаюсь ушкой вверх, пока вот тут не окажусь, тогда ответ это лифтс 0 У.
Ну почему я окажусь действительно вот здесь?
Ну за счет этой проверки неверно, что консестра.
Я точно никогда не поднимусь вот сюда, выше того, где мне нужно.
То есть я всегда нахожусь не выше, чем вот здесь.
Ну и с другой стороны, я просто по сути, то есть мне нужно подняться от У на какую-то высоту.
Я иду просто по всем степням двойки, от максимальной к минимальной.
И каждую степень двойки, которая здесь встречается, я ее прыгаю.
То есть по сути, я просто взял вот это число, равное расстоянию, которое мне нужно попрыгать,
разложил вдовечную систему числения и от старших биток к матшам откусывал.
Не знаю, если тут было там 10, то я сначала сделал прыжок на 8, потом на 2, я оказался вот здесь.
Какая бы здесь ни была глубина изначально, я гарантированно по степням двойки просто пройдусь,
и я окажусь в последней вершине, которая не является предком В.
Потом надо будет взять просто предка, и это будет ответ.
Вот. Это работает за логарифм.
Потому что есть один цикл, где К пробегает логарифмом значений.
Итого мы получили предпочет за НЛГН, вот он, и ответ на запросы за ЛГН.
Ну, в принципе, не так нормально.
Теперь второй метод будет чуть быстрее.
Значит, это спортстейбл на эйлеровом обходе.
С примера начну.
Вот пусть есть такое дерево пронумерованное.
Как выглядит эйлеров обход? Что такое эйлеров обход?
Это, по сути, просто порядок посещения всех вершин в процессе ДФС.
Вот я встал отначально в двойку, как-то там все вот так вот обошел,
и каждый раз, когда я наступаю в вершинку, я ее печатаю.
Что здесь будет?
Значит, сначала я встал в корень, потом спустился в один, потом в шесть,
потом в шести поднялся в один, в четыре, в один, в два,
ну и дальше, собственно, вот здесь просто продолжаем.
Тройка, семь пять семь, восемь семь, три два, три два.
Короче, это вот прям, как если бы вы рукой обводили это дерево,
в каком порядке вы все вершины вот так вот обведете?
Сколько раз, собственно, вы около вершинки проводите,
столько раз вы ее и выписываете. Это эйлеров обход.
Значит, кодом это делается тоже очень просто.
Вам нужно просто в ДФС, и каждый раз, когда вы спускаетесь в ребенка,
печатать от самого ребенка, и, наоборот, когда из ребенка возвращаетесь в вершину,
нужно печатать то, куда вы вернулись.
Короче, каждый проход ребра нужно отразить печатанием до текущей вершины.
Прошли по ребру, напечатали то, где вы находитесь,
поднялись в рекурсии из вершины в предка,
опять напечатали предка, потому что вы наступили в новую вершину.
Вот так работает эйлеров обход.
Ну а дальше замечание следующее, что давайте, наверное, мы уже не будем доказывать,
потому что времени не очень много остается.
Тут оно простые все утверждения.
Значит, утверждение.
Вершина с минимальной глубиной
на отрезке
между первыми вхождениями у и в
это есть их лца.
То есть, если нам нужно эти лца каких-то двух вершин,
например, вот четверки, семерки,
четверки, семерки,
то я смотрю на их первые вхождения в этот наш эйлеров обход,
вот четыре, вот семь.
И на этом отрезке нахожу вершину минимальной глубины.
Это будет двойка.
Это их лца.
Между четверкой и семеркой самый низкий предок это двойка, корень дерева.
Если, например, взять там 5 и 8,
вот первые вхождения пятерки, вот первые вхождения восьмерки,
на этом отрезке минимальная глубина достигается вершины семь, это их лца.
Интуитивно это понятно.
Есть у вас две вершины у и в,
а у вас обход эйлеров.
Чтобы попасть из у в,
что должно произойти, чтобы попасть отсюда-сюда?
Вы сначала должны все это по дереву обойти,
потом как-то подниматься, ходить, ходить, ходить,
и рано или поздно прийти в в.
Для этого вам нужно по сути весь путь от у до в пройти,
значит, вам нужно побывать у лца.
А в более высоких предках вы не побываете,
потому что вы в них побываете только когда все это по дереву обойдет.
Ну так, на пальцах.
Действительно просто минимальная глубина на отрезки между вхождениями у и в,
это есть лца этих самых вершин.
Тут я написал первыми, на самом деле неважно,
какими можно там любыми двумя вхождениями рассмотреть,
потому что все равно, если у вас есть два вхождения у и в,
то чтобы между ними как бы, чтобы из у попасть в в,
вам нужно пройти весь этот путь.
Вы же как-то проходите его, соответственно все вершины печатаете,
обязательно на отрезки между этими вхождениями.
Значит, по сути нам нужно просто взять
и на отрезке вот этого массива найти минимум.
Ну вот мы умеем это делать до вот единицы.
То есть, ну, точнее как бы не на этом массиве, конечно,
это массив вершин, скорее нужно создать пары,
глубина, запятая вершина.
И на этом массиве считать уже минимум.
Тогда, ну, сейчас напишем короче.
Значит, вот мы получили какой-то эллеров-обход, да, вот он.
И дальше я, если у меня был набор вершин,
то я пишу глубина вершины, глубина вершины и сама вершина.
То есть я вот этот массив преобразую в массив пар.
Дальше, ну, соответственно, пары сравниваю, как обычно,
сначала по первому аргументу, потом по второму.
И если мне нужно найти минимум на отрезке,
точнее вершины минимальной глубины на отрезке,
то я просто нахожу на отрезке минимум с помощью Sparse Table.
Минимум у меня как раз минимизирует первые элементы пары,
то есть мы находим вершины минимальной глубины,
ну и соответственно не только ее, но и,
не только глубину, но и саму вершину.
Значит, строим Sparse Table.
Sparse Table на массиве пар.
Вот.
Строится он, ну, предпочет за n log n.
Вот.
Строится он, ну, предпочет за n log n.
Опять же.
Предпочет за n log n.
Зато запрос за единицу.
Потому что запрос Sparse Table работает за вот единицу.
Тут, кажется, все.
Мне надо, конечно, вспомнить, как работает Sparse Table,
что вот у меня есть какой-то массив статически не изменяющийся,
здесь важно, что он как бы не меняется.
Вот я как выписал его, структура дерева у меня никогда не меняется,
поэтому этот массив всегда вот такой.
Вот как он там был, так он, такой никогда не изменяется.
Ну а дальше надо вспомнить, как работает Sparse Table,
и что он на самом деле за единицу на каждый запрос встречает.
Так, ну и, видимо, последнее, что успеем разобрать.
Это тоже решение задачи Убальца.
Это алгоритм парах Култона и Бендера.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Парах Култона и Бендера.
Это прям вообще максимально наилучший, возможно, алгоритм,
потому что у нас будет предпочет за ООН и ответный запрос за единицу.
Ну понятно, что быстрее, чем ООН, нельзя предпочитать,
потому что нужно дерево хотя бы прочитать, вот,
ну и отвечать на запрос быстрее, чем за единицу тоже нельзя,
потому что надо хотя бы вывести ответ.
Поэтому это вот прям оптимум и шикарно.
Как это работает?
Ну смотрите, мы по-прежнему строим Эйлеров обход.
Да.
И замечаем, что в нем соседние вершины имеют глубины и
отличаются ровно на один.
Глубины соседей отличаются ровно на единицу, потому
что это вершины соединённых ребров, значит у них глубины
на один отличаются.
Плюс или минус один.
Так, давайте я скажу, пусть n это длина этого обхода,
пусть n это длина обхода.
Ну понятно, что если n маленькое число вершин, то n это примерно
2n.
Потому что каждый ребро мы проходим два раза сверху
внизу и снизу вверх, поэтому число печатаний будет в
два раза больше чем число ребер примерно.
Поэтому n примерно 2n.
Так вот, как у меня теперь выглядит задача.
Есть вот такой массив длины n из вот тех вот пар, глубина
запятая вершина.
И при этом глубины соседей отличаются на плюс-минус
один.
Тогда мы сделаем следующее, значит мы разобьём наш массив
на блоке длины k, где k это 1 вторая двоичная логарифма
n большой, 1 вторая лог 2n.
Чем хорошо это число?
Ну давайте скажем определение.
То есть вот я разбил на такие блоки длины k, определение,
значит блок длины k называется нормализованным, если в
нём первое число равно нулю.
Блок длины k нормализованный, если первое число в нём
равно нулю.
То есть если здесь первый элемент пара это нуль.
Значит нормализованные блоки, они в каком-то смысле
описывают вообще все возможные блоки, потому что любой блок
это вам нужно знать, какой элемент первый вот здесь,
не знаю, там х.
А также вам нужно знать список изменений плюс-минус
1.
То есть если вы знаете первый элемент и знаете там разность
между первыми двумя, скажем здесь плюс 1, дальше минус
1, минус не знаю, то есть вы знаете как отличается
каждый следующий от предыдущего, это либо плюс 1 либо минус
1.
И тогда если вы знаете ещё, если вы знаете ещё и первый
элемент, то вы знаете целиком весь блок, то есть вам нужно
знать только следующий х, первый элемент, и последовательность
плюс-минус единичек, как меняется следующий элемент
по сравнению с предыдущим.
Ну х понятно одно число, а вот эта последовательность
это по сути просто какой-то нормализованный блок.
Что если я х вычислю из всех элементов, то у меня получится
та же самая последовательность из плюс-минус 1, и она будет
равна какому-то нормализованному блоку.
Значит так вот, любой блок, после вычитания первого
элемента из всех его элементов, становится нормализованным.
Но зато нормализованных блоков, их всего два в степеника
минус 1, всего существует два в степеника минус 1 нормализованных
блоков.
Потому что мы знаем длину к, мы знаем, что первое число
это 0, а каждое следующее отличается от предыдущего
либо на плюс 1, либо на минус 1.
Поэтому, как я уже сказал, любой блок такой нормализованной
задается последовательностью из вот такого количества
плюс-минус единиц.
Значит блоков всего вот столько.
Это с точки зрения симптотики корень н большое.
Но если мы двойку возведем в степень ту самую половину
алгоритма, то у нас останется n в степени половинка, то
есть корень изо.
Окей, разных нормализованных блоков мало, а каждый нормальный
блок задается как бы номером нормализованного блока
и вот этим своим первым элементом х, который я
выщел из всех элементов, чтобы получить нормализованный
блок.
Тогда алгоритм будет следующий.
Значит сначала мы для каждого возможного вообще существующего
в природе нормализованного блока, коих вот столько,
посчитаем минимумы на всех подотресках.
Вот есть у меня такой нормализованный блок длины k, я для всех его
подотресков найду минимум на этом отрезке.
Ну это делается очень просто, ну не знаю там, тупым перебором.
У меня всего k квадрат подотресков в нем, давайте я заведу там
огромный массив, который будет все это хранить.
У меня будет массив размера корень изо небольшое на
k квадрат, то есть на лог n квадрат, на лог квадрат
n.
Да, мне нужно знать номер нормализованного блока,
как вот эта последовательность, плюс-минус один, надо знать
начало отрезка и конец отрезка lr.
Всего их будет вот столько, считается за такое же время.
Если мы заведем такого размера и для каждого l будем
просто хранить список, для каждого r минимум, то для
фиксированного l я могу насчитать список минимумов
вот здесь, вот за линейное время от длины оставшего
массива.
И соответственно весь этот массив я могу заполнить
за его размер.
То есть это время, давайте напишем, что от корни z
на лог квадрат, можем найти минимумы на всех подотресках
всех существующих нормализованных блоков.
В смысле, вообще всех нормализованных блоков.
Ну и тогда дальше, чтобы ответить на запрос исходной
массив, вот есть у меня исходный массив, разбитый
как-то на блоке длины к.
Как найти минимум на отрезке?
Вот на каком-то таком отрезке.
Мне нужно найти минимум вот здесь, ну это я могу
сделать, потому что это какой-то подотрезок нормализованного
блока, для которого я знаю ответ.
Мне нужно найти минимум вот здесь, ну это тоже знаю
потому, что это подотрезок нормализованного блока,
и найти минимум вот здесь, а это несколько подҐдиующих
блоков, на которых я построю спарстейбл. То есть первое, что мне нужно, это вот
это вот, давайте я пронумеру, что это будет пункт А. Минимумы на всех под отрезках
всех нормализованных блоков. Пункт Б это спарстейбл
на всех блоках исходного массива. На всех n поделить на k блоках
исходного массива.
Ну, где вместо блока мы записываем минимум в этом блоке. Где вместо блока
записываем минимум в этом блоке.
И тогда действительно, чтобы найти минимум на отрезке, мне нужно найти минимум на
куске нормализованного блока. Ну, то есть обычного блока. Но я знаю, как он
отличается от нормализованного. Он отличается в вычитании вот этого первого
элемента, с прибавлениями х ко всему формализованному posible. То есть я
беру номер этого блока, смотрю вот этой табличке, которой я предпочитал, минимум
на этом отрезке, добавляю к нему х. Это будет, собственно, на этом отрезке. То
же самое здесь. Я знаю, какой номер у этого нормализован clicked блока. и он
отличаться от него на y, первый элемент y. Я смотрю в этой большой таблице, чему равен
минимум на этом отрезке, проверяю y, получаю минимум здесь. Ну и наконец вот тут вот нужно
просто обратиться к sparse table для последовательности из нескольких подряд идущих блоков.
На отрезке блоков нужно найти минимум, это делается с sparse table. Причем sparse table строится
за вот такое время. nk логарифм n делить на k. Если мы вместо k поставим половину логарифма,
то получим o от n. Давайте я логарифм отношения напишу как разность логарифмов.
k это логан по порядку. Тут написано o от n минус еще что-то. Главное слагаем будет o от n.
Ну все, sparse table это строится за линию, минимум на отрезке извлекается за единицу. И на этих
маленьких кусочках тоже минимум извлекается за единицу, потому что это обращение к уже подсчитанному,
к уже подсчитанной табличке вот такого размера. Все, получается что ответный запрос за единицу.
Вопросы. Окей, тогда действительно получили предпочет за o от n, потому что вот здесь вот будет
o от n здесь будет вот это, но это понятное дело меньше чем o от n, здесь будет корень на что-то
несущественное. Это будет меньше чем o от n. Запрос за единицу. Все это есть алгоритм Фарах Колтона и Бендера.
Ну тогда спасибо, до встречи на экзамене.
