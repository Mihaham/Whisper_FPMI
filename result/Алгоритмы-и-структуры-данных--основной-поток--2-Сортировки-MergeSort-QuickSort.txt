Сегодня мы начинаем говорить про задачу сортировки.
Ну и, наверное, в ближайшие пару лекций будем изучать
всякие сортировки.
Значит, задача ставится очень простым образом.
Представьте себе, что у вас есть массив.
Пока не буду уточнять массив чего, давайте считаем, что
массив каких-то объектов.
И мы считаем, что над этими объектами определена операция
сравнения.
То есть по двум объектам мы можем однозначно сказать,
кто из них больше или меньше, или, может быть, они равны.
То есть на объектах определено отношение порядка.
Ну и наша задача как-то их так переставить, чтобы
они шли в возрастающем порядке.
Надо их переставить таким образом, чтобы они шли в формально
необувающем порядке.
Вот, да, например, если у меня есть какой-нибудь
массив.
Ну давайте чисел.
Там два, десять, семь, девять.
Ну это неинтересно, давайте здесь три еще напишу.
Да, то понятно, после сортировки мне нужно просто числа расположить
в порядке возрастания.
Будет два, три, семь, десять.
Вот, это простая формулировка задачи о сортировке, надо
просто переставить числа, чтобы они шли в порядке
возрастания.
Чуть более точная формулировка была бы в том, что нам нужно
не просто их переставить и вывести результирующий
массив, да, просто порядок возрастания, но еще и сказать
конкретно, как именно я переставил элементы, так
чтобы у меня получилась ровно такой порядок исследования
элементов.
То есть формально, давайте я напишу расширенная задача
сортировки, что ли.
Это найти конкретный способ перестановки, то есть как
именно вот эти элементы нужно так между собой переставить,
то есть формально надо указать на какое место вставит вот
эта двойка, на какое место эта десятка, на какое место
семерка, на какое место тройка.
Формально напишу следующим образом.
Нужно найти такую перестановку.
Сигма как функция из 1,2 и так далее n в 1,2 и так далее
n, что после применения этой перестановки к индексам
массива у нас получается неубывающий массив.
То есть формально a с индексом сигма от единицы не больше
чем a с индексом сигма от двойки и так далее вплоть до
a с индексом сигма от n.
То есть мне нужно не только результирующим массив в
порядке возрастания чисел вывести, в порядке возрастания
элементов, но и именно сказать, кто на каком месте стоит.
Что первый элемент, ну точнее, на первом месте стоит
элемент сигма 1, на втором месте стоит элемент сигма
2 и так далее в исходном номерации.
То есть как именно переставить элементы, чтобы получить
такой порядок.
Так, перестановка, вот это никого не пугает, нормально
все.
Ну хорошо.
Давайте начнем со следующего несложного факта, что если
мы хотим построить, ну давайте я буду решать вот эту задачу
расширенную, она не шибко интереснее, там то же самое
всегда получается, давайте решать обычную задачу сортировки
просто переупорядочения какого-то переупорядочения
элементов.
Так вот, я утверждаю, что если мы рассмотрим произвольный
алгоритм, который основан на сравнениях, то есть все,
что он умеет делать с элементами массива, это только сравнивать
их между собой.
То есть вот попарно взять два элемента, посмотреть
на них, кто из них больше-менше, в зависимости от результатов
взвешивания, в зависимости от результатов сравнения,
делать что-то дальше.
Так вот, давайте нашу любой алгоритм сортировки.
Основанный на сравнениях требует омега от n лог n сравнений
для массива длины n.
То есть в предположении, что наш алгоритм ничего
больше не умеет делать с элементами массива, кроме
как их попарно сравнивать, вот в таком предположении
нам нужно хотя бы столько сравнений.
Напоминаю, омега это оценка снизу, то есть здесь написано
там большее обравно c умножено n лог n сравнений для какого-то
положительного c.
Значит, что это за модель, почему мы можем только сравнивать
элемент?
Ну представьте, что у вас вряд ли лежат там, не знаю,
n камушков, и вы про них знаете, скажем, только их цвета,
красный, синий, желтый, зеленый и так далее, и вы знаете их
исходные номера, но вы не знаете их вес, то есть они
с виду все одинаковые по весу, но там изготовлены
из разных материалов.
Вы не знаете у кого какой вес, вы можете только их
попарно сравнивать между собой, и причем эти весы
вам не показывают веса, показывают только именно
соотношение между ними, кто тяжелее, кто легче.
Вот в такой постановке, если вы про эти ваши камушки
ничего не знаете, кроме того, что их можно сравнить
между собой, вот в такой постановке быстрее, чем
за столько сравнений, а значит быстрее, чем за столько
действий алгоритм построить не получится.
Доказательства.
Ну давайте, во-первых, считать, что в массиве, который мы
подаем на вход нашему алгоритму, все чисто попарно
различны.
Считаем, что все элементы, ну, я буду иногда оговариваться
вместо элементов говорить числа, ну, как бы, обычно
сортировка у нас будет именно на числах, я имею в виду
элементы всегда, пока что у меня сортировка каких-то
элементов.
Так вот, считаем, что все элементы массива А1 и так
далее АН попарно различны.
Рассмотрим какой-то конкретный алгоритм.
Ну, вот тот самый алгоритм сортировки, основанный на
сравнениях.
Вот, тогда я утверждаю, что протокол его работы
на массиве длины N на самом деле описывается с помощью
решающего дерева, потому что, как ведет себя алгоритм,
он сначала что-то делает, да, там, ну, не знаю, что-то
независище от массива, там, что-то предподсчитывает,
чем-то занимается сам по себе, потом в какой-то
момент он начинает попарно сравнивать вот эти элементы.
Ну, понятно, что в зависимости от N там может быть какое-то
первое действие, например, там, сравни первый камень
и второй, или там, второй и третий, ну, короче, вот
есть какое-то первое действие, которое он совершает, давайте
я здесь напишу, там, сравни АИ и АЖ, вот я операцию сравнения
буду такой галочкой обозначать, ну, есть какое-то первое
действие, потом в зависимости от ответа на него, кто из
них там тяжелее или легче, да, скажем, здесь АИТОЕ
больше, здесь АЖИТОЕ больше, он, ну, начинает делать что-то
другое, там, он сделал вот этот запрос, потом в зависимости
от результата вот этого взвешивания он, возможно, там, ну, как-то
разветвляется, в этом случае он делает тот, в другом случае
он делает тот, ну, так или иначе, в каждом, в каждой
вот точке, да, в каждом протоколе работы алгоритма, в каждом
момент времени алгоритма, он уже сделал какие-то сравнения
и вот давайте посмотрим, какое следующее сравнение
он сделает, то есть если мы знаем все сравнения, которые
он сделал до этого момента, то мы точно знаем, какое
будет сравнение сделано следующим, скажем, здесь
он сравнивает, не знаю, там, АКТ и АМТ, и опять в зависимости
от того, какой здесь значок неравенства, больше или
меньше, да, алгоритм как-то дальше себя детерминированно
ведет, то есть, зная, что здесь был такой значок, а
здесь такой, он на следующем запросе обязательно спросит
что-то следующее, то есть мы как бы знаем, какой запрос
он задает к нашим камушкам, но я считаю, что алгоритм
у меня детерминированный, и нет, пока нет случайности,
вот, тогда понятное дело, что вот весь протокол работы
на массиве длины n описывается таким вот решающим деревом,
где на каждом шаге, в каждом решении мы по факту спрашиваем
соотношение каких-то двух элементов, понятно же это,
ну просто потому что мы как бы только это и можем
при элементах спрашивать, вот каждый такой запрос,
каждый вопрос к массиву, каждый запрос в сравнении
двух элементов давайте отразим в виде вершины, да, и соответственно
каждая вершина раздваивается там, что происходит в обоих
случаях, вот, и поскольку я изначально предположу,
что все элементы различные, то у меня никогда не бывает
случая равенства, то есть всегда либо больше, либо
меньше, вот, значит, вот есть такое дерево, у каждой
вершины в нем два сына, да, если вершина происходит
в вершине, то там есть два сына влево-вправо.
Вот, давайте рассмотрим вершину, у которой нет сыновей.
Что это значит?
Значит, алгоритм как-то дошел до вот этого состояния,
задал какие-то вопросы нашему массиву, он что-то узнал
про массив, а дальше никаких запросов не задает, да,
то есть если из этой вершины нет уже стрелочек, значит,
больше нет запросов в ней, то есть мы до сих дошли, больше
никаких запросов не задаем.
Это должно означать, что поскольку у меня корректный
алгоритм сортировки, я же предположу, что А это алгоритм сортировки. Значит вот
здесь вот мы уже точно знаем, как нужно правильно переставить элементы.
Вот мы задали какие-то вопросы, там их возможно было много, но если в этой
вершине больше никаких запросов не задается, значит мы точно знаем, в каком
порядке нужно переставить эти элементы, так чтобы они шли в порядке возрастания.
Вот. Но при этом, понятное дело, что если вы будете в качестве элементов вот сюда
передавать все возможные перестановки каких-то n элементов, то есть вот у вас
есть какие-то n элементов по паре различные, если вы их сюда будете всякими
различными способами передавать, например там 1, 2, 3, 1, 3, 2, все возможные
перестановки n элементов. Вот если все такие передать, так, то алгоритм должен
как бы все их корректно обработать и сказать, как именно нужно переставить
элементы, чтобы они шли в порядке возрастания. Вот. Поэтому на самом деле каждый
вот этот вот лист, каждый вершина, из которой больше нет ветвления, обязательно
соответствует какой-то перестановке, как именно нужно переставить элементы. И
причем, понятное дело, что все вот эти вот n, точнее все вот эти вот возможные
входные массивы, которых на самом деле ровно n факториал по числу перестановок
n элементов, все эти n факториал массивов должны закончиться в попарно-различных
листьях. Ну, потому что каждый лист на самом деле говорит, что нужно сделать с
массивом, чтобы он шел в порядке возрастания. Поэтому не могут два
различных вот таких вот массива прийти в один и тот же лист, потому что тогда
они бы, тогда бы их нужно было одинаково переставить, чтобы получиться
ассортированную перестановку. А такого быть не может, да, потому что они все
различны. Нельзя к двум разным перестановкам применить одно и то же, чтобы
получить возрастающую перестановку. Вот. Значит, давайте что-нибудь из этого
запишем. Лист в решающем дереве, вот в этом решающем дереве отвечает
случаю, когда алгоритм понял, ну давайте напишу так, нашел сигма, нашел сигма. То
есть он понял вот в этих серверах, как именно нужно переставить элементы, чтобы
они шли в порядке возрастания. Дальше различные перестановки, различные
перестановки исходного массива должны, должны завершаться в попарно-различных
листьях, в различных листьях дерева.
Ну, потому что еще раз, лист это в каком порядке нужно переставить входные
элементы, чтобы они шли в порядке возрастания? Не может быть такое, что две
разные входные перестановки надо переставить одинаковым образом, то есть
они могут дойти до одного листа, потому что переставив их одинаковым образом,
мы не можем получить в обоих случаях возрастающую перестановку. Только
одна из них может, потому что если мы к одной перестановке
применили другую и получили возрастающую, то вторая
не может получиться такой же.
Написываем, когда алгоритм нашел сигму.
Да, когда алгоритм нашел сигму.
Ну вот в этом плане.
То есть он понял, как их надо переставить.
Это значит, что листьев в дереве, по крайней мере
сколько?
Ну n факториал все-таки.
Тут я сказал, что различные перестановки входного
массива соответствуют различным листьям.
Значит листьев хотя бы столько, сколько перестановок.
А перестановок в точности n факториал.
Так, от никого не пугают, все знают, что такое факториал.
Хорошо.
Получается, что протокол работы нашего алгоритма
на массивах длины n, это вот такое большое бинарное
дерево, то есть дерево, у которого у каждой вершинки
два сына, кроме листьев, в котором листьев hn факториал.
Ну и тогда утверждаю, что глубина этого дерева, по
крайней мере, вот такая.
Чтобы в бинарном дереве было хотя бы столько листьев,
нужно, чтобы его глубина была хотя бы вот такой.
Значит, осталось доказать, что если в бинарном дереве,
бинарное, это именно такое, что у каждой вершины либо
два сына, либо она листовая и дальше никуда не идет.
Вот такое дерево, что в таком дереве, что если в таком
дереве хотя бы n факториал листьев, то его глубина
это омегатенлоган.
Ну, если мы это докажем, то значит, что на входных
массивах длины n, вот это вот дерево, по крайней мере,
на одном из своих путей, имеет глубину омегатенлоган,
ну там, c умножено нлоган, ну значит, вот в этой ветке
алгоритма, ему нужно хотя бы нлоган сравнений с
точностью домножения на константу.
Поэтому мы докажем то, что хотим.
Почему, если в бинарном дереве n факториал листьев,
то глубина хотя бы омегатенлоган?
Потому что, если в бинарном дереве н факториал листьев,
то глубина хотя бы омегатенлоган.
Ну, давайте такую картинку просто нарисуем.
Вот, я утверждаю, что если глубина дерева у меня будет
k, то листьев в нем будет не больше, чем 2 вкатый.
А если вот эта вот глубина, тогда листьев не больше
2 в степень k.
Ну, потому что вот если есть какая-то вершинка,
на глубине меньше, чем k, ей выгодно сначала раздвоиться,
потому что она таким образом породит больше листьев.
Значит, мне нужно построить такое полно бинарное дерево
сверху вниз, то есть каждая вершина раздваивается,
раздваивается, вплоть до катого уровня.
Ну и тогда понятно, что здесь листьев в точности 2 в степень
k, ну да, значит, их максимальное количество не больше,
чем 2 в степень k.
Листьев не больше, чем 2 в степень k.
Вот, то есть если у дерева глубина k, то листьев в нем
не больше, чем 2 в степень k.
А мне нужно, наоборот, мне нужно листьев хотя бы
n-факториал.
Значит, чтобы листьев было хотя бы n-факториал,
глубина должна быть хотя бы...
Ну, видимо, двоичный алгорифм, да, то есть как получается
вот отсюда вот это, надо взять двоичный алгорифм.
Если у меня фиксировано число листьев, то глубина считается
как двоичный алгорифм от этого количества.
Поэтому глубина должна быть хотя бы двоичный алгорифм
от n-факториала.
Окей?
Вот, значит, осталось понять, как асимпатически себя
ведет алгорифм от n-факториала.
Вот, если мы докажем, что это омега от n-луген, то мы
победили.
Вот это должно быть d.b.
Так, то есть, смотрите, мы свели задачу к следующему.
Мне нужно доказать, что вот эта вот штука, да, алгорифм
от n-факториала, ведет себя как омега от n-луген.
Но давайте даже более сильное утверждение докажем.
Давайте покажем, что алгорифм от n-факториала есть даже
тетта от n-луген.
То есть, это не только оценка снизу, но и сверху.
Вот.
Можно, но давайте руками.
Давайте считать, что мы еще первокурсники и не знаем
формулу стирлинга.
Давайте докажем это совсем элементарными средствами.
Значит, смотрите, что такое n-факториал?
N-факториал это пред REALLY всех чисел от 1 до n.
Вот.
Я могу написать, что алгорифма от n-факториала
это алгорифм произведения, значит сумма алгорифмов
лог единицы, плюс лог двойки, плюс так далее, плюс лог n.
Потому что алгорифм произведения – сумма алгорифмов.
Вот.
Дальше я могу на самом деле каждый логарифм сверху оценить логарифмом n.
Потому что логарифм — это возрастающая функция, какое бы я там адекватное основание не взял.
Здесь подразумевается двоичный логарифм, но я не пишу, основание какое-то.
Мы помним, что основание алгорифма на самом деле нешибко важно,
потому что в терминах вот там омеги и тетты все равно все основания съедаются,
константы нам не важны.
Я могу все алгорифмы оценить по отдельности логарифмом n,
ну и таких n слагаемых, поэтому это все не больше, чем n лог n.
Мы тем самым доказали, что логарифм n факториала — это от n лог n.
Согласны?
Чудесно.
Теперь снизу оценочка.
Давайте.
Нет, я доказал, что log n факториал — это от n лог n.
Пока сейчас я только это доказал.
Еще раз?
Вот утверждение. Я хочу доказать, что тетта.
Помним, что чтобы доказать тетту, мне нужно доказать и о, и омегу одновременно.
Я пока доказал только о.
Сейчас буду омегу.
Вторая часть. Я хочу доказать омегу.
Для этого я напишу следующее.
Опять я напишу, что лог n факториал — это сумма логарифмов.
И здесь я оставлю только большие слагаемые.
Короче, оставлю вторую половину слагаемых.
От n пополам до лог n.
Тут я неявно предполагаю, что n четное.
Если n нечетное, там ничего интересного не будет.
Короче, тоже сам будет работать.
Качественно я оставляю вторую половину слагаемых.
Теперь я их все оцениваю снизу, наоборот, минимальным из них.
Я говорю, что все эти логарифмы больше либо равны, чем минимальные из этих логарифмов.
Их, видимо, здесь будет ровно n пополам.
Согласны?
Я оставил большую половину логарифмов.
Каждый из них оценил меньшим из них.
Ну и здесь n пополам с слагаемых.
Потому что n пополам плюс одно, ну бог с ним.
Больше оно, чем n пополам.
Им более-менее уже победили.
Надо только расписать свой логарифм n пополам.
Это лог n минус лог 2.
Это минус один.
Ну да, это минус один, если у меня основная логарифма двоечка.
Но на самом деле я даже не буду над этим думать.
Потому что что здесь написано?
Здесь написано 1 вторая n лог n минус 1 вторая n лог 2.
Ну понятно, что это доминирует над этим.
Потому что это с точностью константы мультипликативная.
Это n лог n, а это n.
Если позанутствовать, можно формально доказать, что это
больше либо у нас, скажем, чем 1 четверть n лог n.
Ну там, либо вообще всегда, либо для n, начиная с 20, например.
Число 20 из головы взялось, давайте 100.
Короче, я уже знаю, что вот это всегда работает.
Если это хочется доказать, как доказать такое неравенство?
Но на самом деле здесь написано, что
если это туда перенести, что 1 четверть n лог n больше
чем 1 вторая n лог 2.
Что-нибудь сократили, на n поделили, останется...
То есть вот эта неравенство на самом деле равносильна такому.
1 четверть лог n больше 1 вторая лог 2.
Правду пишу?
Перенес сюда, перенес туда, поделил на n.
Ясен пень, здесь растущая функция, здесь константы.
Понятно, что все х, начиная с какого-то, это верно.
Там 100 с запасом хватит.
Можно вопрос?
Да.
Можете, пожалуйста, объяснить?
Покажите, помню еще раз.
Совсем понятно?
Еще раз, вот это или почему мы вообще это доказываем?
Нет, вот это.
Вот это, хорошо.
Вот это понятна строчка?
Первая?
Ну, разложение...
Вторая понятна?
Нет.
Смотрите, у меня здесь n слагаемых.
Все не отрицательные.
Давайте оставим только последние n пополам из них.
Да, я оставляю последние n пополам в слагаемых.
Потому что здесь все слагаемые не отрицательные.
a плюс b больше 0, чем b, если a не отрицательная.
Если я выбрасываю не отрицательные слагаемые из суммы,
у меня сумма только уменьшается, конечно.
Открытие, да?
Вроде не очень сложный факт.
Я ровно его применил.
Еще раз, у меня здесь много слагаемых,
я просто несколько первых выкину.
Сумма только уменьшится могла.
Отлично.
Дальше у меня есть куча логарифмов.
Логарифм растущая функция.
Чем больше аргументов, тем больше логарифм.
Поэтому я все эти логарифмы оцениваю снизу наименьшим из них.
Вот это больше, чем лог n пополам.
Вот это и так далее.
Да, да, да.
Тут, может быть, надо было написать n пополам плюс один.
А, вот здесь n пополам плюс один, да.
Я их все оцениваю вот этим,
и их n пополам.
Поэтому вот такая оценка.
А дальше уже какая-то арифметика.
Вот.
Мы вроде все доказали.
Сейчас мы показали, что log n факториал больше собрав
чем как раз n лог n с точностью до мультипликливной константы,
с точностью до умножения на какую-то константу.
Вот.
Итого, мы показали, что log n факториал
это ω от n лог n,
а раньше мы доказали, что это o от n лог n,
то есть мы доказали утверждение.
Но раз мы доказали утверждение,
то мы доказали предыдущую теорию,
потому что мы свели ее к такому вот утверждению.
Вот здесь равно.
Ну, значит, если есть значок,
то там равно подразумевается всегда.
Вот здесь?
Ну, смотрите, вот у меня есть одна автора n лог n,
из которой я что-то вычитаю.
Это, в принципе, что-то не очень большое
по сравнению вот с этим,
но как бы тем не менее растущее.
Мне нужно оценить вот это вот
n лог n умножить на какую-то константу.
Ну, я бы здесь, на самом деле, мог написать
любую константу меньше 1 второй.
Например, 1 четвертую.
То есть главное, что...
Откуда взялось?
Ну, типа, если это есть, то мы доказали.
Откуда взялось, чтобы это было верно, и все.
Это как в Мотоне, там откуда берется epsilon
равно 7 в 16 на дельт в четвертой.
Ну вот, типа, с ним сходится.
Здесь то же самое.
Ну и не надо тогда.
Понятно все?
Ну вот, вроде все доказали тогда.
То есть, смотрите, получается,
что если алгоритмы над элементами
могут произвести только сравнение,
то надеяться на что-то лучшее,
чем n лог n, с точки зрения симптотики,
нельзя.
Это уже очень интересный результат.
На самом деле, один из очень немногих
во всей его теории алгоритмов,
одна из очень немногих нижних оценок.
Потому что дальше все, что мы будем делать,
кажется, там,
до конца третьего семестра,
это доказывает только какие-то верхние оценки
на алгоритмы. То есть мы будем говорить,
ага, вот такая задача, вот такой алгоритм
ее решает за отом от n квадрата
или за от n лог n.
А то, что не бывает алгоритма с меньшей
симптотикой, это зачастую
сильно сложнее доказывается.
Ну там, кроме тривиальных случаев,
что нельзя обработать массив длины n быстрее,
чем за у от n.
Но это как бы очевидно, не содержательно.
А вот здесь что-то минимально содержательное,
и более-менее ничего такого даже не будет.
Ну теперь, доказав такую нижнюю оценку,
давайте рассмотрим несколько конкретных алгоритмов,
на которых эта оценка достигается,
которые реально сортируют
массив за время n лог n.
Так, давайте начнем сортировку с слиянием.
По-английски это mergesort.
Алгоритм работает следующим образом.
Он использует в качестве подпроцедуры,
в качестве вспомогательной функции,
следующая.
Представьте себе, что у вас есть два
отсортированных массива.
Давайте я их назову a0 меньше
либо равно a1 меньше,
ну и так далее,
там, вплоть до a n-1.
И второй отсортированный массив,
b0, b1,
и так далее, b n-1.
Наша задача их слить
в один большой отсортированный.
Это будет называться процедура merges,
и она состоит в следующем.
Вот представьте, у вас есть два набора чисел,
ашки и бэшки.
Причем ашки упорядочены и бэшки упорядочены.
Вам их нужно так слить всех вместе,
чтобы вот здесь, вот каждый из этих чисел
сейчас ровно по одному разу,
и они опять-таки шли в порядке возрастания.
Например, если у вас есть
какой-нибудь массив там, не знаю,
1,2,5
и там 1,3,7,
то после слияния,
ну понятно, сортировка будет...
Просто мне их нужно расположить опять-таки
в порядке возрастания,
но уже теперь все вместе,
и a и b как-то они там между собой перемешаются.
Да, мне нужно два отсортированных массива слить в один отсортированный.
Вот ровно таким образом.
Значит, как это делать?
Вообще, это на самом деле очень простая процедура.
Простой алгоритм.
Вот есть у вас два отсортированных массива,
как их слить в один отсортированный?
Давайте сделаем следующее.
Давайте мы введем
по указателю
на оба наши массива, вот здесь вот a и b.
И будем просто слева-направо идти
по обоим массивам,
и каждый раз выписывать минимальные из двух чисел
и двигать соответствующий указатель.
Вот на примере этого массива.
Изначально мы смотрим на единицу-иденицу.
Выписываем наименьшую из них,
ну если они не одинаковые, то выписываем любую из них.
Взяли в эту, например, единицу, записали
и её, сдвинули стрелку сюда.
Опять, есть единица, и двойка.
Кто из них меньше?
Ну понятно дело, единица. Взяли ее, записали,
сдвинули стрелку направо.
Сравниваем, двойку, тройку, кто из них меньше?
Понятное дело, двойка, записали, сдвинули стрелку.
Сравнили, записали, сдвинули стрелку.
Сравнили, записали, сдвинули стрелку.
Да, здесь массив кончился,
ну и остается здесь
элементы дописать, и массив тоже кончится. Вот такой простой алгоритм. То есть на самом деле,
что я по факту делаю? Я иду вот по этому массиву, и каждый раз выписываю минимальный из оставшихся
элементов. Ну понятно, что изначально минимум это один из них, потому что это минимум своего
массива, это минимум своего массива. Я его записал сюда. Понятно дело, что на первом месте либо это,
либо это. Потом кто на втором месте? Ну понятно, минимум из оставшихся. На третьем месте минимум из
оставшихся и так далее. То есть по факту просто с помощью двух этих указателей я поддерживаю,
какие куски массивов я уже выписал, ну и из оставшихся элементов я выбираю самый маленький,
записываю ответ. Вот. Ну давайте какой-нибудь псевдокод здесь напишем. Ну вот представьте,
что мне нужна процедура Merge, которая берет массив A, массив B и массив C и пытается два
массива A и B слить в один большой массив C. Как он будет работать? Сейчас, сейчас, секунду. Что говорите?
Мы вводим эти два указателя, здесь будет и здесь будет g. Ну и дальше, давайте сюда перейду,
значит дальше пока i меньше n или g меньше m, то есть пока у меня хотя бы один из двух массивов не
исчерпался. Давайте напишем условия, когда нужно написать i. Нет, нет, не i. Пока хотя бы один из
двух массивов не кончился, да, то есть пока есть что записывать. Нет, не обязательно. Вот я хочу
так, чтобы потом не дописывать еще кучу строчек, я хочу так написать. Вот еще раз, вот пусть хотя
бы один из них не закончился. Каково условие на то, что мне нужно сейчас написать ai в ответ?
Да, ai меньше либо равно чем bg, либо g кончился, либо b кончился, то есть если g равно m или
i меньше n и ai меньше либо равно bg. Это будут корректные условия на то, что нужно сейчас
выписать ai. Что? Не обязательно. Может быть, что вот это меньше, а это равно. Вот этот значок
означает или, то есть либо это, либо это верно, возможно и то и то, но может быть только одно из
них. Вот, значит, когда мне нужно писать ai? Либо в случае, когда второй массив кончился, то есть
я уже все b выписал, но тогда, понятное дело, здесь g равно m, но i тогда точно меньше, чем n,
и можно просто его написать, да, ai-то. Ну, потому что, потому что иначе вот это вот это нельзя
сделать, да, потому что если у вас g меньше, чем m, а i, например, кончился, а первый массив кончился,
тогда вы не имеете права даже так сравнить, потому что эту массиву нет, просто банально. А только,
если у вас и меньше n, только в этом случае вы имеете право сделать сравнение, если оно верно,
тогда его нужно дописать. Вот. Ну и все, в этом случае. Давайте тогда напишем, что c и плюс gt
это ai. Вот. Значит, и увеличу на единичку. Мы, собственно, разобрали случай, когда нужно
писать ai, понятное дело, что он всегда записывается в клетку и плюжи. Всегда все, что мы записываем,
идет в клетку и плюжи, потому что это в точности число уже обработанных чисел, да, число,
количество чисел, которое мы уже выписали. Вот. Ну и иначе нужно, видимо, сделать c и плюс gt равно
bgt, плюс плюжи. Конец. Так. Вот. Действительно, поддерживаю два указателя, здесь и здесь.
Проверяю, могу ли я сейчас, в очередной элемент массива c, могу ли записать ai. Могу ровно в этом
случае. Либо когда второй массив кончился, либо первый еще не кончился, и там число реально меньше,
чем в b. В этом случае я могу его записать и сразу сдвигаю указатель на следующий. Плюс плюс и,
значит, увеличение i на единичку. Иначе мне придется написать bg и сдвинуть второй указатель g на
единичку. Все. После этого while у меня в массиве c лежит склеенная вот эта вот объединенная версия
массива i и b. Понятно? Супер. Ну давайте на всякий случай отмечу, что это работает за, собственно,
сумму длин массивов. Если у меня был массив длины n и массив длины m, то это просто алгоритм,
работающий за линейное время, да, от суммы их длин. Потому что я по первому массиву пробегаю
слева направо, по второму массиву пробегаю слева направо. Понятно вроде, что время работа линейная
здесь. Можно, да, в этом случае можно, потому что мы, ну, по крайней мере, по одному разу все
элементы пробежим, поэтому можно было бы поставить тетту, да, можно. Но я не буду, потому что как бы
мы уже на самом деле доказали все про нижние границы, мы сейчас будем только сверху оценивать. Мы уже
знаем, что быстрее, чем за n log n нельзя. Вот. И сейчас я буду всегда всегда все только сверху оценивать.
Даже вот этот простой, простой алгоритм merge. Нет, в этом случае, смотрите, если я, если я перешел в, то
есть смотрите, у меня либо вот это выполнилось, оператор вот этот палка-палка работает так, что
если это выполнилось, то вот это второе слово даже не рассматривается. То есть если g равно m,
я сразу перехожу сюда. Сюда я смотрю только в случае, если первый аргумент не верен. Значит,
здесь у меня g меньше, чем m, но еще потенциально может быть и равно n. В этом случае вот это нельзя
так сразу проверять, потому что а n не определено. Окей? Хорошо. Так, ну merge вроде написали. Теперь
остался, собственно, merge sort. Как он работает? Смотрите, вот есть у вас массив длины n, а 0,
а 1 и так далее, а n-1. Давайте я его рекурсивно разобью на две половинки, ну, точнее, просто
сначала разобью на две половинки. Первые n пополам элементов и вторые n пополам элементов. Дальше,
с помощью рекурсивного вызова, то есть с помощью вызова того же самого алгоритма, я посортирую эти
две половинки. То есть я вызову merge sort для левой половинки и merge sort для правой половинки. В
результате у меня окажется так, что вот эти оба массива будут отсортированными. Вот. Ну а
дальше нужно их просто будет слить. Давайте их как-нибудь назову. Давайте кратко опишем,
что merge sort от a работает так. Он сначала выделяет левую правую половину, потом вызывает merge sort
от l, merge sort от r. Ну и дальше он видимо просто делает merge. Вот эти два массива склеивает на
место исходного массива a. Вот что такое. Единственное, здесь нужно еще добавить условия выхода из рекурсии.
Скажем, что если массив состоит из одного элемента, то сортировать нечего. То return просто. Ну
потому что если мы дошли, если мы вот в этом нашем спуске дошли до массива длины 1, их даже не
нужно сортировать, они так уже отсортированы. Дальше спускаться некуда. Вот. То есть картинка будет
примерно какая-то такая. Есть у вас изначально весь ваш большой массив, вы его разбили на два
куска левой и правой, на две равные половинки. Дальше вы рекурсивно их сортируете. Что такое
рекурсивная сортировка? Это применить ту же самую идею к обеим половинкам. Вот скажем, вы запустились
слева, давайте сортировать эту штуку. Что такое сортировка? Вы бьете ее пополам, разбиваете на две
половины, левую и правую, и опять рекурсивно их сортируете. Что это такое? Давайте здесь посмотрим.
Вы его разбиваете на два куска, регурсивно сортируете. Ну и так далее. Потом рано или поздно
вот здесь будет лежать отсортированные версии соответствующих массивов. И дальше вы их с
помощью мерджа просто склеиваете в один большой отсортированный. То есть вы сначала массив разбили
на два куска, отсортировали по кускам, а дальше взяли и склеили обратно в один кусок большой.
То есть два отсортированных массива склеили в один большой отсортированный. То же самое здесь.
Сначала отсортировали это, это уже отсортировано. Берете их с помощью мерш и опять склеиваете в
один большой отсортированный. Если это отсортировано и это отсортировано, то просто с помощью мерш склеиваете
два куска в один большой отсортированный. Конец. Понятно? Так, ну хорошо. Осталось, наверное,
оценить только время работы. Я утверждаю, что если за t от n обозначить время работы на массиве
длины n, то рекурьента у нас получается следующая. Так, давай чуть ниже. Чуть не помещается сюда.
Еще раз. Значит, t от n это время работы на массиве длины n. Тогда утверждаю, что t от n это
удвоенная t от n пополам плюс линейная добавка o от n. Ну, собственно, вот здесь все написано.
Я сначала массив длины n разбил на два массива длины n пополам. Рекурсивно в них вызвал тот же
самый алгоритм, то есть с точки зрения времени работы сделал два раза t от n пополам. И потом
еще за линейное время, то есть за o от n, склеил два отсортированных массива в один большой
отсортированный. Поэтому время работы подчиняется вот такой рекурренте. Да? Но опять, я здесь пропускаю
всякие тонкости про то, что если n нечетное, что происходит, потому что если n нечетное,
тогда у вас эти два куска имеют на самом деле разные длины. Там типа n пополам округлись вниз
и вверх. Но это все всегда несущественно, потому что мы можем, давайте скажем в самом начале,
что n равно степени двойки. Если n равно степени двойки, тогда все вот эти деления всегда происходили
целочисленно и всегда все половинки были одинаковые. То есть вот эти по длине всегда одинаковые,
вот эти по длине одинаковые и так далее. Ну и тогда, если мы решим эту рекурренту для степеней
двоек и получим n лог n, то понятно, что на всех остальных n-ках у меня тоже получается порядка n
лог n. Потому что каждое n можно, если что, сначала увеличить, добить до ближайшей сверху степени
двойки. Если на степени двойки у меня будет n лог n, то значит на этом n время работы не сильно
испортится. То есть если что, я могу массив добить каким-нибудь мусором до степени двойки,
потом ассортировать и мусор отбросить. Но время работы от этого, видимо, не сильно вырастет,
потому что если у меня здесь получатся рекурренты n лог n, то и время работы там вырастет не сильно.
По факту я просто n превращаю в 2 вкатый, беру от этого n лог n отсюда, это будет, видимо,
2 вкатые на k, тогда время работы здесь, не больше, чем время работы здесь. Если здесь n лог n,
то здесь тоже будет n лог n примерно. Это все детали, в которые мы никогда не влезаем, на самом деле,
потому что они существенные. Вот если t от n — это время работы мерч сорта на массиве длины n,
то оно удовлетворяет такому правенству. Время работы на массиве длины n — это два раза нужно
отсортировать массивы длины n пополам. Вот два вызова. Плюс еще потом какая-то линейная добавка,
потому что мне нужно два отсортированных массива склеить. Мы сейчас докажем, что это n лог n. Нам
осталось доказать. Докажем, что в таком случае t от n равно от n лог n. Ну да,
можно, например, сразу воспользоваться мастер-тиоремой, которая, по идее, должна была быть у всех на семинарах.
Ну вас обманули нагло. Ну мастер-тиорема, ее нет смысла выносить на лекции, потому что там куча
условий. Мы будем пользоваться только один раз ей вот в этом случае. Поэтому давайте докажем
опять это руками. Значит, почему в таком случае t от n — это от n лог n? Ну что мне нужно доказать?
То есть по факту вот это утверждение означает, что существует какая-то константа C, что t от n не
больше, чем C на n лог n. Вот нам надо ее как бы предъявить. Нам надо найти такое C, что t от n не
больше, чем C на n лог n. Давайте сначала вот то условие перепишем. Плюс у меня там написано o от n,
но мы знаем, что такое o от n. Это не больше, чем Cn для какого-то C. Поэтому здесь я напишу в явном
виде, вместо o от n, я напишу Cn для вот того самого C, которое скрыто в константе o от n. Вот так
константа, которая скрыта в определении o большого. То есть у нас есть вот это. Есть потому,
что o от n — это C, а Cn — для какого-то C. Значит, нужно найти такое, скажем, d. Нужно найти такое d,
что t от n не больше dn лог n. Вот. Если мы такое найдем, то мы победили. Мы в точности доказали то,
что нужно, потому что вот как раз мультипликативная константа d здесь вылезла, которая в терминах у большого
съедается. Вот. Как бы такое d найти? Ну, смотрите, пусть там это верно для всех меньших n. Давайте
попробуем индукцию бахнуть. Значит, пусть это верно для t от n пополам. Тогда t от n не больше,
чем 2 от n пополам, каждый из которых оценится сверху вот такой штукой. То есть здесь будет
удвоенное d, n пополам, лог n пополам. Я считаю, что такое d у меня откуда-то взялось. Дальше я хочу
бахнуть индукцию. То есть я хочу, предположив, что вот для этого n пополам верно такое соотношение,
то есть что t от n пополам не больше, чем d, n пополам, лог n пополам. Вот то, что здесь написано. Я хочу
доказать, это же не равенство для n. То, что, собственно, верно вот это. Ну, давайте это попытаемся
доказать. Что? Сейчас, еще раз. Я считаю, что для этого верно. Ну, а дальше просто применяю. То есть я
считаю, что для t от n пополам верна вот такая соответствующая оценка. d, n пополам, лог n
пополам. А дальше просто использую вот это неравенство. Я пока нигде не обманываю. То есть я считаю,
что если вот это вот верно, то тогда это верно, потому что мы это знаем и так. Вот. Ну, здесь надо
немножко повозиться, чтобы понять, какое нужно d выбрать, так чтобы это все сошлось. Что здесь будет?
Значит, давайте это сократим. Лог n пополам опять распишем как лог n минус лог 2. Ну, и cn остается
само по себе. Нет, я вот это просто переписал. Я вот это переписал, используя знания. Ну, я сейчас
немножко ищу на самом деле. Мне нужно найти такое d, а я считаю, что я его уже нашел и его использую.
Хорошо, да. Давайте доведу, потом еще раз объясню, почему все это работает. Так вот, смотрите. Я
сейчас написал, что t от n не больше чем dn лог n. Собственно, то, что мне нужно. Вот оно dn лог n.
Минус dn лог 2 плюс cn. Ну, давайте здесь уже придется специфицировать, какой именно логарифм.
Давайте считаем, что здесь двоичный логарифм стоит, а здесь везде двоичный. Ну, тогда это просто
единица. И чтобы победить, чтобы вот это было не больше, чем dn лог 2n, мне достаточно, чтобы вот
это вот было неположительным. Значит, мне достаточно, чтобы d было больше равно, чем c.
Еще раз давайте помедленнее. Вот пусть это верно. Пусть верно, что d больше равно, чем c. Тогда что
вот здесь написано? Здесь написано cn, а здесь написано минус dn. Ну, потому что двоичный лог
грифм двойки это единица. То есть я на самом деле могу это просто скрыть. Но понятное дело, что cn
минус dn при таком условии меньше либо равно нуля. Поэтому вот эта вот вся штука после прибавления
чего-то неположительного останется меньше равно, чем dn лог n. Вот. Итого. Смотрите. То есть я
сейчас показал, откуда мы могли бы взять нужное d. Теперь, чтобы завершить доказательство,
я могу написать следующее. Давайте считаем, что просто d равно c. Давайте его таким определим.
Пока что я d никак не задавал. Я знаю, что такое c. c это константа из вот того большого,
которая нам и так дана. Я хочу найти такое d, чтобы выполнялась вот это. Я хочу сам ее предъявить.
Вот предъявляю. d равно c. Теперь я утверждаю, что с таким d все сойдется. Доказываю по индукции. Ну,
база как-нибудь там, наверно, сама собой разумеется, потому что если я поставляю n равно,
там, ну, двойке, да, для единицы, наверное, не работает. Если n равно двойке, то понятно,
что t от двойки не больше, чем c на два на один. Ну, потому что на самом деле можно считать,
что t от двойки это просто единица. Вот. Так. Ну, окей, давайте отдельно еще вопрос про базу. Я
вот вынесу это. Это тоже всегда надо проговаривать. Давайте считать, что база у меня откуда-то есть.
Дальше как делать переход? Ну, вот он на самом деле расписан. Я предполагаю, что верно условие для
n пополамо. То есть вот это вот неравенство просто верно, если поставить вместо n пополам. Ну, а дальше
используя вот это вот неравенство, которое у меня уже известно, я могу доказать, что t от n не
больше, чем dea n log n. То есть просто индукция. Зная условия для меньшего n, я получаю условия для
большего n. Вот. Значит, единственное тонкое место здесь — это база. Почему можно считать, что для
маленьких n это неравенство выполняется? То есть как бы, ну, вот я так делю, делю пополам, а вплоть
до каких-то маленьких значений n. Почему можно считать, что это выполняется для маленьких значений n?
Ну, вот здесь опять те же самые рассуждения про то, что вообще считается элементарной операцией.
Потому что можно, говоря, сказать, что t от 2 — это, например, 1. Будьте здоровы. Потому что такое
t от 2 — это сортировка массива из двух элементов. Ну, понятно, что это занимает какую-то константу
действий. Может быть 100, может быть 200, может быть 5. Ну, там это что-то простое. По факту у вас есть
два элемента. Они сами по себе уже как половинки уже отсортированы. Вам надо их просто, возможно,
переставить, если там один меньше другого. Вот. С точки зрения, как бы, то есть несколько элементарных
операций. Константное количество элементарных операций. Поэтому можно считать, что t от 2 просто
единица. Потому что, ну, вот опять мы не специфицируем, что именно такая элементарная операция,
а любое константное их количество можно считать, что это просто одна простая операция. Вот. Поэтому
вот это вот нас ничем не стесняет. Ну и, понятное дело, что если сюда поставить двойку, то t от
2 равный единиц и будет не больше, чем d на n log n.
Но вот это как раз не проблема. Потому что понятно, что вот здесь вот вы можете c спокойно
увеличивать. Потому что если эта штука работает за там n на c, то она работает не больше, чем n
умножить на c плюс 2, например. Или там c плюс 100. То есть от того, что вы вот здесь увеличиваете
константу по большому, вы точно не проигрываете. Вот. Ну и, соответственно, там тоже это можно сделать.
Да, вопрос еще какой-то был. Ну да, да, тоже верно. То есть с базой можно было бы еще по-другому
разобраться, что вот я сказал, что мне достаточно вот этого для перехода индукции. Давайте еще
выберем d достаточно большим, чтобы это было верно для всех достаточно маленьких n, чтобы база
работала. Можно было бы сделать и так, действительно, да. Тут всегда можно и так, и так. Так, еще есть
вопросы? Хорошо. Ну что, мы тогда вроде доказали, что хотели. Мы доказали, что этот алгоритм работает
от n лог n. Вот. Причем, поскольку он, очевидно, основан на сравнениях, он работает, как мы недавно
доказали, за ω от n лог n. Ну, значит, суммарно он работает за θ от n лог n. То есть ни меньше,
ни больше. Ровно за такую симпатику. Да, но он основан на сравнениях. Видно, да, что элементы
между собой мы можем только сравнивать. Все, что мы делаем между элементами, это только там их
перестановки между собой какие-то и сравнение между собой двух элементов. Значит, он основан на
сравнениях. Значит, она работает хотя бы ω от n лог n. Но при этом не больше, чем от n лог n. Значит,
суммарно будет в точности n лог n. Так, согласны? Хорошо. Еще раз? Ну, про merge sort, да, вот мы сейчас его
конкретно рассматриваем. Мы знаем, что все основанные сравнениях работают за ω от n лог n,
поэтому он в частности. Вот этот в частности. Ну, и он еще и о от n лог n, поэтому ω. Вот этот? Ну,
еще раз, смотрите. Давайте я сотру вот здесь лог 2, потому что лог 2 по основанию 2 это 1. Вот.
Дальше написано cn минус dn. Если d равно c, то это просто 0. Все. Остается dn лог n, да.
Так, дальше можно? Хорошо. Давайте тогда решим такую задачку. Значит, опять пусть есть массив какой-то.
Массив чисел. Значит, инверсия в нем называется такая пара индексов i и j, что i меньше,
чем j, а a и t больше, чем aj. Вот. То есть два элемента такие, что один расположен левее,
но при этом больше. Это как бы препятствие к тому, что он отсортирован, то есть что слева стоит
большее число, а в отсортированном должно было бы быть наоборот. А вот такую пару мы назовем
инверсией, если одновременно i меньше, чем j, но а и больше, чем aj. Так вот задача найти число инверсий.
Найти число инверсий в массиве. Так, есть ли идеи, как решать?
Посчитать, сколько раз будет перестановка. Сколько раз будет перестановка. Ну да, да, да.
Все правильно предлагается. Значит, смотрите, давайте реализуем опять мёртвый сорт и посмотрим,
что в нем происходит. Вот был массив длины n, я его делю пополам. Давайте мы сначала посчитаем инверсии,
которые целиком лежат в одной из половинок. Вот здесь или здесь. Это давайте пусть делается
просто рекурсивными запусками в обеих половинках. То есть я сначала, ну по факту,
опять запущу рекурсивную какую-то процедуру, которая находит число инверсий строго в левой
половине, вот здесь, и строго в правой половине, вот здесь. Ну и ещё заодно по сортируют обе эти
части. Останется учесть такие инверсии, которые пересекают этот разрез. То есть вот такие какие-то.
Но тогда понятно, что от того, что я переставляю элементы внутри половины, такие инверсии,
пересекающие разрез не сломались. Ну потому что здесь неважно в каком порядке их переставить,
если этот элемент всегда левее, чем этот, то как бы внутри половин не перемешивать их,
у меня все-таки инверсии сохранятся, ну и других не появятся. Поэтому давайте мы посчитаем и число
инверсий здесь отсортируем. Посчитаем число инверсий здесь отсортируем, и мне останется теперь
вот для этих двух отсортированных половин найти количество инверсий, вот пересекающих этот разрез.
Ну на самом деле получится просто такая же рекуррента, а значит n log n.
Ну давайте доведем, я еще не до конца рассказал, как мы посчитали число таких инверсий. Смотрите,
вот если у меня есть 20 отсортированных массива, как посчитать число инверсий вот пересекающих
разрез? Ну это на самом деле можно сделать во время мерч просто. Вот смотрите, у вас есть 20
отсортированных массива. Давайте идти по ним слева направо точно так же, как мы шли в алгоритме мерч,
и считать инверсии. Вот, например, здесь я нахожусь в каком-то g, здесь я нахожусь в каком-то i.
Сколько тогда, например, инверсий образует этот элемент g? Мы видим ровно вот столько. Да,
потому что что такое вот эти все числа? То есть как бы, ну вот здесь все элементы уже выписаны,
здесь все элементы уже выписаны, то есть они все меньше, чем вот это вот b g. Ну если я буду считать,
что i меньше ровно чем b g, тогда мне нужно просто к ответу добавить все вот эти элементы, лежащие
справа от i. Тем самым я учту все все инверсии затрагивающие житый элемент. Давайте я вот так
буду считать. Тогда у меня все правильно написано, то есть как раз какие инверсии образуют
житый элемент? Только вот эти вот, потому что смотрите, инверсии есть безотносительно вот
этого значка неравенства, ну как бы все такие инверсии точно есть, потому что вот здесь все числа
больше чем, ну окей, если даже a i t больше чем b g t, тогда все эти элементы тоже подавно
больше чем b g t, потому что они правее. Так, и что? Ну все равно все эти, сейчас. Все, все, я понял,
да, я понял. Один момент. Хорошо, да, то есть я хочу найти для вот этого g, когда впервые здесь
здесь, кажется, значок больше, тогда все вот эти вот добавить, да? Да, так, наверное, разумно. Да,
окей, так проще. Так вот, давайте дождемся момента, когда здесь указатель пришел в точку g,
здесь указатель пришел в точку i. И при этом будем считать, что a i t больше b g t. Ну то есть как бы,
если они равны или там, если a i t меньше, давайте просто и левый указатель двигать. Собственно,
так же, как у нас было в мерже. Я двигаю левый указатель, пока он меньше равен чем правый. До
того момента, пока не будет, наоборот, значок больше. Тогда вот сколько сейчас инверсии образует
вот это вот b g t? Ровно вот эти вот все элементы, начиная с i до конца массива, до конца левой
половины. Потому что это больше чем b g, все более правые тоже подавно больше, а все левые вот эти
вот, они уже не будут больше, они будут меньше, ну потому что это как раз первый элемент больше
чем b g, все остальные были меньше или равны. Поэтому каждый раз, когда я дохожу до такого состояния,
и мне нужно переключать b g, то есть я двигаю после этого второй, вот этот вот указатель,
жишечку на единицу. Значит в этот момент времени мне нужно к ответу будет добавить
количество элементов от i до конца левой половины. Вот так вроде будет работать. То есть по факту
у меня здесь просто будет внутри модификация merge. Каждый раз, когда i больше чем b g,
я к ответу добавляю что-то в стиле там, ну давайте я напишу,
мне лень писать. Короче количество элементов в а, минус что? Минус i, да? Да, вроде так правильно
будет, да. Количество элементов в а. Ну вот собственно мне нужно добавить к ответу вот это
вот количество, сколько есть элементов с номерами i или больше. Это в точности все
количество элементов минус i, потому что вот здесь левее него стоит i. Вот просто здесь и здесь. Но
смотрите, на самом деле алгоритм будет работать точно так же как merge short, просто в merge я еще
вклею вот эту вот штуку. Тогда что будет происходить? Смотрите, вот я сначала разделил весь большой
массив на два кусочка, левый и правый. Рекурсивно вызвал в них merge short вместе вот с этим вот
изменением. Что это такое? Это значит, что вот эти две половинки отсортируются и вместе с этим
посчитают число инверсий внутри себя. То есть я сейчас считаю, я так модифицирую merge short,
чтобы он не только сортировал, но и выдавал число инверсий. Так вот он отсортирует этот массив,
выдаст число инверсий, то есть увеличит ответ на число инверсий в нем. Отсортирует этот массив,
увеличит ответ на число инверсий в нем. А дальше у меня есть два отсортированных массива. Я их
склеиваю с помощью моей обычной процедуры merge, которая также увеличивает общее число инверсий,
но каждый раз, когда видит их. Давайте попробуем. Давайте посмотрим, как они склеиваются.
Есть два таких массива. Изначально я просто описываю единицу, пока инверсий не вижу. Дальше пришел
сюда, вижу инверсии. Я вижу инверсии вот такие вот. Добавляю к ответу двойку. Дальше двигаю
эту двойку. Опять вижу те же самые две инверсии. 4,3,7,3. Опять добавляю к ответу двойку. Двигаю
стрелку. Пока инверсий не вижу. 4,8 нормально соотносится. Двигаю стрелку. 7,8 нормально
соотносится. Инверсий не вижу. Двигаю стрелку. Дошел до конца, инверсий больше нет. Если бы
здесь было какой-нибудь 9, то я бы увидел еще вот такую инверсию, добавил единицу к ответу.
Когда я сравнивал 4,3, я двигал вот здесь вот. Потом сравнивал 4,8, 4 меньше чем 8,
сдвигаю с 4 на 7. Потом сравниваю с 7 и 8, сдвигаю стрелку сюда. По факту идея просто мне
нужно внедрить в мой мерч подсчет числа инверсий вот между двумя половинками, между левой и правой
склеиваемой частью. Время работы остается вот таким вот. По крайней мере по-прежнему будет
отвечать такому соотношению рекуррентному, потому что опять я сначала два раза запускаюсь от половины
длины пополам рекурсивным вызовом, а потом за линейное время склеиваю их, ну еще из-за
одного вот это вот подсчитываю, к ответу там что-то добавляю. Это все понятно, делал все еще линейное
время, поэтому в этой рекурренте там разве что испортится константа вот здесь вот во большом.
Там раньше было C, теперь будет там C плюс один может быть. Но от этого симпатика не испортится. В
терминах у большого останется от n-логан. Следующая сортировка называется быстрая сортировка,
она же сортировка ХААРА.
Работает следующим образом. Опять пусть есть большой массив. Давайте выберем в качестве пивота,
в качестве разделяющего элемента случайный элемент нашего массива. Вот пусть давайте х,
это случайный элемент массива. Вот я его буду называть пивот, ну собственно от английского
пивот разделитель. Какой-то разделяющий элемент. Просто давайте случайный элемент из нашего массива
назначим пивотом, разделителем. Что я сделаю дальше? Вот он где-то здесь у меня стоит. Давайте я так
переупорядочу мой массив, так изменю порядок элементов в нем, чтобы сначала шли элементы меньше
пивота, потом все элементы равные пивоту, возможно их там несколько, несколько равных х, а затем
шли бы все элементы больше пивота, больше х. Вот я их так переставил, чтобы массив выглядел ровно
таким образом. Причем внутри блоков они могут как угодно быть переупорядочены. Ну а дальше та же
самая идея, я рекурсивно посортировал здесь и здесь. На рекурсивные запуски. И если у меня этот
кусок после завершения рекурсии будет отсортирован и этот кусок после завершения
рекурсии будет отсортирован, то все вместе будет правильный отсортированный массив. А потому
что у меня сначала в порядке возрастания все элементы меньше х, потом все элементы равны х,
потом в порядке возрастания все элементы больше х. Понятно дело, что это корректный порядок
сжатировки. Все, веселый алгоритм.
Да, именно поэтому мы его выбираем случайным, чтобы такое почти никогда не
происходило.
Вот. Значит, ну давайте я не буду писать псевдокод. Тут единственный вопрос, как
генерирую случайный элемент. Ну, там, в зависимости от, я не знаю, только на
плюсах умею. Вот есть, например, такой довольно хороший генератор случайных
чисел. Вот. Можете, ну прям так и пишется такой тип. Можете погуглить и научиться им
пользоваться, если надо. Вот. Ну, на крайнях всегда есть просто ранд.
Это класс, видимо. Ну, короче, погуглите. Вот. Я в детали не хочу никогда лезть. Это
вопрос реализации всегда. Вот. Значит, алгоритм в точности такой, да. Каждый раз
просто выбираем случайный элемент, по нему разделяемся и рекурсивно ссортим
обе половинки. Значит, утверждается, что... Да.
Потому что, если мы будем выбирать, например, всегда центральный, то несложно
построить пример, когда эта штука всегда будет работать за квадрат. Ну,
представьте. То есть, что, например, плохого может быть? Плохо может быть, если в
качестве х вы, например, выбираете минимальный элемент массива. Тогда у вас
вот этого вообще не будет. Будет минимум, и вы будете ссортировать все кроме
минимума. То есть, по факту, вы просто один элемент отссортировали и ссортируете
массив длины n-1. Так вот, а представьте, что если минимум стоял бы у вас в центре.
То есть, вот здесь единица. Дальше. После как-то... После переупрядущивания у вас,
ну, опять выбирается центральный элемент, но вполне может быть такое, что там стоит
двойка, и вы взяли опять минимум. Да, поэтому в таком... В таком случае всегда
можно подобрать массив так, чтобы такой алгоритм работал за квадратичное время,
за n-квадрат. Это нам не годится, мы хотим за n-лог n. Что он?
Ну, смотрите, еще раз. Плохо, плохо, когда х близок к минимуму или к максимуму
массива. Но если выбираете его случайно, давайте вот такую картинку
нарисуем. Давайте я скажем, разобью массив на три равные части. Здесь минимальные
элементы, здесь максимальные, здесь какие-то центральные. Ну, то есть, я его
отсортировал. Вот здесь минимальные отрезы, здесь максимальные отряд.
Тогда с вероятностью хотя бы одна тресть, вы его неплохо так разобьете. Потому
что если х будет вот отсюда, то у вас обе эти части будут хотя бы одна треть по
размеру. Получается, с вероятностью хотя бы одна треть, то есть, по крайней мере,
на каждом третьем шаге, вот этого, вашего рекурсивного спуска, вы ваш
Массив сплитите не так в тупую один элемент и все остальные, а хотя бы треть массива и две третьи массива.
Это уже хорошо.
В принципе, из того, что массив не отречен, ты же скажешь, что выбор строго центрального элемента вполне смущает?
Ну, это громкое заявление, потому что массив, подаваемый вам на вход, на нем нет распределения вероятности.
Это какой-то конкретный массив.
И если написан какой-то код, который всегда берет центральный элемент и в нем нет случайности,
то спокойно можно построить такой массив длины n, на котором ваш код работает n квадрат.
Потому что вход это случайный массив, это какой-то массив.
Его можно так сгенерировать, чтобы алгоритм работал в квадратичное время.
А вот здесь я утверждаю, что если ваша программа сама самостоятельно генерирует случайные биты,
сама выбирает вот этот элемент x случайно, то какой бы массив на вход не дали,
от ожидания времени работы будет n log n.
Смотрите, вот эта штука на самом деле на практике работает даже быстрее, чем merge sort.
Здесь только теоретическая оценка получается, в худшем случае n квадрат, в среднем n log n.
Но на практике оно даже быстрее merge sort.
Потому что в merge sort вам там надо много памяти выделять.
Когда вы два 24-ронных массива склеиваете в 11 4-ронных, вам там нужно выделить дополнительную память.
А здесь можно без допамяти все это сделать.
Поэтому здесь даже на практике это быстрее работает.
In place merge sort. Я не умею это. А вы умеете?
Что-то я сомневаюсь.
Можете скинуть в чат, я посмотрю, если такое есть.
Мне кажется как раз пафос quick sort и hip sort, который тоже будет через пару лекций, в том, что они именно in place.
А merge sort тяжело сделать in place, если вообще возможно.
Потому что она быстрее.
Я вот только что говорил, что теоретически она в худшем случае работает за квадрат, в среднем только за n log n.
Но на практике она работает быстрее, чем merge sort.
Итак, теорема, значит, математическое ожидание времени работы без доказательства на массиве длины n есть от n log n.
Что?
Поскольку у вас еще год не будет Тиарвера, то я не буду ничего говорить.
Там доказательства элементарные, но требуют каких-то знаний Тиарвера.
Мы не будем сюда лезть.
Смотрите, что здесь хочется сказать, что здесь довольно важно сказать.
Я вот заикнулся уже про то, что merge sort с точки зрения использования памяти весьма неэффективен.
Потому что когда вам нужно в частности решить такую задачу.
Есть два отсорщенных массива, вам нужно их слить в один большой отсортированный.
Вот так их слить.
Эту задачу, говорят, что где-то на нерке написано, но я по крайней мере не умею решать без привлечения до памяти.
Потому что вам нужно идти слева-направо по этим массивам обоим и сливать результат куда-то.
Вы не можете его сливать ни сюда, ни сюда, потому что здесь элементы лежат.
Вы не можете записать результат на место массива A.
Вам нужна отдельная память.
Quick sort хорош тем, что здесь можно без допамяти обойтись.
Кроме поддержки стека рекурсии, это фигня обычно.
Самое сложное это процедура.
По выбранному х разбить массив так, чтобы сначала шли меньше х, потом равный х, потом больше х.
Это называется partition.
А х это в точности разделение массива на три куска.
Меньше х, равный х и больше х.
Давайте научимся с вами сейчас выполнять этот partition без привлечения дополнительной памяти, то есть на месте.
Давайте не создавать новый массив и в него как за счет записывать, а прямо в этом массиве переставим элементы так, чтобы они шли в таком порядке.
Я, видимо, не совсем так сделаю, я сделаю вот так.
Я чуть-чуть испорчу свои данные, но от этого ничего не сломается.
Я расположу сначала меньше х, а потом больше либо равный х.
Х может быть где-то здесь правее, но это неважно.
С точки зрения алгоритма все равно главное, что мы разбили массив на два куска и рекурсивно их посвятировали.
Так вот, идея. Давайте идти по массиву слева направо и поддерживать ровно вот такое разбивание, что сначала идут элементы меньше х, потом больше либо равный х.
Тогда что делать со вновь пришедшим элементом у?
Смотрите, если он больше либо равен х, то делать ничего не нужно, можно просто расширить эту границу.
А если он меньше х?
А вот здесь были меньше х, а здесь были больше либо равный х, у тоже пусть будет меньше, чем х.
Давайте тогда просто возьмем вот эти два элемента, слопнем.
И у меня как раз расширится окно элементов меньше, чем х, а справа будут те, которые больше, чем х.
Вот и все.
Поменяем местами.
Вот у меня есть элементы меньше, чем х. Следующий за ними элемент больше либо равен х.
Следующий за всеми, которые меньше, чем х, я его поменяю местами с у.
И тогда у меня сначала опять-таки будут элементы меньше х, а потом элементы больше либо равны х.
Давайте здесь какой-нибудь код напишем.
Вот это вот, давайте пусть будет l.
l это последний индекс из тех, которые меньше, чем х.
Изначально пусть будет l минус 1, что ли, не знаю.
А нет, можно 0. Нет, нет, нельзя.
Давайте пройдемся по нашему массиву слева направо.
Вот пусть у этот наш текущий элемент, а х это то, с чем мы...
Ну то есть х это наш пилот.
Ну и вот дальше те самые два условия, что если у больше либо равно, чем х,
то тогда делать ничего не нужно, можно просто делать continue,
потому что у меня и так хорошая картинка l остается последним элементом меньше, чем х,
а дальше идет блок элементов больше, равно, чем х. Тут все хорошо.
Теперь второй случай.
Если у меньше, чем х, то его нужно переставить с элементом номер l плюс 1,
потому что l это последний меньший, а первый больше равно, это l плюс 1.
Поэтому я меняю местами a l плюс первая и a it.
Вот, с опытом как раз поменять местами два элемента.
Ну и, видимо, увеличу l на 1, потому что у меня выросло...
Да, у меня выросло количество элементов меньше, чем х.
То есть было вот так, стало вот так.
Все, вот это partition.
В результате выполнения такого цикла у меня все элементы с 0 по l будут меньше, чем х,
все элементы с l плюс 1 по n минус 1 будут больше равны, чем х.
Это не совсем то, что мы хотели вот в той картинке,
потому что элементы равны х где-то вот здесь вот затесались.
Ну если надо, мы можем их вот сюда вот переставить, но на самом деле не надо.
Можно просто так же честно посажировать этот кусок, посажировать этот кусок.
Все равно в среднем эти куски оба будут достаточно большие
и не будет такого, что, скажем, я отщепил всего один элемент,
или там вообще ничего не отщепил, да, и заново запускаюсь рекурсивно от массива большой длины.
В силу того, что х случайная, на каждом таком шаге такое разбиение довольно эффективно.
То есть у меня довольно много элементов будет здесь, довольно много элементов будет здесь.
Да.
Ну вот нет, смотрите, в такой постановке у меня все будет верно.
То есть когда у меня ни один элемент не рассмотрен, я могу считать,
что у меня элементы с 0 по минус 1, то есть никакие, меньше, чем х,
а все остальные, но тоже никакие, потому что еще больше ничего не рассмотрен,
больше равно, чем х. Короче, это тоже работает.
Я вас уже не слышу, подойдите, если что. Все, до свидания.
