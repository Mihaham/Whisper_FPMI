У нас сегодня с вами 10-я лекция, посвященная хранилищам данных.
В принципе, концептуально мы с вами уже говорили на прошлой лекции о том, что это такое.
Сегодня поговорим чуть более подробно.
И, в принципе, наверное, на этой лекции мы с вами завершаем такую большую тему, как SQL, база данных.
У нас еще будет одна или, может быть, две лекции на тему нерелиционных баз данных,
какими особо они представлены и в чем их особенности.
Сейчас, соответственно, закончу с вами тему хранилища масштабируемости законов Андела и Густавсона Барриса.
Также на прошлой лекции был небольшой вопрос по B-деревьям.
Буквально пару слайдов им посвятим сейчас вначале. Проговорим еще раз, что это и как это.
Индексы B-деревья, как мы с вами говорили, это индекс по умолчанию, используемый позгрессом.
И он в первую очередь употреблен вместе с операциями сравнения, показанными на слайде.
Ну, также, если у нас локаль C, мы можем еще и в запросах с операторами сравнения по шаблону использовать этот индекс.
Ну, или он будет по умолчанию использован.
Технически можно и уйти за пределы локали C, но для этого нужно будет дорабатывать процесс создания индекса, скажем так.
И, ну, определенные технические сложности в этом есть.
Тогда как с символами нативными, а с ангоязычными, да, с работой, ну, и с кодировкой ASCII, ну, или ASCII работает у нас B3-деревья индексовые, индексные по умолчанию.
Ну, что такое B3, наверное, вернее, B-деревья, я думаю, вы, в принципе, представляете кратко, просто в двух словах.
У нас на B-деревья есть, ну, что важно, да, что, наверное, наиболее важно, у нас есть условия на количество потомков.
И от количества потомков зависит количество ключей в каждом из узлов дерева, в каждом из узлов дерева.
И за счет того, чтобы количество потомков не будет, не может превышать заданное, у нас появляется свойство балансировки.
И мы, соответственно, можем таким образом тоже гарантировать время отработки алгоритма поиска по B-деревью за счет того, что у нас до каждого листа есть конечная длина пути, ну, варьируемая на единицу.
А что касается, ну, на примере, да, опять же, приведено B-деревье с числом потомков 3, то есть каждый узел может содержать один или два ключа и, соответственно, два или три потомка.
Понятно, что у нас в зависимости от того, какие ключи в узле, в левую или правую ветвь дерева или ветвь каждого из узлов пойдут значения там больше-меньше или между конкретными ключами.
Ну и, соответственно, от четверки у нас с левой и справа при добавлении от единицы до 9 значений до вершины дерева оказалось четверка, и от четверки на левой и направо пошли ключи меньше и больше, чем она.
Ну, понятно, это не 3 и 5 получилось, потому что у нас последовательное добавление происходило, и поэтому у нас постепенное такое рекурсивное движение по дереву, когда ключи по узлам распределяются и узлы добавляются в зависимости от того, какое значение добавляется очередное в дерево.
Ну, от слов до больших, собственно говоря, не то, что к действиям, а к результатам, к выводам. Вопрос был на прошлой лекции про сравнение в лексикографическом порядке, а если говорить про индексы, про то, что у нас происходит под капотом,
там более сложная система представлений данных, и там сравниваться будут не значения, а ссылки на значения внутри страниц, файлов, которые содержат, собственно, информацию, хранящуюся в данных.
Поэтому там не обязательно будет лексикографический порядок, но некоторый количественный порядок, предполагающий возможность сравнения больше, меньше или равно, будет иметь место.
Просто не для каждого, там не будет значений в виде слов, не обязательно они будут использоваться в виде слов, когда у нас будет последовательное сравнение с каждой буквой слова, каждой буквой какого-то другого сравниваемого слова.
То, чем характеризуется лексикографический. У нас есть массив строка в виде массива, и каждый элемент массива – это буква, и при лексикографическом мы сравниваем порядок каждой буквы.
При, условно говоря, количественном сравнении мы не будем сравнивать каждый разряд числа, мы сравним одно число с другим, будет скорее сравнение одного числа с другим.
Ну хорошо, из интересного, что можно по Бодеревиям посмотреть, почитать в разрезе Позгресса именно, ссылки приведены, есть хорошая статья на Хабре, к ней я отсылаю за, собственно, ее исчерпываемостью, наверное, ссылка приведена там с выкладками о том, как это все представляется, в том числе на системном уровне.
Также, это, конечно, документация, ну и, помимо документации, есть еще прям для очень глубокого погружения, то, что реализовано под капотом Позгресса под названием B3Index, это последняя ссылка в разделе «Почитать», ссылка на документацию Позгресса, ну, ссылка, вернее, на файл в репозитории Позгресса, где подробно описывается вопрос реализации B3.
И, опять же, вот про визуализацию, ссылка в разделе «Посмотреть». В университет Сан-Франциско, утилитовую, небольшую создал, браузерную, где можно в режиме реального времени просто подобавлять, поудалять в некое дерево.
Это, конечно, не совсем уже в разрезе Позгресса, это просто для интереса может поиграться, кому-то будет поиграться с B-деревьями, как они работают при добавлении, удалении, поиске элементов.
Хорошо, хранилища данных. Проговорим еще раз кратенько. Предпосылки мы с вами, в принципе, уже упоминали.
Еще раз основная предпосылка заключается в том, что данных становилось все больше. Анализировать их приходилось все чаще.
Соответственно, нам нужно куда-то эти данные для удобного обращения системе сливать в одно место, в одно хранилище, и из этого хранилища как-то их оттуда изымать, как-то распределять по конечным узлам, с которыми будут взаиводействовать наши бизнес-пользователи.
И все это, в принципе, решается в рамках концепции хранилищ данных или в рамках аналогичных концепций, ну, по сути дела, произрастающих хранилищ данных, просто уже не так привязанных к нормализации какой-то структуры.
Тоже об этом проговаривали мы. Это океаны данных, болота данных, озера данных и так далее.
Но, что интересно еще отметить, хранилища данных стали появляться в рамках систем принятия бизнес-решений.
Первые такие попытки стали появляться, ну, по агрегации какой-то более или менее интеллектуальной обработки, стали появляться вот в 80-х годах.
Это все несколько условно, поскольку что такое бизнес-анализ, математически строго сформулировать нельзя, но можно считать, что в 85-м году Проктор и Энгембл такую систему для них была разработана для того, чтобы анализировать информацию о продаже и данные розничных сканеров.
Business Data Warehouse, термин 88-го года из статьи, ну и первая система управления базами данных, предназначенная для работы с большими данными, с хранилищами данных.
Здесь уже опять, это 91-й год, здесь уже упоминаются имена Кимбала и Инмана, Ральфа Кимбала и Инмана, повторюсь, это основные такие вот, ну, в кавычках теоретики, концепции хранилищ данных, в кавычках они, потому что, строго говоря, в базах, в классических базах данных не так много какой-то глубокой подлежащей математической теории.
Ну, она, безусловно, есть связанная с реализационной моделью, с нормализацией, но это лишь часть, опять же, до того, что вы с вами проходили, и по нашему курсу можете сами судить, сколько мы лекции посвятили чему-то такому, приближенному к математике и теории множеству, и сколько мы лекции посвятили синтаксису SQL и каким-то продвинутым свойствам.
Большая часть лекций у нас была посвящена не математике, к сожалению, пожалуй, что, а в хранилищах данных, в принципе, математики не остаются как таковой, там чистые концепции качественные о том, как лучше взаимодействовать с большими объемами данных.
Ну, напомню, что Уильям Инман выступает за нормализацию данных в хранилище, за такой подход сверху вниз, за entity relationship model при проектировании, за, в принципе, глубокое проектирование хранилищ
по тем же принципам и закономерностям, которые характерны для проектирования революционных баз данных, которые мы с вами проходили.
Грубо говоря, Уильям Инман – это апологет концепции, ну тоже, повторюсь, грубо концепции, согласно которой хранилища данных – это просто одна общая большая база данных.
Соответственно, к ней применимы все те оговорки, которые применены для любой революционной базы данных вне зависимости от того, какие данные, какие объемы в ней хранятся.
Ральф Кимбелл в этом смысле пошел несколько дальше. Он придумал качественную схему звезда, разработал концепцию dimensional modeling, моделирование измерений.
Мы с вами об этом говорили кратко, когда обсуждали вопрос о медленноменяющихся измерениях, как вы помните, вопрос версионирования данных или версионности данных, того, как эту версионность, версионирование поддерживать и оптимально хранить.
Соответственно, напомню вам, что вы тогда говорили, но сейчас, в общем, напоминаю, получается, что измерительное моделирование, моделирование измерений – это термин, имеющий смысл с точки зрения структурного паттерна проектирования данных под названием звезда,
когда у нас есть разделение между таблицами измерений и таблицами фактов, и в таблице фактов записываются данные об измерениях, данные об измерениях фактов хозяйственной жизни компании.
При этом таблицы измерений записываются не в метрике, т.е. в таблице измерений в них речь не о том, что мы что-то измеряем, а о том, что у нас есть некоторые объекты и события, которые мы считаем измерениями по аналогии с пространственными измерениями в 2D пространстве, в 3D пространстве.
То есть целые оси считаются измерениями, а не факт замера по линейке какого-то расстояния.
Вот так же и здесь, т.е. в таблицах фактов мы фиксируем именно нашу метрическую активность, что происходит измерительная активность, что происходит с компанией, что происходит с продуктом, что происходит на кассе с товаром или на складе с товаром, а в таблице измерения мы записываем данные о товаре, о кассе, о складе, о продавце, о магазине, о поставщике, о покупателе и т.д.
То есть факты, то, что происходит, измерения, то, чем это происходит и то, что участвует в том, что происходит. Такие немножко может быть очень абстрактные описания, но я думаю в контексте сказанного это должно быть понятно.
Структурно хранилище, соответственно, проектируется с помощью схемы звезда. И схема звезда, как вы, возможно, помните из прошлых лекций, выглядит, условно выглядит примерно так.
Звезда здесь пунктируема, обозначена, по сути дела, неважно сколько у нее лучей. Смысл в том, что у нас в грубом приближении простая примитивная схема звезда, это когда у нас одна таблица фактов, может быть их несколько, но нас это не особо интересует, они по сути дела равноуровневые, равноправные.
И когда у нас от этой таблицы фактов отходят лучи и появляются на концах этих лучей таблицы измерений. То есть, грубо говоря, у нас такое двухуровневое дерево, где один корневой узел и какое-то количество листов, соединяемых с корневым узлом всего одной дугой каждый.
Таблица измерений может быть разделена или аугментирована, улучшена, дополнена таблицами суп-измерений. И в таком случае у нас появится схема снежинки, тогда у нас корневого узла от нашей таблицы фактов уже будет непонятно.
Путь длиной не в одну дугу, соединять ее с листом, с концевым узлом А, а может быть несколько дуг, то есть может быть суп-суп-суп-суп измерения у каждой таблицы измерений, и тогда у нас получается такое в противовесбой деревьям опять же несбалансированное дерево, где может быть у нас у таблицы фактов какое-то измерение просто измерений без дополнительных таблиц,
но каких-то измерений может быть, как вы видите, либо два суп-измерения, либо суп-суп-суп измерения, и такое более сложное ветвление, но опять же структурно, графически оно появляется с точки зрения наших операций по поиску и излечению данных принципиального различия здесь, пожалуй, нет, потому что все эти буги они репрезентуют собой, констатируют собой только.
Функциональные, по сути дела, зависимости и с точки зрения операций по работе с данными, а я напомню, мы здесь все еще находимся в SQL таком, что ли, пространстве, в SQL-логике, то есть все о чем мы здесь говорим, это все еще не обязательно релиционные, может быть прям такие в классическом понимании схемы баз данных,
но это все еще данные, хранимые таким образом, что к ним применимо синтаксис SQL и соответствующие операции поддерживаемые, так что это все то, что мы видим, это по сути дела отражает просто некую логическую структуру.
Что еще можно сказать про схему Снежинка, что здесь, в отличие от классической схемы, условно классической, первой просто схемы, схемы звезды, таблицы измерений становятся нормализованными, и вот эти вот взаимосвязи рисунки, они не просто
не просто какую-то содержательную логику представляют собой, а в том числе некие релиционные ограничения, в них все-таки поддерживаются, то есть это такой шаг к больше формализации, что ли, схемы звезды.
Да, вот, ну и как во втором будете написано, схемы звезды, таблицы измерений полностью динарбализованы с каждым измерением, представленным в виде единой таблицы, ну опять же, это по такой вот прям, по классике, по классике, вот прям, что называется, при буквальном следовании текста первоисточника.
Конечно, на практике ни схемы, ни схемы звезды, там ни какой-то классической нормализации в схеме снежинки может не быть, поэтому к этому нужно относиться, да, вот, к таким вырежденным, что ли, случаем, как крайнего рода примерам, но тем не менее, отталкиваясь от них, можно как-то анализировать многообразие его,
реально сущего. Чем больше степень нормализации таблиц измерений, тем сложнее выглядит структура схемы снежинки, создаваемый эффект снежинки затрагивает только таблицы измерений и неприменим, что важно к таблицам фактов, то есть таблицы фактов у нас не нормализуются, они записываются, исходя из сугубо бизнес-логики, из реальных бизнес-процессов.
Общая концепция с вами тоже на прошлом занятии, на прошлой лекции к этому слайду уже обращались, но давайте тоже немножко повторим, то есть о чем идет речь в хранилищах данных, в теме хранилищей данных, что у нас есть некоторое количество внешних источников, которые нам поставляют данные, поставляют фактические данные.
Речь не о каких-то вендорах, не о чем-то, что гуляет по сети, речь о том, что где-то сидит начальник склада и оцифровывает ведомости или следит за тем, чтобы цифровые ведомости, электронные УПД правильно заносились, ну условно начальник склада, скорее какой-то IT-специалист, администратор местной базы следит за тем, чтобы
действительно внешних источников, напрямую внешних, там бумажных документов, электронных документов данные заносились в базу.
Базы у нас распределены, и это часто бывает, и это прям часто проблема, реальные проблемы распределены по департаментам, по, может быть, даже отделам.
Еще интереснее, когда у нас разные департаменты имеют разные, не просто даже базы, а разные ДВХ-решения, такое тоже бывает, если организации крупные, и эти разные ДВХ-решения еще и могут быть от разных вендоров.
То есть системы напрямую могут не относиться друг с другом, и мы не сможем слить данные из одного департамента с другим, какой-то удобной, единой командой нам придется что-то промежуточное делать,
какую-то промежуточную стадию хранения создавать, отдельный сервер, отдельные процедуры, отдельная поддержка и так далее и тому подобное.
Ну так вот, ладно, операционные приложения, то есть приложения, которые непосредственно берут данные из внешних источников и их складируют в местные, условно говоря, базы данных по отделам, по департаментам.
Дальше все это посредством некоторых, неких процессов, которые на слайде объединены аббревиатурой ETL, переправляется в ДВХ.
Из ДВХ уже, собственно, зачем нам нужна агрегация? Из ДВХ мы уже можем эти данные извлекать для бизнес-пользователей, представлять в каком-то удобном для анализа, для визуализации в виде,
извлекать там, проводить какую-то аналитику, на них строить какие-то зависимости, выявлять, вернее, что здесь, опять же, подчеркну важно, в первую очередь, это ETL, потому что важно оно потому, что на самом деле оно неважно, неважно в том плане, в каком оно нарисовано.
Повторюсь, на прошлой лекции я вам уже говорил, и на практике такое встречается часто, хотя на собеседовании у вас могут спросить, а что такое ETL, и как бы по классике, вот ETL это экстракт transform load, извлечь, очистить, или очистить, и преобразовать, и загрузить, то есть промежуточный шаг между операционными приложениями и ДВХ-хранилищем, но, по сути дела, в реальности могут быть какие-то отдельные процессы, которые вообще
в
в лапку бы закидывать в какие-то приложения для отчетности, в витрины данных.
Могут быть по-разному настроенные процессы внутри ETL стека, и
И в разном порядке они могут происходить, и не факт, что этот разный порядок...
Ну, то есть говорят, что есть EL, говорят, что есть ELT, то есть Extract, Load и Transform,
когда мы сначала загружаем, а потом уже начинаем трансформировать.
И говорят, что вот ELT, оно может возникать после стадии DWH, то есть после стадии хранения.
Ну, или там Transform будет, этап очистки и преобразования будет после стадии хранения в хранилище и так далее.
На практике все это перемешано, все это проблемно, неоднозначно, и с другой стороны, наверное, все-таки эффективно,
потому что каждая компания делает это под себя и делает так, как и удобно.
И с учетом того, что, повторюсь, у нас за концепцией хранилищ и данных не стоит никакой глубокой математики,
какой-то формализованной модели, в принципе, ограничений на это нет, кроме вот концептуальных.
Поэтому здесь кто во что гораздо, кому что ближе, кому что эффективнее с точки зрения его процесса.
Так что вот так. Поэтому классическую схему надо себе представлять, но понимать, что, может быть,
все там неоднозначно и по-разному, и, возможно, на этапе предсобеседования, как-то,
посмотрите на компанию какую-то, посмотреть вообще на том же хабре, может быть, какие-то статьи
о том, что эти ребята используют у себя на практике при хранении данных.
Очень может быть, что для крупных работодателей, крупных компаний вы какие-то интересные заметки найдете,
и, опять же, сможете соотнести с тем, о чем мы с вами говорим.
Окей, давайте немножко поподробнее посмотрим на ITL-процесс.
Вот на слайде набор процессов, неразрывно связанных с хранилищами данных и основным назначением которых,
является наполнение заранее спроектированной физической модели данных с учетом ограничений логической модели.
Ну, понятно, то есть внутри DWH у нас есть какая-то своя логика хранения, какое-то представление наших
вот этих вот таблиц с данными, и, с другой стороны, у нас есть некоторое количество
несогласующихся между собой данных из наших операционных приложений по разным департаментам.
Разные департаменты, скорее всего, возможно, создавали свои базы данных до того, как компания приняла решение
создать корпоративные хранилища, поэтому здесь данные могут быть совершенно разрозненные,
ну, из того, что вот прям, что ли, в некотором роде классический тоже пример, когда разные форматы
даты времени, и, особенно, если разные часовые пояса, в разных часовых поясах компания операционную
деятельность осуществляет, у вас, если данные не хранятся в каком-то усредненном, в каком-то
нейтральном часовом поясе, вам придется работать с тем, чтобы данные эти все привести к единому
знаменателю, чтобы они хранились в ДВХ, в какой-то реальной, скажем так, последовательности, ну,
или в какой-то заранее выбранной последовательности. Но окей, давайте посмотрим чуть подробнее.
ИТЛ-извлечение. Здесь речь о том, что происходит инкрементальное извлечение, то есть мы данные
выгружаем не массово, постоянно, каждый раз, а мы стараемся оптимизировать работу на всех наших
систем, и операционных систем, и систем корпоративного хранения, поэтому мы, в первую очередь,
выгружаем только то, что меняется. Очевидно, что у нас здесь происходит выигрыш по времени и по
загрузке. Мы, соответственно, должны при этом как-то этот механизм обеспечивать, то есть мы либо храним
дату последнего изменения записи, либо некий условный инкрементальный идентификатор. Опять же,
да, как я и говорил, что мы должны учитывать особенности базы источника, это как раз дата
последнего изменения записи, в каком виде эта дата будет храниться в базе источника. При этом
входные данные нам тоже нужно согласовывать, нужно их очищать и трансформировать, ну и так далее,
в общем, делать то, что делается в процессе ETL, в принципе. Что мы на этапе очистки, ну то есть это
уже на этапе после извлечения, что мы на этапе, который представлен в аббревиатуре буквой T,
делаем. Ну, например, очистка, то есть мы приводим к какому-то общему знаменателю то, что у нас есть.
Вот на левой картинке на слайде показаны номера телефонов, мы их проверяем, мы пытаемся навалидность
проверить. Понятно, что с одной стороны, а с другой стороны, да, вот привести к общему знаменателю.
Понятно, что последние три записи у нас превращаются в нул, потому что они не имеют
какого-то содержания в контексте телефонного номера. Ну, разве что последнюю запись можно было
бы пофантазировать и попытаться московский код дополнить и, может быть, в конкретном юскейзе это
было бы действительно осмысленно, но в общем случае мы это просто удаляем, а первые пять записей мы,
соответственно, очищаем. На пятую обратите внимание, мы и очищаем в том числе от опечаток в виде вот
знака равно и с правой закрывающей скобки. И на правом слайде мы тоже пытаемся записи как-то
провалидировать, как-то их привести к общему знаменателю, ну, либо в виде налов пометить
как отсутствующую запись о адресе электронной почте, если пользователь ввел неправильный какой-то
домен, ошибся в написании почты, ввел почту, которая, ну, очевидно, является какой-то вот
массовой почтой адресом регистрации, ну, типа a.sabaka.gmail.com, то есть a.gmail.com это адрес,
который с очень большой долей вероятности был одним из первых, которые вообще были созданы
и зарезервированы за кем-то. И сейчас может быть даже вообще не используется, потому что
адрес такой похожий на технический и несодержательный. А дедупликация, ну, понятно,
приводим все это в какой-то удобоваримый вид записи, особенно релевантно, когда у нас какие-то
смежные отделы, там, условно говоря, HR и бухгалтерия ведут разные записи, разные, почему-то, записи
о сотрудниках. Ну, как пример, вот у нас появляется, что где-то у нас просто первые буквы имени и
отчества, где-то у нас нет отчества, где-то у нас есть данные паспорта, где-то нет, а где-то есть
данные телефонного номера, где-то нет. Нам это все нужно сопоставить, понять, что это данные об одном
лице, и нам нужно понять, какие данные отбросить, какие данные сохранить. А с чего мы решили, что у
него номер телефона с девятки начинается, не с восьмерки? Да, вопрос как бы концептуально
интересный, к теме он наше не относится, но здесь можно следующую провести, следующий такой анализ.
Во-первых, коды 800 это коды, как правило, бесплатных номеров, ну, таких вот, бесплатных для звонящего
номеров, когда платят именно адреса звонка, технические всякие службы, либо какие-то
сервисы у компании по жалобам, по поддержке и так далее. То есть код 800 изначально он не похож
на реальный код, то есть это не код населенного пункта, это код технически, повторюсь, это не код
оператора сотовой связи. У них у всех с девятки, возможно, я, правда, в этом могу ошибаться,
но, по-моему, у всех внутренний код трех цифр, из трех цифр, цифр с девятки начинается. Поэтому
800 это, скорее всего, либо ошибка, либо номер, по которому вы никогда не дозвонитесь реальному
человеку, позвоните в какой-нибудь службу поддержки. Так что вот так. Ну и, соответственно,
нам нужно это все закладывать, нужно проводить какой-то анализ данных, какой-то скрининг вообще того,
что происходит, чтобы выявлять вот эти шумовые данные или данные ошибочные. Ну, это уже вопрос
скорее даже, да, либо конкретных систем, которые функционируют на этапе ETL, либо вопросы конкретных
случаев, каких-то массовых ошибок, систематических ошибок. Это не предмет для разговора с точки
зрения проектирования баз данных или чего-то подобного. Преобразование этап, опять же,
transform. Что происходит? Ну, матинг входных данных в физическую модель. То есть, да, опять же,
мы, не знаю, преобразуем int в, не знаю, numeric или наоборот, условно говоря, временные данные
трансформируем в какую-то часовую зону общую для компании, принятую за единую для компании и так
далее. То есть соблюдаем все те ограничения, которые у нас наложены. Ну, помните, что такое
физическая модель, да, по теме проектирования. Вот мы наши данные в эту физическую модель
пытаемся втиснуть. Интегрируем данные из разных источников, фиксируем алгоритмы. Ну,
фиксация алгоритмов бизнес правила здесь такая, да, несколько абстрактная формулировка. Здесь
может быть даже не с точки зрения, не с точки зрения базы данных или хранилища, а здесь скорее
вот вопрос тоже в каком-то предварительном анализе. То, о чем мы говорили про номер телефона,
просто масштабируем это не на номер телефона, не на ошибочную номер телефона, условно говоря,
на сумма транзакций. И какие-то транзакции большие, мы данные по ним, мы, может быть,
будем хранить в отдельной таблице, потому что бизнес-пользователи на этапе аналитики,
прошу прощения, на этапе аналитики, который графический был, в такой правой части нашего
слайда концептуального, бизнес-пользователи на этапе аналитики, может быть, захотят к
транзакциям на очень большие суммы выше какого-то порога обращаться чаще, или, наоборот,
на транзакции на суммы ниже этого порога обращаться чаще, к транзакциям ниже этого порога
обращаться чаще, и так далее. По загрузкам в хранилища данных, собственно говоря,
сложность определяется, это соответственно буквка L, сложность определяется применяемым
алгоритмом обобновления. Существует несколько разных типов обновляемых данных, определяемых
термин с ССД, Slowly Changing Dimensions, и чаще всего используется ССД1, ССД2. Ну это, в общем,
то, о чем мы с вами уже сильно раньше говорили. Здесь единственное, что здесь можно добавить,
что тоже в ДВХ могут свои таблицы ССД, свои таблицы версионирования быть, и, более того,
они будут как элемент, во всяком случае, концептуальный про того тех этапов проектирования,
за которые наступает Ральф Кимбл. Понятно, там нужно все это загрузить, распределить по нашим
отношениям, которые у нас в ДВХ есть, хранить изменения, загружать последовательно, следить
за тем, чтобы у нас не было перехлестов между тем, что мы выгрузили и трансформировались,
тем, что мы загружаем, и так далее. Здесь может быть довольно большое количество проблем,
так и довольно понятные варианты их решения, но, опять же, концептуально. Если бы хотим
версионировать, мы создаем ССД таблицы соответствующих типов. Если мы выгружаем
данные, их трансформируем и пытаемся загрузить нашу физическую модель, мы должны загружать
правильно, в правильные колонки, правильные типы данных и так далее. В общем-то,
наверное, вот резюмируя все это, можно сказать следующее, что, повторюсь, все, о чем мы сейчас
с вами говорим в рамках хранилищ, это вопросы концептуальные, математической теории за этим
нет. Мы можем выделять процессы ИТЛ и можем даже говорить о том, что они у нас происходят между
хранением данных в операционных приложениях и хранением данных в хранилище компании, но по
большому счету нам никто не мешает менять порядок того, что у нас происходит в рамках ИТЛ, а говорить
о том, что мы в базу, в наше хранилище, загружая наши данные, мы используем только экстракт и лот,
а трансформ мы делаем уже извлекая данные из хранилища, то есть ИЛТ. Пожалуйста, никто не
запрещает. Вопрос в том, что за оборудование вы используете, способно ли оно поддержать те массивы
данных, которые у вас будут без трансформации загружаться в хранилище, хотя это уже скорее будет
какое-то там болото, океан и так далее, озеро, и насколько эффективен будет и быстрый поиск
среди такого рода агрегации данных. И вот ИТЛ, ВИС, ИЛТ, то о чем мы с вами, опять же,
говорили устно, но теперь немножко графически. Здесь у нас ИТЛ, что называется по классике,
для него выделяется отдельный какой-то процесс, ну там сервер, да, как правило, структурно,
физически понятно, как это реализуется, это очевидно сервер некий, на котором отдельные
процессы, все это в себя загружают, перерабатывают и выдают. С точки зрения ИЛТ можно представлять,
что у нас трансформация может происходить внутри DWH, внутри DWH процесса, но это такое,
как разделение условное на уровне, что ли, по принципу, на каком сервере у нас крутится тот
или иной процесс. Повторюсь, здесь можно говорить, что трансформ, стадия трансформации будет идти
вообще за пределами DWH, и у нас будет сервер, Т-сервер, в рамках этих аббревиатур, трансформ,
трансформейшн сервер будет где-то справа стоять, и из него уже будет аналитика какая-то,
лэп-приложение, и так далее, и так далее, еще проверить, будет располагаться такой условной схеме.
А какие проблемы с DWH возникают? В общем-то, проблема ожидаемая, что у нас данные большие,
их надо хранить много, ресурсы всегда ограничены, стоимость увеличения растет не всегда линейно,
ну и в принципе не линейно, кстати говоря, да, это отдельные вот у нас законы сейчас будут,
и масштабирование системы требует существенных финансовых вложений, как с точки зрения там
подсупки серверов, так и с точки зрения того, что это еще нужно просто физически как-то
проектировать, располагать где-то, подключать, связывать, и так далее. И с точки зрения
масштабируемости можно говорить, что она у нас бывает в нескольких видах, во-первых,
горизонтально и вертикально, очевидно. Во-первых, что такое самопо себе масштабируемость? То есть,
говорят, что система масштабируема, если она способна увеличивать производительность
пропорционально дополнительным ресурсам. И масштабируемость можно оценить через отношение
прирост, производительность системы к приросту используемых ресурсов. Чем ближе это отношение
к единице, тем, очевидно, лучше. И если у нас масштабируемость плохая, то добавление ресурсов
приводит лишь к незначительному повышению порога производительности, а с некоторого порогового
момента добавление ресурсов не дает никакого полезного эффекта. И по этому поводу есть даже
вот парочка таких несложных математически формализованных законов буквально через пару
слайдов. Вертикальная масштабируемость. Вертикальная масштабируемость – это увеличение
производительности каждого компонента системы с целью повышения общепроизводительности.
Масштабируемость в этом контексте у нас означает, что мы можем заменять компоненты внутри
системы более мощными. И это, соответственно, самый простой способ масштабирования, потому что мы
никак не меняем распределение нагрузки по имеющимся ресурсам. Ресурсы мы сами меняем,
но то, как они у нас балансируются в нашей сети, у нас, скорее всего, останется таким же. Ну либо
мы там какие-то коэффициенты, условно говоря, какие-то чиселки в нашей инжинкс-конфигурации
поменяем, может быть, но принципиально не будем заниматься тем, чтобы будем добавлять сервера и
так далее. А горизонтально мы разбиваем систему на более мелкие структурные компоненты и
разносим их по отдельным физическим машинам или кластерам таких машин, увеличивая
количество серверов, параллельно выполняющих одну и ту же функцию, хранящих, может быть,
даже одни и те же данные в контексте базданных. И масштабируемость тогда мы понимаем как
добавление новых физических компонентов к нашей системе. И это уже очевидно требует не просто,
не просто, повторюсь, в инжинкс-конфигурации поменять одни числа на другие, а это уже
требует дописывания новых конфиг-файлов, ребалансировки, может быть, нашей системы.
Более того, помимо каких-то балансиров, балансёров, речь идёт о том, что возможно нам
потребуется иначе реплицировать данные на тех или иных узлах. В общем, теоретически это более
сложный, даже, наверное, может быть, практически это более сложный, очевидно, процесс по сравнению
с вертикальной масштабируемостью. У нас есть, повторюсь, математически формализованный
способ оценки того, насколько система масштабируемая, насколько нет. И, соответственно,
у нас законом дало выглядеть следующим образом, то есть, что теоретическое ускорение выполнение
всей программы можно оценить, как показано по формуле. И, соответственно, у нас применимое
более к вопросу горизонтальной масштабируемости видзакона. Он показан на слайде. Альфа – это доля
вычислений, которые могут выполняться только последовательно, единицы минус альфа, соответственно,
то, что может быть распараллелено, и пи – это число задействованных узлов. Зависимость у нас
получается примерно следующее. То есть, если у нас альфа равна единице, то у нас вне зависимости
от числа узлов, изначально, если альфа равна единице, вне зависимости от числа узлов, у нас альфа всегда
будет равна единице. Если альфа равна нулю, то все процессы распараллеливы ЕМ и Е. Соответственно,
условно говоря, по вот этому математическому приближению у нас чем больше узлов, тем больше
будет этих самых процессов. Увеличение идет линейно. И при значениях альфа в диапазоне от нуля до единицы,
как вы видите, у нас идет нелинейное изменение производительности системы. Вот на предыдущем
слайде, соответственно, оно у нас хорошо показано, когда, соответственно, чем у нас больше
процент распараллеливаемости задачи, вот зеленая линия на графике, тем больше ускорение в зависимости
от числа ядер процессоров. Но все равно на некотором этапе у нас наш график приближается
к некой асимпатите и дальше за нее скорее всего не выходит. Вот у нас опять же лимит,
предел, к которому будет стремиться наш s-latency, показан на слайде внизу в фигурной скобке,
последним уравнением единицы, деленное на альфа, предел при количестве процессов,
стремящимся к бесконечности. То есть у нас максимально, всегда будет некое ограничение.
Ну и да, соответственно, реальность такова, чем не всегда у нас будет, поскольку у нас в
любом случае наша программа на отдельных шагах не сможет быть распараллелена, у нас всегда будет
некий предел, выше которого эффективность горизонтального масштабирования не поднимется.
Так что, в принципе, ее можно прикинуть на некой абстрактной модели вычислений,
если ее сформулировать для той или иной задачи, и даже численно попытаться это все оценить,
если сильно задуматься, если сильно постараться, если сильно захотеть. Но как минимум это просто
нужно знать качественно, что в реальности у нас любое масштабирование текущего алгоритма упрется
в некий теоретический потолок. Вот то, о чем мы с вами говорили,
усно на слайде предложено письменно. Важно, пожалуй, отметить то, что законом Далла не
учитывает время, затрачиваемое на взаимодействие параллельных процессов. И, как вы, наверное,
знаете, у нас при распараллеливании задачи, при последующем ее сведении воедино в неком родительском
процессе отдельно будет затрачиваться время на это сведение. Создание, может быть, процессов
здесь не очень актуальны с точки зрения того, что у нас там где-то отдельные сервера стоят,
там всегда крутятся некие процессы. Но время на взаимодействие между процессами будет
действительно дополнительно отнимать какое-то количество временного ресурса. Так же есть закон
Густавсона Бариса. Барсиса, прошу прощения. И в чем он важен? Законом Далла у нас оценивает
ускорение выполнения задачи фиксированного объема. Закон Густавсона Бариса оценивает
ускорение с точки зрения объемов задач, которые можно решать за то же самое время. И S в данном
случае это доля последовательных расчетов в программе N, количество процессов. И у нас
соответственно, чем больше процессов, тем теоретически больше скорость. Но опять же в
реальности надо смотреть на то, какая у нас доля. То есть чем больше доля распараллеливаемых
задач, тем больше скорость, тем больше выигрыш от того, прошу прощения, от того, что мы добавляем
каждый новый процесс. Еще с точки зрения масштабируемости горизонтальной. Это стало
особенно актуально во второй половине девяностых нулевых годах. А вот первые решения по распределенным
таким хорошо масштабируемым хранилищем данных. Но опять же это уже даже не совсем про базы,
как вы видите. Это распределенная файловая система и хранилища K-value. Но важно то,
что это хорошо программные решения, которые хорошо взаимодействовали с данными в условиях
горизонтальной масштабируемости систем хранения данных.
Ну и собственно говоря, о чем еще стоит сказать. Это о том, каким образом у нас в рамках хранилищ
решаются вопросы и задачи обработки данных в случае, когда мы имеем дело с вертикально,
с одной стороны, распределенной системой, а с другой стороны, с системой, которая испытывает
на себе нагрузки от частых, с одной стороны, запросов. Ну возможно частых запросов от
пользователей, а с другой стороны, постоянно в нее добавляются данные. Ну здесь, с одной стороны,
можно сказать, что не затрагивая вот эти вот варианты многопроцессорной обработки,
можно говорить, что одним из вариантов такого решения, это можно считать витрины данных. То
есть такие субагрегации данных по интересам бизнес-пользователей, грубо говоря. Ну о чем
идет речь? То есть у нас внизу цепочки, грубо говоря, склад или там склады и магазины, из них
данные в ДВХ подтягиваются, из ДВХ данные у нас могут пойти в финдиректору по продажам и покупкам,
директору по персоналу, данные по работе, собственно говоря, персонала складов, персонала магазинов,
данные, не знаю, может быть, директору по безопасности, данные по утерю, утрате товара,
порчи товара. Хотя порча, наверное, не совсем для безопасников интересна, но вот как-то так.
Нам эти данные смысла предоставлять в рамках всего хранилища напрямую вот этим вот директорам,
их секретариату, помощников смысла нет. Это лишняя нагрузка, лишние данные, дополнительные
вопросы по формулированию запросов к хранилищу данных и так далее и так далее. Нам проще
сделать тем или иным образом интерфейс, в котором данные по промежуточку агрегировались,
интересные только для соответствующих групп. Вот такого рода интерфейс это не обязательно просто
набор программ, это может быть какая-то база данных на выходе из хранилища, небольшая база
данных. Поэтому интерфейс-то в широком смысле, это не просто точки входа. Нам удобно сделать
какой-то интерфейс, вернее, удобно получить какой-то интерфейс для того, чтобы взаимодействовать
с данными, которые интересны только для них, строить аналитику по таким данным, принимать
какие-то решения. Вот поэтому хранилища данных тоже как вариант свержения нагрузки на, прошу
прощения, витрины данных, конечно же, как снижение нагрузки на сервера хранилища. Ну а с точки
зрения того, что под капотом происходит, можно выделить несколько вариантов. Некоторые из них
представлены на слайде. Это SMP, симметричная многопроцессорная обработка. То есть множество
процессов выполняют разные задачи, используют общую память. SMP это симметричная многопроцессорная
обработка процессора сравнимой производительности, используют общую память и выполняют одни и те же
функции. И MPP, массивно-параллельная обработка. Каждый узел системы физически независимо
содержит собственные процессоры и оперативную память. На текущем этапе MPP наиболее общепризнанный
вариант архитектуры решения для аналитической обработки больших объемов данных. Дальше здесь
несколько слайдов по тому, как это опять же структурно может выглядеть. То есть у нас есть
какой-то мастер процесс и несколько процессов ему, словно говоря, подчиненных. Мы соответственно
внутри наших подчиненных процессов можем сделать таблицу, распределенную за счет команды
distributed by, распределенную по узлам и распределенную определенным образом. То есть опять же мы можем
равномерно распределять по ID-шнику, неравномерно распределять по иным каким-то полям нашей
таблицы. И дальше у нас мы будем, ну не мы уже, а сама система за счет внутренних алгоритмов
соединения таблиц. А сливание данных будет у нас выдавать результаты из разных узлов внутри мастер
процесса. Опять же, да, мы, зная, как распределены наши данные по серверам, по узлам системы,
можем делать чуть более расширенные и продвинутые запросы, можем конкретно указывать узлы либо
полагаться на автоматическое распределение запросов в рамках какой-то статистики нашей
системы. И таким образом у нас оптимально получается обрабатывать данные из разных узлов. Есть
определенные проблемы, связанные с тем, что есть проблемы и положительные стороны, то есть с одной
стороны у нас может быть положительная сторона в том, что данные распределены и данные у нас будут
подтягиваться из, там, не знаю, 99% узлов при отказе одного узла. То есть мы корректно на
99% данные получить сможем, а с другой стороны, если будут отказывать какие-то мастер процессы,
то возникают проблемы с точки зрения получения результата. Но, опять же, это все применимое
к отдельно существующим базам данных. Если мы их крутим на одном сервере, на одном процессе,
это все может полететь или не полететь, если у нас что-то друг откажет. Дублирование процессов,
не только на нижнем уровне, но и на уровне мастер процессов происходит и в рамках МПП,
за счет того, что у нас отдельные процессы, отдельная память, мы не получаем каких-то проблем,
связанных с дошумлением общего пространства в случае отказа тех или иных узлов. У нас,
тем не менее, остальные узлы работают независимо, и если какие-то узлы отказали,
остальная система теоретически должна поддерживать независимую работу и работать
корректно. Возвращаемся к нашей схеме. Мы уже подошли к этапу составления отчетности
ОЛЭП-приложений, то есть к крайней правой части слайдов. Для конечных пользователей,
соответственно, в рамках концепции хранилищ разрабатываются user-friendly, что называется,
какие-то интерфейсы, где не факт, что пользователи даже будут работать с SQL языком запросов,
может быть, там просто будут реализованы кнопочные, скажем так, запросы или запросы
из каких-то содержательных форм, содержательных для пользователей форм. Приложение ОЛЭП,
это, по большому счету, то, что относится к витринам данных, то есть это приложение
для онлайн, вернее, analytical processing, то есть аналитическая обработка в режиме онлайн.
Там они характеризуются такого рода приложения небольшим количеством одновременных операций,
но операция одновременно затрагивает большое количество объектов базы данных,
запросы могут выполняться при этом сколь угодно долго. Почему так? Потому что нам, может быть,
не очень важно, скорее всего, при обработке данных, быстрота. Мы можем, грубо говоря,
отчет наш запланировать, а запланировать внесение данных, внесение транзакций в базу несколько
сложнее. Конечно, тоже есть статистика, когда пользователи активны или когда рабочий день
начинается и заканчивается и так далее, но на практике OLTP, то есть антипод ОЛЭП,
OLTP онлайн, прошу прощения, transaction processing, он характеризуется именно большим количеством
операций, большим количеством одновременно совершаемых операций и их небольшими объемами,
что ли, скажем условно говоря. А ОЛЭП, наоборот, одновременно мы вряд ли будем часто обращаться
к серверу DWH, мы, скорее всего, возьмем выкраску какую-то по срезу, возможно, по большому срезу,
и будем ее как-то вертеть внутри нашего ОЛЭП-приложения. И что еще? Новые данные не
создаются у нас при этом, данные у нас не могут удаляться, создаются новые расчетные атрибуты,
создаются историчные издачения атрибутов, данные статичны. То есть,
получается, что версионность у нас происходит тоже и в ОЛЭП-приложениях может иметь место
быть, но эта версионность такая вот по интересантам. Мы взяли срез, повторюсь, из нашего DWH по
продажам и по ставкам срез в количественном и стоимостьном выражении, отдали его финдиректору,
он со своими помощниками что-то в ОЛЭП-приложении своем смотрит, крутит, вертит, через какие-то
алгоритмы пропускает, строит модели, тестирует их на основе этих данных. Понятно, что он их не
меняет, он к ним ничего не дописывает, он в DWH не отправляет информацию о своих операциях,
потому что ему этого не нужно, у его операции это построение чудностей, построение планов,
которые меняются на основании этих данных, которые он получает и так далее. И многомерный анализ
ОЛЭП, что это значит, что это позже мы возвращаемся трефреном к Ральфу Кимбалу с его концепцией
Dimensional Modeling, то есть измерение в данном случае, вернее многомерность в данном случае,
речь идет о том, что вот эти вот данные в какой-то таблице, это по сути дела некое измерение и
многомерный анализ, речь о том, чтобы исследуем данные из множества возможно таблиц. Опять же у
нас в DWH не обязательно, повторюсь, какая-то одна таблица фактов и там, не знаю, пять таблиц измерения,
у нас может быть куча таблиц, таблиц фактов, и у каждой может быть некоторое количество измерений,
и у каждой может быть, если эта схема снежинка условная, большое количество суп измерений,
а если мы вообще не используем концепцию Кимбала, а идем от Инмана или вообще строим что-то свое,
у нас может быть сколько угодно сложное внутри хранилища данных, сколько угодно много таблиц,
сколько угодно много различных данных в хранилище может храниться. Олэп-приложения,
они направлены на повышение производительности при работе с данными, на уменьшение нагрузки на
хранилище соответственно, а на создание, ну, единая версия правды, это такая вот условно тоже
концептуальная вещь, что в рамках Олэпа у нас какой-то срез наших данных, который на данный
момент правдив истинен, и мы можем на этой основе формировать осмысленные отчеты и строить планы.
Реализация семантического слоя, то есть мы предоставляем конечному пользователю,
как администратор системы, мы предоставляем конечному пользователю не окно, с которым он
может SQL-запрос написать, как вот, не знаю, в pg-админе, например, если брать утилиту,
позыгры со стандартную, а мы предоставляем вот то, что было на картинке раньше на слайде
представлено, какой-то вот более юзер-френдли, более интересный там графический и более понятный
неспециалисту интерфейс, которым он может там какие-то кнопочки отжать, какие-то поля выбрать,
и таким образом сделать запрос, который трансформируется уже, возможно, и скорее
всего в SQL запрос под капотом системы. Да, ну вот тоже такое графическое изображение,
что такое семантический слой, то есть хочу посмотреть текущий баланс в разбивке по типу
счета, и вот как это все приложение OLAP переводит в семантику SQL. В основе OLAP лежит понятие
гиперкуба, но это тоже больше концепции, чем какая-то структура прям четко выверенная. Каждая
грань здесь, это, как вы уже могли догадаться, это та самая табличка, пресловутая в понимании
релиционных баз данных, пресловутая наше отношение. По сути дела, просто отношения,
соединенные по каким-то атрибутам, пересечению каких-то атрибутов, каких-то данных, и вот
формирует такой, в данном случае трехмерный показан куб, но пересечений по данным может
быть сильно больше, поэтому гиперкуб, то есть не ограничен трехмерным измерением.
