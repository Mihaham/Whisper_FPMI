Сегодня у нас будет лекция от в формате онлайн. Немного необычный формат,
но надеюсь, что непривычный для конкретно этого курса. Надеюсь, что какие-то основные моменты
мы не упустим. Начну я, наверное, с обещанного примера, который называется Multi-Level Monte Carlo.
Лекция 8.
Первая тема, которую мы пройдем. Multi-Level Monte Carlo.
Monte Carlo. На русском языке это пишется через Defic Monte Carlo, а на английском просто Monte Carlo.
Такая традиция. То, что мы будем сейчас рассказывать, это работа где-то 20-летней
давности. Ну, может быть, плюс-минус, я так точно уж не скажу. Майкла Гайлса.
Извините, у меня сейчас лекция. Да, я сейчас все сделаю, я помню. Свет выключу.
Спасибо. Прошу прощения. Мы берем стахастическое дифференциальное уравнение.
Dspdt равняется a sat t. В общем виде записанное. Это, так называемый, диффузионный процесс.
Некая коэффициент b. Иногда его sigma обозначают. В общем там непринципиально.
В самом общем виде и wat это Винеровский процесс. Вот это есть объект изучения наш.
Ну, можно как-то задать точку старта s от нуля. Допустим, равняется s0. Можно
считать ее не случайно, это сейчас не очень важно. Ну и, в общем, интересоваться поведением
траектории этого процесса на промежутке времени от нуля до t большого. В чем задача? Задача заключается
в том, чтобы посчитать мат ожидания, то есть вот некое число y, которое есть мат ожидания f от s от t.
То есть есть какая-то функция, которая, например, есть цена опционы или там, я не знаю,
фьючерса, еще что-то, которое зависит от цены акции. Цена акции, в свою очередь, подчиняется
вот такому вот стахастическому дифференциальному уравнению. И, ну, например, для, действительно,
для классической постановки здесь просто будет s от t, ну такой вот, а здесь постоянная sigma.
Ну то есть, прошу прощения, непостоянная sigma здесь будет ну как бы а на s от t, а здесь будет
sigma, константы на s от t, то есть это все константы. Ну то есть от t они не зависят, а от s от t они
зависят линейно. Но это для вот так называемого геометрического броновского движения будет так
получаться. Так вот наша цель посчитать мат ожидания. Есть две схемы. Первая схема это схема
Эйлера и, в общем-то, в каком-то смысле вычисления в лоб. Ну вот вычисления в лоб это значит,
что мы берем как бы сетку. Значит сетка берется ну вот точками значит 1 и так далее t на h,
t большой на h, h это шаг сетки, шаг сетки, шаг сетки. И пытаемся аппроксимировать вот этот вот
стог дифур, пытаемся аппроксимировать его в дискретном времени, шаг сетки. Вот мы разбили
промежуток времени от нуля до t большого, от нуля вот на такие вот промежуточки, длина которых,
ну соответственно произвольного отрезочка h. Ну и говорим, что соответственно накатом промежутки,
накатом отрезки вот у нас значение вот этой величины будет sk. Но чтобы не путать это с
настоящим значением, мы будем сверху ставить крышечку. То есть мы можем написать такую динамику
s с крышечкой k плюс 1 равняется s с крышечкой k плюс a на s с крышечкой k на tk на дельта t ну дельта
t понятно чему равно, оно равно h вот в нашем случае плюс соответственно b на s с крышечкой k на tk на
дельта wk. Ну чему равняется дельта wk, наверное тоже более-менее понятно, это есть w в точке как бы
объяснить, отвечающем как бы kk плюс 1 минус wk. Ну и все наши обозначения, это на самом деле вот
если так вот как бы пытаться аппроксимировать, что это должно аппроксимировать, то можно это
понимать так, что w как бы от h на k это вот wk, ну и s от h на k это вот s с крышечкой k. То есть мы
вот значит надеемся, что есть какое-то такое соответствие. Но вообще говоря, это просто
отдельная история, просто какой-то отдельный процесс. Ну и если вот скажем здесь я могу
писать на самом деле точное равенство, просто считаю, что у меня вот здесь равенство, ну какой-то
Винеровский процесс, так вот он, ну хотя тоже нет на самом деле, на самом деле конечно это так тоже
нельзя писать точно, это как бы мы хотим, чтобы это было как-то похоже. То вот надежда на то,
что вот это вот дело, которое я обвожу, будет неплохо аппроксимировать вот это вот дело.
Ну и значит в итоге, если мы сделаем таких траекторий много, то есть мы возьмем,
значит я даже другим цветом выделю и здесь запишем индекс i и сделаем такие независимые
траектории. Ну то есть в принципе, если это iid, то есть каждый раз вы независима. Ну по сути
речь идет о независимости вот этого блока, вот этого блока. Потому что, по сути, если это независимо,
все остальное как бы порождено независимостью процесса вот этого. То мы можем в принципе оценить
интересующую нас величину, которую мы назвали y. Напомню, что y этому от ожидания, вот она написана,
этому от ожидания f от st в конечном момент времени. Ну мы можем оценить тогда, например,
так, если возьмем n число траектории. Значит это есть от 1 до i, от 1 до n. Ну f от то, что получается
s крышкой. Ну в последний момент времени, я не знаю, как мы его там обозначали, ну t на h,
то есть мы не ввели никакого специального обозначения. Вот мы использовали t на h,
ну значит ничего не остается, как написать t на h. Вот t на h. Вот что получается, естественно,
тут i. И эта вот независимость вот этих вот реализаций порождает независимость траектории,
значит это должно быть хорошей величиной. То есть закон больших чисел для нее должен выполняться,
или там центрально-предельная теорема. Ну то есть это означает, что существуют такие константы c1,
c2 больше нуля. Такие что, значит, вот это вот мат ожидания y. Давайте только это y
с чертой назовем, y настоящего минус y с чертой в квадрате. Вот, естественно, это все под мат
ожиданием. Что это будет иметь вид c1 на n-1. Это вот как раз следствие того, что вот дисперсия вот
этой случайной величины, а это и есть дисперсия, но она пропорциональна 1 на n. Ну с каким-то
коэффициентом пропорциональности, который зависит от свойств функции. Но это еще не все. Это так
было бы, если бы тут были независимые траектории реально этого метода. То есть если бы мы реально
запускали независимые траектории, так что-то я стер. Если бы мы реально запускали независимые
траектории, то этим бы делом все и ограничилось. Тогда было бы просто вот такая формула и все. Но
у нас не совсем такие траектории. У нас траектории, которые опроксимирующие систему. Ну не сложно
сообразить, что если шаг h, то по сути речь идет о схеме опроксимации Эллера. И если t у нас
ну не какой-то большой, мы там не сильно думаем о том, что вот этот вот фактор c2 там может зависеть
от t как e в степени t. Нас сейчас это не интересует. Мы просто говорим, что c2 да от t зависище, но как нас
не сильно волнует. Нам важно, что от h какая зависимость. То понятно, что bias, смещение,
которое дает эта схема разностная, подобно тому, как это оценивается в чистых методах оптимизации.
Так вот этот bias как раз он просто пропорционален h. Но это значит, что когда мы будем возводить
в квадрат этот bias, он же не случайный, мы получим просто h2. То есть подобно тому, как в
вычислительной математике мы имеем результат о том, что схема Эллера имеет порядок опроксимации
h, то при тех же предположениях липшцевости мы получаем вот такую вот формулу. Ну ясно дальше,
что если от нас требуется, чтобы вот эта вся штука равнялась ε2, то есть мы хотим
опроксимировать, чтобы у с чертой у отличались в ε1. Это значит, что вот эту штуку надо сделать
масштаба, ну как бы разница у и минус у с чертой, она характеризуется по сути корнем из как бы
корнем из вот этого вот выражения у минус у с чертой в квадрате. Мы хотим, чтобы это было
Эпсилон. Вот отсюда следует, что во-первых n должно быть пропорционально Эпсилон минус значит
второй вот, потому что иначе мы не получим значит вот вот вот тут Эпсилон. Ну и второй
результат, который нужно тут сделать, что h равняется пропорционально Эпсилон. Ну и тогда
общее число вычислений значит если хотите вот таких вот шагов, то есть по сути по сути
сэмплирований сэмплирований гауссовского вот это винеровского блуждания, то таких сэмплирований
надо сделать и соответствующих вычислений вот которые здесь стоят вот этого дела. Их надо
сделать то столько сколько итераций, ну не итерации а сэмплов, ну что естественно сэмплов 1 на
Эпсилон квадрате. И соответственно понимать, что на каждом на каждом вот этом вот траектории нам
еще один на Эпсилон. Итерации надо сделать, потому что это t на h, h пропорционально Эпсилон. Значит
итогов получается total от Эпсилон равняется n умножить на t на h, ну и это пропорционально Эпсилон
минус треть. Можно ли эту оценку улучшить? Вот в этом вопрос, то есть вопрос, который правильно
тут задать, можно ли улучшить? Можно ли сделать лучше? Можно ли сделать лучше? Сделать лучше? Ну
вообще такой довольно частный вопрос, потому что вроде как кажется, что это какая-то не очень
важная задача. На самом деле ничего подобного, огромное количество задач финансовой математики,
это вот в общем задачи, ну оценки финансовых инструментов, это как раз вот как это делать,
то что вот я написал, то есть решать вот такую задачу. То есть это не то что не частный вопрос,
это один из преугольных таких вопросов, главных вообще много где. И вот собственно то, что я хочу
рассказать, это схема Гайлса, который называется метод multilevel Monte Carlo, который более изощренный,
более хитрый и позволяет фактически выиграть одну размерность по Эпсилон, то есть Эпсилон минус
второй получить результат, что достаточно в общем оптимистично на мой взгляд. Вот ну то есть
в общем-то немножко даже неожиданно. Для того чтобы значит этот результат получить, значит схема
Гайлса, схема M. Гайлса. Делается следующее, то есть у нас уже сделано обозначение, вот я напомню его,
это вот что такое вот такая вот траектория. Только здесь важно понимать с каким шагом мы идем.
Вот и давайте мы сделаем значит следующее, мы сделаем набор шагов HL, которая есть значит просто
вот такая формула. T делить на некая константа E, ну и просто умножить на M в степени минус L.
Ну то есть например если H0 выбирается, да, то например H0 это просто T, то есть шаг вообще
ну как бы совпадает с последней точкой, то есть мы H0 берем вот собственно 0T. Значит H1 получается
T делить на M, ну и получается вот у нас здесь M, M засечек на отрезке 0T. Если мы делаем шаг,
который например H2 равняется T на M в квадрате, да, то получается засечек сильно больше. То есть
засечек будет M в квадрате от 0 до T. Ну я думаю понятно схема, ну и соответственно каждому такому
HL мы ставим в соответствие S, крышка, значит и ну тоже как бы разные реализации на T на HL.
Ну по идее я еще должен был конечно здесь пояснить, что сама процедура идет шагом H,
то есть по сути вот здесь дельта T берется как HL. Ну и соответствующая разница вот этих вот значений,
то есть это что такое? Это просто берется значение Винеровского процесса в точке,
ну или если хотите, на самом деле это на практике сэмплируется не так. На практике просто берется
нормальная случайная величина с мат ожиданием 0 и дисперсией H, H просто и все. То есть вместо того,
чтобы реально как бы гонять тиректорию случайного процесса, мы просто берем эту разницу, мы знаем,
что она должна распределена быть по N0H, N нормальное распределение, H дисперсия,
ну и сэмплируем собственно из нее. Вот собственно этим фактом мы пользуемся и каждый раз это делаем
IID, независимо одинаково распределенными вот эти вот величины. Ну и в общем-то понятно,
что нам просто надо уметь сэмплировать стандартные нормальные, не стандартные, а нормальные случайные
величины вот с такой дисперсией. И по-хорошему я должен конечно здесь как-то вот зашивать,
что от H зависит. Но я думаю, что не будет недоразумения, чтобы громоздкими не делать
обозначения. Я просто буду обозначать вот так результат, который получается еще раз, вот это вот,
это есть результат, который получается вот в данном процессе, вот в данном процессе, когда H равняется
HL, то есть H тут равняется HL. Ну вот тогда это мы будем обозначать выход, то есть в выходную точку,
мы будем обозначать просто скорректировав HL. Ну вот так. Ну и таких схем. Но теперь нам
хочется по-другому оценивать Y, а именно мы хотим оценивать Y следующим образом,
как Y с чертой равняется сумма YL, L от 0 до L, мы подберем это L, где, соответственно,
Y0 равняется 1 на N0, мы подберем эти числа, значит сумма по И от 1 до N0 на F от, соответственно,
S с крышкой И на T на H0. Вот это просто вот то, что получается, если делать вот такую вот схему,
то есть просто за один шаг. Но это довольно дурацкая оценка, но тем не менее вот мы ее вводим.
Ну и дальше вводим YL с чертой, естественно, это все. Вот YL с чертой равняется уже более
что-то интересной единице на NL, это то, что на L там шаге, значит, подбирается сумма по И от 1 до NL.
И вот здесь стоит такая разница F от S с крышкой И T H, соответственно, L, а здесь стоит минус F,
S с крышкой и T на H на L-1. Вот такая разница. Обратите внимание, что мы считаем среднеаррифметическое
таких вот траекторий, но как бы теперь мы делаем проход с разными шагами, то есть мы берем,
как бы сказать, то есть мы берем траекторию вот с шагом с каким-то вот, не знаю, там HL и HL-1,
то есть по сути вот с таким шагом и вот с таким шагом. И проходим на одной реализации с этими
траекториями. Просто считаем две разницы. Считаем вот такую величину и вот такую величину,
но как бы на одной траектории. И также делаем для всех L, то есть это L от 1 до некого L.
Что можно сказать про эти схемы, про вот эту схему? Ясно, что есть телескопическое свойство,
вообще говоря. То есть во всяком случае мы как бы тут надеемся, что есть такая вот,
что ли, то есть то, что мы здесь посчитали, должно сократиться с тем, что в каком-то смысле вот с
тем, что здесь будет. Ну и так они будут друг на друга, то есть оценки должны быть, но если не в
точности, то хотя бы вот по порядку должны как-то соответствовать вот этому делу. Ну вот оказывается,
что bias, который получается от такой формулы, ну то есть bias имеется в виду, что мы берем от
ожидания, ну от y с чертой минус y, но только нам интересно, значит модуль этого величины, он будет,
вот для такой формулы, он будет о большой от a shale, где a shale это последняя точка. То есть почему?
Потому что просто траектория, которые здесь вылезают, они, как сказать, ну то есть как бы вот тот bias,
который, вот эта грубость, которая вот тут есть, она сокращается вот с траекторией, которая здесь,
то есть у нас будет наблюдаться, соответственно, что ли такой эффект, ну что ли телескопичность,
о котором я уже говорил, то есть фактически, самая, так сказать, последняя составляющая,
то есть та, которая в сумме идет с плюсом, она и будет давать вклад, а все остальные вклады давать
не будут, то есть a shale это вот как бы, как объяснить, ну из-за того, что у нас формула вот такая,
вот мы редуцируем на самом деле вот эту байсную часть, опираясь фактически на последнее слагаемое.
Ну с дисперсией тут ситуация немножко сложнее, чем была в предыдущей истории, потому что дисперсия,
ну я знаю, давайте d назовем это, вот, она же считается вот от этой штуки s с крышкой,
значит, соответственно, и на t на shale, и потом надо будет еще нормировать на число слагаемых,
ну потому что у нас среднее арифметическое берется, значит s с крышкой, и вот здесь будет f,
значит, прошу прощения, надо аккуратно сделать, f s с крышкой и на t на shale минус 1, shale минус 1,
и просто по построению, как мы это сделали, у нас эта дисперсия, она определяется масштабом вот
в этой схеме, масштабом дисперсии вот этой случайности, которая тут есть, то есть,
как бы масштаб неточности, который есть на этой траектории, он будет иметь масштаб вот этого h,
потому что это есть дисперсия, это именно дисперсия вот этой вот штуки, ну и мы получаем,
что дисперсия вот всей этой разницы, ну которая на последней точке, это будет что-то,
о большое какое-то от тоже, ну в данном случае, shale, потому что здесь вот берется, shale не последняя,
а она как бы промежуточная, ну и чтобы посчитать дисперсию уже оценки dy с чертой, чтобы посчитать
оценку dysперсии y с чертой, нам надо, значит, сделать следующее, нам надо просуммировать вот эти
вот дисперсии vl, умножить каждую из них на nl минус 1, потому что здесь есть вот такая вот
нормировка, ну и суммировать это от l до единицы до l большого, ну и заметить, что в данном случае
средне квадратичное отклонение, которое мы до этого считали, ну вот я напомню, давайте введем
для него обозначение mse, вот это mse, я сейчас перепишу, mse равняется мат ожидания, ну там,
значит, это у меня, да, квадрат, значит, это есть модуль y минус y с чертой, там, я не знаю,
модуля как ставил, но можно, конечно, их, да, тут раз квадрат ставится, модуль можно не ставить,
значит, это квадрат, ну и в данном случае это есть bias в квадрате, значит, это есть bias в квадрате,
плюс вот эта дисперсия y с чертой, ну и, естественно, мы должны тоже требовать,
чтобы это было, как и раньше, имело масштаб epsilon в квадрате, раньше мы это требовали неявно,
вот как бы корень не равняется epsilon, ну значит, это должно равняться epsilon в квадрате, вот, то есть,
мы отсюда и находили всякие вот выражения, но теперь, значит, что это означает, это означает,
что первое условие, что bias должен равняться epsilon, то что bias должен равняться epsilon,
ну по порядку, да, означает, что h, ну то есть, o большое от hl должно равняться epsilon,
ну o большое от hl это есть, значит, t на h в степени, не h, а что там у нас, m,
m в степени минус l, ну m мы можем условно выбрать, не знаю, двойкой, там это неважно, это просто какое-то
число, вот, поэтому мы отсюда можем заключить, что l большое должно равняться по порядку, значит,
логарифм epsilon минус первое на логарифм делить m какое-то, ну, то есть, по порядку это
всё логарифм epsilon минус первое, вот, что такое l большое, теперь с дисперсией разбираемся,
дисперсия y с чертой, она уже нами была выписана, но мы же можем подставить, что есть vl,
и vl есть вот эта штука hl, ну, значит, дисперсия y с чертой, она, во-первых,
равняется, как я уже писал, nl в минус первый на vl сумма по l от 1 до l большого, ну, и значит,
это пропорционально сумма по l от 1 до, ну, только не от 1, от нуля, от нуля, тут, надеюсь,
я тоже написал, от нуля надо писать, от нуля до l большого, значит, вот, пишу nl минус первое на
vl, и тоже хочу, чтобы это было пропорционально epsilon квадрате, теперь напишем, что такое total,
но total теперь оно считается посложнее, потому что у нас как бы вот, как устроена схема,
мы делаем единицы, мы делаем nl, nl сэмплов с шагом hl, да, поэтому нам надо как бы суммировать,
то есть total будет равняться nl на hl минус первое, это значит nl, это сколько сэмплов делается,
сколько сэмплов, а hl минус первое, сколько на траекторию попадает, ну, на значение,
то есть это как бы стоимость одной траектории, вот, это l тоже суммируется от нуля до l,
значит, нам надо решать задачу, вот это вот на минимум, при условии, что l равна
пропорционально log минус epsilon минус первое, при ограничении, вот это и звездочка, то есть при
ограничении, что сумма nl минус первое на vl имеет масштаб epsilon квадрате, вот, значит,
пропорционально epsilon квадрате l от нуля до l большого, вот, надо решать такую задачу оптимизации,
вот, ну и можно эту задачу отрешать и получить, что nl равняется, там, о, большое, значит,
epsilon минус второе l на hl, вот, вот какое будет у него решение, ну и тогда, если это решение
подставить, значит, в total, то total epsilon будет равняться, значит, ну, естественно,
большое от epsilon минус второй на логариф в квадрате epsilon минус первое, ну, то есть вы получаете
как бы такой эффект, что, сделав вот такую хитрую схему, о которой я сейчас сказал,
хитрую схему, ну, вот, связанную с, значит, ну, со специальным сэмплированием, то есть со специальной
генерацией траектории, вот, мы, извините меня, до 20-30, да, ну, до 8-30 занятий, я, я, я сотру все,
да, сам сотру все, да, извините меня, лекция, я могу продолжить, да, спасибо, значит, прошу
прощения, да, что, значит, отвлекся, так вот, у нас получается два результата, вот этот вот результат,
это было до этого, как бы классика, то есть просто обычная стандартный подход, ну, и если мы начинаем
хитрить, то есть мы начинаем, значит, вычислять уже по другой схеме, то есть мы сэмплируем как бы,
видите, тут размер сэмпла, он меняется, то есть nl, давайте посмотрим на результат,
который получился, у нас в принципе получается, что ε-2, оно всегда сидит в сэмплах, но обратите
внимание, что тут присутствует ашель, и, например, если l равняется нулю, то это просто
ε-2, а вот если это уже там, не знаю, ну, короче говоря, ашель растет с геометрической,
ну, бывает точнее, с геометрической прогрессией, то есть вы как бы в каком-то смысле, вот эта ашель,
давайте еще раз посмотрим, чему она равняется, вы его все убываете, убываете, убываете,
убываете до момента, когда ашель просто станет пропорционально ε, значит, это означает, что вот
эта nl, которая здесь стоит, оно изначально было ε-2, а уже под конец вы можете сэмплить все,
все как бы меньше и меньше, то есть вы в этом вот выражении берете размер сэмпла, а меньше,
на этом идет некоторая игра, то есть не надо каждый раз сэмплировать ε-2, и заметьте,
что число таких итераций, оно тоже вот как бы логарифмическое, то есть в смысле не тоже,
а как бы оно логарифмическое, это позволяет потерять не сильно много, потерять вот логарифм,
и это вот специальная такая схема, довольно эффективная, ее сейчас активная, но не сейчас,
уже там давно, то есть это была такая кульминация финансовой математики где-то лет 15 назад,
вот был относительный бум, может даже поменьше, побольше времени, для 20 назад, ну где-то так,
20-15 лет назад было очень популярно все это, вот, и вот такими вещами люди активно занимались,
это порождало, значит, вот такие вот исследования, ну вот к чему это приводило,
я здесь описал некоторые результаты, вот, по-моему довольно интересно, значит понятно,
что я не очень аккуратно всю эту схему обосновал, она требует, ну на самом деле более
стругих доказательств, но качественно, я надеюсь, что вы более-менее поняли, значит,
о чем идет речь, вот, ну, собственно, наверное, про multilevel Monte Carlo у меня все, если какие-то
вопросы. То есть единственная разница, что раньше мы били на одинаково маленькие кусочки, теперь мы
как бы сначала одно разбиение, потом другое, потом третий и так далее. Да, ну, то есть раньше мы
использовали одну схему, то есть мы использовали схему с постоянным шагом, то есть h было одинаково
для всех реализаций, то есть сделав большое количество реализаций, вы делали все их на одном шаге,
а теперь мы действуем по-другому, мы делаем схемы с разным шагом и оцениваем вот это y по одной
схеме, потом этот y оцениваем по другой схеме, ну и делаем это еще вот, как бы сказать, вот с такой
разностью, чтобы был какой-то эффект, ну, эффект одной траектории, что ли, что на одной траектории у
нас в принципе, как объяснить, ну, ну, то есть мы, мы теряем, что ли, вот эту проблему большого
байса за счет вот, за счет того, что фактически все сводится к тому, что там на последней траектории,
потому что есть некоторая такая телескопичность этих вот, значит, дел, ну, потому что когда мы
говорим о байсе, мы по сути, то есть нам не важно, что тут разный показатель 1 на 0, 1 на nl, для нас важно
в среднем, что это такое, то есть вы, конечно, можете посчитать, какой байс будет вот здесь,
но ровно такой же байс будет, если возьмете мат ожидания от этой штуки, которая будет сокращаться
вот с этим по байсу, не по дисперсии, еще раз, здесь очень важно понимать, что мы специально разделяем
байс и variance, и вот по байсу вы как бы берете, считаете какую-то величину, ну блин, она очень грубая,
то есть здесь как бы байс отдельного слагаемого, он ужасен, потому что, ну, понятно, что если вы
будете байс y0 считать, он там колоссальный, потому что у вас шаг имеет сетка h0, она
совпадает с t, у вас одна интерация происходит, и это глупый метод, если бы так делали, но вы сделали
хитрее, вы как бы вот эту штуку вот сюда засунули, это еще очень важный момент, и поэтому,
когда вы будете считать у мат ожидания вот этой штуке, а потом мат ожидания вот этой штуки,
то мат ожидания вот этой штуки будут в точности равно мат ожидания вот этой штуки,
оно сократится, но при этом, как бы вот то что вы считаете на одной траектории, вот эту разность,
вот эту разность позволяет вам как бы сказать дисперсию вот этой штуке
определять ну и точнее вот всякие ее характеристики вот связаны с отклонением
около мат ожидания позволяет вот как раз оценивать эту штуку исходя из
свойств вот этого винаровского ну дефузионного процесса то есть когда вы
берете траекторию то масштаб ее как раз определяется масштаб вот невязкий
который тут приобретается масштаб определяется вот этой вот штукой потому
что это одна траектория то есть как бы объяснить у вас есть траектория и вы ее
берете с частотой 2 исчезну то есть просто делите на отрезки да а потом в
два раза чаще эти отрезки делаете и как бы расхождение этих траектории ну
грубо говоря потому что масштаб вот вот как бы масштаб именно вот с точки
зрения случайности дисперсии он вот такой вот это вы наблюдаете вот в этом
месте то есть это просто все так специально подобрана то есть вот вот в
этом месте вы наблюдаете что масштаб у атошель потому что это одна траектория
просто в одном случае шаги в два раза чаще чем в другом и за счет вот
специфики то сказать ну это вот такое несложно упражнение вы можете проверить
что и это и это верно все остальное дело техники как только вы догадались да вот
такой конструкции, ну все, победа. Дальше вы можете просто подбирать, исходя из требования,
вот то, что надо, то есть просто действительно поставить задачу оптимизации, как подобрать,
ну распорядиться той степенью свободы, которая есть. Ну понятно, что L это уже не степень свободы,
вы однозначно ее определяете, но еще осталась степень свободы с выбором размеров сэмплов.
Ну вот ими вы и распоряжаетесь так, чтобы наилучшим образом это все стало. Ну вот-ка,
что это получится? Это надо уже считать, вот можно посчитать, что будет так. То есть на самом деле это
достаточно такой необычный сюжет, но повторю, требует более аккуратного обоснования. Ну если
с байсом еще тут все как-то совсем очевидно, то уже с variance надо чуть поаккуратнее, конечно,
тут объяснять, почему этот variance равняется у атошель, но более-менее соображение,
вот какие приводят к этому я объяснил. Теперь у нас есть такой сюжет, он называется,
ну я не знаю, в общем есть такая книжка, значит книжка Райгородского литвак. Ну вот название
раздела можно понимать как счетчики с короткой памятью. А М. Райгородский давайте я все-таки
сделаю. Красный цвет. А. М. Райгородский. Нелли Литвак. Ну я не знаю, они пишут без имен,
я к сожалению отчества Нелли Литвак не знаю, поэтому будет А. Райгородский и Н. Литвак. Райгородский.
Очень хорошая книжка, называется математика компьютерного века. Вот, она естественно такая,
ну судя, вот наверное можете судить, потому что формул почти нет. Она написана для, в общем,
широкой аудитории, то есть естественно не для нашего курса, потому что у нас такой продвинутый
как бы курс, вроде там такая продвинутая математика. Но тем не менее, мне бы хотелось вот прям не
залезая в дебри, рассказать вот приблизительно на таком уровне, как в этой книжке написано,
об одном сюжете, вот который здесь вот называется счетчики с короткой памятью. Ну и фактически
речь идет о том, чтобы решить очень такую несложную, на первый взгляд, задачу посчитать,
сколько разных чисел встречается в каком-то массиве чисел, то есть у вас есть массив чисел,
вот не знаю, вот он допустим приведен, и сколько раз тут встречается, ну не сколько раз, а сколько
разных чисел здесь есть. Ну вообще говоря, вот собственно мы как делаем, 15 первый раз встречается,
48 первый раз, 32 первый раз, 31 первый раз, 48 ранее встречалось, но это вот я как бы,
так сказать, иду с точки зрения человеческого мозга, то есть я иду и каким-то образом называю
вам, что ага, значит 50 уже встречалось, у меня в памяти, потому что есть, что 50 уже встречалось,
а как вы это запрограммируете, то есть это что надо делать, все это хранить в памяти каждый раз,
когда появляется новое число, сравнивать со всеми, которые до этого были, то есть уникальными,
ну знаете, это очень долго, потому что если действительно вы имеете огромный массив,
например, айпи адресов, и значит вам интересно, сколько там транзакций с уникальными картами было,
или с айпи, ну и с картами банковскими, или сколько вообще значит айпи адресов там,
на этот сервер уникальных обращалось, да, за n log n это решается, значит это вот в том-те дело,
что нам не хочется, чтобы n вылезало, потому что ну вот комментарий был в чате, что я не хочу,
чтобы это n вылезало, это n огромная размерность, я хочу, чтобы ответ был log log n, чтобы моя
процедура позволяла как-то, может быть, неточно, вероятностно за log log n оценивать,
знаете, вот настолько хорошо, что было, понятно, что это вообще говоря кажется немножко фантастичным,
и явно здесь есть какой-то обман, но вот мы давайте попробуем разобраться, как это возможно,
то есть чтобы n не вылезало уж точно в как бы, как n, ну и даже как логарифм n не здорово,
чтобы оно вылезало, значит еще раз повторю постановку задачи, значит она заключается в том,
чтобы посчитать число уникальных адресов чисел в массиве, огромном массиве из чисел, вот так,
что там еще, а как вообще сделать быстрее, чем за n, если нам нужно минимум n единиц в
времени просто в виде числа, так смотрите, речь идет о том, что, значит, ну, как сказать,
речь идет о памяти, то есть речь идет не о том, сколько мы должны пройти, значит, вот n, да,
мы должны пройти весь массив, это правда, то есть если понимать под сложностью, сколько мы должны
пройти как бы элементов, то массив мы должны пройти, вопрос другом, как бы, как вы это будете
делать, что вы будете использовать, какие вы будете структуру данных создавать и что вы в этих
структурах данных будете хранить, если что с чем сравнивать, то есть сложность задач она измеряется
не только тем, что вы должны как бы n чисел считать, но вы же этого числа не просто считываете,
вы его должны сравнивать соответственно, и как бы вот это, значит, соответственно надо его
хранить все, что у вас есть в памяти или как-то их, может быть, как-то разрежено, но в любом случае
это некоторая проблема, что организовать вычисление таким образом, чтобы и память
была эффективно использована, и время было действительно не сильно больше, чем просто прямой
проход по всем числам, это некоторый челлендж, да, ну вы правы, что конечно пройти-то по всем
числам надо, значит, давайте сначала просто предположим вот для простоты, что эти числа случайные,
что эти числа случайные, ну и какое-то количество чисел там, я не знаю, вот выбросили,
ну в данном случае здесь случайно-равновероятно выбирается число от 1 до 50, да, вот от 1 до 50,
ну вот здесь такая постановка задачи, вот, и дальше мы говорим, что если числа случайные и нам
интересно число уникальных чисел, ну или не обязательно, ну как бы вот просто есть огромный
массив, давайте я как бы нарисую, есть огромный массив данных, и они более-менее случайно
выбираются как от отрезка там от 1 или от 0 до некоторого большого числа, вот эти числа как-то
случайно выбираются, возможно с повторениями возникает вопрос, вот если, значит,
чисел n большое, а наименьшее число, которое встретилось, например, равняется 7, то что можно
сказать относительно того, насколько, не знаю, там не обязательно 7, ну просто какому-то числу равно,
то что можно сказать относительно того, сколько всего было уникальных чисел, но если мы считаем,
что как бы вот эта вот величина, она характерна для, ну поскольку числа случайные,
для, значит, как объяснить-то, ну для равномерного распределения на отрезке,
значит, сказать там, ну то есть вы бросили какое-то количество чисел случайно равномерно,
и какие-то из них повторяются, вот сколько независимых было чисел брошено, которые уникальные,
ну как бы, если совсем по-простому, то эти числа, они ну как-то равномерно лягут, вот да, и по идее,
если они вот действительно совсем по-простому равномерно легли, то вот как раз такой вот отрезочек
позволяет вам оценить, с какой плотностью они легли, то есть если n большое, это число всего
позиции, а у вас остался зазор, вот, например, там 0,7, наверное, вы вправе там ожидать, что n на 7,
да, где-то будет, вот, как бы такое число уникальных величин, но, конечно, это очень грубая идея,
и вообще говоря, на самом деле, конечно, надо делать намного аккуратнее, хитрее алгоритм,
который вот так в таком ключе работает, ну, то есть он просто пытается отследить самое минимальное
число, то есть он идет, значит, по списку и следит за минимальным числом, но вот мы видим в этом списке,
что минимальное число равняется 0,1, и это не работает, ну, то есть вы просто получили 0,1,
и все, а как бы, значит, что у вас по такой стратегии, ну, то есть стратегия простая, каждый раз хранить
в массиве, ну, вот есть как бы ячейка памяти, и мы проходим по вот этим элементам, идем-идем,
и каждый раз записываем вот в эту ячейку памяти самое наименьшее число, пока оно 15,
пока оно 15, но вот в какой-то момент оно стало 0,1, и, собственно, после этого момента оно не меняется,
вот это 0,1, ну, и мы доходим до конца, и мы живем с этим 0,1, вот если эти данные просто какие-то
числа, то такая идея не работает, и вообще говоря, она плохая, но если вы действительно как бы
работаете, ну, так сказать, с нормальной компьютерной программой, то никто не заставляет вас работать с
первозданными IP-адресами, которые есть, или с названиями там, я не знаю, вот как тут пример
у Райгородского, с названиями магазинов там каких-то, ну, или вот сайтов, которые вот посещаются,
вы можете ставить им в соответствие случайный этап значения в некое вот хэш, хэшированием
заниматься, то есть, по сути, как бы просто ставить соответствие каким-то там буквам или каким-то
IP-адресам по определенным правилам, ну, практически вот, можно сказать, случайная независимая величину,
а там, на самом деле, не совсем это как бы делается случайно, то есть, как бы некоторые
закономерности там, в том числе, связанные с теоретико-числовыми какими-то вот вещами,
там это все есть, но нас сейчас это не сильно беспокоит, для нас важно, чтобы мы с хорошим
приближением могли считать, что вот эти вот последовательности условных нулей и единиц,
которые кодируют встречающиеся нам элементы множества, ну, что они в каком-то смысле случайны,
вот в хорошем смысле, вот с хорошей степенью, они вот случайны, каждое число, оно имеет
свой уникальный адрес, понятно, что даже если элементов много, за счет того, что мы как бы
битого, например, кодируем, мы можем очень большие числа закодировать, и длина описания у них
будет не очень большая, ну и дальше, собственно, идея лок-лок вот этого алгоритма Флажале,
вот он Флажале, Филипп Флажале, которая позволила просто некоторую революцию совершить,
во всяких алгоритмах там, в том числе работы в социальных сетях, как там считать число рукопожатия,
тому подобное, вот такого типа вспомогательной задачи там возникают, и идея Флажале заключается в том,
чтобы хранить не просто минимальное число, а хранить минимальное число бит, которые равны нулю,
ну не минимальное, а наоборот максимальное, то есть хранить число бит, которые вот мы идем по списку,
вот первое число, вот второе, вот третье, вот четвертое, вот пятое.
После того как мы посмотрели первое число мы храним 1 бит нулевой, после того как мы посмотрели второе число мы храним
3 бита нулевых, то есть число 3 закодировали, ну потом это число не поменялось, тут оно тоже не
поменялось, ну в конце оно тоже не поменялось, то есть и того, мы имеем, что у нас как-бы минимальные
элемент имеет 3 бита в начале ну то есть это означает что разреженность в среднем одна восьмая
поэтому если у нас есть понимание ну то есть если у нас есть например 8 бит да допустим 8 бит 2
в смысле получается 2 восьмой то с учетом того что у нас первые 3 бита значит как бы
получаются нулевыми ну вот как здесь мы можем рассчитывать на то что число уникальных элементов
повторю очень грубо 2 восьмой на 2 третий понятно что на самом деле там какой-то коридор и так вот
делать как я ну наверное аккуратно надо как-то точнее но во всяком случае с точностью до масштаба
2 вы таким образом оцениваете то есть плюс-минус два раза вы ошибаетесь как бы но это уже хотя
приближенно оценивают число вот с точностью до двойки но это можно дальше уточнять как-то это
все делать более вот эту идею использовать но обратите внимание что вы не просто храните
минимальный элемент а вы даже храните число просто бит которые нулевые в минимальном элементе это
получается поэтому лок-лок того что надо как бы хранить про эти числа знать и замечу что на
самом деле это все действительно ну в общем-то как сказать ну осуществимо на практике то есть
это не есть какая-то такая совершенно выдуманная история и вот что замечательно вот в этой книжке
райгородского литвак приводится очень такой яркий пример как с помощью вот этого алгоритма
удалось компании фейсбук привлекая математиков значит да кстати правильно название хипер лок-лок
этого счетчика как удалось значит ну просто посчитать число рукопожатия среднее число
рукопожатия вот в социальных сетях вот также вот объединяя то есть мы берем каждого человека
складываем его друзей массив вот который и считаем число уникальных друзей потом берем значит
всех друзей друзей складываем массив получаем новый массив но уже можно посчитать сколько именно
друзей через два рукопожатия выкидывая числа уникальных ну как бы мы можем посчитать число
друзей первого ранга число друзей второго ранга ну а ну вот иughtersry посчитается как бы
и вычитанием того сколько у него сколько с какой-то на всякой вершины входят множество друзья первого
второго ранга завыч slides dernier первая ранга и вот вот это возможно считать именно 0 du
в 팀ей она важна потому что один и тот же элемент например через два рукопожатия можно
прийти к этому и через своего другого мы вот дружим в четвером вот я дружу с ним и с ним вот
но они тоже дружат вот с этим еще одним человеком я с ним напрямую не дружу но я к нему через два
рукопожатия могу прийти через своего одного друга и через другого но мне его надо в итоге
учитывать один раз вот это уникальная возможность считать сколько различных элементов множестве она
позволяет вот все это делать за реальное время и с реальной памятью и вот это действительно было
революция к сожалению вот тут написано что флажоле не дожил до момента когда это все набрело ну
так сказать стало вот настолько популярно ему буквально не хватило там несколько лет что вот
в одиннадцатом году и не стало его буквально в тринадцатом году в двенадцатом это уже в общем-то
но вот в четырнадцатом году это было внедрение понимание что это все будет классно работать это
тут уже было в 12-13 году вы можете посмотреть ссылки я эту книжку сброшу и мне кажется это
очень поучительные примеры очень простых идей собственно на похожие идеи много чего вот базируется
мы можете посмотреть это вот есть книжка блюма хопрофта канана то есть это недалеко не единственный
так сказать такой сюжет вокруг вот этой всей темы но он достаточно простой чтобы его за небольшое
время рассказать и удивительным образом он у нас по моему особо никуда не входит ни в какие курсы
такие вот по моему школьникам можно более чем рассказывать вот и в общем-то на этом вот та часть
которая не связана с ну как бы не непосредственно математикой машинного обучения в нашем курсе
но не то чтобы заканчивается в моей части она заканчивается вот еще будет вот в частях там
алексея фролова математика которая не напрямую связана с машинным обучением может быть у
максима рахубы вот у александра но иксана безносикова по многом связана с машинным
обучением и вот теперь у меня цель перейти уже непосредственно к тому что ну давайте мы прям
назовем следуя вот этой книжке которая тоже сброшу вы сможете ее смотреть это называется
алгоритм икс та хасте конвекс оптимизейша но мы конкретно будем на это смотреть сквозь призму
приложение к машинному обучению то есть нас будет интересовать не что-нибудь такое абстрактное
смысле стахастической оптимизации а вот стахастическая оптимизация на службе у машинного
обучения я извиняюсь что тороплюсь потому что ну я даже не столько тороплюсь сколько ну стараюсь
не отвлекаться на какие-то такие детали потому что мне очень хочется успеть вам проговорить вот
всю эту первую главу ну хотя бы как-то концептуально хотя бы до там до concluding remarks то
есть 23 страницы как-то главные моменты вам рассказать на чем строится современное как бы
машинное обучение если смотреть на нее с позиции специалиста постов оптимизации вот мы должны это
прочувствовать очень частично у нас это было уже в курсе ну совсем чуть-чуть когда мы говорили
про принцип максимум правдоподобия вот сейчас наша задача пройтись поэтому всему за оставшийся
ну вот полтора часа пройтись поэтому ну более основательно и начнем мы просто с постановки
задачи стог оптимизации то есть нам интересно задача стог оптимизации вот как она формулируется
минимум некоторые функции при вот где функционал этом от ожидания по кси вот сейчас мы столкнемся
ситуации когда это кси нам как раз будет неизвестно и вот собственно пример вот очень яркий пример я
очень рекомендую как минимум его понять потому что ну с этого все начинается с какого-то совсем
простого примера вот и если он будет понятен дальше будет уже попроще вот эти примеры значит
заключается в следующем у нас есть низ прошу прощения у нас есть неизвестный параметр x звездой
вы видите вот на экране вот он он из множества действительных чисел у нас есть шум который
вот имеет гауссовский закон с параметрами 0 сигма в квадрате и мы можем сэмплить мы можем
сэмплить случайной величины ксика которые есть и к со звездой неизвестный параметр скалярный
плюс шум в общем-то проще схемы по моему пока не придумали ну разве что схемы испытаний
вернули вот с неизвестной вероятностью выпадения орла значит все эти этак а я иди но здесь
расшифровано что это означает ну и поставлена задача оценить оценить к со звездой вот из-за
по вот этим наблюдением то есть по сути построить оценку x с крышкой я не знаю как там это обозначать
вот этой выборке кси катая вот такая типичная задача казалось бы причем здесь тох оптимизация да
то есть еще раз мы начали говорить про анализ данных и начали говорить что анализ данных это вот
об этом но я сразу с места в карьер начал говорить что хорошо давайте рассмотрим конкретную задачу
мат-статистики оценить неизвестный параметр и сразу же привожу задачу оптимизации стох
оптимизации я говорю что меня вот это случайно величина кси имеет мат ожидания смотрите какое
она мат ожидания имеет ну дровно то которое имеет ксикатая то есть я как бы по имея модель вот эту
задав модель я в общем и пользуюсь этим тем что это она такая ну и говорю что вот почему-то
именно квадратичную функцию надо минимизировать и минимум этой функции оказывается то само икса
звездой то есть если мне хочется оценить икса звездой то мне надо решить задачу сток оптимизации
дальше вы уже там можете сами додумывать как решить эту задачу например вот заменив мат
ожидания выборочным средним или каким-то стахастическим градиентным спуском а-ля да
это уже дело 10 самое главное сейчас понять что мы действительно можем заменить задачу оценки
неизвестного параметра задачи сток оптимизации почему это так ну как бы самый простой вариант
ну раскрыть мат ожидания получить соответствующую функцию и проверить что эта функция действительно
достигает минимумов точки икса звездой ничего проще тут как бы доказать не получится вот давайте
это сделаем вот написанная выкладка она следует просто из того что у нас задана
раз закон распределения кси то есть мы считаем квадрат мат ожидания кси он складывается из квадра
из квадрата мат ожидания и соответственно дисперсии ну и вот значит из-за того что тут минус берется
смешанное такое слагаемо то есть я надеюсь что как-то сильно пояснять вот эту выкладку не надо
она довольно очевидно я просто раскрыл квадрат и применил мат ожидания ну как бы сказать каждому
слагаемому ну и воспользовался тем что мат ожидания кси в квадрате это равняется ну как бы
это равняется икс со звездой в квадрате плюс дисперсия в квадрате вот что я сделал почему это
так потому что ну в общем так у меня это определяется дело то есть это как бы мат ожидания плюс дисперсии
хорошо значит это действительно так меня вот эта функция достигает минимума ну что дальше но дальше
можно заметить что мы можем заменить эту задачу вот эту задачу на такую задачу которая просто есть
ну грубо говоря метод монте карло для вот вот этого функционала то есть мы заменяем от ожидания на
выборочное среднее ну и решаем задачу которая получается с выборочным среднем она дает решение
этой задачи дает такую оценку совершенно естественную оценку которую самое начало мы
хотели получить ну то есть как бы интуиция подсказывала что просто надо взять и усреднить
потому что этих нулевой мат ожидания и они взаимокомпенсируются ну и это на самом деле
ну в каком смысле наилучшая оценка с точки зрения минимальности дисперсии в классе несмещённых
оценок ну в общем другой способ решение той же самой задачи вот тут как бы концептуально важно
понимать что заменять мот ожидания выборочном среднем это подход оффлайн то есть это подход
который например позволяет хранить разные ксика на разных устройствах потом как-то они
обмениваются это вот такой как бы распределённый потенциально там всякие параллельные сетапы
а вот это и другая история это история которая в каком смысле онлайн получает информацию
о выборке то есть ксика это элемент выборки она берет вводит функцию ну то есть мы вводим
функцию f от x которая у нас здесь задана вот это самая функция ф от x кси мы считаем 100
градиент ну то есть по сути мы считаем градиент функции f от x кси по x ну и как бы мотнут градиент
он перестановочен с будет данном случае с взятием мат ожидания потому что распределение кси не
зависит от x ну и мы можем вот записать какой-нибудь такой процедуры сгд и заметить что она приводит
вот если именно так выбрать шаги то она приводит ровно к такой же оценке после n итерации ну то
есть последняя точка этой процедуры даже не надо брать средне арифметическое но она даст ровно ровно
оценку 1 4 то есть вот как бы две дороги приводящие к одному результату только в одном случае нам
потребовалось как бы формально решать задачу оптимизации в другом случае никакую задачу
оптимизации решать не надо и мы просто корректируем это называется агрегирование оценки то есть мы
агри как бы сказать по мере получения информации корректируем свое текущее представление об оценке
и когда у нас произойдет что мы всю выборку про просмотрим но только тут выборка обозначается
вот стоит обратить внимание что она вот как бы пошла с этого дела с как бы с нуля мы немножко
сдвинули это все вот то есть здесь как объяснить ну просто дань традиции что итерации чистых
методов часто с нуля обозначают но а тут с нуля неудобно суммировать вот поэтому тут ну может
быть тут даже на напечатка есть потому что здесь кси 0 кси 1 а потом к седин они неодинаковые то
есть здесь здесь просто сдвиг здесь надо было написать ксикап плюс 1 но это не важно да то есть
здесь можно было написать ксика плюс 11 ты сейчас это я потом исправлю вот в итоге версия пришлю вам
правильно вот то есть мы получается две дороги рассмотрели которые ведут в одну в одно направление
Но возникает вопрос, а почему это функция квадрат?
Как я угадал?
Как я смог взять и сразу сказать, что это квадрат?
Хочется этот момент не оставлять за скобками,
потому что он и есть главный на самом деле,
а не то, что нам повезло.
Наверное, всегда можно что-нибудь такое подобрать.
И возникает вопрос сразу, а как это подбирать?
Единственное ли это?
Как наилучшим образом это подбирать?
И вот мы сразу переходим к тому, что у нас задача вот этой есть.
В этой задаче у нас есть плотность распределения случайной величины кси.
Обратите внимание, что здесь сидит квадрат.
Вот ровно тот квадрат, который сидит вот здесь, вот здесь, вот здесь.
Наверное, это не случайно.
Действительно, давайте заметим следующее,
что если взять функцию плотности, вероятности,
что имеет место х, а выпадет кс.
То есть что это такое? Что вот тут написано?
Это вероятность того, что мы пронаблюдаем согласно вот этой вот модели,
мы пронаблюдаем набор случайных величин кс,
если истинное значение параметра х.
То есть если истинное значение параметра х,
какова вероятность того, что мы пронаблюдаем набор значений кс?
Вот это и есть так называемое правдоподобие, likely put.
И дальше, естественно, рождается такая как бы гипотеза,
интуиция, что ну хорошо, вот этот likely put,
он дает нам как бы понимание, что он правдоподобие описывает.
Но если мы хотим, чтобы х каком-то смысле наилучшим образом описывал данные,
то, наверное, это правдоподобие должно быть максимально.
Ну так, по логике, что если вот данные кск при заданном х
имеют наибольшую вероятность,
наверное, этот х как бы наилучшим образом им и соответствует.
Но поэтому мы, ну и поскольку мы любим задачи на минимум,
мы переписываем эту задачу как задачу вот на минимум от логарифма.
Ну какая разница, максимизировать likely put
или минимизировать минус лог likely put.
Лог — это функция монотонная, монотонно возрастающая,
поэтому там, где вот эта штука достигает максимума,
там вот эта штука достигает минимума.
Также я могу выбрать нормировочный множитель, если мне хочется.
Логарифм берется для того, чтобы независимые случайные величины,
их плотность расщепилась в сумму.
Но так если мы сейчас возьмем вот эту плотность,
отдельного слагаемого, напишем эту сумму,
мы как раз получим ту самую задачу, которая и была записана.
То есть мы получим вот такую постановку.
Если мы берем гауссовский модель, мы получим вот такую задачу.
Она соответствует вот этой вот постановке,
за исключением того, что здесь нет слагаемых лишних и нормировочного множителя.
Но поскольку задача — найти точку минимума, а не значение функции,
то мы можем вполне себе позволить все это не писать.
Вот это вот не писать. Нас это не интересует.
Поэтому понятно, откуда квадрат появился в этой задаче.
И вот оказывается, что то, что я вам сейчас рассказал,
это на самом деле общая схема.
Это общая схема, и эта общая схема — она вот откуда следует.
Значит, берем точку х звездой,
которой есть минимизатор вот этого как бы функции правдоподобия.
Только в данном случае, если мы считаем выборку iid,
нам нет необходимости вот это минимизировать.
То есть это уже как бы лишнее.
Ну то и зачем?
У нас есть и так уже то, что надо.
То есть у нас вот это есть, но от того, что я здесь просэмплирую,
у меня как бы ничего не поменяется, у них это одинаково будет.
Это вот задача, когда мы имперический делаем.
Это вот я про имперический говорил, там да, там надо ксикат.
А здесь у нас просто как бы мы исследуем вопрос в теории.
Верно ли, что х со звездой будет принадлежать аркминему вот этой штуке?
Ну действительно, это будет верно,
потому что имеет место неравенство,
которое получается из неотрицательности расстояния кульбока Лебера.
По сути это неравенство Йенсона,
ну или если хотите, неравенство выпуклости.
Неравенство выпуклости функции лагарифм.
То есть если для функции лагарифм вы напишите,
что эта функция она выпуклая, она вогнутая точнее,
вот что функция лагарифм вогнутая,
Вот вы можете из этого неравенства, которое формулируется таким образом,
что мат ожидания от вогнутой функции от x, x случайная величина,
значит сейчас соображу, но будет меньше либо равняется, чем мат ожидания для f вогнутая,
чем f от мат ожидания x. Вот собственно вариация на эту тему и дает возможность устанавливать
нужное нам неравенство. Это не отрицательность расстояния кульбока лебера, это то же самое,
что дивергенция, не расстояние, а дивергенция. Что условие, что x звездой является точкой минимум
вот этой штуки. Здесь просто по определению написано, что у нас мат ожидания берется по
мере, которая настоящая, ксито имеет настоящее распределение p от x звездой. И соответственно
логарифм берется по произвольному x, то есть вероятность это считается по x звездой,
которая настоящая, а тут произвольный x. И мы видим, что наименьшее значение как раз тогда,
когда x совпадает с x звездой. Вот все это и написано. Это не значит, что оно единственное,
но это значит, что оно содержится среди минимизаторов, что истинное значение содержится
среди минимизаторов. Ну и собственно оценка максимального правдоподобия,
которую мы уже с вами рассматривали, и она была выборочная средняя. Это оценка,
которая получается, если вот записать вот это все дело, оценку правдоподобия, ну просто вот
записать ее таким образом. То есть что мы уже делали. Только теперь обращаю внимание, вы теперь
работаете с реальной выборкой. То есть у вас дана выборка, и вы пишете как бы не в теории,
что x со звездой есть арк минимум вот такого матожедания, потому что оно невычислимо. У вас нет
возможности считать x со звездой. Вы не знаете x со звездой. Это есть задача. То есть здесь написано
как бы ерунда по большому счету. То есть здесь написано какая-то тавтологическая вещь, что x со
звездой неизвестная является решением некой задачи. Но чтобы посчитать матожедание, вам тоже нужно
как бы брать матожедание по неизвестному x со звездой. Ничего как бы такого великого. Просто тут
x со звездой, тут и тут x со звездой. Но как только вы переписываете это уже, так сказать, апроксимируя
вот это матожедание, ну или заменяя его просто вот этим вот вероятностью, то есть не добавляя
здесь матожедания, понимая, что как бы если объем выборки большой, то вот этот вот арк максимум
должен по идее быть сконцентрирован около того, где там матожедание максимум достигает. То вот
вы получаете способ, который называется maximum likelihood estimation. И для него работает теорема,
которая часто ее называют теоремой Фишера. В старой литературе, даже не в старой, но вот в общем
Фишер к этому приложил руку. Но иногда просто теорема о свойствах оценки максимального
правдоподобия. И теорема заключается в том, что как бы вы не оценивали неизвестные параметры,
как бы спозируясь на выборке, то вот тот способ, который как бы описывается формулой 1.7, он
асимпатический, когда объем выборки, а это мы обозначали n, он асимпатический большой,
ну в смысле асимпатический стремится к бесконечности, то он асимпатический наилучший. То есть вот
асимптотика имеется в виду по объему выборки. То такой способ, наилучший это значит, что у него
наименьшая как бы корреляционная матрица, ну или по-другому говоря дисперсия по любому направлению.
И вот эта матрица, она задается информационной матрицей Фишера, так называемой информационной
матрицей Фишера. Вот это вот будет корреляционная матрица вот этой вот штуки. Ну и видно, что по
сути дисперсия, об этом идет речь, она пропорциональна 1 на n. То есть то, о чем мы много раз
говорили, качество оценки в плане дисперсии 1 на n. Значит отклонение среднеквадратичное будет
1 на корень из n, что ожидаемо. И борьба идет не за зависимость от n, а за коэффициент при 1 на корень из n.
Вот такой способ он максимум likely put on, ну и наилучший. Ну и мы с вами как бы качественно
поняли откуда он возникает. И качественно поняли, что это все как бы возникает как некоторый
эмпирический подход к задачи минимизации риска. Ну к задачи минимизации некого,
так сказать, стог оптимизации по сути. То есть к решению задачи стог оптимизации. Ну здесь в общем-то
неформально сформулировано, что мы не просто знаем, что у нее дисперсия, так сказать,
минимальная, а у нее она еще нормально, ну то есть асимпатически оценка максимального
правдоподобия ведет себя как нормальный случайный вектор, вот с как раз той
самой корреляционной матрицей. То есть получается, что у нас в общем-то имеет
место достаточно такой сильный результат. Ну и надо сказать, что для вот этих вот онлайн процедур,
которые я приводил, вот ключевые фамилики, фамилик Полик, юдитский Руперт, который в конце 80-х,
начале 90-х годов, они в общем-то вот то, что я здесь отмечал, как в общем-то, так сказать,
что то же самое можно достичь некой процедуры типа SGD, вот они это сделали для общих задач,
не обязательно вот значит таких вот простых, они это сделали вот в большей общности, по сути,
для произвольных задач с некоторыми общими условиями, типа локальные там квадратичности,
в общем это это локальные там сильные выпуклости, в общем это все можно прочитать, там ссылки будут,
вот детали, вот уже надо смотреть отдельно работы, но идея та же самая, что пишется правильная версия
с правильными весами вот этого стахастического градиентного спуска и получается аналогичный
результат без всяких имперических средней, то есть без отрешиваний вспомогательных задач,
можно-то добиться того же результата. Ну и в общем-то, идя дальше в этом направлении,
мы можем и даже должны заметить следующее, что в постановке задач, о которой я говорил,
вообще говоря не все было сделано, как бы сказать, ну что ли, не все возможности исчерпаны в плане
постановки, то есть мы говорили про задачу, когда х со звездой ну просто неизвестен, а что если на
х со звездой можно задать какое-то априорное распределение p от x, то есть если у вас есть
априорное распределение на p от x, то вы можете на самом деле задаться вопросом, а какая будет
тогда наилучшая оценка, которую можно получить, потому что это уже другая постановка, то есть вы
как бы сэмплите, давайте мы прям немножко скакнем и рассмотрим вот какую-нибудь такую схему, да,
то есть если например вы знаете, что ну в свою очередь, ну чуть усложнил модель, что х со звездой
генерируется из какого-то распределения, а потом к с и к генерируется из какого-то рассвет.
То есть х со звездой случайной, это ка случайно, то как бы вся случайность, которая есть в модели,
она складывается из того, что это сначала разыграли, а потом начинают из этого сэмплить,
естественно возникает вопрос а как тогда оценивать икса звездой как оценивать икса звездой если у вас
есть принципе априорная информация из какого закона оно распределено вы не знаете как оно
реализовалось но вы знаете уже какие-то последствия которые будут в результате измерений того икса
звезды который реализовалась и вот здесь таких постановках естественно помогает ну во-первых
prior информация о том что есть икса звездой ну и естественный такой принцип что вы как и раньше
выписываете вероятность некого события что выпадет соответственно икса звездой только теперь
надо поэтому интегрировать вот разные значения может выпасть зет ну и что при этом z и релизуется
ксикат и то есть это как бы у это это вот условная вероятность а это формула полной вероятности
я сейчас просто проинтегрировал а меня была к� heat hello вероятность но я хочу получить
оценку я хочу получить оценку этого параметра z который является как бы наиболее вероятным
Поэтому я как бы беру вот эту плотность, плотность вот это вот как называется апостериорная плотность распределения,
то есть вероятность того, что выпал конкретный х, вероятность того, что выпал конкретный х, — это есть вот что такое.
И эту вероятность я как бы оценку пишу, что это мат ожидания по вот этой аппостериорной вероятности,
того, что выпал конкретный х, имея в виду, что априорная вот такая, а это вот условная вероятность, что при заданном y выпадет ксикатой.
Ну и вот это будет как бы формула байса, по-моему, называется.
Вот вы можете воспользоваться формулой байса и получить так называемую байсовскую оценку.
И вот на эту байсовскую оценку вы можете написать аналогичные неравенства, ну прям вот с точностью до всяких ипы,
так же вот с этими матрицами, которые вы писали раньше.
И тоже с той же концентрацией, ну то есть с некоторыми оговорками, о которой я сейчас не хочу говорить.
Но в целом, в общем, важно понимать, что сейчас мы говорим уже, на самом деле, о том, что мат ожидания берется полная.
То есть мат ожидания берется как по х, потому что оно случайно, так и по ксикате.
То есть это немножко другая постановка. Там-то х был параметром.
Но при этом, когда мы говорим о том, что х нормально распределено относить, ну то есть вот такого типа результат, он условный.
То есть это conditional распределение. То есть вот эта байсовская оценка при условии, что мы заморозили х со звездой, она будет иметь вот такое распределение.
Это уже как бы результат, надо понимать, на условное распределение.
Условное приз в том, что мы заморозили реализацию х со звездой.
Но как бы эффект тот же самый.
Но тут еще есть всякие варианты более, так сказать, тонкие, типа теориям Берштейна фон Мизеса.
Одно они заключается в том, что вот это вот пастериорное распределение асимпатически нормально и сосредоточено около, ну сконцентрировано около maximum likelihood estimation.
Вот такой коверационный мат, но это уже какие-то отдельные вопросы там.
То есть для наших целей вполне достаточно того, что написано вот в основной теореме без этих тонкостей.
Ну и замечу, что помимо всяких байсовских оценок, совершенно естественно, если мы берем maximum likelihood estimation, то вот так.
А если мы берем, добавляем в maximum likelihood estimation P от X и формулируем задачу не максимум правдоподобия, а максимум полной вероятности, то надо prior учесть.
И тогда оценка получается вот такой.
Вообще говоря, это не то же самое, что байсовская оценка.
Это maximum posterior estimation, то есть байсовская оценка.
Это как бы average posterior, а это maximum posterior.
То есть это не то же самое, но в ряде постановок они просто совпадают.
И они асимпатически одинаково себя ведут.
То есть в общем-то это дело вкуса, с чем тут лучше вам работать.
Но чисто аналогия с maximum likelihood, она конечно больше вот здесь прослеживается, чем когда я пишу какую-то такую формулу.
Это, наверное, менее прослеживается.
Вот здесь она больше прослеживается.
Давайте конкретно пример разберем.
Rich regression и LASSO.
Ну пускай, как и раньше, у нас неизвестный параметр.
Вектор теперь уже X звездой.
Есть шум.
И пускай каждая вот эта ксика, скалярная величина, она есть, значит, ака, некая матрица, на, значит, X звездой и зашумляется.
Вот X звездой тоже случайно как-то, вообще говоря, разыгрывается.
Ну, вообще говоря, это зависит от схемы эксперимента.
Вот, матрица известна.
Цель оценить X звездой.
Значит, к чему приводит просто maximum likelihood estimation.
Если мы говорим о maximum likelihood estimation, то X звездой это не есть случайно разыгранная величина.
У нас по постановке задачи мы считаем, что оно задано.
Все. Мы не знаем, как оно задано.
Мы не вносим сюда случайности.
Поэтому maximum likelihood estimation это просто метод наименьших квадратов.
То есть AX минус X.
X это вектор вот из этих составлений.
AX это вот, по сути, значит, то, что получится, если вот эти строки записать матрично.
То есть взять вот такую матрицу и записать это векторно.
Ну, вот это будет maximum likelihood estimation.
Это будет то, что дает вот тот способ, который я говорил.
Выписывание правдоподобия и поиск параметра, который его минимизирует.
Bias'овская оценка в данном случае совпадает с оценкой maximum posterior estimation.
То есть они одинаковые.
Они будут иметь вот такой вид.
То есть bias приводит к регуляризации.
Вот что такое bias.
Bias' это регуляризация в методе наименьших квадратов.
Замечательно, правда?
То есть откуда берется bias?
Это просто prior.
Масштаб bias'а, то есть если вы как бы будете здесь смотреть,
то дисперсия bias'а, чем она меньше, то есть если у вас прям точная информация,
то это прям бесконечность будет стремиться к бесконечности,
значит она prior у вас информативен.
Если sigma бесконечности стремится, то есть по сути режим переходит в этот,
то есть не информативный prior,
то вы как бы имеете, что это вымывается, это почти ноль,
потому что в знаменателе бесконечность.
Бесконечность знаменателе это вымывается и регуляризатор исчезает.
Очень естественно.
То есть понятно, что есть предельный переход.
Но помимо вот этих ситуаций мы же можем рассмотреть,
да, это все называется rich regression,
но мы можем рассмотреть вот тогда ситуацию такую,
что если у нас оценка L1, то тогда LASSO,
который будет соответствовать этому,
ну то есть как бы объяснить сейчас,
да, то есть если у нас плотность prior не нормальный,
не такой, а экспоненциальный,
лопласовский он называется,
то тогда вот то, что сюда вносится,
во всяком случае в подходе LASSO,
он будет вот такой, то есть это другая задача.
Это задача, которая в оптимизации называется LASSO,
и она как бы отвечает разреженности,
выделению основных признаков.
И эта задача порождается тоже как байсовская,
но просто с другим prior.
Ну и тут дальше можно замечать,
что все эти штуки вырождаются к чему-то такому,
то есть если, например, лямбда стремится к нулю,
то это дело стремится в свою очередь к нулю,
но лямбда стремится к нулю означает,
что у нас prior неинформативен,
то есть вы фактически имеете равномерное распределение,
но оно как бы и сводится тогда к тому случаю,
когда нет никакой информации об X звездой.
То есть в общем мысль здесь очень простая.
Prior это регуляризатор в этих во всех подходах,
связанных со стох-оптимизацией,
но в данном случае мы на это смотрим не с точки зрения стох-оптимизации,
а с точки зрения мы смотрим имперического риска,
то есть это все отвечает минимизации имперического риска.
Ну и вот яркий пример, который на самом деле уже совсем неочевиден,
если до этого, я думаю, вы где-то сталкивались с тем, что я рассказывал,
то теперь у нас SVM, support vector machine,
и здесь мы имеем вот такую постановку,
что есть какая-то разделяющая гиперплоскость,
и у нас не собственное распределение вероятности есть,
то есть данные сэмпливаются таким образом,
что здесь они имеют плотность вероятности 1,
но поскольку это бесконечное множество,
то задать равномерную плотность на некомпактном множестве,
это непонятно, что такое, оно не собственное,
а вот здесь оно как бы экспоненциально убывающее,
то есть вероятность того, что мы где-то себя здесь найдем,
она экспоненциально убывает по мере отдаления от этой прямой,
то есть фактически, если лейблы правильно там ставить,
то мы должны попадать вот сюда,
но с некоторой маленькой вероятностью точки сэмпливаются и здесь,
и чем дальше, тем меньше вероятность,
ну и дальше, веря в то, что реально точки сэмпливаются вот так,
что существует, короче говоря, нормаль ak,
то есть существует какой-то вектор ak,
и существует вот метка y, которая классифицирует,
что данные сэмплируются по такому образу,
то есть мы говорим, что у нас там мы хотим сэмплировать,
то есть какого типа данные,
ну и в зависимости от метки y, либо та картинка, которую я нарисовал,
либо с точностью до наоборот симметричная,
то есть это соответствует метке y единица,
вот такая плотность распределения,
если у нас y равняется минус единица,
вот у нас два значения она приобретает,
то плотность будет другая,
то есть плотность распределения зависит от y,
ну естественно она зависит и от ak,
ak это нормаль, которая задает эту плоскость,
таким образом у нас есть два параметра,
точнее не так, я неправильно говорю,
прошу прощения, ak это данные,
ak это данные, а y это метки, это все данные,
а и нормаль задается x,
то есть у нас есть x, который задает нормаль,
вот этот x нам и надо определить,
то есть x задает нормаль,
и вот это и есть параметры,
а все остальное это данные,
и здесь написано плотность,
какая плотность будет у данных в зависимости от их параметров,
вот метки y и вот вектора ak,
ну и если у вас такая плотность,
она вполне естественная для классификации,
то оценка, которая map,
которая максимума posterior,
она как раз и есть то, что в SVM,
но регуляризованном SVM,
вот эта как бы часть,
то есть вот это сочетание приводит к такой штуке,
ну а prior, который гауссовский,
если мы его вводим,
он приводит к такой регуляризации,
ну и если prior не информативен,
это бесконечная дисперсия,
он вымывается, его нет,
и вы получаете просто задачу SVM,
support vector machine,
то есть это задача минимизации вот такой негладкой функции,
но выпуклой,
потому что это максимум из нуля,
и какой-то линейной функции,
если максимум берется,
то что это означает?
Вот это максимум,
вот максимум это выпуклая функция,
вот это ноль,
а вот это вот опять линейная функция,
вы можете линейную функцию провести вот так,
это неважно,
тоже максимум будет выпуклая функция.
Ну теперь мы переходим,
я скоро уже заканчиваю вот эту часть,
она компактная,
мы переходим к тому,
что собственно мы сейчас делали,
мы считали f от x к си
минус логариф mp от x,
где p это плотность,
и исходя из этой философии,
мы там брали вот такую разницу,
что-то там смотрели,
но, прошу прощения,
а зачем, зачем все это,
если можно без этого,
то есть вообще говоря,
не вводить никакие плотности,
и сразу написать,
что у нас функция регрета вот такая,
и в этом есть смысл,
мы вообще не знаем ничего
про параметрическую зависимость,
тут же как бы предполагается,
что есть какой-то параметрический закон,
и все это статистика.
Но машина обучения это не любит,
и оно и задается,
машина обучения задается вопросом,
зачем все это,
зачем все эти параметры,
зачем все эти гаусяны,
зачем все это,
если я просто могу,
с самого начала сказать,
что у меня функция риска,
какая-то функция потерь,
это и есть квадратичная не вязка,
Просто я зашиваю специфику задачи не в закон распределения шума, а в штраф, который мне интересен.
Я ничего не знаю о законе распределения кси.
Тем не менее, я также могу ставить задачу. Я имею в виду задачу мат ожидания.
Но теперь мат ожидания может браться по ИА в том числе, потому что я не знаю, как эти данные генерируются.
И мне надо определить тот параметр, который сидит в этой модели.
Но я вполне допускаю, что и А может быть случайно разыгран.
Если в предыдущей модели мне надо было, чтобы А было фиксировано,
сейчас я могу считать, что у меня вот здесь мат ожидания берется по ИА.
И то же самое. Я также могу брать офлайн подход, то есть брать империческую штуку.
Вот эти сэмплы. Будет получаться вот такая задача.
Для классификации, для hinge loss, которая здесь фигурирует, я получу другую задачу,
которая там будет. Вот такого типа она будет.
Ее также можно имперически переписать. Я уже не буду это делать.
И вам надо отрешивать вот такие задачи.
Дальше, собственно, если мы так смотрим на проблематику, то все.
У нас ушла какая-то специфика с законами распределения.
И она нам на самом деле не нужна была.
Потому что где мы здесь пользовались каким-то конкретным законом распределения?
Давайте вернемся к самому началу.
Вот мы задали функцию f от x равняется epsilon-x в квадрате.
В принципе, мы могли сразу сказать, что это и есть функция потерь.
Дальше мы сказали, что нам нужен 100 градиент.
Пожалуйста, кто же мешает его посчитать? Вот он считается.
И нам не нужно вот это знать.
То есть нам все, что нужно, это чтобы оценивать скорость сходимости таких процедур.
Но это какие-то свойства более общие.
То есть чему равняется дисперсия, чем она ограничена.
Но нам не нужен конкретный закон.
Мы эту параметрическую модель, что именно нормальный закон,
поэтому построили квадрат.
Но могли про это не знать и просто изначально рассматривать вот такую задачу.
И когда мы делали с такой моделью,
то этот функционал был однозначно связан с тем,
что мы хотим, чтобы это была оценка не смещена.
В общем, вот это дело сыграло свою роль.
Вот то, что я здесь рассказывал.
Но это потому, что мы имели параметрическую вероятностную модель.
А если ее нет, то мы можем просто говорить,
что нам в целом интересна вот такая задача стокоптимизации,
как вот здесь это вылезает, вот подобно тому,
как это вылезает, допустим, вот здесь.
То есть мы не знаем закон распределения,
мы не знаем вообще ничего про то, откуда Y сэмплится.
Но нас это вообще не смущает.
Нас это не смущает.
Мы продолжаем рассматривать эту задачу как задачу стокоптимизации.
Мы вводим шары в соответствующих нормах.
Rp – это ограничение на параметры.
То есть rp – это радиус шара в p-норме.
То есть, если, например, мы работаем с шаром в 1-норме,
то это будет, так сказать, какое-то такое множество.
Ну и теперь мы, в общем, предполагаем какие-то свойства
о классе функций, чтобы получить какие-то гарантированные результаты.
Значит, это свойства выпуклости, липшцевости, равномерной эпокси.
Иногда будет использоваться generalized linear structure.
Это вот как раз в SVM, но это вообще везде пока.
То, что мы смотрели, это везде generalized linear structure.
Вот она, generalized linear structure.
Вот она, generalized linear structure.
То есть что-то, что, так сказать, афинно,
вот такое скалярное произведение входит,
и некоторая такая функция от скалярного произведения.
То есть это как бы позволяет размерность снизу снижать.
Ну и дальше мы говорим, что можно ввести функцию эмпирическую,
ну и определить минимум вот этой эмпирической функции.
Все, это и есть как бы подход offline.
Это off-line подход.
Ну и, собственно, теорема, которую можно доказать,
она для случая, когда у нас, значит, мы предполагаем
одновременно выполненными вот эти два соотношения.
То есть есть generalized linear structure
и есть выпуклость и липшцевость.
И в этом случае мы получаем, что имеет место равномерная аппроксимация
эмпирической функции, исходной функции.
И порядок аппроксимации один на коре низен.
Повторю, равномерная.
Что, вообще говоря, довольно круто.
Ну и из равномерной аппроксимации мы можем получить вот, так сказать,
два пресеста, что сначала, значит, нам надо, значит,
просто, ну, то есть чтобы записать, чему равняется эта разность,
мы, значит, пишем что?
Что, значит, это есть...
Сейчас, f от x минус f от x со звездой.
Значит, это что такое?
Это меньше либо равняется, чем f от x с чертой.
Это оценка минус f с чертой от x с крышкой n.
Это минимизатор f от x с чертой.
Плюс, значит, f от чертой x с крышкой n минус f от x с крышкой n.
Вот такая вот штука.
Ну и плюс...
Плюс, значит...
Сейчас, минутку.
Минутку, минутку.
Плюс f от f от...
Сейчас, сейчас, сейчас.
Значит, это как-то тривиально делается.
Я что-то немножко запутался.
Сейчас мы это сделаем.
То есть два раза надо вот этим вот воспользоваться.
Несколько раз, который уйдет вот сюда.
И, значит, надо представить эту разность через...
Значит, тут будет тогда f от x со звездой.
Здесь должно быть f от x.
Плюс...
Так, это будет f от x минус f от xn.
Плюс f от...
Минутку.
Минутку.
f от...
Так, что-то я туплю.
Надо точно, чтобы здесь было минус f от x со звездой,
потому что она здесь присутствует.
И, значит, надо точно, чтобы присутствовало f от x.
Вот, значит, f от x.
Так, f от xn.
Сейчас.
То есть надо собрать оценку, которая здесь написана,
из вот этой штуки.
И, соответственно, вот такого типа штуки,
где правильно подставить аргументы.
Значит, схема понятна.
Просто надо сейчас эти аргументы подобрать.
Минутку.
Минутку.
Значит, f от xn.
Дальше мы, значит, делаем f от xn с крышкой f от f.
С крышкой f от x со звездой, наверное, надо сделать вот эту штуку f от f от x.
Минимум.
А здесь будет...
Сейчас, сейчас, сейчас, сейчас.
Так, наверное, вот так проще сделать будет.
Значит, это будет минус f с чертой от x со звездой.
Плюс f с чертой от x со звездой, минус f от x.
Вот так вот.
Да?
Вот эта штука, она меньше либо равняется f с чертой от x
минус f с чертой от x с крышкой n,
потому что x со звездой это просто какая-то точка,
а x с крышкой n это минимизатор f с чертой.
Поэтому это неравенство верно.
А вот это неравенство...
Значит, прошу прощения, здесь x со звездой, конечно.
Значит...
x со звездой, да.
x со звездой.
Да, ну и здесь, конечно, я тоже забыл написать f от x
минус f от x с чертой от x.
Вот, да.
То есть теперь все сходится.
То есть, смотрите, мы берем первую разницу.
Вот f от x соответствует f от x.
Мы берем вот эту штуку, она сокращается вот с этой штукой.
Берем вот эту штуку, она сокращается вот с этой штукой.
Ну и, соответственно, вот эта остается,
вот она тоже здесь остается.
Вот это вот дело, вот это вот дело,
результат позволяет оценивать но тогда оно и получается вот вот вот здесь значит прошу
прощения так да вот мы сюда и приходим вот отсюда и вот сюда мы приходим но это вот дело
оно превращается вот в это дело то есть мы действительно можем аппроксимировать в таком
случае мы можем аппроксимировать невязку по прямой функции в этом цель то есть у нас есть
настоящая функция и мы можем ее аппроксимировать невязкой по имперической функции плюс вот это вот
оценка которая есть на аппроксимацию то есть это хороший результат это уже лучше не бывает но
это все получено в предположении что у нас есть generalized linear structure это на самом деле очень
сильное предположение ну и если есть сильная выпуклость дополнительно причем равномерная
то оценку можно усилить но аналогично это получается я сейчас не буду здесь ушу так
сказать этим заниматься вот к чему это все значит приводит нет извините вот к чему это
приводит если все то же самое но если нет условия два если условия два нет тогда на самом деле все
не так весело вот и и оценка которая значит здесь появляется она будет другая она будет вот такая и
это надо в общем-то доказывать это уже по-другому доказывается это более общий результат то есть
что в сильно именно подчеркиваю сильно выпуклым случае вырожденном случае вот это я такого не
говорил что это будет верно я именно сказал сильно выпуклым случае останется верно вот такой
результат но испортится часть которая связана вот с вот этой вот оценкой ну на самом деле это
просто означает сколько вам надо брать слагаемых в этой сумме то есть вот вот результат о том что
если n берется так что вот эта штука равняется epsilon то и отлично да то есть если например n
брать пропорционально 1 на mu epsilon то здорово но при этом надо еще решить задачу вспомогательную
вот эту вот задачу достаточно точно то есть вот эту задачу минимизации вот вот она написано ее
надо достаточно точно решить а почему это так ну потому что вот видите это тоже должно быть
epsilon если мы хотим чтобы это было epsilon значит это означает что невязка по вот этому решению
должно быть epsilon в квадрате на мю то есть короче говоря вот эту задачу мы должны решить с
точностью epsilon в квадрате на му этот этот этот как бы если хотим чтобы решение вот этой вспомогательной
задача было Эпсилон решением исходной. Вот что такая наука говорит. И более того, доказано, что это не
улучшаемо. То есть ничего не улучшаемо. Не эта часть не улучшаема, не эта часть не улучшаема. Точнее, эта
часть улучшаема, если есть предположение 2. Но если Generalized Linear Structure нет, то оно не улучшаемо. И это все
результаты относительно вот как раз офлайн подхода для вот таких постановок. Но, идя дальше, мы как бы
знаем, что офлайн подход это не конец как бы истории. У нас есть онлайн подход. И вот про этот онлайн подход
мы с вами говорили. То есть, офлайн подход это вот об этом, что надо решать эту задачу. Но есть и онлайн
подход. То есть, не обязательно решать вот эту задачу с какой-то нужной точностью. А чем онлайн и
офлайн подход отличаются? Это вопрос был задан. Значит, офлайн подход это то, что мы как бы рассматривали,
когда заменяли мат ожидания. Вот он, значит, этот офлайн подход. Мы заменили мат ожидания выборочным
средним. То есть, вот у нас задача сток оптимизации. Теперь уже мы не говорим, что она порождена
какими-то плотностями. Мы просто постулируем сам функционал, как это делается в машинном обучении.
Мы постулируем регрет или не регрет, там какой-то лоз. И дальше мы просто отрешим задачу сток
оптимизации, заменяем от ожидания выборочным средним. И все, что я сейчас рассказывал на данный
момент, это как бы насколько точно позволяет отрешивание вот этой задачи. То есть, если мы
решим эту задачу с такой-то точностью, что можно сказать про решение исходной задачи сток
оптимизации? То есть, это вообще говоря, наука о чем? Что вы решаете задачу империческую, а качество,
которое вам нужно, оно меряется по вот этому функционалу. И что можно сказать, если вы там с
такой-то точностью решите вот эту задачу минимизации? Вот она написана. Вот относительно критерия вот
этой задачи. Вот это есть офлайн подход, он тут описан. Вот грубо говоря, к таким же оценкам мы
сейчас придем в онлайн подходе, но здесь сделаем это без решения вспомогательной задачи с какой-то
там повышенной точностью. А именно, мы берем онлайн подход, просто метод проекции сток градиента.
Ну, мы считаем, что множество ку есть. Вот выкладки тривиальные, я их рассказывал на одной из лекций,
когда мы рассказывали про SGD. И эти выкладки, но единственное, что там может быть и новое будет,
что в сильно выпуклом случае шаг надо выбирать зависище мотка. Не фиксированным, а зависище
мотка. Ну, вот нас это приводит, по сути, к таким двум результатам. Я даже про онлайн говорил на
лекции. Ну, и здесь как раз онлайн формулировки написаны. То есть, нас это приводит вот к таким
двум результатам, из которых уже можно вычислить результаты для выпуклой оптимизации, не для онлайн
подхода. Когда все эти функции, ну, значит, как бы сказать, ну, когда этот х выбирается вот таким вот
образом, мы можем, значит, выбирать х со звездой, можно выбирать фиксированный, а можно выбирать,
вот, например, таким образом, когда вот минимизируется вот такая правая часть. И это дает нам,
на самом деле, нужную оценку на вот большие отклонения и на сходимость. То есть, вот такие
процедуры можно установить, как они сходятся. В выпуклом и в сильно выпуклом случае. И замечу,
что эти оценки в точности соответствуют, ну, там с точностью до логарифмов, они соответствуют вот
тому, что было раньше. То есть, вот этим вот оценкам они соответствуют. Видите, m в квадрате на
mu n, вот m в квадрате на mu n, ну, вот здесь m r на корень из n, ну, и здесь то же самое. То есть,
здесь такие же рейты мы получаем, m, ну, тут r задана вот как эта штука на корень из n,
m r на корень из n, ну, а здесь m в квадрате на mu n тоже, тут просто логариф немножко другой
получился, там не было фактора n. Вот, ну, хорошо, то есть, вот мы сейчас с вами посмотрели на два
подхода, которые приводят, в общем-то, к одному и тому же. Но они как бы приводят к одному и тому
же почти, потому что вот если я с оффлайн подходом мог явно выписать результат, вот он, то с онлайн
подходом, с оффлайн подходом я этого не могу сделать. Я сказал следующее, я сказал, что если
condition 2, это вот это condition, оно не выполняется, то все, что мне можно установить, это то, что на
самом деле только вот эта вот штука имеет место. Это сильно выпуклый случай, я уже это говорил,
то есть в оффлайн подходе существенно сильная выпуклость. Я не имею аналога прямого вот такого
результата, если не выполняется ограничительное предположение 2. У меня получается, что в оффлайн
подходе не только, значит, не только получается, что он требует решения вспомогательной задачи
достаточно точно, но еще он не дает в выраженном случае, когда нет сильной выпуклости, вот такой
оценки без предположения generalized linear model, а это очень специфический класс задач. То есть
общая задача обучения выпуклым, ну, например, это какого, логистическая регрессия, свм, вот они
подходят под generalized linear model, но как бы есть более общие модели, где прям совсем как бы ничего
мы не знаем про просто выпуклость. Вот и вот онлайн подход ему все равно, а оффлайн подход ему не
все равно. Значит, какой дальнейший план? У нас остался меньше часа времени, значит, я давайте
наверное, не знаю, имеет ли смысл делать на 40 минут перерыв на 50 или просто уже 40 минут договорить
и на этом закончить. Вот, потому что мы обычно делаем перерыв, когда, значит, вот студенты сидят
в аудитории, но сейчас каждый может сделать перерыв так, как вот считает нужно в какой момент и
ну, разве что с точки зрения восприятия, просто делать какую-то паузу, что вы могли немножко
поспрашивать о происходящем, потому что я действительно немножко быстро иду, но резюме очень простое,
что онлайн и оффлайн подходы, с которых я начал, они отличаются тем, что в онлайн подходе вы делаете
вот это, то есть вы решаете задачу стох-оптимизации, ну как бы просто, как вот, как это мы с вами до
этого рассматривали, как с SGD, это онлайн подход, а оффлайн подход вы заменяете задачу стох-оптимизации,
задачей оптимизации близкой к ней, но опроксимирующей ее, вот такой вот. Ну и соответственно, нужна теория,
показывающая сколько там чего, так сразу несколько вопросов, а какие недостатки могут быть
онлайн подхода, да-да, во-первых, это та же версия книги, которую я скинул 1 сентября, это ответ на
вопрос, только это, нет, это чуть-чуть новая версия, она не сильно отличается, но я ее сброшу еще раз,
вот сегодня, а какие недостатки могут быть онлайн подхода, это хороший и правильный вопрос, ну
представьте себе вот, что, значит, градиент, который здесь считается, например, да, он является
градиентом какой-то сложной функции, такое может быть, например, когда вы Баррицентр Вассерштейна
считаете, то есть это градиент функций, который требует, ну вообще говоря, очень больших вычислений,
ну вот прям больших, а бывает такая ситуация, что двой, градиент двойственной функции считается
сильно быстрее, ну, например, вот вы берете задачу поиска Баррицентра Вассерштейна, если вы ее
оффлайн решаете, вы ее запишете в таком виде, и вы можете построить двойственную задачу, двойственная
задача, и решать двойственную задачу каким-то распределенным алгоритмом, еще как-то, а прямой
подход, во-первых, заставляет вас работать с прямыми градиентами, что может быть дороже, ну и во-вторых,
он не позволяет хранить эти картинки, то есть он в стрим режиме, вам эти картинки, то есть вы
должны их либо на каком-то сервере хранить и последовательно обрабатывать, ну либо, я не знаю,
либо просто как-то они должны откуда-то скачиваться там по мере того, что вот они к вам приходят,
но в любом случае это может быть проблема хранения этих картинок, то есть их содержать на одном узле,
на котором происходит обучение. Вот в этой постановке вы можете распределить, разбив части суммы в узлах
и хранить это в узлах, построить двойственную задачу, решать двойственную задачу. Вот об этом будет
Александр Безносиков рассказывать, но не столько двойственная задача, сколько вообще вот как решать
такого типа задач распределенными алгоритмами, то есть это своя жизнь, это своя жизнь связана с тем,
что big data задача обучения нейронных сетей, огромный датасет, вы храните его на нескольких узлах,
вы в голову даже вам не приходит пересылать ксикаты, ксикаты это картинки, кошечки, собачки,
это как бы в вашем понимании выборка, да, ну то есть, но это большая, много весит каждая картинка,
их много этих картинок, огромный датасет, миллиард сэмплов, ну невозможно все эти миллиард картинок
значит мегабайтных хранить в памяти, в которой есть быстрый доступ, оперативный метод, а нам
хочется, чтобы это все-таки было все в раме, происходило random access memory, мы значит как-то
их распределили на узлы, и вот значит это все не так много в узле, и вот они значит пересылают
какой-то агрегат вычислений, эти вычисления могут быть сильно дешевле, чем стоимость самой картинки,
это сто градиент, то есть посчитать сто градиент может быть или двойственной, сильно дешевле, чем
вообще разобраться с тем, что это за картинка, саму ее пересылать, поэтому когда мы говорим о онлайн
обучении, это на самом деле вполне нас ограничивает даже вот как бы совсем такими современными
ну приложениями, хотя вот явно тут много преимуществ, но вот как обучение нейронных
сетей, потому что не совсем понятно как организовать, значит эту процедуру не распределенно,
чисто вот вычислительно непонятно, а распределенно понятно, что хранятся части задачи и вот они
коммуницируют, ну на самом деле здесь есть некий обман, потому что вы эту задачу можете решать
более-менее этим же методом, так и делают, то есть вы как бы берете сто градиент, просто берете его
случайно выбирая слагаемое, это немного другая история, но как бы в конечном итоге вы получите
тоже качество, если напишете эту задачу и будете решать ее вот таким методом, где сто градиент
выбирается случайно равновероятно, и это как бы восстановит справедливость, то есть вы как бы из
офлайн подхода сделаете онлайн, ну практически такое же по качеству, но тогда вот вы будете терять какие-то
свойства при редукции дисперсии, которую здесь можно сделать, о которой мы практически ничего не
говорили, но вот какой-то некий прием, учитывающий структуру суммы, который позволяет такие задачи
решать, значит хорошо теперь у нас, собственно, вопрос в том, что sample average approximation, то есть то,
что мы называли, значит, я уже забыл, значит, ну короче, Монте-Карло и онлайн, оффлайн и онлайн
подходы, вот видите, тут написано off-line, это sample average approximation, то есть это Монте-Карло,
а это онлайн подход, то есть это SGD, но в западной литературе вот это вот называется stochastic
approximation, ну а это вот так и называется, ну мы называем это Монте-Карло или оффлайн,
оффлайн, вот и, значит, давайте просто ведем понятие вот такое, вот что, значит, решение вот
этой задачи с точностью там дельта, бета, дельта это точность решения, бета это доверительный
уровень, вот это будет такая точка, которая удовлетворяет вот такому условию, то есть
мы решили задачу минимизации имперической риска, функции риска, то есть это оптимум,
я напомню, а это вот то, что мы приближенно нашли, это вот дельта, которая обеспечивается таким
доверительным уровнем, ну и это обозначение мы будем использовать далее, как бы сказать то,
что является опроксиматором для задачи минимизации имперического риска, ну и теперь вот есть результаты
довольно, так сказать, интересные, показывающий, что если задача не сильно выпуклая, не сильно
выпуклая, то обратите внимание, что оценка, которая получается, она портится в n раз, n размерность
пространства, то есть вы действительно имеете аналогичный результат, но в n раз хуже, если
вот заниматься тем, чтобы решать задачу минимизации имперического риска, то есть число сэмплов надо
брать в отличие от онлайн подхода в n раз больше, это вообще удивительно, потому что если бы вы решали
задачу сток оптимизации, вам бы n надо было взять 1 на епсилон квадрате, и от размерности бы это не
зависело, то есть давайте это прям зафиксирую, n пропорционально 1 на епсилон квадрате, это онлайн,
а если оффлайн, то n пропорционально n размерность пространства на епсилон квадрате, это оффлайн,
и разница большая, если размерность пространства большая, вот это как бы необычная ситуация,
похожая на мини бочирование, ну я не знаю, как это прокомментировать, ну наверное, что-то
похоже, значит, и в чем тут проблема, ну проблема ровно в том, что нет вот этой вот как бы сильной
выпуклости, то есть нет гарантии, что сходимость по решению будет иметь место, ну то есть по аргументу,
я доказательства естественные опускаю, оно громоздкое, но замечу, что и с игрой на невклидовость я
тоже это опускаю в детали, но замечу, что вообще говоря, в случае, когда сильно выпуклость есть,
у вас справедливость восстанавливается, то есть вы как раз можете получить тот результат,
который я уже упоминал, только даже в более общем сетапе со всякой невклидовостью, и получается,
что главное, что нужно сделать, это регулировать задачу, то есть она не сильно выпуклая, а нам
надо ее регулировать, и тогда проблема решится сама собой, то есть задача станет сильно выпуклой,
но просто регулировать надо правильно, и если мы это правильно сделаем, то все схлопнется,
то есть можно будет использовать результат, который как бы для сильно выпуклых задач
дает правильную оценку, он же даст правильную оценку при регулиризации для просто выпуклых
задач, то есть онлайн и офлайн подходы совпадут, но чтобы это сделать мачинг, нам надо вести
регулиризацию, здесь она рассказана в самом простом ключе, а именно вот в таком, когда эта регулиризация
делается просто квадратичной, давайте выберем mu равняется epsilon r2, тогда утверждается,
что если сглажен вот эта вот регулиризованная функция, отрешивается, отминимизируется с
точностью epsilon пополам, и mu равняется epsilon на r2, это размер решения в квадрате, но то есть размер
того шара, в котором множество кул лежит, тут есть предположение, что кул лежит в этом шаре,
то тогда мы можем обеспечить, что эта же самая точка будет решением исходной задачи с точностью
epsilon, то есть нам достаточно регулиризовать с таким параметром, а меньше не надо, можно и меньше,
но меньше уже не надо, потому что и так будет выполняться нужная точность, но сильно выпуклась
пострадает, поэтому начну, тут тривиальная выкладка, почему это выполняется, вы можете потом
посмотреть, это в общем я рассказываю в курсе оптимизации, поэтому не хочется здесь повторяться,
тем более, что это вы можете посмотреть потом, но эффект от этого колоссальный, то есть как бы вы
берете задачу минимизации имперического риска, добавляете аккурат тот самый регулиризатор,
который соответствует вот этой теории Митиханова, ну и получаете, что вы уже вот для этой задачи,
не для исходной, вот как бы оценка числа слагаемых вот такая, то есть разница в том,
что если бы я не писал вот это, то у меня бы здесь вылезла размерность пространства, если бы я не
писал, понимаете, это на самом деле очень мощно, то есть еще раз, я этого не пишу, значит здесь оценка
в n раз хуже, а как только я это пишу, у меня оценка в n раз лучше, вот зачем нужна регулиризация,
то есть вот как бы регулиризация обеспечивает то, что число и число слагаемых, которые надо взять в
подходе оффлайн, оно соответствует числу итерации онлайн процедуры, оно и не удивительно, как бы это
правильный результат, другое дело, что здесь еще надо решать задачу, а там она как бы автоматически
агрегируется, но мы с вами уже говорили, что организовать процедуру, когда автоматически
агрегируется, может быть технически сложно, потому что это значит надо всю эту выборку,
где-то схоронить и как-то доступ к ней обеспечивать, тут как бы это все распределено можно делать,
они могут коммуницировать, как бы так и не так и не собирая в одном месте все ксяка,
или там соображение приватности, еще что-то, ну и замечу, что вот когда у нас условия дополнительно
известны, какие-то вот так называемые с growth condition, то есть условия, обычно это возникает
условия, когда вот есть функция, и она минимум имеет вот как бы в граничной точке на множестве
q, и там есть условия какого-то острого минимума, типа острого минимума, например s единица,
это называется острый минимум, тогда в этом случае оценки на число итерации, они становятся
удивительно хорошими, в частности для острого минимума s единица, то есть мы имеем, что если
положить единицы, число итерации будет пропорционально, некая константа, ну короче,
пропорционально один, ну логарифм на епсилон, то есть число не итерации, число слагаемых
пропорционально один на епсилон, то есть от желаемой точности практически никак не зависит,
это потому что вот это обнулится, показатель епсилон, и это хороший результат, это мощный
результат, потому что он по сути означает, что для острого минимума не надо много сэмплов,
но то же самое получается и для подхода, который онлайн, но я не буду контрпример приводить,
вот для подхода онлайн у нас получается, значит прошу прощения, такой же результат, только там
немножко другие логарифмы, получается он как раз рестартами из метода стахастического
градиентного спуска, вот значит здесь есть оценка снизу, оценка сверху, и мы как бы выбираем число
итерации так, чтобы вот эта штука, ну норма невязки, уполовинилась, вот это и есть, вот она идея,
значит, и вот если так выбирать n, мы собственно получим, что число таких рестартов должно быть
логарифмическим, ну и можно оценить каким должен быть размер одной такой итерации
уполовинивающей, и мы можем из любой процедуры, в которую входит расстояние от точки старта до
решения получить процедуру, которая уже имеет правильные оценки, что мы и сделали, вот, ну и как бы
если говорить про всякие релаксации того, что я сейчас рассказывал, то можно обобщать все эти
результаты на случай хвостов тяжелых, в частности, все это верно, если, например, у нас дисперсия
ограничена, но хвосты тяжелые, вот то, что я рассказывал, будет верно, то есть несущественно,
что как бы хвосты не субгаусовские или там нефинитные, то есть нам это не нужно, на самом деле,
вот много и не все, но много из того, что я сказал, будет верно, но вот если дисперсия не ограничена,
но ограничен какой-то момент между двум и один, тогда результат ухудшается, то есть эпсилон минус
второй становится вот так таким, и это, ну точнее вот таким, там, p это у нас двойка, на p можете не
смотреть, я Евклида в случае рассматриваю, ну то есть, вообще говоря, если альфа маленькая,
то результат становится плохим, вот, значит, условия выпуклости можно заменять, можно рассматривать
более слабые условия, например, полика Лоисеевича, и на эту тему тоже есть результаты, что не обязательно
все это делать в условиях выпуклости, значит, все это можно сделать и в каком-то смысле адаптивно,
идея адаптивности, она заключается в том, что вот шаг метода, который раньше выбирался вот так,
теперь его надо выбирать вот, как бы, во-первых, так, чтобы не было зависимости от числа желаемых
итераций, это, конечно, приводит к лишним проблемам, но главное, что вот в этой схеме вы можете сделать,
это заменить m константу Липшица на вот такие штуки, то есть вы фактически вот апраксимируете вот эту
штуку, как r на mk, на m корень из k, но так оно и есть, потому что это и есть какая-то оценка m в квадрате,
и число таких слагаемых k, и вот эта идея, она легла в основу адаграда, то есть вместо того,
чтобы сначала заменить это вот этим, а потом с этим работать, ну было принято, было как бы понято,
что m на корень из k проще вот как бы, не проще, а адаптивно можно вычислять вот так вот, это и есть
m на корень из k, ну какая-то оценка, и это работает, доказана даже соответствующая теорема, что это
должно для выпуклых задач работать. Перепараметризацию мы с вами рассматривали, то есть мы с вами
рассматривали случаи, когда дисперсия задана в нуле, и это, соответственно, порождает оценку,
вообще говоря, линейной исходимости с конкретности, но надо заметить, что вот результат для
эмпирических задач, когда есть перепараметризация, это уже другое, он выглядит как бы хуже, то есть у вас
уже нет линейной исходимости, то есть если вы будете использовать вот эмпирический подход,
то вот эта перепараметризация, она действительно тоже есть некий эффект быстрой исходимости,
оценки, но он вот другой, он не такой быстрый, как в случае онлайн подхода, то есть онлайн подход
здесь, во всяком случае, на данный момент по теории лучше. Самый как бы такой естественный способ
дальнейшего развития всей этой науки, это вот уже теперь преимущество онлайн подхода. Онлайн подход
бочируется, то есть параллелится, когда есть гладкость. Под гладкостью мы понимаем, что целевая
функция имеет констант улипшится градиента. Тогда можно решать задачу ускоренными методами, они
сходятся вот так, что, конечно, лучше, чем всякие оценки один на корень и зен, которые мы писали,
но у нас задача 100-х оптимизации, то есть у нас 100-х аракул, и поэтому мы работаем с так называемым
пробатченным 100-градиентом. И вот можно показать, что если размер батча должным образом выбирать,
вот здесь есть некая наука, как это делать, причем из элементарных соображений, то будет допускаться
вот такой параллелизм, то есть размер батча выбирается, ну в зависимости того ускоренный
там не ускоренный метод, ну вот, либо так, либо так, ну и оценка скорости сходимости будет,
значит, ну вот, допустим, для ускоренного метода вот такая, то есть число последовательных
итераций будет вот таким, размер батча будет вот таким, ну а, соответственно,
общее число итерации это будет не итерация аракульных вызовов 100 градиентов, это будет
произведение двух чисел, оно будет таким, каким было раньше, то есть вы в этом смысле ничего не
улучшили, вы получили такую же оценку, как раньше, но сделали лучше то, что число последовательных
итераций, которые не параллелятся, оно будет меньше, а в предыдущих подходах все это
последовательно делалось, ну то есть здесь борьба за параллелизм. Ну то, что задача вида суммы
обладает специфическими особенностями, которые надо учитывать и решать, это вот так называемые
методы редукции дисперсии, они позволяют эффективнее решать такие задачи, чем, ну чем
какими-то стандартными методами типа ускоренного, вот это вот тоже важное замечание, я не буду
подробно этому останавливаться, вот здесь есть идея метода редукции дисперсии, которую вы можете
посмотреть, в чем она заключается, как выбирать редукцию дисперсии, также вы можете, ну мы уже
с этим сталкивались, например, лассо проблем и так далее, есть композиты, то есть в задачи есть
какие-то, в самой задачи оптимизации есть какие-то, например, регуляризаторы вот такого типа,
и их необязательно брать градиент, потому что, например, лассо в том же лассо плюс лямбда х1,
оно не гладкое, если брать его градиент, то все как бы наука теряется, наука, которая гладко
издает, поэтому идея заключается в том, чтобы брать вместо проекции, значит понимать проекцию,
как отрешивание вспомогать на задачи и, соответственно, смотреть на задачу обучения,
как на задачу с композитом, и вот этот композит оставлять вот в этой модели, которая здесь
присутствует, то есть у нас есть модель квадратичная функционала, вот ее мы сохраняем,
а композит не заменяет ничем, просто оставляем как есть, ну и такие подходы действительно для
лассо дают хорошие результаты, и потому что есть ускорение, есть как бы гладкость, а не гладкость,
она зашивается вот сюда, ну и это усложняет вспомогательную задачу, метода, но вот сохраняет
в онлайн подходе число итерации хорошим, значит я уже упоминал про раннюю, нет не упоминал,
но говорил про трюк, что можно решать задачу минимизации эмпирического риска sgd, и вот здесь
очень важно решать ее, вовремя остановившись, то есть если мы делаем число итерации sgd
пропорционально n, то качество будет n-1,2, это ровно то, что надо, но тут важно, что это n,
оно ровно совпадает с тем n, которое здесь, то есть тут важно, что число итерации sgd надо брать
не больше, не меньше, а порядка n, это то, что вы на практике скорее всего используете, когда проходите
датасет несколько раз, но вы его хотя бы раз проходите, но не проходите его бесконечно много раз,
это если вы не делаете регуляризацию, если вы ее не делаете, то тогда вот это золотое правило,
нельзя его нарушать, иначе будет переобучение, но есть более хитрые всякие механизмы, значит
что будет если, например, в ВТ выбираете немножко по-другому, какая будет, ну то есть здесь,
в общем-то, скорее результаты о том, что ничего хорошего ожидать не следует, и вот это, наверное,
максимально яркий результат, а все остальное это некоторые, так сказать, окрестности, которые в
целом, ну они такие, достаточно пессимистичны, но, например, если вы будете решать задачу вот эту
вот не стахастическим градиентным спуском, а градиентным спуском, понимаете, это как бы круче,
как бы с точки зрения скорости сходимости для этой задачи, градиентный спуск, естественно,
будет сходиться быстрее, но вот я это пишу, вот градиентный спуск, то на самом деле,
сколько бы итераций градиентного спуска вы не делали, вот неважно, какой ВТ возьмете,
вы не получите качество лучше, чем n-5 в 12, но это хуже, это хуже, это хуже, чем n в степени
минус одна вторая, я имею в виду качество на исходной задачи, а можно подробнее немного про
результаты переобучения, ну конечно, пожалуйста, то есть, смотрите, вам надо решать вот задачу
минимизации имперического риска, решение этой задачи как бы дальше исследуется на предмет того,
насколько оно там соответствует настоящему функционалу, а настоящий функционал, это мы от
ожидания, и понятно, что даже если вы сколь угодно точно отрешиваете эту задачу, это еще не значит,
что вы что-то хорошее сделали для исходной задачи, и вот оно об этом, то есть, когда вы очень
точно решаете задачу, допустим, градиентным спуском, вы в принципе не можете гарантировать
аппроксимацию, которую вы можете получить, решая эту задачу стахастическим градиентным спуском,
делая всего n итераций, столько-сколько слагаемых, ну пропорционально, это немного удивительно,
потому что вы как бы нацелены на то, чтобы решать эту задачу, но повторю, если у вас нет регуляризации,
если нет сильной выпуклости, то эта задача плохо аппроксимирует исходную задачу, вам тогда надо
было брать, чтобы была аппроксимация n пропорционально n маленькой на ε2, вот,
ну то есть, здесь как бы момент такой, что как бы достаточно для других процедур 1 на
ε2 итерации, а вот как бы без регуляризации итерации будет больше, это не очень хорошо,
это как бы означает, что эта задача в целом без регуляризации, она, она довольно дурацкая сама
по себе, то есть, ее нельзя просто так решать, например, LBFJS, каким методом Ньютона, ее надо
решать, либо регуляризовав предварительно, и тогда уже можно точно решать, либо решать с остановкой,
early stopping, это early stopping, оно как раз и контролирует переобучение, потому что, смотрите,
вы запускаете какой-то итерационный процесс решения этой задачи, но regret или loss вы
меряете по, то есть, loss вы меряете по невязке по прямой задаче, то есть, f от xk, у вас минус f
от x со звездой по прямой задаче, xk считается исходя из итерационного процесса для этой задачи,
например, xk плюс 1 равняется xkt минус h на градиен, допустим, f с чертой от xk, вот такая процедура,
и вот это xk, оно как себя будет вести, оно будет убывать, убывать, убывать, а проблема в том,
что потом оно начнет возрастать, это потому что вы решаете задачу по вот этому критерию,
и по критерию этому она будет дальше убывать, но по критерию вот этому она начнет возрастать,
уобразной кривой поедет, это будет переобучение как раз, то есть, если бы у нас было вот красное,
это отвечает зависимости f с чертой от xk минус f с чертой от соответственно x с чертой со звездой,
то вы бы действительно убывали так, как полагается там с рейтом там 1 на k, допустим,
то здесь будет как бы так, что вы будете по началу похоже, а потом вот это загнется,
просто потому что задача другая, то есть вы как бы хотите точно решать одну задачу,
то есть хотите точно минимизировать f, а решаете реально другую задачу, вот в этом проблема,
и эта проблема отчасти решается просто непосредственно онлайн подходом, потому что у нас нет вот этого вообще
дела, но с другой стороны вот можно и как бы из оффлайн подхода что-то вытащить, если есть желание
распределенного что-то делать, значит хорошо идем дальше, у нас теперь сюжет вот с распределенной
оптимизацией, но он не очень как бы такой существенный, потому что ну в общем-то дальше
Александр Безносиков про это расскажет на следующем занятии, то есть фактически эта сумма,
она собирается вот в такие подсуммы, и дальше мы можем использовать два фактора, либо редукция
дисперсии, о которой я говорил, либо similarity, то есть тот факт, что слагаемые оказываются
статистически близкими, если это одинаковые сэмплы, вот как математически использовать тот факт,
что в задачах обучения они близки, близкие эти функции, оказывается это можно делать, и здесь
возникает очень красивая математика, красивая наука, я не буду сейчас про это рассказывать,
здесь более-менее написано, но эффект заключается в том, что вот такую задачу, если это хранится на
разных серверах, вот это разные сервера, хранят разные, можно решить за число вычислений 1 на корень
из s, 1 на корень из s, это степень similarity, поделить на μ константа сильной выпуклости, то есть имеется
в виду, что вместо того, чтобы как было раньше число коммуникации с центральным узлом было
пропорционально константе липшица на константу сильной выпуклости, это надо было коммуницировать
столько раз, мы константу липшица редуцируем в s раз, ну то есть как бы s это число слагаемых,
потому что закон больших чисел, то есть как бы эта штука, она имеет, реально как бы они схожие,
из-за этого там возникает не худшая константа, а как бы константа липшица разницы, то есть возникает
ну как бы константа липшицы, не знаю где-то мне это написано, которая вот отвечает такой вот разнице
функции, ну в общем здесь есть детали, это можно посмотреть, это довольно сильно сокращает объем
вычислений, вот, значит можно пойти дальше и рассуждать о так называемых ускоренных методах,
тензорных, то есть не о методах, когда мы берем модель, ну в общем первого порядка, а метода,
когда мы берем модель второго типа Ньютона, то есть можно ли использовать метод Ньютона для вот
этих задач, я имею ввиду задачу минимизации суммы, но если она сильно выпуклая, то можно,
мы с вами про это недавно говорили, то есть если она вырождена, нельзя, ее надо регулиризовать,
а тогда уже можно и методы высокого порядка применять, вот, ну естественно тут есть всякие
отдельные сюжеты про седла, как это переносится на седла, можно посмотреть ссылки, как это все
переносится на, значит, ну какие-то конкретные неевклидовые проксы, примеры, вот Виссерштейн,
Борис Энтер, экзампов, ну и в целом, ну надо, конечно, отметить уже в заключение, что люди,
которые, в общем, ну внесли большой вклад в эту науку, ну вот началось все там около 70 лет
назад статья Робинсона Монро, Робинс Монро, это в общем классики данной области, но вот, конечно,
особо хочется отметить Аркадия Семеновича Немировского, где уже очень многое из того,
что я рассказывал, было получено, это 79 год, книжка, вот, потом были разные, конечно,
всякие, так сказать, результаты, но в основном эта наука начала так серьезно двигаться только
20 лет назад, то есть вот где-то начало двухтысячных годов, ну может быть чуть раньше, и вот многие
результаты, которые же вот мы так современно смотрим, это вот результаты последних 20 лет,
здесь есть большое число ссылок на литературные источники, но думаю, что мы, наверное, на этом
остановимся, потому что, в общем-то, ну не хочется здесь перегружать вас какими-то деталями,
а хотелось просто вот немножко так по диагонали сверху пройтись по вот всем этим постановкам,
вот, ну повторю, что мне кажется, наиболее важный результат, который вот из-за того,
что я рассказывал, вы можете, как бы, ну какой вывод сделать, что либо надо регулировать задачу
минимизации имперического риска, либо надо и ранее остановка соответствующего процедуры типа
SGD, даже не типа, а просто SGD, и что еще важно, что есть две концепции, извините, что я так мотаю,
просто хочу начало лекции, есть две концепции, как строить задачи обучения, концепция статистики,
мат-статистики, которая, по сути, требует вероятностную модель, если есть вероятностная модель,
вот она, значит, есть функционал, значит, есть правдоподобие, и вы решаете задачу стох
оптимизации. Дальше вся та же самая наука, будь то, соответственно, имперический риск минимизации,
или, соответственно, онлайн какой-то подход агрегирования, это уже не так сейчас важно,
более-менее они одинаковые. Ну так, в первом приближении, вопрос только в том,
что онлайн подход, он не требует отрешивания задачи с какой-то высокой точностью, а, соответственно,
оффлайн подход требует. Ну дальше возникают технические вопросы, с какой точностью,
все это сейчас нас не беспокоит, но важно, что именно такой способ оценивания, он, ну,
грубо говоря, наилучший. Но грубость тут заключается в том, что я должен сказать асимпатический,
при каких-то оговорках, и наилучший в каком смысле? В смысле наиболее компактного,
доверительного множества, построенного вокруг вот такой оценки. То есть, если у нас есть оценка,
полученная по принципу максимум правдоподобия, то, значит, построенный вокруг нее доверительный
интервал на основе ее вероятностных свойств, он будет наикрочайший. Ну и доверительное множество,
но для множества уже что такое наикрочайшее, это более интересный вопрос, поэтому тут надо как-то
немножко тоньше говорить. Но все это упирается в каком-то смысле вот в то, что это неравенство
Раукрамера, верное для всех оценок, оно достигает равенства в симптотике на оценке максимального
правдоподобия. Вот в этом результат, что тут равенство достигается в неравенстве Раукрамера,
именно на оценке максимального правдоподобия. Возможно, я, кстати, это плохо проговорил,
но оценка максимального правдоподобия, она обладает наимнейшей дисперсией, потому что в
неравенстве Раукрамера достигается равенство. Аналогом такого неравенства для байсовской
постановки является неравенство Вантриса. Оно просто чуть-чуть прайером скорректировано.
Вот он у меня где-то здесь, должен быть этот сюжет. Немножко скорректировано прайером. Ну и мы
поняли, что байсовская регулизация, это по сути, байсовский анализ, это по сути регулизация сама
собой естественная такая. Не всегда обязательно квадратичная, Лапласова плотность априорно
приводит к L1. Но, в общем-то, все это сохраняет как бы вот эту философию,
ну, философию статистики. Но мы от этой философии можем уйти в машины обучения,
где надо просто пастулировать функционал. Вот мы пастулируем какой функционал и забываем про
всякую вероятностную природу. Мы нигде здесь и дальше в рассуждениях не требовали закон на
распределение вероятности. Все, что мы требовали, это возможность посчитать 100 градиент. А посчитать
100 градиент, это значит просто получить сэмпл, дата, данные получить. По сути, это означает,
что у вас есть картинки, вам даже не нужно знать, из какого закона распределения они. Просто надо,
чтобы они были IID, то есть более-менее независимы из одного закона. И на этом сидит все машина
обучения, потому что вот эти суммы, это и есть проявление как бы IID с результатом. То есть,
то есть, что мы заменяем от ожидания выборочным средним, но это можно делать,
если есть независимая схема. Тогда выборочное среднее, это хорошая оценка. Мы же с вами про это
уже говорили. Если как бы есть зависимость в выборке, то это все не так про... То есть,
так нельзя вообще, говорят, делать. Ну и дальше вот ключевой результат был в том, что если есть
сильная выпуклость, тогда все хорошо. Если ее нет, то надо регулиризовать, либо ранняя остановка. В общем-то,
все. То есть, как ни странно, программа какая-то, которую мы хотели выполнить, она вот так вот
относительно быстро может быть выполнена. Но по модулю того, что вы, конечно, сами прочитаете
детали, которые я опустил, моя задача была вас как-то сориентировать, на что надо обратить
внимание. Вот еще раз, внимание надо обратить на то, что, в общем-то, есть естественная процедура
связана с принципом максимума правдоподобия. И она оптимальная. Эта процедура сразу вам говорит
о том, какой функционал. А есть процедура, где вы постулируете функционал, это называется машин
леонинг. А там, где, значит, функционал определяется по плотности и вероятности, это статистика
математическая. Но и там, и там речь идет об обратных задачах в каком-то смысле теории вероятности.
То есть, есть какая-то модель, и вы пытаетесь вскрыть, какие параметры порождает эту модель.
Только в случае статистики это буквально вероятностная модель, а в случае машинного обучения
хитрее. У вас нет параметрической модели, но у вас есть критерий качества, и все зашивается в
критерии качества. То есть, все вот эти вот какие-то там лопласты априорные или еще что-то, все это
вы как бы выдумываете сами. Но как бы статистика вас наводит на мысли, что, ага, квадратичный
штраф отвечает нормальному шуму, L1 какая-то невязка, отвечает лопластову шуму и так далее.
Далее вы, в общем, смотрите, что там как бы более, а какой-нибудь hinge loss там тоже отвечает, ну вот
мы рассматривали какую-то вероятностную модель, по-моему. И как бы дальше весь вопрос в том, что
надо делать, как решать задачу. Стох оптимизации. Есть два подхода. Имперический риск минимизировать,
это выгодный подход, если задача огромных размеров, а хранить ее на одном узле невозможно,
всю эту выборку. Либо задача вот онлайн, когда, например, есть возможность хорошо параллелить,
когда проблем вот с таким стримом нет. То есть, вы получаете поток, обрабатываете,
корректируете оценку. Ну какие же проблемы. Тем более, что это параллельно можно делать.
И вот в зависимости от контекста, что именно вам надо делать, дальше тут начинается наука,
что онлайн подход можно бочировать, допустим, когда гладкость есть, когда гладкости нет,
бочировать нельзя. Можно, значит, какие-то дополнительные трюки там делать, связанные
с выбором прокса, дивергенции. Ну, в общем, мы там какие-то вещи рассматривали. Стендзорные методы
можно использовать, типа Ньютона. То есть, делать как бы шаг какого-нибудь метода Ньютона условно,
но бочировать. Что-то там еще с гессианом связано. Это тоже можно делать. К слову, сказать,
гессиан надо бочировать меньшее число раз, чем градиент. Что интересно, для вот этих тендзорных
методов, это есть некоторое такое наблюдение, чтобы вот было нужное качество, то есть разные
размеры бача для градиента. Ну и неважно, это сейчас я в сторону. Для оффлайн подхода там в
основном проблемы аппроксимации, которые тяжелые, не все до конца сделано, особенно в категории
больших отклонений. Но тоже эти проблемы решаются. Ну и основной тут отрицательный результат,
что есть оценка, которая не улучшаема. Эта оценка говорит о том, что вылезает размерность.
Это оценка на число слагаемых, которые надо брать в негладком случае, для выпуклой задачи
сток-оптимизации. И вылезает фактор N, чтобы сумма аппроксимировала ее идеальное решение,
давала решение исходной задачи сток-оптимизации. Это фактор N, он плохой. И ровно потому,
что он плохой, задачу регулирует, что он мешает сохранить тот же эффект, что и в онлайн-оптимизации,
чтобы вот этого было достаточно. В оффлайн подходе этого недостаточное, возникает этот фактор. Но
если сделать раннюю остановку процедуры, которая для суммы SGD, то годится. Либо регулиризовать
задачу, и тоже вот этот фактор исчезнет. Вот это яркий сюжет, как бы совершенно неожиданный,
и он много объясняет в реальном машинном обучении, почему люди регулируют, почему они
делают раннюю остановку. Но вот это связано просто с математикой, в том числе с нижними оценками,
о которых мы сегодня с вами поговорили. Поскольку мы не делали перерыва, то заканчивать мне надо не в
20-30, а в 20-20. Ну что, в общем, к чему я и стремился. Ну еще раз покажу вам книжку Рыгородского Литвак,
я ее сброшу. Вот книжка выглядит, значит, таким образом. Математика информационного века,
ну вот как-то так. Но это книжка, которая в электронном виде. Почему-то в бумажном виде ее назвали,
кому нужна математика или зачем нужна математика. Еще бы назвали, кому вообще нужна эта ваша
математика. Ну как-то странно немножко. Но вот в электронном виде то, что версия у меня, название,
по-моему, очень симпатичное. Математика компьютерного века. Но как бы повторю,
что если искать ее по такому названию бумажную версию, вы, скорее всего, не найдете. Потому что
она называется кому нужна математика. Замечу, что тут есть еще другие сюжеты про бигдата,
там миллион аукционов в минуту. Очень красивый сюжет, как устроена реклама в Яндексе и других
сетях. То есть, в принципе, про Тер-САК, там кодирование. Ну в общем, я думаю, что-то из
этого вы, конечно, уже знаете, но не все. Далеко не все. И мне кажется, что, в общем, довольно
интересная эта книжка. И я вам ее рекомендую, естественно. Как вот тоже сюжетная линия. Несколько
сюжетных линий к тому курсу, который мы изучаем. Значит, заметку я сбрасываю, естественно, в нашу
группу, которая у нас математика больших данных, ну телеграм-канал. Ну и на этом, наверное,
лекция заканчивается. Где у нас эта математика? Стальные материалы к лекции я чуть
позже пришлю. Но тут все просто, потому что мы шли по книжке. Если вопросы... Хорошо. Значит,
если вопросов нет, тогда еще раз, на всякий случай, анонс того, что будет дальше. Дальше
следующая среда очная лекция Александра Безносикова. Потом очная лекция Алексея Фролова.
Потом две очных лекции Максима Рахубе. Потом очная онлайн лекция Алексея Наумова. И замечу,
что начало всех лекций в пять часов, как и положено. Это просто... Мне лекция сейчас,
из-за того, что я нахожусь не в Москве, пришлось немножко сместить расписание. Так, в общем,
все будет в пять часов. Только лекция Наумова будет онлайн, а лекции остальных будут очна и,
соответственно, они будут транслироваться онлайн на YouTube. Значит, что касается записи
этого выступления, через буквально, не знаю, полчаса, там может побольше, я ее выложу,
она когда обработается, в варианте зумовской записи с кодом выложу тоже в группу. На YouTube
она будет залита чуть попозже, как я понимаю. Пока придется пользоваться записяю через
соответственно Zoom. Ну хорошо, на этом, наверное, мы на какое-то время прощаемся до того,
что уже начнутся задачи проектов или какие-то вопросы. Я буду доступен для ответов на эти
вопросы, каких-то комментариев, но в целом уже теперь лекции будут читать другие лекторы,
вплоть до конца, до последней лекции, которую прочтет Алексей Наумов по Reinforcement Learning. Я надеюсь,
что если вот все это вы вместе соберете, как-то прочитаете материал, у вас действительно получится
такая некоторая общая картинка, потому что вот те детали, которые я опускал, это ровные детали,
как раз связанные со всякими неравенствами концентрации, вот то, что мы проходили. То есть
опущенные детали, это не пемпердикулярно другим частям курса. Я их опускал потому,
собственно, зачем 10 раз одно и то же. Можно было, конечно, это закрепить, но этим занимаются в
отдельных курсах. В курсах, например, статистической теории обучения, которая читается у нас на кафедре
Moe, там Никита Пучкин, Владимир Вячеславович Югин, допустим, читает что-то похожее. Мне кажется,
что нет цели воспроизвести такие курсы, а цель именно связать разные вещи единой математикой.
Математика машинного обучения — это во многом математика стахастической оптимизации. О чем я хотел
сказать? А математику стахастической оптимизации мы с вами уже немножко поисследовали. И в основном
это вокруг свойств условного мат. ожидания, неравенств концентрации для мартингала разности,
вот и каких-то тривиальных идей оптимизации, типа выпуклости, там гладкости, липшицевости. Вот,
собственно, вся сюжетная линия, которую я хотел обрисовать вокруг этого и дальше,
будут немножко другие сюжеты, даже не немножко, сильно другие. Но, впрочем, сюжет,
который будет Александром Безносиком, он по-прежнему связан с тем, о чем я сейчас говорил.
Тоже будет машинное обучение. Хорошо, коллеги, если нет вопросов, тогда, наверное, мы заканчиваем
лекцию. Вроде всё. Спасибо. Спасибо. До свидания. До свидания.
