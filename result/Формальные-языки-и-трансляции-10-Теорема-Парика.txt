Всем доброго дня, давайте продолжать. В общем у нас получается с пятницы наступит такое интересное
название занятия под названием колоквиум, которое нужно будет сдать. Значит по организационным
моментам у некоторых групп получается большую часть людей мы сможем принять именно на
семинарских занятиях. Некоторые допустим кто желает могут приходить на колоквиум в понедельник.
Сразу скажу, что для моих групп это преимущественно будет сдача во время семинарского занятия.
В понедельник будут времена такие, мы начнем в 4 часа вечера аудиторию уточним и там до
собственного победного можно приходить. Каждый семинарист плюс-минус организует какое-то
количество людей, которые могут сдавать в понедельник. Мы возвращаемся к последней теме,
которую нам нужно разобрать перед колоквиумом, а именно теориям парика. Давайте напомним,
про что вообще мы с вами говорили. Мы с вами построили в прошлый раз такое понятие как образ
парика. Если у нас есть алфавит, вида а1, педали аккаты, мы с вами сказали, что мы
строим отображение из сигма со звездой натуральные числа в катой степени. Здесь ноль принадлежит
множеству натуральных чисел, которое сдается следующим образом. Неужели у нас какая-то тревога?
Это количество буква а1, количество буква а2, количество буква аккаты. Мы с вами сказали,
что у нас с вами есть линейное множество. Если х, это у нас линейная оболочка некоторых,
пусть у НТ, где у ИТ принадлежит натуральным числом в катой степени. Сразу скажу, что здесь
конечное множество. Нет, стоп, секунду, я написал фигню. Р линейный давайте назовем, если Р у нас
представима. Вот так мы с вами определяли, где линейная оболочка у, это собственно все линейные
комбинации, которые у нас могут быть. Давайте, я бы сказал, что вот так, это отдельная. Мы с вами
задавали. Вот так вот. Вот, значит, при этом линейная оболочка. Что это такое? Давайте я напомню.
Альфа и Т у ИТ, где альфа и Т принадлежат натуральным числом, натуральным с нулем. А у ИТ это у нас
с вами Н в катой степени. Вот, так, сейчас, секунду, у НТ. Вот так вот. То есть мы берем вектора,
картежи у нас, которые получаются из количества букв, и их складываем. Значит, сумма двух множеств,
это у нас мы берем элемент из этого множества, берем элемент из этого множества и их складываем.
И дальше мы сказали, что R полулинейно, если R представимо в виде конечного объединения линейных множеств.
Вот, и мы с вами определили понятие линейного прообраза и полулинейного прообраза. Соответственно,
это те языки, образ парика, которых линейн, и полулинейн, соответственно. И мы с вами в
прошлый раз формулировали две теоремы, наш цель которой еще один доказать. Первая теорема,
которая мы с вами будем доказывать для любого. Это простой факт достаточно. Для любого полулинейного.
Что там написано? Ну, давайте обозначим размер фавитом. Существует R регулярный,
такой что, собственно, все от R равно X. Образ парика, это штуки, это регулярный язык. Это
полулинейное множество. Ну, давайте подумаем, как мы можем с вами работать с полулинейным множеством?
Какой у нас есть аппарат для этого? Какой? Что мы ввели для полулинейного множества?
Смотрите, это объединение линейных множеств. Ну, собственно, давайте начнем с этого доказательства.
Итак, если у нас X полулинейно, тогда X раскладывается в объединение, где X и T это линейное.
Найдем. Давайте напишу так. Регулярное выражение либо регулярный язык. Такое,
что Psi от R и T равно X и T. Тогда вопрос. Psi от чего будет равно X нашему? Ну, конечно.
А это язык какой будет? Объединение регулярных какое? Регулярное. Хорошо. Давайте искать
такой регулярный язык. Значит, рассмотрим произвольное XGT. Оно линейное. Тогда что мы можем
сказать про этот XGT? В каком виде мы его можем представить? Мы можем его представить в виде A
плюс линейная оболочка некоторого множества B, где при этом множество B у нас конечное.
Ну, давайте придумывать регулярку. Итак, поскольку у нас B конечное,
это значит B состоит из каких-то множеств B1 и тогда BLT, где B и T у нас принадлежит N в степени
нашего алфавита. Ну и A получается у нас такое же. Сейчас будут индексы.
Произвольное. Теперь смотрите. Давайте поймем, что же на самом деле B и T такое. А B и T это на самом
деле B и T1, B и T2. Это же кортеж. B модуль сигма. Ну, где B и T не отрицательные.
А здесь индекс M. Не обязательно одинаковое количество. А мы берем два множества и их
объединяем. То есть мы берем произвольные элементы отсюда, произвольные элементы отсюда,
складываем их, получаем результат. Итак, давайте явно предоставим слово. Так, мы алфавит обозначили
как-нибудь? Ой, у нас маппинг определений. Так, что сделаем? У нас буковки А там, это буковки
алфавита. Давайте здесь C обозначим эту штуку. Итак, давайте напишем явно слово, образ которого
будет равным B и тому. Ну да, смотрите, нам нужно слово, в котором вот столько букв А1, столько букв
А2, столько букв, получается А последнее количество. Да? Собственно, пишем это слово. А1 в степени B и 1,
А2 в степени B и 2 и так далее, А и получается, что там, о господи, так, а модуль сигма, модуль
сигма равная B и T. Ага, ну в нем получается столько букв А1, столько букв А2, столько букв получается
А3 и так далее. Так, хорошо. Так, а теперь давайте подумаем,
Пси, от чего будет у нас сумма АИТ и БИТ? Давайте это как-нибудь обозначим. Пусть это у нас W,
пусть это будет у БИТ. Как тогда задать вот такой образ? Коэффициент произвольный? У нас линияная оболочка?
Да, то есть смотрите, нам нужно вот эту вот всю вещь повторить АИТ раз, произвольная. А что значит
произвольное количество раз не меньше нуля? Повторите произвольное слово. Звести звездочку? То есть у
нас получается, что это Пси. Вот, господи, сейчас мы будем колдовать. Стоит вести определение, например,
стоит А, вот, и БИТ. Да.
Во. А? Не, не строго больше нуля. Не, мы вводили не меньше нуля.
Мы искали нутральное с нулем. Так, образ этой штуки мы написали с вами. Так,
теперь нам нужно написать образ вот этой штуки. Ну, давайте опять же аналогично
введем. Значит, слова У, Ц, И, Т такие, что Пси от У, Ц, И, Т равно циитому. В принципе,
делается ровно тем, что нам подсчетом, да? Почему? Где Б? Где, где, где Б?
А, да, конечно же. Да, да, да, да. Все, спасибо. Да, я в индексах запутался. Так,
значит, теперь смотрите, как задать множество ц? Да. Если что, это сложение регулярных выражений.
С. Ага, и тогда у нас ответ какой получается? Как слово в итоговое выглядит? Как наш
итоговое регулярное выражение будет? Да. Циит это кортеж. У циит это слово, образ парика,
которого это кортеж циит. Ну, то есть она строится так. У нас циит и кортеж. Мы считаем
каждый раз количество букв и говорим... Где, где, где? Нет, это маленькие. Да, это кортеж.
Умножить на... Господи, я надеюсь, я не обсчитался. Ц, плюс линейная оболочка Б. То есть сначала
берем произвольное слово здесь, потом берем произвольное слово здесь, отсюда. Получается
количество букв, которые здесь и здесь складываются, поэтому здесь получается сумма. Вроде сошлось.
Вот, ну то есть это чистая вычислительная задача. Ну да, мы нашли экзиты, а дальше нам нужно
их объединить всех. Вот эти вот, для каждого экзита нам вот эти штуки нужно объединить.
Ну, собственно, это доказательство. Давайте проверим. Ну, здесь немножко по-другому сделали.
Здесь взяли сумму, взяли со звездочкой. Мне кажется, это не особо отличается. Примеры,
собственно, а примеров не видно, потому что свет горит, да? Ну видно, линейная оболочка 1,
2, плюс линейная оболочка 2, 1. Это, собственно, мы берем АБ квадрат и А квадрат Б и делаем над
этим всем звездом. Здесь такой же пример, а здесь вот такой вот пример, собственно. Ничего здесь
сложного особо нет. Так, с этим пунктом разобрались? Так, еще раз.
Нет, ну тут же мы считаем количество букв только, поэтому неважно. То есть, в принципе, тут как
раз слова коммунитируют в смысле образа. То есть, неважно, как одно слово написать,
одно слева, другое справа или наоборот. Так, а теперь сложная часть этого картобалета,
состоящая в том, что нам надо доказать следующую вещь. Теперь мы парик будем доказывать,
что если ЛКС язык, то на самом деле это прообраз некоторого полуминейного множества. И вот здесь
нам понадобится еще одна лемма о разрастании. Третья уже. Так,
значит ЛКС язык, следовательно, полуминейное множество.
Ну что, давайте докажем этот факт. Но честно, тут доказательство такое крайне не тривиальное,
и поскольку в прошлые года эта лекция была последней, а на ней мы рисовали очень много
елочек, то будем считать, что мы отвечаем не знаю чего. То есть, это была новогодняя лекция,
но сейчас, к сожалению, это не новогодняя лекция. Вот, это в принципе мы с вами говорили. Так,
давайте лему о разрастании докажем. Обобщение. Давайте рассмотрим, что у нас ЛКС язык.
Тогда существует П, такое, что для любого слова, лежащего в этом языке, длина которого хотя бы П.
Существует разбиение. Так, сейчас забыл. Любого К. Забыл вставить больше нуля. Существует такое П,
что для любого слова языка, длина которого хотя бы больше П, существует разбиение.
Х, У1, УКТ, У, ВКТ, В1, З. Такое, что, значит, получается длина вот этого штуки, вот этого
разрастания не больше, чем П. Значит, для любого Г, получается длина УГТ, ВГТ, длина разрастания больше нуля.
Такое, что у нас есть дерево вывода. Я не пишу что-то, для любых индексов мы можем разрастать это
как угодно, потому что по факту это будет разрастание. Вы не против, если я картинкой
нарисую вот эту штуку. Смотрите. Так, что у нас?
Что это такое? Елка. Вопрос, как разрастать? Для контекста свободных языков. Ну, почти можем.
Нет, тут для любого К. Мы доказали для К равную единицу, на самом деле, этот факт.
Не очень хорошо, нет, не хотим. Не, ну индукцию. Давайте вспоминать, как мы доказывали оригинальную
лему разрастания для контекста свободных языков. Да, причем брали грамматику в нормальной
форме Хомского, брали достаточно большую глубину дерева таким образом, чтобы у нас какое-то
правило выводилось ровно два раза. Идея тут ровно такая же. Единственное, что надо П правильно задать.
Итак, опять же, давайте возьмем грамматику в нормальной форме Хомского и возьмем П равное
два в степени Н на К. Ну, факт из этого следовать будет, что мы можем сколько угодно что-то повторять.
Ну, мы можем везде, где у нас есть не терминал, подвешивать либо У2, У2, либо УК, ВК, либо произвольные
из них. То есть берем подвешиваем. То есть у нас получается просто индексов здесь много быть. То есть
мы можем просто в любой момент либо разрастить У1 в какое-то количество раз, либо У2 в какое-то
количество раз, У2, В2, либо У3 и так далее. В чем произвольном порядке. Вот, как раз для этого нам
нужно было с вами использовать вот такие вот интересные фишки. Так, ну смотрите, у нас длина
слова хотя бы ДВ значит длина. Следовательно, у нас высота дерева вывода. Что у нас получается,
Господи. Мы с вами в какой-то момент вывели оценку из того, что у нас дерево бинарное.
НК плюс 1. А что это значит, что у нас высота нашего дерева хотя бы количество не терминалов плюс 1?
Да еще помноженное на К. Да, причем хотя бы К плюс 1 раз. Вот. И получаем, что у нас есть не
терминал А, который повторяется хотя бы К плюс 1 раз. На слайде? Да, на самом деле единиц не хватает,
но там логарифм на двоечке, а длина слова ДВ это НК, поэтому там НК плюс 1 получается. Да,
надо слайд поправить. Ну и вот, ну и давайте возьмем это слово. Берем самый нижний К плюс 1 вхождение,
как мы это делали в прошлый раз. Получаем такое дерево. Ну это пример. То есть если мы с вами
посмотрим на картинку, рассмотрим самое глубокое вхождение. Кто может напомнить,
почему мы смотрим самое глубокое вхождение? Ну для того, чтобы ограничить длину вот этого вывода.
Да, ну мы с вами говорили, что если у нас в обычном случае эта длина вывода не очень большая,
то можно прямо оценку сверху на количество не терминалов, которые на высоту этого вывода
получить. И получаем, что у нас это все сверху будет ограничено.
Сверху ограничивается. Там что-то логарифм. Как раз логарифм. Сейчас. 2 в степени логарифм,
там было Н на К. Ну а собственно это число П. Вот. А почему у нас УКТ и ВКТ не пустые?
Кто мне может напомнить? УИТ и ВИТ, почему не пустые?
В смысле как раз встречается? Да, мы берем отсечение по К буквам А. Которое, точнее самое
глубокое отсечение по К плюс одной буквы А. И стартуем именно отсюда. В чем вопрос? Может быть,
я не понял. Мы берем самое глубокое отсечение по деревьям и поднимаемся вверх? Нет, у нас есть ветвь,
в которой есть хотя бы К плюс одна буква А. Какой-то не терминал. Мы берем из всех ветвей такой не
терминал, у которого К плюс первая буква встречается как можно глубже. Но чтобы остальных буква просто
не было. И других не терминалов не было. Потому что если бы они были бы, мы бы спустились еще ниже
и сжали бы наше дерево. Вот. И получается сверху ограничение на высоту этого дерева вывода. Высота
будет не больше, чем количество терминалов на К. Из этого, как мы в прошлый раз доказывали,
обычно лему о разрастании, у нас появляется оценка сверху на П. Вопрос, почему у житое выжитое не пустое?
Да, потому что мы находимся в нормальной форме хомского. Я отсылаю всех желающих доказательств
2 лему о разрастании. Пл2 это если что пампинг лемма 2. Ну вот, вроде доказали этот факт. Есть
вопросы по доказательству этого утверждения? Это высота дерева. То есть у нас длина дерева вывода
не больше, чем двойка в степени высота этого дерева. Ой, да, все согласен. Давайте перепишем это все.
Там, по-моему, плюс-минус 1, по-моему, вот так это было. Вот, это П. Вот, то есть получается,
у житое выжитое больше нуля. Ну, собственно, поэтому у нас есть такое дерево вывода, и мы им будем пользоваться.
Понятно ли доказательство? Так, вот это дерево мы не стираем, потому что мы сейчас им будем пользоваться.
Вспоминаем, раньше мы лему о разрастании использовали только в отрицательной коннотации.
Говорили, что пусть оно не выполнено, тогда, собственно, что-то делаем. А здесь мы его будем
использовать в положительной коннотации. Итак, давайте вернемся к доказательству нашего факта.
Давайте рассмотрим Л. У нас КС язык. Единственное, сейчас надо вспомнить, чему взять К. Так,
сейчас, секунду. Во, замечательно. Давайте лему о разрастании немножко попозже. Берем Ж.
В НФ Омского. И давайте введем следующий язык. Элема G это множество всех слов w таких,
что только по нетерминалам из m. m это произвольное подношение терминалов в
то есть мы будем использовать только не терминалы м да при этом понятно что с будет лежать то есть
если м не содержит стартовое состояние то если м не содержит стартовый терминал то ничего вывести
мы не можем потому что его просто нет давайте формулируем некоторые понятия первое что мы
можем сказать про элема дж как соотносится элема дж
раз а чему равняется объединение всех элентах
вот и еще важно что забыл сказать давайте сделаем так что элема дж всегда содержит не
терминалы м то есть вот этот пример показывает что если у нас множество м не терминалов содержит
с а б и мы из с повторяемся вывести а а а с а в м а а то а не будет лежать в элема дж потому
что там нет не терминала б дайте выточенную причем все не терминалы используются вот и мы
будем доказывать следующее что элем а дж это линейный прообраз
тогда
объединение по всем не терминалом а дж это будет у нас полу линейный прообраз
собственно что мы хотим доказать а теперь давайте посмотрим на вот это замечательное
дерево так понятно почему если мы докажем что а дж это линейный прообраз то то и весь язык у
нас является полу линейным прообразом я там полу линейным написал все отлично так смотрите
а теперь замечательная фишка давайте рассмотрим как количество не терминалов и п излема
разрастания так а на всякий пожарный ну можно модулем
попробовать взять этого должно хватить вот и давайте теперь посмотрим на следующие вещи пусть
у нас x сейчас в общем идея такая вот у нас видите елка большая длинное слово слово длины хотя бы
давайте мы разрежем эту елку на несколько частей первая елка будет состоять это знаете фундамент
такой елки маленький прототип елки ну видели там сборную конструкцию какой-нибудь это елка у
которой не очень высокая которая вот слово длины не больше чем п и всякие эти аддоны к ней а вот
в качестве аддонов мы будем использовать вот эти вот аддоны вот вот это у нас каркаса это у
нас аддона и докажем что наш язык это на самом деле ничто иное как вот этот каркас плюс
линейная оболочка наших аддонов вот собственно это мы и будем доказывать давайте теперь чуть
формальнее в общем давайте x это у нас будет все от w для всех слов образ длина не больше чем
п собственно y будет такое что длина не больше чем п и у нас вывод как раз вот эта
куска только по не терминалы мз так давайте перепишу все от л
только по не терминалам мз
контрольный вопрос почему все эти множество конечным почему x конечный y конечным
тоже слов конечно конечно же вот и будем по ночь после перерыва доказывают два утверждения
по обе стороны что на самом деле все от л ма дже равняется x плюс линейная оболочка y
одно доказать одна сторона будет конструктивной другая красивая с точки зрения теории
да да да
фишка состоит в следующем напоминаю значит давайте кантилет с континю плис смотрите у нас
значит деревья вывода этого слова будут все не терминал из множества м и здесь будут
все не терминал из множества м а этом давайте рассмотрим пусть у нас есть какое-то число
т кортеж принадлежащий x плюс линейная оболочка y это значит что наш кортеж
выглядит как следующее у нас есть какой-то и все это плюс сумма альфа и ты и ты так ведь
логичный так теперь смотрите а давайте поймем что это значит что вот эта штука лежит фикс
следовательно существует такое выжитое что эта длина выжитого не больше чем длины
п и это выжитое лежит в л м дже так ведь все логично а теперь строим картинку значит дереве
слова вывода вот этого вышитого есть все не терминалы из м пока что картинку нарисовали
теперь смотрите что означает что игреки ты лежит в игреке это следует что из этого
следует что существует такая пара пара уитая витая и существует такой б и ты лежащий кстати
множестве м и только из них такое что у нас есть дерево вывода б и ты выводу и ты бы и ты
вы и ты слишком много индексов и что мы можем сказать про эти индексы б и ты если они в этом
дереве вывода из s слово wg т если тут у нас не терминал бы один в этом дереве вывода есть а почему
смотрите бои ты лежит в м дубль выжитое лежит в л м дже а что значит условия лежит в л м дже
значит все не терминалы из м у нас используется а это значит что в этом дереве есть точно где-то
не терминал бы один так ведь давайте найдем но найдем б2 найдем б3 найдем б м т значит и теперь
прикол почему это называется почему это называлось елочной лекции потому что по факту каждый из этих
аддонов мы теперь спокойно можем подвесить к какому-то из этих кусков если нам надо
разрастить б1 из у1 б1 в 1 то мы к тому месту где у нас есть б1 подвешиваем у1 б1 в 1 при этом у
нас же слово будет вот это дополненно лежать в л м дже если мы подвесим к б1 вот сюда вот этот
кусок дерева вывода ну конечно он будет висеть потому что у нас все не терминалы из м есть вот ну
и поэтому значит берем следующую конструкцию подвешиваем альфа катая раз так давайте альфа
вот полученное слово будет лежать в л м дже но потом а подвешим ну ровно находим не терминал
б1 и нам надо разрастить наше слово целиком но чтобы найти точнее слово про образ которого
является нашим множеством вот это вот вот это вот слово это слово образ которого это
элемент множество x нам надо подвесить добавить сюда единичку к игреку какой-то игреки ты взять
мы берем допустим игрек один находим не терминал б1 он точно есть берем за него подвешиваем поскольку
у нас неважно в каком порядке стоят буквы для того чтобы получить образ парика то берем можем
подвешивать любое место то есть берем и встречаем тогда у нас получается что psi
грубо говоря там дубль выжитая и давайте я не знаю как написать какой буквы какой буквы хаус
обозначим можно культурно можно не культурно да какое-нибудь слово
давайте вот так обозначим это оператор хаус что мы в любое место в какое-то место вставили
слово у 1 в 1 я не знаю просто как обозначить это значит слово у нас есть слово выжитая но где-то
в промежутке в этом слове выжитом мы еще вставляем слово у 1 а где-то вставляем
условия 1 непонятно в какое место на презентации это просто картинка короче которая все поясняет
да вот но поскольку неважно куда нам это вставлять это все равно все от выжитого плюс все от у 1 в 1
вот это у нас игрок один а это у нас экзитове то есть неважно куда мы ставим словом все равно
образ парика будет его вот таким вот экзитой и у 1 игрок один а поскольку у нас есть это не
терминал мы можем его подвесить куда угодно и мы получаем слово вот это вот слово будет лежать
в элемент же потому что вот это слово содержатся не терминалы изн и только их а это тоже в выводе
этого слова мы используют только не терминалы из м так и таким образом мы можем подвесить
каждое слово альфа и т.б. и т.п. определенное количество раз и получить получается произвольное
множество отсюда оно будет лежать в элемент же
во
картинку показать красивую в общем для тех кто это собственно это вывод построим про образ для
х вот то есть нашли б1 подвесили к нему нашли б2 подвесили к нему нашли б3 подвесили к нему
и так далее что в одну сторону кажется доказали да что вот это вещь выложена вот эту вещь
теперь в обратную сторону нам у нас есть какое-то дерево вывода нам его надо распилить
ну представьте себе искусственную елку вам надо взять искусственную елку собрать значит причем
поскольку значит ситуация плохая это кризис все дела нам нужно сделать так что если допустим
елок нам не хватает да мы могли каждый из кусок поставить как отдельную елку чтобы она не
отличалась от оригинальных елок собственно давайте это делать значит
заметьте эту картинку не стираю
господи тяжелые реалии так давайте обратную сторону докажем что
господи вот так вот ну что индукция по длине слова
где вы лежит в эле моджа база как вы думаете какая база у нас будет
ну тут можно общую базу сделать для нас раз длина слова не больше чем п
тогда что мы можем сказать ну да потому что у нас x определялся как образ всех слов длина не
больше чем п переход у нас длина слова больше чем п это значит что мы можем с вами сделать
мы можем применить лему о разрастании 3 и так применяем лему разрастание 3 что мы получаем
тут нужно некоторый счет опять же возьмем самое глубокое дерево в общем всю конструкцию
которая у нас была немножечко перерисуем ее и так что у нас будет с вами здесь у нас
будет дальше у нас будет а x z сейчас единственное дайте мне посмотреть обозначение чтобы они из
презентации соглашались во обозначим наши слова мы кажется ко взяли количество правил
грамматики да значит тут а 0 так что дальше на ката так какая то у нас количество не
терминалов если что и тут у нас получается что внизу y да цель нашего всего этой ситуации тут
у нас будет а в степени количественные терминалов минус 1 найти кусок который мы можем с вами отрезать
что необходимо для этого куска который мы с вами хотим отрезать мы хотим чтобы длина этого
куска была не больше чем п ну нашего под дерево при этом в нем точно содержались бы все не терминалы
из м да а смотрите я кстати тут оговорился кажется мне хорошо вопрос задали значит здесь могут
быть не все не терминалы из м вот я кажется давайте уточнение то есть тут могут быть произвольные
не обязательно все но здесь должны быть все не терминалы из м то есть нам надо отрезать кусок
такой чтобы при убирании него количество не терминалов разных в этом деле вывода оставалось
ровно таким же а теперь давайте считать рубрика комбинаторика и принцип дирекле
потом формально ведем вот смотрите давайте подумаем вот вот здесь вот у нас сколько не
терминалов разных может быть
количество не терминалов всего но утверждение такое что когда смотрим на это дерево вывода
в нем в принципе могли встречаться все не терминала да но без буквы а сколько не
терминалов в этом деле вывода без отжитого там может сказать сколько тут не терминалов
без отжитого без ашек они на один меньше может быть и хуже да смотрите мы брали
вся мое глубокое вхождение из м минус одного термина не терминал это значит что вот по цепи
вывода у нас не терминала а на самом деле не было вот давайте как раз это сейчас вот все
не терминала выводя вот и тогда смотрите что получается а утверждение следующее что
вот здесь вот их не больше чем а минус 1 здесь сколько не терминалов
вот здесь ну хотя бы но ну хотя бы 0 но то есть получается смотрите вот здесь у нас не больше
чем n минус 1 здесь у нас точно хотя бы 0 а теперь смотрите что у нас получается если мы обозначаем
м и т кроме а
мы поняли с вами что м 0 не больше чем количество не терминалов минус 1 но при
этом это больше равно чем нам один м n вопрос сколько у нас здесь чисел
в этой последовательности сколько элементов в этой последовательности
количество не терминалов
да выводе из ажитого то есть грубо говоря м2 это количество не терминалов которые идут вот
этом дереве в котором выкинули все буквы а сколько у нас их сколько чисел у нас от
нуля до количества не терминалов количество терминалов плюс один количество значений сколько
так это значит что
в принципе дирекле
а что значит что у нас количество не терминалов вы в выводе не поменялось то есть смотрите у
нас какая картинка у нас картинка следующий что у нас есть а т дальше выводим а т плюс
и количество не терминалов которые есть в этом выводе совпадается количеством не терминалов
которые есть в этом выводе это значит что если мы выпилим вот эту вот часть то мы не выкинем
никакого не терминала давить да собственно вот эту штуку нам надо выкинуть тогда а т т
а получается так там все хорошо не меняет количество не терминалов
но мы берем такие ребята значит у вас вот это вот елочка которая вот здесь
была она была хорошая мы просто берем утаскиваем ее с собой
давайте давайте финализируем
как написать бы
x у 1
я просто выписываю в 1 z вот это вот слово будет лежать в эле модже
да мы это с вами доказали как раз выкинув эту часть тут нет т плюс один и получается
слово у получается фи си у т плюс один ф плюс один принадлежит игреку выполняем адапционный переход
на этом доказательство те рем заканчивается потому что мы доказали что каждый образ или а дж это
линейное множество да еще раз этот шаг значит мы ищем такой момент в котором в подглубине
не меняется общее кроме этого не кроме а а шки это значит вот вот в этом вот под куски вывода
вот которые вот вот нас здесь раскрывается если мы его выкинем то количество терминалов не
поменяется разных которые используются в этом по дереве это значит что если мы вот эту штуку
при фигачем к этой то если в ней были во всем дереве выводов были не терминала из м причем
все, то и без вот этой штуки останутся все эти терминалы из m, и все будут использованы.
Значит, вот эту вот штуку мы относим к y, а вся остальная штука остается в lmg.
Мы слово уменьшили, поскольку у нас длина, ужитое, выжитое, вот этое, вот этое больше нуля.
Уменьшаем длину слова и делаем индукционный переход.
Хорошо. Понятно доказать теоремы?
Вот, в колоксе оно, по-моему, разбито на три вопроса.
Так, давайте следствие, быстро докажем следствие.
Такое?
А, следствие? Ну он золотый днис доказывается.
Ну, чуть-чуть.
Не, можно это при помощи лемма о разрастании доказывать, конечно, потому что, на самом деле,
теорема парик освоится к тому, что мы просто используем лемму о разрастании, по факту.
Следствие, любое однобуквенное язык.
KVS язык регулярно.
Однобуквенный.
Альфавита за одной буквой состоит.
Почему?
Ну, потому что есть регулярка над тем, что алфавита для вещей.
Ну, да, смотрите.
Значит, что такое язык над однобуквенным алфавитом?
Мы понимаем с вами, что...
Господи, давайте я напишу следующее, это будет страшно.
Все помните, что это такое?
Что это за знак?
Не, не изоморфизм.
Равномочность. То есть у нас есть биекция между сигмой со звездом и натуральными числами.
Ну, потому что любое слово...
Не, не, не.
Изоморфизм, по-моему, вот так обозначается.
Да, в общем, разномочно, потому что любое слово имеет вид авкатой.
Да?
Ладно, пусть будет N, если мы с нулем считаем. У нас все равно все с нулем.
Хорошо, а теперь смотрите, примейте ремпарика.
Угу.
Ну, значит, что такое? Псиатель.
Это X.
Там.
Линейные, да?
Ну, давайте рассмотрим одно из них. Если каждый из них будет регулярным, то и все объединение будет регулярным.
Ну, а что такое X и T?
Это некоторое С плюс линейная оболочка В.
Да?
Ну, где С и В конечное множество.
Ну, а дальше, тут уже можно как угодно говорить.
Поскольку у нас с вами натуральные числа и эти изоморфины, то тут можно делать все, что угодно.
То есть, на самом деле, здесь у нас какой-то С1 и так далее, СМ.
Ну, а дальше, тут уже можно как угодно говорить.
Ну, а дальше, тут уже можно как угодно говорить.
То есть, на самом деле, здесь у нас какой-то С1 и так далее, СМ.
А здесь у нас получается В1, кто ли, ВМТ.
Ну, собственно, вот эти ребята задаются как А в степени В1 получается А в степени ВМТ со звездой.
Вот так.
Вот, а эти задаются А в степени С и В.
Ну, собственно, помните, как мы доказывали первый факт, что прообраз, существует регулярный прообраз?
Просто здесь из этого будет именно вывод, что это именно регулярный прообраз. Обязательно такой.
Нет, не обязательно.
Вот так вот.
Ну, то есть, это красивый вывод.
Из того, что просто образ парика по факту является Ч.
Биекция между множеством натуральных чисел и Сигмы со звездой.
Так, ну что, понятно доказательство этого факта?
Хорошо.
А давайте тогда я сейчас немножечко-немножечко начну говорить про то, про что будет наша следующая часть курса.
Да, все, выдохнули. Мы закончили с категорическими грамматиками в их классическом проявлении.
И сейчас начинается самая интересная часть нашего курса.
Вы помните, какой алгоритм мы с вами уже парсинга проходили?
И почему он нам не понравился?
Кока-янгеракасами мы проходили алгоритм с вами.
В чем его проблема была?
Он вообще долгий, куб.
И вообще он просто берет и делает динамическое программирование.
Это крайне интересно.
И на практике вообще неприменимо.
Поэтому целью нашей вот этой части, посвященной именно парсингу, будет построить такое семейство алгоритмов,
которое, во-первых, как-то учитывало, что мы находимся в каком-то дереве вывода.
Что у нас есть дерево вывода.
А во-вторых, учиться именно парсить входной текст достаточно эффективным образом.
На самом деле первый прообраз нашей теоремы, нашего парсинга, мы уже с вами проходили.
Посмотрите внимательно то, как мы можем из кс-грамматики построить mp-автомат.
Вот если внимательно посмотреть и немножко развернуть конструкцию, которая получится, мы с вами получим парсер.
Кажется, на семинарию своей группы я это делал.
Но, собственно, потом сейчас тоже мы можем это сделать.
Виталий про это тоже, наверное, скажет.
Итак, давайте рассмотрим.
Значит, у нас есть парсер.
Он работает с грамматикой нормальной формы Хомского.
Но можем ли мы сделать парсер для произвольной грамматики?
Вот такой у нас вопрос!
Произвольная кодекс-свободной грамматика!
Для кодекса-обедной формы Хомского мы можем парсер построить?
Мы его уже строили.
Мы его уже строили.
Можно ли мы его построить для произвольной грамматики?
Давайте рассмотрим такую грамматику.
S-v-u-e-t-s-b, c-s-v-u-e-t-s-o-m.
Что это за грамматика?
Какой язык она задает?
Аббревиатуру из трех буквок.
P-s-p — это правильность кубочной последовательности.
Давайте разберем какое-нибудь слово.
Построим дерево разбора.
Дерево разбора такое.
И вот давайте попробуем это дерево разбора пройти в глубину.
Там нормально видно на слайде?
И давайте сделаем две пометки.
Первая пометка — это то, откуда мы пришли,
и вторая — то, где мы сейчас находимся.
По факту, что нам необходимо для того, чтобы реализовать поиск глубину?
Давайте, господа программисты математики.
На каких особенностях у нас реализован поиск глубину?
Дерево.
Что мы находимся в стеке.
Что если мы находимся в каком-то месте, в обходе DFS,
то, в принципе, выйдя из функции, мы вернемся к родителю
и мы находимся в текущей позиции.
То есть на самом деле это нам позволяет реализовывать это на стеке.
И, в принципе, если мы понимаем, куда нам выпрыгнуть,
в аккосе, я не знаю, был такой термин Calling Conventions.
То есть если мы правильно с вами зададим Calling Conventions,
то, в принципе, нам важно знать только просто,
где мы сейчас находимся и куда нам обратно возвращаться.
И давайте на этой основе попытаемся построить парсер.
Итак, давайте обходить дерево.
Парсер.
Итак, давайте обходить дерево разбора.
Смотрите, точка.
Видите, черная точка появилась.
Давайте попытаемся гипотетически обойти это дерево разбора.
Возможно, будет парсеров очень много, много разных способов.
Куда мы пойдем сейчас с вами?
Перед буквой А.
Мы прыгаем вниз.
При этом, когда мы идем в DFS, мы не забываем, откуда мы прыгали.
Что мы сделаем?
А правила разобрать не надо?
У нас слово ААББ.
Нам бы его надо разобрать.
Давайте подумаем.
Если бы у нас в этой штуке первая буква была ББ,
мы бы что сказали, скорее всего?
Ну, сказали до свидания, потому что первая буква у нас не совпадает.
А теперь смотрите.
У нас первая буква А в нашем слове.
И как раз вот та шапка, которую мы насадили, хорошо нам подходит.
Поэтому давайте просто прочитаем букву А
и сдвинем нашу точку за букву А.
Да, Вить?
Ну вот.
Просто это мы гипотетически обойти.
Ну вот.
Просто это мы гипотетически будем делать для всех подобных конструкций.
Так, встретили не терминал.
Что делаем?
Да, при этом построить дерево вывода.
Ну вот, нам надо понять, как строить это дерево вывода.
Я как раз разбираю гипотетическое дерево вывода,
которое мы якобы уже знаем, и хочу промотать инструкцию.
Как мы обошли это дерево вывода.
Только просто история такая, что мы сейчас правила грамматики
превратим некоторые конструкции, которые мы можем с вами соединять.
Ну вот, смотрите, если мы встретились с препятствием,
что мы стараемся сделать с этим препятствием?
Убирать его?
Ну, значит, все действия алгоритмов, про которые будет говорить Виталий,
будут прямо проходить его.
А если мы не можем пройти на пролом, то мы что делаем?
Обходим его, да. Именно спускаемся вниз.
И смотрите, для того чтобы получить Calling Conventions,
мы берем и спускаемся вниз и точку тянем за собой.
Да, то есть куда мы должны вернуться обратно?
Какое английское слово вы говорите?
Какое?
Calling Conventions.
То есть когда мы...
Да, термин для тех, у кого нет окост.
На самом деле, когда мы вызываем какую-то функцию,
мы на самом деле что-то в регистрах должны хранить.
И для того чтобы вернуться из функции,
нам необходимо понять, в каком месте мы находимся,
в какой стэк у нас содержится и где у нас указатель,
где мы вообще находимся.
Поэтому специально говорится, что в определенных регистрах
мы сохраняем информацию, которая необходима для того,
чтобы мы могли вернуться из этой функции.
Вот, это называется Calling Conventions.
Механизм, соглашение при вызове функций.
Да, да.
Причем точки эти мы потом трансформируем в позиции,
где мы находимся в слове, то есть в какой букве мы находимся.
Вот, смотрите, дальше мы... Следующая буква А, окей.
Дальше мы спускаемся вниз.
Поскольку слово пустое, то мы находимся здесь.
Так, теперь что делаем?
Мы дошли до конца правила,
и мы находимся в каком-то не терминале.
Это значит что?
Мы разобрались.
Значит мы эту точку можем обойти.
То есть если у нас получается черная точка,
и черная точка находится в конце правила,
а верхняя точка стоит передний терминал, мы ее можем обойти.
То есть мы можем замкнуть наши препятствия.
При этом, поскольку у нас есть Calling Conventions для вот этой вот точки,
то когда мы вернемся здесь, мы поймем, что точку надо вернуть сюда.
Для этого нам нужен указатель на родителя.
То есть смотрим указатель на родителя здесь, он был здесь,
и перемещаем эту штуку.
Ну и повторяем такую процедуру.
Потом опять возвращаемся вверх, проходим вот это сюда,
переходим сюда, спускаемся вниз, проходим сюда,
обходим слово целиком.
Обход в глубину.
Только вопрос в том,
а если у нас ни одно дерево вывода, что делать?
Ну вот, оказывается, на самом деле все эти дыры,
ну вот, оказывается, на самом деле все эти точки можно закодировать позициями.
Дерево входим в глубину, по позициям точек можно обойти дерево разбора,
точки кодируют правила вывода.
И идея следующая.
Давайте мы с вами для каждого правила ведем такое понятие, ситуации,
мы его еще в следующий раз определим.
Допустим, мы разобрали какую-то часть правила альфа,
и нам осталось разобрать часть правила, связанную с бетой.
И мы находимся в текущей позиции точку,
и говорим, что вот это вот правило,
это ситуация, а, стрелочка, альфа, точка, бета,
запятая и принадлежит некоторому мнению множеству джи-тэ.
Что такое и жи по факту?
Позиция вот этой круглой точки, полой точки,
это и позиция родителя,
сколько мы символов разобрали в родителе,
а жи это наша текущая позиция.
Ну альфа и бета, это левая часть правой части правила
и правая часть правой части правила.
Вот пример.
Вот, сейчас давай.
Вот пример.
Давайте разберем его.
Значит, как задать это правило?
У нас есть с,
мы разобрали уже кусок ас,
и у нас осталось разобрать кусок бэта.
Вот, вот, вот.
Нас разобрали кусок ас
и у нас осталось разобрать кусок бэс.
При этом здесь мы разобрали одно слово,
а здесь мы разобрали уже одну букву,
а здесь мы разобрали две буквы.
Поэтому эта ситуация кодируется таким образом,
что из с мы вывели...
находим ситуацию с, стрелочка ас,
точка, вот эта жирная точка, ela здесь, б-с.
При этом здесь мы разобрали одно слово,
А вот здесь у нас нижнее правило говорит, что мы уже разобрали два символа слова.
Вот такой математический термин мы можем с вами зашить.
И теперь утверждение следующее, что на самом деле нам не важно,
где мы находимся в дереве вывода.
Какой родитель, какой контекст. Нам достаточно вот эти вот позиции.
Только их.
А?
Ситуация состоит из правила грамматики.
Раз.
Левой части до точки.
Точка стоит в произвольном месте правила.
Правая часть после точки.
Ситуация в родителе.
Позиция, сколько букв мы прочитали после родителя.
И сколько на текущий момент мы прочитали букв.
Значит две буквы мы прочитали. Вот они. Буква А и буква А.
И это сколько букв мы прочитали до вот этого момента.
А?
Да, да, да.
Просто почему это называется D2? Потому что это удобно будет хранить в виде множеств.
А на сколько угодил квадрат?
А алгоритм будет работать за куба длины слова, но с сильно меньшей асимпточкой, чем алгоритм Эрли.
Ой, чем алгоритм Кока-Янгера Касами.
И в случае однозначной грамматики он будет работать за квадрат.
С меньше константов.
Да, да, да.
Либо куб сильно меньше константов, либо квадрат.
Ну и в общем смотрите.
Последний момент, как это можно перешифровывать.
Оказывается, что чтение буквы можно просто изменить здесь G на G плюс один.
Здесь мы можем спуститься грамотно, переделать это правило.
И complete.
Мы тоже, используя вот эти позиции, можем с вами перепрошить эту штуку.
Используя просто вот эти множества.
Но это мы с вами разберем уже в следующий раз.
И докажем некоторые факты, посвященные этой ситуации.
Что такое ситуация.
И будем доказывать некоторую динамику.
