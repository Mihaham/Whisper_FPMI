У нас сегодня по плану решить четыре задачи, но в целом
они все достаточно быстро решаются, наверно, еще хочется
обсудить какую-то теорию, которая необходима для
этих задач.
Поэтому план примерно такой.
Мы, наверно, сейчас минут 25 пообсуждаем какие-то
теоретические выкладки, которые у нас уже за первую
половину семестра были, затем минут 20 порешаем
первую задачу, затем еще 15 минут теории в многомерном
случае и за последние там 40 минут, 50, если все будет
как я планирую, мы решим последние три задачи, они
все не очень сложные.
И еще небольшое замечание, далеко не во всех задачах
мне удалось подобрать хорошие числа, поэтому там где-то
мы до конца до ответа доводить не будем, потому что там страшные
штуки какие-то вылезают.
Мы как бы до последнего шага с вами доведем, а там
последний интеграл допустим где-то считать не будем,
потому что что-то у меня не было времени подгонять,
чтобы все было классно.
На контрольной работе должно все считаться просто,
но это же не контрольный по мотону.
Так, ну все, давайте потихоньку тогда начинать.
Вот, я Степа, веду семинары у 220-й группы, вот, кто-то
из 220-й, кстати, пришел.
Не, ну у меня просто очень умные ребята в группе, они
сказали, мы не придем, там будет какая-то халява
очевидная.
Вот, поэтому они не пришли, да, там Дениса знаете, Кондратова,
это вот он сказал.
Так, давайте тогда отсюда начнем, значит, сейчас мы
хотим с вами решить первую задачу, но чтобы решить
первую задачу нам нужно учиться отвечать на несколько
вопросов.
И вот, ну, с теорией начинаем, давайте какое-то введение
будет.
Итак, основной объект, которым мы работаем в рамках курса
теории вероятности, это случайная величина.
Вот, случайная величина кси, это на самом деле измеримое
соображение, здесь измеримая функция, здравствуйте, изомега
напрямую.
Вот, ну, помимо самого пространства у нас там есть еще на самом
деле вероятностное пространство, то есть есть помимо пространства
элементарных исходов сигма-алгебра какая-то, какая-то мера
на этом пространстве.
Ну и вот на самом деле вам это наверное в семинарах
рассказывали, что случайная величина, она как бы индуцирует
меру вот эту напрямую.
Вот, вот эту меру как бы мы сейчас подписали как
пэкси, но на самом деле мы этот индекс писать не
будем, более-менее и так понятно, что эти меры между
собой имеют понятную связь, вот, ну, как мера прообраза
просто для любого баррелизского множества, вот эта мера
определяется как мера прообраза вот отсюда.
Супер, но меры это в целом какие-то сложные объекты,
мы с ними работали с вами в прошлом семестре, вот,
однако есть такой хороший и понятный объект как функция
распределения.
И по определению она есть не что иное, как мера луча
от минус бесконечности до x включительно.
Вот, и собственно, функция распределения на самом
деле взаимно однозначно соответствует любой мере
напрямой.
Вот.
Давайте посмотрим, какие свойства функции распределения.
Это то, что уже тысячу раз было, но повторить лишним
не будет.
Ну, во-первых, функция распределения непрерывна справа, это
следует непосредственно из непрерывности вероятности
на меры, вы можете построить последовательность гейна,
которая право подходит к точке x.
Во-вторых, эта функция не убывающая, этот факт следует
напрямую из того, что мера не отрицательна.
Ну, и также есть замечательное свойство пропределы.
Что в левый предел, в минус бесконечности у вас
нолик, а плюс бесконечности единичка.
Вот.
Замечательный факт также заключается в том, что вот
любая функция, которая обладает вот этими свойствами, на
самом деле является некоторой функцией распределения,
то есть есть объекция между распределениями и функциями
распределений.
Вы сейчас про многомерный случай говорите, мы обсуждаем
напрямую.
Замечательный факт заключается в том, что, если у вас функция
обладает вот этими свойствами, то она соответствует некоторой
мере.
Ну, это действительно так, потому что это мера любого
и вы научились ее строить.
Поэтому, чтобы задать какое-то распределение на прямой,
вам достаточно знать функцию распределения.
Так, на этом моменте, думаю, пока что всем все понятно.
Идем дальше.
Аккуратненько вспомним классификацию функции распределений.
П s определено на это сигма-алгебре бараллельских множеств
и действует в отрезок 0,1.
Это вероятностная мера вот на этом пространстве.
Так, если нужно чуть подробнее, я могу, конечно, остановиться,
когда мы до завтра не закончим, наверное.
А можно было спросить, я еще когда-нибудь не стер?
Ну, вот, допустим, была вот такая вероятностная мера,
да?
Это тоже вероятностная мера.
Просто вот эта вероятностная мера, грубо говоря, задана
на каком-нибудь эксперименте.
Ну, вот здесь, может быть, у вас там как облака устроены,
как облака плывут над Атлантическим океаном, а вот здесь температура
в Долгопрудном.
Понятно, да?
И мера на самом деле у вас вот здесь распределена,
как у вас там облака будут плыть налево, направо, ну,
вы не знаете с какой скоростью.
А вот здесь у вас уже будет какая-то числовая мера.
И они между собой соотносятся, ну, понятно как, что мера
любого бараллельского множества отсюда определяется просто
как мера прообраза его.
Окей?
Отлично.
Тогда я стираю уже, да?
Так, а еще такой вопрос здесь есть?
Вот вода.
Просто хочется… Давайте, я не против.
Просто тут ведра нет, у вас в чем проблема.
А давайте вы в какой-нибудь аудитории украдете пока
ведро?
Украдете ведро где-нибудь?
Нет, ну, в смысле там вот, ну, в ГК выше есть где-нибудь.
Мы его возьмем пока, а потом наверно вернем.
Так, ну, я пока с отручем есть.
Поехали дальше.
Давайте немножко про классификацию вспомним.
На самом деле эта классификация относится и к функциям
распределений, и к случайным величинам, и к распределениям.
Потому что все они между собой там связаны, вот,
как мы это уже поняли с вами.
Потому что всем распределениям соответствуют какие-то
функции распределения.
Давайте немножко про классификацию поговорим.
В общем, сейчас доска будет плохая, дальше я буду стирать
лучше.
Классификация.
Ну, и тут можно чего угодно писать.
Случайных величин, в кобочках можно писать там функции
распределения.
Ну, давайте мы функции распределения будем классифицировать.
Либо вероятностных мер.
Потому что между ними всеми есть какое-то соответствие,
поэтому если мы классифицируем один объект, например, функцию
распределения, мы классифицируем с вами и случайную величину,
у которой такая функция распределения.
Ну и соответственно, в функции распределения у нас, ну и
случайной величины бывают трех видов.
Дискретная, абсолютно непрерывная и сингулярная.
Значит, дискретная это случайные величины, носитель которых
не более чем счетен.
То есть существует какое-то подможество прямой, такое,
что его вероятность равна единичке, при этом х не более
чем счетно.
Вот.
Давайте приведем какой-нибудь пример.
Ну, понятно, что вот, допустим, Бернулевская модель распределения
Бернуля является дискретным.
Ну и несложно понять, как будет выглядеть функция распределения
просто из определения.
У вас будет 0 до нуля, потом 1 минус P от нуля до единички,
и дальше единичка, единички.
Вот такая функция распределения у дискретных случайных
величин.
Какая-то ступенчатая.
Вот.
Это все выстроили чуть позже, это так просто напоминание.
Вот.
Абсолютно непрерывные случайные величины, абсолютно непрерывная
функция распределения.
Значит, функция распределения называется абсолютно непрерывной,
если для нее выполнено равенство Ньютона-Лейбнице.
Вот.
То есть у вас там сейчас на мотоне их как-то там через
эпсилоны и дельты вводили.
Вот.
На самом деле, эти два определения абсолютно эквивалентны.
Это не тривиально показать, но мы будем считать, что
все функции распределения, которые имеют вот такой
вид для некоторой PoETs X gives you what they mean!
А будут у нас называться абсолютно непрерывными
функциями распределениями.
Соответственно, если эта функция распределения соответствует
случайной величине, то такая случайная величина
будет называться абсолютно непрерывной.
Вот.
Пример приводить не надо.
Наверное, уже были у вас на семинарах нормальная
случайная величина, допустим, уровень распределения
выглядит каким-нибудь таким образом.
Вот, но вот тут появляется такой объект, как p от x,
и это плотность распределения.
И давайте мы сейчас с вами что-нибудь про плотность
скажем.
Значит, у плотности есть два основных свойства.
Первое, что плотность не отрицательна, а второе,
что интеграл по прямой правильно единички.
Замечательный факт опять-таки заключается в том, что если
вы придумаете функцию, которая обладает вот этими
двумя свойствами, она будет плотностью распределения
для некоторой функции распределения.
То есть для некоторой случайной величины это будет плотностью.
Так, и остались у нас сингулярные случайные величины функции
распределения.
Это одно и то же.
Значит, функцию распределения мы назовем сингулярной,
если мера точек роста нулевая.
Что такое точка роста?
То есть точка роста функции f, если любого епсилон, f
от x плюс епсилон минус f от x минус епсилон больше
нуля.
То есть грубо говоря, такая точка, в окрестности которой
какое-то превращение происходит.
Вот.
И соответственно, мера вот таких точек роста.
Спасибо большое.
Мера точек роста равна нулю.
Пример такой функции, ну это лестница кантера.
Соответственно, если вы проверите свойство функции
распределения для лестницы кантера, вы поймете, что
лестница кантера это валидная функция распределения.
И по ней, значит, можно какую-то случайную величину построить.
Вот.
А соответственно, сингулярные случайные величины действительно
существуют.
И вот такой классический пример можно вспомнить.
Отлично.
Про классификацию мы с вами поговорили.
Да.
ПТДТ.
Да.
Вы абсолютно правы.
Спасибо.
А то какой-то интегралчик странный получается, вы
правы.
ПТДТ.
Поправьте.
Дискретное на самом деле является сингулярным.
Вот.
Просто, ну так как это более практичный пример, чем
вот все сингулярные, их выделяют в отдельный класс.
На самом деле все функции распределения, ну случайной
величины, бьются на два типа сингулярные, абсолютно
непрерывные.
И просто часто случаи, когда вы это делаете, это
не очень правильно.
Вспомните, например, если вы делаете комплектирую
сингулярного, если вы делаете патриот, то в этом случае
вы делаете сингулярный.
бьются на два типа, сингулярные и абсолютно непрерывные.
И просто часто случаи сингулярных случайных величин
это дискретные, но мы их рассматриваем отдельно.
Тут мы отдельно рассматриваем, что носитель не более чем
счетен.
А там получается попадает все, что больше, то есть
все, что там континентально и выше.
Вот.
Ну с этим более-менее разобрались.
Идем дальше.
Так, ну графичек лестницы кантра, я думаю, вы все
помните.
Тут что-то фрактальное такое, я такое рисовать не умею
хорошо.
Но выглядит оно вот так.
Вот такая функция распределения будет сингулярной.
Сингулярная называется случайная величина или
мера, у которой сингулярная функция распределения.
Что такое сингулярная функция распределения?
Это функция, у которой мера точек роста нулевая.
Что такое точка роста?
Вот определение на строгом математическом языке.
Х минус апсилон.
Но мы с сингулярными случайными величинами работать не
будем, поэтому обсуждать их и как считать в их случаях
там мотожи и все такое мы с вами не хотим сейчас,
потому что это отдельное искусство.
Разобрались.
Теперь немножко с плотностями поработаем.
Немножко поработаем с плотностями.
Вот появляется вопрос.
Вот есть у вас случайная величина какая-то?
Ну понятно, что с дискретными случайными величинами
там все просто.
На самом деле любая дискретная случайная величина это
просто любая функция из-за мега напрямую с не более
чем счетным носителем.
А вот в случае абсолютно непрерывных случайных
величин этот вопрос уже становится на самом деле
чуть сложнее.
То есть пусть у вас была кси абсолютно непрерывная
случайная величина.
Вопрос, а будет ли фи от кси случайной величиной?
Ну вот на самом деле если потребовать от функции
фи, чтобы она была бареллевской, то действительно все будет
хорошо.
Это мы доказывали с вами на авитме, что композиция
бареллевской функции измеримой, есть измеримая функция.
А случайная величина у нас это измеримая функция
от выборочного пространства.
Приводили контрпримеры, что измеримая от бареллевской
может быть допустим не измеримая.
Поэтому смотрите, если у вас есть кси и вы к ней применяете
бареллевскую функцию, тогда вот такая композиция
тоже будет измеримой функцией, а соответственно это тоже
случайная величина.
То есть теперь более-менее понятно, почему мы можем
рассматривать не только значения там, допустим,
на кости или на монетке, а еще и квадраты этих случайных
величин, например, там кубы, модули и все остальное.
Все вот такие функции являются более того непрерывными,
ну а непрерывные это под множество бареллевских
функций.
Что такое бареллевская функция, я думаю, все помните
про образ любого бареллевского множества бареллевский?
Вот, ну просто для решения задач достаточно понимать,
что все хорошие функции, которые вы можете придумать,
они скорее всего будут являться бареллевскими.
Так, отлично.
И вот пусть у вас у кси изначально была некоторая плотность.
То есть так как мы работаем с вами с абсолютно непрерывными
случайными величинами, значит у кси была некоторая плотность.
Вопрос, а как найти плотность случайной величины в пет
кси?
Это как бы интересный вопрос на самом деле, на который
хочется научиться отвечать.
Такая задачка у вас у всех была уже, но мы сейчас с
вами ее аккуратно еще раз обсудим.
Итак, предположим, что у вас есть какое-то открытое
множество.
Ну, давайте рассмотрим интервальчик.
И на нем задана и непрерывно дифференцируемая и строго
монотонная функция.
Тогда утверждается, что фикси будет иметь плотность
и мы ее даже с вами сейчас посчитаем.
Ну, давайте мы это сделаем.
Смотрите, чтобы задать плотность случайной величины, нам
для начала хотелось бы найти функцию распределения
этой случайной величины.
Давайте в точке х.
По определению функции распределения это на самом
деле то же самое, что и вероятность того, что фет кси меньше
либо равно х.
Вот.
А в силу того, что мы потребовали от функции непрерывность
и строго монотонность, прошу прощения, непрерывную
дифференцируемость и строго монотонность, мы можем
с вами взять обратную функцию.
Вот.
И тут с вероятностями все корректно произойдет.
Вот.
А это у нас ничто иное, как появилась опять функция
распределения исходной случайной величины кси
в точке phi в минус 1 от х.
Вот.
А на самом деле, ну, если мы знаем с вами случайную
величину исходную кси, то, наверное, функцию распределения
мы ее тоже знаем.
Вот.
Теперь вопрос.
А как найти плотность?
Ну, на самом деле, нашим нестрогом доказательстве,
которое мы сейчас проделаем, можно просто продеференцировать.
Если у нас функция распределения это интеграл от плотности,
вот, то на самом деле плотность это производная функция
распределения.
Там при решении задач такое допущение можно сделать.
Отсюда мы можем с вами найти плотность вот этой
нашей новой случайной величины.
Это, на самом деле, просто производная функция распределения.
Вот.
Хотел бы еще небольшое замечание сделать.
Вот в этом переходе мы с вами предположили, что
функция phi возрастающая, потому что если бы она была
убывающая, у нас бы здесь знак поменялся на противоположный.
Но на самом деле в итоговом ответе у нас будет модуль
и вот этот случай там учтется.
Как бы там доказательство проделывается абсолютно
аналогичное, мы сейчас это обсудим.
Вот здесь просто пока предположение сделаем, что phi возрастающая
функция.
Вот.
Соответственно, что у нас отсюда следует?
Мы хотим взять производную от вот этого объекта.
Это производная сложной функции.
Это будет x в точке phi в минус 1 от x на производную
от этого объекта.
Вот.
Супер.
Просто отлично.
А откуда у нас здесь вылазит модуль?
Ну вот смотрите, если бы вы предположили, что у вас
функция убывающая, тогда здесь бы у вас знак поменялся
на противоположный.
Тогда у вас бы здесь была бы единичка минус функция
распределения.
То есть у вас, грубо говоря, вот здесь был бы минус перед
этой функцией.
Поэтому, когда бы вы выбрали производную, у вас бы минус
1 оттуда вылез, а 1 минус у вас бы вылез из того, что
производная отрицательна.
И минус на минус дал бы плюс, поэтому в итоговом
ответе вот здесь модуль.
Вот.
Так, просто два случая рассматривается.
Но не всегда функция обладает такими замечательными
свойствами.
Ну как минимум непрерывные функции, ладно, это хорошо.
Потому что она дифференцируема хорошо, но она может быть
не монотонна на нашем интервале.
То есть возможно у вас функция какая-нибудь х в квадрате,
и вот непонятно, что тогда делать.
Ну на самом деле понятно, что делать.
Есть обобщение этой формулы.
Его мы с вами выводить не будем.
Более-менее очевидно, почему будет так.
Грубо говоря, если функция phi у вас обладает вот этими
свойствами, которые мы обсудили на каких-то
непересекающихся промежутках.
Так, сейчас как это аккуратно записать.
Ну вот давайте напишем непрерывно дифференцируемо.
Строго монотонно.
На промежуточках, на промежуточках, давайте a и b.
Вот.
То есть для каждого промежуточка какая-то своя функция,
дифференцируемая, строго монотонная и хорошая.
Поэтому на самом деле мы можем с вами вот эту формулу
применить каждому такому отдельному промежуточку.
Грубо говоря, потому что у нас есть идеи, на почему
мы так можем сделать.
Потому что у вас функция распределения строится
по мере, а мера у вас счетно-аддитивна, то есть по дизинктным
множествам у вас все корректно разбивать и считать вероятности
на каждом куске по отдельности, а потом эти как бы ответы
объединять.
Вот.
Ну и соответственно там плотность будет представлена
в следующем виде.
Ну вот, предположим, что у вас их n штук, абсолютно
такое же выражение.
Вот, давайте только какую-нибудь индексацию здесь добавим,
что эта ita функция будет на каждом отдельном отрезке.
Вот, ну и соответственно нужно домножить на какой-то
индикатор.
Здесь будет такой индикатор, образ промежутка a и b.
Так, сейчас давайте аккуратно запишу как-нибудь, доски
немножко не хватило.
Вот, здесь умножаем на индикатор.
Производную не записал, да?
Вот, да, здесь производную, вы правы.
То есть абсолютно та же формула, просто мы разбили
на отрезке и применили ее каждому отрезочку по
отдельности.
Отлично, мы почти готовы решать первую задачу.
Почти готовы, сейчас я еще вспомню, что мы еще должны
обсудить.
Первая задача, от нас ведь требуется мотождание,
да, посчитать.
То есть нужно еще аккуратно напомнить, что такое математическое
ожидание.
И в принципе мы готовы решать задачу.
Так, это стираю?
Вопросов, наверное, нет.
Итак, господа, я думаю, вы помните, что у нас мы тоже
в предыдущий раз были на Avitme, ну, до Тьарвера, вот,
и там математические ожидания определялись следующим
образом.
Ну, мы просто сейчас какую-то аналогию проведем между
дискретным и абсолютно непрерывным случаем.
В дискретном случае у нас математическое ожидание
C определялось как сумма, как вот такая вот сумма.
Было.
Вот, наверное, вы помните, что вот здесь можно перегруппировать
слагаемые и суммировать не по омегам, а суммировать
по значениям случайной величины.
Вот, в случае абсолютно непрерывных случайных величин, математическое
ожидание случайной величины уже определяется как интеграл
Либега, то есть на самом деле это самый первый шаг
построения интеграла Либега для простых функций.
В случае абсолютно непрерывных случайных величин у нас
определяется как интеграл Либега и от омега по и до
омега.
Вот.
Но вот здесь вот интегрировать по какому-то непонятному
пространству обычно неудобно.
Поэтому вот здесь мы делали перегруппировку, а здесь
мы с вами пользуемся теоремой о замене переменных в интеграле
Либега.
И получаем с вами вот такой интегральчик, интеграл
Либега.
Вот.
Это не тривиальный переход, но мы давайте сейчас поверим
в него.
Ну и вот видна какая-то аналогия между дискретным
и непрерывным.
Думаю, все обратили внимание.
Так.
И еще что хочется сказать.
А, ну, наверное, что если вы хотите посчитать математическое
ожидание функции от случайной величины, вам не нужно
сначала считать ее распределение, можно считать его просто
вот таким вот образом.
Это, я думаю, вы тоже помните.
В принципе, тоже верно и с теоремой о замене переменных
в интеграле Либега.
Так.
Насколько я понимаю, я вроде все рассказал, что хотел.
Почти все.
Еще одно небольшое замечание, и мы начинаем с вами решать
задачу.
Смотрите, мы с вами до этого вот рассматривали случайные
величины дискретные и абсолютно непрерывные.
Ну и функции распределения, соответственно, тоже дискретные
и абсолютно непрерывные.
Но бывают функции распределения, которые являются одновременно
как бы и дискретными и абсолютно непрерывными.
То есть они как бы являются смесью тех типов функций
распределения, которые мы с вами обсудили до этого.
На самом деле есть теорема Либега о разложении измеримой
функции.
Эта теорема утверждает, что в нашем контексте, что
функция распределения любая, представима, давайте
сейчас индексы говорящие сделаем, как вот такая взвешенная
сумма дискретной, абсолютно непрерывной в случае функции
распределения и сингулярной.
Ну и у этих коэффициентов они в сумме должны давать
единичку.
Это теорема Либега о разложении измеримой функции.
Почему нам это понадобится?
Ну на самом деле, потому что если мы будем с вами считать
интеграл, ну вот, мотожидание от смеси, допустим, дискретной
и абсолютно непрерывной случайной величины.
Такая запись, надеюсь, никого не пугает.
Так иногда обозначают интеграл Либега с изъесом,
но просто меры строятся по вот этой функции распределения
в нем.
На самом деле просто распадается тумму.
Получается, в нашем случае будет дискретная случайная
величина, дискретная составляющая и математическое ожидание
от абсолютно непрерывной составляющей.
То есть, грубо говоря, у вас мера разложилась на три
меры.
Ну вот, сингулярную часть мы с вами сейчас рассматривать
не будем.
У нас будет только дискретная часть и абсолютно непрерывная.
Ну и соответственно тогда математическое ожидание
этой случайной величины представимо на самом деле
как сумма математических ожиданий каждой вот этой
компонента по отдельности.
А?
Они на самом деле уже у вас вот здесь вшиты в эту
случайную величину.
У нас уже функция уже с этими коэффициентами идет.
Да, вы абсолютно правы.
Это такое обозначение, можем здесь х написать, это
просто для интеграла Лебега, в нашем случае это вообще
интеграл Лебега с ТС, есть там восемь эквивалентных
обозначений.
Да, здесь будет х, вы правы.
Коэффициенты положительные в сумме дают единичку.
Ну не отрицательные, если аккуратно говорить.
Вот, ну все, вот теперь мы точно готовы решать задачку.
Потому что из вот этого факта следует следующая теорема,
которой мы непосредственно воспользуемся сейчас при
решении задачи.
Я думаю, эта теорема у вас у всех в том или ином
виде как утверждение была на семинарах, и она утверждает
следующее.
Давайте, чтобы с индексами не напороться.
В общем, это секретная теорема, которая решает
семинадцатую задачу в Лебега, но в нашем случае первую
задачу в контрольной.
Если у вас f of x представимо в следующем видео.
Так, аккуратненько, так, первое слагаемое мы выделяем.
Так, ну, а ноль можно не вводить.
Вот так, тогда математическое ожидание функции f of x, вот
это, если что, функция распределения, соответствующая нашей
случайной величине С, тогда математическое ожидание
функции от этой случайной величины, вот такая вот
сумма.
Я не в лес.
Давайте здесь аккуратно допишу.
То есть, как бы, и в точке аи, минус f от i минус 1, а
минус 1.
Вот, ну давайте просто посмотрим на то, что здесь происходит.
То есть, предположим, что у вас функция распределения,
вот мы выяснили с вами, что абсолютно непрерывные
функции распределения имеют там вот какой-то вот непрерывный
график функции распределения, скорее всего.
Вот, а если у вас есть скачок, то это называется дискретная
составляющая.
Но почему это так?
Ну, потому что можно посчитать, на самом деле, вероятность
одной точки через функцию распределения.
Вероятность одной точки в терминах функции распределения,
вот, это на самом деле x не включительно, а вот это
у вас функция распределения, а это у вас левый предел.
Вот, и, соответственно, более-менее понятно, что
абсолютно непрерывные случайные величины, ну вот, давайте
вот эту точку рассмотрим, это абсолютно непрерывная
составляющая.
Вот здесь у вас предел слева равен значению в точке,
поэтому у вас вероятность каждой точки вот в этой
составляющей нулевая.
Просто у вас этот предел равен вот этому выражению.
А вот если у вас дискретная составляющая есть, ну либо
просто дискретная случайная величина, то у вас есть
какой-то скачок.
Тогда на самом деле вероятность этой точки, ну вот, мы аккуратно
с вами записали ее в терминах функций распределений,
это значение, так как у нас она непрерывная справа,
функция распределения в этой точке, минус левый предел.
То есть величина этого скачка, это как раз-таки вероятность
этой точки.
Вот, и если мы посмотрим с вами вот на эту формулу,
что здесь происходит, здесь на самом деле, я аккуратно
переписал, чтобы не наложать в индексах, мы бьем нашу
функцию распределения на области непрерывности,
на областях непрерывности, вот здесь вот.
Мы с вами, грубо говоря, плотно считаем, как производную
от соответствующей функции распределения, и это по
сути у вас просто определение математического ожидания
для абсолютно непрерывной случайной величины.
И отдельно вот эти точки разрывов, вот эти, мы с вами
рассматриваем как дискретную случайную величину.
То есть вот здесь как раз-таки это и написано, что это значение
точки, минус левый предел, но вот здесь левый предел
заменяется на i-1, видите, почему это так.
Здесь просто у вас как бы рассматривается не кусочная
функция распределения, а как бы функция распределения,
которая состоит из, сейчас как объяснить, сейчас на
примере поймем это точно.
В общем здесь, чтобы избавиться от левых правых пределов,
рассматривают вот эти функции полностью.
То есть допустим у вас функция распределения выглядит
каким-нибудь вот таким вот образом, и у вас просто
считается, что вот эта функция номер один, допустим f первое
у вас будет квадрат какой-нибудь, а вот эта функция у вас будет
функция номер два, и она как будто бы определена
на всей числовой прямой, но вот за счет этих индикаторов
мы сужаем на соответствующие промежутки, поэтому здесь
не пределы слева рассматриваются, а значения предыдущей функции
в этой же точке.
В общем, сильно, давайте на этом останавливаться
не будем, это не особо имеет значения.
Еще раз.
Ну, на самом деле, как угодно можете разбивать, у вас на
самом деле в зависимости от разбиения просто значение
не поменяется.
Фиат-Х?
Фиат-Х?
Да.
Нет, вы понимаете?
По точкам разрыва мы точно разбиваем, да, f и t должны
быть непрерывно дифференцируемы, чтобы мы корректно с вами
плотность посчитали.
Давайте это тоже аккуратно запишем.
Мы вот здесь переходим с вами к плотностям.
Вот, а это у вас в некотором смысле дискретная производная
справа.
Так, есть ли вопросы по вот этому утверждению?
Идея такая.
Еще раз повторю на всякий случай, чтобы точно все
поняли.
Мы разбиваем с вами на области непрерывности, то есть отдельно
рассматриваем вот этот кусочек от минус бесконечности
до х в данном случае, отдельно рассматриваем эту точку
и отдельно рассматриваем, ну вот, в данном конкретном
примере правый луч вот от этой точки до плюс бесконечности.
И вот эту часть на нее смотрим как на абсолютно непрерывный
кусочек, соответственно, считаем производную от
него, чтобы найти как бы плотность локальную и считаем
просто по определению от ожидания для абсолютно
непрерывной случайной величины.
Точки мы как бы точку обрабатываем как дискретную случайную
величину, вот этот вот скачок, здесь вот это записано.
Ну и почему у вас здесь n слагаемых таких и n слагаемых
таких?
Ну потому что у вас точка разрыва может быть в данном
данной теореме конечное какое-то количество, и вы бьете
вот на эти интервальчики и отдельно точки рассматривает.
Почему из-за разрывов добавляется второе слагаемое?
Ты про дискретно составляющие.
Мы выяснили, что вероятность точки вот такая вот.
У вас как бы в этой точке функция не дифференцируемая,
но функция распределения, как минимум, поэтому у тебя
эта точка уже не учитывается в определении абсолютно
непрерывном от ожидания.
Вот, но вероятность здесь у тебя как бы не отрицательная,
поэтому вот там появляются эти слагаемые.
Интуиция есть или?
Да, это называется, сейчас я забыл, как это называется,
ладно, помню потом скажу.
Давайте к задачке переходить, если вопросов нет.
Давайте еще посмотрим на это.
Ну все, переходим к задаче.
Так, вы уже начали, кстати, ее решать.
Значит, внимательно слушали.
Так, мы сейчас с вами в этой задаче какую-то лишнюю
работу поделаем, чтобы просто руку набить.
Там поэтому требуется в этой задаче очень много
всего, чтобы мы с вами все, что сейчас обсудили, могли
как-то использовать.
Так, окей, условия задач.
Давайте условия, наверное, на левой половине доски
напишу.
Х и у независимы.
Так, х имеет распределение лопаста, то есть х соответствует
плотность равная 1 вторая е в степени минус модули.
Так, у у у нас задана функция распределения.
И что от нас просят найти?
От нас просят найти плотность х в квадрате, функцию распределения
х в квадрате.
И еще нас просят найти математическое ожидание
максимума х в квадрате у.
Собственно, три вопроса.
Ну, давайте по очереди на них, наверное, и ответим.
Мы с вами обсуждали, что преобразования баррельские
случайных величин действительно сохраняют поиски случайных
величин, то есть это тоже будет случайная величина.
Поэтому как бы этот вопрос корректен.
Нам нужно только посчитать с вами плотность.
Ну, давайте с вами посчитаем плотность.
Мы уже на самом деле даже с вами формулу итоговую
выписали, но давайте мы аккуратно это проделаем
сначала, как это можно сделать, типа, если вы эту формулу
забыли, а потом заметим, что то же самое только в
один шаг получалось бы, если бы вы выполнили формулу.
Так, что от нас требуется?
От нас требуется найти плотность х в квадрате.
Значит, нам можно вначале найти функцию распределения
х в квадрате.
Опять пользуемся определением функции распределения.
И здесь может захотеться корень написать, но это будет
не совсем корректно, потому что у вас вот это преобразование
не монотонно.
Здесь корректно будет записать, что у вас вероятность
того, что х принадлежит от минус корень СТ до корень
СТ.
Окей?
Да, ну и коль скоро, конечно, Т больше либо равно нуля.
Ну как бы это какое-то очевидное замечание, давайте напишем
его тоже.
Окей.
Как мы это можем выразить через какие-нибудь известные
нам объекты?
Так, хорошо, вы предлагаете это записать как разность
функции распределения, но это правда, потому что,
смотрите, у вас как бы есть луч от минус бесконечности
до корени СТ, и вот здесь у вас где-то минус корень
СТ, здесь, соответственно, где-то ноль.
И вас интересует вот эта вероятность, так как события
в друг друга вложены, можно вычесть просто из вероятности
вот этого луча вероятность вот этого луча.
Так, а вас как зовут?
Егор.
Егор, какой ответ?
Пункция распределения в точке корень СТ?
Минус корень СТ.
Вы уверены?
Ну, смотрите, здесь получается с вами вот эту точку вычисли,
потому что вот здесь же у вас как бы скрыта вероятность,
ну предел, либо можно еще на самом деле записать
плюс вероятность того, что х будет равен минус корень
СТ.
Понятно, да, что произошло?
Ну, вот смотрите, это вот нужно аккуратно, типа, когда
вы такими штуками оперируете и как бы знаки неравенства
переходите от строгих к нестрогим, нужно помнить,
если вы работаете с абсолютно непрерывной случайной величиной,
то у вас вероятность любой точки это ноль, мы это с
вами уже показали.
Тут действительно это будет абсолютно непрерывная
случайная величина, потому что есть плотность.
Соответственно, действительно, вот это слагаемое, оно
как бы равно нулю, но в общем случае про это забывать
крайне не рекомендуется, потому что у вас может быть
неправильный ответ, просто сделайте у вас дискретный
кусочек меры, то есть скачок вот в этой точке, и у вас
ответ будет неверным.
Вот, ну вот теперь я согласен, про вот это слагаемое не
забывайте.
Ну, наверное, мы с вами функцию распределения, да, посчитали?
А не, мы функцию распределения с вами не знаем.
Мы хотим с вами что найти?
Плотность, да?
Ну, давайте плотность найдем.
Плотность х в квадрате точки t.
Так, Егор, что делаем?
Абсолютно справедливо.
Давайте продиференцируем.
Так, ну мы с вами дифференцируем вот это вот выражение.
Давайте напишу так.
Мы дифференцируем с вами f и в квадрате по t.
Что у нас получится?
У нас получится одна вторая, корни с t, плотность х в
точке корни с t.
Это первая слагаемая, и минус, и еще отсюда минус
будет плюс одна на два корни с t, f от х в точке минус корни
с t.
Проверите, что я нигде не ошибся.
Я просто продиференцировал вот это выражение.
Производная сложная функция.
Производная f это p-щика будет.
Вот, производная того, что внутри это корень с t, одна
вторая поделить на корень с t.
Ну, вроде все корректно.
Да?
То есть ответ итоговый вот такой.
Один поделить на два корни с t, а в скобочках надо
дать f от х в точке корни с t плюс f от х в точке минус
корни с t.
Ну, а f от х мы с вами знаем.
Оно у нас по условию задачи дано.
Поэтому здесь мы, наверное, с вами уже и ответ можем
дать.
Ответ будет такой.
Один на два корни с t.
Плотность в точке корни с t.
Так, и нужно еще учесть, что у нас t не отрицательная.
Даже можно сказать, что t положительная.
Потому что там у вас иначе ноль в заменах не выскочит.
Одна точка ничего здесь не значит, поэтому у нас
t больше нуля строго.
А если t строго больше нуля, то плотность в точке корни
с t у нас будет одна вторая.
f сепени минус корни с t.
Плюс одна вторая.
Так, там у нас модуль, да?
Поэтому модуль минус yes и будет опять то же самое.
Что имеем?
Кажется, что вот это f сепени минус корни с t просто будет.
Кажется, что ответ какой-то вот такой.
Если я нигде не ошибся.
Кто-нибудь, кто сам решает, получил такой же ответ?
Да?
Ну да, не, я просто прорешивал, но я уже у себя ошибку нашел.
В смысле, в том, что я дома решал.
Теперь все правильно должно быть.
Я про вот этот множитель забыл, и сейчас все корректно.
Сейчас у меня просто чуть дальше ответа не поедут.
И все будет хорошо, короче.
Так, ну что дальше нужно найти?
Дальше от нас просят найти функцию распределения x в квадрате, да?
Как мы ее с вами будем искать?
Ну на самом деле пути есть два.
Вот тут мы уже с вами функцию распределения нашли.
Поэтому можно либо проинтегрировать исходное выражение.
И вот здесь его подставить.
Ну смотрите, мы же здесь уже с вами функцию распределения x в квадрат.
В терминах функцию распределения выразили.
Это первый способ как найти, то есть найти функцию распределения вот этой штучки.
И потом воспользоваться вот этим выражением.
Второй путь это взять и вот это проинтегрировать.
Я вспомнил, а дома не налажал все правильно.
Мы пойдем с вами по первому пути.
Мы с вами с исходной плотностью что-нибудь сейчас поделаем.
Соответственно, идея понятна, да?
Можно вот это проинтегрировать
и найти функцию распределения.
Можно проинтегрировать исходную функцию распределения,
и потому что мы вот здесь в терминах, в исходной функции распределения получили ответ,
получили ответ, можно его им воспользоваться.
Ответы получатся одинаковые, поэтому как вы будете решать
таким путем или таким, без разницы.
Давайте мы с вами исходной плотностью поработаем
и по исходной плотности восстановим исходную функцию распределения.
План такой.
Хорошо.
Просто чуть проще интегральщик тот считать, чем вот этот.
Мне так кажется.
Так, ну смотрите, давайте сначала тогда мы с вами
на первый вопрос мы с вами ответили, вот это ответ на
первый вопрос.
Отвечаем на второй вопрос.
Найдем сначала функцию распределения точки t.
Ну как мы уже с вами выяснили, это на самом деле интеграл
от минус бесконечности до t исходной плотности.
Одна вторая е в степени минус модуль х dx.
Ну и я уже один раз сегодня ошибся.
Смотрите, чтобы у вас перемены были разные, иначе интеграл
будет странный.
Вот.
Но это кажется не очень сложно посчитать.
Просто нужно два случая рассмотреть.
х больше нуля и х меньше нуля.
Так, если х больше нуля, мы разбиваем по t, тогда t.
Если t больше нуля.
Давайте сначала t меньше нуля, потому что тот случай
попроще будет.
Если t меньше нуля, то мы с вами интегрируем е в
степени х получается просто.
И у нас будет одна вторая е в степени х в подстановке
от минус бесконечности до t.
Ну в минус бесконечности это видимо 0, поэтому будет
одна вторая е в степени t.
Вот.
Если же у нас t не отрицательная, то мы с вами пользуемся
аддитивностью интеграла, разбиваем от минус бесконечности
до 0 и от 0 до t.
На два интегральчика.
Первый интегральчик у нас получится, одна вторая
е в степени х видимо в подстановке от минус бесконечности
до 0, плюс интегрируем от 0 до t, е в степени минус
х.
Значит здесь будет минус е в степени минус х, в подстановке
от 0 до t, и здесь у нас получится в 0 это 1 вторая, минус бесконечности
это 0, а здесь будет плюс 1 вторая, здесь будет плюс
1 вторая и минус E в степени минус t. Получается 1, минус 1 вторая E в степени минус t.
Вот у меня что-то такое получилось. У вас тоже самое? Где? Вот здесь?
Нет, потому что здесь правый предел у вас с минусом идет, поэтому вот здесь был
минус и здесь минус, еще один будет здесь плюс, поэтому будет 1 минус 1 вторая E в степени минус t.
Супер, нашли функцию распределения х, а значит мы можем с вами найти теперь
функцию распределения х в квадрате, потому что мы вот уже выражение записали ранее.
Из этого выражения следует, что функция распределения х в квадрате в точке t,
это у нас функция распределения в точке корень с t, точка положительная, поэтому мы с вами вот это
записываем. 1, минус 1 вторая E в степени минус корень с t. Минус корень с t уже будет отрицательным,
поэтому мы вот сюда поставляем. Минус 1 вторая E в степени минус корень с t. Получается 1,
минус E в степени минус корень с t. Да, все совпало. Ну и проверим просто валидно, что это функция
распределения. Вроде похоже на правду, в нуле у вас нолик, ну и все что левее тоже ноль, а на
бесконечности оно у вас стремится к нолику, значит все стремится к единичке. Ну понятно,
что она будет монотонная, но непрерывно справа следует из непрерывности этих функций. Ну как бы
просто такая проверка, то что мы получили действительно хотя бы похоже на правильный ответ. Все,
на второй вопрос этой задачи мы с вами тоже ответили. Можем отвечать на третий вопрос тогда,
который последний в этой задаче. Сайт такой, да. Математическое ожидание максимума х
в квадрате у. Вот, давайте с вами подумаем. Чтобы посчитать математическое ожидание,
нам что с вами нужно иметь? Ну вот по той теории, которую мы с вами на доске выписали до начала
решения этой задачи, нам нужно понимать как устроено функция распределения. Значит на самом
деле, чтобы ответить на последний вопрос, нам нужно с вами понять как выглядит функция распределения
максимума х в квадрате у. Вот, здесь мы уже третий раз за решение этой задачи воспользуемся
определением функции распределения и запишем вот такое равенство. Отлично, а как это упростить? Да,
это правда. Максимум меньше чем t, то это то же самое, что и совместная вероятность того,
что х в квадрате меньше либо равно чем t, у меньше либо равно чем t. Но по условиям они у нас
независимы. Про независимость мы с вами пока теоретически не обсудили ее, но более-менее
понятно, что вот эта вероятность распадается на произведение вероятности. На вероятность того,
что у меньше либо равен t. Ну все, а это на самом деле у вас опять функции распределения собрались.
То есть на самом деле, если у вас две случайные величины независимы, то функция распределения
максимума это просто произведение функции распределения. Есть аналогичное утверждение
про минимум. Оно выглядит следующим образом. Точки t. Вот тут произведение в двух таких скобочках.
Идея какая? Вам нужно перейти к дополнению событий, и у вас тоже все разложится в произведение.
Вот это аккуратно покажите сами. Если возникают вопросы по поводу, почему вот это выражение верно,
попробуйте его доказать сами. Ну вот идея в чем. Смотрите, максимум меньше, чем t,
это значит, что они обе меньше, чем t. То есть это как бы и совместное распределение. То есть и то,
и это выполнено одновременно. Поэтому мы как бы написали вот такое, дальше в силу независимости
разложили в произведение вероятностей. Вот здесь не совсем таким же рассуждением можно воспользоваться,
потому что минимум меньше, чем t, это значит, что у тебя либо одна случайная величина меньше, чем t,
либо две случайные величины меньше, чем t, либо другая случайная, либо первая случайная,
или вторая, либо они обе. Да, просто переходите к дополнению. Попробуйте найти единицу минус
функцию распределения. Вот. То есть вероятность того, что минимум x, y больше, чем t. Это значит,
они обе больше, чем t. Ну и как раз у вас вот эти скобочки вылазят и все появляется.
Более-менее очевидный факт. Ну давайте тогда посмотрим, как выглядит наша функция распределения
на графике. Какой-нибудь схематичный график построим и поймем, как будем дорешивать задачу.
Итак, функция распределения выглядит как произведение функции распределений. То есть
функция распределения максимума из x в квадрате y в точке t, это на самом деле 0, если x официальный,
x плюс 2 на 7 умножить на единичка минус е в степени минус корень из t. Так когда у нас функция
распределения получилась у квадрата? Польс, который x принадлежит от нуля до трех? Так, t вы правы.
Спасибо. Здесь тоже t. t, t, t. Давайте t от нуля до трех. Так, ну и получается единичка минус
е в степени минус корень из t. Польс, коро t больше либо равен трех. И соответственно,
давайте график построим в нашей функции распределения. Смотрите, отрицательное все
ноль будет, то есть здесь нолик. Дальше, в нуле на самом деле за счет вот этой функции у вас здесь
был скачок изначально, но за счет вот этой функции распределения у вас скачок пропал. То есть в нуле
у вас значение 0 и скачка нет. Следующий скачок у нас в точке 3 скорее всего произойдет. Итоговый
график выглядит каким-то вот таким вот образом. Где-то вот здесь единиц.
Вот. Ну и соответственно у нас грубо говоря теперь здесь есть одна дискретная точка,
вот эта вот точка с ненулевой вероятностью. И есть вот две области непрерывности, которые мы
хотим с вами проинтегрировать по-честному. Ну и тогда ответ. Давайте я побольше места
посетру. Досчитывать не будем, просто с вами интеграл запишем. И на этом наверное все с этой задачей.
Так, соответственно ответ.
Ну мы с вами функцию распределения максимума нашли, поэтому на самом деле мы интегрируем
и будем с вами просто х. То есть у нас будет интеграл от 0 до 3. Х на производную вот этой вот штуке.
Х плюс 2 на 7 единичка минус е в степени наскореннее с х. Это все производная dx. Плюс вот этот скачок надо
посчитать. Плюс 3 умножить на величину скачка. Величина скачка это вот из этого значения вычтем вот
это значение для предыдущей функции. То есть это будет единичка минус е в степени минус корень из
трех минус. Получается то же самое. Корень из трех. Вот и сюда надо 3 еще подставить умножить на 5-7.
Вот это величина скачка. И плюс последняя непрерывная часть, которая у этой функции остается вот от
тройки до бесконечности. Плюс интеграл от тройки до бесконечности х и производная вот функция
распределения на этом отрезке, ну на этом промежутке от трех до бесконечности. То есть единичка минус е в степени
минус корень из трех производная х. Ну это ответ. Я вот здесь просто хотел что-нибудь с квадратом дать,
там распределение лопаса, чтобы оно было комсимметричное, чтобы там поскладывать что-нибудь.
Поэтому я не сильно парился, чтобы ответы были простые. Вот это наверное неприятно
производную считать. Наверное такого у вас не будет на контрольной. Но могло бы быть.
Есть вопрос по задачам. В принципе осталось, мы самое сложное с вами закончили, самое неприятное
наверное. Дальше более-менее все задачки простые и веселые. Это было самое такое
вычисление муторное. Если вопросов нет, тогда идем далее. Сейчас у нас еще перерыв тогда на
10 минут на теорию. Нет, не перерыв, перерыв на теорию. А затем мы с вами внутри задачки залпом
наверное решим. И все. Сейчас мы с вами поговорим про случайные вектора.
Соответственно первая задачка, которую мы с вами разобрали, она была на вычисления
математических ожиданий от каких-то функций, которые не являются ни абсолютно непрерывными,
ни искрепными. Вторая задачка будет в общем на теорему о замене переменных в интеграле Либега.
Ну обычно такая. И вот сейчас мы немножко с вами поговорим про многомерные вероятности. И они
в принципе нам все понадобятся вот до последней задачи включительно.
Так где мой листочек? Вот соответственно я сильно углубляться не буду наверное. Так
поверхностно напомню теорию, что происходит в случайных векторах.
Случайный вектор. Ну вот на самом деле мы с вами рассматривались по сути измеримые
функции. Отображение изомега ФП, ВРБР, ПКСИ. Ну и КСИ у нас была случайной величиной,
потому что это какое-то измеримое отображение из вот этого пространства вот в это пространство.
На самом деле никто не мешает вам как бы не измеримые функции рассматривать, а измеримое
отображение любой природы. Вот. И одним из частных случаев является случайный вектор.
Случайный вектор на самом деле это давайте в первом приближении это будет отображение измеримое
ВРН. Вот это будет случайный вектор. То есть сначала мы смотрим на случайный вектор как на одно
единое отображение из вот этого пространства на инмерную, в инмерное пространство. А какое
замечание хочется сделать? Давайте рассмотрим с вами вот такие случайные величины. Это это
проектор. Проектор КАТ и координаты. На самом деле проектор у вас барреливская функция, а барреливская
функция применить к измеримому отображению, вот это будет все измеримо. Поэтому на самом деле вот
это говорит о том, что каждая компонента вот такого отображения единого на самом деле случайна величина.
Поэтому на самом деле определение случайного вектора такое. Это просто упорядоченный набор из
данных случайных величин. Вот. Ну и не трудно понять, что вот это вот единое отображение из исходного
пространства в инмерное пространство является случайным вектором. Потому что мы только что
выяснили, что проектор это барреливские функции, а соответственно проектор на вот этот вектор,
вот это отображение, для его случайную величину, значит оно подходит под это определение.
Но на самом деле верно и обратно.
То есть вот пусть у вас есть n случайных величин, это 1, это n. Они на самом деле все вместе тоже
являются одним единым отображением из исходного пространства vrn, brn, vx. Ну почему? Ну вот давайте
мы с вами dx обозначим этот вектор. Тогда на самом деле прообраз вот такого барреливского
прямоугольника. Это по сути просто есть пересечение таких омега, то xk принадлежит bk. Пока от единички до n.
Вот. Тут надо почувствовать просто. Вот дали вам две случайные величины, это на самом деле вектор
же был случайных веществ. Дали вам вектор из размерности 2, на самом деле это просто две
случайные величины. Все, что вот мы проговорили, по сути про это и есть, что на вектор можно смотреть
как на одно единое отображение, как на случайную точку, а можно смотреть как на n случайных величин,
порядочных. Есть и вопрос по тому, что мы написали на второй и третьей доске. Пересечение таких омег,
токсика от омега принадлежит bk. Это вот у вас на лекции должно было аккуратно
наказываться. Я это повторять не хочу. Так. Что дальше? Вот. Основная мораль, да, вот которую нужно,
которую я вас подталкиваю. Вот есть две случайные величины, есть вектор. Это примерно одно и то же.
Вот в некотором смысле. Дальше. Хочется, наверное, с вами определить, что такое распределение вот в
этом вот n-мерном пространстве. Вот. Или совместное распределение n случайных величин. Так как мы
поняли, что это уже на самом деле совместное распределение n случайных величин или распределение
просто в n-мерном пространстве, это одно и то же, то вероятность определяется на баррелевских
прямоугольниках следующим образом. Это просто вероятность того, что, грубо говоря, каждая компонента
принадлежит соответствующему совместной вероятности того, что каждая компонента вектора
принадлежит соответствующему баррелевскому множеству. Это просто определение совместного
распределения в n-мерном пространстве. Вот. Что дальше хочется сказать? Есть у нас такое
замечательное пространство rn-brn. Что должно стоить? Нет, это просто распределение, просто мера какая-то,
вероятность на меру. Функция распределения сейчас появится. Вот. И теперь вот вопрос. Дали вам
вот такое пространство измеримое, да, то есть какое-то множество элементарных исходов и какая-то
сигма-алгебра на нем есть. Вот. И, соответственно, хочется как-то научиться задавать меры, вот,
ну там, на плоскости хотя бы для начала. То есть мы уже умеем меры напрямой задавать, но хочется
научиться задавать меры на плоскости. Ну и вот тут появляется обобщение, то есть многомерные
функции распределения. Слева? Ну да, смотрите, они более-менее понятны, как между собой сносится.
Можно вот так нарисовать, что это вектор, вот как-то так. А справа совместная вероятность
каждой компоненты, грубо говоря. Понятно? Отлично. Вот. Хочется научиться задавать меры, вот,
на плоскости, там, в трехмерном пространстве и в любом n-мерном пространстве. Ну вот мы с вами
в одномерном случае вероятностные меры задавали при помощи функции распределения. На самом деле
точно такой же объект функции распределения есть и в многомерном случае. Давайте определение дадим.
Вот такая вот функция от n-аргументов, которая есть просто вероятность.
Вот таких вот уголков, по сути. То есть, если мы будем рассматривать с вами плоскость,
мы задаем с вами вероятности для всех вот таких уголков от минус бесконечности до х по одной
координате и под минус бесконечности до y по другой координате. Вот. На самом деле вот такая
функция называется функцией распределения. Вот, n-мерный. Замечательный факт опять-таки заключается в том,
что вот эта функция обладает тремя свойствами. Мы их сейчас выписывать не будем, они нам не
понадобятся. Но эти свойства такие же, там, монотонность, обобщенная на n-мерный случай,
неубывание. Вот. И тоже предел, что если вы там все координаты устремите к плюс бесконечности,
то у вас будет единичка. Если вы все хотя бы одну координату устремите к минус бесконечности,
получится нолик. Вот. Ну как бы со свойствами сейчас работать не хочется, хочется задачки решать.
Вот. И любая функция на самом деле многомерная, которая обладает вот этими свойствами,
такими же как и аналогами одномерной, тоже будет функцией распределения в rn. Таким образом,
мы научились с вами по сути задавать меры на плоскости в любом rn. При помощи вот таких вот
супер. Уже неплохо. Что дальше? Дальше чуть-чуть про независимость давайте еще скажем. Давайте
чуть-чуть скажем про независимость. Вот определение независимости на самом деле нужно было дать еще до
решения предыдущей задачи, потому что мы там независимость с вами пользовались непосредственно
при вычислении функции распределения максимума. Давайте мы выдадим его хотя бы сейчас лучше поздно,
чем никогда. Соответственно, вот если у вас есть n случайных величин, можно сказать,
что они независимы. Если, ну для любых баррельских множеств, вероятность того,
что x1 принадлежит b1, и как далее xn принадлежит bn, нас падает произведение вероятности.
Вот так вот. В принципе, это логичное обобщение. У нас были независимые события на авитме,
вот. А тут у вас по сути уже событием является какое-то баррельское множество. Это вот какое-то
обобщение независимости случайных величин. Вот. То есть, на самом деле, и любые, как бы,
это можно сказать, что компоненты вектора независимы в этом случае. Можно сказать,
что вот эти случайные величины независимы, как бы вот в силу того, что мы можем по-разному
смотреть на определение вектора. Как бы, это такой определение независимости универсальное
и для компонент вектора и для случайных величин. Замечательный факт заключается в том,
то если у вас функция распределения совместно распадается в произведение функции распределения,
тогда у вас случайные величины независимы. Это называется критерией независимости.
Давайте для двух случайных величин сформулируем, но на самом деле это верно и для любого числа
когда и только тогда, когда совместная функция распределения x1, x2 в точке x1, x2 распадается
в произведение функции, в произведение функции распределения. Слева направо вообще очевидно,
потому что здесь у вас, по сути, написаны специальные случаи, когда b1, bn у вас вот такие
лучи. То есть слева направо очевидно. Если для всех баррельских множеств верно, то верно и для
уголков, для вот этих вот множеств. Справа налево не совсем очевидно, но на самом деле доказывать тоже
не очень сложно, потому что вот эти уголки у вас на самом деле образуют п-систему. Пересечение уголков
это уголок. Вот. А на самом деле, я не знаю, вот мы со своей группой решали такую задачку,
я не знаю, у вас разбиралась она или нет, но вот две сигма алгебры, порожденные п-системами независимы,
тогда и только тогда, когда вот эти вот порождающие п-системы независимы. Такой вот факт интересный,
просто там вот через теоремы Дынкина доказывается. Вот. На самом деле уголки, они порождают всю
баррельскую сигму алгебру vrn, это первый факт. А второй факт, что действительно у вас вот для них
независима здесь следует из условия, вот из правой части, а поэтому на самом деле у вас независимы
будут и все сигма алгебры, ну то есть для всех множеств это будет выполнено. Вот. Ну это мы просто
обсудили, как это доказывать. Ну вот m1, m2 должны быть замкнуты относительно пересечения, это
непосредственно используется при доказательстве. А если замкнуты относительно пересечения,
то это п-система. Вот. Супер. Уже вот чуть-чуть, чуть-чуть и задачу начинаем решать. Или может не
нужно так много теории. Ладно. Видимо надо. Не, ну наберитесь смелости, если легко, то скажите
легко. Если тяжело, скажите тяжело. Нормально. Смело. Это было не просто смело, между прочим.
Так, ладно, я еще одну фразу приберегу, но потом. Так. Так, критерии независимости. Что? Ну, смотрите,
чаще всего на самом деле в многомерном случае не функции распределения задаются, а плотности.
Вот. Ну и на самом деле у вас также просто возятся абсолютно непрерывные случайные векторы,
например. Это такие векторы, у которых совместно функция распределения имеет вот такой вид.
Как бы, понимаете, сингулярные случайные величины рассматривать на, в инмерном пространстве уже не
очень интересно, знаете почему? Потому что там любое подмножество меньшей размерности будет
сингулярным распределением. Вот. Это как бы там такой-то отдельный класс был, да? Да, вы абсолютно правы.
Спасибо. Вы правы. Спасибо. Вот. Ну вот, также абсолютно вводится плотность. У нее абсолютно такие же
свойства, что она не отрицательна и интеграл от нее по всему пространству равен единичке.
Если вы любую такую функцию приведете, она будет являться плотностью некоторого случайного вектора.
Вот. Но гораздо более интересен, конечно, следующий факт. Критерии независимости
в терминах плотностей. Так как плотности на самом деле очень тесно связаны с функциями
распределения, но это более-менее понятно, вот такой же критерии независимости в терминах
плотностей можно сформулировать. На самом деле две случайные величины независимые тогда и
только тогда, когда их совместная плотность, давайте все-таки букву П пишем для плотностей,
и 1х2 распадается в произведение плотностей. Вот. Доказательство, это факт, это тоже не
очень сложно, там пару раз теория Муфубини применить и все готово. Это все уже, это финиш.
Это верно для любого количества, но мы с вами просто для краткости формулируем для двух
случайных величин. У нас просто на практике скорее всего будут две случайные величины везде
встречаться, но понятно, что это верно и для большего числа. Так, понятненько? Вот этим фактом мы
с вами пользоваться будем. И последнее, что нам, наверное, еще понадобится, вот последние два момента,
и мы переходим к задачам, и теории сегодня больше не будет. Будут только задачи. Последние два факта
замечательные, которые мы хотим сформулировать. Первое, которое нам непосредственно понадобится.
Так, еще пару фактов осталось. Значит, смотрите, если вам дали две независимые случайные величины
плотностями, то совместную плотность вы очень легко можете найти. Если я независимый, уже,
но это сложнее. Обычно там сразу дают просто совместную плотность. А вот такой вопрос,
если вы знаете совместную плотность, и 1х2, вот так назовем, и 1х2, как найти плотность каждой
случайной величины по отдельности? Найти по x1 от x1. То есть как найти частную плотность?
Ну, маргинальная она называется. Да, давайте мы это с вами, вот этот факт мы аккуратно с
вами сейчас покажем. Во-первых, вот этот факт, я думаю, никого не смущает. Вне зависимости от того,
про какую случайную величину мы говорим, вот это более-менее должно быть всем очевидно. Что
вероятность события, это просто интеграл по нему от плотности. Вот, но это просто следует из того,
что из равенства с функциями распределения вы по сути одинаково задаете вероятность на
порождающей системе, и значит у вас по теории микродоурия однозначно мера продолжается.
Примерно так доказывается. Ну ладно, если что-то страшное, то поверьте, вот так работает. Отлично.
Ну получается, давайте попробуем с вами вероятность множества а найти. Но это на
самом деле вероятность того, что случайный вектор T1 к T2 принадлежит множеству а декартового произведения R.
Вроде понятно, да, все? Ну и все. А дальше просто пользуемся теоремой Фубини.
Так, здесь у нас будет совместная плотность по x1, x2 к точке x1, x2. Вот внутри у нас получается
будет интегрирование по второй переменной, то есть dx2. Вот так вот. А снаружи будет dx1. Вот. Ну и
вот это вот ничто иное, то что внутри записано, как на самом деле плотность к T1. Почему? Ну потому
что смотрите, у вас же плотность, это вот такая функция, что для нее вот это всегда выполнено.
Вот здесь с вами плотность множества а вывели через интеграл вот какого-то вот странного
выражения dx1. Ну значит вот это вот странное выражение, о которых в квадратных скобках написано,
есть ничто иное, как плотность к T1. Вот. Ну все, думаю более-менее понятно. То есть вот это важно,
действительно, если вы хотите получить и совместную плотность, плотность какой-то
компоненты конкретной, вы должны бы интегрировать ненужные компоненты. Это более-менее понятно.
Вот. И еще небольшой факт, вопрос. Не послышалось. Послышалось. Так, и последний факт, который нам
вот прямо сейчас понадобится, это теорема о замене переменных в интеграле Либега.
В каком-то виде нужно сформулировать, потому что мы его используем и будем,
наверное, везде в последних трех задачах. Может не везде, посмотрим. Так. Теорема о замене
переменных в интеграле Либега. Вот. Ну давайте сначала мы напишем самое главное утверждение,
потом потребуем то, что действительно нужно. Давайте здесь от Y пусть будет. Так, ничего не напоминает.
А еще не в сегодняшнее. Это прошлогоднее. Но мы с вами плотность очень похожую считали. То есть на самом
деле просто хочется какую-то интуицию создать, что смотрите, когда мы работаем с плотностями,
мы на самом деле с вами работаем с интегралом Либега. И соответственно, когда вы делаете какую-то
замену переменных или пытаетесь посчитать плотность от преобразования от случайных величин,
вы на самом деле делаете замену переменных в интеграле Либега. Но нужно, правда, потребовать,
чтобы phi было дифиморфизмом. То есть биекция и непрерывно дифференцируемая. Если это выполнено,
тогда вот этим выражением можно пользоваться. То есть если у вас дана исходная плотность какая-то
совместная и вас просят найти плотность каких-то других случайных величин, вы просто пользуетесь
теоремой замене переменных в интеграле Либега и все хорошо. Вот еще нужно сказать, что а это какие-то
там и вот это вот это открытое множество, но мы на этом акцентировать внимания не будем. Это намотание
у вас было. Окей? Ну все, в принципе, мы готовы. Так, время. Нормально выскрываем. Давайте задачу
решать. Задачка номер два.
Задачка номер два. Условия.
Ага, значит у нас х и у имеют экспоненциальное. Во-первых, они независимы. Во-вторых,
х имеет такое же распределение как и у, экспоненциальное с параметром лямбда. И вот
рассматриваются две такие случайные величины х плюс у и вторая х поделить на х плюс у. Вот и что
нужно найти? Нужно найти совместную плотность, совместную плотность у и в. И еще нужно найти,
а еще нужно доказать, что они независимы. Ну проверить. Ну давайте решать. Все, я теорему
замене переменных стираю. И это тоже все смотрю. Так. Так-так-так-так-так. Ну все. Соответственно,
все такие задачи решаются очень просто. Первый шаг. Вы находите просто совместную плотность
исходных случайных величин. Совместная плотность исходных случайных величин. Вот смотрите, х большое,
у большое это случайные величины, х маленькая, у маленькая это аргумент. Надеюсь вас это путать
не будет. Так, как у нас выглядит совместная плотность этих двух случайных величин? Почему?
Потому что по критерии независимости. Отлично. Ну все, осталось только замену
переменных сделать и задача решена по сути. Ну давайте делаем замены переменных аккуратно.
Значит у нас у есть х плюс у, в есть х на х плюс у. Там обратные преобразования в теореме замене
переменных. Поэтому нам нужно найти обратные преобразования. Находим обратные преобразования.
Х это у в. Перемножили вот это уравнение на вот это. Х плюс у сократилось. Получается у в
равняется х. Значит х это у в. Осталось найти что такое у. Ну у похоже на то, что это у на единичку
минус в. Вроде не соврал. Супер. Екабиан. Ну давайте прочитаем аккуратно. Екабиан.
Значит мы берем. Там екабиан тоже обратного преобразования берется. Поэтому вот это дифференцируем
по у. У нас получится в. По в получится у. Второе уравнение по у. Один минус в. По в. Получится
у. Вы правы. Так чему екабианчик равен? Во-первых модуль. Не забываем что модуль. Перемножаем это
будет минус у в. Здесь будет минус у на единичку минус в. Так вот у в. Это с плюсиком будет так,
что вот это сократится. Остается только минус у. Но так как там модуль. Мы же екабиан записываем.
Значит просто модуль. Блин классно. Что дальше? Давайте теперь просто запишем как у нас будет
выглядеть совместная плотность новых случайных величин. Ну совместная плотность новых случайных
величин. Так давайте здесь вот у большое будет. В большое. Так это у нас екабиан. Давайте сначала
екабиан умножим. Затем у нас исходная плотность была п от х точки х. Х это у нас у в. То есть это
п от х точки у в. Умножаем на п от у точки у. У нас это у на 1 минус в. Вот нашли с вами совместную
плотность. Давайте приведем теперь это какому-нибудь численному ответу. То есть подставим плотность
экспоненциального распределения. Что у нас здесь получится? У нас получится модуль у умножить на
лямда е в степени минус лямда у в на индикатор. Так про индикаторы главное тоже не забывайте. У
в больше либо равно нуля и плотность у. Плотность у такая же, но с другим аргументом. Е в степени
минус лямда здесь будет у минус в на индикатор того, что у на единичку минус в больше либо равен нуля.
Давайте немножко упростим это выражение. Вот тут как бы смотрите, мы как бы формально, мы же хотим,
чтобы вероятности совпадали, и по сути мы формально пишем всегда интегралы. Мы как бы
работаем с подинтегральными функциями каждый раз, поэтому здесь корректно просто применять
теорему замене переменных в интеграле Либега. Как видите, здесь интегралов тоже никакого нет,
но на самом деле плотность имеет смысл только если они под интегралами где-то записаны.
Ну они с точностью почти наверно определены. Если вы плотность поменяете в конечном числе точек,
даже в счетном, у вас интеграл Либега не изменится. На множестве меры ноль, если поменяете,
у вас плотность не изменится. Ну интеграл, прошу прощения. Функция плотности изменится,
а интегральчик от нее нет. Логично. То есть плотностей целое семейство, они там...
Ну множество меры ноль. Ну и, во-первых, подождите, если два интеграла равны,
это вообще ничего не говорит про равенство функций. Почему?
Не совсем понятно. Вот смотрите, то есть мы, грубо говоря, с вами... Ну хорошо,
это сокращенная запись для того, что вероятность любого AB множества декартового произведения есть
на самом деле интеграл вот этих исходных плотностей. Совместная плотность у нас произведения
плотностей p от x точки x, p от y точки y, dx dy и все вот это по r2. Ну по сути да. Неформально.
Это просто для облегчения того, что происходит. На самом деле... Да. Но нам плевать, да. Извините,
вот то есть, смотри, теорема о замене переменных для каких-то функций, ну непонятно, почему она
будет работать. Теорема о замене переменных работает в контексте интеграла. Все плотности
как бы неотрывно связаны с интегралами вот такие. А дальше мы, по сути, просто переходим, грубо
говоря, к новым случайным величинам, к новым плотностям. У вас вот эти множества меняются,
вот эти множества, по которым вы интегрируете, меняются и плотности тоже как-то преобразовываются.
По сути мы дальше вот везде опустили интегральчики, где нужно. И все. Извините,
если я кого-то вот прям убил этим. Все. Время пришло. Вот у кого-то это щелкает, а у кого-то не щелкает.
Да-да-да, вы правы, тут множество а на b.
Так, понятненько?
Да, с точки зрения вероятности все останется корректно. Вот смотрите,
помните, что мы когда с вами читали преобразование вот для случайной величины,
мы phi в минус первое навешивали на правую часть. И как бы с точки зрения вероятности
это остались целые. У нас там уже новые какие-то пространства, грубо говоря, и все по-новому,
но вероятности все сохранились, которые были там по омегам, по исходным пространствам.
Тут примерно то же самое произошло. И вот почему это аккуратно, верно, должно доказываться на
лекциях. А сейчас, типа, я показываю как это решать. Ну и формально здесь действительно везде
нужно интегралы написать. И с интегральчиками все будет корректно. Так, идем дальше? Или что-то еще
обсудим? Так, хорошо. Давайте доведем просто задачку до конца, она на самом деле уже почти решена.
Задачка почти решена. Давайте мы просто с вами соберем ответ в более-менее правильной какой-то
форме. Во-первых, давайте заметим, что из УВ больше-либо равно нуля, и из двух индикаторов следуют
какие-то более простые индикаторы. У единичка минус В больше-либо равно нуля. На самом деле,
отсюда будет следовать. Что отсюда будет следовать? На самом деле, что знак у вот этого и вот этого
одинаковый. То есть В на единичку минус В больше-либо равно нуля. Но отсюда на самом деле следует,
что В принадлежит от нуля до единички. А У не отрицательна. Ну почему и так? Вот квадратное
уравнение у вас, веточки направлены вниз, поэтому нам подходит между двумя корнями, корень 0,1,
поэтому В только от нуля до единицы принадлежит из вот этих двух неравенств. А если у вас это
положительно, значит у вас тоже должно быть положительно. Соответственно, на самом деле,
из вот этих вот двух индикаторов, которые мы с вами получили, следуют вот эти два индикатора.
Так, и того мы имеем с вами. Ну значит, модуль с Ушки можно снять. И того мы что с вами получим?
Давайте отдельно соберем все, что с У и отдельно соберем все, что с В. Вот это минус лямбда у В
сократится. И давайте посмотрим, что получится. У нас получится лямбда в квадрате у Е в степени
минус лямбда у на индикатор у положитель, не отрицательный, и умножить это все на индикатор В больше
нуля. Ну что, друзья, я могу сказать, что мы решили задачу. Это совместная плотность и...
Спасибо.
У вас абсолютно непрерывно относительно меры в R2, поэтому там как бы знаки не особо влияют.
Там вообще в принципе без разницы, что происходит на этом множестве. Так, ответ получили. Замечаем,
что он распадается в произведение двух функций. Вот эта функция A2 зависит, вот эта функция зависит
от P. На самом деле это две плотности. Это как раз таки произведение двух плотностей. Можно
аккуратно выинтегрировать каждую лишнюю переменную и получить по отдельности вот это и вот это. А это
значит, что мы получили с вами, что совместная плотность вот этих двуслучайных величин распадается
в произведение вот этой плотности и вот этой плотности. Значит V у вас имеет равномерное
распределение на отрезке 0,1, а У у вас имеет, это более-менее так понятно, сумму двух
экспедиционных случайных величин — это гамма распределения с параметрами 2 лямбда.
Я думаю, что сумма экспедиционной случайных величин равна гамма распределения у вас
воздоказывалось на семинаре? Обидно. Ну, в общем, вот такая случайная величина
называется гамма случайной величиной. Ну, вот такая плотность соответствует
случайной величине, которая называется гамма-величиной с гамма-распределением.
Вот функцию распределения вам не напишу, там будут кое-какие проблемы. А плотность
могу написать. Смотрите, у гамма-распределения есть два параметра, k и лямбда. Вот, тогда плотность имеет
следующий вид. Сейчас я посмотрю, потому что справочная информация. Где мой листочек? На
экзамене, кстати, можно этим пользоваться. Вот. На самом деле там функция распределения имеет,
ой, плотность имеет следующий вид. Лямбда в степени, ну, параметризация только обычно альфа-лямда,
где степень минус лямбда х на индикатор х больше нуля, больше либрономия без разницы.
Ну, вроде, ровно то же самое.
Смотрите, если мы аккуратно это вы интегрируем первую-вторую переменную,
у вас получится вот ровно то же самое. Я это проговорил и не сделал сам. Да, потому что,
смотрите, вы будете интегрировать, оно у вас распалость на произведение. То есть на самом
деле у вас интеграл распадется. Интеграл вот этой штучки будет равен единичке просто потому,
что это плотность гамма-случайной величины, а вот эта плотность равномерная случайной величины
на отрезке 0,1. И у вас просто по отдельности, когда вы будете либо по одной переменной интегрируете,
интегрируешь либо по-другой, у вас все, что от нее не зависит, будет выноситься, а все, что
будет оставаться, интегральчик будет единичка. Я как бы это усно проделал,
действительно, нужно по-хорошему показать, что... в общем, упражнения.
Индикатор V принадлежит от нуля до единички, равен интегралу от вот этой вот функции,
вот которую мы получили, по-ду. А если по-дв вы проинтегрируете, то у вас получится вот эта
часть. Более-менее понятно, почему это так будет. Не, такого быть не может. Давайте, да,
небольшое введение. Вот это, это, друзья, гамма распределения. Мы со своей группы его уже
посмотрели с разных сторон, но на самом деле, что такое гамма от альфа, знаете? На самом деле,
если вы знаете, что такое интеграл от гамма функции, то вот это гамма функция. И просто она
нормирована на гамма от альфа для того, чтобы это была честная плотность, которая приинтегрируешь
даёт единичку по прямой. Если вы знаете, что такое гамма функция, то что такое гамма распределения,
у вас не составит труда понять. Не совсем понятно, как обычно,
когда ты что-то такое считаешь, ты просто сводишь гамма-функции,
у тебя все сокращается. Ну, то есть, допустим, если
тебя попросят мотош вот от такой штуки посчитать,
у тебя, по сути, здесь просто х будет в степени альфа,
да? Не альфа, а минус один. Тогда ты один раз берешь
по частям, сводишь гамма-плотности к той же самой и говоришь,
что интеграл плотности это единичка, потому что
ты сокращаешь на это, и все, и у тебя ответ получается.
То есть, непосредственно там всякие гамма-функции
вычислять в точках не целых, там это то, что на мото-невы
сейчас делаете, не нужно. Обычно достаточно что-то
по частям взять и привести к тем же плотностям исходным,
которые у вас были, а плотности уже вы знаете, как интегрируют,
но это единичка просто по всей прямой. Гамма, да,
гамма от альфа. Не совсем понимаю, это в знаменателе
гамма от альфа.
Прошу прощения, да, на самом деле у вас гамма-функция
бывает от двух параметров, просто второй параметр
это масштаб. Это, по сути, просто она растягивается.
По-моему, да, определяется в некоторой литературе
гамма-функция от двух аргументов. В общем, это сейчас, наверное,
не совсем интересно, у вас должна была быть задача
в фиминарском листочке, что сумма k экспоненциальных
случайных величин – это гамма-распределение с параметром
k лямбда. Это просто на формулу свертки, вы ее по индукции
к раз применяете, и вот этот факт получаете. Тут я просто
заметил, что вот это – это плотность гамма-распределения
с параметром 2, ну, 2 лямбда, а вот это – это плотность
равномерного распределения на отрезке 0,1.
Формула свертки, ну, по сути, вам позволяет посчитать
плотность суммы двух случайных величин?
Не было?
Не знаю.
Давайте небольшой социальный опрос. Социологический.
Кто знает, как формулу свертки в теории вероятности применять?
Да.
Друзья.
Ну, давайте аккуратно выведем. Быстро. Это минута займет.
Так. Ну, в общем, задачу мы дорешали. У нас плотность
разложилась в произведение плотностей, поэтому на самом
деле все хорошо. Эти две случайные величины У и В независимы.
То есть, у вас исходно были случайные величины независимые,
вы сделали какое-то преобразование, и вам так повезло, что новые
случайные величины тоже независимы. У этой задачи
есть физический смысл. Какой? Ну, вот представьте, что
у вас приходят две электрички. Каждую, которая имеет время
прихода, имеет экспоненциальное распределение. Вот. Тогда
на самом деле доля времени, который вы будете ждать
первую электричку, если вы будете ждать две электрички
суммарно, имеет равномерное распределение.
Вот это все связано с экспоненциальными turns распределениями,
сейчас не успеем про это нормально поговорить. Вот.
То есть, понятно, что сумма их имеет какое-то
гамма-распределение, но вот этот факт вы, допустим, не знаете.
Но вот этот факт интересен тем, что
доля времени, который вы будете ждать первую электричку,
имеет равномерное распределение.
Вот. Всё. Это про физический смысл задачи. Теперь давайте
немножко про формулу свёртки поговорим, что ли, тогда.
Короче, на самом деле можно сворачивать функции распределения.
Но обычно формула свёртки подразумевается под тем,
что мы просто научимся с вами считать плотность
суммы двух случайных величин. То есть вот вам дают сумму
двух случайных величин. Во-первых, вам дают две случайные
величины независимые. И говорят, а почитайте нам
пожалуйста плотность кси1 плюс кси2. Вот. Но вы уже
наверное более-менее понимаете, как это делать, если мы такую
сложную задачу решили. Они независимы, поэтому их
совместная плотность – это просто произведение плотностей.
Дальше мы делаем просто с вами замену переменных.
У равняется х плюс у, а в равняется у. Ну зачем нам
именно такая замена переменных? Нам же нужен дефиаморфизм.
Если бы вы только сумму оставили, то у вас бы взаимооднозначного
соответствия не было. Поэтому вы во вторую переменную
кладёте исходное значение. Вот. А обратное преобразование
всё равно то же самое, что мы там проделывали. У равен
v, х равен u минус v. Вот. Ну и тогда плотность суммы…
Во-первых, совместная плотность x1 плюс x2 и x2 с точки uv. Это
у нас что будет? Это будет якобян, но так как это линейное
преобразование, якобян единичка. Ну и тогда плотность
суммы… Ну во-первых, совместная плотность x1 плюс x2 и x2 с точки
uv. Ну без растягивающих коэффициентов, поэтому если
посчитаете, аккуратно, у вас якобян единичка получится.
А pexi1… Так, x у нас чем стало? x это у нас u минус v на pexi2
точки v. Вот. А теперь, так как нас просили плотность
столько суммы, то мы должны с вами избавиться от вот
этой лишней переменной. То есть x1 плюс x2… Ну это на
самом деле будет интеграл по прямой вот этого выражения.
pexi1 в точке u минус v на pexi2 в точке v. А dv. Ну все, это
есть свертка. Теперь вот давайте интересный
вопрос. Вы узнали, что это на свертку из Маттона
похожа? Вот. На самом деле, просто формула в свертке
позволяет вам найти… Позволяет вам найти плотность суммы
двух случайных лишней. Вот. Окей? Вот. Ну и на самом
деле, если вы хотите доказать, что сумма n независимых
экспоненциальных случайных величин имеет гамма распределения
с параметрами n дямда, ну вы просто формулу свертки
вот этого, ну по сути формулу для плотности суммы применяете
по индукции. Вначале x1 плюс x2, потом вот вы посчитаете
плотность у первых двух слагаемых, прибавляете
третье и так далее. Ну все, и вы докажете, что у вас
получается действительно вот эта вот гамма-функция
гамма распределения. Так, все, давайте дальше. Третья
задача. У гамма-функции есть первое свойство. Гамма-функция
точки n, это на самом деле n минус 1 факториал.
Вот такое выражение. Если до базы дойти, то действительно
получится, что гамма-функция в точке n, это n минус 1 факториал.
Вот, ну еще есть связь с бета-функцией. По сути, это все свойства,
которые используются на тервере. Вот это, наверное,
нужно, чтобы доказать вот эту задачу решения, просто
связь с факториалом. Бета-функции здесь не выскакивают, так
что про них ничего говорить не будем. Надо аккуратно
определение посмотреть. Сейчас не смогу написать. Давайте
загуглим википедии и посмотрим. Сейчас, да. Все. Давайте дальше.
Задача три. Время просто поджимает, я домой хочу.
Вот. Хорошая новость, что мы все теорию уже разобрали,
а плохих новостей не будет. Поэтому быстренько сейчас
с вами дорешиваем две задачки и расходимся. Так, третья
задачка. Где мой телефон? О, третья задачка интересная.
Я надеюсь, у вас есть условия перед глазами. В общем,
x и y имеют, они независимы. Если очищать это условие,
то они независимы и имеют равномерное распределение
на отрезке 0,24. Хочется ответить на вопрос, а какова вероятность
того, что x меньше либо равен 12, y меньше либо равен 12
и модуль x-y меньше либо равен 1,2? Там про что задача?
Попросили проголосовать вас где-нибудь в чате, да?
И вы теперь голосуете равномерно где-то в течение всего дня.
Это, конечно, плохое предположение, лучше было бы экспоненциальное,
но там с экспоненциальным нехорошие вычисления выскакивают.
Мы предположим, чтобы равномерно в течение дня голосуете
на выборе представителей, например, курса у вас недавно были.
И какова вероятность того, что два человека, которые голосуют независимо,
проголосуют до обеда и так, что они проголосуют не больше,
чем в получасе друг от друга? То есть, что с разницей не больше,
чем полчаса они проголосуют. Окей, как такую задачу решать?
Это плохо, очень. Да, мы сейчас с вами придем, на самом деле,
мы придем с вами к геометрическим распределениям.
Кстати, да, плохо, что здесь у, потому что это действительно геометрические распределения.
Надо было все-таки здесь что-нибудь посложнее брать.
Экспоненциальное распределение все-таки надо было брать.
Давайте мы с вами все-таки методику решения обсудим,
а у нас будет простой счет. Но как бы на самом деле ведь идея плотности в чем?
Это же у вас по сути геометрическая вероятность, но только в геометрической вероятности
вы предполагали, что у вас как бы каждая точка равновероятна, каждый промежуточек, да?
А тут у вас плотности многомерные как бы дают, что вот некоторые области более вероятны,
а некоторые менее. Но просто здесь мы этого не заметим,
потому что у вас здесь равноверное распределение.
А вот если бы здесь распределение было какое-нибудь экспоненциальное,
тогда вот числа около нуля у вас бы имели бы большую как бы вес, чем числа дальше от нуля.
Это как бы идея такая. У меня идея была в этой задаче такая,
но я когда сейчас вот пытался перед семинаром с экспоненциальными случайными личными посчитать,
там неприятно получается дальше. Я решил поменять на равномерное.
Ну не суть, давайте решать.
Первое замечание. Давайте вот какое мы с вами сделаем.
Вероятность события А, это на самом деле мы уже с вами выяснили.
Это А на плотность X dx.
Ну по сути это же на самом деле то же самое свойство, которое у нас было на авидме,
что вероятность события А это на самом деле математическое ожидание индикатора.
Такое, ну если кому-то это ближе, то это вот абсолютно эквивалентно.
И вот когда вас просят посчитать какую-то сложную многомерную вероятность,
вот например вас могут попросить посчитать вероятность того, что,
это вот просто автопный пример, X больше Y.
Ну вот эту задачу можно ведь по-разному решать.
Можно перенести Y влево, посчитать распределение X-Y
и посчитать вероятность того, что оно больше нуля.
Один вариант.
А второй вариант это действительно как бы вот многомерной вероятности
через геометрическую интерпретацию считать.
Ведь потому что, смотрите, вот эти все неравенства, которые мы здесь записали,
они задают какую-то область.
Область А в нашем случае.
И по сути все, что вам нужно, чтобы выяснить, что в этом случае
Область А в нашем случае.
И по сути все, что вам нужно, чтобы узнать вероятность этого события,
это просто проинтегрировать по области А вашу совместную плотность.
Ну в нашем случае будет совместная плотность.
Итак, давайте вот это все мы с вами обзовем за событие.
Ну давайте B назовем его.
Вот это все?
Почему?
Я такого не писал.
Математическое ожидание индикатора.
Это же по сути то же самое.
Почему?
Почему это то же самое?
Ну потому что это то же самое, что и интеграл по всей прямой,
индикатор от А.
В от Х.
Ну справедливо же.
О, а это есть математическое ожидание.
Ну вот это все.
О, а это есть математическое ожидание индикатора.
Это все равно между собой.
Так.
Ну давайте аккуратно досчитаем.
Итак, вероятность события B.
Это получается просто в нашем случае плоскость, да, интеграл ПР2.
Индикатор события B.
Множить на совместную плотность.
Дх, ду.
И в принципе во всех задачах такого рода,
там вас могут спросить,
какова вероятность, что треугольник со сторонами х, у1 существует.
Ну по сути вам просто нужно какие-то неравенства записать
и вот что-то похожее написать.
Во всех задачах такого вида вам нужно понять,
как выглядит область и проинтегрировать совместную плотность,
которая либо дана вам в явном виде,
либо величины независимой получается как произведение плотностей,
просто проинтегрировать по этому множеству.
Ну по сути все, вся задача на многомерную вероятность решается так.
Обычно.
Ну там могут быть приколы, конечно, свои.
Ну и давайте аккуратно дорешаем.
Нарисуем нашу плоскость.
Итак, вот пусть случайная величина х будет по оси х,
а случайная величина у не поверите, по оси у.
Вот, и это соответственно наш квадратик 24 на 24.
У нас есть три неравенства.
Первое неравенство говорит, что х меньше 12, меньше либо равен.
Второе неравенство говорит, что у меньше либо равен 12.
Мы уже живем как минимум вот в этом квадратике.
А вот это вот модульное неравенство на самом деле говорит,
что нас интересует вот такая вот полоска.
Ну и вот здесь точки, понятно, она вторая.
Она вторая.
То есть по сути, когда нас спрашивают вероятность события B,
нас просят посчитать интеграл от плотности по вот этому множеству B внутри.
Вот, ну и заметьте, вот до этого шага мы нигде не пользовались
тем, как у нас плотность выглядит.
Поэтому плотность мы бы вот прямо сейчас могли поменять с вами
на экспоненциальные случайные величины.
И тогда задача стала бы сложнее, там проще.
Просто чтобы вы понимали, что вот здесь плотности могут быть любые.
Либо вам сразу совместную плотность положенную какую-то дадут.
Либо вам дадут, допустим, две экспоненциальные случайные величины.
Или экспоненциальную равномерную.
Понятно?
Понятно?
Ну все, интеграл, посчитать.
Да и все, в принципе.
Ну, на самом деле, вот в данной конкретной задаче, так как у нас равномерное распределение,
можно жульничать, можно площади посчитать и все.
Но вот просто мне не хотелось настолько про свой пример давать,
а я почему-то его в силу не дал.
Потому что здесь же вам просто нужно найти отношение вот этой площади
к площади всего 24 на 24 и поделить площадь вот этой штучки.
А это плохо.
Это неинтересная задача.
Давайте поэтому мы с вами ее сейчас поправим.
А да.
Плотность нормального распределения.
Ну вот, корень на 2p sigma квадрат
е в степени минус х минус а в квадрате
на 2 sigma в квадрате.
Эти можно пользоваться.
Да, ну типа...
Да-да-да, это справочную информацию запоминать не надо.
Ну давайте чуть-чуть усложним задачу.
Вот пусть у нас х будет иметь действительно вот такое распределение.
А у у нас будет иметь экспоненциальное распределение с параметром 1.
Ну и они независимо все еще будут.
Чуть-чуть усложнили задачу, ну и давайте теперь ее аккуратно дорешаем.
Только теперь мне ваша помощь понадобится, чтобы вы следили, чтобы я в интегралах не ложал.
Время просто позднее, я могу чуть-чуть ошибиться где-то.
Так, друзья, какие есть идеи, как будем разбивать этот интегральчик?
Это всем пофиг.
Не, я просто думал, как-нибудь по-хитрому, чтобы мы могли разбивать этот интегральчик.
Ну, в общем-то, мы будем разбивать этот интегральчик.
Не, я просто думал, как-нибудь по-хитрому, типа, взять, вычесть вот эту вот.
Вот эту площадь, вычесть из чего-нибудь большего.
А в тупую это как?
На три куска, так хорошо, как вы предлагаете.
Ну давайте, короче, кто-нибудь, давайте кого-нибудь позовем, может посчитать.
Ну ладно, наверное, никто не захочет.
Хорошо, значит, разбиваем на три кусочка, да?
Видимо, вот так и вот так, да?
И считаем интеграл по вот этому кусочку, по вот этому кусочку и по вот этому кусочку.
Хорошо, значит, здесь у нас граница интегрирования от 0 до 1 и 2.
Вот эта функция, понятно, какая это. На самом деле, это y равен x плюс 1 вторая.
Вот эта функция, это y равно x минус 1 вторая.
Вот эта граница, это 1 вторая.
А вот эта граница, наверное, это будет 12 минус 1 вторая.
Что еще раз?
Похоже на правду.
23 вторых, я бы сказал.
Ну вот, типа, вот этот кусочек отдельно проинтегрируем.
Хорошо, как у нас выглядит совместная плотность?
Ну, это произведение плотностей.
x мы с вами положили, что имеет вот такое распределение.
То есть, на самом деле, это просто индикатор того, что x принадлежит от 0 до 24.
Ну, нужно отнормировать еще все-таки.
Плотность должна приинтегрирована, давать 1. Поэтому это все поделим на 24.
Это первая плотность. Вторая плотность экспедициональная с параметром 1.
Значит, плотность выглядит следующим образом.
Минус, а ну там лямба единичка, минус y получается.
Все. И на индикатор еще.
Y больше либо равен 0.
Ну вот, в принципе, и все.
Ладно, давайте я, наверное, даже досчитывать не буду. Мы запишем интегралы.
А мы вот аккуратно сейчас запишем все пределы интегрирования.
А досчитайте вы их, если что, сами. Итак, первый интеграл у нас какой получится?
По х там у нас будет от 0 до 1.2.
По y мы откуда интегрируем? От 0 до x плюс 1.2, видимо.
И здесь вот эта плотность пишется.
По-моему, вот это на этот индикатор можно забить, на этот индикатор можно забить.
Мы их уже все учли. И получится просто e в степени минус y на 24.
Ну вот, и на этот индикатор можно забить.
На этот индикатор можно забить. Мы их уже все учли.
В степени минус y на 24.
Вот так. Такая запись префиксных интегралов никого не пугает.
Это значит, что мы потом интегрируем вот эту часть.
Ну, короче, можно было бы сделать вот так.
Есть префиксная просто запись, она чуть более компактная, мне больше нравится.
Но можно и так записать. Хорошо, это первый интеграл.
Второй интеграл. У нас будет от 1,2 до 23,2.
Скобочка. Что у нас в скобочках будет?
Вот получается x минус 1,2 до x плюс 1,2.
Да, все ту же функцию.
E в степени минус y на 24.
Dy и снаружи dx.
Так, и третий интеграл.
Третий интеграл у нас получится от 23,2 до 12.
Здесь будет...
Так, верхняя граница 12.
А нижняя граница, видимо, y, x минус 1,2.
E в степени минус y на 24.
Dy и вот это все dx.
Ну и все. Ответ 1 плюс 2 плюс 3.
Не 6.
В смысле интегралы, которые тут записаны.
Вот. Я думаю, если кто-то из вас сейчас вот за компом может это быстро там вбить в альфрам, мы просто ответ получим.
Чтобы люди, которые потом запись смотрели, могли сравниться.
Чем-нибудь.
А вдруг альфрам сломается?
Ладно.
Давайте к четвертой задаче переходить потихоньку.
По этой задаче есть вопросы?
Эта задача более-менее такая на многомерную вероятность.
Вы выбираете просто тело внутри вашего размерного пространства.
И по нему интегрируете вашу совместную плотность.
Совместная плотность либо вам сразу дана, либо это произведение плотностей, если случайная величина независима.
Так, задачка номер 4, заключительная.
Если что?
А все, вот это уже примерно никак.
Ну, смотрите, вы говорите, что между вашими двумя случайными величинами есть какая-то связь, но какая связь я тебе не скажу.
Ну, по сути.
Поэтому там сразу дают функцию от двух переменных, которая сразу уже как бы эту связь по себе закладывает.
Так, ну и задача номер 4.
Дача 4.
Давайте мы сейчас аккуратненько сформулируем.
Случайные величины x и y независимы.
x имеет стандартное нормальное распределение.
y равномерное распределение на отрезке 0,1.
Вопрос. Найдите-ка вариацию e в степени x корней из y, y.
Ну, вот давайте сейчас еще немножко с вами чуть-чуть помним.
Вот у нас были мотожи. Мы поняли, что мотожи в случае абсолютно непереверных случайных величин, это просто интегралы какие-то.
Потом у нас, ну что вас могут попросить посчитать в похожих задачах?
Ну, дисперсию случайной величины вас могут попросить.
Ну, дальше вы либо по определению считаете, если вам так удобнее.
То есть как математическое ожидание x-e x в квадрате.
Либо через формулу подсчета.
Вот. Ну, что вас еще могут попросить посчитать? Кавариацию двух случайных величин.
Кавариация двух случайных величин.
Ну, также либо по определению, если вам так вдруг оказалось удобнее.
Ну, вдруг мы мотожидание угадали, там будет чуть проще интеграла.
Либо опять-таки через формулу подсчета.
Что у нас там будет? Математическое ожидание x-y минус мотожидание x на математическое ожидание y.
Ну, в принципе, все свойства, которые для интеграла Либега у нас были выполнены, они выполнены для мотожиданий.
Поэтому мы с вами сейчас на доп. 7 их не обсуждали, потому что они у нас все на вид не были.
Вот. Ну, кавариация там как-то связана с корреляцией.
Что-то обозначает про независимость, ну, про некоррелированный случайных величин.
Это все очень круто. Думаю, все знаете.
Вот. Ну, и вас просят посчитать кавариацию двух вот таких случайных величин.
Как это будем делать?
Да, единственный вопрос. Вот здесь у вас стоят случайные величины x и y.
А здесь у вас стоят случайные величины e в степени x корнея из y, запятая y.
То есть, хорошо, какой план решения в твоем мире?
Какой план решения?
Так, хорошо, давайте немножко интуит добавим.
Вот, смотрите, вы хотите посчитать математическое ожидание x в квадрате.
Как вы будете его считать?
Значит, вы зря сегодня приходили на доп. 7.
Это же просто интеграл x в квадрате на плотность от x.
Вам не нужно считать плотность этой случайной величины.
Можно же просто, ну, в силу замены переменных.
На самом деле, вам здесь тоже плотности вот этих случайных величин считать не надо.
Вам достаточно просто будет взять интегральчик.
Просто, потому что у вас здесь в определении, по сути, функции от векторов какие-то.
То есть, вы считаете математическое ожидание функции от случайного вектора.
И так же, как и здесь.
Первый вариант – это найти сначала распределение этого вектора и потом просто посчитать что-то.
А второй вариант – это сразу считать, как бы, g от x на плотность исходную.
Типа непонятно просто, зачем лишнее действие делать.
Вот.
Ну и, соответственно, данная задача вот от нас просит опять три интеграла посчитать.
Ну вот, их давайте быстро доведем.
И какие-нибудь выводы сделаем.
Три интеграла.
Первый интеграл.
Просто обсудим, как их считать.
Аккуратно досчитывать не будем, просто ответ запишем.
И все.
Вот, попадается вам вот такой интеграл.
Давайте его запишем.
У вас здесь будет e в степени x корней из y, y.
На плотность.
На плотность совместную.
А совместная плотность – это произведение плотностей, потому что случайные величины независимы.
Плотность стандартного нормального случайного…
Стандартная нормальная случайная величина – это 1 на корень из 2p.
e в степени – минус x квадрат пополам.
А плотность равномерного распределения – это просто индикатор y принадлежит от 0 до 1.
Да, стандартная – это значит, что в отожидании 0-ой теперь 1.
Вот.
Вот такой интегральчик вам нужно посчитать.
Блин.
Несложно вроде.
Ну, dx dy.
Ну и здесь нужно аккуратно написать, что это r2.
Вот.
Ну давайте просто иди и обсудим, как такое считать.
Пока подумайте, я смотрю с доски.
Вот.
Вот далее вам такой интеграл, и на самом деле он несложно считается.
Вот тут как раз-таки просто нужно уметь…
Короче, тярверский глаз как бы проверяется, что вот вы видите что-то здесь красивое,
то легко считать и не нужно будет ни одного интеграла на самом деле брать.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
И вот здесь нужно 1 интеграл на самом деле брать.
Ну да.
Давайте сначала там типа по теореме Кубини
переходим к повторному интегралу.
Здесь будет от 0 до 1.
dy.
Что внутри останется?
Наверное, можем еще y вынести, потому что от x он не зависит.
то у нас остаётся внутри. А, ну и константы ещё можем вытащить.
Константы вытаскивать не будем, сейчас объясню почему.
Да, мы сейчас плотно соберём с вами.
Значит, здесь у нас E в степени минус х в квадрате пополам,
ну и там ещё одна E есть.
На самом деле здесь будет
плюс два,
нет, здесь будет минус, если здесь минус перед C скобочкой,
здесь будет минус.
Минус два х корни из игрек.
Вот у вас такой интеграл, да, сейчас записан.
Ну всё, обратите внимание, здесь собирается полный квадрат,
добивается до плотности.
Давайте это аккуратно проделаем.
Значит, что нам нужно сюда добавить?
Нам нужно добавить Y,
значит, мы его отсюда вычили,
значит, нам нужно добавить Y пополам.
Ну да, супер.
E в степени Y пополам
у вас опять вылазит.
E в степени Y пополам
на Y.
А в скобочках у вас будет один поделить на корень
из двух π.
E в степени,
так, здесь будет
х минус корень
из Y в квадрате
пополам
dx.
Ну, константу добавим,
это более валидно.
Всё, заметьте, это у вас просто плотность.
Новое математическое ожидание у вас
поменялось, по сути,
в нормальной модели.
Дисперсия не изменилась,
но здесь у вас, по сути, сейчас записана интеграл
от плотности.
Забыл только здесь написать.
Здесь у вас записан интеграл от плотности.
Ну, это единичка.
Ну, всё.
Остается только вот этот интеграл.
Y, E в степени,
Y пополам.
Вот.
Ну, это я аккуратно посчитал, ответ.
4 минус 2 корня
из E.
Ну, E в степени,
одна вторая, вот здесь у вас вылазит,
как раз таки.
Да?
Смотри.
Вот здесь у тебя внутри интегральчик, да,
какой это был. Вот мы всё, что с Y
могли вынести, вынесли.
Здесь теперь пытаемся добить
полного квадрата вот здесь числителя.
Вот в числителе экспонента.
Чтобы мы, по сути, опять собрали,
вот ты у меня спрашивал,
вот здесь, помнишь, на доске было написано,
плотность нормальной
случайной величины.
Интеграл от плотности чему равен?
Да.
Вот. И на самом деле во многих таких задачах,
когда вас что-то просят посчитать,
иногда можно не брать интегралы, а просто
собирать плотности или мотожи, если вы знаете,
чему равен ответ, ну, чему равен мотож,
приводить каким-то известным интегралам
и вот этот интеграл руками не считать.
Вот. Ну, потому что почему интеграл от
E в степени
минус
f квадрат dt равен
корень из P
не совсем очевидно может быть
всем, да?
Ну, это не тривиальный факт.
А?
Ну, это несложно доказывать,
вы в полярные координаты переходите,
рассматриваете, типа вот этот же интеграл
помноженный на себя, переходите в полярные координаты
и у вас на все легко берется.
И у вас получается там P, а потом вы берете
корень из этого и у вас получается корень из P.
Так. Соответственно, здесь
что мы сделали? Мы просто собрали с вами плотность,
вот сюда под дефенсал
константу можно занести, которая так сами зависит?
Ну, чтобы вот здесь
была, типа, плотность теперь у вас получилась.
Ладно, да, да, да, да.
Хорошо, хорошо, вы правы, можно это не добавлять.
Ура, вы облегчили решение.
На один символ.
Ну ладно.
На питоне программируете?
Да.
На питоне программируете?
Так, ну,
разобрались, да, думаю, с этим?
Да.
Окей. Давайте последние два интеграла
обсудим. Смотрите, вот этот интеграл
по сути точно такой же.
Внутренний интеграл будет считаться так же.
У вас просто
вот этого y здесь не будет.
Вот этот y у нас был изначально.
Вот. А как
посчитать вот этот вот интегральчик?
Понятно всем, как вот этот интегральчик посчитать?
Этому от ожидания y нужно найти.
Да, можно сначала
найти плотность его, а можно, на самом деле,
просто сразу по-честному считать, как
в общем давайте, вот раз это вызывает вопросы,
последний интеграл обсудим и все.
И ответ просто запишем, который
получился.
Так.
Так, так, так, так, так, так.
Так.
Соответственно, смотрите, первый интеграл у нас получился
равен вот этому. Давайте я запишу, чему равен
второй интеграл. Второй интеграл
считается абсолютно
аналогично, и ответ там
получится
два корня
из e минус 1.
Вот. И остался вопрос, как считать третий интеграл?
Ну, от ожидания y
по определению
это y, p, y,
dy.
Но, на самом деле, не трудно заметить, что это
то же самое будет, что и
математическое ожидание,
ну,
то же самое, что интеграл
по r квадрат
y на совместную плотность
x и y.
dx dy.
Ну, просто по сути, у вас вторая компонента
здесь при интегрировании по дополнительной
оси у вас также у средницы.
То есть, вы вот здесь, когда будете плотность y считать,
вы же ее будете считать, как интеграл
от p, x, y
dx, так ведь?
Хорошо, если бы у вас не было
данной задачи вам дали, да, моргинальное
распределение, поэтому, хорошо, да,
вы правы. Это одна вторая.
А я что-то подумал...
Я, в общем, уже забыл условия.
Ну, просто
если бы вам дали совместную плотность,
то, в принципе,
можно было бы сначала найти вот эту плотность,
а потом посчитать вот по определению.
Ну, как бы просто такая мораль.
А можно сразу вот такое выражение считать,
потому что они эквивалентны.
У вас просто лишняя компонента
сама по себе вы интегрируется,
ну, вот, по dx и все.
А здесь одна вторая.
Ну и ответ.
Кавариация
d в степени
x корней из y, y
равняется чему?
4 минус
2 корни из e
минус
1 вторая
умножить на вот это выражение.
2 корни из e
минус
Не, у нас y просто имеет
равномерное распределение, так ведь?
p и y это единичка.
Ну, ваш отрезок один.
Ну, а средняя
получается одна вторая.
Ну, в общем, ответ какой-то такой получился,
не нулевой. Соответственно, случайные
величины зависимы.
Тоже могли бы быть зависимы,
но это точно гарантируется.
Если у вас случайные величины не коррелированы,
это не значит, что они независимы.
Но если у вас случайные величины коррелированы,
то значит, они точно зависимы.
Ну, это какая-то база сервера.
И остались ли какие-то вопросы?
Ну, вот, соответственно, будет 4 задачки.
Это как бы Хабанов хочет, чтобы
было 4 задачки, ваши семинаристы могут
что-то поменять. Первая задачка будет
посчитать мотош от вот такой страшной функции
распределения. Вторая
это будет какая-то замена переменных, что-то
в интеграле Бега. Третья будет на многомерную
вероятность, то есть какие-то интегральщики
по каким-то фигурам посчитать.
И четвертая задачка будет какая-нибудь там кавариация,
что-нибудь такое. Примерно вот такой будет
на контрольный. Ну, и все тогда.
Пока.
