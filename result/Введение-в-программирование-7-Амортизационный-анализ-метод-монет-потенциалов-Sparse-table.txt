Так, сегодня у нас с вами седьмая встреча.
Начинаем, да.
Значит, мы, наверное, заканчиваем с кучами, мы, я напомню,
и двоичную, и биномиальную на лекциях.
Сегодня еще немножко посмотрим на примерах.
Вот там в семинаре была задача, если у вас уже было
про инсерт в биномиальную кучу, что если у вас нет
других операций, то инсерт в биномиальную работает
амортизировано за от и днице.
Вот сегодня мы поймем, что такое за амортизировано,
что это значит, да.
И в прошлый раз я тоже немножко про это говорил, строго
ведем определение, докажем, почему в биномиальной куче
инсерт амортизировано за от и днице работает, если
нет других операций.
Ну еще в конце, насколько останется времени, мы посмотрим
на спарстейбл.
Так, пока что мы начнем с амортизационного анализа.
Анализ.
Идея здесь следующая.
Допустим, мы реализуем какую-то структуру данных, скажем,
биномиальная куча, и она умеет обрабатывать какие-то
запросы.
Раньше у нас там были всякие декрески, инсерт, экстрактмин
и так далее.
Ну вот пусть есть, скажем, N типов запросов.
Нет, давайте не N, давайте Q типов запросов.
Q типов запросов к ней.
Первый тип запроса это сделать что-то с кучей, ну или с нашей
структурой.
Второй тоже что-то сделать и так далее, кутый запрос
тоже что-то сделать.
Пусть также нам заданы какие-то функции, вот для каждого
из этих запросов, для каждого, точнее, из типов запросов,
у нас есть какая-то своя функция.
T1 от N, T2 от N и так далее, TQ от N.
Да, мы будем говорить, определение, будем говорить, что ТИТ это
амортизированное или что-то же самое учетное.
Время обработки этого запроса, точнее, время обработки
запроса этого типа, если выполнять следующее условие.
Значит, смотрите, есть у меня вот эти вот Q функции,
которые как бы говорят, до сколько работает каждый
тип запрос.
Но на самом деле, каждый конкретный запуск запроса
возможно, будет работать дольше, чем вот эта заявленная
функция.
Вот здесь написано какое-нибудь декресски, если мы говорим,
что это амортизированно работать за от 1.
Ну, то есть, вот это вот T2 аут N, равно простоpiano, то
возможно, на каких-то конкретных запусках, на каких-то конкретных
обработках этого запроса, мы будем работать дольше,
чем от 1.
Но если мы все просуммируем, то можно считать, что суммарно
каждый из них обработан Crossing от 1.
Значит, это мы здесь сейчас строго сформируем.
Если для любого n и для любой последовательности из n запросов,
я напишу так, для любого q1, не так, qi1, qi2 и так далее qin,
запросы к структуре s, время обработки этих запросов есть o большое
от суммы времен вот этих вот учетных обработки всех запросов.
То есть сумма по i, давайте, по g от 1 до n, t, i, t, g, t от n.
Значит, вот такое громоздкое формальное определение.
Еще раз, какой здесь смысл? Есть у меня q типов запросов и какие-то учетные стоимости,
просто какие-то функции с ними связанные, t1 и так далее tq.
Тогда мы говорим, что это действительно амортизированное время обработки каждого запроса.
Если какую бы последовательность запросов мы не подали,
значит, здесь q это означает, что запрос, индекс это означает, какого он типа.
Скажем q1, q5, q7 и так далее, значит, вот какого типа запрос.
Вот один из этих q. Давайте подпишем, что и 1, и 2 и так далее.
Это типы запросов, то есть это числа от 1 до q.
Тогда суммарное время их обработки не больше, чем если мы просуммируем t с соответствующими индексами.
Пример. Пусть к нашей структуре поступают запросы q1, q3, q2, q1.
Тогда вот те t, которые я там написал, являются учетными амортизированными стоимостими,
если время работы есть o большое от t1 от 4, получается, раз у меня 4 запроса.
t1 от 4, t3 от 4, t2 от 4, t1 от 4.
Ну, тут уже поскольку у меня все константное, то лучше здесь писать не o большое, а какой-то констант.
Давайте напишу, что время работы не большим какая-то константом нужно эту сумму.
Можно еще сказать следующее.
Смотрите, вот это какие-то странные функции, которые, повторюсь, не обязательно равны настоящему времени работы на каждой такой террации.
Это на самом деле какое-то перераспределение времен работы по вот этим типам операций.
Например, есть у вас, как я сказал, здесь, например, второй тип запроса.
В принципе, там может быть такое, что он обрабатывается довольно долго, скажем, за линейное время.
Но, например, t2 от n у вас это константы единиц.
То есть, как бы, в среднем вы делаете за единицу, обычно вы делаете там одно-два действия,
но иногда бывают такие запросы, которые вам приходится обрабатывать за o от n, точнее, за ω от n за линейное время.
Тогда, как бы, вот вы это n, то есть если такие запросы редкие,
то вы можете как бы вот этот n так распихать либо по остальным запросам, либо по запросам того же типа,
что в сумме это n как бы учтется в остальных t-шках.
То есть вы как бы перераспределяете время тяжелых операций либо на остальные запросы,
либо на запросы того же типа, ну просто на другие запросы того же типа.
Скажем, если у вас вот здесь много единиц и мало n-ок, то это n вы можете как бы распихать по остальным единичкам,
единички станут двойками, и сумма там увеличится в два раза, что останется в терминах у большого, останется корректным.
Вот такое определение.
Так, тогда, да, у нас сейчас будет пример чуть позже, у нас будет пример про динамический массив или вектор.
Динамический массив, то, что в плюсах, это STD-вектор.
Значит, это такая структура данных, которая позволяет хранить массив,
который еще также умеет расширяться вправо или наоборот сокращаться вправо.
То есть у него есть операции push-back и pop-back, удалить последний элемент, добавить последний элемент.
Это мы еще чуть позже все напишем.
И оказывается, что амортизированное время работы всех этих операций, это от единицы.
Давайте я напишу вот так, вот со звездочкой это как раз значит, что оно амортизированное.
Амортизированное, амортизированное.
То есть какие-то конкретные операции push-back, pop-back, они могут работать довольно долго.
У нас там будут такие будут тяжелые операции push-back, pop-back, которые работают ω от n,
где n это текущая длина массива.
Но в среднем, если вы просуммируете все время работы алгоритма, у вас получится O от общего числа операций.
То есть как бы можно считать, хоть у вас и есть какие-то тяжелые операции, но можно считать, что каждый из них работает за единицу,
тогда сумма как раз будет, сумма вот этих вот единичек, будет верхней оценкой на время работы.
Вот, значит, потом на этом примере мы еще, ну то есть мы его чуть позже разберем,
пока я введу метод, как можно эти т-шки находить.
Потом на примере поймем, что вот там все единички подходят.
Так, значит, есть такой метод, называется метод монеток или метод бухучета, метод бухгалтерского учета.
Идея следующая, смотрите, мы уже поняли, что наша цель в каком-то смысле, вот чтобы получить эти т-шки,
нам нужно как-то перераспределить время, которое мы тратим на редкие тяжелые операции каждого типа,
ну вот скажем здесь, обычно как сделать pushback, ну просто там скажем, мы будем хранить массив побольше размера,
и чтобы сделать pushback, мы просто сюда положим очередное число.
Чтобы сделать popback, мы просто как бы про это число забудем и передвинем указатель на конец чуть-чуть влево.
То есть как бы обычно эти операции очень простые, просто хранить массив в два раза большего размера,
класть число в нужную позицию или там, ну просто про него забывать и сдвигать указатель на конец на один, то есть обычно это просто.
Но иногда нам придется, когда, например, все вот эти ящики заняты, нам придется выделить вот здесь вот себе еще много места,
чтобы положить сюда новое число, у нас будет такой алгоритм, что он выделяет себе столько нового места, сколько у него сейчас занят.
И вот эта операция будет тяжелая. То есть мы потратим столько времени, какая у нас сейчас длина массива.
То есть мы не за единицу работаем, а как бы за текущую длину.
Но в среднем, если мы вот эту вот тяжелую операцию, которая редкая, понятно, что нам редко приходится раздувать в два раза,
если мы эту операцию как бы распределим по другим операциям того же типа, то как бы получится, что в среднем мы делаем от 1 до 10.
А также и здесь. Мне нужно как бы перераспределить время, которое я трачу на тяжелой операции, по другим операциям.
Значит, вот как работает метод монеток. У нас есть какой-то банковский счет,
на который мы можем вносить деньги. Вносим и снимаем с него деньги. Вносим и снимаем деньги.
И смотрите, когда мне приходит какая-то простая операция, которую я могу быстро отработать,
которую я могу быстро обработать, я просто ее быстренько делаю и могу себе еще положить на банковский счет несколько монеток, несколько рублей.
Это значит, что я быстро обработал запрос, а еще на будущее как бы себе дал время, себе дал возможность с помощью этих монеток,
время, которое я затрачу в будущем на какую-то тяжелую операцию, его как бы занять из текущего времени.
То есть я сейчас говорю, ага, вот сейчас мне очень хорошо ел простой запрос, я отдыхаю, и давайте вот это время, которое я как бы экономлю,
я его учту себе, вот внесу денюжки, которые я сейчас экономлю, на банковский счет.
А потом, когда придет тяжелая операция, я на нее отвечу с помощью тех монеток, с помощью того времени, которое я накопил до этого.
То есть были простые запросы легкие, они вносили какие-то монетки, и теперь я эти монетки буду снимать со счета, и за их счет буду отвечать на тяжелый запрос.
Вот такая примерная идея.
Ну давайте скажем следующее, как он работает.
Пусть поступают запросы, давайте я напишу просто индексы q1, q2 и так далее, qn,
и мы знаем реальное время обработки каждого из них.
Реальное время обработки.
Это t1, t2 и так далее, tn.
И как бы в среднем, если у нас есть запрос какого-то одного типа, и мы знаем, что в среднем это простой запрос,
но иногда встречаются такие выбросы, что они t и t, какое-то очень большое одно,
и если его вот так распределить по остальным, то в среднем будет маленькое число, ну или там сумма небольшая.
Тогда давайте скажем следующее.
Пусть во время обработки этого запроса мы кладем в банк сколько-то монеток и снимаем с банковского счета тоже сколько-то монеток.
Кладем на счет DIT монет, DIT от слова депозит, а также снимаем сколько-то монет.
WIT, WIT тоже от слова снять, снять деньги со счета.
Тогда я утверждаю, что вот такая величина равная реальному времени плюс числу внесенных монеток, минус числа снятых монеток,
такая величина и будет являться учетной стоимостью WIT-го запроса.
Учетная, то есть амортизированная стоимость WIT-го запроса.
И это как раз отражает ту интуицию, которую я в начале пытался сформировать.
Что такое WIT-го запрос? Сначала вы как-то на него отвечаете за какое-то реальное время WIT-го.
Вам нужно сделать реально WIT-го действия.
Затем, если у вас этот запрос простой и, скажем, WIT-го маленькое, то вы можете еще какое-то время фиктивно поработать,
при этом положив в банк WIT монет, и считаем, что эти монетки, которые я себе на будущее кладу, мы их учитываем в текущем амортизированном времени, плюс WIT.
А если, наоборот, WIT слишком большое, то я пытаюсь, наоборот, из банка взять много денег WIT, так чтобы эта разность была поменьше.
То есть я как бы занимаю у себя прошлого время, то есть я когда-то его отложил, теперь я его забираю.
И если TIT примерно такой же, как WIT, то вот это будет от 1, например.
То есть чем больше WIT, тем больше я уменьшаю себе учетное время работы.
Так, ну давайте я напишу это утверждение строго.
Пусть на нашем счету, на банковском счету число монет всегда не отрицательно.
Число монет всегда не отрицательно. То есть мы никогда не берем в кредит.
Тогда AIT – это вот те самые настоящие учетные стоимости, учетные стоимости.
То есть что значит, что это учетные стоимости? Давайте вспоминать определение учетной амортизированной сложности каждой операции.
Это значит, что если я вместо реальных времен работы, вот этих вот T-шек, сложу Ашки, сложу учетные стоимости вместо реальных, то получу верхнюю оценку на реальное время работы.
То есть сумма T-итых есть O-большое от суммы A-итых.
Вот такое у меня было определение, что реальное время работы есть O-большое от учетных стоимости работы.
То есть как бы реальное время работы оценивается сверху тем, как если бы я вместо настоящих времен работы учитывал вот это вот учетное A.
Получается, что на самом деле реальное время работы каждой конкретно мне не интересно, мне достаточно знать только учетное.
И если я учетные сложу, то получу верхнюю оценку на время работы.
Ну доказательств элементарно.
Что такое сумма A-итых? Давайте посчитаем.
Это сумма T-итых плюс сумма D-итых минус сумма W-итых.
То есть сколько я реально отработал, плюс сколько монеток я положил в банк, минус сколько я снял.
Ну вот эта штука не отрицательна по предположению.
Мы всегда кладем не меньше, чем снимаем.
Поэтому суммарно мы положили больше броно, чем суммарно мы сняли.
Значит эта штука не отрицательна.
В итоге мы получаем, что чтобы получить сумму A-итых, мне нужно к сумме T-шек добавить что-то положительное.
Ну не отрицательно.
Значит сумма T-итых не больше, чем сумма A-итых.
Потому что тут написано сумма A-шек.
Здесь сумма T-шек плюс что-то не отрицательно.
Значит такое неравенство автоматически следует.
Ну собственно мы доказали то, что нужно.
Мы доказали, что реальное время работы всей нашей программы, то есть без всяких вот этих монеток странных, реальное время обработки запросов,
оценивается сверху суммой учетных стоимости.
Понятная идея?
Ну здесь простое замечание, что на самом деле мне достаточно хранить не то, что условия,
достаточно не то, чтобы всегда было не отрицательное число монет,
а только чтобы в самом конце.
Потому что здесь мне нужно, чтобы сумма положенных минус сумма снятых больше на нуля.
То есть в принципе где-то по дороге можно было занимать в кредит, это не страшно.
Но главное, чтобы в конце было не отрицательно.
На самом деле число монет может быть не отрицательным где-то по дороге,
может быть отрицательным, может быть отрицательным в середине процесса.
Главное, чтобы в конце была не отрицательная сумма.
Главное, чтобы в конце было больше на нуля.
Ну потому что если мы заменим вот это условие про не отрицательность всегда на не отрицательность только в самом конце,
у меня вот это рассуждение останется, потому что мне нужно только чтобы эта штука была не отрицательной.
Так, ну хорошо, вот определили такой метод монеток.
Давайте мы его сейчас применим для задачи о динамическом массиве.
То, что реализовано в плюсах через интерфейс STD Vector.
Значит, что мы хотим от STD Vector?
Мы хотим по сути хранить обычный массив, то есть с доступом по индексу,
так чтобы вот если вы мне даете И, я могу за от 1 вам сообщить АИТ, какой элемент у меня находится в этой позиции.
Но при этом он умеет расширяться направо и наоборот сужаться справа.
То есть мне нужна такая структура данных, которая умеет отвечать на оператор квадратной скобки,
то есть по индексу сообщать элемент, по И сообщить АИТ.
Ну и дальше вот эти два запроса pushback x, это добавить в конец нашего списка x, добавить x справа.
И popback это удалить элемент справа, удалить, ну я напишу так, удалить самый правый элемент.
То есть по сути это то, что у нас было в самом начале, то, что у нас было в стеке,
добавить в конец и удалить с конца, только появляется новый оператор квадратной скобки,
который позволяет смотреть в данное конкретное место стека.
Напомню, как у нас был стек.
Стек у нас был реализован однозвязанным списком просто, вот такая штука.
И мы конечно же умеем в стеке делать pushback, то есть добавлять элемент справа,
и наоборот popback.
Для этого нам нужно просто удалить этот элемент и сказать, что теперь последним является вот этот.
То есть в обычном стеке pushback и popback работали за вот единицу,
но мы не умели эффективно отвечать на запрос квадратной скобки.
Потому что если я вас попрошу найти там десятый элемент,
то лучшее, что вы можете сделать, это пройти с начала вашего массива или с конца в поисках элемента с индексом 10.
Потому что они как угодно у вас стоят в памяти, это совсем необязательно,
и чтобы получить данное конкретное число, вам нужно пройтись по всем этим стрелочкам.
Мы никак не можем понять по индексу, где он конкретно лежит.
Нам придется вот так целиком пройти весь список.
Давайте это запишем, что в стеке мы умеем обрабатывать последние две операции за вот единицу,
но не умеем квадратные скобки.
Эффективно, по крайней мере, не умеем.
Умеем обрабатывать квадратные скобки.
Эффективно, по крайней мере, не умеем.
Умеем обрабатывать pushback и popback
за от единицы. За честное от единицы не амортизировано, а настоящее,
потому что мне нужно создать новый элемент, переназначить стрелку, переназначить ссылку на хвост.
Это все действия, которые всегда от единиц времени занимают.
Но при этом запрос квадратной скобки у меня может быть очень долгий.
Может выполняться ω от n, потому что если у меня есть стек размера n
и мне нужно, скажем, какой-нибудь n пополам t-элемент, центральный элемент,
то мне либо сначала нужно пройти n пополам стрелочек, либо с конца пройти n пополам стрелочек.
Никак по-другому не получится, ну по крайней мере, вот в нашей наивной реализации.
Поэтому в худшем случае у вас квадратные скобки работают за ωt.
А вектор позволяет вам делать все за от единицы. Здесь будет чистое от единицы,
а здесь будет учетное, то есть амортизированное. Я буду писать со звездочкой, значит оно амортизированное.
Это то, что умеет вектор.
То есть ведет себя как стек, только эти штуки становятся амортизированными,
то есть каждая конкретная может работать долго, но в среднем суммарно как будто бы за единицу.
Плюс еще квадратные скобки за чистое от единицы.
Так, ну вот следующим образом можно это реализовать.
Давайте мы будем хранить просто некий массив длины c.
И в нем будет заполнено несколько первых элементов.
То есть несколько первых его элементов – это содержимое нашего вектора,
а все остальное справа – это как бы пустое место, которое у меня лежит в резерве.
То есть вот это вот s – это число настоящих элементов, число элементов,
число элементов, а все остальное – это как бы свободное резервное место.
То есть посмотрите, я просто как бы храню массив, у которого справа есть какое-то свободное место.
Ну и понятно, что обычно у меня pushback и popback очень простые.
Мне нужно просто, если приходит pushback, мне нужно вот в эту вот ячейку массива написать x.
Да, если у меня достаточно много памяти выделено справа,
я смотрю на эту первую свободную ячейку, туда записываю нужное число.
Ничего сложного. Ну и там учитывая, что s увеличится на единичку.
То есть число активных элементов выросло.
Если наоборот нужно сделать popback, вот было у меня s элементов, и мне нужно сделать popback,
ну давайте тогда я просто s уменьшу на единичку и буду считать, что у меня массив теперь вот здесь заканчивается.
То есть тут что-то лежит, бог с ним, но давайте просто как бы считаем, что там ничего нет.
И что эта память на самом деле просто резервная, куда мы можем добавлять новые элементы.
Просто сузили размер на единичку, ничего не поменялось.
Вот, такая отличная реализация.
Понятно, что квадратные скобки тоже можно зовут единицы,
потому что массив умеет обрабатывать квадратные скобки, зовут единицы.
Но как минимум проблема такая, что если мы много раз делаем себе pushback
и целиком заполним всю выделенную исходную память,
то мне уже будет некуда добавлять вот этот элемент направо.
То есть если я целиком исчерпал всю выделенную себе память заранее,
мне будет некуда, может быть, некуда добавлять новое число.
Ну не беда.
Давайте тогда мы просто попросим у системы себе выделить еще такой же длинный блок памяти.
То есть вот напишу следующее, что если у меня приходит pushback,
в случае s равно c, то есть если вся резервная память исчерпана,
и у меня больше нет места.
Тогда наш алгоритм будет делать следующее.
Он попросит у системы новый кусок непрерывной памяти размера 2c,
запрашиваем у системы массив длины 2c,
ну то есть там что-то типа new вызываем или что-то такое, там какой-то молок.
В общем как-нибудь просим у системы дать нам 2c элементов.
Затем просто вот эти вот c элементы перекопируем туда, вот в этот наш новый массив.
Ну и получается, что у нас есть длинный массив уже в два раза большего размера,
в котором занято только половина элементов.
Да, я завел новый массив размера 2c, старый массив сюда перекопировал,
и теперь у меня опять идеальная ситуация, когда у меня очень много свободного места справа.
Понятно? То есть просто перекопировал свободное место.
И здесь еще нужно не забыть, что вот эту старую память нужно отдать системе, нужно вернуть системе.
То есть давайте я напишу так. Вернуть старый массив системе.
Старый массив системе.
То есть вызвать delete или в общем free как-нибудь дать системе понять, что эта память нам больше не нужна,
мы ее обратно возвращаем, чтобы она и пользовалась.
Нам в программе она не нужна, чтобы у нас не текла память.
Мне нужна ту память, которую нам исходно выделили, вернуть потом в конце системе, если мы ей больше не пользуемся.
То есть мы скопировали все, понимаем, что нам это не нужно, а даем ее обратно системе.
Через free или что-то такое.
Ну и опять у нас хорошая ситуация, у нас очень много свободных элементов справа.
Мы можем сюда при следующих пушбеках просто по одному эти элементы записывать, сдвигая s на единичку вправо.
И опять следующая такая тяжелая операция, когда нужно будет вызывать перекопирование, будет только через c действий.
Только когда я целиком все это заполню, может мне понадобится расширить этот массив еще в два раза.
И вот как раз та интуиция, это будет происходить довольно редко, вот это расширение в два раза.
И получается, что время на это перекопирование можно как бы перераспределить по запросам других типов или просто по более простым запросам.
То есть это мы еще сейчас все докажем, пока давайте до конца алгоритма пишем.
Так, мы описали как работает пушбек, если у нас есть свободное место, пишем туда элемент.
Если нет, то выделяем массив в два раза большей памяти и перекопируем туда то, что было.
Теперь как работает попбек.
Ну можно сказать, что в такой наивной реализации, давайте просто уменьшим s на единичку, считать, что массив сжался на 1 справа и больше ничего не сделаем.
То есть такая простая реализация, это минус, минус s и все.
В принципе так можно делать, но здесь вот если мы хотим написать настоящий вектор, который удовлетает всем тем интуитивным ожиданием от него, то это не очень хорошо в следующем плане.
Смотрите, например, у вас такая цепочка запросов. Пушбек, пушбек, пушбек, куча пушбеков, а потом куча попбеков.
Тогда в самом конце, ну или там на одной из последних итераций, давайте я нарисую.
Сначала мы сделали много пушбеков, завели какой-то огромный массив, потом потихоньку удаляем эти элементы, стираем, стираем, стираем, стираем.
Тогда вот здесь ближе к концу у вас по сути эффективная память находится где-то вот здесь, то есть элементы, которые вам интересны, находятся вот здесь, а выделено у вас гораздо больше памяти.
То есть вы как бы у системы забрали огромный кусок памяти, чтобы хранить совсем немножко там чисел.
Скажем, вот здесь 10 чисел, а это длина там тысячи.
Ну, так можно сделать, но понятно, что мы такого хотим избегать.
Мы не хотим, чтобы у нас хранилось, то есть мы не хотим у системы забирать сильно больше ресурсов, чем нам нужно для хранения.
Сейчас я напишу и поймем, что такого не будет возникать.
Так вот, значит, чтобы такого не было, чтобы у нас не было очень много свободной памяти, мы поступим следующим образом.
Ну, сначала, конечно, мы делаем минус-минус s, просто удаляя один элемент, и затем, если s стало меньше либо равно, чем 1 четверть c, то мы сократим c в два раза, то уменьшим c в два раза.
Меньшим c в двое.
То есть я вот так удаляю, удаляю, удаляю, и если у меня эффективная память меньше либо равно, чем четверть от сей выделенной, то вот эта используется, а эта сколько мне выделена?
И если это c хотя бы в четыре раза больше, чем s, то я половину этих элементов удалю.
И вот, отвечая на ваш вопрос, здесь константа не 2, а 4.
То есть только когда мы в четыре раза аж меньше, чем c, только тогда мы сокращаем в два раза.
Ну, чтобы уменьшить c в двое, можно, скажем, посмотреть на вот этот индекс и запустить от него free, то есть как бы отдать вот эту вот память системе.
Ну, либо, если нам так не хочется, можно просто завести, то есть попросить у системы блок размера c пополам, блок непрерывной памяти размера c пополам, перекопировать вот эти элементы сюда, а это все удалить.
Это все отдать обратно системе. Ну, это уже не важно.
Главное, что не допустить утечек памяти, то есть нельзя не удалить этот указатель, его обязательно нужно вернуть системе.
Если вы делаете такое перекопирование, то вам нужно это обязательно удалить.
Ну вот, то есть, ну и да, вот, например, отвечая на этот запрос, представим, что у нас было много там пушбеков.
Сделали, делали, делали пушбек, потом попробовали сделать еще один пушбек, в результате которого нам пришлось расширить в два раза наш массив.
Расширить в два раза наш массив.
И нам приходит, скажем, теперь попбек, мы удаляем вот этот только что добавленный элемент.
Тогда, чтобы нам сократить обратно в два раза наш массив, мне нужно не просто один раз сделать попбек, а удалить все вот эти вот элементы.
То есть всю вот эту правую половинку исходного массива придется удалить.
И только если я их все удалю, я вот эту память себе освобождаю, отдаю обратно системе, и тем самым сокращаю в два раза резерв.
Да, у меня теперь вот это у системы, а вот эти вот ячейки свободные, куда я могу добавлять элементы.
Вот такой алгоритм.
Значит, ну понятно, что здесь есть тяжелые операции, которые вот такие перекопирования.
В попбеке есть тяжелые попбеки, когда нужно в какую-то новую память перекопировать ТС элементов.
И то же самое есть в пушбеке, когда нужно в два раза расширить текущую область.
Но оказывается, что суммарно можно считать, что каждый из них работает за от 1.
И вот это вот то самое амортизованная оценка.
Если мы сложим настоящее время работы, то оно будет не больше, чем если бы мы считали, что каждая операция работает в 1.
Значит, теперь давайте докажем, что учетное время работы.
Учетное время работы всех операций.
Есть ОТ.
Напомню, звездочка, значит, как раз время речи идет об амортизированной асимптотике.
Так, ну хорошо.
Давайте скажем следующее.
Давайте скажем, что у меня есть как бы легкие и тяжелые пушбеки.
Легкие и тяжелые.
И то же самое с попбеками.
Есть легкие, есть тяжелые.
В том самом смысле, как я говорил, да, легкие это просто там положить число в конец, не нужно ничего перекопировать, то есть у меня есть достаточно памяти, чтобы это сделать.
Тяжелое, наоборот, у меня вся память заполнена, мне нужно выделить новую, то есть тяжелое, когда происходит перекопирование, выделение новой памяти и так далее и так далее.
Так вот, давайте тогда сделаем следующее.
Каждый раз, когда мне приходит пушбек, который легкий, скажем, и он кладет х на позицию И, то есть х кладется в АИТ, ну я вот так напишу, то есть в ИТ-ю ячейку нашего массива.
Мы вместе с этим, то есть поскольку это легкая операция, мы интуитивно хотим класть в банк себе деньги, то есть мы понимаем, что нам сейчас легко.
Значит, мы можем как бы поднабрать жирка, подэкономить денег, положить их себе в банк, так чтобы потратить в будущем эти деньги.
Так вот, давайте положим по монетке, положим по монетке на элементы АИ и А с индексом И минус С пополам, А с индексом и минус С пополам.
То есть я кладу, вот возвращаясь к этой картинке, если я вот сюда добавляю новое число, то я добавляю монетку сюда и вот сюда, отступаю на С пополам, кладу вот сюда.
Нет, сейчас, здесь С пополам будет видимо вот это вот, поэтому кладу вот сюда.
Значит, в тяжелом пушбеке мы не будем класть никакие монетки, в легком попбеке мы тоже кладем, пусть какой-нибудь Y удаляется с позиции АИ,
мы тогда положим монетку на АИТ и АИ минус С на 4.
Кажется так.
Давайте на примере, вот рассмотрим пушбек. Давайте рассмотрим пушбек первые легкие в своей цепочке.
То есть когда-то мы что-то делали, скажем, и потом целиком заполнили вот этот вот блок, который у нас был выделен, потом выделили новый блок того же размера и сюда положили новое число.
И вот этот вот как бы пушбек, когда мы кладем новое число, мы положим монетку вот сюда и монетку в позицию на С пополам меньше.
Если вот это вот все С, то Ц пополам как раз половинка, получается монетка положится сюда.
Затем я опять делаю пушбек, добавится такое число, положится монетка на него и на вот этот вот соответствующий ему в левой половинке.
И так далее, чтобы дойти до этого, до конца нашего массива и чтобы опять потребовалось выделить какую-то память, у меня будет класса монетка на каждый добавленный элемент, а также на соответствующий ему в левой половинке.
И получается, что когда я дойду до конца и мне потребуется завести новую память, выделить себе новую память и все перекопировать, у меня монеток будет столько, сколько нужно.
То есть на каждом элементе лежит по монетке, и я вот этими монетками как бы расплачиваю за те операции, которые мне сейчас нужно сделать.
Расплачиваю за выделение еще большей памяти, за перекопирование и за освобождение вот этой памяти. Я расплачиваюсь вот этими монетками.
То есть их количество как раз равно длине этого массива, их ровно С.
Ну а все операции вот эти вот работают как раз, ну можно считать, что за С действий.
Ну за О, С формально говоря, потому что мне нужно выделить массив размера 2С, перекопировать и еще вот это все освободить.
Ну в общем, грубо говоря, можно считать, что число монеток как раз равно количеству действий, которые мы сейчас делаем с точностью до коэффициента.
Но чтобы про этот коэффициент не думать, можно говорить, что мы кладем не по одной монетке, а по пять монеток, и тогда как раз число монеток нам хватает на то, чтобы сделать все действия. Понятно?
Вот нам монеток хватит, чтобы сделать все действия. То есть каждое действие сопровождается снятием, удалением какой-то монетки из банка.
Ну и как раз получается, что у нас как бы время работы, вот это учетное, вспоминаем, что это реальное время работы.
Реальное. Плюс сколько положили. Депозит. Минус сколько сняли.
Не буду считать этого слова. Минус сколько сняли.
И как раз, если у меня каждое действие, то есть там, ну, выделение массива, перекопирование, если каждое действие сопровождается снятием монетки, то у меня оно, по сути, Т будет равно W и AD вообще нулю.
То есть по сути учетная стоимость будет просто нулевая. Как будто бы мы вообще прям за ноль действия это сделали.
Хотя на самом деле здесь конечно очень много всяких действий. Вот это вот перекопирование, выделение и так далее.
Но как бы за это мы расплатились на прошлых итерациях, когда клали монетки на элементы. Понятно?
Вот. Ну то же самое происходит с поп-беком. Давайте поп-бек нарисуем. Вот был у меня какой-то массив такого размера.
Так.
Был у меня массив какого-то такого размера. И давайте посмотрим на два соседние тяжелые поп-бека. То есть вот когда-то мы длину этого массива уменьшили вдвое.
Когда у меня тяжело вот этих вот задействованных, в четыре раза было меньше, чем весь массив. То есть весь массив был когда-то вот такой.
Я удалил там очередной элемент. Их активных стало в четыре раза меньше.
И я соответственно вот эту память себе освободил.
Теперь смотрим, когда придет следующий поп-бек.
Для следующего поп-бека я должен удалить вот половину этих элементов.
Чтобы пришел следующий, в смысле тяжелый поп-бек, мне нужно, чтобы у меня активных стало в четыре раза меньше, чем вот этот размер. Чем вот это вот С.
Ну то есть как раз половину вот этих я должен удалить.
Ну тогда смотрите. Как это будет работать?
Для этого у меня сначала должно быть вот столько легких поп-беков. Я должен удалить все вот эти элементы.
Но каждое такое действие кладет по монетке...
Ну вот как раз вот сюда, удаление этого положит по монетке монетку вот сюда, удаление вот этого положит монетку сюда, удаление вот этого положит здесь...
И так далее.
сюда, удаление вот этого, положить монетку сюда и так далее. Как раз потому что
минус c на 4, то есть я как раз сдвигаюсь на четверть c и вот кладу монетку в
соответствующий элемент на c на 4 позиции влево. То есть на самом деле здесь даже
можно не класть монетку на а и т. Вот это можно взять скобки, это не обязательно.
То есть я буду класть монетки на те элементы, которые соответствуют удаленным,
которые левее их на c на 4. Ну и тогда чтобы попасть в следующий тяжелый
поп-бэк, я должен сначала их все удалить, то есть положить по монетке на все вот
эти элементы. Ну значит у меня будет опять достаточно денег, чтобы запуститься
нашей нашей сложной вот этой операцией, выделить себе новую память, все
перекопировать, освободить старую. Потому что как раз здесь монеток, их там c на 4
и их достаточно, чтобы сделать все тяжелые действия. Опять там тоже будет
реальное время работы равно числу снятых монеток, а депозит у нас будет нулевой.
Понятно? Да.
Какой ты константу?
Нет-нет, мы с самого начала, это зависит от реализации, это не особо важно, можно
считать, что с самого начала c равно 16, например. То есть изначально
выделяем память под 16 элементов, а s равно нулю. Вот и тогда, например, когда мы
там дойдем и целиком заполним все эти 16 элементов, мы сначала раздуемся до
32. Когда мы будем вызывать поп-бэк, ну давайте считать, что у меня размер никогда не
будет меньше, чем 16. То есть, да.
Да, ну то есть тут просто вопрос про то, что мы делаем для маленьких размеров, но
понятно, что если у меня там один элемент, то лучше не хранить массив длины один и
потом расширять его до двух. Ну там хоть какое-то содержательное количество
элементов нужно хранить, ну там 10, 16, что-то такое обычно кладут. Ну а раз у меня
все равно всегда у меня там удвоение или деление пополам, то лучше какой-нибудь
степень двойки взять, чтобы все хорошо делилось. Да. Что?
Потому что просто все сходится, можно другие константы подбирать, ну типа
наверное можно в три раза увеличивать и там уменьшать тоже, не знаю, в шесть,
сейчас, ну то есть в полтора раза что-то такое. Наверняка, наверняка можно и по-другому.
Ой, я не знаю, я не знаю, можно поработать, подумать, но здесь непонятно, что какое оптимальное.
То есть непонятно, как определить оптимальную константу, во сколько раз надо раздувать,
то есть чтобы, ну мне непонятно, да, как определить оптимальность, вроде так все сходится.
Вот, последнее еще что я здесь скажу, то есть я здесь рассматривал, вот здесь вот я рассматривал
действия между двумя последователями тяжелыми пушбеками, а здесь между двумя последователями
попбеками тяжелыми, но может быть такое, что у меня сначала идет тяжелый пушбек, потом тяжелый
попбек, но тогда тоже самое, что значит, что у меня пришел тяжелый пушбек? Это значит,
что у меня была заклонена половинка, и я заполняю еще один, потом что-то происходит, какие-то пуши,
какие-то попбеки, и следующая операция – это тяжелый попбек, тогда это значит, что вот столько
элементов будет активных, вот эти активные, эти все удалились, значит опять вот все эти элементы
должны были удалиться как минимум. То есть, возможно еще были какие-то пушбеки, кладущие
монетки вот сюда, но также обязательно вот эти элементы должны были удалиться и
каждый из них кладет по монетке вот сюда.
Значит, то же самое, на монетах всегда хватит на то чтобы сделать
тяжелые действия. Итак, давайте посчитаем вот этими ашками,
давайте посчитаем, что делает легкий пушбэк. В легком пушбэке сколько нам
нужно действий? Одно действие, чтобы просто присвоить одно значение, ну и там
увеличить s, не знаю, давайте напишем 2, потому что нам нужно сделать аs-то
равно x и плюс плюс s. Это такой легкий пушбэк, когда мы просто кладем число и
сдвигаем указатель направо. Монеток мы кладем в этот момент тоже две, тоже две,
ничего не снимаем. Вот, тогда учетное время работы, блин, тут коллизия, чтобы вот
это а и вот это а, давайте я так напишу, учетное a и t равно 4 получается, да? t плюс d
минус w это 4. Что такое тяжелый? Тяжелый пушбэк. Тяжелый пушбэк.
Ну, мы поняли, что data это ноль, мы никаких монеток не кладем. Сколько мы снимаем?
Так, мы снимаем монеток столько, сколько было элементов, потому что на каждом
элементе обязательно есть по монетке. Мы снимаем c монеток. Ну и время работы,
давайте я здесь напишу просто c, имея в виду, что, ну вот, вот то, что я здесь
говорил, чтобы создать элемент, создать массив два раза большего размера и
перекопировать туда эти элементы и удалить вот это, нам как бы достаточно, ну не то,
что c операции, но o от c, не знаю, там 5 c операции, ну тогда вот здесь нужно было
класть не по одной монетке, а по пять монеток, тогда бы как раз, ну не знаю, если
вот здесь вот 10, тогда здесь у меня будет 10, ну и там чуть больше надо было
класть, там нужно было класть по пять монеток на каждую. Но чтобы не возиться с этой
константой, давайте считать, что у меня время работы здесь просто c и снимаю я
тогда просто c, и получается учетное время будет 0 вообще. Учетное a и t равно
нулю. Ну и получается, что все это от единицы, и это тоже от единицы, и то же
самое с поп-бэками, значит, легкий поп-бэк,
легкий поп-бэк, он делает просто одну операцию, уменьшение s, да, минус-минус s,
кладет при этом, кажется, одну монетку мы договорились, и снимает 0, снимает 0,
тогда a и t равно 2, что равно от единицы, вот, ну а тяжелый pushback по времени ведет
себя, ну как бы по t-шкам, d-шкам, w-шкам, ведет себя также как тяжелый pushback, он
снимает сколько-то монеток, за то же время выполняет все вот эти вот
перекопирования, и не кладет ни одной монетки, поэтому там учетное время тоже
будет нулем, что тоже равно от единицы, вот. Получается, что учетное время всех,
всех этих операций это от единицы, значит, можно как бы считать, что каждый
из них работает за одно действие, или там за c действий. Получается, что если у
меня поступает q запросов к нашему вектору, если всего q запросов, то они
суммарно обрабатываются за от q, они суммарно обрабатываются за от q, да,
потому что если я просуммирую вот эти вот оценочки, все ашечки, то у меня
получится как раз, ну там q умножен на какую-то константу, на не больше чем четыре,
поэтому суммарное время работы это от q, понятно? Да.
Ну смотрите, а это вот здесь я показывал, что перед тем как приходит тяжелый
pushback, например, я обязательно кладу по одной монетке на каждое из вот этих вот,
то есть у меня всегда монеток хватает на то, чтобы сделать все действия, да, вот здесь я не
беру монетки из воздуха, я беру монетки с, ну в общем они у меня лежат на элементах, то есть я
их уже себе когда-то дал в прошлом и теперь их использую просто, трачу на выполнение действий.
У меня монеток всегда нетрицательное количество, но я объяснил, да, формально не писали, но я
вот здесь показывал, что монеток всегда хватает на выполнение всех действий, да, это важно
подчеркнуть, но вот здесь на рисуночке я показывал. Так, ура, значит с Vector мы справились,
он работает от единицы амортизированной на pushback и popback. Хорошо.
Так, одну секунду.
Теперь давайте рассмотрим задачу. Инсерт в биномиальной куче. Ну скажем так, в отсутствие других
операций, в отсутствие других операций. Что это значит? Вот в прошлый раз мы разбирали биномиальную
кучу, которую мы показали, что инсерт работает за от логарифма, да, потому что если у меня есть
какая-то корректная биномиальная куча, я добавляю, создаю новую кучу, в которой есть только одно
дерево из одного элемента и потом запускаю мерч от этих куч, которые работают за логарифмическое
время. Вот, но если считать, что других операций пока что нету, то есть у нас запросы такие,
сначала куча инсертов, скажем n инсертов, а потом какие-то другие, там экстрактмины, декризы,
новые инсерты и так далее, тогда можно считать, что вот эти вот первые n инсертов работают каждый
за амортизированную единицу, от единицы каждой. Вот это было в профессиональском листочке, то есть
как бы суммарно вот эти вот, если вы знаете, что у вас среди запросов первые n это инсерты,
вы изначально пустую кучу, то суммарно они отрабатывают за от n, то есть каждый за от
единицы амортизировано, то есть суммарно от n. Так, ну давайте это поймем. Значит, на самом деле
здесь все довольно просто, потому что мы показывали, что биноменальная куча, по сути,
это представляет количество элементов n в виде разложения по степеням двойки. Это мы просто
пишем двоичную запись, и те единички, которые там участвуют, соответствуют деревьям, которые
присутствуют в куче. Так вот, пусть у меня есть сколько-то элементов в куче, и это количество
представляется какой-то какой-то строкой из 0 единиц. Не знаю, что-нибудь такое напишу. Здесь
что-то такое. Это младшие биты, это старшие. Текущее число элементов это k. Тогда, если приходит
какой-то новый элемент, инсерт какой-то x, я создаю кучу на одном элементе x, а дальше запускаю
мёрч. И этот мёрч работает на самом деле за количество единичек вот здесь вот. Потому что как
у меня работает мёрч? Я сначала склеиваю вот эти два дерева, вот это дерево ранга 0 и это дерево
ранга 0, объединяю их в одно дерево ранга 1. Потом оно объединяется вот с этим, результат объединяется
вот с этим, результат с этим, результат с этим, и в итоге все, что мы объединили, получается одно
дерево вот этого порядка, а здесь все зануляется. Так работает просто сложение двоичных чисел. Я
иду справа налево, храню этот перенос, и когда встречаю первый нолик, туда ставлю результат.
То есть на самом деле время работы каждой конкретной операции равно, давайте так и напишем,
время обработки катового запроса равно
количеству единиц в двоичной записи, в конце двоичной записи k, в конце двоичной записи k.
То есть я записал k в двоичной системе числения, иду справа налево, считаю сколько у меня единичек,
идут перед первым нулем, и вот сколько у меня в конце единичек, за столько мы и работаем.
Ну и теперь давайте поймем, что на самом деле это амортизированная единичка.
Давайте поймем, что это амортизированная единичка. Например, можно сделать следующим образом,
можно сделать так, давайте мы будем себе гарантировать, будем поддерживать такое,
что на каждой единице в двоичной записи текущего числа и лежит по монетке,
на каждой единице в k лежит по монетке. Давайте еще раз нарисую, вот есть там какой-то префикс,
потом нолик и куча единиц, и на каждой из единичек лежит монетка. Давайте я вот закрашиваю,
чтобы не путать с нулем. Вот есть такие монетки. И теперь смотрите, приходит операция insert,
я добавляю как бы новый элемент, вот они так склеиваются за количество этих единиц,
и в конце у меня получается, что размер вот такой, префикс остается, здесь единица, а здесь куча нулей.
Ну и как раз получается то, что нужно. Время работы вот этого insert, склейки всех этих деревьев,
оно как раз равно числу снятых монеток. Вот если тут у меня в конце было 6 монеток,
то мне нужно сделать 6 объединений деревьев, ровно то, что нужно, и результат положить в
отдельную ячейку. Тогда давайте говорить следующее, что вот если у меня, я понимаю,
что время работы вот этого, время обработки, это количество единиц в конце, количество единиц
в конце, единиц в конце. Ну и это же тоже самое, что WIT, потому что я снимаю по монетке с каждой единицей,
я гарантирую себе, что на каждой единице есть монетка, я ее снимаю из банка, и поэтому число,
реальное время работы равно числу снятых монеток. Ну еще потом в конце кладу одну монетку на ту самую
единицу, которая получилась в конце. То есть я сначала много монеток снимаю, объединяю деревья,
потом на последнюю единицу кладу новую монетку. Получается у меня учетная стоимость такая,
T плюс D минус W, то есть точность единицы. Вот эти сократились и осталась одна новая
монетка, которую я положил на единичку. Значит, учетная стоимость всех операций это единица.
Да, что мы и хотели. Вот как я в начале анонсировал, что каждый из инсертов работает амортизировано
за единицу. Еще раз, каждый конкретный может работать, в принципе, и логарифом. То есть если
у вас K это куча единиц в конце вот здесь, то это работает за логарифом. Чтобы все вот эти единички
склеить и получить одно большего дерева, нужно по ним по всем пройтись и там проставить вот эти
вот ссылочки, что один это предок другого. То есть в принципе каждая конкретная операция может
работать за логарифом. Но суммарно, если вы будете считать, что каждый работает за единицу, у вас
получится корректная оценка сверху на время работы. Будет корректная ООТН. Понятно? Вот,
ну и так работает всегда вот этот вот амортизационный анализ. Каждый конкретный может
работать долго, но если правильно перераспределить время, то как будто бы каждый работает вот столько,
сколько заявлено. И сумма всегда оценивается сверху суммой вот этих вот ООТ1 или в другом случае
других функций. Да, ну можно модифицировать так, что будет не амортизирована единица, а чистая
единица. Но это отдельное упражнение, которое мы на лекции не рассматриваем. Так, ну вот сделали.
Отлично. Теперь давайте еще последний метод. Называется метод потенциалов. Это метод,
альтернативный методу бухучета, методу монеток, который тоже самое позволяет делать, как-то
получать амортизационные оценки на время работы. И так, значит, вспоминаем, пусть С структура данных,
структура данных, и пусть Ф какая-то функция от ее состояния, пусть Ф большое от С,
это какая-то функция состояния структуры. Ну то есть не знаю, если у нас С это массив какой-нибудь,
то, например, феатес может быть размер массива или там длина двоичной записи чего-нибудь. В общем,
какое-то такое свойство, которое отражает какой-то параметр нашей структуры. Пусть опять поступает
Q запросов, пусть поступают запросы Q1 и так далее, Qn, и мы знаем потенциал нашей структуры после
обработки каждого запроса. После обработки ИТ запроса потенциал равен ФИИТ. То есть мы знаем,
как ведет себя вот этот вот потенциал. То, что я говорил, если там размер массива, то мы знаем,
как он себя ведет. Сначала один, потом увеличивается в два раза, потом много раз один и то же, потом
уменьшается в два раза и так далее. Вот какой-то потенциал после каждой операции мы знаем. Пусть
также ТИТ это реальное время обработки ИТ запроса. Реальное время обработки ИТ запроса.
Тогда определяем АИТ как ТИТ плюс ФИИТ минус ФИИ минус первое. То есть сколько нам реально
пришлось поработать плюс изменение потенциала. То есть какой потенциал стал, минус какой он был.
Плюс ФИИТ и минус ФИИ минус первое. Насколько изменился потенциал после этого запрос. Вот это
вот будет учетное время работы. Очень похоже на метамонеток. Реальное время работы плюс что-то,
минус что-то. Только теперь у меня не монетки, а какой-то потенциал от состояния структуры.
Какой-то ФИИ и минус ФИИ минус первое. Учетное время работы. Ну и опять это все работает, если ФИИ конечная,
минус ФИИ начальная больше или равно нуля. Если потенциал никогда не опускается ниже исходного
уровня, тогда вот эти Ашки являются учетными временами работы. Доказательства здесь тоже
элементарные. Мне нужно доказать, что сумма аитых, ну достаточно доказать, что сумма аитых больше
выбрана, чем сумма теитых. Что сумма учетных стоимости, это верхняя оценка на реальное время
работы. Ну давайте напишем, что такое сумма аитых. Это сумма теитых плюс ФИ1 минус ФИ0, плюс ФИ2 минус ФИ1,
плюс так далее, плюс ФИН минус ФИН минус 1. Вот. Ну и тогда все вот эти соседние сократятся,
ФИ1 сократится, ФИ2 сократится со следующим, ФИН минус М, сократится с предыдущим. И останется просто
сумма теитых плюс ФИН минус ФИ0. Сумма теитых плюс ФИН минус ФИ 0.
ноль так и если у меня выполняется это условие что конечно потенциал
минус начально всегда не отрицательный тогда вот эта штука больше нуля и
получается тоже самое не раньше что у нас было в методе в методе монеток что
чтобы получить учетную вот эту сумму не нужно к настоящей сумме к настоящему
времени работы прибавить что-то не отрицательное
значит вот это не раньше выполняется
пример использования пример использования
упражнения даже скорее вот если мы вернемся к задачу про инсерт в
биномиальную кучу тогда можно в качестве потенциала нашей структуры нашей
биномиальной куче взять число единиц в конце двоичной записи текущего
размера кучи число единиц в двоичной записи
текущего размера кучи
здесь в общем-то почти то же самое рассуждение просто в терминах
потенциала вот если у меня текущее число элементов представляет в
двоичной системе следующим образом нолик и куча единиц в конце и вот это вот
количество этих единиц я считаю потенциалом тогда как у меня ведет
себя ашка да когда когда я добавляю сюда новую единичку у меня время работы
равно количество этих единиц и потенциал падает вот с пятерки до нуля
потому что у меня это число превращается в число 1 и куча нулей здесь
потенциал будет нулевой да и тогда как раз вот такая тяжелая операция она
сопровождается с одной стороны падением потенциала и тогда вот эта
вот штука отрицательна сильно отрицательна но при этом она занимает
какое-то время работы и легко отследить что время работы как раз равно измене
потенциала ты это равно минус дельты фи это поэтому как бы учетная учетная
стоимость всех операций будет 0 вот таких вот операций когда мы за нуля им
кучу единичек у меня будет учетная стоимость 0 но если там простая операция
и не требуется вот так складывать единички то просто будет стоимость единицы
вот понятно значит если нету вот попробуйте ну вот честно написать чему
равен потенциал да понять как он меняется вот интерация к итерации и понять что
вот эти ашки считаются по такой формуле они всегда равны от 1 либо 0 либо 1
получается да конечно мы потенциал выбираем так как хотим главное чтобы
нужно чтобы получилось наиболее опсимальное время работы какой мы можем
получить вот у нас мы еще посмотрим у нас что будет потенци셔서 чуть позже
когда мы будем говорить про деревья у нас там будет с плей дерево и время
работы там тоже очень активно будет считаться через потенциал если мы увидим
правильный потенциал у нас получится луч wh obscure на учетное время работы
то есть нам нам вот здесь вот никто не говорит как уп casale выбирать если мы
выберем такой, что аитое получится очень маленьким, значит, ну мы победили. Чем
чем лучше наша оценка, тем мы точнее смогли оценить сверху время работы нашей
программы. А это нам и нужно. Нам нужно оценить сверху время работы программы всегда.
Так, хорошо. Тогда, наверное, с амортизационным анализом пока что все. Мы к нему еще вернемся
чуть позже, как я сказал. Пока давайте мы разберем следующую структуру данных, которая называется
спаррстейбл. Классическая задача, которую решает спаррстейбл, такова. У нас есть массив чисел,
давайте считать, что занумерованный с нуля а 0, а 1, а 2 и так далее а n минус 1. И он неизменяемый.
Неизменяемый. Я буду еще иначе говорить статический. Статический. То есть сами числа
а и т никогда меняться не будут. И поступают запросы всего одного типа. Запрос. По двум числам
l и r нужно найти минимум на отрезке с l по r. Найти минимальное число среди множества a lt,
a l плюс 1 и так далее a rt. То есть минимум на отрезке. А за сколько вы умеете? Вот, мы научимся
сделать единицы. Мы научимся находить минимум на отрезке за вот единицы. Решение довольно простое.
Смотрите, давайте мы введем следующее обозначение. Пусть sparse rt, нет r плохо, давайте kt и t. Это
минимум на отрезке длины 2 вкатой со стартом в точке i. Формально это минимум такого множества.
Минимум среди а и т, а и плюс 1 и так далее и так далее, вплоть до и плюс 2 вкатой минус 1. То есть
мы взяли это элемент в нашем массиве. Вот был весь массив. Мы взяли эту позицию, приложили сюда
отрезок длины 2 вкатой и на нем нашли минимум. Вот на таком отрезке длины 2 вкатой нашли минимум.
Тогда если я вот это вот быстро насчитаю, ну понятно, что k достаточно брать до логарифма,
крайне большим логарифм, потому что если у нас k большим логарифм, то мы обязательно вылезем за
пределы массива, это бессмысленно. Вот, если мы этот массив смогли насчитать, то тогда найти
минимум на любом отрезке довольно просто. Смотрите, вот мне нужно найти минимум на отрезке с l по r,
с l по r. Давайте тогда найдем максимальную степень двойки, которая целиком умещает в этот отрезок,
то есть 2 вкатой, максимально, но при этом не больше, чем r минус l плюс 1, не больше длина
отрезка. И теперь приложим этот отрезок слева и справа, к l и к r. Тогда они пересекутся,
но главное, что в объединении они покроют целиком этот отрезок. Вот эти элементы все покрыты
и эти элементы все покрыты. Ну а дальше, если я знаю минимум с верхнего отрезка и минимум с нижнего
отрезка, то чтобы получать глобальный минимум, мне нужно взять минимум из них. Потому что все равно
каждый элемент здесь учтен, и если минимум где-то и находится, вот здесь, скажем, х, то обязательно
минимум в одной из половинок будет обязательно х, и поэтому минимум из двух минимумов это обязательно
ответ. И здесь одно из приятных свойств минимума в том, что если мы как бы пересекаем наше множество,
какие-то элементы вот эти вот, они участвуют, как бы они влияют и на минимум вот здесь и на
минимум вот здесь. Но минимум такая хорошая операция, что если мы добавляем одни и те же числа в
множество, по которым мы берем эту операцию, скажем, вот здесь были какие-то числа, если я какие-то числа
буду дублировать, у меня и минимум не изменится. А если бы была какая-нибудь другая операция,
например, вот здесь вместо минимума была бы сумма или произведение, тогда так бы уже не сработало.
потому что если я знаю сумму вот здесь вот и сумму вот здесь вот,
тогда мне нужно их сложить, но еще вычесть вот эти вот повторные элементы.
А прелесть минимума как раз в том, что ничего вычитать не нужно.
Для каждого k и для каждого i мы прикладываем отрезок длины 2 вкаты к этой позиции
и считаем минимум вот на этом отрезке, длины 2 вкатых.
То есть формально минимум среди вот такого множества.
Аи-то, аи-плюс-первые и так далее и плюс 2 вкатые минус 1.
Главное следующее, главное, что мы для любой стартной позиции и для любой длины отрезка
равной степени двойки знаем на нем минимум.
И тогда если мы это посчитали, то минимум на отрезке lr это минимум среди вот такого отрезка
и такого отрезка. А такие мы уже знаем, потому что это степени двойки, мы на них уже посчитали ответ.
Итак, давайте сначала тогда начитаем этот массив.
На счет sparse. Первый слой очень простой.
Sparse, нулевое и-то, это просто всегда аи-то.
Если кара на нулю, то я получается прикладываю отрезок длины 1 к и-то позиции и беру минимум на отрезке длины 1.
Ну это просто само число. Это очевидно.
Дальше пусть мне известны sparse, kt, я вот так пишу, kt точка.
То есть я знаю sparse, где первый аргумент k и для любого второго аргумента.
То есть мне известно целиком строка этой матрицы. Я знаю kt строчку целиком.
Тогда как найти sparse, k плюс первое, какое-нибудь конкретное и-тое?
Sparse, k плюс первое, и-тое. Очень просто.
Что такое sparse, k плюс первое, и-тое?
Это мне нужно посмотреть на и-тою позицию в массиве, приложить отрезок длины 2 в степени k плюс 1.
2 в степени k плюс 1 и найти на нем минимум.
Ну тогда давайте я этот отрезок поделю пополам. Получится у меня два отрезка длины 2 вкатый.
Ровно два отрезка длины 2 вкатый, на каждом из которых минимум уже известен.
Потому что я знаю для каждого начала, знаю минимум на отрезках длины 2 вкатый с этим началом.
То есть я знаю минимум вот здесь, минимум вот здесь.
Тогда минимум из них равен тому, чему нужно.
Формально можно написать так. Пусть g это i плюс 2 вкатый.
Тогда sparse, k плюс первое, и-тое.
Это минимум из sparse, k-тое, и-тое.
И sparse, k-тое, g-тое.
Понятно ли эта формула?
Просто чтобы найти минимум на отрезках длины 2 вкатый плюс 1, я его бью на два кусочка одинаковой длины 2 вкатый.
И минимум на них неизвестен. Вот этот вот минимум хранится здесь, да, в этом числе.
Минимум с этого отрезка хранится в этом числе. Вот и все. И просто из них выбираю минимум.
Ну, смотрите, я иду в проект возрастания k. Для k в нулю мне известны такие и такие минимумы.
А дальше пусть мне известна целиком k-тое строчка, то есть я знаю, давайте напишу так.
Для любого s мне известна sparse, k-тое, st. То есть я знаю целиком как бы k-тое слой.
Теперь пытаюсь начать k плюс 1. Ну тогда мне вот это известно, и вот это известно, и я тогда знаю k плюс 1.
Ну деревоотресков это громкое слово, но чуть-чуть похоже, да.
Но это не деревоотресков, тем не менее.
Потому что как минимум оно занимает n log n памяти, а деревоотресков линейный память занимает.
Вот-вот-вот. Да, тут лучше нарисовать, вот оно, g вот здесь.
Это начало вот этого второго кусочка. И начало левого кусочка g, и начало правого кусочка.
Так, ну давайте код напишем тогда быстренько, если мы успеваем. Да, успеваем.
Ну вот пусть есть у меня массив a.
Сначала вот первая строчка я переписываю, и от 0 до n-1 я пишу, что sparse 0 i t это i t.
Дальше я перебираю k от 0 до, ну вот здесь до логарифма, скажем, округленного.
Ну давайте пока просто до логарифма, не будем думать, что там именно.
До логарифма. Вложенный цикл по i от 0 до n-1.
Заводим переменную g равную i плюс 2 вкатой.
И говорим, что sparse k плюс первая i t это минимум из, ну вот то, что там написано справа.
Все, весь алгоритм нахождения sparse table. Нахождение всех вот этих вот минимумов на отрезках.
Так, асимптотика, здесь очевидно n log n. Даже я напишу theta от n log n.
Потому что у меня есть массив размера, ну какие у него размерности.
Первое число у меня до логарифма, второе число у меня до n, там все числа могут быть, от 0 до n-1.
Получается у меня массив размера n log n, и каждое конкретное я насчитываю за от и единицы.
Вот каждое конкретное sparse значение я нахожу как минимум из двух чисел, которые мне уже известны.
То есть каждое число считается за от и единицы, поэтому суммарная симптотика просто n log n. Понятно?
Ну, значит, sparse я насчитал. А дальше напишем код, как найти минимум на отрезке.
Как найти минимум на отрезке? GetMin int l, int r.
Сначала, как я и говорил, давайте скажем, что k, словами давайте напишем, максимальное такое, что 2 вкатой меньше либо равно r-l плюс 1.
Тогда делаем просто return, картиночка будет нужна опять.
Значит, есть у меня отрезок, и я прикладываю отрезок длины 2 вкатой слева и справа.
Ну, соответственно, минимум из sparse вкатая l-t и sparse тоже вкатая.
Только теперь вот здесь нужно написать начало этого отрезка.
Начало этого отрезка это, видимо, r-2 вкатой плюс 1.
Плюс 1.
Скопка закрылась.
Понятно?
Так, ну тут есть несколько вопросов.
Во-первых, как считать 2 вкатой быстро?
Ну, как это написать на C++?
Во-вторых, как вычитать такое k?
Максимальная степень двойку не больше, чем что-то.
И в-третьих, почему это вообще верно?
Почему эти отрезки обязательно целиком покроют наш отрезок l?
Ответы на все эти три вопроса очень простые.
С++ есть команда bit и сдвиг.
Если вы напишете 1 меньше меньше k, то вы как раз получите 2 вкатой.
1 меньше меньше k это в точности 2 вкатой.
Работает это так.
То есть как воспринимает такую команду компилятор?
Он пишет двоичное число 1 в двоичной записи.
То есть это 1 и куча нулей слева.
А потом выполняет сдвиг на k позиции влево.
То есть просто берет и вот так вот целиком сдвигает влево.
Получается вот такое число.
Сдвигает влево на k позиции.
Потом вот этот префикс обрубает, который вылезает за пределы 32 бит.
И получается у вас как раз число, где единица стоит на кате с правой позиции.
То есть в точности 2 вкатой.
А была единица, а стала 2 вкатой.
Вот так работает бинарный сдвиг влево с++.
Второй вопрос. Какой у меня был?
Как найти вот такое k?
Ну самое простое, что можно сделать, это их все предпочитать.
Наверное самое простое это посчитать какой-нибудь логарифм двоичный от этой штуки и округлить его куда-нибудь.
Но такое есть правило, что если можно обойтись без логарифмирования, потенцирования и так далее,
то есть без перехода к вещественным числам, то так лучше сделать.
Потому что если вы считаете двоичный логарифм, то вы переходите обязательно либо к доблам,
либо к тишам, еще каким-то типам, у вас может откуда возникнуть ошибка, погрешность и так далее и так далее.
Поэтому давайте мы обойдемся без логарифмирования.
Ну это очень просто.
Давайте пусть дег хt это как раз вот то самое k такое, что 2 вкатой меньше, чем х.
То есть для каждого х посчитаем максимальную степень войки, которая его не превосходит.
И этот массив дег предпочитаем в самом начале вот здесь, в нашем алгоритме.
То есть там, где мы объявляем массив а и считаем его, мы также посчитаем все деги.
Считаются они очень просто.
Дег от 1 это 0.
Максимальная степень войки, которая не превосходит 1, это 2 в 0.
Дальше.
Идем по всем...
Так, сейчас.
Ну можно сделать как угодно, давайте я напишу, как я привык.
Значит, перебираем х от 2 до n.
Сначала говорим, что дег от ха это то же самое, что дег от х-1.
То есть сначала говорим, что если х увеличится на единичку, то максимальная степень войки не увеличивается.
Но потом, когда может увеличиться максимальная степень войки?
Когда у него было какое-то число, давайте я двоичную запись напишу.
Вот.
Было какое-то число.
Я к нему прибавил единицу, и у меня увеличилась максимальная степень войки, которая его меньше или равна.
То есть на самом деле у меня тогда обязательно картинка такая.
Здесь были все единицы, я прибавил единицу, и у меня все они превратились в нули.
А единица старшая переместилась влево на один разряд.
То есть, ну, иными словами, максимальная степень войки увеличится на единицу каждый раз, когда мы переходим в новую степень войки.
Если мы знаем, что в тройке максимальная степень войки это 2, мы переходим в четверку, то максимальная степень войки становится равно 4.
Здесь нужно написать такое условие, что если х это степень войки, тогда нужно сделать плюс-плюс дега от х.
То есть, если я перешел в число, которое само по себе равно степень войки, то нужно эту дегу увеличить.
И тогда вот здесь вот к можно писать просто дег от r-l плюс 1 с помощью вот этого массива, который я начал в самом начале.
Теперь нам нужно еще научиться эффективно проверять, что х это степень войки.
Ну, я утверждаю, что это выполняется в том случае, когда выполняется следующее условие.
Так, ну что здесь есть?
Выполняется следующее условие.
Так, ну что здесь написано? Я считаю х, считаю х-1. Затем беру их побитую конъюнкцию.
Вот я представляю, что х это у меня какое-то бинарное число в двоичной записи.
х-1 это тоже двоичное число в записи с нулями единицами. Затем беру побитую их конъюнкцию.
Так, что такое конъюнкция, понимаем, побитая?
Ну, там если здесь 0, 0, то здесь 0, если тут 0, 1, то здесь 1.
1, 1 переходит в 1, а 1, 0 переходит в 0.
Вот так побитого делаю конъюнкцию.
И утверждается, что если в конце получился 0, ну или там иными словами, если...
Ну так работает, что вот вы это число посчитали.
Давайте я напишу вот так. Можно написать вот так, что это просто равно 0.
Вот это выражение.
Либо то, что у меня было написано раньше, воскреслятельный знак, х, ant, х-1.
If так работает, что если вы ему передаете внутри число, и оно нулевое, то оно считается false,
а если оно не нулевое, то считается true.
Если наоборот вы ставите воскреслятельный знак, то есть отрицание, то получается, что если вот это было 0, то условие верно,
если это не 0, то это неверно.
Ну иными словами можно написать, что вот это ant должен быть равен нулю.
Ну и как раз в каком случае ant этих двух чисел 0 только в случае, когда х это степень двойки.
Например, пусть х это степень двойки. То есть куча нулей, один и куча нулей.
Тогда х-1 ведет себя так. Здесь остается куча нулей, единица переходит в 0, а здесь куча единиц.
Ну понятно тогда, что их конъюнкция это куча нулей.
Потому что у вас нет ни одного разряда, где и в х, и в х-1 стоит единица.
Поэтому если х это степень двойки, то конъюнкция обязательно нулевая.
Наоборот, если х это не степень двойки, значит у него в двоичной записи есть хотя бы две единицы.
У него в двоичной записи есть хотя бы две единицы.
Ну и тогда х-1 сохраняет на месте старшую из них, младшую может превратить в 0.
Но главное, что после конъюнкции у вас старшая обязательно сохранится.
Поэтому если х это не степень двойки, то хотя бы один общий бит у них будет, значит конъюнкция не нулевая.
Поэтому это условие не пройдет.
Поэтому вместо вот этого гуманитарной проверки, что х это степень двойки, мы пишем вот это условие, что если это 0, тогда мы увеличиваем дегат х.
Да.
Вот это?
Это я таблицу для конъюнкции нарисовал.
Да, смущающе, давайте не будем это писать.
Просто если у вас есть два числа, как считается конъюнкция?
По битве я написал, что конъюнкция 0 это 0, 0,1 это 0, 1,1 это 1, 1, 0 это 0.
Это я написал таблицу для конъюнкции.
Так, и последний вопрос, который нам остался, это почему верно вот эта вот формула, что почему мы целиком покроем наш отрезок?
Почему приложить отрезок длины 2 вкатой слева и 2 вкатой справа обязательно целиком все покроют?
Ну пусть не так, пусть мы не покрываем все целиком.
То есть был вот наш массив, есть наш отрезок LR, и мы приложили слева 2 вкатой, справа 2 вкатой.
И мы покрыли не все элементы отрезка.
То есть у меня где-то здесь еще есть хотя бы один не покрытый, вот такой свободный.
Ну тогда это значит, что 2 вкатой плюс 2 вкатой меньше, чем длина отрезка R-L плюс 1.
Тогда K можно увеличить, взять следующую степень двойки, и будет выполняться такое неравенство, что мы изначально K взяли неверным.
А еще раз, если... сейчас звенит.
Еще раз, если у меня вот эти два отрезочка слева и справа не покрывают целиком мой отрезок LR,
значит есть какой-то свободный элемент, не покрытый ни одним из них,
тогда суммарная длина этих отрезков меньше, чем R-L плюс 1.
А значит исходное K выбрано неверно, его можно увеличить,
неравенство сохранится, что 2 в степени K плюс 1 будет меньше, чем R-L плюс 1.
Значит исходное K подобрано неправильно, а мы предположили, что правильно.
Все, значит мы целиком покроем отрезок и минимум там правильно найдем.
И это работает за от идицы, потому что мы все правильно уже предпочитали.
Мы знаем спасибо большое, мы знаем K, мы знаем вот это, мы знаем вот это,
берем минимум за от идицы и получаем ответ.
Все, спасибо.
