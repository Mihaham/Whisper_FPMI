Приветствую вас. Сегодня у нас последнее занятие перед финальным, где мы подведем
итог всему происходящему, где я объясню все, что было у нас за последние три месяца,
что все это значило, как это нужно воспринимать, как это нужно унести с собой. Сегодня последняя
тема и новая тема для нашего курса. Но для вас все новая, а тема новая и для меня. Она читается
в первый раз. Она очень сложная и она будет посвящена, я бы сказал, частично распределенным
системам. То есть это такая лекция со вкусом следующего спецкурса про распределенные системы,
где мы будем очень интенсивно все это использовать, все, что мы изучаем. И распределенная система — это
тот контекст, ради которого в том числе все это и было выдумано для того, чтобы там как-то
справиться со всей сложностью. Но перед тем, как это тема отмены и обработки ошибок,
cancellation и error handling, но перед тем мы перейдем к этой теме. Несколько слов про текущие задачи и
про то, чего бы я от вас очень хотел и что бы вам стоило сделать для того, чтобы вынести с курсом
максимальную пользу. У нас осталось не так много времени и у нас остались три задачи, на которые
я обращаю ваше внимание. Это задача про канал, про канал, с помощью которого Fiber могут коммуницировать
друг с другом, и про Select, с помощью которого Fiber могут дожидаться сообщения на одном из
нескольких каналах, останавливаясь до тех пор, пока сообщения не появятся хотя бы в одном. Это задача
Future, про то, чтобы построить некоторые такой декларативный язык комбинаторов, с помощью которых
можно композировать синхронная операция. Последовательно с помощью, это не задача Future,
последовательно с помощью комбинатора Zen, ну или Recover, который останавливается после ошибок,
и параллельно с помощью комбинаторов All и First-off. Это очень ценная тема, это очень
ценный инструмент, это несколько другой инструмент, совершенно другой, который не похож сильно на
Fiber, который заставляет вас думать в совершенно другом языке. Мне кажется, это важно. И это
корутины, корутины C++, которые являются тем инструментом, который современные C++ предлагают
для того, чтобы описывать асинхронные операции. Вот если мы хотим исполняться задачи, а потом
остановиться, то у нас есть такое ключевое слово co-await, под которым мы можем с помощью
авейтера остановить корутину и запланировать возобновления по какому-то событию, по таймеру,
по готовности ввода-вывода, по завершению другой синхронной операции. Вот, про эти задачи я писал
в канале, но вот повторяю еще раз, что это три важные задачи, и они одинаково важны. Вот эти
три задачи – это не задачи вообще, то есть не нужно относиться к ним к задачам курса. Это три больших
подхода к конкарнсе, к которым мы шли весь семестр. И вот все, что было до этого момента, это, в общем,
такие приготовления для того, чтобы воспользоваться, изучить один из этих трех больших инструментов,
ну, вернее, все три изучить. Они очень разные, они очень разные, и они очень важны, и встречаются в
языках, с которыми вы будете в жизни работать дальше. C++ вы будете работать с корутинами,
Go вы будете работать с каналами, в какой-нибудь скала или что-нибудь функциональное вы будете
работать фьючами. Вот, что бы вы дальше в жизни не делали, какой бы конкарнс его не писали,
а вам, скорее всего, придется с ним сталкиваться. Ну, даже на JavaScript, неважно, на питоне. В любом
случае, вы будете работать с одним из этих инструментов. Ну, и почему бы не изучить все эти три
инструмента, причем изучить глубоко? Не то, чтобы как пользоваться ими, а вот прям, как они внутри
сделаны. Вот, это очень большой буст на ваше будущее, поэтому я очень прошу вас, вот, сосредоточить силу
на этих задачах. Но вы спросите, как же так? Это же какое-то сомнительное предложение, потому что у нас
осталось две недели, да? Вот, и мы многое не успеем. Ну, во-первых, вы успеете что-то, да? Лучше,
чем не успеть ничего. А во-вторых, есть предложение для всех нас немного сдвинуть дедлайны. Ну,
зачет у нас состоится так, когда и должен пройти зачетную неделю, там, какого-то 21 или 22 числа.
Но у нас, кажется, есть техническая возможность ведомости сдать немного позже или сильно позже
этого дедлайна. Вот, и как это поможет нам? Это, возможно, поможет нам дорешать три эти сложные
задачи. Ну, я, по крайней мере, морально готов сдвинуть дедлайн по этим задачам, но не то, что дедлайн,
не знаю, может быть, даже и дедлайн. Это сильно дальше, но только именно по этим трем. Вот, после
зачета можно будет сдавать, но вот три задачи, которые, мне кажется, важны. Если у вас найдутся
силы там в течение ваших экзаменов, сессий, ваших канникул, то если вы готовы получить более
высокую оценку и разобраться с новым инструментом, важным инструментом, то, ну, давайте договоримся,
что у нас эта возможность будет. Мне очень хочется, чтобы вы и воспользовались. Единственное, что меня
беспокоит, это беспокоит защита, потому что всё-таки сложные задачи, для сложных задач очень полезно
защиту проводить. Я, скажем, физически смогу это делать только до конца мая, а потом уже не смогу.
Ну, мы это, наверное, решим с вами. Просто я предлагаю вам такую возможность, надеюсь, что кто-то захочет
ей воспользоваться. То есть, задачи, сданные даже после зачета, могут пойти в оценку, но только,
если это задачи, которые посвящены вот грутинам, каналам, Future. Я правда не знаю, как среди них
приоритеты какие-то выстроить. Мне кажется, что Future суперважны, потому что это вот декларативный
подход, с которым мы сталкивались мало. С другой стороны, мне кажется, что каналы суперважны,
потому что, во-первых, это клёвая задача, мне очень нравится, а во-вторых, сделав каналы, вот только
тогда по-настоящему можно попрофилировать планировщик, разобрать там разные сценарии.
Ну, вот, собственно, там заиграет лифо-планирование, которое мы писали. Вот без каналов
профилировать планировщик, изучать его поведение довольно сложно. Нужны нетривиальные примеры,
нужны какие-то комбинации. Вот написав каналы, вы получите эти новые ворклоды. Грутины. Ну, разумеется,
тоже грутины важны и не менее важны, потому что это современный C++, и мы, реализуя файберы,
реализуя там все вот эти авейтеры, всю этому шинерию внутреннюю, шли к тому, чтобы как раз
дизайн, грутины изучить. Вот я, правда, не могу какие-то приоритеты выстроить. Мне кажется,
что три равноправные ветки полезны сделать всё вместе. Короче, время у нас будет. Попробуйте. Вот
если я могу чем-то вам помочь, то говорите. Может быть, там какой-нибудь дополнительный семинар провести
или семинары. Ну, а сегодня мы поговорим про тему, которая у нас в курсе пока не возникала и про
которую мало кто на самом деле думает, когда говорит про конкарнси, а без которой жить на
самом деле невозможно. Это тема обработки ошибок и отмены асинхронных операций. И для того,
чтобы вот к этому контексту прийти, нужно понять, вот откуда у нас это нужно вспомнить, вернее,
откуда вообще конкарнси в нашей жизни возникает. Почему мы говорим про конкарнси? Почему нам
нужно запускать эти файберы? Почему нам нужны какие-то фьючи, крутины? Крутины, простите. Потому
что у нас есть система, которая обслуживает пользователей. Вот пользователи приходят и задают
запросы. И этих пользователей много. Скоро угодно много. Больше, чем ядер, больше, чем способна
операционная система поддерживать потоков. Очень много. И у каждого пользователя, для каждого
пользователя, для каждого запроса нужно запустить какой-то, вероятно, нетривиальный контейнер,
конвейер обслуживания этого запроса. Вот какая-то цепочка операций, которые там параллелятся иногда,
делать что-то последовательно, но синхронно. Короче, какая-то сложная логика. Вот оттуда берутся
фьючи, оттуда берутся селекты. Оттуда берутся фьючи и файберы, оттуда берутся примитивы
синхронизации, когда вот эти пайпланы должны каким-то образом координировать свои действия,
потому что они там обращаются к воздрявимым данным, ну или что-то сложное там буферизуют,
что угодно можно себе представить. Вот именно из этих задач берется конкарнси. Но когда мы говорим
про такие задачи, то мы... ну давайте я картинку покажу сейчас. То, как правило, мы работаем не то,
чтобы на одной машине все это делаем. Скорее всего, мы говорим про какие-то системы, которые, ну вот
распределенные. Распределенные, потому что они состоят из разных микросервисов, каждый из
которых решает некоторую задачу, и эти микросервисы, там они могут быть реплицированы. В смысле,
у вас может быть много экземпляров, потому что каждая машина может отказать. Ну и вот клиент
приходит в вашу систему, вот такая условная граница этой системы, отправляет свой запрос,
и вот на первой машине, на какой-нибудь там проксе запускается какой-то обработчик, какой-то,
не знаю, файбер, какая-то карутина стартует где-то. И вот она что-то делает, а потом
порождает новые запросы. И вот у вас из этого кубика, из этого сервиса выходят две стрелочки
в другие кубики, в другие сервисы. Ну эти сервисы, это могут быть там разные машины,
одна машина, можно себе представить разные физические конфигурации, но вот в общем случае
конструкция такая, и у вас внутри этого кубика какая-то конкарнсия, а между кубиками у вас
remote process g-call, то есть ударенный запрос. Ну то есть вы, давайте я покажу, как это может выглядеть в коде,
например, который мы будем писать как раз у вас. Ну как это выглядит сейчас. Вы отправляете запрос
на некоторую другую машину, которая представлена вот таким вот каналом логическим, канал здесь
в другом смысле, нежели в фьючах, нежели в файберах, простите. Отправляем запрос сервису вот с таким
именем, с таким запросом, с такими аргументами, ну и там получаем фьючу, которая представляет ответ.
Вот получается такая конструкция. Здесь физические машины, сервисы, конкарнс,
RPC между ними, между машинами, между сервисами. И с какой проблем мы здесь сталкиваемся? Ну смотрите,
допустим нам для ответа клиенту нужно получить ответы от двух разных сервисов, но пока они
оба не ответят, пока две машины какие-то не ответят, мы ответа дать пользователю не можем. Ну а что делать,
если одна из машин отказала? Ну неприятная ситуация, да, но она абсолютно допустима, и если мы строим
распределенную систему, мы должны быть к этому готовы. Мы должны быть готовы к тому, что любая
машина может отказать. Ничего абсолютно надежного нет, никакого абсолютно надежного железа не
бывает. Все ломается, поэтому к поломке любого компонента мы должны быть готовы. Так что мы
не можем вот просто бесконечно дожидаться, пока нам какая-то машина ответит. Мы не можем
бесконечно дожидаться фьюча, потому что ответ за этой фьюча никогда не появится, потому что машина
взорвалась или утонула в центре, потому что его затопило, или там электричество, больше нет питания,
нет. Ну или по-другому. Вот если вы знакомы с теорией массового обслуживания, вы знаете,
наверное, это очень важный топик, и я когда-нибудь писал даже в канал по смешному поводу, но неважно
про то, что если у вас система перегружена, если в нее приходит пользователь с своими запросами
быстрее, чем система может их обслужить, то было бы очень странно ставить бесконечно запросы эти в
очередь и обслуживать их, потому что тогда с какого-то момента у вас время ответа будет расти по
экспоненте. Это плохой дизайн системы, потому что у пользователя время ответа не ограничено.
Поэтому разумно, чтобы время ожидания пользователя, ну вот время ожидания ответа на этот запрос
пользователя корневой, было чем-то ограничено. Но не имеет никакого смысла обслуживать все
запросы вот до победного конца. Если система перегружена, то она перегружена. Это вот объективная
реальность. Мы должны сказать пользователю, что его запрос отвергается, что система не способна
его обслужить и освободить внутренние ресурсы. Вот освобождение ресурсов — это очень важный
вопрос. Он возникает, когда мы... освобождение ресурсов, отмена операции — это примерно одно и то же.
У пользователей есть некоторый бюджет времени на запрос, и если мы бюджеты стратили и не смогли
на него ответить, то нужно, видимо, всю работу отменить. Если мы отправляем запрос на две машины,
а одна из них умерла, то нужно тоже эту операцию, которая дожидается ответа от одной из машин,
тоже отменить, потому что в ней внутри какие-то ретраи, они бесконечно крутятся, что-то
перезапускают, переотправляют какие-то сообщения, осадение рвется, и так происходит бесконечно,
бесконечно, бесконечно. Это какие-то ресурсы, которые система тратит под капотом, какие-то
объекты, которые выделены в памяти, и они будут жить вечно, потому что машина никогда не живет.
Они не будут копиться, потому что будут приходить новые запросы, отправляются новые запросы вот сюда,
а эта машина никогда не ответит на них. Понимаете, проблема? То есть мы пока научились запускать что-то
и дожидаться чего-то, и синхронизироваться, но иногда дожидаться не нужно. Иногда дождаться не...
ну, дождаться невозможно просто. Или не нужно, или невозможно. И вот в этих сценариях мы хотим
синхронные активности отменить. Ну и давайте подумаем, как можно было бы это делать. Начнем
с простого очень сценария, где вот у нас есть клиент, и у него есть... он приходит с запросом,
система в некоторые точки входа получает этот запрос, и видимо, отводит этому запрос
некоторый бюджет времени. Может быть, клиент сам сообщает этот тайм-аут, может, у нас просто
в системе есть какой-то разумный тайм-аут. И вот этот бюджет времени, он как бы на исполнение
всего-всего по дереву. На все эти RPC вызовы, на всю синхронизацию, на все активности внутри
отдельных сервисов, вот на исполнение всего этого графа распределенного. Тайм-ауты должны быть.
Ну и вот давайте посмотрим на библиотеку в Python, которая называется requests. Это HTTP-запросы для
людей, как говорится в названии. Ну и правда, очень удобная библиотека, и в ней много фичей,
в частности, в ней есть тайм-ауты. Мы не можем перейти по этой ссылке, потому что вот настоящая
ссылка. Смотрите, что здесь написано, что, ну вот если вы пишете какой-то промышленный код,
если вы пишете какой-то настоящий код, который обслуживает живых людей, то вы просто обязаны
для любого запроса устанавливать тайм-аут. Не бывает запросов без тайм-аутов, потому что,
с другой стороны, никогда не ответят. Потому что, с другой стороны, там, от машины отказало уже. Ну или
потому что у вас просто израсходовался ваш бюджет. Вот в любом запросе должен быть тайм-аут. Ну и вот
есть request-get и тайм-аут. Хороший этот дизайн. Ну как бы разумно пока, да? У нас есть тайм-аут,
мы его пропагетим вот в запрос наш. Ну, смотрите, тут даже есть комментарии смешные по этому поводу,
что тайм-аут — это на самом деле не лимит на весь запрос. Тайм-аут — это некоторый тайм-аут,
который передается там в отдельное чтение, там, в синхронную операцию над сокетом. А может быть у
вас запрос — это много таких итеративных чтений из сокета. Вот. И у вас этот тайм-аут, ну то есть
семантика тайм-аута, ну такая уже довольно зыбкая становится. Понимаете, в чем проблема? То есть что
именно? Это тайм-аут на весь запрос, это тайм-аут на какой-то подоперацию. Ну или чтобы стало яснее,
давайте по-другому представим. Вот у вас есть запрос, у вас есть клиент, он присылает вам запрос,
и чтобы на него ответить, нужно сначала спросить что-то у сервиса A, а потом у сервиса B. Вот. И у вас
есть один общий тайм-аут на весь запрос, на глобальный запрос. И вот вы посылаете запрос
сервису A с этим тайм-аутом. Если он расходовался, то все, мы отменяем, мы говорим пользователю,
что мы не можем его обслужить. Ну допустим, мы выполнили запрос к сервису A, он завершился в
отведенное время, и нам нужно отправить запрос сервису B теперь. Какой тайм-аут мы передадим? Но
видимо нам придется тайм-аут пересчитать, потому что он изменился. Потому что тайм-аут отчитывается
от текущей точки во времени, от now, а у нас у пользователя своя точка отсчета, когда он пришел
в нашу систему. И в итоге с тайм-аутами жить становится немного неудобно, потому что их нужно
постоянно пересчитывать, потому что у них точка отсчета меняется. Вот с тайм-аутами работать
неудобно, потому что их сложно пропагетить. Понимаете меня? Вот, как бы можно было упростить нашу
логику, как можно было бы достичь того же самого, то есть ограничить бюджет на исполнение всего
вот этого графа запросов, но при этом не вот страдать от этой сложной семантики тайм-аутов,
от того, что они отчитываются от разных моментов времени. Ну вот, есть такая, можно думать об
этом временном бюджете с двух позиций. Можно думать по тайм-аутам, а можно думать про дедлайны. Вот,
вы приходите, вы клиент, вы приходите в систему, и вместо того, чтобы устанавливать тайм-аут и
дальше его постоянно пересчитывать в каждом внутреннем шаге, вы сразу определяете дедлайн на весь
запрос, а дальше вы можете, если вы делаете что-то параллельно, вы передаете один тот же дедлайн в
два запроса. Если вы задаете запросы последовательно, то вы также используете один тот же дедлайн,
потому что он по-прежнему справедлив. Это понятно, да? Вот, то есть, если у вас есть в коде API с
тайм-аутами, то, пожалуйста, избавьтесь от него и замените его на API с дедлайнами. Это будет уже
более композируемо. Первое наблюдение. Второе наблюдение. Ну вот, нам эти тайм-ауты нужны для
того, чтобы операции отменять. Но операция у нас вот это что угодно. Вот мы научились уже какие-то
штуки писать с вами, какие там фьюч, какие-то там таймеры заводить, какие-то там блокировки
брать, чего-то ожидать разными способами. Как вы себе представляете отмену всей этой сложной
машинерии? Ну скажем, у вас был заведенный таймер. Как вам его отменить? Ну ладно, можно себе что-то
вообразить. А может быть, вы начали операцию учтения из сокета. Как вам отменить операцию
учтения из сокета? Ну то есть, вы подписались в Epoly на этот самый сокет. Ну вот, вы, конечно,
можете брать и как-то принудительно отменять что-то. Прямо буквально отменять. Вот вам,
у вас истек дедлайн, и вот прямо сейчас нужно все срочно остановить. Это может быть сложно,
ну потому что сложно прервать какую-то асинхронную активность в общем случае. Поэтому мы скажем,
что да, у нас есть дедлайны, да, у нас есть задача отменно-осинхронных операций, но мы эту
задачу будем решать как и все в нашем курсе кооперативно. То есть, вот есть асинхронная
операция, у нее есть дедлайн. Это не значит, что она во время истечения дедлайна сразу должна
остановиться. Нет, это значит, что она просто готова периодически проверять этот дедлайн.
Если дедлайн истек, а операция еще не готова, то так уж и быть, она отменится. Вот тут, смотрите,
есть такая естественная гонка, что асинхронные операции, асинхронные вот эти вычисления,
запросы, они вот по этому графу сверху вниз поднимают вам какие-то результаты, а вы спускаете вниз
сигнал отмены периодически, ну в виде дедлайна, да. И вот два этих сигнала, они ответы, которые
поднимаются наверх, и отмена, которая спускается вниз в виде дедлайна пока, вот эти две, эти два
сигнала гоняются между собой. Они могут приходить конкурентно. Так что мы не заботимся о том, в
каком порядке все это пришло. Мы вычисляем результат, а пока он не вычислен, мы можем периодически
проверять дедлайн. И если он истек, то мы бросим вычислять результат. А если он еще не истек,
то мы будем продолжать. И может быть, мы вычислим результат, начнем его отправлять наверх, то есть
отправим его в промисс, а при этом дедлайн уже истек. Ну, небольшая беда, значит,
выше он просто уже не нужен, он не воспользуется. То есть мы сделали немного лишней работы. Нас это
не беспокоит, потому что вот мы готовы к такому поведению. Нас это устраивает, мы готовы отменять
кооперативно. Понятно, да? Отлично, идем дальше. Вот мы сейчас говорим про дедлайны, но насколько
мы говорим про время. Ну, кстати, дедлайны, я сказал вам, что нужно везде работать с дедлайнами,
я на самом деле немного вам наврал, потому что есть такая тонкость, что дедлайны, они же привязаны
к часам. Вот. А часы, вообще говоря, это такой сложный механизм. Ну, с этого начнется следующий
курс про определенным системам, что часы на разных машинах это... Ну, как бы часы — это приближение
к настоящему физическому времени. Вот никто его не знает, но у каждого есть часы. И если у вас есть
двачасовые механизма, то они могут показывать разное время. И сложно заставить их показывать одно
и то же вообще на разных машинах. Что? Да там миллион проблем есть, и вот в общем случае часы
плохо синхронизируются. Поэтому вообще-то сложно передавать дедлайны между машинами. Вообще-то так
делают на практике, потому что часы синхронизируются, ну так, приемлемо. Но, строго говоря, это глубоко
порочная идея, потому что часы не синхронизированы. Вот. Поэтому, может быть, вот здесь как раз нужно
передавать тайм-ауты, а не дедлайны. Ну, это вот такая уже наполовину инженерная, наполовину
какая-то теоретическая задача. Мы обсудим ее опять в следующем семестре. А пока заметим, что если мы
говорим про одну машину, то передавать там дедлайн в виде точки во времени тоже совершенно
необязательно. Можно немного абстрагировать этот самый дедлайн и заменить его на понятие, которое
называется стоп-токен. Стоп-токен... Ну, что такое дедлайн? Он может быть... То есть, когда мы смотрим
дедлайн, мы получаем сигнал такой либо 0, либо 1. Либо дедлайн еще не истек, и нужно продолжать
работу, либо дедлайн уже истек, и нужно пробовать отменить работу. Вот этот состояние дедлайн
истек или дедлайн еще не истек, или пора отменяться, или не пора отменяться, мы можем заменить на объект
стоп-токен. То есть, мы передаем в наш синхронный пайплайн, состоящий там из файберов, из фьюч,
не сам дедлайн, и передаем стоп-токен, у которого можно спросить, а не пора ли нам отмениться. Может
быть, с другой стороны, уже вызвали стоп-реку... Ну, это не вся история. Стоп-токен — это только
половина истории. Есть стоп-токен, есть стоп-сорс. Стоп-сорс — это объект, который строит стоп-токены.
И мы можем сказать на стоп-сорсе, стоп-реквестат... Реквест-стоп, простите. А на самом стоп-токене мы
можем спросить, верно ли что стоп-реквестат. То есть, тот, кто хочет отменить операцию, он через
стоп-сорс посылает сигнал о том, что операцию нужно отменить. Просто ставит где-то вместо 0 единичку.
А тот, кто выполняет асинхронную операцию, смотрит на этот стоп-токен и спрашивает у него, опять не туда,
отменилась ли операция или нет. Ну, то есть, так мы немного абстрагируем дедлайн. Дедлайн можно
представить в виде стоп-токена, для которого стоп-сорс, реквест-стоп вызывается по истечении
некоторого времени. Ну, то есть, такой более унифицированный интерфейс, потому что мало ли
почему мы собираемся операцию отменить. Может быть, под дедлайн, а может быть, еще по какой-то
причине. Потому что какая-то ошибка возникла. Эта мысль понятна? Отлично. Теперь мы посмотрим на
какой-то пример. Ну, посмотрим на язык ГО. И в языке ГО стоп-токенов нет, зато есть библиотека,
которая называется контекст. Она довольно фундаментальна, потому что контекст — это объект,
который как раз вам и позволяет работать с асинхронной отменой. Вот в контексте есть дедлайн.
Контекст — это сложная штука. Она еще тесно связана с распределенным трейсингом, с распределенной
трассировкой для наблюдения за поведением системы. Ну, это тоже тема следующего курса. Но в частности,
контекст позволяет асинхронной операции периодически проверять, что эту операцию пора или не пора отменить.
Этот контекст сейчас... Ну вот какая-то операция. У нее есть контекст и... Да, простите. Могу,
конечно, увеличить. И вот у нас есть какая-то асинхронная операция, и у нее есть контекст. То
есть контекст, то есть сигнал отмены. И вот асинхронная операция чего-то ждет. Она ждет
сообщений из канала, например. Но, может быть, не нужно ждать его вечно, потому что операция просто
больше не нужна. Поэтому мы пишем селект, и ровно поэтому мы в домашней профайбере пишем селект,
и с помощью этого селекта дожидаемся одного из двух событий. Либо через контекст пришел сигнал
отмена, либо через канал с данными пришли какие-то данные, и там мы их обработаем. Что случилось
раньше? То есть важно, чтобы вся эта инфраструктура отмена, она как-то интегрировалась с нашими
примитивами конкарнс, с примитивами блокирующего ожидания. Ну вот контекст это позволяет делать.
Понимаете, судьи? Ну я прямо скажу, что лекция, она такая довольно обзорная. Мы сейчас к чему-то
конкретному придем, а вся мотивация, она находится в следующем курсе, поэтому я вам многое не
договариваю, и сложно просто все это рассказать сразу. Но идея должна быть примерно понятна.
Ну и эти контексты можно декорировать. То есть можно на самом деле строить такое целое дерево
этих контекстов, потому что у нас есть операция, и для нее есть контекст отмены. И у этой операции
есть какие-то под-операции, у них могут быть свои правила отмены, ну то есть свои там дедлайны. И
вот в общем случае эти контексты сплетаются в некоторое дерево. Ну вот такая скромная картинка
должна это иллюстрировать. Вот, ну это я всего лишь рассказываю, как вот в языке Go эта сущность
StopToken представлена, вот такой сигнал отмены асинхронный. И в языке Go это очень важная сущность,
потому что весь код, который пишется в Go, он весь асинхронный, он весь про обработку клиентских
запросов, а в обработке этих запросов должна быть логика по их отмене. Ну хорошо, что же нам мешает
такие StopTokens написать? Да ничего, собственно, не мешает, а дальше нам нужно ими пользоваться.
Вот что предлагает делать Go? Ну Go предлагает довольно скромную стратегию использования. Он
говорит нам, что если вы хотите использовать асинхронные опера, если вы пишете асинхронный код,
и он должен уметь отменяться, то, пожалуйста, просто передавайте в свои функции, которые вы
исполните асинхронно, вызывая там Go что-нибудь, этот контекст первым аргументом, чтобы было
понятно, что вот эта функция, которая где-то запускается, она готова прерваться по событию,
по сигналу отмены. Ну и если мы пишем с вами, если мы пишем с вами собственные файберы,
наверное, мы хотим их писать крупнее, да, хотим или нет, то, ну что мы можем сделать? Мы можем
завести Stop Source, мы можем запустить файбер, и он запомнит этот Stop Token, а дальше будет
что-то делать. Тут ничего не происходит, конечно, но вот смотрите, мы запустили файбер, подождали
три секунды, а потом подумали, что хватит, пора ему остановиться. Сказали на Stop Source Request Stop,
и этот Request Stop записал в некоторое место единичку, этот файбер ее прочитал и решил,
что он остановится. Ну давайте мы на всякий случай все будем запускать, чтобы убедиться,
что все работает. Да, дисклеймер важный, который я не сказал. То, что я рассказываю сейчас,
это некоторый эксперимент, который еще не завершился. Ну, то есть, у меня в голове есть
некоторая конструкция, как все правильно организовать, как все должно быть. Она еще до конца
не привалидирована, поэтому я рассказываю вам какую-то очень сырую версию своего собственного
понимания. Но мне кажется, что она довольно стройная, и если вдруг мы в середине что-то поломаем,
то будет печально, конечно. Но вот код, который буду показывать, он точно еще сырой, и в некоторых
местах очень плохо выглядит, поэтому не ругайте его и меня слишком сильно, все еще впереди. Ну вот,
пример работает, да. Теперь, как этот стоп-токен реализован? Стоп-токен и стоп-сорс. Ну, смотрите,
мы говорим про асинхронные операции. Это что означает? Что у вас есть некоторый продюсер,
который что-то делает, и есть консюмер, который ожидает результата. И вот они как-то развязаны в
смысле их лайфтаймов. Вот непонятно, кто завершится раньше. Поэтому как можно себе вот внутри, изнутри
представить реализацию этих стоп-сорсов и стоп-токенов? Ну, очень-очень-очень просто.
Это не то. Вот стоп-токены. У вас есть стоп-сорс, через него вы отправляете сигнал в стоп-токен.
Но где этот сигнал должен храниться? 0 или 1? Не там-не там, потому что может быть продюсер завершится
раньше, чем консюмер прочитает сигнал. А может быть консюмер завершится раньше, ой, продюсер
завершится раньше. Сейчас, может быть консюмер со стоп-сорсом завершится раньше, чем продюсер со
стоп-токеном прочитает сигнал. А может быть все наоборот. Поэтому не там-не там хранить эту единицу
или 0 нельзя. Поэтому мы выделяем некоторый стоп-стейт с динамическим временем жизни, ставим на него
две сильные ссылки. И эти сильные ссылки поддерживают стоп-стейт до тех пор, пока жив, ну, либо стоп-сорс,
либо хотя бы один из стоп-токенов, которых может быть несколько. Это должно вам что-то напоминать уже.
Ну, если напоминает, то хорошо. Давайте здесь напишем 1. Вот, операция отменилась. Ну, в принципе,
может слышать, что лекция закончена, но можно, в принципе, весь поход так и писать. То есть вы везде
тащите с собой все эти стоп-токены в каждую операцию синхронную. Когда вы что-то запускаете,
запускаете файбер, захватываете токен, передаете токен. Когда вы запускаете что-то в пуле потоков,
то вы тоже в замыкание захватываете токен для того, чтобы его проверять. Так жить можно,
но так жить совершенно унизительно. Почему? Ну, давайте я по-другому скажу, что синхронная отмена
очень важна. Это очень важный инструмент, который должен присутствовать всегда. Но если мы заставляем
каждого пользователя, который запускает какие-то асинхронные там пайплайны, графы, каждый раз
руками протаскивать все эти токены, то, значит, мы говорим, что у нас есть задача, которая решается
всегда одинаково, но мы решаем это каждый раз. В смысле, мы, разработчики фреймворка,
твоими пользователями усилиями. Мы почему-то не сделали это сами прозрачно для тебя. Вот такие
механизмы должны, чтобы они были надежными, чтобы не всегда работали, они, по возможности, должны
быть прозрачными. То есть пользователь не должен их наблюдать. Все должно работать каким-то образом само.
Понятная мотивация. Вот это и трейсинг касается. Ну, и опять следующий курс. Поэтому мы бы хотели,
мы бы хотели делать вообще-то вот так. Ну, тут есть некоторые вспомогательные норсери,
это неважно сейчас. Он здесь не принципиально. Мы как-то запускаем файбер. Файбер запускает
функцию foo, в ней он запускает функцию bar, в ней он запускает функцию baz, в ней он бесконечно спит.
А потом мы бы хотели сказать cancel на этом файбере. Ну, мы бы... Ну, и под капотом все будет работать точно
так же. У нас будет stopToken, stopSource, где-то здесь спрятан stopSource, где-то у файбера есть stopToken,
но в коде явно его нигде нет. Вот давайте подумаем, как можно отменить файбер так,
чтобы отмена была прозрачна для пользователей, которые этот файбер пишет. Мы хотим прервать
исполнение файбера. Ну, файбер, смотрите, он кооперативный, то есть нельзя просто взять его
и прервать в любой момент времени. Но мы сказали, что нас это устраивает, отмена кооперативная. То
есть иногда файбер должен проверять, что ему пора отмениться. Для этого у него есть stopToken.
Файбер проверяет, что его нужно отмениться через stopToken. Вопросов два. Когда он проверяет это и
где? И второй вопрос. Как он, собственно, собирается отменяться? Ну, смотрите, файбер, он выполняет код
пользователя. И в коде пользователя работает код пользователя, поэтому, то есть там отмениться
нельзя. Там его логика написана. Но иногда все-таки файбер, точнее, не иногда, а часто. Почему мы пишем
файбер? Потому что они часто останавливаются, чего-то ждут. Они обращаются к рантайму. То есть мы
исполняли код пользователя, а потом мы прыгаем в реализацию наших файберов. Вот, например,
здесь, когда мы вызываем slip4, мы получаем, на самом деле, фьючу. У нас есть некоторый сервис
таймеров, который строит фьючи. И мы дожидаемся этой фьючи синхронно с помощью операции await,
которая, на самом деле, просто симулирует целиком механику корутин. То есть тоже авейтер строится,
мы засыпаем, ожидая этого авейтера. Это такой способ интеграции фьюч и файберов,
который, кстати, мы тоже можем еще в курсе написать. Если вы знакомы с корутинами, то мы этот код,
в общем-то, изучали. Вот у фьючи есть авейтер, который подписывается... Собственно, что я рассказываю,
я же могу показать. Чтобы дождаться фьючи, нам нужен авейтер. Авейтер в самом привычном для нас
смысле. И авейтер для фьючи выглядит ну как-то так. Мы подписываемся на фьючу, и в ней мы резюмим
файбер в колбэке, а потом мы файбер останавливаем. Но останавливаем его не явно вот здесь,
точнее, явно с помощью этого suspend. А после остановки мы запускаем авейтер await suspend,
и он там подписывается на фьючу и там планирует возобновление файбера. Короче, вы все это написали
уже. Только для Mutex и только для кондвара, но для фьючи, в принципе, то же самое. Так вот,
мы берем и в точках обращения к runtime, где файбер останавливается, потом возобновляется операцию
checkpoint, которая что делает? Она просто проверяет, пора ли файберу остановиться. Черт, спойя. Как
проверять? Ну просто у каждого файбера при запуске должен быть стоп токен. То есть когда мы
конструируем файбер, мы вместе со всем остальным, что ему важно, передаем еще и стоп токен. На самом
деле так можно не делать. Он в супервизоре, может быть. Ну пусть. У каждого созданного файбера
должен быть стоп токен. Если файбер не хочет останавливаться, у него может не быть, ну точнее,
у любого файбера есть стоп токен, даже у файбера, который вообще не хочет останавливаться кооперативно.
Что такое стоп токен? Да, давайте я покажу. Я почему-то не показал это. Стоп токен — это сильная
ссылка на stop state. А stop state — ну это, вообще говоря, флажок отомарный, но, строго говоря,
это некоторый интерфейс, у которого есть операция request stop и stop request. Ну в некоторой
реализации request stop пишет флажок единичку, а операция stop request проверяет. Но есть, скажем,
стоп токен, который строится в функции never. И этот стоп токен устроен так. Он всегда говорит
false stop request, а request stop игнорирует вообще. То есть, ну не вызывается на имени когда request stop.
Это такой дефолт для всех файберов, которые просто запускаются через го. Мы их запускаем,
они там как-то исполняются, и останавливаться они не собираются кооперативно. Это значит,
первый вопрос — как именно файбер может узнать, что ему пора остановиться? Второй вопрос — как
именно он собирается прервать свое исполнение? Он же где-то там в недрах какого-то стека был
погружен. В смысле, в недрах какого-то стека выполнял какую-то работу. Как же нам прервать этот
файбер? Мы же не можем просто выйти из него и разрушить его, потому что на стеке куча объектов,
потому что, да. Есть ли идея не у семинаристов? Вот, да. Но я спойлер уже там показал один раз,
как можно разрушить все объекты, как можно разрушить состояние всех объектов на файбере,
на стеке файбер. Ну, кинуть exception, который начнет разворачивать стек файбера, вызовет
деструктора всех объектов на стеке, и вот файбер освободит все ресурсы, которые он там захватил.
Всю память. Ну, короче, у вас вот обычная рай. То есть, менеджмент ресурсов связанный с скопами.
У нас будет специальное исключение и файбер, когда он... и файбер. Давайте я покажу сейчас.
Так, я не там, где я хочу.
Fiber run. Тут symmetric transfer. Вот. Файбер запускается, делает свой шаг, и из него вылетает либо исключение
любое, либо специальное исключение. И это специальное исключение, оно специальным образом
обрабатывается. Ну, тут похожим образом обрабатывается, но есть некоторая разница,
есть некоторый супервизор, про который пока не понятно ничего. В общем, специальное исключение
для отмены файбера. И теперь возвращаемся к нашим примерам. Вот код, который может отменяться,
и в котором нет никакой специальной ручной машинерии по вот этой отмене. Это хорошо. Это важно,
потому что пользователь может, который пишет файбер, ему не нужно думать, как именно поддержать
отмену. Об этом думаем мы, разработчики фреймворка, в асинхронных операциях, которые мы реализуем. Вот
именно в этих асинхронных операциях, в точке, где файбер останавливается, возобновляется,
мы можем проверять этот флажок и выбрасывать исключение, которое вот прозрачно разворачивает
нам стэк, освобождает ресурсы и таким образом отменяет работу файбера. Это с файберами.
Что касается файберов. Дальше вторая половина. Что касается фьюч. Как с ними быть? Ну, вот мы говорили,
что фьюча... А давайте я открою картинку. Я вам дико рекламирую, если вы до сих пор не прочитали.
Ну, вообще, я на следующем занятии последним расскажу, какие статьи непременно стоит прочитать.
Ну, это стоит уж точно. Я рассказал вам про эту статью про фьюча, про то, как можно на фьючах выразить
вообще всю свою логику. И в этой статье вот есть замечательная иллюстрация, которая мне сейчас
нужна. С помощью фьюч, с помощью вот разных комбинаторов мы можем параллельной композиции,
последовательной композиции, мы можем выстроить такой граф обработки запроса. Вот, этот граф...
Ну, тут стрелки ориентированы... Странная картинка. Она могла быть нарисована по-другому. Ну,
смотрите, с помощью фьюч мы выстраиваем, по сути, граф. У него есть истоки, это продюсеры,
которые что-то вычисляют. Есть промежуточные узлы, это комбинаторы. Дождаться двух ответов,
дождаться первого из двух ответов. И у нас есть консюмер, который дожидается в конечном счете,
в счете подписывается на результат или что-то подобное. Вот мы выстраиваем такой граф, и он
ориентирован как? Ну, если мы смотрим на эту картинку, если мы говорим про какие-то развилки,
вот такое дерево. Вот это как бы логика порождения запросов сверху вниз. Но на самом деле фьючи,
они ориентируют граф в обратном направлении. Когда мы выстраиваем весь граф, то у нас же
результаты, то есть ошибки и ответы идут сверху, снизу вверх. То есть у нас такой граф, в котором есть
истоки, это продюсеры, и единственный сток – это вот консюмер, в которого все сходится. Это что
касается результатов, ошибок или значений. Но если мы выстраиваем асинхронные вычисления не с
помощью файберов, а с помощью фьюч, нам же нужно в этот граф отправлять сигнал-отмен в обратном
порядке. Ну, в обратную сторону. От консюмера к продюсерам. А фьючи так не умеют. Да? Что
можно было бы делать? Ну, можно было бы в каждую асинхронную операцию передавать явно стоп-токен,
по-прежнему. Сейчас, ну, примеров у меня готового нет, но это и, наверное, и так понятно. Мы запускаем
в третпуле вычисления, бросаем туда стоп-токен, получаем фьюч, а дальше вычисляем что-то,
если проверяем стоп-токен. Но опять это явный код, мы опять явно передаем стоп-токен. Как
можно было бы делать это не явно? Кто понимает? У нас ограничено время вообще? После 45 минут или?
Хорошо, воспользуемся этим. Ну, тема важная, правда. Лекция новая, тайминг непредсказуемый,
я читаю это второй раз в жизни, все еще очень спонтанно. Смотрите, на что я хочу обратить
внимание. Что вот есть, есть задача, как можно интегрировать cancellation во фьючи. И тут нужно
увидеть связь между двумя картинками, которые не помещаются на экран, черт возьми. Есть promise
и future, есть producer и consumer. И продюсер отправляет через promise значение, через shared state
консьюмеру. Через фьючу мы читаем. И есть этот shared state, который алоцирован на куче,
потому что опять непонятно, кто завершится раньше. И вот ровно здесь хранится результат. А с другой
стороны есть стоп-токен и стоп-сорс. И мы через стоп-сорс отправляем сигнал отмены и, ну,
через стоп-сорс мы отменяем асинхронную операцию, пишем сигнал в стоп-стейт и через
стоп-токен его проверяют. И опять пишет сигнал, отправляет сигнал консьюмер, пишет,
читает сигнал, простите, продюсер. Вот видите, какая-то двойственность есть такая, очень
естественная, естественно, наблюдаемая. Что? Сокет, господи. Нет, я хочу сказать,
что shared state, он же и стоп-стейт. И я хочу так и написать код. Секунду. Где у меня фьючу?
Откуда все это взялось? Фьюча, shared state, и смотрите, она наследуется от стоп-стейта. Ну,
то есть с одной стороны в этом shared state лежит результат callback, а с другой стороны в этом
shared state лежит еще и флажок стоп-реквеста, который наследуется вот отсюда. И смотрите,
что я теперь могу сделать. Ну, это уже начинаются какие-то такие хитрые штуки. Я в них уверен на
процентов 80, в смысле, что вот так и нужно делать. Но мне кажется, что так все выглядит пока разумно.
Я хочу поканцелить операцию асинхронную. Вот я запустил асинхронную операцию, вот у нее есть
промисс. И я теперь говорю, что через промисс можно читать флажок. Стоп-реквест. Вот у меня есть
фьюча и промисс. Промисс я даю асинхронной операции, и вот она крутится периодически,
проверяя, что нужно или не нужно отмениться. А теперь, смотрите, самое красивое. Я беру фьючу
f1 и подвешиваю к ней продолжение f2. И вот в этом зене скрыто связывание стоп-токенов. Вот я говорю,
на f2 cancel, а отменяется у меня вот эта операция. Опять никакой ручной инструментации,
никакого ручного аннотирования всего этого нет. Ну, смотри, если бы я хотел написать,
например, в десять раз больше и сложнее и замылить основную идею этого кода, я бы,
наверное, так и сделал. Но я не хотел. Нет, в смысле, этот код, он, конечно, бессмысленно,
потому что… Ну, ладно. В этом коде нет смысла, потому что ничего не делать полезного. Он просто
иллюстрирует отмену операции, которая что-то долго вычисляет. Здесь бесконечно долго вычисляет,
вообще ничего не вычисляет. Давайте посмотрим, что это работает. А код просто слишком новый,
вот он… Ну, ладно. Вот, операция отменилась, и мы не ждали ничего вечного, хотя могли бы.
Вот. Что происходит в этом зене? Смотрите, я говорю, у меня есть две future, это два shared
state и два стоп-токена. И у меня стоп-токены, они, смотрите, они немного сложнее, чем я вам
показывал. Ну, в смысле, они немного сложнее, чем просто поставить флажок и прочитать флажок,
конечно. Мне нужно еще уметь подписываться на флажок, вешать кулбэк, то есть выстраивать дерево
этих самых… Сигнал… Дерево этих самых стоп-стейтов. То есть, когда я… Когда я говорю f1 zen,
то я подписываюсь на результат future f1. Я хочу вызвать в кулбэке вот эту лямду,
которая обработает полученное значение. Но когда я подписываюсь, я заодно… Смотрите, у меня сигнатура…
Вот в этом месте я не уверен как раз. Я семантику subscribe у future немного расширяю. Я говорю,
что… Это не то. Я говорю, что у операции subscribe сигнатура теперь такая. Она возвращает
стоп-токен. Вот тот, кто подписывается на результат, должен управлять и отменой операции. И когда я
пишу zen, я пишу zen через subscribe, но это вот ваша домашка, которую стоит сделать. И я подписываюсь
на результат, а вместе с этим я связываю стоп-токен текущей future, новой, которую я строю, f2,
с токеном вот этой future. И в итоге я как бы с одной стороны в одну сторону строю граф,
сверху вниз. Граф из future shared-states, из операции shared-states. А с другой стороны параллельно
строю граф вниз из стоп-токенов, потому что мне в одну сторону нужно отправлять результаты,
а вниз мне нужно отправлять отмену. Схватываете идею? Да. Тут всякое может быть, но утверждается,
что… Еще 5% моих сомнений, что если написать все аккуратно, то оно с какой-то стороны
начнет разворачиваться и разорвется. Но это нужно аккуратно сделать, но это кажется,
что можно сделать. Здесь не должно быть вот прям циклов, потому что оно либо завершается,
либо отменяется. Что-то из двух случается непременно. Ну, потому что консюмер подписался на результат,
значит, он его ждет. Значит, именно он отвечает за отмену. Токен – это ссылка на stop-state,
а stop-states можно связать в граф. Да, это плохой код. Я могу получить стоп-токен и на нем руками
нажать отмену. Либо я могу стоп-токена спросить stop-state и связать его… Ну, смотри, тут все несколько
сложнее. Код, во-первых, еще сырой, поэтому запомнить нужно не реализацию, запомнить нужно идею,
что я строю граф в одну сторону и параллельно строю граф в другую сторону. Это такие двойственные
сущности, потому что двойственность берется отсюда. Я как shared-state и связываю в граф,
так и stop-state и связываю в граф. Просто в разные стороны ссылки ориентирую,
потому что в одну сторону летит результат, а в другую сторону летит отмена. Ну как, понятно,
да? Ну, точнее как, понятно ли, чего мы хотим достичь в итоге? Вот чтобы код выглядел так.
Довольно симпатично. А дальше, собственно, начинается тема лекции.
Вот. Значит, сменим резко тему. Ну, на самом деле не сменим, конечно. На самом деле я
хочу связать... Пока у нас конструкция очень простая. Мы либо вот в этом графе поднимаемся
снизу вверх, либо сверху вниз отменяем. Но реальность, на самом деле, сложнее. И вот тут
возникает понятие, которое называется structured concurrency, и в том числе ради которого мы сегодня
здесь собрались. И про это понятие есть чудесная статья, not structured concurrency,
or Go Statement Considered Harmful. И ровно поэтому этот комментарий был написан в самом начале
в шаблоне Файберов. И почему-то весь семейство никто об этом не спрашивает. Ну, один вопрос
кто-то задал, да. Это была ссылка на эту статью, потому что, смотрите, ну, забудьте про конкарнси.
Давайте подумаем про глубокую старину. Вот. И обратимся к фундаментальной работе,
DXTRA, про оператор GoTo. Вот это, мне кажется, оператор GoTo, критика этого оператора и
термин structured programming — это гораздо более фундаментальная вещь, чем знакомый вам,
видимо, алгоритм этого товарища. Вот нам сейчас гораздо полезнее вот вычисление кратчейших
путей structured programming. В чем идея? Итак, представим себе глубокую старину и некоторую
программу, которая написана на каком-то древнем языке, который, наверное, больше напоминает
Assembler. Ну, тут есть примеры таких программ. И вот смотрите, что можно сразу заметить,
что программа плоская. Это вот некоторый плоский текст инструкций. И эта программа выполняется,
и по этому тексту движется instruction pointer, передается управление. И управление передается с
помощью такого универсального инструмента GoTo. Мы можем просто прыгнуть в некоторую метку.
Ну и так можно написать, в принципе, любой код. Более того, компилиаторы, когда компилируют ваш
код, могут переписывать все ваши циклы и там if и все такое в этот GoTo. Но когда вы пишете
какую-то прикладную задачу, то использовать оператор GoTo, возможно, не лучшая идея.
И не то чтобы вам будет сложно, не только вам будет сложно. Смотрите, о чем я. Когда у вас есть
для передачи управления только оператор GoTo, то очень сложно описать состояние исполнения в вашей
программе. Вот вы находитесь в какой-то строчке, но как вы туда попали? Почему вы туда попали? Что
вообще происходит в вашей программе? Очень сложно понять. Очень сложно отследить траекторию.
Что пишет Dextro? Он пишет чертовски разумную вещь, что вот возможности человеческого интеллекта,
они ограничены. Вот человеческий интеллект, он пытается визуализировать что-то. И нам гораздо
проще думать не про какие-то сложные динамические системы, которые очень часто меняются, а куда-то
двигаются. Ну скажем, нам сложно думать про интерливинге потоков, поэтому мы и страдаем
этот семестер, вот думая, как там все переключилось. Человеку гораздо проще представлять какие-то
статические структуры, вот просто их легко визуализировать. Поэтому было бы хорошо, если бы
исполнение программы было бы согласовано с некоторой статической структурой,
которой можно было бы себе изобразить. Поэтому Dextro говорит, что возможно стоит заменить этот
GoTo на какие-то более ограниченные конструкции. Скажем, оператор видвления, оператор цикла,
оператор вызова функции. И вот эти операторы, они будут структурировать поток управления. Вот,
ну есть даже теорема, которая называется Structured Programming Serum, которая говорит,
что вот на самом деле мы так не ограничиваем вычислительные возможности свои. То есть,
если мы используем только такую передачу управления, то мы по-прежнему можем вычислить
все что угодно. Мы же ограничиваем все-таки себя. В GoTo у нас было больше свободы. Но сейчас мы себя
ограничим и на самом деле мы из этого ограничения получим ясную структуру программы, которую в
теории компиляторов языков программирования называют Control Flow Graph. Сейчас я найду какую-нибудь
ссылку про это. Вот думать о структуре программы нужно не только вам, разработчику, нужно думать
и компилятору, потому что компилятор часто про программу доказывает что-то. Ну скажем,
он занимается тем, что пропагетит константы. Вот вы объявили две константы, потом где-то вы их
перемножили, а потом что-то еще сложили. Вот компилятор хочет уметь эти константы, все эти
вычисления выполнить при компиляции статически, перед исполнением программы. А для этого ему нужно
понимать, вот когда какую-то переменную умножают на другую переменную, какие значения переменная
может принимать. Если только одно значение, то, видимо, не нужно просто использовать перемены,
лоцировать память, поддерживать ячейки, а нужно просто константу записать в этой местопрограмме.
Вот комператору нужно, комператор хочет такие свойства доказывать. Или, я не знаю, вы любитель,
вы любитель, вы любитель Раста и любите, не могу хорошую ссылку быстро найти, проклятие. Секундочку.
Нет, garbage collector здесь ни при чём. Да ладно, может быть, мне эта ссылка сойдёт. А может быть,
у меня здесь есть подходящая. Нет. Ну, в общем, идея. Если в вашей программе есть структура,
то есть вы можете каким-то образом её из текста программы вычленить, и то...
Дальше вы на месте комператора можете на основе этой структуры прям доказывать что-то про вашу
программу. Ну, вот я говорю про Rast, потому что там есть Liveness анализ, он используется в
Borough Checker, Rast известен в первую очередь по нему, потому что вы там не можете случайно написать
что-то в вектор, когда этот вектор перелатировал свой внутренний буфер. Ну, вот для того, чтобы
Rast мог отслеживать такие потенциально опасные программы, ему нужен какой-то механизм для того,
чтобы доказывать, что вот у вас есть две переменные, через которые вы дальше в будущем можете
обращаться к одной и той же памяти. И для этого используется вот тоже такая структура, которая
называется Contraflow Graph и Dataflow Analyze, ну, в частности Liveness Analyze, живость переменных
так называемые. В общем, если в программе есть структура, то, во-первых, вам проще думать про
исполнение этой программы, потому что любая траектория исполнения — это теперь некоторые,
ну, просто стэк вызовов. Это некоторые путь вот в вот в таком графе, ну, некоторая веточка,
которую вы выбрали. Вот вы пошли сюда, или вы пошли вот там пару раз сюда, или вы прошли через
функцию. Вам удобно думать, где сейчас программа остановилась, в каком она состоянии, и это просто
хороший инструмент абстракции. Вам не нужно думать, как реализована функция, вам нужно знать только
её сигнатуру, как её вызвать и как получите ответ через какие регистры. Вот это очень мощная идея,
вот она изменила программирование, достаточно давно уже, там, полвека назад, может быть,
больше. Почему она навожена нам сейчас? Ну, нет, подождите, рано пока. Почему она, да, как она
косвенно относится к нашей лекции? Потому что мы говорим в том числе про обработку ошибок сегодня.
Вот отмена — это одна история, вторая половина — это обработка ошибок. Вот структурное
программирование делает обработку ошибок проще, потому что если у вас есть понятная траектория в
исполнении, которая представляется в виде коллстека, то вам легко ошибку передать выше, до той точки, где
её обработают прозрачно, с помощью исключений. Вот вы бросаете исключение, потом где-то выше по
стеку его ловите, и этот механизм, он для промежуточных вызовов прозрачен опять. Чувствуете некоторую
связь между происходящим до и сейчас? Опять прозрачный механизм для обработки ошибок. Ну,
по поводу того, хорошие исключения или плохие — это отдельная история, сложная. Мы сейчас не хотим
её обсуждать. Ну вот структурное программирование позволяет, в частности, использовать для обработки
ошибок исключения, и рай, то есть деструктора, то есть core-based resource management, позволяет вам
освобождать ресурсы опять же автоматически, когда разворачивается стек, когда летит исключение.
Всё потому, что у вас есть структура. Так, уложилось-то? Вот, а теперь я хочу эти идеи соединить.
Ну, такое синтаксическое наблюдение пока, что Go2 и Go — это похожие штуки. Ну так, вот можно
углядеть в некоторую аналогию между ними, что когда мы говорим Go2, мы куда-то прыгаем, и вот
мы структуру теряем. Когда мы говорим Go, то у нас развилка, мы продолжаем с одной стороны исполняться
прямо, с другой стороны мы запускаем какую-то синхронную операцию, и тоже теряем с ней всякую
связь. У нас теперь две независимые ветки. Вот утверждается, что в этот момент теряется структура,
а структура, разрушенная структура, мешает нам решать задачи. Смотрите, почему мешает. Ну вот,
допустим, допустим, у вас есть в запросе такая развилка. Мы отправляем два под запроса на два
сервиса, и мы хотим дождаться ответов от обоих сервисов. Ну что, если вот при запросе к этому
сервису случилась ошибка? Ну вот, у нас ситуация такая, что нам не нужен теперь ответ второго
сервиса, потому что все, у нас операция провалилась. Мы пока об этом не думали, мы говорили, что либо у нас
сверху снизу поднимаются результаты, либо у нас сверху прилетает cancellation самого верха. На самом
деле все сложнее, потому что у вас есть такой граф, и отсюда прилетают не просто результаты,
отсюда прилетают либо значения, либо ошибки. И вот если отсюда прилетела ошибка, то отмена
операции пойдет не отсюда, а вот отсюда, видимо, должна пойти. То есть, смотрите, если мы в операции
А получили, у нас был форг, мы породили две подзадачи, и из подзадачи мы получили ошибку,
то нам не нужно дождаться операции Б. Это правда.
Давай дорабатывать лекцию во время лекции. Вот, это один сценарий, понятный, да? Что-то пошло не так.
Вот, то есть у нас сигнал отмены родился где-то в корне по дедлайну, а он родился где-то в
промежуточном узле, потому что у нас оператор, комбинатор all разломался. Если мы говорим про first
off, то какой сценарий в нем будет реализован? Нет, нам ошибка, нам, подожди, мы не про ошибки
теперь говорим, мы говорим про результат. Если отсюда поднялся результат, то нам просто второй не
нужен уже. Вот, и теперь смотрите, что получается, что у нас теперь вот этот граф, ну как бы по нему
текут отмены и результаты немного сложнее, не просто сверху вниз или снизу вверх, а они текут вот как бы
сначала снизу, а потом снизу вверх, а потом в разные стороны, то есть наверх течет отмена,
наверх течет ошибка или результат, а вниз отправляется cancellation. Вот то есть граф становится более
сложным, у нас такой сигнал раздваивается. И к чему я клоню? К тому, что вот теперь кажется задача
комбинатора вот это реализовать. А причем здесь structured programming? Structured programming говорит,
что когда вы что-то делаете, как вы выстраиваете поток управления, вы выстраиваете его так,
у вас есть одна точка входа всегда и одна точка выхода, у вас могут быть какие-то форки,
но у вас вы в одном месте зашли, в одном месте вышли, у вас за форком всегда есть join. И вот если у
нас за форком, то есть за двумя параллельными запросами, смотрите, нет, не сюда смотрите,
это мы уже видели, если мы делаем два параллельных запроса, а потом пишем такой код, то если второй
запрос сломается, то мы все равно дождемся первого. Вот этот код и этот код, они выглядят
эквивалентными, но нет, потому что поведение у них может быть разное. Здесь у нас join нет,
а здесь у нас есть точка join, то есть мы разветлились, а потом снова склеились. И вот там, где мы склеились,
это точка, где мы можем получить один из сигналов и сделать вот эту отправку, сделать развилку в
смысле cancellation и ошибки, reconciliation и result. Это та же идея, что и structured programming.
У нас в concurrency теперь как бы ошибка, сейчас запутался, когда мы говорим про structured
programming, у нас когда ошибка летит, она разматывается так, потому что есть просто одна ветка. Теперь у
нас граф сложнее, там есть развилки, но если за развилками есть join, то в этом join ошибка,
прилетев в этот join, может через этот join разветвиться и отправиться с одной стороны дальше,
а с другой стороны отправить отмен. Вот без этого join ничего не выйдет, поэтому основной тезис,
который описан в этой замечательной статье, что оператор Go и вот такой просто асинхронный вызов
чего-то, это плохая идея, потому что за любой развилкой должен быть join. И с фьючами это получается
все довольно элегантно. Вот all, комбинатор all подписывается на две фьючи, и если он из одной
получил ошибку, то он пропагетит ошибку отмену во вторую фьючу. То есть там вот есть в одну
сторону сигнал и в другую сторону сигнал. Ну давайте я даже в коде это покажу. Он, наверное,
плохо написан, ну пожалуйста, не стреляйте в пианиста. Опять я не там.
Вот да, я получил ошибку и я с одной стороны отправляю request-stop, а с
другой стороны говорю с отэррор на верх. Вот эта самая развилка, которая есть в комбинаторе.
При условии, что я вот этот граф сплёл в обе стороны, то я могу вот в обе стороны
все отправлять. Это что касается фьюч, теперь мы хотим... да, и давайте я покажу пример вам.
теперь... Вот, две future, мы запускаем два вычисления в пуле, здесь 10 секунд ждём,
здесь 3 секунды ждём, потом говорим first of и потом дожидаемся, пока всё завершится. То есть,
всё не завершится, пока... Ну, в смысле, пример не завершится, пока не завершатся две операции. И вот
мы теперь готовы это, например, запустить. Видимо, он проработает 3 секунды, а не 10,
потому что там будет автоматическая отмена. Раз, два, три... Сломалось. То есть, мы получили
двойку отсюда и отменили вот эту операцию. И всё это случилось абсолютно прозрачно для пользователей.
Ну, то есть, как бы, конечно, сама операция должна поддерживать отмена, но это уже некоторая
мышленырия. Ну, скажем, кто может продать future? Продать future может RPC Framework. Вот. И, как бы,
пусть он занимается тем этой проверкой этого stopRequested. Вот. В коде всё равно никаких
промесов не бывает, но это вы почувствуете, наверное, осенью, те, кто захочет это почувствовать. Ну,
в коде промесов объективно не бывает. В коде есть только future, и в комбинаторах этих future скрыто
провязывание всех этих токенов, и всё автоматически работает. Что касается файберов, у файберов такой
развилки пока нет. И мы хотим её построить. Эта развилка называется nursery. И вот в статье
про structure concurrency, тут про future ничего нет, поэтому это такой экспромт. Здесь описан объект nursery,
который представляет себе scope файберов. Мы говорим, что если мы файберы запустили,
то мы обязаны его дождаться. Всегда у нас за развилкой должен быть join. И мы пишем объект nursery,
у которого есть операция spawn, которая рождает новый файбер, а ещё есть операция
по порядку. Нет, это есть пример. Пример попроще, секунду. Вот, мы запускаем файберы, и у нас есть
у nursery метод join, который дожидается, пока все файберы завершатся. Этот join должен быть,
потому что вот эта точка, где мы связываем все вот эти развилки, fork, соединяем обратно.
Как устроен этот nursery? У него собственный стоп-токен. Да, и чего мы от него ожидаем? Смотрите,
мы, зачем он нам нужен? Ради чего всё? Вот мы запустили два файбера. Один работает бесконечно,
а другой ломается через две секунды. И когда первый сломается, мы хотим, чтобы отменился второй.
Вот ровно поэтому мы связали их в scope, и поэтому мы требуем, чтобы за каждым
spawn был join дальше. То есть мы всегда дожидаемся всех файберов, которые мы запускаем. Это такое
ограничение, которое мы вносим в нашу программу. И за счет этого ограничения мы получаем прозрачную
отмена. Как это работает? Ну вот допустим, да, у каждого файбера, я показывал вам этот код уже,
у каждого файбера при старте есть супервизор. Супервизор — это некто, кто понимает, что с
файбером произошло. Файбер успешно завершился, файбер отменился, файбер разломался. Когда вы
запускаете файбер, то если он разломался, то вы сообщаете об этом супервизору. А супервизор в случае
nursery — это nursery. Тупое предложение, извиняюсь. И вот смотрите, когда на nursery, ну когда вы
вызываете spawn файбера, то вы стартуете новый файбер в качестве супервизора и передаете себя и
передаете stop токен этого nursery. Вот nursery является stop source, он порождает токены. И если вдруг в этом
nursery разломался файбер, то мы говорим stop source, stop request, stop. И все остальные файберы этого nursery,
которые получили этот токен, они отменяются. Вот опять та же идея, если у нас есть развилка,
у нас должен быть join и вот nursery это обеспечивает. Вот таким образом мы можем, получается, опять
прозрачно выполнять отмену двух расправильных операций. Ну или можно какие-то дикие комбинации
написать. Я вот написал, это выглядит жутко, но ужасный код, но дело не в этом. Смотрите, у меня
есть некий файбер и он есть, ну как бы есть планировщик, полпоток. Я бросаю в него какую-то
операцию, которая бесконечно крутится. Я подвязываю к фьюче этой операции какое-то продолжение,
потом я строю nursery, в нем запускаю два файбера и в одном из них я жду этой фьючи. Ну то есть
какой-то сложный граф плетется бессмысленный. А дальше я говорю nursery cancel и что происходит?
nursery cancel cancelит stop-token. Этот stop-token связан со stop-token. Когда я говорю await, то есть синхронно
дожидаюсь фьючи. Что я делаю? Я, да, когда я дожидаюсь фьючи, вот здесь, то я связываю
token fiber и token future, чтобы когда файбер решит отмениться, он поканцелял бы фьючу. А в этом
зене связывается token future f2 с token future f1. Token future f1 проявляется в итоге здесь. И когда
я говорю cancel на nursery, то отменяется, во-первых, файбер в этом nursery. Этот файбер отменяет,
ну как бы в stop-token файбера появляется единичка, поэтому он завершится. А кроме того,
он прокидывает единичку в stop-token f2, она прокидывает через этот зен stop-token в f1,
и вот снизу вверх всё отменяется, и этот пример завершается. Вот довольно удивительно,
что это работает, но можно в этом убедиться. Вот, и этот пример убеждает меня, что происходит
нечто разумное. Честно говоря, долго я над этим думал, над всем, но кажется, что вот то,
что придумалось, оно похоже на правду. Вот оно как-то гармонично сочетается, и всё вот. Вот есть
многие технические детали, как это сделать быстро, потому что сейчас это работает неэффективно
в разных местах. Как там с циклическими зависимостими аккуратно разобраться. Но это
всё проблема, которая выглядит, честно говоря, решаемыми скорее. А вот фундаментально принцип
такой вот, что мы строим два графа в разные стороны, и вот учимся... Ну, мы, когда говорим про граф
асинхронных вычислений, мы должны понимать, что по нему текут два типа сигналов. Ошибки,
результат, ошибки или значения снизу вверх и consolation сверху вниз. И что вообще-то они текут
не просто сверху вниз, с самого верха вниз и с самого низу вверх, а что они могут как-то вот течь,
вот как-то так, ну сложно представить себе, как это происходит. Но если за каждой развилкой в вашем
коде есть join в виде nursery или в виде комбинатора, то мы гарантируем, что где бы ошибка не возникла,
она запропагетится на весь граф. Это такое очень мощное свойство, которое... И вот в этом состоит
идея structured concurrency, которая из этой статьи мне совершенно не прочиталась, но через некоторое
время она ко мне независимо пришла, но вот ровно об этом здесь человек и говорит. Вот он просто
говорит только про... Не говорит про future, но вот на future все это тоже обобщается. Если у вас за
любой развилкой есть join, то вы можете гарантировать такие простые варианты, что все отменится. По этому
графу любой сигнал может эффективно распространиться. И что самое приятное, абсолютно прозрачно для
пользователя. То есть вы просто пишете код, потом в одном месте у вас что-то ломается, просто exception
бросается в ваш, а дальше все магически, автомагически отменяется, пропагетится и ресурсы
освобождаются. Вот без этого production code представить сложно, ну потому что ресурсы, значит, мы копились
тогда. Где-то что-то потерялось, какой-то файбер бесконечно крутится, все, у вас утекает память. Вот
поддерживая такой вариант, ограничивая себя, то есть запретив себя вот этот go и заставив писать
явно join, что выглядит немного противоестественным поначалу, вы можете достичь такого очень мощного
свойства в своем коде. Ну вот, на этой радостной ноте, я надеюсь, мы заканчиваем новые темы в
нашем семестре, и я вас приглашаю обязательно приходить на следующую лекцию. Мы с вами через
неделю поговорим про вот все вместе, выстроим одну, надеюсь, общую картину, ну и я с удовольствием
отвечу на ваши вопросы, которые у вас после курса останутся. Спасибо.
