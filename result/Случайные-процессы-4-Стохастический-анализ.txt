поехали на прошлой лекции я вел вам новое для вас важное понятие винаровский процесс и
описал примерно откуда он берется это его еще называют броновским движением началось все с того
что если мы наблюдаем частицу в жидкости мелкую и будем следить за ее координатом это мы увидим
что она как бы трясется да то есть координат представляет собой некий случайный процесс вот
броновский процесс броновского движения левинарский процесс этот модель для описания движения такой
частицы и движение этой частицы обусловлено тем что на нее то и дело со всех сторон давит молекулы
соударяются в очень малом промежутке времени на нее воздействует огромное число молекул и
движение определяется именно этим и это можно формализовать вот этот факт то что
винарский процесс получается как сумма большого числа вот этих соударений вот и я хочу вам сейчас
привести доказать теорему о связи винарского процесса и процесса случайных блужданий то есть
сумма так теорема которая говорит следующим значит пусть случайные величины кси 1 и так
далее кси n ну и так далее независимые совокупности вот математическое ожидание
существует равно нулю и сперсия у них тоже существует и равна некоторой сигме квадрат
который будем считать одинаковый для всех этих случайных величин вот тогда
тогда
конечномерные распределение процесса вот такого xnt равняется единице разделить на
sigma корень из n сумма по х от единицы до целой части nt т у нас не обязательно целая да но
вот есть до целой части nt кси катах то конечномерные распределения вот такого процесса поточечно
сходятся к соответствующим конечномерным распределениям винарского процесса вот
но пояснение вот можно картинку такую нарисовать почему этот мы так это интерпретируем что это
некие случайные блуждания суммы соударения легко посмотреть на это так возьмем t равная единице
т у нас целая и тогда целая часть nt это просто n ну просто для простоты понимания вот единицу
возьмем здесь у нас t направлено единицы тогда если n равняется единичке то здесь стоит 1 разделить
на сигму кси 1 вот ну давайте для простоты также считать что наши кси они ну скажем принимают
значение только плюс минус сигма здесь-то на самом деле не обязательно это какие-то плюс-минус
чего-то да здесь это могут быть самые разные случайные величины лишь бы мы от ожидания было
ноль а дисперсия была сигма в квадрате вот ну допустим что это так может быть некоторые постоянные
там к сигма ну так вот она надо только чтобы дисперсия была равно сигме ну и вот тогда здесь
получается сигма кси 1 разделить на сигму вот и значение процесса в точке 1 если здесь он был
ноль это будет определяться только одной случайной величиной вот одна молекула ударила все значение
в этот момент времени вот такое если мы рассмотрим n равняется двойке то тогда смотрите при t равном
1 при t равном 1 n равно 2 и здесь уже сумма двух случайных величин вот с теми же самыми
распределениями но они поделятся правда еще на корень из n так что значение процесса в момент
1 будет уже суммой двух случайных величин ну скажем вот это у нас поднималась мы берем ту же
самую кси 1 но теперь мы ее поделим на корень из два вот она опустится вот и нужно прибавить еще
следующую случайную величину которая у нас не было до этого но допустим она падает да падает на
какую-то величину можно она даже даже пусть она даже попала в эту единицу вот это у нас было при
n равном 1 это у нас было при n равном 2 мы n увеличили добавили одну случайную величину понизили
как бы силу каждой случайной величины, умножили на один делить на корень из 2, и
поэтому у нас здесь они немножечко сильнее прижались к нулю, но их стало больше на одну,
теперь у нас здесь две случайных величины, здесь была прямая, здесь уже вот два, здесь
был один отрезок, здесь уже два отрезка. Теперь если мы возьмем n равное 3, то здесь будет уже
сумма трех случайных величин делиться будет на корень из 3, то есть мы должны сильнее ужать,
но у нас будет больше случайных величин. Это у нас поднималось, это у нас опускалось,
так сейчас, только не до половины, а до трети. Это поднималось, это опускалось,
следующее, допустим, тоже поднимется. Вот. Это уже n равное 3. Ну и так далее. И в
пределе это будет какая-то кривая. Вот. И оказывается, что эти кривые это
реализация некоторого процесса предельного, у которого, конечно, мерное
распределение совпадает с Винерским процессом. То есть, это будет Винерский процесс.
Вот такое вот пояснение к тому, что здесь написано. То есть, как мы видим, мы можем в
смысле вот этой сходимости приближать Винерский процесс вот такими процессами,
как сумма независимых одинаково распределенных случайных величин с такими характеристиками.
Доказательства. Доказательства будем проводить так. Ну давайте введем, во-первых, обозначение нам
полезное. Сn мы будем обозначать сумму k равным от единицы до n кс. Вот. И докажем, что сначала
докажем, что одномерное распределение xn сходится к одномерному распределению v от t. Вот.
То есть, докажем, что единица разделить на sigma корень из n, сумма k равным от единицы до n,
t и kt входится по распределению при н, стремящемся к бесконечности, к vt. То есть, случайно в величине
с распределением v от t. А она распределена как n0t. Вот. Если мы это докажем, то мы докажем
сходимость одномерных распределений. Мы взяли сечение. Мы зафиксировали t. Взяли
сечение xnt. Это вот эта случайная величина. И показываем, что она сходится к соответствующему
сечению, тот же самый момент t, для винорского процесса. Вот это нам предстоит доказать сейчас.
И тогда мы докажем, что одномерное распределение этого сходится к одномерным распределениям того.
И чтобы это доказать, нам нужно действовать так же, как мы доказываем центральную предельную
теорему. То есть, вспомнить о том, что сходимость по распределению равносильна по точечной всюду
сходимости характеристических функций. То есть, мы запишем char функцию вот этой вещи и докажем,
что она по точечной сходится к char функции вот этой случайной величины. Тогда это будет означать,
по теореме неперерывности, что сходимость по распределению имеет место. Ну вот, мы пишем тогда
характеристическую функцию. Вот тут я ввел обозначение, поэтому я сокращу. S целая часть nt,
а t с маленькой. Это аргумент характеристической функции. Значит, что это такое по определению?
Математическое ожидание i s и умножить на единицу разделить на корень из n фигма. И тут у нас,
ну давайте мы так напишем, я распишу x1 плюс и так далее, плюс x целая часть nt. Но экспонент,
а сейчас, и тут экспоненту я забыл, экспонента, экспонент от всего этого. Значит, экспонента от
суммы равна всегда произведению экспонента. Мат ожидания произведения не всегда равно
произведению мат ожиданий. Но у нас случайный величины ks независимо в совокупности по нашему
предположению. Поэтому и функции от этих кси тоже независимы, а значит, математическое ожидание
произведений этих функций равно произведению математических ожиданий, этих функций. Ну,
ну давайте я наверху продолжу значит получается произведение по g равном от единицы до nt
математических ожиданий экспонента от значит i s 1 разделить на корень z sigma
на x jt вот а это есть характеристическая функция вот этой случайной величины
вот в этой точке s разделить на корень z sigma вот то есть произведение g равном
от единицы до n характеристическая функция x jt значит от чего точки s разделить на корень
z sigma дальше так как у этой случайной величины существует математическое ожидание дисперсия
это значит что мы можем записать такую вещь мы можем представить функцию фи приблизить функцию
фи в окрестности s равняется 0 формулой т лора вот это получается единица так как
математическое ожидание равно нулю поэтому слагаемого пропорционального и умножающегося
на есть здесь не будет поэтому пишем минус и минус потому что мимо единицы в квадрате умножить
на дисперсию полам то есть на s в квадрате разделить на 2 n sigma в квадрате да
ой здесь dnt спасибо спасибо вот n значит здесь умалое умалое и здесь в степени а в какой а не
в какой вот произведение мы берем произведение вот таких штук вот произведение таких штук они
все одинаково распределены поэтому вот эта внутренняя часть она джи не зависит так что по
сути здесь написано просто 1 минус s в квадрате разделить на 2 n sigma в квадрате плюс умалое от
1 разделить на n в степени целой части nt вот так и нам остается устремить только n к бесконечности и
посмотреть к чему это сходится но прежде чем это делать давайте мы так поступим мы внутреннюю
часть возведем в степень n а внешнюю часть в 1 делить на n тогда мы получим тогда мы
получим 1 минус s в квадрате разделить на 2 n sigma в квадрате плюс умалое 1 разделить на n
все это в степени n и вот они фигу квадратную не надо а то будете думать что это целая часть
пусть будет круглая вот это в степени nt разделить на n но вот ну и к чему тоже все сходится значит
по теоремам изматонализа мы знаем что внутренняя часть вот это при n стремящимся к бесконечности
сходится к е степени минус s в квадрате так сейчас это мне не нравится или все нормально
так
ну допустим значит все это сходится к е степени с квадрата разделить на 2 sigma в квадрате вот так
так а к чему сходится вот эта вещь значит мы можем написать числитель как просто nt без всяких
скобок минус дробная часть nt и разделить на n и тогда у нас получится просто t минус дробная часть
nt деленная на n и мы видим что если n стремится к бесконечности то так как вот это ограничено
оно принадлежит от нуля до единицы то деление на n делает ее бесконечно малой так что это
стремится к нулю а t это t так что получается что все это сходится вот sigma квадрат мне осталось
вот это странно ну ладно значит это все сходится к е степени минус s в квадрате разделить давайте так
s квадрат t разделить на 2 sigma в квадрате вот sigma квадрат да так ну это характеристическая
функция какой случайной величины нормальный с параметрами 0 t разделить на sigma квадрата
получается разделить на sigma квадрат что не очень хорошо она тут нужно 0 t ну значит так здесь
мы получаем видимо да если это sigma это будет сходимый с ним к винарскому процессу а к винарскому
процессу с параметром sigma квадрат то есть когда там распределение это 0 запятая sigma в квадрате
модуль t-s вот ну а чужую меня сейчас одну секунду а нет нет нет подождите меня есть ошибка так меня
ошибка что я тут делаю я раскладываю по формуле t лора так мото ожидание у меня равно 0 там как
и в квадрате на второй момент а стоп а я вторым момент забыл у меня здесь стоит квадрат
с в квадрате n sigma квадрат двойку а второго момента у меня здесь нет вот а вы молчите второго
момента у меня здесь нет значит второй момент тигмы это получается sigma квадрате то есть
мотожадание кси в квадрате это дисперсия плюс квадрат мотожадания, который равен нулю.
Да, вот здесь сигма в квадрате, я забыл. Я забыл здесь сигму в квадрате. Второй момент. Так что на самом
деле сигма в квадрате сокращаются и здесь тоже сигма в квадрате не будет. Вот. И здесь тоже сигма в
квадрат не будет. И здесь тоже сигма в квадрат не будет. Вот. И здесь тоже сигма в квадрат не
будет. Сигма сокращается. Неважно какая сигма, она сокращается. Ну вот. А это характеристическая
функция случайной величины вот с таким распределением. И точно такое же распределение
имеет w от t. Все. Значит мы показали, что хр функция этой штуки сходится к хр функции этой штуки. Вот.
А это означает это равносильно, потому что эта штука сходится по распределению к этой
штуке. Вот. А это есть одномерное распределение процесса х, это есть
одномерное распределение процесса Винеровского. Так что сходимость одномерных распределений
мы таким образом показали. Вот. Все. Это что касается одномерного распределения. Теперь давайте
рассмотрим двумерные распределения.
Для того, чтобы показать сходимость для двумерного
распределения, нам понадобится один факт, который я доказывать
не буду.
Он заключается в следующем, что если xn-вектор, заставленный
из двух последовательностей, xn-это n, если вот эта штука
сходится по распределению при n, стремящемся к бесконечности,
к xi-это, то тогда отсюда следует, что xn-это n плюс xn сходится
по распределению при n, стремящемся к бесконечности,
к xi-это плюс xi.
Вот этим фактом мы воспользуемся, его можно найти, например,
в книжке Billings-Lee, Вероятностных мер, очень хорошая книжка
глубокая, которая изучает, в частности, Винерский
процесс, советую туда посмотреть, но вот этим фактом мы просто
воспользуемся здесь.
Это очень технический факт, он нам нигде не пригодится,
кроме этой теоремы, поэтому мы его возьмем без доказательства.
Одно из свойств сходимости по распределению.
Так, ну вот и как мы его применим, а очень просто,
для того, чтобы доказать, что вот эта вещь сходится
к v от t, v от s, нам достаточно, нам достаточно доказать,
что это будет следовать из того, что xc на t, ну давайте
возьмем t больше s, допустим, что вот эта штука сходится
как v от t на v от t минус v от s, чтобы просумировать.
Вот, при t больше, значит, если t больше s, то, так,
сейчас, а что тут у меня, все напутал, прошу прощения,
при t больше s рассматриваем.
Итак, если мы докажем вот это, то по вот этому факту
отсюда будет следовать вот это.
Почему мы так делаем?
Потому что трудно понять, какое совместное распределение
имеют эти x, чтобы исследовать на сходимость по распределению.
И здесь тоже они зависимы, эти случайные величины,
поэтому какая у них там функция распределения,
это сложно.
А в этом случае у нас получается, при t больше s, вот эти случайные
величины независимы, потому что процесс имеет независимые
а это проще исследовать.
И на самом деле, смотрите, что получается, все это очень
просто.
Значит, давайте рассмотрим вот эти все вещи.
Значит, вот это, то, что здесь написано, это единица
разделить на корень n сигма от s нt минус единица разделить
на корень из n сигма с ns.
И видите, множитель одинаковый.
Здесь мы суммируем от 1 до nt, а здесь от 1 до ns, s меньше
t.
И поэтому куча слагаемых от 1 до ns у нас сократится.
Так что по сути, то, что здесь написано, это есть единица
разделить на корень из n сигма при кси от ns плюс 1 плюс
и так далее, плюс кси nt, вот то, что здесь написано.
А вот эта вещь, это 1 разделить на n корень из n сигма, значит
кси 1 плюс и так далее, плюс кси ns.
Видите, здесь мы идем до ns, а здесь ns нет, мы начинаем
от него.
Но случайная величина кси независима в совокупности.
А это означает, что вот эта случайная величина и вот
эта случайная величина, эта сумма, они независимы.
Так что вот это и вот это независимы.
Значит, их функции распределения разбиваются на произведение
и характеристическая функция вот этого вектора равна
произведению характеристических функций вот этой и умножить
на хар-функцию вот этой вещи.
Ну и что получается?
Хар-функция этой вещи мы уже выяснили, что она
сходится к хар-функции вот этой вещи.
Хар-функция этой вещи абсолютно аналогична, выписывая все,
что у нас было, просто с точностью до переиндексации.
Мы приходим к тому, что хар-функция этой вещи сходится
к хар-функции этой вещи.
Но хар-функция всего это произведение этих двух
хар-функций, значит, это произведение сходится
к произведению хар-функций этих.
Все.
Доказано.
Значит, раз сходится хар-функция, значит, сходится по распределению.
А раз это выполнено, то по вот этому факту складываем
вот эту с этим, вот эту с этим, и приходим вот к этому,
мы доказываем вот этот факт.
Все.
то есть самое сложное в этой теореме это
выписать нечто похожее на центральную предельную теоремы для одномерного распределения, а здесь уже
элементарно получается
точно также можно это
выписать для
векторов с тремя компонентами тоже через независимые приращения и для произвольного вектора размерности n
вот то есть просто опираюсь вот на эту теорему
вот, ну такие вот детальные выкладки для случаев
более высокого порядка размерности я показывать не буду, мне здесь главное было вам указать некую идею, но я думаю что это будет достаточно для понимания, для доказательств
вот, на этом теорема завершена
свинерский процесс является в этом смысле пределом
случайных блужданий
случайным блужданием называется любой процессу такого вида, где стоит сумма каких-то независимых случайных величин
винерский процесс это предел случайных блужданий, но это вот предел в одном из смысла
конечно можно
найти теоремы о сходимости случайных блужданий к винерскому процессу в других более сильных смыслах на
функциональных пространствах в смысле
некоторых метрик, ну вот у меня в лекциях в pdf как вы можете найти там ссылки
где об этом можно почитать, как эту всю науку углубить, но это
выходит за рамки курса, поэтому мы пожалуй остановимся только на этом
ну вот
вот
ну и на этом мне
вот эту
ветку рассказа про гауссовский и винерский процесс хочется завершить
вот на этой теореме
мы с вами переходим к следующей теме
которая называется стахастический анализ у
вас уже было много разных видов анализа был математический анализ дискретный анализ
функциональный анализ у
кого-то еще выпуклый анализ но вот здесь стахастический анализ
то есть мы будем изучать случайные процессы
точки зрения
пределов разных смысле то есть там будем
изучать что такое непрерывный процесс что такое
дифференцируемый процесс
интегрируемые процессы в каких смыслах это можно понимать
как выяснить является ли процесс некоторый
непрерывным или интегрируемым как это связано с его траекториями и так далее и так далее
вот этой темой мы сегодня в основном и займемся
вот
значит как я уже говорил случайные процессы это функции
двух аргументов
исхода и времени
если мы хотим вести понятие непрерывности относительно времени естественно мы будем это вводить
дифференцируемость относительно t
там интегрируемости по t то тогда нам нужно будет что-то сказать о том как пределы
в этих понятиях в непрерывности
дифференцируемости интегрируемости как они связаны с этой омегой
но вы хорошо знаете из курса теории вероятности что
предел можно
понимать в разных смыслах бывает предел в среднем квадратичном по вероятности почти на верное по распределению
это все разные виды пределов
которые по-разному относятся к этой омеге
вот
соответственно можно по-разному вводить
непрерывность дифференцируемости интегрируемость можно рассмотреть понятие sk
непрерывности
sk
дифференцируемости sk
интегрируемости можно вести понятие почти на верно
непрерывности дифференцируемости интегрируемости
т.е. по вероятности
непрерывности дифференцируемости интегрируемости и по распределению
непрерывности
дифференцируемости интегрируемости и
И у вас в задании будет задача, где нужно будет исследовать винаровский и поассоновский процесс
на непрерывность, дифференцируемость, интегрируемость во всех вот этих смыслах.
Все они отличаются только тем, как они понимают предел.
Ну вот, напомню вам определение в среднем квадратичном.
Мы говорим, что последовательность xn сходится к x,
в среднем квадратичном, при n, стремящемся к бесконечности,
или еще говорят, сходимость в среднем первого порядка,
если математическое ожидание xn-x в квадрате
входит к нулю, при n, стремящемся к бесконечности.
Потому что xn и xy зависят от омеги от исхода,
но здесь мат ожидания квадрата,
и вот эта вещь, она уже от исхода не зависит,
это обычная числовая последовательность,
для которой существует из мат-анализа определение предела.
Так что мы говорим, что случайная последовательность
сходится к этой случайной величине,
если вот эта числовая последовательность сходится к нулю.
Вот и все.
Вот это определение сходимости в среднем квадратичном.
Сразу же скажу, то есть в этом определении есть тонкость.
В этом определении ничего не сказано о существовании
вторых моментов отдельно для xn-го и для x.
Обратите внимание.
То есть это сходится сюда в sk смысле, если вот это.
В принципе, мат ожидания квадрата не xn-го,
ни предела x может не существовать.
Ну, возьмите какую-нибудь случайную величину x,
у которой второго момента не существует.
И возьмите xn, тождественно, равный x.
Тогда здесь будет 0 просто стоять.
И получается, что в этом смысле последовательность сходится,
хотя никто из них, ни у кого из них по отдельности
мат ожидания квадрата не существует.
Ну, вот такая вот тонкость.
Единственное в этом определении есть.
Правда, для того, чтобы многие теоремы доказывать,
нам понадобится дополнительно предположить,
что у x, иногда у xn-го существуют конечные и вторые моменты.
Но в самом определении
конечности вторых моментов отдельных xn-го и x-а нет.
Вот, вот это выясните.
Значит, цитокосический анализ мы будем строить
на основе вот этой сходимости,
потому что это позволит нам получить очень много критериев,
как определить, что процесс является непрерывным, дифференцируемым, интегрированным.
То есть много результатов это дает полезных.
К сожалению, для этих сходимостей
подобных результатов я не встречал.
А здесь они существуют и элементарно доказываются.
Так что мы сосредоточим наше внимание вот на этом типе сходимости.
И будем строить всю нашу дальнейшую науку в основном вот здесь.
Так, ну хорошо.
Значит, прежде чем идти дальше,
я хочу вам привести три леммы,
которые нам пригодятся для доказательств следующих теорий.
Вот.
Лемма 1.
Это одна из самых важных лемм в вашем курсе.
Значит, она звучит так.
Пусть хм сходится к х в среднем квадратичном.
При м, стремящемся к бесконечности.
Пусть.
И пусть ун, я специально беру разные индексы.
Для меня это будет потом важно.
Это к при н, стремящемся к бесконечности, к у.
И пусть у х
существует конечный второй момент.
И у у существует конечный второй момент.
Тогда.
Математическое ожидание.
Хм, у, н.
Ходится, как обычная числовая последовательность,
потому что там от ожидания стоит.
При м, н, стремящемся к бесконечности.
К математическому ожиданию.
Ху.
Вот так.
Причем не важно, как м и н между собой там соотносятся при стремлении к бесконечности.
Доказательства.
Очень простое у этой теоремы доказательство.
Ну, немножечко техничное, но оно простое.
Значит, хм минус х.
Пишем ун минус у.
Значит.
Давайте мы рассмотрим вот такую скобку.
Значит, что это такое будет?
Так, это получается хм, у, н.
Минус хм, у.
Минус х, у, н.
Плюс х.
Так, и мне надо доказать, что м от ожидания вот этой штуки
вообще сходится к м от ожидания вот этой штуки.
Так, как мы тут поступим?
Хм минус х.
Давайте мы вот к этой вещи.
Так, сейчас, сейчас, сейчас, сейчас.
Я подумаю, что мы сделаем.
Смотрите, как мы сделаем.
Мы возьмем вот в этой вещи.
Здесь напишем двойку.
Или нет, сейчас, сейчас, сейчас.
Я напишу так хм.
Сейчас, дайте я сначала напишу.
А потом вы.
Я хочу выразить хм, у, н.
Минус х, у.
Через вот эту скобку и все остальное.
Значит, тогда я получаю хм.
Минус х.
На у, н, минус у.
Вот.
И что у меня останется?
Значит, ага.
Я здесь, считай, вычел минус х и добавлю х.
Давайте так.
Минус х плюс х.
Тогда у меня выделяется вот это и вот это.
Вот.
Они равны вот этому, минус все остальное.
И я приведу слагаемые.
Значит, здесь, здесь, здесь, здесь.
Так.
Значит, что это получается?
Это получается минус или плюс, плюс, наверное.
Значит, хм минус х на у.
И плюс у, н, минус у на х.
По-моему.
Так.
Давайте я еще раз проверю.
Значит, вот это.
Значит, так вот это, минус это.
То перекидываем вправо.
Получаем хм, у, минус х.
У выносим.
Здесь получается разность.
Это идет с плюсом.
Вот.
И это мы переносим туда тоже.
Получается х мы выносим, у, н, минус у.
Да.
Вот так.
Получается вот так.
Все.
Теперь.
Берем математическое ожидание от левой правой части.
Пишем модуль.
Модуль математического ожидания хм, у, н, минус ху.
И получаем, что здесь стоит модуль математического
ожидания того, что стоит здесь.
А это меньше либо равно, чем математическое ожидание
модуля от того, что стоит внутри.
Суммы.
Модуль суммы не превосходит суммы модулей.
Так.
Значит, получаем, что это меньше либо равно, чем
Модуль математического ожидания хм, у, н, минус у.
Плюс математическое ожидание хм, у.
Плюс математическое ожидание у, н, минус у на х.
Вот.
Мел.
Сейчас сменю.
Ну вот.
И теперь нам остается воспользоваться только неравенством
Коши Буниковского.
Мат.
Ижидание модуля произведения не превосходит корня мат.
Ижидания квадрата.
Вот это умножить на квадрат вот этого.
То есть это меньше либо равно, чем корень мат.
Ижидание хм, у, н, минус у в квадрате.
Корень вот такой.
Плюс корень мат.
Ижидание хм, у, н, минус у в квадрате.
А, сейчас тут.
Мат.
Ижидание у в квадрате.
Вот.
И плюс корень мат.
Ижидания у, н, минус у в квадрате.
Мат.
Ижидание ха в квадрате.
Ну и вот.
И мы устремляем м и н независимо друг от друга к бесконечности.
Но так как хм сходится к х, то по определению вот эта
вещь сходится к нулю.
Эта вещь тоже сходится к нулю.
Вот эта вещь сходится к нулю, и она умножается на
нечто, что конечное.
Видите, вот где мы пользуемся тем, что конечный второй
момент.
Вот здесь.
То есть это конечное число, а это сходится к нулю.
Значит, вот это все сходится к нулю.
Аналогично здесь.
Вот это сходится к нулю, а это константа.
Вот.
Так что все это сходится к нулю.
Вот.
Так что получается, что математическое ожидание
этой вещи, минус математическое ожидание этой вещи, сходится
к нулю.
То есть вот это мотожидание сходится к вот этому.
Мотожидание вот этого.
На этом лемма первая доказана.
Да, кстати, небольшое объявление.
Вот у меня на Notion есть раздел Письменные задания.
И там списки.
Вот это те задачи, которые вы должны сдавать своим
семинаристам, чтобы сдать задания.
Понятно?
Я ничего не менял там с прошлого года.
Вроде там все нормально в плане задач.
Так что вот эти и только эти задачи.
И важность задачи решать, потому что эти задачи, они
будут на экзамене.
Но я не помню, все ли из этих задач попадают в билет
на экзамене.
Но, наверное, почти все.
Несколько комментариев по поводу вот этой леммы,
которой мы доказали.
Обратите внимание, что значит, что она гласит, что если
ХН сходится к ИКСУ в СК смысле, и ХН сходится к Y в СК
смысле, то тогда МАТ ожидания ХН сходится к МАТ ожидания
ХЫ, при М и Н, стремящемся к бесконечности.
В этой теореме, кроме того, что должны существовать
конечные вторые моменты у ХА и Y, ничего не сказано
о самих последовательностях.
То есть, это означает, что Х и Y, они могут быть
независимыми, они могут совпадать, могут быть
константами.
Ну, например, пусть YН равняется тождественно единито.
Подставим сюда.
Что мы получим?
Что МАТ ожидания ХМ сходится к МАТ ожиданию ИКСА, при
М, стремящемся к бесконечности.
То есть, если ХМ сходится к ИКСУ в среднем квадратичном
и существует второй момент ИКСА, то тогда МАТ ожидания
ХМ сходится к МАТ ожиданию ИКС.
Вот.
Это прямое следствие этой леммы.
Теперь пусть YН равен Х, ну Н.
Давайте мы возьмем одинаковые последовательности.
Пусть эти последовательности будут одинаковыми.
Тогда отсюда следует, что математическое ожидание
Х, ну М или Н, не важно, в квадрате, сходится к МАТ
ожиданию в квадрате, при Н, стремящемся к бесконечности.
Вот.
Значит, если это сходится сюда в ИКСА смысле, и у
вот этой штуки существует конечный второй момент,
то тогда второй момент этого сходится ко второму моменту
этого.
Вот для других там видов сходимости, из их сходимости
там не обязательно следует, что и числовые характеристики
типа МАТ ожидания сходятся.
Но для ИСКА сходимости это так.
Вот это очень сильно помогает при теоремах, при решении
задач.
Вот это свойство ИСКА сходимости.
Не надо только забывать, что предел должен, для того
чтобы такое утверждать, предел должен быть, иметь
второй конечный момент.
Вот такая теорема.
Значит, вторая лемма, я ее приведу без доказательства.
Она говорит вот о чем.
Что если, что последовательность сходится в ИСКА смысле,
тогда и только тогда, когда она фундаментальная.
Ну, мы привыкли в математическом анализе к такого рода теоремам.
Они помогают нам доказывать, что последовательность
сходится к чему-то без выбора кандидата.
К чему ты хочешь рассматривать сходимость.
Значит,
пусть
xkt
k равным от единицы до бесконечности, это
случайная последовательность,
для каждой из которых
случайная последовательность такая, что
от ожидания xk в квадрате
конечная.
Вот.
Тогда
необходимым
и
достаточным
условиям
xk
сходимости
xk
ну, xk
к x в среднем квадратичном
является равенство
значит, предел
при n и m стремящемся к бесконечности
от ожидания ym-dm
в квадрате, равное нулю
для любых
последовательностей
yn
и
zm
последовательности
xk
то есть
xk
сходится
а, сейчас
сходимости
тут еще добавьте
всюду, всюду это требуем
итак, xk-то
xk сходит к x
тогда и только тогда, когда для любых
ее под последовательностей вот это
вот
когда для любых ее под последовательностей
будет выполняться вот это
y и z опять же произвольные
это случайные последовательности
они могут быть зависимыми
хоть равными между собой, хоть совпадающими
с x хоть какие, любые под последовательности
x-а
вообще вот это утверждение
о том, что
последовательность случайно сходится
тогда и только тогда, когда она фундаментальна
это свойство
не только xk-сходимости
это свойство и сходимости
по вероятности, почти наверно
и по распределению
вот, ну здесь я привел
просто формулировку для xk-сходимости
но для других видов сходимости
это тоже все работает
и если нужно, вы можете этим пользоваться
но, по-моему, нам
в задачах
и пиаремах это нигде
не понадобится
а вот эта лемма 2 понадобится
так
и наконец, лему 3
введу
с доказательством
но она простая
значит, пусть
для последовательности
xk-а
у которой
те моменты
вторые конечные
пусть для этой последовательности
существует c
такое, что
для любых
под последовательностей
yn
и zm
последовательности
xk
выполнено
что
математическое ожидание
yn
zm
входит к c
пусть такая c найдется
что для любых
под последовательности
вот имеет место вот эта сходимость
к одному и тому же c
при n и m
стремящимся к бесконечности
вот
тогда
xk
сходится
то есть, тогда существует x
такой, что
у него конечный второй момент
и xk-сходимость
и xk
сходится
xk-стримящимся к бесконечности
вот
видите, тут не просто сходится
а то, что момент
еще существует второго порядка
вот так вот
давайте доказательства напишем
ну, для этого надо что заметить
тут очень простое доказательство
yn-zm
ну, покажем, что эта последовательность
сходится
и будет вот это
верно
значит, вот это у нас получается
yn2-2
ynzm
плюс zm2
вот
и мы рассмотрим
предел при n и m
стремящимся
к бесконечности
значит, мат ожидания
yn-zm
вот покажем, что этот
предел равен 0
ну, скобку мы написали
мат ожиданий этой суммы
это сумма этих мат ожиданий
мат ожиданий yn2-2
сходится к c
потому что здесь мы пишем, что существует c
для любых подпоследовательностей
в том числе, для которых z и y совпадают
так что если они
совпадут, то получается, что
по этому условию
у нас мат ожиданий yn2-2
сходится к c
здесь получается c
то есть мы применяем вот это вот условие
когда y и z равны
здесь у нас y и z
такие, какие они нам даны
поэтому минус 2c
предел будет равен
и здесь тоже, когда они равны
этому z плюс c
ну вот, все сокращается, получается 0
вот
а это значит, по вот этой лемме
что раз, вот это справедливо
для любых двух подпоследовательностей
значит
у нас имеет место Sка-сходимость
вот такая при вот этом условии y
н效상 Cка-сходимость
еще вот это условие. Вот здесь зашито
вот это
C crimes
darauf stealing
вот это
C whole equals
0
вот такая
лемма
Случайные последовательности мы разобрались. Теперь перейдем уже к определению непрерывности,
дифференцированности и интегрированности. Мы будем говорить, что случайный процесс
x от t, t из t большого, sk непрерывен точки t0, если x от t плюс эпсион входится в sk смысле
при эпсион стремящимся к нулю, к x от t. Случайный процесс sk непрерывен в точке t0, если вот это
вот справедливо. Вот так как тут все сводится в итоге к числовым пределам, а числовых пределов,
помните там мотонализу у нас было утверждение, что если мы по непрерывной переменной куда-то
сходимся, то это равносильно тому, что по любой последовательности, которая отвечает
это исходимости, мы куда-то сходимся. Так что вот на это можно смотреть в терминах
числовых последовательностей. То, что вот это выполнено для любой числовой последовательности,
которая стремится к нулю. Здесь у нас непрерывная переменная эпсион стремится к нулю,
а мы на это можем посмотреть, как она равносильна условия. Что бы любой последовательности,
стремящемся к нулю, если мы его сюда подставим, у нас будет исходимость вот сюда. Но это
просто свойство изоматематического анализа вот но для того чтобы не говорить каждый раз
вот для любой последовательности стремящиеся к нулю мы используем просто вот такое обозначение
как бы непрерывная переменная сходится здесь неважно справа слева просто epsilon стремится к
нулю вот это искание прерывность точки т 0 давайте я сразу веду и другие определения искать
дифференцируемости значит случайный процесс икса т значит с называется с к дифференцируемым
точки т 0 называется с к дифференцируем в точке т 0 если если значит если x от т плюс
epsilon минус x от t разделить на epsilon ходится среднем квадратичном при epsilon стремящимся к
нулю к некоторой случайной величине это вот если сходится к некоторой случайной величине это если
найдет такая случайная лично который сходится вот это случайная величина называется с к производные
процесса точки а сейчас подождите т 0 т 0 а и там т 0 я сегодня не внимательный совсем т 0 вот
называется с к производной в точке т 0 с к производная процесса x в точке т 0 и она обозначается у нас
вот так x штрих от т 0 вот для этого мы придумаем вот такой символ x штрих от т 0 и будем называть
это случайно величины который сходится вот эта вещь значит здесь есть определенная тонкость вот
как считать имеет конечный второй момент это или нет в принципе по определению сходимости это не
нужно но для теорем которые пойдут дальше по-моему нам важно то что у это должен существовать второй
конечный момент поэтому я предлагаю добавить это просто в определение но это не есть что-то
принципиальное либо мы здесь это не добавляем тогда последующим нам нужно постоянно с этим как-то
работать где там и конечно где не конечно либо мы добавляем и тогда мы просто упрощаем себе
жизнь потом просто не будут эти фразы лишние дополнительно и добавляться а так теория будет
построена кивалетным образом так что давайте мы здесь просто ведем что математическое ожидание
это в квадраты конечно дополнительные условия сюда добавим но это не принципиальные условия для
дальнейшей теории вот потому что мы всегда можем позволить себя потом говорить что если
ска дифференцируемо и производный имеет второй порядок вот так теория мы строить давайте мы
добавим и будем вот так считать так и третье это ска интегрируемость тоже веду
такое определение определение определение ска интегрируемости по ривану значит пусть дан
случайный процесс икса т т т большого и некоторые отрезок
принадлежит вот этому т ему будем рассматривать интеграл на этом отрезке значит рассмотрим
разбиение отрезка а б а именно а равняется т0 меньше чем т1 меньше и так далее меньше тн равная
б и точки тау и т которые принадлежат т 0 т т сейчас и минус 1 и и вот для и от единицы до
вот тогда если существует ска предел частичных сумма вот таких вот это значит получается у нас
сумма так сумма значит по и от единицы до n икс от и этого на т и минус т и минус 1 если
существует вот этот предел или если вот это частичные суммы сходится в среднем квадратичном
при n стремящимся к бесконечности к некоторой случайной величине про которую мы здесь тоже
потребуем чтобы она имела второй конечный момент точно также как и там такую оговорку
сделаем то тогда а и этот предел не зависит от разбиения и выбора точек то тогда будем
говорить что этот процесс ска интегрируем по риману и вот эту случайную величину будем
называть ска интегралом римана процесса икс на отрезке а б сейчас и этот предел не зависит от
разбиения и выбора точек но как вот при определении интеграла римана
вот и выбора точек то процесс икс от называется ска интегрируем им по риману
на отрезке а б и случайная величина это называется ска интегралом римана
процесса икс от на отрезке а б вот и обозначается так значит это равняется как обычный интеграл
вот то что здесь написано это некий символ это символ для этой который похож на обычный
интеграл но необычный интеграл здесь предел в котором понимается сходимость частичных
сумм она и ска сходимость здесь но интеграл мы используем обозначение привычное нам вот это
ска интеграл вот да ой так так так так так да спасибо здесь стал получается здесь получается
тау а здесь ты здесь ты и ты минус ты ты минус первая здесь стал да спасибо вот хорошо хорошо
так ну ладно вот я ввел такие определения
значит определение ска непрерывности ска дифференцируемость значит всюду у нас
здесь предел мы требуем для него чтобы мот ожидания квадрата было конечным но
по крайней мере для дифференцируемости интегрируемости давайте мы это и здесь
потребуем чтобы все было симметрично когда получается что непрерывность если мы хотим
чтобы была непрерывность точки то мы требуем чтобы существовал второй конечный момент
как бы да давайте вот так поступим ну что везде симметрично было то придется помнить тогда где
мы это потребовали а где мы это не потребовали вот пусть будет везде все симметрично ну хорошо
а теперь можно воспользоваться возможностями который дает ска сходимость и доказать и вывести
некоторые критерии непрерывности дифференцируемости и интегрируемости но я сегодня все наверное не успею
доказать здесь все очень просто смотрите оказывается что если мы рассматриваем непрерывность
дифференцируемость и интегрируемость некоторого процесса в среднем квадратичном то для
исследования процесса найти свойства нам достаточно посмотреть на ее ко вариационную функцию или что
эквивалентно на ее математическое ожидание и корреляционную функцию а именно мы с вами
докажем что процесс вот в этом смысле является непрерывным ска непрерывным точки т 0 тогда и
только тогда когда ко вариационная функция ко мы обозначали непрерывна вп точке то ноль то ноль
критерии такой так что чтобы это выяснить находишь ковы риационную функцию и проверяешь ее непрерывность
в точке ту нуль ту ноль все вот дифференцируемость там тоже будет некоторому смысле дифференцируемость
кавриционной функции интегрируемость там будет тоже интегрируемос 54 функции то есть вот эти
свойства непрерывности дифференцированности и интегрированности involve
ον неприрывность дифференцированность и интегрировakk
сходятся к проверке соответствующих свойств для мотожидания и корреляционной
функции или к проверке этих свойств для ковриационной функции.
Для других видов сходимости таких результатов уже нет, а здесь они есть, мы этим
будем пользоваться. Давайте, сколько успеем сегодня, столько докажем, и первое,
что мы рассмотрим, это критерии искани прерывности.
Теориям критерий S-к непрерывности.
Значит, процесс X от T с мотожиданием X от T в квадрате меньше бесконечности
является S-к непрерывным T0 тогда и только тогда, когда ковриационная функция KX от T
непрерывно точки T0 T0, что равносильно, и это мы тоже докажем, двум вещам, что
математическое ожидание процесса непрерывно точки T0 и корреляционная
функция непрерывно T0 T0. Вот видите, в чем польза ковриационной функции, она одна,
вот непрерывность этого равносильно непрерывности этого. Корреляционной
функции, ее иногда проще находить, но тогда здесь, видите, надо еще им от
ожидания проверять. Ну, в общем, тут смотришь уже по ситуации, можно так, можно сяк.
Так, ну будем доказывать этот критерий. Так, ну с чего бы тут начать? Мы с вами докажем
следствие вот это, то есть пусть и с K непрерывен, тогда ковриационная функция непрерывна, потом мы
докажем, что если ковриационная функция непрерывна, то тогда и процесс и с K непрерывен. Вот, то есть мы
докажем с вами сначала вот это, вот эту равносильность, а затем мы воспользуемся вот
этой равносильностью потом, чтобы доказать вот эту равносильность. Вот такой у нас будет план.
Итак, сначала предполагаем, что, давайте, первый шаг здесь, это будет вот этот шаг,
первый, что пусть x, значит t0, пусть x от t сходится, ну давайте так, пусть x от t с K сходится к x,
нет сейчас, что я пишу-то, с K непрерывен к точке t0. Вот, тогда что мы можем написать? x от t плюс
некий епсилон 1 сходится в среднем квадратичном смысле к x от t, здесь везде надо 0 писать,
то что мы точку t0 рассматриваем. Вот, и мы можем написать, что x от t 0 плюс какой-то
другой епсилон 2 тоже сходится в среднем квадратичном к x от t 0, здесь только епсилон 1 стремится к нулю,
а здесь епсилон 2 стремится к нулю, и как они стремятся к нулю, они могут стремиться к нулю
совершенно независимым образом. Тогда что мы получаем? Математическое ожидание x от t0 плюс
епсилон 1 умножить на x от t0 плюс епсилон 2, по лемме 1 это сходится к чему? к математическому
ожиданию от x t0, здесь и это тоже сходится к x t0, значит сходится вот к этому по лемме 1,
вот, значит при епсилон 1, епсилон 2 стремящимся к нулю независимым друг от друга образом. Но что
здесь написано? Ведь это есть не что иное по определению как ковариационная функция процесса
x точки t0 плюс епсилон 1, t0 плюс епсилон 2, а это что? А это есть ковариационная функция точки t0 t0,
и вот мы видим входимость при епсилон 1 и епсилон 2 к нулю независимым образом. Вот,
видите как все просто на самом деле. Это был первый вот этот пункт, в эту сторону мы показали,
теперь покажем в обратную сторону пункт 2. Теперь мы предположим, что к x t s непрерывно точки t0 t0,
и мы напишем вот какую вещь, что мы должны доказать, что математическое ожидание x от t0
плюс епсилон минус x от t0, что вот эта штука сходится к нулю. Но давайте посмотрим, что это такое
повнимательнее, раскроем квадраты, что мы получаем от ожидания x от t0 плюс епсилон на x от t0 плюс епсилон,
т.е. вот тут в квадрате. Минус 2 мат. ожидания x t0 плюс епсилон x t0 и плюс мат. ожидания x в квадрате t0.
Так. И выразим это в терминах k. k x в точке t0 плюс епсилон t0 плюс епсилон,
минус 2 k t0 плюс епсилон t0 плюс, допустим, тоже k, не важно, t0 t0. Вот. И мы предположили,
что она непрерывна в точке t0 t0. Значит, при епсилон, стремящемся к нулю, вот это сходится к x t0 t0,
вот это сходится к x t0 t0, а там уже к x t0 t0. 1 минус 2 плюс 1. Нулю сходится. Вот так. Так что мы
предположили это и записали то, что нам нужно доказать. Выразили это в терминах k и показали
в силу непрерывности, что это будет 0. Вот. Второй пункт мы доказали. Если эта штука непрерывна,
тогда вот это все. И мы считаем с этого момента это справедливо. Что процесс сходится, не важно
какой, любой совершенно произвольный процесс, сходится в sk тогда и только тогда, непрерывно,
в sk смысле, тогда и только тогда, когда кавалерационная функция непрерывна, точка t0 t0. Вот. Так. Хорошо. Теперь
рассмотрим вот это следствие туда-обратно. Здесь, наверное, мне ничего не понадобится, я сытру.
Будем доказывать. Так. Ну тут проще всего доказать какую. Смотрите. Давайте вот это будет нашим
третьим. Если это непрерывно и это непрерывно, то k непрерывно. Как это показать? Пусть mx t непрерывно
t0 и rx ts непрерывно t0 t0. Надо просто вспомнить, как связана кавалерационная функция и
корреляционная функция. А мы знаем, что кавалерационная функция ts это корреляционная
функция в точке ts плюс mx t на mx s. Вот. И поэтому, если m и r непрерывны, то тогда это непрерывно,
это непрерывно, произведение непрерывно, эта штука непрерывна, но понятно тогда, что и вся эта
комбинация, вся эта сумма тоже непрерывна. Элементарно. Все. Исходимости непрерывной сходятся,
это тоже будет непрерывной. T0 T0. Просто из этого вида. Так что вот это следствие тривиально.
И четвертое следствие. Пусть теперь kx ts непрерывно t0 t0.
Но по уже доказанному, если она непрерывна в t0 t0, то у нас есть исходимость. Мы можем этим
пользоваться, потому что мы это доказали. Тогда отсюда следует, что x от t sk непрерывно t0, то есть,
то есть, математическое ожидание от xt плюс epsilon минус x от t, тут t0 везде, t0 в квадрате,
входится к нулю с одной стороны. Вот эта вещь сходится к нулю, это то, что мы знаем.
А теперь там мы выразили от ожидания квадрата разности через k.
А здесь давайте выразим через m и r.
И как мы с вами поступим здесь? Мы перейдем к центрированным величинам.
Смотрите, вот эта вещь будет равна следующей. Математическое ожидание x центрированное,
то есть x минус ее мат ожидания в точке t0 плюс epsilon, минус тоже x центрированное t0,
то есть x от t0 минус ее мат ожидания. Нам надо добавить то, что мы вычли. Поэтому мы прибавим
мат ожидания x в точке t, тут везде t0, t0 плюс epsilon, там t0, так, минус mx в точке t0,
так, в квадрате. Вот я написал эквивалентную вещь. А теперь раскроем скобки здесь. И смотрите,
как у нас все свернется интересно. Математическое ожидание вот этой скобки в квадрате.
Дальше я должен написать плюс два умножить на мат ожидания произведение вот этого на вот эту
разность. Но эта вещь не случайная, и поэтому она вынестся за мат ожидания. И там останется
значит два вот этой разности умножить на мат ожидания вот этой разности. Здесь
центрированные величины, их мат ожидания равно нулю. То, что никакого двойного произведения
не будет, оно равно нулю. То, что это центрированные, их мат ожидания равно нулю. Плюс вот эта скобка в квадрате,
она константом от ожидания мы можем убрать. mx t0 минус mx t0. И мы знаем, что это все стремится к нулю,
прежде всего стремящимся к нулю, потому что это вот что у нас такое. Это есть вот это выражение,
оно стремится к нулю, потому что x непрерывно в точке t0, потому что kx непрерывно в точке t0,
как мы предположили. А это следствие мы доказали ранее. Вот так. Но что получается, если мы внимательно
посмотрим на это выражение? Здесь стоит нечто не отрицательное, и здесь стоит нечто не отрицательное,
и их сумма стремится к нулю. А это возможно тогда и только тогда, когда они по отдельности стремятся
к нулю. Видите, как у нас расщепилась отдельно m и вот эта величина. Так что вот это стремится к нулю,
и это означает, что mx непрерывно в точке t0. И вот это стремится к нулю. Но что это такое?
Значит, это означает, что, смотрите, здесь очень хитрый ход, между прочим, вот здесь. Здесь написано,
что вот такой процесс, эксцентрированный, непрерывен в точке t0, правильно? По определению. Он
непрерывен в точке t0. А мы доказали, что если процесс sk непрерывен в точке t0, то тогда его
ковариационная функция непрерывна в точке t0. Следовательно, ковариационная функция эксцентрированного
непрерывна в точке t0. Но ковариационная функция эксцентрированного – это корреляционная функция
Вот и все. Просто по определению. Потому что ковариационная – это мат ожидания вот этого вот в этой
точке умножить на вот это в этой точке. Если мы этот эксцентрированный раскроем, то мы увидим
просто определение для корреляционной функции. Вот так вот. Значит, rx непрерывно в точке t0, t0.
Так что видите, какая логика интересная здесь. Чтобы доказать эту теорему, надо сначала
доказать вот это нерандество. Установить, что sk непрерывность процесса совпадает с непрерывностью
kx в этой точке. Вот это надо доказать. Потому что когда мы будем доказывать вот эту равносильность,
мы пользуемся то одной, то другой. То одним, то другим следствием. Отсюда перешли к sk сходимости.
Теперь из sk сходимости перешли к ковариационной функции, которая в данном случае корреляционная
функция. Вот как. Ну вот. Вот мы с вами и доказали вот этот замечательный критерий. Ну, буквально
пару минут. Давайте сразу выясним для известных нам процессов, что получается. Винеровский процесс.
Что мы про него знаем? Является ли он sk непрерывным в произвольной точке t? Мы знаем, что его
математическое ожидание, тождественный ноль, это непрерывная функция. Окей. Корреляционная
функция. Это минимум t и s. Это тоже непрерывная функция для любого t и s. Значит, так как вот эта
штука непрерывна всюду, эта штука непрерывна всюду, в том числе в точках вида tt, то это означает,
что винеровский процесс sk непрерывен. Причем в любой точке. Прерывен в любой точке t. И самое
интересное. Теперь плацоновский процесс. Плацоновский процесс. Что мы про него знаем? Его
математическое ожидание есть лямбда t. Это непрерывная функция в любой точке. И корреляционная
функция его, это лямбда на минимум t и s, тоже непрерывная функция для любых t и s, в том числе
и в точках вида tt. Значит, по этому критерию плацоновский процесс является тоже sk непрерывным
в любой точке t. Но при этом его траектории это ступеньки, скачки, разрывные функции.
Видите? Так что этот пример показывает, что sk непрерывность не связана с непрерывностью траекторий.
Они могут быть как непрерывными, как у винеровского процесса, так и разрывными,
как у плацоновского процесса. Вот такой примещательный пример. Свойства sk не связаны
со свойствами траекторий. Вот это важное дополнение. А то вы так посмотрите траекторию,
а она непрерывная, а значит процесс непрерывный. Нет, не обязательно. Ну хорошо, на этом мы заканчиваем,
и в следующий раз продолжим доказывать оставшиеся критерии дифференцированности,
интегрированности траектории.
