Так вот, то есть у нас простая тема, казалось бы.
Нет, BFS. Нет, DFS это посложнее, тема будет проще посмотреть. Ну, увидите. Ну, например, потому что в DFS есть деревья доминаторов, а в BFS есть... ну, хотя ладно, да, да, теория Смита в DFS есть на самом деле, да, да, да, да, да, да. И вот начинается 0.7, начинается сложность, да, да, да.
Нет, ну, это все еще достаточно просто. Но здесь нужно сразу оговориться. Вообще говоря, мы в некотором смысле припадаем к истокам, на самом деле. Потому что когда у нас появляется просто такая абстракция как граф, ну, там, ориентированный, неориентированный, не особо важно, какая первая задача вообще возникает. Ну, естественно, одна из первых задач – найти корочеший путь.
Ну, вот. Ну, естественно, там активная какая-то задача, то есть там где-то постоянно, то есть там во все времена вам нужно как-то дойти из точки A до точки B. Ну, и, собственно, хочется там ходить. Вы не можете просто там ходить по прямой, ну, потому что там, я не знаю, овраги там какие-то или там где-то еще домики какие-то стоят, сквозь них тоже ходить, к сожалению, нельзя, да. Вот, поэтому, собственно, приходится искать какие-то качественные пути. В общем-то, все достаточно естественно.
Вот. Ну, и, казалось бы, начинается все с простого. Вот есть у нас, допустим, ориентированный граф. Как же, и, допустим, для разминочки не взвешенный. Вот мы и подразумеваем, что у нас есть вот какие-то дороги, по этим дорогам мы ходим, надо как-то пройти. Вот. Ну, как-нибудь вот так вот сделаем. Как же нам это сделать?
Ну, если мы ищем кратчайшее расстояние от какой-то стартовой вершины, ну, обычно говорят до какой-то там вершины T, но мы будем, давайте, искать от одной вершины до всех остальных, то возникает, конечно, такая естественная идея.
Так. Ну, до какой вершины у нас расстояние ноль? Ну, наверное, до себя любимой и больше никакой. Так, а до каких? Что? Нет. Мы в графе. Мы в графе. Абсолютно обычный невзвешенный граф. В нашем случае еще и конечный. Да. Как говорится, да, скукотище, конечно, жуткое, но что делать?
Ну, хотя бы неравенство треугольника. Нет. Просто все весоребия равны единице. Невзвешенный даже. Да, я понимаю, что, видимо, совсем downgrade, но вот что делать? Да. Как бы начать надо с базы. Да. То есть так, что дай себе как-то. Вот. Вот. Да, вот даже несимметричные, даже там вот.
Вот. Значит, то теперь есть у нас расстояние ноль до себя. Хорошо. А докуда расстояние один? Вот. Ну, наверное, до всех вершин, до которых можно дойти по одному ребру из нулевой вершины. Логично, да? Из старта.
Так. А есть ли вершины до которых расстояние два? Ну, наверное, есть. Что это за вершины? Это все вершины, до которых можно за один шаг дойти из вершин, до которых расстояние один.
До которых мы еще не дошли. Да. Важное точение. Спасибо. Потому что, да. Потому что заметим, что, в принципе, без этой оговорки можно было и там иногда и эту вершину иногда поставить.
Если тут вот такое ребро поставить. И вот это. Да, конечно. Ой, нет, это я зря делаю. Вот. Да, вот у нас два. Так, что у нас дальше?
Ну, если у нас из вершин с расстоянием два можно сделать еще шаг, внепщенный ранее вершины, то до всех этих вершин расстояние, наверное, три.
Ну, в общем-то, и так далее, и так далее, и так далее. То есть, в общем-то, вот в данном случае получается вот такая штука. То есть, вот четыре, и вот до этой вершины расстояние пять.
Ну, очевидно, мы, конечно, как бы разбить не весь граф можем так разбить на слои, а только те вершины, до которых мы и стартовые вершины вообще дойти можем.
Вот. Ну, там скажем, потому что могут быть вот какие-то там еще независимые части. В ориентированном графе еще бывают вот когда из этих частей можно там прийти к нам, но нельзя вот прийти обратно, ну и так далее.
Ну, там про всякие компоненты сильной связности мы, естественно, сейчас говорить не будем, но вот всякие такие случаи бывают.
Ну, то до всех их у нас расстояние так и остается плюс бесконечность.
Ну, просто потому что нет пути от стартовых вершин до них, поэтому длина этого минимального пути мы будем считать плюс бесконечность как минимум пустого множества.
Вот. Так что вот, по идее, такой стандартный алгоритм у нас возникает.
Ну, вот как вам сказать? Тут, конечно, тут тонкая неизвестная общепринятая разница, но я бы, конечно, назвал это скорее волновой алгоритм, на самом деле.
Вот. Который будет у нас использоваться. Волновой алгоритм.
Вот. И в принципе мы его даже кодируем немножко по-другому.
То есть, да, то кто от БФС в Сочи, который вы привыкли, это даже не совсем базовый.
Вот. То есть, потому что на самом деле более базовым оказывается вот такой волновой алгоритм.
И выглядит он примерно к следующему.
Так.
Какие два стэка? Где два стэка?
6 стэков, 8 стэков.
Ну, да.
Боже.
Персистентный БФС.
Так, очень. Вот. Так, у меня тут сохранились какие-то коды, поэтому я сейчас не буду.
А что с ним делать?
Ну, потому что, может, его надо доводкнуть.
Так.
Ну, разве что.
Ну, вот.
Знаете, смотрите.
Да, может быть, легче было написать, конечно. Да, ну ладно.
Ну, вот. Давайте, смотрите.
То есть, в принципе, основа этого волнового алгоритма может выглядеть вот примерно таким образом.
Если уж там совсем разбивать на процедура.
То есть, суть будет заключаться в том, что эти слои находить в явном виде.
Так, что там за шум?
Вот.
То есть, мы прям эти слои создаем в явном виде.
Ну, конкретно, конечно, в классическом случае.
То есть, в классическом, когда у нас никаких весов нет, то в каждом интервью мы берем последний слой.
Вот я его даже по ссылочке в наглую беру.
Вот. И, соответственно, создаю следующий слой.
Вот. То есть, видите, да.
Но, правда, естественно, мне приходится завести массив юзет, в котором я помечаю, какие вершины у меня в слои уже попали.
Вот. Ну, конкретно, в данном случае будем так делать.
То есть, вот получается такая, такой вот поиск слоев.
Вот.
Ну, и более того, конечно, по известным слоям, конечно, расстояние до вершин найти уже достаточно просто.
Ну, просто пробегаемся по вектору векторов этих слоев.
И, соответственно, если вершина попала в слой 57, значит, расстояние до нее 57.
Тут, в общем-то.
А ни в чем.
Оно скорее теоретическое.
Я не агитирую за то, что это лучше, чем реализация с очередью.
Боже упаси.
Ну, собственно, это, очевидно, не так.
Вот.
Но это просто такая, может быть, идейная база, на которой у нас, может быть, даже на которой у нас будут базироваться просто алгоритмы.
Поэтому я начинаю с нее.
Ну, из нее.
То есть, в общем-то, вот из нее.
То есть, на ней уже.
То есть, основной BFS вот с очередью.
Ну, вот он.
Вот этот вот, который.
Да.
Знакомая.
Классический код.
То есть, он, конечно, он на самом деле вырастает из этого.
Каким образом вырастает?
Да, очень простым.
Мы обнаружим, что, на самом деле, там, если наша задача только найти расстояние, но не найти слои.
Ну, в принципе, заметим, что вектор слоев и вектор расстояния, они взаимозаменяемые.
По одному можно найти другое.
Наоборот.
Поэтому, если мы не хотим искать слои, но хотим найти расстояние.
То есть, можно попытаться оптимизировать процесс.
Каким образом?
Ну, первая оптимизация заключается в том, что мы могли бы не хранить вектор векторов, а могли бы хранить только два слоя.
Типа, предыдущие и следующие.
Вот, могли быть такое.
Да, у нас как раз в задаче о рюкзаке там, собственно, такое уже встречалось.
Вот.
Далее.
Далее.
Чего?
Ну, как вот.
Я бы даже не говорил, что не было.
Вот.
Значит, к чему это нас приводит?
То есть, первая идея, что давайте хранить только два вектора, а потом следующая идея.
А потом следующая идея возникает, что давайте все вершины, вместо того, чтобы хранить их в этих двух векторах, хранить в очереди.
Почему?
Потому что заметим, что у нас эти слои обходятся по очереди.
Ну, действительно, мы по-любому обрабатываем сначала вершины нулевого слоя, потом первого, потом второго и так далее.
И оказывается, что, действительно, если мы будем просто вершины, каждую новую вершину класть в очередь, то оказывается, что в каждый момент времени будет, что у нас находиться.
Но в данном случае все просто.
В каждый момент времени будет находиться слой, который мы обрабатываем.
Часть его.
Вот, например, если брать такую реализацию.
И следующий слой.
там следующий слой ну там по камере него какая-то неполная часть как только мы как бы обработаем
выкинем из очереди предыдущий слой значит следующий там в этот момент времени в очередь
будет в точности следующий слой удобно правда вот то есть но это вот конкретно но это конкретно
следствие да вот так можно очень просто реализовать это ехать но это я еще тут слова
дистанцию с употреблением там д писать код вообще будет минималистически вот так что это вот
такой это классический волновой алгоритм но вот это его реализация вот в виде бфс вот ну
действительно тут пока тут пока все просто алгоритм известен тут даже это было называется
слишком смешно даже спрашивать писали вы его когда-нибудь вот соответственно но вот но пойдем
дай нот но возникает следующий день да то есть это конечно решает пока задачу только в графе
только просто в невзвешенном графе хоть конечно и это идеальный алгоритм флом плане что он
работает за время в плюсе да быстрее невозможно потому что надо просто данные считать вот но
возникает следующая идея если у вас отвалился микрофон так что делать что делать что делать
ну как сказать как это не обсуждается да но или обсуждается ну вот видите до шутки не заходит
не это как бы слишком слабый вариант так а вот где бы нам еще взять так у нас еще так у нас еще
еще и этого вытирать нету что ли господи кто что то что так грабил я не понял так
ладненько сейчас я тогда да прям с микрофоном пойду сейчас будете меня слушать да вот так
добрый день так мне требуется что-нибудь чем можно стирать а вот
а спасибо так если тогда еще пару маркеров тоже воюем так это ой это флипча ой это флипча
по красненьке и
что такое?
О, ничего.
Всё.
Всё, принято.
Спасибо.
И enzyme2 quests на 4ait возможно?
Так вот, господа, господа, вот, раз-раз, значит что будет
дальше?
Но дальше выясняет, естественно, идея, но ведь часто же бывает,
что дороги на улице, наверное, разные, длинные, а сталкивались
с такой ситуацией.
Никогда такого не было, и вот, представьте, оказалось,
что дороги бывают, ну, разные длины, но давайте начнем
с какой-нибудь разминочки.
Допустим, длина бывает 1, 2, 3, 4, 5, ну, в общем случае
к, но вот, понимаем, к пока не очень большое, и тоже
хочется находить кратчайшее расстояние, но я только
договорюсь, что да, по-хорошему еще хочется найти кратчайшие
пути, но думаю, там, написать массив по решке, думаю,
для вас не проблема, так что не будем сейчас излишне
на этом оцентировать внимание, вот, значит, спрашивается,
а как же найти кратчайшие пути, если вот длинные
ребер бывают и побольше, то есть, вот, совсем такой
алгоритм уже не работает.
Ну, самое тупое, что можно делать, да, если у вас есть
ребро длинной 4, то самое тупое, что можно делать,
это распилить это ребро, ну, то есть, поставить, так
сказать, на ребре контрольные точки, вот, и запустить
абсолютно обычные BFS, да, это самое такое логичное
решение, таки первое, таки первое, приходящее в голову,
из-за сколько, из-за, из-за какое время оно работает,
ну, я бы так сказал, В, там, В плюс Е умножить на К, вот
так, вот, ну, потому что, да, то есть, ну, а чем точка
вот, ну, два ЕК может быть, но суть такая, да, вот самое
тупое, действительно, можно сделать так, но это даже
не самое простое по реализации, ну, тем более, что понятно,
что, да, что хотелось бы в идеале, конечно, домножать
К не на Е, а, наверное, на В, да и как-то размножать
ребре, это значит, что по заданному графу надо какой-то
другой граф строить, это далеко не всегда удобно,
вот, ой, боже мой, господи, кашпак, вот у вас, да, как
так, да, ну, скажем так, да, вот, видимо, у нас сегодня
будет такой, я вот не случайно писал волновой алгоритм
и мы сегодня будем менять фундамент, да, то есть, да,
я понимаю, что у вас там почти навек, да, когда вам
сказали БФС, вам просто сразу сказали, что вот,
вот БФС, он пишется, вот так, нет, ух ты, а как, прям
сам вот это придумал, а, ну вот, ну вот и хорошо,
кстати, Тарасе проще будет, потому что на самом деле
на его основе, на самом деле сейчас там большинство
остальных алгоритмов сейчас и придумываются, вот, да,
хорошо, а как вам еще рассказывали про БФС?
Да, это БФС, он пишется вот так вперед, да, ну, да,
ну, понятно, да, окей, ну вот, ну, а на самом деле есть,
то есть, на самом деле идея может заключаться в том,
что давайте, то есть, на самом деле реализовывать тот
же самый волновой алгоритм.
Так, пока нет, хотя забегай вперед, не будет тут, с ноль
ребрами никаких проблем в таком виде, ну, сейчас увидите,
короче, не волнуйтесь, сейчас все будет, значит, смотрите,
вот, идея будет такая, вот, жил-был-эс, и тут мы говорим,
так, вот у нас есть нулевой слой, и по-видимому там никаких
вершин больше не будет, да, и тут мы говорим, так, у
нас есть, допустим, ребро длины 5, ребро длины 3 и,
допустим, два ребра, там, ладно, три ребра длины один,
вот.
Тогда мы говорим, что до этих вершин мы нашли путь длинный
один, прямо пробежавшись по ребрам и пишем.
До этой вершины мы дошли путь длины три, до этой
вершины мы нашли путь длины пять.
так на этом нулевой слой закончился так рассмотрим первый слой так но есть
подозрение что все вершины слоя один мы уже нашли правда ну по камере интуитивно
кажется так кажется чуть позже мы поговорим о том как механизме как же
формального доказательства этого всего такого все объемы еще но значит вот
можно перебирать этот слой вот давайте возьмем эту вершину так что мы в ней
видим мы в ней видим что например вот у нас сюда идет ребро веса 3 и тут
получается опа оказывается до этой вершины есть более короткий путь путь
длины 4 так такая релаксация произошла неплохо значит мысленно вот значит
а также есть еще вот сюда ребро веса 3 значит мы дошли до этой вершины путь
длины 4 но здесь он нам не интересен но потому что вершинка находится собственно
уже мы нашли до нее путь длины 3 да пока не интересно так ну что-то еще могло
быть вот но еще могло быть давайте тут еще какие-нибудь дополнительные ребра тут
порисую допустим вот такое можно вот такое давайте вот путь длины 2 нарисуем и
что-нибудь еще ну а ну и давайте а это вершина тупиковая так ну что у нас тогда
получается тогда у нас получается маленькая приятная штука вот вот то есть
теперь мы переходим к слою длины 2 слоя номер два но в этом слое вершин нет но им
больше и взяться неоткуда что прийти в него можем только из вершин слоев 0 1 но
также мы понимаем что тогда получается слой 3 мы уже полностью знаем и это вот
он из него мы тоже делаем какую-то релаксацию но и тогда в результате получается
примерно вот можно это сделать примерно так то есть давайте попытаемся слои реально вот
хранить в реальном виде так если каждый слой искать за от в то вам будет больно
но не совсем на самом нет это еще не фортбелла потому что как я сказал пока бы храним все
слои в явном виде как говорится открываю демонстрирую так и так я штаб демонстрирую да во
но не если бы только маленькая проблема мы релаксируем не следующий слой если
релаксируешь прибру 3 то ты как бы релаксируешь не следующий слой
но глобально произошло что у нас веса добавились ну как бы как бы если мы находимся сейчас слой
57 у нас ребро 3 то как бы да мы отправляем вершину слой 60 если она еще не но во-первых
если она еще не оказалась слои там 59 да то есть обратите внимание то есть обратите внимание то
есть у нас появился появился новый волновой алгоритм внимание смотрите внимательно то есть
Обратите внимание, мы говорим, что у нас этих волн целых k.
То есть целых k умножить на n, на самом деле, обратите внимание.
Но я тут более точную, конечно, оценку написал, но суть, в общем, такая.
Но заметим, что если вершина попала в волну номер 60, вот из 57, то как мы уже увидели,
это не значит, что она там навсегда останется.
Потому что вполне может на этот трасс оказаться, что чуть позже до него расстояние окажется
и вполне себе 59 или даже 58.
k это да.
И пока что важно, веса целые положительные.
Поэтому я их так вот пользуюсь.
Ну ладно, вот мы не знаем, что такое BFS, но вот мы знаем, что такое set.
Правда, не знаем, что такое hash set.
Мы пробегаем слои, то есть мы явно пробегаемся по слоям.
Да.
Но мы же когда-то, как мы второй раз пробежимся, или мы еще раз выбираемся?
В смысле? Зачем второй раз?
Ну а как нам меньше запустить типа пересчет?
Нет, в смысле, а вот идея очень простая.
Смотри, изначально у тебя есть только нулевой слой, в котором находится стартовая вершина.
Да.
Значит, мы говорим, мы пробегаемся по всем слоям в порядке возрастания.
И в каждом слое, в слое номер L, говорим, вот у меня есть пустой слой.
Точнее не пустой слой.
Я достаю из него новую вершину.
Простым, естественным образом.
Вот.
Значит, дальше происходит, что...
Значит, что мы делаем дальше?
Мы перебираем все ребра, торчащие из ГИО.
И говорим, что я вот так, вот конец этого ребра, назовем его NW,
и я нашел до этой вершины новый путь длины L,
до этой вершины новый путь длины L плюс вес ребра.
Если оказалось, что это лучшее, чем мы нашли раньше,
в массиве D, естественно, храню такие пути,
вот, то...
В смысле...
Правильно.
И мы это делаем.
Обрати внимание.
Давайте я побольше нарисую.
Вот.
Пожалуйста.
То есть я...
Вот я тут не случайно пишу, что если вершина уже в каком-то слое находится,
а ведь по сути обратить внимание D, это не просто расстояние,
это в каком слое она находится.
Пока у нас все целое, это вообще одно и то же.
Зачем нам удалять?
Мы можем просто добавлять новое?
Пока для, может быть, какой-то простоты.
То есть давайте отдельно мы поговорим о том, что понятно,
что можно избавиться от анордера сетов,
и вообще есть BFS-нака очередях, до которого мы сейчас дойдем.
Естественно есть.
Но как бы мы давайте все-таки будем все-таки с базы начинать.
Вот.
Здесь я взял максимально простую базу,
когда вот я хотел визуализировать,
что вершина может перемещаться из слоя в слой.
И вот здесь я это реализую с помощью hash-сета.
То есть если она лежала в каком-то слое,
я ее оттуда достаю, ну и потом, соответственно, я ее туда помещаю.
Сейчас.
Я не очень понимаю...
Видите?
Мы же сейчас...
Мы делаем что-то подобие DFS или мы просто...
Я не очень понимаю, почему у нас поддерживается вариант,
что мы всех меньших ловят со души.
Вот я это понимаю.
Вот.
Так.
Но раз возникает вопрос...
Но раз возникает такой вопрос, значит,
приходит время действительно формального доказательства.
Значит, формального доказательства того,
что действительно такой алгоритм действительно работает.
Ну, доказательства...
Так.
Ну а теперь первое утверждение.
Если вершина находится в слое номер L,
это означает, что мы реально нашли какой-то путь длины L до нее.
Это понятно, да?
Да.
Вот.
Ну там можно по индукции.
Теперь остается только показать...
Ну вот.
Теперь остается только показать,
что, значит, каждая вершина обязательно окажется в L-том слое.
Причем до того, как мы...
Причем желательно до того, как мы этот L-ти слой будем обрабатывать.
Но если до вершины...
Я имею в виду пусть до вершины...
То есть утверждение.
Пусть до вершины V расстояние L.
Тогда A.
Она попадет в L-ты слой.
B.
Что важно.
Это произойдет до того,
как мы вообще дойдем...
Как у нас форик дойдет до L-того слоя и начнет его обрабатывать.
Нет.
Вот сейчас тут очень важно.
Действительно.
Потому что вот в какой-то момент действительно у нас так схема может...
Как бы можно поверить излишне в схему,
а она в какой-то момент начнет давать сбой.
Доказать, что будет такое.
Рассмотрим кратчайший путь от вершины S до вершины V.
Ну там какой-нибудь.
Вот.
И длина тут L.
Тут, допустим, 0, 3, там, 5, 9 и так далее.
Значит, теперь пройдемся по всем вот этим вершинам.
Ну там можно включать индукцию,
но, думаю, суть будет понятна и без нее.
Эта вершина сразу попадает в нулевой слой и обрабатывается там, правда?
Но это означает, что вот эта вершина,
просто при обработке этой вершины из нулевого слоя,
попадет в слой №3.
Логично, да?
Более того, она никуда оттуда не денется.
Почему она никуда не денется?
Да просто потому, что если она куда-то денется, значит,
до нее есть путь короче, чем №3.
А это тогда бы и этот путь сделала короче, правда?
Значит, эта вершина ровно в этот момент попадет в слой №3
и, в общем-то, больше с ней ничего не произойдет.
Вот, понятно, да?
Теперь дошли до этой вершины.
Но при релаксации из нее вот эта вершина попадет в слой №3.
Но при релаксации из нее вот эта вершина попадет в слой №5.
Ну, с оговоркой, тут уже не совсем верно утверждение,
что она попадет именно в этот момент, она могла туда попасть раньше.
Но нам это не важно.
Нам важно, что она, то есть не позже, чем при обработке третьего слоя,
эта вершина попадет в пятый слой.
Вот, и никуда оттуда не денется, потому что это тоже корочешее расстояние.
Ну и так далее.
То есть таким же образом эта вершина, там, 9-ый, 10-ый и так далее.
В общем, короче говоря, каждая из этих вершин будет обработана в своем слое.
В общем-то, доказательство окончено.
А правда, что это просто дээкстрация квадратная?
Нет, пока нет.
Которая пробегает просто по всем лишним насам, которые не используются?
Нет, пока на самом деле нет.
Нет, я бы сказал, скажем так, тут у меня немножко другая точка зрения.
Я скажу, что дээкстра, это вот это вот, только слоев бесконечно много.
На самом деле.
Но мы давайте просто не будем бежать.
Да, я понимаю, тут у нас все продвинутые люди, но все-таки давайте постепенно.
Вот, то есть вот таким образом у нас получается такое удобное.
Это мы будем называть, ну да, получается не совсем 1K BFS,
это как бы 1K волновой алгоритм.
Вот.
Ну, на самом деле, да.
Ну, 1K.
Сразу возьмите такой замечательный вопрос.
Действительно, можно ли это реализовать без анордорицитов?
Вот, ну и на самом деле, конечно, да.
Ну, во-первых, действительно, как уже было сказано.
Так, интересно, что у меня тут было?
Ой, боже мой, что это такое?
Так.
Да, но на самом деле обратите внимание вот на что.
Да, то есть можно это в принципе реализовать на фактически к очередях.
Ну, первая идея возникает такая,
что на самом деле вот эти сыты можно прекрасно заменить на обычные векторы или даже очереди.
Единственная только проблема будет, что мы вершину из очереди вынуть просто так уже не можем.
Но это сама по себе не проблема. Почему?
Да, мы просто потому что мы можем достаем,
говорить, достаем вершину из очереди
и говорить, так, если у нее там дешка у нее меньше, чем слой, с которой мы ее достали, значит мы ее игнорируем.
Или там, ну если мы там...
Чего?
Почему?
Можем.
Ну теперь давайте вопрос, а сколько, хорошо, сколько раз в совокупности мы будем добавлять вершины со всеми дубликатами во все очереди?
Это ее входящая степень.
Но потом мы для каждого из этого раза, если мы будем прибирать ее к соседе, это будет ее выходящая степень, и если мы перемножим, то будет тоже.
Да, но тогда правда теперь оговоримся, что в одну очередь одна вершина больше одного раза не будет добавлена.
Это правда.
Это правда.
А, если у нас...
Потому что мы как бы ее добавляем только в случае, если расстояние строго уменьшилось.
Да.
Так что да.
Не, ну хотя бы один раз мы уже, как вы уже выяснили, она добавлена будет, так что...
Что если у нас у ребер могут быть и самой?
Пока еще не бывает.
Ну, во-первых, пока не бывает, чуть позже обсудим,
что принципиально меняется.
Да, подсказка.
Ничего.
Вот.
И в результате получается, что на самом деле, да, можно заменить это на очереди и даже сильно не париться.
Вот.
И на самом деле...
Но на самом деле теперь можно заметить, что каждый раз, когда мы...
Вот раньше, когда мы писали обычный БФС, мы просто обнаруживали, что в каждый момент времени у нас есть только два непустых с этой точки зрения слоя, текущий и следующий.
Ну, все предыдущие опустошены, а следующих больше нету.
Вот.
Поэтому оставалось только всего два слоя.
И как бы мы их запихивали в одну очередь.
А на самом деле можно завести K плюс одну очередь.
Ну, потому что заметим, что если мы сейчас находимся там в слое номер L, то у нас только расстояние до вершин могут быть не более, чем L плюс K, который мы нашли на текущий момент.
Поэтому получается K плюс одна очередь.
Ну и, на самом деле, чтобы их там не сдвигать по циклу, получается вот примерно такая реализация.
Вот. Видно, да?
То есть, видите, тут даже... То есть, на самом деле, видите, мы просто берем предыдущий код и немножко его переделываем.
Видите, да?
Вот. То есть, в каждом моменте... То есть, обратите внимание, как мы это делаем, да?
То есть, у нас L – это все еще тот же самый слой, вообще, который был раньше.
Да? Видите, да?
Вот. Но при этом, как бы, L-ты слой будет находиться в очереди номер L процент K плюс один.
То есть, мы как бы в каждом моменте не храним не все VK-очередей, хотя могли бы, а только K плюс одну, ту, которую нам вообще надо.
Вот.
Видите, значит, мы из нее достаем, соответственно, элемент.
Ну, проверяем, адекватно ли мы его достали.
Вот. Ну и, конечно, после этого, конечно, пытаемся релаксировать.
Вот. Видно, да?
Да, нет, наверное.
То есть, это вот такой классический... То есть, вот это можно назвать, собственно, 1K BFS.
Ай-яй-яй-яй. Ой. Ну вот. А в лошебагу не нашли. Ай-яй-яй-яй. Ну ладно.
Так, нет, надо было так оставить, просто сказать. Да, вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Надо было так оставить, просто сказать. Да, вот.
А то будет кто-то списывать, а потом будет думать, о, оно не работает.
Да. Вот.
А, ну правда, оно поронтаймится практически сразу, да, логично.
Это все равно не совсем понятно, что происходит.
Сейчас. У нас...
Это...
Это...
Ну, смотри, давай вот вернемся к старой версии. Вот в этой версии...
А, я понял, это как раз мы по циклу ходим.
Да.
Ну да, то есть старая версия NL это номер очереди, в которой бы мы находились, но просто мы храним как бы только K плюс одну очередь и ходим, да, именно по циклу.
Вот. То есть это называется BFS така очередя.
А ну-ка поднимите руки, кто сталкивался с чем-то подобным.
Или хотя бы с таким словосочетанием, да. Ага. Окей.
Окей.
Ну, мы и делаем пока не пусто.
Нет, ну, но сформулируем аккуратно, да, тут...
Нет, ну не факт, в худшем случае по-любому будет WK, потому что если у вас...
В общем, да, но...
Нет, ну да, можно там действительно делать какие-то отсечки, я согласен, но это вот такие гилочки.
Ну да, да, да. Пожалуй.
Но это уже детали.
Да, значит пока мы видим...
Да, то есть видишь, что это вот один KBFS такой получился.
В общем-то пока оказалось очень сложно, это у нас работает...
За сколько это работает?
А, ну я могу не вставать, да.
Это все еще работает за V умножить на K плюс E.
Вот.
Так.
Но правда тут возникают, конечно, какие еще идеи возникают.
Ну, можно сразу оговориться.
Давайте вместо...
Тут написано, что это у нас не один KBFS, а ноль KBFS.
Ну, что вот это работает, это он как бы обысковывается так же, как и это, потому что это просто чуть-чуть измененная реализация, не более того.
То есть интеллектуально добавлено только одно, что заметим, что когда мы обрабатываем слой номер L, у нас не пустые слои,
только L, L плюс 1 и так далее, L плюс K.
И все остальное здесь, это просто их аккуратная реалия, просто как их хранить.
Все.
Вот.
То есть можно по индукции говорить, что там, если у вершины вес от L до L плюс K, то есть сейчас длина, то она хранится в слое номер там, вот этот вот L там, процент К плюс 1.
Но доказывается абсолютно так же.
Вот выясняется вопрос, а сильно ли меняет что-то, если мы скажем, что у нас помимо весов от одного докка, бывает еще вес ноль?
Ну, она разорвается в свою очередь, но…
В смысле, вес ноль, это значит, что мы можем просто где-то и кайлы бы запустить DFS.
Почему DFS?
Ну, потому что мы можем просто сказать, что все, что достижено из вершины…
Мы не знаем DFS.
Ну…
Нет, там нет, на самом деле нет, боже упаси, нам не нужно запускать DFS.
Списать отдельный DFS нам не нужно.
Да, то есть на самом деле произойдет только одно, что вершина будет добавлена просто в тот слой, который мы прямо сейчас обрабатываем.
Ну, если что.
Но возникает вопрос, сильно ли для нас это страшно?
Ну, ответ дает очень простой, да.
У нас есть вообще механизм формального доказательства.
Вот давайте проверим, а насколько он сломается, если там вес очередного ребра окажется ноль на этом пути?
Ну, на самом деле, то есть, да, у нас, конечно, чуть-чуть сломается, потому что мы пользовались утверждением, что вершина попадет в слой до того, как этот слой начнет обрабатываться.
Теперь это неверно, но не криминально, потому что для нас, оказывается, важно…
То есть тут, конечно, тонкая разница, что здесь оказывается, что эта вершина попадет в свой слой, причем, что важно, причем более того, до…
Да, до того, как мы закончим обрабатывать этот слой.
И это означает, что, как бы, из нее реалаксация произойдет, но, короче говоря, в общем, индукция продолжает работать.
То есть отсюда получается, что на самом деле, то есть, как бы, да, один кал, вот, то есть, на самом деле, дописать сюда нолик, по крайней мере, пока никаких проблем нам не делает.
Сейчас начнем, что мы сначала берем ребра весом ноль, обрабатывайте подъем.
Не, вообще не надо, зачем?
А какая разница?
Так тот-то и прикол, что ничего не надо.
Как говорится, вот этот же алгоритм без всяких изменений работает.
И все предыдущие, кстати, тоже.
Сейчас можете еще раз, с самого начала, повторить формально доказательства, почему 1k и 0k просто не работают?
Ну и 1k и 0k, значит, ну, суть одна.
Рассмотрим кратчайшее расстояние до вершины V в смысле кратчайший путь.
Ну, у нас продолжает работать, что если вершина оказалась в слое номер L, значит, мы до нее реально нашли путь длинной L, да?
Вот.
То есть, остается только доказать, что мы до этой вершины V путь реально найдем длинной L.
Вот.
То есть, остается только доказать, что мы до этой вершины V путь реально найдем длинной L.
Ну, слушайте, что, ну вот.
Что мы не доем ее раньше, чем мы.
Ну, нет, ну, как сказать, ну, нет, вот исходно.
Что нам надо доказать, да?
То есть, нам надо доказать, что как бы до вершины V будет, там, чтобы вершина V попадет в этот слой, да?
Вот.
Это означает, что, значит, ну, пока утверждение такое, что да.
То есть, если мы вершина попала в какой-то слой, значит, мы путь такой длины реально нашли.
Вот.
Ну, в самом деле, может быть, просто мы этот путь не найдем.
Но давайте рассмотрим кратчайший путь вот этой длины L до вершины V.
Доказательства базируются на том, что мы теперь проходимся по этим вершинам вдоль этого пути.
И доказываем, что каждая вершина попадет в соответствующий слой.
Там номер, там длина от пути, вот от стартовой вершины до вот этой.
То есть, нам индукция по длине пути.
Я бы сказал, в данном случае, по, как бы, нет, по количеству ребер на пути, я бы сказал.
По количеству ребер.
Да, ну, чтобы столиком обработать, да, по количеству ребер.
Ну, в смысле, в количестве ребер?
То есть мы говорим, что для, что-то не я все еще не нашел нормального обоснования?
Как?
В смысле, а в чем проблема?
Смотри, вот, то есть вот жила-была вершина, да?
Ну, допустим, вот, там база индукции, понятно.
Да, эта вершина попадет в нулевой слой и будет там обработана.
Переход.
Допустим, вот, то есть доказали, что вот эта вершина попадет в свой слой и будет там обработана, да?
Ну теперь берем следующее ребро, вот в худшем случае
ноль.
Но даже это любое, ну вот, тогда заметим, что когда
мы обрабатываем эту вершину в своем правильном слое,
вот эта вершина тоже будет попробовать поместиться
в правильный слой.
Почему попробовать, потому что может быть она там была
уже раньше.
Вот.
Вот.
Нам нужно аккуратно шаг оформить как-то.
Ну, в смысле, нет, для 1 кб, понятно, вопрос.
Предполагаю, что для всех ребер на пути меньше ноль.
Почему для вот 0, почему у нас в предыдущей вершине?
По сути у нас как бы, у нас то, что веса ребер не больше
нуля, они отвечают за то, что у нас работает переход
ноль.
Не больше нуля?
В смысле?
Не меньше ноль.
Нет, у нас пока, нет, смотрите, у нас пока все как-то
жестко базируется на том, что у нас веса еще и целая.
Мы пользуемся в индукционном переходе тем, что для предыдущей
вершины у нас все работает.
Да.
Но теоретически если вес 0, то как бы, ну если вес
1, то это просто индукция по номеру слоя.
А если вес 0, то индукция по номеру слоя уже не сработает.
Нет, да, но сработает следующее.
Тут два варианта.
Когда вы попытались прорелаксировать по этому ребру, у вас два
варианта.
Либо эта вершина уже оказалась в данном случае в девятом
слое.
И тогда это означает, что до нее уже был там ранее
какой-то другой путь длины 9.
И это значит, что она будет обработана в этом девятом
слое.
Все в порядке.
Вот.
Либо эта вершина прямо сейчас будет добавлена в конец
очереди.
Вот это важно, что мы добавляем именно в конец очереди.
Ну, девятая, конечно, очередь.
И, соответственно, она там тоже будет обработана.
Видимо, можно сказать так.
Для каждой компонента связанности из нулей в момент начала
обработки кат и очереди у нас хотя бы одна вершина
из этой компоненты будет...
Ой, не надо так говорить.
В ориентированном графе нет понятия компонента связанности.
Почему вообще как-то отдельно рассматривать игру в
персональце, а не в принципиальном ничем?
Смотри, у тебя индукция по номеру слоя.
Ну...
Если доверить...
Тихо, тихо, тихо.
Вот, спокойно.
Нет, лучше в данном случае просто рассмотрим путь,
сделаем индукцию по числу ребер на пути.
Все.
И не парится.
Значит, берем...
Для каждой вершины определяем минимальное...
Значит, минимальное число ребер на пути минимального
веса.
Да?
Минимальное число...
Ну, типа того.
Берем путь с минимальным числом ребер среди тех,
в которых минимальный вес, и делаем индукцию по
количеству ребер на таком пути.
Ну...
Сначала по весу, потом по количеству ребер.
Ну, можно.
В принципе, можно, наверное, и так.
Кажется, и так строго будешь.
Ну, можно, но тут не знаю.
Как по мне текущая.
Строгость, по-моему, вполне адекватна.
Ну, если на экзамене такая строгость пройдет,
то нормально.
Господи.
Господи, когда у меня такая строгость, тогда такая
уже строгость не проходила.
Ну, окей.
Так вот.
Значит...
Вот.
Ну, это значит такой 0kbfs.
Ну, значит, так что видим, что...
Ну, единственное, конечно, нужно отметить 01bfs, конечно.
Знаменитый, да?
Ну, как бы, да, 0kbfs мы написали.
Мы могли бы написать 01bfs, где у нас хранится всего
две очереди в каждый момент времени.
Но, на самом деле, чем у нас отличается 01bfs, да?
Ну, давайте я уж тут покопи пастю чуть-чуть.
А мы требуем, чтобы все расстояния не больше 0?
Ну, в 01bfs, да.
Нет, там просто вот...
Вот давайте bfs 01.
Тогда что у нас тут происходит?
Ой.
Ну, да.
А, это он и есть, господи.
Оказывается.
Ну, давайте это...
Да, пишем bfs, а он на самом деле 01, да.
Все ж, да, все ж было уже, да.
То есть, ну, разница оказывается такая, что если раньше мы
храним просто все кладем в одну очередь и говорим,
что там в каждом момент времени там конец текущего
слоя и начало следующего, то в данном случае мы вот
оговариваемся таким способом.
То есть, заметим, что нам не сильно принципиально
в каком порядке вершины внутри слоя рассматривать,
правда?
То есть, мы как бы в каждое время говорим, у нас есть
какой-то мешочек вершин, давайте достанем из него
вершинку, любую.
И поэтому говорим так.
А давайте заведем вместо очереди deck.
И будем говорить так, что если я релаксирую по ребру
номер 1, то я кладу в конец, то есть я как бы добавляю
в следующий слой.
А если я релаксирую по ребру веса 0, то я добавляю
в начало.
Это как бы я добавляю еще типа в текущий слой.
Вот.
Но правда, здесь, конечно, оговорка, что мы плохо следим
за тем, что мы вершину добавили два раза, она могла в deck
и два раза попасть.
Но на самом деле тут мы пользуемся тем, что, наверное,
пробежаться по всем ребрам из вершины два раза – это
не так криминально.
Ну просто да.
То есть, второй раз, конечно, бессмысленно, просто потому,
что релаксация уже не сработает.
Но тем не менее, асимпатических проблем это нам не даст.
В каком случае она могла попасть два раза?
Ну, потому что, допустим, она могла попасть два раза,
потому что, допустим, жила была вершина V57, и мы сделали
релаксацию в вершину U до расстояния 58.
А потом выяснилось, что, например, до этой вершины
из этой же вершины или другой вершины из слоя 57 есть
ребро веса 0.
Вот.
И тогда получается она и два раза.
Ну, заметим, и здесь вообще мы отмечаем, что когда у
нас 0kbfs, вершина может быть добавлена в очереди
в совокупности k плюс один раз.
Соответственно, это вполне возможно.
То есть мы пользуемся тем, что суммарно количество
вершин со всеми дубликатами, которые добавляются в очередь
не более чем е, потому что по одному ребру вершина
добавляется не более чем один раз.
Вот.
Так что вот.
И это вот 0, да, это вот, собственно, так, классический
0,1 bfs, но он, в принципе, почему бы не анод.
То есть такое тоже приятная такая штука имеет место быть.
Вот.
Ну, и теперь вопрос.
Какой следующий уровень?
Не угадали.
Нет, нет, нет, нет.
Да, вы сейчас.
Сейчас мы неожиданно попытаемся ввести не целые.
Не целые.
Комплексные расстояния это интересно, а минимизировать
как?
Ну, по модулю, очевидно.
О, точно, полярный угол.
А какой?
Любой полярный угол, можно как бы из него вычитать
два пи до бесконечности.
Ну, можно загнать.
Да.
Да, это интеллектуально, конечно, будет, но, пожалуй,
да, мы так делать не будем.
Интеллектуальная минимизация.
А теперь давайте так.
Так, тихо.
Тихо.
Ой, классно.
Ой, да, жалко технокубок такой.
Жалко технокубок закончился, да.
Дать бы школьникам задачи программ.
Не то, что вот это.
Не, ну там, господи, там жаловались, что там
все, как бы система по-любому тормозила.
Так что.
Ну, как бы там среди
среди всех первых ни одной попытки
на нее сдать.
Ну, последнюю, да.
Там только более нижние, но тесты хорошие.
Ну, нет, ну будут, да, решивать.
Чего в чем проблема?
На прекрасной платформе, пока будут решивать.
Ну, да.
Вот.
Значит, так, 1К.
А теперь давайте, нет, давайте
представим себе, что у нас
веса.
Ну, вот у нас
веса от 1
до 2.
Ну, да, в чем подлянка? Подлянка в том, что они
бывают вещественные. То есть, может быть, вес там есть корень из 2,
например.
Или там 1.57.
Да, вполне.
Ну, можно еще е пополам.
Можно, можно.
Вот.
Ну, можно корень из е там какой-нибудь.
Вот.
Все, что угодно.
Что же в таком случае делать?
Ну, на самом деле,
вот.
Вот что, да, что
в таком случае
можно делать?
Ну, на самом деле, да, смотрите.
Нет, погодите, погодите.
Как это? Мы не знаем, что такое
дэкстра.
Да, напоминаю, мы сейчас из этого, мы
выведем дэкстру, а не скажем, что там
какая-то дэкстра есть, она нас выручит.
Ну, лодка такая.
Вообще, действительно, правильно замечено, что
предположим, допустим, что у нас
есть веса 1.1, 1.2
и так далее, 1.9,
предположим, что только такие бывают.
Да?
Тогда мы, как минимум мысленно,
мы могли бы действительно все веса
домножить на 10 и забабахать там
какой-то там уже обычный
BFS.
Вот.
Но это, конечно, долговато.
Тем больше точность там весов,
тем, конечно, у нас будут больше проблем.
А если там это еще и реально
корень из двух,
вот.
Что тогда можно делать?
Ну, на самом деле, заметим,
вот, идейно,
идейно, пока я не верю себе, можно вообразить так.
То есть,
но хотя нет, чуть позже будем так себе
воображать.
Пока будем воображать
по-другому.
Ну, ладно, вот, идейно можно
воображить все так. А кто сказал, что у нас
слои имеют номера только 0, 3, 5,
9 и так далее? А давайте
себе вообразим, что у нас бывает слой номер
корень из двух плюс пять.
Или там E в степени
не понадобится.
Да,
но заметим, что мы
обрабатываем слои все-таки в порядке
возрастания.
Нет,
пока мы на идейном
уровне говорим.
Это мы чуть позже обсудим.
Но тут по-разному можно говорить.
То есть, оставлю я тут как бы сейчас
ответвление будет небольшое, да.
Потому что идейно, конечно, да, если бы мы могли
слои перебирать не дискретно,
а непрерывно,
то, в принципе,
то же самое доказательство спокойно
прокатывало бы,
причем для весов от нуля до плюс
бесконечности.
Правда, пока это
металгоритм, потому что непонятно, как слои
реально перебирать.
Но здесь есть два способа.
Вот способ
номер раз. Предположим, что веса у нас
абсолютно произвольной и рациональности.
То есть, может так случиться, что мы там даже
живем в поле, а плюс Б как не из двух, да,
поэтому все честно.
Но мы знаем, что все веса ребер
от единицы до двойки.
Мы знаем, что веса ребер вычислимые.
Нет, описываемые.
Ну, мы подразумеваем,
что у нас есть веса,
они находятся в каком-то там
нашем реализованном поле,
там есть арифметика, который вообще делает
завод единицы.
Что делать с весами ребер, которые описываемые,
но не вычислимые?
О, Господи. Идти
на другой предмет.
Так, нет, мы здесь спокойно.
Мы здесь все-таки программисты. Да, давайте без
лишних парней.
Так, спокойно.
Так, Миша.
Так, Миша, спокойно.
Так, Миша, ау.
Все, тихо.
Значит, мы программисты, у нас все спокойно.
Веса заданы.
Мы можем, конечно, только еще сказать, что
они там принадлежат какому-то типу
данных, которые реализуют какое-то поле,
которое умеет делать плюс-минус умножение
какой-нибудь деления и сравнения.
Ну ладно, нам по большому счету
в общем-то только сложение вычитания надо здесь,
поэтому...
Вот. Но типичный пример,
который может возникнуть, как я уже сказал, это
A плюс B корней из двух, где A и B
это рациональные числа, реализованные в какой-нибудь там
стильной арифметике.
Вот я поэтому и говорю,
что у нас есть тип данных, кто это делает.
Я говорю, у меня референс
A плюс B корней из двух, где A и B рациональные числа.
Ну да.
В такую математику мы копать не будем.
Нет, абстрактно я лучше так бы ушел.
У нас есть тип...
То есть они принадлежат какому-то типу данных
T.
То есть это под множество действительных чисел,
и которая конкретно на этих числах
умеет там делать сложение
вычитания в идеале умножения деления
и сравнения.
Можно сказать, что можно делать погрешность
ε, но тогда все.
Нет, нельзя.
У нас веса могут быть
действительные теперь.
Не, вот фишка в том, что сейчас
мы придумаем алгоритм, который погрешности не потребует.
Но потребует, правда, он от числа
неожиданно еще одну
конечно читерскую оптимизацию,
читерскую штуку,
это мы по числу должны
уметь получать это число
округленное вниз.
Нет, у одного веса да,
но если я сложу несколько таких чисел, у меня числа
получится и больше.
Ой, ой, ой, ой, ой
Господи, вот, как сложно
рассказывать простые вещи в продвинутом потоке.
Да, никто не может поверить,
что я рассказываю простые вещи,
а не там, как говорится,
да, мы сейчас точно цепных требей не будет.
Нет.
Не будет. Ну хотя, афурье,
ну хотя бы линкат,
да, ой,
ну хотя бы тору, мы
сегодня обсудим, а.
это вот алгоритм, который умеет искать кратчайшие расстояния в целых неотрицательных весах за V+,
правда с оговоркой, целые неотрицательные веса, которые вылезают в разрядность процессора,
но это очень сложно алгоритм, чтобы за V+, а мы говорим предействительное,
оказывается, если мы владеем такой операцией каким-то мистическим образом, то это работает неожиданным образом,
то есть оказывается такое, то есть раньше мы говорили, что у каждой вершины есть слой,
и этот слой совпадает с расстоянием, которое мы до него дошли, правда?
Так вот, сейчас мы будем различать эти понятия, то есть будет понятие D от V, то есть это текущее расстояние, прям честное расстояние, которое мы нашли,
а будет еще понятие, в каком слое она лежит, и layer от V будет то самое D от V, но округленное вниз.
Ну, а вот у нас алгоритм такой.
Что-то поменяется, поменяется то, что номер слоя не будет целым, а в такой версии он будет целым.
Да, вот сейчас будет очень важно, да, вот сейчас формальные доказательства должны стать прям максимально.
Чего? Чего N-вершин? Нет, смотрите, теперь я утверждаю следующее, то есть теперь у меня будет идея такая,
то есть я буду запущу абсолютно тот же самый волновой алгоритм, или даже тот же самый алгоритм на двух очередях, на трех,
на двух, в смысле трех, но фишка в том, что каждую вершину я буду класть в слой номер вот такой.
Но я утверждаю тем не менее, что если у нас ребра от единицы до двойки, именно от единицы до двойки, то это будет работать.
Это мы требуем для того, чтобы у нас, чтобы слоев было все-таки от v. Если это будет от одного до k, то это будет вот тоже vk плюс e.
А если там было от 0,5 до 2, то нужно умножить на 2?
Да, ну сейчас дойдем, давайте пока рассмотрим 1,2. То есть алгоритм вот тот же zvk плюс e.
То есть разница в том, что, заметьте, может вообще так произойти, интересно, что d уменьшилось, а слой нет.
Ну вдруг расстояние было 3,5, а мы нашли расстояние 3,42.
Тогда, получается, вершина как лежала в слой номер 3, так и останется лежать в слой номер 3.
Сейчас k – это длиннейший путь или что?
Нет, k – это вот это вот. Ну просто в общем случае, то есть чуть продвинутая версия от одного до k, вот так будет.
Одного до двух, что я еще раз?
Вес каждого ребра. Либо от одного до двух, либо в следующей версии от одного до k.
Это работает vk плюс e, а ну и vk равно 2, соответственно, это работает zvk плюс e.
Так вот.
А почему в vk плюс e? Ну то есть разве у нас каждая решима входит не больше, чем zvk?
Ну да, но vk у нас только по одной причине, потому что мы эти vk слоев перебираем в явном виде.
Понимаете, у нас там вот где-то в коде, а вот, видите, мы перебираем, у нас есть форик, который перебирает в vk.
Вот ровно этот форик работает в vk.
То есть вот этот форик и проверка на пустоту всех слоев.
Со всеми не пустыми слоями мы реально работаем за o от e на самом деле.
Ну да, добавить вершины может быть много раз, но суммарно e.
Но vk возникает из-за того, что мы перебираем слои в честном виде.
Вот я утверждаю, что оказывается, так, кстати, нет ли у меня, так, нет ли у меня мистического кода на эту тему.
Так, здесь нету.
О, а вот тут есть.
Во.
Вот, и обратите внимание.
То есть представьте себе, что вектор d у нас теперь уже с long doubles.
Ну или там просто с doubles, не важно.
Вот.
И работает это в итоге примерно вот в следующем образом.
То есть, видите, ничего не поменялось, код прям идентичен.
Возможно только n, то есть обратите внимание, что nd это типа long double и номер веса у нас вот такой.
Ну я тут сделал, то есть, да, видите, вот этот код поменялся только в том плане, что мы тут что-то округлили куда-то там и к int загнали.
Но в реальности, хотя тут могло произойти эпическая ситуация, что мы тут это вытянули вершину из слоя и тут же в нее добавили обратно.
Нет, стоп.
Могло, могло.
Нет, нет, оно могло быть, потому что это происходит всегда, когда вот d от nv строго уменьшилось.
Но если оно уменьшилось, как я уже сказал, от 3.5 до 3.42, то как бы тогда мы ее как бы выкинем из третьего слоя и тут же в нее добавим обратно.
Нет, ну это, ну в long double это погрешность, да, но сейчас мы как бы опускаем эти вопросы.
Но это не глобально, ну подумайте, если будет 2.9, то добавим во второй слой, ничего страшного не произойдет само по себе.
Вот, ну теперь выискает вопрос.
Но тут обратите внимание, у нас теперь парадигма совсем поменялся, у нас уже номер слоя, у нас уже не совпадает с расстоянием.
То есть более того, оказывается даже неверно, что вершины перебираются в порядке возрастания или хотя бы неубывания расстояний до них, правда?
То есть вполне вероятно, вот по вышеописанным причинам, что может быть, что в одном слое будет лежать вершина, до которой состояние 3.5, 3.4, 3.9, 3.2, там 3.5 и так далее.
Вот, поэтому снова врубаем его величество, формальное доказательство.
Ну да, формальность, конечно, да, разное бывает.
Ну вот действительно, давайте себе представим.
Что было бы, если бы у нас тут вот так.
Вот, допустим у нас тут расстояние действительно 3.4, 1.7, так нет, 3.4 у нас не бывает, 1.1, 1, просто 1, 1.1, 2 и 1.57.
Вот, значит смотрите, тогда работать будет так.
То есть база понятна, что эта вершина попадет в нулевой слой с расстоянием ноль и будет там обработана, правда?
Но теперь важный момент.
При этой обработке нулевого слоя тогда получается, вот эта вершина попадет в слой номер 1, но не просто попадет в слой номер 1, она окажется там именно с расстоянием 1.4, она же могла попасть в слой номер 1 и с другим расстоянием, правда?
Но она попадет, но в нее будет расстояние 1.4, причем до того, как мы начнем обрабатывать слой номер 1.
Далее при обработке этой вершины с корректным расстоянием в третий слой, там в третьем слой окажется вершина, ну может или она там уже была, но она там теперь окажется с расстоянием 3.1.
Ну в общем-то и так далее, видите, да?
То есть у нас фишка оказывается в том, что просто каждая вершина найдет свое расстояние как бы до того, как мы ее слой будем обрабатывать.
Вот здесь мы очень важно пользуемся тем, что у нас веса не меньше единицы.
Вот, понятно, да?
То есть получается, что если у вас дробные веса от 1 до 2, то никаких этих ваших декстер не надо.
Более того, да, если верить Капилевичу, то в науке это называется А2АБФС.
Ну в том плане, что, заметим, пусть у нас веса не от 1 до 2, а там от А до 2А, где А это там, я не знаю, миллиард, например.
То представьте, да, вот задача, вам нужно идти к кратчайшей путь в графе, а веса у вас от миллиарда до 2 миллиардов, а вы знаете только БФС.
Вот, на самом деле оказывается никаких проблем нет.
Да, если вы знаете обычный А1КБФС, то вы его и забабахиваете.
Просто каждая вершина попадает в слой номер расстояния делить на миллиард.
Ну да, в данном случае понятно, делить на А условно.
Ну в данном случае просто целочисленное деление.
Да, если там это миллиард.
То есть оказывается, да, видите, если у вас ребра большие, но при этом не слишком маленькие, то тоже в общем-то не проблема.
Что?
Ну как я уже сказал, то есть оказывается, то есть у вас как бы, знаете, не проблема, если у вас ребра бывают до 2 миллиардов.
Проблема, если они при этом бывают меньше миллиарда.
Если они при этом бывают меньше одной миллиарды.
Да.
То есть если у вас веса от миллиарда до 2 миллиардов, то оказывается в кратчайшей состоянии, что за то же самое В плюс Е.
Вот это вот важный момент.
Не, ну если они у вас целые от миллиарда до 2 миллиарда, то никаких проблем с точностями, естественно, нет.
Вот, понятно?
Есть проблема с симпатикой В на А.
Вот.
Ну почему?
Ну там, ну как сказать, на самом деле, если у вас ребра, значит у вас действительно на отрезке от А до В, то это работает за О от получается В, В делить на А плюс Е.
Вот такая красота.
Но правда здесь оговорка, что А больше нуля.
Это видно.
Да.
Потому что, нет, а давайте так, вот раньше мы заметили, что давайте введем нулевые ребра и скажем, что ничего не поменяется.
Не, можно еще столько меньше попросить.
Меньше нуля?
Нет, ну давайте поаккуратнее.
Ну потому что, опять же, так еще с простого.
Почему в эту схему даже с целыми чистыми нельзя добавить, например, минус 1?
Потому что, да, если у нас тут было ребро веса минус 1, то ломается инвариант на тему того, что как бы мы вершину добавим в нужный слой, причем до того, как этот слой закончит обрабатываться.
Теперь это не так.
Потому что как бы мы эту вершину добавим во второй слой, когда обрабатываем третий.
Тогда нам надо либо возвращаться во второй слой, либо признавать, что мы не все обработали.
Понимаете, да?
Вот.
Так что-то, ну, так что получается, что с отрицательными фейл уже в целых числах.
А?
Ну, у нас почему от нуля мы не можем?
От нуля?
А теперь давайте предположим, что у нас помимо весов от 1 до 2 есть просто, ну, допустим, даже хотя бы ноль.
А почему просто от нуля до 2?
Или даже просто от нуля до 2, еще сложнее.
Давайте напишем отдельно, ну, как бы, когда из каждой вершины перед тем, как запускать обычный БФС будем запускать БФС 0.2.
Ну, вот.
Ага, казалось бы.
Но только нужно аккуратно, чтобы 8 точек не поломать.
Ну, есть одна, да, понимаете, просто есть одна марк.
Нет, нужно ставить вершину марк, что типа мы из этой вершины уже, мы эту вершину уже проходили в таком БФС.
Да, казалось бы, да.
Но только вот теперь давайте посмотрим.
Смотрим на наши доказательства здесь по индукции.
Подлянка в том, что предположим, что у нас тут вес 0.
Тогда оказывается, что эта вершина, значит, да, эта вершина, видимо, окажется в слое номер 3 и тоже с весом 3.1.
Но есть одна маленькая проблема.
Мы уже находимся в третьем слое.
А кто сказал, что эта вершина не была обработана раньше?
Вот могло же так произойти, что эта вершина была обработана в этом же слое раньше, только до нее расстояние было 3.2.
Давайте добавляем вершину, добавляем вершину в слое, только если у нас целая часть уменьшается.
Ну, в смысле, так мы когда ее, когда 3.2 было, там же все уменьшалось.
У нее целая часть 3.2, у нее целая часть 3.
Стал 3.1, целая часть тоже 3, но мы не добавляем вершину.
Да, не добавляем.
Но да, мы проиграли уже.
Давайте сделаем гомотетическое.
Потому что мы релаксировали из нее, предположили, что ее станет 3.2, а на самом деле 3.1.
Давайте снова сделаем гомотетическое с коэффициентом 1 ате, и тогда такой ситуации уже не будет.
Оили.
А это минимальный вес больше 0 в ребра.
Нет, супер.
Но заметим, что у нас тут пофейлилась, есть у нас вес ребра 0, а не 0.бла-бла-бла.
Нет, наоборот.
Мы как бы, смотрите, мы отдельно разделяем вес ребра весу 0, и отдельно все остальные.
И умножаем все ребра на такой вес, чтобы все, чтобы минимально.
Да, да, да, кайфец, кайфец, кайфец.
А после этого у нас такой ситуации уже не будет.
Да, Оили.
Потому что мы вершину, ну у нас как бы, мы не обработаем вершину с не своим.
Сейчас.
А мы не можем.
Можем просто по словам пройтись два раза.
Сначала рассматриваем только игроков веса 0, а потом уже рассматриваем адекватные ерунды.
А вы гарантируете, что там не будет разветленная сеть нулевых, там, этих нулей?
Давайте дотовый объект запустим нашим ритмом, сделаем супер вершины сжатые по ребрам весом.
Сейчас, тихо, тихо, тихо, погоди.
По очереди, пожалуйста.
Сейчас каждую вершину в слой добавлю не более 1 раз, ну там юсты зарезут.
Нет, в смысле, какая разница?
Ну вы добавили, а это тут при чем?
Вопрос же, проблема уже у нас не в том, сколько раз мы добавили вершину и не добавили.
Проблема в том, что когда мы в слое до нее дожли и стали из нее релаксировать, как бы успели ли мы уже сделать ее расстояние правильным?
Или она правильная только с точностью до слоя?
Ну да, следующая, да, правильная идея будет, давайте находить минимальную, но это будет.
Так, чего, давай.
До того, как запускать алгоритм, сожмем все компоненты связности, ну как бы по ребрам веса 0 в одном супер вершине.
И сразу, вот знаете, за что я действительно буду бить на экзамене?
Это за употребление понятия компонента связности в ориентированном графе.
А если слабая компонент связности?
Да, понятия связности в ориентированном графе нету.
Да, сейчас, ну я про это говорю.
Есть понятие сильная связность, есть понятие слабая связность.
Но понятия связности нет.
Вот, такая важная оговорка.
Да, давай.
Я не понял все равно, почему не сняли.
Просто сначала опять идти по слою и добавить в робро весу 0, а потом уже нормально его просмотреть.
Ну как сказать, и...
Нормально, если мы говорим, что они меньше единицы.
Поэтому следующий слой.
Нет, ну следующий-то слой, да, но...
Ну не знаю, ну просто вот, а если, ну тогда, а если будет такая цепочка из нулей?
Ну это мы пройдем в ФС 0.
Ну когда мы, хорошо, когда мы пройдем по первой раз и рассмотрим только вот это вот нулевое,
то может оказаться, что да, вот эту вершину 3.2 мы превратим в 3.1.
Ну вот, но как бы из этой вершины, ну вот...
Ну вот, но как бы вот эта, ну вот, но как бы вот эта вершина так 3.2 и останется,
потому что мы эту вершину, допустим, в списке пробегали раньше и релаксировали из нее только 3.2.
Так что ты как бы отложишь проблему на более длинную цепочку.
А, вот я спрашиваю, то есть вершина может в слою лежать в новый раз?
Да нет, да нет, почему много раз?
Просто вот эта вершина лежит в слою раньше, и было у нее изначально 3.2, да?
Ну вот, а эта лежит, допустим, еще раньше, там вообще было 3.5.
Тогда при твоем проходе сначала мы увидим эту вершину и скажем, что это 3.2,
а потом увидим эту вершину и скажем, что это 3.1.
Мы можем на них топ сорта попасть?
Топ, не факт, там бывают нулевые циклы вот эти.
Нулевые циклы как раз без проблем, то есть это будет топ сорта с циклами,
ну в плане как обычно.
Отлично, только тема конденсация графа это другая тема,
мы ее будем рассматривать, видимо, когда там, ну наверное недельки через две.
А нет, не будем, а не будем, а не будем, а уже ДФС будет, да, логично.
Почему не будем, потому что сегодня мы рассматриваем кратчайшее расстояние,
дальше у нас теория игр идет, раз ПФС, да.
Поэтому ДФС это, а потом, видимо, включим уже ДФС будет,
у нас там все компоненты вершины и трехсвязности, вот.
Осталось так понять, что это да, вот.
И существуют ли они? Тут еще такой вопрос.
Ладно, ну это будем отдельно писать.
Ну вот, то есть да, там конечно можно пытаться как-то выкручиваться,
но там разность топа, я просто хотел показать, что к сожалению,
вещественные числа ноля, к сожалению, так просто не записывают.
То есть это парадигма, вот, действительно, в этой парадигме, видите,
то есть вот, кстати, вот полезная формальность, потому что вот, да,
формальное доказательство не сработало, я обнаружил,
что на самом деле там действительно принципиальная проблема этого алгоритма.
Но как его можно допиливать?
Ну, ведь, смотрите, вот магия ДФС-то была в том, что вот, знаете,
вот ноль работал, когда у нас веса были целые, вот.
А когда веса стали не целые, ноль работать перестал.
Вот.
Но поэтому мы сейчас пойдем, значит, забудем тогда, значит, да, хорошо,
А2, БФС можно вот так вот локально прикольно закодить,
но теперь давайте себе представим.
Давайте вернемся, теперь пойдем немножко другим путем.
Значит, пойдем немножко другим путем.
Давайте себе представим, что у нас веса целые,
но на этот раз до бесконечности.
Ну, или просто, то есть.
Но веса не бывает до бесконечности.
Да, ну можно.
Но сколько она большая, это значит, что будет бесконечности.
Ну, можно до бесконечности, или просто обнаруживается,
что не до бесконечности, а до к, но к уже не 5, 10, 20, 40,
а к там, я не знаю, 10 в пятый, например.
Ну, к, это видимо то, что не может присутствовать в общем-то.
Ну, да, что-нибудь такое, может даже, может даже 10 в пятый,
может даже 10 в девятый, да.
Чтобы уже как бы там, то есть как бы все пути влезают, влезают,
там соответственно в типа.
Что значит испортить?
А, или имеется в виду, что мы хотим сделать, чтобы у нас
с методикой никак не зависело от к.
А, ну хотелось бы, да.
Но правда, ну, или по крайней мере думать.
Нет, у нас даже пока более простая задача.
Что делать, если у нас веса бывает от одного до миллиарда?
Пока у нас просто нет приемлемого решения.
Потому что vk плюс e нас в таком случае не устраивает.
Ну, то есть, хотя в чем у нас проблема?
Вk плюс e все еще маленькая.
А vk, вот теперь вот внимательно давайте смотреть на алгоритм и думать.
А за счет чего возникает 8 точки вот это vk плюс e?
Вот в каком месте мы делаем именно vk действий?
Да, когда, как так, когда перебираем слои и...
Да, и все, да.
Ну ладно, когда их еще создаем?
Вот, заметим, что то, что происходит, то есть, по большому счету,
реально в k раз мы делаем только вот эти две строчки.
И вот это вот создание.
Вот, но это создание я могу заменить на, скажем, там unordered map.
И вот это вот создание.
Вот, но это создание я могу заменить на, скажем, там unordered map.
И замечаем, что вот это вот все, да?
Ну, такой, для каждой вершины вот это мы проделываем v раз,
не vk, а v раз.
А вот это вот мы проделаем вообще e раз.
Понимаем, да?
Поэтому что нам нужно оптимизировать?
По большому счету нам с вами нужно оптимизировать только одно.
То есть, нам нужно сделать, то есть, по большому счету перебирать не vk слоев.
Но заметим, что и...
Но как же нам перебирать не vk слоев?
Ну, мы заметим, что у нас вообще подавляющее большинство слоев,
которые мы перебираем, они пустые.
Да, но не факт, что именно они более чем v слоев будут пустыми всегда.
Конечно же.
Вот, то есть, у нас там гарантируется, что не пустых может быть вплоть до e слоев.
Но заметим, что по большому счету каждый раз, когда мы ищем новую вершину,
мы говорим о том, что так, нам в каждый момент времени нужен минимальный не пустой слой.
Правда?
Может быть, это текущий слой, если мы из него не все достали.
А если он закончился, значит нам нужно следующий не пустой слой.
Логично, да?
Логично?
И возникает такая естественная оптимизация.
А давайте, ну такой, самый тупой, что можно сделать, а действительно, а давайте заведем там, я не знаю, мапчик.
Ну, мапчик из nta в unordered set.
На этот раз в чем мап не unordered, это обычный.
И мы там честно храним все не пустые слои.
Вот, но я так не буду сейчас писать, но вообразить себе такое можно.
Вот то же самое, храним мапчик.
И вот вместо этого фора, там ищем какой-нибудь там, допустим, пишем там что-нибудь там int l, там равно, условно этот, там map.
точка там begin, frost, вот.
Очень эмоциональный мап.
Ну да.
Вот, может вот что-нибудь такое.
Вот.
И дальше вот мы.
А, ну ладно, мап у нас видимо, ладно, мап у нас видимо waves называется на самом деле, да.
Так, ну ладно.
Нет, слушайте, нет, мне что-то даже интересно стало, так.
Так, мне что-то вот, даже интересно стало, давайте попробуем.
Вот так давайте скажем.
Вот, big k.
Так, и вместо вот этого вот пишем, что waves у нас будет свой локальный, и это будет прям мап.
Мап, а по-моему это мап.
Так, и вместо вот этого вот пишем, что waves у нас будет свой локальный, и это будет прям мап.
Map, int и там соответственно unordered set.
Ну соответственно waves.
И видимо на всякий случай, да k будет настолько большим, что тут будет long long.
Ну и конечно.
Давайте еще что-то тут.
Так, что такое int, правда?
Нет, безобразие.
Ну ладно, тут можно 1g18 написать и не париться.
А, ну или там, как там можно было написать еще?
Так, слушайте, там как там этот выставили, это максимальное значение типа называется?
Нет.
А, вот так.
Во.
Не, unsigned long long это, наверное, ну можно везде unsigned, ну ладно, не важно.
Не будем сейчас на эту тему париться.
Значит, поехали.
Теперь, значит, что поменять?
Вот делаем прям вот абсолютно то же самое.
Значит, только разница будет такая.
Значит, вместо вот этого фора пишем while пока не waves.empty, вот сам по себе, да?
И дальше пишем.
Значит, давайте, можно так написать long long l равно, вот как мы вот это заклинание написали.
Да.
Да ладно, вот так waves.begin first.
Ну и дальше вот мы это все и говорим.
Ну и для того, чтобы это было адекватно, мы еще не забудем в конце сказать waves.erase от waves.begin.
Да.
Ну и для того, чтобы этот day не умер у нас в вакууме, мы напишем вот так.
Да, тут, конечно, да.
Вот получается вот такой волновой алгоритм.
Вот.
Ну да, ну ладно, есть тут еще одна маленькая оговорочка.
Вот.
Ну и в конце, конечно, return d.
Ну distances.
Вот такая красота получается.
Нет, ну первым шагом мы берем нулевую волну.
Значит, достаем оттуда по очереди все вершины.
А, потому что, а, я тут забыл эту дайту, я строчку зря убрал.
Ну да, waves.hotel действительно точка begin first.
А нет, в данном случае еще прочее.
Вот так.
Да.
Все.
Вот.
То есть вот тут в общем-то все достаточно получается просто вот с этой точки зрения.
Вот.
И получается этот алгоритм прекрасно работает с весами от одного до ка и даже от нуля до ка, если они целые.
Ну доказательства абсолютно такое же.
То есть разница только в том, что мы как бы просто все пустые слои пропускаем и на каждом шаге тупо находим минимальный свободный слой.
То есть поэтому vk у нас исчезает.
А вот да, вот вопрос.
Вот я и спрашиваю, какая симптотика получается?
То есть vk мы теперь убили, вот, как раму восьмого в Тайланде, да?
Вот.
Вот.
Соответственно.
А вот с ешкой у нас проблема теперь.
В каком месте получается ve?
Ну, типа если посмотреть вершинку, мы ее можем в очереди добавить условно по каждому ребру.
Но не более.
Ааа, ой-ой-ой.
А у нас тут нет на эту тему отсечки.
Ой-ой-ой.
Ой-ой-ой.
Ой-ой-ой.
А почему ее нет?
Ой-ой-ой.
Потому что мы вершину прежде чем добавить в сет, мы ее удаляем из сета.
Ой-ой-ой.
Так что получается, да, вершина обработана не более чем один раз.
И вот в такой реализации она в каждый момент времени работает за, в каждый момент времени вершина находится не более чем в одной, в одном сете.
Да.
Да, мелкая проблема, что мы тут делаем операции с сетом.
Это нам важно.
Поэтому делая сет, у нас получается ze log vk.
Потому что слои у нас бывают, ну хотя, давайте.
Максимум.
А, да, все.
Да, уговорил, уговорил, уговорил.
Да, все, все, все, все.
Неправ, неправ, неправ, неправ, все.
Вот, вот теперь хорошо.
То есть так, v плюс e log k.
Это если вещественные веса, это если целые веса.
Пока целые, да.
С одной стороны, то есть смотрите.
С одной стороны,
С одной стороны, да, пока у нас целые, видим, да, то есть как бы работоспособность этого алгоритма сомнений не вызывает.
Даже если, я тут еще и могу нолик прорисовать, это тоже будет работать, правда?
Это даже работает.
Вот.
Но теперь фишка такая.
Чего?
Ну потому что, ну в смысле.
Почему не елки?
То есть у нас же каждая.
А, ну кстати еще.
Ладно, вот v плюс e на log k.
У нас вообще log k.
А потому что у нас, потому что.
Ну в идеале хотелось бы сказать, что у нас размер сета в каждый момент времени не более чем k.
Кажется не v плюс e log k, а v плюс e log k.
Ну v плюс e, нет.
Ну почему v плюс e, нет.
Ну v, ну как бы, мы же как бы удаляем вот этот вот минимальный слой как бы из мапа за log k.
Мы же не добавляем те вершины, которые недостижимы.
Не добавляем.
Но мы же, ну удаление это за log k делается.
Вот это вот.
Видите, вот это вот последняя строчечка.
Это log k.
Поэтому v log k мы добавить должны.
Хотя.
Ну не каждая вершина, а только те которые.
А, ну ты прав в принципе, да.
Ну ладно.
Ну да, согласен.
Да, мы добавляем только вершины, которые доступны из.
Из эски да, потому что.
Ну да.
Как мы получили делу?
Ну потому что нет.
Количество вершин, которые мы обрабатываем, не менее чем там количество river плюс один.
Ладно, не более.
Почему log v?
Ну у нас еще более сильная оценка.
Ну а тут разные оценки, да.
Нет, смотрите.
Просто и то и то можно.
Есть оценка log k, потому что мы в каждый момент времени храним не более чем k слоев.
Но можно сказать, что это е log v.
Да, можно сказать действительно е log v.
Хотя тут мелкая проблема.
Пустые слои мы просто так не подчищаем.
Обратите внимание.
Обратите внимание.
Для того, чтобы это так было, мы должны были сказать, что вот делаем erase.
И если сет опустел, то значит мы должны перерезить.
Ну констант, может какой-то стоит.
Хотя в принципе если.
Да, если это.
Ладно, так.
Давайте так напишем.
Е log v с...
А это стоит в том, что у нас будет не е log k, а именно е log v.
Да, с оговоркой.
Хотя без этого как бы на самом деле будет всего лишь е log e.
Е log e всего лишь что?
Это е v.
Заметим следующее, что мы добавляем вершину слоя не более чем е раз, но е плюс один.
Ну один, потому что мы стартовую с нулем добавляем.
То есть каждое ребро и ицирует не более одну попытку добавления, следовательно не более один новый слой.
Следовательно слоев всего не более чем е.
Даже без...
То есть как бы без этой оговорки с подчисткой е log e, с оговоркой с подчисткой е log v.
Но правда это на самом деле не принципиально, потому что по модулю того, что как мы уже говорили, мы можем как бы кратный реобраз сжать.
За o от v плюс e без всяких мабов.
И после этого тогда log e и log v это будет одно и то же.
Ну потому что е не больше чем v квадрат.
Почему у нас вообще log k было изначально?
Потому что к слою.
Ну потому что ты сейчас обрабатываешь слой номер l.
Заметим, что тогда у тебя актуальными слоями может быть только слой l, l плюс один, l плюс два и так далее, l плюс k.
Потому что до больших расстояний ты просто не дожел, а все меньшее ты зачистил.
Следовательно там, ну ладно, не log k, а там формально можно вообще сказать k плюс один.
Ну вдруг там k у вас ноль.
Хотя что это за задача вообще такая, да?
А нет, ну знаете, это надо, потому что если k равно 1, у вас логарифом будет ноль.
И это не очень хорошо.
Поэтому лучше k плюс один.
Написать это будет надежно.
Сейчас какое удаление?
Ну это да.
Ну пойди, пойди, пойди.
Ну тут давай вот.
Нет, тут на эту тему можно вообще думать.
Нет.
Ну скажем так, просто не порти асимптотику.
Нет, понятно, что unordered set лучше убрать там скажем.
Ну его можно заменить.
Ну сам unordered set можно, как уже говорилось ранее, заменить на очередь.
Да, там сложнее будет удалять.
Ну там, дайте, там есть разные читы.
Знаете, есть такой чит.
А давайте вместо этого unordered set, если вас константа смущает, сделаем двусвязный список.
И будем удалять оттуда.
И на каждую вершину, естественно, хранить итератор, по нему удалять, потом вставлять.
Вот, ну конечно, да.
Наверное, по константе будет лучше.
Ну нет, ладно, это психологически лучше для нас, потому что unordered set пока для нас какая-то черная магия с ушами.
Нет, ну там где-то амортизация, где-то вероятность.
Нет, подождите.
Нет, лист экологически честный, да.
Вот.
Так что set он, да, лист он молодец.
Можно на самом деле даже обойтись и обычными векторами или даже очередями.
То есть для этого просто достаточно завести массив user.
И так.
Ну вот, и тогда как бы никаких криминалов не будет.
Вот.
Можно.
Как бы не обязательно, потому что когда рассматриваем вершину слова, мы знаем какое расстояние для этого.
Ну вот.
Мы можем проверять, что расстояние вершины совпадает с расстоянием слова.
Э, ну, а, пока да, хорошо.
Это не достаточно, потому что у нас вершина.
Ладно, уговорили, пока да.
Ну вот, так что-то у нас пока получился вот такой вот красивый bfs, прости, господи.
Да, за е лог е.
Ну или там е лог в.
А, нет, не может быть, не может быть.
Ну просто.
Нет, просто погодите.
Сейчас погодите.
Ладно, давайте сейчас не будем говорить о коде.
Давайте поговорим об идейности.
То есть идейно у нас появился алгоритм, который работает за е лог в с весами целыми от 1 до бесконечности.
Хотя я хочу сказать вопрос.
А если я добавлю дробные веса?
Добавлю дробные веса, но у меня здесь вместо лонг-лонга.
Вместо лонг-лонга, да?
Появится лонг-дабл.
А шо такое?
Нет.
Лонг-дабл мы не храним в анордерит ците, мы его храним в мапе, причем не анордерит.
Так шо все нормально.
Лонг-лонг-дабл это что-то очень странное.
А вы это смеетесь, да, ну ладно, уберу.
Вообще на самом деле лонг-дабл в мапе это очень плохо.
Ой, да, да, да, давайте.
Все.
Так, хорошо.
Давайте сделаем так, как мы уже поступали на этом занятии.
Да, так, сделаем так, как мы поступали.
Ой, так, все.
Нет, поступим, как мы уже поступали раньше.
Представим на месте лонг-дабла другой тип и продолжим получать удовольствие.
Вот.
Соответственно.
Все просто.
Пообразите себе вместо лонг-дабла этот ваш любимый тип А плюс Б корней из двух.
Символ не вычисляет.
То есть нет, а что?
Причем тут символы А плюс Б корней из двух?
Это числа, которые вы можете абсолютно точно складывать, учитать, умножать, делить, сравнивать, правда?
Абсолютно точно, целых числа.
По модулю какой-то там длинной арифметики, возможно, фуриатины, но мы пока будем считать, что это все равно за единицу делается, потому что веса там адекватные.
Вот.
Ну вот, вообрази в себе такую ситуацию.
Да, лонг-дабл без погрешностей.
Тогда будет ли работать такой алгоритм?
Вот парадоксально, но такой алгоритм работает.
Ну да.
Потому что да, мы отвергли в свое время идею о том, что как бы у нас не могут быть слой с непрерывными весами, но на самом деле вот в этой реализации они неожиданно появились.
То есть теперь у нас есть все слои, то есть от нуля до плюс бесконечности, просто реально мы там в мапе храним только те, которые нам реально понадобились.
И заметь, и доказательство вполне себе работает.
То есть обратите внимание, да, то есть у нас там доказательство получается так, то есть доказательство вполне себе, то есть получается на это мы рассматриваем прям путь.
И тогда замечаем, что если тут у нас 1.7, 1.9, корень из двух и так далее, то каждая вершина действительно оказывается в слое номер 1.7, 3.6, 3.6 плюс корень из двух и так далее.
Понимаете, да?
То есть заметим, что у нас тут не может быть так, что у вершины там внутри одного слоя там бывают какие-то изменения, там 3.4, 3.3, то есть теперь у нас все, 3.3 и 3.4 это теперь два разных слоя железобетона.
То есть Вася и Вася плюс Эпсилон это две принципиально разные личности.
Вот.
И поэтому получается, что про алгоритм работает.
Ну почему?
Нет, ну в чем проблема?
Ну что делать?
Да.
Нет, почему жалко-то?
Кто сказал, что как бы этот Эпсилон меняет в худшую сторону?
Уменяет личность.
И что?
Ну личность это по-любому такая штука, которая как бы либо...
Изменение это раздвоение.
Ну да.
Как бы любая личность по-любому либо развивается, либо деградирует как-то, знаете.
А, потому что деградация это развитие со знаком минус, ну да-да-да.
Ой, ну это уже да.
Я не деградирую, я отрицательно развиваюсь.
Да.
Я просто сторонник отрицательного развития, да.
Вот.
Отлично.
Всегда буду использовать.
Ну по-любому.
Да, по-любому.
Да, по-любому.
Да, по-любому.
Да.
Всегда буду использовать.
Ну можно так сказать, конечно, да.
Так вот.
Но заметим, что магия это работает и считает так, что не просто работает с вещественными весами.
Но еще и заметим, что она на самом деле будет прекрасно работать, даже если веса от нуля до бесконечности произвольны.
Включить-то.
А что думаешь мне?
А не включительно, ну как бы давайте считать нули к эпсилонам и радоваться жить.
А не включительно, понятно.
А также абсолютно идентично, потому что если у тебя тут ноль, значит вот эта вершина будет добавлена в очередь номер 3.6 плюс корень из двух.
Если она там не была раньше, конечно.
Ну просто в это, просто почему здесь все стало хорошо?
Потому что, да, очередей стало континуально много.
Вот.
Но зато мы гарантируем, что теперь номер очереди совпадает с реальным расстоянием.
То есть вот когда мы их начали различать, у нас там в айхике какие-то проблемы.
Вот.
А теперь проблем никаких нет.
То есть теперь расстояние есть я.
Да, все.
Расстояние есть номер слоя.
Так что получается, но так же получается мы только что научились за е-лог-е искать кратчайшие пути в графе, где веса абсолютно произвольные, ну по модулю всяких эпсилонов, но не меньше нуля.
То есть мы продолжаем пользоваться тем, что веса не меньше нуля, чтобы у нас как бы не оказывалось, что мы идем в предыдущий слой, который уже ранее обработали.
То есть видите, мы пользуемся тем, что мы слои перебираем в порядке возрастания.
Неплохо так, правда?
Это такой волновой БФС на бесконечность.
Да, правда, станут дарицитами или векторами.
Но на самом деле есть вполне себе естественная оптимизация, которая говорит нам следующее.
Слушайте, а вот ж по этому раскладу нам вообще эти волны не хранить.
Потому что вот альтернативная реализация, так сейчас давайте вот эпшилон дабл, сейчас я ее, вот так.
Смотрите, сейчас будет весело.
Это у нас работает за, напоминаю да, е-лог-е.
Е.
Чего?
Ну ладно, плюс В.
А теперь смотрите, сейчас мы сделаем абсолютно то же самое.
Не без волны.
Нет волнов.
Нет волнов.
Да, да, да.
Но нет волнов, нет.
Как сделать это без волнов?
Нет.
Используй альтернативную реализацию.
Нет.
В.
Вэйтэмон.
Значит, смотрите.
Смотрите, ZD is quite простая.
Нет, плохо звучит.
Да, господи, слушай, я сейчас гугл транслейт включу.
Ну да.
Заказали тут, а можно на китайском.
В связи с последними новостями, у всех R1, поэтому.
Что?
У всех R1 чего? Китайского?
Да.
Да.
А что за новости?
А R1 это что значит?
Это типа, что все английские знают или что?
А что за?
А что за новости?
Я не в теме.
Все, у кого B2+, автоматически на китайском показывают.
Пока.
Китайский B2, короче, будет.
А, ну да, да, да.
Как говорится, да.
Да, всем привет, а если в прошлом, тогда всем бонжур, да.
А если в будущем, ну тогда нихао, действительно.
Нет, самое страшное, что это шутка от азиатов еще 16-го года.
Но, видимо, в Киргизии действительно было давно уже ощущение, что в будущем будет нихао, да.
Так, ладно.
Так.
Так, почему вы начали говорить о Киргизии?
В какой момент вылезла нихао, да?
Кыргызский.
О, да.
Не, ну правильно, да, потому что.
Да, почему? Да, ну потому что Казах без понтов это Кыргыз, там вот это все.
Казах без понтов это без понтовый Казах.
Ну, нет.
Это классическое выражение, а потом кто-то было да Казах без понтов это Кыргыз.
Казах без понтов это Кыргыз, ой, извините.
Вот.
Но я не знаю, конкретно в Астане эта шутка там просто зашла на ура на самом деле.
Ладно.
Так вот, значит, делаем так.
Слои не храним, вместо этого делаем следующее.
Для каждой вершины мы храним, во-первых, да, в каком слое она лежит.
И, во-вторых, конечно же, помещена ли она.
Вместо того, чтобы вейс, ну вот, значит, делаем, то есть мап мы убираем.
Значит, вот эту мы убираем, то есть вот эту мы вот можем даже закомментировать пока.
Вот давайте я тут все буду пока комментировать.
Это буду тоже комментировать, потому что вейвсов больше не существует.
Так, ну и while-waves-empty заменяется на более оптимальный по проверке код while-true.
Ну да, конечно, операция на проверке хотимна меньше.
Причем один из них хватит.
Сейчас все будет. Смотрите int-v равно минус один.
Значит, перебираем.
Так, знаете, что нам не хватает?
Вот что нам реально не хватает? А, у нас n есть, слава Богу.
For int i равно нулю и меньше n.
Пробираемся по всем, без того, чтобы, то есть самый тупой вариант.
Пробираемся по всем вершинам и говорим, что если она еще не юзит,
и еще оказалось, что при этом v меньше нуля или у нее слишком большой слой,
пишем v равно i.
Значит, если v меньше нуля, то мы выбрасываем все из цикла.
Да, с криком все.
Так, а что теперь делаем?
Значит, v равно i.
Значит, теперь важная строчка.
Uset от v равно true.
Потому что прямо сейчас мы ее будем обрабатывать.
Вот, а вместо вот этого всего,
это вот мы вместо вот этого всего делали,
нам остается только взять вот эту вот замечательную штуку
и проделать вот буквально это.
Только вот заканчиваем.
Вот буквально это.
Только вот закомментить еще вот эту штуку.
А, и еще вот эту.
Упс.
Что за бред?
Не обновляйте.
Как-то не вот обновил.
Вы обновили расстояние, но вы не добавили больше, чтобы...
Да.
В том-то и чит. У меня больше нет очередей, нет волн.
Я просто для всех...
Я в весе того, чтобы говорить, найдите мне минимальную не пустую волну,
я говорю, так, так, а какие у нас вообще вершины есть еще,
которые не пройденные?
Ага, вот эти. Так, давайте я среди вас переберу
и найду там минимальную вершину с минимальной волной.
А вы с квадрат делаете?
Да.
Вот такой вот чит.
Чтобы было понятнее, да,
может показаться, что это прям очень страшный код,
но теперь я сделаю совсем крутую версию.
No waves, no comments.
Ну, это заявка на успех, конечно.
Вот, значит, смотрите, сейчас я сделаю абсолютно то же самое,
только вот уберу комментарии.
Да, код ставил без комментариев,
это, конечно, да.
Чего Илья Мещерин?
Ну, это да.
Илья Мещерин в курсе, что мы тут математикой занимаемся,
а не программированием, поэтому...
Ну да, но вот он занимается программированием,
как бы я занимаюсь математикой, да.
Ну, логично, да.
Как бы, точнее, олимпиадные школы, правильно?
Тут как бы у меня математика, у него программирование,
вот так.
Ну да, олимпиадные школы, да.
Вот, и получился вот такой минималистичный код.
Вот, работает он, очевидно.
Но, правда, минус такого кода заключается в том,
что мы теперь, конечно, каждый новый слой ищем за УАТВ.
И это работает в квадрат плюс Е.
Вот здесь, кстати, тоже терминологический момент.
Так вот, по крайней мере, с моей точки зрения,
вот это называется алгоритм ДЕКСТР.
Ну, нет, там я просто в последнее время стал...
Ну, просто тут забавная ситуация произошла,
потому что когда я изучал алгоритм ДЕКСТР,
мне рассказали вот это.
Правда, рассказали, что как найти кратчайшее расстояние?
Найти его вот так, доказательство.
Ну, и там дается доказательство, мы его, кстати,
тоже рассмотрим обязательно.
Потому что, по большому счету, мы там въектом,
в смысле, рассматриваем слои какие-то,
вот как-то там идем и так далее.
Вот, в общем-то, можно проще было сказать,
там просто докажем, что каждый раз, когда мы берем вершину,
там кратчайшее расстояние, доказательство.
Ну, там, ну, поднимите руки, кто даже вообще изучал
когда-то доказательство алгоритма ДЕКСТР.
Ну, вот.
Ну, разумеется.
Да, конечно, спасибо.
Вот.
Ну, просто я в последнее время стал,
стал сталкиваться с тем, что кто-то
вообще даже не в курсе, что алгоритм ДЕКСТР
бывает без кучи.
Или там без сета.
То есть, на самом деле, да.
Я бы просто лично для меня как-то ощущение
все равно осталось, что вот это вот алгоритм ДЕКСТР,
это на самом деле вот это.
То есть, следующее, это можно заметить,
что он работает за В квадрат плюс Е,
и если В квадрат это много, то давайте как-то оптимизировать.
А как оптимизировать?
Ну, самое тупое это, конечно,
давайте действительно хранить,
хранить все доступные там
не в массиве юзет,
а в каком-то сете там
с компаратором по дэшке.
Ну, не с компаратором, а там пары храним.
Да.
То есть, это вот алгоритм ДЕКСТР.
Да, то есть, вот теперь абсолютно та же версия
там с сетом.
Вот, например, самое тупое
по современным меркам, это бывает сет.
Это вот, да, вместо массива юзет
мы заводим просто set per long double.
Значит, int.
Сет.
И в результате тут прям сразу пишем, да.
Ну, по большому счету, да.
По большому счету, это он и есть.
Ну да, то есть, на самом деле, да.
ДЕКСТР это такой продвинутый BFS,
как вот.
И нам потребовалось его лишь там порядка пары часов,
чтобы понять, почему.
Собственно, да.
Вот, видите.
То есть, вот получается теперь то,
то есть, вот такая вот сетовая версия.
То есть, вот это мы убираем.
Там.
Тут мы даже вот...
Там.
Вот.
Так, intv равно p.second.
Вот.
Да, юзет убираем.
Так.
Ну, теперь смотрите.
Тут важно.
Вот.
Видите, я тут надежно пишу,
потому что erase в этом смысле приятный.
Да, если вы удаляете как бы из сета по ключу,
то как бы если его нет, то он ничего и не удалит.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот получается такая версия.
Но это уже, конечно же.
Там сколько получается?
В плюс Е лог В.
Вот.
Да.
Но это...
Да, если мы вспомним, что на самом деле в этом месте,
вместо сета может быть абсолютно любая куча.
Ну, там, конечно...
То есть, если вы напишете самописную кучу,
которая умеет как бы делать дикриски, то да.
Да.
Да, ну вот так.
Оговоримся, что да.
То есть, да, тут нам могла бы помочь куча фибоначчи действительно.
О.
А, ну, чего мы паримся, раз уж мы тут...
Раз уж мы код пишем.
Не, ничего страшного.
Так, смотрите.
Ничего страшного, в этом тоже будет.
Сейчас мы не в самой особой теме.
Мы сейчас будем писать фибоначки.
Ну, нет, конечно, мы не будем писать кучу фибоначчи.
Фибоначчи.
Значит, смотрите.
Тут мы сделаем вот так.
Значит, здесь мы сделаем вот как.
Место сета.
Значит...
Значит...
Ну, вот.
Так.
Ну, значит, теперь мы заведем следующее.
Значит, у нас тут будет фибоначчи-сиб.
Значит, фибоначчи-сиб.
Значит, ну типов у нас будет два, допустим.
Ну, допустим, во-первых, на вершину и там какой-нибудь лонг-дабл.
Ну, просто мы будем подразумевать, что у нас там type-name там...
Там сейчас как там это называется?
Там template, type-name t-vertex, t-weight.
Значит, фибоначчи-хип пишем мы.
Ну, так и пишем fh.
Ладно, или просто hip.
А, и это зарезервировано в STL-слово, поэтому лучше не надо.
Fh.
Что?
Нет, hip зарезервировано.
Нет, я тут не хочу писать фибоначчи-хип, прям вот это.
То есть, правильно написать, конечно, фибоначчи-хип.
Вот так вот, да.
Вот.
Ну, во-первых, это тоже неправильно, потому что надо что более умное написать.
Дистанцистом, например, вот это.
Вот.
Так.
Ну, во-первых, здесь мы и здесь пишем такое.
Ну, вот.
Вот, напишем такое.
Вот, напишем такое.
Я напишу так, у него будет метод дикой ски, но здесь я буду говорить, что просто если вершины нету, но я не умею проверять, если вершина, да.
Но я буду говорить так же, ладно.
Ну, там, хотя нам придется, конечно, для кучи фибоначчи каким-то образом мистическим хранить там, какие вершины в ней есть.
Может быть, внутри ее есть сет, который тупо хранит, какие вершины в ней вообще есть, да.
Ну, вот. Ну, ладно.
Ну, вот. Ну, я так вот. Сейчас будут некоторые такие оговорочки.
Там можно массив юзет ввести для аккуратности.
А, вот давайте ладно, я введу так и быть.
Нет, хотя нет.
Правда, юзет.
Правда, здесь нам придется немножко по-другому сделать.
Да, вектор бул.
Is in heap.
Вот так.
Можно вот так вот читерить.
Просто это я буду делать для того, чтобы понимать, мне как бы делать ставку или...
Вот, а это мы убираем.
Теперь, пока наша мистическая куча не пустая.
То мы делаем следующее.
Ну, допустим, там int v равно, допустим, экстракт мин.
Ну, таки там h, как там, h, как там?
fh.extract-min.
Видим, да?
Так.
Можно даже не int v, а, допустим...
Как там это?
Как там вот...
Что-то там тоже убили.
Как там это?
Что-то там тоже умное слово есть, вот это.
Так, auto, по-моему, v запятая w равно...
Вот что-то такое, да?
Все, не было такого?
Умное слово.
Ну, вот, да.
Давайте int v, long w.
А, уже этого даже не надо делать?
Не надо.
Ого, красиво.
Иначе бы это было более технично.
Значит...
Это не было бы умное слово, иначе.
Значит, смотрите.
Значит, tnl равно вот...
Да, но здесь вот делается то же самое, но теперь надо...
Так, значит, теперь говорим, если из int, значит, hip от int v,
то мы делаем s.decriski от int v.
От nv и, соответственно, вот этого nl.
В противном случае делаем...
Что мы делаем?
Is in hip от nv равно true, и действительно реально делаем вставку.
Вот, а это мы убираем.
Только делаем это не vs, а, конечно, vfash.
То есть вот, в принципе, так может выглядеть алгоритм Dijkstra.
Ну ладно, это мы уже вообще уберем.
С кучей Fibonacci.
Ну или любой другой кучей, на самом деле.
То есть, видите, у меня тут, конечно, есть маленькая оговорка,
что я подразумеваю, что по Dikriski он сразу автоматически найдет вершину, где она находится.
То есть, по-хорошему вам, конечно, надо хранить какие-то мистические итераторы,
по этим итераторам, собственно, Dikriski делать.
Понимаете, да?
Вот.
Ну мы, ладно, там не будем повторяться,
мы в прошлом году, в прошлом семестре уже обсуждали технологии,
как это теоретически может работать.
Вот.
Но, значит, в чем фишка?
Фишка, зачем мы это сделали?
Сделали мы это затем, да, то есть раньше мы v оценивали как e,
но теперь замечаем, что у нас происходит, да,
что мы, конечно, это что у нас insert и Dikriski делаются за вот единицы,
а вот экстракт мины делается, правда, за логарифом.
Поэтому теперь у нас лог v не при e-шке, а при v-шке.
Получился вот уже обсуждавшийся наименит алгоритм,
алгоритм Dijkstra с той кучей фибоначи теперь,
вот, который уже работает за v лог v плюс e.
Вот, понятно?
Вот.
Так что вот так мы вот и вы.
Ну вот.
Так и вывели алгоритм Dijkstra.
Мечты, мечты.
Нет, к сожалению, нет.
Ну, понимаете, просто есть куча базовых вещей,
которые мы с вами обсудить так или иначе должны.
То есть мы с вами должны что-то обладеть там,
ну, во-первых, мы должны обсудить Флойд и Фордон Белмана,
а во-вторых, самое главное, на самом деле,
тут у Dijkstra есть еще обобщение, на самом деле.
Так что не все это, так что просто так от Dijkstra не пойдем.
Так, ну вот, до Dijkstra дошли.
Ладно, думаю, если нет вопросов, то в этом месте, пожалуй,
пришло время перерыва.
Как у нас вообще по-хорошему, давайте помним,
доказывается алгоритм Dijkstra?
Обычно он доказывается так, что в каждый момент времени
у нас есть типа зона, где находятся вершины,
до которых мы расстояние типа нашли.
Да?
Вот там какие-то вот такие.
А есть вот вершины, до которых мы расстояние еще типа не нашли.
Ну, типа у которых use it равно false вот в версии без сетов.
И нам хочется теперь аккуратненько доказать,
что каждый раз, когда мы находим вершину и добавляем ее в use it,
то дэшка до нее реально корректна.
Вот нам хочется такое доказать, да?
Как мы это доказываем?
Доказываем это вот как.
Допустим, у нас вот это, то есть что такое D от U,
вот если это вершина U?
Это очевидно D от V, D от V плюс вес вот этот W, правда?
Вот.
И теперь предположим, предположим,
что там чисто теоретически может быть какой-то более короткий путь, да?
Который тут вот ходит и ходит и ходит и ходит.
Про него можно сказать только одно, что в какой-то момент времени,
ой, я тут еще не сюда пришел,
вот.
То есть про него можно сказать, что он хотя бы один раз выйдет
за пределы зоны use it.
Да?
Он в принципе может туда вернуться, тут гулять там вообще как угодно
и прийти в U.
И что?
Мы доказываем, что вот смотрите, вот мы говорим, что вот у нас
на очередной трассе D extra мы перебрали все непомеченные вершины
и выбрали вершину U, у которой вот этот use it минимальный,
вот D-шка минимальная.
Мы утверждаем, что это реальное расстояние.
Ну почему это реальное расстояние?
Ну потому что, во-первых, это длина реально какого-то пути, да?
То есть, помните, у нас просто сохраняется этот принцип,
что каждая D-шка это длина какого-то пути до этой вершины,
тут без вариантов.
Понимаете, да?
Вот, это была D-шка.
Вот, теперь предположим, что...
Значит, рассмотрим произвольный путь от S до U.
Так, ну существует первый раз, когда этот путь выходит за пределы
помеченной зоны, и это будет происходить через ребро V' U' с весом W'.
Понимаете, да?
Ну, теперь пишем.
Значит, вес вот этого штуки,
это вот экзотической штуки, вот всей вот этой вот, да?
Я ее так напишу.
Так, видно там?
Ой, или меня только не видно, но и не слышно?
Видно, видно, слышно, слышно?
Слышно там?
А, да, все, да.
Вот.
Значит, смотрите, больше это, больше либо равно,
больше это, больше либо равно.
Ну, во-первых, это, конечно,
больше либо равно, чем, значит, W от...
до вот этого, до вот этого вот ребра V' U'.
Логично, да?
Ну, почему?
Потому что у нас как бы, да, мы тут, в этом месте мы пользуемся тем,
что у нас путь ребра не отрицательная, да?
Поэтому если я длинный от пути просто отпилил суффикс,
то вес пути от этого только уменьшился.
Вот.
Дальше.
Теперь заметим, что вот это вот...
можно заменить на кратчайший путь до вершины V', правда?
Да.
Поэтому так и пишем.
Значит, D от V'
плюс W'.
Вот.
Вот.
Заметим, ну, теперь замечаем, что это
больше либо равно, чем текущее W'
Логично, да?
Ну, потому что раз уж W' был, то мы как минимум этим релаксировали.
Может, релаксировали чем-то лучше, я не знаю.
Вот.
А это больше либо равно D от U?
Потому что по определению U, правда?
Вот, все.
В принципе отсюда следует, что длина...
если взять этот произвольный путь,
то длина этого пути не более, чем
там D от U,
которая там в данном случае равна, обратите внимание,
D от V' плюс W'.
Ну, здесь уже по определению.
Вот, понятно?
Вот.
То есть, в принципе, вот классическое доказательство выглядит...
ну, я так немножко его может быть экзотически нарисовал,
но выглядит оно обычно примерно таким образом, да?
Значит, ну вот.
Это вот еще один способ, на самом деле,
доказательств D' и, в принципе, все BFS,
которые у нас были.
Вот.
В' уже U'.
Да.
То есть, смотрите, V' и U' – это первое ребро
на этом вот каком-то пути,
которое как бы выходит за пределы U'.
То есть, V' – это его начало,
еще в помеченное, а U' – не помеченное.
Или, что то же самое, U' – первая не помеченная вершина на пути.
U' – первая не помеченная вершина.
Да.
Вот.
Давайте, вот, я тут помечу.
Это V', это U', это V'.
То есть, вот такой простой доказательств.
Значит, к чему я это?
Да, может оказывать и так.
Но обычно вот, да, классическое доказательство такое.
Но теперь вытекает идея.
Как вы говорите, а как бы нам эту дырку обобщить?
А на что?
А вот.
А вот, смотрите, просто дело в том, что...
Ну, вот, да, мы сейчас говорим о такой достаточно ограниченной задачи,
виду, что у нас есть ребра, у ребер есть веса,
и вес пути – это сумма весов ребер.
Ну, мы точно так же и максимум, и минимум.
Вот.
А теперь вот вытекает такое.
А ведь функционалы бывают разные.
Потому что вес бывает, может, например, длина пути – это максимум весов, например.
Или минимум.
Или два максимума как пара, типа первый максимум, второй максимум.
Вот.
Что еще?
А, или вообще автобусы.
Ну-ка, сталкивались вот с...
Ну, не в этом смысле.
Да.
Но я имею в виду, конечно, задачу на информатике – все автобусы, а не там.
Да.
Задача с автобусом – это интересный опыт, конечно.
Ну да.
Интересно послушать, конечно, тех, кто это сделал.
Если получится.
Ну да.
Вот.
Но я просто имею в виду задачу на информатике – все автобусы.
Ну-ка, погибите руки, кто с ней сталкивался.
Я не помню названия.
Мы, к сожалению, не знаем задачи с информатикой по названиям.
Да, хорошо.
Ладно, сейчас я расскажу задачу.
Задача такая.
Если вы хотите попасть в граф, вы хотите попасть из вершины номер один в вершину номер н.
Но не все так просто.
Да.
Между городами ходят односторонние автобусы.
Вот.
Но они, хаты такие, у них ходят по расписанию.
То есть как бы для каждого автобуса известно, в какой момент он выедет из города и в какой момент туда приедет.
Сканлайн.
Сканлайн?
Какой сканлайн?
Время.
Вот.
Ну, правда, тут, конечно, начинаются мелкие оговорки в ДУТе, что, конечно, там садиться в следующий автобус вы можете там не ранее, чем вылезли из предыдущего в том же городе.
Ну, кажется, это решается ровно также.
Вот, да.
Это еще один пример вот какого-то функционала.
То есть как бы сейчас мы это попробуем обобщить.
Ну, там просто местосложение будет, сложение со взятием максимум.
Вот.
То есть представим себе, что у нас есть какой-то мистический, то есть у нас как бы вместо D от V вот плюс double есть, то есть как бы есть пути, есть какой-то мистический F от пути.
Ладно.
Обычно мы это будем называть как F от RO.
Эту крылью просто поменьше нарисовал.
Вот.
Так, давайте я красненьким начну рисовать.
То есть вот F от RO это будет.
Вот, где RO это вот какая-то вот такая загогулина, там путь, ну путь, короче.
Есть F от RO.
И более того, да, то есть мы умеем, конечно, брать пути и как-то пририсовывать к нему еще ребро.
То есть поэтому вот такую операцию мы типа тоже за O от единицы умеем делать для того, чтобы алгоритм DX3 можно было запустить вообще.
Ну, то есть потому что в D у нас вот F от какого-то RO будет храниться в D-шке, и вот вместо D от V4 плюс W будет храниться вот это.
И вот нам просто жутко интересно, можно ли вообще, нам хочется выработать какие-то критерии на этот функционал, на свойство этого функционала, чтобы алгоритм DX3 доказательно работал.
То есть иногда может быть даже тестировать где-то, да, то есть можно ли запустить DX3 и там вот проверить критерии.
Если критерии будут ветерять, значит DX3 работает.
RO это вершина?
Что?
RO это вершина.
Нет, RO это путь.
RO это путь, E это ребро, которое мы прицепляем к концу этого пути.
Ну точно должно быть, не равенство, что F от RO плюс E больше.
Телефончик у тебя тоже забирать, да?
Господи, да, все-таки ты не можешь делать меньше двух дел одновременно, да?
Не получается.
Не получается, а надо вот сосредотачиваться, да.
Так что переворачивай, переворачивай.
Давай-давай-давай.
А он с тобой там играет, что ли?
Откуда ты знаешь, заканчивается у того времени, заканчивается.
Так, все.
Я сам это читал неделю назад.
Чего?
Я сам это неделю назад рассказывал.
Где?
Ну, в репетиторстве немного просто.
О господи.
А кого ты так репетиторишь?
Тебе надо было об общении DX рассказывать.
Блин, задачи-то решать надо.
Ну, я не прям сильно формально, но с доказательствами.
Ну понятно, понятно.
Ну ладно, давайте тогда разбираться.
Или все это знают, это можно промотать.
Может быть что-то случайно.
Может быть, какие-то пробелы могут быть случайны.
Ну могут, да.
Ну, собственно, да.
По этим причинам это все обычно и рассказывают.
По этим причинам придется рассказывать, что такое DFS.
Нет, там просто будет договор, когда там на самом деле, я просто сразу скажу.
Во-первых, надо понимать, что такое белый, серый, черный цвета.
Там что такое обратное эго, там прямое эго.
Там надо терминологию договариваться.
Там какие-то свойства еще там.
Потому что есть вообще понятие LEMO о белых путях.
Как показывает практика, если просто у рандомного человека спросить.
Все знают, что это такое, но если рандомно спросить, то даны рандомные ответы.
Ну вот.
LEMO в безопасном прибрее, это не на DFS, это на Остове.
Ну, до Остовов мы тоже доживем.
Ну, там до Остовы хотя бы прикольные алгоритмы будут.
А, как будто на DFS не будет дерева доминаторов, да.
Или это прям не все знают, что такое компоненты вершины двух связностей, например.
Ну вот.
Ну, там.
Ну, противладно, это мы с вами выясним еще.
Так вот.
Ладно, давайте с F-ками попробуем это обобщить.
Значит, какие свойства нам вообще нужны?
Ну, нам желательно, чтобы вот это доказательство желательно вот в таком виде прокатывало, да.
Значит, что нам нужно?
Ну, во-первых, W от это тут превращается до F от вот этого РО.
Это должно быть больше либо равно, чем F от, так сказать, РО штрих.
Так сказать, обрубленное, да.
Вот.
Это больше либо равно, должно быть, это у нас должно быть больше либо равно, чем F от, значит, РО, РО оптимальная от В-штрих.
Плюс Е.
Значит, РО оптимальная от В-штрих.
Плюс Е от вот этого вот В-штрих, У-штрих, W-штрих.
Так, давайте эту, так, эту красоту я сотру.
Так.
Чего?
Так, ладно, давайте-ка я даже вот не в строчку буду вписывать, пожалуй, давайте я это лучше отдельно буду писать, чтобы было понятно.
Значит, смотрите, что у нас происходит?
F от вот этого абсолютно рандомного пути, да, где-то тут вот возникает вот это ребро В-штрих, У-штрих, да.
Должно быть больше либо равно, чем F от вот этого вот пути В-штрих, У-штрих.
Видите, мы этим явно, ну вот, я вот просто вот эти неральства переписываю аккуратно, да.
Дальше, больше либо равно.
Это больше либо равно, чем, ну, у нас тут такой, такой интересный шаг, мы тут вот этот часть пути заменили на оптимальный.
То есть, вот этот вот оптимальный путь, ну, типа кратчайший ДВ-штрих и плюс У-штрих, ну, потому что мы ж вот так вот релаксировали.
Вот.
Ну, вообще, так, потом мы сказали, что это должно быть больше либо равно, чем ДАТУ-штрих.
Ну, а здесь это больше либо равно, чем ДАТУ.
Вот. Ну, а это равно типа РО от, соответственно, оптимального пути до В и с приписанным вот этим ребром.
Вот. То есть, вот такое доказательство мы хотим, чтобы прокатывало.
Именно так.
Ну, заметим, такие, значит, что нам требуется?
Ну, заметим, вот это свойство на самом деле не так тривиально.
Вот уже первые требования не так тривиальны.
То есть, этот свойство говорит так, что мы отпилили от пути несколько ребер и от этого, там, с конца от этого хуже не стало.
Вот. Тогда придется ввести такое первое свойство, что отпилили БРО, хуже не станет.
То есть, F от РО плюс Е должно быть больше либо равно, чем F от РО.
Понятно, да?
А, ну, то есть, например, минимум уже не равно.
Да. То есть, это вот, да.
То есть, минимум вылетает.
Но минимум действительно имеет такой аналог, как минус один, да, то есть, слой уменьшается.
Ну, то есть, логично, да, что с проходом по либру слой должен расти.
Ну, тут тоже есть понятие слой, да, но я не знаю, насколько.
То есть, понятно, что подразумевается, что F у нас это выдает значение в каком-то, видимо, линейном порядке на множестве, естественно.
Максимум, как мы знаем, прекрасно подходит.
Да, точно знаем.
А, впрочем, сейчас выясним.
Да, господи, мы же пишем эту технологию, чтобы убедиться, как это выяснить.
Так, и теперь двоечка.
Значит, какие еще свойства надо?
А тут, на самом деле, второе свойство не так тривиально.
Вообще, иногда, на первый взгляд, не очень внимательный взгляд, можно даже не заметить, что тут еще что-то вообще надо.
Казалось бы...
Ассоциативность?
Нет.
Нет, какая ассоциативность?
Тут еще круче.
Вот, смотрите, мы сделали такую операцию, что жил-был какой-то путь.
Мы в нем взяли префикс и заменили его на более короткий путь до этой вершины.
Так вот.
На самом деле, далеко не всегда можно задуматься, а следует ли из этого, что если к этим двум путям пририсовать одно и то же ребро, то как бы неравенство будет в ту же сторону.
А вдруг бывает так, что это дорога короткая, а это длинная.
Но если прерисовать не одно и то же ребро, то, наоборот, это станет длиннее, это короче.
Трансситивность, да, в общем?
Вот.
Чего?
Нет, не трансситивность.
Корридионалность добавления...
Ну, за ординалы не скажу.
Я не знаю, какой может тут пример привести.
Ординал, если слева прибавлять, то оно не будет строганным.
Ну, хотя бы не строганным.
Ну вот.
Будет у нас такой экзотический пример, как сумма двух минимумов на пути.
Ну, допустим, вот на одном пути минимум был, допустим, там были путь 2, 3, 5, а на другом там 1, 100, 200.
Тогда сумма двух минимумов здесь оказалась меньше.
Но если вы прерисовали новое ребро, которое было веса 0, то неожиданно пошел обгон.
А зачем нам это свойство?
Ну вот, это такой экзотический пример.
Но это просто, заметим, что просто, то есть оказывается, что вот это свойство на таком функционале обломается.
Да, вот такая экзотика.
А, потому что, ну да, понятно.
Ну, для того, потому что мы тут, видите, подменяем префикс пути на, так сказать, кратчайшие и, должно сказать, то есть нам, по идее, желательно вот такое свойство.
Что если у нас есть какой-то путь, что, что, допустим, у нас есть вот два пути до вершины какой-нибудь В, назовем их РО и РО штрих, и тут еще торчит какое-то ребро Е.
И тогда свойство должно быть такое, что если F от РО больше либо равно, чем E от РО штрих, то из этого должно следовать, что F от РО плюс Е тоже больше либо равен, чем F от РО штрих плюс Е.
Вот, это второе.
Вот, чтобы вот это неравенство заходило.
У нас разве вот этот путь не есть, ну, кратчайших?
Как кто сказал?
Вот, я что-то же говорю, проблема, что у нас произошло следующее. У нас был вот такой какой-то путь здесь, да?
А мы хотим вот этот путь заменить на кратчайший, но он кратчайший для этой вершины.
И может так оказаться, вот это вот, да, конторинтуитивно, но если вот этот путь, допустим, короче, вот этого, то кто сказал, что вот этот путь будет короче этого?
Да, это не конторинтуитивно даже.
Те же самые автобусы.
Нет, в автобусах как раз нормально, потому что если вы там сюда приехали раньше, то как бы с этим ребром вы приедете одинаково.
Просто показать, что как минимум мы можем в одно время уехать, несмотря на то, что в разное приехали.
Да, но главное, что мы раньше приехали, потому что нет, мы же могли позже приехать и не успеть на автобус.
Да, да.
Чего?
Нет, в первом переходе мы делали другое. Мы брали вот путь и отпилили от него с конца ребра.
Это что за путь?
Да, рассмотрим какой-то вот этот вот путь до вершины У.
Мы пытаемся доказать, что вот этот путь, который мы нашли, да, там вот такой вот, да, через релаксацию, он не хуже.
И для этого мы используем вот эту цепочку неравенств, которая превратилась вот там с Ф-ками вот в такую цепочку неравенств.
А мы обязательно используем это свойство, если мы в самом случае просто не релаксируем.
Что значит не релаксировать?
Я не очень понимаю, зачем нам это свойство.
В смысле, нам это свойство?
Нам это звучит очевидно, но в том плане, что глобально, если мы что-то лучше вычисляем.
Нет, в смысле, а где? Ну, релаксировать там надо, потому что мы же по дешкам минимум выбираем.
Но в плане, бывают ли адекватные примеры, в которых первое свойство работает, а второе не работает?
Это работает, а второе не работает.
Потому что сам еду к минимуму, и первое ломается.
Угу.
Так, ну это да.
Да, ну это называется да, что-то да, что-то да.
Да не, можно придумать, чтобы ломалось второе?
Наверное, можно, они достаточно независимы.
Ну, вот так-то вроде да.
Можно, нет, ну можно как минимум накрутить пример в духе, что к каждому, то есть к каждому, то есть длина пути это сумма весов плюс количество ребер умножить на какой-нибудь там плюс бесконечность.
Ну там что-нибудь типа пара из количества ребер.
Сначала мы меряем по количеству ребер, а при равных количествах ребер меряем расстояние.
Например.
Например.
Ну правда, в чем расстояние, меряем по любому функционалу.
На этот раз.
На этом вроде Dx работает нормально.
Ну не совсем.
Нет, если, ну вот, первое будет выполнено, а если мы второй вес вот при одинаковом количестве ребер будем мерить как угодно, то мы вот подсовываем вот эту вот сумму двух минимумов.
Ну блин, ладно.
Ну смотри, как говорится, супер мега эвка.
Супер мега эвка.
Значит у нее два параметра.
Первое, количество ребер на пути.
Второе, сумма двух минимумов этих ребер.
А, не, ну сумма двух минимумов, ладно, да.
Вот, плюс сумма, да.
Ну если сумма и просто расстояние, то нормально.
Ну конечно, да.
Так-то конечно работает, прям вот здесь же и убеждаемся, да.
То есть там в общем то обе свойства работают, очевидно.
Вот.
Так что вот такая красота получается.
Ну опять, да, по-хорошему еще надо проверить, так, нужно ли еще тут какие-то свойства нарисовать.
Но заметим это просто, но заметим, что все остальное верно просто по структуре алгоритма.
Понимаете, да?
Ну еще ладно, да.
Ну еще ладно, да.
То есть это как бы по алгоритмам, по алгоритмам.
Но еще тут, конечно, что DATU это реально расстояние.
Ну а, ну хотя нам это в общем-то и не важно.
Потому что DATU это длина какого-то пути реально.
Мы доказываем по большому счету, что.
Ну еще для того, чтобы алгоритм работал за быстро нам бы хотелось, чтобы мы могли адекватно пересчитывать, как меняется дешка при добавлении ребра.
Да, ну конечно.
Да, это подразумевается, что у нас F как-то вот хорошо устроено, да.
Ну не просто.
Да, понятно.
Да, потому что может там вообще развлекаться, что там е, там вес строки, то есть вес ребра это строка, а там вес пути это конкотинация.
Вот.
И как мы сравниваем веса, ну естественно, лексикографически.
Количество вхождения одно и в другое.
Правда, там уже больше похоже на циклы отрицательного веса будут, конечно.
Потому что типа нам придется в какой-то момент обязательно прийти, потому что, знаете, вот это.
Не, вершина это строки, а длина ребра это количество вхождения там одно и в другую.
Хотя не так интересно, так сильно посчитали и все.
Мясо, да.
Что-нибудь интереснее можно.
Нет, фишка, я говорю, конкотинация строчек-то на нарисованных на ребрах.
Ну тогда там получается такой эпический тест.
Вот такой.
А, хотя да, потому что мясо точно.
Да, если строки ищем лексикографически, то.
Да.
То мы немножко умираем.
Да.
Но он даже не отрицательный.
Как это называется, какая минимальная строчка будет в хит?
Минус бесконечность, да.
Ну, кстати, он с строками это очень хороший пример.
Это прикольный.
Строка длины минус бесконечность.
Да.
Нет, ну да.
Какое мясо надо.
Нет, на самом деле это в принципе, конечно, уже это начинает
нас приводить вообще к отрицательным ребрам.
Потому что заметим, что, да, вот видите, то есть в некоторых
компаратах функционала вообще бывает так, что можно
то есть накручивать сколь угодно, да.
Но сейчас будем думать.
Потому что заметим, что у Dexter'я, конечно, принципиально
функциональное ограничение, вот как минимум уже первое, о том, что
как бы у нас должны быть какие-то слои и мы по ним как-то
непрерывно движемся.
Ну, вот.
Ну, вот.
Дик, ты первое ограничение, что у нас адекватные условия задачи.
Ну, вот.
Адекватная?
Ну, мы не можем там бегать условно в прошлое.
Ну, нет.
Ну, это как бы наше восприятие такое.
Потому что, в общем-то, возникают задачи, если уж идти дальше.
Так, ну здесь вот, там.
А, ну хотя нет, давайте вот, если тут пообобщать, то тут
как бы можно уже рассматривать примеры, да.
То есть, например, тупо.
Если мы ищем максимум на пути, например, да.
Ну, мы обнаружим, что если пути у нас максимум на пути,
то заметим, что первое условие, очевидно, выполнено, да.
Вот.
И, там, если жили были два пути, первые больше второго,
то если к ним добавили ребро, то мы берем максимум этого
и этого и максимум этого и этого.
Ну, очевидно, что это меньше не стало.
Правда?
Ну, логично, да?
Ну, минимум, ну, вылетает в трубу.
Там два минимума, там вылетает тоже в трубу.
Там что еще?
Автобусы.
Ну, тут автобусов самое интересное тут сформулировать,
а что такое F от РО в терминах автобуса.
Ну, там это, конечно, просто рассмотрим путь, последовательность ребер,
и скажем, что длина пути это минимальное время,
когда мы на таком пути можем приехать вообще по такому пути.
Ну, просто жадно выбирая автобус, либо плюс бесконечность,
если по такому пути приехать вообще нельзя.
Ну, тогда первое слово, первое свойство логично,
потому что мы приезжаем в заданное время и как бы там все-таки едем.
То есть там подразумевается главное, что автобусы в прошлое и не ездят.
На второе, да, если, допустим, я в эту вершину Паро приезжаю чуть позже,
чем Ро Штрих, то как бы прицепляя ребро Е, я, наверное, в У через вот это раньше не приеду.
Потому что, как минимум, тем же автобусом, который я уехал здесь,
могу уехать и здесь.
Так что вот, соответственно, классика.
О, ты значит, ты кому-то прям вот это рассказывал.
Ну, примерно так, только без эфок и не заводя сильно формирую.
Из общего случая как-то.
Ну, это да, нет, просто обычно там задачи автобусы там часто даются проще.
Там рассказывается просто алгоритм дэкстри, а потом в контесте дается эта задача.
А потом на разборе говорим, она решается алгоритм дэкстри, доказательства,
вот приэмулируем доказательства, обнаружим шуфу.
Это совсем треш.
Это совсем треш.
Ну, почти.
В смысле, это просто какая-то неочевидная из названия задача алгоритм дэкстри.
В плане, когда тебе дэкстри читают в первый раз, наверное, это...
Наверное, это может.
Так делают волкаша в параллели ц, и это действительно писано.
Сейчас делаю как? Прямо вот с этим вот рассказываю?
В смысле, рассказывают просто дэкстри.
Правильно.
И это нормально придумывается.
Это примерно то же самое.
Да-да-да. Ну окей, окей.
Единственная проблема, а где волкаша потом рассказывают?
Вот это вот.
Наверное, они разнесут.
На разборе потом.
А, ну могут.
Да, Гайля рассказывали?
Ух ты, а кто вел?
Что?
Что такое разбор волкаша?
Панамарев.
А, ну окей.
Ну окей, хорошо.
Посмотри, тогда просто интересно.
Ой, ну это да, нет.
Интересно иногда просливать цепочки, потому что мне это рассказывал еще мой великий предшественник.
Ну, Гальштейн, который.
Виталий Борисович.
В этом видео.
Вот еще интересно.
Ну окей.
Так что вот такая красота получается.
Ну, значит теперь попробуем копнуть в другую сторону.
В другую сторону.
Ну сейчас тоже будет не совсем тривиально.
Это, конечно, там волкаша тоже и звучает, а волкаша это часто такое, как какая-то отдельная маленькая ветчика, которую как-то не все запоминают.
Так.
Хотя нет, почало, конечно, запоминает тебе.
Потому что что делать, если мы ищем корчайший путь, и там бывают отрицательные веса.
Да, мы сейчас возвращаемся все в обычное время.
То есть в обычное, там.
Ну сейчас.
Она, по-моему, на циклу отрицательного веса не работает.
Сейчас.
Вот сейчас все.
Не, ну тебе же нужно понять, что цикл отрицательного веса есть, а не просто где-то.
Да.
Не волнуйтесь, сейчас все будет.
Бронетанк наших лекций сейчас как бы все это перемелет спокойно, не волнуйтесь.
Если нам гарантируется нет циклов, то можно реально потенциалы расставить.
Ну, правда, для того, чтобы их расставить, тебе придется найти корчайшее расстояние, да.
Посмотрите, что у тебя цельнейших реактораций.
Нет, смотрите, тут какую задачу решать.
Стоп, давайте начнем.
Ну пока, например, мы решаем задачу.
Как она называется?
Сейчас, там просто какие-то, есть просто умная аббревиатура на самом деле.
Там что-то там.
В данном случае, по-моему.
Так, S, S, A.
Вот что там, D, что ли, получается.
Потому что вот такие задачи, есть там вот такие понятия.
Ну вот.
Там S, S, S, ну допустим.
Похоже на трагму.
Т.
Нет, там нет.
Нет, просто я не помню точные буквы, как бы, но классическая там вот.
Как бы расшифровывается так.
Сингл сорс, там сингл таркет.
Или сингл финиш.
Вот я вот там вместо таргета, что-то другие какие-то могут быть буквы.
Там P, по-моему.
Да, один из паттернов в программе.
Нет, просто что это.
Кажется, есть SSSP и сингл сорс шортеспас.
А, шортеспас, точно.
Да.
А, ну значит.
Вот.
А, хорошо.
Да, спасибо, точно.
Да, точно, точно, точно, точно.
Да, точно, точно, точно, точно.
Как паттерн в программировании.
Да.
Да.
Значит.
Ну, тут вот, да.
То есть обычно, то есть разница такая.
То есть бывает разные задачи.
Бывает задача просто дана старта вершины, дана финишни вершины.
И найдите корчайший путь.
Ну, это просто вот на уровне.
Тут есть SSSP.
Ну вот, есть там наоборот.
У него тут есть APSP.
Это как бы all pairs.
То есть, типа, давайте найдем, корчайшие пути между всеми парами вершин.
Есть что-то еще.
Ну, какой-нибудь, видимо, one pair шортеспас.
Нет, ну есть там.
Сингл пейер там, да.
Я вот не помню, как называется задача, которую сейчас решаем мы.
То есть, типа, сингл сорс, но там, собственно, все таргеты.
Вот.
Это, наверное, SSSP.
Вроде это есть SSSP.
Да.
Да.
Да.
Да.
А, да?
А, ну окей, хорошо.
Ладно, пусть.
Ну, наверное, хорошо.
Да, да, да, да.
Ну вот, да, вот так вот, да.
Мы пока ищем корчайшие расстояния от одной вершины до всех остальных.
Чего?
Ну.
А.
А, это ничего.
Это я букву вспоминал.
Так.
Вот, определение SSSP это для всех достижимых из одной вершины.
Нет, ну не совсем.
Но я говорю так.
Найдем все корчайшие расстояния.
Просто иногда оно бывает плюс бесконечность.
Вот.
Да.
Вот.
Та переча.
Значит, теперь, что делать, если у нас.
Ну вот, у нас бывает.
Если у нас есть отрицательные ребра.
То, конечно, да.
Дэкстрей там со всякими BFS-ами тут вылетает в трубу.
Даже если тут единица и минус единица.
Там пять какой-нибудь.
Там шесть.
Там минус восемь.
Там все что угодно может быть.
Вот.
Ну а что можно сделать?
Ну вот.
Тут бывает маленькая проблема.
Ну вот.
Бывает еще проблема, что у нас иногда бывают циклы отрицательного веса.
Это подлянка.
Нет, это не смерть.
Это просто знак того, что расстояние до вершины бывает не только плюс бесконечность, когда просто пути нет.
Но и бывает минус бесконечность.
То есть это означает, что можно накрутить путь сколь угодно малого веса.
В чем?
Малого не по модуле, а в смысле отрицательности.
То есть такое, как минимум, может быть.
И это придется учитывать.
Но как мы это сделаем?
Ну первое, что придется в голову.
Хорошо.
Вот как накрутить минус бесконечность?
Найти отрицательный цикл и собственно и накручивать на нем сколько угодно.
Но правда, для этого нужно найти цикл отрицательного веса, через который можно от этой вершины до этой дойти.
То есть в таком графе цикл отрицательного веса есть, но путь до этой вершины вполне себе...
То есть расстояние до нее вполне себе пять.
Потому что цикл отрицательного веса где-то в ауте.
Но тут давайте какая-то вопрос.
Хорошо.
А может ли обойтись без цикла отрицательного веса и тем не менее получить минус бесконечность?
А можно вопрос?
А, все, нет вопроса.
Но без цикла отрицательного веса и минус бесконечность?
Нет, если у нас путь какой-то, чтобы путь был скорой годно малого веса, он должен быть бесконечным.
Ну нет, бесконечным он быть не обязан?
Нет.
Ну давай туда.
Ну я думаю, что нам не вовремя заходить по одной и той же вершине два раза, если у нас нет цикла.
Ну да.
Точнее, нам не выгодно проходить по циклу и не отрицательного веса.
Нет, ну как не...
Ну ладно.
Идея...
Так, ну ладно, понятно, да.
Не отрицательного веса.
Так, ну понятно.
В общем, идея понятная, это конечно суть вопрос разных формулировок или разных, но суть действительно одна.
То есть просто докажем.
То есть утверждение, можно доказать так, утверждение, расстояние от S до T равно минус бесконечности.
Тогда и только тогда, когда существует цикл отрицательного веса...
На пути из S до T, видимо.
Ну не точная формулировка.
Как бы эта формулировка просто валится вот каким-то вот таким красивым тестом.
Вот такой балалаечкой.
Так я ж не говорю, что на качающем пути.
Нет, ну вот просто...
Ну ассоциации немножко не те, да.
Поэтому сказать, если существует цикл отрицательного веса...
Достижимый...
Ну я так скажу, достижимый...
Достижимый из S...
Ну вот и из...
Ну допустим, из которого достижима T.
Вот.
Вот такое утверждение.
В обратную сторону очевидно, потому что пришли в этот цикл, накрутили сколько нам нужно и пришли в T.
Там всякие подлые тесты на эту тему есть.
Здесь, да.
Тут бывает 10 девятый.
Тут какой-нибудь мелкий тест.
Минус один, минус один, минус один.
И 10 девятый.
Основная подлянка, кстати, бывает еще задачей в том, что тут бывает еще ребро веса минус 10.
И тогда, знаете, очень легко допустить ошибку, которая вот тут минус бесконечности не идентифицирует.
Ну и очень зря.
Ну и другое.
Эта задача, конечно...
Да, но это, в общем-то, это...
Невозможно решить эту задачу на информатике, где нужно находить все пары, короче, расстояния со всеми этими случаями.
Ну почему? Прекрасно можно.
Нет, это можно сделать из асимптутику Форда Белмана и из асимптутику Флойда. В чем проблема?
Проблема в том, что баги, баги, баги.
А, ну, это всегда проблема, знаете?
Это не проблема задачи, да?
Да. Нет, ну почему?
Ну почему?
Ага.
Но это хорошо. Просто если принять это за абсолютную истину, то тогда причин не любить геометрию нет.
Потому что геометрия тоже там не любит, потому что по причине баги, баги, баги, баги.
Глобально в геометрии все хорошо.
А еще подобрать епсилон.
По моему опту в 97% случаев там называется бага не в епсилонах.
А бага просто, что вы там либо случай не рассмотрели, либо просто сильно опираетесь на картинку.
Мне очень интересно, что приходилось будет епсилон, чтобы получить типа 50 из 100.
Угу.
Ну бывает.
Нет, просто многие геометрические задачи, они там бывают на такие, там бывает такое, что решение на самом деле существует целых числа.
В нашем 11 классе епсилон решал 70-100 баллов просто по задаче.
А, ну окей.
А в баллах был епсилон какой-то типа 1-11, по-моему.
Неплохо.
1-10 не получало 100.
А, неплохо.
Но правда, да, а потом не выяснилось?
Это было вообще не очевидно, что нужно именно так покрутить.
Нет, вопрос только не выяснилось ли потом, что у жюри на самом деле, как это в таких случаях положено, есть решение без епсилонов.
Нет, там не было.
Да? Тогда жюри откуда они знают, что это епсилон правильный, да?
Ну просто нет, епсилон приходит тест и все.
Да, а тест, нет, проблема.
Но тесты писали, да, то тесты основаны на, ответ на тесты основан на авторском решении, которое писали авторы, спрашивается антроний.
На задачу был просто, вот там есноу зависело от епсилов.
Вот так вот, внимание просто, откуда жюри знают, что у них правильные ответы тогда в таком случае.
Тогда уже вопрос доказательности.
Нет, я помню Макс Ахмедов, как бы я помню, Петр Заводский там умел там отвечать на такие вопросы.
Ну там действительно был что-то эпик, действительно с епсилонами, но и там говорили, что мы просто проводили эксперименты и обнаруживали, что там вот, и просто выводили правильный епсилон.
Что там как бы они там все кто-то кучкуется, а потом бабах большой гэп и опять кучкуется.
Там в этом смысле мы проводили прям эксперименты, это действительно так, поэтому все хорошо.
Вот.
Кстати, на одну из команд, которые обсуждают, писали по-моему что-то про кода, тоже приходилось епсилон геомикрутить.
Да, ух ты.
Ну бывает. Ну окей, хорошо.
Так, ладно, убираем.
Так вот, господа.
Так, господа, что-то шум пошел какой-то.
Значит, смотрите, идем в эту сторону, все понятно, а вот в другую сторону вопрос.
Ну вот, верно, если путь минус бесконечность, то почему существует центр цикла отрицательного веса, через который можно пройти?
Пусть на пути нет цикла отрицательного веса.
Нет, на каком пути?
На каком пути?
Возьмем.
Да, минус бесконечность, это вещь такая, у нас нет пути длины минус бесконечность.
У нас любой путь, который мы рассматриваем, он как бы скостает из конечного числа ребер и, соответственно, нет.
И, соответственно, имеет какой-то вполне себе конечный вес.
Возьмем минимальный вес ребра.
Домножим его на n.
И скажем, что у нас есть путь веса меньше, чем n на минимальный вес ребра.
Нет, ладно, идея верная, только формулировка из цикла уже нужна, если шнурки в повторной связности.
В повторном связывании, когда вы хотите проверить про удовольствие вам пристрелить себе ногу.
Потому что более короткая формулировка звучит так.
Рассмотрим минимальный по весу простой путь из СПТ.
Ну, заметим, что простых путей у нас в конечном графе конечное количество, правда?
Поэтому и кратчайший простой путь существует. Вот у него, допустим, вес w.
Дист от w равно минус бесконечности означает, что существует путь веса меньше w.
Вот. Рассмотрим путь длины меньше w.
Вот. Тогда заметим, что этот путь рано или поздно зациклится.
Вот я буду идти-идти, пусть я первый раз попал в вершину, да?
И тогда, либо у меня этот цикл отрицательный, тогда мы победили, либо он не отрицательный, тогда я его выкидываю.
То есть на пути уменьшилось количество ребер, а вес все еще остался меньше w.
Дальше идем, идем, идем, идем, идем, и вот тоже находим цикл, если он не отрицательного веса, то отпиливаем.
Ну и, в общем, рано или поздно мы вынуждены будем заключить, что либо мы наткнемся на цикл отрицательного веса, либо мы убьем все циклы.
Ну вот. И тогда у нас получится просто простой путь.
Да, просто простой путь, да. Вот.
Так что вот такое простое доказательство.
Ну, собственно, основные идеи мы, в общем-то, заранее высказали. Это да.
Ну да. Ну, то есть, что такое расстояние? Рассмотрим все пути из s в t, рассмотрим их веса и выберем минимум этого множества.
Вот. То есть плюс бесконечность, это означает, что множество пустое.
Минус бесконечность, это означает, что для любого числа w найдется путь, вес которого меньше.
Вот. Ну, то есть, просто логично, то есть, если мы рассмотрим произвольное под множество действительных чисел, то как бы минимум бывает у них плюс бесконечность, минус бесконечность или что-то конкретное.
Вот. Оказывается, что здесь бывает минус бесконечность, но тогда и только тогда, когда мы наткнулись на цикл отрицательного веса.
Вот. Понимаете, да?
Чего еще раз?
Необходимость.
Необходимость. Ну, смотрите еще раз. Пусть у нас расстояние от s до t минус бесконечность.
Рассмотрим, пусть, рассмотрим все простые пути из s в t. Что такое простой путь?
Простой путь, напоминаю, это путь, который не проходит по два раза, не по одной вершине.
Таких простых путей у нас конечное количество, правда?
Вот. Следовательно, минимум у них вполне можно взять, пусть это w.
Раз расстояние минус бесконечность, значит существует путь от s до t, который меньше w, да?
Рассмотрим этот путь. Он заведомо зацикливается, правда?
И дальше будем говорить, будем идти, идти, идти. Если мы нашли цикл, то либо мы нашли цикл отрицательного веса, и тогда все доказано,
потому что вот мы до него дошли, и мы из него до t дошли, да?
Ну и может, ну может оказаться, что этот цикл не отрицательного веса.
Ну бывает, ну мало ли. Всякое бывает.
Нет, ну как бы это, нет, тогда, ну да, аккуратное доказательство дальше звучит так.
Мы выкидываем этот цикл и начинаем, идем по этому пути заново, да?
Ну количество ребер на пути уменьшается, поэтому как бы рано или поздно мы тогда либо обнаружим, что циклов нет вообще,
и тогда получится просто простой путь от s до t с весом меньше, чем w противоречия, да?
Либо мы все-таки наткнемся на цикл отрицательного веса.
Можно просто сразу сказать, что раз у нас вес меньше w, значит это не простой путь.
Да.
И при этом раз он меньше w, значит у него есть цикл обязательно отрицательного.
Почему обязательно отрицательного?
Ну, на нем обязательно есть цикл.
Безусловно.
Если на нем есть цикл положительного веса, то он…
То как бы мы его выкидываем, да.
Ну ладно, наверное это нельзя вот так просто заменить.
Можно.
Ну да, нет, в такой формулировке надо просто добавить фразу,
из всех таких путей выберем путь с минимальным числом ребер.
Вот, на нем есть цикл, не отрицательного веса он быть не может,
потому что мы как бы его выкидываем и находим путь с меньшим числом ребер тем же свойством.
Значит он отрицательного веса, все.
Да, вот можно так рассуждать.
Это, ну тут уже это, на вкус и цвет фломастеры разные.
О, кстати, какие они интересные, да.
На вкус соленый.
А, вы пробовали, да?
Нет, ну соленый, не да.
Так вот.
Ой, соленый, копченый, да.
О, хорошее блюдо.
Фломастер копченый со спиртом, да.
Так вот.
Итак, ну хорошо, значит маленькое утверждение доказано.
Маленькое утверждение доказано.
Но при этом.
Так, но теперь все равно, как искать коричайший путь не очень понятно.
Значит, идея, ну, идея тупая такая, да.
Мы помним, да, мы не знаем никаких дэекстров.
Мы ничего не знаем о графах.
Но мы знаем динамическое программирование.
Ой.
Вот действительно, представьте себе, что такая ситуация.
Вы только что научились программировать и изучили динамическое программирование.
До того ЛЦС включительно.
Ну, такая типичная ситуация, да.
И только после этого узнали, что существуют графы.
Да, вот внезапно так вот как-то произошло.
Нет, это в целом вполне нормальная ситуация.
Ну да.
Ну, с одной стороны, да, взрослые меня подозрили, что все-таки нет.
Ну, просто нет.
Знаете, у меня была когда-то, знаете, вот пока я стираю, могу байку рассказать на эту тему.
То есть иногда была в какой-то момент идея.
Вот когда мы, особенно, видеокурсы на стейпах записывали.
То есть могла быть такая идея, что можно учить, как обычно учат во всех школах, да.
Обычно там вы приезжаете, и вам у вас учат там некоторым разным темам.
Чуть-чуть графов, чуть-чуть динамики, там чуть-чуть течешки какой-нибудь и так далее.
И там гиомочки чуть-чуть.
Ну, как бы все примерно вот так вот.
То есть такое вот чуть-чуть.
И когда вы приедете в следующий раз, вот тоже будет всего по чуть-чуть.
Ну, она как бы более продвинута на все.
Вот. И была идея.
А ведь можно же на самом деле немножко по-другому.
Можно создать курс, в котором изучать только динамическое программирование.
Так, с нуля.
То есть, знаете, там первая лекция, то есть обычная ДП, намерная ДП, двумерная ДП.
Потом, соответственно, значит, НВП, НУП.
Потом тот ЛУЦС.
Значит, потом там ДП по профилю, соответственно.
И так далее.
Где?
Ну, если НВП за налогами...
Нет, НВП за налогами для этого нужно только бинпоиск изучить.
Очень много ДП, в которых используешь доложку.
Нет, смотрите.
Да, ну а...
Допустимизации ДП, ДП на деревьях, ДП на графах, да, так все изучено.
Ну, тут все постепенно.
Нет, погодите, погодите.
Проблема. ДП на графах, бездание графов, это что?
Нет, все необязательно.
Нет, смотрите, ну там технологии работают так.
Нет, смотрите, там у меня получалось немножко по-другому.
Нет, это все...
То есть, ДП с использованием ДО, естественно, надо использовать, когда вы будете потом изучать ДО.
Но просто, как бы, у вас на этот момент ДП уже будет изучено, поэтому, значит, ДО будете применять.
Не, просто изучаем только ДП, но в ДП пришлось внутри ДП еще изучить ДО, графы там...
Нет, на самом деле, по такому курсу получалось что-то комбинаторико.
Особенно если вы учите, что курс на степи, он должен быть коротенький, то нормально.
То есть вам придется там изучить, что такое сезон по кашечке там всякие вот эти...
Ну вот, а потом уже там начинается, можно там отдельно структуры данных изучить.
А, ну где-то надо изучить, что такое бинпоис, конечно, ну вот.
И да, тоже для ДП.
Ну, это такая база относительная, да.
Вот там где-то отдельно ДП, потом отдельно курс по структурам данных, отдельно курс на строки, там где-то они...
Миксуются, там под...
А, потом геома.
В геоме тоже сразу с нуля до театрамы Воронова сразу просто без лишних проблем, да.
Чего?
Мы же еще не изучали.
Чего не изучали?
Бинпоис.
Не, ну в бинпоис мы все-таки поверили.
Да, в бинпоис мы все-таки поверили, что мы его знаем, поэтому тут все-таки, да.
Так вот, ладно, пока я четверт.
Все.
Итак, задача.
Давайте предположим, что у нас есть граф.
То есть, как всегда, g равно w, e и, допустим, какие-то веса еще.
И, допустим, нам известно пока для простоты, что нет циклов отрицательного веса.
Это эквивалентно тому, что пути...
Что кратчайшие пути не бывают минус бесконечностями, а еще логично, конечно, что кратчайшие пути достаточно искать среди...
Ну, можно сказать, среди простых путей, да.
А еще можно заметить, что кратчайший путь всегда достижим за не более чем n минус 1 ребро, правда?
Логично?
Поэтому получается вполне себе такое естественное решение.
А именно, пишем динамику.
dp, то есть массив такой...
То есть, типа dp, v, l.
То есть, v это вершина, l у нас от 0 до n минус 1.
Ну, в смысле, там n точно равно модуль v, естественно.
Вот.
Это...
Минимальная...
Длина...
Пути...
Просто пути, заметьте, не обязательно простого.
От s до v...
Состоящее...
Ровно...
Ровно из...
l ребер.
То есть, мы рассматриваем пути из l ребер.
Ровно.
Вот такую dp-шку я хочу посчитать.
Да.
Вправивается, как я это сделаю.
Ну, здесь все достаточно просто.
Ну, потому что понятно, что dp от v0 равно...
Знаете, это база, да?
То есть, равно 0, если s равно v.
И плюс бесконечности иначе.
Вот.
Но в противном случае, dp от v, l...
Равно, естественно, минимум по всем, значит...
Именно.
Естественно, минимум по всем, значит...
Имеющимся входящим v ребрам.
dp от u, l-1, плюс w.
Вот.
Так, опять с сидифончиком.
Нет.
Слушай, что-то соблазн какой-то большой.
Давай.
Не отвлекай.
Вот.
Получается вот такой прикол.
Вот.
Пока простая тема.
Все просто, да?
А если правильно это еще реализовать с помощью динамики вперед,
то, как бы, действительно, код у вас...
Все это у вас будет работать за o от v.
Ну, правда ладно.
Это вы только dp-шку насчитали.
А как расстояние от s до t найти?
В чем проблема динамики назад?
Ну, в том, что входящие ребра придется перебирать.
Ну, строим обратный граф.
Да.
Минус заключает в том, что строить обратный граф хочется очень не...
Ну, да, это я и говорю, поэтому динамика вперед, я и говорю.
Да.
Ну, естественно, да.
Ну, понятно, что это...
Ну, кстати, пр-шка это отдельно...
Нет, во-первых, давайте начнем с того, что как бы...
Как найти расстояние от s до t вообще?
Ну, dp, t, n.
Да.
А если подумать?
У нас есть отрицательные ребра или нет?
Конечно, есть.
У нас только циклов отрицательного веса пока нету.
Это по всем длинам, видимо, минимум.
Да, тут, внимание, тут, на самом деле, есть две разные концепции.
На самом деле, я вот люблю эту, она такая более железобетонная.
Вот.
Потому что есть концепция, потому что я говорю, dp от vl, когда ровный из l-rubber.
Да, можно считать, когда она не более, чем из l-rubber.
Да, тогда там...
В данном случае...
Да, так, конечно, так сильно проще восстанавливается.
Нет, так...
Ну, в предыдущем варианте тоже ответ восстанавливается.
Вот.
Ну, не совсем.
Там за большее страдание предоказательств.
Знаете, у меня там любимая...
На самом деле, в одно время у меня самый сложный вопрос был.
Докажите, что там ответ восстанавливается правильно.
И там люди там четыре часа сидели и не могли доказать.
В том числе и будущие медалисты acpc, насколько я помню.
То есть, если меньше или ровно проблемы с дыхательством?
Ну да.
Особенно, если вы это еще...
Особенно, если вы все это еще и в одном массиве делаете.
Ну, как мы будем делать далее в целом?
Ну вот, поэтому я...
То есть, вот как бы два пути.
Либо все-таки сказать, что нет.
Одним массивом можно, там все адекватно доказывается.
Потому что в каждый момент времени там...
Там у вас на порешках строится какой-то корректный дерево.
Там кратчайших на текущий момент путей.
И все в порядке.
Ну или там каких-то просто путей.
Что там цикла...
Что это дерево никогда не зацикливается, поэтому все в порядке.
Хотя нет, это в районе.
Так.
Ну в общем, там...
В общем, геморрой тут еще.
То есть там, по-моему, кому-то удавалось.
Может даже там вот так пример как-то валится.
Хотя вроде нет.
Но не важно.
Но в данном случае железо-бетона.
Диста, ТС, Т. Это что такое?
Это минимум.
Минимум по всем вершинам.
Точнее, минимум по всем элькам.
От 0 до N-1.
Да.
D, P, A, T, L.
Все.
Вот такая красота.
Ну там правда начинается...
Ну просто откуда все проблемы начинаются?
Все проблемы начинаются с того, что вы хотите восстанавливать путь,
но при этом не жрать О от В квадрат памяти.
Ну хотелось бы.
Да.
Потому что заметим, что диста-то вы найдете заворозовые.
Потому что каждый слой как бы требует только предыдущего.
Да?
Но как восстанавливать теперь этот ответ?
Ну тут как всегда, да.
При большом желании можно конечно забабахать технологию Хиршберга в общем-то.
Как?
Ну просто ищите путь от S, ищите путь до T.
Там вот это все, да?
Сейчас.
А что?
Не, не, все нормально.
Показалось, что там есть некая проблема.
Почему мы с Телепом ждем?
А потому что мы можем...
Ну по раме.
Ну по раме, ну вот...
Ну по количеству ребер в смысле.
Так, давайте разделять понятия длина пути и количества ребер.
На пути это разная вещь.
Нет, то это просто разговорный вопрос принципиальный.
Да, по количеству ребер, да, разделять их вполне можно.
Просто не то, чтобы очень есть предельцы.
Что?
Просто не очень есть предельцы, поэтому...
Почему? Нет, смотри.
Ну просто фишка в том, что мы можем развернуть граф и по обратным ребрам тоже запускать.
Так.
Во-первых, по счетам динамику один раз мы вообще можем понять, а, значит, какой вообще ответ на задачу, и б, какое там л, правда?
А теперь, значит, как эти л найти?
Делим это л пополам.
Вот.
И находим, значит, ДПшки на л пополам от Ски.
И находим такие же ДПшки, но уже по обратным ребрам от Тешки.
А, да, а на этой заключается, потому что мы вершины на две половины недели.
Ну да, нет, это технология там...
Нет, ну такая эта технология нам даст восстановление ответа за там время там...
Что-то типа ВЕЛОГВ?
Что-то типа ВЕЛОГВ?
Что-то типа ВЕЛОГВ?
Что-то типа ВЕЛОГВ?
Что-то типа ВЕЛОГВ?
Смотри, допустим, ты вот с помощью этой технологии за ВЕ выяснил, что у тебя есть кратчайший путь, он состоит из л-рёбер,
и где-то посередине у него на л пополам находится какая-то вершина В.
Спрашивается, а дальше что?
Вот ты запускаешься рекурсивно, и тут ты работаешь, получается, за сколько?
Рекурсивно чего, от всего графа?
Ну, получается, да.
А, ну, слушай, он влез, он влез.
Ну сейчас, ну понятно, что там...
Ну вот, хотя...
В худшем случае, понятно дело, что мы весь граф покрываем всеми удалительными слоёв, но...
Меня больше напрягает сам переход, я не очень понимаю, как перейти от л пополам к L.
Ну, в смысле?
Как ты меня не понял?
Ну, тут переход-то понятно, что мы...
Л мы нашли, значит находим просто там...
Ну, может, для двух вершин мы это всё считаем, только для С, да?
Конечно. И находим вершину В такую, что вот этот кратчайший плюс этот кратчайший равен то, что нам надо.
Если мы кратчайшие, то мы стоим, там вершины всё-таки пополам поделятся,
и все, которые у вас будут не плюс без конечности, можно их добавить в левый рекурсивный,
который...
Но там проблема в том, что...
Нет, погодите, погодите.
Нет, что значит достижимый?
Проблема разникает в том, что он очень будет понятно, как бы, вот...
Но память мы используем только...
Но память хочется использовать вот от В плюс Е, да.
В плюс. Ну, мы...
Ну да, мы наверное используем В плюс Е.
Вот единица слоёв мы имеем право хранить.
Окей.
Хотя тут уже даже интересно, можно ли тут херьку упихнуть.
Ну я думал, что у нас херька за...
Вот в данном случае будем работать за В елой.
Да.
Луговая, да.
Ну или луговая.
Ну это луговая, да.
Но пока получается луговая.
Да, можно ли выкрутиться?
Потому что можно попытаться, наверное, для каждой...
Можно ещё попытаться, наверное, для каждой вершины ещё понять там что-нибудь в духе.
Там, действительно, она должна быть там, скажем...
Она как бы лежит вот на этой части пути или на этом.
Если удастся так разделить, то, как бы, в этом нормальный ВЕ вас поприветствует.
Кажется, в полном графе они не имеются.
Понимаешь? Чего?
Ну короче, не понятно, какие же люди делают без потенции по 8 точке.
Нет, слушайте, а я, конечно, понял.
Смотрите, то есть нам нужно за L пополам ребер
и АТС ДВ.
И за L пополам ребер за человек ЛДТ.
И это как чайший путь такой, да.
И мы ещё и L взяли, как чайший.
Так вот, заметим, что мы ещё можем...
То есть мы ещё можем сделать вообще такой следующий чит.
А.
Храни парку, как чайший путь ЛДТ.
А, нет, пару не можем.
Потому что одновременно надо либо S ходить.
Мы как бы в две стороны, хотя, наверное...
Ну, на самом деле, мы могли бы расправить обратно путь по прямым реберам обратно.
Чтобы сейчас...
Угу.
Ну ладно, в общем...
В чем он вообще может лопать?
В смысле...
Какая?
Распилить вершины так, что какие вершины лежат тут, какие тут?
Ну...
Мы же не можем просто построить граф, как чайший путь, и...
Ну, если...
Ну, если у нас как раз-то, да, в том-то и смысл, что да.
Ну, в смысле граф в тупую.
Нет, в тупую построить.
Но у нас ДП-шка сейчас такого не позволяет.
Нет, как бы, да, можно как бы единую ДП-шку взять за там...
За ОТВ памяти и пытаться там это дерево поддерживать,
но тогда просто мы же пытаемся как раз избегать того, чтобы там доказывать,
что это реально дерево, оно будет корректно работать.
То есть там надо доказывать, что...
Да, там...
Там главное непонятно, что доказывать, потому что даже когда вы там...
У вас там пути могут подменяться, и там в каждый момент времени,
у вас там...
Нельзя просто хранить вершины, у которых расстояние от ОТВ меньше,
чем расстояние ОТВ, и тогда они должны как-то хорошо поделить.
Сейчас, а что такое расстояние? По количеству ребр, потому что непонятно.
Не по количеству ребр, по ДП-шке.
Так в смысле, у нас же, у нас же там бывают отрицательные ребра,
поэтому там как бы абсолютная величина расстояния вам не скажет ничего
о том, сколько там ребр.
Если бы...
Их не было, то почему?
Ну вот так что.
Так, ладно, не будем в это копать.
Да, ладно, с Хиршпырком, к сожалению, мы нагрелись, жалко.
Так что можно теперь будет отдельная песня на тему того,
как-то упитывать в ОТВ памяти.
Ну, с восстановлением ответа.
Но хотя, но для нас, ладно, начнем пока с более простой задачи.
Это пока, но по камере мы ДП-шку, уверенно, если нет циклов
отрицательного веса, упихались.
Упихались?
Упихались.
А теперь что делать, если цикл отрицательного веса есть?
Извините, а мы учились это восстанавливать?
Нет.
А это вообще...
Точнее так, восстанавливать, нет, вообще восстанавливать,
если вы ДП-шку храните целиком?
Да, конечно, очевидно.
А вот за память, вот хороший вопрос.
Ну я...
Вы знаете решение?
В слету нет.
Нет, я подозрение, что если 10 минут подумать,
что-то придумается.
А не из-за того, что какое восстановление не будет работать,
просто врать и...
Ну, вот это...
В Фордибелле мы немножко другой вариант поддерживаем все-таки.
Нет, смотри, я...
Нет, если мы будем писать классическую версию,
типа Dp от 0 до n-1 равно там плюс бесконечность,
и там Dp от s равно нулю, да?
Да.
А дальше там...
Нет, у нас есть просто тупой вариант восстановления,
опять зарядим, просто убрать и хранить тупого предка.
Да, ну...
Да, но это предположение, что мы и все Dp-шки храним,
и всех предков храним.
Для каждой линейки.
Нет, вот Dp-шки мы постоянно пересчитываем, правда?
Ну и что?
Мы можем также просто предков постоянно пересчитывать.
Ну потому что для пяти ребер там будет один предок,
для восьми будет другой.
Какой?
Предки будут теми же самыми, что и для...
Что и для...
Нормально.
У нас может ухудшаться ответ, если мы взяли больше ребер.
Из-за того, что мы ровно или ровно требуем,
у нас ответ может стать хуже.
У нас может просто, допустим,
в зависимости от чётности пути быть или не быть.
У нас идёт...
Нет, ну сейчас, давайте так.
Так, ну давайте так.
Просто восстановление ответа говорит нам, что у нас есть, допустим,
ПР от ВН.
Наши Dp-шки неудобные,
у нас удобные Dp-шки.
Зачем их использовать так?
Ну в удобные...
Там просто ещё более худшие проблемы будут, я боюсь.
Ещё, ну вот.
Так вот, значит, ПР от ВН.
Так вот, можно, в принципе, вот...
Не написать.
Ну вот, то есть, не знаю.
Кажется, если я правильно понял Филиппа,
ну, который не я,
да, можно уточнить.
Но предлагает следующее.
Значит, предлагается, что...
Значит, давайте пытаться...
Ну, вместо Dp от ВЛ храним в Dp-шке текущий слой динамики.
В ПР-шке, ну, тоже можно хранить текущий слой динамики, допустим, да.
Ну вот, а вместо этого можно хранить,
ну, вот, один из вариантов, ПР-опт, например.
ПР-опт от В.
То есть...
А, ну и параллельно просто хранить D-опт от В.
То есть, D-опт от В – это минимальная дэшка
среди всех дэшек для этой вершины,
которую мы к текущему моменту насчитали, да.
И давайте хранить к ней ПР-шку.
Просто конкретно ею...
То есть, дэшку мы легко поддерживать
и как бы конкретную ПР-шку тоже вот можно к ней насчитывать.
Кажется, мы получили форда Балмана в домашнем пустое.
В этом, видимо, была идея.
Так...
Теперь...
Да, теперь возникает такой естественный вопрос.
Почему-то хотя бы при условии отсутствия циклов
этого веса работает.
Что такое ПР-эль?
Ну, вообще...
Смотрите, вот D-опт от В.
Это вот такой минимум, да.
Так вот, ПР-эль от В.
Это арк минимум абсолютно того же самого.
Ну вот, там прям идентично, идентично, идентично.
Идентично.
То есть, как бы в идеале,
если бы у нас мы хранили квадратную динамику честно,
то мы могли бы хранить квадратную ПР-эльшку
и естественным образом восстанавливать ответ, правда?
Вот.
А теперь у нас есть какая-то такая идея.
Давайте, если мы уж не можем хранить эту динамику,
но можем хранить там два соседних слоя,
текущие и следующие, да,
то давайте тогда хранить еще D-опт и ПР-опт.
Что такое D-опт и ПР-опт?
D-опт это...
Вот мы прошли, например, сколько L-слоев,
и значит D-опт это какую минимальную длину пути
за эти L-слоев мы нашли?
Вот.
А ПР-опт это рассмотрим вот то L,
при котором это было оптимально,
и ту ПР-эшку мы и запишем.
Вот возникает естественный вопрос.
А почему, собственно, у нас не восстановится ответ?
Если мы по этим ПР-эшкам,
потом из тэшки будем скакать.
Не восстановится.
Ну или наоборот, почему восстановится?
То есть как бы это вот такой есть алгоритм,
и потом его надо доказать или опровергнуть.
Кажется, что восстановится.
Да.
Да, действительно, кажется, что восстановится.
Просто мы делаем перескоки, видимо, с непонятных...
Ну вот, нет, там просто основные подлянки возникали в том,
что у нас раньше вот эти ПР-эшки там у всяких D-экстрах
и BFS-х базировались на том,
что как бы с каждым таким перескоком у нас D-эшка уменьшается,
поэтому за циклов нет.
А тут еще как бы бывают подлянки,
что как бы вы перескочили в D-шку, а там она увеличилась.
И поэтому бывает, может теоретически так случиться,
то есть там, если неудачно вводите варианты,
там получалось, что...
А не получилось ли там какое-нибудь цикло веса 0,
на этих ПР-эшках, по которому мы скачем?
Заметим, что, во-первых, мы можем порезть,
в каких фрешенах рецензий на вес.
До каких фрешен, точнее, есть циклы.
Ну вот, давайте так, вспомним,
что у нас пока циклов отрицательного веса нет.
А, все, отлично.
Да, пока, да.
Пока, вот, да.
На самом деле, можно это обосновать примерно так же, наверное,
как и for the wealth все-таки.
Ну, да, совершенно верно.
Не, ну как, ну не совсем так, конечно, но...
Нет, ну да, в итоге, конечно,
D-opt в самом конце совпадет, конечно,
с реальными расстояниями от СДВ, да.
Это правда.
Ну, да, то есть, логично, и это как бы,
то есть, смотрите, это как бы логично,
что мы берем вершину T,
у нее написана какая-то D-шка и какая-то P-эшка,
которая возникла, да?
Спрашивать, хорошо, мы перейдем в эту V-шку.
И логично, что из V, на самом деле,
до вершины S тоже логично идти по кратчайшему пути.
Сейчас еще раз, что у вас может вообще глобально прийти не так?
То есть, непонятно, что путь, который мы вот взяли,
если мы будем как-то по P-эшкам прыгать,
то мы какой-нибудь путь найдем.
А вот не факт.
Тут как минимум основной вопрос возникает.
То есть, скажем так, я готов, может быть,
ну вот, хотя тут надо думать.
Тут, первое, ну, первое, ну, потому что там нужно доказывать так,
во-первых, почему мы вообще до вершины S дойдем?
Ну, что у нас в динамике,
по которому поражку пересчитывали, L будет уменьшаться.
Да.
Ну, мы и так пересчитывали, что парок ведет в какую-то, но не в нашу.
Так.
То есть, хорошо.
То есть, ты хочешь сказать, что когда мы вот так скачем,
то есть, ты очень, значит, ты, если я тебя правильно понял,
то ты хочешь сказать, что, значит, смотрите, давайте вот,
так, для формальности давайте введем D, Opt, Pro Opt и L Opt еще.
Так, ну понятно, что L Opt, да?
Ну да, пусть будет.
Так.
Но L Opt это типа, вот это вот D, Opt, при каком L оно возникло.
То есть, про это, из какой вершины мы пришли, а L это в каком слое.
Ну да.
Ну, это, ну, мы так, но шо, мы иногда налипято по математике
с таким приходим, чо, там доказать серии его программы,
доказательства, запустим DFS.
Там запустим DFS, есть основное дерево, все остальные ребра обратные,
там бла-бла-бла-бла-бла-бла-бла-бла, все.
То есть, ешь вот такие вот?
если граф не ориентированный. Да, ну там разные. Я думаю, слушайте, есть вообще, как бы это, есть
вообще же вот это, лемма холла, или теория махолла. Доказательства. Поставим СТ, запустим поток. Макс
поток равен минразрезу. Рассмотрим минимальный разрез. Докажем, что вместо этого разреза, вот.
Да, так это, ой, это я вам спалил начало третьего семестра, да. А, или там терема. Рассмотрим там
двудольный дирекулярный граф. Докажем, что в нем есть совершенное пресочетание. Доказательства.
Построим, запустим, построим исток, исток, запустим поток. Поток равен разрезу. Поехали.
Да, а про сочетание ищется. Чем? Куном. Правильно, потоком. Да, построим сеть,
запустим Деница. Докажем, что он еще и быстрее вашего куна работает. Это называется алгоритм
Хопкофта Карпа. Сейчас быстрее, в смысле асимпатически. Да, Е как НИЗВ. Е как НИЗВ, да. Все знают, что куна
работает, а вопрос Е. Ну, как это называется, да. Поговорим об этом на экзамене.
Выделим, но кто сказал, что прешки с ним как-то связаны. Так.
Ну, по большому счету, ладно, угадал, примерно это и хотелось сделать. Или что то же самое, я просто хотел
показать, что на, действительно, когда мы будем скакать, L будет строго уменьшаться. Вот я утверждаю,
что действительно, если мы хотим D-opt, P-opt и L-opt, то L-opt будет строго уменьшаться. Этого нам достаточно
для того, чтобы показать, что, да, зациклов не будет. Ну, потому что, да. Потому что логика такая,
вот пусть у нас там L-opt от T, допустим, равно какому-то L. Это значит, что где-то, когда мы пересчитывали
какой-то L минус, возможно, первый слой. То есть, где-то, видимо, откуда этот путь взялся? Значит,
на L минус первом слое была какая-то вершина V, которая у нас равна вот P-opt от T. Ну, P-opt,
так сказать, от T-L. Мы ее в этот момент пересчитывали, и D-opt от T оказалась вот как D-opt от T-L в этот
момент. И хуже она потом не стала. Следовательно, вот это вот происходило, видимо, в слое L. Получается
хранится, хранилось слое L минус 1. Правда, следует ли из-за этого, что L-opt от V равно L-1? Ну,
само по себе пока еще нет. Потому что, да, в этот момент у нее был какой-то путь такой, что вот этот
путь плюс это ребро, это минимальный путь до T, это да. То есть, само по себе, а может быть,
L потом поменялся? Ну, когда-нибудь потом, после L минус первого шара. Может, L-opt равен,
то есть L-opt, он как бы не меньше, видимо, чем L-1? У V? Если больше, то мы обновили или мы обновили ее?
Нет, смотрите, подождите. Нет, мы у нас, вот смотрите, P-opt это та самая вершина, по которой мы
обновили T на L там слое, и это оказался чемпионский вариант. Это означает, что L-opt от T все-таки равно L-1,
мы бы записали, или L наоборот. То есть, если мы записали L, это значит, что обновляли ее с L-1 слоя.
Но возникает вопрос, верно ли, что у вершины V там L-opt хотя бы нас устроит меньше либо равен,
чем L-1? В будущем нашли еще более короткий путь до вершины V, и значит,
приоритетические даты мы могли, конечно, найти еще более короткий путь. Ну все вот эти поражки мы
сейчас, мы сейчас в это верим, да, и что? Почему?
Да, но длиниться не могут, потому что по этому ребру веса 0 релаксации никогда не
произойдет. Да, но конкретная поражка-то от этого все равно не поменяет. А что это даст?
Да, с этим максимумом то, что как бы DP в каждом столб V столб C, возможно, со
временем не увеличивается. Потому что, типа, хотите зайти на 179 ребер, подойдите за 57 и,
собственно, накрутите 122, разве что.
Нет, просто чит в том, что, как бы, да, это хороший чит, правильно говоря,
просто чит в том, что есть вторая формулировка, где тут меньше либо равно нарисовано, да, и мы,
допустим, мы на ней пытаемся эти все оптимальные, вот эти все штуки забабахать. И тогда оказывается,
что она легко просто, то есть, на самом деле, не жесткая формулировка, это на самом деле та же
самая жесткая, только в предположении, что у нас в украшении вершины есть эта нулевая петля.
Ну да, то есть, разница в том, что у нас, как бы, мы вот эту DP от ВЭЛ до каждом шаге
инцелизируем не плюс бесконечность, а тем, что было раньше, то есть, из предыдущего слоя копируем.
Так что, в принципе, да, можно даже и так накрутить. Хотя, ну, давайте так это, на всякий
случай, добьем. Ну, тут мы поняли, что, да, больше тут быть не может, потому что, иначе,
меньше путь будет. Поэтому, да, тут получается что-то типа меньше либо равно l-1, то есть,
может оказаться, что там, ну, хотя нет, сомнительно. Нет, знаете, скорее всего,
тут будет равно l-1, потому что, если тут меньше l-1, то и тут было бы меньше, чем l,
потому что мы бы этого просто достигли за меньшее число гребря. Ну, и по большому счету, да. Ну,
это уже технические детали. В общем, как бы, основную суть мы уже победили, так что все решение
существует. Так что, гори все пропадом и пойдем спать, как всегда. Вот. Вот. Нет. Ну, это так
получается автоматически. Нет, смотрите, у нас просто дело вот в чем. Если у вас была,
если у вас какая-то dp-шка была найдена за 57 ребер, а потом вы обнаружили ту же пытается,
ту же самую за 79, ну, вы просто не пререлаксируете, потому что релаксация будет на строго меньше.
Получается, что количество ребер вы как бы релаксируете автоматически. То есть, l-opt реально,
обратите внимание, можно не считать, достаточно считать только d-шки и p-r-шки. Нет, правда,
есть маленькая оговорка. Этот алгоритм требует, чтобы вы все-таки хранили два слоя и разделяли
понятие один слой и другой слой. Хотя, с другой стороны, добавление нулевых ребер намекает,
что можно на самом деле в одном слое все сделать, по факту будет то же самое. А нет, нет, нет, нет,
нет, не так, не так, не так, не так, не совсем. Ну, просто в одном слое у вас там просто одна вершина
будет влиять на другие прям быстрее, чем если вы как бы от одного слоя аккуратно переходите в
другой. То есть, да, вы, конечно, да, поэтому, то есть, помните, здесь мы как бы, то есть, мы сумели
выкрутиться за там от v-е времени и от v-плюс e-памяти, то есть, от v-дополнительной памяти. Ну, вот, но,
но, но, но, но, но, но. Но только с оговорками, что мы тут как бы на каждом шаге все-таки два
слоя хранили. А что, какой топ-сорт? А каком топ-сорт? Циклы-то есть? Нет циклов отрицательного веса,
но вообще циклы есть. Ну, короче, топ-сорт на цикле. Да, то никто включает и не знает,
что это такое, да. А тем более, что мы и сами-то не знаем, что такое топ-сорт, что интересно, да.
Ну, по большому счету, да. Нет, погоди,
я пока не очень понял, как... Нет, предположим, что мы все это в одной dp-шке делаем, вот это вот.
То есть, допустим, если мы вот действительно делаем это вот по схеме, вот for it равно от 0 до 1,
там for там u, v, w, пробираемся по всем ребрам, и вот это вот dp от v, там min равно dp от u плюс w.
Ну, там релакс какой-то. Вот в идеале как бы хочется, да, вот я бы не сказал,
чтобы вот такую, прям вот такую схему мы доказали.
Корректная dp-шка, корректная, да. Ну, там просто проблема в том,
как непонятно в какой момент она появится. Ну, как только такая dp-шка появится,
наверное, она не изменится никогда, это да. Ну, наверное, да. Ну, тогда это вообще будет уже
общее доказательство в духе, что... А давайте в каждый момент времени следить, как только... То есть,
очевидно, следующее, что да, по такой схеме кратчайшее расстояние мы, естественно, найдем.
Просто потому что после l-то итерации здесь будет храниться что-то непревосходящее там вот этого
dp-о... d-opto в старой итерации. Нет, то просто железобетонно. Просто, кстати, простое утверждение
по индукции. После l-о итерации, значит, dp от v будет меньше либо равно d-opto от v,
которое было бы тут после l-о итерации. Да, просто доказательство простой по индукции,
потому что, как бы, ну, бажарирует там, релаксация та же, понятно. Теперь как доказать,
что будут хорошие p-r-шки? Ну, заметь, мы будем говорить так, что что такое p-r-шка нас вообще
не интересует, но нас интересует следующее, что как только dp от v стало кратчайшим расстоянием,
оно больше не поменяется никогда. Верите в такое утверждение? Никогда. Ну, тогда возникает такое.
Тогда идея такая. А давайте вот будем называть вершину хорошей, если у нее dp-шка стала оптимальной.
Ну, то есть вершины изначально все плохие, кроме s-ки, а потом они, значит, постепенно... как
каждое становится там похоже на предыдущую. То есть постепенно становится хорошей. Ну,
тогда я утверждаю следующее, что в каждый момент времени, ну, то есть, допустим,
s-ка, рассмотрим, пусть у нас какая-то вершина стала хорошей. Неожиданно. За счет чего она могла
стать хорошей? Ну, я утверждаю, что только за счет того, что мы пререлаксировали ее правильным
ребром из вершины s. Почему? Ну вот, да, просто потому что, если это произошло через другое,
через какую-нибудь вершину постороннюю v-штрих, то тогда эта вершина v-штрих вынуждена уже быть
хорошей, правда? Потому что, если она еще нехорошая, а этот путь, типа, кратчайший,
да, в этом, мы, типа, заменим этот путь на хороший, и получается, до вершины v-штрих
мы некорректный путь нашли, правда? То есть, поэтому, то есть, получается, что в общем случае, получается,
что у нас в каждый момент времени есть вот такое дерево корректных путей, вот этих на p-r-шках,
значит, на хороших вершинах, и каждая новая вершина, хорошая вершина, она, получается,
за счет релаксации из какой-то уже на тот момент ранее ставшей хорошей вершины.
Да, общими усилиями вроде выкрутились, да? Даже вроде не сильно сложным способом,
да, хотя по Денису не скажешь, да. Ты живой? Да. Окей. Да, ну да, потому что это ты все
тоже, естественно, там совсем рассказываешь, да? Вот. Ой, ну классно, да. Нет, просто, если после
l-1 шага ДП там обновилась пряжка, значит, обновился D-opt. Это значит, что мы нашли еще более короткий путь
до v, но тогда мы нашли тем самым и более короткий путь до t, чем вот то, что мы тут релаксировали. А
это противоречие. Потому что мы утверждали, что тут путь, который мы тут смотрели до t, он был кратчайший.
То есть как бы тщит, видите, заключается в том, что циклов кислотного веса нет, значит, кратчайшие
пути все железобетонно существуют. Типа по индукции, да. Ну или не по индукции, там просто оказывалось,
что нет, мы доказали, у нас по большому счету мы доказали простую вещь, что пр, ну потому что
что такое пр? Это на каком слое эта штука стала оптимальной, да? Мы просто взяли пр и доказали,
что там пр от этой вершины меньше. То есть получается, мы на более ранней интерации сказали,
что у нее кратчайшее расстояние до нее кратчайшее. Потом повторили, повторили, и так дошли до s,
и мы не зациклились, потому что l уменьшаются. Да. А, ну, кстати, может, по-моему, кто-то так даже,
может быть, и выключился. Хотя вот концепция, да, назовем вершину хорошей, если до нее кратчайшее
расстояние dp-шкой достигнуто, она, по-моему, даже вот эту реализацию решает. Да, даже просто
как-то оказалось. Вот классненько, классненько. Но, так сколько у нас? Чего? Уже? Господи, вот я бы, да,
я боялся, что сейчас все будет быстро, придется все игры начинать. Теперь придется бояться,
что не успеем. Ну ладно. Чего? Обычно мы боимся второго. Да? Чего? Потому что мы не успеем. Ну,
посмотрим, ладно. Не, ну, так. Ой, ну ладно, сейчас посмотрим, что успеем. Потому что, значит,
смотрите, это пока был простой вариант Форда Бэлмана, значит, когда циклов отрицательного веса нет.
Теперь интеллектуальная ситуация. Да, когда циклы есть и надо идентифицировать минус бесконечности.
Так, давайте это я временно сотру. Нет, вы доказали следующее, но я даже продолжу. Я утверждаю,
что если ДП от В, то есть реально расстояние от С до Т не минус бесконечность, то вот эта
технология его все еще корректно находит и даже порешками там все восстанавливается. А вот тут,
а вот тут, кстати, во всех литературах подлянка. Там доказывают, что сделаем МТ шаг,
если хоть где-то что-то поменялось, значит, цикл отрицательного веса есть. Да, то есть где-то
есть. Поэтому, значит, придется сказать следующее. Вот, там на самом деле много подлянок, там,
я думаю, там всякие, там кто-то, те, кто там в задаче лабиринта натыкались на какие-то ватрицы
с хвостиком. Наверное, догадываются, что там подлянки есть и много. Но нам не нужно искать
все циклы отрицательного веса, но тем более, что их бесконечное количество. То есть нам на
самом деле нужно вот, значит, какая тут идея. Я предлагаю вот эту ДП, я вот люблю эту честную
ДП. Значит, я ее буду, раз цикл отрицательного веса есть, я ее буду насчитывать. Но, оказывается,
не до N. Ну, давайте. Ну, я бы сказал так. Ну, во-первых, можем запустить, прости господи,
ДФС. А зачем ДФС? BFS. И выкинуть все ребра, все вершины, до которых мы из С дойти не можем.
Поэтому, в принципе, без особого значительного ограничения обществе мы всегда можем сказать,
что у нас все вершины из С достижимы. А мы не можем умнее? Мы не можем посчитать последний слой,
посмотреть все вершины, в которых мы прорелаксировались, и из них параллельно
запустить BFS и посмотреть, дошли ли мы до конца. Если дошли, то есть цикл отрицательного веса
на пути. Ну, хватит ли этого? А почему нет? Ну, вот давайте разбираться. Ну, сейчас давайте все
постепенно. Ладно, ну давайте, хорошо. Хорошо, как там Денис заказывает? Давайте, значит,
идея просто вызекает такая. Ну, идея вызекает такая, что рассмотрим, давайте сделаем не N-1
атерацию, а N. Значит, мистическое утверждение. Вот в нашей терминологии воспользуемся Lopt от V
равно N. То есть, если вершина неожиданно, если у вершины Dopt неожиданно обновился на N-ной атерации,
то утверждается, что dist, то, во-первых, A dist от Sv равно, наверное, минус бесконечность. И B,
если U достижимо из V, ну, автоматически, то dist от U тоже равен минус бесконечность. Ну,
если мы, очевидно, если мы в A поверим, то B автоматически. Так, но верно ли A? Ну, действительно,
заметим, что, да, это верно. Почему? Потому что заметим, что после N-1 атерации, то есть,
после N-1 атерации, очевидно, Dopt от V это не превосходило длины минимального простого пути.
Да, если нашелся, да, то есть, если оказалось, что на N-ой атерации произошло обновление,
значит, он, значит, это заведомо путь из N-рёбер, да, может быть, ну да, N-рёбер. И тогда получается,
что там на нём цикл отрицательного веса есть, значит, минус бесконечность. Появляется
естественный лайфхак. Сделаем N-ную атерацию, возьмём минус бесконечности, вот, понимаете,
да? Да, и из этих вершин запустим BFS, просто пометить все вершины, которые достижимы из вот
таких вот V. И всех их пометим минус бесконечностью. Да, то есть, смотрите ещё раз, значит, вот мы
поверили в это утверждение, даже не поверили, а доказали, да. Тогда, значит, модификация алгоритма,
значит, считаем абсолютно ту же динамику, но на N-интерациях. Если неожиданно потом пробираемся
по всем вершинам трёх OPT равен N, и из них запускаем единый BFS. Ну, BFS, а, ну да, тут важная такая тема,
да, никто никогда не рассказывает, это BFS из нескольких стартовых вершин. Да, ну, я поверюсь,
что для вас, наверное, это является простой идеей, что в очередь запихнём не одну стартовую вершину,
а сразу несколько, и до всех 0 напишем, да. Вот, и из них запустим BFS, то есть получится, что мы
пробежимся ровно по всем вершинам, которые из этих вот вершин, вот этих вот достижены, да. До них
расстояние минус бесконечности это тоже очевидно. Остаётся только теперь внимание вопрос. Значит,
смотрите, значит, что мы, что мы получили, значит, утверждение, то есть, ну, как бы заметим, что, как бы,
да, до этих вершин точно минус бесконечности. Также очевидно, что если до вершины реальное
расстояние не минус бесконечности, то мы этим алгоритмом его тоже найдём. Остаётся только маленький
момент, что нам осталось? Да, внимание, вопрос, есть ли, да, минус бесконечности, совершенно верно,
которое мы не нашли? Почему? Заметим следующее, что, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да
могло ли такое быть? Так, ну, давайте разбираться. Значит, ну, тут, конечно, требуется, может быть, там, да, некоторая аккуратность, но давайте рассмотрим произвольную вершину Т, до которой у нас расстояние минус бесконечность, да? Как мы доказали в самом начале, мы так заблаговременно об этом позаботились, да? Значит, у нас существует, то есть,
можно дойти до какого-то цикла отрицательного веса, прогуляться по нему и потом прийти сюда, да? Более того, я тут еще простую картинку нарисовал, хотя, как бы, по-хорошему, мы тут можем, тут, на самом деле, тут любая крокозябра может вполне себе быть в роли этого цикла.
Но заметим следующее, что на самом деле, как бы, утверждение такое, да, что если это, давайте сделаем аккуратно, если, я вот сейчас, конечно, неформально произвучу, но если это можно сделать через просто цикл отрицательного веса, то это можно делать через простой цикл отрицательного веса.
Ну, то есть, я могу цикл отрицательного веса вот этот подменить на простой, ну, не всегда я могу подменить его на простой, потому что, ну, помните этот пример с балалайкой, да?
Вот, ну, могу и ребер на простой, да, ну, но на самом деле, просто идея такая, что, ну, на самом деле, утверждение такое, если, как бы, внутри цикла отрицательного веса, да, то есть, внутри, ну, среди вершин и ребер цикла отрицательного веса, я могу вычленить простой цикл отрицательного веса.
Ну, доказательство там то же самое, идем по этому циклу, найдем первый зацикл, да, если это цикл отрицательного веса, то он простой и все хорошо, если нет, выкидываем, получился цикл отрицательного веса с меньшим числом ребер.
Повторяем операцию, вот, все выкидываем, знаете, это, да, то есть, знаете, да, там вот, ну, в общем, понимаете припол, да, то есть, рано или поздно, как бы, вы наткнетесь на зацикл, который отрицательный, потому что, как бы, если у вас все циклы выкинутся, останется только одна вершина, ну, значит, тогда у вас и цикл был не отрицательного веса, очевидно.
Мы ищем простой цикл отрицательного веса.
Да, внутри просто цикл отрицательного веса.
Как мы еще раз, мы разбиваем на простые по…
Не, не, даже не разбиваем, мы тупо берем первую попавшуюся вершину на этом цикле, да, и идем по циклу, прям жадно, жадно, прям идем, идем, идем, идем до тех пор, пока не зациклились, то есть, когда мы в первой жизни встретили вершину, которую видели раньше.
Это простой цикл, да?
Да.
Теперь, если он отрицательный, то мы победили.
Ну да, легко понять.
Да, потому что, значит, вот внутри цикла мы его нашли, ура, как подпуть.
Если он не отрицательного веса, то давайте его вытянем.
Цикл отрицательного веса от этого останется циклом отрицательного веса, только в нем станет меньшее число ребер.
Повторяем операцию, то есть идем, теперь идем, идем, идем, тоже опять сначала, например.
Идем, идем, идем, идем, идем, опять натыкаемся.
Ну мы всегда будем натыкаться на зацикл, просто потому что это в принципе цикл.
Ну да, пожалуйста, можно, ну как угодно.
Можно, да, те же, можно главное вот эти юзиды снять, а вот эти юзиды оставить, да.
Ну там это уже технический вопрос.
В реальности это нам нужно только для математики, поэтому не понадобится.
Так вот.
Я не понимаю, еще раз, что происходит у нас?
Что мы делаем вообще в принципе?
Зачем мы удаляем циклы какие-то, я не понимаю.
То есть мы хотим найти цикл отрицательного веса у нас.
Мы сейчас доказать что-то пытаемся.
Мы доказать пытаемся или пытаемся вывести алгоритм?
Нет, мы доказать пытаемся пока.
Ой, да, хорошо, что напомнили, да, конечно там, да, поиск или вот циклы действительно где-то здесь рядом будет бродить, конечно.
Но это будет про ДФС, поэтому не заморачиваемся.
Доказать пытаемся следующее, что я могу в качестве цикла отрицательного веса здесь рассматривать простой цикл отрицательного веса.
То есть существует простой цикл отрицательного веса, через который можно из СПТ дойти.
Если реальное расстояние до Т равно минус бесконечности.
Да, все просто. На самом деле мы ничего умного пока не делали.
Мы просто жадно сказали, что если цикл вредный, то давайте сделаем из него не вредный.
Потому что мы удалили цикл не отрицательного веса, то есть суммарный вес только уменьшился.
То есть был отрицательный, стал еще более отрицательным или по крайней мере что-то не поменялось.
Так вот.
Так вот. Чему нас это приводит?
Так у нас находится какой-то простой цикл отрицательного веса.
Вот я даже вот так напишу.
Есть какой-то простой цикл отрицательного веса, до которого мы можем дойти и из которого мы можем выйти.
Вот так.
Причем более того заметим, что я же могу дойти до этого цикла и рассмотреть такой путь, который не пересекается по вершинам с этим циклом.
Ну мне же в общем-то не сильно важно как мы дойдем, правда?
И дальше.
Вот.
Ну исходя из этого, хочется теперь показать только одно.
Хочется показать, что...
Так, что нам хочется показать?
Нам очень-очень-очень хочется показать, что действительно какая-то из этих вершин...
Вот, нам...
Так, тих-тих-тих.
Нам очень хочется показать, что на n-й итерации хотя бы одна из этих вершин...
Хотя бы одна из этих вершин действительно проявит себя с приятной стороны.
Очень хочется, да.
Вот.
Прям очень-очень-очень-очень.
Вы хочется верить в то, что я всю свою жизнь называл мне лажа.
Вот.
Ну не знаю, а может выясним, что это лажа?
Хе-хе-хе.
Сейчас, ну...
Во-первых, можно сказать, что вот в отрицательном цикле у нас на каждой итерации будет какая-то релаксация.
Каждый раз будет происходить какая-то релаксация.
Не скажи.
Ну, смотря в какой версии. Вот в этой не факт.
Для начала нам хочется не больше, чем n-ребер.
Да.
Так.
Нет, ну не более, чем n-ребер, пожалуйста.
Я же сказал, у нас простой цикл и простые ребя.
Я эту технологию ровно ради этого и забабахил.
Поэтому, да, тут не более, чем n-ребер.
Вершинно простой.
Ну.
Вершинно простой по модулю вот этого финального зацикла.
А, ну ладно.
То есть вот этот вот, я могу рассмотреть путь вот такой и вот такой.
Это как бы и реберно, и вершинно по модулю зацикла простой путь.
Состоящий из не более, чем n-ребер.
Поэтому, да.
Да.
Нет, ну нам надо доказать, что именно на n-ном шаге одна из этих вершин повалится.
Нужно доказать, что на каком-то шаге будет релаксироваться сама вершина входа.
Вот.
А по нашей ДПОшке означает, что на предыдущем шаге тоже какая-то до этого релаксировалась.
И так можно обратно идти и доказать, что на всех предыдущих шагах была хотя бы одна релаксация.
Ну.
На этом подграфе.
Нет, ну может и была, и что.
Так.
Ну и все, значит у вас была на n-ном шаге релаксация.
Она могла быть только в этом шее.
Стоп.
Сейчас.
Допустим, у нас нет ни одной релаксации.
Докажем, что у нас и после этого не будет релаксации.
Нет, релаксация может и быть.
У нас больше проблема.
Нам нужно доказать, что...
А, ну хотя...
Да, нам нужно доказать, что на n-ном шаге должна произойти релаксация.
Давайте докажем, что если у нас не было релаксации на n-ном шаге, то у нас и на всех дальше шагах не будет релаксации.
Ну да.
Реала.
Сейчас.
Если у нас не было релаксации, то...
А если у нас на всех дальше шагах не будет релаксации, то в частности не будет двоя, то...
Ну да, ну давайте смотреть.
Предположим, что нам фантастически повезло.
И, значит, на n-ном шаге не на одной из этих вершин.
Не на одной из этих вершин.
Давайте их, кстати, так и назовем.
V1, V2, V3 и так далее.
V...
Ну да.
K мы не использовали, поэтому можно.
Нет, ну почему?
Так, и давайте высалом их будут W1, W2, W3 и так далее.
Wk.
Так.
И мы говорим, что...
Как бы...
Ну как релаксация?
На n-ном шаге могла с ними произойти релаксация.
Релаксация почти наверно и произошла, потому что исходно там вообще написано плюс бесконечности.
Какие-то пути мы всегда найдем.
На этом?
Ну, так.
Вот если вы внимательно посмотрите на ДП-шку, вы поймете, что релаксация на n-ном шаге, конечно же, всегда произойдет.
Если у вас ДП-шка неровная?
Ну потому что вот в этой ДП-шке, да, она произойдет обязательно.
Куда же она денется?
Нет, я не случайно это не просто написал и еще никогда не стирал.
Да, мы обсуждали, что с помощью этой ДП-шки можно свестись к другой и там будет плюс-минус идентично.
Но исходно мы пляшем от этой ДП-шки.
Так, и вот внимание и вопрос.
Тогда у нас просто на каждом шаге будет релаксация.
Но релаксация это, видите, у нас же утверждение требует не этого.
У нас утверждение требует, чтобы релаксация сказала, чтобы прям обновили не просто ДП, а ДП-опт обновили.
И что?
Ну вот хочется это и доказать.
Нет, еще раз.
Вот допустим, у нас ничего не релаксировалось.
Тогда у нас все ДП-шки остались теми же.
Нет, что такое все ДП-шки остались теми же.
Тут как бы картинка, я боюсь, с этой ДП-шкой не совпадает.
Все ДП-шки уровня от 0 до n-1 остались теми же, потому что мы их не трогаем.
А n-ные изначально вообще были плюс-бесконечности, поэтому релаксации там будут.
N-ты стали такими же, как n-1.
Ну вот.
Нет, они, с какого перепуга?
Да потому что у нас ДП-шка идиотская, надо нормально ДП-шку записать.
Нет, давайте не будем работать по принципу, мы все неправильно делаем, давайте себе подменять.
Этого надо избирать.
Мы уже зафиксировали ДП-шку, значит давайте смотреть.
А почему не работает?
Если мы меньше липаем, чем это?
Ну потому что пока невозможно нечетко липать.
Но давайте аккуратно смотреть.
Что означает, что не для одной из этих вершин ДП-опт не обновился?
Значит ДП-2, n меньше липает.
То есть это означает следующее.
То есть мы можем, давайте введем такое понятие.
Ну мы можем ввести такое понятие, как ДП-опт от VL.
То есть ДП-опт, какой он был после L-итерации, да?
Можем такое сделать?
Можем.
Ну это виртуально мы себе такое сделаем, конечно, да?
У нас консистентные массивы.
Значит мы хотим показать, что существует такое И.
Что ДП-опт от VL-итерации N оказался строго меньше, чем ДП-опт от VL-итерации N-1.
Вот по сути мы хотим доказать, что найдется И вот где-то вот от одного ДК.
Почему?
Чем ДП-опт отличается от ДП?
Ну тем, что ДП-опт это, ну короче, минимум на префексе суффикса.
Существует И такое, что ДП-опт от VL-итерации N-ого строго меньше, чем ДП-опт от VL-итерации N-1.
Это эквивалентно тому, но на самом деле это эквивалентно тому, что существует И такое, что вот L-опт от И равно L.
То, равно N.
Ну это то, что мы хотим доказать.
Да.
Да, мы это переформулировали, мы теперь вот это хотим доказать.
Теперь мы говорим, пусть для этих шин это не так.
Тогда релаксация не удалась, в том числе и по этим ребрам, правда?
И это означает, что, то есть если мы идем, как говорят на латыни, ad absurdum.
Вот.
Ну там это говорит ad absurdum, да, так что они так и говорят буквально.
Значит получается следующее, что если ничего не получилось, то мы вынуждены заключить, что, смотрите, я так и напишу,
Dp от VL-1 плюс W1 оказалось больше либо равно, чем Dp от VL-1.
Сейчас.
Да.
Ну так и оказалось, да.
Только не V, а вот V2.
Вот согласно таким утверждениям, да?
Потому что этой величиной мы этот Dpопт пытались обновить, правда?
А еще мы попытались сказать, что Dp от V2 N-1 плюс W2 оказалось больше либо равно, чем Dpопт от V3 N-1.
Ну и так далее, видимо.
Так.
Ну и теперь в конце получается Dpопт от, от чего там?
Тут V1.
И тут соответственно Dp.
В общем мы зацепились и умерли.
Ага, вот сейчас давайте разбираться, умерли мы или нет.
Уверен?
Вот давай, вот расскажи мне почему мы, почему вот из этого следует, что мы каким-то мистическим образом умерли.
А, ну хотя.
Это у нас, собственно, получилось, если по подставлять.
Просуммируем.
Нет, если просто подставить, типа.
Давайте просуммируем, а V1 N-1 плюс W2 меньше нуля по определению.
И что?
И чем это поможет?
Ну у нас.
А, Dp.
Не, а почему у нас?
А, Dp.
Не, а почему у нас?
Почему мы работаем с Dp?
Почему у него просто Dp?
В смысле?
Ну потому что просто, вообще как вы просто Dp напишем?
Ну у нас до этого было просто.
Потому что нам нужно, чтобы произошло обновление лёпта.
Ну и с Dp же он тоже прожидает.
Dp это же обычный формат.
И что?
Если мы не обновили, значит у нас на Dp есть такое неравенство.
Да.
Зачем нам кидать ещё Dp?
Я могу уезжать без опта.
Ну как бы я такого гарантировать не могу.
Нет, ну в смысле там без.
Сейчас.
Так, ну да вот давайте разбираться.
Что из этого вообще следует?
Да, в идеале хочется, конечно, всё эти неравенства просуммировать.
А, ну всё, кажется же всё прекрасно.
Да.
Чем категорически отличается DpOpt?
Dp это минимум на префиксе.
То есть DpOpt это минимум из вот этого и ещё того, что выше.
DpOpt это минимум.
Вот это.
Ну ладно, вот это DpOpt от этого.
Это минимум из вот этого и того, что выше.
Что значит того, что выше?
На префиксу собственно.
Ну как бы.
Ну по столцам.
Я просто себе воображаю, что вершины идут с таблицы так, а расстояние вот.
Мне не видно, как вы себе этого воображаете.
Длина пути не больше равна, чем наша.
Потому что такое выше было непонятно.
Длина пути не больше равна, чем наша.
Всё как...
Сейчас, какой длина пути что?
Всё.
Длина пути не больше, либо равна, чем наша.
Какая длина пути?
Не больше, либо равна, ни фига вы не оформляете.
Ну DpOpt.
Ну DpOpt меньше равен Dp.
Нам мало что даёт.
Нет, что нам это даёт, я не понял.
Так, что мы должны сделать, я не понял.
Нет, я говорю, что такое DpOpt.
ДпOpt.
Правда DpOpt это минимальная, напоминаю, минимальная длина пути, состоящего не более, чем из одного количества ребр.
А Dp это из любого числа ребр.
Что?
Нет, это ровно n-1.
Всё, всё, я понял.
Вот.
То есть Dp это ровно, а DpOpt это неровно, это меньше либо равно.
Ну да.
Да.
Ну вот, само по себе, если я это всё просуммирую, то как бы получится, что вот эта сумма Dp очевидно будет больше, чем сумма вот этих Dp.
Ну вот, поэтому как бы то, что тут цикл отрицает этого веса, само по себе ничего страшного не даст.
Это да.
Ещё раз.
Так, если просто всё дополнительно сложить там не будет.
Что? Какое предложение?
Я думаю, что вот если мы просуммируем, то...
Ну просто, не, ну как бы в идеале хочется сказать, что давайте просуммируем.
Когда получится, что сумма вот этих Dp-шек плюс сумма, плюс длина цикла, больше либо равна DpOpt.
Сумма DpOpt.
Но как бы само по себе это противоречие не рожает.
Это не рожает противоречие?
Ну просто у нас сумма Dp-шек, которая вообще там...
Из этой системы не нравится?
Нет.
А DpOpt равно?
Нет, оно меньше либо равно.
Ну тут давайте думать.
А мы не можем использовать то, что оно меньше или равно Dp для этого размера?
Просто меньше равно не помогает.
А мы не можем?
Стоп, ещё раз.
Ну минусы не вряд ли что-то.
Так, ребят, я не слышу ничего.
Скажите, почему мы не можем сократить Dp-шки слева и DpOpt и справа?
Потому что это разные вещи.
Что такое Dp?
Ну, в смысле, за n шагов.
Ровно n шагов.
Хорошо, а вот если мы рассмотрим постановку задачи не жёсткую, то...
Нет, ну не...
Вот пока не хочется подменять.
Подсмотреть туда, как доказывали там, типа...
Можно попробовать?
Если рассмотреть не жёсткую, то да, будет Dp тут, Dp тут, и они схлопнутся.
А мы до этого доказывали, что вообще-то у нас не жёсткая, она как бы...
Ну да, но всё-таки.
Мы предложили конкретный алгоритм пока, который основан всё-таки на этой Dp-шке.
Мы пытаемся проверить, обвалится ли он.
То, что вы говорите, это давайте рассмотрим другой алгоритм и заметим, что он не обвалится.
Ну да, просто тот мог алгоритм...
Ну в том, в принципе, да.
Более того, я вам даже больше скажу.
Можно даже этот алгоритм докрутить, что считаем динамику Dn-1, а потом возьмём DpOpt и попытаемся прелоксировать.
То есть для кого получится, значит у тех минус бесконечность.
Можно так сделать, можно сразу там так выкрутить.
Так выкрутить.
Но мы пытаемся сделать ещё более жёстко.
Давайте прямо здесь насчитаем, наверное.
Где насчитаем?
Где ещё насчитаем?
Вот вы сказали, прямо здесь насчитаем, вот здесь.
В этой Dp-шке.
Ещё один злой насчитываем.
Вот.
Вот если мы даже вот эту такую Dp-шку, вот интересно понять, чтобы глубже понять происходящее.
То есть действительно ли окажется, что это не поможет?
Может test можно найти, где это валится.
Не понятно.
Хочется взять не рандомный цикл, а отрицательный вес какой-то самый такой плохой.
Какой-то самый плохой?
А что такое?
Что такое какой-то самый плохой?
Не, ну можно как бы напрашивать, скажем, вариант.
Давайте нажмём вот этот путь и этот цикл, так чтобы суммарная длина была как можно меньше.
Можно, конечно, но если это нам что-то даст.
Или наоборот, как можно больше.
Не совсем понятны параметры.
Вот.
Я до сих пор не понимаю, почему мы рассматриваем это в жёсткую формировку, а не в мягкую формировку.
Если в мягкую формировку, то просто всё работает, но только всё проще доказывается.
Почему это?
Ну вот, потому что Денис предложил такой вариант, мы стали рассматривать его.
Я предложил вместо 2n рассматривать n.
Ну да.
ДПшку у нас, ДПшку я точно не предлагал.
Нет, ну на самом деле да, просто вот моя версия была другая.
Давайте тут не n было написали, а 2n-1.
Вот для 2n-1 это доказывается сильно проще.
Я могу вам подобрать задачу, где вы 2n-1 не выпихнёте.
Это вряд ли.
Когда ты квадратичные вещи такие пишешь, вполне себе подбираются.
Ну вот.
Например, если бы тут было не n, а 2n-1, то доказательства, то тогда я бы утверждал, что на всех этих вершинах обновление произойдёт.
Мы бы там смотрели просто разные разницы за последние n шагов, наверное, и всё.
Нет, ну не совсем.
Я бы сказал так.
Рассмотрим как бы кратчайший путь до вершины v1, допустим из s до вершины v1, состоящий из не более чем n-1 ребра.
Вот кратчайший, ну вот.
То есть вот этот кратчайший путь, то есть этот, который берётся из DPopt.
Значит DPopt соответственно от v1 и n-1.
Вот рассмотрим путь, который тут имеется в виду.
Так вот, я утверждаю, что давайте к этому пути прицепим вот этот цикл отрицательного веса длины не более чем n, да?
Тогда, ну вот.
Тогда если его прицепить, то как бы, если он вот, ну тогда получится путь какой-то меньший.
Но если количество ребер в нём останется меньше чем n-1, меньше либо равно, то тогда противоречие с определением вот этого DPopt, конечно.
Ну значит в нём ребер будет, с одной стороны, больше чем n-1, но не более чем 2n-1 при этом.
Следовательно, DPopt поменяется.
Вот, там было вот, если тут описать 2n-1, то как бы вот тут такое доказательство.
И там оказывается, что вот у всех этих вершин vopt заведомо поменяется.
Вот, понятно?
Ну типа того, да.
Какой?
Нет, нам нужна была цель.
Нет, мы пытались доказать, что для минус бесконечности достаточно запускать DFS только из тех вершин, у которых только n-на итерация обновилась.
То есть обновился опт именно.
А почему просто с DP не работает?
Ну то есть, если просто с DP, то у нас понятно, что на каждом цикле отрезовенного веса оно точно обновится?
Непонятно. Вот тут у нас и проблемы возникли, что это непонятно.
Что?
Потому что видимо у многих просто в голове как бы не понятно, что это будет, что это будет.
А что это будет?
Просто если у вас DP-opt в один момент становится больше n, то когда-то он был на единичку меньше, и так далее, и можно спускаться до n.
Ну там возникнут вопросы, а почему он именно на этих вершинах, может он там, они обновления пришли вот откуда там слева, справа, сверху, снизу, там вот так далее.
То есть в прямом.
В прямом?
В прямом.
В прямом.
В прямом.
Нет, если мы дошли до вершины цикла, то нам не важно даже, где они произошли.
Нет, ну как бы, ну я не знаю.
Если мы BFS-ом дошли до вот этой компонента с этим циклом, то все, нам уже в целом не важно, где у нас DP-opt, да и n увеличился.
Ну каким BFS-ом вообще? Не понимаю, я ничего не понимаю.
Еще раз.
У нас идея какая? Посмотреть, где DP-opt стал равен n, и от этих вершин запустится BFS-ом.
Ну да.
Нет, ну я согласен, что если мы докажем, что это произошло там либо на этом цикле, либо на этом пути до него, то в принципе да, это нам тоже хватит.
Я согласен.
Ну вот, только вот, кто сказал, что вот на этом вот все, действительно это тоже повыше, то, что мы знаем, что это было на этом цикле, то мы тоже знаем, что это было на этом цикле.
но вот только вот кто-то только кто сказал что и вот на этом вот всем действительно это тоже
произошло если даже спуститесь обратно куда-то не в этот цикл вы потом сможете дойти из той вершины
в этот цикл кстати да сейчас не понял не в этом цикле он стал н в каком-то другом цикле
в каком-то другом месте нет что значит можете обратно добраться до этого цикла
но это вот так вот и почему это все произойдет и потом мы доказываем что вы а потом вы просто
поэтому же пути возвращаетесь хорошо то есть вы хотите доказать хорошо выходить как что найдется
вершина достижима из с молоды гиммина рассматриваем низко то дара да у которой лёб стал равен н из
которых этот цикл достижим это вы прямо гарантируете это легко гарантировать почему потому что вот ваша
ситуация там с двоим шагов давайте рассмотрим ее просто с точки зрения математики понятно же что
понятно что у нас будет дп опт там больше и больше или равен и у всех этих вершин он будет таким
да ну значит сколько-то шагов назад он был там на единицу меньше на два меньше на три меньше
это кого у кого у этих вершин у каких-то вершин из которых достижим этот цикл так можно откатываться
по одному шагу откатимся до n да откатимся до вершины который цикл достижим так всего
а
смотрите ну-ка давайте еще попробуем давайте сейчас еще раз вариант может нет знаете может
сейчас как бы спокойно надавали хорошо ладно в таком виде утверждение сработало значит так
чем попытались доказать да то есть мы пытаемся доказать не это вот значит мы пытаемся доказать
более то есть мы пытаемся доказать теперь немножко другое все циклы значит зациклиться у нас не
получилось но нас этой не интересует значит мы говорим все еще у нас тут n и мы говорим что значит
хочется доказать следующее что если у нас была есть цикл отрицательного веса то значит то тогда
значит существуют такие хотим доказать что существует такие вершина у и значит существует
такая вершина у что значит во-первых dp значит opt от u равен n ладно не dp opt от lopt и из u
достижимы но там вот эти вот v1 vk да заметим что в общем-то этого нам хватит на самом деле
чтобы сказать что алгоритм правильно работает правда то есть то есть как бы не может быть до
этих ничего не обновилось а вот из лоптов обновились окей так как же мы это будем доказывать
доказательства звучит так заметим да давайте мысленно действительно да мысленно вместо n
интерации добабахаем до 2 n-1 тогда заметим что для всех как мы уже раньше выяснили для всех
этих вершин elopt за эти интерации уж точно поменяется вот теперь давайте рассмотрим что пусть он у
вершины v1 значит соответственно значит у вершины l1 elopt оказался равен ну допустим там я не знаю
n плюс d это плохая буква да n плюс x значит да это означает что была вершина у 1 у которой когда-то
вот так бывал n плюс x минус 1 ну раз вот это произошло значит наверное и в какой-то вершины
у 1 такое было правда ну просто в тот момент когда elopt становился n плюс x значит мы пришли
а нет непонятно да непонятно у 1 elopt может быть нет скажем так он был в тот момент когда
происходила релаксация он был меньше либо равен n плюс x минус 1 да но из этого не следует
может он был меньше либо равно n минус 1 и на самом деле все плохо нет мы отрелаксировались
из динамика n плюс x минус 1 но какой там elopt если вы берете по минимальному количеству ребер
да аккуратное доказательство рассмотрим кратчайший путь и состоящий из не более чем n плюс x ребер
да рассмотрим этот кратчай там какой-нибудь кратчайший путь или несколько кратчайших путей ну
такие могут быть да тогда утверждение такого когда мы первый раз это получили тогда значит
это предыдущая вершина из которой мы делали релаксацию у нее обязана было elopt тогда быть
n плюс x минус 1 почему потому что если там было меньше то при том же самом расстоянии да да да
окей то есть тогда получается существовала вершина у 1 значит с которой есть ребров в 1 у которой
elopt был даже ровно l плюс x минус 1 так хорошо аналогичным образом тогда существует вершина у 2 из
которой есть ребров у 1 где elopt n плюс x минус ой щас да так ну классно ну таки вот такой же цепочкой
получается что существовала вершина для которой elopt бывал n из которых вот это все достижимо
в 1 как следствие все остальное так что следовательно достаточна так что двойной
террации можно не делать достаточно сделать n и этого хватит ну да так что вот ну там конечно
возить тут еще 2 и минус одну итерацию бывает полезно делать если вам хочется еще и там
попытаться восстановить цикл отрицательного веса да ну какой-нибудь там да вот ну и хорошо так
что вот но ладно
