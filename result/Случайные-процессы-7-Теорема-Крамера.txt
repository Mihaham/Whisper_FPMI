Так, ребят, ну давайте начинать. Значит, мы с вами продолжаем заниматься фурье анализом
стационарных процессов. Я напомню, что на предыдущей лекции я анонсировал одно из важнейших
свойств стационарных процессов. То, что стационарные процессы, ну по крайней мере непрерывные,
они не могут быть всякими. Они представляются как суммы или ряды или интегралы некоторых комплексных
экспонент с некоррелированными коэффициентами. И, более того, корреляционная функция таких
процессов имеет тот же самый вид, что и сам процесс. Единственное это то, что вот этот коэффициент,
естественно, здесь не случайен, а он равен математическому ожиданию квадрата модуля коэффициента,
по которым раскладывается сам процесс. Сегодня мы вот эти теоремы с вами сформулируем. Одну из них
мы докажем в разложении процесса. Рассмотрим их более внимательно. И первая теорема, которую я
сформулирую, она пойдет без доказательства, это теорема о разложении корреляционной функции
непрерывного стационарного процесса. Теорема Хинччина. Значит, для того, чтобы непрерывная функция
РТ представляла собой корреляционную функцию некоторого СК непрерывного стационарного в широком
смысле процесса, необходимой достаточно, чтобы она имела вид. РТ равно интеграл от минус бесконечности
до плюс бесконечности е в степени и лямбда t на ds от лямбда. Это интеграл Рима-настельтьеса,
где s от лямбда это с точностью до неотрицательного множителя функция распределения некоторой
случайной величины. Вот. То есть это критерий быть корреляционной функцией непрерывного
стационарного процесса. Мы с вами уже в прошлый раз обсуждали, какой критерий, правда, не для
непрерывных процессов, а для любых процессов. Функция является корреляционной функцией
некоторого процесса, неважно, стационарного или нестационарного, если она неотрицательно
определена. Вот. Это критерий для процессов непрерывных. Вот. Значит, вот это можно
переформулировать. Например, где s от лямбда это функция ограниченная, неотрицательная,
непрерывная слева, монотонно неубывающая, начинающаяся от нуля. Функция. Вот. Но это много слов,
но мы знаем из теории вероятности, что это просто равносильно тому, чтобы это была функция
распределения, если она от нуля до единицы. Вот. Но здесь я хочу написать именно так, где эта
функция с точностью до неотрицательного множителя, функция распределения некоторой
случайной величины. Откуда это? Что это такое? А вот смотрите. Вот мы на прошлой лекции рассматривали
процессы стационарные, непрерывные, которые просто экспонента, умноженная на какую-то кси, или сумма
экспонент со своими кси1, кси2 некоррелированными. Вот у нас там входили просто лямда, лямда 1,
лямда 2. Так вот. Вот эта вещь, s от лямда, она с точностью до вот этого множителя сдает распределение
над частотами лямдами. Вот если у тебя просто лямда 1, лямда 2, это как будто у тебя есть случайная
величина, которая принимает значение лямда 1, лямда 2. Если у тебя ряд, ну или сумма ксиитых на
е в степени и лямда житая t, то это значит, что тебе дали случайную величину, которая принимает
значение лямда 1, лямда 2, лямда 3 и так далее. Но в общем случае, вот этот спектр над лямдами,
он может быть непрерывный. И у тебя может быть целый непрерывный спектр лямд. И вот этот спектр,
это распределение над частотами над лямдами, он как раз задается вот этой функцией s,
которая совпадает с точностью до индициативного множителя с функцией распределения случайной
величины. Что это такое за распределение случайной величины? Что это за случайная величина?
Вот она определяет распределение над частотами. Так, вот эта s от лямда называется спектральной
функцией. Называется спектральной функцией. Значит, у вот этой функции распределение может быть
плотность. То есть распределение может быть абсолютно непрерывным. То есть если существует
ρ от лямда неотрицательная функция, абсолютно интегрируемая полибегу на всей числовой оси,
такая что s от лямда равняется интегралу минус бесконечности до лямда, значит,
ρ от лямда до лямда, то вот эту ρ, то ρ от лямда называют спектральной плотностью.
Называется спектральной плотностью. Вот у тех процессов, которые у нас были в прошлый раз,
вот эти конечные суммы, экспонент, там нет плотности. Вот там f, точнее вот это s от лямда,
это некоторая кусочно постоянная функция, как у случайной величины, которая принимает конечное
число значений каких-то, это кусочно постоянная функция. Вот, но процессы могут иметь вот какую-то
ρ от лямда. Значит, эта функция, она неотрицательная, абсолютно интегрируемая на всей числовой оси.
Она не обязана быть гладкой, непрерывной или что-то там, она может быть вообще всякая. И всякая
неотрицательная функция, абсолютно интегрируемая на числовой оси, задает некую функцию s от лямда,
и если мы ее подставим в это выражение, мы получаем функцию r от t, которая, как следует из этой теоремы,
является корреляционной функцией некоторого непрерывного стационарного в широком смысле процесса.
Вот. Пример приведу один. Какой может быть, например, вот эта плотность ρ от лямда? Вот такая.
Допустим, вот она от минус лямда ноль до лямда ноль определена, здесь она какая-то постоянная,
здесь она равна нулю. Вот просто пример, такой тривиальный пример функции плотности. Значит,
вне этих частот она равна нулю, здесь она равна какой-то постоянной, то есть это значит,
что у нас как будто есть некое излучение, которое во всех частотах одинаково вещает.
Вот. Случайные процессы вот с такой плотностью спектральной называются белыми шумами. Белый шум.
Ну вообще-то белый шум это целый класс процессов, они могут быть и дискретными,
и необязательно с непрерывным временем. Ну вот такие процессы, они относятся к белым шумам.
Белый шум. Белый шум. Вот. Ну там посмотрите, у меня какая у него будет плотность. Это там
что-то типа sin t делить на t у rt. Вот. Есть модели, в которых лямда считается не конечной,
а на бесконечности находится, но при этом константа, она не ноль, а какая-то. Ну тогда эта
функция не является абсолютно интегрируемой, и в строгом смысле этого слова спектральной
функции у такого процесса не существует. Вот. Если вообще сам такой процесс существует. Вот.
Но тем не менее, есть обобщение случайных процессов, обобщенные процессы случайные. Вот.
У которых там спектральная функция или корредиционная функция вернее, она описывается в терминах
обобщенных функций. Вот. То есть такое вот расширение на вот эти случаи, когда нам полезно считать,
что лямда ноль, оно не какое-то конечное, оно на бесконечности, когда находится. Вот. Но мы такие
процессы изучать не будем, с ними связываться тоже не будем, но у меня в PDF-ках можете найти там
ссылки, где об этом можно почитать, как это все формализуется. Но для инженеров это очень полезная
модель на самом деле. То есть либо ты можешь считать, что лямда ноль у тебя конечная, но просто очень
большой, а ты работаешь где-то вот в более узком пространстве, что в принципе для приложений это
как раз тот самый случай. Ну либо тебе, например, удобно считать, что лямда ноль на бесконечности,
но тогда у тебя появляются обобщенные функции, с которыми нужно просто аккуратно работать. Вот и все.
То есть не нужно думать, что если плотности нет, то мы ничего не можем делать, никак с этим работать.
Нет, конечно, люди придумали некие обобщения. Вот. На интересные случаи. Так. Хорошо. Значит,
вот эта теорема, ее можно доказать. Доказательства можно найти у Ширяева в теории случайных процессов.
Вот. Значит, оно очень техническое. Я не буду ее доказывать. Очень техническое доказательство. Вот.
И она никак не опирается в своем доказательстве на тот факт, что процесс можно разложить тоже
в интеграл с комплексными экспонентами, где коэффициенты будут некоррелированы. Теорема Крамера,
которую я сформулирую чуть позднее. То есть это как бы независимая теорема. Вот ее можно доказать.
Все. Вот. Вот ее можно доказать. Так. Хорошо. Да. Нет, вот я написал для нее функцию. Ну, какие-то
задачки, может быть, вы на семинарах порешаете с ней сделать. А потому что излучает во всех частотах
на отрезке и нет приоритетов одних частот перед другими. Вот и все. Вот почему называется белым
шумом. То есть если ты будешь выделять из этого сигнала частоты, то увидишь, что у тебя вот такой
спектр. То есть нет приоритетов одних частот перед других. Шум. Белый шум. Бывает много других
шумов. Там красные шумы бывают, синие шумы бывают. Ну, там у них плотность, соответственно, где-то
она сдает уже приоритеты перед какими-то частотами. То есть если частота низкая, то что красный шум,
дат. В таких терминах можно работать уже. Вот. И смотрите еще какое здесь интересное наблюдение. Вот
r от, так как она корреляционная функция, она не отрицательно определена. Не путайтесь с неотрицательностью.
Она не отрицательно определена в том смысле, который у нас был на прошлой лекции. Вот эта
функция не отрицательная. А еще вот эта вещь, если мы сюда подставим вместо ds-rho от лямда до лямда,
то можно увидеть, что r от является преобразованием фурье, ну или обратным преобразованием фурье,
смотря как определять функции rho. Но мы вроде как помним, что и rho можно выразить через r от.
Если нам дали r от, как найти rho? Вот. Значит, вот если у тебя r от представляет в таком виде,
то не всегда rho от лямда является обратным преобразованием фурье r от. Есть условия,
они формулируются в курсе математического анализа, условия, при которых можно записать
rho через r. Ну это будет тоже интеграл, 1 делить на 2pi, вот тут минус поставить, и тут r от написать.
Вот. Но это определенные условия, когда это можно делать. Вот. Ну какие условия есть?
Их очень много разнообразных условий. Например, если r от непрерывно дифференцируемая,
по-моему, если она всюду... Сейчас. Как там, например, было? Сейчас. Например, да, если r от всюду
непрерывно дифференцируемая, тогда вот эта rho от лямда, она равна тоже такому же интегралу,
только уже от r от, а вот тут с минусом, 1 делить на 2pi, то есть обратным преобразованием фурье справедливо.
Вот. Есть другие как бы условия. Например, если мы запишем обратное преобразование фурье,
получим некую функцию, это наша функция rho от лямда, если она абсолютно интегрируемая.
Вот. Тогда тоже вот это обратное преобразование существует. Вот. Есть там более общие условия,
типа там условия Dini. В общем, но это уже касается курса математического анализа и к нам никак не
относится, поэтому туда и не пойду. Но одну теорему я сформулирую о связи неотрицательной
определенности функции и неотрицательности ее фурье преобразования. Вот. Такую теорему. Давайте мы
сформулируем. Я ее сформулирую, докажу. То есть, пусть функция r от t, всюду непрерывно,
абсолютно интегрируема на r и пусть для нее выполнены условия разложения в интеграл фурье.
Ну, то есть, r от t равняется интегралу минус бесконечности до плюс бесконечности e в степени лямда t rho от лямда
до лямда, и rho от лямда равняется интегралу от минус бесконечности единицы на 2 pi e в степени минус
и лямда t r от t до t. Вот эти слова выполнены условия, то есть, если выполнено вот это. Ну, какие-то
условия там, может быть, дополнительные там на функции накладываются. Так главное, чтобы вот это
было выполнено. Вот. Тогда r от t неотрицательно определена тогда и только тогда, когда rho от лямда
неотрицательно. Вот. Ну, если это, как бы, видите, эта теорема не совсем из случайных процессов,
здесь нет ничего про процессы, вот, какова общая теорема математического анализа, но она
триальнейшим образом доказывается, зная вот эту теорему, теорему хиничного наказательства. Ну,
смотрите, в одну сторону практически очевидно, ну, как всегда это бывает, да, то есть, пусть rho от
лямда неотрицательно оказалось, пусть rho от лямда неотрицательно. Вот. Тогда, если мы посмотрим
вот на это выражение, то оно имеет вон тот вид. То есть, тогда вот эту вещь мы можем записать как ds
от лямда, ввести s как интеграл rho от лямда до лямда, и это будет функция, которая с точностью до
неотрицательного множителя совпадает с функцией распределения. То есть, это будет какая-то ограниченная,
вот, ограниченная, всюду там неубывающая, непрерывная и так далее функция. Вот. Так что получается,
следовательно, r от t имеет вид из теоремы хинчина, вот, имеет вид из теоремы хинчина,
а это значит, что r от t это не просто какая-то функция, она является корреляционной функцией
некоторого процесса. Следовательно, r от t это корреляционная функция некоторого процесса,
а такие функции, как мы знаем, являются неотрицательно определенными. Следовательно,
r от t неотрицательно определена. Вот так вот. Хорошо. Теперь второе.
А может быть, и можно. Если она неотрицательно определена, значит, она корреляционная функция,
значит, она имеет вон тот вид. Ну да, смотрите, да, можно повернуть, но мы должны здесь сослаться
на то, что это разложение, оно единственное. Вот. Это разложение единственное. Вот. Да,
то есть и наоборот. Ну давайте, да, давайте мы так и сделаем. То есть r от t неотрицательно
определена. Отсюда следует, что она корреляционная функция. Отсюда следует,
что она имеет вид из теоремы хинчина. И если вот это следствие, оно просто остается, то вот это
следствие. К нему комментарий, что разложение в интеграл единственное. Вот. Ну вот это то, что
единственное разложение, ну это уже из курса математического анализа. Мы просто знаем,
что вот эти разложения, они единственные. Другого быть не может. Так что если мы представили его в
таком виде, и с другой стороны у нас представлены r от t вот в таком виде по условию теоремы,
то нам некуда деваться. Всё получается. Вот. Ещё маленький комментарий. Здесь у меня не явно
используется то, что r от λ абсолютно интегрировано, но это просто следует из-за того,
что r абсолютно интегрируема. Вот. Прирывно. Так. Так, хорошо. Ну всё. На этом тогда всё.
Движемся дальше. Теперь переходим к важной для нас теореме, теореме Крамера о разложении процесса.
А нет, даже проще. Смотрите. Последний комментарий. Она интегрируема просто потому,
что если существует r от t в таком виде, мы можем вместо t подставить 0, и здесь получится некий
интеграл. Ну r от 0 это какое-то число. Поэтому r от λ интегрируема. Вот. Даже так. Давайте так.
Такой комментарий оставим. Ну это нам нужно, чтобы вот эта s от лямда была ограничена.
Теорема Крамера. Так. Теорема Крамера. Вот у Крамера есть книжка замечательнейшая. Вот. На русском
языке классическая книжка. Просто, ну отлично написана. Я вам её просто рекомендую. Если туда
залезть, что-то почитать, то много узнаете. Это, кстати, одна из немногих книг, про которые я могу
сказать, что читая её, ты можешь учиться тому, как писать книги. То есть настолько всё ясно,
понятно. Ну вот просто, ну да нельзя. Но при этом всё математически обосновано, строго, не
пускается ни в какие излишние формализмы. Знаете, вот как вот любят некоторые навести формализму.
Много формул, там абстракции всяких, за которыми ничего не видно. Вот у него какое-то вот удачное
сочетание между ними. У нас будет ещё одна книжка с такими свойствами хорошими. Ой, да там типа
теория стационарных случайных процессов, что-то такое. Да, если её гуглить, то сразу найдёшь. Так,
ну и у меня на ноушене в списке литературы там тоже она есть. Значит, любому стационарному широком
смысле СК непрерывному процессу X от T с математическим ожиданием МХ соответствует случайный
процесс. Сейчас я поясню, что это такое. С ортогональными приращениями В от лямда.
Эта штука непрерывный аналог конечного числа некоррелируемых случайных величин. Процесс
с ортогональными приращениями такой, что с вероятностью единица выполняется равенством. Вот такое.
X от T равняется МХ, мат ожидания, плюс интеграл от минус бесконечности до бесконечности е в степени лямда
T на dV от лямда. Значит, d интеграл понимается как СК интеграл Римана стильтиеса. А процесс с
ортогональными приращениями это процесс с центрированной, то есть нулевым,
мат ожиданиями такой, что мат ожидания V лямда 3 минус V лямда 2 на V лямда 2 минус V от лямда 1
равно 0 для любых лямда 1, лямда 2, лямда 3. Ой, подождите. Что-то я не то. Четыре же вроде было.
Ну можно на самом деле так и так. Нет, давай четыре сделаем. Потому что так наверное более
общая. 4, 3, 2, 1, 1, 2, 3, 4. И вот тут сопряжение комплекса. Это комплексный процесс, вообще говоря.
Это определение процесса с ортогональными приращениями. Мы будем так называть процесса
центрированной. Ну, центрированность, она тут не принципиальна, но давайте мы, как классики,
это определяли, пойдем, что вдруг это где-то, ну да, мы на самом деле этим воспользуемся здесь.
Да, центрированный процесс, то есть процесс с нулевым от ожидания, и такое, что вот это
выполнено. То есть ортогональный в смысле скалярного произведения. Вот это ожидание
произведения случайной величины на ее сопряженное, вот это вот, это скалярное произведение этих двух
случайных величин. Вот скалярное произведение приращений на вот таких вот интервалах, оно равно 0.
То есть ортогональное приращение, ортогональное. То есть тут аналогия, она очень простая.
Значит, я придумал доказывать эту теорему в этот раз с использованием визуальных инструментов.
Будем сейчас рисовать. О чем мы только формулы пишем? Давайте немножко порисуем.
Нам нужно будет еще и место для того, чтобы все-таки какие-то отдельные формулы написать.
Значит, доказательства.
Значит, в основе доказательства лежит введение двух пространств Гильбертовых
с скалярными произведениями, линейных, и установление между ними взаимоднодоначного соответствия.
И это не случайно так мы делаем. То, что помните, опять же, на прошлой лекции возвращаемся.
Процессы раскладываются в суммы ряды интегралы по комплексным экспонентам,
и корреляционные функции раскладываются точно так же. Только коэффициент уже не случайной
величины, а от ожидания квадратов. Поэтому хочется какое-то соответствие между ними
установить. Вот это делается вот в этой теореме. Значит, мы нарисуем один большой кружочек.
Здесь это будет одно пространство. Сейчас мы его будем наполнять. Какие случайные величины,
что мы сюда добавим. И другое пространство. Мы его тоже будем наполнять. Вот это для случайных
величин и процесса. Вот это для корреляционной функции. Будем устанавливать между ними
соответствие. Итак, введем два пространства. Одно из них, сейчас я вспомню, как оно мне
обозначается. Одно из них мы обозначим за h х-центрированное. Другое мы обозначим за h от s.
Значит, s это спектральная функция х. Спектральная функция х, которая из теоремы Хинччина. Здесь нам
понадобится то, что спектральная функция существует, она определяется как теорема Хинччина.
Вот что мы добавим вот в это пространство. Для каждого t мы сюда добавим, давайте тут по центру
сделаем, х-центрированное от t. Ну это х от t-mx. Вот такую величину. И для всех t мы добавим в это
пространство все вот такие случайные величины. Давайте нам еще пригодится, для удобства введем
х-центрированное от t. На самом деле t пробегает все значения. Здесь много-много точечек для каждого t.
Ну вот одна из них. Ну для какого-то s, скажем, неравного t. Значит, здесь будут лежать все
сечения центрированного процесса. Сюда же добавим а1 х-центрированное от t1 плюс и так далее
а1 х-центрированное от tn для любых комплексных альф, для любых n, для любых t. То есть не просто добавим сюда
сечения центрированного процесса, но все линейные комбинации вот такого вида, все сечения с всеми
коэффициентами комплексными тоже сюда добавим. Они все будут лежать для всех t, n, альф вот в этом
пространстве. И более того, добавим сюда также sk пределы всевозможных последовательностей среди
всех этих случайных величин, которые мы сейчас ввели и предел которых имеет второй момент. То есть
мы ввели сюда вот эти все случайные величины и также добавим в это пространство h х-центрированное
их sk пределы, если эти sk пределы имеют конечный второй момент. То есть замкнем это пространство,
добавим сюда все предельные точки в sk смысле, которые имеют конечный второй момент. Ну вот и
ведем вот на этом пространстве скалярное произведение по очень простому правилу. То есть мы
будем считать, что это 1, это 2, это будет для нас математическое ожидание, это 1,
а это 2 сопряженное. То есть это состоит из случайных величин, у всех у них конечный
второй момент. Значит между ними всеми можно ввести вот такое скалярное произведение.
Это скалярное произведение будет на этом пространстве. Это линейное пространство,
очевидно, с вот таким скалярным произведением. Такое Гильбертово пространство мы ведем. Вот мы
будем считать два элемента тождественными, если расстояние между ними равно нулю, но расстояние,
которое генерируется вот этим скалярным произведением. То есть если математическое
ожидание модуля это 1 минус это 2 в квадрате равно нулю, то мы будем считать эти два элемента
тождественными. То есть они могут отличаться на множестве меры ноль, на самом деле, но вот мы
будем считать, что они как бы одинаковые. Нули равны источнице почти наверное. Так,
я обращаю внимание на то, что все элементы здесь имеют нулевое математическое ожидание. Теперь
мы образуем вот это множество, вот это пространство. Что это будет за пространство? Это пространство
функций, у которых существует, то есть пространство функций g, для которых конечен вот этот интеграл.
То есть это множество функций, интегрируемых по римму, но с функции s от лямда. Где s от лямда,
это не просто какая-то функция, это именно спектральная функция вот этого самого изучаемого
нами процесса x. Это важно. Кстати говоря, то, что функция s существует, и мы ее здесь используем,
это благодаря тому, что мы рассматриваем непрерывные процессы. Вот где у нас используется
непрерывность. Дальше вы можете не понять, где у нас непрерывность, причем непрерывность. Мы ее
используем, потому что мы вводим s, спектральную функцию. Вот, и давайте мы, да. Значит, вот эта вещь,
вот это, это пространство функций вот таких. Все такие функции лежат здесь. Вот, там мы как-то
вот индуктивно вводили, да, такую, такую, такие там пределы, все. Здесь мы сразу говорим,
все пространство состоит вот из таких функций. И на этом пространстве мы введем тоже скалярное
произведение g1 g2 как интеграл минус бесконечность плюс бесконечность g1 от лямда, g2 от лямда
сопряженная на ds от лямда. Вот такое скалярное произведение введем. Вот. А теперь самое интересное.
Давайте установим взаимнооднозначное соответствие между вот этими пространствами. Взаимнооднозначное.
То есть нам на самом деле в некотором смысле все равно с чем работать, с этой штукой или с этой.
Значит, смотрите, х от t мы сопоставим функцию E в степени И лямбда t, как функцию лямбды,
потому что если мы t зафиксируем, вот это будет случайная величина, и в случайной величине мы
сопоставим функцию. Функцию лямбды. Вот такую. t здесь параметр фиксированный. Лямда это переменная,
которая меняется. Это функция лямды. Вот она наша g от лямда. Она здесь лежит. Просто потому что если мы
подставим, здесь будет единица, интеграл ds. Эта штука, она ограничена. Будет s от бесконечности,
минус s от минус бесконечности. Это какое-то конечное число. Значит, эта функция в этом пространстве лежит.
Так что давайте мы вот этой вещью сопоставим вот эту функцию. Соответственно, какому-нибудь
x-центрированное s с другим временным параметром поставится в соответствие E в степени И лямбда s.
Вот. А теперь смотрите, что тут самое-то важное. Хорошо, между этими штуками мы соответственно
установили. Но скалярное произведение x-центрированное t, x-центрированное s в том пространстве,
это есть мат ожидания x-центрированное t, x-центрированное s сопряженное. Так. Но это
по определению корреляционная функция x-а в точке t, s. Здесь не просто что-то написано, это какая-то r,
x, t, s. Но процесс стационарный. Значит, получается, что это есть. Что такое? Что это можно выразить
через r, x, t минус s, где это соответствующая функция одного аргумента, потому что процесс
стационарный. Вот. Так. А по теореме Хинччина, вот эта вещь, это есть интеграл, потому что у нас все
условия выполнены для теоремы Хинччина. Тоже мы снова этим пользуемся непрерывностью, стационарностью.
И это есть интеграл от минус бесконечности до плюс бесконечности, e в степени i лямбда на t минус s,
ds от лямбда, где s это спектральная функция x-а, та самая, которая здесь и везде у нас. Вот. Но вот
эта экспонента, это e в степени i t лямбда на e в степени i s лямбда сопряженная. То есть, видите,
интеграл функции на сопряженную ds. Но это является образом x от t, эта штука является образом x от s.
Это есть скалярное произведение вот в этом пространстве, e в степени i t лямбда e в
степени i s лямбда. Это функция лямбда, это функция лямбда, просто у них параметры разные,
а это скалярное произведение здесь. Получается, что скалярное произведение там равно скалярному
произведению здесь. Ну, для, по крайней мере, для вот этих элементов. Для элементов, которые сечение.
Вот так что вот это преобразование сохраняет
скалярное произведение, по крайней мере, между сетчениями.
А раз скалярное произведение сохраняется между ними,
то и расстояние сохраняются между ними.
То есть расстояние между этими штуками равно расстоянии
между этими штуками.
Расстояние между этими штуками...
Давайте мы обозначим, что это такое.
такое там от ожидания модуль x центрированная t минус x центрированная s вот а расстояние
между этими штоками это есть интеграл модуль g ну получается е в степени и t лямбда минус
е в степени и с лямбда в квадрате ds от лямбда и так как скалярные произведения равны то и вот
эта штука равна вот этому интегралу в от ожидания вот этого квадрата равно вот этому и если одно
ноль то и другое ноль значит если вы рассматриваете равные функции здесь давайте сегодня без перерыва
зато попозже закончим значит если функции равны здесь в смысле вот этого расстояния значит и
соответствующие образы будут равны в смысле вот этого расстояния и наоборот вот установили
здесь соответствие ну а дальше на самом деле все ну просто тривиально потому что вот этой
вещи давайте мы сопоставим ну естественно вот такую вещь альфа 1 е в степени и значит t 1
лямбда плюс и так далее плюс альфа n е в степени и tn лямбда вот такую функции лямбда сопоставим и
если мы будем смотреть скалярные произведения между вот такими штуками а это кстати является
частным случаем такой штуки то в силу линейности математического ожидания мы снова получим что
скалярные произведения сохраняются при таком преобразовании то есть скалярное произведение
между этими здесь равно скалярному произведения между соответствующими функциями здесь просто
в силу линейности математического ожидания и интеграла но я не буду это расписывать но мне
кажется что это понятно взять мот ожидания этой штуки умножить на ее сопряженную раскрыть там
все эти скобки значит расписать посмотреть на каждый элемент в отдельности потом все собрать
обратно все тривиально так что скалярное произведение сохраняется и между такими
тоже вещами вот ну и соответственно расстояние между подобными вещами в этом пространстве
совпадает с расстоянием между соответствующими функциями в этом пространстве все остается только
разобраться с sk пределами то есть как их сопоставить друг другу ну смотрите тут все на самом
деле тоже очень просто ведь если здесь вот из таких штук мы сделаем последовательность случайных
величин которая куда-то в среднем квадратичном сходится да то есть если это n сходится к эти
среднем квадратичном смысле ну и пусть как по по определению того пространства квадрат
мот ожидания квадрат этой штуки ограни существует ограниченно вот то это значит что математическое
ожидание модуля это n минус это m в квадрате сходится к нулю принадлежит бесконечности свойств
фундаментальности последовательности то что в sk смысле она фундаментально но у нас это было
какая-то лемма 2 что ли на лекции 4 такой да вот это в силу фундаментальности но это есть
ничто иное как расстояние между ними расстояние между ними а мы знаем что расстояние сохраняются
вот для вот таких вот величин мы это уже показали расстояние между ними сохраняются это будет
интеграл от минус бесконечности до плюс бесконечности модуль gn который соответствует
эти n минус gm который соответствует эти m в квадрате ds от лямбда и это штука будет стремиться к нулю
это вот эти это вот эти то есть это стечение линейной комбинации для которых мы уже доказали вот
эти соответствия вот только они сюда входят это будет равно вот этому где gn соответствует
эти на gm соответствует это m они равны потому что это расстояние между ними в этом пространстве
расставления между не менее в этом пространстве равен вас до расстояниев между пространствами
мы доказали при этом преобразовании но опять же мы получаем фундаментальную по следовUNDV
этом пространстве а она тоже сходится потому что этоimb 2 полное пространство
всё нормально. Вот, и это получается сходится к нулевую. Значит, существует предел и здесь.
Существует предел. Предел в смысле вот этого расстояния. Какой-то g от лямбда.
И последний шажок, который мы здесь делаем. Давайте мы сопоставим вот этому эти, вот эту g от лямбда.
Предел в этом пространстве, сопоставим предел в этом пространстве. Вот наш последний шаг.
Мы сопоставили между тривиальными сетчениями, потом между линейными комбинациями,
потом между пределами. Вот, потом между пределами. Так, хорошо.
Хорошо, предел этот элемент мы сопоставим обратно.
Значит, любой элемент из этого пространства является sk пределом некоторой последовательности этих
штук. Но на самом деле xt тоже является пределом последовательности, просто постоянной последовательности xt, xt, xt и так далее.
Так что на самом деле любой элемент вот этой вещи является sk пределом вот таких вот штук.
В общем-то здесь то же самое. Любой элемент этого пространства является sk, является вот в этом
смысле пределом вот таких вещей. Вот, является пределом таких вещей. Соответствиями между ними установили.
Так, распространение соответствия. Так, ну и почему у нас будут расстояния? Ну, это просто следует и
свойств сходимости. То есть, если мы установили сходимость для простых объектов, вот таких вот,
которые сходятся к более сложным объектам sk пределам, то тогда вот это свойство сохраняемости скалярных
произведений, оно распространяется и туда тоже. Вот, то есть мы там можем записать, например, это n на эту
предел там равняется и так далее. Ну и перейти к пределу по n и мы получаем то, что нужно. То есть,
короче говоря, по свойствам sk сходимости и сходимости в том пространстве мы получаем, что если вот эти
свойства сохраняемости скалярных произведений расстояния справедливы над элементами, то они
справедливы над их пределами. Вот. Так. Хорошо. Но это мы сделали соответственно. Но причем тут
эта теорема вообще о том, что мы раскладываем процесс. То есть, это мы сделали некие подготовления.
То есть, для нас теперь все равно где работать. Здесь или там. И мы знаем между ними соответствия.
Мы можем взять элемент отсюда и знать, что ему соответствует какой-то элемент отсюда и наоборот.
Мы можем взять здесь последовательность, которая куда-то сойдется. Мы можем взять соответствующую
последовательность здесь, она сойдется туда тоже, куда надо и так далее. То есть, мы можем всем этим
пользоваться. Да. То есть, мы знаем, что пусть предел здесь существует, тогда мы через
фундаментальность показали, что пределы соответствующих g куда-то существуют. И вот
сопоставим вот этому это куда-то. Куда-то сошлось. Неконструктивно получается. То есть,
предел существует какой-то. Вот мы вот эту штуку то и сопоставим. Да. И это будет соответствие,
а взаимнооднозначность будет просто потому, что свойства скалярного произведения расстояния,
они распространятся еще и на вот эти СК-пределы. То есть, мы установили соответствие для этих,
это тривиально. Да, да, да. То есть, расстояние между этими равно расстоянию между теми,
просто в разных пространствах. Если здесь расстояние равно нулю, то есть, они совпадают
почти, наверное, то значит, и там расстояние равно нулю. То есть, они совпадают с мыслью вон того
расстояния. Ну, как бы с точностью значений в отдельных лямбдах функции могут быть разные,
но вот в смысле такого расстояния они совпадают. То есть, в этом смысле взаимнооднозначности.
Не буквальная взаимнооднозначность, а вот в смыслах вот этих вот расстояний взаимнооднозначности.
Мы не различаем объекты, расстояние между которыми равно нулю. Вот. Так, хорошо. Теперь давайте я тут
лишнее сотру. Теперь что мы сделаем? Ну, вы можете нарисовать снова две или рисовать туда же,
но я не хочу тут перерисовывать и я добавлю сюда. Я оставлю X от T, но вы, наверное, лучше нарисуйте
снова. Теперь мы будем работать с этими кружочками, зная, что между ними есть взаимнооднозначное
соответствие. X от T мы оставим, и то, что ему соответствует E в степени и лямбда T мы тоже
оставим. А теперь, вот в этом пространстве давайте мы возьмем вот такую функцию. Имеем право.
G с индексом лямбда 0. Сейчас поясню почему. От лямбда равно индикатор, а лямбда меньше
либо равно лямбда 0. Эта функция принадлежит вот этому пространству, потому что интеграл от нее
будет равен интегралу от минус бесконечности до лямбда 0. Ну, в общем, это получается S от лямбда
0 минус S от минус бесконечности. Что существует конечно и все хорошо. Значит, эта функция лежит
в этом пространстве. Вот просто захотели и взяли. Лямбда 0 здесь параметр, лямбда переменная,
это есть функция лямбды. А теперь, вот этой функцией кто-то соответствует там V от лямбда 0. Почему?
Потому что, если мы лямбда 0 зафиксируем, это будет какая-то, это будет какая-то функция. Этой
функцией сопоставляется случайная величина. Она может зависеть от лямбды 0. Если мы лямбда 0
меняем, функция меняется. Ну и тогда меняется и эта случайная величина. Если мы будем варьировать
лямбду 0, мы получим как бы множество функций для разных лямбда 0. Множество функций. Но это будет
отражаться на вариациях здесь. Мы получим разные случайные величины для разных лямбда 0. Получается,
что на V можно посмотреть как на процесс, который зависит от переменной лямбда 0. Понятно? Вот как
получается. На V можно посмотреть как на процесс, который зависит от лямбда 0. Так вот, оказывается,
что V это есть процесс с артагональными приращениями. Он лежит в этом пространстве,
поэтому его мотождание равно 0. Так? И оказывается, что это процесс
с артагональными приращениями. Почему? Докажем это. Это просто. Это просто доказать.
Вот это я сотру, это уже нам не нужно.
Где еще раз?
Да, для него вот лямбда 0 это время.
Возьмем произвольные лямбда 1, лямбда 2, лямбда 3, лямбда 4 и рассмотрим математическое ожидание
V от лямбда 4 минус V от лямбда 3, V от лямбда 2 минус V от лямбда 1. Сопряженное.
То есть скалярное произведение вот этих приращений. Мы с вами выяснили,
что скалярное произведение здесь равно скалярному произведению соответствующих функций там.
Так что переходим теперь туда. Это есть интеграл от минус бесконечности до плюс
бесконечности. От чего? Значит, G, которая соответствует лямбде 4 минус G,
которая соответствует лямдии 3, на g, которая соответствует лямдии 2, g, которая
соответствует лямдии 1. Перешли сюда. Ну потому что что такое процесс v, мы не
понимаем с вами, что такое абстрактная какая-то v, она существует,
ну кто она неясна. Вот кто она неясна. А вот что такое g, мы знаем, это индикатор. Ну и давайте
вычислим этот интеграл. Но давайте мы вот что заметим. Вот что такое, например, вот эта разность,
когда у нас лямда больше, чем лямда 1. Вот чему она равна? Давайте мы разберемся с вами. То есть у нас
есть прямая лямда, лямда 1, лямда 2. Если лямда очень большая, индикатор равны нулю. То есть и обе
функции, ой, обе функции равны нулю. Ноль и ноль. Если лямды очень маленькие, оба индикатора равны
единицы. А если лямда промежуточная, то тогда один из них ноль, другой один, правильно? Ну кто из них кто?
Значит у этого лямда побольше, поэтому здесь g лямда 2 равно 1, а здесь g лямда 1 равно 0. Потому что
мы больше лямда 1, он ноль. Но для этого мы меньше, чем лямда 2, поэтому тот 1. Значит это получается,
смотрите, индикатор того, что лямда принадлежит, ну я тут не знаю, открыто, не открыто, неважно с
точностью этих отдельных точек. Значит лямда 1 запятая лямда 2. Во, абсолютно аналогично вот
эта вещь, это есть индикатор того, что лямда принадлежит от лямда 3 до лямда 4. Но эти отрезки
не пересекаются, ну быть может только вот в одной точке, но на интеграл это не влияет. Значит это ноль,
видите, это ноль. Просто потому что мы взяли вот такую хитрую функцию g, индикаторную, что ее разность
это вот такая вещь. Вот, значит это процесс с ортогональными приращениями. Ну и последнее,
давайте мы наконец-таки возьмем, давайте мы возьмем частичную сумму того интеграла,
про который нам надо доказать, что он равен х с кружочком от t. Так, только мне бы где-нибудь
будет тут писать-то, я не знаю где. Там как-то узковато, ну или ладно, добавлю.
Так, а вот мы сейчас это докажем, сейчас мы это докажем. Значит мы возьмем эту как сумму,
по памяти ничего не помню. Примерно понятно, но чтобы не тратить время, значит от единицы до n,
e в степени i, t мы зафиксируем, но возьмем разные лямбды, gt, на v от лямбды g плюс 1 минус v от лямбды
gt. Вот рассмотрим вот такую случайную величину. Это частичная сумма того, что у нас стоит в теории
микрамера, правильно? Вот, значит эта вещь принадлежит hx центрированная, ну потому что здесь
просто линейные комбинации e с какими-то комплексными коэффициентами. Вот это наши альфы,
для каждого g это какая-то альфы g. А нет, стоп, нет, нет, нет, я вру, вру, вру, вру, вру. Не это
конечно альфа, альфа это детерминированные величины. Это получается линейные комбинации v и v лямбды g
плюс 1 и v лямбды g. Ну и ничего страшного, потому что v лежат в нашем пространстве, значит любые их
линейные комбинации тоже лежат в этом пространстве. t фиксировано, да, здесь t фиксировано. Так вот,
вот эта штука лежит вот здесь, хорошо. Ну это является пределом чего-то, это является пределом
чего-то, понятно, что их разность является пределом чего-то, все тут нормально. Ну так вот,
вот этой эти, вот этой эти, давайте мы ее эту возьмем, эту, ей кто соответствует здесь, в этом
пространстве? Какая-то функция g от лямбда, которая равна чему? Ну смотрите, как мы соответствия
распространяли, соответствующим образом. Получается, сейчас, сейчас, сейчас, сейчас,
это будет е в степени и t лямбда gt, когда лямбда принадлежит, а нет, и t лямбда, когда лямбда принадлежит
от лямбда g до лямбда g плюс один и ноль иначе. Вот, потому что вот этой разности соответствует
индикатор лямбда, принадлежащий отсюда-досюда, вот, умноженный на е. Ну и здесь получается,
что g это сумма таких индикаторов, вот это, то есть получается, что g от лямбда это сумма
экспонент, умноженных на индикаторы того, что лямбда лежит в этом отрезке. Так вот,
эта сумма индикаторов с этими коэффициентами, ее можно записать вот так. То есть, если лямбда
лежит вот в этом, а нет, сейчас, что-то все равно не то. Тут лямбда g стоит, значит, здесь лямбда g,
вот так, вот так правильно. То есть, если лямбда попадает в этот интервал, то здесь будет е в степени
лямбда g. Например, эта функция равна е в степени it лямбда 1, когда мы от лямбда 1 до лямбда 2. Эта
функция равна е в степени it лямбда 2, когда мы принадлежим от лямбда 2 до лямбда 3. Ну и так далее.
Да, это как бы получается в этом пространстве кусочно постоянная функция. То есть,
на вот этом отрезке она принимает одно какое-то комплексное значение, на другом отрезке она
принимает другое комплексное значение. Понятно, да? Вот. То есть, это кусочно постоянная функция,
вот здесь стоит. Но теперь, если мы возьмем разбиение на множестве лямбд, значит, от лямбда 1
до лямбда n, в каких-то пределах от минус a до a, устремим мелкость к нулю, n к бесконечности,
после этого устремим a к плюс бесконечности. Все это можно описать как некий СК-предел,
в конце концов. То мы получим, что это сходится к интегралу от минус бесконечности до плюс
бесконечности e в степени it лямбда на dv от лямбда, просто по определению вот этой сходимости.
Так, когда мы ввели разбиение, вот эти а устремили к бесконечности, мы получили,
что это стремится вот сюда. То есть, это стремится к интегралу от минус бесконечности
к плюс бесконечности e в степени it лямбда dv от лямбда. А куда устремится g от лямбда? Это кусочно
постоянная функция, которая на вот этой штуке, на этом отрезке. Если мы лямбда устремим, если мы
мелкостью устремим к нулю, то вся эта кусочная постоянность сожмется, и g от лямбда сойдется к
e в степени it лямбда. За счет того, что a устремится к плюс-минус бесконечности, у нас пропадет вот
этот ноль, потому что это ноль вне всех вот этих отрезков. Но так как a увеличивается и все больше
лямбда попадает на всю большую часть числовой оси, то вот этот ноль он просто пропадет. Это я как бы
интуитивно понятно рассказываю, но если немножечко напрячься, то это все аналитически там в одну строчку
получается. Главное, чтобы вот в этих деталях не запутаться. Главное тут что? Что это ушло вон туда,
а g от лямбда ушла не просто куда-то, а вот сюда, к e в степени it лямбда. Но соответствие-то
взаимно однозначное. e в степени it лямбда. Смотрите, наша самая первая стрелочка. Кому соответствует?
x центрированная t. Значит вот эти вещи это одно и то же. В смысле вот этого расстояния. То есть они
совпадают почти наверное. Итак еще раз. Еще раз. Мы вели частичную сумму эту. Ей соответствует вот
эта функция. Эта вещь сходится вот к этому интегралу. Эта вещь сходится вот к этой функции. Но эта
функция соответствует вот этой случайной величине. Так? Расстояние между этими в этом пространстве
устремилось к нулю. Значит расстояние между этими вещами в этом пространстве тоже обязано
устремиться к нулю. Потому что расстояние сохраняется при этом преобразовании. Значит эта
точка она должна быть здесь. Ну или по крайней мере расстояние между ними в смысле этого определения
равно нулю. Все. Вот такая теорема. Итак схемы как бы этой теоремы на следующие. Ввести два у таких
пространства, установить между ними взаимнооднозначное соответствие. Дальше вводим вот такие
индикаторы и замечаем, что при варьировании лямбда 0 они соответствуют артагональному процессу.
Процессу с артагональными приращениями вернее. Вот. Теперь берем частичные суммы такие,
какие нам нужны. Они с одной стороны сходятся вот сюда. С другой стороны функция им соответствующая
сходится сюда. А она отвечает вот этой вещи. Значит они равны. Почти, наверное. Все. Конец. Вот и вся
теорема. Идейно она вся такая. Но все остальное это вот эти вот технические мелкие детали. Все они
несложные. Вот так. Понятно? Ну хотя бы общий скетч. Понятно, что там есть технические моменты. Вы
когда будете разбираться, вы может быть не сразу что-то поймете. Но сейчас, вот когда вы сейчас
здесь сидите, главное вам вот общую мысль понять, вот как это все делается. Вот она вот такая. Вот это
общая мысль. Красиво, да? Это теорема Крамера. Так. Хорошо. Мы движемся дальше. У меня остается не
очень много времени. Значит у меня в ПДФ-ках вы, я думаю, сами прочитаете один абзац о физическом
смысле спектральной плотности. Ну я немножечко уже об этом сказал. Что-то вот спектры, да там,
вот эти всякие фурье преобразования. Это все из физики. Вот эти все функции, которые вы тут встретите,
они все очень похожи. Там сильно стоит делить на Т, как из оптики. Вот. Но это вы почитаете. Там у
меня про это написано. Ну пробелы, шум и обобщенные процессы тут тоже написано. Это тоже, как бы,
вы сами прочитаете и разберетесь. Я не думаю, что на это стоит тратить время мне. Вот. А самое
главное, что я расскажу, это одно из приложений всей вот этой теории. Линейная теория о стационарных
процессах. То, что для инженеров это просто хлеб. То есть это то, что для инженеров является их
основным инструментарем. Ну нет, не только, конечно, инженеров, вообще математиков, которые занимаются,
например, обработкой сигналов. Это вот базовая теория. Линейная теория. И мы просто получили для нее
некий фундамент. И вот буквально вот совсем такие элементы, элементы, элементы, элементы этой
линейной теории, я здесь сейчас вам скажу.
Значит так, так, так, так, так, так.
Линейная теория о стационарных процессах. Значит первое, что я, может быть, стоило об этом сказать во
время доказательства. Ну ладно, неважно, сейчас скажу. Значит вот мы установили, что х, центрированное
от t, есть интеграл вот такого вот вида. Так, есть интеграл вот такого вида. Так, и смотрите, как
интересно получается. Вот видите, х, центрированное от t. Вот здесь стоит тот, кому он соответствует. Вот это
образ вот этой вещи в нашей теореме. Это не просто так, это образ в нашем отображении вот этой вещи.
Можно доказать, но я это опускаю, это не тривиально, но мы это примем без доказательства, что на самом
деле можно написать даже так. Для любого это из пространства х, центрированное, будет интеграл, это
будет равно интегралу g от лямбда на dv от лямбда, где вот это g является образом вот этой этой, более
сильные условия, понимаете, да. То есть мы установили соответствие между этими, нам никаких там
сверхусилий, никаких теорем, лемок, дополнительных нам здесь не потребовалось. Но это можно и обобщить. Это
лишь один из элементов этого пространства h, но на самом деле это равностно распространяется на любые,
где вот это образ, образ это. Давайте мы это примем без доказательства. Вот такое наблюдение. Но отсюда
что в частности следует, что если вы, допустим, умножите этот процесс на какую-то величину альфа,
то это значит, что это перенесется и сюда тоже. Вот, то есть это означает, что эта вещь будет равна
интегралу от минус бесконечности до плюс бесконечности альфа-е в степени и лямбда-т. Ну, в общем-то в силу
линейности интеграла это и так понятно, что это вынесется туда. Это условие, оно более общее, но здесь
мы видим как бы частный случай вот этого условия, сам по себе очевидный, что мы можем альфа внести
внутрь dv от лямбда. Но когда мы умножаем процесс на альфу, то его корреляционная функция увеличивается
в модуль альфа в квадрате раз. То есть это означает, что rx от t перейдет в модуль альфа в квадрате rx от t.
И если rx от t у нас представляется в виде интегралы лямбда-т ds лямбда, то получается, что при этом
преобразовании этот будет интегралом e в степени лямбда-т модуль альфа в квадрате ds от лямбда.
Вот перейдет вот сюда. Ну и отсюда следует, что если мы обозначим за y альфа x центрированный от t,
давайте тоже просто чисто для симметрии его обозначим y от t, то это означает, что ds y от лямбда
это есть модуль альфа в квадрате ds x от лямбда, просто в силу однозначности разложения r. Вот.
Ну и если у них есть плотности у y и у x, то тогда ρу лямбда равняется модуле альфа в квадрате
ρх от лямбда. Вот. То есть такое вот линейное преобразование, оно меняет спектральную функцию
вот таким вот образом. В линейной теории рассматривается обобщение вот таких вот линейных
преобразований и вводят вот такой оператор l. Допустим, у нас есть некоторый линейный оператор l,
который действует на x центрированное, в результате чего мы получаем следующую вещь.
Интеграл от минус бесконечности до плюс бесконечности l, которая действует уже на е в степени и лямбда t на d
в вот этого x от лямбды. Вот пусть нам дали оператор l такой, что он действует вот таким образом,
то есть что его можно внести внутрь интеграла и что все его действия концентрируются только на
действие на вот эту экспоненту. Вот это частный случай такого оператора умножения на некоторую
постоянную альфа. И видите как получилось, что он по сути действует только вот на эту экспоненту.
И есть такой целый класс линейных преобразований, тоже у Крамера можно посчитать, не только у него,
что это такие за преобразования, которые позволяют внести это внутрь и представить это в таком виде.
И пусть вот эта вещь, это есть phi от лямбда на е в степени и лямбда t. Вот не все преобразования
таковы, но пусть это будет так. Опять же здесь мы это видим, это вот действие этого оператора на
экспоненту, это некая функция лямбда, вообще говоря, а в нашем случае это просто константа лямбда,
умножить на ту же самую экспоненту е. То есть да, пусть l такова. И на самом деле таких l очень много,
про которые можно так сказать. Ну вот тогда, ну просто примеров много. И есть теория,
которая описывает такие l. То есть всякие суммы, умножения, даже дифференцирование относятся к
таким вещам. А что существование? Вот умножение на альфу уже существует хотя бы одно. Так,
ну хорошо. И тогда мы получаем, что наш процесс у от t, который равен l эксцентрированный от t,
это есть интеграл от минус в бесконечности до плюс в бесконечности, фи лямбда е в степени и лямбда
t на dvx от t. Это с одной стороны, а с другой стороны это есть то же самое и лямбда t на dvy от t. И в силу
однозначности разложения мы можем записать, что фи лямбда dvx, ой от t, от лямбда, извините,
от лямбда равно dvx от лямбда равняется dvy от лямбда. Вот. Можно так это воспринять? Ну и
по-другому можно воспринять. Мы знаем, что просто интеграл e dvx равен x центрированное от t и ему
соответствует некая r от x. А если мы умножим ее на фи от лямбда, вот это, так сейчас, если мы умножим
f от лямбда, это тоже будет элемент нашего пространства h. Так. Сейчас-сейчас-сейчас. Как бы мне это
ввести, так чтобы было понятно. Не хочу делать несколько шагов вместе. Сейчас, одну секундочку.
Подумаю, как бы мне это ввести. А, вот, наверное. Да, точно. Так, ну хорошо, мы на этом... Здесь
мы на этом остановимся. Теперь вот что сделаем. Значит, v и x и y в пространстве h находятся, и
расстояние между ними соответствует расстояниям для s. Значит, математическое ожидание модуля v от
лямбда2-v от лямда1 в квадрате равно... значит, значит, значит... равно, равно, равно интегралу
от минус бесконечности до плюс бесконечности вот этих наших g от лямбда. Помните? g от лямда2 от
лямда минус g лямда1 от лямда в квадрате ds от лямда. Но вот эта вещь, это, индикатор того,
что лямбда лежит в этом отрезке, значит это получается интеграл от лямбда 1 до лямбда 2
ds от лямбда. то есть s от лямбда 2 минус s от лямбда 1. вот это мне сейчас понадобится. то есть
получается, что математическое ожидание модуля v лямбда 2 любого x и y на v от лямбда 1 в квадрате
равняется s от лямбда 2 минус s от лямбда 1. вот и вот эту вещь еще можно записать,
просто использовать такую запись. она означает вот эту для конечных дифференциалов. модуль dv
значит от лямбда в квадрате равняется ds от лямбда. то есть символ ds можно заменять на вот эту
штуку, если при записи частных частичных сумм мы будем писать не разность s, а мат. ожидание модуля
квадрата разности v. то есть мы можем записать, мы можем заменять в частичных суммах вот эту
разность вот такой штукой, которая не разность, а квадрат разности мат. ожидания. ну в общем,
понятно. ну так вот, я это к чему веду, что при переходе к y мы берем x и умножаем его на phi от
лямбда. так? значит как поменяется s? это означает, что ds y от лямбда, это есть тот же самый ds x от
лямбда. но вот эта v, которая внутри стоит, она умножится на phi. так что здесь получается модуль в
квадрате phi. phi от лямбда в квадрате. вот. вот эту формулу запомните. ну плотности, если они существуют,
они также связаны. плотность y равняется плотность x умножить на вот этот коэффициент. к чему я все
это рассказываю веду? и в чем содержательный смысл всей этой теории? смотрите. в линейной
теории стационарных процессов вот эти линейные операторы характеризуются своими функциями
phi от лямбда. вот эта штука еще называется частотной характеристикой. вот это частотная
характеристика. преобразование l. вот, например, у такого преобразования альфа, да, просто,
просто умножение, у него частотная характеристика, вот она тривиальна, phi от лямбда равно вот этому
альфе. так? тогда как преобразуется ds? модуль phi в квадрате, то есть модуль альфи в квадрате. вот
у нас здесь появился. но у других преобразований у них может быть своя частотная характеристика. во
временной области процесс, он может видоизменяться очень сложным образом. то есть линейное преобразование
над процессом, вот, например, производное, sk производное или почти наверное производное, если они
совпадают, это довольно сложное преобразование процесса. но оказывается, что это линейная, в смысле вот
этих всех действий, операция. и этой производной соответствует тоже некоторая частотная характеристика.
значит, если эту производную можно вносить внутрь интеграла, и там у меня в подъявках, посмотрите,
там тривиальные условия, интеграл там квадрата лямбда на плотность должна быть ограничена,
сходится. вот, то тогда, то есть для l, которая равна производной, которая совпадает с sk и совпадает, пусть
почти наверное, производной, то для нее фи от лямбда, смотрите, если производную мы подействуем на
экспоненту, то у нас вынесется и лямбда, и экспонента останется. это значит, что частотная характеристика
равна и лямбда. вот, это значит тогда, что dsy от l равняется модуле лямбда в квадрате на dsx от лямбда.
ну, и соответственно, плотности тоже так зависит. ρу от лямбда равно модуле лямбда в квадрате на
ρх от лямбда. вот, это вот такой пример. но для того, чтобы это все работало, там нужно, чтобы вот
такой интеграл был конечным. но это вы у меня уже, вот эти всякие детали технические, это вы
посмотрите в моих pdf. вот, вот я прокомментировал вот эту теорию. то есть, все сводится к тому,
что мы над процессом совершаем какие-то линейные операции и выражаем их в терминах вот этой
функции phi. процесс во временной области может меняться очень сложно, но в частотной области
он меняется тривиально. ты просто умножаешь свою спектральную плотность на квадрат модуля
частотной характеристики этого преобразования. и вот над процессом ты можешь совершать
целую серию линейных преобразований. дифференцирование, интегрирование, умножение,
сложение, сдвиги. там кучу всяких операций ты можешь делать. и во временной области процесс
и его свойством от ожидания, корреляционная функция там, ну хрен знает, что происходит с ней.
но в частотной области у тебя просто наращиваются множители перед спектральной плотностью. если ты
знаешь, если ты знаешь частотные характеристики преобразований, которые ты накладываешь процессу,
то новый твой процесс, это просто процесс как бы старый, с плотностью старой, но умноженный
последовательно на функции вот эти вот частотные характеристики. вот почему вот эта теория, она
интересна. в частотной области все просто, проще, чем во времной. перешел в частотную область,
сделал тут все, что тебе надо, а потом вернулся обратно, например, по теореме об обратном
преобразовании. ты можешь найти r через rho. если ты нашел rho, ты находишь r, просто через
интеграл, ну конечно. а так вот ты переходишь в частотную область и в ней работаешь. теория
сигналов, она во многом построена на вот этих вот идеях. перейти в частотную область и там
работать, если это оказывается удобным, а это часто оказывается удобным. вот такие дела, ребята.
значит так, на этом мы с вами первое задание завершаем. торжественно вам объявляю. первое
задание мы закончили. на следующей неделе будет контрольная работа, потоковая. значит в этой
аудитории, в это время, 12-20, место как бы лекции получается. значит, я вашим семинаристам уже
разослал правила. значит, это контрольная, вы за нее не можете получить штрафы, если вы не придете
или придете, но плохо напишете, никаких штрафов вы не получаете. вот, я всем семинаристам об этом
сказал. так, но вы можете получить какие-то плюшки за это. может быть какой-то преподаватель скажет,
что вот вы решили все задачи, я вам засчитываю первое задание без всяких сдач. такой вариант
возможен. вот, единственное, что за хорошее написание этой контрольной вы не можете получить
плюс один балл в ведомостной экзамене. вот ограничение такое. но получить какие-то локальные
плюшки за сдачу зданий, это вы уже обсудите со своими семинаристами. все семинаристы вольны
по-своему это учитывать. кто-то может вообще скажет, что это все туфта и не будет никак учитывать. но это
вы уже там сами разбирайтесь. вот, по крайней мере штрафа не может быть какого. а так вы можете
прийти и попробовать ее написать и обсудить ее со мной. например, эту контрольную задачки просто
свои силы померятся, задачки будут несложными абсолютно. никаких творческих элементов олимпиадного
вот этого там не будет. то есть это будут стандартные задачи на стандартные темы. то есть
абсолютно спокойные нормальные задачи. вы не можете на контрольной ничем пользоваться,
но вы можете задавать вопросы поясняющего характера преподавателям, которые здесь будут
присутствовать. например, вы что-то не понимаете в условии или вы там забыли какую-то теорему,
вам ее могут напомнить. и вы ее тогда примените. то есть препод за вас не может решить вашу задачу,
но просто какие-то моменты подсказать, в том числе теории, какие-то определения, теоремы,
он может. это вполне нормально. у нас так было всегда. вот такие вот условия. а так гаджетами там
и книжками и конспектами пользоваться нельзя. вот это будет контролироваться. ну все тогда.
