Сегодня мы с вами будем говорить о двух вещах, а второй если успеем. Надеюсь, что мы успеем,
значит все будет очень грустно. Первое, это линейные контейнеры.
Вы уже успели насладиться контестом, вот его красоте. В этом виде всякие сдачи по типу
реализовать стек, реализовать очередь, бла-бла-бла. Собственно, это вот сюда. Те, кто сдали,
конечно молодцы. Вот, но я удивлен. Окей, но кто такие линейные контейнеры? В общем-то это
контейнер, это нечто, что хранит в себе, ну просто хранит в себе данные и что-то там делать с ними.
Обычно не модифицировать, а там что-нибудь типа искать и контейнер можно видоизменять путем вставок,
удалений и так далее. Собственно, линейный контейнер это тот, кто хранит данные линейно.
Вот, если вы когда-то слышали всякие деревья, типа деревья в поисках, вот это не линейный контейнер.
И начнем мы с списка. Вот, ну у вас, видимо, существуют лекции по C++, вот, и скорее всего
вы знаете, что массив это какая-то вот такая вот штука. Как-то вот так вот выглядит. Ну тут
какие-то ячеечки. Физически вам представляется чаще всего это как непрерывный кусок памяти,
ну в целом даже не чаще всего, а так и есть. Вот, это непрерывный кусок памяти фиксированного размера.
Что? А, ну это ноут по-английски, замечание. Давайте по-русски напишу, да. Я... Привычка, назовем это так.
Вот, ну не всегда нам нужен непрерывный кусок памяти, то есть не всегда у нас есть такая потребность,
чтобы уметь обращаться к произвольному элементу очень быстро за вот единицы. Ну, как мы привыкли,
что это работает в нашей жизни. Физически это, конечно, не так, но ладно. Доброе утро, Илья Рудольфович. Вот.
Ну, физически мы привыкли, что это просто указатель на нулевой элемент, и по сдвигу мы
понимаем, куда мы обращаемся. Вот, не всегда нам это нужно, иногда нам нужны такие структуры,
где мы хотим просто уметь что-то искать и там что-то быстро делать с данными. Вот. Массив,
он немножко неудобен тем, что он не позволяет вам взять. Если у вас есть вот этот элемент,
ну как-то вы в этом получили там указатель на него или что-то такое. Вот. Вы его взять и просто удалить,
сдвинув при этом индексацию, допустим. Вот. В общем случае мы так быстро делать не умеем,
это будет делаться за линейное время, потому что нам придется создать новый массив и перекопировать
все элементы в него. Ну, это плохо. Где-нибудь к концу этого семестра мы научимся делать за алгорифм
с помощью деревьев, но это нам не важно пока что. Просто великая магия, что массив у нас будет
деревья представляться. Вот. Окей. Иногда нам хочется уметь быстро удалять из середины элементы,
но примеров и приводить не буду, они потом возникнут естественно.
Собственно, кто такой список? Определение это сложно, поэтому просто напишем,
что, точнее это не потянет на определение, что список это просто набор узлов, где каждый знает
своего соседа. Вот. Ну, вообще непонятно, что за этой надписью кроется, но давайте я нарисую.
То есть у нас здесь какой-то узел. Да, узел мы будем означать узлов и будем называть нодами.
От английского note и почти все время это будут ноды. Ну, такой жаргон сложился. Собственно,
этот элемент знает своего соседа. Этот знает своего соседа. Ну, есть один обделенный, у которого
как бы есть сосед, но он указывает в никуда. Это односвязанный список. Вот. Собственно,
односвязанный, потому что связь одна. Односвязанный. Что уметь делать односвязанный список?
Ну, по-хорошему мы храним в памяти у себя где-то там в коде только указательный этот элемент.
Вот. Это мы будем называть head. Ну, от английского голова. Вот. Мы храним в себе head. Ну, и там,
допустим, мы еще поддерживаем размер, когда нам надо узнавать размер нашего списка. Собственно,
как здесь выполняются операции? Ну, поиск это просто проход по всему. Списку вы умеете
получать по хеду его следующий элемент, ну и так далее ходить по ним. Вот. Ставка в этот список
осуществляется обычно вот в этот конец, да, в голову, грубо говоря. Делается на как-то вот так вот.
Вы берете, говорите, вот у меня есть новый элемент. Говорю, что его сосед это текущая голова и
переписаю его голову сюда. Ну, собственно, как-то так. Больше здесь ничего нет интеллектуального.
Что нам это позволяет делать? Во-первых, мы умеем делать вставку бесконечно много, ну, физически
конечно много. В общем случае, если у нас в вам память бесконечно, то бесконечно много раз. Вот.
Причем достаточно быстро, потому что нам не нужно тут как-то что-то тут перевыделять целый кусок
памяти непрерывной. Бла-бла-бла. Это очень долго. Мы сегодня докажем, что это недолго на самом деле. Но
пока что для нас это очень долго. Вот. Соответственно, давайте напишем односвязанный список.
Операция. Какую табличку заведем? Время. И примечание у нас здесь будет. Ну, раздену его
я не буду, потому что иначе это будет некрасиво, если мы не влезем. Вот. Окей, операция. Это,
первое, это будет вставка в конец. Ну, обычно она называется push. Вот. Делается на золоте единицы,
и примечаний здесь, ну, никаких нет, здесь пусто. Также у нас есть операция с удалением. Как она
делается? Вы говорите, ага. Типа скажи, что вот этот элемент, а этот забудь. Ну, на коде это
чуть сложнее выражается, но не сильно. Его мы еще с вами попишем сегодня. Ну, какой-нибудь метод size,
там узнаете размер. Ну, он тоже быстро делается, если вы хрените размер. Иначе вам придется
проходить по всему этому списку и считать, сколько у вас элементов есть. Окей. Теперь вопрос,
за сколько будет делаться удаление произвольного элемента? Вот, давайте подумаем сами. Так, удаление.
Произвольного элемента. Ну, например, по значению нам говорят, удали там первую пятерку. Ну,
просто идем фором по всем. Ну, здесь скорее вайлом, пока у вас не дойдет вот этого отсутствующего
соседа. Вот, в коде на плюсах у нас будет выражаться через 0ptr, скорее всего. Ну, не принципиально,
на самом деле. Давайте по индексу давайте. Так, мне нужна стиражка. Здесь все будет одинаково.
По значению, по индексу. Давайте по индексу. Окей. Понятное дело, что в худшем случае это будет от n.
Ну, n это размер списка. Ну, есть еще дюанс. Если у вас есть указатель на этот элемент уже,
ну, допустим, вы его где-то сохраняли. Ну, типичный пример. Я не помню, у вас в контесте есть задача
про гоблинов, где они в сердинку встают и так далее? Нет? Ну, вот есть, короче, такая классная задача,
где у вас нужно рисовать контейнер, который умеет делать что? Умеет делать уш, умеет делать поп
с другой стороны и поп из середины. Вот, например, вы можете просто поддерживать этот указатель на
середину при всевозможных наборах операций. И, собственно, примечание здесь такое. Если есть
указатель на элемент, то за от единицы будет делаться на самом деле. Почему? Ну, потому что
если у вас есть указатель конкретно на вот этот вот элемент, то как сделать удаление? Ну, сказать
типа, что? Ну, давайте мы скажем, что мы удаляем следующий за каким-то элементом. Вот, вот так вот.
Вот такая вот нотация. То есть мы узнаем указатель на этот элемент, да, и мы хотим удалить этот, то есть
следующий за ним. Тогда скажем, что следующий для вот этого вот, это вот этот вот. То есть, ну,
совсем рисунок умрет, поэтому будем представлять это виртуально. Точнее, методом копирования рисунка.
Вот. Допустим, у нас есть указатель на этот элемент, а мы хотим удалить этот. Пока что неважно,
как это сделать. Допустим, что так получилось. Вот, потом мы поймем, что этот контейнер бесполезен,
если что. Ну, так. Ну, не бесполезен, но не то чтобы, как нужно будет. Вот. Что мы тогда делаем? Мы говорим,
что следующий для этого, это вот этот вот элемент. То есть, следующий следующего. И забываем вот этот
вот. Ну, просто его удаляем. Ну, там как-то. Победа. То есть, можно зовут единицы, на самом деле.
То есть, у нас есть такой набор операций. Существуется здесь. Допустим, говоря, проблема удаления в том, что
вам нужно сделать индексация, это назовем. Вот, индексация. Вот и будет делаться, где идет ваш индекс.
Окей. Так, давайте. Ну, вы хотите удалить элемент по этому индексу. Вам нужно допрыгать до этого
элемента. То есть, вы сделаете вот и прыжков. Ну, и дальше от единицы операции, так у вас уже есть
указательный элемент. Вот. Так, давайте здесь поставим пункт А, как односвязанный список. И перейдем на эту
доску. Пункт Б. Это будет был связанный список. Собственно, им обычно мы и будем пользоваться,
до поры до времени. Вот. Здесь как бы скажем так. Мы изучим с вами кучу контейнеров сегодня. Вот.
Поговорим про, ну, их сравним как-нибудь. И, соответственно, исходя из этого, будем понимать,
какой ситуации, что нам конкретно, какой набор операции нужен. И исходя из этого, выбирать то,
что нам будет оптимальным по времени, памяти, работы и там. И еще там, смотря, что вам будет нужно.
Был связанный список, представьте себе вот такую вот штуку.
Давайте вот так вот.
И здесь для гармонии, вот так вот.
Вот что-то такое. То есть мы храним связи в обе стороны. То есть у нас для каждого элемента известен
его сосед справа, сосед слева. И храним мы в этом всем деле голову и, ну, что противоположно голове,
давайте. Вот, да, молодцы. Пистеха, элита, интеллектуальная все-таки. Отлично. Голова и хвост.
Ну и все. Тобственно, набор операции не изменяется относительно этого, только у вас появляется
ориентация у Пуши и Попа в плане того, что вы умеете делать как спереди, так и сзади.
А это в зависимости от того, как, что вы назовете. Это абстракция. Вы можете его называть хоть лево-право
и разворачивать как хотите. Вы можете там читать его справа-налево. Ну, как вам удобно.
Хед и тейл вообще принятые. Обычно говорят хед. Обычно просто если идет речь об односвязанном
списке, то всем понятно в какую сторону вы добавляете. Там просто Пуш. Потому что в другую сторону вы не
умеете добавлять. Потому что у вас просто нет указательного на последний элемент.
Ну и там, короче говоря, проблем много будет, и это всем лень делать.
Вот. Окей, теперь поговорим о Попапам. Второй раздел. Это контейнеры-адаптеры, так называемые.
Сразу скажу, что слово адаптер здесь в целом не общеприменимое, но здесь возникает не из теоретических
соображений, а из практических. Вот. Есть такая штука в программировании, когда вы там что-то пишете,
пишете, пишете, и вам нужно вырезать функционал чего-либо и назвать это по-другому. Ну, сейчас возникнет,
понятно будет, почему и откуда это берется. Вот. Это называется адаптером. Ну, адаптируется. Вот.
Ну или еще это можно будет назвать как такими несамостоятельными структурами данных, потому
что их можно реализовывать поверх чего вы хотите. Вот. И первый из таких чуваков это стэк, собственно.
Ваш любимый стэк, который вы должны были реализовать после этой лекции, но часть из вас справилась уже.
С чем я их и поздравляю, конечно. Вот. Кто такой стэк? От стэка мы хотим следующих операций. Да,
мы будем определять эти структуры данных с точки зрения не реализации, а с точки зрения API. Ну,
API это просто набор операций, которые мы хотим уметь делать. Вот. Такое определение. Вот.
Мы будем просто расписывать операции. Ставим ничего. Мы хотим делать push. Мы хотим делать pop.
Мы хотим делать size. И мы хотим делать top. Ну, top это взглянуть на элемент. Собственно,
стэк это вот такая вот штука. Я его люблю рисовать как такой стакан. Ну, можно еще назвать это стопкой
какой-нибудь. Типа стопкой тарелок, например. Вы умеете добавлять вот в эту сторону и извлекать
из этой стороны. Вот. Такой вот контейнер интересный. Ну, собственно, здесь мы должны
были сказать, как же так внезапно его подносятся операции. Это подносятся операции односвязанного
списка. Есть такая мысль? Как-то не очень воодушевленные у вас лица. Вот. Ну да, это мы умеем
делать. Мы умеем, по сути дела, добавлять и удалять отсюда. Все. Этому можно будто бы вот
нарисовать вот такую вот ограничивающую рамку и понятно, откуда, куда не ноги растут, а элементы.
Вот. Вот. И, соответственно, он удовлетворяет парадигме, так называемая парадигма, ну или
принцип. Если вам слово парадигма кажется слишком пафосным. Лифо. Расшифровывается как last in, first out.
Вот. Это все, если что, просто умные слова, которые вам на практике особо не пригодятся
для осознания, но для чтения литературы будут полезными. Тобственно, последним вошел, первым
вышел. Вот. Ну, например, мы добавляли один, два, три, четыре, пять. Соответственно, первой будет
извлечена пятерка, которой мы добавили последний. Ну, собственно, стэк можно реализовывать, а, на
списке, б, внезапно на массиве. Если вы знаете максимальный размер стэка, вы можете просто
завести такой массив и урезать его функционал до того, что вы умеете обращаться не к произвольному
элементу, а лишь к последнему. Поэтому и адаптер. Он как бы адаптирован под вот такую вот штуку,
под вот такой вот протокол работы. Так, вопросы. А отдельным исключением, ну не то чтобы исключением,
но, скажем так, что нам может пригодиться в этой жизни? Это такая штука, как MinStack,
назовем ее. Кто такой MinStack? Это стэк, да, по-английски он пишется вот так вот,
плюс Min. То есть операция минимума еще в стэке он умеет делать за вот единицу. Такая вот мощная структура.
Ну как это реализовать? Давайте еще хранить не только элемент, который мы добавили, но еще
минимум во всем стэке, в каждой точке истории, назовем это так. Ну, например, здесь на место хватит.
Ну и здесь давайте мы будем хранить value какой-нибудь, а здесь Min. Ну и давайте у нас
будут операции типа, не знаю, push от пятерки какой-нибудь, push от тройки. Да, соответственно,
минимум мы храним минимум во всей истории. Если стэк пуст, то это просто элемент, который мы
добавили. Дальше идет push от тройки. Ну окей, минимум из тройки и пятерки это тройка. Давайте push
от четверки. Ну здесь, понятное дело, значение будет четверка, а минимум во всем стэке это тройка.
Давайте push от двойки еще сделаем. 2, 2, push. Ну не знаю, чего-нибудь такого нам точно хватит.
Окей, вот вопрос. Давайте мы не знаем, что здесь сидим. Вот мы знаем вот такое вот состояние,
у нас структура. Как понять, какое значение надо написать сюда? Как найти минимум во всем стэке?
Ну внезапно, да, минимум во всем стэке это минимум из вот этих вот двух элементов. Так плохо
получилось. Сейчас. Эта единичка здесь была. Это минимум из вот этой вот и вот этой вот. Потому
что эта штука хранит минимум во всей истории. Соответственно, вот этот пересчет минимума,
он позовет, что делать. Точнее, как его делать. Если у вас стэк пустой, то вы добавляете минимум,
просто текущий элемент, который вы добавили. Иначе вы сравниваете добавленный элемент с минимум в
вершине. Ну и пишете минимум из них. Например, вот здесь вот из четверки и тройки минимум тройка,
поэтому писалось тройка. И утверждается, что в каждый момент времени, если вы спросите у стэка
минимум, то минимум будет лежать вот здесь. На верхушке, на вершине. Доказывать это можно,
не знаю, по индукции, например. Рассмотреть каждую операцию. Предполагайте, что состояние стэка
корректно. Дальше применяйте любую из операций и доказывайте, что корректность сохраняется.
Ну, например, скажем, что здесь мы сделали поп. Забыли вот эти вот.
Ну тогда у вас минимум хранится здесь корректно, это двойка. Дальше делаете поп. Давайте здесь буду
дальше писать. Снова делаете поп. У вас удаляется снова элемент. И у вас все еще
корректно хранится минимум в стэке. Ну как раз-таки просто по индукции того,
что у вас все было корректно на этом состоянии. Окей. Ну, наверное, вы встречали такие
целосочетания, как Stack Overflow. Но Stack Overflow это общий сайт, образованный целосочетанием
Stack Overflow. Overflow это переполнение по-русски. Вот. Собственно, откуда оно берется? Наверное,
вы, возможно, слышали о такой вещь, как Stack Recursion. Было такое? Нет? Окей. Ну,
давайте напишем такую элементарнейшую программу.
Классно, да? Ну, там в мейне вызовем просто f. Ваши идеи, что произойдет? Что? А дальше?
Вот. Она будет все время вызывать себя. Соответственно, и как бы по сути, мы же можем
записывать какие-то аргументы. И по-хорошему, мы хотим уметь откатываться в какое-то состояние.
Ну, давайте, например, что-нибудь такое, да? Давайте n больше 0. Там f от n минус 1. Там,
так вот, перед вами, например, факториал. Ну, только здесь надо еще какое-то значение. Вот. Ну,
давайте здесь вызовем f от, не знаю, от 20. Вот. Она сделала 20 рекурсивных вызовов. Причем
внутри в памяти это будет храниться, как мы вызывали f от 20, дальше мы вызвали f от 19, f от
18, бла-бла-бла-бла-бла. f от единицы. И попытались вызвать f от 0. И каждый раз компьютер вынужден
хранить то, что было в памяти на текущий момент. Логично, да? Потому что вы хотите все-таки
когда вы вернетесь обратно, будете подниматься вверх по этому стеку вызовов, то у вас произойдет
то, что вы хотите на текущий момент знать все-таки, что было, причем именно в тот момент. Поэтому это
все хранится в стеке, причем там хранится, ну, физически я не буду описывать, как хранится вот
этот вот f. Хранится все, что было внутри f. Вот. И у вас так хранится сказки, как стек, потому что
там что нужно мне делать? Добавлять в конец, то есть новый рекурсивный вызов функции, или откатываться
на 1 назад, когда у вас рекурсивный вызов закончился и вы вернулись на уровень выше. Вот. И это все
хранится в специальной стековой памяти, про которую вам расскажут на плюсах, ну, плюсах,
по крайней мере, так. Ну, в других сказках, скорее всего, тоже. Просто я там не знаю, куда именно пишут
стек рекурсии. И stackoverflow возникает, когда у вас переполнение стека возникает. То есть,
когда вы вызвали кучу раз функции f, и у вас закончилась память на рекурсивный вызов. Ну,
бывает такое. Обычно это проблема краски с тем, что у вас вечная рекурсия. Отсюда и stackoverflow
возникло совсочетание. Это такая историческая научпопная справка, назовем это так. Вот.
Про стыки поговорили, теперь про очередь. Или есть вопросы?
Ну, вообще, есть опции у компилятора, которые говорят ему, что прими stack таким-то. Но
безгранично это тоже сделать нельзя. Вот. Я не помню, как там флаг этот называется, к сожалению.
Скажем так, если у вас возникает необходимость увеличить стек, скорее всего, вы делаете что-то
не то. В частности, например, ваш DFS, его можно переписать по-другому, просто явно храняя стек.
Вот. Можно так сделать. То есть, не пользоваться стеком, которым предоставляет ваше физическое
устройство, а как бы явно его создавать и явно в нем что-то хранить. Так тоже можно делать,
и все будет ок. Окей. Так, B это очередь. А кто такая очередь? По-английски это вот такое вот
неудобоваримо произносимое слово, Q. Вот. Ну или, по-моему, она звучит как Q, просто Q и все.
Не Q-U-E-U-E. Вот. Вот, пожалуйста, не говорите Q-U-E-U-E, вас никто не поймет. Не знаю, скажите,
очередь или Q. Ну еще, в американском варианте очередь это line называется, вот, но вас так тоже
никто не поймет, если вы будете в гугле вводить вопрос там, how to blah blah blah in line, то он не
поймет, что вы от него хотели. Вот. Или там какой-нибудь whiz line, например. Можете писать это вот страшное
слово, просто запомните, как оно пишется. Но очередь, у нее операция следующая. Так как нам здесь будет
важна уже ориентация пушев и попов, мы здесь пропишем вот так вот push front, pop back. Ну,
front и там size какой-нибудь. Ну, для органичности, чтобы всем совпадало. Вот. Ну, очередь, она ведет
себя внезапно, как очередь реальной жизни. Вот. Ну, конечно, не как в больницах, где-то можно
только спросить. Мы верим в то, что мы живем в светлом мире будущего, где очереди все прекрасно
работают. Вот. То есть, у вас человек может зайти в конец очереди и выйти из начала. Ну,
например. Будем называть это front. Это back. Ну, видите, я опять перепутал ориентацию очереди.
Тобственно, здесь как бы, назовем это так, что обычно всем понятно из контекста, и вы будете
говорить, типа там push в очередь, добавляем в очередь. Никто не говорит push front в очередь. Ну,
потому что это A долго, B как-то не звучит. Вот. И нет такого вот, нет такого фонетического
единообразия с стэком. Вот. Парадигма у нее, соответственно, противоположная. Я верю, что вы догадаетесь.
Типа, да. First in, first out. Ну, давайте подумаем, в смысле чего можно резать очередь.
Так. Нет, два стэка это для умных. Мы пока что не обладаем таким секретным знанием.
Ну, с помощью стэка не получится одного. Вроде бы направление стрелочек не совпадает,
скажем так. Вот. И как-то адаптировать ему не получится. Да, с помощью двухсвязанного списка,
например. Вот тут вот у нас. Напомним этого чувака. Вот. Причем, ну, я здесь специально не буду
предать front и back, потому что понятно, что они здесь равнозначны. А здесь нет. Ну, с помощью, да,
можно еще с помощью двухсвязанного списка. С помощью чего еще можно? Можно с помощью кольцового
буфера, так называемого. Вот. У вас спойлер. Ну, те, кто не на первом курсе иностранцы,
у вас будет задача реализовать кольцовый буфер. Вот. А у тех, кто умещен, у нас, скорее всего, нет.
Ну, и так вот. Кто такой кольцовый буфер? Это обычный кусок массива. Ну ладно, просто массив,
который хранит себе указатели front и back. И дальше, если у вас идет push, вы front просто
сдвигаете сюда и говорите, что здесь будет какой-то элемент. Что-нибудь такое. Изначально там на один
указывают. Вот. То есть push, он будет вслед за счет того, чтобы вы записали сюда элемент и front
переместили вот сюда. Ну pop, наоборот, то, что вы back сюда будете перемещать. То есть забывать
значение этого элемента и сюда перемещать. На самом деле его даже можно не звать, просто back
переместить и все. Вот. А как делать, если вы там расширились до конца? Берете и закольцовываете
его. То есть считаете, что следующий индекс там по модулю берется. И все, и пишете вот так вот.
То есть, по сути, у вас получается не то чтобы массив, а вот такая вот, не знаю, вублик назовем это.
Это какое-то подобие солнышка, в котором вы так вот пишете.
Ну там направление обхода выбирайте сами. Кольцевой буфер, чтобы очередь писать.
Ну не всегда прикольно писать очередь на дусязном списке. Причина чистая физическая, потому что,
давайте оставим это на семинар все-таки. Я попрошу семинаристов объяснить, почему физически списки
медленнее, чем вот такие вот, интересно загогулины. Ну смотри, вот у меня сюда указывает фронт,
и мне нужно делать пуш, да? Я пишу сюда элемент и говорю, теперь фронт у меня указывает вот сюда вот.
Все. Ну то есть, как понятное дело, что это не очень очевидно, что это то же самое, что и это.
Вот, ну кому-то удобнее так представить, если вам это неудобно, то представьте это вот так вот просто.
Вот. Окей. Тобственно, казалось бы, зачем нам... Ну понятно, эта штука очевидная, а зачем мы вообще
разбирали? Если мы говорим про какие-то линейные контейнеры, то еще какие-то минимумы внезапно
добавляются. Ну, иногда бывает в жизни огорчение, и вам нужно писать вот такую вот штуку.
Очередь с поддержкой минимума. И проблема в том, что здесь, на двухстороннем списке,
вы никак не отдуетесь, чтобы сделать минимум в золоте единицы. Ну почему, казалось бы,
давайте минимум хранить, да и все. Просто в свою личную очередь хранить минимум. Проблема в том,
что если вы храните очередь и просто минимум, и у вас в какой-то момент на запрос SpotDoc удалился
этот минимум, вам нужно внезапно искать за линию. Это очень грустно. И еще мы, ну понятное дело,
можно построить контртест, такой, что у вас каждая операция минимум будет выполнена за ОТ, за линию.
Это совсем печально, потому что вас деградируют все до квадрата, а квадрат это нечто, что для
линейных контейнеров неприемлемо, потому что все-таки, ну, линейное от слова линия, вот,
линейное время, линейный контейнер. Нет-нет, мы хотим за ОТ единицы. Это вот наша великая мечта.
Пока что, если мы пользуемся подходом на той вот доске, продусязный список, у нас ОТ единицы как-то не
работают. Ну, куда ты торопишься? Я тоже могу сказать два стека, ну и что? Вот, да, нам нужны два стека.
Давайте, наверное, передумаем эту доску. Очередь на двух стеках.
Ну, на собеседовании в приемку, ну, в приемной комиссии, не чтобы работать в приемной комиссии,
чтобы вы, короче говоря, сюда поступили в приемной комиссии, у вас там собеседование со студентами
проходит, да? Ну, у иностранцев я не знаю, как это конкретно происходит, я знаю про обычные программы, вот.
Соответственно, там есть задачи у этих, от этих студентов, которые вас там валят и ненавидят всеми
кибрами души. Ну, как вы можете догадаться, нет, на самом деле. Вот, ну, вы все такими, ну, не все, там
кто-то из вас такими точно будет, кто пойдет в приемку, вот, и, пожалуйста, не отыгрывайтесь на абитуриентах
за вашей абита. Вот, и там как бы дают задачу реализовать очередь на двух стеках. То есть,
когда вам говорят, что есть стек, это вот такой вот стаканчик, ну, или такая вот стопка тарелок,
придумайте с помощью двух таких стопок, как реализовать очередь. Ну, давайте, вот гений сидит,
очереди на двух стеках. Ну, да, в общем-то, конструкция будет выглядеть примерно так.
Ох, получилось.
Вот так нормально. Мы как бы умеем, в этом стеке мы умеем делать вот так вот и вот так вот.
А в очереди мы хотим что-то вот такое вот. Какие две стрелки надо соединить, чтобы получить вот такие вот дуги.
Ну, да, то есть нам нужно сделать вот такую вот штуку. Тут у нас план реализовать что-то вот такое вот.
Вот, картинка ясна, она пока останется на доске для того, чтобы просто было
графически понятно, что мы делаем. Давайте я напишу здесь вот такой прекрасной функции,
которая объясню, что она потом делает. Уж простите меня мои одноуквенные переменные и не соблюдение
Код Стайла. Все-таки я пишу на доске, вот, и у меня здесь место ограничено. Да, у вас 80 символами, но у меня
здесь меньше на самом деле, так что не бессудьте. Мы потом с вами будем проходить какую-нибудь структуру,
где я нормально напишу код на доске. Пока что как-то так. While L size больше нуля, R push от l.top, l.pop.
Ну, совсем плохо. Это еще хоть как-то похоже.
Ну, я скажу сразу, что в STL, в C++ стандартный стэк, он на pop ничего не возвращает, он void.
Как фронт в стэке. Мы там ток написали, где стэк. Это получение верхнего элемента.
Функция shift осуществляет этот перенос. Сразу скажем, что это будет l.push здесь, а здесь будет
l.r.pop. Окей, когда вызывать этот shift? Этот shift вам надо вызывать, когда у вас надо извлечь
элемент, а здесь пусто. Или посмотреть на верхний элемент, а здесь пусто. Вот такое бывает. То есть
код push у вас вообще не изменится. От стэк s. Давайте мы пишем здесь l.r, как для единообразия.
Здесь будет просто l.push от… А, ну еще мы все означение перейдем кое-что. int val от val.
Здесь совсем все просто. Давайте я здесь напишу pop от stacr. И здесь мы будем проверять,
что если вот этот r, давайте это l, это r. Но вообще по-хорошему их надо обозначать in-out,
stac-in, stac-out. Stac-in – это в которых мы добавляем элемент out, из которого извлекаем. Но я забыл
об этом, когда писал shift, и сейчас уже поздно переписывать. Так сказать, задумывайтесь о
нейминге с самого начала, чтобы не исправлять потом код style. Если все-таки он пустой,
то мы делаем следующее. Делаем shift от lr. Ну и дальше вы делаете pop. Заметьте,
я сразу не пишу, что у вас там в случае пустых стэков происходит, как работает pop от пустого
стэка. Вот это уже вы сами будете решать, как вам это делать. Вот. Ну и все,
достаточно долго на нашей доске. А, уже перерыв прошел. Ну, что поделать? Что? Да нет, сейчас
сделаем. Тобственно, тогда вопрос, как сделать min? Почему о втором? Да, нам нужно два минимума
взять. Нам нужно сделать return minimum из l-min r-min. И это уже на ваше усмотрение. Я считаю,
что у меня стэки хорошие, не пустые. Вот, если какой-то из стэков пустой, он возвращает страшную
вещь, скажем так. Ну, да, пока что для вас страшная вещь называется бесконечностью. Потом,
когда вы больше узнаете C++, у вас это будет называться вот такой вот штукой. Option. Вот.
Но пока что я сотру, чтобы не дай бог Илья Семирыч не посмотрел ему лекцию и не обнаружил,
что он рассказывает что-то к Option. Вот, иначе он будет очень расстроен, что я отбираю у него
хлеб. Ну, или там у кого-то Даниил Альбертович. Вот. И пока что обработку крайних случаев я ставлю
на вас целиком. Вот. Потому что у нас все-таки лекция, не семинары. Мы пишем код на доске,
а доска прощает многое. Даже ошибки компиляции за код стайла. Ну, зря ты туда отошел, ну ладно.
Собственно, тогда минимум вы золотые единицы получаете, потому что в стейках минимум вы золотые
единицы получаете умеете. Собственно, где вам это может быть полезно? Кто-нибудь может придумать
хоть какое-то адекватное применение очереди с минимумом? А если быть более, скажем так,
реалистичным человеком? Окей. Ну, применение вообще такое. Ну, давайте вместо минимум возьмем какую-то
произвольную ассоциативную операцию, на самом деле. Потому что здесь важна только ассоциативность.
Допустим, у вас есть какие-то данные, которые к вам приходят в режиме онлайн. Напомню онлайн,
это значит, что вы их не знаете, не он как-то приходит со временем. Ну, например, там у вас есть,
не знаю, приложение, какое-нибудь приложение, и вы там ведете его логи. Сколько там? Кролов,
кликов, лайков, бла-бла-бла. Вот. И у вас есть такая вот огромная-огромная-огромная история. И вы хотите,
ну, понятное дело, что, допустим, для анализа текущего состояния приложений вам не очень важно,
что происходило год назад. Вам нужно какое-то окно, ну там, не знаю, недель две, например. И вы хотите
узнавать минимум за две недели минимальную оценку. Ну, что-нибудь такое. Вот тогда у вас что вы
хотите уметь делать? Вы хотите уметь, ваша очередь прекрасная, вы хотите уметь добавлять в нее новые
данные. То, что вам пришел новый отзыв, допустим. Уметь из нее извлекать данные, потому что этот
отзыв уже успел состариться. И в придачу вы хотите уметь извлекать там минимальную оценку. Чтобы это
делать быстро, вы используете очередь с минимумом. Вот. То есть как бы она здесь применяется как такое
скользящее окно в некотором плане. Она вот так вот скользит по всей вашей истории, забывает что-то
старое, запоминает что-то новое, что только что пришло, и при этом поддерживает все минимум быстро. Вот.
Вот как-то так. Ну, там, не знаю, допустим, у вас от этого минимума там что-нибудь зависит,
типа там вы рекомендуете это приложение или нет. Вот. Ну, понятное дело, что минимум здесь не очень
интересно брать. Вот. Там есть более такая классная штука как медианное сглаживание, но про нее мы поговорим,
когда изучим такое медианное деревье поиска, про похожий подход. Вот. А пока давайте перерыв. А последний
контейнер-адаптер это... Давайте я по-русски напишу. Мы ж по-русски сначала писали их. Это дек.
Ну, еще дек называют двусторонней очереди, но двусторонняя очередь это долго, поэтому это
просто дек. По-английски дек. Операция. Это набор из пушей, попов, бреков, пронтов, то есть во
все стороны. То есть вы умеете делать... Выбирайте любое слово отсюда. Любое слово отсюда он умеет. То есть он умеет делать
push-back, push-front, pop-back, pop-front. Ну, там front-back умеет делать. И size. Ну, внезапно, вау,
перед вами двусторонний список в гриме. А сразу нюанс. Давайте напишу здесь замечание. Есть такая штука,
как STD. Deque в плюсах. Он умеет делать очень интересную операцию, помимо всего этого. Он еще умеет
это вот наш дек, я назовем его, плюс индексация. За от единицы. Обычная. То есть умеете по индексу
брать элементы. Что? Ну, он так умеет. Как он реализован внутри, вы хотите узнать? Я не скажу.
Ну, я скажу так, что в первом приближении это кольцевой буфер внутри, но только в первом.
Там на самом деле все гораздо сложнее. Это кольцевой буфер страничек определенной направленности. А дальше,
что за этой фразой кроется, я оставлю вашим векторам по плюсам, которые это разберут где-нибудь во втором
семестре. Если не разберут, то скажите мне, я там напишу в чат, как это работает. Потому что все-таки
нам вот такая вот штука не понадобится. И обычно STD-дек используют как вот такой вот дек. То есть
индексация в нем требуется редко достаточно в практических применениях, но под любую задачу
можно придумать практически кейс, если очень сильно повоображать. Все. Прилинейные контейнеры
адаптера закончили. Прилинейные контейнеры у нас как бы остаются, но мы напишем заголовок 3. Это
амортизационный анализ. Собственно, вот ко мне подошел один человек во время перерыва и спросил,
что если мы делаем вот такую вот архитектуру в очереди на двух стэках, то почему это POP работает
за от единицы, если нам нужно вызвать shift в некоторой ситуации. А вызов shift это линия. Вопрос,
почему POP работает за от единицы. И скажу так, я не слухаю, потому что не говорю, что здесь работает
за от единицы, справедливости ради. Но мы сейчас будем с вами доказывать, что амортизированное время
это от единицы. Давайте определим, что такое амортизированное время. Определение. Пусть
с структурой данных. С структурой проводят операции
а1, аn. Где аи-то это какая-то операция типа push или pop в нашем случае. В общем случае там
больше операции, если такая-то другая структура. И практическое время работы
равно ты и тому соответственно. Вот. Ну ты и то это время выполнения операции аи-то. Ну аи-то операция,
и ты операции. Нет. Ну ладно, проехали. Вот тогда t звездочка равная
это амортизированное время. Время. Операции. Операции. Операции аи-то. Вот. Ну
мы будем чаще всего рассматривать когда у нас тип операции а1. Вот например здесь это всякие
в нашем случае где очередь на двух стэх это попа. Вот. Будем рассматривать время работы кучей попов.
То есть если я вызову n раз pop, то как бы сколько, какое у меня будет время? Вот. Да. Ну средне
рифметическое взял. То есть смотрите, здесь нам важно то, что мы переходим от одной операции конкретной,
вот физически конкретный вызов, ну там функции какой-то, да, к последовательности операции. Потому
что все-таки, как правило, вы совершаете последовательности операции на структуры и
принято усреднять, скажем так. Вот. И мы будем рассматривать с вами несколько методов, а именно
два. Как считать амортизационный анализ проводить. Вот. И мы будем рассматривать его на примере динамического
массива, а не очереди на двух стэках. Для очереди на двух стэках проведете на семинарии анализ.
Динамический массив-то все-таки большая классика. Ну и в целом для очереди на двух стэках применимо
следующее утверждение, что с каждым элементом за его время жизни, его push до его pop, может
случиться три вещи. Его запушили, его один раз перенесли и его pop-нули. Вы не можете переносить
один и тот же элемент кучу раз. Поэтому суммарно с ним совершается константное количество операций.
Вот. Какое вот заявление. Выводы делайте сами. Окей. А динамический массив. А в скобочках это
всеми любимый забавенный std-вектор. Будем обсуждать, как он внутри реализован,
именно что алгоритмически, не с точки зрения плюсов. Он делает следующее. Храним две переменных.
Храним, собственно, массив. Указатель на массив. Указатель на нулевый элемент.
То есть там int звездочка, короче говоря, он храним. Вот. Размер. Фактически. То есть сколько в нем
элементов находится сейчас. И capacity. По-русски вместимость. Емкость. Вместимость. Например,
когда вы делаете в коде, типа вы делаете массив на тысячу элементов, а дальше в него добавили только
один элемент, то его сайз это один, а capacity тысяча. И что происходит когда? Вот вы все пишете
прекрасно массивы в коде, потому что вы, когда алгоритмы решаете, потому что вы знаете максимальный
размер. Вы знаете, что у вас там больше десяти в пятый чисел не введут, например. Значит, понятно,
можно взять да и выделить на десять в пятый. Ну и победа. Это плохо. Плохая идея, потому что все-таки
в реальной жизни вы не знаете таких пределов. Вам лучше иметь что-то, что умеет там расширяться.
Автоматически причем. Поэтому в случае push. И сайз. Отпалась capacity. Когда у вас
массив заполнен. Что вы делаете? Вы говорите увеличим capacity в два раза. Ну каким образом?
Выделив новый массив и копируем в него старый. Понятное дело за от size.
Такая вот идея, что если у вас, ну давайте на примере. Допустим, изначально у нас массив,
на три элемента мы выделим. На два. Выделить там push 1, push 2. Получается единичка. Push от двойки.
Вы делаете двойку. Дальше push от тройки. Что происходит? Эта штука превращается в
массив два раза большего размера. То есть на четыре элемента. В него копируется единичка,
двоечка. И дальше вы в него уже делаете push как обычно. Идея понятна? Утверждается,
что если я делаю n push, то амортизированное время от единицы. Давайте это доказывать,
по определению мы этого не будем. Уж так никто не делает. Мы рассмотрим два метода, как такое
доказывают. Как оценивают амортизационное время. Ну да, амортизированное время. Почему амортизированное
вообще называется? Что такое амортизатор? Кто не знает? Здесь вы тоже как бы сглаживаете
эффекты тяжелых операций и как бы разносите их на более легкие. И первый метод. Давайте это.
У нас был пункт A, пункт B. Начнем с самого сложного для понимания, но самого практически
применимого. Метод потенциалов. Определение. Пусть phi, пусть s. Пусть s это структура данных.
s и t это ее состояние после операции дексировали с единицы. Не важно. После этой операции.
Операции. Тогда phi at s это потенциал, если и выполнено будет несколько свойств. Давайте подумаем,
первое свойство оно плюс-минус очевидное. phi at s0 равно 0. Мы заранее фиксируем точку отсчета,
что s0 это какое-то начальное состояние структуры данных. Мы будем верить, что это пустая структура
данных, например, пустой динамический массив. phi at s0 равно 0. Второй тезис. Для любого i phi at s и t больше
либо равно 0. Физики понимают, что это похоже на потенциальную энергию, что в любой момент энергия
не отрицательна и вы выбираете заранее себе нулевой уровень. Те, кто не физики, но физику в школе
проходили, тоже должны понимать. Ну, если не понимать, ничего страшного. Окей. Вроде бы это все.
Тогда я тестопотенциал, если определение. Сейчас. А время через потенциалы
и и т операции, это t и i t. Ну, давайте t phi его обозначим как-нибудь так.
phi i t. Вот так вот. То есть через потенциал phi в момент операции и, как оно вычисляется?
Давайте даже без phi вот. Так, t i t звездочка. Вот так вот будем обозначать. Это фактическое время операции плюс
phi at s i t минус phi at s i t минус 1.
Тогда я утверждаю, что вот такая вот, если я так буду складывать, то я получу верхнюю оценку на амортизированное время.
Вот если я через такие стоимости буду определять. Утверждение, что t звездочка,
которую мы там определяли, меньше либо равно, чем сумма t i t звездочка, деленная на n.
Давайте доказывать. Наказательство здесь. Доказывать будем на твой доске.
Давайте уберем эту штуку и докажем здесь. Что такое 1 деленное на n от суммы t i t звездочкой?
Что? Не-не-не, у нас t i t звездочка. Видите, как блядь, как t i t звездочка?
Ну сейчас посмотрим, что это такое. На сумму t i t плюс phi at s i t минус phi at s i t минус 1.
Я здесь введу индекс, чтобы было понятно. Вот так. Закрываем скобку. Дальше расписываем это. Что такое?
Закинем под одну дробь. Сумма t i t плюс сумма от i от 1 до n phi at s i t минус phi at s i t минус 1.
Вот они, по-моему, называются телескопический ряд. То есть какая у него сумма будет?
Все промежуточные склопнутся. Останется phi at s n, а здесь phi at s 0.
Phi at s 0 равно нулю. Согласны? Это ноль. Что равно t звездочка по определению просто на той доске,
сумма t i t делить на n. Это вот t звездочка. Плюс phi at s n поделенное на n.
Но phi at s n больше либо равно 0 всегда. Это свое второе свойство. Поэтому это больше либо равно, чем t звездочка.
Так эта штука больше 0. Доказали.
Тогда мы можем через такую интересную величину просто выводить амортизированную верхнюю цинку на амортизированное время.
Мы будем всегда считать, что у нас амортизированное время.
Мы будем просто так делать, что у нас все время было через о-большое амортизированное оценивание.
То есть у нас будет амортизированное время операции, как о-большое от чего-то.
Остается вопрос, как вести потенциал для динамического массива.
Пример. Пусть s это размер, c это вместимость.
Тогда введем phi at s как вот такую формулю. 2s-c. Удвойный размер минус вместимость.
С0 обозначим, что это пустой массив, который при пуше превращается в массив из одного элемента, дальше при пуше в массив из двух элементов, массив из четырех и так далее.
Идем по степьям двойки. Давайте распишем изменения потенциалов.
Рассмотрим, уж если s меньше c строго, если размер строго меньше к пассите. Что тогда?
Тогда давайте рассмотрим его время.
t и t звездочка равно t и t плюс phi at s и t минус phi от s и t минус 1.
Вот оно. То есть время через потенциал определяется вот так вот.
Что это фактическое время операции t и t плюс разность потенциалов, потраченная на изменение структуры.
Мы его просто так определили с бухты Барахта. Доказали, что определение корректно, что с помощью него мы можем получать верхнюю оценку на амортизированное время в среднем.
Просто амортизированное время.
Что происходит здесь? Если у нас размер строго меньше вместимости, значит у нас размер просто увеличится на один и больше ничего не происходит. Согласны?
Поэтому мы можем сказать, что здесь-то по сути структура вообще никак не меняется, мы просто описываем элемент.
Не знаю, давайте скажем, что это один, да?
Тогда t и t равно единичке.
Просто запись элемента.
Равно один плюс два равно три.
Еще раз понятно, почему здесь лойка берется?
Потому что у вас капасти не меняется и только размер увеличивается на единичку, а здесь как бы удвоенное просто.
Хорошо, то есть показали с вами, что у нас амортизированное время пуш, когда он не вызывает реаллокации, назовем это так.
Переводеление памяти или на прогерском реаллокация.
Здесь три, ну константа.
Хорошо, теперь пуш.
Если s равно равно c.
Ну давайте распишем фето с и то, да?
Это 2s минус c.
Не так.
Ну на момент этого пуша, ну ладно, пускай будет вот так вот, да?
Что у вас был размер s стало s плюс 1, вот так вот напишем.
Согласны?
До пуша у вас было вот такое вот.
Потому что у вас размер был s, на момент пуша он увеличился на единичку.
Ну здесь я думаю понятно, если вычислить одно из другого, получится двойка.
Потому что, смотрите, вот пример.
Давайте вот здесь вот я допишу, да?
Пуша 4.
У меня здесь не произойдет реаллокации.
У меня здесь не произойдет реаллокации, то есть мне не нужно будет выделять новый массив и копировать.
Все.
Мне достаточно будет сделать тот же самый абсолютно массив на 4 элемента,
просто дописать ему в конец четверку.
Поэтому переуделения памяти не происходят.
Да.
Ну, собственно, сложность метапотенциала в том, чтобы подобрать потенциал, вау.
Ну и показать, что он корректен.
Корректность мы чуть позже покажем.
Окей.
Пуша s и s равно равно c.
Тогда s и t минус первая имеет пару s и c.
То есть размер s, капасти c, да?
Тогда какое состояние у s и t будет?
Какой у нее будет размер?
s плюс 1, 2c.
Давайте посмотрим, фея от s и t минус 7, что такое?
Это просто 2s минус c.
И от s и t это дважды s плюс 1 минус 2c.
Вычтем, что мы получаем?
2s минус c минус дважды s плюс 1 минус 2c.
Смотрим.
Это 2s минус c минус 2s минус 2 плюс 2c.
Что равно уходит уходит c минус 2.
То есть у вас получается, что фея от s и t минус фея от s и t минус 1 равно 2 минус c.
Согласны?
Ну потому что я здесь вычитал просто наоборот.
Так получилось.
Поэтому здесь с минусом пошел.
Так, вопросов по этим вычтениям нет, я сейчас сотру.
Так, не волнуйтесь, мы сейчас буквально еще две минутки и мы закончим.
Это не проблема.
Ну смотрите.
Вот вы PMF, да?
Отлично.
Как изменилась потенциальная энергия этой штуки?
Ну вот.
Попросы?
А теперь рассмотрим эта звездочка, которая мы хотели с вами.
Таита и звездочка, да?
Таита здесь нам нужно потратить на то, чтобы внезапно что сделать?
Перекопировать n элементов.
Давайте будем искренне верить, что массив выделяется в золоть единицы длины 2с.
Ну иначе там просто будем чуть-чуть более по-другому перепишем потенциал.
Но я верю, что память выделяется в золоть единицы у нас.
Тогда Таита и звездочка, это что такое?
Это s, так как нам нужно s элементов скопировать.
У вас же s размер, да?
Плюс один элемент на то, чтобы дописать новый элемент, который вы запушили.
Логично, да?
Это вот Таита.
Ну, потому что здесь можно везде ошки навешивать, это правда.
Ну, давайте мы не будем их навешивать, просто так будет меньше писать, и это все еще корректно.
Потому что мы так просто определяем стоимости.
Здесь нам важно соблюсти не сколько константность соотношения, сколько порядка.
Но при этом константность тоже важна.
То есть если вы говорите, что в операции, которые выполняют два действия, я буду говорить, что это будто одно, это неправда.
Поэтому я все-таки...
Все-таки в амортизационном анализе, когда вы определяете именно вот эти вот Таиты,
вы же по сути что определяете?
Вы определяете ФИ и Таиты.
А дальше считаете просто.
Вот Таиты, они должны соотноситься с реальностью все-таки, так или иначе.
Причем чем точнее, тем лучше ваш амортизационный анализ.
Значит, можно прийти к неверным выборам.
Вот.
И плюс эта разница.
Плюс два, минус С.
Внимание, вопрос. Чему это равно?
Это равно 3.
Так как С равно равно С в нашем случае.
Видите, мы же рассматриваем ситуацию вот эту вот.
Это равно 3.
Тоже констант.
Все, мы показали, что амортизационное время от единицы.
Амортизированное время.
Даже для Пуши с реаллокацией.
Вот.
Математически все сошлось.
Есть еще один метод, который я, к сожалению, не успел рассказать.
Потому что мы на перерыве завержались.
Нам бы пяти минут хватило бы.
Ну окей. Не судьба.
Я напишу просто его название.
И на семинарах вы его разберете.
На этом же примере.
Я напишу здесь.
Замечание.
Есть еще.
Метод монеток.
Его называют методом бухучета.
Но.
Привычнее метод монеток.
Оба названия эквивалентны.
По-английски это будет
accounting methods.
А этот потенциал он через potentials метод.
Бухучета чуть проще для восприятия, с одной стороны.
Но у него есть проблема.
Потому что когда у вас амортизированное время внезапно не от единицы.
Там становится все очень-очень грустно.
Доказывать очень-очень сложно.
И там нужно будет больше передумывать гораздо.
В этом плане метод потенциалов оптимален,
когда вы доказываете,
что амортизированное время не от единицы.
Например, логариф амортизированный.
У нас, скорее всего, будет структура данных,
где будет возникать амортизированный логарифом.
Но, скорее всего, мы ее доказывать просто не будем.
Потому что иначе мы потратим на это поллегция.
Это сплей дерева называется такая штука.
Кто слышал, тот испугался.
Кто не слышал, тот тоже испугался.
Вот.
Так, вопросы.
О, да, это верный вопрос.
Так, все, тихо, не собираемся.
У вас перерыв 20 минут, я знаю.
Как доказывать корректность потенциала?
Мы должны с вами сказать,
что фет s0 равно 0.
Мы с вами определили s0 как пустой массив.
У него размер 0,
капасти 0, фет s0 равно 0.
Это правда, да?
И самое интересное.
Как доказывать, что потенциал корректен
с точки зрения второго требования?
Утверждается, что в любой момент времени
у вас массив хотя бы наполовину полон.
Вот есть наполовину пуст,
наполовину полон.
У нас оптимистичность для одной вещи.
Потому что мы потенциал уже подгадали.
Вот.
Если у нас размер,
то есть у нас в любой момент времени
s больше либо равно, чем c пополам.
Тогда 2s-c больше либо равно 0.
Собственно,
из этого наблюдения
внезапно формируется этот потенциал.
То есть можно сказать, что
действительно мы его подгадали
из ниоткуда с бухты-барахты.
Но обычно потенциал возникает
из физических ограничений задачи.
А именно, например, из такого,
что у вас есть вариант,
что s больше либо равно c пополам.
Поэтому просто переносите это
Вот.
Подождите.
Про уменьшение я еще ничего не говорю.
Стандартный STD-вектор
он не делает уменьшений.
На семинаре у вас будет задача
придумать, какой потенциал нужно сделать,
чтобы у вас еще при уменьшениях все работало.
И как это делать.
Вот.
Ну там будет модуля 2s-c потенциал.
Ну я, скажем так, точно скажу
семинаристам, чтобы они
понимали, что происходит.
Вот.
Если вопросов больше нет, то все.
