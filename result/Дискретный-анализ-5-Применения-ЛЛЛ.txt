Давайте я все-таки правда попробую продемонстрировать, почему такой вот косой, скажем так, несимметричной
вообще говоря форме теорема тоже очень полезна.
Я напомню такую историю.
Давно знаем, что r от 1t равно единице, r от 2t равно t, а дальше я шутку спросил, как вы думаете,
чему равняется r от 3, запятая t, то есть когда мы ищем треугольник или независимое множество на t
вершин. Так, что такое r от 3t, все понимают, да, то есть либо в графе есть треугольник,
либо в графе есть независимое множество на t вершины. Минимальный n такой, что в любом графе
либо то, либо то, это вот эта величина. Ну, что мы с вами знаем? Мы, конечно, с вами знаем общую
оценку, вот такую, c из t плюс 3 минус 2 по t минус 1, ну или по 3 минус 1, наверное лучше
будем сказать по 3 минус 1. Вот такую общую оценку, c из s плюс t минус 2 по s минус 1,
или по t минус 1, все равно. Вот это у нас такое получается, c из t плюс 1 по 2, ну то есть t на t
плюс 1 попал. Такую оценку мы знаем, в частности, если t равняется 3, то 3 до 4 пополам, это как раз 6,
то есть эта верхняя оценка совпадает с нижней. Вот вся история про число Рамсе, она начиналась
с того, что r3 и 3 равно 6, но это вот оценка, которая для случая t равного тройки прям вот дает
правильный результат, но из этого, конечно, не следует, что она всегда будет давать правильный
результат. Например, может быть вы уже считали на семинарах вот такую величину, или на семинарах
пока нет Рамсе. Чего получилось? 9 получилось, да. Ну а оценка, которую мы знаем, она какая
получается? Мы подставляем сюда четверку, получаем 4 х 5 пополам, и это уже 10. Явно,
что вот эта оценка не является, она для t равного тройки достигается, а для t равного четверки,
может быть, на единичку лучше. Ну, где на единичку, там дальше, может быть, если 4 х 5, то и на 2,
и на 3, а может быть и очень существенно. Ну, давайте я вам так скажу. Без доказательства теорема,
которая сейчас самая лучшая известная, это утверждение о том, что R3t не превосходит такой
величины 1 плюс умалые от единицы на t квадрат логарифом t. То есть вот где-то на единичку просто в
минус, а реально надо делить на логарифе, причем там еще точно сюда симптотика. Это вот самая
лучшая верхняя оценка, которая сейчас известна, это какой-то, я не путаю, 81 год публикации. То есть
вот уже прошло больше 40 лет, никаких улучшений этой оценки никто не придумал. Так, давайте попробуем
соорудить какую-нибудь оценку снизу, какую-нибудь. Ну, каковая она, это пока не понятно. Пользуясь
локальной леммой-ловосом, той теоремой, которую я напомнил в углу, в том углу.
Как воспользоваться той теоремой? Ну чего, давайте рассмотрим, как водится случайный граф.
На n вершинах. Ну, где мы знаем пока что величину n, мы хотим получить оценку какой-то величиной n.
Вот давайте рассмотрим случайный граф на n вершинах, где пока что переменная, которую нам
предстоит оптимизировать, выбрать как можно больше, чтобы оценка получилась как можно лучше. Вот пока
рассмотрим случайный граф на n вершинах, но мы же всегда так делаем. Формально ничего нового нет.
Чего мы хотим добиться? Мы хотим, чтобы положительной вероятностью, положительной
вероятностью в этом графе, ну в этом смысле, в случайном графе, в этом графе не было ни треугольников,
ни независимых множеств, множеств на t вершину. Я бы сказал так, матанализ потихонечку отдает,
выплевывает, так сказать, из своего чрева слушателей. Друзья, вот вы согласны, что мы хотим вот это?
Или не очень понятно? Мы хотим доказать, что r от 3 запитает t больше, чем n. То есть, что существует
граф на n вершинах, в котором отсутствуют треугольники и независимое множество мощности t. Ну, если мы
докажем, что это выполнено с положительной вероятностью, то, конечно, такой граф будет
существовать. Вроде это стандартная идея, которая у нас красной нитью идет через весь вообще год,
покуда мы используем когда-либо там какие-то вероятностные методы. Хотим доказать. И смотрите,
вот я намеренно не написал обозначение случайного графа. Я сказал, просто рассмотрим случайный
граф на n вершинах. Понимаете, что я этим ведь не конкретизировал, какое распределение вероятностей
будет на множестве графов? Или вы подумали, что вероятность ребра я по умолчанию считаю равной
одной второй? Понимаете, когда мы работали с диагональными числами рамсе, очень естественно
было считать, что ребро и антиребро проводятся с одной и той же вероятностью, потому что размер
независимого множества и размер клики, которые мы хотели в итоге исключить, они одинаковы.
Ну, наверное, нам хотелось добиться того, чтобы вероятность исключения клики на s вершинах была
такой же, как вероятность исключения независимого множества на t вершинах. А тут-то перекос колоссанен.
Тут надо, чтобы и треугольники пропали, это маленькие такие клыки, и может быть очень
большие независимые множества на 1000 вершинах. Я понятно? По-моему, совершенно ясно, что не надо
здесь брать одну-вторую. А что брать? Какое-то плэн, да? Вот-вот-вот, то есть надо написать,
а потом подогнать. Только не мат ожидания. Мат ожидания-то мы напишем, но это будет простой
вероятностный метод. А мы хотим применить локальную лему лову. Нет мат ожидания, там надо вот эти вероятности.
Друзья, ну хорошо, поэтому давайте обозначим просто p вероятность ребра.
Какое она окажется в оптимальном случае неясно совершенно, и вообще в чем состоит
будущая оптимизация, мы пока, конечно, не понимаем. Но скоро поймем. Я не знаю, я понятно,
здесь нормально? Так, p вероятность ребра. Какие бытия нам вредят? Давайте вот так обозначим.
Ну что, ладно, попробую в этом году вот так обозначить.
У нас будет как бы две группы событий. Одна группа отличает наличию треугольника того или иного,
а другая группа отличает наличию того или иного независимого множества. То есть БИТ, это что ИТ и
треугольник ходят, случайно играющая от NP является под графом в нем. Ну что значит ИТ,
я думаю понятно. Мы их как угодно перенумируем, просто от 1 до c из анпот. Все тройки вершины.
Просто все тройки вершин пронумируем, и БИТ это событие, состоящее в том, что ИТ-тройка
образует треугольник в случайном графе. ИТ по счету тройка образует треугольник в случайном
графе. И точно также ДИТ. Это значит, что ИТ-независимое множество. Ну или сказать,
вот как я сказал, что ИТ по счету множества вершин образует независимое множество. То есть
там все ребра отсутствуют вот в этом случайном графе. То есть вот что значит, мы хотим,
чтобы с положительной вероятностью в этом было не треугольников, не независимых множеств. Вот это
все равносильно тому, что вероятность пересечения по И от 1 до c из анпот БИТ чертой, пересечением
по И от 1 до c из анпот БИТ с чертой больше нуля. Мы хотим, чтобы эта вероятность была больше нуля.
Ни одной из этих вредных событий не выполняется. Они вредные в том смысле, что они вредят
реализации нашей цели. Наша цель, чтобы не было ни треугольников, ни независимых множеств. А события
говорят, что у них какие-то конкретные треугольники, какие-то конкретные независимые множества. Кстати,
вы поняли, да, почему я использовал буквы B и D. Но я не использовал букву C, потому что писать C
с индексом C из анпот это издевательство. А я не использовал букву А, потому что в локальной
лемму ловоса буква А обозначает события. Я хочу сказать, что мы же применим вот для вот этого неравенства
локальную лемму ловоса. В ней сколько-то событий, и они все обозначены буквами А. Вот если хотите,
у нас сейчас события А1, АС из анпо 3, АС из анпо 3 плюс 1 и так далее, АС из анпо 3
плюс Т из анпо Т. Вот, ну так, переобозначить, чтобы попасть прямо в условия локальной леммы ловоса.
Вот просто первые буквы А совпадают с буквами B, а последние буквы А совпадают с буквами D. Вот
этим объясняется система обозначения. Ну я думаю, это занудство, это понятно. Так,
ну чего нам нужно? Нам нужно проверить, что вероятность вот этих аитов, которые могут быть
бейтами, могут быть дейтами и превосходить вот такие стуки. Ну а что значит проверить? На самом
деле не проверить, а наложить ограничения вот на это P и вот на это N. То есть неравенства,
которые присутствуют в утверждении теоремы, они как раз и будут накладывать ограничения на P и на N.
Но смотрите, вероятность бейтова чему равна? Я хочу услышать от вас, чтобы вас понимать,
как вы действительно воспринимаете, что происходит. Чему равна вероятность B?
P куб правильно, что три ребра присутствуют одновременно, что вот эти три вершины конкретно
образуют треугольник в случайном градусе с вероятностью ребра P. Ну P куб, конечно.
Соответственно, вероятность дейтова это 1 минус P в тепени C и СТ подма. Согласны?
Так, вероятности-то мы нашли, но нам еще надо построить орграф зависимости.
Глядите, на условии локальный лем. Орграф зависимости надо поставить?
Ну, дайте я вот так нарисую. B1 и так далее. B с индексом C и N по 3. D1 и так далее. D с индексом
C и N по T. А стрелки я буду рисовать, как на прошлой лекции, когда из общей теоремы симметричной выводили.
Будут стрелки внутри вот этой доли, будут стрелки внутри вот этой доли,
будут стрелки в эту сторону и будут стрелки в эту сторону. Стрелки и так далее. События, от которого данное зависит.
Сейчас, друзья, это понятно? Мы подняв срок и расстреливаем те события, от которых данное зависит.
Направляем 2 стрелки. Чтобы от оставшихся, куда эти стрелки не направлены, как и того и требует
определение, была совокупная независимость. Так, ну давайте вот так вот обозначим. Сейчас как-нибудь
вот это вот количество. В математике часто вот этой решеточкой, музыкальным диезом, обозначают или
шарпом, если хотите, обозначают количество почему-то. Ну, вот так принято. Модулем, конечно, мы обозначаем,
но вот иногда этим шарпом тоже пользуются. Я вот так вот нарисую Б-итое стрелочка Б-житое.
Ну, то есть это количество стрелок, которые из Б-итое в Б-житое любят. От какого количества событий
типа В зависит данное событие типа В. Не знаю, я понятно говорю. Событие типа В состоит в том, что присутствует
конкретный треугольник. Вот есть конкретные три вершины, и что вот этот треугольник находится в
графе, то есть все три ребра проведены, это какое-то конкретное событие Б-итое. От каких событий
такого же типа, то есть событий, следуя на существующих о наличии треугольника, зависит Б-итое?
Пересекающихся по двум вершинам. Совершенно верно, товарищи. Ну, короче, я могу прям вот это посчитать,
сколько их будет? 3 на n-3. Две общих вершины выбираются тремя способами, и оставшиеся еще n-3.
Ну, аналогично я обозначу Б-итое в Д-житое, аналогично я обозначу Д-итое в Д-житое,
и Д-итое в Б-житое. Я не буду уже считать эти величины, они все, конечно, легко считают,
и там пишут какие-то явные формулы, которые зависят от n и от t. То есть вот эти все шарпые диезы,
все они являются функциями от n и t. Здесь t нету, потому что мы треугольник с треугольником пересекаем,
треугольник пересекаем независимым множеством на t-вершину, поэтому эта функция будет еще и от t зависима.
Но не важно. Осталось написать условия. Вот это условие.
Еще один момент, который хотелось бы обсудить с вами, прежде чем явно писать условия.
Ну, у нас событие двух типов, то есть с одной стороны будет П в клубе оцениваться чем-то,
а с другой стороны, вот там написано 1 минус П в степени ЦСТ подвоха, будет тоже чем-то оцениваться.
Ну, друзья, я надеюсь, понятно, что реально вот среди этих типов К1хсн надо взять две группы совпадающих чисел.
Одна группа совпадающих чисел будет отвечать оценке вероятности B этого, то есть П в клубе,
а другая группа совпадающих чисел будет отвечать оценке D этого, вероятности D этого.
Получается, какая-то система не превосходит. Вот те числа, которые участвуют в этой оценке,
то есть которые соответствуют событиям B, а у будет отвечать событиям D. Вот смотрите,
х-то понятно, что тут написано х, а вот тут в этом произведении что будет? Понимаете,
тут будет произведение числа К1-х и 1-у тоже. Так, ну хорошо, если успеваете,
1-х сколько раз перемножается? Сколько? Ну, 3н-3, да, ну давайте я уже диезом просто обозмать.
Правильно, да. А 1-у это садьба. Вот это понятно почему-то. Но нам нужно, чтобы аито и ожито
образовывало стрелку, направленную в сторону ожитого, да, которая действительно
предлежит множеству рюм. Образовывало стрелку, направленную в сторону ожитого.
Если битое и божитое это аитое ожитое, тогда таких стрелок столько, а если это битое дожитое,
тогда их столько, но перемножаются уже числа 1-у, потому что у отвечает дожитое.
Вот так, 1-п в степени ц и ст по 2 не предпочитает интегрект, на 1-х в степени вот тут будет 100.
Решетка. Боитое, сейчас, нет, дожитое боитое, да, но это важно. Доитое божитое. Ну неважно,
какие тут буквы написать, конечно, ну уж я так обозначил. Вот, а 1-у соответственно будет в степени
дитое дожитое. Ну жуть, признаю, жуть, конечно. То есть как звучит теорема теперь. Вот мы получили
теорему про оценку числа рамсея снизу. Это теорема, вот я опять забыл, какие я со штрихом писал,
какие без штриха. По-моему без штриха я как раз писал теорему как вот та, которая сейчас у нас
получилась. Ну то есть то, что я называл быдло кодингу, надо сделать какой-то жуткий перебор и
тогда вы найдете какую-то оценку. Ну пусть будет она без штриха, потому что я все равно забыл.
Значит, теорема звучит так. Пусть для данного t число n таково,
что найдутся phase 0,1, а также x, y из полуинтервала, такие что, вжик,
все это вместе удовлетворяет системе. Тогда, как следствие из локальной леммелова,
вероятность нашего пересечения больше нуля, а это как мы знаем означает, что r3t больше чем n.
Пусть для данного, куда бы это написать? Вот сюда, да? А, ну сюда. Ладно, это уже сотрем.
Тогда? Ну давай уходи. Ну то есть нам дано число t на вход, мы делаем цикл по n и на каждом шаге
этого цикла, на каждый итератор. По ужас решаем вот эту систему относительно n, p, x, y. Ну как решаем?
Просто пробегаем с каким-то маленьким шагом по всем p из 0,1 и по всем x, y из 0,1. Перебор, конечно,
блядский совершенно, ну просто потому что если вы сделаете шаг 1 тысячное везде хотя бы, а у вас
три параметра, то это уже будет миллиардный перебор для каждого n. Но тем не менее, это вполне себе
алгоритм, пусть и тупой и глупый, но это алгоритм получения некоторой нижней оценки. Вот его важно,
чтобы вы понимали. Следствие отсюда, которое у нас обычно формулировалось как теорема штрих,
видимо, ну неважно, можно сказать следствие из теоремы, это асимпатический результат. Я не буду
вас мучить выкладками, но я вам сообщу удивительную вещь. Математики способны решать
вот эти языки. Посчитать вот эти вот все языки и решить асимпатически относительно n, p, x, y. То
есть написать все вот эти n, p, x, y как функция t, чтобы они удовлетворяли вот этому вот этой
системе неравен. Теорема штрих говорит, что r от 3t больше либо равняется 1+, умножить на t квадрат
и поделить на логарифм квадратный. Но тут есть два варианта. Либо вы сами напрягаетесь и умудряетесь
решить эту систему, если хотите проверить, что это правда. Но я же вам подсказал в качестве n,
ой нет, 1+, это я хватил. Это я хватил. Сейчас перепишу, это я хватил. Существует c больше 0 такое,
что r от 3t больше либо равняется t квадрат на логарифм квадрате. Какое c там, это закопаешься,
это даже я не понял. Ну, конечно, да, т и c такое, что оценка т такая. Конечно, одно для всех t,
это не функция от t, все это константа. Ну, функция она постоянная. По t она постоянная, это важно. Ну,
то есть смотрите, верхняя оценка статистически просто t квадрат на лог t, а нижняя оценка с
точностью до константа тоже самый t квадрат, но лог t в квадрате. Чуть-чуть они не сходятся,
но уже очень близко. Ну, а про два варианта я говорил, либо вы пытаетесь на компьютере уловить вот
эту зависимость, но это сдох, все это программировать, наверное, вам не очень интересно, либо вы пытаетесь
действительно подобрать функции. Одну я вам подсказал, вот она ищется в таком виде, функция n,
вот n сюда такое подставляет. Надо каким-то образом либо подобрать, либо угадать функции p,
x, y тоже, как они зависит от t, чтобы при таком вот n все вот эти два неравенства бы неравенство выполняли.
Ну, друзья, это теория без доказательств. Я и не буду спрашивать, конечно, экзамены. Я однажды
попытался рассказать, это заняло лекцию, все выигрыши. Но это совершенно никому не нужно,
конечно, то есть такие асимптотики решать, но это только специалистов, зачем учить тракурсников.
Главное, чтобы идея была понятна, следствие придется либо поверить,
либо если вам хочется стать специалистами, тогда уже искать какую-то проверку. В принципе,
это можно прочитать в книгах. Например, есть книга Алоны Спенсер «Вероятностный метод»,
она даже на русском языке есть. Там написаны просто эти функции. Можете попробовать хотя бы
даже подставить их, это уже не так просто. Понимаете, вот в это произведение подставить
какие-то конкретные функции от t и проверить, что все получается уже непросто. А догадаться,
да, эти функции, но это как бы отдельные искусства. Вот, ну и еще одна теорема,
без доказательства, конечно, как я уже сказал, и еще одна теорема без доказательства,
это текущий рекорд. Просто вам сообщу, что сейчас известна вот такое неравенство.
1 четверть плюс 1 единиц на t квадрат просто на логарифу t. То есть на самом деле можно
улучшить дальше и дожать почти до верхней оценки. Верхняя оценка примерно 1 умножить на t квадрат
лог t, а здесь примерно 1 четверть. То есть сейчас вот между двумя известными оценками сверху и
снизу. Если не брать вот эти асимпатические составляющие, то уже там изыск, зазор в 4 раза.
Не могу сейчас лекцию читать. Вот, это проект. Но вы поняли заодно, что действительно в общем,
вот эта теорема важна. Давайте получим еще пару следствий симметричного куча,
которые тоже полезны и нет в теории Рамсте, чтобы максимально прониклись величиям локальной
леммы Ловоса. Не знаю, на семинарах кто-то уже делался? Не было еще, но будет, будет. Вот
лемма Ловос точно будет на семинарах. Там много хороших задач придумано. Многие жалуются,
оправдано, что у нас семинары сильно рассинкронизированы в этом курсе лекциями.
Объясняется это тем, что в лекциях много теоретического материала, по которому ты просто в
принципе не сделаешь задачи. Поэтому курс получается дополнительно перегруженным тем,
что в семинарах разбираются какие-то вещи, которых на лекциях даже нет. Это я все понимаю,
да, но вот локальную лему точно снабдили очень хорошими задачками, и вы увидите, насколько это
полезно в разных совершенно вопросах комбинаторики. Но я вот сейчас тоже приведу
еще парочку примеров по поводу того, как можно использовать локальную лему. А знаете,
как я сейчас сделаю? Я сейчас формулирую симметричный случай, потому что несимметричный
больше нам не понадобится. Ну ладно, пока сотру, посмотрим. Надо стирать.
Ждем чуть-чуть, она подсохнет быстро. Что мы знаем, для любого И вероятность аитов не больше,
чем П для любого И, а это и не зависит ото всех остальных
Так, и мы знаем, Е на П на D плюс 1 не превосходит 1, тогда вероятность пересечения отрицаний больше
0. Вот так. Ой, куда пошел? Мел скакал. Я его перехватил. Так, друзья, не умирайте,
я напомнил теорему, из которой мы сейчас получим какие-то следствия. Новые, отличающиеся от
Рамсеевских, хотя тоже относятся к раскраскам. Ну, кстати, я так сейчас рассказываю про Рамсея,
что я думаю, многие могут даже до конца и не осознавать причем тут раскраски. Я где-то в самом
начале сказал, ну взять граф и его дополнение, это все равно, чтобы покрасить ребра полного графа,
красные и синие цвета, но там красится ребра, а мы сейчас будем красить вершины. Причем не у графа,
а у гиперграфа. Ну, что такое гиперграф, товарищи, вы же помните? Помните, у нас была
замечательная задачка про 15 подмножистых? Она была в первом семестре ОКТЧ на первой версии.
Ну, на первой моей, конечно, конечно, шестой. Я имею в виду, на моей первой лекции была это занято.
Понятно, что ОКТЧ снаряжает Мусатов, но вот на моей первой лекции была задачка про 15 подмножистых.
А потом, с помощью матрицы Адамара, мы с ними еще что-то делали. Ну, конечно, вы подзабыли. Я чуть
позже, когда мы вернемся к этой истории так полноценно, напомню, в чем там все дело было,
но вот то, что я сейчас сформулирую, имеет отношение к этой истории тоже. Теорема,
которую можно вывести отсюда, звучит следующим образом. Пусть H это N-однородный гиперграф,
причем
степень каждой его вершины
не больше, чем N. То же самое.
Тогда
хиатаж равняется 2.
Так, у меня есть некоторое смутное подозрение, что, может быть, я не давал определение
хроматического числа гиперграфа. Так и есть. Ну, давайте, что такое хроматическое число графа?
Мы красим вершины и добиваемся того, что концы каждого ребра имеют разные цвета.
Можно бы и так, но нет, тут просто будут неодноцветные. Я буду требовать,
чтобы каждое ребро было неодноцветным. Минимальное число цветов, такой покраски
множества вершин, при которой каждое ребро неодноцветно. То есть цветов, может быть,
вы используете 10 штук, но важно, чтобы в каждом ребре присутствовали хотя бы два разных из этих
десяти. В одном ребре может потребуется красный и синий, в другом синий и зеленый, там еще какие-то,
не обязательно все 10. И тем более, не обязательно, чтобы все вершины ребра были разного цвета. Вот
этого мы не требуем. Мы требуем только, чтобы каждое ребро было неодноцветным. И давайте я все-таки
напомню задачку про 15 подмножек, чтобы вы понимали, что это точно то же самое. Задача была такая,
там было 30 школьников и мы из них, а может я не говорил слово школьник, ну неважно, было 30 просто
элементов и из них составляли 15 подмножек мощности 5. Вспоминается? 30 элементов и из них
выбирались 15 подмножек мощности 5 каждой. Сейчас я напомню, потом устроим перерыв. 15 подмножек
каждой мощности 5. И вопрос был такой, можно ли разбить множество исходных 30 элементов на две части?
А может я и раз красить говорил, я уже не помню, я всегда по-разному говорю. Так, чтобы каждое
множество из пяти элементов попадало и туда и туда. Так я говорил. Ну согласитесь, это то,
что покрасить 30 чисел в два цвета так, чтобы каждое множество оказалось не одноцветным,
каждые пятерки. Ну то есть там речь шла про то, что если мы возьмем 5 однородный гиперграф,
без каких-то условий на степени вершины простым, 5 однородный гиперграф, то он вот в этом смысле
действительно двудолен, красится в два цвета. Кстати, все понимают, что красится в два цвета и
двудолен – это синонима. Но вот для гиперграфа, естественно, тоже говоришь, он как бы двудолен.
Есть вершина одного цвета, есть вершина другого цвета, и ребра они вот так вот нетривиально
пересекаются с каждым из этих множеств. Вот, значит, смотрите еще раз, задачка из ОКТЧ утверждает,
что если этих множеств не больше 15 штук, то они действительно красятся. А здесь говорится,
неважно сколько множеств, смотрите, нет никакого ограничения на их количество. Но если добавить
условия на степень каждой вершины, то есть что каждый элемент принадлежит не более чем n множества,
то получается все равно красить в два цвета. Я надеюсь, вы при этом понимаете, что вот это условие
не является ограничителем для количества ребр. Ребр у гиперграфа может сколь угодно много при
этом условии. Каждая вершина содержится не более чем в n ребрах. Ну елки-палки, ну возьмите вот
такие сардельки и до бесконечности раскладывайте каждая мощность стен. Каждая вершина содержится
не больше чем в n ребрах, конечно, в одном только, не больше же чем в n. Ребер может быть сколь угодно
много, все равно красятся в два цвета, если вот есть такое условие. Все, я давайте бы оказывать
эту теорему, она не сложная как раз. А, ой, кстати, никто не нашел контрпример.
О, и относится к тому, что теорема не верна. Теорема верна. Не, но если бы одна вершина была
в ребре, то вообще непонятно, как его раскрашивать неодноцветным образом. То есть, конечно, n больше
либо равняется двойке, это понятно. Вот, но ведь и для графа это же неправда, товарищи. Не, но возьмите
треугольник, у него этот два однородный, два регулярный граф. Гиперграф. Треугольник. У него
степень каждой вершины двойка и вершин в каждом ребре двойка. Неверное утверждение. Конечно,
надо написать, что n больше либо равно 9. Конечно, это относится к тому, что, ну, просто я забыл
написать, а почему именно 9 вы увидите. Ну, то есть, для двойки это, конечно, неверно. Оказывается,
что если гиперграф довольно жирный, в смысле, количество вершин в каждом ребре, тогда уже это
так. Так, ну хорошо, доказательства. Давайте, как водится, рассмотрим. Ну, во-первых,
рассмотрим какой-то гиперграф конкретный с этими свойствами и будем красить его случайным образом.
Красим каждую вершину с вероятностью одна вторая красный цвет условный и с вероятностью
вторая синий цвет. Естественно, покраска вершин устроена независимо по всему множеству вершин.
За имя независимо, по всему множеству вершин. Такая банальная случайная раскраска. Ну а что,
тут все действительно, в общем, симметрично. И лемму будет симметрично. Заметьте, что мы не
знаем, сколько у нас вершин. Товарищи, вы понимаете, что мы не знаем, сколько у нас вершин. Вот в
задачке из ОКТЧ мы знали, что их 30, но это на самом деле неважно. Вот сколько вершин не имеет
никакого значения. Сколько бы их ни было, конечное число мы красим каждую с вероятностью одна вторая,
так всяко. Бросаем маникю и все. Так, ну давайте ребра как-нибудь обозначим, скажем, А1.
Но ребр тоже непонятно, сколько. Беда. Ну давайте как-нибудь А1, АМ, чтобы не путать с буквой N.
Вот это ребра гиперграф А.
Все ребра гиперграфа. Мы не знаем,
не сколько вершин, не сколько ребр у нас никто не ограничен. Ну обозначим просто
буквой М, количество ребр, соответственно сами ребра это А1 на М. Так, и давайте красивыми
буквами обозначать событие. АИТ, событие, состоящее в том,
что АИТ прямое такое вот, подсветно в нашей случайной раскраске.
Так, ну друзья, случайная раскраска, поэтому событие это множество раскрасок,
а гиперграф у нас фиксирован, произвольный совершенно, лишь бы он обладал вот указанными
свойствами. Так, тривиальный вопрос, на который очень хотелось бы получить ответ от аудитории,
чему равняется вероятность АИТ? АИТ-го красивого. Если оно такое печально наклоненное, оно все равно красиво.
Но не совсем. 2 поделить на 2 в степени N. Ну либо оно все красное, либо оно все синий.
2 поделить на 2 в N или можно написать 2 в степени 1 минус N.
Вот смотрите, если бы мы пользовались нелокальной леммой, то мы пришли бы
фактически к результату задачки из ОКТЧ. А именно, чтобы написали вероятность объединения
АИТ-го по I от 1 до M, то, что я сейчас пишу, это не продолжение доказательства, а попытка объяснить,
почему доказательство крутое, почему нелокальная лемма лучше. Сейчас давайте вот посмотрим. Вот если бы
мы бы вот это оценили просто как M умножить на 2 в степени 1 минус N. Правильно? М, стопайте,
каждый имеет вероятность 2 в степени 1 минус N. Вероятность объединения не больше, чем сумма.
Но мы бы хотели получить, что это меньше единицы. Откуда мы получили бы, что M должно быть меньше,
чем 2 в степени N минус 1? При N-раутом пятерке, как на ОКТЧ было, помните, 5-и элементные
подмножства, это 2 в четвертые, M меньше 16, ну как раз 15. Поминается, да? То есть вот 15 пролезло ровно из-за того,
чтобы уметь изюмиться. Это тоже пролезет, тут на самом деле строго меньше. Ну а дальше уже как бы непонятно.
То есть из банального рассуждения следовало бы ограничение числа рёбер величиной 2 в M минус первой
степени. Но у нас нет никакого ограничения числа рёбер в этой теореме. В этом отличие, мощнейшее отличие того
метода, который дает локальная лемма-ловос. Негарара деломыш на корень из двойки в очередной раз умножили,
как числа хромсе. А нечто действительно крутое. Так, ну ладно, как вот это вот зачеркиваем,
это то, что мы делали на первой лекции по КТЧ. Возвращаем сюда, значит вот это вот, это П. П из локальной
леммы, которая оценивает рост каждого события. То такое D, товарищи, вот это самое интересное. Вот у
нас есть сарделька. Это какое-то ребро АИТ, состоящее из N элементов, из N вертыл. Есть какое-то ребро.
Вопрос на самом деле, давайте обсудим.
Но случиться с другим ребром ожитое, оно должно взаимодействовать с этим АИТом,
чтобы войти на конец. Ну если ожитое вообще не пересекается с АИТом,
будут соответствующие А красивое ИТ, а красивое ЖТ зависимо. По-моему очевидно,
что они будут. Ну здесь мы красим, здесь мы красим. Это может повлиять на это, да? Никак. Но
можете посчитать. Вероятность пересечения, конечно, будет равна произведению вероятности.
Смотрите, другая картинка. Вот А прямое ИТ, вот одна общая вершина, вот А прямое ЖТ. Друзья,
вдумайтесь, это прям такой хороший пример на зависимости и вероятности. Теория вероятности,
прям хороший пример. Если они по одному. Ну кажется, что влияет, потому что если мы знаем,
что, например, АИТ целиком красное, то ожитое может быть одного цвета, только если оно тоже
целиком красное. Казалось бы, влияет, да? Нет, не влияет, правильно, потому что все равно
вероятность пересечения произведения вероятности. Посчитать или понятно?
Ну, из общих соображений так, да. Можно посчитать просто явно и убедиться в том,
что произведение сойдется. Ну, видимо, уже считать не надо, потому что вроде интуицию какую-то
создали или надо. Считать? Нет, ну, вероятность, произведение вероятности это 2 в степени 2-2n,
да? Ну, просто квадрат, вот эти величины. А вероятность пересечения как считается? Ну,
либо оба красные, либо оба синие. То есть, есть два варианта. Ну, а вероятность того,
что все вершины красные, это 1-2 в какой степени? 2n-1. Тут 2n-1. Ну, и такая же вероятность того,
что они все синие. Два варианта. Все красные, все синие. Ну, и вероятность вот такая. Это точно
вот это. Ну, понятно, что если два множества пересекаются по двум вершинам, то зависимость
появляется просто вот из того же расчета. Это видно сразу. Но, смотрите, друзья, тут есть тонкий
момент. Когда мы смотрим на локальную лему ловоса, мы говорим, что аито не зависит от совокупности
всех остальных событий. Я что хочу сказать? Я хочу сказать, что если вы нарисуете какую-нибудь
вот такую картинку, например, тут одна общая, тут одна, тут одна. Вроде они попарно независимые,
как мы только что неожиданно для себя выяснили, но кому-то это было понятно. Да? Попарно же
независимые, они пересекаются только по одной вершине каждые два. А вот в совокупности они
окажутся зависимыми. Поэтому даже по одной вершине пересекать плохо.
Поэтому я хочу сказать, что D, которая фигурирует в теореме локальной леммы ловоса, нужно
оценивать сверху количеством таких множеств, которые с данным пересекаются хотя бы по одной
вершине все-таки. Даже по одной может быть плохо из-за наличия вот таких вот картин.
Я понятно объясню? Чтобы вы не питали иллюзий, что я там что-то огрубил. Нет,
я ничего не огрубляю. Но давайте посчитаем, сколько вот если дана какая-то сарделька из
n-чисел, сколько в нашем гиперграфе других сарделек может с ней пересекаться хоть как-нибудь?
Ну, могут пересекаться по первой вершине. Только таких. Ну, смотрите, на условии степени-то
каждой вершины не больше, чем n. Значит, других сарделек, отличных адаптированных, которые
пересекаются с ней вот по этой вершине, их не больше n-1 штуки. Таких, которые по этой пересекаются,
тоже не больше n-1. И по этой не больше n-1. Ну, значит, суммарно получаем не больше,
чем вот столько. Это вот здесь надо писать. Не больше, чем вот столько. Сейчас я понятно объясню?
Вроде это просто. Вот, тогда мы пишем e умножить на а где она, куда она делась. На 2 в степени 1
минус n. Это вероятность каждого события. Умножить на n, n-1 плюс 1 не превосходит 1. Вот если это
неравенство выполнено, тогда все. Тогда гиперграф действительно красятся в два цвета. Потому что
вероятность пересечения отрица не больше нуля, как следствие из локальной лиммы Лоос. Ну и вот это
вот как раз условие на n. Отсюда получается, что n должно быть больше либо равно 9. Смотрите,
n равно 9. Получается e на 2 в минус 8 на 73. 2 в минус 8 это 1,250. Вот так получается.
Поделить на 256. Это уже меньше единицы. А если вы сюда подставите 8, то получится e на 2 там на одну
128 уже на 2 в минус 7. Тут будет 57. Но в общем 57 e еще больше, чем 128. Это больше единицы. И
для 8 такой метод просто не проходит. Ну люди думали об этом. Вроде бы доказали,
что начиная с пятерки можно вот дать то же самое, но использовать приходится уже не локальную лимму,
а что-то более продвижимое. Что, я неправильно посчитал? Ну e это почти 3. Ну 3 на 57 это 170.
Не, может вы подумали, что e это почти 2. Дважды 57, но тоже почти 128-140. Так что да,
метод не проходит, но на самом деле для пятерки вроде научились до 5. А для четверки
по-моему есть контрпремеры. Я сейчас их не воспроизведу. Ну для двойки вот очевидно,
для тройки вроде тоже простой, а для четверки я не помню. Так, и некоторое обобщение давайте.
Смотрите, вот мы же с вами знаем, что если взять хроматическое число обычного графа,
то оно по индукции или жадным алгоритмам, но совершенно элементарно отренивается вот так,
где delta j это максимальная степень вершины. Мы сейчас вот из этого рассуждения видели,
что степень вершины помогает локализовывать вот эти зависимости, их становится не очень
много. И из-за этого удается хорошо покрасить. В данном случае 20 метров. Просто хотим оценить
каким-то образом хроматическое число гиперграфа. Вот хотим взять хроматическое число гиперграфа
и оценить его сверху как f от дельта от этого гиперграфа. Хочется, чтобы f росла как можно
меньше. Вот ясно, что теорема, которую мы сейчас доказали, такая очень понятная,
иллюстративная, она на этот случай. Сейчас мы это проделаем. Смотрите, товарищи,
я не буду формулировать теорему сразу, а мы ее с вами получим. Ну у нас так бывало вроде в
курсе, что мы думаем, думаем вместе, думаем, получается теорема. А пока думали, возникло
доказательство. Нормально. Но мы же умеем думать, вот тут вот есть эта теорема. Умеем думать. Да,
у нас уже есть заготовка для мыслей. Вот, ну короче, дан какой-то гиперграф. Давайте считать,
что он, наверное, однородный. Ну да, то есть, тоговая оценка будет не только пункты от дельта,
но еще и от n. Вот потом не спрашивайте. От однородности, от числа вершины гиперграфии,
она будет зависеть. Как в ребре гиперграфа, она будет зависеть. Да, дан какой-то однородный
гиперграф. Хотим покрасить его уже не в два цвета, а в какое-то количество r цветов. Ну,
хочется, конечно, чтобы r было поменьше. Так, ну и мы знаем, что дельта, это дельта от h. Максимальная
степень вершины, она уже не обязательно n. Дельта может не совпадать с n. Вот в этой теореме она
равняет с n, а тут она общая. То есть, она однородная гиперграф с максимальной степенью вершины
дельта. Какое минимальное количество цветов, его можно покрасить. Хотим покрасить какое-то,
в r цветов. Что мы делаем? Красим случайно вершины. Красим вершины случайно. Так,
дорогие друзья, понимаешь, что значит случайно? То есть, взаимно независимо. И как из r цветов
с вероятностью одна r цвета присваивается? У нас r теперь цветов, поэтому 1 и 1. То есть, любого
цвета, любого конкретного цвета. Каждого цвета вероятность один поделительная. И цвета
присваиваются, естественно, взаимно независимо. Снова у нас возникают события ребра. В первых
есть а1, и так далее, ам. Но количество мы знаем, что нас никак не будет беспокоить. Так,
устроена локальная лемма. Есть соответствующие события. А1, и так далее, ам. Вероятность а красивого
итого какая? С какой вероятностью одно цвет на ребро, если мы теперь используем r цветов?
Ну да, то есть, точно также это будет r в степени 1-n. Не 2 в степени 1-n, а r в степени 1-n.
r вариантов одноцветности и для каждой вероятности 1 на r в n. Да, это 1 на r в n-1 или r в степени 1-n,
чтобы писать. Тоже самое, все то же самое. Вот это вот будет как раз p и в локальной леммы ловится.
Ну а d точно так же, как и в той теории, которую мы перед этим доказали, оценивает а2 как n
умножить на дельта просто. На дельта минус 1, да? Ой, на дельта минус 1, да. Как губкины имеют
степень не больше, чем дельта, одно множество, которое ее содержит мы уже зафиксировали,
значит остальных не больше, чем дельта минус 1. По этой вершине не больше, чем дельта минус 1 с
данным пересекается, ну и суммируем по всем вершинам. Получается, что d не больше, чем n на дельта минус 1.
Условия локальной леммы ловится и получаем теорему. Так, ну давайте напишем e на r в степени 1-n,
теорему мы сейчас получим, и на n дельта минус 1 плюс 1 должно быть не больше, чем единица.
Тогда вероятность пересечения отрицаний вот этих событий больше нуля, ну так и граф
таки красится в r цветов как нам нужно, что каждое ребро не одноцветно. Вот если это выполняется,
то хиатаж не превосходит r. Если это условие выполняется, то хиатаж не превосходит r. Ну
давайте явно напишем, как выразить r через n и дельта, то есть вот в виде такой функции от
n и от дельта. Туда что ли? Нам уже локальная лемма не нужна. Так, сейчас напишем r, берем вот таким
целая часть, мы его переносим сюда, вот так вот сюда перетаскиваем, тут получается r в n
минус 1. Значит оно должно быть больше либо равно того, что осталось слева. Больше либо равно. Тогда
целая часть должна быть верхняя. Берем верхнюю целую часть от корня n минус первой степени из
e на n дельта минус 1 плюс 1. Вот так. e на n дельта минус 1 плюс 1. Вот если взять такое r,
то хиатаж его не превосходит. Ну мы берем самое маленькое число целое, которое действительно
снизу оценивается корнем n минус первой степени. Вот это рассуждение, которое мы тут провели,
доказывает ту теорию. Понятно не очень. Чему r взяли как верхнюю целую часть? Ну утверждение-то
какое, что если r в степени n минус 1 больше либо равняется e на вот эту скобку, то гиперграф
красться в r цветов. Но если мы возьмем верхнюю целую часть от корня n минус первой степени и
потом ее возведем в степени n минус 1, но это же будет больше либо равно, чем e умножить на скобку.
Все значит гиперграф красться в r цветов. Согласно вот этому доказательству. Давайте еще раз подумаем,
представим себе, что n равняется двойке. То есть гиперграф это просто граф. Тогда у нас получилось,
что хиадже от графа не больше чем e на 2 дельта минус 1. Но это немножко хуже, чем тривиальная
индукция или жадный алгоритм, которые были заявлены в предыстории. То есть локальная
лемма здесь дала худший результат, чем то, что мы знали из простейших соображений. Я утверждаю,
товарищи, но это голословное утверждение, но вам придется в него поверить, что если n больше
либо равняется тройке, то ничего кроме локальной леммы тут использовать не умеют. То есть вот
эта вот оценка даже при n равном тройке, но она превращается там просто в корень квадратный,
из чего из e на 3 дельта минус 2. Оценка величиной порядка корень из дельта ничем кроме локальной
леммы ловуса не берется. То есть не берется ничем кроме вероятностного метода. Для три
однородного гиперграфа с максимальной степенью вершины дельта доказать, что его хроматическое
число по порядку не превосходит корни из дельта, это вот сложная задача, которая без локальной
леммы просто не поддается решить. Такой вот удивительный тоже результат.
