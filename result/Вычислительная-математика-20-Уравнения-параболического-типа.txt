Есть ли вопросы по прошлой лекции? Если нет, то по ходу дела. Смотрите, какие вопросы будут, по ходу дела
задавайте. Поэтому я некоторые вещи буду, естественно, обращаться с некоторыми вопросами
прошлой лекции, прошлой и так далее. У нас все лекции, на самом деле, завязаны. Сегодня мы будем
учиться решать уравнения параболического типа. Задач таких прикладных этого типа уравнений
очень много. Это и физика, и механика, теория диффузии, фильтрации в геофизике, это и динамика
популяций, то есть это изменить численности стадо, саранчи, олени, волков. Это модели социодинавики,
в экономике они используются, ну и так далее. Ну, значит, пришли они, конечно, из физики, это
процессы типа проводности, диффузии, вязкости, то есть как бы такие десепативные процессы. Ну,
это действительно так, но если уравнение параболического типа имеет явно выраженный
нелинейный вид, то там могут быть и необязательно десепативные процессы, скажем так. Почему
десепативные процессы? Поскольку в этих уравнениях присутствует вторая производная по координате.
По координате. Это обычно описывает описание таких десепативных процессов. Ну, я начну с
простейшего уравнения. Значит, простейшее линейное уравнение имеет такой вид. Мы с вами его записали,
поэтому я подробно не буду устанавливать. Ну, например, вот так пусть будет а константа,
то есть это линейное уравнение, а t зависит от координата. Время мы будем полагать вот в
таком промежутке. Правильно написать вместо t большую бесконечность, но у нас бесконечностью быть
не может. В вычислениях x меняется от 0 до x большого, то есть координата. Ну, и начальные
ограниченные условия всегда обязательно задаются. То есть у от 0 до x, начальные условия,
ну пусть будет такой psi от x, то начальные условия при t равном уню у от t 0. Левое
ограниченное условие phi1 от t и правое ограниченное условие u от tx большое, ну пусть будет phi2 от t.
Ну, это вот такая постановка исходной дифференциальной задачи. Мы ее обозначали вот таким образом.
L u равняется f. Это исходная дифференциальная задача. Так, ну напомню, что
аппроксиммирующие уравнения мы обозначали l tau u tau равняется f tau в операторной форме.
Удобная такая. В alt x, вообще говоря, переменная, и вообще говоря, коэффициент может быть разрывный.
Тогда дифференцировать мы просто не можем. Поэтому здесь в таком виде делается.
Ну и нелинейные уравнения. Ну, записывается вот в таком виде d u d t, это d d x. Здесь a от u,
то есть коэффициент типа проводности уже может зависеть от решения. Здесь d u d x.
Ну и плюс правая часть, которая тоже в случае нелинейных уравнений может зависеть от самого решения.
Ну что, вот нелинейное уравнение, оно, конечно, физически наиболее интересным.
Оно используется очень часто и в физике плазмы, физике космоса, и в квантовом механике,
и динамике популяции и так далее. И вот когда коэффициенты зависят от решения,
возможны очень такие неожиданные физические эффекты. То есть вот я говорил, что вот уравнение
типа проводности при постоянном коэффисенте, оно вот такой десепативный вид имеет.
Ну действительно, если бы возьмем какую-то тепловая волна, это не совсем физический термин,
но если мы будем нагревать, например, вот нашу поверхность какую-то, например, на доску,
то мы знаем прекрасно, вы решаете такие задачки, то волна будет вот так вот как бы расползаться.
Ну это, ну тепловая волна, это такой условный термин, тепло.
На самом деле, если вот коэффициенты и правая часть будут зависеть от решения,
то возможны разные эффекты. Возможно, например, что тогда уже тепловая волна может появиться.
Например, в плазме появляются тепловые волны, которые также описываются такими параболичными уравнениями.
Они вот так распространяются, даже здесь вот бесконечная производная.
Возможно, другие варианты. Возможно, что вот где-то мы нагрели, ну, например, какой-то кусочек,
это тоже эффекты, которые в таких сильно нагретых средах типа плазмы.
И вот начинается рост, резкий рост температуры. Подобные эффекты в плазме называются пинч-эффектами.
Возможно, не один такой эффект, а несколько вот таких структур. Их называют контрастными структурами.
Все это нелинейные эффекты. Это очень важно. Нелинейные эффекты.
То есть, нелинейные эффекты не всегда, но чаще всего предсказуемы, скажем так, в своем качественном поведении.
Вот линейные решения более-менее предсказуемы. Ну, качественно, конечно.
Количественно нужно все честно решать. На коленке мало какие задачи решается.
В основном все решается на компьютерах численно.
А вот нелинейные задачи, там бывают такие эффекты совершенно неожиданные.
Совершенно неожиданные.
Например, вот задача при коэффициенте типа проводности равна, ну, скажем так, некая константа на
У в степени К, где К больше единицы больше двух.
Что характерно, например, для плазмов, для задач в детонациях.
Ну, вот как раз и приводил к таким эффектам.
К образованию тепловых волн, диагоничному росту.
Вот в плазме пинч-эффектов, флагм, и так далее.
Это все было.
Ну, а вот если у будет вот такой функции правая часть, то это вот такие процессы.
Например, имеет место будет детонация.
То есть процессы детонации описываются вот такими уравнениями.
Но это все существенно нелинейные задачи.
Они, конечно, самые интересные, самые красивые.
И не всегда предсказуемо поведение вот таких решений.
Ну, вот физика есть мощная наука.
Поэтому, как правило, если корректно сформулировать даже нелинейную задачу,
с экспериментов совпадение чаще всего вполне приличное.
Чистое решение с экспериментом.
Ну, вот это о задачах, о которых мы сегодня будем говорить.
Ну, разумеется, еще задача есть неодномерные.
Мы о них тоже обязательно будем говорить.
Уравнения такие линейные вы, наверное, разбирали,
либо будете разбирать в уравнениях математической физики.
Например, на кодке PdO PdT равняется D2U PdX дважды плюс D2U PdEbD дважды.
Ну, и это записывается вот в такой виде.
Видела пассиану коротко, в операторном виде.
Ну, проходили уже, наверное, или еще не проходили.
Многомерные уравнения.
То есть, линейные уравнения многомерные имеют точные решения.
Но они бывают разные.
Они бывают линейные, бывают с переменными коэффициентами,
бывают нелинейные, бывают они затропные.
То есть, коэффициенты могут быть в разных направлениях разные.
Ну, такие задачи, конечно, решаются только чистым путем.
Очень часто так и так все не бывает.
Ну, идем дальше.
Что касается опроксимирующих уравнений.
То есть, мы имеем исходную дифференциальную задачу
и будем как-то ее опроксимировать
с помощью некого вот такого операторного уравнения.
Я не уточняю какого, поскольку опроксимировать задачу дифференциальную
можно по разным, можно разными медленами, разными способами.
Мы об этом с вами говорили и будем говорить.
И для каждого класса задач существует свой класс опроксимирующих уравнений.
И это очень важно.
Ну, потому как можно, разумеется, решать и другими медленами,
ну, вы будете получать менее точные либо менее физические результаты и так далее.
Поэтому здесь надо знать, какие классы методов, вот какие классы задач нам подходят.
Вот давайте так.
Я вам показывал, что такое двухслойная схема.
Ну, двухслойная схема, грубо говоря, имеет...
Пусть будет вот такой у нас шаблон.
Здесь n слой, здесь слой n плюс 1.
Ну, здесь у нас будут координатные слои или лучи m, m плюс 1, m минус 1.
Такие схемы имеют название двухслойной.
Ну, ещё бывают трёхслойные, если ещё один слой по времени добавляем.
Большее количество слоёв обычно не используется.
То есть либо схемы обычно используются либо двух-либо трёхслойные.
Количество лучей по координатам не обязательно 3, может быть и больше.
Если мы хотим уточнить, увеличить порядок опроксимации нашей схемы,
мы можем увеличить расширять шаблоны.
Это даёт возможность увеличивать точность или порядок опроксимации схемы.
Ну, давайте остановимся пока на двухслойных схемах.
В общем виде мы их можем записать вот в таком виде.
уn плюс 1, это есть такая двойная сумма, уi, уj.
Здесь коэффициент у нас будет α и gt.
Это коэффициенты разности схемы, которые зависят от tau и h.
И здесь уn плюс i, m плюс n плюс g.
Вот такой вид опроксимирующей разности схемы, двухслойная.
То есть здесь вот i у нас будет либо 0, либо 1, либо n, либо n плюс 1.
А g может меняться от m до m.
То есть шаблон мы можем расширить.
Не обязательно делать три точки, можно и шаблон расширять.
Теперь о личных методах решения и как можно их уточнять.
Но давайте это восстановимся.
Я на самом деле уже останавливаюсь на разности схеме,
которые обычно называют схемой типа Кранко-Никольсена,
либо просто схемой Кранко-Никольсен.
Для решения давайте пусть будет линейное уравнение.
Соединический коэффициент для простоты.
И мы предложим такую схему, самую простую.
Производную по времени мы опроксимируем
со отношением первого порядка точности.
Производную по координате давайте я в левую часть унесу.
Пусть будет схема...
Давайте так сначала я ту схему напишу,
которую мы с вами уже однажды писали.
Xi это параметр схемы, которая меняется от 0 до 1 единицы.
Здесь у нас будет лямбда х, х у n плюс 1 на m.
И плюс единица минус кси на лямбда х, х у n, m.
Вот такую схему мы с вами писали.
Давайте уточним ее свойства.
Первое, если кси равняется 0, то мы имеем просто явную...
Я напоминаю, что лямбда х, х...
Помните, что это за оператор или нет?
Но давайте напишу на всякий случай.
Может быть, не все помнят.
Например, лямбда х, х у n, m.
Это, собственно говоря, прощемация второй производной по координате.
Это у n, m минус 1.
Минус 2 у n, m.
Плюс у n, m плюс 1.
На h квадрат.
Такой оператор мы с вами писали.
Я просто вам напомню.
Ой, чуть ровнее.
А, кси зачем водится? Сейчас объясню.
Вопрос совершенно законный.
Зачем нужно параметр кси?
Да, да, да.
Сейчас объясню.
Это совершенно законный вопрос.
Зачем нам нужно кси? Значит, мы смотрим сюда.
Если кси равняется 0, то мы имеем только явную схему.
Явную схему.
Кстати говоря, производную по времени часто записывают так.
В таком тоже сокращенном виде.
Дельта тау у n, m делим на тау.
И мы получаем схему лямбда х, х на у n, m.
В таком виде оператору приятнее писать.
Просто меньше писать.
Свойства я немного разверну на ваш вопрос, но он совершенно верный.
Свойства явной схемы.
Как исследовать схему на порядок аппроксимации находить, мы с вами проходили.
Поэтому я вам сразу напишу, что порядок аппроксимации этой схемы
у от тау плюс h квадрат.
Первый порядок по времени и второй порядок аппроксимации по координате.
Явная схема.
Что касается исследования схемы на устойчивость.
То, что мы с вами говорили, мы представляем решение по нейману
в виде разделяющихся переменных лямбда п на e в степени i альфа м.
И находим лямбда.
Если вы это аккуратно сделаете и поставите в схему,
ну это уже чисто такая техническая работа,
которую вы без меня без проблем сделаете,
то получите, что условия устойчивости выглядят так.
Тау меньше или равняется h квадрат делить на 2.
Вот так по ходу замечу, что если у нас здесь будет стоять коэффициент,
например, а константа, то здесь будет внизу на 2а.
У нас коэффициент единица, поэтому так.
Что здесь, на ваш взгляд, не очень хорошо в этом условии?
Посмотрите.
Все мне здесь нравится или не все?
В принципе, формальные условия можно макнуть рукой и сказать,
ну вот мы выполнили и задача будет.
Можно писать программу, да, действительно, программу можно писать.
При выполнении условий все будет работать.
А что все-таки здесь нехорошо на ваш взгляд?
Или все хорошо?
Ну, смотрите, h квадрат для одномерной задачи,
это, как правило, число малое либо очень малое.
Даже для вашего компьютера, который следит в общежитии, учебном зале,
больше чем 10 минус 4, 10 минус 5, даже брать как-то нехорошо для одномерной задачи.
Тогда какое будет у нас тал?
Тал будет соответственно совсем маленькое,
то есть шаг по времени будет просто очень маленьким, просто очень малым.
Поэтому все хорошо, но шаг по времени,
ограниченный шаг по времени очень жесткий.
Теперь давайте другое возьмем.
То есть вот что для кси равного нулю мы изучили.
Теперь кси равное единичке.
Что получится? Мы получим неявную, просто неявную схему.
Здесь у нас будет n плюс 1 в правой части.
Если мы будем, опять же, следовать на порядок опроксимации,
мы получим без проблем.
Но это, в общем-то, и так видно. Вот такой результат.
То есть порядок опроксимации у оттал плюс h квадрат.
Здесь никаких, как говорится, загадок нет.
Что касается исследований на устойчивость полной эману,
я говорю, чаще всего именно это условие используется, хотя есть и другие.
То мы получим здесь результат намного более оптимистичный.
Схема окажется в линейном случае устойчивой для любых таллаж.
То есть любой шаг по времени вы можете выбирать.
Ну, конечно, не слишком усердце,
поскольку чем больше шаг вы будете брать, тем меньше точность вы будете получать.
В соответствии с вот этим.
Поэтому здесь нужно оценивать, знать точность, хотя бы примерно,
какой вы хотите получить численный результат.
И, соответственно, с этим выбирать шаги по времени и по координату.
То есть большие шаги по таллу тоже брать нехорошо.
Просто будет у вас падать точность решения задач.
Тем более, что для данной схемы порядок по времени первый.
Невысокий порядок.
Далее идем. Пусть у нас кси теперь будет равно 1 и 2.
То есть здесь будет одна вторая, здесь будет одна вторая.
Такую схему я вам на прошлой лекции писал.
И более того, мы доказали ее критерию ее устойчивости.
Критерию по Самарскому, которую предложил академик Самарский.
Оказалось, что если мы ее выпишем в канонической форме,
в которой предложил академик Самарский Александр Ильич,
то в общем-то исследовать ничего не нужно.
Прямо в канонической форме дает нам критерию устойчивости этой схемы.
Поэтому можно ее не исследовать в этом смысле,
но можно ее исследовать и по фонейму, и по критерийной.
В любом случае мы получим, что схема будет устойчива для любых таваш.
И схема будет абсолютно устойчива.
Но что важное для этого случая, кси равно 1 и 2, здесь у нас будет стоять квадрат.
То есть схема поднимает свой порядок по времени.
Второй порядок по времени и по координате.
Это, собственно говоря, обуславливает ее довольно большую популярность.
Именно эта схема ее называют схемой Кранко-Никольсон в шведской математике.
Действительно, она весьма популярна.
Но забегая вперед, скажу, у нее есть только один некий недостаток.
Есть понятнее.
Скорее всего, я на следующей лекции дам определение монотонности схемы.
Это важное такое свойство апоксидирующих уравнений.
Немонотонность.
То есть схемы разностной схемы могут обладать таким не очень хорошим свойством, как немонотонность.
То есть решение истинное должно быть монотонным.
А вот апоксидирующие уравнения дает решение немонотонным.
То есть дает ассоляция.
Вот схема Кранко-Никольсон не является монотонной схемой.
То есть она может давать, но ассоляция где дает?
В области больших градиентов решения.
То есть на гладких решениях ассоляция не появляется.
Поэтому слоиство монотонности оно актуально, но для, скажем, уравнений параболических,
и особенно близких к линейным оно не очень актуально.
Из-за его дезапротивных свойств, из-за второй производной.
Но, тем не менее, в случае больших градиентов мы можем получить нефизичную ассоляцию.
Вот это некий недостаток.
Кстати говоря, если кси равна единице, то схема будет монотонной.
То есть вот свойство схемы при кси равную единице, чисто неявная схема,
она будет не монотонной, но за это мы будем расплачиваться
чем порядком опроксимации по времени.
Но обе эти схемы на самом деле рабочие.
В случае гладких решений, конечно же, используется обычно схема Кранко-Никольсона.
То есть при кси равно 1 и 2.
Поэтому я дал развернутый ответ на ваш вопрос.
Но, в общем-то, это все вопрос правильный.
И время я не потерял, поскольку, действительно, эта схема используется очень часто.
Для решения такого сорта задач.
Теперь вопрос вот какой.
У нас такой порядок опроксимации.
Вопрос в следующем.
Можно ли его увеличить?
Действительно, вы сами понимаете, что если вы увеличиваете порядок опроксимации схемы,
то вы можете делать более грубую сетку.
Шаг сетки можно увеличивать.
При этом не теряя в точности.
Поэтому, в общем-то, есть целое направление в численных методах.
Это построение высокоточных методов.
Особенно это актуально для решения задач 3D.
Либо 4D. Это не социальная 3D задача.
Вы сами понимаете, что для компьютера, который у вас стоит в общежитии или в учебном зале,
вы в 4D случае подробную сетку не сделаете.
Ну, представьте себе, что даже если вы захотите взять сетку 10 в кубе на 10 кубе на 10 в кубе,
по трех координатам.
А там у вас еще есть четвертая координата время.
Какая сетка будет?
Десять-девятая.
То есть вы сами понимаете, что это уже не игрушка.
Не всякому компьютеру это миллиард узлов подвластен.
Для этого уже используются суперкомпьютеры и так далее.
Разумеется, суперкомпьютеры имеют большие возможности.
Но там у них беда другая, что их немного.
Даже не их немного.
В стране еще меньше.
Я могу их все перечислить.
Все суперкомпьютеры, которые есть в нашей стране, просто знаю лично.
Знаю их хозяев и так далее.
Наиболее мощные компьютеры стоят, как вы догадываетесь, в Китае, Японии и в США.
У нас тоже есть очень приличные компьютеры, которые позволяют решать очень-очень широкие классы задач.
Там можно сетки делать еще более подробные.
Но, конечно, персональный компьютер или подробный сеток не позволяет делать.
Но есть задача, которую можно решать и на персоналках, на грубых сетках.
В частности, в том числе, используя высокоточные методы.
То есть методы высокого порядка аппроксимации.
Как, например, это можно делать?
Сейчас я покажу один из вариантов.
Но это один из вариантов на самом деле.
Другие способы или методы увеличения точности методов.
Один из таких методов, наиболее понятных, я уже об этом как-то только что намекал,
это расширение шаблона по координарии.
Действительно, расширяя шаблон, мы можем добиться увеличения порядка точности.
Давайте знакомить с самым простым примером, чтобы много не писать.
Здесь мне не хватило доски.
Пусть будет у нас опять та же линейное уравнение типа проводности.
И для простоты явно разностая схема, чтобы не писать очень много.
А то мы будем заниматься школьной алгеброй.
Берем, пишем разностую схему простейшую.
Ту, которую мы только что уже на самом деле писали.
Пусть будет так.
Производную по времени я аппроксимирую обычным образом.
Только что мы это делали, поэтому я не поясняю.
Производная по координации.
Тоже я ее только что писал, поэтому не комментирую.
Это аппроксимация вторая, производная по координации.
То есть это у нас есть не что иное, как λ уравняется f.
Вот это уравнение.
Я переношу вторую производную в левую часть.
А правую часть у нас просто в данном случае ноль.
То же самое здесь.
Здесь у нас λт ут равняется f.
f tau.
Здесь я тоже в правую часть переношу в левую.
Это у нас будет как раз аппроксимирующий оператор.
А правая часть будет просто ноль.
То есть я сделал предельно простой случай.
Давайте, чтобы совсем было просто, так и сделаем.
Пусть будет вот так.
Ут минус у два штриха между стороны производной ноль.
Здесь тоже будет минус.
А здесь будет ноль.
Тогда будет совсем всё понятно.
В левой части стоит оператор L.
Либо нефилициальные, либо разности.
В правой части правая часть.
Но она в данном случае пусть будет нолью для простоты.
Теперь мы хотим поделять порядок аппроксимации схемы.
Как мы это можем делать?
Вот один из простейших способов.
Если мы хотим исследовать схему на аппроксимацию,
то мы что, в наш разностный оператор или не аппроксимирующий оператор
более правильно ставим решение, которое пока условно назовём точным.
У большое это проекция точного решения на нашу разностную сетку.
Как мы говорим, равняется f, t.
Функцию r-tau, которая есть разница l-tau на u-tau минус f-tau,
мы называем, как вы помните, невязкой.
Невязкой, если норма невязки меньше равняется,
c1 мы обозначили на t в степени p,
то мы говорим, что схема имеет по этому порядку точности.
Правда, для одной переменной.
Если у нас две переменных, то у нас невязка будет оцениваться
как t-tau в степени p плюс h в степени q.
T-tau, то есть p, это порядок опроксимации по времени, q порядок опроксимации по координате.
Ну а если три переменных, то у нас здесь будут три шага по трёх координатам.
Но я не буду сейчас забегать вперёд, мы сегодня до этого дойдём.
Так, давайте вот так и сделаем.
Давайте так и сделаем.
Ну здесь, в общем-то, это сделать довольно просто.
То есть я на самом деле здесь уже вам выписал эту схему.
Давайте, чтобы экономить место на доске, здесь у малой давайте заменим на у большой.
То есть будем исследовать наше апроксимирующее уравнение вот таким образом.
А здесь я пока пишу равно. То есть я как бы в наше апроксимирующее уравнение поставил точное решение,
точнее проекцию точного решения на нашу разницу в сетку. Зачем?
Затем, чтобы исследовать это уравнение на апроксимацию.
Я напомню вам, мы это делали уже.
Например, что такое ун плюс один? Ун плюс один большой.
Это есть ун плюс тау на у. Два штриха по времени нм.
Плюс тау квадрат пополам на у.
Здесь у нас уже будет три штриха по времени унм.
И плюс у большой, у тау фубе.
Это мы просто брали с вами и разлагали в ряд Эвера.
Да, действительно точки нм.
То же самое я могу написать для ун плюс один и ум минус один.
У нас есть ун плюс один и ум минус один.
Мы относительно точки нм тоже можем разлагать.
Давайте вопрос.
Так, сейчас здесь. А, я специально ноль убрал.
У нас был ноль, когда здесь была умалая.
Сейчас мы хотим что сделать?
Подставить вот это уравнение, ну это операторное наше уравнение, апроксимирующее,
вот эти разложения в ряд Эвера.
Понятно, поэтому я ноль убрал.
Это как раз то, что мы на самом деле делали и на прошлой лекции,
и на позапрошлой лекции.
То есть техника исследования апроксимирующего уравнения на порядок апроксимации,
это разложение в ряд Тейлора.
Если мы это все аккуратно поставим сюда, в это уравнение,
то получим следующее.
То есть мы получим Lt U-F в точке нм.
То есть мы получим наш дифференциальный оператор просто-напросто.
Ну это мы с вами делали, и это вы будете делать и на упражнениях,
на семинарах и в заданиях.
Это чисто такой технический вопрос.
Да, давайте.
Это верно, это я слишком много поставил.
Здесь будет вторая производная и так далее.
Конечно.
Но это мы с вами все уже делали.
И теперь, значит, что у нас получится?
А у нас получится следующее.
Как раз это первая производная, что вы правильно заметили,
войдет сюда, в дифференциальный оператор.
Почему здесь?
У нас получится следующее, tau пополам.
Здесь у нас будет tau пополам, а здесь будет как раз вторая производная.
Вторая производная, нм, и минус h квадрат на 12.
Давайте здесь сотрем.
Здесь у нас будет четвертая производная по х, в точке нм.
И плюс обольшое tau квадрат, плюс h в четвертой степени.
Вот что у нас получится после того, как мы все разложим в ряд нм,
относительно точки нм.
Но здесь что?
Давайте я напомню.
К нашему дифференциальному уравнению,
кстати говоря, в данном случае у нас просто ноль.
l u минус f у нас просто ноль в нашем случае,
поскольку это l u равняется нолью.
Здесь вот все это выражение, это есть наша невязка r tau.
Это невязка r tau, которую мы, прежде чем решать задачу, должны найти.
Но решающее значение в погрешности, решающий вклад дает функция,
которую мы называем обычно главным членом ошибки аппроксимации, r1 tau.
Это вот как раз слагаемые с минимальными степенями при tau и h.
Что это означает?
Это означает, что наша схема, r1 tau, это есть обольшой tau плюс h квадрат.
То есть схема имеет первый порядок по tau и второй по координате.
Это мы с вами уже получали.
Это мы с вами закрепили.
А вот теперь такой вопрос.
А здесь у нас tau квадрат плюс h4.
Теперь вот такой вопрос.
Несколько секунд для размышления.
Мне очень хотелось бы поднять порядок аппроксимации схемы,
в частности, до второго по времени и четвертого по координате.
Что я, имея вот это исследование на аппроксимации, должен сделать,
чтобы получить вот этот порядок, повышенный порядок аппроксимации?
Что мне нужно для этого сделать?
Давайте пять секунд для размышления.
Какие идеи будут?
Первая идея, конечно, самая экстремальная, радикальная.
Занудить. Прекрасно.
Но на самом деле, если мы занудим, то мы получим некие функции.
А это четвертое производное.
Отсюда, когда мы разлагаем вот это второе производное,
если вы честно разложите у m-1, у m-1 в ряда Тейлора,
поставите в эту аппроксимацию второй производной,
то вы получите второе и четвертое производное.
Просто здесь эти третьи производные симметрично сократятся.
Здесь m-1, здесь m-1.
Ну, на самом деле, посмотрите, то ли на поздно прошлой лекции мы это делали,
ну или на семинарах будете делать.
Просто честно возьмите, разложите и получите как раз,
что минимальное производное четвертое будет.
Сгущать сетку, прекрасная идея.
Сгущение сетки это всегда хорошее дело, это всегда увеличение точности.
Но, как я говорил, здесь не всегда удается ее сгустить до такой степени.
Ну, в случае задач, скажем, одномерно, где t и x есть,
это реально, действительно, там можно сгустить сетку до 10 в 9 степени и так далее.
То есть сделать очень мелкую сетку,
получить результат очень близко к точному решению одномерной задачи.
Но когда вы переходите на задачи двух, особенно трехмерные,
здесь уже это все будет намного сложнее.
Нужно будет поднимать точность метода.
Таука, кашка, водорад.
Так, ладно.
Нет, ну это все, вы идете потому, что давайте занудим этот член.
Не удастся его так просто занудить.
Не удастся, у вас будет очень сложная зависимость между Тау и Аш,
если вы просто будете занудить.
Ну, я подсказываю идею.
Смотрите, у нас есть в левой части...
Давайте я вот это затру, да, разложение в ряд Тейлор.
Это вы без меня все сделаете.
Вот у нас вот эта левая часть, есть не что иное, как разностный оператор.
Разностный оператор.
Что он опроксимирует нашу задачу с порядком точности о Тау плюс Аш квадрат.
Теперь, смотрите, я беру и вот этот главный член ошибки опроксимации
перетаскиваю в левую часть уравнения к нашему разностному оператору.
Это подсказка, что дальше нужно сделать.
Тогда если я перетащу, у нас в правой части останется вот это.
Тау квадрат и Аш четвертый.
Но перетащить мало.
Нужно еще что-то сделать.
Что?
Что?
Вот главный член ошибки опроксимации.
Вот его.
Перетаскиваю в левую часть.
И если я правильно опроксимирую этот главный член ошибки опроксимации,
то у меня получится вот схема с таким порядком точности.
С повышенным порядком точности.
Тау квадрат плюс Аш четвертый.
А как мы опроксимировать будем?
Да, чтобы такое получилось.
Хорошо, смотрите.
Итак, что у нас будет у второй производной по времени?
Так, смотрите.
Теперь мы смотрим сюда.
Из этого уравнения мы можем выразить вторую производную по времени
через четвертую производную по координате.
Как это сделать?
Дважды продифференцировать.
И окажется, что в данном случае у Т, Т, вторая производная,
это есть не что иное, как четвертая производная по координате.
То есть продифференцируйте ее дважды.
По Т, потом по Х, вычтите и получите вот.
То же самое мы получали.
Получаем, чтобы вторая производная по времени
для данного уравнения равняется четвертой производной по координате.
Вот возьмите это и сделайте, продифференцируйте.
Уравнение по Т, потом по Х, вычтите и получите.
То же самое мы делаем, кстати, для уравнения переноса, если помните.
Помните, у по Т минус у по Х.
И оказалось, что производные все по Т равняются производным по Х.
Но здесь похитрее.
Разумеется, если я поставлю коэффициент какой-то,
типа коэффициент и по проводности, то здесь будет еще коэффициент входить.
Поэтому я вот эту вот вторую производную
могу вместо нее написать производную по четвертую производную по Х.
У нас здесь четвертая производная и здесь четвертая производная.
Хорошая идея.
Конечно, потому что схема, я взял явную,
но вы точно то же самое можете сделать со схемой неявной.
А если схема явная, вам тау придется брать маленькая,
а если схему возьмете неявную, то схема будет устойчива при любом тау и аж.
Понятно, да?
Но я просто взял для простоты схему явную, чтобы меньше писать.
Неявную вы без меня распишите.
Там просто больше писать придется.
Итак, я беру вот этот вот главный член ошибки аппроксимации
и переношу в левую часть.
Давайте я это сделаю.
Как бы здесь нам лучше это написать?
Давайте я еще раз припишу.
Вот у нас левая часть.
Это у нас просто в силу нашего уравнения ноль.
l2-f это просто ноль.
Я могу его просто убрать, чтобы меньше было записей.
А вот эту вот часть я пишу минус, а здесь плюс.
И перенес в левую часть.
Тогда здесь у нас будет не плюс, а равно.
То есть элементарная алгебраическая операция.
Перенес главный член ошибки аппроксимации в левую часть.
Это уже совсем близкая подсказка.
Что дальше я делаю?
Мне нужно сделать, чтобы получить повышенный порядок точности.
Ой, да, у нас все правильно.
У по х.
Давайте я возьму и напишу более аккуратно.
Tau пополам.
Минус Tau пополам, минус h квадрат.
Я переписываю главный член ошибки аппроксимации на 12.
И на У.
И четвертая производная по У.
Ну, и равняется O.
Tau квадрат плюс h в четвертой.
То есть если мы аппроксимируем вот этот главный член ошибки аппроксимации
с нужной степенью точности,
то мы получим разноцветную схему вот такого порядка.
Второго по времени и четвертого по h.
Что нам осталось сделать?
Нам осталось расписать четвертую производную по точкам.
То есть аппроксимировать четвертую производную.
Ну, у меня есть сомнения в том, что вы помните,
как аппроксимируется четвертая производная.
Или я не прав, кто-нибудь может расписать,
как четвертая производная аппроксимируется.
Как?
Абсолютно верно.
Любую производную мы можем выразить через площадь бинома Ньютона.
Но давайте я не буду расписывать бином Ньютона,
а то мы далековато уйдем.
Просто вы пишу, как аппроксимируется четвертая производная.
Четвертая производная аппроксимируется по 5 точкам следующим образом.
И делим на h в четвертой степени.
Это будет аппроксимация четвертой производной
с четвертым порядком точности.
Если мы так делаем, то мы получаем,
то есть вставим вот эту аппроксимацию сюда.
То есть мы берем и пишем следующую.
Ну, давайте двойку вынесем.
Одна вторая tau минус h квадрат на 6.
А здесь вот такой оператор четвертая производная.
Аппроксимация четвертая производная обычно пишется так.
λ4х, у, н, н.
Разнообразная аппроксимация четвертой производной.
Если мы так делаем, то мы получаем схему повышенного порядка точности.
Все здорово, но какая расплата за повышенный порядок точности?
Всегда нужно чем-то расплачиваться приходится за улучшение метода.
Шаблону, конечно, да.
То есть у нас шаблон получится следующего вида.
У нас будет вот такой шаблон.
Он будет действительно двухслойный.
То есть слой n и слой n плюс 1.
Здесь точка m, m плюс 1, m плюс 2.
Здесь у нас m минус 1 и m плюс 2.
То есть у нас уже шаблон не трех, а пятипотечный.
Ну а мы же можем сделать как?
Это у меня явная схема.
Мы можем сделать неявную схему.
Поскольку ясно, что явная схема будет иметь жесткое ограничение на шаг по времени.
Тогда можно сделать неявную схему.
То есть вот сюда перенести наши точки.
Неявная схема будет абсолютно устойчива.
Для любых того и ваше.
Но это вы уже без меня сделаете.
Получите неявную схему, высокого порядка точности и так далее.
Но здесь какие будут у вас дополнительные задачи?
Какая еще возникнет?
С краевыми условиями.
То есть нужно будет опроксивировать краевые условия с тем же порядком точности.
Эту задачу нужно будет тоже решить.
То есть опроксивация краевых условий.
Но это один из вариантов.
Есть другие, но не все сразу.
Схема самой высокой порядка точности, которую я знаю,
это получил профессор Толстых Андрей Игоревич.
Это мой старший товарищ.
Он еще ученик великого академика биоцерковского,
который создал не только нашу кафедру, но и весь вестих.
Андрей Игоревич Толстых.
Он предложил схему 32-го порядка опроксивации.
Понятно, да?
Но там просто встает немного другой вопрос такой, деликатный.
Какой компьютер нужно подбирать?
Поскольку там и double precision, и все прочее.
То есть там уже точность метода начинает быть точнее от точности компьютера.
На это просто он отвечает очень оптимистично.
Для будущих компьютеров.
Будущие компьютеры действительно будут еще более точны,
еще больше разрядность иметь и так далее.
Ну, здесь пока вот так.
Все, я вот так.
Сколько у нас времени?
Я показал пример.
Время у нас есть еще.
Теперь идем дальше.
То есть как строить схему, как увеличивать порядок
с помощью расширения шаблона, вы уже знаете.
Теперь идем дальше.
Давайте рассмотрим, как мы будем работать
с уравнением параболического типа одномерным,
если у нас есть схемы с переменными коэффициентами.
То есть коэффициенты зависят от независимых переменных tau х
и с нелинейными задачами.
То есть когда коэффициент, его правая часть может зависеть
от самого решения.
От самого решения.
На первый вопрос на самом деле мы уже с вами частично отвечали,
когда говорили о краевых задачах для обыкновенных дифференциальных уравнений.
Ну, давайте я напомню.
Итак, пусть у нас будет опять же уравнение типа проводности одномерное.
Это вот линейное уравнение.
Нам нужно сделать так, чтобы у нас коэффициенты были переменные.
То есть d под x, а здесь a, например, от xt на d под x,
плюс f от xt, плюс x.
Я напомню, что-то подобное с чем-то подобным мы сталкивались,
когда говорили о краевых задачах с переменными коэффициентами.
В чем был вопрос?
Дело в том, что если у нас есть три точки, скажем, m, m плюс один и m минус один,
но в данном случае на координатной оси,
то, например, мы в точке m можем поместить контактный разрыв.
Ну, скажем, биметаллическая пластинка, алюминий вайфрам,
и в точку m мы помещаем контактный разрыв.
Какой коэффициент брать в этой точке?
Алюминий или вайфрам?
Трудно сказать.
Поэтому лучше всего коэффициент брать здесь алюминий, а здесь вайфрам.
А эту точку не трогать.
Поэтому опроксимация этого уравнения имеет такой вид.
Давайте так ОНМ.
Это я сокращенную опроксимацию производной по времени пишу.
А здесь у нас будет так.
Единица делить на h.
Так, здесь у нас что?
Коэффициент a, m плюс одна вторая.
Здесь у нас u.
Ну, давайте схему неявную уже для разнообразия напишем.
Обычно чаще всего, как вы, видимо, догадались, для этих уравнений явные схемы используются.
Так, минус u, n плюс 1, m делим на h и минус a.
Давайте возьмем a, n.
М минус одна вторая, u, n плюс 1, m.
Минус u, n плюс 1, m минус 1 на h.
Ну и плюс f от u, n, m.
Ну вот в таком виде, если мы помещаем в точку m наш контактный разрыв,
мы можем решать задачу, не задумываясь о решении задачи, так называемой задачи, контактного разрыва.
То есть, вообще говоря, если у нас есть какие-то разрывы в решениях,
то в этих разрывах обычно решается отдельная система уравнений, как правило, гибридических.
Но можно, оказывается, делать такие схемы, которые называются схемой бегущего счета.
То есть схема, в которой проходят все разрывы и их корректно описывают.
Это вот такая схема.
На самом деле мы с вами об этом уже говорили в декабре, когда говорили о задачах краевых.
Или в январе, по-моему.
Алгоритм решений, только вы меня помните.
Вот я здесь не дописал, а вы не заметили.
Чего я здесь не дописал? Подскажите.
Что-то я здесь не дописал.
Плюс единичка.
Но я не специально. Торопился, наверное.
Ну вот теперь, если мы на каком-то слое n плюс 1 остановились,
какое алгоритм решения вот этой задачки у нас будет, если мы на слое n плюс 1 остановились?
Это система линейных уравнений у нас получилась, да?
Как мы будем их решать? Каким алгоритмом или методом?
Смотрим. У нас есть три неизвестных.
Ум минус 1, ум плюс 1.
Так, давайте, чтобы было совсем понятно, я вот сокращенную аппроксимацию беру
и напишу не сокращенную, а полную.
Аппроксимацию в производной по времени, в первом порядке точности.
Теперь давайте отвечайте.
У нас в нашей системе линейных уравнений есть три неизвестных.
Остальные другие.
Если мы выпишем эту систему в матричном виде, то матрица у нас будет какой?
Трехдиагональная, то есть прогонка.
Или по американски алгоритм Тобсона, либо так, либо так.
И так, и так, верно, но мы обычно называем прогонкой.
И одновременно этот алгоритм был предложен в конце 50-х годов прошлого века
в Америке Тобсоном, у нас в Гельфандом.
Гельфандом, вы не судите про рекламную математику.
То есть алгоритм решения на каждом временном условии прогонка.
И так мы идем по временным слоям и решаем эту задачу,
имея, конечно же, краевые условия, имея начальные данные.
Хорошо.
Так, посмотрите, что непонятно может быть.
Давайте.
Почему мы на n плюс 1 берем производную?
Давайте вспомним нашу разностную сетку, кардината ТХ.
По времени мы разбиваем нашу ось по слоям.
Ну, слой там m, n плюс 1, n минус 1 и так далее.
То есть это по времени мы по слоям разбиваем.
По координатам, по лучам.
Ну, слои и лучи, это такая неофициальная, но признанная терминология.
По времени слои, по координатам лучи.
Ну, например, m луч, этот m плюс 1 луч, этот m минус 1.
Здесь у нас дается при х равно 0 одно левое краевое условие.
Здесь при х, равном х большое, правое краевое условие ставится.
Правое краевое условие ставится.
Вот у нас, например, слой n.
Ну, пусть будет n плюс 1 и n.
На слое n мы все знаем.
Ну, например, на n равно 0, это просто начальные данные будут.
Ну, потом мы поднялись до слоя n, и на слое n нам все решения известны.
Тогда нам нужно определить решение на слое n плюс 1.
Что мы получаем? Мы имеем три точки на слое n плюс 1 и одну точку,
соответственно с этой системой уравнения, на слое n.
Эта точка решений нам известна.
В этой точке решения, это краевое условие наше, оно дано.
У нас нет решений в двух точках.
Что мы можем сделать, чтобы их определить?
Только одно, решить систему линейного уравнения вдоль всего этого слоя, n плюс 1.
А здесь у нас будет краевое условие опять заодно.
То есть это та же самая прогонка, о которой мы с вами говорили,
когда разбирали решения краевых задач.
Только тогда у нас была одна прогонка, от 0 до х большое,
а здесь у нас n большой прогонок.
Сколько сладёв, столько прогонок мы и делаем.
Ну подумайте ещё, задавайте вопрос.
Сейчас ещё раз.
А, хороший, правильный вопрос.
Мы, конечно, описали любая функция в узле n плюс 1 на 2,
это есть fm плюс fm плюс 1 делим пополам.
То есть это просто точка посередине, двух узлов.
Если нам нужны другие функции между узлами,
мы используем оператор интерполяции, о которых мы говорили.
Но если мы линейный оператор интерполяции возьмём, это и получим.
Но если мы захотим, скажем, какой-то более точный оператор второго порядка точности,
то для этого нам потребуется 3 узла, чтобы правого построить.
Тогда у нас будет более точный порядок интерполяции,
и количество узлов будет увеличиваться.
То есть для всего нужно платить.
В данном случае я писал именно так.
Ну посмотрите и подумайте, что вот здесь непонятно.
А, да, конечно, конечно.
А давайте тогда, если есть вопросы, начнём с самого начала.
Пусть у нас будет так.
Вот этот слой n равняется нулю, начальный данный.
Слой начальных данных весь нам известен, вот за одну задачу.
То есть нам известно всё здесь,
нам известно всё вот здесь, правое краевое условие, всё здесь, левое краевое условие.
Нам не известно решений в этих узлах, о которых мы говорим.
Давайте пусть у нас будет n равна единице.
То есть вот оно, n равна единице.
Как мы ищем решение при n равной единице?
Нам известно решение во всех точках вот этого нижнего слоя.
Это у нас начальные данные.
Ну давайте пометим крестиком.
Вот оно, да.
Всего у нас какие точки?
Вот я их обозначил.
M минус 1, M и M плюс 1.
Решение вот в этих точках нам не известно,
а вот в этих двух известно.
Краевое данное и начальное данное.
И здесь нам известно решение.
Краевое условие и так далее.
И вот для всех этих точек мы выписываем систему уравнений.
Ау равняется f.
Вот эта система уравнений.
Поскольку здесь M у нас меняется от 0 до M большого.
Вот система уравнений получается вдоль слоя n.
Ну первого слоя в данном случае, первого слоя.
Поэтому на первом слое мы все решаем.
И переходим на второй слой.
n равняется 2.
Тоже самое, прогонку сделаем при n равняется 2.
Потом при n равняется 3.
Поднимаемся по шагам.
Подумать несколько секунд, что может быть еще непонятно.
Но чтобы окончательно было понятно,
можете вспомнить нашу лекцию по краевым задачам.
Мы это подробно разбирали.
Там все то же самое, только там одну прогонку мы делаем.
А здесь мы делаем прогонку на каждом слой по времени.
Так все одно и то же.
Помните метод стрельбы, метод прогонки, метод простых итераций.
Это все для краевых задач.
Все то же самое здесь.
Только n большой раз мы делаем.
Идем дальше.
Теперь пусть у нас задача нелинейная.
То есть коэффициенты правой части могут зависеть от решения.
В данном случае я чуть изменю ситуацию.
У нас правая часть от u и коэффициент от u зависит от решения.
Давайте осмотрем.
Сколько у нас времени осталось?
Сейчас?
20 минут?
Нет, осталось 20.
Осталось 20?
Это же куча времени.
Отлично.
Тогда мы успеем это сделать.
Идем дальше.
Итак, у нас коэффициент зависит от решения.
Вот решение.
Я предложу пока ту же схему, которую я предлагал.
Производную по времени опроксимирую.
А здесь сделаю следующую единицу от h.
Пусть будет an.
n плюс 1.
Вторая.
Ун плюс 1.
m.
Минус ун.
Здесь m.
На h.
Минус an.
m минус 1.
Вторая.
Здесь ун плюс 1.
Минус ун плюс 1.
Здесь у нас m.
Здесь m минус 1.
Делим на h.
Ну и плюс f от u, n, m.
Смотрите, с первого взгляда.
То же самое, что и раньше.
Я написал буквально один к одному то, что было написано на доске и раньше.
На самом деле есть некая разница.
Мы смотрим.
Действительно, у нас в правой части мы берем решение с нижнего слоя.
Это называемая нелинейность с нижнего слоя.
А на верхнем слое, n плюс 1, у нас опять тоже три точки.
Ум минус 1.
n плюс 1.
Ум.
n.
Ум.
Плюс 1.
n плюс 1.
То есть опять среднеизвестная прогонка.
Прямо один к одному, как вот до этого.
Это верно, но почти верно.
Что на самом деле может нас затормозить в быстром программировании этой задачи?
Коэффициента.
Коэффициента, правая часть.
Обращаю внимание на правую часть.
Помните, когда мы говорили о решении нелинейной краевой задачи, у нас было некое условие.
Берем гипотон на шаг по времени, которое связано было с правой частью, точнее с ее производной.
Вот-вот-вот, прекрасно.
Это, друзья, есть вещи, которые называются в педагогике рекерные точки.
Это рекерная точка.
Вот такую норму много меньше денег.
То есть у нас, на самом деле, при наличии нелинейности опять появляется это условие.
Ну, на самом деле, если функция правой части меняется очень медленно, то ничего страшного.
Тау будет достаточно большим, и мы можем решать задачу.
Но часто это может быть и функция быстрорастущая, например, для решения задач детонации, физики плазмы.
Это, как правило, экспоненты, либо степенные функции, либо экспоненты, либо степенные функции.
И там уже вот это условие, придется с ним считаться.
Поэтому нелинейность нижнего слоя можно делать, но имея в виду, что мы получим ограничение на шаг по времени.
А что если у нас функция в правой части растет быстро?
Экспоненты какая-нибудь, степенная функция, плазмы, например, степенная функция, детонация экспонента и так далее.
Что нам делать?
Сделать неявную схему, то есть здесь поставить n плюс 1.
А если мы поставим n плюс 1, то что мы получим за задачу?
Что эта задача на n плюс 1 слое будет у нас?
N-ный слой задан, а на n плюс 1 слой у нас вот такие три неизвестные.
Прогонка пройдет или не пройдет?
Вопрос на два балла. Друзья, пройдет здесь прогонка или не пройдет?
Ответ правильный, вроде не должна. Почему вроде? Можно уточнить?
Ну конечно, у нас вот нелинейный член, какая же это прогонка?
Прогонка работает только для линейных задач, либо для задач с переменными коэффициентами.
Для линейных она в принципе не может пройти. То есть нам что-то нужно из хитриса сделать,
чтобы все-таки редуцировать задачу к алгоритму прогонки.
Слушайте, вот вы радуете меня уже. Значит, чему-то все-таки научились.
Конечно, линейно-резовать. Линейно-резация, это процесс великолепный, правда, физики его порой используют не всегда справедливо.
Для быстрого решения задач линейизуют задачи, которые в принципе нельзя линейизовать.
Но на самом деле, если числые методы применять, то линейно-резовать все можно.
И что при этом будет использоваться? Метод итерации.
Какой метод, кстати говоря, наиболее быстрый итерационный метод?
Ньютона, правильно. Ну, друзья, вы меня сегодня радуете. Я просто, так сказать, в накрылих или чем-то.
Подсказываете мне, так сказать, постоянно. Это меня радует. Значит, чему-то вы обучились.
Метод Ньютона, правильно. То есть мы берем и мы должны построить итерационный процесс.
Что это означает? Это означает, что вместо индексов n я вставлю итерационный индекс.
И плюс один, и. Ну, здесь давайте я n вставлю.
И, и, и, и. И здесь тоже и.
Так, итерационный процесс. Ну, разумеется, если я так сделал, то я должен сказать, что у меня у ноль я должен задать начальные данные.
Но у нас здесь с начальными данными, к счастью, все просто. Что у нас является начальными данными для данного итерационного процесса?
Точнее начальным приближением. Решение на n-м слое. У, н, н.
То есть начальные приближения нам всегда заданы. Это облегчает решение.
Более того, если функции не очень сильно растущие, то мы прекрасно понимаем, что решения на n-м слое и на n-м слое отличаются не сильно.
А это означает что? Что итерации надо делать, как правило, много не нужно.
Часто там удается обладиться двумя-тремя итерациями.
Это хорошо, так. Ну, это хорошо. Ну, что плохо, опять же?
Плохо то, что я ничего не изменил. У меня, опять же, прогонка не проходит.
Но вот здесь, так сказать, ваша идея. Линьеризация.
Это означает, что вот эту функцию нам нужно линьеризовать. То есть сделать линейной.
Давайте так и сделаем. Линьеризуем эту функцию в правой части.
И построим процесс, который называется процесс Ньютона в функциональных пространствах.
Либо процесс в базе линьеризации.
В чем мы отличаемся от процесса Ньютона для нахождения решений нелинейного уравнения?
Там мы ищем одну точку. Нелинейное уравнение.
А здесь мы ищем N точку. То есть мы ищем всю функцию.
Причем и по координатам, и по времени.
А если у нас три координата, то это, сами понимаете, мы ищем функцию, в которых не одно пространство.
Поэтому такой математический аппарат этих методов – это функциональная анализ.
То есть мы работаем в функциональных пространствах.
Итак, f от ui плюс 1 мы представим как f от ui t плюс ui плюс 1 минус ui t.
А это давайте линейеризуем.
Это будет f от ui t плюс f' по u.
А здесь уi плюс 1 минус ui.
Для корректности давайте везде поставим еще индекс m.
Вот, пожалуйста, ваше предложение. Очень хорошее.
Нашу функцию я представил в виде функции линейеризованной.
Какой бы она ни была.
А теперь мысленно представьте себе весь полный итерационный процесс, который мы с вами построили.
То есть процесс Ньютона, нашего великого Ньютона.
Который и здесь руку приложил.
Ну, правда, здесь, может быть, он не прилагал.
Он для линейного ровнения прилагал руку.
Но это тоже линейеризация.
А линейеризация – это вот процесс Ньютона.
Так что это тоже метод Ньютона.
Ну, он так и называется.
Метод Ньютона в функциональных пространствах.
Либо метод квазилинейеризации.
То есть мы вместо вот этой функции сейчас берем и пишем f.
f от u и m плюс f' по u и m на u и плюс 1 m минус u и m.
Это я стираю.
Это я стираю.
Вот он наш итерационный процесс, друзья.
Так, только что-то здесь не хватает.
А, нет, нет, у нас здесь все нормально.
Равно здесь и правая часть линейеризованная.
Вот наш итерационный процесс.
К нему, естественно, надо добавить начальное приближение.
То есть функции начального приближения.
Ну, как я сказал, функции начального приближения –
у нас это есть решение на Н-м слое.
Вопрос, которого мне задавали.
Откуда брать решение на Н-м слое?
На Н-м слое решение нам известно.
С нолью н идем по слоям и находим решение.
Но здесь уже у нас итерационный процесс получается.
Итерационный процесс на каждом н-м слое мы заканчиваем при выполнении условий.
Норма ui плюс 1 минус ui меньше некой заданной точности епсилон.
Ну, как обычно, во всех итерационных процессах задается точность.
Ну, а норма разности, например, это может быть максимум модуля между двумя решениями.
Ну, если обномерная задача, то это, как правило, так и есть.
Евклидову норму можно взять.
Либо максимум по координатной оси.
Подумайте над вопросами.
Самый лучший метод понять и задать самые острые вопросы,
это взять и попробовать саморос писать алгоритм для программы.
А еще лучше программу написать для решения уравнения.
Тогда все вопросы тут же снимаются.
Ну, подумайте сейчас, сколько у нас времени осталось на вопросы.
Так, ну, у нас еще немного времени есть.
Почему? А, сейчас, секундочку.
То есть, когда вот здесь вместо линии резону функции, я писал функции просто, да?
Да, то есть, чуть-чуть раньше у меня было вот такое написано.
Ф и плюс один М.
Да, почему вот это нехорошо?
Так, ладно, кто ответит на этот вопрос?
Ну, прогонка не проходит в этом случае.
То есть, прогонка у нас проходит, когда у нас есть три неизвестных матрица
системы линейных уравнений трехдиагонально.
Вот три диагонали не нулевые, остальные все элементы нулевые.
Здесь у нас есть три элемента.
У М минус один, М плюс, вот они.
Три элемента есть.
То есть, прогонка это чисто решение линейной системы уравнений, линейной.
Пока эти три слагаемых неизвестных у нас есть, у нас система линейная.
Вот здесь мы раз и наталкиваемся на нелинейные функции.
Все, прогонка летит.
Единственный способ ее решения, ну, на самом деле лучший способ это линейная.
Но, в принципе, мы можем, конечно, вспомнить про метод простых итераций.
Это не мета ньютна.
Это означает, что вот здесь мы берем, ставим не И плюс один, а И.
Тогда тоже прогонка проходит.
Поскольку нам у ИТ известно, с нижнего слоя мы можем снять.
Но это будет то же на то же.
Опять же, у нас здесь встретится вот это условие.
То есть, мы опять будем ограничены шагом по времени.
Ну, и хотя мет простых итераций можно использовать, но он будет, естественно, медленный.
Поэтому можно, конечно, использовать мет простых итераций,
но мет ньютна, как вы знаете, как правило, быстрее работает.
То есть, количество итераций меньше.
Поэтому лучше линеризовать функции.
Давайте.
Какую функцию?
А, начальную?
А, при линеризации.
Ну, смотрите, у нас здесь я пока...
Это не всегда так хорошо, конечно, бывает.
Я считаю, что у нас правая часть задана аналитически.
Ну, например, экспонента E в степени х.
Ну, и в степени U.
Тогда вот F это экспонента в степени U будет, например.
Или sin в степени U, например.
И дальше вот по ряду Тейлора.
Первый член ряда Тейлора.
То есть, здесь функция вам задана, короче говоря.
Та, которая вас интересует, функция задана.
То есть, мы здесь добиваемся опять чего?
Редуцирования к меддопрогонке.
Почему к меддопрогонке?
Мы его любим.
А любим не просто так.
Длиннее случаев он очень устойчив.
Ну, мы условия устойчивости меддопрогонки с вами выводили.
В случае переменных коэффициентов можно найти очень экзотический случай,
когда прогонка вдруг, конечно, неустойчивая.
Такой экзотический случай можно привести, например,
если в правой части стоит очень сильно аксолирующая синусоида,
которая пересекает ось Х в каждом узле сетки.
Вот такая функция.
Действительно, прогонка для такой функции может оказаться неустойчивой.
Но эта функция, сами понимаете, уже очень экзотическая.
А так очень даже для быстрорастущих функций, это быстрорассолирующие все нормально.
Если либо линейный, либо переменный коэффициент.
Для нелинейных задач прогонка не проходит.
Их нужно линияризовывать, чтобы прошла прогонка.
Ну, еще давайте подумайте.
Это я вам рассказываю, как говорится.
С одной стороны, можно назвать это теорией,
но это теория такая, по которой программу можно писать.
Здесь писать программу.
Может быть, у вас первый такой предмет над этим функцией появился,
который одновременно и теоретический, и математики много,
и все это математика можно тут же в программу.
То есть он одновременно и прикладной получается.
Причем методы, я рассказываю, рабочие, которым можно решать реальные задачи.
Ну, посмотрите, что еще.
Здесь мы, получается, на каждом слое будем считать ньютона.
Да.
То есть мы на каждом n раз решаем систему по ньютону.
Сколько у нас слоев по времени, столько мы и решаем.
Но не хочу вас пугать, для одномерной задачи и персонального вашего компьютера,
для вашего ноута.
Эта задача очень посильная.
Когда вы переберетесь на многомерные задачи, там это будет намного сложнее.
То есть там время решения, память намного, все возрастает.
Одномерная задача решается на ваших персональных компьютерах.
Так что ничего страшного в этом плане нет.
Количество итераций по ньютону, мы смотрим, у нас был криптон.
Это было выражение, которое описывает.
Точно, что-то я помню.
Вы, получается, его примерно делаете?
Вы метнютное имеете для нелинейного уравнения?
Да.
Да, там действительно было выражение, можно его выписать.
Мы с вами много раз выписывали.
Но оно откуда идет?
Оно идет из того, что мы брали функцию,
ну там f от u, и ее линеризовали.
И оттуда брался ньютон.
Просто из самой простой линеризации функции нелинейной.
Здесь, на самом деле, все то же самое.
Только явной такой формы здесь не получается.
Ее нереально явную форму написать,
поскольку здесь получается система линейных алгебрических уравнений.
И от этой системы вы как не хотите уйти, не уйдете.
Нужно решать вот такую.
На каждом слое нужно будет решать систему нелинейных уравнений.
То есть на каждом слое нужно будет несколько итераций делать там.
Обычно это 2-3, максимум 4 итерации.
Обычно выбираются вот так, как я написал.
То есть вы задаете точность.
Ну, например, 10-6.
Ну, например, 10-6.
И смотрите на норму разности.
Вот это точность?
Нет, не обязательно.
Порядок аппроксимации мы все-таки напомним.
Это есть c tau в степени p.
Это разность между точным решением и численным решением.
c на tau в степени p.
Если мы уменьшаем tau к нулю, то мы получаем точное решение.
Здесь мы вообще-то итерационный процесс используем.
Это немного другое.
Я точность схемы уже задал.
То есть данная схема, вы помните, какая точность?
Первый порядок по времени и второй по координате.
Ну, мы можем уменьшать шаг и получать достаточно точное решение.
А вот количество итераций...
Либо вы задаете его каким-то стабильным, скажем, 5 итераций задали все.
Но обычно все-таки количество итераций обусловлено точностью.
Норма разности между решениями на ита итерации и и плюс первой.
Это мы тоже делали, когда говорили о методном ньютном.
А то есть они никак не связаны?
Нет, они не связаны.
То есть порядок метода и точность решений вообще говоря не связаны.
Вообще говоря, не связаны.
Другое дело, что вас может смущать, что вы можете задать такую точность,
скажем, 10 минус 16, которые просто ваши итерации не достигнут.
Ну, это верно.
Надо задавать точность реальную, которую вы можете достигнуть.
Поэтому я и говорю, что повышение порядка, апроксимация метода –
это задача важная и нужная.
Чем более высокий порядок метода, тем более грубую сетку мы можем использовать.
А для задач многомерных это момент важно.
Для одномерных не очень важно, скажем так.
Вы можете очень мелкую сетку задать для первого порядка,
а для многомерных задач, когда у вас там 4 переменных, с этим надо считаться.
Мы об этом говорили с вами.
Мы знаем, насколько наше решение будет примерно отличаться от действительного.
Да, при заданных шагах.
Но также наше решение мы ищем с помощью Newton.
Это уже итерационное решение, понимаете, в чем дело.
Смотрите, понимаете, в чем дело.
Здесь вот в чем, что вас может смущать.
Здесь вот эта схема выписана.
На самом деле это есть нелинейное уравнение.
Здесь заданы и tau h, все.
Это нелинейное уравнение мы решаем.
tau h мы менять не можем.
И решаем его с той точностью, которая нам нужна.
А точность задается только вот этим условием, больше ничего.
Это просто уже рассматривайте как систему нелинейных уравнений,
которую мы решаем по меду ньютона, линеризации.
А tau h здесь уже задано, все.
То есть вы его менять не можете tau h.
Вы их задаете так, как позволяет ваш компьютер,
и разумная ваша точность.
Мы же не сможем задать настолько маленькое, чтобы переключить?
Можно задать, да, вот столь малое эпсиум,
что вы можете этой точности не достигнуть.
Поэтому здесь точность тоже...
Я говорю, если вы задаете там 10 в минус двадцатой степени,
вы этой степени, скорее всего, точность не достигнете.
Поэтому точность нужно задавать разумно.
Давайте.
Кстати, вопрос тонкий.
Очень хороший вопрос.
Что делать с коэффициентами?
Они ведь тоже, вообще говоря, зависят от у.
Я как-то этот вопрос промолчал.
Но на самом деле вы совершенно правы.
Есть два варианта.
Первое, поставить здесь значки ита итерации.
Это первое.
Но можно ины поставить, итерации взять с нижнего слоя.
Но наиболее корректно вы сказали совершенно верно.
Наиболее корректно сделать тоже эти коэффициенты линеризованными.
Но просто здесь практика численного решения таких задач
говорит о том, что в первую очередь
на скорость решения влияет линеризация правой части.
Коэффициенты тоже влияют.
Их действительно нужно делать либо итами,
либо и плюс первыми брать.
Вот тогда линеризовать.
И плюс первыми, если вы возьмете, то вы так тоже в прогонке лежать.
Но если вы линеризуете вот так же, как я это сделал,
то, пожалуйста, вы можете делать прогонку.
Но, вообще говоря, здесь чаще всего, если из практики брать,
чаще всего делать так.
То есть берут на сытые итерации.
Просто практика показывает, что правая часть больше влияет на решение.
Вот это хороший вопрос.
Дело в том, что действительно это условие появляется для правой части.
Для достаточно гладких функций вот этих коэффициентов a и nm такого условия нет.
Правда, конечно, всегда можно придумать какой-нибудь очень крутой коэффициент.
Ну там, я не знаю, e в степени u, в степени u и так далее.
Когда ваш метод развалится.
То есть всегда можно придумать какой-то экстремальный коэффициент.
Но чаще всего это все-таки какая-то экзотика.
Обычно коэффициенты себя не так портят в решении задачи, как правая часть.
Ну то есть не портят.
Портить – это нехорошее слово.
Портить может исследователь, программист, который составил плохую задачу.
А физика природа не портит.
Природа она такая, какая есть.
Мы ее можем изучать, решать задачи и так далее.
Так что здесь вот с коэффициентами вопрос менее острый, чем с второй части.
Я, собственно, по этой причине о них не сказал.
То есть часто берут просто на слой n их.
Но более правильно брать так.
То есть в итерационный процесс их вгонять.
Это правильно.
Какие еще идеи есть?
По ускорению итерационного процесса.
Ну ладно.
Так, слушайте.
Ну вот, скажем, задавал вопрос.
А почему мы линеризуем функцию?
А если мы возьмем не первый член линейный, а второй член квадратичный,
почему бы нам квадратичные функции не сделать?
Еще лучше будет.
Да, мы теряем линейность, конечно.
Это первое.
А во-вторых, если помните, метод ньютный имеет второй порядок скорости сходимости.
И больше его не увеличивает, как правило.
Редко бывает, берут выше.
То есть его можно есть метод Чебышова, метод n порядка сходимости.
То есть ни второго, ни третьего n порядка сходимости.
Ну там проблема какая?
Попробуйте вспомнить, какие там проблемы возникают.
Почему все-таки дальше ньютна чаще всего не идут?
Ну идут, но в реке случаев.
Там начальные данные нужно брать с такой точностью,
что мы можем чуть ли не решение должны найти.
Очень близко приблизиться к решению точному.
Поэтому даже в метод ньютна, если вы помните,
есть ограничения на начальные приближения.
На второй порядок от третьей там еще более жесткие приближения.
Поэтому обычно ограничиваются линейнеризации.
Другое, что я нередко видел, просто физики делают еще проще.
Говорят, функции линейизуют и так с ней работают.
Вот это не есть правильно.
Мы можем получить в нелинейном процессе чисто линейную задачу.
Нужно честно итерировать.
То есть честно решать нелинейную задачу.
Темы медными, которые у нас есть.
Давайте еще есть вопросы?
Все, все, да.
