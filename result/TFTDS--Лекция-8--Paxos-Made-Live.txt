Сегодня у нас две лекции, хотя мы их не различаем, в принципе, но я различаю.
Мы хотим в следующий раз успеть новую лекцию и новый семинар, поэтому нужно как-то уплотниться.
Поэтому мы сегодня немного бодрее. Итак, вторая лекция на сегодня называется Paxos made live или Paxos в продакшене.
И что я вообще имею под этим в виду? С одной стороны, лекция Paxos в продакшене про то, как взять протокол, типа multipaxos или raft, который мы изучили,
и вот довести его до какого-то production ready RSM, то есть какие еще задачи нужно решить, помимо, собственно, репликации лога, чтобы из этого построить реплицированный автомат.
Это, во-первых, а с другой стороны, можно посмотреть на название Paxos в продакшене по-другому.
А как вообще Paxos или Consensus выглядит в продакшене?
С одной стороны, это, видимо, библиотека Consensus.
Я показывал вам сайт RAFTA, где есть ссылки на репозиторию с реализациями на разных языках.
Если вы хотите использовать Consensus, RAFTA или multipaxos, вы берете open source реализацию, включаете свой бинарник и дальше с ней работаете.
Но если вы посмотрите, давайте я вам сейчас это покажу.
Если мы сейчас посмотрим на статью, которую опубликовал Google в 2000-х, в середине, про свою инфраструктуру.
Ну, они писали статью про Bigtable, я уже немного говорил про GFS, про reproduce и еще про Chubby, сервис блокировок.
Так вот, Google строил отказоустойчивую инфраструктуру, но сначала он строил GFS, вы про нее знаете, что это не самая отказоустойчивая вещь на свете.
Но потом, конечно, они так больше не делали.
И Bigtable, их большое кивалию хранилища, которое используется и сейчас, оно, конечно же, отказоустойчивое.
Но для отказоустойчивости вам нужен Consensus.
И Google говорит, что мы вместо того, чтобы писать библиотеку Consensus, смотрите, паксисом,
подключать ее к каждой новой системе, которая хочет использовать Consensus внутри себя,
мы вместо этого напишем сервис блокировок.
Вот lock service.
И будем эту систему, сервис блокировок использовать, мы скажем, что это и есть Consensus as a service.
То есть вы не включаете библиотеку multipax в свой код, вы используете внешнюю систему,
которая предоставляет вам почему-то описать блокировками с lock-unlock, с acquire-release.
И с помощью этого решаете те задачи, которые вы бы решали, используя multipax в своем коде.
Почему это разумно? У них про это есть параграф.
Почему они так хотят делать?
Тут причины разные.
Они в том числе говорят где-то вот здесь, что блокировки более понятны людям, чем Consensus.
С другой стороны, вы знаете, что с блокировками можно портачить.
А распределенные блокировки, это вообще вещь довольно сомнительная, о которой мы сейчас поговорим.
Тем не менее, они такую систему построили, и вот тот же самый Bigtable, он эту систему использует,
использовал уж по крайней мере.
Использует, да, и сейчас, наверное, тоже использует для хранения данных и для еще чего-то, о чем мы поговорим чуть позже.
Ну, в общем, я начну не с того, как, не с той половины паксов в продакшене, где нужно что-то оптимизировать
или дополнительные какие-то фичи прикручивать к RSM, а с другого взгляда на Consensus в продакшене,
на Consensus как сервис и вот на сервис блокировок.
Вот давайте вообще представим, что бы это могло быть.
Ну, сервис блокировок – это нечто отказоустойчивое, что реализует APIS вызовами lock и unlock.
И, конечно же, этот сервис блокировок должен быть отказоустойчивым, поэтому он сам является RSM,
и вы каким-то образом Consensus внутри него используете как сервис.
Итак, lock-сервис – это RSM, и вы как клиент можете пойти в него и взять блокировку.
Вам могу сказать, хорошо, вы блокировку захватили.
Ну, конечно, не то чтобы это один глобальный Mutex какой-то, это было бы странно.
У вас, наверное, в программе много Mutex может быть.
Плюс замысел сервиса блокировок в том, что разные системы могут использовать один и тот же lock-сервис.
Совершенно разные, не пересекающиеся друг с другом, они могут использовать его как
инфраструктурный сервис, с помощью которого они внутри себя координацию выполняют.
Поэтому нужно как-то адресовать блокировки.
Но вот у нас в коде просто имена переменных, а в случае с Chabi, в случае с lock-сервисом,
у нас есть некоторая иерархия имен.
Ну, то есть такое дерево, и вы можете лочить, скажем, его узлы.
Так что мы здесь говорим какой-то путь.
Ну, почему иерархия? Потому что, скажем, у каждой подсистемы может быть своя ветка в этом дереве.
А в одной ветке одной подсистемы могут быть еще какие-то там вспомогательные поддеревья.
Ну, это не очень важно. Мы поговорим на другом курсе про Zookieper, и там все будет очень наглядно.
А пока вот вы просто берете блокировки, адресуете их вот некоторым путем в дерево.
И вам говорят, что вот вместо Paxos вам нужен такой вот сервис.
Разумно ли это звучит? Но в таком виде это абсолютно дико звучит, конечно.
Вот я хочу понять, ну, в смысле хочу, чтобы вы поняли, чего же пока в этой конструкции,
чего не хватает, почему это выглядит безумно.
Вообще идея распределенных блокировок, ну, идея вот блокировок локальных там на одной машине,
она еще куда не шла. Мы вроде бы умеем с этим работать.
Мы знаем, что блокировки нужно в каком-то порядке брать.
Ну, а с распределенными блокировками что не так? Вот нельзя просто так взять Mute и сказать, что
а теперь он распределенный Mutex.
Ну, вот смотрите, вы взяли блокировку. Что вы должны с ней сделать?
Ну, вот может быть и нет. Может быть, ты этого совсем не хочешь.
Может быть, ты ее взял, чтобы держать бесконечно долго.
Но это нормальное намерение. Собственно, сервис блокировок, он не для того, чтобы ты
брал блокировку на секунду, он для того, чтобы ты брал блокировку надолго.
Это основной сценарий, и вот вы пока можете подумать, о чем я говорю.
Но если, да, и сам сервис блокировок отказоустойчивый, то есть если одна машина ломается в нем,
но все-таки собирается квором, то, конечно же, ваша блокировка логически остается жить.
Ну, потому что это сам по себе RSM, отказоустойчивая сущность.
Вот. Но что делать, если вы сломаетесь?
Вот. Но вы с собой эту блокировку унесете.
Вот. Это очень странно. То есть ее никто больше взять не сможет.
Поэтому что вы хотите сделать, ну, помимо того, чтобы отдать блокировку пользователю?
Ну, вы хотите быть уверенными, что он выживет.
Но вы этого не можете гарантировать, он тоже не может. Он, конечно, может умереть.
Поэтому вы даете ему не блокировку. Вы даете ему блокировку с тайм-аутом.
А это называется лиза. То есть он не получает во владение эту блокировку, он получает ее в аренду.
Вот. И эту аренду можно назвать в одностороннем порядке, если вдруг этот клиент умрет.
Вот. А как понять, что он умер?
Ну, видимо, клиент с системой как-то взаимодействует, помимо того, что он берет блокировку.
Вот. Он устанавливает сессию.
Вот. У каждого клиента есть своя сессия.
Ну. И он отправляет сессию, такое логическое соединение, поддерживаемое клиентской библиотекой.
И он состоит в том, что вы просто посылаете хардбиты какой-то из реплик,
и система понимает, что вы все еще живы, и вы продляете эту блокировку, вы все еще и владеете.
Если вдруг протухает тайм-аут какой-то здесь, потому что вы вдруг отказали,
то, видимо, блокировка у вас отнимается, она становится свободной,
и другой кандидат, который на нее претендовал, его теперь, ему ее можно выдать.
Ну, то есть у нас здесь есть сессия, в ней есть какие-то хардбиты,
то есть механизм обнаружения сбоев, вот. И блокировка отзывается в одностороннем порядке.
Да, разумеется, если у вас вот этот узел умрет, то это не обязательно значит,
что сессия порвалась, и что блокировка будет отобрана.
Ну, потому что это проблема системы, а не клиента.
Вот. Так что сама система, она может реплицировать не только состояние дерева,
то есть кто какие блокировки взял, а и состояние сессии.
Так что здесь смерть узла может быть даже незаметной.
Но если вот клиент умер, то точно у него блокировку нужно изъять.
Хорошо ли это?
Это необходимость некоторая, то есть мы не можем отказаться, разумеется.
Но к чему это может привести?
Ну, видимо, у тебя здесь может быть тайм-аут не прямо на секунду,
потому что если вдруг там секундная пауза, чтобы у тебя не терялась большая работа.
Действительно. Но дело-то не в этом.
Зачем ты берешь блокировку вообще?
Вот, здесь некоторый код, который должен выполняться только тобой.
Вот. И видимо, у тебя есть конкурент не потому, что он твой соперник,
а потому, что он хочет тебя подстраховать.
Ну, вряд ли ты на одной машине выполняешь какую-то работу.
Если она умрет, то вся работа не будет выполнена.
Видимо, у тебя есть какая-то другая машина, на которую ты переключишься, если это упадет.
Вот. И если у тебя блокировку отберут, то она ее подхватит.
Вот. Тот же самый зеленый паз.
Ну, а мы, кажется, уже знаем, что довольно трудно отличить медленный узел от сбоенного.
И что может получиться? Что вы почему-то, ну, не знаю, вы залипли...
У вас, вы пишете вообще код на джави, у вас клиентская библиотека написана на джави,
и она хардбиты шлет. Вот.
Тут случилась пауза, сборка мусора.
Вот. И вы не отправляли эти хардбиты.
В итоге сессия у вас протухла, но вы при этом живы.
Но если вы умерли, то как раз все хорошо, это хороший сценарий.
Вас подстрахуют. Вот.
Но если вы все еще живы, но вы очень медленный, и у вас протухла сессия,
то блокировка логически освободится с системой и будет передана другому узлу.
Вот. А зачем вы берете блокировку?
Видимо, за тем, чтобы работать с каким-то внешним состоянием.
Ну, например.
И получается, что красный узел, красный клиент блокировку получил
и собирается что-то написать в это состояние, как-то с ним работать.
А зеленый все еще думает, что он ее владеет.
И тоже собирается писать.
Что же им делать?
Точнее, что же делать вот здесь вот?
Потому что, если мы делаем распределенные блокировки,
то они как бы бай-дизайн не могут гарантировать заименные исключения.
Это невозможно.
Вот. Нужно как-то помнить, кто из них был первым, а кто вторым,
чтобы понять, что на самом деле этот запрос уже не актуален.
Нужно сказать, что когда мы получаем блокировку,
мы не просто получаем подтверждение, что мы ее владеем.
А мы еще получаем эпоху вместе с ней.
И вот здесь эпоха 1 будет, а здесь эпоха 2.
И если вы уже в этом месте перешли в новую эпоху,
то вы отвергаете те изменения, которые вам шлет старый клиент.
Но он рано или поздно поймет, что он уже не актуален.
Но пока он это сделает, время какое-то пройдет,
нужно, чтобы он за это время ничего не сломал.
Но это по сути та же самая ситуация с конкуренцией лидеров,
которая у нас была в Multipax, которая может быть в RAF.
В RAF тоже не бывает так, что лидер прямо один во времени.
Их может быть двое, просто не в разных термах.
Есть старший и есть младший.
И вот нужно слушать того, кто в старшем терме находится,
и гонировать того, кто младший.
И если мы посмотрим на статью GoogleChab,
то на API, которая эта система нам предоставляет,
видно что-то.
А, перебор же, да?
То смотрите, это с одной стороны Acquire,
а с другой стороны это Sequencer.
То есть вы, как владелец блокировки, вы понимаете,
как его порядочно относительно других владелец.
Это важно, потому что они могут быть живы,
и вы можете в каком-то смысле владеть блокировкой параллельно.
То есть с точки зрения системы, которая была нарисована,
лог только у одного клиента.
А с точки зрения клиентов, они могут думать немного по-другому,
потому что знание это распределенное.
Вот система знает, что вы не владеете блокировкой,
а вы думаете, что еще владеете.
Так что чтобы сами клиенты не поломали жизнь друг другу,
они должны быть упорядочены самой системой.
Ну а теперь вопрос.
Зачем все это?
Ну то есть зачем нам распределенные блокировки
и почему нам дают вместо библиотеки консенсус, а сервис блокировок?
Как мы собираемся его использовать?
Мы разработчики какой-то другой системы, скажем Bigtable.
Какой смысл эти блокировки? Зачем они?
Кто их берет?
Просто пока это довольно абстрактно все, да?
Вот я беру блокировку, это что означает?
Кто я?
Что я собираюсь с ней делать?
Смотри, Bigtable – это киволюхранилище большое.
И я про него уже рассказывал в довольно смешном контексте.
Сейчас напомню.
Мы говорили про GFS, про распределенные файловые системы.
А потом я сказал, что мы говорили сначала про LSM, про локальное хранилище.
Про roxdb в частности, про leveldb-roxdb.
И что оно реализует LSM?
Вот у вас есть log, у вас есть memtable, у вас есть ass stable.
Потом поговорили с вами про дизайн распределенной файловой системы.
А потом я сказал, что раз уж мы умеем делать
LSM киволюхранилище поверх локальной файловой системы
и умеем делать распределенные файловые системы, то какая разница?
Давайте построим LSM поверх распределенной файловой системы
и получим key-value хранилища от козоустойчивой уже,
потому что сама файловая система DFS распределенная от козоустойчивой.
Но key-value оно большое, то есть пространство ключей большое,
поэтому мы разделим его на диапазоны, на рейнджи,
и каждый рейндж будет отдельным вот таким вот LSM-ом поверх распределенной файловой системы.
Bigtable так реализован, там есть понятие Tablet, Tablet это shard,
это кусочек, отвечающий за диапазон ключей,
и каждый кусочек хранит все свои данные в GFS.
А GFS, ну, колоссус, там сложно.
В общем, в базовом дизайне у вас есть GFS,
Bigtable хранит там данные Tablet в виде LSM.
Храняться-то ненадежно, и все помещается, потому что DFS масштабируется.
Но каждому Tablet нужна точка обслуживания, то есть в чьей памяти будет жить MemTable?
Кто будет добавлять в лог?
Должен быть какой-то узел, который это делает для каждого Tablet.
То есть данные хранятся на многих узлах в файловой системе,
но кто-то все равно должен обслуживать запросы,
кто-то должен хранить все MemTable, кто-то должен его дампить.
Этот узел должен быть один.
Так вот, Bigtable, сейчас я покажу в статье.
Bigtable использует Chubby, в частности, для выбора лидера.
И сам смысл лог-сервиса – это задача выбора лидера.
Вот тот, кто взял блокировку, он становится лидером среди других кандидатов
и как-то координирует действия других.
Но поскольку невозможно гарантировать, что лидеры только один во времени,
ну, пока невозможно, они могут конкурировать, нужно разделить их по эпохам.
Кто из них первый, кто второй, кто третий.
Игнорировать, блокировать старых лидеров.
Но вот ровно для этого у наших блокировок есть эти самые эпохи.
Или там Sequencer, неважно, как мы это назовем.
То есть вы выносите задачу выбора лидера и упорядочивания лидеров в такой вот сервис,
и он вам заменяет собственный multiprocess.
Ну а дальше это полезно тем, что вы можете, ну, у вас много распределенных систем
или много инсталляций распределенной системы,
и можно в каждой консенсус заводить, а можно установить, как бы,
развернуть один лог-сервис, и чтобы все им пользовались.
У вас в параллельном курсе будет ZooKeeper.
Это система, которая была написана как раз по мотивам Google Chubby.
Но что мне интересно, тут плохо опять видно,
что ZooKeeper, он решает те же самые задачи,
но в отличие от Chubby, вместо блокировок он вам предлагает атомики.
Потому что они говорят, что давайте сделаем лучше атомики,
потому что из атомиков можно сделать блокировки,
но как бы можно, как сказать-то, но можно lock-free или wait-free строить из них.
То есть это больше соответствует духу распределенных систем,
потому что wait-free это есть аналог сбоев, бесконечная пауза, но то есть сбой.
Поэтому в ZooKeeper нет lock-unlock, но зато вы можете построить обычный тикет spin-lock,
и мы это в лекции сделаем поверх атомиков, которые есть в ZooKeeper.
Короче, это все вот как бы связано, и все вот это это консенсус как сервис.
Это было такое длинное вступление в эту лекцию.
Сейчас последняя часть этого вступления.
Почему лекция так называется?
Потому что про Google Chubby была написана статья,
которая называется Paxos Made Life.
Почти мачится.
О чем она была? О том, что инженеры написали этот Chubby
и делятся своим опытом.
Они пишут, что если мы читаем код Paxos, то он там вмещается в одну страничку, там 20 строчек.
Но почему-то продакшн реализация на C++ занимает тысячи строк.
Как же так получилось?
Но вот они пишут, что дело не в том, что C++ многословный какой-то.
Дело не в этом. Дело в том, что просто есть зазор содержательный
между базовым алгоритмами репликации лога и нуждами промышленной системы.
Но она должна больше уметь, и она должна быть просто эффективнее,
лучше масштабироваться и быстрее работать.
И как раз сегодня на этой лекции мы поговорим о том,
какие задачи нужно еще добавить к Крафту или Мультипаксусу,
чтобы он сдеплоился в какой-то промышленной системе,
и как в нем можно что-то ускорить или промасштабировать.
Ну вот, давайте чего-то начнем.
Мы пишем RSM. Какие задачи нам необходимо решить,
что нам нужно сделать, чтобы вообще его как бы развернуть?
Во-первых, нам нужно выбрать число реплик.
Мы доказывали для произвольного алгоритма консенс сверхнюю оценку.
Выбираем число реплик.
Мы доказывали, что любой алгоритм консенсуса,
который гарантирует safety свойства agreement в любых сценариях
с любым количеством отказов, должен блокироваться, когда отказов слишком много.
То есть у него есть граница на отказоустойчивость.
Эту оценку сверху можно трансформировать в какую-то инструкцию для нас,
для разработчиков, для инженеров. Если мы хотим пережить f отказов,
то мы должны взять число реплик как 2f плюс 1.
Этого достаточно, а больше не нужно, потому что кворумы растут и становятся только медленные.
Маленькое замечание конкретно про паксос и мультипаксос.
Алгоритм паксос мы излагали в двух ролях, пропозор и аксепторы.
В мультипаксосе у нас есть пропозор, аксепторы, еще клиенты.
Так вот, если переложить оценку на роли, а не на число реплик,
если считать, что роли могут быть на разных узлах физически находиться,
то получится чуть более общим.
У нас есть клиенты, и они отправляют свои команды пропозорам.
Пропозоры общаются с аксепторами.
Вот их, допустим, тоже 3.
Мы должны сначала пройти через первую фазу, потом через вторую, потом через третью.
Один раунд трип, второй раунд трип. Первая фаза, вторая фаза.
Вот, команда зафиксирована в логе, и после этого мы можем отправить ее куда? На реплику.
Вот это все разные роли алгоритме.
Мы, когда говорили на прошлой неделе про мультипаксос, говорили, что это все один узел.
Но если мы их разнесем, то получится, чтобы пережить f отказов, нам нужно сколько пропозоров?
f плюс 1. Сколько аксепторов? 2 f плюс 1. Сколько реплика? f плюс 1.
То есть мы чуть аккуратнее сформулировали число ролей, которые нам нужны.
И если вдруг аксепторы отделены от пропозоров, а это может быть разумно по некоторым причинам,
как мы сегодня увидим, то можно сказать чуть точнее, что пропозоров нам много не нужно,
реплик у нас тоже много не нужно, нам нужно аксепторов много, чтобы коврово собирать.
Но смотрите, когда я говорю, что вот 2 f плюс 1, f отказов, значит 2 f плюс 1 реплик.
Я вот тут, ну и вы, наверное, тоже вместе со мной думаете неявно, что отказываете независимые.
Вот если мы хотим пережить 3 отказа, то, видимо, мы считаем, что возьмем сколько 7 реплик.
И почему мы берем 3 отказа? Потому что мы считаем, что ни разу не случатся. Невелика вероятность этого.
То есть диск может выйти из строя, но вот 2 разом или 3 разом это уже гораздо ниже вероятности.
Но это так, но не всегда. Потому что вы можете поступить неаккуратно.
Вы можете взять и свои реплики поместить, скажем, в одну стойку в дата-центре.
Помните, я показывал вам картинки, там шкафы такие, стоят в них провода.
Ну вот, у вас есть рэк.
Если там окажутся 2 реплики, то мы их можем потерять разом, потому что в этой стойке откажет коммутатор.
И в итоге мы потеряем все машины, которые в ней находятся, в том числе две реплики.
Поэтому любая разумная промышленная система не подбищает реплики в одну стойку, она знает про них.
В общем случае говорят про понятие, которое называется доменалказов, fail-domain.
Fail-domain это компонент инфраструктуры, который может выйти из строя разом, весь в результате какого-то одного сбоя.
Ну скажем, если у вас поломался диск, то вы потеряли машину.
Если у вас поломался коммутатор в стойке, то вы потеряли сразу много машин.
Ну стойки организованы в здании DC. В общем случае можно сказать, что это там зона доступности.
Почему вы можете потерять целое здание? Потому что, не знаю, пожар, наводнения, проблемы с питанием, не знаю, подстанции.
Ну там есть резервные питания, конечно, но всякое бывает. Выкопали кабели к этому DC.
Но можно подняться еще выше и говорить про регион целый.
Регион – это какая-то местность большая, в которой расставлены разные дата-центры на большом удалении друг от друга.
В чем смысл? В том, что вы можете потерять весь уровень из-за какой-то проблемы.
Начался ураган, смело DC просто все. Ну то есть это возможно.
Но вероятность коррелированного сбоя, она с ростом, с каждым уровнем в этой иерархии, она становится все ниже.
Вот здесь у вас есть один диск, и вы потеряете его и лишитесь машины.
Поэтому здесь у вас есть много машин с независимыми дисками.
Но зато с одним коммутатором или с двумя.
Но в дата-центре у вас уже много стоек, там немного коммутаторов.
Но правда у них у всех общая подстанция или общая система охлаждения.
Ну тогда вы переходите на уровень еще выше, там у вас это тоже задублировано.
У вас теперь много зданий, у каждого своя система питания, своя система охлаждения.
То есть вы, поднимаясь по уровням этой иерархии, резервируете то, что могло сломаться на предыдущем уровне.
И какая польза от этого знания?
Что когда вы говорите, что я выбираю 2F плюс одну реплику, вы должны сказать, на каком уровне вы находитесь.
То есть как вы их расставляете? Вы их расставляете по разным стойкам, или вы их расставляете по разным дата-центрам,
или вы их расставляете по разным континентам.
Понятно, что чем выше вы их размещаете, то есть выбираете разные континенты, например, тем вы снижаете вероятность кавелированного отказа.
Но с другой стороны, вы проигрываете, потому что у вас растут задержки.
Потому что, поднимаясь выше, вы просто ударяете друг от друга машины.
И здесь это, наверное, еще не очень страшно.
То, что вы по разным стойкам расставили, это бесплатно.
Но если вы размещаете их в разных дата-центрах, или в разных регионах, то вы получаете уже большие задержки просто по проводам.
Потому что вы в состоянии физически большие. Свету долго лететь.
И вы должны выбирать, на каком же уровне вы работаете.
Хорошо, с этим разобрались.
Следующий вопрос.
Даже не вопрос, а наблюдение, скорее, которое мы раньше не делали.
Почему вас беспокоит вот эта географическая удаленность рефликта друг от друга?
Ну, потому что вы же кворумы собираете.
Вы пересекаете там, не знаю, Северную Америку, Западу на Восток и Востока на Запад, или Афлантику пересекаете.
Вот здесь вот, когда кворумы собираете на фазах паксуса.
И вы так делаете для разных аксепторов.
Я весь семестр очень аккуратно говорил вместо слова большинства слово «кворум».
Вот кворумы, это еще одна деталь, которую можно...
Стойте, рано про кворумы.
Стойте, стойте, стойте.
Вот выбрали реплики, число реплик, расположили их, выбрали уровень в иерархии доминов отказов.
И вот реплики живут. Система ваша живет.
А потом что-то ломается.
Вот там совсем машина взрывалась. Ее раздавил бульдозер.
Или вы хотите повысить отказоустойчивость, добавить новые реплики.
Вот мы тогда этого момента не делали.
Мы всегда на каждой лекции говорили, пусть у нас есть там три реплики в мультипакс,
три реплики в рафте, там пять реплик, неважно.
Мы не меняем их состав, потому что плывут кворумы.
Вот смотрите, что вообще может произойти, когда вы захотите добавить или изменить состав вашей системы.
Почему так делать нельзя? Совершенно наивно.
Вот были у вас три реплики.
Одна вот, ну не знаю, все, она не нужна вам больше. Не нравится.
Вы хотите ее вытащить из этой конфигурации, из состава RSM, а новую добавить?
Можно ли так делать?
Ну, сообщить, ладно, ты не можешь всем сразу сообщить.
Вот, а вообще-то вот такая конструкция, она выглядит как...
Ну, если ты сделаешь тянение аккуратно, это все будет выглядеть как замена диска у машины.
В смысле, ты берешь и стираешь ее диск.
То есть у вас по-прежнему три реплики, но почему-то третья реплика больше не помнит никаких обещаний, ничего не знает.
А она раньше участвовала в кормах.
Ну, так себе идея.
Давай немного попроще сделаем. Вот у тебя есть три реплики.
Нет, пусть четыре есть. Это странно, конечно, что у тебя четыре реплики, но все же.
Ты хочешь, не то чтобы что-то поменять, ты хочешь отказустойчивость повысить и добавлять реплики по одной.
Вот ты хочешь пятую добавить, потом шестую, но сначала пятую.
Вот можете добавить пятую?
Какой quorum сейчас у этих реплик?
На большинство, да.
Вот, если мы добавим сюда пятую реплику, то кажется это безопасно.
То есть можно сказать иначе, что у нас было пять реплик с самого начала,
просто одна была мертва долгое время, потом ее все-таки реанимировали,
и вот она теперь в какой-то зоме появился.
Но quorum не возросли, поэтому абсолютно легальная операция.
Значит, это переход от четного числа к нечетному.
Странно, что у нас нечетное число возникло.
Оно возникло по пути, потому что до этого мы говорили про добавление к нечетному еще одного.
А вот так можно делать?
Но у нас сейчас quorum размера два.
А с четырьмя они должны увеличиться.
Стать размера три.
Вроде бы не безопасно.
Или безопасно?
Но смотрите, я добавляю этот узел сюда, видимо, ожидаю, что он знает про все существующие.
То есть у него у узла либо старая картина мира, где вот есть эта тройка и quorum и 2,
либо это новый узел, он знает про все, то есть у него quorum и 3.
Если мы расскажем этому узлу, что появился новый, то у него тоже будет quorum и 3.
Но окажется, что 2 и 3 на четырех узлах все равно пересекаются.
Что же получается-то?
Что я могу просто брать и добавлять по одному узлу, или нет?
Посмотри, к трем могу добавить один.
К трем могу добавить один.
В случае четного и нечетного исчерпались.
Но где-то обман, конечно, есть.
Ну не знают, она собирает quorum размера два, но это нормально, потому что quorum пересекаются.
А что им еще нужно?
Что?
Ну она же потом узнает, будет же она в неведении находиться.
Она же будет собирать quorum из трех узлов, или как?
Ну если она знает про это, значит она знает про все пять, получается.
Иначе странно.
Ну обман-то не в этом, в этом обмана нет никакого смысла.
Действительно ничего не ломается.
Проблема в том, что, а что если вам нужно добавить не один узел, а два?
Потому что, в конце концов, это ваша цель.
Чтобы сущность повысить, вам нужно добавить два узла к трем.
Вот.
Добавить один, а потом добавить один.
А что если вы прямо сейчас не можете достучаться до всех узлов?
И вот если вы добавите один, а потом еще один,
то вот уже неприятная ситуация может возникнуть.
У вас было три.
У вас есть еще два.
И они, допустим, про все знают.
Но у вас есть какие-то...
У вас есть узлы, которые знают только про очень маленькие quorums.
И вот у вас здесь какой-то есть узел.
Вот он почему-то считает, что quorum размера два.
Размер два.
Почему-то потому, что он жил в мире, где quorum были размера два.
Вот.
А теперь у вас еще есть этот узел и этот.
А они живут в мире, где quorum размера три.
И вот теперь они перестали пересекаться.
Ну, вы скажете, а давайте не будем добавлять машины,
пока все не знают про старое обновление.
Но это не очень отказоустойчиво, потому что если у нас partition есть,
то получается, мы не можем ничего сделать.
Если мы не можем синхронно достучаться до всех машин,
а мы не можем все так сделать, потому что в большом классе
всегда кто-то не работает, потому что диски поломаны.
И там их меняют, и перезагружают.
В общем, в этом наивном протоколе добавить один узел,
потом дождаться всех не работает то, что нужно дождаться всех.
Это не отказоустойчиво.
Поэтому тут варианта два.
Либо делать неаккуратно, ну тогда мы пожертвуем согласованностью,
потому что quorum перестанут пересекаться.
Либо, ну как не знаю, выключить все,
переконфигуировать, включить заново.
Вот нам это не нравится.
Мы бы хотели, чтобы мы могли переконфигуировать систему,
то есть заменять в ней узлы, добавлять новые,
ударять какие-то без остановки системы на лету.
Система продолжает работать, и при этом в ней меняется состав узлов динамически.
В чем здесь сложность?
В том, что если мы говорим про мультипаксос,
то в каком-то слоте этого мультипаксоса разные реплики могут разойтись
относительно конфигурации, в которой они работают.
То есть одна может быть, что у нас конфигурация вот такая из трех узлов,
а другая, что из пяти уже.
И в итоге quorum не пересекутся.
Вот беда в этом, что слот лога 1, задача консенсуса одна,
а миры конфигурации, в которых живут реплики, она разная.
Поэтому возникает очень естественное решение.
Какое?
Видимо, упорядочить конфигурации относительно остальных команд.
Да? Нет?
Тут у нас как бы реплики, которые совмещают в себе разные роли.
Нет, acceptor не должны ничего знать.
Acceptor это узел, который просто реагирует на сообщения.
Он ни с кем не общается.
Proposer должен знать.
Каждый узел тут и proposer, и acceptor.
Кому будет легче?
Я не очень понял, что ты предлагаешь.
А может быть столько же?
Ну вот зуки перейти одни и те же узлы, например.
Так что давай так считать.
Проблема не в том, что их меньше, а в том, что нужно до всех достучаться.
Это не отказуствует чего уже.
Так что делать?
Я же решение рассказал.
Нет?
Смотрите, в слоте разные proposer могут думать про разные конфигурации.
Ну вот давайте упорядочим смену конфигурации относительно остальных команд.
А что это значит?
Вот у нас есть реплика, у нее есть лог.
Давайте считать, что сначала, когда мы только RSM запустили в первый раз в жизни,
мы выдали всем репликам конфигурацию Ц0.
И вот реплика живет и знает, что во всех слотах лога нужно использовать конфигурацию Ц0.
А потом мы хотим перейти к конфигурации Ц1.
Что мы для этого делаем?
Мы администратор этой системы.
Вот смотрите, вот система, а вот администратор.
Что он делает?
Он посылает команду, которая называется реконфигурация.
Ну он просто ее предлагает.
То есть это такая служебная команда, которая не подается на вход, конечно же, автомату.
Но тем не менее, эта команда, она должна куда-то попасть в лог.
То есть пропозер, лидер должен выбрать для нее слот и положить ее туда.
Вот она сюда закомитилась.
Как-то нам помогло.
Но, видимо, давайте считать дальше, что мы до этого момента жили в конфигурации Ц0,
а с этого момента мы живем в конфигурации Ц1.
Что скажете?
Это нам помогает, что теперь все реплики понимают, в какой конфигурации нужно работать в каждом слоте.
А что нам еще нужно было?
Под конфигурация я понимаю набор узлов, которые образуют RSM.
Я хочу добавить две реплики.
Беда раньше была в том, что тебя один пропозер жил в одном слоте в одной конфигурации, другой в другом.
Ну вот я сделал переконфигурацию служебной командой и упорядочил ее через лог,
ну а через что мне еще упорядочивать их, с другими командами.
В итоге теперь я знаю, что вот здесь конфигурация Ц1, а здесь была Ц0.
Вот то, что это работает, сомнения же, не вызывает?
Ну в принципе-то понятен, да?
Это просто плохо работает, так делать нельзя.
Но хотя бы что это работает, понятно?
А почему это плохо работает? Почему так делать в продакшене нельзя?
Ну вот смотрите, вы реплика в мультипаксисе.
У вас есть такой лог.
Вот у вас есть какой-то закоммиченный префикс уже.
Ну то есть там какие-то команды лежат.
И вам приходят две команды.
Что вы с ними делали?
Ну что вы с ними делаете, что мы с ними делали в прошлый раз?
Ну вот мы запускаем два паксиса.
Один пытается положить команду move в пятый слот, а другой команду jump в шестой слот.
И мы живем в конфигурации Ц0 пока еще.
Вот утверждается, что уже все плохо.
Потому что у нас есть другая реплика, которая получила команду от администратора переконфигурации.
И сейчас пытается положить в слот 5 переконфигурацию.
Ей это удается.
И это означает, что команда в слоте 6 должна коммититься через паксис относительно конфигурации Ц1.
А мы уже начали состараться ноль.
В итоге пока мы не зафиксировали этот слот, мы не можем заполнять этот слот.
В итоге у нас теперь ноль параллельности. Мы команды коммитим только по одной.
Как это починить?
Тебя все устраивает, да?
Решение такое.
Ну как добавить больше параллелизма?
Мы не можем начать следующую команду, потому что здесь может быть переконфигурация.
Но это нормальная ситуация. Мы не знаем предыдущей команды, мы не хотим, чтобы нас ограничивало.
И даже если здесь окажется переконфигурация, мы не хотим, чтобы она у нас сразу влияла.
Как нам тогда перестроить наш алгоритм переконфигурации?
Давайте скажем, что переконфигурация имеет отложенный эффект.
Вот у нас сначала конфигурация Ц0, а здесь оказалась Ц1.
Вот это называется альфа-метод.
Грандиозное название.
Смысл в том, что конфигурация Ц1, если оно закоммитчено в слоте К, начинает действовать только со слота К плюс альфа.
Тут некоторые глобальные параметры, которые выбираются один раз, которые, видимо, лучше дальше не трогать.
И вот здесь мы живем в конфигурации Ц0, а здесь мы переходим уже в конфигурацию Ц1.
Так что у нас есть такое окно альфы, в которое мы можем параллельно предлагать команды.
Но если вдруг у нас есть команды, которые могли бы добавить в лог, но альфа-команд назад все еще не зафиксировано окно,
то мы должны остановиться и ждать, пока там что-то не закоммитится.
Понятная идея?
На самом деле это некоторый обман, потому что звучит очень просто, очень просто звучит.
А на самом деле там есть еще масса частных случаев, которые нужно решать, если вы пишете код.
Про это есть отдельная статья, мы не успеем все.
Хотя вообще-то было бы здорово написать.
Встребовался сразу.
Еще есть проблема в том, что у тебя есть ограничение на альфа, оно тебя тормозит, даже когда переконфигурации нет.
Это неприятно.
Вот какое-то место, которое можно было бы улучшить, но даже сейчас не проулучшен.
Вопрос такой очень хитрый.
Теперь вы знаете алгоритм RAFT.
Громко сказано, что знаете, пока не написали, не знаете.
Вы читаете статью, и там есть собственный протокол переконфигурации, собственный алгоритм.
Видимо, он там есть неспроста, но чем-то этот не устроил.
Вот оказывается, что RAFT с этой конструкцией не работает.
Я вот не знаю, то ли это сложный вопрос на зачет, то ли я хочу рассказать вам сейчас.
Как мне поступить?
Он останется на зачете все равно, а ты забудешь все равно.
Смотрите, вот жил был RAFT, у него было альф равно 3.
Выбрал был лидер, он получил три команды, записал их в три реплики.
Я, кстати, не сказал, что RAFT может реплицировать сразу пачки команд.
Он не по одной это делает.
Он собрал пять команд в клиента и сразу суффикс длины 5 отправил.
В общем, у него был префикс длины 3, он заполнил его тремя командами какими-то,
отреплицировал их на фоллеров и взорвался, перезагрузился вернее.
Команды не закоммичены, потому что он об этом никому не сказал и сам пока не знает.
Он стартует, перезагружается, стартует, переходит в следующую эпоху, в следующий терм.
Как ему быть дальше?
С одной стороны, чтобы работать дальше, ему нужно подумать, что с этим всем происходит.
У него есть три команды в логе.
Знает ли он, что они закоммичены?
Нет, чтобы узнать, что команда закоммичена, ему нужно закоммитить еще одну команду из текущего терма.
Вот, собственно, про это и было правило коммита в RAFT-е особенное.
Закоммитить четвертую команду ему нужно.
А с другой стороны, чтобы коммитить четвертую команду, ему нужно, если альфа-3,
чтобы он был уверен, что в логе в позиции 0 не переконфигурация, он этого не знает.
То есть, с одной стороны, переконфигурация и альфа запрещают ему коммитить новые команды.
С другой стороны, чтобы убедиться, что переконфигурации не будет, он должен закоммитить.
То есть, у него проблемы некоторые. Понятно или нет?
Еще раз, закоммитить новую команду он хочет, но не может, потому что альфа ему запрещает.
Потому что может быть переконфигурация.
То есть, делать ничего нельзя.
Еще раз, ты лидер, ты в терме 2, перезагрузился в терме 2, у тебя 3 команды в логе.
Ты получаешь новые команды от клиента, что ты с ними делаешь?
А как же ты можешь коммитить, когда ты не знаешь, что у тебя в логе в позиции 0?
Ты не уверен, что эта команда закоммичена?
Пока она не закоммичена, там может быть переконфигурация.
Но чтобы ее там не было, ты должен закоммитить этот префикс.
Но ты не можешь его закоммитить, потому что у тебя альфа исчерпалась.
Ну все, не нужно использовать этот протокол в RAFT.
Вот, собственно, поэтому авторы и не используют.
Неприятная ситуация. Так что RAFT еще в одном месте нас подкачал, подвел.
Итак, переконфигурация. Переконфигурация необходима для RSM.
Как мы без этого будем деплоить в продакшене все это?
Дальше. Что еще необходимо для продакшена?
Ну, чтобы вообще это все заработало.
Я говорил об этом на лекции про томик Broadcast.
Мы должны убедиться, что у нас автомат детерминированный.
Ну, то есть, да, RSM реплицирует логи, да, команды в одном порядке, история изменений.
Но при этом, если автомат будет делать недетерминированные переходы, то все поломается.
Вот. А с недетерминизмом сложно, потому что он может браться из разных мест.
Ну, например, не то чтобы вы монетки подкидываете, а дело в том, что вы можете использовать в своей реализации хэшмэпы.
А в хэшмэпах есть хэш-функции, а хэш-функции могут инициализироваться каким-то, не знаю, адресом в памяти.
Вот хэш-таблицы AppSale, Google AppSale, их Open Source библиотеки.
Очень быстрые хэш-таблицы так и работают.
И если вдруг вы запустили два процесса, то у них как бы выбираются две хэш-функции на разных узлах с разными параметрами,
потому что там адресное пространство процессорандомизируется.
Ну и все. В этих хэш-таблицах получается разный порядок итерации.
Если вдруг от него что-то зависит, то у вас реплики могут разойтись.
Ну или у вас время используется, вы там, не знаете, ставите атрибуты в DFS, время последнего обращения к файлу,
или последней записи в файл. На каждой реплике свои часы.
Вот непонятно, как там синхронизировать это все.
Или же у вас просто реплики меняют, вы обновляете код на репликах, код самого RSM.
Вы не можете выключить, а потом включить новую версию, это неэффективно, вы останавливаетесь.
Вы хотите на лету это делать. В итоге у вас есть реплики с новым кодом, реплики со старым кодом.
И вдруг они ведут себя немного по-разному, нужно об этом думать.
Они могут общаться на разных версиях протокола, нужно обратную совместимость поддерживать.
И вдруг вы здесь что-то нарушите, то реплики могут разойтись.
Вот нужно все это учитывать. Ну там в общем случае можно взять это недотерминизмом.
Еще одна проблема, которую необходимо решать в промышленной реализации, это семантика экзеклианса.
Точнее, это гарантия, которую вы очень хотите достичь.
Вы клиент, вы общаетесь с RSM, то есть общаетесь с какой-то машиной из этого RSM,
отправляете ей свою команду, эта машина, допустим, лидер, начинает ее реплицировать.
Допустим, даже это удается, а потом она перезагружается и соединение рвется.
И вы не понимаете, что произошло. То ли соединение провалилось до того, как команда применилась к автомату, то ли после.
Если вы ретравитесь в первом случае, то ничего страшного.
Если вы ретравитесь в втором случае, то вы применили команду дважды.
Она может быть недопотентная, может быть вы какой-то инкремент делаете или CAS.
Так что даже имея multipaxos или raft в своем распоряжении, вы сходу этот экзеклианс не получаете.
Это протокол, который должен быть делан частично на стороне RSM, а частично на стороне клиента.
И про это рассказывать не буду, потому что про это домашка есть следующая, так что будет.
Так что там вы попробуете придумать сами.
Ну вот про такие вещи статья Paxos Made Live.
Но я хочу поговорить не только про то, что вам необходимо делать, типа переконфигурации, экзеклианс,
а про то, что можно делать, чтобы RSM ускорить.
Потому что ускорить RSM или масштабировать RSM, это немного разные задачи, непросто.
Давайте про масштабирование говорить.
То есть что понимается под масштабированием?
Мы можем добавлять новые машины, система работает лучше, быстрее, производительнее,
у нее растет пропускная способность.
Вот у RSM при добавлении реплик ничего лучше не становится, становится только хуже.
Потому что отказоустойчивость растет.
Ну как бы, бог с ним, мы уже ее выбрали, зафиксировали с самого начала, сколько мы готовы отказов пережить.
А дальше мы хотим при заданной отказоустойчивости просто увеличивать число запросов, которые RSM способен перевалить.
И тут беда, потому что просто добавлением узлов ничего делу не поможешь.
Мы добавляем еще 10 аксепторов и становятся только хуже.
Quorum растут, самая медленная машина из Quorum остановится еще как бы дальше от нас,
в смысле дальше по времени, еще медленнее, поэтому мы все медленнее делаем.
Мы хотим, наоборот, быстрее и больше.
Вот давайте подумаем, в чем проблема, почему RSM медленный?
Кто в этом виноват?
Ну это неизбежно, если ты используешь консенсус.
Мы не можем этого избежать.
Тут есть разные места, которые можно тюнить.
Вот давайте я вам покажу сначала.
Есть очевидное место.
Вот у вас есть лидер и через него все проходит.
На нем очень много работы.
Ну буквально вся работа.
Вот.
Но это понятное точка, понятное узкое место.
Я хочу вам рассказать про неожиданное узкое место.
Не то, что про узкое место, а про место, в котором можно неожиданным образом что-то потюнить.
Про кворумы.
Вот я весь семестр очень аккуратно говорил про кворумы.
Говорил всегда не о большинстве, а о кворумах.
Потому что сегодня кворумы перестанут быть большинством.
Помните ли вы, как мы доказывали корректность паксуса?
Или рафта?
Это одно и то же.
Вот мы два кружка рисовали.
Но это были разноцветные кружки.
Почему разноцветные?
Потому что здесь была фаза prepare, а здесь была фаза accept.
То есть мы говорили, что если значение выбрано, то есть за него проголосовали большинство accept,
ну, кворум аксепторов,
и если у нас появился какой-то пропозор с большим номером, с большей эпохой,
и он прошел через фазу prepare,
то обязательно в пересечении будет какая-то реплика.
И это означает, что через эту реплику этот новый пропозор узнает про уже выбранное значение и его не поменяет.
Так вот, из этих рассуждений следует нехитрое наблюдение.
В алгоритме Paxos мы нигде не требовали, чтобы, скажем, пересекались кворумы одной фазы.
Нам достаточно пересечение кворумов разных фаз.
И вот я сейчас собираюсь здесь и здесь использовать разные кворумы.
Раньше у нас были просто большинства, и любые два большинства пересекаются.
А теперь я хочу разделить систему кворумов на две.
Значит, система кворумов, которая про первую фазу и система кворумов про вторую фазу.
Как это мне поможет? Как я собираюсь это использовать?
А я собираюсь сейчас увеличить количество аксепторов.
Вот давайте я возьму 10 аксепторов.
Сначала нарисую тупо. Раз, два, три, четыре, шесть. Отлично, 10 аксепторов.
И давайте я буду в качестве кворумов...
Ну и смотрите, что важно-то, что в алгоритме multipaxos есть кворумы более частые и более редкие.
Репер — это выбор лидера нового. Он редко происходит.
Зато на каждую команду собирается кворум из аксептов.
То есть в RAF-те у вас есть иногда кворум на request-vote,
и всегда кворум на append-entries при каждой репликации, при каждой команде.
Так вот, давайте сделаем кворумы, которые собираются чаще, поменьше.
Вот я скажу, что у меня кворум на accept будет вот такой вот.
Три. То есть любая тройка.
А кворум на prepare какой у меня станет?
Ох, ну пусть 8.
Не слишком клёвая идея пока, но в таком виде.
Ну не клёвая идея здесь, а здесь она клёвая.
Понятно ли почему?
Что я собираюсь здесь выиграть?
Но в чём профит-то?
Если бы я взял с самого начала пять реплик, то у меня было бы...
То есть смотри, я переживаю по-прежнему два отказа.
Два отказа мне достаточно сколько реплик взять? Пять.
А я взял десять. И переживаю два отказа.
Где-то должен быть смысл.
Вот я собираюсь не число отказов увеличивать, потому что я отказы зафиксировал.
У меня устраивает два. Я хочу accept разгрузить.
Я сделал их больше, и хочу что сейчас сделать?
Понятно или нет?
Ну да, можно сказать, что если мы хотим из десяти выбрать три быстро,
то это проще, чем из пяти.
Там меньше шансов, что кто-то будет тормозить.
Но смысл не в этом.
Вот смотрите, есть технология RAID. Знаете про неё?
Это redundant array of independent disks.
То есть это способ брать диски и строить из них такие виртуальные диски,
у которых отказоустойчивость вышла, но какие-то свойства лучше.
Вот есть разные уровни RAID. Вот есть RAID 1,
когда мы берём два диска, и когда пишем блок в диск, то мы пишем в два диска сразу.
Отказоустойчивость повысилась.
А можно делать RAID 0. Вот RAID 1 это mirroring, то есть мы беззеркалируем диски.
Они одинаковые теперь. А есть RAID 0, это striping.
Мы когда пишем, пишем сначала то на один диск, то на другой, потом на один диск, то на другой.
В итоге у нас пропускная способность удваивается. Мы пишем два раза больше.
За одно и то же время.
Смотрите, вот есть система, которая называется lock device.
Это система очередей, которую написали в Facebook.
У нас будет на лекциях кавка, это что-то похожее, но не совсем.
В первом пробежении пусть будет похоже.
Раид там использует консенсус, во-первых.
Ну вот, вы можете почитать. Вот тут есть история про консенсус.
У них есть слайды, и смотрите. Ну вот они сначала говорят, вот возьмём,
действительно тупо очень сделаем, возьмём большие кворумы.
Кворум на PPR огромный, кворум на accept маленький.
Зато мы можем теперь выбирать, на какие аксепторы мы пишем какие данные.
И чередовать. То есть первую команду мы запишем на эти три.
Вторую команду мы напишем на эти три. Третью команду на эти три.
Четвёртую команду мы вообще как-то разбросаем.
В итоге каждый аксептор будет обрабатывать меньше команд, у него будет меньше работы.
Нагрузка на каждую машину будет меньше. Отказоустойчивость та же.
Но эти машины остаются разгруженными, более разгруженными.
Ну как бы для RAF это не подойдёт вообще.
Потому что никогда не поздно рекламировать Paxos в лишний раз.
В RAF протокол работает, когда вы знаете предыдущую команду в логе.
Здесь вы не знаете, а Paxos всё равно.
Поэтому вы можете выбирать разные тройки и в итоге писать несколько раз быстрее.
Что делать к клиенту?
Смотрите, LogDevice это система очередей.
Она просто слушает все реплики и из них клеит один непрерывный лог.
Понятно ли идея?
Ну вот так можно всё промасштабировать.
А теперь...
О, это было чётче.
А теперь про вот эту штуку.
Кворумы маленькие на второй фазе мы можем использовать.
А теперь гигантский корм на первой фазе. Можно сделать умнее?
Расскажи.
Наверняка можно, да?
Сейчас. У нас 10, да?
Да, я по-другому нарисую картинку.
Пусть стало сколько? 12?
12.
Допустим, я хочу выбирать кворумы зелёные маленькими.
Вот, как мне теперь строить кворумы первой фазы, но не такие большие?
Ну вот, можно взять строчку, да.
Вот это то, что называется Great Quarums.
Ну то есть мы, сохраняя отказоустойчивость, зафиксировав её,
и зафиксировав размер кворума для второй фазы, который позволяет нам делать striping,
можем уменьшить кворумы до первой фазы.
Так, чтобы они всё равно пересекались. Нам этого достаточно.
Но вот так делать всё равно не нужно.
Почему? Потому что это уже следующая ступень понимания
кворумов.
Почему вообще у вас столько машин?
Вы хотите что-то ускорить.
А с другой стороны, вы хотите повысить отказоустойчивость.
Ну, в смысле, с другой стороны, у вас отказоустойчивость беспокоит.
Вот, есть некоторая недоработка у нас. Мы выбрали себе f
и сказали, что вот для f нужно 2f плюс 1.
Ну, если вы говорите о разной уровне доменов отказов,
то отказы же бывают на разных уровнях.
Это просто отказ из одного узла. Но f – это количество узлов, которые мы можем пережить.
Но вообще-то у вас может не узел сломаться, у вас может до центра выйти из строя.
И вы потеряете сразу много узлов.
Поэтому, когда вы говорите, что я выбираю себе отказоустойчивость f,
вообще-то у вас не одно должно быть f, а разные f.
Я готов пережить сбой, потерю 1 dc целиком.
Или 2 dc целиком.
Так что у вас есть f маленькие, есть f побольше.
И вот смотрите, пусть у вас 12 машин, но они находятся в 4 dc.
Приберите зону.
Вот 4 штуки.
И допустим, вы берете такие кворумы. Вот чем это вам грозит?
Но если мы говорим про репликацию, если одна зона умерла,
1 dc отказал. Это не страшно, потому что вы пишете в другой dc.
Пока хотя бы один жив, кворум собирается.
Но в такой системе кворумов смерть любой зоны доступности, любого dc
автоматически убивает любой кворум на фазу 1.
Так что ваши кворумы с одной стороны переживают 2 любых отказа,
а с другой стороны они не переживают смерть 1 dc.
А мы не можем гарантировать, что ее не будет.
То есть это просто один отказ фактически. В смысле это одно событие.
И оно нас сразу убивает. Поэтому как быть?
Вот выберем себе 2 f. Скажем, что f маленькое это 2 отказа,
мы готовы пережить отказ 2 любых машин.
И мы готовы пережить смерть 1 f большое около 1 dc.
И какие мы кворумы построим?
Я сейчас нарисую примеры, вы поймете, надеюсь.
Вот я беру из каждого dc majority просто 2 машина.
Сейчас, ну, ерунду конечно написал. Здесь один в каждом dc.
Нет, 2 наверное тоже зайдет.
Я беру majority в каждом dc и для одного кворума беру на уровне zone.
Я беру с одной стороны f плюс 1 zone для 2 фазы.
А для первой фазы беру число zone минус f.
И в итоге я переживаю здесь, ну, в каждом dc смерть машины,
я переживаю смерть всей зоны целиком. Я просто как бы ее обойду.
Ну что, понятна идея?
Ну, это кворум, смотри, ты для кворума выбираешь прямоугольных себе.
Ты выбираешь число машин в каждой зоне, вот эта сторона,
и число зон, которые ты захватываешь.
Вот я для двух кворумов выбираю во второй фазе f плюс 1 зону,
чтобы пережить отказ одной, чтобы не потерять данные, которые я записал.
А здесь я беру z минус f, чтобы эти кворумы пересеклись с одной стороны.
То есть если я беру f1, то я беру здесь 2 зоны, здесь 3 зоны,
и мне не нужно всех четырех сразу. Вот так что я одно могу потерять.
Вот здесь вот? И здесь проблема была в том, что когда у нас умирает дата-центр,
то мы теряем весь столбец, а один столбец убивает нам любую строку.
Да можно вообще полную вещь творить.
Представь себе, любой путь с севера на юг, с запада на восток, они где-то пересекутся,
но это уже математика, это не программирование.
Что делает Фейсбук в своей системе? Они делают еще сложнее,
потому что они думают не только про смерть ДЦ, они думают еще про смерть регионов.
Вот сейчас мы постараемся разглядеть.
Сейчас, у нас есть три региона, вот есть Орегон, Каролина, Северный и Техас.
В каждом регионе есть 3 ДЦ, а в каждом ДЦ две машины.
Ну в смысле машин-то много, это в смысле реплики.
Вот мы хотим, чтобы у нас для наших данных, для нашего лога в Логдевайсе
реплики были в трех зонах, в 9 ДЦ, в 18 копиях.
И когда мы собираем кворум на запись, ну мы их размазываем, чтобы был страйпинг,
а с другой стороны мы выбираем такой кворум, чтобы в нем было 4 узла как минимум,
из трех зон как минимум и из двух регионов.
И вот если такой кворум собирается, то все.
То есть тут мы не говорим, что мы отправляем данные на все узлы и дожидаемся кворума.
Мы вот именно выбираем под множество, на него отправляем.
За счет этого нагрузка на отдельные реплики снижается, и при этом мы переживаем отказ
трех узлов двух зон доступности одного региона целиком.
Ну как? Понятно? Вот такие системы кворумов.
Тут можно, конечно, совершенно дикие варианты изобретать.
Я просто показываю, что в продакшене люди используют.
Окей, идем дальше.
Что нас еще беспокоит с точки зрения производительности, с точки зрения масштабируемости?
Ну у нас есть совершенно тупое место, совершенно тупое узкое место, которое нужно сразу же пооптимизировать,
а мы этого не делаем. Вот есть лидер. К нему приходят клиенты все.
И лидер для каждой команды запускает свой консенсус.
Свои фазы там проходят. Ну одну фазу, две фазы, неважно.
Для каждой команды у него отдельная запись в логе.
Как это пооптимизировать? Как уменьшить работу на одну команду?
Ну вот нужно, я не знаю, поставить перед клиентами еще слой прокси.
Вот они набирают запросы с клиентов, строят из них пачки и уже их отправляют лидеру.
Вот они накопили за полсекунды 2000 запросов, упаковали их в одну пачку и отправили.
В итоге у нас вся работа РСМ относительно пачек происходит уже.
То есть на уровне автомата это все распаковывается в отдельные команды, но вся промежуточная деятельность,
то есть мы не делаем тысячу фаз, мы не делаем тысячу аксептов, мы делаем один аксепт для пачки.
Вот это такая была наивная оптимизация.
Что? Сколько не жалко? Ну f плюс один, по крайней мере.
Что? Ну это такое естественное место, чтобы, не знаю, отделить одно от другого.
Просто лидер занимается массой вещей. Он бачит команды, он выкладывает их в лог, он собирает кворумы.
Вот все это можно разнести. Скажем, вот собирать кворумы тоже можно делегировать работой кому-то,
потому что как бы кворумы в разных фактах собираются независимо, поэтому можно было бы...
Ну это уже такая странная оптимизация, она в академических статьях есть, а в продакшене я не слышал, чтобы вот прямо так делали.
Но есть оптимизация суперважная, которую необходимо делать. И про нее я тоже когда-то рассказывал уже.
Должен был. Итак, вы лидер, вы получаете команды.
И я говорил, что вот на уровне мультипакса или рафта вы не знаете, что это за команды.
Вы просто их упорядочиваете, кормите ими, стоит машина, она дальше уже реагирует на них.
Вот кое-что полезно было бы знать. Полезно было бы различать...
Полезно было бы различать команды, которые изменяют состояние, которые не изменяют состояние автомата.
Как бы это вам помогло?
Совсем наивно. Вы сервис-блокер, киволю хранилища, и вам сыпется операция пута и гета.
И гетов у вас в сто раз больше, чем путов. Ну так жизнь устроена.
А вы, тем не менее, и эти геты не меняют состояние автомата.
А вы все все равно проплетите через лог, через RSM.
Вот может быть, можно быстрее делать, раз они не меняют состояние.
Вот можно ли просто прочесть текущее состояние с реплики и ответить клиенту сразу?
У нас же есть копия киволю хранилища, ну там какого-то кусочка его таблито.
Вот читаем сразу локальные значения и отдаем пользователю.
Но это, конечно, работать не будет, потому что у вас реплики могут отставать,
у них могут быть пустые логи, по крайней мере, в мультипаксесе.
Если они будут отвечать на чтение, то будет странно.
Это называется stale read. Устаревшее, протухшее чтение. Мы такого не хотим.
Вот, следующая идея. Давайте пусть лидер отвечает на чтение.
Он-то точно знает, что происходит? Почему это не работает?
У него такая нагрузка и была.
Это что же еще? Я говорю, чтобы вместо того, чтобы команду в лог запускать,
я просто прочту без лога. Нагрузки меньше станет. Это моя цель.
Я же увеличиваю пропуску способности системы. Будет ли это работать?
Это супер понятно звучит. Ты лидер, у тебя есть полная история,
ты получаешь чтение, локально его обслуживаешь, возвращаешь сразу.
Дело не в том, что лидер будет жить или нет, а дело в том, что он думает,
что он лидер, но у других может быть другое мнение по этому поводу.
То есть ты в multiplex выиграешь себя как избрался сам лидером,
потому что у тебя самый старший ID. Но ты просто в маленькой части partition находишься,
а в апдейтах не знаешь, они к тебе не попадают.
Думаешь, что лидер, а в другой половине кластера в большей части,
уже новый апдейт копится. И ты их не учитываешь, когда отвечаешь.
Ну понятно, что у вас тут три реплики, вот partition, и вот здесь лидер новый,
здесь лидер все еще старый, а все запросы ходят сюда,
и все мутации происходят здесь. А вы здесь без общения с другими отвечаете сразу клиенту.
Как это подчинить?
Мы даже про это сегодня говорили в контексте RAFTA.
Ну так придумай.
Ты можешь быть уже не лидером, думать, что ты лидером,
но не важно, для multipax, для RAFTA все равно одно и то же.
Вот у тебя есть какой-то лог у тебя, у лидера.
Вот если он полный, то все хорошо, безопасно ответите на чтение без консенсуса.
Но может быть, у тебя в системе есть новый лидер, у него лог уже более полный,
он больше того накомитил. Ну давайте опросим Quorum.
Если у нас есть альтернативный лидер, который успел закомитить что-то еще,
то мы с его Quorum на запись пересечемся, и от реплики в пересечение узнаем, что мы отстали.
Понятная идея, да? В случае RAFTA мы можем просто опросить Quorum и узнать,
верно ли, что есть Quorum с нашим термом. Если Quorum с нашим термом не набирается,
значит, видимо, кто-то ушел вперед уже, есть новый лидер, он что-то успел закомитить.
Но вот это все все равно выполняется на лидере.
Но вот эту идею можно вынести на все остальные реплики.
То есть размазать чтение не только... все записи, например, RAFTA проходят через лидера,
это неизбежно. А вот чтение можно размазать по остальным узлам.
И это, конечно, сильно лидеру поможет. Как это сделать?
У вас есть реплика, у нее есть какой-то лог, но не то чтобы полный.
Она возьмет и опросит Quorum и узнает старший индекс, который в логах Quorum есть.
Но не факт, что все команды закоммитчены. Может быть, какие-то закоммитчены,
какие-то только будут закоммитчены. Но безопасно... вот этот старший индекс вот здесь.
Вот безопасно узнать этот старший индекс, а потом подождать, пока до него все не закоммитится.
Тогда мы учтем все завершенные к моменту запросы команды и часть команд, которые с нами конкурировали.
То есть так или иначе чтение линейризуется относительно других записей.
Так что мы опрашиваем Quorum и ждем. Но причем, разумеется, это можно делать сразу для пачки команд.
То есть мы получили тысячу чтений, опросили один раз Quorum, узнали, что самый длинный лог на 300 дальше чем наш,
подождали, пока 300 заполнится, и после этого ответили сразу на тысячу запросов.
Вот так можно разгрузить лидера на чтение. А можно сделать еще лучше.
Потому что... сделать еще лучше в том смысле, что избавиться от этого Quorum.
То есть вообще ни с кем не общаться и при этом отвечать.
Но мы так уже делали, ни с кем не общаться и что-то делать при этом в True Time.
То есть мы время задействовали. Вот мы сейчас делаем то же самое.
Смотрите, вы лидер в эпохе там, не знаю, три, в терме три.
И вот вы были бы рады отвечать на запросы на чтение без коммуникации с другими узлами.
Но вы так не можете делать, потому что в терме вы единственный в RAF, но может уже начаться новый терм
и с вами конкурировать во времени. Давайте сделаем так, что устроим такую процедуру,
чтобы гарантировать, что лидеры не могут пересекаться во времени.
Если мы это гарантируем, то можно будет отвечать на чтение сразу, локально, ни с кем не общаясь.
Вот я сегодня писал уже слово Лиза. Вот мы сейчас построим Лизу.
Это речь про лидера. У лидера полный лог, у него может быть не полный лог,
только потому что появился уже новый лидер. Вот если мы разобьем их во времени, то все будет хорошо.
Итак, мы стали лидером.
Что надо делать дальше? Мы не хотим, чтобы с нами кто-то пересекался во времени.
Поэтому давайте мы попросим всех остальных реплик.
Скажем, пожалуйста, не голосуйте,
не голосуйте, пожалуйста, со других лидеров в течение времени дельта.
Ну и, допустим, мы собрали к ворам подтверждения.
Одного хватит, потому что мы сами себе тоже верим.
И вот реплика R3 и R1, если они дали подтверждения свои, то они в течение некоторого времени дельта
в новых выборах не участвуют.
Вот дельта – это как бы зазор, когда мы можем быть спокойны, что конкурентов у нас не будет.
Правда, дельта вот здесь отчитывается от этого момента времени.
Здесь был T0 какой-то, здесь T1, T2. Вот мы эти T1, T2 не знаем.
Но мы знаем, что T0 не больше, чем T1 в любом случае.
Поэтому мы у себя дельта отчитываем от отправки нашего сообщения.
И вот от этого момента вот до этого момента мы точно можем обслуживать чтение локально,
ни с кем не общаясь, потому что мы уверены, что вот до этого момента точно другие реплики
не могут участвовать в выборах, отдавать голоса и выбирать нового лидера.
Мы сейчас говорим скорее про RAFT, но про Paxos тут нужно какие-то еще пары замечаний сделать, я ренюсь.
Давайте про RAFT. Какие выбирать дельта?
Ну, сейчас, большие, Grand Lease, маленькие выбирать плохо, потому что мы же хотим надолго
получить уверенность в том, что с нами не конкурируют, а большие выбирать плохо,
потому что если мы вдруг умрем, то мы заблокируем систему надолго.
Поэтому мы выбираем небольшое дельта, но когда время подходит, мы просто обновляем свою ризу.
Ну, то есть мы сказали, мы еще живы, мы еще живы, мы еще живы, пожалуйста, сохраняй обещание.
То есть если мы вдруг перестанем это, то есть дельта небольшая, если мы вдруг умрем
и перестанем эти ринью отправлять, то реплика понимает, что, видимо, все, нас нет,
и можно про обещание забыть спустя дельта. И вот этот период будет небольшой,
то есть мы подвисим систему ненадолго, потому что пока эта дельта живет, у нас система не может
восстановиться после сбоя узла. Но все-таки нам хочется, мы же лидер стабильный,
мы надолго выбрались в RAFT на неделю, и вот мы хотим, чтобы всю неделю мы могли обслуживать
чтение без коммуникации с другими. Понятно? Вот, что здесь может не работать?
Но мы здесь используем время, время это опасно довольно.
Вот какие предположения о времени мы сейчас делаем?
Где это мы делаем такое предположение?
Сейчас, ну, t1 больше, чем t0, не меньше, чем t0 по причинам хода времени, что найдет вперед.
Да, но мы это точно уверены, в смысле, t1 и t0 это время абсолютное, его никто не знает,
но это неважно. Где ты здесь сравниваешь t0 и t1? Сравниваешь где-то?
Ты не сравниваешь, что надо делать, только заводишь локальный таймер на время дельта,
и твоя задача – успеть отправить renew и получить ответ до того, как этот таймер растечет.
Время раунд-tрипа, конечно, меньше, да, это больше, чем время раунд-tрипа,
чтобы запас, чтобы не протухал часто.
Вот время идет с одинаковой скоростью, то есть часы не дрейфуют.
А что будет, если они, например, вот здесь будут спешить?
То мы откажемся от обещания раньше, чем, то есть лидер этот будет думать,
что обещание все еще в стиле, а мы от него отказались уже.
Если здесь часы будут замедленно идти, то получается, что будем ждать дольше, чем нужно.
Поэтому мы берем вот этот ro, который был, значит, миллионные доли,
в которых часы могут торопиться или опаздывать, и здесь мы, получается,
интервал немножко увеличиваем.
Время ожидания увеличиваем.
А здесь мы локально его пессимизируем.
Х, это умножить, да.
Ну вот, и тогда все должно быть хорошо.
Покажу вам...
Я вам не рассказывал про Джепсон, совершенно напрасно, но еще повод представиться.
Есть человек, его зовут Карл Кингсбри, он занимается тем, что ломает базы данных.
Ну, в смысле, это его хобби, но работа его, которая, кажется, началась с хобби.
Я вам уже показывал этот сайт на самом деле.
Здесь была диаграмма модели согласованности, помните ее?
Вот, он тестирует промышленные базы данных чаще всего, кучу систем.
То есть он тестирует их на выполнение модели согласованности.
То есть ему говорят, система линеризуемая.
В буклете рекламной написано, он берет и начинает задавать запросы,
при этом ломая сеть, ломая узлы, ломая часы, и проверяет, верно ли,
что во всех исполнениях она будет линеризуемой.
И вот у него есть...
Ну, кстати, это смешно, потому что я сегодня про ETCD уже упоминал.
Ну, в смысле, он берет виртуальные машины, начинает между ними настраивать кучу униксовых футилит,
которые позволяют себе сеть настраивать.
Но он делает это прям с кодом и с настоящим всем этим секундом.
Вот я вам показывал уже про ETCD сегодня, про то, что из-за этой системы возник доунтайм на 6 часов,
из-за того, что сеть поломалась, и Рафт к этому был не готов.
Вторая история про ETCD, но это случайно получилось на...
Вот, вторая история.
Он говорит, что он запустил систему, ну, в смысле, запустил тест и получил нелинеризуемое исполнение.
И дело оказалось...
И он написал об этом разработчикам.
Мне кажется, даже выяснил, в чем дело было.
Он написал разработчикам, и они сделали патч.
И этот патч его то ли взбесил, то ли насмешил.
Вот патч выглядел так.
Сейчас найду его.
Сейчас тут видно название коммита, да?
Ну, вот как бы изменилось это дельта, и вот система стала проходить тест.
Но это, конечно, не является надежным фиксом этой проблемы.
Смотрите.
Какова здесь мораль?
Мораль в том, что вы здесь, используя время,
подвергаете угрозе нелинеризуемой своей системы.
Если вдруг у вас действительно вот эти...
Ну, где-то что-то будет быстрее и медленнее,
вы можете ответить на запрос локальным чтением,
а при этом вы уже можете быть нелидером,
и чтение станет старым.
Так что вы здесь безопасность рафта нарушаете, вмешиваясь в его протокол упорядочивания команд.
Так что автор советует отключить эту опцию.
То есть ее не нужно отключать, конечно.
Она для масштабируемости важна, для пропуску способности.
Но, тем не менее, вы должны что-то выключивать здесь с запасом.
И у вас страйдов такой.
Либо время паузы при смерти узла, либо линеризуемость.
Ладно, последнее, что я расскажу,
не расскажу даже просто коротко, за 5 минут.
Что еще можно пооптимизировать в мультипаксисе или в рафте?
Ну, что мы сделали?
Мы здесь устроили страйпинг на аксепторах.
Мы здесь сделали бачен для того, чтобы просто на одну команду было меньше работы.
Мы поэкономили на чтениях.
Но еще есть одна функция, которая вот плохо масштабируется.
Это упорядочивание команд.
Вот все равно у вас есть лидер, который принимает все команды
и выкладывает их подряд в лог.
И это выглядит почти неизбежно.
И вот то, что у вас лидер один, через него все проходит,
является особенно печально, когда у вас система геораспределенная.
Вот пусть у вас есть три реплики в Северной Америке,
в Европе и где-нибудь еще далеко.
Восточном, Западном побережье в Европе.
Вот далекие машины.
Свет долго идет.
Почему вам от RSM плохо?
С одной стороны, мы пооптимизировали фазу в мультипаксисе.
Ну или в рафте просто всегда одна фаза в репликации.
В мультипаксисе почти всегда одна фаза.
Но у вас же относительно лидера одна фаза.
Но с другой стороны, вам нужно сначала на лидера команду принести.
То есть у вас один раунд трип от клиента до лидера
и один раунд трип кворумный.
От лидера до реплик.
И вот то, что у вас кворум собирается в геораспределенной системе, это неминуемо.
Но плохо здесь то, что вы клиент, находитесь в Европе,
а лидер сейчас находится в Штатах.
И вы просто чтобы прислать ему команду должны отправиться сначала туда,
а потом еще раз обратно.
А потом еще раз обратно, чтобы ответ получить.
То есть вы делаете два раунд трипа через Атлантику.
Так вот, есть подходы в вариации мультипаксиса,
где строится не линейный порядок на командах, а частичный порядок на командах.
И система становится симметричной в том смысле,
что у вас все пропозеры могут выстраивать часть своего порядка.
И в итоге, если все идет хорошо, то вы делаете только один раунд трип через Атлантику, а не два.
То есть вы ходите к своей близкой машине и не ходите далеко.
Ну вот, в общем, ровно поэтому в мультипаксисе 100 статей было на странице, я вам показывал в прошлый раз.
Потому что вот каждое место можно потюнить более-менее.
Ну в RAFT все же, в RAFT так делать не стоит,
но потому что вы видели, даже переконфигурации нельзя потюнить, там можно что-то сломать.
Ну в меньшей степени свободы.
Ну что ж, наверное, это все, что у меня поместилось сегодня.
Но я не рассказал вам до конца историю, потому что RSM, RSM еще кое-чего не хватает.
Это я вам рассказывал в следующего семинара, наверное.
Вот у вас RSM держит лог.
И он растет, растет, растет. Что делать, если он переполнится?
В смысле, он растет бесконечно.
Что делать, если у вас машина перезагрузится?
Что, историю заметить накатывать на себя, что ли?
Или просто у вас лог слишком большой, но он не помещается уже в одну машину, нужно что-то с ним делать.
Ну вот, мы не поговорили про то, как этот лог сокращать, как делать снапшоты,
как вообще работать с диском надежно.
Ну вот в следующий раз мы об этом и поговорим, наверное.
Про то, что файлы это сложно.
Файловая система это сложно. Если вы хотите сделать это надежно,
это сложно не только потому, что машины отказывают,
а потому что еще файловая система работает очень странно.
Не так вы от нее ожидаете.
Ну на сегодня все, спасибо.
