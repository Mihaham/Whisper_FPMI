Коллег, один из студентов, я бы хотел вам его задать.
Я предлагаю это даже на запись уже включить, все, скринкаст
запись экрана тоже пошла, 3-2 раз, 1-2-3, потому что вопрос
достаточно актуальный.
А именно, вот есть у вас лабораторная работа, там как раз есть
задачка применить PCA, куда-то все спроецировать, и тут
скорее вопрос не про лабу, а про PCA.
Если у вас нет главных компонентов, применяем
к самой выборке, к самому датсету.
Внимание, вопрос.
Вот мы взяли с вами PCA, взяли датсет и выбрали
количество главных компонентов, равное количеству признаков
в нашем датсете.
Условно у нас была 10-мерная выборка, 10 признаков, мы
взяли 10 главных компонентов, применили, PCA соответственно
выучили все главные компоненты, на них отобразились.
Получили ли мы тождественное преобразование или нет?
Нет.
Кто за да, кто за нет, подумайте, пожалуйста.
Вопрос, есть ли метод главных компонентов, в качестве
главных компонентов используют столько же главных компонентов,
сколько у нас координатных осей в байсе пространства?
Получим ли мы тождественное преобразование или нет?
Ну вот, коллеги с правой части для меня зала считают,
что нет.
Коллеги с левой части зала.
Ну да, домножаем, вопрос, эта матричка будет единична
или нет?
Хороший вопрос.
Ну давайте, кто за то, что да, оно тождественное?
Даже те, кто спрашивали, говорят, что уже нет.
Кто за то, что нет?
Большая часть аудитории воздержал, я понял.
Ну хорошо, давайте те, кто за то, что нет, дадут какое-нибудь
обоснование.
Ну пожалуйста, вот вы говорили в начале.
Ага, классно, пример с овальчиком, работает.
Если вы эллипс нарисуете, у вас первая главная компонента
будет направлена вдоль первой главной полуаси.
Вообще не обязательно, что она совпадает с осью
координат.
Теперь как это обосновать в общем случае?
У вас главные компоненты – это направление наибольшей
дисперсии по убыванию, если вы их отсортируете.
Соответственно, у вас направление наибольшей дисперсии вовсе
не обязательно координатной оси вашего пространства,
тем более в том же порядке.
Поэтому, конечно же, в общем случае PCA все равно меняет
ваше пространство признаковое.
По сути, вы его поворачиваете.
Так что, если вы примените к выборке PCA и сохраните
количество компонентов, равным количеству координат
осей вашей выборки, вы просто-напросто в другой
базе спирейете в том же пространстве.
Вы не потеряете ни йода информации, у вас все останется
на месте, но тем не менее база у вас будет другой.
Данный вопрос понятен?
Супер.
Хорошо.
Еще какие-то вопросы по предыдущим занятиям есть?
Мало ли там что-то еще в голове сло, мы можем с вами
их обсудить вначале.
Три, два, один, ну ладно, тогда предлагаю продолжать.
И сегодня мы с вами поговорим о градиентном бустинге,
о ужас, о той технике, которая немножко, скажем так, затмила
нейронные сети в начале нулевых, в 2001 году был представлен
GBM, Grading Boosting Machine, и за счет этого в том числе нейронные
сети на 10 лет ушли в подполье и сидели там, крайне тихо
развивались.
Собственно, градиентный бустинг это на данный момент
наверно некоторая максимально высокая точка развития
классических моделей, в каком смысле, он все еще актуален,
все еще широко применим, все еще крайне любим и
не сдает позиции нейронным сетям в том смысле, в смысле
подходу, где мы используем какие-то дифференцируемые
преобразования, каскадом их выстраиваем и так далее.
То, что нейронные сети и линии на модели, суть примерно
одно и то же, можем их отнести примерно в одно семейство.
Отдельно могут стоять метрические алгоритмы, тот же самый
KNN и так далее, отдельно может стоять дерево и их
ансамбли.
Сегодня мы с вами поговорим про ансамбли деревьев, про
градиентный бустинг.
Не обязательно на самом деле деревьев, но исторически
он используется в основном на неглубоких деревьях,
но опять же это исторически сложилось, его можно и с
другими моделями использовать.
И сегодня у нас в меню четыре основных шага.
Первое, мы с вами постараемся интуитивно понять, что такое
бустинг и как он вообще работает.
Второе, мы с вами попытаемся математически объяснить,
что происходит и как мы можем градиентные методы использовать
вроде как деревьями, которые недеференцируемы.
Ну а дальше поговорим еще чуть-чуть про другие техники
ансамблирования, будь то стекинг, блендинг и про
что-нибудь еще.
Вопросы сегодня приветствуются, в какой-то момент придется
чуть-чуть расширить сознание и понять, что такое градиентный
спуск в пространстве моделей, если так грубо говорить.
Если у вас был уже функкан, то вам, наверное, будет
чуть проще.
Если у вас его не было, вам все равно будет нормально.
Функкан нам сильно не понадобится, но понимать, что у нас
это выражение в разных местах работает полезно.
Но перед этим давайте коротенько вспомним, что было на прошлом
занятии.
Конкретно про random forest поговорим, про случайный лес и про
ансамблирование деревьев в лоб.
Вот у вас есть куча деревьев.
Узяли их, усреднили.
Что можно сказать первое?
Во-первых, все деревья были построены независимо
друг от друга.
Правильно?
Вы можете одно строить на одной машине, другое
на другой.
На разных датсетах, на разных признаках, подможествах.
Они все независимы.
Но тут, если вспомнить, опять же, не знаю, там, электричество,
электродинамика, то у нас есть последовательная
сеть, какие-то элементы последовательные и параллельные.
Вот здесь мы явно все строим параллельно, поэтому оно
независимо друг от друга.
Можете сразу напроситься вопроса, что если строить
последовательно.
Этому как раз к бусинку и подойдем.
Во-вторых, какие основные свойства у рандом-фореста
и ему же подобных бэйгинг-моделей, но рандом-форест, наверное,
как некоторая высшая ступень развития этого подхода.
Давайте их еще раз повторим.
Во-первых, деревья сами по себе хорошо работают
с пропусками раз и со скоррелированными признаками два.
Рандом-форест это все у них перенимает, потому
что скоррелированные признаки абсолютно по барабану мы
их раздельно рассматриваем.
Пропуски в данных.
Если есть пропуск, то мы используем оба под дерева,
потом усредняем ответ в зависимости от мощности
левого и правого под дерева в смысле объема выборки,
который туда и сюда пошел на этапе обучения.
И в-третьих, мы можем использовать out-of-back оценку для того,
чтобы получать оценку на не увиденных ранее данных.
Короче, валютационная выборка бесплатна, нам не нужно
делить наши данные на две части.
Тогда мы получаем с вами оценку сверху на ошибку
модели, потому что если мы работаем out-of-back, у нас
лишь часть ансамбля работает.
Вот вы здесь можете видеть, что мы здесь все модели,
у которых данный объект не попал в обучающую выборку
используем.
Соответственно, размер ансамбля меньше, эффективность
ранним форреста меньше, ниже, поэтому качество
тоже ниже.
Ошибка выше.
Ну и также я говорил коротко в конце занятия, что мы с
вами можем использовать другие версии вот этого
самого случайного леса, extremely randomized trees, там мы вообще
доводим до абсурда случайность, если у нас краски сильно
скоррелированы и множество.
Или isolation forest, это техника поиска аномалий, как я уже
говорил.
Повторить про нее еще раз, или все уже все помнят
и движемся дальше.
Повторить.
Ну хорошо, давайте тогда еще раз, тогда это было в
конце занятия.
Еще раз формулируем.
Что такое вот аномалия или же выброс, с точки зрения
именно признаков описания, не будем пока смотреть на
таргета вообще.
Вот у вас есть множество точек, какие-то из них какие-то
аномальные, какие-то нестандартные, вы можете какие-то свойства
их описать самостоятельно, не глядя на выборку.
Ну кто-нибудь, давайте.
Далеко от других точек, классно, что-нибудь еще?
Легко отделить.
Хорошо.
Ну по сути, если мы с вами нарисуем какое-то наше множество,
мы с вами краски заметим, что у нас наши данные могут
образовывать какую-то там достаточно плотную группу,
причем она вообще не обязательно какая-то правильная, условно.
У нас может быть просто какое-то облако точек круглое,
а может быть какая-нибудь вот такая вот крыказиабра
непонятной формы от буков КС, и внутри у него у нас
накиданы точки.
И, допустим, вот эта точка, она в среднем-то не так
уж далеко до всех, но она будет выбраться того, что
у нас плотность как-то вот таким образом распределена,
а здесь у нас краски низкая плотность объектов, а туда
кто-то попал.
Вот все.
Соответственно, выборку мы можем, точнее не выборку,
а выбросами или аномалиями мы можем называть те точки,
которые визуально выбиваются из вот этого нашего общего,
скажем так, распределения, из генеральной совокупности,
откуда все пришло.
Грубо говоря, если вы нарисуете многомерную функцию плотности,
то они краски будут торчать там, где у вас плотность
вашего распределения очень низкая.
Ну, с простейшим случаем для гауссовского распределения,
например, слева-справа, вот там, не знаю, за двумя
с половиной стигмами, можете считать, что это у вас какие-то
аномалии, так обычно и поступают в статистике.
Типа, если у нас там три сигма, это вот почти, наверное,
хорошо.
Там 99,7 нам уже достаточно, в принципе, из ста.
Так вот, isolation forest работает ровно на этом принципе.
Давайте попытаемся тогда отделить наши объекты от
всего остального и попробуем это сделать наименьшим
числом разделений.
Тогда мы можем это с вами делать каким образом?
Ну, вот чтобы эту точку отделить, можем там 1, 2, 3, 4, все, условно
как-то так.
Но при этом, если вы попытаетесь отделить ее с самого начала,
у вас, наверное, вызовет какие-то проблемы, гораздо
проще будет выделить вот такую точку, ее вообще там
можно одной, одним ихом отделить и так далее.
А те точки, которые сидят здесь внутри, их будет отделять
гораздо сложнее, потому что их нужно вообще прям
очень точно от всех остальных отводить и так далее.
Понятная идея, правильно?
То есть, чем меньше точка похожа на другие, тем меньше
нам в среднем нужно шагов, чтобы ее откинуть от остальных.
Плюс там точно также используется идея того, что мы используем
случайно признаков подможества и какие-то там бусттрапированные
выборки используем и так далее, чтобы деревья были
не похожи.
Соответственно, тогда мы имеем для каждой точки,
мы строим дерево, например, до какой-то глубины.
Для каждой точки мы имеем глубину, на которую мы ее
выделили в каждом дереве, или что мы ее вообще не выделили
отдельно.
И тогда вот скор для каждой точки – это что?
Это средняя глубина, на которой она была отделена.
Тогда у вас получится, если отранжировать точки вот
по этой средней глубине, получится, кто-то сидит слева,
все остальные где-то там справа или вообще делены
не были.
А кто-то сидит слева, мы говорим, ну хорошо, это вроде
как аномалия.
Понятное дело, это тоже не всегда хорошо подходит
и так далее.
Ну представь себе, я не знаю, там завернутую, вот представь
себе, что у вас все точки лежат на эдаком многообразии,
вот у вас есть двумерная плоскость, да, там все точки.
Потом вы взяли и ее свернули в рулу, вот коврик для йоги
мы так сворачиваем.
Теперь это все в сверхмерном пространстве.
И теперь там все точки, по сути, лежат вот на этой
закрученной поверхности, а некоторые между слоями
лежат.
В точке зрения расстояния до стальных расстояние
будет маленькое.
В точке зрения отделения тем же самым изволоченным
форстом проблем будет много.
Тем не менее, это тоже точки являются аномалиями, они
как раз не лежат на вот этой общей гиперповерхности.
Это нормально, этот метод не универсальный и он не
всегда подходит.
Просто чтобы вы понимали, это некая церебряная пуля,
что вот мы ее запустили и все работает.
Но с этим вот сложным многообразием вообще бывают проблемы.
Тут вопросы есть?
Три, два, один.
Хорошо.
Ну и в целом, если у вас есть какое-то желание работать
с данными, я надеюсь, у вас оно есть, раз вы ходите
даже очень на лекции, то изволоченный, ой, изволоченный,
random forest это классный такой подход, который можно в
копилку себе положить и всегда его использовать.
Одно маленькое но.
Пожалуйста, будьте осторожны, если вы пытаетесь его использовать
а, с данными, которые упорядочены во времени, потому что вам
нужно все-таки четко понимать, что у вас валидация работает
как.
Хорректно с точки зрения течения времени, потому
что вот эта ваша аутов бэк оценка может казаться
так, что вы оцениваете, по сути, на прошлых точках,
а лес обучался на будущем, если у вас точки упорядочены
во времени.
Это не очень хорошо, потому что у вас распределение
х новый, у новый при условии х, у предыдущего.
Если вы пытаетесь построить наоборот х, у предыдущий
при условии новых, вы по сути что-то другое делаете,
вы нарушаете ход событий и ваша модель учится чему-то
не тому.
Давайте, пожалуйста, всегда, когда данные упорядочены,
будьте очень осторожны с этими всеми случайными
подвыбреками и так далее.
Тут вопрос есть?
Все понятно, все просто, едем дальше, правильно?
Или ничего не понятно, ничего не просто спасите, помогите?
Вы про изволейшн форс сейчас?
Или про кого?
Вот про эту штуку.
Сейчас, я вопрос не поделал, к сожалению.
Когда точки изолированы где-то на маймару?
Не, не, я говорил, что изволейшн форс работает не всегда,
он все равно смотрит на то, что у вас точка находится
как-то подаль от всех остальных.
Ну, условно, доведите вот этот пример до абсурда,
заверните эту спираль очень сильно, у вас все лежит
на спирали, а какие-то точки лежат не на спирале
между клоев спирали.
В точке зрения какой-то закономерности они выбиваются
из этой закономерности.
В точке зрения расстояний они все равно рядом со всеми.
Поэтому этот мет просто не сможет их отделить.
Это нормально, он не рассчитан на все, он в среднем работает
неплохо.
Половили?
Так, больше вопросов нет?
Едем дальше.
Ребят, вы какие-то скучающие, вы меня пугаете, у вас уже
все, подкрадывается сессия, середина семестра все сложно
или вам просто скучно?
Снег не выпал, рано ботать.
А что вы тогда-то делаете?
Хорошо, ладно.
Ну и давайте тогда чуть-чуть поднимем градус настроения
в аудитории.
Мы с вами чуть-чуть говорили про bias-variance, я решил его
вынести на отдельный, наверное, доп-семинар, чтобы мы про
это с вами могли более развернуто поговорить.
Да, кстати, на всякий случай онлайн-семинары идут по
средам и субботам, все, туда можно ходить, это особенно
всем тем, кто в онлайне нас смотрит, приходите, подключайтесь,
все ссылки есть в чате, каждый раз они публикуют
заранее.
Ну, давайте по одному.
Там будет то же самое, но с маленькими оговорками
в каком-то смысле.
Материал опорный, то есть ноутбук и тема, они те
же самые.
Но, во-первых, там учитывается, что у вас уже есть запись
этого семинара и вы можете его посмотреть, то есть там,
как правило, разбираются больше вопросы, которые
идут уже от аудитории, потому что они пришли уже после
лекции, возможно, люди что-то смотрели, обдумали и
так далее.
Во-вторых, все равно каждый преподаватель чуть по-своему
подает материал, например, Валерий, он больше расписывает
все руками на планшете, потому что у него есть такая
возможность, потому что у него рядом все книжки,
у него рядом планшет, у него есть время, это дело,
круговоря, заранее вопросы, видите, и так далее.
Альбина, я думаю, наоборот, будет делать это все попроще
и с красивым визуализажкой.
То есть я больше стараюсь захватить теорию и практику,
чтобы удержать максимальный баланс между тем и другим.
То есть там, грубо говоря, больше уклон в одну или
в другую сторону.
В принципе, можете посмотреть запись, ей будет лучше.
Да.
Да, мои семинары остаются до конца симметрии.
Ну, с оговоркой, что в какой-то из дней я могу оказаться
в отъезде, и тогда меня кто-то заменит.
Так, хорошо, ладно, и давайте тогда кортенько поговорим
про bias variance.
Ладно, давайте про него в конце поговорим, я прессую.
Итак, тогда перейдем к бустингу, цель наша сегодняшняя.
Что такое бустинг?
Ну, понятное дело, что бустинг, опять же, от английского
boost, как-то усиливать, улучшать, я думаю, вам знакома библиотека
boost, правильно?
Ну, по крайней мере, те, кто на плюсах писали, и всем
незнакомые, те знают, что это такое.
Вот.
Давайте тогда подумаем, как нам перейти от идеи
параллельности, где у нас все независимо, к идее
последовательности наших моделей, чтобы каждое следующее
делало предыдущую лучше, тогда у нас получается
некоторый каскад моделей, которые все вместе работают
как единое целое.
Прям замечательно.
Но возникает вопрос, а как нам обучать каждую следующую
модель?
То, что в принципе с тем же самым решающим деревом
мы с вами можем сказать, что взяли мы решающее
дерево, мы его можем просто обучать до упора, оно всю
выборку обучающую запомнит, переобучится под нее, ошибок
не будет, исправлять нечем.
Почему нам нужно строить каскад модель?
Также можно заметить, что вот здесь предлагается
самая простая версия, просто линейная комбинация моделей.
Как вы думаете, если у нас в качестве базовых моделей,
вот эти вот, ашиты, h1 и т.д., hn, будет линейная регрессия?
Смысл вообще какой-то имеет?
Не имеет, потому что линейная комбинация линейных отображений
есть линейное отображение.
Все, конец.
А если логистическая регрессия?
И сверчок такой на фоне.
Да, и что?
Зачем?
Ну, если я сюда просто линейные модели засуну, тоже нейросеть
можно обозвать.
Ну, линейная регрессия тоже однослойная нейросеть
без нелинейности.
Ладно, хорошо, смотрите, тогда в конце к этому вопросу
вернемся, если коротко, да, логистические регрессии
можно даже иногда работать.
Хорошо, вот вам выборка, вот вам задачка.
Давайте-ка попытаемся ее решить с помощью решающих
деревьев, а точнее, решающих деревьев, доведенных до
иступления, решающих пней, то есть единых if-ов.
Каждом модели будет решающий пень, она говорит, налево
или направо, вверх или вниз, больше она что делать не
умеет.
Как видите, у нас выборка явно не делится ни одним
пнем поровну, правильно?
Давайте попробуем это сделать последовательностью
пней.
Ну вот, первый пень мы с вами обучаем, ладно, он
все три показал.
Хорошо, первый пень мы с вами обучаем, отделили
правые две точки и сказали, справа все синие, слева
тогда логично, что все красно, тогда у нас появились
синие точки, вот эти три рите они специально пожирнее
нарисованы, на которых ошибка выше.
Согласны?
То мы можем сделать, мы можем с вами на каждом шаге
перевзвешивать нашу обучающую выборку, отдавая больше
вес тем объектам, на которых мы совершили ошибку классификации.
Например, регрессия абсолют or все то же самое давайте
пока с классификаistiей.
На этих точках они стали поменьше, вес маленький,
потому что там ошибка маленькая.
А на точках слева синих там будто очень больш tanoss
в monkey孔- rabbit.
Давай Давайте строим вторую модель.
Тette есть нас bothering теперь все, что слева, DUO
красная eleven справа и о�.
У жеön тетти, все.
Т Netflix businesses, А절, Laterum,那 эти точки тебе McM arrow
Salology по universo прибав Isa.
estososto было вот эти точки Dutch & Highman с камперами
Строим третью модель. Соответственно, те, кто сверху синие, те, кто снизу красные. Хорошо, супер.
И в итоге у нас получаются вот такие три модели, которые, если с какими-то весами
сложить, возникает вопрос, с какими весами, то у нас получится вот такая нелинейная
разделяющая поверхность. По сути, такая ступенчатая. На самом деле, пример абсолютно игрушечный,
но в чем суть? Здесь мы с вами только что увидели, что мы с вами из множества простых моделей,
вот у нас три решающих пня, которые могут построить вам только линейную разделяющую
поверхность, да более того, она должна быть параллельна оси координатной какой-то. Мы из
трех моделей, которые очень простые, получили гораздо более сложную модель. То есть три простых
модели объединились в одну более сильную. Логично? В этом... что? Ро-1, Ро-2, Ро-3, это ровно те веса,
с которыми мы их объединяем. Откуда их брать, мы сейчас тоже с вами поговорим. Ну мы с вами эти
классификаторы, вот у нас есть 1, 2, 3, соответственно. Чего? Ну у вас каждый классификатор предсказывает
какую-то чиселку, например, вероятность. Или там, в общем случае, логит. Вы строите линейную
комбинацию ваших моделей. Линейная комбинация бывает взвешенной. Вот это веса, с которым вы их
добавляете. То есть мы с вами можем из трех получить более сложную модель. Но на самом деле
гораздо больше, чем из трех. Вы можете 25 штук построить, но тут 3 достаточно. И давайте теперь
вернемся вот к этой вот красивой картинке. Вы ее видели на третьей лекции, на четвертой лекции.
Что у нас здесь нарисовано? У нас здесь нарисованы все вот эти наши верхние оценки на истинную,
в кавычках, функция потерь, на ошибку классификации. И тут у нас с вами сидела еще экспоненциальная
функция потери. Вот она. Давайте попробуем ей заодно и воспользоваться. Когда мы на самом деле
переизобретем алгоритм, который был предложен в 97-м, что ли, а допустим, он назывался или 99-м,
и сделаем что? Давайте скажем, что у нас функция потерь с вами экспоненциальна. E в степени
минус маржина. Логично, тогда она у нас справа убывает, нормально слева она растет экспоненциально.
Вон она. То есть чем глубже объект оказывается вне своего класса, тем больше у нас ошибка,
причем растет экспоненциально. Сразу можно заметить, что так себе результат, экспоненциальный
рост вообще не очень хорошее дело. Примерно везде. Все может сломаться, взорваться,
вычислительная точность конечная и так далее. Мы сейчас по сути придумывали, смотрите, мы с
вами выбрали пока что простую функцию потерь экспоненциальную. Почему? Сейчас увидите. И для
нее как раз попробуем вот это перевзвешивание переизобрести. А потом в общем случае уже просто
по стопам Фридмана пройдем, который как раз таки... Фридман, джей. Я надеюсь Фридман. Я в начале
лекции говорил имя, сейчас я уже запутался. Просто есть еще классный автор, в MIT ведет лекции,
на ютубе у него прикольный подкаст, Лекс Фридман. Сын, собственно, выпускника физтеха,
если мне не изменяет память. И у него классный подкаст. По-моему, все-таки тоже Фридман. Ладно,
давайте скажем, что у нас с вами функция потерь экспоненциальная, то есть е в степени
минус марджин. Хорошо, тогда у нас есть с вами над этом шаге наш алгоритм. Это ансамбль из
предыдущих первого по Т-большой алгоритмов. Вот он. И вот наша функция потерь. l от y и
предсказание f с крышкой от t. Это что? Экспоненты минус y на f с крышкой от t. Согласны? Пока просто
марджин написали. Супер. То есть мы можем это расписать как экспонента минус y на сумму вот
этих штук. А что мы с вами знаем про экспоненту от суммы? Ну, логично, что если у нас в степени
экспонента стоит сумма, мы это можем разделить на произведение экспонентов. Логично. Работаем.
И мы отсюда с вами можем совершенно спокойно взять и вытащить последний элемент. Давайте скажем,
что мы сейчас находимся над этом шаге, и у нас есть все модели, кроме последней, обучены. То есть
у нас уже есть с первой по Т-большой у нас один модель, который мы обучили, они отлиты в бетоне,
их трогать нельзя. И есть последняя hT-большая модель, которую мы сейчас должны обучить. Ну,
собственно, вот она. И получается, что на шаге t вот это у нас константа, у нас ничего не
меняется. И мы должны минимизировать ровно вот эту штуку. Потому что все предыдущие модели уже
обучены в ансамбле. Ну, замечательно. Но раз это константа, получается, что у нас для каждого
объекта функция потерь приобретает вот такой вид. Возникает вопрос, зачем нам здесь экспоненциальная
функция потерь? Потому что по ней краске очевидно, что такое взвешивание объекта. Смотрите, вот ваш
вес. На каждом шаге ошибка нашего алгоритма, который был построен до текущего шага, это и есть
вес объекта. Если объект был классифицирован правильно, ошибка у него маленькая, вес маленький. Если
ошибка большая, то есть объект был классифицирован неправильно, мы хотим на нем учиться. Понятно,
что происходит? Понятно, зачем здесь экспонента? Потому что, если бы не был экспонент, мы не могли
вот так факторизоваться и выделить отдельный член. Ну, назвали это дело Adaboost, от слова
адаптивный бустинг, adaptive boosting. И вроде как казалось, что вот классно. Мы придумали, как
работать, но у Adaboost была куча проблем, он переобучался в лед. У него вот эта экспонента
мешала вычислительно всем процессам, и далеко не всегда экспоненциальная функция потерь хорошо
подходила. В том числе у нас с вами есть не только задача классифицироваться, а еще есть задача
регрессить. Там не очень понятно, как сходу это исправить. Тоже можно, но тем не менее. Но на самом
деле в 90-х было множество различных подходов. Adaboost, Brownboost еще был, многие там называли
фамилия автора Boost, и так далее. А потом в 2001 году к краске пришел градиентный бустинг, который
показал, что все вот это вот многообразие, это на самом деле частный случай общей истории градиентного
бустинга. И с ним давайте краски сейчас и попробуем разобраться. Во-первых, я сейчас сразу вас немножко
попрошу, наверное, напрячь внимание. Сейчас будет немного больше математики, чем на предыдущих
слайдах. И здесь будет, наверное, тема, которая в первом семестре кажется одной из наиболее
сложных, наряду с SVM, который часто вызывает вопросы. В этом году мы оттуда почти полностью
выполнили двойственную задачу, поэтому он стал кажется очень простым, но тем не менее. И вместе
с, не знаю, кому-то первой лекции сложно там всякие правдоподобия вылазить, кому-то всякие
нейронки становятся сложными. Короче, давайте сейчас напряжемся на 10-15 минут, все осознаем. Итак,
шаг номер один. Как всегда, постановка задачи. У нас с вами есть выборка, пара x, y, причем абсолютно
все равно регрессия, классификация, что-нибудь еще там придумайте, неважно. У вас есть множество
пар объект-ответ и у вас есть функция потерь. Мы хотели бы с вами найти такую модель, которая
достигает оптимума на данной выборке, минимума, нашей функции потерь или что-то же самое,
минимума эмпирического риска. Ну, что мы хотим? Мы на самом деле не имеем доступ ко всей
генеральной совокупности, ко всему распределению, откуда пришли наши данные. У нас есть только наша
выборка, поэтому вместо нашего вот этого вот ожидания по факту мы с вами будем брать что?
Среднее по всей выборке. То есть мы хотим получить модель, которая в среднем получает наименьшую
ошибку. И пусть у нас с вами не просто какое-то семейство моделей, из которых мы ищем оптимальную,
потому что среди всех, типа среди линейных, метрических, деревьев, их ансамблей,
непараметрических и так далее сложно найти оптимальную, надо все перебирать. Давайте пусть
будет какая-то параметрическая патрика моделей, параметрическая семейство моделей. Что это значит?
Что модель параметризуется вот этим вектором тета, неважно что это, это вектор параметров
нашей линейной регрессии, множество параметров неровной сети, просто множество плитов вот этих
трешолдов и фичей для дерева или что-нибудь еще. Главное, что мы вот эту запихнули все наши
параметры, которые мы можем каким-то там образом менять. Градиентным, неградиентным, все нормально.
Тут понятно? Вот здесь? Ну, я так скажу, здесь это скорее... Хорошо, здесь, наверное, стоит сказать,
что х приходит из какой-то генерально-совокупности и здесь мы, собственно, по нему мат ожидаем. Короче,
вот это просто выкиньте и все. Выкиньте второй член. Грубо говоря, это эквалентные записи в том
смысле, что у нас с вами х и у приходят из вот этого нашего распределения, откуда пришли данные.
Тут просто мы явно это написали. Тут, наверное, да, не совсем корректно написано. Наверное,
надо поправить. f это краска. Смотрите, мы говорим, у нас вот что такое оптимальная модель,
а которая достигает минимума мат ожидаемости нашей функции потерь. Далее мы говорим, нам ее надо
как-то найти, поэтому пусть наша f будет из код параметрических 8s. То есть мы можем каким-то
векторам параметров ее определить. Пока у нас ее нет. Пока мы договорились, что...
f от... Ну, функция потерь от y и от нашего предсказания. Предсказание. Ну, смотрите,
функция потерь у вас обычно что считает? У вас есть ваше истинное значение и предсказанное
значение? Средне квадратичная ошибка, разница квадрат, квадрат разницы в течение,
log loss, p log q и так далее. То есть это ваша функция потерь. Половили, нет?
Так, коллеги, кто-нибудь вообще записывает за вашим вопросом, я в тот раз еще на самом деле
просил, если вы вот такие штуки видите, вот да, здесь надо написать f от x. Так будет лучше.
Может, пожалуйста, после занятия, если кто-то это лагирует, кидать в чат,
тогда это будет все оперативно поправлено. Я, к сожалению, забываю через два с половиной
часа, после того, как я это услышал. Спасибо. Хорошо. Опечатки вроде починили. Еще что-то
понятно? Не понятно точнее. Вроде все окей. Хорошо. Давайте тогда разобьем нашу вот эту
текущую модель краски в том смысле, что мы знаем, что у нас с вами последовательность наших
моделек, классикаторов, например, или регрессоров, последовательность алгоритмов, и мы знаем,
что на текущем шаге у нас есть, допустим, с 0 по t минус 1 уже обученные все. Вот мы их обучили
каким-то образом, не важно, но вспомните мат индукции. То есть тут мы сейчас говорим про шаг
индукции. У нас уже что-то обучено, мы хотим еще одну модель дообучить, номер t. То есть нам,
по сути, надо для модели на шаге t, ρt это ее вес и θt это ее параметры, решить вот такую задачу
минимизации. У нас есть y, истинный, который у нас есть, и собственно f от x, причем с крышкой вот
все, что было раньше, плюс ρ на h от x. Вот это вот h от xθ это наша новая модель, которую мы хотим
добавить. Чего? Говорите погромче, пожалуйста, я вас плохо слышу. Еще раз, мы с вами, вот это было
в общем случае написано, это работает для всего. Теперь мы говорим, давайте будем строить модели
последовательно. Каждое следующее будет улучшать результат предыдущего ансамбля. Значит у нас
модель общая, вот алгоритм, ансамбль, давайте вот так называть, представим в виде суммы наших
моделей. Каждое следующее, это все модели вместе что-то предсказали, получили результат. Согласны?
Вот мы с вами пока что прошли t-1 шаг, и у нас есть вот эта вот f с крышкой, она уже каким-то там
образом обучена, пока не важно каким, мы собственно сейчас с вами на шаге индукции и покажем как мы ее
обучили. Соответственно на новом шаге нам нужно дообучить еще один кусочек ансамбля, вот он.
Все согласны? Что? Базу индукции, сейчас мы до нее дойдем. Давайте сначала шаг индукции и пишем потом
базу, окей? Если у нас уже есть с вами обученная часть ансамбля, как нам к нему добавить еще один
элемент? Вот что мы сейчас делаем, понятно? Хорошо, тогда мы с вами можем разбить в наши функции потерь
вот это на две части, наше текущее предсказание и по сути поправка к тому что есть. Верно? Все вот это
понимают, правильно? Тут, тут, тут, тут. Нормально. И тогда краски оптимальная, наша tt модель вот f с крышкой t,
которую мы должны сюда добавить, это будет ρt на hхθt. Нам надо вот этот дел найти. Теперь внимание в
вопрос, как нам найти ρt и tt? Это основной вопрос. И здесь вступают краски в силу гридентный бустинг.
Вопрос вы видите уже на экране. А что если бы мы могли использовать гридентный спуск не в
пространстве как-то там параметров и так далее, а в пространстве моделей? Что это значит? Помните,
вот эту картинку она у нас была на втором занятии, если исключить занятия по повторению линии на
регрессии. Это вот у нас линии уровня или же эквипутенциальной поверхности, тут оптимум,
вот наша начальная инициализация, вот первый гридентный шаг, второй, третий и так далее. Вот мы
куда-то там шагаем. Но мы с вами привыкли это делать где? В пространстве параметров. У нас есть
гиперповерхности эквипутенциальной поверхности функции потерь и мы с вами шагаем туда-сюда,
пытаясь понизить значение функции потерь. Верно? А кто сказал, что только в пространстве параметров
мы можем это делать? Мы это можем делать в пространстве модели и вообще где угодно. На самом деле,
я поэтому говорил, что если у вас был функкан, вам будет проще. У вас есть какое-то пространство,
а потом есть какие-то эквапутенциальные поверхности, и в котором, допустим, каждая точка
соответствует какому-то отображению. В модели это и есть отображение. Можем так сделать? Можем.
Остается вопрос, где нам взять вот этот самый гридентный спуск? И вся красота в том, что нам
достаточно с вами одного единственного допущения. Давайте договоримся, что вот эта функция потерь,
которую мы с вами выбрали, дифференцируема. Хорошо? Чего? Да, например. Вот. Каждая модель — это,
по сути, некоторый оператор, сдающий отображение из пространства исходного,
в пространство таргетов. Идет? Все, супер. Поэтому я и говорил, что функкан здесь полезен,
просто чтобы вы понимали, что пространство операторов тоже можно задать, оно тоже существует.
Хоть и не столь привычно. Так вот, единственное ограничение. Пусть вот эта функция потерь
дифференцируема. Договорились? Но, я думаю, слово «градиентный бустинг», вот «градиентный» намекает,
что где-то там будут градиенты. Нам нужны градиенты. Вот. Функция L — дифференцируема. Что мы тогда
можем видеть? Ну, тогда давайте шагом. Вот наша текущая с вами константа, которая предсказывает
на каждом шаге. Она у нас есть. Тогда теперь мы с вами что можем сделать? На каждом объекте из обучающей
выборки у нас с вами есть истинный ответ. Правильно? И у нас с вами есть что? У нас с вами есть какое-то
предсказание нашей текущей модели. Правильно? Ну, давайте я назад лисну. Вот оно. Предсказание
нашей текущей модели для каждого х тоже есть. Она же у нас уже обучена. Плюс у нас есть какое-то
х. Правильно? Вот давайте вот эту штуку обзавем просто РИтой. В данном случае где-то он у нас. Вот. А, нет. Вот Df от
х. Короче, вот это наша добавка. Роа на х тета — это краткий f. Наговорились? Согласитесь, что если вот эта
штука дифференцируема, L от Y — f плюс какая-то поправка. Мы же можем с вами по этой поправке
продиференцироваться. Это проф — наш свободный член. Вспоминаем производную сложной функции DL по D
вот эта поправка. Это что? Это DL по D сумма и D сумма по вот этой штуке. Согласились все? Все согласны. И
внезапно у нас получается, что для каждого объекта обучающей выборки, обратите внимание,
для каждой пары х и у мы можем считать с вами функцию потерь, предсказание и соответственно
значение производной. И получается, что для каждого объекта из нашей обучающей выборки,
для каждой пары, у нас есть поправка. Причем это не просто поправка, это ровно то значение градиента,
которое показывается. Вот настолько надо здесь поменять предсказание, чтобы стало лучше. Потому
что что такое градиент? Направление нескорейшего возрастания функции. Антиградиентное направление
нескорейшего убывания. То есть ровно вот так мы должны поменять предсказание на этом объекте,
над этом шаге нашего ансамбля, чтобы ошибка ансамбля стала меньше. Вот это понятно? Сейчас
еще раз проговорю. То есть мы с вами посчитали производную функцию потерь по предсказанию нашей
новой модели, которую мы пока не обучили. Это наш свободный член. Вы ловливаете? Давайте попробую
это на доске тоже написать. Вот у вас по сути L. Белый. L у вас зависит от Y этого, потом F от X этого.
Вот с крышкой. Это все то, что мы сейчас обучили. Давайте. Вот. Да. X у нас есть. Вот. Взяли один
объект, обучающий выборки. Только один. Взяли и с ним работаем. Все. Соответственно, у нас вот
эта штука есть. Правильно? Давайте вот эту штуку я просто для удобства обзову кси. Хорошо? Тогда мы
говорим с вами DL по DL от Y и кси по D кси и опять же. Чему-то равна. Согласны? То есть это вот та
величина, это наш градиент. Это то, как нам надо поменять предсказание, чтобы стало лучше.
С этим все согласны? Ну так мы же с вами только что говорили, что мы будем наше предсказание
менять ровно вот на эту величину. А вот нам примерно что надо его менять. Все. Мы с вами
получили оценку градиента в точке, то есть насколько нам нужно поменять предсказание на каждом объекте.
А теперь финтушами. Мы для каждой точки из нашей обучающей выборки или, грубо говоря,
для каждой точки в признаковом пространстве, до которой мы знаем значение таргета, мы понимаем,
как нужно исправить предсказание. Вот наш градиент для градиент LOS по предсказанию,
то есть надо идти по антиградиенту. Верно? Так давайте на него и обучаться. Давайте наша
новая модель будет апроксимировать не ответ сам по себе, а антиградиент функции ошибки по
предыдущим предсказаниям. То есть наша новая модель, мы когда добавляем новую модель,
мы по сути делаем градиентный шаг пространств модели. У нас была какая-то модель, мы добавили
новую, которая апроксимирует градиент. Уловили, что произошло? Мы не параметры поменяли, у нас
новая модель апроксимирует градиенты, вы ее туда добавляете. Все. Ну смотрите, у вас модель,
вот ваш ансамбль, это последовательность моделей. Вот сумма. На новом шаге вы к ней добавляете еще
одну модель. Вот это все у вас уже обучено, оно уже где-то есть, оно уже прибито гвоздями. Все,
вы его трогать не можете. На N плюс первом шаге вы говорите, хочу найти новую добавку к моему
ансамблю, чтобы стало лучше. Как мне эту добавку обучать? Мы ищем антиградиент ошибки по текущим
предсказаниям ансамбля, понимаем, что надо подменять предсказания ансамбля вот так и на них
учимся. То есть, наш новый элемент ансамбля апроксимирует антиградиент. Предыдущих ошибок
ансамбля. Наш новый элемент, ну вот смотрите, вот наша h х тета, вот он ваш, новая модель,
которая пока не обучена. Еще раз, вот ваш текущий ансамбль, вот вы к нему добавите
РО на h х тета. РО это learning rate просто, это градиентный шаг родмирового. Все, теперь вы
нашли антиградиент, говорите, вот мой антиградиент, вот ровно на него вы вашу новую модель,
поправку, будете обучать. Кто? Ашмалая, это как раз, смотрите, ашмалая это ваш алгоритм,
который вы будете учить. Какой он будет, от вас абсолютно зависит, может быть, линейная модель,
кайн и так далее, по барабану. Нет, аш это просто модель из какого-то семейства. Единственное,
что вам нужно, вам нужно уметь аш обучать по выборке. То есть, если у вас есть множество пар
объектов и ответы, вы можете по ним настроить аш. Ну да, то есть, аш приходит из какого-то
параметрического семейства. То есть, вам не надо ее искать везде, например, вы сказали, аш это
решающие деревья. Все, тогда у вас для каждого объекта есть х, признаковое описание, есть новый
ритый, который оценка антиградиента, на парах х и ритый, вы обучаете ваше новое дерево. Все.
Почему именно квадратичное? Смотрите, потому что по сути у вас теперь от задачи регрессия,
правильно? И вы сюда можете абсолютно на самом деле ошибку запихнуть. Квадратичные краски потому,
что когда вы минимизируете квадрат, вы получаете именно оценку среднего, и у вас там под капотом
защиты гауссового распределения. Все. Бинго. Абсолютно неважно, если у вас функция потерь есть
дифференцируемая, регрессия, классификация, какой-нибудь там ранжирование придумайте, вам вообще все равно.
Есть дифференцированная функция потерь, вы знаете, как сделать ее лучше. Все. Вам вообще не
дифференцируемо. Более того, у вас изначально вот эти вот модели, опять же, в чем вся прелесть
градиентного бустинга, они могут быть недифференцируемыми. Тот же самый градиентный
бустинг над решающими деревьями. Деревья сами по себе градиентной оптимизации не поддаются,
каждое дерево это кусочек постоянной функции. Но вы их можете использовать для опроксимации
градиентов в каждой точке пространства. Все. То есть у вас, получается, недифференцируемые модели
сидят как базовые алгоритмы в ансамбле типа градиентный бустинг. Да.
Это не очень логично. А дальше что? Почему это не очень логично?
Смотрите, давайте я это напишу тогда на доске. Смотрите.
Не, здесь у нас любые модели абсолютно. То есть про деревья я просто говорю,
что даже дерево и даже какой-нибудь KNN здесь будет работать. Смотрите,
у вас есть текущая модель, вот F от X, крышкой. Это ваша текущая модель. Мы говорим,
хочу получить новую модель, которая лучше. Вот это у меня на шаге T, мы хотим получить F,
T плюс 1 с крышкой опять же от X. Тогда у нас здесь есть два допущения. Первое, мы говорим,
что F, T плюс 1 с крышкой, это что? Это F, T с крышкой от X плюс какое-то РО на какое-то H от X. Ну,
с параметрами тета. Вот, чтобы как там было. Согласны? Это мы пока сказали. И теперь, соответственно,
вот это наша первая посылка. И второе, мы говорим, как нам лучше всего исправить ошибку нашего
текущего ансамбля. Ну, давайте посчитаем. DL от Y и F с крышкой T от X по кому? Ну, даже может
T плюс 1 по D краске F с крышкой T плюс 1 от X. Все, вы говорите, как мне лучше всего исправить
предсказания? Чистая математика, вот она вам. Вы поняли, как лучше всего исправить предсказания?
Ну, теперь добавьте вот вам ваш, по сути, шаг исправления предсказаний. То есть, вроде как
логично. Мы хотим оценить, насколько нам нужно подвинуть предсказания на каждом объекте, чтобы
стало лучше. Чего? Я понял. Ой, хорошо, давайте посчитаем. У вас L считается от Y и от F с крышкой
T плюс РО, H, X и T. Вот с этим согласны? Давайте я для начала вот это обозначу просто как
кси, просто чтобы было удобнее писать. Тогда DL Y кси по D кси чему равно? Ну, вот чему-то там равно,
мы не знаем, это от функции потери зависит. Хорошо, но мы это дифференцировать умеем. Это у нас есть.
То можем дальше сделать. Это у нас есть галка. Дальше мы с вами можем посчитать D кси по кому?
По D РО. Ой, ну D тета я забежал вперед. По D РО можем продиференцировать? Чему это будет равно?
H X тета. Все, хорошо. Соответственно D кси по D тета. Можем посчитать? Это соответственно будет D кси по D
H на D H по D тета. И тут еще РО будет сидеть. Согласны? Вот вы градиенты посчитали. Да,
спасибо. Я его просто потом явно написал. Мысли зачем? Не, в смысле, вот вам все,
вот ваши все градиенты, откуда они взялись. Вот вы отсюда получили по сути оценку D тета или
просто вам достаточно D кси по D H нарисовать, вы знаете чему оно будет равно? У вас будет
вот эта штука, умноженная на РО, это ваша D кси по D H. Это то, как надо настроить H. Все. Чего непонятно,
ребят, я не понимаю. Ну, ну да. Не, погодите, я вам всего лишь показываю что. Вот у вас эта штука,
F от X, правильно? Она в себя включает константную часть, ваше текущее предсказание, вы по константе
не можете продиференцировать, она константа. Плюс ваше новое предсказание, которое вы краски
будете на него обучать. Так, что я сейчас делал, по шагам. Первое, у нас есть текущая модель,
которая предсказывает что-то, правильно? Вот. Сейчас она уже, вот эта часть, она обучена. Вот скажите
мне, кто-нибудь может продиференцировать лост по константному предсказанию? Оно константное,
вы его поменять не можете. Есть смысл дифференцироваться по константе? Не очень. Хорошо. То есть мы
говорим, хорошо, давайте в целом по предсказаниям, считая, что оно может линейно как-то меняться,
продиференцируемся. Вот, я только что это писал. Вот, это у вас констант, а это у вас туда краски
входят каким-то образом. По нему продиференцируемся и получаем, что вот это та же производная. Потому
что у нас есть член, который свободный, он обладает крепким свободным, мы его менять можем. Мы на
него краски обучаем кого? Нашу новую модель, которую у нас есть. Есть модель, она делает предсказания.
Мы, у вас, вы берете предсказания модели как просто какую-то свободную переменную,
кси. Все, вот она. Дл по дкси. Можете посчитать? Можете. В каком месте я вас запутал, ребят?
Хорошо, ладно, это было лишнее. Ну, в плане, сейчас ладо для прав, для понимания, скорее вредит. Вы правы.
Я всего лишь хотел показать, что это все дифференцируемая операция. То есть, у вас
нет того, что вы дифференцируетесь по ком-то константному предсказанию, потому
что это смысла не имеет, вы не можете по константе дифференцироваться. У вас здесь
ровно зашит свободный член, поэтому вы и имеем право дифференцироваться. Все. Мы, по сути,
для простоты понимания еще раз, у вас есть текущее предсказание, обозначаем его свободным
членом, дифференцируемся по свободному члену и получаем как надо изменить текущие предсказания,
обучаем новую модель ровно на то, как надо его изменить. Логично что? Логично то, что у нас
скорее всего модель не сможет идеально аппроксимировать градиент с каждой точки. Поэтому
мы с вами не получим идеальную поправку, мы получим какое-то движение в сторону антиградиента
ровно как здесь у нас указано. Мы за один шаг не пойдем в оптимум. В том числе потому, что чтобы
попасть даже в случае выпуклой задачи в оптимум за один шаг, нам нужны методы второго порядка,
применять метод ньютон-равсна и так далее. А егебьяны считать эгесианы никто не любит,
особенно на больших водах. Нет, это все для любой задачи, смотрите.
Именно поэтому я вам уже пятую лекцию говорю, четвертую. В задачи классикации мы предсказываем
вероятность. Все, забудьте про метки класса, это слишком детский сет. У нас там вектор вероятности,
по нему можно совершенно дифференцировать. Так, еще вопросы есть? Да. Сейчас, смотрите, мы должны
опроксимировать наши антиградиенты. Это уже просто какой-то вектор, в общем случае, в каком-то
пространстве, правильно? Если мы решаем задачу, где надо опроксимировать вектор, это какая задача?
Регрессии. Регрессию можно решать с помощью минимизации МСЕ, МАЕ, МАЕ и кучу других там всяких
функций ошибок. Когда мы с вами минимизируем средне квадратичную ошибку, мы на самом деле делаем
оценку максимального правдоподобия, если у нас гауссовский прайор. Ну, это из статов просто
вытекает. Оценка максимального правдоподобия при предположении, что у нас нормальное
распределение, это называется эквивалентом минимизации средней квадратичной ошибки. Вот,
поэтому я и сказал, что по сути это говорит, что у нас где-то там гауссовский прайор. Запихнуть
сюда МАЕ, у вас будет лапласовский прайор. Так, у вас тоже был вопрос. Вот, смотрите,
что такое РО, давайте вспомним. РО это просто наш размер градиентного шага. Помните, мы с вами,
когда говорили про градиентный спуск, у нас там была какая-то тета, это на размер градиента. Вот,
у нас функция наша с вами, она умная, она апроксимирует чисто наш градиент. Всё, но она его
апроксимирует, она апроксимирует каким-то неидеальным способом. Поэтому теперь мы, зная, что мы
шагаем вон туда, мы задаем вопрос, а как именно нам нужно шагнуть в этом направлении оптимально?
По сути, мы на каждом шаге находим оптимальный градиентный шаг. Мы выбрали направление, ну и,
по сути, норма вектора, тут тоже, на самом деле, как это есть. Но мы смотрим, не надо ли нам его
растянуть, только и всего. Возможно, у вас будет отличная оптимальная величина этого шага от 1,
тогда вы, соответственно, лучше шагнете в этом направлении. Всё. Да, смотрите, вы сначала
апроксимируете антиградиент каким-то там образом, а потом, вы уже зная, что идем в этом направлении,
ищите оптимальное значение РО. Потому что РО это просто, грубо говоря, растяжение и сжатие в
этом направлении. Куда именно нам шагнуть? Сильно или слабо? Ну, слушайте, по сравнению с тем,
что на каждом шаге вы какой-то модель обучаете подобрать какой-то коэффициент, у вас же тут,
ну, сами посмотрите, линейный, по сути, всё линейно. Производную вы уже считали, чтобы вот
это получить, вам достаточно всего лишь сюда подставить в аналитическое выражение ваши новые
предсказания и подобрать порожки производные. Всё. Так что ничего страшного. Не, ну, второй
вариант вы можете, если совсем не хочется, может каким-то, не знаю, там линейным поиском пробежаться
и всё. Тоже вариант. Да? Сейчас. Что значит? А, смотрите, аргмин, что такое? Ну, мин – задача
минимизации. Аргмин – это задача поиска аргументов, при которых достаётся минимум. То есть минимум
выражения – это его экстремум, аргмин выражения – это значение аргумента, при котором достигается
экстремум. Ну, экстремум – минимум, в смысле argmax, при котором достигается максимум, соответственно.
Всё. Хорошо? Да. Вот как. Сначала вы нашли параметр theta, вы знаете, какая модель у вас новая на
новом шаге. Всё, модель зафиксировали. Теперь вы говорите, с каким весом мне добавить его в ансамбль?
Всё. Я ещё этот вопрос не понимаю. Почему мы в один
шаг не нашли и роет эту одновременно? Смотрите, мы с вами с помощью дифференцирования нашли наш
градиент. Градиент мы потом аппроксимировали каким-то там образом. Он неточный, это уже оценка
градиента, она уже имеет ошибки. Теперь мы говорим, с такой оценкой градиента, насколько нам нужно
сместиться? Всё. Если бы у нас с вами был точный градиент, ещё вопрос бы, наверное, имел смысл. У нас
вообще оценка градиента, нам не понятно, насколько он вообще хороший. Ну, условно, у вас градиент
оценивается трёхслойным деревом в глубиной 3. Он очень грубо оценивается. Вопрос, насколько нам
вообще надо идти? Может, нам вообще с таким градиентом идти никуда не надо, потому что слишком
паршивая оценка? Всё. Ещё вопросы тут есть? Ну, давайте тогда посмотрим на простой пример. Сразу
дисклеймер. В случае регрессии и средней квадратичной ошибки это всё вырождается вообще в детский сад.
Это частный случай, так работает не всегда. Хорошо? Поехали. Давайте посмотрим на средней
квадратичной ошибку. У нас тогда lost это квадрат отклонения, правильно? То есть 2y с крышкой
минус y. y с крышкой наша оценка, y то, что есть. Правильно? Ну, видим, что по сути пропорционально
с коэффициентом минус 2, y с крышкой минус y. Верно? А? Пропорционально?
Ну, ладно.
Ну, наверное, всё-таки пропорционально, потому что я эти слайды составлял. Вывод про это.
Так, какой символ вам не нравится? Какой символ вам не нравится?
Ребят, нам же основная суть какая? Мы должны условиться об обозначениях. Я хоть горшок на
доске нарисовать могу, если вы понимаете, что это такое, абсолютно неважно. Что мы здесь с вами
видим? Что у нас градиент по сути пропорционально чему? Реально отклонению нашего предсказания от
истинного значения, правильно? То есть мы на каждом шаге с вами будем пытаться оценить что? Мы
на каждом шаге будем с вами пытаться краски оценить, насколько мы ошиблись, и каждая новая
модель будет предсказывать именно ошибку предыдущей модели в прямом смысле. То есть надо было
предсказать 25 овец, мы предсказали 21, надо поправить на 4 овца. Я понять не имею причем здесь
овца, мне только что в голову пришли. Извините, я вспомнил мимачик, который я вчера видел.
Да, именно, ну то есть смотрите, это именно предсказание в каждой точке. Я еще раз говорю,
почему я вот это расписывал, потому что если у вас уже модель фиксирована, все в ней все
параметры фиксированы, вы не можете по константе продиференцироваться, чтобы вы понимали,
что это значит. Понятно? То есть в случае с линейной регрессией градиентный бустинг вырождается в то,
простите, с линейной регрессией, с минимализацией среднего трагичного ошибки, с задачей регрессии,
градиентный бустинг вырождается в том, что каждая следующая модель обучается на ошибке предыдущей
буквально. Все, он просто, вот вы предсказали, 25 надо было, 30, он учится на 5. Но это работает,
потому что у вас производная будет вот такая линейная. Условно с какой-нибудь средней
абсолютной ошибкой это уже не работает, потому что производа будет какая? Сигнум вот этой величины.
Согласны? Уловили? Ну и давайте посмотрим на классную Демку,
которую в далеком 2016 году запилил мой тогда еще коллега, мы с ним в последние
годы точно вообще не общались, но Алекс Аргожников классный следователь, классный
преподаватель, приложил руку к различным задачкам и преподаванию в ШАДе и многогде. И, в принципе,
достаточно... Смотрите, во-первых, вот наше решающее дерево, давайте, наверное, на него
сначала посмотрим. Вот у нас с вами гиперповерхность, видите, да, такая волна. Вот что у нас
делает решающее дерево, глубины 1, глубины 2, 3, 4, 5, 6. Вот такая вот ступенчатая функция у нас
получается. Погодите, пока что одно дерево. Сейчас, или что? Линейная комбинация, да. Погодите,
вот же мы с вами только что это писали. Вот, каждое с вами дерево, вы просто добавляете его
с весом РО, РО находится в градиентном какой-то оптимизации опять же. Маленькую подзадачу решаю.
Погодите, у вас всегда будет ступенчатая функция при сумме, а ступенчатая функция не линейная. Ну,
смотрите, давайте я вам это нарисую. Вот у вас одна модель, вот у вас вторая модель. Давайте их
просуммируем. Соответственно, тут у нас был 0, тут 1, тут опять 0, 1, 1, 0. Получается у вас будет 0,
потом 1, потом 2, потом опять 1. Вот, просуммировал. Ну, вот этого края, правда, нет. Уловили?
Короче, вот у нас одно дерево может вот так максимум сделать. Дерево глубиной 6. Возникает
вопрос, а что если у нас с вами гораздо больше деревьев, но они все глупенькие? Вот вам градиентный
бустинг из 100 решающих деревьев. И давайте посмотрим. Вот у нас 100 деревьев глубиной 3. Согласитесь,
кажется, гораздо более плавно описывает нашу вот эту гиперповерхность по сравнению с одним
деревом глубиной 6. Ступенник меньше и так далее. Можно даже сделать глубину поменьше и видеть,
что все равно достаточно плавно он его описывает, хотя, конечно, на сами пике не может добраться,
почему? Потому что глубина дерева слишком маленькая, деревьев маловато. Если увеличим
глубину дерева, даже вон решающие пни, они из-за того, что каждый раз только по одному признаку,
они вторую ось не распознают. Все. Но, соответственно, вот вам два признака уже есть,
вот он хорошо работает. Три, и того краше четыре. Ну, практически на таком, скажем так, удалении
не видно вообще это гладкая поверхность или куча ступенек. По факту это куча ступенек. Но,
соответственно, 100 деревьев глубиной 6. Ну, вот вам замечательная опроксимация той самой вашей
гиперповерхности. Работает. Хотя одно дерево глубиной 6, как видите, даже рядом не лежало,
и тут очень такое все дискретно и не очень красивое. Понятно, что происходит, правильно? Вот. И еще
раз, собственно, возможно, вам тут станет понятно. Вот ваш ансамбль, вот первое дерево, второе дерево,
и так далее. И все их мы обучаем. На четвертом шаге три дерева уже построены. Мы говорим,
что это три дерева плюс четвертое, это наше f от x. Давайте поймем, как нам поправить предсказания
и обучим на этой краске наше четвертое дерево. Все. Вот оно. Вот, смотрите. Вот наша целевая функция.
И теперь, кстати, да, вернемся сразу к краске с вами, к самом начале. Помните, я говорил,
что мы только шаг индукции с вами обозначили. Где взять базу индукции? Фридман, предложивший
гридиэтный бусинг, предложил очень просто. Абсолютно не важно, с чего вы начинаете,
потому что каждая следующая модель будет все равно все поправлять. Давайте всегда у нас в начальной
модели будет просто среднее значение таргета. Констант. Все. Вот у вас слева, вот наш таргет.
Видите, просто ноль. Вот эта гиперпло… вот эта плоскость – это наша текущая оценка. Каждая
следующая модель будет ее исправлять. Чего? Просто среднее значение у. Просто выборочное
среднее. Взяли, да и все. У нас так как нет распределения, у нас интеграл нет, просто
среднее выборочное. Все. Соответственно, вот у нас первое дерево, смотрите. Мы его построили,
с каким-то весом его сюда добавили. Добавили второе дерево. Эх, жалко он нас, эти, не строит нам,
как его называют, остатки. Третье, четвертое, пятое, шестое. А, не, вот, смотрите, справа видно
остатки. Посмотрите, смотрите, слева полностью наш ансамбль, вот он нарисован, и наша целевая
функция. Справа каждая новая дерево и та гиперповершенность, которую дерево должно
опроксимировать, это ровно те самые наши градиенты, антиградиенты. Следите за гиперповершенность
справа. Пока нормально, одно дерево добавили. Заметьте, видите, уже тут появились какие-то
неоднородности, вот их видно. Если идти дальше, видите, у нас уже где появляются, тут у нас почти
все хорошо предсказано, поэтому тут у нас никаких впадин нет, тут почти константа грубая. Вот эта
штука все еще торчит, потому что мы здесь, видите, сильно ошибку имеем, тут градиент большой. Едем
дальше, заметьте, у нас опять гиперповерхность, которую наше дерево опроксимирует, она уже сильно
отличается от исходной, она же больше на шум похоже по центру. 6, 7, 8, 9, 10, вот здесь в конце совсем
хорошо видно. Видите, ошибки у нас большие только в районе пиков, в районе пиков у нас все еще есть
градиенты, в остальных местах у нас скорее какие-то небольшие девиации. И отсюда мы, собственно,
с вами видим, в чем суть градиентного бусинга. Если до этого момента мы с вами всегда, когда
решали задачу какую-либо, мы пытались построить все более-более-более информативное признаковое
описание, мы пытались упростить признаковое описание, придумать новые признаки, придумать
подходящее ядро, сделать нелинейную нашу модель то же самое дерево. Градиентный бусинг заходит с
другой стороны, у нас на каждом шаге признаки те же самые остаются, мы каждый раз упрощаем
таргет. По сути мы говорим, вот смотри, мы уже вот здесь хорошо предсказываем, не обязательно на этом
объекте, вот в этой области хорошо предсказываем, а вот тут у нас все плохо, поэтому надо
фокусировать внимание вот здесь. Вот вам пример, мы в центре уже все достаточно хорошо предсказываем,
а с краев у нас все плохо, поэтому следующие модели будут все больше и больше фокусироваться на краях,
игнорировать центр. Если говорить с точки зрения дерева, дерево будет что-то вроде вот такого,
иметь столбца где-то там слева с краю, а по центру будет просто нулевой констант предсказывать.
Улавливаете? И почему это важно? Потому что когда мы с вами говорим про градиентный бустинг или про
линии на модели, про все это остальное, это не какие-то два абсолютно разных мира, это просто
две крайности. Мы можем либо только работать с признаками, либо только работать с таргетом,
как вы понимаете, можем работать и с тем, и с другим. И поэтому это занятие у нас предшествует введению в
диплеринг, потому что когда мы доберемся с вами до нейронных сетей, мы ровно и открываем глаза на
то, что мы на самом деле можем строить с вами некоторое отображение из пространства объектов,
пространства ответов, и мы менять можем как одно, так и другое, причем последовательно. В чем проблема
градиентного бустинга, если про него говорить? В том, что он строго последовательный, и попав на шаг
n плюс 1, мы теряем возможность поменять предыдущий шаг. Это дерево, если там стоит дерево в качестве
базового алгоритма, в основном дереве. В общем случае, вы все равно построили модель, она фиксирована,
вы от нее считаете градиенты и так далее, вы не имеете права предыдущие модели менять. Поэтому
когда вы попали на n плюс первый шаг, все то, что было до шага n, отлиты в бетоне, больше его не
трогайте. Проблема в том, что это не всегда корректно, и иногда нам хочется что-то в начале поменять,
потому что ошибка в начале, она очень дорога, она потом всегда нам будет аукаться. Нейронные сети
ровно краски этим нам потом и помогут, и мы сможем менять любые шаги, любые преобразования в любой
момент, но об этом на следующей фрексе. Просто чтобы у вас не было вот этого разделения, что вот бустинги,
а тут нейронная сеть, нет, одно к другому очень хорошо подводит. Более того, бустинг появился
после появления нейронных сетей, просто он менее прожорливый с точки зрения данных, поэтому он в
начале нулевых зашел гораздо больше. Нейронные сети к тому моменту показали свой, скажем так,
милый оскал и стали переобучаться в лед на все, что только можно. Градиентный бустинг казался,
что «О, к doo не переобучается», ладно сделали просто побольше ансамбль тоже стал переобычаться,
все опять пригорюнились. То же самое было с нейронными с Templest nut с начала нейронные сети были маленькие
а до ацепты уже накопили большие, казалось, что нейронные сети это идеально, они работают везде
они не переобучаются. Просто потому, что вычислительные мощности на тот момент были слишком маленькие,
чтобы построить достаточно большую сеть, чтобы все переобучилось. Построили большую сеть,
все переобучалось, потом пришел бустинг, все такие БА, бустинг не переобучается –
переобучился. Потом опять нейронные сети в итоге пришли к выводу, что все переобучается, грузь, печаль, беда, обида, но при этом с этим можно бороться.
Хорошо. Вопрос сейчас есть?
Давайте как раз на примере еще вот простеньком
как это называется?
Регрессии. Разберемся. Вот что нам надо. Нам нужны данные,
дифференцированная функция потерь. В чем, кстати, плюс? Вы можете сразу аналитически посчитать производную функцию потерь по предсказаниям один раз и
потом сразу эту формулу эксплуатировать. Вас никто не заставляет на каждом шаге градиенты считать, вам не надо.
У вас аналитическое значение градиента есть, если у вас функция дифференцируема. Вот у нас какая-то семейство алгоритмов,
число итераций и initial value. Давайте просто константой первой модель. У нас будет и все.
Например, вот у нас будет вот такая зависимость. Косинус плюс Эпсилон, то есть каким-то шумом.
Функция потерь будет МСЕ. Опять же, в случае МСЕ все слишком просто. Мы просто предсказываем ошибку предыдущих моделей.
В случае с лог-лостом это уже не работает. Будьте осторожны.
У нас будут решающие деревни глубиной 2, уже не совсем пни, три итерации в начале константа.
Что мы видим? Слева опять же наш ансамбль полностью, справа наш текущий модель.
На первом шаге у нас только константа и, соответственно, ее ошибки. Это уже ошибки модели. Это вот наши эти градиенты.
На втором шаге вот наша добавочная модель, которая на это была обучена.
Вот наш полный ансамбль. Потому что средняя была ноль, соответственно, ноль плюс наша модель. Получилось то же самое.
Посмотрите на наши остатки на третьем шаге. Видите? Вот на что обучается вторая модель. Ну, третья, если с нуля считать.
Это уже далеко не везде похоже на наш Косинус.
Вот общий ансамбль. Вот четвертый шаг. Вот на что похожи наши остатки, на которые учится четвертая модель.
Вот наш полный ансамбль.
То есть каждый раз у нас все ближе и ближе к какому-то шуму становится наш сигнал.
Таргет, на который пытается обучиться наша модель.
Все.
Стал понять, что происходит?
Замечательно.
Ну и как бы пара графиков. Вот вам пример при увеличении числа деревьев для бэддинга.
Просто видим, что он выходит на переобучение в районе там 500 деревьев. Вот для рандом-пороста.
Синький. Он гораздо лучше держится.
Итоговая ошибка у него ниже. То, что деревья менее скоррелированные. У нас больше эффект снижения вот этой дисперсии.
Но тем не менее он тоже уходит куда-то на насыщение.
Вот наш гридентный бустинг. Он выходит на насыщение только в районе тысячи деревьев. Но заметь, итоговая ошибка еще ниже. Почему?
Потому что все равно решающий лес, решающее дерево, оно может переобучиться.
Когда мы с вами усредняем их между собой, мы просто-напросто избавляемся от ошибок остальных деревьев.
Но тем не менее мы итоговую сложность модели усреднением повысить не можем.
Потому что у нас невзвешенные средние. Они просто друг к другу пытаются, грубо говоря, скроховать везде.
В гридентном бустинге каждый следующий модель усиливает предыдущую. Поэтому чем глубже
в лес, чем больше моделей, тем больше у нас с итоговой будет качество, по крайней мере, на обучающей выбраке.
Понятное дело, на тестовый в какой-то момент у нас все переобучится и будет плохо.
Но гридентный бустинг замечательно переобучается. Будьте осторожны. Его можно переобучить в лед. И в чем проблема гридентного бустинга?
Если рэнд и форст вас кое-как страхуют от переобучения в том плане, что переобучилось одно дерево, не беда,
много деревьев, краски, проблемы с переобучением нивелируются, потому что они усредняют друг друга.
С гридентным бустингом, если одно дерево было обычно, ладно, одна модель была обучена где-то в ходе,
все что после нее это мусор.
То, что у вас переобученная модель, повлияет на все оставшиеся гриденты.
Соответственно, если у вас один элемент ансамбля переобучен, весь ансамбль с этого момента и далее это мусор. Он бесполезен.
Поэтому следить за гридентным бустингом надо очень аккуратно и там смотреть на валидацию.
А потому что у вас гридент станет сильно меньше, у вас ошибок стало сильно меньше на обучающей выборке.
То есть вы уже переподстроились под обучающую выборку, у вас гриденты почти все слопнулись.
А следующая модель пытается подстроиться под гридент, которых нет.
Вот.
Как-то так. Ну и вот вам пример краски из начала, вот вам опять две концентрические окружности, очень старая картинка, надо перерисовать.
Короче, снаружи красные точки, в центре синие точки.
Ну, поверьте мне на слово, потом можете посмотреть записи и я перерисую, наверное.
Синие точки в центре, красные по кругу.
Линейная модель одна не способна отделить, правильно?
То, что линия разделимой выборка.
Но мы можем вспомнить, что логистическая регрессия это ни разу не линейное отображение, это сегмойда от линейного отображения.
Поэтому их линейная комбинация уже вполне себе может задавать что-то нелинейное.
Собственно, вот вам гридентный бустинг над логистическими регрессиями.
Замечательно ограничивает центр.
Уловили?
Каждая полоса соответствует какой-то логистической регрессии.
То есть, каждая из них дает линейную разделяющую поверхность, но все вместе они смогли отделить центр от всего остального.
Да, в идеальном случае мы с вами можем три прямых провести и треугольником отделить все.
Но так как у нас там шум присутствует и так далее, вот за 40 шагов он хорошо отделился.
Хотя мы видим с вами, что за первые там 10, на самом деле он уже примерно перестал ошибку ронять.
Вот.
Ну что, гридентный бустинг вас вызвал страх и ненависть в БХИМе.
Вот здесь?
Ну...
Смотрите, это тестовая ошибка, поэтому то, что она себя ведет таким образом, абсолютно нормально, потому что обучаемся на трене, а на тесте валидируем.
То есть, на трене она, как правило, падает достаточно равномерно, если считать по всей выборке.
Если считать по бачам, то она себя будет вести вот так, потому что у вас от бача зависит хорошо или плохо, вы там на этом баче конкретно отработали.
Вот.
Смотрите, тут она, например, сглаженная, во времени, видите, она в среднем-то падает, достаточно стабильно.
Тут сглаживание применено, чтобы мы видели, что вот эти вот плески, они на самом деле в среднем все равно идут вниз.
Ну и коротенькое, наверное, аутро.
Рано-поро Stuff вас работает строго параллельно на уровне деревьев, поэтому вы его можете хорошо парализовать.
И если у вас словно есть 40 потоков, то 40 деревьев можете одновременно построить, будет быстро.
Применять тоже можете быстро.
Градиентный бусинг, он не парализуется влоп, но при этом стоит помнить, что дерево можно тоже строить достаточно эффективно.
Если вы строите, например, градиентный бусинг над деревьями, то каждый дерево может строится, грубо говоря, на два под дерева поделили, они могут параллельно строиться.
строится. Поэтому не стоит думать, что гранитный бустинг уж совсем медленная
штуковина. В современном мире он, конечно, медленнее, чем рано пора, но при этом он
тоже достаточно быстро строится и, как правило, сильно быстрее всяких нейронок.
Окей, сложных нейронок. Ну что, тут какие-то вопросы есть?
Еще раз, я именно и говорил, что если он переобучится, то все плохо.
Именно поэтому в среднем, исторически, глубокие деревья не используются, потому что
неглубокое дерево переобучить сложно, глубокое дерево переобучить легко.
Но опять же, это в среднем, это не то, что только так и никак иначе. Скорее так, если
вы не понимаете, что делать, лучше использовать неглубокие деревья.
С гранитным бустингом и глубоким, и с рано порастым. Если вы понимаете, что вы
делаете, плак вам в руки, барабан на шею. Делать можете угодно. Просто пока у вас
нет понимания, как бы, как в данной задаче отработает тот или иный алгоритм, например,
сильно у вас там шум присутствует или слабый, лучше придерживаются
каких-то общепринятых норм. Вот, как-то так. Короче, моя главная цель была, на
самом деле, чтобы сегодня вы поняли простую вещь, что градиентный бустинг
строит именно на каждом шаге аппроксимацию антиградиента вашей функции потерь по
предсказаниям. По сути, в каждой точке пространства, где есть обучающие значения
парой из обучающей выборки, вы строите ваши антиградиенты, вы аппроксимируете. Вот
это коровая вещь. Все остальное это всякие там свистопляски и так далее. Это осознали?
Хорошо. Ну, смотрите, у меня на самом деле еще простейкинг и блендинг, дополнительные
слайдики. Я, наверное, предлагаю что сделать? Продолжаю даже прямо сейчас сделать перерыв,
потому что не самая легкая была штуковина. Где-то 18-40 мы продолжим тогда, то есть 15 минут
перерыва. И там мы поговорим сначала на практике про деревья и про бустинг, а потом я вам еще про
то, как стакать это все дело расскажу. Все, лекция over.
