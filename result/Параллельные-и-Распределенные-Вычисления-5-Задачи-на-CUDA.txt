Во-первых, мы должны рассмотреть блок, связанный с особенностями синхронизации, и понять вообще,
какие примитивы синхронизации существуют в куде, а после этого разобрать задачу подсчета
суммы чисел массива и задачу нахождения суммы на префиксе. Это очень интересная задача,
поэтому, я бы так сказал, эта история даже пережила некоторую эпопею с тем,
как ее решали еще, не знаю, 10 лет назад, и по сравнению с тем, как решают ее сейчас.
Вот, и это мы с вами все действительно рассмотрим. Значит, по идее, у вас был
некоторый семинар, не знаю, был у вас он или нет, у моей группы, по крайней мере, был,
в котором мы говорили следующее, что у нас существует разделяемая память,
и память, которая выделяется в разделяемой памяти, у нас выделяется именно на один блок,
и она располагается у нас на чипе, и имеет скорость доступа, сравнимую со скоростью доступа в L1 cache.
Я не знаю, говорили вам это или нет, но я о своей группе говорил. Правда, на прошлый семинаре тоже
людей было. Видимо, все сдавали или отходили от задания по MPI, либо наступил еще один какой-то дедлайн.
Вот. Либо уже март наступил. Ну, кто его знает. В общем, в чем состоят? Сейв в том, что у нас
некоторые потоки, которые у нас могут работать внутри одного блока, они у нас синхронно работают
только в пределах одного варпа. То есть мы в пределах одного варпа действительно гарантируем то,
что у нас все инструкции выполняются атомарно. Но важен один момент. Это работало до архитектуры
вольта. То есть если у вас видеокарта V100, то в некоторый момент времени это может быть нарушено.
При этом те потоки, которые работают не в пределах одного варпа, а в разных варпах, но при этом они
находятся внутри одного блока, выполняют свои операции неодновременно. То есть у нас один ворп
может начать работу раньше, чем другой ворп. А если у нас возникает какая-то операция синхронизации,
вот здесь нам нужно взять значение этого элемента и сложить с значением этого элемента, то вернут
результат в этот поток. Тогда что у нас может быть? У нас может быть следующая ситуация. Представь
себе, что в момент времени ноль мы записали значение. Тогда у нас что может произойти? У
нас может произойти следующее, что в первый момент времени у нас отработал этот ворп,
потом в следующий такт времени отработал этот ворп. А дальше происходит следующее. Поскольку этот
ворп уже дошел до этой операции, то он может во второй такт времени начать записывать значение,
свою ячейку. А вот эта сумма, которая здесь у нас находится, она приходит в третий момент времени.
И если у нас было значение здесь х, здесь у нас было значение у, здесь было значение у',
то во второй момент времени какой результат у нас будет? Если мы складываем элементы во
второй момент времени, вот здесь. Ну тут вариантов немного. Либо х плюс у, либо х плюс у'. Кто
голосует за х плюс у'? Можно вопрос мне задать. Смотрите, еще раз. Значит, у нас есть временная
шкала. Вот у нас есть в момент времени ноль. У нас в ячейках записаны какие-то наборы значений.
Значит, у нас здесь изначально было записано значение х. Давайте здесь х0. А здесь у нас было
записано значение пусть у. Что дальше происходит? Пусть будет у0. Что происходит в дальнейшем? После
первой операции здесь у нас появляется значение х1. После записи значения в третьем момент времени
здесь появляется значение у3. А дальше мы в момент времени складываем значения, которые были в этой
ячейке и в этой ячейке. И мы получаем с вами некоторое значение х2. Так вот, вопрос. Чему равняется
х2? Есть здесь два варианта в ответа. Первый это х1 плюс у0 или х1 плюс у3? Кто за какой голосует?
К регистрам они атомарно обращаются? Нет, несколько варпов.
Она в принципе параллельно может работать с несколькими варпами. Просто мы не знаем,
с какими варпами она работает. Ну может. Так вот, вопрос. Какое значение у нас может получиться?
Ну мусорно вряд ли. Все-таки мы читаем значение вот здесь, из регистра, которое находится в этой
ячейке. Смотрите, если у нас порядок тот, который я задал временной, то есть сначала у нас идет
запись в эту ячейку, потом сумму сюда, а после этого у нас приходит значение сюда, то у нас
получается значение х1 плюс у0. А если у нас с вами порядок идет такой, что сначала мы делаем
запись в варпе, после этого мы делаем сумму, то тогда у нас значение будет х1 плюс у3. Какой
результат мы ожидаем с вами увидеть логически в порядке исполнения? Мы хотим допустим здесь
выполнить операцию, здесь выполнить операцию, после этого сложить элементы. Ожидаемый для нас х1 плюс у3.
Но такое быть не всегда возможно. Поэтому, чтобы выполнить вот эту вот операцию, нам нужна операция
sync threads. Что делает операция sync threads? Она берет и делает глобальную блокировку на блок. Мы рассматриваем все
внутри одного блока и гарантируем, что все операции записи внутри этого блока у нас будут отработаны.
Так, это понятно? То есть всегда, как только вы хотите прочитать петличку, вот так ее сделаем,
вот теперь у него катится. Теперь смотрите, что получается. Прежде чем мы хотим прочитать
значение из соседнего элемента разделяемой памяти, лучше делать sync threads. Причем он
должен вызываться всеми блоками, и всеми потоками в одном блоке, потому что это барьер. Если какой-то
из потоков у нас с вами не дойдет до sync threads, мы получим с вами deadlock. То есть аккуратнее с ним
внутри EFA. Но не поверите, это еще не все. Давайте мы с вами предъявим некоторые пример кода
на видеокарте. Я специально его подготовил в примерах. Вот такой код у нас. Представим себе следующую
ситуацию. Что у нас поток номер один выполняет функцию writexy, а второй поток выполняет функцию
readxy. Смотрите внимательно на код. Здесь указано следующее, что первый поток выполняет функцию
writexy, то есть у нас первый поток восстановляет значение х равно 10, у равно 20. А второй поток
указывает значение b равно y и a равно x. Вопрос, какие варианты результатов a и b у нас могут быть?
Все. Вы не поверите, варианты могут быть все. У нас x это 10, x это у нас один или сколько?
10, у это 2, 20. Получается, а это у нас x. 1, 10, 2, 2, 20, 20. Хорошо. Давайте подумаем в
концепциях классического параллельного программирования, какой вариант был бы невозможен.
Утверждается, что в концепции классического параллельного программирования какой-то из
вариантов был бы невозможен. Да, 21. Не был бы возможен вариант. Вот этот вариант невозможен на
цепу. Почему? Потому что когда мы ставим переменную a равно x, то у нас получается следующее, что перед этим
выполняется уже код b равно y. Значит, если у нас выполняется код b равно y, это означает, что в данном
случае b равняется 20, а a равно x, получается у нас в этот момент времени x уже равен 10. То есть,
по идее у нас если y равно 20, то a равно 10. На видеокарте это неправда. Точнее, далеко не всегда
гарантируется. Почему? Потому что здесь указано следующее. Здесь способ вычисления, который
используется в модель памяти. Это weekly ordered memory model. То есть, пока вы явно не запрашиваете
результат операции из какого-то потока, вы явно не получите результат. То есть, в принципе,
видеокарта сама вольна себе переставлять значение элементов и порядок операции,
который она исполняет. То есть, в принципе, она может переставить опции b равно y и a равно x.
И каким образом упорядочить как раз эту модель? Для этого как раз возникает такое понятие как
threadfans. Собственно, они здесь описаны в документации достаточно хорошо. И здесь есть следующие
гарантии. То есть, у нас есть threadfans-блок, у нас есть просто threadfans и есть threadfans-систем. То есть,
что гарантирует вызов функции threadfans-блок перед следующей операцией? Она гарантирует,
что все записи в память, которые были сделаны в thread, перед вызовом threadfans-блок, они будут
обнаружены всеми потоками в блоке. То есть, это означает, что если мы с вами вот в том коде,
который у нас был, поставим threadfans-блок, мы по факту зададим порядок, в котором эта операция
происходит. То есть, по факту, вот если мы сюда вот после этой штуки поставим threadfans-блок,
то у нас становится невозможным вариант. Какой? Вот этот вариант невозможен. Потому что мы
явно зададим порядок. Это кажется логичным. Вот просто нужно уточнять, что видеокарта,
она вот такая хитрая вещь. И есть вот такая глобальная блокировка. При желании ее можно
использовать threadfans-систем. То есть, вы по факту все операции записи сихронизируете,
ставите в правильном порядке. Но при этом, если вы будете использовать threadfans-систем,
это приблизительно похоже на глобальную блокировку. То есть, вы всем потоком,
который у вас есть в гряде, устанавливаете запись определенного значения. Поэтому лучше
его не использовать, но в целом вы можете прямо явно прописывать порядок операций. Вот. И
благодаря этому можно как раз реализовать глобальную блокировку. Значит, для этого нам
нужны атомарные операции. То есть, вообще, если вам нужно посчитать количество элементов,
то просто взять счетчик внутри блока нельзя. Вот. Потому что мы будем прислать неатомарную
операцию. Поэтому нам нужна атомарная операция. Значит, главная особенность еще атомарных
операций на видеокарте заключается в том, что они работают на уровне ледвакоша. То есть,
они работают достаточно быстро. И это даже можно будет увидеть, если вы попытаетесь решить задачу
подсчета суммы чисел в массиве и пытаетесь сравнить его с классическим решением,
которое я предоставлю. Вот. И оказывается, что операция подсчета суммы при помощи атомарных
операций работает быстрее, чем половина представленных реализаций. Просто потому,
что это происходит на уровне ледвакоша. Значит, смотрите, операции на видеокарте,
они пишутся на устройстве. Это функция atomic add, которая будет гарантировать, что после того,
как вы ее выполните, у вас значение счетчика account увеличится на единичку. То есть, что у вас не
будет датарейса в этот момент времени. То есть, у вас по факту будет внутренняя блокировка на
уровне ледвакоша. Есть вот такая вещь. Есть операция atomic exchange, которая позволяет вам получить
значение измененное по адресу. И есть еще одна операция atomic cas. Наверное, вы догадываетесь,
что она делает. Кто знает, что такое cas? Compare and set. То есть, вы сравните значение,
которое у вас есть. Если оно совпадает с тем, которое у вас есть, вы ставите определенное
значение. Для чего нужен cas? Для синхронизации, для блокировок. Именно так. Ну и, собственно,
вы можете сделать синхронизацию между блоками. Значит, вы берете специальную переменную типа
device. Device int lock равно нулю. А дальше делаете следующее. Вы пишете вот такой вот код. Do while atomic
cas lock 01. То есть, что он означает? Он означает следующее, что если у вас значение переменной lock
равно нулю, то вы ставите единичку и выходите из этого цикла. Иначе двигаетесь дальше. После этого
вы ставите операцию threadfence, чтобы все записи, которые были до текущего момента времени были
синхронизированы. То есть, устанавливаете порядок. Дальше вы уже можете выполнять определенные
операции. То есть, вот таким вот образом берется блокировка внутри GPU. Опять же,
лучше сводить количество блокировок минимуму, потому что это приводит потом к печальным
последствиям. Значит, смотрите. Тут я уже сказал, что sync threads используют внутри блок, как работает
threadfence. Значит, она для shared памяти будет делать все операции внутри блок, синхронизировать.
Плюс она указывает порядок для device элементов. То есть, мы ставим с вами sequential order для
массивов. В конце, когда мы выполняем блокировку, нам нужно будет ее снять.
Вот так вот работает глобальная блокировка. Так, идеологически понятно, как она работает?
Хорошо. И последний момент, который очень важно делать, если вы хотите эффективно писать на
видеокарте, это вам нужно понимать, какие есть ограничения на видеокарте. Для этого нужно
понимать, сколько у нас в распоряжении имеется регистр, потому что операция регистр спилинг
это очень неприятная операция, когда у вас значение, которое могло бы оказаться в регистре,
падает в оперативную память видеокарту. Значит, смотрите, ограничение по регистрам. Всего можно
получить 2 в 16 регистров на один блок. То есть, это 65 тысяч элементов. Ну, кажется, много. Но при
этом количество регистров на поток, который выделяется один, их всего до 255. То есть по факту
у вас количество регистров равняется одному байту. Одному байту бита. Значит, дальше, максимальное
количество потоков на один стриминг-мультипроцессор. Точнее, я бы так сказал, что на один блок это 1024.
Значит, как это проверить? Вы берете, меняете параметры ядра и увеличиваете размер блока в два раза.
В какой-то момент времени у вас программа не запустится, и все. У вас по факту будет ошибка
запуска ядра. Поэтому это нужно четко отслеживать. Значит, максимальное число потоков на стриминг-мультипроцессор
на самом деле не 1024, в разных архитектурах разные. Где-то оно 1536, где-то 2048. То есть сколько у
нас один стриминг-мультипроцессор может одновременно обрабатывать потоков. Значит, смотрите,
если у нас размер блока 1024, то регистров на поток у нас будет 64. То есть мы спокойно
можем с вами использовать 64 регистр на один поток без memory-спелинга. Значит, если размер блока 32,
то число регистров, которое у нас получается, уже будет равняться 2048, которое трансформируется
в 255. Да, потому что максимальный число регистров на поток у нас 255. 2048 больше, чем 255. Хорошо,
давайте вопрос контрольный. Какой должен быть размер блока для того, чтобы мы сделали максимально
возможное количество регистров, при этом не сильно теряли в производительности, исходя из этого. То есть
смотрите, что у нас получается. У нас получается, когда размер блока 1024, у нас регистров на поток
не хватает. Когда мы делаем размер блока достаточно маленький, то количество регистров на поток обрезается
сверху. Да, смотрите, когда мы ставим размер блока 256, то мы используем максимальное количество
регистров на поток. Это значение будет 255. Это крайне полезно для того, чтобы некоторые вещи
оптимизировать. Хорошо, мы с вами добили тему, связанную с синхронизацией. Давайте вопрос.
Где? Пока? Мы пока не дошли до подсчета суммы чисел массива. Пока что у нас были лог-при везде
вычисления во всех тех примерах, которые мы рассматривали. Теперь пора брать блокировки.
Едем к следующей презентации. Хорошо, давайте поедем к следующей презентации. Мы с вами сегодня
просмотрим две задачи, по крайней мере начнем рассматривать. Первая задача это как посчитать
сумму чисел массива, и второе это вычисление суммы чисел на префикс. Сразу скажу, что эти задачи
можно распараллелить. Единственный момент, который я должен сказать, а симптотика алгоритма может
быть большой. А симптотика алгоритма может быть нелинейной. Количество операций, которое мы делаем,
нелинейное. Можно посчитать сумму чисел массива параллельно за n лог n. А симптотика будет больше,
чем линейная. Наша цель сейчас будет рассмотреть базовый алгоритм, который работает за n лог n,
но свести его к тому, чтобы он работал за линию. Давайте сформулируем задачу. Мы поняли с вами,
что мы уже можем делать достаточно сложные операции. Мы можем складывать массивы между собой. Мы
там даже можем попробовать матрицу перемножить на вектор, и это тоже будет параллельно. Но вот
что будет, если мы попробуем с вами посчитать сумму чисел массива. Что такое сумма чисел массива?
Мы с вами понимаем, что нам нужно взять все элементы в массиве, которые у нас есть,
и каким-то образом сагрегировать в одну общую кучу. И сделать это еще каким-то образом параллельно.
Пока что кажется, что это неприятно, потому что нам нужно большое количество блокировок. И здесь
возникают два способа, которым мы это можем сделать. Но прежде чем мы это сделаем, давайте
введем общее понятие задач Reduce или Reduction. У нас с вами есть некоторый массив А, и нам нужно
выполнить некоторую операцию над этими элементами, которая будет являться, внимание,
коммутативной, ассоциативной и с наличием нейтрального элемента. Какие операции подходят
под это свойство? С нейтральным элементом. Да, конечно же, сложение. Увножение по модулю, да.
То есть первое, что мы должны потребовать от операции звездочка, первое это звездочка B на C,
второе, мы должны потребовать коммутативность, потому что если у нас не будет коммутативности,
то один из алгоритмов, который я сегодня предоставлю, он сломается. Я даже специально
спрошу, где ломается коммутативность. И третье, это наличие нейтрального элемента.
Да, по умолчанию некоторые алгоритмы будут работать, но не все. Так, какие операции
ультворяют этому свойству? Первое, это операция плюс. Какие еще операции? Умножить. Еще.
Не, канкотинация не коммутативная. Миниум максимум. Сор, да. Нет, обратимость не нужна.
Еще одна операция есть. Нот. Нот согласен. Вы не поверите, есть еще одна операция, но на самом
деле она хитрая. И есть еще одна операция, это операция вычисления среднего, но важно здесь
сказать, что она не напрямую является такой. Нужно сумму поделить на количество. То есть мы
считаем сначала операцию плюс, потом делим на общее количество. Да, есть еще операция количество,
в которой мы складываем единички, как ни странно. Потому что такое количество? Это сумма. Сумма
единичка. Вообще каунт можно не считать. Хорошо. Наша цель будет посчитать сумму чисел в массиве.
Классическое решение, у нас есть n операции сложения, мы делаем это все в одном потоке.
Кажется несложно. Давайте вспомним решение, которое предлагалось на блоки, связанных с классическим
параллельным вычислением, с mpi. Что мы можем сделать, когда у нас есть c потоков?
Да. Именно так.
Хорошо. Давайте как раз обсудим это решение. То есть у нас есть большой массив. Мы его делим
на c больших блоков. Вот это блок 1, вот это блок 2, 3, блок c. Значит в каждом из них мы считаем сумму.
Вот. А дальше складываем c элементов.
Получаем суммарное количество операций какое? Какой у нас будет wall time? Симпатически.
Ну это n, но если возьмем параметр c, равное количество потоков.
Мы получим где-то n делить на c плюс c операций. Потому что для того, чтобы посчитать сумму в каждом
блоке, в каждой ячейке, нам нужно n делить на c операции плюс сумме еще c операции.
Можно залог c. Ну все равно, а симптойтка хорошая. Ну нет, она даже оптимально работает.
Ну количество операций приблизительно. Хорошо, приблизительно количество операций.
Да, суммарное количество операций, да, согласен. Суммарное количество операций,
которое у нас есть, равняется n. Так, вопрос. В чем проблема этого алгоритма будет на GPU?
Я как минимум две знаю. Ну первое. Первым проблемам последовательно складывать плохо,
потому что у нас сломается кашление. Ну если варпам, то еще нормально, да, но все равно
размер массива-то у нас большой. Хотелось бы, чтобы... Ну да, то есть по идее нам нужно разбить
массив уже по-другому. То есть нам нужно взять наш массив. И, кстати, сразу подчеркну, что это
требуется сделать в домашнем задании. Смотрите, как мы отдаем это все. Мы берем элемент нулевой,
первый, c-1. Значит, дальше отдаем элемент цетой. Во-первых, чему может равняться c? Первый вариант
c это размер блока. Это первый подход. Второй подход, который здесь есть c, это количество
кудоядер. Да, в принципе, мы можем задать такие параметры, чтобы это у нас работало. Но третий
вариант, правильный, это сделать следующее. Задать c. Нет, нет, смотрите, у нас есть три варианта,
каким образом можем назначить c. Первое, это c, это размер блока. То есть это разбиение. То есть наша
цель максимально распараллелить наш код. Параллельность идет как раз по вот этой ветке. То
есть сверху вниз. И мы по факту должны сделать так, чтобы каждый поток максимально эффективно
считал некоторую частичную сумму. То есть здесь мы считали ее горизонтально, а здесь мы будем ее
считать вертикально. Вот. То есть здесь у нас будет c плюс 1, 2c минус 1. Да, да, да. Нет,
здесь c это определенный параметр, пока мы его не специфицировали. То есть нам хотелось бы,
чтобы вот тот алгоритм, где мы разбили наши все ядра для оптимального количества ядер c,
наш код, наш массив на вот эти вот блоки. Блоки последних элементов. Каждый поток мы хотели бы,
чтобы каждый поток вот эту сумму считал самостоятельно. То есть первый поток считает
вот эту сумму, второй поток эту сумму, третий поток эту сумму и последний поток последнюю сумму.
Да, но с видеокартой будет некоторая проблема. То есть мы хотели бы сказать,
чтобы первый поток, первое кудоядро считало бы сумму 0.20. Второй кудоядро считало бы вот эту сумму,
а последнее кудоядро считало бы вот эту сумму. Но нас здесь постигнет некоторая проблема,
потому что количество кудоядер у нас не обязательно будет делиться на размер блока,
чтобы у нас был оптимальный сдвиг. Поэтому здесь есть несколько подходов, как это решать.
Значит первое это сделать следующее. Мы выделяем с вами один блок. Это подход номер один. И c это
размер нашего блока. Мы тогда получаем ускорение, правда, получается не в с раз, не в оптимальное
количество кудоядер раз, а всего лишь от силы в 128 раз, потому что у нас все обрабатывается одним
стриминг мультипроцессором. В одном стриминг мультипроцессоре у нас 4 варпшедуллера,
в каждом из которых по 32 потока. То есть мы вот при таком подходе, если мы назначим один блок и c
равной размеру блока, мы получим ускорение где-то в зависимости от категории видеокарты в 64-128 раз.
Но если у нас количество стриминг мультипроцессоров это там порядка двух с половиной тысяч или там 4532,
если мы смотрим с вами видеокарту RTX 2080 Ti, то такой вариант не подходит.
По 32.
Нет, варп это физическая сущность.
Сейчас.
Нет, я говорю просто в одном стриминг мультипроцессоре у нас либо два варпшедуллера,
и тогда количество CUDA-ядер в нём 64, либо четыре варпшедуллера, и тогда количество CUDA-ядер 128.
Вот, второй вариант это просто назначить c равное количество CUDA-ядер, но тогда с этим будет работать
сложно, потому что параметры ядра, которые нам нужно будет передать, это количество стриминг
мультипроцессоров и 32. Но, как мы видели уже в предыдущей презентации, это не максимально,
не оптимальный вариант, потому что количество регистров, которые будут выделяться, оно будет не максимально.
И третий вариант, который у нас есть, он самый оптимальный. Собственно, мы назначаем параметры ядра
равное количеству стриминг мультипроцессоров, и последнее мы назначаем размер ядра оптимальный,
допустим 256. Да, конечно у нас агрегирующий массив в итоге с результатами получится в два раза больше,
но асимптотика будет честная. Порядка n делить на c, получается n делить на c, плюс какое-то большое от c.
Так, хорошо. Давайте я спрошу, понятно ли этот алгоритм? В чем его недостаток? У него есть один большой недостаток.
Какой? Есть идея? Вы уверены, что видеокарта в этот момент времени параллельно не работает?
И не загружена каким-то другим процессом? Вы точно удостоверились, что вы сначала запустили код на одной
видеокарте, а потом кто-то ночью пришел, подменил вам видеокарту, и у вас вот эти параметры поехали?
Внезапно ваш алгоритм начал работать в два раза медленнее.
Я считаю, что посчитать сумму элементов в массиве – это самая важная задача на вашей видеокарте, а во-вторых, никто же не будет менять видеокарту.
Ну а если она сгорела? Мне надоело просто массивы суммировать несколько лет подряд, а вот она и сгорела.
Согласен, она может сгореть, но на самом деле главная проблема этого алгоритма заключается в том, что этот алгоритм не является стабильным.
То есть как бы оптимальная производительность получить сложно. Поэтому есть другая идея, которую тоже придется реализовать.
Давайте мы научимся с вами, попытаемся с вами эффективно вычислять сумму чисел внутри одного блока.
Параллельно.
Тогда смотрите, у нас будет такой пирамидальный алгоритм. Мы посчитаем с вами сумму чисел внутри блока, потом мы эти блоки агрегируем, посчитаем сумму чисел внутри-внутри блоков.
И после этого мы получим одно итоговое значение.
Давайте попробуем это на картинке нарисовать здесь.
То есть у нас получается следующее.
Раз, два, три, четыре блока. Мы считаем сумму S1, S2, S3, S4. А потом мы берем это все как один отдельный блок и еще делаем один разок сумму.
Бинго.
Вопрос как это реализовать эффективно.
И как раз в следующую часть лекции мы посвятим тому, каким образом к этому всему можно подходить.
А подходить к этому можно аж целых шестью или семью способами.
Каждый способ будет улучшать предыдущий.
Каждый способ будет улучшать предыдущий.
Да, мы обсудили еще с вами очень тупой алгоритм, который не работает. Точнее он работает, работает достаточно быстро.
Вы можете в принципе сделать следующее.
Берете атомарную переменную sum и делаете for. Запускаете просто внутри каждого блока по счет суммы чисел и говорите, там у вас есть некоторые тит, thread.id.x, и вы пишете просто, ни на что не обращая внимания, вы пишете atomic at sum x от tit.
То есть такое тоже никто не запрещает делать.
Это даже работать будет быстро.
Давайте мы перейдем к задаче подсчета суммы чисел внутри блока.
И есть ли мысли у кого-нибудь из вас, как можно быстро попытаться посчитать за алгоритм сумму чисел внутри блока?
За алгоритм тактов.
Ну, вопрос. Представьте себе, у нас идет чемпионат мира.
Как обычно, как мы за умереть могут это делать, вот так?
Ну, турнирную сетку организовать.
Ну, допустим по Фи-Фе, любой чемпионат мира берем по футболу, мы понимаем, что это огромное мероприятие, в котором нам нужно выяснить победителя.
Количество победителей у нас один, да, нам нужно выяснить победителя.
Количество партий, которые нам нужно провести для этого, это приблизительно порядка ОАТ.
Но при этом мы разбиваем все на стадии, то есть у нас есть четверть финалы, полуфиналы, финалы.
Причем четверть финала у нас могут проходить параллельно, полуфиналы тоже могут проходить параллельно.
И мы доходим с вами до финала.
Вот, поэтому мы будем делать следующую вещь.
Значит, первая картинка заключается в том, что давайте мы как раз те самые партии, которые у нас есть,
расположим в разделяемой памяти, а дальше каждый поток будет соответствующим заслужению своего элемента.
То есть первый раунд у нас получается одна восьмая финала.
Нам нужно определить победителя одной восьмой финала.
Для этого у нас будет поток с номерами 0, 2, 4, 6, 8, 10, 12, 14,
и мы будем делать первую картинку.
Для этого у нас будет поток с номерами 0, 2, 4, 6, 8, 10, 12, 14,
которые будут складывать значения соседних элементов.
То есть в нулевую ячейку у нас будет записываться сумма нулевого и первого,
во вторую ячейку сумма второго и третьего и так далее.
Дальше что у нас происходит?
Вторая ячейка у нас получается сумма нулевого и второго,
это четверть финалы, потом четвертый и шестой,
восьмой, десять, двенадцатый, четырнадцатый.
После этого в третьем раунде у нас уже нулевой будет победитель,
по факту агрегатор четверть финалов,
встретятся между собой в полуфинале
и посчитают сумму уже половины элементов массива.
И в конце мы посчитаем общую сумму элементов массива.
Алгоритм работает за алгорифм.
Видно, за алгорифм тактов.
При этом давайте посчитаем,
какое количество операций мы по факту производим.
Ну да, получаем 2n-1
и в итоге осимпточка нашего алгоритма
в итоге будет n на log n.
В итоге, если у нас массив размером n,
то у нас общее количество операций будет n на log n.
Ой, тактов процессора.
А, нет, стоп, не n на log n.
Сейчас, секунду, о господи.
Ну если они все в это время работают,
на самом деле ничего не делают,
то так.
Да.
Но если их как-то освобождать,
то все не так?
Да, на самом деле спасибо большое.
Именно так нужно сказать.
То есть наша цель как раз понять,
действительно ли все операции у нас выполняются эффективно.
И смотрите, вспоминаем
омпцию дивергентности ворпа.
Мы говорили следующее,
что если у нас хотя бы один элемент в ворпе что-то делает,
то весь ворп выполняет операцию.
Возможно, просто элемент не записывается.
Давайте поймем, на первой операции,
сколько ворпов у нас задействовано.
У нас идет сложение
по четным элементам.
Вопрос.
Есть ли у нас ворпы, которые
простаивают и ничего не делают?
Или таких ворпов нету?
Нет.
Потому что у нас взаимодействует каждый
четный элемент.
И сейчас получается в каждом ворпе каждый четный элемент
у нас в своем работе.
То есть по факту мы, кажется, с вами
производим 16 сложений,
16 операций сложений
внутри ворпа, если у нас размер ворпа 32.
Но по факту мы производим с вами 32
операций сложения.
Потому что у нас каждый элемент ворпа
берет и складывает элементы.
То есть нечетный элемент ворпа тоже
производит сложения.
Просто они его опускают.
Посмотрите.
В итоге получается,
если у нас размер блока 256,
то на первом шаге мы вычисляем элементы 0, 2, 4
сложений.
У нас получается 8 ворпов.
Второй шаг. 0, 4, 8.
Тоже 8 ворпов. Все ворпы участвуют.
На каком момента мы это будем повторять?
Даже 64 пока он не станет.
Третий шаг. 0, 8, 16.
Четвертый шаг. 0, 16, 32.
Пятый шаг. 0, 32, 64.
Казалось бы, здесь количество ворпов
у нас задействованных должно быть
сильно уже меньше.
То есть мы дошли с вами, когда у нас
должно складываться 8 элементов,
мы складываем с вами 8 элементов
и на это тратим 8 ворпов.
Хотелось бы использовать один ворп для этого.
Да?
Но у нас же есть там
какой-то эльдорф кэш,
а мы не могли вот просто
для него вручить
то, что мы не читали,
чтобы сразу освобождать?
Вот есть,
это нужно смотреть инструкции,
но здесь суть как раз будет состоять в том,
чтобы правильно переномеровать потоки
для того, чтобы этим не заниматься.
Да.
Да.
Шестой шаг.
Вот здесь у нас 4 получается ворп-операции,
седьмой шаг, две ворп-операции,
один шаг, последний шаг,
это ноль операции.
То есть смотреть в итоге,
несмотря на то, что кажется,
что у нас все выполняется
за 8 тактов,
за 8 операций,
хотелось бы сказать, что у нас размер
ворпа 32 элемента,
поэтому по факту нам хотелось бы использовать
порядка от 8 до 16 ворп-операций,
то есть делать на 1-2 такты
на каждый ворп,
мы с вами получаем 47 ворпов
на сложение 256 элементов.
То есть мы делаем 47 тактов
в 4 раза больше,
чем мы хотим.
Беда.
Хотя здесь все честно.
Понятен ли этот алгоритм?
Хорошо. А теперь следующий,
второй подход к решению задачи,
давайте перенумеруем ворпы.
Перенумеруем номера потоков.
Ну это да.
То есть смотрите, у нас все получается,
нулевой поток складывает нулевой и первый элемент,
первый поток будет складывать второй и третий элемент,
второй поток будет складывать четвертый и пятый,
и так далее.
То есть как бы мы берем компексификацию
наших потоков.
Да.
Ну, кажется алгоритм простой.
Вот, это отдельный вопрос, который мы сейчас рассмотрим.
Ну да, да, да.
Да, скорее всего нужно каким-то образом
убрать эту операцию.
Так, давайте посчитаем, что с ворпами.
Вопрос.
Если мы сделаем так, то у нас получается,
что первые 128 элементов
внутри потока,
внутри блока будут заниматься сложением.
Сколько это ворпов будет?
Было 8 ворпов.
Теперь у нас первая половина
потоков отвечает за статус
ворпов.
И у нас первая половина потоков отвечает
за сложение. Вторая половина стоит.
Сколько у нас ворпов будет
задействовано?
4, конечно же. У нас будет задействовано только первая половина.
На втором шаге будет задействовано
два ворпа,
на третьем шаге будет задействован
один ворп.
Один ворп, один ворп,
один ворп, один ворп, один ворп.
то есть мы как бы берем и делаем следующее, что у нас первая половина будет отвечать за сложение
элементов. Вот, поэтому у нас будет здесь ворп 1, ворп 2, ворп 4. Вот, давайте еще раз на картинку
перемотаюсь. Тут важно смотреть именно на индекс. Видите, в кругляшках обозначены индексы.
Ну что, берем алгоритм рассмотрения. Вот это уже сказали про подводный камень. А что будет в памяти
в этот момент времени? Давайте обратим внимание, что мы с вами работаем с разделяемой памятью. Это
очень важно. И у нас ломается с вами кагеретность киша. Но более того, она ломается здесь еще более
критичным способом. Представим себе, что у нас с вами происходит сложение чисел массиве. И
посмотрим внимательно на алгоритм. Сейчас я сотру с доски. Вот у нас массив. Сейчас подсохнет.
Вот у нас поток номер 0 занимается сложением элемента 0 и 1. Поток номер 16 занимается сложением
номера элементов 32 и 33. Но более важно то, куда они пишут свои значения. То есть этот пишет в поток
с номером 0, а этот пишет с потоком номером 32. А теперь вопрос, как ни странный. Ходили ли вы
когда-нибудь в МФЦ? В 32 элемент он пишет массива. Не, ну вот такой алгоритм просто, чтобы у нас
данных не портился. Да, ходили в МФЦ. Вот вам говорят следующее. У вас в МФЦ 32 окна. В данном случае
32 окна. У нас хиленькие МФЦ, так сказать. У нас с вами 32 окна. И говорят следующее. Значит,
вот у вас обращение такое. Вы идете в окно, ваш номер по модулю 32. Ну, грубо говоря, будем считать,
что у нас операции типа повторяются случайно. То есть у нас первый человек идет в первую,
кабинку второй во вторую. 31 идет 31 кабинку. 31 и 32 человек идет в нулевое окно.
Нет, сотрудников там 32. Ну вот теперь смотрите, у вас получается следующее, что у вас вот этот
нулевой элемент, он должен идти в нулевое окно. Он должен идти в нулевое окно. А 32 элемент,
он в какое окно должен идти? Тоже в нулевое. Ну а дальше что происходит? Они работают внутри одного
варпа. То есть они делают это все за один такт времени. Смотрите, у нас возникает проблема,
что у нас в один такт времени два элемента внутри одного варпа хотят записать значение в одно и то же окно.
Да, вспоминаем то, как работает ворп. И вот эти вот 32 окна, которые я здесь перечислил,
в концепции разделяемой памяти называется банк. Размер банка равняется размер варпа.
И получается следующее, что если у нас два одинаковых потока, два потока внутри одного варпа,
захотят записать ячейку в один и тот же банк, то у нас возникнет конфликт. И в итоге видеокарта,
она должна быть user-friendly, она не должна кидать тик-фолд. Она сделает это за два такта,
то есть она сделает запись в два такта, а не в один. Давайте подумаем, как это можно решить.
Писать элементы в соответствующий номер потока. Хороший вариант. Единственное, что если мы здесь
начнем писать не в 32-й элемент потока, а в 16-й, то то значение, которое у нас было в 16-й элемент
потока, может перезатереться. Ну так, к слову. У нас еще появляется дополнительная правильная
синхронизация. И вот здесь, смотрите, нам понадобится коммутативность, наша операция. То есть пока мы с
вами нашим алгоритмом коммутативностью нигде не пользовались. То есть мы складываем элементы, как они
складываются. Что мы могли бы? Давайте придумаем порядок, который нам позволит как раз записывать
результат в свою собственную ячейку. Надо складывать с кем-то далеким. Бинго. Мы берем, бьем наш массив пополам
и делаем следующее. Этот элемент будет складываться с тем же самым элементом из второй половинки.
Этот элемент будет складываться с тем же самым элементом из второй половинки. В итоге у нас
каждая ячейка будет записывать результат свой собственный элемент массива. Ура-ура. У нас теперь
не будет конфликтов, потому что каждая ячейка, и мы записываем свой элемент массива, значит записывают
результат в свою собственную банку. Поток, который будет записывать результаты в ту же самую банку,
будет находиться уже в другом ворпе. Вот, поэтому вот такая вот вещь. Я тут промотаю, пример еще. Тут
большое количество фору конфликтов, банк конфликтов возникает. И главная особенность программирования
на видеокарте заключается в том, что когда вы работаете с разделяемой памятью, то нужно
максимально сильно избегать банк конфликтов. Это особенность архитектурная видеокарта. Давайте
еще раз. Что такое банк конфликт? Это поведение в shared memory, когда два потока внутри одного ворпа
пытаются записать данные внутри разных кашлений по одному индексу. Вот, собственно, здесь есть как
раз пример, что если у нас на каких-то дальнейших операциях будет запись вот такая, то мы получим
с вами, что нулевой и первый поток будут конфликтовать по нулевому банку. То есть особенность
здесь в том, что это мы на первом уровне обнаружили банк конфликта. То есть у нас получается где-то
половина конфликта именно по парам конфликтует. Если мы дальше пойдем, то они будут уже по четверками
конфликтовать, восьмерками конфликтовать и так далее. Но в этом расположении данных у нас
такой проблемы не возникнет. Так, хорошо. Вот как это решается? Это решается вот таким образом. То есть
еще раз. Мы берем значение в первые ячейки, складываем со второй половиной. И этот алгоритм уже
будет работать эффективно. Значит так, хорошо. Давайте сделаем затравку на семинары, потому что
здесь рассмотрелись только основные решения этой задачи. Значит решение следующее. Будет один хак,
связанный с тем, что первую операцию можно делать до копирования в shared memory. То есть взять
значение элементов, сложить, посчитать их сумму, отправить сумму в shared memory. Это ускорит где-то в
два раза. Алгоритм в том, что количество операций в shared memory уменьшится в два раза. Вторая вещь. Вот видите,
у нас здесь код. У нас после каждой операции, вторая оптимизация, у нас будет sync threads. То есть нам
необходимо будет синхронизировать потоки. То есть у нас сначала 256, потом 128, потом 64, потом 32. И
смотрите, когда мы уже будем получать элементы внутри одного варпа, нам окажется так, что операции
уже не надо делать, потому что мы все операции будем производить внутри одного варпа. То есть мы
можем снять пять блокировок, пять барьеров. Более того, есть некоторые прямо ассемблерные
инструкции, которые работают по производительности так же, как размер варпа, которые позволят нам
работать с этим всем эффективно. Задание со звездочкой. Знаете какое? Задание со звездочкой.
Вспоминаем процесс математики. 1024. Что вы знаете про это число? Да, хорошо еще. Нет,
тысячи нам не надо играть. Что еще мы знаем? Да, это 32 варпа. А это размер варпа. А теперь фишка в том,
что если вы умеете складывать сумму чисел внутри варпа эффективно, то вы можете провернуть ту же
самую операцию, но не на уровне блоков, а на уровне варпов. И в итоге у вас будет только две блокировки,
а не блокировки на каждой из операций. То есть здесь у нас получается раз сингтрец, два сингтрец,
три сингтрец, четыре сингтрец. И дальше снимаем блокировки. Здесь будет только две глобальные
блокировки, если мы будем считать именно это все на уровне варпов. Вот так вот.
Хитрая математика. Нет, я не знаю на семинарах. Если я успею к семинару этого дописать, то это будет
на семинаре. Можем дать до балла за это, если я не успею к семинарам это дописать. Да, лучше сейчас
спросить. То есть идея такая, значит еще раз. Мы по факту говорим следующее, что если нам
нужно сложить элемент, то мы говорим, что S от TIT, S от TIT плюс 32. Код будет вот такой вот здесь.
Ну когда у нас 64 элемента всего, мы пишем, что если номер нашего потока меньше чем 32,
то мы делаем S от TIT плюс равно S от TIT плюс 32. И не выполняем операцию сингтрец. Почему не выполняем
операцию сингтрец? Потому что у нас и так уже номер потока меньше чем 32. То есть у нас все
потоки находятся внутри одного ворпа. Ну то есть нам не нужен вот тут вот. Да, да, да. Да, да. А просто
их реализация занимает время. Звучит опасно, но ладно. Вот, поэтому что мы делаем? Мы берем,
говорим, что это у нас ворп номер 0, это ворп номер 1, ворп номер 32, 31. Значит в каждом из них
проворачиваем эту операцию. То есть мы пишем, грубо говоря. Что? Да, да, без синхронизации
складывать можем. Да. А здесь мы говорим следующее, что S от 0 плюс равно S от 16. Значит S от 1.
Во втором мы делаем S от 32 плюс равно S от 48. Складываем. А дальше у нас получается следующее,
что у нас в ячейках S0 получается S32. Сколько-то там находится сумма чисел внутри своих собственных
ворпов. Да, пройдет пять тактов. Без синхронизации, да. Пройдет пять тактов. Дальше мы вызываем общий
sync threads и перекладывание элементов. Да, и кладем это все в один ворп. И опять это все повторяем.
Одна блокировка. Да. Причем это дает ускорение где-то на 15-20 процентов по сравнению с самым
оптимальным вариантом, который был рассказан здесь. Так. Аккуратнее с камерой. Так, понятно ли
эта задача? Вообще на семинарах будут разобраны некоторые примеры, связанные с тем, что будет,
если в каких-то моментах времени что-то не подключается, то есть где-то sync thread забывается,
либо еще что-то. Ну вот. Но задача крайне полезная. И, собственно, дома, в домашнем задании вам ее
нужно будет решить одним из двух способов. Первый способ, это который на правой доске,
второй способ, это тот, который мы разобрали. Один из тех, который мы разобрали внутри блоков.
Так, значит, да. Слайд И. Видимо, что-то с ним пошло не так. Не был выполнен sync thread.
Давайте следующую задачу начнем, по крайней мере, рассматривать. Задача более интересная. Она
заключается в том, что мы хотим с вами посчитать не только сумму чисел массива, но и посчитать
сумму чисел на префексе. В каких случаях это может быть полезно? Знаете ли вы задачу под названием
RSC? Да, то есть где нам нужно посчитать сумму на определенном отрезке. Тогда мы можем статически
решить, первый раз посчитав сумму чисел на префексе, а во втором дальше вычислять раз
на значении двух элементов. Вторая вещь, которая здесь достаточно полезна, которую можно решать,
это задача фильтрации данных. Вы можете сказать, что я какие-то значения элементов массива оставить
только те значения элементов, которые меньше определенного. Это можно эффективно делать на
видеокарте. Давайте подумаем, вообще задача вычисления суммы чисел в массиве, суммы на префексе,
она параллелизуется вот в лоб или нет? В лоб нет. То есть в отличие от вычисления суммы чисел в
массиве, которые можно достаточно просто распараллелить, здесь парализация не происходит. Немножко подумать
и за n лог n мы с вами сможем распараллелить эту задачу, не за o от n. Хотя можно и за o от n,
но правда за o от n будет работать медленнее, чем за o от n лог n. Вот такие пироги, потому что асимптотика
алгоритма будет сложная. Поэтому задача скан будет заключаться в следующем. У нас с вами есть массив
a0, a1 и так далее, и наша цель посчитать сначала a0, потом a0 плюс a1, потом a0 плюс a1 плюс a2 и так далее.
Первый способ это параллельный способ, то есть вы берете последний способ, берете последний
и складываете элементы. Значит второй способ это сделать вот такую картинку. То есть смотрите,
давайте я поясню здесь детально на доске. Вот у вас есть элементы, у вас есть 7 элементов,
здесь индоксация будет 0, 0,4, 7, 6,
что мы делаем? Давайте посмотрим, что такое сумма элементов с 0 по 3, с 0 по 2. Как ни странно,
оказывается, что сумма элементов с 0 по 2 может быть подсчитана следующим образом. Мы берем,
считаем сумму элементов с 1 по 2 плюс 0 элемент. Что такое сумма чисел, допустим, с 0 по 7?
Это мы берем сумму чисел с 4 по 7 и складываем его с суммой чисел 0 по 3. Давайте я сотру,
убрали. А здесь мы как раз считаем вот эту сумму. Сумма чисел с 0 до 6 может быть подсчитана
следующим образом. Вы берете сумму чисел с 3 по 6 и складываете ее сумму чисел с 0 по 2.
То есть каждый элемент массива на каждом уровне, на уровне D,
будет хранить сумму 2 в D этой чисел нашего массива.
Вот, то есть сначала мы будем складывать элементы последовательно.
Потом у нас будет получаться, допустим, здесь у нас 0,1, здесь у нас будет посчитаться 2,3.
А дальше мы будем считать сумму чисел через 2. То есть у нас 0,1 и 2,3 складываются между собой,
получаем 0,3. И повторяем это до победного. Что мы с вами видим здесь? Мы с вами видим такую
достаточно тяжелую пирамидку из значений. И сколько здесь операций у нас будет?
Каждый раз примерно половина операций. Ну да. И слоев блоков. Да. То есть у нас получается асимптотика N лог N.
На самом деле, если честно так подумать, то асимптотика для одного блока будет в данном случае
блок size на логарифм блок size. То есть всего у нас асимптотика будет следующей. Если мы говорим в рамках одного массива,
за один блок мы из N, N делить на блок size, будем получать за N на логарифм блок size элементов.
Вот. Дальше потом у нас мы будем уменьшать размеры блоков. Мы будем получать с вами N делить на BS.
Да. Да-да-да. Если так, то это N лог N, да. Да. Смотрите, давайте тогда я тут перемотаю как раз.
Это мы тогда в следующий раз рассмотрим. Ну это на самом деле так. Во. Что мы делаем. То есть по факту,
мы считаем блок scan. Дальше мы храним суммы блоков в определенном массиве. А дальше у нас получается,
что для того, чтобы получить итоговый результат, вот у нас допустим есть вот здесь вот смотрите.
Элементы 4, 5, 6, 7. У нас будет сумма значит 4, 4, 5, 4, 6, 4, 7. Как ее добить до общей суммы?
Да. Прибавить то, что слева. То есть ставить сюда 0,3. А если у нас здесь элементы 8, 8, 9, 8, 10, 8, 11, то что нам нужно вставить?
Префикс суммы по блокам. То есть получается следующее, чтобы посчитать это все, нам нужно посчитать значит суммы по блокам,
посчитать суммы по префиксам, по суммам блоков и дальше вставить их в итоговый результат. Да, то есть у нас,
если мы посчитаем, у нас выходят элементы здесь 0. Начало пустое множество. Вот у нас сумма по блокам,
у нас есть элементы 0,3. Отсюда выходят у нас 4, 7. Отсюда у нас выходит 8, 11. А отсюда у нас выходит 12, 15.
Если мы посчитаем сумму по префиксам по блокам, то у нас получается следующая сумма.
Получается 0,3, 0,7, 0,11 и 0,15. Тогда мы можем еще сюда вставить пустое множество слева от этого и сделать следующее.
Пустое сложить с этим, 0,3 сложить с этим. Что получается? 0,7 сложить с этим и 0,11 сложить в последнюю.
То есть сделать общий инжект в конце. А поэтому здесь как раз за счет того, что у нас операция будет
инжект, то асимптотика как раз этого алгоритма будет немножко меньше, чем n лог n. Из-за того, что здесь
константа будет меньше. Поэтому те вот исхищения, которые будут здесь по поводу того, что мы хотим
избавиться от этого алгоритма за счет увеличения константа, они будут на самом деле нерентабельными.
Смотрите, сейчас объясню. Что тут будет? У нас будет асимптотика. Смотрите,
n на алгоритм блок-сайза плюс n на блок-сайз на алгоритм блок-сайз плюс и так далее. То есть это
вычисление как раз суммы на префиксах. Вот, сначала общий уровень, потом уровень меньше,
уровень меньше, уровень меньше. На самом деле здесь еще будет некоторый момент,
что нам нужно будет вставлять эти значения дальше вот в этот алгоритм. То есть мы должны
будем вставить эти частичные суммы после того, как посчитаем. Поэтому здесь еще дополнительно где-то
плюс n появится. Вот, ну и в итоге мы получаем с вами n на алгоритм блок-сайз
плюс логарифом n по основанию блок-сайз. Вот такая формула, вот такая асимптотика у нас получится.
Не, минимум мы искать не будем, потому что анафига нам нужно, если у нас это в итоге все делится на
количество кудоядер. Ну то есть получается в числителе у нас будет порядка 10-15,
образно говоря, а в знаменателе будет порядка четырех тысяч. Вот мы получаем,
что ускорение будет приблизительно в 40 раз, даже на таком тупом алгоритме. Вот, а если мы как раз
попытаемся избавиться от константа n, логарифм блок-сайз заменить здесь на единичку, у нас
будет здесь константа не единичка, а намного больше, порядка 5-7. Поэтому вот выигрыш, он не будет
работать. Вот давайте как раз с этим, чтобы понять, почему здесь константа будет достаточно
большая, мы это как раз на следующей лекции разберем. Но идея там достаточно красивая,
она может использоваться не только для вычисления суммы на префиксе, но и для
вычтения корреляции Кенделла. Так, давайте вопросы. В этом алгоритме? Да-да, но если правильно
организовать математику, то там нужно сделать IF на номер потока, не на четность-нечетность,
а типа в первой половине, либо во второй мы в половине находимся. То есть здесь нам нужно как
раз будет сделать IF номер нашего потока больше или равен чем offset? На самом деле вот в первом
подходе, который был с проблемной математикой, там он повлияет, а остальных он не влияет.
Все, наверное. Спасибо, что пришли. И тогда в следующий раз будем добивать эту тему.
Немного поговорим про concurrency в видеокартах.
