Ну что, приветствую всех, давайте начинать.
Прежде чем мы перейдем к сегодняшней теме, я хочу сказать пару слов про вашу домашнюю работу, которую вы решаете, возможно, прямо сейчас.
Я на самой первой лекции, на нулевой, говорил, что мы в конце концов собираемся написать свой собственный ГО с каналами, с селектами, со всем, что там бывает, с файберами, с какими-то примитивами синхронизации для них.
И я говорил, что мы собираемся это сделать буквально с помощью одного атомика.
Вот нам его функциональности достаточно, чтобы потом построить собственный планировщик, свои собственные легковесные потоки и примитивы синхронизации для них.
И вот в связи с этим я очень хочу обратить ваше внимание на две задачи, которые в вашей домашней работе есть, и на два аспекта в них.
Эти две задачи — это Mutex и Spinlock.
Что мне важно от Mutex, чтобы вы очень основательно разобрались, что такое Mutex, что он из себя представляет.
Потому что это единственный способ блокироваться из визу спейса.
Это единственный способ сказать планировщику, что вы чего-то ждете, а кто-то потом вас уведомит.
И сложно здесь не только в том, чтобы с помощью этого фьютекса написать блокирующий Mutex, а чтобы понять, какие гарантии фьютекс вам дает.
А чтобы это сделать, нужно разобраться, как он устроен.
И единственный честный и, мне кажется, самый хороший способ разобраться в том, как устроен Mutex,
это пойти по этой ссылке в ядро линукса, где, собственно, фьютекса написан, и прочесть комментарий там, где описаны его гарантии этого фьютекса и некоторые псевдокоды.
Понимания этого псевдокода достаточно для того, чтобы хорошо осознать гарантии.
Ну а поскольку мы дальше собираемся писать свои потоки, свои Mutex, нам и фьютекс потребуется самим самостоятельно написать,
поэтому полезно разобраться уже сейчас.
Ну и дополнительный приятный бонус у этого комментария в том, что если вы начнете его читать до конца,
то, возможно, вы придете в глубокую кроличную нору, связанную с моделями памяти.
Опять же, не предполагается, что мы сейчас способны понять вот эти картинки, но в будущем они нас коснутся.
К тому же, тут есть некоторая пасхалочка про пример, который я показывал на прошлой лекции.
Про сценарий, когда процессор довольно странно себя ведет.
Вот оказывается, что внутри фьютекса такая проблема возникает, такой сценарий синхронизации.
Но про это вы поговорите еще раз на семинаре, так что вот сфокусируйте, пожалуйста, внимание свое на этом, когда будете решать задачу.
И вторая задача, которая мне важна, это атомик, потому что...
Ой, простите, спинлог, потому что там нужно написать, конечно, не спинлог, а атомик,
и разобраться, что мы понимаем под атомарными операциями.
Exchange, FetchEd, какими-то другими.
И вот вас, мне кажется, это немного сбивает с толку, что в задачу уже как будто написана реализация.
Ну, задача написана не реализацией, в задаче описана семантика на ассембляре этих операций.
Вот мы читаем и пишем.
Но это не значит, что атомарный Exchange вот именно так реализован.
Вот вы будете решать эту задачу, и вот, во-первых, познакомитесь с какими-то другими инструкциями процессора.
Во-вторых, ну просто осознайте, почему они атомарные, какие гарантии вам даются.
И вот самое хитрое, что в этой задаче есть, и что даже непонятно, в какой степени вы способны сейчас осознать,
это различные варианты решения этой задачи, потому что можно пройти тесты и написать разный код.
Ну и что бы это означало? Наверняка же это что-то значит.
Наверное, какие-то гарантии у этого кода, у этих разных решений, какие-то гарантии будут отличаться у одного и другого решения.
И вот про эти гарантии и про эти разные решения вам задают два вопроса в условии.
Вот попробуйте на них ответить, по крайней мере подумайте над ними, покопайте.
Задача не про то, чтобы пройти тесты, конечно, задача про то, чтобы провести маленькое исследование и разобраться самому, почему оно именно так.
Вот если вы написали реализацию и вам кажется, что она тамарна, ну вот как-то убедите себя в первую очередь, что она тамарна.
Но на защите вам потребуется это сделать еще и со своими семинаристами, своими преподавателями.
Ну хорошо, про это мы поговорили, а сегодня у нас другая тема, сегодня мы поговорим про потоки.
Вот на прошлой лекции кто-то спрашивал, мы говорим про Mutex, как потоки синхронизируются,
а при этом мы их почему-то не запускаем до сих пор, что довольно странно.
Было такое, кажется.
Вот, и я эту тему избегал, вот уже две лекции избегаю, почти что, ну как избегаю.
Я вам показывал очень простой пример на самом первом занятии, где мы запускали потоки для того, чтобы обслуживать клиентов.
Вот мы создавали STDetright, передавали туда функцию, которая будет исполняться с аргументом,
и говорили Detach, то есть мы отвязывали исполнение потока от вот этого объекта STDetright.
Этот объект разрушался, а поток в фоне продолжал бежать.
И при этом мы сказали, что вроде бы нам так не нравится, мы так не хотим делать,
потому что операционная система не способна для каждого отдельного клиента нашего сетевого сервиса заводить целый поток.
Слишком дорогое удовольствие.
И нам нужно, видимо, делать что-то иначе.
Мы сказали, что нам нужно придумать некоторые файберы, которые будут выглядеть для пользователя так же,
но почему-то они будут более легковесными, видимо, потому что операционная система не будет их обслуживать
и запуск этих файберов и их планирование будет осуществляться в пространстве пользователя.
Но тем не менее, мы потоки все-таки запускать хотим в этом курсе,
потому что потоки, как я уже говорил раньше, это виртуальный ядропроцессор, это доступ к физическому параллелизму.
Так вот, мы хотим запускать потоки, безусловно, чтобы исполняться параллельно,
чтобы утилизировать наши вычислительные ресурсы, наш процессор,
но в то же время запускать потоки совершенно наивным образом.
Вот так вот конструируется Детраида и каждый раз, когда нам нужен поток,
когда нам нужна какая-то конкурентная активность, мы не хотим, мы не можем себе позволить.
И сегодня мы поговорим о том, как мы будем делать, как мы будем запускать потоки в этом курсе.
И решение называется «Пул потоков». Давайте перейдем в подходящий нам репозиторий сейчас.
Мы хотим сделать «Пул потоков», и вот предупреждение — это единственный способ,
которым мы будем запускать потоки в этом курсе. Больше мы к этому вопросу возвращаться не будем.
«Пул потоков» выглядит вот так вот. Мы конструируем его, мы передаем в конструктор число потоков,
которые будут выполнять некоторые задачи, а дальше у нас есть метод Submit,
который способен одному из этих потоков каким-то потоком передать задачу,
и эти потоки эту задачу исполнят. Вот мы просто фиксируем набор потоков, которые у нас будут в программе,
фиксируем их количество, и мы хотим всю работу, которую у нас есть,
исполнять в этом фиксированном наборе потоков. Новых потоков мы заводить не хотим.
Программа у нас может работать очень долго, она может быть демоном, она может работать недели, месяцы, не выключаясь,
но при этом новых потоков в ней не появится. Вот они на старте создаются, а дальше переиспользуются просто.
Что наш пул потоков будет уметь?
Он умеет буквально один метод, Submit. В него мы передаем какую-то лямду, в общем случае мы называем это задачей,
то есть некоторую функцию без аргументов и без возвращаемого значения, и пул потоков обязуется
после вызова Submit исполнить переданную задачу, переданную лямду в одном из своих потоков.
Какому именно мы не знаем. Когда именно это случится, мы тоже не знаем.
Вот если у вас есть вопросы, задавайте их сразу, я сейчас буду показывать вам пример.
Сделайте что-нибудь покрупнее, как вы думаете.
Ну, про реализацию мы сейчас поговорим. Мы скажем, что вот число задач может быть любым.
Число потока фиксировано, число задач, конечно же, не от пула зависит, мы этим не управляем.
Как правило, число задач растет с размером задачи или еще с чем-то, или с количеством пользователей.
Вызов Submit, когда он завершается, мы не знаем, как это будет работать.
Вызов Submit означает, что мы запланировали задачу на исполнение в пуле потоков.
Гарантировать что, прости?
Но если мы вызвали Submit, и он вернул нам управление, и пул, забегая вперед, не остановлен,
то задача должна обязана Eventual и выполнится в этом пуле.
Нет, верхней границы на время исполнения нет.
Поскольку мы собираемся нагружать пул задачами, которые эксплуатирует процессор,
видимо, число потоков там будет измеримо из числа физических ядер.
То есть, это вот представление, это вот представление, что если мы собираемся нагрузить
то число потоков там будет измеримо из числа физических ядер.
Это физическая параллельность для нас пул потоков, это вот виртуальные ядра.
Не совсем понятно, причем здесь глобальные переменные.
Кажется, это какой-то перпендикулярный вопрос.
Глобально ли так тоже тебя помешает? Не понятно, как это связано с потоками.
Нет, причем здесь... Сейчас, стойте, давайте не будем говорить про другие языки.
Мы пишем на C++, и вот это пул потоков с языком программирования мало связан.
Но, с другой стороны, если говорить про Python, то там нет смысла потоки запускать
в стиле реализации интерплитатора, так что это просто не очень подходящий пример.
У нас C++, давай все-таки про него.
Я покажу, когда придет время, но вот пока у нас такой пример.
Здесь нет... Я пока не говорю о слове join, и такого слова у нас вообще в поле потоков
нет нигде, поэтому вопрос не принимается, к сожалению.
Смотрите, что у нас пока пул умеет. Он умеет submit, и вот мы кладем в него три задачи.
Во-первых, мы кладем первую задачу, которая как будто бы изображает какую-то деятельность,
как будто бы изображает какая-то просто процессор сном, вот она блокирует поток.
Тут могло быть какое-то тяжелое вычисление, но вот тут написан slip.
Есть вторая задача, которая сразу печатает что-то на экран, и есть третья задача,
которая сначала спит, а потом из самой себя обращается к текущему пулу потоку
с помощью свободной функции current. То есть мы из пул потоков находим этот самый
пул потоков текущий, и в него планируем новую задачу.
То есть мы можем делать это снаружи, можем делать это прямо изнутри.
И у нас есть метод wait. Метод wait блокирует вызывающий его поток до тех пор,
пока в пуле остаются задачи. Вот когда пул закончит выполнять все задачи,
которые в нем уже есть или которые в нем появятся, то есть когда счетчик задач
такой логически опустится до нуля, этот вызов wait разблокируется и вернет
управление пользователя, до тех пор он будет поток блокировать.
То есть мы здесь вызываем wait и останавливаемся до тех пор, пока не будут
выполнены все задачи. А сколько их тут всего?
Четыре задачи. Вот мы должны увидеть один, два и три. Вопрос только в том,
в каком порядке. Ну вот давайте запустим и...
Нет, здесь никаких файберов нет. Здесь есть только вот потоки, есть метод submit
и есть вот задача. Задача, она абсолютно абстрактная, но тут мог бы быть STD
function, тут написано немного другой класс, потому что STD function имеет
свои ограничения, а именно он должен быть капельным.
И мы можем делать это снаружи, снаружи, снаружи, снаружи, снаружи.
Вот такой класс, потому что STD function имеет свои ограничения, а именно он
должен быть копируемым, а, скажем, лямбды, которые, замыкания, которые
захватывают move-on-ly объект, они не могут копироваться, поэтому STD function
с ними не работает, поэтому мы используем другой класс.
Ну, не суть. Это вот некоторый контейнер, который содержит функцию без
аргументов и возвращаемого значения. Вот все сущности, которыми мы
оперируем пока. Набор статических потоков, задача и вот метод submit,
который каким-то образом запускает планирование.
Вот к этому примеру еще раз вернемся, смотрите, что тут произошло.
Мы бросили в пул три задачи, там было четыре потока, и вот первая задача,
она заснула на каком-то потоке, а вот вторая задача, она запланировалась
на другой поток, раз у нас их всего четыре, и выполнилось сразу,
напечатала два. Дальше мы запланировали третью задачу, не дожидаясь,
пока вот эти две завершились, ну или параллельно с ними.
И третья задача запланировала четвертую и запланировала через секунду
после submita, так что вот вывод у нас получился в таком порядке.
Да, она заблокировала поток пула. Ну и давайте сразу договоримся,
что вот такой код писать неприемлемо. Вот этот код написан здесь для примера,
но когда мы будем говорить про какие-то полезные сценарии
использования пулопотоков, мы договоримся вот сразу, раз и навсегда,
что мы никогда не блокируем потоки пула. Это очень плохой, очень плохой
сценарий, потому что мы сначала договорились, что этих потоков
будет фиксированное количество, что мы новых заводить не будем,
и если мы поток заблокируем, один из этих потоков во всем приложении,
то мы у себя отнимем целое ядро процессора. Это не то, чего мы хотим, конечно.
То есть блокироваться ни в коем случае нельзя. Ни на слипах, ни на каких-то,
не знаю, ожидания других задач, ни на какие-то другие задачи.
Вот такие сценарии должны быть у нас исключены.
Ну, технически можно, насколько это полезно, это отдельный вопрос.
Вот пока мы к этому не стремимся.
Ну вот я пока акцентирую внимание именно на блокировке, что мы не можем
позволить себе заблокировать, чтобы не было таких ситуаций,
мы не можем позволить себе заблокироваться в потоке транпула,
потому что их ограниченное количество и все сценарии использования,
которые у нас будут дальше, там, карутины, файберы, какие-то вычисления, пусть неважно,
все они прямой блокировки потока должны будут избегать.
Блокировка в смысле фьютакса. У нас есть единственный способ заблокировать поток.
У нас есть ограниченное число способов заблокировать поток.
Это сисколы, которые обращаются к планировщику.
Например, слип или это фьютакс.
Вот слип мы просто, безусловно, блокируемся на некоторое время.
Во фьютаксе мы блокируемся на время ожидания какого-то уведомления
через фьютакс вейк из другого потока.
Но вот все эти механизмы для нас в пуле потоков должны быть исключены.
Ну да, иначе мы придем вот сюда, разрушим пул потоков, а задача еще не выполнится.
Еще раз, сабмит завершается вот почти сразу.
Он возвращает управление, когда задача запланирована на исполнение.
Завершение сабмита не означает, что у нас задача исполнилась.
У нас три сабмита завершаются очень быстро, а потом мы блокируемся на три секунды,
пока не завершатся все задачи, которые были в пул потоков, которые попали в пул потоков.
Или попадут.
Семантика вызова стоп следующая.
Мы хотим завершить все потоки, независимо от того, остаются ли в пуле задачи еще не выполненные.
Ну и просто вернуть управление.
То есть задачи, которые не успели выполниться, они просто выбрасывают, сигналируют сплом,
и потоки останавливаются.
Да, именно так.
Но это namespace с пулом потоков, который мы сегодня собираемся написать.
Нет, и кажется, до 26-го года не будет.
Вот оказывается, что очень сложно написать пул потоков.
Мы напишем сегодня какой-то, а вот прям идеальный пул потоков пишут бесконечное время в данный момент.
Ну вот мы с вами научимся писать идеальный пул потоков, кажется, к концу семестра, но это потребует усилий.
Итак, что мы хотим сделать, понятно, да?
Ну потому что стоп выполняет некоторую нетривиальную работу,
а выполнять нетривиальную работу в диструктуре по разным причинам не очень хорошая идея.
Лучше сложные вещи делать явными.
Ну это вопрос дискуссионный, это вопрос вкуса на самом деле, но мне кажется, что разумнее так.
Нет, почему? Просто current из разных потоков, разных пулов будет возвращать разные указатели.
Вот. Для этого требуется так называемые threadlock-переменные.
Вот про threadlock-переменные, кажется, мы ничего не знаем еще, да?
А здесь они где-то должны быть.
Случится неопределенное поведение, ну либо какой-нибудь ассерт упадет.
Ну это такие вопросы, которые мелкие инженерные подробности, они не влияют на суть происходящего.
Поэтому давайте перейдем к сути, а именно как этот пул потоков устроен.
Ну вообще, а что такое пул потоков для нас? Для нас это планировщик.
Он планирует задачи, простые функции без аргументов и без возвращаемого значения
на наши вычислительные ресурсы, виртуальные ядра в виде поток, операционной системы.
Как это планирование происходит?
Оно происходит с помощью очень простым механизмом, с помощью глобальной очереди.
Вот где-то у нас здесь есть картинка.
Вот это самый простой механизм планирования на свете.
Разделяемая очередь.
Вот здесь кружочки, это вот эти пустые кружочки, это потоки, которые мы называем
воркеры, которые выполняют задачи, работают.
Снаружи находятся клиенты, цветные кружочки, это задача.
И вот клиент, когда он говорит Submit, кладет свою задачу в некоторую общую очередь,
а все потоки воркеров внутри пула разбирают эту общую очередь.
То есть они блокируются до тех пор, пока в этой очереди не появится доступная задача.
После этого они ее берут и запускают.
Это очень разумный механизм планирования, потому что он хорошо балансирует нагрузку.
Если у вас какой-то поток простаивает, он простаивает только потому, что
на данный момент задач не остается, которых нужно выполнять.
То есть прямо сейчас работы больше нет.
Если работа есть, то все потоки нагружены уже.
Ну и кроме того, очередь это довольно разумный способ планирования,
в смысле FIFO-планирование. Чем раньше задача попала в пул потоков, тем раньше она исполнится.
Звучит разумно, правда? Согласны или нет?
На самом деле нет, это не разумно, потому что приложения бывают разными.
И где-то разумно FIFO-планирование такое естественное, а где-то разумно почему-то
покажем планирование. Есть разные сценарии синхронизации.
Но вот наш пул потоков планирует быть довольно универсальным и подходить под разные задачи.
И вообще говоря, под разные задачи нужно немного свои алгоритмы планирования иметь.
Ну вот у нас сегодня очень простой механизм, это общая очередь.
Ну, разумеется, настоящий планировщик устроен сложно.
Ну и забегая вперед, у нас будет лекция про планировщик Go.
И там мы разберем DesignDoc, ну и реализацию посмотрим.
Настоящий планировщик сложный устроен, конечно, сложнее, чем одна глобальная очередь.
Это не самый разумный алгоритм планирования для некоторых задач, для наших задач.
Как работает пул потоков, точнее, как пользоваться пулом потоков примерно понятно.
Как он устроен в первом приближении тоже должно быть понятно сейчас.
Давайте поговорим о том, что мы с ним собираемся делать.
Как мы будем его использовать? Какие задачи мы будем решать?
Ну вот какой-то очевидный пример, который приходит в голову.
Ну просто независимый пример.
Ну вот какой-то очевидный пример, который приходит в голову.
Ну просто независимые тяжелые вычисления.
Нам нужно, не знаю, принимать из сети какие-то блобики и там распаковывать их, декодировать как-то.
Вот мы бросаем задачу в Threadpool, там эта задача независима от других,
исполняется, декодирует что-то, возвращает нам результат каким-то образом, пока не понятно.
Вот можно себе такую задачу представить, а можно представить себе задачу чуть интереснее.
Вот, например, пусть вы пишете сортировку, и вот вам хочется ее распараллелить.
Вот если вы будете делать очень наивно, скажем, вы пишете QuickSort,
и на каждое разбиение вы запускаете по два потока, на две подзадачи,
то получится, что если вы запустили много сортировок, то у вас получится безумное количество потоков,
они все будут в ядре соревноваться за процессоры, будет очень много переключений контекста совершенно бесполезных.
Вот мы бы хотели, скажем, алгоритм сортировки упаковать его исполнение в пул потоков.
Причем этот пул потоков будет, пусть будет общий на разные сортировки.
Вот подходит ли наш пул потоков для задач, например, QuickSort или MergeSort?
Что, прости?
Ну, не знаю, почему.
Не совсем понятно. Что мы оптимизируем здесь?
Так у нас число потоков фиксированное.
Вот здесь проблема-то другая.
Что с таким интерфейсом проще написать QuickSort или MergeSort?
Почему?
Вот, а случай с MergeSort, какие у нас проблемы будут?
Ну вот, случай с MergeSort написать алгоритм довольно сложно здесь,
потому что мы породим две подзадачи, они завершатся,
а теперь нужно после завершения двух подзадач сделать еще какую-то третью.
И как нельзя делать ни в коем случае?
Породить задачу, которая породит две подзадачи, а потом заблокируется до их завершения.
Потому что блокироваться в пуле потоков мы не можем.
А значит, нужно каким-то образом запланировать третью задачу Merge
после того, как завершатся обе дочерние подзадачи.
И вот в задачах появляются зависимости.
Ну как, поток могут снять с ядра, то есть поток операционной системы,
а стедетрат могут снять с ядра просто планировщик операционной системы.
Такое может быть.
Ну вот, сами задача, это произвольные функции, что ты в них написал, то и будет.
Ну при блокировке заблокируется поток, а их всего там четыре.
То есть никакой магии-то не произойдет.
Кажется, что если мы знаем про PuTX и про потоки, то произойдет то, что должно.
Поток заблокируется.
Так вот, здесь мы видим, что возникают какие-то естественным образом задачи,
в которых нужно чуть больше, чем просто Submit иметь.
В некоторых задачах хочется, скажем, получить из функции результат.
Мы хотим запустить ее в пуле асинхронно, как говорят,
но при этом получить ответ из нее, то есть получить результат вычисления.
Пул потоков этого не умеет, у него есть просто Submit.
А в некоторых задачах у нас появляется еще одна, нам требуется еще одна функциональность,
а именно мы хотим в пуле потоков планировать не просто отдельные независимые задачи,
мы хотим планировать целый граф из задач.
Как-то их связывать, чтобы они синхронировались между собой,
чтобы одна вызывала другую.
И опять пул потоков ничего такого не умеет.
Значит ли это, что мы хотим доработать пул потоков? Нет, не значит.
Значит ли это, что мы рано или поздно научимся это делать?
Конечно, научимся.
Но вот пул потоков меняться не планирует.
Пул потоков хочет оставаться таким же простым.
И в этом будет его достоинство, мы об этом чуть позже.
Так вот же мы делаем.
Не, мы внутри сабмита делаем сабмиты, мы внутри сабмита мы в сабмите
передаем задачу, которая внутри себя может сделать еще один сабмит.
Вот она это и делает.
Хорошо.
Вот этот пример с вычислениями и зависимости между ними, он про что?
Про параллелизм, про то, как эксплуатировать тот факт, что у нас много ядер
и как-то их нагружать равномерно.
Но с другой стороны, мы же говорили, что в нашем курсе нас параллелизм
и ускорение за счет параллелизма не очень сильно беспокоит.
Это не наша тема.
Мы в этом курсе стремимся не ускорить исполнение ассортировки.
Нас беспокоит масштабируемость, нас беспокоит конкарнси.
Как именно упаковать в маленькое количество потоков в наш процессор
очень много активности пользователей, то есть обработчиков их запросов.
Вот как здесь вот.
Здесь мы делаем это очень неэффективно.
Мы хотим как-то эффективнее.
Мы не будем писать с вами сортировки на пуле потоков.
Наши задачи будут другую природу иметь.
Давайте подумаем, что в нашем курсе будет являться задачей.
Для пула потоков задача — это некоторая абстрактная функция.
Пул не понимает, что это задача, что она делает, зачем она нужна.
Как же будут выглядеть наши задачи?
Понимаете ли вы?
Звучит очень абстрактно.
Такого слова в курсе не было еще.
Так, а что будет таской? Что будет задачей?
Нет. Нет, не получится.
Потому что в запрос клиента он же, смотри, он же блокируется.
Вот он заблокировался на чтении сокета, потом заблокировался на запись сокета.
А задачи в пуле потоков не могут блокироваться.
Что будет задачей?
Трэдпул — это уже планировщик.
Куда еще больше планировщиков?
Тут уже есть операционная система.
На дне юзерспейса есть трэдпул.
Планировщик виртуальных ресурсов, виртуальных ядер.
Нет?
Ну вот, смотрите.
Мы это обсудим через две лекции.
У нас же файберы есть, да?
И зачем они нам нужны?
Ну не для того, чтобы, конечно, иил-то не делали.
Или что-то такое бестолковое.
Нам они нужны для того, чтобы они запускались в большом количестве.
А исполнялись в маленьком количестве потоков.
Но в данном случае файбер исполняется вообще в одном потоке.
И при этом как-то его эффективно используют.
Так вот, эти файберы, ну пока они ничего не умеют,
но однажды они научатся воду-выводу работать с сетью.
Или синхронизации.
И вот, смотрите, такое интересное наблюдение.
Вот файбер сам по себе — это не что иное как цепочка задач.
Вот мы говорили, что в трэдпуле мы хотим запускать цепочки графа задач.
Вот этот файбер отдельный, легковесный поток наш,
он и будет графом задач, цепочкой задач.
Он будет исполняться некоторое время, а потом будет встречать запись socket.
Или чтение из socket.
Или блокировку на мьютоксе.
И что он будет делать? Он не будет блокировать поток, разумеется.
Он будет каким-то образом подписываться на результат вот этой разблокировки,
или чтения, и поток освобождать.
А когда чтение завершится или мьютокс освободится,
то этот файбер запланирует обратно.
То есть нашими задачами будут кусочки кода между блокирующими операциями в файбере.
Но блокировок потоков при этом не будет.
И вот сами файберы будут для нас графами задач.
И вот именно поэтому трэдпул претендует для нас на универсальность.
Ему не нужно знать про задачи.
Какую они природу имеют?
Такое вычисление – это фрагменты файберов между точками блокировки.
Для нашего трэдпула это просто задача.
И мы увидим, что такая декомпозиция на самом деле очень разумна.
То есть мы сможем с вами параллельно развивать трэдпул как планировщик
и параллельно делать файберы, скажем.
Добавлять в них мьютоксы, контвары, каналы, селекты, все, что ГО умеет.
При этом трэдпул нам менять не потребуется.
Вот файберы будут знать про трэдпул буквально одно –
что в трэдпуле есть метод Submit.
Этого будет достаточно.
Да, а пул потоков про это ничего не знают.
Ему просто дают задачи.
А в этих задачах происходит некоторая сложная магия.
Но вот пул потоков, как планировщик и файберы,
как средство выражения конкурентных активностей,
будут разделены вот такой очень простой границей.
Вот одним методом Submit, который дает гарантию,
что задачи, запланированные на выполнение,
будут однажды где-то кем-то выполнены.
Ну, это долгая история.
Не то, чтобы планировать сейчас это объяснять.
И скорее объясняю, что пул потоков для нас – это очень важный механизм.
Это, собственно, планировщик в Visual Space.
И он артагонален конкретному приложению.
Ну, почти что.
Не совсем справедливо, конечно, так говорить.
Но можно будет придумать инструменты для того,
чтобы писать квиксорты какие-нибудь поверх пула.
Можно будет придумать инструменты, чтобы запускать легковесные потоки.
Ну, в общем, трэдпул для всего сгодится.
И вот поэтому я говорил на первой лекции,
что у нас есть две такие большие сюжетные линии в курсе.
Одна про то, как конкурентные активности выражать в коде
и у нас будут файверы, у нас будут фьюч, разные способы.
А параллельно с этим мы будем говорить про то,
как эффективно задачи исполнять.
И это история про внутренности трэдпула, в конце концов.
У нас там будет много маленьких, ну, много больших маленьких шагов
на этом пути.
И вот этот дизайн, он, на самом деле, очень разумен.
Ну, потому что он развязывает две большие задачи –
исполнение и выражение в вашей логике.
И этот дизайн, вот эта декомпозиция, она, конечно, справедлива
не только для нашего курса, в смысле, она универсальна.
Поэтому мы здесь ее и изучаем.
Вот, скажем, я показывал вам на первой лекции пример эхосервера на Расте.
Вот тут снова мы принимаем соединение клиентские с точки await.
Я про него уже упоминал.
Мы в будущем разберемся, что это значит.
И запускаем задачи, которые для каждого клиента запускаем задачу,
которая в цикле читает из socket и пишет socket.
Но вот это выглядит немного иначе, чем мы будем делать, чем наши файберы.
У наших файберов не будут никаких специальных ключевых слов.
Но, тем не менее, под капотом у этого фреймворка что происходит?
Смотрите, все вот это исполняется в некотором пуле потоков.
Тут его мы явно не видим, но он есть.
Ну или, скажем, мы говорим про корутины C++.
Вот на них тоже можно...
На корутины C++ 20.
На них тоже можно написать эхосервер.
Тоже с какими-то await-ами, ключевыми словами специальными.
И опять же, где это все будет выполняться?
Это все будет выполняться в некотором пуле потоков.
Или мы говорим про язык Kotlin с его корутинами,
которые умеют запускаться и блокироваться тоже умеют.
Так вот, где они исполняются?
Вот они исполняются в так называемых диспетчерах.
Если вы не указываете, где именно корутина исполняется,
она запускается в некотором фоновом пуле потоков.
Или мы говорим про файберы, которые делают Java.
И вот файберы файберами, но для них нужен планировщик,
и это вот просто готовый планировщик из библиотеки Java,
который уже написан, fork-join-pool.
Короче говоря, декомпозиция разумная, и мы будем дальше ей пользоваться.
То есть мы будем отдельно делать файберы, отдельно делать пул потоков,
и то и другое будем развивать, ну почти что независимо друг от друга.
В какой-то момент мы увидим, что все-таки нужно какие-то связи учитывать,
но до этого нужно еще добраться.
Итак, почему нам важен пул? Мы выяснили, что такое пул потоков,
как мы собираемся с потоками вообще в курсе работать.
Мы выяснили примерно, как он реализован и почему нас он интересует.
Осталось только написать.
Ну вот давайте мы этим и займемся.
Итак, у нас есть пул потоков с предсказуемым API.
Submit, fade, stop, которые мы обсудили.
И вот мы хотим, чтобы этот threadpool мог работать вот с такими вот примерами.
Давайте запустим этот пример, посмотрим, как это работает.
Ну вот, у нас есть пул потоков с предсказуемым API.
И вот мы хотим, чтобы этот threadpool мог работать вот с такими вот примерами.
Давайте запустим этот пример, посмотрим, что он напечатает.
1, 2. Что вы про это скажете?
Это не похоже на threadpool, потому что threadpool должен запустить задачи параллельно
на разных потоках, потому что всего их 4, задача 2, одна спит,
но почему другая в это время не исполнилась на другом потоке?
Ну, это в общем не странно, потому что threadpool пока реализован очень лаконично.
Вот он в методе Submit просто запускает задачу синхронно.
Ну потоков у нас нет просто.
Ну вот давайте мы начнем с того, что заведем в threadpool потоки.
Пока у нас такая заглушка, тут ничего нет.
Submit исполнение задачи, fade пустой, stop пустой, threadpool ничего не умеет.
Ну раз уж мы сказали, что в threadpool должны быть потоки, то давайте мы заведем потоки.
Вот, я буду писать какие-то ошибки к имперации, поэтому, пожалуйста, поправляйте мне, если буду так делать.
Потоки называются worker, они вот рабочие потоки запускают и исполняют задачи.
Почему бы и нет?
В смысле, почему мы не используем framework для тестирования, потому что мы не пишем домашнюю работу сейчас.
Ну можно было бы использовать, тут просто короче будет так писать.
Окей, пишем конструктор.
Что мы здесь напишем? Ну давайте заведем отдельный метод, что ли.
А может быть даже и не будем, напишем прямо здесь.
Нет, не хочу.
Чем эти потоки будут заниматься?
Ну пока не интересно, они будут выполнять какую-то функцию.
Рабочая функция для каждого потока.
Вот давайте мы напишем EU.
Итак, worker исполняет вот эту пока пустую функцию.
И у нас есть submit, ну вот давайте мы submit это тоже.
Изменим в правильном направлении.
Итак, что делают worker?
Они, наверное, ждут, когда им сюда идет вопрос.
Но судя по картинке, что делают worker и что делают клиенты в submite?
Они работают с очередью.
Вот клиенты кладут в очередь,
worker забирают задачи из очереди и исполняют их.
Поэтому, видимо, нам нужно написать очередь.
И для этого у нас есть заготовка, отдельный header, в котором будет очередь задач.
Но смотрите, очередь задач, она нужна не только для пулопотоков.
Просто примитив коммуникации и синхронизации для потоков довольно общий.
Поэтому очередь у нас будет, конечно, шаблоном.
Назовем ее пока так, чуть позже пересмотрим это название.
Что она будет уметь?
Здесь? Не знаю.
Почему мы копируем его?
Мы пишем шаблон.
Тут класс T.
Это могут быть копируемые объекты, могут быть move-only.
Вот, кажется, такая сигнатура позволяет нам работать и с move-only объектами.
Если клиент хочет копировать, он просто копирует, передает по значению.
Если клиент хочет помувать, он пишет put std move и свой объект.
Кажется, что это довольно универсально.
И в пуле потоков мы собираемся эту блокирующую очередь использовать для того, чтобы передавать задачи.
Вот у нас есть задача, это std function.
И что мы сделаем в Submitty?
Мы положим туда задачу.
Что мы сделаем в процедуре потока?
Мы положим туда задачу.
Ну, это процедура, которая выполняет каждый поток worker.
Вот, смотри, мы завели потоки в конструкторе.
Завели count потоков.
Создали в массиве workers, в векторе workers потоки.
И каждый из них исполняет вот такую вот лямду.
Ну, вот, вот.
Такое вот замыкание.
Понятно или нужно пояснить что-то?
Ну, можем. Мне просто...
Мне кажется, так...
Ну, там нужно будет все эти байнды писать. Вот не хочется.
Лямбда... Короче, в C++ какого-то, не знаю, с какого-то года не нужно писать все эти байнды, нужно писать лямбда.
Это правильный способ, по разной причине.
Что?
Во-первых, не надо, потому что я могу и так, и так делать.
Я могу ему-ить, когда я захочу, и копировать, когда я захочу.
Я всем управляю. Мне не надо, например.
Вот. Значит, пока понятно, да, что происходит?
Пока только не написана очередь.
Ну, вот мы уже научились ей пользоваться, пока не написана очередь.
А вот смотрите, нужны ли в этой очереди какие-то другие методы?
Ну, скажем...
Ну, вот да. Хотелось бы какой-нибудь метод из empty, да?
Да я его вообще писать не хочу, потому что это бессмыслится.
В блокирующей очереди не нужны ни методы empty, ни методы size, ничего подобного.
Это не контейнер для хранения данных.
Это примитив коммуникации. У него совсем другие сценарии использования.
Вот вы... Зачем вам метод empty? Вы вызвали его и получили true. Что это означает?
Да ничего, потому что после вызова через миллисекунду очередь снова может стать пустой.
Для вас это абсолютно бесполезный сигнал.
Вы не можете на него надеяться. Все слишком мимолетно.
Поэтому метод empty... Констат такие... Просто сотрем это все.
У нас ни empty, ни size ничего не будет. Вот здесь мы кладем задачу в очередь,
здесь мы дожидаемся очередной задачи. Вот и все, что нам нужно.
Вот, ничем другим нам пользоваться. И в эту задачу не потребуется, и в принципе не потребуется.
Ну что, давайте писать теперь вот эту самую очередь.
Потому что сам предпул кажется пока слишком прост, чтобы его как-то комментировать.
Но метод wait не написан, к этому вернемся еще.
Итак, очередь... Для нее нужен контейнер.
Давайте возьмем контейнер.
Ну и что этому контейнеру не хватает еще?
Не хватает Mutex, потому что, смотрите, разные потоки вызывают take
на одной и той же очереди, разные воркеры, и разные клиенты вызывают submit.
И все работают с одной очередью, с одним контейнером buffer внутри.
Так что его нужно защитить. Для этого мы используем Mutex.
Вот, к сожалению, для Mutex имя Mutex лучше всего походит,
но это буквально единственное исключение в жизни, кажется, когда такая ситуация возникает.
Во всех остальных случаях можно подобрать какое-то более подходящее имя,
но вот здесь сойдет такое.
Окей, давайте напишем put теперь.
Что?
Не очень понял.
Ну, во-первых, этот класс, которого нет в std, мы пишем сейчас на std.
Во-вторых, нет, не подойдет. Ну, почему мы сейчас не понимаем пока...
Ладно, мы можем это понимать, но, видимо, пока не понимаем.
Давайте допишем put.
Пут готов, да?
Давайте напишем take теперь.
Что в нем должно быть?
Так, я вот руками Mutex не захватываю, я использую Rybert. Отлично.
Ну, давайте я напишу сейчас такой вспомогательный метод, который потом мне пригодится,
пока он может выглядеть немного лишним.
Вот метод, который извлекает из головы очереди элемент в предположении,
что эта очередь не пустая, буфер не пустой.
Потому что я хочу Assert.
Нет, не очень понял.
Извини за мой тупой ответ. Это precondition для функции.
То есть функция вызывается в предположении, что буфер не пуст.
Ну, потому что было бы странно, если бы я move-ал из головы буфера что-то, когда он пустой.
То есть это не то, что я проверяю, я вот предполагаю, что функцию иначе бы не вызвали.
Вот. А теперь что мне написать в take?
В общем, какая семантика подходит потоку воркеру?
Ну, чтобы оно блокировалось до сих пор пока либо в YouTube заплачено,
либо пока заплачен в YouTube или очень пустая.
То есть смотрите, мы вот в этом месте, в этой строчке хотим,
чтобы поток воркер блокировался, если очередь пустая.
Поэтому, собственно, у нас blocking queue называется это все.
Ну вот, что же мы тут напишем?
Ладно, прежде чем мы что-то напишем, у меня есть некоторые комментарии к именованию этого класса,
потому что, возможно, название можно улучшить.
Дело в том, что очередей в мире великое множество.
В смысле, очередей десинхронизации потоков, потому что они все предназначены для немного разных сценариев.
Вот бывают очереди неограниченной ёмкости, бывают ограниченной ёмкости,
вот наша очередь будет неограниченна.
По некоторым причинам так разумно. Вообще говоря, теория массовое обслуживание говорит,
что если у вас система обслуживает пользователей и в ней бесконечные очереди,
тогда это бесконечное время ожидания, и вот это так не нужно делать.
Нужно явно отказывать, они увеличивают время ожидания для бесконечности,
но вот здесь нам подойдет такая семантика.
Кроме того, есть сценарии в зависимости от того, различают сценарий в зависимости от того,
какое количество потоков кладет элементы в очередь и какого извлекает.
Потоки, которые кладут элементы в очередь, их называют продюсерами.
Потоки, которые извлекают, называют консюмерами.
Вот тут верно. Поэтому мы скажем, что это мультипродюсер, мультиконсюмер.
Ну или пишут так вот. Или бывает там мультипродюсер сингл консюмер.
Такие у нас очереди тоже будут. Ну она блокирующая.
То есть если очередь пустая, то поток, который извлекает, у него что-то,
который ждет из нее элементов, он заблокируется.
Вот такая вот штука. Так вот, хорошо бы это все отразить название.
Вот вы читаете код, и вы сразу понимаете поведение этой очереди.
Это довольно разумно. Правда, очередей бывает много разных.
Я не шучу сейчас. В смысле, это хорошее, это лучшее название для этой очереди.
Ну и вот, она должна заблокироваться в методе take, если очередь пустая.
Что делать-то?
Да-да-да. Продюсеры-консюмеры.
Ну вот, если буфер не пустой, то мы так уж и быть вызовем функцию takeLocked.
Простите. А иначе что нам делать?
Нет, не просится.
Фютекс не просится. Давайте я сразу объясню, наверное, почему.
Потому что фютекс, это очень низкоуровневый приметив синхронизации, очень низкоуровневый.
И у него семантика такая, она связана с ячейкой памяти.
То есть мы заснем мы или не заснем зависит от содержимого ячейки.
А здесь заснем мы или не заснем зависит не от содержимого ячейки.
Здесь это зависит от состояния дека.
Это несколько более сложный объект.
Поэтому фютекс, в конечном итоге вы правы.
В смысле, операционная система ничего, кроме фютекса, для блокирующего ожидания не дает.
Но, тем не менее, вот прямо фютекс мы здесь использовать не хотим.
Давайте мы напишем сначала очень тупое решение без знания фютекса.
Допустим, про фютекс в первый раз в нум вообще не знаю ничего.
Вот напишем следующее.
Заменим это все на униклог, во-первых.
Который умеет разблокироваться вручную.
То есть он в конструкторе тоже захватывает мютекс, диструктор освобождает, но у него есть минутанлог.
И вот если очередь была не пустая, то что мы сделаем?
Мы заберем элемент и вернем его.
А иначе как нам быть?
Мы пришли в очередь, взяли мютекс.
Видим, что очередь пустая.
Пока мы мютекс держим, новый элемент никто не положит.
Поэтому мы должны лог отпустить.
Так нам же нужно время дать другим потокам, чтобы они сделали что-то полезное.
Зачем?
Чтобы они тоже имели доступ к этой очереди.
Я сейчас напишу какой-то скверный код.
По разным причинам он скверный.
Например, не пишите using numspace в заголовочных файлах.
Но все равно этот код стелеть придется, так что не страшно.
Вот такая реализация.
Мне кажется, что она лучше, чем ничего.
То есть она должна примерно работать.
Может быть, это не самый эффективный способ делать синхронизацию.
В смысле, спать 10 мс.
Потому что, может быть, через 1 мс. элемент появится.
Пока так.
Мне кажется, что очередь мы в целом написали.
Трэдпул тоже мы почти написали.
Вот здесь мы ждем задачу, исполняем задачу, игнорируем исключение правды.
Здесь мы планируем задачу на исполнение.
Ну и давайте напишем тест для нашего трэдпула.
Тест будет с датарейсом, простите меня.
Аккуратные люди.
Я бросаю в пул задачи, которые будут просто увеличивать счетчик.
А потом я, видимо, хочу дождаться их завершения.
Кажется, мы не написали эту функцию, да?
Ну ничего.
К этому вы вернетесь к домашней работе.
Вот. Ну и у нас не хватает еще метода stop.
Ну или даже пока напишем еще проще.
Напишем в деструкторе, что у нас...
Потоков не осталось.
Что?
Что?
Что?
Сломается? Ну так и должно быть, мы же не написали метод.
Нет, еще раз. Не еще раз, в смысле, я обозначу нашу цель.
Наша цель написать какой-то пул потоков.
Хороший вы напишите дома сами.
Вот все, что вам не нравится, вы можете потом исправить.
В смысле, почему он сейчас должен задачу запускать уже?
Ну деструктор это не совсем не работает, не упривыречивай.
Вот давайте мы запустим сейчас этот пример.
Ну он что-то вывел и сломался, да?
Насколько разумно то, что он вывел?
Давайте вот убедимся, что задачи все выполнились уже к этому моменту.
Просто, может быть, он какие-то задачи потерял, их было 100 500,
а получилось вот 9 9 3.
Нет, судя по осердту, у нас просто деструктор упал,
потому что мы потоки не остановили.
Я сейчас ожидаю, что числа совпадут.
Отлично. Значит, наш пул потоков
он работает, потому что числа совпадут.
Задачи кончились в нем.
Но ответ не 100 500, потому что он работает параллельно.
И вот эти счетчики, они между другом,
эти инкременты гоняются и получается, что какие-то два инкремента
читают в регистре одно и то же. В регистрах увеличивают,
потом пишут дважды одно и то же. То есть, инкременты теряются.
То есть, то, что у нас число меньше, чем 100 500, это наоборот хорошо.
Значит, пул работает параллельно. Запускать задачи в разных потоках.
Ну так сложили, так вот выстроились планеты, я не знаю.
Я бы не стал здесь, короче,
это не то, что нужно делать.
Насколько много у вас гонок получилось в программе?
Должно быть ноль просто.
Ну, я не знаю.
Ну, тут от многих вещей это зависит.
Пока планируем задачи, мы планируем их в один поток,
а исполняются они в четыре потока.
Но, может быть, их просто много там не накапливается в пуле.
Ладно, пул работает в целом.
Пока у нас очередь плохо написана.
Вот давайте мы это место исправим.
Ну, давайте мы это место исправим.
Пока у нас очередь плохо написана.
Вот давайте мы это место исправим.
И смотрите, я утверждаю, что здесь задача довольно общая.
Вот смотрите, у нас было некоторое...
Что происходит у нас?
У нас есть очередь, в ней есть буфер.
Мы берем mutex, смотрим на буфер.
Если он не пуст, то извлекаем элемент.
Если он пуст, то мы должны mutex отпустить, чтобы дождаться,
пока в буфере появится новый элемент.
Проснуться и этот элемент забрать.
Забрать mutex обратно, забрать этот элемент.
Можно здесь увидеть некоторую общую задачу.
Вот у вас есть разделяемое состояние.
У вас есть mutex, который вас защищает.
У вас есть потоки, которые ждут
выполнения некоторого условия на этом разделяемом состоянии.
И у вас есть потоки, которые это состояние меняют
и это условие реализуют.
И им нужен примитив для синхронизации.
Вот мы здесь... Чего бы хотели в идеальном решении?
Вот в этом месте, в этом else.
Мы бы хотели заблокировать текущий поток.
Мы бы хотели отпустить mutex
и заблокировать текущий поток до тех пор,
пока другой поток не захватит mutex сам
и не положит в буфер новый элемент.
Задача довольно общая.
Эта очередь с этим буфером, это просто частная иллюстрация этой общей задачи.
Ждем исполнение предиката на разделяемом состоянии,
выполняем предикат и уведомляем другой поток.
Ну и вот для этой общей задачи есть
общее решение, которое называется condition variable
или условная переменная или кондвар, просто говорят.
Вот у этого самого кондвара есть,
ну, можно сказать, три метода.
С одной стороны это wait для блокирующего ожидания
и с другой стороны два вызова notify one и all
для того, чтобы уведомлять другой поток,
что условие некоторое выполнено.
Какова семантика этих операций?
Семантика wait. Давайте перейдем
в условия одной из домашних задач ваших.
Все, что мы видим в этом курсе,
мы потом делаем руками, поэтому и кондвар не станет исключением.
Вызов wait.
Вызов wait мы передаем,
ну, в наш wait в домашней работе мы передаем
прямо захваченный mutex, в std condition variable
мы передаем
unique lock с захваченным mutex.
И семантика такова.
Мы отпускаем lock внутри вызова wait
и засыпаем в некоторые очереди внутри ядра.
Ну, под капотом там все равно будет mutex, вы это сами увидите
в домашней работе. Ничего другого вы все равно нет.
И когда другой поток
вызывает notify one, он вас будет
и вы из wait возвращаетесь обратно,
обратно захватывая lock.
То есть снаружи wait вы всегда
lock'ом владеете, внутри wait вы его отпускаете,
заходите и забираете обратно,
когда вы возвращаетесь из вызова.
Один из ждущих потоков.
Условные перемены, как ты видишь,
просто по сигнатурам вызовов, ни про какие предикаты,
это можно стереть из своей памяти,
чтобы закрыть глаза и не видеть этого.
Вот у вызова wait нет никакого предиката.
Условная переменная про предикат ничего не знает.
Состояние, условие, буфер, пуст, не пуст.
Кондвар про это ничего не знает.
У него есть просто wait.
Это неправильный вывод,
правильный ответ сложнее.
Но вот в нашей домашней работе в кондваре не будет этого предиката,
это просто некоторое,
ну не знаю, не сахар, не так не говорят,
некоторая маленькая утерита,
которая помогает использовать кондвар, чтобы это было проще немножко.
Но это не фундаментальный метод кондвара.
Операция основная кондвара это wait, notify one, notify all.
Wait с одним аргументом захваченный mutex.
И очень важно, пока мы этого не понимаем, наверное,
что когда мы вызываем wait,
то мы атомарно отпускаем блокировку и встаем на очередь ожидания.
Конечно, на уровне процессора это не атомарно все,
но вот атомарность, как она достигается,
вы опять же в домашней работе увидите.
Когда мы вызываем notify one, мы будем один из ждущих потоков.
Он просыпается, захватывает mutex обратно,
и выходит. Если мы зовем notify all,
то мы будем все потоки, которые ждали на кондваре,
и они все пытаются выйти из wait,
но они не могут, потому что mutex один.
Но они все по очереди его захватят и выйдут из этого кондвара,
из этого wait.
Осталось теперь кондварам воспользоваться, чтобы написать
блокирующую очередь чуть получше.
Давайте ее назовем пока вот так,
вот это плохая идея, мы имя скоро исправим.
Какой код мы здесь напишем?
Опять захватываем mutex.
А теперь мы будем их исправить.
Я неаю, неаю, неаю, неаю.
Я неаю, неаю, неаю.
Опять захватываем Mutex, а теперь нам нужна не пустая очередь.
Что делать? Видимо, мы хотим Mutex и дождаться, пока очередь станет не пустой.
Отлично.
А в методе Mutex мы напишем на tf1.
Мы положили элемент в очередь и разбудили один из потоков, который ждал, возможно, этого элемента.
Сейчас, повтори вопрос, пожалуйста.
Сейчас, повтори вопрос, пожалуйста.
Wait отомарно. Wait, во-первых, отпустит Mutex, во-вторых, заснет в очереди.
В-третьих, когда другой поток вызовет на tf1, проснется, захватит Mutex заново и выйдет из Wait.
То есть, когда мы выйдем из Wait, мы снова владеем Mutex. Мы снова в критической секции.
Кондвар, это такое примитив синхронизации.
Так мы его даже используем не то, что в пуле, а мы его в очереди используем.
Вообще, кондвар – это довольно низкоуровневый примитив синхронизации.
В смысле, в каком-то прикладном коде вы его не должны использовать.
Как правило, кондвар появляется в реализации каких-то других примитивов синхронизации.
В домашней работе вы напишете несколько таких штук.
Вы напишете барьер для потоков. Вы напишете симафор.
Вы напишете, ну, future напишете, вы с помощью кондвара или нет, я не знаю.
Ну, в общем, с помощью кондвара можно разные вещи делать.
Ну, вот в данном случае мы с помощью кондвара делаем очередь.
Ну, а в свою очередь сам кондвар сделан, разумеется, через Mutex.
И вы всю эту цепочку отследите, кажется, разберетесь в домашней работе.
Кондвар и Mutex, они помогают друг другу. Вот здесь они работают в связке.
Здесь нам одного Mutex мало. Нам нужно дожидаться в выполнении некоторого условия.
Вот мы здесь отпускаем Mutex, встаем в очередь и делаем это атомарно. Это важно.
Почему это важно? Потому что представьте себе, что мы проверили, что очередь пустая,
буфер пуст, отпустили Mutex внутри вызова Wait.
Пришел другой поток, сделал put целиком, взял освободившийся Mutex,
положил элемент в очереди, сделал natify1.
Natify1 никого не разбудил, потому что никто не спал еще.
А потом управление вернулось вот этому потоку Teiko, и он наконец заснул на втором шаге.
Вот такого быть не должно.
Такого быть не должно.
Wait и natify, они относительно друг другу должны быть атомарными.
Не может быть так, что между шагами Wait выполнится natify.
Ну, по крайней мере, между первыми двумя шагами.
Как это реализовано, ну, вот вы увидите.
Ладно, давайте, во-первых, переменную и переименуем.
Вот условная переменная, она для того, чтобы дожидаться
в выполнении некоторого предиката на разделяемых данных.
В данном случае, что буфер не пуст.
Ну, вот давайте мы так и назовем.
Вот для кундвара всегда нужно давать разумные имена.
Вот по тому условию, которое вы на них ждете.
Потому что здесь нет слова task вообще нигде.
У нас просто очередь для каких-то элементов.
Ну, там hasValues, hasItems тоже подойдет.
Вот тут получается not empty, wait.
То есть я жду, пока очередь не станет не пустой.
Вот такая реализация.
Прежде чем запустить код, давайте я покажу вам картинку,
которая, мне кажется, хорошо объясняет кундвары.
Как это можно себе визуально представлять.
Вот смотрите, ну, картинка тупая, но вот она дает хорошую модель,
на самом деле, для понимания.
Вот у вас есть разделяемые данные.
И у вас есть mutex, который их защищает.
Вот здесь данные – это вот очередь, буфер,
а mutex – он в такой виде комнаты.
И чтобы зайти в эту комнату, вы должны mutex захватить.
То есть внутри этой комнаты находится только один поток.
Вот он приходит и видит, что очередь пустая.
Что ему делать?
Он хочет заснуть, дождаться, пока очередь перестанет быть пустой.
Для этого он говорит not empty, wait.
Отпускает mutex.
И как будто бы переходит в кладовку и сидит там.
И вот в этой кладовке может быть много поток.
И они все без mutex уже.
То есть mutex освобождается и может зайти в другой поток,
захватить mutex, положить элемент в буфер и сказать notify1.
И тогда этот notify1 разбудит один из потоков, который идет в кладовке.
И этот поток попытается выйти.
Но чтобы ему зайти обратно, то есть выйти из wait,
ему нужно снова захватить буфировку.
Да?
Если эта картинка понятна, то давайте запустим код
и посмотрим, как он работает у нас.
В смысле порядка пробуждения?
Я думаю, что никаких.
Ну вот, у нас есть стредпул, у нас есть более совершенная очередь.
Можно запустить теперь пример.
Он сломался.
Но сломался по-другому.
Он сломался на этом ассерте.
А это был precondition для функции.
То есть мы вызывали takeLogged, если мы были уверены, что он будет работать.
И мы его не делали.
И мы его не делали.
И мы его не делали.
И мы его не делали.
То есть мы вызывали takeLogged, если мы были уверены, что очередь не пустая.
А почему-то в нашем исполнении метод вызвался,
но очередь пустая, буфер пустой.
Это довольно странно, потому что если буфер был пустой,
то мы зашли в wait и заблокировали до тех пор,
пока нам не просигнали, что буфер не пустой.
А, а давайте while делаем.
Ну вот.
Вот, так рассуждать нельзя.
Так рассуждают люди, не слишком осведомленные в кунварах.
Вот вы идете в документацию по кунвару и читаете, что, оказывается,
оказывается, из wait вас могут вывести просто так.
Вот просто, просто так.
Это называется spurious wakeup.
Вот вам не просигналили, никто не сделал на TI5.1, но вы проснулись.
И вы такие, ну ладно, какой-то баг в реализации, нужно написать while.
И вы пишете этот while, запускаете снова пример.
И все работает.
То есть вы починили.
Но вы думаете, странно, ерунда какая-то, да?
Почему вы не починили кунвар вместо этого?
Так вот, кунвар чинить не нужно, потому что проблема на самом деле не в этом.
И код упал у нас не потому что там spurious wakeup.
Спулю свейкапов здесь не было.
Вот почти наверняка не было.
То есть, то, что почти не было в этом исполнении spurious wakeup.
Проблема в другом.
Вот такой код, который мы делали, он был в этом исполнении спулю свейкапов.
Но он не был в этом исполнении спулю свейкапов.
Проблема в другом.
Вот такой код.
В нем не спулю свейкапы, в нем race condition просто.
То есть, можно запланировать ходы потоков так, что все развалится.
Вот смотрите.
Пришел поток в метод take, взял блокировку.
Посмотрел на буфер.
Буфер пустой.
Ушел спать в wait.
Mutex освободил.
Пришел другой поток.
Ушел Mutex освободившийся.
Положил элемент в буфер.
Просигналил.
Первый поток.
Этот сигнал получил.
Сигнал в смысле не сигнал операционной системы, разумеется.
Я так условно говорю.
Уведомление, нотификацию.
Mutex wake получил.
Он проснулся.
В смысле, он проснулся из ожидания внутри wait.
Но из самого вызова wait он еще не вышел.
Почему?
Потому что Mutex нужно захватить.
При выходе из wait нужно вернуть себе Mutex.
А теперь представим себе, что появляется третий поток,
который приходит в take.
И вот смотрите на картинке.
У вас теперь есть...
У вас есть буфер, в нем есть один элемент.
И есть два потока.
Один приходит в take отсюда.
Просто первый раз в него заходит.
А другой выходит из кладовки.
И вот они борются за общий Mutex.
И кто его захватит первым, непонятно.
Но если вы Mutex писали, то вы понимаете,
что никаких гарантий нет, кто его первым захватит.
Вот они конкурируют между собой.
И если получится так, что первым возьмет блокировку поток из wait,
то он видит в буфере элемент, возьмет его и завершится успешно.
Но если выиграет другой поток, который просто заходит в take,
то он зайдет в take.
Он увидит, что в буфере есть один элемент,
сразу его заберет и уйдет.
А потом мы проснемся,
ну, в смысле, а потом, наконец, мы в выходе из wait
заберем себе блокировку обратно,
выйдем из wait и увидим, что буфер снова пустой.
Ну, мы этого не увидим, потому что...
Да, мы этого не увидим и сломаемся просто.
Ну, в смысле, увидим в ассерте.
Что?
В смысле, он решает проблему эту.
Мы, если нас разбудили, мы должны снова перепроверить условия,
потому что нас могли подрезать.
Тут другой поток нас опередил.
И никакого с пулю своей капы не было,
никакой проблемы в кондварах не было.
Тут проблема именно в race condition.
Просто вот так упорядочились шаги потоков.
Так что мы обязаны писать while, и поэтому, пожалуйста,
пожалуйста, пожалуйста, раз и навсегда запомните,
что кондвары нужно использовать с while
и поймите, почему.
Вот забегая сильно вперед, на зачете невозможно получить зачет,
не понимая этого.
Вот все, кому удается не получить зачет, не понимают этого.
Ну, потому что как это...
Mutex, он сам по себе.
Сам Mutex не может этого гарантировать.
Я предлагаю тебе написать решение задачи
kundvar, slash kundvar, там, где нужно написать kundvar.
И тогда ты ответишь себе на свой вопрос.
Возможно, не стоит с этого начинать домашку,
потому что как бы это...
Ну, в общем, задача для того, чтобы разобраться,
почему возникают с пулю свои капы,
но почему может произойти что-то странное,
и вот почему гарантии именно такие.
Ты напишешь и поймешь.
В смысле, зачем еще один Mutex?
У нас состояние одно.
Mutex должен быть общий, разумеется.
Взаимное исключение.
Да нет.
Все...
Кажется, здесь все...
Все уместно. Так, стоп.
Это...
Ну черт возьми.
Возвращаемся к второй пулу.
Возвращаемся к второй пулу.
Нет, я сейчас...
Был момент на лекции, когда я говорил,
что Race Condition это не то же самое,
что DataRace, это вообще разные вещи,
я говорил, что Race Condition это нарушение вариантов
в нашем коде.
Ну вот, поток пришел делать Popfront из пустого дека.
И это происходит, потому что
вот так сложилось планирование потоков.
DataRace это ситуация, когда у вас есть
ящика памяти, и вы с ней работаете
без синхронизации из разных потоков,
и в некоторых потоках вы пишете.
Вот это Race Condition.
А вот...
Вот это, это DataRace.
Одна ящика памяти, мы с ней работаем
несинхронизированно.
Здесь несинхронизированного доступа
нет нигде.
Здесь синхронизации все OK,
здесь DataRace нет.
Ну что ж, у нас осталось три минуты, да?
Наверняка я забыл сказать, что это важное.
Ну вот, давайте подведем итог,
чему мы научились.
Ну, наше локальное достижение.
Мы поговорили...
Мы на примере пулопотоков увидели
некоторые новые сценарии синхронизации.
Мы увидели, что мютоксов мало,
ну, разумеется, их мало,
и увидели, что возникают какие-то очереди,
какие-то ожидания на каких-то предкатах.
Ну и вот для этого у нас есть кондвары
для того, чтобы
решать больно общую задачу, дожидаться
выполнений некоторого условия,
дожидаться выполнений некоторого...
дожидаться выполнения предката
на разделимых данных.
Для этого у нас вот есть кондвар.
Ну, и надеюсь, чтобы вы увидели,
как примерно с ним правильне
обращаться.
А второе более...
Второе более важное наше достижение,
более глобальное, мы увидели, что
потоки, мы не собираемся в этом курсе запускать, вместо этого мы хотим использовать пул потоков, и вот пул потоков когда-нибудь
на самом деле уже довольно скоро станет для нас таким вот универсальным планировщиком, в котором будут запускаться все те
все те средства выражения конкурентности, которые мы в курсе изучаем. Файберы, карутины, фьючи,
вот все будет исполняться там. Так что
с одной стороны Домашка сейчас будет про то, чтобы разобраться, как там на низком уровне все это синхронизируется и работает, а
дальше мы перейдем к пулу потоков как такому базовому инфраструктурному компоненту для всего нашего курса.
Вот пожалуйста, отслеживайте такие вот глобальные сюжетные линии. Спасибо большое, на сегодня это все.
