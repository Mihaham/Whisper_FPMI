сегодня обе пары буду с вами я и у нас сегодня нам предстоит закончить разговор о контейнерах
и начать разговор об аллокаторах последний контейнер который надо обсудить я кстати сбил
нумерацию в прошлый раз значит да на самом деле да короче 8 ну давайте так сказать формальности
чтобы соблюсти значит 8 2 это был вектор 8 3 значит это был дек 84 это были итераторы 85 это была
реализация тераторов 8 короче надо сдвинуть нумерацию 86 это был лист 87 это был мэп и 8 8 у нас
сейчас будет вот так да значит последний пункт это unordered map мы с вами обсудили как устроен
обычный мэп и осталось определить как устроен unordered map я сразу скажу что unordered map вам тоже
надо будет реализовывать это будет третья задача но там уже его надо будет реализовывать еще и с
муфсемантикой то есть план такой я сейчас мы сейчас поговорим о том как устроено алгоритмически а
потом у вас мы обсудим локаторы и вам надо будет написать лист уже с локатором а потом уже мы
обсудим муфсемантику и надо будет написать вам unordered map еще и с муфсемантикой вот такой план
значит а я вспомнил почему я не помню ответа на этот вопрос про дек потому что эта задача в
прошлом году была только на основном потоке а на основном потоке я ничего не принимал вот поэтому
я не помню как не знаю как это делали вот просто ее не было просто просто с листа сразу начали
а в этом году да в этом году что-то я решил что что вам надо вам поменьше чились а то вы как-то
слишком быстро справляетесь но в листе там нету такой проблемы там там тебе не нужно
реалацировать ничего так unordered map кто знает что такое хэштаблица люблю задавать вопрос на
продвинутом потоке в конце первого семестра я обнаружу что не все знают вот но я понимаю да да да
вот к сожалению программа курса алгоритмов она немножечко не согласована с нашей вот но на
основном потоке людям рассказывали что такое хэштаблица правда же вот она про две нет ну
сейчас короче будет легбез за пять минут что такое хэштаблица значит хэштаблица ну это такая
структура данных что она позволяет делать insert erase и find по ключу примерно за вот единицы если
повезет вот тут главные слова если повезет потому что может не повезти тогда будет уатен а как может
не повезти ну что вообще такое хэш хэш вот тут я уже должен не ошибиться с переводом это значит
типа мелко рубить так шинковать вот перемешивать а nor de red да хорошо так вот хэш будем называть
хэшом такую функцию которая по нашим объектам возвращает некоторые ну скажем int и она обладает
таким свойством что ну грубо говоря тяжело по числу восстановить обратное значение то есть
она как-то очень странно вычисляет какое-то числовое значение от нашего объекта и оно очень ну похоже
на случайное вот применительно к разным объектам она выдает разные числа и эти числа ну как-то
очень странно очень равномерно разбросаны по всему множеству интов и непонятно вообще не
предскажешь каким оно будет так вот и по числу обратно понять каким будет каким был объект из
него получен и очень сложно вот вот хорошая хэш функция она таким свойством обладает что она более
или менее равномерно перемешивает объекты по по множеству чисел и для объектов которые
отличаются довольно слабо хэш функция отличается очень сильно ну вообще непредсказуемо как случайная
она короче такая вот как-то перемешивает просто их что это нам позволяет делать нам позволяет
хранить эти объекты просто в массиве и когда нам кладут какой-то объект мы массив по значит
индексу h от x где а что его хэш функция записываем что он там лежит вот и если нам повезет то есть
если объекты действительно будут если хэш функция действительно хороша и она действительно так
равномерно как бы распределяет объекты по по числам то когда мы будем класть разные объекты мы
мало вероятно что у нас в одну и ту же ячейку надо будет положить их много вот так у нас при этом
размер массива будет не очень большим ну он будет куда меньше чем общее возможное количество
интов у нас гораздо меньше чем два миллиарда скажем не знаю 10 тысяч и вот мы кладем туда
10 тысяч объектов и массив размера 10 тысяч но ввиду того что наша функция как мы предполагаем
хороша и хорошо перемешивает объекты равномерно так случайные числа выдает почти в ответ на
объекты у нас будет в среднем не очень много попаданий в одну и ту же ячейку ну может какая-то
константа может 5 попаданий в одну и ту же ячейку но немного за счет этого мы поймем что у нас в среднем
от единицы ну в среднем то есть если нам повезло и в среднем по всевозможным наборам объектов
по всевозможным там значит значение хэш функции ну короче вот усреднение такой по вероятности вот
это не амортизировано от единицы это именно в среднем от единицы разные вещи ну вот единица
вероятностная амортизировано это единица значит что у вас если вы много операций делаете то вот чем
больше операции тем в пределе общая суммарная стоимость операции деленно количество операции
будет единицей а здесь не так здесь может очень не повести и если специально под хэш функцию
подгонять объекты так чтобы они все попадали в одну и ту же ячейку то будет очень плохая
сложность будет у отн сложность добавления но среди но такой случай супер гипермаловероятен
а нормальный случай типичный средний случай выглядит что мы редко попадаем в одну и ту же
ячейку разными объектами это называется коллизия у нас редко происходит коллизии поэтому в
среднем добавление быстро происходит и удаление быстро происходит то есть по той же причине мы
в одну и ту же ячейку ну грубо говоря в одной и той же ячейке у нас может лишать несколько
объектов когда мы хотим удалить мы смотрим в эту ячейку ищем среди всех объектов которые
мне лежат тот который нужен и удаляем его вот и опять же мы думаем что редко будет так что в
одной и той же ячейке много объектов поэтому удаление тоже в среднем будет быстро ну и поиск по
ключу тоже будет среднем быстро если в среднем в ячейках в среднем мало объектов лежит а это
такой лигбез по хэштаблицам за 5 минут я конечно никаких утверждений тут строго не сформулировал и не
доказал вот но строгая теория этого всего дела требует знакомство с теорией вероятности и
по этой причине значит филипп предпочитает рассказ это в третьем семеостряне в первом вот
там какие-то мат ожидания надо писать какие-то неравенства выводить что-то там оценивать
вот но да я сейчас ничего этого делать конечно не собираюсь вот это вам что потому что
ну ну в основе там насколько я знаю было две лекции быстро и это все осветили и все а у вас
будет на насколько я понимаю более подробно со всеми там выводами формул вот ну или одна я не
знаю сколько там было вот но в общем у вас будут в третьем семеостре ну я тем не менее думаю что
вы все ну если даже не все то большинство из вас пользовались хэштаблицами может даже не
понимая что это такое ну как минимум он ордерт мэпом наверняка многие из вас пользовались кто
пользовался он ордерт мэпом ну вот ну вот он ордерт мэп это хэштаблица ну можно и так да хэштаблица
вот тут надо понимать что есть два таких глобально-фундаментальных таких разных подхода
к хэшированию решение этой вот задачи а первый подход называется не хэширование с открытой
адресацией второй подход называется хэширование методом цепочек что такое хэширование с открытой
адресацией это когда у вас вот есть такой массив и что происходит когда вот вы добавляете в него
новый элемент и обнаружить что там уже лежит элемент вы говорите ну ладно тогда давайте просто
в соседнюю положу или вы говорите ну хорошо давайте тогда у меня будет еще функция прыжка то есть
я как бы от этой функции вычислил еще какое-то значение и прыгну в следующую у меня будет если
я попал сюда то у меня есть правило в какую пытаться класть если я не сумел положить сюда вот
хэширование кем у меня послышал с бабушкой я не знаю про насчет бабочку есть хэширование кукушкой
вот хэширование кукушкой это нет это не что другое но там есть разные подходы как решать
можно например считать что у вас есть две хэш функции и вы ну даже если уж по одной будет
коллизия то по двум то уж совсем вряд ли и вы просто если одна из один из вариантов занят то вы
во второй идете ну вот примерно такой подход это по-моему как раз и называется хэширование кукушкой
есть другие разные подходы вот вот а ну да правильно вы вы смотрите что один из вариантов занят там
а другой если этот занят то вы пытаетесь его переложить во вторую альтернативу для него а свой
положить сюда и так далее там свопать и чтобы каждый лежал в одном из двух вариантов доступных
для него да но это что-то такое есть много очень разных умных способов как оптимизировать как
снизить эти вероятности это все я думаю вы будете разбирать и доказывать какие там у них оценки и
чего но все эти способы меняет то что мы не будем ими пользоваться сейчас потому что он ордер
мы поспользует второй подход второй подход называется хэширование методом цепочек что
такое методом цепочек метод цепочек заключается в том что спроска в каждой вершине массива
хранится лист связанный список ну или другой массив если хотите и вы просто когда у вас нужно
положить что-то в эту ячейку но вы просто докладываете в этот лист то есть у нас реально в каждой ячейке
может лежать как бы несколько объектов но на самом деле в каждой вершине у нас просто будет
храниться указатель на голову списка представляющего собой вот список объектов лежащих в этой вершине
вот соответственно чем мы умеем делать мы умеем делать insert erase и find но все то же
самое что и мэп у нас набор функций работы с контейнером абсолютно такой же как у мэпа у
нас будут квадратные скобочки это вот и все это работает за от единицы значит так скажем
ожидаемо expected от единицы но я уже сказал при условии что нам везет и значит никто специально
не подбирает объекты так чтобы все время попадать в одну и ту же ячейку зная нашу хэш функцию вот
ну собственно как раз вот один из параметров хорошести так скажем хэш функций в том что по
числу трудно подобрать объекты которые дадут такой хэш вот если хэш функция такова чтобы по
числу легко подобрать объекты дающий такой хэш то такую хэш функцию легко ну за abused сломать
короче то есть вот представьте у вас хэш функция такая что вы по хешу легко понимаете что надо
сделать какие объекты нас собирать чтобы такой хэш получить когда вы можете легко задосить значит
эту хеш таблицу просто все время отправляю объекты которых будет один и тот же хэш и
они все время будут попадать в одну и ту же цепочку
что в этом плохом, ну ты можешь
запрос за OATN
запрос за OATN, да
ты можешь, зная хэш функцию
если хэш функция легко
к обращению, легко обратимо
что называется, то тогда
ты можешь специально, будучи там
злым хакером, подобрать такой набор объектов
и начать вот эту хэш таблицу
дозить, да, и будет все очень медленно
работать, и все там погрязнет
вот
например
ну или
в криптографии
ты можешь что-нибудь сломать таким образом
в криптографии вроде другие хэши
да, в криптографии как раз используются специальные
криптостойкие хэши, которые
в том числе обладают и таким свойством
ну да ладно
ну вот мы считаем, что
мы не будем обсуждать какая у нас
хэш функция, мы будем использовать TD hash
она не то чтобы
хорошая, но
нормально, короче
сойдет для наших целей
жить можно, да
для int она просто возвращает его сам
вот
ну для строки там
она по-моему делает что-то
типа там какой-нибудь полинамиальный
наверное хэш там типа считает
будем надеяться
будем надеяться, да
вот, если что
std hash можно переопределить для своих типов
когда вы используете hash таблицу
когда вы используете std unordered map
у вас
что забавно, std hash не работает
по умощанию для пары рейнтов
да
по-моему
для всех стандартных типов он таки работает
да, ну ладно
ну короче
когда вы используете
когда вы используете hash таблицу
если вы хотите
класть в нее свои собственные типы
то вам нужно доопределить для них std hash
это тот редкий
случай, когда вам нужно дописать что-то
в namespace std
можно передать свой hash
а можно доопределить std hash
ну чтобы не передавать свой
hash можно
доопределить std hash просто, то есть можно написать
namespace std
и там
написать
специализацию std hash
для вашего типа
значит тип
нам будет выдаваться каждый раз различнее
мы даже не знаем какой тип нам будет выдаваться
но пользователям
мы не знаем в какой тип
нашу мапу захочешь положить человек
в смысле
у тебя контейнер чего
если ты сам реализуешь мапу
то ты должен
дать возможность человеку свой hash передать
а стандартная мапа
она позволяет
как вообще свой класс hash передать
свой шаблонный параметр
так и специализировать стандартный
можно специализировать
стандартный чтобы не париться писать свой
шаблонный для всех типов
можно просто для конкретного типа сделать специализацию std hash
hash это структура
у которой определен оператор круглой скобочки
все как обычно
который принимает объект t
и возвращает там size t
или там int
число какое-то я не помню точно какое именно int
ну да
у нас есть итераторы
итераторы у нас forward
только не bidirectional
bidirectional
итераторы в hash таблице смысла не имеют
потому что
hash таблица
она хранит все в случайном порядке
с точки зрения пользователя
чем hash таблица
казалось бы все за 1 в среднем
а у мэпа все
за логарифом
казалось бы всегда использовать unordered map
вообще
главное
главное
недостаток
с логарифмической точки зрения
это то что он unordered
то есть в unordered map вы не можете задавать запрос
и виды найти минимальный ключ
не превосходящий данного
больше или равный данного
просто нет такой функции
а если вы захотите то это за oatn придется всю hash таблицу обойти
потому что они лежат в абсолютно перемешанном порядке
вы не знаете как
вот
поэтому у нас forward итераторы
но
остальное работает
все в принципе так же
там
insert, erase, find, квадратные скобочки
это все как в обычном мэпе
у нас есть
шаблонные параметры
ключ значения
key value
соответственно в вершинах лежат пары
опять key value
как и в обычном мэпе
в вершинах лежат вот эти вот пары key value
и когда вы разыменовываете
итератор вы получаете
именно пару key value
третий шаблонный параметр это hash
hash это вот как раз
это
ой вы знаете что
я понял что я вам забыл сказать
одну очень важную вещь про мэп
и про unordered map заодно
сейчас скажу хорошо что вспомнил
а то вы бы на этом
облажались в какой-нибудь момент
короче hash и еще
компаратор
ну в случае
unordered мэпа у нас less
не нужен у нас сравнение на меньше не нужно
но нужно сравнение на равенство
вот этот вот компаратор по умолчанию равенства equal to
он сравнивает ключи
вот
я вам
это
это мой косяк я совершенно забыл
когда я рассказывал про мэп про эту деталь
а она важная
когда вы что-то храните в вершине
вот у вас есть структура node
в мэпе
в ней
ну она там наследница base node
в ней лежит пара
я сказал из key value да
это не совсем правда
так
ну так будет работать но это
неправильно
на самом деле тут const key
value
то есть пара
она ключ константный в ней
а значение не константное
это очень важный блин момент
вот я очень жаль что забыл про него сказать тогда
потому что если бы ключ в паре
был не константный то вы могли бы сломать мэп
просто взяв разыменовав
итератор и присвоив ключу другое число
и тогда у вас был
бы рушилась бы структура дерева
и дальше было бы ub сплошное
когда вы в это дерево что-то вставляете
вот поэтому
вот на этом уровне защита стоит
что у вас ключи
они могут быть даже не константные
переданы в мэп то есть вы делаете
мэп от int int например
но в реальности там лежит const int
на месте ключа и только мэп
может его менять
ну на самом деле она его даже не меняет
никогда сама ну короче
в зрении пользователя после того как он
положил туда пару ключ значения
для него ключ стал константным и поменять
его он уже не может извне
вот только мэпом может там изнутри
распоряжаться то есть возможно даже const cast где-то
делать придется но скорее всего
нет потому что вам не нужно реально менять ключи
никогда вы же не перекладываете ничего
вы же в вершины не
ну короче когда вы что-то
положили в вершину оно там так и лежит навсегда
то же самое в unordered map
в unordered map лежат пары из const ключа
и значений
а почему
да по той же причине потому что если бы
можно было разоменовав итератор получить пару
key value без константногости
на ключе то можно было вот подменить
ключ и у вас бы сломался
сломалась бы unordered map
потому что получилось бы что вот в этой вот
в этом списке лежит ключ
у которого hash на самом деле
не такой как должен быть у
у объектов
в соответствующем
ячейке
поэтому что в unordered map
на самом деле под утератором лежат пары
из const key value
вот это довольно
забавный эффект и он
иногда там
проявляется неожиданно
в некоторые моменты
вы можете даже не думать
что есть такая проблема
ну короче
например
вот когда вы пишете
for вот допустим вы хотите обойти весь
мэп я вам сейчас приведу пример
когда это критично бывает
например вы хотите обойти весь мэп
и вы пишете for const
pair key
value
ampersand
мэп ну то есть
когда вы делаете range based for по мэпу
вы же можете написать
вы не по утератору идете
а по штукам которые там лежат
мапа состоит из таких пар
вы по константной ссылке
проходите весь мэп
вы просматриваете весь мэп
чтобы не копировать вы пишете const
вот это ampersand
и казалось бы вы избавились от копирования
но нет
вот если вы вот так будете обходить мэп
у вас будет все равно лишнее копирование на каждом шаге
а знаете почему?
а потому что вы здесь const забыли
в мэпе на самом деле лежат
pair из const key
value
а вы инициализировали
const pair key value ampersand
поэтому
это одна из причин
по которым рекомендуется писать авто
в таких ситуациях
потому что вы вот такую маленькую деталь забыли
тип не совсем точно назвали
и у вас будет копирование
несмотря на то что вы казались бы такие умные
вы const не забыли ampersand написали
а вы const вот здесь забыли
то есть вот такой проход
по мэпу таки будет делать копирование
вот
ну да ладно возвращаемся к unordered
мэпу
как
он устроен внутри
что там хранится как он должен быть
организован чтобы все быстро
работало ну смотрите
понятно что на верхнем уровне то есть в unordered
мэпе у нас будет некоторый массив
ну я могу даже сказать
так у меня будет
некоторый вектор это не совсем
правда это будет не совсем вектор
и не совсем forward листов но я могу так
в первом приближении сказать что
в unordered мэп это на самом деле вектор
из forward листов
из чего
ну вот из этих пар
вот в
что в мэпе что в unordered мэпе есть такой
внутренний тип он называется value type
и он равен ну как
и в любом контейнере вообще есть внутренний тип
value type вот что в мэпе что в unordered
мэпе этот тип называется
как раз пара из const k value
да еще один
способ избежать копирования
не умничать и не писать
не писать вот явных какой
там тип а писать for
const value
ну ваш контейнер value type
значит m тогда вот этот
value type он в контейнере правильно определен
он точно говорит что там лежит
так вот значит вектор из forward
листов из value
type
что такое forward
лист это был
пункт восемь пять кажется
это односвязанный
список вот
что такое forward лист мы
обсуждали в прошлый раз мы обсуждаем что такое лист
forward лист это просто односвязанный список
то есть по сути это
просто массив в котором лежат
односвязанные списки
вот и
как происходит вставка
когда вы вставляете что-то в unordered
мэп вычисляется
хэш функция хэш функция
вычисляется кстати от чего
да значит
по умолчанию этот хэш это
std хэш от
кей
от ключа
и equal это по умолчанию
значит std equal to
equal to тоже от ключа
как происходит добавление
в unordered мэп вот вы
вычисляете хэш функцию
находите соответствующую ячейку
смотрите
пустой ну короче вот смотрите
в этот лист в этот список
который там уже лежит
и дальше вы с помощью
вот этого компаратора
начинаете проверять то что
вас просят положить в этот список
вот ту пару key value
она уже величина с таким ключом
уже есть здесь то есть вы должны пройти
по всему этому списку в этой ячейке и проверить
нет ли там уже значения с таким ключом
и проверяете вы это с помощью вот этого компаратора
вы идете по списку и сравниваете ключи
то вот что там лежит
вот а если
если там такого нет
то вы просто докладываете новую пару
в конец этого списка ну или в начало
этого списка докладываете
скорее в начало потому что у фореллиста нету
pushback есть только pushfront
а если такая есть то вы говорите
ой такая уже есть и возвращаете
значит итератор на нее
как происходит erase
аналогично вы заходите
в соответствующий вот
вот эти вот штуки называются бакетами
корзинки
вот это бакеты
вы заходите в соответствующий
бакет и
идете по нему
сравнивая ключи есть ли
значит штука с таким ключом
если есть если вы находите то
вы цепляете из фореллиста
уничтожаете это
происходит золотые ениции для фореллиста
и
все если
нет ну значит не нашли
вот
как происходит
find ну понятно как
то же самое просто идете по соответствующему
forward листу и либо находите либо нет
если не находите возвращайте
итератор наконец что такое итератор
наконец мы кстати сейчас еще обсудим
а
что дальше
есть
такая проблема
если вы добавили в unordered
map слишком много элементов
ну то есть как
изначально unordered map создает
массив на сколько-то там элементов
какой-то начальный кпс
есть вот у этого массива
и все элементы в нем
это пустые forward листы
ситуация почти все forward листы большие
да то есть когда у вас уже слишком
много элементов ну unordered map
изначально же не знаете сколько вы в нее кладете
элементов изначально она задает какой вот
размера массив
да есть резерв
но как это работает
если вы вот просто добавляете
добавляете и так миллион раз добавили
что происходит с unordered map
а чего
пустой unordered map уже не должен выделять памяти
пустой unordered map
наверное ничего не выделяет
ну как только вы добавляете первый элемент он сразу выделяет
какой-то с каким-то запасом ну как и вектор
и дальше начинает туда докладывать
ну вот по мере только вы кладете кладете кладете
у вас может случиться
ситуация что у вас элементов уже слишком много
ну объективно много допустим у вас
массив там на 100 был выделен
а вы положили миллион но очевидно unordered map
не должна такое терпеть она должна
реаллоцироваться в какой-то момент
и unordered map как и вектор делает реаллокацию
как и дек
внешний массив умеет реаллоцироваться
то есть когда у вас становятся элементов в мэпе
слишком много
а что такое слишком много
есть такой параметр
у unordered map который называется
loadFactor
это отношение
количество элементов в мэпе
количество элементов в этом массиве
и есть такой параметр max loadFactor
значит вы можете
спросить у мэпа
какой у нее сейчас loadFactor
и можете спросить какой у нее сейчас
что такое max loadFactor
это такой loadFactor при достижении которого она реаллоцируется
да вот по умолчанию
я кстати каждый раз забываю
чему он равен по умолчанию
ну типа там
нет нет
блин боюсь соврать
лучше не буду говорить сколько
по моему он даже меньше единицы
1.0 даже
ровно 1
по умолчанию да
ты проверил да
мне казалось что он меньше единицы
ну это не важно
можно узнать какой он
можно его установить
по своему желанию
1.0
по умолчанию 1
это значит что по умолчанию
unordered мэпа
реаллоцируется в ситуации
когда у вас добавленных элементов больше
чем количество бакетов
кстати количество бакетов
в текущей вы тоже можете узнать
вы можете спросить bucket count
он вам вернет
сколько у него бакетов
в этом внешнем массиве
вы можете сказать
setmax loadfactor
то есть вы можете сказать
я хочу чтобы ты реаллоцировалась при достижении вот такого loadfactor
а не такого
а также вы можете
сделать резерв
unordered мэпа
как и vector умеет делать резерв
это вот помимо vector единственный контейнер
который умеет резерв делать
что такое резерв
вы говорите резерв и число
резерв допустим 100 000
это значит что unordered мэпа
реаллоцируется таким образом
чтобы выдержать добавление 100 000 элементов
без реаллокации
в зависимости от того какой у него max loadfactor
например если max loadfactor 05
и вы сказали
резерв 100 000
то она реаллоцируется на 200 000
чтобы при добавлении 100 000
она еще не реаллоцировалась
но на 1000 добавления она выдержала без реаллокации
ну хорошо
как происходит реаллокация
внешний массив мы
реаллоцируем
а дальше нам надо бакеты все пересоздать
но ведь когда мы реаллоцируем внешний массив
у нас полностью структура бакетов
сломается
потому что
хэш функцию мы еще берем
по модулю размера массива
и когда у нас размер массива
меняется
разные реализации unordered мэпа
делают это по-разному
кто-то в два раза просто увеличивает
а кто-то я не помню какая именно
из реализации unordered мэпа
но какая-то
то ли в GCC, то ли в Силенге, то ли в MSWC
реаллоцируется по простым числам
то есть у вас там
когда реаллоцируется не в два раза
чтобы размер
этого массива был не степенью
двойки, а чтобы размер этого массива
был каким-то большим простым
числом, она там берет следующее
большое число там, почему?
потому что так меньше шанс
коллизий создать, но если у вас было дофига
коллизий, когда вы реаллоцирулись
в два раза, от того что вы стали
брать по модулю большей степени двойки
у вас коллизий то меньше может и не стать
поэтому лучше реаллоцироваться
не в два раза, а как-то похитрее
чтобы когда вы по модулю размера массива берете
у вас все съезжало и чтобы вот эти
коллизии как-то равномерно распределились
при релокации, понятно?
так вот, когда вы реаллоцируетесь
весь этот набор бакетов
надо пересоздать, то есть вам надо все эти
форвард листы пересоздать заново
и все вершины в них
соответствующим образом переложить
это работает конечно же за ОАТН
это если еще повезет
а бывает и не везет
а
ну давайте поподробнее подумаем
как это происходит
ну то есть мы просто берем по очереди
вершины из старых форвард листов
и прицепляем их
в новые бакеты
вот
так, значит
у нас по этому нет кроме
вычисления хэша нет никаких
операций больше с типом Т
кроме вычисления хэша
ну еще сравнение
что такое Т? Т это key?
ну еще сравнение
нет, хэш то не зависит
в какую ячейку будет
ну мы считаем хэш, а потом берем его по модулю
массива, возможно еще с каким-нибудь там
наворотами
чтобы по индексу массива понять
ну зачем нам проверка равенства?
чего проверка равенства?
ключей?
как мы ищем?
ты про резерв говоришь?
а когда происходит реаллокация, наверное не нужна проверка равенства
да
вот
мы считали хэш
положили в нужное место
ну я смотрю у тебя такой очень плохой хэш
он все время в одном
и каждый добавление
добавление
так что реаллокация
всегда с другого
сейчас, я немножечко
завис, дайте-ка я подумаю
сейчас, что-то я сходу не могу ответить
почему там может быть больше у отн
я
давайте-ка
сейчас мы поговорим
еще о кое-каких проблемах, а потом возможно мы и сами
поймем, почему может быть больше у отн
у нас есть еще пара нерешенных проблем
да, чего
лот фактор, это
сколько сейчас лежит элементов
в мэпе делить на количество элементов
количества бакетов
а зачем делить?
почему не просто сохранить количество элементов
в мэпе
потому что
удобнее оперировать числом отношения
это отношение
количества добавленных к размеру бакетов
при котором мэп реалацируется
ты хочешь лот фактор, в мэпе устанавливать
кастомный может быть, ты говоришь 0,5
это значит, что при достижении элементов
0,5 от количества бакетов, оно будет реалацироваться
просто не целое число
если по основному
да-да, это не целое число
ну
ты же не можешь в зависимости
ты же не знаешь количество бакетов
лот фактор, это глобальный параметр х-таблицы
то при достижении чего
оно реалацируется
у нас еще есть две нерешенных проблемы
первая проблема такая
unordered map
не инвалидирует
указатели и ссылки на элементы
при любых операциях
включая rehash
rehash можно вызвать, кстати, явно
есть операция rehash
не инвалидирует
указатели и ссылки
а итераторы инвалидируют
как и дек
это не очень логично
тут есть много уровней понимания
и
сейчас короче
сейчас надо вам будет
их быстро все пройти
так, давайте поймем
можем ли мы добиться не инвалидации
ну понятно, что когда мы
когда мы
добавляем элементы
если rehash не происходит
то все нормально
ничего не инвалидируется
когда мы делаем rehash
как нам добиться того
чтобы не инвалидировались указатели и ссылки на элементы
а у нас же есть
что получается splice
ну короче, стандартные методы с листами
которые позволяют просто
да, на самом деле мы не пересоздаем
вершины листов, вот в чем фишка
вот что важно
мы когда реаллоцируемся
мы не создаем новые вершины
из старых
мы вот эти вершины
обновляем
перекладываем их в новый лист
то есть мы
не должны реально создавать
новые вершины, мы должны
выцеплять эти вершины из старых листов
и вставлять их в новые листы
вот
ладно
ну казалось бы указатели и ссылки не инвалидируются
а итераторы
вот могут инвалидироваться
вот
вот итераторы могут инвалидироваться
прям в жестком смысле
то есть разыменование итератора может оказаться плохим
а
пока непонятно показалось бы
что в нем такого плохого
но я вам сейчас озвучу еще одну проблему
которая должна сломать ваши
наивные представления о том
как устроена Nordart Map
проблема звучит так
кто может быть отгадает
что за проблема
хотя это тоже весело
я еще не озвучил
на самом деле вот так как я
описал, все было бы очень здорово
но к сожалению так не работает
потому что есть одно требование
которое мы пока вообще не смогли
удовлетворить
требование заключается, оно было и в мэпе
оно было во всех контейнерах
просто там оно не было настолько критичным
это требование заключается в том
что проход итератором по всей мэпе должен быть
о большое от количества элементов
содержащихся в мэпе
ну когда мы обходим дерево
у нас
линейная сложность обхода его
но когда мы будем обходить такую констанцию
как вообще итератор устроен должен быть по вашему
что должен хранить итератор
не должен быть ни о чем проблема
мы просто обходим
кого? нет
от количества элементов, вот у меня
сделан резерв на миллион
а добавлено 5 элементов
у меня не должен проход обход этих 5 элементов
занимать миллион шагов
если даже резерв сделан
да, еще раз
обход итератором контейнера
можно было бы просто сказать
что если мы обнаружили что у нас
сильно мало элементов
то давайте
можно все эти листы сделать
одним листом, образно
если как бы один лист и у всех просто разные
нахеды точно
правильно, так и есть
вот это решение нашей проблемы
но еще пока возможно
не все осознали проблему
давайте осознаем проблему как следует
независимо от того
сколько бакетов
обход итератором должен быть за О от Н
где Н количество элементов лежащих в мэпе
если у меня даже резерв на миллион
но элементов всего 10
то for-auto
value-type в мэпе
должно за 10 шагов пройти
а не за миллион шагов
еще можно по идее лодфак
можно еще прехешиться
не только с фалфак по большой, но и маленький
сейчас, давайте по очереди
окей, такая проблема
почему вот здесь не получится так
почему
что должен хранить итератор
итератор должен указывать на какую
допустим, на бакет
да, на указатель
ну, проблема
с пустыми бакетами, если у вас слишком много пустых
бакетов, то как вам сделать
переход от этой вершины к следующей
допустим, следующий занятый бакет у вас вот этот
как вам
вот этот шаг пройти достаточно быстро
конечно вы можете
в каждом бакете хранить номер
ближайшего не пустого
но тогда
если вы вставите что-нибудь сюда
как вам обновить быстро все эти
номера и здесь и здесь
вот
и это проблема
поэтому
да, ДО, отлично
поэтому вам придется
вам придется
ну
решение следующее, в общем
как это реализовано на самом деле
мы храним немного, не в каждой
вершине форвард лист
мы храним 1 большой форвард лист
а вершины
просто указывают на разные его места
то есть, на самом деле у нас не вектор из форвард листов
у нас вектор
итераторов по форвард листу
и отдельно 1 большой
форвард лист
на самом деле, картинка не такая
а вот такая
есть 1 форвард лист
в котором лежат все элементы добавленные в мэп
и есть вектор бакетов
и некоторые бакеты пустые, то есть там, ну, на lptr допустим хранятся, а некоторые
указывают на какие-то вершины форвард листа, например, вот этот указывает на эту, вот этот указывает на эту
вот этот указывает на эту, а остальные бакеты пустые никуда не указывают
что это значит? Это значит, что у меня
сейчас
два элемента вот с таким хашом они вот тут лежат
два или один элемент вот с таким хашом он вот тут лежит и три элемента вот с таким хашом они вот тут лежат да
И хранительство мы храним хранительство?
Где? кого храним?
А! Как мы теперь, от... отлично вопрос, да, теперь
теперь нам нужно заново переусмыслить как работает вставка и поиск
Как работает вставка? Ну, как работает поиск? Хорошо. Мы прыгаем в бакет, начинаем идти по форвард-листу.
Как нам понять, что хватит уже идти по форвард-листу? Начался следующий бакет.
Либо хранить размер бакета отдельно, либо внутри листа повесить какой-нибудь флаг, типа...
Вот, на самом деле это можно узнать ничего и не храня, просто хэш пересчитывать каждый же.
Ну, вы видите очередную вершину и смотрите хэш у нее все еще такой же, как вы ожидаете, или уже другой.
Это слишком долго. Поэтому есть следующее решение. На самом деле форвард-лист он хранит не только
value type, а в вершинах листа хранится пара и ее хэш. Хэш предподсчитан. То есть мы для всех вершин хэши храним,
чтобы не пересчитывать каждый раз при поиске.
Вообще так-то Bool позволяет еще всякие нечестные хаки в указатель его упихать и вообще дополнительно в памяти не тратить.
Не знаю, может быть можно и так, но насколько мне известно, вот реализации STL-ные хранят именно хэш.
Ну, типа хэш хранить как-то естественнее. Вот, ну... Сходу я не могу придумать, что сломается, если просто хранить Bool голова или это.
Понятно, что это придется обновлять иногда. Вот.
Ну понятно, где обновлять.
Да, ну понятно, в каких ситуациях это придется обновлять.
Гораздо проще размер просто в багете хранить. То есть багет это указатель плюс size-t.
И это, кстати, тоже не проигрывает по...
Может быть и так можно, да.
Не проигрывает по памяти, по реализации как бы не проще оказалось.
По памяти может быть проигрывает, потому что можно в каждом.
По памяти это играется лучше, потому что мы можем хранить для каждого багета, а не для каждого элемента.
То есть вот когда у нас указатель на голове, вот рядом с ним хранить размер, а не рядом с каждым элементом хранить хэш.
Ну у тебя элементов всегда меньше, чем багета.
Ну да.
Ну короче, нет, окей, по памяти это может проигрывать, если хранить размер.
Вот в чем будет проблема. Как делать рейс по итератору?
Рейс по итератору?
Да.
Зачем нам пора рейс? Давайте просто лист.
Если вы в багете храните размер багета, вам говорят и рейс по итератору сделать, что вы будете делать?
Ну ничего, просто лист.
Ничего, проблема.
Ну вот, решение с... или инсерт по итератору. Ну инсерт по итератору нельзя делать, и рейс по итератору должно быть можно делать.
А зачем нужно пора лист?
Что значит за... а что, какая альтернатива?
Если бы у нас был лист, то можно было нормально сделать.
Ну то есть хранить в обе стороны указатели. Ну это не лучше, чем хранить хэш.
Нет, нет, подожди, все равно пришлось бы дойти до этого патета и...
Короче, я вам рассказываю решение, которое я знаю. Если вы придумаете лучше, я рад.
Но, чтобы не тянуть время, я просто напишу решение, которое точно работает.
Значит у меня в вершине листа хранится, собственно, пара из const kvalue.
Который назову kv.
Ну, тут будет указатель на следующую вершину.
А еще, ну, sizeT, хэш текущего ключа.
Хорошо, как делать инсерт?
Понятно, кроме одного случая. Как делать инсерт, если вам в пустой бакет попросили вставить?
Что если меня попросили вставить в пустой бакет?
В конец не могу, в начало могу. Просто вот так вот.
У меня нет указателя на вот эту вершину, он нигде не хранится.
Если меня попросили сделать инсерт в пустой бакет, я просто делаю push front в лист,
и эта штука становится теперь начальной вершиной листа.
Новый бакет появляется таким образом.
Вот, если меня просят сделать инсерт в бакет, который уже существует,
ну, я прохожу, во-первых, этот бакет, смотрю, есть ли вершина с таким ключом.
Если нет, то я просто вставляю сюда, значит, соответствующий элемент в этот forward-лист,
золотой единицы. Как теперь делать erase?
И вот здесь самое интересное. Как делать erase по ключу?
Если я делаю erase по ключу, иду по бакету, понимаю, что нашел-то элемент с таким ключом,
ну классно, вырезаю его из forward-листа, замечательно, удалил эту вершину.
Проблема, а что если мне нужно сделать erase первой вершины в бакете?
Пройдем еще на одну вершину, проверим, что она последняя.
Вот мне нужно сделать erase вот этой вершины. Что мне придется сделать?
Ну, пройти на еще одну.
Ну, посмотреть следующую?
Нет, окей, я понял, что, в смысле, следующую.
Ну, для начала на понятие, если это единственная вершина в бакете, то мы удаляем еще и итератор.
Короче, опустеет ли после удаления этой вершины бакет?
Вы что-то не в ту сторону думайте.
Мне нужно обновить указатель на следующей вот у этой вершины, а я его не знаю, вот в чем проблема.
То есть, мне нужно, вот когда я делаю вырезание из forward-листа этой вершины, мне нужно у предыдущей обновить next.
А откуда мне знать, какая предыдущая перед этим?
Да, это проблема. Тут хотелось бы использовать обычный лист.
Но мы не хотим использовать обычный лист, потому что, ну, короче, только ради этого использовать двусвязанный список вместо...
Это единственный момент, в который нам лист требуется вместо forward-листа.
Какой? Нет, с хэшом нам не требовался.
А чего было бы проще-то, я не понял.
И как бы это нам помогло не хранить хэш?
Вы хотите хранить булевый флаг, правда ли, что это голова бакета?
И как тогда ирейс по итератору... Что конец бакета.
И как тогда делать ирейс по итератору, если у вас булевый флаг, что это голова бакета?
Как вы знаете, к какому бакету вы относитесь?
Вы делаете... Вот вас попросили ирейс вот по этому итератору.
Если он не голова, то нам просто пофиг, вы просто вырезаете.
Если он голова, то мы смотрим на следующий...
Нет, подожди, вырезаем, а вот этому как мы next обновляем? Откуда мы знаем, кто он?
То есть все-таки двусвязанный список нужен?
Нет, вопрос был именно про то, как мы... Есть идея.
Мы можем свопнуться с next и вырезать next.
А если next уже следующему бакету относится?
Мы не можем.
Мы не можем векторе хранить итератор на вершину перед бакетом?
Ты опережаешь, мы тут пока другую его проблему обсуждаем.
Мы обсуждаем все еще, почему буль я не хочу хранить.
Короче, давайте опустим этот разговор.
Можно подискутировать после пары, но сейчас хочется все-таки обсудить, как это на самом деле работает, а потом уже что-нибудь пори вести.
Какая проблема у нас возникла при такой реализации?
Мы не понимаем, как делать ирейс в начальной вершине в бакете, потому что нам нужно у предыдущей обновить next, а мы не знаем, какая предыдущая.
Есть два решения.
Первое решение – хранить двусвязный список вместо односвязного.
И именно так сделано в реализации Microsoft в MSWC.
Второе решение – хранить в бакетах указатель не на первую вершину бакета, а на последнюю вершину предыдущего бакета.
Перед первым хранить указатель на последнюю вершину предыдущего бакета.
Ну да, здесь можно как-то хранить.
Давайте подумаем, как хранить указатель на последнюю вершину предыдущего бакета.
Да.
Может ли что-нибудь сломаться при этом?
Какие у нас могут новые проблемы возникнуть?
Но мы никогда не вставляем новый бакет между уже двумя существующими, правильно?
Может случиться так, что нас попросили сделать эрейс какой-то вершины, которая была последней в бакете.
Что если нас попросили сделать эрейс от вершины, которая была последней в некотором бакете?
А в чем проблема?
Ну, тогда указатель, который указывал на нее, сломается.
Он будет хранить указатель на невалидную вершину после этого.
А мы не можем в этом случае просто пройти по бакету, предполагая, что это маленький?
Чего-чего пройти? Куда?
По всему бакету и дойти до предыдущей вершины с начала и с конца.
Тебе пройти по бакету, которую мы видели?
А как мы найдем? Нам нужно понять, кто хранит интернатор на эту последнюю вершину?
Кто предыдущий? Да, непонятно.
Нет, предыдущего найти мы можем, предполагаю.
Найти вершину вектора ты имеешь в виду?
Да, да, да.
А у нас же есть хэш.
А, окей, да, справедливо.
Вот, кстати, почему стоит хранить хэш, потому что мы можем быстро находить, собственно, какая вершина вектора у нас указывает.
А, о, отлично, да, то есть смотрите, что мы делаем, все, все, мы придумали решение.
Значит, мы... это сразу и объясняет, почему хэш нужен.
Если нас просят удалить последнюю вершину в бакете, например, эту, то как нам...
Короче, теперь у меня на самом деле бакеты выглядят вот так, вот это бакет.
Ой, вот это один бакет, вот это один бакет, вот это один бакет и вот это один бакет.
Но указатели указывают не на начальной вершины бакетов, а на...
Ну, здесь вообще куда-то на фейковую вершину.
Этот указывает на последнюю вершину отсюда, этот указывает теперь на...
Нет, минуточку.
Этот никуда не указывает, этот указывает теперь вот сюда, этот теперь указывает вот сюда,
этот теперь указывает вот сюда, и кажется все.
То есть, короче, теперь указатели указывают на последние вершины предыдущих бакетов,
а не на первые вершины настоящих бакетов.
Именно так сделано в C-Lang и в GCC.
Они не хранят двусвязанный список... они хранят односвязный,
и указывают на предыдущие вершины последних бакетов.
Вот, но мы храним хэш в каждой вершине, и если нас просят удалить последнюю вершину бакета,
мы понимаем, какой у него хэш, то есть мы понимаем, к какой вершине вектора она относится,
и можем пройти по бакету сначала, и тем самым найти предыдущую. А вот тут вопрос, рейс по
итератору, он все-таки должен работать за от единицы в среднем или от единицы гарантированная?
В среднем, конечно, все работает. А, рейс по итератору? По итератору?
Сейчас он у нас в среднем за единицу работает. Ну, значит, видимо, будет работать в среднем за
от единицы. Давайте проверим, как написано на себе переференс. Чего? Потому что приходит
пройти весь бакет, в худшем случае, который может быть не очень маленьким. Да, еще раз,
вот нас просят удалить последнюю вершину некоторого бакета. Для этого нам надо... Ну,
значит, так это и работает. Ну, понятно, что с двусвязным списком это легко было бы сделать,
а вот с односвязным мы вот такие вот трюки применяем, как в GCC и CLNG сделано. Еще раз,
если нас просят удалить последнюю вершину бакета, нам нужно обновить указатель... Кого нам надо
обновить указатель? Нам надо обновить указатель... Она относится к этому бакету. Нам надо обновить
указатель вот этот, чтобы он указывал теперь на правильную вершину. Вот. И мы, зная, какой хэш
ей соответствует, находим предыдущую к ней вершину. Да, и... Ну, переподвешиваем туда. А если...
Если эта вершина была вообще единственной в своем бакете. Она была первой, она же последней,
то есть предыдущая вершина перед ней имела уже другой хэш. У нас есть хэш из массива указатель
на предыдущую переголовку. Чего? У нас есть ее хэш, да? Так, ее хэш. Мы берем... Ну, по-моему,
в момент критики массива тогда решит... Ну, итератор на предыдущую передней вершину. Значит,
если мы удаляем вершину, которая единственная в своем бакете, то нам надо обновить указатель
из элемента массива, который как бы соответствует следующему бакету. Он раньше указывал на нее,
а теперь он должен указывать на предыдущую перед ней. Но это та самая, которая у нас на соответствующей
ячейке вектора хранится как вершина для нас. Ну, еще раз, как мы делаем удаление, если вершина
единственная в бакете? Вот вершина единственная в бакете. Как мы ее удаляем? Мы хотим удалить,
вот, очистить этот бакет. Ему соответствует одна единственная вот эта вершина, и удаляя ее,
мы должны обновить вот этот указатель, потому что он указывает на предыдущую вершину для этого
бакета. Теперь она не будет предыдущей для этого бакета. Теперь этот указатель должен указывать
сюда. Но этот указатель мы знаем, потому что он здесь и хранится. Вот, собственно, это тот указатель,
который соответствовал нашему текущему бакету. Теперь мы его переставляем сюда. То есть,
вот это теперь будет указывать на вот то, куда указывал наш бакет, а эту вершину мы просто
вырезаем, а тут просто на ЛПТР, потому что этот бакет теперь пустой, и этой вершины больше нет.
Все. Что? Нет, когда, ну да, да, ну просто когда эта вершина была еще единственной, у меня возник
вопрос, как мы обновляем вот этот указатель. Ну, короче, ладно, разобрались. Если что,
пересмотрите запись. В начало листа. Вот, лист этот, я напомню, сам по себе зацикленный, в нем есть
фиктивная вершина. Вот, forward list он, вот, конечно, вы здесь не будете использовать настоящий forward
list, вы будете использовать некоторые приватные, то есть forward list придется кастомизировать
немножечко для Unordered Map, потому что тут в нодах что-то хранить дополнительно придется и так
далее. Да, именно поэтому для задачи Unordered Map вам нужен будет написанный уже лист, потому что
в задачи Unordered Map вам придется использовать уже написанный вами код в лист из листа. То есть,
вот задача Unordered Map, формально мы не будем требовать, чтобы у вас был сдан лист, чтобы
вы сдавали Unordered Map, но без написанного листа писать Unordered Map вам будет трудно,
логично сначала лист написать. Короче, Unordered Map существенно использует лист в себе. Так, что?
Потому что в вершинах forward листа лежат не просто вот эти пары, а еще, например, hash, как минимум.
И еще, как минимум, у вас довольно, ну, там какие-то манипуляции с итераторами надо
производить. Вот, что из себя представляет End, итератор, наконец, Unordered Map? Это чесалка спины?
Офигеть. Блин, мне надо было попросить такую на день рождения себе вчера подарить. Блин,
черт, надо wish list следующего года добавить, я не догадался. Хорошо. Она не достает. Так,
чш, ладно, нам осталось немного. Что такое End в Unordered Map? Ну, это просто End в этом самом forward
листе. Нет, это End, вот это Begin. Это End, это фиктивная вершина. Не знаю, по-моему нет,
но я не помню какая конкретно там будет проблема. Ну, короче, я помню, что прям вот в чистом виде
использовать forward list итератор неудобно, оказывается. А давайте все-таки, например,
вам нужно указатели на следующие вершины вручную иногда переставлять. Как rehash теперь будет
работать? Нам нужно из этого листа сделать новый лист, в котором переупорядочить все бакеты заново.
То есть, что будет из себя представлять вот этот вот новый forward list? Вам нужно взять весь этот
лист и начать insert по одной вершине в новый forward list, меняя hash еще в вершинах. Вот.
Какой может быть плохой случай? Потому что при пересчете... А, ну, кстати, hash можно не менять,
вы, наверное, можете хранить просто функцию hash без деления по модулю. Вот, да. Hash тогда менять
вам не придется в вершинах, то есть, вершины реально менять не придется, но придется их
поменять порядок полностью. Вот. И вам придется этот forward list полностью перестроить, кладя по одной
вершине в новый. То есть, вы берете эту вершину по очереди, смотрите, в какой бакет она теперь
попадает, создаете этот бакет. Ну, короче, так insertите много раз. Вот. И каждый раз при этом вам
нужно поддерживать правильно вот эти вот указатели на предыдущий бакет. Ну, или вам надо уже потом их
расставить, когда вы все поинсертили. Вот. Утверждается, что это может работать в худшем случае
за n квадрат, но я забыл почему. Давайте поймем, что может пойти не так, если мы... Ну, короче,
на cpp-референс написано, что rehash работает за n квадрат в худшем случае, но это уж, как-то,
совсем плохой случай должен быть. Ну, вот, допустим, у нас все элементы попадут в новый,
в один и тот же новый бакет. Это что тогда будет означать для нас? Вы изначально они были в одном
бакете. И что тогда это будет для нас означать? Ну, нам придется делать erase, видимо. Нам придется
делать erase из старого листа, но как бы нам придется вырезать вершину из старого листа и класть
новый лист. Короче, ладно, я не помню, почему там может возникнуть у тебя n квадрат. Может быть,
в этой реализации не может возникнуть. Может быть, я просто забыл. Да нет. А, в смысле, вы хотите
сказать, что если нам не везет на каждом erase, то мы поэтому n квадрат получаем. Короче, ладно,
я не помню. В общем, не буду сейчас думать об этом. Но, понятно, идейно, как rehash реализовать. Что
надо сделать теперь? Ну, что надо просто, вот этот лист, из него вырезать все вершины по одной и
вставить в новый лист уже в новом порядке, по-новому расставив все указатели. Вот, при этом,
вот сейчас супертонкий момент. Вообще очень такой вот прям уровень глубокого понимания,
уже не средней школы. Почему ломаются итераторы, но не указатели из ссылки? Ведь, казалось бы,
мы вершины не пересоздаем. У нас не должны ломаться итераторы, указатели из ссылки на
вершины unordered map, когда мы делаем rehash. Потому что мы не пересоздаем вершины, мы просто
перекладываем их в новый лист. И что? Разаменование это все равно нужно корректно работать. И что?
Да, если мы бы реализовали это через двусвязанный список, то итераторы бы тоже не ломались. И в
Microsoft реализации так и есть. Итераторы не ломаются при rehash, потому что нам не нужно хранить
указатель на предыдущий бакет. Мы храним указатель на текущий и вершину никуда не
перекладываем. Но в реализации GCC и в той реализации, которую мы только что обсудили,
итератор он хранит, значит, сейчас, итератор на вершину. Так, а давайте поймем. Что хранит
итератор? Что хранит итератор? А может это так не работает? Да, я думал, что я понимаю,
видимо, я сам еще не понимаю, но бывает. Мне казалось, я понял в какой-то момент.
Если мы в вершинах вектора храним указатели на последней вершины предыдущих бакетов,
то что у нас пойдет не так, если мы сделаем rehash? Что может пойти не так с итераторами?
Ну, кажется, что если мы в итераторе храним действительно только указатель на конкретную
данную вершину, то как будто бы ничего. Как будто бы итераторы все равно не ломаются. Значит,
видимо, итераторы в GCC хранят что-то еще. Возможно, итераторы хранят действительно еще и сам бакет,
а не только вершину. Смотрите. Сейчас. Допустим, итератор хранит только лишь указатель на текущую
вершину. Как тогда будет рейс по итератору работать еще раз? Мы обсудили, что мы берем просто
по хэшу, считаем, какая предыдущая, и в зависимости от этого понимаем, кому надо давить next.
Вот. А если у нас произошел rehash, то когда мы пытаемся использовать итератор для доступа
к вершине, кажется, что для доступа к вершине мы сможем его использовать. А вот и рейс по этому
итератору мы уже сделать не сможем после rehash, потому что он не сможет получить последнюю вершину
предыдущего бакета, например. Ну, потому что у вас вектор стал другим. А у меня есть более
интересный вопрос. Откуда итератор вообще знает, где вектор? Вот если у нас произошел rehash. Да,
смотрите. Если у нас произошел rehash, а итератор хранит только лишь указатель на текущую вершину,
то по этому итератору мы вообще, кажется, не можем ни insert, ни рейс уже делать, потому что...
Потому что мы...
Нет, это решается, если бы мы хранили hash настоящий, а не hash по модулю, если бы мы хранили.
Если бы у нас был двусвязанный список и мы хранили hash по модулю, то, кажется,
что в двусвязном списке даже если произошел rehash, нам не мешает ничего сделать и рейс или insert.
А как мы пересчитаем ссылку, которая ведет из списка? В случае двусвязного списка мы можем ее не
пересчитывать, потому что мы можем просто на начало бакета вот в двусвязном списке. Вот у тебя начало
бакета удалили. Да, если удалили начало бакета, то, кажется, все равно ничего не получится. Короче,
кажется, итератор инвалидируется при любом раскладе в том смысле, что разыминование, кажется,
не перестает работать, а вот insert и рейс поэтому итератор уже делать не получится, потому что в
итераторе нужно хранить указатель на вектор хотя бы, чтобы понимать где вектор, поэтому итератор
инвалидируется. Если в ноде хранить не hash, а как бы не то чтобы не позицию, а вот прямо указатель на
нужный элемент вектора. А мы тогда при реалокации указатель на вектор, ну типа на бакет, с которым мы
работаем. Вот так. А при реалокации мы, ну пока мы это все перекладываем, мы в том числе эти указатели
тоже можем пересчитать, это нам потребует при реалокации пересчитать хэши, ну типа окей,
наверное, вот, и тогда нам будет достаточно только указателя на ноду. Но как мы будем делать и рейс,
я все равно не понимаю, в смысле элемент вектора как мы обновим, если нас и рейс по итератору
попросят? А так у нас же теперь есть указатель на этот, ну, на кого? На элемента этого вектора. Так вектор
реаллоцировался, и он теперь вообще в других местах лежит. Если реаллоцировался, этот же указатель
в ноде лежит, значит пока мы его реаллоцировали, мы в ноде этот указатель обновили. А, ты предлагаешь
в самих нодах хранить обратно указатель на ту ячейку вектора, которая соответствует эта вершина?
Может быть, я не знаю. Короче, итераторы инвалидируются при rehash, и указателей ссылки нет. Вот с
итераторами проблемы мы поняли какие. Ну, можно хранить указатель на вершину и указатель на сам
вектор, например. Этого этого будет достаточно. Какая структура? Итератор. Ты по итератору должен
делать, уметь и рейс, например. Как ты будешь делать и рейс по итератору? Мы же вызываем метод и рейс
от структуры, от итератора, типа. Так. Мы же знаем, где лежит в плане инструменты и рейс. У итератора нет методов, которые по нему и рейс делают.
Сейчас.
Типа мы вызываем и рейс у контейнера, и поэтому нам не надо знать в самом итераторе, где это лежит.
А, так блин. Так кажется это правда. Так кажется, действительно, если так делать, если до связи
записок хранить, тогда все нормально вообще, никакой инвалидации. Типа, если ты делаешь. Так, еще раз, смотрите, нам
кажется не нужно хранить вообще ничего, связанного с вектором в итераторе, потому что если у контейнера
вызвали и рейс по итератору или инсерт по итератору, то контейнер-то знает, где лежит вектор его, и итератор не должен знать.
Поэтому, если список двусвязанный, то все хорошо, а вот если список односвязанный...
А так тоже с хешами хорошо, если это вызвали у контейнера.
Да, только итератор может хранить, значит... А он хранит только указатель на доду. И, кстати, он действительно хранит только указатель на доду,
потому что связок это 8 бай. Итератор хранит указатель на ноду, и вот, допустим, произошел рехеш, итератор у нас хранит только указатель на ноду,
и мы хотим сделать и рейс по этому итератору, а у нас односвязанный список. Как тогда это будет работать?
Ну, мы байтит, можем ровно так же найти байда в контейнере.
Ну, мы точно так... Да, то есть, типа, у нас же есть хеш, мы знаем позицию, мы знаем...
То есть, мы по хешу поймем, к какой ячейке нового вектора соответствует этот элемент,
поймем указатель на... последнюю ноду предшествующего бакета к нему, и пойдем дальше по этому бакету, и удалим оттуда.
Правда ли это сработало? Ну, я как будто бы не вижу подвоха, как будто бы действительно работает, но, наверное, что-нибудь выпускаю.
Ну, вот мы и напишем, да, и проверим.
Да, в общем, почему-то, короче, в ГЦЦ... почему-то в стандарте написано, что итераторы инвалидируются.
Вот как-то оно реализовано так, что они инвалидируются. Вот почему это происходит конкретно, видимо, я все-таки не могу ответить на этот вопрос.
Видимо, у них что-то там вот портится, что-то они не могут после этого делать с итераторами в их реализации.
Если вы попробуете это нагуглить, то вы не нагуглите.
Вот я... ну, то есть я... я вопрос, почему в дек... в roadmap инвалидируются итераторы.
Много раз пытался гуглить и на stackoverflow искать, но вот не нашел вразумительного ответа, понял только, что в MSWC вроде они не инвалидируются, потому что список двусвязный.
А здесь они вроде инвалидируются, потому что список односвязный, но кажется, как будто бы можно и так обойтись.
В общем, ладно, я не буду ничего утверждать наверняка.
По крайней мере, их можно инвалидировать. Нет, я не понял.
В смысле, почему rehash за квадрат?
Почему rehash за квадрат, мы тоже, кажется, не поняли.
Да, я загугливал.
Да, я тоже. Там, короче, мы, если у нас все n элементы попали в один список...
Так, в один bucket.
Ну, в смысле, да, в один bucket.
То что?
...как мы будем вставлять в это знание?
За 1 плюс 2... а, в начало...
В начало просто...
А, нет, мы же приставки проверяем, есть ли оно или нет.
Так, у нас, на самом деле, пара закончилась.
Последняя вещь, которую надо сказать про unordered map, последней осталась вещь, это...
отгадайте, что?
Exception safety.
Теперь давайте вспомним, что у нас конструкторы key, value, как и операторы присваивания,
а также, что более весело, функция hash и comparator могут кидать исключения.
Просто выкаливаем себе дозырение...
Особенно интересно задаться вопросом, что при rehash мы должны делать в таком случае.
Вот мы делаем rehash.
А в rehash все просто.
Мы не вызываем hash, мы не вызываем сравнение.
Hash один раз вычисляется, когда решина создается.
Да.
У нас hash хранится, поэтому нам вызывать rehash...
Вызывать hash не надо, вызывать равенство не надо, потому что мы и так знаем, что они все различные.
Так что единственный exception, который мы можем получить, это bodologue, когда мы реалитируем.
Ну, казалось бы, да.
Еще раз давайте продумаем, что происходит при rehash.
Мы не пересоздаем вершины, мы лишь переставляем указатели.
И при rehash мы не вызываем ни разу hash, потому что hash мы храним.
Вот, кстати, еще одна причина, почему hash хранить надо.
И да, храним не по модуле, а просто, видимо.
И кроме того, мы не вызываем сравнений никогда, потому что и так все ключи различные, как мы знаем.
Поэтому кажется, что опять-таки, как и в обычном мэпе, исключение в hash и в equal to это не проблема при rehash.
Но при остальных операциях там понятно, это просто надо аккуратно обработать.
Но кажется, что при rehash ничего не сломается, если хранить hash и делать все так, как мы описали.
Просто перестраиваем лист, но не пересоздаем вершины.
Нам же нужно пересчитать вершины.
Нет, hash у нас один и тот, hash по модулю размера массива меняется.
А значение функции hash не меняется.
По-моему, это все, что я должен был рассказать про Nordart Map.
Да, очень жалко, что так мы и не поняли, почему все-таки операторы могут инвалидироваться при rehash.
Ну, надо читать исходники, видимо, кроме как читать исходники не понять, что там происходит.
Не рекомендую вам читать исходники.
Если читать исходники, то тоже не понять, почему.
Да, там проблема, короче, с Nordart Map исходниками.
Ну, если что, в C++23 собираются добавить flat hash, flat map, по-моему,
которая будет таблицей с открытой адресацией, а не с цепочками.
С цепочками?
Я не знаю.
На самом деле, давайте совсем последняя мысль, которую я расскажу по этому поводу.
Nordart Map многие не любят в промышленной разработке, потому что он медленный.
Медленный в смысле константы скрытой.
И зачастую просто обычный мэп бывает быстрее, чем Nordart Map на малых размерах, на небольших n.
Потому что вы видите, сколько всего дополнительно должен делать Nordart Map при каждой операции.
То есть, во-первых, этот forward list, по которому вы постоянно прыгаете,
То есть, когда у вас одна единственная вершина в бакете, вы прыгаете на предыдущую и только потом на нее,
когда вы делаете insert и raise, вы вообще какое-то огромное количество лишних действий,
вы ходите по бакету, обновляете какие-то дополнительные указатели.
Ну, короче, это все долго.
И на самом деле, есть много реализаций хэштаблицы от разных компаний.
Есть Google HashMap, есть Яндекс какой-нибудь.
В свое время мы изучали, еще когда я в Яндексе работал, мы изучали вопрос быстроты разных хэштаблиц.
И очень много написано разными компаниями разных хэштаблиц.
Фейсбуком написан свой хэштаблиц, он даже в публичном доступе, по-моему, выложен где-то на GitHub.
Короче, STD Unordered Map проигрывает по быстроте, потому что с этим forward-листом много возни.
И поэтому в коде, который требует low latency, быстроту выполнения, Unordered Map обычно предпочитают не использовать, насколько я знаю.
Вот. Ну FlatMap можно использовать, то есть с открытой адресацией хэштаблицу, но ее в стандарт пока не добавили, вот скоро добавят.
Да, потому что там не приходится прыгать вот по этому списку, ходить туда-сюда, переставлять какие-то указатели постоянно.
У тебя просто все в одном массиве хранится, и ты там все на столе делаешь, а не ходишь-прыгаешь постоянно.
То, что вы говорили в Facebook или Google HashMap, там они что, с открытой адресацией или с закрытой?
Там все есть, и то и другое, все на любой вкус написано, короче, хэшмэпов.
Я уверен, что ты можешь найти реализацию на любой вкус, вот как тебе хочется.
Можно нагуглить статью, но я, может, нагуглю и вам пришлю еще раз, там, типа, сравнение разных мэпов от разных компаний, кто быстрее работает.
Ну, опытные олимпиадники знают, что в GCC, в GCC Либе есть, как он там называется?
ГП-хэштейбл.
Да, какой хэштейбл?
ГП-хэштейбл.
ГП-хэштейбл, ну вот.
Там есть еще CC-хэштейбл, еще пара.
Да, ну вот они побыстрее будут, чем это, потому что кажется, какая-то из них даже flat, то есть с открытой адресацией.
Ну вот, а unordered map эта штука довольно-таки тяжеловесная, именно по причине того, что в ней вот эти вот манипуляции с форверт-листом и сатераторами сложны.
Ладно, давайте на этом закончим, в смысле сделаем перерыв, и сейчас мы начнем.
Так, следующая тема называется memory management и аллокаторы.
И сейчас я вам расскажу кое-что, после чего вы будете способны написать вторую задачу, которая называется лист с аллокатором.
Сначала мотивиру... вот это поворот, я надеюсь, я его не сломал? Вроде нет.
Ну если сломал, сорян, будете без записи лекций.
Не сломал же, да? Работает?
Хорошо.
Так, аллокаторы и memory management.
Пришло время копнуть еще на уровень глубже.
Значит, идея, ну как обычно, первый параграф, идея и базовое использование аллокаторов.
Ну, как вы наверное неоднократно уже замечали, но возможно не хотели это замечать, тем не менее вы наверняка видели, что если вы посмотрите на любой контейнер,
например, на тот же вектор, то там его полное объявление выглядит так.
А еще есть такой параметр по умолчанию.
Значит, класс-вектор. И это абсолютно у всех контейнеров, то есть у всех контейнеров есть еще один параметр шаблонный, аллокатор, который по умолчанию это STD-аллокатор.
Ну или вот в случае мэпа от STD pair const k-value, ну и так далее.
Вот. Вот сегодня нам предстоит ответить на вопрос, что же это такое и что будет, если это поменять на что-то другое.
И на что вообще это можно поменять? И зачем это нужно?
Давайте начнем издалека. Представьте, что вы создаете лист или map или unordered map и собираетесь много туда элементов класть.
Вот. Вы знаете, что каждое добавление элемента это вызов оператора new на самом-то деле.
Ну вот когда вы работаете с листом, вы же понимаете, что insert в list это всегда вызов new.
Далее. То же самое и с map и с unordered map. Каждое добавление элементов в list map или unordered map это вызов оператора new.
Потому что так работает этот контейнер.
А что такое вызов оператора new?
Ну вообще это очень длинный и сложный разговор.
Это мы даже не в состоянии сейчас все это осветить, так сказать, что за собой скрывает вызов оператора new на самом деле.
Но я могу вам сказать на таком очень пока простом уровне, что вызов оператора new на самом деле он приводит к вызову сишной функции malloc, ну или какой-то там аналогичной ей функции сишной библиотеки.
То есть оператор new это же просто обертка, некоторая умная над какой-то сишной функцией в его делении динамической памяти.
А эта функция в свою очередь она на самом деле тоже содержит очень сложную логику.
То есть она там ну скажем так старается не всегда обращаться к ядру операционной системы, потому что обращение к яду операционной системы ну это уж вообще очень долго.
Но иногда эта функция там достаточно часто, может быть не очень часто, приводит к тому, что вы вот обращаетесь к операционной системе и говорите дай мне еще памяти.
То есть делаясь так называемый системный вызов.
Системный вызов это ситуация, когда ваша программа прерывает свое исполнение и говорит все теперь пусть операционная система мне что-то выдаст, а потом когда она мне это выдаст, я возобновлю исполнение.
И это в масштабе операций над целыми числами это супер долго.
Ну не знаю, это может быть там в тысячу раз.
Сделать одно такое действие там тысяча или десять тысяч в масштабе обычных операций над целыми числами, может даже еще больше.
Короче это очень долго.
Такое происходит не при каждом вызове new, но такое происходит время от времени при вызове new, потому что время от времени вызов new означает прервие исполнения, обратись к операционной системе, подожди пока она тебе что-то ответит.
А вы вот лист делаете и вы допустим заранее знаете, что вы в лист положите ровно 150 тысяч элементов, 150 тысяч интов.
Вот вы знаете, что в лист вы положите не больше чем столько.
И вот нельзя ли как-нибудь например сделать так, чтобы вы заранее зарезервировали память под этот лист, но вы заранее же знаете, что лист вы будете использовать ровно в таком объеме.
И вы ровно 150 тысяч раз попросите new нам на 8 байт.
Но операционная система этого не знает и функция malloc заранее этого не знает.
Поэтому она будет работать по общему алгоритму и будет каждый раз такой, ну еще 8 байт попросили, ну что ты будешь делать, ну опять пойду просить операционную систему.
И так 150 тысяч раз. Возможно в какой-то раз она там что-нибудь закреширует, что-нибудь вам выделит, но она заранее не знает, что будет ровно 150 тысяч запросов по 8 байт.
И конечно же заранее она не догадается попросить операционной системы 150 тысяч умножить на 8 байт, чтобы потом распоряжаться самостоятельно.
Придется много раз прерываться, ждать операционную систему.
Хотелось бы иметь механизм сказать листу заранее, что, например, будет столько-то элементов, ну короче зарезервировать заранее пул памяти, чтобы он не делал new через вот это все, а брал из него.
Хотелось бы, чтобы у контейнера такого как лист или так мэп, или как мэп, был механизм сказать ему откуда брать память, чтобы не приходилось ему 100 тысяч раз вызывать new, который будет вызывать операционную систему и что-то там ждать от нее.
В ран тайме конечно. Ну в ран тайме вы создаете лист и он допустим один раз спрашивает операционную систему дай мне столько памяти вот на сразу заранее, потому что я знаю сколько ее будет.
Короче какой-то аналог резерв для листа хотелось бы.
Резерв для них.
Ну типа, да. То есть, если вы заранее знаете, что вам нужно будет ровно столько раз вызывать new, ровно настолько byte, то почему бы вам не написать какой-нибудь механизм, который сразу это делает и потом уже распоряжается памятью сам, а не вызывает new заново.
Это долго очень вызывать new каждый раз.
Мы же вроде бы дали placement new, который как раз.
Плейсмент new вообще ничего с памятью не делает, он просто конструктор вызывает по данному адресу, он не запрашивает никакую память.
В чем проблема в резерве?
В каком резерве? У листа нет функции резерв.
И у UnorderedMap, но она есть, но делает не то.
Другой, другая проблема. Хорошо, ладно, фиг с ним. Допустим вы с этим смирились.
Допустим, у вас, вы вообще не хотите использовать динамическую память? Может такое быть?
Вот вы хотите создать связанный список на стеке? Такое можно?
Да.
Как?
Просто...
Нет, ну вот если вы...
А?
Поинтим самому сейчас.
То есть у нас 150 тысяч элементов?
Вы хотите создать STD-лист, но так, чтобы он на стеке хранился, а не в динамической памяти?
У вас, допустим, вы знаете, что нужен связанный список, маленький, на 100 элементов всего?
И вы не хотите, чтобы под него оператор New вызывался? Вам на стеке места хватит?
То есть 100 тысяч просто храним и все?
Нет, вы хотите, чтобы был связанный список? Ну или на 5 тысяч элементов?
То есть вы свой лист будете писать? Для этого? STD-лист вы не сможете?
Я знаю, что у меня будет лист очень маленький, или вектор очень маленький, или вектор, например.
Я знаю, что у меня будет вектор не более чем на 1000 элементов.
Но хочу, чтобы он был именно вектором, а не константным STD-рэем или C-шным массивом.
Я хочу, чтобы он на стеке алоцировался, а не в динамической памяти. Почему бы мне такого не попросить?
Чтобы просто стандартный, или MAP на стеке, или Unordered MAP на стеке.
Могу, если он маленький, если он умещается на стек, заведомо. Зачем в динамической памяти?
Стандартный алокатор, если вы пользуетесь контейнерами в таком режиме, не уточняйте,
то оно будет все время вызывать New, и вы ничего с ним не сделаете.
Шаблонный параметр алокатор как раз призван решить эти проблемы.
А именно он позволяет взять управление памятью для контейнеров в свои руки.
Например, не обращаться к Нью 100 000 раз, а заранее сказать, выдели сколько-то там,
а потом отдавай по чуть-чуть сам, уже не обращаясь к Нью.
Или вообще на стеке все делать, а не в динамической памяти.
Что такое алокатор? Алокатор – это еще один промежуточный уровень между контейнерами и оператором New.
Контейнеры, вот надо вот эту схему понимать в голове хорошо, что алокатор – это штука,
которая является промежуточным звеном между контейнером и оператором New.
Не между New и malloc, не между malloc и чем-то там ниже.
Алокаторы, вот это уровень абстракции выше, чем оператор New, но ниже, чем контейнер.
Вот. А вот здесь вот проходит граница между C и C++.
Вот. Но вот алокатор – это еще один промежуточный уровень, вот здесь.
Что такое алокатор? Это такой класс.
Ну, упражнение для нелью вычитателя. Открыть себе переференс named requirements алокатор
и прочитать, что такое алокатор формально.
Там перечислено, какими требованиями должен удалять алокатор.
Алокатор – это такое же метапонятие, как и контейнер.
То есть тип называется алокатором, если он и там перечислено что.
Что должен уметь алокатор?
Алокатор должен уметь четыре вещи.
Ну вот, так, главным образом четыре вещи.
Он должен уметь делать allocate от n от числа.
allocate от n – это метод выдели память на n штук типа t.
Алокатор – это шаблонный тип от t.
allocate от n значит выдели память на n штук типа t.
deallocate от pointer и n.
Вот в deallocate надо передавать то же число по стандарту,
которое было таким же, как и здесь вы передавали n на соответствующий allocate.
Если не передадите, будет уб.
Ну да, если вы не передадите или передадите неправильно,
то уб разрешено алокатору делать.
И дальше освободить память по этому указателю,
которая была ранее выделена allocate.
На самом деле, вот это две главных функции.
В общем-то от алокатора, как правило, больше ничей не нужно.
Но есть еще две, которые иногда бывают нужны от алокатора.
В общем, пока я просто скажу, что они у алокаторов должны быть,
потом мы немножечко уточним эту фразу.
На самом деле, не совсем.
Но короче, алокатор должен еще уметь делать констракт.
Значит, что такое констракт?
По указателю создать объект типа t.
Это аналог placement new на самом деле.
А второй это что?
Какой move? Нет.
Destroy.
Уничтожить по указателю объект типа t.
Вот раньше мы писали...
Вот что это такое?
Это аналог просто new.
Вот у нас, когда мы писали вектор, у нас было new
и там какой-то reinterpret, cast, char, бла-бла-бла.
Вот, короче, выделить сырые байты.
Выделить n умножить на size of t.
Вот это теперь заменяется функцией allocate.
Delete, reinterpret, cast, char, бла-бла-бла.
Заменяется теперь функцией allocate.
Констракт заменяет нам placement new,
а destroy заменяет нам явный вызов деструктора.
Вот.
Что такое std-алокатор?
std-алокатор — это такой класс, который просто...
Вот здесь вот делает new, char сколько надо.
Здесь делает delete сколько надо.
Здесь делает placement new, а здесь вызывает явный деструктор.
Вот все то, что мы раньше делали векторе напрямую,
на самом деле надо делать через аллокатор.
И я думаю, это момент, когда надо достать ноут
и начать писать код.
А сейчас вы...
Сейчас я напишу и...
Если бы мы писали на уровне следующего ула выше,
тогда бы вы точно были...
А если бы мы писали на уровне следующего ула выше,
то бы вы точно были...
Если бы что мы писали...
На уровне выше, чем средняя школа,
то бы вы точно были...
Ну не совсем.
Ну, короче...
Сейчас мы будем писать вектор
на уровне уже не средней школы,
а ну...
Старших классов, да.
Я вам обещал, что мы несколько раз
вернемся к написанию метода pushback.
Спасибо.
И вот произошел первый раз.
Сейчас мы снова посмотрим
на наш код вектора
и поменяем его, уже зная,
что надо аллокаторы использовать.
Аллокаторы же полезны,
когда мы заранее знаем, получается,
сколько нам нужно быть памяти, а здесь мы не знаем вектора.
А...
Не...
Не понял вашу претензию.
Аллокаторы же,
когда мы заранее узнаем.
Не обязательно.
Сейчас.
Вот
наш вектор.
Так.
Давайте
вспомним, что тут было.
Вот наш конструктор вектора.
Здесь, вот тут мы делали
довольно мерзкую вещь.
Мы, да, мы писали
reinterpret-каск, т-звездочки. Вот, на самом деле
вектор так не делает.
Он использует в этом месте аллокатор.
Откуда он берет аллокатор?
Ну, вектор хранит
объект аллокатора. Я вам говорил, что
это не все поля, это...
Я вас немножко обманулся.
У всех контейнеров есть еще одно дополнительное
поле, которое мы пока не упоминали.
Это аллокатор.
Блин, тут какой-то
код-стайл, типа,
с этими, с подчеркнений. Ну ладно, давайте я буду
соблюдать. Значит, type-name
alloc по умолчанию равно
std аллокатор
от t.
Ну, я
сделал include-memory, чтобы...
По-моему, он в memory объявлен,
std аллокатор.
Что...
Да, мы сейчас его реализуем.
Вообще, std аллокатор.
А t я сейчас покажу быстро, как он реализован.
Значит, теперь вместо этого
мы говорим
вот не вот это, а просто
говорим alloc.
Но только есть проблема,
нам надо alloc
в начало положить, потому что
его нужно создать до того, как мы начнем им пользоваться.
Значит, сначала мы создаем alloc
по умолчанию.
Ну, alloc
инициализируется по умолчанию.
Вот.
alloc.allocate
сколько?
Count просто, да.
Вот.
Что мы делаем вот здесь?
Третья попытка.
Мы говорим alloc.
construct
от
it.value
Что мы делаем здесь?
Мы говорим alloc.destroy
от
вот этот вот delit,
как он у нас называется, господи.
Ну и наименование.
И здесь мы говорим
alloc.
Ну, я комментирую, так сказать, для истории.
И здесь мы говорим alloc.
allocate
от
begin
запятая
и сколько там у нас было?
Count, видимо.
Вот.
Аналогично здесь
в reserve
ну, давайте напишу.
Тут мы делаем тоже alloc.allocate
new cap.
Тут мы делаем
alloc.construct
alloc.construct
значит
begin
plus i
запятая
нет,
newar plus i. По указателю
newar plus i мы делаем
construct begin
этого.
Здесь мы делаем
alloc.destroy
newar
plus j.
И здесь мы делаем
alloc.
deallocate
newar
new cap.
Да?
Ну, еще тут
мы делаем
alloc.destroydelete
И тут мы делаем
alloc.deallocate
begin
запятая
что там у нас было? cap
boof and
minus begin, видимо.
Вот все.
Вот все, что
использование аллокатора в контейнере, короче.
Но
базовое использование.
Хорошо.
Давайте
теперь обсудим какие-нибудь
А!
Ну, во-первых, давайте теперь просто реализуем аллокатор.
А что же делает аллокатор-то на самом деле?
Ну, аллокатор,
std-шный аллокатор, это
супер простой класс, он на самом деле
кого-то могло это пугать,
вот это вот std-аллокатор, что-то непонятно.
На самом деле, класс аллокатор, он просто максимально
примитивный, он делает
примерно следующее,
у него есть метод
t звездочка allocate
от size t
count
и здесь он просто делает вот то, что мы раньше
делали, return
ну, на самом деле
и тут он
не совсем так делает, но
можно сказать, что
так, reinterpret
cast к t звездочки
от new char count
умножить на size of t, то есть,
по сути, вот вся та
дрянь, которую мы раньше писали в
векторе, теперь перешла сюда.
Значит, void
deallocate
от t звездочка
ptr, запятая size t
count,
size t мы генерируем здесь, нам count не понадобится.
Просто
говорим delete квадратные скобочки
от reinterpret cast
обратно к чару.
от
e
t
от чего? от ptr
да
вот
construct
вот construct он уже
с переменным количеством шаблонных аргументов
он принимает переменное количество
шаблонных аргументов
construct
он принимает, значит, указатель
на t
и тут я немножечко вру, но
потом мы это исправим
принимает вот эти
вот аргументы
и делает placement new
new по этому адресу ptr
t вот этих аргументов
args многоточие
ну и наконец destroy
от t звездочка
ptr просто вызывает destructor
по этому адресу
ptr tilde
t
вот все, что
делает allocator
ну вот
обратите внимание, что allocator
стандартный allocator он вообще
полей даже не содержит
он, что называется, stateless
то есть
все методы правил
нет, все методы
ну, понятно, это можно
назвать структурой
то есть у него
эти все методы, разумеется, публичные
и он не содержит ни одного поля
потому что ему нечего хранить
стандартный allocator это просто обертка над new delete
зачем
delocate там
по стандарту требуется
для некоторых allocator это может быть важно
но для стандартного это не важно
а какой интеректор
в диалогейт передает
он передает, да, я же написал
мы передаем в диалогейт то
число, с которым вы деляли это
вот
давайте прежде чем двигаться дальше
рассуждать о проблемах, которые нам
принесет добавление языка allocator
поговорим о том
какие сначала проблемы
мы сможем решить с помощью allocator и как
ну, например, какой
можно было бы написать не стандартный allocator
чтобы
решить вот одну из озвученных проблем
да
какой может быть
не стандартный allocator, ну вот
классический пример не стандартного allocator это
pull allocator
это, значит, template
allocator не обязательно
должно быть стейлос, да? конечно
вот, давайте я напишу такой класс
pull allocator
только не пишите, пожалуйста,
pull как ull, это
а то
из года в год люди пишут такое
некоторые
не тянуть allocator, а, значит
pull от слова бассейн, да
что этот pull allocator
может в себе хранить
он может хранить указательно
некоторую
память
выделенную заранее, вот, некоторый
буфер
и в конструкторе
этот pull allocator
будет
выделять памяти
допустим, на сразу
столько штук
то есть он будет говорить вот этот вот buf
ну, списки инцелизации
buf от
new, ну и вот тут вот надо
написать вот это вот опять дерьмо
reinterpret cast
к t звездочки
от, значит, new, ой
Господи, что я делаю?
buf это значит reinterpret cast
звездочки от new char
там
count, ой, n умножить на
size of t
ну и все, вот
и что
что?
лишняя скобка
а, подождите, квадратная скобка
потом круглая скобка
круглая скобка, да, вот теперь правильно
и что теперь
можно делать?
а теперь, когда этому allocator
уговорят allocate
он распоряжается этим буфером, то есть
он может на самом деле какой-то алгоритм распределения памяти
реализовывать, не обязательно просто тупо
как вектор выделять подряд
он может как-то манипулировать блоками
то есть он может быть приспособлен
для какого-нибудь умного
управления памятью
у вас наверняка была в первом семестре
будет задача реализовать какой-нибудь memory
не было у вас задачи реализовать
memory manager с помощью там кучи
связанного списка, что-нибудь такое?
была?
на алгоритмах, конечно
да, что ж такое
какого черта
в смысле, у вас же должны были быть кучи, как минимум
теоретически куча
а на основе не было задачи memory manager?
нет
кажется нет
ну короче, вы можете реализовать
какой-то алгоритм управления
у вас есть пул вот этот большой
и вам приходят разные запросы
выдели столько-то, удали столько-то
и вы внутри поддерживаете какую-то структуру
в которой помните как
вот эти все штуки
кто у вас там
какой-нибудь список внутри
сами храните и так далее
но суть в том, что
в пользу этот локатор
вы можете
например, добиться того
что у вас лист
или map, или unordered map
не будет при каждом инсерте
делать вызов new
вы избежите
вот этого вот спуска каждый раз
на низкий уровень к операционной системе
путем того, что вы вот на верхнем уровне
видели дополнительную абстракцию
вы вот этот промежуточный слой контейнеру
подменили, сделали кастомным
и теперь, когда вы
в контейнере что-то добавляете
он уже не лезет в системный код
а в ваш код лезет
у вас в коде написано, как вы управляете памятью
где взять память для следующего элемента
вы заранее запросили у операционной системы много
например, гигабайт
в конструкторе
локатора вы запросили сразу много
и потом вы им распоряжаетесь как-то
и что-то умное делаете
другой пример, вы можете делать вообще
stack-локатор
допустим, вы завели какой-нибудь
массив на стеке
то есть вот здесь вот я допустим сказал
char
буфер
на
миллион
и
допустим, у меня есть класс stack-локатор
на какой-нибудь тип
не знаю, на int
а
alloc от вот этого буфера
и дальше я хочу создать
list, например, std list
или std map
из int в int
мне нужен, правда, stack-локатор тогда будет на пару
на std pair
из const int
int, тут надо не ошибиться
обязательно const int int, а то ничего не получится
вот
не знаю, my map
и проинициализировать
ее этим локатором
только здесь надо написать
ну, надо указать явно
std list
от int
и четвертый параметр вот этот вот stack-локатор
от std pair
от const int int
тут, к сожалению, придется это все
перечислить
а у мэпа не от какого-нибудь
члена типа
p-u-type
он есть, да
что, p-u-type
это и есть p-u-type
а почему тогда
мы пишем
а потому что к кому
на vlu-type-то обратиться
std map int int
std list int
и снова std map, это как
нет, std map int int
а дальше говорю
компаратор и последним параметром передаю свой кастомный
аллокатор и создаю my map от этого
аллокатора
у всех контейнеров есть конструкторы
соответствующих аллокаторов
а он не может
подставить
автоматически
последний параметр template не подставить
учитывая ваш номерок
да, к сожалению, не может
вывод типов шаблонных
параметров класса работает либо полностью
либо никак
да
компаратор
ну
да нет, не обязательно
компаратор можно и не создавать
так, давайте я сейчас
открою
на новой вкладке браузера cpp
референс
ой, не то сделал
сейчас
а он внутри
хранит именно
аллокатор
или может ссылки
вопрос, сейчас мы это обсудим
ну вот, допустим, map
давайте посмотрим еще раз, какие есть
конструкторы у мэпа
значит, на самом деле у мэпа
вот сколько конструкторов
его можно создать от объекта-компаратора
объекта-аллокатора, можно создать просто
от аллокатора
можно создать от пара
итераторов, компаратора и аллокатора
во многих конструктор он передается
по умолчанию
явно указать при создании. То же самое там с вектором
или с листом. То есть вы можете, например, вот скажем
вектор создать сразу от n значений сразу с кастомным
аллокатором. Вот. Тогда первым делом он создаст
этот аллокатор, объект этого аллокатора, и дальше
уже им будет выделять и создавать память, инициализировать
память под эти значения. Короче, во все объекты контейнера
можно передавать аллокатор. Теперь. Вы спросили, а что
делать, если аллокатор на самом деле хранит в себе
много всего. Если аллокатор какой-то сложный, и в нём
на самом деле большая структура данных какая-нибудь, которая
управляет этим блоком памяти? Потому что это будет
полем у контейнера. То есть у вас в контейнере будет
полем. Хорошо, если копируется контейнер, что будет происходить?
Зато честно. Да. На самом деле аллокаторы принято
считать легковесными типами. Если у вас аллокатор хранит
в себе какую-то большую структуру данных, это неправильный
подход, это идеологически неправильное использование
аллокатора. Аллокатор должен хранить мало всего, аллокатор
должен быть легким. Если у вас есть какая-то большая
структура данных, например тот же пул, вот как у меня
сейчас здесь написано, вот у меня есть какой-то пул,
вот я храню только указатель на него. Сам пул, я не делаю
огромный массив полем аллокатора, иначе он станет полем контейнера.
Контейнер хранит именно объект аллокатора в себе.
А не указатель на аллокатор. Контейнер хранит именно
объект аллокатора. Объект аллокатора это легковесная
штука, которая маленькая по размеру и которая управляет
блоком каким-то памяти. А сам блок хранится где-то
отдельно. Соответственно, когда вы копируете контейнер
когда вы присваиваете один контейнер к другому, у
вас этот аллокатор, он в случае чего его легко тоже
скопировать или присвоить вот это первое замечание касательно нестандартных
аллокаторов второе замечание вот смотрите такой
интересный момент вот у вектора написано alloc равно std аллокатор t ну это
не вызывает никаких вопросов аллокатор мы алоцируем объект типа t да
хорошо давайте посмотрим еще раз на лист например который вам писать предстоит
вот уже скоро вот я вам уже сегодня выдам условия у листа тоже есть
конструкторы у листа есть конструктор от аллокатора кстати кстати интересный
момент тонкий такой заметьте что до c++11 конструктор выглядел так тут было
const t value равно t const аллокатор равно аллокатор а начиная c++11 стал const t value
без конструктора по умолчанию и const аллокатор равно аллокатор еще explicit
пропал да ну explicit пропал это не интересно вот почему исчезло вот это
интересно explicit понятно почему пропал потому что у такого конструктор уже два
параметра и тут экспли обязательных и тут explicit не нужен так-то получалось бы
что ты просто от числа мог число не явно скастовать в лист если бы не было
explicit пропал default t по умолчанию да потому что появился новый конструктор
вот этот да почему так сделано было если бы у вас нет конструктора по умолчанию то и
тот и другой бы не скомпилировался все равно ну не скомпилировать нельзя вызвать лист
account по умолчанию если нет конструктора по умолчанию если нет конструктора по умолчанию
ничего бы не скомпилировать в любом случае если был конструктор по умолчанию тем не менее
решили вот этот конструктор вынести отдельно и вам тоже предлагается так сделать
знаете я вам сейчас объясню почему потому что это на один вызов конструктора больше бы тогда
было если вы создаете лист от шесть от пяти элементов то вызвался бы шесть раз конструктора так
он вызовется только 5 но потому что один раз он вызовется когда создастся аргумент по умолчанию
а потом еще пять раз этот элемент типа скопируется в ваш контейнер но когда вы создаете лист вот таким
у вас вызовется 1 раз конструктор по умолчанию и 5 раз конструктор копирование value а так да а так
у вас просто 5 раз вызовется конструктор по умолчанию нет конструктор копирования
да например если у вас нет конструктора копирования это бы не работало а так это
будет работать да не знаю не помню в ли스트 не уверен
ну возможно
нет копий констрактебл точно не должен быть
такого требования точно нет как минимум векторе элементы могут быть не копий констрактебл
они могут быть move только констрактебл короче нет такого требования не должно быть
ну как 5 по умолчанию конечно какой еще
так вернемся к локаторам а то мы ушли от разговора немного так вот смотрите
у стд листа тоже есть конструктор от кастомного локатора ну кто бы сомневался но
этот локатор он по умолчанию равен стд локатора t у вас ничего не смущает в этом
да у вас же лист выделяет не t он выделяет ноды а локатор вам на t дается и что
же делать та же проблема имеет место в мэпе и ван ордерт мэпе да и в деке когда
вообще во всех контейнерах кроме вектор на самом деле такая проблема имеет место
потому что векторе вы выделяете просто массив т-шек
внутри кого
вот у вас есть вот у вас есть лист template type name t и эту строчку просто скопирую вот
допустим я начинаю реализовывать лист пишу класс класс лист и тут в полях мне
нужно хранить а локатор и что я пишу что я пишу конкретно ага интересно
какой у него шаблонный параметр а лок а нет поскольку мы поскольку мы уже внутри то
что такое но до локатор просто стракт но до локатор ну давайте ноут а лок и что в ней
то есть вы то есть лист реализует здесь вы оборачивать короче вы в листе реализовывать
еще один локатор по сути обертку над тема локатор а что делает этот локатор хорошо как работает
вот видимо ноут звездочка а локейт и что он делает сайс тн да нет мы хотим выделить память
тема локатором которые нам дали и что мы делаем тот локатор умеет t выделять а нам надо выделить
ноды вы запрятали проблему на уровень глубже но проблема не исчезла как мы делаем это что мы
делаем здесь что мы пишем типа мы мы выделяем столько т чтобы в расчете на размер те у нас
типа но сколько надо получилось да класс а какой смысл вообще делать было вот этот
локатор мы там можно было ну вы просто ну что я должен написать ретерн что
да мы не имеем право писать нью я напоминаю все мы больше нью отныне не пишем в контейнерах
вообще короче мы ну там до тех пор пока я не говорю отдельно обратное больше мы нью не
используем мы всегда используем а локаторы потому что вся стандартная библиотека использует
а локаторы только а нью используется внутри локаторов в деке можно да вот а вот начиная с
листа unordered map никакого нью только локаторы ну нью конечно в реализации самих локаторов
можно использовать но в контейнерах никаких никаких нью больше контейнер не имеет права
вызывать нью напрямую он должен все делать только через а локатор который ему передали
короче проблема не решит непонятно как выделить ноды если а локатор умеет выделять т нам бы
хотелось как-то сказать что-то в духе дай нам пожалуйста сделай пожалуйста нам такой же
а локатор как тот который дали только не от и от ноут вот и на самом деле есть способ это сказать
но просто а локатор помимо всего прочего еще должен опять же должен в кавычках я потом уточню
на самом деле уже не должен но я потом уточню как это правильно писать пока считаем что должен
а локатор должен обладать такой метафункцией который называется rebind а в локаторе просто
еще есть такая штука она называется template type name u struct rebind и в ней написано using
значит other равно а локатор от у то есть что мы делаем когда нам нужно имея локатор на
т получить такой же а локатор но на другой тип мы просто говорим using ноут а лок равно type name
а лок двоеточие двоеточие rebind от у other от ноут да тем самым мы получаем на самом деле
а локатор такой же как нам дали но от другого типа от ноут а не от t почему зачем
возможно надо написать вот так ну я не знаю это зависит от компиляции
какой-то компилятор это умеет партий так какой-то наверно не сумеет отличный вопрос нет нельзя
это вопрос на подумать давайте поймем почему это это прекрасный вопрос да который задают
из года в год и к сожалению комитет тоже думал над этим но нет у нас же есть казалось бы у нас
есть шаблонные шаблонные параметры мы могли бы сказать что allocator это не type name а это ну
еще один template от type name да блин а класс alloc равно sd allocator вот казалось бы могли
так написать понимаете идею кто понимает идею мало кто я думаю уже там хорошо ладно почему
мы не можем так написать да потому что это дает нам ограничение что у allocator может быть лишь
один шаблонный параметр а вообще-то это неправда allocator может быть от многих шаблонных параметров
а когда мы перейдем шаблонный шаблонный параметр мы вынуждены ограничить мы вынуждены заранее
сказать какое у него будет число шаблонных параметров можно было бы конечно вот так сказать
но параметрами allocator могут быть и числа и на самом деле тот allocator который вам предстоит
написать он как раз вторым шаблонным параметром будет принимать число дело в том что pool allocator
как раз удобно делать со вторым параметром числом можно было и так наверное но кажется
уже проще вот это значит на самом деле вот allocator который pool allocator ему как раз удобно
делать шаблонным параметром число или stack allocator ему тоже удобно делать шаблонным параметром число то
есть вот это число сколько размер буфера это константа зашитая в тип и именно такой allocator
вы передаете в свой лист а поскольку allocator может быть каким угодно с каким угодно количеством
шаблонных параметров еще и разных по виду то мы не можем сделать его шаблонным шаблонным мы
должны сделать его конкретным типом вот
я все слышу ну еще раз потому что потому что синтаксис такой потому что тебе
template в угловых скобочках type name и сколько-то раз type name тебе надо написать ну вспомни синтаксис
шаблонных шаблонных аргументов ты поймешь что он фиксирует фиксирует количество шаблонных
аргументов allocator а идем дальше так вот есть такая штука rebind соответственно в листе вы
храните не alloc не alloc а node alloc как и в мэпе как и в unordered мэпе вот в листе вам надо хранить
ну раз уж у нас camel case в листе вам не надо хранить allocator на t вам нужно хранить лишь
один allocator и это allocator на nodu вот но вам нужно уметь создавать allocator на nodu из allocator
на t если вам в лист передали кастомный allocator то вам нужно allocator на nodu создать из него а
это значит что allocator еще должен иметь конструктор от такого же allocator с любым
другим типом то есть на самом деле у allocator должен быть еще конструктор от такого же allocator
с любым другим u allocator должен уметь создаваться от const allocator от u ampersand но в случае std allocator
это тривиальный конструктор который ничего не делает понятно потому что он stateless но должен
быть также оператор присваивания ему другого allocator короче allocator должен уметь он вообще
должен уметь каститься в такой же allocator от другого типа ну просто подмена типа allocator
это легкая операция должна быть вы должны уметь создавать allocator на t allocator на u и так далее
и обратно я уже не понимаю что значит allocator для хитрого типа allocator он
как allocator он же не привязан к t allocator он он памяти управляет а не занимается каким-то
специальным конструированием для конкретного типа t allocator не должен идейно отличаться от
allocator от другого типа работа allocator это память распределять а не что-то там про внутреннюю
структуру типа знать вот такие дела значит это это был пункт 9.1 сейчас я проверю что ничего не
а давайте дальше пункт 9.2 будет называться allocator trades по аналогии с тем как были
есть еще allocator trades что такое allocator trades сейчас мне пришло время исправить вот небольшой обман
который вот был здесь я вам сказал что любой allocator должен обладать методами констракт и
destroy а еще структура rebind но на самом деле после некоторого размышления комитет по
стандартизации понял что что-то они пережестили с требованиями к allocator ведь почти у всех
allocator в которые вы только можете придумать констракт и destroy они одинаково выглядят как
и rebind в общем-то довольно трудно придумать allocator у которого констракт должен был бы
быть не так реализован что еще может быть сделать констракт кроме как вызывать placement new ну
казалось бы ну например куда-то логировать да хорошо но как правило
констракт это штука которая делает одно и то же всегда она просто вызывает placement new по
данному адресу было бы странно требовать от каждого allocator просто вот это вот повторять это
это просто дублирование кода одно и то же то же самое с destroy тоже самое с rebind rebind у
всех почти allocator одинаковый он вот так должен выглядеть зачем его всем allocator требовать
писать если можно его один раз для всех allocator просто сделать поэтому решили вот эти методы
констракт destroy и rebind вынести в отдельную структуру которая называется allocator trades
и она уже параметризовано allocator есть такая структура allocator trades
которая в себе содержит методы констракт она принимая этот метод во-первых они все статические
этот метод он принимает allocator кстати не помню по константной ссылке или по значению но
пусть будет по константной ссылке и значит параметры этого allocator ну тут t звездочка значит да кстати
по поводу t звездочка а как узнать какой тип должен быть у да value type вот для этого allocator
все-таки требуется определить здесь еще value type вот value type allocator все-таки должен определять
так вот type name alloc 2.2. value type звездочка ptr и это все еще параметризовано шаблонным
параметрам type name многоточие args const args амперсант многоточие args и что делает эта функция она
если у allocator реализован метод констракт с нужными параметрами то вызывает его а иначе просто сама
доделывает за него то что казалось бы он должен делать тут написано если allocator has метод
констракт тут написано некоторая шаблонная магия которая в compile time просто проверяет присутствует
ли у allocator такой метод с такими параметрами это хороший вопрос на который мы ответим ближе к
концу семестра здесь написано некоторая шаблонная магия более высокого уровня чем мы сейчас владеем
значит если короче allocator есть такой метод то надо вызвать его значит alloc.construct от
значит ptr и args а иначе надо вызвать ну тут и в constexpr понятное дело а иначе надо вызвать
placement new значит alloc опять type name alloc value type от кстати тут может быть type name и не надо
писать от args аналогично реализован destroy вот а еще реализована структура rebind alloc значит внутри
конструктор который себя просто принимает неконстантную ссылку то как это совсем
чего-чего-чего у конструктора есть конструктор который одним из параметров берет неконстантную ссылку
то как со всеми этими шаблонами это будет работать
тут есть туду которая нам надо поправить заключается в том что вообще здесь на
самом деле не констаркс амперсант это правда это правда там на самом деле 2 амперсанда там
у всемантика еще должна присутствовать но мы пока игнорируем эту проблему короче мы исправим эту
проблему через некоторое время да там там на самом деле более хитро сделано это некоторое туду
которое мы еще исправим во всех местах где я пишу констаркс амперсант на самом деле другая ссылка
должна быть но пока мы короче забиваем на эту проблему там все сложнее пока мы считаем что мы
просто все копируем это будет третья причина по которой мы вернемся к реализации pushback и
переделаем ее еще раз тоже самое с destroy еще структура rebind alloc то есть здесь есть такая
template type name u struct rebind alloc ну на самом деле это просто using уже а не struct rebind alloc это
и тут написано некоторая шаблонная магия которая опять-таки если в аллокаторе значит определен
rebind то она берет из него а иначе сама каким-то чудом до определяет а давайте посмотрим на
аллокатор trades memory management library а локатор trades вот rebind alloc
ну вот да как она это если там есть эта штука то она просто его берет а иначе она ну вот каким-то
чудом пока опять-таки опустим вопрос как она это делает но как это умудряется возможно это кстати
зашита в какие-то внутренние языковые конструкции я кстати даже не уверен можно ли это написать самому
что-то я засменивался возможно она просто
возможно это зашита в компилятор я не уверен что даже можно написать если честно что я сходу
не придумываю как это написать поэтому возможно это просто зашита в компилятор и так сделано
возможно это не реализуемо само языке надо утеснить этот вопрос ну короче вот такая структура такой
using вот и ну вот тут что-то написано и теперь а еще а еще для симметрии так сказать для
единообразия в allocator trades также есть методы allocate и deallocate аналогичные вот вот такие же
короче и на самом деле в контейнерах нет если allocate и deallocate не реализованы в allocator
они обязаны быть реализованы просто для симметрии чтобы не делать так что часть методов мы через
allocator trades вызываем мы все делаем через allocator trades это просто обертки и на самом деле вот в этой
вот схеме который нарисовал на доске надо впилить еще один промежуточный уровень между контейнером
allocator а именно allocator trades то есть на самом деле я тебе скажу еще более сильное утверждение
контейнер не то что никогда не обращается к нью напрямую он никогда не обращается к методам
allocator напрямую он всегда делает все через allocator trades значит контейнер не вызывает alloc.allocate
он говорит allocator trades от этого alloc.allocate с параметром allocator и так далее вот и здесь
на самом деле удобно написать в самом начале using alloc.trades равно std allocator trades от этого alloc
и везде во всех обращениях к alloc.allocate писать не alloc.allocate count а alloc.trades
2.2.allocate от alloc.account и так везде во всех методах allocator а мы во всех моментах где мы обращаемся
к alloc.allocate мы теперь пишем alloc.trades вот здесь мы пишем alloc.trades вот здесь мы пишем alloc.trades
что именно alloc.trades?
ну это вот то что мы это нужно чтобы была эта обертка нужна чтобы allocator некоторые методы
мог не реализовывать ну вот да такой вот костыль тем не менее да вот кстати alloc.trades есть еще
такие usings тут есть value type pointer cons pointer void pointer не знаю зачем они нужны вот это вот
интересные штуки которые мы сейчас обсудим ну вот в принципе что еще есть alloc.trades
а значит существует тем не менее пример alloc.trades у которого констракт и дестрой не стандартные то
есть там не просто placement new а нечто более хитрое вот то есть казалось бы вообще зачем нужно вообще
зачем нужно alloc.trades иметь метод констракт и дестрой если они у всех alloc.trades одинаковые но нет
в следующий раз мы вам покажем пример alloc.trades я не знаю кто из нас я или федя мы еще подумаем
существует пример alloc.trades у которого констракт не стандартный он не просто вызывает placement new
а делает нечто гораздо более хитрое он называется scope allocator adapter и в нем метод констракт делает
нечто очень необычное а именно вот примерно вот вот вот это но вот что это такое и как это работает
это мы обсудим в следующий раз но короче пример alloc.trades у которого констракт не стандартный
существует вот пример значит но это мы обсудим в следующий раз а пока нам надо обсудить еще
один пункт с вами а именно понятие alloc.trades aware containers
значит пункт 9.3 и последний на сегодня будет называться allocator aware containers
allocator aware да контейнеры волнующиеся об а локаторе ну как бы осведомленные о нем
не allocator concern containers allocator aware containers обеспокоенные а локатором ну переводить как хотите
в общем контейнеры уважающие allocator можно сказать давайте я открою вам формальное
определение того что allocator aware container опять таки на cpp reference это еще один name
requirement allocator aware container появившийся cpp 11 впрочем вот в чем суть помимо того что этот
контейнер обязан все делать через allocator ну одно из главных требований к этому контейнеру это что
он все выделения памяти и все конструирование объектов делать через allocator а точнее через
allocator trades него вот но здесь написано что значит
ладно тут написано не это тут сразу тут сразу с места в карьер написано ну в общем этот allocator
должен этот контейнер должен делать все через allocator но этого мало он не просто должен делать
все через метода allocator есть еще более стрёмные требования есть требования как должен контейнер
себя вести при копировании вот представьте что вы копируете контейнер у вас есть две опции
скопировать allocator или не копировать allocator как вы думаете надо ли копировать allocator при
копировании контейнера allocator как правило это легковесный объект то есть это штука которая
ну у вас есть ну представьте у вас есть pool allocator и allocator хранит себе там указатель на вот
этот pool в пуле там какие-то какой-то памяти управляет вот вы копируете контейнер что
представляет копирование allocator тогда вы просто даете там другую ну ну у вас просто теперь
несколько allocator владеет одним и тем же pool ну допустим они там какой-нибудь shared ptr на
него поддерживает чего это вопрос не всегда это может быть хорошо в этом и проблема да то есть
у вас если вы если у вас allocator владеет каким-то pool памяти и вы копируете контейнер то у вас
получается что два теперь несколько allocator могут владеть одним тем же pool это значит что
allocator теперь должен учитывать своем алгоритм что он не единственный allocator который этим
владеет что вообще-то там может быть еще несколько allocator в параллелье с ним что-то делает и
ну не всегда короче так хотелось бы чтобы было иногда вам могло хотеться бы чтобы allocator
единолично владел pool который он создал чтобы когда вы копируете контейнер не allocator
а новый pool бы создавался то есть создавался бы новый allocator заново и новый pool бы создавал то
есть не то что вы скопируя скопироваться allocator это значит создать еще один allocator указывающий
на тот же pool а может быть вы хотите при копировании контейнера создавать новый pool то
пишет создавать новый allocator с дефолтный там с какими-то дефолтыми параметрами чтобы он
новый пулон заведовал и а локатор может указать вам как бы он хотел чтобы вы вели себя при
копировании контейнера у а локатора есть такой точнее не есть а он может быть у а локатора может
присутствовать такой а юзинг
сейчас а ну а локатора локатора у стандартного такого нету а вот у обычного локатора у
точнее у общего а локатора у cpp nametrip arguments а локатор у него может присутствовать такой
метод под названием select onContainerCopyConstruction этот метод возвращает а локатор и есть как бы два
подхода и он может вернуть как копию текущего а локатора так и новый такой же а локатор и
когда вы копируете контейнер если вы а локатор aware контейнер вы обязаны не копировать а локатор
а вызывать у него метод select onContainerCopyConstruction таким образом либо получая новый а локатор либо
получая копию старого а локатора но поскольку а локатор не обязан реализовывать этот метод вы
конечно же должны это делать через локатор trades а локатор trades в себе для каждого локатора
реализует метод select onContainerCopyConstruction который если в локатор реализован этот метод возвращает
то что возвращает он а иначе просто возвращает вам по моему новый а локатор такого типа или
копии я не помню что он делал по умолчанию что у а локатора а локатор вы должны реализовать
просто не всегда вы должны копировать а локатор когда копируете контейнер копирование контейнера
не всегда нужно приводить к копированию а локатора копировать локатор вы должны
уметь но вот копировать контейнер не всегда значит копировать а локатор то же самое с
присваиванием контейнера когда вы присваиваете контейнер другому контейнеру вы можете либо
либо скопировать аллокатор, либо, я вижу фейс-палмы, да, у людей, правильно, либо скопировать аллокатор,
либо опять создать новый аллокатор. Вот вы присваиваете один контейнер другому контейнеру,
вы можете, это может означать, что либо нужно сохранить аллокатор, либо аллокатор тоже нужно
присвоить из того контейнера. И в зависимости от этих двух случаев вам нужно вести себя по разному
в контейнере, в аллокаторе wire-контейнере, а вам лист именно таким надо сделать. Вот. И здесь
вам нужно смотреть на такой юзинг, который в аллокаторе может быть определен, который называется
propagate on-container-copy-assignment. Это либо структура, в которой написано юзинг static-cons-bool-value
true. Короче, это либо std true-type, то есть это штука, в которой просто написано поле true,
либо false-type, то есть константа, в которой написано поле false. Вы должны посмотреть на это,
и если true, то вы должны контейнер, аллокатор тоже присвоить при присваивании контейнера,
а если false, то вы должны сохранить старый аллокатор при присваивании контейнера.
Что это в свою очередь значит с точки зрения ваших действий над объектами? Вот представьте,
вы присваиваете один контейнер другому контейнеру, и вам говорят, что propagate on-container-copy-assignment
true, то есть вы должны присвоить аллокатор тоже от того контейнера. Вы должны тогда удалить старым
аллокатором старые элементы контейнера, вот вы присваиваете вектор другому вектору. Вы не
имеете права удалять другим аллокатором свои объекты, вы обязаны удалять объекты тем
же аллокатором, которым они были выделены. То есть если у вас propagate on-container-copy-assignment
true, вы обязаны удалить старым аллокатором ваши объекты, после чего заменить ваш аллокатор и уже
новым аллокатором создать новые объекты. Ну да, сначала вам нужно, видимо, создать новые
объекты новым аллокатором, потом удалить старым аллокатором старые объекты, потом, значит,
заменить аллокатор на новый аллокатор. Возникает резонный вопрос, какой должен у вас возник
вопрос в такой ситуации? Exception safety. А что если присваивание аллокатора кидает исключение?
Значит, что если присваивание аллокатора кидает исключение? Ответ содержится вот на этой самой
странице. Аллокатор обязан не кидать исключение при копировании и присваивании. Именно по той
причине, что если бы аллокатор кидал исключение при копировании и присваивании,
то вы не смогли бы соблюдать exception safety при присваивании и копировании контейнеров.
Значит, аллокатор обязан быть noexcept при копировании и присваивании. Так, давай.
Почему название эти кьюзинг какие-нибудь длинные? Почему один из них это кьюзинг, а другой метод?
Потому что Select and Container Copy Construction должен дать вам новый объект аллокатора. Вы же вообще,
говоря, не знаете с какими параметрами создавать аллокатор, если что. Select and Container Copy
Construction, он дает вам тот экземпляр аллокатора, который вы должны создать, который вы должны
использовать, но его может не быть. При присваивании вы либо сохраняете свой,
либо берете тот, присваиваете от того. А Select and Container Copy Construction либо дает вам тот,
либо дает вам какой-то новый. Вот, поэтому это метод, а это значит кьюзинг. Ну, вот так.
Вот, давайте последнее, что я вам скажу в этом пункте, и мы на этом закончим. Это вот что. Ну,
небольшой анекдот будет, так сказать, из области C++. Смотрите, вот последняя коротенькая смешная
байка просто. Смотрите, вот в векторе полем является аллокатор, как мы теперь знаем,
как и в любом контейнере еще есть дополнительный поле аллокатора, но аллокатор почти всегда
пустой, он не содержит никаких полей. Мы с вами выясняли, тем не менее, что size of
вектора это 24, правда же? Там три указателя и все, говорили мы. Но на самом деле нет,
там еще есть аллокатор, он пустой. Как же так выходит, что этот аллокатор не добавляет size of
к вектору, ведь это же дополнительное поле, и из-за выравнивания он должен до 8 добиться,
то есть size of вектора должен быть 32 тогда, а не 24. Кто поймет, кто догадается, почему нет
тут дополнительных 8 байт на поле на хранение аллокатора? Так это анекдот, то можно... Да,
это анекдот. Что? Нет. Нет. Мы с вами проходили в первом семесте, кто вспомнит, тот молодец,
как... В смысле не инстанци... Чего? Нет, он инстанцировался, что он используется?
На самом деле я напоминаю, что есть такая штука, как empty base optimization. И я могу просто сделать
вектор приватным наследником аллокатора, и если этот аллокатор пустая структура,
то это не добавит размера к моему вектору. И теперь я, когда создаю свой вектор, то первым делом я
создаю родителя, а уже потом создаю все свои поля. Аллокатор trades это не объект, а аллокатор
trades это... В нем все методы статические. На самом деле все контейнеры являются наследниками
соответствующих аллокаторов. Просто приватными, поэтому вы никак не можете это узнать, ну вот,
то есть вы можете затестить это, попробовав скастовать какой-нибудь контейнер к соответствующему
аллокатору, и вы скорее всего получите ошибку приватности. Нельзя, потому что это приватное
наследование. Вот такие дела. Я думаю, что я вас попрошу сделать то же самое. На самом деле,
начиная с C++20, эта проблема решается менее костыльно, а именно существует такой атрибут,
который называется... Да, не знаете, но я вам заспойлеру. Существует атрибут, который называется
nouniqueaddress. Начиная с C++20, вместо того, чтобы делать приватное наследование от аллокатора,
можно просто поле в своем классе пометить вот так. Это подсказка компилятору, что у этого поля
адрес может совпадать с адресом какого-нибудь другого поля и ничего страшного. Начиная с C++20,
так разрешили делать для полей, которые пустые. И тогда это не добавляет новой памяти. Но до C++20,
и на самом деле до сих пор, потому что стандартная библиотека, скорее всего, если у вас не новая
версия стандартной библиотеки, то в C++17 контейнер это наследники аллокаторов.
Ну да, просто сделали такую штуку, чтобы не приходилось приватное наследование пилить каждый
раз, когда вы хотите пустое поле добавить. Вот такие дела. Ну на сегодня все. Мы все успели,
