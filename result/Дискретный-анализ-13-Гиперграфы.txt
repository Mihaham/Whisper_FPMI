так друзья ну все надо начинать вернее надо знаете чего надо не начинать а заканчивать только
не в том смысле в каком вы подумали наверное что надо заканчивать курс фигушки вам я понимаю что
у вас начались сплошные зачеты дедлайны поэтому вы бы с удовольствием закончили курс сейчас это
фигушки я до упора буду читать заканчивать надо ту теорему которую мы начали в прошлый раз у меня
чуть-чуть не завершился катарсис я даже объяснил в чем он будет состоять поэтому в каком смысле
сорвал его на сегодня но тем не менее давайте вы мне напомните формулу которую я насчитал
я наизусть не помню вот ту которая через мю то дельта равняется там как что такое пв равно мёд
мюрт что за мюрт я понял не надо подождите у меня то чего получилось там куса звездочкой
какое-то было которое отвечало за вероятность вытаскивания еще раз
что
сейчас подождите ну давайте напомнить я сейчас это конечно очень нехорошо что нам
приходится вспоминать что-то по сути так еще раз мы мы оценивали давайте давайте напомним мы
оценивали математическое ожидание и грекатого первого оно оказалось за счет вот этого
рандомизированного алгоритма который мы придумали оно оказалось не меньше чем мю умножить на куца
звездочкой минус дельта куса звездочкой в квадрате пополам было такое но тогда я сейчас вспомню сам
чему равно мю раз уж меня заставили это вспоминать такое было что-то миша вот как не может и этого
найти тоже было было но я писал что это не меньше чем мат ожидания там какого-то модуля c минус да
да да да да да да там было множество дубль вы который дубль ве штрих как
которая состояла из вредоносных пар пар который перенул это тоже давайте
напомним ладно это же нам нужно еще вот дубль ве штрих давайте я напомню это важно оно
состояло из всевозможных пар так потому что так я их называл да каитое кожитое
давайте вспомним что такое дубль ве штрих это множество таких пар каитое кожитое что каждый
из них принадлежит с и что мощность пересечения каитое кожитое больше либо равняется двойке вот
это правда товарищи но я написал тогда вот ошибочно что оно не превосходит единицы перепутал
не в ту сторону неравенства написал после этого кто-то мне сказал ну все теперь катарсиса не
будет кто-то точно сказал только кажется этого человека тут нет вы были да
ну конечно здесь различные ежи да конечно да да да да да здесь пары различных каитое кожитое
каждый из которых попало в прореженный набор вот этих независимых множеств мощности к 1
каждая и прореженные то вот я его так называю обозначается он ц прореженный в том смысле что
мы ц отбирали добавляю вот эту случайность ку со звездочкой что все все забыли что так смотрится
на меня грустно так я поэтому и хотел чисто формально вот просто мы к чему-то пришли вы
потом будете вспоминать то я ж не могу каждую лекцию заново напоминать то что был на предыдущий
но тогда у нас курс будет слишком долгим то есть я его буду читать по два раза в неделю я не
обломлюсь значит ц со звездочкой это был это под множество множество ц которое получается из
множества ц путем выкидывание по одному элементу из каждой пары принадлежащей w штрих мы берем
каждую вредную пару вредная она в том смысле что она плохо пересекается слишком сильно нам не
нас не интересует независимое множество которые сильно пересекаются потому что наша цель была
оценить мат ожидания y катова первого а y катая первая определялась как набор мощность набора
независимых множеств каждые два из которых пересекаются противоположным образом мало не
больше чем по одной вершине не знаю но вот на таком уровне вспоминаете и большинство лиц
повторяются я имею в виду вот вы здесь сидите я помню что вы и прошлый раз тут сидели и позапрошлый
то есть вы не то чтобы ну как бы совсем с нуля сюда пришли конечно не понимаете чего я рассказывал
поняли как ц со звездочкой строится да поэтому конечно
мат ожидания грекатова первого оценивается снизу как мат ожидания мощности исходного ц
минус мат ожидания мощности w штрих
ну и в прошлый раз мы писали что вот это так а это так там еще было дубль вы у которого дельта
пополам было мат ожидания дубль вы оно отличалось от дубль ве штрих тем что вот здесь не ц а к красивая
которая состоит просто из всех независимых под множество а ц только прорежен это прореженая
как красивая там еще было дубль в оно в точности такое же просто вот здесь надо писать как красиво
все остальное полностью повторяется вот у нас по определению мат ожидания мощности
в это дельта пополам мы так обозначили просто из этого мы получили что мат ожидания мощности
w штрих это дельта пополам умножить на ку со звездочкой в квадрате отличие только в том что
оба множества должны еще вот сюда попасть это происходит с вероятностью ку со звездочкой в
квадрате вот после чего мы просто продеференцировали вот это выражение по ку со звездочкой и убедились
что максимум достигается ну что там убеждаться это школьный материал что максимум достигается
когда ку со звездочка равняется мю поделить на дельта да или наоборот да мю поделить на дельта
вот так это просто вот минус б поделить на 2 а как учит в школе максимум квадратного трех членов
откуда следует что мат ожиданий грекатого первого не меньше чем мю квадрат поделить на
2 дельта вот до этого мы точно дошли вот а цель наша цель лемма то в том состояла вот лемма
которую нам оставалось доказать до полного так сказать катарсиса до завершения теоремы нам
нужно было доказать что мат ожиданий грекатого первого не меньше чем вот такая вот функция м в
квадрате на 2 к 1 четвертой степени черт похоже долго буду все равно говорить ну что делать надо
чтобы все все поймать как уж в какой год пойдет так и пойдет главное чтобы публика понимала так
помните что вот в этом утверждение состоит лемма состояла в этом и из этой
леммы мужа всю теорему вывели теорема по модулю вот этой лемма она доказана у нас
теперь я говорю так смотрите я получил вот это это я получил а хочу я вот это
они рядышком отведены в кружочек что хочу что получил ну то есть наверное мне мне хочется хочется
чтобы
мю квадрат поделенная на 2 дельта а симпатически равнялась м в квадрате поделить на 2 к 1 четвертый
то есть я завершу доказательство леммы если вот это хочется оно еще и наколется оно еще и
сможется вот если оно сможется да тогда все тогда лемма мы доказали ну понятное дело что можно
двойки сократить от этого хотение не поменяет свой смысл двойки сокращаются так чего теперь
хочется теперь хочется вот это равносильно тому что дельта дельта перекидываем направо ведет
себя как мю квадрат на к 1 четвертый поделить на м в квадрате но это равносильно просто тому
что хочется хочется вот это значит давайте прежде всего заметим заметим то к у со звездочкой в этом
случае если будет реализовано то что нам хочется вот в этом случае вот в этом если она получится если
это получится к у со звездочкой оно ведет себя как мю поделить на мю квадрат к 1 четвертый умножить
на м в квадрате согласны ну разделил просто на то что хочется это будет поехали сюда это будет
м квадрат поделить на мю и на к 1 четвертой степени вот то что я сказал на прошлой лекции в
конце у нас по условию выбора параметров мы их так подбирали вот это мю что такое мю помнишь
такое мю это короткое обозначение для мат ожидания просто мера это мат ожидания поэтому мю вы
знаете что мю еще это такое стандартное обозначение для первого параметра в нормальном распределении
мне никогда не встречали n от мю сигма квадрат ну ладно все тогда забудьте короче я это мю написал
не потому что это мера потому что это мат ожидания мю это было мат ожидания которые у нас с самого
начала вот в таком виде выбиралась это вот выбор параметров которые мы долго обсуждали в самом
начале доказательства теория это точно было товарищи не хочу к этому возвращаться мю ведет
себя вот так поэтому вот следствие относится к этому последнему равенству поэтому мы получаем
1 поделить на m степени не три уже а 1 плюс о малой от единицы и еще на к 1 в четвертой и вот этого
хватает для того чтобы утверждать что кусать звездочкой находится в пределах от нуля до одного
то есть это корректно заданная вероятность вот это то что я обещал катарсе состоит в том что вот
это условие на параметры которые мы долго обсуждали оно реально нужно для того чтобы убедиться
том что мы взяли именно вероятность куса звездочка и не какую-то хрень которая больше одного имели
меньше нуля и дай бог сейчас вот стало понятно да я аккуратно это посчитал и видно что это
стремится к нулю но то есть при больших значениях n m мы конечно можем считать что это корректно
определенная вероятность с которой отбираются вот эти вот независимые множество вот эти вот
независимые множество они отбираются с этой вероятности да это мы показали корректность то есть
нам осталось вот это реально нам осталось вот это смотрите давайте посчитаем дельту просто честно
посчитать что такое дельта это мат ожидания мощности w но мы вернемся просто к тому что пары
станут упорядоченными тогда удвоенная мат ожидания мощности w это тоже самое что рассмотреть
упорядоченные пары ну то есть посчитать что каитое кожитое кожитое каитое суть разной
вещи то то же самое что умножить над сейчас я напишу ответа вы мне скажете понятно или
нет но я буду в соответствующей степени пояснять я утверждаю что дельта это есть боже ты мой дельта
это есть сумма по т от двойки до к1 минус 1 сумма нет тут сумма уже больше не нужна
т из к1 по t на c из m минус к1 по к1 минус t а что только две цешки а мне что-то хотелось
что больше сейчас т из к1 по t не то не вроде правильно ц из м минус к1 по к1 минус
что-то меня смущает подождите что ж такое так что не так-то идиот самое первое это не выбрал
господи боже мой надо было начинать вот с этого сначала выбираем к одну вершину для одного
независимого множества потом уже к нему прицепляем второе так и тут будет одна
вторая в степени так в какой степени 2 ц с к1 по 2 минус ц ст по 2 вот так вот я утверждаю что
дельта это вот такая мерзительная бяка значит как я посчитал дельта я понимаю это никто не
понимает ли кто-нибудь понимает с объяснением да как я посчитал дельт но объяснение это
сарделька конечно значит нас есть мы вершин нашего случайного графа сарделька это мы вершин
нашего случайного графа нас интересуют пары пары под множество вот этой сардельки значит
в этой сардельке нас интересуют пары под множество каждая мощность и к1 просто по
определению если она находится вот здесь то оно мощности к1 и надо еще чтобы пары пересекались
хотя бы по двум вершинам вот я говорю пусть t это количество общих вершин t это просто
количество общих вершин вот это это количество общих вершин давайте мы сначала выберем к и т
любым из вот стольких способов вот мы фиксируем к и т оно мощности к1 поэтому выбрать его можно
вот столькими способами так все успевают выбрали теперь нам нужно да выбрать еще к и т пары
упорядоченные поэтому мы ни на что не делим пары стали упорядоченные вот мы выбираем к и т как
мы выбираем мы должны выбрать отсюда махонькую такую сардельечку состоящую из т общих вершин
т это число общих вершин вот мы выбираем с из к1 по т тут к1 вершина а выбрать надо
т вот мы выбираем любые т вершин когда мы их выбрали мы из оставшихся м минус к1 вот тут
вот было к1 а осталось м минус к1 выбираем соответственно к1 минус т чтобы в сумме
получилось к1 то есть вот это как раз к большое житое ну а дальше это просто линейность математического
ожидания мы перебрали все возможные пары и вероятность того что пара присутствует а что значит
пара присутствует надо чтобы и к к большое и т и к большое житое чтобы они оба были независимыми
но это значит все ребра которые находятся в объединении вот этих двух сарделик должны
пропасть 1 2 это вероятность исчезновения ребра мы сейчас работаем со случаем когда
п равно 1 2 почему 20 ска один по два но потому что тут цск 1 по два ребер и вот тут вот в этой
сумме двух маленьких сардельчик тоже цск 1 по два ребер и у них есть общие цст по два ребер
которые надо вычесть вот я их вычитаю в объединении каитова кожитого количество ребер вот такая разность
ну вроде поняло
формально тут ничего сложного нет противно это теперь убеждаться в том что вот такая сумма
а симпатически вот так себя ведет значит дорогие друзья я все-таки считаю что мы с вами учимся
заниматься асимптотиками но не до такой степени мне кажется что я достаточно хорошо объяснил
людям как заниматься асимптотиками давайте я единственное что сделаю смотрите я утверждаю
внимание это важно сейчас мы кое-что сделаем то при t равном двойке то есть вот единственное это
слага и мы с таким часто сталкивались помните там историю например про порог для связности
когда я сумму разбивал на какие-то две части но в итоге все концентрировалось в начальном значении вот
здесь тоже при t равном двойке та симптотика и сосредоточен вот это я доказывать не буду
потому что это доказывается еще омерзительнее чем просто путем разбиение суммы на два куска
ну а мерзительно доказывать тяжело но анализ такой очень скучный очень рутинный вот если поверить в
то что при t равном двойке главное слагаемое то вполне уже по силам нам убедиться в том что да
действительно оно имеет вот такую асимптотику вот я предлагаю это сейчас попробовать проверить то
есть я хочу проверить что c из к1 по 2 на c из м минус к1 по к1 минус 2 на c из м по к1 и
на одну вторую в степени 2 c из к1 по 2 минус 1 тут минус 1 будет при t равном двойке что вот это вот
асимптотически равно что такой мю квадрат кстати давайте мю квадрат тоже явно напишем
это c из m по к1 в квадрате на 1 вторая степени 2 c из к1 по 2 вот дорогие друзья вы понимаете
что это мю квадрата то вы забыли а это как раз похоже на то что написано слева и сразу становится
легче мю по определению мат ожидания просто числа независимых множеств вот этих товарищей
просто мат ожидания числа ну конечно это c из м по к1 просто выбираем 1 к айта мощности
к1 выбираем его 1 и умножаем на одну вторую степени 20 из к1 под вот просто цск 1 под
что оно независимое но а мю в квадрате это я вот возвел в квадрат просто возвел в квадрат так
это мю в квадрате дальше надо еще к1 в четвертый написать и разделить на м в квадрате вот друзья
если вы осознали то что я сейчас говорил то стало намного легче вот как картинка должна
была сложиться сейчас что смущает что мю такое нет это мы сейчас проверим я вот вот это вот это
последнее что я хочу сделать последнее вот в этой теореме что я хочу сделать строго ну как
получается сейчас возьмем разделим лево направо и убедимся что при деле 1 это наша задача товарищи
вы поняли что задача в этом это вы поняли да ну тогда давайте делить щпок так с из м по к1 в квадрате
на 1 вторая степени 20 из к1 по 2 на к1 четвертый на м квадрат что
но я что говорю что оно вообще очень мило сокращается леп леп
можно ролик номер два снимать ясно если кто видел там шлёп шлёп да да да ну нет я имею
в виду что можно его потом обработать нет там просто так понимаете вот я так как-то двигаюсь
туда сюда туда сюда вот я явно не так двигаюсь нам аж шлёп шлёп оно еще так сделано очень забавно
то есть добавлено еще некоторые харизмы происходящим так ну вот еще один шлёп шлёп вот
такое специально перечеркнув другую сторону чтобы было понятно кто с кем сократился хух так
что же у меня осталось то так дайте напишем тильда к1 в квадрате пополам это я написала
симптотику для вот этой цешки ну к1 к1 минус 1 это к1 в квадрате во симптотике так дальше 1
вторая в минус 1 это двойка 1 вторая в минус 1 сейчас будет опять шлёп шлёп да так и еще
умножить на м квадрат и умножить на с изм минус к1 по к1 минус 2 так а тут поделить на давайте
к1 в четвертой и на с изм по к1 ну действительно шлёп шлёп еще раз хлоп хлоп вот тогда к1 в квадрате
ну что нам осталось доказать что остается доказать следующую замечательную вещь то
с изм минус к1 по к1 минус 2 разделить на с изм по к1 это симпатически равно к1 квадрат на
м в квадрат ну вообще мне-то это более-менее очевидно но я могу это доказать ничего тут
такого сложного нет смотрите что у нас тут получается м минус к1 факториал поделить на
к1 минус 2", на m минус 2к1 плюс 2, а тут у меня получается м факториал в знаменателе
к1 факториал м минус к1 факториал, то у нас остается после сокращения значит
после сокращения у меня остается сверхуxo сразу а симптотику напишу к1 в квадрате как раз как
хотелось, но потому что k1 факториал, делённый на k1-2 факториал, это k1 на
k1-1, но это k1 в квадрате, асимпатически. Спеваете? Не очень гадим. Пока вроде
должны быть живы, но вот эти вот два сократил, это в асимптотике, это k1
квадрат. Теперь я пытаюсь сократить, наверное, вот это и вот это. Ну всё равно,
на самом деле. Что с чем? Знаете, я вот так вот напишу. А, в общем, действительно,
наверное, всё равно, что с чем тут сокращать. Значит, вот тут останется m, m-1 и так далее.
Какое m-k1 плюс 1, да? Вот так. Если я m факториал в знаменателе пишу, а в числителе
m-k1 факториал, вот у меня получается вот такая штука. Так, и тут надо сократить
наоборот. Вот эти два факториала. Что-то останется m-k1 и так далее.
m-2k1 плюс сколько? Плюс один или плюс три? Я сам туплю. Плюс один, да? Плюс три? А,
следующее плюс два, да, вроде правильно. Ну ладно, ладно, это на самом деле всё неважно.
Вы должны понимать, ну важно количество вот этих совмножителей. Только важно,
только количество этих совмножителей. Вы должны понимать, что k1 же у нас это 2 лог 2-ичный m.
Ну так он подбирался. 2 лог 2-ичный m. k1. Ну это вы можете посмотреть, просто в прошлый раз мы это
писали. Это 2 лог 2-ичный m. Поэтому всё, что стоит в знаменателе, например, всё, что стоит в знаменателе,
в асимптотике имеет вид m в степени количества совмножителей. Потому что k1 очень маленькая,
почти как константа. Ну можно расписать там в виде экспонента от суммы логарифмов, как мы много раз
делали, и убедиться в том, что k1 настолько маленькая, что всё хорошо. Нужно расписывать,
я распишу. Это довольно скучно, то есть это стандартная выкладка, на неё безумно не хочется
тратить время. Сколько тут совмножителей? k1 совмножителей, товарищ. А тут k1-2. Вот тут
то же самое. Тут будет асимптотика в степени k1-2. Ну и всё, получилось в квадрате в знаменателе,
это мы доказываем. Вот это вот, там квадрат в знаменателе. Нормально? Вот на таком уровне вы
должны владеть асимптотикой. Почему концентрируется вся вот эта сумма в t равном двойке? Почему огромное
количество других слагаемых не влияет? Я объяснять не буду. Ну ещё раз, вернее, если вы хотите, давайте я
объясню примерно, просто буквально в кратце. Не надо это будет делать на экзамене, потому что
это довольно мутрно, страшно, сложно. Да. Да, да. Это вот и есть нюк квадрат. Но ещё раз, давайте я
ещё раз напишу. Видимо, быстро говорил всё-таки для кого-то. Вот так вот. Мю, по определению, это
мата ожидания. Ой, мата ожидания, что вдруг написал так. Хк, ты первая. Мата ожидания просто числа
независимых множеств мощности k1. Да-да-да, м в кубе, мы уже это, оно сработало. Не важно, что эта
штука асимпатически равна м в кубе, но она просто по определению вот такая. Сразу-то она такая. При
этом да, k1 подобран так, чтобы она оказалась примерно м в кубе, и за счёт этого мы получили,
что вероятность подобрана корректно. Теперь мы про это забываем, нам сейчас это не нужно,
пользуемся исходной формулой, её сюда подставляем и получаем. Ну вот такая вот штука. А, я хотел
пояснить коротко, да, пояснить, почему концентрируется в t равном двойке. Смотрите, в чём тут
принципиальное отличие от истории с связанными компонентами, когда сумму можно было просто разбить
на две части. Если вы посмотрите t равное тройке, например, следующее слагаю, я не предлагаю это делать,
но просто слушайтесь, если вы его посмотрите, то оно действительно окажется сильно меньше, чем то,
что мы посчитали. Оно окажется бесконечно мало по сравнению со слагаемым при t равном двойке.
Также было и в сумме, которая про связанность. Помните? Если вы посмотрите t равное четвёрке,
я вас уверяю, оно тоже окажется бесконечно мало по сравнению с тем, что было при t равном тройке.
То есть это как бы бесконечная убывающая геометрическая прогрессия. С главным членом t равняется
двойке. А дальше t равно тройке во много раз меньше, t равно четвёрке ещё во много раз меньше,
чем t равно тройке. Но, к сожалению, этот процесс в какой-то момент раньше, чем вот такой, остановится.
И хуже того, хуже того, мало того, что оно остановится, слагаемые снова начнут расти. То есть
картина будет вот такая. Вот тут вот t равняется двойке. Оно как бы самое большое. Потом пошло ниже,
ниже, ниже, ниже. В какой-то момент достигла дна минимума и пошло выше. Но, понимаете,
мы умрём сейчас с вами вот это всё аккуратно считать. Я утверждаю, что когда оно дойдёт вот
до этого верхнего предела, да, оно будет выше, чем дно, но всё ещё сильно ниже, чем t равно двойке.
Вот это всё считать, мы умрём. А смысл вот такой. Ну и дальше там всё сходит к t равно двойке,
потому что всё остальное меньше. Но проблема в том, что вот оно одно время меньше, потом больше,
и вот из-за этого надо и тут считать, и вот это суммировать отдельно, и вот это суммировать
отдельно. Но неужели я такое буду спрашивать на экзамен? Кому это надо? Главное, чтобы вы смысл
понимали. Ну смысл-то понятен. Не надо, самой выкладки не надо. Главное, чтобы вы поняли,
как получилась теория. Суть стандартная, а вот уже там выкладки технические, но мы почти все сделаем.
Почти все. Уф! На этом огромная тема про хроматическое число случайного графа окончена. Поздравляю
вас с этим обстоятельством и даже могу устроить перерыв, потому что он почти подгрёб. Давайте
сделаем перерыв, правда, но главное, что сейчас будет другая тема совсем, а звонок через одну или
две минуты. Так, друзья, давайте продолжать. Так, скажите мне, пожалуйста, все-таки начались уже
линейно-алгебрагические методы или нет еще? Уже закончились, да, то есть, понимаете, вот я
просто должен выбрать темп, в котором это рассказывать. По идее, я должен рассказать аккуратно,
подробно все, но вот как это лучше делать? Это вопрос, который сейчас все-таки возникает,
потому что линейная алгебра это очень важно, это такой мощный метод, который позволяет работать
с гиперграфами. Но давайте я коротко скажу, что следующая большая тема, которая нас интересует,
может быть собрана под крышу гиперграфа. Гиперграф – это главный сарделичный объект. Если вот уж
говорить о том, где сардельки прямо естественным образом появляются, это гиперграф. Давайте я
коротко напомню, что гиперграф отличается от графа просто тем, что у него ребра не обязательно
состоят из двух вершин, а могут состоять из любого их количества. То есть, это по-прежнему пара,
которая есть вершины и ребра, В – это множество вершин, Е – множество ребра, только, товарищи,
потише. Я понимаю, что вы уже как бы это или этого вы не знаете. Слово гиперграф на семинарах
произносилось. Вот у кого-то нет, у кого-то да. Давайте я аккуратно скажу, гиперграф – это
практически то же самое, что граф. Отличие состоит только в том, что в ребре может быть
несколько вершин. В каждом ребре может быть не две вершины, а много. Я сейчас все скажу. Мы будем
рассматривать только гиперграфы, которые в каком-то смысле устроены как простые
графы или обыкновенные графы. То есть, нам не будет важен порядок вершин внутри ребра. Гиперграф
в нашем случае по определению не является ориентированным. Е – это под множество в два
в степени В. Не бывает кратных ребер. В этом смысле то, что я написал, тоже является корректной
записью. Не бывает кратных ребер. Так? Ну и нет ориентации. То есть, это под множество,
которое является в терминологии ОКТЧ – сочетание. Ребра – это сочетание. Сочетание вершин.
Почему это сарделичный объект? Ну, потому что если вершины традиционно обозначать,
не обозначать, а изображать точками на плоскости, то ребро – это что-то вот в таком духе. Ну, это
уж прямо сарделька-сарделька. Вот прям вот такая. Я вот все-таки так и не понял, почему на наклейке,
где я изображен на фоне такого круга из «Поля чудес», у меня в руках все-таки не сарделька,
а цукинь. Ну, не знаю, мне сказали, что сардельку отдельную не нашли, но это странное объяснение.
Но цукини, ладно, пусть цукини тоже похожи. Есть такая вот, знаете, кастрюлька, в которой варятся
сардельки. Вот так себе представляете вершины и рёбра. Гиперграф – плох, но они вот как пересекаются.
Ну, представьте себе, что они прозрачные, вот они друг на друге лежат, ну, пересекаются, да. То есть,
понимаете, вот относительный минус гиперграфа по отношению к графу состоит в том, что непонятно,
как его изображать. Ну, вот я изображаю такие сардельки и прямо в голове себе что-то такое
и представляю. Но есть люди, которые очень геометрически ориентированы и могут себе
представить многомерный симплекс. В этом случае, ну, я думаю, что вот, например, Аркадий Борисович
считает, что гиперграф – это симплециальный комплекс. И люди, которые любят топологию,
они вот так себе и будут это представлять. Но не любой симплециальный комплекс является гиперграфом,
для тех, кто знает, что такое симплециальный комплекс. Наоборот, не любой гиперграф является,
симплециальный комплекс, конечно, гиперграф, но не любой гиперграф является симплециальным
комплексом. Всё, это забыли, проехали. Так, друзья, вы поняли, что такой гиперграф просто по
определению. Значит, гиперграфы бывают, давайте я буду писать R однородными, чтобы не путать
обозначение. Гиперграф называется R однородным, если все его ребра имеют мощность R. Являются
R-сочетания, если все его ребра – R-сочетания. Ну, то есть, например, полный R-однородный гиперграф
на N вершинах имеет C из N по R ребер. В частности, два однородные гиперграфы. Два однородные
гиперграфы – это грав. Это просто обычный, обыкновенный грав. Это грав. Как правило,
товарищи, давайте считать, что у нас не бывает ребер из одной вершины. Нет, реброй из одной
вершины – это непонятно что. Просто реброй из одной вершины – это под множеством мощности 1. Это
не петля. Ну, нельзя, потому что петля – это все-таки пара совпадающих вершин. Петля, по определению,
это пара, состоящая из двух одинаковых вершин. Петля в гиперграфе – это, наверное, просто,
например, R одинаковых вершин. Но мы решили, что у нас никаких повторений не бывает. У нас только
сочетание, причем без повторений, в полном R-однородном гиперграфе C из N по R ребер.
Это сочетание без повторений, обычные цешки. Поэтому никаких петель у нас нет. Одновершинные
ребра, строго говоря, могли бы быть, но я решил, что мы не будем такую ситуацию рассматривать. Будем
считать, что R, например, больше либо равняется двойке, если мы имеем дело с R-однородными,
ну и еще как. Так, вот предметом обсуждения на оставшихся лекциях, ну две с половиной осталось
лекции, сегодня еще две. Значит, предметом обсуждения на этих лекциях будут несколько,
извините, экстремальных, но не по сложности, а по сути, по комбинаторной сути, экстремальных
величин, которые ассоциированы с однородными гиперграфами. Обсуждать хроматические числа
гиперграфов мы начали на первой лекции по КТЧ, потому что там речь шла про пяти-элементные
подмножества, 30-элементного множества, и вопрос как раз в том состоял, а можно так покрасить эти
30 элементов, чтобы каждое подмножество было не одноцветным? Это прямо в точности хроматическое
число 5-однородного гиперграфа. Мы это будем обсуждать, но в следующем семестре. Сейчас я хочу
обсуждать, ну иначе мы только раскрасками будем заниматься, а люди, которые в следующий семестр не
перейдут, вообще никакого кругозора не получат. Я имел в виду людей с ПМИ и информатика, товарищи,
а не тех, кого отчислят. Разница в том, что те, кого отчислят, не получат кругозора не только в
дискретном анализе. Они перейдут, но не в следующий семестр дискретного анализа.
Это тоже верно. Тут много правильных утверждений. Так, ну ладно, давайте что-нибудь успеем.
Значит, я сейчас напишу три величины. Начну с Саши. Так, это максимальная м, натуральная, такое,
что существует эрооднородный гиперграф на N вершинах. Причем такой, что для любых двух его
ребер не больше, чем С. Так, дорогие друзья, вот на самом деле, я приостановлюсь, у меня еще
будет две величины. Но вот это вот то, с чем мы имели дело буквально на прошлой лекции, на самом
деле. Это величина, которая характерна для кодов исправляющих ошибки. Мы хотим выбрать как можно
больше R элементных множеств в N элементном множестве, чтобы пересечение каждых двух из них не превосходило
за ДНВС. Это чистой воды код исправляющей ошибки. У нас есть N элементное множество, большое,
кастрюля. Мы хотим в эту кастрюлю запузырить как можно больше сарделек каждой мощности R и чтобы
каждые две пересекались не больше, чем по S. Это вот точности задачи про коды исправляющей ошибки.
А, я забыл, конечно, написать, да. Да, да, да, да, да. Ну, конечно, я забыл написать, что мощность
E равняется M. Ну, конечно. Что-нибудь я обязательно в этом месте забуду. Это максимальная мета,
кое-что существует. R однородный гиперграф, вот сюда это лучше писать, вот сюда. С N вершинами
и M ребрами. С N вершинами и M ребрами. Не-не-не, алфавит у нас состоит из нуля и единицы. То есть,
если интерпретировать это в терминах кодов исправляющих ошибки, то мы говорим о кодировании
нулями и единицами. Просто в этом случае вы вот эти множества интерпретируете как векторы из нуля
и единиц, состоящие из N координат. Вот если у вас есть какое-то множество, например, один, два,
три, то тогда соответствующий вектор это один, один, один, а дальше N минус три нолика. Вот это вот
интерпретация в терминах теории кодирования. Тогда утверждение о том, что каждые два множества
пересекаются не больше, чем по S, равносильно тому, что вот эти вот наборы единиц мало пересекаются.
То есть, расстояние между этими словами большое, скалярное произведение не больше, чем S,
да вот эти множества мало пересекаются, это означает, что расстояние между ними большое. И даже
если сильно покоцается слово, то вы будете понимать, что вы находитесь в шарике с центром в этом
слое и значит покоцалось именно оно. То есть, на выходе вы сможете восстановить информацию. Помните,
я про это рассказывал, слова далеко, даже если сильно покоцали, все равно не вышли за пределы
своего шара. Куда бы ни попали, на выходе точно знают, что это было вот это слово. Чем меньше вот
эти вот слова, вот эти множества A и B пересекаются, ребра, гиперграфа, чем меньше они пересекаются,
тем больше ошибок мы исправляем. Сейчас, друзья, нормальный вот этот темп, это я понятно объяснился?
Это все было, но просто надо вот как-то одно с другим ассоциировать. Так, вот те, у кого были
семинары про линейно-алгебранический метод, изучали вот такую величину. Все в точности то же
самое. Прямо в точности. Сильно-сильно, да. То же самое, максимальная М, такое, что существует
эрооднородный гиперграф с N-вершинами, M-ребрами. Единственное вот отличие, это что ребра пересекаются
не по малу, а то ли по малу, то ли по многу. Но только вот не по этому. Единственный запрет, ровно один запрет.
Только не бросай меня в этот перновый куст, там остальные, пожалуйста. Это вот как раз будет
сейчас линейно-алгебранический метод, который вы начали изучать на семинарах, потому что я
слишком долго говорил про раскраски. Вот так. Ну, вполне понятно, тоже симметричная штука.
Не-не-не, но вот это вот три классических таких ситуации, которые изучаются и в теории кодирования,
и в комбинаторике, и во многих других приложениях. Я традиционно в последние годы не успеваю
рассказывать применение к задачам комбинаторной геометрии. Там раскраска пространства, проблема
борсука. Ужасно хочется про это рассказать, непонятно когда. Вместо всего остального. Ну, в общем,
посмотрим. Да, друзья, посмотрим. Я с удовольствием прочитаю несколько факультативных лекций для
желающих, если у вас будут силы. Но заставлять всех учить больше, чем влезает в два семестра,
это уже какое-то издевательство. Но вот эти три величины мы должны изучить. Так, ну, поскольку
у вас уже начался линейно-алгебранический метод, может с МАТНРС начнем тогда? Значит, смотрите,
МАТНРС, она тоже допускает известную нам интерпретацию. Если H от НРС это классическая
задача о построении как можно более мощного кода, исправляющего заданное количество ошибок,
то МАТНРС это альфа от графа G от НРС, который у нас неоднократно встречался в разных контекстах.
Был у нас такой граф? Ну, дайте я напомню, что такое G от НРС. Это граф, это уже граф,
не гиперграф, ну, граф это частый случай гиперграфа, но понятно. Это уже граф, у которого вершины,
это вакурат под множество чисел от 1 до N, каждый из которых имеет мощность R. Соответственно,
рёбра – это пары под множество, мощность пересечения которых в точности равна S.
Самый стандартный наш пример, это когда вот тут 3, вот тут 1, и он был еще на ОКТЧ,
и там был как раз зачаток вот этого линейно-алгебрагического метода. Там был граф G от N3 и 1,
про который мы доказывали с помощью линейной алгебры, что его число независимости не больше
чем N. То есть мы уже знаем, что M от N3 и 1 не больше чем N, но и больше того я говорил,
чему оно равно. Оно равно N, если N делится на 4, N-1, если N сравнимо с единицей, и N-2 в двух оставших случаях.
Интересно, кто-нибудь хотя бы смутно припоминает, что такое было. А, даже в билете на экзамен. Это
хорошо. Вот это мы доказывали с помощью индукции, такая скучная индукция, а вот это обалденный
линейно-алгебрагический метод. Так, друзья, нужно напоминать обалденный метод? Ну, наверное нет,
иначе мы слишком много времени потратим на то, что знаем. Я лучше другой обалденный метод расскажу,
я обобщу. Ну, я так понимаю, что есть присутствующих, большинство уже знает,
потому что это началось на семинарах, но я должен как-то для общности это записать,
видимо, да? Или вы на самом деле сходу не скажете мне, как действовать? Подивите руки,
кто скажет, как действовать в общем случае? Лес рук. Ну, так, давайте действовать. Слушайте, друзья,
я стараюсь никуда не торопиться, мне хочется дать вам больше, но я хочу это сделать качественно,
чтобы все все четко поняли, могли записать для себя, потом воспроизвести, поэтому давайте
спокойно работать, никуда не торопясь. Все поняли, что м от nrs, вот такая гиперграфовая характеристика,
это альфа от вот этого же nrs. Такое вот, такое жонглирование понятия происходит. Так, ну,
когда работаем пока что с m, работаем пока что с m, вот давайте обсудим. Я считаю,
нужно обсудить сначала такую величину, чтобы максимально было понятно, что делается в общем
случае. Пять-два, да. Ну, то есть мы рассматриваем пяти-элементные под множество аналиментного
множества. Ребра это такие пятерки, пять сочетания. Сарделька состоит из пяти вершин каждой. При этом
мы им запрещаем иметь ровно две общих вершины. Вот можно одну, можно не одной, можно три-четыре,
но только не две. Две запрещено. Ну, тут еще сохранилось. Две запрещено. Казалось бы,
только один запрет. Вот давайте прежде всего подумаем, что проще. Как бы предъявить какую-нибудь
жирную конструкцию, в которой один запрет присутствует, и тем не менее, вот она жирная. Как бы придумать
побольше таких сарделек? Просто явную конструкцию. Как можно построить много множеств мощности 5 среди
N вершин? Как? Четыре элемента и один менять? Мне кажется, что три достаточно и два менять. Во,
смотрите, правильно. Мне кажется, что вот такая конструкция является вполне себе неплохой. Мы
фиксируем первые три числа и дальше из оставшихся N-3 выбираем любые две. C из N-3 по 2. Каждые два
таких множества, они имеют мощность 5, конечно, все. Каждые два таких множества пересекаются по
трем элементам или больше, по четырем, но точно не по двум. Заметьте, мы как бы даже меньше
использовали, чем могли. Нам разрешено еще по одному и по нулю, но в этой конструкции мы этого
не используем никак. Тем не менее, а симптатика этого числа это, конечно, N квадрат пополам.
Что? Не, ну это можно обобщить легко, но это мы потом обсудим. Понятно, что для MOTN 5.2 вот
такая нижняя оценка точно имеет место. Вот она симпатически ведет себя как N квадрат пополам,
и теорема, которая доказывается с помощью всего того же обалденного линейно-алгебрагического
метода. Я считаю, что это офигенно круто, то есть это надо прямо прочувствовать. Она утверждает,
что эта величина ограничена сверху кем-то, симптатика чего такая же. А именно мы сейчас
докажем, что это не больше, чем C из N по 2, но давайте я вот так напишу, плюс 2 C из N по 1.
Но это я сейчас докажу. Понятно, что асимпатически это тоже N квадрат пополам,
но это больше, конечно, чем C из N-3 по 2, но разница между нижней и верхней оценкой,
она порядка N. То есть главный член асимптотики найден, а остаточный он порядка N. Но это уже
следующий вопрос, конечно, как найти в точности. Я вас уверяю, что обычная комбинаторика без
привлечения линейно-алгебрагического подхода даже вот этого не дает. Вернее, получается безумный
перебор, от которого можно концы отдать. А тут будет очень красивое рассуждение, до которого
додуматься, но вот человечество додумалось. Короткий вопрос. Все присутствующие понимают,
что многочлены бывают от N-переменных. Бывают же от N-переменных многочлены? Я просто спрашиваю,
что? Все понимают, что многочлены бывают не только от одной, но от N-переменных тоже,
и что многочлены бывают не только над R, но над любым полем. Это важно. Давайте рассмотрим
любое множество ребер гиперграфа. Ну, давайте их как-нибудь вот так, например, обозначим. Это
ребра гиперграфа, который 5-однородный, и про который известно, что каждые два его ребра имеют
какое угодно пересечение, но только не два. Давайте я напишу. А ИТ, пересеченное сожитым,
не равняется двойке. Для любых R. Ну, рассмотрим любое. Он написал любое в виде кванта. Ну,
я согласен, но неужели непонятно? Любое, но надо было написать любое. Да, это читается для любого.
Хорошо. Я пошел навстречу пожеланиям трудящихся. Рассмотрим любое множество ребер вот с этим условием.
Так, товарищи, все, хватит, нас времени мало, я хочу успеть. Катарсис хочу. Вы хотите катарсис?
Значит, АИ тому сопоставляем вектор. Помните, как вектор сопоставляется из нулей единиц? Вот я
где-то здесь рисовал пример, вот так. Но там уже будет 5 единиц, а на минус 5 нулей. Ну, то есть,
мы знаем, что скалярное произведение каждых двух векторов не равняется двойке. Скалярное
произведение векторов это в точности мощность пересечения вот этих множеств. Это все понимают?
Скалярное произведение, мощность пересечения, суть одно и то же. Так, теперь строим по вектору
многочлен. П это полином, многочлен. Я скажу, какой, но давайте сперва скажем, что он находится в Z,
по 5, как же по 5, по 3. Неожиданно, по 3 Z. Вот, ну давайте Y1 и так далее Yn. То есть,
это многочлен от N переменных над полем вычетов по модулю 3. Ну, есть мнение, что тогда будет
путанец с обозначением триодических чисел. Бывают п-одические числа, их часто обозначают Zp. Чтобы
не путать, пишут фактор группу Z по 3Z, но это она и есть, вычеты по модулю 3. Что? Ну, хотите,
я напишу Z3. Ну ладно, все. Как вам нравится, так и пишите, но смысл, что это вычеты по модулю 3.
Вот такое вот пространство. Почему по модулю 3 вот это будет катарсис? Сейчас. Теперь я напишу,
как он определяется. Значит, определяется он в точке Y. Y со стрелочкой это вот набор этих
переменных. Y со стрелочкой это N-мерный вектор переменных Y1, Yn. Определяется он вот так. Это
xt скалярно умножить на Y, а тут будет то же самое xt скалярно умножить на Y, но минус 1.
Так, привожу пример, чтобы было понятно, просто трудно воспринимать без примера,
я хорошо понимаю. Вот представьте себе, например, что xt вот такой. Раз, два, три, четыре, пять. И
дальше пошли нули. Ну, то есть аито это просто один, два, три, четыре, пять. Не, ну может такое
случиться, что аито это просто первый пять чисел. Да, вероятность не равна нулю. Значит,
тогда xt будет вот таким, а pxt от Y. Это просто вот что. Это Y1 плюс Y2 плюс и так далее плюс Y5
умножить на все то же самое, и из этого вычитается единица. То есть это такой многочлен второй степени.
Ну, в данном случае как бы от пяти переменных, но понятно, что если бы аито было не таким,
а эти пять единиц стояли где-то в другом месте, но от пяти других переменных было. Поэтому реально
задействованы, конечно, все переменные в зависимости от того, какие у нас тут множество а1, аt. Вполне
могут покрыться все переменные. Так, сейчас понятно, как устроено многочлен, но на примере вроде видно.
То есть можно вообще просто сказать, если у вас есть множество какое-то вершин, например,
1, 2, 3, 4, 5, то здесь вот эти номера и возникнут. Номера вот этих перемен. Хорошо, да? Сейчас будет
еще лучше. Дорогие друзья, я вам сейчас предскажу катарсис, в чем он состоит,
а почему катарсис. Смотрите, друзья, сейчас вы все поймете. Если я эти скобки раскрою,
ну вот эти скобки раскрою, то какой очевидно базис нарисуется? Базис, порождающий все вот эти
многочлены. Ну из чего он будет состоять? Он будет состоять из вот таких вот штук, правильно?
yt в квадрате. Он будет состоять из вот таких вот штук, где i не равно j и в нем еще будут просто
y и t. Таких штук c и z по 2, таких c и z по 1, таких c и z по 1. То есть чего, товарищи, я хочу доказать.
Смотрите сюда и смотрите сюда. Я хочу доказать, что многочлены, которые мы сопоставили всем нашим
вот этим a1at, линейно независимы над z3. Если я сейчас докажу все, теориям доказана.
Вот это пока непонятно. Это будет следующий катарсис. На z3 это следующий. Но вы поняли,
да, в чем идея? Идея доказать, что сопоставленные нашим ребрам алгебронические объекты в твоем
пространстве линейно независимы значат их не больше, чем размерность этого пространства. Ну
базис-то там такой, значит размерность это вот то, что мы заявили. Все, кого-то проканало.
Сейчас, друзья, идея всем понятна, да? Ну круто же, да? Давайте ее реализуем, поймем, зачем я взял
именно z3. Это же был мой произвол, я могу коэффициенты где угодно рассматривать, хоть в R. Многочлен от этого не
поменяется. А вот я для чего-то еще доказываю линейную независимость над z3. Я не утверждаю,
что над z5 она есть. Вот над z3 она будет. Ну давайте писать c1 px1, так далее, плюс ct pxt равно нулю.
Друзья, я на всякий случай всегда в этом месте занудствую. Я прошу вас очень аккуратно с алгеброй,
вы понимаете, что вот этот 0 это не число, это многочлен нулевой в своем пространстве. Это все
понимают. А вот цииты это вычеты из z3. Вот мы так подобрали коэффициенты, что получился 0. Смотрите,
я очень аккуратно пишу. Это неравносильно тому, что сейчас появится, но из этого следует то,
что сейчас будет на доске. Именно следует. Следует, что для любого y, ну например, из 0,1 в n степени,
то есть когда координаты все равны нулям и единицам. Ух, c1 px1 от y, плюс и так далее,
плюс ct pxt от y. Но я все-таки пишу равно нулю. Но имеется в виду уже в z3. Чувствуете разницу,
да? То есть здесь складываются многочлены как формальные выражения, как формальные степенные
ряды, если хотите, с какими-то коэффициентами. И получается многочлен, у которого все коэффициенты
нулевые. Ну понятно, что если теперь вместо переменных подставить какие-то реальные чиселки,
например, нолики и единички, то как следствие будет 0 уже в числовом смысле этого слова. Но только
как следствие? Это, конечно, неравносильно одно другому. Нормально? Понятно, что я говорю?
Ну реально нам, конечно, нужно вот это. Но оно следует, конечно, из нашего предположения исходного.
Ну что ж, давайте возьмем в качестве y, ну, например, x1. Не важно. Возьмем x1. X1 он же из 0 единиц
по построению. Я понимаю. Так, допустим, что будет такое px1 от x1? Вот сюда подставляем вместо y
x1. Смотрим на определение. Это будет x1 на x1 и тут будет x1 на x1. Так, чему равен x1 на x1? 5. У нас же в каждом
векторе 5 единиц. Если вы его над самого себя умножаете, вы 5 получаете. Так, друзья, все понимают,
что 5. Так, значит, здесь получается 5 на 4. Чему это равно? Ну, 20, но оно же и 2, да? Потому что по модулю 3. Вот
тут уже становится важно, что по модулю 3 живет. По модулю 3 это равно 2, но главное, на самом деле,
что не равно 0. Вот это равно 2. Теперь, смотрите, подставляем px1 тот же самый x1, где и уже больше
либо равно 2. Подставляем туда же, в оставшуюся часть нашей суммы. Что здесь получается? Получается xt
на x1. Да, да, кроме 2. Да, да. xt на x1 минус 1. Какие вычеты-то возможны? Все кроме 2 и 5. Ну, кроме
2. Потому что пятерку мы отмели. Вот пятерка была тут. xt и x1 разные. Поэтому остается 0, 1, 3 и 4. 0. 1 тоже
дает 0. 3 тоже дает 0. 4 тоже дает 0. Это 0, товарищи, всегда в наших условиях. Мы запретили 2. 2 могла бы
дать снова вот такую же двойку, но ее нет по условию. У нас не бывает двойки. Вот условия. Вот она.
Двойки не бывает. А бывает что угодно, но только не двойка. И от 5 мы уже избавились, потому что 5
это когда они совпадают. Все, значит, остаются только такие вычеты, которые дают на этой форме 0.
У нас получается вот тут 0 сплошной, а тут 2. Какое отсюда следствие? c1 равняется 0 в z3. Ну, друзья,
ну все симметрично. Это я для примера подставил x1. Если я также подставлю x2, x3, у меня все остальные
окажутся нулевыми. Ну, то есть из предположения вот этого равенства следует, что все коэффициенты
нулевые. Ну, значит, многочлены независимы и таких действительно не больше, чем размерность пространства,
в котором они живут. Все, я доказал. Ну, согласитесь, это по сути в одну строчку. Ну, по сути, если
понимать, да, поля там что-то такое, это же в одну строчку. А пойди вот комбинаторно это докажи.
Вот такая вот удивительная вещь. Значит, в следующий раз я сформунирую, ну и как бы докажу,
наверное, общее утверждение. Сейчас я не успеваю уже. Вот, и еще некоторые его важные обобщения. А дальше
двинемся дальше. Там же у нас еще есть h, есть f. Вот такой план. На сегодня все.
