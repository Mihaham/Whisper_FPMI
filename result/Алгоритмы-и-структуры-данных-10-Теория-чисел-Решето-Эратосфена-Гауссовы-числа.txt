Лекции, три замечательные лекции будут посвящены теории чисел, все дело в том, что Филипп Рухович у вас заболел, попросил меня все это дело рассказать, ну точнее он это не планировал рассказать, у меня изначально просил рассказать вам алгоритм поиска дерево тандемных повторов за линейное время, где самая короткая статья, которую я нашел, была на 40 страниц. Вот, но я к сожалению отказался, потому что...
В том, что читать статьи я не люблю, вот, и просто мы с ним договорились, чтобы я рассказал вам всякую базу о теории чисел, ну такой устраивал ликбез, как бы олимпиадникам, которые бывшие, нормально будет, я думаю, потому что вы так все алгоритмы знаете, у вас будет изи устный экзамен, а остальным, ну ликбез получается, и все такое.
Ну давайте начнем с проверки на простоту.
За линию.
Одного числа, именно так. Ну проверка на простоту, естественно, чисел...
Я могу за линию минус 1.
От 1 до n.
Кстати, вот вы как пруфы вообще любите?
Филипп очень любит.
Вы не очень.
Лучше с пруфами.
Хорошо, ну тогда я запрофаю обычный, что за n-lock-lock.
Я думаю, кстати, вот не все умеют, ну типа...
У нас в школе было это, да, естественно, не факт, что я его помню.
Окей.
Ну хорошо, собственно, как это делается?
Ну делается достаточно просто, типа заводим какой-нибудь там вектор булов, там исправим, заполняем его изначально трушками и заполняем его краской размера n.
Ну и алгоритм состоит в том, что мы просто проходимся...
Ну мы как в школьном алгоритме, собственно, мы просто проходимся по всем числам от 2 до n.
И, типа, если у нас от числов встретилось непростое, то мы ничего не делаем.
А иначе мы пробегаемся по всем числам, которые кратны этому числу i.
Ну, то есть мы...
Можно начинать с 3 квадрата, но это такая себе оптимизация.
Тем более, если мы работаем в числах там до 10, 7, 10, 8, это, кажется, роли не особо играет.
Ну хотя давайте с i квадрата пробежимся, пофиг.
Можно это и пооценивать?
Оно одинаково оценивается.
Ну в плане отдельно почитать.
Ну окей.
Ну давайте тут буду считать, что с 2 i бегу.
Бегу по числам g кратным i.
И, типа, помещаю все числа, которые кратны i, как непростые.
Ну, собственно, на этом алгоритм закончился.
Самый-то веселый это оценка времени его работы.
Давайте это сделаем.
Соответственно, есть пруфа, которая полагается на то, что у вас k-то простое число примерно натуральный алгоритм от k.
K натуральный алгоритм от k.
Вот.
Но вы это умеете пруфать?
Да.
Ну мы доказывали, что...
Нет, ну мы не совсем это умеем пруфать.
Мы умеем пруфать, что среди первых n их от n делить на лог до 4n делить на лог.
От n делить на лог?
Ну хорошо.
Ну там чуть меньше, чем n делить на лог.
Ну окей.
Ну нам, на самом деле, понравится простая оценка.
Я, например, там легко выводил такую оценку, что это примерно k ln k, но лог 2-ичный k, поделить на 12.
Вот.
Ну в принципе, это пруфать можно очень просто.
Типа, если мы просто посмотрим на, соответственно, числа от n до 2n невключительно.
Ну и рассмотрим, например, какой-нибудь там...
Давайте от 2n включительно будет, а n невключительно.
Ну и посмотрим на какое-нибудь там выражение типа c с 2n по n.
Собственно, оно как минимум...
Хочешь пластула от беретрана?
Не, ну...
А нам пластула от беретрана не нужен.
То есть там есть первая часть пластула от беретраны, которая начинается с того, что простых чисел не слишком много.
И в принципе, она нам только и понадобится.
Вот.
Ну это типа произведение всех простых будет на этом отрезке.
Сама эта штука меньше, чем 4 в степени n.
Но произведение всех простых, оно, понятное дело, как минимум n в степени количества простых.
Соответственно, мы отсюда сразу получаем нужное неравенство.
Если все пролографмируем по основанию 2, тут получим 2n.
Тут получим k ln 2n.
Ну как-то так.
Собственно, мы получаем, что у нас простых чисел не больше, чем 2n поделить на ln 2n.
Вроде нигде не вру, да?
Похоже.
Похоже.
Окей.
Ну уже это так и доказывается.
Ну да.
Ну и типа дальше как бы proof к чему сводится.
В общих чертах, если.
Мы берем как бы наше число p-каты.
Смотрим, в какую она попала блок.
Ну и дальше у нас есть же не только этот блок.
Есть еще чисто раньше него.
Вот.
И тут можно их количество оценить получается сверху.
Если мы посмотрим блок от n по полам до n,
от n поделить на 4 до n и так далее.
То есть нам придется просуммировать какую-то такую сумму.
Ну собственно, давайте это сделаем.
Ну как сделаем?
Я накурекую, что там если сворачивается, вы мне очень сильно поверите.
Потому что там реально все делается школьными методами.
Типа.
Что?
Четыре.
Ну там не четыре выйдет.
Там у меня на шестерку оценка была.
Типа.
Потому что мы делим его чуть меньше.
Ну фиг знает.
Ну короче, надо понять, как примерно такая сумма сворачивается.
Тут у нас n это что?
Это у нас будет в степени двойки.
Соответственно у нас будет тут сумма 2 степени k плюс 1.
Поделить на, а давайте с единички бежать, лог 2k.
Окей.
Ну среди этих слагаемых есть максимальная.
Это 2 степени минус 1 на лог 2m.
Вот.
И в принципе там прав к чему сводится.
Он сводится к тому, что если мы как бы берем и рассматриваем другие слагаемые,
то у нас последняя слагаемая будет ровно эта слагаемая.
Следующая слагаемая, она как бы с одной стороны в два раза меньше,
а с другой чуть-чуть меньше знаменателя.
И вот короче можно показать, что оно будет...
Лог строгости.
Не, ну в смысле.
Я тут...
Не, в смысле.
Сея не равен спорам и жуточной вы сможете доказать.
Просто ну зачем вам это?
У нас соответственно последняя слагаемая будет 2 степени m минус 1 лог 2m.
Вообще без труб, чем с такими трубами.
Ну хорошо, давай докажем.
Хорошо, давайте прям честно-честно это докажем.
Я надеюсь код могу стереть?
Да.
Окей.
Давайте прям аккуратно это сделаем.
Соответственно, что тут?
Ну давайте только тогда не так и нарисую,
а нарисую, что мы прям смотрим на...
А, я намокрый, поэтому все плохо.
Давайте прям тогда степени двойки нарисую,
чтобы все было красивенько.
Типа вот наш ступэ,
оно попало в какой-то полинтервал
2 степени k, 2 степени k плюс 1.
Тут был какой-то интервал 2 степени k минус 1, ну и так далее.
Соответственно, нам надо начинать, естественно,
с единички, как помню.
Типа с два нулевой, да, два в первой включитель.
Окей.
Ну хотим просто оценить тут суммарное количество простых чисел,
но, видимо, они тут,
а вот тут, чтобы получить какое-то неравенство на вот это число.
Чтобы оценить снизу как 2 степени k, ну и что-то сделать.
Ну давайте посчитаем.
Типа чего у нас тут будет?
С 0 по k минус 1.
Кстати, вот лог 2k, мне кажется,
что-то двойку можно подставлять?
Тяжко.
Давайте здесь еще там выходит, кстати,
надо посмотреть поаккуратнее.
Типа у нас мы сюда логариф мы подставляем
от правой границы, да?
Или от левой?
У нас тут это 2n,
а, от левой границы, окей.
Ну тут у нас левая тут граница 0,
давайте это отдельно учтем, боксним.
Т с единички по...
Да, окей.
И то что будет?
Это количество как будет снизу оцениваться?
Это будет 2 степени удвоено тут.
И плюс первое поделить на И.
Вот такая вот сумма выйдет.
Ну потому что лог 2, типа он засунулся,
вот у меня получилось, осталось только И.
Ну и дальше, да, давайте посмотрим,
как это выглядит с самого начала.
У нас будет 2 степени...
Ну давайте для...
Потом как-нибудь поставим сюда k-1,
давайте это n сделаем,
чтобы все выглядело красиво.
Давайте, во-первых, все разделим на 2.
Такую сумму будет легче рассматривать.
У нас получается вот такая сумма,
на самом деле.
Окей.
Но давайте посмотрим на какое это слагаемое.
Может разделить на 4 и взять интеграл?
Да нет, зачем интегралы, господи?
До интегралов как бы...
Ну вы-то, возможно, доросли, я не очень.
Что нам надо сделать?
Оценка такая, мы хотим показать,
что 2 степени n-t поделить на n-t
поделить на 2 степени n поделить на n
не превышает 2 третей в степени n-t.
Ну давайте скажем, что при n больше равно 2, например.
Достаточно для соседних, кажется.
Ну можно для соседних, конечно,
но для соседних как ты это хочешь сделать?
Ну просто...
Сейчас 2 в третьей степени может быть просто t.
А, ну давайте по 2 степени n поделить на n.
Ты хочешь что сделать?
Ну поделить на 2 степени n-1 верить на n.
Давай сделаем это, окей.
Проверишь, что это, например, меньше чем 2 трети.
Ну давай, окей.
И потом все равно все как геометрически, соответственно, прогрессия.
Окей, давайте сделаем это.
То есть у нас тут получается 2,
поделенное на n, умноженное на n-1.
А сейчас кажется дичь какая-то.
Нет, так нельзя делать.
Не совсем 2 трети, но кажется вот отсюда надо скакать.
Кажется все-таки так надо делать.
Хотя, стоп.
Там одна вторая.
Там не 2, а одна вторая.
Сейчас нет, стоп.
Давай сделаем, окей.
Так.
Что-то кажется начало все подавиться.
Давайте, окей, раскроем тут.
Так.
n-t, n-t.
А, тут степени t, естественно.
Да, тут степени t надо.
Если t равно 0 поставить.
Окей, ну n равно 0 мы никогда в жизни сюда подставлять не будем.
t, да?
Если t равно 0, то должна быть единичка.
Окей.
Хорошо.
Давайте это сделаем.
Что тут будет?
2 степени t.
Тут t.
Оно ушло сюда, сократилось.
Да нет, какая-то дичь выходит.
Да, если t равно 1 поставить, то должно быть 2 трети тогда вырождаться.
А у нас по-моему поистине что нет.
Кажется я вас обманул.
Профов не будет.
Вот так.
А если на экзамене вы даже соваем?
Не, ну окей.
Сейчас.
Не, ну тут должен быть проф какой-то.
Сейчас, я это просто делал как раз перед коллекцией.
Прям готовился, жестко выводил.
Не, ну хочется просто взять первую половину членов оценить.
Как мы делим на n пополам.
А на вторую половину плюс-минус забить.
Давай сделаем, окей.
Теперь что ты хочешь?
Ты хочешь взять от i до от n пополам, да?
Примерно.
Да, n.
Что тут?
Это оценить снизу мы хотим.
Мы хотим снизу оценить.
Да, умножить просто на 2 будет.
Ну потому что мы делим на n пополам.
Ну окей, да.
Мы везде, сейчас.
Мы везде уменьшили знаменатель.
У нас значение увеличилось.
Нет, нам надо его наоборот увеличивать.
Нет, подожди.
Нет, мы хотим снизу оценить количество просто их.
А снизу оценить?
Или сейчас?
Если снизу, то можно...
Не, не, не, не, стоп.
Мы хотим сверху.
Нет, мы хотим сверху оценить.
Все-все-все, я убил немножко.
Мы сейчас вообще что?
А мы профаем обычный рэштурер с фена,
что он работает за iLogLog.
Вот, ну и типа собственно чем?
Мы воспользовались вот такой вот леммой,
что типа у нас от n до 2n вот столько вот,
не больше, чем столько простых чисел.
А дальше мы хотим запрофать,
что их в принципе, типа вот на таком префиксе,
не больше, чем вот какая-то константа поделить на iLog2n.
А зачем мы это делаем?
Ну в смысле, это у нас доказывалось не в другом курсе.
А, да?
Зачем мы это еще раз доказываем?
Ну ладно, окей.
Не, ну действительно тогда.
Не, ну можно довести тут уже что-то.
Ну окей.
Ну хорошо, я думаю да, можно сослаться.
Да, окей, соря.
Не, ну просто не знаешь,
что вы проходили в этом,
как бы большая проблема.
Ну я говорю, кажется, мы просто берем
деленное пополам у нас умножается на 2,
но зато все делится на n.
Сейчас.
А вот этот достаточек он...
Давай минус 1.
Да нет, там типа...
Нет, тут надо просто двумя этими штуками пользоваться.
Типа одна...
Двумя указателями?
Да, двумя указателями.
Двумя тряпками.
Метод двух тряпок.
Так и запишем.
Окей.
Ну хорошо, ладно.
Там какую-то ценечку вы сделали,
после этого у вас...
А что не так-то?
Конечно, хорошо.
Да ладно, что тебе не нравится?
Не, ну это правда, что у нас было много тачей.
Я говорю, что количество простых до n
не больше, чем 4...
4...
n деликанлоген, так?
Не, ну нам...
Ну хорошо, давайте просто представим,
что мы знаем,
какой-то нерайн, особенно на простое катое.
Но из этого, да, не следует.
Из этого, наверное, не следует.
Нет, следует.
Можно типа его оценить, типа, снизу,
и радоваться жизни как-то.
Вопрос.
Вот мы не можем очень прям в тупую...
типа мы знаем сколько на таком отрезке,
потом добавить сколько на вот таком отрезке,
который граничит с этим, но...
А вот мы только что попытались это сделать,
но не получилось немножко.
Почти получилось.
А нет, а нет, стой.
Не, ну хорошо, окей.
Ну хорошо, окей.
Давай, типа, сравним все-таки, да?
Окей.
Мне кажется, все бы получилось, действительно.
Не, вот этот раз, типа...
Типа давайте поскажем, что 2...
А, сейчас, нам же вот эту штуку,
снизу надо оценивать.
Нам надо не вот эту штуку,
а вот такую, да, все получится.
Не забиваем на логрифы, мы складываем эти карты.
Вот, типа у нас что тут получится?
Мы просто типа 2 степени n-1,
типа оно тут...
Получилась 1 вторая, как раз таки,
у нас вышло.
Тут n-1 на n.
Да.
Ну и давайте заметим,
что при n больше либо равным 5.
Так.
Да, ну в смысле,
ну мы все для больших чисел, да?
При достаточно больших n,
ну это типа штука,
ну, например, меньше, чем 5 четвертых.
5 восьмых.
А, 5 восьмых.
Да.
Ну и все, как бы.
Мы показали, что этот ряд,
типа он у нас, соответственно,
убывает как прогрессия геометрическая.
Ну тогда он суммируется
примерно как старший член,
умноженный на какую-то константу.
Вот.
Ну исходя из этого уже,
мы типа знаем, что вот у нас есть
какое-то простое число.
Давайте дальше без конкретных чисел.
Мы асимптотики будем рассматривать,
типа посмотрим на ПКТ,
на ПКТ число.
Пускай, типа оно...
Ну и поместим его в какой-то,
типа, собственно, блок.
Чисел от 0 до n.
Вот тут.
И сейчас надо сделать аккуратную оценочку.
Пускай вот перед ним было n-чисел.
То есть тут у нас,
соответственно, не меньше, чем...
Тут, соответственно, давайте представим,
что у нас камень...
Хорошо, давайте посмотрим на отрезок,
который содержит это число.
Тут нам, как уже известно,
чисел будет не больше...
Соответственно, кау у нас будет не больше
либо равно, чем 2 ПКТ.
Вы вроде оценку снизу хотели, да?
Да.
Ну, собственно, сейчас у нас
на ПКТ и возникнет оценка.
На лог 2 ПКТ.
Соответственно, ПКТ...
Ну, тут только не двойка будет.
Тут будет побольше, на самом деле.
Я когда сворачивал, у меня получалась тут шестерка.
Вот.
Ну, это совершенно не принципиально.
Типа, соответственно, ПКТ у нас будет больше
либо равно, чем 6, 1 шестая, k, лог 2 ПК.
Ну, давайте заметим, что, например,
у нас катое простое число точно больше
либо равно, чем k.
Ну, и получаем, соответственно, оценочку,
типа, что оно как минимум вот столько.
Окей?
Окей.
Хорошо, теперь давайте наконец
с помощью вот такого вот пререквизита
докажем то, что у нас линейный рестор
работает за n лог лог n.
Соответственно...
А как это делается?
Ну, тут уже, наверное, без интегралов не обойтись.
Что?
Как-то мы это в школе нормально делали.
Да нет, в смысле, я нормально сделал,
просто запутался посередине.
Там восстановится.
Вот, собственно, за сколько это работает?
Ну, соответственно, когда мы просеиваем
по первому простому числу, мы, типа,
делаем n поделить на P1.
Действие, ну, округленное вниз,
ну, давайте, типа, это от 1,
на него забьем, в принципе.
У нас, типа, оно не страшно.
Потом, типа, у нас будет n поделить на P2.
Ну, и так далее.
Мы дошли до какого-то максимально большого,
максимально большого простого числа,
до которого мы дошли.
Ну, пускай такая была.
Соответственно, сейчас я k не фиксирую.
Типа оно может быть как примерно
Pk t равно от корни n примерно,
так примерно, и линия может быть.
Мы потом, в принципе, посмотрим, что выходит.
Вот, соответственно, давайте эту штуку
еще сверху оценим.
Соответственно, мы знаем, что P1 каждая,
оно снизу оценивается вот так.
Поэтому получаем вот такую вот забавную
сумму.
Эта линия, давайте на нее забьем.
А, нет, P1 нормально.
Ну хорошо.
Давайте на P1 все равно забьем.
Что-то мне не нравится.
И получим, типа, сумму n поделить на...
Соответственно, на шестерку мы забиваем.
У нас остается, типа, сумма примерно такая.
ln2, плюс так далее, плюс nklnk.
Вот.
Ну и дальше, типа, на семинарах по матанальзу
вы, скорее всего, доказывали, что эта штука,
как раз таки, выглядит как...
Ну, соответственно, n мы можем вынести из этой суммы,
а эта штука, она сверху растет как lnlnk.
Было же у вас это, да?
Окей.
Я не верю, что в таком виде было, но...
Ну, можно проинтегрировать в любом случае.
Хотя нет.
Интегрирование-то нормально будет?
Ну, хорошо, можно...
Что конкретно такое?
Ну, доказать, что эта сумма просто,
у меня сверху оценивается как...
Ну, понятно, n сопрощаем.
Да, соответственно, ну, как это можно, типа, доказать?
Ну, типа, как бы там сумму монотонно убывающую
можно оценить интегралом всегда, вот, нотация.
Вот, ну, интеграла считать не очень хорошо,
но можно просто попытаться вот это продиференцировать.
То есть нам нужно интеграл от 1 делить на x log x.
Да.
Вот.
Ну, мы уже знаем результат заранее,
так что можно это просто продиференцировать,
убедиться, что тут краски выйдет то, что надо.
Ну, а что не так-то?
Мне кажется, что все так.
Нет, ну, в смысле, давайте продиференцируем,
типа, получится как раз, типа, у нас еще
1 поделить на lnk умножить на производную внутреннюю функцию.
Ну, это, типа, вот, как раз получили то, что надо.
Окей.
Хорошо.
Ну, давайте теперь посмотрим, что будет при различных k.
Вот, пускай мы pk-ты выбирали так,
что pk-ты у нас доходила до корня n.
Ну, тогда k это у нас примерно что?
Ну, давайте не раньше фигнем фигли.
Еще раз.
Почему бы и нет?
k это у нас pk-ты.
У нас больше, чем 1.6.
Ну, ладно, пофиг, напишем.
k log2k, да?
Ну, давайте точно скажем, что это меньше 1.6k.
Ну, понятно, что log2k, типа, ну, можно пренебречь,
типа, оно там у нас под логарифом.
Да, еще раз, типа, ну, вообще никак не повлияется,
скорее всего, то, что мы его убрали.
Ну, и как бы все мы получили, что k у нас примерно 6 корня n будет.
Ну, типа, оценивать сверху как 6 корня n.
Типа, ну, у нас ln корня n, да?
А то давайте заметим, что если бы у нас тут просто было n,
то у нас бы получилось синтетически то же самое.
Вот.
И тут даже, типа, рост не в константу, а на константу n.
Ну, коэффициент при n прибавляется на константу,
потому что, типа, у нас еще раз логарифм берется.
То есть оптимитация, как бы, синтетически такая и себе.
Вот.
Но, тем не менее, про линейный рашто еще можно,
ну, про обычный рашто можно еще кое-что сказать.
На самом деле, хоть тут оно и работает,
но это вот это такое синтетику.
Ну, lnk растет очень медленно.
И, как бы, это считайте почти бесплатная линия.
Ну, и как раз из-за этого возникают всякие эффекты,
что константные, ну, как бы, линейные у нас слагаемые,
о которых мы в онотации не учитывали,
они у нас могут иметь гораздо большее значение,
вот, чем вот это слагаемое.
Поэтому, соответственно, существует множество алгоритмов,
которые делают все возможные оптимизации,
упаковывают как-то наш числ от 0 до n,
так, чтобы алгоритм работал быстрее, быстрее, быстрее,
и там люди добиваются каких-то больших цифр,
маленьких, точнее, цифр.
Большая производительность влечет маленькое время работы,
как говорится.
Соответственно, вот.
Так что тема достаточно интересная,
но мы, естественно, тут занимаемся теоретической фигней,
поэтому на этом останавливаться не будем.
Называть это теоретической фигней довольно самонадеянно.
Нет, в смысле, так практически ты просто берешь
и понимаешь, что у тебя оценка...
Не, ну, напомнили.
Ну, как бы, что, ну, по крайней мере,
типа вспомнили, да, школьную программу,
как там количество просто чисел оценивать, все такое.
Хотя я не знаю, но мы школьный пример явно не доказывали.
Мы там квадратное уравнение кое-как умели решать.
В среднем по больнице.
Не, ну, квадратное уравнение мы, кстати,
сегодня тоже будем учиться решать.
Чуть позже.
Так что будет забавно.
Так, ну давайте теперь к чему-то нормальному пройдем,
типа за алгоритму, за ОАТН.
Линейная Решетограэса Мисра.
Я его не уважаю.
Не, ну, как бы, алгоритм достаточно постой,
типа я не знаю, зачем именовать его, это как не знаю.
СНМ называть именем алгоритмом там не знаешь,
какой-нибудь Шеховцово, что-то такое.
Странная фигня.
Ну окей.
Как работает линейная Решетограэса?
Давайте заметим, что мы когда просевали в обычном Решете числа,
мы некоторые числа удаляли по несколько раз.
Ну и как раз-таки у нас,
из-за того, что у нас простые числа,
они не так быстро растут, как хотелось бы,
у нас получалось так, что в среднем мы каждое число
зачеркивали ЛН на ЛН ОТН раз.
Вообще, основываясь на каких-то там простых ретензических действий,
можно типа так же доказать, что у нас в принципе количество простых делителей
с учетом даже кратности будет тоже равняться ЛН ЛНН.
Но это упражнение такое читательное небольшое.
Ну, как бы это медленно.
Среднее количество делителей у числа?
Простых.
Или максимально?
В среднем от одного до Н.
Ну окей, О от Н.
Ну, я имею в виду, что если мы берем случайное число,
у него примерно столько.
Да, да.
Простых делителей с учетом кратности.
А оценка на максимальное количество простых делителей?
Ой, на максимальное количество простых делителей?
А смысл?
Ну это с учетом кратности?
Не-не-не.
А, ну это ты про prime-логарифм, да?
Ну типа.
Ну давайте так, для алгоритмов нам понадобится,
что он растет очень медленно.
И на практических тестах типа не вращает 40.
А на практических местах он растет все еще быстро,
потому что там простые очень маленькие.
Ну то есть он растет же, по-моему, медленнее, чем алгоритм в любой степени, вроде бы.
Ну, типа такой, да.
Практически, точка зрения, ну там, не знаю, алгоритм пополам.
Ну окей.
Не, ну там, да, естественно, все сводится к тому,
что вы просто, типа, там, их произведение просто смотрите,
вот по этой оценочке, типа KLNK, и смотрите, как она растет,
естественно, так же оно будет, типа, расти.
Ну окей.
Ну я не думаю, что это прям сильно интересно.
Там понятно, что LNLN, типа, это какая-то дичь,
которая ни на что не влияет.
Хорошо.
Давайте проверка на постуду для числа от 1 до N.
Собственно, проблема линейного расчета в том,
что мы зачеркивали числа по много раз некоторые.
В среднем LNLNN.
Давайте зачеркивать их не более, чем по одному разу.
Ну как это делается?
Капец, у меня руки чмазые.
Ну ладно, пофиг уже.
Короче.
Как мы будем зачеркивать числа?
У нас у каждого числа, на самом деле,
оно, на самом деле, как-то раскладывается на простые.
Так вот, среди этих простых,
однозначно, можно определить
минимальный простой делитель.
Стой, делитель.
Стоит.
Стоит.
Стоит.
Стоит.
Стоит, делитель.
Как, собственно, этим можно воспользоваться?
Ну давайте мы будем бежать по линейному расчету.
Опять-таки от чисел от 2 до N.
Соответственно, мы будем также
хранить массив помеченных, типа,
чисел простой или непростой.
Давайте теперь его хранить с большей информацией.
Давайте для каждого числа хранить минимальный простой делитель.
Вектор int.
Какой-нибудь minP.
Ну и давайте, типа,
если у нас простых делителей еще не найдено,
мы туда будем записывать нолик.
Соответственно,
если мы не нашли простой делитель,
для какого-то числа i,
то это значит, что оно само простое.
И давайте его pushback-нем
вектора простых чисел p.
p, p, p, i.
Окей.
И установим значение minP тут как равное i.
Окей.
Как теперь мы будем проставлять числа?
Ну давайте
попытаемся домложить
наше число i
на все простые числа,
которые меньше, чем minPi.
То есть вне зависимости от того,
исходно оно было простым или нет.
То есть мы пробежимся, условно,
по g in P
и там если g меньше
либо равно, чем minP,
то мы, соответственно,
пометим в нашем линейном решете
число minPi умножить на g.
И у него минимальный делитель,
соответственно, тоже будет равняться g.
Ну иначе сделаем брейк,
потому что у нас векторы,
они все pushback-и в предке возрастания.
Соответственно, если у нас когда-то g
и на g превысило
требуемое значение,
ну давайте тут еще int end
i умножить на g меньше
либо равно n.
Соответственно, да, если у нас
оба ограничения делают
ограничение g сверху, поэтому если в какой-то момент
она нарушилась, то дальше g будет только больше
и мы можем сделать, в принципе, брейк.
Вот утверждается, что вот этот алгоритм
как раз-таки работает за линейное время.
Ну как это делается?
Как это доказывается?
Ну давайте, во-первых,
докажем, что
любое число оно будет помечено.
Ну это будем делать по индукции.
Почему бы и нет?
Вот у нас есть число n.
Все остальные у нас корректно размещены,
все простые корректно найдены.
У нас может быть два варианта, либо n простое,
но тогда мы тут, очевидно,
его никак не задели,
потому что тут у нас и ножи рассматривались только составные.
Хорошо, тогда все будет OK.
Мы его добавим в Prime,
в MinP правильно установим, все будет хорошо.
Напускай n составное тогда.
Но опять-таки у него есть
минимальный простой делитель.
То есть n равняется P
на n поделить на P.
Но давайте заметим, что когда мы
посещали тут
в цикле i равно n поделить на P,
то у нас, очевидно,
выполняется неравенство, что
минимальный простой делитель n поделить на P
больше либо равен, чем P.
Потому что мы тут либо
от минимального простого делителя избавились
и убили его совсем, либо он остался в какой-то кратности.
Может быть два случая.
Я думаю, что в этом циклике
мы как раз и наши числа корректно пометим.
Окей.
Вот более того, утверждение более сильное,
что каждое число помещено не более чем один раз.
Как доказывается, мы могли пометить только
по минимальному простому. Конец.
Соответственно, вот это и что.
Оно уже работает за O от n.
Но потребление памяти у него
пока что плохое.
Оно как бы линейное.
И казалось бы O от n и O от n, но на самом деле
мы скорее всего будем
работать с большими числами, поэтому хочется
как-то оптимизировать это все дело.
Оптимизировать с самым простым методом
можно так. Мы можем, во-первых, MinP
хранить не VectorInt.
Ну, например, да.
Давай первую
такую оптимизацию сделаем.
Давайте заметим, что нам не нужны
VectorIntP, числа больше, чем Coordinate.
Внутри?
Внутри Vector нам не надо pushback эти числа.
Вообще никак.
Почему это так происходит?
Ну, потому что, когда мы обновляемся,
давайте это сделаем.
Вот мы обновились тут через g на i.
У нас i как бы оно меньше,
чем минимальный просто делитель i, значит, соответственно,
меньше либо равно, чем i. А эта штука
меньше либо равна n. Значит, g нас интересует,
только которые меньше либо равны корня n.
От первой оптимизации,
соответственно, этот вектор у нас был
линейного, ну, n поделить на log n размера.
А теперь он у нас стал
от корня...
Почему ты оптимизируешь Vector простых?
Потому что
с помощью этого я сейчас могу оптимизировать
VectorIntP. В плане VectorIntP
очевидно, занимает линейную память,
а Vector простых линейно делить на log,
а очевидно, на него кофе.
Ну, я хочу сейчас делать аккуратную оценочку,
чтобы в MinP минимально возможный тип уложить.
То есть, соответственно,
смотри, у нас если простых будет много,
ну, например, все-таки даже
если n поделить на l, да,
мне все равно тут понадобится int, скорее всего.
Если я рассматриваю число до миллиарда,
мне тут, скорее всего, понадобится int.
И я не смогу оптимизировать.
Все еще short.
Ну, в плане short это 65 тысяч.
Сколько это?
И в квадрате он больше.
А сколько, типа, чисел простых до миллиарда?
Примерно. Ты помнишь оценку?
Ну, не оценку, а...
В миллиарде, видно, log?
Ну, нет, это, конечно, хорошо, да,
но я разделю, типа, ну, там, не знаю,
на ln 10, там,
на 9, да, ln 10, типа, оно,
что там, ну, примерно двоечек, да, ну, в 20, окей.
Но получается 10 восьмой
поделить на 2, 5
на 10 седьмой, ну, кажется, это в short
не укладывается.
В плане внутри min p
у тебя либо
у тебя внутри min p либо само число
простое, либо его минимальный простой
делитель меньше, чем корень из него.
Че?
Ну, минимальный простой делитель s,
либо само это число, либо оно меньше, чем корень
из этого числа.
Значит, я могу либо хранить отдельно, что
это само число, ноль, например.
А, окей, окей, окей, я понял,
ты хочешь, соответственно, хранить,
тут получается само число p, да?
А я хочу сейчас предложить просто индекс
простого числа хранить, ничего более.
Ну, индекс все еще будет
short, потому что...
Ну, вот, типа...
Ну, он чуть поменьше,
да, да, да, но он чуть поменьше будет все-таки.
Поэтому хочется...
Окей, ну, хорошо,
вектор primes, окей,
мы как-то соптимизировали, например, да,
кто-то говорит, что это не очень хорошая оптимизация,
дальше, да, обсуждение провело к тому,
что мы можем min p
попытаться использовать там
не int 32t, а, например, int 16t,
например, и
хранить там, соответственно, что?
Ты в min p хранишь индекс
простого? Да.
Тогда у тебя просто неверный переход,
да, нет, в смысле, вот, смотри,
вот тут я храню простое число, но я же говорю
устно как-то оптимизировать, я что, буду пояснять
каждую строчечку кода, как ее менять, чтобы
был нормальный алгоритм?
Нет, в смысле, ну, типа, тут можно, да, типа, первый вариант,
да, есть за ifat просто, если у нас
min p равно i, то ifat это случаем
ну, давайте как-то
минимальный делитель
n, неравный
можно ifat, типа, это либо ноликом,
как Миша предложил,
вот, ну, и тогда, типа,
у нас p, он не будет превышать корня n,
ну, соответственно, нам, чтобы
это число уместить, понадобится не более, чем
там 10 четвертый на корень из 10,
что влезает в int 16, да?
Ладно, я понял, зачем. Вот.
Либо мы можем
делать то же самое, но при этом
заметить, что у нас простые числа, типа,
их мало до корня n, и хранить
вместо, типа, самого числа его номер.
У нас это особо сильно не замедлит код,
потому что тут мы, ну, что такое
пробежаться по массиву p, да, это на самом деле просто
взять индекс какой-то
и его перебирать
от нуля до размера массива p, да?
Соответственно, нам придется просто этот индекс
сравнивать с нашим значением n, так что там
особо по кишу хуже не станет,
но при этом мы сможем
все еще для больших n хранить
наши значения в шарте.
Типа, вторая оптимизация,
типа, вместо числа
простого, вместо простого делителя
хранить
номер простого.
То есть тогда будет, типа,
количество простых до корня n,
то есть корня n делить на ладарифе корня n.
Да-да-да, тогда у нас максимальное значение будет
типа n поделить на lnn, примерно, да?
Вот, ну и тут
можно еще чутка для больших n
попытаться упихать это в n16d.
Вот, при этом, типа, не используя никакие там структуры
данных жесткие, типа,
хранить это все как-то в битах,
да, аккуратно выделяя по минимальному количеству.
В лонг-лонге 5 штук.
Вот. Ну, как-то так.
Вот, примерно такой алгоритм,
примерно так он оптимизируется.
Ну, самое главное, что этот алгоритм
линейный. Вообще, типа, есть алгоритмы более
сложные. Например, там
Риштоаткино, оно вроде работает за
n поделить на ln, lnn
по их обещания.
Делить.
Но, типа, соответственно, у них,
нет, у них, типа, есть действительно создание массива,
да?
Как бы они его не учитывают в
линейном. Ну, вот, Риштоаткино,
представим, что тебе сверху он пришел с единичками,
да? А дальше действие, типа, они делают реально вот столько в нем.
Он основан
на том, что есть некоторые квадратичные
формы, и там для простых чисел
выполняются какие-то крутые свойства.
Мы это
делать не будем, потому что
я не очень хорошо
знаю теорию чисел и квадратичные формы, не очень
хорошо изучал.
Поэтому тут это все рассказывать не буду,
но, соответственно, наука как бы дальше идет,
там есть, и все круто.
Ну, и давайте наконец
последнюю модификацию Риштоа посмотрим.
Это Риштоа для больших чисел.
Пускай, типа, у нас такая
издачка стоит, мы смотрим на,
и, кстати, мы его оценим как раз таки.
Нам понадобится вот эта оценка, что
простых делителей даже с учетом кратности,
я это доказывать не буду, сами докажете,
оно доказывается так же абсолютно.
Простых делителей с учетом кратности
у нас
в среднем
по больнице
не больше, чем
ln, ln, n.
Хорошо, как
оно у нас выглядит?
Как поставлять издачку? Настя, есть какой-то отрезок
чисел l, r?
Ну, r, например, не включительно.
И мы хотим среди них
найти все простые, или
найти разложение всех этих чисел на множество.
А как можно поступать?
Давайте заметим, что если какое-то
число отсюда не простое, то у него есть делитель меньше
корни r. Давайте первым шагом
просто посчитаем простые,
а меньше корни
из r.
Дальше мы хотим
просто взять по этим всем
простым просеть. Алгоритм максимально глупый,
тут не надо ничего себе придумывать,
что-то сложно будет и так далее.
Мы просто берем очередное
простое число,
и тут по всем кратным
пробегаемся. Но делаем это, естественно,
для каждого по отдельности. Берем простое число p,
смотрим минимальное, которое на него делится,
это можно сделать с помощью формул,
типа там остатки, все такое, да, и пробежаться
по этой штуке.
Вот, оказывается,
то есть тут главный вопрос,
а за сколько это работает?
Это все еще r-l.
Это у нас, ну вот оказывается,
что это работает у нас за r-l
плюс корень r
умножить на ln,
ln, r.
Вот, оказывается, что вот эта оценочка,
она работает даже для каких-то больших
вот таких отрезков.
Наш алгоритм никак
не меняется из заздвига.
Да, он никак не меняется
из заздвига, но тут
вопрос
в чем?
Вопрос в том, почему тут
умножить ln, ln, r? Вдруг у нас
такая ситуация возникла, что тут простые,
мы выбрали такой отрезочек r,
что у нас тут простых дофигища,
да, простых делителей,
ну типа больше, чем в среднем, а такое может быть.
Вот оказывается,
что такого не происходит.
Нам же интересует именно,
но в плане
тут, соответственно,
поэтому тут такая оценочка.
Вот там вот так прыгали?
Здесь мы прыгаем ровно,
только начинаем не соединиться с l.
Ну вот,
а почему у тебя все равно
все так хорошо?
Ну вдруг?
Единичка от каждого простого.
Давайте
посчитаем просто, да.
Давайте посчитаем, там все будет хорошо.
Для каждого простого, по сути, надо просуммировать
r поделить на p
минус l поделить на p.
Давайте просто посчитаем, не будем обсуждать это.
Факт простой,
но все-таки, мне кажется, надо проделать,
он такой аккуратненький, тут хорошо выходит.
Я хочу написать, что это
r-l поделить на p, плюс
да, я так же хочу сделать,
именно так это делается.
О большой, оно в сумме сколько выйдет?
Давайте qr выйдет,
фиг с ним.
И тут, соответственно, просто
r-l поделить на p.
И вот у нас
дальше сумма по простым p,
и дальше мы знаем уже, как она сворачивается.
Ну и еще,
для того, чтобы посчитать посты на
первом отрезке qr,
мы воспользовались тоже линейным решетом.
И у нас поэтому
асимптотика такая, алгоритма
такая асимптотика получилась.
Следовательно, если там считать
в среднем на этом отрезке
количество делителей
с счетом кратности, но если мы, например,
хотим для каждого числа тут посмотреть его факторизацию,
то оказывается, что
тут оценка времени работает точно такая же,
но в чем дело? Но дело в том, что
у нас вот эта вся сумма
r поделить на p,
минус l поделить на p,
а тут надо еще добавить k-ты степени,
то есть мы прибираем просто число и k-ты степени.
Вот оно у нас как раз таки
будет равно.
Давайте поставим, что у нас
p фиксировано, мы прибираем k.
Опять-таки у нас от каждого слага
будет от 1,
то есть давайте
сверху асимп просто как 1
прибавили, да?
r-l поделить на p вкатый
плюс 1 поделить
на p вкатый.
Вот, но каждая такая сумма
оценивается сверху не более чем 2,
поэтому у нас все еще линия выйдет
r-l,
а каждая такая сумма
в целом, да, она тоже оценивается,
но тут надо чуть-чуть постороже это сделать,
как p и давайте умножить на 2.
Вот уже так оценивается.
Ну как-то так.
То есть верен еще и более сильный факт,
что если мы просто хотим факторизовать,
то мы делаем тот же самый алгоритм, он работает
на той же самой симптотику.
Ну ладно, я понял, в чем могла быть проблема действительно.
Вот. Привет!
Давно не виделись.
Это правда.
Вот, ну как-то так.
Хорошо.
Так, а сколько сейчас времени?
Я хочу посмотреть,
сколько я на это все потратил времени уже.
О, 40 минут мы общаемся на тему
линейных решет всяких.
Ну ладно.
Соответственно,
сейчас,
что будет примерно происходить, давайте объявлю.
Вот мы рассмотрели линейные
решето, научились искать простые.
Сейчас мне Филипп еще попросил
очень настоятельно рассказать вам расширенный алгоритм
невклида.
Ну я его расскажу
для многочленов, почему он работает
от nm, нормальная версия алгоритма,
которая всегда можно написать.
Ну как бы...
Как по модуле ты пишешь.
Ну короче, можно написать алгоритм невклида.
Как ты? Ну да, это правда.
Да нет, в смысле, просто алгоритм
невклида можно просто реально написать
нормальную реализацию, и она будет работать
типа быстро, клево, качественно, всегда
бесплатно. И будет выдавать маленькие
решения краски, а если точнее минимальные.
Ты точно не хочешь сменить паркер или что-то?
Да, давай сменю, наверное, все-таки.
Ой, блин.
Ну смотри, просто я там давно
не работал с реальными досками.
Которые так физически
существуют в этом мире.
Подожди, а у вас занятие full online?
В смысле, так вышки не я занятия веду.
Не, в плане
теньков поколений.
А, теньков поколений? А там электронная доска.
Типа там... С этим есть свои
проблемы, что приходится как-то ее заставлять
зумиться, перемещаться, она думает, что
ты хочешь на ней порисовать, но в принципе
зато руки не пачкаются.
Ну я с детства такой чумазый.
У меня нормально. Окей.
Ну давайте просто напомню.
Нарисую схему, как пишется
algorithm.evglide. Это будет коротко, просто напомню.
Ну и потом без пруфов покажу, что он
работает круто, потому что у вас это было на теории
чисел. Зачем мне пафать второй раз?
Расширенные algorithm.evglide,
разумеется. Ну вот пусканность была по-арабы.
Как у нас algorithm.evglide работает?
Давайте больше, вычтем меньше.
Ну хорошо, давайте это все сэкономим, и сразу
его возьмем остаточек. Большего
по модулю меньшего.
Ну окей, произошло что-то просто замечательное.
И мы, если будем дальше делать, получим
пару G0.
Окей, как отсюда
выделить решение AX плюс BY
равно AG?
Метод очень простой, давайте заметим, что
что у нас было на первой итрации? У нас было AB,
потом, например, мы вычли A минус
B, B, потом мы, например, вот так
наоборот вычли, 2B минус
A, получили A минус B. Типа, идея основная
в том, что мы каждый раз вот будем получать
числа вида AX1 плюс
BY1,
AX2 плюс BY2.
Соответственно, мы знаем,
что мы куда прибавляем с какими
коэффициентами, поэтому можем типа X1, Y1,
X2, Y2 в принципе поддерживать.
Типа, спускаемся до конца, получили
пару AX плюс BY.
Что?
Так это по коду выглядит очень просто,
типа ты пишешь что-то вроде...
Ну, я не знаю, я типа его несколько раз писал,
но каждый раз ты сидишь, выводишь эти формулки
и умираешь. В смысле, тут формул не надо выводить.
В этом его прелесть, не надо вообще
ничего выводить. Ну, формулы для пересчета
вот этих X2, Y2.
Так, в смысле, ну давай посмотрим, что за формулы.
Типа, вот ты знаешь, типа вот тебе надо
из A вычесть BK раз, ну K равно чему,
ну A поделить на B, ну well. Ну, давай
типа A минус равно B на K.
Может дело в том, что я в последний раз делал
кто-то 9 класс? Ну, возможно, типа.
Y2 на K, Y1 минус равно Y2 на K.
Ну, как бы, формулы закончились.
Но просто когда ты свопаешь AB,
надо не забыть X1, X2 по своей
Y1, Y2. Вот.
Типа, алгоритм он очень простой,
формул никаких выводить не надо.
Окей. Ну и более того,
теперь у нас доказывается, что у нас в конце
решение, вот если мы вот именно так делаем
и никак не помодули, у нас получится так, что
X у нас будет равняться,
он не будет, точнее, превышать
B поделить на модуль
Nod AB все по модулю,
а Y не будет,
наверное, наоборот, да, X по модулю
не будет превышать, и Y по модуле не будет превышать
A поделить на Nod AB.
И все еще
пополам будет, даже вот
так. То есть, вообще
строго говоря, такое решение, оно может быть только
одно, и
как раз именно вот это минимальное
в каком-то смысле решение у нас и находит этот алгоритм.
Поэтому он такой приятный.
Ну и работает, все очевидно, залог.
Я объяснять, я думаю, это не буду.
Это не то, чтобы прям супер очевидно.
Что вот вы к этому приходите?
Типа, если мы берем AB модулю B, то она в два раза уменьшается.
Ну...
Чуть-чуть неприятно, но в целом ладно.
Не, ну...
Нет, смотри, у вас это было на Теоречисел,
вы это писали в школе. Вот. Тут, на самом деле,
нитро реально, почему вот такие оценки получаются,
тут надо прям жестко изучить последовательность, но вы это делали, да,
вы там строили последовательность X1, X2, X3, X4,
да, этих остаточков
делали. Смотрели, что у вас там одно убывает,
там X и Y строго возрастают по модулю.
Я не помню, но в целом
не обязательно это делать.
Ну, в принципе, да, я думаю, типа,
как бы, это в принципе один раз то,
что надо проделать и забыть про это, в принципе, навсегда.
Кстати, мне кажется, это тоже для
флипчарта, тут нет нормальных маркеров.
Что флипчарт?
Это тоже...
Тут, кажется, все маркеры они, вот.
А там два сторонние?
А там дальше мел.
А, ну, отлично.
Если будет только мел, его тоже
принеси.
А, Ваня!
Саня, это я, да, я забыл.
Окей.
Ладно, погнали дальше.
Хорошо, давайте что-то интересное про алгоритмы
в клида, скажу.
И вот сейчас как раз-таки подходим к теме
ключевой, который я хотел раскрыть сегодня.
Это всякие
алгоритмы, которые
решают многочлены по простому модулю P.
Вот это уже плюс-минус
Ну, прикольно, будет такой рандомизированный простой алгоритм,
который изи написать.
Никакие ффтшечки там, что-то подобное не надо,
оно все равно вас ничего не ускорит.
Мои алгоритмы какие-то базовые
совсем вспомнили, то, что Филипп просил.
Давайте к чему-то интересному переходить.
Тема, на самом деле, тут
две будет раскрыта.
Это нод многочленов.
Расширенный
Euclid, по сути.
Расширенный Euclid
для полиномов за время
от DEC P на DEC Q.
С помощью него
мы получим алгоритм,
который
ищет квадратный корень из чисел
за время от LOC P, рандомизированной.
Давайте с QRT
за
от LOC P.
Вот.
А уже с помощью этого алгоритма мы
научимся
решать произвольный полином,
находить корни произвольного полинома
за время. Давайте сейчас, чтобы не обмануть
вас.
O от N квадрат LOC P.
N это степь многочленов.
Что еще?
Вот, как-то так.
Ну и там дальше поговорим что-то про ток
работает с кратностями. Ну там я особо
честно не читал статьи по этому поводу.
Там какие-то техники плюс-минус наскребываются
и нормально, я думаю, хватит.
Ну и вторая сейчас
лекция, она будет посвящена тому,
это вот мое обещание сейчас,
что мы как-то поработаем с гауссовыми
чистыми и посмотрим пару алгоритмов на них.
А сейчас нет.
Сейчас гауссовый это совсем бонус у меня был по плану.
Ты уверен, что гаусс пишется
со S? Я уверен, что
мне очень тяжело писать вот этой штукой.
Но я вот добавил S-ку.
Это S уже?
Надеемся. Это короче бонус, типа
ну там научимся за отлокп
находить вот решение такого уравнения.
Для простого P.
Ну оно в принципе существует, я думаю, вы это уже доказывали.
Вот. Но есть такое
доказательство, которое пользуется
свойствами гауссовых чисел и позволяет
еще построить явный алгоритм для нахождения
за время отлокп.
Да.
Да, вполне и детерминировано можно сделать.
Ну естественно, если
у нас 4k плюс 1, потому что для 4k плюс 3
решения просто нет.
Но вообще, этот бонус
есть просто время хватит между где-то двумя
темами. А вторая тема это
префиксная сумма для
мультипликативных функций.
Ну это, я думаю, те,
которые были в тень кофе
обучались, они уже знают, что это такое.
Как это все считается, наверное, я думаю,
не помните. Вот.
Но оно позволяет, например, посчитать количество пар
взаимопростых чисел от нода n,
где 2 числа x и y перебираются
от нода n, например, за время
n степени 2 третьих.
У нас на УКТЧ, да, у информатика
что-то такое было. У вас было такое, да?
На него всех. Ну окей.
Ну значит, посмотрим, типа если
будет время, просто выпишу эти формулы, расскажу,
плюс-минус базовая теория
и все будет ок. Ну хорошо, давайте
начнем с многочленчиков,
потому что они тут кажутся самыми интересными.
И давайте
начнем, собственно,
с того, что научимся их
правильно для них вычислять нод.
Собственно,
как он вычисляется?
Вычисляется он достаточно просто.
У нас опять-таки есть два многочлена,
ну давайте вот будет P0,
так как-то он не пишется,
P0 от x будет
и будет P1 от x.
И мы хотим для них
почитать нод. Делается это очень просто,
мы просто вводим последовательность, типа P и
плюс первая от x равняется
P от
x mod
Pi-1x.
Вот, ну проблема в чем? Проблема в том, что мы
один раз можем поделить многочлены, но конечно
давайте алгоритму с помощью FFT,
как это делается, но применять его в данной задачке,
как мы убедимся. А давайте посмотрим,
что будет с моим упримением тут.
Это, кстати, от x сколько будет? N log квадрат?
Это N? Нет, деление у нас
за N log работает.
А суммарный лог делений примерно?
Ну, у нас будет не лог делений,
у нас логарифма,
давайте проговорим,
у нас логарифма тут никакого не возникнет
от количества действий, у нас с количества действий
будет N плюс M.
Ну, или минимум N минус,
ну, минимум N на 2, либо что-то такое.
То есть у нас за каждое,
хотя, скорее всего, минимум N
плюс 1, да? У нас за каждое действие
будет сноситься не более чем одна степень многочлена
у каждого.
И поэтому
у нас оценка будет именно такая.
Ну, хорошо.
Ну, я думаю, все понимают, почему
тогда. P от x, следующий многочлен
мы можем только гарантировать, что он
может снести, но мы
это не можем гарантировать.
Вот, и там как раз таки можно легко
построить тест, когда это будет работать задолго.
Ну, например, когда мы
делаем что-то такое,
смотрим на какую-то такую последовательность
сейчас,
x минус 1, например, да?
Хотя...
Ну, давайте, кстати,
подумаем, да?
Мы можем просто обратно его остановить. То есть мы
ходим, чтобы срезалась не больше, чем одна.
Да, да.
Да, вроде работает.
Можно просто начать уже с 1 0,
и тут
будет x, тут как сделать,
чтобы снесталась одна? Ну, давайте сделаем
x квадрат
P от x, ну, там плюс
x, например, да? И так далее у нас будет
все по одной степени сноситься, мы можем построить
такую пару многочленов. Хорошо.
Ну,
то есть у нас будет всего
от n действий.
Ну, пускай мы будем считать, что
н меньше равно m, да?
У нас будет от n действий,
каждый будет происходить за
n лог n. То есть мы получим
n квадрат лог n.
Ну, это как бы имеет
смысл, но вообще-то
если мы аккуратно
реализуем алгоритм по-дормальному, то я вам
обещаю синтетику от
n квадрат
плюс m
лог n,
m лог m. Если мы все-таки решили сделать первое
деление честно через FFT и
от n, если
мы просто применили этот алгоритм.
То есть, как вы видите,
тут FFT нам никак не помогает
улучшить синтетику, оно даже портит
ситуацию.
Кроме вот этого случая, если мы им грамотно воспользуемся.
Так что тут надо
делить их в тупую.
Но давайте посмотрим, как работает деление
двух многочленов.
Вот у нас есть многочлен, какой-то
PIT,
у него пускай старшая степень
это ANXN, например,
и так далее. И вот у нас есть
предыдущий многочлен,
Pi-1x,
у него степень
должна быть побольше, ну давайте m,
m же больше, чем
n, как известно.
И собственно, вот мы делим,
а нет, вот Pi-1,
надо взять по модулю
PIT.
И собственно, что мы делаем? Мы как бы
хотим снести одну степень, и так далее,
по алгоритму сносим в деление. И как раз
мы снесли вычля,
потом записали результат, что вот нам
надо к частному приводить x-степенька,
ну и так далее.
А потом мы в основе
массива такие, вот мы уже знаем, что надо умножить
a, чтобы его вычесть
из b, чтобы получить то, что надо.
Давайте заметим, что мы
делали ненужные действия,
мы могли просто сразу начать сносить
степень,
прямо вот тут, не выполняя деления отдельно.
Вот это вы же понимаете, да?
То есть вместо того,
чтобы их поделить стандартным алгоритмом,
который будет все равно работать точно так же,
мы можем просто снести первую степень,
вторую, третью, четвертую, и так далее.
Ну в плане подобрать вот это вот
an-1 на bm,
t умножить на x в m,
да-да-да,
там вычислить bm на an-1,
все, вычислить этот коэффициент,
вычислить его отсюда сразу.
Потом типа, посмотри,
дальше на степень, опять его вычесть.
То есть это будет то же самое,
что делать деление, по сути, у нас никакого проигрыша
не будет, просто мы ускорим наш код в два раза,
примерно. В два? Да.
Почему в два? Потому что как у тебя
проработал определение? Ты делал все то же самое,
а потом забывал изменения в массиве b.
А потом, типа, ты уже, когда знал частный,
ты краски его домножал вот на многощельно anxn,
если это применял,
то есть ты два раза по кругу пускал вот операцию.
Потому что, типа, тут работает вот метод сноса степеней.
Мы сносим сначала старшую степень,
потом следующую, и так далее.
Поменяли степень местами,
сделали наоборот.
Ну и удивительно, за сколько это работает.
Вот у нас вначале были степени, например, nm.
А дальше мы сносим степень
вот тут на единичку.
Сколько мы на это действие потратим?
Ну, точнее, большую степень, тут побольше у меня получилась n.
Вот мы хотим ее на единичку снести,
но степень второго многочлена.
Да, это одно вычитание.
Давайте из этого прямоугольника, по сути, вычислять один столбец.
Дальше мы сносим опять ее.
Мы опять столько же вот 10 потратим.
И давайте заметим, что вот такой геометрический способ
нам показывает, что
суммарное количество действий, которое мы сделаем,
оно будет равняться от nm.
Все.
Всем понятно, что произошло?
Это плюс-минус очевидно.
Ну вот еще, типа, забавный результат оказывается,
если мы будем параллельно
хранить, если мы захотим
вдруг сделать...
Кстати, вот такую оценку, типа,
м логм плюс н квадрат. Вы же тоже понимаете,
как она достигается, да?
Да, просто...
Теперь м меньше.
Да, да, именно так.
То есть ничего сложного в этом нет.
Более того, там, кстати, можно
эту оценку еще сильно уточнить, типа, в конце,
если мы нод получим...
Ну вот, что у нас получится?
У нас будет много чаянина какие-то,
но пускай у нас нод имеет степень D.
Ну, это такое все уточнение,
потому что обычно он маленькую степень.
Да, он имеет обычно маленькую степень,
но сейчас как бы...
Сейчас увидим, зачем оно.
И тогда у нас как раз последние D квадрат действия,
они на самом деле выполнятся за от от D,
и можно считать, что они не выполнились.
Окей?
Да, ну то есть мы сразу все обновим.
Да.
Вот, ну то есть будет оценка, типа,
нодов.
Но давайте заметим, что если мы ноды для
нескольких многочленов уже выискиваем,
то у нас это все, у нас будет
телескопическая сумма,
и у нас просто будет работать за квадрат
степени минимального многочлена
плюс суммарная длина остальных
на логарифмы соответствующие.
Это если мы делаем чс на первое деление,
через f of t.
Вот, но мне кажется, это вполне неплохо.
Окей.
Сейчас, почему у нас N квадрат минус D квадрат выходит?
Почему?
Потому что, ну помнишь, мы, типа, вычитали,
а мы сносили степень по одной, да?
Ну хорошо, мы снесли 1, 2, 3,
вот мы дошли в какой-то момент
до того, что у нас есть два многочлена степени D, да?
Ну хорошо, да.
Вот тогда, типа, мы за D операции
снесем полностью один из многочленов в ноль.
Потому что у нас D имеет
как раз-таки степень их нода.
Вот, значит, вот мы эти
D действия сделали, ну давайте скажем, что мы их
делали раньше, да, где-нибудь.
Типа просто забудем про то, что мы их сделали.
Типа скажем, что вот они учились
где-то раньше, например. Вот.
Ну и тогда вот у нас D квадрат действия остались не сделанными.
Вот получили какую-то такую сумму.
Она сворачивается иногда.
Такой забавный факт.
Вот.
Давайте теперь поговорим про то,
как работает расширенная лгм в клид для многочленов.
Вот помните, я писал код типа
A минус равно B на K,
X1 минус равно, короче, пишем то же самое,
как работает зафигеть как быстро.
То есть это все еще будет упихиваться в отнм.
Почему так
происходит? Ну давайте
я пару слов все-таки скажу. У нас все-таки строилась
последность P0, P1, P2,
когда мы один на другой делили, да.
И так далее, мы в конце дошли до многочленов
Pk, который равен ноду
и нолику.
Вот давайте вот тут при оценке
считать, что мы как бы делали деление честно.
Нам просто так будет удобней.
Ну и тут, соответственно, запишем
массивы частных, типа Q и T.
Это типа P и T
поделить на P и
плюс один.
Ну, без остатка. Типа, такая запись для
многочленов не используется, но, я думаю, вы понимаете,
что я имею в виду. Хорошо.
И что тут можно понять про эти...
И дальше мы строим последность X0,
которая равна изначально единичке,
и последность Y0, которая изначально равна 0.
И вот так вот
она у нас начинается, как
неожиданно матрица E.
Но для многочленов.
Собственно, дальше что будет происходить?
Мы будем делать эти операции. У нас X...
Давайте, например, Y, да.
Посмотрим на Y, он тут поудобнее будет.
У нас будет Y и плюс 1
вычисляться по формуле.
Вот из большего вычили
меньшее сколько-то раз, да. То есть мы
из Y и минус 1
вычили
Q и T раз,
Y и T.
Не вру?
Не X и T.
Y и T.
Это получилось, что они вообще
между собой не коррелируют? Да. Именно так, все верно.
Все так и должно быть.
Давай вспомним, как Algorithm of Clid работал.
Algorithm of Clid у меня
X1, Y1, он как их искал?
Все-таки, значит, надо это
проговорить. Вот у меня была какая-то пара
AX2 плюс BY2, да.
Вот эти как разки X и Y
это как разки члена
вот этой последовательности. На каком-то шаге.
Вот что происходит, когда я отсюда
из первого слага вычитаю второе.
У меня отдельно вычитается X1
и отдельно вычитается Y1.
То есть это действительно все происходит параллельно.
Поэтому тут ошибок никаких нет.
Подожди, а почему
ты именно в таком виде записал?
Почему я именно в таком виде записал? В плане
ты не знаешь пока эти коэффициенты
X1, Y1.
Ну, то есть они есть такие.
Подожди, изначально... Нет, я их всегда
знаю. Я их могу запоминать. У меня изначально
дана пара AB, да.
Но это типа просто A умножить на
единичку плюс B умножить на ноль.
А тут у меня
A умножить на ноль плюс B умножить на единичку.
Я их изначально знаю.
То есть... А ты же их местами должен менять
в какой-то момент? Да, я их могу местами
поменять. Я сделаю swap X1 и swap Y2
swap Y1 и swap Y2, да.
Все будет ок.
Но просто для того, чтобы анализировать
агретминиф клида, неудобно стоять, что мы
меняем их местами, когда-то не меняем.
Удобнее сразу сказать, чтобы у меня была пара P0 P1,
я P0 поделил на P1
с насадком, получил P2.
Дальше у меня есть пара P1 P2.
И дальше я вот так окошком двигаюсь.
Удобнее для анализа делать именно так.
То есть я так и написал сразу, потому что
предполагал, что вы на ТЧ это делали.
Ну, мы это делали на алгебре.
Ну, я не знаю, как у вас эти
предметы называются.
Так что вот.
И дальше мы вот также можем собственно X поддержать
и Y. Они у нас
также будут какие-то две последовательности.
Вот.
Значит, мне надо было нормально
рассказать расширенный агретминиф клида, как Филипп
обратил. Было бы меньше проблем.
Да, все ок.
Ну хорошо, у нас Y вычисляется
по такой формуле. То есть действительно от X не зависит.
Кстати, X по такой же формуле вычисляется.
Там такая же рекурренты возникают.
X1 равно X и
минус 1, минус Q и
X и T.
И в конце мы получаем решение, и все круто.
Давайте что заметим?
Давайте заметим, что у нас
Q может иметь степень...
То есть на самом деле можно вычислять
это как словно матрицу.
Короче говоря, у нас только начальные данные
не разные. Да-да-да.
На самом деле типа агретмиф клида это у нас что-то вроде
данного P0, типа X0, Y0.
Даже если это числа.
P1, X1, Y1.
И мы просто довнажаем эту матрицу
на такие вот штуки какие-то
минус Q, потом опять
минус Q и так далее.
Ку2 и ку1 они могут быть разные.
То есть, по сути, да,
материчный подход к этому анализу тоже применим.
Все ок.
Давайте посмотрим на кушки внимательнее.
В самом начале у нас могла быть подстава.
У нас P0 и P1 могли иметь
равную степень, или вовсе P0 мог иметь
меньше степень, чем P1.
Ну, давайте не менять даже.
Давайте забьем в принципе.
Тогда у нас Q1 мог быть константой.
Верно?
Мог быть константой.
Но давайте заметим, что дальше тогда
у нас никогда константы не бывают.
Потому что степень
соседних многочленов они всегда
различны.
Теперь, что я хочу сказать
про Y, например. Я хочу сказать, что у Y
в степень она строго возрастает.
Тут
как раз вот понравился факт, что
не константа, потому что казалось бы,
могло что-то сократиться,
потому что в начале у нас такая вот ситуация.
Но в принципе мы знаем,
что тут у нас Y и T, он изначально
имел степень больше Y и минус 1,
но его еще умножили на что-то, что имеет какую-то степень.
Значит, Y и плюс 1 имеют еще большую степень.
То есть, дек
так, чтобы было видно,
дек Y и T, он растет.
Про X и T я могу сказать то же самое.
Но тут, видите, какой нюанс.
У нас X0 равна 1, а тут у нас
0 типа степени минуса бесконечности получается.
Ну, хорошо, давайте скажем, что он растет
просто с первого шага, потому что это РОМ,
у него значение всегда будет равно 1.
Всегда.
Сейчас.
Это X и минус 1.
Да, всегда равно 1.
Всегда X2 равняется 1.
А, нет, X2, окей, возможно.
Да, ну и давайте заметим, что тут...
Не-не, ну X2, я про X2 говорю, да?
Вот, давайте заметим, что вот X1
равно 0, X2 равно 1, и дальше у нас все то же самое,
что с Y только со сдвигом 1 пойдет.
Поэтому типа степени
X они тоже возрастают.
Окей.
Вот теперь сейчас нам... Хорошо,
теперь что мы сейчас накопили в нашей копилке знаний?
Мы накопили, что степени Y
растут, ну и степени X
растут.
Причем они строго
возрастают. Это тоже
не мало важно.
Ну с какого момента там со второго шага?
Ну там до второго шага давайте считать, что мы линейные действия
сделали, все пофиг.
Хорошо.
Теперь давайте оценивать.
Сейчас
как раз вот Миша верно все сказал,
нам понадобится матрица.
Нам понадобится рассмотреть матрицу
P0,
P1, X0,
Y0, X1,
Y1.
Что происходило в алгоритме
Euclid? Мы брали
и домножали ее слева на матрицу,
1,1 поменяли местами,
и еще какой-то костюм вычисли,
минус Q какой-то, и тут 0.
Да, у нас сейчас в матрице
многочлены, я думаю, это вас не пугает.
В матрице можно пихать что угодно,
что можно умножать и складывать.
И по плюс-минус нормальным
законам, типа кольца туда можно пихать же.
Окей. И так далее
мы делаем какие-то действия.
0,1, минус Q, например.
Давайте это все
назовем буквкой G.
Вот это у нас алгоритм Euclid,
как он преобразовал наши данные.
Там нетрудно
понять, на самом деле, что тут были 1,1,
0,0, и как раз результирующая
матрица, которая получилась, это будет
алгоритм Euclid G.
Все больше и больше
людей прошло, окей.
Давайте посмотрим повнимательнее, что происходит.
У нас вот эта матрица,
она у нас имеет детерминат минус 1.
И все матрицы
тут имеют детерминат минус 1.
Ну тогда DEDG, он типа
минус 1 степени K.
И что получается?
Получается, что у нас в конце мы получим какое-то действие
типа pk,
pk плюс первое.
Ну давайте я только тут индекса не буду
писать, и так понятно.
x и y.
Ну ладно, все-таки напишу.
Вот, и мы хотим понять, что получится.
Но мы уже какими-то рассуждениями
поняли, что x1,
что соответственно у нас xk и yk
будут удовлетворять,
будут как раз решением уравнения
p и x
плюс q и y равно g, да,
в гцдх.
Но вот хочется что-то понять про остальные.
Про xk плюс первое
и про yk плюс первое.
Ну тут надо понять, что у нас
будет в p-шках. Вот тут в p у нас
будет гцд, верно?
А тут будет 0.
Потому что мы закончили
агритм Евклида вот тут.
Он заканчивается именно так. Но давайте тогда
посмотрим. Представим, что мы пальчиком
закрыли последний столбик.
Но тогда у нас просто квадратный матриц
преумножается, верно? А это значит, что
детерминат можно вычислить у конечного.
То есть у нас будет
гцд многочленов
p0 и p1.
Потом будет 0.
Потом будет xkt
y
xk плюс первое.
И вот оно будет как раз таки равняться
изначальному
детерминату. А вот он чему
равнялся? У нас x0 был равен 1,
а x1 равен 0, да?
Соответственно, это просто было
минус p1.
OK?
Минус p1 умножить на
минус 1 степени k. Получается как раз
минус 1 степени k плюс 1
на...
Чего там p1, да?
OK?
Тут можно сделать
шпоньк.
У нас детерминат вычислить, потому что
мы уже взрослые дяденьки, мы умеем его вычитать
устно.
Отсюда можно заключить, что краски понятно,
что будет на месте x.
Это будет конкретно наш исходный чел
p1 поделить на их ГСД.
Ну и понятно, какая будет степень, да?
Она, понятное дело, степень этой фигни
не будет превышать n.
А m, видимо.
Так, второй рассматриваем, да?
Это все понятно?
Ну, sorry, что там так получается писать.
Я не умею пользоваться мелками.
Я в детстве мало рисовал на асфальте.
Вот.
Как-то так. Это OK?
Точно?
OK. Ну давайте заметим, что yк плюс 1
мы можем сделать такую же оценку и заключить,
что его степень не будет превышать n.
Ну, на самом деле, n минус
там их нод. Ну, давайте на это забьем сейчас, да?
Это нас не особо интересует.
Ну, давайте тогда это оценим точно так же, как мы
оценивали вопрос с самым алгоритмом вклида.
Мы доказали, что остатков степень не больше, чем...
Стри, мы доказали во первых...
Стри.
Не-не-не, стоп, подожди.
Мы смотрим на расширное алгоритм вклида.
Стри, мы доказали...
Мы доказали сначала, что
степень иксов они растут.
Ну, начиная с двойки, да? Мы доказали, что
степень иксов растут.
И мы доказали, что в конце они будут не очень большие.
Самый последний элемент
последовательности, да?
Ну, это значит, что когда мы...
Ну, я хочу сейчас, по сути, применить тот же метод,
что мы использовали для оценки,
вот сколько тот действие было, да?
И сказать, что у меня будет отnм действие
примерно.
Вот.
Почему это так работало?
Ну, давайте опять это проделаем.
Вначале мы сделали какие-то действия,
был вот этот квадратик, да?
Вот тут пускай будет степень икса,
иксы этого очередного, тут степень дек
у этого для вычислений.
Ну, в конце у нас степень икса
не будет превышать n, степень у не будет
превышать m.
Ну, я думаю, тут все очевидно, да?
Типа просто у нас
степень повышается,
причем, как я тут раньше писал, тут это стерлось,
у нас она повышается ровно
на ту степень q,
на которую мы домножаем.
Соответственно, если у нас, типа, степень
вот тут увеличилась на k какой-то,
то мы ровно столько действий,
типа k на текущую степень другого накачали,
мы и потратим.
Сейчас, и...
Сейчас, стоп.
Сейчас, стоп, да.
Самовод через себя, да.
Да.
Кажется, ценка неверная.
Не, ну, бывает забавности, бывает.
Сейчас, да, прикинем.
Там должно выходить отnm, точно,
возможно, должно.
В начале лекции все было OK.
Там просто вы меня запутали,
все было нормально.
Да-да-да, именно так.
Так, у нас иксы растут,
мы их пересчитываем вот
по такой формуле,
которой тут нету.
Надо что-то из этого вывести.
Денис, ты умеешь профайчить, что это робот за отнm?
Я не знаю, что это еще за мою формулю.
А я расширенный алгоритм не вклит для многочленов.
Ладно.
Я никогда не видел, как это делать.
Вот жаль, что ты опоздал.
Очень жаль.
Там формула,
ты знаешь,
что у нас
существует решение для
чисел просто, да?
Для чисел существует решение
x плюс y на 1, если ab взаимно просты.
Вот очень жесткий факт, да?
Очень жесткий факт, да?
Как его можно запрофайть?
Один из пруфов сказать, что у нас всегда
первый-второй член нода,
он будет линейные суммы i, b.
Очень жестко.
Давай вместо того, что писаете
алгоритм x, просто будем поддерживать
эти штуки.
Утверждение это работать быстро.
Для чисел.
Утверждение №2 это быстро работать для многочленов.
Ну вот все.
Теперь ты знаешь алгоритм.
Вот теперь докажи его.
Ну ладно.
Давайте тогда не буду заходить
подалеко. Давайте скажу, что это работает за i квадрат
плюс m квадрат. Как вам идея?
Ну короче, за квадрат мы как-то научились
находить эти коэффициенты, все круто.
Ну за квадрат оценка очевидна.
Повысили степень
на, ну, типа на
единичку. Знаете, мы потратили
не больше мани-действий, потому что суммарная степень
она будет не больше мани.
Ну все. То есть эта оценка как раз
плюс-минус очевидная.
Ну просто обычный алгоритм
Ивклида без этой фигни он работает за o отnm,
что тоже приятно.
И как раз-таки вот нам этот первый алгоритм не понадобится,
потому что я честно говоря не помню у него применений никаких
примерно. То есть он такой
just for fun. А второй теперь сейчас
мы будем использовать активно.
А могу стирать, да?
Давайте я сотру вот тут.
Мне кажется тут совсем что-то бесполезное написано просто.
Да и тут типа
эти все обещания, как бы они
все еще обещания, так что
они ничего не значат.
Хорошо.
И давайте вот это сотру,
потому что
Что?
О, Сашка кстати пара
прошла.
Давайте да, перерывчик сделаем.
Там и так был перерыв, потому что я
уходил руки мыть из маркерной доски.
Будем честно. Давайте типа 10 минуток.
Почему руки в геомикста?
Да, руки в геомикста.
Окей.
Давайте
короче 15 минут заберу.
И потом перерыв.
У нас же типа все равно тут нет жесткого расписания, так что
пофиг.
Если ты спросишь как вести занятия Филиппа, то
Если все заберешь.
Да нет смысла, ну пофиг.
Иногда короче у
прошлых курсов была так что
пары рукавичей шли не подряд, то есть
типа есть пара, окно, пара, пара.
Короче окно он забирал.
Ужас.
Ну хорошо.
Давайте разберем
Рандомизированный алгоритм решения уравнений
x квадрат равно a по модулю p.
Вот вообще
это вроде бы основному потоку рассказывали алгоритм
уже, но он во-первых был какой-то мерзкий, противный.
Его сложно запомнить.
Какому основному потоку? 3?
Да. Откуда ты знаешь?
Короче я решил
Стой. Мне Филипп сказал
что будет запись. Я решил погуглить
какие есть записи и нашел у основного потока теорию чисел.
Ну там
еще за полтора часа примерно рассказал
3 алгоритма и нормально было.
То есть это уже больше, чем я рассказал на самом деле.
Но сейчас будет первый алгоритм нормальный.
То есть как решать такие уравнения?
Есть действительно
подход, который рассказывали в основном по токену.
Он не сильно обобщается на случай
больших полиномов, поэтому мы его разбирать не будем.
Мы разберем другой подход.
Ну во-первых
про квадратичные вычеты
вы все теорию знаете?
Понятное дело, что мы в самом начале проверяем, что a равно 0.
Если там равно, то
честно 1 корень. Если
a в степени p-1 пополам равно
минус 1, мы выводим, что корни нет.
Вот у нас остался случай, когда
корни все-таки есть, их равно 2, они различные.
Окей.
Ну пускай тогда это корни x и y.
То есть x квадрат равняется y квадрат
равняется a.
Да, там это просто те же числа, но разные по знаку.
1 и минус 1.
Что, нет, они всегда различные, все нормально.
Ну потому что если x подходит,
то x минус x подходит. Это жесткий факт.
2x равно 0.
Окей.
И типа в чем идея?
Идея в том,
чтобы их как-то научиться разделять.
Но
блин, мне кажется, я поспешил,
ну ладно, пофиг. Давайте заденем это.
Короче, их как-то хочется разделить.
Но вот очень круто было бы,
если бы одно из этих чисел...
Что?
Вот очень круто было бы, если бы
эти числа, ну, одно удовлетворяло
кому-то свойство, другое нет.
Ну, например, одно было бы квадратичным
вычетом, а другое не было бы.
Вот давайте представим на секунду,
что такая штука произошла,
и попытаемся тогда
решить задачку.
Ну, как предлагается делать?
Вот у нас есть x квадрат
минус a многочлен.
Теперь вот мы хотим...
Что сделать?
Мы хотим найти нод с каким-то многочленом,
например, который будет содержать все квадратичные вычета.
То есть это будет многочлен xp минус 1 пополам
минус 1, да?
Вот утверждение, если мы найдем
нод этих многочленов, то мы вытащим
один из корней.
Вот, это в случае, если x, например...
Если они действительно разные.
Да, если один квадратичный вычет, а другой нет.
Это понятно?
Давайте обсудим, как это делается.
Ну, делается это очень просто, да? То есть тут казалась бы
степень большая, но давайте воспользуемся алгоритмом
бинарного здания степень по модулю.
И просто сразу xp минус 1 пополам
вычислим по модулю.
Это у нас затратит от логп действия, а потом будет от 1
какой-то фигни.
Ну, круто.
Вот мы за от логп
научились что-то делать.
И, кстати, эта штука, она
вообще-то выполняется.
Иногда для некоторых простых p, всегда.
Например, если у нас
p имеет
вид 4k плюс 1,
4k плюс 3, наверное, да?
Подожди.
А на что бинарное возведение степени?
А чтобы x с степенью p минус 1 пополам
вычислить сразу по модуле x квадрат минуса.
Я хочу вычислить этот нод, мне достаточно
это вычислить по модулю первого.
Вот, например, 4k плюс 3, да?
Вот если я не ошибаюсь, тут минус 1
не квадратичный вычет.
Ну, там где-то квадратичный, а где-то нет.
Сев, я него?
Точно? Минус 1 это 3 по модулю
не квадратичный вычет.
2 не квадратичный вычет
по модуле 3, все нормально.
Окей, вот, и, например,
так как мы знаем, что у нас корония, типа это y
минус y, например, да?
То мы можем сразу эту штуку применить
и без каких-либо рандомов решить уравнение
по вот такому модулю.
Но вообще, там есть решение проще, можно еще раз формулу сделать,
но это так, просто по приколу.
Вилл, ну давайте что-то делать.
А иначе минус один квадратичный вычет.
Да, и там они одинаковые.
Можно спастись, оказывается.
Изначально были корни.
Давайте ровнение, давайте a t его назову,
чтобы многочлен был нормальный.
Хорошо, подскажем, был t квадрат минуса.
В чем идея?
Давайте прибавим случайное,
давайте выберем случайное число дельта какое-то
и рассмотрим многочлен
t а плюс дельта в квадрате
минус a.
Давайте t минус дельта в квадрате.
Вот, тогда
в чем мем? У нас оба корни увеличились
на дельте, верно?
То есть если мы уже решим это
уравнение, то мы решим исходное.
Вот, ну вот оказывается, что если мы такую
штуку сделаем, то
у нас корни будут
иметь различный
как называется,
они будут один квадратичным вычетом,
а другой нет, с вероятностью не менее одной второй.
Почему это так?
Давайте вот посмотрим.
Сейчас, если p равно 4k плюс 1,
то минус 1 это будет квадратичный вычет.
Да тут вообще p не важно.
Неважно какой p.
Сейчас пройдем это рассуждение. Смотрите, вот пускай у нас сначально
были альфа и бета, да?
Они не равны друг другу, мы это уже знаем.
Но давайте скажем, что альфа минус бета равняется
какой-то константе лямбда.
Тогда
какие мы можем получить пары
корней, если мы
прибавим случайную константу дельта?
Он утверждается, что это просто пары, типа
какое-то случайное число х и х плюс лямбда,
верно?
Давайте запишем уравнение, что они
одновременно
либо являются квадратичным вычетом, либо не являются.
Но утверждение это уравнение выглядит вот так.
p минус 1 пополам степени
х плюс лямбда, p минус 1 пополам
равняется нулю.
Вот.
Давайте сюда поставим, например, нолик.
Мы убедились, что наш
многочлен не константно равен нулю.
Но тогда он имеет степени
больше, чем p минус 1 пополам.
А значит у нас
не более, чем p минус 1 пополам решения
этой штуки.
То есть не более, чем
в p минус 1 пополам случаях,
у нас они
одновременно либо являются квадратичными вычетами,
либо одновременно не являются.
А значит p минус 1 пополам
короче звучит, типа
как что-то вроде
с вероятностью
p плюс 1 пополам,
что больше 1 второй,
один будет квадратичным вычетом, а другой
не будет.
Ну либо где-то еще будет нолик выскочит,
но это тоже у нас положительный исход.
Если мы будем выбирать дельта нулю,
то у нас
дельта равна нулю, если мы не будем выбирать, то у нас там тоже будет
певец 1.
Короче то, что мы певец 1 пополам.
Ну, короче, там может быть крайний случай,
когда мы пришли в ноль случайно.
Да-да-да, он все равно хороший для нас.
Нет, в смысле, если мы пришли в ноль,
мы сразу поймем.
Да, так что это тоже хороший случай,
но, короче говоря, у нас удачный случай
происходит с вероятностью как минимум 1 вторая.
Вот.
Ну, значит, алгоритм такой типо. Давайте пробиваем случайно дельта.
Пересчитаем
коэффициентики этого многочлена. У нас получится уже какой-то там
не какой-то жалкий t квадрат
минуса, а уже какой-то достаточно серьезный
многочлен t квадрат плюс pt
плюс q.
И давайте вот для него сделаем вот эту штуку.
Ну, от ожидания количества сделанных попыток
2. Да, поэтому мы
разработали алгоритм с ожидаемым временем работы
от ЛАКП.
Открывай дисперсию.
Чел.
Ну, почитай.
В чем проблема?
Понятно, что у меня вероятность того,
что я у них...
Ну, смотри, хорошо.
У тебя вероятность того, что ты k раз обосрешься,
она... Ой.
Она у тебя 1 поделить на 2 степеника.
Она падает очень мало.
Она очень небольшая, короче.
Вот, как-то так.
Ну, и все.
Я предлагаю сейчас прерывчик делать.
И вот если...
И, короче,
после этого забрать уже сложный алгоритм.
Ну, не сложный, на самом деле, простой, как пробка.
Алгоритм, который решает просто полином
в произволенной степени.
Вот.
Давайте вот алгоритм.
Вот у нас есть произволенная многочлена p от x степени n.
Собственно, что мы делаем?
Во-первых, хочется избавиться
от кратных корней.
Ну, от кратных корней избавиться достаточно просто.
Нет, зачем...
Нет, производная, как раз,
она у нас столько кратной корни найдет.
Нет, я хочу, в принципе,
чтобы у меня был многочлен p от x, да?
У него выпускали корни
лямбда 1, лямбда k,
или так далее, лямбда k, да?
Я хочу, чтобы, в принципе, получить многочлен
x-лямбда 1,
или x-лямбда k.
Ну, так, чтобы экономно,
чтобы у меня еще константа была хорошая исполнение.
Чтобы я не отвлекался на всякие там
квадратичные, ну, несократимые множки
и так далее, степени больше одного.
Как это сделать?
Ну, давайте внезапно заметим, что
нам надо просто найти нод этого многочлена
с многочленом x степени p-x.
Это очевидно?
Ну, это плюс-минус очевидно.
Почему это так?
Ну, потому что это x степени p-x,
то есть на x-1, так далее,
на x-1.
Вот, все хорошо, теперь у нас все корни
сращаются по одному разу.
Ну, мы получили какой-то многочлен
новый p от x, простарый забыли.
Ну, что делаем дальше?
Дальше, типа, логерет такой,
выбираем случайное дельта,
причем его можно выбрать
равным нулю, в этом ничего страшного нету,
абсолютно.
Типа и рассматриваем многочлен
p от x плюс дельта,
и берем его нод,
соответственно, с многочленом
x степени p-1
пополам минус 1.
Ну, еще, типа, если мы вдруг угадали
какой-то корень, то
у нас у нас p от x плюс дельта будет просто делиться на x,
да, давайте, типа, сократим.
Вот.
Давайте как-то оценим алгоритм,
то есть после этого у нас, типа, мы получим какой-то многочлен
a от x, да.
Вот, в принципе, мы
могли получить вторую половину b от x,
таким способом. Ну, мы могли либо p от x разделить
на a от x,
ну, кстати, так вроде бы эффективно и нормально, давайте так и сделаем.
Вот.
Собственно, мы получили
многочлен a от x, b от x, который произведет
p от x, и они примерно корень пополам
разделили. Ну, мы пока в это верим,
сейчас мы докажем, сейчас мы докажем,
почему пополам. Там очень простая оценка.
То есть даже я справился
это доказать. Вот, собственно,
и как бы дальше
мы просто рекурсивно будем запускаться.
Ну, итерацию разделения мы сделали за время,
давайте посчитаем.
А вот эту штуку мы делали за...
Мы тут f of t, ничем не будем пользоваться,
но все равно, типа, нот в конце, так что пофиг.
Ну, собственно, самая тяжелая часть, а вычислить вот такую вот штуку,
это работает за n квадрат логп.
Ну, почему так? Потому что мы
в тупую...
Мы в тупую перемножили за n квадрат, да,
а потом по модуле мы можем взять тоже за n квадрат.
И все, у нас будет хорошо
и отлично.
Ну, окей.
Нет, у нас, смотри, у нас n логена
не будет тут никогда, потому что нам надо нот взять.
Ну, как ты нот будешь быстро вычислять с помощью f of t?
Или можно?
Денис?
Ну, так вроде бы я
больше чем уверен, что вроде бы, ну, нельзя это делать.
Ну, в общем, нельзя быстро.
Окей. Ну, вот, все равно у нас
крайняя операция ноты, да,
ну, тут сильно это ускорять нет смысла.
Ну, ладно, хорошо, мы можем сделать это
за o от n квадрат
плюс n лог n логп.
Ну, есть ощущение, что это
довольно значительное ускорение,
потому что p до 10 в 9,
n там тоже какое-то.
Это значительно, ну...
Окей, ну, можно, да, делать так, но, типа, сказать, что это
просто o от n квадрат, да?
Ну, у нас в итоге все равно получится
либо o от n квадрат, либо o от n квадрат логп.
Я тут какие-то там супер странные случаи, когда там, типа,
p оно на несколько порядков больше,
чем длина n, типа, не буду рассматривать.
Понятно, что у нас, типа,
либо n квадрат лог, либо n...
И у нас в 30 раз ускорение.
Нет, просто, типа, если многочлен, типа, 5000 размеров, да,
то там уже, типа, f of t, как бы оно не особо
эффективно, тебе лучше там, не знаю, крат,
субы побаловаться чем-то еще таким.
То есть многочлен в степени 5000, мне кажется,
сомнительно f of t-шкой делать.
Там, вроде, с 10, ну, хотя,
с 40 f of t-шка как раз такие.
Да, ну, понятно, короче, какую-то такую синтетику получаем.
Давайте посмотрим, как они разделятся.
Вот посмотрим на наши корни, как на полный граф,
то есть, типа, у нас вершинка это будет корень,
а, соответственно,
типа,
ребра они будут, как бы, ну, просто
ребрами будут в графе, да, вот.
Типа, давайте вот посмотрим, вот у нас, типа,
мы как-то разделили x плюс дельта, да,
какой-то дельта выбрали, вот у нас, типа,
корни разделились на две группы.
Квадратичные вычеты и неквадратичные вычеты.
Ну, хорошо.
А тогда, чтобы доказать, что они будут
делиться хорошо, я буду смотреть на мат ожидания
количества ребер в разрезе.
Вроде бы очевидно. Почему все так?
Ты все ребра проводишь?
Да, я провожу все ребра.
И давайте заметим, что у меня каждый отдельное ребро,
оно вводит в разрез с вероятностью 1 на 2.
Ну, как минимум 1 на 2.
Это из того, что мы уже доказали.
Да, это из того, что мы уже доказали.
Из того, что я для двух значений,
типа, если я к двум значениям
провалю одинаковое случайное число,
то у меня с вероятностью как минимум 1 на 2
один будет квадратично вычетен, другой не будет.
Но это, собственно, значит, что ребро
пойдет в разрез.
Да. Ну, типа, что у нас получается?
Вот это вот мат ожидание количества ребер в разрезе,
оно у нас с одной стороны
как минимум, давайте, строго больше
нарисую, давайте, ладно, нет, больше
бы равно. Вдруг я где-то ошибся.
Да, не, не понадобится.
Все окей, все
школьными фактами доказывается,
все нормально. Вот.
Окей, у нас оно, у нас с одной стороны
больше бы равно, чем 1 вторая c из n по 2.
Ну, это примерно, что?
Давайте скажем, что это примерно n квадрат.
Да.
Ну, минус n, да?
Бог с ним, это неважно.
Хорошо, теперь давайте посмотрим, ну, типа, прям
возьмем и посчитаем все
возможные исходы. Вот пускай, типа, у нас в
таких, они, вот при дельте
к какому-то равному i у нас
будет одна группа размера i и другая размера
b i t.
Ага. Ну, тогда,
естественно, эта штука с другой стороны, она равна
чему? Ну, по-среднеразметическому,
по всей этой штуке. То есть, типа,
среднее значение a i t
умножить на b i t.
Да?
Нет.
Да, именно так.
У нас же сами группы неравно, вероятно,
могут появляться. Нет, стоп, подожди. Ну, я говорю,
вот пускай, типа, при дельте равном i у меня появится
группа a i t и b i t. Да.
Вот. Ну, хорошо, давай я просто все такие чисто
выпишу. Я пока их никак не определяю, да?
Ну, вот, хорошо.
Ну, хорошо, давай тогда сделаем такое вот
рассуждение. Ну, типа, в чем тут идея?
Идея в том, что, ну, пускай, типа, разница между
ними, она там, типа,
x, да? Типа a i t это, типа,
это n минус x пополам,
а b i t это
n плюс x пополам.
Получается, вот мы за этим x будем следить.
Ну, тогда, типа, это что такое? Это среднеархметическая по
а
n квадрат
минус x и t
в квадрате поделить на 4.
Больше либо равно n квадрат
минус n поделить на 4.
Ну, на четверку домножаю, тут справа
и слева. Еще получается,
то есть, ну, и тут n квадрата я могу вычесть,
тут получается минус n
и получается, что у меня мот ожидания
квадрата и их разницы не превышает n.
А дальше, ну, не знаю, как-нибудь там можно
поиграться, типа, сказать, ну, давайте
допустим, что с вероятностью
там разделим случай на 2, типа,
ну, эта штука вроде бы она уже решается
через дисперсик по-нормальному. Я просто
сходу не помню, как это делается.
Ну, давайте поскажем, что с вероятностью 1 вторая,
типа, у нас, ну,
с вероятностью 1 вторая у нас будет фигово делиться
как-то, да? Ну, давайте назовем фигово,
что x и t, типа, на 1 пример оно
больше
корни из 2n.
А с вероятностью 1 вторая будет по-нормальному
делиться.
Ну, и тогда давайте
заметим, что у нас тут уже получится
притворить еще. То есть у нас, типа,
с вероятностью как минимум 1 вторая,
то есть с вероятностью
больше 1
и 2,
размеры
группы отличаются не более, чем на 2 корни n.
Не более, чем
на корни из 2n,
точнее.
Вот, ну, это все, в принципе, конец
заказательства, да, типа.
Дальше, что мы говорим? Ну, типа,
говорим, что ну, пускай там n больше 100,
ну, потому что n меньше 100, кого
интересует? Ну, никого, верно.
Ну, значит, там корни из 2n, типа, он там, ну, явно
больше, чем там 1,5, меньше,
чем 1,5n. Ну, значит, они примерно так
поделятся, типа, 2, которые в худшем случае,
с вероятностью 1 вторая. Ну, как-то так.
То есть,
ну, и давайте, типа, еще сделаем, типа, прям
совсем шикарно. Понятно, делать это в жизни делать
не надо, но давайте, типа, скажем, что если фигово разделилось,
то давайте еще раз разделим.
Ну, просто для того, чтобы было попроще запруфать.
Не более того. Это, естественно, бесполезное действие.
Оно только заметит
наш алгоритм, но все равно, типа,
оценка, симпатика будет нормально.
Ну, хорошо, вот мы делим...
В смысле, а как мы поймем, что фигово разделилось?
Ну, просто берешь, типа,
вычислил a, b, да? Вот, пускай степень
а меньше.
Двайн поделить.
Да, да, да.
Но мне просто так удобнее симпатику будет.
Мне так удобнее просто симпатику будет оценивать. Ничего более.
Ну, почему бы нет? Ну, в смысле,
если я сейчас это начну учитывать, то у меня там вероятность
и что-то такое. Я это всего не знаю, типа, я просто
первокурсник.
Вот. Ну, как-то он будет
делиться. Ну, понятно, что, типа, у нас сколько будет делений?
Ну, логен, типа, логен слоев, типа.
Ну, круто. Ну, вообще
давайте по-нормальному, давайте по-нормальному оценим, да,
t от n. Вот у нас t от n чему будет равняться?
Вот мы сделали
n квадрат лог по действию, да? На то,
что мы делаем,
это у нас
где-то universe.
Вот у нас
есть
галлюцин,
вон он, типа.
Вопросов нет, потому что
произошло?
Для мастер-сериала мы умные. Ну, глобально порядок.
Ну, то есть, как бы, алгрейт
в принципе, ну, такой. Его даже школьники, мне кажется, поймут.
И тут
рассуждение не очень сложное с доказательством.
Наверное, оффтеников я буду читать, хотя сейчас школьники вообще пошли нынче прям, ну не знаю, слабые, слабые.
Слабые?
Да, очень.
Может быть, просто все сильные пошли в Яндекс?
Не-не-не, в смысле, во-первых, во-первых, во-первых, во-вторых, в Яндексе тоже не очень сильно, ну типа там вообще в принципе по стране, ну кто там, Гемран остался, Дашка Грекова, кто еще, а, Иван Пискаров?
А теперь, ну нет, ну нет, ну нет, ну Чесовских он математик, к сожалению, А это что?
А это матиша, а, я тут еще хотел сказать пару слов о том, как, типа, смотреть на кратность крайней быстро, вот, это тоже, типа, может быть интересно, ну тут в чем идея, как бы, давайте, да, тут уже вот эта краска штук понадобится, и вот внимание, у этой штуки есть название, я в афиге, это короче называется,
сейчас как это называется, а, это Square Root Decomposition, короче, это фигня на фулл сериозе дали название, а, не, Square Free, все-таки название адекватное, Square Free Decomposition, да-да-да, ну это тоже, ну это то, что происходит, да?
Не, не, не, смысл, это получается, когда, типа, это берешь, типа, и f от x, ну, p от x, да, хорошо, p мы заменяем на, что, p поделить на нода p и p штрих, вот, это, короче, называется Square Free Decomposition, ну, давайте, заметьте, что после, что не так, ну, просто есть такое название, ну, смешно же, нет, ну, это плюс-минус, понятно, почему так, да, ну, потому что, типа, если p делился на, какую?
На алгебре, это понятно, да, вот, окей, все, тогда не буду объяснять, типа, вот этому дали название, это смешно, вот, ну, и, типа, собственно, что мы можем делать, ну, мы можем сделать Square Free Decomposition, и после этого выделить все, типа, корни, которые случаются один раз, потом, типа, все, которые 2 и 3 и так далее, ну, после этого, типа, дальше каждый корень можно проверить, да-да-да, ну, то, типа, можно, в принципе, посмотреть вот на эту штуку, да, а потом, типа, отдельно запуститься для мода p и p штрих, да, это будут корни, которые два раза встретились, ну, можно и так, да.
А это будут корни, которые ровно один раз встретились, все круто, все классно, позитивно, и так далее.
Что лучше, чем вы проверяете все корни, которые мы нашли в одном, а то, в какой степени, на квадрате?
Да, я фиг знает, ну, вообще, типа, а сколько ты будешь проверять каждый корень, ну, за 1 квадрат, типа, да, ну, вообще, да, кстати, ну, интеллектуально-интеллектуально.
Нет, даже суммарно по всем за 1 квадрат кажется.
Да, да, я об этом говорю, да, да.
Не, стоп, а как-то суммарно, как-то один корень за линию, а, да, да, ну, сейчас, ну, ты одну делимость проверяешь, не, Сева, ты врешь, ты врешь, ты проверяешь за n квадрат логен, хорошо, как ты делаешь алгоритм?
Ты врешь корень, делаешь, по-настоящему, это смеется за корень.
Да.
А, ты по одному делишь, все, окей, все, все, sorry.
Все, sorry, все, sorry.
Ну, да, действительно.
Ну, тогда, типа, хуя, так это бесполезно получается.
За то название.
За то название, да, да.
Блин.
Как бы, вот, ну, и давайте, типа, у меня был блог, посвященный алгоритме в Клида, давайте еще про Гаусс, прочисла, немного поговорим.
Короче, оказывается, что он не только для многощеленов, не только для чисел, но еще для офиговых чисел работает круто.
Вот. Ну галусы все знают, что такое, да? Ну я думаю все.
Просто взяли A и B игру, у которых A и B целые.
Вот, оказывается, галусы для них можно сделать.
Ну типа для них делимость вполне так же определяется, как для целых.
Я думаю, ну давайте посмотрим на галусы для них, как его можно реализовать.
Его можно реализовать. Реализуется, кстати, на удивление, очень просто.
Мне кажется, поэтому его и стоит рассказать.
А как-то определяет...
Да, давайте его определим для начала, мне кажется, это будет полезно.
Так. Давайте скажем, что вот у нас у каждого галусового числа есть типа норма.
Типа его модуль в квадрате, ну короче Z на Z сопряженное.
Собственно, я нодом, нода AB, типа галусовых чисел, просто буду называть число C,
у которого будет два условия, типа C, его норма максимальна.
Нет, норма это не длина.
Ну это длина в квадрате просто.
Окей.
Ну короче, тут может длина, норма, типа тут одно и то же на самом деле будет.
По сути не сильно отличается. Его короче длина максимальна,
а, соответственно, при этом оно делит и A, и B.
Кажется, нужно доказывать, что она точно всегда противна.
Да, мне пока пофиг как-то.
Иначе у нас?
Ну, я просто буду нодом любое такое число называть пока что.
Ну в плане, правда ли, что их всегда четыре?
Ну, ща.
Ну, вроде да.
Ну, типа.
Ща, ща, ты хочешь еще вот эту флагу доказать, да?
Ну, их может быть больше, чем четыре, поэтому.
В смысле?
В смысле, я тут не говорю вообще, что нода единственная.
Да, может быть, норма больше.
Нет, давай.
Короче, стри, Миш, Миш.
Миш, ты подожди, давай так сделаем.
Я сейчас вообще не говорю, что нода единственным образом определяется.
Я вообще не накидываю.
Окей? У меня все, просто единственное, что мне пользуется.
Я могу число C называть нодом A и B, вот только в таком случае.
Пока что я их не говорю, что их равны четыре, окей?
Да, да, да.
Ну, все, без проблем. Ну, типа давайте заметим, что.
Давайте заметим, что агритмия в клида работает, да.
Типа, если я попытаюсь вот.
Вот если у меня C, типа это вот.
Ну, нод, типа, пускай какое-то число, да.
Это A и B, то у меня, типа оно также является нодом A-B и B, да.
Ну, офигеть теперь, да.
Теперь я более того могу B давать на что угодно, в принципе.
Главное, чтобы оно было целым галсовым.
Это все работает. И туда и обратно.
Это очевидно вроде, да.
Давайте теперь построим агритм галсов.
Как он будет выглядеть?
Вот пускай у меня было число B, которое больше по модулю.
И тогда что хочется сделать?
Вот я хочу из A вычесть B на какое-то целое число галсового.
Ну, тогда вот как это число выглядит?
Ну, это на самом деле просто какая-то решетка.
Ну, не решетка, а такое вот клеточное поле.
Я...
Как тут она делит?
Типа у нас есть B, есть BIT, ну и как-то...
Где-то тут может быть...
А что тут не так-то?
Непарамельный вектор, в принципе.
Ну...
А почему ты сказал, что это не решетка, а всякая решетка?
Не, ну слово решетка, ну просто типа еще в более общем случае применяется.
Типа я не хочу его использовать, чтобы никого не напрягать.
Не, у нас были решетки на...
Ну, короче, просто какая-то сетка.
Вот, и у нас где-то тут располагается число A.
Ну, чем нам известно?
Ну, вот это вот квадратик на самом деле, да?
А значит, длина расстояния от A до ближайшей точки, оно не превышает, собственно, стороны квадрата.
То есть B поделено корень из двух.
Угу.
Вот, ну как такие точки быстро искать?
Ну, что тут можно сделать?
Ну, можно просто взять, попытаться спроецировать A вот сюда.
Спроецировать A вот сюда.
Ну, короче, мы получим, мы просто в таком случае понимаем, что X плюс Y и E это на самом деле...
Ну, A поделить на B, что очень неожиданно.
Ну, что то же самое, что там A на B спряженное поделить на B.
Окей.
Ну, вот нам эту точку надо выбрать.
Ну, понятно, как выбирать точку среди этих четырех.
Нам надо округлиться в ближайшую сторону.
Вот что это ты написал?
Это вот я написал вот X и Y, вот эти.
То есть я спроецировал A вот на эту сетку.
Я говорю, что вот X типа плюс Y и E это на самом деле частное A и B.
Это очевидно.
Ну, и просто дальше расписал чуть подробнее.
Вот, и дальше мне, типа, что надо?
Мне надо просто, типа, действительную, ну, мне надо действительную часть и мнимую округлить к ближайшему целому числу.
Ну, что заметим?
Давайте заметим, что если мы A на B спряженное домножили, да,
то у нас, типа, уже получилось какой-то там X штрих плюс Y штрих,
который отдельно делится на B, да, на B.
Норма B.
И, типа, мы как-то, ну, как-то я думаю, что сможем, типа, тут найти ближайшее.
Без выхода в добылы.
Типа там не знаю какой-нибудь формулы типа X плюс там, не знаю,
B, 2, там, поделить на B, там, округленное, строго вниз.
Ну, короче, как-то так вот мы можем сообразить.
И в итоге, типа, оказывается, что, ну, как-то за вот один вычисляется эта ближайшая точка.
Ну, значит, что мы делаем?
Просто ее из A вычитаем и продолжаем алгоритм.
Ну, типа, за одну операцию у нас длина одного вектора,
у нас длина вектора меньшего, она уменьшается в корень два раза.
Вот.
Какого-то вектора в корень в двух раз.
Давайте заметим, что у нас изначально было их произведение,
а их норма, соответственно, уменьшается в два раза.
Давайте заметим, что изначально у них там произведение норм было равно чему-то.
А в конце стало равно...
Ну, в конце, типа, оно не могло стать меньше 1 никак.
Ну и все, дальше мы понимаем, что у нас, соответственно, действие у нас будет log2,
вот, умножить на норму норма A, умножить на норму B.
Ну, и там, не знаю, давайте допишем сюда норму их нода в квадрате.
Вот.
Ну, как-то так, то есть, вообще, алгоритмическое время, типа, алгоритм вклита, в принципе, классно, прикольно.
Вот.
Ну, для чего он может использоваться, я думаю, вы и так понимаете,
ну, например, типа, если у вас там есть две вот такие вот прямоугольные сетки,
то вы можете, типа, смотреть их сумму по Миндковскому
и там определять, что будет за сетку у вас в итоге выходить, например.
Одно из применений.
Вот, ну, тут дальше возникают вопросы, сколько у нас может быть нодов различных.
Ну да.
Ну, и давайте чего заметим.
Ну, понятно дело, что если C-нот, то CIT тоже мод.
И C в квадрате мод.
И C в кубе мод.
И C в кубе, даже так, да. Вот у нас, типа, есть эти вот ноды, да.
Ну, хорошо.
Тогда чего заметим.
Вот пускай есть еще какой-то нод, который сюда не попал.
Вот он по длине будет такой же.
Да.
И чего я хочу сказать?
С третьим.
Я хочу сказать следующее.
Денис, ты понимаешь, какой проф там есть?
Ну, не знаю.
Можно сказать, что просто не делится.
Ну да, можно, например, так сказать.
Типа да, действительно.
Давайте посмотрим, что будет, если их разделить друг на друга, да.
Да.
Вот типа.
Почему делится?
Потому что по алгоритме расширенной, я могу сделать расширенные алгоритмы в клида, да.
Значит, у меня один из нодов представляется в виде ах исходной на плюс бу, да.
Да.
Значит, он тоже должен делиться вот на этот нод.
С, да.
С делится на этот С.
Б делится на этот С.
Значит, и это делится.
Вот.
Ну, тогда что?
Давай разделим.
Тогда что я получу?
Так я получу вектор единичной длины, у которого угол ни 0, ни 90, ни 180, ни 270.
Это противоречие.
Вот на самом деле, вот этот момент с тем, что у нас есть расширенный алгоритм в клида, он на самом деле ключевой.
Потому что есть такие странные случаи.
Например, можно запускать в клида не только для полей, да.
Ну, и для колец каких-то некоторых хороших, да.
А, например, можно определять многочлены в кольцах.
То есть, ну, например, рассматривать только целочисленные многочлены.
Вот.
Типа, ну, например, х квадрат, рассмотреть, да, и 2.
Вот, например, если мы, типа, определили в расценах числа, они х квадрат на 2 делятся, а в целых, типа, они и делятся.
Ну, потому что 2, ну, на шее недавно уже у меня будет старший коэффициент четным.
Очевидно, да.
Но у них вполне можно определить нод, да.
Он вполне, типа, есть алгоритмы, которые его вычисляют.
Но при этом, типа, у нас никакой простотии речи быть не может, ну, основной термин арифметики.
Потому что у нас не работает расширенный алгоритм нефклида и все такое.
Ну, тут расширенный алгоритм нефклида работает.
Короче, и отсюда можно вывести, соответственно, и лему архимеда, насколько я помню.
Это когда у нас AB делится на P, значит, одно из них делится на P, да.
А значит, у нас работает основная термин арифметики.
Ну, короче, круто.
А есть ли у нас, кажется, область целостности?
Короче, иди нафиг.
Ну, конечно, у нас все поняли, или если внуля, то у нас все хорошо будет, или не будет ничего хорошего.
А, ты про это?
Ты вот имел в виду с нодами или с…
Конечно, если у нас…
Да, можно.
Да, да, ноды можно вычислять в каких-то случаях, можно.
Но тут, да, то есть тут никакой, типа, расширенного алгоритма нефклида и речи быть не может.
Ну, типа, давай, например, вот тут, типа, как…
Что?
Ну, если у тебя исходный алгоритм у тебя не работает, там нужен модифицированный EF-клит.
То есть для многочленов.
То есть, например, вот ты x² 2 никак не вычислишь, да.
Там какая идея? Там, типа, идея в том, чтобы сказать, что…
Ну, давай x² плюс 1, да, будет, бог с ним.
Там, типа, идея какая?
Если у тебя этот многочлен не делится на x, то там можно показать, что в любом кольце, у тебя, типа, эту штуку можно домножить на x, у тебя нод не изменится.
Ну, типа, после домножения у тебя будет что-то вроде x² нод 2x².
Ну, и давай, типа, вот для этих старших коэффициентов начнем фигачить алгоритм EF-клита.
Ну, это то же самое вы, наверное, делали на линейной алгебре, когда рассматривали системы целочисленных факторов.
Мы рассматривали.
Вот, ну, типа, алгоритм такой.
Давайте просто, типа, вот из этого вычтем это.
Ну, тут два раза.
Ну, давайте просто, что-то тройка была, да, например.
Тогда вот мы отсюда вот это вычтем.
Получается, типа, x² плюс 1, 2x².
Ну, и потом, типа, дальше алгоритм EF-клита тут.
Ну, понятно.
Вот, и дальше мы, типа, смогли сократить одну из степеней.
Как бы он закончится у вас когда-нибудь.
Но при этом, так как вы тут сделали такой вот лайфхак, да, можно сказать,
который тут казался клевым для вычтения нода, вы домножили на x²,
то у вас сломался расширенный алгоритм EF-клита.
Потому что там надо было с этой точечкой в центре разделить на x².
Это не всегда возможно.
Как-то так.
Ну, давайте про применение алгоритма.
Ну, первое применение алгоритма EF-клита для гауссовых чисел понятно.
Давайте что-нибудь более простое.
Давайте что-нибудь простенькое предложу.
Давайте вот сейчас я приведу доказательства всем известного факта,
которые вы в школе еще доказывали, но вместе с ним приведу алгоритм.
Доказательства того, что если у вас P имеет вид 4k плюс 1,
простого числа P, то...
Да, но не делится на 2.
Да, но не делится на 2.
Во-вторых, типа, x² плюс y² найдутся такие целые x и y,
что x² плюс y² меняется P.
Вот мы сейчас типа...
Это факт, да, его все, я думаю, знают, все умеют доказывать,
но мы сейчас, типа, найдем алгоритм, как их искать за отлаг P.
Вот, придумал вчера ночью.
Ну, это реально забавно.
Окей, ну как мы это будем доказывать?
Доказывать будем по индукции.
Почему бы нет?
Ну, во-первых, что надо понимать?
Давайте про эту штуку еще поймем.
Заметим, что это просто x плюс y и умножить на x минус y и.
Уминус y и.
Ага.
Хорошо, но это просто какой-то z, но умножить на z сопряженное.
Хорошо, то есть у нас, типа, утверждается, что на самом деле
каждое простое число вида 4k плюс 1, но у нас перестало быть простым здесь.
Окей.
Отсюда следует мультипликативность наличия решений, например.
Ну, пока что это вроде бы нам не надо особо.
Давайте, да, давайте пока это не делать.
Хорошо.
Или надо.
Нет, не надо.
Хорошо, вот пускай мы встретили простое число.
Оно имеет вид 4k плюс 3.
Там решений нет, очевидно, по модуле 4 посочетали.
Встретили новое число p.
Равное 4k плюс 1.
А, смотрите, тогда еще я сейчас сделаю.
Я скажу, что у меня существуют такие x и y, что x квадрат плюс y квадрат
равняется нулю, но только по модулю p.
То есть почти то, что надо.
Ну, например, p квадрат и 0 квадрат.
Нет, вот мне вот тут важный нюанс.
Мне надо не p квадрат, а кроть не тривиальную штуку.
Ну, например, если 4k плюс 1, то у меня же существует
коронизация единички, например, да?
Ну, значит, я могу типа тут выбрать какое-то, ну, типа единичку
плюс x квадрат, например, так.
Такой в принципе подойдет.
А теперь, и при этом я x могу выбрать так.
Я могу тут поставить либо x, либо минус x.
Либо x, либо минус x.
Я при этом могу считать, что x у меня абсолютно не превосходит
p минус 1 пополам.
Окей, давайте посмотрим, что у меня получится тогда, если я сделаю просто равенство.
В просто равенстве у меня получится 1 плюс x квадрат равняется p умножить на k.
Где k у меня не превосходит, p минус 1 поделить на 4, например, да?
Ну, короче, он меньше p.
Это самое важное, что нам тут надо.
Я вроде не обманываю.
Ну, плюс 1 p, наверное, да.
Ну, короче, он меньше p будет строго.
Я вот это хочу сказать.
И при этом не будет равняться 0.
Ну, тогда смотрите, что получается.
Вот мы нашли какой-то делитель.
То есть мы знаем, что x плюс i на x минус i.
Ну, x плюс i на x минус i.
Ну, x плюс i на x минус i у нас равняется pk.
Ну, хорошо.
Давайте тогда рассмотрим x плюс i.
Как он?
Ну, давайте рассмотрим тогда, вот тут сюда перейдем.
Давайте рассмотрим нода x плюс i и p.
Какие могут быть случаи?
Ну, во-первых, он пр-шки точно не равен.
Во-вторых, он может быть равняться либо...
Что, давайте предположим, что у p нет решений, например.
Или нет, не надо это предполагать.
Не-не-не, стоп, сейчас.
Сейчас надо аккуратно это сделать.
x плюс i, x минус i, да.
Видимо.
Давайте сейчас сделаем.
А нет, все.
Окей, x плюс i.
Что надо сделать?
Короче, идея...
Короче, давайте алгоритм.
Алгоритм заключается в том, что вот это число всегда будет, типа, решением.
Чего мы делаем?
Сейчас мы доказываем, что для любого простого p существуют такие штуки
и находим алгоритм, который за lockpake находят.
Вообще, на самом деле, алгоритм заключается в том,
что если мы такой нод вычислим, то мы уже получим нужное решение.
Вот сейчас надо это аккуратненько запров...
Ты же x еще не нашел.
Нет, так я x могу вот тут найти.
Вычисляем как нод на x?
Ну, например, да.
Не надо просто из минус 1 вычислить корень.
А, в плане ты берешь вот x оттуда.
Да-да, я же x могу найти.
Ладно.
Вот, но идея в том, что вот это краски будет, типа, делителем p.
Не тривиальным.
Как это доказать?
Давайте подумаем.
Хорошо, давайте, во-первых, посмотрим на модуль.
x плюс i.
Но это очевидно x квадрат плюс 1.
Но это равно p, да?
Фигня какая-то.
Так.
Так.
Сейчас все будет.
А, ну давайте, типа, что заметим?
Что вот эта штука, она нервна...
Давайте закажем, что она нервна 1.
Почему она нервна 1?
Потому что, если я рассмотрю, тогда нод x...
Я просто докажу это.
Что?
x минус i?
Тогда, типа, смотри, если у меня эта штука...
Представляешь, что эта штука равна 1, да?
Тогда у меня вот эта штука тоже равна 1.
Почему?
Почему это так?
Потому что у тебя, типа, это то же самое, что...
Смысл, у тебя они сопряженные.
Если у тебя есть какой-то общий делитель у сопряженных,
то давай его сопряжен...
Ну, это...
x плюс z на самом деле с сопряженными к x плюс z.
А p это сопряженная к p.
Потому что p целая.
Ну и давайте 또 заметим, что если у тебя тут есть какой-то делитель общий,
то мы его можем сопрячь
и получить делитель с таким же модулем здесь.
И наоборот...
Туда и сюда, окей?
Сейчас мы сейчас для произвольного x проверяем, что x² плюс 1 не делится на p с помощью нода.
Смотри, давай, вот ты тут пропустил немного.
Мы нашли пару 1, мы нашли такой x, что 1 плюс x² делится на p.
Такой мы можем найти залог p.
Хорошо, теперь я рассматриваю, тогда смотри, у меня 1 плюс x² это p умножить на k.
Вот я утверждаю, что можно рассмотреть нод x плюс i и p.
И я хочу сейчас доказать, что он как раз-таки будет по модулю равен x² плюс 1 будет ровно p.
Сейчас, нет, не то сказал.
Смотри, я как-то фигню сказал.
Я нашел 1 плюс x², которое делится на p.
Вот это k у меня, можно считать, он меньше p.
Что я хочу сделать?
Я хочу вычислить вот такую штуку x плюс i и нод p.
Она у меня будет равна какому-то комплексному числу.
a плюс bi.
Окей?
Вот я сейчас хочу доказать, что вот на самом деле вот это число, оно типа по модулю,
по норме, оно будет давать p.
То есть a² плюс b² будет равняться ровно p.
Вот цель у меня сейчас такая.
Ну хорошо, давай предположим, что он равен 1, да?
Пускай у меня случай фиговый.
Тогда у меня эта штука равна 1.
Не знаю, что у меня произошло.
У меня x плюс i взаимно просто с p.
x минус i взаимно просто с p.
Ну тогда их произведение взаимно просто с p, да?
Все такое.
Ну типа тут через Euclid можно это доказать.
Упражнение на теорию чисел.
Вот, с другой стороны оно может равняться p, да?
Точнее даже не так.
С другой стороны его норма может равняться, да,
его норма, она может равняться либо 1, либо p, либо p², да?
Пускай она равняется p².
Либо ещики, либо p, либо p²?
Да.
Ну понятно почему.
Потому что у тебя делимость чисел,
из нее следует делимость их, соответственно, норм.
Ну потому что у тебя типа ab это
норма a, потому что нормa b.
Вот, ровно из этого, да?
То есть ровно из этого следует, что у меня тут норма,
она может быть равна либо ещики, либо p, либо p².
В случае, когда норма равна ещике,
у меня отселся.
Я хочу сейчас отсеть, когда норма равна равняется p².
Ну это что значит?
Это значит...
Это значит, что...
Ну может быть сейчас...
Ну если у того норма p²...
Да, да, все, да, да, все.
Действительно, у сопряженного тоже будет норма p², да?
Ну тогда типа что будет?
Будет произведением норма p².
У их произведения...
Сейчас, произведение вот этих нодов, да?
А, да, то есть это значит, что у нас x плюс i норма,
она как минимум p², да?
x минус i как минимум норма p-square, да?
Так...
А это значит, что мы получили претворечие вот здесь.
Да? Ты это имел в виду?
Все, конец.
Значит, мы доказали, что норма равняется p у этой штуки.
Давайте заметим, что это значит,
что мы нашли решение уравнения x²,
потому что y² равно p.
Как вам фокус?
Не очень?
А если у них норма...
Представим, что у них норма у обоих по p.
Нет, не может быть. Я рассмотрю k меньше p.
А сейчас, у обоих по p?
У x плюс i и x минус i.
Ты это имеешь в виду?
Сейчас...
Короче, что у них норма
из самой штуки,
она очевидна больше
либо равна норме нода,
ее и его с чем угодно.
Сейчас, что ты имеешь в виду?
Я утверждаю,
что у меня нода ab
обязан быть делителем
нормы a.
Я хочу сказать,
что тогда у нас норма x плюс i...
Но x плюс i может быть любой,
я рассматриваю только ноды x плюс i и p.
Просто она у нас хотя бы p,
у x минус i норма такая же,
то есть хотя бы p,
и у их произведения получается норма
хотя бы p квадратка,
у нас правое число меньше,
а правое у нас норма...
А, ну все, все.
Так, давайте...
У меня есть подозрение,
что люди записи вообще ничего не поняли.
У меня подозрение,
что мы не вывели случайно,
что ворона 1.
Нет, мы рассматривали ноды,
все окей.
Да.
Да, давайте еще раз повторю доказательства
и алгоритмы.
Все сходится.
Мы можем за от лакп...
Кстати, да, за от лакп
можно не...
Ладно, тоже равномизированный есть алгоритм,
но он приятнее, пофиг.
Можно вычислить x такой,
что x квадрат сравним с минус 1
по модулю p.
Потому что у нас p имеет...
Хорошо, ну тогда у нас 1 плюс x квадрат,
мы можем также считать,
что x меньше равен половинке p,
а значит эта штука будет равна
p на k,
где k меньше, чем
соответственно p
строго.
Ну тогда идея в чем?
Идея в том, чтобы сказать, что это 1 плюс x
и это 1 минус x.
Да, нет, я просто повторяю,
потому что, мне кажется, на камере
вообще ничего не понятно.
Он сказал, что что-то добавит, 100%.
Он сказал, что что-то добавит,
и мне кажется, вот это захочет.
Пусть он лучше добавит это, чем
галилы сейфирасы.
Ну да.
Вот, ну и типа...
И тут мы какому противоречию приходили?
Мы просто смотрели на
1 плюс x и p.
И 1 плюс...
Минус...
Господи.
Все правильно делаю.
И p. И типа дальше мы смотрели,
у них норма одинаковой должна быть,
и она может быть равна либо 1, либо p, либо p в квадрате,
потому что это делитель p.
И дальше мы отменили случай 1,
p в квадрате остается только случай, когда норма тут равна p.
А это значит, что вот как раз вот это число
галсова, оно дает нам решение
x квадрат просто y квадрат равно p. Конец.
Вот, все.
Это все, что касается
алгоритма Ивклида. Я вроде бы
все, что хотел
рассказал. По алгоритму Ивклида
наконец-то все.
Вот, а дальше
я не знаю, насколько это вам интересно будет.
Типа
мультипликативные функции
свертки Деркли. Но кажется,
все и так знают уже, когда школьниками были.
Что нет.
Вот.
Расширенные алгоритмы Ивклида рассказали полностью.
Галсовые числа рассказали.
И расширение пленомов рассказали.
Все, остается только мультипликативные функции тогда.
Я думаю, это можно сделать все
после третьего перерыва
или второго.
Мы Ленин Рештоф рассказали. Сейчас будет его применение.
Некоторое. Там
еще пару технических нюансов задену.
Потому что это
Ленин Рештоф придется немного модифицировать,
чтобы быстро все вычислять. Ну и нормально.
Ну типа тут для
участников
ACPC там ничего. Нового не будет
особо. Ну и для тех, кто тайников посещал.
Но
ACPC иметься в виду 1 и 2 и там
1 и 4.
Скорее всего все знают. Ну типа
для тех, кто олимпиадами
не сильно занимался, я думаю, это будет полезно.
Так что я это все-таки проговорю.
Все будет ок. Давайте
ведем определение мультипликативной функции.
Вот у нас F
будет называться мультипликативной.
Тогда и только тогда,
когда для любых
взаимнопростых чисел A и B
выполняется
F от A
B равняется
F от A умножить на F от B.
Ну как-то так.
Окей. Какие есть примеры
мультипликативных функций? Давайте
самые базовые примеры проведем.
Вот функция умножения.
Вообще гениальная функция.
Нет, ну хорошо. Есть типа
давайте совсем
есть функция ID, например,
которая просто
возвращает нам то же самое число N.
Ну она очевидно мультипликативная.
Несколько могу посудить.
Вот.
Key есть еще. Есть, например, функция,
которая у нас
называется Noxiat1.
Это индикатор единички. То есть она
возвращает единичку,
если у нас N равна 1
и 0 в ином случае.
Корень. Ну корень степенные
функции. Ну не хочется рассматривать. Мы все-таки хотим
какие-то коммедаторы решать.
Вообще да, в принципе, там любая функция, типа N
степени альфы подходит, наверное.
Вот. Но мы такие рассматривать не будем.
Например, еще есть
функция, которая всегда единичку возвращает.
Какая-то константа.
1. Она тоже у нас мультипликативная.
Ну и давайте наконец
до сложного примера доберемся. Я думаю
многие знакомы с функцией Эллера.
Которая определяется как...
Она у нас была.
Она у нас была, да?
Да, конечно.
Окей. Давайте напомним, что вопрос
количества
k, N. Количество k таких, что
k, N, взаимнопросто, где k, типа у нас
от 1 до N.
У нас даже сверх, где все было.
Даже так, да?
Не у всех.
Нет, у всех. В первом семестре
комбы.
Сейчас.
Либо я не понимаю, что у нас сейчас сразу сверх,
либо я... Кстати, камера
второй доску записывает.
Полностью.
Ну хорошо, давайте напомним.
Я думаю, не страшно.
Ну окей.
Хорошо.
Давайте какие-то менее тривиальные примеры, которые
возможно
неподготовленный слушатель не знает.
Например, есть такая функция замечательная.
Мы возможно даже докажем,
что она, типа, мультипликативная.
Например, такая забавная функция. Мы суммируем k
от 1 до N и суммируем
значение нода k, N.
Радикал, кажется, мультипликативный.
Радикал, да.
И давайте прям совсем
какой-то жесткий пример проведу.
Возможно, мы им, кстати, воспользуемся.
Возможно, нет. Ну короче, типа, мы там
обсуждали галосовый число, но на самом деле
функция, которая
равняется одной четвертой
от количества решений уравнения
х квадратов
н,
тоже является
мультипликативной.
Но это вроде бы очевидно.
Ну, типа, кто хочет доказать,
это я к чему привожу, к тому, что
мультипликативных функций, ну, их, типа, много.
То есть всякие разные бывают, всякие
веселые. Давайте научимся их быстро вычислять
для чисел от 1 до N.
Ну,
например,
функцию
вычислим фиата.
Вот, а перед этим надо кое-что понять про них.
Про мультипликтивные функции верен, по сути,
один и тот же факт.
Тут мы говорим, что мы можем функцию разложить
на произведении двух функций за именно простыми
аргументами. Но вот если у нас известна
факторизация числа n,
то что мы можем сделать? Ну, по сути, мы же можем
просто взять эту функцию, расписать как
f от p 1
k 1, так далее,
f от p mt в степени
k mt.
И, то есть, по факту, если мы знаем, как
ведет себя функция в каждой такой
точке в степени простого числа,
то мы знаем, какая функция у нас в принципе задана.
Окей.
Ну, давайте, например, сделаем это для функции
фи. Для функции фи все вроде бы очевидно, да?
Типа там
фи, если мы туда подставим сначала 1, потом
p, потом p в квадрате, так далее.
А что мы получим? Мы получим
1, тут мы получим
p-1, ну и дальше мы получим, понятно
дело, p в квадрате
минус p, p в
кубе минус p в квадрате, ну и так далее.
Собственно, как предлагается считать?
Вот как предлагается это все дело считать?
Предлагается для начала
выделить простые числа,
что кажется логичным, потом
хочется
взять и
для них как-то формулы посчитать, а потом
с помощью линейного решта как-то научиться быстро
раскладывать число
вида n на 2 взаимопростых делителя.
Но вот оказывается, что
этого делать не надо, можно просто немного модифицировать
алгоритм линейного решта, и тогда
оно все будет хорошо. Что я конкретно предлагаю
сделать?
Я предлагаю,
ну давайте его заведем, собственно у нас
будет вектор v'
v' это вектор int,
у нас там будет
не знаю, minp, без оптимизации каких-либо
серьезных.
Как у нас выглядел алгоритм?
Мы, собственно, проверяли, что у нас число
простое, во-первых, мы могли вот так
делать, если не minp
от i, то мы понимали, что оно простое.
Собственно, раньше мы просто помещали, что
i равно i, но сейчас давайте сделаем
кое-что посложнее, давайте
возьмем и сразу посчитаем
нашу функцию, ну в данном случае
функцию l для всех значений
вида i, и в квадрате, и в кубе
и так далее.
То есть тут мы заполняем
значения вида
phi
и в каты, вот для всех таких значений
что-то мы пишем.
Ну для функции l
соответственно понятно, что мы пишем pfk и
minus p, да, для каждой
такой степени.
Сейчас, что, нет, pospfk в
minus pfk и minus 1, окей, ладно,
я, наверное, говорился, вот, но это делается
просто обычным фурориком, я думаю, вы справитесь.
Дальше мы что делали, мы перебирали
простое число, на которое надо множить,
оно у нас лежало вектор и праймс
и у нас были какие-то
ифы на ограничение сверху, что у нас, типа
g должно быть меньше, чем minus pi
и у нас было ограничение, что
p, ну и что оно еще
g на i меньше n,
меньше равно n. Ну хорошо, вот мы это
пускай все заефали, дальше, что мы делаем тут?
Тут предлагается
во-первых
делать g,
рассматривать только g, который меньше, чем
minus pi, то есть это я вот тут
пропишу отдельно, g меньше, чем
minus pi.
И
еще одним внутренним
фурориком,
то есть
мы будем перебирать степень g,
на который мы домножим наше число i.
То есть мы будем как бы
вот тут записывать значение
phi вида i
умножить на g вкатый.
То есть у нас будет 3 вложенных фурорика.
Почему мы делаем так? Ну можно было
действительно как-то поиграться,
предпосчитать там разложения такие,
но в принципе достаточно просто делается.
Но вот такой подход он позволяет нам
использовать от
единички дополнительной памяти.
Ну по сравнению с линейным рэштоном, естественно,
то что мы линейный рэштон написали, нам это придется сделать,
нам придется завести массив
обязательно значение phi.
Но при этом
мы смогли как бы
никакие другие данные
не использовать в памяти.
И у нас все хорошо.
Но это вроде бы плюс-минус очевидно.
На самом деле есть ощущение, что
можно...
Есть ощущение, что возникает какая-то
копипаста в случае, когда у нас
i вкатый и когда у нас g вкатый.
Нет, смотри, тут копипасты нет, потому что
и вкатый, тут конкретно ты прописываешь значение.
А тут ты будешь
прописывать...
Да, ты можешь прописать и умножить на это значение,
а можно написать, что мы просто
сюда помещаем значение
phi, а ты... Я могу посчитать phi
от единицы как фиктивное значение.
Или нефиктивное,
оно один.
А потом g вкатый
оно будет домножаться на то же самое, но чтобы
домножалось i вкатый.
Оно будет домножаться на то же самое p вкатый
минус p вкатый минус 1.
И условно для пересчета
видимо можно что-то...
Тут можно придумать, но я предлагаю вот так
перерасчитывать phi i на phi g вкатый, чтобы
заново формулы просто не писать.
Но в принципе можно так, да.
Нет, тут на самом деле фиговые ситуации выходят.
Вот тут можно либо...
Что еще сделать? Либо тут можно
вот тут сделать какой-то грязный хак,
чтобы сказать, что если g у нас оказалась равно i,
то давайте там
заведем кому-нибудь еще
t, с которой мы на самом деле будем
обновляться. Ей просто вам единичку, изначально
будет i. В общем можно делать...
Там будет единичка, phi от одного будет у нас.
Окей.
Нет, нормально, да.
Ну, как-то так. Но идея примерно какая-то такая.
В принципе копипаста тут не страшна.
Копипаста, она, как известно, на скорость работы
не влияет.
Окей.
Вот.
Ну, хорошо. Это вот первый подкод.
И так, естественно, можно считать
все мультипликативные функции на самом деле.
То есть там для значения
от 1 до n. Можно phi посчитать, можно rad
посчитать, можно вот такую странную функцию
посчитать. Все круто, все работает, плюс-минус очевидно
почему. Вот. Есть еще один метод.
Он такой уже
более предлоговатый.
Вот это если у нас просто мы получили
свирку массив праймс.
И у нас
никакого линейного решета не было.
Но тогда идея в том, что мы можем
просто рекрусивно перебрать все числа,
зная их факторизацию.
Это будет работать точно так же, как этот форик.
Ну, просто без
допамяти.
То есть там будет допамяти от log n числа
на хранение стека вызовов.
Окей.
Ну, что?
Ну, давайте
будем как-нибудь ручками доказывать, что
g-a-t у нас она мультипликативная.
Давайте
докажем. Давайте докажем.
Хорошо. Вот пускай у нас.
Ну, про остальные понятно, я думаю.
Rad тоже понятно.
f-a-t мы...
f-a-t, ну,
что-то не хочется доказывать.
Ну, там любители галовских чисел
могут доказать. Ну, давайте это сделаем.
Вот g-a-t.
Во-первых, я сделаю такую страшную вещь.
Я
переделаю суммирование
не от 1 до n, а от 0
до n-1.
Ну, почему бы нет?
Дальше.
Ну, и тут у нас g-a-t.
Ну, какая идея?
Идея в том, что я могу
эту сумму переписать.
Я могу перебрать... Вот у меня
если n равняется a-b.
По китайской теории
время об остатках я могу k перебрать
либо просто k, либо остаток
определений на a и остаток определений на b.
Соответственно, пускай число x, y.
То есть x, a, in, z,
a,
y, in, z, b.
Вот.
Из x, y у меня однозначно
устанавливается k, например.
Логично. Ну, тогда чему будет
равен нод k, n?
Ну,
легко показать, что
у нас будет равен просто произведению,
собственно,
x, n на y, n.
Ну,
а точнее не так, не-не-не, вру.
x, a на y, b.
Ну, почему
так? Ну, потому что...
Ну, понятно, потому что, типа, если у нас
есть какие-то делители простые у а, то там
именно от остатка x будет зависеть,
типа, делится или не делится.
Ну, и соответственно, также с простыми
делителями числа b.
Ну, и дальше, типа,
тут просто у нас еще суммирование,
суммирование, перемножение. Понятно, что это просто
перемножение вот таких вот сумм.
Сумма по x, x,
сумма по y,
z, b.
Ну, и дальше, я думаю, вы понимаете, что
это просто g от a,
а это g от b.
Как-то так.
Вот. Ну, это такое вот...
Простенькое применение мультипликативных функций,
что они вот бывают такие странненькие,
новенькие, они с нодами очень хорошо дружат,
очень хорошо дружат с делителями. А, ну, кстати,
еще на тему делителей можно
еще докинуть очень много функций
связанных с делителями, да, типа,
sigma 0
от n, типа, количество делителей,
sigma 1 от n,
сумма делителей.
Ну, и типа
sigma квадрат, например, я думаю, остановлюсь
на этом. Это сумма квадратов.
Типа...
Ну, в принципе, упражнение
для читателя, да, то есть типа там сумма по делителям
точно так же делается, так типа у нас каждый делитель
n, он будет формироваться как делитель a
умножить на делитель b. И там поэтому все
эти суммы квадратов, да. А давайте так
запишу.
Как в анекдоте.
Если я попрошу, что такое sigma 3t?
Ну, это
сложный вопрос, на который надо читателю
будет найти ответ самостоятельно.
Ну вот, как-то так. То есть
мультипликативных функций в принципе много,
вот у нас есть алгоритм для их решения, но
у этого алгоритма есть
такая вот некоторая проблема.
Он
ищет от 1 до n
все числа, а вот если мы хотим
не все значения узнать, а просто сумму
от 1 до n, ну, тогда этот алгоритм у нас
работает
за линейное время, ну, и кажется, что
не особо можно его как-то ускорить, но оказывается,
что все-таки для некоторых мультипликативных функций
можно вычислить, делать вычисления быстрее.
Так.
Давайте
обсудим свертку
Dirichlet.
Она была у вас вроде бы, но я просто напомню,
что это такое.
Так, Dirichlet, надо большую букву написать,
Имиша, уважаемого человека,
между прочим.
Как она обозначается?
Ну, собственно, представим, что у нас есть две функции f и g.
Сверткой Dirichlet
этих двух функций
будет называться новая функция,
f,
которая в точке n у нас будет равна
сумме по всем парам
a умножить на a и b,
которые в произведении дают n,
f от a умножить на g от b.
Вот такая
функция.
Окей.
Что оказывается у нас?
Оказывается, что
у нас эта операция
сверткой Dirichlet коммутативная,
что она у нас клево дружит с умножением.
И еще оказывается, что
она дает всегда мультипликативную функцию.
Это будем профайть
или это у вас было все-таки?
Вряд ли у всех точно.
Давайте за профайем.
Я думаю, тут не лишним будет.
Давайте представим, что у нас
мы хотим вычислить f от g,
x и y взаимно просто.
Кстати, вот тут взаимная простота не требуется.
То есть если условие у нас требовало взаимной простоты,
тут она не обязательно.
Просто а умножить на b равно n.
Только такой интересует. Окей.
Ну хорошо.
Тогда что тут получается? f на g от x и y.
Давайте это распишем.
У нас получится что?
У нас сумма по всем a умножить на b
равным x и y
ведет суммирование f от a
и g от b.
Ну замечательно.
Давайте теперь
заметим вот что. x и y взаимно просто.
Значит a можно разделить на два множества.
Один из которых будет делителем x,
а другой будет делителем y.
Ну и что тогда получится?
Тогда получится у нас следующее.
f от a,
x.
Давайте тут я
сделаю g от
b,
x.
Потом за письмом
будет делителем
f от a,
x.
Давайте тут я
сделаю g
g от bx, потом запишу, потом запишу f от ay, извиняюсь, и g от by, что я получил?
Ну, я получил 1 множитель, 2 множитель, этот множитель зависит только от элементов первой суммы,
а этот множитель только от элементов второй, ну, значит, эта двойная сумма не есть что иное
как произведение двух сумм. Соответственно, сумма по ax, bx равным x, f от ax, g от bx.
Ну, я думаю, на самом деле вы понимаете, что это просто свертка дирекле в точке x.
Ну, и тут давайте прям так сразу запишем, мне как-то лень это переписывать.
f от g свертка в точке y. Ну, это в точке, соответственно, x.
Ну, как бы вот, всю мультипрокативность доказали, то есть просто порасписывать суммы.
Как-то так. Вот окажется, что для вычисления префиксных сумм, ну, сумм значений мультипрокативных функций
свертка дирекле будет играть ключевое значение, поэтому давайте вот немного поподготовимся к этому моменту
и попытаемся как-то попредставлять наши функции в виде соответствующих сверток дирекле.
Ну, например, давайте возьмем… Что возьмем?
Давайте, например, возьмем phi и рассмотрим ее свертку с id.
phi id. Что тогда получится?
Тогда у нас получится сумма по всем… Давайте так.
Давайте так напишу. По всем делителям n phi от d умножить на n поделить на d.
Собственно, что это такое? Что это за сумма такая? Ну, она что-то там суммирует, да?
Но это не мебелось, ни фига нет.
Это… Давайте вот посмотрим. Я думаю, вы угадаете, что это за функция.
Ну, смотрите. Вот phi от n он умножил на единичку, да?
Давайте представим, что у нас… Давайте phi от 6 посчитаем.
Вот давайте в точке 6 посчитаем, да?
Если мы в точке 6 считаем, то что у нас получается?
У нас получается phi от 6 он умножил на… 6 поделить на 6.
Плюс там, не знаю, phi от 3 он посчитал, умножил на, например…
Давайте это единичка phi от 6.
Просто n.
Нет, n поделить на d.
Плюс 2 на 3.
И плюс phi от 6, наконец, он посчитал, умножил один раз, да?
Ну, давайте попытаемся дать смысл этой фигни.
Да, просто сумма всех фишек она просто id дает, да.
Но это чуть посложнее.
Вот, ну давайте посмотрим.
Ну, типа у нас оно каждое взаимопростое число с 6, оно умножило на 1.
А потом, вот что такое phi от 2, например?
Ну, это то же самое, что phi от 6 поделить на 3, да?
А это что такое?
Это по сути количество чисел, которые имеют с 6 нот равный 3.
Мы их умножили, соответственно, на 3.
phi от 3 – это количество чисел от нота 6, которые имеют с 6 нот равным, соответственно, 2.
Это мат ожидания нода.
Умноженные на n, то есть просто сумму нотов.
То есть это просто функция g от n у нас.
В данном случае у нас вышла функция g от n.
Например, так.
Вот, и в принципе, так как мы знаем уже этот факт, что g – это просто…
Давайте так запишу.
Это просто g получится.
Тут это в точке n, но я думаю, вы понимаете, что я имею в виду.
То есть мы уже из этого факта, например, могли бы не доказывать, что g мультипликативная.
Ну, прикольно.
То есть это такой способ получать новую мультипликативную функцию.
Ну, давайте еще что-нибудь сделаем.
Давайте еще скажем пару очевидных слов.
Наверное, мы хотим, очевидно, чтобы в мультипликативной функции у нас f от 1 равнялся 1, иначе бред получается, верно?
Ну, a и b я могу поставить равными 1, да?
Тогда у меня f от 1 должно равняться f от 1 в квадрате.
Понятно, что еще 0 подходит, но давайте 0 не учитывать, он какой-то странный.
Можно еще поговорить про обратимость.
И вот оказывается, что все функции, они относительно свертки и диреклей обратимы.
То есть для любой функции мультипликативной существует такая функция g, что f от g равняется нейтральному элементу.
Ну, вот что такое у нас нейтральный элемент относительно свертки и диреклей?
Вот может показаться, что это единичка либо id, но вот оказывается, что это не так, и оказывается, что это просто f от 1.
Почему это так, я думаю, понятно.
В принципе, у нас в этой сумме, если бы у нас тут была f от 1, например, f от n поделить на d,
то у нас бы ровно одно слагаемое было бы не нулевым, равнялось единичке.
То есть это было бы слагаемое, которое бы тут получалось при d равном n.
Так что да.
Вот, доказывать это не будем, потому что зачем, это делается очевидно,
просто по индукции pn мы доказываем, что у нас существует значение в каждой точке.
Вот, что интересно, это наконец-то уже решать задачку какие-то, начать.
Да, ну вот про задачки там нужна функция мебельса, я как раз ее тут пропустил.
Это забавно.
Давайте ведем функцию мебельса.
Как мы начнем про додвигации, вот с функциями мебельса мы начнем уже суммирование функции,
объяснять эту технику.
Вот пускай у нас есть какая-то милотен.
Милотен такая достаточно простая функция, она будет определяется так, что
милот p равно минус единичка, а милот p вкатый, где k больше единичка, будет равняться нулю.
То есть такая функция, которая равна нулю, если у нас число делится на квадрат какого-то другого числа,
и равняется минус один степени количества простых делителей.
Вот, эта функция очень прикольная, она имеет какое-то большое значение в комбинаторике,
то есть во многих случаях она работает как будто бы как функция включения и исключения,
только в теории чисел, но мы пока этого сильно касаться не будем.
Вот оказывается, что как раз на ее примеры будет очень удобно считать все это дело.
Ну, мы ее пока что просто ввели, мы ее пока использовать не будем.
То есть такое вот ружье, заготовленное чеш, чеховское ружье.
Называется она функцией меблса.
До чеховского ружья, когда мы ее ввели посередине лекции, далеко.
Ну да, логично.
Ну вот я ее забыл типа.
Анти-чеховское.
Анти-чеховское, да.
Получается сланце, эре.
Ну хорошо, давайте префиксные суммы, основное равенство мы видим, и из него научимся все считать.
Префиксные суммы, давайте их обозначать вот так.
Обозначений тут каких-то общепринятых нет, поэтому буду пользоваться теми, которые мы хочу.
Но в течение префиксных сумм, например, удобно вот так обозначать.
То есть это будет сумма f от n, это будет просто f от 1, плюс так далее, плюс f от n.
Ну хорошо.
Вот давайте сделаем странную вещь.
Казалось бы, мы еще не умеем считать префиксные суммы для наших мультипликативных функций.
Ну на самом деле для каких-то умеем.
Для id умеем, например, для x1 умеем, для единички умеем.
Но для остальных как-то не получается.
Вот предложение такое.
Давайте мы сейчас ведем какое-то равенство для префиксных сумм и суммы и свертки диреклей,
и из этого научимся все считать.
Оно будет работать на нас в общем случае.
Вот пускай у нас мы рассматриваем свертку префиксной суммы, свертки phi и g от n.
Тогда чему будет равно ее значение?
Ну нам по-хорошему что надо сделать?
Надо перебирать k.
От 1 до n.
Потом перебирать ab, который равны k.
И соответственно просуммировать f от a на g от b.
Это можно сделать проще.
Давайте заметим, что мы перебираем k от 1 до n, потом перебираем ab равной k.
Но мы вместо этого могли бы просто перебирать пары ab, которые в произведении дают меньше либо равно n.
f от a, g от b.
Ну вроде плюс-минус логично.
Давайте дальше идти.
Теперь давайте вытащим из этой суммы a.
А у нас будет перебираться от 1 до n.
И мы будем суммировать что?
f от a можно вынести будет, да?
А теперь нас интересуют какие-то b.
А какие b можно k представить?
Давайте вот сейчас подумаем.
Но можно представить b равной единичке, наверное.
Двойки, тройки, ну и так далее.
Сколько это можно будет делать?
n поделить на a кругленно вниз.
Тоже логично.
Ну значит, а это что такое?
Давайте как сумму сначала нарисую, потом ее зачеркну и напишу по-нормальному.
То есть это будет сумма k от 1 до n поделить на a.
Ну дайте b.
g от b.
Ну это то же самое, что просто префиксная сумма g.
Давайте вот так ее запишем сразу.
То есть это будет умножить на...
Это будет все равно умножить на префиксную сумму g от n поделить на a.
Вот.
И оказывается, что это равенство, которое мы сейчас получили, оно получается достаточно просто, как вы видите.
Просто туда-сюда и готово.
Вот оказывается, что оно прям капец какое полезное.
Почему оно полезное?
Потому что значение n поделить на a у нас может быть не более чем 2 корень n различных штук.
Как это доказывается?
Я сейчас это докажу.
Нет, я знаю, что это очевидно, но я сейчас докажу картинкой, потому что нам еще кое-что понадобится.
Доказывайте.
Доказывайте, это очень просто.
Давайте нарисуем вот такую вот гиперболу.
Доказательство наглядное, если что.
Нарисуем такую вот гиперболу.
xy равно n.
Да вроде гипербола называется.
Или аллегория, я уже точно не помню.
Можно перевести в...
Вот это по-моему b от v.
Можно перевести, например, v от t.
Для чего-то.
И так оказывается.
Да, ну так.
Нет, шикарное доказательство, но ладно.
Под этой гиперболу у нас существуют какие-то столочисленные точки, на самом деле.
Вот тогда как эти точки устроены?
Вот тут у нас примерно есть то, что меньше корня, есть то, что больше.
Вот тогда у нас значение n поделить на a это что?
Это взять какую-то точку x и посмотреть, что находится в ближайшие точки под гиперболой.
Окей.
Вот тут их может...
Тогда как у нас гипербола выглядит?
Что у нас может тут в принципе стать вот такой вот точкой?
Ну точка может стать...
Мы можем попасть в эту точку, только если сверху от нее ничего нет.
Но давайте так еще скажем, что если у нас справа есть соседь точки,
то мы попадем именно в него.
Ну то есть если у нас тут есть какие-то подряд идущие точки,
то давайте скажем, что мы попадаем только в самую правую.
Ну да.
Такое вот накрытие точек под гиперболой минимальным количеством прямоугольников.
Вот.
То есть у нас раз точка появилась какая-то особенная.
Два.
Точка, в которую мы можем попасть.
Три.
Ну и давайте четыре.
Какие-то такие точки.
Вот.
Их очевидно не больше, чем два корня из n.
Ну почему так?
Потому что их до корня из n...
Ну давайте вот такую прямую проведем.
Вот их тут меньше корня из n и тут меньше, чем корня из n.
Окей.
Давайте, чтобы было чуть-чуть понятнее, я нарисую это все-таки лесенкой.
И покрупнее я попытаюсь.
Типа раз.
Два.
Три.
Четыре.
Пять.
Да.
Эта картинка, она у нас, кстати, будет симметричная.
Да.
Окей.
Хорошо.
А тогда вот получается, что функцию g префиксами нам надо будет считать только вот в каких-то этих точках.
В каких-то вот этих координатах.
Верно?
Теперь давайте подумаем, как можно вообще этим пользоваться.
Вот у нас n поделить на a, оно вообще-то принимает постоянные значения на каком-то отрезке a.
То есть какие нас префиксные суммы a интересуют?
Нас интересуют только те префиксные суммы a, при которых значение n поделить на a меняется.
Да.
Ну тогда смотрите, что это за значение?
Это значит, что если мы взяли точку какую-то, да, и вот прыгнули направо, то мы попали на следующую ступеньку.
Ну давайте заметим, что это все те же самые точки.
Окей.
То есть у нас есть некоторое множество чисел m от n, которые равняются всем возможным вариантам n поделить на k круглить вниз при натуральных k.
Ну включая 0, например, да, это неважно.
И получается, что нам префиксную сумму g надо будет вычислить в точках из мн.
И точке, и префиксной суммы f надо будет тоже вычислить в точках из этого множества.
И этого будет достаточно для вычисления функций в точке х-вертки, в точке n.
Ну, возможно, там нужно будет по плюс-минус 1.
Нет, нет, вот не будет, оказывается.
Оказывается, что не будет.
Ну типа смотри, давай на эту лестнику подробнее посмотрим, да, еще раз.
Вот типа ты смотришь на n равно 1, да.
Вот у тебя раз первый отрезок, вот у тебя первый отрезок, да.
Типа ты до m1 дошел.
Потом типа ты идешь до m2.
Вот, ну вот типа тебе нужна эта точка, вот минус префикс этих уже взятых.
Ну ты их уже вычислил, да.
Дальше ты идешь на следующую ступеньку.
Тут типа ну тебе опять нужен весь этот префикс, минус последний вычисленный точек и так далее.
То есть у тебя новых точек не возникает.
У тебя реально нужны только точки множества m от n.
Окей?
Вот это такой важный достаточно момент, о котором стоит упомянуть.
Вот, ну доказательства попростую.
Потому что вот картинка у нас такая, она симметричная, классная, прикольная.
Окей.
Хорошо, то есть мы свели вычисления phi на g, по сути, к корнюю z вычисления префиксных сумм для f и для g.
Пока что мы ну прям совсем мало сумм умеем считать.
Давайте так, что хоть что-нибудь нетривиально посчитаем.
И вот предлагается как раз начать с функции миобилса.
Так, Сев, это og g?
Вообще нет?
А, ты не слушал?
Окей, нормально.
Давайте с функции миобилса начнем.
Я думаю, я могу вот эту табличку функции стереть.
Там все посмотрели на функции, они красивые, классно.
Давайте функцию мио вычислим.
Вот для того, чтобы мио вычислить, нам нужно какое-то равенство относительно мио.
И вот я сейчас предлагаю взять равенство мио.
И тут надо подумать.
На ID, видимо.
И тогда я получу функцию х от единички.
Вот, утверждается так.
Но почему это так? Давайте проверим.
Х от единички это 1 в 1 и 0 в остальных.
Да.
Давайте проверим.
Мы уже знаем, что результат будет в мультипликативной функции,
поэтому надо посмотреть только то, что происходит в точках П степенника.
Хорошо, давайте рассмотрим.
Как будет вести себя мио в точках П степенника?
Она будет сначала давать единичку, потом минус единичку, потом 0, 0 и так далее.
Функция мио, она так определяется, да?
Это с нулевой степени.
Да, с нулевой степени, естественно.
Программисты все такое.
ID, 1.
А нет, стоп, не ID.
Не-не-не, ID наврал.
Нам нужна функция, которая постоянно единичка,
которая всегда единичку возвращает.
1, 1, 1 и так далее.
Это у нас единичка.
Но не удивительно.
Давайте, собственно, их вычислим.
Эти две функции замечательные.
Так, вот тут, чтобы вычислить 0, надо 1 на 1 умножить.
И все, готово.
Чтобы вычислить 2, надо 1 на 1 минус 1 на минус 1.
Ну окей, 0.
Тут вычисляем то же самое.
То же самое, везде получится 0, да?
То есть для того, чтобы нам какую-то единичку тут вычислить,
надо взять эту единичку, ну, на единичку,
а предыдущую на минус единичку, да?
Может и все будет ок.
X минус 1 может на 1 делить на X минус 1.
Ну, возможно, да.
Я, возможно, тупо объясняю, сорри.
Возможно.
Мне лень.
Мне лень разбираться, но как-то так это работает.
То есть мы действительно получаем het единички.
Окей, ну, в чем проблема?
То есть если мы совсем посмотрим на эту формулу пустыми глазами,
мы что увидим?
Мы увидим, что мы научились вычислять het единички,
префиксную сумму, уже звучит смешно, да?
Через вычисление функции мебиос,
префиксная сумма функции мебиоса
и префиксная сумма функции единички.
Ну, кажется, мы хотели сделать что-то наоборот,
но оказывается, что и в этом случае, в принципе, норма.
Почему так?
Ну, потому что давайте вот посмотрим
на вот эту сумму.
Давайте, что сделаем?
Давайте представим,
что n не равно единичка
и посмотрим, что получилось.
Я прямо это перепишу, наверное.
У нас при n больше единички.
У нас слева мы
получили нолик,
потому что свертка их равна het единички.
Нолик равен.
Почему нолик? Единичка?
Хет 1 тут. Мы
подставляем сюда вместо...
Сверх же.
Сумма сверта, это типа хет 1
плюс хет 2, плюс так далее.
Смотрим.
Да.
У нас мю на
1 равняется хе 1, да?
Да. Значит, это
префиксная сумма хе 1, верно?
Да. А это 1 сюда.
Да, кстати, это всегда 1.
Да, реально бомбанул.
А тут давайте...
Как будет удобнее
подставить, я думаю?
Ну, давайте у нас f это будет
функция единичка, да?
f это функция единичка будет.
А g это
у нас будет функция мю.
Окей, тогда какое мы
равенство получили? У нас
получается, что для каждого
такого значения сумма по a
равна n,
у нас дальше
будет f от a,
то есть это 1,
умножить на
сумму...
Нет, да, n поделить на a.
Вот так все будет. Все будет именно так.
Все нормально. Окей?
Окей. А что из этого
получим? Ну, давайте отсюда
вытащим сумму при
a равна единичка, то есть получаем
что у нас?
Сумма мю n
плюс сумма с a равна 2
по n.
Суммирование по
n поделить на a. Ничего
сложного, да? Ну, осталось только
заметить следующее, что
вот для вычисления
этой суммы нам надо
всего лишь-то вычислить
сумму мю
в корень из n точках.
Что вы рожаете?
А, ну понятно.
Собственно, сумму мю
в n точках надо вычислить
и умножить на какие-то константы,
потому что у нас эти значения будут все на какие-то
отрезки, которые мы можем вычислить.
Окей. Но проблема в том, что их надо
вычислить. Давайте возьмем да их вычислим их.
Рекурсивно. Рекурсивно. И давайте
делать минимализация.
Вот. А что оказывается?
Есть такое свойство, оно в принципе достаточно простое,
что n поделить на a
округлитнице, потом еще раз поделить на b,
это то же самое, что
n поделить на ab.
Отличное свойство. Нет, ну реально простое,
ну доказывается в одну срочку.
Как ты, но я это доказывал сначала плохо,
а потом хорошо. Вот.
Да, действительно,
это доказывается очень просто, и
оно нам гарантирует, что в рекурсивных
вызовах нам не потребуется вычислять
сумму мю в новых
точках. Да.
Ну и все, окей. Так давайте
оценим алгоритм, что ли.
За сколько он у нас будет работать?
Так.
Нам надо отдельно
посмотреть, в случае a меньше
корни из n, да? И больше.
А нет, не-не-не.
Хочется сначала расписать сумму, а потом уже...
Да-да, давайте, окей, давайте сумму.
Хорошо, вот у нас будет o от
суммы по m,
давайте, из m,
из mn, да?
Это те значения, которые у нас
возникнут, да? Да.
И что, каждую мы решаем, по сути, за o от корни
из n? За количество
делителей. Ой, ну да-да,
за корень. Нет, за корень. Никакого количества
делителей тут нет, да? Тут реально корень.
Хорошо.
Дальше что? Как эту сумму мы можем расписать?
Ну если типа m, который меньше корни из n?
Да, это типа что будет?
Это будет сумма k
от 1 до корня n?
Корни из k, да?
А тут
что будет? Тут будет сумма
от...
Вот чисто больше...
Не-не-не, пока что я
и близко оптимизировать
не хочу до n в степени 2 третьих,
поэтому уж так запишу,
так будет попроще.
Тут до корни z, и тут, соответственно, будет суммироваться
n поделить на k.
Но оказывается, что если мы это все
просуммируем, как-нибудь там проинтегрировали,
мы получим оценку n в
степени 3 четверти.
Ну что быстрее, чем o от n, да?
Это уже круто. То есть мы не зря делали всю эту фигню.
Вот, замечательно.
Но мы пока что вычислили
только mu.
Давайте посмотрим дальше, как мы, например,
можем вычислить значение phi.
Phi у нас чему уравняется?
Ну это у нас
чердмена как-то выражается, да,
насколько я помню?
Это id на mu, вроде как, насколько я помню.
Вот.
Вроде так.
Ну почему так? Ну давайте действительно посмотрим,
как у нас тогда будет выглядеть
свертки Dirichlet по определению.
Мы, типа, давайте переберем аргумент
при mu. Мы будем перебирать делители
n. Ну, естественно, можем считать, что только
свободно от квадратов, да?
И дальше мы, типа, вычтем из n все, которые
делятся на p1, потом все, которые делятся на p2,
на pk в этой свертке.
Потом, типа, мы возьмем, переберем
эти делители по 2 простые, их обратно
прибавим к своему. Короче говоря, получим формулу вкушения
исключения, которая, очевидно, считает значение функции phi.
Вот. Ну и, типа, что посмотрим?
ID мы умеем быстро считать? Ну умеем.
mu мы умеем считать? Ну уже умеем.
И более того, типа, нам mu
надо считать только вот в этих точках m от n.
Поэтому мы это отдельно сделали за n степень 3 четверть,
а потом можем отдельно считать за n
степень 3 четверть значение функции phi.
Ровно так же. Да, и на самом деле
так можно продолжать, что-то делать,
радоваться жизни, но
возникает вопрос, а можно ли быстрее
оказываться, что ответ положительный?
Делается это очень просто.
Вот. Какая тут проблема
алгоритма? Проблема в том, что
у нас слишком глубокие
рекурсы. Мы, типа, n, как бы,
чтобы нам обрабатывать какое-то
число n. Ну давайте даже
так. Давайте представим, что мы маленькие
числа n обрабатываем. Вот их
относительно может быть, то есть все до корня могут быть.
И мы каждый за корень обрабатываем.
То есть кажется логичным, что мы их можем
взять и за линию предпредсчитать. У нас же есть линии,
наверное, что ретасфена. Вот так
что давайте сделаем такую оптимизацию.
Давайте
все числа до какой-то
константа k. Вот сейчас я уже веду.
Сейчас понадобится...
А k есть уже?
Ну давайте m.
Лучше?
m у вас тоже в индексах.
Где? Нет в индексах.
m принадлежащей m. А это m
большое? А, так оно только тут
появляется, неважно.
С большое. Давай
t.
Можно t?
Большое.
Это же константа.
Константа должна писаться в капс локом.
Но это не констэкспро.
Константа я хочу заметить, поэтому...
Вот, окей, давайте.
Хорошо, мы первое значение t просто посчитаем за ot
с помощью линейного решта.
И мы будем сразу полагать,
что мы сразу t выбираем больше, чем корень он.
Теперь, тогда у нас вот тут
остается что?
Теперь вот тут нам остается
вот за такую синтотику порешать только какие-то
самые большие делители.
Ну, это что будет за делители? Давайте в индексах
используем. Сумма у нас пока будет.
До скольки пока непонятно.
Но это будет у нас корень из
n поделить на k.
Ну, почему непонятно?
Ну, это будет, соответственно, да,
поделить на t, да, именно так. Хорошо.
Ну и давайте, собственно, что сделаем?
Все посчитаем.
У нас, ну, это ot, понятное дело.
Вот мы хотим сейчас понять, какую t надо выбрать.
Это будет ot.
Эта сумма, ну,
корень из n можно вынести.
Корень из k можно представить в виде как
корень из k плюс корень из k-1.
Короче, получить телескопическую сумму и радоваться.
Короче говоря, тут мы получаем n поделить на t.
Ну, смотри, вот t из...
А, знаменатель?
Да, просто хотим такую сумму.
А синтетически равна корню из k.
Ну, это очевидно, плюс-минус.
Ну, можно, типа, это делать с помощью...
Что?
Ну, это либо можно проинтегрировать,
но интегрировать это, конечно, сложно.
Можно проще прикол сделать, типа,
увеличить каждый знаменатель, типа,
ну, поделить как бы пополам ее,
вот, подсмотреть вот на такую сумму.
Да?
Ну, примерно то же самое.
Ну, оценка сверху вроде.
Ну, типа, давай заметим, что это телескопическая сумма,
потому что это, типа, корень из 1 минус корень из 0.
Следующий будет корень из 2 минус корень из 1 и так далее.
Да, корень из k минус корень из k-1.
Ну, такой вот фокус есть.
Ну что, ну...
Не, ну интегрировать это я не умею, честно говоря.
Поэтому я не интегрирую.
Не, ну в смысле, ну вот это понятно, почему то же самое?
Примерно то же самое.
Ну, смотри, ну просто, типа, давай посмотрим на корень из n
плюс корень из n-1, да.
Да, множим на сопряженное.
Тут что получится?
Тут корень из n минус корень из n-1, а тут что?
n минус n-1, да.
Ну, это единичка, ну, получил телескопическую сумму.
Вот самое главное, что не интегрируем.
Окей.
Вот, ну, короче, получили вот такую сумму, да.
Вот это что такое?
Это от t плюс n поделить на корень из t.
Ну, и отсюда легко видеть, что
оптимально выбрать t равное
кубическому корню из n-2.
Вот.
Ну, и мы получим тогда асимптотику
n в степени 2 трети.
Вот.
Как-то так.
То есть, в принципе, ну, лгритм достаточно простой,
типа там
получаем, как бы, просто расписываем
по вот этой сумме
через свертку Dirichlet.
Если просто так делаем, у нас
n в степени 3 четверти, если посчитываем вначале, то у нас
n в степени 2 третих. Конец.
Вот.
И у меня, видимо,
материал вообще не хватает на три лекции.
Ну, на три пары, как хотел Филипп.
Три пары это гораздо больше, чем
ты думаешь до того, как начинаешь читать.
Да я это понимаю.
Не, в смысле, я изначально понимал,
что у меня времени не хватит.
Поэтому я докидывал
цыганских фокусов посередине, но, к сожалению,
цыганский фокус рассказывать алгоритму
Euclide полчаса не сработал.
И поэтому как-то так.
Ну, вот, в принципе, все.
Может быть,
что-то еще есть.
Ну, вот если нет, я думаю,
тут смысла нет собираться.
Можно, в принципе, расходиться
вам, типа,
все.
Вам, наверное, тоже не по кайфу учиться весь день.
Весь день?
Большинство из нас, только алгоритм.
А, только алгоритм, окей.
Ну, аж три пары.
А, нормально.
Сразу видно.
Так, ну хорошо, давайте.
Так, ну ладно,
хорошо, давайте какую-нибудь фигню
о мультипликативных функциях.
Еще пару слов скажу, наверное,
не то чтобы супер важно,
но мультипликативные функции
еще, оказывается,
можно считать. Помните, мы обсуждали
Решетто, ретосфена, которая работает
от
r-l
плюс коренизер
за log log r, да?
Ну, обычный Решетто, ретосфена,
по сути, да?
На отрезке. Ничего сложного.
Ну, вот оказывается, что есть иногда такие
исключительные случаи, когда его можно
использовать для обучения мультипликативных функций
в достаточно больших точках.
Тут пример с дачкой говорить не буду,
потому что это с дачкой с китайского контеста.
И, типа, она как раз была вот про
эту функцию, помните, я сам показывал,
одна четвертая количество решений с квадрат
плюс игрок датков, наверное. Вот, короче, это оттуда была с дачкой.
И как раз
решалась вот такой техникой. Ну, и в принципе
вот так вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
