Так, ладно, ну-ки, давайте начнем.
У нас сегодня пятая лекция, по-моему.
А сегодня мы будем с вами говорить про такую штуку,
как минимальные остовные деревья.
Это первая часть лекции, а вторая часть в зависимости
от того, сколько, как быстро уложимся в эту штуку,
там будет определяться находу, импровизация.
Давайте определение.
Пусть G, V, E это неориентированный граф, тогда T равный V, E штрих.
Это остовное дерево.
Если это дерево, в общем-то, здесь ничего интеллектуального
нет.
Как это понимать?
У вас есть какой-то граф на множестве вершин V, на
ребрах E.
Затем вам дали тоже множество вершин.
Вы выбрали какие-то ребра в графе, и у вас получилось
дерево.
Например, тоже граф, раз взяли ребро, два взяли
ребро, три, четыре, пять.
Это остовное дерево, точнее говоря.
Зачем они нужны?
Ну, с тем, чтобы хотя бы просто понимать, сколько ребер
можно удалить, чтобы, например, там осталось связанности,
какие.
Ну, это можно делать с помощью остов, а здесь мы поставим
задачу немножко по-другому.
Теперь мы введем минимальный остов, что это такое.
Пусть G, V, E, W, то есть мы даже добавляем сюда вес
функцию, это неориентированный, взвешенный граф, на W ограничений
не будем накладывать, тогда T равный V, E, W, это минимальный
остов.
Давайте T звездой его обозначим.
Почему?
Потому что я хочу вот так вот делать, T со звездой
равно argmin, W от T, где T это остовное дерево.
То есть я беру минимальный остов по суммарному весу.
Например, вы можете с помощью этого решать задачу,
не знаю, какое там самое дорогое множество ребер
можно все еще выкинуть, чтобы граф остался связанным.
Но это самое простое, что можно придумать.
Так-то на минус 100 можно много всякого придумать.
Например, не знаю, у вас есть там схема, электросхема
или микросхема, у вас тут длинные соединения, например,
или их стоимость.
Вы хотите найти минимальную штуку, которую можно оставить,
чтобы у вас граф был связанным, чтобы схема была связана.
Вот, ну и теперь нужно понять, как их искать.
Не знаю, здесь 100, здесь минус 10, минус 2, 1, 3, P делить
на E.
Что-нибудь такое.
Вот у вас классный граф, то есть вы можете назвать
себя отрицательной, рациональной, вообще любые веса.
Здесь W действует из E в R.
Что?
Ну, вы не умеете сравнить комплексные числа.
Ну что значит, что одно комплексное число меньше
другого?
Что?
Ну, хорошо, на которых определен полный порядок.
То есть, которые являются лумом, если уж так хочется.
Все-таки у нас граф конечный, здесь фунтированность не
очень интересна.
Окей, так, что мы еще хотим?
Надо подступиться к чему-нибудь, надо сформулировать снутиарем
вообще, сформулировать определение.
Пусть, надо подумать, как бы это сказать, не нарочно.
Пусть T штрих равно W E штрих, это подграф некоторого
миностово, давайте два штриха здесь напишу, миностово
T равное W E штрих графа G V E.
То есть, вы взяли граф G, нашли в нем миностов, взяли
какой-то его кусок.
Тогда, ребро E, E маленькое, равное U V, E не лежит в E
два штриха, это безопасно для T два штриха.
Если T три штриха V E два штриха в объединении с парой U V подграф
некоторого миностово G равный V E.
Ну, я думал сюда еще миностов T четыре штриха вставить,
но я не решился.
Как-то понимать, очень классное определение, я уверен, хотите
вы мне сказать.
Что?
Нет, в смысле, нет, какая разница, у вас подграфы
миностово.
То есть, у вас вершинки могут быть те же, у ребра
еще не закончили добавлять туда, да, здесь не принципиально
на 2 штрихи ставить, но можно, конечно, и везде подмонстры
вставить, но не очень интересно.
Например, такой граф, да, и допустим, я знаю, что у
меня вот эта вот часть, это подграф некоторого
миностово.
Ну, если что, это правда, это правда подграф миностово,
спойлер.
Вот, то есть, вот это вот, давайте, у нас будет T два
штриха.
То есть, вот сейчас вот T два штриха выделено.
Я хочу понять, какое ребро является безопасным.
То есть, например, какое ребро я могу добавить, чтобы
у меня снова получился подграф какого-то миностово.
Ну, будто бы минус три добавлять, классная идея,
да.
Потому что это такое минимальное ребро здесь, которое достижено
из этих, наверное, оно войдет в миностов в итоге.
Ну, тоже спойлер, да, но является безопасным, потом
поясним с вами, потеряем, почему это будет так.
Вот, пока что просто нужно поверить, что вот это подграф
миностово, если я добавлю это ребро, то это все еще
будут подграфы миностово, поэтому это ребро называется
безопасным.
Вот и все.
Окей.
То есть, понятная идея, что здесь имеется в виду.
То есть, здесь T три штриха, это вот эти три ребра.
Нет, конечно.
Ну, здесь не выгодно добавлять, например, миностово.
Зачем?
Если бы минус десять добавить.
Я не помню, упреляли ли мы с вами, что такое разрез
в графе.
Наверное, нет.
Ну да.
Еще определение тогда.
Пара СТ разрез в G равным VE, если равно V.
Надеюсь, что всем знакома эта квадратная оскобка,
что это дизюнкное объединение.
То есть, у вас С и Т не пересекаются, в объединение
будут все П.
Например, не знаю, но я могу вот так вот рассечь
граф.
И вот эта вот часть у меня будет S, вот это T.
Ну или наоборот.
Ну, разрезов очень много внезапно.
Например, сколько у вас способов выделить подмножство
S?
Почему?
Потому что T однозначно определяется.
Это столько подмноженств.
Ну, обычно С и Т еще считаются непустыми все-таки.
То есть, сколько способов выбрать непустое подмножство
S?
2V минус 1, да.
Да, в степень мудра В минус 1.
Вот столько разрезов.
Вот.
Но это не очень интересно.
И ребро УВ пересекает разрезы с Т.
У лежит в С.
И В лежит в Т.
Или У лежит в Т.
И В лежит в С.
То есть, это ребро, у которого концы по разные стороны.
Давайте посмотрим.
Вот до момента добавления минус 3 в минус 100, что у нас
с вами было?
По сути, вот это был отдельный разрез.
То есть, у нас вот три вершинки лежали в одной половинке,
все остальные в другой.
И полемия безопасного ребра, который мы сейчас формулируем,
утверждается, что минимально ребро пересекающий разрез
обязательно является безопасным.
Не находите ничего похожего сразу, спрашиваю вас.
DX должно похоже быть.
Потому что по DX мы тоже делали что?
Мы просто делали разрез, пытались докидывать вершинку
в одну половинку и брали минимальную по оценке.
Дальше у нас будет алгоритм прима, который берет без оценки
просто минимальный по весу ребро через разрез.
Но это забегает вперед, а пока что
лемма по безопасному ребре.
Пусть ST это разрез GVE.
И пусть на S построен...
Блин, я не могу теперь обозначить дерево за T,
потому что есть ST разрез.
Да нет, я H назову его просто.
Устроим H штрих, равный SE штрих,
E штрих под множество E.
Так, H штрих равный SE штрих под граф,
миностово H равный VE штрих.
Неудобно, давайте здесь два штриха, здесь один штрих будет.
Что мы сделали?
Вам говорят, хорошо, пускай я выбрал разрез,
и у меня известно на его половинке миностов.
Под граф миностово будущего, то есть сам миностово на разрезе.
На одной из половинок разреза.
Пусть ребро EUV это ребро минимального веса, пересекающее разрез.
Тогда E безопасно.
То есть еще раз, вот у меня есть разрез,
я на нем строил миностов.
Я рассматриваю все ребра, пересекающие разрез.
Раз, два, три, четыре.
Беру из них тот, который минимального веса, минус три.
Полемия это ребро получается безопасным,
то есть я могу его добавить, я все равно еще останусь в рамках какого-то миностово.
Быть может, другого.
То есть вот этот вот H штрих, да?
То есть мы получим H2 штриха, когда добавлю ребро E туда.
Быть может, он уже перестанет быть под графом этого миностово.
Потому что миностовов много может быть, на самом деле, в общем случае.
Вот. Если это так, то тогда что происходит?
По сути дела.
Что у вас этот H может быть другим.
То есть у вас E штрих здесь будет не такое.
Вот, но это не очень важно.
Важно то, что вы стоите в рамках какого-то миностово.
Окей, давайте доказывать.
Зареза здесь крайне интеллектуальная.
СТ, да?
Это будет, как вы изначально миностово обозвали.
На S построен H штрих.
Это будет H штрих.
Здесь есть какой-то еще...
Это H без H штрих.
И у нас есть какое-то ребро соединяющее.
Это наше ребро E.
Ну, доказывается такое.
Хорошо, достроим H штрих до миностово.
Так как у вас, очевидно, дерево это связано, граф,
у вас должно быть хотя бы одно ребро через разрез выбрано.
Ну, более того, ровно одно на самом деле, потому что у вас цикл образуется.
Окей, выбрали ребро.
Пусть... Ой, сори, что я несу?
Что это H без H штрих?
Это просто под граф какого-то миностово в T.
То есть это не обязательно какое-то множество ребра здесь будет.
Хорошо, что мы дальше делаем?
Пусть E штрих это ребро, пересекающее разреза с T.
Очевидно, такое существует, значит, фотограф не связан просто-напросто.
Может получить миностов.
Два случая. Случа первый.
Так, это U, это V.
E равно E штрих.
То есть мы действительно взяли какой-то E штрих, который равно E.
Ну, тогда все доказано. Мы остались в рамках миностово, когда мы добавляли E штрих.
Да, когда мы добавляли ребро, мы остались в рамках миностово, потому что оно просто лежит в миностове.
Тогда по определению E безопасно.
Второй случай. E не равно E штрих.
Хорошо, есть какое-то другое ребро.
Это E штрих.
Рассмотрим.
Давайте напишем.
У нас же не было H2 штриха в формулировке.
Не было. Вот, теперь есть H2 штриха.
Рассмотрим путь из U в V, H2 штриха.
Какой вид он имеет? Давайте это U штрих, это V штрих.
U штрих равно U штрих V штрих. U штрих лежит в S, это лежит в T.
Хорошо.
Тогда я могу сказать следующее, что...
Давайте заметим такое очевидное соотношение, что если у нас есть какие-то вершинки, есть два пути между ними,
то мне в миностове выгоднее взять тот, который...
Короче, по весу просто.
Потому что у вас связанность здесь не нарушится.
Это не самое содержательное здесь.
Так как E штрих это минимальное ребро...
Нет, E это ребро минимального веса. Вот так вот.
Что мы сами определили в итоге?
Что у нас E это ребро минимального веса, пересекающего разреза, E штрих это то, что ушло в миностов.
Заметим, что замена E штрих на E не испортит связанности.
Почему? Потому что у вас здесь есть связанная компонента, здесь есть связанная компонента.
Вы убрали одно ребро, поставили другое.
Поэтому замена E штрих на E не меняет связанности и оставляет древесность.
Ну что тогда можно сказать?
Но E штрих, вес ребра E штрих, он какой у нас по сути по сравнению с весом E?
Больше либо равен. Ну, равенство тоже может быть.
Вес E штрих больше равен, чем вес E.
Откуда вас следует?
Следует две вещи.
Первый случай, если строгое неравенство, значит, что это просто-напросто добавление E штрих.
Это плохая идея была.
И надо было добавлять именно E, потому что E штрих не является безопасным.
А второй случай, это то, что E штрих является безопасным.
Но это то, что мы хотели получить из условия.
Потому что тогда вес равен весу минимального и в том числе минимальным.
Давайте первый вариант.
W от E равно W от E штрих.
Следует, что E штрих безопасно, но он тоже имеет минимальный вес.
Откуда вас следует, что все окей в этом случае.
Второй случай, это W от E меньше, чем W от E штрих.
Откуда вас следует, что H2 штриха не именно стов.
Противоречие.
Все, доказали лев.
А, да, я забыл сказать, как минимальный ствол на дереве по-английски.
Минимальный это минимал, это понятно.
А стовный это спеннинг.
То есть это будет...
Надеюсь, подпишу.
Минимал.
Спеннинг 3.
Или еще МСТ.
Вот их обычная МСТ куплет.
Окей, ну все.
Судимо, доказали ключевую леву.
Теперь быстренько два алгоритма поиска миностов.
И первый алгоритм, это алгоритм Прима.
Устроено очень просто.
Шаг первый.
А, ну не первый шаг, а...
Что будет делать? Поддерживаем разрез СТ.
Где на С построен миностов.
Это все, что мы будем делать.
То есть мы будем постепенно увеличивать одну часть и другую часть.
База С равно С, Т равно В без С.
То есть у вас есть какая-то стартовая вершинка С маленькая,
и вы от нее начинаете отсчет свой.
Это стартовая вершинка С, например.
Браться произвольно, потому что в любом случае ваш миностов должен до всего добраться.
Да, кстати, сразу спойлер.
Если возьмете несвязанный граф, у него нет миностова.
Это вроде тривиальное замечание.
Просто ему, что если у вас там будут задачи в контесте, вы увидите миностов,
а граф не связан, то что-то не так.
Где-то.
Какой-нибудь такой граф, да?
Вот наш стартовый вершинка С.
Вначале у нас вот такой вот разрез.
Ребра пересекаются через минус один, три, два.
Переход.
Е равный УВ, УВС.
ВФТ.
Ребро минимального веса, пересекающее СТ.
Тогда мы объявляем, что С равно СВ, ВВС.
Т равно ТВ.
ВВС.
ВВС.
ВВС.
ВВС.
ВВС.
ВВС.
ВВС.
ВВС.
ВВС.
ВВС.
Равно Т без В.
То есть что мы делаем?
Мы берем ребро минимального веса, например, минус один.
Примокей, тогда оно входит в С.
Теперь разрез представляет себе вот такую картинку.
Вот наш миностов на текущий момент.
Дальше убираем снова ребро минимального веса.
Минус три, три, три, два.
Минус три минимального веса.
Становится новый разрез.
Это входит к нам.
Кто пересекает?
Восемь, десять, три, три, два.
Ну два минимального веса.
Окей.
Выберем миностов.
Давайте я здесь перерисую линию разреза.
Немножко другое уже.
Вот такого вот.
Ну кто пересекает разрез?
Десять, три, три.
Минус пять, восемь, один.
Минус пять.
А один не пересекает разрез, сори.
Вот минус пять.
Крутой кандидат, давайте его и возьмем.
Вот такой вот разрез.
Здесь остается одна вершинка по сути.
Можно его замкнуть.
Ну ребро минимального веса пересекающее разрез.
Кстати, заметим, что восемь разрез не пересекает.
Потому что у вас особо конца в С.
Поэтому надо замкнуть здесь.
Такая вот интересная картинка получилась.
Ну здесь ребро минимального веса это один.
Ну вот у вас миностов получилось.
Давайте подумаем, что мы с вами делаем этому гритме.
Мы умеем...
Мы, по сути, поддерживаем множество.
Если у нас есть какая-то вершинка...
Это множество ребер, да, мы поддерживаем с вами?
Мы поддерживаем, точнее, множество вершинец.
Давайте еще поддерживать множество ребер,
которые пересекают разрез.
А ну, окей.
Так, корректность.
Просто полимия на безопасном ребре.
Корректность очевидна,
потому что на каждом шаге просто ее применялись.
А теперь нам нужно
понять, что по таймингам
и как это плюс-минус реализовывать.
Реализуется это, на самом деле,
тривиальнейшим образом.
Вы поддерживаете напрямую множество ребер,
которые пересекают разрез.
То есть вы поддерживаете,
если вы поддерживаете,
вы поддерживаете напрямую множество С и Т.
Ну, можно просто С поддерживать.
То есть поддерживаем напрямую множество С.
Можно one-order множество.
И множество ребер,
пересекающих разрез.
Ну, или когда-то добавленных множеством.
Потом мы поймем, что все будет
гораздо лучше, чем кажется.
Вот.
Что мы будем делать?
Ну, давайте возьмем.
И здесь мы хотим
извлекать минимум,
поэтому это либо С,
ну, вроде как здесь priority-Q хватит.
Сейчас посмотрим.
То есть база понятна.
Множество ребер,
пересекающих разрез,
это ребра, исходящие из С.
Мы их все докидаем туда.
Ну, С и Т
определены. Переход.
Вот, допустим, если было какое-то множество,
я пришел по ребру в В.
Так какие ребра у меня начали пересекать разрез?
Вот ребра, исходящие из В.
Очевидно, не все,
но некоторые.
Поэтому давайте я буду, когда,
когда я добавил вершинку В,
в множество С,
я буду валять ребра, буду просто проходить
по всем ребрам из В и смотреть, правда ли,
что их конец в С.
Если да, то они пересекают, точнее,
если да, то они не пересекают разрез,
потому что они уже внутри С-большого будут лежать.
То есть, как бы до
это ребра там, сюда,
сюда, сюда, сюда, сюда,
сюда, да,
у В
это С.
Новая ситуация,
что есть ребра сюда,
сюда,
и ребра наружу.
И вот вы смотрите, правда ли, что конец ребра лежит в С?
Если да, то его нет смысла добавлять,
потому что он не пересекает разрез.
Иначе действительно у вас
ребро пересекает разрез,
и вы его добавляете туда.
Казалось бы, проблема, все равно мы не можем
явно учесть в нашей куче
в множестве,
только ребра пересекающего разреза,
когда-то они, то есть, в какой-то момент
могли нам давать какое-то ребро, оно
после добавления нескольких вершин перестанет быть
пересекающим разрезом, оно останется в очереди.
Проблема, ну, на самом деле
нет, потому что при извлечении ребра
вы можете просто посмотреть правильное, что у него бы конца С.
Если да, то вы его игнорируете,
потому что у вас уже было
добавлено лучше ребро.
Все.
То есть вы поддерживаете
кучу с приоритетами
или бинарную пирамиду,
докидываете туда
ребра, каждый раз исходящие,
можно там или даже с концом
в С, не очень важно, вы все равно потом
вы его выкинете при извлечении,
то можно вообще все ребра то закинуть, исходящие
из вершинки В.
Вот. Потом, когда вы достаете
ребро, вы проверяете, правда ли, что оно внутри
С, оба конца.
Если да, то оно неволидное, а почему?
Потому что он небезопасный, это развал,
просто цикл образуете,
потому что у вас уже есть под граф С
и еще ребро добавляете, это
порождает цикл обязательно.
Вот.
Это вы смотрите правильно, чтобы конца С есть,
если нет, то все. Выкидываем.
Не смотрим его.
Ну и все.
Это и делаем.
Окей.
Что можно сказать?
Будто бы у нас здесь даже в стадии
проще, чем в Dx,
а время работает плюс-минус такое же. Почему?
Потому что вы, по сути, делаете
E раз добавление
в кучу.
Вот.
Единственное проблема в том, что у вас
размер кучи может быть большим,
не принципиально.
Вот.
И что вы делаете?
Вы делаете извлечение из кучи.
То есть вы добавляете в кучу элемент
инсерты и GetMino делаете.
Ну или экстракт.
Это может быть как set, так и unordered set,
если им точку не влияет.
Вот что получается?
Порядка E log V здесь.
Но если оценивать наивно E log E будет,
если там чуть-чуть
поавтимизировать этот процесс,
E log V получится. Прям как в Dx.
Ну и там получится то,
что у вас все вот эти контейнеры,
то, что можно на массиве делать
за V квадрат,
куча, выначивай куча,
на чем-то можно и не делать.
Второй алгоритм он
как по мне более элегантный.
И вообще требует ноль
идейности.
Если этот хочешь его-то требовал,
то это вообще ничего не требует.
Алгоритм
Kruskao.
Ну, что можно сказать?
Ну шаг первый, отсортируем
ребра.
Ребра по весу.
И тут
на сцену выходит
легендарный участник нашего курса
алгоритма в системе не пересекающихся множеств.
Напомню, эта штука,
которая умеет отвечать ровно на два запроса.
Первое, правда ли,
что элементы U и V в одном множестве?
Второе, объедини множество
где лежит U и где лежит V.
Построим SNM
на
вершинах.
То есть, если
мы рассмотрим наш
граф любимый.
2-5
8-3
10-3
3-1
Вроде бы
нет, не все скопировал.
С 1 это 5.
Изначально считаем, что все вершинки
это отдельные компоненты.
Все будто бы у нас вот такое леса, столб двух деревьев.
Шаг 3.
Пока
число
множеств
SNM
больше одного.
Делаем следующие шаги.
E
равный U и V.
Что-то такое.
Это
очередное ребро.
Дальше, если
по-моему, называли
same операцию,
то если U и V лежат в одном множестве,
то
там continue.
Else
если они
лежат в разных,
unite
от U,
U,
минус 100.
Что?
Да, да.
Очевидно,
что ребра сортированы
на графе.
Вот минимум.
Минус 5.
Очевидно, что U и V лежат
в разных компонентах.
Поэтому
говорите, что это одна компонента.
Дальше.
Смотрю следующий ребро минимального веса.
Это минус 3.
Это одна компонента.
Они в разных лежат.
Следующий ребро
минус 1.
Окей.
Следующий ребро
минус 1.
Окей.
Следующий ребро
минус 1.
Окей.
Следующий ребро
минус 1.
Следующий ребро минимального веса 2.
Все, что ли?
Даже не попалось,
чтобы в одном ноте не повезло
ситуации.
Это очень приятная идея.
То есть мы просто делаем примо,
запустив сразу низких вершинок.
Корректность, внезапно,
не поверите,
но полемия о безопасном ребре
для подграфов.
Все.
Больше ничего.
Поэтому это классное утверждение,
что она доказывает все эти алгоритмы.
Вот.
Ну, заметьте, минус 100, кстати, один тоже получился.
В этом семинаре у вас будет задачка
доказать, что если
минус 100 единственным, то
все веса и ребра различны.
В обратную сторону это неверно.
Ну, давайте подумаем.
Это
от E
logE.
Ну, если вы там какие-то радикс-сорты пишете,
там по-другому будет работать.
Это
от V.
Давайте посмотрим, сколько здесь запросов.
В случае запросов E,
запросы к SNM, которые
выполняются амортизировано за альфа от V.
Поэтому суммарно
можно оценивать
как-то вот так вот.
Ну, это, очевидно,
меньше, чем это.
Поэтому в сумме
получаем от
E
logE.
Время работы.
Ну,
можно сказать, что
E не больше, чем V квадрат.
Поэтому
logE, это на самом деле
logV с точностью сюда константы.
И вы действительно будете правы.
Однако обычно пишут logE,
чтобы все-таки подчеркнуть, что
от ребер зависит. Нет, совершенно.
Но по факту
между примой и кросскалом
почти ноль, плюс-минус
отличия в работе, по времени работы.
Иногда даже эта штука быстрее,
потому что
воспользоваться кучу раз кучей
или один раз отсортировать, ну, понятно.
Плюс-минус чего? Лучше.
Все-таки попроще
опираться, чем куча лазить.
С точки зрения константа.
Вот. Окей.
Поехали, вторая часть лекции.
Она с ненастоянием особо
не связана вообще, поэтому давайте я все это затру.
Задача называется
LCA.
Так, наименьший общий предок.
Меньший
общий
предок.
По-английски
лист
common
ancestor
или LCA.
Давайте определим.
Вот это такой.
Пусть T
в E
это корневое дерево.
То есть в нем явно видно какая-то вершинка
как корень.
И все остальное можно считать, что
растет вниз или
куда вы хотите, чтобы ваше дерево росло.
Все.
И у
в лежат
в.
Ну, картинка будет здесь.
Что-нибудь такое.
Например, вот у вас у,
вот у вас в.
Тогда
LCA
с большой буквы не очень важно.
А то в
это такая вершина
из в,
что
в лежит
на пути
от корня до U,
ну, на путях
корня до U,
от корня до V
и
на
максимальной
глубине.
То есть
вот, например, U и V
рассматривают пути
до U
и, не знаю, давайте градиентально
их отметим, до V.
То есть вот у вас общие вершинки.
Раз, два.
Берут самую глубокую из них.
Это наша
LCA
от U и V.
Вот для этих вот двух вершин LCA
будет корнем. Для этих двух вершин LCA
будет вот это вот, собственно.
У LCA может быть равен какой-то
из вершин.
Когда одна вершина лежит на пути другой.
Чем-то нужно, ну,
те применения, как вы думаете, могут быть
в этой штуке вообще.
Вот, внезапно.
Очень удобно.
Что делать?
Например, считать всякие
операции на пути в дереве.
Например, сумма на пути в дереве.
Берете, подвешиваете,
находите LCA, потому что сумма на пути
это сумма двух нисходящих путей.
Зачем это нужно? Я потом приведу
прикладку.
А пока что, скажем так, есть некоторые задачи,
которые нужно решать даже
в плане того, чтобы поиск какой-то
операции на пути.
В общем случае,
например, у вас есть две версии проекта.
У и V вы хотите узнать, когда они
разделились в гите.
Самое простое, что можно придумать.
То есть на какой момент они все еще были общими,
а потом они разорвались.
И, конечно,
в любом случае,
в общем, потом они разорвались.
Что?
Можно, да.
Можно искать, насколько
поколений вы далеко от
королевы Елизавета, например.
Кажется, не очень далеко.
Я не уверен.
Не очень важно.
Ну, там, не знаю, какие-нибудь файловые системы,
тоже они там же иерархические. То есть любая
иерархическая система, где у вас есть
связь предок-потомок,
можно искать
илца и придавать этому разные
смыслы.
Как это делается? Давайте
наивное решение.
Посчитаем
для каждой
вершины глубины
наш любимый DFS.
Что мы дальше будем делать?
Пусть
глубина
вершинки В
меньше,
чем, наверное.
Ну, без ограничения общности можно сказать так,
потому что иначе вы просто UEV сваппаете,
алгоритм никак не меняется.
То есть вот наша ситуация.
UEV DFS от UU больше, чем DFS от A.
Здесь 1, 2,
1, 2, 3. Глубина.
Окей.
Что мы дальше говорим?
Что?
Да, да, конечно.
Давайте DFS от A напишу.
В смысле?
Ну, по ребрам, например.
Рёберная глубина.
Вы к антесу 1 писали там?
Хорошо, так вот напишу.
Не очень важно.
Окей, хорошо.
Это справедливо.
Третий шаг.
Пусть
U'
такая вершина
на пути
корень
U, что
от U' равно
depth
от V.
То есть что вы сделали? Вы знаете, для каждой вершины её предка.
Например, тоже в DFS посчитали.
Допустим.
Обычно дается дерево в формате.
Для каждой вершины дан номер предка.
Тогда вы что сделали?
Вы говорите, от U я прыгаю вверх
на depth от U-depth от V шагов.
Здесь глубина от 3,
здесь глубина от 2, я прыгаю на 1 вверх.
Получаю вот этот нашу
U штрих.
Теперь можно догадаться, что если я
пойду одновременно вверх
несколько раз, то в тот момент,
когда я припрыгаю в одну и ту же вершинку,
будет у нас в самом первом момент
4
while
Заметьте, что здесь
while U не равно V.
Потому что вы же могли U-штрих припрыгать
уже равно V.
While U-штрих
не равно V.
U-штрих равно
ancestors
от U-штрих.
U-штрих равно ancestors
от V.
Всё.
Ну, return U-штрих
или return V.
Это будет ответ.
За сколько это работает?
Здесь
будет у нас две стадии. Первая стадия
предподсчет, вторая
ответ-назапрос.
Ответ-назапрос
выдается до вершинки УВ,
до этих L-ца.
Предподсчет.
Какой здесь предподсчет?
Надо ДФ запустить.
Да,
заметьте, что здесь
раз-то дерево, в нём ребер
на единицу меньше, чем вершин,
поэтому здесь всё будет в терминах В.
Все симпточки считаются.
Что можно дальше сказать?
Ответ-назапрос.
На глубины мы знаем, предков мы знаем.
Но проблема в том, что нам нужно
подниматься сначала до U-штрих,
потом подниматься с В одновременно.
В худшем случае это
глубина дерева.
Глубина дерева в худшем случае
совершенно.
Поэтому запрос.
Вот модуль В.
Безмерно долго
давайте улучшать
нашу ситуацию.
И первое, что можно заметить для улучшения
всего этого дела,
что, в суть,
что нам нужно знать?
Нам нужно уметь прыгать как-то
желательно не на одну вершинку вверх.
Давайте реализуем эту идею,
а именно
так называемый метод
двоичных подъёмов.
В чём это заключается?
Введём такую динамику.
ДВК
это
вершина,
если из В
прыгнуть
на два степенька вверх
или корень
при перепрыгивании.
То есть
корня,
если вы слишком сильно вверх прыгаете.
Например,
ДП у 0
это её предок.
ДП у 1 это вот это вот.
Давайте от этой вершинки рассмотрим.
Вот у неё ДП у 0
это её предок.
ДП у 1
это будет прыжок на два вверх.
ДП у 2 это будет прыжок на четыре вверх.
ДП у 3 это прыжок
на четыре вверх.
Ну, за корень это будет,
поэтому в корень прыжок.
Давайте посчитаем.
Очевидно, что К не превосходит
логан двоичный,
потому что у вас два в степени
вы прыгаете,
а у вас длина пути не больше, чем N.
Поэтому здесь будет логан
по этому измерению,
поэтому измерение будет N.
Поэтому N логан будет предподсчёт.
Давайте напишем формулу.
Открываем.
Анцестер от V
если K равно нулю.
То есть это база динамики.
Предок корня
это корень.
Для корректного рассчёта нам будет важно,
что предок корня это корень.
Надеюсь, подпишу,
что это корень.
Иначе отработки не будут, я сразу скажу вам.
Если вы должны когда проставить массив предков, вы должны в корень засунуть в предкорни это корень.
Иначе это будут ифы неприятные, я не хочу ифы, я хочу написать классную формулу.
Как выразить вот эту штуку через k-1?
Внезапно, что такое прыжок на 2 степени k? Это прыжок на степени k-1 и прыжок из этой вершины на 2 степени k-1.
Поэтому это будет dp от dp от v к-1 к-1.
Все, такая классная формула.
То есть смотрите, что это такое. Это я прыгаю из v на 2 степени k-1 вверх, прихожу в какую-то вершинку.
И из нее прыгаю на 2 степени k-1, то есть суммарно я пропрыгаю в 2 степени k.
Можно вот так классно это расписать.
Предподсчет n лог n согласны.
Потому что у вас пока лог n слайв по v н слайв.
Здесь предподсчет от v лог v.
Давайте теперь обсудим, как делать шаги.
Идея будет абсолютно такой же, просто у нас прыжки будут быстрее совершаться.
Что? Не, запрос будет лог v.
У нас будет предподсчет чуть дольше, но что?
Вот так, что мы хотим дальше?
Хочешь сделать следующее?
Ну казалось бы, я же говорил, что мы здесь прыгнем, по сути, когда ищем у штрих на depth от u-depth от v.
Согласно нам, что мы прыгали вот ровно от кубича вверх, чтобы найти у штриха.
Давайте ее разложим по степеням 2-ки, да пропрыгаем динамикой.
Чудурочки, что ли?
То есть это раскладываем по степеням 2-ки.
Ну и все, и прыгаем соответственно с динамикой.
Как на самом деле это делаться будет?
Вы будете делать порка от логарифма до нуля.
Если в степень k, то есть bit катый, входит вот в это число, прыгни вверх, поменяй вершинку.
Все это, все что вы будете делать кодом. То есть код у вас будет примерно такой.
Вот этой вот стадии, третьей.
Ну, короче, эту штуку вы заведомо предпочитаете.
Я пишу так, потому что я нигде ее не предпочитывал.
Если катый bit в depth от u-depth от v, вы давайте обозначу эту штуку за дельта просто.
Если я говорю, что катый bit в дельте, ну как-то можно проверить.
Ну, например, не знаю.
Ну, я не знаю.
Я не знаю.
Я не знаю.
Я не знаю.
Я не знаю.
Я не знаю.
Взять какой-нибудь XOR с один сдвинутый на k, и там что-нибудь проверить.
Дельте.
А, ну можно взять по bit i с один сдвинутый влево на k.
То есть взять дельта по bit i на k, ну так вот.
Если это 0, то значит дельте нет бита.
Иначе есть bit.
Поэтому просто вот эта вот штука можно написать туда.
Ну, лучше написать, что не равно 0, например.
Короче, там код ставил, скажет, что надо написать, что вот эта вот дельта, побитая из 1 до k, не равно 0.
То есть если k-to-bit есть дельта, мы говорим, окей, u равно dp u k.
Все, это весь код этого шага третьего.
Теперь u равно у штрих на этом этапе.
Ну, чтобы просто разложили, будто бы постепенно двойки эту штуку.
Вроде все логично, да?
Хорошо.
Что дальше?
Теперь нужно u и v одновременно поднимать.
Независимо, мы будем заниматься сейчас тем же самым абсолютно.
То есть мы по сути же знаем, что w, то есть hilt, оно имеет какую-то глубину.
Если бы мы ее знали, мы бы явно могли бы все абсолютно то же самое сделать.
Прям в том, что мы не знаем этой глубины.
Поэтому будет делаться следующим образом абсолютно так же.
Только если при прыжке вверх мы припрыгаем в одну и ту же вершину, то мы скипаем этот бит.
Иначе, если мы приходим в разные вершинки.
То есть давайте отсюда пишем.
Вот так вот.
Сюда вот и отсюда вот.
Это не на одной глубине.
Вот я беру и смотрю.
От k равны log2.
Здесь k равны 4.
Вот 2 в четвертый.
Если я прыгну в четвертый отсюда, я приду в корень выше корня, очевидно.
Поэтому мне нет смысла прыгать на эту величину.
Окей.
Значит я скипаю эту штуку.
2 в третье тоже много.
Это будет за корнем.
Тоже нет смысла.
2 во второй.
Раз, два, три, четыре.
То есть я окажусь вот здесь.
Это будет dp, v, 2.
Много.
Значит я не прыгаю.
Хорошо, смотрю.
Если я прыгну на первой.
Раз, два, окажусь в разных.
О, подходят.
То есть это новое наше положение.
Прыгаю на ноль, смотрю, окажусь в одной.
Груз-то я скипаю.
И утверждается, что в конце этого путешествия такого прыжков, мне останется сказать, что lc это их предок.
То есть я утверждаю, что к концу такого фора, где я скипаю бит, если я попадаю в одну и ту же вершинку или нет, я в конце концов закончу ровно на один уровень ниже, чем lc.
Почему это так?
Почему это так?
Потому что я будто бы на самом деле по битам раскладываю величину разности высоты lc и вершин, только минус один.
Вот, есть вот минус один играет.
То есть по сути я делаю все то же самое.
Если я прыгаю слишком сильно, это плохо.
Вот.
Тогда значит я в конце концов допрыгаю разницу глубин минус один.
Потому что вот я краски пропрыгаю.
Потому что почему это так?
Потому что ровно в этом числе стоят те биты, которые меня не приведут в конце концов в одинаковую вершинку.
Вот.
Ну да, только мы там смещаемся еще постепенно.
Ну то есть да, это как вы по сути делаете, да вы делаете типа бин поиск по ответ, только сужаете диапазон все время, каждый успешный прыжок.
В два раза причем ровно сужаете его.
Почему в два раза? Ну вроде понятно, потому что если вы не смогли прыгнуть в два раза больше, но смогли прыгнуть ровно на такую величину, значит у вас там ответ где-то внутри диапазона t2t.
Причем t2t минус один.
Вот.
Тогда, то есть понятно, здесь код будет почти такой же, только здесь будет и в другой стоять.
И здесь будут u и v меняться на dp, ut, kt, vt, kt.
Поэтому время снова log n.
Поэтому запрос.
Вот log v.
Это долго.
Хочу быстрее.
Хочу здесь от единицы.
Нет, вот мы сейчас будем, следующая решение будет от единицы ставить запрос.
Ведь может мы конечно не успеем сейчас скорее всего, но мы заложим фундамент.
А в конце, уже на следующей лекции, где там пол лекции у нас будет уйдет, чтобы vlog v превратить просто в b в предпочете.
Ну и заодно мы сами научимся.
Помните у нас была задача и рамка такая классная.
Которая говорит минимум на подотрезке.
И мы там решали либо деревом отрезков, либо разреженной таблицей.
Разреженной таблицей мы решали, назовем log n построение от единицы ответа на запрос.
В общем, это цель нашей следующей лекции.
Первая половина следующей лекции будет построить такую структурку.
Тотичную, естественно.
То есть у нас не будет запросов изменения.
Чтобы мы могли стать их онлайн на рамку.
Решать за линейный предподсчет.
И константное время на запрос.
Наверное тебе вот как.
Я расскажу задачу, которая нужна, для которой это применяется в жизни.
Вот это вот действие.
А там уже наверное.
Сейчас ставим на следующую лекцию.
Все, что хотелось рассказать.
Потому что план такой, что мы хотим научиться сводить задачу лца к рамку.
И наоборот.
То есть умею решать рамку, мы хотим решать лца.
И наоборот, умею решать лца, мы хотим решать рамку.
Вот.
Пока что там сведение одно и другое.
То есть мы будем решать рамку.
То есть мы будем решать рамку.
Мы будем решать рамку.
Вот.
Пока что там сведение одно интеллектуальное и другое.
Используя дикартачи по неявному ключу.
Но простейшее.
Вот.
Поэтому оставим это пока что.
Задача такая.
Ну, прикладывая сюжет вообще.
Сама задача вообще так.
У вас есть какие-то.
Что-то написано на ребрах.
Например числа самое простое.
Он говорит две вершины УВ.
Хочу сумму на пути найти.
Ну вы такие окей.
Могу просто в тупую идти.
А могу заметить что.
Давайте я просто введу динамику.
Абсолютно такую же.
Как вот двоичные подъемы.
Только она будет хренить и вершинку а там.
Сумму на пути длины 2 степняка вверх.
То я такими прыжками.
Я найду лца сначала.
Потом от У до лца соберу путь.
От В до лца соберу путь.
А теперь прикладной сюжет.
Можно до корни хранить.
Ну да там будет двойная сумма.
Это плюс сумма.
Это минус двойная на пути до корни.
Не очень важно.
Вот теперь.
Допустим у нас необратимая операция.
Не знаю минимум на пути например.
Вот здесь придется явно хранить.
Незавтра я там.
Я работаю.
Я работаю тем, что разрабатываю бесплотные автомобили.
Вот.
И в бесплотных автомобилях есть очень интересная штука.
То, что они постоянно шлют системы координат.
Они же двигаются.
И все вокруг них двигается.
И у них есть куча разных систем координат.
Система координат связанная с картой.
Связанная с GPS.
Еще несколько систем ориентирования.
Связанная с ним самим.
Его система координат скорости.
Ускорения боковых скоростей.
Боковых ускорений.
Координат двигается.
Соответственно постоянно меняется матрица поворота.
Переходы между одной системой координат и другую.
И вот допустим вы хотите понять там.
Ну я занимаюсь тем, что мы предсказываем траекторию агентов среды.
Вот.
И мне нужно понимать там условно три секунды назад.
Где был пешеход.
Он запоминает же это.
Прямо в том, что у меня уже новая система координат.
У меня уже там 100 матриц новых пришло.
То есть я должен уметь понимать.
Как я от одной системы координат должен переходить в другую.
И там как будет все меняться.
Вот.
Как это решается?
Тем, что по сути беспилотник пишет.
Вот тебе сообщение новое.
Это тайм.
Это.
Система координат.
Какую я хочу.
System from.
Or System to.
Такие вот сообщения с тремя вещами генерируют.
Из какой системы куда и в какое время хочу.
Например из системы GPS, системы беспилотника в три секунды.
Внезапно он там пишет более тысячи в секунду сообщений таких.
Много.
И теперь я хочу понять там в системе.
Какая была угловая скорость пешехода или там у другой машины.
В системе отсчета связанной с матрицей.
У другой машины.
В системе отсчета связанной с моей угловой скоростью.
То есть мы разъезжаемся или встречаемся.
Но при этом мне нужны исторические данные, чтобы построить траекторию.
Поэтому я должен уметь быстро запрашивать от разных систем координат в разное время.
И как решать эту задачу?
Первый вариант вы можете явно хранить, когда вам приходит новое сообщение.
Вы можете просто поддержать явный пересчет со всеми возможными матрицами.
Всеми возможными системы координат во всем возможные таймстемпы.
Тогда это будет действительно у вас будет все это быстро делать.
Потому что вы будете доставать нужную матрицу за вот единицу.
Она просто в памяти хранится.
Но при этом в том, что у вас запрос добавления одного сообщения.
Это линия от того, что у вас уже хранится в базе.
Потому что вам нужно все матрицы пересчитать.
Это раз.
Два у вас квадрат по памяти выходит.
Потому что у вас каждый с каждым хранится.
Согласитесь, очень много, если у вас там больше тысячи сообщений в секунду приходит.
Безумно много.
Это проблема.
Учитывая то, что у вас там агентов куча.
Например, вы едете в бесплотник ваш.
И он там едет где-нибудь в центре Москвы.
И там вот пешеходный переход.
Там две минуты светофор.
Вот там 100 человек набилось.
И он там для каждого из 100 пытается строить траекторию, как-то дектировать.
Ему вообще очень плохо становится.
Вот если вы так будете делать.
Поэтому придумали другое решение.
Давайте хранить дерево этих систем координат.
А именно, каждое сообщение.
Что это такое?
Это дописывание новой вершинки вниз.
К вершинке, которую мы знаем.
И знаем таймстэмп.
Мы говорим, окей, чувак.
Ты хочешь к этой вершине прицепить нового ребенка.
Вот тебе сообщение.
Иногда сообщение приходит с запозданиями.
Поэтому там все очень интеллектуально сделано.
То есть вам может потом прийти сюда ребенка.
Прицепить.
И потом говорят, хочу.
И с такой-то системой координат в такое-то время.
И с такой-то системой координат в такое-то время.
Вы говорите, окей, не вопрос.
Раз, два, вот они мои штуки.
И я знаю повороты, написанные на ребрах.
Тогда чтобы получить матрицу и только поворота, мне нужно посчитать произведение матриц на пути.
Двоечные подъемы.
Тогда у вас запрос добавления вершинки.
Это что такое?
Посчитать для одной вершины динамики на лог n всего лишь раз.
Потому что у вас для всех остальных она уже посчитана.
Потом посчитать произведение матрицы соответствующей.
То есть снова лог n.
Добавление вершинки.
И ответный запрос тоже лог n выходит.
Потому что вы можете найти лца.
И это все быстро посчитается.
То есть как бы можно делать.
И причем памяти линейное количество?
То есть наивный способ.
Что он нас предлагал?
Он предлагал память, запрос добавления, запрос матрицы.
Он предлагал n квадрат памяти.
От n на добавление, от 1 на запрос.
Через лца он предлагает от n памяти.
Ой, n лог n.
Потому что у нас динамика же еще хранится.
От n памяти.
От лог n на добавление.
И от лог n на матричку поворота нужного.
Но согласитесь, что это выглядит гораздо привлекательнее, чем это.
Банально по памяти.
Потому что если бы мы хранили в памяти все эти сообщения, то у нас были бы не терабайты данных.
Мы бы никогда не закончили их обрабатывать.
Вот как-то так.
Поэтому что хочется сказать?
На самом деле это вообще неочевидное применение.
Но оно действительно существует.
Вот как-то так.
Поэтому не всегда очевидно, как можно применить алгоритмы, но они применяются.
Причем в таких неожиданных местах вообще.
Вот как-то так.
Заодно мой спич окончательно заканчивает текст.
25 минут.
Все, всем спасибо.
