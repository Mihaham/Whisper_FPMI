Все, отлично. Запись поставлена. Смотрите, сегодня будет, типа, немножко доделаем то, что мы успели в прошлый раз, и начнем обзор, ну или закончим, обзор выпуку оптимизации, с которой в дальнейшем будет речь.
То есть, напомню, что мы в прошлый раз говорили про выпуклой функции, и у нас осталась неохваченная тема того, какие преобразования сам выпуклый сохраняет.
Поэтому давайте я сейчас верну слайды, и где они тут были. Вот, наверное. Давайте пойдем в порядку.
То есть, первое, довольно очевидное, что если у нас происходит некоторое линейное преобразование от угументов, то функция остается выпуклой.
Ну, давайте это покажем. Вот, то есть, у нас есть f от x буквы, и у нас есть g от x, которая равняется f от a x плюс b.
Вот, обратите внимание, что здесь матрица по-прежнему любая, и не принципиально какая у нее там размерность, откуда куда отображает, и квадратность тоже неважна.
Ну, давайте покажем, что будет с выражением g от α x плюс или минус.
Он еще потихоньку подключается, это нормально. Вот, ну, это будет просто-напросто такая штука f от a α x плюс 1 минус α y плюс b.
Вот, ну, функция f у нас выпуклая, ну, пока это даже не важно. Важно, что мы можем это записать как f от α a x, да, воспользовавшись свойством линейности.
Вот, α a x плюс чего? Давайте я аккуратно заспешу, чтобы все получилось.
α от a x плюс 1 минус α а y плюс b. Вот, это просто я скобки раскрыл.
Так, вижу чат, не видно, что вы пишете. Ой, прошу прощения, да, я забыл поменять источник Sherin.
Так, ну, сейчас все должно заработать, я надеюсь.
Заработало. А, я забыл, что он тут. Извините, технические оплатки.
Да, короче, вот, еще раз проговорю. У нас выпуклая функция, и у нас же от x вот такая вот.
И теперь мы проверяем, собственно, определение выпуклости, положив здесь α от 0 до 1.
Ну, соответственно, подставляем явным образом, что у нас такое g, и раскроем пока что здесь просто скобки.
Ну, а дальше вот это вот выражение b, оно же у нас f от α a x плюс b плюс 1 минус α умножается на a y плюс b.
Вот, абсолютно точно так же. И это меньше либо равно в силу выпусти f от a x плюс b плюс 1 минус альфа f от a y плюс b.
Ну, это в точности же от x, это в точности же от y.
Поэтому так, короче, включается, немножко задерживается.
Поэтому у нас получается тоже выпукло. Поставьте плюс, если понятны преобразования и результаты.
Так как я вижу, что вроде бы много людей поставили плюсы, надеюсь, если кто не поставил, вы тоже просто не поставили, а не то, что что-то не поняли.
Вот, если что-то вы вдруг увидите в процессе, что непонятно, пожалуйста же отреагируйте как-нибудь, постарайтесь все прояснить.
Так что это значит? Это значит, что если у вас была какая-то выпуклая функция, например, f от x, там что у нас было? Была норма, да?
Вот, ну вот можно взять f от x равная норму а x минус b какой-нибудь, это тоже будет выпуклая функция, просто как вот такая суперпозиция с линейной.
То есть взять и линейные всякие преобразования, которые повышают размерность, понижают размерность, это ничего не портит абсолютно.
То есть тут как бы есть прямая корреляция с тем, что у нас было для выпуклых множеств, которые тоже линейные.
Такие вот преобразования ничего не портит. Вот, это первое утверждение. Давайте я буду почему-нибудь формировать.
Понятно, что сейчас темы, которые существующие не охватим, но самые главные для приложений я постараюсь как раз таки их и на них сфокусироваться.
Вот у нас значит, да. Вот следующее довольно важное на самом деле утверждение, что если у нас есть...
Например, вот равносильность оказывается. Вот, что выпуклась функция f от n-мерного или матрично определенного аргумента.
Это то же самое, что и выпуклась из столярной функции. Вот jt ведь t, он не жирный, поэтому это скалярка.
Виде f от x плюс ty, где во-первых x плюс ty это нежит в области определения, а во-вторых, некоторые x фиксируются произвольными,
а y это направление, которое как бы... Ну, паринтеризация прямой, короче говоря.
Надеюсь, вы помните, что мы можем паринтеризовать прямую таким вот образом.
То есть x это, грубо говоря, наш сдвиг от 0, y это наш направляющий вектор.
Оказывается, что можно, если это выполнено для любых x, y таких, что вот это вот выполнено, то у нас получается равносильность с выпуклостью функции.
То есть мы как бы ее... У нас какая-то n-мерная страсть того же определения, мы ее дробим до прямые.
Если по каждой прямой есть выпуклость, то и глобально по всему n-мерному аргументу выпустить будем.
Вот такой вот пример. Сейчас я, во-первых, докажем этот факт.
А во-вторых, я поясню на примере, зачем это надо.
Ну, возможно, если у вас в семинарах что-то подобное было, то вы знаете, зачем это надо.
Я вот так сделал стоп и теперь я показываю доску.
Вот. Если у кого-то... Что такое if? А, вот, прекрасный вопрос.
Начнем с обозначения if и f. f – это сокращение if and only if.
Тогда и только тогда. То есть, зачастую, если вы в литературе будете встречать...
Ну, долго писать вот это вот, поэтому сокращать до if, f.
Вот, это как бы неопечатка. Надеюсь, да. Понятно.
Да, значит, давайте я попробую еще раз написать, что у нас f от x выпукла равносильно
g от t равное f от x плюс t y выпукла как функция скалярного аргумента.
Видите, у нас был какой-то безумно мерный аргумент функций f.
Мы взяли и свели это все к анализу выпуклости функции волшебного скаляра.
А выпуклость от скаляра, ну, понятно, что, скорее всего, будет проще проверять.
Ну, давайте докажем это все. Первый шаг.
Пусть тебя выпукло. Возьмем три точки.
Произвольные t1, t2 и t альф, которые их выпуклая комбинация t2.
Понятно, что альфа 0 до единицы здесь будет.
Вот, и в потайник бумаги по вопросу берем.
Далее. Собственно, берем и подставляем теперь.
Ядом образом подставляем это выражение в, что такое, как связано g и f.
Дальше раскрываем скотки.
То есть берем и разносим, что у нас связано с x.
Ну, то есть x тоже умной 0 делаем из него, то есть плюс альфы, минус альфы и x.
И разносим так, чтобы у нас альф относился к некоторому вектору.
Так вот, понятно ли, что произошло в последнем равенстве?
Если не понятно, милус поставьте.
Вроде всем все понятно. Это прекрасно.
Ну, а дальше функция f у нас выпукла.
Вот это меньше либо равно, чем альфа f от x плюс t1 y плюс
1 минус альфа f от x плюс t2 y.
Ну, это в точности g от t1, это в точности g от t2.
Все, выпуклась g, показан.
Есть ли вопросы по доказательству в эту сторону?
Так, окей. Вроде тщательная тишина, верно?
Значит, все хорошо.
Теперь давайте в обратную сторону. Пусть у нас x g будет выпукло.
И теперь нам надо каким-то образом вести этот результат к тому, что у нас исходная функция выпуклка.
Ну, в общем, для этого мы берем произвольные пару точек.
x1, x2.
Произвольные.
И выначаем y как x1 минус x2.
То есть, собственно, направление генерируем.
Ну, а дальше начинаем, что называется, следить за руками.
f от x1, это что такое?
Это g от x1 плюс 0 умножить на y.
Все же время f от x2, это g от x2 плюс 1 умножить на y.
То есть, это g от 0, это g от 1.
Ну и дальше, собственно, что нам осталось показать?
Нам осталось показать, что f от альфа x1 плюс 1 минус альфа x2.
Это то же самое, что здесь мы просто выносим на скобке.
x1 плюс альфа x1 минус x2.
А вот дальше будет некоторая хитрость.
x1 плюс...
А вот то, что стоит перед...
Ну, это по сути y, да, у нас?
А вот то, что стоит перед y, расписывается вот таким вот образом.
0.
Так, прошу прощения, я как мог случайно...
Тут вот не альфа, тут 1 минус альфа, извините.
Плюс x1 и минус x1 происходят.
Тут будет, получается, 0 на альфу плюс 1 на 1 минус альфа.
Вот, и это же умножается на x.
И вот эта штука, на самом деле, что такое?
Это g от 0 умножить на альфа плюс 1 умножить на 1 минус альфа.
По определению.
Ну а g выпукло.
Ну, это меньше либо равно, чем альфа g от 0 плюс 1 минус альфа умножать 1.
Ну а дальше просто явно вот это вот подставляя...
Ой, тут я немножко переборщил, извините.
Сюда подставляю, получаю выпукло из функции.
То есть, давайте я допишу, что это f от x1 у нас, а это f от x2.
Ну то есть, всемагия, она спрятана вот в этих строчках.
Наверное, вот в этой строчке раз.
Ну да, вот здесь, в этом переходе.
То есть, как представить нам нашу функцию f, так чтобы мы могли сослаться на выпукло из g.
Вот ровно это здесь и происходит.
Так, ну в общем-то, вовремя стороны вроде показали.
Оставьте плюс, если все понятно, и минус, если нужно в какое-то место пояснить.
Так, ну вот я вроде...
А, вот 9.
Больше половины.
Я просто ждал, когда будет больше половины плюсов.
Да, 16 вроде человек.
Летелось на 9 плюсов.
Наверное, хороший знак.
Что происходит с остальными, не очень понятно.
Так, ну давайте еще буквально 30 секунд подождем и продолжим.
Так, ну хорошо.
Вроде никаких минусов вопросов пока не появилось.
Так, следующий пункт нашей программы, который надо обсудить.
Он выключается в следующем.
Следующее преобразование, точнее, которое хочется разобрать.
Это то, что зубкость функций.
Здесь у вас есть набор функций, то максимум вот этого набора будет выпукло функциями.
А, да, простите, я же хотел пояснить, о чем нужно было предыдущее.
Вот смотрите, оно нужно для того, чтобы в случае, когда у вас функция, типа от матрицы,
f, вот из большого, да, вот ее выпукло, зачастую проверять довольно сложно.
Поэтому лучше это все перевести в функцию g от условно u плюс tv.
Вот, и проверить выпукло все такой функции, как вот в скалярном аргументе.
Вот, ну давайте, не знаю, логарида терминанта, наверное...
Так, логарида терминанта разбирали на семинарах?
Постарше, плюс, если разбирали.
Ну и минус, если не разбирали.
То есть функция вот такая.
Минус, логариф, логарида терминанта матрицы.
Ага, вот вижу, что не у всех разбирали.
Окей, ну давайте сюда покажу просто, как это работает.
Ну видите, такая страшная функция.
Вот, но на самом деле, если это...
Ну давайте минуту пока отложим.
Отложим.
Если перевести это все к u плюс tv.
Вот, а дальше сказать, что...
Типа жатто.
Сказать, что вот эту штуку можно расписать через...
Типа u в одной второй на u в одной второй.
Типа произвести двух матриц.
Вот.
И сказать, что...
Ну мы вот, как бы говоря, перепишем.
Это как u в одной второй.
90 плюс t.
Вот так.
Извините, у нас доску не видно.
Да, спасибо, спасибо.
Я, как всегда, забываю все это включить.
Спасибо, что следите за тем, чтобы все транслировалось, куда надо.
Так, вот сейчас должно быть все заработать.
Я нагреюсь.
Да, вот так.
Короче, вот еще раз.
Минус log death.
Оставляем вот сюда.
А дальше матрицу u, которая вот здесь вот...
Ее можно...
Ну предполагаем, что при t равно 0 у нас...
Уль входит в нашу область определения.
Так, кстати.
Здесь у нас x лежит в Sn++.
Вот.
То можно найти такие две матрицы, что выполнена такая вот штука.
Что можно как бы корень, квадратный, матричный посчитать.
Вот.
Мы это дальше выносим.
Слева и справа.
Вот.
Ну тут единичный матрица образуется.
Здесь образуется такая штуковина.
А дальше, пользуясь свойствой терминанта,
это все дело пропорционально просто log death.
Ну, пропорционально, в смысле, будут слагайны, которые t не зависят.
Которые на утку здесь не повлияют.
u плюс t.
v.
Вот.
Понятно ли вот это, что вот обведено в рамочку?
Ой, в кружочек, извините.
Или нужно пояснить?
Давайте.
Плюс.
Все понятно.
Минус надо пояснить.
Так.
Я вижу пока только три плюса, что довольно тревожно.
Четыре.
Так.
Ну хорошо.
А если я скажу, что здесь используется свойство,
что determinant ab равен произведению терминантов?
Вот.
Станет ли после этого легче?
Так.
Ну где-то 8.
Типа, получилось.
9.
Наверное, да.
Больше половины.
Окей.
В общем, да.
Вот.
Вот.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
В общем, да.
Это разложение по собственным векторам.
Ничего больше.
Но после этого уже все более-менее то же самое будет.
Qqt, plus t, Qλqt.
Вот.
Ну, соответственно, Q вносится абсолютно аналогично.
Это уже вот неравно.
Тут надо пропорциональность писать.
Ой.
Да.
Извините.
Вот.
Ну и, смотрите, что произошло.
Мы свели задачу к тому, что у нас локаринная терминанта,
диагональная матрица.
Вот эта штука – это диагональная.
То есть, диагональная матрица – это произведение диагональных элементов.
Лямда и.
Ну, логариф, произведение суммы логарифа.
Тут, как бы, лямды и-то не какие-то.
Поскольку про определенность этой штуки, про определенность в дубльбе мы ничего не знаем.
Но он достаточно себе течит.
Вот.
Ну и дальше, собственно, это нажатая.
Ну, я думаю, что посчитать вторую производную, в общем-то, не сильно сложно.
Будет сумма единица на 1 плюс лямды и т, умножить на лямды и т.
Первая производная, вторая производная, минус.
Так, если будет сейчас подвисать, пожалуйста, крепите.
Минус 1 плюс лямды и т в квадрате.
Лямды и т в квадрате.
Видите, меньше, чем для себя.
То есть, следовательно, лог дата тк с вогнутой функцией.
Так.
Поставьте плюс, если результат и шаги, которые мы предпредели понятием.
Если вы сходу не понимаете, не видите, почему правомерно те или иные преобразования,
поставьте минус.
Все преобразования должны быть очевидны сходу.
Если что-то не очевидно, то вы говорите, я поясню детально.
Так.
Вроде 9 убралось.
Смотрите, почему вообще эта функция нужна.
Например, это, конечно, безумная функция.
Какой-то тринад логарифм.
Зачем все это делать?
Совершенно непонятно.
Мы делаем это ровно за тем, что вот у этой функции,
ну, типа, если мы смотрим на наши конусы,
такой небольшой, откатимся назад,
то это были конусы.
Помните, наверное, конус.
И конусы у нас были такие.
Был Rn+.
Был Sn+.
Но для Rn+, например, вот как он выглядит.
В двумере это просто эта штука.
И если мы хотим каким-то образом,
ну, и нам обычно нужно, чтобы наши переменные лежали в этом конусе.
Ну, и чтобы их заставить лежать в процессе интерационного какого-то метода,
естественно, можно потребовать, чтобы была какая-то функция.
Ну, то есть у нас вот была, словно, минимизация f от x.
Там x лежит в конусе.
Чтобы когда мы пересчитывали там x1, x2 и так далее, x3,
чтобы эти точки не улетали из области определения.
Поэтому делается так.
Ставим такую вот вспомогательную задачу.
Плюс там, условно, mu на некоторую функцию b от x.
b – это барьерная функция,
которая при b от x равняется, ну, в идеале,
нулю x лежит в конусе и плюс бесконечности, если x не лежит в конусе.
Ну, здесь такая типа ступенька.
Понятно, что она не дифференцируемая,
и с ней не очень понятно, как работать.
Поэтому ее приближают к некоторой другой функции,
типа b с крышкой.
Гладкая аппроксимация b от x.
Ну, и, например, для функции, ну, для конуса Rn+,
это довольно стандартная функция b с крышкой.
Давайте я тут напишу Rn+, такое безумное обозначение,
минус логарифм x.
То есть если нарисовать, то он действительно, тут будет единичка,
он типа вот так идет.
То есть, видите, если наш x приближается к стенке,
ну, к вертикальной, ну, к нулю, короче говоря, если он приближается,
то наша функция начинает безумно возрастать.
Только я вру, да? Я вру или нет?
Ну, то есть просто логарифм возрастает, минус логарифм.
Или правильно? Вроде правильно, да?
Вроде нет, в смысле, вроде не вру.
Спасибо, да. Что-то я это...
Бывает такое.
Ну, в общем, вот такой вот барьер для неотрясательного актанта происходит.
Соответственно, если у нас конус вот таких вот матрицы Rn+,
то тут как бы тоже надо ограничивать некоторым образом их,
ну, получается, спектр, чтобы он был всегда положительный.
И вот барьером для этого конуса,
как раз таки, будет минус логарифм до терминала.
То есть понятно, что нарисовать это я уже не смогу,
но идея именно в этом.
То есть когда у нас будет функция от матриц некоторых...
Пункция от матриц минимизируется,
и надо будет ограничение вот такого характера.
Вот эта вот функция будет гарантировать нам то,
что мы точно не вылетим за границы нашего множества.
Вот такая мотивация.
Оставьте плюс, если понятно, зачем все это было,
и минус, если непонятно.
Так, вижу, плюсов стало только 6.
Так, 7.
Так, как дела у вас остальных, интересно.
Так, ну что, минус, плюс, что-нибудь поставьте, пожалуйста,
все, кто еще не поставил.
Ага, спасибо.
Ага, супер.
О, отлично, вижу.
Так, good.
Все, теперь можно ехать дальше.
И следующая наша программа, которая была анонсирована,
это преобразование видом максимум.
У нас есть f1.
Я думаю, это на семинарах точно было.
У нас есть функция gatx, которая максимум.
F, i, t.
Вот.
И вот эта функция, она, собственно, будет тоже глупая.
Вот это все глупое семейство.
Вот.
Она выпукла, потому что операция gtmax,
ну, во-первых, можно по пределу это показать.
Это первый факт.
Ну, это я верю, что все справятся.
На самом деле, тут просто надо подставить определение сюда,
оценить максимум f, i, t от аргументов,
как меньше либо равно, чем...
Ну, в общем, суперпозиция выпукла,
как называется, максимум.
Вот, то есть, по максимуму,
меньше либо равен сумму максимуму.
Вот, вроде как.
Вот, и все получится.
Вот.
А можно просто хитрее...
Я думаю, я надеюсь, по крайней мере,
что из семеров про это более хитрее вы рассказали,
что если, например, у нас какие-то есть такие вот линиевые функции,
вся те из максимума,
по сути, означает, что мы вот так вот берем
и пересекаем их над графики.
Вот.
А дальше идет некоторый набор слов про то,
что изначально у каждой функции над графикой выпуклой
мы их пересекаем,
и в конце получаем выпуклую ножицу,
потому что мы пересекаем выпуклую ножицу.
Ну а раз мы получаем выпуклую ножицу,
и выпуклая ножица является над графиком функции,
то эта функция является выпуклой.
Вот.
Такие рассуждения.
Я надеюсь, что...
Поставьте минус, если этого либо не было, либо непонятно.
А, понятно.
Так.
А что...
Минус, это чего?
Что надо пояснить?
Можете уточнить, пожалуйста.
Так, не было.
А сейчас понятно?
Хорошо.
Ну, то есть, это значит, что, во-первых,
можно брать максимум, а можно брать супреум.
Игру гаража от x может быть супреумом f от x y,
где y какому-то множеству принадлежит.
При этом эта ножица может быть любым.
Главное, чтобы f от x y с крышкой была выпуклой
по x при фиксированном y с крышкой.
Вот.
То есть, ну, пример такой функции,
я не знаю, приводили ли это на семинарах,
но я просто проиллюстрирую, вроде.
Надеюсь, что не отнимет много времени.
Вот.
Это лямбда максимальное собственничание
симметричной матрицы.
Потому что оно представляется в виде
премума, ну, там, максимум, понятно.
У y, x, y по нормам y равна единице.
Вот.
И вот эта функция, f от x y,
при каждом y с крышкой,
это линейная функция по матрице.
Ну, потому что...
Потому что можно записать явно определение.
Давайте я запишу сейчас.
Вот, видите?
То есть, мы просто взяли,
все разнеслось,
независимо даже от знака.
Поэтому эта линейная функция,
она будет выпуклая.
Вот.
И, следовательно, эта штука
тоже выпуклая, как с упремума.
Оставьте плюс, если понять, например,
и минус, если не понять,
что происходило в последние...
Так, спасибо, вижу.
Так.
Вроде бы большинство поставили,
я так понимаю.
Вот.
Так, окей.
Это мы обсудили историю про...
Максимум.
Все крышки решены.
Вот.
Посмотрим, пойдем дальше.
Какие еще преобразования нам будут полезны.
Так.
Ну, я верю, что про то,
что сумма выпуклых функций
отрицательными коэффициентами выпуклых функций,
вы само определение можете себе указать.
Это вообще несложно.
Вот.
Просто подставляйте и все у вас получается
правильно и неравенственно.
Единственное, что обращаю ваше внимание,
если когда мы говорили про выпуклые множество,
то мы могли их складывать,
то есть лиминков складывать,
с предсвольными коэффициентами.
Вот.
То есть здесь важно,
чтобы коэффициенты были не отрицательными.
То есть нельзя, грубо говоря,
взять и вычислить две выпуклые функции.
У вас получится ерунда.
Вот.
Пожалуйста, не обращайте на это внимание.
Вот.
Следующий пример это то,
какие композиции можно создавать.
Вот.
Тут вот, в частности,
пример скалярной композиции.
Вот.
Ну, давайте сейчас я попробую это расписать.
И посмотрим, каким свойством
должна быть эта функция h,
чтобы ее суперпозиция
с выпуклой функции f
не сломала выпуклые функции.
Вот.
Вот.
Ну, наверное, сейчас я,
чтобы показать просто технику.
То есть у нас есть что?
У нас есть...
Так, это какой номер-то?
Уже сбился счет, как всегда.
Так.
Бла-бла-бла.
Это была...
Двойка была тут.
Соответственно...
Ла-ла-ла-ла-ла.
Да, здесь тройка должна стоять.
Ла-ла-ла-ла четверка.
Ла-ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Ла-ла-ла.
Верно.
Верно.
Можно дальше продолжать.
Вот.
Значит, домашнее упражнение, вы, наверное, можете догадаться,
какое оно будет.
Вот.
Это понять, что будет, если у вас происходит не скалярная
суперпозиция, а векторная суперпозиция.
То есть, упражнение такое.
У вас есть две функции.
Две функции g и h, да?
g, давайте, сравним обозначение h от f от x.
Вот.
И h, например, выпуклу.
f отображает там rm в rm.
То есть, h от f1 от x и так далее fm от x.
И вот надо понять, что функция f, какая она,
чтобы это все еще осталось выпуклу.
То есть, надо что-то поделать по аналогии.
Видимо, понять, каким свойством она будет обладать.
Вот.
Ну, ладно.
Это, значит, домашнее упражнение.
Как же без него?
Вот.
Теперь давайте следующий факт.
У нас были перспективные отображения множества.
Теперь будет перспективное отображение функции.
То есть, пусть f от x выпуклу.
Посмотрим функцию g от xt,
который имеет следующий вид.
t умножается на f, x делить на t.
t, соответственно, больше всего должно быть.
И x на t лежит вовлечение определения.
Вот.
То вот это g от xt тоже выпуклу.
Вот.
Понятно ли что происходит?
То есть, стандартный пример.
f от x пусть будет, ну, все знают эту функцию.
Квадрат второй нормы, например, да?
Ну, теперь давайте просто построим функцию g от xt.
Вот это что это такое?
Это t.
И вот сюда представляется x делить на t.
И у нас остается квадрат второй нормы делить на t.
И эта функция одновременно выпукла.
Ну, выпукла.
То есть, да, тут, наверное, важно упомянуть,
что выпуклость имеется в виду по всем аргументам сразу.
Вот.
Это пример.
Ну, в общем, так.
Понятное преобразование.
Пожалуйста, как-то там.
Поставьте минус, если преобразование непонятно.
В плане, мы его еще не доказали?
Пока не доказали.
Нет, нет, пока ничего не доказали.
Я просто хочу, чтобы узнать, понятно ли,
как это преобразование совершается.
Ну, то есть, в плане...
Не то что мы что доказали, а в плане того,
что просто вот это преобразование,
оно как бы, видите, как-то все там умножается.
Какой-то аргумент странный берет.
Понятно ли, как его, собственно, осуществить?
Так, вроде вижу плюсики, наверное, все понятно.
Ну, по крайней мере так, не вижу минусов.
не знаю того, насколько понятно все, хотя бы минусов нет.
Наверное, если были минусы, надо было бы по-другому рассказать.
Ну окей, давай теперь это как-то докажем относительно небезболезненно.
Понятно, что первый путь это по определению страдать.
Так можно тоже сделать, и все скорее всего получится.
Но мы попробуем пойти немножко по-другому, воспользоваться...
Тут тоже нам понадобится связь над графиком и тем, что мы про над графики знаем.
Давайте просто сейчас попробуем это все дело свести к тому, что нам уже известно.
Да, то есть что нам уже известно.
Немножко валивают, включаются, это все нормально.
Нам известно, что...
Я правильно сформулирую.
Ну, смотрите.
Рассмотрим три точки x, t и s, которые будут принадлежать над графикой функции g.
Что это значит?
Это значит, что...
Вносим на тому, что t f от x делить на t меньше либо равно s.
Мы можем на t поделить.
Будет f от x делить на t меньше либо равно s делить на t.
Это означает, что выражение x, t и s делить на t лежит в над графике f.
То, что я написал.
Смотрите, у нас получилась такая вот связь между над графиком g и над графиком f.
И эта связь действительно осуществляется перспективным преобразованием множества.
То есть тут у нас был xs, то есть у нас было множество из xs выпукло.
И мы его перспективным образом преобразовали в над графикой f.
То есть здесь как бы обратное преобразование в каком смысле получилось.
Ну и обратное преобразование для перспективного отображения тоже, понятное дело, будет упуклом.
Просто противность доказывается.
То есть тут равносильность выпуклости над графикой как раз таки позволяет показать выпуклость функции после перспективного отображения.
Понятна ли такая аргументация?
Не стесняйтесь поставить минут, пожалуйста.
Я вижу, что плюсов пока что два.
И возможно нужно что-то пояснить, чтобы помочь в их появлениях.
Да, вижу, что это прибавилось немножко, но все равно это не очень убедительно.
Давайте может еще что-то проговорим.
Смотрите, у нас была некоторая множество.
Еще раз, идея доказать, что насильность.
Доказать выпуклость эпиграфов.
Вот равносильность их выпуклости.
Вот правильно сказать.
То есть смотрите, сначала записываем определение, что такое у нас эпиграф для g.
Вот он.
И показываем, что этот эпиграф, точнее принадлежность некоторой точке этому эпиграфу,
равносильна тому, что такая точка принадлежит эпиграфу f.
А раз она принадлежит эпиграфу f, мы получаем перспективное преобразование между этими эпиграфами.
Таким образом, в силу того, что мы знаем про перспективное отображение выпуклых множеств,
мы делаем вывод о том, что они выпуклые.
Может быть такая точка рассуждений более аккуратная?
Ого. Кажется, код помогло. Приятно. Здорово.
Так, ну, все еще там шесть.
Конечно, меня тревожит, что вы не ставите минусы, если не понятно.
Все должно быть прям сходу очевидно из объяснения.
Если это не так, то значит надо другому объяснить.
Так, ну ладно, я, к сожалению, поскольку минусов нет, я не очень понимаю,
нужна ли помощь с дополнительными пояснениями.
В общем, зачем нам будет нужна эта штуковина?
Эта штуковина очень нам сильно пригодится, когда мы будем обсуждать,
как преобразовывать выпуклые множества в конической форме.
Да, собственно, эти правила, и еще некоторые,
позволяют автоматически проверить функции на выпуклых.
То есть вы берете некоторые базовые функции, выпуклые с которых доказывается по определению,
дальше с помощью подобного рода преобразования и комбинируете,
получаете целый зоопарк очень большого набора функций,
которые позволяют вам формализовывать достаточно шоуихлозадачи.
Окей, смотрите, сейчас, я надеюсь, буквально минут за пять я смогу рассказать,
так это уже было в прошлый раз, да.
Смотрите, следующий важный момент, который хочется,
я его не всегда рассказываю, но сейчас хочется,
в том, что если у вас есть выпуклая задача,
это еще не значит, что ее всегда легко решить.
Вот, то есть тут есть пример выпуклой задачи,
которая определенная на конуки,
в которой положить матрицу.
Вот здесь это определение дано,
что это как бы под множество,
то есть не под множество,
а что конус положить на полуопределенных,
это под множество вот этого конуса,
и что задача проверки матрицы на непринадлежность к конусу,
уже коин пополна.
И есть пример определения максимально независимого под множество графов.
У нас эта задача сводится к ровной задаче оптимизации,
нам не на таком множестве.
Вот здесь вот это подробнее пояснено.
Вот, когда мы с вами через пару недель
разберемся с двойственностью,
я надеюсь, что я смогу там предоставить
какое-то более детальное пояснение,
потому что эта штука жестко опирается на двойственность,
которую мы пока еще не освоили в достаточной мере.
Полезное упражнение проверить,
чтобы найти спряженный конус к конусу цен, точнее.
Вот, то есть сейчас я нарисую картинку,
чтобы понять не о чем не речь.
Обычно такие картинки хорошо отопливаются.
Да, то есть вот, например, смотрите,
вот у нас есть выпуклые задачи,
по этой картинке.
Понятно, что...
Только внутри них есть...
Сейчас как-то нарисую конструкцию на кружочек.
Какое-то подмножество выпуклых задач,
решаемых за предмельмельное время.
И, собственно,
вся история и сложность в том,
что вот надо понять, чем
конусы Rn+, Sn+, k2, которые порождены второй нормой,
то есть все те самосогласованные конусы,
с которыми мы уже сталкивались,
чем они отличаются от конуса Cn,
по положительных матрицам.
Вот почему вот здесь все хорошо,
и они относятся вот к этому классу,
а вот здесь все плохо,
и оно попадает вот сюда.
То есть задачи выпуклого
на полинамерального способа разрешения существуют.
Ну, по крайней мере, пока что неизвестно.
Понятно ли утверждение?
И может быть, у кого-то будут гипотезы,
почему так происходит?
Не знаю. Интересно.
Просто мы уже об этом немножко упоминали.
Вот, может быть...
Хорошо, давайте поставьте плюсы,
чтобы поняла, о чем шла речь последние пару минут.
Так, хорошо, вижу плюсы.
Наверное, с теорией сложности
у всех все более-менее хорошо.
Не радоваться.
Смотрите, разница,
которая между ними кроется,
это разница в наличии
соответствующих барьерных функций,
которые могут ограничивать этот конус.
То есть для всех конусов,
которые отмечены рангливеньким,
такие барьерные функции есть,
часть из них я уже показываю.
Для этой истории
барьерные функции необходимы не свойствами,
какие-то свойства будут явно в ближнем конце курса.
Их пока не придумали.
Не знаю, есть ли попытки,
есть ли какие-то оценки,
но просто не хватает.
Но в общем,
из-за отсутствия правильных барьерных функций
получается так, что
эти все задачи оказываются непосложными.
Вот такая вот странная, на первый взгляд,
возможная история.
То есть, в принципе, утверждение,
что задачи решаются легко все,
оно формально неверно,
но практически верно,
потому что то, что появляется на практике,
ровно вот этот вот оранжевый кружочек.
Так, ладно, теперь в обратную сторону.
В обратную сторону пример
легкой невыпуклой задачи.
То есть, мне кажется,
уже как-то я упоминал,
что поиск минимального собственного вектора
является невыпуклой задачей,
потому что
невыпуклое множество это область определения.
Вот.
Ну ИКУ, например, СН+,
это не так важно.
Понятно же,
но минус, если понятно, почему это
невыпуклая задача.
Вот это и минус, если не понятно.
Невыпуклая задача.
Непонятно.
Прекрасно.
Она невыпуклая,
потому что область определения нашей пункции,
вот видите вот.
Это невыпуклое множество.
То есть, это, тут вторая норма стоит,
то есть, это граница шара.
Граница шара у нас, я пытался рисовать,
вот. Вы берете две точки на границе,
то есть, равные единицы,
проводите отрезочек, и у вас куча точек,
которые на границе не лежат.
Поэтому это невыпуклое множество,
и поэтому вся задача получается невыпуклой.
Так, стало ли сейчас понятнее?
Так, Лидия, Андрей,
как? Что-то надо еще, может быть, уточнить?
Окей, вижу.
А, вижу плюсы. Спасибо.
Ну вот.
Ладно, я надеюсь, можно продолжать.
Ну окей. Вроде, в общем, ответ здесь
будет понятно, какое это будет
минимальное собственное значение у матрицы Q.
Вот.
Нужно ли это пояснить? Вот этот переход,
он требует пояснения?
То есть, напишите, да или нет.
Видимо, да, да?
Надо пояснить.
О, Михаил, спасибо.
Вот такая задача, да?
Мы можем, поскольку у нас есть требования
на то, что матрица симметричная,
то мы можем по собственным векторам разложить же его, да?
Это наше некоторое решение.
Ну давайте его явно подставим. У нас будет
сумма alpha i t, v i t
транспанированная у.
Так, ну дальше понятно.
Вот, собственно, подставляем, используем определение,
поэтому эта штука, а, это и плюс
v i t транспанированная v j
равно нулю, если i не равно j,
потому что они орко-нормированы.
Оно орко-нормировано. Это просто их свойство.
Поэтому здесь образуется,
что
здесь образуется
вот так.
Вот я не очень правильно написал,
надо написать вот так, что v i t транспанированная
на v j равняется 0,
если i не равно j,
и единички, если i равно j.
Так, оставьте плюс,
если это такие равенства, понятно?
Так, 4 плюсы, 5, 6,
так, 7,
так, 8, good.
Чего? Так, ну 8.
Наверное, давайте пока
может быть на этом остановимся.
Ну если еще кто-то
состоит, то, пожалуйста, делайте это.
И это в итоге наша
новая целевая функция, которая,
по сути, мы теперь ищем альфы на самом деле,
потому что мы выразили наш
неизвестный лектор через альфы.
И норма, то, что у нас норма
нашего, какое у нас ограничение
вот такое,
равно единицы, но опять же можно
квадрат поставить, это ничего не изменит.
Это все
будет выродиться в то,
что сумма квадратов равно единицы.
Ну а дальше
просто делать следующий
вот это больше либо равно,
чем лямбда минимальная,
а сумма
так. Ну, потому что матрица
положительно определена,
поэтому можно так сделать. Все лямбы положительные.
Это равно единице.
Это равно лямбда минимальной.
Вот.
Ну и дальше альфа со звездочкой
равный, условно,
0.0.0.1, на нем это все достигается.
Достигается оценка снизу.
Это должен был быть
восклицательный знак.
Все, это, в общем-то, ответ.
Понятно ли, как мы это получили?
Все прекрасно.
Вопрос остался в силе.
Есть ли что-то непонятное в получении
этих оценок?
Так, ну, я надеюсь, что...
Окей. Короче говоря.
Разрешение с такой, что вот это решение этой задачи
не выпукло, является минимальным собственным значением.
Вот. А раз так, то
для его поиска существует
полинамиальный метод.
Для поиска лямбда миним
есть, ну,
условно говоря, за n куб.
Вот. Таким образом, в общем,
ни любая не выпуклая задача
плоха. Так, окей.
Вроде все продолжает работать, к счастью.
И я все еще хочу показать картинку.
Не любая,
не выпуклая
задача
нерешаема.
То есть, слишком много нет, да?
За разумное время. Вот.
Короче, да. Ага, прекрасно.
Скоро лекция закончится. Окей.
Смотрите, значит,
это все про вот такой функции
и то, что с ними связано.
Давайте сейчас я кратко
пояснил про...
Начну по крайней мере пояснить про те задачи, которые
надо будет поисковать. Вот я думаю, что
наверное сделаю это скорее на уровне
слайдов и доски.
Вот, чтобы...
Дело максимально
лоптизировать и не распыляться.
Да, значит, смотрите, что нам
будет важно. Важно понимать, что такое
стандартная форма выпуклой задачи.
Вот. У нас будут стандартная форма такого
вида. Мы будем минимизировать
выпуклую функцию при условии, что у нас
афинные, ну, линейные ограничения
и вся ограничение типов неравенств,
они тоже выпуклые. То есть,
f0 и fg выпуклые.
Вот. Легко понять,
что вот это вот множество
x таких, что fg
от x меньше либо равно 0,
это выпуклое множество.
Да, ну, берем две точки
x и y, которые в нём лежат
на втипе большой, например, да?
Вот. И просто получим
определение. Получили нужное неравенство.
Надеюсь, что
поставьте там плюс или минус, если
понятно или непонятно. Алё.
Есть кто-нибудь?
О, вижу, вижу, вижу, да.
Возможно, немножко подлагивает опять связь, но вроде
не вырубает. Вот.
Тогда, ну, то есть, вот всё, что
дальше будет происходить, оно будет происходить вот для этого.
Вот. Далее важно понять,
что каким
у нас будут задачи. Вот у нас будет линейное программирование
lp.
В стандартной форме я его уже писал
на одной из первых лекций.
Вот. Тогда у нас здесь будет вот так.
Вот. Собственно, про
конуса я тоже уже говорил, что вот этот конус
rn+,
мы можем заменить на некоторые другой
и получим множество разнообразных
задач
нелинейных, но с
конечной структурой. Вот. Да.
В заключении, важный момент, который
сейчас, наверное, будет особенно вместо сказать,
это то, как, то есть
я уже про это несколько раз говорил,
что если у нас есть, в-первых, вот такая вот задача,
то мы её можем преобразовать
к такой задаче.
Помните, был такой, да, мы там в...
Так, а я показываю дальше.
Поставьте плюс, если помните, что такое было.
Там ещё картинку рисовал про то, что мы
как будто его по епигруппу
идём. Так. Отлично.
Ну так вот. У нас осталось понять, что делается
вот этой штукой, чтобы её переписать
вот в такой вот вид. Так вот, оказывается,
что чтобы это сделать, нам как раз-таки
очень сильно понадобится
и поможет перспективное преобразование
функций. Вот. И как нам это поможет, сейчас
я постараюсь пояснить.
Вот. Так. Сейчас.
Ну. Вот. Ну, смотрите.
Для этого рассмотрим следующий конус.
Если вы поймёте, что это конус, x, y, z.
Вот. И такое, что y
от f от y делить
ой, x делить на y,
как в кофейне, меньше или равно z.
Ну там всё или мы его ещё объединим.
Или полнотой картина. Вот смотрите, ведь это ж
конус. Да?
Кто может сказать, почему он будет выпуклый
для f выпуклой?
Вопрос на внимание.
То есть тут как бы надо...
Интересно два факта. Первый факт. Смотрите, какой.
Что функция f выпукла, поэтому
функция вот это, g от x, y
тоже выпукла.
Это мы только что сегодня несколько минут
назад обсуждали. Помните?
Видите, что это одно и то же?
А, ну и теперь это множество уровней
выпукла функции.
И теперь это множество уровней выпукла функции.
Ну, не множество уровней, а это над график.
Который мы, ну,
обсуждали. Помните, да?
Что у нас все такие tx, что t больше, чем f от x.
Вот. Но здесь то же самое, только у нас теперь
x это x, y, t это z.
То есть вот эта штука
эпиграф от
y, f от x на y.
А поскольку эта функция
выпуклой, как перспективное преобразование
выпуклой функции, то и
kf тоже выпуклое множество. Ну, и то, что это
конус, там, ну, легко умножить
x, y заодно не отрицать на число
и получить то же самое.
Получилось ли воспринять такое, может быть,
немножко скоротичное пояснение?
Так, ну вот. Синей Андрею
получилось. А как дела у остальных?
Так.
Вот.
То есть еще раз. Мы взяли
выпуклую функцию, делали
перспективное преобразование, функцию
g, и построили над график. И внезапно
увидели, что это график или это конус.
А раз так, то неравенство
f от x меньше либо равно
t становится эквивалентным
тому, что x1t
внезапно лежит
в конусе. И для каждой
выпуклой функции мы можем генерировать
свой конус k.
Мы считаем для него, например, сопряженный,
двойственный, и тем
самым получить там, ну, в дальнейшем мы получим
некоторые результаты про коническую двойственность.
То есть вот это вот способ приведения
задач выпуклой оптимизации
в привычном виде с
неравенствами к задачам именно
конической формы, когда все-все
эти нелинейные ограничения
у нас отправились в требование
принадлежности наших
искомых величин некоторому конусу.
То, что мы сегодня и продемонстрировали.
Давайте еще пару минут.
Вот это как раз ровно 10.25.
Давайте еще пару минут
на то, чтобы осмыслить произошедшее
и задать вопросы.
То есть теперь мы
целиком полностью оснащены всеми
необходимыми инструментами для того, чтобы
рассматривать задачу только вида
линейная функция,
а x равно b,
и x лежит в конусе. Все для перехода
от исходной задачи
к задаче вот такого вида.
Задачи вот такого вида у нас есть.
Ну и конус k, он, понятно, будет
для картопроизведения f0, f1,
ну, в общем, понятно, fp.
Ну и, к счастью, для большинства функций
есть довольно простые конусы,
которые им соответствуют.
Можете потренироваться на тех функциях,
которые мы уже с вами рассмотрели,
как те функции будут быть полезными упражнениями.
Тобственно, через пару занятий,
я надеюсь, будет понятно,
почему такая конструкция
задачи, она удобна
для ее решения,
и к этому мы стремимся.
Так, ну что, вопросы,
комментарии, предложения, пожалуйста.
Так, вопросов нет,
комментарии тоже не видать.
Ладно, тогда давайте на сегодня закончим.
В следующий раз тогда быстро, кратко
посмотрим на примеры задач
и перейдем к условиям оптимальности наконец-то уже
и поймем, собственно, что нам надо делать
того, чтобы решить задачу.
Все, всем спасибо. Запись я также скину.
В общем, я надеюсь, ответственные люди
вовремя ее там как-то предобработают,
зальют, куда надо,
и у всех будет к ней доступ.
Большое спасибо за внимание.
И до следующей недели.
Спасибо, до свидания.
