Так, ну чё, поехали.
Мы сегодня начинаем последний блок.
В триллекс у нас нету идёт всё про деревья.
Пообсуждаем всякие разные алгоритмы на них.
Определение давайте я дам такое.
Пусть g это неориентированный граф.
Тогда он называется деревом, если он связан и не содержит циклов.
Сразу замечание, что можем сказать про деревья.
Если же это дерево, то, во-первых, мы можем сразу сказать, что в нём количество рёбер на 1 меньше, чем число вершин.
Ну потому что, что вот это значит?
Что значит, что он связан и не содержит циклов?
Ну давайте я сделаю следующее.
Давайте я нарисую вершин нашего графа.
И буду проводить постепенно рёбра.
Буду проводить постепенно рёбра.
При этом циклы не появляются, и в конце все они попадут в одну и ту же компоненту связанности.
Каждый раз, когда я провожу рёбро, я провожу рёбро между разными компонентами связанности, то есть я беру, соединяю.
Раньше я считаю, что все вершины — это отдельная компонента связанности, стоящая за одной только вершинкой.
Потом провожу рёбра и объединяю компоненты.
Вот компоненты, вот компоненты, потом могу их союдить, станет вот такая большая компонент, ну и так далее.
А раз циклов нет, то я не могу проводить рёбров внутри одной компоненты, а только между компонентами.
Ну и в конце они все должны склеиться в одну большую компоненту, значит всего шагов был ровно минус один.
Если на каждом шаге две компоненты склеиваются, а в конце все в одной компоненте, значит шагов ровно на один меньше, чем вершин.
Вот такое простое рассуждение.
Ну и второе замечание такое, что между любыми двумя вершинами существует ровно один простой путь.
Существует единственный простой путь между ними.
Ну тут я менее формально скажу, смотрите, вот если есть две вершинки у и в, если вдруг предположить, что между ними есть два разных пути каких-то, вот такой вот и такой вот,
ну тогда как бы видно на картинке есть цикл.
Да, это так неформально, чтобы доказать формально и показать, что при наличии двух разных путей в графе найдется цикл,
надо сказать, ну давайте посмотрим на множество ребер, используемых в этих путях, возьмем их симметрическую разность, и это получится в точности цикл.
Потому что поскольку пути различные, то это будет какое-то непустое множество, и в нем у всех вершин будет степень 2 как раз такие,
ну за счет того, что мы берем симметрическую разность, мы что-то похоже уже делали, когда эти ребер же доказывали,
брали симметрическую разность двух множеств, ну здесь будет как раз цикл, ну точнее цикл там или несколько циклов может быть,
если возьму вот такое что-нибудь и вот такое, ну тогда вот вам, пожалуйста, куча циклов получается.
Так, значит давайте посмотрим на следующую характеристику графа.
Определение диаметром графа G называется максимально возможное кратчайшее расстояние между всеми парами вершин.
Максимум по всем УВ, дист УВ, ну где дист как обычно это число ребер на пути между ними, ну на кратчайшем пути между ними.
Более того, поскольку мы сказали, что путь на самом деле единственный между вершинами, то можно даже не особо вариться про то,
что он кратчайший, не кратчайший, он единственный, на единственный путь между У и В есть.
Вот, простой. Ну и давайте научимся как в дереве находить диаметр.
Ну давайте алгоритм.
С помощью DFS, если мы запустим DFS от произвольной вершины дерева, мы на самом деле сможем все дерево подвесить за вот этот корень, за эту вершинку,
и по сути тогда картинка будет примерно такая. Вот мы какую-то вершину назначили в качестве корня, потом у них будет сколько-то детей на первом уровне,
потом у них будут дети на втором уровне соответственно, ну и так далее.
То есть это в каком-то смысле как дерево обхода BFS, мы взяли корень, соответственно все вершины смежные с ним лежат на первом уровне,
все новые вершины смежные с ним на втором и так далее.
Но поскольку в графе у нас все пути единственны между парами вершин, то это может быть даже не BFS, а просто DFS,
и каждый раз, когда мы переходим в новую вершину, мы сразу понимаем, что то расстояние, которое мы донесли, это есть кратчайшее расстояние.
Поэтому вместо BFS можно всегда использовать DFS на деревьях.
Просто встали в R, пошли куда угодно, это получается вершина на глубине 1.
Пошли в любую непосещенную вершину из нее, это вершина на глубине 2, ну и так далее.
Потому что назад я никуда не перепрыгну и более коротких пути никогда не найду.
Поэтому если я нашел путь какой-то длины, то он есть кратчайший путь до вершины.
Поэтому это можно делать с DFS.
Ну тогда давайте скажем следующее.
Давайте x это произвольная вершина дерева, запустим DFS от x, и тем самым мы найдем все глубины всех вершин, если x это корень.
То есть вот я подвесил наше дерево за x, у каждой вершины теперь есть своя глубина.
Это глубина 0, глубина 1, глубина 2 и так далее.
Давайте от depth обозначу.
Глубина здесь 0, тут 1, тут 2.
И давайте найдем параллельную вершину с максимальной глубиной.
Пусть y, вершина с максимальным depth от y.
То есть другими словами y это самая удаленная от x вершина.
Потому что глубина по факту просто расстояние от корня или там до корня.
Вот пусть y самая глубокая вершина.
Вершина с максимальной глубиной.
Тогда давайте мы запустим DFS от y.
Ну опять пусть z это вершина с максимальной глубиной, ну теперь уже относительно y.
То есть я переподвесил моё дерево, запустил новый DFS от y, вынес y в корень и заново насчитал все глубины.
Так вот пусть z это вершина с максимальным значением глубины от z.
Вот.
Тогда я утверждаю, что y, z это диаметр.
То есть на пути между ними как раз достигается то самое максимальное кратчайшее расстояние.
То есть смотрите, что мы сделали.
Наша цель была найти вообще максимальное кратчайшее расстояние между всеми парами вершин.
Что я сделал?
Я сделал произвольный x, нашёл самую далёкую от него y, нашёл от y самую далёкую z.
И вот оказывается, что y, z это диаметр.
То есть нет более длинных путей, чем пути между y и z.
Понятно, что это работает за o от n.
Потому что по факту мы просто два раза запустили DFS, а DFS работает за n плюс m.
А поскольку у нас в нашем дереве m от n минус 1, то значит всё работает просто o от n.
Теперь почему-то всё корректно.
Давайте рассмотрим настоящий диаметр.
Вот есть a, вот есть b.
Пусть между ними, единственный простой путь между ними, это диаметр.
Тут какие-то вершинки есть.
Тогда давайте поймём вообще, как дерево всё может выглядеть, если a, b это диаметр.
То есть мы вот так вот взяли две самые далёкие вершины, растянули их, нарисовали дерево так, что a и b образуют какую-то прямую.
Давайте поймём, как вообще всё остальное дерево может выглядеть.
Я утверждаю, что вот здесь вот вершин быть не может.
Потому что если бы у b был какой-то сосед отлично от вот этого, тогда мы бы могли найти путь от a до сюда, и получился бы путь длиннее диаметра.
Такого не бывает.
Значит здесь никого нет.
Что может быть здесь?
Я утверждаю, что к этой вершине, давайте вот так нарисую,
что если я рассмотрю компоненту связанности, который получается после удаления этих двух ребер, подвешенный в это вершине,
то здесь будет дерево глубины максимум 1.
Потому что если отсюда есть глубина 2, то я точно так же мог бы от a дойти до сюда,
и потом вместо шага в b сделать два шага вниз, получить путь больше, чем диаметр.
Поэтому всё, что находится здесь, это под дерево глубины максимум 1.
Ну и давайте симметрично скажем, здесь ничего нет, здесь под дерево глубины максимум 1,
здесь под дерево глубины максимум 2, потому что если было бы 3, то я мог бы от a дойти до сюда,
и в этом вместо этих двух ребер использовать 3 ребра вниз.
Симметрично здесь не больше, чем 2 глубина, здесь не больше, чем 3, не больше, чем 3,
ну и здесь центрально имеет глубину максимум 4.
Ну как-то так выглядит наше дерево.
И теперь если просто аккуратно проанализировать, что делает наш алгоритм,
то мы поймём, что реально y и z это тоже будет диаметр.
Ну давайте что-нибудь нарисую. Давайте скажу, что x где-нибудь вот здесь вот лежало.
Пусть x было здесь.
Тогда y это самая далёкая вершина от x.
Так, я утверждаю, что...
Так, сейчас будет мерзкая формула, но я её хочу написать всё равно.
Я утверждаю, что если я найду самую далёкую вершину от x, y,
ну не знаю, где-нибудь вот здесь пусть,
тогда максимальное расстояние от y до a или от y до b, максимум до двух расстояний, это диаметр.
Так, одну секунду.
Да, почему?
Ну потому что если не так, то я на самом деле мог бы вместо y взять a или b,
и расстояние от x я бы увеличил.
Ну например, давайте скажем, что y где-нибудь вот здесь вот находится.
Y находится где-нибудь вот здесь, то есть на расстоянии от 1 от вот этой вершины.
Ну тогда понятно, что ни a y, ни b y, это не диаметр, потому что они меньше длины имеют.
Ну тогда смотрите, на самом деле можно было бы от x дойти до сюда,
и вместо того, чтобы идти до y, дойти до b, мы бы получили только больше расстояния.
Поэтому y не может быть самой далёкой вершины от x.
Ну и вообще в любом случае можно показать, что если y находится...
То есть на самом деле вот это равенство можно интерпретировать так,
что y это вершина в одном из этих поддеревьев на максимально возможной глубине.
То есть если она здесь лежит, то она обязательно на глубине y, на глубине 3 лежит.
То есть на максимально возможной, какой у нас есть тут ограничение.
Потому что если она лежала бы выше, то тогда b была бы дальше от x, чем y.
Можно дойти до сюда, и вместо того, чтобы пройти меньше, чем 3 ребра здесь,
можно пройти 3 ребра здесь и попасть в более далёкую вершину.
Ну значит y как раз вот на максимально глубоком расстоянии,
возможном от очередной вершины нашего пути.
Ну а раз она на максимально возможном расстоянии от этой вершины,
то тогда либо досюда диаметр, либо досюда диаметр.
Ну более-менее всё.
Поэтому потом, когда я запускаю DFS от y и нахожу самую далёкую вершину от y,
мы найдём как раз-таки либо a, либо b, либо на самом деле возможно что-то ещё.
Например, мы могли бы найти вот такой вот путь.
Это тоже может быть диаметр.
Ну его длина такая же, как длина пути a-b.
То есть никто не гарантирует, что вы найдёте тот самый диаметр a-b,
но длину вы найдёте такую же.
Потому что раз вот это вот верно, максимальное расстояние от y до a или от y до b, это диаметр.
Мы найдём самую далёкую вершину от y в качестве z,
но понимаем, что она находится на расстоянии в точности таком же, как диаметр.
Вопросики?
Ну тут рука махается.
На самом деле надо просто въехать, что глубины вот этих подеревьев вот так вот ограничены,
и понять, что делает DFS, что делает вот этот алгоритм, если x где-то лежит.
Где может лежать y?
Так, хорошо.
Тогда давайте определение.
Скажем, вот здесь хорошая картинка.
Вот эта вершина называется центром.
Центр всего дерева.
То есть по факту это просто серединка диаметра.
Вот, короче, любого, да?
Если чётность не совпала, то там будут две вершины посередине, они обе центры.
Значит, определение.
Если диам, вот g, ну я считаю, что g-дерево здесь,
если диаметр имеет чётную длину,
то его середина называется центром.
Ну а если длина нечётна,
то две центральные вершины на нём это будет центры.
То есть, например, если у меня есть вот такие вот пять ребер,
то две центральные вершины это центры.
Вот, и простое утверждение говорит о том,
что центры лежат на всех диаметрах.
То есть сколько бы ни было центров, один или два,
то есть такая картинка или такая,
эти центры лежат на всех диаметрах.
То есть, если у меня есть вот эти центры,
то они лежат на всех диаметрах.
Если бы ни было центров, один или два,
то есть такая картинка или такая,
эти центры всегда лежат на всех диаметрах вообще.
Любой центр лежит на любом диаметре.
Ну давайте докажем.
Посмотрим случай сначала отчётной длины,
когда центр однозначно определён.
Давайте нарисую какой-то диаметр.
Вот его центр.
Пусть какой-то другой диаметр через этот центр не проходит.
Значит, он целиком либо вот здесь слева,
либо целиком вот здесь справа.
Ну вот, да.
Ой, как мерзко.
Сейчас я полминутки позалипаю.
Если не получится, то руками помашем.
Ну вот, да.
Но вот не очень понятно, на самом деле.
Ладно, да, окей, придётся.
Ну да, смотрите.
Давайте вот опять нарисуем вот эти вот по деревьям.
То есть я знаю, если я ещё продлю его немножечко,
я знаю, что здесь по дереву глубины максимум 2,
здесь по дереву глубины максимум 1,
здесь ничего нет, но здесь то же самое.
Но если я предположу вдруг,
что есть какой-то диаметр, не проходящий из этого центра,
то значит, второй диаметр находится целиком либо здесь, либо здесь.
Ну вот, да.
Ну вот, да.
Ну вот, да.
Второй диаметр находится целиком либо здесь, либо здесь.
Но давайте попытаемся найти максимально возможную длину пути,
которая находится вот в этом подграфе,
не содержащем этого центра слева.
Ну, видимо, он имеет длину максимум 4.
Ну, в нашем случае, да.
На самом деле, он имеет длину строго меньше, чем вот этот большой диаметр,
потому что, ну, как он может выглядеть?
Если он даже находится где-то вот здесь,
ну, вот так вот, 2 вверх, 2 вниз.
Ну а если он идет куда-то влево,
то опять-таки длину максимум 2 может себе прибавить.
Ну да, да, да.
В любом случае, этот путь выглядит как-то так.
Мы из одного под дерево идем куда-то влево и спускаемся в другое под дерево.
Мы из одного под дерево идем, ходим.
Но понятно, что тогда суммарная длина вот этого пути,
просто длина этого пути, меньше, чем...
Ну, короче, меньше, чем...
Да. Меньше равно, чем вот этот путь, видимо.
3, 4. Удвоенный, да.
Вот.
Ну, неприятно, короче.
Ну, кому-то понятно.
Хорошо.
Я говорю, что путь вот здесь лежащий, он строго меньше длины имеет.
Строго меньше длины имеет.
То же самое, если у нас два центра, давайте вот это вот рассмотрим.
Вот они два центра.
Если вдруг диаметр не содержит, скажем, вот эту вершину,
значит, он находится целиком либо здесь, либо здесь.
Ну и тот же самый аргумент проходит.
Скажем, если он лежит здесь,
то значит, мы знаем, как здесь ограничены глубины всех этих под деревьев.
Ну и опять, если посчитать максимально возможную длину пути,
которая здесь находится...
Обе-обе. Любой центр лежит на любом диаметре.
Ну, понятно, что они...
Неважно, да, в любом случае это одно и то же рассуждение.
Неважно, как это сказать, можно ли слаться из одного в другое.
Ну, то же самое, если здесь померить максимальную длину пути,
то она будет меньше, чем весь большой диаметр.
Вот, хорошо.
Вот.
Вот.
Вот.
Так, следующая полезная характеристика.
Центроид.
Вершина.
Вершина.
Вершина.
Вершина.
Вершина.
Вершина.
Вершина.
Вершина.
Вершина.
Вершина.
Вершина.
Вершина.
Вершина.
Вершина.
Вершина.
Если после ее удаления размер всех компонент связанности
g-v, то есть в графе, получающемся удалением вершины v, ну и, соответственно, всех реберезней исходящих,
если в этом графе все компоненты связности
имеют размер не больше, чем n пополам, ну где n, как обычно, число вершин.
Утверждение такое же, что центроид всегда существует, и он либо единствен, либо их два, и не соедини ребром.
Центроид всегда существует, и он либо единствен, либо их два, и не соедини ребром.
Так, давайте сначала докажем, что он всегда существует. Давайте придадим алгоритм поиска центроида.
Алгоритм такой. Давайте мы в нашем DFS еще посчитаем для каждого поддерева его размер.
Вот смотрите, мы подвешиваем, мы всегда подвешиваем дерево за какую-то вершину, за какой-то корень,
и, соответственно, неявно мы ориентировали все ребра сверху вниз, да, от корня вниз к листам.
Давайте мы для каждой вершины сохраним, сколько вершин лежит в ее поддереве.
То есть вот для каждой вершины v мы хотим посчитать, сколько, вот здесь вот суммарно, вершин находятся в ее поддереве,
то есть сколько вершин достижено из нее по ребрам вниз. Это будет называться sub3 от v, размер поддерева.
Это очень легко посчитать с помощью DFS, ну потому что если я для какой-то вершины,
точнее если я для всех детей какой-то вершины знаю размер их поддеревьев, то есть я знаю сколько здесь, знаю сколько здесь,
то размер вот этого поддерева с корнем в этой вершинке, эта сумма размеров поддеревьев с корнями в ее детях плюс один.
То есть мне надо либо в поддерево пойти, либо остаться в вершине v, сумма поддеревьев плюс один.
Вот, значит хорошо, давайте мы с помощью DFS насчитаем все наши sub3.
С помощью DFS найдем все sub3.
Для всех вершин посчитаем размер поддерева.
Ну а дальше делаем следующее, смотрите, вот у меня есть корень v.
Понятно, что его размер в точности n. В поддереве корни лежат все вершины.
Давайте сделаем следующее, давайте мы будем идти в такого сына, у которого размер поддерева хотя бы n пополам.
Вот если здесь sub3 хотя бы n пополам, то мы в него спускаемся.
Здесь то же самое, если есть какой-то сын, у которого размер поддерева хотя бы n пополам, мы в него спускаемся.
И так далее, пока соответственно не дойдем до вершины, у которой нет такого сына.
То есть мы закончимся либо в вершине вообще без детей, либо в вершине, у которой все дети имеют sub3 строго меньше, чем n пополам.
А сама вершина еще имеет sub3 больше набравной, чем n пополам.
Ну тогда понятно, что вот эта вершина, последняя вершина, у которой sub3 больше, чем n пополам, является центроидом.
Потому что после ее удаления что происходит? Давайте так нарисуем.
Что происходит после удаления? Во-первых, все поддеревья дочерние становятся компонентами связности, но мы знаем, что их размеры меньше, чем n пополам.
Потому что у них sub3 было меньше, чем n пополам.
С другой стороны, мы знаем, что все вот это поддерево суммарно имело размер хотя бы n пополам.
Значит, дополнение, все остальное, имеет размер не больше, чем n пополам.
Потому что если здесь хотя бы половина, то в дополнении не больше половины всех вершин.
Ну а значит, удаление этой вершины как раз оставляет мне несколько компонент связности и вот эту большую.
Все размеры которых не больше, чем n пополам.
Профит.
То есть по факту алгоритм очень простой. Мы просто спускаемся вниз в произвольную вершину sub3 хотя бы n пополам, пока так можно делать.
Пока есть сын с размером поддерева хотя бы n пополам, спуск в него.
Последние вершины, в которые мы закончили, это будет центроид.
Понятно, что этот алгоритм конечен, но мы не можем бесконечно долго спускаться по нашему дереву, потому что он просто конечен.
Значит, рано или поздно мы закончимся в вершине, которая удовлетворяет всем этим свойствам.
Мы нашли какой-то, мы показали, что он существует.
Конечно, иногда их бывает два, например, в таком интеллектуальном дереве.
Здесь обе вершины центроида.
В более сложном дереве, вот таком тоже.
А не обе центроида.
На самом деле это может быть.
Мы нашли самый низкий центроид.
Возможно, еще вот этот товарищ тоже центроид.
Потому что для него тоже самое верно.
Если размер вот этого по дереву ровно напополам, то получается после удовлетворения этой вершины здесь будет напополам и сверху меньше напополам.
Ну, значит, возможно вот эти два центроида.
Ну, неважно.
То есть вот это рассуждение нужно, чтобы показать, что он существует.
Теперь мы докажем, что их не больше, чем два.
Значит, это мы показали, что он существует.
Почему центроидов не больше, чем два?
Ну, пусть их...
Я скажу так.
Пусть есть два центроида, не соединенные ребром.
Придем к противоречию сейчас.
Если мы это сделаем, то мы покажем на самом деле, что центроида всегда не больше, чем два.
Потому что если бы у нас было три центроида, то понятное дело, что хотя бы два из них ребром не соединены,
но не может быть такого, что все они соединены ребром.
Иначе есть цикл.
Значит, мы показали, что центроидов будут не больше, чем два.
И если их два, то они соединены ребром.
Ну собственно то, что мы хотели показать.
Давайте предположим, что есть два центроида не соединенные ребром.
Ну вот есть какой-то у, есть какой-то в.
есть кое-то v. Давайте рассмотрим путь между ними. Здесь будет хотя бы одна
промежуточная вершина, потому что там не ребро, значит хотя бы два ребра между
ними. Вот. Ну и давайте напишем следующее. Давайте опять у нас есть какой-то путь,
давайте рассмотрим это под дерево, это под дерево, вот это под дерево. То есть
компоненты связанности, на которые распадается дерево после удаления всех
ребер этого пути. Ну смотрите, размер вот этой штуки хотя бы n пополам, потому что
поскольку u это центроид, то после ее удаления вот это вот все будет связанной
компонентом размера не больше н пополам. Но после удаления u все, что
лежит здесь справа на этом пути и в под деревьях, имеет размер не больше н
пополам. Значит вот это вот как дополнение имеет размер хотя бы n
пополам. Согласны? Ну то же самое для v, верно? Вот это вот под дерево имеет
размер хотя бы половина, потому что поскольку v центроид, то после удаления
вот это вот имеет размер максимум n пополам, а значит дополнение к нему хотя бы
n пополам. Ну все, противоречие. Мы получили, что есть два под дерево размера n
пополам, между которыми есть еще по крайней мере одна вершина. Значит суммарный
размер дерева это хотя бы n пополам плюс хотя бы n пополам плюс хотя бы один. А
надо n получить, но такого не бывает. Мы получили, что n больше чем n пополам
плюс n пополам плюс один равно n плюс один. Противоречие.
Нет, вот здесь я когда пишу n пополам, это у меня всегда число, сравнение как с
числами обычными. Я здесь нигде ничего никуда не округляю. Это вам в коде, если
надо, вам надо будет подумать куда округлить. А вот здесь я все, ну как бы у
меня математика была, у меня не программирую, у меня математика была, без округления
работала.
Так, хорошо. Значит, ну с центроидами тоже разобрались. Упражнения, ну это вот
часто окажется, да, что центры и центроиды что-то похожее, что там их всегда один или
два, и они тоже там, если два соединяются ребром, но вот придумайте деревья, в которых
центроиды и центры это разные вершины. Ну вот придумайте. Придумать дерево, в котором
центры это не то же самое, что центроиды. Так, хорошо. Следующий сюжет про изоморфизмы.
Определение. Пусть g и h этого графа, тогда функция phi, действующая из множества вершин
графа g, множество вершин графа h, называется изоморфизмом, если выполняются одновременно
два условия. Во-первых, фиетабеекция. Во-вторых, ребра, соединенные ребром, переводится
в ребра, соединенные ребром, а ребра, не соединенные ребром, переводится в ребра,
не соединенные ребром. Значит, если uv это ребро графа g, то, соответственно, фиату,
fiat g, fiat v, то есть это ребро графа h. А если не ребро, то не ребро.
Вот. Значит, на самом деле изоморфизм это по факту просто перенумерация вершин такая, что вот после
нее граф остается самим собой. То есть в каком-то смысле g и h это один и тот же граф, отличающийся
лишь перенумерация ребр. Ну что такое биекция? Это как раз перенумерация. Мы все вершинки
перенумеровываем просто, и у нас сохраняются все ребра. То есть, например, вот есть такой граф,
и такой граф. Вот. Они изоморфизм, ну понятно, у них одинаковая структура. Понятно, что их можно
перенумеровать так, что один переводится в другой. Надо сказать, что вот это вот перенумеруется в
тройку, вот это в единицу, но эти два в двойку-четверку. То есть изоморфизм это как бы одинаковость с
точностью до перенумерации вершин. Вообще говоря, задача проверки графов на изоморфность,
задача сложная, и пока ее за пленом решать не умеют. То есть если вам даны два графа, произвольные,
неориентированные два графа, и спрашивают изоморфы они или нет, то есть ну можно ли перенумеровать
вершины одного так, чтобы получить другой, это сложная задача, пока ее никто решать не умеет за пленом.
А с деревья мы решим за n log n. Наверное, не буду записывать, не очень важна информация. С деревьями давайте
научимся проверять изоморфность двух деревьев. Значит сначала давайте считать, что деревья корневые,
и давайте проверим два корневых дерева на изоморфность. Корневые это по факту значит,
что они просто за какую-то вершину подвешены, и корень должен перейти в корень. Давай считать,
что вот они корневые у нас. Ну здесь все очень просто. Идея следующая. Давайте мы для каждого
поддерева, который у нас в принципе существует в одном из наших деревьев, давайте мы каждому
поддереву сопоставим какой-то номер CO2, который однозначно определяет класс эквивалентности вот
этого всего поддерева. То есть мне нужно сделать так, что изоморфные поддеревья отображаются в одно
то же число, а разные, точнее не изоморфные, поддеревья отображаются в разные числа.
То есть мне нужно биекции из поддеревьев в натуральные числа, чтобы изоморфные соответствовали
одинаковым числам, не изоморфные – разным. Например, можно поддеревья, состоящие из одной
вершины, все отобразить в ноль. Ну понятно, это все изоморфные поддеревья, состоящие из одной
только вершины, они и заморфнут. А если у меня, скажем, вот такие есть два дерева, то они должны
в разные числа отобразиться. Например, это в один, это в два. Ну или наоборот, как угодно.
Разные поддеревья в разные числа, одинаковые в одинаковые. Как это сделать? Ну смотрите, вот есть дерево.
Давайте мы каким-нибудь DFS-ом сейчас посчитаем классы эквалентности всех поддеревьев.
Ну для листьев понятно. Давайте скажем, что лист это по факту поддерево из одной вершины.
Давайте сразу скажем, что такое поддерево кодируется нулем. Теперь пусть есть какая-то вершина.
И для всех ее детей мы уже знаем номер класса эквалентности соответствующего поддерева.
То есть если есть V, то я рекурсивно запустился от всех детей и уже знаю C для всех вот этих
поддеревьев. Ну давайте скажем, что это у1, у2, у3. Соответственно у меня класс эквалентности это C от у1,
C от у2, C от у3. Ну они рекурсивно там нашлись с помощью DFS. А дальше смотрите, чтобы понять класс
эквалентности V, мне на самом деле достаточно знать вот эти вот числа как мультимножество. Потому что
понятно дело, что от перестановки этих чисел между собой у меня изоморфинность не пропадает. Я
всегда могу просто поменять порядок следований детей, так что у меня поменяются два числа местами.
С другой стороны, если есть какая-то другая вершина, у которой вот это вот множество классов детей
отлично от вот этого множества, то они понятное дело неизоморфны. То есть если здесь скажем классы
0,1,4, а есть другая вершина, у которой классы 0,1,3. Ну понятно дело они неизоморфны. Мы не можем
понять, что 0 надо отобразить на 0, 1 на 1, а 4 на 3 мы никак не отобразим, потому что они неизоморфны.
Неизоморфны соответствуют разным числам. Значит у меня каждая вершина по факту кодируется мультимножеством
вот этих вот классовых эквалентностей детей. Давайте после перерыва доведем этот алгоритм.
Итак, давайте алгоритм напишем, может быть в гоблинском переводе, но все же. Смотрите, я сказал,
что мне вот здесь вот нужно как бы мультимножество сравнивать на равенство между собой. Для этого давайте
я просто сложу их в вектор, вот эти вот числа я сложу в вектор и посорчу его. Тогда понятно, что равным
мультимножством соответствуют одинаковые векторы, разным разным. После сортировки одинаковое
мультимножство дают одинаковые векторы, разные разные. То есть я вот это складываю просто в вектор,
вектор int и сортирую его. И чтобы узнавать, какой номер класса эквалентности будет соответствовать
вот этому вот вектору, я заведу map из вектор в int. У меня будет map из вектор в int. Ну давайте
как-нибудь назову num. Эта штука говорит следующее, что если у вершины вектор детей образует вот такой
вот набор классов, тогда номер класса эквалентности самой вершины вот такой-то. А отображение из
вектор в номер, что если дети вот такие, то сама вершина имеет такой класс эквалентности.
Слово hash только у вас в голове пока что. У меня его нет, у меня нет и не будет. Итак,
DFS. Значит, давайте заведем какой-нибудь вектор A. Проходим по всем детям. Ну давайте здесь я имею в виду,
что как бы вот сейчас, во-первых, всех именно детей. Если у меня граф был не ориентирован,
то мне нужно проверить, что я не поднялся в родителя, но давайте там в комментариях напишу.
Tu это ребенок V. Если у вас граф не ориентирован, надо проверить, что вы не в родителя поднялись,
а именно вниз пошли, в новую вершинку. Но это легко делается. Запускаемся рекурсивно и считаем,
что этот DFS уже сделал так, что ceut tu корректно определено. Ceut tu это номер класса эквалентности
по дереву с корнем вту. Значит, его надо pushback-нуть в A. A pushback ceut tu. После этого цикла в A лежит как
раз-таки то самое мультимножество номеров класса эквалентности детей. Дальше у него нужно посортировать.
Ну и, собственно, в вершине V присвоить классы эквалентности, которые соответствуют этому
вектору A в нашей мапе. Но, возможно, его, правда, еще не существует. Давайте когда его заведем и
скажем, что вектор A соответствует какому-то новому числу. То есть, если его в мапе еще не было,
давайте положим и скажем, что он соответствует какому-то новому натуральному числу,
которого еще не было. Давайте какой-нибудь глобальный счетчик я заведу, каунтер какой-нибудь,
равный нулю изначально. Если, ну тут опять я напишу как умею, вы наверняка это лучше можете
написать. Значит, если в num не было A, если неверно, что он там был, тогда я его туда кладу с новым
каунтером. То есть, я завожу новый класс эквалентности, говорю, что этот вектор A соответствует
кнтшке и кнт увеличиваю. numata равно knt++. Все, теперь у меня в мапе я знаю, что этот вектор A
чему-то соответствует. Но надо сказать, что c от v равно numata. Конец. Теперь мы для каждого
подерева знаем номер классикой эквалентности. При этом, одинаковым и заморфовым подеревям
соответствует одинаковая классика эквалентности, разным и разным. Ну и в терминах исходной задачи,
если есть два корневых дерева, вот есть одно дерево, есть другое дерево, как проверить,
что они не заморфованы? Ну давайте запустим dfs здесь, оба посчитают класс эквалентности для
корней. Если они одинаковые, то дерево изоморфное, если нет, то не изоморфное. Ну потому что, как бы,
у нас вот сохраняется вот это свойство, что одинаковым векторам соответствует одинаковое число.
Значит, изоморфность это то, что у нас вот эти цешки в корнях одинаковые. Да-да, корневые деревья
у нас, поэтому мы подвесили за корень, и соответственно тогда корень обязательно должен в корень перейти.
Не торопитесь, пожалуйста. В точку. Значит, за сколько это работает? Я отражаю, что за inlog. Почему?
Вообще не очень понятно. Потому что в мапе у меня лежат в качестве ключей векторы, а векторы
сами сами могут быть достаточно длинными. Я их pushback'у расширяю. Но за сколько вообще тогда
работает сравнение, за сколько работает запрос к мапе? Вот это вот за сколько работает, вот это вот
за сколько это работает? Ordered map написано. Я unordered не знаю, что такое, и вам не советую, и вам не советую.
Так вот, вопрос к вам. За сколько работает вот такая операция? Проверка вхождения a в num.
Чуть дольше, потому что как бы за логарифом действие в мапе, но каждое действие это сравнение a с каким-то другим ключом.
Как у нас работает дерево поиска? Мы встали в корень, сравниваем корень с нашим a, и спускаемся там влево
или вправо. Поэтому не просто логарифом, а логарифом умножить на время сравнения. И поскольку у меня
векторы это какие-то сложные объекты, то их сравнение работает задолго, но на самом деле за модуль a.
Потому что чтобы сравнить вектор a с каким-то другим вектором, достаточно вот такого времени. Мы идем
слева-направо по обоим векторам, либо один из них кончился, либо мы нашли два, ну короче,
обычное лексиграфическое сравнение векторов. Либо один кончился, либо мы нашли позицию, в которой один
отличается от другого, тогда мы знаем, кто из них меньше, кто больше. Вот, ну тогда все вот эти штуки
работают за analog-n. Поэтому суммарное время работы это, ну вот здесь вот какая-то линия из-за всяких
DFS-ов, push-backs и так далее, плюс сумма по всем вершинам, ну по a давайте напишу, analog-n. Вот, а вот это вот, это n.
Потому что размер a это в точности количество детей у вершины v, а суммарное количество детей
по всем вершинам, это просто общее число вершин. Все, поэтому это будет analog-n. Понятно? Чудно, ну все,
значит корневые деревья мы на изоморфность научились проверять. Теперь некроневые.
Решение очень простое. Давайте оба дерева подвесим, ну скажем, за центроид. Идеальный мир, это когда
центроид единственный. Тогда мы точно знаем, за какую вершину надо подвергать первый дерево, за
какое второе. И понятное дело, и понятное дело, что при изоморфизме центроид перейдет в центроид.
Ну потому что у меня полностью графы сохраняются, значит все свои тоже сохраняются. Вот, поэтому если
были единственные, мы бы просто за них подвесили, запустили тот алгоритм и проверили, что корневые
деревья изоморфны. Ну а если там два центрои, давайте просто переберем, за какой центроид мы
подержим в каждом дереве. И хотя бы в одном из случаев должна быть изоморфность. Переберем в качестве
корней центроиды обоих деревьев. Ну все, дальше дерево становится корневым, мы умеем проверять
корневую изоморфность. Собственно все. Конечно, можно центры. Можно взять в качестве корня любую
характеристику, которая от единицы вариантов. Тогда симплотика останется точно такой же.
Я не шарю. На самом деле здесь можно два, потому что можно в первом один зафиксировать, а второй
перебирать. Можно не перебирать в первом. Я не знаю, кто единственный там. Давайте напишу, что можно
центры. Альтернативно можно подвесить за центры. Ну вот. Поэтому симплотика остается такой же,
Вопросики? Смотрите, не можем, потому что без сортировки мы, скорее всего, никуда не продвинемся.
Да, кстати, я забыл посчитать время работы сортировки, но понятно, что сортировка работает
за аллога. И это меньше, чем аллогн. Поэтому вот это вот доминируется вот этим. Хэш таблица,
говорю, не даст выигрыша, потому что вам нужно что? У вас самое главное, это проверять мульти-множество
на одинаковость или различность. Вот без сортировки я не умею этого делать. Ну то есть нет, можно
как-нибудь просто каждому числу поставить что-нибудь большое, как-нибудь проксорить. Ну можно, да.
Ну ладно, короче, вы меня поняли или нет? Это хороший вопрос. Тоже думаю,
что ничего не даст, потому что у вас хоть векторы маленькие, но там числа могут быть до n. И поэтому
у вас тогда будет за n каждый с сортировкой таких n штук. Короче, подумайте, но мне кажется,
что быстрее чем аллогн не будет. Чего? Ну подумайте. Ну вы что, вам аллогн не нравится, что ли? Если
хотите лучше, думайте сами. Так, последний сюжет на сегодня это LCA, он же наименьший общепредок.
Я его не давал, ну сейчас скажу. Неформально, да? Я что делаю? Корневое дерево, когда выделена какая-то
вершина, названная корнем, и я подвешиваю все дерево за нее. Скажу так, формально, что такое, вот так скажу,
значит, корневое дерево это когда ребра ориентированы по направлению от какой-то одной вершины ко всем
остальным. То есть я перехожу к ориентированному уже графу, но просто путем введения ориентации
на всех этих ребрах по направлению от одной вершины, от корня до всех остальных. Это то же самое,
то есть мы как бы любую вершину можем назначить корнем, просто сказать, что ты корень, запустили
DFS, ориентируй ребра из нее вниз. И тогда, соответственно, вот эта вот штука, вот здесь,
в точности мы проходим всех детей в порядке сверху вниз. Неважно, мы можем выбрать что угодно, мы знаем,
что вот если наши деревья вот эти вот некорневые, если некорневые деревья изоморфные, ну давайте
с центроидами. Понятно дело, что центроид перейдет в центроид, потому что вообще изоморфизм это как бы
просто перенумерация вершин по факту. Тогда понятно, что если в исходном дереве какая-то
вершина была такова, что ее удаление оставляет все компоненты размера n пополам, не больше чем
n пополам, то в другом, после перенумерации, она сохраняет это свойство, там все равно все компоненты
будут не больше чем n пополам. Вот, ну вот давайте я насильно, тогда понятно, что центроид должен
перейти в центроид. Давайте я насильно назначу центроиды корнями обоих деревьев, подвешу, ориентирую
все деревья сверху вниз от центроида вниз. Может, может, может, поэтому я и говорю, я перебираю
центроид в первом дереве, перебираю центроид во втором по дереве и проверяю, можно ли первый пересел
в второй. Ну а уже после этого я их объявляю корнями и проверяю их заморсанность как корневых
деревьев. То есть я перебираю центроид в первом, во втором, за них подвешиваю и проверяю как корневые.
Так, хорошо. Дальше LCA, наименьший общий предок. Наименьший общий предок. Ну по английски это,
соответственно, List Common Ancestor. Здесь опять работаем с корневыми деревьями, то есть неформально какая-то
вершина назначена корнем и все пути они вот как бы сверху вниз у нас идут. Насчет такого LCA, для
двух каких-то вершин U и V, это такая вершина на пути между U и V, которая наиболее близка к R. То есть
я рассматриваю пути между ними, вот он, и на нем выбираю самую высокую вершину, самую близкую к R.
LCA U и V это, ну давайте я так и напишу, самая высокая вершина, вершина на пути
от U до V. Самая высокая, то есть с наименьшей глубиной, то есть наиболее близкая к корню R.
Значит альтернативно можно было бы определить так. Смотрите, что это за вершина? Как вообще
выглядит любой путь от U до V? Ну давайте сначала поймем, как выглядят вообще пути от U до корня,
например, от U до R. Понятно, что бы дойти от U до R, мне нужно просто каждый раз подниматься вверх по
ребру, то есть в родителей идти каждый раз. Путь от вершины до корня очень легко определить. Если
я запускаю DFS сверху вниз, то я у каждой вершины знаю предыдущие пути, соответственно мне нужно
просто пропрыгать по предыдущему. То же самое я знаю путь от V до корня, вот так, вот так, вот так.
Ну и теперь если я посмотрю, где эти пути впервые пересекаются, соответственно тогда я знаю, что надо
от U дойти до сюда, от V дойти до сюда, и вот как раз тогда у меня эти два пути состыкуются. И вот эта
вершина, где они состыкуются, будет как раз LCA. Можно альтернативно сказать, можно сказать, что это
такая вершина наиболее глубокая, что она является общим предком и для U, и для V. Давайте напишу альтернативно.
Вершина LCA от U и V это самая глубокая вершина, являющаяся предком U и V. Ну а предок это такая вершина,
которая, можно сказать так, что вот относительно нее U и V лежат в ее поддереве, то есть ниже от нее,
где-то ниже. Меня интересует самый глубокий общепредок. Например, вот это их общепредок,
потому что они обе лежат в поддереве этой вершины. Вот это их тоже общепредок, потому что все они
лежат в поддереве R, но при этом это не самая глубокая вершина. Самая глубокая это вот она.
Но, например, вот это это не общепредок, потому что V не лежит в этом поддереве. Ну и так далее.
И вот наша задача научиться находить LCA как-нибудь забыстро. Тогда, например, в частности, если мы
научимся искать LCA забыстро, то мы вообще можем быстро понимать, как выглядит путь от U до V.
Например, его длину можем определять. Если мы знаем их LCA, то путь между U и V выглядит так.
Сначала от U надо дойти до LCA, потом от LCA до V. То есть LCA такая очень полезная характеристика для
двух вершин. Мы так все пути можем характеризовать, что сначала от U поднимаемся до куда-то,
потом от этого куда-то спускаемся до V.
Так, ну давайте научимся это как-нибудь делать. Способ первый. Дваичные подъемы.
Сначала мне нужно будет вести процедуру, которая проверяет, является ли одна вершина предком другой.
Давайте я напишу, был консестор, int, давайте x, y. Эта процедура проверяет, правда ли, что x является предком y.
Верно ли, что x предок y? Предок, то есть повторю, y лежит в подделье x. Вот есть корень, за который мы подвесили все дерево, где-то есть x и где-то в его подделье y, тогда x это предок.
Ну как это можно сделать? Можно, например, ввести, как мы это делали, когда писали DFS, можно вернуть ti на tout, как времена входа и выхода вершины из вершины.
Вот скажем этот DFS фиксируется так. Вот здесь при входе я говорю, что ti на tv равно timer++, здесь при выходе говорю tout на tv равно timer++.
То есть каждый раз при входе и при выходе из вершины я говорю, что время увеличивается на 1 и соответственно я фиксирую времена входа и выхода из каждой вершины.
Тогда я утверждаю, что вот эта функция пишется так. Надо проверить, что ti над x меньше либо равен ti над y и tout от x больше либо равен tout от y.
Так, ну это вообще работает на самом деле для любого DFS, для DFS в любом неориентированном графе.
Если я записываю ti на tout, то мы когда-то на самом деле с вами понимали, что вот эти вот отрезки, отрезок времени между входом в вершину и выходом из вершины,
все вот такие отрезки, любая пара отрезков, либо не пересекается вообще, это значит, что мы сначала проходим одно дерево, а потом другое, ну под деревом, либо одно вложено в другое.
Значит, я сначала вошел в одно под дерево, потом спустился куда-то, целиком прошел под дерево другой вершины и потом вышел и только после этого закончил по дереву первую вершину.
То есть такие отрезки, они либо не пересекаются, либо вложены друг с другом.
Так работает DFS, так работает обход графа в глубину, что такие отрезки либо не пересекаются, либо вложены.
Ну вот здесь я пересекаюсь, что они вложены друг с другом, при этом отрезок y вложен в отрезок x.
Ну понятно, вот это вот ровно такая картинка, что я сначала вошел в x, потом что-то поделал, потом нашел y, его целиком обошел, вышел из него,
и только после этого вышел из x. То есть я сначала вошел в x, потом в y, потом вышел из y, потом вышел из x.
Вот ровно вот это вот условие я проверяю здесь.
Да, а как бы антоним к этому условию, это что либо они здесь поменены местами тогда y предок x, либо они не пересекаются, но тогда понятно, что ни один из них не предок другого.
Поэтому это условие ровно то, что нам нужно делать, за от изницы.
Так, хорошо, тогда сделаем следующее, собственно двоичный подъем.
Давайте для каждой вершины и для каждой степени двойки, 1, 2, 4, 8 и так далее, посчитаем ее предка в поколении с номером этой степени двойки.
Ну как-нибудь давайте я назову лифтс.
Катая ветая, это родитель, ну давайте предок v в двовкатом поколении.
То есть предок, например, в первом поколении это просто родитель, на 1 ребро вверх, во втором поколении это на 2, в четвертом поколении, соответственно, на 4 ребра вверх.
Это про дедушка, но не важно, короче.
То есть получается, где я окажусь, и иными словами, где я окажусь, если я из v вот столько вот раз поднимусь в родителя.
Значит, это либо предок, либо корень, если предка в таком поколении нет.
То есть я вот прыгаю-прыгаю и хочу еще выше прыгнуть, например, на 100-500 вверх подняться, а такого просто нет.
Тогда я просто корень храню.
Либо корень, если такого предка нет.
Вот это собственно двоичные подъемы.
Лифтс.
Извините, лифтс.
Вот.
Значит, как его заполнять сначала?
Заполнять очень просто.
Что такое лифтс нулевое?
Лифтс нулевое от v.
Это предок в 2 в 0, то есть в первом поколении, то есть просто родитель v.
Родитель v.
Но это очень просто заполнить, потому что для корня это он сам, потому что у корня нет родителя.
А у всех остальных, когда я спускаюсь из вершины v в вершину 2,
я могу сразу сказать, что лифтс нулевое тут это v.
Каждый раз, когда я в нашем DFS спускаюсь по ребру,
я сразу записываю, что родитель этой вершины это v.
Тем самым я нулевой слой нашей, по сути, динамики заполню.
Теперь пусть мне известны все лифтсы нулевые.
Пусть, даже не так, пусть известны все на item-слоя.
Пусть известны все лифтс kt для любой вершины v.
Тогда как найти лифтс k плюс первое v?
Смотрите, я хочу понять, где я окажусь, если я из вершины v прыгну вверх 2 в степени k плюс 1 раз.
Вот если я вверх поднимаюсь вот на столько ребер,
где я окажусь?
И при этом я умею подниматься на 2 в степени k ребер.
Ну как обычно, мы один раз прыгаем на 2 вкатый, второй раз прыгаем на 2 вкатый.
Так же, как в спортстейбле у нас было, отрезок большой длины я покрываю двумя отрезками длины вдвое меньше.
Поэтому, чтобы прыгнуть на 2 в степени k плюс 1,
я сначала прыгаю на 2 вкатый, потом из него еще раз на 2 вкатый.
Значит, если вы хотите убить себе глаза,
можно писать вот так.
Вот лифт с k плюс 1 vt это лифт с kt от лифт с kt vt.
То есть, я сначала поднимаюсь на 2 вкатый из v,
и потом еще поднимаюсь на 2 вкатый из нее.
При этом, вот это вот граничное условие, что если мы пытаемся прыгнуть выше, чем положено,
выше, чем за корень, то здесь тоже все будет нормально.
Потому что, скажем, если вот это вот внезапно стало корень,
то здесь любой прыжок к нему тоже будет корень.
Поэтому здесь не будет никаких проблем с этим условием.
Короче, с этим условием все будет нормально.
Да.
Ну, для корня в самом начале скажут, что лифт с ульевой от корня это корень.
Так, теперь, зачем это нам было нужно?
Давайте я нарисую картинку.
Смотрите, мы хотим найти...
Все, я теперь начитал все лифцы, да, начитал все двоичные подъемы.
Понятно дело с УЗН логН.
Потому что нет смысла брать k больше, чем логН.
Там логН, округленный куда-нибудь, вверх, например.
Но нет смысла брать степень двойки, превосходящую количество вершин в графе.
Поэтому это можно сделать с УЗН логН.
Так вот, как найти лица между У и В?
Давайте я буду прыгать из У в предке по вот этим двоичным подъемам.
От больших степеней к меньшим.
То есть, скажем, вот здесь я прыгну, скажем, на 8.
Вот здесь вот на 4.
И здесь еще на 1.
Я буду прыгать по вот этим степеням двойки вверх, вверх, вверх, пока могу.
И найду тем самым самую высокую вершину, которая еще не является предком В.
Вот такое странное условие.
Я сейчас вверх, сохраняю условие, что У это не порядок В.
Тогда если я так сделаю, то я на самом деле допрыгаю до вот этого левого сына, их LCA.
И чтобы найти сам LCA, нужно будет просто один раз перейти в родителя.
Сейчас будет код.
Так, LCA для У и В.
Ну, во-первых, простой случай.
Если У это порядок В, то У это ответ.
Если одна вершина предка другой, то она, собственно, есть их LCA.
Потому что путь выглядит как-то вот так.
Путь сверху вниз от У до В.
Понятно, что самая высокая вершина в этом пути, это она сама У.
Это простой случай.
Теперь более интересный случай, когда У это не порядок В.
И картинка какая-то такая.
Так вот, давайте я буду прыгать ушкой по вот этим вот нашим двоичным подъемам.
Сохраняя условие, что У это не порядок В.
Значит, дальше давайте мы сохранять условие, что У не предок В.
Значит, вот я хочу прыгнуть как можно выше из У.
Поддерживаю условие, что У это не предок В.
Делается тривиально.
Ка, ну давайте вот Ка Макс до нуля.
Если можно прыгнуть на двафкатой, сохраняя условие, что это не предок В, то прыгаем.
Так, если неверно, что предок
лифтс
катая утая
В
тогда У это вот этот самый лифтс катая утая.
Вот.
Все, в конце, после этого фора
у меня по-прежнему выполняется, что У это не предок В,
потому что я всегда эти условия сохраняю.
И я утверждаю, что У тогда это вот эта вот вершина,
самая высокая вершина на этой части пути,
которая все еще не предок В.
То есть по факту это просто вот этот ребеночек кольца.
И тогда в качестве этого нужно вернуть родителя нашей У.
Return
лифтс
нулевое утая.
Так, еще раз.
Понятно, что вот это условие у меня всегда сохраняется.
Вот до этого момента У это не предок В.
Изначально это не предок В,
потому что это условие не сработало.
И дальше я всегда поддерживаю,
что если я У пересчитываю, меняю на что-то,
то У это не предок В остается.
Но при этом я поднимаюсь вверх.
Так вот, я утверждаю,
что после этого фора
У это самая высокая вершина,
которая является предком изначального У,
которая все еще не предок В.
Почему это самая высокая?
Почему это действительно последний вершинный пути
до Ульца?
Давайте сделаем так.
Давайте померяем вот это вот расстояние.
Сколько у меня здесь было?
13, да?
Вот пусть расстояние у У до Ульца это 13.
Тогда что я делаю?
Я иду по степеням двойки сверху вниз.
И по факту я вот это число 13 разбиваю
в двоичную систему счисления.
Как как раз таки 8
плюс 4 плюс 1.
Прыгаю сначала на 8,
потом все еще ниже чем Ульца.
Потом еще на 4 все еще ниже чем Ульца.
Так, сейчас, плохо, плохо.
Извините, извините.
Одну секунду.
Плох сказал.
13 это вот это вот.
Не до Ульца расстояние,
а до вот этого сына Ульца как раз.
Вот до него.
Тогда как раз я раскладываю число
по степеням двойки.
Ну и каждую возможную степень двойки прыгаю.
Как раз 8, 4, 1 будет.
Я закончусь вот здесь.
То есть получается, каким бы ни было это расстояние,
я просто с жадным алгоритмом
от больших степеней к меньшим, я его обязательно пройду.
И закончусь вот в этой вот вершинке
в сыне Ульца,
которая все еще не под дерево,
не предок В.
Чтобы стать предок В, надо подняться
на один верх.
Вы видите расстояние от У до Ульца?
Нет, ну смотрите,
если отсюда до Ульца 12,
то мне нужно прыгнуть на 11.
Согласны?
11 это 8, плюс 2, плюс 1.
Ну вот так вот.
Вот так вот.
Вот так вот.
Вот так вот.
Вот так вот.
Вот так вот.
Вот так вот.
Вот так вот.
Потому что, смотрите,
когда я прыгаю на 8,
если я потом пытаюсь прыгнуть на 4,
я уже становлюсь предком В,
поэтому я на 4 не прыгаю.
Значит, 4 игнорируется.
А на 2 и на 1 я спокойно прыгаю,
и как раз окажусь в этом ребенке Ульца.
Еще раз?
Да, ровно это я и говорю.
То есть вот эта штука,
это просто разложение,
ну да, просмотр выставленных бит
в расстоянии от У
до вот этого сына Ильца.
Да, это правда.
Ну вот.
Все, значит, смотрите,
что у нас получилось с асимптотикой?
У меня получился предподсчет
за n лог n,
потому что двоичные подъемы.
И запрос еще за логарифы.
Потому что в цикле
по k от k-max до 0.
Ну, давай тогда быстренько,
второй способ.
Чуть более быстрый.
Ну, его быстрее объяснить.
Ну, вот так вот.
Вот так вот.
Ну, его быстрее объяснить.
Значит, это Эйлеров обход.
На примере.
Пусть есть вот такой граф,
такое дерево.
И опять дерево корневое,
вот оно пусть подвешено,
завершу номер два.
Тогда Эйлеров обход
это запуск DFS-а,
который каждый раз,
когда входит,
точнее, каждый раз, когда попадает в вершину,
записывает ее.
То есть, смотрите, мы начали в двойке,
давайте запишем двойку.
Потом идем в шесть, записали шесть.
Спустились в один, записали один.
Вышли из один, поднялись по этому ребру.
И опять оказались в шестерке.
Написали шесть.
Потом спуск в семь,
подъем обратно в шесть.
Потом все это по дереву уже обойдено,
поднимаемся вверх в двойку,
потом подъем опять в тройку,
в двойку, в четверку и в двойку.
То есть, по факту,
это просто запись,
как DFS посещает все вершины.
То есть, он либо спускается вниз,
и тогда вершину печатает,
либо разворачивает рекурсию,
поднимается из вершины вверх к родителю
и тоже печатает эту вершину.
То есть, если я поднимаюсь снизу вверх,
я тоже вершину записываю.
Вот это Эйлеров обход.
Он хорош тем, что здесь любые две вершины
это ребро графа.
Любые две соседние вершины
это ребро графа.
Потому что я либо сверху вниз прошел,
либо снизу вверх.
Потому что каждый раз, когда я прошел по ребру,
я печатаю очередную вершину.
Вот у меня 2,6, 6,1, 1,6
это ребро снизу вверх,
6,7, 7,6 снизу вверх и так далее.
Каждые соседи вершины
это соседи в графе,
соединенные ребром вершины.
Тогда утверждается следующее.
Чтобы найти
LCA УВ,
нужно найти вершину
с минимальной глубиной
на отрезке между УВ.
Вершину с минимальной глубиной,
с минимальным depth,
на отрезке
между УВ.
Например, вот здесь
у меня есть 1,7,
их LCA это 6.
Потому что на отрезке
между 1,7
их наименее глубокая вершина,
минимальная глубокая вершина между ними
это 6.
LCA, например, в семерке и пятерке,
мне нужно вот на этом отрезке
найти вершину с минимальной глубиной,
это будет 2.
Сейчас.
Очень простая идея.
Почему работает? Ну понятно почему.
Потому что путь между вот этими вхождениями,
это вхождение вверх-вниз, вверх-вниз,
ну и значит понятно дело,
что мы в частности путь между ними целиком пройдем.
Мне нужно от семерки попасть в пять,
значит между ними я весь путь напечатаю.
И ясное дело, что я выше этого пути никуда не поднимусь.
Потому что если я иду из УВ
и как-то вот так вот
выше, чем до LCA зашел,
что значит?
Что значит, что я посещаю вершину выше, чем LCA?
Ну это бред, потому что если я прохожу
вот это ребро снизу вверх, то я потом уже не вернусь.
Снизу вверх я иду только,
если у меня все внизу обойдено.
Поэтому таких ребров точно не будет
на этом пути.
Ну а LCA точно будет.
Любое.
Неважно.
Потому что все равно, если я когда-то находился в У,
то чтобы попасть когда-то в В,
мне нужно весь путь между ними пройти.
Неважно какое вхождение.
А что мы будем с собой брать?
Мы sparse table на этом сделаем?
Вот.
Значит, смотрите, мы получили ref-обход.
На нем, с помощью sparse table,
мы можем найти
минимумы на отрезках за единицу
с предпочетом за n log n.
Еще раз?
Почему?
Она и так за n решалась.
Можно было просто DFS запустить
на те расстояния, там путь.
Значит, предпочет
n log n
запрос за единицу.
Вот.
Это уже лучше, чем то,
но надо написать sparse table.
Написать sparse table.
Вопрос, вопрос.
Единственное, смотрите,
давайте вот здесь замечу,
что длина вот этого массива,
она будет примерно вдвое
больше, чем число вершин.
Потому что каждая
бропа факту рассмотрится
дважды, сверху вниз и снизу вверх.
Значит, каждая вершина напечатается
примерно столько раз, как у нее степень.
А суммарная будет в два раза больше,
чем число вершин.
Поэтому здесь на самом деле sparse table
больше.
Но это, конечно, не важно.
Все, до следующего раза.
