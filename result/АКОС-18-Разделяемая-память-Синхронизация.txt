Так, значит, мы фиксируем, что мы остаемся в этой аудитории,
никуда не переезжаем.
Техническое решение, которое будет составить разработчик
из проекта, найдено.
Так, и тема сегодняшней лекции.
У нас она не одна.
ЦУП.
Во-первых, это один из механизмов межпроцессного взаимодействия
под названием разделаемая память.
Во-вторых, разные средства, которые есть,
используют API для механизмов синхронизации.
Итак, по поводу различных механизмов межпроцессного взаимодействия.
Вы уже изучили, что такое каналы, вы изучили сокеты.
Что плохого в этих средствах коммуникации?
С одной стороны, достаточно удобный и универсальный способ.
Особенно сокеты, которые масштабируют год-весетий.
Но есть определенные недостатки.
А именно, что вам нужно много раз вызывать системные вызовы.
Рит и Врайд.
Ну, либо в случае сокетов, Рик и Сэнд.
Для того, чтобы передавать данные.
Если вы работаете по сети, это вполне смысл.
Другое дело, если у вас есть один и тот же компьютер,
и вам нужно организовать взаимодействие разных процессов
на одной и той же системе.
То такой подход становится слишком дорогостоящим.
Потому что каждый системный вызов – это переключение из контекста
после контекста игра, и затем наоборот.
Плюс, вам нужно держать какой-то буфер,
и чем занимается игра, значительную часть времени.
Тем, что перекладывать данные из одного буфера,
который находится в пространстве пользователя,
какой-нибудь другой буфер, который находится в пространстве ядра.
Ну и в обратную сторону тоже самое.
В общем, достаточно затратные операции,
просто для того, чтобы передать данные от одного процесса к другому.
Что можно в этой ситуации поделать?
Для того, чтобы много раз не вызывать
системные вызовы Рит и Врайд.
Одно из решений – это использовать системный вызов под названием SendFile.
На самом деле используется в проде где-нибудь в серверах.
В чем смысл этого системного вызова?
Он принимает два уже открытых файловых дискриптора
и делегирует на ядро задачу по перекладыванию данных
из одного открытого файлового объекта в какой-то другой.
И тем самым у нас не вовлекается сама программа.
То есть вы вызвали SendFile, и дальше ядро уже,
используя свои внутренние буферы,
просто перекачивает данные из одного места в другое,
и не происходит никакого постоянного копирования
из одного буфера в другой.
В чем недостаток такого подхода?
Недостаток в том, что здесь все-таки нужно передавать данные
из одного файла дискриптора в другой.
То есть это должны быть какие-то файлы подобные объекты.
И самое плохое здесь – это то, что есть разные реализации
одного и того же системного вызова в разных операционных системах,
которые существуют совершенно независимо друг от друга.
И кроме того, что у них различаются сигнатуры,
разные заголочные файлы, разные типы параметров
и возвращаемые значения для систем BSD и Linux,
но это еще полбеды.
Другая ключевая проблема в том, что вам может понадобиться
не только передавать данные из одного файла дискриптора в другое.
Например, sendfile хорошо использовать,
когда вы реализуете какой-нибудь файловый сервер
и вам нужно выдавать уже существующие файлы без модификации.
Если вам нужно как-то данные модифицировать
либо передавать, генерировать данные на лету,
то такой подход вам уже не подойдет.
И что можно еще сделать и вообще,
где у нас возникают задачи,
когда вам нужно обмениваться большими объемами данных
между разными процессами таким образом,
что у вас возникает большая нагрузка, например,
на процессор только из-за счета передачи данных.
И один из примеров, если вы используете Unix Desktop,
то любой видео-плеер, неважно на движке M-Player, GZine,
ну, чаще всего на M-Player,
как вообще у нас устроена жизнь в какой-нибудь Unix машине.
Вот вы запускаете Gnome, Unity,
Unity уже не популярна, это убунтовская,
Gnome, KDE, XFCE, что у вас там еще стоит?
Кто пользуется Linux на desktop?
Именно как виртуал?
У вас есть полноценные системы с графическим интерфейсом.
Но Gnome либо KDE, либо MATE, либо XFCE.
Скорее всего, у вас там стоит программа,
которая называется X-Server.
А что такое X-Server?
X-Server — это процесс, который имеет доступ к вашей видеокарте,
имеет доступ к клавиатуре мыши, тачпеду,
и как осуществляется взаимодействие с X-Server.
Вы запускаете какой-нибудь процесс, который хочет вывести графику.
Он через socket просто стучится к X-Server
и просит что-то отрисовать.
Но заодно обрабатывает сообщение от X-Server в обратную сторону.
Это разные события, которые у нас возникают.
Клавиатура, мышь и так далее.
Так вот, если мы работаем, просто рисуя какие-то окошки,
это вполне небольшая нагрузка.
А что произойдет, если мы начнем передавать какой-нибудь большой поток данных?
Например, видеопоток из Videoplayer.
Будет большая нагрузка и непонятно зачем.
Потому что вам нужно передавать данные из одного места в другой.
Просто, почему бы не скормить X-Orgo ссылку на уже декодированные видео,
чтобы он сам это сделал?
И вот здесь как раз используется оптимизация,
механизм по названиям разделяемая память.
Немного забегая вперед, M-Player это консольный Videoplayer,
который можно запустить из командной строки.
Там есть разные способы вывода, настраивать все из командной строки.
То есть совершенно даже не обязательно иметь X-Server.
Может работать даже с настроенным frame-буфером, хотя это медленно.
Либо он может выводить данные не используя разделяемая память,
и при этом у вас будет большая нагрузка на процессор,
и какие-нибудь тяжелые видосики будут просто тормозить.
Как у нас осуществляется взаимодействие между разными процессами,
и сколько насут процессов для запуска обычного мультика?
Это, если что, open-source BigBug Bunny с высоким качеством
может скачать бесплатно без регистрации SMS.
Так вот, можно управлять любой консольной программой,
используя механизм пайпов.
То есть есть стандартный поток вывода для того,
чтобы имитировать нажатие клавиатуры и читать то, что программа выводит.
Для взаимодействия с видео между самим M-Player
и уже непосредственно X-Server, который рисует вам картинку на экране,
используется механизм разделяемой памяти и как устроен этот механизм.
Механизмы разделяемой памяти базируются на том знании,
что у нас все современные процессоры имеют Memory Management Unit,
но современные имеют в виду десктопные, планшетные, телефонные, серверные и так далее.
На самом деле бывают современные процессоры без поддержки Memory Management Unit,
и как правило это микроконтроллеры, поскольку модуль достаточно тяжелый.
Помните, в конце прошлого семестра, когда вы изучали МАП,
такую штуку как трансляция из виртуального адресного пространства в физическое адресное пространство.
Для 34-убитной архитектуры у нас есть двухуровневая схема трансляции,
для 64-убитной архитектуры это уже четырехуровневая.
И тот реальный адрес, тот виртуальный адрес, который используется в вашей программе,
затем транслируется процессором совершенно прозрачно в настоящий физический адрес.
Он может ссылаться либо на участок физической памяти, либо на какой-то файл.
И все адресное пространство делится у нас на странице фиксированного раздела.
Соответственно, что у нас является записью, характеризующей одну страницу памяти?
20 бит. Это старшая часть физического адреса.
Три бита не используются, и там есть еще девять разных флагов,
которые используются для того, чтобы обозначить, является ли страница доступна для записи,
реально ли она находится в физической памяти, или нужно подгрузить из файла, и так далее.
И вот механизмы операционных систем, которые позволяют использовать аппаратные возможности процессора,
как раз используются для реализации разделяемой памяти.
Причем, опять же исторически, поддержка разделяемой памяти была реализована по-разному в разных UNIX-системах.
Проблема о том, что у нас есть разные UNIX-системы, она возникла не вчера,
не когда MacOS стал популярным, и не когда Linux стал популярным, и развивались они независимо.
Раньше существовала система UNIX-System5 и BSD-UNIX.
В UNIX-System5 в 88 году появился целый набор разных технологий, которые поддерживаются, в том числе Linux.
Он поддерживается FreeBSD и Mac, но во FreeBSD UNIX-System5 механизмы обычно по умолчанию отключены,
и нужно пересобрать ядро, чтобы включить.
Что это за механизмы? Это API для разделяемой памяти, симфоров и очереди сообщений.
И с другой стороны, отдельная реализация в BSD-UNIX, которая называется MMAP,
которая вы уже немножко умеете пользоваться, но немножко про System5.
System5 разделяемая память подразумевает, что у вас есть какое-то специальное пространство имен разделяемых сегментов памяти.
В Linux есть инструменты, которые отображают, какие у вас сегменты есть.
С ними можно даже что-то сделать, имея про ворота.
Что здесь нехорошего в этом механизме? Он слишком переусложнен.
И есть одна опасность, что если вы создали какую-то область разделяемой памяти, забыли потом удалить,
то она останется висеть и просто потребляет ресурсы.
Механизм сложный и ненадежный, поэтому используется только legacy софтом.
Поэтому тянется поддержка совместимости в современных системах.
В случае с BSD все намного проще, потому что есть всего лишь один системный вызов,
который позволяет вам выделить какую-то память в виртуальном адресном пространстве.
Затем вы эту память можете либо наследовать в начальных процессах, либо строить какому-то файлу.
Используйте какой-то файл совместный между процессами.
С одной стороны, это достаточно простое решение.
Напомню, что память у нас бывает с атрибутами либо разделяемая, то есть она доступна разным процессам.
То есть когда у вас одни и те же страницы отображаются на виртуальном адресном пространстве разных процессов.
Либо приватная, когда страницы могут отображаться на разные процессы,
но при первой же попытке в любом из процессов сделать хоть какую-то запись,
просто создается ее копия. Результат с парадигмой copy-on-write.
Здесь еще можно указать какой-то файл.
Если FD у нас отличный от минусе единицы, что это означает?
Это означает, что у вас будет отображение не на область физической памяти, а на некоторые файловые системы.
В чем ключевая проблема, если вы используете анонимное отображение, то есть без привязки к файлу?
У вас взаимодействовать могут только родственные процессы.
Если у вас процессы не родственные, то просто взять и подключиться, залезть в память другого процесса, вы никак не сможете.
Для того, чтобы можно было это сделать, нужно как-то уметь анонсировать имя, которому другие процессы смогут дальше подключаться.
Этот подход используется в механизме POSIX shared memory. Каким образом это делается?
Вы просто создаете обычный файл, не важно, где он лежит.
Главное, чтобы у него были права на доступ. Необходимо вам либо чтение, либо запись.
У другого процесса, который хочет с вами общаться.
Дальше вы делаете файл не нулевого размера.
Это можно сделать, например, с помощью системы вызова truncate, либо ftruncate.
После этого скармливаете файлик уже нашему системе вызову mmap, который приотачивает его содержимое виртуальное адресное пространство нашего процесса.
Этот файл теперь можно использовать для межпроцессного взаимодействия очень быстро.
Использование разделяемой памяти – это самый быстрый способ межпроцессного взаимодействия, который ядро вообще никак при этом не вовлекает.
Какие здесь возникают проблемы?
Тут в какой-то момент вам файл станет не нужен, хотя бы по той причине, что взаимодействие закончилось, процессы у вас могут завершиться.
И кто этот файл должен удалить?
Очевидно, какой-то последний процесс, который его использовал, должен файл удалить.
Тут, кстати, h5, не close, а...
У вас остается файл, который болтается, он доступен, просто какой-то фантом.
Но если у вас процесс, который должен удалять, вдруг сломался, что произойдет?
Будет просто болтаться лишний файл, занимать место на диске, что не очень хорошо.
Как с этим можно бороться?
Совсем это пооборот никак невозможно.
Но если вы периодически компьютер хотя бы перезагружаете, либо вы запускаете какие-то контейнеры,
что такое слово, докер, вы должны знать,
соответственно, контейнеры могут монтировать свою файловую систему,
и есть разные типы файловых систем.
Одна из них предназначена как раз для временных файлов.
Собирается на tmpfs, с этой файловой системой не связаны никакие дисковые устройства,
все ее содержимое хранится в физической памяти.
Соответственно, все, что находилось в этой файловой системе в момент ее отмонтирования,
отмонтирование у нас может происходить либо при перезагрузке и выключении компьютера,
либо если вы завершаете работу какой-нибудь докер контейнеров,
который имеет свою обособленную файловую систему,
то, естественно, он тоже отмонтирует свою внутреннюю файловую систему tmpfs.
И все данные у вас пропадают.
Исходно эта файловая система имеет некоторый размер, указываемый при ремонтировании,
но может быть легко на лету изменен.
И реально в памяти он занимает ровно столько места, сколько занимают файлы,
которые в этой файловой системе лежат.
Если у вас файлов нет, почти ничего.
Если много, значит, или файлы большие, значит, занимает места много.
Если у вас очень много файлов, либо они тяжелые в файловой системе tmpfs,
то происходит то же самое, что при ситуации нехватки памяти они просто сбрасываются в swap-раздел.
Какие вообще в типичной линукс-системе могут быть разделы tmpfs?
С помощью команды mount можно вывести список всех примонтированных файловых систем.
Отдельная строка – это отдельная файловая система.
На современной системе systemd тут таких записей будет очень много под линукс,
потому что очень много в линукс делается через виртуальный файловый систем.
Чтобы из этого мусора извлечь что-то похожее на tmpfs, мы можем воспользоваться
утилитой grep, что у нас является в произвольной запущенной файловой системе, временными файловой системе.
Возможно, если вы ставили на настоящий компьютер, а не виртуальную машину, это будет slash tmp.
Файлы системы slash run, куда все запущенные сервисы запихивают информацию, например,
о том, какой у них есть процесс ID в виде обычных файлов.
Run log – это катал, в который обычно все запущенные фоновые сервисы засовывают лог-файлы.
Run user, дальше user ID. Создается уже при графическом входе в систему, если у вас там где-нибудь болтается xorg,
менеджер сеансов, создается уже через systemd.
Есть еще одна файловая система, которая подмонтирована к slash dev slash shm.
Сокращение shm означает shared memory. Это в линуксе некоторая файловая система,
которая используется для хранения сегментов разделяемой памяти.
Как работать с этими сегментами разделяемой памяти?
В некоторых системах есть системный вызов, в некоторых системах – библиотечная функция.
Называется штука shm open, которая имеет все те же самые параметры, что и обычный системный вызов open,
то есть имя файла, флаги открытия, чтение, запись, чтение плюс, запись append и так далее, плюс флаг creat.
И соответственно, если указан флаг creat, то нужно указывать обязательный режим создания файла.
Прямо точная копия системного вызова open. В чем разница?
shm open открывает файловый дескриптор, который находится где-то внутри файловой системы dev shm.
Причем в линукс что такое shm open? Это самая обычная простая дурацкая функция, которая что делает?
Она составляет полное имя файла, приписывает просто к названию slash dev slash,
и shm вызывает обычный системный вызов open. Все, больше эта функция ничего не делает.
А вот в системах FreeBSD, Mac OS и других BSD-системах реализация разделяемых сегментов памяти сделана в стиле System5,
то есть это ортогональная совершенно файловая система пространства имен.
То есть у каждого разделяемого сегмента есть свое имя, которое никак не связано с файловой системой.
И тут возникают некоторые ограничения, которые нужно соблюдать в том случае,
если вы хотите сделать так, чтобы ваш код был портируем на любую систему.
Итак, теперь конкретный пример. Вот простенькая программа, которая что делает?
Она просто создает разделяемый сегмент памяти, но никак его не использует.
Одна и та же программа, запущенная просто с shm open, дальше можно убедиться, что что-то создано,
нажать кнопочку ввод и затем удалить используемый сегмент.
Итак, первое, что нужно сделать, это скомпилировать нашу программу.
Для компиляции под Linux нам требуется еще дополнительно указать библиотеку LRT.
На самом деле это часть стандартной сибиблиотеки, но просто в Linux есть фрагментация.
Точно так же, как с POSIX threads. Все, скомпилировался.
Если мы хотим скомпилировать тот же самый код один в один под FreeBSD или под Mac,
то ни с чем больше линковать не нужно.
Теперь запустим какой-нибудь разделяемый фрагмент и укажем имя файла в виде A, B, C, D, E, F.
Все, создан файл, который мы можем наблюдать.
Файлы системе немножко на проекторе не видно.
Ls slash dev slash shm.
И вот этот файл есть. Это просто самый обычный файл.
Никакой магии тут нет.
Какие у нас здесь возникают естественные ограничения?
Если мы захотим сделать какое-нибудь имя вида A, B, C, D, E, F, что у нас произойдет?
Зависит от того, существует ли у нас каталог A, B, C в этом D, F, C, D или не существует.
Если вы ручками создадите подкаталог, ну пожалуйста, все хорошо, все замечательно.
Если нет, получаем ошибку.
Если чем Open вам возвращает минус один, почему нельзя создать файл с таким именем?
Потому что здесь подразумевается полный путь, содержащий подкаталог.
Если вы вручную его создадите, ну пожалуйста, если нет, значит не судьба.
И под FreeBSD Mac OS.
Итак, shm, A, B, C, D, E, F.
Создали, разделяемся в имя памяти, но вы его нигде не найдете в файловой системе.
Давайте мы перейдем куда-нибудь в корень.
Посмотрим, что у нас есть файловые системы, slashdef.
Тут даже никакого подкаталога shm нет.
Кстати, раз уж я заговорил про монтирование и про разные файловые системы,
давайте посмотрим, может где-нибудь procfs, tmpfs у нас болтается.
Количество файловых систем в BSD обычно меньше, чем в Linux.
И нет здесь никакого slashdef, slashshm.
И вообще механизм разделяемой памяти у нас, это просто артагонально что-то файловой системе.
Как можно получить доступ к этому файлу?
Сделать еще один процесс, который откроет тот же самый файл и сможет с ним работать,
зная какое-то определенное имя.
Зато здесь нет ограничений, связанных с каталогами.
Я могу как угодно обозвать наш файл, в пределах разумной длины, естественно.
И все хорошо, все замечательно.
Будет создан разделяемый сегмент с каким-нибудь диким именем.
Даже если оно не является валидным именем файла, ничего плохого с этим не произойдет.
Еще одно ограничение, которое есть в системе FreeBSD, надо вначале slash писать.
Под Mac это работает и так, а по FreeBSD уже не будет.
У нас есть разные ограничения на то, какие есть имена.
Но если вы просто аккуратно пишите код и соблюдаете эти ограничения,
то у вас будет все работать одинаково на разных платформах.
Как можно наблюдать за тем, какие у вас есть открытый разделяемый сегмент?
Под Linux можно просто посмотреть содержимое, где в S&Chem.
Под FreeBSD есть отдельная команда POSIX S&Chem Control.
Под MacS такого нет.
Можно, конечно, попробовать перекомпилировать FreeBSD open-source toolzoo,
но работать она будет не совсем полноценно.
И если вы попытаетесь нагуглить что-то,
как все-таки посмотреть под FreeBSD или MacOS список открытых разделяемых страниц,
почему-то на стык overflow вылазит использование утилиты IPC-S.
Это к тому, что не нужно верить всему, что пишут в Гугле и на стык overflow,
потому что IPC-Toolz предназначены для System5 разделяемых сегментов.
POSIX это совершенно не то.
Вторая тема на сегодня.
Здесь все достаточно просто.
Что такое MAP? Вы уже использовали это, все знаете.
Поэтому проблем у вас при решении задач семинарских возникнуть не должно.
А вот проблема гонки данных. Что это такое?
Это то, ради чего у вас целый семестровый курс теории, практики и многопроточной синхронизации.
На окусе мы рассмотрим только то, что относится к межпроцессовому взаимодействию.
Коротко напомню о том, что такое проблема гонки данных и когда она возникает.
Есть у вас однопроцессорная система, на которой запущена куча программ.
Все-таки операционная система у нас уже много лет как многозадачная.
Эти программы могут в свою очередь запускать несколько трэдов.
И если у вас процессор одноядерный, не знаю, где вы сейчас найдете, но допустим,
то все хорошо, все замечательно. Они будут просто работать не одновременно,
а последовательно переключаясь между собой по планировщику заданий.
Никаких проблем возникать не будет до тех пор, пока у вас не появится хотя бы двухпроцессорная система или двухядерная.
Если у вас система стала уже двухядерной, то возникает настоящая многозадачность,
когда у вас одновременно работает больше одной задачи.
И если у вас возникает больше одной задачи, то они начинают конкурировать за одни и те же ресурсы,
в частности за оперативную память, в том числе в пределах одного процесса,
в пределах одного виртуального адресного пространства.
И каким эффектом это может производить?
Один, допустим, поток либо процесс что-то пишет в общую память,
в это время другой процесс либо поток пишет туда же и получаем какие-то невалидные данные,
потому что один процесс мог записать часть, а другую-другую часть,
и вы можете получить ситуацию, что даже у вас не от первого процесса, не от второго процесса данные, а что-то перемешанное.
И вот эта проблема называется проблема гонки данных, как с ней бороться.
У вас могут несколько процессов разделять один и тот же сегмент памяти,
и что можно сделать для того, чтобы процессом между собой общаться и как-то говорить, что товарищ,
вот я сейчас записываю данные, пожалуйста, не трогай.
Можно использовать какие-то дополнительные механизмы межпроцессного взаимодействия,
например, пайпы, сокеты, но это получается переусложнение нашего взаимодействия,
когда у нас и так уже есть разделяемые страницы памяти.
Можно использовать сигналы, но сигналы это очень плохой ненадежный способ. Почему?
Даже для передачи простой информации, например, о том, что нам нужно предотвратить, заблокировать какой-то участок памяти.
Даже дело не в том, что их ограниченное количество, потому что у нас не гарантируется доставка сигналов всех, которые вы отправите.
Напомню, что обычный UNIX сигналы у нас проставляют бит в маске сигналов, ожидающих доставку,
и если вы отправили несколько сигналов, которые процесс не успел обработать, то обработан будет только один сигнал.
И для задач синхронизации это совершенно неприемлемо.
Есть, конечно, сигналы реального времени, но, опять же, они поддерживаются не всем операционными системами.
В Linux хорошо, а в macOS уже грустно. Можно, конечно, и каналы использовать, но тоже так себе решение.
И универсальным решением для межпроцессной синхронизации, и не только межпроцессной синхронизации, но также межпоточной, является симафор.
Что такое симафор? Это просто обычный счетчик, целочисленный, без знаков.
Операции это увеличить значение счетчика либо уменьшить.
Причем если у вас число априори должно быть без знаковым, целочисленным, что значит уменьшить счетчик?
Это значит, что вы можете либо его уменьшить, если оно строго больше нуля, либо вы ничего не можете с ним делать, потому что число не бывает отрицательным.
И вот в ситуации, когда нельзя ничего с этим числом сделать, у вас текущий поток просто приостанавливается до тех пор, пока это не станет возможным.
То есть пока кто-нибудь другой не увеличит этот счетчик.
И в чем особенность симафоров? Казалось бы, просто обычное целое число.
Почему бы не взять, не использовать обычное целочисленное значение, просто реализовать функции, которые одна делает инкремент, другая делает попытку декремента с возможным ожиданием.
Главная особенность симафора в том, что все операции как инкремента, так и декременты являются атомарными.
Атомарными это значит, что в процессе выполнения какой-нибудь инкремента, например, у вас никто посередине в клинице не сможет, и не сможет это значение из другого потока другим ядром как-то изменить.
Вот что означает вообще атомарность? Атомарность бывает в разных уровнях.
Например, с точки зрения сигналов, атомарность гарантируется тем, что вы выполняете какие-то инструкции, в это время прилетает сигнал, вы прерваны, и вы можете сделать запись либо чтение атомарно, только что-то, что заведомо умещается в размер машинного слова.
Потому что здесь прервание может возникнуть только аппаратный, значит, процессор не выполнил одну из инструкций.
И обычно с точки зрения обработки сигналов либо переключения контекста процессов у вас достаточно условия, что данные у вас не больше, чем размер машинного слова, и обязательно является целочисленным, то есть использует регистр общего назначения.
Вот тип данных сигнала к томикте. На самом деле для большинства современных систем это обычный type-dev на int, даже несмотря на то, что называется атомарным.
Но такой тип данных не подходит, он не является атомарным с точки зрения многопоточности.
Если у вас есть два конкурирующих потока, которые выполняются на разных ядрах процессора, то один из процессоров может быть приостановлен планировщиком заданий, либо выполнять какую-то задачу, и в это время другое ядро имеет полное право вытворять все, что угодно.
То есть использование такого типа данных вам еще ничего не гарантирует.
И как можно все-таки добиться того, чтобы у вас не было никакой проблемы в гонке данных?
Самые распространенные решения это использовать какие-то защитные механизмы для того, чтобы защищать разделяемые участки данных.
А в том числе достаточно крупные, которые заведомо больше, чем размер машинного слова.
Некоторые из них называются мютексы. Это простой объект, который может быть либо в разблокированном состоянии, либо семафоры, которые являются счетчиками.
Итак, семафоры. Это с точки зрения API просто специальный тип данных, над которым предусмотрены операции.
Post – это инкремент семафора. Очень простая операция, она просто увеличивает счетчик и все, достаточно быстро работает.
Всемвейт – это попытка уменьшить значение семафора.
Если его значение у нас строго больше, чем ноль, то семвейт моментально завершается, при этом значение счетчика у вас уменьшается.
Если два параллельно работающих потока пытаются одновременно вызвать семвейт, кому-то из них повезет, кому-то не повезет.
А может быть и так, что повезет обоим, потому что, в отличие от мютексов, семафоры могут иметь значение не только 0,1, а произвольное без знаков.
Если вы изначально семафоры инициализировали значением 10, а потоков у вас всего 2, то они никогда друг другу мешать не будут.
Кстати, семафоры могут использоваться в том числе для того, чтобы организовать взаимодействие барьеров между разными потоками или разными процессами.
Какие бывают у нас семафоры?
Семафоры бывают неименоваными. Что есть общего у именовых и неименовых?
У них есть некоторое начальное значение, которое не обязательно бывает 0, или 1.
Семафоры неименованы, это те, которые могут быть использованы только родственными процессами, либо могут быть использованы в пределах одного процесса, но разными тредами.
Именованные семафоры это по сути те же самые сегменты разделяемой памяти.
В линуксе реализация семопон это просто открыть разделяемый сегмент памяти, с помощью семопон дальше создать ммапом одну страничку, в которой помещается семафор, и в общем-то все.
Ничем больше не отличается.
Есть еще такая штука, как мютекс, у которого есть две операции заблокировать, разблокировать.
В чем отличие мютекса от семафоров? В общем случае мютекс имеет только два состояния, хотя на самом деле это не совсем так.
Вам рассказывали, что такое рекурсивные мютексы.
На самом деле мютексы бывают не только с двумя состояниями, есть такое понятие, как рекурсивный мютекс, когда один и тот же тред может несколько раз захватывать мютекс, и у него это будет получаться.
Зачем это бывает нужно? Например, если у вас используется какая-то переменная, которую нужно защищать от других потоков, и эта переменная может быть использована в разных местах кода,
и понаставлены везде какие-нибудь проверки, мютекс локи. Если мютекс является рекурсивным, то соответственно вы можете его из одного треда захватить несколько раз.
Для того, чтобы его освободить, вы должны его несколько раз освободить. При этом другой тред захватить рекурсивный мютекс не может, если он захвачен уже одним из тредов.
У мютексов есть одно существенное ограничение. Кто захватил мютекс, тот и обязан его освободить.
Если вы захватили мютекс в одном треде и пытаетесь освободить из другого треда, то ничего у вас не выйдет. Это будет undefined behavior.
В некоторых случаях программа у вас грохнется. Иногда она не грохается, но можно сделать так, чтобы она принудительно грохалась.
Второе существенное ограничение, почему в курсе о космо мютексы не очень любим, хотя на практике они очень часто используются.
Мютексы работают в одном адресном пространстве. Если у вас есть разные треды в одном процессе, мютекс полезная классная штука.
Если вы хотите устроить синхронизацию между собой разных процессов, то мютексы уже не подойдут. Единственный способ здесь что-то использовать, это только симафор.
Мютексы очень опасная штука. Если вы мютекс захватите и забудете его разблокировать случайно, что у вас произойдет?
Да, с большой вероятностью у вас произойдет дедлог, который не всегда воспроизводится случайно. Это трудно воспроизводимые баги, которые трудно отлавливать на практике.
Для этого даже существуют специальные отдельные инструменты, чтобы ловить. Всякий Intel Thread Profiler достаточно другой инструмент, не опенсорсный.
На C++ есть еще класс по названию LockGuard, который реализован следующим образом. Конструктор захватывает мютекс, деструктор освобождает.
Если вы где-то не прописали явное разблокирование мютекса и при этом выходите из какой-то области видимости, где этот мютекс уже не используется, то LockGuard у вас автоматически в деструкторе его освободит.
Решает много проблем. Казалось бы, мютекс — это бинарный симафор. Реализовать мютекс можно, сделав обычный симафор с значением 1, но операция Lock — это захват симафора, освобождение, релиз симафора, то есть увеличение счетчика на 1.
Но на самом деле мютекс из соображений производительности реализованы через другую конструкцию, которая называется FUTEX.
FUTEX работает намного быстрее, чем обычный симафор. В Linux есть стена вызов, которая называется FUTEX, которая как раз используется для манипуляции над FUTEX.
У FUTEX есть две основные операции. На самом деле операция чуть больше. Эта операция — ждать, пока кто-нибудь его не разбудит, и операция — разбудить.
Что такое FUTEX с точки зрения программного API? Это некоторый системный вызов, для которого даже есть MAN-страница с сишным интерфейсом, как ни странно.
То есть вы можете брать MAN, FUTEX, и получите вот такие заголочные файлы, сигнатуру. Но есть одна маленькая приписка в мане.
No Gleepsive wrapper for system call. Что это означает? Это означает, что если вы пытаетесь скомпилировать какой-нибудь код с использованием этой функции, с каких-то заголочных файлов, у вас ничего не выйдет.
Потому что это фейк. Никого в FUTEX не существует. FUTEX — системный вызов, но предназначенный для внутреннего использования библиотекой POSIX Threads.
Вручную его использовать, конечно, можно, если вы просто скопипастите из MAN-а вот это объявление, сделайте свою функцию, которая через функцию syscall будет явным образом делать syscall.
А вот в некоторых системах типа FreeBSD, macOS такого системного вызова нет, поскольку там вся реализация взаимодействия между потоками и использованием симафоров, она реализована уже в самом ядре, а не в отдельной библиотеке.
То есть в Linux у нас есть один примитив, который реализован в ядре, а дальше все остальные примитивы, это уже надстройки, использующие FUTEX, во FreeBSD, macOS — все у нас находится в ядре.
Так, и еще один примитив синхронизации, очень полезный на практике, называется условные перемены. Тоже реализуется через FUTEX.
То есть для чего нам нужен FUTEX? FUTEX у нас является базовым кирпичиком для постранения мютексов, условных переменных, симафоров.
В свою очередь уже в прикладных применениях, когда вы пишете какой-то реальный софт с нормальной логикой, вы не должны задумываться о том, что вам нужно сделать какой-то спинлок, реализовать.
Просто уже берите и пользуйтесь готовым решением. Вот еще одно готовое решение.
FUTEX предназначен для того, чтобы защищать какие-то критические секции, чтобы они были одновременно доступны разным тредам.
Еще один инструмент — это условная переменная, которая является некоторым барьером. На самом деле, название не очень удачное условная переменная.
Это не в том смысле, что переменная, в которой можно записать значение. Нет, это просто некоторый флаг, который может быть либо установлен, либо снят.
Разные треды у вас могут ждать, пока возникнет какое-то событие, а другие треды могут сигналить на это событие.
Для чего могут использоваться условные переменные? Например, у вас есть какой-то тред, который ожидает данных, тред-потребитель данных.
Он ждет, пока какой-то другой тред закончит подготовку данных и скажет о том, что данные готовы, можно их использовать.
Вот как это можно организовать? Можно с одной стороны сделать какой-нибудь бульфлаг готовности, который будет доступен обоим тредам.
Один тред будет записывать, что флаг готовности, другой его читать. Оба этих флага можно защитить мьютексами, периодически их проверять с определенным интервалом.
Но это, во-первых, переусложнение логики, во-вторых, возникает вопрос, с какой периодичностью нужно флаг проверять.
Условные переменные как раз это инструмент именно для нотификации.
Причем на одну и ту же условные переменные может быть навешано несколько тредов, которые ждут какого-то события.
И уведомлять можно либо по одному треды, либо сразу все.
Подводим итоги. Что для чего нужно?
Если у вас взаимодействие в пределах одного процесса, есть два основных инструмента, которые вы в реальной жизни будете использовать.
На самом деле их чуть больше, но в реальной жизни маловероятно, что вы им будете пользоваться.
Это мьютексы, которые являются просто замочками для каких-то критических секций, для того чтобы предотвратить гонку данных.
И второй из них это условные переменные. Семафоры на самом деле можно использовать тоже.
Но возникает вопрос, а зачем, когда у вас есть уже более высокоуровные инструменты.
Поэтому на практике они не так часто используются, хотя это тоже возможно.
Семафоры удобно использовать в тех задачах, когда у вас есть несколько условий, поскольку этот счетчик целочисленный, может быть больше, чем единица.
Зато если вы хотите организовать межпроцессные взаимодействия, то вариантов у вас практически не остается.
Это только семафоры, больше ничего.
И последнее, о чем хотелось бы сказать, о том, что современные процессоры уже очень многоядерные.
Сколько сейчас ядер в каком-нибудь процессоре? Кто знает? Самое большое число.
А МД?
Да, а МД, там порядка 64. Я за последними новостями о МД не слежу.
В общем, есть Зиона, у которых 24 ядра.
А вы про это не знаете, и мы про это не должны знать, потому что они паразиты такие.
Решили провести последнюю конференцию без нас и даже решили отключить нас от видеороликов.
В общем, последний М1, который не МАКС, а Ультра, там 20 ядер.
Фигня, посреди Зио МФИ. Так что могли бы не показывать, ничего мы не потеряли.
Так вот, 20 ядер. И на самом деле это не предел. Это только на один процессор.
В серверах можно ставить по несколько процессоров, каждым из которых там по 20 с лишним ядер.
В общем, уже много. Чем больше ядер, тем больше чего, тем больше толкучки.
Возникает много потоков, которые начинают уже мешать друг другу.
И классическая проблема. 100 000 одновременных подключений.
Ну хорошо, 100 000 одновременных подключений, навряд ли вы создаете 100 000 трэдов, которые будут работать одновременно.
А вот 20 трэдов, которые работают одновременно с одними теми же данными, это уже вполне себе прилично.
И какие тут возникают проблемы? Проблема в том, что они начинают захватывать мьютексы.
И захват мьютекса, вообще блокировка, она хоть и не расходует процессорное время,
но заставляет все отдельные потоки просто простаивать впустую.
Просто ожидая, что какие там мьютексы вдруг внезапно станут свободными и может быть продолжать свое выполнение.
И в некоторых задачах, например, обработка большого количества подключений, это становится неприемлемым.
Поэтому могут использоваться не блокирующие структуры данных.
Например, лог-фри очереди. Это самая распространенная структура.
Когда у вас в одну сторону записывают какие-то данные без блокировок, без мьютексов, а с другой стороны не могут читаться.
Что они про не блокирующие структуры данных рассказывали?
Лог-фри не было. Значит, будет еще.
И на самом деле это очень сильно повышает производительность именно в ситуации.
Никогда у вас там 2-3 потока. 2-3 потока используете мьютексы, не парьтесь.
Если потоков уже становится много, то без лог-фри уже становится сложно.
И как у нас реализуются блок-фри структуры данных?
Есть атомарные операции во многих процессорах, что ARM, что x86.
Но они работают только с целочисленными значениями, не превышающими по размеру машинное слово.
Вообще, целочисленные значения, не превышающие по размеру машинного слова, достаточно для чего?
Например, для указателя.
Как можно, имея атомарные операции над каким-то целочисленными значениями, реализовать не блокирующую очередь?
Очередь – это односвязанный список.
Соответственно, вы можете параллельно в двух трейдах создавать 2 объекта, которые хотите добавить.
Как выполняется добавление? Это просто обмен указателями.
Не важно, какой размер у вас данные в этой очереди.
Если вы создали какую-то порцию независимо друг от друга, не мешая друг другу,
то потом перекинуть указатели на tail или на следующий элемент списка вы тоже можете сделать атомарным образом.
Этот сломанный светофор – это очередное творение бота Рудали от Сбербанка.
Наш ответ загнивающему западу.
На этом все.
