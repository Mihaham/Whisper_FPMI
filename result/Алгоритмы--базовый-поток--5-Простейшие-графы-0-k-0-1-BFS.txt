,
,
,
,
,
,
,
,
,
,
,
,
,
,
произведение v на v. Соответственно, связи могут быть как неориентированными,
то есть у нас по сути нет такого, что в этой связи b и c как-то выделены отдельно
вершины b или как-то выделены отдельно вершины c, либо рёбра или связи могут быть
ориентированными. Мы говорим, что связь проведена из вершины c в вершину b.
Соответственно, когда мы будем обсуждать какие-то конкретные алгоритмы,
когда вы будете решать конкретные задачи, обычно уточняется, что имеется в виду рёбра
ориентированные или неориентированные. Если мы говорим про эти множества,
то есть если мы говорим формально про множество v и e, то если у нас граф неориентированный,
то эти пары в множестве e не упорядочены. То есть это просто некоторые двойки.
Соответственно, если граф ориентированный, то пара упорядочена. Всё достаточно просто.
Вот у нас есть связь b-a и, соответственно, вот есть рибро b-a. Пока всё понятно.
Ну и соответственно, для чего нужны такие структуры? Почему важно изучать алгоритмы
на таких вещах? Вообще говоря, довольно много вещей из реальной жизни.
Я уже в процессе общения привёл несколько примеров. Довольно много приложений,
так или иначе, на самом деле представляют в виде графов, в виде их взаимодействий и так далее.
И, собственно, здесь уже можно придумать много различных постановок.
А как быстро можно добраться из одной вершины до другой?
А вообще, в принципе, из одной вершины до другой можно добраться или нет?
Вообще говоря, можно ли выделить в этом большом графе какой-нибудь кусок,
который, условно, сильно связан, в котором между любой парой вершин есть какая-то связь.
Или между любой парой вершины можно добраться до любой другой и так далее.
То есть эти вопросы, я думаю, вы сами понимаете, что довольно часто в многих приложениях
представляют некоторый интерес. Ну вот, соответственно, мы какие-то общие алгоритмы,
какие-то общие подходы работаем с такими структурами, мы и, собственно, рассмотрим.
Вот. Да, соответственно, ещё продолжаем несколько определений.
Соответственно, если у вас в графе допустимые так называемые мультирёбра,
то есть между одной парой вершин может проходить сразу несколько ребер,
то такой граф называется мультиграф. Соответственно, вот тут между парой 1 и 2,
то есть из вершины 1 вершины 2 приведено сразу два ребра, поэтому этот граф – это мультиграф.
Вот. Что? Ну смотрите, у вас может быть такая ситуация, что есть вершина 1, есть вершина 2.
И, скажем, на одном ребре написано значение, допустим, длина этого пути равна единице,
длина этого пути равна двойке. То есть два разных пути.
И плюс вы можете ставить различные вопросы типа, а сколькими способами можно из одной вершины
добраться к другой. Вот. И если у вас путей несколько, то, соответственно, вы путь из 1 и 2
учитываете два раза. То есть, грубо говоря, у вас из единицы двойку есть два пути.
И, соответственно, естественно, вот эти кратные ребра влияют длина количества общих путей
из какой-то вершины до любой другой. Понятно, да?
Такие ситуации вполне могут возникать. Вот. Плюс могут возникать ситуации,
при которой у вас связь проведена из одной вершины в саму себя. Вот. Это так называемые петли.
Граф с петлями называется псевдографом. Соответственно, если вы в графе разрешаете
и петли, и, скажем, микратные ребра, то такой граф называется мульти псевдограф.
То есть мульти означает, что между парой вершин может быть проведено несколько ребер.
Псевдографы это значит, что у вас в графе допускаются петли. Все понятно? Окей.
Дальше. Еще несколько определений. Соответственно, степень вершины в неориентированном графе
называется prosnap с количеством ребер, которые торчат из этой вершины.
Ну, если у меня ориентированный граф, соответственно, если у меня есть
какой-то неориентированный граф, здесь такое, то, соответственно, если я
у насмотрю вершину A, то степень этой вершины равна finding point.
Степень вершины В – равна 1, степень вершины Ц – это 1.
То есть, ровно степень совпадает с количеством ребер, которые торчат из этой вершины.
Если у нас граф ориентированный, то тут мы говорим не про степень вершины,
а про полустепень вершины. Рёбра в вершину могут как входить, так и выходить.
Полустепенью исхода вершины обозначается вот так. Мы будем называть количество исходящих ребер.
Количество ребер, у которых в качестве первой координаты выступает сама вершина В.
Полустепенью захода вершины – это количество ребер, которые в эту вершину входят.
Всё довольно просто.
Ну и соответственно довольно очевидно утверждение состоит в том, что если вы возьмёте неориентированный граф и просуммируете все степени вершин,
то получите 2e. Это для неориентированного графа.
Если возьмёте ориентированный граф, то и просуммируете какую-нибудь полустепень, например, полустепень исхода, то получится g.
Это нужно как-то отдельно пояснять? А у вас теория графа уже была?
Ну всё, отлично. Давайте кратко просто скажу, что у каждого ребра есть своё начало.
То есть тут мы взяли и все начало просуммировали, но соответственно все начало совпадают.
У нас есть значение соответственно между ребром и его началом.
А тут у нас и начало и конец совпадают, поэтому каждое ребро в этой сумме учитываем два раза.
Ну соответственно, если теория графа уже знакома, давайте быстро пробежимся, просто напомним какие-то определения.
То есть путём в графе называется простонаобоспоследовательность вершины ребер.
Причём каждое ребро соединяет соседние вершины в последовательность.
То есть вы говорите, что сначала идём в эту вершину, потом по этому ребру проходим все в эту вершину,
потом по этому ребру проходим в другую вершину и так далее.
Почему нам важно уточнять ребра? Потому что опять же повторюсь, что у нас могут быть ситуации, при которой
соответственно нет.
Почему мы уточняем ещё дополнительные ребра?
Потому что у нас может быть такая ситуация, что между двумя вершинами может быть несколько ребер.
Соответственно мы уточняем по всему конкретному ребру, мы идём из вершины х в вершину у.
Хотя если у вас граф не мультиграф, то есть если вы запрещаете кратные ребра,
то это просто последовательность вершин.
Простой путь — это путь, в котором нет повторяющихся вершин.
Грубо говоря, путь без циклов. Путь без циклов — это простой путь.
Цикл — это замкнутый путь. Это путь, который начинается и заканчивается в одной и той же вершине.
Это довольно просто.
Это значит, что касается теории, теперь давайте поговорим больше про алгоритмы.
Мы сейчас будем изучать такую штуку как графы.
Естественно мы хотим эти самые графы, чтобы это не значило, как-то уметь представлять в памяти компьютера.
В зависимости от того, как вы представляете граф в памяти компьютера,
это очень сильно влияет на эффективность алгоритмов, в чём мы неоднократно убедимся в процессе следующих лекций.
Давайте пока просто обсудим, как можно представлять графы в памяти.
Как мы будем представлять вершины, тут всё довольно просто.
Мы всегда будем предполагать, что на вершинах задана какая-то естественная нумерация.
То есть у нас просто вершины, то есть понятное дело, что мы будем работать с конечными графами.
И каждой вершине мы ставим соответственно некоторый индекс.
То есть от 0 до v-1.
Предполагаем, что все вершины просто-напросто пронумерованы с нулевого элемента по v-1.
Самое интересное это то, как мы будем представлять ребра.
Тут начинаются всякие разные тонкости, разные всякие интересности.
Самый простой способ представлять ребра это просто взять массив или вектор
и сохранить в нём последовательность пар.
Если у меня есть граф 0,1,2 и в нём такие вот ребра, то соответственно я создаю массив,
в котором храню пары 0,1,1,2,0,2.
То есть это довольно простой и тупой способ.
Давайте поговорим о том, как он работает на практике.
Меня будут интересовать 4 штуки всегда.
Это памяти, сколько памяти мы занимаем, сколько памяти занимает наш граф в компьютере.
Соответственно за сколько времени у нас проходит обход всех ребер.
То есть я хочу взять и обойти все ребра графа.
Дальше поиск ребра, это значит я хочу взять какое-нибудь конкретное ребро
и понять, а есть оно у меня в графе или нет.
То есть грубо говоря, у меня есть две вершины 2 и 3.
Я хочу понять между ними есть ли бро, между ними есть какая-то связь или нет.
И последнее это получение соседей вершины.
То есть это тоже будет важная операция, которая будет использоваться многократно в последующих алгоритмах.
То есть я хочу взять вершину и узнать все вершины, которые смежены с ней.
То есть все вершины, которые являются её соседем.
Все вершины, в которые я могу попасть из этой вершины.
Давайте обсудим память.
От Е, наверное.
От модуль Е.
Даже тета.
Ну понятно.
То есть так как я храню массив пар, то у меня каждое ребро один раз встречается в списке.
Поэтому тут все понятно.
За сколько я могу обойти все ребра?
Тоже тета от Е.
Тоже прохожусь просто-напросто по массиву и, соответственно,
не знаю, печатают на экран, что-то узнаю про них и так далее.
Тут все просто.
Поиск ребра.
Тоже тета от Е.
Действительно.
Так как я храню просто-напросто неупорядоченный список ребер,
то чтобы найти конкретное ребро, в худшем случае мне придется пройти по всему массиву
и определить, есть ли он или нет.
Ну и наконец получение соседей вершин.
Почему Е квадрат?
Ну тоже за Е, на самом деле, да.
Тоже за линию.
То есть все операции выполняются за линию.
Почему там, как последний пункт, получение соседей вершин?
Ну просто мы проходим по всему списку.
И, соответственно, если у нас граф не ориентированный как здесь,
точнее, наоборот, ориентированный как здесь,
то мы просто смотрим на первую координату.
Если первая координата совпала с интересующей нас,
то там печатаем ее на экран, что-то с ней делаем.
Соседей. Да, есть одна вершина.
Получаем в соседе вершину единицы или двойки.
Ну тут не интересно.
На самом деле эта структура данных нам пригодится.
То есть тут она довольно простая.
У нее очень мало накладных расходов.
Но в большинстве ситуаций бесполезно.
Поэтому давайте пока ее оставим и пойдем дальше.
Следующая идея заключается в следующем.
Смотрите, всякого рода операции поиска, то есть поиск конкретного ребра
или поиск соседей вершины занимает долгое время.
Поэтому, соответственно, возникает естественное желание как-то ускорить.
И вот, собственно, самая простая идея, то, как можно хранить ребра,
не просто в виде списка, а в виде сортированного списка.
Давайте возьмем наш список ребр
и будем поддерживать его от сортированных.
То есть будем поддерживать его от сортированных
по первой координате
и по второй координате.
Идея понятна, да?
То есть сначала...
Спасибо. Сначала по первой координате, то есть откуда идет ребро.
А потом внутри вот этого списка.
У меня есть все ребра, которые ведут из вершины ноль.
Да, соответственно, внутри него сортируется уже по второй координате.
Но обычно лексиографическое сравнение пар.
Окей? Вот.
Чего мы таким образом добиваемся?
Со сколько теперь у нас будет работать поиск ребра?
Да, поиск ребра теперь будет работать за логарифм D.
Ну, обычным бинарным поиском, так как мы знаем, что все пары отсортированы
в порядке взрастания или в порядке убывания, соответственно, тут можно спокойно применить бинарный пояс для того, чтобы определить, есть ли данное ребро в нашем графе или нет.
Ну и, наконец, получение соседей вершины.
Ну, не совсем. Тут более точный ответ.
То есть, действительно, за логарифмом что мы можем найти?
Да, за логарифм можем найти, ну, скорее, lower bound.
То есть, начало того момента, когда у меня начинаются ребра, которые ведут из конкретной вершины.
Но чтобы вывести все остальные вершины, естественно, мне нужно еще деговое время, согласна?
Ну, я нашел начало, и потом мне нужно пройтись, там, все их вывести, там, все сохранить куда-то и так далее.
Вот такая история.
С этим тоже проблем нет, тут все понятно.
Так, давайте спложнять структуры и перейдем к наиболее, на самом деле, к наиболее применимым на практике.
Вот как ни странно, сортированный список ребер используется довольно редко, и нами он тоже, я думаю, практически не будет использоваться.
Теперь давайте перейдем к более применимым структуре данных на практике.
Первая это матрица смешности.
Значит, идея тут очень простая.
Давайте заведем двумерную матричку размера В на В.
И просто напротив каждой ячейки ИЖ будем хранить либо булевский флаг, либо количество ребер.
Ну, в общем, так или иначе, будем хранить некоторую информацию о том, принадлежит ли ребро ИЖ множеству ребер Е.
Тут стоит либо единичка, либо ноль.
Ну, либо просто количество ребер, если мы говорим про мультиграф.
То есть, если у нас есть граф 0,1,2, то, соответственно, в ячейке 2,1 стоит ноль, потому что из вершины 2 в вершины 1 нет ревра.
Но при этом в ячейке 1,2 стоит единичка, так как у нас есть ребро из единицы в двойку.
Идея понятна, да?
Ну, я думаю, сразу не вооруженно взглядом вида, что недостатком такой структуры данных является то, что она в памяти занимает В квадрат.
То есть, условно, если вот, скажем, больше тысячи вершин, то уже больше тысячи или больше десяти тысяч вершин, то уже как-то становится все грустно.
Да, еще один момент нужно упомянуть.
Тут сказано про разреженные графы.
Давайте тоже я про это скажу, что мы будем, как правило, рассматривать две ситуации.
Первая ситуация – это граф разреженный.
Разреженным графом будем называть такой граф, к которому количество ребер не примерно равно, но по порядку величины совпадает с числом вершин.
То есть, это означает, что из каждой вершины торчит не очень много ребер, так скажем.
Скажем, количество ребра отличается от количества вершин не больше, чем на какую-то константу.
Не больше, чем в какую-то констанцию раз.
И, значит, будут у нас плотные графы.
Плотным графом называется такой граф, у которого есть практически все ребра.
Но я думаю, вы понимаете, что если у вас полный граф, то есть, если у вас в графе есть все ребра, то, соответственно, в таком графе, если, опять же, мы не учитываем повторяющиеся ребра,
максимум вот столько ребра.
Ну, это порядка в квадрат.
Соответственно, если у вас из каждой вершины торчат все ребра практически в каждую вершину, то, соответственно, у вас порядка в квадрат ребер.
Ну, соответственно, тут сразу понятно, что если у вас граф разреженный, то есть, не очень плотный, то хранить матрицу смежности не очень-то эффективно.
Почему? Потому что у вас там очень мало единичек и очень много нулей.
Соответственно, вы просто тратите в пустую большое количество памяти просто для того, чтобы сохранить там нули.
Ну, не очень приятно.
За сколько будет работать обход всех ребер?
Так, первый пункт в квадрат, второй.
Ну, действительно, тоже в квадрат.
То есть, понимаем, как получить все ребра из этих стокпурданов.
Ну, нам нужно просто-напросто пройтись по всем ячейкам.
И скажем, если в ячейке стоит какое-то не отрицательное, не нулевое число, то, соответственно, мы говорим, что это ребро есть в нашем графе.
Поиск ребра.
Вот, а поиск ребра работает за единицу, что уже приятно.
То есть, тут мы уже, в отличие от предыдущих структур данных, в смысле списка ребер и сертированного списка ребра, мы теперь чисто за единицу можем понимать,
а есть ли данное ребро в нашем графе или нет.
Ну, просто-напросто так матрица смежности устроена.
То есть, идем в соответствующую ячейку, и там стоит либо единичка, либо нолик.
Ну, и наконец, получение соседей вершины за линию относительно чего?
За В, да.
То есть, как получить соседей, например, вершины 1?
Нужно просто пройтись по этой строчке и выписать все те столбцы, в которых стоит значение 1.
Тоже все. Тоже все, думаю, понятно.
Вот такая вот структура данных.
Так, ну и наконец, финальная структура данных это списки смежности.
Значит, списки смежности устроены довольно интересно.
Значит, тут мы будем действовать следующим образом.
Давайте просто-напросто заведем массив.
Массив размера В.
И в каждой ячейке, ну, например, ячейке номер 2, будем хранить список из тех вершин,
в которые ведут ребра из вершины 2.
Х, Ю, З.
То есть, это означает, что у вас есть вершины 2.
Из вершины 2 торчат ребра в вершину Х.
В вершине Х.
вершину х, вершину у и вершину z.
Про это мы отдельно поговорим, что если у нас граф неориентированный,
как его хранить, это будет отдельный вопрос.
Давайте пока рассуждать терминах ориентированного графа.
Пока все просто.
С неориентированными графами там...
В общем, поговорим отдельно.
Пока граф ориентированный, все довольно понятно.
Вот пример еще одного графа.
Тут у меня есть вершина 0,
и из нее торчат ребра в единицу и двойку.
Соответственно, вот из нуля торчит список.
В нулевом списке хранится список из единицы и двойки.
Из единицы есть ребро только в двойку, поэтому тут хранится двойка.
Соответственно, из двойки никуда пройти нельзя, поэтому тут пустой список.
Как устроить список смежности тоже понятно.
Кстати, очень похоже на хэш-таблицу.
Грубо говоря, у вас ребра с одинаковым началом пронятся в одной и той же ячейке.
Ну да, по сути, это оно и есть.
Вот.
Соответственно, я думаю, понятно, что памяти данной структуры данных
занимает вот этот v plus e.
То есть просто-напросто линейная память от размера графа.
Кстати, граф представляет...
Размером графа считается пара из числа вершины и числа ребр.
То есть и то и то входит в понятие размера графа.
Вот. Ну откуда берется v plus e, понятно?
Надо, то есть v это внешний список, ну и суммарная длина внутренних списков равна e.
Окей? Окей.
Так, значит, теперь я хочу обойти все ребра графа.
За сколько у меня получится это сделать?
Да, тоже на самом деле v plus e.
То есть тут v plus e.
И обход всех ребра графа тоже занимает v plus e, ну, по понятным причинам, да, опять же.
Ну, мне нужно пройтись по всем спискам,
и плюс мне нужно еще дополнительно пройтись по всем элементам этого массива.
Но даже если, скажем, какая-то ячейка пустая, мне об этом нужно как-то узнать.
Поэтому я прохожусь и по всем ячейкам внешнего массива,
и по всем спискам, и по всем внутренним спискам.
Окей, теперь мне нужно найти какое-то конкретное ребро.
Да, если я хочу найти...
Не буду большое.
То есть если меня спрашивают какую-то конкретную вершину,
точнее, меня спрашивают конкретное ребро v-у,
то, соответственно, понять, есть ли данное ребро в моем графе или нет, довольно просто.
Я просто иду в соответствующий список для вершины v
и прохожусь по нему.
Соответственно, работаю за степень v.
Вот тут, кстати, можно обсудить сразу же некоторые улучшения списка смешности.
Вот, можно ли как-то эту симптотику улучшить?
Будут ли какие-то предложения?
Нули? Какие нули?
Так, да, можно вот эти списки сами внутри хранить сортированными.
Окей, что в итоге получим?
Глударифом дег v, да, это если мы храним сортированный список.
Да, там еще была идея у кого-то хранить бинарное дерево поиска.
В самом деле неплохая идея тоже.
То есть если мы тут храним...
Ну, не важно, просто какое-нибудь сбалансированное бинарное дерево поиска, да.
Мы храним какое-то сбалансированное бинарное дерево поиска,
и тогда тоже ассимтотика поиска будет вот такой.
И более того, мы можем эффективно вставлять элементы вот в эту структуру данных.
Вот тоже за алгоритмом.
А можно что еще сделать?
Последние две лекции, что обсуждали?
Хэш, что у нас тогда будет?
Ну, единицу в среднем, да.
То есть вот тут на самом деле, вот здесь вы можете хранить хэш-таблицу.
Вот в этой хэш-таблице хранить все элементы,
все вершины, в которые ведет ребро из нулевой вершины.
И скажем, если хэш-таблица достаточно хорошая,
то в среднем за единицу вы будете как вставлять туда новые ребра,
так и удалять новые, удалять ребра.
И, соответственно, поиск ребер тоже будет в среднем за единицу выполняться.
Нет, это все просто фантазии.
Скорее всего, вам это не понадобится.
В большинстве ситуаций нам поиск ребра тупо не понадобится.
Самая важная операция, которая нам будет нужна, это краски последние.
И вот для последней на самом деле плевать, как вы храните.
Ну, точнее, с точки зрения константы не плевать,
но с точки зрения симптотики все равно, как вы храните.
За сколько времени я могу получить соседей вершины?
Ну да, тут смотрите, тут есть такие рассуждения,
что если вы хотите вернуть отдельный список вершин,
то вам нужно потратить степень вершин.
Почему? Потому что вы идете в соответствующую ячейку
и проходите по этим элементам, выводите их на экран
или возвращаете какую-то копию массива.
Но тут есть такой момент, что на самом деле,
если вы под получением соседей вершины подразумеваете просто-напросто,
что вам нужно вернуть какой-то список,
то вы на самом деле можете за единицу вернуть уже сразу готовый список, согласны?
Ну, допустим, вот если это STD-вектор, то вы можете просто вернуть ссылку на вектор,
то есть ссылку на тот же самый список.
И тогда вот в этом смысле поиск соседей вершины занимает просто от единицы.
Понятно?
Поэтому тут можно скобку указать, что вообще это от единицы,
если речь идет про возврат либо указателя на этот массив,
либо ссылку на этот массив внутренний и так далее.
Поэтому в этом смысле списки смежности очень крутые,
то есть мы можем и поиск ребра свести к единице,
и получение соседей вершины тоже свести код единицы,
в случае, если это действительно требуется.
Ну и на самом деле списки смежности – это будет самое часто используемое у нас на лекции,
то есть у вас на семинарах структура данных.
Понятно?
Ну да, собственно, вот то, что мы обсудили, что на самом деле вместо массивов и списков
можно хранить бинарные деревья поиска или, конечно, таблицы,
вот тогда, соответственно, асимпатически третий пункт будет выполняться быстрее.
Да, ну, понятное дело, что это асимпатически, в каком смысле?
Смотрите, если у вас на самом деле граф достаточно небольшой,
или если третий пункт вам на самом деле нафиг не нужен,
то, вообще говоря, хранить хэш-таблицу или хранить бинарные деревья поиска не очень поразумно.
Да, потому что если у вас размер списочков небольшой,
то это означает, что вы храните очень большое количество дополнительных ресурсов,
вы тратите гораздо больше лишнего времени на то, чтобы поддерживать эти маленькие списки
ассортированными или организовывать хэш-таблицу.
Кроме того, если вам пункт 3 не нужен совсем, то есть если вам не нужно искать ребра,
а вам нужно, скажем, просто получать список соседей,
то тогда вы тратите лишнюю память на хранение всяких разных указателей и так далее.
Ну и плюс, я думаю, вы понимаете, что обход дерева занимает гораздо больше времени,
чем, скажем, просто обход массива.
Поэтому тут надо уступать из принципа разумности.
Что в конкретной задаче вам нужно, то есть нужно ли вам осуществлять быстрый поиск или нет.
Так, ну и да, перед тем, как пойдем дальше,
давайте, собственно, обсудим вопрос, который возник.
Вот тут были приведены примеры представления графов для ориентированного случая.
Что если у нас в графе все ребра имеют определенное направление?
Что можно сказать про неориентированный граф?
Какие у вас будут предложения?
Ну скажем, вот есть вот такой вот граф.
И, допустим, я хочу его хранить в списке смежности.
Что будем делать?
Ну да, на самом деле более-менее есть два подхода.
Можно хранить только то, можно представлять всегда так, что у вас, значит,
стартовая вершина всегда является меньшей ребро.
То есть тогда мы тут храним 0,1, а 1,0 уже не храним и так далее.
Но, возможно, другая ситуация, при которой мы храним одновременно оба ребра.
То есть, грубо говоря, у нас такая, то есть заменяем одно ориентированное ребро,
точнее одно неориентированное ребро, двумя ориентированными ребрами.
И, на самом деле, на практике именно вот такой вот способ он гораздо удобней,
ну как правило.
Вот такая вот ситуация.
Понятно, да?
Но тут я сразу должен сказать некоторые замечания
Несмотря на то, что это, как правило, удобней,
стоит помнить вот о такой проблеме.
Понимаете ли вы, что вот такой граф вообще, говоря, не эквивалентен вот такому графу?
Так, ну а давайте так, в термине какого-нибудь свойства графа.
Какое свойство, что есть у этого графа и чего нет у этого графа.
Да, циклы.
Вот одна из первых задач, которые мы с вами рассмотрим, это будет поиск циклов.
Ну, скорее всего, уже в следующий раз рассмотрим, но так или иначе.
Важно помнить, что в этом графе циклы есть, а вот в этом графе циклов нет.
Поэтому, если вы изначально работаете с неориентированным графом
и пытаетесь в неориентированном графе найти циклы,
но при этом представляете вот такой граф, как ориентированный с двумя направленными ребрами,
то алгоритм поиска циклов скорее всего даст вам неправильный ответ,
он даст вам информацию в том, что тут на самом деле циклы есть.
Об этом стоит помнить, окей?
Можно, тут скорее будут другие истории,
на конкретном алгоритме, что если вы, скажем,
прошлись из вершины 1 в вершину 0, то обратно
проходить вы будете запрещать просто-напросто.
Ну а о конкретных применениях мы просто поговорим,
просто я предупреждаю, что если вы храните
неориентированный граф как ориентированный,
что, как правило, удобнее, но стоит помнить о том,
что иногда свойства неориентированного графа не сохраняются.
Сейчас вы увидели, что появились лишние циклы.
С обсуждением того, как представлять графы в памяти мы покончили.
Давайте еще раз напомню, о чем поговорили.
Можно хранить граф в виде просто списка ребер,
точнее так. С хранением вершин никаких проблем нет.
Просто у каждой вершины мы ставим соответственно
некоторую учиселку, то есть от 0 до v-1.
Главная проблема заключается в том, как мы будем хранить ребр,
как мы будем хранить связи в графе.
Первый способ это список ребер, дальше сортированный список ребер,
дальше соответственно матрица смежности и список смежности.
Есть четыре способа.
На самом деле обсуждать мы будем, как правило, только последние два.
К первому двум будем обращаться в отдельных ситуациях.
Как картинку?
В смысле, вы имеете в виду...
Как бы вам объяснить?
Так можно делать, но это крайне неэффективно в том смысле,
что я хочу обратиться к вершине номер 10 и узнать ее соседей.
Скорее всего, мне придется еще дополнительно отдельно хранить
какой-нибудь массив, который будет хранить еще дополнительные указатели
на вот эти самые штучки.
Тут по сути вы получили список смежности,
в котором еще между элементами списка хранят еще дополнительные связи.
То есть вы еще сильнее вы сложили структуру.
Поэтому так, как правило, никто не делает.
Первый алгоритм, который мы рассмотрим, и, наверное, единственный на сегодня,
это обход графа ширину.
Давайте сначала разберемся с тем, что такое вообще обход графа.
Обход графа — это процесс посещения всех вершин и ребер графа.
Все очень просто.
То есть стоит задача такая, у нас есть граф,
нужно просто посетить все вершины и посетить все ребра.
Казалось бы, задача очень неинтересная.
В цикле проходимся по всем вершинам, в цикле проходимся по всем ребрам.
Но, как правило, обходы устроены следующим образом.
Обходы осуществляются с учетом того, какая у вас в графе существует структура.
Обходы устроены так, что они учитывают локальность графа.
Если у вас из вершины 0 есть какие-то ребра в вершины 1 и 2,
то, соответственно, из вершины 0 вы можете пройти только в вершины 1 и 2.
Если дальше из вершины 1 у вас есть ребра только в вершины 5 и 6,
то вы можете пройти только в них и так далее.
То есть обход графа — это некоторый процесс посещения вершины ребер такой,
что он позволяет выявить какие-то свойства графа,
какие-то локальные свойства графа или какие-то глобальные свойства графа.
То есть это обход с уважением структуры графа.
А не просто-напросто вычисление вершины и ребер.
Сегодня знакомимся с обходом графа ширину,
и обход графа ширину действует на самом деле очень просто.
Вот у нас есть, допустим, какой-то граф.
Какие-то вот ребра, пусть 0, 1, 2, 3, 4, 5, 6.
Когда мы начинаем обход, мы, как правило, выбираем какой-то стартовый вершин,
то есть ту вершину, с которой мы начинаем обход.
Давайте предположим, что мы начали обход с вершины 0.
Как устроено обход ширину?
У нас сначала берет какую-то вершину и просматривает ее соседей.
После того, как мы просмотрели соседи одной вершины,
мы рассматриваем соседей соседей.
То есть по сути мы постепенно увеличиваем область нашей видимости.
Таким образом мы открываем все более более новые вершины,
все более более удаленные ребра.
То есть как устроен обход здесь?
То есть как устроен обход здесь? То есть сначала мы находимся в вершине номер 0,
дальше, соответственно, мы видим, что соседними нашими являются вершина 3, 4 и 6.
То есть порядок обхода у нас примерно следующий. То есть это вершина 0, вершина 3, вершина 4 и вершина 6.
То есть вот то, что мы обошли в нулевой момент времени, то, что мы обошли в первый момент времени.
Что происходит дальше? Дальше мы берем, соответственно, вершину, которую мы уже пустили,
сейчас вершину 3, и обходим ее соседей. То есть идем в вершину номер 1, идем в вершину номер 2.
Добавляем x список, вышли вершину 1, 2. Дальше у нас была вершина номер 4, мы обходим ее соседей,
в данном случае это вершина номер 3. Идем в вершину номер 6, обходим ее соседей,
и увидим, что всех соседей мы уже обошли. То есть это вершина не 3, а 5.
Всех соседей вершины 6 мы уже обошли, поэтому мы на нее забиваем, больше ничего не делаем.
И, соответственно, вот у нас получился вот такой порядок обхода.
Это вот то, что у нас получилось на втором уровне.
То есть вот в нулевой момент времени у нас была точна только стартовая вершина 0.
Дальше, когда мы обошли ее соседей, мы получили, скажем так, соседей первого уровня,
это вершины 3, 4, 6. Дальше на следующий момент времени мы обошли соседей соседей,
то есть получили соседей второго уровня. Ну и, понятное дело, что если игра большой,
то мы продолжаем действие таким образом.
Соответственно, получился вот такой вот порядок обхода.
Ну и перерывом давайте ответим на вопрос.
Как вы думаете, если мы действуем вот такой вот тактикой,
то есть если вот такой тактикой мы пытаемся обойти все вершины и ребра графа,
какие свойства мы о графе можем узнать таким образом?
Вот, я услышал корочеше расстояние, отлично.
Понимаете ли вы, что если я покажу таким образом сначала соседей, потом соседей, соседей и так далее,
то я на самом деле для каждой вершины знаю ее расстояние,
ну расстояние от нее до стартовой вершины.
Вот, то есть отлично, первое применение это кратчайшее расстояние от,
ну давайте обозначу S, от стартовой вершины.
Так, что еще?
Число вариантов дойти.
Число вариантов дойти, ну...
Ну на самом деле число вариантов скорее всего не получится.
Почему? Потому что у нас есть серебра, которые мы просто игнорируем.
Вот это ребро, вот это ребро.
Ну, возможно, можно, короче, тут все-таки мы предполагаем,
что мы отходим только те ребра, которые там ведут в непосеченные вершины.
Тут на самом деле есть второе очень хорошее применение,
это множество достижимых вершин.
И третье это проверка связности.
Проверка связности нюорграфа.
Понятно, и второй и третий пункты это про что?
Ну второй пункт, по сути он похож на первый пункт,
мы просто узнаем все те вершины, до которых можно дотянуться из этой вершины.
То есть мы узнаем список всех вершин,
до которых теоретически есть путь из данной вершины.
И третий пункт, проверка связности неориентированного графа.
Все понимают, что какой связанный граф, связанный неориентированный граф.
Но это просто граф, в котором из любой вершины есть путь до любой другой.
Понятно ли, как с помощью вот этого обхода проверить связность графа?
Ну да, если мы запустили обход из поля бы вершины и посетили все вершины,
то граф соответственно связный.
То есть если из одной вершины можно добраться до любой другой,
то это означает, что из любой вершины можно добраться и до любой другой.
Ну как минимум через вот эту центральную вершину.
Ну и наоборот тоже, естественно, верно.
Ну окей, давайте...
Можно четвертым пунктом найти количество связанных компонентов.
Найти компоненты связанных.
Ну действительно, если у вас компонент связанности несколько,
то соответственно вы запускаете один обход,
тогда он находит вам одну компонент,
потом из непосещенной вершины запускаете второй обход и так далее.
Таким образом вы находите все компоненты связанности.
Но опять же повторю, это верно для неориентированного графа.
Понятно, что для ориентированного графа этот алгоритм не сработает.
Ну на самом деле тут вопрос в другом,
что на самом деле непонятно, что означает связанность в ориентированном графе.
Ну например...
Ну ладно, это мы уже...
Ну давайте, в общем, перерыв в любом случае будет.
Давайте такой философский вопрос.
Вот как вы думаете, этот граф связан или нет?
Вот, отлично, да.
Если в общем для ориентированного графа есть два понятия связанности,
сильный связан, слабый связан,
о ней мы тоже поговорим, но не сегодня.
Поэтому пока мы когда говорим про связанность,
мы имеем в виду именно, собственно, неориентированные графы.
Все, перерыв.
Такой-нибудь небольшой пример.
Два, три, четыре.
Вот такой вот.
Вот такой вот граф.
Значит, что мы будем делать?
Ну, то есть мы будем хранить в процессе работы алгоритма
последний functions данного алгоритма.
Начну, смотрите, так как мы поняли, что с помощью данного алгоритма
в принципе можно вычитать кратчайшее расстояние,
то давайте заведем специальный мотив,
в котором, собственно, будем хранить кратчайшее расстояние до каждой из вершин.
Вот, соответственно, если мы будем знать кратчайшее
расстояние до каждой из вершин,
то, соответственно, и множество до AlongedStoreah в вершин, и так далее,
мы, естественно, тоже узнаем.
Ну и, собственно, давайте скажем, что изначально,
так как мы про вершины ничего не знаем,
все, соответственно, расстояния равны бесконечностям.
Соответственно, бесконечность, она как раз таки будет нам сообщить о том, что до
данной вершины добраться невозможно. Ну, какое-то законечное число шаблов.
Вот это нулевая вершина, первая, вторая, третья, четвертая. Вот, дальше, смотрите,
чтобы восстановить путь, да, как мы будем восстанавливать путь? Это тоже интересный
вопрос. Значит, смотрите, чтобы восстановить путь, я утверждаю, что нам достаточно, на самом деле,
для каждой вершины, знать, из какой вершины мы ее посетили.
То есть, из какой вершины мы в нее попали. То есть, вы 있으reto скажете,
если мы знаем, что с четвертой вершиной вывали из третьей вершины,
а из третьей вершины попали из нулевой вершины, то, соответственно, таким образом и путь мы тоже восстановим.
Дополнительно мы еще будем хранить массив родителей, массив parents.
Ну, parent, собственно, будет как раз таки хранить, из какой вершины мы попали в данную преобходим.
Понятно? Ну и везде пока храним.
1, 2, 3, 4. Пока тут ничего нет. Ну и, собственно, как работает данный алгоритм.
Соответственно, мы выбираем какую-то старую вершину. Ну, например, нам в условии сдачи сказано,
что нужно найти кратчайшее расстояние из вершины под номером 2, да, ну и кратчайшее расстояние из вершины под номером 3.
Если это неважно, то, скажем, берем какую-то произвольную вершину. Да, мы ищем алгоритм обхода в глубину, в ширину умеет искать кратчайшие пути из данной вершины до всех остальных.
То есть есть некоторые отдельно выделенные вершины, из нее мы ищем пути, мы ищем все остальные пути.
Ну, в данном случае давайте просто и возьмем просто нулевую вершину, скажем, что нам нужно найти все кратчайшие пути из нулевой вершины.
Вот. Что мы делаем? Ну, во-первых, так как мы начинаем с нулевой вершины, мы понимаем, что кратчайшее расстояние из нулевой вершины до нулевой это 0,
и, соответственно, ну, редко у нее так и нет. Вот. И что мы сделаем? Мы заведем некоторую очередь, очередь посещения вершин.
Ну, и, соответственно, посещать вершины будем в порядке очереди, которой будет задаваться вот эта вот структура данных.
Ну, и алгоритм на самом деле очень прост. Пока у нас не опустеет очередь, мы из этой очереди достаем вершины и посещаем их.
В чем состоит опот вершины? Значит, вот мы берем вершину, которая находится в очереди, то есть извлекаем ее.
В данном случае это была вершина 0. Вот. И дальше проходимся по всем ее соседям. То есть мы достали вершину 0 и идем по всем соседям.
Значит, как только мы встречаем соседа, мы проверяем, посещали мы его раньше, как мы узнаем, посещали мы его раньше или нет.
Ну просто сравним ее с бесконечности. Понятно? Если до него, до нового соседа расстояние бесконечности, значит мы его раньше не посещали.
Окей? Вот проверяем. Ну, соответственно, вот единицу мы раньше не встречали, поэтому мы ее добавляем во первых в очередь,
а во-вторых мы говорим, что мы до нее нашли новое расстояние. Да? То есть мы обновляем расстояние тут с бесконечности до единицы.
Почему до единицы? Потому что расстояние до вершины 0 это 0, расстояние до вершины 1 стало равно 0 плюс 1, то есть 1.
Допустим, мы дальше встречаем вершину под номером 3 в рамках вот этого цикла.
А, да, еще забыли, обновить родители. Вот у единицы мы ставим родителя 0.
Встречаем вершину под номером 3, добавляем ее в очередь,
обновляем до вершины номер 3 расстояние, то есть была бесконечность, стала единица.
И, соответственно, родителям вершины 3 стало вершина 0.
Дальше встречаем соседа с номером 2.
Двойки тоже обновляем расстояние до единицы и обновляем родителя.
Добавляем в очередь. Все, на этом цикл завершен.
Мы прошли всех соседей. Ну и на этом закончили, понятно.
Вот, ну, конкретно этот цикл. Дальше снова приходим вот в этот цикл while.
У нас очередь не пустая, поэтому достаем очередную вершину.
Очередная вершина — это вершина номер 1. Достаем ее и теперь продолжаем делать то же самое
из вершины под номером 1. Вот. То есть в цикле проходим по всем ее соседям и, собственно,
проверяем, посещали мы ее соседа или нет. Если не посещали, то, соответственно,
делаем все то же самое. Ну давайте посмотрим. Вот есть вершина номер 1.
И видим, что у нее есть сосед под номером 2. Но соседа под номером 2 мы уже посещали.
Как мы это поняли? Вот мы поняли это с помощью вот этого WI-FI.
Мы посмотрели на расстояние до вершины 2 и поняли, что оно было уже когда-то раньше обновлено.
Но это значит, что мы когда-то раньше эту вершину уже встречали,
поэтому ее заново обрабатывать уже не нужно.
Окей, забиваем на вершину номер 2. Смотрим на другого соседа единица.
Другой сосед единицы — это четверка. Четверку мы еще не посещали,
поэтому мы до четверки обновляем расстояние. Это 2.
Да, почему 2? Потому что мы берем расстояние до чекущей вершины,
то есть до единицы, и прибавляем единицу. То есть до четверки у нас расстояние на единицу больше,
чем до единицы. Ну и, соответственно, до четверки обновляем родителя.
До четверки родители — это вершина под номером 1. Вот. Добавляем четверку в очередь.
Все, на этом обработку единицы завершили. Снова идем в цикл. Пока очередь не пустая,
у нас очередь не пустая. Достаем вершину, достаем вершину под номером 3.
Из вершин номер 3 пытаемся обойти соседей. Смотрим, а все ее соседи,
все соседи вершины 3, уже посещены. То есть ее соседом является четверка,
четверка уже была посещена, поэтому у нас для тройки жизнь завершается.
Снова у нас очередь не пустая, достаем двойку. Достали двойку, из двойки вообще нет никаких
исходящих ребер, поэтому цикл в принципе не отрабатывает. Завершили. Достаем четверку,
из четверки тоже никаких исходящих ребер нет. Завершаем обработку четверки. Все, в этот момент
у нас очередь опустела, больше никаких новых непосещенных вершин у нас нет. Соответственно,
этот цикл отработал, мы заканчиваем работу алгоритма, то есть возвращаем, что нам нужно,
либо массив расстояния, либо массив родителей, либо и то и другое. Понятно, да? Вот, собственно,
все в докод алгоритма и то, как он, то, как он устроен. Что? Каким образом?
Ну, можно поступить и так. Вообще говоря, мы поговорим про улучшение этого алгоритма,
но, смотрите, вообще говоря, посещение вершин оно же в чем заключается? Тут же не обязательно,
то есть тут стоит не обязательно просто цикл посещения всех вершин. Процесс
посещения вершины может заключаться в том, что мы посещаем вершину и что-то в ней делаем и так далее.
В этом случае нам нужно зайти в каждую вершину, то есть добавляем очередь. Когда добавляем
очередь, мы говорим, что когда-то мы ее посетим, когда-то мы в ней stupidity сделаем.
Или когда-то мы обработаем. И обработка, она не обязательно может заключаться,
вы просто обходите соседей. Это просто наиболее общий алгоритм того, как обойти все вершины
и обойти все рёбра, окей?
Окей, за сколько работает данный алгоритм?
Ну, давайте просуждаем.
Смотрите, тут есть цикл в цикле.
Да?
Ну и когда мы говорим про цикл в цикле, вообще говоря, довольно...
Не знаю, самое первое желание, которое возникает, какое?
Посчитать количество итераций внешнего цикла, посчитать количество итераций внутреннего цикла и перемножить.
Да?
Но, к сожалению, это будет слишком грубая оценка. Почему?
Вот сколько итераций выполняется внешний цикл?
Ну, максимум v раз, согласны?
Каждая вершина у меня не более одного раза находится в очереди.
Соответственно, у меня общее количество итераций цикла while тоже не больше, чем v.
А с чему равно количество итераций внутреннего цикла?
В худшем случае?
Ну, v.
Погласны?
То есть если вдруг у меня из каждой вершины торчат ребра во все остальные,
то вот такая ситуация получается.
Погласны?
Почему?
Каждую вершину обещаем не больше, чем по разу.
Так, и что из этого следует?
Да. Вот я как раз говорю к тому, что вот это на самом деле очень грубая оценка.
То есть, смотрите, действительно, если мы сверху будем оценивать
общее количество итераций внешнего цикла,
это v, сверху будем оценивать количество итераций внутреннего цикла,
тоже v, согласны?
Вже в эд подрат.
Но это слишком грубая оценка. Давайте под точнее.
Что мы делаем на каждой итерации?
Давайте же просто просуммируем общее количество работы
в этом внешнем цикле.
что мы делаем во внешнем цикле? Во-первых, в худшем случае мы действительно пройдем по всем вершинам, поэтому суммируем по всем вершинам, окей?
Мы делаем какую-то работу за единицу, например, достаем из очереди вершину. Эта работа занимает единицу условно. Понятно?
И плюс, сколько суммарно занимает этот цикл по времени? Сложность этого цикла какая?
Согласны, что это просто дег v? Ну дег плюс v, давайте напишу. Полустепень исхода. Согласны?
Сложность этого цикла это просто степень вершины v. На самом деле не совсем так.
Вот тут важно сделать следующее замечание. Вот тут становится важно то, как мы представляем граф памяти.
У нас тут есть операция получения соседей вершины v. А мы как раз об этом на первой части лекции говорили.
В зависимости от представления графа, до сколько времени мы получаем всех соседей вершины, время этой операции сильно зависит от того, как мы представляем граф памяти.
Давайте предположим, что мы работаем с помощью списков смежности.
Вот если мы делаем с помощью списков смежности, то действительно этот цикл работает за дег v.
И что в итоге получается? Что будет, если я просуммирую вот такую сумму?
Согласны, что сумма единиц это v. Доказывать не будем. Хорошо. Дальше.
А сумма степеней? Да, у нас было утверждение, что либо e, либо 2e, если вас грахнете.
Ну так или иначе, это просто обольшее от v и e. Понятно?
Все, соответственно, алгоритм работает за v и e. Это значит случай списков смежности.
Теперь давайте просто обсудим, а что будет, если я, скажем, вместо списка смежности буду использовать матрицу смежности?
Изменится ли асимптотика или нет? Как изменится?
Да, если мы будем использовать матрицу смежности, то тут нас будет стоять не дег v, а v. Почему?
Потому что соседи вершины в матрице смежности мы получаем за линейное время.
Поэтому перед тем, как мы начнем цикл, мы за линейное время сначала найдем всех соседей, а потом, соответственно, будет работать цикл.
Поэтому тут будет стоять θ от v2.
Вот, соответственно, я привел пример, когда списки смежности гораздо эффективнее, чем матрица смежности.
Все понятно? Отлично.
Так, ну и давайте поговорим про корректность.
Смотрите, вроде как все понятно. Да, алгоритм я псевдокод написал, как работает на картинке показал, даже сложности оценили.
Но все-таки хочется как-то формально показать, что этот алгоритм работает всегда, а не только на каких-то конкретных картинках, которые я привожу.
Давайте, собственно, оставшуюся часть посвятим тому, что докажем корректность.
Ну вот, там понадобится две леммы, первая из них утверждает следующее. Вершина в очереди расположена по неубыванию дист, и расстояния отличаются максимум на единицы.
То есть это про что? Это про то, что у нас был массив расстояний дист и была очередь.
Так вот утверждается, что если я в какой-то момент времени я бы не взял эту очередь, вот у меня есть какая-то очередь.
У меня ситуация всегда устроена следующим образом. Вначале идут, вот отсюда я извлекаю вершину, сюда я кладу вершины.
Вначале у меня идут вершины с расстоянием d, а дальше у меня идут вершины с расстоянием d плюс один.
Причем этих вершин, ну, давайте скажем больше на единицы, этих вершин больше равно нулю. Число вершин.
Доказательства тут просто по индукции. Изначально у нас в очереди всего лишь одна вершина, для одной вершины, естественно, это верма.
Теперь давайте докажем переход. Допустим, у нас в какой-то момент времени возникла вот такая вот ситуация.
Ну, что мы делаем? Мы извлекаем вершину с расстоянием d, а что делаем потом?
А потом добавляем в очередь какое-то количество вершин с расстоянием d плюс один. Согласны?
Ну, все, то есть к началу следующей итерации у нас сохраняется вот такой вариант.
Ну, точнее не такой вариант, то есть тут больше равно нулю, тут тоже больше равно нуля.
В общем, так или иначе, тут все вершины расположены в порядке возрастания, то есть в порядке неубывания,
и плюс расстояние минимальной вершины и максимальной вершины различается не больше чем на единицу. Понятно?
Ну, все довольно просто.
Вопросов нет, да? Хорошо.
Дальше, вторая лемма. Значит, вторая лемма заключается в том,
что если вдруг алгоритм нас обманывает, то есть вдруг алгоритм нашел неправильное расстояние,
то брать он может только в большую сторону, то есть в меньшую сторону он обмануть нас не может.
То есть если на самом деле кратчаешь расстояние от начальной вершины до какой-то вершины равно 5,
то наш алгоритм не может сказать, что на самом деле расстояние равно 3.
То есть если алгоритм и врет, то только в большую сторону.
Ну, собственно, вот тут используется стандартное обозначение,
ρ от s и v, это истинное кратчайшее расстояние от вершины s до вершины v. Понятно, да?
Ну, давайте докажем. То есть доказывается на самом деле тоже по индукции.
Ну, то есть база такая. Расстояние до начальной вершины равно 0,
и оно в точности совпадает, давайте так напишем, больше либо равно, чем расстояние от s до s, которое равно 0.
База выполняется, согласны? Очевидно.
Теперь переход.
Пусть достали вершину v. Что мы про нее знаем?
По предположению индукции, у нее d от v больше либо равно, чем r с v.
Значит, сосед v – это вершина u.
Значит, d от u у нас равно d от v плюс 1.
Ну, у нас так алгоритм устроен, да?
Когда находим новую вершину, мы говорим, что у нее расстояние равно расстоянию из ее родителя в един... ну, плюс 1.
Согласны? Ну, что делаем?
Это больше либо равно, чем r с v.
r с v плюс 1.
И это явно больше либо равно, чем r с u.
Так, вот последний переход может быть неочевиден.
Понятно, почему последний переход верен.
Смотрите, что такое r с u?
r с u – это истинное кратчайшее расстояние от s до u.
Давайте тут.
Зря.
Вот у меня есть вершина s, есть вершина u.
И вот здесь какое-то истинное кратчайшее расстояние от s до u.
А что такое r с v плюс 1?
А r с v – это просто кратчайший путь от s до v и плюс 1 ребро v у.
Ну, согласны, что какой-то произвольный путь точно никак не короче, чем самый короткий путь.
Согласны?
Ну, вот r с v плюс 1 – это длина какого-то пути, который мы нашли.
Он не обязательно кратчайший.
А есть истинный кратчайший путь r с u?
Ну, соответственно, какой-то путь не короче, чем самый короткий путь. Согласны?
Вот доказали, что d от u больше ребра v, чем r с v.
То есть переход доказан.
Окей? Нормально?
Хорошо.
Ну, и, наконец, последняя теорема.
Ну, собственно, корректность BFS.
Давайте теперь докажем, что мы на самом деле вообще не врём,
что у нас на самом деле всё хорошо, все расстояния...
То есть после того, как мы у нас отработал BFS, у нас все расстояния найдены корректно.
То есть на самом деле в предыдущей леме тут стоит знак небожки-бравно, а стоит точность равенства.
Как будем доказывать?
Давайте возьмём следующую штуку.
Пусть существует v такая, что d от v строго больше, чем r с v.
То есть предположим, что в какой-то момент у нас нестрогое неравенство превращается в строгое неравенство.
То есть наш алгоритм действительно врёт.
Значит, рассмотрим v со звездой вот такую штуку.
Аргмин у всем r с v среди вот такого множества, что d от v больше, чем r с v.
Рассмотрим все вершины, на которых мы брём.
И среди всех таких вершин я возьму вершину, расстояние до которой, истинное расстояние до которой, минимальное.
Понятно?
У меня есть какое-то множество вершин, на них я соврал.
И среди всех этих вершин я ищу самую ближайшую к S-вершину.
Вот, ну давайте, давайте просуждаем.
Соответственно, что я знаю?
Да, пусть, да, ещё давайте так скажем.
Пусть, пусть u это parent от v со звездой.
У со звездой.
А p это истинный предок на кратчайшем пути из S до v со звездой.
Ну то есть на реальном кратчайшем пути, то есть я рассматриваю реальный кратчайший путь от S до v со звездой.
И вот там предыдущая, ну предыдущая перед v со звездой вершина, это p.
А та предыдущая вершина, которую я нашёл, это вершина u.
Значит, можно писать следующие соотношения.
Во-первых, нам достоверно известно, что d от v больше, чем ρсв.
Это первый момент.
А второй момент нам известно следующее, что ρсв в точности равен ρсp плюс 1.
Так как p это истинный предок v со звездой.
Так как p это истинный предок на кратчайшем пути v со звездой.
А ещё мы знаем, что d от v со звездой на самом деле это d от u плюс 1.
D от u со звездой.
Каждое неравенство и равенство понятно.
Ну смотрите, вот из этого на самом деле следует следующая вещь.
Давайте я просто вот эти равенства ρ от s со звездой поставлю вот сюда, а d от v со звездой поставлю вот сюда.
В итоге я получу, что d от u со звездой у меня больше, чем ρсv.
А ρсv у меня точно совпадает с d от p.
Вот это почему.
Потому что d от v со звездой это вершина до расстояния, на которой я вру, и расстояние до которой минимально.
Ну а понятное дело, что ρсv меньше, чем ρсv со звездой, поэтому до вершины p я нашёл расстояние верно.
А раз я нашёл на неё расстояние верно, соответственно вот тут достигается вот это равенство.
Ну теперь на самом деле я могу утверждать, что я закончил доказательство, почему я пришёл к противоречию.
Смотрите, расстояние до вершины u со звездой, ну точнее d, вот эта d, которую я подсчитываю во время алгоритма, она строго больше, чем расстояние до dp.
Что это означает, до вершины p?
Это означает, что вершину p из очереди я достал раньше, чем вершину u.
Ну тут уже можно сюда перейти. Всё, без спойлеров.
То есть вершину p мы достали из очереди раньше, чем вершину u.
Согласны?
Ну так у неё dp меньше, чем du.
Согласны?
Ну а всё, а так как вершину p мы достали раньше, и плюс из p есть ребро в вершину v, то соответственно и вершину v мы должны были рассматривать раньше, чем вершину u.
Согласны?
Ну тут мы пришли к противоречию. Почему?
Потому что мы подсказали, что u это родители v, ну а u никак не могла быть родителем v.
Потому что v мы достали раньше, чем вершину u.
Согласны?
Вот всё.
Вот такое доказательство.
Есть вопросы?
Какой переход был непонятен?
Так, сейчас я...
Я, возможно, неправильно выразился.
Мы вершину p рассматривали раньше, чем вершину u.
Да?
Раз мы вершину p рассматривали раньше, чем вершину u, то это значит, что мы...
Вот у нас была такая ситуация.
Из вершины u есть ребро в вершину v, и из вершины p есть ребро у вершины v.
Так как мы вершину p рассматривали раньше, чем вершину u, То вершину v мы видели раньше, чем вершину v.
То есть вершину v мы видели ранее.
из вершины p и вершины v увидели раньше, чем из вершины u. Согласны?
Поэтому v, поэтому u никак не могла стать родителем v. То есть v мы обработали гораздо раньше, чем мы обработали вершину u.
Не обработали, в смысле встретили.
Почему вот это? Смотрите. Согласны ли вы, что...
Давайте тут напишу, что rho sv строго больше, чем rho sp.
Но это следует вот отсюда.
Теперь смотрите. Так как rho sv строго больше, чем rho sp, то до rho sp мой алгоритм нашел расстояние точно правильно. Почему?
Потому что v это такая вершина, до которой rho sv минимально.
Для которой я нашел расстояние правильно.
Среди всех вершин, до которых я расстояние нашел неправильно, у v минимальное истинное расстояние.
Но это значит, что для любой вершины, до которой расстояние меньше, я нашел расстояние корректно.
Теперь понятно?
Ну окей.
Так.
Еще есть вопросы?
Ну, в общем-то, рассмотрели алгоритм, алгоритм обхода в ширину, и даже доказали его корректно.
Мне кажется, круто.
Так, теперь за оставшееся время...
Никогда не удается, на самом деле, слайд до конца зачитать, но ничего там.
Сейчас на семинарах, значит, останется.
Обход в глубину для взвешенных графов.
Смотрите, сейчас мы искали кратчащее расстояние для графов, для так называемых невзвешенных графов.
То есть для таких графов, для которых у нас каждая ребра, по сути, равнозначна.
То есть длина каждого ребра, по сути, равна единице.
Но у нас, согласитесь, бывают ситуации, при которых у нас ребра не разназначены.
Например, по одному ребру пройтись дороже, чем по другому, и так далее.
Так вот, в некоторых таких ситуациях BFS тоже может сработать.
Ну вот, часть из них давайте разберем.
Ну, самый простой вариант, который возможен, это 01-граф.
Что такое 01-граф?
01-граф – это такой граф, у которого ребра бывают двух видов.
Первое – это ребро с весом 1, второе – это ребро с весом 0.
То есть по каким-то ребрам нам нужно заплатить, чтобы пройти.
А по каким-то ребрам мы проходим абсолютно бесплатно.
То есть какие-то ребра в кратчащем пути вообще не участвуют.
Ну, в том смысле, что по ним мы проходим бесплатно, абсолютно.
Вопрос, понимаете ли вы, что нужно делать в таких ситуациях?
Как обрабатывать такие графы?
А каким образом?
Ну вот, к сожалению, объединить не получится,
потому что у вас просто-напросто разные наборы ребер торчат из одной вершины и из другой вершины.
Ну, то есть нет, на самом деле я понимаю идею.
Идея стоит в том, что если у вас есть вершины С, вершины У, есть какое-то ребро,
то это означает, ну, и при этом это ребро имеет вес 0,
то по сути вот эти ребра можно отдать в вершине С, да, и по сути будет то же самое.
Вот, я с этим согласен, но мне кажется, что это слишком долго.
Вам как минимум нужно найти, дойти до вершины С, потом пройти по всем,
то есть по всем вершинам, до которых вы можете дотянуться с помощью нулевых ребер,
и все эти ребра засунуть в вершину С.
Ну и так далее сделать, на самом деле, для всех вершин.
То есть кажется, что это, ну, как минимум по Константе не очень эффективно.
Значит, на самом деле предлагается очень простой вариант.
Смотрите, у нас же есть очередь.
Давайте поступать следующим образом.
Х, у. Если до какой-то вершины у меня расстояние 0,
то давайте я эту вершину буду класть в начало очереди.
А если у меня до какой-то вершины расстояние 1, то я буду класть ее в конец очереди.
То есть таким образом у меня утверждение леммы 1 сохранится.
Согласны? То есть у меня по-прежнему будет очередь,
у которой все расстояния будут расположены по неубыванию,
да, все расстояния будут расположены по неубыванию.
И различаться будут максимум на единицу.
Ну и соответственно все остальные рассуждения, естественно, тоже будут сохранены.
То есть история очень простая. Давайте использовать не очередь, а двунаправленную очередь, то есть дек.
Да, и класть вершины как в начало, так и в конец.
То есть если ребро 0, то в начало, если ребро 1, то в конец.
А вы в начало можете класть вектор? Нет.
Даже если бы был, он работал бы за линейное время.
Это не то, что вам нужно явно.
Так, ну и последнее. Давайте, значит,
эффективный способ поставим на семинар.
А сейчас разберем более, значит, простой вариант.
Значит, 0 к граф. Что такое 0 к граф? Вот у вас есть вершины.
Из вершины торчат ребра там 0, 1, 2, 3, ну и так далее.
Максимум к.
То есть у вас ребра имеют некоторый неотрицательный вес.
Но причем не больше, чем к.
Что будем делать?
Это хорошая идея, и она практически приводит
к наиболее эффективному алгоритму, но там есть некоторые тонкости.
Самый тупой способ. Что тут можно сделать?
Как можно вот эту задачу свести к предыдущей?
Нет. Предыдущей в смысле, то, что мы минут назад
обсуждали, а не лекции назад.
Вот у меня есть вершины х и у, между ними ребро размера 3.
Что я могу сделать?
Да, давайте я просто возьму это ребро и разобью на
три фиксивных ребра.
Х штрих, х два штриха, у. Тут один, один, один.
Все-таки можно свести с виду датчик предыдущий,
в который у нас все ребра имеют длину либо 0, либо 1.
Ну и такой алгоритм будет работать за kg плюс v.
Ну почему kg плюс v? Потому что в худшем случае я каждое
ребро разобью на k-1 дополнительное ребро.
Точнее так. У меня максимум появится k-1
умножить на e дополнительных вершин.
Вот у меня появляются дополнительные вершины.
И плюс у меня появляются дополнительные ребра в размере
количества k-e штук.
Соответственно, если я сложу новое количество вершин
с новым количеством ребер, то я получу асимптотику k-e плюс v.
Понятно, да?
Что на самом деле может работать, но
коэффициент перед e-шкой не очень приятен.
Это может быть большим, но как бы и по памяти грустно,
и по времени грустно.
Есть второй способ, который вы, видимо, обсудите на семинаре,
который работает за kv плюс e.
Его обсудите, да, как я сказал, на семинаре.
Ну а пока с алгоритмами все, дальше с плюс плюсом.
