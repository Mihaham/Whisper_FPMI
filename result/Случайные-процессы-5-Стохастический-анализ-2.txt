Мы с вами продолжаем заниматься стахастическим анализом и изучать свойства непрерывности,
дифференцированности, интегрированности случайных процессов. Так как непрерывность,
дифференцированность, интегрированность касаются переменной t времени, а у нас же у процесса есть
еще одна переменная, омега-исход, то мы должны определить, каким образом мы понимаем предел,
который во всех этих понятиях непрерывность, дифференцированность, интегрированность
встречается. И в теории вероятностей существует множество различных видов пределов. Мы с вами
выбрали предел среднем квадратичном, он позволяет нам выработать критерии непрерывности,
дифференцированности, интегрированности очень удобные. В прошлый раз я напомнил вам
определение sk предела, sk сходимости, доказал некоторые из лемма вспомогательных, которые
мы используем для теориям ВЁЛ, определение sk непрерывности, дифференцированности, интегрированности.
Пояснение тут только одно будет, вот если вы посмотрите, то вот эти леммы, на которые мы опираемся,
они предполагают, что случайная последовательность и предел имеет второй момент, второй порядок. Это
принципиально, потому что мы там записываем неравенство к ошибке Буниковского, чтобы его
записать нам нужно, чтобы все это конечно было. Если что-то бесконечно, то мы этого не запишем,
и тогда там непонятно, что будет. Так что когда мы вводим определение sk непрерывности,
дифференцированности, интегрированности, и даже никогда мы это вводим, а когда мы критерии
записываем, то так как мы хотим опираться на эти леммы, мы должны тоже предполагать, что эти процессы,
ну по крайней мере в окрестности момента времени, который мы рассматриваем, что они хотя бы там
имеют второй порядок. Во всех точках, некоторые окрестности, вот точки t0, вокруг которой мы
рассматриваем непрерывность, дифференцированность, интегрируемость. Но есть вот такие процессы,
которые в суду имеют второй порядок. Для любого t такие процессы называются процессами второго
порядка. То есть x от t процесс второго порядка, если для любого t, ну где этот процесс определен,
может быть это вся числовая ось, может быть это только от 0 до плюс бесконечности, может быть это
какой-то отрезок. Ну в принципе, даже если t дискретно, то тоже можно определять процесс второго
порядка. Итак, это процесс второго порядка, если для любого t математическое ожидание x в квадрате
от t конечна. Ну оно может зависеть от t, но оно конечна для любого t. И примеры Виннеровский
процесс, Пуассоновский процесс это процессы второго порядка, потому что у них существуют
вторые моменты. Ну у нормальной случайной величины, у Пуассонской случайной величины
существуют моменты любого порядка, что в принципе это процессы любого порядка. Но, как минимум,
это процессы второго порядка и примеры. Ну вот, прошлый раз я напомню, что мы с вами выяснили,
что свойство sk непрерывности процесса связано со свойствами просто непрерывности к авариационной
функции. Вот хочешь ты понять твой процесс sk непрерывен или нет, вычисляй его к авариационную
функцию и смотри в точке t0, t0. Если эта функция непрерывна точке t0, t0, значит,
исходный процесс sk непрерывен в точке t0. Вот и все. Вот оказывается, что то же самое можно сказать
про дифференцированность и интегрируемость. И я привел теорему, в прошлый раз, критерии
непрерывности. Теперь давайте я сформулирую и докажу теорему критерий sk дифференцируемости.
Теорема. Итак, пусть процесс xat tst, это процесс второго порядка,
то есть у него всюду существует математическое ожидание квадрата xat, конечная.
Значит, xat sk дифференцируем в точке t0 тогда и только тогда,
когда существует конечный предел, вот такой, какой я сейчас напишу. Существует конечный предел
при епсилон, стремящемся к нулю, дельта, стремящемся к нулю, независимо друг от друга,
стремящемся к нулю. Значит, единицы разделить на епсилон дельта, коварационная функция процесса
x в точке t0 плюс епсилон запятая t0 плюс дельта, минус kx от t0 плюс епсилон запятая t0,
минус kx t0 запятая t0 плюс дельта и плюс kx t0 t0. Существует конечный вот такой предел.
k это коваряционная функция процесса x, то есть математическое ожидание x в точке t
умножить на x, то есть мат ожидания x от t умножить на x от s. Вот это математическое ожидание x в этой
точке умножить на x в этой точке и так далее. И вот это все оказывается равносильно в терминах
математического ожидания и корреляционной функции тому, что, тут фигурную скобку надо нарисовать,
что математическое ожидание процесса дифференцируемо в точке t0, ну и существует
конечный предел вот такого вида только не для коваряционной, а для корреляционной функции. То
есть существует конечный предел вот этот вот, но только для корреляционной функции в точке t0 t0.
Вот так. То есть помните, как у нас для непрерывности было, либо ты говоришь про непрерывность k, и это
равносильно непрерывностью двух вещей и мат ожидания и корреляционной функции. Здесь то же самое с
дифференцируемостью, либо ты в терминах только коваряционной функции говоришь, либо вот в терминах
мат ожиданий корреляционной функции. Вот будем сейчас доказывать эту теорему.
Значит точно так же, как мы делали это для непрерывности, мы сначала докажем вот это
следствие, затем мы докажем вот это следствие, и потом уже на основании вот этой равносильности
будем доказывать вот этот равносильность. Вот у нас скорее всего будет вот так. Вот это в эту
сторону легче всего показать, вот в эту, в обратную сторону тоже не сложно. Вот такой у нас будет план
доказательств. Итак, первый пункт. Мы предполагаем, что наш процесс второго порядка Sk дифференцируем
в точке t0. Пусть x от Sk дифференцируем в точке t0. Давайте покажем, что вот этот предел
существует и конечен. Для этого мы рассмотрим с вами, как я их там сейчас обозначаю, y я их
обозначаю, y епсион x от t0 плюс епсион минус x от t0 разделить на епсион. Введем вот такую
функцию епсион, можно посмотреть на это как на процесс с параметром епсион. Намножество
таких случайных ключин посмотрим. И соответственно, y дельта x от t0 плюс дельта минус x от t0 разделить
на дельта. Такие вот наши конечные разности. Давайте мы введем и вот что сделаем. Мы рассмотрим
математическое ожидание произведения y епсион на y дельта. Вот так рассмотрим. Ни кто не
запрещает. Давайте просто возьмем и посмотрим, что это такое будет. Значит, смотрите, когда мы
возьмем произведение этих двух y, у нас, во-первых, вынесется епсион дельта. Это вообще не случайная
вещь, да, выносим. И тут получается, что нам надо перемножить вот эти две скобки и взять
математическое ожидание. Когда мы скобки раскроем, у нас получится математическое ожидание этого
умножить на вот это. А это и есть кавариационная функция в точке t0 плюс епсион t0 плюс дельта.
Видите, что получается. Что происходит-то? kx t0 плюс епсион t0 плюс дельта. Вот. Ну и дальше вот надо
вот эти все перекрестные рассмотреть и последнюю. Вот тут так и получается. Минус kx, давайте вот это
t0 плюс епсион умножится вот на эту t0. Минус kx вот это t0 умножится на вот эту t0 плюс дельта. И вот эти
две перемножатся, но тут стоят минусы, значит будет плюс. Вот почему здесь плюс. t0 t0. Вот. Значит,
вот эта штука, которая тут написана, это есть не что иное, как математическое ожидание,
произведение конечных разностей. Вот. Такой у нее смысл. Да. Но что нам дано-то? Нам дано,
что вот этот процесс ск дифференцируем в точке t0. Значит, вот эта штука сходится в ск смысле
при епсион, стремящемся к нулю, к некоторой случайной величине с конечным вторым моментом,
которую мы условились обозначать x' t0. И мы условились ее также называть ск производной. Процесс
x. Мы предполагаем существование, значит существует. Сходится в ск смысле при дельто, стремящемся к нулю,
тоже как x' t0. Вот. Но раз эта штука сходится к чему-то, что имеет конечный второй момент,
и эта вещь сама тоже имеет конечный второй момент, потому что x имеет конечный второй момент всюду,
и это тоже сходится в ск смысле, то тогда и математическое ожидание произведения сходится
к математическому ожиданию произведения их пределов. Это лемма-1. Так. Вот эта штука
сходится при епсион, стремящемся к нулю, дельто, стремящемся к нулю. И неважно,
как между собой соотносятся эти епсионы, дельты. Они могут совершенно независимым образом стремиться
к нулю. К математическому ожиданию пределов x' на x'. А это квадрат. x' в квадрате это 0. Вот.
Но так как ск дифференцирована, в определении ск дифференцированности мы требуем,
чтобы предел был, имел конечный второй момент, вот он, этот наш конечный второй момент.
Так что получается, ну давайте так, по лемме 1, лемма 1 вот здесь используется. Так что, видите,
вот эта вещь, которая здесь написана под пределом, это математическое ожидание произведения
конечных разностей. А предел этой штуки, оказывается, это не просто какое-то число,
это второй момент производный. Вот. Это второй момент производный. Вот эта вещь,
которая тут написана. Все, мы с вами доказали в одну сторону, что если процесс ск дифференцируем,
значит вот этот предел существует и конечен, и мы даже знаем, чему он равен. Вот. Вот написано.
Так. Это было доказательство в одну сторону. Все понятно? Так. Теперь будем доказывать в
обратную сторону. Будем доказывать в обратную сторону. В обратную сторону, кстати, несложно.
Несложное доказательство, это я штуку стирать не буду, наверное, я умещу. Второе. Теперь пусть
вот этот предел, давайте мы его как-то обозначим, что ли, потому что я все время говорю,
этот предел, этот предел. Звездочка я его обозначу. Значит, пусть звездочка существует и конечна.
Но тогда обратите внимание, что тогда, если мы снова возьмем с вами у эпсилона и у дельта,
как угодно их будем стремить к нулю, то это будет означать, что математическое ожидание у эпсилон у
дельта сходится к некоторой константе, которая не зависит от того, как эпсилон дельта стремится к
нулю. То есть это сходится к некоторой константе, давайте мы ее обозначим буквой С. При эпсилон дельта,
стремяющимся к нулю, независимо от того, какие эпсилоны дельта взят. Вы на это можете посмотреть,
как на то, что нам дана как бы одна последовательность x0, t0, там плюс эпсион или плюс какая-то
убывающая к нулю последовательность, минус x0, делить на эту убывающую последовательность. И мы
можем брать из нее любые подпоследовательности, вот с дельтой мы взяли, которая как-то иначе может
к нулю. Мы можем брать любые подпоследовательности, это и общие последовательности, но математическое
ожидание произведения подпоследовательности сходится к одной и той же C. Вот так это можно
интерпретировать. Но на этом случае у нас есть Лемма 3, которая говорит о том, что, если у тебя
получается что для твоей последовательности, для любых ее подпоследовательности эта штука сходится
к некоей константе, то это означает, что существует,
следовательно, по лемме лемма 3, отсюда следует, что
существует предел, в sk смысле, sk предел, ну давайте
так, у и эпсилона, это неважно, неважно чего, они все равны,
sk пределы у и эпсилона, с конечным вторым моментом,
то есть, смотрите, что получается, но у нас же у и эпсилон это
не просто, а вы что, это вон что, х от t0 плюс эпсилон
минус х от t0 разделить на эпсилон, входится в sk смысле
при эпсилон стремящемся к нулю, какой-то случайной
величине, я обозначу это, причем ее математическое
ожидание, второй момент конечен, по лемме 3, о как,
лемма 3 у нас доказывалась легко, а лемма 3 опирается
на лему 2 про фундаментальные последовательности, что
она обязательно сходится, ну вот, так что мы здесь,
кстати, не указали, к чему именно она сходится, но
зато мы точно знаем, что это что-то, к чему сходится,
существует, вот, исходимость в sk смысле есть, ну вот,
так что мы показали с вами и обратное, обратное следствие,
то есть так легко получилось просто потому, что вот эта
конструкция имеет специальный вид, это не просто что-то,
это мотожидание произведения одного и того же, взятые
по разным последовательствам, при стремящемся к нулю,
эпсилона дельта, то есть просто потому, что вот эта
вещь имеет специальный вид, вот мы этим воспользовались,
здесь не просто что-то, а произведение как бы одинаковых
вещей, просто разные параметры представляются, по-разному
стремятся к нулю, вот, этим мы здесь существенно
пользуемся в этом пункте, все, значит, это мы считаем
теперь доказанным и известным, что sk дифференцированность
точки t0 равносильна существование конечного вот такого предела,
и теперь воспользуемся этим знанием и воспользуемся
вот этой равносильностью и докажем вот эту равносильность,
так, но это мне уже не пригодится, это я сотру, так, это мне тоже не пригодится,
пока вот так оставлю, если кто еще не успел списать, так, теперь третий пункт,
пусть выполнена вон та фигурная скобка, то есть пусть mxt дифференцируемо в t0 и существует
конечный предел звездочка для корреляционной функции процесса x.t0t0, пусть, почему тогда вот этот
предел существует, конечно, тривиально, потому что так же, как доказать это предыдущие теоремы,
мы вспоминаем, что kx ts равняется rx ts и плюс математическое ожидание x.t нам от ожидания x.s так,
что если мы теперь, значит, нам что дано, что для r и m выполняется вон то, почему для k выполняется,
давайте мы запишем этот предел для k, вместо k подставим вот это, тогда у нас выделится предел
звездочка для r, а он существует и конечен по этому предположению, и выделится вот этот предел для
вот этого произведения, и когда мы его запишем, то мы получим, что там будет предел произведения
конечных разностей для m, для этого множителя и для этого множителя, а эти пределы существуют,
потому что эта функция дифференцируема, то есть получится mx t0 плюс эпсион минус mx t0 разделить
на эпсион, умножить на mx t0 плюс дельта минус mx t0 делить на дельта, предел при
эпсион дельта тремящимся к нулю, вот, так что там будет двойной предел, предел по двум
переменном вернее, но здесь эти множители отделяются, пределы расщепляются, произлучается
произведение одного предела умножить на другой предел, все, так что ввиду того, что эта функция
дифференцируема, эти пределы существуют, вот этот страшный предел для этой функции существует,
по нашему предположению, а это является просто их суммой, значит, если пределы для этого существуют,
пределы для этого существуют, то они для суммы существуют, вот и все, все отсюда следует, что и для
kx ts звездочка существует и конечна, вот и все, все очень просто, единственный пункт, с которым нужно
немножко поковыряться, это четвертый, хотя тут тоже все просто, так, это я сотру,
так, четвертый пункт у нас про что, значит, пусть существует конечный предел звездочка для
кавариационной функ, так, мы хотим доказать, что тогда мат ожидания дифференцируема и существует
этот предел для rx, так, отсюда хотим перейти сюда, значит, так как существует конечный предел kx для
kx, то по уже доказанному вот здесь мы заключаем, что процесс x sk дифференцируем в точке t0, так,
следовательно, по доказанному x от t sk дифференцируем в точке t0, так, а это значит, что математическое
ожидание, давайте я так нашел y епсилон, то есть вот это вот, конечной разности, минус x штрих от t0 в квадрате,
что эта вещь сходится к нулю, при епсилон стремящимся к нулю, по определению sk сходимости,
конечная разность сходится к sk производной среднем квадратичном, то есть вот это нам дано,
и теперь мы попробуем вот из этого вывести в нту фигурную скобку, вот и все, ну давайте подставим,
ладно, вместо y епсилон сюда, что у нас там стоит, это есть x от t0 плюс, t0, да, везде, t0, плюс
епсилон минус x от t0 разделить на епсилон минус x штрих от t0, вот, в квадрате, так, теперь перейдем к
центрированным, помните, как мы это делали для непрерывности, когда доказывались, мы вычтем и
прибавим, то есть мы вычтем вот здесь мат ожидания в этой точке, прибавим мат ожидания в этой точке,
и сюда у нас пойдут соответствующие, так, что получается, математическое ожидание от x
центрированное t0 плюс епсилон минус x центрированное t0 разделить на епсилон минус x центрированное
штрих t0, и вот прибавим то, что мы вычли, а именно мат ожидания x точке t0 плюс епсилон,
почему прибавим, а, прибавим, да, прибавим, так, минус mx t0 разделить на епсилон, так, и минус,
ну, получается, минус математическое ожидание, мы вычитали x штриха, точке t0, вот, это все
эквивалентные вещи, мы вышли и добавили, так, хорошо, теперь раскрываем квадрат, но как, мы на это
смотрим, на это выражение, как на вот это, плюс вот это, и тогда мы получаем математическое ожидание
квадрата вот этой вещи, плюс мот ожидания удвоенного, это на вот это, плюс квадрат вот этой
вещи, это вообще постоянное, ну, давайте я, наверное, сотру сверху и допишу, потому что
писанина здесь много,
так, так, так, так, так, так, что получается, равно математическое ожидание x
t0 плюс епсилон минус x, значит, t0 разделить на епсилон минус x штрих t0 в квадрате, дальше,
удвоенное мот ожидания вот этого на вот это, это вообще констант, ее можно вынести, останется
только мот ожидания вот этой вещи, но тут центрированные величины, мот ожидания равно нулю,
все, удвоенного произведения здесь на самом деле нет, плюс мот ожидания квадрата вот этой вещь,
опять это константа, мот ожидания можно убрать, плюс mx t0 плюс епсилон минус mx t0 разделить на
епсилон минус мот ожидания x штрих t0, так, ну и вот, и что нам известно, чтобы это не было,
это сходится к нулю при епсилон стремящемся к нулю, это мы знаем, сходится к нулю при стремящемся к нулю,
но здесь стоит сумма не отрицательных величин, их сумма стремится к нулю, значит каждая по
отдельности стремится к нулю, для этой скобки это значит, что существует пределы этой вещи,
и он, кстати, равен вот этому, кстати, обратите внимание, получается, мы тут параллельно с вами
получили, что производная мот ожидания равна мот ожиданию ск производной, так, походим к делу,
получили, видите, в любом случае, как бы там ни было, пределы этой вещи существует, конечные равны
вот этой вещи, вот, так что вот это сходится к нулю, и, следовательно, существует производная mx t в
точке t0, ну и вот эта вещь сходится к нулю при епсилон стремящихся к нулю, но по определению это
означает, что эксцентрированный t ск дифференцируем точки t0, а это, по доказанным 1, 2, равносильно тому,
что существует конечный предел звездочка для кавариационной функции эксцентрированной,
но кавариационная функция эксцентрированного это корреляционная функция просто x,
то есть существует конечный предел для r от x, вот такая теорема,
аналогичная, аналогичная ск неперерывности критерию, вот мы и доказали,
так теперь я хочу несколько комментариев дать по поводу вот этой штуки вот этого предела значит
если внимательно посмотреть на то, что здесь записано, то можно догадаться, что это выражение
напоминает вторую производную смешанную по двум переменам, по одной и по другой,
видите мы здесь сделали плюс s, здесь сделали плюс дельта, потом вычли, вот то есть это как
будто напоминает нам производную смешанную, значит предел вот этот звездочка, предел звездочка
он называется обобщенный второй производной или производной второго порядка,
ну от функции, от которой берется, ну в данном случае кавариационный или корреляционный обобщенная
fertilize the second order or sealed the second prroizvodnoyya?
значит если она существует то есть вот этот предел существует и конечен то численно
численно обобщ μно 2 производная совпадает с обычной привычной нам
смешанные производные 2-го порядка если существует и конечен то численно совпадает
но обобщенная вторая производная и смешанная производная вообще говоря не совпадают потому что
смешанная производная это когда ты сначала взял производную по одному аргументу а потом
производную по другому аргументу то есть сначала один предел вычислил потом другой
предел вычислил так что как бы получается повторный предел если это расписать в этом
же пределе предел не повторный это предел по двум переменным одновременно и путь их к нулю
может быть самой заковыристой вот так что обобщенная производная отличается от смешанной
производной как предел по двум переменном отличается от повторного предела вам по
мотональзу должны были контр примера какие-то приводить когда вот эти пределы неравны вот так
вот эта вещь более сильная если она существует то смешанная подобно существует и численно они
естественно должны совпадать вот так что если ты уверен что этот предел существует то тогда
ну ты это как-то доказал показал выяснил то тогда чтобы его вычислить ты можешь вот взять
смешанную производную сначала по одной потом другой вот и посчитать в точку и 0 то 0 вот
но если у тебя смешанная производная существует вот рассчитанное сначала по одной там увидеть
отсюда не следует что обобщенные существует вот ну когда можно сказать что обобщенные
вторая производная существует. Есть такое
достаточное условие, что для
существования обобщенной второй
производной достаточно непрерывность одной
из смешанных производных ds dt или dt ds.
Вот если там скажем ds dt непрерывная
функция, это смешанная производная
непрерывная, то тогда обобщенная вторая
производная существует и численно вот
они совпадают. Вот есть такое
достаточное условие. Но честно говоря, по
моему опыту на практике эта теорема
мне вот ни разу не пригодилась, потому
что если я хочу выяснить, что существует
эта обобщенная вторая производная, я
просто пишу вот этот предел, подставляю
туда конкретику, свою функцию kx и смотрю
на нее. И вы знаете, обычно понятно,
существует предел или нет. Ну у вас не
будет в задании или где-то там задач
слишком сложных, где вы бы там закопались
и думали, там существует предел или нет. То
есть обычно это выясняется тривиально,
существование вот этого предела. Ничего
страшного нет. Вот имейте в виду, вот такое
вот отличие между этими, между этими
вещами. Вот. Тем не менее, кстати, существуют
учебники, где ошибочно называют вот эту
вещь смешанной производной и понимают ее,
как мы понимаем вот эту. То есть это явная
ошибка, так нельзя. Вот. Причем много таких
учебников есть, которые путают эти виды
производных. Вот. Хотя, кстати говоря,
конкретно для этих производных
контрпремеры я не знаю. Вот. Но я имею в виду,
что можно ли предъявить такую
кавариационную функцию, чтобы вот это
не существовало, чтобы вот это не существовало,
а это существовало. Вот, кстати, подумайте о
таком контрпремере. Но это надо посмотреть,
вот, контрпремеры в анализе, какие там вот
повторные пределы, двойные пределы, вот
как там получаются такие вот противоречия.
Примера такого не видел, но тем не менее,
относиться к этому нужно осторожно. Вот. Их
нужно различать. Так. Хорошо. Это что касается
дифференцируемости. Что насчет известных нам
процессов, вот Пуассоновский и Винеровский,
являются ли они СК-дифференцируемыми?
Значит, ну, смотрите, вот, если мы рассмотрим,
например, Винеровский процесс, то его
математическое ожидание равно нулю. И эта функция
дифференцируемая. Так что вот это свойство
выполнено. Но ее корреляционная функция, это
минимум ТС. Так вот, можно доказать, что вот этот
предел для нее не существует. Но я надеюсь, что вы это
выясните на семинарах. Не буду я это делать на
лекции, вы выясните на семинарах. И доказывается
это не попыткой вычислить смешанную производную,
ни в коем случае, а именно попыткой рассмотреть вот
этот предел. Если вы его рассмотрите, то можно
выбрать такие эпсионы дельты, такой путь к нулю в пространстве
эпсион дельт, что этот предел будет равен бесконечности.
Он не будет конечной. Все. Значит, для этой функции
в этом смысле не дифференцируемо. Нигде. Вот так. Вот такие
дела. Так что ВАТ, ну у пулассонского процесса
просто лямбда минимум. КАТ не СК дифференцируемо.
Нигде. Ни в какой точке. Так. Ну вот. Такие дела. Так,
ну хорошо. Так, ну что, тогда идем дальше. Мы с вами поговорили
про дифференцируемость. Теперь что насчет интегрируемости.
Ну для интегрируемости я вам только сформулирую
этот критерий. Пойдет без доказательства. Но я думаю,
что вы уже поняли все равно, как его, как такое критерий
можно было бы доказать. Ну все абсолютно аналогично.
Я в общем повторил одну и ту же процедуру. С одним
и тем же планом. Видите, и для непрерывности, для дифференцируемости.
И для интегрируемости все абсолютно так же.
Итак. Значит, это был критерий СК дифференцируемости.
Это будет у нас критерий СК интегрируемости по риману.
По риману вам можно интеграл по-разному водить. Вот по риману.
Это значит рим со звездочкой. Доказывать я и не буду.
Так. Ну давайте я сформулирую и пойдем на перерыв.
Значит, пусть процесс, ну мы его определим на отрезке.
Вот. Пусть процесс это процесс второго порядка.
Нам это нужно просто для того, чтобы вот этими леммами
пользоваться и чтобы доказывать то, что нам нужно.
Пусть это процесс второго порядка.
Так. Х от Т СК интегрируем по риману на отрезке АВ
тогда и только тогда, когда существует конечный интеграл римана.
Значит, интеграл от A до B. Интеграл от A до B. Двойной интеграл.
K X T S DT D S.
Вот в самом обычном смысле понимаемый интеграл.
По такому квадрату. По прямоугольнику.
Или по квадрату.
Вот. И это равносильно фигурной скобке.
Что существует конечный интеграл от A до B.
Математическое ожидание.
И существует конечный интеграл от A до B.
Интеграл от A до B.
Ой, не K уже. Уже R.
R X DT D S.
Вот и все.
Хорошо.
Напомню из математического анализа.
Следует, что если какая-то функция дифференцируема в точке,
то она не прерывна в этой точке.
Вот как это распространяется на процессы ?
Так как свойство непрерывности, дифференцируемости
и интегрируемости процессов
сводятся согласно этим критериям
к непрерывности, дифференцируемости, интегрируемости
обычных функций to это значит, что saved activities
тоже, так как она справедлива для обычных функций,
она переносится и на случайные процессы, вот, если ты хочешь показать это, допустим, что из дифференцированной следует непрерывность для процесса,
значит, ты еще говоришь, у тебя дифференцируемо, дифференцируем процесс, значит, дифференцируемо там, скажем, от ожидания,
раз от ожидания дифференцируемо, значит, оно непрерывно, вот, и то же самое для корреляционной функции, получаешь эту фигурную скобку, потом по критерию возвращаешься обратно,
вот, так что, если процесс, если процесс ск дифференцируем, следовательно, он ск непрерывен, так, если процесс ск непрерывен,
следовательно, он, ну, на, во всех точках отрезка, или на отрезке будем говорить, он на АВ ск интегрируем по риману, вот, мы с вами выяснили, что Винеровский процесс,
Пулассоновский процесс, ск непрерывны всюду, вот, это значит, что Винеровский процесс и Пулассоновский процесс ск интегрируемы по риману, ну, в любом отрезке, так, вот такие прямые следствия.
Хорошо, теперь вот еще о чем хотелось бы поговорить, вот мы говорим, ск производная, а как ее считать, вот давайте рассмотрим такой игрушечный пример,
хт равно кси на синус т, пусть кси имеет нормальное распределение с параметрами 0.1, ну, синус т, детерминированная функция, вот такой процесс идет,
и спрашивается, чему равна его ск производная, ну, во-первых, существует ли она и чему она равна, ты сразу хочешь написать кси ко синус т, а почему, что такое кси ко синус т,
действительно ли это х' от t, вот мы сейчас об этом поговорим, ну, во-первых, давайте поймем, существует ли ск производная, математическое ожидание кс от t от ожидания равно 0, да, потому что от ожидания кси равно 0, это просто детерминированная функция, а эта штука, она дифференцируема, хорошо, теперь корреляционная функция,
корреляционную функцию найдем, ну, это получается мат ожидания х от t на х от s, минус произведение мат ожидания, но мат ожидания равны 0, мы их не пишем, и это получается просто синус т, синус с, на мат ожидания кси в квадрате, а это единица, умножить на 1, вот.
Ну, предел, тот страшный звездочка, для этой функции существует, это можно убедиться непосредственно, подставив все туда, и там будут разные синусы, в пределе дает косинус, либо, можно, кстати, по той теореме, по достаточному условию, у этой штуки существуют непрерывные смешанные производные, в обычном смысле, понимаемые, значит, существует обобщенное производное, вот, можно так, например, еще говорить, в любом случае, предел звездочка для него существует, и следовательно,
по критерию х от t ск дифференцируем в любой точке, в любой точке он ск дифференцируем, но чему равна ск производная, ведь ни одна теорема нам пока еще не говорила о том, чему она равна, как мы можем вычислять эту ск производную, из предела, то есть мы должны что, написать конечную разность и посмотреть, куда она ск сходится, ну, в принципе, наверное, да,
но на самом деле, хочется сказать, что она равна кси косинус t, действительно ли это так, что такое кси косинус t, смотрите, вот, процесс, это функция двух переменных, х омега t равняется кси от омега на синус t, что такое кси косинус t, это когда мы зафиксировали исход и взяли производную по времени, правильно, давайте мы обозначим это x точкой,
то есть это частная производная по t, вот этой функции, и это есть кси от омега на косинус t, кси косинус t это частная производная по времени при фиксированном исходе,
видите, какое отношение к исходу мы здесь имеем, мы исход фиксируем и по t берем производную, но в ск смысле, там отношение к исходу другое, там математическое ожидание квадрат разности стремится к 0,
вот, поэтому, вообще говоря, это не одно и то же, но, что вот это такое, когда мы фиксируем исход, а берем предел по другой переменной, в почти наверное сходимости,
что такое, что, скажем, кси n сходится кси почти наверное при стремящемся бесконечности, это по определению, по определению это означает, что мера тех омег, для которых имеет место сходимость числовой функции, равна единице,
то есть, ты зафиксировал омегу, посмотрел, сходится ли, допустим, сходится, окей, омега подошла, взял другую омегу, зафиксировал ее, посмотрел на сходимость числовую, сходится, сходится, все, в копилку ты омегу положил, для какой-то омеги не сошлось, ладно, в другую копилку положили, прошлись по всем омегам, вот, если мера множества омег, для которых сошлось, равна единице, значит, это почти наверное сходимость,
здесь, когда мы фиксируем омегу, берем производную по t, это почти наверное производная, почти наверное сходимость, если существует частная производная по времени, для почти всех омег, то тогда эта штука называется почти наверное производной, кси cos t, это почти наверное производная,
а нам нужно, например, найти эска, а производную, а как они между собой с относятся, для этого я предлагаю вспомнить диаграмму сходимости, то, чего влечет, значит, смотрите, есть эска сходимость, есть почти наверное сходимость, есть по вероятности сходимость и по распределению сходимости,
если последовательность эсха сходится к чему-то, то она и по вероятности сходится к тому же самому, вот это важно, не просто она тоже сходится, а к тому же самому, к чему этот сошелся, если почти наверное сходится, значит, и по вероятности сходится к тому же самому, эти, вообще говоря, не связаны, они связаны только через дополнительные условия, а так, вообще говоря, нет, если по вероятности сходится, значит, по распределению сходится,
вот такая диаграмма, и теперь смотрите, что получается, если эска производная, если эска производная существует, значит, конечная разность стремится к чему-то, в эска смысле,
если почти наверное производная существует, а ее мы вычисляем вот так, просто буквально вот так, через частную производную, если почти наверное производная существует, то тогда по вероятности существует, к тому же самому, здесь к тому же самому, мы здесь к тому же самому, но сходимость по вероятности, если она есть, то этот предел он единственный,
значит, если и так, и этот предел существует, и этот предел существует, они обязаны совпадать,
вот, значит, если эска производная существует, предел конечных разностей существует, и почти наверное предел конечных разностей существует, значит, они обязаны совпадать, вот вам теорема, чисто из этой диаграммы следует,
и так, если процесс эска дифференцируем, и почти наверное дифференцируем, то эти производные эска и пн совпадают, и поэтому эска производная мы можем считать просто через частную производную, вот и все,
вот такая теорема, но я как бы на словах доказал, что если существует эска производная xt в t0, и почти наверное производная,
когда это обычная частная производная, которая существует для почти всех омек, производная xt в t0, то они совпадают,
то они совпадают, так что x' равно x точкой, вот в этом случае, так что для этого процесса ответ, да, действительно, x' в точке t0, скажем, равняется x точкой,
точке t0, потому что эска производная тут не просто почти всю, она просто всюду существует, а сейчас, только тут, то они совпадают почти наверное,
давайте так напишем аккуратно, почти наверное, то есть в отдельных омегах они могут не совпадать, это почти наверное равенство, то есть вероятность того, что это равно этому, равна единице,
вот, почти наверное равно вот этому, равняется psi cos t, вот это эска производная,
ну так, точно так же, из точно такой же диаграммы другая теорема, что если существует эска интеграл x at на ab,
и существует почти наверное интеграл x at, то есть когда вы зафиксировали омегу и просто по t вычислили этот интеграл,
допустим, интеграл x sin t, почти наверное интеграл, это получается минус x cos t, вот, то они совпадают,
это просто следствие вот этой диаграммы, вот этих сходимости не более того,
вот так, что у вас есть рабочий инструмент для вычисления этих эска производных и эска интегралов,
то есть это не просто какие-то абстрактные вещи, это вполне себе понятные вещи,
но если эска сходимости есть, а почти наверное нет, ну, тут нельзя сказать, что это такое,
это, наверное, надо уже выписывать этот предел и пытаться подобрать такую вот случайную величину,
это, которая в эска смысле сходит, то есть если pn сходимости нет, мы этими теоремами воспользоваться не можем,
но это уже тогда смотрим по ситуации, что это такое,
так, про это мы тоже поговорили, ну, к слову, раз мы перешли на эту диаграмму,
то давайте поговорим вообще и о других видах сходимости,
вот сейчас мы немножко затронули, наверное, почти наверно о сходимости,
другие виды сходимости, значит, для других видов сходимости теорем у нас нет,
но что у нас есть, у нас есть теоремы для эска сходимости,
и вот эта диаграмма, в принципе, это по большому счету достаточно,
потому что, ну, смотри, вот, допустим, процесс эска непрерывен в точке t0,
ты можешь это проверить, воспользовавшись критерием,
допустим, он эска непрерывен в точке t0,
но из этой диаграммы следует, что тогда он и по вероятности непрерывен в точке t0,
и по распределению непрерывен в точке t0,
вот это отсюда, из этой ветки ты никак не выяснишь,
эта ветка тебе только подскажет, к чему смотреть почти наверная сходимость,
потому что если она есть, она обязана быть к тому же, к чему вот это,
и если это есть, то и к этому тоже, вот.
Так что, сначала мы выясняем вот эту ветку, здесь есть критерии,
если это выполнено, значит, все автоматические выполнены,
вот, и если это выполнено, тогда эта сходимость, если она есть,
она должна быть там же сам, вот такая логика здесь может быть,
ну а ее уже смотреть приходится вручную специально здесь у нас уже какой-то вот
такой легкой теоремы нет чтобы это проверить но только если посмотреть на
какие-нибудь теоремы когда стрелочка есть отсюда сюда при определенных
условиях только если так так вообще говоря нет ничего и так если sk непрерывен
значит ты непрерывен дэн terrible от этом проверяем отдельно если с к
дифференцируем значит там п дифференцируем дэ дифференцируем это
проверяем отдельно если с к интегрируем значит п интегрируем
интегрируем это проверяется отдельно и если SK не непрерывен скажем про эти
ничего сказать нельзя здесь может не быть сходимости здесь
сходимость может быть. Значит, если это не выполнено по критериям, ну блин, проверяешь отдельно, p, d.
Если это не выполнено, это проверяешь.
Но вообще, если, смотрите, лайфхак, есть у тебя есть подозрение, что сходимости нет, проверяешь сразу вот это.
Если сходимости в d смысле нет, ни в каком смысле больше сходимости нет, и в голову ломать не надо. Вот у вас,
например, в задании есть задача
исследовать виноровский процесс на
дифференцировомон y во всех смыслах.
Во всех смыслах, вот этих вот, всех четырех смыслах.
И там, оказывается, что, мы выяснили, что вот этой сходимости нет, но оказывается, что
d дифференцировомости нет виноровского процесса, и это
элементарно показывается, что в этом смысле дифференцировомости нет, значит, ни в каком другом смысле дифференцировомости нет.
develops this notebook.
Вот это показывается элементарно.
Тут сложнее, тут уже думать надо, а это показывается
элементарно.
Видите, оно мгновенно влечет и всё остальное, если это
не выполнено, всё остальное тоже не выполнено.
Для поас restroom процесса скажем exc-деференсfor Fare
там нет но вот у evaluate Ф- geb atualize
есть Rod lift для по-afätta supplemental процесс это Kurdish
проверить не сложно вот это это есть и оно мгновенно
вот это. Вот это можно проверять отдельно. Но можно также доказать, начинать сразу отсюда и
показать, что по основament this process, он почти наверно дифференцируем. Так что вот это все
автоматически выполнено. Значит это мы проверяем по критерию не будет выполнена, а вот этот мы
проверяем вручную. И это будет выполнено, дифференцируемость. тогда в этом смысле
дифференцируемость тоже выполнена. И здесь не нужно тратить время на доказательства для них. Вот,
Поясню про дифференцированность полосоновского процесса. Почему так? Ведь вроде бы у
полосоновского процесса траектории разрывные. Почему тогда я говорю, что он почти наверно дифференцируем?
Да, совершенно верно. Потому что, смотрите, что такое почти наверная дифференцированность в
точке t0? Это значит, что мы точку t0 взяли и зафиксировали. Это важно. Точка t0 фиксирована.
И мы теперь смотрим, сколько траекторий в этой точке непрерывно или дифференцируемо. Ведь есть
вот такая зависимость. Здесь повезло, а здесь мы не попали на разрыв. Поэтому для этой траектории
в этой точке мы и непрерывно дифференцируемы. Для другой траектории, скажем, вот так вот которое
идет. Здесь тоже мы попали сюда. И здесь траектория тоже непрерывно дифференцируемы
Так вот, для того, чтобы у пуассоновского процесса получилось так, что здесь имеется разрыв,
нужно, чтобы tau, помните нашу tau n, момент времени, когда происходит скачок,
чтобы он попал в точности на эту t0. То есть, чтобы существовал n, что tau n равняется t0.
Ну а мы, кстати, уже показывали это, что мера такого события равна нулю. Так что, в принципе,
такая ситуация возможна, но ее мера нулевая. Вот и получается, что почти наверное процесс
непрерывно в точке t0, хотя его траектории разрывные. Вот так вот.
Вот все это говорит о том, что тут, когда вы говорите о непрерывности дифференцированности
еще в разных смыслах, тут надо быть очень аккуратным. Видите, в разных смыслах еще
понимается. И вот когда мы говорим, что траектории пуассоновского процесса разрывные, мы имеем в
виду, что существуют такие моменты времени, когда происходит разрыв. И если мы зададимся,
например, таким вопросом, будут ли траектории пуассоновского процесса непрерывными, скажем,
на каком-нибудь конечном отрезке, то тогда мы выясним, что лишь некоторой вероятностью траектории
пуассоновского процесса будут непрерывными на вот этом отрезке. То есть тогда и только тогда,
когда у тебя траектория первая скачка начинает после для этой картинки. То есть тогда и только
тогда, когда у тебя tau1 больше, чем t0. Тогда на отрезке 0, t0 у тебя пуассовский процесс во всех
точках непрерывный. Вот. Так что, видите, тут надо отличать. Мы зафиксировали t0 и варьируем
всевозможные траектории и ловим из них те, которые непрерывны t0. И собираем их в одну кучу и смотрим
меру этого множества. Это одно. А другое дело, когда ты выделяешь целый отрезок,
какое-то континуальное множество точек, и ловишь траектории, которые непрерывны
всюду внутри этого отрезка. Это другое. Надо вот такие моменты различать. Вот. Так. И последнее,
чтобы завершить со стох-анализом, вот таким вот теоретическим, последнее, что я здесь скажу,
это про непрерывность траекторий Винеровского процесса. То же с плацонским процентом тут понятно,
да? Вероятно, с того, что существует n, что tau1 равняется t0, а t0 равна 0, это тривиально
показывается, поэтому почти, наверное, непрерывно. А что насчет Винеровского процесса? Ведь у
Винеровского процесса траектории вообще не понятно, что такое. И как там понимать непрерывность,
дифференцированность? Вот давайте проверим. Посмотрим. Ну как сказать, вот видите, например,
здесь вроде как разрывы есть, тем не менее, почти, наверное, он непрерывен в каждой точке. Поэтому я
говорю, тут всё равно как сказать, вот ты говоришь непрерывность траекторий, а что ты имеешь под этим
в виду? Вот. Это еще недостаточно, потому что либо ты имеешь в виду в определенной точке, фиксированной,
вот это почти, наверное, непрерывность, либо ты имеешь в виду на отрезке непрерывность. Она не
относится к этим, это другое. Ну это тоже почти, наверное, но не в точке, а на отрезке. Понятно? И
надо еще отличать, допустим плацонский процесс, он почти, наверное, непрерывен в любой точке, но нельзя
сказать, что он почти, наверное, непрерывен на любом отрезке. Понял? Вот. В любой точке, но не на
любом отрезке. Потому что в любой точке ты точку зафиксировал и не двигаешь ее. А отрезок – это
консинюальное множество точек, там это другие утверждения, другие события. Так вот, переходим к
Винерскому процессу. Значит, он Sk не, он D не дифференцируем, значит, не дифференцируем
в никаком этом смысле. Он Sk не прерывен, P не прерывен, D не прерывен. Проверяем. Почти, наверное,
непрерывность Винерского процесса. Значит, у нас на первой лекции была теорема Колмогорова о
существовании непрерывной модификации, которая говорит о том, что если нам дан процесс, который
задан на отрезке, ну и мы можем, например, рассмотреть Винерский процесс на каком-нибудь очень
большом отрезке, ноль, Т большое, какой-нибудь очень большой. Вот дан процесс. И если существует
альфа больше нуля, бета больше нуля, Т меньше бесконечности такие, что математическое ожидание
модуля xT, T плюс h, минус xA, T в степени альфа меньше либо равен C, модуль h, 1 плюс бета,
для любых T и T плюс h из отрезка AB, то тогда у процесса кси существует непрерывная модификация.
Давайте мы это проверим для Винерского процесса. Значит, если мы сюда поставим Винерский процесс,
в нашем случае это вот так будет, то по третьему свойству Винерского процесса вот эта случайная
величина имеет нормальное распределение с параметрами 0h. И здесь вычисляется
математическое ожидание модуля такой штуки. Пусть альфа равно 4, тогда модуль мы можем
упустить и оставить просто скобки, и у нас получается математическое ожидание четвертой
степени вот такой случайной величины. Если вы вспомните, то мы такую штуку уже вычисляли,
когда у нас была теория Мовика. И получается, что математическое ожидание вот такой штуки,
но я условно напишу N0h в степени 4, это есть 3 дисперсии в квадрате, 3h2. Мы вычисляли это,
когда была теория Мовика, мы пример такой разбирали с нормальной случайной величины.
Вот специально для этого мы такой пример и тогда и разобрали. Ну и все, тогда у нас получается,
что это меньше либо равно, чем 3 модуль h1 плюс 1. Вот твоя c, вот твоя beta. Beta больше 0,
вот твоя alpha, больше 0. Все, тривиально. Значит, по теории Мойкова-Магорова,
Винеровский процесс имеет непрерывную модификацию. Что это значит для нас? Сейчас напишу.
Значит, VAT по теории Мойкова-Магорова имеет непрерывную модификацию. Вот,
это означает, что на том же самом вероятностном пространстве, на котором он задал свои конкретные
задачи, существует его непрерывная модификация. То есть другой процесс, но эквивалентный ему
стахастически и следовательно с теми же самыми конечномерными распределениями. Вот, а отсюда в
свою очередь следует, что Винеровский процесс можно определить на другом вероятностном
пространстве, не исходном, на котором у тебя был, и на котором существует непрерывная модификация,
а на другом вероятностном пространстве, на котором пространством исходов является множество
непрерывных на отрезке AB функций. То есть следовательно, VAT можно определить, сохранив его
имейство конечномерных распределений, можно определить на вероятностном пространстве,
где Омега, то есть пространство исходов или пространство элементарных событий,
оно еще называется, это есть множество непрерывных функций на отрезке AB. Мы тут произвольный
отрезок рассмотрели на отрезке AB, для произвольного отрезка AB. Вот, а это означает, что на этом
вероятностном пространстве все траектории Винеровского процесса непрерывные. Вот так. Все,
уже не даже почти все, а именно все, вот на этом пространстве все траектории Винеровского процесса
непрерывные. Ну, это вот и отвечает на вот этот вопрос. Является ли Винеровский процесс почти
наверно непрерывным? Да, потому что существует такое вероятностное пространство, где его можно
определить таким образом. Это следствие теоремы Колмогорова. Вот так вот. Раз он почти наверно
непрерывен, во всех других смыслах тоже непрерывен. В СК смысле мы проверяем по критерию. Там тоже
получается СК непрерывность. Так что Винеровский процесс непрерывен во всех смыслах. Не
дифференцируем ни в каком смысле. Интегрируем во всех смыслах. Пуассоновский процесс непрерывен
во всех смыслах. Интегрируем во всех смыслах. И не дифференцируем в СК смысле, но дифференцируем
во всех остальных смыслах. Вот так. Вот получается вот так. Разобрались.
Эти мы разобрались. Ну хорошо, об этом мы поговорили.
Сколько у нас там времени остается? 12 минут, да? Так, сейчас проверю. Тут у меня все.
Ну ладно, чуть-чуть времени есть. Давайте я уже доведу до конца.
Значит, эту мы ветку, линию замкнули. Мы завершили. Теперь будем готовиться к следующим темам. И для
этого я введу еще одно помогательное определение. У нас был интеграл по риману. Нам еще пригодится
СК интеграл римана сельтьеса. Определение вот такое будет. Значит, пусть процесс
xt второго порядка определен на отрезке AB. Точно так же, как для римана, интеграла римана, мы построим
разбиение отрезка AB. А равное t0, равное t1, меньше чем t1, меньше и так далее, меньше чем tn,
равное b. Вот для произвольного n, построим произвольное разбиение. Выберем точки tau тоже
произвольным образом. И тогда если при n, стремящемся к бесконечности, ну и мелкости разбиения,
стремящемся к 0, то есть максимум ti-ti-1, стремящемся к 0 для любых i. Если имеет
место СК-сходимость, то есть вот такие частичные суммы для некоторой функции непрерывны g. Я сейчас
ее веду. g от tau и t на скобку x от ti-x от ti-1. Сумма берется от 1 до n. Если вот эта штука
СК-сходится вот для непрерывной, ну какой-то фиксированной непрерывной gt, то как бы предел,
этот ск предел, а сейчас, если он сходится для непрерывной gt, и ск предел не зависит от выбора
разбивения и tau и t, то ск предел этой штуки называется ск интегралом римана илтьеса
от функции g от t по процессу x от t. Интеграл римана илтьеса от функции g по процессу x. В общем-то,
конструкция такая же, как для обычного интеграла римана илтьеса, но только у нас сходимость в СК-смысле
здесь понимается, и вот эта функция непрерывная, мы предполагаем. Значит, для этого вида интеграла
тоже существует критерий, вот чем хорошая СК-сходимость, тоже существует критерий
сходимости, критерий существовала, а не интеграла. Тоже существует критерий, вот такая теорема тоже у вас
пойдет без доказательства. А сейчас, вот этот вот интеграл мы будем обозначать вот так, интеграл
от a до b g от t dx от t. Это символ, это как бы цельный символ, который обозначает СК-предел вот этой
штуки. Ну и теорема такая, что СК интеграл римана илтьеса от функции g от t по процессу x от t, вот этот
вот он существует тогда и только тогда, когда, ну тоже можно выразить в терминах, значит,
функции, значит, интеграл от a до b, интеграл от a до b, g от t, g от s, d2k от ts, сейчас все поясню,
существует и конечен. Существует конечный интеграл такого вида. Здесь хитро, это двукратный
интеграл римана илтьеса. Двукратный интеграл римана илтьеса. Обычный низкий предел, здесь
обычные все функции. Значит, он понимается по определению, это предел частичных сумм вот таких.
Значит, это получается сумма, сумма g tau it g на сигму, скажем, g, и здесь у нас kx, значит,
t и, сейчас, как там было-то, t и плюс один s g плюс один, минус kx t и s g плюс один,
минус kx t и плюс один s g плюс kx t и s g, вот где tau i это точка с t и t и минус один,
а нет, извините, t получается i плюс один до i, здесь вот так. Значит, сигма g это точка из t,
из s g плюс один, нет, подожди, что я не так пишу? Сейчас, кто больше t? Кто справа, да? Так,
сейчас, сейчас, сейчас, от i до i плюс один, а здесь от g до g плюс один. Вот, а t и s gt,
это произвольное разбиение, отрезка ab, вот, то есть, вот такая вот двойная частичная сумма,
но здесь два разбиения, t-разбиение, s-разбиение, и предел частичных сумм берется при мелкости
этих разбиений, стремящимся к нулю независимо друг от друга, вот. Ну, нам, на самом деле,
эта конструкция, она так-то не пригодится, я ее здесь привожу просто для симметрии,
чтобы вы понимали, что и существование sk интеграла Римана-Сельтееса тоже, для него
тоже есть критерий, вот, тоже описывается некоторым критериям, но вот, правда, такого
вида очень сложного, но, тем не менее, все, в конце концов, сходит сюда, и, в общем-то,
доказывается, эта теорема абсолютно аналогична, как и теоремы, вот, но просто вот, вот такое более
сложное выражение имеет. Это интеграл Римана-Сельтееса, вот он нам потом дальше пригодится. Так,
ну все, значит, на этом я лекцию свою завершаю и делаю объявление насчет того, что нас ждет в
следующий раз. Значит, на следующий вторник, 8 марта, и лекций не будет, значит, как бы вести
лекцию какую-то дополнительную я тоже не буду, вот, но это не значит, что вы не должны ничего делать,
вы должны будете к, получается, 15 марта посмотреть в записи лекцию номер 5, вот,
лекцию 5. Моих прошлогодних записей, ну, это вы найдете на Notion, ссылку на плейлист
видеолекций 21 года по случайным процессам. Лекция номер 5, которая немножко, ну, там,
по-моему, у меня снова дается определение интеграла Римана-Сельтееса, потом идут некоторые
полезные формулы, а потом идет эргоодичность и стационарность. То есть это про полезные формулы,
значит, эргоодичность, стационарность. Это, пожалуйста, посмотрите, и когда вы вернетесь сюда 15
числа, я буду продолжать, я буду уже, как бы, на основе вот этого материала, который у меня там
рассказан, дальше уже рассказывать и пойду дальше. Понятно вам? Вот, это важно, потому что там
вводится понятие. Но это не самая прям сложная лекция, я вам скажу. То есть тут все, там очень
понятные определения и теоремы там, я тоже доказываю, вполне себе. Я думаю, что вы разберетесь. Это, как
бы, вместо того, чтобы мы с вами дополнительно собирались. Посмотрите вот эту лекцию. У меня все.
