тогда мы, наверное, начинаем. Давайте начнем с текущих задач, с того положения в курсе,
где мы оказались. Я сначала, пока мы не разошлись, там, к концу третьей пары,
прорекламирую важное. Вот у нас сейчас май, и где-то в конце мая наша лекция закончится,
наша встреча закончится, поэтому мне хочется, чтобы у вас останется еще некоторое время,
чтобы задачу дорешать. Но мне кажется, что было бы разумно, если бы за май мы от меня получили
максимальную пользу, извлекли которую только возможную. А для этого нам нужно успеть что-то
решить и обсудить. Ну, скажем, я вот сегодня лекцию читаю одну, а не другую, потому что мне хочется,
чтобы мы дорешали, скажем, мы прорешали задачу про канал. Ну и вообще, вот данный момент курса у
нас есть. Ну, ради вот этого месяца и ради текущих задач, в общем-то, курс затевался,
потому что это была некоторая подготовительная работа. А сейчас у нас есть три, ну, четыре большие
задачи. Это планировщик, это канал для файберов и селект, это фьючи и это картина. И я хочу,
чтобы мы как-то синхронизировали свое понимание и важность этого момента. Но вот есть еще какие-то
другие задачи, какие-то там про лог-фри, что-то, но это быловство на самом деле. На самом деле у нас
есть три больших инструмента, которые мы хотим изучить. Три задачи, которые на самом деле означают
три очень разных подхода к конкарнси. Как выведет ГО, как выведет в функциональные языки, скажем,
скала и как его видит C++. Это, соответственно, канал, фьючи и картина. И, ну, разумеется,
для того, чтобы получить какую-то хорошую оценку, вам не нужно решать все. Но с другой стороны,
чтобы пользу извлечь, а не оценку получить, что в конце концов имеет значение единственное,
разумно попробовать все подходы, разумно разобраться, как они работают, причем как они
выстроены изнутри. Ну вот, скажем, задача про фьючи мне представляется, наверное, в данный момент
самой важной, потому что это то, что мы меньше всего еще и спробовали. Это декларативный подход,
когда мы работаем с асинхронными операциями не в императивном стиле, когда мы там запускаем,
что-то думаем про то, какие интерливинги случаются, как потоки синхронизируются. Вместо этого мы
думаем про асинхронные операции, как представляем асинхронные операции в виде некоторых объектов,
а дальше комбинируем их с помощью специальных функций комбинаторов, которые позволяют выстраивать
цепочки, обрабатывать ошибки, параллельно композировать вычисления с помощью all of our
stuff комбинаторов. Но про них сегодня мы как-то будем говорить. Ну и все это вписывается в некоторую
общую концепцию функциональных явлений, разных там функторов и монат. Мне кажется, это очень
полезно изучить, тем более, что это все не то, чтобы какой-то совершенно параллельный мир. Нет,
это мир, который прекрасно сочетается с обычными файберами. Ну и вот в частности в следующем
семестре, когда мы будем говорить про распределенные системы, то мы с вами будем постоянно пользоваться
фьючами, потому что мы будем постоянно пользоваться RPC, потом как-то комбинировать их ответы от RPC
вызовов. Ну в общем, это то, что нужно, это то, что нам будет полезно осенью, и я предлагаю не пропускать
это. То есть формально можно решать другие задачи, набрать там полный балл, но мне кажется, что мне
представляется, что функциональная композиция, она очень важна для понимания конкуренции. Это
подход, который говорит вам, что в общем не нужно думать про то, как консинхронизируется в конце концов.
Вот когда вы напишите фьюч, вы увидите, что никаких промесов там в коде нет, некой синхронизации явной
в коде нет, просто комбинаторы и графы. Вот это довольно любопытный подход, как сместить фокус
своего внимания полностью, вот с контрол флоу, с интерливингов, на просто описание того, что мы
хотим сделать. А потом с другой стороны, как это изнутри сделать так, чтобы это работало максимально
эффективно. Вот, ну про то, как это выглядит, вы почувствуете уже, читая условия, про то,
как это устроено внутри, как это можно делать максимально эффективно, это как раз то, что мне
с вами хотелось бы обсудить. Потому что, кажется, я сам научился фьюч делать очень хорошими. Вот,
и хотел бы поговорить с кем-то об этом. Дальше, карутины. Это тоже чертовски важная задача,
потому что вот так видится автором C++ наше светло-синхронное будущее. И это будущее,
оно как-то не очень безоблачно, честно говоря, потому что, с одной стороны, инструмент максимально
эффективен, а с другой стороны, в нем есть некоторые то ли изъяны, то ли какие-то такие
фундаментальные ограничения, особенности, не знаю, как назвать. У меня вообще по плану на следующем
занятии устроить такую лекцию про критику дизайна карутины. То есть, что с ними не так,
или что можно было бы сделать по-другому, или что в них неудобно. Вот, если вы напишете
lock-free mutex в файберах, что мы сегодня, кстати, делаем на последней паре на семинаре, а потом
попытаетесь его перенести, хороший lock-free mutex, а потом попытаетесь его перенести в карутины,
или просто напишете lock-free mutex группу для карутин, то вы, в общем, увидите, что там есть
некоторое довольно большое неудобство. Ну ладно, не буду навязывать в свою точку зрения не то,
что неудобство, но вы столкнетесь с некоторым нюансом, и опять, вот про него хочется поговорить,
а чтобы о нем говорить, нужна мотивация ваша, в первую очередь, чтобы это вам было нужно,
чтобы вы видели этот нюанс сами. Ну и вообще, все наши файберы и все вот эти авейторы, которые
мастерим, и вся эта история про то, что фьютекс не нужен, а нужна вейт-группа, ой, вейт-группа тоже не
нужна, нужен suspend. Это же как раз вот просто такая длинная дорожка к дизайну карутин. Вот в
карутинах никакого фьютекса обычного и не напишешь, в принципе. Там есть только suspend, то есть только
avatars, co-avatars, avatars и avatars suspend, и в любой операции, которая останавливает карутину, карутина
останавливается строго один раз, ну, точнее, не более одного раза. Вот вы не можете циклу с
ожиданиями писать. Это про то, что фьютекс не нужен, фьютекс фундаментально ограничен и бесполезен,
гораздо лучше иметь другой IP. Ну и вот вся эта цепочка задач про файберы, она в том числе про
то, чтобы лучше почувствовать дизайн карутина, поэтому, опять же, чтобы вся наша работа не
прошла напрасно, нужно эту задачу тоже сделать. Ну и давайте я рекламирую еще канал, потому что
это моя любимая задача, потому что, реализовав канал и реализовав Select, можно почувствовать,
как, что, во-первых, в фьюче, ну, что вот комбинаторы всякие декларативные в фьючах, всякие эти
all-in-firsts, вот Select это аналогия некоторая, такая императивная для всего этого. Select это
инструмент, с помощью которого Go решает задачу комбинирования параллельного. На Select в Go
построено огромное количество идиом, такой, ну, каналы плюс Select. Буквально из всего этого
все остальное строится, вообще все строится. И это же чертовски клевый дизайн, чертовски
согласованный дизайн, очень точный, продуманный. Вы берете, не знаю, какую-нибудь джаву, в которой
очень большое историческое наследие, читайте, библиотеку там, утиль кон карант. И там просто вот
огромное количество, ну, не то, что барахла, но вот очень неточных, очень неаккуратных интерфейсов,
которые просто исторически как-то эволюционировали, мутировали, и в итоге вот вышло что-то. Go — чертовски
продуманный язык в этом смысле, в нем все, вот все идиомы, как бы все сценарии покрываются. Ну,
неудивительно, собственно, Google писала его на основе своего опыта, как писать распределенные
системы, как сделать язык для того, чтобы потом их писать. И вот все паттерны, все какие-то сценарии,
которые нужно в них выражать в распределенных алгоритмах, в Go поддержаны с помощью очень маленького,
очень компактного, очень эртагонального набора инструментов. Вот решая эту задачу, можно об этом
подумать и вот связать это все тоже в какое-то понимание. Плюс, что мне особенно ценно, вот только
написав каналы и селекты, можно по-настоящему профилировать планировщик, который мы пишем сейчас.
Надеюсь, что вы пишете его. То есть, решив эту задачу, можно будет уже какие-то нетривиальные
ворклоды делать, там действительно лифо будет играть, там действительно какие-то более сложные
сценарии возникают, чем Mutex, потому что Mutex можно заоптимизировать вообще без планировщика. То есть,
можно написать Mutex так, что он будет работать очень быстро, потому что планировщик там вообще
не участвовать не будет. Ну это такой некоторый обман, но все же, так можно сделать. А вот с
каналами и селектами, там действительно будет взаимодействие с планировщиком более интенсивно,
и вот только так можно все это померить. Короче, лучше сделать все, вот тогда вот полностью весь
замысел курса раскроется. Так что, пожалуйста, призываю вас попытаться, по крайней мере,
ну и вот желательно в течение майя нам побольше успеть, чтобы была возможность это обсудить.
Ну и вообще задачка клевая. У нас вообще-то следующая лекция по плану это про то,
как сделать хороший супер лог-фри канал и селект. Его так написали в код-лине. Возможно,
не даже переборщили, то есть даже не стоило так сильно стараться. Но тем не менее, это очень,
там очень нетривиальные вещи, там какой-то хитрый лог-фри. Вот я через неделю про него расскажу.
Итак, надеюсь, реклама удалась. Сегодня наша тема — это, наконец, новая для курса тема — это
structured concurrency и cancellation и обработка ошибок. Как жить с отменой синхронных операций. И вот
эта лекция, это занятие сегодня, оно будет в каком-то смысле рекламой осеннего курса про
определенным системам, потому что я буду рассказывать про то решение, которое в голове у меня
сложилось, которое, мне кажется, ну если я нигде не ошибся, мне кажется, очень согласованным,
очень встроенным и которое мы должны осенью использовать. Ну вообще все, что мы пишем,
мы будем осенью использовать. Ну, в частности, отмену. И это особенно важно привязывать к
распределенным системам, потому что в распределенных системах просто без этого
жить невозможно. Ну и давайте мы, собственно, перейдем к нашей сегодняшней теме про cancellation
и про обработку ошибок. Отлично. Итак, представьте себе, что мы пишем распределенную систему.
Распределенная система — это, ну давайте считать, что это набор каких-то сервисов,
которые живут потенциально на разных машинах, и вот есть некоторый клиент снаружи, который с
этой системой общается. Вся коммуникация, давайте считать, что она устроена через RPC. Мы посылаем
запрос, мы ожидаем ответ. Работаем в модели клиент-север, но осенью это еще раз подробно
обсудим. Вы, конечно, что-то знаете уже, но еще поговорим. Но детали нам пока не важны. Мы вот
просто представляем себе, что клиент посылает запрос на какой-то сервис. В этом сервисе запускается
какой-то обработчик этого запроса. Ну, можно тут нафантазировать себе разные представления этого
обработчика. Это может быть коррутина, это может быть какие-то там pipelines-fuge, это может быть
файбер, который запустился там что-то делать. Ну короче, какой-то конкарнс начинает шевелиться,
и возможно при обработке этого запроса нужно будет в свою очередь отправить запросы в какие-то
другие сервисы. Вот у нас получается такая логическая развилка. У нас там был один файбер, а потом он
сделал, не знаю, два RPC-запроса в разные стороны. И запустил два других файбера. И вот полетели
запросы сюда. Ну и в итоге выстраивается такое дерево запросов. И нас интересуют сегодня две вещи.
Что будет, если где-то в этом конвейере, чтобы уже не конвейере, в этом дереве обработки запроса
клиентского, возникла ошибка. И что, если где-то в этом дереве какой-то сервис просто недоступен,
потому что там машина, на которой он запущен, отказала. Ну тут, конечно, вы скажете, что у нас
есть балансировщик нагрузки. Если одна машина отказала, то возьмем другую машину. Но представьте
себе, если вы что-то знаете про определенную систему, что в этом какие-то кворы мы собираете,
отправляете три запроса, вам нужно получить два любых ответа. Вот какая-то машина может быть
недоступна, а запрос мы туда отправили. А что такое запрос? Ну опять же, вот я буду показывать осенью,
но можно себе представить, наверное, что машина, которая отправляет запрос, заводит у себя в памяти
какую-то структуру, которая материализует этот запрос. И там, не знаю, ретроит что-то,
ждет чего-то. Короче, память какую-то тратит, по крайней мере. В общем, на каждый запрос отводятся
какие-то ресурсы. И если вдруг мы дождемся двух ответов из трех, а третий просто забудем,
а он будет там где-то бесконечно ретроит, то это довольно печальная история. Не то, что он не
завершится, ну и бог с ним. Машина отказала навсегда. Но он просто ресурсы отъедает,
он время отъедает, он память отъедает, а запросы мы обрабатываем постоянно 24 на 7. Ну или мы задаем
HTTP запрос просто. Давайте вот совсем к простому примеру перейдем. Мы говорим request get. Вы знаете,
нам реквест. Такая самая известная библиотека для того, чтобы эти запросы задавать. Вот HTTP для
людей, кто-то написано. И смотрите, ну вот в продакшн коде, конечно, такого никогда не будет
вот такой строчки. Почему? Потому что нет гарантии, что такой запрос вообще завершится. Поэтому давайте
мы разные ссылки откроем. Поэтому в самом реквесте написано, что невозможно ставить запросы без
тайм-аутов. И просто во всем, в любом промышленном коде, в любом коде, который обрабатывает запрос
пользователей в продакшн, должны быть установлены тайм-ауты, потому что запрос может не завершиться
никогда. Ну или сколь угодно долго не завершаться и отъедать ресурс. Поэтому фокус установлю. Мы сейчас,
в первую очередь, говорим не про обработку ошибок, которые где-то возникают. У нас два топика. Есть
обработка ошибок и отмена. Вот мы хотим, чтобы операции наши не длились бесконечно. Мы хотим
их отменять. Ну и вот самый простой повод отмены операций, отмены вот этих всех вот запросов в
учислении, там обработки операции пользователя, это просто тайм-аут на стороне клиента. Вот вы,
наверное, подозреваете, что если вы приходите в систему с своим запросом, то система не должна
эти запросы складывать просто в какую-то очередь, а потом обрабатывать. Вот если она делает прямо так,
то, а я не знаю, вот быстро мы найдем подходящую ссылку. Но про это мы тоже обязательно осенью
поговорим, если... Вот, да, отличный доклад про то, что нельзя обрабатывать все запросы.
Нам нужен какой-то впечатляющий график. Нельзя обрабатывать все запросы, потому что в какой-то
момент, если просто складывать в очередь и потом процессить, то при перегрузке системы... Ну,
система может быть перегружена просто потому, что пользователи пришли. Ну, потому что все наши
конкурентные активности — это пользователи их запроса. Если все обрабатывать, то в конечном итоге
время обработки улетит в бесконечность. Поэтому мы должны где-то привести горизонтальную черту и
сказать, что вот просто есть тайм-аут, и после тайм-аута мы запрос отвергаем, и клиент должен
прийти попозже. Это очень... Это необходимо делать в любой продакшн-системе. Опять эта тема следующего
курса. Но пока вот просто представим себе, что у нас есть у пользователя тайм-аут, и после
пересечения этого тайм-аута мы должны операцию всю... Весь граф как-то отменить. Ну, вот мы говорим
про тайм-ауты теперь и сталкиваемся с тайм-аутами вот в таком вот виде. Довольно пока разумный опи.
Передаем тайм-аут вот в секундах, видите? Но смотрите, тут даже вот к такому опи уже есть довольно
смешной комментарий, на мой взгляд, что тайм-аут, здесь параметр, это... У него семантика довольно
странная, потому что это не тайм-аут на весь запрос. Это тайм-аут, который передается в сокет при
ожидании начтений. Ну, то есть этот запрос может выполняться сколь угодно долго. Просто если вот
каждую там одну миллисекунду приходит очередной байт, то чтение продолжается. И все это может
тянуться годы, но вот, тем не менее, этот тайм-аут у него такая странная семантика. Очень сложно ее...
Сложно о таком коде думать. Сложно думать, какие гарантии он дает. Поэтому как правильно поступить?
Вот что сделать вместо тайм-аутов? Может быть, есть инструмент получше? Да, вот другой пример,
почему тайм-ауты могут быть не самые удачные идеи. Вот вы делаете... Вы получаете запрос от
пользователя, и вам, чтобы его обработать, нужно задать запросы последовательно у два других
сервиса. В сервис A и в сервис B. И у вас есть глобальный ваш тайм-аут, временной бюджет на
обслуживание всего запроса пользователя. Там 500 миллисекунд. И вот вы эти 500 миллисекунд
отправили, ограничили им запрос в сервис A. А что делать с сервисом B потом? Ну, видимо,
нужно как-то перевычислить тайм-аут, потому что вы какую-то часть его и стратили уже при запросе в
сервис A, когда вы синхронно дожидались от него ответа. Ну, не то чтобы это было невозможно делать,
но это просто неудобно делать. Если у вас вот есть такой сложный граф, где есть какие-то шаги
последовательные, где вы чего-то дожидаетесь, потом делаете следующий ход, то в этом случае вам
нужно постоянно пересчитывать тайм-ауты, потому что тайм-аут, он всегда относительно нау. И вот
для каждого запроса нау разный. Время старта разный. Поэтому вот такой опи с тайм-аутами это...
Ну, тайм-аут в каком-то виде должны быть, но может быть они должны быть не в виде тайм-аутов.
Для ограничения времени должны быть, но, возможно, не в виде тайм-аутов. Может быть,
нужно придумать какой-то другой опи. Что бы вы предложили? Можно дедлайн ставить. Вот.
Гораздо лучше представить тайм-аут дедлайнами. То есть у нас есть ограниченный бюджет времени.
Он отчитывается от момента, когда пользователь пришел в нашу систему, перестег эту границу,
попал вот сюда. Ну, вот давайте мы возьмем нау вот здесь, прибавим к нему бюджет времени,
который, допустим, мог сам клиент сообщить. Ну, или мы за него решили. И вот полученный дедлайн мы
будем пропагетить дальше. Вот если мы задаем два запроса, то дедлайн для них не меняется.
Просто так код композируется лучше. Вот. Это первое, что нужно заметить. Что дедлайны,
кажется, лучше тайм-аутов. Но, опять, есть некоторый нюанс. Вот. Кажется, что дедлайны довольно
тяжело передавать между машинами. Потому что, как мы осенью опять поговорим, есть задача
синхронизации часов, и она довольно скверно решается. И часы, в общем случае, но, наверное,
можно считать на практике, что они довольно близки друг к другу, довольно аккуратно синхронизированы.
Но, все же, формальной гарантии нет. И, как мы увидим, их формальной гарантии быть не может.
Есть некоторые нижние границы, лучше которых нельзя. Поэтому, если вы передаете дедлайн,
то формально вы поступаете не совсем корректно. Потому что дедлайн проверяется относительно
других локальных часов, других локальных wall-time часов. Они могут быть немного смещены
относительно друг друга на разных машинах. Поэтому, может быть, на границах нужно делать все-таки
тайм-ауты между машинами, а не дедлайны. То есть пересчитать все обратно в тайм-ауты,
потом дедлайны. И, может быть, немножко пессимизировать. Но это не страшно. То есть,
можно делать здесь работу чуть дольше, чем здесь хотелось бы. Но, в конце концов, тогда мы просто
здесь ее бросим. Ладно, к этому нюансу мы опять вернемся через несколько месяцев. А пока подумаем,
вот над чем. Что вообще такое дедлайн? Когда мы проверяем дедлайн, мы смотрим,
он истек или нет. Мы получаем такой бинарный сигнал. Дедлайн истек или у нас все еще есть
время. Вот почему бы нам каким-то образом не абстрагировать этот самый дедлайн до более
общего понятия? И это понятие называется stop-token. Это довольно универсальный термин. stop-token или
cancellation-token можно такие названия встретить. Суть одно и то же. Это объект, у которого можно
спросить, верно ли, что пора завершиться. Этот stop-token может представлять дедлайн,
или же этот stop-token может представлять сигнал отмены, который спровоцирует вручную,
вызвав request-stop. Есть stop-source, который порождает stop-tokens, и на котором можно сказать
stop-request-stop. Есть stop-token, с помощью которого можно проверить, что через stop-source сказали
stop-request-stop. Понятная идея. То есть тот, кто хочет отменить какую-то асинхронную деятельность,
он говорит на stop-source request-stop. Тот, кто выполняет какую-то асинхронную операцию,
он проверяет stop-request. И тут, смотрите, важно, что мы себе сейчас задачу сильно упростим. Мы
скажем, что да, мы хотим поддерживать отмену асинхронных операций, да, вот никакой промышленный
код без этого не мыслим, но мы согласны на то, чтобы наша асинхронная отмена вот всех этих
графов была кооперативной. То есть, смотрите, вот у нас есть такие учисления, и снизу вверх
по этому графу текут результаты, ошибки или ответы, а сверху вниз пропагетится сигнал отмены. И вот
два этих встречных сигнала, они, конечно, гоняются между собой. И мы, в общем, готовы к тому, что мы
вычисления завершаем где-то, а на самом деле оно уже не нужно. Нас это не тревожит. Наша отмена
будет кооперативной. То есть, ну, представьте себе, что вы стартовали вычисления, чтение из сокета,
и вот вы сейчас прямо читаете данные. Вот, а вам сверху прилетает сигнал отмены. Ну, нужно ли прямо
сейчас все отменить? Вот не всякую операцию можно в любой момент отменить. Вы запустили вычисления,
то есть вы там, не знаю, откуда-то читаете данные, там их разжимаете в каком-то третпуле, а сверху вам
прилетает сигнал отмены. Можете ли вы распаковку данных в третпуле сейчас отменить каким-то образом?
Ну нет, там код запустился, он будет работать еще какое-то время. Вас это не беспокоит. Вы готовы
периодически просто проверять, что можно отмениться. То есть вы выполняете работу и иногда проверяете
вот этот самый дедлайн или вы проверяете стоп-токен, что, ну, ваша работа больше не нужна. Тогда вы ее
отменяете. Тогда вы бросаете то, что вы делаете прямо вот сейчас. Но какой-то вот прям мгновенной
реакции не требуется. Ровно поэтому у нас здесь не какие-то кулбеки, хотя кулбеки тоже нет.
На самом деле кулбеки были бы важны, но с другой стороны это СТД стоп-токен, от него каких-то
хороших вещей ждать, наверное, не стоило. В общем, в первую очередь проверка — это полинг. Просто
проверяем флажок. Пора ли остановиться. Вот это такое наше ограничение, ну, есть ограничение,
соглашение на все наше занятие и весь наш дизайн. Остановка кооперативная. Ну вот, стоп-токены.
Про это все написана отличная статья в одном прекрасном блоге, про который я расскажу чуть
позже. Тут как раз начинается с того, что вот есть тайм-ауты, потом есть дедлайны, и все это
можно потом заменить на стоп-токены. Ну это, в общем, стандартное решение. А теперь
посмотрим, как эта идея выражена в, ну скажем, в ГО. Есть ли в ГО стоп-токены? В ГО есть понятие
контекста. В ГО есть, есть, конечно, контекст. И контекст, ну, это некоторая штука, которая похожа
на стоп-токен, она на самом деле чуть более общая. Ну вот тут есть, смотрите, with cancel. Вы
говорите, что теперь есть контекст, который можно, в который можно отправить сильного отмена. И есть
вот ручка для того, чтобы это отмена спровоцировать. Но в общем случае контекст — это более общая
источность, потому что она передает именно сигналы отмены, какие-то дополнительные там поля,
какие-то записи, которые нужны для логинга, для трейсинга. Опять про это поговорим, и этим
будем пользоваться. Но вот в первом приближении для нас сегодня контекст — это именно сигнал
отмены. И смотрите, как ГО идиоматически предлагает его использовать. Ну, с помощью селектора.
Вот. Иногда вам мало просто проверить, что сигнал отправлен. Может быть, вы хотите
сблокироваться на канале. Но вы хотите заблокироваться и дождаться сообщений с каналу,
только если у вас просто отмена не произошла. И вот здесь вы опять идиоматически с помощью,
ну у вас контекст представляет вам сигнал отмены не просто в виде флажка или дедлайна,
а еще и в виде канала. И вы можете все это, на все это навесить селект и остановить
грудину до тех пор, пока либо не придет сигнал отмены, либо не завершится обработка чего-то.
Ну вот, мы этим контекстом пользуемся. Только есть беда. Беда с этим самым контекстом и беда
с дизайном ГО в том, что, ну как вам говорят пользоваться всем этим? Ну, вам говорят,
что если у вас есть какой-то там граф вычисления, граф каких-то асинхронных шагов, который нужно
которые порождается запросом, то, пожалуйста, когда вы там запускаете какую-то новую активность в
этом графе, порождаете новый дочерний узел, то вот функцию, которая, собственно, отвечает за этот,
ну, которая представляет этот узел, первым аргументом передавайте контекст, чтобы было видно,
что вот эта функция, она может сигнал получить и отмениться. Вот, ну и предлагается этот контекст
с собой таскать везде. Почему это плохо? Ну, это такой очевидный дурной запах, очевидный симптом
плохого дизайна, потому что, с одной стороны, вам говорят, вот здесь вам говорят, что в любом
продакшн коде должна быть поддержка отмены, то есть вам говорят, что всегда будьте готовы к
отмене операции, всегда поддерживайте такой сценарий. И вместе с этим вам говорят, каждый раз руками
таскайте контекст, то есть есть некоторая забота, которая нужна, есть этот контекст, который нужен
всегда, но почему-то вы заставляем пользователя руками каждый раз его таскать. Выглядит как-то
не очень эргономично. Понимаете проблемы, да? То есть понятно, что можно, но не очень удобно. Но давайте
я вот, кстати, уже примеры какие-то покажу про стоп токен. Вот мы, в принципе, можем им пользоваться,
чтобы отменить файберы. Вот мы запускаем планировщик, вот мы создаем стоп сорс,
вот мы запускаем файбер, вот мы захватываем в нем стоп токен, этот файбер собирается бесконечно
долго работать, но мы вот спим три секунды, тут на всякий случай мы спим, не то чтобы мы slip
зовем трэдовый, мы зовем slip файберный, а slip файберный это await на future, который нам
строит некий таймер сервис. Он строит фьюч от юнита, которые заполняются юнитом, когда проходит
заданное время, а await это, кстати, вот то, что мы можем еще после того, как вы решите файберы,
и после того, как вы решите future, можно будет в нашем коде написать такой свой собственный await,
который компилятор пишет C++ за нас, а мы можем для стекла с файберов его написать сами. И вот
склеить future и файберы через await, но так мы делаем это все C++. Короче, вот этот код он блокирует,
останавливает файбер на три секунды, а потом говорит request stop, и видимо этот файбер должен
отмениться, но можно это проверить. Давайте мы будем эти примеры запускать.
Это стиль, в котором нам предлагают писать весь код в Go, и стиль, который, наверное,
нам не очень нравится. Ну вот, мы поработали три секунды, потом, видимо, через этот request
stop сюда прилетел флажок, и мы прекратили крутиться. Хотелось бы теперь решать задачу отмены более
прозрачно для пользователя. Если пользователю всегда что-то нужно, и пользователю, если пользователю
нужно что-то делать всегда, то было бы хорошо, если бы инфраструктура сама поддерживала этот
сценарий прозрачно для пользователя, чтобы в коде пользователя явно никаких вот этих проверок не
было. Поэтому что мы хотим? Мы хотим писать вот такой вот код. Мы хотим запустить файбер,
вот, который выполняет функцию foo. Тут есть некоторые nursery. nursery здесь пока не очень важен.
Просто запускаем файбер. Этот файбер вызывает функцию foo. В этой функции foo вызывается функция
bar. В этой функции bar вызывается функция bus. В этой функции bus написано в бесконечном цепле slip4,
тот же самый. Вот, но тем не менее мы хотим, чтобы этот код он остановился. То есть пользователь
написал какой-то код, и он сразу из коробки поддерживает асинхронную отмену.
Ну что, похоже, пример завершается. Давайте теперь думать, а как же это произошло? Как этот
файбер умудрился остановиться? Как можно было бы сделать отмену файберов прозрачной для
пользователей? И тут два вопроса на самом деле скрыты. Первый вопрос. Сейчас аккуратно. Механика
отмена такая же. Где-то под капотом есть стоп токен, есть стоп сорс. Вот вопрос, где же стоп токен
проверяется в файбере тогда, в этом коде? И второй вопрос. Как нам, собственно, файбер отменить? Что мы под
этим понимаем? Ну, файберы это потоки, которые с одной стороны это потоки, а с другой стороны это
потоки, которые должны больше времени спать, ждать чего-то. Именно поэтому мы их можем много завести в
программе. Так вот, если они часто засыпаются, значит они часто, еще раз, файбер, когда он работает,
он выполняет код пользователя. И мы на него влиять не можем, и мы не можем просто, точнее, можно себе
было бы это представить, но мы так не хотим. Мы не можем взять и прервать файбер в любой момент
времени. Но с другой стороны, файбер сам по себе, по своей природе, должен часто останавливаться,
часто переходить в runtime, то есть реализацию свою. И вот в этом случае почему бы нам просто не
вставить проверку? Почему бы нам не связать просто каждый файбер с некоторым стоп токеном? То есть,
если мы создаем файбер, у него должен быть стоп токен. Это просто требование. Файбер без стоп
токена немыслим. И мы у файбера сделаем метод, который будет называться isCancelled, который будет
проверять этот самый стоп токен. Где мы будем этот метод вызывать? В suspend, я не знаю, там,
где мы попадаем в runtime. Ну вот, например, я проснулся, и в suspend... Нет, не в suspend,
в том-то и дело. Чтобы это объяснить, нужно ответить на второй вопрос. Вот у меня есть функция
checkpoint. Вот checkpoint — это вызов, который нужно вставлять повсюду в коде, где файбер ходит в runtime,
вот нужно поставить checkpoint, и вот ровно в этом месте, то есть там, где файбер мог бы отмениться,
нужно поставить этот вызов, а он внутри проверит стоп токен файбера. Второй вопрос — что значит
файбер отмениться? Вот файбер работал, он там сделал какой-то вызов, в этом вызове он какие-то,
не знаю, mutex взял, потом пошел в какой-то другой вызов, а потом внутри отменился. Вот что мы понимаем
под отменой файбера. Ну да, как этого добиться? Вот, да, поэтому, когда мы проверяем в checkpoint
стоп токен, мы, если он оказался установлен, мы бросаем exception. Этот exception разворачивает
стэк, вызывает деструкторы, и в конце концов он прилетает в корень файбера и где-то здесь написан
вот такой вот catch. Вот файбер отменился. Это специальное исключение, видимо, перехватывать его
не стоит, обрабатывать его точно не стоит, это такой clean-up файбер автоматический. Тут некоторые
супервизоры появляются, об этом чуть позже. Значит, с файбером вроде понятно все, да? То есть можно
его так вот прозрачно останавливать, не таская с собой топ токен явно, просто храняя его,
по сути, сделать watered local, ну по своей сути. Хорошо, это одна часть истории. Другая часть
истории это фьючи, потому что... Ну мы же хотим... Когда мы говорили про фьючи, мы говорили, что зачем
нужно фьючи? Затем, что иногда мы хотим делать вещи параллельно, делать с вещами последовательно,
тогда это файберы. То есть мы хотим сделать два запроса подряд. Кажется, что здесь файберы подходят
нам. Сделали один запрос, дождались, потом сделали второй запрос, дождались. Ну ладно, тут другой
написан. Понимаете, о чем я. Что если нам нужно распараллельно два запроса и получить первый
ответ? Ну, кажется, это first-off. Вот нам хочется такой комбинатор иметь. Мы комбинируем две фьючи,
потом дожидаемся. И, значит, у нас есть файберы, и у нас есть равноправные, равнополезные,
ну правда, в другом контексте, фьючи. И для них тоже нужно поддерживать отмену.
И для того, чтобы... Да, и вот смотрите. Давайте откроем даже домашню.
Вот, что мы понимаем под отменой фьюч?
Вот у нас было вычисление, потом было другое, потом был Zen. Мы получили фьючи G. Что мы
хотим? Что мы понимаем под отменой? Мы бы хотели каким-то образом... То есть у нас фьюча — это
представление какой-то ассинхронной деятельности, операции, вычисления. И мы бы хотели через эту
фьючу, потому что это единственное, что у нас осталось, это вычисление, эту операцию отменять. Ну,
или целый граф отменять. Поэтому мы бы хотели, чтобы у фьючи был, видимо, метод, который... Давайте
мы сейчас его найдем. У фьючи был метод, который назывался бы cancel, который бы в обратную сторону
отменял весь граф, который на фьючах выстроен. И чтобы увидеть, как это можно сделать,
очень красиво, на мой вкус, давайте подумаем, что вообще такое stopToken и stopSource.
Смотрите, в чем замысел stopSource и stopToken? stopSource — это сущность, которая находится у
консьюмера, который чего-то ждет и который может решить перестать ждать, передумать,
потому что там устегнут line. И у нас есть продюсер, который делает что-то полезное для консьюмера и у
которого есть stopToken, через который продюсер проверяет, что его работа все еще нужна.
И каким-то образом от stopSource к stopToken нужно передать сигнал отмены. Где его хранить? Вот,
его нельзя хранить в stopSource, потому что консьюмер может отменить асинхронную операцию и просто
завершиться. А отмена кооперативная, поэтому stopToken пока еще может не провериться. Аналогично
нельзя хранить единицу в stopToken, не потому что операция уже может завершиться, а мы только ее
сейчас собрались отменять. Где-то вы такое уже, наверное, видели, если вы решали фьючи,
если вы решаете фьючи. Поэтому что мы делаем? Мы строим sharedState, который называется здесь stopState,
и в этом stopState хранится флажок, нужно отмениться или нет. И stopSource и stopToken
держат просто сильную ссылку на этот объект. То есть этот объект живет до тех пор, пока жив
либо stopSource, либо stopToken. Ну и stopToken может быть много. В коде мы хотим это немного обобщить,
сказав, что stopState это не просто конкретная реализация, где лежит флажок отомарный.
На всякий случай иногда им рекомендуется скверный код, однажды он станет лучше,
но в орган прогресс. В stopState лежит флажок stopRequested, но вообще-то stopToken это sharedPointer не
на... sharedPointer тоже не нужен, нужен интуизивный pointer. Он хранит stopToken и stopSource хранят
ссылку на stopState не на конкретный, а на интерфейс. Почему? Потому что stopState и можно представить
себе очень разными и скажем, вот мы говорим, что у каждого файбера есть stopState, а какой должен
быть... у каждого файбера есть stopToken? Какой должен быть токен у файбера, который мы просто
запускаем через go? Мы говорим файбер, go, и он там летит. Очевидно, его никто не собирается отменять,
просто сигнатура такая. Поэтому мы скажем, что у него будет свой собственный токен, который устроен
вот так вот. Он всегда говорит false и вот просто ничего не делает, с максимальной легкой реализацией.
Короче, можно представить себе разные реализации stopState для разных сценариев,
которые специализированы. Ну вот, к чему я это все рассказываю? К тому, что, глядя на эту картинку,
можно догадаться, как можно интегрировать прозрачно отмену в фьючи. Вот и давайте
проверим вашу интуицию, потому что это очень красиво, мне кажется. Прямо очень красиво.
В случае с файбером, мы просто в объект файбер запоминали stopToken, таскали его с собой. А как быть
с фьючами? Как быть с этими конвейерами, которые мы там ассинхронно строим? Вот.
Мы не можем в sharedState добавлять проверку? Не отменился ли stopToken?
Смотри, ты не чувствуешь пока красоту. Ну давай я покажу тебя, чтобы, может быть,
она была лучше видна. Что такое фьюч и promise? Этот sharedState, где лежит результат потенциальный
будущий. И есть promise – это сильная ссылка на sharedState у продюсера, и future – сильная ссылка на
sharedState у консюмера. И консюмер и продюсер передает результат консюмеру через этот sharedState.
Но вот тут вопрос не в том, как можно поддержать фьюч во фьючах cancel, а в том, что нужно просто
увидеть некоторую двойственность между двумя этими картинками. И тут не просто так эта картинка
нарисована. Тут вот есть этот граф, и мы снизу и вверх отправляем результаты, сверху вниз cancellation.
Это какие-то, ну, как бы, ну, смотрите, мне нравится такая аналогия с кровеносной системой. У нас
есть артерии и вены, и они просто противоположные цели выполняют, противоположные функции выполняют.
И они как бы дублируют друг друга в некотором смысле. Если есть в одну сторону, то есть в другую
сторону. Ну что ж, получается, что с одной стороны продюсер-консюмер им нужен два объекта для того,
чтобы передавать результат в одну сторону, а с другой стороны им нужен такой же разделенный
объект, чтобы передавать отмену в другую сторону. И может быть, это не просто как бы
каких-то два отдельных механизма, две параллельные сущности. Может быть, это вот как бы просто
future и promise, они по своей природе двойственные такие. Вот мы от promise к future передаем результат,
а от future к promise передаем сигнал отмены. И поэтому давайте так и напишем код. Давайте мы в... где же
мы были? Мы хотим попасть в future, в shared state. Давайте мы скажем, что shared state он наследуется от
stop state. Ну то есть shared state это в том числе и stop state. Или можно было бы даже красивее сделать,
сказать, что у нас есть stop state, есть как бы result state, а shared state он наследует и то и другое.
Это, наверное, было бы самым красивым выражением в коде этой идеи. И поэтому,
как наша API future доработается в связи с этим? Мы скажем, что у future есть операция cancel,
а у promise есть операция stop requested. Ну потому что promise это... Здесь promise,
он как бы и promise для отправки результата, и как бы stop token для проверки флажка отмены,
а future она одновременно и для получения результата, и для отмены. То есть она и
как бы future и stop source разом. То есть здесь вот future она похожа на stop source, а promise здесь
похож на stop token. Понятная идея? Вот, мне кажется, очень красиво, но это только начало.
Двигаемся дальше. Что я, наверное, упустил? Я упустил следующую картинку, и мне она сейчас
пригодится. Такая незамысловатая. Смотрите, контекст или stop token представляет собой
некоторые сигналы отмены. Например, deadline. Но если вы пишете какую-то композитную операцию,
у вас есть сначала запрос в сервис A, потом строго после запроса в сервис B, который использует
ответы сервиса A, то вообще говоря, может быть, у вас есть общий deadline, а может быть, у вас есть
какие-то вложенные дедлайны, вложенные лимиты. И тогда у вас такая система дедлайнов получается,
или система каких-то причин, по которым вы отменяете операцию. И вот эта иерархия, она может быть
выражена прямо через иерархию на самих stop token, на самих контекстах. Вот, скажем, в Go,
вы когда оборачиваете контекст, вы... У меня сейчас, наверное, нет под рукой кода.
Найду я сейчас что-нибудь быстро. Нет, это вообще не то, что подсылывают какие-то плохие сумки.
А контекст разве в рантайме? Это же сторонний библиотект, кажется.
Ну, сейчас, не в рантайме, да. Я просто так говорю, потому что для меня это логически часть рантайма,
потому что в Go это как бы снаружи, потому что мы таскаем руками, а у нас сейчас это внутри,
потому что мы не хотим таскать руками все. В Go у нас контексты, они связаны отношением вот ребенок
родителей. И к чему я это говорю? К тому, что буквально такая картинка, во-первых,
появляется на самом деле в контекстах. А во-вторых, как это относится к нам? Это относится к нам
самым прямым способом, потому что смотрите, что мы делаем здесь. Мы в этом примере же не просто
запустили, построили Future, построили пару контракт Future Promise, Promises отправили в Threadpool,
и там проверяем отмену, а на Future говорим cancel. Мы вообще-то на Future сделали ZEN еще,
и вот мы сделали cancel здесь, и он пролетел сквозь эту построенную цепочку вот сюда,
в корень. Как мы этого добились? В этом вся соль. Как это все композируется? Потому что пока мы
просто буквально пронесли стоп-токен руками, мы пока ничего особенного интересного не сделали.
Вот красота где-то здесь появляется, потому что вот здесь никакого кода пользователи не написал,
он ни синхронизации не написал, ни прокидывания токенов не написал, а все автоматически работает.
Вот это наша цель. Как же это произошло? Как же мы это добились?
Что?
Должны, да. Ну вот смотри, что такое ZEN?
Вот ZEN – это комбинатор, который берет Future и который запускает лямбду,
когда Future заполнится значением. Как реализовать ZEN? Ну, нужно подписаться на Future и в колбеке
вызвать эту лямбду. Но нужно же еще каким-то образом, когда, если случится отмена,
протянуть сигнал отмены. Так вот, где складывает, где происходит связывание? Ну, это не знаю,
по-моему, это очень красиво. По-моему, это очень красиво. Это не то, это... Вот что я хочу. Смотрите,
ну или даже по-другому скажу. Любая операция на Future, просто любая. Ну вот, берем API Future.
У нас в синхронных Future был очень простой API и очень скверный API. У Promisable Set с ним все
нормально. У Future был блокирующий GET. В хороших Future никакого блокирующего GET у самой Future
нет. У Future есть только subscribe. Вот то есть поглотить значение, результат вычисления синхронного,
можно, операция синхронная, можно только через subscribe. Если вы хотите заблокироваться, то вы
можете использовать какую-то внешнюю функцию. Сейчас у меня где-то написано условия.
Да, если вам нужно заблокироваться во Future, то вы используете внешнюю функцию GET RESULT,
а сама Future блокироваться не умеет, потому что это для нее ненормально. Future, они для того,
чтобы исполнять что-то в третпуле, а в третпуле выблокировать потоки не хотим. Поэтому, поэтому,
есть только subscribe и смотрите какая семантика у subscriber. Мы подписываемся на результат.
А как это связано с отменой? Вот была некоторая синхронная операция, она представлялась Future.
Пока Future это такая невостребованный результат, пока никто его не дожидается. А значит,
его пока некому отменять. Но, если вдруг вы подписываетесь на Future, а любой код,
который хочет что-то с Future делать, в конце концов подписывается, то вы сразу получаете
Stop Source. Вот вы подписались, повесили колбэк свой, ну тогда вот вы ответственны за отмену. Вот вам
Stop Source, разбирайтесь. Как это реализовано? Ну, очень просто. Subscribe, Future держит ссылку на
стейт. Этот стейт, он является и Stop Source в том числе. Поэтому просто берем Stop Source,
строим, который хранит shared pointer на I-stop-state. А shared-state это в том числе и I-stop-state,
поэтому в общем полная гармония. То есть просто Future теряет свой стейт, она уже как бы использована,
но пользователь этот стейт дается в виде stop-state, чтобы операцию можно было отменить. И когда я
говорю Zen, вот в этом примере, то я с одной стороны подписываюсь на выполнение Future F1,
а с другой стороны я свой токен, в смысле Future F2, связываю со Stop Source Future F1. Вот Stop
Token коннектится к Stop Source, я могу их связать всегда. У меня просто в Stop Token есть операция
связать с Stop Source. То есть я буду вот так вот отправлять сигнал отмены. Понятно? Красиво, да? И
все это сплетается внутри runtime. То есть мы пишем Future F2 с комбинаторами, и вот оно так плетется,
то есть смотрите, когда я выстраиваю граф с помощью Future, вот почувствуйте это,
я с одной стороны выстраиваю граф снизу вверх, откуда будут течь результаты, и параллельно я
выстраиваю синхронный граф сверху вниз, по которому будет течь отмена. Это вот буквально
такие две кровеносные системы, в смысле две части кровеносной системы, и они абсолютно
параллельны, они друг без друга не могут быть. Вот, очень красиво. Сам себя не похватишь.
Так, в какой момент мы отменяем Stop Source? Мы Stop Source не ринкуем, это довольно странная
симматическая операция была бы. Мы Stop Token и Stop Source линкуем всегда. Stop Token Future,
которую мы порождаем в зене, и Stop Source Future, которую мы консюмим в зене. Вот, еще раз,
мы здесь подписываемся на Future F1 и в ней запускаем Callback. Подписываемся на Future F1 и
в обработчике запускаем лямду. Следующий шаг вычисления. Вот в этом зене мы связываем
Stop Token F2 со Stop Source F1. Так, чтобы, когда я сказал на F2 Stop Cancel, то этот cancel бы,
вот так, наверное, было бы симпатичнее написать. Пожалуйста. Не то чтобы у Promise есть
там какой-то поле Stop Token, потому что он в том числе и Stop Token сам по себе. То есть,
Promise 2, который Stop Token, соединяется с Future F1, который Stop Source. Вот, и дальше сигнал
прилетает вот по цепочке. Дальше, если я наворачиваю новые и новые зены, ну, это легко делать. Дальше,
потом я скажу на конце цепочки cancel, и он развернется и долетит до вот самого источника. И
здесь мы, ну, если хотим, проверим и отменим. Итак. Если у нас длинный pipeline какой-то,
ну, там несколько зенов, мы можем где-то в середине cancel отправить? Ну, как, если мы на Future
подписались, то вообще говоря нет. Ну, то есть, если мы сделали zen, то значит за cancel отвечает
кто выше находится теперь. А здесь мы просто пропагетим. Но можно, на самом деле, по-разному делать.
Можно делать по-разному. Можно еще и внутрь задачи, внутрь кулбека прокидывать контекст. Это
это можно делать, и это, наверное, стоит делать. И это чуть более общий вопрос. Тут пока для него
код не написан, но я могу идею, кажется, рассказать. Секунду. Это уже про экзекьюторы разговор. И я хочу
сказать, что, наверное, в экзекьюторах у каждой задачи просто должен быть свой контекст. У любой
задачи, которая запускается, должен быть контекст для трейсинга, для логинга, чтобы можно было в
других библиотеках этот контекст читать. И в том числе оттуда можно было бы забрать stop
токен текущий. Ну или даже там, не знаю, отменить что-то. Ну в первую очередь проверить,
все же, а не отменить. Тут можно еще глубже все это интегрировать. Вопрос разумный. Да,
можно было бы. Кажется, что фундаментальных препятствий к этому опять нет.
Нет, у нас, смотри, у нас stop. Тут нужно не про stop токенные сорсы говорить, потому что это
всего лишь такие обертки, которые поинтеры держат на stop стейт. У нас каждая фьюча это,
ну каждая новая фьюча это новый shared state. Каждый shared state это stop стейт. И мы вот их связываем в
граф. То есть у нас вот здесь граф строится для вычислений и в обратную сторону, то есть строится
противоположно направленный граф для отмены. Так, секунду, у нас садится ноутбук и это не
помогает быстро работать. Вот это работа. Вот такой вопрос про семантику канцела. Он предотвращает только
будущие вычисления. Но он кооперативный, то есть он говорит, что вот если что-то не вычислилось еще,
то и не нужно больше, а если уже успело, то ну ничего не поделать. А если прямо сейчас что-то делается,
то возможно можно еще отменить, еще не поздно отменить. Ага, ясно. Вот в этом и смысл кооперативности,
то есть мы не можем каким-то магическим образом отменить там, не знаю, вычисления, там разжатие
данных в пуле. Вот оно запустилось и будет работать пока не завершится. Вот, но если что-то можно отменить,
то кто-то, кто потом этот стоп токен смотрит, может быть он согласится бросить свою работу. Да,
я не договорил еще такой нюанс, очень красивый мне кажется. Смотрите, у нас есть, мы говорим,
что вот стоп сорс, стоп токен и future promise это какие-то очень просто одно и то же названные иначе,
да, потому что просто коммуникация в противоположные стороны. И мы говорим,
что future она потребляется как подписка и кулбэка. Вот на самом деле вопрос в чат.
Хорошо бы развернуть вопрос, потому что я не понимаю вопроса пока, ну точнее замечания.
А, это шутка? Тогда поясни шутку. Ужасная ситуация, да, когда не понял шутку. Ну, такое случается,
к сожалению. А, я понял, это... К чему я веду? К тому, что подписываться можно на future,
но с другой стороны подписываться на стоп токен, ой, на стоп токен, да, с другой стороны,
это тоже разумно. То есть кажется, что если у нас есть promise и он представляет собой стоп токен,
в том числе, то операция подписки на promise, она не выглядит так уж безумно. Ну, в смысле,
она вообще не выглядит безумно, это разумная идея. Чего я так говорю? Потому что, ну, представьте
себе RPC. Вот это еще, у нас осенью будет RPC, он будет интегрирован с этим фреймворком конкарнси,
и вот это то, что я еще не написал в нем, а мне, наверное, хочется, ну, по крайней мере,
попробовать хочется. Вот что, если вы фреймворк RPC, и вы там породили запрос, отправили его в сеть,
и вы, библиотека RPC, держите promise, future даете пользователю, а promise держите у себя, чтобы,
когда придет ответ, вы бы отправили во future результат. Но что, если пользователь сам сказал cancel
на future? Что мог бы сделать RPC framework? Он мог бы повесить callback на promise,
и в этом callback отправить на другую машину специальные служебные сообщения,
что вот сворачиваетесь, вы больше не нужны, вычисления ниже. И это было бы все реактивно,
вот с помощью подписки на подписки вот здесь, вот с этой стороны, то есть на стороне продюсеров,
понимаете? Красивая идея. Вопрос? А мы ничего не ожидаем, это же best effort, мы просто попробуем,
и все. Может быть, на этой машине запрос уже завершится к этому времени, когда сообщение дойдет,
может быть, так не нужно делать вообще. Да, я понял, да. Вот, вообще про это есть... Я уже многократно
рекламировал статью про future в твиттере, вот если вы решаете задачу, а даже если вы не решаете,
вот необходимо ее прочесть, она великолепна, она про дизайн, про то, как вот сделать хорошие
фьючи. И эти фьючи, они зарелизили твиттер в виде библиотеки, в которой очень много всего,
и вот на которой написан, собственно, весь твиттер. И я сейчас хочу найти... Тут много всякой
инфраструктуры, все эти контексты, трейсинги, ну короче, вот все, что нужно, не просто вот как бы
future promise, этого очень мало, нужна вот вся сопутствующая инфраструктура, всякие там балансеры,
ретрои, метрики, трейсинг. Опять про это осенью. Секундочку. У меня где-то спрятана ссылка,
я сейчас хочу ее найти и порекламировать. Да, есть чудесный доклад одного из инженеров,
который над этими фьючами работает, где он рассказывает, что вот фьюч в твиттере,
они так делают. Они умеют пропагетить консолейшн в... Где-то это должно здесь быть. Ладно,
это или... Ладно, это в твиттере, его точно есть, совсем недавно написал про то, что фьюч у них
очень клевый, про то, что они вот все это умеют делать, они лучше, чем скала фьюча, ну то есть
биоретика написана на скале, вот в скале тоже есть фьюч, но вот они этого не умеют, а вот у них
умеют и уже много лет умеют. И, скажем, у IT яндекс и фьюч тоже умеют такую отмену делать.
Вот, ну потому что, ну по-моему, кстати, они, я не уверен, что они умеют, по-моему, Паша Сушин,
я не помню, что он рассказывал, умеют ли они пропагетить, пропагетят ли они сигнал прямо отмены
через служебные сообщения, ну вот в твиттере пропагетят. И вот это все связано с возможностью
повесить, ну если смотреть на все это как на двойственную сущность, то вешать callback на
фьюч так же разумно, как вешать callback на promise. Вешать callback на promise так же разумно,
как на фьюч, только с противоположным назначением, с целью противоположной,
чтобы подписываться на отмены и вот посылать сообщения вниз по этому графу к дочерним сервисам.
Итак, это понятно все, да? А теперь мы переходим к теме реакции, собственно, ну,
к основному ключевому содержанию, как все это объединить в совсем выстроенную систему,
встроенный фреймворк. Для этого нужно поговорить про несколько другой топик,
которого мы сейчас, в общем-то, избегали. Мы пока говорим, что, ну, почему вообще случать отмена,
потому что вот есть клиент, он приходит, у него есть бюджет времени, вот он истекает,
и все, вниз полетело отмена. Но это не единственная причина, по которой отмена может случиться.
И есть еще второй аспект — это обработка ошибок. И чтобы к этой теме выйти, нужно
подойти вот довольно очень издалека, я бы так сказал. Нужно вернуться в 1968 год и прочитать
просто величайшую статью. Ну, это как бы одна из заметок, на самом деле, но стоит того,
чтобы прочесть. Это Сэ Дэйкстры про то, что, ну, с критикой оператора Гоу Ту — Considered Harmful.
Вот она таким названием известна. Именно поэтому в шаблоне задач везде было написано, что Гоу
Considered Harmful. И забегая вперед, некоторый спойлер, мы хотим сказать, что... Ладно,
давайте пока без спойлеров. Всему свое время. Итак, мы говорим про обработку ошибок, и для этого
нам нужно вернуться в глубокое прошлое, в 68 год, и подумать о том, как выглядела обработка ошибок,
как вообще выглядели программы в те далекие времена. Это вообще, не знаю, скан манускрипта,
набранного на печатной машинке, наверное. Ну, и такие статьи тоже полезны читать, особенно сейчас.
Да, всё-таки я покажу картинку. Она как раз из статьи, которая называется Go Considered Harmful.
Потому что утверждается, что Гоу и Гоу Ту — это очень похожая вещь, Симонтич. Ну, вот в некотором
смысле очень похожие вещи. Эта аналогия, она очень глубокая и ведет к очень чертовски разумным
выводам. Всё, на этом закончу. Итак, утверждается, что... Ну, не то, что утверждается, в глубоком
прошлом, в далеком-далеком прошлом программы выглядели как-то так. Ну, можно себе представить
там разные программы, но суть в том, что они были плоскими. Вот это некоторый текст в плоскими,
и если мы думаем про исполнение такой программы, то мы думаем про вот буквально перемещение
некоторого курсора, про перемещение управления по этому плоскому тексту. И перемещаемся мы по этому
тексту преимущественно с помощью оператора Гоу Ту. Вот мы прыгаем из одного места в другое. Ну,
и понятно, что так можно в принципе любой логику выразить, что еще нужно. Кроме того, Гоу Ту — он
и в современных языках есть, но, правда, в каком-то ограниченном виде, но и компилиаторы, когда они
компилируют ваш код, они могут переписывать все ваши конструкции, все эти ифы, циклы и там
интерацию на Гоу Ту. Но вот все-таки в нашем современном языке этого всего нет. Почему? Отвечает
Дэкстра. Он говорит, что если вы думаете про исполнение вашей программы, то если ваша программа
плоская и в ней передача управления происходит с помощью Гоу Ту, то очень сложно думать про
динамику исполнения вашей программы. Дэкстра говорит, что человеческий мозг, он хорошо работает
со статическими структурами, и он плохо работает с какими-то очень динамичными системами. Ну,
собственно, далеко за примером ходить не нужно. Мы в этом курсе говорим про потоки, которые там
переключаются друг на друга, и вот нам нужно представлять себе все возможные интерливинги,
и это неестественно для человека, это сложно для человека, он легко там ошибается. Вот сложно об
этом думать. И если мы говорим про Гоу Ту, тут точно такая же идея, что вот мы пришли в какую-то точку
программы, а как мы там оказались, не очень понятно. Что предлагается? Предлагается заменить вот эту
сложную динамику на какую-то очень простую статическую структуру, которую можно визуализировать.
Для этого предлагается сделать следующее, воспользоваться идеей, которая называется
structured programming. Фундаментальная идея, которая изменила программирование давным-давно.
Идея в том, что не нужно думать про вот такие сложные динамические сценарии, нужно представить
себе управление в программе, выразить передачу управления в программе однопоточной, обычной,
через ограниченный набор конструкций. Во-первых, это последовательная композиция, когда мы сначала
выполняем там не знаю, шаг A, шаг B, вызываем под программу A, под программу B. Итерация в виде циклов
while for и витление. Вот тогда исполнение, тогда нашу программу можно представить себе в виде графа.
Есть всегда точка входа, есть точка выхода, и вот этот граф имеет структуру некоторую,
и эта структура, она тактически выражена просто, ну не знаю, вы наблюдаете ее в виде отступа в
программе, отступов и пустых строк. Это в общем-то отражение этой структуры. И вам гораздо легче думать
о том, что происходит. Вообще, идея под программой, она очень мощная, потому что она абстрагирует
содержимое. Вам не нужно думать, что внутри происходит, вы просто знаете сигнатуру, и все. И это не
только вам упрощает жизнь, это упрощает жизнь и даже в первую очередь, ну не то, что в первую
очередь, в равной степени это упрощает жизни компилятору, потому что компилятор, вот то,
что мы рисуем, компилятор строит явно, и эта конструкция называется, где-то у меня должна быть
ссылка, и где же она. Эта сущность называется control flow graph. Вот компилятор, он парсит текст вашей
программы и строит по ней control flow graph. То есть вот все вот эти ваши там блоки и передачу управления
между ними, он отражает в виде графа с понятной структурой. А потом, пользуясь этим графом,
он просто доказывает некоторые свойства вашей программы. Ну вот скажем, Borrow Checker в Rust
использует Liveness Analysis. Ничего здесь не написано про Liveness, черт возьми. Но Liveness Analysis для
того, чтобы определять, какие перемены, к каким переменным дальше, ниже по тексту могут обращаться.
Но не ниже по тексту, а вот как бы дальше в исполнении. Вот компилятору Rust нужен для Borrow
Checking этот самый control flow graph. Это называется data flow analysis. Как по графу текут результаты.
Или скажем, ну такая привычная вещь, как распространение константов. Вот у вас есть одна
константа в коде, другая константа в коде, потом вы там между ними что-то вычисляете,
вычисляете новую переменную, где там переносите две константы. Вот компилятор что пытается сделать?
Он пытается от переменных избавиться, не аллоцировать там память, а просто понять,
что вот в этой точке, вот этой переменной, хоть и тут написано какое-то вычисление,
но на стадии компиляции будет известно, что здесь будет некоторая фиксированная константа. Поэтому
я ее просто вычислю и напишу в текст программе сразу ее, не аллоцируя переменные, не там вычисления.
Вот все это работает, потому что у вас есть структура. Ну это такие общие вещи, а теперь конкретно
про нас. Почему структура важна? Потому что эта структура позволяет легче обрабатывать ошибки.
Ну вот представьте себе, у вас есть, давайте вернемся на картинку, на вот эту картинку,
у вас есть некоторый граф, по которому вы двигаетесь в своей программе. То есть у вас есть развилки
здесь, но на самом деле вы идете только по одной ветке, конечно. И вот ваше исполнение это некоторая
цепочка в этом графе, и она представлена в физических виде Callstack. А теперь где-то с вами
происходит неприятность, возникает ошибка, и вам нужно ее обработать. Ну обрабатывать вы будете,
скорее всего, и не здесь, где она возникла, а где-то выше, где вот можно ее обработать. И вам нужно
ее передать наверх. И вот смотрите, здесь мы пользуемся тем, что у нас есть структура,
что координаты в исполнении программы представлены Callstack.
И тут возникает механизм исключений. Исключения позволяют передать ошибку до места обработки,
при этом скрыть всю внутреннюю механику. Это ведь, ну я вот говорю пока про довольно абстрактные
вещи, которые как-то с конкарнцией не связаны, но вот сейчас их нужно связать хотя бы вот формально.
У нас была проблема со стоп-токенами, что мы их таскали вручную. Вот, а потом мы подумали,
что можно как-то хитрее сделать. И вот сейчас с исключениями та же самая история. Не нужно таскать
ошибки вручную, можно довериться runtime, который сам пронесет ошибку в нужное место, потому что
есть структура. И что самое важное, за счет того, что у нас есть структура, за счет того, что у нас
есть деструкторы, то вместе с обработкой, вместе с передачей этой ошибки выше, мы сможем и ресурсы
освободить. А нам это важно. Мы говорили, что нам нужно обеспокоиться про ресурсы, когда мы
отправляем там два параллельных запроса. Вот exception. Механизм, конечно, несовершенный, у механизма
большой overhead. Вы про это знаете, что некоторые проекты оптимизируют exception и не используют их
вообще. Вот Google стал гадить, что они запрещены. Но сейчас вопрос не о максимальной эффективности,
а о том, что структура позволяет такие вещи делать, скрывать эту внутреннюю механику,
от пользователей делать прозрачной все это. Делать ее прозрачной. А теперь, собственно,
имея этот контекст, можно перейти к нашим баранам, а именно к Go. Вот в чем проблема Go2? В том,
что структура передачи управления становится какой-то произвольной. Go — это такой асинхронный
Go2, где мы продолжаем сами бежать, но просто запускаем еще какой-то асинхронный управление,
асинхронный поток, который там тоже как-то дальше двигается. Совершенно хаотично. Почему это проблема?
Потому что вот в этом Go могут возникать ошибки. И ошибки, когда мы что-то распараллеливаем — это
вообще беда. Потому что представьте себе, что вы пишете обработчик запроса, где вы параллельно
задаете два подзапроса в разные сервисы на разные машины. А дальше вам нужно дождаться оба этих ответа.
И, допустим, вот запросы тяжелые, они долго работают, отнимают какие-то ресурсы у подсистем,
но оказывается так, что вот в поддереве А что-то пошло не так. И оттуда прилетела... и там
случилась ошибка. Что бы мы хотели сделать? Мы бы хотели отменить B. Ну, то есть смотрите,
дело немного сложнее. Вот я на этих рисунках говорил, что вот просто либо сверху отменяем,
либо снизу собираем результаты. Но вообще-то бывают и более сложные сценарии, когда у нас
просто где-то в середине нашего графа возникла такая ситуация, что вот здесь возникла ошибка,
и поэтому здесь нужно отменить. То есть отмена, она случается не прямо в корне. То есть она может
случиться в корне, разумеется, но не обязательно там. Она может случиться где-то здесь. Точнее,
она логически может случиться где-то здесь, потому что вот тут отменится... тут случится ошибка.
Но нужно же как-то вот из ошибки здесь, в этом поддереве, получить отмену здесь, в этом поддереве.
А для этого нужно воспользоваться той же самой идеей, что была здесь, а именно структурировать
нашу асинхронность. Вот в таком графе всегда очень просто всё. Есть точка входа и точка выхода.
Вот чтобы там в середине не случалось, есть одна точка входа, и потом всё это как бы
смыкается. Даже если есть развилка логическая, то всегда есть один выход после неё. Или вызов
под программу. Мы хотим сделать следующее. Мы хотим сделать то, что называется structured
programming, а мы сейчас хотим structured concurrency. Собственно, это тема нашей лекции. Мы хотим,
чтобы если что-то распараллеливается в нашей программе, то дальше обязательно была бы точка,
где был бы написан join. То есть если мы что-то запускаем параллельно, то мы в будущем обязательно
явно дожидаемся завершения этих параллельностей. Если мы запускаем файбер, то мы должны явно
сделать join всегда. Если мы запускаем три файбера, то мы всегда должны сделать join всех трёх файберов.
Поэтому мы го хотим запретить в принципе. Почему это важно? Смотрите, давайте сначала на примере
фьюч. Тут сразу всё станет понятно. Вот у нас есть комбинатор all. Давайте я покажу пример сейчас.
Вот у нас есть два RPC вызова параллельных, две фьюча. И вот есть два кода. Дожидаемся синхронно одного
ответа, дожидаемся синхронно другого ответа. Блокируем, останавливаем файбер. А есть вот такой код,
где мы сначала строим одну фьючу из двух, а потом синхронно дожидаемся её. Вот выглядит так как будто
бы одно и то же, потому что мы дожидаемся в любом случае двух ответов. Какая разница как, да?
Зачем нам лишнее фьюча? С точки зрения успешного сценария разницы нет. А с точки зрения сценария,
где возникают ошибки, разницы есть. Почему? Потому что если эта операция тяжёлая, а здесь возникла
ошибка, то мы в любом случае эту операцию завершим. А если бы у нас был комбинатор all,
который и является таким join, то есть точка, где мы соединяем. Вот мы здесь сделали что-то
параллельно, разветвили граф, а в эти точки мы его соединяем обратно. И вот в этом комбинаторе мы
можем написать вот такую логику. Если из-под дерева А прилетела ошибка, то с одной стороны мы её
пропагетим наверх, ну потому что all разломан, а с другой стороны мы можем отменить другого ребёнка,
который всё ещё работает. И если посмотреть на код, как это можно написать в комбинаторах,
то там буквально так и будет написано.
Файберы, фьючи, комбинатор, all. Вот, пожалуйста, если возникла ошибка, то я с
одной стороны отправляю её наверх, а с другой стороны я отправляю сигнал отмены вниз.
Очень красивый код получается, он буквально отражает эту картинку. А если у нас комбинатор first
off, то похожая история. Если мы получили хотя бы один результат, нам второй уже не нужен, и мы
отправляем отмен. Вот, и можно этим всем воспользоваться и написать уже пример.
Посмотреть на пример.
Вот first off.
Секундочку.
Почему... А, я написал где-то комментарий, он теперь пересобирается в библиотеку. Понятно.
Я здесь запускаю, получаю две фьючи, которые делают какую-то работу в трейдпуле, спят там
периодически секунду и проверяют стоп токен. И я говорю на этих фьючах first off, а потом дожидаюсь
синхронно. И вот этот код, он мог бы работать... Ну, он будет работать, понятно, как бы время
меньшее из двух задач. Здесь мы делаем спин три секунды, здесь мы спим десять секунд, в
лучшем случае. И у меня в конце кода написано wait idle, то есть я все-таки дожидаюсь всех запущенных
задач. Но, тем не менее, код будет работать только три секунды, потому что первая выполнится эта
фьюча, она заполнит результат, и после этого set value в комбинаторе first off, через комбинатор,
который стоит за этой фьючей, отправится сигнал отмены в эту операцию, и она тоже отменится,
и вычисления десять секунд идти не будет. Ну, представьте себе в этом месте два RPC вызова и
вот какие-то развесистые графы в распыленной системе, все это понятно.
Сейчас, подожди, здесь проверка вообще явная. Здесь мы явно проверяем.
Здесь никакой скрытой механики нет. Ну ладно, к концу минут пять и соберется все это. Пока это,
например, запускается, речь про файберы. Вот статья про structured concurrency, вот эта вот
знаменитая, она не про фьюч, тут про фьюча ничего нет, она про файберы. Ну, точнее, про
про гоуту, то есть про такую, про там крутины, про файберы, и тут вводится понятие nursery,
nursery или yasli. Идея такая, тут даже картинка есть, сейчас я ее покажу. Все, что мы запускаем в
nursery должно, то есть nursery, он связан с некоторым скопом лексическим, то есть мы в блоке
создаем nursery, при выходе из блока мы должны явно дождаться завершения всех активностей внутри
nursery, всех файберов, которые мы там запустили. То есть всегда мы дожидаемся файберов. Это после
его выглядит довольно неинтуитивно, но да, вот кстати, можно, например, запустить теперь и
посмотреть, что он работает. Там 3 секунды 301, 302, 303, 304. Готово. Не 10 секунд. После go это выглядит
довольно неинтуитивно, что мы дожидаемся каждой запущенной активности, но вот нам говорят,
это structured concurrency, так нужно делать. И как это будет работать, как это будет выглядеть сначала?
Вот так вот. Мы берем nursery, в нем запускаем две задачи. Одна из них работает 2 секунды,
потом взрывается, другая работает бесконечно. И вот мы говорим nursery join. За счет этого nursery
опять пример будет работать 2 секунды, потому что этот файбер взорвется, в нем вылетит ошибка.
Эта ошибка пролетит до самого корня файбера. Нет, не сюда. Вот сюда она пролетит. То есть мы
вызвали здесь крутина резюм, и в этом резюме случился exception. Этот exception пролетел сюда,
это был не cancel, и нам вроде нужно упасть. Но это раньше бы мы упали, если бы просто файбер
запущенный через go, мы бы упали. Но теперь мы не знаем, что делать, и мы поручаем это решение
супервизору. Супервизор решает, как обработать нашу ошибку. Когда мы запускаем файбер, мы ему
отдаем супервизор. Это компонент, который следит за файберами и обрабатывает их завершение,
либо успешное, либо отмененное, либо ошибка. И nursery для файберов является супервизором. И что там
написано? Ну, во-первых, когда мы... во-первых, у nursery есть stop token. Точнее, у nursery есть stop
source. Все файберы, которые запускаются в nursery... вот мы запускаем... аккуратнее... вот мы запускаем...
запускаем... очень медленно... вот мы запускаем файбер. Мы строим токен от своего stop source. И
если вдруг файбер решит сломаться в нашем nursery какой-то, то в этом случае мы на stop source
этого nursery скажем request stop, и он отменит все файберы, которые в данном скопе выполнялись.
И тут можно писать какие-то, не знаю, более сложные ивристики. Писать там, не знаю,
буквально... почему супервизор? Эта идея, вообще, она из... откуда? Знаете ли вы, откуда она?
Есть ли у меня должна быть где-то хорошая ссылка?
Из Erlang, конечно. Потому что Erlang — это язык, который разрабатывался с идеей, что вот нужно
думать про отказы устойчивость прямо на уровне там дизайна самого языка, дизайна конкурентности в
нём. И вот супервизор — это компонент, который наблюдает как бы за дочерними подзадачами и
перезапускает их, если они ломаются. Вот у нас nursery отменяет, а могла бы перезапускать. Ну,
то есть вот можно любую логику писать. И опять, у нас есть join — это nursery. nursery — это объект,
который представляет собой join запущенных параллельных файберов. И за счёт того,
что этот join есть, мы в нём можем покэнцелить соседей.
Да, давайте я вот ещё пример не показал. Покажу его. Это... ну, можно делать это рекурсивно. Это ладно.
Можно...
Можно делать вообще сложные вещи. Вот давайте я покажу, как всё это можно комбинировать. Вот всё,
что я рассказал, прости, можно комбинировать в один пример. Но он довольно замороченно написан,
не слишком аккуратно. Но я объясню, что происходит здесь. Смотрите, у нас есть пара future promise.
Мы здесь создаём задачу в пуле, где мы что-то вычисляем, пока не отмениться. Потом мы на эту
future наворачиваем с помощью zena продолжение. Потом мы строим nursery. В нём мы запускаем файбер,
который синхронно блокируется в ожидании future. То есть у нас есть такие разные точки связывания.
Есть zen, есть await, есть nursery. А потом мы говорим nursery cancel. И что происходит?
nursery cancel cancels its stop source. Этот stop source, когда мы спаунили файбер, этот stop source
породил токен, который мы отдали этому файберу. Когда мы говорили файбер await future, то... ну,
это не здесь написано, это написано в коде await для future. Когда мы ждали future, то мы, подписавшись
на возобновление себя, подписавшись на future, чтобы возобновить себя, мы после этого заодно
склинковали собственный токен с stop source future. Вот. Этот stop source future был склинкован с stop state
future, был склинкован со stop state future f1. И в конце концов это всё здесь проверялось. И вот когда я сделал
cancel, то я вот по такой цепочке спустил отмену h вот сюда. Эта операция завершилась. Она закомплетила
эту future. Эта future закомплетила эту future. Эта future отпустил этот файбер. Этот файбер наконец
завершился, и в destructory nursery завершился join. И пример доработал. Вот. На мой вкус довольно
впечатляющая конструкция, потому что в этом коде нет никаких аннотаций для отмены. Нигде
нет явного пропагейта. Вот вся механика скрыта, всё работает. Ну, тут можно было ещё first-off и
какие-то навернуть. Ну, в общем, всё это работает абсолютно прозрачно для пользователя, и ему нужно
лишь поддержать отмену там, где он готов к этому. В смысле там, где он готов что-то отменить, он
проверяет токен, и... А дальше всё распространяется автоматически. Ну вот, всё поотменялось.
Пример завершился. И ключевая идея здесь... Ну, тут... Что? Хочешь закончить уже, да? Пять минут
осталось. Пять минут осталось, честно. Но я не хочу это разрывать. Это очень сложный доклад,
но рассказ, он очень долго у меня выдумывался, я хочу довести его до логического конца честно,
пять минут. Какие ключевые идеи здесь были? Ну, во-первых, мне кажется, что вот эта идея довольно
любопытна, что нужно посмотреть на фьюч и на промесы как на просто двойственную сущность и вот
как на две системы противонаправленные кроме нас. А вторая идея в том, что вот нужно такую картинку
понять, что вот не просто сверху вниз и снизу вверх, а вот как-то более сложно течут эти сигналы
по графам. И для того, чтобы... То есть что Structural Concurrency нам говорит сейчас? Что если у вас за
любой развилкой есть join, то где бы ошибка не возникла, она распространяется наверх,
распространяется... Она, распространяясь наверх, распространяет сигнал отмены и в стороны. И вот
поднимаясь как бы от ошибки вверх до корня, вы гарантированно покроете отменами весь граф.
За счет того, что у вас есть join, и вот ничто не потеряется. Вот где бы в графе ошибка не возникла,
весь граф может автоматически отмениться с помощью вот этих норсерей и комбинаторов. Очень красивая
идея, которая берется совершенно из глубокого прошлого. Тут нужно было это увидеть, это почувствовать,
связать. Идея очень простая, очень естественная, но как бы придумана была она не сразу. Есть чудесная
статья, в которой это написано. Это Structural Concurrency. Честно говоря, я читал ее давно, ничего не понял,
потому что акценты там как-то по-другому совершенно расставлены. Но попробуйте,
прочитайте. Мне кажется, что ключевые идеи... Вот нужно вот такие картинки нарисовать. Нужно
сделать сначала Future, понять вот это, потом сделать для Future вот такие вот комбинаторы,
которые умеют такие штуки делать, а потом уже идея вот здесь, она станет полностью понятна.
И эта идея очень мощная, и она повлияла буквально на весь современный мир, потому что... Ну смотрите,
вот DesignDoc файберов, которые делают в джабе. Делают Structural Concurrency. Вот DesignDocSwift.
Делают Structural Concurrency. Ну или сделали уже, по-моему. Есть очень классный доклад Романа Иризарова
про Kotlin, про то, как они делали конкуренции, карутины. И он рассказывает не просто, к чему они
пришли, а вот то, как они над этой задачей бились. И вот в это же время был придуман термин для нее,
и вот у них все сошлось, в общем. Это то, что делать научились совсем недавно, и вот сейчас во всех
местах. Ну, как недавно. Вот в Скале сделали давно уже. Вот в IT, в Яндексе тоже Future's Council,
кажется, давно. Ну вот как бы лексику и какое-то распространение этой идеи получила совсем-совсем
недавно. А идея кажется очень важной, потому что без нее, в самом деле, невозможно представить
себе некую продакшн. Ну что, мы закончили. Спасибо большое, что вы пришли сегодня,
послушали. Для меня это очень важно. Я долго это все переваривал сам. Если было понятно, то здорово.
Значит, у нас получилось.
