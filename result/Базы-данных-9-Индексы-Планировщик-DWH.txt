Наша очередная лекция по теме баз данных. Закрываем с вами по большому счету вопрос
использования SQL. Вервение SQL, прошу прощения. Вопрос использования Postgres, в принципе,
реалиционных с УБД. Ну, скажем так, основные. Много, конечно, каких тем, наверное, осталось за
бортом, возможно, финальной лекции, которая случится. Вот-вот какие-то вещи. Проговорим слух,
типа, например, object relational, mapping, использование каких-то более продвинутых. А утилит,
поставляемых в комплекте с Postgres. Ну ладно, не будем забегать вперед. В общем, у нас сегодня
тема это индексы и планировчик запросов и хранение больших объемов данных. На примере
хранилищ данных. Постараемся тоже сегодня затронуть. Поехали. Индексы. Ну, в принципе,
очевидно, что такой индекс. Все мы с вами пользовались, как минимум, книгами,
которых есть, соответственно, предметные, алфавитные, указатель-указатель имен. Вот индексы
выполняют аналогичную функцию, способ определенной структуры данных, позволяющая быстро находить
расположение нужной информации. Postgres поддерживает некоторое количество индексов из коробки. Это
что называется? Основной список. Основной перечень на слайде приведен. Но, в принципе,
он допускает расширение в ответвлении, скажем так, Postgres для больших данных,
которое называется Greenpalm. Идет активная разработка индекса для колончатых структур
данных. Postgres на данный момент пока не поддерживает в качестве стандартной такую возможность. Но,
возможно, когда-нибудь войдет соответствующий индекс и в основной дистрибутиф Postgres. Всего
6 поставляемых типов индексов. По умолчанию это B деревья. И дальше идут все менее и менее очевидные
и понятные структуры. Давайте посмотрим на синтаксе. Довольно простой, известная нам
команда Unique. Прошу прощения. Конечно же Create, а индекс также аналогично используется
команда для удаления индекса или DropIndex. То есть те основные операции, которые мы с вами изучали в
самом начале курса для операций Data Definition Language в рамках подмножества Data Definition Language языка
SQL. По сути дела и применяем мы к другим объектам. Не только к таблицам или к представлениям,
например, но к индексам в том числе. Как вы видите, довольно тоже разведленный синтакс
предоставляет спецификация Postgres. Но по большому счету нам на данный момент для понимания
требуется упрощенный вариант, приведенный внизу слайда. Это самая основа. Мы задаем
директивы CreateIndex. Указание индекса создать, создаем его имя. После предложения on указываем
таблицу и можем также специально указать тип, какой индекс конкретно будем использовать на
том или ином столбце. Конечно, using тип можно опустить по умолчанию будет бы дерево. Пройдемся
кратенько по каждому индексу. Что каждый из них означает и для чего предназначен. Б-деревья
базовый простой индекс могут работать в условиях на равенстве и в проверках диапазонов с данными,
которые можно отсортировать в некотором порядке. В следующем буллите указана базовая операция,
с которой индекс B3 работает по умолчанию. Также можно использовать эти индексы и с операторами
сравнение по шаблону, но есть проблема, что по умолчанию B3 будет работать только по умолчанию
с ASCII символами. С символами классическими, локальный язык ASI, англоязычный алфавит и
для настройки работы B3 индекса на другие варианты локалии необходимо проводить некоторые
оптимизации, но это уже более техническая информация, не будем на ней останавливаться.
Индекс hash тоже из названия понятно, что происходит при индексировании. У нас получается 32 битных
hash код для значений в столбце и поскольку это hash здесь у нас понятно будут только простые
условия равенства, мы не можем осмысленно совершать какие-то иные операции с данными индексами.
Гист индексов это не индексы как таковые, не какой-то конкретный тип. Система как раз
наоборот выберет представление самостоятельно, но задать системе из какого под множество вариантов
индексов выбирать мы можем. Игист индексы семейство или как еще в литературе указывается
инфраструктура позволяет нам индексировать более сложные комплексные данные и вот например
это геометрические объекты, полнотекстовый поиск, поиск по массивам, в том числе по массивам JSON.
В зависимости от настроек можно распространить индекс для работы с большим количеством
операторов, в зависимости от настройки индекса, в зависимости от типа данных.
Ну вот пример для двумерных геометрических данных приведен на слайде, но если вы обратитесь к
спецификации, там будет прям очень большая таблица, у строк там наверное мне кажется штук 20,
вариант операторов в зависимости от различных настроек и типа данных.
Дальше это SP-гист и в общем-то это под множество гист индексов в некотором смысле.
Поддерживается индексация данных структурированных по принципу разделения
пространства, то есть если у нас нет пересечения внутри наших данных,
ну условно да понятно, что мы здесь мы надо понимать, что речь идет о таком не табличном
представлении, а уже представлении что ли логическом того, чтобы храним в возе данных.
Вот если у нас с точки зрения логики хранения данные разделяются на какие-то изолированные
под множество классы, то SP-гист теоретически должен отрабатывать быстрее, но в принципе
use-кейсы для SP-гист аналогичны тому, что приводят, что были приведены для индексов типа гист,
но с условием, что если данные не пересекаются, то по идее SP-гист у нас будет работать быстрее.
GIN, Generalized Inverted Index, ну здесь те из вас, кто знаком с системами текстового поиска,
я думаю для вас инвертированный индекс структура близко и понятная, то есть по сути дела это то,
что та структура, которая позволяет нам искать по значениям, по отдельным значениям
входящим в множество, само это множество, то есть по под множеству некоторого множества мы можем
найти, ну да само множество, пример яркий простой, это когда вот по ключевым словам,
просто по словам ищем некий документ и если мы правильно определили специфику конкретного
документа для полнотекстового поиска и задали правильный набор вот этих вот компонент нашего
искомого документа, то мы его, причем отличительных компонентов, уникальных, мы его сможем довольно
быстро и эффективно найти, если мы ошиблись задали какие-то, опять же применительно к документу
шумовые слова, то мы его найдем с меньшей долей вероятности, нам потребуется дорабатывать наши
запросы. Зачем нужен ПЭШ, если по сути это в каком-то смысле просто неправильные реки, конечно, но очень близко, потому что мы же только на равенстве, никакой подъездной информации, текстов.
Ну да, не углубляясь скажем тогда во внутреннее представление, просто фактически у нас
он будет работать быстрее, чем просто, но на больших объемах данных, понятно, да, если у вас там 100 или 1000 записей, индекс вам возможно и не нужен, в зависимости правда длины записи, но не важно, грубо говоря, там для тысячи записей индекс вам не поможет найти быстрее, чем без индекса, ну хэш индекс, но для большего количества записей просто хэш индекс будет работать быстрее, чем голое равенство
столбцам без индексирования, то есть это внутренняя оптимизация и ну там есть техническая поднагодная, но просто она уже как бы совсем выходит за рамки нашего курса, просто вот по факту на поверхности для работы с УБД, если у нас большой набор данных, набор записей и мы прохэшируем все это, сделаем индекс с типом хэш, у нас запросы будут отрабатывать быстрее, вот собственно и все.
Поэтому, да, такой ответ может быть не очень конкретный с точки зрения технической стороны вопроса, но, честно говоря, я сейчас даже вам вот не воспроизведу технические именно особенности реализации, но по факту работает это вот так, как я сказал, он будет работать быстрее при его наличии,
чем голое сравнение прямых, явных значений, содержащихся, условно говоря, в ячейке таблицы, еще тип индекса это Брин, тоже кратенько про него просто скажем, что предназначен для работы с большими данными и с условием, что данные в таблицах относительно упорядочены по значению индексированного столбца,
ну, да, там определенная неупорядоченность допускается, но, грубо говоря, у нас все равно должно быть, должен быть определенный тренд, что в начале таблицы хранятся наименьшей записи, в конце наибольшей, грубо говоря.
Ну, не будем, наверное, подробнее об этом говорить, потому что тоже такие совсем, может быть, технические детали, просто для вашего общего понимания, иметь в виду надо в первую очередь, это, конечно, B3, что работает по умолчанию, hash и, может быть, гнист или джин для того, чтобы с более специфическими типами данных работать.
Планировщик запросов. Еще одна интересная тема, почему об этом говорим, собственно говоря, вот почему. У нас, как вы помните, мы на первой лекции об этом говорили, есть такой, условно говоря, жизненный план запроса, как он у нас отрабатывается в самой базе данных.
Причем план не с точки зрения того, как у нас Select работает, не с точки зрения логики, а выполнения SQL-команда, с точки зрения отработки сервером с процедур, которые физически происходят с базой.
И у нас сервер базы данных перед тем, как непосредственно выполнить запрос, он проводит серию операций, направленных на то, чтобы минимизировать итоговое время выполнения запроса и наименьшим образом нагружать систему с точки зрения операции чтения и потенциального блокирования тех или иных строк или вообще таблиц.
По отношению к другим параллельным запросам. И что делает, собственно говоря, сервер, когда мы, как пользователь, посылаем запрос? Ну, во-первых, это разбирает запрос лексически, то есть выявляет все вхождения,
все вхождения, как и написано на слайде, все вхождения, грубо говоря, слов и предложений, слов и фраз, а далее к всем запрос. Это ключевые слова для SQL или LPG SQL, хотя, конечно, с процедурными языками планировочек работает хуже, повторюсь.
Ключевые слова, строковые и числовые литералы. Далее запрос разбирается синтоксически, то есть мы убеждаемся, что запрос, ну не мы, сервер, конечно же, убеждаются, что запрос соответствует грамматике языка, и на выходе после вот этих вот двух, работы двух этих программ анализаторов, в принципе, после каждой, после первой тоже уже появляется синтоксическое дерево.
Дерево, первое запроса в первом приближении, и результат, в принципе, это некое абстрактное синтоксическое дерево, где узлы являются логическими операциями, еще и операциями на уровне SQL.
Далее запрос разбирается семантически, уже начинается поиск релевантных отношений в базе, иных объектов, участвующих в запросе, и результатом разбора уже будет синтоксическое дерево, дополненное указанием имен отношений, указанием каких-то иных объектов и типов данных или иной информации.
Далее запрос может трансформироваться по правилам, либо используемым по умолчанию, входящим в стандартную компонентную структуру, либо мы теоретически, как администраторы и разработчики, можем переписать правила трансформации, если мы понимаем, что мы делаем, если нам это действительно нужно, конечно же.
Ну, так или иначе, происходит трансформация запроса, то есть у нас подставляется в текст исходного нашего запроса, грубо говоря, подставляется в текст, по сути дела дорабатывается дерево синтоксическое, но для нас можно это воспринимать как доработку текста.
В текст нашего запроса подставляются запросы, эквивалентные каким-то представлением, например, какие-то подзапросы могут раскрываться, и таким образом, полный такого рода запроса уходит на планирование, уходит планировщику.
Планировщик запросов тоже выполняет целый ряд операций, причем довольно сложных операций, связанных с оценкой стоимости выполнения.
Результатом в процессе работы планировщика строится дерево плана, а вернее даже деревья, ну, по большому счету, наверное, можно сказать лес планов, и далее планировщик запросов пытается некими какими-то способами определить,
какой из вариантов планов запроса нужно отправить на сервер для дальнейшего исполнения. Для этого используется, условно говоря, стоимость оптимизатора, но, по сути дела, что происходит?
Планировщик, как уже сказано было, строит несколько планов выполнения запроса, он определяет их условную стоимость, она зависит от объемов данных, от ресурсов процессора, нагрузки на него, и выбирает наиболее оптимальный план из них.
Но оптимальность плана не гарантирована, потому что у нас планировщик запроса работает не со строгими правилами определения, он не строит все планы, на самом деле.
Там планы растут, их количество растет экспоненциально, и даже уже на сравнительно простых запросах используются уже специфические стратегии для того, чтобы минимизировать число планов и уже работать на каком-то подмножестве из всех возможных планов.
Так вот, у нас планировщик занят выбором наиболее оптимального плана, при этом оптимальный план ищется на подмножестве построенных планов, строится это под множество использованием некоторых евристических подходов.
И более того, второй аспект, который нам не гарантирует, из-за которого СУБД не может гарантировать выбор наиболее оптимального варианта, это зависимость от стратегии, прошу прощения, от статистики нашей базы.
Как мы с вами говорили ранее, когда рассматривали язык определения данных и язык манипулирования данными, особенно язык манипулирования, у нас при операции дилит, в частности, как пример наиболее яркий, у нас при операции дилит не происходит физического удаления строк,
соответственно, статистика по нашей таблице конкретной, из которой мы что-то удаляем, не меняется при использовании команды дилит.
Соответственно, если мы в таком случае не проведем, не используем другую команду, мы об этом тоже говорили, это команда Wacom, если мы ее не используем, мы в таком случае не сможем обновить статистику по конкретной таблице,
и у нас планировчик будет пытаться оптимизировать наши запросы, выбрать наиболее оптимальный план, исходя из неверной статистики, и соответственно, понятно, что это влечет потенциально неверный выбор варианта плана запроса.
Вот такой пример громоздкий с обращением к материалам второй, третьей лекции.
Зачем мы вообще будем использовать планировщик, заглядывать к нему под капот, вернее, скажем так, за тем, что мы можем посмотреть вообще, что у нас происходит с временем выполнения, найти какие-то бутылочные горлышки конкретные, не просто абстрактно понимать, что у нас запрос отрабатывает почему-то пять минут вместо того, чтобы выдавать результат.
В течение 30 секунд мы поймем, где конкретно у нас происходят проблемы, и соответственно, понимая это, мы уже можем пытаться корректировать запрос, пытаться корректировать, может быть, правила трансформации, пытаться корректировать, может быть, статистику базы данных, если мы это давно не делали, давно не обновляли ее, ну и использовать какие-то иные варианты, грубо говоря, не знаю.
Если у нас все оптимизировано, понятно, мы будем окидывать мощности, разделять информацию данных горизонтально, ставить новые сервера, новые узлы и так далее.
Ну, так или иначе планировщик запросов поможет нам понять, что происходит под капотом.
Как мы к нему можем обратиться? Ну, мы можем обратиться SQL запросом, можем, кстати, да, это опять же, можем через утилиты обращаться, ну ладно, это отдельная тема.
Можем использовать синтаксис SQL запроса, Explained operator, Explained command, она, правда, не входит в стандарт, но, по сути дела, она довольно проста и здесь сложно ошибиться с юниоризмом.
Перед интересующим нас оператором мы пишем Explained, указываем, возможно, какие-то параметры.
Параметры, в принципе, больше, на слайде приведено два, Analyze и Overbose. Analyze подтягивает, соответственно, более современную статистику.
Overbose может предоставить чуть больше полезных данных в рамках запроса по умолчанию, и то и другое стоит на, и то и другое стоит в значении false.
Соответственно, мы работаем с тем, да, что, с тем, что есть у нас на данный момент, на текущий момент в базе.
Ну и пример, на данный момент, на данный момент, на данный момент, на данный момент, на данный момент, на данный момент, на данный момент, на данный момент, на данный момент.
С тем, что есть у нас на данный момент, на текущий момент в базе. Ну и пример, приведен, соответственно, результат выполнения.
Вот у нас query plan, да, появляется, появляется запись query plan, и некоторая строка scan on foo, и какие-то значения в скобках, и что вообще все это значит, да, что происходит.
Надо понимать, в первую очередь, вот что. Во-первых, sec scan – это сокращение от sequential scan, последовательное сканирование, базовая, наверное, можно сказать, операция, да, в простых каких-то запросах,
типа того, что приведено на рисунке, в скобках проведена условная, условная информация о статистике запроса.
И что значит условная? Это не значит, что она неверная, да, но это не значит, что она проведена абсолютно точная, или, например, с привязкой к миллисекундам, условно говоря.
Ну да, об этом, наверное, поговорим чуть-чуть попозже, через несколько слайдов. Что здесь еще? Это у нас, по сути дела, вот эта вот запись – это представление нашего деревозапроса.
И то, что мы видим, это у нас, по сути дела, один узел нашего дерева. Узлов может быть больше, вот он у нас, по сути дела, один, потому что у нас одна операция – select выбрать все данные из одной таблицы.
И вот мы последовательно scan, последовательно сканируя таблицу foo, выбираем все возможные данные, которые там есть. Поэтому, несмотря на то, что это дерево, по сути дела, вот одной срокой оно представлено.
Давайте создадим тестовую таблицу и немножко попробуем погонять по ней запросы и посмотрим, что происходит с нашим деревом планом.
На тестовой таблице какие там дополнительные узлы появляются или, может быть, исчезают. Строим таблицу, рандомно генерируем текст какое-то, ну текстовые значения.
Рандомно генерируем один миллион значений и, соответственно, все это записываем в нашу двухколончатую таблицу.
Что у нас получилось? Мы читаем из нее, ну здесь все довольно просто. Читаем все данные из нее, получаем все тот же один узел – sequential scan.
Последовательное сканирование блок за блоком расположенных на диске данных считывает наш запрос.
И у нас, как вы видите, в значении rows вот здесь вот появляется число, соответствующие числу наших строк в таблице.
Значение ширины – это условное значение, значение длины строки на диске, грубо говоря. И значение cost, но об этом мы сейчас тоже с вами поговорим чуть попозже.
Да, вот sequential scan, что делается он-фул, какая таблица читается и, собственно, что такое cost.
Как я уже говорил, это не время, это условные значения. И что это значит? Первая часть вот этого диапазона, цифры стоящие слева – это затраты на получение…
Ну, грубо говоря, первой строки для простоты можно считать так. Если говорить чуть-чуть точнее, как бы погружаясь вниз, что ли, на уровень ближе к реализации – это затраты на начало выполнения операции.
То есть мы выполняем операцию, сразу стартуем с места в карьер, и в конкретном случае здесь мы действительно получаем первые строки за 0 единиц условного времени.
И последнее число – это, понятно, затраты на получение всех строк. Вот сколько затратит система условных своих тактов единичек времени.
Ну, не тактов процессора, повторюсь, а вот некого такого внутреннего времени выполнения в рамках СУБД.
Роуз, как вы сказали, – это число срок, и да, важно иметь в виду, что оно приблизительное, потому что мы вот здесь видим вот в этом параметре, видим результат на последнее выполнение операции «Vacuum», это последнее обновление нашей таблицы.
И если мы забыли там обновить данные, если что-то мы не учли, какие-то удаления, например, то, конечно, значение в строк будет у нас неверное.
И средний размер одной из строки в байтах, соответственно, значение последнего параметра.
Что у нас произойдет, если мы попробуем изменить нашу таблицу и добавить в нее 10 новых сгенерированных данных?
Почему у нас не произошло изменение строк? Ну, то, о чем мы и говорили, потому что мы не провели…
Ну да, помимо «Vacuum» есть еще просто команда «Analysis», как справедливо завещано на слайде, ребят.
А можно отдельный оператор «Analysis», он тоже нестандартный, тоже можно им отдельно пользоваться.
И в данном случае тоже так же статистика у нас подтянется для таблицев «U».
Вот, как вы видите на слайдах, на слайде значение для строк у нас изменилось, добавились 10 строк новых в нашу статистику.
Ну а если точнее, в таблицу, которая хранит статистику у нашей таблицы «U», в системную таблицу данных.
Статистику мы можем посмотреть напрямую, и таблица данных со статистикой, она системная, она имеет наименование.
Ну если быть точнее, там даже более сложная ситуация, там с таблицами вот системными они могут быть, внутренних могут быть представления какие-то, они сами могут быть представлениями.
И вот этот вот, казалось бы, простой запрос, на самом деле там может сильно очень ветвиться под капотом и вызывать много-много разных данных,
для того чтобы подтянуть результаты и выдать в конечный запрос конкретного пользователя.
Ну ладно, это такое лирическое отступление небольшое.
Давайте посмотрим, что у нас произойдет, если мы, например, добавим параметр «analyze».
Вот у нас в данном случае добавилось немного, чуть больше данных, и у нас запрос выполняется реально.
Что нам позволяет это посмотреть? Вот у нас появилась execution time в миллисекундах, и появилось planning time в миллисекундах.
Planning time – это время планирования запроса, сколько стоит нам планирование запроса системой execution time,
сколько стоит выполнение реальной запроса системой, и появилась дополнительная информация в скобках,
то есть реальное время в миллисекундах, затраченное на получение первой строки и всех срок соответствует.
Ну вот у нас произошла такая конверсия из условного времени в реальное.
Но как было написано на предыдущем слайде, не забываем, что нам нужно, если мы делаем explain analyze, то обязательно откатываться,
чтобы наши данные не изменились. По сути дела, когда мы explain analyze используем, мы тестируем наши запросы, чтобы наши данные не изменились.
При такого рода тестирования не забываем откатываться.
Роуз – понятно, реальное количество. Loops – сколько раз пришлось выполнить операцию sex scan, по одному запросу, в одном цикле мы все выбрали.
Время planning time и execution time – об этом мы уже с вами сказали.
Посмотрим, что будет, если нам потребуется какое-то условие выборки.
У нас, во-первых, новые узлы в нашем дереве появляются. Это узел filter с его значением.
И указание на количество строк, которые были удалены нашей фильтрации – это 510 строк.
Потому что у нас c1, наш индекс должен быть больше 500, а мы добавляли еще 10 значений с индексом от 1 до 10.
Это условный индекс, в смысле некого поля идентификационного.
Но мы не накладывали никаких ограничений, поэтому от 1 до 10 у нас значения повторились дважды.
Обратите внимание, повторюсь на дополнительный узел в дереве.
Давайте добавим индекс, и что у нас происходит?
У нас происходит вот что. У нас остается все то же самое, но у нас сильно поменялось время выполнения запроса.
Вместо 693 мс у нас всего 180 мс. Но нужно иметь в виду, что у нас здесь осталось много строк.
То есть мы из миллиона строк откинули только 510 и обрабатываем 999 500 строк.
Причем здесь обратите внимание, в нашей технической информации, которая без параметра analyze появляется,
у нас число строк не вполне корректное, и поэтому тоже нужно относиться к этому параметру rows с некоторой долей условности,
потому что не всегда выдается точное значение при усложнении вариантов запроса.
Почему sequential scan? Мы можем принудительно запретить sequential scan,
и тогда у нас появятся новые иные узлы в нашем дереве.
Появится index scan как метод выполнения запроса, как метод проходки по нашей табличке.
И здесь как раз как мы видим при использовании именно index scan у нас и при использовании index count,
то есть когда именно index отрабатывает при такого рода запросе лучше не стало,
потому что у нас для такого типа выборки, если мы будем при создании индекса еще использовать индекс напрямую,
то на самом деле операция обращения к индексу будет дороже, чем простое сканирование типа sex scan.
Теперь смотрите, у нас при этом планировщик, он не просто в некотором роде слепо следует каким-то очевидным правилам,
есть индекс, используй индекс, нет индекса, не используй индекса.
Что мы здесь сделали? Мы теперь выбираем мало строк, то есть у нас выросла селективность запроса,
мы специфицировали результирующий набор данных, который стал заметно меньше исходного набора данных,
в таком случае планировщик как раз отрабатывает, ну в данном случае может быть это не выглядит очень умного,
потому что миллисекунды сильно уменьшились, прежде прочения, он отрабатывает уже алгоритм корректно,
и он использует индекс scan самостоятельно, при том что мы enable scan опять включили и предоставили возможность ему решать.
И соответственно у нас сильно меньше стало, чем могло бы быть, сильно меньше время выполнения запроса,
из наших предыдущих вариантов связанных с sequential scan, изначально в 693 миллисекунды мы опустились до 0,201 миллисекунды,
при том что мы выбираем всего 510 значений, и без индекса соответственно это было бы сложнее,
но правда надо иметь в виду, у нас по сути дела последовательные значения в полиции 1, если бы они были рандомные,
ну наверное было бы поинтереснее, там были бы несколько иные значения, не настолько замечательные, как вот 201 тысячные миллисекунды,
было бы похуже, но все равно лучше, чем если бы был sequential scan, выбор 500 случайных значений из целого миллиода.
Давайте усложним, мы здесь добавим выборку по соответствию шаблону, у нас появляются новые узлы bitmap-hip-scan,
bitmap-index-scan, и что все это значит, ну bitmap-hip-scan это значит, что у нас планировщика самостоятельна,
ну во-первых, мы индекс построили по нашей колонке с текстом, поэтому у нас здесь индекс-scan происходит.
Что такое bitmap? Это построение планировщикам битовой карты запроса, ну не запрос, вернее, а данных по интересующим нас колонкам,
и в дальнейшем происходит просто сравнение вот этих вот битовых карт довольно простым способом,
ну просто буквально по битвой операции происходит между двумя строками, в данном случае строкой нашего запроса и строкой,
которые содержатся в столбце C2. Вопрос такой. Да. Вот мы сделали индекс по какой-то строковому статусу,
он будет сравнивать их дексографически, потому что молчание у нас там дерево, и там нужна операция сравнения.
Поэтому вопрос такой. Ну, дексографически, то есть что вы имеете в виду? Будет ли какой-то порядок сравнения строк?
Не, ну по идее он же нужен для дерева, он для индекса, ну индекс, которые по деревьям, как он их, или он придумывает порядок, если его нет, то что он делает?
Смотрите, он, ну у нас появляется иной порядок при B деревьях, то есть там не получится дексографического,
по сути дела, дексографически это было бы, ну нет, не дексографически точно, я понял, не дексографически точно, там будет немножко сложнее,
то есть он будет идти по узлам дерева, ну примерно, скажем так, я не то чтобы вот здесь глубоко погружался в реализацию такого рода операции, скажу вам честно,
но здесь наверное даже для нас как для пользователей с одной стороны нет какого-то, какой-то сильной разницы как происходит, как происходит поиск по индексу по B дереву,
а с другой стороны, ну представляете структуру, то есть структура B дерева это не структура лексиграфического словаря, лексиграфического порядоченности все-таки,
и здесь нет прямого соответствия, поэтому здесь будет вопрос как конкретно построено B дерево, по данному столбцу какие там данные вообще лежат, как они представлены будут в этом B дереве и так далее,
и соответственно будет порядки скодирования узлов дерева, дополнение, ну не дополняться до запроса, ну будет прохождение, не могу он наверное точнее, давайте так я оговорюсь,
по точнее вам сказать не могу, но это будет точно не лексиграфический порядок.
То есть как бы в общем, я просто про индекс не понял до конца, поэтому я постоянно спрашиваю, то есть в общем он как бы строит свое собственное B дерево и сравнивает уже как бы с ними, то есть ему не нужно знать, что эти строки они между собой сравниваются, он как бы даже для типов, которые не особо имеет смысл сравнения, он как бы сам его придумывает с помощью чего-то там.
И вопрос скорее с этим был связан.
Ну скорее всего, скорее да, чем нет.
Хорошо, давайте я в следующий раз наверно вернемся, посвятим этого минут 5-10, там прямо есть прямо утилита наглядная, ну такая демонстрационная, в свое время я натыкался, как B дерево происходит, такого рода поиск, но здесь скорее знаете какой момент,
а нам как пользователям, ну условно пользователям, как администраторам и разработчикам такого, может быть и не сильно важно какой конкретный порядок там идет, нам просто важно, что в данном случае это будет быстрее, потому что это индекс, потому что индекс у нас срабатывает быстрее.
Он для этого предназначен, у него другая структура, чем просто последовательная совокупность последовательных записей, ну и так далее, и так далее, и так далее.
Как конкретно? Ну хорошо, я понял, вернемся, затронем это в следующей лекции немного.
Так, давайте дальше видимся, посмотрим, что еще у нас появится, индексонный скан, если мы выбираем не все, а только полифильтрация и, соответственно, планировщик у нас дополнительно меняет наше сканирование, на сканирование только по индексу,
и теоретически это может нам выдать чуть больше, чуть больше прибавку на скорости.
Что вообще все это значит, да, собирая совокупность, собирая все, о чем мы только что проговорили, в совокупность.
Ну вот, варианты узлов, секс-скан, это вся таблица последовательная, индекс-скан, используется индекс для условия where, читает таблицу при отборе строк.
Битмэп индекс-скан, сначала индекс-скан, затем контроль выборки по таблице.
Да-да-да, но самое главное это битмэп, что у нас строится дополнительная промежуточная структура данных, битовые карты запросов, битовые карты строк, там битовая карта, вернее, условия, битовая карта
Каждые строки после сканирования по индексу и потом начинается операция по битовому сравнению, довольно быстрый, да, эффективный, но для построения битовых карт потребуется время.
С другой стороны, запросы можно делать более сложные, вот как мы смотрели по шаблону, выискивать строки.
И индекс-скан самый быстрый, считает только индекс.
Так, хорошо, давайте еще немножко посмотрим, удалим наш предыдущий индекс и посмотрим, что у нас происходит при изменении дополнения наших запросов какими-то дополнительными командами.
Вот у нас появилась сортировка по столбцу C1, и здесь мы видим из того, что интересно.
У нас изменились узлы, главный узел стал gather-merge, и он всегда идет с parallel, то есть у нас где-то будут параллельные процессы.
Gover, gather, соединение, объединение такое, это когда у нас результат параллельных процессов подтягивается в родительский процесс, и там происходит какое-то обобщение, ну не обобщение в данном случае, а операция соединения.
Опять же, мы здесь Analyze использовали, поэтому у нас здесь все в реальности происходит, но из того, что так, наверное, постоянно делать не надо, только на тестовых все-таки таблицах, это во-первых, во-вторых, из того, что еще интересно посмотреть.
Вот у нас сортировка по C1 и дополнительные узлы, дополнительное сканирование получается в трех итерациях при процессе, и таким образом мы пытаемся немножко распараллелить, ну не мы, но мы, конечно же, не мы.
А что еще здесь, на что можно посмотреть? Вот добавили limit выдачи, соответственно, появилось верхний узел нашего дерева запроса, это limit, sequential scan при этом остался, у нас появляется буфер, появляется опять, ну фильтр, понятно, здесь мы с этим уже с вами сталкивались,
то есть фильтрация строк по значению, заданному в шаблоне, и сколько строк удалено из выдачи тоже соответственно.
Чуть более интересная вещь происходит при join запросах, вот создаем новую таблицу, да, а где у нас будет значение в колонке C2, ну, булева, условно говоря, по сути дела будет 0.
Проверка на кратность двойки. И что у нас здесь появляется? Появляются новые узлы hash join, hash condition, hash condition, hash hash, hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash hash
И все равно sequential scan внизу ответвление нашего дерева для пробегания по нашим таблицам.
то для чего все это важно понимать наверное вот для чего для того чтобы иметь в виду что в зависимости от метода соединения у нас будут появляться те или иные узлы и они по разному
ну они занимают разное время и они при разных условиях отрабатывают вот nested loop
все водокодом здесь показано что происходит да то есть здесь проверяется на прямое соответствие условию нашей записи в таблице
для хэш джойн проверяется есть ли какое-то условие какое-то да чуть более сложное и тогда тоже формируется строка ну и мерч джойн сливать сначала сортируем все
а потом проверяем условия и формируем строку и вот при различных видах джойнов у нас здесь мы видим хэш джойн для
для параметра соответствия по сталпцу ц1 мы видим nested loop для соответственно условия меньше или да для условия меньше и с лимитной выдачи опять же здесь будет
здесь будет откидывание и лимитирование в нашей таблице появляется опять же узел materialize и для мерч вот вариант запроса
планом когда у нас появляется мерч джойн мерч condition и так далее но опять же это в первую очередь иллюстрация да наверное здесь не суть может быть важно
что конкретно происходит на наших тестовых таблицах потому что но они они такие они вот прям совсем совсем искусственные когда мы там создаем да либо какую-то
рандомную строку либо там значение истинно ложь это все довольно просто и до некоторой степени примитивно иметь просто в виду что у нас дерево выглядит да вот так вот у него есть
различное количество узлов в зависимости от сложности запроса у узлов может быть различные варианты могут быть различные варианты действий их не так да
наверное много но и немало есть определенные варианты пробегания по значениям либо sequential scan как базовый вариант либо варианты
пробегания по индексу индекс bitmap индекс индекс он ли и варианты когда мы проводим те или иные соединения в зависимости от тех или иных условий nested hash и
может возникать ну характеристики nested loop
только да очень дешевый с точки зрения ресурса быстро и на больших на небольших объемах не требует много памяти и умеет соединять не только по равенству
плохо то что работает только для плохо работает для больших объемов данных hash join не нужен индекс но он относительно быстрый может
использоваться для full outer join но любит память мы устроим hash соответственно соединение только по равенству у нас возможно и не любят много значений в колонках
соединение великое время получения первой строки ущит потому что мы первую строку кстати говоря прихожу получаем только когда мы
сначала построили hash для всех наших значений которые у нас работают в наших условиях пока мы hash не построим мы не начнем выполнять запрос
по сути у нас обычно вот когда мы смотрели планинг тайм и рел тайм у нас каждый раз типа ошибка в десятки раз из-за чего так происходит
планинг тайм это время от работы только планировщика то есть только директивы explain без команды analyze execution time это то что у нас происходит именно за счет
это не планируемое время исполнения а планировщик да да да время планирование получается так ура ура ура в пух пробежали мы с вами более менее но как-то много
времени потратил или ладно хорошо наверное про все-таки про планировщик чуть чуть мы еще вернемся поговорим потому что там с одной стороны много чего
еще можно сказать с другой стороны такие технические подробности которые требуют погружения наверное может быть несколько из лишнего давайте мы начнем
хранилище данных здесь не будет по сути дела какой-то наверное техническая информация здесь будет может быть наверное больше концептуальной информации о том что это вообще такое
и для чего это нужно да ведь если звезды зажигает значит это кому-нибудь нужно значит кто-то даже называет эти плевочки жемчужинами
а все довольно просто на самом деле все довольно просто элементарно то есть то о чем мы с вами немножко проговорили на первой лекции хотя возможно это заслуживает
какого-то отдельного может быть маленького цикла небольшого из лекций про историю баз данных да и вообще наверное да интересно было бы уже послушать как интересно было бы послушать цикл
лекции про историю вычислительной техники и компьютер science то ладно это лирика так вот на первой лекции мы с вами говорили про немного про историю баз данных и все
начиналось чего с того что нам нужно было уходить от прямой работы с адресами физическими к каким-то абстракциям которые будут система независимы
система независимы логика независимы языка независимы то есть нам нужна какая-то абстракция для того чтобы нам было удобно работать только с данными и ням не нужно учить особенности
конкретной машины конкретной реализации процессора архитектуры и так далее и так далее и так далее и соответственно у нас стали появляться системы управления данными
появилась появилась релиционная модель появилась появились системы релиционной системы управления базами данных но прогресс не стоит на месте с увеличением
роста вычислительных мощностей увеличением ускорением даже роста вычислительных мощностей увеличением объема хранимой информации появление различного рода алгоритмов
обработки информации и анализа данных появилась потребность в том чтобы хранить адекватным образом большие объемы данных и с ними взаимодействовать
за какие-то приемлемые величины времени используя какие-то удобные программные средства с точки зрения сроков это 80-е и 90-е годы это вот период развития концепций
хранилищ данных и в принципе можно говорить наверное двух таких теоретических подходах основных которые вот устоялись пожалуй что и на практике но они знаете такая вот
такая вот абстрактная штука на самом деле но тем не менее есть подход который отстаивает
инман william inman и есть подход который отстаивает ralph kimball
подход инмана заключается в том чтобы по сути дела проектировать хранилища данных нормализую их вплоть до 3 нормальной формы и ну по сути дела это большие релиционные базы данных если
о грублять и второй подход это подход господина кимбала который предложил идею измерений разделять таблицы измерений таблицы фактов то о чем мы с вами говорили при
описание версионности да схема звезда потом чуть более сложная схема снежинка и господин кимбал в своих трудах отстаивал идею того что нормализовывать вплоть до 3 нормальной формы
не обязательно он даже это называет нормализованные системы хранения в противоре противовес своей концепции которую он считает ну недостаточно что нормализовывать там конечно данные не хранятся а бы как как попало и так далее нет
безусловно нет данные хранятся там тоже первая вторая форма они все-таки соблюдаются плюс-минус и но тем не менее жестких жесткого закрепления на то что нужно обязательно там не менее трех а может быть даже и больше такого нет и есть некая вот такая структура проектирования отношений чего релиционная модель сама по себе не имеет
у нас нет какой-то завязанности на то что одно отношение у нас должно быть с отношением фактов а вокруг него должно там строится отношение измерений редгар код так не учил ну давайте собственно чуть ближе к телу что такое хранилище по сути дела это чуть более сложные но все-таки как правило но все-таки как правило
все-таки часто еще релиционные базы данных по крайней мере базирующиеся на основных идеях релиционной модели которые которых сливаются данные по различным отделам компании вот такая вот привязка будет к таким что производственным моментам вообще
уильям инван он говорит о корпоративной модели данных то есть модели данных целой компании целые фильмы подразумевая большую корпорацию у которых у которых множество отделов департаменты у них свои есть базы данных которые отрабатывают свои задачи фиксируя транзакции в ойл типе режиме он
и вот эти вот базы данных по департаментам они потом сливаются в хранилище единое целой компании и вот это хранилище оно собой репрезентует по сути дела корпоративную модель то есть мы его строим и вот та модель которая там есть это корпоративная модель данных вот
корпоративный данный данный данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных данных дан
данных данных данных данных данных данных данных è тbr это можетely
там логисты, промо-акции, маркетинг, ну и так далее.
А что нам с этим делать? Нам нужно это как свести, соответственно, мы для этого
строим большое, большую, проектируем некое пространство, да, емкое, куда это все
будет сливаться. При этом у нас вместе с тем, помимо того, что хранительща данных, они
хранят само по себе информацию, в них еще должны быть средства для работы с
этой информацией, для работы с этой информацией, эффективной работой с этой
вот большой агрегированной информацией с точки зрения ее анализа, ее обработки и
появляется концепция так называемая витрин данных, то есть того, куда
данные выливаются, если в хранилище данных они сливаются, из хранилища данных они
выливаются в витрины данных, но можно говорить, что это часть хранилища данных,
можно говорить, что это такие-то отдельные подсистемы, здесь уже это вопрос может
быть вкусов, нежели какой-то строгой теории, больше того, я бы сказал, что в плане
хранилища данных особой-то теории и нет, и то, о чем я вам только что сказал, это
больше концепция, больше две концепции Инмана и Кимбала, нежели строгие
научные теории по типу революционной модели с привлечением какого-то
математического аппарата, но тем не менее, как хотя бы элементы того, о чем мы говорим,
то, что может быть истинно хранилищем, вам знать придется, вот схематично общую
концепцию можно изобразить, как показано на рисунке, и как вы видите, собственно,
ДВХ, Data Warehouse, он как бы вот здесь, посерединке, вот в такой пиктограмме, условно обозначающей базы
данных, есть у нас еще операционное приложение со своими базами данных, непосредственно
взаимодействующие с внешними источниками, ДВХ у нас взаимодействует с OLAP-приложениями,
которые предоставляют уже возможность анализа на лету или подготовки отчетности,
есть еще ETL-процессы, которые вроде бы как здесь идут от операционных приложений к ДВХ,
ETL это, соответственно, Extraction, Transform и Load, извлечение, преобразование, куда входит
там и очистка, и преобразование, вот как здесь два буллета, очистка, преобразование, можно сказать,
что это Transformation или Transform, и Load, загрузка, что нужно понимать, что нужно при этом понимать,
и возвращаясь к тому, что ДВХ, хранилище данных, это больше концепция, то, что на самом деле в каждой
конкретной компании, в каждом конкретном, может быть даже департаменте, не реализована своя
система хранения больших объемов информации, ETL может быть не здесь, а она может быть там,
не знаю, условно говоря, ее можно продлевать параллельно где-то вот прям слева направо,
и ДВХ может быть там, условно говоря, в ней, может быть Extraction, может быть не ETL,
а другой порядок, ETL, Extraction, Load, Transform, когда у нас Transformation происходит после того,
как мы данные сливаем и храним в хранилище, а потом мы их трансформируем на этапе передачи в
или создание отчетности или на этапе онлайн-аналитики, и вообще это все довольно условно,
и каждый здесь вот все это строит под себя исходя из своих нужд и из своих запросов. Вот это вот такая
в некотором смысле классическая схема, но она не жесткая, она не жесткая, никто вас или там никто
в принципе никого там не будет ругать, если мы здесь что-то нарушим и передвинем местами,
поэтому не относитесь к этому как к чему-то жесткозаданному. Ну дальше, что там понимается
под источниками и так далее, с вами поговорим, но давайте, наверное, мы на этом уже остановимся,
судя по времени, уже время подошло к концу. По хранилищам тогда, ну такую общеконцептуальную
информацию я вам проговорил, две основные парадигмы Инман-Кимбл, вокруг них как бы нарастает все
остальное и даже какие-то альтернативы строятся, по большому счету, какой-то базы строгой
теоретически или еще того страшнее математически во всем этом нет, это просто
варианты хранения больших объемов данных и более того, как вы очевидно должны были слышать,
есть еще и концепции океана данных, озера данных, болота данных, которые отражают тот факт,
что облака данных, которые отражают тот факт, что у нас в принципе, с одной стороны,
современные технологии позволяют не заботиться о структуре, а с другой стороны говорят о том,
что мы вот эту вот этвель-составляющую будем переносить как раз справа по отношению к вот
вот этой сущности, которую мы называем крадилищем, ну или болотом данных, если все-таки говорить чуть
более последовательно.
