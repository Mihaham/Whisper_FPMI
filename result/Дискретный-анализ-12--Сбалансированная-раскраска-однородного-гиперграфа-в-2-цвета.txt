Как вы думаете, про что теорету нам нужно доказать?
Про энтропию это вспомогательная вещь, а теорета у нас, конечно, была не про энтропию, а про
разброс в раскрасках. То есть нам нужно доказать, что если у гиперграфа число вершин и число
ребер одинаковые, равны какому-то n, то может добиться того, что, скажем, на ребре разброс
между красными и синими вершинами не превосходил какой-то констант, умноженный на корень из n.
Дайте я это напишу еще раз. Значит, теорема, если h равняется ve и мощность v равняется,
g равняется n, то существует такая раскраска, что на любом ребре нашего гиперграфа разность между
числом красных вершин и числом синих вершин не превосходит. Ну, я описал что-то 20 корней из n.
Я не буду аккуратно считать в рамках доказательства эти константы. Мне главное,
чтобы вы поняли и так, мне тоже никакого подсчета от вас требоваться не будет. Вот эти вот 20 или 6,
или сколько там можно посчитать. Главное, чтобы вы поняли смысл происходящего. Ну, давайте,
я еще раз повторяю, что доказательство будет таким, аккуратным, но только в
некоторой части своей, в той, которую я считаю наиболее сущностной, и ее, соответственно,
и буду спрашивать. То есть, идея такая. Давайте сперва докажем, что можно так
покрасить не менее 1 минус 10 в минус девятой степени на n вершин. Вот, друзья, 10 минус 9,
это я помню, вам запоминать не нужно. Но вам главное смысл понять. Сейчас я напишу, как покрасить.
Я же начал фразу так покрасить, а как покрасить-то я же не сказал. Значит, так покрасить почти все вершины,
но почти все не в смысле асимптотики, а в смысле, что доля покрашенных будет очень существенной.
Значит, так покрасить в каком-то смысле почти все вершины красные и синие цвета,
что вот этот разброс на каждом ребре нашего гиперграфа, число красных вершин, минус число
синих вершин, будет не больше, чем 10 корнейза. Ну, 10 тоже такая условная величина, которую
не обязательно запомнить. Главное, чтобы был понятен смысл происходящего. Но в каком-то смысле это и есть то,
что я аккуратно докажу. То есть мы почти все покрасим так, чтобы разброс был небольшой на каждом ребре.
Но при этом какие-то вершины, их будет одна миллиардная от общего числа, они будут, вообще говоря,
не покрашены. Ну и дальше идея такая, берем вот эти оставшиеся не покрашенные вершины и с ними
проделываем примерно ту же процедуру, какую я сейчас подробно опишу для всех вершин. Там получится
еще меньше, естественно, константов, там вот 10 минут с девятой-то вылезет, и ряд из этих константов
сойдется к 20. То есть идея такая, покрасить почти все с маленьким разбросом, потом оставшееся снова
покрасить почти все еще существенно меньшим разбросом, там совсем чуть-чуть останется,
это мы снова почти все покрасим, ну ряд сойдется. То есть вот надо, чтобы вот эта идея была ясна
буквально на пальцах, а почему он сходит, какие там константы получаются, это запоминать нелепо,
ни к чему это не приведет, перегружать голову. Так, а вот это я сейчас буду аккуратно рассказывать,
но там будет тоже кое-что без доказательства, но в целом все будет понятно. Итак, давайте рассмотрим
просто случайную раскраску для начала, обычную. Рассмотрим обычную случайную раскраску множества
вершин, ну то есть вероятностью одна-вторая мы присваиваем каждой вершине один из двух цветов,
независимо от остальных. Скажем, красный это то же самое, что плюс один, синий это то же самое,
что минус один, здесь вероятность одна-вторая и здесь вероятность одна-вторая, независимо на каждую
вершину. Просто берем обычную случайную раскраску. Так, теперь давайте рассмотрим, как-нибудь
обозначим наши ребра. Как мы ребра до сих пор обозначали? Какими буквами? Не читаем большое,
да, помнится? Вот давайте, пусть наши ребра это м1 и так далее мн, это ребра, которых n штук,
столько же, сколько вершин, ну а вершины это, если хотите, просто числа 1, 2 и так далее n, вроде так
она тоже была обычно у нас всегда. Вот давайте для каждого и определим свою случайную величину,
некую, сейчас я скажу какую, значит сейчас я скажу какую, давайте вот так их обозначим,
случайные величины b1 и так далее bn, это будут случайные величины, b1 отвечает ребро m1,
bn отвечает ребро mn. Теперь какие значения они могут принимать, это я сейчас скажу. Давайте b1
равняется нулю, если вот эта вот величина hi от m1, ну или bit, давайте сразу писать зачем b1,
hi от mit, так вот здесь я напишу, напомню, hi от mit, это просто сумма по всем g, вершина множества
hi от g, где hi от g это плюс или минус единицы в зависимости от цвета, было ведь у нас такое, все это понимают,
вот это как раз вот тот разброс, который здесь обозначен как разница между kr и sin, как раз
разница между kr и sin в точности, hi от mt, так вот если hi от mt принадлежит ну давайте полу
интервалу для красоты, чтобы все было однозначно определено от минус 10 kr и sin до плюс 10 kr и sin,
полу интервалу обещал же, а сам нарисовал отрезок, так от минус 10 kr и sin до 10 kr и sin тогда мы
полагаем bt равным нулю, то есть вообще фактически bt это будет просто ближайшее целое число к дроби
hi от mit поделить на 20 kr и sin, вот так можно сказать, bt равно единицы, сейчас все будет понятно, если
hi от mit, ну просто так лучше писать, так будет понятнее потом все рассуждение, можно короче
сказать, но лучше написать явно, принадлежит теперь на отрезку от 10 kr и sin до 20 kr и sin,
не отрезку, полу отрезку, полу интервалу, а до 30 конечно, странно согласен, до 30, до 20,
а до 30, обсчитался, что странно, 20 для нас, все время 20 kr и sin, я обсчитался,
ну дальше точно так же, то есть bt равняется двойке, если от 30 до 50, потом там от 50 до 70,
bt может равняться минус единицы, минус двойке, минус тройке, то есть пожалуйста, ну понятно,
если она принадлежит соответственному отрезку, полу интервалу, длины 20 kr и sin, от 30 до минус единицы
равным минус единицы, но это действительно в каком смысле ближайшее целое к дроби hi от mit поделить
на 20 kr и sin, правда же? просто hi от mit без модуля, конечно, да, сейчас в чем вопрос?
ну оно может быть отрицательным, конечно, мы же не знаем, в какую сторону разбалансировка прошла,
красных больше, чем синих, тогда будет положительная, синих больше, чем красных,
тогда будет отрицательная, мы не знаем, какого размера ребро я mit, оно может быть размера порядка n,
поэтому в отрицательную сторону можно уйти очень далеко, тут же порядка корни из-за длины отрезка,
а mit может быть мощностью n пополам, например, то есть она, конечно, bt принимает не бесконечно
много значений, но очень много, в каком смысле бесконечно, можно оценивать это рядом,
так пока все понятно с определением? это просто ребра нашего гиперграфа, мы взяли гиперграф,
у которого n вершин, вершины обозначили просто вот так, это v, а ребра, как и в прошлый раз обозначили
вот так, все, я написал вот e, это просто множество, состоящее из каких-то подмножеств, вот отсюда,
вот гиперграф, так мы рассматриваем гиперграф, товарищи, это уж я прошу прощения, может вас не
было там на прошлой, позапрошлой лекции, я так не соображаю, кто был, кто не был, не очень запоминаю,
это неважно, но конечно, да, мы работаем с гиперграфом, то есть это ребра гиперграфа, они могут состоять,
например, из n минус одной вершины даже, из n вершин, то есть какое-то ребро вполне может
состоять вообще из n вершин, поэтому разница между количеством красных и синих вершин в этом
ребре может быть и порядка n тоже, соответственно, вот тех значений, которые b и t принимает,
с ростом n оно стремится к бесконечному количеству этих значений, так, ну смотрите, давайте попробуем
посчитать энтропию, зачем-то, пока не понятно зачем, но потом все будет понятно, давайте попробуем
посчитать энтропию отдельной случайной величины b и t, ну как по определению, это минус сумма,
какие-то значения, какие значения принимает, ну, s, формально от минус бесконечности до
бесконечности вероятность того, что b и t равняется s на лог двоичной той же самой вероятности,
так, давайте я отдельно посмотрю на вероятность того, что b и t равняется нулю, давайте я это
отдельно сделаю, вероятность того, что b и t равняется нулю, это вероятность того,
что модуль h и t не превосходит 10 корней z, ну, то, что тут выкинут какой-то конец,
я думаю, это не очень принципиально, если хотите, я напишу не больше, ну, понятно, в общем, равна,
равна, да не, ну, сейчас вы увидите, не важно, конечно, ну, ну, хорошо, можно в какую-то сторону,
конечно, оценить, тут написать 9,999 и успокоиться на этом, вот, сейчас вы увидите, что просто эта
вероятность очень хорошая, так, это есть, так, что это такое, это один минус вероятность того,
что модуль h и t больше чем 10 корней z, а это мы оценим с помощью неравенства,
которое про большое уклонение, помните, мы в прошлый раз это делали, вспоминали мы, да,
такое неравенство, все помнят, нет, что если мы складываем, как случайное блуждание,
если мы складываем плюс-минус единицы, то вероятность уклониться на а не больше чем
е в степени минуса квадрат поделить на дважды там мощность вот этого м этого, пьяница, пьяница,
да, я доказывал это неравенство еще в прошлом семестве, пьяница, да, в общем, это больше или
равно единица минус е в какой степени, надо вот это возвести в квадрат будет 100n и поделить
на 2n, на 2 мощности омытая, но мощность омытая она не больше чем n, чпок-чпок, ну, то есть,
это будет 1 минус е в минус 50, это очень близко к единице, прилично близко к единице,
конечно, если здесь заморачиваться тем, что не совсем этот отрезок, ну, будет е в степени минус
там 49,99, ну и что от этого изменится, в итоге ничего, если вот здесь заморачиваться тем,
что был полуинтервал, то здесь вот изменится только этот контант, и чуть-чуть может быть,
это, в общем, никакого значения не имеет, смотрите, как ведет себя вот эта функция,
вот эта вот функция, минус х лог 2 ич на х, как у нее устроен график, если х меняется от нуля до
единицы вот х, а вот эта функция х меняется от нуля до единицы, как можно рисовать функцию минус х лог
х, в нуле что будет, нуля ноль, да ведь, и в единице ноль, то есть, она вот такая,
но у нее максимум в одной-второй, ну, логариф нуля неопределен, конечно, но предел,
посмотрите на это, предел, конечно, будет в нуле, то есть, чем ближе х к нулю, тем это ближе к нулю,
ну в нуле, значит, полагаем, просто равным нулю такая вот устранимая особенность. Так, друзья,
это не должно никого хохнуть, это вроде понятно, то есть, если мы знаем, что один из вот этих х,
а именно тот, который получается при с равным нолику, он очень, ну не важно, очень близок к единице,
но главное, что правее половины, тогда мы можем говорить, что эта штука не больше чем и дальше
вот этого всего подставить вот это. Да, да, да, да, да, я пока при бои равном, ну я сейчас напишу
бои равные, ну а дальше что-то какую-то сумму напишу, конечно, да, вот я сейчас хочу выписать то слагаемое,
которое соответствует с равному нулю, вот центральная слагаемая этой бесконечной суммы,
чего у меня получается-то? У меня получается что-то, купа минус один,
минус е в минус пять, пятый налог двоичный от один минус е в минус пятидесят, и на это примерно ноль.
Не напутали, потому что вот в эту сторону она убывающая, поэтому если мы ее оцениваем снизу,
то саму функцию мы оцениваем сверху, и это правильно, она после одной-второй убывающая,
поэтому если мы аргумент функции оценили снизу, то саму функцию мы правильным образом оценили
сверху. Друзья, это понятно? И наоборот, все остальные аргументы будут находиться здесь,
функция будет возрастающей, но там будут оценки меньше либо равно, сейчас вот мы на остальные
слагаемые посмотрим и убедимся, что все остальные слагаемые наоборот маленькие,
и дальше прибавим, прибавим, конечно, ну давайте посмотрим на какой-нибудь отрезок,
вот например, вот на этот, значит, с какой вероятностью у нас хи атомы Т принадлежит вот этому
отрезку, то есть б и Т равняется единице, так от десять корней из Н до тридцать корней из Н,
эта вероятность точно не больше, чем вероятность того, что хи атомы Т просто больше либо равняется
десять корней из Н, а это снова согласно неравенству про пьяницу не превосходит е в минус пятидесятой
степени, уже не превосходит, ну и хорошо, потому что значение наоборот слева, здесь функция возрастающая
и неравенство опять в нужную нам сторону, то есть вот здесь будет слагаемый е в минус пятидесятый на
лог двоичный от е в минус пятидесятый, это слагаемая, которая соответствует с равному единице,
но для с равного минус единицы слагаемая будет в точности таким же, я надеюсь это понятно,
отклониться от кабака вправо на десять или влево на десять это одно и то же, минус единица это когда
оно от минус тридцати корней из Н до минус десяти корней из Н, но то есть меньше уж во всяком случае,
чем минус десять корней из Н, отклонились от кабака влево на такое же расстояние, то есть если хотите,
я здесь двойку нарисую, а дальше, ну хорошо, ВИТ равняется двум, это значит, что вот здесь уже вот
здесь слева стоит тридцать, это два на е в степени минус четыреста пятьдесят, налог двоичный от е в
степени минус четыреста пятьдесят, ну и так далее, тридцать в квадрате пополам это четыреста пятьдесят,
не-не-не, у нас есть много-много слагаемых, мы предыдущие слагаемые просто так оценили,
что значит мы все учли, я не очень понимаю, как это мы все учли, мы оценивали просто вот это вот
произведение для s равного единицы, ну оценили мы его вот для s равного единицы и минус единицы,
оценили вот так, теперь мы должны подставить s равное двойке и для этого написать тоже оценку,
ну мы ее немножко избыточной сделали, но на самом деле не очень сильно, потому что вот попасть в такой
интервал или оказаться просто правее левой границы этого интервала, ну вероятность примерно одинаковая,
сейчас я не понимаю, не усиливаем, а ухудшаем,
ну потому что я знаки потерял, ну знак, я вот этот минус потерял, я идиот, извините,
я вот прям на камеру это говорю, ну идиот, да, спасибо большое, конечно я знак потерял,
ну конечно, да, мы ухудшаем оценку, ухудшаем, товарищи, из зала поступило, да, правильное
замечание, когда тут стояли плюсы казалось, что мы усиливаем оценку, непонятно как это вообще можно
сделать, почему усиливаем, потому что логарифм берем от отрицательной степени едешь с минусом пойдет,
нет, оно пойдет с плюсом, потому что я вот этот минус забыл нарисовать, вот здесь не забыл,
а здесь забыл, ну виноват, но это все положительные числа, и вот этот логарифм тоже как бы отрицательный,
предомножение на минус, дает положительное число. Но эти все числа примерно равны нулю, и вот это
примерно 0, и вот здесь наоборот вот это примерно 0, а это гораздо дальше от нуля, чем оно. То есть оно
никак этот 0 не убивает. Короче, если взять, загнать вот эту сумму в компьютер и посчитать, то будет
примерно меньше, чем 3 на 10 в минус двадцатой степени, и вот это число мы сейчас обозначим
временно буквой EPS. Сейчас я нормально объяснил, я минус потерял, это, конечно, нелепо, но вроде
все остальное это было хорошо или что-то непонятно. Нет, друзья, но вроде простая выкладка совсем. Я
надеюсь, что нормально. Да, я где-то загрубил чуть-чуть неравенство, но это на самом деле очень
несущественно. Все равно получилась очень маленькая сумма, меньше, чем 3 на 10 в минус двадцатой,
5 вы можете не помнить для себя, там, чего это равно, но понятно, что это очень маленькое. Вот обозначим
это EPS. Так, воспользуемся теоремой, которой мы закончили прошлую лекцию. Там была теорема,
доказывавшаяся с помощью выпуклости о том, что энтропия вектора не больше, чем сумма энтропии
его компонент. Но была такая теорема. В общем, у нас есть векторы случайных величин B1 и так далее,
Bn. Вот они тут выписаны. И мы знаем, что это не больше, чем EPS. Потому что энтропия каждой
из компонентов не больше EPS, это мы сейчас посчитали, а когда мы их сложим, но будет не
больше, чем EPS. Это результат прошлой лекции. Мы его подготовили. Так, теперь давайте так.
Если это верно, а это верно, то отсюда следует, что существует такой вектор значений S1,
а так далее, Sn, значений вот этих случайных величин B1, Bn, мы их пуклками S обозначали,
значений S1, Sn, что вероятность того, что B1 равняется S1 и так далее, Bn равняется Sn,
больше либо равна 2 в степени минус EPS. Почему такое следствие? Давайте предположим противное.
Давайте предположим, что все вероятности вот таких вот значений для любых S1, Sn меньше,
наоборот, чем 2 в степени минус EPS. Тогда давайте посмотрим на энтропию. У нас по определению,
чему равна эта минус, сумма по всем S1 и так далее, Sn, вероятность вот эта самая B1 равно S1 и так
далее, Bn равно Sn, на лог двоичной этой же вероятности B1 равно S1 и так далее, Bn равно Sn.
Ну, это просто определение, энтропии совместной, энтропии векторов случайных величин B1, Bn.
Суммируем по всем возможным. Мы предположили, что каждая такая вероятность меньше, чем 2 в степени
минус EPS, но тогда лог двоичной такой вероятности меньше, чем минус EPS, правильно?
Вот давайте я вот здесь вот так подчеркну. Получится, что он меньше, чем минус EPS. Но
со знаком минус у нас идет эта сумма, поэтому все вместе получится больше, чем EPS умножить на сумму
по всем S1 и так далее, Sn, вот этих вот вероятностей B1 равно S1 и так далее, Bn равно Sn. Но эта сумма
равна единице, сумма всех вероятностей равна же единице. Это все возможные значения, которые принимает
векторная случайная величина. Сумма вероятностей равна единице. Мы получаем просто EPS и это
противоречие. Мы с вами знаем, что h не превосходит EPS, предположив, что все значения имеют
вероятности меньше, чем 2 в степени минус EPS, мы получили противоречие, что энтропия больше.
Мы только под логарифмом вероятность оценили из предположения противного, а эти вероятности не
оценивали, а тупо сложили, получив единицу. То есть действительно это обоснование, а вывод,
вот он существует, такие S1, Sn, что наш вектор принимает эти значения с вероятностью достаточно
большой. Перейдем к количествам. Что, куда писать? Так, я стер теорему недавно, но что поделать?
Значит еще раз, никаких особенных выкладок тут нет. Мы хотим доказать, вообще говоря,
что существует такая раскраска, но правда частичная, мы не докрасим там 10 в минус 9 степени,
в которые уклонение красных от синих на каждом ребре не больше, чем 10 корней из N. Мы до этого
не дожили. Мы на каждом ребре ввели случайную величину B1, Bn, на ребре M1, B1, на ребре Mn, Bn,
ввели такие случайные величины, и пока мы, оценивая энтропию, вот после всех выкладок,
получили такой важный промежуточный результат. Есть конкретный набор чисел,
который служит значением вот этого случайного вектора с большой вероятностью. Сейчас я хочу
перейти к количественному результату, то есть переформулировать вот это не в терминах вероятности,
а в терминах количеств. Ну что значит, вероятность большая? Это значит, есть очень много раскрасок,
в наших раскрасках случайно. Друзья, вы понимаете, что вероятность это, в общем,
как бы это сказать, заметённое под ковёр сравнение каких-то количеств. Так или иначе,
может с весами, с какими-то. Но тут вероятность банальная. Тут мы каждую вершину красили с
вероятностью одна-вторая. То есть все раскраски равновероятны, правда же? Друзья, все понимают,
что у нас каждая раскраска имеет вероятность. Просто сама раскраска имеет вот такую вероятность.
У нас N вершин. У нас N вершин. Каждая вершина красится в красные с вероятностью одна-вторая,
в синие с вероятностью одна-вторая. Фактически мы живём просто
в классическом вероятностном пространстве, 2 в минус N это вероятность каждого
элементарного события. И тут мы выясняем, что вероятность встретить раскраску,
раскраску, на которой одновременно b1 равно s1, bn равно sn, она большая. Вот давайте я эту часть стирать не буду,
разотру только выкладки. Это означает, что таких раскрасок просто много с одинаковыми значениями b1, bn.
Сколько, как минимум?
Совероятность встретить такую раскраску не меньше, чем 2 в степени минус epsilon n, то сколько таких раскрасок?
Как? Нет, там gen должно быть какое-то. Значит, смотрите, я утверждаю, что количество раскрасок
х таких, что одновременно b1 от х равняется s1. Мы не знаем, что такое s1, но оно существует, вот мы его ввели, все.
b и n от той же самой х равняется какому-то конкретному sn, который мы точно знаем, что существует.
Вот количество таких раскрасок не меньше, давайте я словами напишу, чтобы было понятно, что к чему относятся, чем 2 в степени a1 умноженное на n.
Потому что вероятность, это результат деления вот этой штуки на 2 в n степени, а это и будет 2 в степени минус epsilon n, как мы доказали.
Красим в два цвета, 2 в n степени у нас раскрасок. Ну я вот здесь даже писал, что каждая раскраска имеет вероятность 2 в минус n степени.
Так, то есть их дофига, вы если забыли, я вам напомню, epsilon это 3 на 10 минус 20.
Ну во всяком случае их очень много, таких раскрасок, у которых полностью совпадает вот этот вектор значений, их очень много.
Может сейчас устроить перерыв, чтобы у вас немножко это улеглось в голове.
Ну в принципе его уже скоро пора делать, через 3 минуты.
Но могу попробовать объяснить, что вот я хочу сказать. Что такое раскраска?
Мы вот этим вот числом от единицы до n присваиваем значение плюс-минус 1. То есть фактически раскраска это вектор из плюс-минус единиц размерности n.
Так значит, что на множестве раскрасок, всех вот этих 2 в n степени раскрасок, можно ввести хемминговую метрику.
Вы помните такое хемминговая метрика? Забыли? Кодированию я вас учил.
Ну это очень просто. Это количество несовпадающих координат.
В скольких координатах у них разные значения, у одной плюс, у другой минус, или наоборот, у одной минус, у другой плюс.
Вот сколько таких координат, это называется расстояние хемминга между двумя векторами, например с плюс-минус единиц.
Ну мы говорили может про нули и единицы, но какая разница? Можно ввести хемминговую метрику.
А у нас очень много раскрасок, очень много, которые обладают некоторым важным, там почему-то важным для нас свойством.
Я хочу после перерыва показать, что раз их много, то среди них есть две, которые очень сильно разнятся по хеммингу, между которыми большое расстояние.
Ну если векторов в пространстве много, то среди них есть такие, которые удалены друг от друга далеко.
Ну чисто интуитивно это же понятно.
Вот есть вершины куба, условно говоря, минус один-один в n-ной степени. Вот такой куб минус один плюс один в n-ной степени.
Вот они вершины куба. Среди них есть очень много вершин.
Я утверждаю, что тогда гарантированно какие-то две отстоят друг от друга сильно.
А из этого уже будет нужный вывод.
Но может быть катарсис будет, раз вы сходу не понимаете, что надо сделать.
Катарсис будет тогда, когда у вас глаза откроются.
Опа! Это же и есть катарсис. Ладно, все, перерыв.
Поступило совершенно правильное соображение, которое я, собственно, и хочу реализовать.
Есть такой интуитивно понятный факт, который в комбинаторном случае я формально доказывать не буду,
потому что не хочется слишком много всего здесь впихивать.
Но факт понятный. Если вам задан диаметр множества, то есть максимальное расстояние между точками в нем,
то самое объемное множество – это шар.
Среди всех множеств данного диаметра самым объемным является шар.
Интуитивно кажется, что это понятно, а формально это надо доказывать.
В общем, это, конечно, не бог какое утверждение, особенно в комбинаторном случае.
Давайте это оставим за скобками.
Поэтому смотрите. D – это величина диаметра. Давайте так. D – диаметр.
Да-да-да. Нет, количество точек внутри шара не надо оценивать. Это комбинаторная величина, это сумма цешек.
В нашем-то случае это как раз просто, потому что что такое шар в хемминговой метрике?
Это просто множество точек, которые отличаются в одной координате, в двух координатах, в трех координатах.
Это цешки. Да-да, это цешки. То есть здесь как раз шар – это такая вещь, совсем простая.
Если нам дан какой-то диаметр, пока мы не знаем, какой, то вот такая теорема, что ли, то количество точек в любом множестве диаметра D
не больше, чем количество точек в шаре радиуса D пополам, ну не более, чем D пополам или D пополам.
Наверное, D достаточно. Количество точек в любом множестве диаметра D не больше, чем количество точек в шаре радиуса D.
А оно в нашем случае просто равно сумме по K от нуля до D пополам.
Друзья, я так это очень эмоционально сказал, но я надеюсь, это правда понятно.
Он не тоже комбинаторный. В смысле, это шар в хемминговой метрике.
Вот у вас есть центр, какой-то вектор с плюс-минус единиц.
И точки, которые отстоят от этого центра не больше, чем D пополам расстояния, это на самом деле точки, которые от данного вектора отличаются либо в одной координате, либо в двух, либо в трех.
Вот отсюда сумма этих цешек. 0 – это когда центр мы считаем тоже.
0 – это одна центральная точка, 1 – это следующий слой тех точек, которые отстоят от данной на хемминговое расстояние.
1 отличается в одной координате. N способов изменить координату, C из N по 2 способов изменить две координаты, ну и так далее.
Теперь надо вспомнить в очередной раз первый результат первого семестра этого года.
Нет, ну давайте я нарисую вот так вот, и все будет хорошо.
И вот здесь тоже напишу вот так, но это точно правильно, а мне этого хватит.
Да-да-да, мне этого хватит.
Так, смотрите, надо просто вспомнить в очередной раз вот этот вот результат, который у нас с вами был,
что если мы берем C, ну даже не в целой части, а просто по альфе N,
где вот стоит любая функция, которая симпатически равна тому, что написано вот наверху, C из N по альфе N,
по целой части, по альфе N, по что угодно.
Это будет, мы записывали это, 1 на альфа в степени альфа, 1 минус альфа, 1 минус альфа, плюс от единицы в N степени.
Ну нам, наверное, выгодно написать в таком, в каком мы оцениваем количество раскрасок, то есть точек в этом хемминговом пространстве в верхней строчке.
Видите, количество раскрасок оценивается как 2 в степени. Ну давайте это тоже представим как 2 в какой-то степени.
Это значит будет, ой, ну 2-ичный логориху надо писать. Ну ладно, аж от альфы я все-таки не буду.
Давайте действительно напишем, альфа лог 2-ичный альфа минус 1 минус альфа лог 2-ичный от 1 минус альфа.
Надо еще как-то эту асимптотику написать. Ну там вот так, например, плюс у малой от единицы и на N. Вот так вот.
У малой от единицы, конечно, должно быть внутри скобок. Оно и тут внутри скобок. Это, я надеюсь, понятно.
Так. Ну, короче говоря, я же хочу, исходя из вот этого, оценить снизу диаметр моего множества.
Вот того количества раскрасок, количество которых вот такое. Хочу оценить диаметр этого множества.
Ну я утверждаю, давайте я просто напишу, что я утверждаю. Я утверждаю, что диаметр множества раскрасок таких, что...
Ну вот это вот. Не переписывать. Диаметр вот этого множества раскрасок, количество которых большое.
Он исходя вот из этого и из вот этого, может быть оценен снизу как 1 минус 10 минус 9 степени на N.
Вот, собственно говоря, это и утверждается. Ну еще раз, как это можно получить?
Типа, предположим противное, предположим, этот диаметр не превосходит или строго меньше, чем вот эта величина.
Вот это вот альфа у нас получается альфа N. Пусть альфа это вот это число. Да?
Или хотите два альфа, чтобы было поприятие? Ну пополам, делить будет альфа.
Да, вот здесь наверху стоит вот такая штуковина, поделенная пополам, то есть прямо в точности альфы N.
Но альфа это уже 1 вторая, минус там 1 вторая 10 минус 9. Альфа это тогда 1 вторая, минус 1 вторая на 10 минус 9.
Вот таким получается это альфа. И понятно, что поскольку альфа левее серединки, то есть вот это вот альфа...
Что ж такое-то?
Если вот у нас диаметр, и он больше либо равен вот этой величины, то его верхняя целая часть, она тоже хотя бы альфа N.
То есть вот среди этих слагаемых есть цешка вот с таким вот альфа вот здесь.
Нормально объясняю или путано? Понятно, да? Точно понятно. То есть среди вот этих слагаемых точно есть цешка именно с таким альфа.
Это почти ц из N по N пополам. Почти. Но вместо N пополам написано N пополам без чего-то очень маленького.
Численно просто можно, подставив вот сюда вот эту штуку, проверить, что это противоречит вот этому неравенству с конкретным епсилом, которое 3 на 10 минус 20.
Ну, еще раз, ц из N по N на 2, это вообще 2 плюс о малой от единицы в N степени.
А мы чуть-чуть влево отступили от N пополам, это уже будет не 2 в N, ну там 2 в N на 1 плюс о малой от единицы, не 2 в N, а 2 в степени 1 минус дельта на N.
Дельта будет противоречить этому епсилам. То дельта, которая вот здесь вот получится, вот оно вот так получится путем подстановки вместо альфа вот такой штуки в это выражение.
Оно будет просто... Чего? Оно будет меньше, чем...
Плохо объясняю, да? Плохо объясняю.
Ой...
У меня плохо объясняю, потому что сейчас... Ой, сейчас...
Диаметр множество... А, еще раз, не так.
Еще раз, мы утверждаем, давайте еще раз повторим, мы утверждаем, что отсюда следует, что диаметр большой, вот такой.
Я утверждаю, что он такой. Я говорю, давайте предположим, например, противное. Ну, например, что диаметр меньше вот этой величины.
Тогда это значит, что вот в этом суммировании сама эта величина может быть и не присутствует. Я, наверное, действительно зря сказал, что она присутствует.
Она присутствует вот в этом случае. И тогда противоречия здесь не такого нет.
Еще раз, если мы предполагаем, что D строго меньше вот этого, то в этой сумме есть почти вот эта величина.
Вычтите 100 угодно, вычтите, я не знаю, 10 в минус сотой степени, например, и такая штука тоже будет присутствовать при больших N.
Понятно, да?
Нет, плохо объясняю. Ну, что ж такое-то?
Для меня это настолько очевидно, что я, видимо, не могу это объяснить. Сейчас, подождите, я попробую как-то по-другому сказать.
Да-да-да-да-да, сейчас.
Это совершенно простая вещь, ну, просто стандартная вещь. Я думал, что я уже этому научил, но, видимо, научил плохо.
Так, и себя плохо научил это объяснять, а вас плохо научил это сходу воспринимать.
Сейчас, подождите, хотим показать, что диаметр множества больше либо равен.
Предположим, что суммирование ведется до числа, которое, ну, меньше или даже не превосходит вот этой величине.
Так, нет, не надо мне это, минус сотой, хорошо. Давайте, пусть оно идет даже досюда.
Даже пусть оно идет досюда, тогда последняя слагаемая, неважно, что у нее целая часть, а симптотика у него будет такая же точная.
Правильно? То есть, а симптотика у него будет такая же точная, альфа умножить на N.
Так, эта последняя слагаемая, оно будет иметь вид вот такой вот.
Теперь, каждая из предшествующих слагаемых меньше. Это правда.
Самих слагаемых не больше, чем N. Тоже правда.
Если мы оценку самого большого слагаемого, вот она, умножим на N, то это будет оценкой всей суммы, у которой D меньше, чем вот эта величина.
Ну, или меньше либо равна, даже, неважно. Вот это будет правдой.
Тогда мы вот это N представим как 2 в степени лог 2-ичный N, после чего прибавим этот лог 2-ичный N вот сюда.
Почему мне все очевидно? N вынесем за скобку. В скобках останется вот это, плюс O малое от единицы и плюс лог 2-ичный N, поделенный на N.
То есть, тоже O малое от единицы. Вот у меня как-то это перещелкивает сразу. То есть, тоже O малое от единицы.
Вся вот эта сумма на самом деле сосредоточена в последнем слагаемом.
Сосредоточена в том смысле, что меняется только вот это O малое от единицы.
Так вот, вот эта альфа сейчас подобрана таким образом, что даже если прямо до него суммировать...
Фактически надо рассмотреть только последнее слагаемое, потому что все предыдущие идут вот сюда.
Даже если суммировать прямо до него, то вот эта вот чиселка будет строго меньше, чем 1 минус эпсилон, где эпсилон равно 3 на 10 минус 20.
Вот сейчас я, наверное, нормально объясню.
Извините, да, это я. Я ни в коем случае из себя не списываю ответственности.
Конечно, это надо было подробнее сказать. Но сейчас вроде сказал, да?
Вот оно подобрано так, чтобы вступить именно в этом смысле, в противоречие.
То есть, диаметр действительно оценивается снизу вот этой величиной.
Может быть, даже строго, это неважно.
Много мучений было вот из-за этого анализа.
Не знаю, как лучше добиться вот этого понимания аналитических вещей, не знаю.
То есть, формата не была очевидна, у него полей не хватило.
Было прямо очевидно, но очень хочется, чтобы такие вещи...
Ладно, все, пора получать катарсис, потому что все получилось.
Не, ну пока же не кокнуло. Ну, казалось, что кокнуло, а мы склеили.
Нормально, да? Вот, нормально.
Вот, смотрите, значит, какой отсюда вывод?
Раз диаметр большой, значит, есть просто две конкретные раскраски.
Назовем их х1 и х2, которые плюс-минус единицы отстоят друг от друга на не менее, чем вот такого.
Так давайте рассмотрим раскраску хи.
Господи, куда же это писать?
Это все уже почти получилось, которое представляется как хи1 минус х2 попало.
Понимаете, что поскольку они разнятся почти всюду, то разность это будет опять плюс-минус единица после деления на два.
Почти всюду. А ноль получится не более чем 10-9 на n координатах, то есть недокрасанными.
Вот в этой раскраске она частичная, она неполная.
У нее координаты не меньше, чем столько.
Но у этой раскраски хи есть и координаты, равные нулю.
Вот этих координат, равных нулю, не больше, чем 10-9 на n.
То есть это уже, ах, теоремка стерта.
Напоминать формулировку или не нужно?
Ну да, но теперь еще надо кое-что проверить.
Зачем нам нужно было, чтобы вот эти b1 от хи и b2 подали?
Дело в том, что получается-то чего?
Получается, что для любого и хи1 от mit, и хи2 от mit вот эти вот разбросы.
Радость у нее. Радость идти к вершинам.
Друзья, они же лежат на одном и том же отрезке.
Потому что все вот эти значения совпадают.
Мы так выбирали хи1, хи2, чтобы они находились в множестве, где b1, bn все совпадают.
Какие бы мы ни нашли, мы нашли те, которые далеко друг от друга отстоят.
И за счет этого мы не докрасили только одну миллиардную от общего числа вершин.
Но больше того, мы добились того, что у них одинаковое вот это вот значение с точностью до попадания на отрезок.
То есть модуль хи от mit не больше, чем 20 корней из n поделить пополам.
И это 10 корней из n, которые заявлены в теории.
Модуль вот этой разности в числителе из-за того, что они лежат на одном интервале длины 20 корней из n, он, конечно, не превосходит 20 корней из n.
Ну а если мы делим пополам, то будет 10 корней из n, как и заявлено в теории.
Ну что, сумел объяснить?
С какого момента? Вообще с самого начала те?
Смотрите, мы специально выбрали такое множество раскрасок, у которых все b1, bn одинаковые.
Что значит, что bit от hi1 и bit от hi2 совпадают?
Это значит, что hi1 от mit и hi2 от mit лежат на одном и том же отрезке длины 20 корней из n.
Значит, модуль разности hi1 от mit и hi2 от mit не превосходит 20 корней из n.
Они живут на одном отрезке длины 20 корней из n.
Значит, модуль вот этой разности не больше, чем 20 корней из n, но мы его еще делим пополам, получаем 10 корней из n.
Модуль hi1 от mit и hi2 от mit – это модуль вот этой разности пополам.
А модуль разности не больше, чем 20 корней из n, потому что они живут на одном отрезке.
Вот такая вот офигенная теория.
Ну, я сказал, что дальше надо взять вот эти оставшиеся одну миллиардную n-вершин и к ним похожий трюк применить.
Там недокрашенными останется, по-моему, что-то типа 10 в минус 49-й, что ли, степени.
Это мне на память помнится, но это вот запоминать надо с ума сойти.
Зачем это нужно?
Важно, что дальше ряд сойдется, то есть дальше я, честно говоря, предлагаю уже не прописывать доказательства.
Я начал с этой идеей, ну что ее повторять снова.
Чительки я называть не буду, это довольно бессмысленно.
Там каждый раз на 40 будет какое-то уменьшение, что-то минус 49-й, минус 89-й.
И мне этот ряд придется.
Слушайте, ну давайте я, наверное, на сегодня закончу просто пораньше,
потому что ничего нового мне начинать уже за оставшиеся 15 минут не хочется.
