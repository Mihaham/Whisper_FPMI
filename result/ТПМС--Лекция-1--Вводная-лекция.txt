в целом стало лучше ну хорошо давайте тогда начинать во-первых я очень рад вас всех
видеть здесь потому что вот я сказал уже я год разговаривал с компьютером это очень скучно
ну и к тому же вряд ли вы будете собираться так каждый раз поэтому здорово что сегодня мы здесь
надеюсь что никто не заболеет и мы весь семестр сможем видеться и разговаривать с вами вот здесь
друг с другом сегодня у нас нулевая лекция сегодня не первая лекция сегодня нулевая лекция по курсу
который называется конкарнси вот чтобы вас не написано было название в расписании название
неправильное курс называется конкарнси и вот сегодня я здесь для того чтобы объяснить вам о чем
же этот курс на самом деле что же я понимаю под этим словом и чем мы будем заниматься весь
семестр у сегодняшней лекции есть некоторые нюанс вот начиная со следующей субботы у меня
будет цель вам что-то объяснить вот я буду ждать что вы ничего не знаете приходится вам что-то
рассказываю вы узнаете больше чем знали на входе сегодня у меня такой цели нет сегодня я буду
говорить много каких-то сложных слов терминов и кажется не собираюсь их никак определять и
пояснять но то есть что мы поймем здорово если мы не поймем то будем в течение семестра разбираться
но просто я буду говорить те слова которые я буду объяснять вот следующие три месяца если
мы что-то сможем схватить в этом рассказе чем больше мы сможем схватить тем нам наверное будет
проще но если вы ничего не поймете то это не станет неким блокером мы дальше будем разбираться
подробнее я сегодня хочу объяснить вам во первых что такое конкарнти а во вторых чем мы будем
заниматься весь семестр потому что можно вообще разными вещами заниматься я пытаюсь объяснить что
мне важно и что мне кажется важно делать вам чтобы вы извлекли из этого курса просто максимальную
пользу для себя ну давайте начнем я почти весь семестр проведу на экране поэтому буду сидеть
здесь не очень уважительно к вам все же но так нам будет удобнее ну давайте разбираться так просто
объяснить что такое конкарнти нельзя и к сожалению привести это на русский нельзя если вам этого не
хватает я буду так называть конкарнти окей вот перед вами картинка не очень яркая но вы
наверное можете угадать что это там наверное написано но может быть написано мелко его не
разглядите поэтому придется угадывать это похоже на процессор да что примечательно в этом процессоре
вы видите но что-нибудь то есть мы конечно не понимаем какой он устроен он устроен очень
сложно но все какое-то одинаковое то есть какие-то компоненты которые почему-то повторяются ну и вот
если мы здесь выделим какие-то функциональные элементы в консервной блоке то мы вот видим что
здесь есть такие вещи как ядра cpu core когда-то на заре времен этих ядер не было вот такой
старенький процессор arm он выглядел так а сейчас он выглядит ну он выглядит гораздо сложнее
во первых конечно же прошло много лет а вторых вот в нем появляются какие-то одинаковые элементы
которые почему-то вот просто реплицированы скопированы это ядра и нужно объяснить почему
они в процессорах появились потому что наш курс про многопоточность там видимо ядра будут как-то
замешаны нужно мотивировать их появление ну вообще говоря не то чтобы они всегда были нужны вот
вы наверное знаете про закон muro слышали про него он про транзистор про то что там примерно каждые
два года число транзистора в процессоре удваивается но и этот закон в общем-то выполняется до
сих пор судя по этой картинке становится все больше и больше но вы signature то чтоational уменьшают
что их количество увеличиваются то есть не уменьшаются а важно то что их становится что
не становиться быстрее но вообще что такое транзистор как можно об этом думать вот процессор
на самом низком уровне он состоит ہے тех самых транзисторов таких элементарных переключателей из этих переключателей можно
собирать какие-то логические вентилей из этих вентиля можно собирать какие то функциональные элементы из них можно собирать
собственно весь процессор и вот этот процессор он там несколько миллиардов раз в секунду меняет свое состояние все эти
транзисторы переключается и вот видимо происходит какое-то вычисления
ну и о чем был закон мура о том что процессоры она был есть о том что транзисторы становятся меньше их становятся больше они становятся еще
еще и быстрее, по крайней мере раньше так было, они быстрее переключаются, вот они
научились переключаться два миллиарда раз в секунду, ну миллиарды раз в секунду,
вот и до какого-то момента времени, но до середины 2000-х годов они становились
меньше и быстрее, и вот вы можете написать программу в 2000 году, потом сесть,
подождать два года и она станет быстрее работать, потому что больше транзисторов
станет они будут быстрее переключаться и вычисления будут происходить тоже
быстрее. Но с какого-то времени, это перестало работать в смысле, они
перестали одновременно, становится и меньше, и быстрее, а не становятся меньше,
в процессоре их становится больше, из них, можно собрать какой-то более
сложную логику, но быстрее они больше не переключаются, вот и программы сами по
себе ускорятся, перестали довольно неприятно. Но вот если мы инженеры, которые
делают процессор и мы хотим делать процессор более быстрыми, то, что мы можем
сделать, если мы не можем вычислять быстрее.
Но вот мы можем делать что-то параллельно. Вот у нас транзистор
становится больше в процессоре, и мы можем задублировать элементы,
которые отвечают за вычисление, вот собственно сделать эти самые ядра.
Вот ядро — это тот компонент процессора, который отвечает за вычисление.
Что мы понимаем под вычислением? Ну вот такая условная картинка, есть
процессор, у него есть какие-то регистры, и процессор вычитывает
в памяти инструкции вашей программы и исполняет их.
Ну инструкции могут быть самыми разными, это могут быть инструкции,
которые выполняют какие-то репетические операции над регистрами,
это могут быть инструкции, которые отвечают за поток управления,
условный и безусловный переход, мы можем прыгнуть в другое место программы.
Ну и инструкции типа MOV, которые позволяют процессору взаимодействовать с памятью,
загрузить что-то в регистр из памяти или записать обратно.
И мы такие компоненты дублируем. Ну а дальше мы собираемся научить программиста
с этими ядрами работать. Нам нужно дать какой-то инструмент программиста,
чтобы он смог писать параллельные программы.
И так появляются потоки. Вот вы открываете документацию, скажем, по C++,
открываете библиотеку потоков, и вот там есть класс «Поток».
И что вы можете с помощью него написать? Вот вы можете написать такую программу.
Запускаем два потока, создаем экземпляр класса std.read,
передаем две функции foo и bar, и вот начиная с этого момента,
у вас на процесс, если вам вообще это позволяет, если у него достаточно ядер,
может параллельно исполняться функция main на одном ядре,
на другом ядре будет запущена функция foo, на третьем функция bar.
Ну они тут ничего полезного не делают, но могли бы.
Вот, то есть std.read – это такой интерфейс к ядру процессора.
Во-первых, задавайте вопросы, чтобы было сказать об этом.
Пожалуйста, задавайте вопросы, если вам непонятно, если вам интересно,
если я не говорю того, что вы ожидаете, то всегда спрашивайте,
так будет полезнее для нас всех.
Теперь отвечаем на вопрос. Программа скомпилируется, конечно,
но в конце концов представь себе старый процессор и операционную систему.
Вот там одно ядро в процессоре.
Это же неверно, что ты можешь запустить только одну программу в операционной системе.
Скорее всего, ты можешь запустить больше, но они будут просто упаковываться в это одно ядро.
Операционная система будет запускать одну программу,
а через 10 миллисекунд снимать ее с процессора и ставить другую.
Собственно, multitasking.
Вот здесь та же самая история.
SDTrad это такое виртуальное ядро.
Но вот как вы работаете с памятью оперативной в программе,
вы же не думаете, что у вас там 2 гигабайта, у вас там, не знаю,
экзобайты виртуальной памяти, более-менее бесконечная, это абстракция.
Вот здесь то же самое. SDTrad это такая абстракция,
которая дает программе как будто бы отдельное виртуальное ядро.
Конечно же, целое ядро программы не получит,
она будет делить это физическое ядро с другими программами.
Но вы как разработчик этого не замечаете, вы исполняете функцию main
и вы не знаете, когда планировщика операционной системы снимет ее с ядра
и поставит другую, когда вернет вас обратно.
Это все происходит для вас прозрачно.
В этом и смысл абстракции, вы не наблюдаете физические ограничения.
Так что программа скомпилируется, и если у вас ядер 4 или 8,
то эти потоки будут работать параллельно.
Если у вас ядро одно, то они будут чередоваться на одном ядре.
Ну, собственно, где-то у меня про это была картинка.
Вот какая-то такая история.
Вот у вас 3 потока, 2 ядра,
и они как-то перемещаются, возможно, между этими ядрами.
Ну и какое очевидное применение для этих потоков вы можете придумать?
Численное интегрирование.
Обычно вы этим занимаетесь, когда приходите домой, садитесь за ноутбук.
Да, наверное, вы можете с помощью этих потоков что-то распараллелить.
Вот действительно можно подумать про какие-то там численные методы,
про какое-то модулирование, вы строите там гоночный болид,
вам нужно, наверное, динамику обчитывать.
Или вы любите машинное обучение и там какие-то матрицы перемножаете.
Как вам помогут ядра здесь, потоки?
Ну, вот вы возьмете свою задачу и каким-то, ну, возможно, сложным образом
поделите ее, мне не хватает картинки, давайте ее найдем.
Да, конечно.
Они могли, ну, смотри, программа, можно, я не знаю, про это ты спрашиваешь или нет,
можно прибивать поток к ядру.
Так можно делать, но это нужно в довольно редких случаях.
Чаще всего это делать не нужно и о таких мелочах,
но о таких низкоуровневых деталях думать скорее вредно для твоей программы.
Так что нет, мы такого делать, наверное, не будем.
И чуть позже я, наверное, лучше смогу объяснить, почему мы этого делать не хотим,
пока это довольно сложно было бы сделать.
Ну ладно, вернемся к потокам, к распараллеливанию.
Что мы можем сделать?
Мы можем вот разбить задачу вот этой синенькой квадратики на части
и на каждую часть, каждую часть отдать своему потоку.
И если у вас едер достаточно, то эти потоки будут исполняться параллельно
и, там, не знаю, ваша операция, ваше учтение будет происходить,
ну, если у вас 4 гидрата, 4 раза быстрее, если 8, то 8 раз быстрее,
если 64, то, возможно, все 4, а возможно и меньше,
потому что есть закон Амдала, который ограничивает параллелизм,
потому что не все задачи идеально параллелятся.
Но не суть, вот мы таким заниматься вообще не будем, нам это не важно.
Мы не занимаемся параллелизмом в этом курсе.
Наш курс называется Concurrency, а это вещь совершенно иная.
Ну, вот параллелизм – это вот такая картинка.
Это вот, смотрите, здесь есть щенята,
ну, это классическая картинка из доклада RoboPike'а про Изого.
Вот здесь есть какие-то задачи, это вот миски с едой,
и есть щенята, которые их едят, видимо, в потоке.
Мы хотим поговорить про такую картинку.
Вот здесь все происходит немного иначе.
Здесь происходит какой-то бардак, потому что задачи нам интересуют другие.
Вот давайте посмотрим на код.
Я не знаю, умеете ли вы читать C++ с сетевыми какими-то операциями, с сокетами,
и уж тем более вряд ли вы знаете библиотеку ASIO, которая здесь используется.
Но вот на что это похоже?
Это похоже на сервер, да?
Он, видимо, обрабатывает каких-то клиентов.
Вот, во-первых, знаете ли вы, что такое сокет?
Все знают, что такое сокет, да?
Ну, хорошо, вот представьте какую-то большую компанию,
у которой есть гигантский дата-центр на десятки тысяч машин,
и в этом дата-центре живет какая-то распределенная система,
какая-нибудь база данных, которая хранит все ваши письма за миллионы лет.
И вот в этом большом здании, где эти 10 тысяч машин стоят,
есть две отдельные машинки, находятся далеко друг от друга,
и они хотят пообщаться друг с другом.
Между ними есть огромное количество каких-то сетевых коробок,
коммутаторов, все это связано в какую-то очень сложную,
очень хитрую многомерную коммутационную фабрику.
В общем, добраться от одной машины до другой довольно сложно.
Но вы как программист думать об этом не хотите.
Вам операционная система дает абстракцию прямого провода просто.
Это называется TCP-соединение.
И по этому прямому проводу можно в одну сторону
управлять поток байтов и в обратную сторону получать.
И TCP гарантирует вам, что вы получите те же байты
в том же самом порядке.
Ну либо соединение просто порвется.
Вот что делает этот код?
Он начинает слушать на некотором порту и принимает соединение.
Вот здесь написано acceptor accept,
и после этого вызова мы получаем очередной socket с очередным клиентом.
Вот я не сказал socket, это конец TCP-соединения.
По сути, это файловый дискриптер,
который вы можете писать с помощью системного вызова write
и читать с помощью вызова read, ну как обычно.
Если вы работали с пайпами, то socket здесь,
ну они, конечно, отличаются, но в первом приближении
можно о различиях не думать.
Ну и смотрите, что мы хотим делать с этими клиентами.
Мы пишем echo-сервер.
Echo-сервер – это такой бесполезный сервер,
который получает данные от клиента и посылает вам эти данные обратно.
То есть мы просто открываем, мы принимаем клиента,
и мы запускаем поток, который в цикле из socket-а читает какие-то байты в буфер.
Может быть вопрос?
Да.
Он же с переполнением будет?
Переполнение чего?
Ну при чтении вы же никак не придавите максимум в чтении.
Ну вот эта функция buffer, она выводит размер массива статического.
Так что я читаю не больше чем емкость этого буфера
и пишу данные обратно.
Но если ошибка, то я, видимо, сворачиваюсь.
Вот не слишком полезная программа, но это такое Hello World
сетевого программирования.
Вот если вы хотите сетевой сервис, то вот если вы пишете
какой-нибудь сетевой фреймворк, а мы, собственно, примерно для этого здесь собрались,
то вот Hello World – это такой базовый пример, который можно написать.
Чего мы от этого сервера хотим?
Ну, видимо, мы хотим, чтобы он мог обслуживать много клиентов.
И, видимо, все клиенты для нас равны.
Мы хотим, чтобы они обслуживались, ну, по возможности, параллельно.
Поэтому мы для каждого клиента запускаем поток.
Вот мы конструируем std-thread и в нем исполняем вот такую лямду.
Мы туда захватываем socket, и в этой лямде, в отдельном потоке
запускаем функцию handleClient.
Ну, вот смотрите, с одной стороны, потоки нам нужны были для того,
чтобы что-то распараллелить, чтобы что-то делать быстрее.
Вот мы могли умножить две матрицы там за какое-то время,
а теперь можем умножить их там 4 раза быстрее.
Это такое очевидное применение потоков.
Вот здесь же потоки для чего-то другого нужны.
Но вот мы же здесь явно ничего не ускоряем, у нас нет цели что-то ускорить.
Мы здесь боремся не за то, чтобы клиенты обслуживались быстрее,
а чтобы они все справедливо обслуживались просто,
чтобы мы могли пережить такой рейд-запрос, в который у нас будет.
И вот здесь есть много существенных различий.
Например, когда мы говорим про распараллеливание,
то сколько потоков разумно заводить?
Настолько, сколько ядер, потому что если их будет больше,
то просто операционная система будет их постоянно менять на ядрах
и просто тратить дополнительное время, чтобы перепланировать их,
чтобы всем отдать процессорное время.
То есть мы сами выбираем число потоков и разумно, чтобы оно было
сопоставимым с числом ядер.
Здесь же в этой программе мы число потоков не выбираем.
Число потоков зависит от того, сколько у нас будет клиентов,
и чем больше клиентов способно такой сервер пережить,
тем, кажется, нам будет лучше.
Мы боремся не за скорость, мы боремся за масштабируемость,
за то, чтобы обслуживать тысячу клиентов, 10 тысяч, 100 тысяч,
может быть миллион клиентов.
В чем еще существенное различие?
В том, что потоки делают.
Вот если мы что-то распараллеливаем, то потоки занимаются чем?
Они занимаются какими-то вычислениями.
Они читают из памяти, пишут память, что-то перемножают, делят, что угодно.
Чем занимаются здесь потоки?
Они чаще всего ничего не делают, они спят.
То есть ждут на операциях водовывода.
Они блокируются на чтении сокета и блокируются на запись сокета.
Большую часть времени они не работают.
Именно поэтому мы и надеемся упаковать вот эти потоки в небольшой число ядер.
Мы можем запустить серверы и обслуживать 10 тысяч клиентов.
Только потому, что вот эти 10 тысяч потоков все-таки могут улечься на 4 ядра,
потому что большая часть потоков спит, они работают.
Они параллельно не вычисляют, они параллельно спят.
Но есть некоторая проблема в таком подходе.
К сожалению, операционная система незадумана для этого.
Во-первых, вот это и есть конкарнси.
Это отличие от параллелизма.
В параллелизме мы сами выбираем число потоков, делим задачу на части и что-то ускоряем.
В конкарнси мы не выбираем число потоков.
Мы вынуждены обслуживать каких-то клиентов столько, сколько у нас есть.
И чем больше, тем для нас лучше.
Так вот, утверждается, что это решение не идеально. Почему?
Потому что в нашей задаче мы пишем эхо-сервер.
Единица конкарнси — это клиент, это обработчик.
Для каждого клиента должен свой обработчик, у него написана какая-то логика.
Пока она тривиальная, но, видимо, есть приложения более сложные.
Для операционной системы единица конкарнси — это поток или task, если говорить про ядро Linux чуть аккуратнее.
Это единица планирования.
Та задачка, которая ставится на ядро, исполняется 10 миллисекунд, потом с ядра снимается.
Так вот, операционная система не заточена под то, чтобы на ней запускали миллион или сто тысяч таких обработчиков.
Операционная система ожидает, что если вы запускаете поток, то, видимо, для того, чтобы он занимал процессор.
Чтобы он что-то вычислял, а не для того, чтобы он прыгал туда-сюда на чтение к записи.
И вот есть несоответствие масштаба.
Вот скажем, вы такой код не сможете запустить на сто тысячах клиентах.
Ну, вы упрете какой-то лимит, там библиотеки, операционные системы, но, в общем, это не слишком хорошо работает.
В то же время вы можете написать программу не на C++, а на языке Go.
И вот смотрите, как она устроена.
Тут я ни в коем случае не сравниваю C++ и Go, на смысле, что лучше или хуже.
Смотрите, вы можете не знать Go, это неважно.
Код вы должны прочесть, потому что Go похож на C.
Функция main, в ней тоже такой же цикл написан.
Бесконечный цикл, где мы принимаем соединение от клиента.
Тут вместо socket называется connection и запускаем.
То, что называется в Go, Go-рутиной.
И эта Go-рутина исполняет handle request.
Go-рутина – новое слово, я не собираюсь его определять.
Впрочем, я и поток не определял пока.
Но, надеюсь, это на какое-то ваше интуитивное понимание.
В первом приближении, Go-рутина для пользователей в Go неотличима от потока.
Это не совсем справедливо, но к нюансам мы вернемся гораздо позже.
И что делает эта Go-рутина в функции handle request?
Она в цикле читает в тот же самый буфер, а потом пишет обратно.
Она откладывает закрытие соединения на момент завершения функции.
Это как рай FC++, если известно, что это.
Код похож, да?
Он вроде не сильно отличается от этого кода.
Но я бы сказал, что ничем не отличается, кроме языка.
Но почему-то этот код способен пережить 100 тысяч запросов.
И миллион запросов способен пережить.
Оказывается, что Go-рутина в Go – это все же не потоки.
Go-рутина в Go – это некоторые виртуальные потоки.
И сам язык Go занимается их планированием, а не операционной системой.
Мы не можем довериться операционной системе.
Операционная система не задумана для такого.
Она планирует вычисления.
А мы здесь планируем вот вывод.
И поэтому в языке Go есть собственный runtime и собственный Go-рутина.
Или, скажем, код, который мы напишем, буквально через месяц.
Смотрите, как он выглядит.
Тоже эхо-сервер.
Мы принимаем в цикле клиентов.
И мы снова запускаем какой-то поток, который выполняет handle-request.
И в этом handle-request написано снова то же самое.
Кажется, третих кода похожи.
Но по крайней мере этот код на C++ написано, этот код написано на C++.
Тут style-guide отличается.
Немного интерфейса отличаются.
Но, в принципе, тот же самый код.
Вот сколько потоков использует этот код?
Откуда такая гипотеза появилась?
Но эта логика правильная, конечно.
Этот код использует всего лишь один поток.
Потому что в этом коде написан собственный планировщик.
Который планирует собственные...
Здесь это называлось в ГУАГ-рутины.
А здесь у нас это будет называться Fiber.
Но тоже какие-то виртуальные потоки.
Это некоторый инструмент, который необходим для того, чтобы уметь обслуживать клиента в большом масштабе.
Более-менее неограниченном масштабе.
Мы пишем свои собственные потоки.
Мы воспроизводим в пространстве пользователя
некоторую часть операционной системы.
И так делает, разумеется, не только ГУАГ.
Потому что сетевые приложения нужно писать более-менее везде.
Почти все, что люди сейчас пишут, они пишут с расчетом на то, что к ним по сети будут приходить запросы.
Так что в любом современном языке такие механизмы нужны.
Но вот есть ГУАГ, который вам предоставляет вот эти самые грутины.
Есть, давайте я покажу вам, похожую программу на языке Rust.
Она делает то же самое.
Снова цикл, в нем мы снова принимаем клиентов, а потом снова запускаем что-то.
И в цикле этой задачи мы снова читаем из socket, а потом пишем в socket.
Но если вы Rust не знаете, то опять не страшно, потому что, кажется, слова знакомые.
Socket, read, write, loop.
Но есть какое-то отличие.
Тут, смотрите, появляется какая-то точка await.
Какое-то асинхронное ждание.
В общем, какой-то специальный синтаксис для того, чтобы дождаться чтения socket.
Или же, смотрите, как выглядит эхо-сервер, написанный на C++20.
Что нам предлагают разработчики?
Вот предлагают писать такой код.
Тут, правда, нет обработки ошибок никакой, то есть этот код короче, чем должен быть.
Но опять снова цикл, снова socket, read, write.
И перед этим снова какие-то coawait.
То есть в C++20 есть некоторый механизм, который позволяет нам делать конкурентность
и не упираться в лимиты операционной системы.
В языке Go у нас только такой механизм и есть.
Грутины.
В Rust у нас тоже есть async await и framework-tokyo.
Да.
Это отличный вопрос, замечательный просто.
Вот смотрите, мы говорим, что вот такой код не масштабируется.
Операционная система не может обслуживать такое количество клиентов в отдельных потоках.
С другой стороны, если вы ходите на операционные системы или будете ходить, я не знаю,
зависит от вашей программы, то скорее всего вас научат способы эффективнее.
Вот есть E-Poll, такой событийный механизм, который позволяет обслуживать много клиентов в одном потоке.
Но правда код, написанный на E-Poll, получается абсолютно чудовищным.
Ну и вы сами напишите и убедитесь в этом.
Он чудовищный вовсе не потому, что он написан на C очень низкоуровневый.
Его можно переписать на C++, и он станет более удобно писать.
Но все равно он вывернут наизнанку.
Вот вы смотрели время приключений? В первом сезоне там появляется Magic Man.
Ему на руку садится голубь. Не помните, что дальше происходит?
Но я пришлю в чатик потом ссылку.
В общем, этот код вывернут наизнанку просто.
У вас здесь нет какого-то понятного цикла.
Вот вы пишете здесь код, и у вас есть простой цикл FOR.
Вы в нем читаете и пишете. Сразу понятно, что происходит.
И также такой же код вы пишете в GO.
Такой же код вы пишете в REST.
Такой же код вы пишете с циклом в C++20.
Где же он? Вот здесь вот.
А если вы пишете через E-POL, то почему-то все разрывается,
и никакого внятного цикла нет.
Есть какая-то странная цепочка из разорванных фрагментов,
которые перепланируются.
Это не похоже на цикл WHILE.
Здесь просто нет нигде цикла WHILE.
Тем не менее, операционная система для того, чтобы делать эффективный вывод,
дает вам именно этот самый E-POL и событийный механизм.
Так вот, как же вы думаете,
GO умудряется справляться с миллионом соединений в одном потоке?
Как мы собираемся делать это тоже в одном потоке с помощью некоторых файберов?
Но ровно так и собираемся.
Просто этот E-POL нигде наружу не торчит, и код вправлен обратно.
То есть это выглядит удобно.
Это удобно писать, но это эффективно работает.
И вот мы с вами хотим как раз в этом семестре, в этом курсе научиться,
как можно эффективно, как можно удобно описывать какие-то конкурентные активности в коде,
и при этом не жертвовать эффективностью, не жертвовать масштабируемостью.
Мы хотим и масштабироваться, и иметь эргономичные инструменты для выражения наших целей.
Ну и начал перечислять.
Такие инструменты есть в разных языках.
В GO это горутины, в C++ это корутины.
Ну или с программой, если вам так больше нравится.
В Rust это...
Ну там это фьючи называется, не суть.
В Java этого всего пока нет, но там делают.
И там это тоже называется файберы, как у нас.
Но потом их в Java переименовали и стали называть виртуальные потоки.
Еще одно слово.
Вообще слово множество.
В Python есть такие инструменты.
Правда, это клиент написан, а не сервер, но опять.
Какой-то await.
Опять, мы можем заводить много клиентов, заводить много соединений,
и все они будут упаковываться в маленькое количество ядер.
В Kotlin есть корутины, разумеется.
Вы тоже можете запустить какую-то отдельную активность,
она будет работать и чередоваться с остальными.
Кстати, чтобы лучше пояснить, что такое конкарнсия.
В этом коде, я сказал, запускается много обработчиков,
но они работают на одном ядре.
Это в чистом виде конкарнсии.
Здесь параллелизма нет.
Параллелизм конкарнсии — это вообще вещи перпендикулярные.
У вас может быть параллелизм без конкарнсии.
Это умножение матрицы параллельное.
У вас может быть конкарнсия без параллелизма.
Вот оно.
У вас один поток, и в него упаковываются много обработчиков.
Они просто чередуются там постоянно.
У вас может быть конкарнсия с параллелизмом.
Вы можете запустить программу на языке ГО,
и вот эти грутины, мало того, что их в одном потоке много,
они еще и запускаются параллельно в разных потоках.
То есть это можно комбинировать просто для повышения производительности.
В общем, в разных языках, во всех современных языках,
есть какие-то инструменты.
Но правда, вот иметь одни грутины или карутины,
или как они там, виртуальные потоки называются, мало.
Потому что программа бывает обычно сложнее, чем эхо-сервер.
Вот в осенье я на спецкурсе рассказываю про распределенные системы.
И вот там особенно много задач, которые связаны с конкарнсией,
потому что клиенты там начинают взаимодействовать друг с другом.
Они обращаются к какому-то раздеревному состоянию,
они должны друг с другом синхронизироваться.
Ну и тут появляются какие-то примитивы синхронизации.
Появляется, ну, Mutex для начала.
Mutex — это такой базовый примитив,
который позволяет синхронизировать два потока,
ну или большее количество поток.
Вот у вас есть потоки, которые запускаются, допустим, параллельно,
физически на разных ядрах.
Но они обращаются к одним и тем же данным в общей памяти.
Скажем, к какому-то, не знаю, STD-мэпу.
А вот теперь представьте, что у вас два потока на разных ядрах
начинают вращать одно и то же дерево.
Но они же ему переломают просто все конечности.
Их нужно запретить им так делать.
Для этого у нас есть Mutex.
У него есть всего лишь два метода — lock и unlock.
И гарантия такая, что если потоки вызывают,
перед тем как обращаться к общим данным Mutex-lock,
а потом после обращения вызывают Mutex-unlock,
то гарантируется, что между вызовом lock и unlock
может находиться только один поток одновременно.
Если кто-то Mutex-ом сейчас владеет,
если кто-то зашел в lock и находится между lock и unlock,
то другой поток, вызвав lock, заблокируется
и будет ждать, пока первый поток lock не освободит.
Ну вот такой примитив.
И это самое наивное, что можно сделать для синхронизации.
В C++ есть разные примитивы.
Есть Mutex, здесь есть RV-Mutex,
есть условные переменные, есть какие-то симмофоры, луэчи, барьеры.
Но мы это все напишем, это мелочи, это пустяки.
Современные языки, конечно же, предлагают вам инструменты более сложные,
более выразительные, потому что с помощью Mutex-а и кондвара
вообще-то в высокоуровневом промышленном коде вы нигде
почти не будете использовать никакие кондвары,
вот эти условные переменные.
Если вы видите, то этот код очень низкоуровневый
или плохо написан просто.
Например, что вам дает язык Go для какой-то сложной синхронизации?
Он вам дает...
Ну, Mutex-а тоже дает, конечно, но дает вам вещи посложнее.
Где-то они у меня были, здесь написаны, привиденные, сейчас я их найду.
Ну или полистаю так.
Дает вам каналы.
Вы запускаете грутину и протягиваете между этой грутиной, основной грутиной канал,
и здесь вы можете в него положить сообщение,
а потом здесь вы можете достать сообщение.
Ну тем, что канал реализован в пространстве пользователей,
никак с операционной системой не взаимодействует,
и он гораздо сложнее, потому что...
Ну ладно.
Если мы пока не знаем детали, а мы пока их не знаем,
может быть, что ничем не отличается.
Это, конечно, совершенно неправда.
Канал, наверное, что-то более виртуальное.
Пайп-то это просто...
Ну у нас здесь виртуальные потоки, и канал тоже, в общем,
этот пайп тоже, по нему операционная система ничего не знает.
Это такой примитив синхронизации.
А дальше, что с ними можно делать?
Можно, ну, блокироваться, ожидая сообщения из канала,
а можно делать...
Смотрите, что?
Можно делать селект.
Можно дожидаться сообщений из первого канала.
У нас есть два канала, мы не знаем, откуда прилетит сообщение в первую очередь,
мы дожидаемся сообщений из первого канала.
Ну и я вот осенью рассказываю желающим,
как, скажем, писать протокол репликации в определенных системах.
Протокол RAFT.
И вот здесь есть реализация этого протокола ногой,
и тут используются каналы и селекты для того,
чтобы мультиплексировать события,
с одной стороны, хардбиты, с другой стороны, запросы от пользователей.
Ну, более сложная логика.
Здесь вот как-то грутины сложнее взаимодействовать,
чем просто запускаются и там независимо работают.
Вот GO нам предлагает один набор инструментов,
каналы и селекты.
Язык Kotlin, в принципе, те же самые инструменты предлагает.
То есть там тоже есть каналы, там тоже есть селект.
Очень сложно написано, и мы в самом конце курса про него поговорим.
Это, наверное, такая очень продвинутая лекция.
Но это не единственные инструменты,
которые доступны для синхронизации высокоуровневые инструменты.
Скажем, вот есть такая известная статья,
и она плохо отображается у нас, и мы сейчас это починим.
The Server is a Function.
Это статья, которая была написана инженером Твиттера
про их фреймворк, на котором они пишут весь свой код,
все свои сервисы.
И здесь они оперируют не потоками и не каналами и не селектами,
они оперируют другими сущностями,
они все свои сервисы раскладывают на такой ортогональный базис
из трех абстракций, из фьюч,
рпс-сервисов и фильтров,
которые декорируют эти самые фьючи и сервисы.
Что такое рпс?
Должно долго объяснять, но идея такая.
В распространенных системах, опять пример,
в который нам нужно углубляться очень долго,
но лекция обзорная, поэтому я что-нибудь расскажу.
В распространенных системах узлы,
которые эту систему образуют, общаются с собой
часто, конечно, не напрямую через socket,
из слишком низкого уровня IP,
они общаются через протокол вызова удаленных процедур,
или удаленного вызова процедуры, я путаюсь, неизвестно.
В общем, идея такая, вы делаете вызов,
как будто бы вызываете какой-то метод на каком-то объекте.
На самом деле этот объект находится на другой машине,
и нужно ваш запрос, ваш вызов серилизовать,
отправить по сети, там он десерилизуется,
запустится в каком-то обработчике,
тут снова какие-то файберы появляются, видимо,
вычислиться ответ,
он серилизуется, полетит в обратную сторону,
мы его дождемся, запустим обработчик.
В общем, для того, чтобы такие RPC вызовы делать,
нам нужен какой-то специальный инструмент,
какой-то фреймворк.
И вот вы вызываете метод на другой машине.
Вот если вы вызываете обычный метод,
на локальной машине, вы вызываете функцию foo
и дождаетесь, пока она завершится.
В случае, когда мы отправим запрос по сети,
у нас API, как правило, асинхронная.
Мы отправляем запрос,
а когда он будет готов, мы не знаем.
Может, машина вообще откажет,
и мы никогда не получим ответ.
Поэтому мы не можем просто ждать значения.
Мы должны вернуть что-то, что называется future.
Это некоторое будущее представление
будущего ответа.
У нас прямо сейчас ответа нет,
но есть некоторый контейнер
для этого будущего ответа.
И мы можем с помощью специального синтаксиса
передать его в следующую функцию, какую-то асинхронную.
Это звучит как некоторая магия.
В общем, это некоторые другие API.
В твиттере написали все
на фьючах RPC,
а не на файберах.
Короче говоря, есть разные инструменты
для того, чтобы
описывать конкурентные активности
и чтобы их синхронизировать.
И каждый язык предоставляет
какие-то свои инструменты.
И даже если они похожи,
то они часто называются по-разному.
Я вот говорил файбер,
гарутины, виртуальные потоки.
Короче, целый зоопарк.
Как мы все это пишем и как мы это синхронизируем.
Но с другой стороны,
какой бы язык мы не использовали,
в конце концов,
под этим языком, под компилятором
находится один и тот же компьютер
с одной и той же операционной системой,
с одним и тем же процессором.
И значит, все эти разные
средства синхронизации,
разные инструменты должны в конце концов
на каком-то уровне работать одинаково.
Но тут уже упоминали про E-Poll.
Вот E-Poll — это некий низкий уровень,
который делится между всеми реализациями.
Если у вас фьюч,
если у вас файберы
с блокирующими сокетами,
в конце концов все спускается в E-Poll.
А с другой стороны,
по-другому скажу,
если все аккуратно написать,
то можно добиться такого дизайна,
где на верхнем уровне у вас
либо фьючи, либо
фьючи с комбинаторами,
либо гарутины с каналами и селектами,
а под капотом
у вас некоторое общее следоисполнение,
которое одинаково подходит для всего.
Ну вот, выглядят программы
на Rust, на Go
и на фреймворке
Twitter
по-разному,
но в конце концов
исполняются они все примерно одинаково,
используя примерно одни и те же абстракции.
Мы снова переизобретаем планировщик,
мы снова переизобретаем
логику планирования,
и оказывается,
что можно
всю эту сложную логику
разделить, отделить
от этих самых средств синхронизации,
средств конкарнсии
какими-то очень простыми абстракциями.
Короче говоря,
в нашем курсе будут две такие большие параллельные
сюжетные линии.
С одной стороны, мы будем говорить,
как описывать конкурентные активности в коде,
как их синхронизировать,
а с другой стороны, мы будем говорить
о том, как это эффективно исполнять на компьютере,
потому что компьютер, в конце концов, у всех одинаковый.
Если вернуться
к эхосеверу, то можно сказать так, что наш курс
про то, что с одной стороны,
как эхосервер написать красиво,
а с другой стороны, как написать его масштабируемо.
Это вот две цели, которые
не тривиально сочетаются.
Но смотрите, я показываю вам примеры
на разных языках. Неужели я от вас
требую все это знать?
Знать Rust, знать Go,
знать Kotlin.
Как вы думаете, требую я или нет?
Будет хорошо, если вы все это знаете.
Вот я так скажу, чем больше вы в своей жизни
видели, тем вам будет полезнее,
тем вам будет понятнее.
Но, конечно же, я этого
не требую прям строго, но я...
Мы знаем с вами C++, ну или думаем, что знаем.
И
мы собираемся все делать
на C++.
Ну,
с этим есть некоторые проблемы, потому что
в C++ почти ничего нет. Там есть библиотека
потоков, в которой нет почти ничего полезного.
Ну, точнее, есть какие-то очень базовые вещи,
но никакой промышленный код сложный,
никакие проекты настоящие с помощью
этого кода писать не...
С помощью этой библиотеки писать невозможно, конечно.
Но мы с одной... Мы, смотрите,
мы и не собираемся
как бы учиться вот пользоваться
всеми этими грутиными каналами и селектами,
и фьючами. Мы просто собираемся
это все написать сами.
Вот мы, в конце концов,
с теми из вас, кто справится, конечно, это будет
далеко не все, мы с вами за семестр
напишем свой собственный го.
Мы с вами напишем...
Ну, начнем с этих однопоточных
файберов потоков и напишем
масштабируемый эхо-север.
И сложность, конечно, не в этом коде,
а сложность вот где-то здесь спрятана.
Вот внутри этого вызова,
внутри этого вызова,
нам важно это сделать.
А потом мы научимся делать
эти файберы физически параллельными.
Мы сделаем для них...
Ну, напишем свой собственный го,
в котором будут запускаться...
Ну, тут не 100, можно 100 тысяч написать.
Мы...
Что сделаем?
Напишем свой собственный где-то...
Есть мютекс, наверное,
для вот этих самых файберов
параллельных уже.
Напишем свои собственный каналы для них.
Вот, строим канал,
запускаем файбер, и он
ждет с одного канала, пишет в другой.
И вот этот...
Ждет с второго, пишет в первый.
И они обмениваются сообщениями друг с другом.
Мы напишем для них селек.
Но это, правда, совсем уже сложный уровень.
Но те, кто сделают, будут большими молодцами.
Вот мы просто напишем свой го.
И...
Как вам сказать?
Не то, чтобы вы на работе
будет писать свой го, конечно.
Скорее всего, вы...
Есть некоторая тонкость.
С одной стороны, это полезно,
потому что вы поймете, как все работает.
Вы же приходите сюда не для того, чтобы...
Читать мутацию.
Это вы можете сделать на работе за первую неделю,
с тажировки вашей.
Я хочу, чтобы вы пришли на работу,
писали, допустим, на каком-то языке,
на языке Kotlin, Nagone, на любом.
Скорее всего, с какой-то вероятностью
это будет даже не C++.
Но при этом, запуская вот эту горутину,
вы будете глубоко, в самую глубину
понимать, что происходит.
Так же, как вы делаете pushback-вектор
и понимаете, что там под капотом происходит.
Где там реаллокации,
мы хотим этого добиться.
Но иногда, все-таки, нужно писать и самим.
Вот, смотрите,
совсем недавно
на хабре в блоге Яндекса
публиковали статью, Антон Получин
написал, если вы знаете, кто это,
про то, что Яндекс.Такси
когда-то был написан
на... Они используют микросервисную
архитектуру, то есть, у них много сетевых сервисов,
которые взаимодействуют между собой
и обслуживают все ваши поездки.
И весь сервис был написан
на Python.
Но на Python очень сложно поддерживать
большие проекты, и там есть проблемы с производительностью,
и тестировать это сложно, поэтому
разработчики за некоторое время
переписали все на C++.
И им потребовался свой
собственный фреймворк для конкуренции.
И они написали фреймворк,
где будут свои...
Вот пример кода.
Вот, скорее всего, да, вот он.
И тут какие-то...
Обработчик запроса, он
обращается к базе.
И, конечно, за таких обработчиков
запускается конкурентно очень много.
И это снова не потоки,
это те самые файберы.
И для этих файберов нужно писать
свои примитивы синхронизации.
И вот разработчики этим занимаются.
Сейчас я найду пример.
Вот кусочек
реализации их мьютокса для их файберов.
И вот на этом фреймворке дальше
пишется весь код.
Ну, то есть, иногда нужно писать свой го,
потому что...
Потому что задачи у вас такие.
Этим мы будем заниматься.
Ну, конечно, мы не с этого начнем сразу
с семестров, потому что
это сложная задача. Все-таки язык ГО
пишут очень опытные разработчики.
Мы начнем с чего-то простого.
Мы будем возиться сначала, там, первые недели,
первый месяц с какими-то вот мьютоксами,
условными переменными.
Научимся делать какие-то банальные вещи
для потоков, а потом мы пойдем глубже.
То есть, мы сначала напишем простенький
мьютокс для потоков.
Потом мы его используем для того,
чтобы написать thread pool.
То есть, просто будем использовать мьютокс
при нитивы синхронизации.
Потом мы в этом thread pool научимся запускать файберы.
Потом мы для них
переизобретем мьютокс.
Потом мы изучим лог-фри и узнаем,
как можно сделать мьютокс без мьютокса.
Ну, короче...
Это довольно сложно,
и все будет усложняться.
И я хочу, чтобы вы увидели, что
те, кто будут сдавать курс на отлично
или на очень хорошо, они увидят,
что мы делаем все по два раза,
потому что мы воспроизводим это сначала
на уровне какого-то верхнего,
а потом мы закапываемся очень глубоко.
Можно еще про атомики сказать?
Про атомики, да.
Я могу сказать следующее, что мы увидим с вами,
что Go можно сделать, имея один атомик.
Вот если у вас есть атомик,
то, в принципе, можно написать свой Go.
А что вы хотели про них услышать?
Если ты пишешь какие-то сетевые сервисы,
ты пишешь какую-то прикладную логику,
то вообще в твоем коде не должно быть
никаких мьютоксов, почти что и кондваров,
и атомиков.
Это очень низкоуровневый код.
Атомики нужны, чтобы написать
этот фреймворк, а не для того, чтобы
ты ими каждый день пользовался.
Но иногда нужно ими пользоваться,
но мы, собственно, этому всему научимся.
Что такое атомик?
Про это есть Домашка 1.
Там говорят, напишите атомик, пожалуйста.
Мы к этому вернемся через неделю.
То есть я говорю, сегодня понимать ничего
не обязательно, просто я какие-то слова произношу,
вы их запоминаете, а потом мы...
Атомик – это ячейка памяти, с которой можно
делать более хитрые вещи, чем чтение
и запись.
Вот чтение и запись – это две операции,
которые мы понимаем хорошо, но которых
не делали.
Нужно что-то еще.
Мы, в общем,
напишем все это голыми руками.
Имея один анатомик, мы напишем свой целый
ГО. И там, конечно же, научимся
какой-то ловкой синхронизации.
Но я бы сказал, что это только половина
истории. Но, по крайней мере, для меня
это только половина курса и может быть даже
не самое важное, потому что
вы изучите лог-фри, изучите какие-то схемы
управления памятью в лог-фри,
какие-то хитрые паттерны синхронизации,
а потом через полгода забудете это все.
Ценность курса не только в этом
и не столько в этом.
Вот, смотрите,
я вам поясню, в чем она довольно
таким странным способом.
Есть такой код,
есть крутины C++, такой механизм
для того, чтобы описать конкаранция.
И на крутинах можно написать
такой код.
Правда, непонятно, что такое
коэвейт, зачем мы его пишем здесь,
почему он нам нужен. В некоторых
кодах и не нужен, в ГОМ мы так не пишем,
но в C++ мы пишем. И вот мы решили разобраться,
как это все работает. Мы читаем
документацию вот эту, она чудовищная,
невозможно ничего понять, мы бросаем.
Но я вам говорю,
есть очень хороший блог, сейчас я найду
его, вот он.
Его автор Льюис Бейкер, один из разработчиков
крутины C++, он написал
5 постов про то, что такое...
сейчас я сложу 4...
4 поста про то, что...
как крутина внутри устроена.
И вот вы пытаетесь понять что-то
про коэвейт, вот этот самый, про это
маленькое ключевое слово.
Открываете этот блог, нажимаете
на ссылку,
и попадаете в огромную, сложнейшую
простыню.
Что происходит в этом коэвейте?
И в принципе
вы, может быть, даже разберетесь,
но с трудом запомните, впихнете
в это в голову. Но
как вам сказать? Вот представьте,
что вы хотите узнать, как что-то работает.
Вы набиваете там в поиске,
как работает там, не знаю, мьютекс.
И вам открывается какая-то статья, или вы код читаете.
Как работает Go, открываете там исходники
Go, читаете их.
Может быть, вы разберетесь.
Но, скорее всего, у вас
будет такая проблема, вы не сможете отличить
вот в этой огромной простыне кода
какие-то случайные, инженерные...
ну, какие-то инженерные случайности
от каких-то фундаментальных идей.
Вы не поймете, что важно, а что вот просто
ну, так написали.
И вот, читая этот пост, вы
вот сейчас, вы, в принципе, можете
через примерно месяц это осилить.
То есть, разобраться
в механике крутины. Вы способны
на это. Но
я хочу, чтобы мы...
Ну, если
открыть план лекций, где-то
он у меня есть...
Попробуем еще раз. То
крутина C++ это где-то середина апреля.
Довольно не скоро.
Почему?
Что?
Да, у нас будет канал... Сколько у нас вообще осталось времени?
Нисколько, да?
Сколько?
О, здорово, тогда мы все успеем.
К крутины
будут довольно не скорость C++.
Почему? Потому что я хочу, чтобы
к моменту, когда...
Когда мы к ним подойдем,
мы не просто смогли понять, как это работает,
а мы смогли понять, почему
оно именно так сделано.
То есть, мы начнем с каких-то простых задач,
напишем какой-нибудь простой
threadpool, напишем какие-то простые
файберы, а потом начнем думать,
а что с нашим решением не так?
Может быть, где-то можно что-то улучшить, может
где-то чего-то не хватает. У нас есть
threadpool, но мы не умеем из него вернуть
результат вычисления. У нас есть
файбер, но там почему-то планировщик довольно
монолитный, и там смешаны какие-то разные
подзадачи. И вот мы будем придумывать
какие-то абстракции, мы будем придумывать какую-то
декомпозицию. Итак, постепенно,
постепенно наши простые, грубые решения
будут
разделяться на какие-то,
ну я надеюсь,
артагональные, универсальные,
точные абстракции. Мы их будем постепенно
придумывать, и мне важно,
чтобы мы сами видели, что в них появляется
необходимость.
И вот мы будем заниматься этим
несколько месяцев, и когда мы дойдем до корутин,
то мы уже сами будем
чувствовать, что нам вот эти
абстракции и эти точки
абстракции необходимы. Мы будем
понимать, почему дизайн такой,
а не просто как он работает.
Ну то есть для меня это курс
наполовину про дизайн, и дизайн
это тот навык, которому
долго нужно учиться.
Вот вы можете закончить университет, вы можете знать,
как вращать красно-черное дерево,
стоить фибоначевой кучей, как суффиксные массивы
и там деревья писать, но это
из вас, ну вы все равно станете
старшим или средним разработчиком.
Вы не можете выпустить старшим, младшим
или средним, вы не можете выпустить старшим,
потому что для того, чтобы делать сложные
вещи, нужно хорошо понимать,
как выделять абстракции, как выполнять
декомпозицию, собственно дизайн уметь делать.
А этому учиться нужно
долго. И вот в
этом курсе, кажется, если вы будете
в правильном порядке
решать много задач,
то
ну не то чтобы вы научитесь
этому, но по крайней мере вы увидите,
как это можно делать, как можно придумывать
вещи, а не просто разбираться, как они
устроены. Это гораздо
гораздо сложнее.
Но еще раз, для этого нужно делать задачи,
поэтому я могу
вам объяснить, что да, вот здесь не хватает
этого, а тут можно сделать так.
Но я бы сказал, что
единственный честный способ этому научиться
это писать код самим и самим убеждаться,
что вам чего-то не хватает, что
вы сами чувствуете, что стало лучше,
что сейчас плохо, а можно сделать
лучше.
Поэтому
призываю вас решать задачи,
это потребует довольно большого количества усилий,
но если вы любите
программировать, то это все будет
оправдано. Ну и без дизайна,
конечно, будет
будет сложно, особенно в конце
курса, потому что вот темы,
которые будут у нас в конце, сейчас мы
к ним вернемся, вот Stackless Coroutines
и Unified Executors, это темы,
которые аккумулируют
очень большое
человеческий опыт, инженерный опыт,
который накопился. Ну вот, скажем,
все плюс-плюс сейчас разбираются,
а как сделать тредпул?
Это довольно базовая задача,
тредпул у нас буквально вторая лекция,
и мы его
напишем, за полчаса я вообще ничего не знаю,
мы ничего не знаем, приходим, тредпул готов.
Почему-то
все плюс-плюс
инженеры до сих пор пытаются придумать,
как он должен выглядеть,
как придумать для него интерфейс вообще.
И вот,
если какой-то длинный
пропозал, он, конечно, не только про тредпул,
но вот он совершенно гигантский, про то,
как вообще запускать параллельно задача.
Ну я его не долистаю до конца,
я устану, видите, он длинный.
Там какое-то огромное количество сущностей
задействовано. Рома, я правильно
посылки даю, да? Вот оно.
Вот огромное количество каких-то там, не знаю,
концептов, абстракций, вот
это такое, ну,
я бы сказал, что это
такой слишком
декомпозируемый дизайн, очень мелкие,
очень аккуратная абстракция,
у нас будет проще, достаточно хорошо.
Но вот люди приходят в конце концов
к этому, и
невозможно объяснить
то, что придумывают сейчас, не объяснив
какие-то более простые вещи, и не
пройдя путь с...
не пройдя путь, в котором
все эти абстракции сами собой будут
постепенно появляться.
Мы почувствуем необходимость во всей этой сложности.
Ну, что сказать?
Почему-то никто не спрашивает, почему мы пишем на C++.
Нет, это неправильная логика.
Мы пишем на C++
по двум причинам.
Сейчас объясню, что я имею в виду, спрашивая про язык.
Мы пишем
на C++, во-первых, потому что на нем можно
написать все.
Вот скажем, если мы пишем на языке Go, то
Go вам вот задает некоторые правила,
задает некоторый набор инструментов, грутины, каналовые селекты,
пожалуйста, пользуйтесь ими.
Язык очень продуман.
Он, собственно, создан для того, чтобы на нем
писали сетевые приложения, только для этого и создан.
В нем
все очень хорошо друг к другу подходит,
все продумано.
Его написали в Google, собственно,
аккумулируя весь свой инженерный опыт.
Там до 10-го года.
Но есть другие языки,
и вот есть, я показывал вам
статью про
дизайн в Твиттере,
и там другие примитивы используются.
Вот мы пишем на C++, потому что
на C++ можно написать все, что угодно.
Можно и написать Go, и можно написать Future,
и мы, собственно, это сделаем.
Но мне важно, чтобы вы понимали,
что курс, он не про C++, конечно же.
Это инструмент, с помощью которого
мы будем все делать.
С помощью которого можно делать и несколько
уровневые вещи, и
какие-то сложные абстракции выдумывать.
Но мы изучаем, конечно же,
не C++, и не дай бог,
не библиотеку потоков C++.
Это вообще вещь довольно бесполезная.
Мы изучаем какие-то
общие идеи,
какие-то общие идеи дизайна, общие концепции,
которые вы встретите в любом языке,
на чем бы вы дальше не писали.
В любом современном языке есть
конкуренция.
Крипт, Раст, Котлин,
Go, ну что угодно. Придумайте в любом
современном языке, там будут эти инструменты.
Если вы...
Простите. Пройдете курс
до конца, ну или почти до конца,
то чем бы вы дальше не занимались,
на чем бы вы не программировали, вам
вот эти вещи, которые вы встретите, будут знакомы.
Они будут немного отличаться, там будут
другие слова, другие названия,
но принципиальные внутренние механики будут теми же самыми.
Да.
Да, давайте я скажу,
что вот с введением
я закончил, я рассказал,
что я хочу от курса и от...
Да, вот я
рассказал про конкуренцию,
а не про курс пока, ну то есть в смысле,
что мне важно и что кажется
полезно понимать нам всем,
то есть какие задачи глобально мы собираемся
в этом семестре решать.
А теперь давайте поговорим
про курс, про току он организован.
Ну, во-первых, действительно,
говорю, что если вы пройдете курс до конца,
потому что не все пройдут,
и не всем это просто важно,
но может быть вы пришли сюда машинным обучением заниматься,
а вас сюда пригнали.
Вот курс, я сразу скажу, про программирование.
Вот он понравится тем, кто любит программировать.
Вот есть люди, но не то чтобы я их
осуждаю, вот просто разные люди есть.
И вот некоторым нравится возиться в байтиках
и писать какие-то структуры данных,
а некоторым важно заниматься чем-то полезным.
Для них программирование это просто инструмент,
чтобы там запустить обучение
за сети. И то и другое нормально.
Но вот наш курс он про
первых людей, конечно же, про людей,
которые им нравится программировать,
чтобы они не программировали, потому что мы будем
программировать довольно абстрактные вещи.
Вот какие-то там корутины,
файберы, экзекьюторы,
сендеры, ресиверы. Этого всего
на улице не встретишь. В реальной жизни
этого не существует. Это то, что придумал человек.
И вот вам это будет
интересно, если вам просто нравится программирование.
Если не нравится, то
ну, видимо, мы друг другу
не пригодимся.
Но не совсем, на самом деле.
Вот вернемся к плану курса.
Я бы сказал, что первые
пять лекций,
ну, четыре, если считать с нуля,
это не считается. Первые
четыре лекции полезны, наверное,
послушать всем, чем бы вы не занимались.
Они более-менее универсально
полезны.
Если говорить про конец
курса, то для того, чтобы
понять вот эти лекции,
нужно,
ну, или вот эти тоже,
нужно понимать
хорошо, что было на всех предыдущих
и все предыдущее сделать своими руками.
Ну, то есть, я ожидаю,
что у нас как-то вот очень резко будет
уменьшаться количество людей. Но по опыту
прошлого года,
по-моему, пятьдесят человек получили отлично.
Это очень много.
Из каких? Из двухсот.
Что значит уменьшаться количества людей?
Ну, вы послушайте первые пять лекций,
а потом перестанете ходить.
Потому что вам достаточно.
Что?
Нет, ну, вы можете отказаться,
конечно. Я имею в виду, что
курс обязательный.
Я бы хотел, чтобы он был по выбору,
чтобы людей, которые хотят обучать
нейросеть, не заставляли программировать картины.
Но пока это
не в моих силах, я попытался, но вот что-то
не получилось в этом году.
Так что
вам придется все-таки
что-то сделать, чтобы получить
какую-то достойную оценку.
Если вы не хотите работать
и вы согласны на минимальную
положительную оценку, потому что
вы просто ненавидите программирование,
то этого можно достичь за две недели работы,
за два воскресенья.
Мне кажется, что это довольно
гуманно.
По поводу устройства курса.
У нас будет канал, вот лекция закончится,
и до вас долетит каким-то способом
неизвестный мне ссылка на этот канал.
Там будет вся необходимая информация.
Курс представляет из себя
репозиторий, в котором
лежат все задачи.
Вы будете эти задачи
решать, они сначала будут простыми,
потом они будут усложняться.
Чем вы займётесь на первой неделе,
вам нужно просто пройти инструкцию
и развернуть
этот самый репозиторий,
развернуть рабочее окружение и научиться
давать задачу А плюс Б.
Это не так-то просто.
Заготовьте вечер
для этого, на это уйдёт время.
Не сразу объясню,
прокомментирую коротко,
почему так сложно.
Потому что курс сложный,
это некоторый большой
проект, в котором
много зависимости, какие-то библиотеки,
пять режимов сборки.
То есть ваша программа будет собираться
пятью разными способами,
и по-разному исполняться, чтобы
я смог из вас вытрести какие-то баги.
Опыт Шада прошлого года говорит,
что да, докер кажется умеет эмулировать другую
платформу, другую архитектуру,
должна работать.
То есть это всё
сложно, потому что программирование
сложно устроено.
Мы пишем не мэйн СПП
с какой-то
и читаем из файла, пишем файл,
мы пишем какие-то библиотеки,
они сложно устроены, для них нужно
понимать, как там устроена
сборка в C++, как работает система контроля
версий, что такое CMake,
что такое линтеры.
В общем, какой-то
опыт промышленного программирования
вам потребуется, если у вас его нет, вам придется
его получить. К сожалению,
другого способа у нас не будет.
Если у вас он есть, кажется, у вас должен быть
курс про это какое-то, то
вы с этими инструментами
столкнетесь.
Тут лучше вопросы вы задавайте, что вас
в первую очередь волнует, а я буду вспоминать и рассказывать
что-то сам.
Да, у нас будет
документ, вот он снова
не загрузился, там
описаны все правила, как вычисляются
баллы задачи, про дедлайны, про какие-то
лимиты, про обязательные задачи, требования
к оценкам разным,
про защиты, про списывания,
не списывайте, пожалуйста,
про то, как общаться в
каналах. Да, вот важно,
это все вы прочитаете сами,
в конце концов.
Давайте я расскажу про то, что вы
не прочитаете, то,
как получить от курса максимальную пользу.
Смотрите, курс у нас довольно короткий,
15 лекций,
и за это время не возможно ничего успеть толкового.
И я не смогу рассказать все, что знаю,
я бы хотел, но не смогу.
Времени у нас на все не хватит объективно, на лекциях,
на семинарах даже не хватит.
Поэтому я ожидаю от вас, что если вам
интересно, если вам хочется чему-то научиться,
то вы должны делать разные вещи
дополнительно. Во-первых, вы должны задавать
вопросы в чатах.
Вот у нас будет общий чат, и все вопросы,
которые возникают в мире,
должны попадать туда,
не к вашему семинаристу, не к вашему другу,
а в общий чат.
Потому что любой вопрос, который у вас возник,
скорее всего, нужен еще кому-то.
И тут есть следующая проблема.
Вот появляется какой-то умный человек
в курсе, но скорее всего, у вас
среди вас есть какой-то очень умный человек, слишком умный.
И вот он начинает сразу глубоко
копать и задает какие-то очень сложные вопросы.
Вы читаете чат и видите, что вы даже вопросы не понимаете,
которые этот человек пишет, и вас чертовски
расстраивает. А мы с ним
пообщаемся.
И если бы ему приятно, и мне интересно с ним
общаться, вы думаете, ну, Боже мой.
А я со своим тупым вопросом, что такое Атомик?
Вот так и знал, что я что-то ляпну.
Вот вопрос про Атомик
абсолютно нормальный, если вы его
первый раз слышите.
Собственно, вы для этого и пришли. Если вы все знаете,
то я вам не нужен. Вы просто
почитаете код и сами разберетесь.
Я для того, чтобы отвечать на вопросы,
когда вы чего-то не знаете.
Вот именно такие вопросы мне интересны.
Мне интересно, чтобы вы задавали простые вопросы
и узнавали то, что вы не знаете.
Вот тогда вы получите
пользу.
Вот я сегодня наговорил вам огромное количество слов,
которые вы вообще не понимаете, наверное.
По моему замыслу не должны.
Если вы понимаете, то, возможно,
вам не стоит сюда ходить.
Я говорил что-то про Мьютаксы, про Атомики,
про какие-то сокеты, еполы, файберы.
Задавайте вопросы, пишите свои вопросы.
Понимаете,
вы не пишете эти вопросы,
по разным причинам.
Вы ровно для этого поступаете в университет,
а не учитесь на курсере,
чтобы иметь возможность задать вопросы.
Это главная польза от очного обучения,
от того, что мы здесь присутствуем все вместе.
Часто бывает так, что
синдром самозванца.
Вы думаете, боже мой, он сейчас узнает,
что я ничего не соображаю.
Я этого и не жду вообще-то.
Это нормально, если вы чего-то не знаете.
Вы для этого и пишете,
задаете свои вопросы.
В чате будут рады и сложным вопросом,
и очень простым вопросом.
Но единственное, я от вас все-таки чего-то ожидаю.
Когда вы задаете вопрос,
было бы здорово, если вы не просто задаете,
как мне сделать что-то.
А вы объяснили бы,
подумали ли вы над ним сами.
Может быть, вы подумали
и ничего не смогли придумать,
и ничего.
А может быть, вы на чем-то споткнулись конкретным.
Напишите о том,
что у вас в голове происходит.
Я могу, конечно, вам
просто ответить на вопрос.
Как сделать это? Используйте такой вызов.
Или напишите такой код.
Но это не очень полезно, потому что я вам даю готовый ответ.
Вы все-таки учитесь для того, чтобы ответы сами находить.
И если вы объясните мне,
о чем вы успели подумать,
я смогу вам объяснить,
как додуматься дальше до ответа.
И это касается любых вопросов.
Сложных, самых элементарных.
Вот нет тупых вопросов.
Нет, конечно, нет тупых вопросов.
Я ожидаю,
что вы понимаете много
и понимаете мало. И то, и другое одинаково
годится. Это первое.
Очень важное. Пожалуйста, чем больше будет вопросов, тем лучше.
У нас в чате много семинаристов,
много ассистентов.
Если я буду до вас докапываться
с этими расспросами, то может быть,
ассистент вам ответить сразу нормально.
Пишите, главное, в чат.
Это первая сторона.
Второй способ извлечь в курс
больше пользы.
Читайте код.
Смотрите, вы открываете
первую домашку.
У вас уже будут сегодня задачи
про Mutex. Мы еще не знаем, что это.
Я вам кое-как за минуту объяснил.
Этого, в принципе, достаточно.
Для того, чтобы
что-то сделать
уже в первую неделю.
Открываете домашку, и там написано
«Напишите дедлог».
Но, правда, не на потоках,
а на файберах.
И вы идете
в эти файберы.
Это репозитория какая-то.
Научитесь его себе клонировать,
открывать VDE,
настроите себе IDE
и научитесь
запускать там примеры. Я открыл какой-то пример.
Запускаю его.
И он сейчас, надеюсь,
соберется, если я
не натворил бед ночью.
И он как-то работает.
Вот пример такой вот.
Так вот,
смотрите, что мне от вас нужно делать,
чтобы вы не просто запустили этот код,
а чтобы вы могли сделать вот так
хоба и попасть в реализацию.
А потом хоба и опуститься еще глубже.
А потом пойти сюда.
А потом пойти сюда.
А потом пойти в разные библиотеки.
А потом могли вернуться обратно быстро.
Вот в нашем курсе
будет довольно много библиотек,
довольно много кода, которые написаны вокруг вас.
И, собственно,
такова жизнь. Вы придете на работу,
и там будет написано уже миллион строк кода вокруг вас.
И вам придется...
Ну, у нас целый семестр впереди.
Мы...
У меня там компилируется, не знаю, там
200 файлов в спецкурсе.
Ничего не поделать. Так устроен мир,
но его можно изучать ингриментально.
То есть как-то по слоям. Не нужно
понимать все. Но нужно уметь
навигацию по коду. Нужно уметь по нему двигаться,
переходить в реализацию, смотреть, как что-то устроено.
Вот, пожалуйста,
научитесь это делать, потому что иначе
для вас курс превратится в какую-то череду заклинаний
странных.
Вот у нас есть какая-то одна из
задач, которые будут уже через несколько
недель, и вам там нужно
писать библиотеку.
Ну, собственно, файберы
с поддержкой сокетов.
И там используется какой-то механизм
обработки ошибок. И вот вы просто
должны уметь это сделать вот так.
Просто перейти в реализацию.
Не важно,
делайте это в Vim, VDE, просто научитесь
в вашей среде разработки
этим пользоваться.
Чем больше кода вы прочитаете,
тем большему вы научитесь.
У вас будет больше вопросов, вы просто будете
лучше понимать, что происходит.
Ну, и еще одна, может быть, странная вещь, про которую
на семинарах мы тоже подробно поговорим,
но пока, чтобы вас сразу не сбивало
это с толку. Если вы
открываете домашние работы в репозитории,
то вы увидите, что мы
используем на самом деле
не то чтобы STD
Mutex и STD
Treads.
У нас почему-то вот
такие странные объекты будут.
Ну, то есть,
namespace будет не STD, а Twisted Like.
В чем смысл? В том,
что мы занимаемся
синхронизацией в этом курсе.
И, конечно же,
вы будете ошибаться
в этой синхронизации.
Писать баги. Так вот,
баги, скажем, в алгоритмах искать
просто. Ну, почти всегда просто.
Это большой случайный тест, и там что-то разваливается.
В конкарнсе баги
проявляются сложно,
потому что они недетерминированы.
Вот все зависит от того, как
планировщик будет запускать потоки,
когда он какой-то поток снимет, седра поставит,
что он запустит параллельно, что он запустит последовательно.
Поэтому, если вы напишете даже грубый баг
и запустите такой наивный стресс-тест,
то, скорее всего, он ничего не поймает.
Просто вот сложно баги ловиться,
иногда очень сложно.
И ровно поэтому мы используем
для того, чтобы писать весь наш код,
мы используем
сейчас я найду,
специальный фреймвор, который
когда-то был для этого курса написан,
но не то, чтобы он как-то к курсу привязывал,
он на самом деле довольно общий,
про то, как можно тестировать
вот такие многопоточные баги,
ну, в смысле, код тестировать, как нам баги.
Мы берем, и в репозитории
про это есть короткая документация,
пожалуйста, прочтите ее.
Там говорится следующее,
что мы заменяем все примитивы
из стандартной библиотеки
на вот собственные примитивы.
Вот здесь раньше мог быть
STD-атомик, про который мы пока ничего не понимаем,
а теперь будет вот такой вот атомик.
Документацию можно
читать для STD, потому что
все эти примитивы повторяют интерфейсы,
ну, там с некоторыми очень редкими исключениями.
Но при этом
вот этот STD-твист-атомик
он может компилироваться
ну, там, по-моему,
тремя или четырьмя разными способами.
Вот тесты будут собираться, компилироваться
там раз по пять, и в каждой
сборке они будут вести себя по-разному.
Вот mutex, он может быть
mutex-ом настоящим,
а может быть mutex-ом, в котором встроенные
то, что называется fault injection.
То есть вы говорите mutex log,
а я вместо этого потока ваш переключаю на другой.
Ну, просто потому что, почему бы и нет.
Потому что операционная система сама это не сделает.
Она будет реже переключать. Я буду часто переключать.
И, скорее всего, из вашего решения
выйдут какие-то баги с большей вероятностью.
А в некоторые сборки...
Ну, вообще говоря, мы весь наш код
будем тестировать не только под настоящими
потоками параллельными, а еще и
под виртуальными потоками.
То есть, с одной стороны, вы будете их писать, а с другой стороны,
я их буду использовать для тестирования вашего кода.
И все это чертовски хитро.
Но когда-нибудь мы это поймем.
Просто не удивляйтесь и имейте это в виду, что
нужно писать всегда вот так.
Прочтите инструкцию в репозиторе, обратите на это внимание.
Ну, тут тесты очень специальны.
Тут не то чтобы тесты хорошие, тесты они
какие-то...
Запустим много потоков и навалим
их на какую-то структуру данных.
Дело не в этом, а в том, как это все
исполняется. Вот тут ронтайм меняется.
То есть не сам какой-то тест, а вот именно
то, как эти потоки на самом деле
под капотом этого фреймворка планируются.
Да, да.
Код style обязательно. Google Style Guide.
Линтеры будут.
Линтеры позволят вам отформатировать
автоматический ваш код.
И заодно проверяют, что
вы не пишете такое
if условия return true.
Вот такой код в курсе
запрещен, и он запрещен
автоматическими инструментами.
Clangtide.
Вот код, который не проходит
Style Guide, не соблюдать Style Guide,
не просто не протестировать.
Домашки будут...
Ну, если все совсем хорошо,
то буквально для каждой лекции будут
какие-то свои задачи.
Да, давайте сделаем...
Забыл. Самое главное для меня.
Решить задачи невозможно.
Но кажется, что в прошлом семестве никто
не смог. Но там, правда, некоторые задачи
появились позже, но...
Или смог?
Нет, в прошлом семестве никто не смог.
Но там, правда, некоторые задачи появились позже, но...
Или смог?
Или смог?
Три человека вроде было.
Но вот теперь будет больше, и
предлагается объявить какой-то конкурс
с каким-то грандиозным призом, который еще не придуман.
Вот для человека, который решит все задачи
в семестре.
Насколько я знаю, это некоторые альтернативные
моему предложению вещи.
Вот то, что я предлагаю сделать
очень сложно.
На это придется потратить много времени,
много усилий, много чему научиться.
Но вот если кто-то попробует решить все,
то будет здорово.
Все задачи решать не нужно для того, чтобы
получить отличный, даже от ЛУ-10 все задачи не нужны.
Критерии есть.
Там написаны обязательные задачи,
как рассчитывается балл.
Критерии может быть немного пессимизирован,
а может быть и нет.
Но вот если что, пройдет некоторое время,
мы, может быть, его пересмотрим.
Но, скорее всего, на это рассчитывать не стоит.
Все правила игры есть.
Если вы их соблюдаете,
то с вами ничего плохого не случится.
Ну что, у нас закончилось время?
Это будет... да, ура.
Это в канале будет.
