Окей, а сегодня у нас четвертая лекция, и мы продолжим, и, надеюсь, закончим говорить о
крещайших путях в графах. В общем, у нас сегодня будут две таких разноплановых,
два разных направления. Давайте обсудим. Первое – это двунаправленный алгоритм.
В чем их суть? Все задачи, которые мы с вами решали, они ставились, как у нас есть пара вершин.
Вообще у нас, точнее, одна вершина, и мы хотим либо найти крещайшие пути от нее до всех остальных,
либо вообще между всеми парами. И рассматривали разные графы, если это 0kbfs веса 0.123k, если это
до x веса, они отрицательные, форт Белман, вообще любые. В этот раз задача будет стоять
немножко по-другому. Дан граф, хотим дист от s до t, где s и t – это конкретные вершины, уже
определенные. Действительно, нам в реальной жизни, когда мы ищем крещайший путь, мы, скорее всего,
ищем путь от чего-то до чего-то, а не от чего-то до всего остального. И рассмотрим, что рассмотрим?
Рассмотрим в случае а, это двунаправленный bfs. Как ставится задача? Давайте мы 0k не будем
рассматривать. Будем рассматривать просто произвольный граф, где есть вершина s,
есть вершина t, есть какое-то облако между ними. Это может как-то петлять путь.
Что мы будем делать? Заведем очереди qs и qt. Вот такое, что у нас будет bfs и t одновременно
распространяться из вершины s такими волнами и одновременно из вершины t.
Вы знаете, что если граф ориентированный, то из вершины t мы будем ходить по развернутым рябрам.
Для bfs из s и bfs от t в g-транспонированном. И мы будем запускать их параллельно. Каким
образом мы это добьемся? Как вы помните, у нас bfs какой-то ваил. Пока очередь не пустая,
вытаскиваем вершины, обновляем расстояние, бла-бла-бла. Что мы здесь будем делать? Давайте мы будем
проверять, чтобы у нас пока никакого из очередей не пусто. И при этом мы будем извлекать и qs,
и qt-вершинки, и внутри одной тарасы этого ваила их релаксировать. Что тогда? Тогда
нужно понять, где достигается оптимум. Пусть будет вершинка f и напишем определение. Пусть f
это такая вершина, что ее первой извлекли из qs и qt. Ну, можно сказать и так. То есть
вместо встречи двух волн. В это время у вас просто не факт, что они одновременно ее извлекут,
но оптимальная картинка выглядит как-то вот так вот. И тут у физиков должны начать волн
и складываться. Тогда что утверждается? Когда мы извлекаем вершинку из очереди bfs,
а мы уже нашли до нее кратчайший путь, утверждается. Мы говорили, что мы храним вершинки
по оценке сверху на кратчайший путь, и дальше как только мы извлекаем, мы говорим, что эта оценка
точна. Здесь мы просто храним по кратчайшему расстоянию, поэтому кратчайший путь устроен как-то
вот так вот. Вот сюда, сюда. Зачем это нам надо? Ну, здесь и далее я буду пользоваться интересным
таким соображением. Наверное, все узнают, как выглядит карта Европы. Сейчас будет примерно
урок рисования. Это типа Италия. Конечно, есть что-то вот сюда. Есть что-то типа вот здесь вот
какой-то штуки. Ну да, здесь Балканы. Часто здесь вот где-то Греция находится. Где-то здесь Рим.
И допустим, вы хотите искать кратчайший путь из Рима в Афина. Зачем-то вам понадобилось? Не знаю,
у вас европейская турнира. Хотя не знаю, как скоро она может быть в наших реалиях, но допустим. И что
бы делал ваш обычный БФС? Как бы волны были бы устроены? Вот так вот. Ну, то есть понятно,
что вы захватываете какой-то лишний огромный кусок. В Афинах у вас бы аналогично бы распространялись
волны из них. А в случае, если у вас двухсторонний БФС, то вы на этом этапе уже найдете пересечение,
по сути. И у вас не будет вот этих вот огромных волн дальше распространения.
Но я не претендую на историческую и географическую точность. На географическую,
скорее, да. Вот. То есть у вас как бы гораздо меньше вершин будет затронута. Окей. Ну,
казалось бы, граф дорог это, конечно, классно. Но причем тут БФС, потому что у нас там,
мы считали за вершины перекрестки, за дороги мы считаем дороги между ними,
внезапно за ребра. И мы берем его вес как, что? Ну, внезапно как среднее время проезда этой дороги.
То есть у нас как получается вообще вещественные числа. БФС здесь не очень подходит. Давайте
перейдем к следующему. Двусторонний и двунаправленный принципиально. Да,
если захочется погуглить, то по-русски Google находит как двунаправленный, так двусторонний,
по-английски это bidirection. Да, сразу для некоторых по-английски фамилия Dx пишется
именно вот так вот, а не как в тех посылках, которые я просматривал. Ну, в общем-то традиции
я не буду изменять и сделаю все то же самое. То есть также запущу из СССР одновременно Dx,
да? Ну, все то же самое по сути. Давайте рассмотрим пример.
Какая вершина будет первой из обеих чередей? Через нее проходит кратчайший путь? Засада. Не
работает, получается, алгоритм. Вот, здесь его надо модифицировать. В случае Dx делается все вот так.
Пусть F это первая извлеченная из обеих чередей. Вершина тогда... Что можно сказать тогда? Тогда
ответ будет выглядеть вот так вот. Это минимум из двух величин. Dx от S до F плюс Dx от F до T. И
вторая врачина будет куда интереснее. То есть это вот то, что мы сами получали в ходе вот
этой вот конструкции. Dx от S до U плюс Dx от V до T. И еще скобку. О, такая вот штука.
Что это значит? Это значит, что давайте обозначим за S множество тех вершин,
таких, что Dx от S до U уже известно точно. Но, аналогично T, U, что Dx от U до T известно.
Вот почему неверно, когда мы извлекаем в момент одну вершинку? Потому что, на самом деле,
вдруг у нас в очереди, в наших очередях обеих, кто хранится? Хранятся, хранится такое вершина,
что между ними есть ребро и есть путь лучше. То есть мы знаем, что в этой, когда мы вытаскиваем
эту вершину из QS, у нас же в QS что находится? Как тройка, так и четверка. И когда мы вытаскиваем
тройку, мы действительно делаем, как в алгоритме Dx, здесь то же самое. Но проблема в том, что у вас
вот это вот ребро, оно может быть лучше, чем сумму вот этих вот бух. Поэтому вам нужно
привязать серебра между очередями. Собственно, это здесь и делается. Вот. Собственно, это доказывает
этого утверждения. Почему не нужно рассматривать другие вершинки, другие ребра точнее? Думаю,
плюс-минус понятно. Потому что у вас, если у вас вершинка не в очереди QS, значит она где-то
еще дальше. И она либо в QT, либо она вообще не участвует в кратчайшем пути. Если она в QT,
вы ее найдете. Если она нет в QT, значит она где-то вообще далеко. И если мы до нее даже не
добрались, значит очевидно, что есть путь короче. Вот. Строго доказывать я это не буду, потому что не
хочу. Так, это по двусторонним алгоритмам. Есть ли вопросы? Собственно, чем они хорошо тем,
что они работают на специальных графах гораздо быстрее, чем обычный алгоритм. С одной стороны,
с другой стороны, мы жертвуем функциональностью тем, что мы заедем и ограничиваем себя от одной
вершины до другой. Не от одной вершины до всех. Проблем нет, но зависит от того,
какую задачу вы решаете, тот инструмент выбираете. Это в принципе применимо не только к алгоритмам.
Здесь вам нужно поддерживать множество извлеченных вершин с каждой очереди. Ну да, как-то понимаете,
узнаватели пересечения, у вас множество излеченных из QS, множество излеченных из QT. Когда вы извлекаете
из нас, проверите, извлечена ли она из QT. Ну, unordered set, быстро проверяйте. Можно вектор булов.
Если у вас есть хорошая маска вершин в инты, то да, можно вектор булов. В общем случае, это будет
unordered set, конечно же, как вы узнали на ревью. Окей, что мы хотим дальше? Хочется обсудить вот,
что некоторые графы, в общем-то, не обязательно помещать все целиком в память. Почему? Ну,
допустим, я хочу посчитать расстояние от Афины до Рима, как на той картинке. Что тогда? Наверное,
весь граф дорог Европы немножко большой. Точных чисел я не нашел и для России не нашел. Нашел
для США количество чисел, ну, оценки, короче. Вот на 2010 год число, ну, давайте в таком
представлении считается, что модуль V порядка 24 на 10 в шестой, и Е порядка 60 на 10 в шестой,
что-то такое. Ну, много, много. Угадалось бы, в списке конференции не очень много, да, в памяти
можно целиком загрузить, да, и нормально в целом. Ну, как-то не очень хочется загружать оперативку
такими данными. Все-таки это, конечно, влезет, но это будет долго. Это раз, два, ну, Е лог В,
окей, хорошо, будет считаться плюс-минус норм. Но, опять же, у вас там всякие структуры,
которые требуют очереди и так далее. Ну и, суммарно, все замедляется, становится очень долгим.
Вот. Что предлагается делать? Давайте предложим так называемый евристический поиск. Что это значит?
Вообще, евристика — это такая некая идея, пришедшая сверху. Мы определим ее немножко по-другому.
Что евристика — это некоторое знание о задаче. Например, алгоритм Dx не обладает никакими
евристиками, потому что он просто ищет в произвольном графе пути. Но вот у вас есть,
смотрите, в контесте задача пятнашки. Это, если кто не знает, у вас есть там квадрат 4 на 4,
и у вас есть одна дырочка свободная в нем. Все остальные плитки расписаны,
ну, обычно вот здесь помещаются, и пишутся числа от 1 до 15. Ну и суть головонки в том,
что вам дали в каком-то произвольном положении, и вам нужно ее привести к такому виду,
где вы можете двигать плитки только на свободное место. То есть, например, вы можете один сдвинуть
сюда, и у вас свободное место станет вместо единички. Но если перебрать, то число вершин в графе будет
n!2. Ну, n здесь 15, 15!2 — это даже 16, n16!2 — это много. Будем честны. Вот, поэтому перебрать-то не
очень хочется целиком, хотя до иксера просто бы перебирал бы явное, и то есть в нем было
экспоненциальное время. Вот, и в общем случае наши евристические алгоритмы будут зависеть от того,
какие евристики мы используем, и мы не будем нигде строго оценивать их время работы. Почему?
Ну, потому что банально это очень сложно, потому что у вас для каждой задачи свои евристики, ну и
как-то вообще непонятно, как классифицировать, вот. Ну и, короче, как-то так, вы будете просто
надеяться на удачу, когда вы будете их писать. Вот, однако есть некоторая теория касательно
кратчайших графов, которую мы сейчас с вами будем обсуждать. Собственно, евристика — это
некоторое знание, евристический алгоритм — это алгоритм, обладающий евристиками.
Алгоритм, использующий евристики. Окей, и такой алгоритм евристический мы будем
изучать этот алгоритм Астар. Астар, а звездочка, а звезда, как его еще можно назвать, вроде больше
никак. Не, ну можно, конечно, а — это рация к линии, но такого я не слышал. А звездочка. В чем его суть?
Постановка задачи такая. У нас есть, опять же, граф, ориентированный, неориентированный, не важно,
мы хотим найти расстояние от С до Т, и все веса не отрицательно. То есть, хотим дист от С до Т,
W больше либо равна нуля. Да, весовая функция. Нет, это уже отдельно будет раздел. Евристический
алгоритм. Что мы будем делать? На самом деле действовать мы будем крайне просто и одновременно
крайне эффективно. Пусть H от W — это евристическая оценка на дист от W до T. И обычно берут оценку
снизу, потому что если у вас оценка сверху, то вы не будете идти по кратчайшему пути. Обычно берут
оценка снизу. Хотя, если там свести к эквивалентной задаче, то можно построить оценку сверху,
она окажется оценкой снизу в исходной. Но это такие шаманские трюки, которые мы не будем
изучать. Вы будете их дома проходить, когда будете пятнашки решать. Так, ну давайте возьмем не задачу
пятнашки, а возьмем нашу вот ту задачу с картой. И какую евреистику вы могли бы предложить? Ну,
банально, да. Давайте введем просто Евклидову расстояние. Пример. На карте. H от W. Ну расстояние
от W до T. А, Евклидова. Почему это будет оценка снизу? Вроде очевидно. Если вы говорите,
что H от W вот такая вот штука, то вы не можете бы лучше, чем это сделать. Ну, окей, хорошо,
здесь предполагается, что у вас уделенная скорость в среднем, порядка одной единицы длины на единицу
времени. По неравенству треугольника, не треугольника, точнее, у вас как-то путь будет
устроен как-то ломанное. Если предполагать, что у них средние скорости здесь и здесь равны,
тогда понятно, что этот путь короче, чем этот. Поэтому это оценка снизу. Вот.
Ну, казалось бы, оценка снизу можно быть, конечно, но не факт, что вы вообще классная оценка.
Там и простой пример. Это, внезапно, H от W тождественно равны нулю.
Ну, классная оценка, не спорим, она оценка снизу, она вообще обладает кучей классных
свойств на самом деле, которые мы будем потом выписывать. Это будет первый случай
предельный, а второй предельный случай будет вот такой вот. Ну, казалось бы,
тривиальные случаи, но только их можно анализировать адекватно. Вот. Так,
теперь про сам алгоритм, потому что мы его так и не сказали. Мы привели пример эвристики и
привели пример самых балдежных эвристик. Теперь нужно про сам алгоритм рассказать.
Алгоритм будет устроен очень просто. Будет прям как D extra, только равниваем по вот такой вот
интересной. F от W равный G от W плюс H от W, где G от W, оценка сверху на Dist от S до W из алгоритма D
extra. То есть у вас код вообще не поменяется на самом деле никак. Вы просто добавите в ваш алгоритм
D extra код вычисления эвристики от вершинки и будете в кучу классить не по G от W, а по G от W плюс H от W.
Поэтому давайте подумаем, что происходит в случае H, то это же ясно равный нулю.
В смысле ничего. Ну алгоритм работает, нет? Алгоритм работает прям как D extra, он просто
вырождается в D extra. Если вы сюда напишите 0, то у вас F2R внушает W, и вы получаете абсолютно D
extra просто. А что происходит в этом случае? Да, мы сразу идем по правильному пути, идем сразу вдоль
кратчайшего. Да, есть еще один алгоритм, в котором внезапно ставится G от W, тоже ясно равный нулю.
То есть F от W равно H от W просто. Он называется BFS внезапно тоже, но это не тот BFS, потому что
классический BFS to breadth first search, где мы это вот обход в ширину, а в этот случай будет BFS
best first search. То есть выбираем сначала лучшую вершину. Ну, видимо, да, в английском языке не очень
классно с разнообразием слов. Вот, но best first search никто не пишет, потому что это немножко
бесполезная идея, но просто как факт она и есть. Окей, теперь давайте немножко поговорим о том,
какие еврестики вообще бывают. Так, определение. H от W допустимо, если для любой вершины W из
множества вершин. H от W меньше либо равно, чем dist от W до T. То есть допустимая оценка,
допустимая еврестика, это когда мы оценим снизу. Поэтому обычно берут всегда допустимые
еврестики, и с ними все хорошо. Потому что если у вас еврестика недопустимая, то там, как правило,
вообще полный раздрай, и алгоритм еще хуже, чем дейсер себя ведет. Но насколько, опять же,
вдаваться мы не будем. Поэтому посвящены целые статьи огромные, в случае разных
еврестик, разные характеристики поведения. Окей, ну пример допустимой еврестики опять же вот,
эвклидовое расстояние. Но оказывается, этого недостаточно для хорошего работы алгоритма.
H от W монотонно. Если для любого ребра УВ выполнять следующее. H от У минус H от В
меньше либо равно, чем W от УВ. И H от T равно нулю. Такое определение. То есть ваша разность
еврестик не должна превышать вес ребра. И при этом еврестика от кончого состояния
равно нулю. Но это вроде естественное требование. Это не очень очевидно зачем-то надо. Но внезапно
оказывается тогда, что у вас верно, что у вас вот этот прирост не больше, чем вес,
и поэтому у вас очень похоже на Dx происходит действие. Вот.
Окей. Теперь докажем интересное утверждение об еврестиках.
W? Вот это вот? Ну у вас же есть весовая функция. Ну все, вот ее берете от УВ.
Утверждение следующее. Любая монотонная еврестика допустима. В обратном стороне это неверно,
кстати. То есть допустимые монотонными не всегда являются. А от монотона является допустимый.
Давайте доказывать. Что будем доказывать? Давайте доказывать индукции, наверное, да?
Индукции по реберной длине кратчайшего пути от V до T. Докажем, что h от V
не превосходит Dx от V до T. Ну и план такой, но это надо оформить красиво. Собственно,
это называется индукция в реберной длине. База индукции. h от T внезапно равно 0 по определению.
Потому что здесь h от T равно 0. Ну очевидно, для допустимой еврестики h от T тоже равно 0. Ну почему?
Потому что у вас h от T меньше, чем Dx от T до T. То есть меньше равно 0. И поэтому пути длины 0 это верно. Путь длины 0.
Так, переход. Давайте рассмотрим вершинку U и вершинку T. Давайте будем h от U показывать.
Чтобы у нас была согласованность обозначениях. Что мы будем делать? Рассмотрим кратчайший путь от U до T.
Очевидно, он имеет вот такой вот вид. Есть ребро у V, дальше от V до T. Почему? Потому что у нас
переход, потому что длина реберная кратчайшего пути хотя бы один. Пусть U, V, T кратчайший путь из U в T.
Что мы с вами знаем? Ну по определению монотонности мы просто знаем с вами, что h от U минус h от V меньше верно, чем Dx от U в V.
Логично? Логично. Что еще мы с вами знаем? По предположению индукции h от V меньше ибо равно, чем Dx от V до T.
Откуда вас следует, что h от U меньше ибо равно, чем h от V плюс W от U до V. Да? Ну просто h от V перенес сюда.
Теперь применяю вот это вот неравенство вот сюда. Вот следующий переход. Что меньше ибо равно,
чем Dx от V до T плюс W от U в V. Ну так как у нас V выбиралось как вершинка на кратчайшем пути, здесь просто
равенство Dx от U до T. Ну тривиальней, что это уже не доказано. Собственно, как вы думаете,
почему ивристика называется допустимой? Нет, не поэтому. Потому что давайте подумаем,
что происходит, если у вас ивристика недопустима. Правда ли тогда, что в первом инфривене,
когда ваш астар обнаружил вершину T, будет верное кратчайшее расстояние? Вот, поэтому она
недопустима будет. Собственно, ивристики допустимы, если только если у вас оказывается,
что ответ, когда вы нашли их первые вершины T, это будет кратчайший путь. Вот, вот так вот скажем.
То есть допустимость как раз таки обозначает то, что вы найдете, что если вы нашли ответ,
то он правильный. А монотонность гарантирует вам плюс-минус оптимальность поиска этого пути.
Потому что он работает не хуже, чем Dx. Вот так скажем. Доказывать это я тоже не буду. То есть
если у вас ивристик монотон, то ваш алгоритм работает не хуже, чем алгоритм Dx. Вот так скажем.
Ну здесь наверное хочется посмотреть на то, как будут устроены у астара волны его. Но они будут
устроены реально просто. На самом деле в BFS я вам соврал немножко. Я не рисовал волны вниз,
чтобы BFS бы и их проходил. А вот астар уже почти не будет их проходить. У него будут какие-то вот
такие вот волны. Также здесь. Такое. Даже не будет далеко уходить на самом деле.
Он отсюда пойдет. Они пересекутся где-то вот здесь. Не совсем мало просмотрят пути.
Круто, да, уже получилось. Если у вас есть ивристика геометрическая, то он будет как-то
каситься вдоль этой прямой в основном. Но, однако, можно ввести еще какие-нибудь парочку ивристик,
всяких географических. То, например, мы знаем, что от этого до этого нельзя добраться быстрее,
чем пройти через эту точку. То есть вести несколько таких ориентиров по карте, где мы будем выбирать
из множества ориентиров тот, который нам ближе всех, и ходить до ориентиров так. Вот внезапно
эта оптимизация называется ALT алгоритм. Я про него пока что умолчу. Если будет интересно,
можете почитать. Там выбирается несколько ориентиров на карте. Дальше там берется из каждого
ориентира считается крещейшее расстояние до всех, обычной dx-трей. А дальше у вас очень
быстрый ответ происходит, потому что вы из каждой вершины пытаетесь добраться до оптимального
ориентира на текущий момент. И все. Мы там в силу неравенства треугольника и прочей геометрии,
все очень быстро схлопывается. Еще быстрее, чем вот это. Что еще нам нужно? Наверное, все.
Единственное, что можно доказать, что эвристика эвклидового расстояния является монотонной,
но это опять же в силу неравенства треугольника, верно? Всякие примеры эвристики вы будете
рассматривать на семинаре. И тут, казалось бы, можно сказать, ну окей, давайте сделаем двусторонний
астар. Можно же двусторонний астар сделать, да? Но я не буду этого делать, опять же, потому что это
немножко неприятно. Кому интересно, тоже можете почитать. Очень классный алгоритм, но там, во-первых,
надо сам астар менять немножко, потом там эвристики нужно выбрать две и их согласовать. То есть,
не самая приятная техническая задача. И сейчас, внезапно, мы вообще от графов немножко отойдем.
Внезапно. Почему мы это сделаем? Потому что для дальнейшего изучения графов нужна определенная
структура данных интересная. Система непересекающихся множеств.
СНМ или по-английски DSU. The Joint Set Union. Вот. В чем ее суть? Изначально у нас есть
N элементов. Каждый из них все множество. Вот какое-то вот такое вот интересное множество
на восьми элементах. Что происходит дальше? Есть два запроса. Первый тип запросов это Unite,
от A, B это объедини множество, где лежат A и B. Ну, если это одно и то же множество,
ничего не делай. И второй запрос это R Same, от A, B лежат ли в одном множестве A, B. Ну,
самая простая сдача, которую можно придумать на эту штуку, помимо таких запросов, это вам
дан изначально граф без ребер, докидывают ребра, спрашивают, сколько компонент связанности на
текущий момент. Если разрешить удаление ребер, эта штука не работает. Эта штука называется Dynamic
connectivity problem. Это вообще достаточно известная научная проблема, по которой последние оценки
получил товарищ из Петербурга относительно недавно. Но там сложные структуры, и в целом Dynamic
connectivity problem мы разбирать не будем. Таковую тоже вам на самостоятельное изучение материал.
Идеи как-то реализовывать. Ну, самое простое, это давайте для каждой вершины будем хранить номер
множества. Тогда R Same действительно вообще за вот единицы делает. Просто берете листья в две
ячейки и такие, ну круто, равно не равно. Но вот Unite немножко долго будет, порядка ООТН. То есть
наивная реализация, это будет у нас пара ООТН от единички. То есть первый элемент запрос Unite,
второй R Same. Вот. Ну что еще можно делать? Ну, наверное, ну не знаю, как еще можно делать.
Ну можно хранить суты, да? Просто, вот прям как говорится, система не пересекающая множество.
Давайте просто хранить множество явно. Давайте подумаем, Massive, Unite, за сколько работает.
Вот, ну неправда вообще. Мы доказывали с вами на семинарах, амортизированно, что если вы меньше
приливаете к большему, то получается амортизированный логарифм. Ну окей, а R Same, если Нор, то единичка. Давайте
от единицы напишу. Если здесь просто сет писать, то здесь лог квадрат и от лога N будет. От N, от суммарного
числа элементов. В смысле, от суммарного всего элементов изначально. А, правда, да, действительно. Мы не
умеем так проверять. Согласен. Мы не умеем проверить, что А и Б в одном множестве. Давайте научимся так.
Будем хранить не множество, да? Давайте здесь напишем ОТН. Пока что. Такую грубую оценку. И это скажем,
что это unordered set. Теперь давайте посмотрим, если это деревья поиска обычные, тогда что я могу
брать? Я могу взять у элемента его корень, его дерево поиска. Аналогично у этого взять, у Б взять
корень дерева поиска. Если они равны, то они лежат в одном множестве. Если нет, то нет. Логичная
идея. Давайте просто напишу set. Ну тогда у нас здесь будет пара. Ну и допустим, что я умею брать,
ну не знаю, давайте возьмем минимальный элемент в множестве, например, а не корень, чтобы я умел
ходить к нему. Чтобы я не мог писать свои деревья, просто брать там звездочка Бегин. Здесь я получу
амортизированный квадрат логарифма, а здесь я получу от лог N, потому что я должен у А и
Б запросить у его множеств, типа чувак, давай-ка говори, чтобы в одном множестве. Ну и как это
все поддерживать? Например, можно поддерживать массивчик от 1 до N, ну длиной N, где у нас будет
в этой чеке лежать указатель на ноду в дереве. Согласны, что так можно сделать? Ну и тогда я
смогу получить явный доступ к этой ноде, я смогу получить от А и от Б явный доступ к этому дереву,
к ноде, явный доступ к ноде этого дерева какой-то. Добраться до их корней, давайте без минимума
обойдемся, и проверяем вот это вот на равенство. Вот уже круче, да, идея? Ну, только в массиве мы
храним указатели, здесь мы не храним никакую информацию о том, как они там объединены и так
далее. United делается очень просто, вы просто делаете все то же самое, что здесь, главное за
указателями проследить, что они останутся валидными. И что, ну вы можете хранить указательные элементы,
как вы будете хранить указательные элементы. Точнее, не так, тогда вам придется при переливании кучу
указателей перекинуть, а не НСМР на Луген, да. Ну да, можно в этом массиве, давайте вот с этим массивом
еще что можно сделать, можно в нем хранить, собственно, самый NORROR set, но его не копия,
а указатель на него. Я смогу из АСБ узнавать нужную мне хаш табличку и прячь, что они равны или нет,
ну по адресу просто равны или нет. Ну почему? У нас станет новый сет, и мы вернем на него указатели,
просто двумя им переприсвоим. Так нет, зачем вы вливаете? Так нет, давай, я не буду просто
создавать новых сетов, я изначально создам все пустые, ну начнем все по одному элементу,
но дальше при переливании меньшего к большему у меня на большее указательство не поменяется.
Зачем? Я явно же их переливал и просто им переприсвою указатель новый массиве.
Да, но это тоже самое, что здесь Луген амортизировано, то же самое число действий.
Ну вы доказывали на семинаре, что у вас при переливании меньшего к большему будет за Луген
амортизировано делаться при переливании. Это тоже самое, абсолютно. Вы для того же числа
элементов меняете штуку за вот единицы. Будет, но мы же в этом же не предложили.
Не, на самом деле мы-то придем к нормальной реализации в конце концов. Вот, ну окей,
понятно, что есть куча вариантов реализации, но мы сейчас обсудим нормальную, уважаемую реализацию.
А именно у нас будет две эвристики. Ну здесь эвристика не в плане того, что это какое-то
сверхзнание, а в плане того, что это будет просто такой эвристический подход к этому всему.
То есть мы будем применять какие-то два соображения, которые не очевидно, что дадут профит,
потом мы с вами не докажем, что они дадут профит, а просто напишем, что они дают профит.
Да, план примерно такой у меня. Ну, там есть просто нюанс, что если доказывать,
что будет профит, то это ну немножко 25 листов в статье Тарьяна надо переписывать. Поэтому я откажу
себе в таком удовольствии, но с удовольствием скину вам ссылку, чтобы вы могли почитать.
Вопрос на 9 на экзамене. Что мы хотим? Мы хотим эвристики. Первое это ранговая или весовая эвристика.
Что бы она заключается? Переливай меньше к большему, собственно все. Переливай
меньше к большему. А теперь перед второй эвристикой надо обсудить, как мы будем хранить
нашу структуру вообще. Давайте хранить для каждой, вообще мы будем хранить систему не пересекающих
множеств, внезапно это будет просто лес деревьев, где каждый дерево это отдельное множество.
Видим, как массив где-то деревьев. В одном дереве одно множество. Ну тогда понятно,
что вот это амортизированный логариф, он там и существуется, как мы делали в хэштаблицах.
За счет чего теперь мы будем делать? Как будем проверять? Раз у нас есть дерево,
можно для каждого элемента вычислять его предка, да? Арсейм это будет равны ли корне,
а юнайт это будет прилить меньше к большему. Указалось бы профита пока никакого.
Теперь давайте делать следующую интересную величину. Давайте вызовем функцию
pine set от A вернет представителя множества или корень дерева. Потому что мы хотим,
чтобы для всех элементов одного и того же множества был один и тот же представитель.
Очень удобно сказать, что это корень. Тогда арсейм это равенство pine set от A и B,
юнайт это просто прилить. Теперь давайте сделаем единственное, что классное в этой
всей операции. Давайте рассмотрим путь. Сказать, что у каждой вершины это дерево,
предок это вот этот чувак, это корень. Можно так сказать, да. Ну да, так будет проще,
вы хотите очень быстро делать, поэтому говорите, что будто бы подвешиваете меньше к большему
такой связью. Давайте, что я сделаю, давайте обозначу вершину 1, 2, 3, 4, 5 и в момент вызова
pine set я же что делаю, я иду от этой вершинки вверх, а если меня будут вызывать кучу раз pine set от A,
давайте сделаем это оптимизировано. То есть всех, кто на пути, будем подвешивать корню,
и это называется веристика сжатия путей. Путей на пути, pine set, всех к корню.
Здесь будет несколько утверждений про время работы и всего этого добра. Так, утверждение 1,
если применить только одну веристику, то время работы
на запрос. На любой из запросов будет звёздочка от log n время работы при применении любой одной веристики.
Давайте определение дадим для следующей штуки. log звёздочка от n равно k, если log log log
k раз, здесь берётся лог гриф по основанию 2 обычно.
Здесь log звёздочка от n меньше либо равно ум и единица. То есть для 16 что вы делаете?
Почему? лог гриф 2 от 16, 4, лог гриф 2 от 4, 2, лог гриф 2 от 2, 1, лог гриф 2 от 1, 0. То есть это не
просто логарифм, это сколько раз нужно взять логарифм, это вот настолько медленно растущая
функция. Например, можете показать, что лог звёздочка от 2 в степени k это k. Да, ну совсем плохо, это фиаско вообще.
Вот утверждение, которое может выпасть на экзамене в качестве задачи на 10. Это если применять
обеевристики, то время работы на запрос.
Звёздочка, это вот этот вот. Ну не принципиально в каком основании, у вас же констант здесь
тогда будет вылазить. Ну можно по двоичному взять. Вот это уже интересная оценка. Нас заведомо крусе,
чем логарифм, но ещё не от единицы. Но до от единицы мы не дойдём, не бойтесь, потому что так случилось,
что не дойдём всё-таки. Нет, ну это если вы пойдёте на 10, вам совсем не повезёт,
его придётся доказывать. Я доказывать его не буду, очевидно. Ну это задача на 10.
Читайте статьи. Можно доказать сразу следующую оценку будет, тогда я поверю. Вы знаете,
как это доказывать. Ой, так, сейчас, если я возьму листочек, потому что здесь что-то страшное. Это
то, что я напишу, вы даже на экзамене не должны это помнить, скорее всего. Определение. Знаете,
что такое функция кирмана? Это такая интересная функция. Равно n плюс 1, m равно 0.
У неё есть несколько замечательных свойств. Это первая в истории полученная непримитивно
рекурсивно вычислимая функция. Если у вас был матлог, дискретки или что-то похожее на это,
вы должны знать о понятии рекурсии с точки зрения формальной теории алгоритмов. Там самый класс
примитивно-рекурсивные функции. Это функции, которые используют самый примитив вообще,
который можно только в рекурсии использовать. На программическом языке приводится, что вы
имеете использовать for, всякие if и всякие if-мечку тоже можете использовать. Но вы не можете
использовать call while. Примитивно-рекурсивно вычислимые функции — это те, которые не используют
while в своих вычислениях, или у которых можно реализовать без while. То есть вам нужно в каждом
форе знать четко, сколько у вас итераций будет. То есть там нельзя, например, написать for и условия
is while. Нет, вы должны четко знать число итераций. Но это было бы классно, конечно, for и условия
is while, но нет. Вместо того, что есть у вас for и от 0 до n-1 плюс и. Вот. Это только такой for разрешен.
Вот. Этой функцией внезапно нельзя так написать. Потому что, если вы будете это пытаться делать,
у вас там будет в форе вылезать рекурсия, когда вы будете читать границу фора. Это неприятно.
Собственно, чем интересна еще эта функция? Это последняя, чем она интересна. Да, во-первых,
эта штука используется в тестах рекурсии, очевидно. Если у вас там был питан, то, по-моему, есть задача
написать функцию кермана и посчитать 4 рекурсивных вызовов. И оно очень быстро умирает внезапно.
Почему оно очень быстро умирает? Но здесь нужно просто знать вот такое вот. Ну как нужно знать?
Нужно просто понимать, что это вот такое вот интересное число. Сколько тут? Еще двоечка. Еще
двоечка. Еще двоечка. Еще двоечка. Еще двоечка. Еще двоечка. Вот так вот. 8 двоечек. Это много.
Это точно константа? Да. Это точно константа. Люди посчитали 1,4,4. Ну с какими целями? С такими,
что вводят вот такую вот штуку. Сейчас, ладно, я скажу, что вот что у меня здесь написано. Возможно,
я ошибся в количестве двоечек. Что если я здесь вот так вот оставлю, здесь напишу 6,5,5,3,6. Вот это
будет правдой. Но это вроде 2 в 16, 2 в 16 это 2 в 4. То есть 2,2,2,2. Да, 4 двоечка еще сверху надо
накинуть. То есть длина башенки 8 двоек. Балдежная, да, тема? Зачем нам это надо? Есть вот такая функция,
обратная функция кирмана. К такое что? Да. Как вы можете догадаться, альфа от вот такой
штуки это 4. Теорема по авторствам товарища Тарьян. Без доказательства. Время работы запроса.
Амортизировано альфа т. Как он это доказывал? Оставляю вам 25-страничную статью Тарьяна на
домашнее чтение. Ну это и при использовании обеих ибристик, конечно же. Не при одной,
обеих надо сразу использовать. Есть какие-то провокационные статьи, что здесь можно единицу
поставить просто. Но там как-то не верят. Вот этому поверили. Возвездочка от единиц еще не верит
научное сообщество. Подожди, это важный вопрос. Вопрос компьютер-сайенс.
Вот когда вы решаете теорки, вам явно будут писать альфа от n. Если вам не пишут альфа от n,
значит вы должны без альфа от n обойтись. Вот в теорках. В контесте, конечно же,
можете считать, что эта единица смела при оценках. Потому что она не больше 4. Ну камон.
Ну не для трех. Там, по-моему, более-менее удовлетворимое число. Число башенок сильно меньше,
здесь не минус 3, а минус какое-то другое число. Но можете на википедии табличку посмотреть,
там есть от 1 до 4 по каждому параметру, вычисляя функции значения кирмана. Быть может до 5 даже,
но я не уверен. А дальше они просто пишут, как оно плюс-минус должно выглядеть. Потому что это никто
не считал. А, давайте я код напишу. Ну короче, там суть в том, что самое интеллектуальное – это как
вот эту часть реализовать. Там рекурсивные свойства C++, так скажем. Рекурсия – это плохо,
но здесь без нее никуда. Потому что… Можно, конечно, по-моему, раскрыть эту рекурсию.
Типа сначала вы находите предка, явного корень, потом каждому форум подвешиваете на этом пути.
Но там прикол в том, что там просто в три строки получается реализация. Короче,
файнсет пишется вот так вот. Но это если вы по кодстайлу пишете. Ладно, можно все написать по
одну через тернарник. Но на этом мы не будем этим заниматься. Так, давайте… Мы говорили,
что мы храним предков, да, для каждой вершинки? А потому что я так захотел.
Ой, че я несу? Ancestor здесь надо брать, предки.
Ой, сейчас здесь будет красотуля. Да, ну еще веса, ну ранги или веса. Да, рангом вершины
будем называть глубину дерева из нее, а весом вершины – просто количество элементов. Вот
кажется, что ранга, весовая квиолента. Ancestor в этой равно… Ну и тебе нужно же понимать,
кого к кому приливать. Действительно. То, что никогда не пройдет в кодстайл, но это работает.
Да. То есть, смотри, что вы делаете. Когда вы заходите в вершинку, вы берете и ищете ее предка.
Она рекурсивно найдет ее предка. Рекурсивно найдет ее предка и так далее. И скажет,
ага, как только я нашел корень, окей, верни корень. И она всем Ancestor в этом
проставит корень. Почему это так? А потому что у вас оператор равно… вспомните, что возвращается
в песах. Ссылку на то, что у вас здесь находится. То есть, он вернет вам результат присваивания.
То есть, вот эту вот штуку вернет вам. А она вам вернет, единственный раз, корень. Это на всем
вершинам на пути сразу корень проставит в обратном ходе рекурсии. Ну здесь можно тернарденчик
бахнуть. Да, если это равно, поставить вопросик, то типа верни В, иначе вот это вот пойду. Но тут я
не уверен, если честно, разработать тернардник. Ну вот я про это и говорю. По-моему, это не очень
скобилируется, это не плюсов, а может сработает, я не помню. Там не только типы, там должны быть
категории, значения одинаковые. У вас еще этого не было? У вас C-style вещь. Ну короче, вот так вот.
Окей, тогда какие у нас планы на дальнейшее наше свое существование? Это то, что у нас будут
миностовы. Наверное, одну лекцию потратим. Раз мы про это с нами уже поговорили,
там одной лекции хватит вполне. И дальше после миностовов пойдет ЛЦА задача, еще одна лекция,
третий контест, соответственно. И потом пойдут по токе четвертый контест, в том строке пятый
контест. И мы закончили семестр. Ну все, тогда всем пока.
