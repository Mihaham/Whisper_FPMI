У меня с прошлого раза остался долг. Мы закончили на форд-белмане. Давайте
напомню лему, которую мы доказали в конце прошлого раза, что если сделать
n итераций в алгоритме форд-белмана, то для каждого отрицательного цикла,
достижимого из той s, из которой мы запускаем форд-белмана, хотя бы у одной вершинки уменьшится значение dp.
То для любого отрицательного цикла, достижимого из с, из той вершинки,
от которой мы считаем все расстояния, существует некоторая вершинка, до которой dp уменьшится.
Вот это мы доказали в прошлый раз. Теперь, как это использовать? Зачем нам это нужно?
Использовать очень просто. Смотрите, если у нас на каждом цикле есть вершина, на которой dp уменьшилось,
значит, мы в каком-то смысле нашли все отрицательные циклы. По крайней мере,
на каждом отрицательном цикле у нас хотя бы одна вершинка выделена. Та, на которой dp уменьшилась,
для той она обязана лежать на отрицательном цикле. Мы показали, что на каждом отрицательном цикле
такая есть, но в обратную сторону тоже вернут. То есть, если для какой-то вершины это верно,
такое неравенство верно, то она, конечно, лежит на отрицательном цикле. Или, по крайней мере,
достижимой из отрицательного цикла. Потому что если здесь такое неравенство,
значит, используя n ребер, можно найти более короткий путь, более дешевый путь, чем займаться
с одной ребро. Значит, обязательно в этом пути есть циклы, значит,
она достижима из s, используя хотя бы один цикл. Давайте замечание обратную сторону тоже верно.
Если dp в n меньше, чем dp в n-1, то, ну, я такую картинку нарисую. И вот это
отрицательный цикл. Это мы обсуждали в прошлый раз. То есть, если вдруг путь длины n оказался
дешевле пути длины n-1, значит, ну, в этом пути обязательно есть какой-то цикл, и он обязательно
отрицательный. Ну, в смысле, есть отрицательный цикл, потому что, если бы он был не отрицательным,
мы бы могли обрезать, получить более короткий путь, и тогда dp не уменьшилось. Поэтому тем самым
для всех вершинок, у которых это неравенство выполняется, они либо сами лежат на отрицательном
цикле, причем на каждом таком цикле мы найдем хотя бы одну, либо они достижены из отрицательного
цикла. Поэтому, если мы хотим найти все вершины, до которых расстояние минус бесконечность, то есть,
ну, на самом деле, сколь угодно сильно его можно уменьшать, вот так вот, мотаясь по отрицательному
циклу, это делать очень просто. Давайте просто из всех вершинок, у которых это dp-шка уменьшилось,
запустим dfs, обойдем все, что из них можно, как бы, ну, достичь, обойдем все, что можно достичь,
тогда для них для всех distance это минус бесконечность. А для всех остальных, кого мы не
достигли, соответственно, таким dfs, dp, у нас найденное, ну, вот равное на ином слое минус первым,
это есть ответ. Итак, для любой вершинки u, чему равно dist su? Значит, первый случай,
dist su равно минус бесконечности, если существует какая-то v, вот с таким условием,
и u достижимо из v. Ну, это очевидно, да, что если вдруг мы можем из v попасть в u, и при этом
до v, ну, v сама лежит либо на отрицательном цикле, либо достижимо из отрицательного цикла,
значит, мы можем сколь угодно много раз промотаться по этому отрицательному циклу,
и, значит, до u дойти со сколь угодно маленьким расстоянием, ну, сколь угодно большим, по-моему,
отрицательным. Значит, distance будет минус бесконечность. Ну, и второй, наоборот, если она не достижима ни
из одной такой вершинки, то расстояние, соответственно, равно просто тому, чему мы посчитали на
n-1-ой итерации. dist su равно dp u n-1 иначе. Потому что если мы понимаем, что эта вершина недостижима ни из
одного отрицательного цикла, значит, самый короткий путь из s в u, он таких циклов не содержит,
значит, он вообще циклов не содержит, поэтому это просто какой-то простой путь, содержащий
не больше m-1-ое ребро. Иначе так как в этом пути нет циклов. Но раз в пути нет циклов, то мы знаем,
что его длина не больше m-1, не больше m-1-ое ребро в нем. Отсюда рождается алгоритм. Если мы хотим
для каждой вершины посчитать расстояние, вот в этом смысле, как dist, то есть либо какое число,
либо минус бесконечность, тогда давайте просто запустим Форда Белману на n итерации. Дальше из
всех вершин, для которых у меня расстояние уменьшилось на n итерации по сравнению с n-1,
я запущу произвольный обход типа dfs или bfs, от чего угодно. Какой-нибудь обход,
который пометит минус бесконечностями все вершины, которые из них достижимы. Значит,
в них будет ответ, понятно, такой, ну а все которые мы не достигнем, у них ответ просто равен dp на
n-1 итерации. Ну и оно же на самом деле равно на n итерации, но это уже не важно. В итоге алгоритм.
Форд Белман на n итерации, дальше dfs из всех вершин, с тем самым неравенством.
Посещенные вершины имеют расстояние минус бесконечности.
Вот, ну а остальные, как я сказал, из dp-шки берутся на n-1 слое. Вот, получается, что здесь,
что самое сложное. Конечно, самое сложное от Форд Белман, потому что он работает за nm. Дальше
просто dfs, который работает за n плюс m, потому что нужно просто из многих вершин запуститься,
пометить минус бесконечностями все достижимое. И, соответственно, после этого мы корректно
знаем все дисты, потому что если там на самом деле должна была быть минус бесконечность, то она
достижима из кого-то цикла, а на каждом цикле мы хотя бы одну вершинку пометили, значит ее тоже
увидим. А если не минус бесконечность, значит циклов нету на пути, ну поэтому просто нам
значение dp-шки у нас правильно посчитано. Вот, тем самым Форд Белман нам позволяет найти все
расстояния корректно. Вопросы?
Хорошо. Тогда переходим к сегодняшней теме. Это минимальная остовая.
Начну сначала с пара определений. Во-первых, если у нас есть неориентированный граф,
значит ну сегодня работаем только с неориентированными, сегодня только неориентированные.
Значит пусть g неориентированный граф, тогда его под граф называется остовным,
если он содержит все вершины графа g. Если v от h равно v от g. Вот, ну что такое,
значит, что такое вот это выложение, что такое граф является под графом? Ну это в самом простом
понимании, что у нас множество вершин графа h это какое-то под множество v, множество рёбер
графа h это тоже какое-то под множество рёбер графа e. Короче, мы можем взять под множество вершин,
под множество рёбер. Вот, и под граф называется остовным, если на самом деле мы взяли все вершины,
если множество вершин графа h совпадает с множеством вершин исходного графа g. То есть если все
вершинки оставили и подаляли только какие-то рёбра, это остовный под граф. Ну и соответственно,
остовное дерево, это остовный под граф, который сам является деревом.
Тогда остовный под граф
называется остовным деревом, если он дерево.
Так, ну дерево для нас это связанный граф без циклов, связанный граф без циклов.
Ну, пример какой-нибудь нарисую. Вот был исходный g. Какой-нибудь такой. И в качестве
остовного дерева можно взять, давайте обведу, вот, например, такой под граф. Я взял рёбра, понятно,
что я тогда, соответственно, беру все вот эти вершины. То есть множество вершин совпадает
с множеством вершин графа g, я все вершинки взял. Ну и взял ещё какие-то рёбра, вот эти вот четыре,
так чтобы они образовывали дерево. То есть мы как бы обеспечиваем связанность между всеми вершинами,
между всеми нашими пяти вершинами. И при этом циклов в нашем графе нет. То есть это вот в каком-то
смысле какое минимальное число ребер можно оставить, чтобы оставить связанность, чтобы между
любыми вершинами можно было добраться по ребрам графа h. Так, ну и соответственно, задача у нас
на сегодня такая. По данному взвешенному, неориентированному графу найти остов минимального веса. То есть
выбрать какой-то остов, в котором сумма весов ребер минимально возможна. В данном взвешенном графе
найти остов. Ну я буду писать остов, потому что не лень писать остовное дерево, одно и то же
минимального веса.
Все алгоритмы, которые мы сегодня рассмотрим, они базируются на лемме безопасном ребре,
который разрушусь следующим образом. Значит, смотрите, пусть мы строили-строили наш как-то
минимальный остов, по ребрам ребра как-то к нему добавляли, и вот в какой-то момент мы получили некое
подножие минимального остова. То есть мы как-то действовали и знаем, что текущее положение, когда мы
набрали какой-то под граф, это под множество какого-то минимального остова. Тогда вот существует
какое-то ребро, которое можно гарантированно добавить, и мы по-прежнему останемся под множество
какого-то минимального остова. Значит, пусть g это граф, t это под граф g, являющийся также под множеством
какого-то минимального остова. Ну, под графом давайте тоже скажу, под графом какого-то миностова.
Давайте еще для удобства считаем, что t это дерево. Тогда если я рассмотрю самое дешевое ребро,
соединяющего вершинку из t с произвольной вершиной не из t, то его можно будет добавить к t, оставив
при этом все это подножие минимального остова. То есть картинка такая, вот было t, тут какое-то
дерево нарисовано. Такое, что его можно продлить до ответа, до минимального остова. И есть все
остальное, есть оставшийся граф g без t. Тогда если я рассмотрю самое дешевое ребро, соединяющие t
вот с этим дополнением, то его можно будет добавить в t, это будет по-прежнему подножие
минимального остова. То есть якобы мы подножие увеличил, сохранив свойство, что мы все еще,
как бы, что текущий, текущий дерево можно продолжить до ответа. Так вот, пусть e это ребро
минимального веса, соединяющие t и g-t. Тогда t плюс e тоже под граф минимального остова.
Доказательства. Давайте рассмотрим вот тот минимальный остов, который является над графом
для t. Как-нибудь бы его назвать s. Это миностов, содержащий t. В первом случае, если s содержит
ребро e, то доказывать нечего. Если e принадлежит s, то доказывать нечего. Потому что понятно,
что если мы рассмотрим t и добавим к этому графу ребро e, то мы по-прежнему останемся подножием
минимального остова. Вот оно, собственно. Вот этот самый минимальный остов s. Иначе, пусть e
соединяет вершинки u и v. Опять нарисую картинку. Вот есть дерево t, есть какое-то ребро e. Так,
чуть побольше я хочу нарисовать. Пусть он соединяет вершинки u и v. Давайте считать,
что e не лежит в s. Если e не лежит в s, то тем не менее, поскольку s это у меня остов, то есть
дерево, то есть связанный граф, все равно есть некий путь между вершинками u и v. И причем он не
совпадает с e, потому что ребра e в нашем s нет. Так вот, давайте рассмотрим путь между u и v.
Рассмотрим путь между u и v в s. Мы знаем, что s это дерево, u и v это какие-то его две вершинки,
значит между ними точно есть какой-то путь. Просто из-за связанности. Как может этот путь
выглядеть? Ну, главная мысль в том, что этот путь когда-то пересекает этот разрез. То есть он
обязательно когда-то перемещается из t в g-t. Ну, действительно, если он начинается в u, то он не
может петлять здесь и попасть в v. Понятное дело, что ему нужно когда-то переместиться из одной доли
в другую. Давайте я там что-нибудь нарисую. Вот он как-то так попетлял, пришел сюда. Возможно,
тут еще походил, вернулся сюда, тут походил, вернулся сюда и здесь дошел до v. Короче, главное,
что мы по крайней мере несколько раз пересечем вот это вот разделение между t и g-t. Тут я нарисовал
когда три раза. Главное, что хотя бы один раз мы пересечем. Так, ну и что у меня получилось? У меня
на самом деле получился некий цикл в исходном графе. У меня есть цикл, который содержит ребро
e и несколько вот еще других ребер, которые пересекают разрез. Давайте рассмотрим произвольное
ребро e', которое пересекает разрез и в этом цикле лежит. Пусть e' какое-то
ребро на этом пути, причем e' пересекает разрез. Пересекает разрез, то есть его концы в разных
половинках. Одна в t, другая в g-t. Дальше, где очень простая, мы знаем, что e по формулировке
леммы, e это самый дешевый ребро, соединяющий t с g-t. Значит, вес e по крайней мере не больше,
чем вес этого ребра e'. Значит, если мы просто ребро e' удалим, а вставим e, то наш остов как бы
останется деревом, то есть мы связываемся и восстановим, а при этом стоимость могла только
уменьшиться. Ну, не увеличится, потому что мы более тяжелое ребро поменяли на более легкое.
Значит, есть остов, содержащий e. Ну и так, конечно. Рассмотрим наш остов s без ребра e',
но с ребром e'. Вес не увеличился, так как e это самый дешевый ребро пересекающий разрез по условию.
Ну и при этом у нас остается дерево, потому что, смотрите, число ребер у нас не поменялось,
у нас мы одно убрали, одно добавили, и при этом связанность у нас сохранилась. То есть у нас,
как бы, ну, представьте, да, вот я рассматриваю этот цикл, содержащий e и e', я одно ребро цикла
удаляю, одно ребро цикла вставляю. Поэтому понятно, что все вершинки, лежащие на этом цикле,
по-прежнему друг с другой достижимы, ну а все остальные достижимые, потому что, собственно,
были достижимы друг с другом в s. То есть якобы мог сломать только что-то на этом цикле, но я
его этот цикл чиню, да, добавив ребро e, поэтому связанность тоже никуда деться не могла. Вес не
увеличился, а связанность не пропала, связанность сохранилась. Ну, собственно, все, значит, вот есть
какое-то другое остовное дерево, веса, возможно, даже меньшего, которое содержит ребро e, победа.
Это вот тот самый остов, который мы искали. Это остов, веса, ну, на самом деле он будет
ровно такого же веса, потому что, если s был минимальный остов, то это не может быть веса
меньше, значит, у них вес, ну, вес у него такой же, как у s. Получается, вот вам минимальный остов,
который содержит e и при этом содержит t. Этот остов содержит t плюс e. Из этой леммы мы
сразу можем реализовать алгоритм прима, который находит минимальный остов в графе. Собственно,
просто многократно эту лему применить. Давайте считать, что у меня сначала дерево — это одна
вершинка без ребер. Добавляем самое дешёвое ребро, которое из неё торчит во внешность графа.
Добавили. Теперь дерево — это одно ребро. Опять рассматриваем все исходящие ребра, добавляем их
самое дешёвое. Теперь у нас есть два ребра в остове и так далее. Просто по одному ребру
добавляем, пока не получим n минус одно ребро. Алгоритм прима. Сначала мы считаем, что t — это
одна вершина произвольная. И дальше просто n минус один раз применяем лему обезопасным
ребрем. Просто каждый раз есть у нас t, есть у нас g без t. Среди всех этих ребер рассматриваем
самое дешёвое и добавляем его к t. Применяем лему обезопасным ребре. Так, ну вот такой алгоритм.
Что тут можно сделать с симпточками? Давайте поймём, как мы это будем делать
за квадрат сначала. Чтобы находить минимальное ребро, пересекающее такой вот разрез,
то есть среди всех таких ребер, мне нужно найти самое дешёвое, самое дешёвое по весу.
Давайте я для этого, для каждой вершины вот в этой вот части, в g без t, буду хранить самое дешёвое
ребро в неё торчащее. Пусть d от v — это минимальная стоимость ребра у v, такая, что ух ты, ну а у v — это ребро.
У v — это ребро. То есть для каждой вершины вот в той вот части, которую я ещё не обработал, в g без t,
я храню минимальное торчащее в неё ребро. То есть вот для этой вершинки я, скажем, храню такое
ребро, для этой вот такое, для этой, ну короче, для каждой вершинки храню минимальный вес ребра.
Дальше, если мне нужно выбрать самое дешёвое входящее сюда ребро, то я просто по ним про всем
пробегаюсь и нахожу минимальное значение d. Если у меня есть минимальное входящее в каждую вершину,
то просто беру из них минимум, это будет минимальное входящее во всю вот эту долю.
Осталось научиться это пересчитывать при расширении t.
Ну это делается так же, как на самом деле в алгоритме dxt. Потому что, смотрите, вот у меня было t.
Дальше, я какое-то ребро нашёл самое дешёвое исходящее из него. Давайте я назову это u.
И t расширил моим новым ребром. По сути, я добавил одну новую вершинку. Тогда вопрос,
как выглядят d от v для всех вершинок, лежащих в g без t. То есть вот я t расширил, как поменялись d.
Ну понятно, мне достаточно просто рассмотреть ребра исходящие из u и попробовать обновить
дешки, как бы пререлаксировать d для каждой вершины через стоимость вот этих ребр исходящих из u.
Потому что других ребр не появилось в входящих в вершинке g без t. Ну собственно, мы просто их все
обрабатываем и насчитываем правильно d от v. Если u добавляется в t, то мы делаем следующее.
Для любого ребра uv мы выполняем обновление, что d от v это минимум из того, что там уже лежало,
и стоимость этого ребра. Потому что вот если я какую-то вершинку v рассмотрю, то для нее какие
есть в нее входящие ребра? Они либо раньше вели из t, ну то есть из вот этой части v, но они уже
и так учтены. Единственное новое ребро, которое могло появиться, это ребро из u в v. Ну давайте я
просто им мою дешку обновлю. Поэтому алгоритм очень похож на алгоритм dx. У меня есть для каждой
вершинки какое значение d, есть вершинки, которые я уже обработал, которые уже лежат в t, есть
необработанные. Тогда я на каждом шаге, среди всех необработанных, нахожу вершинку с минимальным
d, отношу ее в множество обработанных, то есть как бы добавляю в дерево, а затем вот это вот у,
я ее отнес в t, и дальше рассматриваю все ребра, исходящие из u, и обновляю значение d для
концов всех этих ребер. Прям супер как в dx, ровно так же, только здесь немножко другая формула
пересчета для d, для вот этого самого дешевого ребра, входящего в вершинку v. Вот, ну и отсюда
собственно получается симптатика n квадрат, потому что мне нужно n-1 раз найти самое дешевое
ребро, вершинку с минимальным вот этим вот значением d, это n квадрат, то есть мне нужно n раз найти
минимум среди n элементного множества. И затем еще вот эти обновления, но понятно, что обновления
суммарно работают за m, за от m, потому что каждая вершина ровно один раз добавится в t, значит
каждое такое ребро просмотрится ровно один раз, ну окей, два раза, потому что у нас граф не
ориентированный, то есть мы рассмотрим ребро вот так вот и вот так вот, ну ничего страшного,
за два m это будет работать. Поэтому все эти обновления работают за время от m, ну и мы считаем,
что если в графе нет кратных ребер, то конечно m меньше чем n квадрат, поэтому это главное слагаемое.
Вот, алгоритм за квадрат. Вопросы. Так, ну и тогда здесь же можно сказать, что давайте мы вместо вот
этого тупого алгоритма за квадрат можем делать что-нибудь с кучей. За m лог n, так же как в dx-3,
можно сделать с помощью кучи, бинарная куча. Потому что, повторюсь, нам нужна структура,
которая хранит в себе вот эти вот дэшки, умеет извлекать минимум и уменьшать значение. А именно,
что мне нужно n раз сделать экстракт мин, ну там n-1, n раз сделать экстракт мин и m раз сделать
криски. Ну это вот в точности бинарная куча. Либо же, опять, если мы вдруг умеем писать себе
на чую кучу, то здесь будет симптомика m плюс n лог. Потому что, смотрите, каждая вишина u добавится в t
ровно один раз. Значит, когда у меня вообще происходят декризы, когда я добавляю какую-то
вишинку в t, и мне нужно рассмотреть все исходящие из нее ребра и для них, для всех,
попробовать обновить d от v. Значит, вдоль каждого ребра декриз будет проходить ровно один раз,
когда один из его концов первым попал в t. Значит, декризов с небольшими ребер.
Так, хорошо, тогда едем к следующему алгоритму, алгоритму Крускала. Тоже еще один алгоритм просто
поиска минимального астова. Он работает следующим образом. Давайте мы сначала все ребра отсортируем в
порядке возрастания весов. Отсортируем все ребра в порядке возрастания весов.
Дальше будем проходиться в этом порядке по ним и считать, что изначально у нас подграф пустой,
то есть у нас есть все вишинки, нет ни одного ребра, то есть не взято ни одно ребро. Дальше я
прохожусь по этому списку и добавляю ребро в наш подграф, если оно не образует циклов.
То есть вот изначально у меня есть такая картинка, скажем, я изначально добавляю
самое дешевое ребро, ну просто первое в этом порядке. Потом вижу второе ребро, добавляю его,
потом вижу третье ребро. Если оно вдруг образует цикл, то я его не беру. Нам нет смысла брать в астов
ребра, образующие циклы. Поэтому если ребро такое, то я его просто скипаю. Третье пропускаю,
смотрю четвертое. Четвертое, например, такое, оно опять не образует циклов, то есть соединяет
какие-то две несвязанные вершинки до этого. Вот и в момент, когда мы, собственно, связали все вершинки
в одну компоненту, мы заканчиваемся. Ну давайте напишем так. Добавляем ребра в этом порядке,
не допуская циклы. Вот, и тут вопрос, как это делать, как проверять, что то ребро,
которое я сейчас рассматриваю в списке всех ребер, оно хорошее, оно не образует циклы,
если его добавлю в мой текущий подграф. Для этого нам нужна будет вспомогательная структура данных,
системы не пересекающихся множеств, которая нам позволит на все эти запросы быстро отвечать.
По-русски это СНМ, по-английски это ДСУ.
Значит, это структура, которая умеет отвечать на следующие запросы. Первый запрос это... Так, момент.
Ну давайте так, нам нужно, нам нужно что сделать? Вот давайте приметно к нашей задаче. Нам нужно уметь
проверять, вот если у меня пришло какое-то ребро, ребро, которое там образует или не образует цикл,
мне нужно понять лежат ли вот эти две вершины, лежат ли концы этого ребра в одной компоненте связаности?
Потому что ребро как раз добавляет циклы, если только если они и так были в одной компоненте связаности.
Мне нужно по двум вершинкам моменты определять в одной они компоненте или нет, во-первых, а, во-вторых
если в разных, то нужно объединить эти компоненты, потому что если было две компоненты связаности,
я прогружу между ними ребро, то теперь эти два множества объединяются в одно и получается одна
большая компонента связанности. Поэтому с точки зрения нашей задачи нужно
уметь делать две вещи. Во-первых, проверить, лежат ли два элемента в одном множестве,
два элемента в одном множестве. Второе, объединить два данных множества.
Два данных множества. Если мы на этом научимся быстро отвечать, то и, собственно, алгоритм
Крускала мы тоже реализуем и закончим быструю асимптотику. И мы сейчас это сделаем.
Итак, давайте пока абстрагируемся от графов, от астолов, забудем вообще про алгоритм Крускала.
Просто сфокусируемся на этой задаче. Есть у меня изначально n элементов. Изначально
все, каждый в своем множестве. Первый элемент это отдельное множество, второй элемент это
отдельное множество. И так далее n элементы это отдельное множество. И поступают такие запросы.
Проверить в одном или не в одном и объединить два. Тогда давайте сделаем следующее. Давайте мы
каждое множество, каждое вот это вот множество которое с остальными не пересекается. Будем
представлять в виде дерева. Каждое множество в SNM представляем в виде корневого дерева.
То есть изначально понятно, что каждая вершинка просто сама себе корень,
дерево из одной вершинки, и ничего не происходит. Ну а там на какой-нибудь следующей стадии алгоритма
может быть какое-нибудь вот такое дерево, например. То есть некая вершинка является корнем, давайте
назову R, и у меня есть вот такое дерево. Значит, что все эти вершинки лежат в одном множестве,
и в каком-то смысле их лидером выступает вот эта вершинка R. И тогда я буду как-то так это дерево
хранить. Лидер множества. Тогда, чтобы, например, проверить, лежат ли два элемента в одном множестве,
достаточно просто у обоих элементов найти их лидера, найти корень просто дерева, и проверить
равны или неравны. Потому что если они в одном множестве, скажем, вот эти два элемента, я для
них обоих нахожу корня, то есть просто прохожусь вверх по дереву, пока они не ведут до корня. Если
они совпали, закончатся в одной вершинке, значит они в одном множестве, в одном дереве лежали просто.
Если они не совпали, то есть у них разные лидеры, разные корни деревьев, значит это и деревья различные.
Поэтому нам достаточно в ответ на первый запрос как-то вот найти корень в том дереве, в котором данная
вершинка лежит. Для этого будем просто, давайте просто ориентировать наше дерево снизу вверх,
и для каждой вершинки храните родителя в этом дереве. Для любой v храним p от v, это родитель вершинки
v в соответствующем дереве. Родитель v в дереве. Ну родитель, то есть следующая вершинка на пути до корня,
тот, кто непосредственно выше расположен, предыдущая вершина на этом пути, первая снизу верха слетит,
это первая вершина. Вот я просто в нее буду соваться. Если же вершинка v является сама корнем, то понятно,
где у нее нет родителя, некуда идти выше. Давайте хранить минус 1. p от v это минус 1, если только
если v это корень своего дерева. Если только если v корень. Тогда повторюсь, если мне нужно для
двух вершин понять в одном они множестве или нет, я просто вместо v беру p от v, p от p от v,
ну и так далее, навешиваю p столько раз, пока не приду в вершинку, у которой нету родителя,
то есть пока не приду в корень. И так делаю и для v, и для u, для двух данных вершинок. Если они
пришли в одну вершинку, то значит они в одном дереве, если нет, то в разных.
Поэтому процедуру get, давайте я, а нет, не готов написать. Ну ладно, пока давайте идею оставим
такую. А дальше, дальше мне нужно как-то научиться объединять, объединять два множества. Вот есть
одно дерево есть другое, я хочу как-то как-то их слить в одно дерево, в одном множестве. Давайте
у этих деревьев найдем корни, а и б их назову, и подвесим меньшее дерево к большему. Значит,
а именно, что я буду в каждом корне хранить размер этого дерева, то есть сколько здесь есть вершин,
то есть я буду знать там size от b, сколько здесь есть вершин, и буду знать size от a, сколько здесь
есть вершин, и подвешивать буду меньшее к большему. То есть я в любом случае хочу объединить два дерева
в одно, это можно, например, сделать проведением такого ребра, то есть я могу назначить p от b равно
a, провести по сути такое ребро, подвесить все вот это дерево как бы к a, в качестве правого сына,
к вершинке a, ну одного сына к вершинке a. И буду делать это подвешивая меньшее дерево к большему,
тогда у меня будет хорошая симпатика. Итак, пусть size от v это размер под дерево вершины v,
пусть a и b это корни, и при этом size от a больше равно size от b. Тогда, чтобы два множества объединить,
мне достаточно написать две строчки. Во-первых, p от b равно a, во-вторых, size от a плюс равно size
от b. Все. Я провел это ребро, назначив родителя вершинки b. Раньше p от b было минус 1, раньше оно
было корнем и не было у него родителя, теперь назначаем. Ну и size пересчитали, потому что к a
подвесилось целиком по дереву b, мы должны size увеличить. Так, вот то, что я написал,
да, вот эта вот штука условия на size, это так называемая эвристика по рангу, ну или по размеру.
То есть, ну здесь как бы под рангом подразумевается размер под дерево, и мы подвешиваем меньше к дереву
к большему всегда. Тогда у меня будет, сейчас будет логарифм. Вот давайте напишем какой-то код,
первое приближение. Ну давайте сначала get напишем. Get это получение корня дерева,
получение лидера. Пишется очень просто, поднимаемся по p, пока не дойдем до вершинка с p равно
минус 1. Значит, если p от v равно минус 1, тогда return v, а иначе return get от p от v.
Да, если мы уже в корне, то нам надо его вернуть, иначе нам нужно вернуть get от родителя. Вот, ну и void
unite для двух вершинок u и v. Есть две вершинки, мы хотим провести ребро между ними. Ну, во-первых,
можно сразу заменить u на get от u и v на get от v, ну то есть подняться в лидеров. Да, вот здесь,
ну давайте считать, что у меня уже гарантированно они различны. Давайте сейчас теперь u не равно v,
иначе нам не надо провести ребра, они и так в одной компоненте, ничего добавлять не нужно. Ну или там
запрос некорректный. Так вот, если они не равны, тогда нужно в соответствии с тем, какие у них
сайзы пересчитать, ну возможно их свопнуть. Давайте напишу так, что если size от u меньше,
чем size от v, тогда своп u v. Ну а дальше u это тот из корней, который имеет больший size,
значит надо просто подвесить v к u. Пишем вот те самые строчки, что p от v равно u и size от u
плюс равно size от v. Вот так можно реализовать наш S&M. Ну и на вопрос, за сколько это работает,
каждый запрос за логарифм у нас будет, потому что глубина дерева будет всегда максимум логарифм.
Потому что смотрите, когда я делаю такой переход, когда я выполняю подвешивание одного дерева к
другому, у меня размер текущего поддерева по сравнению с размером всего, то есть когда я
перехожу от поддерева к над деревом, у меня размер рассвета хотя бы вдвое, потому что это было
меньше, чем это, значит это меньше, чем половина всего. Когда я перехожу от b к p от b,
к родителю, я размер текущего поддерева увеличу хотя бы вдвое, значит подъемов по родителям у
меня будет максимум логарифм. Вот это условие, увеличение размера, оно всегда гарантирует,
что подъем вдоль ребра, вдоль p, оно увеличивает размер текущего поддерева хотя бы вдвое. Значит
глубина всех деревьев будет всегда максимум логарифм. Глубина всех деревьев всегда не больше
чем логарифм. Так как, давайте восстановим эту картинку, когда у меня появляются ребра,
только когда я объединяю два дерева, только в юнайте, а когда я их объединяю, это значит,
что размер этого меньше, чем размер этого, значит размер этого меньше, чем половина размера всего.
Так как, когда я перехожу от b к p от b, размер поддерева растет хотя бы вдвое.
Ну и понятно, если здесь у меня хотя бы единица сначала, то здесь хотя бы два, хотя бы четыре,
хотя бы восемь и так далее, поэтому глубина всегда максимум логарифм. Ну и значит у меня есть там
несколько деревьев, каждое множество это какое-то дерево, у каждого дерева глубина логарифм,
значит get всегда работает максимум за логарифм, потому что мне нужно просто взять вот вишенки
дойти до корня. Это время ограничено глубиной дерева, она растет на логарифм, значит get
работает за логарифм. Ну а size, юнайт тогда вообще работает за единицу, если get игнорировать,
то юнайт работает за единицу, там swap, присвоение и плюс равно. Значит ответ на запрос за логарифм.
Ответ на запрос от логарифма. Согласны? Хорошо. Ну здесь есть еще одна идея, которая позволит
еще ускорить это решение, называется еврестика сжатия путей. Идея следующая, смотрите, вот если у
меня есть какое-то ветвистое там длинное дерево, вот например там есть какой-то корень, есть такой
путь из него длинный, и пусть я в какой-то момент сделал get от v, вот после этого я в какой-то момент
запустил get от v. Ну в каком-то смысле понятно, что структура дерева нам не нужна. Вообще я ввожу
дерево только для того, чтобы компонента связанности, какое-то дерево, соответствовало
однозначно множеству. Поэтому как бы структура дерева мне не очень важна, я ее какой угодно
могу делать. Поэтому если я запускаю get от v, давайте я весь этот длинный путь замню вот, ну как бы в
такое дерево превращусь, корень у меня остается, а все остальные вышники, которые я прошел в течение
этого пути, теперь становятся непосредственными детьми r. То есть я их просто все переподвешиваю в
качестве детей к r. Это выгодно, потому что теперь если в следующий раз у меня захочется найти get от v,
или get от этой вершинкой, или get от этой, или get от этой, мне не придется весь этот путь заново
проходить. У меня уже сразу весь известный ответ. Ну по крайней мере этот кусок пути точно сокращен
до r. Это вот как раз жатие пути, что если я для каких-то вершин в какой-то момент нашел значение,
корня, то я их просто всех переподвешу к корню. Это нам ничего не сломает, потому что мы нигде не
пользуемся структурой дерева. Нам не важно, что вот здесь именно такой путь. Нам важен только
представитель. От каждого дерева нам важен только корень. Единственное, что мне нужно в этих процедурах,
это чтобы для вершинок из одного дерева они возвращали одного и того же корня. У них был один
тот же корень. Вершины из разных деревьев имеют разный корень. Ну понятно, что здесь сохраняется. Я не
нарушаю. Корень всегда остается на месте. А если кто-то был корнем, то он им и останется.
То есть я в каком-то смысле просто облегчаю себе работу на будущее, переподвешиваю все их к r. И все,
юна никак не меняется. Гет, соответственно, можно будет переписать так. Давайте я прямо здесь его
перепишу. Первую строчку я оставляю. Вот, а вторая будет так.
Возможно, это не очень хорошо с точки зрения стиля кода, но если мы зачем-то стремимся писать как
можно меньше символов, можно писать так. Мы сначала рекурсивно находим гет от p от v,
то есть поднимаемся в родителя ищем для него корни. Вот эта штука находит нам корень. Дальше
выполняем присваивание, что p от v равно корню. И это присваивание еще опять возвращает значение,
равное корню, мы его возвращаем. То есть вот эта строчка составлена из двух операций.
Мы сначала родителя v переназначаем равной корню и затем возвращаем то самое значение корню.
Вот хорошо. Теперь за сколько это работает? Тут мне нужна шпаргалка.
Значит, рассматриваем такую функцию.
Это какая-то функция, принимающая целые неотрицательные аргументы.
Рассмотрим обратную функцию.
Альфа от k это минимальная неотрицательная n, такое, что а, n, n хотя бы k. Так вот тогда
наши запросы работают у звездочка от этой альфы. Смысл такой, что эта функция очень быстро растет,
соответственно, эта функция как обратная, наоборот, очень медленно растет. Так вот тогда
вот эта эвристика жатия путей вместе с эвристикой жатия по рангу,
эвристики жатия путей плюс жатия плюс по рангу, отвечают на запрос за у звездочка от альфы.
Звездочка от альфы. И почему это хорошо? Нужно написать какие-то значения.
Вот. Уже А4,4 такое огромное. Ну, я даже, типа это что-то огромное, это, не знаю, точно там
10 тысяч знаков точно в этом есть. Скорее даже больше. Ну, поэтому понятно, что альфа от всего
адекватного, не знаю, от всего интернета, наверное, будет меньше, чем 4. Но я на всякий
случай там напишу, типа 10,20 точно не больше, чем 4. Потому что даже уже на точке 4,4 это что-то
очень просто астрономически большое. Значит, наоборот, если мы фиксируем вот это вот значение и
хотим найти минимальное n такое, что а,n,n больше, чем вот это, то для всех чисел, если здесь в
аргументе что-то не больше, чем вот это, там 10,20 точно, то это будет не больше, чем 4. А значит,
то есть хоть это и растущая функция, то есть это бесконечно растущая функция, значит это тоже
будет бесконечно растущей, как обратно к ней. То есть, по сути, это бесконечно растущая функция,
но на всем адекватном это 4. Ну, то есть вот 1. Вот, и в этом, в общем-то, и прелесть этих двух евристий,
что они работают практически за вот 1 на запрос. Ну, тут еще звездочка амортизированная, но,
по сути, по сути, вот 1. Так, давайте я скажу, что это называется функция Кирмана. Вот это вот
а, это функция Кирмана. Это, соответственно, обратная функция Кирмана. Обратная функция Кирмана.
Вот, я, к сожалению, не знаю, откуда это все берется, поэтому, поэтому без доказательства,
но главное для нас, что вот просто есть какая-то супер-быстро растущая функция, соответственно,
обратной к ней очень медленно растет, и асимплатика будет вот такая. Вот. Так, что осталось сказать? Да,
почему, почему, о, звездочка, да, почему амортизированная? Ну, здесь, ну, как бы в
каком-то смысле важно, что амортизированная. То есть, не каждая операция будет там за вот
1 работать, а вот именно амортизированная, потому что в худшем случае может быть такое,
что я подвешиваю, подвешиваю, подвешиваю, подвешиваю и ни разу не вызываю здесь гета, ни разу не сжимаю
путь. То есть, скажем, сначала я подвесил эту вершинку к этой, потом эту, ну, там вот к этому
по дереву, эту вот к этому и так далее, и, соответственно, здесь не произведено ни одного сжатия. Для них
гет не вызывался. И вот когда-то потом, в будущем, когда запустится гет от этой вершинки, мне
придется весь этот путь пройти. То есть, может быть такое, что какая-то конкретная операция работает
дольше, чем альфа. Ну, то есть, логарифм в худшем случае, если я весь этот путь не сжимал ни разу,
тогда мне придется сделать здесь логарифм шагов, чтобы дойти до корня. Но зато, когда я сделаю
логарифм шагов, у меня для них, для всех, сразу известен, известен корень. Типичная идея из
амортизованного анализа, что если у меня там даже есть какая-то тяжелая операция, то в будущем она
сильно мне упрощает жизнь, потому что, если я одну сделал, то я сразу для многих вершинок знаю правильный
ответ. Ну, возможно, он там обновится, когда я буду еще переподвешивать, но, в любом случае, для них,
для всех, я сильно сократил наш путь. Поэтому амортизированный вот этот вот обратный керман.
Вопросы? Окей, вот какая-то такая магия. Ну и, соответственно, отсюда алгоритм Крускала работает
уже очень просто. Если у нас есть такой механизм, который позволяет поддерживать разбиение на
компоненты связанности и объединять их, то, соответственно, за сколько работает Крускал. Ну,
давайте посчитаем. Во-первых, у нас там была изначально сортировка ребер. Сортировка ребер. Ну,
давайте я напишу, что это m log m. Сортировку в порядке возрастания весов. А дальше мне
нужно m раз, то есть пройтись по всем ребрам, и м раз запустить get и unite. М раз, get и unite. То есть
я просто прохожусь по всем ребрам, запускаю для концов ребра get. Если они в одной компоненте,
то я их игнорирую, перехожу к следующему ребру. Если не в разных компонентах, то я делаю unite.
В итоге у меня будет в худшем случае m раз get. На самом деле unite будет максимум n, потому что
объединение не больше, чем n. Ну, давайте тоже сверху оценим m. И мы знаем, что все вот эти
вот товарищи работают за амортизированную α от n. Значит, итог будет такой. m log m плюс m на
α от n. Потому что вспоминаем, если у меня есть амортизационная оценка, и я делаю m итерацией,
то это означает, что суммарно время работы ограничено такой штукой. Это есть определение
амортизационного анализа. Если каждая штука работает за α амортизационно, то суммарно все
работают за m умножить на α. Ну и да, эта штука какая-то очень маленькая. Здесь, конечно,
основная слагаемая это сортировка. Здесь можно поговорить про то, насколько быстро можно ребр
сортировать. Потому что, например, если вам известно, что веса ребра маленькие целые числа,
то здесь вместо m log m можно писать m с помощью сортировки подсчетом. Ну и вообще про сортировку
мы много что знаем. В зависимости от того, насколько быстро мы это можем сделать, соответственно,
у меня вот эта вот штука, основная слагаемая, можно уменьшать. Поэтому к русскал в каком-то смысле,
если у вас там, скажем, веса ребер маленькие целые числа, от 0 до 100, например, тогда эту
сортировку можно сделать за m, а это за m на α. То есть практически линия алгоритма получается. Ну тут
какая-то константа растущая, но для всех нормальных n она маленькая. Поэтому в каком-то смысле
даже линия алгоритм. Ну так, с натяжкой.
Вот, хорошо, хорошо. Так, тогда последний алгоритм того же самого. Это алгоритм барувки.
Здесь короткая идея такая. Давайте мы для каждой вершины в нашем графе найдем самое дешевое входящее
в нее ребро. В каком-то смысле понятно, что ответ, если в эту вершину входит ребро веса там 10,
и все остальные только большего веса, то понятно, что в ответе здесь нужно хотя бы 10. То есть в ответе
этой вершины хоть с кем-то связано, хотя бы одним ребром, и вес этого ребра хотя бы 10. Поэтому в
каком-то смысле это ребро нам нужно взять, по крайней мере его вес точно нужно взять. Так вот давайте
тогда сделаем следующее. Для каждой вершины находим самое дешевое исходящее ребро. Что-нибудь такое
я нарисую. Добавляю эти ребра в ответ. Говорю, что вот я их взял. Самое дешевое для каждой вершинки
взял и положил их в миностов. Ну а дальше сжимаю компоненты связанности, которые получились,
и запускаю алгоритм рекурсивно на том, что получилось после сжатия. Итак, как бы это написать,
для каждой вершины выделяем самое дешевое исходящее ребро. Дальше все выделенные ребра
добавляем в остов и сжимаем компоненты связанности. Все выделенные ребра добавляем в остов,
сжимаем компоненты связанности и рекурсивный запуск. Я сжал наш граф, получил какие-то,
уже какие-то ребра добавил в миностов, и теперь у меня есть граф поменьше, и мне нужно в нем решить
опять задачу о минимальном остове. То есть вот здесь скажем, я сожму вот это в одну вершинку,
вот это в одну вершинку, это в одну вершинку, останутся какие-то ребра между вершинами,
вот эти вот. Ну и опять у меня есть та же самая задача, что есть несколько вершинок, есть ребра
между ними, нужно найти миностов. Потому что чтобы связать вот эти вот кусочки, мне нужно найти
какой-то дерево их соединяющий минимального веса. Вот такой алгоритм. Тут есть как минимум,
как минимум одна ловушка, что нужно немножко уточнить про вот это минимальное исходящее
ребро. Его нельзя брать произвольным, потому что, например, рассмотрим такой случай,
когда у меня есть треугольник, и веса всех ребр в нем это единица. Тогда если я никак не
специфицирую, какое из минимальных ребр я беру, то, например, я мог взять для этой вершинки это
ребро веса 1, для этой вершинки это ребро, для этой вершинки это ребро. И тем самым я как бы цикл
добавил в свой остов, это плохо. Так вот, чтобы избежать циклов, можно сказать следующее, что если
из В исходит несколько ребер минимальных одного и того же веса, исходит несколько
минимальных ребер, то давайте выберем то из них, которое вьет вершину с минимальным номером.
С минимальным номером. Тогда в этом случае, в случае этого треугольника что получится? Ну давайте
я как-нибудь их пронумеру 1, 2, 3. Тогда для единички есть два исходящих ребра одного и того же веса
минимального. Я выбираю вот это ребро, потому что оно ведет вершинку номер 2. Дальше для двойки
есть опять два исходящих. Я выбираю вот это опять же, потому что один меньше чем три. И для тройки
я выбираю вот это ребро. То есть я какое-то ребро выбрал дважды, это у меня всегда так будет на
самом деле. Я вот это ребро выбрал дважды, но при этом циклов не образовалось. Я как бы имею в
виду, что если я какое-то ребро назначил дважды в минимальном, то я беру его один раз. Ну понятно,
нельзя взять ребро два раза, я беру его один раз. Вот, получится такая штука, и циклов я не добавлю,
по крайней мере в этом случае. Давайте докажем, что так будет всегда.
Докажем.
Что в таком случае циклов не появится.
Ну действительно, давайте мы договоримся, что если я для какой-то вершинки v выбираю исходящее
из нее ребро e, то я это ребро вот так ориентирую, нарисую в нем стрелочку. Что если я из-за v взял
ребро e, то я нарисую на нем такую стрелку. Может быть такое, что я взял какое-то ребро два раза, то
есть я его выбрал для u и для v. Это самое минимальное ребро для u и минимальное ребро для v. Тогда я буду
рисовать стрелки в обе стороны. Так вот, что у меня получается за граф, если я выбираю для каждой
вершинки какое-то исходящее из нее ребро. Это так называемый функциональный граф. Это ориентированный
граф такой, что у каждой вершинки исходящей степени ровно один, потому что у каждой вершины ровно
одно ребро из нее торчит. Я напишу out degree для каждой вершинки равно 1. Из каждой вершины исходит
ровно одно ребро. Как такой граф выглядит? Следующим образом, это обязательно некий цикл,
к которому подвешены деревья. Точнее несколько циклов может быть. Вот как-то так. Почему граф
выглядит именно так? Это легко доказать. Давайте начнем в произвольной вершинке v и начнем исходить
по нему, по тому самому ребру e. Вот я нашел исходящее ребро, нарисовал его, нашел еще ребро,
еще ребро, еще ребро. В какой-то момент, понятное дело, я не могу бесконечно долго посещать новые
вершинки, в какой-то момент я вынужден буду посетить одну из вершин, которая была раньше. Вот она
где-то здесь, например, будет. То есть это либо v, либо какая-то более правая вершинка. Значит, из каждой
вершины мы достижем некий цикл. Из каждой вершины мы идем, идем, идем. Понятно, что мы рано или поздно
зациклимся. Поэтому если я теперь выделю вот этот цикл, скажу, что это вот такой кусок, то получается,
что все остальные вершинки, из которых достижем этот цикл, они в каком-то смысле образуют деревья,
подвешенные к этому циклу. Потому что если из вершинки достижем опять этот цикл, из u опять
достижем этот цикл, то мы как-то шли-шли-шли-шли-шли и попали в этот цикл. Ну да, то есть мы сначала
прошли некий путь, однозначно определяемый до вот этого цикла, и затем в этот цикл вклинились. То
есть если я теперь все подвешу в каком-то смысле за этот цикл, у меня будут вот эти вот пути, восходящие
к этому циклу, ну значит у меня получается некие деревья с корнями в вершинках цикла. И так
может быть несколько циклов, если вот эти циклы различны для нескольких разных вершин. Вот, то есть у
меня есть такой граф, и алгоритм Боровки объединяет вот это вот в отдельную компоненту, сжимает ее,
сжимает вот это в отдельную компоненту, и потом рекурсивно запускает задачу, рассматривая вот это
как одну большую вершинку. Так вот, я утверждаю, что циклов не появятся. То есть когда я нахожу
вот эти вот самые дешевые ребра, то у меня на самом деле не будет такой картины, что длина этого цикла
будет хотя бы 3. Потому что если длина хотя бы 3, то будет цикл, а тут 4 будет цикл. А вот если
была длина 2, то цикла бы не было. Потому что что такое цикл длины 2? Это две вершины, которые друг
у друга ссылаются. Вот так, что самый дешевый исходящий из них ребро ведет вот в противоположную.
И здесь какие-то деревья подвешены к нему. Тут дерево, и тут дерево. Понятно, что это означает
просто-напросто, что я беру одно ребро между ними. То есть здесь не два ребра, а одно. Опять,
я считаю, что кратных ребр нету. Значит, между вот этими двумя вершинками ребро однозначно определено.
Если я говорю, что самый дешевый исходящий из этой вершинки ведет сюда, а самый дешевый из
этой ведет сюда, то это одно и то же ребро, по сути, описываю. Поэтому вот здесь как раз цикла не
появится. Если я все эти ребра добавлю в минимальный остов, то циклам, ну, собственно,
нет куда будет взяться. Здесь деревья, здесь деревья, здесь еще перемычка между деревьями.
Цикла нет. А вот там были бы. Так вот нам достаточно доказать, что все вот эти, ну, как бы,
компоненты связанности в кавычках, все вот эти вот облачка функционального графа, ведущие в циклу,
они имеют циклы длины ровно 2. Достаточно доказать, что все циклы имеют длину 2. Тогда как раз таки при
объединении, ну, при добавлении этих ребер в остов у меня циклов не появится. Так, ну, хорошо.
Хорошо. Давайте, чтобы доказать, заметим сначала следующее. Давайте рассмотрим два последовательных
ребра исходящих. E и E'. То есть для этой вершинки кратчайшее минимальное ребро это E, а для вот
этого конца этого ребра кратчайшее ребро это E', причем это какие-то разные ребра. Тогда понятное
дело, что кост от E больше равен, чем кост от E'. Ну, потому что, смотрите, я вот когда нахожусь в этой
вершинке, что такое E', это ребро минимального веса, торчащее из нее. Ну, тогда понятное дело,
что E имеет вес больше равный, чем вес E', потому что если E' это минимальное, то E имеет вес
больше равный. Поэтому дополнительное свойство нашего вот этого функционального графа в том,
что при проходе сверху вниз по нему, вес ребра только уменьшаться может. Ну, не строго,
не увеличивается. Что я прохожусь по ребру выше-выше-выше, и текущий вес ребра, кост,
он может только уменьшиться. Ну, или остаться таким, как был. Поэтому в частности, если у меня есть
некий цикл длины больше равной, чем 3, пусть есть цикл длины больше, но чем 3, то на нем все
ребра имеют один и тот же вес. Потому что когда я иду по ребру, я понимаю, что у меня кост не
увеличивается. Значит, кост этот меньше равен, чем кост этот. Дальше, кост здесь еще меньше равен,
кост здесь еще меньше равен, и еще кост этот меньше равен вот этому. Поэтому у меня есть цепочка
неравенства меньше или равно, значит, они все равны. Все веса ребра на цикле одинаковые.
Одинаковые.
Хорошо, но как же так вышло, что веса одинаковые, а мы выбрали цикл. Давайте
поймем, как это может быть. Давайте нарисуем. Вот есть некий цикл длинный v1, v2, v3, v4, vn,
и здесь, соответственно, e1, e2, e3, en. Я знаю, что веса всех ребер одинаковые, веса всех ребер,
которые я взял в цикл одинаковые. При каком условии я для вершинки v1 выбрал вот это
исходящее ребро v2. Но это означает, что v2 меньше, чем vn. Потому что из v1 есть как минимум два
этих ребра одного и того же веса, и я предпочитаю ребро, исходящее в v2, а не vn. Значит, у этой вершинки
номер меньше, чем у vn. Так, тогда мне нужно будет продолжить в эту сторону.
Тогда давайте для вершинки номер vn-1 посмотрим, что тут написано. Почему для... тяжело, да? Давайте
какой-нибудь цикл понятный длинный нарисуем, потому что иначе мы не поймем. Цикл на пяти вершинах.
Итак, для v1 я предпочел v2 в вершинке v5. Значит, v2 меньше, чем v5. Теперь для v4 тоже сам посмотрю.
Я для v4 выбираю v5, а не v3, хотя они одного и того же веса. Значит, v5 строго меньше, чем v3.
Для v2 я предпочел v3, а не v1. Значит, v3 имеет номер меньше, чем v1. Ну, вы понимаете, к чему я
клоню? Значит, сейчас я продолжу, получу, что v2 меньше, чем v2. Для v5 я могу написать, что я
раз выбрал v1, а не v4, значит v1 меньше, чем v4. Для v3 v4 меньше, чем v2. И все. Получилось, что v2
меньше, чем v2. То есть, по сути, у меня будут вот такие вот скачки на два назад. То есть, если я
рассмотрю произвольную вершинку и говорю, что я вот эту вершинку предпочел предыдущей, значит,
вот когда я так возвращаюсь на два по циклу назад, я уменьшаю значение вершинки. Ну и понятно,
что я как бы так вот, так еще уменьшил на два, еще уменьшил на два, еще на два, еще на два. Таким
образом, я рано или поздно зациклюсь и получу, что x меньше, чем x. Вот. Значит, в случае, когда,
например, у меня было бы 6, значит, тут было бы еще проще. 6 вершин v4, v5, v6. Значит, если бы я
тоже самое написал, у меня получил, что v2 меньше, чем v6, v6 меньше, чем v4, v4 меньше, чем v2. То есть,
мы бы еще быстрее нашли противоречие. Ну короче, мы все равно рано или поздно так зациклимся и получим
противоречие вида x меньше, чем x. Это значит, что циклов длины хотя бы 3 не бывает. Единственный
возможный цикл, когда вот я завершаю вот этот вот цикл, может иметь длину только 2. Ну длины 1
быть не может, потому что у меня нет петель. Мы не можем выбрать вот такое ребро. Нет петель у
меня в графе. Может быть только цикл длины 2, как вот на этой картинке. Поэтому, действительно, циклов
не появится. Согласны? Так, ну хорошо. Циклов не появится. Ну теперь надо еще доказать корректность,
что мы найдем обязательно минимальный остов, но это несложно. То есть, мы поняли, что циклов не
появится, значит у нас всегда дерево. То есть, мы найдем какой-то остов. Вопрос, у чего он минимального
веса? Докажем, что находимое дерево, находимое остов имеет минимальный вес. Так, ну здесь наша любимая
лемма о безопасном ребре. Только ее нужно немножко аккуратно приложить, потому что как у нас
работает лемма. У нас было было что-то, я добавляю одно ребро и получаю подножие
минимального остова. Так вот здесь некоторая неприятность в том, что я добавляю сразу
много ребер с копом. У меня есть подножие минимального остова, я добавляю сразу много
ребер и говорю, что это опять подножие минимального остова. Не по одному, а с
копом сразу группу. Так вот, почему же это верно? Давайте нарисую какую-нибудь компоненту.
Вот, например, вот эта вот штука, этот кусок функционального
графа, описывает, какие ребра я добавляю на очередном
этапе.
Значит, смотрите, понятно, что эта вершина является
подножием минимального астова, вершина это всегда
подножие астова.
Дальше, я знаю, что это ребро, вот исходящее из него,
которое я выбрал, это ребро минимального веса, из него
торчащее.
Если бы я применил лему о безопасном ребре к этому
множеству, если бы я сказал, что это Т, тогда она бы мне
сказала, что это ребро можно безопасно добавить, потому
что это просто самое дешёвое ребро.
Значит, это ребро точно можно добавить.
Дальше, для этой вершинки я знаю, что вес этого ребра
меньше равен веса этого ребра.
Кост Е штрих меньше равно кост Е.
вес этого меньше равен весу этого.
Мы это уже замечали, что если для
этой вишенки я выбрал ребро e' а не e,
значит у него вес меньше равен, чем у ребра e.
Поэтому, если я скажу, что вот это текущее
подмножство 100, то это ребро будет
самой дешевой из него торчащей.
Потому что смотрите, как выглядит самый дешевый
ребро торчащий из этого множества.
Это либо ребро из этой вишенки, либо из этой.
Но мы знаем, что самое дешевое ребро торчащее
из нее было e, и мы его уже взяли,
значит все остальные весы еще большего.
А из этой вишенки
какие-то новые ребра появляются,
и вот у ребра веса меньше,
Schw copyrightfect Bunun tz explicit, значит оно будет минимfficiency.
То есть, когда я обьединяю вот это в одну компоненту связанности,
то самое дешевое исходящее ребро будет
ровно вот это вот. Потому что все исходящие из этой вишенки
более низкой, имеют вес больше,
имеют вес больше ночьем e,
значит больше ночьем e'.
Поэтому я могу объединить вот это все
в одну компоненту связанности.
То есть, считать, что это подм�ба balanced rule.
Ну и так, что мы дальше по дереву делаем, давайте еще раз это рассуждение проведу.
Вот есть подножие минимального астова, и есть самое дешевое ребро, исходящее из этой вершинки.
Ребро E2'H. Я знаю в силу моего вот этого подъема, снизу вверх поднимаюсь,
я знаю, что ребро E2'H дешевле, чем E' и чем E.
Поэтому, если я буду считать вот это вот все одной, ну как бы, неделимой сущностью,
и находить самое дешевое ребро, торчащие из нее во внешность графа,
то, конечно, это самое дешевое ребро будет E2'H, потому что оно самое дешевое,
торчаще из нее, и оно недороже, чем торчаще из этих и из этих, из-за этих неравенств.
Значит, я могу объединить вот это вот в одну компоненту.
Ну и то же самое я просто для всех делаю, что для этой вершинки я могу добавить это ребро,
потому что оно самое дешевое.
Для вот этой вершинки я могу добавить это ребро, потому что для всей этой компоненты это ребро самое дешевое,
потому что он меньше от ps, чем все остальные. Ну и так далее.
Это означает, что в конце я просто, многократным применением нашей леммы,
получаю, что все эти ребра можно добавить в остов,
тем самым я никогда ничего не делаю незаконного.
На каждом шаге я добавляю ребро, которое можно добавить.
Так, ну, многократное применение
леммы о безопасном земле.
Вот, значит, алгоритм действительно корректный.
Получает минимальный остов.
Осталось понять, за сколько он это делает.
Я утверждаю, что асимптотика здесь будет m log n,
потому что всего итерации в рекурсе будет log n.
Это следует из того, что на каждом шаге,
когда я сжимаю компоненты связности,
вот эта функциональная мемографа,
у меня число компонент уменьшается хотя бы вдвое.
Потому что, представьте, изначально было n вершин.
Дальше я для каждой нашел исходящее ребро самое дешевое
и сжал компоненты связности из тех самых дешевых ребер.
Тогда понятно, что после сжатия,
то есть тут будут какие-то вот такие объединения,
компонент связности будет не больше, чем n пополам.
Потому что размер каждой компоненты будет хотя бы 2.
Так как в каждой компоненте
хотя бы две вершины.
Хотя бы две, потому что из каждой вершины что-то выходит,
поэтому она не работает, и она не работает,
хотя бы две, потому что из каждой вершины что-то выходит,
поэтому она не одна в своей компоненте.
Значит, все компоненты имеют размер хотя бы 2.
А значит, их количество не больше, чем n пополам.
Поэтому число вершин после сжатия уменьшается хотя бы вдвое.
Если тут было n, то здесь не больше, чем n пополам.
Значит, суммарно глубина рекурсии,
сколько раз я сжимаю, сжимаю, сжимаю,
не больше, чем логарифм.
Немного уменьшается, поэтому глубина рекурсия максимум логарифм.
Ну а m нужно для того, чтобы для каждой вершинки
определить, какое самое дешевое входящее в нее ребро.
Я просто все ребра просматриваю и определяю из них самое дешевое.
Log n это глубина рекурсии,
m это поиск самых дешевых ребер.
Самый дешевый ребер.
Вот, кажется, все.
Так, ну алгоритм Барувки
он с точки зрения симптотики не выглядит
сильно лучше, чем Прим или Крускал.
Но, во-первых, насколько я понимаю,
он просто исторически самым первым был придуман.
Поэтому, я думаю, что это очень хорошо.
И еще, если его совместить с алгоритмом Прима,
то можно получить новый алгоритм с еще более
ну, в общем, с еще более быстрой симптотикой.
На семинаре посмотрите, там что-то типа вот здесь можно написать
log log вместо логарифм, можно написать повторный алгоритм,
если совместить Барувку и Прима.
Так, ну а на этом, наверное, давайте закончим.
Спасибо за внимание.
До свидания.
