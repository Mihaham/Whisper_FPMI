Одним давно, когда с дерева Фенвика начинался второй
семестр, в принципе, была создана вот такая презентация.
Так, ну давайте смотреть, значит, как мы ее будем.
Значит, я сразу предупреждаю, будьте внимательны, потому
что, как бы, то того Фенвика, который я вам сейчас буду
рассказывать, он может немножко отличаться от
того, к которому вы привыкли.
Вот.
Чего?
А, вообще не привыкли, да?
Ну ладно.
Хотя что-то сомневаюсь.
Ну-ка поднимите руки, кто хотя бы раз в жизни писал
дерево Фенвика.
Вот, логично, практически, да.
Нет, ну сформулируем так, пишется дерево действительно
редко.
То есть вообще структура, конечно, сугубо практическая.
Ну потому что, да.
Мы же с вами выяснили, что, на самом деле, с точки зрения
глобальной теории, там, на самом деле у нас даже дерево
отрезков крайне редко вообще надо, потому что все, что
оно умеет, умеет阿вель дерево, например.
Вот.
Это называется, да, спорт теоретика с практиком,
это называется.
Да.
Потому что да, авель дерево вот так..
Да, да, на поверх, да, на поверх.
Да, то есть на поверх куда с одной стороны.
АВЛ прекрасно пишется, я надеюсь к концу к дедлайну вы в этом прекрасно убедитесь.
Теоретически вам можно написать на контесте, это не означает, что вы его будете на 5 часов дуэй.
Да, но проблема даже не в этом, даже если убрать там конкретный какой-то там экзотический спорт,
в котором кто-то из вас там случайно занимается, допустим, да.
Писто случайно, да.
Ну вот. О, ты занимаешься керлингом?
Пока нет.
Пока это обнадеживает. Эх, я бы тоже когда-то так мог сказать.
Ну ладно.
Ой. Ну да, да. А потом чемпионат мира перестали показывать на ютубе.
Да, обидно стало, да.
Вот. Значит, да.
Но тут проблема действительно в том, что да.
Конечно, использовать AVL-дерево там под задачей решать деревоотресков немножко глуповато,
просто потому что деревоотресков А, проще пишется,
Б, что самое главное, констант у него, конечно, лучше.
Вот. А у Фенрика еще лучше.
Поэтому, конечно, можно говорить о структуре данных,
которая с точки зрения практики, наверное, пишет там, проще пишется и быстрее работает.
Правда, к сожалению, про нее нельзя сказать, что он умеет даже то же самое, что деревоотресков,
потому что массовое, скажем, присваивание наотрески деревоотресков,
у дерева Фенрика полномочия тут, как вы сами понимаете, все.
Правда, вот прибавление наотрески, как это ни странно,
дерево Фенрика прекрасно кушает.
Потому что это можно делать без массовых операций.
Ну, на самом деле, да.
Вот, в общем-то, массовое дерево, там какой-нибудь двумерный,
или там какой-нибудь, знаете, хит-сезон, конечно, двумерные деревоотресков,
конечно, на самом деле, может оказаться сложнее, чем двумерные дерево Фенрика.
Хотя как сложнее, они на самом деле одинаковые.
Вот. Ну, в этом все, в общем, мы попробуем убедиться.
Да, стой.
Вот тут мы будем аккуратны в терминологии, на всякий случай.
Потому что я вам сразу скажу, то, что мы сегодня будем называть деревом Федрика,
деревом Федрика, деревья Фенрика, это не является там двумерным деревом Федрика.
Да, там немножко будут разные технологии, но это, конечно, чисто терминологический вопрос.
Вот. То есть у нас будет идея в том, что будем и заведем дерево Фенрика
в каждой ячейке, в которой находятся деревы Фенрика,
но при этом эти деревья на разные размеры.
Вот. Мы, собственно, посмотрим, где же это возникнет.
Вот. Но с точки зрения теории, оказывается, это тоже не без интереса,
потому что это оказывается еще там такой альтернативный взгляд
на то, как это все может быть устроено.
Вот. Будьте здоровы.
Вот так значится. Поехали. Давайте.
Как тут вообще?
Так. Слайд-шоу. Ну, давайте.
А, вот так надо.
Значит, давайте смотреть.
Так. Ну, давайте воспоминать, чем мы из этого уже занимались.
Вот. Ну, вот базовая задача, которую мы попытаемся сегодня решать,
это дан массив. Допустим, в ноль индексации.
Че?
Яндекс-контест.
Что Яндекс-контест?
Пять раз за славу на пятый зашел.
Замечательно. Замечательно.
Обязательно вам им лекции это делать?
Да.
Нет.
Вот. Итак.
И, соответственно, хочется нам искать, допустим, сумму,
пока просто сумму на отрезке и делать присваивание.
Но присваивание одного элемента, да.
То есть менять мы будем, к сожалению, только один элемент.
Вот.
Но зато, когда мы меняем один элемент, тут вот он есть две классические задачи.
Искать сумму на отрезке и искать минимум на отрезке.
Вот. Ну, в принципе, конечно, да.
С помощью всяких там дикартовых сплей и прочих эвей,
или, конечно, мы это все умеем делать за логарифом.
Вот.
Но, таки, попробуем, значит, более простые.
Значит, что мы хотим?
Так.
Ну, в первую очередь мы, конечно, сосредоточимся на задаче риску,
хотя, забегая вперед, рэмку мы тоже делать научимся.
Вот как это не странно.
Значит, смотрите.
То есть мы здесь немножко подмодифицируем.
Говорим, что вместо операции присвоить элемент,
мы будем говорить прибавить элемент,
потому что, в общем-то, принципиально ничего не поменять.
Вот. То есть у нас такая модифицированная задача риску.
Присвоить одну прибавку.
А! В одном месте.
В одном. Да.
В один элемент, если быть точнее.
Нет.
Что?
Ну, для минимума наоборот отрицательный.
Да.
Да, но мы сейчас для риску.
Нет.
Когда мы ищем сумму, можем прибавлять что угодно.
Сейчас мы в этом убедимся.
Вот.
Значит, будем решать для массива, ну, допустим, целых чисел.
Целость тоже не принципиально.
Ну, соответственно, значит, что у нас тут требуется?
Огромное количество там всего.
Но как бы это все требует у нас о отн дополнительной памяти.
Прошу, помните, да?
Потому что даже в каких-то самых простых версиях там все равно
для любого элемента вам потребуется в деревьях какая-то вершина.
У нее должно быть хотя бы два указателя.
Вот эти left и right.
Ну и там дальше можно там выкручиваться как угодно.
То есть там один бит там какой-нибудь.
Там что-нибудь там AVL какая-нибудь или там.
Вот иногда говорят, давайте в AVL хранить не высоту дерева, например,
а только там разность между высотами там сосекими.
Да, там плюс-минус один.
И как-то там подгоняться можно так пробовать.
Вот.
Ну, правда, там сплитые мержи, правда, тут начинают вылетать в трубу немножко.
Ну вот.
Ну, по крайней мере, за идеальную там для нас асимптотику, конечно.
Ну вот такое.
Но так или иначе отн дополнительной памяти есть.
Ну и там всякие еще динамические памяти есть.
Ну, можно, понятно, там, конечно, там попытаться это оптимизировать,
там вызывать какой-нибудь буфер, там заводить себе заранее буфер
и там выкапывать это.
То есть там всякое можно.
Вот.
Но наша структура, по крайней мере, вот в исходной простой задачи
будет занимать едва ли не от единицы дополнительной памяти.
Ну, потому что реально мы массив хранить не будем,
мы будем хранить только само дерево.
И оказывается, что там на него требуется буквально вот массив размера N
и какой-то там может быть от единицы памяти и то необязательно.
Вот.
То есть сейчас вот посмотрим, как же это будет работать.
Вот.
Значит, работать будет так.
Значит, у нас есть массив A.
Значит, мы будем хранить, значит, внимание, вот тут
классическое такое отличие, у нас будет...
Мы заведем такой массив B,
который мы позже будем называть массив F
большое на самом деле.
Вот.
Ну ладно, раз уж кто-то в презентации написал,
что уж нам менять, что ли.
Вот.
Значит, соответственно, но внимание,
массив у нас B будет у нас со сдвигом,
то есть у нас будет массив в один индексации.
И после этого
вот.
Ну вот.
И в этом массиве, значит, мы будем хранить
суммы на некоторых подотресках.
Ну что это за подотрески?
А вот очень интересно.
Оказывается, что в этом отрезке
мы будем хранить сумму на, обратите внимание,
полуинтервале.
Видите, да?
Полуинтервале от F, от E включительно,
до E не включительно.
Вот.
Ну будет вот у нас такая приятная штука.
Вот.
То есть если у нас такой массив B есть,
то можно как минимум префиксные суммы достаточно просто искать.
То есть вот какую-нибудь там префиксную сумму
там от 0 до E, допустим, да,
можно теперь найти,
просто найдя такую сумму элементов B и плюс первое,
B, F от E плюс первое, B, F от F это и плюс первое,
и так далее.
Вот.
Понята логика, да?
Вот.
Ну и, конечно же, если мы умеем искать префиксную сумму,
то мы умеем, собственно, и обычную сумму искать.
Да, потому что суммы у нас какими свойствами овладают?
Обратимость.
Ну да, в данном случае обратимость.
Да.
Да, вот эту штуку мы умеем искать,
потому что сумма ассоциативна,
а эту штуку умеем искать, потому что она обратима.
Коммутативность тут, в принципе, пока ни при чем.
То есть коммутативность нам понадобится,
когда мы будем менять.
Вот.
Но для того, чтобы менять,
сначала нам нужно понять,
а чему равна функция F?
Потому что самая,
чему может быть равна функция F?
На самом деле она может быть равна практически чему угодно,
если мы гарантируем,
что F от И всегда строго меньше И.
Логично, да?
Ну, с точки зрения того,
чтобы, по крайней мере, находить эти префиксные суммы правильно.
Но нам же нужно эффективно,
потому что, в принципе, так-то можно было ввести там F от И равно
И-1.
Вот.
И тогда, по большому счету,
то есть получается массив В,
это такой же массив А,
только сдвинутый на единичку,
по каким-то причинам.
Вот.
И получается, что чьи префиксные суммы ищутся за И.
Ну, зато обновлять элемент легко.
Вот.
Можно было бы и наоборот.
А давайте в каждом B-итам хранить E.
Вот, допустим, F от И равно ноль.
То есть просто в B-итам честно префиксные суммы храним.
Ну классно.
Тогда префиксные суммы ищутся за O от единицы.
Правда, потом обновлять будут проблемы, да?
Потому что, чтобы обновить И-то элемент,
что нам надо сделать?
Уходить по всем ответствам, которые его пересекали?
Да.
Ну, точнее, содержат.
Если быть точнее.
Да.
Чтобы обновить.
То есть теперь, чтобы сделать там,
добавить И-тому элементу 57,
надо перебрать все подотрески,
которые содержат И-то элемент,
и ко всем их суммам прибавить 57.
Вот.
Но хочется, конечно, это делать как-то эффективно.
И вот тут начинается немножко битовой магии.
Вот.
Потому что по каким-то вот мистическим причинам
вот сидел товарищ Фенвик, думал.
Да, Фенвик это реальная фамилия, естественно,
как вы догадываетесь.
Собственно даже статья есть.
Вот.
То есть шаманим, шаманим, шаманим, шаманим.
И оказывается мистическое определение.
Да, тут официально какая-то магия,
а значит она на самом деле маленькую простую вещь.
Мы берем двоичную запись числа,
берем самый младший единичный бит,
то есть самый правый,
и обнуляем его.
Вот таково у нас будет определение функции Ф.
Просто убить последний единичный бит.
Ну, Ф от нуля так и быть,
напишем нулю, хотя Ф от нуля нам
может быть нам даже правильнее было бы считать,
что Ф от нуля не определено.
Вот.
Соответственно.
Ну тогда.
И даже вот.
То есть как бы правильнее считать,
что оно не определено,
и там в реальном коде уже писать,
если вы там пытаетесь вычислить Ф от нуля,
значит там кинуть какое-то исключение.
Ну или вызапить каким-то другим способом.
Вот.
Ну тогда, значит, чем приятна эта функция?
Да.
Но эта функция приятна тем, конечно,
что получается префиксную сумму от элемента,
и вы найдете за какое время?
Ну это да, верно.
Да.
Точная оценка, конечно,
это количество единичных бит в числе каком?
Совершенно верно.
И плюс один.
И плюс один.
Право.
Да.
Вот.
В среднем примерно будет попало.
Ну да.
Если не кидается рандомно,
то да.
Вот.
Ну вот.
Не, ну это тоже неплохо вообще.
Вот.
Ну правда, тут еще, конечно,
константа еще будет зависеть от того,
а как вообще эту Ф вычислять?
Ну да.
Желательно за быстро.
Ну как за быстро?
Ну за вот единицу ее вычислить достаточно легко.
Ну, например, предподсчитав ее
я всех чисел от 0 до n.
А вы не можете сказать,
что операции с машинными словами
работают за один день?
Можем.
Но для этого надо просто подумать.
Просто они буквально за один работают.
То есть это наша единица измерения.
Нет, безусловно, да.
Но там да.
Да, безусловно верно,
то, что функция на самом деле вычисляется
напрямую с помощью битовых операций.
Мы чуть позже даже обсудим как конкретно.
Да.
Но как бы, смотрите,
пока мы просто,
пока мы временно оставим этот вопрос,
просто пока временно удовлетворившись тем,
что там как-нибудь за вот единицы это вычисляется.
Вот.
Итак.
Значит, как же нам теперь вычислять?
Ну вот.
Но как же теперь вот вычислять этот?
Вот возникает маленькая проблема.
Вот.
Ну, здесь действительно все, казалось бы, просто.
Действительно.
То есть нужно просто увеличить на дэйта все такие,
такие бриты, что, значит, FAT меньше либо равно
индексов, которые мы обновляем, там меньше.
Вот.
Так.
Но дальше вот начинается черная магия.
Так.
Дальше там написан какой-то текст.
Давайте-ка я лучше достану доску
и попробую, собственно, прямо
просто наглядно показать на картинке,
о чем он значит.
Так.
Значит, смотрите.
Ой.
А, там уже все понятно, да?
Так.
Значит, ну давайте думать.
Жило было какое-нибудь рандомное число индекса.
До какого-то момента оно, ну то есть оно бесконечно влево,
но там бесконечное число нулей.
А вот количество единиц?
Конечно.
Вот.
Ну тут вот.
Вот так вот.
Ой.
Значит, тут получается 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0.
Так.
Итак, что мы теперь хотим?
Мы хотим найти какое-то, какие-то числа И, а желательно все,
чтобы FAT было меньше либо равно индекса,
индекс был строго меньше, чем И.
Вот понятно, да?
Так.
Ну давайте думать.
Что означает, что И строго больше индекса?
Это означает, что мы идем, идем, идем, идем слева-направо идем
и биты И и индекса совпадают.
До какого-то момента.
А в какой-то момент они впервые не совпадают.
Но в тот момент, когда они не совпадают,
в тот момент, когда они не совпадают,
неожиданно выясняется, что раз И больше, значит и в И бит должен быть больше.
Но единственный вариант, это когда у нас в И тут единичка,
а в индексе в этом месте стоит 0.
Пока логично вроде, да?
Вот.
Так.
Ну теперь думаем.
Чему должен быть равен FAT?
Ну у него 0 должен быть в этом месте.
Вот, да.
Ведь действительно смотрим, что FAT.
Пока существует эта единица,
заметим, что FAT вот эти биты по-любому не тронет.
Потому что эта единица, может последняя, может нет,
но может последняя где-то правее.
Но уж эти единицы точно не последние.
Поэтому пишем тут.
Тут все как бы красиво-красиво-красиво.
Так.
Ну а теперь следующий вопрос.
Ну это следующий момент.
Но теперь заметим, что если я тут напишу единицу,
то тогда получится, что FAT тоже строго больше индекса.
Правда?
Пока логично, да?
Так.
Но получается единицу тут написать нельзя.
Так нельзя, значит пишем 0.
Так, но получается, что конкретно в этом бите получается
и FAT отличаются.
Но вывод очень простой.
Это означает, что справа от этого элемента
все биты числа i равны 0.
Вот.
Ну и FAT автоматически тоже, да.
Совершенно верно.
Это единственный вариант вообще, который нас может устроить.
Так.
Что же это все означает?
Так, означает это маленькую приятную вещь.
То есть это означает, что как...
То есть необходимые условия для того, чтобы i подходило нам.
То есть должно быть так.
То есть мы должны взять индекс, взять у него какой-то нулевой бит,
заменить его на единицу, а все справа заменить на нули.
То есть вот i должно быть таким, чтобы, может быть, оно было хорошим.
Правда, на самом деле это не только необходимые условия,
но очевидно и достаточно.
Потому что FAT от индекса будет отличаться тем,
что мы как будто просто начиная с какого-то момента
все биты занулили.
Но обратите внимание, число могло, кстати, вообще не поменяться,
если тут единиц не было вообще.
Вот, здорово.
Так.
Ну вот.
Но правда возникает вопрос.
Вот.
Есть.
Вот.
Вопрос какой?
А сколько подходящих чисел i вообще есть?
И как их найти?
Нужны i, которые не больше, чем i большое.
Кажется столько нулевых битов.
Так, а сколько у нас нулевых битов в числе?
Десять.
Стас, совершенно верно.
Да, обратите внимание, что на самом деле подходящих i для любого индекса
бесконечно много.
Ура!
Есть.
Но мы не на Питоне пишем, поэтому и в 60.
Или сколько?
64.
Но это работает не по такой логике.
Тут работает по логике.
Действительно, заметим, что i-то нам нужны действительно не все,
а только те, которые не превосходят n.
Вот.
Но тогда очевидно, что количество подходящих i не превосходит логарифма.
А точнее не превосходит количество нулевых бит в числе индекс,
если дописывать все нули, в степени двойки которых не превосходят, собственно, числа n.
Вот так вот.
Так.
Но остается только вот маленький вопрос.
Как же их аккуратненько вычислить?
Ну, для того, чтобы их аккуратненько...
Так, интересно, может там следующий...
Ой, нет, дальше я писать не буду, потому что у меня в следующем слайде, наверное, все красиво написано.
Вот.
О, Господи.
Внезапно, да?
Да.
Ну, тут вот да.
Нет, тут на самом деле просто написано то, что я тут сказал, по большому счету, да.
Вот.
Вот.
Значит, ну теперь оказывается следующее.
Что если мы...
То есть оказывается на самом деле следующее.
Рассмотрим какой-нибудь вот первый попавшийся число индекс, да?
Ну, там немножко другое, но вот.
И тогда рассмотрим все числа, которые нам нужны.
Вот давайте пока вот этот столбец я вот так вот закрою, да?
Вот.
И давайте смотреть.
То есть у нас первое число, это вот действительно берем,
заединичиваем вот этот нолик и обнуляем все справа.
Потом берем вот этот нолик, заединичиваем его, обнуляем все справа.
Берем этот нолик, тоже там единица справа, ну и так далее.
Ну, легко заметить, что первое число, которое мы берем, это всегда просто вот это число плюс один, правда?
Ну, кстати, если бы тут в конце стоял нолик, то как бы этот нолик мы на 1 заменяли, в общем, очень удобно.
Вот.
А каждое следующее число, а каждое следующее число на самом деле идет,
зависит только от предыдущего, устроено очень простым образом.
Мы находим последнюю единичку, находим этот непрерывный блок с этой единичкой,
смотрим на нолик перед ними и объединичиваем этот нолик, а остальное за нулями.
Вот видно, да, что вот каждое следующее ровно так и устроено.
Вот.
Ну вот и так у нас естественным образом возникает функция G.
Вот. То есть вот так мы ее и определим.
Вот давайте прыгаем.
G от положительных целых чисел, это функция, которая делает вот эту капсу.
Вот.
То есть если мы откуда-то эту G научимся вычислять, то тогда модифицировать дерево нам будет достаточно легко.
Вот.
Но на следующем слайде мы видим, как на самом деле с помощью битовых операций эту штуку вообще вычислять.
Вот.
Но здесь немножко магии, да, то есть действительно если рассмотрим число И, там рассмотрим число И-1,
вот, и быстренько обнаружим, что для того, чтобы занулить последнюю единичку, мы будем вычислять,
и быстренько обнаружим, что для того, чтобы занулить последний единичный бит,
на самом деле нужно просто написать вот такое мистическое заклинание.
Видно почему, да?
Ну потому что да, смотрите, то есть как бы вычитание единички как бы зануляет последний единичный бит,
но объединичивает все стоящие справа от него нули.
Ну вот, но если вы берете N этих чисел, то у вас тогда получается, что единичка занулилась,
единичка занулилась, все справа тоже занулилась, все остальное не поменялось, то что на 0.
Очень удобно.
Вот.
Но если вы вместо N-да возьмете OR, то наоборот, получится, что последний блок нулей,
ну, возможно, пустой, кстати, заединичится.
Вот.
И тогда оказывается, что если вы к этой штуке прибавите 1, то получится ровно функция G,
ну и таким образом вот формулы есть.
Вот.
Так что да, тут, ну тут, конечно, ну вот, то есть на самом деле тут, конечно, по-разному можно мыслить.
Вот.
То есть получается, что F и G у нас вот так вычислились.
Но на самом деле, конечно, отметим, да, в презентации этого нету, но на самом деле можно еще,
вот нам еще пригодится рассматривать и функции немножко по-другому.
То есть на самом деле в этом месте целесообразно ввести функцию H.
Где H от И, это будет просто 2 в степени, угадайте, какой?
Младший единичный бит.
Да.
Ну давайте так и напишем.
Младший единичный бит числа И.
Вот так.
Вот.
Вот.
Вот.
Вот так.
Вот.
Если вы правильно понимаете, что это, то становится очевиден, очевиден маленький приятный факт,
что F от И это на самом деле тождественно равно И минус H от И.
Удобно, правда?
Вот.
Но.
Вот.
Чуть менее очевидно, но даже более красиво.
Оказывается, еще больше магия.
G от И это всегда И плюс H от И.
Вот.
Ну да, по большому счету, да, легко убедиться, что вот это, что мы говорили про последний блок единичек,
на самом деле это вот буквально это мы и делаем.
Да, к сожалению, у меня нет красивой интерпретации действительно,
из каких глобальных, красивых соображений это сразу глобально взялось.
То есть просто пока вот, то есть просто рассматривали функции F и G и вот заметили, что.
Да, так получилось.
Вот.
Почему?
Не знаю.
Вот.
Ну вот.
Это было F, это было G.
Вот.
Ну и соответственно H можно там пытаться отдельно вычислять,
но правда тут дальше аккуратно надо делать, действовать, конечно.
Потому что на самом деле, да, тут сразу возникает вопрос,
как с помощью битвах операций вычислить функцию H.
Ну можно вычислять F и потом вычислить.
Ну да.
Но тут на самом деле аккуратный момент.
Тут смотрите, какой аккуратный момент есть.
Потому что, с одной стороны, да, тупой вариант для нас, конечно, И минус F, а ты, который мы напрямую вычислять умеем.
Так, есть кто живой?
Вот.
Значит, смотрите.
Ну вот.
Но, с другой стороны, потому что на каких-нибудь этих ваших E-max очень любят вычислять что-то типа H, а ты
там с помощью каких-то формул типа E и минус E.
Ну да.
Это внезапно, да?
Ну вот.
Ну, скажем так.
Ну, на самом, а я тоже так скажу.
С точки зрения стандарта C++, кстати, эта магия не работает.
Это, капиллятор же не, нет стандарта, как капиллятор хранит числа.
Он может хранить их в любой запас.
Капиллятор их не хранит.
Нет, ну там нет.
Да.
Нет, стандарта C++ говорит, насколько я помню, следующее, что не отрицательные целые числа хранятся адекватно.
Обычные там инты хранятся, пока они не отрицательные, хранятся тоже адекватно.
Вроде и соответствуется явно, что у нас, как это называется, дополнительная форма записи для отрицательных интов.
Да, а вот по-моему в стандарте это не прописано, что возможно по-другому.
Да, конечно, с вероятностью 99.9999999 у нас целые числа, отрицательные числа используют дополнительные.
9999999 у нас целые числа, отрицательные числа используют дополнительную форму записи.
А как мы бы складывали числа, если это было бы не всегда так?
Ну, возможно существовала бы другая архитектура, которая делала бы это как-то красиво.
Ну или не красиво.
Так что философский вопрос. Ну да, давайте напомню на всякий случай.
То есть действительно, что тут имеется в виду?
Имеется в виду следующее. Допустим, у нас число 0 обычно записывается как сколько-то нулевых бит.
Ну давайте я пока 8-битное число напишу, хотя суть везде одинаковая.
Там 0, значит это у нас 1, 2, это у нас 0000010, там 3, там это 000001.
То есть как бы честно в битовой записи 1 прибавляем и хорошо.
Вот. Ну и так мы идем до 127.
Где у нас тут? То есть мы тогда идем до соответственно 0 и 111111111111.
Вот. То есть что такое дополнительная форма записи?
Ну она предлагает следующее.
То есть давайте вот по этой логике просто пойдем не только вперед, но и назад.
И скажем, что если у нас минус 1, давайте тут единичку вычтем.
Ну будем вычитать, вычитаем ее с переносом, переносом, переносом, переносом, переносом, переносом, перенос, вылез, вау, мы говорим окей.
Вот. То есть вот так хранится минус 1.
Вот. Соответственно минус 2, значит получается 111111110.
Да. 1111110. Слушайте, а поднимите руки ради интереса.
А кто когда-нибудь был в олимпиадных школах по информатике?
Нет. Именно олимпиадных школах. Тут важная сейчас.
Которая наша, да.
Да. Так и будет.
Ага. Так. Окей.
Так. А кто был когда-нибудь на лекциях Снарка?
А. Из вас никто, да?
Ну окей. Нет. Просто жалко.
Ну это логично, потому что он обычно рассказывает там в самой младшей группе.
Но при этом он очень любит рассказывать вот эту.
В самой младшей группе?
Нет. Он там конечно не рассказывает Фенлика, естественно.
Но он рассказывает. Но как бы там же есть же такая там тема как типы данных.
Вот. Но он собственно и рассказывает, собственно как они устроены.
Вот. Поэтому просто на всякий случай так, что возможно от него вы еще могли все это знать.
Вот. Но вы с ним не пересеклись в этом месте. Окей.
Нет. Так-то да.
Хотя да. Кто был в олимпиадных школах?
Ну понятно, что да. В олимпиадных школах скорее всего были там чуть менее чем все.
Или нет?
Ну-ка поднимите руки, кто никогда не был ни в одной олимпиадной школе.
Нет. Вот на этот раз да.
Ни в ЛКШ не был. Ни в наших олимпиадных школах.
Ни в инополисе там каком-нибудь. Или еще что-то в этом.
Серьезно считается?
Конечно.
Господи.
Как вы это сделали?
Просто да.
Мастовские сборы считаются?
Нет.
А вы из Беларуси?
Нет.
Хотя в Беларуси тоже школы есть.
Нет. Они-то везде есть.
Господи. Как вы это сделали вообще?
Ну окей.
Человек сидит на оке, он по жизни самостоятельно.
Правильно. Ну да.
Окей.
А вы с Кена на Мальсармении не знакомы случайно?
Нет.
Нет. Но нет. Это просто вот тоже.
Нет. Просто еще один студент МФ3.
Вот тоже, который никогда никуда не ездил.
И все изучал самостоятельно.
Называйте уровень финалист чемпионата мира.
Опистиха.
Вот.
Ну хотя да. Мало вероятно, что вы с ним пересеклись.
Да. Уже.
Вот. Окей.
Хорошо.
Да.
Ну да. Действительно.
Зачем эти школы ездить?
Реально.
Только время тратить.
Так.
Так вот.
Вернемся к делу.
Чем удобна вообще такая запись?
Казалось бы, что-то очень сложно.
Минус один, вот это, минус два.
Это как-то перекореживаться.
К компьютеру, когда он перчатает число на экран,
приходится еще что-то как-то думать.
Как переводить вот это в дистичную систему
и так далее.
Особенно, когда тут 32 бита, 64.
Но о этой штуке, конечно, есть очевидное преимущество.
Потому что по большому счету заметим, что в каждый момент времени
мы в числе храним остаток отделения числа на 256,
ну или там два в степени количества бит.
И при этом губилеатор все равно,
но то, по-моему, считает остаток промазанной.
Ну.
Да.
Все плюс-плюси, да.
Ну, почему-то там так приписали.
Да.
Хотя в какой-нибудь питоне, как вы помните,
минус два процент пять равно вполне себе три.
Да.
Да.
Да-да-да-да.
Если питон, да.
Если питон еще и быстро работал, конечно.
Но что делать?
Ну вот, здесь просто оказывается удобно,
что если мы вместо каждого числа храним остаток по модулю два в степени,
то складывать, вычитать и умножать становится легко и приятно.
Также легко заметить, что как стануть теперь in consint into?
Что надо сделать с числом?
Да, правильно.
Ничего.
Просто поставить пометку, что он теперь не знаковое число,
а безнаковое, биты те же.
Очень удобно.
Вот, действительно.
Поэтому, конечно, скорее всего,
такую систему встретите с вероятностью 99.99999999%
и тогда вот в этом предположении может работать функция h вот такая.
Ладно, а разве g++ явно не прописано, что это должно быть?
Нет.
Нет, там в явном виде прописано, что...
Что в стабилитаре плюсов это не прописано,
может g++ это всегда так, извините?
Ну, это интересно.
Это как?
В смысле, что комбинатор конкретно говорит, что это так?
В смысле, что комбинатор говорит, что у меня всегда так,
или он используется на всех линкадах всегда?
Нет, погоди, я боюсь, что это дело не в g++,
а дело в том, что в какой архитектуре у вас, собственно, это все вычисляется.
Потому что вычисление, то, что я описываю, это не компилятор c++.
Это как бы зависит от архитектуры компьютера.
Потому что как бы там всякие непосредственно сложения битовых чисел,
у вас там все-таки зашиты там на аппаратном уровне практически.
То есть там какие-то там буквально едва ли не схемы там спаяны.
Поэтому на самом деле это не от компилятора зависит.
Вот, то есть скорее всего архитектуры.
Да, то есть там понятно, что какая-то там условная там,
какое-то умное словосочетание гарвардская архитектура там, по-моему,
или вот что-то в этом роде.
То есть она там встречается чуть менее там практически всегда.
Но там, возможно, там все остальное прописали,
потому что теоретически возможны другие архитектуры,
а мы должны быть там толерантные, соответственно, и все такое.
Вот.
А вот.
Но, соответственно.
Да.
Поэтому дело тут вообще не в компиляторе.
Вот.
Но если вот в это поверить, да.
Но там подробнее на самом деле вы все это на окосе будете изучать на самом деле.
Это знаете, если мы поверим в другие архитектуры,
у нас вот это все в целом ломается,
потому что нам берут какие-нибудь троичные числа вместо дворечных и все.
А, ну.
Да, да.
Нет, ну почему?
Ну да.
Ну не знаю.
Но вот такой тонкий момент,
чтобы почему-то про беззнаковые числа
уже даже компилятор C++ все-таки верит,
что там все адекватно устроено, поэтому.
Вот.
Ну да.
Или, по крайней мере, он будет гарантировать,
что беззнаковые числа,
то есть для беззнаковых чисел есть вот эти вот все битвы-операции.
Да, битвы-энд, битвы-или,
то есть да, может быть, конечно,
там просто в других архитектурах эта операция будет как-то плохо работать.
Ну вот.
Ну там как-то понятно, что, знаете,
чтобы сделать битвы-энд,
вам придется перегнать число из троичного вида в двоичный,
сделать энд, перегнать его обратно, там вот это все.
Но,
ну вот.
Но здесь, видимо, все-таки считается,
что, ну, скорее всего, ну как-то странно, да, это у вас.
Ну в смысле и здесь как-то странно, что такое вообще-то.
Ну да.
Ну вот.
Но факт остается фактом.
Так написано в стандарте.
Вы же помните, в стандарте много удивлений, да,
потому что в конце концов как-то тут почему сет реализован так,
что, например, как каты порядка,
ну вот.
Вот так договорились по каким-то причинам.
Вот.
Да.
Ну понятно, да, что причина, конечно, да.
То есть, видимо, решили, что всем одновременно неугодимая эффективность
хоть какая-то должна быть, да,
а для всех остальных существует оргнорецепт.
Но такие потом уже кто-то допилил,
то это пока неофициально.
То есть это как бы вот реально там гнушная подхачка.
Да, не гнусная, а гнушная, да, понимаете.
Вот.
А.
Что бы я знал.
Нет.
Что-то не стандартирует.
Как бы мы что-то работаем с безнаковыми числами,
и у них не будет работать.
У них есть много разных идей.
Ну, не знаю.
Нет.
Возможно, через 20 недель придет какая-то крутая идея,
а у тебя уже все карты написаны.
Нет, почему отрицательные?
Нет, для безнакових чисел нет минуса.
У тебя этот трюк работает, типа.
У тебя же по идее для безнаковых чисел минус
ты должен в плане взять отрицательное само у себя.
Да, есть определенное читание в чисел,
которое может быть сделано как-то внутри.
Нет, подожди.
Ты можешь написать,
минус size t равно минус один.
Это каст.
Нет, это да, но он кастанет,
и получится там,
и получится там,
называется, max size t, да.
В смысле, выход на каком языке пишете,
на плюсах, вроде как можно отрицательные брать.
Нет, ну там просто,
нет, если вы возьмете
там unsigned things, там a,
и напишете равно минус один,
то это просто будет каст.
Это не явный каст.
Он вызывает функцию.
Эта функция может ничего не делать,
если она не нормальная.
А, все, я понял.
Нет, потому что я сказал,
что просто вот,
как бы теоретически просто можно вычитать fg
вот таким вот образом,
но это работает только вот в этом жестком предположении.
Хорошо, можно написать size t0
minus size ti.
И это с точки зрения стандарта кажется...
Ну, как сказать,
ну будет переполнение,
но дальше уже надо,
да, настолько глубоко в стандарт,
это уже не ко мне.
Переполнение безнаковых, это точно нормально.
Это нормально.
Переполнение безнаковых, да.
Окей.
Но это переполнение нот.
Нет, ну просто это означает,
что примерно так,
только там число минус один
не называется числом минус один,
потому что беззнаковое.
А вот int могут быть устроены как угодно.
В int может это уже работать не будет.
Мы же не гарантируем,
что у нас число минус один
в беззнаковом типе устроено как все единицы.
Это стандарты не гарантируют.
Нет.
Так, минус один в беззнаковом типе
не устроен никак,
по определению словосочетания беззнаковый тип.
Хорошо, мы гарантируем,
я бы не гарантировал.
Ну я скажу так, я бы не гарантировал,
но опять...
Если стандарт гарантирует,
что минус один это максимально,
то почему мы обсуждаем,
как конец социализации?
Это на питание будешь писать?
Сказали, что это не гарантируется стандартом,
это гарантируется стандартом.
Если в вас статикаст, то да.
Нет, беззнаковый...
Если мы гарантируем,
что минус один переходит в максимум ССТ,
тогда...
То есть ноль беззнакового типа,
минус один.
Да хорош уже, блин.
Ну хорошо, ладно.
По-хорошему говоря,
эти все вопросы лучше сегодня,
ближе к вечеру обсуждать с Мещегеном,
собственно, на лекциях по С++.
Вопросов того, что написано в стандарте,
он, я думаю, компетентнее меня.
О, Господи.
Вот.
Ладно, поэтому пока
просто понаслаждаемся
как классическим.
Ну, почти.
Не, ну конечно,
классическим для условных там СИШников,
которые не очень любят вектора.
Да, потому что, да,
как можно писать себе дерево фермика,
если вы не любите.
Соответственно, если...
Не, ну нормально.
Не, ну как сказать,
СИС классами, да,
какое-нибудь такое, да.
Что?
Где аллокатор?
А что?
А у нас уже
New Delete не работает?
Не, ну да.
С этой точки зрения,
а где шаблоны?
Почему интернет там,
какой-нибудь template там,
по этой логике.
Вообще-то да.
Не, не надо.
Это просто тщательные решения,
которые решили написать дерево фермика.
У нас тут все просто, да.
Вот.
Вот, так соответственно, да,
мы тут завели массив размера N3S1.
Да, ну допоминаю, что обнуляется массив,
кстати, вот таким приятным способом.
А если мы верим в ту архитектуру,
то, кстати, очень удобно,
на самом деле, в массе там заполнять
массив N-тов числами минус 1.
Для этого нужно просто вместо нуля
написать, соответственно,
вот.
Вот.
Ну, потому что да.
Потому что тут указывается,
как бы, проверить по всем байтам
вот этого диапазона
и в каждой из них запиши вот это.
Вот.
Так, ну и дальше, оказывается,
действительно, код оказывается,
действительно, как-то вот очень красиво устроен.
Вот, ну да.
А если вы еще на Олимпиаде,
то там всяких вот этих вот вещей
вообще писать не надо.
А здесь нигде.
Мы использовали только F и G.
Кстати, эта презентация не знает
о существовании функции H.
Почему?
Где?
Нет, презентация об этом не знает.
Презентация знает только функции F и G.
Про H это я вот потом, это я вот
отдельно рассказываю, да.
То есть как бы презентация старая,
там потом как бы, знаете, данные
обновлялись, соответственно,
и так далее.
Сейчас, как?
Чего еще раз, как пройдет?
Ну, мы не обсудили, почему,
если мы будем проходить по функции F и G
и так прибавлять,
то тогда у нас будет корректно.
Обсудили, ну как,
обсудили примерно еще в этом месте.
А, да.
Ну как бы, ну как, логично,
потому что, да, мы храним вариант на пол.
Ладно, давайте, краткое содержание
предыдущих серий, а то что-то мы тут
оставляем.
Чем мы занимаемся?
Мы занимаемся тем, что у нас вот
есть дерево, которое в этой ячейке
хранит сумму чисел от F от и включительно,
да и не включительно.
Прям на уровне определения,
где F это там, типа, вот такая функция.
Ну ладно, мы сказали, что это функция,
которая там обнуляет последний,
младший единичный бит, ну потом выяснили,
что она вот так вот вычисляется, да.
Ну и понятно, говорим, что
префиксную сумму вот так
найти можно.
Потому что с таким вариантом
уж точно она ровно так и ищется.
Вот.
А дальше мы, вот, то есть дальше
у нас было аккуратно, что мы там
сидели, аккуратно говорили, что если
вы хотим там обновить, допустим,
элемент номер индекс, то нам нужно
перебрать все и такие, что F от и
меньше, либо равно индекса меньше и,
и ко всем этим суммам прибавить дельта,
потому что такие суммы увеличились
на дельта, а все остальные нет.
Вот. И мы вот аккуратно доказали,
ну вот действительно, что оказывается,
эти все подходящие и перебираются
ровно таким нехитрым способом.
Да, вот это вот эта функция
G от индекса, на самом деле.
То есть тут можно написать,
индекс равно G от индекса.
Так что нет, тут мы вполне себе все
обсудили.
Вот.
Итак.
Но замечаем,
да, пока, ну вот, то есть это вот все
красиво работает,
но теперь попробуем это как-то обобщить.
Потому что, заметим, что,
то есть можно, конечно, подсовывать любые
какие-то типы, любые там бинарную
операцию с ними,
ну как любую, но правда, это любая
операция должна обладать жесткими
свойствами.
Как бы, чтобы найти хотя бы,
чей префиксную сумму нужна
ассоциативность,
чтобы работал файн сумм
с помощью там префиксной суммы
минус префиксной суммы,
нужна обратимость,
а чтобы работал add,
очевидно, нужна еще и коммутативность
сверху.
Потому что мы прибавляем
это, то, что нужно добавить,
абсолютно рандомный момент времени.
Вот.
Ну, видимо, не момент времени.
Но сначала мы вычисляем всю сумму,
а потом еще вот это.
Ну, как бы в конце к нему
прибавляем.
Ну, как бы в конце к нему
прибавляем.
Для того, чтобы работала
вот эта вот типа
сумма на подотреске,
это сумма на префиксе,
минус сумма на префиксе.
Вот тут обратимости есть,
вот это знак минус.
Вот.
Значит, то спрашивается,
можно ли как-то ославить требования?
Деревоотресков лучше чем.
Деревоотресков работает, как вы помните,
для абсолютно любой ассоциативной операции.
Да.
То есть коммутативность не нужна,
я вообще не знаю структуры данных,
которые работают с не ассоциативными операциями,
если честно.
То есть, потому что все оптимизации
все-таки как бы все, что там,
все структуры данных все-таки там,
которые ищут как-то быстро суммы
на каких-то подотресках,
они по-любому базируются на том,
что суммы на некоторых подотресках
вы в том или ином виде храните.
Ну, а какие у нас вообще есть
осмысленные не ассоциативные операции?
Можно рассчитать прыжки на корень
типа из каждого индаста,
но если операция не ассоциативна,
то это все как бы не поможет.
А, черт, да, блин, ладно.
Вот тут и проблема, да.
Ну, можно рассчитать на всех подотресках,
а потом отдельно.
Ну, разве что.
Но это не структура данных,
это полный предподсчет.
Нет, дадаем в степени 5 в треть.
Делим на блоки по...
Да.
Если мы потом компонуем эти блоки,
то мы опять делим на блоки по...
Да.
То есть мы опять требуем ассоциативность.
Нет, мы из каждого индаста насчитываем.
Ага.
Ага.
Вообще из каждого.
Это точно не квадрат.
Из каждого, но при этом таких отрезков
самих, типа корень.
Ну, допустим, хорошо.
Ну, окей, ладно.
Можно повыкручиваться.
Да.
Ну, окей, ладно, пойдемте дальше.
Итак, перейдем к дереву Фенрика.
Дереву Фенрика.
Более известному как встречное дерево Фенрика,
в котором от операции используется только ассоциативность.
Ну, как и нот.
Ну, и у нас есть...
Ну, в первую очередь мы, конечно, будем работать с операцией минимум,
хотя хоть она и коммутативна.
Но на самом деле...
Ну, вот.
Она, конечно, коммутативна, но она так немножко полукоммутативна
с нашей точки зрения.
Что я имею в виду?
Потому что заметим, что прибавить к элементу что-то,
если мы ищем минимум на подотрезке,
то мы не можем.
Вот, потому что если мы там к какому-то элементу прибавили 5,
то на всех подотрезках, в которых он лежит,
минимум на 5 увеличиваться не обязан.
Логично, да?
Вот.
Значит, мы теперь будем работать так.
Значит, выясняется, что раз у нас F и G так красиво симметрично устроены,
так давайте-ка хранить два массива.
Мы будем хранить массив ТФ.
Ну, это было то же, что было раньше.
А также будем хранить массив ТЖ.
Вот.
Ладно, на поверхную я вам даже больше скажу.
Тут написана такая интерпретация,
но в реальности мы ТЖ от нуля хранить даже не будем,
оно нам не понадобится никогда.
У нас просто Ж от нуля толком не определено, правда, поэтому...
Ж от нуля определено.
Ж от нуля? Нет.
А, сейчас.
Тут написано, что до определим,
но это скорее под хак.
А, да.
То есть, на самом деле, это разный способ навести марафет.
Хотя, может быть, правильнее было бы сказать,
что давайте Ж от нуля не определим и будем следить за тем,
что мы Ж от нуля никогда вызывать не будем.
Вот.
Значит, смотрите.
Значит, что же...
Ну, будем говорить, что каждая такая структура будет хранить себе минимум,
ну или там, мистическую операцию ИТЬ
от полуинтервала LR.
Ну, полуинтервал, он либо F от RR,
либо L Ж от L, соответственно.
Вот.
Тут мы говорим, да, говорим, минимум, подразумеваем ИТЬ.
Вот.
Решали когда-нибудь задачу R ИТЬКУ?
Нет.
Ассоциативную?
Конечно.
Да-да-да. Такая задача.
Ассоциативная ИТЬКУ.
ИТЬКУ.
Ой, можно это как-то быстро произносить?
ИТЬКУ.
РИТЬКУ.
Пойдемте-ка.
Пойдемте-ка ИТЬКУ попьем.
Так.
Ну да, наверное как-то так.
Не важно.
РИТЬКУ объелись просто.
Верните, пожалуйста, на секунду.
Пожалуйста, пожалуйста.
О господи.
Ну хорошо.
Ну как вы догадываетесь, презентация у вас естественно будет.
Так у нас в итоге произведение матрицы лимитировано?
Ааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааа
там уйтят и уйтят или там уйтят их сыгрок-то, я не знаю
да знаете, чтоб лишний раз подчеркнуть, что как бы это алгебра, тут как бы сами по себе буквы значений не имеют
можно там этот твердый знак там можно еще написать
вот
итак
значит, смотрите
значит, для того, чтобы чуть-чуть-то работать вот с этим деревом
ну понятно, что надо как-то значит с помощью этих штук находить нам себе
как-то там все-таки суммы там или там эти на полуинтервале LR
в чем на это распроизвольном, а не том, что там хранится
а также еще нужно если там и-то элемент поменялся
то надо, наверно, пробежаться по всем отрезкам здесь и по всем отрезкам здесь
и на самом деле суммы поменять
вот
для этого мы заметим кое-что
значит, ну давайте скажем, да
то есть назовем полуинтервал LR интересным, будь здоров
если этот полуинтервал у нас тут где-то лежит
то есть если этот полуинтервал у нас встречается в дереве
вот
значит, но мистический факт
интересный полуинтервал содержит в себе ровно 2 в степени k для некоторого целого k идущих подряд чисел
но более мистическое свойство заключается в том, что, оказывается, эти числа отличаются только в младших k двоичных битах
вот, да, тут вот
так что такая вот красота
ну вот, отсюда, на самом деле, следует уже такая более нетривиальная, но очень важная для нас лемма
что рассмотрим два интересных полуинтервала
тогда эти полуинтервалы либо не пересекаются, либо один из них вложен другой
но на самом деле, да
знаете, мы сейчас сделаем даже по-другому
для Жени правда, что они различаются только меньшим видом?
ну если мы же от нуля определяем, то, конечно, неправда
не-не-не, бюджет от нуля
почему?
число вида, например, было 110 в двоичной, а стало 1000
у нас в степени k это типа k равно 2, но отличаются они в 3-4 младших
ну k почему? в данном случае k будет просто
сколько там?
просто k будет 1
разность у них это 2, но отличаются они в 4-4 младших
да, они будут отличаться еще в тех видах, в которых у нас была такая цепочка единиц
а насколько это длинно?
у них префикс совпадать должен
да, но это префикс не длинный, без х младших
он может быть вот так
что-что-что-что
мы замеляем единицы
ты меняешь только правую часть
нет, ну давайте, так, сейчас, смотрите, давайте посмотрим
так, если число и равно 110
то, смотрите, f от и
g от и
сейчас, и то и то
f от и равно 1,00
и получается хороший полуинтервал f от и
он содержит в себе числа 1,00 и что-то в конце
с f от и понятно
вот, теперь g от и
g от и
это 1000
значит, тогда полуинтервал и g от и
тогда я утверждаю, что он равен чему
так как 1000-то в этом полуинтервале не содержится, напоминаю
а и содержится
поэтому получается, что тут содержится числа вполне себе
1,1 и последний бит
какой угодно
а какого туждения левому 1,9?
а
а
младших
справа
а содержит в себе
равно
ну точно тогда
ладно, утверждение верну, но не точно
хорошо
хотя
не, ладно, вроде нормально
нет, нет, правильно
то есть у нас само же от и в него не включается
не включается, да
это важно
но на самом деле тут есть
может быть еще более красиво
давайте возьмем доску
и нарисуем
как эти полуинтервалы вообще устроены
вот полуинтервалы
которые берутся из f от и
я буду рисовать с зеленым
а полуинтервалы из g от и
я буду рисовать красным
отставим
вот
значит смотрите
так нет, это мы тоже уберем
ну давайте
представим себе
что n у нас равно
ну я не знаю, 16
значит смотрите
так ну
начнем с того, в каких случаях h от и
будет равно 1?
для чего?
для ничего
для нечетных
и только для них
поэтому рисуем
так
сейчас я попробую тут узенько
нарисовать
0,1
но как вы смотрите
f от и от единицы равно 0
g от единицы равно 2
так это мы убираем
и нарисуем
1,2
вот
дальше идет полуинтервал
2,3
ну потому что f от 3 равно 2
дальше получается
3,4
вот это я просто рисую
все полуинтервалы
для всех u у которых h от и
равно 1
то есть они так красиво
их красиво так подряд можно нарисовать
вот
так
для ускорения процесса
ну как
ну я так скажу
все таки
я рисую такой минимальный тест
который нарисовать с одной стороны можно
но с другой стороны чтобы он был максимально нагляден
в подобных случаях бывает
помните фурятери, что мы тоже рисовали
я до сих пор помню как вы
рисовали и я уснул где-то между
проснулся и вы все еще его
рисовали
спойлеры
я все сразу
спойлеры
что сразу спойлеры
кому-то я рассказывал дерево в олимпиадной школе в чем проблема
не волнуйтесь
это все будет еще
конкретные примеры я конечно не обещаю
сэмпл
на всю доску
я каждый раз его вспоминаю
видишь как полезно
так ну вот
так
нет
он хороший
есть о чем пожалеть
так вот
если правильно хорошо понять алгоритм
то он красивый
идем дальше
это было ашаты равно 1
а как устроены числа у которых ашаты равно 2
нечетные поделенные на 2
наоборот
нечетные поделенные
это не целое что ли
нечетные умноженные на 2
нет
нечетные деленные на 2
это называется полу целое
вот
ну поехали
делится на 2 но не на 4
тут я нарисую
в таком виде
нечетные
не квадратичные
это новые не квадратичные вычеты
не квадратичные вычеты
ну а что такое
не квадратичные вычеты
действительно что-то новое
не важно
как бы ладно
мы быстренько рисуем конечно
там есть 12
что там дальше
14
что да
догадывайтесь что будет дальше
ну дальше мы будем рисовать
а если ашаты равно 4
делится на 4 но не делится на 2
это как?
точнее не весна
делится на 4 но не делится на 2
так что тут происходит вообще
человек после этого передумывает
заходить по аудиторию
да-да-да осторожно что-то
так человек же математикой может перестать заниматься
от шока вообще
не было
так вот
4 8 8 12
так ну вот
дальше я тут уже рисовал
ну и до кучи еще вот это
так ну что
ничего не вспоминает
да
мало кто знает
но встречное дерево федвика
это просто практически в явном виде
они буквально те же отрезки
просто
в двух массивах и в другом порядке
а так суть
вообще одна
ну как
бесполезно
хотя
это практически идентична операциям снизу
в дереве отрезков
ну а
а что бы нет
но если там
для двумерности операция по-любому должна быть коммутативной
но тогда вы как бы не сможете
брать квадратные блоки
так что коммутативность по-любому вам понадобится
минимум вы там найдете
а вот там произведение матрицы
уже не гарантирует
но соответственно
из такой картинки уже наглядно видно
что полуинтервалы либо не пересекаются
либо ложены друг в друга
это прям вот максимально наглядно
но отсюда следует маленькое
приятное такое техническое утверждение
я
она говорит что если у нас l меньше
чем r то тогда у нас
оказывается что
или g от l меньше либо равно
или l меньше либо равно
f от r
то есть если у нас есть какой-то lr
то не может быть так что f от r скокнется
и
g от l скокнется
то есть как видите такого не
бывает
если поверить
в эту лему
то в результате
оказывается вот таким вот простым
образом на самом деле можно найти
соответственно
нечто там произведение
матриц оно же там или минимум
на полуинтервале lr
ну
не совсем
о вот вы заказывали шаблон
да вот он пожалуйста
так
то есть
то есть
почему
почему
а потому что если
это не так вот пусть для каких-то lr
это не так
тогда у вас получается что вот есть
lg от l а есть rf от r
получается что отрезки пересекаются у нас такого
не бывает
так что вот и все
что там
лучше убирать
а то понимаешь чем проблема
то есть ты садишься на первую парту
смотри делать что-то постороннее
чем больше делаешь тем больше улектра возникает соблазн
сделать тебе точечный массаж
лица понимаешь
а вот
так вот
как же нам это считать
то есть оказывается
это очень удобно то есть как найти сумму
на lr если это полуинтервал конечно
вот так
ну на самом деле ладно код написан неправильно
хорошо
вот
ладно если мы верим что
g от 0 равно 1 то конечно можно и так
но на самом деле можно и без этого
если тут писать про if что
если f от
index right больше либо равен index left
тогда берем вот это иначе вот это
понятно что тут написано в принципе
почему у нас
else на другой строчке
а
а надо типа на той же
ну не знаю
я что-то так пишу
в прочем не суть
вот
технология понятно
ну
по большому счету да
она эквивалентная она конечно очень
похожа на то как искать там допустим
сумму там в дереве отрезков с помощью
там операции снизу
ну вот но как вот строим немножко по
другому
чего
различия чего
дерево отрезки снизу
и вот это вот стричь
глобально
в интерпретации скорее
потому что мы
через какие-то битвы операции это вот
по другому делаем
другой взгляд хотя храним
да буквально то же самое
деревья отрезков мы как бы эти отрезки
по другому храним и по другому ищем
ну на самом деле да
а очень просто значит
смотрите ну давайте нарисую картинку
значит смотрите то есть
нет вот то есть
происходит это примерно следующим образом
в идеале по крайней мере
вот у нас есть элер да
господи что у нас
только красный зеленый маркер
вот у нас есть элер какой-то
значит идея очень простая
значит мы
значит мы говорим так
то есть мы идем
то есть некоторое время
мы поделим этот полуинтервал
вот тут где вот это вот равно f от r
потом идем там
f от f от r
ну вот можно так
вот берем вот эти все полуинтервалы
и насчитываем
получается произведение на
в суферсе
вот обратите внимание да когда мы тут это делаем
нам принципиально с какой стороны домножать
кстати помните да у нас нет
комбатативности поэтому здесь это принципиально
но в какой-то момент
неожиданно выяснилось что f от
f от f но если мы просто упёрлись
в l то кайф мы победили
но если выяснилось что мы как бы
следующие тут у нас
где-то дальше идет
то теперь мы
делаем немножко другое мы от l
теперь идем
и идем значит у нас тут получается
g от l
там g от g от l
и соответственно опах
ну вот и в какой-то момент мы упираемся
собственно вот в эту вот границу почему
мы в нее упираемся
потому что у нас есть вот этот вот мистически
большой полуинтервал
внутри которого l находится
и g от l
и все эти g от l
перескочить через эту штуку
не могут ну потому что если какая-то перескочится
значит будут пересекающиеся полуинтервал у нас такого
не бывает
получается вот мы тут что-то
на суффиксе нашли на префиксе нашли
остается их только перемножить
ну и на этом все
с вами были подписывайтесь
ставьте лайки и вот
соответственно
вот больше тут ничего не будет все
понятно
сейчас все будет
ой тут аж презентация от этого
вылетает
презентация этого не знает
замечательно
так
последние леммы это простые
они на тему того что find product
работает за логарифом
или на самом деле вот даже вот
за логарифом
подотреска
но презентации у нас
в этой презентации
этого нет
но у нас есть вторая
презентация
давным-давно этот
этот предмет назывался объектно-ориентированное
программирование
а в первом семе это называлось введение
в программирование
алгоритмы структуры данных вы бы изучали только на втором курсе
да ну не совсем
по моему зачет вы будете получать под именем практику
по программированию
нет вам сейчас все нормально
потому что как бы практика по алгоритмам потом
там
а ну да хотя отдельно
доброе утро
давайте напомним раз об этом
раз возить вопрос
отценки две нет
отценки будут две
но предупреждаю в этом семестре
если PC бонусов нет
вот
отлично
потому что зачет вы получаете за практику
а экзамен за теорию
не знаю
видимо их кафедра
решила так а наша кафедра решила так
и вот так
ну отчасти
отчасти тоже кстати
исторически вещь такая
исторически складывалось что мы в этом предмете должны были
C++ как-то на семинарах изучать
презентация осталось все времена когда так и было
но нет это не совсем то
сейчас у вас
как бы тут
в результате
на самом деле тут огромная заслуга собственно
на самом деле только недавно
стало что C++ стал отдельным предметом
с отдельными зачетами
то есть вы по моему едва не первое поколение у которых там зачеты
по C++ за счет по алгоритмам не пересекаются
от слова никак
просто а так мы по моему едва не в прошлом
ваши предшествия
просто нынешние второкуры возможно получали
одну оценку за C++ алгоритмы как-то там
пополам я уж не помню мы там как-то
с межирием договаривались
так что знаете
так что
так что на самом деле тут
да правда
то есть на самом деле в этом смысле
организация учебного процесса
вот
а в этом
вот
но почему это как устроено у нас на кафедре
как устроено на кафедре высшей математики я не знаю
но правда я знаю только что кафедра высшей математики
там она история
насчитывает уже там много десятилетий
ну вот поэтому там
поэтому почему у них там собственно
там отдельный зачет по мотану
за DZ по мотану не ставят этого я честно говоря
не знаю
вот
и это при том что
по традиции вы же там по мотану
еще помнится два экзамена сдаете
ну письменный и устный да
логично
ну да
ну как бы да
не ну там
все равно оговорка что там за устный
что там за устный вы скорее всего
чтобы результат за устный вы вряд ли там
получите выше чем то что получили за письменный
да
ну плюс минус один плюс один какой
это письмак 16 из 30
за устный 10
ну примерно так
у нас примерно всего потока
что то подобное
письменный экзамен глина а устный экзамен идея
ну да
не ну просто скажешь не ну просто странно
ну не знаю не ну значит все меняется
в первом семе мне так сказали что как бы да
что там на устном экзамене еще нет уровень ваших ответов
там называется там
на голову выше там многих ваших коллег
но называется уровень вашего
письменного экзамена выше хора поставить не позволяет
ну вот
ну да ну вот
у меня в первом семе это не получилось
во втором пробить удалось да
но там как бы
но там повезло я собственно лектору отвечал
но там как бы там
другая ситуация была там еще удалось
сапелировать на том что там сказали что
там
сейчас как там был
история про синус
а ну
не про синус это на дифурах было
вот нет там была другая история
там была история о том что некоторые решения
были зарублены потому что там ожидалось
что надо это делать каким-то вот фиксированным
заданным методом который там
ну вот а я делал видимо каким-то другим
вот ну как бы
ну я как бы
что значит
где было написано что я обязан решать
ровно этим методом и никаким кроме
вот
то есть ну как бы просто предупреждать надо
просто таких вещах что это такое
на эту тему беден вот поэтому там
сапелировать удалось вот
так вот
идем дальше
напоминать да давным-давно
это вообще были старые времена когда лекция
была одна
а семинаров было два и они были в другое время
иногда даже в другой день
они как у нас вот собственно
три пары подряд и собственно вот
то есть не надо ничего напоминать
не надо ничего напоминать
так вот
так но вот это уже всё понятно
мы вообще обсудили обсудили
обсудили obs Idaho
так вот
значит смотрите
интересные интервалы
итак значит задача надо
изменить значения в ди
jesteśmy по интервалу у нас индекс содержат
вопрос только как это делать
ну вот
Ну давайте для начала уже хотя бы простой притат в ТФ,
вопрос, как эти интересные полуинтервалы хотя бы найти?
Как их хотя бы найти?
Вот. Ну как бы в ТФ, как их искать, мы уже знаем.
А вот как их искать в ТЖ, это уже вопрос.
Вот.
Вот.
Но на самом деле, оказывается, можно прописать просто примерно
какой-нибудь такой анализ, который был уже ранее.
Значит, смотрите.
Мы хотим найти в массиве ТЖ все интересные полуинтервалы.
То есть полуинтервалы, которые...
Да.
То есть дано число индекс, я хочу найти все такие условно И,
что и меньше либо равно индекс, и строго меньше, чем g от k.
Ну без этого как-то наша жизнь легко приятной явно не будет.
А можно просто все пропуски из ТФ заполнить в ТЖ?
Что такое пропуск из ТФ?
Вот у нас в ТФ есть отрезки размера 1 и 4.
Обрезок размера 2 точно из ТЖ.
Ну...
Ну главное, его там правильно находить.
Нет, ну в принципе можно, но давайте все равно вот.
Но давайте, смотри, тут по-разному можно.
Давайте тут разные подходы уже посмотрим.
Значит такой более старый подход.
Давайте честно вот посмотрим.
Как-то вот жил-был число индекс.
Вот.
Там 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1.
Вот.
1, 0, 0, 1, 0.
Вот.
И тут мы говорим, так.
Значит нам нужно, чтобы у нас было число И, которое меньше либо равно,
и нужно число g от i, которое строго больше.
Так, ну давайте думать.
Что значит g, а ты строго больше?
Значит g, а ты должно быть устроено как?
До какого-то момента у нас копипаста, копипаста, копипаста, копипаста.
Копипаста, копипаста.
А потом в какой-то момент неожиданно 0 заменился на единичку.
Вот.
Так.
Вот.
Может быть здесь?
Но нет.
Ну причина очень простая.
Потому что, значит, если тут g, а ты здесь, и чтобы i было меньше либо равно,
нам придется, чтобы i было здесь равно 0.
Но для того, чтобы i было тут равно 0,
нужно, чтобы тут хотя бы одна единичка добыла.
Тут же должен быть блок из единичек, правильно?
Но если тут стоит 0, тогда это число i будет больше индекса.
Ой-ой.
Вывод.
Значит, получается, вот эта единичка должна стоять.
Вот.
Ну получается, где она должна стоять?
Ну да.
Действительно, где-то в конце блока нулей перед какой-то единичкой получается.
Вот.
Да, соответственно.
Значит, ну тогда тут получается действительно все аккуратненько.
Тут получается 1, 1, 1, 0, 0, 1, 0.
Ну а тут автоматически получается зачистка.
Естественно.
Вот.
А что такое?
Да.
Ну правда...
Ну вот.
Чего?
Ну давайте, да.
Тут должен стоять 0.
Хорошо.
Да, там должен быть отрезок единицы, а потом все 0.
Да.
Ну а теперь давайте думать, сколько тут единиц может быть?
Ну больше, чем вот этого не будет?
Да.
С одной стороны, заметим, что любое количество единиц здесь нас, в принципе, вполне устроит.
Да, да.
Вот это нас тоже устроит.
Так.
Ну тогда получается.
Получается, что у нас тогда получается.
Ну вот.
Ну опять же.
Если вот опять взять, вот дорисовать, просто взять какой-то индекс и нарисовать
все числа, которые нам подходят, начиная с самого индекса, да, то мистическим
образом окажется, что, по большому счету, это как бы любое подходящее число, это
число индекс, у которого взяли несколько единичных битов младших и их все занулили.
Но там все-таки не остались все.
Нет, тут как СФ.
Ф, который уменьшает.
Да.
Ф это индекс минус х от индекса.
Х от индекса.
Ну Ф это, которое обнуляет младший единичный бит.
А-а-а.
Ну да.
То есть, обратите, то есть, действительно, как вы только что доказали, получается
И это такой индекс, у которого обнулили какое-то число единичных бит младших.
И легко убедиться, что любое такое число нам подойдет.
Поэтому получается, что, видите, то есть G и F, они такие вот, действительно, напарники.
То есть, получается, у F, значит, интересный интервал ищется с помощью G и уже интересный
интервал ищется с помощью F.
Вот, понятно, да?
Так, дальше, оказывается, достаточно удобно.
То есть, в результате, вот.
То есть, на самом деле, код можно написать примерно вот таким вот образом.
Вот.
Вот.
Но, правда, за кое-чем точку это будет работать?
Да.
А тут мы уже пользуемся квадративностью?
Нет.
Нет, зачем?
Нет, здесь заметим, что в такая функция все, что делает, это перебирает интересные
полуинтервалы и для каждого из них находит, как бы, новое произведение честно.
Это лог квадрат?
Лог квадрат?
Да, это лог квадрат, да.
А мы знаем, что вот это, когда мы, мы же сейчас по ходу изменяем дело, и во время
его еще вызываем...
Да, да, вот есть такой психологический момент, но никаких, но это ничего страшного
в этом нет, вот почему.
Дело в том, что мы find product вызываем от полуинтервалов, которые вот этот
изменяемый элемент не содержит.
Поэтому мы лезем только в полуинтервале, который индекс не содержит, поэтому
ничего страшного.
Вот.
Так что вот такой вот...
Мы не можем что-то подоптимизировать, вот сюда то, что у нас не за алгоритм,
а не за алгоритм, а за алгоритм.
Да.
Ну, как же, конечно, можем.
Еще как можем.
Вот.
Вот.
Не надо, конечно, так писать.
Ну, идея кода на самом деле базируется вот на чем.
Да.
Так, да, что тут написано, в общем.
Так.
Как это еще, я не понял.
Ой, все в этом...
А на самом деле, просто идея базируется в следующем, что если рассмотреть
последовательность полуинтервалов, вот, допустим, вот этих красивых
полуинтервалов на f-очке, то на самом деле можно заметить маленькую
приятную вещь, что каждый следующий полуинтервал, то есть каждый
предыдущий полуинтервал вложен в следующий, правда?
Поэтому на самом деле...
Так, что происходит?
Поэтому на самом деле оказывается, что можно на самом деле
эти произведения на всех таких вот такого рода последовательности
полуинтервалов насчитывать не за лог квадрат, а за логарифом
с помощью очень простой технологии.
Ну, самый первый полуинтервал, это тут какой-нибудь типа
индекс, индекс плюс один, ну или там индекс минус один,
индекс, я уж не знаю, неважно.
Вот.
Но теперь заметим следующее.
Что...
Ну вот.
Значит, как теперь найти сумму на этом полуинтервале?
Ну заметим, что надо просто скакать f-очками вот сюда.
То есть заметим, так как вот этот хороший полуинтервал
вложен вот в этот, да?
То есть это вот какой-то хороший полуинтервал, то
оказывается, что если вы будете из этой позиции
скакать f-очками, то вы ровно вот сюда и придете в какой-то момент.
Еще из-за малалаш A BC.
Да, ну мимо не проскочите.
Ну пока главное, что мимо не проскочите.
Ну да, суммарно будет логорифм, потому что дальше вы от этой
границы потом тоже будете двигаться f-очками вот сюда,
на этих шагов, в принципе, логарифм будет. Потому что если проскочите мимо, то у вас будут два
пересекающихся хороших полуинтервалов, которые либо от f от и до и, либо от и до g от и. Мы уже
выяснили, что они либо любые два интервала, либо не пересекаются вообще, либо один выложим
другой. То есть вот классического вот этого пересечения нет. Ну да, пока рассматриваем
только полуинтервалы f. Сейчас, но у нас уже каждый раз будет либо увеличение f на 1,
либо g на 1. Но это это уже более глубоко. Мы пока этого не замечаем. Мы пока замечаем,
что каждый следующий, каждый предыдущий вложен в следующий. Вот, и тогда получается,
что тут левую границу, то есть как бы что делать, если у вас есть сумма на полуинтервале, и надо
вот расширить полуинтервал, но тогда левую границу значит добиваем f, правую границу добиваем
g. Вот, ну и оказывается, что суммарное количество шагов и влево, и вправо у вас будет, оказывается,
от логарифма, ну потому что сколько вы можете с g скакать, чтобы выйти за n или сколько скакать
f, чтобы прийти в ноль. Вот, то есть вот такая, то есть вот таким вот образом можно, то есть
можно вот даже на эту на эту тему вот такой код экзотический написать.
Или нет. Да, но этого делать не надо, конечно. Или надо. Ну да, тут, конечно, да, такая вселенная,
у кого-то там это просто вселенская грузь, конечно, такая от этого кода. Зачем вообще такое писать? Ну
да, потому что действительно, на самом деле, конечно, такое писать, если вспомнить дерево
отрезков, то такого писать не надо. Нет, не в смысле, что надо вместо этого написать дерево отрезков,
конечно. Вот, но на самом деле, конечно, и конкретно Фенрики, да, ну тут просто старая презентация,
там просто, знаете, ой, как бы наука в голове автора с тех пор, конечно, немножко развилась.
Так что да, нет, кофейпаст не надо, потому что на самом деле мысль простая, то есть на самом деле
вместо того, чтобы рассматривать ТФТЖ, можно рассматривать все интервалы подряд, потому что
заметим, что нам нужно, как мы помним из картинки с деревом отрезков, что у нас есть какой-то
исходный полуинтервал, ну а дальше у нас есть там бывает следующий полуинтервал, потом следующий
полуинтервал, потом еще следующий полуинтервал и так далее. То есть у нас точно все вот полуинтервалы
длины 1, длины 2, длины 4, длины 8 и так далее. И более того, можно заметить, что каждый следующий,
на самом деле, получается из предыдущего путем домножения слева или справа на один не меняющийся
полуинтервал. Вот видите, да? Да, тут не совсем такая картинка, но суть на самом деле такая,
просто идея такая, что исходно у нас есть полуинтервал, ну какой-нибудь там допустим,
равен он, понятно, индекс и индекс плюс один. И теперь думаем, так есть полуинтервал длины 2,
который его содержит. Но как его найти? Ну найти его очень просто. Тут возникает вопрос,
этот полуинтервал, он как бы из f или от z? Вот, но если он, ну проверить очень легко просто там,
верно ли, что вот эта штука равна f от этой штуки? Понимаете, да? Кстати, интересно,
а вот можно сразу заметить, что вот есть такая система уравнений f от l равно r, g от r равно l.
Спрашивается, есть ли у этой системы решение? Кто пустой? Я не типа, да? Заметим, что, не, ну как
сказать, l равно r быть не может у нас? Ну разве что, да. Но если предположить, что g от 0 все-таки не
определено, потому что оно в дереве отрезков не вписывается, то на самом деле оказывается,
что таких решений нет. Раз решений у этой системы нет, значит, если у нас есть интересный
полуинтервал, то мы можем легко понять, он из g или от f однозначно. То есть просто проверить,
верно ли, что l равно f от r, да или нет? Если да, то он из f, если нет, то значит он из g. Но если он из
f, то значит, у него слева есть вот такой напарник, и их объединение дает какой-то отрезок. Правда,
непонятно, он из f или из g, но уж, по крайней мере, сумму на нем вы найти можете легко. Понимаете,
да? На этот раз да. Ну да, ну по крайней мере код будет, ну код ладно, может не будем писать код,
но конечно код будет сильно проще, чем вот это. Ну ладно, не сильно. Хотя... Один вопрос, зачем
это писать? Ну, я подозреваю, что это работает примерно за ту же скорость. Ну может быть,
вот это чуть быстрее, а может и нет. Хотя пишется-то примерно за столько же, да. Только там вам придется
с индексами пошаманить. Нет, ну мы понимаем, кто у нас родители, мы не теряем на левой и правой,
поэтому нам гораздо меньше. Не, ну там код на самом деле нет, ну давайте попробуем, кстати. Так,
что там у нас с кодом-то, так. Ох.
Так, ну ладно, напишем так. Ну и всем смотрите. Так, ладно, вот, кстати, альтернативная версия
фенвика, ну ладно. То есть, на самом деле, такой встречный фенвик может выглядеть примерно
следующим образом. Так, как вы там писали, t-matrix, да. Ну вот, ну допустим, так, как у меня там написано
было, uint32r. Ну и допустим, что lr это полуинтервал. Я так напишу. Тот же самый find product,
только попроще. Ну, который был вот, вот этот вот. Вот, на самом деле, его можно писать сильно
проще. А, хотя нет, подождите, какой find product? Ой боже, и все, я с ума сошел. Да, assign. Да,
то есть, на самом деле, да, t-matrix atu key и там, соответственно, uint32index. Значит, смотрите.
Значит, пишем так, uint32l равно изначально индекс. Вот, uint32r равно индекс плюс 1.
Ну и, конечно, t-matrix current product равно, соответственно, пока ключ. Вот, понятно? Значит,
ну и дальше будем говорить. While, ну допустим, r меньше либо равно n. Ну ладно, там в каком-то
локальном n, конечно, мы же там. Значит, дальше тут два случая. То есть, мы находимся в полуинтервале,
на котором у нас есть сумма, которая равна, то есть произведение, которое равно current product.
Мы его хотим, во-первых, значит, записать, куда надо, а во-вторых, там, проапдейтить отрезок.
Делать мы это будем так. То есть, во-первых, то есть, надо рассмотреть два случая. Если оказалось,
что f of r равно l, даже лучше по-другому будет писать, l равно f of r, то тогда идея очевидна. Тогда мы
пишем, что tf of r равно, соответственно, current product. Так, но заметьте, тогда у нас есть вот этот
отрезок tf of r, в котором мы пишем current product, а напарник его находится в tg of r, очевидно.
Поэтому пишем, что current product равно current product,
product умножить нас, соответственно, tg of r. Ну вот, ну и типа того. Хотя ладно,
тут лучше, конечно, написать, если r равно n, то, наверное, мы брякаемся.
Вот, и дальше, соответственно, r равно g of t. Вот, соответственно, в противном случае,
что мы делаем? В противном случае, значит, у нас напарник слева. То есть, наоборот, пишем,
tg of l равно current product. Ну вот, но l у нас, конечно, заведомо больше нуля, поэтому тут уже без всяких
ифов. То есть, теперь внимание, current product равно, соответственно, внимание, тут мы, наоборот,
пишем tf of l умножить. То есть, видите, напоминаю, у нас нет коммутативности, поэтому нам принципиально.
И l равно f of l. Ладно, тут нижнее подчеркиваем. А, и мы все, в общем-то. То есть, вот на самом деле,
код можно написать вот таким нехитрым образом. Но это уже сопоставимо, по-моему, по сложности,
с дерева снизу. Вот. Так что вот такой вот красота, на самом деле. Так что да. Ну,
можете вот так написать, конечно. Но после вот этого, мне кажется, не нужно. А, смотрите,
я знаю, что надо делать. Ну а вы думаете, те слайды как-то принципиально по-другому делались?
Были надежды на это. Правда, ой, что-то, что-то, шрифт какой-то подслеповатый. Ну ладно, так тоже
пойдет. Ну ладно. Так вот. Ну что ж. Ну как теперь в таком виде кода уже действительно
легко понять, что действительно тут все работает за логорифом, причем так железобетонно и надежно.
Вот. Так что получается массив А мы при этом не храним. Кстати, обратите внимание, мы храним
просто чисто два массива. Да, ну суммарно по памяти это буквально идентично дереву отрезков.
Ну вот. Ну и нормально. Так, ну что, есть ли тут какие-то вопросы? Так, ну просто у меня
есть ощущение, что пришло время перерыва. Нет, почему-то общее предупреждение. Задачи в кубке
ФТИ по сложности отсортированы, обязаны быть не. Там часто получается так, что они примерно по сложности отсортированы,
но бывает что-нибудь в последних халеаптоваях. Нет, давайте в белом, то это в последние две по-другому.
Но есть утверждение, что в предпоследние две по-другому. По крайней мере. Честно, я возможно не придумал
в последние две по-другому. Вот, значит, поехали дальше. Так, сейчас у нас будет немножко такой приятности,
потому что мы изучили, как работает дерево Фенлика, искреченное дерево Фенлика, но возможно в
будущем мы почти не будем пользоваться, теперь смотреть, как оно устроено. Нет, хотя нет, но для того, чтобы изучить дерево Фенлика,
дерево Фенлика, нам, конечно, потребуется изучить, как оно устроено. Нет, тут, нет, нам потребуется. Нет, там даже не для профов, там,
что, извините, в каждой ячейке дерева Фенлика вам придется хранить дерево Фенлика. Так что для этого придется
понимать, как устроено дерево Фенлика. Я имею в виду следующее. Вот сейчас мы перейдем к следующей задаче. Сейчас мы будем делать прибавление на отрезки.
Да, сейчас мы забываем о препарации. Мы слов вспоминаем, что у нас есть классическое сложение, и мы хотим искать сумму на отрезке и прибавлять теперь на отрезки. Вот такая у нас мечта.
Вот. Но мы будем не просто мечтать, но и воплощать мечты. Да, все это мы будем делать с помощью дерева Фенлика.
Да. Значит, смотри. Начнем мы вот с чего. Ну, давайте, да. Конечно, важную роль у нас в игре будет, будет, конечно, у дерева Фенлика, у дерева Нот, у префиксных сумм.
Естественно. Вот. Ну вот, но начнем, начать можно даже не с этой задачи. Ну да, потому что префиксные суммы возникают где? Ну, допустим, если нам не надо было бы обновлять массив вообще, а нужно было бы изменять только, только искать там, скажем, сумму на подотреске, да, статической массиве, то с помощью префиксных сумм мы бы сделали легко, да, там, вот, при подсчета, вот, единицы, там, ответа на любой запрос. Верно, да?
Или нет? Вот. Вот.
Но, оказывается, значит, давайте сейчас попробуем себе упростить задачу. Представим, вот мы с помощью обычного дерева Фенлика научились изменять один элемент и искать сумму на подотреске. Было дело?
Было.
Было.
А теперь, смотрите, сейчас мы неожиданно себе, скажем так, смотрите, теперь давайте себе представим, что мы хотим прибавлять на подотреске.
И все.
Ну можно ничего не делать, запросов никаких нет?
Ну конечно, да.
Ну а чтобы, конечно, избежать метода УГУ, мы скажем, что, знаете, такая классическая постановка задачи, у нас будет куча запросов, типа, на прибавляй на подотреске, на прибавляй на подотреске, вот, а потом скажите в конце, что получилось.
Ну да.
Ну вот.
Ну и здесь просто важно, да, пока деревья Фенлика для этой задачи не надо, но здесь просто очень важно, действительно, причеркнуть этот метод.
Значит, смотрите, как у нас, значит, делается очень просто. Допустим, у нас есть мотив А, который равен?
Устроим разность приносить.
Да, ну обязательно, да, вот.
Но это просто обязательно надо обсудить.
Что? Кто шарит? Куда шарит?
Шарит ПТР.
А, ПТР шарит.
Ну да.
Так.
ПТР шарит, да.
Это да.
Да, ну вот.
Значит, идея такая.
Значит, мысль может возникнуть такая.
Так, вот, допустим, мы тут решили что-то поприбавлять.
Вот к этому подотреску мы решили прибавить плюс 57.
Если делать это в массиве А,
Ну почему 57?
А какие еще числа мы прибавляем вообще?
Вот.
Реально других титулов нет.
Летово.
Ну нет, есть 179, конечно.
Есть нет.
Летово это не число.
Почему?
Нет, летово и фото летово, и прочее.
Фоксфорды мы будем использовать.
Ну вот.
Извините, я не хотел обидеть выпускников Фоксфорда. Извините.
Ха-ха-ха.
Кирилл, а что пока снялся?
Ну да.
Ну, как-то я думал, можно, да, давайте.
Нет, что, можно, можно с энергию вставить.
У летовцев вены полопались просто.
У кого?
У летовцев в этой аудитории полопались вены от напряжения.
Знаете, Катя не похожа на человека, который полопался веном.
Катя из летового?
Точно нет.
Вот, значит, смотрите.
Значит, да, пока мы тут обсуждали какие-то там школы,
значит, я тут нарисовал еще один массив.
Значит, смотрите, идея такая, давайте вместо массива A хранить частичные разности.
Да, претекстные разности, ладно, разности соседей.
Он просто так, вместо каждого элемента будет пройти разность этого элемента
и предыдущего.
Там изначально было хорошо, как будто ноль был.
Ну, кстати, Кир, что приятно?
Заметим, что, кстати, операция взять такие вот разности соседних
и операция найти префиксные суммы, это взаимообратная операция.
То есть, если я возьму префиксные суммы от этого массива,
я найду буквально массив A.
Вот, удобно, правда?
Но чем нам это приятно?
Приятно мы на этом обучим.
Если мы хотим теперь прибавить в массиве A57 на подотрезке,
то оказывается, что в случае рейна частичных разностей
тут становится все удобно,
потому что меняются только две разности.
Вот это и, соответственно, вот это.
Удобно, правда?
Невероятно.
Ну да, как говорили в одном мистическом шоу, поразительное,
не могу бы это поверить.
Теперь элемент, это просто взять сумму на префикс.
Ну да, то есть теперь,
да, во-первых, действительно,
если у вас просто надо сделать это,
потом в конце восстановить массив,
то как бы вы просто делаете все операции за УАД единицы
и потом по этим разностям восстанавливаете массив очень легко.
В целом, нам вообще коротко.
Вот, конкретно тут пока не нужно.
Ну а теперь следующая мысль.
Теперь давайте себе представим,
что мы теперь хотим в онлайне все-таки получать
не только прибавление на отрезки,
но и получать
элемент вот такой.
А кто там у тебя сейчас в позиции пост находится?
Ну это Фенрик тогда уже.
Вот.
Ну это получается мы забабакиваем просто дерево Фенрика,
ну или там, я не знаю, дерево отрезков
на массиве префиксных разностей.
Как их называть?
Хочется называть вообще частичные разности.
Ну давайте будем их называть частичные разности
или простоты.
Да.
Вот так.
Тогда получается, что get от pos
это всего лишь там просто сумма на префиксе
в массиве dA очень легко.
Вот.
Ну просто важный такой лайфхак.
Иногда там в Олимпиадах тоже помогает,
поэтому вот помнить полезно.
Ну и вообще.
Вот.
Но нам хочется, конечно, получать.
Нам хочется, конечно, и прибавлять на подотрезки
и искать сумму на подотрезки.
Или хотя бы сумму на префиксе.
Ну если мы научимся сумму на префиксе искать,
то, наверное, сумму на подотрезке мы тоже легко найдем.
Правда?
Так.
Итак.
Сумма на подотрезке.
Значит, для этого, ну там можно,
да, знаете, по-разному можно делать, знаете,
да, можно просто делать какую-то минимоническую операцию
и заметить, что они работают.
Вот.
Ну и сейчас убит.
Но мы будем делать так.
Итак, мы хотим найти сумму на префиксе.
Внимание.
Так.
Внимание.
Итак, мы хотим найти сумму на префиксе.
То есть сумму вот таких элементов.
Но, как вы уже сказали, нам их,
так, хранить не очень хочется,
поэтому мы пойдем в ДАЖ.
Ну, вот.
То есть, каждая алина я пока записываю вот там.
Что же я делаю дальше?
Замечаем, что
да, я замечаю, что действительно,
я перебираю ДАЖ иOK,
и которые я буду использовать,
Что действительно, я перебираю ДАшки от 0 до f и каждую из них просто суммирую какое-то количество раз.
То есть я могу вот так написать.
То есть я могу написать dAj умножить на... а сколько раз я суммирую dAjt?
R-j...
Ну посмотрите, этот элемент мы смотрим один раз.
R-1 два раза.
А R-2 получается три раза.
Ну и так далее.
Поэтому получается, когда мы дойдем до нуля, нам будет все-таки R-1 должен.
Вот.
Ну да, R-x это как раз R.
R-t элемент сколько?
У нас же первый элемент всегда наливает.
R-t элемент один.
Мы от нуля даем, видите, суммируем.
R-t элемент один раз, да, все.
Вот.
Не, ну как бы Д, да?
Значит, запишем теперь это по-другому.
Я могу это описать как R плюс один сумма дАжитых.
Да, и это очень приятно, потому что вот эту штуку мы уже с помощью обычного фенлика искать научились.
И теперь еще один маленький подлянка.
Ну почему?
Ну это элементарно.
Ну а теперь, да, вот такую сумму, конечно, из вот этого массива мы не посчитаете.
Заводим еще один.
Да-да, ну спокойно, давай.
Что ты так любишь спойлеры?
Спокойно.
Спойлеры?
Ну блин, баяны разбираем.
Ну не баян, а классик.
Скажем так, все, что рассказывается практически на всех предметах на самом деле в данном Узе,
или в любом-любом, является баянами.
Не все является настолько баянами.
Не знаю.
Смотря для кого.
Смотря для кого.
Ну, как сказать.
А потом на экзамене все это спрошу, ага.
Давай вот задание, допиши, да, допиши мне это, давай, трехмерного фенлика с прибавлением на попринянную пипель.
Я это один раз писал, и мне не понравилось.
Молодец.
Ну вот.
С прибавлением на попринянную пипель.
Ну все равно, дальше, да.
Тут все просто.
В конце концов, если вы уже так понял, что тут настолько все неинтересно,
можно в конце концов взять вот все вот это вот, пойти вот там в коридорчик,
там вот столик стоит с диванчиками, там автоматами, можно вот там для нас прекрасно порешать.
Дальше это все лучше, чем выпить.
Называйте.
Нет, ну на самом деле, нет, можно еще по-любому, ладно.
Ну поднимите руки, кто все это действительно и так знает.
Что конкретно?
Ну вот, вот это вот все, вот эту всю технологию с прибавлением на подотрезки с помощью дерева Федрика.
Ну давайте так.
Может я вас действительно все зря рассказываю?
Окей.
Нет.
Большинство все-таки не знает.
Так что, нет, увы.
Лом, самый умный.
Так что, нет.
Так что нет, да.
Не все так просто.
Ну вот.
Ну да.
Да, суммой заключает в том, что приехать ко мне в Лоши, я просто, я же это все и рассказывал.
При чем?
А, ну может и не я.
Не, без значения, я все и делаю.
А Локшай тоже рассказываю?
Это ведь те рассказывали?
О, слушай, вот это точно, ну типа младших параллелей.
Ух ты, зачем это?
Ух ты, а кто это Локшай рассказывал?
Это бесполезно, зачем он это знает?
Нет, Лоши будет на Ферме рассказывать.
Нет, ну нет, а Ферме, конечно, Лоши это я рассказываю, да, Локшай это кто рассказывал?
В Лоши я точно видел это где-то там, в третьей параллели может быть.
Нет, Лоша это понятно.
Это вот эта параллель.
Нет, вот третья параллель.
Это очень, очень элементная Лоша.
Ну это да.
Ну правда.
Испитива.
Нет, ну окей, окей.
Ну там, ладно.
Рассказывай, ну вот.
Ну не важно.
Нет, просто, нет, интересно, кто это параллель еще рассказывает.
Потому что Лоша там скорее всего просто рассказала, рассказала либо я, либо там, собственно, по моему же плану.
Или что-то в этом роде.
Вот.
Поэтому просто если Лоша рассказывает, кто это еще рассказывает.
Так, ну давайте так.
Вот вам-то кто рассказывал, кстати?
Это в основе.
В основе?
А, ну точно, Илья Степанов, да, так.
А, ну откуда он?
Не-не-не.
Не-не-не.
Ну я не знаю такого.
Именно Ильи Степанова, по-моему, называется вот этого в программе не было.
Это уже знали всех.
Мне не знали.
Ну я не знаю, я откуда-то не знал.
Я это узнал, потому что когда-то там прочитал подобное там просто в блоге Петро Митекчева на самом деле.
И то он, на самом деле, и то он выдал это, что как делать прибавление там на отрезку с помощью чатировок Фенлика.
Ну на самом деле нужно просто взять вот эти два Фенлика и сделать вот так.
Ну, собственно, очевидно, что это правда все.
Ну правда.
То есть у меня там были какие-то жуткие интерпретации, там жуткие доказательства, действительно, почему это так.
Но вот очень позже до меня дошло, что на самом деле это берется вот отсюда.
На самом деле это какие-то технологии.
Так, ну давайте разберемся, откуда это все берем.
Значит, смотрите дальше.
Так, значит, ноль, минус два, десять, значит, минус шесть.
Значит, что такое dAj, короче?
Ну вы уже догадываетесь, что по определению я просто скажу, что dAj, jt это будет просто равно j умножить на dAj.
То есть когда вы прибавляете 57 к третьему элементу, надо просто в dAj к третьему элементу прибавить 57 умножить на 3.
А если вы там из четыре, пять, шесть, семь, восьмого элемента вычитаете 57, то значит здесь надо вычесть 57 умножить на 8.
Ну, то есть у нас просто прибавление этой четыре эфирации изменения в точке, а...
Ну да, да, да.
То есть по факту, да, обратите внимание, то есть все, что вы делаете, вы просто храните двух фен...
Ну вот, то есть просто заводите два массива, там, таких, разности, разности, до множества, и, собственно, честно храните аккуратненьких фен-венчиков.
Как мы обновляем вот этот новый...
А мы это еще не прошли.
Прошли, прошли.
Как мы обновляем...
У нас есть дерево фен-венчика, которое умеет искать сумму на отрезке и обновлять в точке, да?
Ну, используем как черный ящик.
Да, мы заводим, то есть вместо массива A мы храним массив его частичных разностей, частичных разностей, да, множенных на индекс.
На обоих этих массивах мы честно заводим фен-венчиков.
Теперь, значит, когда мы ищем сумму...
Ну да, мы пользуемся вот этой формой, то есть находим там сумму на префиксе...
Когда ищем сумму на префиксе R, мы находим сумму на префиксе в одном, сумму на префиксе в другом, первую домножаем на R плюс один, вторую вычитаем, радуемся.
Но второй вопрос у нас, который есть, это прибавление на отрезке в исходном массиве A.
Как мы это делаем?
Ну, мы замечаем, что мы в массиве A не храним, а вместо R храним DA и DAG.
Но мы замечаем, что частичная разность, что при вот таком прибавлении только две частичные разности поменяются.
Почему?
Ну, потому что, смотрите, у нас бывает четыре типа партий соседних элементов.
Первый тип, расс untersеля dellом два по типам.
Ну да первый тип, те, которые слева от этого отрезка.
Два элемента не поменялись, разность не поменялась!
Есть два элемента, которые находятся после отрезка, но они не поменялись, разность не поменялась!
А вот дальше интерес.
Есть два, если эти два элемента находятся внутри отрезка, то оба увеличились на одно и то же число и разница опять не поменялась.
опять не поменялось.
Ааа, ну, сейчас.
Оба линейки
разности умножены
на джипа.
Не-не-не, погодите,
смотрите, вот этот вот массив
он порождается чисто вот этим, то есть я
джипа, это вот берем разность жито,
если разность не поменялась, то и разность умножена
на жито тоже не поменялась.
Нет, ну да, тут вот я...
Да, хорошо, да.
Да, тут надо...
Возможно, не надо
искать какой-то физический смысл у этого массива,
он просто порожден вот тем, что мы тут
посчитали, получилось.
Вот. Ну вот, так что получается,
вот эти два не поменялись,
и получается, то есть надо брать только две пары
соседних, которые один лежит
в отрезке, другой нет.
Вот этот берем, разница тут увеличивается,
а тут разность уменьшается, но это всего две точки.
Да, и ДА поменялась,
и ДАЖ, ну просто одновременно,
если вы меняете в точке ДА,
то надо и ДАЖ тоже в точке
по-меня-те, будет здорово.
Так что вот такой вот
не сильно
хитрый красота оказался.
То есть обратите внимание, то есть мы никак
не пользовались тем, что мы на ДАЖ
используем реально дерево фермика. В принципе,
с деревом отрезка вы такое могли
провернуть вполне.
То есть помните, да, что если вам нужно только
прибавлять на подотрезке, то отложенной
операции в дереве отрезка вам писать
надо совершенно не.
Вот.
Там можно модификаты просто хранить,
но в вершине не проталкивая.
Нет, но это тоже
отложенная, это тоже своего рода
отложенная операция. Да, без облака.
Да, без, ну да-да-да-да-да,
есть так. Ну нет, такие хаки
тоже есть, иногда помогают, но там уже да.
Хотя, конечно, вот иногда
иногда забавно отметить, что почему-то
так мне никто не сказал, что я без микрофона
это все говорил.
Да?
Или я говорю достаточно громко, что я могу
микрофон не одевать?
Ну ладно, давайте все-таки одену, а то мало ли.
Хотя не знаю, да,
тут я неожиданно одеваю микрофон
и тут кто-то неожиданно просыпается, да.
Мало ли.
Ну да.
Не, ну по-разному.
Ну вот.
Чего доцент Степен?
Нет, ну мало ли.
Какую бы.
Так, ладно.
Какой-то какие-то сложные внутрики пошли.
Ага,
предел по базе это доцент Степен,
но как бы да.
Как это называется? Я мало информации,
я пытаюсь ее компоновать как могу.
Получается вот так, да.
Так.
Ну вот, значит это было прибавление
на подотрески.
Так, ну теперь
соседней задачей возникает
ой, даже не знаю с чего она.
Ну ладно.
Ладно, теперь следующий номер
нашей программы, двумя
дерево чего-нибудь.
Ну, например, фенвика.
Хотя, опять же, технология,
которую сейчас расскажу, будет работать и
на двумерном дереве отрезков. На самом деле,
как это ни странно.
Вот.
Тоже не, ну вот, в общем-то
не сильно сложно.
Фенвик, фенвик, фенвик.
Значит, смотрите,
что будет дальше?
А дальше будет примерно
следующее.
Значит, представьте себе, что мы теперь снова хотим
искать сумму, но
в двумерном массиве.
На каком-то его подмассиве.
Так. Ну, значит
попробуем применить технологию.
Пока пять на пять.
Так, ну давайте тут.
Так, у меня тут ИЖ будут
как-нибудь вот так идти.
Так, ну и я тут какие-нибудь числа от балды напишу.
Конечно.
Будьте здоровы.
Во. Итак, вот
представьте себе, что массив может быть не пять
на пять, а побольше, там, ну,
N на M, например. Вот.
И нам хочется, конечно, тоже делать те же самые
операции. То есть, менять элемент в точке.
Ну, пока в точке.
Значит, меняем элемент
в точке.
И, соответственно, потом
ищем сумму на под прямоугольники.
В тупом виде, конечно, изменения,
то есть, какой-нибудь там
edit
от ИЖ делается
за от единицы.
А вот поиск какой-нибудь суммы
от там L1,
R1 и там L2, R2.
Он ищется за сколько?
Правильно,
за от NM.
Вот.
Это многовато.
Спрашивается, да. Но можно
говорить, что можно, конечно, жизнь себе тут немножко
сократить.
Вот.
Это, господи, первый раз, что ли?
Ну что вы такие?
А, это самое тупое.
Да.
Значит, нет, самое
там тупое, что есть, ну так.
Значит, да, то есть
идея такая.
Значит, да, можно заметить.
А, ну давайте так, ладно, для разминочки.
Нет, знаете, это идея, на самом деле,
пока без Z давайте делать.
Вот если просто сумму хранить,
то значит, можно было бы сократить, конечно,
себе поиск суммы.
Для этого давайте просто в каждом,
допустим,
ряду мы можем
просто насчитывать префиксные суммы.
Прямо вот
честно взять и насчитывать, да?
Пять там, сколько у нас там будет?
Шесть, десять, одиннадцать,
семнадцать.
Вот, красота.
Благотать.
Мы обожаем
двумерное DO или двумерное ферми?
Знаете, отличий
особо не будет.
Ну, скажем так, двумерное DO
будет жрать, правда, четыре раза больше памяти.
А трехмерное DO
восемь.
Где вы видели трехмерное DO?
Ну...
А трехмерное ферми, трехмерное DO
в классе.
Ну, а что такое?
Нет, трехмерный фенвик, конечно, будет проще описаться,
чем трехмерное DO, да?
Но, в принципе, теоретически можно.
Трехмерное DO.
Да.
Хотя...
Ну, правда, нет, не волнуйтесь.
Когда мы будем прибавлять на подпараллелепипеде,
то, на самом деле, это, по-моему, разница нивелируется.
А вот увидите.
Ну, могу уже намекнуть.
Вы же, как бы, ни одного фенвика
храните в водомерном случае, а двух.
Так вот, открою страшную тайну.
В двумерной версии вы будете хранить четырех фенвиков.
А в трехмерной
будете хранить восьми.
Нет, как еще двух камер не хватает вот этих?
Это вот, знаете, типа, которые...
Ну, там...
Ну, знаете, это да.
Как вот, если в недавнюю формулировку брать,
то, да,
журналисты это те люди, которые
профессионально делят любую фразу на две части,
чтобы вторую часть сказать другую
камеру.
Ну, вот это вот все.
Вот.
Ну, да, можно, ну, там более старые отсылки на дружку,
конечно, есть, да, но...
Он это тоже говорил, да?
А, ну, хотя, ладно, он там затыл, да,
там было 30 выпусков, что он только там мог
не говорить, да.
Действительно.
Ну, не все же там про
Джарахова и Ларина рассказывать, действительно.
Вот.
Так вот.
Значит, ладно, пока мы тут обсуждали
Джарахова и Навального, значит, я тут насчитал
префиксные суммы.
Да, камера, камера,
да, я помню, так.
Значит, соответственно.
Ой.
Значит, смотрите.
Значит, тут у нас соответственно И, тут у нас
соответственно G.
Ну, вот, то есть,
закрою симптомику,
теперь мы можем искать сумму.
Ну, теперь мы ее можем искать
за время
получается от M.
Ну, если вот это N
типа, а это M, то как получается
от M? Почему? Потому что
если мы ищем сумму,
допустим, на подотрезке,
вот на под
прямоугольники, ну, например,
вот на таком,
да, то есть я вот должен,
тут бы я должен был просуммировать все вот это
вот, а здесь
на самом деле все гораздо проще.
Теперь я должен просуммировать все,
плюсовать все вот эти элементы
и повычитать все
вот эти элементы.
Но теперь мы замечаем
там, замечаем маленькую
мистическую, маленький мистический момент.
Маленький
мистический момент заключается в том,
что оказывается в каждой,
ну, вот, что, во-первых, да, мы задействуем
всего два столбца, но в каждом столбце
мы ищем сумму одного и
того же подотрезка элементов.
Удобно, да?
И поэтому возникает
естественная идея.
А давайте еще раз найдем
префиксные суммы.
Но на этот раз не на строчках,
а на столбцах.
Что же тогда получится?
Так, ну, получится тут понятно
пять, шесть, восемь, тринадцать, девятнадцать.
Так, ну, дальше тут проматываем.
Так, ага.
Так.
Так, ага.
Тридцать семь, пятьдесят, ага.
Одиннадцать, двадцать один,
тридцать два,
сорок шесть,
шестьдесят девять,
семнадцать, тридцать два,
сорок девять.
Там, соответственно, шестьдесят пять
и девяносто семь. Вот.
В такой версии оказывается, что
чтобы найти сумму на
таком подотреске,
надо, получается, просто взять, вот, прибавить
вот этот элемент и вычесть вот этот.
Ну, а здесь, соответственно, вычесть вот этот,
найти вот этот.
Получается, что мы теперь научились искать
сумму за
от единицы.
Так. Ну, в принципе, это то, что я
тут пока описал то, что известно, как
собственно двумерные
префиксные суммы.
Потому что, ну, как легко убедиться,
то есть, в каждой
то, что написано в каждой ячейке здесь,
это не более чем сумма на вот
таком вот под прямоугольнике здесь.
Логично, да?
Ну, как понятно, да? Мы тут, как бы,
посчитали сумму на префиксах в строчках
и потом еще просуммировали на столбцах.
Получилась, например, сумма на вот таких под прямоугольниках.
Вот. Ну и оказывается, что чтобы найти
теперь сумму на подотреске, то есть, можно интерпретировать
вот так, просто сказать, что вот
я вот нам сказала, что это надо делать вот так.
Ну или можно просто
это приинтерпретировать, что на самом деле
сумма под таком прямоугольнике
это как сумма на таком
минус tam вот сумма
на таком, минус сумма на таком,
минус сумма на таком, и еще плюс сумма
на таком. Потому что мы тут 2 раза вытесли,
ну там, начинается вот эти там заклинания,
типа формула включения-исключения, там вот это все.
Ну вот.
А это вот это вот.
Хех.
то есть на самом деле так но я так не буду сейчас совсем углубляться потому
что на всяких там комбинаторика хвостом форма включение исключение еще обязательно
вы а было даже о чем вы тогда спрашиваете что это а это шутка ой хорошо а ну раз было так
тем более хорошо значит так плюсик минусик минусик плюсик кайф но кайф кайф вот но теперь
оказывается что подобного рода технология но технология даже не в том что тут плюс
минус минус плюс а в том что можно на каждом в каждой строке что-то сделать а потом с
результатом сделать что-то в каждом столбце на самом деле прекрасно миксуется например с
деревом фенлика а именно вот теперь давайте я уже тут примеров тут уже рисовать не буду
но теперь представим себе что у нас есть массив в котором мы хотим делать операцию
это до к одному элементу и хотим делать сумму на поднот сумму на подотрески
да пока изменяем один элемент значит замечаем что сейчас это у нас работает за от единицы
а сумма за отнм вот здесь мы делали значит тут мы искали префиксные суммы горизонтально
а вот тут префиксные суммы вертикально
вот ну теперь у тебя такая а давайте теперь вместо того чтобы значит то есть вместо то
есть теперь делаем тоже самое только в каждой строчке мы вместо того чтобы построить
префиксные суммы мы построим фенлика то есть вот так скажем фенлик горизонтальный
господи звучит как лорд какой-то там до фенлик горизонтальный да видимо часто проигрывал на
турнирах видимо да так значит смотрим что же у нас тогда получится если в каждой горизонтали
теперь сумма ищется через фенлика то конечно сумма у нас теперь ищется уже за тут был отнм а
тут теперь отнм но правда прибавление поменялось потому что теперь нам нужно взять этого в одном
фенлике сделать одно изменение это делается за логан но уже неплохо но если эддев не то есть
там если эддев не прям прям супер пупер гипер криминально больше чем сумма то это на самом
деле уже лучше почему но нет нет ну так знаете если эддев плюс бесконечность а сумм 3 то как бы
называется вот это вот это будет лучше чем вот это вот но смотрим то есть это ну ладно вот это да
так вот смотрите что же будет дальше до минимума где вот здесь что ли а ну можно но не нужно потому
что мы все равно сейчас как бы потому что действительно у фенлика горизонтального есть
напарник фенлик вертикальный но не оно мало ли не знаю нет на самом деле они все равно друзья как
бы да они тот как бы и фенлик горизонтальный фенлик вертикальный они как бы и один без другого они
в общем-то там живут только в одномерном мире а в двумерном мире сначала один потрогают другой
причем они хорошо так взаимозаменяем это в каком порядке не сделает все равно мы кстати с
этими доблестными лицами уже встречались в общем-то в фуриатине но ладно не не с фенликами это
были это конечно там это были там там фурия горизонтальный фурии вертикальный там вот ну
на самом деле да мало кто знает но лица любили ходить парами вот вот нет в общем проблем нет ну
а что такое на самом деле конечно то есть как-то знаете одно дело там что-то там называется одному
ходить воевать а другое дело называть когда вас два товарищей когда как каждый другого поддержит
что проблема но чуда нет ну да нет она но да у меня была бы и следа выучить кучу песен и
петь их пока я тут что-то рисую да чего но этой куче не знаю нет но там дайте тот
проблем еще в том что они еще контекст должны вылезти так-то нет что-то я конечно знаю но там
иногда ой да прозвучало как заклинание честно говоря а да мы не знаю это я знаю потом др потом
пока да и все две недели там караоке караоке 30 но даже нет у меня 1 апреля я не знаю
пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп п
пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп
пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп пеп п
пеп пеп пеп пеп пеп пеп пеп пеп пеп
сумму на каком-то прямоугольнике, мы фактически перебираем
сколько-то последовательных подряд идущих рядов и на
каждом из них берем какие-то значения.
Причем более того, эти значения в каждом ряду как бы одни
и те же, в смысле по позиции.
Ну вот, ну и минусики там еще какие-то есть, вот такие,
да?
Вот.
И тогда, давайте сказать, идея такая, а вместо того,
чтобы прям каждое значение из каждого столбца брать,
так может быть переберем все столбцы, в которых надо
что-то взять, да, и возьмем из них сумму на подотрезке
в этих столбцах.
Ну и следующая идея, так давайте просто на каждом
столбце тоже забабахаем вот этого фенвика-напарника.
Но тогда получается, что действительно сумму мы теперь
ищем за произведение логарифмов, но правда и Эдды нам теперь
придется делать, соответственно, за произведение логарифмов.
Понимаете почему, да?
Ну потому что если здесь изменяется логарифм значений,
то как бы тогда получается в логарифме фенвиков получается
нам надо поменять значение за логами.
Ну, в общем-то, вот я и описал, как выглядит, в общем-то,
двумерный фенвик.
Вот.
То есть код уже, ну, получается, то есть код пишется достаточно
тривиально.
Можете изначально считать, что там все элементы нули.
Вот.
И дальше, если вам там приходит какой-нибудь запрос поменять,
ну вот, то есть скажем, приходит какой-нибудь там запрос поменять,
то вы, говорите, вы перебираете, в каких столбцах вы должны
делать прибавления.
Это вы делаете с помощью функции g внешней, да?
То есть там получается там условно for и и, значит, равно
i плюс 1, и и меньше либо равно n, значит, и и равно g от и и.
Вот.
Это вы перебираете столбцы, в которых надо что-то поменять.
Понимаете, да?
Но в каждом столбце, значит, надо поменять, ну, здесь
вы бы просто поменяли житую ячейку, да?
А вот в глобальном фенвике, ну, значит, вы пишете for ж
ж равно ж плюс 1, ж меньше либо равно n, ж равно ж от ж ж.
Вот.
Значит, и, соответственно, пишем 3 и и т ж ж т будет
0 плюс равно х.
О, все.
Удобно, правда?
Да.
И вы можете, да, кстати, да, то же самое у технологий,
которые, конечно, могли тут в каждом месте вместо
дерева фенвика хранить реально дерево отрезков,
кстати.
Правда, дерево отрезков потребовало от вас в два
раза больше памяти.
Ну, по горизонтали в два, а в совокупности в четыре.
Да, в коммерном пространстве в два степеника раз больше,
конечно.
Но, в принципе, вот просто двумерный дерево отрезков,
да, но существует и вот реализуется, в общем-то, буквально на
этой же технологии.
Ну, это, блять, логично.
Да.
Так вот.
Вот.
Значит, add мы нашли.
Ну, а теперь все, что вам остается, это уметь находить
теперь сумму на подпрямоугольнике.
Но, правда, замечаем, что сумма на подпрямоугольнике
достаточно быстро сведется к, действительно, к четырём
префиксным суммам.
Ну, к четырём там суммам вот такого вида, да?
На подпрямоугольнике это еще приятно.
А там на подприлепипеде это уже совсем отравление.
Нет, какая разница?
Нет, наоборот.
Ты пишешь просто общий код.
Нет, погоди, давай так.
Вот давай посмотрим.
Как будет выглядеть, значит, как будет выглядеть это нахождение
суммы на префиксном подпрямоугольнике?
Да, будет 4,4.
В трехмерном пространстве 4,4,4, да?
Ну и так далее.
Это префикс.
Да, но это на префиксе.
Проблема будет в том, что здесь вам придется вызвать
4 раза, в трехмерном 8 раз и так далее.
То есть вот эту формулу включения и включения.
8 раз, что аккуратно расписать, нигде не попечататься
в индексах, в которых вы пишете 8 вызовов.
А ты фориком пиши.
То есть там перебираем масочку и говорим, что запускаем,
и если там элик нечетное количество, значит, мы читаем.
Если четное, то прибавляем все.
Ну или так, да.
Хотя, ну, да, допустим.
Так вот.
Вот такая красота у нас получилась.
То есть так выглядит двумерный фенвик.
Так, смотрите, так выглядит, значит, внимание, внимание,
сейчас будет аккуратно.
Так выглядит двумерный фенвик, если вы обновляете
один элемент.
Но теперь возникает немножко медицинство.
А если мы хотим делать прибавление на подпрямоугольники?
Ну, на самом деле, на уровне идеи можно посмотреть
на эту картинку и сказать вот.
Потому что, в общем-то, технология работает буквально так же.
То есть сначала у нас есть...
Ну вот, так, ну давайте я ее могу третий раз нарисовать.
То есть прибавляем, допустим, L1, R1, L2, R2.
Ой, ладно, тут еще иксик, наверное, не помешает.
Ну вот.
И как бы можно, по идее, делать обе эти операции за OATM.
Вот.
Но у нас есть рыцарь-фенвик.
Вот наш горизонтальный фенвик.
Который умеет действительно сказать, что и add, и sum у нас
теперь будут работать за OATM лог N.
Потому что в каждом ряду мы забабахиваем, что мы забабахиваем?
Обычного одноверного фенвика с прибавлением на подотрески.
Продолжаем.
Бабахиваем.
Обычного одноверного фенвика с прибавлением на подотрески.
Правда, с мелкой оговоркой.
Потому что был у нас массив A, а теперь у нас будет, значит,
массив DA.
Я его даже так напишу, потом увидите почему.
Значит, DEA и DEI.
Ну что такое DEA?
Это типа префиксные разности по переменной I.
А DEI это означает, что это префиксные разности массива A по I умноженное на I.
Логично, да?
То есть, ну, мнимоника у меня будет такая.
Но массива всего два, поэтому, в общем-то, на симптомику это не влияет.
Но теперь вычекается следующая идея.
Можешь к горизонтальному фенвику теперь прицепить и вертикального.
Все равно он где-то рядом бродит.
Вот.
Вот.
Значит, соответственно, что же будет дальше?
Вот.
Ну дальше замечаем, что теперь просто на...
То есть, нет, фенвик фенвиков это другая технология.
Мы еще сегодня это обсудим.
Вот.
Значит, DEA, DEI.
Но теперь идея такая, что теперь на каждом из этих вот фенвиков,
то есть, на каждой из этих массивов хочется по каждой вертикали
под тем же причинам забабахать тоже фенвик.
Понятно, да?
Ну вот.
То есть, тогда это приведет к тому, что у нас тут будет log N,
значит, сумма будет, соответственно, тоже от log M, log N.
Вот.
Вот.
Не, ну что, для этого просто каждый массив превращается в два.
Значит, во-первых, он превращается в DEI...
Ну, во-первых, так, в DEJI, DEIA.
И в DEJI, DEIA.
DEJI, DEIA.
Это первый массив вот тут превращается, да?
То есть, как бы, просто разности по JI, а тут разности по JI,
еще и продолженные на JI.
Видите, то есть, сначала мы взяли разность по I, потом разность по JI.
Понимаете, да?
Вот.
И, наконец, и напарник.
Значит, ну, напарник, понятно, пишем DEJI, DEIA.
Ну, и, конечно же, то, что мы напишем DEJI, AIG.
Вот.
То есть, на самом деле мы храним...
Ну, можно тоже поинтерпетировать, что мы храним, на самом деле,
просто массив таких разностей, где мы взяли разности по I,
потом разности по JI.
То есть, по большому счету, это если у нас тут есть четыре клеточки, да?
То мы как бы храним разность, что-то типа берем вот эту,
минус вот эту, минус вот эту, плюс вот эту.
То есть, такой двумерный аналог частичных разностей.
Да, тоже, кстати, по ним можно также восстановить там исходный массив, там вот это все.
Вот.
Ну, вот. Ну, в трехмерном пространстве то же самое надо инвертировать,
написать там под ним, и получится такой кубик трехмерных разностей.
Ну, и так далее.
Ну, что сразу дичь?
Это не дичь.
Это да, это не дичь.
Это трехмерные частичные разности.
Это трехмерные дичь.
Ну, вот.
Ну, допустим, ладно.
Так.
Так вот.
Может еще раз какие там массивы?
Где массивы?
Ну, смотрите.
Вот у нас здесь какие массивы были?
Массивы с разностями по I, и тут массивы с разностями по I, умноженных на I, да?
Значит, теперь аналогично мы теперь делаем фенвиров пожи.
Для этого нужно в каждом из этих массивов взять разности пожи и разности пожи, умноженные ножи.
Каждому массиву DI.
Ну, вот.
Поэтому я тут пишу DG DI.
А, то есть я просто взял вот эти разности DI и в них взял частичные разности пожи.
Нет, это не Федрик.
Вот.
Ну, вот.
И у него на парке я взял те же самые разности, но каждую домножил на жи, то есть номер строки.
То есть теперь я вот на каждом столбце вот этого массива умею делать прибавления на отрезки.
И сумму надо.
То есть сумму на под столбце, так сказать.
Я не понимаю, что это массивы.
Чего?
Я все равно не понимаю, что это массивы.
Можно написать формулу.
Формулу?
Нет, тут технологика растребует, чтобы и формула не писалась.
Ну, еще раз.
Ну, D и A.
Давайте D и A.
Значит там A и T житое.
То есть D и A и T житое.
Это у нас что такое?
Это просто A и T житое.
Минус A и минус 1 житое.
D и A и.
D и A.
Значит это было D и A.
D и A и и T житое.
Равно, короче, то же самое D и A и T житое умножить на I.
То есть это те же самые формулы, которые написали, когда делали одномерного Фенрика.
Но теперь у меня технология заключается в том, что я в каждом из этих массивов буду обращаться к одним и тем же элементам.
Ну, с точки зрения по столбцам.
То есть я переберу нужные строчки и в каждой из них обращусь к элементам в одних и тех же позициях.
Поэтому я хочу вместо этого в каждом из этих столбцов сделать что-то на подотреске.
Поэтому я на вот каждом из этих массивов забабахиваю, соответственно, тоже дерево Фенрика, но уже по вертикали.
В результате.
Чтобы забабахивать в массиве D и A, я тебе говорю D жи, D и А.
Значит пишу.
D жи, D и А.
И Т житое.
Равно.
D и A и Т житое.
Минус.
D и A и Т житое.
Понятно, да?
А здесь, ну здесь понятно, что D жи, D и А жи равно, соответственно, ну здесь понятно D жи, D и А умножить на жи.
Тут индексы писать не буду.
Тут индекс и жи и тут индексы жи.
Понятно, да?
Ну то же самое вот можно написать здесь, просто буквок еще больше будет.
Но как бы я сделаю просто абсолютно тот же самый по вертикали, только для массива D и A и.
Так что вот такая вот магия.
В скопках нет.
Вот.
Понятно?
Во.
Вот.
То есть получается 4.
Как я уже говорил, да, то есть как вы дорадуетесь, в трехмерном Федвике с прибавлением на под Параллелепипеде вам придется заводить 8 массивов.
В четырехмерном 16, в пятимерном 32, в шестимерный, дай бог, чтоб встретился.
То есть по сути мы...
Скорее, чтоб не встретился.
Тихо, тихо.
Наш, как бы, массив внешний на столбцы, в которых нам нужно найти сумму.
И делегируем обязанность поиска суммы на внутренние Федвики.
Да.
Не, не, не.
Нет, 4 это вот эти.
Нет, 4 массивы это
Ну, короче, Dg, Di, A это общий префикс.
Потому что мы везде берем сначала...
То есть фишка такая.
То есть мы берем как бы частичные разности по I, а потом в результате берем частичные разности по G.
А дальше зависит от того, на что мы домножаем.
Здесь мы не домножаем и на show, здесь домножаем на I, здесь домножаем на G, а здесь домножаем на обоих.
То есть нет, если будет так проще, вы можете вот...
Вот мы писали вот формулу для 1-мерного Фенрика, да?
Так вот, на самом деле вы можете попытаться написать ту же самую формулу и для 2-мерного Фенрика.
Ну, просто там у вас вылезут суммы, в которых не помешает вот такого рода элемент.
То есть можно мыслить так.
Что, действительно, прибавлять так, а когда вы будете там, скажем, прибавлять на под прямоугольники,
вы заметите, что такое...
Вот еще раз, что такое частичная разность на под прямоугольники, да?
То есть вообще глобально в массиве частичная разность.
Это когда вы берете элемент, вы читаете два соседних и прибавляете вот этот по диагонали, да?
Ну вот.
И тогда оказывается, что если вы храните не массив A, а массив вот такой, это и есть, кстати, D, G, D и A, да?
То тогда оказывается, что если вы прибавляете на под прямоугольники, то, оказывается, изменяется ограниченное число элементов.
Значит, а именно что меняется?
Значит, к этому элементу происходит плюсик, к вот этому минусик, к вот этому минусик и к вот этому плюсик.
На самом деле все остальные, как легко убедиться, не меняются.
Ну просто потому, что там либо кто внутри пересекается не интересно, кто не пересекается не интересно, кто пересекается по двум соседним элементам тоже не интересно, они взаимо убиваются.
Вот.
Поэтому остаются только те, кто пересекается по одному или по трем элементам.
Ну с по трем элементам у нас никто не пересекается.
Поэтому пишем.
Все.
Так что оказывается не сильно сложным.
технология
ну пока и но вот но такие знаете она может казаться
контринтуитивной но на самом деле видите мы просто сделали пару технических вещей причем обратите внимание фурятине мы эту
делали
было дело да было было дело да было дело да
ой
а
вот
так что вот это был так что таким образом получается что прибавлять по примере
прибавлять на под прямоугольник это пожалуйста
кстати что интересно присваивать на под прямоугольники вы так конечно не сможете
ну скажем так вот так сможете а
вот так уже затруднительно
в чем самое самое страшное что как прибавить как присваивать на под прямоугольник я честно говоря не знаю
я
тот и прикол что нет понимаете потому что все вот у нас одномерное присваивание базировались на технологии отложенных операций
так что поэтому получается что
технологии отложенных операций
жутко базируется на том что
как бы вы к любому элементу пройдете только из какого-то корня по фиксированному пути в дереве
вот в двумерно в двумерном дереве отрезков такой структуры нет поэтому извиняйте
то есть нет там в
некоторых редких случаях на самом деле иногда
удается обойтись например делать присваивание на подотрезке и все-таки обойтись на самом деле без отложенных операций
потому что вот давайте я в этом месте тогда расскажу один маленький чит вот предположим что у нас есть тупая задача
дан массив но не важно там от 0 до 10 в 9 даже например даже сейчас будет него
но хотя ладно 25 и массив и вам нужно делать и вам нужно сделать кучу присваивания на подотрезках
ну как всегда там сделай 100 тысяч присваивания на подотрезках потом в конце выдай результаты выдать что там в итоге получилось
или даже еще круче вот давайте вот задача будет такая давайте это я убираю
задача будет такая то есть вы хотите уметь делать присваивание на подотрезке да мы возвращаемся в одномерии и
получить гетатпоз
что да то есть я утверждаю что эта задача прекрасно решается тупо с этими
да я так вот я да это задача на самом деле никаких деревьев отрезков писать не надо это задача решается тупо с этом
но вот но там правда вам тебе все немножко амортизационного анализа конечно чтобы доказать что все работает
но просто идея будет такая но давайте представим себе что изначально у вас
отрезок то есть идея такая мы в сете будем хранить то есть мы массив будем хранить как набор полуинтервалов
набор полуинтервалов на каждом из которых значение одинаково
вот
то есть в результате такой цепочки
ну изначально вы можете считать что в сети у вас вообще один полуинтервал на котором присвоен 0
ну типа если там массив изначально задан ну там сделайте еще лишних там 10 в пятый присваивание длины 1 это мелочи
вот а теперь значит история так но
но как делать дед то есть если вы эти полуинтервалы то есть прям заводите прям структурку в которой храните или там допустим лр х да
то вы как бы эти полуинтервалы можете хранить с эти с компаратором по эльки
ну вы конечно гарантируете что они только соприкасаются на не касаются да и
тогда если у вас такой сет хранится то где-то вы получаете просто на уровне просто с помощью там какого-то там лавербаунда а пербаунда правда
потому что вам нужно пройти там какой-то минимальный отрезок то есть там какой-то полуинтервал который содержит пост да то есть для этого нужно
найти там что-то типа последний полуинтервал у которого элька не
превосходит поса
по каким строкам мы мы вернулись в одномерие напоминаю
вы другую задачу решаем
нет это одномерный случай это присваивание напоминаю присваивать на одно под прямоугольники я не умею вообще
не не обожжу
да ну
ну вот но я просто всякий случай рассказываю то что кто-то там не задумывался в эту сторону то есть понятно да что решение простое да но вот
помните что оказывается что здесь мы тогда там
находим просто полуинтервал в котором лежит постом это в сете там с помощью лавербаунда фапер баундов сделается да а
если вы хотите делать присваивание на по присваивание то как это делается
то получится примерно следующее то есть вы там находите полуинтервалы которые пересекаются с вашим
и
что вы заметили но как бы есть два крайних которые надо вот просто уменьшить и
есть те которые струй лежат внутри значит вы их из сета честно удаляете
часто правут буквально итератором прибегаем все прям вырезаем а
вместо этого вставляем один полуинтервал на вот это все с числом x
но легко убедиться что на каждом таком на каждом таком шаге на каждом таком эти вы создадите не более то есть вы будете удалять
какие-то полуинтервалы но взамен создавать не более двух поэтому суммарно вы создадите не более чем 2 на когда 2 q
полуинтервалов 2 q плюс 1 если считать исходный и
получается что учетная стоимость тогда всех этих операций получается лог и
ну потому что каждый каждая вставка удаления полуинтервалы это естественно зелого рифом делается не заединиться
вот то есть вот полезно помнить вот такой технологии вот эти то есть иногда на самом деле можно там без деревьев отрезков обходиться
вот
так что если вам вот такое
вот
так что это вот просто вот хотелось ответить вот да и то есть редкий случай когда вот какие-то простые операции дайда и
иногда можно там без всяких деревьев отрезков и феновиков обходиться вот такими вот простыми штуками
вот
но это вот такие локальность так сколько у нас там времени
да
так ну ладно тогда видимо пришло время устроить еще один перерыв после которого мы рассмотрим еще одну красивую задачу видимо с кодексом
да
но вот просто задача которую мы решим двумя способами и все милы по-своему они
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
вот
мкашпана несколько раз не успевали на 20 секунд запихать задачу ну вот так что дальше так
что помните да то есть на самом деле с этой точки зрения помните помните да что на тренировке вы
помните вот так то есть конечно да один из важнейших скиллов это крыша уметь решать средние
главное сложные задачи но не менее важный скилл это уметь решать простые задачи быстро но вот
вот в этом смысле кстати до половины смысла кубка мф 3 кстати именно в этом то есть да там
мой там у вас в контесте могут быть там много халявных задач но эти халявные задачи нужно а
быстро распоздать б очень быстро написать вот потому что чем быстрее вы напишите издадите
вообще там без багов собственно простую задачу тем больше нот времени у вас будет на то чтобы
это решается два варианта либо тренируетесь его переписывать без этого либо вот лекция вот
предыдущие три часа были ровно за то чтобы ты как бы это понимал что тут происходит вот отлично
значит лекция прошла не зря но я скажу вот ну скажем так ну как по хорошему тут
проблема швейк и проверю но я скажу так в идее нет значит идея но я вам скажу так я думаю так
я даже разрешу пользоваться при этом кодом если вы его переписываете с бумажки ну объясню
смысл объясню смысл но как бы цель этого всего это что это подготовка к cpc на cpc вы копипастить
код там из другого места у себя не можете потому что вы пишите его с нуля но на практически любой
адекватный контест по моему уже не осталось в этом смысле не адекватных контестов вы можете
предоставить им ноутбук да то есть там ранее написанная заранее написаны какой-то там вашей
команды код какой-то вот и собственно тогда там какие-то алгоритмы типа там какого-нибудь у
или там вот я не знаю фенвика например но вы тогда спокойно спокойно можете переписывать
бумажки так что я думаю с этой точки зрения у вас там заготовЛ evolutionary notebook тогда вот я
сказал да то есть я думаю потом тогда вы если вы будете там отрабатывать переписывание таких
алгоритмов то это будет хорошо да нет и то чтобы вам там сильно часто это будет надо но
ну хотя иногда надо правда кстати кстати с этой точки зрения еще можноribly задуматься потому
потому что если вы будете часто переписывать большой код, кстати, тоже на самом деле вы CPC такой скилл,
может быть там относительно второстепенный, но тоже иногда полезный, это убение вот этой вот быстрой печати.
Ну, кстати, я не знаю, когда я был на сборах на межна, кстати, там, собственно, там требовалось, что как бы, что как бы,
там от всех, там, по крайней мере, высказывали пожелание, что все вы должны научиться быстро печатать.
Вот, ну я не знаю, там, не сильно много народу в итоге реально умело, но вот...
Ну вот, ну там, конечно, такой момент, что как бы понятно, что реально быстрое печатание вам скорее всего поможет только в том случае,
когда вы там переписываете какой-то большой код или там пишете,
потому что в остальные моменты, в общем-то, вы пишете с той скоростью, с которой вы думаете, поэтому, в общем-то,
локально, но тем не менее, если вам, ну вот, ну...
Ну, видимо, подразумевается, что думаете быстрее и тогда вы придете скорой с печати.
Ну, в принципе, да. Ну, тут вот, да.
Не, ну как сказать, если у вас слепая, как бы вы там, допустим, вам не надо смотреть на клавиатуру там лишний раз, чтобы напечатать там неожиданную букву, то, в общем-то,
это вам тоже какое-то преимущество даст.
Потому что, вот видите, как мы уже, потому что я уже говорю, то есть, знаете, там, все-таки принципиально, да, то есть, например, там, за какое время вы решите там задачи, да.
Все-таки, ну вот, то есть, там всякое, конечно, может быть, это да, потому что, то есть, как бы все-таки, ну вот,
то есть, все-таки, как бы, чем быстрее вы решите, соответственно, быстрые задачи, тем, собственно, может быть, лучше.
Потому что, на самом деле, просто быстрое решение может дать неожиданный профит.
Ну, потому что, ну, относительно быстрое.
Ну, вот, потому что, ну да, там всякое может быть, конечно, быть, то есть, там, потому что классический пример, вот, на моем единственном финале ACPC в истории,
это, ну, вот, это был финал, по финалу 14-го года.
Там произошла эпическая ситуация.
Вот, значит, команда МГУ по результатам в заморозке, значит, на момент заморозки, то есть, после 4 часов решила 6 задач.
Второе место, 4 задачи.
В общем, отдельно вам дам, в контесте было 12 задач, если что.
Вот, там, отдельная песня.
Вот, мы вообще две решили, не важно.
Вот, значит, так вот, так вот, команда МГУ в заморозку сдала еще одну задачу.
Но при этом уситрилась чемпионат не выиграть.
Значит, почему?
Потому что в заморозку мало сдали.
Нет, они сдали в заморозку одну задачу, а вот команда SPBU-4, собственно, сдала в заморозку 3 задачи.
Но оказалось, что у нее там первые 4 задачи, она решила прям вот очень быстро.
И в результате со счетом 7-7 чемпионом 14-го года стала команда SPBU-4 в составе.
Ну, что, ну, там в составе, понятно, там Павел Курявский, Егор Суворов, там Дмитрий Егоров, если быть напрямую.
Вот.
А команда МГУ, очередной на тот момент, раз, значит, заняла второе место.
Ну, просто до Рэд Панды на самом деле у МГУ была традиция.
МГУ на финале получает либо второе место, либо 10-е, либо без медалек.
Да, Петр Митричев два раза второе место брал.
Вот, ну, там, там, ну, там всякое бывало, там, вот.
Ну, потому что мало ли, там, на одном финале просто, да, ну, то есть всякое такое.
Ну, вот. Ну, то есть Рэд Панда потом выиграла там два раза, но это вот только второе место.
Ну, в 14-м году это был не Петр Митричев, это была, это была там команда, собственно, там, Евстропов-Пидёркин, там, соответственно, Амельяненко, но это уже, соответственно.
Вот. Так вот. Это я вот к тому, что оказывается, что, то есть быстро сданные, собственно, задачи в начале, это на самом деле может так зарешать.
Ну, собственно, вчера на тренировке, в общем-то, тоже при счёте 7-7 победил тот, кто, собственно, это не начал сдавать задачи после тренировки, то после второго часа.
Вот. Соответственно.
Ну, вот. Нет, правда, тут бывает, конечно, обратная ситуация, да, то есть обратная ситуация в этом смысле произошла на, вот, когда, вот, когда команда Линкетт, собственно, на финал выходила, она выходила совершенно внезапно.
Ну, вот. Потому что там, да, да, по идее, как фавориты шла, как бы, сильно более опытная команда, там, сильно более опытная команда, и, в общем-то, казалось бы, всё, всё шло хорошо. Ну, вот.
Ну, как сказать? Ну, то и значит, на самом деле. Потому что команда Линкетт, это была просто, там, молодая, просто, команда второкуровка.
Ну, вот. Ну, вот. А была команда, тогда называлась Малая Бронная, там, в составе, там, собственно, Мачулок, Аминетян, там, Семёнов.
Вот. Ну, у которой Юра Семёнов, конечно, а не Костя. Вот.
Ну, соответственно. Ну, вот. Ну, то есть, нет, это была много...
Нет, просто это, ну, нет, это, собственно, было, просто это уже опытные, там, старшекуры были, соответственно.
То есть, так, ну, вот. Ну, и в тот момент это, как бы, вроде, шёл безоговорочный фаворит.
Ну, вот. Ну, как бы, если сравнивать с Линкеттом, то, как бы, на момент середины контеста Малая Бронная выигрывала со счётом 4-1.
Да. Ну, вот. Ну, в итоге. Ну, вот. Более того, там. Ну, в результате я проиграли со счётом 5-6.
Ну, там, правда, там, другая песня произошла, потому что там они сдав пятую задачу, потом в последний час пытались сдать две задачи, не получилось ни одной.
В результате Линкетт в результате там Халяву всё-таки доздал, потом сдал пятую задачу, потом они там втроём, собственно, добивали там шестую геому и за три минуты до конца её сдали.
Вот. И потом, с удивлением для себя, обнаружили, что они, оказывается, в финал вышли.
Потому что, собственно, никто этого не ожидал. Как потом грустно, по-моему, там, по-моему, подсчитали то ли они, то ли Мачуло, то ли все вместе.
По-моему, это был единственный раз в истории, когда команда Линкетта выиграла команду Малая Бронная.
Вот. Ну, не знаю. Вот. Ну, просто внезапно немножко получилось.
Единственный, зато какой.
Нет. Ну, тут, нет. Тут мораль это называется, что крайне нежелательно просто в последний час.
Вот. Поэтому я вот всем советую активно всегда, что по возможности, то есть в последний час две задачи параллельно не решать.
То есть обычно на момент 50-60 минут до конца. Просто надо обычно садиться.
И, то есть обычно так, уже просто сесть в команду и посмотреть, что у вас есть, выбрать задачу, вот, которая, значит, с большей вероятностью сдаться и наброситься на неё втроём.
Ну, потому что пятый час вы уже устали, то есть, а явно уже не халяву, скорее всего, пишете, поэтому там соответственно.
Ну, если, конечно, это не блиц какой-нибудь, но вот, поэтому так.
В конце концов, если там втроём сдадите эту задачу, можете наброситься на другую, но это как бы больше шансов будет просто.
Ну, и у нашей команды как-то вот в каком-то Петрозаводске как-то результаты прям на голову скакнули, как только мы приняли тактическое решение в последний час более там, собственно, больше одной задачи не писать.
И как-то вместо стабильного нуля в последний час у нас стали там появятся стабильные единички в последний час, и как бы места сильно от этого увеличились.
Вот.
Так, ладно, не сейчас, возможно, да, не сейчас я, возможно, должен об этом говорить, но ладно.
Так вот, значит, идём дальше.
Значит, последняя задача, которую мы сегодня рассмотрим, ну, возможно, мы её рассмотрим двумя способами, будет звучать так.
Смотрите, дан квадрат десять девятый на десять девятый, а в нём точки, десять в пятый точек, в каждой точке написано чиселка, ну, как всегда там.
Сумма на прямоугольнике.
Да, значит, два запроса, вот традиционных два запроса.
Первый запрос, возьми точку и там измени число, ну, там прибавь ещё что-нибудь.
Ну, точку уже известны ранее.
Что? Да, координаты точек известны заранее, и они, что приятно, не меняются.
Так что, ну, чиселки, которые на них написаны, меняться могут.
То есть, первый запрос, то есть, это опять, значит, добавь к какой-то точке какой-нибудь х.
Именно к точке, которая уже есть.
Да.
И на этой точке, то есть, мы уже знаем, что точка, которая уже есть.
И на этой точке, то есть, мы уже знаем, что точка, которая уже есть.
То есть, это опять, значит, добавь к какой-то точке какой-нибудь х.
Именно к точке, которая уже есть.
Да.
И на этот раз, ладно, тут, допустим, прибавь там какой-нибудь вал, а тут х1, х1, х2, х2.
Ну, вот опасно тут думать на тему там явных-неявных ДО, ну, потому что, например,
можно сжать координаты.
Так, ну, хорошо, значит, ладно, да, хорошо, начнем с того, что можно сжать координаты
без граничей общества и считать, что тут 10 пятый на 10 пят.
Ну, и там понятно, что во всех запросах там на сумму, естественно, там просто,
там придется потратить логарифом времени на 4 бин поиска.
Магнитный ГПХ тейбл.
И Феллик Фелликов.
И Феллик Фелликов.
И Феллик Фелликов.
Пыщ, пыщ, пыщ.
Да, да, да, давай, иди пиши, иди пиши.
Так, иди пиши, иди пиши, да, давай, иди пиши, я пока подробнее расскажу, давай.
Значит, смотрите, что произойдет дальше.
Ну, потому что просто, конечно, двумерное, давайте, двумерное ДО тут не напишешь,
потому что массив 10 пятый на 10 пятый, это больно.
Вот, да, поэтому тут, ну да, можно, ну вот, скажем так, ну тут, конечно, есть разница,
разные щиты, да, можно попытаться, конечно, хранить действительно двумерный,
там действительно двумерного Фенлика, как мы описывали, но хранить при этом,
но при этом хранить в хэштейбле не все под прямоугольники, которые есть,
а только те под прямоугольники, которые содержат точечку.
Причем тут хэштейбл, я не понимаю.
Ну, а как вы предлагаете?
Какой хэштейбл?
Ну, идея такая, давайте хранить двумерную, там допустим,
там действительно заведем, представим, что это массив 10 пятый на 10 пятый,
и заведем на нем двумерного Фенлика.
Да, ой, у нас проблема, это требует слишком много памяти.
Так вот, идея такая, давайте хранить не все отрезки,
а хранить только те отрезки, в которых реально хотя бы одна точка Д есть.
Да, вот, ну такой метод тоже есть, это уже более, это уже может зайти,
но как повезет, потому что по памяти это очевидно сколько?
Правильно, n лог квадрат.
Потому что каждая точка лежит в лог квадрате прямоугольников.
Ну, кажется, что там можно и логом оценить.
А, не, не, нельзя лог оценить.
Да, n лог квадрат, особенно если он маленький, точно не оценить.
То есть какие-то такие идеи могут у вас там пройдить,
или там какой-нибудь ДО какой-то еще тоже не явно забабахать,
у вас там будет тоже лог квадрат.
Поэтому мы пойдем, поэтому слюшайте другой метод.
И я расскажу то, что называется фенвик фенвиков.
Нужна двумерная неявность, там нужна одномерная неявность.
Погодите, сейчас, нет, сейчас мы будем вообще хранить все более-менее явно,
но в другом формате.
Значит, смотрите, сейчас будет, вот сейчас будет то, что я называю фенвик фенвиков.
Не путайте двумерным фенвиком.
Потому что идея у меня будет такая, заведем одномерного фенвика.
Вот, ну вот, допустим, если это x, это y, то давайте вот по x заведем фенвика.
Ну, на 10 в пятый, да?
Но, но при этом, значит, что такое будет tf от x?
Значит, но для начала вообразим себе такое,
пока для начала, в итоге будет не совсем так,
но давайте вообразим себе, что в tf от x мы будем хранить множество точек.
То есть впервые в истории мы будем хранить не одно число, а какое-то множество точек.
Ну, естественно, это будет множество точек, значит,
соответственно, там pit такие, что, значит, x pit у нас лежит в хорошем полуинтервале,
то есть в полуинтервале от f от x до x.
То есть вот такая вот красота.
Вот.
То есть вот такая идея.
То есть я заведу 10 в пятый множество, и в каждом множестве буду хранить точки.
Да, множества, как вы понимаете, пересекаются.
Ну и, конечно, они разные по размеру.
Где-то лежит много элементов, где-то лежит мало элементов.
Но как вы думаете, каков суммарный размер этих множеств?
Да.
Суммарный размер, очевидно, n log n.
Просто потому, что каждая точка лежит в не более чем логарифме таких множеств.
Понимаете, да?
Ну вот, удобно, правда?
Вот, удобно?
Отлично.
То есть в каких-то множествах лежит так.
Ну а теперь идея такая.
Что мы будем делать дальше?
Значит, следующая идея, конечно, уже банальная для нас,
она будет заключаться в том,
что мы, конечно же, задачу поиска суммы на прямоугольнике
будем сводить на задачу поиска суммы на, так сказать,
префиксном прямоугольнике, да?
И будем их 4 раза запускать.
Понимаете, да?
Никогда такого не было и вот опять.
Ну, естественно.
Ну вот, как-то у нас нередко бывает.
Вот.
Значит, как теперь искать это на префиксе?
Ну идея очень простая.
Значит, тут у нас есть подотрезок от 0 до x,
тут от 0 до i.
Значит, этот отрезок мы разбиваем
на вот такие фенвиковые отрезки.
То есть это x, это вот понятно, f от x, это f от f от x.
Ну вот это там f от f от f от x, ну и так далее.
Понимаете?
И теперь у меня идея, что...
Ну теперь у меня захочется понятно,
что для каждого подотрезка мне захочется залезть в tf
от него и найти сумму тихой.
И найти сумму чисел на всех точках,
которые туда попали,
но при этом они еще и должны попадать вот в этот прямоугольник.
Так, ну думаю, кто-то...
Думаю, многие из вас уже пробили,
что я буду делать дальше, да?
Вы сказали да-да или дэ-дэ?
Нет.
Нет, идея очень простая.
То есть внутри каждого множества
я буду точке, отсортирую точки по y.
То есть внутри одного множества, да,
мне будет уже начхать на x,
главное, я их отсортирую по y.
И на этом массиве
забабахаю фенвика размера, вот сколько там точек.
Вот.
Поэтому я это называю фенвик фенвиков.
Работает это тоже за лог квадрат,
ну потому что у нас лог фенвиков,
в каждом из которых мы работаем за лог.
Ну и если нам надо поменять значение в точке,
то нам нужно пробежаться по логарифму фенвиков,
в каждом из которых за логарифм поменять.
То есть вот это считается таким классическим решением этой задачи,
где вот у нас асимптотика на запрос
o от лог квадрат n.
Все, сколько времени?
О, нормально, отлично.
Так что вот это называть фенвик фенвиков,
это полезная технология, так что вот,
рекомендую поуметь.
Вот, понятно?
Вот такая красота.
Чего, когда вы меняете число?
Нет, да, но одна точка находится не в одном фенвике,
а в логарифме фенвиков.
Ведь эти же полуинтервалы, они же не пересекаются,
вот эти вот, этих логарифм.
То есть получается вы как бы глобая, да,
то есть вы пробегаете, то есть получается фенвик-фенвик,
потому что как бы у вас дерево фенвика,
в каждой ячейке которого находится тоже фенвик,
причем свой, локальный, там, свой глубоко локальный.
Вот, но пожалуй, знаете, Сергей, да, ну обычно, да,
на этом в общем-то и заканчивается то,
что я обычно рассказываю про дерево фенвика,
хотя я не знаю, может я что-то забыл,
может с фенвиком что-то еще делать.
А, нет, ну обычно, а, ну ладно, посмотри,
если останется время, есть, конечно,
такая штука, как казахский фенвик.
Нет, казахский фенвик, как говорят,
это решение последней задачи вашего ДЗ,
но используют только мапчики и фенвички.
А мы здесь нигде, по сути, явно не пользовались тем,
что это фенвик.
Ну да, да, внутри, но нет, не совсем,
ну внутри вот этого глобального фенвика
вы можете, во-первых, забабахать дерево отрезков.
Это раз, а во-вторых,
в принципе, на этих десяти пятый
вы вместо дерева фенвиков можете забабахать дерево отрезков.
То есть будет такое дерево отрезков, дерево отрезков.
Вот, кстати, интересный момент,
вот знаете, я вот часто люблю говорить,
что дерево отрезков, с точки зрения теории, не нужно,
как и дерево фенвика.
Так вот, на самом деле, это не совсем так.
Ну, потому что, смотрите,
просто у дерево отрезков и дерево фенвика
есть одна маленькая приятная вещь,
стабильность структуры.
Потому что всяких вот авиалек, да,
вы никогда не можете гарантировать,
а кто у вас находится в корне, правда?
То есть в корне может быть кто угодно.
Вот, а там в каком-нибудь сплее дереве,
ну, вообще кто угодно.
Соответственно.
Ну, и в дикартеачке тоже там от рандома зависит.
Но периодически вот встречаются вот подобного рода задача.
Вот, видите, мне здесь жестко пользуемся тем,
что вот у фенвика или там дерево отрезков
структура никогда не поменяется.
А у вас будет какой-нибудь типа скейпгоат 3?
Чего? Кто?
У вас будет какая-нибудь гадость типа скейпгоат 3,
которая без поворотов балансирует самортизированное?
Ух ты, скейпгоат 3?
А что это?
Ну, типа, когда мы добавляем вершинки,
мы их сначала подвешиваем, подвешиваем, подвешиваем,
пока можем.
А как только разбалансировалось достаточно сильно,
говорим, ну, в топку это под дерево,
и перестраиваем его заново в виде идеально сбалансированного.
О господи.
Ага.
Да, и это прям официальное название структуры.
Вроде так оно называется, да.
Ну, ладно, если такое есть, пришлите,
это будет очень интересно, да.
Хотя, да, скейпгоат, да, скейпгоат, господи.
Нет, конечно, да, технология с перестройками,
это, конечно, всегда хорошо, да.
Да, ну, правда, это называется, а что такое слишком сильно?
Потому что, как бы, если каждый корень раз перестраивает,
то, как бы, мы такое даже уже обсуждали.
Вот, как балансировать?
Правильно, да, за корень, да.
Так, ну, а теперь, смотрите, ладно,
про фенвика, как бы, все обсудили,
но, тем не менее, конкретно у этой задачи есть другое решение.
Я, конечно, обычно рассказываю в курсе геометрии,
но оно, конечно, уместнее здесь.
О, скейпгоат.
Ага, классно.
Так вот, поэтому, значит, забыли о фенвиках,
это, слушайте другой метод.
Сейчас будет вообще другой метод
с вообще неожиданной асимптотикой.
Ладно, кто знает, не палите.
Вот.
Это ожидаемая асимптотика.
Значит, смотрите, обычно на таких задачах,
обычно на таких, ну, просто в одномерном случае
на подобного рода задачах, вот какой-то дерево отрезков, да,
и, как бы, к каждой точке мы там аккуратно как-то спускаемся.
Так вот, идея такая.
А давайте-ка, ну, давайте я тут побольше точек нарисую.
Ну, мы запомнили, что на каждой есть число.
И давайте попробуем построить
какой-нибудь аналог дерево отрезков.
Как он будет выглядеть?
Значит, идея такая.
Так, ну, во-первых, давайте разделим эти точки
на пополам какой-нибудь вертикальной прямой.
Ну, пока можем для простоты считать,
что все точки там различны по иксу и различны по икаку,
хотя в реальности там на самом деле просто,
если там на медианной вот этой вот половине
будут там, будет слишком много точек,
то значит, какая, до какого-то момента они будут
отправляться влево, а после этого момента вправо.
Вот, понятно, да?
Вот.
Значит, смотрите.
Значит, вот разделили эти точки.
И как бы говорим теперь, что у нас есть,
вот был корень, который отвечал за все,
а теперь у него есть левое и правое под дерево,
которые отвечают вот за, так сказать,
эту половинку эту, то есть вот за вот эти точки
и за вот эти точки.
Понятно, да?
Теперь следующая идея.
А теперь каждую из этих половин
мы тоже поделим пополам,
но делим пополам по количеству точек, а не по площади.
Поэтому вполне вероятно, что прямое разделение
у вас пройдет в разных местах.
Во.
Но очень важно, что разделять мы будем не по иксу,
а на этот раз по игроку.
Вот, понятно, да?
Вот, понятно?
Не слышу.
А вот принципиальная разница.
Потому что, видите, у нас как бы получается отсечка
и по иксу, и по игроку.
Да.
Ну, да.
Такой типа, еще скажем так,
еще может быть у вас ассоциироваться
с понятием двумерное ДО.
А это типа 2D3, как это называется?
Это называется 2D3.
Оно же известно как КД дерева, на самом деле.
Да, потому что дальше каждую следующую иксу
мы тоже будем делить напополам,
по точкам, обратите внимание, да?
Ну, там мы, например, ну, ладно,
пока мы теоретики, нас устроит вариант,
что, ну, как бы вы же медиану, что по иксу,
что по игроку можете найти, правда?
Вододерево называется?
Да.
Да, по факту, да.
У вас там вот этот уголочек зеленый нарисован.
Нет, этот зеленый уголочек, он случайный, да.
Никакого.
Да, и все, и фенвичков этих тоже мы забыли.
Технология будет базироваться вообще не на этом.
Вот, ну и дальше, соответственно, там распиливаем,
но, естественно, когда у нас в прямоугольнике
осталась всего одна точка,
то, естественно, мы, там, как бы, поезд дальше не идет,
естественно, просьба там, соответственно,
остановить рекурсию.
Вот.
Вот такая красота.
Ой, прям совсем красота получилась, ну ладно.
Вот.
То есть, идея такая, то есть, что, то есть,
получился такой аналог дерева, да?
То есть, тоже мы, как бы, только каждый раз,
то есть, каждая вершина отвечает теперь не за подотрезок,
а за под прямоугольник.
В общем, под прямоугольник можно хранить прям в точности,
потому что каждая вершина знает,
за какие точки она отвечает.
Поэтому для всех этих точек можно хранить,
когда минимальный х, ну, в общем, короче, их bounding box
легко хранить, правда?
Ну и дальше.
И дальше технология очень, ну дальше прям буквально
будет работать, как в дереве отрезков.
То есть, да, именно, мы на каждом вот этой вершине храним
честно сумму всех чисел, чисел всех точек,
которые в них попадают.
И делаем прям буквально нет.
Это, я говорю, это квадродерево.
Это аля квадродерево?
Нет, нет, квадродерево, это если вы там делили
на четыре части и там когда-то отсекались.
Ну да.
А это 2D-дерево, это другое.
Мы спускаемся рекурсивно, пока нам нужно.
Да, но оговорка, в квадродерево вы, как бы,
честно на четыре части делите прям вот как плюсик.
А тут каждый раз, каждый раз делите пополам,
причем независимо и в разных местах.
Ну, это понятно.
Да, это важно.
Сейчас мы храберат делим пополам.
Да, ну понятно, плюс-минус один.
Ну понятно.
По очереди.
Это на четных уровнях по вертикали,
а на нечетных по горизонтали.
То есть нам прям принципиально, что мы меняем.
Это очень важно.
Кстати, в более мерных аналогах, например,
вы будете просто по циклу проходить по всем координатам.
Там x и z, там x и z, x и z, x и z.
Вот.
То есть заметим, кстати, у этого решения есть
даже преимущество по сравнению с деревом Фенрика.
Потому что эта штука будет работать,
даже если у вас будет присваивание на под прямоугольнике.
Кстати.
Но вы еще не сказали, как она будет работать?
В смысле?
Ладно, мы просто рекурсивно опускаемся по...
Нет, просто, нет, смотрите, делаем,
нет, все делаем прям буквально как в дереве отрезков.
То есть у нас хранится вот прямоугольник,
на который мы хотим что-то сделать.
Значит, мы пришли в вершину.
Если вершина с нами не пересекается,
то до свидания с нулем.
А если у нас полностью входит,
значит тоже выбрасываемся, но уже с хранимой суммой.
Ну пишется прям вообще практически как дерево отрезков, в общем-то.
Вот.
Ну вот, а в противном случае, если там вершина пересекается,
ну значит придется запуститься от двух детей рекурсивно что делать.
Ну да, то есть теоретически это может быть и из-за n.
Ну да.
Вот самое интересное, да, самое веселое в этом месте,
за какую асимптотику на каждый запрос это работает.
Мечты, мечты, да.
Значит, смотрите.
Ну там как пойдет, они там все будут отсекаться.
Поэтому, значит, смотрите.
Сейчас я вот покажу технологию, как можно вычислить асимптотику.
Значит, как я тут обычно вычисляю асимптотику.
Значит, смотрите.
Я думаю, интрига будет, конечно, держаться до последнего.
Но на самом деле, смотрите.
Так, ну во-первых, начнем с того, что время, которое мы ищем, это t от n.
Значит, смотрите.
Но t от n будет, смотрите какой.
Значит, как я буду его хранить?
Значит, я буду, значит, смотрите, я буду рисовать вот такую диаграмму.
Диаграмма, вот такая диаграмма будет считать,
что, вот смотрите, я буду зелененьким рисовать запрос,
а красненьким рисовать вершину, в которой мы сейчас находимся.
И вот t от такой диаграммы будет означать, что у меня,
ну вот, что у меня, соответственно, там мой запрос входит внутрь,
внутрь вершинки, в которой я сейчас нахожусь.
Значит, t от n, чему оно равно?
Ну, когда вы попилите этот запрос на два,
а вы его по-любому попилите, у вас может быть два варианта.
Ну, когда вы его решили попилить, да, вот давайте я вот тут погромче нарисую.
Так, вот.
Значит, когда я тут решил попилить, то у вас два варианта.
Либо я как бы пройду мимо, и тогда, значит, выброшусь за 1, да,
из одного из рекурсий, либо я вот попилю здесь.
Но тогда у меня будет, да, уже два рекурсивных нетривиальных запуска,
но при этом обратите внимание, но при этом в обоих уже,
как бы мы знаем о пересечении чуть больше.
Понимаете, да?
То есть я буду рисовать, то есть у меня два варианта.
Либо я сведусь к такому же случаю, но от n пополам.
Либо...
Сейчас.
А, если... сейчас, что?
А разве не просто вот, ну...
Нет.
Ну, нет, как бы мы ж в этом случае влево-то пойдем,
и тут будем это ответ искать, куда ж мы денемся.
Если у нас распил проходит не по нам...
Не по запросу, да, то значит...
Либо сразу выходим и возвращаем ответ, либо сразу выходим...
Нет, нет, это если, нет, как бы такой выбросу от единицы,
это будет вот в таком случае.
Ну вот у нас там вторая тэшка, она...
Что у вас что обозначает?
Ну зеленая это запрос, а вот эта красная это вершина.
То есть поэтому пилем мы вершину.
То есть она либо не пересекается, если содержится то одного,
красная...
Нет, если содержится, то один рекурсивный вызов такой же,
если не содержится, то от единицы.
Если мы содержимся в запросе, то один?
Да.
Если не содержим запрос.
Вот, то зачем от него честно рекурсивно запускаемся.
От кого?
Ну от этой вершины, в которой нас запрос содержится.
Слева справа или справа?
Ну слева справа не принципиально.
Потому что все равно он будет один.
Ну симметричность лучше будет.
Нет, ну вот если не пересеклось с разрезом, то один.
Потому что второй у нас как бы будет не пересекаться,
и мы выпустимся с разреза.
Да, мы запустимся от того, кто содержит вот эту вершину.
Ну да.
Запустимся от обоих.
Другой вопрос, что если мы быстро выясним,
что вершина не пересекается с запросом,
то мы просто выбросимся за от единицы.
Ага, и поэтому мы ровно от одного ребенка запустимся?
Да.
Но это если разрез не пересекает запрос.
Если пересекает, то рекурсивных запусков нетривиальных будет два,
но я их нарисую вот таким интересным образом.
Ну то есть да, на самом деле там они конечно,
будет один слева, один справа,
но заметим, что мы как бы дальше будем делить по игроку,
поэтому целесообразно как бы повернуть картинку там на 90 градусов.
И оба раза получится, как бы смотрите,
что у нас есть вершинка и прямоугольник запроса,
точнее та часть, которая внутри находится,
но мы можем всегда пересечение хранить,
она как бы прижата к нижней части,
ну может быть к верхней, но это точно симметрично.
Ну или к левой и правой, но видимо...
Нет, ну смотрите, проблема такая,
что когда я тут смотрю, я подразумеваю,
что я как бы первое деление буду проводить по иксу.
А где будут варианты?
Ну в расположении запроса.
Ну у нас же может быть и второе деление.
У нас же может быть и второе деление,
если мы второй раз так делаем, то мы уже по им границам.
Сейчас, нет, ну подождите,
смотрите, когда вы здесь поделили,
то как бы, когда вы вот так здесь поделили,
вы находитесь как?
То есть у вас как бы одна часть прижата к левой части,
другая к правой, да?
Но на этом уровне рекурсии вы как бы пошли
теперь делить и по игроку,
поэтому давайте поберем картинку на 90 градусов.
Да, на той террации мы могли делить и по игроку.
Нет, на этой мы будем считать, что по иксу.
Без границ меня, в общем-то.
Ну и здесь просто сведем к по иксу,
просто поворачиваем на 90 градусов,
ну там можно, то есть на самом деле один снизу,
один сверху, но это будет одно и то же.
Но правда с этой точки зрения оказывается,
что снизу сверху это одно и то же,
слева справа это одно и то же,
но снизу и слева это не одно и то же, очевидно.
Ну да, то есть короче мы сначала вращаем тот прямоугольник,
чтобы разрез проходил вертикально,
а после этого мы понимаем,
что тогда следующий будет...
Точнее так, мы делим вертикально,
а потом оба эти поворачиваем на 90 градусов,
чтобы разрез тоже был для них вертикальный.
Да, это нас сокращает количество случаев.
Снизу и слева это не одно и то же.
Что?
Снизу и слева это не одно и то же.
Ну потому что когда он будет снизу или сверху,
мы как бы делить будем вот так,
а когда он будет слева, то мы как бы будем делить
и там просто другие картинки будут возникать.
Сейчас мы это увидим, смотрите.
Ну во-первых, давайте,
когда появилась новая рекуррента,
давайте расписывать ее.
Оп-оп-оп-оп-оп-оп.
Значит, t от n, ну я буду все от n писать, равно.
Ну и здесь два варианта,
либо распил пройдет мимо этого зубчика,
и тогда этот зубчик повернется на 90 градусов.
То есть получится t от,
короче, n пополам плюс o от единицы,
но этот зубчик будет находиться,
ну там либо слева, либо справа,
но это одно и то же.
Если распил прошел мимо него.
Да.
А если не мимо, то на самом деле будет 2t от уголочка, да.
Так.
Так, классно, у нас появились две новые рекурренты.
С какой начнем?
Ну, очевидно, что вот вторая рекуррента,
она симметрично наша.
Вот это?
Какой?
Не факт.
Чего?
Ну, потому что если распилить вот так вот,
то вот получится уголочка.
Что за издевательства?
И что сразу издевательства?
Так, ладно, у нас появились две новые рекурренты.
С первой начнем.
Ну да, лагит, ну ладно, да.
Да нет, там, ну господи.
Вот.
Значит, поехали.
Чего?
Вот это?
Не факт.
Ну, потому что разделять-то мы будем строго вот так по иксу.
И получится, смотрите, два случая получится.
Либо разрез опять прошел мимо,
и мы снова свелись к уже вот такой рекурренте.
Будь здоров.
Так.
Либо.
О, ребят, смотрите, сейчас вообще весело будет.
Так, и распил вот здесь.
Тогда здесь оказывается следующее.
Тогда получается, значит, здесь, ну когда мы тут поворачиваем,
значит, что у нас тут получится?
Получится вот примерно вот такая штука.
Да, ну как бы.
Пока вроде да.
Но при этом во втором рекурсивном запуске появляется уже полюбившийся нам зубчик.
Вот это вот штука, когда у нас много границы, по какому-то направлению задется.
Это можно, кажется, оценить.
Ну вот.
Ну там аккуратненько надо будет делать, поэтому на всякий случай пока так распишем.
Ну пока мы уже можем как бы в принципе сказать, что вот это вот мы можем в принципе из
рассмотрения выкинуть, потому что вот эта рекуррента вот эту по любому мы жерирует.
Ну понятно, схема будет понятна, что мы там будем потом доказывать, что каждая T не
превосходит, ну там чего там она не будет превосходить, мы пока не знаем.
Ну вот.
Но как бы очевидно, что в доказательстве по индукции там понятно, что если это
докажем, то и это упадет само.
Поэтому можно считать, что тут случай один.
Так.
Что дальше?
Дальше уголочек.
Так, поехали, уголочек.
Так, ну тут тоже на самом деле два случая.
Но на самом деле заметим, что в обоих случаях будет уголочек, вопрос только в том,
будет ли уголок кроме уголочка что-нибудь еще или не будет.
Поэтому давайте так, я этот случай даже писать сразу не буду.
Поэтому честно напишу самый интересный случай.
А интересный случай звучит так.
Значит тут получается примерно вот такая уже штука.
Так, ну здесь уголочек никуда не делся.
Так, идем дальше.
Значит так, с уголочек расписали.
Так, что у нас там дальше идет?
О, дальше идет вот этот вот красивый вертикальный полоса.
Да, он красивый.
Так, настолько красивый, что я давайте вот это все сотру.
Так.
Так, сейчас это мы стираем.
Так, так, так, так.
Значит он...
Так, значит смотрите.
Так, Т от этой вот полоса.
Какая-то просто полоса.
Так.
Чего, что не так?
А это работает значит...
Так, вот тут нам принципиально распил произойдет по полосе или мимо полосы.
Потому что, если он пройдет мимо полосы, то получится очевидно Т от горизонтальной полосы,
получается теперь.
И плюс тому от единицы какой-то.
Либо распил произойдет по полосе, и тогда у нас получится два Т от...
Кстати, от того, чего у нас опять еще не было.
Вот такой красоты.
Спасибо, Господи.
Ой.
Так, ладно.
Так, бфэсимся дальше.
Так, что мы еще не...
Так, что мы еще не расписывали?
Так.
А, этот зубчик мы расписывали, уголочек расписали.
А, получается вот эта штука у нас дальше идет.
Можно пока сделать...
Нет, у нас еще не было полосы горизонтальной, которая вот там была.
Вот эта?
Нет, пройдем.
Но сначала у нас еще вот это не было, поэтому все постепенно.
Спасибо.
Ну как бы, раз уж мы тут в порядке...
Раз уж мы завели структуру данных очередь.
Так, значит смотрим.
Вот.
Так, ну здесь на самом деле тоже становится достаточно приятно.
Потому что заметим, что распил тут устроен так,
что как бы у нас либо пустая ячейка пойдет в ноль,
либо полная ячейка пойдет в ноль, да?
Ну не в ноль, а там в единицу идет.
Поэтому получается железобетонная ситуация,
когда у вас будет Т от Н пополам плюс О от единицы,
от ячейки вот такого красивого рода.
Ой, как удачно.
А можно вопрос?
Почему с права у нас не повернулись?
Последний.
Что там?
С права, в последней строке,
у нас же должны были повернуться и стать горизонтальными.
Справа где?
Вот здесь?
Нет, но повернулась, потому что когда вы тут распилили,
у вас тут была полоса как бы отсеченная по вертикали,
поэтому она повернулась, стала отсеченной по горизонтали.
А тут еще остался угол.
Ну да, этот угол, конечно, должен быть немножко может быть в другом месте,
но там в каком из четырех мест угол, на самом деле, неважно.
Это называется 2D-дерево, а не дерево разбого случая.
Это называется доказательство 2D-дерево.
Точнее, выводы симпатики.
А это же...
Это же даже не близко доказательства общего случая.
Не близко.
Я честно говоря, я доказательства общего случая не знаю,
но я призываю, что общий случай, наверное, как-то обобщает это все.
Аккуратненько.
Разбирает случаи, да, опять.
Разбор случаев кажется совсем немного,
но вот глобально, что у нас происходит?
У нас либо что-то отсекается,
мы просто испускаем рекурсивный вызов от этого пола,
либо у нас одна из сторон,
как будто бы, ну, почти всегда у нас одна из сторон
просто добавляется в количество прижатых сторон
без нашей возможности.
Кроме одного единственного случая,
когда мы подряд отсекаем сначала одну сторону
и противоположную ей там сверху, и с другой стороны.
Я просто как-то...
Я не могу сейчас нормально это промализовать,
но на самом деле...
Сделать типа один вариант.
То есть количество прижатых сторон
либо не меняется,
мы идем только в одну ветвь,
либо увеличивается на одну ветвь.
Ну вот, хорошо, давайте это добьем, и там уже...
Чуть аккуратнее, потому что прижатые стороны может быть...
Ладно.
Прижатые стороны может быть там примерно посередине,
потом в углу, а потом вся сторона.
Значит, смотрите, так, что мы там дальше должны?
Так, дальше у нас идет горизонтальная полоса,
но здесь, слава богу, все в порядке.
Потому что это 2t от вертикальной полосы,
а то он пополам.
300 единиц.
Так, хлоп-хлоп.
Так, что там у нас осталось?
Так, у нас еще осталось что-нибудь?
А, у нас осталась еще вот эта штука.
Давайте t от вот этой вот красивой штуки, штукенцы.
А t равно у нас чему?
Не слышу.
Я вас не слышу.
Да пытаться-то всегда можно.
Так.
Так, ну давайте так.
Так, правильно ли я понял, что у нас все это...
Рекуренты закончились.
Так, ладно.
Давайте, есть ли у нас рекуренты,
которые еще надо раскручивать?
Или все, система замкнулась?
Так.
Стоп, вот это мне не нравится.
Где?
Что тебе не нравится?
Нет, что?
Тут распилы однозначно идут.
Вот так и вот так.
Мне не нравится, что она в два переходит.
Ну в два.
Но при этом ее состояние не меняется.
Ну как не меняется?
Поворачивается.
В плане мы можем так рекурсить.
А теперь смотреть.
Так, ладно.
Так.
А чего нам не хватает?
Типа не только адена еще не знаю, а...
Нет.
И сведение с Терон, чтобы он уже вычислялся.
Типа каждый...
Да нет, смотрите.
Типа за два шага уменьшаем все в три раза.
Что такое?
Ой, сейчас.
Так.
Ну давайте думать.
Кажется, на два раза...
А вот там справа, по случаю, с уголком...
Где?
А после повернули...
Ну рядом.
Ну а если мы рядом прошли, то останется только вот это и это,
это будет мажорироваться.
Вот я тут имел в виду, что тут должно быть вот это,
потому что у нас такая ситуация уже встречалась.
Ну было бы, типа, то же самое, но без этого.
Ну кому это надо?
Вот сверхоригинальная удавка из капронового волокна.
Так.
Как говорится, пальчики оближете.
Значит, смотрите.
Так, ребят, смотрите.
Смотрите.
Сейчас будет немножко магии.
Так.
Система рекурренции замкнулась.
И мы можем начать, кажется, собственно, нормально жить.
Так, ну давайте начнем с того, что избавимся от вот этой.
Так.
Нет, ладно, избавляться от нее не будем.
А сразу заметим следующее, что вот в эту штуку можно сразу подставить вот эту.
Видите, да?
Понятно, что это на самом деле равно чему?
Это равно 2t от того же самого, но n поделить на 4 плюс o от единиц.
Опа.
Ой, сюрприз.
Это равно 2t от того же самого от n делить на 4 плюс 1.
Опа.
Так, то есть веселое время, да?
2t от n равно 2t от n делить на 4 плюс o от единиц.
Так, задачка есть там первая, из первой семи.
Ставим два линии первой лекции.
Может, второй.
Чему равно t от n?
Но если я все это умею считать, то это корень.
Да, это...
Да, да, да.
А кто-то прям вообще был в шоке.
Но да, это...
Но это n в степени 2 поделить на 4 равно t от корень из n.
Ну вот, факт остается факт.
Ну что делать, знаете?
Ну знаете, да...
Нет, ну знаете, что делать, когда там...
Для того, чтобы понять, как устроен мир, вы там отправляетесь
в какую-то эпическую экспедицию, и результатом этой экспедиции
узнаете, что на самом деле вы существуете только там в компьютере
какого-то нерадивого студента, которому дали задание
проимулировать жизнь.
Ну там есть такой красивый рассказ.
Так вот откуда столько бара.
Ну да.
Так там был такой человек, да.
То есть там студент был таким не особо хорошим физиком, но хорошим программистом.
Поэтому забабахал какую-то физику.
То, что происходит на длинных меньше 10-9.
И так, ладно, закидаем рандомом.
Ну и так далее.
Вот.
Ну там отдельно рассказ могу...
Идея интересная, реализация, к сожалению, не очень.
Но вот...
Но прикольная хотя бы идея.
То есть, в результате, кончилось тем, что вообще очень грустно,
что цивилизация по ее меркам миллион лет жила,
а потом...
Умерла на том, что диск формат нули.
Ну в итоге-то да.
Хотя картинку оставил, потому что это было грустно,
потому что там какой-то товарищ научился жить вечно.
Но как бы и в результате сделал просто меропроект максимум, что мог сделать.
То есть он полностью разобрался в мире
и там переставил звезды таким образом, чтобы на рабочем столе они выражались просто в такую огромную на весь экран фразу.
Твой быдлокот нас огорчает.
Вот, кстати, так и гуглите.
Так рассказ и называется.
Твой быдлокот нас огорчает.
Вот очень рекомендую на самом деле, да.
Нет, на самом деле, конечно, это очень грустно, да, потому что...
Конечно, да, что вся наша жизнь это просто курсовая работа раздолбанного студента, да.
Что?
Ну, не знаю.
Ну, как сказать?
Ну в дачном мире это означает, что в любой момент времени крышка ноутбука может быть захлопнута.
В смысле?
Мы делаем бэкап.
Мы не делаем бэкап.
Мы внутри.
Мы живем в бэкапе.
А в трехмерном случае там вообще получится что-то другое?
Ну, пока не знаю.
Ладно, давайте тут добьем вообще.
Как бы корень и зен, это вот это вот корень и зен.
Вот давайте разбираться.
Так, вот это вот корень и зен.
И вот это автоматика.
И вот это корень и зен.
А теперь давайте разберемся.
Я думаю, что мы можем с верхней разобраться.
Так, ну давайте разбираться.
Так, нет.
Ну, смотрите, не совсем.
Вот здесь мы можем сказать, что в этом случае корень и зен.
А вот в этом не факт.
Повторить, пожалуйста.
Как мы говорим по очереди?
Ну, смотрите, потому что вот здесь мы вот это раскрыли по этой формуле.
И получилось, что t от n, вот от этого равно 2t с той же самой картинкой, но от n делить на 4.
И все еще плюс о от единицы, но там чуть более жирных.
И получилось вот такая рекуррента.
Сейчас мы можем заменить вот там вот сверху такой палки.
Ну да.
То есть на самом деле да, мы можем тоже сказать, что если вот по этому случаю пошли, то получится 2t от вертикальной полосы, n делить на 4 плюс о от единицы.
И там по аккуратной индукции тоже вывести, что это тоже корень.
То есть как бы либо мы сразу получим корень, либо круты рекурсию, которая сама нам дает корень.
Вот.
Ну там можно аккуратно по индукции уже расписывать, что это корень.
Так, ну и как вы догадываетесь, ну это автоматически тоже корень.
Но притем дальше, по-моему, там сопротивление начинает быть уже более-менее бесполезным.
Вот.
Ну потому что вот в этой ситуации очевидно, что у вас тут корень плюс какой-то рекурсивный запуск.
Ну здесь понятно будет корень из n плюс корень из n пополам, плюс корень из n на 4 и так далее, если расписывать это прям до упора.
Ну вот, поэтому это автоматически.
Поэтому пока не интересует корень из n.
Так, ну вертикальная полоса у нас теперь тоже корень из n.
Поэтому получается опять, значит, что тут получается?
А, ну здесь смотрите, здесь тоже как-то аккуратно получается, что тут как бы этот зубчик это вот корень из n плюс зубчик.
Ну вот, а зубчик либо сразу выдает вам корень, либо вы сводитесь к себе g.
Да, то есть опять получится корень из n плюс g, и там получится тоже и тут корень из n, короче, и тут корень из n.
Ну и как вы догадываетесь?
Ну тут тоже, видите, до какого-то момента спуска не больше, чем логарифм шагов, и после этого корень.
То есть получается, ну вот, то есть мораль.
Да, то есть это было абсолютно непредсказуемо.
Оказывается, что у нас t от n равно t это от корень из n.
Оказывается, что лучше было писать корневуху.
Ну вот, ну я не знаю, я не знаю, как ты тут будешь писать корневуху.
Типу фен, видите, построить на блоках по корням.
Ага, разобьем точки на множество по корень, в каждом из них, а в каждом из них попытаемся что-то там, да.
В общем, я боюсь там, да, напрямую.
Слушайте, когда дерево работает за корень катой степени или n-кодат.
Нет, скорее, на целик на n-коди.
В общем, там в общем, значит...
Может быть с n-коди или 2-коди степени каты?
Нет, там...
Да, вот, n-коди.
Да, в демерном случае на самом деле вот так.
Ну, кстати, да, сколько у нас времени есть?
Потому что мы до раз проведем.
О, кайф, ой, кайф, время еще есть, давайте думать.
В демерном случае оно обретает смысл какой-то, что мы такое делаем, что...
Оно теряется.
Да-да, делаем не за ОАТН, а за ОАТН, да, вот в такой степени, да.
Не, ну это меньше, чем n-код будет, да.
Там константа, скорее всего, такая будет.
Ну, это понятно.
Ну, а вы когда последний раз это делали в шестилетии?
В шестилетии.
В шестилетии.
В шестилетии.
В шестилетии.
В демерном мире, да.
Константа как раз не должна быть большая, мы просто проходимся, но у нас рекурсия...
Но не совсем, знаете, константа, когда у вас шестимерный массив, она жирная.
На практике оказывается, что константа от собственного вот этого по счету шестимерного индекса оказывается больше, чем если бы этот шестимерный массив хранили в одномерном и вычисляли бы индексы ручками.
Нет, базируясь на своем опыте, я говорю, у меня была ситуация, когда я написал пятимерный массив.
Задача получала ТЛ.
Вот, ТЛ был 15.
Я заменил пятимерные индексы на одномерные индексы, ну там честно ручками прям расшифровывал, там 1 в 5, 5, 1.
И получил окей, причем зашло за время 9, точка там бла-бла-бла.
Если вы сдавали на Яндекс.Контесте, это ни о чем не говорит?
Да, но если мне не изменяет память, я сдавал на Код Форсисе.
Жалко, жалко.
Да, Як умеет в 3 секунды.
Вот, а так вот действительно можно додуматься. Интересно, вот да, потому что, потому что возможно да, то есть я тут конечно расписал прям максимально скрупулезно.
Но теперь да, но вот какая-то идея, вот можно оставшиеся 10 минут подумать действительно.
А нельзя ли этот одализ действительно упростить?
Ну я так понимаю, мы типа, мы каждый раз либо витруемся один раз, либо витруемся два раза, но переходим в следующую категорию состояния.
Их там порядка D в какой-то степени, или там 2 в степени D, ну D короче маленький.
2 в степени D скорее всего.
Ну да, и потом короче мы приходим в итоге вот в такую категорию, что каждый раз когда мы проворачиваемся D раз, у нас идет один рекурсийный вызов, а остальные два раза.
Ну да, ну можно да.
Можно получить вообще типа сразу просто вверх на последние параметры.
Ну снизу да.
Ну да.
А, ну типа если вам сразу запрос вот такого вида, то вы как бы уже на него отвечаете за кое-что.
Ну вроде более-менее очевидно, что мы можем его построить.
Ну типа того да. Ну да, то есть получается, что да, что как бы лучше мы не получим, да.
Да.
Нет.
Нет.
Зачем?
Не надо.
Потому что, не, ну не совсем.
Не, ну...
Нет, там просто получится, что скорее всего там просто в глубину мы будем идти там, то есть на какой-то такой полосе мы туда будем идти там скажем на глубину, там на какую-то глубину D, то есть D поворотов.
Там у вас как бы получится, да, два в степени D, значит слагаемых, одно из которых отсечется.
И получ...
А D в степени D.
Нет, там два в степени D.
Ну вот.
Ну давайте так, смотрите.
Так, ладно, тут все понятно, смотрите.
Значит, смотрите, давайте попробуем проанализировать инмерный случай.
Кажется вроде, вот конкретно сейчас у меня начинает уже ощущение, что не убой, вроде как.
Не убой?
Не убой.
Ну вот.
Ну, можно, конечно, отдельно посмотреть.
Да.
Но давайте смотреть.
Мы введем такое понятие, как, значит, T с индексом, значит, с допустим индексом K от N.
Что это означает?
Это означает, что в подпрямоугольнике, то есть допустим...
Вот как бы это сформулировать-то, а?
Ну ладно.
Как бы сформулировать камерную картинку из головы словами, да?
Ну да.
Нет, ну просто видите, у нас тут...
Нет, просто видите, у нас сколько картинок получилось?
Ну вот.
Ну да.
То есть там...
Обычно получается у нас что-то типа...
Каких-то там...
Что-то типа 9 картинок.
Вообще, по идее, тут должно было в двумерном случае получиться 9 картинок.
Потому что по каждому направлению...
По каждому направлению X и Y, да, мы как бы либо не прижаты вообще,
либо прижаты к одной стороне, либо прижаты к обеим сторонам.
Мы можем быть прижаты в центре стороны, с края стороны и на всю сторону.
Ну, я и говорю, то есть прижаты по направлению к одной стороне или к двум сторонам.
А вы фиксируете стороны относительно ее стороны.
Ну типа того, да.
Ну вот, хотя, видимо, у нас какой-то случай просто не произошел.
Так, какой у нас случай не произошел?
Ко всем прижаты.
А, да, потому что, да, есть когда ко всем прижата, но мы ее расписывать не стали,
потому что это вот единица все равно.
Бесполезный случай.
Так, не, ну не скажите, не скажите.
Почему?
Так.
Это самый полезный случай, наоборот, который есть, в этом он говорит.
Благодаря ему он работает.
Не, ну можно как бы так, а можно...
Нет, ну можно пытаться вообще попроще.
Изначально думал попроще, давайте так.
Давайте просто говорить, давайте считать, что нам просто...
Нам интересно только, он прижат, он как бы прижат или не прижат.
Ну хотя бы, хотя бы по одному направлению.
И пусть у нас ТК от Н будет говорить о том, что, значит, к К-сторонам,
К-направлением не прижато.
Вот давайте попробуем, вот интересно сейчас получится или нет.
И что получится?
Ну получится следующее, что когда мы сейчас запускаем от Х, то что у нас получается?
То есть либо по этому направлению произойдет распил,
и тогда что получится?
Ну давайте так.
Значит у нас, ну скажем так, по конкретно нашему направлению,
который у нас сейчас есть, там что могло произойти?
Мог произойти распил, а мог не произойти.
При этом по этому направлению уже прижато или не прижато, да?
Вот.
Получается что-то типа четыре случая.
Так, ну допустим, ну правда, если не произошел распил,
ну могло ж быть так, что как бы, ну вот, ну правда, если не произошел распил,
то в общем-то скорее всего ничего и не поменялось, правда?
То есть получится два Т от Н пополам, плюс 100 единицы,
с индексом того же самого К.
Ну того же самого, но с поворотом.
Что-то если вот прям так анализировать...
Что?
А, хотя нет, наврал.
Сейчас, наврал.
Если распила не произошло, по-моему, просто вот так даже.
Вот так похоже, на правду.
Так.
Вы уже провалились.
Ну понятно.
Давайте идти дальше.
Хорошо.
Значит, если распил произошел, то тут как бы два варианта.
Либо распил уже был, ну вот, либо распила...
Ну правда, смотрите, если распила не была, он произошел, да?
Ну да.
Нет, хотя тут как бы возникает вопрос...
Сейчас.
Потому что мы же там еще типа поворачивать будем.
А, хотя нет, какая разница?
Значит, если...
Так.
Ну да, тут же надо еще правильно вообразить себе распил.
В коммерном пространстве?
Ну да, главное распил, то есть мы делаем распил не по Х, а по всему, кроме Х.
То есть у нас такая гиперплоскость, которая как бы разделяет Х и все остальное.
Ну я вот в трехмерном пространстве вот сейчас себе воображаю плоскость.
У меня уже плоскость стала.
То есть как бы, да, если произошел...
Если распила не было, а он резко стал, то получается, что у нас там 2t от n пополам плюс о от единицы,
но на этот раз индекс стал уже резко k-минус 1.
Так, что еще могло произойти?
Что еще могло произойти?
Ну еще могло произойти, что как бы у нас по этому направлению уже прижатость.
Ну вот, и...
Кажется, что оценка лучше, чем первая мы уже не получим, и хуже, чем вторая тоже не получим.
Давайте с этим жить просто.
Ну да.
Нет, можно даже, знаете как, можно сказать даже не...
Нет, а может все-таки это...
Кажется, следующий случай будет симпатически где-то между этими двумя.
Ну, может быть.
О, или может быть, знаете еще как надо сделать?
А давайте...
Нет, а может считать, давайте так.
У нас всего из 2k направлений, ну типа там...
Ну типа вверх-вниз отличаем, да?
И говорим, что k из них не прижато.
То есть говорим, всего направлений у нас 2d направлений.
Вот.
Вот.
Тогда как бы, да, получается, что действительно если конкретный распил произошел,
то значит, наверное, какая-то прижатость определенно наблюдается.
А если, то есть, как бы, а если тут по этому направлению прижатость была,
то тогда получается, может остаться прижатость та же, да?
То есть t с индексом k, а t пополам.
Но вторая, но в этом случае тогда...
Вторая прижатость все-таки откровенно остается...
Ну да.
Так, а t пополам.
Ну и плюс 1.
Плюс от единиц.
Но это все равно, кажется, лучше.
Так, а если... ну вот.
Нет, ну на самом деле или еще...
Нет, ну там всякое могло быть, на самом деле еще могло так случиться, что...
Нет, знаете еще какая проблема могла быть?
Нет, подлянка еще заключается в том, что могло быть так,
что по этому направлению уже есть две прижатости.
То есть вот этот случай, когда у нас как бы одна прижатость.
По этому направлению.
А если у нас как бы двум сторонам прижато,
то рискует особо ничего не поменяться,
и нам все-таки придется написать вот это вот.
Вот.
Тогда нам нужно как-то аккуратно расписать,
в каких случаях это происходит,
потому что иначе в таком виде мы получаем от t.
Вот прям сейчас.
Нет.
Ну, значит, смотрите.
Нет, ну мистицизм тут обычно заключается в следующем.
А может быть мы разметнулись?
Нет, просто нет.
Фишка...
Размерность.
В смысле?
Размерность.
У нас прижато по всей стороне,
значит можно эту размерность не учитывать.
Ну как, разве не учитывать не получится,
потому что надо на двойку дом нажать.
Нет, смотрите.
Мы возьмем, мы введем параметр k и d,
и типа напишем там шаг.
Нет, там, знаете, фишка будет такая.
На самом деле как угадываете симпточку?
Ну а симпточку можно угадывать так.
То есть теперь вспомним,
что так прям до бесконечности вот эта вот рекуррента распиливаться не может.
Потому что на самом деле,
ну,
то есть там произойдет так,
что вот как бы переход каким-то более мелким случаем, да,
то есть на самом деле у вас не более,
чем задез запросов произойдет,
потому что, помните, вы же пилите все.
Ну как бы, вы же пилите не просто,
вы пилили по одному направлению туда,
но могли бы до бесконечности ходить вот в этот случай
и получать свое отм.
Ну все равно не очень понятно,
почему у нас не может быть.
Вы хотите ввести параметр?
Ну не каждый, но почти каждый случай там.
У нас почти каждый и есть,
потому что у нас 1 минус 1 dt.
Вот.
Вы хотите ввести параметр,
который говорит, на какой стороне мы сейчас находимся?
Ну да.
Нет, ну я говорю, что,
нет, я говорю, что на каждом шаге у меня как бы получается,
ну, если допустим выкинуть этот случай,
как мы жарируем и вот этим,
да, ну или там можно случай,
то я как бы, каждый случай,
у меня как бы как бы распадается на 2,
да, и на следующей глубине каждой 2 распадается точно на 2,
то есть если я сделаю глубину D,
у меня это распадется на как бы 2 в степени D слагаемых,
да, но я утверждаю,
что все они свестись в степени Tk, Tn не могут.
Почему?
Потому что это означает,
что как бы мы, ну вот,
потому что это означает,
на самом деле, что во всех запросах у нас получится
по всем сторонам прижатости,
потому что это может быть только,
когда в той стороне,
которой мы сейчас распиливаем,
у нас будет обязательно там обе прижатости события.
То есть мы сейчас получим что-то по типу 1 минус 1 делить
на 2 в степени D?
Или...
Ну сейчас давайте думать.
Потому что мы из 2D случаев выкинули.
Ну вот, нет, просто самое плохое,
что можно получить в этом плане,
это, ну вот, ну тогда получается,
давайте так, получается Tk, Tn.
Должно быть,
должно быть получается,
ну там, ну допустим так,
если это расписывать,
то у нас получится Tk, Tn равно Z какой-то там на Tk, Tn.
Ладно, вру, вру, вру,
делить на 2 степени D, конечно, да?
Плюс, ну нечто явно,
явно, плюс нечто, что там получается?
Ой, K не там написал.
Вот, нет.
Дальше получается ровно 2 в степени D минус Z,
ну нечто не больше, там 2 в степени Z,
на T с индексом там k минус 1.
Ну может давайте как-нибудь поверим,
что там, наверное, T с индексом каким-нибудь
явно мажорирует T с меньшим.
Потому что я считаю, что T с индексом k минус 1
мажорирует T с индексом k минус 2, k минус 3 и так далее.
Да, там естественно могут быть там...
То есть мы просто сверху пытаемся оценить.
Да, конечно, ну вообще мы думаем,
что мы тут можем выжить.
Ну вот, ну я просто вот утверждаю,
что вот может быть вот такое.
Ну вот, ну тогда теперь, значит,
начинаем думать, да, спрашивать,
а к чему может быть равно вот это вот там,
соответственно, T, особенно в предположении,
что это...
Ну вот, ну как бы в идеале как бы распишется вот так,
но теперь вот возникает вопрос,
а что такое Z?
Ну вот, но на самом деле можно заметить,
я утверждаю, что на самом деле утверждается,
что 2 в степени D слагаемых за D шагов не выживет.
Что-то явно отсечется и уйдет вот единица.
Ну это нас не сильно спасет.
Нет, ну вот.
Так, ну хотя, нет, хотя, нет, не факт.
Нам же надо...
Так, нет, почти, ну сейчас,
а, ну да, это будет не 1-1 делить на D,
а 1-1 делить на 2D, что ли вы хотите сказать.
В степене D у нас, да, получается,
в двумерном случае оценка 3 четверти.
Нет, ну...
Нет, ну как сказать, сейчас посмотрим.
Мы хотим в двумерном случае корень, а не...
Нет, погоди, ну давай посмотрим,
если D от N равно, допустим,
окажется там 2 в степени D минус 1,
на T, соответственно...
От N делить на 2 в степени D.
Ну да, ага.
Ну и плюс 1.
Да, вот допустим, у нас получилось такое.
Да, вот могло такое получиться, допустим.
Так, спрашивается, к чему это нас приведет.
Так, это нас приведет, что...
Нет, почему?
Нет, погоди, это придет N в степени,
логарифум по основанию...
А, кстати, я тут наврал, тут не 2 четверти.
Тут лог по основанию 4-2 вообще-то.
Да, по случайному совпадению тоже 1-2.
Так что здесь получается лог по основанию 2 в степени D,
числа 2 в степени D минус 1.
Это называется ИЧО.
Давайте положим сюда D равно 2
и увидим, что это не то, что мы доказали ранее.
Дааа...
Поэтому такая оценка нам не годится.
Да...
Чья слипа нам не нужна.
Ну окей, ладно.
Не получилось, жалко.
По крайней мере, она как минимум не точна.
Но она как минимум меньше N.
Она меньше N, но она не точна.
Наверное, но я не знаю, да.
Скажем так, сформулирую так.
Здесь я, конечно, просто ссылаюсь на книжку.
Да, кстати, литература про эту.
По крайней мере, первая про исходный метод,
но он, по крайней мере, надежный.
Или нет?
Исходный, надежный.
Ну вот.
Но здесь, кстати, книжка вообще, в принципе,
могу порекомендовать.
На экзамене же не будет KД дерева?
Как же, будет.
2D дерева.
Ну 2D, но KД дерева, конечно, нет.
Но мы его, конечно, на следующем занятии
не докажем случайно.
Вот.
А сразу так БПС захотелось?
Угу.
Мне тоже, да.
БПС.
Чего?
Чего?
Игры еще есть?
Нет, смотрите.
Нет, понимаете, дело в том, что ретроанализ,
это же он базируется на БФС.
Поэтому, наверное, логично пройти,
обсудить БФС.
Вот там просто обсуждаем БФС.
Там тоже, возможно, в следующий раз даже
не успеем теорию игр начать.
Ну, вы знаете, там в БФС есть что обсуждать.
Вы знаете?
0.1 БФС, 0.2 БФС.
Не, не в том порядке.
Не-не-не.
Не-не-не, погоди.
Не, ты не угадал.
Нет.
Там порядок другой.
Там будет так.
БФС, значит, 1К БФС там с ответвлением
в 0.1 БФС и 0К БФС.
Потом, соответственно, БФС, там 1К БФС
с дробными ребрами, значит, увеличение
кадра бесконечности, и так мы выходим
на алгоритм ДЭКСТР.
То есть ДЭКСТР это такой БФС,
на просто бесконечном числе очередей,
в котором мы не храним явно очереди.
Вот.
Нет, другой вывод скорее.
Чего?
Тихо, тихо, тихо.
Чего?
В этой книге там прям вот такое доказательство.
Ну, насколько я помню, да, ну, я же это откуда?
Ну, скажем так, я это вроде оттуда брал,
потому что откуда я еще это мог взять,
я не помню.
Вот.
Так что вот.
Нет, ну в принципе,
тут вообще могу посоветовать книжку,
если это считается одним из просто классических
таких учебников, он, конечно, относительно старый,
там 80-е годы какие-то.
Вот.
Но какая-то вообще, какая-то база по геометрии
там есть.
В общем, но правда интересно, что половину
структуры там слабо будут применимы именно
в олимпиадах в силу там непонятной какой
асимптотики у алгоритмов.
Ну вот.
Но на реальной практике геометрической,
собственно, они там будут активно использоваться.
Так что кто там занимается чем-то
связанным с геометрией, там, я не знаю,
может там, может там какой-нибудь
рисованием каких-то картинок там,
визуализация там трехмерных пространств
и так далее, это вам может очень сильно помочь.
Ну, по геометрии, а, ну я вообще,
если уж по геометрии, я всегда, конечно,
рекламирую там еще, ну там,
пока нас геометрии не будет, то к следующему
семестру вы уже можете хорошо подготовиться,
потому что, на самом деле, в интернете,
ну, во-первых, есть такая вещь, как
компьютер science club, кстати,
ну ее можно просто абстрактно
абстрактно.
Или там сокращенно, компский клаб,
в общем, погуглите там, в общем,
что-то найдете. То есть, на самом
деле, просто в Питере есть вот такой
компьютер science club, в котором, ну,
можно сказать что-то, сейчас, сейчас,
что-то типа шада. Ну, это что-то типа
шада, ну вот, и там, собственно,
проводится огромное количество лекций,
в том числе, кстати, и там знакомые
преподаватели тоже найдете, ну и в том числе
не знакомые. Ну вот, но там есть какие-то
видео лекции каких-то старых курсов,
и вот тут, с точки зрения геометрии,
крайне рекомендую познакомиться с
таким замечательным человеком, как
Кира Вяткина.
Вот. То есть, это вот абсолютно, это
абсолютно реальные ученые в области
вычислительной геометрии.
Вот, и, собственно, поэтому вот лекции
от нее, это будут просто лекции просто
от специалистов просто из этой области.
Ну, вот так, что там, то есть, я думаю,
некоторые лекции, возможно, скорее
все она прочитает даже лучше, чем я.
Выше озвученной причины.
Так что, вот там, собственно, Кира Вяткина
там курсы у нее так называют, там
вычислительная геометрия или там еще
какие-нибудь там курсы типа диаграмма
Воронова там и так далее. Вот.
Так что, вот, могу просто вот заранее
вот очень порекомендовать, на самом деле
вот будет очень интересно. Вот.
Так, ну, на этом мы, собственно, и закончим.
