и посмотрим задачу о покрытии вот задача о рюкзаке это типичный случай задачи упаковки
а мы с вами рассмотрим задачу о покрытии сначала задачу о вершинном покрытии потом
уже общую задачу о покрытии и посмотрим на двойственные задачи значит ну давайте
эти мы займемся поскорее да задача vertex cover задача о том как покрыть граф взяв
поменьше вершин а что значит вообще покрыть граф но граф он состоит всего из как бы объектов
двух типов вершины и ребра и ребра это вообще не совсем самостоятельные штуки да это пары
вершин но вот за этой задачей есть у нас граф и мы берем некоторые вершины этого графа пачкаем
я мне вот почему-то в таких терминах вот мне про рюкзак удобно говорить терминах духов
которые мы бочку наливаем вершинное покрытие обсуждать терминах запачкования графа так вот
мы пачкаем некоторое количество вершин так чтобы каждое ребро оказывалось запятанным значит но
вот мы можем для этого графа взять наверное вот так вот запачкать некоторые вершины бац и бац и
окажется что каждое ребро в этом графе запачкан да вроде получается у некоторых ребер запачкан на
оба конца у некоторых ребер запачкан только один конец но у каждого ребра хоть что-то запачкан но
можно эту задачу притянуть за уши к разным практическим задачкам хотя сама по себе она
может быть не столь практичной но я за уши все-таки по притягиваю потому что нельзя же не сказать что
на самом деле это важная практическая задача и там ее обязательно нужно иметь решать но дело в
том что вот по сути эта задача это просто важный такой частный случай более общей задачи о покрытии
которую как раз таки на практике и важно интересно решать вот но эту задачу можно как воспринимать
ну например вот этот вот граф это какая-то значит сеть каналов обмена информации да компьютерная
сеть просто и для того чтобы канал функционировал одно из устройств на этом канале хотя бы должно
иметь возможность быть таким мастер устройством то есть устройством которое способно инициировать
связь там наладить протокол обмена информации и тогда если вы вот во всей вашей коммуникационной сети
только эти устройства снабдите вот такой вот мастерской функцией остальные устройства будут
ведомыми то тем не менее каждый из каналов связи окажется функционирующим да то есть он может
быть задействован использован но еще такая менее практичная еще менее практичная постановка
представьте что это такой граф дорог и это прямые дороги прямые улицы ну а соответственно вершины
графа это перекрестки на которых сходится несколько улиц тогда мы можем разместить вот на этих только
перекрестках камеры видеонаблюдения поворачивающиеся так что мы сможем обозревать каждую улицу с
помощью только этих камер вот но это менее конечно практичная постановка но знаете оказывается
несмотря на то что задача так выглядит вроде не очень трудно найти действительно минимальное
подможество вершин которая бы покрывала все ребра графа это задачка np трудная но мы с вами в
курсе почти все задачи которые смотрим это np трудная задача сплошняком значит на входе да у
нас вот это граф ну и естественно как всегда у этой задачки есть взвешенная и не взвешенная
модификация да вот на входе у нас либо просто граф либо граф и весовая функция на его вершинах
давайте я сразу во взвешенном варианте поставлю весовая функция до из множества вершин вам
множество действительных положительных чисел нам нужно найти такое под множество вершин
которая бы покрывала все ребра то есть можно сказать что для любого ребра для любого ребра
пересечение этого ребра со множеством в шторих не пусто и при этих условиях мы должны минимизировать
вес вот этого множества в шторих где вес множество понимается как сумма весов его вершин но вроде
разумная задача
минимизируем минимизируем вес множество да не переживайте вот я хотел было стать врачом вот
потому что почерк подходящий для врача но все остальное у меня не срослось вот поэтому пришлось
так вот значит давайте мы эту задачу попробуем решить с помощью нашего пока единственного знакомого
нам инструмента именно поставив эту задачу в качестве задачи целочисленного линейного
программирования и целочисленная программа будет как выглядеть помните мы вводим decision
variables да переменные выбора переменные которые кодирует наш выбор основного неизвестного нам
объекта то есть вот этого в штрих и мы знаем что когда комбинаторная задача задача комбинаторной
оптимизации выглядит как выбор под множество из какого-то заранее фиксированного известного
множества то разумно это под множество закодировать и вектором булевских переменных то есть таким
характеристическим вектором этого множество соответственно мы можем взять и с каждой вершиной
графа связать вот такую вот булевскую переменную x индекс мв которая равна единице или нулю в
зависимости от того хотим мы включать вершину в под множество или не хотим как мы тогда можем
записать нашу целевую функцию да то что мы минимизируем это мы называем всегда целевой
функцией наша целевая функция по-английски это objective function как бы нам ее выписать через
вот эти вот переменные ну как в рюкзаке да точно да сумма мы домножаем вес на соответствующий
x и суммируем это теперь уже по всем вообще вершинам то есть сумма у нас больше не зависит от
конкретного множества там в штрих от этих переменных она суммируется всегда по одному и тому же множеству
просто по всем вершинам графа и эта сумма получается дает нам линейную функцию относительно вот этих
вот переменных уже хорошо но теперь бы нам закодировать линейными неравенствами вот это
вот условия что каждое ребро графа оказывается хотя бы одним из концов в множестве в штрих у
каждого ребра хотя бы один из концов выбран как нам это можно линейным неравенствам как-то
закодировать давайте возьмем какой-нибудь ребро вот есть у нас ребро кстати вы знали что значок
принадлежности можно вот так вот задано вперед написать отлично вот есть у нас ребро такое там
обе да какой-нибудь из двух вершин состоит значит что мы можем с вами сделать мы можем взять икса
плюс xб да больше нуля но я напишу больше или равно единицы хотя это то же самое что вы сказали просто
мне не строгие неравенство нравится чуть больше чем строгие действительно строгие они такие строгие
они строгие они такие мягкие вот ну вроде как нормально да действительно мы запрещаем этим двум
переменам одновременно устанавливаться в нолик у нас переменные это и так только нолики или
единички и мы говорим что для каждого ребра с вот такими концами а и б хотя бы один из концов
должен быть единицей если оба конца единица то тоже хорошо да вот ну двойка больше рано единица
тоже годится вот но два нуля здесь у нас быть не может то есть для каждого ребра мы вот
такой вот неравенство потребуем окей значит получается что целочисленная мининная программа
для нашей задачки она выглядит как-то так мы минимизируем вот такую вот целевую функцию при
условии того что для каждого ребра давайте я уже здесь поставлю значок всеобщенности для
каждого ребра у нас должно быть выполнено вот такое вот неравенство да в общем-то и все вот мы
задачу поставили но это конечно задача сквернее чем рюкзак потому что в рюкзаке у нас с вами
одно всего было неравенство и ну и целевая функция была очень похожая но здесь у нас по
одному неравенство для каждого ребра графа то есть сами неравенство стали проще всего из двух
слагаемых в левой части но зато у нас сложнее стала система теперь это неравенство не одно
ничего мы с ним научимся разбираться значит давайте мы сначала давайте мы сначала представим
что мы решили такую целочисленную линиейную программу а нет не целочисленную программу мы
же не имеем решать мы ее умеем решать но никогда она большая это по-прежнему и трудная задача
же да вот мы давайте решим соответствующую линейную программу чтобы перейти вот целочисленной
линейной программы к линейной программе мы чего с вами делаем мы оставляем все требования кроме
целочисленности а требования у нас были какие для булевских переменных требования булевости оно
вот такое да для каждой вершины графа мы ввели переменную которая болтается между нулем и
единицей и вообще говоря мы должны были бы еще записать что это переменная целое число вот тогда
бы это была полноценная булевская переменная и смысл этой переменной вот такой на самом деле но
целочисленная линейная программа наш ничего не знает про смысл переменных просто переменная и
переменная да мы solver загнали бы вот такую вот программу он бы нам что-то выдал а дальше мы
бы трактовали мы бы вкладывали опять в значение вот эти нолики единицы мы бы вкладывали некий
комбинаторный содержательный смысл что это оказывается вот берем на вершину графа или нет ну
вот если мы теперь избавляемся от целочисленности то мы получаем обычную линейную программу и вот
такая штука это уже то что называется linear relaxation of vertex cover линейная релаксация какой-то
комбинаторной задачи берем комбинаторную задачу ставим на языке clp убираем требования
целочисленности получаем линейную программу которая называется линейной релаксации
помните какое свойство линейной релаксации что она сама по себе тоже очень полезна когда
мы переходим вот к этой программке и решаем ее уже теперь быстро потому что это больше не
np трудная задача что мы можем сказать про минимальное значение целевой функции вот здесь как оно
связано с оптимальным решением задачки вот здесь меньше ли равно да потому что сняп ограничение
целочисленности мы сильно расширяем область допустимых значений переменных и на этой области
могут оказаться какие-то новые точки которые раньше были запрещены потому что у них не целые
координаты да а мы теперь им разрешаем существовать и на них вот это вот сумма может стать еще меньше
вот так что оптимальное значение целевой функции в линейной релаксации всегда дает нам оценку
гарантированную некую на значение целевой функции в исходной трудной задачи ну вот теперь давайте
посмотрим как мы можем приблизиться как-то к ну собственно к этому решению к этой задачке да опять
округление можно попытаться сделать и в рюкзаке все было просто и хорошо там мы посмотрели так
подумали и решили что мы даже solver не будем запускать линейной релаксации мы так знаем как
выглядит оптимальное решение там только одна перемена не целочисленная но представьте что мы
вот взяли например и задачку запустили на вот таком вот графе вот такой шестиугольник взяли
но допустим вершины занумерованы буквами за именованы за именованы буквами ф и тогда у нас
неравенство всевозможное да вот такие до x и а больше равно единицы а минимизируем мы давайте
даже эту задачу рассмотрим как невзвешен и вот просто у всех вершин одинаковые веса по
единичке то есть мы минимизируем сумму запишу даже вот так вот прям сразу x а плюс x б плюс
и так далее плюс x и как вы думаете какое оптимальное решение вот такой вот задачки что
там и все иксы от нуля до единицы да вот такие неравенство и вот такая целевая функция
скорее всего все по 05 когда задача симметричная вот такая да то естественно предположить что
ну как при перестановке переменных мало чего меняется да наверное они все по 05 вот для
такого симметричного графа и правда решение будет оптимальным по 05 и оптимальное значение
целевой функции будет какое 3 да оптимальное значение целевой функции будет 3 можем мы здесь
достичь тройки можем да так отлично да то есть взять просто через одну можем достичь отлично
чудесно
давайте теперь еще один пример рассмотрим то есть бывают случаи когда оптимальное значение
вот здесь вот совпадает с настоящим оптимумом давайте рассмотрим еще один пример а если бы
я вообще теперь провел провел все прям возможные ребра все все все невозможные но я здесь может
какое-то ребро забыл но теперь представим что у нас полный граф на шести вершинах что тогда
если возьмем только одну вершину например а то у нас куча ребер не не запачканы и это
ребро и это это так 3 5 5 вот все кроме одной можно взять если какие-то две вершины забудем
пару вершин то в полном графе между любой парой вершин есть ребро значит и ребро забудем да а вот
если мы все кроме одной вершины возьмем если мы возьмем все кроме одной вершины все кроме
f например то это оптимальное покрытие и меньше никак не получится да то есть оптимальное покрытие
в этой задачке у нас содержит все вершины кроме одной вот а оптимальное значение вот такой программы
какой получится ну представьте что здесь еще побольше неравенств по-прежнему очень симметричная
такая программа да теперь здесь вообще все пары вершин присутствует в левых частях но функция
это целевая опять вот такая же да и все переменные опять скорее всего будут по 0 5 но они будут по 0 5 да и
оптимальное значение 5 тройка получается и что будет когда мы рассматриваем полные графы на
все большем и большем числе вершин по-прежнему ведь оптимальное значение здесь это все вершины
кроме одной взять n минус 1 оптимальное значение здесь какое получается n пополам да n пополам и
при деле у нас отношение оптимального значения нашей целевой функции в комбинаторной задачи
к оптимальному значению целевой функции в релаксации будет 1 2 ну или 2 в какую сторону посмотреть да
брун свесов а какие у нас на рисах то и не было определенных ограничений просто положительные
числа какие-то мы в линейной релаксации всегда делаем одно и то же мы единственное условие
которым жертвуем это целочисленность вот всегда здесь это абсолютно технический момент как мы
ставим линейный релаксация творческий момент состоит в том как вы закодируете комбинаторную
задачу с помощью цлп а вот уже совершенно технический момент автоматически это как вы
цлп перейдете к лп смотрите бывает бывает разные ситуации и мы понимаем что в пределе бывает так
что оптимумы в релаксации их комбинаторная задача отличаются вдвое вот эта штука мы про
нее пока что не будем подробнее говорить она называется она называется ну что-то типа разрыв
связанный с целочисленностью по-английски это будет интегрэлити гэп интегрэлити это
целочисленность гэп это разрыв дистанция вот интегрэлити гэп для этой задачки у нас
получать для задачи о вершинном покрытии равен 1 2 чем он больше тем хуже это значит что тем
больше мы потеряли как бы как раз когда вот целочисленность отбросили ну что ж давайте
попытаемся мы все равно добиться как какого-то использования до позитивного вот этой релаксации
для решения комбинаторной задачки а мы сейчас вот эту двойку сможем сможем достичь в рюкзаке
помните та же история была мы придумали алгоритм который вдвое ошибается вот здесь тоже у нас
будет алгоритм который вдвое ошибается но не то что вообще всегда при использовании линейной
релаксации в любой задачке у нас всегда ошибка вдвое это конечно неправда просто так совпало вот
что рюкзак и вершинное покрытие одинаковую по константу аппроксимации имеют давайте
предположим что мы решили задачки задачку релаксацию и получили вот такой вот набор значений x и
со звездочками пусть это оптимальное решение оптимальное решение линейной релаксации так
чудесно чего мы про него знаем мы знаем что если мы запишем значение целевой функции на вот
этих вот иксах подставим иксе со звездочками целевую функцию то эта штука будет меньше или
равна чем оптимальный оптимальный вес вершинного покрытия да вот в этой задачке а мы с вами
обозначали вот опт не будет в рюкзаке отлично вы знаете да что это значит вы знаете что это есть
оптимальное значение целевой функции в исходной кабинаторной задачи с которым мы как раз сравниваемся
умеем умеем умеем то есть есть как раз смысл в чем почему мы работаем с линейной
релаксации потому что задача линейного программирования решается за полинамеральное
время причем не просто в теории знаете в теории есть такая штука называется галактические
алгоритмы серьезно галактические алгоритмы это такой сленг конечно нету формального
определения но все компьютер-сантисты понимают это одинаково это такие алгоритмы которые
формально быстрые даже могут быть линейные а линейный алгоритм что может быть круче да но у
них такая константища в большом ну типа там 10 в десятый в десятый в десятый так вот что как бы
чтобы почувствовать превосходство этого алгоритма на другими придется слишком долго жить вот и
слишком большие данные подавать на вход этого алгоритма вот тогда мы возрадуемся но то есть
алгоритмы которые имеют преимущество только в рамках входных данных галактических масштабов
вот они называются галактическими алгоритмами но линейное программирование это задачка для
которой есть вовсе не галактические а супер практические алгоритмы вот мы с вами говорили что
задачи лп не ци лп лп да они решаются легко на там десятках тысяч неравенств и там тысячах
переменных не проблема и вы это почувствуете когда будете решать как раз я надеюсь когда
будете задача о вершинном покрытии решать тоже с помощью лп релаксации а вот исходная задача
ци лп поскольку она один в один кодировала трудную нп трудную комбинаторную задачу то она
сама тоже нп трудная получается и нам ничего не гарантируется есть солверы которые решают
задачки целочисленного программирования но они вам не гарантируют чтобы такую задачу быстро
решить они начнут работать на дне когда закончат это уж как повезет так что так что так но для
ци лп есть там google у артулс есть уробия всякие гл пк солверы есть так так вот давайте мы подумаем
как можно было бы округлить решение вот это вот так чтобы получилось решение исходной
комбинаторной задачи помните что мы делали в рюкзаке но в рюкзаке у нас только одна
переменная была не целочисленная там все было хорошо и мы ее округляли куда вниз чтобы в рюкзак
точно все влезло вот здесь у нас переменные ну не понятно какие из них целочисленные вот
у нас пример был только что где все переменные не целочисленные все по 1 2 но давайте мы рассмотрим
вот такое округление давайте мы я обозначу через x vs крышкой округленное значение давайте
переменной просто округлим к ближайшему целому то есть возьмем округлим к единичке если исходное
значение этой переменной было больше равно 1 2 и к 0 иначе ну куда уж интуитивнее да округляй
к ближайшему целому вот 1 2 мы будем округлять все-таки к единичке они к нулю ну может показаться что
это вот особенно в свете наших примеров да вот этих вот там шестиугольника например это ужасно
потому что у нас здесь все переменные были по 1 2 и мы бы их все округлили к единичке то есть
мы бы взяли все вершины графа просто покрытие но с другой стороны но мы ошиблись бы в два раза
оптимальное покрытие из трех вершин а мы взяли бы все вершины мы уже представляем что может быть
вдвое мы да нам придется ошибаться иногда может быть придется давайте посмотрим что мы хотя бы
корректное решение получаем помните у нас в дискретной оптимизации есть такая терминология
коррект допустимые решения feasible solutions и оптимальные решения вот первое что нам нужно это хотя
бы чтобы у нас получилось допустимое решение чтобы условия главные были соблюдены на структуру
решения а потом мы уже думаем а как соотносится качество нашего решения там стоимость вес да там
и так далее с оптимальной возможной стоимостью но сначала мы всегда про допустимость думаем вот
будет ли такое решение допустимо верно ли что если мы возьмем вот эти вот значения и с крышками
подставим в наше неравенство вот в эти то они будут выполняться по-прежнему а почему
да все четко да мы в рюкзаке кстати говоря уже помните занимались таким делом мы две
еврестики придумали и сумма этих эврестик давала рюкзак как минимум оптимальный значит лучше из
этих эврестик была как минимум половинка от оптимального рюкзака если у нас сумма двух
как минимум единицы то наибольшее из этих чисел как минимум 1 вторая и
значит поскольку исходно иксы со звездочками это оптимальное решение вот этой вот задачки
значит они удовлетворяли вот этим неравенством то есть для каждого их со звездочкой вот такие
суммы были больше равнединицы после округления стало быть хотя бы 1 из этих
cot круглица единицы его этого неравенства слева будет как минимум одна единица после
округления, а может быть и все 2 единицы, так? Значит, мы получаем, да, я давайте это
запишу как-то, ну более-менее аккуратно, что для каждого ребра E вида AB
х со звездочкой h-ная плюс х со звездочкой b-шная было больше или равно 1, потому что мы
рассмотрели решение задачки. Следовательно, максимум, максимальное из чисел х со
звездочкой a, х со звездочкой b больше и равняется 1 и 2. Следовательно, либо xA
с крышкой равно 1, либо xB с крышкой равно 1, согласно тому, как мы их
округляем, а может быть они оба равны 1, кто ж их знает. Получится, может и так.
Ну и следовательно, вот отсюда уже вытекает, что х с крышкой A плюс х с крышкой B
больше или равно 1. То есть это округленное решение по-прежнему является
допустимым решением вот этой вот линейной программы.
Но теперь давайте мы, да, я это удалю наверно уже, сотру. Вот теперь давайте
посмотрим насчет стоимости. Про корректность сказали, теперь про стоимость.
Стоимость у нас определяется чем? Суммарным весом тех вершин, которые мы взяли.
Смотрите, вот эти перемены округленные, они уже имеют комбинаторный смысл, правда?
Это уже все, нолики и единички. То есть их можно трактовать как действительно подможество вершин
графа, как покрытие. Мы действительно убедились, что это покрытие и его вес
получается таким. Х с крышкой с индексом v помножить на w с индексом v, по всем v.
Вот теперь давайте убедимся, что выполнено неравенство, что вот эту штуку
можно оценить сверху удвоенной суммой. Х со звездой v помножить на w с индексом v.
Вот почему так? Это вес нашего эвористического покрытия, да? Вес
полученного покрытия. Да, потому что для каждого из х при переходе от звездочки к крышке мы
увеличиваемся не больше чем вдвое. Если х был меньше 1 и 2, то он вообще уменьшился, а не
увеличился. А если х увеличился, то он увеличился как минимум с одной второй до единицы. То есть
отношение х с крышкой к х со звездочкой никогда не превосходит двойку. И вот это вот неравенство,
оно следует из оценки просто для каждого слагаемого. Вот здесь у нас тоже неравенство с тем
же коэффициентом 2, поэтому для суммы получается неравенство с коэффициентом 2. Ну и теперь мы
можем взять вот эту штуку и заметить, что она не больше оптимума. То есть продолжить это, да? Не
больше чем 2 на оптимум. О, классно, мы с вами уложились в первую половину пары и обосновали,
что решение, полученное округлением просто к ближайшему целому, оно не только корректно,
но оно еще и дает вершинное покрытие, веса не более чем удвоенный оптимум.
Так, смотрите, что мы сейчас делаем. Мы вернемся сейчас к задаче о покрытии, но невзвешенной,
и поговорим с вами про какой-нибудь комбинаторный алгоритм. Вот смотрите,
в рюкзаке так было удобно, но мы там поговорили по ходу дела про линейное программирование,
бла-бла-бла, а потом все равно предъявили ивристики, которые новее на линейном
программировании, но можно без него обойтись. А здесь вроде как получается, что я вам предлагаю
использовать там какой-то сторонний solver для того, чтобы решать вот эту вот задачу. Ну там simplex
метод, например, закодить. Да, вот как бы нам от этого избавиться, по крайней мере, здесь. И вот
мы сейчас как раз про это поговорим. Вот про комбинаторный алгоритм для задачи о вершинном
покрытии. И начнем мы с вами. Можно я это сотру? Тогда можно я это сотру? Белое на белом плохо пишет.
Хорошо. Ну вот эта вот штука мне еще понадобится, а вот что-то из этого я бы начал, наверное,
стирать. Давайте рассмотрим вот такой вот комбинаторный алгоритм для задачи о покрытии
без весов. Ну или когда все веса одинаковые. Комбинаторный алгоритм отлично для невзвешенной
задачи vertex cover. Значит, этот алгоритм у нас будет выглядеть следующим образом.
Простой да безобразие. Давайте возьмем graph и пройдемся по всем ребрам просто по одному разу.
Берем ребро. Видим, это ребро не покрыто, не запачкано. И давайте оба конца этого
ребра запачкаем, чтобы наверняка оба конца этого ребра отмечаем. При этом вместе с этим ребром
естественно оказываются запачканными еще, наверное, какие-то ребра. Но давайте я еще
даже два ребра в одну вершину нарисую идущими. Все ребра, перечисленные на картинке, они запачканы.
Но может быть осталось не запачканным еще какое-нибудь ребро. Давайте мы такое ребро
найдем, если оно есть. И давайте мы его тоже запачкаем, оба конца причем. Опять-таки,
получается, что у нас много чего дополнительно еще запачканное. Потом найдем еще ребро,
если такое есть, не запачканное. Опять оба его конца. Вообще неважно в каком порядке. Просто
по разу рассматриваем каждое ребро. И если на момент просмотра очередного ребра оно оказывается
еще не запачканным, мы оба его конца берем и закрашиваем. Странный алгоритм, но точнее вообще
непонятно, насколько он хороший. Единственное, что понятно сразу, это что он корректный. То есть,
что он строит вершинное покрытие. Это правда. Он точно покроет все ребра, потому что он каждое
по одному разу просмотрел и гарантировал, что это ребро покрывается. Только один. Да.
Вот. Хотя бы так. И вот алгоритм у нас строит некое множество V' вершин, которое точно вершинное
покрытие. Давайте убедимся, что это множество V' по мощности не превосходит, опять-таки,
удвоенный оп. Смотрите-ка, без всякого линейного программирования. Удвоенный оп. И сделаем это
с вами вот каким образом. Мы воткнем между этим множеством и оптом некоторую промежуточную
штуку. Что это будет за штука? А давайте посмотрим на множество ребер, которые в этом алгоритме
сыграли. То есть, как раз вот те ребра, для которых, когда мы их рассматривали, оказывалось, что на этот
момент времени это ребро еще не было покрыто. Вот раз ребро, вот два ребро, вот три ребро. Например,
как на картинке. Что про эти ребра можно сказать? Что они не имеют общих концов, правда? Потому что
если мы в очередной раз ребро смотрели и говорили, о боже мой, оно еще не запачкано, то это потому,
что ни один из его концов не был раньше запачкан. Это значит, что это ребро не имеет общих концов,
ни с одним из запачканных досели ребер. Вот. Итак, если мы посмотрим на множество ребер,
которые вот как раз мы отмечали, то они образуют то, что называется в теории графов как пара сочетания.
Множество ребер без общих концов. То есть, итог работы алгоритма, можно сказать, это не только подмножество
вершин V, а это еще и вот такое подмножество специальных ребер. Итог. V' это покрытие. Но еще у нас
есть подмножество ребер, некое специальное, которое мы называем пара сочетания. И теперь давайте
посмотрим на какую-то такую абстрактную картинку. Вот в графе есть пара сочетания, но, например,
на четырех ребрах без общих концов. Какой минимальный, самый-самый минимальный размер покрытия
для этого графа может быть? Как минимум количество ребер. Вот эти. Потому что из каждого ребра мы
должны запачкать хотя бы одну вершину. И поскольку все вершины у этих ребер, все-все разные, то это
значит, что на каждом ребре мы берем хотя бы по одной какой-то уникальной вершине. Как минимум
четыре штуки нам взять придется. То есть, мы с вами понимаем, что как только в графе мы смогли обнаружить
пара сочетания, какое-то m, мы понимаем, что оптимальное вершинное покрытие, которое я по-прежнему
буду обозначать OPT, имеет размер не меньше, чем m. И с каждого ребра нам придется взять хотя бы по
одной вершине в это покрытие, и все они будут разные, эти вершины. А как связаны v' количество
вершин, отмеченных нами, и m, количество ребер, которое в пара сочетаний вошло? Они как раз связаны
понятным образом v' равняется 2m, ну две мощности m. Давайте я здесь мощности поставлю, все-таки мощность
v' равняется удвоенной мощности m. Вот этот сюжет позволяет мне поговорить о очень важном для
всего, не только для дискретной оптимизации, а для вообще информатики, понятии сертификата. Вот у вас
про NP ничего вы не говорили? Да, были, отлично. Вот там мы определяем целый класс сложностной, как
класс-задач, для которых существуют полинамиально проверяемые сертификаты в случае положительного
ответа. Если ответ задач отрицательный, то у нас не должен существовать никакой сертификат вообще,
а если ответ положителен, то должен существовать полинамиально проверяемый сертификат. Как мы его
добудем, кто для нас его добудет, это в классе NP никак не уточняется, но должен быть. Вот здесь
вот мы что с вами смогли сделать? Мы смогли мало того, что решить исходную задачу, ну приближенно
решить, естественно, мы смогли получить некий сертификат не оптимальности, потому что мы не
претендуем на оптимальное решение NP трудной задачи, а сертификат качества. Мы говорим, что вот
это парасочетание, которое мы предъявляем, показывает, что меньше, чем вот столько-то вершин даже
самое-самое лучшее покрытие в этом графе не может содержать. Да, ну и это неплохо. Это неплохо,
когда мы можем доказать другому человеку, не заставляя его решать за нас ту же самую задачу,
перевешивать, мы можем как-то обосновать, что мы получили не самое плохое решение. Так вот,
если про это я предлагаю нам запомнить, что вот здесь у нас возникает такой сертификат качества.
Давайте мы теперь попробуем это все обобщить как-то на веса, на случай с весами. Попытаемся
обобщить это на веса. Так, да, ну мы сказали, что у нас есть такой алгоритм поиска вершинного
покрытия на графе, что этот алгоритм по итогам своей деятельности выдает не только вершинное
покрытие, но еще и парасочетание. И это парасочетание, которое он выдает, является сертификатом
определенного качества того вершинного покрытия, которое мы выдали. То есть, грубо говоря, смотрите,
вот представьте, что вы запустили граф, и по этому графу вы построили покрытие и сказали,
что вот v' у вас там содержит 20 вершин, а еще вы предъявили паросочетание, которое содержит,
ну там скажем, 10 ребер. И там скажем, да, у нас получается всегда так, что v' по мощности
удвоенная m. Мы точно тогда знаем, что opt не меньше 10, правильно? И это значит, мы точно знаем,
что вот это 20, это не больше, не хуже, чем в два раза, чем оптимальное решение, не хуже, чем в два раза.
Причем вот это m, да, это доказательство, можно считать доказательством, потому что человеку
предъявляешь 10 ребер без общих концов, но кто не поверит, что нужно у каждого из этих ребер хотя
бы по одной вершине покрытия включить, да, вот, и все. 10 ребер значит, как минимум, 10 вершин войдут в любое
покрытие, сколько угодно оптимально. Да не за что, всегда рад. Могу еще там не с 20 и 10, а, например,
с 30 и 15, может, еще понятнее. Так вот, давайте попробуем наш успех продлить на задачку с весами,
да, значит, как мы это с вами будем делать? А мы, да, сначала давайте посмотрим, что этот алгоритм крайне
плохо работает на задачи с весами. Достаточно рассмотреть какой-нибудь такой граф, вот такую
звезду, у которой вершины крайние, они веса 1, дешевые, а центральная вершина, ну, какая-нибудь супердорогая,
там 10 в шестой, миллион. Какое оптимальное покрытие у этого графа? Понятно, что лучше взять больше
вершин по количеству, зато меньше по весу, там взять всего 6 вершин. Но что сделает наш вот такой
комбинаторный алгоритм? Он посмотрит на первое попавшееся ребро и сразу оба его конца возьмет, бах-бах, да. А у нас же
задача о покрытии взвешенная бывает, вот, собственно, когда мы алгоритм, не, на ребрах нет весов, вот это
вершины веса 10 в шестой, эти все по 1, вот. То есть, вот брать так сразу у каждого ребра, да у любого
ребра, брать сразу, а промечь его оба конца, это как-то слишком плохо годится вот для такого типа графов,
у которых очень неравномерно распределены веса. Чего ж делать? А все равно мы справимся с вами, вот.
Просто у нас алгоритм будет другой немножко, у нас доказательство собственное, доказательство качества, да,
вот этот сертификат качества будет немножко отличаться от парасочетания. Давайте мы посмотрим
на вот эту задачку, на вот эту вот задачку и сделаем из вот этой вот системы неравенств некоторые выводы.
Давайте повспоминаем школьную алгебру. Если у нас есть два неравенства одного знака, то мы можем эти
неравенства сложить, правда, и получить неравенство того же самого знака. Чудесно. А еще, если у нас есть
неравенство, то мы можем его, это неравенство, домножить на положительное число, ну, на не отрицательное
число даже, и получить по-прежнему верное неравенство. Стало быть, мы можем с вами вот что сделать.
Давайте представим, что для каждого неравенства, вот из этих, мы взяли некоторую константу, которую я
назову y с индексом e. Ну, поскольку вот такое неравенство соответствует ребру, да, то логично это
неравенство само связать с этим ребром, ну и вот с этим ребром связать соответствующую какую-то
константу. Вот возьму я такую константу, не отрицательную, домножу вот такое неравенство на эту
константу. У меня получится неравенство вида xA на yE плюс xB на yE больше или равно, чем yE. Я
каждое неравенство могу домножить на свою константу, да, потом могу взять эти же неравенства
все одного знака, я могу взять бабах сложить. Что получится тогда? Что же у меня тогда получится?
Получится такая сумма слева по всем ребрам и сумма справа по всем ребрам. Вот такая странная штука
получится. Причем вот здесь у меня, я уже убрал эти индексы A и B, потому что для каждого ребра E это
будут свои какие-то концы, это будут свои концы. А вот теперь я хочу сделать вот что, я хочу
перегруппировать немножко вот эту вот часть так, чтобы у меня сумма была теперь по вершинам. Я
хочу это преобразовать сумму по всем вершинам графа и здесь уже, чтобы у меня был x соответствующей
вершине, ну а тут было может быть какой-то уже коэффициент при этом x. Правую часть я оставлю
без изменений пока. Вот что будет, если мы с вами в этих всех членах, которые суммируются, перегруппируем
их так, чтобы x вытащить, а при каждом x сложить все y, которые там на него домножаются. Что у нас
тогда получится? Давайте посмотрим, какие пары x и y участвуют вообще вот здесь. Это всегда какая-то
пара x соответствующей какой-то вершине графа и y соответствующей какой-нибудь ребру графа. Причем
эти вершины и ребро это же не просто абы какие, а вершина является концом ребра. Правда? Мы изначально
брали неравенство соответствующей ребру и в это неравенство входили x, которые соответствуют
вершинам концам этого ребра. Стало бы теперь, когда мы перегруппируем эту сумму и вытащим
отдельно x, при каждом x будет стоять сумма всех таких y, всех таких ребер, по всем таким ребрам,
которые торчат из вершины v. То есть по-прежнему, чтобы получались пары всевозможные вида x, v на y,
к е, где вершина v является концом ребра е. Ведь именно такие пары здесь все равно и стоят. Так,
как бы нам это записать? Вам знакомы такое обозначение? Delta от v множество всех ребер
графа, которые инцидентны вершине v. Отлично, значит это новое знание для нас. Это множество
всех ребер, торчащих из вершины v, но математически говорят ребра инцидентны вершине v.
Вот мы с вами здесь это в сумме и напишем. Я напишу крупно, чтобы всем было видно. Сумма по всем
е, торчащим из вершины v. Здесь у нас y с индексом е. Это просто перегруппировка вот этого
неравенства. Ну а правую часть я оставлю, больше ли равно, чем сумма y с индексом е,
просто по всем ребрам графа. Так, чудесно. А давайте теперь предположим, что для каждой вершины
вот эта сумма, которая здесь стоит, меньше ли равна, чем вес этой вершины. Пусть для каждой
вершины сумма, которая, давайте я просто вот стрелочку так поставлю, вот эта вот сумма,
меньше ли равняется, чем вес соответствующей вершины. Тогда я мог бы продолжить это неравенство.
Я бы мог сказать, ага, если вот эта штука, каждая такая скобка, меньше ли равна, чем
вес соответствующей вершины, то тогда вот эта штука, меньше ли равна, чем xv помножить на w.
А где у меня встречается такое выражение xv помножить на w? Да, это целевая пункция. Вот оно,
вот оно это выражение. xv, помноженное на w. То есть, если вдруг я подобрал y, так что это
произвольные какие-то положительные числа, но если вдруг дополнительно окажется, что сумма вот такая,
каждая, не превосходит w, то тогда все вот это выражение будет меньше или равно, x-ы-то не отрицательные,
эта штука не отрицательная, w не отрицательные, значит, можно продолжать по-прежнему по такому
неравенству, это бы оказалось меньше или равно, чем значение целевой функции. Тогда, значит, вот эта
вот сумма y, которая здесь стоит, оказалась бы меньше или равна, чем значение целевой функции.
Так, чем сумма w с индексом v, помножить на x с индексом v по всем v-шкам.
Могу вам что-то пояснить? Давайте. Что мы сделали? Мы сказали, что есть такие школьные правила,
что если взять неравенство и домножить его на положительное число, то это неравенство
останется верным. А еще неравенство одного знака можно складывать. И вот мы говорим,
у нас есть столько неравенств по одному для каждого ребрографа, давайте мы каждое такое неравенство
домножим на какое-то пока неизвестное число, которое мы потом выберем,
выберем чему его положить равным. Пока просто предположим, что для каждого ребрографа мы выбрали
какой-то y или зафиксировали какой-то y, домножили на него такое неравенство,
а потом все эти неравенства, раз они одного знака по-прежнему, мы их поскладывали. Получится
неравенство, по-прежнему того же знака, у которого в одной части стоит сумма
единичек, помноженных на у, это как раз вот эта сумма, а в другой части у него
стоит сумма у с индексом е, помножить на xа, плюс у с индексом е, помножить на xb, да, вот
эта штука. Дальше мы сказали, а давайте мы вот эту вот часть перегруппируем
немножко, запишем просто по-другому. Вот в этой сумме у нас по факту
встречаются всевозможные пары x с индексом v на y с индексом е, где x это конец
ребра е. Мы распишем эту сумму по-другому, сгруппировав ее по вершинам, тогда здесь
мы выносим x с индексом v, а в скобках остается сумма всех тех y, которые
соответствуют ребрам, торчащим из вершины v. Это просто такое обозначение
стандартное для дискретной оптимизации, ну, для computer science. Не буду присваивать это
обозначение дискретной оптимизации, это широкое такое обозначение, стандартное.
Так вот, теперь мы дальше говорим. Смотрите, такое неравенство у нас выполнено, но если
мы вдруг дополнительно сможем подобрать y так, чтобы каждая такая сумма
оказывалась меньше или равна, чем w, то тогда вот эта вот сумма будет меньше или
равна тоже с тем же знаком, чем x сумма x вшек на w вшки. А это и есть то, что у нас
стоит вот здесь целевой функции. А теперь давайте прочувствуем такой пафосный
момент. Пафосный момент. Вот в этом условии, вот в этом условии, а где здесь x вообще?
А что мы про них требуем? Да ничего. Ничего. Мы не требуем на x вообще ничего, кроме того,
что они должны удовлетворять исходным вот этим вот неравенствам. Мы требуем только на y. Мы
накладываем требования только на y, что если y не отрицательные, если для них выполняются вот
такие неравенства, то тогда можно взять и оценить какую-то сумму, которая зависит от x в целевую
функцию. При любых получается иксахта, от них ничего не зависит. Оценить вот эту вот сумму
через сумму y. То есть мы получаем какую-то универсальную оценку, которую мы управляем,
на вот такие вот суммы для любых вообще иксов. Но в частности, ведь сюда же можно подставить в
частном случае какой-нибудь оптимальный набор иксов, правда? Можно. И значит,
минимальное значение вот такой вот суммы тоже может быть оценено снизу суммой вот таких вот
y. А минимальное значение вот такой вот суммы, в свою очередь, меньше или равно, мы сейчас про
линейную релаксацию с вами говорим, чем оптимальное значение целевой функции в исходной комбинаторной
задачи, оптимизации, там бла-бла-бла. То есть вот эта штука меньше или равняется, чем опт.
Меньше или равняется, чем опт.
Но это как, знаете, вот в матане, если каждый член последовательности не больше, чем какая-то
константа, то и предельные значения последовательности не больше, чем эта константа. У нас есть всякие
такие предельные теоремы. Но вот здесь у нас тоже получилось, что выполняются такое неравенство
независимо от того, какими вы берете иксы. Значит, и при самом-самом-самом оптимальном выборе иксов такое
неравенство тоже будет выполняться. Но отлично, это значит, что и для опта мы можем тоже такое
неравенство с организовать. Опт можно оценить снизу вот такой суммы y. Так, чудесно. Сколько у нас
времени-то? 15 минут. Отлично, мы успеем. Давайте мы теперь это используем наконец.
Если мы возьмем, можете повторить,
y единицами, но тогда не факт, что у нас вот эти неравенства выполнятся, но это какие веса нам
дадут на вход? Это входные данные нашей задачи. W? Не, W это просто произвольные, W это произвольные
действительные числа на входе нашей задачи о покрытии. У нас на входе граф и веса на вершинах.
На самом деле, то, что мы с вами здесь провернули, это частный случай применения
теоремы двойственности в линейном программировании, но я просто не хочу еще тратить время на общий
случай. Пока оставим это все вот так, в частном. Давайте алгоритмы сформулируем, комбинаторные,
для взвешенной уже теперь задачи о покрытии. Алгоритм для взвешенной задачи о покрытии. Давайте с каждой
вершиной графа свяжем переменную x индексом v. Возьмем вот такой набор переменных x индексом v по всем
вершинам. Изначально полагаем все эти x равны нулю. Да, вот то, что мы с вами рассмотрели, это мы
рассмотрели частные случаи теоремы двойственности для линейного программирования. Если потом смотреть,
что читать дополнительно. Не, виноват, давайте это z обозначим. А сейчас я алгоритм напишу для
взвешенной задачи о покрытии. Комбинаторный алгоритм, он не будет в себе содержать никакого
линейного программирования. Но для его анализа мы с вами задействуем вот эти вот неравенства,
которые, в общем-то, мы получили из рассмотрения линейно-программистской формулировки задачи о
покрытии. Не просто так они возникли. Давайте введем для каждой вершины графа переменное z,
которые мы изначально положим равными нулю. И для каждого ребра графа мы тоже введем свои
переменные y, которые изначально тоже полагаются равными нулю. А дальше давайте сделаем похожую
процедуру на алгоритм для невзвешенной задачи. Просто одно за другим просмотрим все ребра,
и если очередное ребро не покрыто, то мы будем его как-то покрывать. Каким образом? Вот мы
сейчас это с этим разберемся. Это такой питоновский псевдокод получается. Для каждого ребра из
множества ребер графа, если ребро е не покрыто, если ребро е не покрыто. Ну помните, что мы делали в
невзвешенном случае. Мы брали сразу оба конца ребра и в покрытие включали. Вот сейчас мы не
будем делать так. Сейчас мы сделаем вот такую штуку. Мы переменную y с индексом e, который у нас
есть в запасе, выставим вот в такую величину. Минимум из w, мне нужно ввести здесь обозначение
для концов ребра. Давайте я концы этого ребра обозначу через a и b, ладно? w a-z a и w b-z b. Вот,
возьмем минимум из этих двух величин и добавим этот минимум к каждой из переменных z. То есть,
скажем, что z с индексом a плюс равно y e и z с индексом b плюс равно y e. Но это c++
терминология, с которой вы знакомы, c++ синтекс. Это некие переменные, просто которые изначально
для всех вершин графа выставлены нулями. Да, w – это вес. Вообще есть разница между
ω и w. ω – это греческая буква, у которой хвостики расположены внутрь буквы, это ω. У нее рога
внутри. Вот, а w английская, у нее рога наружу. И в одном и том же тексте может встречаться и
ω и w, поэтому будьте аккуратны. Ну вот, и теперь дальше мы говорим вот что. После того,
как вот эти вот две команды выполнились, что мы можем утверждать гарантированно? То хотя бы одна
из вот этих вот двух величин z, она достигнет w соответствующей. Правда, ведь мы изначально так
и выбирали вот этот y, который мы добавляем к этим z. Фактически мы его выбирали как раз как
минимальное возможное значение, которое после прибавления к вот этим вот величинам доводит
их до уровня соответствующей w. Вот теперь мы одну из этих вершин включим в покрытие. То есть
дальше мы говорим с вами, что если z а сравнялась с w а, то тогда к v штриху мы добавляем
вершину а. И если zb сравнялась с wb, то тогда v штриху мы добавляем еще и b.
Точно, а здесь мы их увеличиваем.
Да, разность. Вот то есть, заметьте, что я хочу, чтобы мы сейчас заметили, что как раз при таком
выборе у мы гарантируем, что хотя бы один из этих двух ифов он выполнится. Мы в него войдем и мы
добавим множество штрих, хотя бы из одну из вершин а и b, а может быть и обе, хотя бы одну из них.
И стало быть, на этом шаге, вот на этом шаге, мы гарантируем, что хотя бы один из концов ребра
е будет взять покрытие. Поэтому этот алгоритм корректен. То есть корректность алгоритма, как и в
случае невзвешенного, помните, невзвешенного алгоритма, она довольно тривиальная. Здесь никакой
rocket science нам не нужен, чтобы корректность обосновать. А вот давайте теперь будем обосновывать
с вами качество. Массив ye? Не нужен он по факту. Он нам нужен сейчас для анализа. То есть мне
просто захочется сейчас кое-что поговорить про вот эти вот ye. На практике, конечно, вы скорее
просто введете одну переменную, какую-нибудь t, временную переменную. Здесь ее положите равной
этому минимуму, и ее вот используете, и забудете потом до следующей итерации. Но для анализа мне
нужно, чтобы у каждого ребра сохранялось вот это вот значение. Вот, потому что мы его сейчас с
вами как раз используем. Мы с вами его используем. Так, давайте запишем вес нашего покрытия. Вес
множества v', который мы получили по итогам алгоритма. Это сумма весов вершин, которые
входят во множество v'. Но это вроде определение веса множества. Давайте заметим, что такую сумму
можно оценить суммой всех z по всем вершинам графа. А почему такая такая оценка выполнена,
как бы вы сказали про это? Почему? Ну про y пока ничего не говорим вроде. Точно, потому что,
вообще-то говоря, справедливо вот такое равенство. Ведь для тех вершин, для которых мы включаем в
покрытие, мы их включаем-то когда? Когда у них z совпадает с w, так? То есть, вообще говоря,
выполнено вот такое равенство. Но если я в этой сумме возьму и еще побольше слагаемых, не только
по вершинам множества v', а вообще по всем вершинам графа, просуммирую z, то получится не равенство,
потому что z все равно не отрицательное. Ну окей, получится верхняя оценка тогда. Так, чудесно.
Помните лему о рукопожатиях? Она про что? Если много пожимать друг в другу рук, то ковид
распространяется лучше. Нет? Как она звучит? Ну да, бывает в таком виде, прочетность. А бывает
просто про сумму. Если просуммировать степени всех вершин в графе, то мы получим удвоенное
количество ребер. Правильно? Чудесно. Давайте заметим теперь, что вот здесь мы можем сформулировать
что-то типа обобщение лему о рукопожатиях. Если просуммировать все z, те z на всех вершинах,
то мы получим удвоенную сумму y. Я сейчас это поясню, естественно, я вас не буду бросать на произвол
судьбы с вот этой штукой. Давайте посмотрим на алгоритм, что у нас там происходило. Посмотрим
на произвольную какую-то вершину. И вот этой вершины есть ее z с индексом v. Эта z изначально была равна
нулю. Правда, мы начинаем с нулевых значений. А потом у нас z на протяжении алгоритма увеличиваются.
Но ведь z-ки увеличиваются не оба на что, они увеличиваются на вот эти y. То есть это z,
она так с нуля началась и росла, росла, росла. И почему она росла? Потому что находились какие-то
ребра, которые не были покрыты, и на этих ребрах выбирались соответствующие y, и вот этот y добавлялся
к значению z. И в итоге это z складывается из всех вот этих вот отдельных y, соответствующих вот
этим ребрам, торчащим из вершины. Ну и смотрите-ка, каждое ребро, каждый y дает вклад в два z,
в z у вот этой вершинки и в z у вот этой вершинки. А этот y дает вклад вот в эти два z. Ну и так
дальше. Это точности как клемма о рукопожатиях. Каждое ребро дает вклад по единичке в степени
двух своих концов. Именно поэтому сумма степеней вершин равняется удвоенному числу ребер. Здесь
абсолютно та же самая картина. Каждый y дает вклад в два z неминуемо, вот в эти два z. И поэтому
сумма всех z равняется удвоенной сумме всех y. Нормально? Ну такая вроде клемма о рукопожатиях,
только обобщенная на какие-то произвольные странные числа z и y. Но теперь-то давайте заметим,
что эти y удовлетворяют всем вот этим вот условиям, которые мы поставили. Ой, зря я здесь
стер. Зря я стер. Да. Ведь по ходу алгоритма, заметьте, мы никогда не сделаем так, что вот этот z
превзойдет вес соответствующей вершины. Правда? Мы всегда устанавливаем очередной y в минимальное
такое значение, чтобы вот один из этих z достиг веса вершины, а другой точно не превзошел веса
своей вершины. То есть по ходу выполнения алгоритма у нас выполнен, как, сказали бы,
компьютер-сантисты, такой инвариант. Инвариант — это какое-то свойство, которое не меняется на
протяжении всего алгоритма. Вот инвариант нашего алгоритма такой, что сначала до самого-самого конца
вот эти вот y, вернее, эти z, они не превосходят соответствующих w. И y мы выбираем соответствующим
образом, чтобы этот инвариант не нарушить. То есть у нас всегда есть предельный уровень,
меньше ли равняется, чем wv, и при выборе очередного y мы смотрим, как бы больше этой разности y не
взять ни в коем случае, потому что если мы возьмем больше такой разности, то это неравенство нарушится.
Вот поэтому мы берем здесь минимум из двух разностей, чтобы для каждого конца z сохранила свое
свой потолок. Но z-ка-то складывается как раз из вот этих вот y отдельных. То есть у нас
действительно выполнено эти условия. Для каждой вершины графа сумма y по всем ребрам, торчащим из этой
вершины, равняется этой z-ке по определению, которая в свою очередь не больше, чем w,
которая в свою очередь не больше, чем w. Ну и нигрики, очевидно, не отрицательные величины на
протяжении всего алгоритма. Стало быть, вот по этому свойству мы можем с вами заключить,
что вот эта сумма не превосходит опта. Оказалось, что мы способны наконец поставить здесь удвоенный
опт. Мы с вами предъявили комбинаторный алгоритм, который ничего не содержит
пролинейное программирование. Но при этом для анализа этого алгоритма мы с вами построили
некий специальный набор констант. И то, что этот набор констант вообще как-то связан с оптом,
последовало из анализа нашей системы линейных неравенств, которая кодирует задачу о вершинном
покрытии. Вот бывает и так, оказывается. Ну что ж, не буду задерживать, спасибо за сегодня,
до встречи на следующей неделе.
