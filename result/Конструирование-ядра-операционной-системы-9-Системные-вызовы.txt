Ну, тогда еще раз всем добрый вечер.
У нас сегодня по плану разговор о полноценном юзерспейсе,
т.е. так как мы с вами уже победили полностью
настройку виртуальной памяти в операционной системе,
то наше ближайшее будущее лежит в организации способностей
в организации способов обмена между пользовательским пространством
и, соответственно, ядерным пространством.
Поэтому сегодня мы поговорим, как вообще перейти
на пользовательский уровень, соответственно, в юзерспейс на x86.
Поговорим о том, как работают прерывания,
как работают системные вызовы, т.е. один из механизмов обмена данными
между пользователем и ядром.
Поговорим о том, какие есть дополнительные механизмы,
которые позволяют нам защитить ядро от пользовательского пространства.
И также поговорим про то, какие методы динамического инструментирования
существуют, которые также позволяют находить ошибки
в коде операционной системы и используются в том числе
для проверки на границах юзерспейса и кернелспейса,
т.е. такие вещи, как фазинг системных вызовов.
Об этом мы сегодня тоже поговорим.
Итак, соответственно, юзерспейс.
В x86 юзерспейс или пользовательский уровень привилегий,
как мы уже знаем, определяется маршами битами сегментного регистра.
В младших двух битах кодируется значение привилегий или CPL.
Если там сохранено значение 3, то текущий уровень привилегий юзера.
Если значение 0, то уровень привилегий керна.
Стандартный механизм отображения пользовательской памяти
заключается в том, что в таблице страниц,
в те области памяти, которые видны пользователю,
устанавливается bitU, он же user.
И в этом случае при установке привилегий в режим user
вы можете получить доступ к этой памяти.
При этом все страницы ядра у вас также находятся в этой таблице страниц,
но так как у них bitUser не установлен, то прав доступа вы к ним не имелите.
Также из предыдущей лекции вы знаете, что существуют различные атаки
микроархитектурного типа, например, такие как meltdown,
по причине которых сейчас в современных операционных системах
часто не отображают большую часть памяти ядра в таблице страниц
потому что существуют некоторые механизмы,
позволяющие прочитать вот эту память в обход
этих установленных битов привилегий из-за ошибок в микроархитектуре процессора.
Но мы все-таки с вами рассматриваем достаточно стандартную схему,
где это условно не так.
В неприлегированном режиме или в пользовательском режиме
у процессор выполняется не то чтобы в песочнице,
но в некотором специальном подрежеме, где часть инструкций,
например, такие инструкции как включение-отключение прерываний
или чтение машин specific регистров,
соответственно, доступ к отдельным регистрам, например, запись сегментной регистры,
он невозможен.
И это предназначено для того, чтобы пользователь не мог повлиять
на выполняющиеся другие программы на данном оборудовании,
и тем самым неприлегионный режим позволяет выполнить
самую базовую задачу любой многозадачной ОС,
такую как защита ядра от программы и другой программы в неприлегированном режиме.
Как именно происходит переход из kernel space в user space?
В разных процессорах понятно, что это делается немножко по-разному,
но в целом схема, которая присутствует в x86,
она очень хорошо похожа и на схемы других процессоров.
В x86 существует некоторая специальная структура,
с которой вы уже познакомились, она у вас использовалась при переключении контекста
без изменения режима с ядерного на пользовательский в третьей лабораторной работе.
В этой структуре лежат такие регистры как RIP,
Instruction Pointer, Code Segment, RSP, Stack Segment,
Register Flags, Airflags.
И записав фактически на стэк вот эту структуру,
вы можете воспользоваться специальной инструкцией IRED,
ну или IRED-Q, как ее кодируют в ассемблере AT&T для 64-битного режима,
которая, собственно, восстановит этот контекст из стэка
и, соответственно, обновит значение этих регистров,
то есть тем самым перейдет фактически в пользовательский режим
посредством обновления кодового сегмента,
текущего указателя на инструкцию кода,
соответственно, обновит стэк,
и вы сможете в дальнейшем выполнять пользовательский код.
То есть, в принципе, для этого также можно было бы использовать фар инструкции,
но так, во-первых, никто не делает,
во-вторых, у них есть там больше ограничений,
поэтому основной механизм все-таки это вот именно IRED-Q,
но в случае, например, не x86-процессоров,
то вполне могут быть вот конструкции типа Jump, Far точно так же.
Каким образом мы можем вернуться?
То есть понятно, что большая часть времени
операционная система должна заниматься тем, чтобы выполнять
действительно пользовательский код.
Но так как мы время от времени должны выполнять
какую-то другую задачу, у нас операционная система многозадачная,
или в какой-то момент мы должны выполнять
функции, которые не могут обойтись без функционирования ядра,
ну, например, там какое-нибудь выделение памяти,
заранее не выделенный на пользовательский процесс,
или, например, обращение к какому-нибудь устройству,
которым управляет ядро.
Поэтому время от времени мы должны все-таки возвращаться
к тому, что мы делаем.
Поэтому время от времени мы должны все-таки возвращаться
в ядерное пространство.
И для этого используются два механизма.
Ну, соответственно, первый механизм — это механизм прерываний.
В частности, у нас могут возникать прерывания, например, от устройств.
Ну, простой пример, прерывания от таймера,
которые могут вызывать планировщик и тем самым, соответственно,
переключать управление с пользовательского режима на ядерный,
и, соответственно, возврат из этого прерывания
вернется обратно в пользовательский режим.
А также системные вызовы.
Ну, соответственно, системные вызовы — это один из механизмов,
ну, как мы помним из второй, кажется, лекции,
общения между пользователем и ядром,
когда, соответственно, пользователь формирует специальным образом
некоторые наборы аргументов и говорит ядру, собственно,
что мне нужно выполнить вот такую вот задачу.
То есть на ядро проверяет, что пользователь действительно
имеет право выполнить эту задачу и ее, соответственно, выполняет.
В x86 возникает некоторый там вопрос,
а на каком, например, стеке вы должны работать в ядре
в тот момент, когда, соответственно, возникло, например, прерывание
во время работы пользовательского процесса?
И ответ на этот вопрос звучит в том, что это происходит, ну, там,
плюс-минус аппаратно, то есть есть такая структура
под названием, соответственно, task state segment,
и именно, собственно, эта структура определяет,
как именно будет, как бы, воссоздан ядерный контекст
в момент возникновения прерывания.
В случае с системными вызовами, то есть если вы используете
не механизм прерываний, то есть вполне нормально реализовать
поддержку системных вызовов просто с помощью прерываний.
Но так как мы хотим получить достаточно высокую производительность
при работе этих системных вызовов, то очень часто в современных
процессорах существуют механизмы, которые позволяют этот
процесс ускорить, то есть некоторые там специальные расширения,
и вот, собственно, они, например, позволяют нам меньше сохранять
регистров при переключении между контекстами, что, естественно,
увеличивает скорость работы системных вызовов.
Task state segment – это некоторая структура в памяти,
на которую указывает специальный регистр под названием TR.
Он очень похож на сегментные регистры типа CS, SS и подобные,
но для обновления используется специальная инструкция типа LTR,
в отличие от сегментных регистров, которые можно менять
с помощью инструкции MOV.
Но идея, в общем-то, ровно та же самая.
В GDT прописывается некоторый адрес этой самой структуры,
в которой содержатся две основные вещи, которые нам интересны.
Это, соответственно, адрес стека, то есть RSP,
для соответствующего уровня привилегий.
И ICT стеки для прерываний – это дополнительное расширение
в режиме x8664, которое позволяет вам для некоторых отдельных прерываний
установить собственные стеки, чтобы можно было часть прерываний
обрабатывать параллельно.
То есть как параллельно, в смысле не отключать прерывания глобально,
а отключать их локально для группы прерываний.
Соответственно, task-stake-сегмент чисто гипотетически позволяет
делать аппаратное переключение между задачами,
потому что вы можете сделать несколько TSS-сегментов
и их все расположить в GDT.
Но в связи с тем, что у вас задачи чаще всего гораздо больше,
чем размер таблицы GDT, то этот механизм практически никто не использует.
Но, тем не менее, он действительно есть.
С точки зрения терминологии x86, существует вообще два вида прерываний.
Здесь стоит оговориться, что терминология x86 применяется не везде.
И очень нередко, когда в новую архитектуру вы приходите,
вы столкнетесь с тем, что словами exception, interrupt
называют совершенно разные вещи.
Потом появляются вещи типа critical interrupt, особо critical interrupt.
Но здесь скорее идея в том, что прерываний существует, скажем, много.
И эти прерывания делятся на так называемом уровне.
Есть, грубо говоря, менее привилегированные прерывания, более привилегированные,
еще более привилегированные прерывания.
Например, на x86 различают стандартно два уровня прерываний.
Асинхронные прерывания, они же interrupt.
Эти прерывания являются маскируемыми.
То есть маскируемые означают, что их можно отключить.
То есть выставляется специальный флаг AF.
Ну, вы с ним уже знакомы, потому что видели инструкции STI, CLI в ранних лабораторных работах.
И на асинхронные.
Это exception или же не маскируемые прерывания, то есть их нельзя отключить.
Кроме этого, у вас в принципе существует множество других прерываний.
Например, прерывания inter-processor interrupt, то есть прерывания между ядрами.
Существует SMI System Management Mode Interrupt.
То есть это прерывания, по которому процессор заходит в режим System Management Mode.
И на самом деле там много других.
К счастью, в операционных системах вам не всегда нужно о них знать.
Кроме этого, у устройств могут быть реализованы собственные прерывания.
Например, для тех, кто возьмет задание с PCI-шиной.
Ему придется познакомиться с MSI прерываниями.
И выяснить фактически, что поверх имеющихся прерываний в рамках какой-то отдельно взятой архитектуры.
Например, x86.
Другие устройства могут выстраивать свою схему прерываний на полупрограммном, полуаппаратном образе.
Возвращаясь к нам, в x86 основные виды прерываний.
Синхронное прерывание это некоторый результат выполнения текущей инструкции.
Но представьте, что в инструкции у вас происходит целочисленное деление.
И в результате этого деления вы разделили на ноль.
В этот момент у вас будет синхронное прерывание, вы не можете его никак заблокировать.
Кроме этого, к синхронным видам прерывания относятся такие прерывания, как неправильная работа с указателями.
Например, у вас отсутствует страница в оперативной тему, которая не может быть в
Или страница недоступна на запись, недоступна на исполнение.
У вас пейчфолд возникнет.
Кроме этого, прерывания можно вызвать вручную.
Например, на x86.
Возвращаясь к нам, в x86 основные виды прерываний.
Кроме этого, прерывания можно вызвать вручную.
Например, на x86 есть специальная инструкция, называется int,
куда записывается номер прерывания.
Один из способов использования этой инструкции это генерация прерывания breakpoint.
Когда вы ставите breakpoint в дебагере, то, соответственно, можно увидеть, что дебагер подменяет какую-либо инструкцию на int3.
Соответственно, вот эта инструкция используется для срабатывания breakpoint на участке кода.
Вопрос.
Да, давайте.
Чем тогда идейно отличаются прерывания от syscalls, если и то, и другое?
Это попросить операционку сделать что-то в ядре.
На самом деле вы как раз задали вопрос, который я хотел только что задать зрителям.
Собственно, вопрос, который хотел задать я, звучал следующим образом.
Как можно реализовать syscalls, обладая знанием, которое есть на этом слайде?
Взять int80 и порадоваться.
Ну, соответственно, на самом деле здесь неважно.
Сразу видно тех, кто пользовался UNIX, тех, кто пользовался DOS.
Действительно, инструкция int, то есть генерировать некоторое прерывание,
это один из наиболее простых способов реализовать сyscalls.
То есть вы, выбрав некоторое прерывание и договорившись с ядром,
что, соответственно, обработчик этого прерывания будет обработчиком syscalls,
можете организовать некоторое соглашение при обработке прерываний.
Например, на 21h или int80h, или int40h, неважно,
у вас будет обработчик системных вызовов,
и он позволит общаться пользователю с ядром.
Именно так прерывания достаточно долго были реализованы в операционных системах,
и в DOS они так реализованы до сих пор.
Это простой портативный вариант реализации системных вызовов.
Проблема с таким подходом связана с тем, что любое переключение контекста,
вход в ядро – это переключение контекста,
это дополнительные накладные расходы,
и мы хотели бы эти накладные расходы уменьшить.
Мы понимаем, что когда мы переключаемся на ядро,
если мы выполняем, например, прерывание по таймеру,
то нам нужно как минимум убедиться, что пользователь ничего об этом не узнает.
То есть фактически нам нужно обеспечить сохранение всех регистров, которые у нас есть,
и затем их восстановление в момент, когда мы вернемся в пользовательский овер.
В случае с системными вызовами они отличаются от асинхронных прерываний,
от прерываний, возникших внешним образом к текущему исполнению процесса.
То есть они отличаются тем, что пользователь знает о том,
что он в данный момент хочет выполнить системный вызов.
И соответственно нам не обязательно сохранять все регистры.
Чувствуете, да?
То есть нам не обязательно помнить все состояние пользовательского процесса
для того, чтобы обработать системный вызов.
На самом деле многие регистры, например, пользователь может сохранить сам.
Мы даже помним колли-конвеншн, в результате которой часть регистров, например, колли-презерв,
то есть их должен сохранить вызывающий.
То есть пользователь даже сам не ждет, что мы какие-то регистры будем сохранять.
И здесь возникает возможность оптимизации, которая позволяет нам часть регистров не сохранять
и тем самым сэкономить время на обработку системного вызова.
В связи с этим в процессорах, в том числе в современном x86,
существуют специальные механизмы, которые позволяют реализовывать системные вызовы
более быстрым способом, чем простой вызов синхронного прерывания
с помощью классической инструкции на.
Ответил на вопрос?
Ну да, в целом понятно.
Хорошо.
Соответственно, про синхронные прерывания, то, что к таким прерываниям относится,
например, прерывания от таймера, от других устройств, я только что сказал.
Поэтому как эти прерывания описать?
Есть такая структура под названием interruptDescriptorTable.
Поверхностно вы с ней уже познакомились, но делали это достаточно неглубоко,
поэтому я все-таки остановлюсь на этом снова.
И скажу, что это 256-слотовая структура.
При этом первые 32 записи зарезервированы Intel под некоторые системные исключения.
В процессе отладки вам наиболее актуальные исключения 13 и 14.
Первая это General Protection Fold.
Чаще всего возникает, когда вы пытаетесь выполнить что-то
и у вас нет прав на это действие.
Например, пытаетесь выполнить инструкцию, которую вы не можете выполнять в этом режиме.
Или что-то подобное.
Второе 14-е прерывание это PageFold.
PageFold возникает, когда вы пытаетесь обратиться к памяти,
которая вам в данном режиме недоступна.
У PageFold существует две полезных вещи.
Это адрес CR2, который вам говорит,
к какому адресу вы пытались обратиться, и у вас возникло исключение.
И код PageFold, который вам пушится вместе с контекстом,
в котором записано действие, которое вы пытались выполнить.
Например, там есть BitPresent в коде.
То есть была ли страница в памяти, когда вы пытались обратиться к ней.
Там BitWrite.
То есть пытались ли вы записать в эту память.
Или пытались прочитать.
BitUser, который говорит вам о том, что возник PageFold в пользовательском адресном пространстве.
Или в ядерном.
BitIF, то есть InstructionFetch.
То есть пытались ли вы исполнить какую-то память.
Или это была операция чтения или записи.
И, соответственно, эта информация вам может дать очень много
в процессе отлаживания вашей программы.
Особенно, когда вы пытаетесь обратиться к ней.
То есть довольно нередко у вас может упасть ваша хостовая операционная система.
Ну, там, не знаю, винда, там, Linux, Mac.
И у вас будет некоторый краш репорт, на который вы посмотрите.
И будете пытаться понять, что вообще произошло.
Вот наличие Stack Tracer и наличие, соответственно, вот этих дополнительных данных закодированных в регистре.
Они вам неплохо могут упростить задачу понимания проблемы.
А что же, собственно, произошло в данной точке.
На таблицу IDT указывает специальный регистр IDTR.
Ну, вы, соответственно, его помните по инструкции LIDT.
И, ну, как я уже говорил, в этом таблице.
И, ну, каждый слот в таблице IDT выглядит достаточно там понятным, очевидным образом.
То есть там есть, соответственно, кодовый сегмент и, соответственно, адрес RIP.
Куда нужно перейти в момент возникновения прерываний.
Уровень привилегий, с какими привилегиями нужно, собственно, обрабатывать данные прерываний.
Ну, понятно, что там всегда 0 пишется.
Потому что обрабатывать прерывания в пользовательском адресном пространстве, ну, практически всегда слишком небезопасно.
И сейчас, наверное, нет ни одной операционной системы, которая бы делала в не нулевом.
Тесно бит презент.
А можно ли, ну, то есть давай использовать, ну, какой-нибудь диапазон прерываний свободный.
Ну, то есть с правом пользователя обрабатывать, чтобы он мог пользоваться.
Технически можно практически, вот, честно говоря, не знаю, ни одной операционной системы, которая бы так делала.
Пользы от этого, если честно, тоже непонятно.
Вреда чаще всего много, потому что там на векторе может сидеть какое-нибудь устройство.
И в векторах и так тесно.
А, соответственно, просто обрабатывать голые прерывания от устройства прямо в режиме пользователей Aziz,
чаще всего чревато.
Вот, есть еще gate type.
Кому интересно, в принципе, могут прочитать, вот там есть ссылка специально.
Но основная, как бы вам, важность этого gate type, она заключается в том, что будут ли включены прерывания в момент входа в обработчик или не будут.
Собственно, механизм позволяет стереализовать прерывания, тем самым уменьшить количество, то есть уменьшить потребление стека в гидре,
тогда, когда прерывания обрабатываются.
Ну и, соответственно, IST, это там фишка x8664, это, соответственно, номер стека в TSS.
Таким образом, вы, соответственно, можете выбрать несколько стеков для обработки разных прерываний, устройств разных типов.
Например, там есть просто устройства, которые генируют много быстрых прерываний.
И вы, например, хотите их обрабатывать быстрее, и для этого, соответственно, используете специальный стек для этих прерываний.
Что касается, соответственно, самих системных вызовов, мы об этом уже немного поговорили.
Но, в общем-то, системные вызовы состоят из фактически двух частей.
То есть первая часть – это, собственно, ABI системных вызовов.
Если в случае кода генерации, например, хищного кода, у нас есть сложившаяся ABI.
Например, мы видели Microsoft x64 ABI, которая используется в UFI коде, или она в Windows также используется.
А также мы видели ABI System 5, которая используется во всех UNIX совместимых системах,
и она в том числе используется в JOS, определяющей, собственно, calling conventions,
или соглашение о вызове для функций.
То в случае с системными вызовами также существует ABI, но этот механизм является
специфичным для каждой отдельно взятой операционной системы,
и вот каждая операционная система определяет его по-своему.
Чаще всего при организации системных вызовов пользовательский код старается сохранить все аргументы
в некоторые регистры в определенном порядке,
и в дальнейшем из каких-то регистров получить результаты, которые ядро предоставит.
При этом, если необходимо обращаться к памяти, то у ядра одна из важных задач при обработке системных вызовов
появляется проверка, а можно ли писать или читать в ту или иную память,
которую передает пользователь.
Поэтому один из немаловажных моментов, который, как ни странно, также добавляет
оверхед при обработке системных вызовов, заключается в проверке прав доступа,
чтобы не возникла ситуация, когда вы выполнили какой-нибудь системный вызов с кодом записи,
с операцией, которая выполняет какую-то запись данных из ядра, например, в user space,
передали не свой указатель, а ядерный, и в результате ядро что-то перезаписало,
и тем самым, соответственно, отработало некорректно, и, например, произвело какую-то проблему в безопасности.
Как ни странно, вот проблемы такого типа достаточно часто возникают в операционных системах,
поэтому проверка, что в системном вызове нет возможности скомпрометировать операционные системы,
это одна из важных задач при разработке операционных систем,
и для этого строятся разные инструменты, о которых мы немножко позднее тоже поговорим.
В свою очередь в Jaws используется инструкция INT для генерации прерываний системных вызовов,
в частности INT30H, но в рамках индивидуального задания вам будет предложено реализовать специальные механизмы
для реализации системных вызовов, которые позволяют эти системные вызовы ускорить.
В X86 существует три основных пары организаций ускоренных системных вызовов.
Для 64-битных приложений есть стандартный механизм, который общий и для AMD, и для Intel.
Это, соответственно, функция syscall и sysret.
Когда вы выполняете функцию syscall, у вас не изменяется текущее значение RSP,
но при этом адрес RIP загружается из специального MSR-регистра.
Вот пример одного из MSR-регистров, который также является стандартным для процессоров разных производителей.
В частности, его поддерживают и AMD, и Intel, в отличие от специфичного для отдельного вентера регистра.
То есть он является частью ISA.
В свою очередь пользовательский RIP сохраняется в регистре RCX,
и когда вы выполните инструкцию sysret, он по этому регистру перейдет.
В случае с флагами у вас есть некоторая маска,
и в рамках этой маски вы удаляете те биты, которые вы бы не хотели, чтобы стояли при обработке системного вызова.
Например, флаг обработки прерываний, когда вы не хотите, чтобы в случае возникновения системного вызова у вас прервал таймер.
Что касается 32-битных приложений, то здесь есть некоторое разделение в зависимости от поддерживаемых архитектур.
В частности, у Intel есть механизм sysenter-sysexit, который не использует точно так же стэк,
но USP при этом меняется на значение, сохраненное в специальном MSR регистре.
Он также теряет значение RIP, потому что его перезаписывает на другое значение из MSR регистры.
При этом прервание маскируется безусловно, а остальные флаги остаются неизменными, что не очень удобно.
Это legacy-механизм, недостатки которого здесь видны, и они были учтены при разработке механизма syscall-sysred.
В случае с AMD, обычно AMD не поддерживает sysenter-sysexit, хотя вроде бы было несколько процессоров, которые этот набор инструкций поддерживали.
И там используется syscall-sysred, работающий в похожем режиме, то есть похожем на 6-3-убитный режим, но в 3-100-убитном режиме.
Что? Вопрос?
Вопрос.
У sysenter-sysexit не используется стэк, а для чего меняется ESP?
Чтобы можно было выполнять ядерный код на ядерном стэке.
Ну, у вас как бы при входе в обработчик системных вызовов можно сразу стишу на функцию написать.
Так, а как мы с адресом возврата живем?
Адрес возврата нужно сохранять через регистры или, соответственно, через память.
Ну, то есть адрес возврата нужно каким-то образом передать.
Потому что вот тут же, да, сказано, что EMI теряется.
Да, он теряется, да. Его нужно передавать через другие регистры или через память.
Вот такое вот неудобство.
Хорошо. Соответственно, когда мы обрабатываем системные вызовы,
мы меньше всего хотим, чтобы системный вызов себя вел неправильно.
Ну, или скорее привел к ситуации, которая может каким-то образом скомпрометировать наше ядро.
Как мы и помним, существуют специальные механизмы в таблице страниц,
которые предупрощают непреднамеренный доступ к памяти.
Вот мет такой как, собственно, исполнение страниц с данными,
тот же самый NX bit.
При этом X86, они по историческим причинам не зависят от текущего уровня привилегий.
Если, например, посмотреть на ММУ, используемое в каких-нибудь PowerPC букье,
то в данном ММУ устанавливаются раздельные наборы привилегий для пользователя и для ядра.
То есть, грубо говоря, память, которая доступна для чтения или для записи в пространстве пользователя,
она может быть целиком недоступна ни для чтения, ни для записи в пространстве ядра.
А в X86 так сложилось, что права соответственно пользователя действуют и в пространстве ядра.
То есть за единственным исключением, что пользователь не может получить доступ к ядру,
а вот ядро как раз может получить доступ к ядру целиком и полностью.
Дорешая эту проблему, в X86 добавили в CR4 специальные два бита,
называемые как раз SMAP и SMAP. Они же соответственно Supervisor Mode Access Prevention
и Supervisor Mode Execution Prevention.
SMAP просто запрещает исполнять всю память, которая доступна пользователю,
или имеет соответственно bit.u в таблице страниц.
SMAP в свою очередь запрещает любой доступ к памяти пользователя в ядре.
Соответственно это можно отключить, временно установив bit.ac в Airflux.
Сюда вопрос, допустим, что вы не хотите отключать SMAP,
как бы вы могли вернуть пользователю, например, какой-то память,
записав ему какие-нибудь данные через системный вызов?
Вопрос на понимание.
Ну, через регистры всегда можно.
Ну да, но допустим вам нужно вернуть пользователю очень большое количество памяти,
скажем, 2 мегабайт. Через регистры будет долго, очень долго.
Ну, в принципе, по-моему, есть кусочек памяти, который доступен пользователю только для чтения.
И что?
Ну, можно куда-нибудь туда попробовать записать.
Запрещает любой доступ к памяти пользователя в ядре.
Если у пользователя в ядре означает, что если в странице есть bit.u, то, соответственно,
пользователя она будет, то есть ядро она будет полностью недоступна.
Не важно, для чтения она, для записи, для исполнения, не важно.
Любая пользовательская страница будет недоступна для ядра.
Так, а если мы, Ватюм, какую-нибудь страничку снимем, с нее bit.u,
запишем, просто проигнорируем ее, содержаем ее, запишем что-то новое и установим bit.u?
Ну, это уже ближе. Так работать действительно будет, но спрашивается,
зачем с какой-то конкретной странички снимать bit.u, если можно просто сделать еще одно отображение
по какому-то другому адресу?
Ну, то есть вам никто не запретит, то есть если у вас есть отображение
на некоторой пользовательской странице, на какой-то физический адрес,
то вам никто не запрещает, соответственно, дать доступ
из другого адреса, который замапит чисто для ядра,
в этот же самый физический адрес и через него, собственно, записать.
Вот, понятная идея, да?
Точно с ума не сойдем, если начнем такие фокусы делать.
Ну, большинство современных операционных систем именно так работают.
То есть есть специальные вызовы, типа там vm-map в ядре,
которые вот как раз и реализуют всякие там функции, типа vm-write, vm-read и подобные.
То есть они делают там временное, например, отображение в адресном пространстве ядра
и таким образом, собственно, записывают.
С ума пока еще никогда не сошел, но действительно такой механизм
накладывает дополнительные ограничения на драйвер ММУ.
То есть вы, например, уже не можете использовать статическую конфигурацию памяти
в операционной системе или можете, но там достаточно ограничено.
И также, собственно, добавляет дополнительный overhead,
потому что вам приходится изменять состояние таблицы страниц
если не каждый, но, по крайней мере, при многих задачах доступа к памяти.
Но, тем не менее, безопасность требует жертв,
и на современных процессорах overhead он очень маленький,
поэтому в современных процессорах смап,
в современных операционных системах, на современных процессорах
вы вполне можете увидеть включенный смап в вашей операционной системе.
Вот. К сожалению или к счастью, вот такой механизм
он, скажем так, не всегда, не находит там все проблемы
на стадии, когда эти проблемы можно исправить.
То есть, как вы знаете, у вас нередко может произойти какое-нибудь повреждение,
например, памяти, но при этом, в тот момент, когда операционная система уже крашнется,
то есть генерирует какое-то сообщение об ошибке,
у вас уже может не быть тех данных, которые позволяют идентифицировать,
по какой причине, собственно, операционная система крашнулась.
Бывали у вас такие ситуации?
Ну, типа у нас в процессе выполнения там седьмой лавы крашился Джоз,
и еще он крашил Куэму заодно, причем без сообщения об ошибках.
Так что да, наверное.
Это у некоторых людей с некоторыми версиями Куэму.
Ну, здесь, конечно, пример из жизни немножко не тот, про который я говорил,
но, по крайней мере, у всех там что-то похожее в любом случае было,
то есть когда возникает некоторая ошибка,
и мы не можем фактически понять, а где конкретно эта ошибка произошла,
потому что, грубо говоря, момент краша, например,
и момент возникновения ошибки, они разнесены по времени,
и тем самым вы просто не можете установить,
собственно, какое изменение или какое действие повело к тому,
что такая проблема возникла.
Именно по этой причине в операционную систему,
по крайней мере в отладочную ее версию,
стараются внедрить максимальное количество проверок выполняемых в динамике,
которые, собственно, мониторят состояние операционной системы
или состояние программ, которые работают в этой операционной системе.
И в момент нарушения какого-то инварианта,
то есть в момент обнаружения, что операционная система работает некорректно,
стараются ее уронить максимально рано,
при этом собрать максимальное количество информации
о операционной системе в том месте, где этот вариант был нарушен.
Один из способов как раз выявить такие проблемы
это способы динамического инструментирования.
Динамическое инструментирование применяется много где,
и, наверное, два основных направления развития в нем есть.
Первое направление развития – это сбор метрик,
и он появился даже сильно раньше.
Например, слышали, наверное, про то, что должно быть полное покрытие кода тестами.
Слышали что-нибудь про такое?
Ну да.
Ну вот, мы, соответственно, примерно представляете,
как, наверное, работает механизм сбора покрытия в классическом виде.
Не очень, там слишком большое разветление дерева,
и реально это очень сложно посчитать.
Ну, в случае с разветлением дерева
действительно честный сбор покрытия посчитать очень сложно,
поэтому используют приближенные методы,
то есть такие как, например, покрытие по строкам
или покрытие по веткам, если брать классические способы сбора покрытия.
Есть там более интересные способы сбора покрытия типа MCDC,
то есть тогда, когда вы проверяете условно, что каждый, грубо говоря,
конъюнкт в дизюнкции был проверен как в состоянии единицы
независимо от всех остальных конъюнктов,
но это уже как бы такие более продвинутые способы сбора покрытия,
применяемые в специализированном Сейфти Критику программном обеспечении.
Но технически нам важно именно, как это происходит технически.
Для сбора покрытия преобразуется программный код
либо на уровне исходного языка, программирования что реже,
либо на уровне компилятора или эмулятора, в котором происходит исполнение.
Второй механизм чаще используется.
Таким образом, что в программе,
которую можно представить как некоторый Control Flow Graph,
все знают, наверное, из курса компиляторов,
что у вас есть некоторый граф потока управления,
в котором, грубо говоря, каждое условие это порождение
фактически двух базовых блоков, по которым может пойти программа.
У нас компиляторов пока не было, но, думаю, многие знают.
Да, ну вот, хорошо, значит, будете...
А, да, у вас следующий, наверное, семестр.
Окей, ну вот, вам на всякий случай про это расскажут,
но вещь достаточно известная, что у вас есть фактически набор базовых блоков,
и, соответственно, они являются, соответственно,
части у графа потока управления.
То есть в момент, когда у вас появляются условия,
то есть у вас происходит расщепление вот этого графа.
И для того, чтобы, например, собрать простейшее покрытие по строкам,
вам достаточно добавить каунтеры во все базовые блоки.
И в момент, собственно, когда вы выполнили какую-то программу,
просто посмотреть, что мы действительно там прошли по всем блокам,
просто проверив эти каунтеры и отобразив там в отчете,
что соответствующий конкретным строкам, например,
на C каунтере установлены в единицу.
Если да, то тогда покрытие этого блока произошло.
Вторым направлением развития динамического инструментирования
является направление с поиском ошибок.
И там поиск ошибок — это, ну, например,
некоторая там трансформация, скажем так, программы,
таким образом, чтобы в момент, когда там программа что-то делает,
проверять, ну, что происходит,
чтобы в момент, когда там программа что-то делает,
проверялись дополнительные структуры,
дополнительные какие-то особенности,
позволяющие вам выявить ошибку, например, на более раннем уровне.
Простейший пример, который я, кажется, ранее уже приводил на защите.
Вот представьте, что у вас есть процессор 1, процессор 2.
В программе происходит целочисленное деление на ноль.
Вы знаете, что деление на ноль,
с точки зрения языка оси, это неопределенное поведение.
Но вот так сложилось, что вы не уследили за своей программой
и все-таки на ноль разделили.
Вот, допустим, интеловский процессор хороший,
он сгенирует исключения в момент, когда вы на ноль разделите.
Однако другие процессоры могут быть далеко не такими хорошими.
Например, на PowerPC разделили на ноль, получили ноль.
Ну вот так.
И самый простой пример динамического инструментирования для поиска ошибок.
А давайте на уровне компилятора вставим проверку перед инструкцией деления,
что делитель не равен нулю.
Если, соответственно, делитель равен нулю,
то всегда будем генерировать какое-нибудь сообщение об ошибке
и ронять программу.
Это простой пример, который вам позволит найти ошибки
независимо от того, какая архитектура у вас используется.
Именно по этому пути идут вещи типа санитайзеров LLVM,
которыми вы начали использовать
и которые, собственно, начиная как раз с восьмой лабораторной работы,
у вас будут действовать в расширенном режиме,
то есть у вас появятся санитайзеры и в пользовательском адресном пространстве,
и в ядре.
Соответственно, само по себе инструментирование может выполняться
как внутри программного обеспечения,
например, посредством добавления кода некоторым компиляторам,
так и в изолированной среде.
Например, это может быть виртуальная машина Quay.
Кто-нибудь может сказать, когда второй способ инструментирования предпочтительнее?
Тут вариантов много.
Например, в Valgrind используется что-то больше похожее на второй способ,
потому что ему надо к теневой памяти играться.
Но при этом адрес санитайзер также использует теневую память
и работает внутри программы.
Может, когда у нас нет исходного кода?
Да, вот это один из примеров ситуации, когда в изолированной среде работать удобнее.
Если у нас нет исходного кода к программе,
то ее можно инструментировать с помощью эмулятора.
Так работают некоторые файзеры.
Кроме этого, еще возникают ситуации,
когда у вас, например, может быть в целевой машине
достаточно малое количество оперативной памяти
и вы просто не можете разместить ваш инструмент
на целевом устройстве,
внутри вот этого вот программного пакета.
Но при этом вы можете написать эмулятор этого целевого устройства
и уже в эмуляторе инспектировать состояние вашего кода.
То есть такой механизм тоже вполне себе работает.
Итак, санитайзеры LVM.
Санитайзеры изначально были проектом Google,
который можно найти на нашей странице на вики,
где есть достаточно подробное описание.
Идея у этих санитайзеров заключается в том,
что в программу добавляются специальные санитайзеры,
добавляются специальные конструкции,
автоматические на этапе компиляции,
максимально бесплатно предоставляемые проверки,
при условии, что у вас есть компилятор Clang
или с некоторыми исключениями компилятор GCC.
Там санитайзеры есть, но они добавляются медленнее,
и соответственно не все,
потому что в первую очередь санитайзеры
довалились как фича в компилятор LVM.
Вот на слайде есть примеры санитайзеров,
которые каждый направлен на выявление определённых классов ошибок.
Например, адрес санитайзер – это инструмент,
который ищет ошибки при обращении к оперативной памяти.
То есть представьте, что у вас есть, грубо говоря, адрес,
и вы хотите проверить,
что могу ли я к этому адресу обращаться или нет.
Адрес санитайзер вам на этот вопрос ответит
за счёт достаточно простого механизма
под названием «теневая память».
Читали уже такое «теневая память»?
Ну, по крайней мере, на вики написано было у нас.
Не читали, но это вроде как какие-то свои аллокаторы делают.
Ну, не совсем.
То есть идея заключается в следующем.
То есть у вас есть основная оперативная память,
она же Origin.
Но когда вы работаете с обычной оперативной памятью,
вам, собственно, есть доступ к вашей памяти,
с которой вы непосредственно читаете, пишете,
к стеку доступ, к куче доступ,
к глобальным переменным доступам и так далее.
Мы можем вот эту память
отобразить некоторым образом на другую память,
так называемую «теневую».
Отображение происходит
посредством простой арифметической операции,
в частности сдвиг и смещения.
То есть взяли, грубо говоря, адрес,
сдвинули его на три
и прибавили некоторое число именуемое
на базовым адресом теневой памяти.
Получили некоторый другой адрес.
И вот мы считаем, что в этой теневой памяти
у нас хранится статус доступности памяти Origin.
То есть если, например, вот так вот,
сформировав адрес тени,
мы получим адрес,
в котором будет, например, лежать единичка,
то это означает, что мы получили адрес,
в котором обращаться нельзя.
А если мы получили адрес тени,
в котором лежит нолик,
то это означает, что, соответственно,
к этому адресу обращаться можно.
Соответственно, задача инструмента
заключается в том, чтобы построить
вот как раз эту карту адресов
в теневой памяти,
к которым можно и нельзя обращаться,
и поддерживать ее, соответственно,
в актуальном состоянии.
А также, соответственно,
при обращении к любому адресу
в вашей программе
организовать проверки,
что вот по соответствующим адресам,
действительно там,
по соответствующим адресам,
теневым адресам,
действительно находятся там нолики.
То есть мы имеем полное право
к этой памяти обращаться.
Понятен механизм?
Ну да.
То есть это по типу как
битва и вектора доступности
всех этих обходов,
DFS, например, где-нибудь.
Ну да.
То есть идея в том, чтобы просто
это запихать, соответственно,
в генерируемый инструмент,
в генерируемый компилятором код
без каких-то внешних программ,
фактически.
Соответственно, например, у вас там есть
глобальная переменная.
Эта глобальная переменная может, например,
быть типа sizeT,
например, занимать 8 байт
на архитектуре Intel x86-64.
Мы берем и отступаем
от этой глобальной переменной
по 8 байт, например, слева и справа.
Тем самым сформируем некоторые
красные зоны,
в попадание в которые, соответственно,
будет у нас считаться ошибкой
доступа к памяти.
Соответственно, в теневой памяти
мы можем взять, например,
по 3 байта.
То есть 3 байта там.
Соответственно, 1 байт
будет полностью забиться единицами
перед этой переменной,
потом следующей забит нулями
и потом опять единицами.
И тем самым, если мы обратимся
по адресу следующему
за этой переменной,
то инструмент сгенерирует ошибку,
а если, соответственно, по адресу перед,
если по адресу этой переменной,
то, соответственно, ошибки не будет.
По
такому же принципу работают,
например, аллокаторы.
То есть, если у вас есть аллокатор
с, например, Free,
то можно
пометить ту память,
которую мы только что освободили,
как Poisoned
и потом, соответственно, стараться
максимально
долго эту память не переиспользовать
под следующей аллокацией.
Тем самым, если мы разуменуем
указатель, который
уже был освобожден,
то, соответственно, инструмент сообщит об ошибке,
что у вас типа User-to-Free.
В зависимости от того,
как организована
там операционная система,
у вас адрес-санитайзер может
работать либо в режиме там черного списка,
либо в режиме
белого списка.
Режим белого списка
означает, что инструмент
знает обо всех адресах, которые
доступны для
обращения
и разрешает
доступ только по ним.
Соответственно, режим
черного списка
работает
в большинстве
операционных систем
общего назначения
в ситуации, когда вы разрешаете доступ
ко всей памяти, за исключением
тех адресов, которые
вы явно пометили как недоступными,
ну, то есть, такими как RedZone,
соответственно, освобожденная память
и так далее.
Понятно, что при добавлении
инструмента в операционную систему
начинать нужно там
чаще всего с режима черного
списка, но
при развитии
операционной системы или программы
можно и
достичь там, например, вполне себе белого списка,
то есть, как в джойсе, например, сделано.
Memory-санитайзер
работает точно
так же, как адрес-санитайзер,
но он
говорит не о том,
какая память доступна,
какая, собственно, недоступна,
а проверяет статус инициализации.
То есть, вот скажите мне
обращение к
неинициализированной памяти
является неопределенным поведением
с точки зрения языка C или C++?
Ну,
если речь идет о глобальной переменной,
то по стандарту не обязана быть
инициализированной в автоматическом времени.
Да, допустим,
соответственно, эта переменная
в куче или на стеке.
Да, это является
по стандарту
неопределенным поведением.
Нет, я с вами не согласен.
Я про неопределенное поведение
отвечал на вопросы там, был про это.
Ну ладно.
Ну, смотрите, не всякое обращение
к неинициализированной памяти
является неопределенным поведением.
Например, если я просто...
А, на ручейне надо опять полнеопределенное вроде, да?
Это тоже,
но я имел в виду чтение.
Например, если вы просто скопируете
неинициализированную память
в другую там память,
это не является неопределенным поведением.
У вас там может быть паддинг
какой-нибудь неинициализированной,
или просто неинициализированная еще переменная.
Проблемы
возникают, когда вы, например,
начинаете витвиться
по значению
вот этой вот, собственно,
неинициализированной переменной.
Или когда вы пытаетесь, например, перейти
по указателю, который неинициализирован.
Или когда вы, например,
начинаете передавать
значение неинициализированной памяти
в системные вызовы.
То есть вот проблемы начинаются здесь.
А просто там
скопировать память это совершенно нормально.
Нормально, потому что у вас может быть, например,
часть байт в буфере неинициализированной.
Представьте, что у вас там, например,
256 байт
используется, например,
для строки с названием. У вас
строка заполнена в первые 16,
а, соответственно, 17
нулевой.
И вы, соответственно, mem.spy
копируете все 256 байт.
Это поведение вполне себе
определено, оно вполне нормальное.
Поэтому Memory Sanitizer
как инструмент
он проверяет
статусы
инициализации памяти
именно в тех случаях,
когда обращение к ней является
неопределенным поведением.
Например, ветвление в программе.
И кроме этого, он также
имеет функцию пропагейта.
То есть когда вы,
например, копируете
неинициализированную память
в какой-то участок
в программе, то у вас также
обновляется теневая память
нового участка,
ну, то есть,
куда вы скопировали,
сохраняя, соответственно, статус
неинициализированной памяти
от той, из которой вы изначально
копируете.
Кроме этого,
существует
такой инструмент, как
Undefined Behavior Sanitizer.
Он у вас также есть в джосе
и в его задачи, соответственно,
входит поиск неопределенного поведения,
например, за сдвиговыми операциями,
с операциями с плавающей
точкой,
с операциями
арифметики,
деления на ноль
и так далее.
Соответственно, он наиболее
простой
из тех, которые
можно поддержать
в операционной системе,
потому что он не требует
теневой памяти,
но при этом достаточно
полезный, например,
он также еще позволяет определить
обращения по невыровненным указателям,
которые в
ином случае были бы
не обнаружены, потому что
далеко не все процессоры
могут обнаруживать
даже, не говоря
про то, что не поддерживают
обращения к
невыровненным указателям,
хотя такие процессоры есть
и, соответственно, отлаживать ваш код
без undefinedBehaviourSanitizer
на предмет невыровненных указателей
не то, чтобы тревя.
Есть также
такие инструменты,
как ThreadSanitizer,
который позволяет находить
гонки, то есть, когда вы пытаетесь
обратиться к данным
из двух потоков
и не обеспечиваете при этом
экстранизацию.
LeakSanitizer, позволяющий
найти утечки
оперативной памяти
при использовании
кучи.
SafeStack, то есть, скажем так,
минифицированная версия
адрес санитайзера,
проверяющая, соответственно,
на переполнение
данных на стэки и, соответственно,
предвращающий эксплуатацию
некоторых уязвимостей,
собственно, несколько
выбивающихся из всех этих инструментов,
потому что, в первую очередь,
эти инструменты предназначены для работы
в отладочном режиме
программы, когда же SafeStack
предназначен
для использования в боевом режиме.
EfficientSanitizer,
то есть, инструмент, который
ищет использование
не очень удачных
конструкций
в вашем коде, который можно было бы
переписать иным способом
для повышения прообразовательности
вашей программы.
Липфазер, то есть, фазер,
который используется
в связке со всеми
инструментами для
построения некоторых входных
данных, которые
бы позволили вам
находить ошибки
в вашей программе, говорим чуть позже.
Как вообще
реализовать
Sanitizer
в операционной системе?
Здесь есть
некоторая тройка.
То есть, первая часть
это кодогенерация.
То есть, ваш компилятор
должен поддерживать
генерацию
инструментированного кода, который
будет лезть, например, в теневую память,
который будет вставлять
проверки на деление
на ноль, например,
или на неправильную работу
с издигами.
Второй момент
это поддержка
на уровне следы
выполнения, то есть, на уровне рантайма.
Здесь можно
пойти несколькими
путями. Например,
в LLVM есть
библиотечка CompilerRT,
она же библиотечка built-in,
предоставляющая
сервисы
для работы
скомпилированных
с помощью LLVM Clang
программ,
типа программного деления
и так далее.
Она, соответственно, также предоставляет
и рантайм для работы
Sanitizer, основной задачей
которого это вывод
человека понятных
ошибок и инициализация
инструмента
на конкретной
операционной системе.
Можно пойти
другим путем
и реализовать
для операционной системы,
например, для ядра Linux
или для ядра Mac
некоторый свой рантайм специфичный
для данной
операционной системы.
Например,
в JOS
используется
некоторый гибрид
для поддержки адрес Sanitizer
и undefined behavior Sanitizer
из BSD системы,
в частности, из Mac
и из NetBSD
используется адаптированный рантайм.
И, соответственно,
третий момент
это добавление
поддержки на уровне исходного кода
в вашего
конкретного взятого
проекта,
потому что
когда вы инициализируете, например,
пользовательскую программу,
в целом можно подстроить
инициализацию операционной системы
так, чтобы
Sanitizer можно было
использовать сразу же.
Однако, если речь идет
о санитайзинге
прелегированного кода,
то есть кодом является ядро
операционной системы,
в самом начале
у вас может не быть
таких базовых вещей, как
аллокатора, возможности отображать
какую-то оперативную память,
у вас
вообще может не быть
даже принтфа условно
для того, чтобы вывести какую-то информацию
на экран
или в serial port.
Поэтому
операционная система обычно делится,
так сказать, на две стадии.
Стадия до инициализации инструмента
и стадия после
инициализации инструмента.
И, соответственно, нужно
во-первых
подправить систему сборки,
чтобы код,
выполняющийся на начальном
стадии инициализации, не выполнялся
под
санитайзером,
если речь идет о санитайзере Halloween.
И, соответственно, подправить сам код
таким образом, чтобы
санитайзер инициализировался
максимально рано.
При этом
также могут быть полезные
аннотации
для отдельных функций
и отдельных инструментов.
Например,
мы этим достаточно регулярно
пользуемся, мы аннотируем
системные вызовы
в операционные системы
для того, чтобы
поймать
неправомерное
использование этих
системных вызовов
с какими-то некорректными данными
на более ранних этапах
и
тем самым пользователи
об этом сообщить
в более понятном виде.
Соответственно,
если говорить
об использовании
инструментов, то вот есть
некоторая такая карта.
У вас в
джосе реализованы
первые два.
Убесан и
асан у вас сейчас
появились как в пользовательском адресном
пространстве, так и
в юзерском.
О механизмах их работы
можно почитать у нас на вики,
можно почитать
на страничке Google санитайзер.
Там же, соответственно, есть
пейперы, которые описывают
такие вещи,
как безопасный stack
при использовании
санитайзеров.
Что касается
memory санитайзера и thread санитайзера,
то это
индивидуальные задания,
можно их взять
и реализовать
в джосе
их поддержку
в индивидуальном порядке.
В двух словах,
чем должен заниматься thread санитайзер?
Смотреть, что пользовательский процесс
отдает thread?
Если
очень вкратце,
то у вас, грубо говоря,
есть такое понятие, условно,
happens before, happens after.
И thread санитайзер
проверяет
фактически, что
не было
обращений
к отдельному участку
памяти
из
параллельного потока
в конкретный момент
времени.
Если по существу,
то
thread санитайзер работает
наиболее хорошо, когда у вас
большое количество ядер.
В отличие от
убесана, асана и эмсана,
которые гарантированно находят ошибку,
если она есть,
и если, соответственно, код через нее пройдет,
то thread сан имеет
достаточно
предикативный
механизм работы,
когда
вы узнаете о проблеме,
например, если у вас программа работает
на четырех физических ядрах,
а если на двух физических ядрах,
то, возможно, вы и не увидите проблемы.
Что касается файзинга,
то
файзинг на самом деле является
некоторым развитием
динамического инструментирования,
связанный
с тем, что
когда мы
сделали нашу программу наиболее
восприимчивой к тому, чтобы тайна
становилась явным,
то есть мы
переделали нашу программу,
таким образом, что в ней
появилось больше инвариантов
и, соответственно,
в больших случаях программа может
сообщить о том, что что-то произошло не так,
мы ее
автоматически хотим
также иметь возможность
воспроизвести эти ситуации,
потому что, в отличие
от статического анализа, который
происходит с программой без ее запуска,
динамический анализ
имеет одну большую слабость.
Чтобы выявить какую-то
проблему,
вам необходимо действительно
эту проблему
выполнить в самой программе,
то есть фактически
нужно, чтобы программа
прошла по конкретному пути
возникновения этой проблемы,
при этом там данные, которые
при этом порождаются,
действительно должны вызывать
так называемое
интересное поведение программы.
Термин
из файзинга
интересное поведение
программы может быть как условно краж
этой программы,
так срабатывание инструмента,
так и, например, зависание программы
или просто какое-то
неожиданное ее поведение,
неожиданный ответ.
Интересное поведение программы
может по-разному фиксироваться,
то есть наиболее простой способ
это действительно просто фиксировать краши.
Но в случае,
например, какого-нибудь
Model Checking,
то можно определить, что интересное поведение
программы – это выдача
какого-либо кода ответа
за исключением
вот такого-то, такого-то и такого-то.
То есть программа может и не упала,
но вернула что-то неожиданное.
Соответственно, сам по себе
фазинг
заключается в том,
что мы можем генерировать
некоторые
псевдослучайные входные данные
собственно
с самой целью
вызвать вот это интересное поведение.
То есть
генерация
она может осуществляться
разным способом,
и в этом как раз лежит классификация фазингов.
То есть, например,
бывает фазинг
генерационный.
Генерационный фазинг, или фазинг,
часто еще его называют фазинг по грамматикам
выполняется тогда, когда у вас есть
некоторый
известный
фактически
формат, грубо говоря, данных.
Например, сказано, что у вас
есть
картинка с таким-то
заголовком.
И, соответственно, фазер
будет порождать
только картинки,
даже не только картинки,
а только данные,
которые будут содержать некоторые
из заголовок, и тем самым
соответственно сможет пройти
часть проверок
в программе, которые отсекают
данные,
то есть отсекают некорректные
входные данные, позволяет
войти
в более интересные места в программе.
Вариант второй
это, например, мутационный фазинг,
то есть тогда, когда у вас есть
некоторый корпус данных,
например,
вот эти самые картинки,
и вы просто псевдослучайным образом
меняете
определенные последовательности байт
на другие и проверяете,
как на них будет реагировать
ваша программа.
Можно все это смешивать
и получится,
например, эволюционирующий
фазинг, тогда,
когда у вас
поведение
программы,
например, сбор покрытия
говорит о том, что
соответственно
по прогону
получившегося
объекта входных данных
у вас улучшилось покрытие
в
вашей программе.
Соответственно, значит, что
нужно пробовать мутировать,
например, этот новый вариант,
и, возможно, он позволит пойти
в еще более новые места.
Соответственно, вот как раз
липфайзер это пример
мутационного эволюционирующего
файзера.
При этом файзеры
работать могут бесконечно
долго.
И, скажем так,
идея
фазинга, она заключается
в том, что вы, например, выпустили
некоторый программный продукт,
и после
этого ваш продукт
бесконечно долго фазится,
и когда, соответственно, он
находит, например, какое-нибудь падение,
то вполне возможно, что
в вашей программе есть проблемы
безопасности. Не обязательно
безопасности, но какие-то проблемы.
Соответственно, также фазеры
бывают
умными
или глупыми.
Соответственно,
умный файзер
он либо знает,
структуру входных данных
либо ее не знает.
Например,
как раз
построение входных данных,
то файзеры они чаще всего умные,
потому что они знают, в каком формате
нужно выдавать входные данные.
В свою очередь там, например, ли файзер,
это глупый файзер, который
просто генирует какой-то последователь,
какой-то набор байт,
не зная о том, что он именно генирует.
И, соответственно, файзеры
могут быть белого или черного ящика,
то есть они могут либо знать
о
структуре программы,
либо, собственно, ее не знать.
То есть когда
соответственно, файзер ничего
не знает о
структуре программы, это черный ящик,
то есть он просто подает на какие-то
входные данные и смотрит, как эту программу
поведет.
Если файзер
специально, нацеленно
подает какие-то входные данные,
ну, например, за счет анализа
с помощью солвера
некоторого потока управления в программе,
и выявив, что
подав такие данные, он действительно
дойдет до какого-то там отдельного
блока, который ему кажется интересен,
то это файзер соответственно
белого ящика.
Более подробно
есть в книжке,
которая доступна по ссылке,
я рекомендую, по крайней мере,
прочесть введение.
Оно позволит,
по крайней мере, понять,
как вообще
файзеры используются,
и
на самом деле можно попробовать там
почитать документацию
на лифт файзер
на странице
LLVM,
по крайней мере, будет понятно там
условный quick start guide,
как можно легко проверить
свой код на предмет
ошибок, например, работы с памятью.
На этом
у меня все.
Если еще есть какие-то вопросы,
то готов на них ответить.
Спасибо.
Спасибо, но тут
комментарии есть, просто я чуть-чуть
про файзеры смотрел, еще есть серые
в ящиках файзеры.
Да, серые в ящиках файзеры это что-то
среднее между белыми
и серыми, но чаще всего
про серые говорят,
что это вот те, которые с покрытием.
Ну, то есть,
когда
грубо говоря, у вас
либо там есть
некоторый фидбэк
на основе покрытия,
либо там
когда у вас
симбиоз
solver
и, соответственно, не solver.
То есть, когда solver не справляется,
то просто работает файзер черного ящика.
Когда solver что-то нашел,
от него данные
приходят.
Ну, там вроде что-то по типу
мы знаем, что когда n
больше тысячи, программа ведет себя не так,
как n меньше тысячи.
Как конкретно не знаем, но, возможно,
стоит генерить и такие-такие тесты.
Это вроде серый ящик получается.
Ну,
не обязательно,
но, в принципе, надо смотреть в отдельные
случаи.
То есть, вот откуда пришло
название n больше тысячи?
Если оно пришло, грубо говоря,
от solver,
то тогда возможно.
А если
это просто какое-то интересное значение,
то
скорее это файзер
черного ящика.
То есть,
грубо говоря, интересные значения, например,
когда у вас происходит мутационный файзинг,
то
интересными значениями являются 0,
f, f, f, f,
и, то есть, такие подобные значения,
которые чаще приводят к крашам.
То есть, они были выявлены, грубо говоря,
на статистическом
каком-то тестировании, и, соответственно, файзеры их
вставляются
при мутациях использовать в первую очередь.
Но вообще сейчас
большую часть файзеров можно привести
к категории серого ящика.
То есть, скорее белый-серый
и вообще все примеры
из предыдущего слайда
это такие границы,
которые
можно определить на плоскости
или на каком-то
многомерном пространстве. И, соответственно,
каждый отдельно взятый файзер
будет ближе к тому-то,
ближе к тому-то,
как и любой другой инструмент.
Потому что хороший файзер
использует большое количество
параметров.
Можете сходить
к ребятам
с первого этажа
мы студии системного программирования,
когда будете в гостях
в Испе.
Они там много расскажут про
Испфайзер
и не только про него.
На этом, я думаю, можно
заканчивать и потихоньку
переходить
к защите.
