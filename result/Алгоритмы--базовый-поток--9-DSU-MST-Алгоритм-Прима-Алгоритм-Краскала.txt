Своиста дерева. Своиста дерева состоит в том, что у каждого элемента ровно один родитель.
Давайте просто обрабатываем нашу кукуту.
Выведем размер, который совпадает со размером общей системы непосекающих новостей, то есть общего количества элементов.
И просто для каждого элемента в ячейке массива будем хранить его родителя.
Для любого элемента родителем является двойка, поэтому написано двойка.
Для четверки родителем является восьмерка, поэтому тут записано восьмерка.
И так далее.
Аналогично в этой структуре данных можно помечать узлы, которые являются корнями.
Например, тут представлен вариант, когда вы говорите, что у вас корень зациклен сам на себя.
Если родителем элемента является эта вершина, то соответственно этот корень.
Вы можете там представлять себе это другим образом.
Либо хранить какие-то наны, либо минус единицу.
Просто каким-то образом вы помечаете, что это корень дерева, то есть выше уже подняться нельзя.
И вот таким образом я на самом деле представляю все дерева, которые есть в моей теме перескальшим родцам.
Понятно?
То есть всего лишь один массив, и я сразу же все понимаю.
Допустим, на как-то удалось организовать все множество видов таких вот деревьев,
и соответственно эту структуру данных очень легко представлять в виде просто массива,
в каждом элементе, в этом индексе которого мы просто храним предка этого элемента.
Надо посмотреть, вот для единицы шестерка, вот для единицы шестерка.
Ну тройка соответственно корень, поэтому там хранить тройка ну либо минус единицы,
либо как-то еще мы помечаем, что это корень.
Другой вопрос.
Другой вопрос, да.
Другой вопрос стоит следующим образом.
Ну хорошо, допустим у нас есть такая структура данных, давайте обсудим то,
как можно выполнять те или иные операции.
Понимаете ли вы, как можно выполнить операцию, например, make set?
Как создать новое одноэлементное множество?
Да, соответственно вот тут у нас в примере всего 9 элементов,
соответственно мы создаем новую вершинку,
ну и говорим, что это дерево зациклено само у себя.
Вектор делаем pushback в девятке.
То есть make set это просто pushback.
На pushback вот в этот вектор родителей.
Теперь соответственно давайте поговорим про find set.
Нет, звездочками тут просто помечено, что это корни дерева.
То есть тут имеется в виду, что вот тут вы можете поступать по-разному.
То есть либо вершина может ссылаться само на себя,
если она корень, можете там писать минус единицу,
можете ставить на ан.
В общем, каким-то образом просто умеете, что это корень.
Ну тут для удобства я сделал так, что мне так удобнее,
что вершина ссылается на само себя.
Если вершина ссылается на само себя, значит у нас сама себе корень.
Вот.
Окей.
Давайте теперь поговорим про другие операции.
Ну короче, с make set все понятно, все просто
давайте поговорим про find set.
Давайте напомним, что такое find set.
Значит find set возвращает некоторый идентификатор множества,
в котором лежит x.
Т.е. find set от x это идентификатор множца, в котором лежит x.
То есть главное свойство find set – это то,
что find set от x равно find set от y,
тогда и только тогда, когда x и y лежат в одном множестве.
Что можно возвращать в качестве ответа у find sets?
Если у нас есть вот такая вот структура.
Допустим я прошу find set от 5, и find set от 4.
Что мне можно вернуть от 5 и от 4, чтобы как бы изменить
чтобы их индексы совпадали. Если у нас каждое множество организованно в виде некоторого корневого дерева,
то у всех вершин будет один общий корень, согласны? И поэтому если я для каждой вершины, для каждого элемента
буду возвращать корень соответствующего дерева, то соответствующего элемента из одного множества будет один и тот же представитель.
То есть, грубо говоря, это еще иногда называют представителями, а не родителями. У всех элементов здесь один общий представитель.
Здесь у всех элементов один представитель – это шестерка, здесь у всех элементов один представитель – это тройка.
Соответственно, мы для двух элементов возвращаем просто корень соответствующего дерева. Если корни различные, значит они лежат в разных множествах,
если корни один и тот же, значит они лежат в одном множестве. Просто? Окей, давайте посмотрим, как это выглядит.
Ну, соответственно, find set. Вот find set выглядит очень просто. Меня спросили find set от x, и я говорю, что пока у меня x не совпадает со своим собственным…
пока x не является своим собственным представителем, то есть пока я не дошел до корня, я поднимаюсь наверх.
Вот только я поднялся наверх, я возвращаю, собственно, x. Вот здесь сам корень.
Ну и как вы понимаете, время работы одной операции find set – это от h от x, где h от x – это глубина, на которой находится элемент x.
Прогласны? Окей. Следующая операция – это union. Давайте посмотрим… ну давайте нарисуем здесь картинку.
Допустим, у меня есть какие-то два множества.
Допустим, здесь x, тут y. Я говорю union x, y.
Напомню, что делает union. Union объединяет два множества, то есть множество, в котором находится x, и множество, в котором находится y.
То есть теперь эти элементы должны лежать в одном множестве, плюс все элементы, в которых они раньше держались, тоже должны лежать в одном множестве.
То есть грубо говоря, я беру все это множество и должен объединиться со всем этим множеством.
Да, и тут в этой постановке, в таком построении нашей структуры данных, тоже достаточно просто реализовать эту операцию.
То есть достаточно просто, например, этот корень привязать к этому корню, ну либо наоборот.
То есть достаточно всего лишь добавить одну ссылку. Согласны?
Сейчас тут проблемы будут, но пока давайте просто поговорим про базовую реализацию.
Базовая реализация действительно очень простая.
Значит, во-первых, если я говорю union x, y, не нужно взять представителя x, a.
Надо взять корень дерева, в котором лежит x, взять корень, в котором дерево, в котором лежит y,
и, например, привязать дерево y к x.
Ну либо наоборот, взять period от y равно x.
Вот, да, это действительно хороший вопрос.
Давайте пока констатируем тот факт, что время работы это theta от h от x плюс h от y.
Почему? Потому что файнцет первый работает за h от x,
второй файнцет работает за h от y, ну глубину находится y,
ну а это, соответственно, вот единица, в этом ничего страшного.
Соответственно, теперь понятно, как у нас возникают вот такие вот деревья.
Как у нас строятся деревья, понятно.
То есть изначально у нас есть просто набор отдельных вершин,
а потом в какие-то моменты мы вызываем union и, соответственно,
у нас возникают вот такие вот иерархические структуры.
Понятно, да? Просто одно дерево подвешено к другому дереву,
и, соответственно, у нас возникают вот такие вот конструкции.
Понятно, да? Вот.
Так, ну действительно, собственно, прозвучало уже небольшое опасение,
ну как небольшое, большое опасение, которое заключалось в том, что,
ну вообще говоря, если мы действуем вот по такой-то поискеме,
то есть, ну окей, да, union работает,
union работает, ну в смысле, вот, сама значимая часть union работает довольно быстро.
Да, но вот find set у нас может работать теоретически долго. Почему?
Потому что работает за глубину, за глубину соответствующей вершины.
Да? Ну и, на самом деле, легко представить себе ситуацию,
при которой у нас соответствующие деревья будут вырождаться в цепочку.
Например, вот я сделал, я объединил вот так, ну давайте наоборот.
Я объединил вот этот элемент вот этим элемент, привязал он к этому корню,
дальше я решил объединить вот это дерево с вот этим деревом,
и привязал вот так. Дальше объединил вот это дерево с вот этим элементом
и учу такую ситуацию. Ну и так далее.
В итоге у меня дерево вырождается в список.
Соответственно, find set работает за линейное время от размера самого
дерева или от размера самого множества.
Ну естественно, это, наверное, не то, чего мы хотим.ering foundation.
Давайте подумаем, как мы можем это улучшить.
Ну да, проблема. Возможно, действительно, линейный рост глубинных деревьев.
То есть у аташ вырождается вот это. То есть если у нас есть какая-то цепочка,
и мы ее, соответственно, подвешиваем к дереву, то у нас длина цепочки, соответственно, увеличивается.
Давайте подумаем, как это можно исправить.
Ну, исправить на самом деле это очень просто.
Ну, смотрите, какая у нас проблема тут возникает. Давайте переписуем.
Вот, допустим, у меня есть какое-то очень большое дерево. Есть маленькое дерево.
Ну, большое в смысле глубины и маленькое в смысле глубины.
А какое дерево какому выгоднее всего подвешивать?
Маленькое к большому или, наоборот, большое к маленькому?
Да, маленькое к большому. Почему?
Потому что если пусть здесь глубина этого дерева равна 10,
а глубина этого дерева, скажем, равна 5,
тогда когда мы подвешиваем маленькое дерево к большому,
у нас глубина под дерева увеличивается на 1, и глубина всего дерева не изменяется никак.
Потому что глубина была равна 10, и у того дерева она тоже стала равна 10-ти.
Но если я поступлю наоборот, если я буду, наоборот, большое дерево подвешивать к маленькому,
то возникает беда. У меня был большой поддерево глубины 10, и оно увеличило свою глубину на единицу.
Соответственно, чтобы у меня максимальная глубина поддеревьев не увеличивалась,
мне выгоднее подвешивать маленькое дерево к большому.
В этом заключается ранговая ивристика.
Что такое ранг? Ранг – это просто верхняя оценка на глубину дерева.
Почему верхняя оценка станет понятна позже? Пока у нас ранг в точности будет совпадать с глубиной дерева.
В последствии он станет просто верхней оценкой. Давайте считать, что ранг – это глубина дерева.
К верхней оценке перейдем потом.
Для каждой вершины храним ранг. Что такое ранг? Ранг – это глубина дерева, в котором глубина соответствующего под дерево.
Что мы делаем? Переходим к корням деревьев.
x равно фанцет от x, y равно фанцет от y.
Перешли к корням деревьев x и y.
Если глубина дерева x меньше, чем глубина дерева y, то подвешиваем x к y.
Если ранг y меньше, чем ранг x, то подвешиваем y к x.
Понятно ли последние условия else?
На самом деле, картина не настолько радужная.
Действительно, мы понимаем, что если мы маленькое дерево подвешиваем к большому, то у нас глубина не изменяется.
А что делать, если у нас глубины одинаковые?
Скажем, и тут 5, и тут 5.
Ну да, именно оно.
Если у вас глубина первого дерева меньше, чем второго, то мы первое подвешиваем к второму.
Если глубина второго дерева меньше, чем глубина первого, то подвешиваем второе к первому.
А если глубины одинаковые, то это единственная есть ситуация, когда нам все равно, что к чему подвешивать.
У нас, как ни крути, глубина дерева увеличится на единицу.
В последнем else это и написано, что если у меня все-таки ранги совпадают, то, например, я x подвешиваю к y, и ранг y увеличиваю на единицу.
Что сделать?
Да.
Но тут проблема в том, что количество сыновей может быть большое.
Если, короче говоря, у вас у корня количество сыновей увеличивается, когда вы это дерево будете подвешивать к другому,
то, понятное дело, вам нужно будет пройтись еще, короче, снова по этим сыновьям, которых стало много,
что, соответственно, увеличится темп-тотику.
Мы, на самом деле, с этим поборемся, у нас получится хорошая темп-тотика, и без этого.
Пока глубина увеличивается, это норм.
То есть как бы это нормально.
Мы либо увеличиваем количество детей, что на самом деле тоже плохо, либо увеличиваем глубину.
И это не так страшно, как могло бы казаться.
Утверждение состоит в том, что, если вы используете ранговую эваристику,
то у вас размер дерева всегда больше равен, чем 2 в степени глубина этого самого дерева.
Давайте докажем. На самом деле утверждение довольно простое.
Доказывается по индукции.
Изначально
рамка x равен 0,
и, соответственно,
size of x равен 1.
Ну, соответственно, понятное дело, что 1 больше равен, чем 0.
Далее. Переход.
Пусть, соответственно, для деревьев
x вибрик
верно следующее.
Size of x
больше равен, чем 2 в степени
рамка x
и size of y больше равен, чем 2 в степени
рамка от y.
А что, когда мы объединяем два дерева, что у нас происходит?
Размер итогового дерева, давайте так напишем,
size от объединения tx и ty
точно совпадает с
size x плюс
size y.
Значит, по предположению, это все больше или равно, чем 2 в степени
давайте так напишу, r от x
плюс 2 в степени r от y.
А это, соответственно, больше или равно
давайте без ограничений общности
считать, что r от x
больше или равно, чем r от y.
Тогда что происходит?
Когда я меньше под дерево подвешиваю к большему под дерево,
у меня глубина не увеличивается.
А если у меня r от x равно r от y,
то у меня глубина может увеличиться на единицу.
Согласно, что вот тут я могу написать следующую вещь.
Я могу написать, что это больше или равно, чем 2 r от x
плюс 1.
На самом деле, я это могу написать просто так, давайте так напишем.
Да, спасибо.
2 r от y плюс 1.
Что еще раз?
Нет, r от x больше или равно, чем r от y.
Вот.
Вот-вот-вот.
Так, что мы хотели? Мы бы хотели доказать,
говоря, что это...
Так, если у нас r от x больше или равно, чем r от y,
то мы, соответственно, y подвешиваем к x.
Так, тогда размер...
Что?
Да-да-да, давайте так, давайте так поступим.
Давайте так поступим.
Так, значит, вот это верно.
Теперь давайте рассмотрим два случая.
Если у нас,
если у нас,
если у нас,
если у нас,
если у нас,
если у нас r от x
больше, чем r от y,
вот, то что у нас получается?
Мы тогда, соответственно, под дерево y
подвешиваем к x.
Вот.
И, соответственно, вот эта вещь тогда у нас априори
будет больше или равна, чем...
от степени r от tx объединенное.
Так, давайте так пушу.
Это больше или равно, чем 2r от x.
Вот, да, давайте так, давайте так сделаем.
Все, получили такое соотношение.
Значит, дальше давайте напишем так.
Первое, если r от x
больше, чем r от y,
то r от tx плюс
объединенность ty
объединенность ty
равно r от x, согласны?
Вот. Ну а, соответственно,
2r от x
плюс 2r от y
больше или равно, чем r от tx
объединенность ty
Вот. Это очевидно, да?
2 в степени, да, 2 в степени r от x.
Тут 2 в степени r и 2 в степени r от x.
Окей? То есть, неравенство выполнено.
То есть, я доказал, что размер объединения двух деревьев
больше или равно, чем 2 в степени rank этого дерева.
Ну а, соответственно, второй случай,
равен r от y. Ну, точнее, тут, понятное дело, есть симметричный случай,
когда r от y больше, чем r от x, но аналогично абсолютно.
А если ранги равны, то, соответственно,
что у меня получается? У меня получается, что 2r от x
плюс 2r от y
равно 2 в степени r от x плюс 1.
Но когда я объединяю
два дерева с одинаковым рангом, у меня ранг увеличивается на единицу.
То есть, r от x плюс 1 – это в точности есть ранг
объединенного дерева. То есть, равно 2 в степени r
от x объединенной с t y.
Ну да, собственно, рассмотрим два случая.
Если r от x больше, чем r от y, то, соответственно,
r от объединенного дерева – это есть r от x.
Но, соответственно, понятное дело, что по предположению индукции
два ранга 2 в степени r от x плюс 2 в степени r от y
больше равен, чем r от x.
А если ранги равны, то, соответственно, сумма рангов будет равна
2 в степени r от x плюс 1, а это в точности совпадает новому рангу.
Потому что, когда у меня ранги равны, у меня ранг
итоговый дерево увеличивается на единицу.
То есть, это доказали.
Ну и, собственно, следствие заключается в чем?
Следствие заключается в следующем, что
по глубина дерева,
точнее, глубина дерева у меня не больше, чем
ранг дерева.
То есть, у меня получается, что
время на выполнение
mindset у меня занимает
логарифмическое время от размера x.
Ну и, грубо говоря, если я просто
прологарифмируем обе части, получится, что
ранг не превосходит логарифма size.
Ну а, соответственно, ранг – это есть верхняя оценка
на время поиска mindset.
На глубину дерева. Все.
То есть, с помощью ранговой ивристики мы смогли
улучшить асимптотику с линейной в худшем случае
до алгоритмической в худшем случае, да, до алгоритмической,
от размера множества.
Ну и теперь, собственно, будет ивристика, которая
изменит вообще все.
Значит, смотрите, ивристика – жатия путей.
В чем стоит эта ивристика? Ну давайте
посмотрим и поймем, что мы можем сделать.
Ну вот представьте себе, что у меня
x находится где-то вот здесь, и, соответственно,
ну а это, ну не знаю, давайте назовем x' – это представитель x.
Когда я вызываю, то есть давайте посмотрим
на алгоритм предыдущий,
на алгоритм предыдущий кодер.
Вот как у нас работает
findSet. Вот здесь.
Значит, findSet устроен следующим образом.
Я нахожусь здесь, дальше, собственно, я рекурсивно
поднимаюсь, ну либо рекурсивно, либо итеративно поднимаюсь наверх,
соответственно, спрашиваю findSet вот этого элемента.
Дальше спрашиваю findSet от этого элемента, findSet от этого элемента,
и как только у меня findSet совпадает с самим элементом,
вот. Смотрите, в чем дело.
Смотрите, вот в процессе подъема
мы же на самом деле получается так, что мы узнаем
представителя, ну, самого главного представителя, не только для этого элемента,
но и вообще для всех сразу, согласны?
То есть, в принципе, что мне мешает сказать, что, ну, как минимум
сказать так, что вот я для x нашел представителя самого главного,
а давайте я сделаю так, вот когда мне в следующий раз попросят findSet от x,
я не хочу снова подниматься по этому пути, а давайте я просто
возьму вот эту связь, удалю, и x непосредственно привяжу
к самому главному представителю.
Логично? Ну, допустим, меня два раза подряд попросили findSet от x, findSet от y,
findSet от x, и снова findSet от x.
Смыслом мне два раза подниматься по одному и другое пути.
Я могу просто взять этот элемент и сразу же подсоединить его к орне.
Да.
Ну потому что
Ну как почему? Потому что вот представьте, у вас есть одно дерево,
у вас есть второе дерево,
за сколько времени вы будете подсоединять все элементы вот сюда.
А тут я предлагаю, как бы, ну вот мы же всё равно, смотрите, у нас
вот эта вот штука, подъём по этим или подъём
от кокового до элемента до корня,
у одного элемента до корня,
а с учетом этого мы должны перешепливать
от какого-то элемента до корня, занимает время h от x. То есть я все равно вот это время h от x потрачу.
Давайте я не буду тратить его пустую, а давайте я его грубо говоря сомартизирую.
Давайте я подсоединю x к корню, потом вот этот элемент подсоединю к корню, вот этот элемент к корню и вот этот элемент к корню.
То есть грубо говоря добавлю еще h от x времени, а симптомикой это не изменит.
Но зато это уменьшить время для будущих файнсетов, согласны?
Короче говоря, идея состоит в том, чтобы не только для того элемента, для которого мы нашли представителя,
присоединить его к корню, но и вообще для всех элементов, для которых мы определили представителя,
сразу же подсоединить их к корню.
Понятная идея. Ну и соответственно реализуется она тоже довольно просто.
Называется это все ивристикой жатия путей.
Ивристика жатия путей.
Давайте поступим следующим образом.
Как построить файнсет от x? Если я уже нахожусь в корне, то этот корень я возвращаю в качестве ответа.
Если я нахожусь не в корне, то давайте я напишу так. Я напишу parent от x равно файнсет от parent от x.
При условии, что присваивание у меня как c++ возвращает результат присваивания.
Когда я нахожусь не в корне, я говорю, что давайте я найду представителя своего родителя,
а потом сразу же присоединю себя к тому, что я нашел.
Процедура рекурсивная. Она по сути рекурсивна. Каждого родителя, каждого предка
подсоединит непосредственно к корню.
Понятно? По сути, я рекурсивно поднимаюсь и каждого подсоединяю к корне, вот как здесь.
То есть, вначале я вызвал файнсет от x, файнсет от x вызвал файнсет от y,
файнсет от y вызвал файнсет от z, вот файнсет от z вызвал файнсет от t.
Соответственно z в качестве представителя вернулся t, но z уже подсоединен к t.
Дальше y в качестве ответа вернулся t, я сразу же y подсоединил t.
Дальше x в качестве ответа вернулся t, и я сразу же присвоил сюда t.
Грубо говоря, можно считать, что это идея на такая амортизация.
То есть, если я для какого-то элемента уже посчитал его представителя, то в следующий раз
я представителя посчитаю за единицу.
И, соответственно, утверждение второе без доказательства заключается в следующем,
что если вы используете ранговую ивристику, ту, которую мы сейчас обсудили чуть-чуть ранее,
и используете одновременно с этим ивристику сжатия путей, то амортизационная сложность
операции файнсет есть O от αn, где α – это обратная функция кирмана.
Все понятно?
Поясню, что такое функция кирмана. Это очень замечательная обратная функция кирмана.
Это очень замечательная функция. Чем знаменитая функция кирмана?
Функция кирмана знаменита тем, что она очень быстро растет.
Растет очень-очень быстро.
Но, соответственно, про обратную функцию кирмана можно сказать следующее, что она, наоборот,
растет очень медленно. Ну, давайте посмотрим.
Например, альфа от единицы равно нулю, альфа от трех равно единице, альфа от семи равно двойке,
альфа от шестидесяти одному равно тройке. Ну, казалось бы, нормальный рост.
А вот четверке эта функция равна уже вот при таком значении.
Ну, такой рост, ну, понимаете, да?
Да, в общем, определение можете почитать в «Икипедии», там, в общем, да.
Определяется рекурсивно, все верно.
Вообще, на самом деле, скорее диагональная функция кирмана, ну ладно.
Функция кирмана на двух аргументах.
Ну, в общем, вы понимаете, да, к чему я клоню.
В общем, это, на самом деле, число, оно гораздо-гораздо больше, чем число атомов, видимо, части вселенной.
Поэтому, в общем, я гарантирую, что в наших контестах, вот, это число никогда не будет больше четверки.
Даже если я очень сильно хотел, я бы не смог сделать так, чтобы оно было больше четверки.
Поэтому, на практике, вообще говоря, на практике считается, что, ну, короче говоря,
люди считают, что это лодки единицы, просто-напросто.
Потому что у нас пока нет таких данных, чтобы, короче говоря, достичь роста этой функции.
Но формально, формально это растущая функция.
То есть, чем больше у вас размеров множества, тем дольше работает пайнсет в эмортизационном смысле.
Ну, на практике можно считать, что пайнсет работает эмортизационно за константное время.
Все ясно, да?
Но это верно. Опять же, повторюсь, давайте еще раз поговорим про утверждение.
То есть, какую структуру данных мы построили?
Мы построили структуру данных, которые организованы в виде леса, не пересекающихся множеств.
То есть, у нас каждое множество организовано в виде некоторого дерева.
Дерево деревья корневые.
Соответственно, мы их представляем в виде массива предков.
То есть, для каждого элемента мы храним ее непосредственного предка.
А дальше, соответственно, мы используем две эвристики.
Первая эвристика – это ранговая эвристика.
То есть, мы подвешиваем маленькое дерево к большому дереву, а не наоборот.
Вот этот первый момент.
А второй момент заключается в том, что мы используем эвристику жатия пусей.
То есть, если мы для каких-то элементов...
То есть, когда в процессе пайнсет мы находим представителя для каждого элемента,
мы его сразу же подвешиваем непосредственно к его корню.
Да, ну и тут еще нужно сказать следующую вещь.
Вот как раз таки про ранги.
То есть, мы говорили, что ранг от X...
Ранг от X – это...
глубина дерева...
глубина дерева X.
Значит, смотрите, когда мы делаем эвристику жатия пусей,
мы вообще говоря ранги не обновляем.
И это может показаться странным.
Да?
Ну, смотрите, ну вот у меня, допустим, было какое-то вот такое вот дело.
Так что получилось так, что у меня дерево было слишком глубоким.
Какая-то такая история.
После того, как я сделал пайнсет от X,
после того, как я сделал пайнсет,
я все вот эти элементы подсоединил к корню дерева.
Естественно, у этого дерева, ну и плюс у всех вот этих вот деревьев,
глубина уменьшилась.
Глубина не увеличилась.
Но, тем не менее, утверждается, что ранг менять...
что изменять ранг, соответственно, обновлять ранг,
высчитывать новую глубину и так далее не нужно.
В общем, достаточно пользоваться старым рангом,
и тогда просто ранг меняется не на глубину дерева,
а на верхнюю оценку.
Оценка...
глубины дерева.
Вот. Окей?
То есть теперь в ранге хранится у меня не истинная глубина дерева,
а всего лишь оценка сверху.
То есть, какой максимальной глубины это дерево может быть?
Но теоретически, ну как?
И практически оно будет меньше,
то есть у вас постоянно дерево сжимается.
Окей?
Вот.
Есть ли вопрос с такой стукверданах?
Окей, тогда давайте вернемся графом.
И поговорим про минимально острые деревья.
Значит, задача формулируется
следующим образом.
Данный ориентированный граф...
А, да, давайте сделаем небольшой анонс.
После перерыва получается.
Вот.
Перерыв.
Время вышло.
Про что будет,
собственно,
следующая завершающая часть
нашего курса по алгоритму,
которая посвящена графу.
Вот мы до этого рассматривали графы,
и при этом интересовались только,
скажем, исключительно
структурой графа.
Какие у него компоненты связанности,
компоненты сильной связанности,
какие соединены ли вершины,
не соединены ли вершины,
как можно топологически ассортировать графы и так далее.
Без привязки какой-то полезной информации,
которую граф может хранить.
Скажем, у нас интересовали
так называемые ввешенные графы.
На ребрах, на самом деле,
может быть написана какая-то информация,
о которой мы будем в дальнейшем говорить.
Сколько единиц чего-либо
может протечь по этому ребру,
либо по весу ребра.
Насколько это ребро важнее, чем второе ребро и так далее.
Насколько дороже там проходить по этому ребру,
чем по второму.
Будем переходить к таким алгоритмам.
Первым алгоритмом из них будет
алгоритм построения минимального
основного дерева.
В чем заключается задача?
Нам данен некоторый неориентированный граф,
и при этом дополнительно
еще на ребрах задана некоторая весовая пункция.
Просто некоторое отображение из множества
ребер во множество, скажем,
деспительных чисел.
Соответственно, что такое останный подграф?
Первое определение.
Подграф графа g' называется
останым, если он содержит все
исходные вершины графа g.
То есть мы взяли исходный граф,
выделили из него вершины и, возможно,
оставили еще какие-то ребра.
Такой граф называется останым, который сохраняет все
прежние вершины исходного графа.
Что такое минимально останое дерево?
Это останный подграф,
который, во-первых, является деревом,
а в треке который имеет наименьший
вес среди все возможных останых деревьев.
Мы скажем,
вот у нас есть граф,
из него можно каким-то образом выделить подграф,
который будет являться деревом.
Среди всех таких деревьев мы выделяем
именно такой подграф дерева,
который обладает наименьшим весом,
у которого сумма весов ребер минимальна.
На данном примере
вот такой подграф, который обозначен зеленым цветом.
А нет, наоборот, он является острым деревом, но при этом он не является минимальным.
Почему он не является минимальным?
Как из него можно сделать еще более минимальное острое дерево меньшего веса?
Да, можно убрать DAC и поменять на DA, а еще?
Да, убрать вот это ребро и добавить вот это ребро.
Вот этот граф будет действительно являться минимальным острым деревом.
Теперь мы потихоньку переходим к алгоритму.
Всем понятно, что такое минимальное острое дерево?
В принципе, как обычно, задача довольно понятна, непонятно, как ее решать.
Давайте введем несколько определений и утверждений, которые нам помогут это сделать.
Пусть у нас есть подграф некоторого минимального острого дерева.
Минимально острого дерева еще называют MST.
Соответственно, пусть у нас есть некоторое минимально острое дерево.
HH3 – это подграф этого минимального острого дерева.
Это именно подграф неисходного.
Во-первых, он является подграфом исходного графа,
во-вторых, он является подграфом некоторого оптимального острого дерева.
Значит, реброба U называется безопасным,
если при его добавлении в граф HH3 этот граф останется подграфом
некоторого минимально острого дерева.
Грубо говоря, история такая.
Давайте, как это все применяется к алгоритму, который мы будем строить.
Минимально острого дерева мы будем строить икаративно,
постепенно добавляя все более и более новые ребра.
Понятное дело, что мы добавили какие-то ребра,
у нас появился подграф, который еще не является деревом, но к нему стремится.
Что такое минимальное ребро?
Минимальное ребро – это такое, которое я могу добавить в этот строящийся граф,
так что у меня этот граф по-прежнему будет стремиться к некоторому минимальному острому дереву.
Понятно?
И уже этот граф, как ни крути, не станет минимально острым деревом,
соответственно, это ребро безопасно не является.
И, соответственно, если мы рассмотрим такой подграф,
то для него безопасными являются ребра AD и CE, как мы сказали.
Если мы в этот подграф зеленый добавим ребро BE,
то полученный граф уже никак не будет подграфом минимально острого дерева.
Потому что минимально острого дерева этого ребра вообще, говоря, нет.
Поэтому вот это ребро не является безопасным, вот это ребро не является безопасным,
то есть единственные безопасными ребрами, здесь вот это и вот это.
Ну и, соответственно, план на самом деле очень простой.
У нас изначально есть просто вершина.
Возьмём эти самые вершины и выберём какое-нибудь безопасное ребро.
Добавим безопасное ребро в наш граф.
Возьмём второе безопасное ребро, добавим наш граф.
И так далее, будем давать безопасные ребра до тех пор, пока мы не построим минимально остальное дерево.
Круто?
План очень простой. Остается неясным единственный вопрос, а как найти безопасное ребро?
Это хорошая идея, но не все дешевые ребра на самом деле полезны.
Вот, это уже близко к правде. То есть действительно на самом деле можно считать, что
в случае построения минимального остого дерева подходит такой, можно сказать, почти жадный алгоритм.
То есть мы действительно будем на каждой итерации, то есть на каждом этапе, выбирать
минимальное по весу ребро. Но не просто минимальное по весу ребро, а который будет творять определенным критериям.
Критериям он такой.
Лемма о безопасном ребре.
Для начала давайте определимся с еще несколькими понятиями. Во-первых, разрез графа.
Расрез графа – это просто разбиение
вершин
на два не пересекающих множества.
Множество С и множество В без С. Вот это разбиение графа.
То есть мы взяли вершины графа, разбили на два множства. Это называется разбиение. Вот вот. КПар множества.
Ну, соответственно, будем говорить, что ребро в У пересекает разрез, если один конец ребра лежит в одном множестве разреза, а второй конец ребра лежит в втором множестве.
То есть, грубо говоря, есть у вас вот такая вот картина.
Лемма о безопасном ребре дает нам необходимые и достаточные условия для того, чтобы мы могли находить безопасные ребра.
Пусть же штрих – это подграф некоторого минимального основного поддерева графа G.
То есть, опять же, история такая же, как я сказал.
У нас есть какой-то подграф, и нам известно, что его можно достроить до минимального основного дерева.
Возникает вопрос, какое ребро можно у него добавить, чтобы он по-прежнему оставался способным быть достроенным до минимального основного дерева.
Есть такой ж-штрих подграф, и также есть некоторый разрез.
Причём этот разрез устроен так, что никакое ребро из ж-штрих не пересекает этот разрез.
То есть, грубо говоря, у меня есть разрез какой-то, и все ребра из ж-штрих лежат строго вот в одной компоненте разреза.
Ну или вот только здесь.
Вот таких вот ребер у меня не существует.
У меня есть граф ж-штрих, я каким-то образом разбил множество вершин на два множества так, что ни одно ребро из ж-штрих не пересекает эти два множества.
Если я среди всех таких ребер, которые пересекают этот разрез, выберу минимальное по весу, то вот такое ребро будет безопасным.
То есть такое ребро я могу спокойно добавить в мой граф ж-штрих. Понятно?
Смотрите, есть граф ж-штрих.
Давайте так.
Зелёным цветом.
Есть граф ж-штрих.
У него есть какие-то ребра.
При этом все ребра лежат либо внутри вот этой компоненты, либо внутри вот этой компоненты.
То есть не существует ребра, которая бы проходила отсюда-сюда.
Вот в этом графе.
Тогда я рассмотрю все ребра, которые на самом деле этот разрез пересекают в исходном графе g.
У меня есть граф g.
Ж-штрих – это под множество t, которое является под множеством графа g.
Вот g – это мой граф. Это тот граф, который нам дали.
А ж-штрих – это то, что я хочу построить, достроить до t.
Соответственно, тут есть какие-то ребра черные, но при этом они не лежат ж-штрих.
Вот если я среди всех таких ребер выберу минимальное, то я могу спокойно его взять и добавить ж-штрих.
И при этом ничего не испортить.
Давайте докажем, почему это так.
Давайте рассмотрим тот на разрез.
Множество s и множество u равное v без s.
Ну и пусть e – это минимальное ребро, пересекающее разрез v-u.
Нет, почему-то давайте s.
Пересекающий разрез s-u.
Вот. Пусть e не попало в минимальное основное дерево.
Допустим, что e – это минимальное ребро, и вот так получилось, что e не принадлежит минимальному основному дереву у моего графа.
Вот так получилось.
А вот тогда что я могу сказать? У меня обязательно существует ребро e-штрих,
который ведет из компонента s компонента u. Почему это так?
Что? Да, потому что не то, что граф g связан, а потому что у меня дерево должно быть связано.
Вот.
Соответственно, тогда найдется e-штрих такое, что...
Давайте так напишем. e-штрих равное v-u такое, что v принадлежит s, а u принадлежит u.
И при этом e-штрих не равно e.
Вот.
Так напишем e-штрих, принадлежащее минимально основному дереву.
Вот. Что можно сказать тогда?
Ну, смотрите.
Что можно сказать тогда?
Давайте добавим...
Добавим e в полученный mst.
Вот. То есть мы предположили, что g в нашем минимальном основном дереве не лежит.
Соответственно, без e получилось вроде как нормальное минимально основное дерево.
А давайте мы этот e добавим в наш минимально основное дерево.
Что мы тогда получим?
Ну, мы вообще получим не дерево тогда. У нас появится в любом случае цикл.
Согласны?
Ну, то есть вот у меня тут...
У меня тут был какой-то путь, и тут был какой-то путь.
Соответственно, из этого следует...
Получили...
Получили цикл.
Получили цикл.
То есть получили какую-то вот такую вот...
Получили какую-то вот такую вот ситуацию.
Да?
А теперь смотрите.
Что у меня получается?
Вес ребра e-штрих больше и бравее, чем вес ребра e.
Что произойдет, если я уберу ребро e-штрих?
Ну, у меня граф останется связанным. Согласны?
Все. То есть если уберем e-штрих, то граф...
Ну, точнее, ну да, граф останется связанным.
Что станет с его весом?
Не увеличится, скорее.
А вес не увеличится.
А вес...
...Не увеличится.
То есть что получили?
Если вес не изменится, то это на самом деле означает, что e-штрих спокойно можно было заменить на e.
Кстати, если вы посмотрите на bangs
А вот они эти provided😅
А если вес не изменится, то это на самом деле означает, что е штрих
спокойно можно было заменить на е. То есть на самом деле е тоже является
безопасным ревром. То есть е можно было спокойно добавить в наш граф,
и тогда бы ничего не изменилось. Мы по-прежнему могли бы смогли его достроить до минимального основного дерева.
Вот я его предъявил. То есть удалили е штрих, добавили е. Все нормально, согласны?
А если тут стоял наоборот знак больше,
тогда бы мы пришли к противоречию. На самом деле мы предположили, что без е
получается нормальное минимальное основное дерево, но оказывается, что нет.
С помощью е можно было построить еще меньшее минимальное основное дерево,
что является противоречием. То есть как ни крути, получается такая ситуация, что е
в любом случае можно было спокойно добавить в наш граф и спокойно
достроить его до минимального основного дерева. Из этого следует,
что е было безопасно.
Ну вот.
Мы получили способ получения безопасных ревер,
но одновременно с этим мы получили способ, на самом деле целую кучу способов
построения минимального основного дерева. В чем он заключается? Он заключается в том,
чтобы построить хороший разрез, то есть разбить вершины графа так, чтобы в текущем
построенном под графе у нас не было ревер из одной компоненты в другой,
и устрелить всех этих ревер, найти минимальное. Потом снова построить каким-то образом разрез,
в этом разрезе найти минимальное ребро и добавить его в наш граф.
Ну и так далее и я. Но вопрос, как строить разрезы? Краски отдается на откуп
конкретным алгоритмам. Давайте на них посмотрим. Всего на ваш суд я
предложу три алгоритма. Первый с них это алгоритм Прима.
Алгоритм Прима работает следующим образом. Давайте наш разрез инициализируем
следующим образом. Пусть, давайте тут нарисую.
Пусть во множестве s лежит одна вершина 0, а во множестве v без s лежат все остальные вершины.
Изначально так. Согласны ли вы, что выполняются все требования для лемы
о безопасном ребре? То есть у нас ни одно ребро вот этого под графа пустого
изначально не пересекает разрез. Ну и что мы делаем? Рассматриваем все
ребра, которые торчат из вершины 0. И среди них выбираем минимальное.
Изначально у нас была одна вершина, так как изначально у нас граф пустой,
то можно просто взять минимальное среди всех ребр, которые торчат из конкретной вершины 0.
Давайте добавим это ребро. Допустим, минимальное ребро это вот это ребро.
Добавим его в наш граф и, соответственно, перенесем эту вершину в левую часть разреза.
Ребро оказалось здесь. Как у нас изменилось множество ребр, которые пересекают разрез?
У нас появились ребра, которые торчат из вершины 0, согласны? Давайте просто
просто возьмем и все их добавим вот так. И теперь уже найдем минимальное среди всех ребр,
которые ведут из вершин 0 и из вершин 1. Снова, допустим, это какое-то вот такое ребро.
Все, соответственно, вот это ребро добавляем в наш граф же штрих и, соответственно,
перенесем эту вершину в множество s. Ну и, соответственно, добавим ребра, которые ведут из этой вершины
во все остальные вершины. Ну и снова продолжим алгоритм. Снова найдем среди вот этих всех ребр
минимальное, добавим, ну и так далее, пока не получим минимально остальное дело.
Разрез устроен очень просто. Мы просто-напросто берем и по одному добавляем вершину в левую часть разреза.
То есть вначале там находится только одна вершина 0. Дальше по какому-то ребру нашли новую вершину,
перенесли эту вершину в множество s. Дальше, соответственно, снова у нас есть торчащие ребра
вот в эту компоненту. Нашли какое-то новое ребро. То есть понятное дело, что ребер вот тут внутри
уже новых появиться не может. Потому что иначе возникнет цикл, согласны?
Поэтому среди этих ребер выбираем новое, новое ребро. Минимальное соответственно переносим вершину сюда.
Ну и так далее, пока все вершины не перейдут отсюда вот сюда. Нормально?
Ищем минимальное ребро среди всех, которые перестекают разрез. Добавляем это ребро в минимально остальное дерево,
а конец ребра переносим из вот этого конца, вот сюда. Ну и повторяем до тех пор, пока вот в этой части разреза
не окажется все наше множество вершин. План примерно понятен?
Давайте посмотрим, как это выглядит на практике. На практике алгоритм работает...
Ну давайте, не знаю, может быть приведем пример.
Ладно, давайте сначала рассмотрим середокод, а потом на примере разберем, как он работает.
Алгоритм довольно простой. Давайте просто навестом заведем массивдист.
В массивдист будем для каждой вершины хранить минимальный вес ребра, который в нее ведет.
Для каждой вершины будем хранить вес минимального ребра, который в нее ведет.
Ну вот здесь вот.
Вот для каждой вершины отсюда мы знаем
бес минимального ребра, который в нее ведет.
Да, вот из s вот сюда.
Скажем, вот у меня есть какая-то вершина, в нее
ведет там три ребра. Не знаю, три, пять, один.
Соответственно, в 10 от v будем хранить значение 1.
Дальше, преф. В преф мы будем хранить
начало соответствующего ребра.
Скажем, вот для вершины v мы знаем, что в нее ведет
минимальное ребро размера 1.
И для нее мы знаем ее соответствующее начало.
Это вершина u.
То есть для каждой вершины мы знаем, во-первых,
вес минимального ребра, который в нее ведет,
а во-вторых, начало этого самого минимального ребра.
Конечно, такой дистый преф.
Ну а теперь, собственно, главный вопрос.
А каким образом мы будем искать минимум?
Вот какие у нас есть варианты?
Какая структура данных позволяет нам эффективно искать минимум?
Ну, пирамида, да, условно.
Вот, познакомьтесь, вот, hip.
То есть все вот эти вот ребра, все вот эти ребра мы будем хранить в hip'е.
То есть hip будет упорядочен у нас по дисту.
Ну и соответственно, в качестве второго элемента пара мы будем хранить
соответствующую вершину, в которую ведет данное ребро.
Вот.
Окей?
Нормально?
Ну вот.
Ну и что мы делаем в цикле?
Пока у нас очередь, пока у нас приоритетная очередь,
или пока у нас пирамида не опустела,
мы достаем оттуда минимальное,
мы достаем оттуда минимальное, минимальное ребро.
Вот, из этого множества ребер.
Достаем минимальное ребро.
Вот.
Ну и соответственно, если у этого ребра есть какой-то начальт,
мы добавляем его в минимально, в минимально ост실ное дерево.
Ну что значит, у ребра есть начальт, но это значит, что мы достали не нулевую вершину.
Да?
То есть изначально мы просто достаём нулевую вершину и нулевую вершину кладём ну
ну ну нуjuno tanta нав spur на нуλевую вершину,
не имея смысла добавлять приоритетную очередь.
Поэтому просто, ну как бы не знаю какой кастырь.
Окей?
Ну потому что изначально мы знаем только расстояние до нулевой вершины.
Ну а дальше поступаем следующим образом. Вот мы добавили во множество s, то есть вот мы вытащили вершину v
И что нужно сделать? Нам нужно обновить множество ребер, которые ведут из этой компоненты вот сюда
Вот мы взяли вершину отсюда, перенесли вот сюда, и следственно у нас появились новые ребра, которые пересекают разрез
Нужно их все добавить, согласны? Вот соответственно в этом цикле я добавляю все эти ребра
То есть просто прохожусь по всем соседям вершины v
Если вершина u лежит в приоритетной очереди, и с помощью вот этого ребра я смог обновить минимальное расстояние, то я его обновляю
Окей?
То история такая, вот я достал вершину v, точнее не то что я достал, я добавил очередное ребро в минимально остальное дерево
И перенес вершину v отсюда вот сюда
Теперь мне нужно что сделать? Мне нужно просмотреть все ребра, которые торчат из вершины v, и обновить минимальное расстояние до вот этих вот вершин
Вот раньше до этой вершины минимальное расстояние было 3, до этой 5, до этой 7
Вот тут ребра имеют размер 5, 2, 8
Вот это ребро оно не обновляет расстояние до вот этой вершины, потому что до этой вершины ведет какое-то более короткое ребро размера 3, согласны?
Поэтому вот это ребро оно никогда в принципе не будет безопасным, поэтому я его игнорирую
Вот раньше до этой вершины было какое-то ребро длины 5, а из вершины v в него торчит ребро размера 2
Поэтому между вот этим ребром и вот этим ребром, естественно, я буду выбирать ребро 2
Поэтому, соответственно, я обновляю дист до этой вершины и обновляю ее преф
Теперь я говорю, что до этой вершины теперь у меня расстояние не 5, а 2, и в нее ведет ребро из вершины v
Понятная история? Ну вот
Ну и в кипе я делаю decrease k
Нормально?
Сдайте вопросы, все ли понятно
То есть я просто-напросто по одному достаю вершины из приоритетной очереди, дальше прокажу все к ее соседе и обновляю расстояние до всех остальных вершин
Ну и на самом деле вопрос заключается в следующем
Сколько это все работает?
Если мы работаем с обычной, вот, важный момент, внимание
Для чего нам нужна была фибоначчика пирамида? Вот здесь
Это первый и единственный момент, когда нам пригодится фибоначчика пирамида чисто для того, чтобы теоретически посмотреть, что у нас получается
Если мы используем обычную бинарную пирамиду, то выходит следующее
Сколько раз всего выполняется этот цикл?
Этот цикл выполняется всего не более в раз
Согласны, да?
Да, не более в раз, потому что мы...
Каждое ребро, потому что у нас в дереве сколько ребр?
В-1, да, поэтому, соответственно, мы минимально у нас на дереве добавляем всего в-1 ребро
Ну а так на каждую итерацию мы добавляем одно ребро
У нас всего будет в-1 итерации, ну на самом деле в итерации
И с того, что мы еще на левую июшу добавляем, ну ладно
А вот, всего, соответственно, в итерации
В итерации
Дальше, за сколько у нас выполняется экстракт мин в бинарной пирамиде?
Низ как звездит
Мы удаляем, еще нам нужно просеять кто-то вверх
Ой, наоборот, низ
Да, то есть все это работает за логарифм от чего?
За логарифм от размера пирамиды
Ну размер пирамиды в худшем случае у нас E, согласны?
Ну в худшем случае у нас в пирамиде лежат, ну не, на самом деле лог В
Да, все нормально, лог Е
Потому что в худшем случае мы в пирамиду сложили все ребра
Вот
Ну ладно, пусть так будет
Лог Е, лог В, на самом деле одно и то же
Окей, что дальше?
Дальше мы, собственно, в цикле проходимся по всем вершинам
То есть в лог Е это суммарное время экстракт мин
Дальше
Теперь давайте посмотрим суммарное время работы вот этого цикла
Сколько всего итерации сделает этот цикл?
Вообще всего-всего, за все время работает алгоритм
У нас уже встречалась такая штука
Сколько?
Ну E или 2E, почему?
Потому что мы берем вершину и проходим по всем ее соседям
То есть по сути мы суммируем количество степеней для каждой вершины
Ну а сумма всех степеней равна 2E
То есть суммарно этот цикл выполнит E итерации
Понятно почему, да? Опять же
Всего E итерации
А на каждой итерации какое количество работы мы совершаем?
Вот так работает decrease k в бинарной пирамиде
Ну тоже за алгоритм, да?
Поэтому у нас получается E умноженное на лог Е
Ну или лог В, в общем, как угодно
Давайте напишу лог В
Ну скобка, давайте укажем, что лог Е совпадает по порядку с лог В
Почему? Потому что E это порядка либо В, либо В квадрат
Алгоритм от В и от В квадрат
Понятно, да? Отличается с константу раз всего
Это что? Это суммарное время decrease k
Ну соответственно, В умножено на лог В плюс E умножено на лог В получается E лог В
Потому что количество ребер у нас заведомо больше, чем число вершин
Согласны?
Поэтому в случае бинарной пирамиды время работы E лог В
Нормально?
Теперь фибоначевая пирамида, внимание
Давайте теперь представим себе, что вместо бинарной пирамиды мы используем фибоначевую пирамиду
Что можно сказать про время работы экстракт-мин?
За сколько работает экстракт-мин?
Нет, не угадали
Да, экстракт-мин – это единственная операция, которая работает за алгоритмом в амортизированном смысле
Поэтому это суммарное время работы экстракт-мин в любом случае
А за сколько работает дикрискей?
А вот дикрискей для фибоначевой пирамиды работает как раз за единицу
Поэтому тут логарифм уходит
Для фибоначевой пирамиды
Поэтому для фибоначевой пирамиды получается совсем дотика E плюс В лог В
То в логарифм раз лучше, чем…
Если у вас E больше, чем В, то в логарифм раз лучше, чем просто бинарная пирамида
Но с вами говорили, что на практике фибоначевая пирамида обладает большой констант
И поэтому на практике бинарной пирамиды работает гораздо лучше
Ну а симпатически фибоначевая пирамида круче
Ну ладно, другие алгоритмы мы не успеем, значит, на семинарах разберете
Но давайте пока с примой разберемся
Нет, все алгоритмы на самом деле они очень похожи по сути
Смотрите, такая история
А как вам такой план?
Давайте я просто забью на бинарную пирамиду
Ну из-за чего нам нужна была бинарная пирамида?
Для того чтобы эффективно искать минимум
Ну а насколько сильно станет хуже, если я от бинарной пирамиды избавлюсь?
Как вы думаете?
Ну давайте я избавлюсь от бинарной пирамиды, на что это повлияет?
Ну бинарная пирамида мне нужна в двух местах, вот здесь и вот здесь, согласны?
Давайте я избавлюсь от бинарной пирамиды и буду просто-напросто искать минимум в тупую
То есть вот у меня есть массив dist, массив дистанции
Давайте я минимум буду искать в ней в тупую, то есть просто буду линейным образом проходиться по ней и искать там минимум
За сколько будет работать extract min тогда?
За линию, окей
Давайте отдельно напишем
То есть всего итерации у нас v, и за линию работает extract min
То есть v умножить на v, то есть v квадрат, это время
extract min
для массива
Окей, ну вроде как хуже, но v квадрат не очень приятно
Ну ладно, давайте рассуждать дальше
А decrease k, за сколько работает в массиве?
Вот у меня есть конкретная ячейка, я хочу в ней уменьшить значение, за сколько это работает для массива?
За единицу, смотрите, для пирамиды это работает долго, ну то есть для бинарной пирамиды, за алгорифом
Ну потому что мне нужно изменить уменьшить значение ключа и просеять вверх
А в массиве ничего делать не надо, то есть я просто ввижу ячейку, уменьшил в ней значение и все
Соответственно decrease k теперь работает за единицу
То есть получается e умножить на 1, это время decrease k
То есть суммарно получается e плюс v квадрат
Согласны?
То есть в случае пирамиды у нас было e log v, а теперь получилось e плюс v квадрат
Вот реализация с массивом
То есть теперь я тут, грубо говоря, экстракт-мин заменил просто на arg-мин
Ну а decrease k заменил просто на изменение в массиве Дист
E плюс v квадрат то же самое, что v квадрат
Ну можно и так сказать
Короче говоря, мой вопрос вот в чем
Есть реализация на массиве?
Есть реализация на пирамиде?
Кто победит?
Вот, смотрите, то есть мы получаем следующую историю
На самом деле не так, что пирамида эффективна
То есть вроде как кажется, что действительно пирамида это такая структура данных, которая по сути служит для того, чтобы эффективно искать минимум
Но смотрите, все становится не так, как это значит, когда мы говорим про разные типографы
Смотрите, есть у меня граф разреженный
То есть есть у меня E, порядка V
То что тут получается?
Тут получается b квадрат, а тут получается v лог w
П tonnes b явно быстрее, чем v квадрат
Но если у меня граф плотный
То есть есть у меня количество ропINAUDIBLE порядка v квадрат
То что получается?
Тут v квадрат плюс v квадрат все равно v квадрат
А тут v квадрат log v
в квадрат log v, то есть в log v раз больше. То есть мы получаем ситуацию, при которой в зависимости от
типа графа нам вы не используете либо одну структуру данных, либо вторую структуру данных.
Соответственно, если у меня граф разреженный, я использую бинарную пирамиду, то соответственно у меня время работы в log v
для пирамиды в log v, для массива в квадрат. Если я использую плотный граф, то бинарная пирамида работает за в квадрат log v
и массив за v квадрат. То есть мы видим, что для разреженного графа лучше всего использовать бинарную пирамиду,
для плотного графа лучше всего использовать массив. Тут может показаться, что фибоначевая пирамида
вроде как и в том и в другом случае дает оптимальную асимптотику, но на практике нет.
Ну а асимптотика, конечно, та же, но работает значительно дольше. Вывод понятий.
Массив с поддержкой минимума. Ну пирамида это и по сути массив с поддержкой минимума, нет?
Вот. Ну значит, есть еще пара алгоритмов, ну вот их вы разберете на семинарах.
Эти алгоритмы значительно проще. Давайте коротко пробежимся.
На чем стоит алгоритм Краскала? А алгоритм Краскала просто стоит в следующем. Давайте обсудим алгоритм Краскала,
потом пойдем на 5 минут. Хочется дойти до того момента, когда он все-таки пригодится системе не пересекающих нор,
с которым мы зачем-то обсуждали. Алгоритм Краскала очень простой, очень простой.
Возьмем ребра, список ребр и отсортировываем их по весу, sd sort, сортировка ребр по весу.
А дальше просто в тупую будем идти по этому сортированному списку и добавлять, соответственно,
добавлять ребро, если оно не будет давать нам цикл.
Ну вот, просто нам дам список ребр.
E1, E2, E3, E4, E5 и так далее.
Вот, добавили ребро E1, потом добавили ребро E2, потом добавили ребро E3.
И вот у нас появилось ребро E4,
который образует цикл. Вот если ребро E4 образует цикл,
то я его просто скипаю, перехожу к следующему. Ну и так далее, пока у меня не получится дерево.
Вопрос, как мне проверить, будет ли ребро давать цикл или нет?
В каком случае ребро мне будет давать цикл?
Вот, когда у меня эта вершина и эта вершина находятся в одной компоненте связности.
Если у меня ребро соединяет две вершины из одной компоненты связности,
то соответственно у меня получается цикл, поэтому это ребро я должен пропустить.
А если ребро соединяет две вершины из разных компонент связности,
то это нормальное ребро. Ну и главный вопрос, как проверить,
лежат ли две вершины в одной компоненте связности или нет?
С помощью системы непересекающих ножей.
Вот алгоритм красного.
Сортируем ребра, создаем системы непересекающих множеств.
Создаем одноэлементные множества.
И дальше просто в цикле проходим по сортированным ребрам.
Если вершина В и вершина У, которые являются концами этого ребра,
лежат в разных компонентах, то объединяем эти две компоненты
и добавляем данное ребро в минимально основное дерево.
Ну и так далее.
А вот простой алгоритм. Соответственно, алгоритм работает за Е лог Е, ну или за Е лог В.
Просто чисто за счет сортировки. Все остальное работает за линейное время.
Окей?
Все, ну а другой алгоритм уже на семинара.
Спасибо.
Спасибо.
