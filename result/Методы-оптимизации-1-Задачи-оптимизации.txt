я вас тоже от себя поздравлю с началом семестра вот третьего года обучения вы на половине пути
вот ну и дай бог вам все это успешно закончить так я представлюсь соответственно зовут без
носиков Александр Николаевич и соответственно в этом семестре мы будем встречаться с вами в
этой аудитории вот ну те кто доживет там до конца или до середины на курсе по методам оптимизации
на курсе по методам оптимизации у кого-то уже были семинары у кого-то не было пока семинаров но
в общем-то это неважно хочу в любом случае представить нашу команду тут немного про меня
я соответственно недавно защитил кандидатскую на фистехе занимаюсь активно наукой вокруг методов
оптимизации сейчас уже написал более 10 статей на всякие там а со звездой конференции и ко один
журналы это самый так скажем высокий уровень среди научного сообщества где-то на стыке
оптимизации и машинного обучения всего где-то более 30 статей соответственно работаю здесь
заведующим лабораторией мф и яндекс еще соответственно работаю в инополисе скалтехи в
ше и пи и что там еще а еще вот соответственно арабский университет который искусственного
интеллекта их шейха вот сайт почта телеграмм можно писать спрашивать как у меня дела
рассказывать как у вас дела вот что еще чей верно самое интересное что в первую очередь
вам хочется узнать это выставление балла выставление оценки вот здесь соответственно
обозначены все виды активности которые
что случилось здесь соответственно обозначены виды активности которые могут принести вам
некоторые баллы в итоговую оценку соответственно первый вид активности это соответственно тесты
на семинарах каждый семинар кроме 1 вас будет начинаться с некоторые 10 минутки по теме
лекций и по теме семинара то есть предыдущего семинара и предыдущей лекции вот соответственно
три балла вот говорит соответственно домашнее задания домашние задания будут выдаваться на
две недели по теме двух лекций и по теме двух семинаров дедлайны жесткие вот соответственно
Тоже три балла. Фидбокс, я думаю, по ним будет довольно полный, потому что ребята-
ассистенты будут сидеть проверять и, соответственно, выдавать вам не просто
оценки, а какие-то еще и комментарии к тому, что вы там натворить успели.
Также контрольная работа в середине семестра на лекции по темам,
соответственно, которые мы прошли до этой контрольной работы. И на лекциях, и на
семинарах. Колоквиум, что-то типа зачета экзамена в формате билетов,
все как на устном экзамене в конце семестра. Либо на последние недели, либо на
зачетные недели на ваш выбор. Разделим вас просто. Каждая семинария свою группу
разделит. И получится так. Ну и последний вид активности это разбор статьи.
Можно попросить статью на разбор про какие-то современные темы оптимизации.
И, соответственно, тоже получить за это баллы. Тут более подробно. Первое
важное уточнение, что если вы хотите получить оценку удовлетворительно, то
либо за колоквиум, либо за контрольную работу нужно набрать больше, либо равно
одного балла. Вот. Мы должны удостовериться, что вы хотя бы где-то
приходили в сознание. Вот. Они просто там списали домашние задания или что-то
там сделали. Вот. Если хочется получить оценку хорошо, либо отлично и по
контрольной, по колоквиум, нужно получить оценку выше единицы. Вот. Из трех. Ну то есть
какой-то базовый уровень показать. Ну а дальше уже все как набирается. Небольшие
комментарии. Как вы понимаете, ни один из видов активности не является 100
процентов обязательным. Вот. Можно, например, что-то пропустить и все равно получить
оценку удовлетворительно. Тесты мы проводим в начале семинаров. Вот.
ДЗ и, соответственно, обновления конспектов будут происходить на выходных.
Как раз четверг у нас большая часть семинаров плюс лекция. Вот. И что мы сейчас
еще, соответственно, будем делать? Ну посмотрим ваш фидбэк пятницу, что-то
обсудим и, соответственно, будем делать новые выкаты выходные. Вот. При
подозрении на списывание обнуляются все ДЗ, в том числе тех, кто дал списать.
Контрольная работа в середине семестра по материалам восьми лекций и восьми
семинаров. Колоквиум, как я сказал, по билетам, проводит его ваш семинарист и
приглашает кого-то еще в помощь, например, лектора или других семинаристов. Вот.
Соответственно, не ходите на семинары, приходите на колоквиум, семинарист
удивляется, а кто вы такой? Вот. Соответственно, наверное, стоит туда все же
иногда заглядывать. Вот. Ну и про разбор статей, соответственно, до 31 числа их
можно попросить на разбор до 31 октября. Вот. Ну и как происходит, соответственно,
зачет этого всего безобразия? Вы разбираете статью, разбираете доказательства,
воспроизводите эксперименты, которые там сделаны, и потом выступаете перед
одногруппниками и выступаете на нашем семинаре. Вот. Рассказываете, что же в
этой статье там такого интересного происходит. Так. Вопросы? Пожелания,
жалобы по этой части? У вас будет эта презентация? Возможно, даже у всех она
будет. Так. Еще? Ну супер. Значит, всем все понятно, и мы можем переходить к уже
более интересным вещам. Вот. Каким-то сутьевым вещам. Так. Окей. Давайте-ка чуть-чуть
расшатаемся. Куар-коды вы просканировали, но давайте вы мне что-нибудь и какие-нибудь
вопросы еще поотвечаете. Вот. Встречали ли вы когда-то задачи оптимизации уже в
своей жизни и где?
Где? В анализ данных. А что вы там делали? Так. Здорово. Где еще? Все только в
машинном обучении встречали? Нет, и этого в принципе достаточно. Вот. Потому что
машина обучения сейчас становится все более и более популярным, и на самом деле
действительно, судя по тому, что те же статьи, которые пишем мы, мы тоже часто
опираемся на машинное обучение, как одну из основных мотиваций. Но на самом деле
оптимизация имеет довольно много приложений. Да. В первую очередь, на данный
момент это машинное обучение, анализ данных, там какие-то статистические модели.
Ну, конечно, она возникает и в финансах, и в управлении, в том числе там управлении
там, не знаю, ракетами, дронами и так далее. Вот. Всякими вопросами логистики,
вопросами планирования и много где еще. То есть до всяких там мелких задач в духе
того, как нужно обработать или там отфильтровать картинку, избавить от шумов.
Вот. То есть там какие-то есть и глобальные цели, и цели, которые там какие-то локальные,
чтобы фотку для инстаграма улучшить. Вот. Окей. Вот. Ну, к сожалению, я не знаю, вот так
вот повелось, что часто оптимизацию воспринимают как просто некоторый
инструмент, который у вас там задача оптимизации возникает как вспомогательная
вашей там исходной задачки. Вот. Ну и эту задачку оптимизации как-то решают,
используя некоторые там известные всем пакеты, черные ящики, не особо разбираясь,
что же там внутри этих черных ящиков происходит. Вот. Наша задача на этом курсе разобраться и в
некотором смысле как с какими-то основными черными ящиками познакомиться с ними, но и заглянуть в них,
что же там происходит внутри этих черных ящиков. Вот. И в том числе с точки зрения теории. Вот.
Это цель у нас курса. Вот. Тут немного историй, как вообще развивалась оптимизация со временем.
Все же первым основателем оптимизации считаются каши. Каши, которые ровно те теоремы, которые вы
выучили, он и здесь отличился. Вот. Он, соответственно, использовал задачу оптимизации для решения
линейных систем. То есть была у него задачка решить линейную систему, но он ее переписывал,
соответственно, вот в таком вот виде и говорил, что я хочу, наверное, получить ноль, а тогда я,
наверное, могу вот это вот так вот сделать. То есть попытаться минимизировать вот эту функцию,
потому что как раз вам Евклидова норма даст ноль в решении системы. Вот. Один из
альтернативных способов, как решать систему линейных уравнений, вот придумал каши и,
соответственно, придумал он метод решения градиентный спуск. Ну, вот это, соответственно,
точка отсчета оптимизации. Дальше, соответственно, надолгое время про нее как-то подзабыли. Но вот,
соответственно, в середине двадцатого века в связи с развитием всяких численных методов,
в том числе для космических исследований, для программ и всяких ядерных программ,
вот, стали супер актуальны и появились, начали рассматривать конкретные задачи оптимизации,
типа линейного программирования и ненедельного программирования. И в то же время примерно
появляются первые стахистические методы, так скажем, то, что улегло в итоге в фундаментом вот
того, что сейчас используется для нейронных сетей. Вот. В девяносто-восемидесятые годы,
соответственно, появляется уже общая теория оптимизации с оценками сходимости. Ну, в первую
очередь, тут, конечно, отличились наши соотечественники. Это Борис Полик, Юрий Нестеров,
Аркадий Немирорский. Теория оптимизации, можно еще считать, что лежит на плечах вот этих трех
гигантов советской математики. Ну и, соответственно, сейчас, что еще сейчас? Сейчас эта оптимизация,
в первую очередь, заточена на задачи большого размера, в том числе нейронные сети, и, соответственно,
популярность приобрели особые стахистические методы разного рода для разных постановок задач.
Окей. Здесь, соответственно, выписана вам общая постановка задачи оптимизации. У нас есть целевая
функция F, которую мы хотим минимизировать. При этом, в общем случае, у вас может быть задано
некоторое ограничение в виде множества Q. Часто это множество какое-то простое, какой-то шарф в
произвольной норме. Возможно, симплекс вероятностный. Ну, главное, что множество не очень сложно и
легко описываемо. Плюс у вас могут быть еще дополнительные ограничения типа неравенств и
равенств. Вот. Эти ограничения могут быть функциональными, то есть заданы в виде какой-то
функции. Они, соответственно, добавляют, что ли, дополнительных проблем задач и дополнительного
шарма. Вот. Как это все решать? Окей. Вот, соответственно, общая постановка. Как выглядит у вас задачка
оптимизации? Вот. Ну и у меня, соответственно, к вам вопрос. Что вообще можно про эту задачу
сказать? И сложно ли она вообще для решения? Какая у вас есть уже сейчас интуиция и понимание того,
что происходит в решении задач оптимизации? Не стесняемся. Если вы не будете сами отвечать,
я спрошу кого-нибудь самостоятельно. От конкретной задачи? Ну, это правда, да. Ну,
вот с теми задачами, с которыми вы сталкивались, сложны они или нет? Не всегда тривиальны. Вы даже
на первом курсе, когда нам от анализа считали вот эти все производные, искали ноль производных,
даже там было не совсем, что ли, хорошо, как вот найти какой-то минимум вот у этой производной.
Для каких-то базовых примеров все было хорошо, но когда функция становилась сложнее, даже в
одномерном случае у вас уже были проблемы. Ну и, соответственно, когда мы говорим про реальные
задачи оптимизации, но очень часто так бывает, что аналитически вы ее решить не можете. Нет
никакого выражения в явном виде, например, как решить систему уравнения, она же не всегда имеет
единственное решение. Возможно, численные методы в данном случае помогут вам лучше.
Про нейронные сети тут вообще говорить не приходится, ну, то есть какое аналитическое
решение у какой-то там очень сложной, там, не выпуклой задачи. Соответственно, да, приходится
прибегать к каким-то дополнительным ухищрениям, чтобы эти задачи решать, на бумажке вы ответ не
выпишете. Ну и, соответственно, да, здесь я отмечаю основные особенности, первая особенность,
соответственно, что задача оптимизации может вообще не иметь решения даже в самых простом случае,
минимизируем линейную функцию, понимаем, что на всем пространстве R и понимаем, что у нее есть
минус бесконечность и по факту оптивум это нет. Вот, ну, как я сказал, аналитически мы их решать
не можем, ну и часто действительно сложность этих задач зависит от целевой функции и от тех
ограничений, которые у нас накладываются на задачах, в качестве множества Q и в качестве
вот этих дополнительных функциональных ограничений G. Вот, да, вот, ну и, соответственно, да, в связи
с тем, что аналитического решения у нас нету, аналитического решения нету, предлагается как-то
подбираться к решению, потихонечку, итеративно, например, и находить его приближенно. Часто этого
достаточно. То есть для большинства приложений этого достаточно. Более того, для referring dolly
доли приложений этого достаточно. Главное-то точность, для каких-то приложений достаточно
какой-то небольшой точности решения, приближенного, там, окрестностей до которой вы дошли. Вот. Для каких-то
приложений нужно рассчитывать все более точно и точно. Вот, вообще, когда мы говорим про методы
оптимизации, как искать минимум функции, мы говорим в некотором... мы пытаемся решать
не какую-то конкретную задачку. То есть если мы там, например, хотим минимизировать просто
функцию x в квадрате, то решение для этой задачки вы знаете. Для этой конкретной задачки вы знаете,
что решение в нуле. Но это неинтересно. Это неинтересно. Предполагается, что методы оптимизации,
которые вы будете разрабатывать, они будут способны решать целый класс из задач. То есть,
например, как-то вы все же можете описать функцию, с которыми вы работаете, и в этом классе задач
соответственно как-то жить. И для него разрабатывать уже методы. Это уже более
интересно, потому что появляется какая-то универсальность. Соответственно, поменяли
задачку, а метод все равно работает. В связи с тем, что у вас метод универсальный, появляется важная
особенность. То есть, метод не знает полной информации о функции. То есть, он заточен на то,
чтобы по факту ему на вход что-то подавали. И, соответственно, как-то с этим работает. При этом,
как выглядит функция полностью, он не знает. Ну и не должен знать по факту, это же как раз
исследствие универсальности, что он подстраивается под ту функцию, которую его просит минимизировать
в данный момент. Ну и, соответственно, да. И предполагается в численных методах, что у нас метод
может запрашивать у какой-то дополнительной программы информацию о функции. Насколько полная эта
информация, ну уже зависит от метода. Хочется, конечно, обходиться более простыми вещами. Ну понятно,
что, например, просто метод берется, спрашивает у какой-то дополнительной программы, где минимум
функции выдает это как ответ, это неинтересно. Понятно, что мы хотим построить что-то более
реальное к жизни. То есть, хочется как-то спрашивать не особо много про функцию,
используя какие-то не особо сложные дополнительные процедуры, выяснять информацию какую-то о
функции, чтобы ее использовать уже в минимизации этой функции, в оптимизации нахождения решений.
Ну и, соответственно, к вам вопрос, какого рода информацию можно спрашивать у аракулов. В данном
случае, вот то, что как раз дополнительная программа, которая нам выдает информацию о функции,
это аракул. Что можно спрашивать? Производную. Хорошо, что еще? Сколько минимумов есть. Сколько
минимумов есть хорошая, в принципе, информация, но уже сложно ее доставать. Сколько минимумов есть,
это значит, я примерно знаю где минимумы. Это уже такая довольно дорогая информация. Что еще?
Вторые производные. Все правильно. То есть, часто действительно в численных методах оптимизации мы
запрашиваем какую-то информацию нулевого первого порядка. То есть, в данном случае могут быть
просто значения функции. То есть, дополнительная программа просто вычисляет значения функции.
Может вычислять какие-то градиенты. То есть, производные по каждой из переменных. У нас
понятна задача оптимизации. Зависит от целого вектора переменных. И мы можем посчитать
градиенты частные производные. Соответственно, можем посчитать информацию второго порядка.
Соответственно, матрицу Гесса, он же Гессиан. Ну и можем более старшие производные, там уже в
зависимости от специфики. Понятно, что в реальности на самом деле вот это появление аракула, оно
конечно немного математично, что вот мы называем, что у нас есть дополнительная программа. Но в
реальности на самом деле так и есть. Часто приходится иметь дело в жизни, что действительно
значение функции или градиент вычисляет дополнительная процедура. Я думаю, вы когда
даже реализовывать это будете в домашнем задании, вы подсчет градиента будете реализовать
дополнительной функцией. Или дополнительным процедуром, или дополнительным классом. Неважно,
как вы будете делать, но главное, что это что-то
отдельное.
Ну и в жизни, например, часто мы можем просто
иметь доступ только к информации нулевого порядка,
и даже она может быть дорогой, просто посчитать значение
функции дорого.
Я не знаю, кто-то знаком с всякими обучением с подкреплением,
когда у вас есть какая-то среда, и у вас есть возможность
действовать в этой среде, и вам нужно увеличить
свой выигрыш, меняя действия, которые вы можете применять.
Но при этом вы действуете вслепую, то есть вы можете
применить какое-то действие и посмотреть, как на него
отреагирует среда.
Можете применить другое действие, посмотрите, как
на него отреагирует среда.
То есть по факту, среда вам возвращает просто значение,
насколько она удовлетворена или не удовлетворена тем
действиям, и какой нам выигрыш вам за него дает.
И, соответственно, вы получаете просто значение функilities
при этом может быть дорого, в реальных задачах motsчет
и функция может занимать день.
Ну и в градиенте, когда вы там обучаете нейронной
сети, тоже подсчет этого градиента, это тоже дополнительная процедура, там forward-backward
процедура, которая тоже занимает время, это понятно, вот такие вот аракулы могут быть.
Окей, общая схема того, как вообще устроены методы оптимизации, как их можно описать.
Вот здесь сяду, и мы чуть-чуть поговорим. У нас есть начальная точка, просто откуда мы
стартуем кандидатное решение, возможно очень плохой кандидат, но почему нет. Как-то мы решили,
что у нас точка x0, может быть как-то хорошо, может и плохо, может мы просто взяли и сказали,
давайте стартуем из нуля. Важное уточнение, во всех местах я буду использовать номер текущего
значения x с верхним индексом, это значит, что это текущее значение x, во время итерации мы его
будем менять, соответственно у нас будет появляться x ката, это значит, что x на кат итерации,
это не степень, это просто x на ката итерации. Ну я не знаю, я так привык, просто часто приходится
работать с распределенной оптимизацией, когда у нас задача оптимизации решается на нескольких
устройствах, и там соответственно появляется еще нижний индекс, который отвечает за номер устройства,
который эту задачку решает, вот, и мне просто уже привычнее лепить вверх этот индекс,
вот, потому что тогда там приходилось вот так делать, это неприятно, вот. Вот, есть, короче,
точности epsilon, которую мы хотим достичь, вот. Что происходит? Мы задаем счетчик итерации,
в данном случае пока он равен нулю, вот, плюс мы задаем нашу информационную модель, то, что мы
те знания, которые мы накопили в функции на данный момент, вот. Как происходит обычно метод? На
текущей итерации мы задаем вопрос аракулу какой-то точки x каты, текущей точки x каты, и аракул возвращает
нам информацию о функции в этой точке, ну, например, значение функции, градиент, гисиан, вот. Что мы
делаем? Мы добавляем соответственно в нашу информационную модель то, что мы знаем о функции,
текущую точку и то, что нам рассказал аракул, то, что нам рассказал аракул. Ну, и соответственно,
дальше вступает в дело наш метод оптимизации. Он что берет? Он берет нашу информационную модель,
и как-то ту информацию, которая в этой информационной модели хранится, использует для оптимизации,
ну, то есть для следующего шага, для пересчета текущего значения переменной x ка плюс 1. Выглядит
немного муторно и сложно, сейчас разберемся, например, что тут происходит. Ну да, чтобы остановить эту
процедуру, мы проверяем критерий. Останова, если критерий выполнен, тогда мы возвращаем значение,
если нет, то переходим на новую итерацию. Давайте на примерчике посмотрим, на примерчике градиентного
спуска. Пока мы с ним не знакомы особо, мы в следующий раз познакомимся с ним поближе, вот. Здесь
главное просто посмотреть, как выглядит метод. Вот, у нас есть задача минимизации функции f без
ограничений, решаем ее на rd. Мы более того, мы знаем, что у нас функция дифференцируемая. Вот, что мы
можем делать? Можем запустить вот такую интеративную процедуру, которую как раз передумал Каши. Вот,
мы же знаем, что производно нам о чем говорит. Локально, локально, что? О чем она говорит? О направлении
роста. Вот. А тогда минус производно говорит о направлении спуска. Все правильно. И вся идея
градиентного спуска говорит, заключается в том, что давайте идти по антиградиенту, раз туда функция
убывает, вот. Ну, мы туда и пойдем. Да, делая какие-то маленькие шашки, потому чтобы далеко не улететь,
потому что опять же, для какой-нибудь квадратичной функции вы берете, говорите, ну вот да, вот нам
градиент говорит, что нужно идти туда, я сделаю огромный шаг и улечу вообще вот сюда, куда-нибудь,
это далеко. Вот, делая маленькие шашки, мы соответственно по чуть-чуть приближаемся к решению.
Вся суть градиентного спуска. Но давайте его разберем с точки зрения вот той информационной
модели, которую мы с вами ввели. Вот. Что тут происходит? Что здесь оракул? Да, то есть какая-то
процедура, которая умеет нам возвращать градиент. Это оракул, соответственно. Что тут информационная
модель? Что мы в ней храним? В информационной модели мы, соответственно, храним что? То есть в
теоретическом случае, то есть в теории, мы можем там хранить вообще все x-каты и все градиенты, да? Вот.
А потом, соответственно, подгружать эту информационную модель в метод. Ну и метод справедливости ради
вообще не использует все k, так? Все, что у нас хранится в информационной модели, он использует только
последнее, да? Вот. Ну, почему нет? Есть методы, которые действительно сильно используют предысторию. Мы
такие тоже с методами встречать. Вот. Они используют как-то предысторию. Ну, вот, градиентный спуск не
использует, он пользуется только локальными свойствами функции. Ну, такой вот метод, довольно
простой. Вот. В этом его как бы и плюс, и в этом его и минус. Ну и, как вы понимаете, с точки зрения теории,
в принципе, мы в информационную модель можем просто бесконечно пихать вот эти все точки и не
особо волноваться. С точки зрения понятной реализации методов информационной модели можно как-то
дополнительно модифицировать. То есть зачем нам хранить эти предыдущие точки, если метод их вообще
не использует? Вот. Поэтому можно в информационную модель там оставлять те точки, которые нужны
конкретно для нужной итерации, и сразу как бы онлайн их пересчитывать. То есть модифицировать
информационную модель, а не просто бездумно туда что-то пихать. Вот. Ну, это некоторые особенности
реализации, которые в принципе становятся понятны, когда вы видите метод. Вот. Ну, здесь ответом можно
просто из информационной модели выкидывать все, кроме текущей точки, текущего градиента. Вот. И
не жрать память. У меня такой вопрос. До этого я вам описывал общую схему. И тут показал метод.
Чего не хватает в схеме? Критерия останова. Здесь я использовал такой супербанальный критерий
останова. Сделаем к большой итерации, остановимся. Вот. На самом деле можно останавливаться и по
другому. Останавливаться и по другому. Например, когда вы достигли решения по аргументу, и вы близки
к решению по аргументу, там до точности епсилон, вы прям приближаетесь, приближаетесь, приближаетесь,
и можете гарантировать, что x-каты там очень близко лежит в епсилонокрестности решение. В чем проблема
такого критерия? Да. То есть такая вещь, это такая, больше теоретическая. То есть в теории мы как раз с
вами будем доказывать, что метод гарантирует, что вы приближаетесь к решению вот так вот.
Отлично. Отлично. Вот. Смотрите, то есть да, вот тот критерий, который написан сверху, он не супер
практический. В теории мы с ним будем взаимодействовать. Там теория нам будет гарантировать,
например, градиентный спуск через какое-то число итерации будет сходить, приближаться к решению.
Окей, но как мне это использовать на практике? Вот. А на практике можно использовать так. Я знаю,
что у меня в теории вот это будет меньше епсилон. Вот. И вот это будет меньше, чем епсилон. Ну,
тогда вот расстояние между соседними точками будет меньше, чем два епсилона. Здесь я просто
неравенством треугольника воспользовался. Ничего тут только сверхъестественно нет. Я надеюсь,
для всех это понятно. Все. Супер. Кивнули только на первой партии остальные. Молчание, знак, согласие.
Ну, смотрите, то есть тут, видите, это следует из того, что, например, мы для алгоритма можем
доказать, что вот он к решению приближается. По заданной точности епсилон мы знаем число
итерации, через которое он их достигнет. Ну и тогда вот это действительно точно будет выполнено.
Вот. Ну понятно, что не для всех этих алгоритмов это можно сделать. Вот. Но мы
будем как раз работать с такими алгоритмами, для которых мы это можем сделать и для таких
задач, для которых мы это можем сделать. Да. Какая? А тут мы пока вообще не говорим про скорость
сходимости к ответу. Не-не-не. Я скорее говорю про критерия Останова. То есть мы не оцениваем
по расстоянию до оптимума. То есть в теории мы, смотрите, можем гарантировать вот это. То есть
теория нам говорит, что вот для этих задач вот этот метод через k итерации может гарантировать
А теперь вопрос. Как мне на практике этот метод остановить, если я не знаю оптимум? Вот. Либо я
могу как-то останавливать просто по теории, говорить, что я знаю число итерации. Вот. Либо,
например, метод мне говорит о том, что там вот условно я достиг точности епсилон или там
епсилон пополам, тогда здесь будет епсилон. Вот. И зная то, что у меня метод гарантирует,
что мы приближаемся к решению, что xkt плюс 1 становится ближе к решению, чем xkt,
тогда это тоже могу ограничить епсилон пополам. Ну и тогда, если у меня вот будет точность
епсилон, вот. То метод в принципе можно остановить. Я согласен, что это не совсем эквивалентная вещь.
То есть отсюда мы не можем делать, вот просто из этой строчки мы не можем делать четкий вывод,
что разница между решениями нас ведет к тому, что мы в итоге сходимся к решению. Но тут еще
дополнительно нужно принимать во внимание, что есть теория, которая говорит, что для этого класса
задач мы к решению действительно сходимся. Вот. То есть вот из этой строчки просто без какой-то
дополнительной информации о том, что мы сходимся, действительно сделать нельзя. Мы может просто какой-то
дурацкой точке сходимся, ну и метод перестает как бы сходиться, а оптимум вообще в другой стороне
валяется. Не обязательно на епсилон, но на какой-то кусочек, на какой-то кусочек. Да. Да, да, да, да, да.
Они не стоят рядом. Ну смотрите, тут видите вопрос в том, что у вас есть теория, которая вам
гарантирует, что условно через какое-то число итераций, через какое-то число итераций, у вас точно
это будет выполнено. Вот. Это скорее вот так вот. Понятно, в теории мы будем работать вот с этим
критерием. На практике можно использовать вот такой. Опять же я говорю о том, что часто, ну вот есть
ситуации, что действительно вот отсюда вывод о том, что метод сходится как-то к решению, сделать
нельзя. Но работать неплохо. Может так случиться, может так случиться. Может так случиться раньше
времени, да. Окей. Есть еще также такая проблема в виде того, что х звезда не уникальна. Вот. Ну
разные задачки соответственно у вас не обязательно для какой-то задачи есть точное решение, которое
вот единственно. Вот. Например, для какой задачки, которая кажется довольно тривиальной, решение
может быть не единственным. Ну, давайте что-нибудь попроще придумаем, чтобы было понятно. Давайте совсем
просто полином напишу. Вот такое вот. Где у него оптимум, понятно, да? В нуле, то есть оптимальное
значение у него ноль. Ну, вектор х у него состоит из двух компонентов, х1 и х2. Вот. У него два
параметра, оптимальное значение у него ноль. Так. Вот. Но при этом, какие х дают это оптимальное
значение, х1 равный х2. Так. И это целое семейство значений, которые по факту, все они нам подходят.
И что из этого решения? Ну, непонятно. Поэтому вот как вот с таким работать, уже возникает вопрос
даже в теории. То есть функция, например, самая простая функция, это вот какая-то константа,
где каждая точка подходит как решение. Ну, тогда к чему мы там сходимся, вот непонятно. Поэтому можно
и в теории, и на практике это модифицировать чуть-чуть вот так вот. И проверять уже сходимость по
функции. Вот. Это решает соответственно вопрос. Ну и более того, можно использовать что-то типа
сходимости по норме градиента. Потому что вы знаете, что в оптимуме у вас что происходит?
Производная ноль. Производная ноль. Производная ноль. И поэтому вы можете проверять как бы как
меняется у вас градиент. Но в каких задачах, соответственно, это можно использовать?
Не только. Смотрите, это как бы разные варианты того, как мы можем проверять,
вообще сходимся мы к решению или нет. Вот. То есть, смотрите, первый не подходит. Часто он
действительно, когда мы, например, не понимаем, какой х у нас оптимум, то есть он не уникален,
можно просто проверять сходимость по функции. Вот. Потому что функция как раз оптимальное значение
функции. Я эту задачу, которую я описывал, она выпуклая. Вот. В принципе, там все должно сходиться,
мы это будем доказывать. Но вот оптимум не уникален в этом проблеме. Но зато по функции все хорошо.
Ну а такой самый вообще точно работающий критерий — это сходимость по норме градиента. Но вот вопрос,
когда он работает? Вот вы сказали, что норма градиента равна нулю. А?
Функция дифференцируема — окей. Пусть будет дифференцируема. Какие еще могут быть усложнения?
Констант. Там же все хорошо будет. А?
Могут быть проблемы, да, какие-то. Ну это какие-то такие, не особо… Так?
Стационарная точка. Стационарная точка тоже может быть проблемой. То есть вы нашли
стационарную точку, но не нашли в реальности решение. Вот.
Может быть. На самом деле я тут больше говорю про тот пример, когда у вас,
например, есть функция какая-то. Вот. Но ваше оптимизационное множество — оно ограничено.
Вы решаете задачку вот на том, на тех воротках, которые я нарисовал. Так? Тогда у него оптимальное
значение вот здесь вот. Так? Но градиент там не нулевой. Вот. Поэтому вот тот критерий,
который используется, то есть его можно использовать только для безусловной оптимизации. Ну и опять же
со специфика того, что вы не нашли стационарную точку и другими всякими частными случаями проблем.
Окей. Когда вообще мы говорим про алгоритмы, хочется как-то их сравнивать с точки зрения того,
что нам требуется для вычисления. То есть да, мы можем сравнить, какой оракул используется. Вот.
Но мы сможем сравнивать алгоритмы исходя из того, что… Вот, например, алгоритмы,
использующие одинаковый оракул, мы тоже между собой можем сравнивать. Для этого соответственно
вводится аналитическая оракульно-аналитическая сложность и соответственно арифметическая
сложность. Аналитическая сложность, она же оракульная сложность. Заключается в том,
что вы просто смотрите, сколько вызовов оракула вам необходимо было сделать для достижения
точности ε. Вот. В принципе неплохой критерий, потому что, как я и говорил, оракул может быть
дорогим. И на самом деле, наверное, самой дорогой операцией, часто вот в численных методах
оптимизации является вызов оракула. То есть там подсчет градиента, вызов функции. Вот. Но более
так скажем, приближенное к времени вычисления, потому я здесь пишу временная сложность,
это арифметическая сложность алгоритма. Там вы учитываете не только количество операций,
то есть каких-то атомарных операций, необходимых для подсчета оракула, но еще и всякие атомарные
операции, которые вам нужно дополнительно сделать методом. В том же градиентном спуске вы посчитали
градиент. Вот. Но, соответственно, там еще дополнительно нужно поскладывать два вектора,
умножить вектор на число. Это тоже дополнительное вычисление, которое необходимо сделать. Часто
ими пренебрегают, потому что оракул, вычисление оракула значительно сложнее. Окей. Но вообще вот
мы будем с вами строить какую-то теорию вокруг методов оптимизации, будем доказывать их
сходимость. Вот. Хочется понять вообще какого рода результата мы сможем получать. Вот. И для этого
давайте посмотрим вот на такой примерчик. Вот. Хочется же получать какие-то адекватные результаты,
что вот метод сходится быстро, довольно быстро там за какое-то понятное время. Вот. Ну давайте
посмотрим, например, ну то есть в принципе в качестве целевой функции, в задаче оптимизации
может быть что угодно. Какая-то плохая функция, в которой, например, есть какой-то глобальным оптимум,
ну вот пусть есть. Вот. Ну вот я предлагаю рассмотреть невыпуклые задачи, невыпуклые задачи. Вот. И функция
f при этом является Липшицевой. Липшицевой. И мы рассматриваем эти задачки на таком вот кубике,
на кубике. Вот. Ну в двумерном плоскости это вот просто соответственно у нас такой квадратик. Вот.
Ну там понятно дальше будет кубик и так далее. У нас размерность d. Вот. И мы предполагаем, что наша
функция является Липшицевой. Выполнено следующее утверждение Липшицевой в L бесконечность нормы.
Ну то есть получается значение функции, так скажем, меняется не сильнее чем m умножить на вот эту
разность нормы кредитов в норме бесконечность. Норма бесконечность это просто максимум. И по
компонентный максимум из разности x и t и y и t. Вот. Мы могли вообще ничего не предположить о
функцию, но вот предположили это. Ну и окажется, сейчас увидим, что и этого окажется не особо
достаточно для того, чтобы получать какие-то интересные результаты, но вот это мы к концу дойдем.
Вот. Смотрите. Во-первых, в чем мы замечаем? Множество b это у нас компакт. Вот. Из-за Липшицевой
этих функций следует то, что она, вот если мы устремим норму бесконечность, ну вот x устремим к y,
мы получим непрерывность нашей функции. Вот. А в силу того, что у нас теперь непрерывная функция на
компакте, что мы про нее знаем? Есть. Она достигает и своего минимума, и своего максимума, так? Поэтому
давайте, почему бы нет? Максимум обозначили вот так вот. Верхний индекс. Ну и соответственно. Да,
пожалуйста. Вот. Берем методы нулевого порядка. Можем считать только значение функции. Ну и
хотим, соответственно, найти что-то близкое к Эпсилон решению. Так. Задача понятна. Какого рода
метода мы можем использовать тоже понятна. Вот. Давайте попробуем решать. Может быть, вы какой-то
предложите метод, который может подойти. Как решать? Только нулевое порядок. Градиентов нет.
Отличный вариант. Отличный вариант. Вроде бы, как бы он простой, банальный. Давайте попробуем. Вот,
пожалуйста. Сеточка. Если мы соответственно. То есть, что делаем? Давайте я на картинку нарисую.
На квадратике нарисую. Берем. Разбиваем наш кубик на сеточку. Вот. И смотрим значение в узлах этой
сеточки. Так. Где самое минимальное, то соответственно и вернем в качестве решения. Согласны? Хороший
вариант. Хороший вариант. Понятный, главное. Вот. Он здесь и описан. Строим сеточку. Вот. И,
соответственно, среди точек просто находим с минимальным значением и ее возвращаем. Вот.
Давайте докажем вообще какие у нас есть гарантии на то, как этот метод работает. Вот. Здесь дана теорема,
но ее нужно бы доказать. Вот. Давайте скажем, что вот у нас есть некоторая точка X звездой,
которая является минимум нашей функции. Миниум нашей функции. Вот. Тогда давайте,
что сделаем? Тогда вот в этой сетке этот минимум выделим. Ну, вот он пусть будет где-то вот здесь.
Лежит он в каком-то из квадратиков. Так. Тогда что? Тогда я могу найти в некотором смысле этот
квадратик, где он содержится. То есть, я могу задать этот квадратик уголками. Вот. Вот можно
даже перерисовать этот квадратик. Какой-то квадратик есть. Я его, соответственно,
вот так вот выделил. Вот. Мы, понятно, не знаем, где он находится, но вот вычислили значения в
уголках и, соответственно, в том числе в уголках квадратика, где находится X звездой. Вот. Дальше,
что хочется сделать? Дальше, что хочется сделать? Мы можем, соответственно, ну мы знаем,
что стороны этого квадратика 1 на p, 1 делить на p, где p у нас это количество, у нас наш квадратик
кубик размера единица, количество отрезочков, на которые мы разбили p. Поэтому размер вот этого
маленького квадратика 1 делить на p. Вот. Соответственно, расстояние у него будет 1 делить
на p. Дальше, что я хочу сделать? Дальше, я хочу найти уголок этого квадратика, который наиболее
близок к X звездой. Вот. Ну, в данном случае-то вот будет вот этот уголок. Понятно, что это в
любом случае можно сделать. Вот. И теперь наша задача понять, насколько алгоритм, наш алгоритм,
мог ошибиться, если, например, он выберет вот эту точку, вот эту точку, как решение. Пусть наш алгоритм
выбрал эту точку как решение. Вот. И вернулся, соответственно, f с крышечкой, и x с крышечкой,
и значение f с крышечкой. Насколько это решение отличается с точки зрения значения функции от того,
что могло произойти в X звездой? Так? Ну, давайте посмотрим. Здесь мы можем воспользоваться тем,
что, видите, я могу оценить расстояние между вот этим уголочком и до X звездой. В худшем случае
оно будет 1 делить на 2p. Согласны? 1 делить на 2p. Так? Когда вот у меня, соответственно,
X звездой находится в серединке. Это худший случай. Вот. Понятно, там оно может быть поближе. Вот. Ну,
вот я оцениваю сверху. Соответственно, говорю, что расстояние до решения от точки,
которые мы выдали, от точки, которые мы выдали как решение, ну, вот оно меньше, чем 1 делить на 2p.
Ну, соответственно, бесконечную норму мы тоже можем оценить вот таким вот образом. Окей. Дальше
пользуемся липшицовостью функции и выписываем следующее. Вот это, соответственно, у нас точка уголок.
Уголок. И мы пользуемся, что расстояние от уголка до решения меньше, чем по бесконечной норме 1
делить на 2p. Ну, и соответственно, функциональное значение меньше, чем m делить на 2p. Согласны?
Вот. Здесь также учтено, что в качестве решения мы могли выдать что-то, кроме уголка. Что-то,
кроме уголка, где у нас по факту значение было меньше. Но вот в худшем случае как бы мы вернули
этот уголок, и тогда мы точно можем гарантировать, что у нас m делить на 2p. Расстояние до решения,
именно функциональное оно, m делить на 2p. Вот. Вот этот момент мне кажется немного таким вот хитрым,
потому что мы могли вернуть что-то лучшее. Вот. Но по факту могли точно вернуть уголок, и там вот
решение будет отличаться от реального, не меньше, чем вот на это число. Вот. Этот момент мы еще чуть-чуть
к нему потом вернемся. Вот. Окей. Тогда мы можем сказать, что вот то решение, которое мы вернули,
вот. Оно меньше, чем вот это. И тогда мы можем оценить число точек, которые нам нужно набросать,
то есть то число p, которое нам нужно сделать, насколько нам нужно разбить наш квадратик. Ну,
и делается это следующим образом. Мы хотим, чтобы это было меньше либо равно, чем эпсилон. Мы хотим
достичь точности эпсилон. Поэтому отсюда мы можем найти p. Так. Вот. А значит, мы можем найти
количество обращений к ракулу нулевого порядка, потому что мы знаем теперь количество точек в
сетке, мы знаем размер, у нас размер у нас задачи d. Получается, что мы сделали, мы сделали p в степени
d в учислении. То есть растет экспоненциально с размером задачки. Так. Вот. Окей. Хороший
результат или плохой? Средний. Сейчас поймем. Сейчас поймем. Смотрите. Хороший или плохой
результат предлагается посмотреть на следующем примере. Пусть у нас m равно 2. Небольшая константа
липшится. Размерность задачи равна 13. Точность решения 1 сотая. Ну, то есть кажется, что все очень
небольшое. Вот. Размерность? Это маленькая размерность. Для задач оптимизации эта размерность
маленькая. Ну, это количество переменных, от которых у вас зависит целевая функция. Вот. Для задач
оптимизации, для тех же нейронных сетей, это миллиарды. Вот. Обычно. Вот. Ну, для каких-то
поменьше задач, понятно, там это тысячи сотни тысяч. Вот. Размерность 10, это очень маленькая
размерность. Ну, там 13 в данном случае. Вот. Смотрите. И тогда вот количество обращений к нашему
аракулу будет 10,26. 10,26. Вот. Если при этом обращение, ну, подсчет градиентов, ну, значение функций
в точке довольно простое, то пусть у нас какая-то арифметическая сложность компьютера нашего, там,
10 в 11 арифметических операций в секунду. Вот. Возможно, сейчас какие-то они более мощные есть. Ну,
получается, что для решения вот такого вот несложной задачи, небольшого размера, да, не самой
крутой точности нужно 30 миллионов лет. Не очень оптимистично справедливости ради? Вот. Не очень
оптимистично. Ну, давайте я вам задам вопрос. А что мы вообще получили? Что это вот то, что мы
получили какую-то оценку на решение? Это верхняя оценка, нижняя? Что вообще такое верхняя и нижняя
оценка? Может, вы уже сталкивались с этим? Ну, вообще, то есть мы для алгоритма какого-то,
который наш построили, получили какую-то оценку. Что вот он найдет решение через только вот вызова
фаракула? Вот. Эпсила решения. Это верхняя или нижняя оценка? А как вы поняли, почему это? А что такое
верхняя и нижняя оценка? Ну, смотрите, на самом деле чуть-чуть не так. То есть вы правильно сказали,
что верхняя оценка, это у нас условно есть какой-то алгоритм, вот нами придуманный алгоритм, есть класс
задач. Так. Ну, например, млипчество функций. Вот. И мы хотим гарантировать, что наш алгоритм для
любой задачи из этого класса работает не хуже чем, и вот тогда мы получаем верхнюю оценку. То, что мы
получили, это верхняя оценка. То есть какую бы мы задачу не взяли, наш алгоритм за вот представленное
число итераций, огромное число итераций, оракульных вычислений найдет решение с точностью
эпсилы. Эта верхняя оценка, соответственно, она вот выполняется для любой функции с классом,
вот мы получается бомбим класс задач алгоритмом. Если мы говорим про нижнюю оценку, это в некотором
смысле обратная вещь. У нас есть тоже класс алгоритмов, то есть у нас есть класс алгоритмов,
алгоритмы нулевого порядка, алгоритмы, которые используют только значение функций. Мы выбрали,
когда брали верхнюю оценку, выбрали определенный алгоритм оттуда и бомбили им весь класс функций,
которые мы рассматриваем. В нижней оценке наоборот. Мы говорим, что вот есть такая плохая задача,
что любой алгоритм из алгоритмов нулевого порядка найдет решение не раньше, чем через такое
арифметическое число оракульных вызовов. Ну и смотрите, а что происходит, когда у нас
верхняя и нижняя оценка совпали? Что это говорит? О чем это говорит? Мы нашли оптимальный алгоритм,
то есть вот этот алгоритм для этого класса задач не улучшаем. И в связи с этим у нас возникает
вопрос, то, что мы вот с вами напридумывали, это вообще нормальный алгоритм или нет? Ну то есть,
может быть, мы алгоритм плохой придумали, может, мы плохой анализ сделали, потому что я как говорил,
то что для точки X, которая находится в углу, да, мы можем гарантировать вот это, но возможно нам
надо как-то по-другому выбирать эту точку, и возможно вот для какой-то другой точки вот эта оценка
будет лучше. И на этот вопрос как раз отвечают нижние оценки, причем нижние оценки можно приводить
не только для класса алгоритмов, а для конкретного алгоритма, чтобы просто проверить его на анализ,
то есть на то, насколько он хорошо работает. То есть привести тоже ему плохую функцию и конкретно
для этого алгоритма показать, что вот как бы он не работал, то он будет работать плохо. Ну и
соответственно, да, давайте поработаем над этим и покажем, что на самом деле тут все не улучшаемо.
То есть для вот этого класса функций вот такая сеточка это лучший вариант.
Мы не знаем, где он, я просто хочу оценить, что произойдет, если вот он находится,
например, в этом квадратике, вот, и я же верну какое-то значение в узле сетки по алгоритму,
алгоритм так работает. Ну вот я смотрю на ближайший квадратик и смотрю, насколько там отличается.
Вот этой? Первый?
А нет. Так, вот она.
Вот, окей, теперь хочется показать то, что мы сейчас натворили, на самом деле еще и хороший
алгоритм для вот такого класса задач. Вот, окей, смысл тут будет вот такой. Пойти
от противного. Опять давайте рассмотрим нашу вот эту сетку. Рассмотрим эту нашу сетку. Вот,
и скажем, что вот существует алгоритм, вот это я обозначу за n, число итерации n, там m делить
на 2 эпсилон d, вот, пусть будет это еще pd, вот. Я говорю, что существует алгоритм, который за n,
с волной итерации меньше, пусть будет меньше, чем n, найдет решение, найдет решение, так? Вот.
Не итерация, только арифметических вызовов нулевой точки. Ну так, давайте подумаем,
что мы можем сказать вообще о том, что происходит. То есть, вот, смотрите, у нас есть, опять же,
сетка, и вот в этой сетке теперь я рассматриваю не узлы, а вот эти внутренние квадратики. Эти
внутренние квадратики, та же самая сетка, что была в предыдущем случае. Мы взяли нашу функцию,
разбили вот этот кубик, на p сегментов получили вот такой вот кубик, то есть разрезанный кубик,
то есть получается pd вот таких вот квадратиков. Мы вызвали аракул в n с волной точек, так? n с
волной точек. Вот. И предполагается следующее, давайте изначально определим нашу функцию нулем везде,
нулем везде, и запустим тот алгоритм, мы предположили, что он существует, который работает
быстрее, чем вот, чем вот это, чем вот это. Вот. Пусть он существует, пусть он существует,
давайте его запустим на чисто нулевой функции. Просто функция везде равна нулю. Что он начнет
делать? Ну, он как-то работает, мы не знаем, как он работает, но в любом случае он вызывает
значение функции в точках, так? И эти точки как-то ложатся в нашу сетку, так? В итоге он вызывал там
свое n с волной точек и выдал какой-то, и в итоге он везде, и мы говорят, везде ноль. Ну,
он что-то выдаст, он еще выдаст одну точку, давайте вот здесь на всякий, для строгости напишу n минус
один, вот. Он в итоге запросил n с волной точек, n с волной точек, как-то они раскиданы на квадратик,
возможно они в одном и том же квадратике попадают, вот кубик наш маленький, вот. В итоге он выдал
какое-то решение, ну вот понятно, он какой-то тоже от балды выдал, потому что везде у него ноль,
вот. Как он будет по этому рассуждать? Ну, он тоже дал еще одну точку, которая тоже легла в квадратик.
В итоге по факту мы просмотрели n с волной точек плюс одну точку, то есть n с волной это он
просто популял, вот, а плюс одна это то, что он выдал в качестве решения, вот. И в силу того,
что у нас n определено вот так вот, n большое, без волны, вот, то что у нас по принципу Дерехле, верно?
В каком-то квадратике мы не заглянули, в какой-то квадратике мы не заглянули, вот. И получается,
что решение, которое мы получили, которое он выдал, ну в лучшем случае лежит на границе этого квадратика,
да? Вот. Ну идея в том, что давайте теперь чуть-чуть модернизируем функцию под этот метод конкретный и
минимум просто провалим в этот квадратик, вот. И вот здесь вот сделаем вот такую вот ямочку в
этом квадратике, сделаем ямочку, вот. Для каждого алгоритма это рабочая схема, то есть может быть
другой алгоритм, он, возможно, выбирает по другому точке, по другому возвращает решение. Но для него
я тоже найду квадратик, возможно, не этот, который здесь вот, а другой, куда я помещу ямочку. Куда я
помещу ямочку и, соответственно, в лучшем случае я буду только на границе этой ямочки. А значит,
могу оценить, насколько я там, вот, для этой ямочки далек от решения. Далек от решения. Ну и там,
соответственно, получается ровно та оценка, которую получили, потому что у нас, вот, я полипшется
в эту ямочку максимально спущу минимум, вот. Здесь у меня значение на границе ноль, вот. А вот здесь у
меня ноль везде на границах, а здесь, соответственно, в центре вот этой ямочки будет там значение,
сколько m делить на 2p, вот. Все. Получается, что вот так вот. Видите, в чем проблема. И, на самом деле,
для нашего конкретного алгоритма это тоже верно, вот. Тоже можно определить вот эту плоскость,
которая везде ноль. Мы начнем тыкать, тыкать, тыкать, тыкать. Вот. Но только мы натыкаем везде в
нолик, так. Ну и вернем какую-то из точек. Они везде, в принципе, они между собой эквивалентны. И вот,
когда я здесь говорил, что она может быть лучше, вот здесь вот. То есть, точка, которую мы вернем,
от точки, которая ближайшая к решению именно по сетке, вот. Ну, в нижней нам оценке говорят о том,
что в худшем случае эти точки между собой имеют одинаковое значение. Вот. То к чему я хотел вернуться.
Получается, что вот для такого класса функций мы вроде как-то ограничили функции. Сказали,
что это не совсем произвольная функция целевая. Не совсем произвольная множество, на котором мы
решаем. Но, оказывается, мы можем как бы всегда найти такую плохую функцию, для которой вот метод
нулевого порядка работает не лучше, чем вот этот тупой сеточный перебор. Вот. Вот плохие новости
справедливости ради. То есть, это, как мы поняли, работает плохо. Вот. Поэтому вообще теория оптимизации
строится на более, так скажем, приятных функциях. Вот. В том числе выпуклых, гладких. Вот. Но об этом мы
подробнее, соответственно, поговорим уже в следующий раз. Почему такие функции рассматриваются?
Ну, вот соответственно, какие, что это за функции? Какие у них есть свойства? Какие у них есть
свойства? Вот. Да? Почему вероятностный? Он детерминистический? В среднем на классе
функций? В среднем на классе функций довольно сложно. То есть, это интересный вопрос, но такое,
конечно, исследователи пока не способны. Вот. Как алгоритм BCI ведет в среднем на классе функций?
Ну, это довольно жестко. Вот. Что значит вообще среднее по всем функциям? Сложно вообще описать
класс функций, вот именно как вот. Я понимаю, да, да, да. Да, конечно, конечно. И вот это, на самом деле,
хорошая мысль. Мы будем рассматривать выпуклые задачи, гладкие задачи. Вот. На самом деле,
условно, там нейронные сети, они не выпуклые, не гладкие. Вот. Но при этом, как показывает жизнь,
алгоритмы на них работают ровно так, как работают в теории для выпуклых и для гладких задач. Это
удивительно. Вот. Удивительный факт, что вот, ну вот, практические задачи, они действительно не
настолько плохие. Там мы явно не делаем специальные ямки, чтобы алгоритм у нас облажался. Вот. Они
лучше, они значительно лучше, у них лучше природа. И поэтому вот вся теория, которая действительно
строится сейчас в оптимизации, она более чем релевантна. Несмотря на то, что многие практические
задачи, они, ну, именно с точки зрения, именно описания, они ни разу не какие-то красивые. Вот.
Но можно предположить, что они близки к красивым задачам, хорошим задачам. И поэтому вот эта теория,
она в том числе перекладывается и на нейронные сети. Вот. Но к этому мы, соответственно, придем уже
на следующей лекции, и там поговорим про свойства, функции, которые мы будем предполагать. Вот. А сейчас
я вообще покажу, на какого рода сходимости мы вообще будем смотреть. Потому что эта безобразие,
с которой растет экспоненциальность с размерностью, это ужас. Поэтому мы будем говорить про более,
конечно, классные сходимости с точки зрения числа итераций. Вот. В частности, сублинейная,
линейная, сверхлинейная, квадратичная. Сублинейная сходимость, сходимость как
полюном от к, ну, деление на полюном от к. Например, один делить на k,
один делить на k в квадрате. Нормальная сходимость, но можно лучше. Можно сходиться
с линейной скоростью, также со скоростью геометрической прогрессии. Когда вы к решению
приближаетесь, выедая постоянно вот этот множитель Q.
Это значительно быстрее, чем полином.
Можно вообще сверхлинейно, то есть тут в K добавить
еще дополнительную степень, и тогда у вас выед будет
еще быстрее.
А можно еще круче, можно вот в степень Q поставить
2 в степени K.
Понятно, что у вас экспоненты 2 в степени K будут расти
быстрее, чем в любой полином K в степени P, ну понятно,
вы симптотики.
Вот такие 4 вида сходимости, со всеми мы в некотором
смысле столкнемся, поговорим про, в каких алгоритмах они
наблюдаются.
Ну а на графиках это все безобразие выглядит следующим
образом.
А, кстати, да, вопрос, почему скорость геометрической
прогрессии называется линейной?
В агарифмической шкале она линейна?
Ну, просто принято в теории оптимизации, потому что
мы хотим все более точное решение, мы спускаемся как
бы, то есть берем одну сотую решение, потом одну тысячную
там условно, и так далее, там 10-6, и поэтому вот в теории
оптимизации принято по оси Y строить лагарифмическую
шкалу, вот, она удобнее просто, и вот на этой лагарифмической
шкале как раз у линейной сходимости у вас как раз
будет график выглядеть как линия, поэтому и называется
линейной.
Вот, ну, соответственно, здесь я добавляю уже супер
линейный, видно, что все работает значительно лучше,
ну и как добивочка квадратичная, вот, более того, действительно,
будут методы, которые работают как квадратичные, то есть
условно там градиентный спуск работает линейно,
а, например, метод Ньютон, он уже сходится квадратично,
значительно более быстрый метод, вот, так, все, на сегодня
у меня последний слайд, на сегодня все.
