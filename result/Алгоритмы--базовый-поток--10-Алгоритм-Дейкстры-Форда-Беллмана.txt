Добрый день, давайте начинать сегодня по плану продолжения плана предыдущей лекции.
Мы продолжаем говорить про полезную информацию на графах, то есть так называемые взвешенные графы,
графы, на которых на ребрах написаны какие-то чиселки, которые что-то значат.
В прошлый раз мы рассматривали задачу поиска минимального основного дерева,
то есть такого дерева, такого основного под графа, который, во-первых, является деревом,
который, во-вторых, соответственно, имеет минимальный возможный вес для всех таких деревьев.
Сегодня мы рассмотрим, наверное, самую очевидную задачу, которую можно поставить на графах,
это поиск кратчайшего пути в графе. Мы уже решали эту задачу методом обхода в ширину.
То есть у нас был граф, при этом граф был невзвешенный, и, соответственно, мы в нем искали
минимальные реберные расстояния, то есть как-то идти от одной вершины до второй,
при этом потратив минимальное количество шагов по ребрам.
Ну и у нас там были какие-то приколы, связанные с тем, что эту задачу можно решать,
если у нас, соответственно, ребра имеют какую-то целую длину, соответственно, ограниченную как-то сверху.
То есть, соответственно, можно на этом что-то придумать.
При этом у нас асимптотика сильно зависела от максимального веса ребра.
Сейчас мы решим эту задачу без всякого предположения, что у нас ребра какие-то целые
или, скажем, ребра имеют какую-то ограниченную длину.
В самом общем случае постараемся решить задачу поиск кратчайшего пути.
Ну давайте начнем.
В общем, задача, на самом деле, постановка задачи очень простая.
Дан некоторый граф, ориентированный или не ориентированный, неважно, на котором задана весовая пункция.
Давайте пока считать, что весовая пункция устроена так, что она отображает ребра в некоторые неотрицательные чиселки.
Давайте пока предполагать, что у меня на ребрах написаны неотрицательные числа.
Позже мы это ограничение снимем.
Ну просто если мы допускаем наличие отрицательных ребр, там возникают какие-то проблемы, о которых мы поговорим.
Пока давайте не задуматься об этом, просто у нас на ребрах написаны неотрицательные числа.
Соответственно, есть некоторая выделенная вершина, из которой мы хотим найти кратчайшие пути.
Такая задача обычно называется single-source задачей, задачей одного источника.
То есть у вас есть некоторая выделенная вершина, из которой вы хотите найти пути до всех остальных.
Что значит найти кратчайший путь?
Нужно построить такую функцию, которая для любого V находит минимальный путь.
Вес пути считается как сумма ребер, которые лежат на этом пути.
Думаю, все понятно.
Давайте с коду рассмотрим первый алгоритм, как можно такую задачу решать.
Первый алгоритм — это алгоритм Dx.
Сразу откажу, что алгоритм Dx очень похож на алгоритм Prima, который мы рассматривали в прошлый раз.
В чем идея?
Давайте задачу будем решать итеративно.
А если быть точнее, то скажем таким динамическим алгоритмом.
Давайте скажем так, что у нас есть некоторое множество вершин S.
Постановка задачи. У нас есть какая-то вершина, фиксированная.
Нам нужно из нее найти кратчайшие пути до всех остальных вершин.
Из нуля можно добраться до пятерки за 7 шагов.
А можно предъявить сам путь в виде самих ребер или вершин, которые мы посещаем.
В зависимости от установки задачи.
Алгоритм Dx. Как устроена алгоритм Dx?
Алгоритм Dx установлено очень просто.
Предположим, что у нас есть некоторое множество вершин S, до которых мы знаем кратчайшее расстояние.
Вот, естественно, где-то есть вершин S, и соответственно, есть вершины, до которых мы точно знаем кратчайшее расстояние.
Что мы будем делать?
На каждой итерации, и плюс, у нас есть какие-то другие вершины, до которых мы знаем следующую характеристику.
Пусть это вершина V, и для каждой такой вершины V мы знаем следующую штуку.
Мы знаем кратчайший путь из S в, который проходит только по вершинам из множества S.
Для каждой вершины, вне этого множества, мы знаем следующую штуку.
У меня есть вершина S, и я знаю такую вещь.
Я знаю, как кратчайшим образом добраться до вершины V, при этом используя только вершины вот отсюда.
Допустим, у меня есть такая картина.
Что утверждает алгоритм Dx?
Если у меня есть такая картина, то, соответственно, если я среди всех таких вершин V1, V2, V3, V4, V5 возьму наименьшую,
то есть я возьму V со звездой равная аргмин D от V, где V не принадлежит множеству S,
то тогда D от V со звездой будет точно совпадать с истинным кратчайшим расстоянием
от вершины S до вершины V со звездой.
То есть алгоритм очень простой.
У меня есть некоторое множество вершин, да которых я нашел кратчайшее расстояние,
соответственно, у меня есть множество вершин, до которых я знаю кратчайшее расстояние,
но с всем ограничением, что я мою проходить только по этому множеству.
Дальше, соответственно, по каждой и Foiter Deck буду выбирать вершину с наименьшим весом
с наименьшим весом, и добавлять ее в множество s, ну и так далее. Согласен, что это очень похоже на алгоритм Прима, да?
То есть мы в нем тоже, собственно, у нас было некоторое множество, то есть мы строили разрез, у нас были в одном разрезе вершины, и ребра, которые торчали в остальные.
Мы среди всех этих ребер выбирали минимальное, добавляли в множество, ну и так далее. Здесь, по сути, то же самое, только вместо длины ребер мы используем длину пути.
Окей? Окей.
Да, будем поддерживать массив d от v, которых они к длину кратчайшего пути, проходящего только по вершинам из s.
Ну, соответственно, можно, давайте приведем пример, чтобы
точно все понимали. Ну, давайте вот для этого графа построим массив d.
Вершины до 5.
4, 5.
Давайте считать, что мы ищем кратчайший путь из вершины 0. d от нуля чему равно?
Ну, очевидно, 0, да? Почему? Потому что кратчайший путь из вершины в нее саму, ну, он очевидно, равен 0.
Чему равен d от единицы?
d от единицы.
Еще раз, что такое d? d от v, d от вершины, это длина кратчайшего пути
из старта вершины, ну мы считаем, что старта вершины у нас 0, которая проходит только по вершинам из s.
Ну, то есть, давайте, ну, тут мы будем использовать, ну, мы будем использовать, ну, мы будем использовать,
которую проходит только по вершинам из s.
Ну, ты, давайте, ну, тут, может, не совсем корректно, но в качестве промежуточных вершин можно использовать только вершины из s.
Понятно дело, что, когда мы выходим из этого нож, то мы можем как бы ребра использовать.
6, нет, смотрите, 6, действительно, смотрите, какие, давайте просто наблюдаем по смотрке, у нас пути есть в единицу.
Ну, понятное дело, что есть короткий путь, который идет вот так 2, 2, 1, да, то есть, 5, но тут в качестве промежуточной используется вершина номер 4,
4, то есть она не подходит, то есть путь через эту вершину проходить не может,
окей, значит есть путь 2, 2, 3, да, то есть длины 7, но есть путь 3, 3, вот, то есть тут в качестве
промежуточных используется только вершины из самого множества s, и это самый кратчайший путь
среди всех таких, согласны? То есть 6, окей, ну для двойки, соответственно, 3, а для тройки 2,
до четверки, до четверки 4, да, наконец 5, да, от пятерки до бесконечности, то есть не надо стесняться,
то есть все, действительно, то есть если мы из старта до вершины не можем добраться до вершины,
проходясь только по вершинам из этого множества, ну, используя их в качестве промежуточных, то
соответственно считаем, что расстояние до вот этой вершины равно бесконечности, ну,
действительно, у меня вообще в принципе не существуют пути из нуля до пятерки,
которые бы не затрагивал вот эти вот вершины, согласны? То есть я не могу напрямую из этого множества
попасть в вершину 5, вот, поэтому дай от пятерки равно бесконечности, ну, вот, да, ну, если, конечно,
что говорит алгоритм Dx, алгоритм Dx мне говорит, ну, смотрите, у меня тут, то есть я предполагаю,
что для вершины 0, 2 и 3 я уже нашел корректные кратчайшие пути, соответственно, алгоритм Dx
мне говорит следующее, что я среди оставшихся вершин, то есть, среди вот этой wearing, вот этой,
вот этой, вichtig, выбрать вершину, до которой, до которой расстояние минимально, но это соответственно
эта вершина, 4, соответственно, вершина 4, кратчайший путь раменно 4, соответственно мы четверку
добавим во множество s, обновим расстояние вот этих вершин, и соответственно мы продолжим алгоритм, понятно?
В общем, алгоритм D extra, если коротко, выглядит так.
Ну, инициализация понятна. Как чему равно изначально множество s?
До каких вершин мы, гарантированно, знаем путь?
У нас есть только одна такая вершина, и это вершина s. Согласны?
То есть до вершины s мы, гарантированно, знаем путь, и он равен нулю.
Все, то есть изначально инициализируем множество s с одной вершинкой s маленькая.
Ну а для всех остальных вершин инициализируем вот этот массив d. Каким образом?
Просто-напросто длиной ребра из s до b. Согласны?
Ну потому что чему равна длина пути из вершины s, из множества s,
которая состоит из одной вершины, до всех остальных вершин,
если можно двигаться только внутри вот этого множества?
Ну понятно, дело в том, что совпадает длина ребра из вот этой вершины до остальных.
Соответственно, если этого ребра нет, то считаем, что расстояние равно бесконечности.
Окей?
Ну дальше, собственно, как я сказал, мы из среди этого вот этой массива ищем аргумент
по всем вершинам, которые не лежат в нашем множестве s,
вот добавляем найденную вершину вам множество s.
Дальше обновляем расстояние d а с, в, то есть так, как мы добавили в нашем множество s новую вершину,
если мы эту вершину добавили во множество s, то соответственно, у нас из этой вершины
может быть торчат ещё какие-то ребра до этих вершин.
Соответственно мы можем до этих вершин обновить расстояние. Согласны?
Вот. Соответственно вот, для остальных вершин обновляем расстояние как минимум из текущего расстояния
и d от u плюс w, u, v. Понятно, почему такая формула.
Ну, d от u — это, соответственно, истинное найденное расстояние до вершины u.
Давайте, вот тут вот. Нарешу эту вершину u.
Вот, до вершины u мы знаем уже точно кратчайшее расстояние. Вот оно, d от u.
И плюс, возможно, до остальных вершин, до остальных вершин.
Вот до этой вершины, до этой, до этой мы смогли обновить кратчайший путь.
Мы говорим, что это расстояние до вершины u плюс одно ребро из вершины u в вершину v.
Соответственно, если этот путь новый оказался короче, чем старый путь для вершины v,
то мы его обновляем. Понятно, да?
Ну, то есть банальное просто обновление путей для остальных вершин.
То есть мы предполагаем, что из вершины u мы теоретически можем как-то обновить расстояние до других вершин.
То есть если смогли обновить, то обновили, если не смогли, то не обновили.
Вот. Ну и все, по сути. Повторяем все пункты 1, 2, 3.
То есть продолжаем искать r минимум, добавляем в множество s и так далее.
Пока, соответственно, не перенесем все вершины в множество s.
То есть как только у нас множество s станет равно t ум в множество вершин, значит, что мы закончили алгоритм.
Ну, то есть множество s, по сути, по определению множества вершин, до которых мы знаем точно корректный путь.
Понятно? Отлично.
Так, ну давайте посмотрим на какой-нибудь пример.
Ну давайте будем формировать множество s и массив d.
Так. Ну изначально в множестве s у нас стоит вершина 0.
Только вершина 0. Вот.
Ну и чему у нас будет равен массив d?
Значит, расстояние до вершины 0 очевидно равно 0.
Расстояние до вершины 3 равно 2.
До вершины 4 равно 6.
До вершины 7 равно 5.
Да?
2, 6, 7, 5.
Остальные расстояния равны бесконечности.
Вот.
Окей, ну начинаем. Смотрим на этот нож.
Давайте помечать, что вот так вот.
Пометим, что эта вершина уже лежит во множестве s.
Значит, смотрим на этот массив и ищем в нем, соответственно, минимум.
Минимум равен тройке, поэтому тройку мы добавляем во множество,
до которых мы нашли корректное расстояние.
Теперь, соответственно, так как тройка лежит в нашем множестве s,
то есть теперь в нашем множестве s состоит вот из этих вершин.
Понятно, да?
Соответственно, все возможные пути, которые проходят через ноль, мы рассмотрели.
Теперь давайте обновим расстояние до остальных вершин с помощью тройки.
Ну, это по порядку.
Из тройки ведет ребро в четверку.
Соответственно, до тройки расстояние 2.
Соответственно, путь из тройки до четверки, точнее, из нуля до четверки будет равен 2 плюс 3.
То есть 5.
То есть обновляем.
Смогли обновить.
Идем дальше. Из тройки есть еще ребро в шестерку.
До тройки расстояние 2 мы видим.
И в шестерку еще есть ребро длиной 1.
То есть путь до шестерки равен 3.
Ну, соответственно, бесконечность больше, чем 3.
Обновляем.
Ну, и наконец, до семерки.
Значит, до тройки расстояние 2 плюс ребро 3.
Соответственно, до семерки расстояние 5.
Значит, было тоже 5, поэтому до семерки расстояние не обновилось.
Вот. Окей.
Следующая итерация.
Снова смотрим на наш массив.
И еще у него минимум.
6.
Это шестая вершина.
Поэтому добавляем шестерку в множество s.
И говорим, что до нее мы нашли корректное расстояние.
Ну, окей. То же самое.
Смотрим ребра, которые торчат из шестерки.
И пытаемся обновить расстояние до остальных вершин.
Смотрим ребро 1 ведет в вершину номер 2.
То есть до шестерки расстояние 3.
Еще плюс 1. То есть 4.
Вот.
Обновляем бесконечность до 4.
Окей.
И шестерка еще и с ребровой в пятерку.
На пятерке было расстояние бесконечность.
То есть до шестерки расстояние 3.
Плюс 4. 7.
Обновляем.
Ставим семерку.
Все.
Кажется. Да.
Ну, снова смотрим на наш массив.
Ищем минимальное значение,
которого нет во множестве s.
Ну, соответственно, это значение вот это.
То есть добавляем двойку.
До двойки мы уже нашли корректный путь.
Где у нас двойка? Вот она.
Ну, с помощью ребра обновляем расстояние до семерки.
До двойки у нас длина пути 4.
Плюс 1. 5.
Ну, до семерки снова расстояние 5.
Мы ничего не обновили.
На этом завершаем работу.
Следующая итерация. Снова выбираем минимальное значение.
Тут уже не важно.
Давайте выберем четверку.
Добавляем ее в множество s.
Из четверки у нас...
Из четверки у нас ребер нет.
Из четверки у нас ребер нет.
Поэтому, соответственно, обновлять нечего.
Завершаем работу.
Следующая итерация.
Берем семерку.
Добавляем во множество s.
Из семерки пытаемся обновить расстояние до остальных вершин.
Расстояние до шестерки...
Ну, в принципе, до шестерки не имеет смысла проверять.
Потому что до шестерки уже нашли корочеше расстояние.
Ну, в принципе, все.
Из семерки больше никаких ребер нет.
Поэтому завершаем.
Ну, и последняя вершина, которую мы достаем, это пятерка.
За Collect, а на этом завершаем работу...
И на этом завершаем работу алгоритма.
Да, не завершаем.
В смысле, у нас есть еще форм数 следующий итерация,
на который мы достаем единицу.
Соответственно, единицу добавляем.
С расстоянию никого нет.
Здесь растояние равно бесконечно,
из нуля до единицы добраться невозможно.
Соответственно, утверждается...
Пока니다 доказано, но я утверждаю,
что данный массив,
то данный массив будет содержать всегда корректные расстояния до всех вершин из вершины 0.
То есть, я утверждаю, что
кратчайшем пути из s до v.
Остались вопросы?
Ну и доказательства корректности. Почему на самом деле вот этот массив,
почему этот алгоритм приводит нас к корректному результату?
Теорема проста. Если ребрографы не отрицательны, то по завершению работы алгоритма
все элементы массива D точно совпадают с длиной кратчайшего пути из вершины s до вершины v.
Ну давайте доказывать.
Ну докажем по индукции.
Ну база индукции простая.
База изначально во множестве s у меня содержится только вершины s.
Ну и соответственно, что я знаю? Я знаю, что D от s равно 0, но это в точности совпадает с process.
То есть изначально во множестве s у меня до всех вершин найдено расстояние корректно.
Теперь переход.
Переход. Пусть для любой вершины v из s верно, что D от v равно process v.
То есть пусть для любой вершины из множества s большого, то есть для любой вершины v
из s верно, что D от v равно process v.
То есть пусть для любой вершины из множества s большого у меня верно все кратчайшие стояния.
Ну и обозначим за u argmin od от x по всем x, не принадлежащим s большого.
То есть на очередную итерацию достаем вершину u.
Теперь докажем, что нам нужно доказать.
Нам нужно доказать, что до этой вершины у нас расстояние найдено корректно.
То есть мы предполагаем, что во множестве s у都 всех вершин найдено корректно.
Давайте теперь предположим, что для вершин вы millenn剛я, великое introdu�� Wort권ка.
Мы тоже нашли на расстоянии коррект ReadyC menstrual per cognizant.
То есть мы эту вершину можно raw fol Raw flay hpleel.
gravy о exile
Ну давайте, собственно, смотреть, что здесь.
Давайте изобразим вот такую картину.
есть вершина С, есть вершина У. Давайте рассмотрим истинный кратчайший путь
из вершины С до вершины У. Вот он выглядит как-то так. То есть мы идем-идем, тут вершина Х, дальше
ребро XY, ну и дальше соответственно каким-то образом, ну не важно, может как-то вот так,
ну в общем случае, как-то вот так находим, доходим до вершины У. Вот пусть это истинный
кратчайший путь до вершины У. Давайте пропишем. Пусть кратчайший путь из С до У
пересекает разрез С В без С по ребру, по ребру XY. Так, ну давайте рассуждать,
давайте, давайте рассуждать, что у нас, что мы знаем? Мы знаем, что,
так, ну давайте так скажем, что у нас D от, что у нас РОСY, так, нет, секунду,
так, во-первых, мы знаем, что D от X точно совпадает с РОСY, так как X лежит во множестве С.
Это первый момент. Далее, далее, что мы знаем? Мы знаем, что соответственно у нас расстояние
D Y, оно, во-первых, меньше либо равно, чем, смотри, когда мы добавляли X, когда мы добавляли X в множество S,
да, мы в том числе обновляли расстояние из X до Y, да, то есть мы писали, мы писали,
D Y равно минимум из D Y и D X плюс, плюс W XY согласно, вот, поэтому расстояние до
вершины Y меньше либо равно, чем D X плюс, соответственно, плюс W XY, соответственно, равно
РОСX плюс W XY, вот, может, давайте. Да, секунду, сейчас, секунду, разберемся.
Да, все, какой вопрос был? Да, соответственно, вот, а что я хочу показать? Я хочу, смотрите,
вот эта штука, вот я утверждаю, что вот эта штука, продолжаем рассуждение, точно равна РОСY. Почему?
Смотрите, D от Y тоже точно не меньше либо равен, чем D от X плюс W XY, согласно. Почему? Потому что
когда я добавлял вершину X, я обновляю расстояние до всех вершин, то есть в том числе до Y я
обновлял, то есть у меня расстояние как минимум вот такое, ну, не более такого, вот, соответственно,
дальше я знаю, что D от X точно все равно РОСX, я писал вот так. А теперь смотрите, что я знаю?
Я знаю, что я рассматриваю кратчайший путь от S до Y, и у меня, соответственно, на этом пути
попадается ребро XY, но согласно, что подпуть кратчайшего пути тоже является кратчайшим путем. Задача,
она оптимальна по подзадачам, да, то есть если я каким-то образом добрался от S до U оптимальным
образом, то это означает, что я до Y тоже добрался оптимальным образом, согласны? Вот, ну, а это,
собственно, означает, что расстояние до вершины Y точно совпадает с РОСХ плюс WXY. Нормально?
То есть вот это понятно, вот это тоже понятно следует вот отсюда. Теперь почему у нас есть вот такой
переход? Ну, почему вот эта штука равна вот этой штуке? Снова, кратчайшее расстояние от S до Y
оно устроено именно вот так, да, потому что это подпуть кратчайшего пути от S до U, поэтому кратчайший
путь от S до Y это кратчайший путь от S до X плюс WXY, то, собственно, тут и написано. Нормально? Вот,
то есть мы пока, да, а в свою очередь вот эта штука меньше равна, чем D от Y,
ну, по очевидным причинам, потому что в D у нас хранится путь, который проходит только по вершинам
из S, а РОСХ это вообще произвольный, точнее не произвольный, а вообще глобальный кратчайший путь.
Ну, понятное дело, что более ограниченный кратчайший путь, он никак не меньше, чем глобальный кратчайший
путь, согласна? Ну, все, то есть отсюда мы получаем, то есть это вот, что у нас было, а отсюда мы получили
логическим образом, что D от Y совпадается РОСХ. Вот. Давайте дальше. Так, это мы знаем,
и это мы знаем. Картинка у нас вот такая. С, Х, вершина У. Ну, а далее рассуждаем,
далее рассуждаем в следующем образе. Вот у меня есть вершина, а вот у меня есть расстояние D от U.
Что я знаю про D от U? Про D от U я знаю, что это меньше чем равно, чем D от Y. Почему это так? Да, потому что
Аргмин. У это как раз такая вершина, которая обладает минимальной дешкой среди всех вершин, которые не
попали во множество S. Поэтому она точно никак не больше, чем D от Y, согласна? Так, а D от Y это у меня...
Нет. Нет, все нормально. Вот. Соответственно, АD от Y я доказал, что это равно РОСY. А РОСY в точности меньше
либо равен... Ну, не в точности, а просто меньше бы равен, чем РОСУ. Потому что путь от S до Y это под
путь, пути от S до U. Согласна? Ну, вот. Давайте поясним каждый. Значит, вот это следует из того, что U это
Аргмин. Дальше. Почему D от Y равно РОСY? Это мы доказали ранее.
Дальше. Почему РОСY меньше равно, чем РОСУ? Потому что SY это под путь SU. Согласна?
А вот это почему? Да, по определению кратчайшего пути. Ну, то есть, какой-то путь не может быть
меньше, чем самый короткий путь. Согласна? Ну, и что получили? U равно РОСУ. Ну, что-то D. Нормально?
Так. Ну, давайте. Ну, вроде не набагали нигде. Ну, короче, давайте еще раз коротко прибежимся.
Доказываем по индукции. База индукции очень простая. У нас изначально в множестве S
всего лишь одна вершина S маленькая. Расстояние до нее мы знаем. Оно равно нулю. Дальше. Предположим,
что пусть теперь у нас есть какое-то множество S. И предположим, что для каждой вершины из
этого множества S мы знаем кратчайший путь. Вот. Соответственно, возьмем вершину U, которая не
лежит в этом множестве, у которой Аргмин по всем D. Вот. Докажем, что до этой вершины мы корректно
нашли путь. То есть мы докажем, что действительно мы обоснуем корректность алгоритма. То есть докажем,
что до вершины U действительно все найдено верно. Ну, значит, предположим, что у нас существует
какой-то кратчайший путь из вершины S до U. И, понятное дело, он в какой-то момент должен пересечь
наш разрез. Должен пересечь, должен выйти из множества S, скажем так, наружу. Вот. Предположим,
он пересекает этот разрез по ребру X, Y. Вот. Соответственно, что мы знаем про вершину Y? Мы
знаем, что D от Y меньше равно, чем D от X плюс WXY, потому что в какой-то момент мы из X
обновляли расстояние до Y и обновляли его вот таким значением. Но, возможно, у нас была какая-то
другая вершина, с помощью которой мы тоже обновляли до Y. Поэтому у нас, как максимум, вот такая вот
длина. Ну окей. Но что мы знаем про X? X лежит в множестве S, поэтому до него мы нашли кратчайший путь
верма. Поэтому D от X равно rho SX. Дальше. Что мы знаем? Мы знаем, что SY это подпуть
пути из S до U. Поэтому путь SX, а дальше Y, соответственно, является кратчайшим путем. Ну все,
соответственно, вот этот путь, rho SX, а дальше WXY, точности равен кратчайшим пути вот S до Y. Ну а кратчайший
путь от S до Y никак не может быть больше, чем какой-либо путь. Ну, не важно какой. Ну все, в итоге пришли
к вот такому соотношению. Вот. Ну а дальше, собственно, написали те же самые, по сути, те же самые неравенства,
но для вершины U. D от U никак не больше, чем D от U. Ну, по определению, так мы U взяли,
как аргумент. Дальше D от Y мы доказали, что равен rho SY, а rho SY никак не больше, чем rho SU.
Ну, а rho SU не больше, чем D от U. Ну все, получили цепочку неравенства, из которой пришли из начала в
конец, то есть, к тому себя. Ну, соответственно, тут везде стоит, значит, тут везде стоит равенство и доказали,
что D от U равно rho SU. Вот. Все понятно? Тогда вопрос вам. А в какой момент мы вообще, ну, смотрите, вот,
утверждение теоремы говорится следующее. Если ребрографы не отрицательные, то все окей. А в какой
момент мы вообще говоря использовали не отрицательность ребр? Предпоследним, то есть, вот здесь. Да.
Вот здесь. Да. Все понятно, почему вот тут мы использовали не отрицательность ребр. То есть, мы на самом
деле, то есть, вот тут мы сказали следующую вещь, что у меня есть путь от S до Y и есть путь от S до U. И
вот этот вот более длинный путь по количеству ребр, он обязательно будет длиннее, чем путь от S до Y. То
есть, вот этот вот путь обязательно будет не отрицательным. И это как раз следует из-за того,
что у меня все ребра не отрицательные. Понятно? Если у меня ребра были отрицательные, то вот
здесь вот я такого не смог утверждать, соответственно, доказать это было бы некорректно. Ну, и вообще говоря,
алгоритм сам был неверным. Понятно? Поэтому в случае отрицательных ребр алгоритм, соответственно,
не работает. Ну, и соответственно, реализация алгоритма Dijkstra, ну, по сути, ничем не отличается
от реализации алгоритма Prima. У нас есть массив dist, в котором у нас все значения равны бесконечности,
кроме элемента, который стоит на позиции S. Ну, дополнительно, можно хранить массив предков,
помните, да, массив предков, чтобы можно было восстановить кратчайший путь. Храним массив предков.
Ну, и соответственно, как мы будем искать минимум? А минимум мы будем искать с помощью пирамиды.
У нас в алгоритме есть поиск аргумина. Давайте искать минимум быстро. Ну, а быстро это, как правило,
пирамида. Соответственно, доведем пирамиду, и в пирамиде будем хранить пару из расстояния до вершины
и саму вершину. Ну, дальше, собственно, все просто. Пока у меня хипа не пустая, пока у меня пирамида
не пустая, я достаю оттуда минимум, то есть беру тот самый аргумин. Ну и, по сути, прохожусь по всем
соседним от вершины и пытаюсь обновить расстояние. То есть если расстояние до вершины u больше,
чем расстояние до вершины v, плюс w в у, то я обновляю расстояние до вершины u. Ну, собственно,
обновление мы показывали. И говорю, что до вершины u, то есть предком вершины u, является вершина v.
Ну и дальше говорю декрит скейдинг. То есть у меня в пирамиде есть ключ, который соответствует
вершине u. Я его изменяю, то есть уменьшаю до такой величины. Ну и так далее и я. Понятно, да?
Есть вопросы? Окей. Ну и, соответственно, ровно как и в алгоритме Прима, соответственно,
сложность этого алгоритма при использовании бинарной пирамиды e log v. Почему? Ну давайте еще раз
проговорим это. Соответственно, общее количество вот этого цикла, общее количество, давайте так,
по порядку. Какое количество раз я достану из хипы, соответственно, вершины? Ну не более в раз,
потому что, не более в раз, потому что, соответственно, ну когда я дошел, когда я нашел кратчащий
состояние до вершины, мне уже нет смысла его обратно класть в пирамиду. Окей? Вот. То есть
вот этот цикл while выполняется в раз. Дальше. За сколько работает extract min? Extract min работает
за алгоритм. Да, поэтому я получаю v log v. V log v это на Extract min. Вот. А дальше у меня, соответственно,
есть вот такой вот цикл, и вот он суммарно, суммарно, за все циклы while выполняется e или 2e раз,
в зависимости от того, ориентированных граф или нет. Согласно, да? Потому что я для каждой вершины
просматриваю ее соседей. Ну в худшем случае для каждой вершины я просморю всех соседей. Вот. Ну и на
каждой итерации, ну в худшем случае, опять же, я сделаю decrease k. А decrease k тоже делается за
алгоритм v. То есть e на log v это уже decrease. Вот. Да, ну и, соответственно, если я использую
фибоначевую пирамиду, то у меня получается асимптотика e plus v log v. То есть вот этот v log v остается,
а тут будет e, если у меня f hip. Ну потому что decrease k в фибоначевой пирамиде делается за единицу.
Амортизирован. Понятно, да? Вот тут? В общем случае, e log v. Ну, окей, да, можно писать e plus v log v,
но предполагается, что, не знаю, интуитивно предполагается, что в графе ребер, как правило,
больше, чем число вершин. Ну да, можно писать v plus e log v. Ну, на самом деле, да, на самом деле,
тут есть еще один момент. Вообще говоря, тут есть такая история, что вот я сказал, что у вас в хипе
в каждом момент времени больше, чем v вершин. Вот. На самом деле, это не всегда правда, потому что на
самом деле на практике проще, ну смотрите, что нужно делать? Когда вы встречаете очередную вершину,
вам нужно проверить там, а лежит ли она во множестве s или нет. То есть, грубо говоря,
нашли вы до нее кратчайшее расстояние уже или нет. Соответственно, если вы до нее уже нашли кратчайшее
расстояние, то ее добавлять в хипу не имеет смысла. Ну, логично. Но, в принципе, на самом деле,
вы можете это не проверять. То есть, вы можете просто на это добить и просто-напросто добавлять
хипу все то, что вам попадается под руку. Вот. И тогда, соответственно, у вас вы в хипу добавить
максимум e ключей. Вот. И, соответственно, эта точка будет с точностью e логуя. Ну, это уже на семинарах
обсудить, значит, детали реализации. Ну, в общем, грубо говоря, можно, ну, короче говоря, можно не проверять,
там лежит у вас что-то в хипе или нет. То есть, точнее так, вот decrease k делать. Ну, кто на самом деле в
реальности реализовывал decrease k в пирамиде или где-нибудь? decrease k. Ну, decrease k — это неприятная
операция. Вот. Поэтому можно обойтись без decrease k и просто-напросто добавить, ну, в смысле, не делать
decrease k, а можно просто добавить в пирамиду еще одну пару. Ну, уже там обновленный дистат u и u. Понятно, да?
Ну, типа у вас в пирамиде где-то хранится значение 10 и вершина 5. Допустим, до вершины 5 вы нашли
новый кратчайший путь, который равен 8. Предполагается делать так. Давайте просто-напросто
возьмем, добавим пару 8, 5. Вот. А с этой парой ничего делать не будем. Пусть она там лежит,
все равно она будет, но все равно мы ее достанем позже, чем вот эту пару. Согласны? Поэтому вот эта пара нам
ничего не испортит. Понятно, что я пытался сказать? Впрочем, можно забить на decrease k и просто-напросто вместо
вот этого decrease k сделать insert, то есть добавить хипу. И если вы вместо decrease k используете
соответственно insert, то у вас получается так, что у вас максимальный размер хипы равен не v, а e,
поэтому тут yellow v – это честная оценка. Ну, это уже такие практические детали, которые будете
обсуждать на семинарах. Вот. Ну, смотрите, ровно как и с алгоритмом Prima, в алгоритме Dextre можно
вместо пирамиды использовать просто массив. Ну, скажем, ну зачем нам мучиться с пирамидой? Давайте
просто-напросто заведем массив. Ну, в смысле у нас так есть, у нас есть массив. Давайте, собственно,
не будем ничего выдумывать, не будем искать минимум за алгоритмическое время пирамиде, а давайте
просто-напросто возьмем и старым дедовским способом честно будем проходиться по массиву и искать
в нем минимум. Ну, то есть, тут у меня совсем нет хипы, поэтому я просто-напросто храню, ну,
грубо говоря, размер, просто храню в отдельной переменной размер построенного множества s. Дальше
я, у меня есть массив dist, я беру в нем argmin, честный argmin, линейный, за линейное время. Вот. Ну,
и, соответственно, дальше. Почему? Нет, смотрите, аргмин вы в любом случае достанете, если у вас,
ну, в смысле бесконечности, вы в любом случае будете доставать, так или иначе. Ну, это детали
псевдокода, ну, короче, не обязательно граф связный, вот. В смысле, что если вы, ну, то есть,
тут while может заменить на цикл, когда вы ищете минимум, а минимум равен бесконечности. Если минимум
равен бесконечности, то, соответственно, можно завершить работу. То есть, ну, это особо неважно.
Вот. Ну, и да, соответственно, тут мы не используем операцию decrease k, а просто-напросто
сразу, непосредственно, меня обновляем dist в самом массиве. Вот. Ну, и, соответственно, как
обсуждали тоже в прошлый раз, к чему это приводит? Да, у нас аргмин теперь считается дольше. То есть,
раньше он считался dllq суммарно, а теперь он суммарно считается 2 квадрата. Да, потому что,
вообще, так, вообще не перерыв. У нас общее количество итерации while не более чем v, и, собственно,
и, собственно, сам пояс минимум занимает v, поэтому v квадрат. Вот. А тут, с другой стороны,
мы избавляемся от логарифмичности в пользу единицы. Да, поэтому получается просто v квадрат
плюс e. Ну, и ровно как в алгоритме prima мы получаем следующую картину. То в случае разреженного
графа, реализация на бинарной пирамиде работает за v логв, а в случае массива работает за v квадрат.
А в случае плотного графа, бинарная пирамида работает за v квадрат логв, массив работает за v квадрат.
Ну, то есть, получается ситуация, что в зависимости от того, разреженного графа или плотный,
вы должны выбрать там либо реализацию на бинарной пирамиде, либо на массиве. Окей. Вот. Но это тоже
такая вот эта строчка, да. Но это чисто техническая деталь, чтобы в следующий раз я ее не вытащил по аргмину.
То есть, таким образом, я просто ее помечаю, что она лежит во множестве вес, и ее в следующий раз
доставать не нужно. Окей. Вот. Да, но тут, видимо, из-за этого будет баг, да, вот тут. Короче, да,
вот этот пункт надо поменять. То есть, вот этот надо как-то заменить на то, что мы должны игнорировать
элементы, которые лежат в множестве веса. Окей. Все ясно? Ну, тогда перерыв.
Короче, пути при любых обстоятельствах данных, любых графов, неважно, ориентированные,
неориентированные, при этом вне зависимости там от длинных ребер, да, то есть, неважно, целые,
рациональные, хоть какие, в общем, позволяет найти кратчайший путь. И при этом мы с вами поговорили о том,
что в случае разрешенных графов эффективнее всего использовать бинарную пирамиду, в случае плотных
графов эффективнее использовать массив. Вот. Ну, значит, алгоритм Dijkstra, у него есть ограничение,
которое стоит в том, что алгоритм Dijkstra умеет работать только в ситуации, когда ребра не отрицательны.
Давайте поговорим теперь о том, что делать, если у нас есть отрицательные ребра, и вообще в чем там
проблема, да, то есть, почему на самом деле задача поиска кратчайшего пути в графе с отрицательными
ребрами, она, ну, скажем так, значительно сложнее, чем задача поиска кратчайшего пути в графе,
в котором отрицательных ребер нет. Задача поиска... Ну, что значит актуальная? Насколько она актуальная?
Нет, в смысле, что вы имеете в виду под актуальной? В смысле, встречается она на практике или нет?
Нет, на самом деле, на практике, ну, естественно, то есть, как бы, не знаю, можно привести банальные
какой-нибудь игровой примеры, да, то есть, вы можете двигаться, ну, смотрите, у вас есть как бы две
стратегии, да, то есть, вы можете двигаться просто там, бесконечно по пути, то есть, если, опять же,
представить какую-нибудь угонку, типа Formula 1, да, вы можете просто двигаться, и тогда вы просто,
все быстрее и быстрее приближаетесь к цели, да, можете, собственно, какое-то время, условно, остановиться и,
там, не знаю, до заправиться. Отвестного, вот тогда ваши ребра графа, это условно... длина ребра положительная,
если вы там на этом пути что-то теряете, да, теряете, не знаю, какую-то массу, какую-то ценность,
какую-то стоимость, и так далее... а ребра отрицательная, если вы это приобретаете, и, вот, естественно,
вам выгоднее там ходить по отрицательным ребрам в этом случае, чем по положительным. То есть, скажем так,
Тут возникает такая двоярская ситуация. С одной стороны, вам выгоднее как можно быстрее добраться до финиша,
то есть двигаясь по положительным ребрам, а с другой стороны, вы можете двигаться чуть более долго,
в смысле, количеству ребр, но при этом передвигаясь по отрицательным ребрам, и тут уже непонятно,
какая стратегия будет оптимальна. То есть, постановок на самом деле тут масса, нет такого,
что у нас есть только положительные ребра, а отрицательные ребра до практики не имеют смысла.
Нет. Понятно, да? В общем, задача такая. По-прежнему мы пытаемся найти кратчайший путь или кратчайшее
состояние, но при этом снимаем ограничения с того, что у нас есть, с того, что у нас только
не отрицательные ребра. Как вы думаете, в чем проблема? Вот просто заменили R+, на R.
Вот, да, смотрите, у нас есть, да, действительно. Давайте подумаем вот о чем. Вот у меня есть какая-то вершина,
соответственно, один, и вот, не знаю, какая-то вот такая вот ситуация. Один.
Чему равен кратчайший путь от S до T? Ну нет, на самом деле его не существует, потому что, как
правило, мы рассматриваем конечные пути, да, ну и в любом случае, как бы, не существует пути,
который каким-то образом доводил вас до T, да, потому что вам выгоднее бесконечно
количество раз бегать вот тут, соответственно, вы до T так, на самом деле, никогда и не доберетесь.
Вот. Поэтому, действительно, в случае, если у вас есть отрицательные ребра, то, вообще говоря,
задача не совсем корректна. В общем, пословка задачи, которую мы ставили исходно, она не совсем
корректна в том смысле, что минимального пути может, в принципе, не существовать, да, то есть вы,
в принципе, не можете предоставить там какой-то путь, который будет обладать тем свойством,
что он меньше любого другого пути, да, то есть задача поиска минимального пути, она становится
некорректной как раз из-за наличия вот таких вот, из таких вот отрицательных циклов. Вот. Окей, значит,
ну смотрите, окей, мы поняли, что в кратчайшей пути вот эта дата не существует, потому что мы тут
можем бегать бесконечно еще раз, постоянно там набивая все более и более короткий путь. Но
можно поставить задачу другую. Давайте поставим такую задачу. Давайте будем искать не просто
кратчайший путь, а будем искать кратчайший простой путь. Ну что такое простой путь? Простой путь – это путь,
который не проходит по циклам. Давайте просто запретим бегать по циклам и скажем, ну давайте
искать минимальный простой путь. Ну согласен, что в этом случае задачи поставлены корректно.
Количество простых путей всегда конечное число в графе, ну в конечном графе всегда количество
простых путей конечное, да, но соответственно в конечном множестве всегда можно найти минимальный
элемент. Прогласны? В чем тут проблема? Проблема заключается в том, что задача поиска простого пути
непосложная. Ну в том смысле, что задача, может, корректно поставлена, но никто не знает,
как ее решать эффективно. К сожалению, задача поиска простого пути, но несмотря на то, что она звучит
проще, то есть найти не произвольный путь, а вот простой путь, но в этой постановке задача
эффективно нерешаемая, давайте так говорить, к сожалению. Поэтому, как ни крути, отрицательные
ребра приводят, не всегда, но правда, отрицательные ребра приводят нас к проблемам. Если у нас есть
отрицательные циклы, то задача либо некорректно поставлена, либо эффективно не решается.
Соответственно, давайте договоримся вот о чем. Когда мы будем говорить про задачу поиска
кратчайших путей в случае отрицательных ребер, мы всегда будем заранее договариваться в том,
что в нашем графе нет отрицательных циклов, потому что если в нашем графе отрицательные циклы есть,
то задача поставлена корректно. Давайте я докажу следующее утверждение, что на самом деле
отрицательные циклы это самое худшее, что может с вами случиться при решении этих задач.
Ну, помимо там CE и так далее. Ну и ML, вот это все заскобки. Вот с алгоритмической точки зрения самое
плохое, что может произойти, это собственно наличие отрицательного цикла. Если отрицательных циклов
нет, то задача вполне себе решается, то есть вполне себе имеет единственное решение. Вот, блин, тут уже
спойлер, ну давайте, ладно, абсолютно. Задача поиска кратчайших путей корректна только тогда,
когда в графе нет циклов отрицательного веса. Ну, значит, в одну сторону понятно, только что я все
проговорил. Т.е. если эта задача корректна, то вAM offered циклов отрицательного веса,
потому что все пути у меня находятся корректно, все пути восстанавливаются однозначно,
но все же означает, что у меня не существует ситуации, при которой я там бесконечно бегаю
по отрицательным циклам. Ну и в обратную сторону значит, если в графе нет циклов отрицательного веса,
то что это означает? Это означает, что у меня в графе любой путь простой, согласны? Ну,
Любой кратчайший путь – это простой путь.
Давайте так предположим, что у меня кратчайший путь в графе не простой, то есть в него он содержит цикл.
Ну а вопрос, а нафига ты содержишь цикл, если он не отрицательный?
Если цикл не отрицательный, то это значит, что он либо положитель, либо нулевой.
В любом случае, от него можно избавиться просто и сделать из него простой путь. Согласны?
Если у вас нет цикла по отрицательному весу, то тогда можно рассматривать только простые пути.
Простые пути – все конечны, то есть их общее количество конечно,
но соответственно в конечном множестве мы всегда можем найти минимум.
Всегда можем предъявить самый кратчайший путь, поэтому задача поставлена корректно.
Понятно? Окей.
Ну и собственно алгоритм, которым мы будем решать задачу поиска кратчайших путей
в случае, если у нас есть отрицательные ребра – это алгоритм Порда Беллмана.
И, к счастью, это, наверное, один из самых простых алгоритмов, который мы будем рассматривать в нашем курсе.
По сути, он состоит из одной процедуры под названием Relax.
Процедура довольно просто устроена.
Допустим, у вас есть вершина В и есть вершина У.
И у вас есть какой-то путь до вершины В и какой-то путь до вершины У.
Это В.
Допустим. Вы нашли какой-то путь до вершины В и какой-то путь до вершины У.
В чем состоит релаксация ребра ВУ?
Релаксация ребра ВУ состоит в том, что мы пытаемся с помощью ребра ВУ
обновить расстояние до вершины У.
То есть, если расстояние до вершины Уbaarше, чем расстояние до вершины В, плюс вот это ребро,
то есть, если вот по этому пути пройти быстрее, чем вот по этому пути,
по этому пути, то мы это ребро, что называется, релаксируем. То есть, что это
означает? Мы обновляем расстояние до вершины u, забываем вот этот путь и говорим, что вот этот путь
теперь тогда от u. Ну и, при необходимости, обновляем предка. Ну, еще заодно, говорим,
возвращаем true или false, если ребро отрелаксировалось или не отрелаксировалось.
Ну, простая процедура. То есть, можем не с помощью этого ребра обновить путь до вершины u.
Окей? Вот. Ну и, соответственно, алгоритм for the blame заключается на следующей идее. Ну, смотрите,
если у нас задача поставлена корректно, то это означает, что если у нас есть кратчайший путь
от вершины s до какой-либо другой вершины, то он состоит не более чем v-1 ребра. А это, собственно,
означает что? Это означает, что мне всего лишь достаточно v-1 раз отрелаксировать все ребра. Ну,
смотрите, вот у меня есть вершина s. Вот у нее есть, допустим, какой-то кратчайший путь до вершины v.
Ну, изначально я не знаю никаких кратчайших путей, и, допустим, у меня все кратчайшие
путей равны бесконечности. Давайте я просто возьму и тупо отрелаксирую все ребра. Ну, просто втыкли
возьму, все ребра пройду и все их отрелаксирую. Что у меня получится? Согласны ли вы, что у меня,
как минимум, обязательно отрелаксируется вот это ребро. Ну, расстояние дает вершину бесконечности,
это ребро, естественно, имеет какую-то конечную длину, поэтому это ребро в любом случае отрелаксируется.
Нормально? Теперь так. Снова возьму все ребра и снова их все прорелаксирую. Ну, согласны,
что на второй итрации у меня обязательно отрелаксируются, ну, не обязательно,
на второй итрации, будет отрелаксирано 1-2-й. То есть до первой вершины я уже
нашел кратчайший пут и, соответственно, на следующей итрации, возможно,
за первые два итрации я найду кратчайший пут до второй вершины, согласны? Ну и так далее.
дальше возьму снова тирелоксирую все
ребра, miles то есть таким образом я гарантирую
что будет от реалоксировано вот это
ребро,
но от реалоксирую все ребра гарантирую что
меня будет отреалоксировано это ребро,
ну и так далее будет от реалоксировано это
ребро соответственно за V- 1
атерацию я гарантирую на 2 крufficient муть
до вершины V. Girls
11
не согласно, observим идеи, понятно?
т.е. так как любой крφ состоит не более
из чем В RE, мне достаточно
просто взять и В¹ раз отреалоксировать
рёбра. В произвольном порядке. Просто релаксирую все рёбра и всё.
Но, собственно, алгоритм как слышится, так и пишется. Весь алгоритм. У нас есть
массив расстояния, дист, массив предков, преф. Дальше в цикле проходим,
заводим цикл на выминус одну итерацию и, собственно, внутри этого цикла
проходим по всем рёбрам и релаксируем каждое ревро. Всё.
Гарантируется, что этот алгоритм найдёт все кратчайшие расстояния. Нормально?
Ну, если сложить этот алгоритм, естественно, v умножить на e. Почему? Потому что внешний цикл
делает по-минус одну итерацию, а внутренний цикл мы проходим по всем рёбрам,
соответственно, e итерацией. Нормально?
Ну и доказательта корректности. Ну, по сути, корректность я уже проговорил.
Если в графе g отсутствует цикл от официального места, то по завершении работы алгоритма
дист от v, то есть расстояние до любой вершины, ну, дист, который я нашёл, в точь
совпадает с истинным кратчайшим расстоянием. Ну, по сути, доказательства я уже
проговорил. То есть, можно разжечь по индукции. То есть, докажем, что после k
итерации, после k итерации и релаксации всех рёбер, мы обязательно найдём дист vk.
Ну, где vk? Это, соответственно, v1, v2, v3, v4, ну, и так далее.
То есть, дист vk – это вершина, которая находится на расстоянии k-рёбер от старта вершины.
Ещё докажем, что, соответственно, я найду корректное расстояние.
На k итерации я найду корректное расстояние. Ну, по индукции рассуждать очень просто.
То есть, на нулевой итерации у меня, корректно, найден путь до вершины s.
Соответственно, так как я на нулевой итерации нашёл корректный путь до вершины s,
то после первой итерации я корректно иду путь до вершины v1. Почему?
Потому что, так как я релаксирую все рёбра, то это ребро я тоже гарантированно отрелаксирую.
Согласны? То есть, после первой итерации у меня кратчайшее расстояние до вершины v1 будет
корректно найдено. Ну, и по индукции и дальше. Вот, допустим, у меня найден кратчайший путь до вершины vk-1.
Так как до вершины vk я нашёл кратчайший путь, корректно, по предположению индукции, то на следующий трат,
когда я буду релаксировать все рёбра, вот это ребро мне тоже гарантированно будет отрелаксировано.
Ну, в смысле, будет запущена от неё процедура релакс. Вот. Но, соответственно, так как это ребро будет отрелаксировано,
то я и найду кратчайший путь до вершины vk. Несортированно. Смотрите, теорема утверждает, что после k-итерации
я корректно найду путь до каты вершин, до вершин, которые находятся на расстоянии k-рёбер от исходной.
Да какой-то. Смотрите, теорема утверждает, что я обязательно после k-итерации найду корректный путь до любой вершины,
которая находится на расстоянии k. Но, как вы правильно заметили, мне может повести,
представьте себе, что у меня снова такая картина. Давайте заново перельцую.
Смотрите, мне может теоретически повести так, что я буду релаксировать рёбра в строгом таком порядке.
Сначала отрелаксирую вот это ребро, потом вот это ребро, потом вот это, потом вот это, потом вот это и хоп,
за одну итерацию я нашел все кратчайшие пути. Но теорема утверждает, что в худшем случае
за v-одно итерацию я гарантированно всё найду. Понятно? Т.е. это лучший случай.
В лучшем случае действительно я за одну итерацию уже всё найду. Но в худшем случае, какой у меня худший случай?
Если, допустим, у меня ребра отформированы так, что я всегда релаксирую в обратном порядке,
вот это ребро не откину. Давайте. Бесконечность, бесконечность. Что у меня произойдет?
Попытаюсь отрелаксировать это ребро. Не релаксируется, не релаксируется, не релаксируется, не релаксируется.
Вот это релаксируется. То есть тут, не знаю, хоть D1. Дальше. Снова иду в обратном порядке.
Нет, нет, нет, да. Ну и так далее. Понятно.
То есть в худшем случае я буду продвигаться только на одно ребро вперед.
Но не хуже. То есть я в любом случае всегда хотя бы на одно ребро вперед двигаюсь,
потому что я все ребра в любом случае отрелаксирую. Понятно?
Поэтому да. В худшем случае это когда я сделаю V-итерации, но, в принципе, возможность ситуации, при которой,
ну, может, так повезет, что вот я за одну итерацию сразу все нашел. Но это вряд ли. Нормально?
Окей. Ну вот, по сути, корректность алгоритма и вот, вот сам алгоритм.
Обсуждать, я думаю, в нем больше нечего. Давайте обсудим другую постать этого.
Что? Сейчас мы об этом поговорим. У меня будут слайды про эффективность, но, к сожалению, асимпатически нет.
С точки зрения константа и так далее можно придумать что-то лучше.
Асимпатически, к сожалению, я, кстати, давно этим вопросом не интересовался, но, по крайней мере,
на момент, год назад или два назад, в общем, не было. Асимпатически, по крайней мере.
Вот смотрите, мы с вами говорили о том, что алгоритм Порда Белмана работает корректно в том и только в том случае,
если у вас нет циклов отрицательного веса.
Но не все задачи устроены так, что они гарантируют вам отсутствие циклов отрицательного веса.
Представьте, вам дается произвольный град, и вам, собственно, нужно на нем найти кратчайший путь,
либо сообщать о том, что кратчайший путь найти невозможно.
По сути, задача сводится к тому, чтобы сначала определить, если у вас цикл отрицательного веса,
а потом запустить какой-то алгоритм. Ну или, наоборот, в процессе работы алгоритма
как-то определить наличие отрицательного цикла.
Вопрос вам, как вы думаете, может ли как-то в процессе работы алгоритма Порда Белмана
определить наличие или отсутствие цикла отрицательного веса?
План нормальный, но, мне кажется, есть небольшой изъян.
Давайте рассмотрим вот такой цикл.
Допустим, 1, 1, 1, минус 10.
На первой итерации я отрелаксирую вот это ребро.
На второй итерации я отрелаксирую вот это ребро.
На третьей итерации я отрелаксирую вот это ребро.
А так как я делаю В-1 итерацию, то до этого ребра у меня дела вообще не дойдет.
Понятно, что я имею в виду.
То есть вроде как цикл отрицательного веса есть, но так как я делаю всего 3 итерации,
то, соответственно, ребро отрицательного веса до него может в очередь даже не дойти.
Есть еще предложение?
Смотрите, можно на самом деле воспользоваться просто доказательством той теоремы.
Что нам теорема утверждала?
Теорема утверждала следующее, что если у нас задача поставлена корректно,
то алгоритм все корректно найдет.
И что из этого следует?
Как вы думаете, алгоритм как работает?
Я делаю В-1 итерацию, релаксирую все ребра и на этом завершаю работу.
А как вы думаете, что произойдет, если, скажем, я релаксирую чуть дольше,
как и в жизни, то если я сделаю процедуру релакс еще несколько раз?
Если мы точно знаем, что за В-1 итерацию мы находим все корректно,
то следующие итерации ничего нового мне не должны дать, согласны?
Какая разница? Я сделаю В-1 итерацию, В-2 итерацию, ничего мне не изменится.
Я уже нашел все кратчайшие пути, у меня граф стабилизировался,
больше ничего более короткого найти нельзя.
Но если у меня есть циклы отрицательного веса,
как вы думаете, будет ли что-то меняться или нет?
Скорее всего, будет, и это является примером.
Я сделал три итерации, вроде как на этом алгоритм завершился.
А если я уже сделаю еще одну итерацию, то тут уже возникнет проблема.
Я найду еще более короткий путь, хотя мне теорема утверждала,
что за В-1 итерацию я все найду.
Идея краски заключается в том, чтобы просто выполнить
еще одну итерацию релаксации всех ребер.
То есть, вот это обычный Форд Белман.
То есть, мы В-1 шаг, релаксируем все ребра.
А после того, как мы все ребра отрелаксировали В-1 раз,
выполним еще один раз процедуру релаксации всех ребер.
И вот если на этой дополнительной итерации у нас хотя бы одно ребро релаксируется,
то значит у нас есть цикл отрицательного веса.
Если нет, то нет.
Идея понятна?
Это мысль довольно неочевидна.
Оно вроде как звучит разумно, но и не очевидно.
Если у меня есть цикл отрицательного веса,
то на этой итерации у меня обязательно что-то пререлаксируется
И наоборот.
То есть, верно ли ut если что-то прелаксировалось,
то у меня есть обязательно цикл отрицательного веса.
57
Это надо доказывать, чем мы сейчас займемся.
Алгоритм корректно определяет наличие отсутствия цикла отрицательного веса,
Ну, алгоритм выше. Давайте доказывать.
Ну, давайте так. Первый шаг.
Если отрицательного цикла нет,
то у теориями 1
после v-1 итерации
все пути,
все кратчайшие пути
найдены.
И дальнейшие итерации
ничего не изменят.
Ну, это следует просто на практике скорректности алгоритма.
Да, что если у меня нет циклов отрицательного веса, то, соответственно,
за v-1 итерацию я все найду, но дальнейшие итерации мне ничего не дадут.
Ну, самое интересное, это второй пункт, что если у меня есть цикл отрицательного веса?
Если есть цикл отрицательного веса.
Вообще говоря, не очевидно, что если у меня есть цикл отрицательного веса,
почему именно на бета итерации у меня обязательно что-то прелаксируется, согласны?
Ну, давайте я это докажу. Вот рассмотрим его.
Ну, пусть от цикл v-1, v-2 и т.д.
vk.
И допустим,
допустим, не случилось
ни одной релаксации.
Допустим, не случилось ни одной релаксации. Что это означает?
Вот, то есть, д v2 меньше
либо равно, чем d v1 плюс w v1 v2,
то есть, я реалксировал в это ребро, но оно не было отреалксировано.
Дальше, d v3 меньше либо равно, чем d v2
плюс w v2 v3,
То есть я релаксировал вот это ребро, и оно тоже не было отрелаксировано.
Ну и так далее есть для всех ребров, запишу.
Значит, в конце у меня будет вот это последнее ребро.
То есть dv1 меньше равно, чем dvk
плюс wvkv1.
Согласны?
То есть если у меня не случилась ни одной релаксации,
то это означает, что эти ребра тоже не были релаксированы.
А они не были релаксированы, так как у меня выполняются вот эти неравенства.
Да?
Окей?
А теперь давайте сделаем следующий вид.
Давайте просто возьмём эти неравенства с ложем.
Окей?
Просумируем.
Не-не-не, просто вот взяли цикл,
мы просто пронумеровали по движению цикла.
Ну а это неважно.
Я же тут не предполагал,
давайте я просто наоборот все эти неравенства переставлю в другом порядке.
Я просто говорю, что для каждого ребра у меня не выполнилось релаксация,
значит для каждого ребра выполнялось такое соотношение.
Что произойдёт, если я всё просуммирую?
Что у меня будет слева?
Сумма всех ДВИ, да?
Сумма по всем вершинам.
Вот из этого цикла.
Сумма
ДВИ
ну и от изницы до ка.
Ну а неравенство сохраняется.
А что будет справа?
Та же самая сумма ДВИ, да?
И сумма всех ребр.
Ну сумма весов всех ребр.
Та же самая сумма
ДВИ
плюс сумма
ВИ
ВИ
ВИ плюс 1.
Ну понятно,
предполагаем, что давайте напишем, что
ВК плюс 1
предполагаем равным В1.
Так.
И что дальше делаем?
Ну шлёп-шлёп, да, вот.
Это сокращается, это сокращается.
Получаем ноль. Меньше равно, чем сумма
ВВ, ВИ
ВИ плюс 1.
О!
А что такое?
Да, вы же предположили,
что есть цикл отрицательного веса.
Более того, вот он.
Мы сказали, бот — это цикл отрицательного веса.
Давайте мы его рассмотрим.
Предположили, что не случилось ни одной релаксации
и доказали, что на самом деле цикл отрицательного веса
ни фига не цикл отрицательного веса.
Понятно?
Ну всё.
Говорить же
Ну, следовательно, соответственно, хотя бы одна
релаксация обязательно должна
случиться. Понятно?
Ну всё.
Соответственно,
корректность обосновали.
Вопросы?
Так, что у нас по времени?
Так, есть ли вопросы?
Окей, тогда давайте
давайте, давайте, давайте
посмотрим ещё
кое-что.
Значит, вот тут задавали вопрос про то,
а можно ли лучше?
Вот у нас есть алгоритм Форда Белмана,
ну или Белмана Форда,
который работает за ВАЕ.
Можно ли лучше?
Опять же, как я уже сказал, лучше можно,
но как бы
улучшения касаются только, скажем,
каких-то эвристик или улучшений
в какое-то константное количество раз.
Вот давайте их обсудим,
если всё успеем.
Значит, есть?
Соответственно,
алгоритм под названием
Shortest Faster Algorithm,
то есть SPFA, ну или под названием
более известный как SPFA,
это алгоритм, который основан на алгоритме
Белмана Форда, но
добавляет просто некоторую эвристику,
некоторые улучшения.
Ну смотрите, в чём проблема?
Тут же всё написано, в общем, согласитесь,
что мы, когда релаксируем все ребра,
мы довольно часто
выполняем действия впустую.
Ну то есть, на самом деле у нас,
если посмотреть на то, как работает алгоритм
форда Белмана, вообще говоря, у нас очень часто возникает
такая ситуация, что мы делаем бесполезную
релаксацию. Но бесполезная в том смысле, что
релаксация не успешная.
Ну действительно, смотрите, в чём соль.
Вот, было у меня ребро ВУ.
И соответственно, в какой-то итерации
я попытался отрелаксировать ребро ВУ.
Ну, релаксация была неуспешной.
Допустим, мы перешли на следующую итерацию,
но при этом мы знаем следующую вещь.
Допустим, мы знаем, что расстояние до вершины В
никак не изменилось.
Вопрос, имеет ли смысл
снова делать релаксацию ребра ВУ?
Ну нет, да, почему? Потому что
на предыдущей итерации я написал
то ДУ, ну это минимум,
из ДУ
и D от В
плюс
ДУ.
Вот.
То есть на предыдущей итерации я это уже отрелаксировал.
Вот.
А если, если у меня в течение этой итерации
расстояние до вершины В не изменилось,
то и вот эта штука тоже не могла измениться.
Да, соответственно,
релаксировать с этим ребром не имеет никакого смысла. Согласны?
Поэтому издевать довольно естественная идея.
А давайте релаксировать только те ребра,
которые торчат из вершин,
расстояние до которых реально поменялось.
Потому что если расстояние до вершин не поменялось,
то релаксировать из него я тоже ничего не смогу.
Окей?
Собственно, вот в этом и заключается
идея алгоритма СПФ.
И на самом деле алгоритм СПФ внезапно очень похож на алгоритм BFS.
По сути, он его повторяет.
То есть у меня есть массив расстояния,
есть массив предков,
и есть некоторая очередь.
Очередь вершин, до расстояния которых у меня поменялось.
Вот.
Соответственно, я пишу,
что пока у меня очередь не опустела,
я достаю вершину из очереди,
и отрелаксирую ее соседям.
Если, соответственно, у меня удалось отрелаксировать ребро ВУ,
то я добавляю вершину У в очередь.
Но почему я ее добавляю в очередь?
Потому что я говорю, что расстояние до вершины У у меня изменилось.
Соответственно, теоретически из нее я смогу еще что-то прелаксировать.
Понятно?
Ну, на самом деле...
Ну, на самом деле нет.
Наверное.
Ну, кажется, нет.
Да.
Хотя, стойте.
Ну, в общем, надо подумать.
Я могу пояснить, почему работает алгоритм с очередью.
Потому что мы таким образом моделируем
основной алгоритм Форда Белмана.
Потому что если мы релаксируем все ребра,
то у меня изначально в очереди находятся
только те вершины, до которых я...
В общем, такая ситуация.
Вершина С, из нее торчат какие-то ребра.
И вот что обычный Форд Белман
с алгоритмом СПФ
обновит расстояние вот до этих вершин.
Понятно?
На следующей трассе я возьму вот эти вершины
и, соответственно, с помощью них буду обновлять
другие расстояния.
Естественно, что алгоритм СПФ, что алгоритм Форда Белмана
тоже по сути построит вот такие вот
новые вершины и так далее.
Вот.
Что Испорт действительно использует вместо очереди С
так я не могу, но кажется, что все будет нормально.
Этот вопрос можно поисследовать.
Ну, в целом, понятно, да?
Идея.
Ну, смотрите, в общем случае
асимптотика также остается от В плюс Е.
То есть, опять же, в худшем случае у меня будет
В итерация.
На каждой итерации в худшем случае я сделаю
е-релаксации.
Ну, на практике на случайных графах работает быстрее.
На случайных графах в среднем работает
за от Е, то есть, за ней на от количества ребер
время.
Окей, да?
То есть, алгоритм СПФ
полностью эквалиден алгоритмом Форда Белмана
с в среднем чуть более
лучшей, ну как,
случайных графов с лучшей асимптотикой.
Ну, а в случае там обычно графов
в среднем константа чуть более
приятная. Вот.
Да, вот тут, кстати,
не понятно, как проверять наличие такого
веса, но тут на самом деле можно
просто хранить
для каждой вершины
хранить количество раз
сколько раз я обновил расстояние до этой вершины.
Как только я превысил какой-то определенный
порог, то есть, я понимаю, что
до вершины я не могу обновить расстояние больше
определенного количества раз.
Можно считать по количеству итераций.
Смотрите, я точно знаю, что
в худшем случае
в корректном
корректном алгоритме
у меня будет не более чем
v-1 на e итерация, v-1 на e релактация.
Ну, согласна.
Соответственно, если как только у меня появляется v-1
умножить на e плюс первая итерация,
то это значит, что все, я точно куда-то не туда поехал.
Так. Но остальные улучшения
давайте поговорим в следующий раз,
начнем с них. Перерыв.
