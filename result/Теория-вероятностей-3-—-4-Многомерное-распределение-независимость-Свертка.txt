У нас сегодня будет две лекции. Одна сейчас, вторая в 3.30, кажется. После этой лекции сделаю
ссылку сразу на вторую лекцию, пришлю, чтобы она была заранее. Прошу прощения,
что я протормозил с первой. И уже со следующего раза в аудитории, видимо,
если ничего не произойдет экстравзионарного. На чем мы с вами в прошлый раз остановились? Мы
говорили про многомерное распределение. Я только начали говорить. Что я сказал? Я сказал,
что такое функция распределения и сказал, что если есть функция распределения, то по ней
однозначным образом восстанавливается распределение целиком. Теперь давайте по
аналогичному плану как-то было в одномерном случае поговорим про свойства функции многомерного
распределения. Свойств тоже три. Они аналогичны, но в силу специфики многомерной они немного
отличаются. Во-первых, было свойство неубывания. Как свойство неубывания будет выглядеть в многомерном
случае? Но откуда бралось у нас неубывание? Мы говорили, что возьмем вычтемость функции
распределения в точке B, функции распределения в точке A, и мы получим вероятность отрезка между
аипами. Здесь мы делаем совершенно то же самое, только вместо отрезка мы говорим про параллель
пипи. То есть нам нужно из функции распределения какими-то арифметическими операциями, из ее
значений получить вероятность параллель пипи. Давайте с вершинами определимся. Пусть у нас есть
а1 меньше, чем b1, меньше либо равно, и т.д., ак меньше 0, чем bkt. Следующая должна быть выполнена,
я сейчас напишу и поясню. Дельта 1, 1b1, и т.д., дельт k, ak, bk от f, а у нас n, н-мерная функция.
Давайте будет n-мерная функция. f от x1 до xn не отрицает. Что такое вот эти дельты? Вот это такие
операторы, которые мы будем применять в нашей функции. Значит, дельты it, a it, b it от функции,
давай напишем f маленькая, от x1 до xn. Это есть следующее. Мы берем просто it-ую позицию, вот у
нас аргумент n-мерный, мы берем it-ую позицию, на эту позицию ставим b it и a it и оставляем разность.
То есть это будет следующее. Все аргументы остаются без изменений, кроме it-ого.
На место it-ого аргумента подставляется b it и a it, оставляясь разностью. Но, значит, если применить
по очереди, начиная, скажем, с внутренней операции к внешней операции, применить по очереди вот эти
вот дельты, то мы в результате получим, конечно, некоторую линейную комбинацию. Я здесь написал f
маленькая, а не f большая, потому что каждый раз, когда мы будем применять, у нас функция будет
меняться. Мы сначала к этому аргумент применим. У нас будет, в результате получится разность f от
x1 и так далее bm, минус f от x1 и т.д. И мы уже вот к этой новой функции будем применять дельты
n-1. Получится такая линейная комбинация, и это, значит, несложно видеть, это по индукции,
можно доказать, что это есть не что иное, как как раз вероятность параллепипеда с вершинами вот
в этих точках 1a и 1b. То есть 1a и 1b это левый нижний угол от параллепипеда, 1b это верхний
правый угол, если можно так сказать. Есть какие-то вопросы по первому свойству? Второе свойство.
Есть вопрос? Да. А вот вторая строчка это условие или что? Ну то есть где куча дельт? Смотрите,
вот это определение дельты, да вот это определение операции дельты, а вот это само условие. Само
условие звучит так, что для любых 1 меньше чем b1, tln меньше чем bn выполнено вот это нералист.
А да, понятно. Смотри, где дельта определяется вот таким вот образом. Хорошо, значит, что у нас там
еще было? У нас там была еще непрерывная справа, да, вот, но здесь тоже будет непрерывная справа,
только что мы будем подразумевать под непрерывная справа, мы будем иметь в виду, что любой
последовательности, которая стремится, зафиксируем какую-то точку, мы рассматриваем любую последовательность,
которая стремится справа в том смысле, что все ее координаты должны убывать. Да, то есть давайте
вот так вот напишем, что если у нас есть дваимерных векторов, будем писать, вот у нас есть вектор y,
скажем, y1, ym. Будем писать, что он больше либо равен, чем вектор x, составленный из координат x1, xn.
Если есть координатное неравенство, да, если для всех и, yt больше ночи, чем xt.
Теперь рассмотрим просто любую точку x и последовательности x, которые к этой
точке сходятся вот именно так, что каждый следующий меньше либо ранее, чем предыдущий.
Давайте будем писать следующим образом. У нас есть последовательность xкт векторов,
которая стремится справа, в каком-то смысле, к x. Если для любого k, xk
x1 меньше либо равно, чем xкт, ну и x это предел, x равняется предел при касты
мячностей бесконечности xкт. Вот, значит, рассмотрим последовательность, которую так сходится, и для этой
последовательности должна быть непрерывность. Значит, предел любой последовательности xкт,
который стремится к x справа, предел при касты мячностей бесконечности f от xкт равно f от x.
Есть вопросы? Нет, прекрасно. Третий. Значит, третий, это предел в минус бесконечности и плюс
бесконечности, тоже будет отличие. Отличие будет вот какое. Смотрите, откуда бралось свойство,
что предел в плюс бесконечности равен единице, но оттуда что из непрерывности вероятности меры.
Да, то есть при устремлении xкт плюс бесконечности, куда стремится функция
распределения в точке x, ну она равна просто, устремляется к вероятности объединения всех
тех норгов, так как эти множества, выдающиеся в лучи, они вложены, и все их объединение дает все r,
то в пределе мы получаем единицы. Тоже самое должно произойти в многомерном случае, мы тоже должны
в пределе получить все rm. Но чтобы это сделать, нужно чтобы каждый аргумент, конечно, стремился к
плюс бесконечности. То есть стремление к плюс бесконечности должно быть одновременно по всем
аргументам. Вот, а с минус бесконечности будет по-другому. Значит, что там должно происходить? Мы
должны посмотреть на предел пересечения ложных множеств, и пересечение вот всей этой счетной
последовательности ложных множеств должно быть пустым. Да, это был случай r. И, конечно, это будет,
если просто хотя бы один из аргументов стремится к минус бесконечности, то пересечение всех этих
ложных множеств будет пустым. Поэтому вторая часть этого свойства выглядит так. Любого i предел
при x и том, стремящемся к минус бесконечности f от x1, тогда xm равно 0. Так, есть ли вопросы?
Мы доказывать будем эти свойства? Да, сейчас докажем. Давайте докажем.
Ну, давайте первое свойство докажем, наверное, по индукции, по индукции пока. Первое свойство.
Докажем, что...
Сейчас. Ну, давайте так, с дельта Каттву начнем. И на дельта Энтом закончим.
Ну, то есть самый первый Ка, который надо рассмотреть, это Ка равно n. При Ка равно n мы имеем
просто дельта N aN bN от f от x1 до xn. И по определению это есть просто f от x1 и так далее bN минус f от x1
Ну, значит, что мы делаем? Мы из функции распределения вот в этой точке, то есть из вероятности декартового
произведения вот таких вот лучей от минус бесконечности dx1, от минус бесконечности dx2, от минус бесконечности
bN, мы учитаем вероятность декартового произведения вот лучей, соответствующих вот этим агументам.
И понятно, что внутри этих двух декартовых произведений все лучи будут одинаковы, кроме
последнего. В первом случае будет луч от минус бесконечности dbN, а во-втором случае будет луч
от минус бесконечности daN. Поэтому когда вы вы honorary, в силу аддитивности меры, ну,
короче, вот этот множество, вот этот декартовый произведение в этом влож았�. Поэтому когда мы вычитаем
вероятность, вы получите просто вероятность разности двух этих множеств, ребята, это
будет ничто иное как вероятность декартового произведения всех лучей до n-о 1-го.
и последний луч от аэнтэ до бэнтэ да теперь значит ну предположим что для ка мы доказали
для какого-то ка и попытаемся доказать для ка плюс один то есть для ка минус один
мы в обратную сторону идем то есть мы рассматриваем дельта ка минус один а
сейчас давайте знаете даже я по-другому немного пишу давайте докажем мы не это здесь а докажем
на самом деле вот что докажем что это в точности вероятность декартового произведения лучей
вплоть до ка минус первого то есть прямо явно напишем чему равно это множество чему
равно вероятности чему равно это линейная комбинация функций распределения значение
функции распределения значит это будет первый каменус одна координата дадут просто лучи а
остальные дадут полу интервалы от а до б вот и на самом деле мы действительно для ка равно
мы уже доказали да мы получили в точности вот такую вот вероятность теперь докажем
переход индукции значит для ка доказано это да мы рассматриваем вот такую вот штуку
и значит здесь у нас следующая дельта имеет индекс ка и поэтому начиная со следующей дельты
мы уже умеем поменять их кф мы по индукции знаем что мы должны получить да значит тогда
в силу определения дельта это будет дельта каменус 1 каменус 1 б ка минус 1 примененная к
вот всему что осталось что по индукции по предположения индукции равно просто вероятности
от милых бесконечности дэкс один и так далее от милых бесконечности дэкс каменус один а ка
т б ка т так далее а н т б м т вот ну и теперь по определению дельты мы просто применяем
к этой функции вот у нас есть аргумент да и к каменус каменус 1 когда мы применяем мы получаем
следующее мы получаем f извиняюсь вероятность от того же самого да только на место и к каменус
1 мы подставляем соответственно сначала б ка минус 1
а потом подставляем а ка минус 1 и видим что эти два декарта предведения отличается только
в одной координате и соответственно второе множество просто вложено в первое поэтому
разность их вероятности это точности вероятность разности этих множеств то есть в точности то что
нам нужно было получить данный каменус первом месте стоит интервал от а ка минус 1 дабы ка минус
1 и на всех остальных тоже стоят такие интервалы вот ну все значит по индукции мы действительно
доказали что наша вещь при применении этих дельт откатый до янтый дают такую вероятность а значит
в частности пика равно единица что мы получаем да то есть пика ровно единица это именно тот
номер дельт который нам нужен то есть все дельты от первой до энтой
значит получается просто вероятность некоторого множества дай декарта у произведения лучей
этих интервалов от 1 до б1 так далее м тв м т и она не отрицательно что тревоз если вопросы
можете по-быстрому прокрутить на самый верх на самый верх это вот сюда да все спасибо
так хорошо теперь второе свойство ну здесь уже доказательств не ничем не отличается вот
доказательства свойств для одномерной вероятности давайте быстренько вспомним как мы это делали
значит итак у нас есть последователь скаты который стремится с права к и мы
смотрим на предел приказ стремящимися бесконечности афотекс карты
по определению функции распределения это есть просто вероятность декарта у произведения лучей
от минус бесконечности до x к 1 и так далее от минус бесконечности до x к n эти в силу того
как ведет себя последователь скаты до у нас последовательность мит с права в том смысле
что каждый следующий член последовательсти не превосходит предыдущий это означает что вот эти
все множества не просто вложены друг в друга каждое следующее содержится предыдущим и значит
по теореме непрерывности вероятности меры можем перейти к пределу под вероятностью да то есть
это будет вероятность просто пересечение когда множество так ложно что каждое следующее содержится
предыдущим и говорим про пересечение пересечение по всем к наших лучей ну и в силу сходимости
до сходимость вектов а здесь ничто виноват как сходимость как компонент этого вектора мы
получаем в пределе то есть вероятность всех этих множеств это в точности лучи соответствующей
иксу да то есть это вероятность декарта у произведения лучей от минус бесконечности до x к 1 и
так далее без конечности до x м что есть функции распоряжения в точке икс
точно также в третьем пункте
если все аргументы стремятся к плюс бесконечности
то но опять значит мы пользуемся определением функции распределения да это значит вероятность
такого декарта произведения лучей вот и теперь эти лучи увеличиваются они растут и
значит опять же можно считать да здесь стоит сказать о том что можно считать что
это сходимость что все иксы возрастают то есть можно писать вот так и это будет без ограничения
общности в силу того что есть не обувание функции распределения да то есть вот такой вот
предельный переход когда вы здесь рассматриваете возрастающую последовательность или когда
вы берете произвольную последовательность они равносильны поэтому когда поэтому
вы можете воспользоваться теоремой непрерывности вероятности меры да и перейти к пределу множеств
то есть так как они все будут ложен друг другу каждое следующее содержится предыдущие вы в итоге
получите вероятность объединения этих множеств что есть рм опять же при стремлении хотя бы одной
координате к минус бесконечности по аналогичным причинам вы можете вы можете считать что это
координата просто убывает это будет равносильно рассмотрение любой последовательности в силу
не убывание функ? по аргументно поэтому опять же можно перейти к пределу и
значит когда вы перейдете к пределу вы просто получите де-карту произведения всех лучей вплоть
до и минус первого на месте на месте этого луча будет просто пустое множество в пределе
ну а де-картового произведения с пустым множеством это пустое множество поэтому
это есть вероятность пустого множества что равно 0. есть ли вопросы? а может еще раз повторить
почему можем возрастающую толпу последовательность рассматривать? да, смотрите мы предположим что у нас
есть произвольная последовательность немозрастающой почему мы можем для неё вывод сделать
из того что у нас есть всевозможные возрастающие последовательности? ну что означает что все x
стер DES-конечности? да это значит что начиная с некоторого.. как бы вы не зафиксировали уровень
начиная с некоторого номера, вообще Frog-ексы будут выше этого уровня.
Вы можете выбрать какие-то
уровни, не знаю, единицы, двойка, тройка и так далее,
и рассматривать подпоследовательность. То есть брать не все последовательность
эксов, а первый момент, когда sciences geratum контролирует
вашу последовательность, trustworthy minutenus,
и ты смотришь на первый момент,隱 zwdoor,
а потом смотришь на первый момент, когда части höherа тройки.
то у вас есть какая-то ваша последовательность, которая как-то себя невозрастающе ведет, но стремится к людям бесконечности.
И вы из Тьи вы из неё достанете подпоследовательность, которая возрастает, стремится к людям бесконечности.
Для этой подпоследности у вас есть пределия единицы.
Ну, значит, и для всей последовательности тоже, конечно, в пределе единицы,
конечно, в пределе единицы, потому что, какой бы вы достаточно большую точку вашей последовательности
не взяли, она будет больше какого-то уровня, который вы зафиксировали. И это правда для любого
уровня. То есть для любого уровня вы найдете момент, начиная с которого вообще все точки
выше этого уровня. Поэтому если под последовательность у вас в пределе один, то для всей последовательности
у вас тоже в пределе один. Да, понятно, спасибо. Возможно вы хотите в нижней строчке написать
x и t плюс один справа. Спасибо, очень хочу.
Так, ну хорошо, со свойствами разобрались. Да, теперь давайте, давайте немножко я еще скажу пару
слов о связи между многомерной функцией распределения. А, да, я должен сказать, конечно,
что если есть функция распределения с этими тремя свойствами, то она является функцией
распределения. То есть полностью аналогичная ситуация с одномерным случаем. Значит, если f из Rn в 0.1
обладает свойствами 1,2,3, то найдется распределение вероятности, для которого f это функция распределения.
Да, ну конечно по аналогичным причинам, как и в одномерном случае. То есть у вас тоже есть,
благодаря на самом деле этому первому свойству, благодаря не отрицательности всех таких дельту,
вы можете положить вероятность всех параллепипедов равной вот такой вот величине,
и потом продолжить эту меру на всю сигналы. Но давайте все-таки это оставим без технических
подробностей. И теперь хочется сказать про связь между многомерной функцией распределения
одномерно. Во-первых, вот что. Представьте, что у вас есть функция распределения многомерная,
и у нее есть маргинальные распределения. То есть как будто бы вы можете спроектировать на каждую
из осей. Вот у вас есть функция распределения, скажем, на плоскости, и вы можете сказать,
какая у этой функции распределения проекция, как на ось absys, так и на ось ординат. Как это сделать?
Эти распределения будут называться маргинальными распределениями. Пусть П распределение ВРН,
и возьмем координату, зафиксируем, и от 1 до N. И определим распределение теперь ВР следующим
образом. PIT от B равно просто вероятности декартового произведения R в степени I-1 на B,
на R в степени N-I. То есть вы делаете любого орлевского множества в R. То есть вы берете
просто и смотрите, какое распределение индуцируется именно на IT координате,
на всех остальных позициях вы ставите все действительные числа, и ставите на IT позицию
орлевского множества, и получите на самом деле распределение вероятности ВР. Это будет распределение
вероятностей. Простое упражнение проверить, что это действительно будет распределение вероятностей.
И оно называется маргинальным. Маргинальное распределение вероятностей. Понятно,
что если у вас есть все маргинальные распределения, это еще не значит, что вы знаете,
как устроено ваше распределение целиком. То есть проекции на оси недостаточно для того,
чтобы восстановить распределение. Тем не менее, вы можете, в принципе, если у вас есть маргинальные
распределения, вы можете с помощью них распределение на СМРН задать. Единственным образом,
но вот самый естественный, на первый взгляд, способ, как это можно сделать, он следующий.
Значит, пусть P1, Pn это одномерное распределение. Да, можно просто задать многомерное
распределение P следующим образом. На всех декартовых произведениях баррельских множеств
определим его просто как произведение распределений соответствующих. P1 от B1
умножено тогда на Pn от Bn. Мы получим, конечно, многомерное распределение. То есть оно единственным
образом продолжится на всю сигму. Его задать распределение на декартовых произведениях баррельских
множеств достаточно. Более того, его достаточно задать на декартовых произведениях лучей,
как мы только что выяснили. То есть можно было бы просто сказать, что это верно для лучей. То есть
функцию распределения задать, и функция распределения однозначно сдала бы распределение целиком.
Оно называется декартовым произведением распределений P1 del Pn.
Понятно, что у него функция распределения будет равна произведению функции распределений.
Соответствующих этим распределениям P1 del Pn. И повторюсь, что это не единственный способ задать
распределение, когда у вас маргинально есть. Мы скоро будем говорить про случайные величины,
про случайные векторы, и там будет понятие независимости случайных величин. Вот эта вот
ситуация, когда вы рассматриваете декартовое произведение распределения, она отвечает в случае,
когда случайные величины независимы. Но они могут быть в принципе независимы,
тогда совокупное распределение будет другим. Есть ли какие-то вопросы?
Хорошо, теперь типы распределения. Значит, как и в случае одномерного,
здесь можно говорить про дискретные распределения, и можно говорить про абсолютно
неприятные распределения, и определение абсолютно аналогичное.
Здесь опять есть какое-то множество носитель распределения, которое является не более чем
счётом. И если мы нашли такое множество, что его вероятность пространной единицы,
то распределение называется дискретным. Ну я не буду здесь, наверное, долго об этом говорить,
приводить кучу примеров, потому что на самом деле все важные примеры, мы о них уже сказали,
они получаются из одномерного случая. Вы можете просто брать там какие-нибудь
вернулевские распределения, биномиальные, равномерные по-асоновски, дискретно их перемножать,
ой, прошу прощения, декартовых перемножать, вот как я здесь говорил. Возьмём два, перемножим два
равномерных распределения декартовых, мы получим многомерное равномерное распределение. Но,
значит, что здесь важно подчеркнуть, это то, что по аналогии с одномерным случаем распределение
просто восстанавливается по значениям вероятностей на множестве х. То есть,
здесь на самом деле вы можете просто говорить про какие-то индивидуальные точки, такие атомы
распределения, которые единственным образом все распределение задают, и будет не более,
чем счётное количество. Если множество х конечное, будет конечное количество этих точек,
которых вероятность не ноль, и которые просто целиком сдают всё распределение. А в случае,
если х счётно, то их тоже будет бесконечный счёт. Итак, если мы рассмотрим такую функцию,
х маленькая, которая действует из х большое в 0,1 и ставит х в соответствии значения его
вероятность просто, то тогда эта функция однозначно восстанавливает распределение.
Её ещё называют функцией вероятности, дискретной плотностью, по-разному называют,
но смысл понятия. Смысл в том, что очень удобно искать вероятности, потому что,
очевидно, для любого баррельского множества b, его вероятность – это просто сумма по всем
хам, которые из х большого пересечения с b по x. Давайте назовём дискретной плотностью.
Можно называть её функцией вероятности. Но на самом деле мне больше нравится дискретная плотность,
потому что когда мы говорим про абсолютно непрерывное распределение, говорим про обычную плотность,
то мы имеем в виду, что распределение является абсолютно непрерывной мерой относительно
классической меры하세요 бибибелка. Здесь распределение будет являться абсолютно непрерывной мерой относительно
такой так называемой считающей меры. Это когда вы просто в целых числах, ну в множестве х – если
их не обязаны быть множество целых чисел, вы на множестве их говорите, что мера равна единице на
каждом из элементов множества х, а во всех стыдных местах она ноль, вот это будут считающие меры,
и это дискретное распределение будет абсолютно непрерывно относительно нее, и значит вот эта
дискретная плотность это есть не что иное, как плотность Радонны-Никодима. Плотность Радонны-Никодима
определяется вообще для любых пар абсолютно непрерывных мер, но мы об этом поговорим
еще в курсе чуть позже, я пока просто хочу сказать, что слово плотность здесь на самом деле
существует. Это не просто какая-то видимая аналогия с абсолютно непрерывным случаем,
а аналогия полная. Так, абсолютно непрерывные распределения.
Ну, значит, здесь должна быть просто многомерная плотность. По аналогии с намерным случаем мы делаем
следующее. Мы говорим, что если существует такая функция, p маленькая, которая действует из rn
в r плюс, множество действительно неотрицательных чисел, что любого х из rn, f от x это есть интеграл
от минус бесконечности до x1 и так далее, от минус бесконечности до xn, от плотности
вот этой вот функции, p, то соответствующий этой функции распределение, а распределение
называется абсолютно непрерывным, а p называется его плотностью. Вот, ну и верны все те же самые
утверждения, о которых мы говорили. В намерном случае, значит, во-первых, для любого барреля
его вероятность, это просто интеграл по b от p. Интеграл, конечно, в смысле обычный интеграл
лебедя по классическим лебедям. Во-вторых, что еще? Значит, если p, какая-то функция, которая действует из rn в r плюс,
такова, что интеграл от нее по rn равен единице, то она является плотностью для некоторого
распределения вероятностей. Возьмите просто совершенно любую функцию, не отрицательную интегралу, которая единица, и вы по ней восстановите какой-нибудь распределение вероятностей.
Я здесь не буду подробно останавливаться, здесь все полностью аналогично, в одномерном случае, никакого никаких отличий нет.
Ну и, наконец, можно еще добавить, что если функция f является хорошей, в том смысле она дифференцируема по каждому аргументу,
то распределение вероятностей является абсолютно неправильным, и плотность можно найти как производную по каждому аргументу.
Да, вот такое вот кино. Но опять, если хочется привести какие-то примеры абсолютно непрерывных распределений, можно взять абсолютно непрерывные распределения одномерно и составить из них дикартовое произведение.
Это тоже важный момент, который я сейчас запишу. Значит, если у вас есть одномерные распределения P1, Pn, которые являются абсолютно непрерывными с плотностями P1, Pn,
с плотностями P1, Pn. Так, распределение в одномерном случае, то есть это одномерное распределение.
С плотностями P1 маленькое, это далее Pn маленькое, то дикартовое произведение этих распределений, вот так оно обозначается, является абсолютно непрерывным,
уже многомерным, да, на rn, bt, rn, с плотностью, равной произведению плотностей.
Ну почему так? Ну смотрите, давайте просто проверим, давайте просто проверим, что это так.
Вот возьмем вот эту функцию, обозначенную за P, и увидим, что это действительно будет плотность дикартового произведения наших распределений.
Ну как это увидеть? Надо взять, значит, вот, должен быть выполнен вот это вот определение.
То есть давайте возьмем интеграл, который написан справа, и посмотрим просто, чему рано.
Интеграл от минус бесконечности dx1, и так далее, от минус бесконечности dxn, наши вот функции P, которые мы определили.
Ну раз она распадается в произведение плотностей, и тем самым все аргументы разделяются, то это будет произведение интегралов.
Это будет вот такое вот произведение интегралов.
И так как P1, P2 на этой плотности, то каждая из этих интегралов, это просто соответствующая функция распределения в соответствующей точке.
Что и требовалось. Да, это действительно определение, функция распределения дикартового произведения.
Есть ли вопросы?
Если вопросов нет, то давайте...
У вас там единственная маленькая описка, в том, где плотность выражаете через производную, там последняя у вас D, прямая вместо загнутой.
Это почему-то похоже на F, а не на T. Сейчас исправим все.
Так лучше.
Так, ну хорошо. В общем, вот это все, что я хотел сказать по многомерным распределениям.
Мы с вами можем двигаться дальше, наконец-то, и перейти к случайным величинам, случайным векторам.
Семинар, который уже давно сделан, но еще мы догоним.
Давайте немного порассуждаем на тему того, что такое случайное величине, случайный вектор, какие-то случайные объекты.
Мы не обязаны говорить на самом деле про числовую случайность.
У нас случайность может быть и на каких-то других множествах.
Например, бывают случайные графы, случайные матрицы, много всего разного случайного бывает.
Но смысл вот какой. Давайте поговорим про случайные величины.
Мы имеем в виду случайность на множестве действительных чисел, и неспроста мы перед этим говорили про распределение.
Сейчас верну экран.
Вот когда мы говорим про какой-то эксперимент в физике или еще где-нибудь, который связан с некоторыми числовыми характеристиками.
Мы можем измерить температуру в данный момент времени, мы получим какое-то число.
Потом мы измерим в другой момент времени, температуру изменится.
То есть это вот изменение этой температуры, это некоторые случайные процессы.
Мы можем в разные моменты времени просто посмотреть, как реализуется этот случайный процесс.
На эти случайные процессы как можно смотреть в терминах нашей аксиоматики вероятности?
Да, я напомню, что у нас есть вероятностное пространство, которое состоит из множества элементарных исходов.
И на нем зная вероятность.
Думайте об этом вероятностном пространстве, как о некотором хаосе, который следит по основе вещей, по основе случайности.
В принципе, у того факта, что температура равна 10-15 градусов или еще сколько-то, есть какие-то причины.
Да, это на самом деле не просто так. В природе что-то происходит, какие-то процессы происходят.
Именно из-за них, как функция всех этих факторов, температура будет равна 10-15 градусам.
Соответственно, вы можете думать про вот эту всю совокупность факторов, которые влияют на те или иные измеряемые вами величины, как про вероятностное пространство.
Вот случился такой расклад, вот такая температура, случился какой-то другой расклад, какая-то другая температура.
И вот после этой мысли, кажется, естественно, смотреть на случайную величину как на функцию от элементарного исхода.
То есть тому или иному элементарному исходу вы ставите соответствие числу.
Мы с вами так и сделаем.
Значит, случайная величина.
Ну, давайте начнем с общей ситуации.
Как я уже сказал, нам не обязательно говорить, что случайность у нас будет во множестве действительных чисел, да, может быть, где угодно.
Поэтому давайте считать, что есть помимо нашего вероятного пространства мега ФП.
Мы будем говорить еще про некоторое измеримое пространство Есигма.
Ну, измеримое в том смысле, что просто Сигма – это сигнал-агиталоник.
То есть есть некоторое множество, есть система измеримых множеств.
Зачем нам нужно второе измеримое пространство?
Ну, вот как раз для того, чтобы случайность из вероятностного пространства перенести на него.
То есть мы вот, например, будем сейчас говорить о том, что мы можем измерить второе измеримое пространство.
Когда мы там думаем про температуру, нам, в принципе, не очень уместно думать в терминах, какая вероятность, что температура там ровно 10 градусов.
Мы когда строим прогнозы, мы всегда хотим какой-то, конечно, маленький иметь интервал, но вероятность попадания в этот интервал большой.
То есть мы хотим сделать какой-то прогноз в духе пространства.
Вероятность того, что температура будет в интервале от 9,5 до 10,2 градусов, равна 0,98.
То есть мы тем самым хотим измерять вероятность событий, которые будут связаны с действительными числами.
Ну или если это какие-нибудь случайные графы или какие-то случайные матрицы, то это будут события, которые ассоцииированы соответственно с графами или смартфонами.
То есть у вас есть некоторое множество, на нем знана некоторая сим-алгебра, и вы хотите вот эту вероятность, ее перейти сюда, чтобы уметь измерять события из сим-а, то есть элементы сим-а.
Рассмотрим функцию х, которая действует изомегаве, которая является измеримой.
Ф-палочка сигма-измеримый. Там называется случайным элементом.
Я напомню, что значит ф-палочка сигма-измеримая. Это просто означает, что для любого b из сигма его прообраз полный принжет f.
Ну и понятно, конечно, зачем это условие нужно, оно нужно для того, чтобы вы могли говорить про вероятность попадения в любое измеримое множество.
То есть, коль скоро у вас есть такое определение, вы можете сказать оно окей, тогда, когда я пишу вероятность того, что х помежит множество b, я имею в виду не что иное, как вероятность, что х помежит множество b,
что х помежит множество b, я имею в виду не что иное, как вероятность множества тех омега, которые по действиям х перешли в b.
То есть, это есть как раз полный прообраз множества b, который лежит в f, как мы знаем, а раз он лежит в f, мы можем померить его вероятность.
И поэтому вот эта штука, это событие, от него можно найти вероятность, и для удобства его обозначают вот так, чтобы не писать вот эти фигурные скобочки омеги.
Зачем об этом думать? Можно писать просто вот так. А еще можно записать вот так, psnxmx от b.
Что это будет значить? Это будет значить, что вы на самом деле с помощью вашего случайного элемента х можете уже забыть про то, что у вас там было какое-то вероятное пространство, у вас теперь вероятность здесь.
И вот эта вот px, это вероятностная мера, уже заданная на измеримом пространстве e sigma.
Несложно видеть, что px, это вероятность на e sigma, и она называется распределением вероятностей случайного элемента х.
И вот это вероятность, которая еще раз каждому множеству измеримого e sigma ставит в соответствие просто изначальная вероятность, исходная вероятность p, его правообразы.
И, значит, эта мера, она оказывается, является вероятностью меры и называется распределением вероятностей х. Есть какие-то вопросы?
Значит в частности,
называется усилием вероятностей X. Есть какие-то вопросы?
Значит, в частности,
если E это R,
а sigma это баррельская сигнал URW, то X называется случайной величиной.
Но я бы сказал, что в англоязычной лизературе вообще часто случайно величиной подразумевают случайный элемент,
то есть не различают и говорят, что не важно число, это граф или матрица, будем называть random variable.
Но в русской языческой лизературе, как правило, когда мы говорим с членами, мы имеем в виду именно вот эту функцию,
которая применяется в члене ver, и мы с вами ее так и будем считать для удобства.
Все это понятно, просто вопрос терминологии.
Значит, если же E это Rn,
sigma это, соответственно, баррельская сигнал URW Rn, то X называется случайным вектором.
Давайте поговорим про какие-то важные свойства случайных величин и случайных векторов.
Ну, во-первых, давайте критерии измеримости, о котором поговорили наверняка с Иваном Емельевичем, поэтому просто напомню.
Значит, вот это свойство измеримости, которое лежит в определении случайного элемента, его можно ослабить.
Оно останется от этого.
Что я имею в виду?
все возможное множество из сигма, проверять то, что их прообразы лежат в веб,
достаточно смотреть какую-то образующую систему. Если есть какая-то система множеств m в сигма,
такая, что наименьшая сигма алгебра, которая содержит m, просто сигма совпадает?
Да, например, когда мы говорим про баррельские множества, но возьмем множество интервалов,
или множество лучей, они, как известно, порождают всю сигму алгеброна, то тогда
когда функция x является f сигма измеримой, тогда и только тогда, когда свойство измеримости справедливо
не для всего сигма, а достаточно только для m, то есть любого множества b из m, x-1 от b,
нж-дэф. Насколько понимаю, вы с Ваном Генриховичу это обсуждали, доказательства не сложные,
но я его опущу, если есть вопросы. Так, хорошо, значит, еще один важный момент.
Еще один важный момент. Можно посмотреть на, нам это понадобится очень сильно, когда мы будем
говорить про условные математические ожидания, сразу это здесь скажу, значит, когда мы рассматриваем
события, порожденные случайной величиной. Что это значит? Вот рассмотрим такое множество событий
f сигма. Так, у нас случайный вектор, случайный элемент, давайте будем вытяжить их. f с индексом x.
Значит, вот это сигма алгебра, которая порождена случайным элементом x. Что это такое? Это есть
просто множество всех прообразов, множество всех прообразов, всех множеств из сигма. Вот утверждается,
что это сигма алгебра. Ну, давайте проверим, это тоже очень простое упражнение. Воспринимать это,
важно очень понимать, что это такое, вот эту вещь нужно воспринимать как все события,
которые соответствуют вашему случайному объекту. Какие-то события могут не иметь никакого
отношения к вашему случайному объекту. У вас масса разных факторов в мире, которые на те или иные
процессы влияют. На температуру влияют только некоторые из них. Эта вся совокупность процессов,
которые имеют отношение к температуре, они образуют сигму алгебру, порожденную вашей температурой.
Почему это сигма алгебра? Ну, во-первых, x-1 от всего e, это конечно все омега. Поэтому омега принадлежит
нашего множества fx. Во-вторых, надо проверить, что дополнение принадлежит. То есть, если возьмем
какой-то элемент из нашего fx, а его обозначим. Почему x-1 от e равно омега? Потому что x большое
это функция, которая действует из-за мега ве. Поэтому к каждому элементу из-за мега мы поставили
соответственно этот элемент. Поэтому полный прообраз всех элементов из-за е это все омега.
Если a принадлежит fx, то по определению fx найдется такое множество из сигмы,
что это его прогресс от точности a. Возьмем тогда дополнение к этому множеству. Мы знаем,
что дополнение к множеству b, так как сигма это сигма алгебра, дополнение к множеству b тоже принадлежит
сигму. А значит, x-1 от дополнения к b должно принадлежать fx. Потому что fx принадлежат
вообще все прообразы, в частности это. Но прообраз дополнения это дополнение к прообразу. То есть,
x-1 от b с чертой это в точности дополнение к x-1 от b, что есть дополнение к a. А значит,
дополнение k принадлежит fx, что и требуется. Ну и со счетным объединением тоже, конечно,
все просто. Если у вас есть счетный набор множеств, то найдутся их образы, найдутся
b1, b2 и так далее из сигма. Такие, что их прообразы это соответствующие a. Ну и дальше мы что говорим?
Мы говорим, ну хорошо, давайте объединим наши аиты. Это будет не что иное, как x-1 от объединения
быитых. Раз все быиты принадлежат сигма, то в частности их объединение, так как сигма это
сигма, а у евро тоже принадлежит сигма. Значит, по определению fx прообраз этого объединения принадлежит
сигма. Господи, принадлежит f, что и требовалось. Есть какие-то вопросы.
Теперь еще важный объект, бареллевская функция. Ну вы знаете прекрасно, что это такое, я напомню.
Значит, функция f из rn в rk называется бареллевской,
если прообраз у всех бареллевских множеств является бареллевскими множествами.
То есть она просто измерима относительно двух бареллевских сигмал. f-1 от b принадлежит бареллевскому
сигму rn. Значит, очевидно, что если у вас есть случайный вектор, и вы примените к нему бареллевскую
функцию, то вы снова получите случайный вектор. На самом деле это в каком смысле равносильные вещи?
Я это утверждение тоже оставлю без доказательства. Значит, в каком смысле равносильные? В том смысле,
что пусть у вас есть, сейчас, пусть есть кси-энмерный случайный вектор,
а это, ну это какая-то пусть функция, которая действует из омега rk.
Тогда это является f-кси-измеримым случайным вектором. Тогда и только тогда,
когда существует бареллевская функция f, которая действует из rn-vrk, такая, что это равняется f от кси.
Ну, в одну сторону это очевидно, в другую сторону не очень. Давайте я в очевидную
сторону быстро поясню, почему это так. Значит, понятно, что если это бареллевская функция от кси,
то тогда верно, что это f-кси-измеримый случайный вектор. То есть справа налево легко можно доказать.
Значит, смотрите, что нам нужно проверить? Нам нужно проверить определение f-кси-измеримости.
То есть нам нужно проверить, что для любого бареллевского множества, в данном случае,
f-кси-измеримости из rk, ее прообраз принадлежит f-кси. Ну, вот возьмем произвольное бареллевское множество из rk
и посмотрим на это в минус первое от b. Мы предположили, что это, это есть бареллевская функция f от кси.
Да, и мы, значит, эту штуку убьем в минус первую степень и применяем в b.
Да, значит, что это значит? Это значит, что мы сначала применяем f-1 к b, а потом к этому мы применяем кси в минус 1.
Но f – бареллевская функция, а b – бареллевское множество. Это значит, что f-1 от b – это бареллевское множество, но из rm.
А так как кси – это случайный вектор, то по определению f-кси эта штука должна ему принадлежать.
Что ей требовалось? Да, то есть в одну сторону понятно, в другую сторону я опущу, но это некоторая, да,
это некоторая на самом деле задачка предъявить эту бареллевскую функцию по имеющимся случайным векторам кси.
И это, если Иван Геннадьевич не рассказывал, но может попробовать сами доказать.
Время хоть это занимает, я от лекции не очень хочу вынимать все-таки эту вещь из теории функций, а не из теории вероятности непосредственно.
Есть ли какие-то вопросы? Что означает f-кси измеримый случайный вектор?
А, ну это как f-измеримый случайный вектор, да, то есть мы здесь вместо множества событий f рассматриваем множество событий f-кси.
Ну то есть я имею в виду обычное определение измеримости.
Ну да, понятно, спасибо.
Да, на всякий случай напишу, раз возник вопрос.
Значит, для любого b из бареллевского сигмала Геннадьевича ворка, это минус 1 от b принадлежит f-кси.
Я бы мог здесь сказать, что это просто случайный вектор, но это было бы более слабое утверждение,
потому что мы даже можем сузить нашу сигмал Геннадьевич событие f и говорить только про событие, которое связано со случайным вектором кси.
Ну здесь на самом деле все логично.
Вот это, это функция от кси.
Это означает, что по тем событиям, которые определяют кси, они точно так же определяют и это, тем более, раз это функция от кси, да.
То есть на самом деле вот эта равносильность, она интуитивно очевидна.
И в одну сторону она легко оказывается, в другую, но не очень.
Так, еще один, значит, важный момент, который из этого следует.
Следующее утверждение, которое мы сейчас легко докажем,
что вектор является случайным тогда и только тогда, когда его компоненты от случайной величины.
Да, то есть кажется понятно, что если вектор случайный, то его компоненты случайной величины оказываются верно и обратно.
То есть случайный вектор можно определять не так, как мы это только что сделали,
сказав, что это функция измеримая, которая действует в Rn,
а сказать, что просто случайный вектор, это вектор, который состоит из случайных величин.
Значит, кси, вектор составный с компанией x1, t, xn является случайным вектором.
Тогда и только тогда, когда x1, t, xn это случайное величине.
Вот, ну давайте докажем.
Ну, хоть слева направо кажется очевидно, но доказывать надо.
Давайте докажем, сначала слева направо.
Значит, возьмем какое-то произвольное i, докажем, что xit это случайная величина.
Ну, по определению случайной величины, возьмем любое баррелевское множество b
и поймем вообще, что такое x-1 от b, xit-1 от b.
Что это такое?
Ну, это есть множество тех омега, которые под действием xit и t переходят в b.
Это, конечно же, в точности множество тех омега,
которые под действием xit переходят в декартовое произведение R и минус 1 раз,
потом b, потом еще декартовое произведение R и t.
Понятно, что i и t координата принадлежит множеству b.
Это то же самое, что весь вектор принадлежит вот такому декартовому произведению.
Это просто одно и то же.
А так как это множество является баррелевским,
то по определению случайного вектора его прообраз принадлежит f.
Значит, действительно xit это случайная величина.
В обратную сторону.
Пусть теперь есть x1, t, xn, случайные величины.
Ну, возьмем, что нам надо проверить?
Нам надо проверять, что xit это случайная ве treateddoctor.
Ну, теперь мы будем пользоваться критериями измеримости.
У нас есть благо критерия измеримости.
Вот он.
Которое говорит что нам не обязательно свойствуют измер película или деп seineεις非,
ведь на самом деле их Whoa OH wasza ting!!!
Вот.
Итак, moving on.
который говорит, что нам не обязательно свойство измеримости приобретать вообще для всех множества
сигма-алгебра, в нашем случае это баррельско-сигма-алгебра ВРМ, а нам достаточно взять какую-нибудь систему
образующих множество этой сигма-алгебры и для неё проверить. Ну, например, возьмём декартовое произведение.
Мы знаем, что все декартовые произведения являются системой, которая образует всю сигму-алгебру,
да, то есть, если я рассмотрю множество всех декартовых произведений, то на меньше сигма-алгебра,
которое это множество содержит, это в точности баррельско-сигма-алгебра ВРМ.
Поэтому мне достаточно рассматривать декартовое произведение для проверки на измеримости. Я это
сейчас и сделаю. Я беру кси в минус 1, это какого-то декартового произведения, и понимаю, что это
множество тех омега, которые под действием кси перешли в это декартовое произведение. Что значит
перешли в декартовое произведение? Это значит, что первая координата должна перейти в первое
множество, то есть кси первое от омега. Должно попасть в первое множество, кси второе от омега в
второе, и так далее, кси nt от омега должно попасть в это множество. Ну и понятно, что если я просто
отдельно рассмотрю прообразы В1, Вn, то их пересеку и получу то же самое. То есть, это есть не что
иное, как пересечение по всем и от единицы до m множество омега таких, что кси и т от омега попало в
Вt. Ну а это как раз прообразы Вt от действия кси и т. А кси и т это случайная величина.
Значит, каждый из прообразов принжит f, то и все пересечение принжит f, что и требуется.
Так, есть ли какие-то вопросы?
То есть, основное, что нужно доказать, это просто измеримость этих функций. То есть,
основное, что нужно доказать, это просто измеримость функций кси и т или кси.
Ну да. Ну это есть определение случайного вектора. Так, хорошо. Теперь давайте поговорим про
арифметические операции над случайными величинами. То есть, мы поняли, что если есть случайный вектор,
то его компонент это случайная величина. Это оправдывает арифметические операции.
Да, почему это оправдывает арифметические операции? Ну возьмем две случайные величины и сложим их.
Правда ли, что мы получим слово случайную величину? Конечно, правда, потому что последующие формальные
причины. Значит, если мы возьмем вектор из этих двух случайных величин, составим. Это просто вектор
из двух случайных величин. Вот подоказано только что утверждение. Он является случайным вектором.
А потому, что я сказал перед этим, если мы применим к нему баррельскую функцию, мы получим снова
случайный вектор. В частности, если мы сложим компоненты вектора, сложение этой баррельской
функции, мы получим случайную величину. А значит, там сумма случайных величин – это случайная
величина. Разность случайных величин, произведение, отношение. То есть, все арифметические операции,
которые можно делать с числами, их можно делать как с функциями, со случайными величинами,
и вы получите снова случайные величины. Итак, следствие. Хотя давайте еще одну
утверждение с перерасформируем. Любая непрерывная функция является баррельской.
То есть арифметические операции являются баррельским, потому что они являются непрерывными функциями.
Ну или кусочно-непрерывные функции тоже являются баррельскими.
Кусочно-непрерывные функции.
Почему я сказал про кусочно-непрерывные? Но если нам надо будет разделить
одну случайную величину на другую, мы должны в нуле как-то, если знаменитая
может обращаться в ноль, мы должны как-то с этим поворотиться, вот поэтому нам должна
в этом случае будет кусочек непрерывности. Ну и очевидное следствие это, что если есть две
случайные величины, вы их смело можете. Что буду с ними делать? Значит, если x это случайные величины,
то их сумма, разность, произведение, частное, ну тут можно умножить данный индикатор того,
что это не равно нулю, чтобы выколоть эту точку, являются случайными величинами.
Вот, ну и последнее на сегодня, нет, не на сегодня, на вот эту лекцию, на первую лекцию утверждение,
которое мы с вами докажем, это то, что можно не только делать технические операции,
но еще и к пределу переходить. Значит, если есть последовательность x1, x2 и так далее случайных
величин, ну вообще говоря, предела может и не существовать, конечно, но если он существует,
то он будет являться случайными величинами. Более общего можно сформулировать следующее утверждение.
Ну во-первых, можно брать infinum, supremum, если они существуют, а можно брать нижние пределы и
верхние пределы, опять же, если они конечные. И это все будут случайными величинами.
Вот, ну давайте начнем наказывать. Докажем, я думаю, попробуем успеть доказать для infinum
и для supremum, а с нижними и верхними пределами на следующий кусок лекции,
которая в 15-30 начнется. Так, ну давайте supremum, с infinum просто аналогично.
Рассмотрим функцию, которая равна supremu. Что значит supremum? Еще раз, у нас есть последовательность
функций, конечно, а не чисел, а именно функций, и мы просто для каждого
аргумента находим свой supremum. Если мы какой-то омега маленький, какой бы мы аргумент не
зафиксировали, мы получим последовательность чисел, то есть значение нашей функции на этом
аргументе. Вот, и мы берем для каждого аргумента свой supremum, и у нас получается новая функция.
Мы для каждого аргумента нашли свое собственное значение, получили новую функцию xi, и вы задержали,
что она будет случайной величиной. Значит, чтобы проверить, что она является случайной величиной,
нам нужно проверить измеримость. Возьмем прообраз
луча от минус бесконечности до x. Ну, то есть это множество таких омега, что xi от омега меньше
чем x. Так как xi это supremum, то это есть не что иное, как множество таких омега, что для любого n,
xi и n меньше, чем x. Это есть, конечно, пересечение по всем n, xi и n в минус первый от луча от
минус бесконечности до x, что является элементом f. Что является элементом f, так как все эти
прообразы f принадлежат, f это сигма-агебра, то есть счетное пересечение тоже подходит. Из этого,
конечно, все следует, потому что вот эти лучи, они порождают всю сигму-агебру. По критерию измеримости,
так как множество лучей является образующей системой множеств, то достаточно только для этих лучей
проверить свойства измеримости. Мы это сделали, а значит, xi действительно случайно начинает. Аналогично с
инфинумом рассмотрим лучи, которые в другую сторону смотрят. Рассмотрим луч от x до плюс
бесконечности. Имеем право, эти лучи тоже образуют всю сигму-агебру, то есть это тоже система,
которая порождает всю сигму-агебру. И по аналогичным причинам, это множество амек таких,
что все ксии больше либо равны чему. В данном случае будет пересечение по всем n, ксии n в
минус 1, луча от x до плюс бесконечности, и опять это элемент f, что и требуется.
Время осталось мало, давайте с нижним пределом и с верхним пределом чуть сложнее разберемся
после перерыва, а именно в 15.30. Если какие-то вопросы,
если вопросов нет, то на этом все. Спасибо всем присутствующим, увидимся через 3.5 часа.
Прекрасно. Давайте продолжим. На чем мы остановились? Мы с вами сформулировали
подтверждение про пределы и выяснили, что инфину у нас в правом последовательстве действительно
случайная величина. Давайте теперь разберемся с тем, почему нижний верхний предел — это тоже
случайная величина. Давайте с верхнего начнем, чтобы ознать верхний предел за ксии. Как и выше,
нам нужно взять какую-то систему множеств, которая образует всю сигму-агебру, показать,
что для нее есть измеримость, верхний предел. Что значит, что верхний предел больше какого-то
х? То есть, по москвальму, на ксии минус 1 от луча от х до плюс бесконечности х не включает. То есть,
что верхний предел больше, чем х. Верхний предел больше, чем х, это означает, что найдется сколь
угодно большой член последовательности, который больше, чем х. Чтобы верхний предел был больше,
чем х, должна быть под последовательность, которая в пределе дает нечто большее, чем х. То есть,
на самом деле, это множество таких омега, что для любого к найдется n больше, чем равное, чем k,
такое, что ксен больше, чем х. Да, это в точности условие заключается в том, что верхний предел
больше, чем х. Нет, я не прав. Верхний предел может быть равен х, и, тем не менее,
может находиться сколь угодно большой член последовательности, который больше, чем х. Но,
то есть, тут должно быть нечто более сложное условие. Ксен должен быть больше, чем х плюс
некоторое эпсилум. То есть, на самом деле, правильно писать вот так. Это пересечение по всем
эпсилум больше нуля. Вот таких вот событий. Если поставить квадратную скобку, то тоже не очень
понятно, потому что если верхний предел равен х, то тогда это может означать в принципе, что и все
члены последовательности могут быть меньше, чем х, но при этом верхний предел будет равен х. Нам
именно нужно, чтобы было больше, чем х с некоторым запасом. То есть, даже если мы потребуем больше
оно, чем х, нам в целом придется что-то умудрить вот в таком же духе. То есть, так вот просто обойтись
без этого эпсилума, короче, не получится. То есть, нам нужно три квадра, на самом деле, не два, три.
Теперь понятно, что мы можем объединять не по всем положительным эпсилумам, а по любой
подпоследовательности положительных эпсилум, которая стремится к нулям. То есть, мы можем
взять, например, написать вместо этого сумму по всем натуральным м, объединение, прошу прощения,
по всем натуральным м. А здесь написать вместо эпсилум, написать х плюс 1мт. Это будет просто
равносильным условием. Ну и все, это уже есть объединение по всем м, пересечение по к, объединение
по м больше, чем к, событий кси-н больше, чем х плюс 1мт. Вот теперь, так как си-н это случайная
величина, прообразы вот этих всех, вот этих всех лучей являются барреллерскими множествами. Здесь
у нас счетное объединение-пересечение, значит, это тоже барреллерское множество. Господи, это тоже
событие, да, элементы f, так как f это сигнал гибра, что и требуется. Да, ну раз мы доказали вот для всех
таких лучей, то значит, мы доказали, что кси-это случайная величина. Действительно. Вопросы.
Ну и по аналогии с нижним пределом,
с нижним пределом, ну прям можно по аналогии, то есть взять теперь, чтобы долго не думать,
что есть луч от минус бесконечности до х, не включая х, да, и тогда события, заключающиеся в том,
что нижний предел ниже, чем х, это события, которые заключаются в том, что для некоторого
епселон найдется бесконечно много членов последовательности, которые меньше, чем х-эпселон.
То есть это объединение опять по всем положительным епселон. Событие. Для любого k найдется такой
номер, превосходящий k, что ксен меньше, чем х-эпселон. Ну и опять это есть объединение по всем
m, пересечение по всем k, объединение по всем n больше, чем k, событие ксен меньше, чем х-1mt,
которое принадлежит f, что и требуется.
Есть какие-то вопросы?
Так, хорошо, ну с этим вроде всё. Давайте я напоследок еще раз скажу то, что я уже сказал в начале.
А именно, что у нас есть какой-то случайный элемент, будь то случайный величина или случайный
вектор, то ему соответствует вероятность, которую он индуцирует во множестве, в которое действует.
Мы его обозначили здесь по х и сказали, что это на самом деле распределение вероятностей
случайного элемента х. Понятно, что все определения, все понятия, которые мы связывали с понятием
распределения, они просто переносится на случайную величину и случайный вектор. То есть мы можем
говорить про функцию распределения случайного вектора или случайной величины. Можем говорить про
абсолютно непрерывный случайный вектор, если его распределение является... Он точно так же может
быть дискретным. Можем говорить про плотность случайного вектора или случайной величины,
имея в виду плотность соответствующего распределения вероятностей. Давайте это запишем.
Давайте считать тогда, что х это случайный вектор
для общности, а по х это его распределение вероятностей. То есть это та самая мера,
которая порождает этот случайный вектор. То есть это такая мера, которая действует из баррельского
сигмала URM01, что по х от B это есть вероятность события, х принадлежит B. Это распределение х.
Распределение х. Ну и тогда мы будем говорить заодно и про функцию распределения х. То есть fх,
которая действует из RRM01, функция распределения, соответствующая распределению по х,
мы будем называть ее функцией распределения самого вектора.
Функция распределения х. Ну и если по х дискретно,
то мы будем говорить, что х это дискретный случайный вектор.
Ну и если по х абсолютно непрерывно,
то мы будем говорить, что х это абсолютно непрерывный случайный вектор.
Вот. Ну и соответственно, если в этот раз у нас тут непрерывно,
у него есть плотность, мы будем называть плотностью вектора.
По маленькой х. Плотность по большому х.
А мы будем ее называть плотностью случайного вектора.
Так, ну все, теперь давайте подойдем поближе к тому, чтобы что-нибудь посчитать,
какие-нибудь вероятности соответствующие случайным векторам.
Ну там скажем, какая вероятность? Вот есть две независимых случайных величины.
Как нам посчитать вероятность того, что их сумма попала в какое-нибудь множество?
Подобные задачи мы с вами научимся решать, но вот как раз, чтобы их решать,
нам нужно поговорить про независимость. Независимость случайных величин,
это такой очень важный частный случай совместных распределений.
Но вот есть у вас случайный вектор. У каждой случайной величины этого вектора есть какое-то
распределение вероятностей. Как мы сегодня говорили, это называется маргинальное распределение.
То есть у случайного вектора есть распределение в РН, распределение всего этого вектора целиком.
У каждой кардиналты есть свое распределение в Р, которое называется маргинальным распределением.
И знать маргинальное распределение недостаточно для того, чтобы восстановить распределение целиком.
Ну вот, например, если вы скажете, что давайте распределение вектора, это будет произведение,
декартовое произведение распределения его компонента. Вот это как раз означает,
что компоненты в случайном векторе независимы. Но если вы там измеряете температуру, грубо говоря,
здесь и в Австралии, но, наверное, это какие-то похожие на независимые случайные величины.
То есть это те величины, что наступление одних не влияет на наступление других.
Давайте поговорим про независимость случайных величин и случайных векторов.
Понятно, что это очень важное понятие, которое является вообще центральным в
серии вероятности, понятие независимости. Мы с вами уже говорили про независимость событий,
и из этого определение вытекает независимость случайных величин. В частности, я в начале,
о впоминал, что есть такое физическое определение вероятности и математическое определение вероятности,
то есть вероятность можно понимать как частотность наступления событий,
если вы могли бы это событие реализовывать независимо много раз. То есть проводить
какой-либо эксперимент, в рамках которого это событие может произойти. Если вы могли
бы делаться без конечного много раз независимо, то тогда бы оказалось,
что частота наступления вашего события, она в пределе была бы равна вероятности.
И чтобы проводить рассуждения, связаны не только события, но и случайные величины,
нужна независимость. Закон больших чисел, центральная предельная теорема, о которых мы
будем говорить в курсе, они все опираются на понятие независимости. Они работают именно для независимых
случайных величин. Для зависимого бывает всё, что угодно. Но понятно, что зависимости могут слабы
быть. То есть вот эти предельные теоремы, о которых мы будем говорить, их можно обобщать на какие-то
зависимые ситуации. Мы этого делать не будем. Мы будем ограничиваться независимым случаем. Но,
тем не менее, можно. Если не требовать никакой независимости, то бывает всё, что угодно. И все
предельные теоремы работают только по модулю какой-то независимости или слабой зависимости.
Итак, ну, во-первых, независимость двух случайных величин. Независимость часто обозначают вот так.
Значит, случайная величина xi это независимая, если для любых баррельских множеств, ну или это
случайный вектор, пусть это был случайный вектор. Пусть, например, xi имеет размерность n, а это имеет
размерность k. То есть любых баррельских множеств в одном случае zrn, b1 и b2 из rk. Вероятность того,
что x1 принадлежит b1, это принадлежит b2 равна произведению вероятности.
Вот. Ну, по аналогии можно говорить про независимость, на самом деле, любого
набора случайных причин. Давайте начало конечного. Пусть у нас есть, скажем, случайные векторы.
Ксиодинт или ксен. Мы будем говорить, что они независимые. Если для любых баррельских множеств, ну,
из соответствующих размерностей, да, понятно, что давайте мы будем считать, что итый вектор имеет
размерность, скажем, k итая. То есть для любых b1 из b от rk1 и так далее bn из b от rkn выполнена
вероятность совместная, потому что x1 принадлежит b1 и так далее xn принадлежит bn равна произведению
вероятностей. Вот понятно, что есть тоже попарная независимость. Можно говорить про попарную
независимость случайных величин, просто когда каждая пара в совокупности является независимой.
И из попарной независимости, как обычно, не следует простая независимость, независимость
в совокупности, если хотите. Можно говорить про независимость целой произвольной системы
случайных величин, то есть можно рассмотреть там какой-нибудь набор, индексированный индексом
alpha, может быть любой мощности, он не обязан быть счетным, он может быть больше, тогда говорят,
что случайная величина, которая в нем находится независимая, если независим любой конечный
поднабор, то есть если для любого n и для любых alpha 1, alpha n различных,
различных, кси alpha 1 и так далее, кси alpha n независима.
можно вопрос? да. а что это означает? вот в третьей строке сверху вероятность того,
что кси принадлежит b1, запятая это принадлежит b2. а это типа расписывается через элементарные
сходы что ли? вы про эту строчку, да я правильно понял? да. ну смотрите, вот я выше говорил,
что такое px, помните? вот я сказал, что давайте, когда у нас есть некоторое событие,
ну в любом случае у нас вероятность задана изначально на множестве элементарных сходов,
именно там она и существует. когда мы говорим про букву именно p, да, у него мог появиться индекс,
это вероятность, которая уже перенеслась в другие множества, вот. когда мы именно пишем букву
p, то мы имеем в виду событие, которое лежит в f. вот это, это просто сокращение вот такой записи,
то есть событие, это множество омега, которые в некотором условии подчиняются, да, в данном
случае множество таких омега, что их 100 мега принадлежит b. соответственно, если я пишу вот так,
да, я могу там через запятую тоже перечислять какие-то условия, то это означает все то же самое,
это просто множество тех омега, что все от омега принадлежит b1, и одновременно это от омега принадлежит b2.
понятно, спасибо. так, еще какие-нибудь вопросы?
можно в определении говорить просто что? не для всех баррелевских, а только для порождающего?
да, спасибо за вопрос, сейчас я к нему отвечу. нет, нельзя, но можно для некоторых систем порождающих множеств,
и для этого можно использовать критерии независимости, которые мы еще с вами сформулируем.
этот критерий, его можно формулировать для случайных векторов и для случайных величин,
все то же самое. доказывать давайте точно для случайных величин, чтобы не громоздить много
буков, а формулировать, ну сформулировать давайте для случайных векторов, почему нет?
пусть у нас есть случайные векторы x1, тогда xn, тогда они являются независимыми,
тогда и только тогда, когда функция распределения случайного вектора составленного из этих
случайных подвекторов. ну вот если бы это были случайные величины, то я бы сказал, что функция
случайного вектора составленного из этих случайных величин просто равна произведению функции
распределения. значит для случайных векторов это в принципе все равно то же самое, только вот
эти x здесь они имеют разметность, то есть x1 принадлежит rk1, и тогда xn принадлежит rkn.
вот никакой проблемы нет, когда я пишу вот так, я просто имею ввиду, что я записал все эти векторы
просто подверг. то есть это вот один длинный вектор, который составлен из-под векторов x1,
то ли xn, и то же самое здесь, вот это вот длинный случайный вектор, который составлен из-под
векторов x1, то ли xn. вы его в индексе просто записали, да? кого? вот этот вектор? а где мне
его еще писать? только в индексе. это функция распределения случайного вектора. да, я напомню,
что у нас случайный вектор порождает распределение вероятностей, которую мы обозначали по x,
по x, и у него есть функция распределения. то есть это есть на самом деле не что иное,
я поясню на всякий случай. да, это есть не что иное, как просто вероятность того,
что x1 меньше значим x1, и тогда xn меньше значим xn. вот, ну а это соответственно произведение
вероятности того, что x1 меньше значим x1, и так далее. xn меньше значим xn. вот, то есть на самом деле
то, что здесь написано, это как раз то, о чем вы спросили, что вместо всех бороться, можно
достаточно рассмотреть некоторую порождающую систему, но не а во какую. вот подходят лучи,
которые в определении функции распределения. вот, ну давайте, чтобы просто не городить, не думать о
том, что у нас на самом деле эти x это тоже векторы, давайте будем, когда доказывать, будем думать о
том, что это случайные величины. хотя доказать никак не зависит от случайных величин или случайных векторов,
чтобы было проще воспринимать. значит, смотрите, идея доказательства это так называемый принцип
подходящих множеств. это так называемый принцип подходящих множеств. значит, то, что нам нужно
доказать, это что... ну что нужно доказать? нужно доказать вот это. то есть у нас вот такое
равенство есть для лучей, а нам нужно доказать для всех баррельских множеств. и вот давайте мы скажем,
что все баррельские множества, которые этому равенству удовлетворяют, они являются подходящими,
вот рассмотрим систему всех подходящих множеств, которые предподстановкивают равенство, дают
верное равенство, и докажем, что оно просто совпадает с баррельской сигмалкой. то есть идея в том,
что возьмем всех систем множеств, которые нам подходят, и докажем, что они являются сигмалкой.
вот как это аккуратно сделать? значит, во-первых, будем доказывать наше утверждение по индукции,
то есть вот это равенство будем доказывать по индукции не по N, а по количеству баррельских
множеств здесь внутри. мы часть из вот этих условий оставим в виде лучей, а часть в виде
произвольных баррельских множеств. значит, давайте докажем по индукции,
что для любого k от 1 до n, для любых b1 это далее bk баррельских,
и для любых xk плюс 1 xn действительных верно, что вероятность того, что кси1 принадлежит b1,
и так далее, ксиk принадлежит bk, ксиk плюс 1 меньше, чем xk плюс 1, и так далее,
ксиn меньше, чем xm равно произведению этих вероятностей, вероятность того, что кси1 принадлежит b1,
и так далее, вероятность того, что ксиk принадлежит bk, вероятность того, что ксиk плюс 1 меньше, чем xk плюс 1,
и так далее, вероятность того, что ксиn меньше, чем xm.
По индукции пока это будем доказывать. Прикар равно единице, надо доказать, что вероятность того,
что кси1 принадлежит b1, кси2 меньше, чем x2, это далее ксиn меньше, чем xm, рана произведению всех этих вероятностей.
Ну и вот давайте рассмотрим все баррельские множества, которые нам подходят. Допустим, скажем, m – это множество таких b.
Простите, а не проще будет начать с кар в нулю тривиальной базы, чтобы не повторять просто одни и те же рассуждения в шаге?
Наверное, вы правы, да. Наверное, вы правы.
Ну хорошо, наверное, так получится. Давайте считать, что база – это кар в нулю, и для нее это равенство является тривиальным,
потому что это просто то, что дано. Да, для кара в нулю получается просто, что все эти множества – это лучи.
Так, теперь предположим, что доказано для k.
Для k. И хотим доказать для k плюс 1.
Вот. Ну тогда, значит, тогда что мы хотим? Мы хотим, чтобы были равны такие вероятности, ну, где вместо k, k плюс 1, на самом деле, написано.
Давайте мы, не буду переписывать это равенство, мы хотим, чтобы были равны такие вероятности, ну, где вместо k, k плюс 1, на самом деле, написано.
Давайте мы, не буду переписывать это равенство, давайте я сразу поясню, что мы делаем.
Мы рассматриваем систему множеств m, баррелявских, таких, что, значит, давайте еще зафиксируем прямо все, кроме…
Вот на k плюс 1 позицию у меня будет стоять это баррелявское множество b, а все остальные баррелявские множества и числа мы зафиксируем.
То есть фиксируем баррелявские множества b1, bk и фиксируем числа xk плюс 2, это до lxm.
А вот на k плюс 1 месте у меня будет стоять вот это множество, множество b, которое здесь в b.
Значит, m это множество всех таких баррелявских множеств, что вероятность того, что x1 принадлежит b1,
и т.д. xk принадлежит bk, xk плюс 1 принадлежит b, xk плюс 2 меньше, чем x2, xk плюс 2, и т.д. xn меньше, чем xm, ну, равна просто произведению вероятностей.
Вот, смотрите, значит, что мы знаем про m? Мы знаем, что как минимум все лучи принадлежат m.
То есть множество вида от минус бесконечности до x, свящая x, в m, конечно, лежат, ну, это дано.
Нам дано по предположению индукции, что мы доказали наше условие для k.
Наше условие для k это как раз, если вот это баррелявское множество, это луч.
Это как раз получается условие, которое мы якобы доказали для k.
Поэтому все такие множества лежат m.
Поэтому мы знаем, что наименьшее сигма алгебра, которое содержит m,
она совпадает с баррелявской сигма алгеброй.
Ну, так как m это подножство баррелявской сигма алгебры, и в нем належат все лучи,
но как минимум, значит, наименьшее сигма алгебра, которое содержит m, является баррелявской сигмалгеброй.
Поэтому если мы докажем, что m это сигма алгебра,
что она сама сигма алгебра, сама по себе, то это будет сразу следовательно,
что совпадает с баррелявской сигмалгеброй.
Вот, в принципе, можно доказывать, что это сигма алгебра, но, на мой взгляд,
чуть проще доказывать, что это лямбда-система.
Давайте я для широты кругозора, поэтому расскажу, что такое лямбда-система,
как это можно сиспользовать.
Что такое лямбда-система?
concerts ? У нас есть некоторая система множеств сигмы.
Мне понадобится понятие p-системы.
Во-вторых, лямбда-система.
Значит, система множества сигмы называется p-системой banksigmalgibra.
audience. sichmalgibreinnen.
Это система множества, которая замкнута относительно некоторых операций.
Значит, система множества сигмы называется p-система, если она просто замкнута относительно пересечение.
пересечения. Если принадлежность множеством множество ab sigma вылечет принадлежность
сигме их пересечения, тогда система называется по системе. Значит, она называется лямбда системой,
лямбда системой, если выполнено несколько свойств. Во-первых, всё множество e. Вот у нас есть
единица, это некоторое множество e. Одно должно принадлежать этой лямбда системе. Во-вторых,
если два множества содержатся в e и они вложены, то их разность тоже содержится в sigma.
Ну, наконец, приход к пределу. Значит, если есть вложенная последовательность множества 1 на 2,
каждый из которых принадлежит sigma, то их объединение тоже принадлежит sigma.
Ну и такое утверждение, техническое, оставим его без доказательства, что если есть какая-то
P-система, то наименьшее sigma-алгебра, которое это P-система содержит, совпадает с наименьшей
лямбдой системы, которую эта P-система содержит. Вот. В связи с этим, так как мы знаем, что наша
система M содержит P-систему, множество всех лучей от минус бесконечности до x – это P-система.
Можете объяснить, в чем различие лямбдосистемы и просто sigma-алгебра?
Ну, вообще говоря, лямбдосистема совсем не обязана быть замкнута относительно
пересечения событий или объединения событий.
Но наш замкнут относительно объединения и пересечения – это как разность?
Где вы видите назад? Назад относительно объединения вложенных множеств.
Понятно.
Это вложенные множества, да, то есть можно перейти к пределам.
Можно еще вопрос?
Да.
Когда M вводили, вот B без индекса, мы по нему строим, и оно – это то, куда вложено x от k плюс 1, правильно?
Когда вводили M, B без индекса, да, они играют роль на самом деле множества B k плюс 1. В этом вопрос?
Да, типа одно и то же B. И по нему мы строим.
Да. Мы думаем, у нас все фиксировано, мы думаем исключительно про k плюс первое множество.
Поэтому, так как у нас вот все эти позиции фиксированы, первые k из k плюс второй по n,
то я в это множество индекс не стал ставить, мы просто зафиксировали.
И, значит, для вот этих всех вещей фиксированных мы меняем множество B.
Так, хорошо, спасибо.
Да, значит, так как множество всех лучей – это и система, и она является под множеством V,
то если мы докажем, что M – это лямбда-система, то она и сигма логибра.
Да, значит, еще раз мы знаем, что наименьшая лямбда-система, которая содержит P-систему,
совпадает с наименьшей сигма логиброй, которая содержит эту P-систему.
Значит, у нас M P-систему содержит, поэтому если M – это лямбда-система сама по себе,
то она и сигма логибра почему? Потому что она, конечно, наименьшая,
она не может быть никакой другой.
Мы знаем, что наименьшее сигма логиброй, которая содержит наша P-система – это бареллевская
сигма логибра.
Пр想 파, наша P-система содержится в самой маленькой возможной сигма логибройlynn tego,
которая содержится – это в бареллевской сигмала.
И M там же находится, все множества, которые лежат от V, они бареллевские.
Поэтому, если же M – это лямбда-система, она не может быть меньшая, чем бареллевское сигма логибр.
тогда именно это баррельская сигма-алгебра, с которой она просто совпадает. Поэтому всё,
что нам осталось доказать, это то, что m – это лямбисистема. То есть, короче, проверить вот эти
три свойства. Давайте это сделаем. Первое. Значит, e принадлежит сигма, e – это в данном случае r.
Отверждается, что r принадлежит m. Давайте это проверим. Возьмём, но подставляем вместо b
вот это r и проверяем равенство. Значит, нам нужна вероятность того, что кси1 принадлежит b1,
и так далее, ксиK принадлежит bK, ксиK плюс 1 принадлежит r, ксиK плюс 2 меньше 0, чем xK плюс 2,
и так далее, ксен меньше 0, чем xN. Нам нужно, чтобы она распалась по зрению вероятности.
Как это сделать? Давайте заметим вот что. Давайте заметим, что потеремия непрерывности вероятности – это
есть не что иное, как предел при x, стремящемся к плюсбесконечности, вероятности того, что кси1
принадлежит b1, и так далее, ксиK принадлежит bK, ксиK плюс 1 меньше 0, чем x, ксиK плюс 2
меньше 0, чем xK плюс 2, ксен меньше 0, чем xN. Да, понятно, что если мы стремляем к плюсбесконечности, то вот
эти вот события, они становятся вложены, и поэтому можем перейти к пределу и получить в точности
вероятность объединения всех этих событий, то есть вероятность того, что ксиK плюс 1 принадлежит r.
Вот, в силу независимости, то есть я имею в виду, что в силу предположений индукции,
по предположению индукции мы знаем, что для K наше утверждение доказано, то есть вот мы умеем
писать такое ранение, это в точности оно. У нас до K позиции стоит принадлежность к множеству,
а начиная с К плюс первой лучу, и значит поэтому по предположению индукции мы вылучаем, что это
просто предел при х, стремляющейся к плюсбесконечности произведения вероятностей. Вероятность того,
что ксиK принадлежит b1, ксиK принадлежит bk, ксиK плюс 1 меньше, чем x, ксиK плюс 2 меньше,
чем xk плюс 2, и так далее, ксиK меньше, чем xn. Ну и вот, значит, предел у нас при х,
стремляющейся к бесконечности, только один из множеств, этот в эксазовист, вот этот. Опять,
переходя к пределу, мы получаем, что это вероятность стремляющейся к единице, да, но это есть
не что иное, как предел функции распределения, на самом деле, это х, и он, конечно, равен единице,
и мы получаем в результате вероятность того, что кси1 принадлежит b1. Вместо единицы напишем
для удобства вероятность того, что ксиK плюс 1 принадлежит r. Да, мы же явно хотим показать,
что мы получили произведение вероятностей, но вот мы его и получили. Значит, действительно,
первое свойство из определения лямбли системы выполнено. Второе, значит, если a и b вложены,
то b-a должно принадлежать sigma. Значит, итак, пусть a и b вложены множество, и они принадлежат m.
Мы, значит, берем разность этих множеств и хотим показать, что эта разность будет
принадлежать m. Ну, значит, то есть мы берем вероятность того, что кси1 принадлежит b1,
и далее ксиK принадлежит bK. КсиK плюс 1 принадлежит разности b и a. КсиK плюс 2 меньше,
чем xK плюс 2, далее ксиN меньше, чем xN. Вот, но теперь, так как вероятность адитивна,
мы тут имеем на самом деле разность двух множеств. То есть мы вот на это все,
можно смотреть как на разность двух множеств, где первые там k и последние n-k-1 координаты
являются фиксированными, а здесь в одном случае будет b, в другом случае будет a. Так,
эти множества вложены, и вероятность функции адитивная, то мы получаем разность вероятностей.
Вероятность того, что кси1 принадлежит b1, и далее ксиK принадлежит bK. КсиK плюс 1 принадлежит b.
КсиK плюс 2 меньше, чем xK плюс 2, и так далее ксиN меньше, чем xN.
Минус, точно такая же вероятность, но только вместо b надо написать a.
Вот, только здесь нужно b исправить на a. И, собственно, все, потому что по предположению в нашем пункте мы
считаем, что множество a и b принадлежат к m, это означает не что иное, как то, что обе вероятности
распадутся в произведение. Распадутся в произведение, что мы и сделаем. И точно так же со
второй вероятностью. Минус. Точно такая же вторая вероятность, только вместо b будет стоять a.
Здесь будет стоять a. Вот, ну и последнее, что осталось сделать, это увидеть, что в обоих произведениях
все множества одинаковы, кроме вот этих. Их, соответственно, можно вынести за скобки,
получим разность двух вероятностей. Вот это минус вот это. И так как b содержится в a,
мы получим вероятность разности множества. То есть окончательно получаем то, что хотели.
То, что хотели. Вот, поэтому пункт два тоже доказан. Следовательно, b-a принадлежит m.
Пункт три. Пункт три. Значит, здесь нам нужно перейти к пределу. У нас здесь вложено множество.
Ну, понятно, что все то же самое. Значит, пусть есть вот эти вот 1, 2 и так далее. И они все
принадлежат m. Значит, и мы хотим... Ну и давайте за a обозначим их объединение. Если объединение
а, надо доказать, что он тоже принадлежит m. Ну опять, значит, берем вероятность того,
что x1 принадлежит b1 и так далее. xk принадлежит bk. xk плюс 1 принадлежит a. xk плюс 2 меньше
на xk плюс 2. Далее xn меньше на xn. Вот, ну напоминаю, что множество вложенное. Поэтому можно считать,
что вот эти множество, вот эти события целиком, они являются множество, они являются вложенными.
То есть они отличаются только вот этим куском, вот этим условием, а это условие является вложенным.
Ну, значит, все события целиком являются вложенными. Мы можем перейти к пределу при
стремящемся... Так, только не n давайте, а то у нас m до количества координат. При m стремящемся к
бесконечности вероятности того, что x1 принадлежит b1 и так далее. xk принадлежит bk. xk плюс 1 принадлежит
am. xk плюс 2 меньше на xk плюс 2 и так далее. xn принадлежит xm. А так как по нашему предположению
все множество am являются элементами m, из этого означает, что вероятность распадается к произведениям.
Мы получаем произведение этих всех вероятностей того, что x1 принадлежит b1, xk принадлежит bk,
xk плюс 1 принадлежит am, xk плюс 2 меньше на xk плюс 2 и так далее. xn меньше на xm.
Вот, и вот эта вероятность, она в пределе, конечно, 1. Она в пределе, конечно, 1, потому что мы снова
переходим к пределу, мы засовываем внутрь вероятности за счет того, что вот эти множества am вложены,
ну и соответственно, это означает, что эти события тоже вложены. Вот, и в пределе получаем вероятность
принадлежности множества a. Вероятность того, что xk плюс 1 принадлежит множеству a на все остальные
вероятности. Ну вот, собственно, и всё. Из этого сходу следует, что a принадлежит m, что и требовалось.
Значит, действительно, так как мы доказали, что все три свойства лямблесистемы выполнены, то наша m
это лямблесистема, а значит, она является сигмалгебой и совпадает со всей барреллесской сигмалгебой.
И это завершает, конечно, доказательство нашего утверждения, да, потому что я напомню, что m это
система подходящих множеств, то есть всех тех множеств, которые дают, чтобы вероятность пересечения
на произведение вероятностей, но, конечно, это вообще все множества нам подходят, тем самым по индукции мы
доказали наше утверждение, и в частности, при k равно n, мы получаем требуемое.
Итак, значит, утверждение по индукции доказано.
По индукции доказано, в частности, при k равно n, мы получаем требуемое, то есть вероятность того, что
кси1 принадлежит b1, и так далее, ксен принадлежит bn, равна произведению вероятностей.
Есть какие-то вопросы?
Так, вопросов нет. Прекрасно. Ну, что тогда? Тогда давайте поговорим еще немножечко про какие-то простейшие
свойства, важные с точки зрения независимости, потом я скажу о том, как сворачивать распределение,
то есть как находить, в частности, распределение суммы независимо случайных величин, чего не посчитаем мы на этом закончим.
Так. Ну, какие-то простейшие умозаключения, которые мы с вами в курсе будем использовать.
Давайте их будем называть утверждениями.
Во-первых, такое утверждение, что если у вас есть случайные векторы, которые являются независимыми,
вот пусть у вас есть независимый блок, если у вас есть независимые случайные величины, и вы из них
нас составляете случайные векторы. Понятно, что вы получите независимые случайные векторы.
Значит, если есть набор независимых случайных величин,
если вы из них делаете векторы, да, там как мы их называем,
кси к1, потом кси к1, плюс 1 и так далее, кси к2 и так далее.
Ну, вы заставляете из них векторов, но при этом эти векторы не будут пересекаться по компонентам.
Понятное дело, то они снова будут независимыми.
То есть, если у вас есть куча компонентов, вы из них насовираете случайные векторы,
так чтобы они не пересекались по компонентам, вы получите независимые случайные векторы.
Более-менее очевидно, но давайте, наверное, докажем.
Ну, например, следует из критерий, которые я только что написал.
Если вы возьмете просто функцию распределения вот этого вашего вектора, сложно составленного,
то есть, возьмете вектор, который состоит из кусков размера k1, размера k2 минус k1 и так далее,
в точке x1, x2 и так далее, то что это такое на самом деле, что это за функция?
Ну, у вас вектор составлен из-под векторов.
Если вы берете все эти вектора вместе, получаете на самом деле просто функцию изначального вашего случайного вектора.
То есть, вот этот вектор, который в индексе написан, это просто изначальный случайный вектор.
А вот эти x это тоже векторы, длина которых просто соответствует соответствующей длине самого случайного вектора.
То есть, в частности, у этого вектора длина k1.
Но понятно, что они состоят из компонентов.
Поэтому, если вы все эти векторы выписали, вы получили один длинный вектор.
Можно его обозначить 1,0tm. У него будет, конечно, ровно столько же координат, сколько у вас случайных величин.
И в силу того, что ваша случайная величина независимая, вы получите, что это просто произведение функции распределения.
А дальше вы эти множители просто сгруппируете теми же самыми кусками, которые у вас были.
То есть, кусок размера k1, потом кусок размера k2-k1.
И сделайте здесь соответствующие группы из множителей.
И дальше вы увидите, что в силу независимости ваших случайных величин каждое такое произведение это в точности функция распределения соответствующего вектора.
То есть, внутри этих групп, вы эти произведения свернете в функции распределения, вы получите как раз исходные вот эти вот векторы размера k1, k2-k1 и так далее.
То есть, вы получите все вот эти вот векторы и им соответствующие функции распределения.
В общем-то, что и требуется.
Так, есть ли вопросы?
Еще одно утверждение.
В следующем перейдем к сверткам.
Значит, так, пусть у вас есть независимые случайные векторы.
k1, k2, независимые случайные векторы.
И есть соответствующих размерностей.
Пусть их будет n штук.
И соответствующим их размерностям параллельский функции.
То есть, если у it и случайной величины размерность, скажем, k it, то функция будет действовать из r в степени k it.
То есть, есть вот f1, который действует из r в степени k1.
Размерность образа не имеет значения. Какое-то m1 и так далее.
fnt из rkn в rmn.
И все они параллельские.
То есть, еще раз, размерность аргумента совпадает с размерностью соответствующего случайного вектора.
То есть, у x1 размерность k1, у xn размерность kn.
То есть, мы сейчас будем применять эти функции к случайным векторам.
Значит, тогда f1 от x1 и так далее, fn от xn является независимым.
Ну это, в общем-то, тоже очевидное упражнение. Давайте быстренько докажем.
Так понятно, что это должно быть так, потому что независимость это, на самом деле, о том, как устроено совместное распределение.
Если вы знаете, что они независимы от того, что там разные функции будете применять, они независимо останутся.
Хорошо. Ну, любой параллельский может, наверное, взять правильных размерностей.
То есть, первый будет из r степени m1 и так далее. nt будет из r степени mn.
И берем вероятность того, что f1 от x1 принадлежит b1 и так далее, fn от xn принадлежит bn.
И дальше берем полные прообразы, в смысле, вот этих параллельских функций.
То есть, это будет x1 принадлежит f1 в минус 1 от b1 и так далее, xn принадлежит fn в минус 1 от bn.
Далее, в силу независимости мы получим, что это есть произведение вероятностей того, что x1 принадлежит f1 в минус 1 от b1 и так далее.
xn принадлежит fn в минус 1 от bn. Ну и теперь обратно применим эти функции и получим то, что нам нужно.
Вероятность того, что f1 от x1 принадлежит b1 и так далее, fn от xn принадлежит bn.
Да, то есть, это действительно независимость, что и требуется.
Так, есть ли какие-то вопросы?
Нет, хорошо, тогда, собственно, переходим к свертке.
Итак, какая у нас задача? Ну вот, предположим, что у вас есть независимость случайной величины, мы хотим понять, какое распределение у их суммы.
Да, ну или у разности, или у произведения, это все делается точно так же.
И здесь ключевым инструментом является тремофубини. Вы знаете прекрасно, что такое тремофубини, но давайте я напомню.
Свертка – это про распределение суммы. Мы именно на примеры распределения суммы будем решать эту задачу,
но потом вы по аналогии сможете решать такие же задачи для любых альфинитических операций,
то есть брать разность случайных причин произведения отношений, неважно.
Так, напоминаю, что такое тремофубини.
Ну, давайте в терминах наших вероятностных пространств, очень неважно, можно для любых мер то же самое делать,
но будем ее применять только в таком случае.
Значит, пусть у нас есть дикартовое произведение, то есть мы будем использовать это,
и, соответственно, дикартовое произведение сигмалью, которая на этих двух омек задана,
и дикартовое произведение мер.
Значит, это есть дикартовое произведение двух вероятностных мер.
Значит, это есть дикартовое произведение двух вероятностных пространств.
Омега-1, f1 и p1, и омега-2, f2 и p2.
Сейчас мы будем применять, ну да, мы будем применять для вероятностных вещей.
Хорошо.
Я напомню, что такое дикартовое произведение.
Значит, дикартовое произведение множество мега-1 и мега-2 – это обычное дикартовое произведение.
Дикартовое произведение сигмаль slice, это просто минимальная сигма-алгебра,
которая содержит все дикартовые произведения множеств из этих сигмалгебр.
сигма-алгебр, и декарта произведения мер мы уже тоже о нём говорили, то есть
P1 крест P2 от A1 крест A2, это есть произведение вероятностей, а на всю сигма-алгебру оно
продолжается единственным образом. Вот, значит, есть декарта произведения двух вероятностных
пространств, и есть какая-то случайная величина, и предположим, что интеграл от неё конечен,
значит, пусть интеграл по мега один креста мега два от модуля кси на dP1 крест P2, он конечен,
да, где кси это какая-то случайная величина на нашем декартовом произведении. Вот, тогда
можно переставлять местами, да, можно сначала там по мега один, по мега два интегрировать,
либо наоборот, то есть вот этот вот интеграл от кси dP1 крест P2, это есть интеграл по
мега один от интеграла по мега два кси dP2 dP1, либо наоборот, сначала по мега два, потом по мега один.
Вот, значит, как это нам помогает? Ну, давайте возьмём теперь, собственно,
к нашей задаче. Пусть у нас есть две независимых случайных величины.
И спрашивается, каково распределение суммы? Каково распределение кси плюс это?
Ну, давайте напишем функцию распределения. И вспомним, что это есть не что иное, как вероятность
того, что эта сумма меньше, чем x. То есть, на самом деле, можно на это посмотреть ещё
по иначе, как на распределение вектора, да, вы можете взять распределение вектора составным из кси это,
на множестве таких точек уv, что у плюс v меньше, чем x. Да, вы просто в R2, вы берёте такую, вот у вас есть R2.
Такая плоскость. Значит, вы берёте множество всех пар уv, таких, что они там суммейшены, чем x,
да, то есть такая вот прямая. И вас интересует множество всех точек, которые находятся под этой прямой,
и у вас задано распределение вероятностей, которые соответствуют вашему вектору. И на самом деле,
вот смысл этого распления вероятностей, мера вот этой полуплоскости, это в точности, на самом деле,
ваша изначальная функция распределения. Чему равна мера множества? Ну, она равна интегралу
от индикатора этого множества, правда ведь?
Да, то есть, если вы берёте индикаторную функцию, просто воинтегрируете и вы получаете просто в
точности меру соответствующего множества. То есть, если я вот этот индикатор проинтегрирую по
распределению вероятностей нашего случайного вектора, я в точности получу, конечно, нужную мне
вероятность. А это в точности интеграл из теремофубии. Благодаря тому, что этот интеграл не
превосходит единицы, то есть, он конечен. Я могу менять местами, интегрировать по очереди, то есть,
например, написать так. Сначала по u проинтегрировать, а потом по v. Но если я u зафиксировал,
то v будет от минус бесконечности до x-у. Да, значит, и я должен сначала проинтегрировать по
распределению случайного вечноэта, а потом уже кси. Что это за внутренний интеграл такой? Я
интегрирую, на самом деле, индикатор принадлежности множеству от минус бесконечности до x-у. То есть,
это в точности p-эта от множества от минус бесконечности до x-у dpc. А это есть функция
распределения. Я получил функцию распределения это в точке x-у dpc. Вот это называется формула сверки.
Давайте я ее выпишу ярко посередине. Функция распределения x-у в точке x. Это есть интеграл по r.
Функция распределения это в точке x-у dpc. Ну а дальше тут можно еще заметить важную вещь. Во-первых,
если так вышло, что кси является абсолютно непрерывной случайного вечноэта, то интеграл по
соответствующему распределению вероятности можно свести к классической мере либега. То есть,
функция распределения кси плюс эт в точке x будет просто равна интегралу по r от f-эта от x-у плотность
кси в точке u du. То есть, случай, когда случайная вечноэта является абсолютно непрерывной,
мы получаем просто обычный интеграл либега по классической мере либега от произведения
функции распределения плотности в точке u. Давайте внимательно посмотрим на эту формулу и увидим,
что у нее есть понятная интуиция. Вероятность того, что сумма не превосходит x, это есть интеграл по
u. Про интеграл мы думаем на самом деле как про сумму. То есть, это как бы сумма по всем возможным
значениям u. Когда мы думаем про интеграл как про сумму, мы про плотность можем думать как
про вероятность попадания в точке u. То есть, если бы мы заменили абсолютную непрерывную
дискретность, то есть, если бы кси была дискретной, мы бы здесь написали сумму по всем возможным u,
а здесь это было бы вероятностью того, что кси равняется u. И это была бы очень естественная формула,
она бы нам говорила, что, ну, понятно, что если кси равняется u, то мы получаем вероятность того,
что это не превосходит x-у. То есть, конечно, функция распределения суммы в точке x,
это просто сумма, функция распределения at в точке x-у, умножить на вероятность того,
что кси равняется u. Да, вот эта формула, то есть, для случая, когда кси дискретно,
она является очевидной. И оказывается, она естественным образом переносится на
абсолютно непрерывный случай, вот как мы увидели. Более того, если ещё и это абсолютно непрерывно,
то тогда можно найти плотность суммы, тогда сумма тоже будет абсолютно непрерывна. Её плотность,
ну, смотрите, если бы всё было дифференцировано по x, то вы могли просто обе части этого равенства
продиференцировать по x, вы получили вот что. Вы получили вот что. Ну, не факт, конечно,
что функция распределения является дифференцированной, но, тем не менее, всё равно
это райстудент. Тем не менее, всё равно плотность суммы равна такому интегралу. Ну, это надо
доказывать просто из определения плотности. Вот давайте предположим, что она равна такому
интегралу, поставим функцию распределения, увидим, что это действительно так. Давайте это проделаем.
То есть, найдём интеграл от минус бесконечности до x от вот этой вот плотности, которую мы
предположили, что является плотностью, от этой функции, которую мы предположили, что является
плотностью. То есть, это будет двойная интеграл. Ну и дальше, опять же, потеряем фубинию, мы можем
поменять местами пределы интегрирования и написать, что это есть интеграл по r,
по x от u, на интеграл от минус бесконечности до x, по это от t-у, dt, du. Вот. Ну, в силу того,
что вот эта p-eta, это есть плотность, случайная величина eta, вот этот интеграл, это, конечно,
в точности функция распределения. Смотрите, можно замену сделать, можно написать это как,
значит, если t-у заменить на y, мы получим тут плотность от точки y до y, а пределы интегрирования
будут от минус бесконечности до x-у. Вот. Ну и тогда видно теперь, что это в точности функция
распределения. Это функция распределения at в точке x-у по определению плотности. И,
значит, мы получаем произведение по x от u на функцию распределения at в точке x-у du. А это и есть,
собственно, наш функция распределения к c плюс at. По формуле свёртки это действительно функция
распределения к c плюс at в точке x, что и требовалось. Значит, да, действительно, даже когда не
дифференцируем всё хорошо, мы можем считать, что вот именно по такой формуле считается плотность
суммы независимо случайных причин. Есть какие-то вопросы? Давайте разберём задачку
на применение формулы свёртки, на этом закончим. Ну, я не люблю сложные задачи решать. Это вы любите
сложные задачи решать. Я буду решать простые задачи. Значит, пусть x-и это равномерные на
отрезке 0,1. Значит, хотят от меня плотность суммы. Как вообще сумма распределена? Какая у неё плотность?
Ну, смотрите, вот складываем мы две независимо случайных величины равномерно сплённых на отрезке
0,1. Они, конечно, станут распределены на отрезке от 0 до 2. Ну, то есть, вот эта сумма,
она будет принимать значение от 0 до 2. Вы спросите, а равномерно ли? Ну, конечно же,
неравномерно. Да, потому что с краёв. Принять значение 0 можно только, когда обеи случайно
равны 0. Принять значение 2 можно только, когда обеи случайно равны 1. То есть, понятно,
что чем ближе мы к центру этого отрезка, тем больше дуэль, тем больше плотность. The density
по идее плотности должна как-то вести себя так. Она должна к концу этого отрезка 0,2 уменьшаться,
а к середине отрезка увеличиваться. Давайте увидим, что это действительно так.
Но у нас есть формула, которая говорит, что плотность xi плюс et в точке x, это есть интеграл по r от
плотности это в точке x минус u, плотность xi в точке u du. Ну а плотность равномерноспределения
это просто индикатор принадлежности соответствующему отрезку по длину отрезка. У нас
отрезок имеет длину 1, поэтому плотность это это будет просто индикатор того, что x минус u
лежит в отрезке от 0 до 1. Ну а вторая плотность это индикатор того, что u лежит в отрезке от 0 до 1.
Ну и сразу становится понятно, что x должен попасть в отрезок от 0 до 2, иначе тут все индикаторы
внуляться. Значит, поэтому получаем... так, что получаем? Во-первых, интеграл будет от 0 до 1
от индикатора того, что x лежит между u и u плюс 1. Это если x от 0 до 2 и 0 иначе.
И 0 иначе. Ну и вот давайте, если x от 0 до 2...
Сейчас.
Давайте x сначала от 0 до 1, рассмотрим две ситуации. Да, сначала x от 0 до 1.
Тогда u плюс 1 и так больше забраен, чем x. То есть вот это условие, оно выполнено автоматически,
потому что u лежит от 0 до 1, значит, у плюс 1 лежит от 1 до 2. То есть у нас имеет смысл только вот
это условие. У нас получается, на самом деле, интеграл от 0 до x в точности x. Если же x лежит
в отрезке от 1 до 2, то тогда уже x будет больше равно, чем u. То есть вот это условие будет
выполнено автоматически, потому что u от 0 до 1. И, значит, интересовать нас будет только второе условие,
а именно u больше либо равно, чем x минус 1. То есть плотность будет равна интегралу от x минус 1 до 1
d u, что равно 2 минус x. Теперь мы можем нарисовать плотность. Мы можем посмотреть, как она выглядит.
И выглядит она будет вот так. Ну, как я и сказал. То есть вот есть точки 0, 1 и 2, и она ведется
следующим образом. То есть до точки 0 она, понятно, 0 равна. Дальше она равна, просто идет под углом 45
градусов и потом обратно к нулю. Потом снова равна нулю. Вот такая вот плотность будет у суммы двух
независимо случайных величин, равномерных на отрезке 0 и 1. Все на этом. Есть ли какие-то вопросы?
Вопросов нет. Хорошо, работайте. Увидимся, дай бог, в аудитории в следующую субботу в
наше обычное время. До свидания. Всем спасибо, до свидания.
