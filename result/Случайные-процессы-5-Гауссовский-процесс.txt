Вероятностная мера, вероятностная мера, это я в прошлый раз уже начал говорить, но это давно уже было.
Вероятностная мера Нью-Найерана.
Ганусовская, если ее преобразование в фурье, которое такой вот формулой сдается, имеет вид вот такому углу.
Где А вектор, значит А вектор АК, это квадратичная форма.
Ну и этот вектор А, он задается вот таким вот условием.
А оператор, оператор, как говорится, он задается, ну в частности его квадратичная форма, он будет получена вот из такого района.
Ну и обратно, если данный, понятно, что этот оператор из этого района, видно, что он неотрицательный, неотрицательно определенный, то есть его квадратичный, он симметричен, он симметричен, это очевидно из формулы.
Ну и понятно, что его квадратичная форма неотрицательная.
Ну и обратно по таким двум объектам сдается мета.
А значит, ну образ, образ стандартный, галзовский метр, ну стандартный, это когда мы мылю пика динамичной кераши.
Значит, при отображении, кумафинном отображении, теперь, значит, случайный вектор галзовский,
значит, если, если его распределение галзовский, ну это относительно тому, что все линейные комбинации галзовские и случайные величины.
Значит, обратите внимание, это требование сильнее, чем отдельная галзовая компания.
Вот в качестве упражнения полезно уметь переводить пару галзовских случайных величин, для которых вектор не будет галзовским.
Значит, тут не только идентичные эти галзовские, но еще и линейные комбинации, это более сильное требование.
Значит, это все делается довольно просто и полезно уметь проделывать качество упражнения с помощью этого характеристического функционата, преобразованного в виде.
Вот, теперь галзовский процесс, это непосредственное обобщение вот этого, значит, определение.
Значит, случайный процесс с каким-то временем T галзовский,
а если все конечномерные распределения галзовских,
ну и понятно, что это равносильно тому из вот этого замечания, что все вот такие линейные комбинации галзовские случайные величины.
Поэтому это такое совершенно прямолинейное обобщение вот этого определения, в котором фактически время конечное.
Теперь, значит, этот процесс, галзовский процесс, однозначно, в смысле, что его распределение конечномерное, однозначно определяется средним.
Значит, среднее, давайте будем, ну скажем, M, F, это надо ожидать, все от такой функции средней.
И кавариационные функции, ну еще это называют иногда кавариацией или корреляционной функцией.
Кавариационная функция, это функция двух переменных,
и это просто кавариация вот этих, коэффициент корреляции, вот этих двух галзовских случайных величин.
Значит, давайте посмотрим, почему это так.
Ну, это так, потому что речь идет о конечномерных распределениях, то есть мерах на РН.
Галзовская мера на РН, как мы видели, определяется своим средним и кавариационным оператором.
Поэтому это, так сказать, ничего нового, это просто констатация вот такого конечномерного факта.
А теперь, значит, вот эта функция, кавариационная функция, она не отрицательно определена.
Ну, в смысле не отрицательной определенности матрицы.
Значит, это означает, что вот такие вот всевозможные, всевозможные вот такие квадратичные формы оказываются не отрицательными.
Ну, откуда это видно?
Значит, откуда, давайте посмотрим, откуда это получается.
Ну, для этого нужно просто понять, что это за выражение такое, откуда оно взялось.
Ну, более-менее понятно, что если что-то не отрицательно, то это скорее всего из-за того, что оно чей-то квадрат.
Но чуть более, чуть более, так сказать, тонкое наблюдение в этом направлении, это когда, это интеграл чего-то.
Ну, вот здесь, значит, смотрите, что будет.
Значит, если взять вот такую вот сумму, значит, вот такую вот сумму взять, возвести ее в квадрат и взять мат ожидания.
Ну, и раскрыть, как там полагается, если вы еще не забыли, как там полагается раскрывать квадрат с суммой, то вот должен получиться параллельно один.
Но я не рисую раскрывать, поскольку я уже давно тренировался, но попробуйте.
Вроде бы это получается вот то, что там написано.
Теперь это дает и обратную импликацию, а именно верна такая диаленда, впоследствии диалена Колмогора.
Значит, если m произвольная функция на множестве с этим параметрическим t.
Так, значит, смотрите, и дана функция, не отрицательно определенная на t на t, то существует Гауссовский процесс.
С со средним m этой функции t и к вариации k. То есть по двум таким объектам.
От первого вообще ничего не требуется, а от второго требуется неотрицательная определенность в этом смысле.
Это простое следствие теоремы Колмогорова.
Значит, доказательства.
Значит, проверяем согласованность конечномерных распределений.
С помощью следствия теоремы Колмогорова в терминах преобразования фурье.
Значит, смотрите, у нас что есть.
Значит, у нас есть конечномерные распределения.
С фурье вот такого вот вида экспонента.
Сумма лжи этой единицы до n.
Вот так выражается.
Здесь будет стоять k, t, житое k, t, житое y, k, t.
Вот такое вот фурье.
И нам нужно, чтобы ограничение.
Нам нужно, чтобы ограничение на y, m равное нулю совпало с тем,
что дается без y, m.
Значит, если убрать из этих точек t1, tn убрать tm, то получится аналогичное выражение.
И нужно, чтобы оно совпало с тем, которое здесь получится, если y, m взять равным нулю.
Но очевидно, что так оно и будет.
Поэтому здесь, видите, абсолютно ничего не требуется.
Но, конечно, нечто требуется.
Положительная определенность этой функции k, t, это, конечно, убрать нельзя.
Но в остальном, видите, абсолютно ничего не требуется.
Теперь давайте посмотрим, когда есть процесс, что нужно,
тем самым теорема доказана, что нужно, чтобы был гауссовский процесс с независимыми превращениями.
Давайте такой вопрос поставим.
Здесь пока что абсолютно общая ситуация.
Значит, t было абсолютно произвольное, непустое множество.
Но когда начинается разговор про независимые превращения,
то здесь t, это часть R.
Ну, как правило, у нас это отрезок неотрясательный или луч неотрясательный.
И даны бывают, значит, phi, phi t, phi s, phi s t, это фурье разности, когда s меньше t.
И вот у нас в этих терминах был критерий.
Некое соотношение должно выполняться вот на такие.
А именно, когда вы возьмете промежуточную точку и умножите вот это на это,
то должно произойти сокращение u должно быть вот так.
Давайте рассмотрим ситуацию, чтобы упростить немного дело.
Давайте возьмем ситуацию, когда средняя ноль.
Ну, понятно, что общий процесс получается просто добавлением некой функции не случайной к процессу с нулевым средним.
Поэтому большинство вопросов про гауссовские меры решаются для центрированных процессов.
Значит, тогда получается, тогда остается только вот эта функция в двух переменах.
Что-что берем? Ну, для упрощения дела.
Ну, чтобы процесс стал центрирован, чтобы не возиться еще со средним.
Ну, просто чтобы упростить немного, чтобы параметров стало меньше.
Потому что... Нет, это на корреляцию не повлияет, но это, конечно, повлияет, так сказать, на приращение, это, конечно, повлияет.
На что не повлияет? На независимость приращения не повлияет, да.
Ну да, но на распределение повлияет.
Но просто чтобы упростить вычисление немножко.
Ну и, так сказать, чтобы менее громоздкие были выражения.
Значит, смотрите, тогда для центрированного процесса только вот эта функция есть.
И давайте посмотрим, какое распределение у разности.
Значит, какое распределение разности.
Ну, когда s меньше, чем t. Давайте посмотрим, как его вычислить.
Ведь вот эта штука, это Fourier.
Ну, можно написать так, что phi от s и от y.
Это e в степени минус одна вторая.
Ну, дисперсия. Значит, y квадрат. Тут будет и дисперсия.
Сигма st. Сигма st.
Значит, это дисперсия. То есть это вот эта вещь.
Вот видите, что получается? Вот такая вещь получается, дисперсия.
Значит, как она выражается через кавариационную функцию?
Ну, тут нужно раскрыть квадрат.
И смотрите, что получится. Получится k от tt плюс k от ss и минус 2kst.
Значит, вот получается такой ответ.
А теперь давайте...
Вот давайте это сюда подставим.
Значит, смотрите, что здесь происходит.
Здесь перемножаются какие-то экспоненты. И тут какая-то экспонента.
Но когда экспоненты перемножаются, то у них вот эти вот складываются.
И поэтому смотрите, какое соотношение получается вот здесь.
Тут на доске как раз удобно можно вмелым вписать.
Значит, смотрите, какое соотношение получается.
Значит, получается так. Давайте я сначала перепишу в терминах просто дисперсии.
Su плюс...
Сигма ut. Это должно быть равно сигма st.
Вот в терминах дисперсии.
А дисперсии вот так выражаются через кавариационную функцию.
Давайте посмотрим, что это дает.
Вот это соотношение.
Ну, некое соотношение на дисперсии, которое по той формуле что-то дает.
Если подставить в эту формулу вместо вот этих сигм, подставить кавариационную функцию,
ну, у вас получится некое соотношение на кавариационную функцию.
Но теперь давайте мы сделаем еще одно упрощение,
которое, конечно, не всегда можно делать, но мы предположим еще дополнительно.
Если больше ничего не предполагать, то вот у вас получаются критерии независимости перерощений гауссовского процесса.
Тут он коротко написан в терминах дисперсии, но если вы сюда это подставите вместо дисперсии кавариационную функцию,
ну, у вас немножко более длинное соотношение получится.
Ну, в нем что-то сократится.
Посмотрите сами, что получится, если сюда подставить вот такое соотношение.
Ну, естественно, для каждой пары.
Тут, конечно, кое-что сократится, потому что тут будет квадрат этого, и тут будет квадрат этого.
Тут будет квадрат этого, и тут будет квадрат этого.
Но здесь еще, видите, квадрат с У, которого там нет, в правой части.
Но зато еще будут их вот такие попарные.
Ну, будет некое соотношение, посмотрите, что получится.
Но чтобы получить нечто более осязаемое, то мы предположим еще, что АК от СТ это функция разности.
Ну, давайте будет функция ПСИ какая-то.
ПСИ от t-с.
Значит, это функция двух переменных.
Ну, вообще говоря, она ни с какой стати не обязана быть функцией от разности.
Но мы знаем, что у Винеровского процесса...
Например, значит, Винеровский процесс, он нам дает вот такую функцию.
Значит, сейчас, только я нехорошо сказал.
Сейчас, сейчас, сейчас, нехорошо, я нехорошо сказал.
Час не так.
Час...
Значит...
Час нехорошо.
Дайте я посмотрю, как я тут хотел, как я тут хотел сказать.
Сейчас, не КАТС, конечно, я вижу, что-то я ерунду написал.
Не КАТС, конечно, а СИГМА.
Сигма, вот это.
КАТС, конечно, не может зависеть.
Ну, может, но это будет в очень выраженной ситуации.
Я смотрю, что-то у меня странное получилось.
Вот так, вот.
Пусть АК от СТ это функция.
Пусть вот так будет.
Вот у Винеровского процесса.
У Винеровского процесса как раз вот эта С от Т будет равна Т-С.
Вот так будет.
Сигма не КАТС, а Сигма должна от разности зависеть.
Значит...
Ну, это какое-то такое разумное дело.
Значит...
То есть вот...
Ну, это какое-то такое разумное условие.
Значит, раз есть процесс, который этому удовлетворяет.
Тогда смотрите, что здесь получится.
Тогда здесь вот это, вот это нижнее, я прямо под ней напишу,
Получится вот что.
Так, видите, вот какое соотношение.
А значит, как это еще по-другому можно сказать?
Значит, иначе говоря, это можно так переписать.
Вот давайте...
Ну, вот это сделаем...
Вот это сделаем аргументом В.
А вот это сделаем аргументом В.
Значит, вот это стало В.
А вот это стало В.
Так.
И кто здесь тогда стоит?
Здесь тогда стоит их сумма.
О, видите?
Вот такое соотношение, видите, получилось.
Такая вот агитивность функции psi получилась.
Так.
А вот если...
Ну, таких функций много.
Таких функций много.
Но если...
Если psi непрерывно, ну или измеримо по либегу,
то...
А...
Пси будет обязательно...
К...
Умножить...
Ну, линейная такая функция будет обязательно.
В других нет решений.
Видите?
Вот у этого уравнения, в классе произвольных функций,
есть crisis operator,
и это просто никак не работает.
в классе произвольных функций решений очень много ну и они так сказать ну в общем необозримом много но
если на решение наложить ну довольно таки разумное ограничение
что оно хотя бы измеримо полибегу они оба какая функция то оказывается класс решений
редко сокращается получается фактически
что с точностью до множителя с таким условием есть только виноровский процесс так значит вот при к
при к равном единице получаем
получаем виноровский процесс
так значит вот это дает также
это дает также
его существование
потому что
можно в обратную сторону пойти у нас же это все были равносильные условия и
можно пойти назад и
взять виноровский процесс ну то есть
взять вот такую функцию и сказать а она удовлетворяет этим условиям значит есть для нее
соответствующий процесс но вот он как раз и будет виноровский правда в нашем определении от виноровского еще
была просьба о непрывности траектории но как мы видели это
автоматически вытекает для модификации процесса так что тут важно просто получить
какой-то процесс с данными конечно мерными распределениями как ну
какие мы хотели от виноровского процесса а непрывность траектории она уже
отдельно появится поэтому видите вот значит
значит вот еще один способ
ну он не сильно конечно отличается от того первого тот первый был просто предложение непосредственно проверить
выполнение теориям колмогорова для
ожидаемых
конечно мерных распределений это ну надо признать первым способом а это ну так сказать видите тут
вообще практически ничего не надо
считать кроме того что только заметить что вот для виноровского процесса
вот благодаря этим всем ситуациям вот ну выполнено нужное то что потому что для него вот такое равенство
ожидается и все и больше ничего уже проверять не надо то есть тут вычисления сведены к минимуму а
ну в общем я бы даже сказал что их практически нет но правда так если
оглянуться назад то видно конечно что
часть этих вычислений просто запрятана было в другие места вот там где мы
проверяли с помощью
следствие теориям и колмогорова
существование гауссовского процесса потом вот здесь мы некие манипуляции производили с
преобразованиями фурье и с
дисперсиями там тут тоже были какие-то мелкие вычисления так что конечно так по-честному то не ну
абсолютно никуда они не делись но вот конечное вычисление в виде получилось очень простое и
смотрите что еще
знаменательно
получилось у нас вот из этих наших рассмотрений получилось следующее
что если у нас
процесс гауссовский с независимыми
приращениями
да еще вот такой вот
ну как бы они еще
стационарно эти приращения то есть вот эти дисперсии зависит только от разности то такой процент
он есть винаровский и фактически он один всякий другой
получается умножением этого процесса на констант так так что видите у нас что так такая получилась
характеризация уникальности винаровского процесса
но мы дальше увидим
что винаровский процесс он еще там в разных ипостасях тоже уникальный вот получается так что
если на процесс
наложить несколько
ну ну так сказать никак друг с другом не связанных условий то очень часто он оказывается
именно винаровским вот всякие комбинации условий там связанный с мартингальными
свойствами там с марковскими свойствами еще какими-то вот всяких процессов много но как только мы
изучаемые
свойства начинаем требовать одновременно ну вот так зачастую оказывается что только винаровский процесс и
годится так так что вот вот вот в этом еще его уникальность
так теперь
теперь несколько замечаний
уже отдельно про винаровский процесс значит вот он у нас появился уже можно сказать двумя способами
так еще двумя способ а да еще
значит еще давайте
значит вот еще такой пример
значит давайте такой пример
вот такая функция давайте возьмем вот такую функцию
как т т тождественная равна единице а кат
ст
0
при с
неравном т такая вот очень видите очень выраженная такая функция на диагонали единица вне диагонали 0 ну можно проверить что она
значит не отрицательно определенные это соответствует
это соответствует
гауссовскому
процессу
с независимыми
с независимыми значениями
то есть все значит вот эти попарно независимые
попарно независимые ну и и
ну вот такие вот
тоже независимый
вот
такой так сказать базовые теории вероятностей
последовательность независимых случайных величин это ну вот один из таких
фундаментальнейших исходных пунктов потом с ним ну с ним что-то дальше происходит но ну и вот скажем последовательность
независимых гауссовских случайных величин это нечто такое очень стандартное классическое с чего многое начинается
значит если на это посмотреть с натурально как на процесс с натуральным временем то вот как раз получается вот такая ситуация но
вот если время не натуральное они прывное то как ни странно вот такой прямой аналог
последовательности независимых случайных величин
в приложениях не возникает то есть видите ну теоретически процесс то есть но только почему-то нет разумных задач с ним связанных вот когда время
натурально есть
множество разумных задач но как только время становится континуальным почему-то вот такой процесс хоть он и есть он куда-то пропадает вот
вроде бы как
нет разумных примеров там физических или иных а
винаровский процесс у него он он как раз очень разумный всюду возникает но у него
значения как раз таки зависимые у него приращение независимые а вот сами значения у него в высшей степени
так сказать зависимым оказывается так
значит так что видите вот
такое значит ну какой-то такое вроде бы
проявляется отличие вот ну время в времени счетного от несчетного вот вот
я на это хотел обратить внимание
так теперь
теперь значит некоторые дополнительные свойства винаровского процесса
значит дополнительные ну это так сказать к сведению
дополнительные свойства винаровского процесса
значит а значит первая важная теорема как его можно еще третьим способом получить
значит теорема значит пусть
ксиенные
независимые
независимые
стандартные
гауссовские случайные величины так и пусть ен
ортонормированный
базис
в л2 ну на отрезке на каком-то там от нуля до т
так
значит вот мы хотим на отрезке с помощью этих объектов построить
винаровский процесс оказывается его можно задать явной формулой такого
вот так сказать на первый взгляд довольно-таки простого вида
значит тогда
ряд
вот такой вот ряд
значит это
значит где фиэнные это первообразные от этих еэнных
входится
сходится равномерно
при
почти всех омега то есть видите этот ряд от функции двух переменных его и вот утверждается что если омега зафиксировать
то он будет сходиться
равномерно но только так будет не для каждого омега для почти всякого так значит и его сумма
значит и
результат который получится
винаровский процесс
вот это довольно удивительное явление особенно удивляет здесь что что
не важно какой
ортонормированный базис вы взяли
ну например можно взять
базис
тригонометрический например ну или еще какой иной вам
абсолютно это не важно и что еще характерно
в общем-то для любого базиса
доказательства сходимости трудная
ну для некоторых чуть-чуть легче но вот не для какого базиса
доказательства этой теоремы не становится простым вот ну это нужно знать как просто как полезный факт
вот теперь еще
пара замечаний
значит значит еще одна теорема
начитая рема
значит
пусть
пусть альфа значит это число
а
меньше 1 2
тогда
существует случайная величина
с альфа от омега значит такая
что
все от
ксе от t от омега минус ксе от с от омега
оценивается
через с от альфа
от омега на t минус с
степени альфа
ну значит это почти всюду
при почти всех омега и сразу для всех т ну или можно или можно взять
модификацию процесса у которого так будет для всех омега и для всех
и для всех т ис то есть что оказывается
оказывается что
процесс траектории процесса гельдеровский порядка альфа так
но альфа никакое угодно а почему-то меньше 1 2
ну а почему не годится
1 2 это более менее
понятно ну 1 2 и больше
значит почему не годится 1 2 и больше ну потому что если вы возьмете
t плюс дельта
минус
ну вот так возьмете вот такую вот штуку и поделите на корень из дельта так
то это получится
стандартная
стандартная галсовская
так величина
ну ну и вот из этого
можно извлечь что вот для уже для альфы одной равной 1 2 это не пойдет но в качестве
упражнения вот докажите что вот используя это замечание
докажите что альфа равная 1 2 или больше в этой теории не годится
ну в частности частности конечно
траектории не являются
липшицевыми
но тут даже с траекториями даже немножко хуже
насчет значит липшицысти
траектории
значит
значит еще одна теорема которая нужно знать просто как ну полезно не то что нужно полезно знать как факт а
значит почти все
вот такие вот
траектории
почти все траектории они имеют
не имеют точек дифференцируемости
и
обладают
обладают неограниченной
вариацией
на всяком отрезке
то есть вот значит гельдеровость есть а
дифференцируемости нет и ограниченности вариаций тоже нет
ну вот то что в отдельно взятой точке нет
дифференцируемости это довольно очевидно потому что если вы зафиксировали t и
уже поделили на корень из t это уже у вас получилась стандартная гауссовская а если вы еще додавили
еще одним корнем что получилось разностное отношение то у нас получилось что вы стандартную гауссовскую
делите на очень что-то маленькое когда это маленькое идет к нулю это будет
но идти ну в общем никакого предела разумного не будет но в теореме
утверждение более сильное не то что в каждой отдельной точке нет дифференцируемости а то что вот вы взяли выборочную траекторию и
у нее вообще не будет точек дифференцируемости
то есть это какая-то такая очень странная вроде бы физически наблюдаемая траектория
у которой некоторая регулярность есть
вот типа
значит гейдоровости а
дифференцируемости нет
ну правда в этой траектории есть такая более слабая
на дифференцируемости такая дробная дифференцируемость они вот там
принадлежит принадлежата некоторым так поэтому так называемым классовым классом бесово функций
дробной дифференцирую есть и но вот такой честной дифференцируемости нет
ну и наконец последнее так значит последнее ли значит что я еще хотел сказать
значит про
значит про
винаровский процесс это еще одну теорему привести тоже без доказательств он очень
полезную она она выглядит элементарно но доказывается ну я бы не сказал что уж
очень элементарно но вот может подумать как ее доказывать у вас на
дискретный какой-то вернее не дискретная вариант дискретным временем
наверное этого был значит теорема такая
арема такая значит с вероятностью с вероятностью единица верны вот какие
равенства ну во втором этих равенств процесс
надо взять на всей полуаси
значит верхний предел
значит это называется закон повторного логарифма
видите тут не пределы а верхние пределы
говорит о том как себя траектория ведет на бесконечности и в нуле
вот два таких предела равны по единицей между ними связь этими пределами есть но это
данном случае нам не важно вот поле полезно знать что видите такое некоторое такое
а симпатическое поведение процесса в нуле и на бесконечности но но это вот
еще раз подчеркну что это не предел а это верхний предел
значит верхний предел ответствен ну как бы за максимальную осцилляцию так и вот
когда какая-то и регулярная значит траектория как-то осцилирует то ну вот
там она значит так условно говоря вот картинка примерно такая значит
картинка примерно такая значит вас какая-то функции есть вот какая-то вот
такая регулярная функция а случайная и регулярная траектория
она вот как-то вот так себя ведет так значит это ну это вот в 0 так вот
видите, получается, что процесс он симметричный, он положительный, отрицательный, тут модуль по
этому стоит, и поэтому в нуле, видите, значит эта траектория, она как-то идет в ноль, ну так очень
нерегулярно, асцелируя, и вот как бы зажато, ну зажато это только не совсем правильно, потому
что я так нарисовал картинку, как будто она правда зажата, но это на самом деле реальная картинка не
такая, это, видите, это всего-навсего говорит про верхний предел, это значит, что эта штука
выскакивает за эти границы, но, так сказать, условно говоря, все меньше и меньше, поэтому вот
картинка не соответствует точному утверждению, но вот, так сказать, примерно передает дух
асцеляции, ну и аналогично на бесконечности, видите, аналогично на бесконечности, то есть,
иначе говоря, траектория, значит, ну как-как, у нее какие-то всплески бывают, так, и вот
типичные всплески это вот такие, но это не значит, что процесс не может подняться за этот всплеск,
он может подняться, но только со временем он как-то относительно все меньше и меньше вылезает,
так вот, абсолютно он все равно может очень сильно вылезать за эту границу, но вот это отношение
говорит о том, что такое относительное вылезание за эту границу небольшое, значит, на бесконечности,
ну тоже, видите, получается, что он как-то вот так асцелирует, у него какой-то размах, и вот,
вот типичный рост вот такой, ну вот у вас, наверное, в теории вероятности, может быть, там был или
без доказательств такой факт упоминался, если у вас есть последовательность независимых стандартных
гауссовских случайных величин, то для нее там тоже есть некое с двойным логарифом тоже есть некое
соотношение, значит, вот, так сказать, похожая, ну вот, похожая на вот на эти формулы, так, значит,
и, значит, еще последнее, что, значит, я хотел привести тут про, сейчас, вот, кстати, сколько
времени у нас еще есть? А, полчаса, а, слушайте, ну раз полчаса, то это я вам еще кое-что про Виновский
процесс расскажу, ну, значит, обратить внимание, это все, что я сейчас говорю, это, так сказать,
в билеты не входит, но вещи полезные к сведению, значит, вот еще один класс процессов, который в
последние годы финансовой математики приобрел большую популярность, это у нас будет задача,
но задача не очень банальная, ну, сразу скажу, что, так сказать, свидетельство неполной банальности
этой задачи то, что ее Колмогоров решил, значит, задача вот какая, значит, пусть дано число,
значит, от нуля до ну единицы, единица включается, тогда вот такая вот функция,
значит, вот такая вот функция странная,
значит, где, значит, ну эст, ну в ээр или полу, значит, значит, это кавриационная функция,
а гауссовского процесса, значит, гауссовского процесса, так, и вот этот вот это число, значит,
сейчас только число число число число я не туда поставил, сейчас, почему альфы-то что-то,
я стал смотреть как конспекты, а в конспекте не исправил тоже аж, значит, число тут давайте будет
аж, значит, так, слушайте, вот надо исправить даже и в конспекте, значит, вот это, значит,
это гауссовский процесс получается и вот это число аж это индекс индекс фёрста,
так, ну вот если если альфа то есть если аж вот это никак я от него начну, значит,
если аж одна вторая то это виннеровский процесс, так, значит,
а значит как доказать что есть такой процесс вот значит в сороковых годах колмогоров написал
небольшую заметку окривых в гильбертовом пространстве, так, значит, и идеи этой маленькой
заметки оказавшейся важной нашли воплощение даже в их учебнике с фоминым элемент теории
функций функционального анализа, значит, в этом учебнике есть разделчик маленький написанный
мелким шрифтом, вот это то, что написал колмогоров по мотивам этой своей заметки,
значит, в этой заметке как раз показано, что такой процесс есть, но а как это показать,
ну, точнее говоря, даже самого процесс там в общем-то и не обсуждалось, это вот в последние
годы он привлёк внимание финансовой математики, до этого как-то в основном виннеровский процесс
считался таким вот основным модельным, а вот последние там пару десятилетий вот этот процесс,
его еще называют процессом дробного бровеновского движения, вот он, значит, приобрел какую-то
популярность, но что не очевидно, что не очевидно, не очевидно, что эта функция двух переменных не
отрицательно определенная, так, вот если вы начнете просто в лоб проверять, что она не отрицательно
определенная, то я что-то сомневаюсь, что это увенчается успехом, вот тут, значит, требуется
проявить, ну, некую изобретательность и, значит, доказать, что вот эта функция не отрицательно
определенная, а, значит, ну, как доказывается, что она не отрицательно определенная,
значит, это доказывается так, тут подбирается, значит, подбирается кривая в гильбертовом пространстве,
то есть никакая там не случайная, просто кривая в гильбертовом пространстве, значит, для которой,
ну, вот, собственно, Колмогоров подобрал такую кривую своей этой заметки, для которой выполнено
вот такое вот равенство, значит, после того, как подобрана кривая с такими свойствами, ну,
ее можно явно подобрать, вот Колмогоров это сделал, то, значит, получается, что соответствующая
функция не отрицательно определенная, то есть, как видите, никаких процессов нет, никаких процессов
нет, подбирается кривая, из этого извлекается не отрицательная определенность функции, а потом из
общей теоремы по ней получается гауссовский процесс, значит, вот этот процесс сейчас предмет
там изучения во многих работах, ну, и там не только финансового математика, в общем, довольно
интересный оказался процесс. Так, теперь, значит, теперь еще последнее, что я хотел сказать, это тоже,
ну, у нас в программу не входит, но к Винеровскому процессу имеет отношение и, значит,
давайте это я в виде замечания, значит, оформлю, значит, замечания. Для функции, для функции phi из
0.2 на 0.t, можно определить, значит, можно ввести стокастический интеграл Винера,
значит, phi, а он формально выглядит вот так, так, но это нельзя сделать с помощью, это нельзя
сделать с помощью обычного интеграла, но не интеграл стилть еса. Почему? Потому что вариация
неограничена, так как вариация неограничена, вот по функциям ограниченной вариации можно там ввести,
значит, в римановском стиле такой вот интеграл стилть еса, но здесь-то вариация неограничена,
и, значит, так не сделаешь, значит, как, значит, как это делается, значит, как водится такой
стокастический интеграл. Делается так, делается так, если phi вступенчатая, так, ну, то есть она
принимает, ну, вот давайте, давайте вот где-нибудь здесь я изображу, значит, она до t1 была c1, потом стала
до t2, значит, стала c2, ну и там и так далее, значит, и таких конечное число, так, то тогда,
значит, этот стокастический интеграл, он, значит, сдается явной формулой, будет c1 на wt1
плюс c2 на wt2 минус wt1, ну и плюс и так далее, так, то есть, то есть он тогда, ну, действительно,
как риммоновский, там и риммонов стиль еса суммы, значит, вот в таком, значит, точно стиле, да,
значит, последнее будет cn там на wtn минус wtn минус 1, так, значит, вот так, значит, он задается,
значит, что про него можно сказать, значит, это, значит, и от phi гауссовская, случайная увеличина,
ее средняя, значит, ее средняя ноль, так, значит, ее средняя ноль, а ее дисперсия,
она легко считается, потому что приращение независимой будет c1 на t1, c1 в квадрате на t1
плюс c2 в квадрате на t2 минус t1, ну и так далее, и чему же это равно, и это равно,
очевидно, интегралу от phi в квадрате, так, значит, поэтому возникает, значит, изометрия такая,
значит, видите, получается, что и, и, значит, переходит отображение из l2 в l2 на омега,
так, значит, линейная, линейная и сохраняет норму, так, и, значит, можно продолжить,
значит, можно продолжить на все l2 по непрерывности, значит, продолжаем, продолжаем на все l2 по
непрерывности, значит, у нас задан непрерывный линейный оператор из, значит, линейного
подпространства чудоплотного, значит, из линейного подпространства чудоплотного в l2,
значит, линейный оператор, значит, ну из одного гильбертового пространства в другое гильбертово,
он сначала определен не всюду, а на ступенчатых, ступенчатые образуют чудоплотное линейное
подпространство, на них он линейен и сохраняет норму, ну и, значит, скалярное произведение,
и поэтому его по непрерывности можно продолжить на все l2, ну и получится продолжение тоже,
получится линейный оператор, сохраняющий норму, он задан на всем l2, но его образ не все l2p,
а что, пространство гауссовских случайных величин, вот что получится, то есть образ,
конечно, будет не все l2, значит, вот эта вот полезная конструкция, и, значит, в ней в этой
конструкции phi не случайно, а начали эту конструкцию, но если будет время, в конце я про это скажу,
когда будем говорить про марковские процессы, если, значит, phi сделать случайным, то, ну несколько
более сложная возникает конструкция, но похожая, которая дает интеграл ита, но вот здесь в этой
конструкции это пока такая промежуточная, значит, цель достигнута, построен интеграл,
вот видите, от не случайных функций, но интеграл такой довольно неординарный, потому что, ну,
превращения вот не являются независимыми, значит, вот это вот, так сказать, это я изложил некие
дополнительные вещи про Виннерский процесс, который полезно знать, но, значит, в экзамен это не входит,
а в экзамен что входит про Виннерский процесс, ну, вот его определение, так, и обоснование построения,
ну, вот одним из двух способов, либо прямой проверки согласованности распределений, конечно,
либо вот как сегодня с помощью вот этого Гауссовского критерия, преломленного для процессов
независимыми превращениями, вот, вот, ну, одним из этих двух способов, значит, нужно уметь объяснить,
откуда взялся Виннерский процесс. Так, теперь, значит, следующий сюжет, это некоторые базовые
вещи, связанные с Мартингалами и Марковскими процессами, значит, вот у нас, смотрите, прошли
два конкретных процесса, Пуассоновский и Виннерский, которые надо знать, значит, они представители,
значит, большего класса процессов с независимыми превращениями, Виннерский еще вдобавок
представитель Гауссовских процессов, но Пуассоновский, как вы догадываетесь, нет, так,
а еще два важных класса процессов, это Мартингалы и Марковские, ну, вот, собственно, никаких других
в нашем этом вводном курсе и не будет, и, значит, вот дальше будет некий разговор, ну, довольно
короткий про Мартингалы и про Марковские процессы, но чтобы этот разговор начать,
ну, нужно техническое понятие, условное, условное мат ожидания, потому что и Мартингалы и Марковские
процессы вводятся технически вот через понятие условного мат ожидания, значит, ну, то есть это
опять такой небольшой кусочек, ну, такого, ну, такой смеси меры, теории меры с функциональным
анализом, так, так, сейчас, ну, вот теперь еще раз, значит, сколько, сколько сейчас времени еще у нас
есть? О, слушайте, ну, это как раз, как говорил тот герой, успеем добежать до канадской границы,
так, значит, значит, смотрите, значит, пусть, значит, вот классика, значит, пусть Омега,
значит, Омега, сейчас только, знаете, давайте, ну, конечно, какие буквы не важно, но, но давайте я
сделаю все-таки, чтобы они были больше похожи на то, что конспекте, значит, а, значит, вот,
значит, сейчас, да, только еще какая у меня буква для меры в конспекте, П, ну, пусть П,
я чуть было, вот, смотрите, какой был риск, был риск написать вместо БА, а вместо ПМЮ,
ну, как вы понимаете, разницы нет, но только, вот, если на доске будет так, а в конспекте иначе,
то кому-то может показаться, что это разные вещи, но это одно и то же, значит, теперь, смотрите,
значит, вот это вероятностное пространство, так, и в нем, то есть не в нем, а вот еще дополнительно,
при нем, значит, есть под сигма-алгебра, значит, вот есть под сигма-алгебра, а теперь, значит,
а для, значит, давайте, определение, значит, пусть, значит, интегрируемая случайная величина,
значит, условное мат ожидания или для краткости условное среднее, ну, я дальше, чтобы терминология
была чуть короче, буду говорить условное среднее, значит, условное среднее, значит, вот этой
случайной величины си есть а измеримая, а измеримая случайная величина, вот так мы ее будем обозначать,
для которой, ну, которая интегрируемая, в которой интегрируемая, значит, и для которой,
значит, для которой верно вот такое тождество, давайте, я его здесь напишу,
значит, для всех, для всех, значит, а измеримых, а измеримых ограниченных
случайных величин это, ну, или в терминах интегралов, терминах интегралов получается так,
что интеграл от произведения есть вот, вот что, так, значит, если
если кси лежит еще и в L2, ну, что заранее не предполагается, то вот эта случайная величина есть
артагональная проекция, проекция кси на замкнутое подпространство, подпространство в L2,
замкнутое подпространство, давайте мы его как-то обозначим, сейчас я только посмотрю, у меня в конспекте
есть обозначение для него, так, да, есть, значит, замкнутое подпространство L2A, порожденное,
порожденное, значит, а измеримыми функциями, значит, смотрите, в L2 есть всякие функции, некоторые
из них а измеримые, а некоторые нет, но вы еще спросите, а что значит, что функция в L2 а измеримая, ведь
функция из L2 это же не индивидуальные функции, так, а классы эквивалентных функций, так, поэтому точный
смысл, вот, порожденное, это вот, что такое, это, это вот, что такое, то есть, это, значит,
значит, такими элементами, такими элементами L2, которые имеют а измеримую версию, значит,
саму функцию измеримую можно исправить на множестве мир и ноль, и она перестанет быть измерима
относительно A, но она измерима относительно большой сигмал гибр и бета останется, конечно,
а вот измеримая относительно маленькой сигмал гибр она уже не будет, вот, так что, вот, точный
смысл, это вот эта более длинная фраза, значит, ну, оно и понятно, оно и понятно, потому что в этом
случае, смотрите, что получается, получается, что, значит, вот это соотношение можно записать так,
кси минус, значит, вот это среднее умножить на это, значит, это равно нулю для всех п, ну,
для всех это ограниченных, ограниченных а измеримых, то есть, разность, видите, разность
получается артагонально в L2 всем ограниченным а измеримым, но ограниченные а измеримые всю
доплотны среди квадратично интегрируемых, а измеримых, потому что квадратично интегрируемую
можно в L2 приближать ограниченными а измеримыми, вот, поэтому, если так верно, значит, для ограниченных,
то из этого тогда будет вытекать, что вот это же соотношение верно для всех, это уже вот из этого
гильбертового пространства, ну, а это и значит, что этот вектор артагонален гильбертовому
пространству, но, но, а это значит, что вот это то, что мы вычли, было проекцией на это гильбертово
пространство, значит, так получается доказательство существования условного среднего для квадратично
интегрируемых, а откуда взять существование, если нет квадратичной интегрируемости, так, а только
есть просто обычная интегрируемость, но это можно сделать двумя способами, значит, это можно сделать
двумя способами, ну, кстати, вот еще почему это буквой Е обозначена вроде ожидания, нужно вроде
как буквой О что ли обозначать, ну, буквой О как-то не принято объекты обозначать, кроме редких
исключений там типа артагональных групп, но Е это от слова expectation, так, значит, вот как раз
как раз получится, ну, одно из значений, значит, слово expectation как раз и есть ожидание, так, так
что тут согласуется, ну, впрочем, у этого слова еще разные значения, потому что вот если кто
помнит, например, у английского классика есть, значит, роман Great Expectations, который на русский
однако переводится вовсе не как ожидание, как большие надежды, значит, так что, значит, вот у этого
Е есть какой-то мнимонический смысл, но в нашей учебной литературе это условное среднее также
часто обозначают буквой М, ну, буквой М она вот пришла от математического ожидания, чтобы вот
это, так сказать, длинное, значит, как-то вот закодировать, ну, вот буква М, но буква М, ну,
мне не кажется буквой М хорошим обозначением, и к тому же она уж очень, ну, не традиционно для
других языков, поэтому вот буква Е мне кажется более уместной, уместным символом. А теперь, значит,
если, давайте это я помечу, значит, если кси только в L1, но не в L2, то можно применить,
то можно применить теорему Радона-Никодима,
Никодима, значит, из теории меры. Значит, смотрите, как, ну, как можно применить эту теорему тут,
значит, пусть сначала, ну, давайте я напишу, значит, понятно, что это сводится к неотрицательным,
так, значит, пусть кси неотрицательно интегрируем. Так, значит, берем, берем меру ню, которая
получается из меры, ну, почему ню, ну, давайте х будет, меру х берем, которая получается умножением
вот этой интегрируемой функции на меру П на сигма алгебре А. Так, тогда эта мера получается
абсолютно непрерывно относительно, ну, П тривиальным образом. Отсюда следует, что у есть интеграл от некой
функции, вот когда мы берем множество из этого А. Ну, и вот отсюда следует, что здесь можно взять в
качестве условного среднего, можно взять вот эту РО. Значит, АРО, значит, РО. А измеримая функция.
Так, то есть, видите, мы тут в этом определении забываем, что еще была, что вообще-то большая сигма
алгебра В, она где-то там осталась в стороне, а вот на этой маленькой, значит, применили теорему
Родона-Никодима, получили вот такое равенство, ну, из него там вытекает то, что нужно. Ну, и тогда
общую раскладываем в разность, ну, и вот так делаем. Так что вот такой способ возможен. Ну,
еще можно, так, ну, сейчас уже кажется надо закончить. Значит, смотрите, в следующий раз будет
короткое резюме свойств, ну, с какими-то пояснениями, конечно, свойств условного среднего, потому что это
довольно примечательный объект, такой довольно интересный функционально-аналитический и
вероятностном отношении. И дальше это условное среднее будет фигурировать вот в двух оставшихся
определениях. Значит, у нас еще будут два определения, Мартингалов и Марковских процессов. Так, ну, и вот,
значит, в следующие разы будем, значит, постараться, значит, энергично эти два класса
обсудить. А самый-самый конец, ну, когда будет самый конец, это мы решим и посмотрим, будут решены
там две конкретные задачи, ну, такие вот из старой-старой вероятностной классики, которые вот с
помощью всякой вот этой, ну, технологии более современной, ну, как-то решаются легче, чем вот
когда-то они были решены сто лет назад классиками. И, значит, вот, смотрите, у нас в марте еще, значит,
значит, в марте у нас еще два раза, по-моему, да, сейчас вот сегодня какое число, сегодня 15, 22,
22, два раза в марте у нас, так, встречи. В апреле, я не помню, то ли четыре, то ли пять раз, так, ну,
и вот цель к маю закончить, так, ну, посмотрим, как это удастся, потому что формально там у вас еще
какие-то майские дни, но они какие-то уж очень неподходящие для лекций, вот, а, значит, вот,
ну, как-то у меня, так сказать, у меня большое искушение, вот, как говоря по-армейски, сделать их
днями самоподготовки. Так, все, значит, давайте на этом закончим.
