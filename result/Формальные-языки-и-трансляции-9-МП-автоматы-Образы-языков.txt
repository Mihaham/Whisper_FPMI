О, чудеса! С вами в прошлый раз мы с вами построили конструкцию как SKS грамматики
строить МП-автомат. Давайте быстренько напомним. Мы с вами сказали, что мы строим с вами, у нас есть
правило видов грамматики, а выводит альфа, и мы решили построить с вами такой автомат с магазиной
памяти. Что первый переход у нас будет? Эпсилон снимаем со стека, читаем со входа Эпсилон, снимаем
со стека Эпсилон, на выход кладем С. Дальше мы с вами делаем следующее. Если у нас есть правило
такого вида, то мы снимаем со стека Эпсилон, кладем альфа, читаем Эпсилон, снимаем со стека А,
кладем альфа перевернутая, и для каждого символа алфавита добавляем правило, что мы читаем со
входа А, пишем на вход А, читаем со стека А, пишем Эпсилон. Напоминаю, что для этого символа мы делаем
копию, потому что у нас стекалфавит не может пересекаться с обычным алфавитом. Да, и теперь
мы с вами делаем следующее утверждение. Мы с вами доказываем, что если у нас альфа принадлежит N
объединить сигма, то альфа выводит слово W тогда и только тогда, когда у нас вот это у нас состояние
Q1, Q1 получается на входе у нас слово W, альфа выводит в автомате Q1, Эпсилон, Эпсилон. И мы с
вами в прошлый раз доказали переход с права налево, он был сложнее. Давайте доказывать
переход слева направо. Ну, по классической традиции, как мы его доказываем, эндокс подлиннее
число шагов. База. Давайте мы будем обозначать длину вывода решеткой, количество шагов. Чему равна
решетка в базе? Ноль. Как ноль получить? Как из не терминала или символа алфавита вывести слово W?
Да, значит у нас это может быть только если альфа равно W равно а. Ну, тогда нам надо показать,
что, смотрите, что тогда Q1 такое W альфа. Мы можем просто подставить это все дело, мы получим Q1,
а, а. А это выводит Q1, Эпсилон, Эпсилон. По какой причине? У нас есть правило такое замечательное.
Так как у нас есть правило Q1, а, значит со стека снимаем а, то есть этот случай мы с вами разобрали.
Давайте теперь переход. Пусть мы вывели, для всех шагов меньше чем K, утверждение доказано. Давайте
рассмотрим вывод за K шагов. Тогда у нас есть какой-то не терминал, альфа тогда у нас является не
терминалом, и он за K шагов выводит некоторое слово W. Тогда мы можем сказать, что рассмотрим первое
правило, которое у нас появляется в дереве вывода. Тогда мы за А, из А за один шаг выводим альфа 1,
альфа 2. Какое-то альфа K, давайте альфа МТ. Дальше мы каждый из альфа ИТ раскрываем какое-то
слово WИТ. Так, WМТ, которое будет нашим словом W. Тогда что мы получаем? Напоминаю, что альфа ИТ
у нас будут принадлежать N объединить сигма. То есть это наша правая часть правила. Тогда давайте
соединять. Альфа ИТ выводит ВИТ. Следовательно, по предположению индукции у нас получается что?
Q1, так получается ВИТ, альфа ИТ выводит Q1 и апсилон и апсилон. А дальше смотрите,
что мы получаем. Давайте напишем, что такое Q1, W, A. За один шаг, поскольку у нас есть правило
А, стрелочка альфа 1, альфа K, то мы выводим с вами Q1, W и перевернут эту штуку.
Дальше смотрите внимательно, за ноль шагов. Вот мы раньше никогда не пользовались свойством
рефлексивности в этом отношении. Никогда. Я просто покажу, что выводимость за ноль шагов. Мне
просто надо раскрыть слово W, которое у нас есть. Только у нас не КТ, тут МТ было.
За ноль шагов получаем Q1, WMT, альфа МТ, альфа 1. Теперь что мы с вами можем сделать
из предположений индукции? Кто понимает? Проспаемся. У нас верхний символ на стеке,
альфа 1. А первое слово, которое мы можем прочитать, W1, что мы можем с ним сделать?
Мы можем его считать, со стека все снять и слово прочитать. То есть мы берем и отцепляем W1,
альфа 1. Повторяем так некоторое количество раз. Получаем здесь Q1 и тем самым
доказываем индукционный переход. Вот этот шаг понятен? Просто берем, разворачиваем правила по стеке.
А теперь давайте докажем наше утверждение. Точнее, наш теорем. Что такое, что слово лежит в языке,
задаваемым грамматикой. Это эквалютно чему? Давайте по порядку. Во-первых,
из стартового терминала у нас вводит слово W. Из леммы, которую мы с вами доказали, как мы это можем
переписать. Q1. Так ведь? А теперь смотрите, прикол в чем.
За один шаг обязательно какое правило у нас появится при выводе любого слова.
Посмотрим на нашу цепочку. Вот у нас Q0, вот у нас Q1, мы всегда на стек кладем S.
Поскольку это всегда, то мы можем здесь написать эквивалентность. Потому что это правило всегда у
нас первое. И тогда что у нас получается? Единственное нам надо написать вот так.
А, Q1 у нас всегда завершает состояние. А это чему эквалентно у нас?
Все, доказали теорему. То есть мы из любого K из языка получаем язык, задаваем им по автоанатам.
И доказали, что языки совпадают. Так, понятно ли доказательство этого факта?
Хорошо, теперь давайте подумаем немножечко наперед. Помните, мы в прошлый раз с вами
конструкцию строили для автомата без эпсилом переходов. У нас была с вами нормальная форма
гребах. У нас были правила A, A, B, C. И строили автомат следующего рода. Все правила вида,
которые у нас были, они у нас всегда должны считывать один символ со стека. То есть это A,
A получается для правила A, A, B, C. Вот так. Для правила A, A, эпсилом оно у нас всегда остается.
И остаются такие правила для соответствующих выходов. И дальше мы делали следующее.
Вот это состояние у нас становится завершающим. Если у нас есть правило S, эпсилом. Правила в нашем
грамматике. И что еще мы с вами сделали? Мы сказали, что если у нас есть правило из S,
выводится A, B, C, то вот сюда мы добавляем переход какой. Мы читаем со входа эпсилом,
точнее мы читаем со входа букву A, снимаем эпсилом со стека и кладем букву C, B. Теперь давайте
подумаем на следующем выражение, утверждение. Верно ли в этом утверждении следующий факт?
Вот этот. Ровно тот же факт, который мы с вами доказывали.
Давайте подумаем, верен он или нет. У нас из альфы выводится слово W,
тогда и только тогда, когда мы берем, находимся в Q1, читаем слово W.
Говорим только про Q1 состояние.
Давайте сделаем альфа не S. Тогда это утверждение становится верным. Те же самые
индукционные рассуждения необходимо провести для того, чтобы доказать этот факт.
А теперь давайте немножечко разберемся с первым переходом, который у нас есть.
С выводит W. В случае W равное эпсилом закрывается тем, что у нас Q0 завершающий
состояние, поэтому слово читается. А второй случай, что у нас есть какая-то первая буква.
У в нашем слове, и у нас есть правило следующее, например. Давайте без ограничений общности считать,
что у нас первое правило будет из S выводится A,B,C. Тогда скажите мне, пожалуйста, какой у нас будет
первый шаг. У нас с вами Q0. Слово W нас таки эпсилом. Дальше, за один шаг что мы получаем с вами?
Если у нас правила такого вида. Мы считываем первую букву A в нашем слове. На выходе получаем U,
на оставшемся входе. А здесь переворачиваем C,B. Давайте я на другую доску перейду. Мокрая,
мокрая, практически сухая. Нет, она оказалась мокрой. Еще раз давайте повторим. У нас Q0,
Q1, U,C,B. А теперь смотрите, у нас правило S выводит A,B,C. A,B,C выводит AU. Это значит,
что мы можем разложить с вами U в виде UB и UC. Такое, что B выводит UB, а C выводит UC.
Отлично. А тогда смотрите, опять же, за ноль шагов мы выводим из Q1 UB, UC,C,B. И опять же,
здесь уже используем ту лему, которая будет доказана дополнительно. Вот по аналогии.
Получаем следующее. Значит, из леммы у нас будет получаться, что Q1, UB выводит Q1,
Q1, UC,C выводит Q1, UB. Мы, собственно, подставляем это все. Так, U,C,C. А это будет эквалент,
потому что слово W выводится. В языке называем МП-автомат. То есть, по факту, что мы делаем? Мы,
на самом деле, каждый раз просто снимаем букву со стека. Аккуратненько этот случай прорабатываем.
И прорабатываем первый переход в нашем автомате. А в остальном доказательство ровно аналогичное.
Так, давайте я остановлюсь и спрошу. Вот эта идея понятна?
Такого упражнения осталось провести аккуратненько индукционный переход.
Так, что, движемся дальше? Или еще вопросы есть какие-то? Если есть вопросы, задавайте обязательно.
Так, смотрите, мы по КС грамматики построили МП-автомат. Теперь что нам охота сделать?
Да, по автомату построить грамматику. Отлично. У вас были семинары по КС грамматикам уже?
Строили картинки со скобочным балансом? Все, отлично. Сейчас мы будем их вспоминать.
Давайте я, пожалуй, покажу их на презентации, потому что там они красиво нарисованы.
Чудеса теха все-таки как-никак решают. Так, это мы пролистываем. Это пример, как это все строится.
Смотрите, что мы понимаем? Какого у нас МП-автомат было вида? Мы всегда с вами договорились,
что мы либо снимаем букву со стека, либо добавляем букву на стек. Помните, мы добавляли специальную заглушку,
чтобы мы всегда либо что-то снимали со стека, либо что-то добавляли на стек. А теперь прикол.
Давайте построим график длины стека относительно длины слова. Точнее, длина стека относительно
количество правил, которые мы прошли. Глобально наша задача состоит в том, что у нас есть МП-автомат,
для него надо КС-громатику построить. Давайте обсудим следующее. Где мы изначально находимся?
Предполагаю, что у нас слово лежит в языке, задаваемым МП-автоматом М.
Дальше давайте поймем, где мы заканчиваемся, на каком уровне.
В конце мы заканчиваемся, но при чем мы должны прийти в завершающее состояние.
А теперь давайте поймем. Кстати, если есть тут цветные мелы, это будет офигенно. А тут есть
даже две штучки. Чудеса тихо откладываются. Предположим, что мы с вами поднялись по какой-то
букве А по стеку. Давайте обозначим этот уровень плюс А. И предположим, что мы с вами
прошли здесь из состояния куитое, некоторое состояние кужитое. Вопрос. Вот у нас на стеке
лежит буква А. С учетом того, что мы где-то в конце слова, должны будем снять все буквы
со стека. Что мы можем сказать про букву А? Да, мы в какой-то момент ее сняли. Причем мы понимаем,
на каком уровне мы снимаем эту букву со стека. Да, мы находимся ровно на том же самом уровне,
которое здесь было. Пусть это у нас состояние было куертое и квесттое.
И дальше мы можем отследить тот момент, когда мы с стек сняли еще какую-то букву,
когда мы ушли с этого уровня. Вы же должны были с этого уровня? Возможно, не сразу,
но в какой-то момент мы еще с вами спустимся по другой букве В. Пусть это будет у нас буква ку.
А теперь давайте подумаем в этой штуке. Интересный факт.
Предположим, что у нас с вами мы находились... Вот у нас есть слово W,
которое лежит в языке сдаваемого по автомату. А теперь вопрос, который я хочу вам задать.
Вот у нас от этой точки до этой точки, если мы посмотрим, стек меняется. Вот здесь находимся
со стеком, где буква А последняя. Здесь находимся в моменте, когда буква А последняя. У нас стек
меняется, если мы посмотрим вот эти два снапшота. Нет, не меняемся. А поэтому давайте сделаем
вариант. Мы будем заводить с вами пары состояний А, G, T, R, T. Это именно тот спуск, который снимает
именно эту А. Смотрите, давайте мы сделаем следующее. Делаем отображение из пары состояний QG,
QR. Сделаем правила грамматики А, G, R. Причем мы будем с вами делать следующее, что если у нас...
Это тот вариант, который мы с вами будем доказывать, что если мы...
Так, сейчас, секунду. Вводим слово U тогда и только тогда, когда с Q житого
у Эпсилон выводится QR и Эпсилон, Эпсилон. То есть с ней меняется стек. А теперь прикол.
Давайте посмотрим вот на эту картинку на следующий момент А и ТТ. Давайте подумаем,
что оно должно выводить. Смотрите, у нас А и ТТ не меняет стек. Вот уровень,
которым давали буква. А вот это первый момент, когда мы ушли с этого уровня.
Да, давайте подумаем, как мы это можем написать красивым образом. Переход наш.
Для этого нам нужно написать вот этот переход. Давайте напишем. Пусть у нас есть переход Q и Т.
Сейчас, секунду. Q и Т, значит, по слову... Блин, у меня буква кончается. Вы не против,
если мы русские буквы заиспользуем? Мне понравилась практика с прошлого раза.
По твердому знаку, значит, получается Эпсилон. Переходим в состояние Q. Житое кладем на стеке А,
принадлежит нашему правилам автомата. И второе правило, значит, QRT. Какая? Буква Э пусть будет.
А снимаем со стека, выводим... Что? Переходим в состояние QS и кладем на стек слово пустое.
То есть вот такие два правила зафиксируем. И теперь давайте подумаем, как эквивалентным
способом переписать правила в нашей грамматике. То есть как вот эти вот штуки и вот эту картинку
преобразовать в правила грамматики. Ну, смотрите, здесь мы на выходе какую букву пишем. Твердый знак.
Мы поднимаемся на этот уровень. Дальше что у нас происходит? От Житого до Эртого. Стек не меняется.
А это значит, что мы можем написать? Дальше. Какой S? Как мы обозначаем с вами переходы,
в которых стек не меняется? Как мы можем трансформировать эти правила? Ну, не A, это AGR,
потому что здесь у нас QGT, а здесь QRT. Дальше что? Мы переходим из Эртого в состояние WS.
В состояние E. Так, и дальше. AST.
Добавляем для всех переходов такого вида правила вот такое. Понятно вот эта идея? И тем самым
мы будем доказывать вариант, что у нас так не меняется. Ну, по факту мы с вами, если честно написать,
то мы с вами показываем переходы с правой стороны влево. Опять же напоминаю, помните, когда мы
строили нормальную форму грейбах, мы такую же штуку, то есть построили конструкцию, а дальше из
конструкции вывели индукционный переход, который получится справа налево. Так, база индукции какая?
Давайте подумаем. Как построить базу индукции? Мы хотим сейчас построить следующую штуку,
чтобы каждой паре переходов у нас строилась вот такой вот не терминал, из которого будет
выводиться слово WF только в том случае, когда у нас по сути стэк будет пустой на том же самом уровне.
Смотрите. Да-да-да, мы как раз строим алгоритм, как из переходов МП автоматик построить
переходы в КС грамматики. Не-не-не, нам еще 201 надо доехать. Итак, смотрите, теперь давайте предположим,
когда у нас слово лежит в языке, задаваемым по автоматам. Давайте вспоминать. Когда существует
какое-то кукатое завершающее состояние, что из Q0 слово W epsilon мы читаем кукатое epsilon epsilon.
Это в терминах нашего автомата. Какое правило в грамматике мы должны породить? Какой не терминал
должен отвечать за вот это вот? Смотрим индексы. 0K. То есть это в соответствии ставится терминал A0K.
И как сделать так, чтобы реально в нашей грамматике из слова, ну, из стартования терминала выводилось
слово W. Какое правило добавить?
Нет, ну мы понимаем, что здесь выводится у нас W, а откуда мы выводить это должно?
То есть нам нужно прифигачить нашу конструкцию к стартовому состоянию в
нашей грамматике. То есть будем добавлять вот это правило
для любого кукатое, принадлежащего множеству завершающих состояний.
Так, еще один кейс. Для того, чтобы сложилась наша картинка, нам нужна база индукции. То есть
мы с вами построили индукционный переход, мы по факту с вами уже построили доказательство
теперь нам надо базу индукции построить. За какое количество шагов вот эта вот конструкция
минимальная может выполняться? Какую? Вот это? Да-да. Осталось вот это породить.
Я утверждаю, что это можно сделать за ноль шагов.
Смотрите. За ноль шагов. Тогда что мы можем получить с вами? Из этого у равно
Эпсилон. Дальше что? И равно Р. И чтобы у нас реально база индукции сошлась,
мы должны добавить такое правило. Почему? А, там же, да? Да, согласен.
Так, давайте запишем теперь это все формально. Готовы? Давайте напишем. На самом деле мы
доказали подтверждение справа, налево. То есть у нас есть база, у нас есть переход за ноль шагов,
значит у нас есть такое правило, которое выводит слово Эпсилон. Построили с вами индукционный
переход при помощи этой картинки. То есть нашли такую ситуацию, что мы поднялись по А,
попустились по А, в последний раз нашли момент, вывели такое правило. И дальше доказали, что если у
нас есть слово W-водящее слово, то мы выводим вот такой не терминал, а из него по доказанному факту
вводят слово W. То есть понятно? Вопрос. Понятно, как из кс-громатики, из mp-автомата мы сразу
доказываем выводимость в кс-громатике? Для каждой пары состояний мы вводим не терминал.
А дальше это все подвязываем правилами так, чтобы у нас реально из выводимости в mp-автомате
строилась выводимость в кс-громатике. Так, теперь давайте это формально напишем.
Итак, значит теперь формально доказательство. Потому что если бы я сейчас ввел эту конструкцию,
вообще бы не было понятно, что у нас есть. Итак, предположим, что у нас есть mp-автомат.
Так sigma гамма дельта q0 f, в котором мы будем обозначать qkt, то есть проиндексируем их.
Тогда смотрите, где мы сделаем следующее. Для любого куитова получается у альфа
q житая бета, пролежащим правилам в громатике, фиксируем, что модуль альфа плюс модуль бета равно 1.
То есть берем такой mp-автомат и строим громатику g, которая имеет следующий вид правил.
Значит, во-первых, не терминала s, объединить а и житая, где q житая принадлежат нашим состояниям в автомате.
Дальше у нас алфавит не меняется. Правило определим с в стартовании терминала s.
Где? Правило громатики состоит из следующего вида. По-первых, правило такого вида.
Объединить, объединить с, я вот тут страшная, а и т выводят
твердый знак a, g, r, e, a, s, t, где у нас есть правило q i, t, твердый знак епсилон выводит q житая,
тут надо написать, что существует такое а из нашего стека алфавита, что из этого выводится такое,
а и получается из q, r, e, a выводится q, s, t, епсилон, вот так.
Вот, теперь представьте, что я бы начал это рассказывать.
Вот, ведем такую громатику и непонятно, как она построилась. Устроится она ровно вот таким вот
рассуждениями. И дальше лему, которую нам надо доказать, это вот эта вот штука. Давайте я просто
выпишу ее. Давайте я сейчас напишу лему. Так, выводят слово у,
тогда и только тогда, когда из q.
Так, контрольный вопрос, какую сторону уже доказали?
Не, ну по факту.
Длина вывода равна нулю. Тогда какие рассуждения мы применяем?
Вот эти вот, которые у нас были. У равно епсилон, g равно r и тогда у нас получается,
что g,r равняется a, g,g выводят епсилон. Вот так мы правила это выводили. Переход. Давайте напишу так.
Смотри картинку. То есть у нас просто появляется цепочка вывода. Значит, что у нас правило раз
появляется, потом мы снимаем всю эту штуку со штека, появляется правило два. А индукционный
переход срабатывает вот именно на ажиры, на аст. То есть у нас есть. Что получается у нас?
У нас q и t. Получается у. Что у нас там? Эпсилон выводит qt, епсилон, епсилон. Значит, существуют
такие, что, собственно, блин, жаль, что тут нет копипасты. В общем, вот эти вот все знаки. Такие,
что у нас выполняется вот эти соотношения, которые у нас есть. А, еще и а есть. Такие,
что у нас один и два. Вот. Но тогда мы можем написать следующее, что у нас у может быть
представимо в виде твердый знак. Чего там? x, e, y. Да, и получается следующее, что цепочка у
нас получается такая. q и x, e, u. За один шаг мы снимаем q, g, t. Получается кладем на стек что?
Получаем h, u, a. Потом за какое-то количество шагов мы снимаем эту букву со стека. Получаем q,
r, t, e, u, епсилон. Дальше мы снимаем. Так, стоп, что-то лишнее сделал. А. Потом мы заходим в q,
s, t. По букве a снимаем букву u, букву e. И дальше мы доходим до состояния q, s, t. Получаем
епсилон, епсилон. Вот. Ну и выходит следующее. Смотрите. Значит, из вот этого у нас получается,
что из q, z, t. Чего у нас получается? q, z, t, x, епсилон выводится q, r, t. Сейчас, секунду. q, r, t,
епсилон, епсилон. Вот. А из вот этого соотношения, собственно, оно у нас есть. И по предположению индукции
получаем, что из a, z, r у нас выводится x. А вот для вот этого у нас получается, что из a, z, t
выводится y. Что? Мне кажется, вы все выпали уже. Что? Да, то есть мы смотрим путь наш в автомате
от этой вершины до этой вершины, в которой в первый раз... Тут важно сказать, что мы смотрим первый
момент в слове и смотрим именно такой переход, в котором буква а нас так добавляется. Да-да-да. То есть
смотрим в момент, когда у нас добавляется буква, смотрим в момент, когда у нас эта буква слетает.
Вот. И что у нас получается? Смотрите. У нас а, с, т выводит у, у, а, ж, р выводит х. Да? И у нас
есть правило грамматики для такой штуки как раз. Какое? Господи. А, и, т, т выводит твердый знак а,
ж, р, т, а, с, т. Твердый знак а, ж, р, т, а, а, с, т. А вот это уже предположение индукции получается,
что из а, ж, р, т выводим х, а из а, ст выводим у. А это наше слово в W. Вот. Как бы это формально
расписанный тот переход, который мы с вами обсуждали на картинке. Не поверите, в обратную
сторону проще. Ну, собственно, как обычно, у нас доказательство в одну сторону простое,
доказательство во вторую сторону. Надо это, надо включить мозги. Опять же индукция по длине вывода.
Из а, и, т этого, да, выводит епсел. Ой, выводит славу. База какая? А? Как из них терминала
можно что-то вывести за ноль шагов? Один шаг, да. Так, ну, что мы за один шаг мы можем выводить? Вот
у нас есть правило, что мы можем вывести здесь за один шаг. Кажется, только пустое слово. Да ведь?
Так, тогда и равно t. И что тогда мы из Куитова, имея на входе слово епсел. Сможем вы вывести
вот это епсел на епсел. Но, кажется, сможем, потому что и равно t, и это выводит за ноль шагов.
Честно, да? Переход. Так, рассмотрим первый вывод. Значит, у нас есть а, и, т, и тогда он обязан
раскрываться у нас за один шаг по правилу нашему любимому. Твердый знак a, g, r, e, a, s, t. Я теперь
понимаю в чем польза графических планшетов. Знаете в чем польза графических планшетов? Копипаста есть,
да. Так, господи. Из этого следует, что у нас существует, давайте вот, опять же, выводят и,
x, e, u. Вот так вот, да? Значит, из этого будет существовать у нас такое. Существует а,
и существует правило q, что-то там. Я пропущу это. Такие, что q, e выводят. Давайте я буду писать за
один шаг. q, g, t, ε. И дальше, что у нас q, r, t. Получается e, a. За один шаг выводят q, s, t.
Вот такие штуки у нас есть. Теперь, смотрите, давайте писать следующее соотношение e. Значит,
у нас с вами, тут надо, так, эту картинку я могу стирать? Мне кажется, она нам уже не понадобится.
Итак, смотрите. Ох, поехали. Значит, давайте писать, что у нас получается из q и t.
Соединяем вот это вот правило. Получаем следующее. Значит, что мы получаем? q, g, t, x, e, a. Дальше
используем предположение индукции. И мы можем вывести. У нас a, g, r выводят x. А это значит,
что мы можем здесь заменить g на r, прочитать x и букву a оставить на стеке. Потом за один шаг по
второму правилу мы можем снять букву r со стека. О, qr заменить на q, s, u, e. Букву a снимаем со
стека. И, опять же, используя предположение индукции, мы можем добраться из q, t, t, e, e.
Лему доказали. Просто пишем руками. Говорю, имея графический планшет, можно сильно ускорить
себе время. Я просто помню, я в прошлом году читал это на дистанте. Это просто ctrl-c, ctrl-v было.
Вот, ладненько. А теперь давайте докажем теорему, собственно. Предположим, что у нас слово лежит в
языке, сдаваемом грамматикой g. Тогда что у нас получается? Тогда у нас в СС каким-то образом
выводится слово w. Но при этом количество переходов будет больше, чем один. Да, потому что у нас правила.
А это значит, что это эквалентно тому, что существует такое q, k, t при лежащем завершающем состоянии,
что из e за один шаг мы выводим слово a, 0, k, t, не терминал, а дальше выводим слово w. А это эквалентно тому,
что существует такое q, k, t, не терминал, вот это как раз с использования леммы выходит,
что из q, 0, в эпсилон выводится q, q, q. А это эквалентно чему? Да, что слово принимается?
Ура. Так, ахалай махалай, просыпайся, понятно идея доказательства? Смотрите,
сразу скажу, что у нас процедура такая, мы не требуем полностью формальные доказательства,
мы требуем только понимания идей доказательства и основных переходов. Да, сразу скажу, что на
колокве мы будет регламент такой, ну и на экзамене тоже. Главное понимать, какие основные ключики
к решению проблемы, к доказательству теоремы, а дальше на самом деле дело техники.
Вот, то есть, грубо говоря, вот эти все переходы, вы думаете я их запоминаю? Нет, я их не запоминаю,
я просто понимаю, где основные ключевые позиции, и вот именно по основным ключевым позициям мы
проходим. И сразу говорю, что экзаминаторы будут не злые дядями и тетями, они именно будут
подсказывать в некоторых моментах, если, допустим, вы формально где-то чуть-чуть запутались в этом
концепции. Так, что, докажем следствие? Следствие, на самом деле, вы уже пользовались не один раз.
Опять же, я расскажу идею доказательства. Доказательства это две индукции, собственно,
так, понимаем, кто ходит на семинары,
да, и теперь мы это можем доказать. Давайте следствие тирей теоремы, потому что ее можно
использовать как теоремы. Как доказываем? Да, ровно так же, как пересекаем обычные автоматы.
Смотрите, давайте напишу идея. КС чему у нас эквивалентны? По автомату. Чему эквивалентны
регулярки? Просто автоматы. Причем мы доказали, что существует автомат с однобуквенными переходами.
А автомат существует с однобуквенным переходами? Ну, конечно, любой берем.
Теперь смотрите, у нас есть автомат, автомат стэк. Пересекаем автомат, сбоку к нему стэк
приделываем. Давайте сейчас формально напишем это.
Формально. Значит, берем автомат. Пусть у нас есть М автоматный. Это у нас Q сигма дельта
Q0F. Давайте будем обозначать Q. А ММП. П это, если что, то же самое, что Q, только другая буква.
Просто так будет удобнее обозначать. Дельта гамма П0 ФП. Где все переходы однобуквенные.
Тогда строим М пересечение. Это у нас будет дикартового произведения Q на П. Дальше строим сигма.
Дельта сейчас определим. Давайте вот это обозначим. Дельта Q, вот это дельта П. Стартовые состояния какие
будут у нас с вами. Ну, с 0 по 0, Дикартова, конечно, пара с 0 по 0. А завершающие.
Пара Q, ФQ, ФП. Ну и дальше нам надо определить дельта. Дельта. Это переходы, ведь это Q1, П1.
Давайте тут буква А. Снимаем, состояка альфа. Переходят в, получается, Q2, P2, бета. В том случае,
если у нас есть два перехода. Получается Q1, А переходит в Q2. В автомате получается в обычном.
П1, получается А, альфа, переходят в Q2, бета. Дальше открываем доказательства,
которые у нас было для обычных автоматов. И за счет того, что у нас стэк пустой,
должен быть в начале и в конце, просто везде добавляем вот то, что будет на стэке.
В конфигурации просто. Мы просто в конфигурации сохраняем то, что происходит на стэке.
У нас конфигурация есть. Мы всегда же работали с объектом конфигурации. У нас есть пара,
тройка состояния, слово, текущий стэк. Когда мы доказывали пересечение автоматов,
то мы хранили именно конфигурацию. Здесь двух. То есть просто надо переносить стэк аккуратненько.
Чего? Чего не совпадает? Буквы? Нет, алфавит совпадает. Мы же пересекаем с одним алфавитом.
Ну да, то есть это интересно. Мы же обычно работаем над конструкцией с одним алфавитом.
Ну можно, да, так. Конечно же. Так.
Идея ровно такая же. Так, понятно. То есть теперь мы можем пользоваться этим для того,
чтобы доказывать, что языки неконтекстно свободные. Да, то есть если у нас этот язык
неконтекстно свободный, а мы пересекаем с какой-то регуляркой, то мы получаем неконтекстно свободный язык.
Так, ладно. Теперь мы вас будем немножко развлекать. Мы дошли до материала, так сказать,
предновогодней лекции, но теперь это не предновогодняя лекция, а будет ноябрьская лекция.
Значит, идея такая. Давайте попробуем подумать, а можем ли мы как-то явным образом отделить язык
регулярный от контекстно свободного? Логичный вопрос. У нас есть два класса в иерархии хомского.
У нас есть контекстно свободные языки, у нас есть регулярные языки. Вопрос. Можем ли мы придумать
какое-то евристическое правило, которое позволит нам явно сказать, что вот эта штука не регулярная,
контекст свободный, а вот эта штука, допустим, регулярная. Ну, понятно дело, проверка на автоматизм.
Терема Махилла Нерода дает такой критерий, но при этом оно, так бы сказать, немножко трудноприменимо в теории.
Да, евристически, а хотелось бы точно. Ну, это да, тут тоже можно над этим подумать.
Давайте вот сейчас окунемся в историю развития этого всего. Что мы можем у любого слова достаточно точно быстро сделать?
Длину посчитать, хорошо. Играли в Баки коровы?
Ну, в общем, там есть последствия четырех цифр, и надо отгадать этот последствий за десять попыток.
И дальше там говорилось, что либо позиция точно совпала, либо эта цифра где-то есть, но вот непонятно где.
Что мы еще можем посчитать? Хэш, зашибись, да, вот не работает.
Смотрите, мы можем посчитать количество букв? А, В, В, Г, Д, Е, Ё, Ж, З, и так далее. Можем же?
Так вот, люди как раз пытались проработать теорию, связанную с тем, можно ли понять что-то, считая количество букв в словах.
Как вы думаете, ответ на этот вопрос какой?
Да, ну можно ли отличить контексты свободной языки от регулярных?
Нет, нельзя. В общем, это как раз последняя тема, которую мы будем рассматривать перед колоком.
Для этого нам нужно ввести некоторые определения. Сегодня не 31 октября, сегодня 32 октября, для которых немножко не умеют считать даты.
Давайте построим отображение, которое считает количество букв в нашем слове.
Обозначим его в С. И тогда у нас получается, что мы можем построить отображение языка.
А как построить отображение языка?
По сути, это образ при вот таком отображении.
Примеры.
А, Б, Б. Одна буква А, две буквы Б.
Тут что получим?
1, 2, 0, да, тут.
2, 1, 2. Хорошо.
Образы языков. Вообще это называется образ парик.
Прошу внимания обратить на ударение.
Ударение на первый слог.
Давайте построим образы языков, образ парика.
Для вот этой штуки как будет выглядеть образ?
N.
Множество неотрицательных целых чисел.
Так, полиндромы четной длины.
Тут надо алфавитом А, Б.
Это будет множество видов 2n, 2m.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
ДНМ неотрицательные.
Так, кажется я что-то обкурился.
Кажется, давайте подберем регулярный этот.
Подберем контекстный язык, который обладает образом N, N.
Подберем контекстный язык, который обладает образом N, N.
Да.
Подумайте, есть регулярный язык такой же?
Конечно же.
Так, у нас закрадывается первое подозрение.
То, что у нас существует регулярный язык и нерегулярный язык, образ парика,
которого совпадают.
Так.
Собственно, А плюс Б со звездой так.
Вот.
И тут нам нужен немножко линал.
Давайте будем работать с множеством, ну, количества букв.
Да.
То есть у нас пусть Х, это у нас такая последовательность,
как линейная оболочка обычно определяется в линейной алгебре.
Двух линейных пространств.
А.
Да, наименьшее это.
Вот, единственное тут ограничение будет следующее,
что у нас будут все числа неотрицательными и натуральными.
То есть, если у нас есть
х,
хн,
о, че там у нас х,
блин, тут че, маппинг-определение плохое, да?
Да.
хк,
под множество n-венной,
n тут с нулем, сразу скажу.
То, линейная оболочка х обозначим
α, и, то, и, и, то.
Где α иты больше равны нуля,
а α иты принадлежат целым числам.
И теперь мы сможем с вами определить
некоторые штуки.
Примером.
Линейная оболочка 1,1 это n, n.
Линейная оболочка вот такого множества
это 2n плюс m, 2m плюс n.
А?
А?
Да, да, да.
Да, да, да, только оно конечное
под множество.
А?
А, или в презентации, да?
А, я поправил, тут их k,
на самом деле, везде.
Ну, то есть размерности не совпадают.
Количество элементов в размерности.
Угу.
Так.
2,1 и 1,1 это,
оказывается,
2,1 и 1,1 это, оказывается,
2,1 и 1,1.
1,1 и 1,1 это, оказывается,
линейные оболочки n, m,
где n от m до 2m.
Я не знаю,
вы решали задачу в домашнем задании
задать контекстно свободной грамматике
множество слов,
в которых количество букфа зажато
между количеством букф b и удвоенным количеством букф b?
А?
Нет.
Там решается
следующим образом эта задача.
В общем, берется грамматика для количества букфа
удвоенного количества букф b.
Такое строили, наверное,
на семинарах.
Вот, количество букфа равного количества букф b.
И берете, смешиваете
эти все правила.
Получается такую грамматику.
Собственно, идея доказательства
состоит вот в этом факте.
То есть, что нам доказать, что линейная оболочка будет
удовлетворять такому виду.
Вот.
Так.
Понятие суммы множеств давайте ведем.
Ну, собственно, тут гадать ничего не надо.
То есть, у нас есть два множества.
Мы берем по элементам складом.
Только у нас это, по сути,
эти вектора
н-мерные, поэтому мы это можем сделать.
Так.
Собственно, тут можно
колдовать.
Кстати, как плюсик получается?
То есть, мы берем
вектор 1,1 и складываем
с линейной оболочки вектора 1,1.
Линейная оболочка вектора
1,1 это n,n,
где n не отрицательная.
Поэтому мы получаем множество пары n,n,
где n больше 0.
Вот это понятно?
Да?
И еще,
говорите, медленнее буду.
Вот. И теперь нам надо
с вами определить, что же такое
линейное множество. Значит,
линейное множество, вот это уже первое
определение, которое нам надо дать,
это такое множество,
которое представимо в виде какого-то
вектора,
плюс линейные оболочки других векторов.
Вот.
И давайте второй пример дадим сразу.
А, под множество n,n
полулинейно,
если
если
если
где a и t
это линейные.
То есть это множество, которое
представимо в виде
конечного объединения линейных множеств.
Что-то попахивает
рихметическими прогрессиями. Вам так не кажется?
Ну, собственно, это работа с рихметическими прогрессиями.
Так, а теперь смотрите фишку,
в чем. Значит, я сейчас пойму,
у меня есть это. Примеры линейных множеств.
Конечное множество
можно задать всегда таким образом.
Надо просто с нулем все сложить.
n,n
собственно, оно всегда
представимо в таком виде.
Вот.
А чтобы получить пара n и m,n,
то нам нужно взять вектор 0,0
и сложить с линейной оболочкой
векторов 0,1,1,0.
Ну, мы берем линейную оболочку
вектора 1,1. Это что у нас?
Это у нас пара как раз n,n.
Ну и дальше прибавляем
нулевой вектор, получаем то же самое.
Угу.
Тут еще какие-то примеры были.
О, пол линейное множество.
Нас будут как раз о ней интересовать.
И теперь смотрите,
ведем два примера.
Давайте как раз тогда сейчас буду финализировать,
чтобы в следующий раз уже доказывать утверждение.
Значит, давайте ведем понятие языка,
который является линейным прообразом.
Значит,
говорим.
Так, берем сухой мел.
L, это язык L
является линейным прообразом.
Если
psi от L
линейно.
Это второе определение.
L, пол линейный прообраз.
Прообраз парика.
И если psi от L
пол линейно.
Два определения.
Теперь факты.
Первый факт
это упражнение.
Если
сейчас
R регулярный язык
то R будет пол линейным прообразом.
И в следующий раз
мы будем доказывать две теоремы.
Теорема 1.
Если
сейчас.
Если x пол линейно
то R
пол линейный прообраз.
То существует
R регулярный
такой, что
он по сути является прообразом.
То есть для любого пол линейного множества
существует регулярный прообраз.
А теперь теорема 2, которая
имеет формулировку
теоремы парика.
Любой
КС язык
пол линейный прообраз.
Так, вопрос.
Теперь на понимание.
Почему теперь мы не можем
отличить КС языки
от регулярных с точки зрения
подсчета букв?
Кто может сформулировать?
Давайте попробуем сформулировать.
Ну да, давайте
предположим, что у нас есть какой-то КС язык
и у нас есть какой-то критерий, который
его отличает от другого.
От код регулярного языка.
Тогда возьмем его.
Посмотрим.
Он является пол линейным точно прообразом.
Смотрим.
Образ этого
контекстно-свободного языка
он оказывается пол линейным.
И поскольку он является пол линейным, для него
существует регулярный прообраз, который туда же
маппится. То есть у нас есть
получается
LKS.
Смотрим PSI от L.
А потом
берем R регулярный.
Для него точно существует, который
бьет в тот же самый образ при отображении
PSI. Проиграли,
не отличили.
То есть у нас всегда существует
регулярный прообраз в виде регулярного языка.
В следующий раз
мы эти факты будем доказывать.
А чтобы было с вами
быстрее и понятнее
вкатиться, вспомните, как мы доказывали
лему о разрастании для контекста
и свободных грамматик. Это нам понадобится.
