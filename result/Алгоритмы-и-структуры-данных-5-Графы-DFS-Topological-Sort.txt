Мы начинаем говорить про графы, наконец, формально.
Начну сегодня, в первую очередь, DFS.
Так, начинаем с определений.
Я думаю, что у многих из вас это было, но все-таки
для полной картины давайте повторим или узнаем.
Значит, неориентированный граф.
Это такая пара. Пара VE, где V это какое-то множество,
а E это какое-то под множество пар внутри V. Я напишу вот так.
E это под множество C из V по 2, имея в виду, что такое C из V по 2. Это все возможные неупорядоченные пары,
то есть двуэлементные под множество, множество V. И E это какое-то под множество, то есть есть у меня
все множество пар, там AB, BC и так далее, все возможные пары. Ну, E это какие-то из них.
Значит, это мы будем называть вершинами, это будем называть рёбрами. Вот это граф, такая пара.
Ориентированный граф.
Это тоже пара VE, где V это множество, а E это под множество V квадрата, то есть Декартова квадрата V на V.
Вот, значит, здесь пары у меня неупорядочные, то есть ребро это как бы две вершины неупорядочные,
там UV или VU это одна и та же пара. А здесь, поскольку у меня фиксировано вот это вот произведение,
то UV и VU это будут разные пары. Вот, ну, картинками это изображается там очень просто. Например,
вот это вот, это неориентированный граф, соответственно, точки это вершины, палочки это
рёбра между ними, неориентированные. Ориентированные рёбра это что-нибудь вот такое, например,
это рёбра со стрелочками. Вот это ориентированный граф. Так, ну, я уже, кажется, говорил когда-то,
что ими можно делать, ими моделируются любые какие-нибудь сети, в которых есть взаимодействие
каких-то объектов, там, не знаю, группа друзей с отношением друга между ними или какие-нибудь
самолётные рейсы между городами и так далее. Едем дальше, значит. Что такое путь? Ну, путь
это просто последовательность вершин такая, что из первого есть рёбра во вторую, из второго в третью и
так далее и так далее. Это набор вершин, V1, V2 и так далее, VK, набор вершин, ну, точнее,
последовательность вершин. Такая, что первые две вершины образуют ребро, вторая пара вершин
образует ребро, ну и так далее, вплоть до последней пары. Вот, здесь надо аккуратно
обговориться. Я рисую в круглых скобочках пару из двух вершин. Вот, круглые скобки — это,
соответственно, упорядоченная пара. Непосредственно такое определение — это для ориентированного графа.
Но в случае неориентированного я буду писать точно так же. То есть, формально, с точки зрения
неориентированного, я должен был бы писать что-то вот такое. Это вот в неориентированном случае.
Ну, потому что у меня пары неупорядочные, я не могу написать круглые скобки. Если две вершины
соединены, то порядка на них нету. Поэтому корректнее было бы писать фигурные скобки здесь, как
быдовое элементное множество является ребром. Но я не буду сильно заморачиваться и буду неформально
писать всегда круглые скобки, означая, что вот такое ребро. Если граф неориентированный, то имеются
в виду тогда фигурные скобки. Вот это путь. Еще можно здесь отметить, что на самом деле вот в том
определении, которое я дал, не бывает кратных ребер. То есть, если есть ребро из УВ, то оно не больше
чем одно. Вот, и поэтому здесь, когда я задаю последность вершин, мне на самом деле, ну вот,
ребра между ними однозначно определены. То есть, вот здесь вот ребро, оно не больше чем одно. Я
просто проверю, что оно есть в графе. В случае, если бы у нас был там какой-нибудь мульти граф,
то есть, с кратными ребрами, когда между одной и той же парой вершин может быть несколько
стрелочек, тогда здесь в определении нужно было бы еще вставлять какие-то ребра между ними,
потому что а какое именно ребро имеется в виду, чтобы пройти между этими вершинами. Но в нашем
случае такого не бывает, поэтому я обхожусь только перечислениями вершин. Так, дальше,
значит, путь называется ребер на простым, если ребра в нем не повторяются.
Ну, примеры какие-нибудь простые, значит. Давайте я буду рисовать примеры для ориентированных
графов. Вот что-нибудь такое, это ребер на простой путь, да, то есть, вот если мы так будем идти по
графу, то понятно, что это путь, потому что каждая пара соседних соединяет ребром, и при этом понятно,
что никакое ребро не используется дважды. Да, вот эта вот вершинка используется дважды, то есть,
мы в нее раз вошли, потом еще раз вошли, но никакое ребро дважды не используется. То есть,
это корректный, то есть, это путь, который является ребер на простым. Ну, а что-нибудь вот такое,
например, это уже не ребер на простой, потому что вот это ребро используется дважды. Ну, понятно.
Дальше путь называется вершина простым, если вершины в нем не повторяются.
Так, ну я вот даже не знаю. А, ну, собственно, да, вот это вот уже будет не вершина простой,
потому что эта вершина взялась дважды. И в случае, что мы можем сказать, это просто вот какая-то
такая цепочка, в которой все вершины различны. Это будет вершина простой путь. Ну и вообще,
вот эта вот вершина простой часто сокращается до просто простого. Здесь я могу просто написать
простой. Путь называется простым, если в нем вершины не повторяются. Простое замечание,
что из вершины простоты следует реберная простота. Потому что если вершины не повторяются,
то ребра точно не повторяются, потому что чтобы повторить ребро, надо и левый конец,
и если правый конец повторить, значит, он не может быть вершиной простой. Хорошо.
Дальше цикл. Путь в один и так далее в икан называется циклом, если первые и последние вершины
совпадают. Если в один равно в икан. Ну понятно, что-то вот такое, например. Вот такое или даже
вот такое какое-нибудь. Тоже цикл. Здесь наследуется определение вершины простоты и реберной простоты.
Значит, цикл реберной простой, если в нем ребра не повторяются, цикл вершины простой, если в нем все
вершины не повторяются, ну кроме вот этой вот стартовой конечной. Понятно, что там, где начали, там же
закончили, но вот вершинная простота, это когда нет таких вот самоперещений, когда никакая вершина
не посещается, кроме вот, кроме стартовой, не посещается больше, чем один раз. Значит, замечание.
Определение реберной и вершины простоты наследуется.
Еще раз?
Да-да-да. Ну еще раз. Тут как бы я сказал, что кроме вот этой вот вершинки, все остальные посещаются
ровно один раз. Так, дальше, дальше, дальше. Достежимый. Да, сейчас, извините, будет просто много
простых определений, многие из которых вы знаете, но я считаю, что должен их формально вести. Значит,
мы говорим, что вершины, ну не так, из вершины У достижимы вершина В.
Если существует путь из У в В. Если существует какой-то путь в 1, тогда или в К, что он начинается в У,
а заканчивается в В. Вот. Значит, и дальше здесь, в зависимости от того, какой у нас граф ориентированный
или неориентированный, то есть до этого момента неважно было, какой граф ориентированный или
неориентированный, вот. А сейчас можно будет вести отношение эквивалентности по-разному, ну в общем,
отношение достижимости по-разному в ориентированном и неориентированном графе. Значит, определение,
если G неориентированный граф, то отношением связанности можно назвать просто наличие пути из У в В,
то есть две вершины связаны, если есть пути из одной в другую, то вводим отношение связанности.
У связано с В, тиличку пишу, если из У есть путь В. Ну, раз граф неориентированный, то на самом деле
наличие пути из У в В равносильно наличию обратного пути, потому что просто если мы ревершим порядок
следования этих вершин, то это тоже будет путь в исходном графе, да? Потому что если V1,
V2 это ребро, V2, V3 это ребро и т.д., ВК, МК это ребро, значит, когда весь порядок обращают, то все эти
пары, поскольку они были неупорядочены, это тоже будет все ребра, при этом первые и последние
поменяются местами. Значит, на самом деле наличие пути из У в В равносильно наличие пути из В в У, вот.
простое утверждение, что на самом деле вот это отношение является отношением
эквивалентности. Утверждение, отношение связности в неориентированном графе, это
отношение эквивалентности. Так, все знают, что такое отношение эквивалентности? Отлично.
Ну, доказывается тривиально по определению. Значит, что нам нужно от отношения эквивалентности?
Во-первых, нам нужна рефлексивность. То есть, если мы возьмем произвольную вершинку У, то из У есть
путь В. Но это очевидно, да? Можно просто стоять на месте, можно рассмотреть путь из одной вершины
без ребер. Ну, тогда мы, соответственно, из У попадаем в У. Это рефлексивность. Значит, дальше
симметричность. Тоже тривиально, если есть путь из У в В, то, как мы уже показали, есть путь из В в У.
Потому что тот же самый путь, если его развернуть, он будет доказывать нам связанность между В и У. Ну,
и, наконец... Это была симметричность. И, наконец, транзитивность. Если из У есть путь в В,
из В есть путь в В, то понятно, что у путь из У в В, просто два пути склеить. Надо просто два
пути склеить. Сначала из У добраться до В, потом из В добраться до в В. Это транзитивность.
Ну, все, значит, это отношение эквивалентности. А раз у меня на вершинах ведено отношение
то значит, если я по нему факторизую, то есть, разобью все на классы эквивалентности,
то у меня получатся какие-то кусочки вершин моего графа, ну, точнее, множество вершин моего графа,
и эти множество будет называться компонентами связности.
Компоненты связности.
Ну, то есть, формально определение компонент связности – это класс эквивалентности по этому отношению.
Давайте это запишем, класс эквивалентности по отношению вот этому тильду, по отношению связности.
А в случае ориентированного графа у нас будет немножко другое определение,
потому что там уже вот такая штука не будет являться отношением эквивалентности.
В частности, например, не будет симметричности,
потому что если мы просто оставим наличие пути слева направо, то это не обязательно значит, что есть путь справа налево,
не обязательно будет симметричность, потому что, если у меня все ориентировано,
то наличие пути из УВУ не означает гарантированного наличия пути из ВВУ.
Поэтому в случае ориентированного графа будет немножко другое определение.
Если же ориентированный граф, то вводим отношение сильной связности между вершинами.
У состоит в отношении с В, если есть оба пути из УВ и из ВВ.
Существует путь из УВ и существует путь из ВВ.
То есть мы требуем, чтобы был путь в обе стороны.
На самом деле здесь тоже самое можно было бы написать, что здесь есть путь в обе стороны, из УВ и из ВВ,
но на самом деле для этого достаточно, конечно, только вот этого.
Ну и то же самое, это отношение эквивалентности.
Значит, тильдочка, это отношение эквивалентности.
Доказательство столь же тривиально, значит, рефлексивность.
Почему у состоит в отношении тильда с У?
Ну потому что чтобы попасть из УВУ, надо стоять на месте.
Почему есть симметричность?
Почему из такого следует вот это?
Ну просто по определению, что значит у тильдочка В, значит есть путь отсюда сюда и отсюда сюда.
А надо доказать, что есть путь отсюда сюда и отсюда сюда.
Последняя транзитивность, что если у в отношении с В, В в отношении с ВВ, то у в отношении с ВВ.
Ну, то же самое. Что значит, что у в отношении с В.
Значит есть путь из УВ, есть путь из ВВ.
Значит есть путь из УВВ обратно, раз В в отношении СВ,
его есть путь отсюда сюда, есть путь отсюда сюда, значит есть путь из УВУ,
Ну короче, в общем, доказательство почти дословно повторяет доказательство в случае неориентированного графа.
Ну вот просто нам нужно, чтобы были в обе стороны явным образом.
Поэтому это тоже будет отношение эквивалентности на вершинах.
И все множество вершин опять распадается на несколько классов.
Теперь эти классы будут называться компонентами сильной связности, не просто компонент связности, а компонент сильно связанности.
То есть вот опять есть какое-то разбиение вершин на множество, это уже компоненты сильной связности.
Какое еще есть отличие? Отличие, например, в том, что когда вы рассматриваете компоненты сильно связанности в ориентированном графе,
здесь могут быть какие-то ребра, лежащие вне компонента.
Например, может быть какое-нибудь вот такое ребро спокойно.
То есть между компонентами сильной связанности могут быть ребра.
Это как бы ничему не противоречит.
А в случае неориентированного графа у нас ребер между компонентами точно быть не может.
Потому что если бы какое-нибудь ребро было, то это бы означало тогда, что между его концами есть путь.
Значит, они на самом деле лежат в отношении.
Потому что для отношения нам достаточно пути, ну как бы, просто пути между вершинами.
Тогда вот эти компоненты надо было бы на самом деле склеить.
А здесь такого не возникает, потому что наличие ориентированного ребра из одной компонента в другую
означает лишь, что есть путь в одну сторону, отсюда-сюда.
Но чтобы они попали в отношение, нам надо чтобы еще в обратную сторону было ребро.
Ну понятно, что...
То есть в принципе ребра здесь могут быть.
Главное, чтобы не было, грубо говоря, в две стороны их.
Вот тогда это плохо.
Тогда вот эти компоненты были бы тоже в отношении, их пришлось бы склеить.
Если такого нет, то никакой противоречия тоже нет.
Отлично.
Так, ну вот, вроде базовые определения все обсудили.
Теперь давайте обсудим, как можно хранить эти графы в памяти компьютера.
Давайте рассмотрим три подхода.
У каждого есть свои удобства.
Первая – это матрица смежности просто.
Кажется, мы ее рассматривали пару лекций назад.
Значит, если у меня n всего вершин, то синонта мощность множества v.
Тогда можно завести квадратную матрицу n на n.
И в ячейках, в этой же ячейке, писать единичку, если есть ребро из и в жи.
Значит, на перещении и этой строки житого столбца мы ставим единичку, если есть ребро из этой вершинки в житую.
Значит, напишу так.
m и та жита равно единице, если пара и жит в множестве е, ну или иначе.
Ну, здесь опять, да, вот эти круглые скобки означают либо упорядоченную пару, если граф ориентирован,
либо неупорядоченную, то есть вот такие скобки.
Если граф неориентированный.
Вот. Что здесь, значит, хорошего?
Ну, хорошего то, что мы можем за от единицы проверить наличие любого заданного ребра.
То есть если мне сказали, скажи, пожалуйста, есть ли в данном графе ребро из у в,
мне нужно просто посмотреть на пересечение этой строки житого столбца, ну, то есть просто м у в.
И то, что там лежит, будет ответом.
То есть плюс, это то, что мы за от единицы умеем проверять наличие ребра.
Проверять наличие ребра.
Минус, ну понятно, что жрет много памяти.
Требует квадратичной памяти.
И это невыгодно, если ваш граф очень разреженный.
То есть если, скажем, м, число ребер,
если число ребер сильно меньше, чем квадрат множества вершин,
то такой подход будет, ну, не очень оптимальным.
В нем хранится слишком много нулей.
То есть для разреженных графов, для графов, где м мало, это не оптимально.
Значит, первый подход.
Второй подход, еще менее интеллектуальный, это просто список ребер.
Список ребер. Ну, значит, мы смотрим на граф,
просто перечисляем все пары вершин, которые являются ребрами.
То есть все пары у в такие, что у в это ребро.
Например, там у1, в1, у2, у3, у4, у5, у6, у7, у8, у9, у10.
У1, в1, у2, в2, и так далее, ум, вм.
Вот вы просто передаете все такие пары, как, собственно, описание вашего графа.
Ну, здесь из плюса я могу назвать только то, что это в каком-то смысле естественное представление.
Естественность.
Например, так, ну, если мы хотим, как бы, описать граф,
то, наверное, это почти что самый простой способ.
То есть вы видите какую-нибудь картинку, вот такую.
Чтобы описать этот граф в виде, ну, там, не картинки,
а в виде чего-то более-менее формального, в виде списка,
короче, чтобы как-то его представить не картинкой, а каким-то текстом, да, каким-то данными,
то, наверное, проще всего просто перечислить, между какими парами вершин есть ребра.
Вот, вы говорите, что есть ребра между 1, 2, 2, 3, 3, 1, есть ребра между 3 и 4.
В частности, вам не нужно перечислять все пары вершин, между которыми нет ребра.
Вам нужно только те, между которыми есть ребро.
Ну, а минусы, это как бы, что, по сути, вы никакой информации быстро вытащить отсюда не можете.
Ну, неудобность я напишу, неудобство обработки.
То есть если так хранить граф, то мы, по сути, никакой полезной информации извлечь не сможем.
Например, чтобы проверить, есть какое-то ребро или нет,
мне придется по всему этому списку пройти.
Проверить, что есть ли пара, равная данной паре УВ.
Чтобы, например, узнать, с кем соединена данная вершина У,
то есть вывести всех соседей У, вывести все вершинки, с которыми У соединена ребром.
Тогда мне опять надо по всему этому списку пройти
и вывести все пары, где есть вершинка У.
Короче, неудобно работать, мы тут ничего за быстро извлечь отсюда не сможем,
если будем так граф хранить.
Ну и третья, собственно, то, чем мы будем пользоваться, это список смежности.
Я даже напишу списки смежности.
Начнется следующее представление.
Давайте для каждой вершины хранить список вершин других, с которыми я нас соединяю ребром.
У меня будет n списков,
а у меня будет 1 список вершин других, с которыми я соединяю ребром.
У меня будет n списков и l, скажем, УТ,
и это все такие В, что УВ это ребро графа.
Утый список, это список,
ну да, Утый список, это множество тех вершин, в которые есть ребро из У.
То есть вот есть какая-то вершинка У, мы перечисляем, по сути, просто всех ее соседей,
куда мы можем перейти за 1 шаг, куда мы можем перейти за 1 ребро.
Ну список, тут как бы можно воспринимать как там односвязанный список,
но нам будет достаточно вектора. Всегда с вектором будет удобнее всего работать.
Вектор просто номеров вершин, в которые есть ребро из данной.
Значит, чего?
Ну плюсы, собственно, здесь можно почти все написать.
Во-первых, это эффективность представления в памяти,
только линейного размера памяти, n плюс m памяти.
То есть почему n плюс m?
Напоминаю, n это число вершин, m это число ребер.
Значит, n у меня всего списков, то есть у меня тратится n,
чтобы создать вот этот вот, ну, грубо говоря, вектор векторов,
вектор списков m.
Ну, это суммарный размер всех списков, потому что
у меня есть один список.
Если, например, даже если граф неориентированный,
то каждое ребро дает мне как бы два вхождения в списке.
Если у меня есть ребро из u в v, точнее между u и v,
то у меня в списке для u будет хранится v,
и в списке для v будет хранится u.
Поэтому суммарный размер всех списков – это на самом деле удвоенное число ребер.
То есть если граф неориентированный, то сумма размеров всех списков – это 2m.
Если граф ориентированный, то сумма всех списков –
сумма длинных списков – это 2m.
Потому что каждое ребро дает ровно одно вхождение в один из списков.
Поэтому память линейная по представлению графа, по n плюс m.
Так, что еще?
Значит, с памятью все хорошо.
Еще плюс, что мы можем...
Ну, по сути, у меня для каждой вершины хранится множество ее соседей.
Для каждой вершины.
Для каждой вершины хранится множество ее соседей.
Для каждой вершины знаем множество соседей.
Ну, соседей – это ровно то, что мы храним.
Это список тех вершин, в которые есть ребро.
Если, например, нам приходит запрос «скажите, пожалуйста, всех друзей Васи»,
мы просто смотрим на список Васи,
печатаем все вершинки из этого списка.
Так, ну можно здесь еще к минусу отнести то,
что нельзя за от 1 как-то эффективно проверить,
есть ли данное ребро в графе или нет.
Давайте я напишу, что это минус за от 1.
Нельзя проверить наличие ребра в графе.
Ну, потому что если мне сообщили пару УВ,
то мне, значит, нужно перейти в УТ и список
и проверить, есть там числовые или нет.
На самом деле, это можно как-нибудь решить.
Например, можно вместе с каждым вот этим вот вектором,
вместе с каждым списком хранить какое-нибудь дерево поиска.
И, соответственно, тогда за логарифом проверять,
есть такое ребро или нет, то есть есть ли В в списке для У.
Либо, на самом деле, я вот в конце прошлой пары говорил,
что на самом деле вот эта вот штука решается
совершенным хэшированием.
Потому что, по сути, что у нас есть?
У нас есть фиксированное множество ребер, М-ребер.
Давайте создадим вот с помощью совершенного хэширования
хэштаблицу, которая за от 1 позволяет проверять наличие
ребра в графе или нет.
Ну а дальше, чтобы проверить, есть какое-то данное ребро
в графе или нет, мы считаем его хэш.
Ну там, как обычно, сначала внешний, потом внутренний.
Вот в этой вот табличке размера k квадрат.
То есть, если у меня в ячейке попало k ключей,
то будет здесь хэштаблица внутренняя размера k квадрат.
Я считаю внутренний хэш h и t.
И проверяю, если на этом месте лежит правильное ребро,
то значит, это оно.
Если там вообще пусто или лежит какое-то другое ребро,
значит, исходного ребра в графе нет.
Поэтому вот эта вот штука, она как бы, ну,
исправляется применением какого-то другого алгоритма.
Неявным образом мы вот используем списки смежности,
а скорее совершенное хэширование поверх нашего графа.
Окей?
Хорошо.
Так, значит, со способами хранения вроде разобрались.
Ну, теперь переходим к DFS.
Значит, DFS – это способ обхода графа.
Давайте я тут напишу DFS.
Depth, First, Search.
По-русски это поиск в глубину.
По-русски это поиск в глубину.
Значит, поиск в глубину работает неформально так.
Мы стоим в какой-то вершинке, у нас есть список,
вот мы считаем теперь, что у нас граф хранится в виде списка смежности,
то есть для каждой вершины есть список,
вершинку, куда можно попасть за одно ребро.
Вот мы стоим в вершинке, есть какие-то исходящие из нее ребра.
Есть исходящие ребра.
Тогда просто в каждую из них попробуем перейти
и рекурсивно запустить DFS оттуда.
То есть наша цель – это как бы обойти весь граф
и, например, отметить посещенными те вершины, которые достижимы, были из стартовой.
Вот есть какая-то стартовая вершинка, я помечаю ее посещенной.
И дальше рекурсивно, от всех вот этих вот запускаюсь,
тоже рекурсивно прошу посетить все, что достижено из них.
Да, и если наша цель – это очень простая, просто посетить все, что достижено из V,
то сработает такой простой алгоритм.
Пометь эту посещенной и запусти алгоритм для всех этих вот рекурсивных.
Давайте сделаем это с некоторыми еще дополнительными данными.
Во-первых, мне нужен будет вектор векторов G.
Это, собственно, то, что у меня там L обозначено, списки смежности.
Значит, G от V – это список вершин, в которые есть ребро из V.
G от V – это то, куда можно попасть из V за один шаг.
Дальше, так, я, чтобы ничего не забыть, подсмотрю.
Мне нужны будут вектора T in, T out.
Значит, это будет время входа и выхода в каждую вершину.
Нужен будет какой-то таймер, чтобы мерить время.
Нужен вектор цветов.
String color.
На всякий случай еще будем хранить предков, родителей.
Vector and parent.
Значит, сейчас напишем код, потом будем разбираться, что все эти вектора хранят.
Значит, void DFS.
Давайте DFS будет принимать вершинку, какую-то V, от которой мы пытаемся все обойти.
И в качестве второго параметра передадим еще предка, которая, по умолчанию, равен минус единице.
То есть это родительская вершина, грубо говоря, то, откуда мы пришли.
И, например, если V – это первая вершина, которую мы обходим, то мы ниоткуда не пришли.
Соответственно, родитель у меня минус единичка.
Иначе мы будем передавать предыдущую вершину на пути.
Так, ну давайте сначала сделаем следующее.
Скажем, что мы в эту вершинку вошли, t и на t равно таймер плюс-плюс.
То есть мы в нее вошли, в какой-то момент времени таймер, и сразу таймер увеличили.
То есть мы считаем, что есть вот это время, таймер, который отмеряет, сколько времени прошло с начала работы программы.
И для каждой вершинки мы меряем время входа в нее и время выхода из нее.
Соответственно, когда мы вошли, мы сюда написали таймер и таймер увеличили.
Далее выставляем parent.
Parent от V равно P.
Ну parent – это вот как раз то, что сюда перейдется в качестве второго аргумента.
Родительская вершина, откуда мы пришли в V.
И еще я назначу цвет этой вершинки, скажу, что она сейчас серая.
Grey.
Причем изначально все они были white.
Значит у меня у вершин будет всего три цвета – белый, серый и черный.
Вот изначально все белые. Давайте считаем, что здесь изначально лежат white для всех вершин.
Зашел в вершину, пометил ее серой.
То есть она раньше была белая, белая такая нетронутая, чисто не загрязненная белая.
Захожу в нее, отмечаю ее серой, что она сейчас в обработке.
Так, вроде все.
Теперь давайте мы пройдем по всем соседям.
То есть попытаемся пойти по ребру.
Вот такой цикл позволит мне как раз проитерлироваться по всем.
Ну вот если в это вот эта штука, то тут пробегает список всех возможных детей, куда можно перейти.
Так, открываем скобку, переходим сюда.
Напишу следующее. Если цвет вершины 2 не белый, тогда continue.
Если color2 не равно white, тогда continue.
В заявке soybeans, что если вершина не белая и по сути это значит, что в нее вошел dfs,
когда-либо в нее вошел dfs, тогда давайте просто не будем заново запускаться
потому что, если она не белая, то значит в нее когда-то входил dfs.
Ну там, в какой-то другой момент времени возможно.
И по сути мы уже обошли все, что из него можно было.
Поэтому давайте не будем заново запускаться.
Нет смысла пытаться обходить что-то из вершинки.
из нее пытались что-то обходить. Поэтому в таком случае мы ее просто скипаем.
Ну а иначе, если color of tu равно white, мы рекурсивно запускаемся с параметрами tu и v.
То есть была вершина v, была вершина tu, тоже белая вершина, в которой мы еще ни разу не бывали.
Тогда давайте мы рекурсивно запустимся от нее с параметром v, как родительская вершина,
откуда мы попали в tu. Все, на этом цикл заканчивается. И перед тем как выйти, давайте еще пометим вершинку.
Давайте скажем, что мы из нее выходим. tout от v равно timer++. И скажем, что ее цвет черный.
То есть мы ее обработали, она теперь черная, больше в нее заходить не надо. Конец.
Так, есть ли вопросы по тому, что мы сделали? Пока я не расшифровываю, что здесь, как бы,
что здесь по сути происходит, но есть ли вопросы, что тут написано может быть?
Пока нет, да, пока нет, пока для нас-то одно и то же, но чуть позже будем.
То есть я это скорее на будущее ввел, пока нам цвета, да, действительно серый и черный,
но мы пока не отличаем. Лемма называется лемма о белых путях. Она утверждает следующее, смотрите,
что если мы в какой-то момент запустились DFS от вершины v, и к моменту, когда мы сюда пришли,
то есть к моменту времени, по сути, ti над v, когда мы вошли в вершинку v, если есть какой-то путь
целиком состоящий из белых вершин, то есть вот здесь white, вот здесь white, вот здесь white,
вот здесь white, короче, если есть целиком белый путь, то к моменту времени выхода из v, то есть к
моменту ti от v, мы весь вот этот путь посетим, и они все будут помещены черными. То есть мы от них
запустимся, обойдем, то есть запустим DFS от них, посетим из них все, что можно, завершатся те DFS,
они перекрасятся в черные, и мы вернемся в v. Формально, значит, следующее, если в момент
ti над v, то есть в момент входа в вершинку v, есть некий путь из v по белым вершинам,
то к моменту ti от v все эти вершинки просмотрятся и будут помещены черными. Все вершины этого пути
будут черными. Ну а черными они могут стать только если от них DFS запустился и целиком отработал. То
есть если я стою v, DFS сейчас стоит v, и есть какой-то путь по белым вершинкам, ну вниз, да, по ребрам,
вот есть такой путь по белым вершинкам, тогда до того, как мы выйдем из v, до того, как мы целиком
обработаем вершину v, у меня успеют обработаться целиком все вот эти вот вершинки по всему белому
пути. Так, ну доказательства. Пусть не так, пусть для какой-то вершинки v был какой-то белый путь
к моменту времени входа в нее, давайте на другой доске нарисую все-таки, к моменту времени входа v
был некий путь по белым вершинам из нее, white, white, white, white. Пусть к моменту времени выхода из v,
к моменту t-out от v, не все здесь черные, тогда давайте рассмотрим самую высокую не черную,
рассмотрим самую высокую, ну то есть самую близкую к v, не черную вершину
в момент времени t-out от v. Я предлагаю, что они не все черные к моменту времени выхода,
давайте из этих не черных рассмотрим самую верхнюю, то есть пусть, например, это черное,
это черное, а вот это не черное. Это перекрасилось, это перекрасилось, а это не перекрасилось,
ну то есть по крайней мере не черное. Я назову эту вершинку u. Какая она тогда может быть? Если она
не черная, то она либо белая, либо серая. Ну давайте рассмотрим оба случая. Пусть u белая. Если u белая,
тогда давайте рассмотрим тот момент, когда обрабатывалась эта предыдущая вершина, раз
она стала черной как к моменту времени выхода из v, она черная, значит, повторюсь, стать черной она
могла, только если DFS от нее запустился. Потому что вот эта строчка есть только в момент времени выхода,
да, в момент времени выхода из DFS. Значит, если она черная, то DFS из нее целиком работался. Но,
извините, если от нее целиком работался DFS, а вот эта вот штука белая, тогда у нее DFS не
и не просмотрел почему-то это ребро.
Потому что если бы мы стояли здесь и
прошлись по всем исходящим ребрам,
то мы обязаны были в эту белую вершинку перейти,
потому что белые мы не скипаем, мы в них спускаемся.
Ну, противоречие, да?
Потому что
противоречие так как
рассматривалось
ребро
u,
sorry, p запятая u,
и p это вот это вот предыдущие вершины на пути.
Согласны, что такого не может быть?
Вот.
Ну и второй случай, когда она серая,
u серая,
что это значит?
Это значит, что мы до нее как-то
дошли, но не успели выйти.
Дошли, но не успели выйти.
Что это тогда означает?
Ну, смотрите, я напишу такую цепочку неравенства, из которой все будет следовать.
Значит, во-первых,
t на тв меньше, чем
t на тв.
Это следует из того, что
когда мы вошли в v,
u еще белая.
Значит, мы в нее только после входим,
и она становится серой когда-то позднее.
Поэтому t на t больше, чем t на v.
С другой стороны, поскольку она серая
в момент времени t от v,
то я могу продолжить цепочку вот так.
Значит, еще раз.
Вот это следует из того, что
вершинка u белая
в момент времени t на тв.
Дальше. Вот это следует из того, что вершинка u
не белая в момент времени
t от v. То есть до того, как
выйти из v, мы успели в нее зайти.
Поэтому t на t меньше,
чем t от v.
А последнее следует из того, что
в этот момент у нас не было
вершинки у,
а последнее следует из того, что
вот эта серая в момент времени t от v.
То есть мы еще не успели выйти из u,
потому что выйти
значит перекрасить в черный. То есть мы не успели
перекрасить в черный, значит это
происходит после этого. Согласны?
Вот. Но такого быть не может.
Давайте я вот здесь
нарисую эту
пару отрезков. Есть у меня отрезок
вот такой вот
t на tv,
t от v,
есть вот такой вот отрезок
t на t,
t на t.
Вот. Но, конечно, такого быть не может в рекурсии,
потому что, если мы, значит,
ну,
можно, например, в терминах stack и recursive рассуждать.
Если мы, значит, спустились в какой-то момент
времени в вершинку v,
значит, добавляем ее в stack recursive. Потом
запускаемся recursive над каких-то других вершин,
в какой-то момент добавили на stack вершину u,
то есть запустили dfs-ом от u.
Когда до того, как выйти из v,
понятное дело, надо бы целиком уработать u.
Чтобы удалить
из stack v, надо сначала удалить из stack
все, что было положено после нее. Поэтому
вот эта граница всякой должна была быть раньше, чем
вот эта квадратная скобка.
Поэтому, на самом деле,
попутно мы доказали следующее утверждение,
что вот эти отрезки нахождения
внутри каждой вершины,
t на tv, t от v, они,
если и пересекаются, то вложены друг в друга.
То есть, на самом деле, эта картинка не валидна.
Валидной была бы только какая-то такая картинка.
То есть, если они не пересекаются,
то один вложен в другой.
Согласны?
Ну вот, хорошо.
Тогда мы доказали лему о белых путях,
что все, что было достижимо по белым,
будет достигнуто к моменту времени
выхода из v.
Чудно.
Следствие.
Если запустить
DFS от s,
то после
его обработки
DFS посетит ровно те вершины,
которые были достижимы из s в исходном графе.
Только те вершины,
которые были достижимы из s.
То есть, если я весь граф изначально крашу в белый,
запускаю с DFS
вот какой-то произвольной вершинки s,
то к моменту времени выхода из s,
ну то есть, когда DFS обработается,
когда он весь выполнится,
у меня обработается все,
что было достижимо из s.
То есть, по сути, посетится
все, что из этого s достижимо.
Все, что достижимо,
посетится и перекрасится в черный.
Все вот эти будут черными.
То есть, все, что было достижимо,
будет черным.
Все вот эти будут черными.
Ну а тогда, соответственно, все остальное будет белое.
Все, что недостижимо, будет белое.
Начнем доказательство очевидно.
Во-первых, посетиться может действительно
только то, что достижимо из s,
потому что мы переходим каждый раз вниз по ребрам.
Значит, если я оказываюсь в какой-то вершинке,
то я ее достиг с помощью переходов по ребрам из s.
Значит, достигнуть я могу только достижимые.
Ну и из лемы о белых путях,
если какая-то достижимая,
то есть, достижимая по белым путям,
ensed by,
следствие следующее.
напишем следующее, пусть в мейне выполняется dfs от s, то есть вот у меня есть
такая рекурсивная функция и из основной
программы я ее дергаю один раз, вызываю один раз, и от какой-то стартовышинки s. Тогда в
графе существует цикл, достижимый из s, если только если в какой-то момент времени мы найдем
ребро в серую вершинку, dfs когда-то находит ребро в серую вершину, серую вершину. Вот, и это в
частности объясняет, зачем мы вводили три цвета, белый, серый, черный, потому что вот здесь вот,
если, то есть, если мы это утверждение докажем, то вот в этой строчке, когда мы проверяли, что цвет
не белый, можно, ну, немножко по-другому написать, что если цвет черный, то continue, если цвет серый,
то мы нашли цикл, а если белый, то запустились рекурсивно dfs. Вот в этом месте у нас играет
покраска в серый цвет, то есть если в какой-то момент времени я стою v, пытаюсь пойти в tu и
tu при этом серая, то я нашел цикл, используя ребро v tu. Доказательства. Так, ну, справа налево,
давайте попробуем сначала. Наверное, я хочу сказать следующее, для доказательства мы скажем
следующее, что в каждый момент стек рекурсии это путь из серых вершин,
причем других серых вершин в графе нету. Причем других серых нет.
То есть вот что такой стек рекурсии? Это, ну, например, я начал с какой-то вершинки s,
покрасил его в серый, перешел рекурсивно в какой-то v, покрасил его в серый, перешел в какую-то
вершинку tu и так далее. Потом, когда какую-то вершинку обработал, я ее перекрашиваю в черный,
удаляю стек рекурсии и откатываюсь на шаг назад. Почему это верное утверждение? Ну, более-менее
понятно. Во-первых, почему в стеке лежат только серые? Очевидно, что чтобы положить вершинку в
стек, я ее должен сначала перекрасить, потом рекурсивно запуститься в какой-то другой. Потом,
когда я ее хочу удалить, я ее перекрашиваю в черный и удаляю стека, потому что завершается
рекурсивный вызов. Поэтому в стеке обязательно лежат только серые, они образуют обязательно путь,
потому что чтобы добавить какую-то вершинку в стек, надо чтобы было ребро из перед последней
в последнюю. Почему нет других серых? Ну, потому что, как только вершина перешет быть серой,
она снимается со стека. Значит, все, что вне стека, оно точно не серое. Понятно? Ну и тогда справа
налево доказываем, что если мы в какой-то момент нашли ребро в серую, значит, по сути,
вот смотрите, у меня был вот такой стек, там С, какой-то В, какой-то Ту, какой-то там еще У и все
они серые сейчас. Грей, грей, грей. Я нашел ребро в серую. То есть я нашел, по сути, ребро в одну из
предыдущих вершин на стеке рекурсии. Она обязательно в стеке, потому что, повторюсь, серые лежат все в
стеке рекурсии. Вне стека все белые и черные. Ну, значит, если я нашел такое ребро, то, пожалуйста,
вот вам путь. Надо сначала использовать его, ребро в серую, которое я нашел, а потом спускаться
обратно по стеку к этой последней вершине, от которой я нашел ребро. Согласны? Поэтому
наличие ребра в серую автоматически вам означает наличие цикла. Ну, в обратную сторону. Почему,
если цикл есть, то мы его обязательно найдем таким способом? Мы его найдем, увидев ребро из
стекущей вершины в серую. Ну, хорошо, вот пусть есть какой-то цикл. Пусть есть какой-то цикл С. Я
утверждаю, что мы обязательно найдем, ну, то есть мы обязательно увидим ребро в серую когда-то. Так,
вот пусть С это стартовая, от которой мы запускаем DFS в мейне. И дальше, ну да, надо еще сказать,
что С это цикл достижимый из С. Раз это цикл достижимый из С, то есть какой-то путь из С в,
ну там, по крайней мере, в одну из этих вершин. Да, например, вот до сюда. Давайте тогда в качестве
В возьмем ту вершину, у которой Tn минимальный. Значит, пусть В это вершина цикла С с минимальным
TnV. То есть возьмем вершину цикла, в которую мы заходим раньше других. То есть мы как бы сначала
доходим из С до В, потом обработаем этот цикл. То есть В самая первая на цикле при обработке.
Тогда я утверждаю следующее. Смотрите, значит, вот я дошел в В. Впервые дошел до В, больше никакие
другие вершины цикла пока не вижу. Это в частности значит следующее. Значит, когда я в нее захожу,
я ее перекрашу в серую, а все остальные на цикле пока что еще белые. White, white, white, white, white.
Все остальные на цикле пока что еще белые, потому что я до них не успел дойти. У них Tn больше,
они только позже будут увидены. Поэтому, в частности, из LEM о белых путях, потому что есть вот такой
вот белый путь, есть путь по циклу, целиком состоящий из белых вершин, к моменту времени выхода
из В. Я точно всех вот этих вот товарищей обработаю. К моменту времени выхода из В я точно обработаю все
вершины цикла. В частности, вот эту вот предпоследнюю. Я ее обработаю. Что это значит? Значит, что DFS
отсюда вызовется раньше, чем DFS отсюда выйдет. Поэтому сначала эта вершинка покрасится в серый,
я увижу это ребро в В, и тем самым увижу ребро в серую вершину. То есть до того, как я отсюда
выйду, я увижу это ребро, и увижу ребро в серую вершину. То есть найду цикл. Давайте это запишем кратко.
По лемме о белых путях до момента
Таут от В, все вершины цикла посетятся. Значит, в частности, посетится вот эта вот предпоследняя
вершина, скажем, У. В частности, У. То есть я найду ребро из УВ, где В в данный момент серое, а У обрабатывается.
Поэтому я найду ребро как раз таки в серую вершину. Победа. Согласны? Да. Не обязательно, конечно. Я
этого не утверждаю, но главное, я говорю, что мы найдем ребро в серую. То есть если есть цикл в исходном
графе, то мы обязательно найдем ребро в серую. Конечно, совсем не обязательно обход устроен именно
так, что он доходит до В, потом обходит этот цикл, и потом обратно это ребро. Потому что, например,
может быть какой-то другой цикл, вот такой вот, по какому-то другому пути, через У и В. И тогда он,
в принципе, мог найти не вот этот цикл, а какой-то другой. Но главное, что он что-то нашел. То есть я
не утверждаю, что мы находим какой-то конкретный или вообще все. Главное, что если какой-то есть,
то мы обязательно обнаружим вот это вот ребро в серую вершинку. Замечание. Мы не ищем все циклы
или конкретный цикл С. Мы только проверяем наличие цикла. Мы лишь проверяем наличие цикла.
Так, ну что, тогда, наверное, ДФС я это могу стереть. Мы объяснили, зачем нам нужны цвета,
зачем Т in и Т out. Все, тогда я могу это убить. Хороший вопрос. Линейное, конечно. Симпточка этого
всего дела, конечно, N плюс M. Это очень просто доказать, потому что от каждой вершины ДФС
запускается максимум один раз, потому что войти в вершину, запустить в нее ДФС, я могу только,
когда она до этого была белой, а после этого ее сразу перекрашу в серый, а потом в черный.
Поэтому запуск от каждой вершины может быть максимум один раз. Это слагаем вот этот N. Ну а
дальше, если я посмотрю, как у меня работает ДФС из конкретной вершины В, то я, по сути,
просто перебираю все ребра из нее. Ну, то есть вот этот цикл 4 in 2, G out V, он работает за
количество исходящих ребер из В. Ну а сумма количества исходящих ребер это как раз от M. В случае
ориентированной граффы это просто M, число всех ребер. В случае неориентированной граффы это 2 М,
потому что каждый ребро дает мне ребро и туда и туда, поэтому с точки зрения ошки это все равно М.
Так, еще вот здесь замечание хочу сделать, чтобы найти какой-то цикл.
Сейчас, момент. Ну да, чтобы найти сам цикл, то есть, например, мы поняли, что цикл есть,
да, мы увидели ребро в серую, теперь мы хотим вывести этот цикл, вывести какой-то цикл. Надо
использовать массив parent. Ну тоже, в общем, понятно как. Я рисовал стек рекурсии, вот представьте,
что вот у меня такой стек рекурсии, и я нашел какое-то ребро в серую, то есть нашел в какую-то
более раннюю вершину на стеке ребро. Что это значит в частности? Значит в частности, что parent от
вот этого это вот это, parent от этого это вот это, parent от этого это вот это, parent от этого это вот это,
потому что если я использую какое-то ребро, спускаюсь с DFS из одной вершины в другую, то я в частности
помечаю, что родительская вершина вот этой, это вот это. Значит тогда у меня все вершины на стеке,
которые на стеке рекурсии, они на самом деле являются сыновьями одна другой, и если я хочу
вывести вот эту последовательность, зная, что вот этот В, а вот этот вот Т, мне достаточно просто
просто от v брать parent до тех пор, пока я не берусь до tu.
Тем самым я восстановлю как раз тот цикл, который у меня лежит на стеке.
То есть это parent от v, это parent от parent от v,
ну и так далее, пока я не дойду до tu.
Вот такое восстановление цикла.
То есть мы можем не только проверить, что он есть, но и вывести какой-то цикл.
Ура! Разбрались с циклами.
Так, хорошо.
Дальше идет топологическая сортировка у меня.
Топологическая сортировка.
Значит, определение dag – это directed acyclic graph.
Ну, соответственно, по-русски это ориентированный циклический граф.
А циклический значит без циклов.
То есть если на нем запустить вот эту штуку, то мы не найдем ни одного цикла.
Ориентированный граф без циклов.
А циклический.
Топологическая сортировка – это такая перестановка вершин p1, p2 и так далее pn.
Перестановка вершин графа.
Перестановка вершин графа.
Что ребра исходного графа ведут только слева направо.
То есть ведут из вершин с меньшим номером в вершины с большим номером.
Такая, что ребра графа ведут только слева направо.
То есть из pi в pj только для i меньше, чем j.
Только в порядке увеличения индекса в этой перестановке можно иметь ребра.
Это топологическая сортировка.
Просто какая-то перестановка вершин такая, что ребра идут только слева направо.
Нет ребер справа налево.
Ну, пример какой-нибудь давайте нарисуем.
Какой-нибудь DAC и какая-нибудь у него топологическая сортировка.
Вот я такое что-нибудь нарисую.
Так, 0, 1, 2, 3, 4, 5, например.
Тогда что будет являться топологической сортировкой?
Например, можно написать что-нибудь такое.
2, 1, 3, 4, 0, 5.
Давайте проверим, что ребра действительно в такой перестановке идут только слева направо.
Вот есть ребро 2, 1, слева направо идёт 1, 5, слева направо 2, 0, 0, 5, 2, 3, 3, 0, 3, 4, 4, 5.
Ну вот действительно все идут слева направо.
Никаких других нет.
На ней нет ребер справа налево.
Простое упражнение.
Топологическая сортировка есть только у ациклических графов.
Есть только у ациклических графов.
То есть если в графе есть цикл, то надеюсь на топ-сорт нельзя.
Но это совсем просто.
Если есть цикл, то не может быть такое, что все ребра в нём идут слева направо.
Когда-то мы обязательно должны вернуться справа налево.
Вот, значит, если есть у меня граф какой-то ориентированный, то чтобы в нём был топ-сорт,
надо, чтобы он был ациклическим.
Давайте теперь найдём топ-сорт, зная, что он ациклический.
Найдём топологическую сортировку в даге.
В ориентируемом ациклическом графе.
Решение будет следующее.
Значит, мы перебираем номер вершины.
Запускаем от неё DFS, если она белая.
Если color от V это white, тогда DFS от V.
И в конце, чтобы получить топ-сорт, нужно напечатать все вершины в порядке убывания Т-аута.
То есть мой DFS, он для каждой вершины проставляет время входа в неё, время выхода из неё.
Раз у каждой написано Т-аут, они все различны,
давайте тогда напечатаем в порядке убывания Т-аута.
Это будет топ-сорт.
Это и будет топологическая сортировка.
Наверное, это надо доказать, почему это верно.
Почему это топологическая сортировка?
Нам надо доказать, что ребра идут только слева направо.
То есть каждое ребро, если оно встречается в нашем графе,
то оно идёт из вершинки с большим Т-аутом в вершинку с меньшим Т-аутом.
Давайте теперь переформулируем то, что нам надо доказать.
Если УВ это ребро, то надо доказать, что У будет расположено раньше, чем В в этом нашем порядке.
То есть у него больше Т-аут.
Т-аут от У больше, чем Т-аут от В.
Это надо доказать.
Это будет достаточно.
Тогда то, что мы напечатали в порядке убывания Т-аутов, это будет топ-сорт.
То есть если есть ребро, то есть какое-то отношение на Т-ауты.
Ну хорошо, давайте переберём два случая, какая из двух вершин была посещена первой.
Сравним.
Т и над У и Т и над В.
Значит, случай первый.
В У мы вошли раньше, чем в В.
Т и над У меньше, чем Т и над В.
Что это значит?
Это значит, что мы вошли в У.
В тогда была ещё белая.
Мы до неё не дошли, то есть только позже её увидим.
Поэтому В белая в момент, когда мы входим в У.
Мы сюда вошли, перекрасили сразу в серый, а это ещё белая.
Ну мы с вами знаем, например, по лемме о белых путях, что раз у меня есть целиком белый путь, ведущий вот эту вершинку, в эту белую вершинку В,
значит до того, как я выйду из У, я успею в это целиком работать.
То есть у меня от неё рекурсивно запустится ДФС, он целиком отработает, перекрасит её в чёрный, и только потом я выйду отсюда.
Поэтому, в частности, по лемме о белых путях, выйду отсюда и раньше, чем отсюда.
Ну то есть здесь лемма о белых путях это, конечно, оверкил.
Можно что-то более простое сказать.
Ну раз есть белый ребро, то я сначала, ну не совсем.
Да, я, возможно, в неё как-то вот так по-другому попаду.
Да, то есть по какому-то другому пути.
Но неважно, окей, да.
По лемме о белых путях, к моменту ТАУТ от У, В уже посетится, то есть ТАУТ от В меньше, чем ТАУТ от У.
Это то, что мы хотели доказать.
Ну а что, если есть ребро, то есть неравенство вот такое между ТАУтами.
Ну теперь второй случай, когда, наоборот, зашли в В раньше, чем в У.
Зашли в В раньше, чем в У.
Зашли сюда, перекрасили её в серый.
А это ещё, это ещё белое.
Это белое, а это вот серое, мы в неё только что зашли.
Ну тогда я утверждаю, что к моменту времени выхода из В к моменту ТАУТ от В, я У точно не смогу посетить.
Потому что если я, ну то есть смотрите, у меня ДФС запустился от В, да, ДФС от В, я в неё зашёл, запускаю рекурсивный ДФС.
И пусть, к моменту времени выхода отсюда, я посещу У.
Но это тогда означает, что я нашёл какой-то путь из В в У.
А это бы означало наличие цикла в исходном графе.
А мы предполагаем, что у меня исходный граф ДАГ.
Противоречие.
Значит, если к моменту ТАУТ от В алгоритм В, то есть у меня ДФС.
К моменту ТАУТ от В алгоритм посетит У, то в графе есть цикл, что противоречит условию.
Ну потому что как мы можем, то есть мы запускаем ДФС от В, У к тому моменту времени была ещё белая.
Как может быть такое, что мы попали из В в У?
Ну попасть мы можем только по ребрам, только по стрелочкам.
Мы нашли какой-то путь из В в У.
Значит, если его замкнуть по среднему реброму, то будет цикл. Противоречие.
Значит, к моменту времени выхода из В мы У ещё не трогали вообще.
Значит, она белая в момент времени выхода.
Значит, У белая в ТАУТ от В.
Ну значит, только после этого момента я её когда-то найду, У как-то найдётся в моём обходе.
То есть мы её либо из какой-то другой вершины посетим, либо вот здесь вот запустимся непосредственно ДФС от У в мейне.
То есть в мейне запустим ДФС от У.
В итоге в любом случае У мы начнём видеть только после ТАУТ от В.
Поэтому не просто вот то неравенство выполняется, а даже вот это выполняется.
Что ТИ на ТУ больше, чем ТАУТ от В.
Ну значит, ТАУТ, который больше, чем ТИ на ТВ, подавно больше, чем ТАУТ от В.
Конец. Доказали, что если ребро между У и В есть, то есть требуемое неравенство на ТАУТы.
Поэтому то, что мы построили, это топ-сорт.
Вопросы?
Окей.
Так, тогда зачем это может быть нужно, например?
Пам-пам-пам.
А, пример.
Пусть, например, нам задан дак, ориентируемый на циклический граф,
и нам нужно в нём найти число путей.
Просто число путей в даге.
Так, я вот, не уверен, я хотел сказать, что задача
подсчёта числа путей в произвольном графе, она,
заполином пока неизвестно, решается или нет.
Но не буду говорить такого утверждения,
короче, в произвольном графе задача сложнее.
Проверить число путей в произвольном графе,
найти точнее число путей в произвольном графе сильно сложнее, чем найти число п VII,
типа, было бы VERYriers.
Ага, хорошая такая задача для меня.
найти точнее число путей в прерывном графе сильно сложнее, чем найти число
путей в ориентированном ациклическом графе.
Ну как это сделаем? Очень просто, с помощью топсорта.
Давайте выпишем топсорт. Это какой-то порядок вершин.
И ведем динамику. Пусть dp от v это число путей, которые начинаются в вершине v.
Число путей, начинающихся в v.
Начинаешься в v.
Как такие пути могут быть устроены?
Давайте скажем, что это топсорт.
Давайте найдем в этой перестановке v.
Как может быть устроен путь, начинающийся из v?
Но есть две опции. Либо мы начались в v и сразу закончились.
Никуда не идем, просто путь из одной вершинки.
Либо мы пытаемся прыгнуть туда направо, используя ребро.
Из всех этих ребер, которые ведут из v, мы выбираем какое-то одно.
И, соответственно, пытаемся продолжить путь, начиная с какой-то этой вершинки.
Поэтому можно писать такую простую формулу.
dp от v это единица, плюс сумма по всем u таким, что v, u это ребро.
dp от u.
Потому что если я фиксировал какое-то первое ребро, скажем, из v в u,
то чтобы найти число продолжений, мне, по сути, нужно просто узнать, сколько есть путей, и начинаешься в u.
Это dp от u.
Значит, вот выполняется такая формула для пересчета dp нашей.
Ну а насчитать ее можно очень просто, пройдя справа-налево по нашему массиву топ-сорта.
Потому что мы видим, что каждая dp зависит только от того, что расположено справа.
Значит, если я буду идти справа-налево по моему массиву топ-сорта,
то, зная все, что располагается справа, то есть зная все вот эти значения,
dp от v однозначно восстановляется по этой формуле.
Время работы, конечно, здесь будет линейное.
n плюс m.
Потому что, во-первых, топ-сорт строится за столько, потому что dfs работает за n плюс m.
Ну а дальше, чтобы эту динамику насчитать, мне нужно завести n в ней ячеек,
и потом пересчитывается она за время от m.
Потому что каждое значение пересчитывается через размер этой суммы, количество слагаемых здесь.
Это число ребер, исходящих из v.
Ну и сумма размеров вот этих вот сумм, она как раз будет число ребер просто.
Ну от m.
Согласны?
Кайф.
Так, времени еще немножко есть.
Давайте тогда мы начнем алгоритм Косараю.
Не успеем его закончить, но по крайней мере сам алгоритм опишем.
Так, алгоритм Косараю.
Это алгоритм нахождения всех компонентов сильно связанных.
Ну, по крайней мере, это алгоритм кассарая.
Ну, вот, это алгоритм кассарая.
Кассараю.
Это алгоритм нахождения всех компонентов сильно связанности.
Компонент сильно связанности.
То есть, вот у меня есть граф.
Мы помним, что отношение сильно связанности, когда мы можем дойти из u в v в u в обе стороны,
значит, мы хотим разбить все вершины на классы эквивалентности по этому отношению.
То есть, на компоненты сильно связанности такие, что внутри каждой компоненты
между любыми двумя вершинами есть путь в обе стороны,
а между вершинами разных компонентов нет пути хотя бы в одну из сторон.
Значит, давайте сделаем тогда следующее.
Начало будет такое же, как в топ-сорте.
Мы, значит, сначала вот эту, короче, вот эту штуку, я просто сюда скопирую.
То есть, я сначала все вершины крашу в белый,
потом, ну, вот, в порядке от 0 до n-ой спермы, на самом деле, не важно в каком,
в каком-то порядке запускаю DFS-ы из всех непосещенных вершин, то есть, из всех белых.
И дальше вот пусть p, пусть p, это список вершин в порядке убывания т-аутов.
Список вершин
в порядке убывания т-аутов, так же, как раньше.
То есть, например, если бы мой граф из входа был ациклическим,
то к этому моменту я бы получил топ-сорт.
Если в графе есть циклы, то, ну, это, понятное дело, не топ-сорт,
топ-сорта вообще не существует для графов с циклами.
Это просто какая-то перестановка вершин.
Вот, а дальше делаем следующее.
Красим опять все вершины в белый.
Мне лень писать код, давайте я словами напишу.
Значит, красим все опять в белый.
А дальше проходимся по вот этому, по этой перестановке p,
и для каждой белой вершины, которую встречаем,
запускаем DFS по обратным ребрам.
То есть, DFS, ну, по сути, в обратном графе.
Если было ребро из u в v,
то, когда я делаю обратный граф,
ну, строю реверс к этому графу,
то у меня будет обратный ребро из v в u.
Короче, я, по сути, меняю направление всех ребр.
Так вот, значит, я прохожусь по перестановке p,
для каждой белой вершины запускаю DFS по обратным ребрам,
и все, что я обойду вот этим обратным DFS-ом,
это будет очередная компонента сильно связанности.
Проходим по p,
запускаем,
я вот так пишу, DFS реверсанта
от белых вершин.
Все, что посещает очередная итерация DFS-а,
это новая компонента сильно связанности.
Новая компонента сильно связанности.
Значит, доказывать корректность будем в следующий раз,
пока давайте пример нарисуем
того, что этот алгоритм делает.
Ну, смотрите, первый пример, когда граф исходно был ациклический.
Пример первый, когда граф ациклический.
Что-нибудь вот такое нарисую.
Значит, тогда мы знаем, что к моменту времени,
когда построено p, когда мы посортили все вершины
по убыванию т-аута,
мы на самом деле построили топ-сорт.
То есть первой, грубо говоря, будет вот эта вершина,
потом вот эта, ну, например, в таком каком-то порядке
может быть у меня топ-сорт.
Тогда, смотрите, если я буду запускать DFS
по обратным ребрам вот в том порядке,
в котором мне адептуется эта перестановка,
то есть, по сути, у меня есть вот такое порядочение
всех вершин сверху вниз, в каком-то смысле сверху вниз.
Я запускаю сначала DFS по обратным ребрам
от самой верхней вершины.
Понятно, что в нее нет никакого входящего ребра.
Поэтому она будет сама по себе
отдельной компонентой сильной связности.
Одна вершина, больше с ней никого
в компоненте не будет.
Дальше, например, вот эта вершина идет у меня
в перестановке p. Я опять от нее запускаю DFS
по обратным ребрам, то есть, по сути, я мог бы как бы
перейти вот сюда, но
поскольку она уже перекрашена
в черный, она уже использована в другой компоненте,
я никуда не поднимаюсь, это будет
отдельная KSS, компонент сильной связности.
То же самое для всех остальных.
Запускаю здесь, идти некуда, потому что там уже все занято,
это отдельная KSS. Запускаюсь отсюда,
идти некуда, потому что это уже занято, это уже занято,
это уже занято, они все использованы,
поэтому это отдельные компоненты
сильной связности. Тоже самое здесь.
В случае, когда GraphDuck,
у меня все компоненты сильной связности,
это отдельные вершинки.
Если же это Duck,
то все
KSS, я буду леницей писать,
то, что компоненты сильно связанности, это просто
1 элемент множества.
Ну, потому что понятно, как могут 2 вершины быть
в одной компоненте.
Как могут быть 2 вершины u-ve в одной компонент с saints
inator или sv3, значит, есть какой-то такой путь,
цикл. Значит, если хотя бы какая-то ксс, хотя бы двуэлементная, значит есть цикл в графе.
Да, поэтому если он ациклический, то значит такого не будет, все они в отдельных компонентах.
Так, пример второй.
Пример второй, пример второй. Ну что-нибудь, что-нибудь поинтереснее с циклами давайте граф рассмотрим,
какой-нибудь, что-нибудь такое, такое. Вот такое. Вот смотрите, вот такой граф.
Значит, ну здесь видно по картинке, есть писание так нарисовал, что вот это вот отдельная ксс,
вот это отдельная ксс и вот это отдельная ксс. Потому что внутри каждой компоненты,
ну по сути это цикл. Значит, ну ясное дело, что если у вас есть цикл, то можно между
любыми двумя добраться в обе стороны. Если я буду добавлять другие ребра, то это будет подавна ксс,
что-нибудь такое, тоже ксс. Вот, ну а между разными компонентами нет, ну не может быть
идти в обе стороны. Например, вот отсюда я не могу, то есть я могу попасть сюда, но обратно уже никак
не попаду, потому что вот отсюда нет ребер туда и никак по-другому я не смогу туда попасть. Вот в ту
компоненту я никак попасть не смогу вот отсюда. Поэтому у меня будет три такие ксс. Значит, дальше,
как будет работать p? Как выглядит перестановка p? Ну, например, здесь может быть что-нибудь такое.
Сначала тут будут, сейчас. Напоминаю, p это у меня вершины в порядке убывания т-аута. То есть в начале
идут те, у которых максимальный т-аут. Такой максимальный т-аут. Ну, скорее всего, у вот этих
вершинок, потому что, ну, например, я запускаю с dfs изначально вот отсюда. Тогда я сначала обойду
всю компоненту, потом, например, запущусь отсюда, потом вот отсюда, всё обойду. И чтобы выйти отсюда,
мне, короче, придется обойти весь граф. Поэтому максимальный т-аут будет у вот, этих вот вершин.
То есть, в начале у меня будет, как бы ну, какая-то вершинка вот отсюда. Ну, там, не знаю,
p0 будет отсюда. Потом от сюда будет какой-то p1, отсюда будет какой-то p2. Ну так, неформально. То есть,
понятно, что максимальный t-aut будет у вершин отсюда, потом t-aut поменьше будет у вершин отсюда,
самый маленький будет у вершин отсюда.
Значит, когда я запускаю DFS по обратным ребрам, скажем,
от какого-нибудь вершины отсюда, то я могу посетить
только вот эту компоненту связанности, потому что
все остальные ребра идут как бы наоборот из этой
компоненты, то есть вот это ребро, вот это ребро,
я их не буду рассматривать, я по обратным ребрам посещу
только вот эту компоненту связанности.
То же самое здесь, я вот это назначу отдельно к СС,
потом я перехожу сюда, обхожу все, что доступно
по обратным ребрам.
Это вся к СС и больше ничего, потому что есть вот это входящее
ребро, оно ведет в уже посещенное, я туда не иду, ну а это из
входящего ребра, я его игнорирую, поэтому это тоже найдется
как отдельное к СС.
Ну и здесь останется три вершины, я запускаю вот
любой из них, тоже нахожу целиком всю к СС, больше
никуда не поднимаюсь, потому что они уже посещены, значит
это тоже отдельное к СС.
То есть я найду все правильно, как и надо.
Все доказательств стоят в следующий раз, спасибо.
