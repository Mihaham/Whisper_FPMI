В прошлый раз мы с вами, насколько я помню, мы все проговорили
про квариацию и корреляцию, свойства их доказали,
там все здорово было.
Соответственно, сегодня последний раздел у тервера,
мы коснемся этой предельной теории.
Начнем с неравенств, с неравенств для вероятности,
с помощью которых будут доказываться наши предельные
теории.
Развественно, первый результат неравенства Маркова.
Чем он говорит, что, если у нас кси не отрицательная
случайная величина, существует математическое ожидание
кси, то утверждается, что для любого епсуума больше
0 будет верно следующее неравенство.
Вероятность того, что кси больше либо равно епсуум,
меньше либо равно от ожидания кси, делить на епсуум.
Это кстати в тему того, зачем, в частности, почему мы
так много занимались математическим ожиданием, вы должны понимать
Я много раз говорил о том, что нас интересуют вероятности
подобного вида.
Из банальных бытовых соображений, если кси – это ваш средний
балл, то у вас интересует вероятность, что они будут
больше или меньше каких-то значений.
Получается, что мы эти вероятности сможем оценивать через
выражения, в которых будут участвовать моменты ваших
случайных величин.
Идея ясна?
Киваем?
Хорошо.
Так, как это доказывается.
Смотрим, что такое математическое ожидание кси.
По определению, не по формуле, а по определению, мат ожидания
кси считается как сумма произведения вероятности
по элементарным исходам на значение случайных
величин, случайные величины в этих элементарных исходах.
Чтобы я вообще мог написать эту сумму, мне поэтому пришлось
потребовать, чтобы у меня мат ожидания существовало.
Дальше эту сумму я разобью на две суммы.
Сумма по таким омега, что кси от омега больше любя
внуя эпсуум, на сумму по таким омега, что кси от омега
получается меньше эпсуум.
Дальше что я сделаю?
Меня интересует вероятность вот таких вещей, вот это
меня не интересует, поэтому я просто выкину.
Если я это выкину, что у меня произойдет с суммой?
Не увеличится, может тут слагаемых ноль, но она
точно у нас не увеличится.
Это первое, что я сделаю, а второе, что я сделаю, получается
вот в этой сумме каждый кси от омега у нас будет
больше чем эпсуум, правильно?
Поэтому если я сейчас вместо вот этого кси напишу эпсуум,
я тоже не увеличу мою сумму.
То есть получается, что здесь будет сумма по всем
омега таким, что кси от омега больше и равно чем эпсуум.
Вероятность этого омега маленького множество на
эпсуум.
Все в порядке?
Окей.
Теперь мы видим, что соответственно этот множитель не зависит
от индекса суммирования, он выносится за знак суммирования,
получается мы суммируем вероятности элементарных
исходов по таким элементарным исходам, что выплыл нет,
но понятно, что если мы соберем все эти омеги вместе, мы
получим вероятность события, что кси от омега больше
либо равно эпсуум.
Ну и все, деля на эпсуум мы получаем то, что мы хотели
доказать.
Ну то есть вообще несложно.
Следствие из-за этого результата, которое мы называем неравенство
ЧБ-шоу.
Неравенство ЧБ-шоу заключается в том, что если у вас есть
произвольная случайная величина кси, для которой
существует дисперсия, понятно, что от ожидания дисперсии
могут не существовать.
А может быть так, что существует дисперсия, но не существует
от ожидания?
Ну да, она призначена из-за от ожидания, было бы странно.
Хорошо.
Что утверждается?
Что для любого эпсуума больше 0, вероятность того, что
кси отличается от своего от ожидания, как нас очень
тихо на нос существует, больше чем эпсуум, вероятность
такого события будет не больше, чем дисперсию
случайной величины кси делить на эпсуум в квадрате.
Ну это действительно следствие неравенства Маркова, потому
что мы в качестве случайной величины рассматриваем
вот этот вот модуль.
Очевидно, это не отрицательная случайная величина, у которой
существует математическое ожидание.
Не, ну нехорошо, тут же у нас непонятно, поэтому
давайте сделаем вот так.
Вот такую случайную величину рассматриваем.
Поскольку дисперсия существует, мат ожидания это и есть
дисперсия кси, это же видно, ну просто по определению.
Поэтому для этого выполнено, что с одной стороны эта
штука не отрицательная, с другой стороны существует
мат ожидания это.
То есть выполнено все требования неравенства Маркова, отсюда
любого эпсуума больше у нуля, вероятность того, что
это больше эпсуум в квадрате, это будет меньше верно,
чем мат ожидания это делить на эпсуум в квадрате, а
это и есть дисперсия кси делить на эпсуум в квадрате.
Ну все, 4d.
Понятно, откуда квадрат взялся?
Я вот здесь неравенство взял в квадрат.
Программа восьмого класса.
Если обе части неравенства не отрицательны, то возведение
в квадрат приводит к односильному неравенству.
Вы очень задумчивы над этим результатом как-то.
Закон больших чисел.
Стандартная аббревиатура, никто не пишет закон больших
чисел, все пишут ЗБЧ.
Давайте я его сначала сформулирую, потом поговорим о чем речь.
Пускай у нас есть последовательность случайных величин x1, xn.
Независимо одинаково распределенные случайные величины.
Тоже стандартная аббревиатура, вы к ней привыкаете, потому
что много теорем будут содержать это.
Независимо одинаково распределенные случайные величины.
А что про них известно?
Что существует дисперсия кси и т.
Как они между собой связаны?
С чего вдруг?
Почему?
Это все понимают?
Поскольку дисперсия, так же как любое математическое
ожидание, является характеристикой распределения, то если
у величины одинаковое распределение, то и все
моменты, все эти характеристики у них будут одинаковые.
Поэтому в принципе можно было написать вот так.
То есть существует дисперсия кс и т.
Давайте, раз у них одинаковые дисперсии...
Мат ожидания существует, поскольку существует дисперсия,
мат ожидания обозначен как А.
Что утверждается?
Утверждается, что вероятность того, что кси1 и т.д., кси n
делить на n минуса больше или давно, чем епсул, стремится
к нулю при стремящемся к бесконечности для любого
положительного епсула.
Причем обычно закон больших чисел, но впервые, когда
люди с ним сталкиваются, записывается даже не так.
Они его немножечко ослабляют и пишут.
Вот так, вот так, вот так, вот так, вот так.
Ух!
Ну что, огонь?
Ослабление, то, что сейчас, когда мы будем доказывать,
вы увидите, что на самом деле одинаковую распределенность
можно ослабить до того, что у них одинаковые дисперсии,
как-то связаны математические ожидания.
Можно ослаблять вот этот набор свойств, ну и не требовать,
чтобы у них от ожиданий были даже одинаковые.
Ну как смотрится?
Очевидно, что правда.
Это хорошо, это радует.
Ну сейчас мы это докажем, действительно доказательство
будет коротенькое.
Но основной, как бы, вопрос, который должен быть, какой?
Это единственное, что вас интересует.
В теории Большого взрыва была серия, когда они участвовали
в Кубке физики.
Там Шелдон организовал свою команду.
Ну вот, и когда был последний вопрос, там вываливается
вот такое вот равнение, и говорят, решите его.
У всех был вопрос, что за дичь написано.
Ну то есть вообще непонятно, это зачем.
Ну, явно, что это какой-то глобальный хороший результат,
но как бы вообще непонятно, о чем это хрень написано.
То есть какой-то модуль, больше равно Эбсу, на вероятности
этого стремится к нулю.
Давайте попробуем подумать на смысл происходящего.
Вероятность, что модуль случайно начинай, больше
Эбсу, он стремится к нулю.
Идейно это что значит?
Похоже в каком смысле, ты можешь как-то поточить.
Ну то есть отличаются, да, то есть у вас что получается,
что значение вот этой дироби, эта диробь является
случайной величиной.
Да?
Ну вот, то, что вот эта диробь отличается вот
от него, это кто?
Какой-то мат-объект.
Ну, математический объект, это какой?
Это число.
Вот это у вас случайная величина, это число.
И что говорится?
Вероятность того, что он отличается хоть сколько-нибудь
значим, вот вероятность такого стремится к нулю.
Но на самом деле вот этот результат идеально хочется
воспринимать как?
То, что кси1 плюс этагралия кси n делить на n, стремится
к a при n, стремяющемся к бесконечности.
Почему мы не написали так сразу?
Что вообще с n?
Ну не то, что она не имеет смысла, она непонятна,
вот эта вот часть.
Ну то есть слева у вас идет последовательность случайных
величин.
Ну то есть тут как бы у вас две перемены.
Во-первых, количество слагаемых раз, и во-вторых,
это все функция от элементарного исхода, то есть это случайная
величина 2.
И это стремится к числу 1.
Что значит, что у вас последовательность случайных величин стремится
к чему-то?
Ну можно, конечно, тут как бы понять, что это получается
функция от омега маленького.
Может быть есть какой-то мотанский смысл сходимости?
Какой мотанский смысл сходимости?
Это в мотане такое было, да?
Ну хорошо.
Ну вот.
Это действительно будет сходимость по мере, и нам
это нужно будет тоже в частности отработать в произвольных
пространствах.
Почему?
Потому что то, что вы делали еще раз, чем то, что вы делали
в мотане, на той части, которая касалась меры интегра
Олибего, отличается от того, что мы делаем сейчас.
Мы не знаем природу омега-большого.
Мотан – это как бы вы изучаете там свойства функций, определенных
на Rn и с изначениями в Rn, это основная идея.
То есть область определения ваших функций – это вещь
понятная.
Вы работаете, начиная с какого-то там класса.
Ну вот.
Здесь природа омега-большого неизвестна.
Это понятно?
Проблемы?
Кивайте.
Вы какие-то утухлые сегодня.
Что не так?
Как-то повеселее.
У меня голова болит, поэтому давайте, чтобы было повеселее.
Ну вот.
Поэтому это тоже вопрос, который мы с вами будем
решать во второй части.
Что значит то, что случайный величин, ну в общем случае
измеримые функции сходятся и какие есть смыслы этих
сходимости раз и как они связаны между собой два.
Идея ясна?
Ну вот.
И в этом плане, то есть ценность вот этого результата – она
понятна.
А кто-то может сказать, то есть чем цени, ну хорошо,
есть какой-то предел.
Ура!
И что?
Ну когда у тебя есть скорость сходимости, когда ты можешь
хоть как-то оценить, начиная с каких значений n мы можем
рассчитывать хоть на какую-то точность, тогда да, здесь
же пока этого нет.
Именно в плане тервера, то есть чем вот это, вот именно
та мысль о том, что вот эта дыробь стремится к А, потому
что мы ведь на самом деле, молодец, сейчас снова напишу,
чем вот эта идея, пускай мы пока не понимаем, что
значит стремиться, но чем вот этот результат приятен
с точки зрения вообще тервера, то есть как бы тервера – это
науки, главным объектом исследования которой является
случайный эксперимент.
Ну погромче, ну погромче, как это правильно, да, ну
смотрите, то есть что такое, у вас есть случайная величина
кс1, мы представим себе стандартную историю, то
есть, прошу прощения, моя химическая прошлая дает
о себе знать, вы снимаете пашу какую-нибудь, ну там
у вас есть раствор, и вы снимаете, но как бы на результаты
исследований влияют еще случайные факторы, то есть
у вас есть, ну вот у вас есть какое-то значение
паш, и вот эти вот ошибки, которые у вас влияют на
результаты ваших измерений, всегда во всех этих историях
считается, что среднее значение ошибок оно нулевое, потому
что если у вас это не ноль, то значит у вас есть постоянный
снос ваших значений, вы никогда не сможете восстановить
то истинное значение, которое вы считаете, так постановка
ясна, да?
есть какой-то показатель стандартный, но вот есть
ошибки, и в результате вы получаете чиселка плюс
случайная начина, вы получаете случайную, в чём от ожидания
есть С, и ищете вы С, понятно то, что если вы снимаете
показания ксиеты, но у вас это случайная начина,
она принимает случайные значения, о чём говорит
закон больших чисел, что если вы сделаете несколько
измерений, ну вот, и возьмёте среднее, то при достаточно
большом количестве измерений вы будете близки к числу,
что вы не знаете, идея ясна, то есть вот то, что было
сказано о том, что если вы сделаете несколько измерений,
случайность уходит, идея ясна, то есть та вещь, которая
у вас просто на уровне интуиции находится, да, ну потому
что если бы вот вообще за рамками тервера вам бы
описали задачу, ну как-то красиво её там назвали, вы
бы этот ответ сказали, что надо сделать, ну нужно
сделать несколько измерений, взять среднее арифметическое,
закон больших чисел это обосновывает, давайте докажем,
как нас учит, Тихон делается действительно очень просто,
посмотрим, вот здесь мы обсудили, что поскольку
у нас есть одинаковая распределённость, дисперсии одинаковые, поэтому
достаточно только первые, это не похмелье, чтобы вы
думали, я просто плохо себя чувствую, я что-то понял,
что смотреть в кадре совсем плохо, погнали, понятно,
что это вероятность, она в точности из условий неравенства
чепешоу, то есть вот у вас, ну вот та вот случайная
величина кси, вы вычитаете её математическое ожидание,
потому что видно, что мат ожидания вот этой дроби
это и есть мат ожидания кси1, это же видно, да, ну вот
поэтому я даже звёздочку обозначу, ну а что получается,
что в силу неравенства чепешоу звёздочка меньше или
равна, чем дисперсия, дисперсия чего, ну вот это
то есть кси1 плюс и так далее кси n делить на n и всё это
мы делим на epsilon в квадрате, теперь смотрим дисперсия
дроби, как она прообразуется, ну вот эта штучка выносится
из-под дисперсии в квадрате, ну в силу свойств дисперсии,
то есть у нас будет epsilon в квадрате на n в квадрате,
ну вот, дальше у нас получается дисперсия сумма, да, они
независимы, поэтому получается сумма дисперсии, дальше
мы что видим, что дисперсии у нас одинаковые, но они
предположим равно sigma в квадрат, ну вот, кстати у
нас здесь получается n sigma в квадрат, делить на epsilon
в квадрате на n в квадрате, насчёт sigma в квадрат у нас
всегда дисперсия в это науке обозначается как sigma в
квадрате, ну то есть sigma это среднее квадратическое
отклонение, я о нем говорил, это такое оно дисперсия,
а дисперсия обозначается как sigma в квадрате, при
этом сред Kiddo акунares seit struck in this context we and will
не когда дисперсию будем пользоваться всегда, но
именно она обозначается как sigma в квадрате, чувствуете
отсутствие логики, ничего страшного, вы привыкаете,
то есть как бы так всегда, всё видно, что это стремиться
к нулю упрямин стремляющимся к бесконечности. Что мы могли ослабить? То есть все доказали. Ура!
Что можно было легко ослабить в нашей истории? Принимаются… Ну, что можно было легко ослабить здесь?
Первое замечание насчет независимости. Нафиг она нам нужна. Мы с вами договорились,
что дисперсия суммы распагается в сумму дисперсии, если слагаемая попарно некоррелирована,
то есть квадрация их равна нулю. А мы с вами договаривались то, что требование некоррелированности
случайных величин намного более слабее, чем независимость. Поэтому от независимости
первую можно было избавиться. А насчет… Что еще? Ну то есть от чего можно было легко избавиться? От
одинаковой распределенности тоже можно было легко избавиться, потому что чем мы пользовались?
Во-первых, нам нужно было что сделать? Во-первых, чтобы мот ожидания были одинаковые. Кстати,
нам этим можно было не пользоваться. Если бы мы здесь писали не минус А, а минус там сумма мот
ожидания деленных на Н, это вообще нам не нужно. А дисперсия, что нам нужно? В общем там…
Скажите, пожалуйста, вот эту сумму должна быть какой, чтобы это в результате стремилось к нулю?
Как можно? По маленькой от Н. А поточнее? От Н, да, нет, сумма. От Н в квадрате? Зачем от Н?
У малой от Н в квадрате. Мы понимаем дисперсии, ксиитах – это какие-то числа, мы складываем их
по количеству равно Н. Если вот эта дрянь в результате будет у малого от Н в квадрате,
этого достаточно для того, чтобы это стремилось к нулю. То есть на самом деле это тоже можно было
ослабить. А дальше внимание вопрос. Если все это можно было ослабить, нафиг я так доказывал?
Доказательство, кстати, бы не пострадало нисколько. Оно было бы таким же простым. Почему именно в таком
виде я сформулирую закон больших чисел? Ну, в смысле, применяется. То есть закон, вы должны
понимать, что законы больших чисел очень много в разных вариациях. То есть как вы правильно говорите
о том, что вот это есть сходимость по вероятности. Есть закон больших чисел, так называемый усиленный
закон больших чисел, где будет сходимость почти, наверное, она же почти всюду. Ну вот, поэтому нет.
А второе какое было замечание? Ну так как понятно хотя бы о чем речь, о чем ценности
результата. То есть я же говорил о чем, то что у вас ксишки – это есть независимые как бы результаты.
Одно это уже эксперимент, который вы проводите случайно. И потом вы просто складываете и делите
на Н. Ну понятно, что если они одинаковые и вы их проводите независимо друг от друга, то вот это
нужно. Идея ясна? Хорошо. Законы больших чисел у вас будет много разных, хороших, будете их доказывать.
Ну вот, единственное, только это все будет сильно сложнее, чем вот это. И второй результат – центральная
предельная теория. С вашего позволения, вот здесь вот все будет то же самое. Условия, я имею в виду. То есть
у вас есть последовательность независимых одинаковых с определенных случайных величин. У них
существует дисперсия, мат ожидания обозначается как А. Центральная – это С. Центральная предельная
теорема. Центральная предельная теорема. Давайте я еще вот обозначу СН и кси1 плюс ксен. Вот это условие.
Вот эта первая часть. У вас есть последовательность независимых одинаковых с определенных. У них
существует дисперсия, которую мы обозначаем как сигма квадрата. Ну и мы от ожидания мы обозначим
А. И сейчас у меня будут другие обозначения. Я молодец, ладно, простите меня, пожалуйста.
Так, соответственно, что мы делаем? Если мы возьмем нашу сумму и ее концентрируем, то есть вычислим из нее
математическое ожидание. Дальше мы ее отнормируем, то есть разделим на корни с дисперсией.
С. Центральная. Сейчас мы с вами выпишем как это выглядит, но то тогда вероятность того,
что вот эта дробь, зажата между А и B, будет стремиться при настримящемся бесконечности
Контеграу от A до B. Единицы разделить на корни из 2P, E в степени минус x квадрат пополам dx.
Что, красота? Скажите спасибо, что я это не доказываю. E в степени x квадрат пополам.
Какой-то год я даже пытался это доказывать в ситуации, когда ксишечки это у вас
Бернулевские случайные величины. Вы помните, что такое Бернулевские случайные величины?
Нет. Она принимает значение 1 и 0 с вероятностью P единичка минус P. Соответственно, если у меня
ксишечки Бернулевские случайные величины, то Sn это кто? Я подожду. Бермяальная случайная
величина. Ну это понятно, потому что сумма N независимых каждой принимает значение 0 и 1 с
вероятностью P единичка минус P. Соответственно, Sn будет иметь бермяальное распределение. В принципе,
то есть где-то там три страницы мышенаписанного текста вы это доказали. Потому что понятно,
что вот эти вероятности это что? Если вот это у вас Бермяальная случайная величина, то это всякие
цели из N по К по f степени K единица минус f степени N минус K формулы стирлинга. Потому что N это
стремится к бесконечности. И прямо там такое удовольствие. Кто хочет, может посмотреть,
как это доказывается. Называется интегральный терроримовый ровопласт. В общем, толку никакого,
потому что там идёт любимая Рыгоровская комбинаторика. Ну всякие вот эти выкутки я
терпеть не могу. Понимание это не даёт. Давайте всё-таки попробуем понять, что здесь происходит.
На что вот это похоже? Ну то есть как бы слева понятна вероятность того, что какая-то случайная
величина. Пока не понятно, зачем мы её так составляли, но вот такая случайная
величина зажата между чиселками a и b. И утверждается, что эта вещь сходится куда. Может кто-то чувствует,
что это такое? Горбик это вы про вот эту вот функцию. То есть это действительно у вас так называем
плотность нормального распределения, колка гауссовский стандартный. А когда мы берём интеграл от a до b,
мы тем самым что делаем? Ну а какой вероятностный смысл этой площади? Интуитивно понятно, нет?
Это вероятность. Вот это вот, это вероятность того, что случайная величина эта, которая имеет
нормальное распределение с параметрами 0 и 1, попадает в интервал от a до b.
У вас ещё нет нормального распределения, потому что это не дискритное распределение,
никаких других распределений вы пока не знаете. Ну то есть проблема вот в чём. То есть как бы в те
веры, вы пройдёте произволенные распределения, в частности абсолютно непрерывные. Αбсолютно
непрерывное распределение, то есть это имеет абсолютно непрерывное распределение, если
что вероятность того, что это попадает в какое-то множество а, есть интеграл по множеству а вот этой функции.
То есть вот это вот у вас будет потом такое определение. То есть понятно, теперь вот это вот понятно,
что вот такой интеграл, вероятность попасть в интервал от a до b, где вот эта штука, это есть плотность нашей случайно-минечной.
Вот такие случайно-минечные. То есть вот это вот плотность нормальной случайно-минечной, причем с хорошими параметрами 0.1.
Параметры нормального распределения это на будущее, привыкайте к этому. Первый параметр это математическое ожидание,
второй параметр это дисперсия. Кстати, вопрос в студию. Какое математическое ожидание этой дроби?
А дисперсия? Это видно, да? Теперь давайте попытаемся понять, о чем говорит этот результат.
То есть я беру оба какие случайные величины. То есть смотрите, вот о распределении этих случайных величин не известно ничего.
То есть если я в качестве кси возьму вот эти Бернульевские, которые принимают значение 0.1, то есть проще там только констант.
Слушайте, единственное, только вот ты здесь не ноль, чтобы я делить мог.
Или я возьму какие-то сложные случайные величины, например Плассоновские, или потом вы пройдете непрерывные распределения.
То есть вне зависимости от того, какое у вас распределение случайной величины ксен, вы всегда сойдетесь к нормальному распределению.
Вот в этот момент, вот прелесть Тервьера, причем опять это все идет к тайной мирозданию, какого фига это так.
Причем очень было забавно, когда у меня такая работа была немножко устаревшая, в плане постановки задач.
Я читал кучу всяких статей 80-х годов, и там был вопрос о том, что вот я писал вам вот эту задачку.
Ксиитр равняется Ц плюс Эпслунитр. Эпслунитр это шум, который возникает.
И практически всегда было предположение, что этот шум имеет нормальное распределение с параметрами 0 сима квадрата.
Ну, 0, потому что от ожидания оно не должно быть не нулем, потому что иначе у вас постоянно есть ошибка, которая сносит ваше наблюдение.
Ну и какая-то там дисперсия. И дальше было очень интересно наблюдать.
А кто вам сказал, что у этого шума нормальное распределение? Это было шикарно.
То есть математики говорили, что все вот эти прикладники, у них есть огромные базы наблюдений и всегда получается колокол, поэтому нормальное распределение.
А прикладники в своих статьях писали о том, что математики доказали, что шум всегда имеет нормальное распределение.
Было очень забавно.
Но такое объяснение, почему у шума нормальное распределение, потому что шум складывается из огромного количества факторов с небольшим весом.
Типа, когда очень много всего, получаем нормальное распределение, ссылаясь на центральное определение теоремы.
Чувствуется, что объяснение так себе.
Ну а потом пошли финансы, в которых шум уже ненормальный, и поэтому перестали задаваться этим вопросом.
Фишка в том, что в конце тервера вам докажут этот результат, для этого будет построена целая техника,
потому что вы можете открыть Ширяеву и любую другую книжку, посмотреть, как доказывается интегральный терминал вопроса и просто почувствовать тошноту, потому что это отвратительно.
Но там безумные выкладки, которые тяжелые, и зачем это все нужно непонятно.
При этом с помощью характеристических функций доказывается бусквально несколько строк, и вы это сделаете в общем случае.
И это все произойдет, к сожалению, в конце курса. Обычно центральные определение теорем плохо воспринимают, потому что все, что в конце курса, плохо воспринимается.
Это так работает.
Но я хочу, чтобы вы уже сейчас оценили прелести результата.
Что вне зависимости от того, какие были распределения ваших случайных величин СНТ, впорядок того, что они могут быть дискретные, самые простые или какие-то очень сложные, непрерывные, все равно в пределе всегда получится нормальное распределение.
Поэтому, когда у вас появится это нормальное распределение, не надо плеваться, потому что даже без параметров это отвратительно.
Е в степени минус 6,5, господи, у этой функции даже первообразной нет. Вы знаете, что у этой функции нет первообразной?
Хотите анекдот?
Я когда во второй школе учился, я очень хорошо первообразный считал.
И у моей учительницы карточки закончились в какой-то момент.
Ну, то есть дополнительные задачи.
И она говорит, ну ладно, все, давай, интегрируй.
Я до слез, честно.
Потом дома сидел долго.
Причем я к ней ходил, я говорю, что, как?
Она говорит, ой, отстань, некогда того заниматься.
У меня там много двоечников, и я буду им заниматься.
В втором курсе я узнал.
Потом я прихожу и говорю, что это такое?
Она говорит, я ничего не помню.
Когда у вас появится на тервере нормальное распределение,
причем с параметрами, то есть если у вас n, с параметрами a sigma квадрат, плотность будет выглядеть, прости меня, вот так вот.
То есть мерзость.
Но чтобы вы осознали, что вы от нормального распределения никуда не денетесь,
поэтому с ним нужно будет очень внимательно, аккуратно разобраться.
Потому что это самое главное распределение в тервере вероятности.
Окей?
Хорошо.
Соответственно, доказывать эту историю я не буду.
Даже для самой простой ситуации.
Но опять же вопрос.
То, что вот здесь вот, что вот этот результат это view один educ cancers как видисходности вот этой случайной величины к нормальной случайной величине.
Вероятность того, что случайная величина принадлежит отрезку Huh, стремится к веро continua Eles 가� Mars, что другая случайная волна принадлежит этому же отрезку.
Понятно, что этот результат кажется, что это head enhance вот этого к нормальной случайной величине.
Это тип сходимости, сходимость по распределению или так
называемая слабая сходимость, мы ее не коснемся, но она
в тервере потом появится.
Мне просто не хватит времени для того, чтобы с этим разобраться.
У нас будет два основных вида сходимости.
Это сходимость почти всюду или почти наверно в тервере
и сходимость по мере или по вероятности как в тервере.
Мы будем именно с этими двумя результатами работать.
Это понятно, киваем.
Слушайте, а то, что у нас никогда не бывает перерыв,
это не проблема?
Нормально.
Нормально.
С тервером все.
Давайте сейчас соберем вместе те вопросы, которые
мы с вами разбирали, формулировали в процессе разбора вот
этих поверхностных терверных результатов и дальше начнем
их разбирать.
Соответственно, первые два вопроса, которые взаимосвязаны
между собой.
Я напомню то, что мы работаем в рамках итематической
модели, когда у нас база является вероятностное пространство.
Первое это вероятность элементарных исходов, множество событий
и вероятностные меры на событиях.
Первый вопрос, который есть каково f, что это такое?
Потому что всегда, когда мы работали в дискретной
тервере вероятности в качестве f, у нас было что?
Множество всех под множество омега большого, мы не напрягались.
Но даже простейшая история, когда мы решали задачку
с геометрической вероятностью, то есть мы кидали точку
на какую-то площадь РН, и там было понятно, что
такое вероятность.
Мы упирались в то, что не для каждого под множество
нашего омега большого мы можем задать эту вероятность.
То есть мы не можем в общем случае в качестве f брать
просто так множество всех под множество.
Потом у нас окажется, что на самом деле, не потом,
уже даже сейчас понятно, почему мы не можем задать
там вероятность.
Потому что есть неизмеримые полебегу множества.
Как мы с вами знаем, они есть, но мы не представляем,
как они выглядят.
И поэтому задаться вопросом о том, вероятность того,
что мы попадем в неизмеримые полебегу множества, это
какой-то мазохизм.
Есть как бы, то есть, вы сейчас, извините, так плохо
говорится сегодня.
Тезис о том, что мы страдаем просто для того, чтобы страдать,
он не работает.
Это понятно?
Ну то есть, если что-то больно, то значит вы не допонимаете,
то есть нет!
Если больно, оно как бы больно, это не значит, что
плохо.
Но как бы вы должны понимать, для чего это больно.
Если вам кажется, что это как бы больно, просто для
того, чтобы было больно, значит вы чуть не допонимаете.
Надо попытаться это выяснить.
То есть можно это выяснить у преподавателей, если
они ответ не дают, надо идти к академическому руководителю
вашей программы, и спрашивать, зачем эта хрень нам нужна.
Это понятно?
и он должен суметь на это ответить. Идеальных академических руководителей не существует,
но может быть он сможет. Следующий вопрос о том, как задавать эту меру. Потому что если у вас F
это будет какая-то система под множество, всё равно это будет богатой историей, там будет очень
много множеств. И дальше вам что нужно? Каждому множеству сопоставить вероятность, то есть меру
этого множества. Как это вообще задаётся, это непонятно. Потому что функция задаётся формуле,
вы к этому привыкли. Вы знаете, что она есть, что вы объем умеете считать для произвольных множеств.
Вот это вот. Супремум или инфинум по всем покрытиям. Ну хорошо. В общем случае хотелось бы понять,
как это вообще делать. Следующая проблема, которая у нас с вами возникла с понятием случайной
величины. Что это такое? Я напомню в чём была проблема. Нас в конечном счёте с вами будут
интересовать вероятности вот таких событий. То есть это что? Это вероятность таких омега маленьких,
что кси принадлежит множеству от а до плюс бесконечности. То есть по сути это что такое? Это
есть прообраз луча от а до плюс бесконечности. Всё понятно, что я написал, да? Ну то есть вот это
просто я расшифровал. Это вероятность всех таких омег, что вот это. Но это и есть просто прообраз вот
этого луча. И дальше вопрос. Кто вам обещал, что вот эта хрень будет принадлежать f, если f не множество
всех подножий? Мы с вами вообще не напрягались, потому что у нас был дискретный случай, f будет
множество всех подножий. Поэтому это какое-то подножие омега большого, значит точно принадлежит f.
Если мы ограничиваем f, то кто вам сказал, что это будет его элементом? Никто. Отсюда вывод.
Определять случайную величину просто как какую-то числовую характеристику случайного
эксперимента нельзя. Вы можете упереться в ситуацию, что эта вещь будет неопределена. То
есть надо как-то ограничивать себя в определении случайной величины и мы будем с вами выяснять как.
Четвёртый вопрос. Это сходимость случайных величин. Потому что основные результаты теории
вероятности это все-таки предельные результаты. Вот того типа, который мы с вами выписывали.
Придельные. То есть это про предел, принятость, объявляющимся к бесконечности. Для кого? Для
последовательности случайных величин, которые как правило будут строиться подобным образом как
суммы. Что-то с суммами мы там делаем. Поэтому вопрос о сходимости. Как они сходятся? Пятый вопрос,
который есть тоже непонятный. Вопрос про моменты, про математическое ожидание. Потому что мы с вами
определили, мы отождаем. Когда мы его вводили, мы оттолкнулись от понятия среднего в случайном
эксперименте. Отсюда вывели в нашей мат-модели определение математического ожидания. Это что
там? Это сумма по всем омегам маленьким. П от омега на окси от омега. Понятно, что эта штука
похожа на интегральную сумму. Это у вас дельта х, это мера х. А это значение вашей функции при
этих х. Эта штука похожа на интегральную сумму. Поэтому в общем случае математическое ожидание
будет интегралом. Спойлер, что это будет интеграл Лебега. Но опять же, строить интеграл Лебега
мы пока не умеем в ситуации, когда у нас область определения нашей функции это нечто. Я напомню то,
что у нас с вами омега это множество, на котором нету ничего кроме какой-то системы подмноженств.
Там нету метрики, там нету топологии, нету ничего. И вы пока не умеете строить интеграл Лебега в таких
суровых обстоятельствах. Это понятно? На эти пять вопросов нам с вами нужно будет до конца декабря
ответить. Окей, киваю. Хорошо, начнем с системы множества. Так, система множества. А поднимите,
пожалуйста, руки, кто в посвяти задействовал. Черт, то есть у вас не будет, жалко. Просто у вас
становится все меньше. Каждый слушатель уже на это нарезал. Так, система множества. Смотрите,
вот эти вот два вопроса идут в связке. Почему? Потому что не надо делать F чересчур богатый.
Это понятно, да? Но потому что чем богаче F, тем непонятнее, как задавать на ней P. Поэтому нужно,
когда вы определяете F, ограничиться только теми множествами, которые нам нужны, раз,
чтобы было попроще задавать P. Так, соответственно, первая система множества. То есть мы сейчас что
сделаем? Мы сейчас формулируем последовательно систему множества от самых бедных к тем,
которые нам нужны. Не продумываю я этот переход логически. Поэтому в общем,
просто с определением начнем. Система множеств S называется полукольцом. Если система множеств,
то есть каждый элемент S это какое-то множество. Если выполна следующее требование. Первое. Пустое
множество является элементом этой системы множества. Второе. Эта система множества замкнута относительно
операции пересечения. То есть, если у вас два множества являются элементом S, то их пересечение
тоже должно быть элементом S. И третье требование, что если у вас есть два элемента S,
при этом выполнено то, что один из них является под множеством другого, то утверждается,
что вот это множество можно добить элементом S до этого множества. Что это значит? Что существуют
конечное число элементов нашей системы такие, что множество A представили в виде дизюктного
объединения, а этих поет единички до N. Так вы же знаете, что такое дизюктное объединение. Это ирония
или... Ну да. Хорошо, ладно. То есть мысль какая? Это достаточно бедная система множества.
Давайте рассмотрим пример. Рассмотрим систему полуинтервалов, которые являются под множеством
какого-то фиксированного полуинтервала. Докажем, что это полукольцо. Ничего нам нужно проверить.
Во-первых, нам нужно проверить, что пустое множество является элементом A и B. Соответственно,
это число, а на A и B это число, которое удовлетворяет вот этому требованию. Ну погнали. Первое. Пустое
множество является элементом этой системы. Да или нет? Да. Почему? Хорошо. Дальше. Пересечения
являются... Ну да. Можно? Давайте я корзиночку наносю. Если вы берете два полуинтервала,
то их пересечение это полуинтервал. Ну либо пусто. Поскольку пустое является элементом S,
если это пусто, это уже хорошо для нас. И третье. Если у вас вдруг так оказывается,
что какой-то полуинтервал является под множеством другого полуинтервала, то вы его можете добить
конечным объединением. Но видно, что это правда. Ну соответственно, у вас может быть как? Тут
никакая граница не совпадает. Тогда вот этот маленький можно добить вот этими двумя до большого.
Но если вдруг какая-то граница совпала, то одним. Это понятно? Окей. При этом очевидно,
что вот эта система множеств не замкнута относительно операции объединения. hate
объединения двух полуинтервалов не есть полуинтервал. Ну это понятно. Если они не пересекаются,
вы их объединяете, получаете объединение двух полуинтервалов с дыркой посередине. Ну ладно.
С одной стороны, это система множества она плюс-минус хороша в том плане,��도 что она
замкнута относительно операции пересечения. Потом вот это хрень какая-то непонятная,
понятно, зачем это спрашивают. Пока тайно. Но очевидно
ее нам мало, потому что она не замкнута относительно
тех теоретикам множных операций, которые нас интересуют.
Поэтому ведем следующий объект. Это кольцо. Дайте
вот сюда. Мне здесь хватит. Кольцо. Кольцо называется
системой множеств. Обозначать мы ее будем как R. Как вы
думаете, почему R? Да, мы все любим этот фильм. Что
выполнено следующее? Во-первых, R не пусто. Во-вторых, R замкнута
относительно двух операций. То есть для любых A и B, которые
будет выполнено. То, что A пересеченная с B и A симметрическая
разность B тоже будут являться элементами R. Какие вопросы
у нас возникают? Во-первых, да. Кажется, что судя по
названию, это должна быть более сложная структура.
Эта структура должна обладать всеми теми свойствами. Это
пока не очень понятно. И второе. Странный набор
этих самых операций. Симметрическая разность. Соответственно,
второе то, что кольцо замкнута относительно всех теоретикам
множественных операций. Давайте это докажем. Так,
если R кольцо, то. Во-первых, R полукольцо. И второе. Для
любых A и B, принадлежащих R, будет выполнено. Какие у
нас еще были операции с теоретиками множественных?
То есть A объединенная с B. Еще что? Такие стандартные.
A без B. A без B. Тоже будет элементом R. Никогда не сдавался этим
логичным. Не знаю, я уточню. Вот так вот живешь и живешь,
а тебя вдруг спросит. Хорошо. Погнали. Первое. То, что
оно действительно полукольцо. Первое, что пустое множество
принадлежит S. Почему? R не пусто, то есть есть какой-то
элемент R. Тогда симметрическая разность A с A это есть пустое
множество. Согласно второму свойству, это тоже элемент
R, а R хорошо пустое является элементом R. Так, сейчас
скажи. Вижу недоуменные лица. Что не так? R не пустое
множество. То есть там кто-то есть. Если мы его симметрично
с самим собой пересечем, мы получим пустое множество.
Все его определения симметрической разности. Все знают определения
симметрической разности.
Почему мы требуем линии пустоту вместо того, чтобы
требовались просто что-то содержимое пустое множество?
Какие-то вопросы сегодня задаете, которые я не знаю,
как отвечать. Вообще логично, если там, тут, то так, здесь.
Можно я дальше? Я подумаю и про кольцо, и про это. Нет,
ответы есть, мне просто нужно задуматься над этим
секундом. Так, что у нас там еще? Второе, оно вот, поэтому
неинтересно. А третье, если одно вложено в другое. То
есть мы берем А и А1, при этом А1 является под множеством
А, они оба элемента кольца. Что тогда? Поднимите руки,
кто как бы очевидно, что это равенство верно. Ну,
смотрим. У нас симметрическая разность. Если у нас оказывается
то, что одно множество является под множеством
другого множества, то симметрическая разность это что?Now
дополнение. Ну и все. Соответственно, вот это у вас
А1. Вот это А, а симметрическая разность А и А1, это дополнение.
То есть вот это у вас элемент r по условию. Это элемент
по второму свойству, и ура, мы представили в виде
дизинкутного объединения двух элементов R.
Ура, всё сделали.
То есть действительно кольцо является полукольцом.
Окей.
Второе, то что кольцо действительно замкнуто
относительно всех наших теоретико-множечных операций,
но у нас осталось объединение и разность.
Ну что, а?
Ну давайте начнём с чего?
Давайте начнём с разности.
Или с объединения?
Разность проще?
Разность проще?
Я не помню.
Ну давай разность проще.
Так, то есть вот у нас есть A, у нас есть B.
Сейчас, смотри, есть A, вот есть B.
Так, разность это у нас кто?
Это вот это, да?
Так, и чё?
Это A без A-пересечки с B.
Без у нас нету.
Так мы делаем без.
То есть мы без будем отлипать через без?
Ну то есть хочется взять симметрическую разность,
но симметрическая разность будет включать в себе вот
эту хрень, правильно?
Поэтому что мы делаем?
Мы сначала… А, симметрическая разность с пересечением.
То есть смотрите, мы берём вот это вот пересечение.
Пересечение становится под множеством A большого,
да?
А мы с вами только что договорились, что когда мы берём симметрическую
разность множества его под множество, мы получаем
его дополнение.
Это как раз получается A без B.
Хорошо?
Не цель нашего курса доказывать законы Деморгана, но я думаю,
а вы тренировались там через характеристические
функции, делали это?
Нет?
Ну в общем, мы на картинках понимаем, что это правда,
а если нужно доказать, то пишите свои характеристические
функции.
Все кивают насчёт характеристических функций?
Хорошо.
А где это было?
В какой науке?
Матрогене.
Матрогене.
Хорошо.
Так, и что у нас ещё?
Объединение.
Что, Дин?
A без B?
Ещё раз, A без B?
С это что?
С это типа объединение, но теперь можно симметрическую
разность.
Можно формулу?
A без B, симметрическая разность без B.
Вот так?
Да.
Всё.
Так, A без B, это соответственно у нас вот это множество,
да?
Ну вот.
Если мы возьмём, то есть если вы берёте симметрическую
разность двух непересекающихся множеств, вы получаете
просто их объединение.
Это понятно, да?
Симметрическая.
Ведь что такое симметрическая разность?
Это объединение без пересечения.
Да?
Ну вот.
Чего добился Тихон?
Тихон добился того, чтобы эти две вещи не пересекались
и взял симметрически разносну.
Окей.
Ну то есть всё, ура.
То есть почему кольцо формулируется именно так?
Ну то есть мы будем доказывать, что какая-то тема, что является
кольцом.
Нам хотелось бы иметь наименьший список требований для
проверки того, что это кольцо.
Поэтому сформулируем это так, но идейно это такая
система множеств, что она замкнута относительно
всех операций.
Окей?
Ну вот.
На следующей лекции мы с вами аккуратно будем
строить наименьшее кольцо, содержащее данное полукольцо.
И его элементы, они достаточно легко выиграют.
Хорошо.
Ну поскольку я уже сказал про наименьшее.
Вообще сейчас должно чувствоваться некоторое
раздражение от того, что кольцо – идея понятная.
То есть это система множеств, которая замкнута относительно
всех наших операций, которые мы привыкли.
Понятно то, что F должна удовлетворять вот этому
требованию.
Ну вот.
Нафиг нам вот этот объект?
Такой спойлер небольшой.
Главным результатом достаточно долгого нашего исследования
будет являться теоремка ретеодории.
Я ее сейчас произнесу, но просто чтобы было понятно,
что происходит.
Потом мы до нее дойдем.
Так, представь себе.
Так, сейчас надо сконцентрироваться.
Там мысль будет заключаться в чем?
Что если у нас есть мера, которая задана вот на этой
бедной системе множества.
Она немножечко странная, то есть вообще непонятная,
но просто именно она нам нужна.
Если мера задана на этой системе множеств, то она
однозначно продолжается на наименьшую сигму алгебру.
Сигма алгебра – это будет система множеств, которая
замкнута относительно всего и еще там счетного их
количества.
Ну так вот, если мера задана на полукольце, она однозначно
задает меру на наименьшую сигму алгебру, которая содержит
полукольцо.
То есть достаточно задать меру здесь, и после этого
она переносится на наименьшую сигму алгебру.
А это самая бедная система множества, на ней легко
задавать меру, и мы с вами будем это делать.
Идея ясна?
Именно поэтому мы занимаемся вот этой странной.
Она решительная страна.
Вот кольцо не странное, это просто система множества
замкнутой системы всех операций, это понятно.
А вот это странное.
Такое использование, чтобы было понятно, почему мы вообще
с ней работаем.
Сейчас основная проблема, которую нам нужно с вами
обсудить, вот эта приставка наименьшей сигмы алгебры,
которая содержит данное что-то.
Во-первых, почему такое существует, что это и из чего оно
состоит.
Начнем в этом постепенно разбираться.
Первое утверждение, которое нам нужно.
Пересечение любого числа колец.
Есть кольцо.
Оно может быть совсем бедным.
Кстати, какое самое маленькое кольцо?
Множество состоящее из одного элемента пустого множества.
Понятно, что это самое маленькое кольцо.
То есть вот это должно быть выполнено.
Один элемент в нём должен быть и дальше должны быть
выполнены такие требования.
Понятно, что самое маленькое кольцо состоит из пустого множества.
Идея в чём? У вас есть система каких-то колец. При этом
у вас число их любое, то есть не обязательно счётное.
Количество, ты так хочешь. Соответственно в качестве
r получается, что мы берём пересечение r альфа, где альфа
принадлежит лямбде большой. Почему в частности, в чём
ценность этого курса? Когда вы уже на стадии математической
статистики будете вспоминать этот курс, вам будет тяжело
вспомнить, какие результаты там были. Чем он нужен? Кто
математический объект? Это система множеств. Вы пересекаете
системы множеств, то есть вы ищете одинаковые множества
в этих системах и из них будет состоять вот эта
новая система множеств. Обычно у народа это плохо воспринимается.
То есть у вас теперь новым объектом, новым множеством
является множество, состоящее из множеств. Тяжело это
идёт, потому что раньше вы с этим не особо работали.
За эти полгода вы как бы свыкнетесь поработать
с разными системами множеств и это перестанет вас травмировать.
Теперь погнали. Почему r? Для того, чтобы проверить,
что какая-то система множеств является… Понятно, что если
мы пересекаем систему множества, мы получаем систему множества.
Чтобы проверить, что это кольцо, нам нужно проверить
те три фактора. Первое, что r не пусто. Почему r не пусто?
Для любого альфа у вас пустое множество является элементом r альфа,
но поскольку это выполнено для любого альфа, то отсюда мы получаем,
что пустое будет элементом r. Ура, значит оно не пусто,
потому что пустое множество является его элементом. Красиво.
Поэтому вот так. Второе, то, что замкнута от всех операций.
Двух. Нам нужно двух. Давайте возьмем два элемента r.
Поскольку они являются элементами r, отсюда следует, что для любого альфа
a и b будут элементом r альфа, потому что r определялся как пересечение.
Поскольку a и b элементы r альфа, а r альфа само по себе кольцо,
отсюда мы получаем, что и пересечение a и b, и симметрическая разность a и b
будет элементом r альфа, потому что r альфа – это кольцо.
А теперь смотрим. Вот это множество под любым альфа является элементом r альфа,
значит оно возьмет в r как пересечение. То же самое здесь. Все.
Ну, неинтеллектуально. Окей? И важные следствия из этого результата.
Ой, слушайте, я еще одно не ввел в систему.
Это был алгебр.
Определение.
Так, система множеств.
Это я попытался нарисовать a красивое. Вот эта буква a, такая ветереватая.
Называется алгеброй.
Если, во-первых, a – это кольцо, и, второе, если существует элемент этого кольца,
такое, что любой другой элемент этого кольца является под множеством этого множества.
Получается, что a – это система под множество нашего e, и само e входит в эту систему.
Все понятно, да? Окей.
Соответственно, вот это множество называется единицей.
То есть, по сути, что такое алгебра? Это кольцо с единицей. В принципе, так везде и пишут.
Вот, пожалуйста, у вас здесь полукольцо. Да, иногда есть такое понятие, как полукольцо с единицей.
Вот, пожалуйста, вам пример полукольца с единицей.
То есть, у вас эта штука является в силу определения элементом этой системы множества,
и каждый его элемент является под множеством этого элемента. Это понятно? Окей.
При этом здесь я мог взять какое полукольцо другое. То есть, было, например, не так, а просто вот так.
Хорошо? То есть, я беру все полуинтервалы прямой. Окей?
Все тогда здесь тоже будет выполнено, при этом единички у нас при этом нет.
То есть, нет такого множества, что он является элементом этой системы, и любое другое является его под множеством.
Так.
Но, смотри, вот если я здесь объединю их всех, я не получу элемент данного множества.
То есть, если объединение всех является элементом нашей системы, то тогда да.
Просто объединение всех не обязательно конечным.
Ну, конечным. В каком смысле?
В элементах всех может быть.
У нас с вами будет... Ну, вы, наверное, уже в мотоне с этим столкнулись.
То есть, соответственно, вы долго и упорно на КТЧ занимались вопросами мощностей множества.
Доказывали, что у вас множество равномощные, питью способами. Такое множество, такое множество. Я видел листки.
Я сам плохо это умею делать, если честно. Но я этим занимался только на первом курсе.
Ну вот. А дальше у вас появился вопрос мощностей множества, а появилось меры множества Лебеговской.
Ну, на Мотонеево-Лебеговской занимались. И Жардановской, да? Да?
Вообще разные вещи с вами между собой связаны. Это же понятно, да?
Хорошо.
Так. Следствие вот здесь. Вот из этого результата.
Пересечение любого числа алгебры с общей единицей.
Это и есть алгебра.
Пересечение любого числа алгебры с общей единицей. Это тоже будет алгебра.
Ну, тут добавляется только еще один пункт.
То, что вот это е, которое общее у всех Р альфа, оно будет принадлежать этому Р.
Ну и все.
Это понятно.
Теперь определение.
Наименьшим.
Наименьшим.
Извините. Неправильно. Минимальным.
Минимальным.
Ну, вот.
Минимальным кольцом.
Минимальным кольцом.
Содержащим данную систему множества.
Содержащим данную систему множества.
Ну, как-то мы ее будем обозначать. Х.
Минимальным концом, содержащим данную систему множества Х.
Называется кольцо. Мы его всегда будем обозначать Р в скобочках.
То есть, как бы, Р это у нас в этой науке всегда будет кольцо.
А в скобочках указывается система множеств,
которая порождает это кольцо.
Ну вот. Что выполнено?
Ну, два слова. Два требования, очевидно.
Во-первых, Х является элементом Р от Х.
Что?
Что? Нет.
Хорошо, ладно.
Тебя выгнать надо, ты мешаешь.
Понятно, что так.
Еще раз, и Х это система множеств,
и Р от Х это тоже система множеств.
Имеется в виду то, что...
Смотрите, Х это у вас какая-то система множеств,
которая не замкнута относительно каких-то операций.
Понятно, что когда вы получаете систему множеств,
которая будет замкнута,
то есть, вы обогащаете Х новыми множествами,
объединениями, пересечениями элементов Х,
чтобы система множества стала замкнута.
Это понятно, Кеварин?
Понятно, что она становится богаче.
То есть, там множеств будет больше.
То есть, первое, что Х входит в наше кольцо,
а второе какое? Требование.
Ну, то, что минимальность.
В чем будет заключаться минимальность?
Любого кольца R1.
Любого кольца R1, такого, что Х содержится в R1,
будет верно что?
Ну, наоборот.
Оно же минимальное.
Вот так вот.
Минимальное.
В чем фишка, почему минималь не наименьшая
в этом плане, чем терминология?
Потому что, смотрите,
на множестве колец нет операции сравнения.
Это понятно, да?
Но это для любой пады выполнено?
То есть, отношение сравнения для любой...
Ну, так он же частичный.
Но частичные варианты бывают наименьшие в множестве.
Это те, которые сравнены с кем угодно,
и меньше их.
Ты загнал меня в угол сегодня.
По идее, правда, да.
Ну вот, да.
Если мы сейчас докажем, что оно единственное.
Да, если оно единственное, то оно наименьшее.
Так, ну, соответственно, теорем.
Ну, то есть, наименьшее кольцо, которое содержит,
надо поднять.
Слушай, напиши мне список,
на чем я сегодня тупил, пожалуйста.
Аккуратно проверю.
Так, теоремы.
Наименьшее кольцо существует.
Минимальное. Все-таки минимальное.
Нет, там уже какой-то был смысл.
Я забыл.
Да все, так, спокойно.
Напиши мне, я выясню.
Я в следующий раз расскажу.
Хорошо.
Почему существует?
Почему аэротех существует?
Ну, то есть, нам нужно его просто предъявить,
и потом доказать, что он творяет этим требованием.
Ну, для того, чтобы что-то пересекать,
надо быть уверен, что хотя бы одно есть.
Почему существует хотя бы одно кольцо,
которое содержит аэротех?
Его надо как-то предъявить.
Давайте подумаем, как можно предъявить
кольцо, которое содержит аэротех?
Еще раз.
Подожди, стоп,
давай вслушаемся.
Множество всех подмножеств, кого?
Множество всех подмножеств
элементов х.
Пускай у нас х
состоит из...
Вы какой курс вообще?
Какие у вас группы?
100, да?
Вы сотки, да?
Ну, то есть, как бы х, это что у нас?
111 группы.
У вас PMF еще есть?
Ой, динозавры, вы не знаете.
112, 121,
ну и так далее. То есть, что такое х?
Х – это система множеств.
Каждое множество – это множество студентов,
что предлагает делать докладчик.
Он говорит, мы рассмотрим все подмножества
наших элементов.
Нет, ты рассмотри все подмножества
каждой своей группы.
То есть, в первом шаге мы что делаем?
Мы введем какое-то множество.
Его давайте обозначим М.
М – это кто?
Нет.
Начинаем мы с чего?
Мы объединяем все элементы х.
То есть, пускай у нас...
Извините. Пускай у нас х – это
какие-то альфы, да?
Альфа – какой-то индекс.
Мы не знаем, какой он.
Я имею ввиду, не обязательно счетный.
И мы рассматриваем множество М,
которое есть объединение А альф
по всем альфам.
Так?
Да.
И потом мы рассмотрим, что?
Надо бы как-нибудь тоже назвать.
М есть, х есть.
Какие-то у меня буквы были, наверное, записаны.
Давайте вот тут Б сделаем.
Я там просто...
И М – это кто?
Два в Б.
Это два в Б.
То есть, это множество всех под множество,
Б большое.
Что мы можем точно утверждать про М?
Это кто?
Даже алгебра.
Единичка, очевидно, есть. Это само Б.
То есть, это у нас алгебра.
Алгебра.
Поэтому, когда мы
рассмотрим Р альфа,
альф уже нехорошо,
давайте Р бета,
это множество колец,
содержащих Х,
множество колец, содержащих Х,
М – это будет какое-то
Р бета нулевое.
Потому что это кольцо,
содержащее систему Х.
Видно, да?
Еще раз.
Х – это изначально наша система множества.
Р бета нулевое.
То есть, получается,
что наша алгебра – это
какое-то конкретное колечко,
при конкретном значении индекса,
вылежащего этой системе.
И дальше мы берем пересечение
всех наших вот этих вот колец.
Что мы знаем про Р?
Во-первых, про Р мы знаем то, что это кольцо.
Это мы доказали вот в том утверждении,
в первом, который есть.
Вот это множество колец.
Бета принадлежит
к какому-то множеству.
Еще раз.
Вот это вот множество
всех колец,
содержащих Х.
И мы их все пересекаем.
Мы точно знаем, что оно
не пустое, потому что
наша М является элементом
вот этого Р бета.
Окей?
Да? Да? Да?
Окей. Все.
Что мы знаем про Р? Во-первых, мы знаем, что
Р это точно кольцо.
Это мы доказали в утверждении.
Второе, мы точно знаем, что Х
является под множеством Р.
Потому что Х является
под множеством каждого Р бета,
значит оно является под множеством их пересечений.
И третье, что мы знаем,
что
для любого Р1,
такого, что Х является
под множеством Р1 и Р1 кольцо,
существует
бета 1,
такое, что
Р равняется R бета 1.
Но поскольку это есть
все кольца, которые
содержат Х,
то если мы возьмем какое-то,
оно будет из этого семейства.
Это ясно?
А поскольку Р это есть
пересечение их всех,
отсюда следует то, что
Р будет под множеством
Р1.
То есть выполнено и вот это,
и вот это.
Идея ясна?
Проблема в этой теории заключается в чем?
Непонятно, как выглядят элементы.
То есть всегда,
когда мы с вами будем определять
минимальную сигму алгебру, минимальное кольцо,
мы именно так и будем сдавать.
То есть это пересечение всех,
которое содержит
нашу систему множества.
Главная проблема, мы не понимаем, как выглядит ее элемент.
Причем с кольцом
мы на следующей лекции разрешим.
То есть там я смогу выписать,
как выглядят элементы кольца,
если в качестве Х берется полукольцо.
Это будут там всевозможные конечные объединения
не пересекающихся элементов полукольца.
А вот для сигма алгебры это сделать не получается.
То есть выписывать в явном виде,
как выглядят элементы сигма алгебры,
это нельзя.
То есть мы доказываем, что она есть,
но представить через элементы не получается.
