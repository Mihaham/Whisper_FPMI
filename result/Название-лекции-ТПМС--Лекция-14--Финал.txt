Итак, приветствую всех. У нас сегодня то ли последнее, то ли предпоследнее занятие,
ну, в зависимости от того, что мы решим, потому что у нас ещё есть, кажется, и, может быть, даже
немного времени в следующую субботу, и темы, которые мы не успели покрыть, которые совершенно
бонусные, но те, кто захочет, может быть, решит их послушать. Но по плану у нас сегодня последнее
занятие, финальная лекция, и на этой лекции мы не будем что-то новое изучать, хотя, может быть,
я случайно неаккуратно расскажу что-нибудь. Но наша цель сегодня просто поговорить о том,
как этот курс был устроен, о чём он был, что оттуда можно вынести и чем можно заняться дальше,
потому что было бы довольно наивно надеяться, что по истечении трёх месяцев мы освоили большую
дисциплину, которую люди разрабатывают уже не первые десяток лет и до сих пор не нашли какого-то
окончательного, идеального, всем удобного решения. Я надеюсь, что сегодня не только я буду говорить,
а в первую очередь, может быть, вы будете задавать вопросы. У меня есть какой-то внутренний план,
ну, такой довольно свободный, чтобы я хотел рассказать, но мне важно, чтобы вы получили ответы на какие-то
вопросы, которые у вас остались к этому моменту. Ну, не в смысле там, как что-то синхронизировать или
почему у меня переполняется StackBlock, FreeMuteX и с Fork в онлоке, а какие-то более фундаментальные,
более масштабные вопросы про организацию всего, про то, как это можно в своей голове уложить.
Вот, ну, если у нас прямо сейчас есть вопросы, то можно прямо с них и начать.
Про ThreadSanitizer и Coroutine, это пока не вопрос.
Трэд санитайзер с корутинами C++, я, честно говоря, не вижу прямой связи между ThreadSanitizer.
Я не знаю, мне кажется, что ThreadSanitizer и Coroutine C++ никак не связаны между собой абсолютно,
но просто вот Coroutine – это какой-то код. ThreadSanitizer ищет обращение
рейса к… Ну, может быть, все в другом проблеме. Ну, еще раз, да. Давай по порядку. Мы сегодня не
разбираемся с какими-то мелочами. Я вот попросил этого не делать, и мы начали с этого. Мы не про мелочи,
мы про какие-то инженерные подробности, вот как там что-то починить сейчас, а про то,
как организовать все те знания, все те подходы, которые мы за эти три месяца коротких довольно…
Куда вообще движется конкарнс? Куда движется конкарнс?
Давай сначала итог какой-то подведем, чтобы… Видите, куда движется конкарнс.
Ладно, значит, с вопросами, пока у меня трудно, я… Вопросы, или маленькие, или не те, которые я хочу,
видимо, я морально не готов на них пока отвечать в таком формате. Давайте сначала все-таки расскажу
то, что хочу, а потом уже мы… Уже по мере того, как я что-то рассказываю, скорее нужно на это,
наверное, откликаться и уточнять, и спрашивать что-то. Что мы делали в этом семестре? Мы с вами…
Ну, как бы, начну с главного, с самого большого. Чем мы глобально занимались весь семестр? Мы с вами,
как можно было заметить, писали некоторую библиотеку, некоторый фреймворк для того, чтобы в
этом фреймворке можно было… Через этот фреймворк можно было описывать и исполнять какие-то конкурентные
активности, под которыми мы понимаем, видимо, какие-то запросы пользователей. Ну, конкретная там
логика обслуживания пользователей нас совершенно не волновала. Она нас будет волновать, но скорее вот
осенью на спецкурсе кто захочет послушать про распределенные системы. Ну, можно себе представить
какую-то более простую логику, нежели там какие-то сложные распределенные системы с консенсусом.
Но в любом случае, в этом курсе это было в топик, мы в первую очередь занимались тем, собственно,
как описать эти активности и как их исполнять. И понятно, что у нас есть компьютер, у нас есть
тюринг полный язык, можно что угодно написать и как угодно исполнять. Наша цель была в том, чтобы,
во-первых, описывать эти конкурентные активности и какие-то сценарии, их взаимодействие, отмены,
синхронизации было очень удобно, а во-вторых, чтобы все это могло очень эффективно исполняться. И вот
это две большие половины курс, две половины курсы, они одинаково важны, и вот перед нами список лекций,
и вот каждая лекция, она относится либо к одной половине, либо к другой. Либо мы говорим про
выразительные средства, про то, как мы описываем обработчики запросов, либо мы говорим про рантайм,
про среду исполнения, которое эти обработчики должны эффективно исполнять. Ну и из чего наш курс
начался? Мы начали его с взаимного исключения, это как раз вот первая базовая тема про рантайм,
по сути. Про то, как что-то исполнять, а чтобы что-то исполнять, нужно просто уметь решать
простейшую задачу, синхронизировать обращение разных ядер к общим ячейкам памяти. Вот в идеале,
конечно, у нас все параллельное, и никакой коммуникации, никакого взаимодействия нет,
но все-таки мы пишем программы, которые запускаются и разделяют какие-то данные, там какие-то,
ну не знаю, в любом случае обработчики, они разделяют общие ресурсы исполнения, там
аллокаторы, какие-то очереди пулопотоков, которые у нас к этому времени еще не появился. В общем,
синхронизация в любом случае нужна, и эта синхронизация, она не про, нужно сразу разделять,
мы сейчас можем об этом поговорить, нужно сразу разделять синхронизацию на уровне потоков,
и вот какие-то файберы, карутины, фьючи, которые мы строим выше. Вот тема взаимной исключения и
тема Lock Freedom, это две довольно удаленные друг от друга темы, две удаленные лекции, между ними
там два месяца, но это две парные лекции про то, как решать одну и ту же задачу, про то,
как обращаться к разделяемым данным с разных ядер. Мы сейчас не говорим там про файберы,
потоки, вот в этих лекциях это неважно, у нас код может исполняться на разных ядрах, в файбере,
в потоке, это не имеет значения, он обращается к общим ячейкам памяти, и нужно синхронизироваться,
нужно работать с каким-то разделяемым состоянием, переводить его из одного состояния в другое,
делать это корректно, не разрушая какие-то внутренние инварианты. И в теме про взаимные
исключения мы поговорили про самый базовый примитив для решения такой задачи, собственно,
Mutex, который обеспечивал взаимные исключения, то есть гарантировал, что между Lock и Unlock
исполняется только один поток на одном ядре, а в Lock Freedom мы... что сделали? Как можно
соотнести два этих топика? Мы ослабили требования к планировщику. Когда мы говорили про взаимные
исключения, мы говорили про свойства safety and liveness, что не происходит ничего плохого и
происходит нечто хорошее eventually, то есть если Lock свободен, то кто-то его захватывает и совершает
полезную работу. Но если Lock захватывает, если какой-то поток захватывает Lock, а потом планировщик
операционной системы там по системному таймеру просто вытесняет его с ядра, то мы получаем простой
всей нашей системы, потому что один поток не работает, который владеет Lock'ом и мог
делать что-то полезное, вытеснен, не работает, а другие потоки, которые сейчас на ядрах, не могут
работать, потому что они упёрлись в захваченный Lock. Вот гарантия liveness, она у нас была формальна
для Lock, она была в предположении, что планировщик не может вытеснить поток на бесконечное время,
видимо он его вернет и прогресс продолжится возобновиться. Но вот в Lock Freedom мы это требование
ослабляли, мы избавлялись от требования к планировщику не ставить потоки на паузу на бесконечное
время и таким образом получали более сильную гарантию, которая уже позволяла достигать прогресса
независимо от того, как ведут себя другие потоки, когда они исполняются, когда они не исполняются,
в какой момент их вытесняют с ядра, это всё для Lock Freedom было неважно. Вот два таких парных топика,
пожалуйста, соотнесите их, ну и вот поймите, что они решают одну и ту же задачу. Просто Lock
Freedom делает это более, ну, более сложную версию решает без требований к планировщику и решает
её, разумеется, более сложно, потому что теперь мы можем там наблюдать какие-то промежуточные
состояния. В теме про взаимные исключения, что можно оттуда ещё было вынести? Ну, наверное, можно
было подумать над тем, как, обратите внимание в разных задачах, как безопасно с взаимным исключением
работать, как можно гарантировать, что мы не попадаем в локи, как можно строить API, которая вообще
более безопасна для работы с локами. Ну, не самый важный, наверное, в курсе топик, но всё-таки он
там был, стоит обратить на него внимание. Дальше мы перешли к теме про Treadpool. И про что была лекция
про Treadpool? Ну, во-первых, она была про, это была первая задача, где нам потребовалось ожидание, где мы не
просто вытеснялись, ну, соревновались с другими потоками за доступ к каким-то разделяемым ресурсам,
а где мы ждали какого-то действия другого потока. И тут у нас появились кондвары, и тут у нас
появились, ну, у нас на самом деле появились ещё в первой лекции фьютекса, они появились при ожидании
в мьютексе, в ожидании онлока. Но вот Treadpool — это задача, где у нас была, был более явный сценарий
ожидания. Мы блокировались на кондваре в ожидании, пока в очереди не появится новая задача. И вот мы
увидели в этих двух занятиях базовый примитив, который у нас есть в процессоре для того, чтобы
работать с этим ожиданием — это фьютекс. Ничего другого у нас нет. И вот с одной стороны фьютекс,
а с другой стороны атомик, который появился в лекции про взаимные исключения — это вот те два
простых инструмента, из которых мы, в общем, дальше изготавливали ну вот вообще всё. И в конце концов,
мы там дошли до, ну, тех, кто дошёл и прорешал почти все задачи, они, кажется, увидели, что вот буквально
ничего, кроме атомика и фьютекса, от операционной системы, от компьютера, от процессора нам не нужно,
чтобы построить такой целый изыго с сложным планировщиком, с какими-то выразительными
инструментами и всякими там каналами фьючами. Вот всё это достаточно, для всего этого достаточно
двух очень простых механизмов. Про что ещё лекция по Трэдпулу в первую очередь? Зачем она была нужна в
курсе? Почему она появилась так рано? Она была с одной стороны, мне кажется, поначалу, может,
немного фрустрирующей, потому что мы сказали, что мы не собираемся больше работать с потоками
напрямую, только запускать их в Трэдпуле. Но, надеюсь, вот по прошествии этого времени стало понятно,
почему мы так сделали, потому что потоки для нас – это довольно низкий уровень, и потоки для нас – это
не масштабируемый инструмент. Для нас потоки – это вот буквально виртуальные ядра. Их не
может быть сильно больше, чем настоящих физических ядер. Если мы пытаемся занимать работы, то вот
сколько у нас физических ядер, столько у нас, наверное, и поток, который загружен какой-то
полезной работой и стоит на процессоре. А уже поверх этого ограниченного количества потоков,
мы можем писать какие-то свои инструменты, свои Future, Fiber, Stackful, Stackless-крутины, которые
будут уже конкурировать и которые будут много спать, поэтому их можно уместить в один компьютер,
в один Трэдпул очень большое количество. Так что это были вот эти две лекции про замены исключений
и про Трэдпул. Это две лекции про рантайм. Что еще можно было в лекции про Трэдпул
вот сейчас детреспективно отметить? Можно сразу обратить внимание, что мы очень аккуратно в первой
же лекции ограничили APP у лап потоков. Там был единственный метод Submit, фактически, и мы увидели
спустя продолжительное время весьма, что ничего другого от Трэдпула не требовалось, хотя, возможно,
хотелось бы. В Трэдпуле могут запускаться зависимые задачи, в Трэдпуле иногда хочется дожидаться
какой-то конкретной задачи, но мы решили, что сразу не будем ничего делать с этим AP, и более того,
наше AP в Трэдпуле оно получилось даже избыточным, потому что, если вы, скажем, писали планировщик,
а я надеюсь, что те, кто собрался сегодня писали планировщик, вы могли заметить, что, скажем,
метод WaitIdle там выглядит довольно инородно, потому что это, по сути, единственное место,
в котором остается такой contention. Вот все остальное мы шардировали, и вся остальная работа делается
потоками независимо, все эти локальные очереди, но даже общение с координатором можно оптимизировать,
чтобы там какие-то мутирующие, изменяющие состояния операции были редки. И вот у нас столько дурацкий
счетчик оставался, который мы там каждый раз накручивали и опускали. Так что наш Трэдпул даже
получился избыточным в этом смысле, но и в хорошем Трэдпуле, в хорошем дизайне такого метода не
должно быть, но мы его все-таки пощадили, оставили, потому что с ним было очень удобно писать тесты.
Пока у нас ничего нет, вот этот WaitIdle был удобен просто потому, что можно легко с ним написать
какой-то простой дождаться чего. Но потом, спустя долгое время, вот в лекции про сендеры и ресиверы,
мы... Ну, вообще, мы Трэдпул достаточно долго развивали, если вы заметили. Сначала мы построили
самый простой Трэдпул с разделяемой очередью, потом мы заметили в лекции про... Про фьюч, кажется,
да? Что этот Трэдпул... Когда мы используем этот Трэдпул для исполнения файберов или для
исполнения фьюч, то, по сути-то, мы не пользуемся знанием про Трэдпул. Мы пользуемся только тем,
что он способен исполнять задачи, и эти задачи могут быть чем угодно. Ну, а если мы от этого Трэдпула
много не требуем, то почему бы нам его не абстрагировать и не заменить на какой-то абстрактный планировщик,
абстрактный экзекьютор? И мы получим тогда абстракцию, которая будет очень простой, очень точной,
ну, то есть просто у нее будет очень компактная API. Она решает вот очень конкретную задачу. Это говорит
о том, что вот мы выделили какую-то проблему вот в отдельный компонент, и дальше мы можем разбивать
независимо. Мы получили очень универсальную абстракцию, потому что, как мы увидели, она подходит
ко всему. И к файберам, и к фьючам, и к рутинам, причем не требует какой-то модификации. И дальше
мы за этой абстракцией в лекции про фьюч и экзекьюторы поместили разные реализации. Ну, и я бы обратил
внимание на manual executor, который там возник. Может быть, он не привлек вашего большого внимания,
но на самом деле это чрезвычайно важный топик, потому что тестирование – это сложно, и тестирование
конкурентного кода – это особенно сложно. А мы этим manual executor'ом пользовались в, скажем,
stackless коррутинов. Ну, то есть вы написали его, потом я же его, взяв вашу реализацию, использовал
для того, чтобы тестировать вашу коррутину, детерминированно. Это чертовски удобно, и в это
направление можно очень далеко зайти, но про это я отдельно поговорю. Ну, и этот threadpool, он
завершил свою… Ну, не то что завершил, но вот он продолжил свою эволюцию в занятии про sender и
receiver, которое у нас было совсем недавно. И там мы пересмотрели API этого threadpool,
которое, казалось бы, уже проще быть не может, и избавились там от прямого метода send, заменили
его на метод, который возвращает нам планировщик, который строит некоторые sender,
которые представляют собой еще не запущенные, но как бы уже готовые запуститься некоторые
вычисления задач в пуле. И такое API позволяет нам еще аккуратнее выполнять какие-то задачи,
избегать накладных расходов в тех сценариях, где это не нужно. Ну вот, threadpool начался,
продолжался, продолжался, продолжался, и вот завершился в sender и receivers, ну и вот вы можете
сейчас осмыслить всю его эволюцию. Ну, давайте я сейчас немного прервусь, я так буду дальше
рассказывать. Ну вот, вернусь к соображению, что у нас все лекции поделены на runtime и выразительные
средства. Ну вот, лекции про runtime это какие у нас? Это взаимные исключения, это threadpool,
это часть про executors, это log freedom, это планировщик, это безусловные модели памяти,
а часть про выразительные средства — это потоки, в смысле файберы, это крутины, это future
executors, это sender и receiver, это stackless крутины, это structured concurrency. Вот два таких отдельных,
больших параллельных топика. И вот почему я сейчас об этом говорю? Потому что в лекции про
future и executors, и на самом деле в двух лекциях, в крутине, в лекции про крутины и в лекции про
future executors мы сделали два очень больших шага, а именно мы декомпозировали одно от другого. И
именно поэтому мы вообще за семестр смогли сделать то, что мы сделали. Напомню, что мы сделали в лекции
про крутину, она была чертовски важна, потому что мы в этот момент уже умели с одной стороны
писать threadpool, который исполняет какие-то задачи. Ну так вот, абстрактный threadpool вакууме,
который мы даже не понимали, зачем он нам толк. А с другой стороны, мы рассмотрели на четвертом
занятии простую реализацию файберов, которые использовали механизм переключения контекста и
могли чередоваться на одном потоке операционной системы и изображать concurrency без физического
параллелизма. И вот две этих занятия, они были на уровне кода, которые мы писали, ну вот,
абсолютно независимые, но в плохом смысле, как бы нам хотелось бы иметь параллельные и файберы,
а с другой стороны, у нас был отдельно threadpool, отдельно вот эти самые однопоточные файберы,
и как получить многопоточные файберы, честно говоря, после двух этих занятий не должно было
быть понятно, наверное. Ну если вы, конечно, очень наблюдательно этого могли догадаться, но все же мы
рассмотрели совершенно два разных механизма, и они по отдельности были понятными, но вот самое
главное, наверное, в курсе мы совершили вот на этом занятии, когда мы посмотрели внимательно на
реализацию файберов и заметили, что переключения контекста там структурированы, что мы всегда
переключаемся из планировщиков файбер и обратно, и вот в этот момент мы выделили сущность карутина,
и вот ровно в этом занятии мы разделили две эти большие подзадачи, декомпозировали друг от друга,
и после этого момента мы отдельно развивали средства выразительности, ну, на основе преимущественно
stackful карутина, дальше были stackless, дальше были future, и независимо от этого мы разбирали рантайм.
Ну, это была такая декомпозиция, вот, собственно, про это была задача карутинные файберы,
и это очень важная задача, я рад, что в этом году её очень многие написали, потому что это отправная
точка, это вот такая база для нашего дизайна, разобрав вот эту декомпозицию, разобрав, как наша
задача выражается через некоторый набор сущностей, и как это всё, эта декомпозиция вот выражена в коде,
в самом дизайне библиотеки, мы дальше смогли уйти очень далеко и очень сложным образом развивать
планировщик, то есть среду исполнения, и очень сложным образом развивать сами файберы. Вот всё
благодаря этой задаче, ну, в смысле, всё благодаря этой идее. А дальше мы эту идею ещё развили, и это
был следующий очень важный в курсе момент, наверное, два таких ключевых момента, которые нужно
обязательно, на которые нужно обязательно обратить внимание. Это декомпозиция в задачах
корутина, и это следующий шаг, который мы делаем в экзекьюторах, а именно мы говорим, что корутины
и файберы с одной стороны, и конкретный тредпул с другой стороны, они уже достаточно изолированы,
и можно теперь и с одной стороны внести вариативность некоторую, и попробовать разные
инструменты, в смысле, разные средства выразительности писать, и с другой стороны, под капотом,
среди исполнения, пробовать разные планировщики. И тут было очень важное замечание ещё в самом
начале условия, в том, что у нас есть разные выразительные средства, stackful-файберы, цепочки
фьюч, stackless-корутины, которые вы уже все знаете. Вообще полезно возвращаться назад и перечитывать
условия, потому что в них очень много таких отсылок вперёд в будущее, которое нужно потом в этом
будущем освоить. Так вот, все эти инструменты, они выглядят очень по-разному, но при этом в конце концов,
когда мы пытаемся их запустить, где-то всё это сводится к тому, что мы запускаем некоторые цепочки
задач. Ну вот, если вы пишете сейчас фьюч, или вы уже написали фьюч, то вот представьте себе граф,
где у вас есть shared-states, и они там друг на друга указывают. Это же буквально граф.
Понимаете, да? Или мы говорим про... А может быть, я его покажу сейчас? Не знаю,
может быть, у меня под рукой есть картинка? Секундочку.
Ну вот, когда мы пишем какую-то сложную конструкцию, мы берём две фьючи, там F и F, навешиваем на неё
продолжение, получаем новую фьючу, потом мы связываем их к комбинаторам... Ну, кстати, нет, это уже
неправда, здесь нужно за него ударить. Мы связываем это к комбинаторам, мы получаем граф задач. Ну, если вы
пишете, скажем, фьючи, то вот, если вы представите себе, какая конструкция у вас возникает в памяти, то вот
возникает такой граф, где у нас есть фьюча с зеном, есть другая фьюча, мы их связываем first-off, а потом
навешиваем на всю этот колбэк, который останавливает файбер и дожидается, пока вот эта фьюча итоговая
не готова. Мы же буквально выстраиваем граф задач, где вершина это shared-states и комбинаторы, и в них
лежат колбэки, и вот промесы, они запускают исполнение этих колбэков по цепочке. Получается такой
граф. Или мы говорим про файберы, это же тоже граф задач, только вот такая вот цепочка. Мы работаем-работаем,
потом останавливаемся, подписываемся на какое-то событие, ну или просто делаем yield в самом тупом
сценарии, потом продолжаем. Ну, stackless-карутина, тут нет большой разницы между stackless и stackful,
потому что, в смысле, разница, конечно, огромная, но в смысле вот этого осмысления как графа в
задач, разницы-то нет никакой. Так что, если мы это сходство обнаружим, если мы на него обратим
внимание, то мы можем заметить, что у нас все вот эти механизмы самые разные для выражения наших
намерений конкурентных могут подходить одной и той же среде исполнения. И всем этим механизмом
от среды исполнения требуется очень простой API, просто возможность запускать задачу. И почему бы
теперь не абстрагировать вот эти конкретные средства выразительности от runtime и выделить
интерфейс iExecutor, который будет давать очень простую гарантию, как исполнять, что он просто
исполняет задачи, даже непонятно где, непонятно когда. И дальше мы можем переписать весь наш код,
но вот к этому моменту Fiber'а на эту абстракцию Executor почти ничего в них не поменять, но зато
получить возможность, ну вот, детерминированно тестировать код. Ну, это очень важные возможности,
я продолжаю говорить, что я к ней вернусь. Но вот именно благодаря этой декомпозиции и
этому абстрагированию мы в какой-то момент смогли сделать, решить очень сложную задачу. Мы написали
планировщик быстрый. Ну, кто-то из вас написал быстрый планировщик. И вот давайте я к этой
половине перейду, потому что быстрый планировщик мы писали на самом деле долго. Ну, то есть,
мы к нему шли долго. Вот вся половина, я бы сказал, добрая половина лекций, она, где же она была,
секундочку. Вот добрая половина лекций, которые про runtime, вот взаимные исключения, thread pool,
потом кэши, модель памяти, lock freedom. Вот они все были нужны просто для того, чтобы дать задачу
про планировщика, чтобы хороший планировщик написать. Все к этому шло. Вот мы там использовали все эти
топики. Ну, про взаимные исключения мы уже поговорили, мы понимаем, что это такая совершенно базовая
задача, самая простая, которую только можно вообразить. А дальше мы вот, скажем, перешли к кэшам.
Про что была лекция про кэши? Ну, с одной стороны, да, что вот есть кэши, что это важная оптимизация в
процессоре, в компьютере, что благодаря этому сглаживается зазор между там скоростью процессора,
скоростью памяти. Но какое это отношение к нам имело? Ну, можно сказать, как? Лекция про кэши была в
какой-то степени про то, чтобы мы в реализации там своего, своих там планировщиков могли бы написать
вот такую вот строчку. Ну, то есть, в какой-то степени это справедливо. Ну, то есть, в нашем
итоговом коде знание про кэши оно выродилось вот в такую строчку в спинлоке, в сокращение сценария
пинг-понга, когда мы, значит, оптимизировали трансферы данных и вот инвалидацию кэш линий в соседних
кэшах при ожидании потоками захваченного другим потоком спинлока. Но это, конечно, неправда,
потому что лекция про кэши, она была в первую очередь про другое. Про что она была? Ну, вот давайте
проверим, провалидируем ваше понимание. Зачем нам в курсе была лекция про кэши нужная? И с какой
лекцией она вот, какую лекцию она продолжала на самом деле? Ну, она была до модели памяти,
поэтому было бы странно, если бы она продолжала эту тему, согласись, да? Тогда бы мне стоило
их читать в другом порядке. Эта лекция продолжала, конечно, взаимное исключение, потому что о чем она
была? О том, что взаимное исключение — это очень плохой сценарий с точки зрения когнитности кэшей
для процессора, для компьютера. Что вот, собственно, та цена, ту стоимость, которую мы платим за
синхронизацию, она рождается именно при когнитности, при синхронизации кэшей. Вот то, что мы хотим
минимизировать — это коммуникацию между ядрами. Эту инвалидацию, когда мы поддерживаем инвариант
протокола Мессия, когда наша запись должна инвалидировать копии кэшлини в других кэшах.
И мы вот, захватывая спинлок на одном ядре, инвалидируем копию данных на другом ядре,
получаем их себе монопольно, модифицируем, потом отпускаем спинлок, потом его захватывает другой
поток на другом ядре, он инвалидирует копию других, забирает себе. И вот в такой бессмысленной
коммуникации проходит процессорное время. Процессор тратит время на то, чтобы вот обрабатывать
сообщение об инвалидации. Это очень негативный для процессора сценарий, и мы его в задаче
пересмотрели. Мы сказали, что мы не хотим исполнять код, который... у нас есть код,
который не может исполняться параллельно, который должен исполняться последовательно. И мы его
исполняем на разных ядрах, и это оказывается очень неэффективно. Да, мы там можем в протоколе
блокировки там какие-то евристики придумывать, но в конце концов, когда мы работаем уже с данными,
нам приходится их постоянно двигать между ядрами, между кышами. И вот эта лекция, она про то,
что не нужно двигать данные между ядрами, не нужно двигать данные к потокам, нужно потоки двигать
к данным в обратную сторону. Это такая очень большая, очень мощная идея, которая используется особенно
в распределённых учислениях. И мы придумали... ну, это был такой промежуточный для нас шаг,
на самом деле он сам по себе важный. Мы придумали такую штуку, как асинхронный Mutex, Strand. И вот
ему отдавали асинхронные критические секции, а Strand уже их кластеризовал там где-то на одном
потоке и выполнял сериями. Причём, чем больше нагрузка, тем он больше серии брал. Между сериями
не было синхронизации внутренней, и они попадали в горячий кэш, и всё это работало быстро. Вот для
этого нужна была лекция, для того чтобы понять, что Mutex — это, возможно, не самый разумный сценарий
синхронизации, когда у нас есть много активности, которые работают с общими данными. И второй важный
вывод из этой темы, что вот конгериантность кэшей — это и есть цена синхронизации. Это и есть то время,
которое мы расходуем неэффективно. Нам нужно его минимизировать. И вот эта идея про то, что мы
хотим снизить коммуникацию между ядрами, она где потом нашла своё отражение? Ну вот она нашла отражение
в планировщике как раз. Там мы сказали, мы не хотим работать с разделяемым состоянием. Разделяемое
состояние — это неэффективно. Мы хотим, чтобы потоки, которые работали с одними Mutex-ами,
скапливались на одном ядре. Мы хотим, чтобы они находились там, не знаю, в одной очереди
планировщика. Мы хотим, чтобы потоки, которые отправляют друг другу данные через каналы,
они исполнялись вот прямо друг за другом и подали в кэш. Вот лекция про кэши, она чертовски,
она выглядит как такая маленькая инженерная подробность, но на самом деле она для организации,
для понимания правильных сценарий синхронизации критически важна. И вот мы дальше, отталкиваясь
от знания про кэши, говорили в планировщике, что нам нужно не просто там планирование с
очередями, нам нужно refo-планирование, потому что оно нам ускорит все. А дальше мы, как этот
Strand развивали, мы же напрямую им не пользовались, но на самом деле мы будем пользоваться осенью на
спецкурсе, там в RPC-фреймворке я покажу, как Strand находит очень естественным образом свое
применение, свое место. Но мы связали сейчас вот этот Strand асинхронный, который про исполнение,
с нашими средствами выразительности, с файберами или с теклусской рутинами, неважно здесь. И заметили,
что вот у нас есть Strand, и он по своей природе асинхронный, то есть мы запускаем задачу,
критическую секцию, чтобы она когда-то исполнилась. И это не похоже на сценарий работы с мютоксом,
когда мы блокируемся, дожидаемся секции, потом выполняем, потом идем дальше. Но тут мы сделали
следующий шаг. Мы подумали, что вот файберы, они про что? Или с теклусской рутиной, про то,
чтобы исполнять код, чтобы писать код последовательно, а если ему нужно сделать паузу,
то он просто остановится, там становится карутина. Мы подпишемся на какое-то событие,
что Лок освободился, и когда Лок освободится, кто-то его освободит, мы возобновимся. И вот здесь
нужно заметить общую идею, что стеклуска-рутины или stackful-файберы за счет вот этой карутины своей
останавливаемой природы помогают трансформировать асинхронное, а пивсинхронное. И вот мы взяли и
просто переиспользовали идею Strand с этими всеми соображениями про когеретность кашей,
про серийность и перенесли ее в файберы. И вот так у нас все-таки два мира пересеклись немного.
Схватываете, да? Это очень важно для планировщика все. Ну а дальше модели памяти. Ну и модели
памяти – это такая бездонная абсолютно тема, про нее можно целый курс читать. Мы уложились там,
не знаю, в две лекции, я рассказал самые базовые вещи и, наверное, еще я не помню,
пару семинаров, но это огромная тема в этом всем курсе. И она про что? Ну, с одной стороны,
как будто бы про оптимизации, про то, как можно оптимизировать код, который там работает с
разделяемыми ячейками памяти. Но это на самом деле еще один топик про абстрагирование чего-то
сложного. У нас есть чертовски сложные машины, у нас есть чертовски сложные, ну в смысле,
процессоры. Они устроены совершенно по-разному, ведут себя совершенно дико иногда. И мы хотим
как-то эту сложность подчинить своему разуму, как-то думать о ней. И вот модели памяти нам дают очень
мощную, очень сложную абстракцию, в которой можно думать, в которой можно о чем-то что-то доказывать,
в которой можно формулировать гарантии, которых мы ожидаем от примитива синхронизации. И,
ну то есть это такой целый формальный язык, на котором можно говорить о работе разделяемых,
о работе ядер с разделяемыми ячейками памяти. И что самое-то интересное, что этот язык позволяет,
что вот на этом формальном языке, в общем, в этой формальной системе можно оптимизировать настоящий
исполняемый промышленный код. То есть мы можем доказать, что мы сохраняем какие-то свойства,
что мы соблюдаем, что мы имеем необходимые нам гарантии, и при этом мы используем самые слабые
предположения о том, что в исполнении все-таки будет упорядочено. И потом, вот сделав такую работу
в формальной системе, мы комперируем код, и этот код, ну если все сработали хорошо, и разработчики
процессоров, разработчики модели памяти, то этот код комперируется в оптимальный машинный код,
там с оптимальными барьерами, с минимальной синхронизацией. Что еще можно было заметить,
если вы аккуратно изучали модели памяти и пробовали их применять? Ну, можно было заметить,
что среди сценария синхронизации есть более и менее оптимальные. И вот, возвращаясь к взаимному
исключению и кэшам, мы там могли заметить, что есть такой обычный mutex, и он неэффективен с точки
зрения кэшей, с точки зрения всех этих протоколов инвалидации и когелентности, а есть асинхронный
mutex, который гораздо более разумен. И вот модели памяти на самом деле нам указывали на ту же самую
идею, что у нас есть сценарий, когда у нас разные потоки одновременно что-то пишут в разные ячейки,
и нам для них требовалось sequential consistency. Ну, иногда требовалось, иногда мы могли его избежать.
А вот иногда у нас был сценарий продюсер-консюмер, когда один поток писал, а другие читали, ну или
еще лучше single writer вообще. Вот это идеальное воплощение, когда у нас только один поток пишет,
а другие там читают. Ну или, ладно, просто продюсер-консюмер уже лучше, потому что такая
модель коммуникации, она позволяет процессорам минимизировать накладные расходы на упорядочивание
операций. Нам не нужно иметь какой-то глобальный сквозной порядок, когда продюсеры работают с
консьюмерами. Нам достаточно соблюдать причинность. И вот happens before — это одна из гарантий,
которые мы в моделях памяти получали. Мы обеспечивали то, что, то есть если у нас в коде есть причинность,
мы опираемся только на нее, а не на какой-то глобальный порядок, то мы специальным образом
аннотируем свои обращения к раздреваемым переменам, и процессор гарантирует, что эта причинность
будет соблюдать нам в исполнении на конкретном, на каждом процессоре. И вот только иногда в каких-то
вырожденных случаях нам могла потребоваться именно sequential consistency, то есть сквозной порядок на
разных ячеек. И опять такое какое-то простое, ну не то что простое, какое-то очень инженерное
наблюдение про какие-то маленькие совсем вещи, про какие-то ячейки памяти там записали, прочитали,
а с другой стороны, вот посмотрите на Design Go. И он ведь отталкивается от понятия канала, а не
mutex, от того что мы там отправляем, получаем. Почему так сделано? Ну потому что это хороший
сценарий, потому что этот сценарий, ну как бы он выразительный, то есть в нем можно все что угодно
написать, любую вашу логику оформить, а с другой стороны, он просто очень хорошо подходит к компьютерам,
потому что там можно или фо-планирование делать, и более слабые memory ордера ставить, это все
как бы чертовски разумно и подчиняется. То есть вот этот дизайн, который вы видите там в языках
программирования, он же, в частности в Go, он же не случайный, он же не произвольный, он с одной
стороны очень согласованный, выразительный, очень удачный на мой вкус, а с другой стороны, он очень
хорошо ложится просто на специфику оборудования, на то что в процессоре, в компьютере исполняется
эффективно, а то что неэффективно мы стараемся не использовать, то есть мы уходим от взаимного
исключения, переходим к продюсеру консюма, вот про это были модели памяти в том числе, вот то есть
это все, тут все связано, вот все что происходит связано, ну мы собственно и в домашних это видим,
потому что мы пишем одну большую библиотеку, и вот все эти топики, они друг за другом цепляются,
и вот еще раз кэши и модели памяти это предвизит к планировщику, ну и логфри разумеется, потому что
мы за счет логфри получали более масштабируемый код, который реже упирается в блокировки и там
реже просто потоки ждут другие потоки, одни потоки ждут другие, то есть вот раз два три четыре пять,
вот эти занятия они все подчиняются планировщику, и в конце концов мы можем этот планировщик хороший
написать, и поэтому очень важно, чтобы вы, реализуя хороший планировщик, собственно в своем коде
использовали все, что мы изучили, потому что ради него все и делалось, и модели памяти там ставили,
и когнитность кэшей про нее думали, и там какой-то логфри, вот все это собиралось в этой задачи,
но а теперь я откатываюсь далеко по стэку вверх, и возвращаюсь к задаче про
про экзекьюторы, вот очень важно, что мы в какой-то момент нашего курса взяли и разделили экзекьюторы
и файберы, то есть провели между ними очень простую границу, видя одного метода экзекьютора,
и дальше мы смогли и файберы развивать, там всякие вот эти овейтеры творить, всякие там фьютексы,
они не нужны конечно, это отдельная тема, все вот эти овейтеры, вейт-группы, мьютексы,
кондвары, каналы, селекты, которые вы еще не написали, вот это все же довольно сложная,
там логфри, мьютексы, это же довольно сложная машинерия, все там много код, и он довольно,
такой сложный, непонятный, очень абстрактный, оперирующий какими-то странными словами,
нечеловеческими, а с другой стороны, мы под этой сложностью за простым интерфейсом громоздим
другую большую сложность, и за счет того, что мы одно отделили от другого и разделили простым
интерфейсом, мы в общем-то можем вот эту сложность, этой сложностью управлять, то есть эта
сложность не перемножается, она складывается, и это очень на самом деле важное достижение,
потому что ну, вообразите себе альтернативную реальность, где вы пишете весь этот код, вот
весь код, который мы написали, вот просто соберите его в одну задачу, мы кстати это сделаем, я вот на
днях выложу ее, где можно все-таки все вместе вообще собрать, фьючи, файберы, карутины,
планировщик, ну просто вообразите себе, что вот вы приходите на первую лекцию, да, мы там говорим
про то, что есть атомики, у них там есть операция compare exchange, да, спинлог можно написать, а потом вот вам
говорят, вот напишите пожалуйста библиотеку, да, в которой есть каналы, фьючи, там быстрый
планировщик, в чем здесь сложность-то, ну в чем сложность вообще всего происходящего, в том,
чтобы правильно задачу декомпозировать, и вот это разделение на две половины, оно с одной стороны,
ну вот мы к нему уже привыкли, воспринимаем как естественное что-то, но благодаря этому все и
произошло, благодаря тому, что мы вынули карутину из нашего кода, обратили на это внимание, и вот от
карутины мы дальше построили весь наш дизайн, и мы дальше можем спокойно, вот находясь за абстракцией
экзекутера, подставлять там мэнал экзекутер и тестировать что-то, подставлять там чудовищно
сложный планировщик, и при этом мы не беспокоимся, что это как-то начнет взаимодействовать с файберами,
ну здесь конечно всякое бывает в жизни, но вообще говоря вы знаете, что если у вас файберы протестированы
под одним планировщиком, то подставляет другой планировщик, и что-то вдруг не работает, вы понимаете,
где проблему искать, вам не нужно менять сразу очень много кода, вот вы занимаетесь отдельным
компонентом, и подставляете его вот в некоторые пазлы, просто ставите одну детальку, ставите
другую детальку, более сложную, более оптимальную, и все вместе продолжает работать. Все это благодаря тому,
что мы провели вот такую некомпозицию, вот здесь вот про фьюч-экзекутер. Что еще нужно рассказать?
Наверное про, собственно, фьюч, потому что мы только сейчас их пишем, но мне кажется,
что сейчас удачное время, чтобы их писать, потому что мы уже накопили довольно
большое понимание о том, как код должен эффективно исполняться, про то, какие оптимизации в нем
можно делать, и поэтому мы можем сейчас найти очень хорошие фьючи. Но вот фьючи и, смотрите,
по-другому начну, у нас в курсе были stackful-файберы и stackless-карутины, и они в принципе про одно и то же,
то есть мы просто взяли понятие карутины, построили от него идею какой-то активности,
которая может что-то делать, синхронизироваться, останавливаться, перепланироваться, а дальше
просто сказали, что у нас есть два варианта эту карутину реализовать. Stackful-вариант с переключением
контекста и stackless-вариант, где мы делегируем реализацию карутины, написание этого автомата
к императору. Вот это как бы один подход к выражению конкурентности последовательной,
когда мы выполняем операцию A, потом выполняем операцию B, потом выполняем операцию C. И ну как бы
две альтернативы, но вы понимаете, что вы используете одну из них, то есть вы берете либо stackless-карутину,
либо stackful-файбер в своем проекте, а вот фьюча — это инструмент, во-первых, альтернативно
выглядящий совсем, а во-вторых, комбинирующийся с stackful-карутинами, stackful-файберами или
stackless-карутинами. И для меня очень важен этот пункт в задаче про карутины, ой, про фьюч, простите.
Про то, что вот файберы slash-карутины и фьюча — это не какие-то вот альтернативные
способы описывать цепочки задач, потом их исполнять. Это инструмент, который дополняет
синхронный интерфейс файберов-карутин, потому что файберы подходят для задач, когда у вас выполняется
а, потом b, потом c. На файберах удобно писать циклы, удобно писать витвления, удобно работать с
включениями, но когда вам нужно сделать что-то параллельно, то в этом случае гораздо более
выразительными оказываются фьючи. Ну, можно, конечно, как бы совсем через фьючи все писать,
и про это есть чертовски хорошая статья у Server-as-a-Function, которую я вам продолжаю реклонировать,
и буду продолжать, пока у меня есть время. Что? Да, ну, про ссылки в задачах — это отдельная
история, я сейчас к этому перейду. Где я был? Можно писать весь код, в принципе, и это тоже
интересно понять, как можно вот совершенно по-другому к задачу подходить, но лучше комбинировать,
и как раз осенью мы поговорим про то, как это комбинировать. Но фьючи — это такая отдельная,
я бы сказал, даже ветка в курсе, потому что она начинается с блокирующих фьюч, которые, конечно,
неполноценные, и фьючам их называть не стоит, можно только смеяться над ними. Дальше идут настоящие
фьючи, которые мы пишем, и которые можно написать очень хорошо. Очень хорошо можно написать. И есть
задачи, которые мы к ней не подошли, но в этот раз как-то не успели, и я, может быть, успею выложить
в этом смеси обновленную, может быть, нет. Посмотрю, это таски для корутин, это такое продолжение
фьючи, в смысле, ленивое фьючи, когда фьюч представляет вычисление асинхронную операцию,
которая уже исполняется, таск, который еще не исполняется, корутину, которая еще не исполняется.
И, во-первых, это такая отдельная линия в курсе, асинхронная, асинхронная API. А во-вторых,
это, в принципе, другой способ мышления, другой язык, на котором можно говорить. Это язык
декларативный. Вот fiber — это про то, про control flow, когда мы запускаем код, и он там начинает
как-то исполняться, чередоваться, переключение контекста. Вот мы об этом всем думаем. Когда мы
говорим про фьюч, то мы думаем не про control flow, мы думаем про data flow. То есть мы строим граф и
думаем, как по нему текут какие-то результаты, ну, либо ошибки. Вот я в прошлый раз вам показывал
картинки про cancellation. Вот cancellation — это как раз топик, который про... Ну, вот на фьючах он
очень красиво изображается. Мы строим какой-то граф, и по нему текут результаты, сигналы отмены,
ошибки. Все это как-то движется. И мы, когда пишем код, не думаем о том, как это происходит. Мы думаем
о том, в каком... как мы комбинируем вычисления. Ну, комбинируем о синхронной операции. Мы думаем,
как из одних операций составить другие операции. Мы запустили две, а потом дождались первой,
или дождались всех, или там еще что-нибудь. А вся синхронизация, вся вот эта машинерия,
все promises, все вот сигналы отмены, все там какие-то weight-free автоматы, все вот это спрятано
внутри. Это очень мощная идея, и вот на ней буквально можно production написать,
а можно комбинировать с файберами. Ну, или там с чем-то таким останавливаемым. И на самом деле
хорошие фреймворки... Ну вот в любом хорошем фреймворке используются два подхода. Вот у вас
есть корутины, и это такие... ну, как бы не потоки, но... не знаю, как это назвать... цепочки шагов,
но они сами порождают таски, они же фьючи, и можно вот комбинировать что-то на уровне таск,
а можно синхронизировать сами корутины. Или у вас запускаются файберы, они делают запросы там
по RPC, получают фьючи, и вы там в файбере дожидаетесь двух фьюч через комбинатор там... первый
фьюч через комбинатор first-off, потому что через него можно сделать эффективную отмену второй
синхронной... второй синхронной операции. Вот, то есть эти инструменты всегда работают сообща,
но само понятие фьюча, оно само по себе интересное, оно иллюстрирует понятие там монад функторов,
это вот совершенно параллельный, очень красивый функциональный мир, и ну вот таким вот очень
косвенным сложным путем можно туда тоже проникнуть и про это почитать. Мне кажется, что это очень ценно,
поэтому я очень рекламирую задачу фьюча. Попробуйте все-таки успеть ее сделать.
Дедлайн по ней какой-то большой, да, но как бы дедлайн и дедлайнами, а задачу-то сделать
все равно нужно. Вот, если мы хотим что-то вынести из всего этого. Вот мы получаем такой дизайн,
плюс еще у нас есть важный топик, это structure and concurrency, вот обработка ошибок и cancellation,
это очень важно, это очень важно для промышленного кода, любой промышленный код должен работать с
отменами, он не может просто запускать и дожидаться вечно. И вот с одной стороны у вас есть stackful
fiber, stackless коррутины, у вас есть перпендикулярно этому фьюча slash task в зависимости от того,
что вы выбрали среди этих двух, и у вас есть cancellation, то есть распространение отмены в
противоположную сторону, распространение всех этих сигналов по графу вычислений. И вот все это
образует ваше выразительное средство, а под капотом у вас есть экзекьютор, эффективный планировщик или
threadpool с общей очередью для вычислений, для независимых вычислений, или у вас есть
manual executor для тестирования кода, и все это собирается вот в такой один большой сложный
фреймворк. Ну и давайте я, наверное, про это расскажу, потому что это большое достижение этой
итерации курса, мы с вами, честно говоря, сделали очень много и очень сложно, и вы большие молодцы,
потому что вы с этим справились, потому что... Ну я, прямо скажем, особо не думал о том,
справитесь вы или нет, потому что мне просто так хотелось сделать, мне казалось это правильным,
но вы справились. Я, конечно, старался вам помочь в этом, как мог, в смысле,
направлял вас в правильные моменты, в лекциями и условиями задач, в нужную сторону, но вообще то,
что мы написали, это дико сложно, и я бы сказал так, что мы, наверное, нигде, ну может быть, иногда,
но мы почти что нигде не писали с вами какой-то учебный код, мы с вами писали код, который,
ну кажется, может быть максимально хорошим, то есть там некоторые шаблоны, конечно, упрощены,
но мы их потом дорабатываем, усложняем, и всегда оставлена возможность сделать, ну просто максимально
хорошо. Вот так, чтобы лучше уже нельзя было, ну в рамках там предложенного подхода, разумеется.
Поэтому, ну именно поэтому мне важно, чтобы, скажем, вы научились работать с профилировщиком,
строить Flame Graph и оптимизировать. Мне важно, чтобы вы использовали знания про протокол когерентности и
про модели памяти и думали про слабые memory-ордеры, потому что то, что вы получили, может работать
супер быстро, может работать максимально быстро, как это возможно. Мы нигде не пишем с вами учебного
кода, мы, ну я честно вам рассказываю и строю шаблоны так, вот настолько хорошо, насколько я умею,
вот я стал на год умнее, да, и почему-то научился, и вот задачи стали немного сложнее, немного
аккуратнее. Вот сейчас они, мне кажется, в очень хорошем состоянии, в том смысле, что,
ну почти всю лишнюю работу в них можно аккуратно соптимизировать, и для этого даны какие-то
указания. Ну вот, скажем, я вас мучаю с интрузивностью, да, вот весь семестр, и, наверное, ошибка, что я
пытался заставить вас самостоятельно придумать, нужно все-таки просто рассказать напрямую. Ну,
как бы, это мы учтем в будущем. А сейчас это один из тех нюансов, который важен для производительности,
и, с одной стороны, вот можно думать про все это, как про оптимизации, да, вот мы там оптимизируем
memory-ордеры, мы оптимизируем там локации, мы оптимизируем там еще что-то. Ну, у оптимизации есть
такой, ну, я не знаю, можно заметить такую негативную краску небольшую, что мы как будто бы
усложняем код, делаем что-то, как будто бы у нас был код простой, а теперь мы что-то с ним делаем,
чтобы он был быстрее, ценой какого-то, не знаю, усложнения, ухудшения его. На самом деле, вот вся
та мелкая возня, которую мы делали в курсе, и с локациями, с memory-ордерами, это не про то, чтобы
прям оптимизировать код. Я бы по-другому на это смотрел. Мы стараемся думать о том, что коду нужно
делать, а что не нужно. Вот на какие предположения об упорядочивании операции обращения к памяти
он опирается. Думаем об этом, думаем, ага, продюсер-консюмер, там нету глобального порядка. Отлично,
ослабили memory-ордеры. А доживет ли объект до конца выполнения операции там в тредпуле? Доживет,
ага, можно лоцировать его на куче, ой, на стэке, а не на куче. То есть мы скорее пишем не то чтобы
оптимальный код, мы пишем просто аккуратный код, который не делает того, что ему делать не нужно.
Вот, и если вы пишете аккуратный код, то у вас, ну в смысле, если вы подходите к этому как к чему-то
аккуратному, то вы можете написать и как бы фреймворк, который эту аккуратность поощряет. Ну да,
конечно, он будет сложнее, но тем не менее там не будет, то есть это не то чтобы мы там какими-то
ассемблерными вставками что-то оптимизируем, это совсем другой класс оптимизации. Мы наоборот
пишем какие-то интерфейсы и вот за счет них, за счет того, что мы вот там, не знаю, отделили
понятие сториджа от виртуального вызова и вот сделали где-то локации на куче за счет этого. Это
вопрос аккуратности. И вот с этой аккуратностью можно зайти очень далеко с одной стороны, то есть
получить очень сложный код, с другой стороны он получится очень эффективным и будет понятно каждый
компонент за как бы за какую оптимизацию отвечает. Вот мы видим айтайск, мы понимаем, ага, это про
там экономию локаций. Это про то, чтобы определиться с временем жизни объекта. Или мы видим,
мы reorder и думаем, ага, это про коммуникацию потоков. То есть все заключается в какие-то вот такие
рамки и об этом все еще можно думать. Это все вот, ну то есть мы написали много код на самом деле и
все же о нем можно думать довольно модульно, потому что мы разделили задачи, мы разделили
абстракции, мы разделили там как бы в разных плоскостях, разделили сложность на какие-то
независимые компоненты, которые комбинируются между собой и про комбинации которых мы почти не
думаем. Это чертовски сложно. И я бы сказал, что вот это и есть настоящее содержание курса. Ну то
есть вы там конечно пишете всякие синхронизации, всякие там файберы запускаете, но то, чему вы
можете научиться из этого курса, это не только писать лог-free mutex или лог-free stack. Ну то есть вы
этому научились, вы забудете об этом через неделю, потом вспомните, когда потребуется.
Настоящая польза от этого курса — это то, как мы взяли Atomic, потом из него, потом из него
построили mutex, потом к нему нам потребовалось добавить какой-нибудь кундвар, который мы тоже
написали своими руками. Мы из этого сделали thread pool, а потом мы заметили, что можно взять
корутину, а потом их можно скомбинировать, получить планировщик, а потом можно заметить,
что планировщик можно абстрагировать, сделать файберы, а потом можно заметить, что файберы,
независимо от планировщика, можно сделать интерфейс, а с этим интерфейсом можно сделать
теперь разные реализации, а потом можно сделать асинхронный интерфейс, потом понять, что это
все граф и задач, и значит, можно их совместить, а потом все это разрастается, и каждый шаг в
эволюции этого кода — это то знание, на самом деле, которое вы получаете в этом курсе. Вот как можно
было развиваться от таких простых примитивов к целому языку Go, практически языку Go? Потому
что представьте себе, как вам дали просто задачу — напишите свой Go, но это же ушло в бесконечное
время, и мы бы не справились все равно с этим. Вот смысл всего курса, смысл всех лекций и
домашних задач не в том, чтобы слушать меня и то, что я вам рассказываю про какое-то решение,
которое мне нравится. Тут вопрос, вкус очень большой, очень значимый, он сильно влияет на
все происходящее, но ценно в этом курсе именно та эволюция, которую наш код претерпевает. Поэтому,
скажем, мне кажется правильным, это с одной стороны неудобно и, наверное, вас бесит. Да и меня
тоже немного бесит. Но мне кажется, это правильным, что мы постоянно, у нас дублируются задачи,
в смысле, мы не пишем один код, мы постоянно переписываем некоторый код. И вот при переходе
из одной задачи к другой, из одного шаблона к другому, мы чувствуем разницу, мы понимаем,
что изменилось, где мы немного продвинулись вперед. Вот, к сожалению, очень сложно сделать одну большую
задачу, в которую все бы можно было интегрировать, потому что в ней было бы слишком много выходов в
будущее, слишком много ответов. Сейчас задача устроена так, что задача Fibers Mutex, она оперируется
очень простым шаблоном, нет экзекутеров, нет ничего такого. Потом мы в другой задаче находим
экзекутеры и выражаем отдельный директорию со всеми этими вариациями. Потом мы переносим ее туда,
потом мы что-то еще делаем. И вот эта эволюция, она и есть содержание курса. Ну или смотрите,
есть стеклоскорутины. Где они были? Стеклоскорутины. Я говорил вам, что, в принципе, дизайн можно
рассказать не то, чтобы в середине мая, а где-нибудь в середине апреля, а вот раньше там на месяц, скажем,
или на полтора. Но что мы сделали в курсе? Мы взяли Fibers, сделали там простой Yield,
ну как-то на коленке придумали, написали, вот прям Fibers захардкодили его. Потом мы подумали про там
немножко про EO, про Event Loops, это отдельная история, наверное, не успею сейчас про это поговорить.
Потом мы стали делать Mutex, стали делать Futex, что-то там накостырили, а потом стали думать,
а как же со всем этим управляться? Потому что там как бы набор операций, на которых Fiber блокируется,
растет, но их, эти там примитивы операции множатся, нужно каким-то образом опять выделить
какую-то подзадачу, абстрагировать сами Fiber от конкретных примитивов. И вот так мы придумали
Awaiter. И вот все эти маленькие шаги нужны были для того, чтобы потом перейти к рутинам и
свести всю лекцию буквально к одной фразе. Все то же самое, только теперь компилятор пишет
коррутину, а не мы. И вот вся механика коррутин в этот момент должна быть для нас ясна. То есть
мы не то чтобы, изучая вот дизайн, который упал на нас с неба, мы, пройдя через эту серию итераций,
сами чувствуем, откуда такой дизайн появился, чем он мотивирован. Ну, тем, что, видимо,
Awaiter это точка кастомизации, которая позволяет нам отделить, как бы, ядро коррутин, которое,
ядро коррутин, от конкретных примитивов от рантайма. И в случае с Techless коррутин это
особенно важно, потому что теперь коррутин и пишет компилятор, и он уже не может интегрироваться в
наш рантайм, он про него ничего не знает. Ну вот, еще одно соображение, которое мне представляется
важным. Ну и возвращаясь к тому, что мы пишем, кажется, довольно хороший код, мы можем написать
очень хороший код в задачах, и именно поэтому в задачах очень много, ну не то что очень много,
есть ссылки. И это не просто какие-то случайные ссылки из интернета, это, мне кажется, самые
хорошие ссылки, по которым только можно в интернете переходить по этой теме. И они даны не
только для того, чтобы вы просто вот изучили, что как бывает, вы просто можете пойти в future
фоли и посмотреть, как вот, это future, который используется в продакшен и фейсбук, и посмотреть,
как там реализовано что-то, где я, черт возьми, как я сюда попал. Идем во future и просто, не знаю,
читаем код, читаем, смотрим там, что у них в shared state находится, какой там автомат.
У нас будет немного попроще, но вот как бы, вот эта часть автомата у нас будет ровно такой же. Или
там можно посмотреть, как там устроена синхронизация, можно посмотреть, как там устроены экзекьюторы,
или, ну я, по-моему, про это не успел еще написать, в stackless корутинах, опять ссылка на фоли,
и ну вот там корутины, которые интегрированы с экзекьюторами фоли, и вот вы можете пойти и
посмотреть, как там реализованы, ну вот mutex, или вот то, что мы в этой задаче пишем. И не то,
чтобы у вас получиться другая реализация, у вас вот такая реализация и получится в итоге. Ну,
потому что мы пишем настоящий промышленный код, можем написать, и вы можете заимствовать идеи из
промышленного кода, который вы видите вокруг себя. Про future ссылки скорее не про реализацию,
наверное, а про то, про дизайн, про то, что future должны, это не то, про то, что future должны уметь.
Вот, скажем, ссылки про скалу, они как раз про то, как может выглядеть такой сложный,
развитый язык комбинаторов, что там future может уметь. Как можно комбинировать разные синхронные
операции с помощью вот этих вот функций. Или, ну вот, этот доклад мне тоже представляется интересным,
я его рекламировал уже, это future в твиттере, и какие технически-инженерные идеи в них
реализованы, которые позволяют этим future быть эффективнее, чем скальный future.
Или, не помню в какой задаче, кажется в задаче про карутины, самый первый. Да, есть совершенно
чудесная ссылка про… Что? Почему это видео? Не, так не пойдет. Как мы без этой ссылки живем? С ума сойти.
Ссылка на то, как устроены, как дизайнерись файберы в джаве, которые вот скоро приземлят там. А? Ну,
их делают не так давно, кстати, несколько лет всего. Несколько лет в масштабе. Там их делают не для
джавы, их делают для GVM. Вот, дизайн-док, который тоже можно прочитать. Ну, и вот,
собственно, мы этот же дизайн с вами используем. И в этом дизайн-доке инженер пишет, что вот мы делаем
карутины в GVM, поверх мы в библиотеке сделаем файберы, а потом мы просто переиспользуем
готовый, хороший планировщик, который есть в джаве, который называется fork-join-pool, который как
раз использует work-steering. Вот, это ровно тот дизайн, который мы с вами используем. Ну,
то есть, мы в курсе… Ну, почему курс… Он иногда, возможно, кажется сложным, потому что он… Ну,
потому что он не делает никаких скидок на вот то, что вы втором курсе, к сожалению, для вас. Он
пытается действовать максимально честно. То есть, то, что люди умеют делать в продакшене хорошо,
то мы и пытаемся сделать с вами. Вот, это, разумеется, сложно, но можно попытаться. Можно попытаться.
Про планировщик, да. Ну, про планировщик-то особенно. Там замечательные же ссылки. Они про то,
что… Они про… Где планировщик? Про то, как устроено планирование карутин в Котлине,
про то, как устроено планирование гарутин в Расте, про то, как гарутин в ГО, про то,
как устроено планирование синхронных задач в Расте, в Токио. Вот вы пишете такой же планировщик,
и вот вы просто посмотрите. Великолепный доклад Дмитрия Бюкова, если вы еще не посмотрели,
когда вы писали планировщик, то посмотрите. Я бы сказал, что весь этот курс нужен для того,
чтобы походить по ссылкам. И чтобы вы могли… Ну, то есть не то чтобы… Я вот вам что-то рассказал,
и вот вы там профессионал. Вероятно, нет. За три месяца им сложно сделать. Но вы теперь можете
на основе того кода, который вы написали, и вот как бы попробовали написать, по крайней мере,
вы можете ходить по вот этим ссылкам и смотреть, как устроен настоящий реальный мир,
как устроен продакшн в ГО, в Расте, в Пайтон, в Котлине, в Скале, в любом современном языке.
И все сущности должны вам быть понятны, все слова должны вам быть понятны, все механики должны
вам быть понятны. Да, мы пишем на C++, но мы пишем на C++, потому что мы, во-первых, его знаем,
а во-вторых, потому что на нем можно все что угодно попробовать, все подходы просто. И
фьюча написать, и файберы написать, стэк, фуллфайберы, и стэк лоскарутина у нас готова есть,
можно ими воспользоваться. То есть весь спектр инструментов нам доступен, и нам доступны все
низковыровневые оптимизации. У нас есть слабые модели памяти, у нас есть там доступ к ассемблеру
с каким-то примитивным инструкциям, у нас есть там сисколы, фютексы, все вот это можно использовать,
из этого всего можно собирать очень сложные вещи. Что еще, мне кажется, важным? Да, конечно,
протестирование. Это отдельная история, которую вы, наверное, не замечаете, ну, точнее, я не знаю,
замечаете вы или нет, но это очень важная мораль, которая, наверное, сейчас не ощущается как важная,
но без хорошего тестирования невозможно писать сложный код. И в этом курсе мы пробуем достаточно
много разных техник. Ну, мы, разумеется, работаем с санитайзерами, там, с тремя санитайзерами,
и вот без санитайзеров код надежно писать невозможно просто. И, что очень важно, мы используем,
как мы тестируем именно конкарнси, потому что, если вы пойдете смотреть в какую-нибудь продакшн,
ну, вот вы смотрите реализацию каких-нибудь примитивов, фоль, и думаете, боже, как это
тестируется? А непонятно, как это тестируется, потому что, если вы видите сложный конкурентный код
со слабым модеримом памяти, совсем вот этим вот, то, если вы пишете его или видите его, то как
вы убедите себя, что он работает? Ну, потому что человеческий ум не справляется с этой сложностью,
он не может в голове перебрать интерливинги даже. А если мы используем где-то слабые модеримы
ордера, то все, мы даже должны про интерливинги, мы даже думать больше не можем, мы должны про графы
думать формально. Вот, и это совсем сложно, это вообще уже невозможно. Поэтому нужна какая-то
автоматика, которая позволяет все это тестировать. И здесь мы использовали две очень важные техники.
Во-первых, мы использовали fault injection. Вот без fault injection ничего с stress-tests не ловится,
вот просто ничего. Если вы просто напишите stress-test, ну, вот повезет, там что-то найдете. Но опыт
показывает, что stress-tests без fault injection — это очень слабые тесты, они очень много упустят. Поэтому то,
что мы принимаем как данность, то, что мы даже не замечаем, как работает, вот благодаря этому
всему тесты и работают на самом деле, богищицы. А во-вторых, очень важный топик — это дотерминизм.
Дотерминизм, ну, вы, я его показывал вам через manual executor, но вот опять никто этого не видит,
а на самом же деле под капотом, когда мы тестируем ваш код под файберами, то только подумайте,
что происходит, потому что это полная дикость, я сам не понимаю, как это работает. Вот вы написали
груду вот этих файберов с lock-free mutex, да, положили это все на workstream-планировщик,
где еще горо кодок вот сложного, да, и все это запускается еще на виртуальных потоков,
которые файберы на самом деле, которые тоже переключают контексты. Вот если подумать,
как это все вместе работает, это становится невыносимо абсолютно для человеческого ума,
ну, для моего скромного. Но за счет того, что как бы есть некоторые слои абстракции, можно эту
сложность как-то все-таки декомпозировать и думать про нее отдельно. Но вот когда у вас виртуальный
поток делает переключение контекста ваше, ну, только подумайте, как это работает. Это
несколько странно. Вот благодаря этому код тестируется детерминированно, воспроизводимо и очень
быстро. И все это совместимо с санитайзерами. Это очень мощные техники, и вот осенью, кто захочет
послушать, я покажу, как можно так тестировать прямо распределенный код. Это подход, который мало кто
использует, так буквально в нескольких местах в мире так делают. Так делают где-то, кажется,
иногда в Амазоне, в AWS, так делают в одной системе в Apple. Но, в принципе, этот подход очень дорогой,
очень сложный, и у него нужно очень много сил инвестировать. Но тогда это дает какие-то
невероятные возможности для тестирования очень недетерминированного, очень конкурентного кода,
который работает со временем, с сетью, с переключением потоков, с планировщиками. И все это можно
запустить в IDE, по кнопке «воспроизвести» и добавить лагирование и повторить в точно
такой же порядке. Поэтому, пожалуйста, продвигайте Fault Injection, когда вы уйдете в мир, продвигайте
эту тему, без нее невозможно. Что еще важного? А у нас время кончилось, но мы, кажется,
можем немножко сдержаться, да? Вот, так что давайте я… Не знаю, все ли я про курс рассказал,
что хотел. Наверное, не все, наверное, что-то забыл. А, что я забыл, да, действительно. Давайте
рассказать, что я забыл, но не успел в курсе. Мы и так уже не помещаемся, конечно, по времени,
но еще нам очень не хватает, наверное, домашней работы про cancellation. Нам не хватает домашней
работы… Ну, это мне не хватает, вам, наверное… Мне хочется, чтобы у нас была такая отдельная
линия. Это канал Lock Free, канал через Lock Free, очередь Майкла Скотта, но это такое… Это красиво.
Еще не хватает интеграции с вводом-выводом. Мы в этом году пошли немного по другой траектории и
собрали вместе такой большой фреймворк. Это наше большое достижение огромное. Вот, гордитесь им,
вы большие молодцы. Но в нем мы кое-чего еще не успели интегрировать, а именно мы вот вывод так
немного посмотрели на него в сторону немного, на это ASIO. А нам все-таки хочется интегрировать это
все в наши планировщики, потому что ASIO — это как бы альтернативное представление нашего фреймворка,
который мы пишем. Там и экзекьюторы, и рантаем, и вот-вывод. А нам хочется взять конкретный
компонент, реактор, который про события, и интегрировать поддержку событий в наши планировщики.
Но вот если вы помните, когда мы говорили про планировщик ГО, когда мы код смотрели. Давайте
посмотрим на код. Да. Смотрим на find runnable, да, и там вот мы перебираем локальную очередь,
глобальную очередь, а потом мы полим сеть. И вот вывод — это еще один источник задачи,
также как и очереди. Вот очереди — это когда задачи синхронизируются, запускаются. А вот вывод,
когда приходят там, не знаю, клиенты, когда приходят данные в сокеты, и вот представьте,
что у вас есть в коде некоторый компонент, интерфейс, реактор. Какой у него API? Подписаться на
события, там сокет зарегистрировать, таймер завести, и опросить события, получить там пачку готовых.
И вот это еще одна очередь, и вы ее опрашиваете иногда. Просто это очередь в системе, а не у вас.
Но это такая же очередь, и она интегрируется удобным образом. И, например, когда вы паркуете
Fiber в планировщике, где вы его паркуете? Ну, пока вы паркуете его на атоматомике, на фьютаксе,
по сути. А могли бы парковать его на E-Pole до тех пор, пока либо событие снаружи не придет в ваш
поток, ну, в смысле, в ваш планировщик, либо когда кто-то не сделает через этот E-Pole, через там
какой-нибудь такой пайп, зацикленный, интерапт. И вот вы интегрировали свой фреймворк с быстрым
планировщиком, еще и с вводом-выводом, и можете там всякие скипфоры писать, сокеты и так далее.
Если повезет, я, может быть, в этом месяце даже успею это сделать, и там можно будет
попробовать вписать это все в свой код. Это довольно просто делается в том пределе.
Вот. Это, наверное, то, чего не хватает, чего мне очень хочется, и тогда получится полноценный
уже ГО. Но нам бы это успеть, честно говоря. Я даже не знаю, что делать, потому что мы и так
не успеваем. Курс начался вот сейчас, когда мы накопили базу для того, чтобы решать сложные
задачи, к сожалению. Так что будьте сейчас внимательны. Ну и давайте я последнее,
что я расскажу, а потом отвечу на ваши вопросы любые. Я должен… секунду. Да,
я должен рекламировать осенний курс, которые просто определенные системы, и можно было бы сказать,
что весенний курс рекламы осеннего, но это одна из интерпретаций моя. Пожалуйста,
если вам понравилось, если вам интересно, приходите, потому что дальше мы будем говорить
про… ну как бы сказать, в таком же духе, но про вещи гораздо более масштабные. То есть мы будем
говорить не про ячейки памяти, не про того, как два потока синхронизировать, и про то,
как классы написать, а мы будем говорить про системы. То есть это как бы следующий уровень
иерархии, и мы будем говорить про системы, ну вот иногда очень большие. И где-нибудь там к ноябрю мы
дойдем до системы, которая называется Google Spanner, которая про то, чтобы построить огромную геораспределение
базу данных, которая хранит все данные Google. Там какие-то, ну не знаю, несметные там… что там
после пятобайтов идет? Вот. Это все там хранится в масштабах всего глобуса, синхронизируется через
спутники, GPS в том числе. Ну короче, это жутко сложные, очень красивые вещи. Там очень много
алгоритмической составляющей, поэтому половина курса про алгоритмы, потому что вот от них,
по сути, зависят ключевые свойства системы. Сколько отказов они переживают, сколько какова их
доступность, как их масштабировать. А с другой стороны, этот курс будет, ну, наверное, вот в этот
раз особенно заметно это будет про системный дизайн, то есть про то, как строить надежные системы,
про то, как там быть с отменой, с трассировкой, с логированием, с RPC-серилизацией, с тайм-аутами,
с балансировкой нагрузки. Короче, все вещи, без которых настоящий промышленный код просто
негде запускать. Это очень большие и сложные топики, и это как бы следующий уровень. И, конечно же,
на третьем курсе, ну, мы еще маленькие, можно сказать, для этого, нам хорошо бы перед этим
получить какой-то промышленный опыт. Но я, кажется, вполне могу это все рассказать, а вы, в свою очередь,
можете попытаться меня понять. Но если вам вдруг это кажется интересным, то я вам рекомендую,
ну, прямо сейчас можно примерно составить представление о том, в каком направлении
будем двигаться. Вот я вам порекомендую такие статьи. Ну, почитайте про «Мопредьюз». Это,
собственно, то, с чего начались распределенные системы современные. Это статья Google, где они
показывают, как построить... Вообще, о чем наш курс-то будет про распределенные системы? Он про
то, как строить надежные системы из ненадежных компонентов. Из сети, которая теряет сообщения,
которая переворачивает биты в проводах, из дисков, которые ломаются, которые зарепают,
из компьютеров, которые перезагружаются, из проводов между дата-центрами, которые выкапывают
экскаваторы. Вот из всего этого что-то сделать надежно, которое никогда не ломается. Мы будем
писать код, который должен быть устойчивым к ошибке в любом месте. Вот работал компьютер,
и вот между какими-то двумя инструкциями он взорвался или там перезагрузился. Взорвался — это,
наоборот, удобно. Перезагрузился. И вот любые две строчки это могли быть, и нигде не должно
ничего потеряться. Вы писали в сокет, написали половину, ничего страшного не должно произойти.
Вы писали на диск, и записалась половина вашего буфера, а половина затранкетилась. Ничего плохого
не должно произойти. И вот все это должны пережить. Вы отправили три запроса, получили только два ответа,
или один ответ получили, или, ну не знаю, там у вас сеть раскололась на две части. Вот никакой
сбой, вот все, что можно представить себе, что может поломаться, не должно ломать наш код. Это
чертовски сложно, и мы попытаемся, ну я попытаюсь объяснить, как это все можно делать. Это сложный
курс. Иногда очень такой дотошный к мелочам, но с другой стороны, я вот попытаюсь вам рассказать
честно все, что я знаю к этому моменту. Нигде вас не обмануть. А теперь статьи, про которые можно
почитать к началу этого курса. Это, конечно, спаннер не нужно читать, это не получится.
MapReduce — это система, с которой началась инфраструктура современная, начался Google современной,
ну там с PageRank из MapReduce. Это система, которая позволяет вам надежно, отказоустойчиво выполнять
распределенные вычисления, и при этом не думать о том, как это отказоустойчивость реализуется.
Вы просто говорите, я вот сейчас собрал такой граф из там функциональных операций MapReduce,
вот вам, исполняйте. А дальше он как-то исполняется на сотнях машин параллельно. Там машины залипают,
машины выключаются, у машин пропадают диски. Все это работает без участия пользователя. Как
такую систему построить? Вот Google писал, и до сих пор этой идеей пользуются, и в следующем
семестве вы на другом курсе будете тоже ей пользоваться в виде HDFS Hadoop. И вот к этой
системе прилагается файловая система для хранения данных, распределенная файловая система, и мы этот
дизайн будем в курсе развивать, то есть мы его изучим, будем дальше его масштабировать и делать
более отказоустойчивым. Ну опять, это вот начало двухтысячных, это то, с чего Google начинал.
Почитайте про это. Ну и еще одна очень клевая статья. На 13-го года написал Джефф Дин. Джефф Дин
написал... не написал Джефф Эс, странно. Джефф Дин написал MapReduce со своим товарищем,
это такой большой коллективный разум, очень крутой, который развивал инфраструктуру Google
долгое время. И он написал другую статью. Вот есть Fold Tolerance, которая про то, чтобы делать
систему отказоустойчивыми, а есть Tail Tolerance, чтобы делать системы, ну так скажем, доступными в
смысле, чтобы пользователи, которые отправляли запросы в нагруженную систему, ну вот вы как бы
пользователь счастливый, вы отправились на удачную машину, и вам ответили за 10 миллисекунд. А может
быть ваш запрос ушел на машину какую-то неудачную, и там сборка мусора началась, и вам ответили за
100 миллисекунд или за секунду вообще. Вот статья про то, как можно строить, какие техники использовать
для того, чтобы строить системы, которые всегда отвечают за 10 миллисекунд. Даже если какая-то
машина может залипнуть, даже если там какие-то там общие ресурсы есть. Вот два этих аспекта,
две этих половины, как строить что-то отказоустойчивое, и это достигается алгоритмами,
и как строить что-то доступное, это достигается другими техниками инженерными. Вот про это
весь курс и будет, про комбинацию всего этого. Я буду рад, если вы придете. Опыт показывает,
что среди, ну мне нужно 20 человек. Вот, если вас больше, то вероятно кто-то из вас не захочет его
слушать. Не потому что там он сложный курс, или потому что, не знаю, вот просто этот курс,
он такой более специализированный. Он для людей, которым нравится, вот есть люди,
которым нравится делать кнопки, и которым перекладывать байты. И вот этот курс для людей,
которые любят байты перекладывать. Так что, вот вы можете выбрать, ну в смысле, лучше быть и тем,
и тем, конечно, но в первую очередь он для людей таких инфраструктурных, которым интересная
оптимизация, интересные все вот эти инженерные подробности, и интересный алгоритм, потому что
мы про них будем много говорить. Что? Этот курс, он, этот курс, ну он, в нем должно быть, конечно,
больше кнопок, но он все еще про байты. Просто смотри, этот курс, вот текущий, он более понятный,
более доступный, потому что ты вот куда бы ни пришел, потом на каком бы языке ни писал,
ты так или иначе столкнешься с какой-нибудь корутины или с Fiber или с Future. Вот какой бы современный
язык ты ни взял, там что-то будет. Поэтому у тебя не возникает вопроса, зачем тебе это нужно. Мы
будем говорить про системы распределенные в следующем году, и мы будем говорить о них с позиции
не пользователя, а разработчика. Как такие системы строить. Вот, и это, ну такие довольно специальные
люди, в смысле, что вот это люди, которым это интересно, которые это делают, и таких людей, ну,
меньше, чем людей, которые делают кнопки. Ну, я так утрированно говорю и никого не оскорбляю
ни в коем случае. Я просто говорю, что есть люди, которые делают продукты, а есть, которые делают
инфраструктуру. Вот, и я буду говорить про инфраструктуру. Вот, просто вопрос в том, в чем
ты видишь больше ценности. В том, что ты соптимизировал там какой-нибудь процентиль
своего сервиса, или в том, что там у пользователя теперь там работает саджест поиски. Вот, что тебе
больше нравится, что тебе кажется важнее в жизни. Ну, то есть, тут зависит просто от твоих вкусов,
того, что тебе больше по душе. Просто опыт показывает, что если тебе по душе все-таки что-то такое более
прикладное пользовательское, то, наверное, те подробности, которые у нас будут, они будут
изматывать. Они сложные, они очень… Ладно. Их очень много, и это все про такую инженерию,
про очень абстрактные вещи. Ну, вот если ты уже налочился говорить, строить предложения из слов
«крути новейтор», «экзекьютор» и т.д., а не произносить ни одного нормального человеческого
слова, то, как бы, там все тоже будет понятно. Ну, в смысле, там будет похожим образом. К сожалению,
инфраструктура – это про такие понятия, которых в природе нет. Вот, «пойди на улицу,
найди корутину». Довольно сложно. А? Автобус. Не знаю. Ну, значит, такими налогами можно, конечно,
многое покрыть. Я бы не стал. Все-таки мне кажется, что корутин в природе довольно мало. А понятия
для нас совершенно фундаментальные. Вот. В общем, если вам интересно, вы можете, по крайней мере,
оценить, насколько вам это интересно, почитав пару статей. Мы в любом случае это все разберем еще
осенью, но вот вы можете представление составить уже сейчас. Со всеми ссылками курса? Так он же в корне
Редми лежит. Добро пожаловать в репозиторий. Смотри, давайте я сейчас покажу. Возможно,
ты удивишься, но вот первая ссылка в Редми курса – она про ссылки курса. Ну, вот. Там ее нужно
актуализировать, конечно, и переструктурировать. Я этим займусь. Но вообще, обязательно сходи,
и давай я покажу, мне кажется, самые важные ссылки, которые можно прочесть в первую очередь. У меня
где-то они были открыты. Ну, в случайном порядке. Про фьюч я уже много раз говорил. Очень полезно.
Ну и посмотри, как это сделано в фолле, там документация и дизайн этих фьюч в Фейсбуке.
Есть довольно старый уже пост про принципы дизайна, которые за Unifex, за Unified Executor.
Но это старый пост, но он отражает ключевые идеи дизайна. Понятно, что там он уточняется,
полируется. Но вот то, что мы делали, сендеры, ресиверы, шедулеры, интрузивность, вот все вот
это этим постом покрывается. Дальше, если вы понимаете это, то вот можно почитать уже,
собственно, и Proposal to Execution. И, собственно, теперь все это можно читать. Если вы решили задачи
там на отл разные, то можно надеяться, что, конечно, все это будет сложно, потому что здесь,
ну это промышленный код, и в нем больше сценариев учтено, больше инструментов дано. Но принципиально
вы должны все понимать. Ну, я не знаю, нравится ли вам эта серия постов. Мне она кажется разумной,
потому что это Льюис Бейкер, один из авторов Coroutine C++. У него есть серия постов про то,
как эти корутины работают. И кто-то мне говорил, что это все сложно читать. Но, с другой стороны,
потому что он просто описывает дискоуровневую механику подробно. Вот мало где это все можно
увидеть еще. Конечно, обязательно посмотрите доклад Дмитрия Вьюкова. Он великолепен. Дмитрий
Вьюков сам по себе великолепен, бесподобен. И его доклад тоже про планировщика Go, который он
написал, про все вот такие подробности, которые мы потом переиспользуем в нашем коде. Ну и вот
по мотивам этого доклада и этого дизайна есть тоже замечательный пост из Токио. Там, когда там
переписывали этот планировщик на Rust, поделились своим опытом. Просто как они переписывали,
что они попробовали, это тоже было бы интересно изучить. Ну, просто чтобы эволюцию отсредить.
Очень клевое короткое эссе What Color Is The Function про то, что мир, асинхронный, корутинный,
делится на… ну, красится в два цвета. Точнее, как корутинный мир, в зависимости от того,
выбрали ли вы stackful корутина или stackless корутина, будет у вас либо монохромным,
либо двуцветным. Либо он будет красно-синим, либо он будет, ну не знаю, серым или каким-то. Розовым,
да, совершенно верно. Конечно же, stackful корутины гораздо приятнее, потому что в них не нужно ни о
чем думать. А вот если вы пишите stackless корутину, то вы неизбежно красите свой код в синхронные,
асинхронные функции, и они вызываются по-разному, они работают по-разному. И вот, ну, это довольно
серьезное отличие. Вот эссе обращает внимание на вот это, на это отличие, как бы проводит эту
границу между синхронным и синхронным миром, как-то влияет на код. Это довольно сильная, ну, довольно
заметная особенность, потому что она влияет на то, как вы пишете код, как вы комбинируете этот код.
В общем, предлагаю почитать. Это такая довольно знаковая статья, очень многие на нее ссылаются,
но и вы всегда отличите розовый язык от красно-синего языка, просто по наличию ключевого слова await.
Мне очень нравится статья про барьеры памяти, вот такая вот вводная, про то, откуда вообще
появляются, ну, мы перешли от примитивного синхронизации, в смысле от выразительных средств, простите,
к процессору, каким-то мелочам, к runtime'у, да. Простая статья, где берется процессор с двумя ядрами,
с шинами, с шиной между кышами, с протоколом когерентности простым, и объясняется, откуда
вообще берутся модели, откуда берутся вот эти барьеры памяти и почему вдруг у вас может
разломаться причинность, почему вы пишете простую программу, где вы, ну, где здесь простой пример
программы, вы пишете A, пишете B, а потом в другом потоке читаете B, если вы видите B единицу,
то вы, наверное, ожидаете увидеть и в A единицу. Вот почему такая простая программа,
скопировавшись на процессоре, может ломаться. Какие там оптимизации над протоколом когерентности
будет ваш процессор исполнять, чтобы разломать ваш такой простой код, который опирается на причинность?
Ну, дальше про модели памяти. В модели памяти тут есть много хороших статей, мне очень нравится вот
это, потому что она написана, во-первых, основателями всего этого, то есть декларативных моделей.
И она описывает не то, чтобы вот модель памяти спустилась на нас с неба, она про то,
как строили модели памяти и как там просто отталкивались от существующей реальности. Потому
что модели памяти, все вот эти memory orders, happens before, все эти порядки, они не произвольные,
они просто фиксируют ожидания разработчика от исполнения программы, соблюдение причинности,
соблюдение порядка некоторого, и фиксируют просто реальность аппаратную, как процессоры себя ведут.
И вот эта статья, она связывает два этих мира, то есть как отталкиваясь от аппаратной реальности дать
какую-то понятную модель для рассуждений, для доказательств разработчику. Очень классная статья.
Ну а дальше я бы, наверное, посоветовал серию постов Расси Хоккса, который написал совсем недавно,
это один из разработчиков языка ГО, и вот совершенно великолепная серия постов про то,
как, собственно, мы в курсе следовали примерно этой же схеме, когда я рассказывал о модели памяти,
сначала идет рассказ про аппаратную реальность, про то, как устроены процессоры, почему они там
что-то реордерят, потом рассказ про то, как можно эту аппаратную реальность описать в виде
декларативной модели в языке программирования и избавить разработчиков от знания о том,
как все это работает под капотом, и в-третьих, как дальше на основе всех вот этих общих соображений
инженеры конкретно выбирали, значит, как построить, как выстроить модель памяти языка ГО. Нужно ли там
делать слабые memory order или ненужные? Какой ordering выбирать по умолчанию? Все это, мне кажется,
очень ценно, когда вообще люди рассказывают, как они что-то делают. Вот я надеюсь, что наш курс
выглядел так, в смысле, что вот я рассказываю, как мы что-то делаем, мы решаем одну большую задачу.
Только так и можно чему-то научиться не решению, в смысле, не через решение, в смысле, готовое
решение, а через вот дорогу к этому решению, где мы пробуем разные варианты. Вот это такая
серия постов, где такая траектория описана. Ну а напоследок можно, если вы уже освоили модели
памяти, можно разобраться с тем, где они несовершенны, потому что они несовершенны,
в них много странностей. И вот есть такая классная статья, где, скажем, описывается проблема out of
scenario. Почему есть некоторые странные сценарии, которые почему-то допустимы с точки зрения модели
памяти формальной, и для которых в модели памяти написаны какие-то, в смысле, в документации
модели памяти написаны какие-то костыли. Ну вот, я это показывал на одном из семинаров. Почему
вдруг мы открываем вроде бы такую сложную навороченную модель памяти, она там написана
прямым текстом, что вот в этой программе запрещается читать 42. Вот как будто бы кто-то
захардкодил какой-то странный частный случай в модели памяти, хотя у нас были какие-то порядки,
гарантии. Вот почему так вышло? Почему люди решают задачу там много лет уже, и все равно
получаются вот такие странные частные случаи, которые общим фреймворком не покрываются? Непонятно.
Ну и, да, вот Андрей нам советует почитать статью про то, что даже атомики с memory order
sequential consistency — это не самая тривиальная вещь в модели памяти, потому что как только они
начинают взаимодействовать с какими-то слабыми моделями памяти, то начинается путешествие где-то
в к центру земли, там к ледяному озеру, короче, вот в самый ад, где вот очень сложные, очень
нетривиальные сценарии реализуются, которые должны быть в модели памяти учтены. И как вообще описать
гарантии memory order? Вот, да, обращу внимание, я это говорил как-то то ли на семинале, где-то,
то ли кому-то в частной беседе, что не учите, пожалуйста, модели памяти по cpp-референс,
или в чате, наверное. Cpp-референс — это справочник для разработчиков, а модели памяти — это такая
сложная наука, и никакого способа ее изучить, кроме как вот закапываться в такие подробности нет,
к сожалению. Но вот если вам будет интересно, как это все по-настоящему, об этом вообще правильно
думать, по-честному, без всяких там скидок упрощений, вот вы можете до такой статьи добраться,
но это, конечно, уже такой высший пилотаж, так мало кто умеет. Ну что ж, не знаю, у меня кончились
слова, я устал, наверное, что-то забыл, но, наверное, что-то не очень важное. Поэтому если у вас
вопросы есть, потому что происходило, что я еще о чем не рассказал вам, то давайте я, может быть,
отвечу на них. Я не думаю, что изменится что-то драматически, скорее оно, не знаю,
уточняется, полируется, обретает какую-то более удобную форму. Но вот из того, что прямо сейчас
делается или делалось там в какие-то последние годы, но, кстати, вот много всего, много того,
что мы изучаем, делается прямо сейчас. Ну вот я говорю, Fiber и Java, Project Loom делают сейчас,
еще не выкатили. Sender и Receiver, но это вот как раз какой-то новый подход, который вот нигде,
кроме C++, не пробовали, вот этот такой пионер. Делают прямо сейчас, уже тоже много лет,
развивают этот дизайн. Structured concurrency — это то, что появилось, да, как же я вам не посоветовал,
обязательно, обязательно, обязательно почитайте статью про structured concurrency. Конечно, ее мало
для понимания, но она, если знать о чем она, то она очень мощная. Этот топик, который тоже делали
совсем недавно, я вам рекламировал доклад Романа Елизарова, который сейчас главный дизайнер
языка Котлин, и у него есть великолепный доклад, где он рассказывает про то, как в Котлине внедряли
эти идеи. Этого тоже делали совсем недавно, там три года назад, и в новых языках это продолжают
делать. Так что то, что мы изучаем, это скорее вот такая текущая реальность, этим и занимаются.
Ну вот здесь скорее к решению близки. Вот кажется, что как бы удобные формы нащупаны. В конце концов
все сводится к тому, что у тебя асинхронные интерфейсы или асинхронные, и для синхронных
интерфейсов у тебя розовый или красно-синий мир. Вот скорее это какой-то такой незыблемый
фундамент, тут особо ничего не поменяется. Ну ладно, я вру, есть еще акторы. Есть еще акторы,
которых в курсе нет, потому что я на акторах ничего не писал, никогда сложно, чтобы в этом
рассказывать. Но, кстати, вот на днях будет High-Load, и там будет один из разработчиков
Yandex DB рассказывать про акторную систему, в которой на Яндексе написана очень большая база данных.
Вот именно на фреймворке актора. Там под капотом тоже, кажется, всякие переключения контекста. Но
вот акторы — это такой отдельный топик, который полностью изолирует runtime от конкурентных
активностей. То есть мы пишем отдельные акторы, которые последовательные, которые не могут напрямую
с кем-то конкурировать за какие-то разделяемые ячейки, их там просто не бывает. И все оптимизации
спущены в runtime. То есть это нечто похожее, в смысле идея похожая чем-то на future, в том смысле,
что мы синхронизацию скрываем, прячем ее под капот, дальше вот декларативно что-то делаем.
Но это другой подход. Я не привожу ни в коем случае знак равенства или какой-то параллель,
просто обозначаю, что цель — отделить runtime от активности, которую мы пишем. Ну вот это еще
одно направление, которое, ну есть языки, которые его развивают. Есть, там скажем,
довольно экзотические языки. Есть еще одно направление интересное. Оно связано на самом
деле не с конкуренцией в первую очередь, оно связано с языками программирования. Но тем не
менее, это вот сейчас языки программирования очень активно развиваются в самых разных
направлениях. И большое направление — это условно safety в самом широком понимании. Safety,
которое достигается разными сложными системами типов. И вот некоторые способы дизайна системы
типов приводит к тому, что наши программы становятся корректнее в смысле конкурентного
доступа к разделяемым объектам. Вот есть язык Rust. И там в безопасном расте невозможно сделать
датарейс, потому что невозможно иметь ссылку на две ссылки, две конфликтующие ссылки на одну
ячейку памяти. Просто такая программа не комплирируется. Это с одной стороны ограничение,
а с другой стороны — это, ну как бы, любая система типов, она чем занимается? Вот у вас есть класс
всех программ, и есть корректные программы, есть некорректные программы. И вот любая система
типов пытается отрезать максимальное количество некорректных программ, но нельзя их точно
выделить. Но если вы там, не знаю, какую-то теорию изучали, то невозможно построить такой алгоритм,
который отделяет от некорректного. Поэтому мы отделяем много некорректных программ и заодно
отсекаем какое-то количество корректных. То есть мы где-то жертвуем удобством, но при этом мы
получаем более безопасный код, в общем случае. Вот и есть разные подходы к системе типов. Там
есть, в первую очередь, это все двигается в функциональных языках, конечно. Но скажем,
вот есть совершенно экзотический PonyLang, который язык акторов, который вроде бы про то, что данные
нужно копировать, а не разделять. Но за счет системы типов можно гарантировать, что можно
все-таки актором обращаться к разделяемым ячейкам, и что они точно ничего не поломают. Вот за счет
сложности системы типов. Вот это тоже направление, которое сейчас развивается, которое с конкуренцией
связано. Чинить модели памяти, пытаются починить, пытаются что-то придумать. До сих пор задача не
решена. Вот. Удивительно, что как бы все это делается и все это покоится на понятие коррутина в
конечном итоге, да. А понятие коррутина вот больше полувека уже. Или вот structure of concurrency,
там идея тоже 50-летней давности. Вот. Но люди обращаются к глубокому прошлому, находят какие-то
идеи, переиспользуют их, переносят на новую реальность. Хорошие, удобные concurrency делать
научились совсем-совсем недавно. Вот раньше люди работали с потоками и там с колбэками. Совсем
недавно. Вот Котлин сделал коррутины. Когда? Последние несколько лет. Ну, Go это... Go появился
10 лет назад. Но Go это очень, очень разумный, очень согласованный язык, где очень аккуратно все
декомпозировано и собирается вместе в такую структуру. Потому что, ну, Go написали в Google,
а Google собаку съели на том, чтобы строить отказоустойчивые, надежные, конкурентные,
распределённые системы. Вот. У них был большой опыт. Ну, вот они предложили некоторое решение.
Rust появился, ну, как бы он появился там 10 лет назад примерно. Ну, в смысле, он развивался. Ну,
вот он совсем недавно пришёл к своим Async Await и Future. C++ Execution делают вот сейчас. Коррутины
появились тоже, там, в C++ 20. И то, ну, как бы есть некоторое мнение, что они не сам... Это не
самый удачный дизайн коррутины. Можно было бы сделать лучше, если бы ещё их там немного поварить.
Ну, или по-другому вообще поварить. Вот. Так что трудно представить, что что-то вот фундаментальное
новое изобретут, но вот над эргономикой сильно работают и прямо в самых разных языках всё это
прямо сейчас делают. Ну, вот так. Как я это вижу. Всё, нет больше вопросов. В Memory Order, конечно же,
мне нравится больше всего Release the Acquire. Какой вопрос, такой ответ. Ну, он, смотри,
это Memory... Ну, это наполовину серьёзно. Это потому, что он всем нравится больше всего,
потому что, во-первых, он про синхронизацию, да, вот. Что-то меньше ему не можем рассчитывать. А с
другой стороны, это вот, как бы, та наиболее оптимальная синхронизация, которую мы хотим иметь в
процессоре. Мы не хотим порядка, мы хотим причинности. В смысле, я не считаю Memory Order,
его нет. Я закрываю... Вот нет никакого консюма. Не думайте о консюме. Вычеркните его из своего
ума. Ну... Не знаю, мне в моделях памяти больше нравится, вот, и во Future это нравится,
и в моделях памяти это нравится, то, что вам предлагают думать не императивно, а декларативно.
То есть думать о том, какие гарантии вы имеете и что вы получаете, а не то, как это работает.
Это всё-таки абстракция, но, то есть она получается очень сложной, очень, как бы, ну, короче,
с дырами она течёт где-то, она где-то вот, как-то её корёжит вот в там Out of Scenair. Но это правильный
путь. Мы пытаемся сложность спрятать, потому что иначе этой сложности невозможно управлять.
Что-нибудь? Про историю курса я не знаю, это неинтересно, наверное. Ну,
каждый год курс становится в два раза лучше, чем он был в прошлом году, то есть пока это работает,
а? В полтора? Ну, я не знаю, мне кажется, что в этом году он стал сильно лучше для меня,
потому что, во-первых, всё собралось в одну задачу, и это большое достижение. В смысле,
всё всему подходит, это очень важно. А ещё, мне важно то, что никто не видит, то,
что всё это тестировалось под файберами очень хорошо, и поэтому я спокоен за то,
что тот код, который я вижу в EmergeRequest, там очень мало неправильного кода. Вот, это тоже
очень большое внутреннее достижение. Ну, всякое бывает, конечно, бывают исключения,
но в целом по-прежнему всё так. Ну, не знаю, наверное. Мне кажется, что в этом году получились,
ну, у меня более хорошие условия, там много, там более чётко и аккуратно выстроена линия,
ну, дерево это эволюционное, как всё это развивается, что от чего зависит, где мы что добавляем. Вот.
Мне очень важно, чтобы вы, пройдя курс целиком, могли бы вернуться в прошлое и понять, что же это
всё было, о чём же эти все замечания, там абзац, лекции были. Курс движется в сторону такую,
ну, больше прикладную. Раньше мы забавлялись каким-то, ну, давным-давно, на заре времён,
какими-то синхронизациями, там, лок-фри хэштабрицами, но это всё я склонен считать каким-то
праздным занятием. Всё-таки мы сейчас пишем, ну, кажется, гораздо интереснее решать большую
сложную задачу, писать собственные ГО, а не, там, изучать какие-то ловкие способы синхронизировать,
там, не знаю, построить хэштабрицу. Потому что, ну, это забавно, это, как бы, у вас такая инерция
после всяких, там, олимпиад алгоритмов сохраняется, но, в целом, никогда производительность настоящего кода,
настоящих систем, от этого не зависит. Если вам интересно, от чего зависит производительность
систем, ну, вот мы занимались memory-order, интрузивностью, там, протоколом конгерентности кэшей,
там, лифо-планированием. Мы будем, там, заниматься осенью всеми этими отменными ошибками, там,
вот этим tail-tolerance, full-tolerance. Вот-вот, что влияет на настоящий мир, на настоящие системы. И
акцент у курса сильно сместился в эту сторону. Мне кажется, что это важно. Вот что мы потеряли в этом
году, то, что я не успел сделать в угоду другим вещам, это вот вывод. Но если вы понимаете,
что происходит, вы понимаете, что там довольно, как бы, технические вещи остались. Но, все-таки,
там, одну-две задачи вписать в это все, в наш фреймворк стоит. Что? Я не знаю, как быть потом.
Ну, как маленькое. Смотри, сколько мы времени потратили сейчас. Смотри, у нас вот
раз, ну, сколько? Пятнадцать, да, плюс шестнадцать, семнадцать, восемнадцать. Ну, вот такое количество
лекционных часов. Ну, я бы сказал, что, если бы было, ну, вот вышки, я читаю три пары. Ну, то есть,
там, формально, лекции два семинара, но я, мы всех обманываем и делаем, как бы, два занятия, плюс
семинар, там, про разбор задач. Вот это, наверное, оптимальное время. Но, в принципе, я, вот, за
семестр укладываюсь по темам. Ну, я, скорее, укладываюсь. То есть, мне можно было бы это
растягивать, но я, вот, в общем-то, все, что хотел рассказать, рассказал. Может быть, можно где-то
развернуть, где-то подробнее, вот там, еще какой-то хвостик получится. Но мне кажется, что лучше,
когда насыщенно, плотно, и вот, как бы, больше параллелей, больше связи возникает, больше
интенсивность. Для меня это ценно. Наверное, мне не хватает еще кусочка с семинарами. То есть,
мы могли бы там еще встречаться месяц-полтора и, там, разговаривать про то, что мы дописываем
сейчас. Это правда. Как тут поступить, я пока не знаю, но, ну, я, скажем, в среду проведу семинар.
Можно к нему, не знаю, можно на него прийти всем. Можно на сдачу прийти, да. Вот, в следующую субботу
я тоже могу прочитать еще одну. Вот, про лог-фри канал мне хочется, я не прочисла консенсус,
я не знаю, что мне больше нравится. Короче, выберу что-нибудь. Ну, если я не знаю, если я в конце
мая останусь в Москве, то, может быть, то и другое. Да. Нет, неправда. Ну, в смысле, он всегда был,
ну, был конкарнс, а потом я просто сделал распределенные системы, потому что, ну, как бы,
это инструмент, а распределенные системы — это цель. То есть, это то, что мне интересно, и без
конкарнси невозможно говорить про распределенные системы. Я не знаю. Ну, это уже, мне кажется,
сейчас не очень интересно, все сильно далеко ушло вперед. Ну, важно не то, как бы что было,
потому что вас это в меньшем, ну, вас это как-то касается, непонятно как. Мне важно, к чему мы
пришли. А мы пришли к тому, что мы вот в этом семестре собрали одну большую сложную библиотеку,
в которой совмещается все. И это сложно. В смысле, сложно подогнать так, чтобы все сочеталось,
чтобы все друг с другом клеилось без какого-то оверхеда. Вот если вы это увидите, то вот вы
осознаете, прочувствуете мощь нашей библиотеки и вот всего происходящего. Это сложно было сделать,
это потребовало больших усилий. Но оно собралось, оно не идеально собралось, там можно еще по-другому
что-то делать. Но то, что уже сейчас, мне кажется, это здорово. Я вот рад, что в этом семестре у нас так
получилось. Мне кажется, что, то есть, я первый раз почти что доволен. Вот так, я близок к тому,
что вот процентов на 70, наверное, доволен происходящее. Это уже получилось неплохо.
Да. Ну, смотри, это не решается никаким курсом, это решается учебным планом. Ну,
я не знаю. Тебе нужно сдавать 10 экзаменов, да, и я не могу на это повлиять своим курсом.
Просто проблема в другой плоскости. Ну, не то что проблема, я не знаю. Ты, с одной стороны,
сдаешь 10 экзаменов, ты становишься жутко умным за счет этого. Вот. Ну, с большим трудом. Может быть,
ты бы где-то стал умнее, да, если бы ты посещал теме какой-то более, ну, специализация у тебя была,
но ты бы там что-то другого не узнал. Ты поступил в МФТИ, потому что тебе, наверное, нравится так.
Ты к этому должен быть готов, ты к этому уже должен быть привычен. Я не знаю, как с этим поступить,
я вот просто стараюсь рассказывать все, что могу, а дальше кто найдет время, тот разберется
основательно. Я так скажу, я разговаривался там в семействе с разными людьми, там на защитах,
на реакциях, там просто где-то между, и я в итоге, кажется, проговорил с людьми примерно все подземные,
все там подводные камни, все скрытые уровни, задачи, которые были. Другое дело, что это были
разные люди, если вас всех сложить, то вы, наверное, вы в сумме освоили все детали курса. Я не знаю,
есть ли где-то какое-то сосредоточение этого, но вот, скажем, по таблице есть пара человек,
которые сделали почти все, кроме одной из задачи. Все никто не успел сделать до последней реакции,
но с другой стороны, для меня все это без лук фри, это можно сказать, что все. Но вот с бонусными
уровнями это по-настоящему все. Вот, это требует времени, да, и я тут найти его за вас не могу,
только вы сами. Не знаю, что сделать. Мы можем продолжить общаться в чатике, и там, не знаю,
как-нибудь, если у нас будет, я не знаю, может быть, если у нас будет время, желание, мы можем как-то
вот ближе к концу месяца устроить какой-то разбор приватный про то, чтобы посмотреть,
как это все можно было бы написать и обсудить все вместе. Если мы так захотим, можем подумать над
этим. Вот, ну, когда мы уже докрутим задачи, вот эти последние, про там, грутины, каналы.
Летом CI, наверное, закроется, я не знаю. Не знаю, если там виртуалка. Локальные тесты останутся,
да, с ними ничего не изменится. Вот, ну и осенью я, ну или осенью-весной, собственно, мы будем работать,
да, я забыл, когда рекламировал осенний спецкурс же, рекламировать то, что мы будем весь код писать на
том фреймворке, который мы вот в этом курсе разрабатывали. То есть, вот буквально то, что вы сейчас
пишете, вот этим мы будем пользоваться. Не то чтобы, если вы не написали, то не сможете, да. Нет,
я за вас написал, и я пишу этот фреймворк, из него делаю этот курс, так он получается побочный,
можно сказать. Ну вот, мы будем этим пользоваться для того, чтобы писать уже какой-то распределенный код.
И этот фреймворк, он, не знаю, он там летом появится, я его открою снова. Он на семестр закрывается,
чтобы не провоцировать людей, подсматривать него. Ну вот, можно будет его почитать и сказать,
а я же могу и лучше сделать. Это тоже запросто может случиться. Вообще, вот я скажу, что в разных
mergeRequest'ах я видел очень клёвый код, то есть вы делаете прям очень хорошие вещи. Ну не то, что
кто-то один делает хорошие вещи, а вот разные люди в разных задачах пишут иногда чертовски хороший
код, доходят до самых глубин. Это здорово. Супер-приз. Так нет же победителя. Никто не
победил. Не знаю, приза нет пока. Я не знаю, нужно зафиксировать условия, то есть мы считаем до
конца месяца или мы считаем до сегодня. Придумаем что-нибудь, посмотрим. Ещё непоздно, я думаю. У нас
ещё есть время формальное, до когда можно сдавать задачи, так что давайте подождём.
Если у нас вопросы закончились, то спасибо большое, что были этой весной здесь, ходили,
слушали. Спасибо большое, что решили задачи. Вы большие, молодцы, вы сделали очень много,
поверьте мне. Я от вас ждал этого, но надеялся, ну вот вы смогли. Спасибо вам.
Аплодисменты.
