Ладно, давайте тогда продолжим, собственно, на чём мы в прошлый
раз остановились.
Вот.
Ну, как остановились, мы в принципе в прошлый раз
активно занимались, ну, помимо того что мы там изучали
как искать медиану за линию, в основном мы занимались
амортизационным анализом.
Ну вот, давайте кто мне скажет, что такое амортизационный
анализ.
Амортизация, мы в среднем.
Так, в среднем, мотожедание?
Ой.
Мотожедание?
Мотожедание хороший термин.
Это, короче, мы берём кооперации и считаем отдельную
струну.
Удельную?
Какую удельную?
Это платформа в Питере такая?
Мы оцениваем общее количество, мы оцениваем общее количество
времени на все операции.
Ну, типа того, да.
То есть, идея заключается в том, что когда мы берём
какую-то структуру данных, действительно, и мы выполняем
какие-то запросы к ней, то мы разрешаем себе некоторые
операции делать долго, но хотим чтобы в целом, то
есть, в некотором смысле, в среднем, эти операции
работали хорошо.
Ну, что это за некоторый смысл?
Ну, это как мы уже говорили.
В общем, у нас есть там структура данных, вот от
балды.
Чёрный ящик.
И говорят, давайте, что с ней можно делать там
четыре операции.
Нет.
Ну, для начала операция – твёрдый знак, операция
Операция мягкий знак, вот, да, и операция э, конечно,
да.
Вот.
Ну, как говорится, не будем сгорать, да, хоть операция
б52, да.
Вот.
Соответственно.
И теперь говорится, вот, предположим, что мы делаем
структуру данных, и у неё есть операции вот там
С1, С2, С3, С4, С5 и так далее, допустим, N операции, каждая
из которых, соответственно, это одна из этих, ну, допустим,
четырёх.
А тех, может быть, там 5, 6, 8 и так далее.
И мы говорим, ну вот, и мы говорим, что, ну, как обычно
меряется, то есть обычно, чтобы измерить время работы,
для каждой операции пишется там типа какая-то оценка
на её время работы.
Ну, вот, допустим, операция твёрдый знак работает
за там log N, операция И работает за корень из N, операция мягкий
знак работает за, так, какие ещё симпотики бывают?
Да, действительно, что тут думать.
И операция E работает, не, ну, давайте уж тогда log звёздочка.
Вот.
Ну, там, в данном случае, даже не важно, что это,
я тут мог бы вообще написать T1 от N, T2 от N, T3 от N, так
что пока даже не важно, что это такое, хотя в своё
время мы, конечно, это узнаем, в чём своё время даже в
этом семестре, скорее всего, наступит.
Вот я про это и говорю, узнаем в своё время, пока считайте,
что какая-то чёрная магия.
Сейчас, сейчас, нет, это не указатель, и это не указатель.
Вот.
Хотя, да, структурно, вот.
Так что пока считайте, просто мистическая функция,
какая-то, абсолютно мистическая.
Так вот.
Значит, тогда в чём ради, тогда говорим, если мы оцениваем
это в честном или так в худшем случае, то это означает,
что каждая, что если вот, скажем, C5 это операция твёрдый
знак, то она работает прямо вот железно за логарифом,
то есть там не более чем C log N действий, там операция
Каждая операция выполняет не более чем корень из N действий,
операция мягкий знак там требует не более чем от N действий
гарантированно, да, это дольше чем это, но тем не менее
гарантированно, что уж не более чем C N точно.
И операция E, собственно, работает за железный лог
звёздочек.
Ну, что такое маркетизационный анализ, то есть когда мы
говорим эти стоимости учётные, мы говорим, что на самом
деле каждая конкретная операция E может занять
у вас чуть дольше, время есть 7 лог звёздочек.
Вот, да, правда, как и твёрдый знак, но в целом они работают
именно так.
Что такое в целом?
В целом это означает, то есть в целом это означает,
что если среди этих N операций у нас оказалось, там, допустим,
K1 было операцией E, там K2 операции E, K3 операции мягкий
знак и K4 операции E, то тогда мы гарантируем, что, да, то
есть каждая конкретная операция будет работать там сколько
угодно, но все вместе они будут работать не более
чем за O от K1 на логарифом N, вот именно в сумме, плюс
K2 на корень из N, плюс K3 на N, плюс K4 на лог звёздочка
N, вот, то есть это более слабую структуру.
Заметим, что если бы структура железная, каждая операция
за столько работает, то все вместе они точно работают
за такую асимптотику.
Ну вот, но когда мы говорим учётную стоимость, мы говорим,
что, то есть мы не требуем жёсткой асимптотики от
каждой конкретной операции, но мы требуем суммарной
эффективности.
Вот, такой подход на самом деле замечательно работает,
то есть он действительно в некотором смысле развязывает
руки, ну вот, то есть там позволяет достаточно эффективно
реализовывать там ещё какие-то вещи, ещё какими-то способами,
ну то есть у нас, конечно, там аморизационные анализы,
там такие вот учётные структуры будут появляться сплоши
рядом.
Вот, но оно вот, ну вот, и это действительно чаще
всего, это вполне хорошо, но до определённого момента,
потому что иногда, конечно, на самом деле такая амортизация
может выдавать подлянки, потому что, вот, например,
бывает, вот иногда возникает такое явление, как персистентные
структуры данных, вот, значит персистентные структуры
данных.
Так, а ну-ка, поднимите руки, кто знаком со словосочетанием
персистентной структуры данных?
Так, хорошо, так, ладно, кто когда-нибудь раз в жизни
писал хотя бы одну персистентную структуры данных?
Ого, неплохо, так, мощно, мощно.
Вот, хорошо.
Да, действительно, а кто когда-нибудь писал какую-нибудь
мощную персистентную структуры данных отличия от персистентного
стэка?
А, ну да, кто и когда пишет «спасибо, персистентный
стэк!»
Да, логично.
Так, ладно.
Хорошо.
А кто писал?
Ладно, поступим по-другому.
Кто когда-нибудь писал персистентную структуры данных отличия
перистентного деревоотреска.
Так, уже меньше.
О боже!
Ну это мы сейчас убедимся, насколько или… Ладно, понятно.
А кто как-нибудь писал перистентную очередь?
А, а зал от леденицы?
Ой-ой-ой.
Да, мясо, да.
Ну ладно, сейчас будем разбираться.
Ну ладно, тогда давайте… Ну да, тут всегда сильно
больших комментариев на тему того, что такое перистентность
тогда делать.
Нет смысла.
Ну на всякий случай говорим, что… Ну вообще, что такое?
Ну тогда вот кто мне скажет тогда?
Что такое вообще перистентная структура данных вообще?
Ну по-разному.
Ну по-разному.
Ну по-разному, да, давайте, то есть, на самом деле, может
быть с оговорками.
Основная суть то есть та же, что действительно, если
вот рассматривать структуру данных, то в каждый момент
времени у нее есть какое-то состояние.
Ну например, если мы пишем стэк, то в каждый момент
времени в стэке находится вот какой-то стаканчик
элементов.
Ну там, если мы пишем деревоотресков, то значит у нас есть в каждый
момент времени какое-то состояние деревоотресков.
И вот перистентная структура данных – это когда мы хотим
помнить, собственно, все версии.
Ну классический пример жизненный – это, конечно, любая система
контроля версий.
Так, ну-ка поднимите руки, кто когда-нибудь раз в жизни
пользовался хоть одной системой контроля версий.
А, так.
Нет, это не система контроля версий.
Нет, система контроля версий – это ГИП, СВН, там вот это
все.
Может, например, курял там вот это.
Эти пользовались?
Ну вот такое.
Вот.
И совсем.
Ну вот.
Ну вот.
В чем здесь суть?
Да.
То есть, действительно, это оказывается там в ГИПах
и СВНах очень удобно, потому что если вы там что-то поменяли
и вам не понравилось, то можно, в принципе, посмотреть,
о чем было раньше.
И вообще посмотри, ну вот.
Ну особенно удобно, если, конечно, несколько человек
меняют, потому что если кто-то что-то поменял и все
испортилось в какой-то момент, то вы можете там
в любой момент просто посмотреть, а кто это был, и что он сделал.
Вот.
Ну там, соответственно, да нет, оставим вопрос,
какие санкции нужно применять, но речь не об этом.
Вот.
Но к чему нас это приводит?
Ну вот.
Вот теперь выясняет вопрос.
Как же эти версии хранить?
Ну самый тупой вариант – это, ну как вот иногда
питон поступает с целыми числами, это объявлять,
что у нас все версии неизменяемые.
То есть их менять нельзя.
Да.
Ну как бы вот, ну, по крайней мере, на уровне идеи, это
вот удобно сказать, что версии, что менять нельзя.
То есть если вот у меня есть версия номер пять, все,
она вот такая навсегда, и больше она никакая не будет.
Вот.
Казалось бы, зачем нам это?
Ну вот.
То есть это не значит, что к ней нельзя применить
операцию там, я не знаю, твердый знак.
Это означает, что просто, то есть по факту вы можете
себе вообразить, что по факту мы просто взяли
эту пятую версию, типа условно стэка или чего там, скопировали
ее полностью, и к этой копии применили операцию твердый
знак.
То, что у нас получилось, мы объявили, что это там
версия номер девятнадцать.
Вот.
Но это другой вопрос.
То есть мы сейчас говорим об идее.
Вот.
То есть, например, если вот мы хотим писать там, допустим,
персистентный стэк, то это будет выглядеть так.
То есть у нас изначально есть нулевая версия, где
стэк пустой.
Потом мы решили добавить элемент, там, троечку, там
сделать push три к версии ноль.
Вот давайте я версии буду писать в эшо, чтобы было
понятно, где версия, где элемент.
Тогда, заметим, нулевая версия от этого никак не меняется,
а то появляется версия номер один.
Это где мы как бы скопировали этот пустой элемент и добавили
троечку.
Вот.
Допустим, вторая версия рождается, если мы решили
сделать еще один push.
Там элемент пятьдесят восемь добавить в версию один.
Но так получается.
Вот пятьдесят восемь, три, а тут мы неожиданно, так,
погоди, парни, давайте возьмите снова первую версию, но
добавь туда, вот мы что-то очепятались не пятьдесят
восемь, а пятьдесят семь.
Вот.
А то что-то там, а то промашка какая-то произошла.
Ну что, копируем опять первую версию и пишем уже тут пятьдесят
семь.
Тут мы еще радуемся, о, вот теперь хорошо, давай теперь
вот в эту третью версию еще и сто семьдесят девять
напишем.
Вот.
Вот получается такая красота.
Так, ну вот.
А потом говорить, так, стоп, нет.
Сто семьдесят девять не надо.
Рядом с пятьдесят седьмой точно не надо.
Как вы запустите?
У вас должна быть пятьдесят семь тире пятьдесят восемь
тире.
Нет.
Нет, зачем тире?
Видите, я каждую версию стека бережно отдельно
храню.
Ранень, вы уже в версию в два добавили пятьдесят семь.
А ты смотрел, в какой версии?
Нет, я в один ее добавил, обратите внимание.
Видите, у меня тут не случайно это написано.
Вот.
А теперь говорим, так, да, точно, слушайте, а может
лучше надо было это, пятьдесят восемь из второй версии,
или пятьдесят восемь из второй версии, удалим, что
это такое.
Просто поп в два.
И тогда у нас получается пятая версия, и в которой
есть вот три.
А потом вспоминаем, ой, а давайте, конечно, четвертую
версию сто семьдесят девять удалим, а то что это такое
вообще.
Ну вот.
Неправильный номер школы.
Ну вот.
Поп, наверное.
Ну вот, да, поп.
А, ну или да, надо было пушить ее второй раз, да, действительно,
потому что замечательная школа и все такое, да.
Так, да, поп в четыре пишем, и соответственно получается.
Вот.
А потом кто-то приходит и говорит, нет, нет, погодите,
сто семьдесят девять это круто, лучше давайте идти
дальше, давайте лучше в эту четвертую версию добавим
еще.
Чего добавить?
Хорошо.
Пожалуйста.
Нет, ну уже двадцать девять было раньше, так что.
Нет, ну уже двадцать девять было раньше, так что.
Нет, два три девять.
А, два три девять.
Хорошо, хорошо.
Пожалуйста.
Так.
Если продолжаем с номерами школы.
Ну а что еще делать?
Так.
Ну я не знаю, ну не цифры же к числу АПИ вообще вставлять,
правда?
Так.
Вот.
Ну ладно, это можно остановиться, потому что суть в общем-то
понятна.
Все.
Пушь, солнце в голову.
Так вот.
Не, ну если бы мы делали третью строчку, да.
То есть, ну о чем суть?
То есть видите.
То есть мы теперь бережно храним на самом деле все
версии стека.
И, ну вот, и соответственно аккуратненько действительно
все поддерживаем.
Вот.
Но.
Ну вот.
Но, конечно же, это, наверное, не самое эффективное, что
может быть.
Потому что вот действительно, если бы высвоение там допустим,
то есть если бы в гите, например, там при изменении малейшей
строчки копировали бы всю базу гита, то, наверное,
там где-то в параллельной вселенной произошел бы коллапс.
Ну даже не в параллельной вселенной, а там, видимо,
с той стороны земного шара где-то коллапс произошел.
Вот.
Поэтому хотелось бы, конечно, это хранить как-то эффективно.
Но, правда, ну вот.
Ну как это можно сделать?
Ну, конечно, основные идеи, которые тут возникают, они
базируются на том, что все висит на указателях, вот
которые вы как удачно только что проходили.
Вот.
То есть действительно, ведь нам, как можно заметить,
в общем-то копировать иногда излишне, ну просто потому
что, например, вот мы видим, что от версии v1 и v5, например,
они совпадают.
Что это значит?
Ну вот, то есть в принципе можно было просто сказать,
что там говорить, что версия v5, так, ну ладно, когда тебе
обратятся к v5, ты просто смотри на версию v1 и делай то
же самое.
Да, но заметим, версия v5 не поменяется больше никогда.
Потому что когда мы применим операцию, то есть мы ее типа
копируем.
В результате на примере персистентного стека получается,
то есть можно хранить просто красивое дерево.
Вот давайте преимулируем те же самые операции.
Смотрите.
Итак, у меня будет, начнем, то есть изначально все,
гид будет начинаться с крестика.
Вот.
И на этот крестик мы будем смотреть как на нулевую версию.
А теперь идея такая.
То есть дальше мы сейчас будем строить такое деревце.
То есть версию v1, значит.
То есть мы, говорим, берем эту версию v0, вот как тут
написано, да, создаем элемент номер 3 и из этой троечки
вешаем указатель на версию 0.
Ну, то есть на крестик.
И получается, и говорим, что вот теперь эта троечка
это типа начало версии v1.
Теперь мы говорим, так, надо сделать пушк версии v1 и 58.
Что значит это значит?
Это значит, что мы создаем версию 58, то есть число 58
и из него даем ссылку на то, что было раньше версии v1.
Это будет называться v2.
Вот.
Если у нас версия 57, то что мы делаем?
Ну, ничего страшного мы не делаем.
Вот 57.
Только теперь, видите, то есть ссылается она ровно на тот же элемент.
То есть вот у нас получается такое вот красивое дерево.
То есть есть вот v2, есть v3.
Вот если мы к v3 еще хотим прицепить 179, пожалуйста,
вот просто такие вот указатели.
Вот.
Или вот пришло время сделать поп.
То есть вот у этой версии надо сделать поп.
Смотрите, мы его будем делать достаточно хитерским образом.
То есть мы просто скажем так, значит, последним элементом
будет не этот элемент, а просто следующий.
Вот давайте, вот мы 58 удалять не будем,
но версия v5 будет указывать на следующий элемент.
Вот теперь так и получилось, что версии v1 и v5 смотрят
на один и тот же элемент.
А поп из середины мы не делаем?
Почему?
Нет, поп это стэк.
Нет, в смысле, что-то пока что.
Это стэк.
У стэка вы имеете право делать поп только с конца.
Как вы делаете с середины, это уже другая структура данных.
Там какие-то там.
Вот.
Ну да, там всякие вот это.
До этого мы тоже доберемся, но пока вот.
Но теперь что нам надо?
Теперь вот из v4 тоже хочется сделать поп.
Что мы делаем?
Ну да, v4 сдвигаем вот сюда, то есть вот теперь v7.
Ну даже не сдвигаем.
В принципе, так, и что там?
Теперь push v4 239.
Ну, пожалуй, ничего страшного.
Значит, рисуем сюда 239.
То есть в принципе это оказывается очень удобно.
Смотрите.
Так.
А, понял, да.
То есть это все достаточно удобно.
Все это просто.
Вот, то есть получается будет,
то есть будет получаться красивое дерево.
Особенно если вы храните все версии.
Ну персистентность стэка это, конечно, простейшая персистентная структура данных.
То есть здесь максимально просто реализовать так,
чтобы каждая операция работала за o от единицы.
Действительно.
Более того, здесь достаточно легко реализовать так, чтобы хранились только те элементы, которые нужны.
Ну что я имею в виду?
Я имею в виду следующее, что
да, мы говорим, что мы хотим вот все версии,
но иногда нам нужны не все версии.
Ну, предположим, вот мы знаем, что на самом деле
нас, допустим, мы там
в целях какой-то оптимизации решили,
что нас интересует там только
нулевая версия, третья, пятая и двадцать восьмая.
Тогда оказывается,
что мы, в принципе, тогда эти указатели
можем убрать, то есть все, кроме
нулевого, третьего, пятого и двадцать восьмого.
А если
на какой-то элемент
никакая версия уже больше не указывает
и никакой предыдущий элемент
не указывает, то его вообще
можно удалить.
Ну вот, ну в принципе,
то есть можно даже там реализовать,
то есть можно для каждого элемента посчитать
сколько вот этих вот указателей, сколько
версий на меня вообще указывают. Если их
стало ноль, то давайте я себя просто удалю.
Подожди, а почему их может стать ноль,
только если мы версию удаляем?
Ну да, если мы
удаляем версии,
тогда может стать ноль, значит, всегда будет
положить на число какой-то.
Ну вот, то как бы...
У нас тогда уже версия появится.
Ну мы как-то добавляем...
Понятно, что в случае стека, да, на каждый элемент
должна указывать хотя бы одна версия.
Но если мы какие-то версии решили не хранить,
то на какой-то элемент указать не мог.
Вот, например, если мы решили
сказать, что, например,
версии второй больше нет,
ну тогда мы торжественно объявляем,
что тогда элемент 58
можно торжественно удалить.
Если на него ничего не указывает. Да.
Вот, например, да, если мы решим удалить четвертую
версию, то вот этот элемент 179
не удалится.
Почему он не удалится?
Да потому что он еще является
частью, на него еще указывает 239,
который в свою очередь является V7.
Пока он... Погодите,
ну доживем. Да, удалять его не надо.
Но, если мы после этого
скажем, давайте удалим и версию V7,
то тогда, по идее, должно произойти
следующее. Элемент 239
объявляет, что, ну, все, в принципе,
я, там, я сделал свое дело,
я могу уходить.
И исчезает.
Тогда элемент 179
неожиданно понимает, что
как бы да, я жил ради того, что на меня
вот указывал этот 239,
и 239 тоже ушел.
Но тогда я вот в этом месте тоже
разворачиваюсь и ухожу.
Ну вот, теперь да, 57 тоже узнает
эту трагическую новость, что на него указывает
на одно 179 меньше.
Но оно от этого
не умирает.
Почему оно не умирает? Потому что
на него указывают еще две версии.
То есть мы в каждом элементе храним
сколько на него указывает?
Ну, например, да.
Нет, смотрите, нет.
Удалять, ну, как сказать, удалять.
Вот здесь, как ни странно,
амортизация начинает работать.
То есть, обратите внимание, да, тут амортизации
изначально не было, потому что каждая операция
за честную единицу работала.
Но обратите внимание, глобально
вы удалите не более, чем
количество, каждый элемент,
как бы, если он удалился, он удалился навсегда.
Потому что если мы, допустим, указываем
две версии на один и тот же элемент,
сначала мы удаляем первую всю ветку, потом вторую всю ветку
и третий снова всю ветку.
Проходим и уже тогда удаляем.
Да, ну, в смысле, что нам приходится
изчетку всей ветки просто...
Зачем мы только...
Нет, ну, может так случиться,
нет, правда, может так случиться,
что мы действительно за один шаг,
то есть когда после очередного неожиданного
удаления версии,
неожиданно удалим прям большую цепочку.
Нет, вопрос не в этом.
А в чем?
Вопрос в том, что если мы в каждом элементе
храним, то сколько на него есть ссылок,
то надо после каждого действия
обновлять всю...
всех родителей.
Не-не-не-не, всех родителей не нужно.
Достаточно рядом с каждым элементом
хранить, а сколько на меня
указателей еще стоит.
А как это делать?
А элементарно.
Но дело в том...
А элементарно. Вот есть элемент,
решили сделать к нему пуш.
Все, вы говорите, что отлично, здесь плюс один.
Все.
Вот. И там если...
Если у него там количество версий тоже плюс
один, когда удаляете версию, значит говорите,
что у конкретного элемента минус одна версия.
Вот.
То есть конкретно... Чего?
А предки не... А зачем предки?
Предки не надо.
Нет, не нужно.
Не нужно, не нужно.
Не зачем, потому что, смотрите, тут все надежно так,
что для каждого элемента
мы просто храним даже не сколько у него предков,
а сколько конкретно указатель
на него указывает.
Потому что, смотрите, элемент
обязан жить
только если выполнено хотя бы одно из двух
условий. Хотя бы одно.
Первое условие, на него указывает какая-то
версия.
И второе, он...
И второе, может быть, он является
не последним элементом какой-то версии.
А это эквивалентно тому, что
на него еще кто-то указывает вот из этих элементов.
Сейчас, то есть если мы удаляем
какую-то версию,
мы просто сообщаем нашему клетку, что...
Да, то есть когда мы удаляем 200,
видите, вот 239, мы не просто ее удаляем,
а вот смотрим на кого
она указывала и сообщаем ему, что у него
минус один указатель.
Вот и все.
То есть тогда гарантируется,
что как бы у вас не может...
То есть у вас, если на элемент
никто, вот никакой другой элемент не ссылается,
значит, на него ссылается какая-то версия.
Потому что если ни то, ни другое, значит, этот элемент
можно прямо сейчас удалить.
В общем-то, технология классическая,
когда вы будете проходить всякие
шарит ПТР на C++,
вы неожиданно эту технологию обнаружите
просто во всей красе.
Забегая вперед, скажу,
что, скорее всего, вам придется ее даже писать.
Вот.
Да, к вопросу о домашних заданиях по C++.
Да, они будут
и достаточно мощные.
Так что...
Да ладно, я что-то не задавил завтра.
Не.
Детлайн будет вчера.
Вот.
Ладно.
Так вот, идем дальше.
То есть конкретно в стэке
действительно тут максимально хорошо.
Ну вот.
Ну вот.
Правда, ну вот.
Тут, конечно, имеет смысл
некоторая амортизация на тему удаления элементов.
То есть каждый конкретный
элемент может там неожиданно
работать долго.
Потому что вы удалили версию,
и он неожиданно устроил тотальную зачистку.
Но, впрочем,
с другой стороны, если вас не устраивает,
что тут происходит амортизация,
то это делается просто. Вы можете там, скажем,
отдельно хранить, какие элементы нужно удалить
и на каждом шаге удалять по три
элемента, скажем.
Вот, понятна технология, да?
А то сейчас чуть позже она тоже
еще более мощно включится.
То есть тогда суть будет такая,
что если вы решили удалять элемент,
надо его не удалять, а поместить,
так сказать, в какой-то список элементов,
которые подлежат удалению.
Этот список он же должен быть там амортизированно
работать.
Ну вот. Нет.
Нет, это будет реальный двусвязанный список,
например.
Вот прям реально двусвязанный список.
И тогда на каждом шаге,
то есть вы там сначала там, может быть,
кого-то добавляете в карантин,
а потом после этого говорите, что
если есть что удалять, ну там возьмите
первые три элемента и удалите.
Вот.
Да, причем, возможно, после этих трех
удалений там появятся еще кандидаты
на удаление, но их вы уже не удаляете.
То есть тогда,
смотрите, в чем тогда рахится?
Тогда уже вообще никакой амортизации не будет,
и тогда каждая конкретная
операция будет работать за
железобетонные от единицы.
Ну то есть да, правда, с учетом
этой вот, собственно, этого
пылесоса, как этот пылесос
в джаве называется, а,
как бы, школлектор.
Я не знаю, у меня почему-то в голове
все равно я его пылесос почему-то называю,
ну вот.
Да ладно.
Ну кто, в джаве не знаю.
А конкретно тут,
ну как бы мы реализовали пылесос,
ну можно реализовать в тупую, что когда есть
что удалять, давайте удалять до конца.
Это тогда будет учетная стоимость
единицы, в смысле, по всем созданиям Векси.
Учетность.
Но если вы будете, вот как я сказал,
то есть хранить там
двухсвязный список из того, что надо удалить
и удалять на каждом шаге там, скажем, по три элемента,
ну вот, то тогда
окажется, что этот пылесос будет работать
за, тогда это будет железобетонные
единицы. То есть тогда
так, то есть память будет очищаться не сразу,
но вот постепенно вот так, постепенно.
Когда нам приходит информация
о том, что этот элемент
надо удалить. Ну в том плане,
чтобы когда на него больше ничего не указывать.
Вот.
Так что вот такая красота получается.
Вот. В чем, казалось бы, кайф.
Вот прям идеальный спект, то есть даже уже
с удалениями за вот единицы.
Ну а теперь какая следующая идея
возникает? Так давайте,
а может быть реализуем персистентную
очередь?
Нет.
Но если очень хочется, то давайте.
Ну вот, да. Нет, казалось бы
причем. В чем проблема?
Ну проблема, первая, конечно, проблема
сразу заключается в том, что
к сожалению, да, вот у стека есть маленькая
приятная структура.
То есть это приятное свойство. Его можно
как бы подвесить за начальный элемент и как бы вот
такой, да? И работа только с концом.
У стека, у
очереди это несколько не так.
Потому что у очереди фактически
есть такая висящая цепочка и работаете
вы как с одним концом, так и с другим.
То есть скажем, вот
такая древесная структура уже не прокатит,
потому что, например, если у какой-то версии
скажем мы объявим поп, то теперь
вопрос там куда двигаться, там условно. Сюда
или сюда.
Ну что же, что же делать?
Тут мы говорим, хм,
так какие проблемы-то вообще?
Мы же, кажется, по-моему,
там полтора часа в прошлом занятии,
если не больше убили на то, чтобы реализовать
очередь через два стека.
Нельзя. Можно.
Что это можно?
Да, казалось бы,
нет, казалось бы,
нет, нет, скажи так, тут аккуратно.
На самом деле, форум так. Реализовать-то можно все,
что угодно. Да,
сейчас, дойдем, дойдем, давай не перебивай. Да, все понятно.
Молодец. Вот.
Да, действительно, казалось бы,
давайте, если мы хотим реализовать очередь,
то давайте просто реализуем
там, реализуем просто стек.
Ну, там в лице даже у нас будет
единый персистентный стек,
и у каждой очереди это будет
просто две версии стека.
Ну, типа, одна версия соответствует стекуин,
другая стека, думаю, понятно, о чем речь, да?
И давайте,
и прям честно делаем все эти операции.
Ну, мы же знаем, что там все
за вот единицы делается.
Ну вот, возникает маленькая подлянка.
Да, вот тут называется, вот, где
амортизация нагревается.
Потому что там
оказывалось, что у от единицы,
то есть это означает, что некоторые
операции могут работать за линию, но гарантируется,
что если вы делаете эти последовательные
операции, то у вас
тогда конкретно одна операция может
работать за у от н, но в сумме все
будет адекватно.
Но в доказательстве этого,
то есть в этом, в анализе, мы жестко
пользовались тем, что
все операции делаются последовательно.
Вот.
Потому что конкретными версиями
действительно может так не получиться.
Ведь действительно, если мы реализуем очередь,
и у нас там получается, делаются
операции, операции, операции, операции,
операции, и, допустим,
честного времени, допустим, c и t оказалось
равно там teta от n.
То есть мы тут делали, видимо, очередной
поп, да?
Допустим, поп
из какой-нибудь там v
какой-нибудь там 345, давайте.
Вот.
То есть если мы из этой версии делаем,
и выяснилось, что она там работает за у от н.
Вот.
То есть там, ну, создалась
конечно там новая версия там и все такое.
Но проблема в том,
что, как минимум в том, что вообще говоря
структура этой амортизации
позволяет нам вообще вызывать
этот поп сколько угодно раз.
От той же версии.
Да, прям от той же версии, прям подряд.
Pop v345.
Pop v345.
Pop v345.
И каждый раз она будет, ну,
если не принять там каких-то мер, она будет в тупую
реализовываться за т.т.
То есть знаете там вот
как-то вот
за эти вот
там сразу ассоциация вот
в Гарри Поттере было описана
такая сцена, что например там
ребята там поехали на чемпионат мира по квирикю
и они там использовали какую-то
бинокль с возможностью там
перемотки и повтора.
Чего?
Ну я не помню как
он называется, по-моему он так бинокль назывался.
Ну ладно, от перевода зависит, не важно.
Ну вот. Но как бы
суть этого всего перемотка там
замечательно сформулировал Рон Уизли.
Который сказал, круто, я могу заставить
того старого хрыча поковырять в носу еще раз.
Еще раз. И еще раз.
И еще раз.
Ну вот.
Вот тут примерно та же ситуация.
Потому что тут, к сожалению,
если это происходит
за т.т.,
то как бы
то получается, что весь анализ
на смарку все работает за N квадрат.
То есть у нас если отдельные части
работают за OATN, то каждый из них
может быть заставлен и быть переделан еще раз.
Вот. И это
не то, что мы хотим.
Вот.
То есть получается действительно
N квадрат. То есть мораль такая,
что персистентность не очень дружит
с амортизацией.
То есть если мы хотим персистентизировать
структуру, то мы должны как-то
реализовать ее желательно таким
образом, чтобы каждая операция работала
за честную асимпозицию.
Вот.
Ну желательно там чтобы как-то еще удобные изменения
проходили.
Вот. В результате оказывается, чтобы реализовать
персистентную очередь,
приходится придумывать сильно более сложную
структуру. Вот сейчас мы с вами
с вами, возможно, сейчас
впервые изучим реально сложный алгоритм.
Не, не, не. Мы завод единицы.
Не, не, не.
Нет. С персистентным
софхипом напряг, потому что
структура нас просто пропитана
амортизацией.
Так что нет, персистентный
софхип это не к нам.
Да, вот там
если
хочется веселых словосочетаний,
лучше пишите персистентную леватскую кучу.
А есть ли какие-нибудь утверждения
по поводу того, что любую структуру
даже амортизированную можно сделать персистентной?
Ну там не вся операция уже нет.
Ну не знаю, мне об этом не известно.
Вот так скажу.
Итак.
Знаете, смотрите.
Что такое
как же нам реализовать персистентную очередь?
Ну, идея
казалось бы, будет та же.
Да, начало будет такое же.
То есть у нас будет
стэк L,
в который мы будем добавлять элементы.
Ну, по крайней мере, по идее.
И стэк R,
из которого мы эти элементы
будем доставать.
Вот, понятно, да?
Ну, в принципе,
до некоторого момента,
то есть вообразив в себе
какую-нибудь серединую ситуацию,
что в этом стэке много элементов,
в этом стэке меньше элементов.
Ну, как бы, что мы делаем тогда?
Ну, тогда, действительно, приходит push,
запихиваем сюда, приходит pop,
достаем отсюда.
Ну, или там топ какой-нибудь, ну, смотрим сюда тоже.
Не проблема.
Понимаете, да?
Вот.
Но просто проблема возникнет в том,
что когда-нибудь элементы здесь закончатся,
и тогда все эти элементы придется
перекинуть.
Причем самое обидное, что мы должны
озаботиться этим сильно заранее.
Почему? Потому что если у нас, например,
очистится весь вот этот стэк,
и мы потребуем следующий, то нам придется
докопаться аж до сюда.
Прямо, то есть, возможно, потребуется
отн операции, просто чисто для того, чтобы
докопаться до этого элемента, не говоря уже о том,
чтобы там куда-то кого-то перетащить.
Поэтому, значит, мы...
Ну, то есть вся суть, то есть сейчас будет действительно
достаточно сложная, там, какие-то махинации,
но смысл очень простой.
Вот смысл очень простой.
Мы на каждую операцию будем тратить
время на то, чтобы
перекинуть
соответствующие элементы из стэка
L в, там, условно, стэк R.
Вот как бы, вот я не случайно
вот упоминал структуру в стэке, когда
мы амортизируем, то есть мы как бы
постепенно удаляем, да, то есть
у нас есть список элементов,
которые надо удалить, и мы на каждом шаге
удаляем по три элемента.
То есть, как бы, чтобы делать
как бы на каждом шаге
за вот единицы. Вот сейчас у нас
такая же смысл, то есть мы не будем
полностью перетаскивания делать,
мы сделаем какие-то
там три или четыре
шара навстречу этой светлой
цели.
В результате работать это
будет так. Вот давайте так.
Первое приближение. Значит, смотрите.
Ну, во-первых, ну, давайте подумаем.
Вот, если у нас уже прямо сейчас
есть элементы в стеке L
и элементы в стеке R.
Значит, забирая вперед, сразу скажу,
что, как бы, режим
перекопирования, то есть, ну, то есть
на самом деле, то есть, режим, то есть
два режима. Нормальный режим, когда мы ничего не делаем.
Почти.
И режим перекопирования.
Режим перекопирования включается, когда
в стеке L становится на один элемент больше,
чем в стеке R.
То есть,
то есть, пока в стеке L не больше,
чем элементов, чем в стеке R, нас все
устраивает. То есть, просто
ничего не делаем. Вот.
А есть режим перекопирования.
Но теперь, смотрите, что нам нужно?
Нам нужно каким-то образом вот эти элементы
запихнуть вот сюда. Да?
Вот.
В чем сделать это? Желательно за там
X-операцией.
Почему именно за X-операцией? Потому что
через X, потому что, ну,
то есть, мы знаем, что не позже,
чем через X, не раньше, чем
через X даже, через X-операции,
через X плюс один, нам вот этот элемент
вообще, до этого элемента вообще докопаются.
Поэтому, если к этому моменту
он окажется в стеке R,
то, в общем-то, нас то устроит.
Но, правда,
заметим, чтобы запихнуть его куда-то сюда,
вот эти элементы тоже придется
доставать, не правда ли?
Понимаете, да? Вот.
Поэтому,
значит, нам придется
провернуть такую махинацию. То есть, надо.
Нам придется достать,
значит, придется, значит, перекопирование.
Будет устроено так.
Сначала мы
стек R,
элементы
из стека R перетащим в некий
дополнительный стек S.
Вот он.
Вот. Потом,
ну, то есть, эти элементы, вот давайте я сейчас нот.
Вот.
Потом, ну, давайте я сейчас абстрактно
напишу, потом я, собственно, продемонстрирую, что тут
в идеале хотелось бы иметь.
Смотрите, это вот R, S.
Потом все элементы
перетащить
из элемента нот
из стека L в стек R.
А потом из R,
а потом из S вернуть элементы
обратно в R.
Сейчас, давайте, я сейчас вот,
давайте так, чтобы было всем понятно,
я сейчас это на примере просто покажу,
что тут пока хочется делать.
Пока это все там,
то есть, знаете, так, идея и там,
ну, я не знаю, там, что-то типа
декларации намерений, что ли.
Ну, вот. Ну, такие там может быть постепенное
приближение, значит, что мы будем делать.
Значит, смотрите, вот, допустим, у нас
было, что у нас там в стеке R, допустим,
там, допустим, элементы 2,
3, 5, 8 там,
я не знаю, 21, 38.
Вот. А вот с этой стороны у нас тут
образовались какие-нибудь числа.
Я не знаю, 4, 9, 16,
25, 49,
52.
И 8.
Да, еще одна.
Так, ну ладно, чтобы,
давайте выясним.
Ну, по барабану, да.
Топеречи. Ну, вот.
Что мы хотим сделать?
Сначала мы хотим перекинуть
все вот элементы из R в S.
То есть, тогда у нас,
если мы их будем по одному перекидывать,
то у нас так и получится.
38, там, соответственно, 21,
ну, прям вот в том же порядке,
8, 5, 3 и 2.
Отлично. Наконец-то зачистили вот это все.
Ой, да, легче уже так, да.
Вот все за один заход.
Нет.
Это мы все хотим сделать,
все вот это вот мы хотим делать за
X заходов.
Амортизирован, да?
Нет. Ну, в итоге хотим, чтобы не амортизирован.
Но, как бы, мы хотим, чтобы
каждый из операций,
то есть, параллельно с push и pop,
то есть, рядом с каждым push и pop
должно делаться какое-то константное количество
операций, там, по 3, по 4,
но так, чтобы суммарно потом
за X этих операций произошло следующее.
Во-первых, вот эти элементы перелезли
в stack S.
Потом мы перегнали вот эти
элементы все в stack R.
То есть, вот давайте
так и перепишем. То есть,
вот эти мыши отсюда достаем,
как бы, да, и поехали. 18, 52,
49,
25, 16,
29, 40.
Вот. Ну, и этот stack становится
пустым.
Вот.
И тогда получается
следующее. Следующее, следующее.
Вот. Теперь у нас stack пустой.
И, наконец, все, что нам остается,
это теперь вот эти элементы в том же порядке
вернуть в stack R.
И получится вот
два, три,
пять, соответственно,
восемь,
двадцать один и
тридцать восемь.
А что мы делаем, если
по мере того, как там
идут новые пуши и попы? Ну, что-то
происходит с этими stackами?
Вот. Да,
правильный вопрос.
Правильный, абсолютный вопрос. Да, поэтому я и говорю,
что это декларация намеренности. Да, потому что
да, мы будем это делать, но
у нас параллельно что-то
будет происходить.
Что будет параллельно происходить?
Параллельно будет происходить то, что нам
нужно будет выполнять сами
пуши и попы.
То есть, скажем,
может оказаться, например,
что мы хотим за x операции, допустим,
перекопировать x плюс один элемент.
Но у нас есть маленькая подлянка,
что если мы начнем перекопировать
вот этот stack, а потом нам бабах
сделали пуши, сделали пуши сюда же,
то это будет
немножко не очень, правда?
Вот.
Вот.
Поэтому, то есть, такая проблема.
Еще более того, если мы
там что-то добавим, то порядок элементов
просто навсегда порушится.
Поэтому мы
будем говорить нот. Поэтому сейчас
вот и будут появляться, да, вот stack s у нас.
Да, он будет, и смысл
его будет ровно тот же.
Вот.
Но теперь
смотрите, рядом со stack l
мы заведем
stack l'.
Значит, смотрите, то есть, идея такая,
в нормальном режиме,
то есть, в нормальном режиме
stack l', ну, равно как и stack s,
не работают.
Понимаете, да?
То есть, просто они,
то есть, они вот такие
молодцы, они не работают.
Что?
Сейчас, то есть, не понял?
Нет, сейчас дойдем,
погодите.
Давайте...
Ну вот, значит, l',
то есть,
то есть, идея будет следующая, да,
что получается
в нормальном режиме,
то есть, действительно, push
соответственно просто в l,
pop,
в r.
А в режиме
перекопирования,
ну, вот,
ну, вот, ну, здесь придется
еще оговариваться, но push
будет делаться в l'.
Ну, то есть, на уровне идеи уже говорим,
что, да, в конце получится,
что вы сделали вот это перекопирование,
да?
Да.
Ну, вот, сделали это перекопирование,
но при этом были запушены еще элементы.
Но тогда у вас теперь будет l'
пустой, а вот здесь у вас
появились еще какие-то там элементы
веселые.
Да, совершенно верно. И тогда просто
идея, что в этом месте вы эти стэки
можете просто поменять местами.
Да, ну, просто, да, если у вас стэки
на указателях реализованы, то, в общем-то,
вам их просто можно поменять местами.
Да.
Этот стэк нужен
для того, чтобы в процессе
ну, потому что
перекопирование происходит параллельно
с реальными push'ами и pop'ами,
которые происходят.
То есть, напоминаю, мы не можем просто
взять и перекопировать, и потратить
отn времени до того, как возьмем
следующую операцию, да? То есть,
напоминаю, в чем... То есть, как бы,
мы вот это вот будем делать постепенно.
То есть, как бы,
вот мы себе описали, что мы вот,
если у нас тут было x элементов,
x плюс 1, то мы как бы
за x элементов
перекидываем из r в s,
потом x плюс 1 элемент перекидываем
сюда, из l в r,
а потом из s в r перекидываем x элементов. То есть,
и того у нас есть 3x плюс 1
операции.
Да, мы это делаем
не сразу.
То есть, фишка то, что на каждом шаге
мы, ну, давайте так, для простоты скажем,
тратим, то есть, делаем
4 из вот этих необходимых действий.
Сейчас, почему 4?
4 для того, чтобы за x операции
вот с этим всем покончить.
Ну, привите, тут
3x плюс 1, поэтому я говорю 4.
Ну, если хотите, можете в самом начале
сделать на одно действие больше, но суть
одна. Мы уже не одновременно их делаем,
мы изначально должны из r в s,
потом...
Да, мы их, ну, последовательно,
эти действия делаем последовательно, да.
Почему нам по 4 тогда? Ну, потому что
суммарно мы делаем, должны сделать 3x плюс 1
действие, а я очень хочу
за x пушей попов
это все сделать. Почему
именно за x? Потому что напоминаю.
Потому что напоминаю.
Мы начали перекопирование,
когда тут было x элементов,
а тут x плюс 1.
Почему я хочу успеть
за x?
Ну, вот. Ну, хотя можно делать
и по 3 операции, потому что
можно считать и ту, после которой
вот это вообще произошло.
Но я хочу... Но дело в том, что
после x операции,
в худшем случае, может быть, что тут будет
x попов, да, и следующий
элемент будет какой-нибудь фронт.
И будет фронт. И тогда вот мне
нужно, чтобы этот элемент уже был доступен.
Именно поэтому
я хочу успеть именно за x операции.
Да.
Да.
Да.
Да.
Причем обратите внимание, мы действительно перешли
в нормальный режим, потому что
в эре тогда не менее, чем
x плюс 1 элемент, то есть вот эти вот все,
да, а при этом
в L-штрихе на этот момент будет
сделано не более, чем x пушей.
Поэтому значит в эре будет меньше
элементов, чем в эре, и тогда значит
режим действительно нормальный. Да.
В x может быть порядка n нет?
Ну, может.
И что?
Ну, суммарно.
Суммарно, да.
Но еще раз идея, вот основная
идея заключается в том, вот
самое главное, что вы должны понять,
что мы это делаем
не за 1 операцию.
То есть у нас есть
запросы
вот эти, да, вот там.
Там запросы, там query1,
query2, query3 и так далее.
И так далее, да.
Вот.
И вот это вот перекопирование
вы вот не между там
третьим и четвертым делаете,
а в течение некоторых запросов.
Ага. А сейчас
после x операции
у нас в L будет x элементов,
а в R получается 2x минус 1, да?
Э, почему?
Ну, в худшем случае...
Ну, в идеале, конечно, их должно быть
x плюс 1, но если там
это x будет x push, то тут будет
2x плюс 1 элемент.
Вот. Но да,
но правда, тут, конечно, еще есть оговорочка,
что... сейчас дойдем.
То есть будет оговорочка,
что, конечно, это мог быть
x попов, тогда тут будет x плюс 1 элемент.
Вот.
Нет, ну а так суть, вот действительно,
как бы переформулировать суть следующая.
То есть, смотрите,
то есть, допустим, представьте себе, вот вам каждый
день нужно учиться, да?
Ну, в смысле, ходить на пары.
Вот.
А параллельно вы хотите,
ну, я не знаю,
прочитать книжку.
Не, ну любую,
там, смотрите,
любую, ну там любую книжку, неважно.
Там, пожалуйста, ладно, что-то, ладно,
отбалдывай. Отбалдывай, в чем давайте,
чтоб не связанность программировали, там, ладно,
звать Анна Коренина.
Нет, хорошая,
нет, ну на самом деле нет,
там, как бы...
Нет,
нет,
нет, нет, нет,
если я честно, на самом деле
мотивирует, потому что там, как бы...
Потому что
как минимум, ну,
потому что как минимум там история
рассказывается трех семей, история одной
из них очень мотивирует, правда.
Чего?
Анна Коренина, я же говорю.
Да.
Нет.
Это вот пример того. Вот вы хотите прочитать?
Да, она два тома.
Но у вас есть вот эта вот учеба.
Пум-пум-пум-пум-пум-пум.
Да, вот вам нужно вот ходить
на пары.
Но, смотрите, можно сделать...
Можно, конечно, сказать так, что
да, мне нужно потратить там, вот, там много времени,
чтобы ее прочитать.
Но как бы, если вы будете делать это
между какими-то парами,
то, скорее всего, вы пары прогуляете.
Потому что, ну, а ну-ка, ну,
либо вы там будете читать, ну, совсем, там, быстро-быстро,
там, лишая себя там сна, обеда, ужина и так далее.
Даже если на выходных, потому что
ну, реально, это, конечно, не война и мир, но тоже
два тома. Вот.
Какие есть варианты? Есть варианты
другое. Значит, есть варианты
амортизации. Это означает, что
после каждой пары,
скажем, на перемене,
вы тратите пять минут на то,
чтобы прочитать, допустим, о от единицы страниц
данного романа.
Вот, четкие о от единицы.
Не скажите.
То есть, это происходит
достаточно параллельно.
То есть, получается,
как бы так, то есть, получается,
что тогда, получается, вы с одной стороны
на уроке успеваете.
То есть, другое дело, что просто,
ну, просто по сути у вас, да, каждый урок, конечно,
виртуально увеличивается на пять минут, которые вы тратите
на Анну Каренину.
Вот. Но зато
процесс идет стабильно.
Абсолютно.
Да.
Мы же можем к разному
состоянию вызывать. То есть, нам
мы можем нескольким состоянием
делать рекопи,
тогда у нас будет много операций.
Нет, нет, нет. У нас будет так. Если мы запустили
рекопи, то как бы это
рекопи идет до конца.
И только когда мы вот дошли
до этого рекопи, мы обнаруживаем нот.
То есть, восстанавливаем и том же думаем.
Надо ли дальше там рекопи еще?
А, такое не будет.
Смотрите еще раз почему.
Значит, еще раз напоминаю.
Рекопи запускается ровно в тот момент, когда
в стеке L стало на один элемент больше,
чем в R.
Да, в какой-то момент.
То есть, изначально режим нормальный.
Ну, изначально режим нормальный,
да?
В какой-то момент на один элемент стало больше.
Ровно в этот момент
на ближайшие X
или там X операций
нот, ну и плюс одну операцию,
когда вот это произошло,
объявляем режим перекопирования.
Это же состояние меняем?
Или это новое состояние?
Нет, ну как сказать...
Режим перекопирования.
Ну, не совсем. Нет, у нас пока нет
версий. Пока мы
просто делаем последовательно
там очередь на стеках,
так, чтобы это был мой нот.
Так, чтобы каждый момент времени мы делали
вот от единицы действий.
Пока это не персистентное.
Нет, персистентность, смотрите,
ну цель такая, что если мы достигнем
того, что у нас будет, может быть, много
стеков, но зато каждая операция
будет за железные от единицы,
и только со стеками, то персистентно
ее будет сделать очень легко.
Потому что любую операцию с персистентностью
она будет включать в себя, что
на самом деле мы находимся вот на такой-то фазе
перекопирования, и просто она там, когда вы
на этой версии что-то запустите, она там сделает какую-то
свою часть перекопирования.
Вот. То есть глубокий
смысл того, что происходит, вот.
Да, давай.
Два вопроса, один и другой не очень.
Во-первых, почему не ходить на лекции
амортизировано? Во-вторых,
почему у нас все хорошо
будет с попом, когда
у нас и режим перекопирования будет?
У нас же элементы перекладываются
в стек-с, они там резко оказываются
в другом порядке.
Нет, ну, смотри так.
Так, погодите.
Так, погодите,
погодите.
Ну,
ну, считать, значит, давайте так,
почему это мы... Это не амортизировано,
это просто, смотрите. То есть, ну
просто ситуация здесь такая. Вот есть пары.
И на них надо ходить.
Так, можешь на них амортизировано ходить.
Всё в записи есть.
Ну, не, давайте так.
Сейчас мы живем в предположении, что на пары жестко ходить надо.
на самом деле хорошее предположение кстати вот кстати более того вот из этих причин тоже
следует почему на самом деле вот сейчас даже расскажу почему значит смотрите то есть вот
хорошо ну пока предположим что действительно вот на паре жестко ходить надо вот потому что
иначе там я не знаю расстреляют там не зачет по физкультуре там ну вот вот это все вот то есть
жестко ходить надо тогда получается что если вы хотите почитать анну коренину вы должны это
жестко делать значит где-то между парами нет ну как сказать после пар это между последней
сегодняшней парней завтрашней следующей так что вот но просто тут просто суть оказалась в том что
вас между парами нету там промежутка который вот позволит вам просто вот прочитать анну коренину
целиком вот ну и психологически это сложно потому что в это время хочется там ну я не знаю поесть
там есть поесть по спать там я не знаю там называется погулять там потанцевать там и так далее ну вот все
что угодно там спортом там позаниматься вот вот соответственно значит что еще эти нот и но вот
поэтому просто называется не успятий психологически просто и вообще и даже поняли еще там есть
психологический момент и дуйте что да это очень сложно меня может энергии не хватит что даже не
не хочется пытаться.
Поэтому что мы делаем вместо этого?
Мы просто говорим, что после каждой пары мы 5 минут тратим
на Анну Каренину.
Вот все, прям каждую перемену, уходим, садимся на диван,
5 минут читаем Анну Каренину.
И тогда в чем разница?
То есть тогда получается, что вы стабилизируете,
тогда вы движетесь, может и медленно, но зато стабильно
и надежно.
Потому что 5 минут там после пары находятся.
Вот стабильно.
То есть более того, почему и на паре имеет смысл
ходить, вот тоже на самом деле есть такой классический
анекдот про студента сессию амортизации.
То есть мало кто знает, но когда студент поступает,
называется любой вуз, к нему приходит черт и говорит,
поздравляю ты попал в ад, и у тебя только есть выбор
режима.
Режим нормальный и режим студенческий.
Вот, ну студент говорит, ну давай попробуем нормальный.
Ну вот что такое нормальный режим?
Студент, значит человек приходит к студенту каждый
день, забивает ему молотком в голову гвоздь и уходит.
Каждый день.
Ну студент там держится неделю, две, три, а потом
говорит, давай попробуем по-другому, давайте попробуем
студенческий ад.
Вот, что говорит, окей, и исчезает.
Месяц проходит, два молотни приходит, три проходит,
и вот наконец-то декабрь, неожиданно вечером когда-то
студент стук в дверь, значит на пороге стоит черт с коробкой
гвоздей и говорит, ну что студент, сессия.
Вот, вот это называется амортизация.
То есть мы все время амортизировано учились, да?
Да, точнее наоборот, нет, наоборот, хотя к сожалению
это не амортизировано учились, вы амортизировано отдыхали.
То есть у вас цель была вот сколько-то отдохнуть,
да?
Сколько-то отдохнуть.
И вы как бы говорили, что вот давайте вот я как бы
сейчас отдохну, но в сумме как бы будет нормально,
что dann сессию сession.
Абортизированная учеба.
Нееет, это если ты решил, что вместо 6 пар в день
у тебя ближайшее 2 месяца будет 12, зато потом последние
2 месяца у тебя не будет пар вообще.
Наоборот.
Это амортизированная учеба.
Если у тебя первые 2 месяца отдыха потом последние
2 месяца по 12 пар в день, значит амортизированный
отдых а принципиально на самом деле если внимательно посмотреть на
амортизацию то это требует что но но хотя но хотя да да да вы правы пожалуй да
но да да правильно да то есть до некоторые операции и перекладываем на
потом но гарантируем что в каждом моментом да да да согласен согласен
да хорошо да но в принципе да вот то есть гвоздями получается так то есть к заданному
сроку как бы вы все равно в объёте в голову все гвозди только вопрос что вот но вот только
если у вас там просто значит одновременно будет виды все вози у вас будет там мишанина
собственно там взорвана голова и так далее вот а если вы будете собственно учится вот
собственно постепенно уже там начiekну вот уже прямо сейчас собственно аккуратно там аккуратно
там вот там по чуть-чуть все предметы, то ну во-первых это будет гораздо стабильнее, то есть
во-первых это стабильнее, то есть вы уже так привыкнете к этому графику, да, то есть возможно
там действительно там будет конечно некоторое страдание, отчасти из-за того, что да, приходится
работать, да, отчасти из-за того, что вы там завидуете, что там ваши товарищи уже там, называется там,
там бегают по дискотекам, они там играют в кёрлинг, там радуются там, называются жизни всеми
способами, вот, но зато когда, но вот, но зато когда придет сессия, называется там, но вот вам
особенно прииграться не придется, да вот, ну и потом стипендия, нет потом стипендия, которая даст вам
собственно возможности, да, собственно самим потом играть, да, то есть тут вот, то есть как вы даете
то, что заложить действительно семена, потому что потом это, потом знаете, на работе это вам потом
собственно тоже в профит пойдет, нет, даже не потому, что там вы там пройдете собеседование, да, или не
пройдете там, дело даже не в этом, просто дело в том, что ну как бы на работе подавляющие больше
свойства скорее всего там, называется, пойдут работать в какие-нибудь IT-компании типа там Яндекс.АБИ,
там ВК и так далее, да, ну вот, соответственно, и тогда что, ну вот, и тогда если у вас уже есть
привычка того, что действительно вы вот можете действительно вот большой частью дыря там действительно
посвящать именно какой-то вот учебе работе, то во-первых, вам будет легче адаптироваться к работе, а во-вторых,
собственно, вы будете готовы, что вы можете рядом с этой учебой тратить там пять минут на то, чтобы
там вместо Анны Корениной уже изучать что-нибудь там, что необходимо реально по работе, и в результате вы
окажетесь сильно более востребованным специалистом в итоге, просто в конечном счете, то есть да, то есть на
самом деле это даже преимущество, знаете, вот в этом смысле на самом деле вот эти вот иногда вот, например,
какие-нибудь неолимпиагрики, например, вот боятся олимпиагников на тему того,
что я там вот буду, вот я там с ними учусь, и все, там я услужу лекцию, я с трудом понимаю,
я не знаю, эти олимпиагники там явно уже своими вос 我們 там, называется, дают понять, это все понятно
давно там, это все там, ну ладно там, если даже, ладно, если они там знают это одно дело, ну
тут даже не знаю, но это все самоочевидно ,что вы тут это все разжевываете, вообще, не интересно,
давайте лучше дальше вот но если но в итоге на самом деле тут просто для
олимпиагиков очень большая подлянка после есть но вот просто если я просто
вдавал не олимпиагика подлянка сразу если они поздравлю скажут они и олимпиагиков
никогда не дают это там какие-то божие мега там космические люди которые там
называются умеют там якобы раз в десять больше чем обычный человек вот ну
сразу скажу на самом деле нет вот как вот правильно вот на топкоге руки
Надя Короткевич и замечательный статус на эту тему статус называется статус
ее простой я не гений я просто хорош в этом вот просто помните да то есть
то есть в общем да он просто он очень круто решает там спортивное
программирование все то есть в общем-то высокий рейтинг на топкоге говорит
практически только об этом сам себе вот а во вторых с отец но то есть подлянка
вот для нет но если вы не сдадитесь то есть говорите ладно да нормально кто-то
занимался этим больше там кто-то у кого-то может быть там может быть там
больше способностей там и так далее и нынче страшного
называется я но значит я буду все равно действительно двигаться собственно и
собственно работать и тут тогда в перспективе подлянка начинается уже
олимпиаде потому что олимпиагики некоторое время наоборот радуются вот
очень сильно радуются на эту тему там что вот а мне тут вот очень все легко это
я все знаю на мотоанализе там эти все пределы мы там уже во всех листочках
мат школах там уже изучали поэтому там не напрягаться вообще не надо то есть
сейчас вот это параметри время ну вот и собственно так привыкайте потом на
самом деле этот архив быстро заканчивается потому что день там в
лучшем случае в середине первого курса ну или хоть там середине там первое
семестр или там в лучшем случае первого курса это уже все ваше знание
заканчивается там уже приходится ботать но собственно вас уже организм привык
к сильно более низкой нагрузке и тут тогда вот а вот у не олимпиоников на
оборот собственно уже производная в этом смысле пошла выше ну вот то есть тут
на самом деле вот олимпиаде тоже такая подлянка так что результат в результате
оказывается что там олимпиадники вылетают также как не олимпиадники на
самом вот чего вот так это я да это я на первый вопрос ответил дам да начали
с Анны Корениной да так да ладно это я тут ладно потратил да на воспитательную
работу ладно давайте теперь вернемся по делу да давай напомним вопрос как у
нас при копии работает мы же перекладываем из рвс у нас с порядком
все плохо они не с порядком ничего плохого не происходит вот видите ну
смотрите вот это вот наглядно видно вот когда вот слева направо смотрите потому
что когда вы из рвс кладете вы как бы достаете отсюда кладете сюда поэтому
порядок как бы все еще слева направо ну смотри
вон а это следующая проблема которая да вот дойдем потому что перед этим мы
занимались тем что решали проблему лишних пушей которые происходят то есть
теперь мы убедились что если мы гарантируем что ближайшие икс операции
будут только пуши то в общем-то я структуру данных уже описал правда
понимаете да значит теперь попробуем уровень следующий значит на самом деле
может возникнуть такая проблема но на самом деле есть у вас стеги это такие
вектора которые позволяют вам еще из в оператор квадратной скобки лазить да
то вы бы могли на самом деле просто хранить сколько элементов на самом деле
у вас было попопано да и там с точки зрения перекопирования просто сказать
если оставшийся элемент который надо перекопировать они уже попопаны то в общем
то надо их не копировать а тупо удалять то есть это тоже надо делать потому что
может скопиться много элементов, которые надо удалить, но
вы просто их удаляете, а не добавляете.
Но поэтому, если бы у вас стэк еще и поддерживал
какую-нибудь операцию вида, а покажи мне там какой-нибудь
там седьмой с конца элемент, то, собственно, в общем-то,
на этом структуру можно было, описание структуры
можно было бы и закончить.
Вот, понятная идея, да?
Ну просто идея в том, что давайте так, просто храним
сколько элементов из этих вот R мы попопали, вот из
этого X.
Ну, в процессе перекопирования.
И тогда просто, когда вы будете перекапывая, перебирать
элементы из S в R, то просто те элементы, вы знаете, что
там последние несколько элементов просто надо не
добавлять в R, а просто удалять.
Ну да, то есть, когда вы поняли, что все вот эти
элементы, они уже были попопаны, вы же можете легко хранить
информацию о том, сколько элементов из этого R на момент
начала перекопирования вы попопали, да?
Да даже не указать переменную просто.
А если мы уже начнем лишнее перекладывать в R?
Ну вряд ли вы так начнете, потому что функция-то непрерывно
растет.
Ну потому что сначала 0, потом 1, потом 2 и так далее.
Поэтому, соответственно.
Поэтому просто, и потом, это решается очень просто.
Это решается на момент того… Смотрите, keти, эти элементы
вы по-любому перекладываете сюда честно и эти элементы
вы тоже сюда перекладываете честно.
А вот когда вы тут перекладываете, вы просто достаете очередной
элемент и говорите.
Так, этот элемент был попопан?
Если он не был попопан, значит вы его перекладываете.
Если он был попопан, значит вы его тупо удаляете, но
из S вы его по-любому достаете.
То есть, тогда заметим, что некоторое время может операция
уже и закончится, и тогда там в эсе останется несколько
элементов удаления, но это тоже будет у нас частью
перекопирования.
То есть еще есть перекопирования, те которые мы из эсе просили?
Ну да.
Это мы научились не добавлять удаленные элементы.
Значит это мы, да.
А находить какой элемент?
Вот, а вот находить какой элемент, да, мы пока поверили,
что мы это откуда-то можем.
Находить какой элемент что-то?
Ну просто, ну потому что смотрите, возите такой вопрос, у нас
помимо операции push и pop есть операция top, которая
говорит, так, скажи мне, пожалуйста, кто у тебя сейчас
наверху.
И тогда у нас возникнут проблемы.
Почему?
Потому что этот элемент может не находиться на верхушке
ни одного стека.
Он, там, он скорее всего в этот момент будет где-то
в стеке S.
Фронт, который раньше лежал в эльке наверху, а теперь...
Нет, топ.
А, топа, у нас нет топа, а у нас есть операция front.
Нет, наоборот, front вот типа front вот здесь, а back вот здесь.
Ну вот, да, поэтому, то есть, этот элемент, да, back без труда,
но если бы у нас был не front, а back, это был бы стек и
мы бы не заморачивались.
А надо front.
Чего?
Вот.
Но я говорю, вот эту проблему мы сейчас решаем.
Ну вот.
Ну смотрите, значит, еще раз, давайте так, раз у нас
пара сейчас заканчивается, сейчас я подведу итог просто
своего левра, до чего мы дошли и в каких предположениях
мы уже победили.
Значит, мы предполагаем сейчас, что у нас есть стеки,
потому что в каждом стеке есть операция, возьми не
самый верхний элемент в стеке, а возьми элемент,
я не знаю, восьмой с верхней шины.
Ну типа квадратные скобки такие, да?
Предположим, что у нас такое есть.
Тогда возникает следующее.
Тогда, значит, реализация такая, мы заводим вот эти
четыре стека.
Значит, есть два режима, нормальный и перекопирование.
Значит, нормальный режим, это когда в стеке, значит,
в нормальном режиме, это вся очередь находится
в двух стеках L и R, здесь x элементов, здесь меньше
либо равно x.
Понимаете, да?
В этот момент стеки L' и S вообще пусты, мы их не
трогаем.
Потому что все, что мы делаем в нормальном режиме, это
абсолютно то же самое, что мы делали в режиме двух
стеков.
То есть push добавляется сюда, pop удаляется отсюда.
Top, соответственно, смотрится сюда, понятно, да?
Но как только у нас наступил момент, когда после очередного
push в стеке L стало x плюс один элемент Rx, то мы запускаем
режим перекопирования.
Значит, он делается так.
То есть, во-первых, мы заводим переменную, которая будет
считать, типа colpop, она изначально равна нулю, но вообще colpop
это будет информация, сколько в процессе перекопирования
элементов вот этих вот были уже попопаны.
Понимаете, да?
И теперь вы в ближайшие x операции, или x плюс одну
включая эту, делаете вот эти вот, вот с этими элементами
L, R, S, проворачиваете вот этот механизм.
То есть, независимо от того, у вас там push или pop, вы
прям проворачиваете вот этот механизм.
Теперь, как вы делаете push и pop?
Когда вы делаете pop, вы просто увеличиваете colpop.
На единичку.
Когда вы делаете push, значит push вы теперь делаете в,
как уже сказано, в L'.
Понимаете, да?
И теперь, говорите, что независимо от того, был
у вас push или pop, вы делаете следующее, то есть вы вот
из этого механизма делаете, ну скажем, четыре действия.
Вот, понятно, да?
Ничего не понятно?
Ну и сначала, если у нас есть в R, то мы копируем
B3 или B4.
Да, то есть, каждое действие, то есть, нам нужно сделать
x плюс один действие.
Каждое из действий говорит такое, если у нас, то есть,
как бы мы храним, на какой фазе мы находимся, на первой,
второй или на третьей.
Если мы сейчас находимся в первой фазе, значит, наши
действия перекинуть один элемент из R в S.
Нет, мы делаем, я сказал, три действия, но я описываю
одно действие.
Одно действие – это перекидывание одного элемента из какого-то
стека.
Причем, мы можем понять, что если мы на этой фазе,
значит, мы перекидываем это.
Если эта фаза закончилась, значит, переходим ко второй
фазе.
Значит, если мы на второй фазе, значит, мы перекидываем
один элемент из стека L в стек R.
Как только мы перекинули последний элемент, мы объявляем
третью фазу.
На третьей фазе мы перекидываем элементы из S в R, но на этот
раз с оговоркой.
Оговорка заключается в том, что мы, когда, т.е. мы,
когда приходит время перекинуть элемент, мы его достаем
из S, но с помощью кол попа понимаем, а не был ли он случайно
уже по попам.
Если был, тогда мы его в R не добавляем, а мы его
просто выкидываем.
Как мы понимаем, был ли по попам или нет?
Вот, просто, потому что, нет, не-не-не, все еще проще.
Дело в том, что, ну, соответственно, просто S это, по сути, конец
очереди.
Ну, точнее, начало очереди.
Поэтому, по сути, мы говорим, что если у нас в S 8 элементов,
а кол поп равно 5, это означает, что три элемента надо еще
перекопировать, а следующие 5 уже не надо.
Или, если вы говорите, что кол поп равен 7, а у вас
там стейк так, сколько у вас сейчас, достаем элемент,
каким он был в стейке?
Четвертым, а все, выкидываем.
Потому что он был уже по попам.
А если у нас кол поп, в принципе, превзошел стейк S?
Ну, такая, отлично, и он и будет его превосходить.
Нет, ну, просто, это еще будет приводить к тому,
что если кол поп выиграет, то тогда можно просто из
самого R уже поп делать и фронт в него смотреть.
Остается только одна мелочь.
А что делать, если от вас потребовали фронт, а как
бы нот, а этот нот, что делать, если соответствующий
элемент находится еще не в R, а вот соответствующий
элемент еще где-то в S.
И вот тут нам приходится ввести предположение, что
мы можем в стейке рассматривать не только последний элемент,
но и любой там i и t.
Тогда мы говорим, что если у меня в стейке 9 элементов,
а кол поп равно 5, значит, и в этот момент приходит
фронт, значит, мы просто возвращаем из этого стека
шестой элемент.
Ну, потому что 5, вот эти они типа лишние, а вот шестой
это то, что нам надо.
А если кол поп превосходит стейк S, то мы вообще...
Нет.
Как только кол поп стал превосходить стейк S, это
означает, что тогда у нас L' и R это уже актуальная
очередь, актуальная очередь, а все что в S надо просто постепенно
удалять.
И тогда фронты и попы вы делаете уже честное из
стека R.
А, то есть вы начинаете в нормал мод, да?
Нет.
Нет-нет-нет-нет.
Нормал мод вы переключаетесь только когда вы еще и S зачистили.
Да, ну и в конце, да, то есть как бы, да, вот, режим
рекопии заканчивается только в тот момент, когда вы не
только все перегнали из L' в R, но и зачистили S.
Мы с стеку R можем обращаться к этому элементу?
Ну да.
Но там лучше уже тогда лишние элементы удалять,
чтобы просто их там не было.
Нет, просто вот если у нас кол поп превосходит S, то
нам нужно же...
Кол поп не может превосходить.
Чтобы кол поп на этом превосходить S, должно произойти хотя
бы X попов.
А мы строим ОГИ так, чтобы за X операция...
Не-не-не-не-не-не-не-не-не.
Не совсем так.
Почему?
Нужно 4 операции.
Нет, кол поп легко может превосходить S по одной простой
причине.
Ну, предположим, что вы, значит, перегнали все элементы
в S, потом даже из L' в R все перегнали, даже так, да?
И после этого стали начинаться попы, да?
И тогда представьте, у вас тут 57 элементов и начали
приходить попы.
Тогда как бы у вас один элемент вытянули, кол поп
ставим равен один, а три элемента с другой стороны
вы перетянули сюда.
Тогда у вас тут вот, потом еще, тут еще кол поп увеличился
на единичку, то есть уже два элемента лишних, и еще
три.
То есть получается они вот так сталкиваются.
В какой-то момент они столкнутся.
Ну там не в какой-то элемент, а в какой-то там, где-то
через 14 шагов у вас получится, что там 42 элемента вы уже
перекинули в R, а 14 элементов уже это типа вот кол поп.
И тогда на следующем шаге вы оставшийся этот 43-й
элемент перекинете в R, а потом обнаружите, что хотите
перекинуть еще два, а потом окажется, что ой, а эти элементы
уже подпадают под кол поп.
И тогда получается, что когда вы их достаете, их просто
не надо отправлять в R, их надо уже просто тупо удалять.
А тогда мы кол поп уменьшим.
Нет.
Зачем?
Кол поп не надо удалять?
А зачем его уменьшать?
Зачем?
Кол поп...
Что такое кол поп?
Кол поп.
Определение кол попа.
Это сколько было попов в процессе нашего перекопирования.
Это прям вот, просто математическое определение, это, собственно,
это понятие.
Да, но когда мы выбрасываем элементы из S, то кол поп
уменьшаем.
Нет.
Нет.
Определение кол попа не имеет никакого отношения
к стеку S.
Оно вообще определяется чисто для очереди.
То есть, говорят, мы вырубили режим перекопирования.
Кол поп.
Это сколько произошло после этого события попов.
Все.
Хорошо.
Если нам...
Есть идея?
Если мы видим, что элемент уже удален, ну, если кол
поп больше, чем размер стек, то мы его сразу удаляем
и уменьшаем кол поп.
Нет.
Не уменьшаем.
Нет.
Почему?
Я скажу еще раз.
Это количество попов, которое было выполнено после начала
перекопирования.
Кол поп — это не количество элементов стеки S, которые
надо удалить.
Хорошо.
А если у нас был...
Это разные вещи.
Если у нас кол поп был уже больше, чем S, и мы сделали
еще один поп, то мы уже должны удалить из S.
Ты знаешь?
Да.
Абсолютно верно.
И мы будем это делать, потому что нишо нам это не мешает
делать.
Но мы это сделали.
Да.
Как только кол поп стал больше либо равен размера S, начиная
с этого момента, мы попы будем делать реально из стека
S.
Вот.
То есть, по факту, все, что нам надо, на самом деле,
это уметь и этот элемент искать только в стеке S,
по сути, надо.
В стеке S даже не обязательно.
Да.
Что-то бы изменилось, если бы мы...
Тогда L больше и равно, чем X делено на 2 плюс 1.
Сейчас.
L...
X делить на 2 плюс 1.
Ну, там, Влада, по модулю некоторых начальных условий,
что ли.
Но стала вот такая.
Нет.
X пополам плюс 1.
Ну, тут вот...
Попопопа.
Так что сложно.
Ой.
Так, кажется.
Да.
Ну, я не знаю.
Понимаете, тут как бы еще начало, потому что есть вот 0.0,
и, скорее всего, первый пуш уже вызовет режим перекопирования.
В чем персистентность?
Пока ни в чем.
Нет, персистентность в том, что это теперь можно
делать персистентом, потому что каждая операция делается
за честных вот единиц.
Сами делайте следующее.
Ага.
Так.
Colpop у меня равно 8.
Так.
Значит, смотрите.
Когда вы будете доставать восьмой элемент с конца
стека, значит, вы, пожалуйста, там запишите и отправьте
собственно вот в ответ на этот запрос.
Сами запросы записываете в двухсвязанный список
и, собственно, обрабатываете там, по мере достижения.
Вот.
Так.
Так.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Давайте, кстати, попробуем, честно, написать примерный
код.
Как это вообще будет выглядеть?
Может, так передумаю.
Так.
Тоже, может, немножко лучше, там, понятнее, будет происходя
чем е.
Значит, ладно?
Ой.
Так.
Хотя, честно, так.
Так.
Ладно.
Ладно.
Попишем код на доске.
Хотя, конечно, могли быть линии, за которые, честно.
Вот.
Ну, я знаю.
Не-не-не.
Зачем?
Да мы тогда не будем все описать.
Нет.
Только, кстати.
Нет.
Я тоже буду писать с нуля, если что.
Нет.
Ладно.
Просто вопрос как бы как?
Как я это буду писать?
Я это буду писать по телевизору?
Нет.
Лучше на доске.
Да.
Но лучше на доске, потому что картинка интереснее.
А есть какой-то онлайн-компилятор, который позволяет, типа,
что-то на своих мониторах видеть, или что-то еще.
Что?
Чего еще?
Есть какой-то онлайн-компилятор, который позволяет другим
включаться.
Ага.
Онлайн-компилятор называется зум шерингом экрана.
Мне кажется.
Ну, там, может, прям текстом все работает.
Ну, так.
Не, ну ладно.
Ну, не важно.
Нет, на самом деле, ладно.
На доске тоже хорошо, потому что можно это, писать строчки,
это разными материнами, там, вот это все.
Значит, смотри.
Что мы будем делать?
Итак, struct.
Ну, я не знаю.
Сейчас будет у нас это.
Super stack.
Как там это?
Ага.
Ну вот.
Ну вот.
Ладно.
Давайте так.
For.
Ну, давайте так.
Напишем.
For stack.
Пьюер.
Можно вопрос?
А.
Это код на плюсах будет или всем такой же?
Ну.
Попробуем пример на плюсах, но там.
Спасибо.
Точную компилируемость не гарантируем.
Хотя скорее всего.
Ну вот.
Ну как минимум из этого ладова.
Как минимум из того, что мы сейчас поверим в мистическую
структуру данных stack.
В общем, stack как просто абсолютную черную ящик,
который нам дает топ, поп, там.
То топ, поп и там вот эти вот цепи.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Но вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
они в этом месте вполне могли по памяти сэкономить
так они для этого и выбрали красно-черное дерево, чтобы по памяти сэкономить
да, но следующий элемент вам все равно придется искать
красно-черное дерево выбиралось по памяти сэкономить
потому что в ВВЛ дерево для вам пришлось бы в каждой вершине еще хранить переменную
которая хранится, сколько там чисел в под дереве
это вот в ВВЛ важно
то есть лишние 4 байта памяти
поэтому красно-черное дерево сделали для того, чтобы этого не надо было хранить
там надо было хранить только один бит, который записывается в лишний бит в указатель прицепа
поэтому согласно этой концепции, скорее всего, подобного не будет
поэтому скорее всего...
то есть понятно, что там фишка в том, что если вы прибежите с отбеги на дареты, то амортизировано это будет за ОАТЭ
потому что вы по сути ДФСом дерева обойдете
ну вот, конкретные плюс-плюс и минус-минус могут работать за реальностью
и то там отдельная песня, что для вершины еще придется родителей там всяких хранить
так что там вопрос еще как-то реализованный
но в этом смысле надеяться на STL сложно
но с другой стороны, может оказаться так, что конкретно вам те фишки, которые предлагает STL наоборот не надо, а вам нужны другие
и тогда оказывается, что структуру данных можно реализовать там более эффективно
то есть структури просто более под ваши нужды
то есть стрей в этом месте не очень настраиваем
поэтому иногда, тем не менее, несмотря на наличие STD-стринга
соответственно, когда компании идут на то, чтобы записать свои версии структуры данных под свои нужды
то есть там, по-моему, более этого помимо строти, на самом деле в Янтарсе еще STL есть
тоже еще одна разновидность строки, но я там уже не помню деталей зачем
но смысл есть
вот, так что вот, T-Spring
T-Spring 2
ну вот еще один тип строки в Яндекс
ну я не помню зачем, но вот так
нам у нас еще не нужна очередь операции
чего нужна?
очередь операции, которую мы должны сделать
режимикой, конечно
нет, не нужно
нет, смотрите, не нужно
нам достаточно знать, на какой мы фазе находимся
потому что у нас есть 3 фазы
перекопирование из R-S
перекопирование из L-V
или перекопирование из S-V
понятно, да?
вот, значит, смотрите
значит, пишечка
теперь такая, ну вот
так, вроде пока лучше ничего не надо, то есть еще допишем
я тут тоже
ну вот, теперь, значит, пишем
так, даже некой нот
давайте так
что-то еще надо писать
значит, ну
теперь пишем так
так, вот давайте
начнем с push, да?
значит, void
push
ну, допустим
там
t-element
x
нет, t-element плохо
t-element
t-element
вот так
ну, мы добавляем t-element, кстати
но я специально избегаю
тентов, чтобы мы не цеплялись, понятно?
то есть, от этого мы сейчас обстрадились
там был шаблон написан
так, ну, поехали
значит, по сути
теперь будем говорить следующее
значит, говорит так, что
если у нас не
режим перекопирования
если не перекопии
то мы
просто говорим
значит, мы просто говорим, что в stack l
мы добавляем
вот этот элемент
и говорим
что если
если оказалось, что l.size
внимание
если оказался строго больше, чем r.size
то, соответственно, мы неожиданно
начинаем кричать, алярма, алярма
в лице
recopy
равно true
алярма
значит, face
будет равно
id
вот
значит, далее
значит, далее
call pop пишем
а, ну, call pop
обязательно равен нужным, конечно
так
еще мы там еще пишем
а, ну, и x можно написать
равно r.stack
хотя, на самом деле, не обязательно абсолютно
и, конечно, уже здесь
make
теперь
теперь
делаем такую функцию, как
make recopy steps
внимание, да
я вложу на будущее новый метод
который будет
получать
на вход какую-то переменную
и делать шаги перекопирования
а
в плане
и в recopy
то как раз
попасть где
в смысле
не понял
если бы у нас было recopy 1
то мы бы все равно делали его
перед теми
а чем у нас сейчас recopy как раз
сейчас recopy
нет у нас
а, в смысле потом
не-не-не-не, потом не надо
потому что если у нас прямо сейчас recopy
понимаете, то эти операции
надо посчитать
вот
так
ну, давайте так
так, ладно, я не умею так быстро
ответить на этот вопрос, просто давайте лучше
не будем так это сразу
бежать и оптимизировать, давайте тут сразу
что-то где-то учтем
что?
make recop
потому что мы делаем три шага перекопирования
а может четыре хотели
пожалуйста
сделать его и тут, то уже
нас хватило три, потому что у нас есть 3 и плюс 1
вот
так, соответственно
мы же не должны проверить
то, что у нас сейчас recopy
нет
если не recopy
нет, видите, если не recopy, то теперь он
true и можно уже первые три шага сделать
вот, это у нас будет перемен
мы это чуть позже реализуем
так, теперь давайте
то есть просто говорим, что вот это шаги-шаги
перекопирования делается
вот, в противном
случае
а, ну
в противном случае мы больше ничего не делаем
просто сделали push, если у Эли
все еще больше леврабдальмента, значит все в порядке
никто ничего не делает
то есть по
поэтому
все запишется
на вот эту тифу
то есть в противном случае
то есть
если recopy есть
то, что мы делаем?
то, ну
да, отличие по большому счету только
мы пихаем элемент
просто stack
edge-tripper, обратите внимание
просто push
и
make a copy step
yeah
make a copy step
yeah
тоже давайте
3, можно 4, 3
да
вы уже выяснили, что хватит
ну, как бы
если вам не хватит, пихайте 57
и не парить
так, ну а на самом деле
хотя я вот так
ну на самом деле пихайте 57, потому что он
там
там написано
две строчки, первая строчка
edge-tripper
это не
edge-tripper, точка push
от элемента
и второе
вторая строчка
make a copy step
все
дальше там все, две фигурные скобки
и push заготь
и push на этом
то есть обратите, вы видите, мы так
абстрагируемся, то есть
единственная вот наша деталь будет сейчас
когда мы будем реализовывать
поп
давайте я вот сейчас аккуратненько
вот так писать
так, попробую поп уже
так, теперь
а, ну нам
правда теперь нужен не
да, нам нужен теперь не
поп, а соответственно
front
ну давайте вот для простоты напишем
t-element
так, внимание
t-element front
ну давайте вот там не ссылку будет
возвращать
в чем дело? то, в первых, как всегда
если у нас нере копия
то что мы делаем?
из эра просто
да, совершенно верно, это называется
return nr
.top
все, да, front обратите внимание
сам по себе ничего не делает, но при этом
модификатор const мы тут
не ставим, потому что структура внутри
себя, ой как меняется
что такое модификатор const?
а, не проходили еще?
да, ты можешь в класс поставить
что бы гарантировать, что бы...
так, давайте не будем сейчас
если не знаете, то лучше пока и не узнавайте
это пока не будет
вот именно поэтому
давайте не будем это копать
понятно, что
кто-то знает, мы можем сейчас бесконечно долго
на эту тему говорить, но лучше
в свое время лучше сначала следуя на эту тему
поговорить
так вот, если рекопии, то просто
это точка копии
а вот если рекопии
ну что делать?
что делать?
ну как мы уже с вами
выяснили
если оказалось
что call poop
значит
call poop оказался
ну допустим
чем он оказался?
не, не больше
не, если call poop все
меньше, либо равен s.size
ну
меньше, меньше
чего, чего, чего?
да, мы же берем типа на
не скажи меньше
пока именно меньше, либо равно
если он равен, то мы все и засветли
нет, если равен, то значит
а, ну то есть все эти удалили
да, согласен, хорошо, говори
если call poop оказался меньше, либо равен
меньше
нет, меньше, либо равен
это фронт и не call
хотя
не важно, мы тут тоже
эти рекопии можем вставить
так, так
ну давай так, ладно
я хочу сравнить
так, давайте я скажу идею
если call poop
с.size
что-то там
то мы хотим вернуть
тоже
add.pop
add, а вот тут начинается
мистическая функция
return
n.for
s, во-первых
.top
от call poop
допустим call poop
плюс первого элемента
давайте с единицей будем
вот
то есть
вот, то есть нам нужен
call poop плюс первый элемент
ну соответственно он либо находится сейчас
в s-ке
либо нот
ну вот, либо нот
ну и соответственно для того чтобы находился в s-ке
надо написать так
нет, это мы r-то берем
если m тоже будет больше или равно
да, да, да
окей
вот, если
у нас пока волнует
только вот это вот
что мы и не умеем
ну и конечно не стоит забывать
раз уж у нас рекопия, хотя в принципе это не обязательно
честно скажу
по большому счету
то есть в принципе можно на этом закончить
на самом деле
ну да, то есть
здесь не надо
здесь
не надо
вот
ну в принципе да
давайте так и скажем
давайте лучше вот
да, то есть топ 1
это значит верни первый элемент
давайте иногда
удобно выйти в первых этапах
ой, как там 90-е
года по гарнистам советовали
когда общаетесь с девушкой, ни в коем случае не говорите
ты у меня нулевая
не указывайся елозой бинпоэстом
начинай с печени
нулевая
начинай бинпоэст с 18
так вот
значит далее
хорошо, и смотрите
это фронт
так
значит это болты эвера
теперь
а теперь давайте делать пуп
значит пойдем сразу
в пуп и
будем смотреть
ну и здесь, значит внимание
так
значит
смотрите, о, а вот тут
начинается копипаста
потому что
если не в копии
то что
происходит
ну понятно
что во-первых в R
значит
из R мы этот элемент торжественно
добавляем
он там
заведомо есть
потому что размер R не меньше
чем размер L
единственное что может быть
это оба они пустые, тогда очередь пустая
там ладно, так что
заниматься этими сериями
олярными с эксепшнами мы сейчас не будем
так же это R.пуп
и неожиданно выясняется
что если оказалось
что L.size
больше
чем R.size, а после этого
тоже так могло произойти случайно
то
ну я переписывать не буду
вот этот блок
торжественно
целиком сюда
помещается
чисто по-хорошему
если бы я сейчас
кодил по телевизору
то я бы это все выкопистил функцию
старт или копия
но делают буквально
то же самое
понимаете, да?
ну а теперь самое интересное
значит L.size
а вот теперь начинается внимание
самое интересное
а нет, не самое интересное
не здесь самое интересное
а callpop
должно нас остановить
callpop
смотрите
пока у нас не происходит рекопия
callpop2x вообще значения
не имеет
вот когда мы
делаем
так и что
да
callpop
оно говорит сколько произошло попов
после того как вырубился режим
этот мы не считаем
вот
и то как бы без целей
на будущем нам понадобится только Facebook
но вы вообще уже можете увидеть
что сам по себе этот X нам не особо понадобится
его уже можно выпиливать
мы пока не будем
в противном случае
что делать если рекопия
уже идет
callpop++
так
но не совсем
не совсем
смотрите, во-первых
plus plus callpop
а во-вторых нам, напоминая, надо проверить
что этот элемент случайно не находится
или он уже в R
поэтому и говорим, что если оказалось
что S.size
меньше чем callpop
то тогда что мы делаем
правильно
тогда мы из R
реально делаем
и конечно же
не забываем про make
recopy steps
да
вот тут
да, тут у меня немножко сдвиг
L
относится вот к этому внешнему
ИФу
нам
после этого
ИФа нужно
сделать callpop
сейчас у нас может быть такое
что у нас как раз
S.size станет меньше
чем callpop
а, нет
вот тут важно
именно то, что нам нужен callpop
именно актуальность
с учетом именно этого callpop
потому что, по сути, callpop
символизирует, сколько элементов
было ударено
а S.size там говорит, сколько элементов
еще не перефиксировано
то есть, если их перекопировано
меньше либо равно callpop
значит, этот элемент еще рано ударяется
вот, и make recopy steps
так, тут закончили
и вот тут, соответственно, то же
сейчас, а у нас не может быть такого, что в R нет элемента?
что?
у нас вот на вот этом шаге
может быть такого, что в R нет элемента?
допустим, элементы лежат в L'
элементы лежат
в L'?
нет
этого не может произойти
вот почему, смотрите внимательно
важный момент, спасибо, Рус, значит, смотрите
идея тут заключается в следующем
когда мы стартовали recopy
у нас в L' было
x плюс один элемент
и в R' x
это важно
то есть, получается, к тому моменту
когда мы сделаем
x раз pop отсюда
мы уже сделаем
3x плюс 3 операции
перекопирования
это даже чуть больше, чем достаточно
для того, чтобы
провести вот эти все операции
допустим, у нас на каком-то pop'е
в R не оказалось
элемента
вот именно мы уже все перенесли
нет, ну, смотрите
нет, убеждение такое
промежуточное
когда не west
ну, не совсем, смотрите
если не west, то мы поймаем
не, просто смотрите
на самом деле, то есть, идеально в каждый момент времени
если бы там, типа, ничего не удаляли
вот если бы там просто
то есть, если бы у нас было
все честно, то у нас были бы
все элементы из R
вот эти x элементы мы бы перегнали в west
а потом бы вернули обратно
и тогда
тогда каждый элемент должен
находиться в north
как-то даже
объяснить не знаю
вот мы делаем pop'ы
и вот, допустим, мы перекинули все элементы из R в west
ну
перекинули
мы перекинули, никого не удаляли, pop'ы равен 0
не, не, так
не, стоп, стоп, стоп
pop'ы
нет, мы перекидывали
потому что у нас были все
допустим, у нас в левом x плюс 1
а в правом x
и мы вот после этого момента начинаем делать
постоянно pop'ы
да, ну, теперь, смотрите
ну, тут, смотрите, во-первых, тут
начинаем без того, что R
перегоняем в west
и мы сейчас pop'ы опустим
и
у нас на каком-то pop'е
на каком-то pop'е
у нас V закончились элементы
и при этом количество pop'ов уже больше
чем элементов
в west сейчас может быть такое
не может, в левом x по 3 за раз
мы один D и вместе V
не, ну ладно, тут может быть подлянка
что это в самом
в самом начале
в самом начале уже L в R лежит, нет?
нет, смотрите, в самом начале
вообще так, основная идея
была в том, что тут элементы
при копировании R пополняются быстрее
чем происходит pop'ы
вопрос только в самом первом, потому что
когда мы только начинаем эту фазу
у нас может быть... так
хотя нет, все нормально
в самом начале вообще
у нас в R лежит 3 штуки
нет, в самом начале
в R лежит 3 штуки
мы и позаботились об этом
если бы там было 0, ничего страшного
мы просто сделали pop отсюда
и потом начали бы при копировании
с этого элемента, так что тоже кайф
да, как-то да
все оказывается еще надежнее
но теперь остается только реализовать
recopy steps
собственно, да?
как это будет выглядеть?
ну давайте начнем с void
make recopy steps
ну ее реализовать очень просто как раз
циклы пропижаться
и выводить аккорды
совершенно верно
и говорим while
я такие вещи пишу
while k-минус
make recopy steps
все
все, видите?
очень простой
третий шаг
а теперь начинайте
самое интересное
как же этот мистический шаг сделать?
так, тут скажем
вызвать предыдущую функцию с параметром 1
было бы неплохо, конечно
да, но мы не будем это делать
потому что мы не
мы, видимо, сначала фазу пробираем
но пока R не достойно
ну давайте проверяем
значит, теперь, смотрите
ну здесь можно реализовать так
я предлагаю так
ну понятно, что пробираемся, естественно, по фазе
значит, если
phase равно
1, ну допустим 1
хотя тоже вы познакомитесь с енамами
хорошо, что мы плохо писали магические константы
но...
то есть надо было ввести енам
и будут фазы R to S
L to R, S to R
а нереально по Define
не надо
ну не знаю, Define
я вообще никогда не пользуюсь Define
а то и по
подключишь файл, а там Define
а в будущем, видимо,
будет бана зарянула
в будущем не будет банов, если вот так писать
фаза равно 1?
ну подумай, может и будет
в будущем, когда у вас только появятся енамы
то... ну ладно, либо это
либо даже когда они не появятся, мы скажем
а вы изучите, что такое енам
да, но пока
итак, если фаза 1
то, значит, смотрите
тут я сделаю следующий чип
смотрите
значит, внимание
внимание, значит
говори, значит, мы должны скопировать
значит, не говори
если не R
точка
если R еще не пустой
ну, на всем
я вот так аккуратно напишу, хотя можно играть
если R не пустой
то, соответственно, понятно
S.push
соответственно от R.top
R.push
и внимание
return
lz, внимание
я пишу
phase равно 2
видите, да?
то есть у нас два варианта
либо мы на первой фазе
и нам есть что копировать из R.west
и мы тогда копируем и выбрасываемся
а это не конец всей функции
это конец только и факт
потому что дальше я пишу
и phase равно 2
а мы не хотим
а мы не хотим lz
ну, я не знаю
мы не хотим ли lz
нет, вот и прикол
что не хотим
нам важно, чтобы мы после этого
нам важно, чтобы мы после этого
и фаза могли переключиться в вторую фазу
и пойти ее делать
все равно делать make recovery step
понимаете, подлянка
мы если тут вот R был пустой
и фаза работала 1
то мы по факту этот шаг не сделаем
потому что шаг для нас это перемещение элементов из стека
я не хочу вот этот лишний шаг
то есть можно, конечно, его сделать
и увеличить тройбан там на 57
но как-то хочется поэкономнее
что ли
итак, фаза 2
ну, в общем-то
практически копипаста
значит, смотрите
дальше происходит следующее
то есть я тут пишу
если не l.empty
если не l.empty
то в чем идея
то, соответственно, да
что-то там l.push
что там
от l.no
от l.no
от l.o
от l.o
от l.o
от l.o
выбросится
ну вот
и л.l.s
фейз равно 3
и наконец
самое интересное
но теперь, в общем-то, фейз равно 3
я напишу примерно то же самое
Так, давайте, так, где бы мне это сделать, так.
А может свопнули, или что?
Пока не свопнули.
Удачи, смотрите.
Так, ой, на самом деле мы еще кое-что забыли.
Да, на самом деле мы еще кое-что забыли.
Так, это если вот у нас, да, делаем recopy step.
Да, по-хорошему, ладно, на будущее тут придется, возможно, вставить, что a recopy вообще живой или нет.
А то могло так случиться, что мы делаем лишние шаги пока нота, а уже не надо.
Ну, это первая точка, их не легко греть.
Хорошо, в...
А разница?
Ну, да везде можно проверить.
Можно просто вот в том вайке добавить еще, что...
Да, можно написать хоть в фейс равно 4, это мы тоже сделаем.
Ну ладно, давайте, идем.
Давайте по фазам, да.
Итак, если равно 3, то что мы делаем?
Так, t элемент, допустим, e, равен s точка top.
И соответственно s точка pop.
Ну и теперь говорим, если после этого оказалось, что col pop, то есть все удаленные элементы, все еще, то есть col pop они все еще в esc,
то тогда этот элемент мы...
А, ну да.
То мы тогда в этот элемент записываем.
В противном случае, естественно, нет.
Вот, понятно, да?
Да, но мы, естественно, поторопились это все писать.
Да, меньше либо равно.
Потому что надо было задать вопрос, а s случайно не пустой там?
Ой.
Да.
А иначе mbs?
Да, поэтому, значит, придется это все сдвинуть.
Если s точка empty, а если col pop?
Да, col pop.
Нет, пока просто смотрите.
Если оказалось, что s точка empty, то, в общем-то, на этом все с вами были подписаны.
То есть, если мы на фазе 3 и s точка empty, то остается только сказать, фейс равно 4.
Да, а, что там нам начало?
А, посвапать l и l4.
Их помните, да?
Почему?
Да.
Мы это будем называть l точка свап от l4, чтобы почеркнуть, что вызывается именно внутренний метод, который умеет отзывать и делиться свапами.
Разве надо?
Ну, как сказать?
Сейчас, сейчас.
А где внутренний метод?
Ну, где внутренний метод?
Ну, я не могу гарантировать, что там по всей исторической структуре общий шамлонный свап перегружен.
А такой свап существует?
Если что, то такой метод, тот, что существует, еще до появления муссиматики.
Там, по-моему, написано на cpp.reference, что свап от двух параметров вызывает первую точку свапа от второго.
Ну, он просто думает или делает именно так?
Нет, как сказать?
Нет, общий, нет, общий свап такой.
Вообще, по-моему, это вот просто такая обертка, по-моему.
Ну, я не знаю, откуда будет метод свап вымта, потому что у этапа, в принципе, метода быть не может.
Ну, скорее всего, определен свап для базовых типов, а потом определен свап.
Ну, я не знаю, я вообще подозреваю, что там по идее свапи должно быть написано там t равно с tdmove от a,
a равно с tdmove от b, b равно с tdmove от t.
Вообще, должно быть так написано.
А, ну и все, и мы тоже здесь с джестом выбрали.
Фейс четвертая, что надежда.
А фейс четвертая, это просто говорить о том...
Ой, реклопер равно false, конечно.
Так, recopy равно false.
Нет, а face равно 4 будет, знаете, что делать?
Оно просто будет говорить, что ни одно из этих крипов не сработало,
поэтому make recopy false не сработало вообще.
То есть это будет означать, что recopy false и ничего делать не надо.
Ну, можно было с этим выпроситься прямо сразу, эту проверку сделать, но вот...
Да, можно тут написать вот эту вставочку.
Если вообще me recopy, то обошли мы отсюда.
А так мы же можем просто выставить файлика, в файле можно просто делать...
Не, но я имею в виду смысл make recopy steps, потому что, знаете, это неправильно делать make recopy steps, по каким причинам?
Потому что, может быть, в будущем вы когда-нибудь здесь захотите использовать make recopy step как независимую функцию.
Вот, и тогда как бы вспоминать, что там проверка recopy проверялась где-то в другом месте, это как бы вот плохо.
То есть как бы это надежнее с точки зрения варианта.
Чего?
Чего меньше либо равно? Где?
Вот здесь?
Вот здесь, да?
Ну, потому что, смотрите, принцип такой, что у нас в S находятся несколько последних еще не перекопированных элементов.
А call-pop это сколько элементов вот спереди должно быть удавено?
Вот.
Или...
Сейчас.
Хотя...
Нет, не совсем, не совсем.
Вот.
Нет, ну просто оказалось, смотрите, вот вы сделали плюс плюс call-pop, да?
Теперь думаем, если выяснилось, что оказывается ты седьмой уже элемент, который надо удалить, и у вас в стеке S находятся семь элементов.
То есть тогда это означает, что как бы этот элемент не надо удалять из зера, потому что он находится здесь.
Вот.
Поэтому при равенстве ничего делать не надо.
Если бы этот элемент стал восьмым уже, а тут семь, то значит тогда этот восьмой элемент в R находится, или какой он там, и его точно надо удалить.
Ну просто R.
Вот так.
Так вот, значит, и так, значит, S, M все разобрали, а если он не пустой, то вот тут мы уже и начинаем писать, вот это переписываю заново.
T элемент E равно S точно pop, S точно pop, и теперь говорим, что если после этого, значит, да, мы достали этот элемент, и теперь надо выяснить, что если оказалось, что call-pop меньше либо равен текущего размера S,
то есть там в S еще находятся все элементы, которые надо удалять, то тогда мы меньше просто, нет, меньше либо равно.
Потому что, видите, потому что у нас только что размер S уменьшился.
Вот.
То есть пишем R.pushedE.
Вот.
И соответственно тоже, так, вот давайте, так вот.
Вот так.
Так.
Ну и все.
И тут, конечно, давайте тоже в любом случае выбросимся на всякий случай.
Почему S, если R, да?
Вот так.
А, ну и все.
То есть как бы, если фейзером будет 4, значит, просто реклопер уже закончился.
Ну как бы, тут вот так.
Можно, знаете, в таких случаях, говорят, что если до этого места программа она вообще не должна находить,
можно написать тоже просто там assert false или там написать какой-нибудь exception, типа алия, я еще тоже.
Мы дошли до сюда, а такого не было, не должно быть.
Вот.
Так что вот таким вот образом мог бы, могла бы выглядеть наша это, мистическая очередь на четырех стеках.
Если бы из стека S мы могли бы доставать этот элемент.
Вот.
То есть, да.
Почему уменьшить call pop?
Call pop мы...
Так, ну...
Не, я просто сейчас...
Не, я просто не очень понимаю, почему мы его должны уменьшать.
Я для тебя родил 10 раз, проговорил о формальном определении, с которого следует, конечно, не доложить.
Значит еще раз, формальное определение call pop.
Как бы, сколько раз был вызван pop в глобальной очереди после объявления или popping?
Все, вот что дает call pop.
Поэтому, конечно, мы его уменьшать не должны.
Ни с каким стеком S он не следует.
Я не знаю, почему так хочется мыслить, что действительно удаление из S уменьшили call pop.
Удаление из S уменьшили call pop.
Я, честно говоря, я сейчас даже просто не понимаю, почему у вас всех так мало.
Почему-то в эту сторону мозг поваляется.
Ну, одно нет.
Давай.
Что?
Петличку включите, пожалуйста.
Чего?
Не обнажать.
Не, по-другим по...
Ой, боже.
Так, я не знаю.
А, только я не слышал было, да?
Да.
А в прошлом году...
Я не слышал.
А, на записи?
Нет.
Ну, я не знаю.
А там она прям принципиально туда...
Нет, можно надеяться, что я говорил достаточно громко, чтобы было слышно хоть как-то, но вот...
Нет, просто с прошлогодними лекциями просто есть такая проблема.
Я их вчера на YouTube не нашел.
Вот.
Вот.
Почему-то там по умолчанию сейчас в лектории ФПМИ находятся только те лекции, которые
записываются в этом году.
Там, собственно, это как бы...
Почему не знаю, но вот...
То есть свою там я только одну...
Свою там я только почему-то какую-то там одну первую когда-то нашел.
А, да-да, ну окей.
Ну, может быть, хорошо, да-да-да.
Ну, тогда их просто искать будет сильно сложнее.
Вот.
Так что вот.
Так, господи, надо же.
Ну, ладно.
Так вот.
Вот так бы это выглядит.
Вот примерно вот такая у нас технология, да.
А мы прикрутим к этому персистентность?
Вот.
Ну, разве что в самом конце это у нее если успеем.
Ну, то есть продолжение...
Нет, то есть персистентность из цикла, что мы это все делаем так, чтобы персистентность
понятно как прикручивается.
Это как бы просто...
То есть это уже мелочь.
То есть даже вот в персистентности, если мы какие-то элементы для...
Для одной версии перебросили, то для другой версии мы тоже должны их перебросить, да?
Ну, да.
Каждой версии будем по чуть-чуть их перебрасывать.
Да.
Нет, ну просто смотрите.
Просто...
Нет, там понимаете как это будет устроено?
Просто отличие персистентной будет такой.
То есть будет такая же структура, только понятно в роли этого стека будет версия
там, версия персистентного стека.
И вместо вот этих воидов, сейчас вот скажу только,
и вместо вот этих воидов будет возвращаться новая версия.
То есть по факту мы там сделаем копию себя, в ней вот проделаем там вот эти вот все операции
и вернем вот это.
Только в этом будет разница.
Вот.
Или, может, скорее будет так.
Можно даже сделать так.
Все эти методы будут объявлены приватными.
Все эти методы будут объявлены приватными.
Там с нижним подчеркиванием.
А по факту всякие пуши, фронты и так далее будут, соответственно, оберточкой.
Что нам дают приватные?
Ну, что в них никто кроме нас не влезет.
Так, а вы еще не знаете, что такое приватные?
Нет.
Господи, вы чем там на C++ занимаетесь уже третью неделю?
Господи, ну ладно.
Оригинально, да, да, да.
А.
Ну хотя да.
Понятно.
Ну ладно.
Ну окей, окей.
Ладно.
Ладно, Илья строит курс как-то по-другому.
Поэтому окей.
Ладно, неважно.
Крывается.
Геркин.
Много раз мы все еще не научились брать, правда?
Правильно.
Нет, абсолютно верно, да.
Поэтому я не случайно обвел это в рамочку, да.
Потому что пока у нас этот код весь базируется на то,
что почему-то со stackMS мы это умеем делать.
Поэтому сейчас мы будем пытаться, значит, эту досадную оплошность поправить.
А почему мы делаем make recap steps 3, а не не больше, не меньше?
Ну сразу же так, больше можно, меньше не-не.
Потому что, как мы уже сказали, нам нужно 3x плюс 1 step на то, чтобы сделать вот эту всю эту перегонку.
И у нас на это есть, значит, наша текущая операция, где вот recopy стартовала.
И еще x следующих операций.
Ну потому что это до того, как там вот этот вот элемент, который вот тут на дне лежал, может понадобиться.
Поэтому мы сказали, что так, у нас по факту вот мы x плюс 1 раз вызываем make recap steps,
поэтому получается тройка, это минимум, которого нам хватит.
Вот.
Да, вот у нас такая проблема возникла.
Как же ее мы будем решать?
Ну, собственно, именно поэтому у нас очередь о 6 stack, а не о 3x.
А как же мы будем решать?
Ну, собственно, именно поэтому у нас очередь о 6 stack, а не о 3x.
А как же мы будем решать?
Ну, собственно, именно потому что у нас очередь о 6 stack, а не о 4x.
Потому что...
Вот, ну к черту.
Вот, 4x, да, да, да.
Знаешь, смотрите.
Акция была хорошо.
Итак, значит, ладно, давайте так, до этого момента все понятно?
Да.
Ну, по модулю того, что мы так и не научились.
Вот сейчас будем учиться.
Не будет.
Но, точнее, будет, но вектор амортизированная структура данных.
А у нас как раз цель избавиться от амортизации.
Так-то мы бы уже на двух stack'ах все там, я думаю, вот в этой полосе все уместилось.
Так что в том тыру...
Да, в том тыру будет и смысл, да.
Нет, так-то...
Ладно, так вот, внимание.
Так вот, теперь новинка.
Значит, внимание, исходную концепцию мы чуть-чуть поменяем.
Мы говорили, что в нормальном режиме у нас элементы кладутся в L и достаются из R.
И мы можем в этом режиме внести амортизацию.
Мы говорили, что в нормальном режиме у нас элементы кладутся в L и достаются из R.
Так вот, ребята, теперь это не так.
Не свисти!
Денег не будет, примета такая.
Вот.
Значит, у нас мы введем новый stack.
R, C.
Ой, точно, а мы же еще...
R, C.
Что это такое?
Так вот.
Так, значит, сейчас я напишу нормальное состояние.
Значит, нормальное состояние.
Это когда?
Ну, по крайней мере, поначалу.
Сейчас мы тоже постепенно решим проблемы, как это называется.
Так что смотрите.
Постепенно решим проблемы.
Смотрите.
Постепенно мы их будем решать так.
Значит, L' пустое.
S пустое.
И в L находятся что-то чуть-чуть элементов.
8, 13, 22, 9.
И в R находятся элементы буквально чуть-чуть побольше.
Очень сильно.
Так.
3, 8, 5, 13, 179, 57, 2.
1, 4.
Нет.
Почему?
R не видно?
Так, ладно, давайте.
R.
И он будет называться R, C.
Вот C теперь даже лучше видно.
Почему?
Потом C от слова копия.
Да, совершенно верно.
В нем будут абсолютно те же элементы, что и в R.
Это логичная идея.
5, 13, 179, 57, 2, 1, 4.
То же самое, да?
Абсолютно.
Значит, теперь магия такая.
То есть идея будет в том, что на всякий случай.
То есть для того, чтобы...
Смотрите, то есть мы храним копию.
То есть пока все нормально, мы будем доставать элемент прямо из двух копий.
То есть отличие будет такое.
То есть в пуше...
Нет, ладно, в пуше это все в порядке.
А вот в функции pop, соответственно...
То есть если или копии нет, то я вот здесь приписываю.
Обратите внимание.
R, C.pop.
Вот видите, я красненьким помечаю, что поменялось.
Вот.
Удобно, да?
Удобно, да?
Видите, да?
Видите?
Чего-чего?
А вот смотрите, не совсем.
Потому что отличие начинается в режиме перекопирования.
Потому что фишка в том, что...
Смотрите, мы сейчас будем заниматься следующим.
Да, мы будем перекладывать элементы из R, значит вот тоже будем перекладывать.
Но параллельно у нас будет еще и актуальная версия стека в R, C.
Ну не актуальная, а вот типа то, что там осталось.
Это нужно нам для того, чтобы мы делали адекватный pop.
Адекватный...
Адекватный фронт.
Вот.
То есть обратите внимание.
Вот.
Ну вот давайте попробуем подумать, как это можно сделать.
Ну да, то есть смотрите, то есть pop в нормальном режиме, да, то есть все тривиально.
Но теперь...
Ну что тогда теперь должно поменяться?
Ну должно поменяться, наверное...
Ну вот, ну в передах.
Ну кажется, что в перекопировании что-то может поменяться.
Но тут теперь задумаемся вот о чем.
Да, вот на уровне идеи мы себе представим, что мы занимаемся перекопированием,
вот тут созданием, вот из, там, R, и R перекидывается в S,
значит, ну там, R перекидывается в S, значит, L перекидывается в R,
S перекидывается в R, и параллельно мы там лишние элементы в R не кладем, да.
Но при этом у нас пока происходит рекопия, вот эта R, C остается на посту,
с R, C мы ничего не делаем, и как бы фронты и, соответственно, pop мы, соответственно, делаем актуально с R, C.
То есть примерно, смотрите, что поменяется?
То есть, ну, соответственно, ну здесь, понятно, ничего не поменяется,
значит, но, значит, во фронте теперь, то есть это даст нам возможность вместо,
ой, не то, не тем зачеркиваю, вместо вот этого вот, я теперь пишу,
Реатурн, R, C, точка, фронт. Вот.
Вот.
Вот. Ну, правда, да, придется, да. Ну, правда, возможно, да, придется еще допиливать, конечно, но сейчас будем смотреть.
Что-что?
У нас даже, когда есть рекопия, придется R, C, D, pop делать.
Чего? Где рекопия, что рекопия?
В поп функции. Зелит тоже, когда нет рекопии, тогда R, C, D, pop.
Сейчас, ну мы, нет, естественно, R, C, нет, зачем?
Пока нет рекопии, как бы R, top и R, C, top это одно и то же, так что без разницы.
Тут в том-то и фишка. То есть, еще раз говорю, что фишка заключает в том, что, да, то есть R, C остается на посту,
а с R мы пока вот развлекаемся.
Вот в чем тут, собственно, теперь фишка.
Ну, если мы делали pop, то тогда, когда мы сделаем front, то нам нужно R, C, D, top, C.
Чего? Top.
Проблема, что после рекопии R, C уже не будет совпадать с R.
Да, вот, да, действительно. Видите, основная проблема, да.
То есть, пока мы, конечно, живем, и на время рекопии нам этого хватит.
А потом что делать?
Но, но, действительно, в азинке это только действительно маленькая проблема, что в самом конце у нас, конечно,
состояние этой штуки вообще, то есть, состояние R, состояние R, C совпадать не будут.
Поэтому, с этой целью, вот и получается шестой стег.
R, C штрих.
Чего?
Так, чего?
Вопрос.
Ну, смотрите, дело в том, что когда мы закончим режим перекопирования, у нас должен будет соблюдаться инвариант,
что в R и R, C должны быть одинаковые состояния стека.
А в процессе рекопии мы это явно нарушали.
Вот.
Хотя, хотя, погодите, а насколько явно мы его нарушали?
Ведь обратите внимание на маленькую приятную вещь.
А, нет.
Когда мы в R, C вообще делаем пуши?
Ага, а вот мы еще рекопии, потому что не модифицировали.
Потому что по факту, вот в этом месте, а теперь, вот по хорошему, здесь мы должны вот в это R, C как раз пуши и делать.
То есть, мы достаем из R, а потом как бы и да.
Но, правда, здесь проблема будет, что пуши мы будем делать здесь, значит, не только в R, но и одновременно в R, C, но, внимание, штрих.
Кажется, во втором шаге тоже.
Чего?
Кажется, во втором шаге тоже.
Да.
Во втором шаге мы тоже будем делать.
Да, кстати, да, да, да.
Вот, R, C, штрих.
Да.
Он неправильно работает, потому что он берет в ремере копии, он берет у нас в R, C топ.
Нет, он-то берет как раз правильно, потому что во время рекопии R, C это типа дежурная копия.
R, C поп надо сделать еще, когда мы поп делаем.
И мы делаем.
Где?
Сейчас, когда не рекопит, да.
А где рекопит?
Так, сейчас.
Ну, давайте смотреть, к чему нас это будет приводить.
Когда мы делаем рекопи?
Так, сейчас.
А, ну да.
Да, да, да.
Нет, нет, здесь надо.
Потому что...
А, ну всегда надо делать, да.
Да, да, да, да, да.
То есть, да, это спасибо, это обязательно.
R, C, точка, поп, обязательно, да.
Вот.
Вот.
Значится.
Так, хорошо, с поп-ом вроде разобрались.
Что дальше?
Что дальше?
Но надо еще думать, как эти степы делать.
Ну, давайте пишем, что на второй фазе, значит, мы торжественно пишем, что R, C штрих, точка, push, от L, точка, поп, обязательно.
Вот сюда.
Перед L, точка, поп, обязательно, да.
Видите, что еще надо делать.
Так, и по-моему еще на какой-то фазе это не помешало бы сделать, да.
Так, ну смотрите, что еще надо сделать теперь.
Надо теперь добавить в R, C, штрих.
Так, вот где тут добавляем?
А, вот этот элемент E, да, значит, col pop, S, точка, size.
А, надо его добавить в R.
А, ну здесь тоже, соответственно, если мы его добавляем в R, то мы его одновременно добавляем и в R, C, штрих.
Так.
То есть мы прям следим, что, вот. Чего?
Что повторить?
Нет, ну я сказал, что на второй и третьей фазе, да, что мы поддерживаем, мы стараемся поддерживать, когда мы из S начинаем копировать в R, мы поддерживаем, что мы это все делаем не только в R, но и в R, C, штрих.
Для того, чтобы у нас R и R, C, штрих были одинаковы.
А делаем мы это еще.
Да, еще, кстати, важно, когда у нас заканчивается вот эта рекопия, у нас еще есть очень важный момент.
Да, вот в этом месте я вставляю еще, что R, C мы свапаем с R, C, штрих.
Какой?
Так.
Ну и тогда, ну тогда, ладно, смотрите, пока для просты скажем.
Так, ну пока давайте убедимся, что это единственная проблема.
То есть давайте я сейчас скажу, после этого я скажу R, C, штрих.clear.
Вот.
Сейчас, а зачем?
Это фаза третья, да, и мы...
Да, ну, потому что, ну, смотрите, нам просто потом, потом когда-нибудь очень сильно захочется, чтобы в тот момент, когда начнется следующая рекопия, R, C, штрих было пустым.
Ну, мы же не можем сделать, это же...
Так, ну, тут вообще какая-то вопрос отчетним.
Ну, теоретически можем.
Потому что, ну, особенно если пишем персистентный стек, потому что создать новую версию пустого стека, это заодно от единицы по-любому делается.
Да, так, так, да, да, да, да, да.
Но на самом деле, смотрите, так.
Ну, по крайней мере, да, ну, давайте так, я сейчас тоже обведем в рамочку, да, то есть давайте, что?
Да, у нас теперь новая проблема.
Но это уже более такая проблема.
Ну, чтобы, да, чтобы утищей памяти не было лишним.
Да, но проблема просто в том, что нам не нравится.
Стек, он очищает, стек размера N будет очищаться за O от N все-таки.
Стоп, мы его не будем очищать.
А если мы его не будем, ну, я говорю, тогда утища памяти.
Да, нам это...
Ну, то есть там во многих моделях, конечно, алгоритмов нам по барабану, но по факту вообще мы следим за тем, чтобы лишнюю память не использовать.
Стоп, а у нас же по-любому мы с ним ничего не сможем сделать, потому что его будут использовать другие версии.
Не-не-не, ну...
А, но да.
Ну, просто скажем, что указатели нулевые становятся.
Ну вот, ну да. Ну, да, в персистентности, да, в персистентности, да, можно на это забить.
Нет, там мы по-другому ничего не сможем сделать.
Нет, ну...
Нет, ну в принципе сможем. Нет, на самом деле можно и это допилить так, чтобы проблем не было.
А давайте попробуем.
Так, правда.
Ну, в случае персистентности...
Сейчас.
Не важно ли, что можно реализовать стек как вектор, короче...
Вектор вектор, короче, как...
Вектор амортизированный, поэтому у нас запреты, такие штуктуры.
В случае персистентности,実� stronglar, там, в случае не персистентности, почему бы просто не удалять, когда оно амортизировано?
Нет, в случае не персистентности у нас остается...
В случае не персистентности у нас так становятся две цели.
Первая – чтобы все было честно завал от 1.
И вторая – чтобы лишняя память при этом использовалась нея.
Можно обмuxz reject?
Или по... Или, по крайней мере, мы стремились к этому.
Но без персистентности мы тогда можем все-таки опять закашировать, что мы должны быть удалять каждую...
Да, на самом деле пробегаться по всем элементам не надо, но я так, я уже не буду дописывать, но суть, на самом деле, в том, что в реальности можно объявить, на самом деле, четвертую фазу.
И четвертая фаза будет говорить, что уже все в порядке, просто в экс-штрихе еще лишние элементы находятся.
Но там надо понять, почему оно успеет удалиться до того момента, когда нашнется новый...
Похоже, мы больше элементов...
Нет, на самом деле, нет, я утверждаю, нет, парадокс, на самом деле, знаете, в чем?
Парадокс, на самом деле, в следующем.
Смотрите, давайте я сейчас внимательно проанализирую, потому что решение проблемы тут может быть неожиданно просто.
Давайте себе представим, что после вот этого вот, вот после того, что вот это произошло, у нас оказалось, что в rc-штрихе оказалось, допустим, к элементам.
Тогда, смотрите, заметим, что ровно, то есть означает это на самом деле следующее.
Ну потому что, потому что я утверждаю, происходит следующее.
Что на самом деле r отличается от rc-штрихи сейчас только тем, что помимо, что там находятся ровно вот эти k элементов.
И перед этим еще x плюс один элемент, который находились раньше.
Сейчас, а rc-штрих не отличается, нет, разве?
Чего еще раз?
Ага, после того, как мы свапнули, да?
Ну после, да, вот прямо сейчас, вот после того, как мы свапнули, да?
В rc-штрихе пусть находится k элемент.
Я утверждаю, что тогда в r находится x плюс один плюс k элемент.
Да.
Логично, да?
Логично.
Так, ну теперь давайте дубать.
Почему, ну вот, то есть смотрите, что произошло в этот момент?
В этот момент произошла следующая ситуация.
То есть в этот момент прошло x плюс один операции push и pop, правда?
Popов, видимо, было сколько вот этих?
К чему call pop равен сейчас?
Вот давайте так.
Call pop в этот момент равен к чему?
Ну получается, да, вот сейчас x минус k.
Ну да, x минус k, действительно.
Вот, да, x, ну вот, то есть и получилось действительно x минус k.
Значит, после включения копий, строго после, получается, у нас было k push, правда?
Да.
Так, ну хотя нет, так тут.
Теперь тогда смотрите.
Тогда раз у нас было k push, это означает, что прямо сейчас у нас в стеке l находится
k элементов.
Ну и здесь x плюс один плюс k элементов здесь.
Сейчас почему в l k элементов?
Потому что вы вычислили, что после recopy было ровно k push, а мы, как бы, a l там, когда
он был еще l 4, он заполнялся с нуля.
Вроде x минус k push.
Нет, popов было x минус k.
Да.
Почему?
Потому что есть на копе.
Да, ну да, фронты мы так аккуратно реализовали, что мы их не считаем.
А было бы еще меньше, так еще лучше.
Почему лучше?
А потому что вот что, смотрите.
Получается в эре на x плюс один элемент больше.
То есть это означает, что следующие и как минимум x плюс один шагов recopy не включится.
А, значит, можно просто спокойно...
Да.
И x плюс один, обратите внимание, что самое главное, это больше, чем k.
Даже строго больше.
Поэтому все, что на самом деле надо сделать, это просто вот если, ну вот, то есть просто
сказать, если не recopy, то можно что в push, что в pop так жественно написать простую вещь.
Написать, если не rc'.empty, то rc'.pop.
Прям в самом начале, вот если не recopy, то прямо можно даже перед l написать.
И функции pop мы обязательно это пишем, да.
Вот-вот-вот-вот, да.
Кстати, это само персистенция, это только хуже нам сделать.
Да, нам лучше просто сделать.
Нет, персистенция в принципе пока что нельзя такое сделать.
Такое можно сделать.
Нет, это нужно чтобы оно вышло.
Мы все уже сделали персистенцию.
Вот.
Ну вот так.
То есть тогда, в этом смысле, тогда как бы вот...
Персистенции можно сделать.
Тогда никаких clear'ов уже нет.
То есть мы просто...
Ну вот.
То есть на самом деле, вот простой хак, и в общем-то поздравляю, мы победили.
это это что значит еще раз пусть давайте значит и так фейс равно 3 давайте
смотреть пусть у нас произошло так что вот наконец мы объявили что конец
рекопи но при этом вот мы тут посвапали rc с rc штрих напоминаю да но
при этом в rc штрих после этого оказалось к элементов что это значит это означает
что когда было rc у нас изначально было x элементов да осталось к но после реку
вызовы рекопи после вызовы рекопи мы как бы каждый поп честно из rc делали
значит всего попов было x минус к ну как следствие пушей было к потому что
фронт мы за операцию не считаем как видите но с точки зрения марктизации то
есть пушей было к но теперь нет попов было x минус к потому что к это
количество элементов которые выжили а теперь ну как бы у нас после этого ну
когда ну как вы смотрите вот кстати да еще и к чему нас то есть к тому моменту
когда у нас рекопи закончилась да у нас уже произошло
значит произошло не менее чем x операции пуши поп правда вот то есть это но вот
вот это вот соответственно произошло кстати в этом смысле сейчас становится
хорошо почему у нас тут именно три они 57 вот и тогда происходит следующее что
раз прошло но вот что раз прошло допустим x операции скорее всего ровно x
потому что мы нам нужно сделать ровно 3 x плюс 1 операции именно через x
операции это будет достигнуто вот соответственно поэтому получается что
именно попов x минус к а пушей соответственно к но тогда это означает
но теперь смотрим куда девались эти пуши раз у нас было к пушей вот ну вот вообще
не понял вопроса что чего чего чего так ну как на фронт а ну да функции фронта
когда мы специально так реализовали что ничего не делаем ну могли бы может это
там даже ускорила бы амортизацию но в данном случае тогда как бы но в данном
случае это нарушает степенность то есть посмотрите если никуда не торопиться то
как бы у вас там получится что потом там следующая операция будет еще через долго
поэтому вот еще поправить поэтому лучше вам вот так поправить хотя в общем-то это
и неважно особо скорее всего наверно если вы 3 замените на 4 все равно нет хотя нет
если 3 замените на 4 будет плохо но там но потому что это быстрее произойдет вот здесь мы сейчас
жестко пользуемся тем что у нас как бы до конца рекопи произошло ровно их шагов то есть рекопи
будет снята ровно через их шагов мы этим жестко пользуемся вот когда утверждаем что у нас в стеке
р икс плюс один плюс к элемент а впрочем нет мы этим не здесь более неважно да в общем да да да да да
все да мы этим пользуемся тем что тогда икс плюс один откуда взялся это вот эти вот стекл просто
у нас цель была перекопировать перекопировали икс плюс один а к это те кто вот с хвоста еще остались
да да да да икс не причем да чушь наговорил окей вот такая красота получается что теперь значит
то есть это означает что после окончания этого рекопи получается что только через там не менее
чем икс плюс один операции точнее более рекопи будет вызвано в следующий раз но при этом к обратите
внимание оно не больше икса поэтому получается мы можем просто никуда не торопясь когда нет
рекопии мы знаем что то есть теперь у нас инвариант рекопии то есть теперь инвариант режима
перекопирования говорит так все стэки то есть как бы рс равны л значит заход л штрих с пусты а в
рс штрих возможно остался мусор но там гарантируется что там скажем но там как гарантируется что
размер этого мусора не превосходит размера там размеров стэков r минус l и он же память не
отчаяет отчаяет драсти нет там же capacity остается какая capacity в стэке а вектор мы
запрещаем напоминаю у стэка никаких capacity по умолчанию нет это смотря на нет смотря можно
отдельно думать на чем выразить если на векторе туда если вы выразите нормально на указателях то
никого capacity у него нет но вот поэтому тут в классическом стэке считается шинка амортизации
чего мы не можем примут идею то что что когда у нас нет рекопитом мы чистим эти ноды он может
являться для кого-то рц для кого-то просто рц штрих не вообще там а какая разница персистент
персистент а в стэке каждый топ и поп это извините замена версия тут везде должен писать вот
вместо s точка пуши должны писать там f равно s точка пуши условно мы не сумеем никак отчищать
рц штрих но очистка это мы в этой мы создаем новое но там да вариант во-первых можно так не во-первых
можно делать ровно то что написано это во-первых а во-вторых ну пожалуйста да в персистентной
версии и да проще всего дописать что рц штрих это новая пустая версия все но по-другому же
почему ну вот вот мы описали как можно по-другому почему у нас есть так рц штрих ну и что допустим
у нас там есть какие-то ноды ну если что вот для каких-то версий эти ноды будут вполне реальны
да но когда ты делаешь поп ты ничего не удаляешь да ты создаешь новую версию которая да ну да
если чтобы сделать как заключается по памяти персистент с ним и никак не сумеем сэкономить
персистент но почему нет это уже просто это уже забыли нет это уже забота другой структуры
данных это забота структуры данных персистентный стек то есть это то есть она там то есть дальше
уже персистентный секс там там будет себе там гарбыш коллектор какой-то включать вот персистентный
стек соответственно и все нормально будет так что не паникуйте вот ну да но я говорю там уже это
уже там персистентность, это уже тут без разницы. Так что вот получается такая красота, вот такая
структура данных. Если тут соответственно какие-то вопросы. Ой, как хорошо-то. О, ну вот кажется у нас
пара и прошла. А, ну почти. Ну ладно, так что думаю так. Ладно, так еще по этой структуре вопросы есть.
Ну просто дальше мы как бы будем заниматься чем-то, ну вообще с этим не связанным. В домашке? Ну не
уверен. Ну в ближайшее время точно нет, потому что, как выясняется, вы плюсов, вы плюсы для этого
не знаете. Не, ну понимаете, чтобы нормально это реализовывать, тогда надо и констру и знать,
и приваты надо знать, и шаблоны надо знать. То есть вот, чтобы совсем по-хорошему. Чего? Нет,
экзамен естественно будет. Куда ж мы денемся. Так, напоминаю, напоминаю, что у нас будет,
напоминаю, что у нас есть зачет и есть экзамен. Это независимая источность. То есть зачет это
значит за домашние задания, оценка, которую мы выставим по итогу выполнения вами домашних
заданий в семестре. Экзамен, это будет вот теоретический экзамен в вашу сессию. Это две разные
соображения. Нет, ну, соображение там следующее, что, ну, скажем так, просто, как бы, скажем так,
то есть просто, когда становится больше, это означает, что пока больше, но больше чуть-чуть, да? То есть
непосредственно перед добавлением этого элемента были, элементы были приблизительно равны. И мы
знаем, что если у нас там, скажем, х тут и х тут, то где-то за О от Х действия мы вот это вот сюда
передать можем. Это с одной стороны, а с другой стороны было важное соображение, что вот этот
элемент реально нам понадобится не раньше, чем через X операции. Поэтому получается вот такой вот
покойничная застава получилась вот такая. Так, ребят, я вопрос не слышу, давай.
Нет, ну это да. Нет, ну у нас в принципе цель, да, что по сути мы занимаемся тем же самым. Мы
перегоняем эти элементы в stack R. Только проблема возникает в том, что, как бы, мы не хотим, чтобы
было пусто-пусто-пусто и там до скончания века. То есть мы хотим, чтобы вот, условно, читать по
пять страничек в день. Вот. Или там по пять минут в день мы хотим на это тратить. Вот. Так, ну что, еще вопросы?
Вот. Так, но если вопросов нет, ладно, значит тогда пока перерыв, ну а соответственно минут через 15
мы тогда и будем говорить о сортировках. Давай. Ну и тем более как-то вот может объединить это все вместе.
Вот. Так. Значит соответственно, значит смотрите. Так, это у нас значит и так, так что краткое
содержание сегодняшнего занятия и, возможно, следующего и еще предыдущих. Вот тут еще он про
стэки тут еще. Вот. Да, это вот что такое stack, если что. Ну ладно, мы к этому там в какой-то момент
вернемся. Так, кратенько прибежимся. Так. Вот. Так, ну вот. Так что да, это было краткое содержание того,
что нас ждет. Что хотелось бы. Ну вот просто мы, ну у нас как-то вот пошло, мы немножко в другом
порядке это стали проходить. Вот. А, кстати, да, да, на тему обратизационного анализа, кстати,
обратите внимание, там у вас в домашних заданиях еще три задачи появились. Ну дедлайн, естественно,
не сегодня. Так. Дедлайн нет, по умолчанию дедлайн через две недели. Да, но там подлянка такая,
более того, как бы не уверен, что вам будет знаний хватать на то, чтобы уметь решить хотя бы две.
Чего-чего? Кучу? Какую кучу? А, ну мы тут сейчас узнаем, что такое куча, так что можно. Так,
смотрите. Так, ладно. Ну это так, если кто-то не помнит, что такое симтотики, то я думаю, тут все
понятно. Вот. А теперь смотрите. Значит, ну задача о сортировке. Ну тут на самом деле, чтобы
анализировать как бы сложные задачи об симтотике, тут как бы половину вопроса решает точная,
соответственно, постановка задач. Вот. Потому что вот мы попытаемся ее решить вот в таком,
вот в таком достаточно жесткой формулировке, чтобы вот легче было анализировать там самую
лучшую симтотику. Ну у нас цель иногда не только сказать, что придумать самый лучший алгоритм,
но еще и доказать, что лучше нельзя. Вот. Ну вот с другой стороны. Вот, например, вот у нас задача.
Вот предположим, что у нас есть n камней, как написано. И причем, да, камни — это вот чисто
название. И они абсолютно одинаковые на вид. Ну там ладно, максимум только маркером на них написано
1, 2, 3 и так далее. И наша задача их отсортировать. Для этого нужно их как-то сравнивать. Теперь
предположим, что все, что мы умеем — это брать два камня, положить их на весы. Весы подчешутся,
подчешутся и скажут, у кого вес больше. Типа вот туда или туда. Все. Но для простоты предположим,
что у нас там все камни веса попарно различны. И в результате даже вот совсем формально пропишем,
что нам нужно их отсортировать. То есть выдать вот перестановку этих камней, такую, что в этой
перестановке каждый следующий камень весит больше предыдущего. Вот теперь возникает вопрос.
Хочется найти наилучшую асимптотику, за которую мы можем это сделать. Так вот прикинем все вениками,
что мы пока этого не знаем. Вот давайте аккуратно. Значит, смотрите. Вот теперь давайте задавайте,
за какое минимальное количество действий это можно сделать? Но на самом деле какая тут модель,
может быть, как это вообще можно сделать? Но в принципе, одной из моделей является дерево решений.
Вот сейчас вы видите, то есть смотрите, то в принципе, если бы мы отсортировали три камня,
то по большому счету алгоритм, вот вы знали, что их ровно три, то алгоритм можно было бы представить,
как вот такого рода набор ифов. Но даже этот набор на самом деле можно представить как просто
вот такое двоичное дерево, где в каждой вершине мы говорим, возьми вот этот камень и вот этот.
Если первый оказался весит меньше, то значит идем в левую веточку. И соответственно, вот,
а что я вам руками показываю? Вот в левую веточку, вот. И соответственно, вот, а если этот вот,
что вправую, вот что-нибудь такое. Ну вот, ну в данном случае, например, да, то есть если нулевой
весит меньше первого, мы идем вот влево. Если первый весит меньше, то вправо. Вот, то есть получается,
если просчитать все варианты, а всего у нас вариантов, а теперь заметим, что всего у нас
вариантов ответов сколько? Ну n-факториал, ровно. То тогда получается, что у нас листов у этого
двоичного дерева поиска должно быть n-факториал. Вот. Ну теоретически или более, ну потому что раз каждый
может быть ответом, значит на каждый, то есть теоретически может быть так там, вообще в алгоритмах
в общем, что там, что какие-нибудь там два листа дают одинаковый ответ. Но практически в нашем случае
не очень понятно, как это, поэтому соответственно. Вот. Ну теоретически в других алгоритмах. Ну да,
ну здесь как-то очень странно, потому что, нет, в данном случае, если мы сравнили х камень с
игроковым, да, то тогда, ну там где нот, ну то есть как минимум, вот заметим, вот мы в корне сравнили
нулевой с первым, тогда очевидно, что во всех листах левого по дереву нулевой камень будет стоять
раньше первого, а во всех листах правого по дереву, наоборот, первый будет стоять раньше нулевого.
Поэтому понятно, что там одинаковый не будет. Ну да, получается так. Нет, ну это вы, нет, стоп,
стоп, стоп, не так. В один лист ведет одна ветвь, так или иначе, так дерево устроено. Но имейте в виду,
что мы говорим о том, что не может быть двух одинаковых листов. Нет. Да. А вот какие-то,
вот алгоритм так сказал. То есть на самом деле любой алгоритм, какой бы вы ни написали алгоритм,
но если вы зафиксируете, ну детерминированный, конечно, да, то вы, если вы зафиксируете алгоритм и
зафиксируете число n, то тогда по этому алгоритму можно нарисовать вот такое дерево.
В один лист, не понял. Так, мы договорились, что это вообще дерево. Да, у нас мы договорились,
что это дерево. Да, то есть как бы, ну что, что да, в один лист ни в одну вершину более одного
ребра не ведет. То есть у нас не может быть так, что мы тут пришли и сказали, а вот в этом месте
давайте одно и то же делать. Нет. Лист это уже ответ на задачу. Вопросы задаются в промежуточных
вершинах. Так, давайте терминологически, да, помните, да, в дереве лист это вершина,
у которой детей нет. Вот все остальные вершины листами не называются. А то давайте это,
потому что в этом мире, где у нас оказывается в некоторых местах лист это массив, так называется,
знаете, надо очень четко понимать действительно значение слов. Но тем более, знаете, очень
сложно общаться с человеком, у которого представление о том, что значит слова,
отличается от вашего представления. Ну, то есть типичный пример, это когда вам якобы на белое
говорят, что это черное. Так вот, значит теперь, ну вот, значит, то есть каждый алгоритм по сути
действительно можно прописать как вот такое дерево. Ну, потому что там любой мэш-сорт напишете,
то есть по факту он там, вы просто можете проследить, просто дать ему на вход все n
факториалы, собственно, вариантов ответа и смотреть, какие элементы он будет сравнивать и,
собственно, какие результаты будут. И тогда в наборах будет получаться дерево. Потому что,
по большому счету, разветвление у него по-любому будут только там где-нибудь в каких-нибудь ифах,
правда? Ну вот, то есть, точнее так, все ифы будут зависеть от того, какие результаты сравнений были,
потому что если вы сделали там, то есть скажем так, если первые там, скажем, десять сравнений там
в мэш-сорте, например, дали одинаковый результат, как строчка 0,1, там 1,0 и так далее, то соответственно
мэш-сорт до этого момента будет делать ровно одно и то же. Логично, да? Вот, поэтому получается дерево.
И теперь возникает вопрос, что нас интересует? Нас, конечно, интересует высота этого дерева для
каждого n. Ну, потому что что такое, вот алгоритм работает за о от, он работает за не менее чем
о от, за омега от высоты этого дерева в худшем случае, правда? Потому что эти сравнения уже алгоритму
сделать все равно придется, так или иначе. Вот, вот просто там без вариантов. Вот, то есть это, то есть,
да, то есть, ну, точнее так, мы оцениваем, да, мы оцениваем время работы алгоритма любого снизу,
как количество сравнений, которые он делает в худшем случае. А теперь замечаем следующее. Ну вот,
но теперь заметим надо, чтобы алгоритм действительно работал четко и чтобы у этого дерева должно быть не
менее чем n факториал листов. Вот, но теперь возникает вопрос, что же это может быть? Ну, с одной стороны,
снизу, с другой стороны, давайте посмотрим, какие у нас алгоритмы вообще есть. Вот, ну, можно пробежаться
так. Ну, например, как можно вообще сортировать? Ну, один из самых таких тупых алгоритмов, которые,
там, возможно, вы там, если вас попросить, там, в седьмом классе придумать хоть какой-нибудь алгоритм
сортировки, то можно придумать вот, например, такой. То есть, условно, в каждый момент времени мы тупо там
находим, то есть, сначала тупо перебираем, находим минимум, ставим его на место, потом находим из
оставшихся второй элемент, ставим его на место, потом третий, четвертый, пятый. Это называется сортировка выбора.
Почему? Нет, next permutation это надо знать, что такое next permutation. Очень сомнится, что вам в седьмом классе вы
будете знать, что такое next permutation, до того, как узнаете, что такое сортировка. Вот, ну,
ой, ну, чтобы вы в седьмом классе знали, что такое рандом, вот, ну, адекватно хотя бы. Вот, значит,
вот, то есть, такой вот, такая вот штука есть, но тут я скажу, да, алгоритмы простые, но их полезно
помнить, потому что каждый из этих алгоритмов, на самом деле, может вылезти в абсолютно неожиданные
места, на самом деле. Вот, поэтому, соответственно, надо знать. То есть, у всех там свои, на самом деле,
неожиданные приколы есть, как мы увидим. Так вот. Какие еще варианты есть? Вот, ну,
видим, за сколько у нас сортировка selection работает. Он работает за, даже не o от n квадрат,
а theta от n квадрат. То есть, отметим, что этот алгоритм, он прям железобетонно за квадрат
работает. Да, у него худший случай от лучшего, в общем-то, отличается не особо. Вот, сортировка
вставками. Так, следующий вариант. Нет, ну, не совсем. Не-не-не. Разница такая, смотри. Нет,
разница такая. Тут ты, смотри, да, у тебя тут слева отсортированная часть справа, но здесь,
у тебя отсортированная, ты вне отсортированной части находишь минимальный элемент и помещаешь,
и вставляешь его в начало, именно в конец. В insertion, в сортировке вставками ты делаешь по-другому.
У тебя в каждый момент времени префикс отсортирован, ты берешь следующий за префиксом
элемент и вставляешь, но уже не в конец, а уже куда придется. Вот, собственно, код, в общем-то,
вы видите. Да. Как минимум, потому что некоторые нам пригодятся еще, как это ни странно. А вот,
а что объяснять? Вот код. Чего не умеете? Код не умеете читать. Ну, смысл простой. Ну,
по сути, то есть, сортировка вставками заключается в том, что у вас есть массив, то есть отсортированный,
изначально пустой, и вы берете элементы по очереди и этот или и каждый элемент вставляете в массив так,
чтобы было сортировано. Первая, да. А это сортировка вставками. А то и значит, прям в середину
вставляем, там раздвигаем, если что, две половинки. Да. Да, вот обратите внимание, то есть, реально,
внутри одного массива это можно сделать так. Вот вставляем, предположим, что у нас есть префикс
длины и уже отсортирован. Тогда аит-элемент мы хотим вставить. Тогда идея такая. Тогда вот
идея возникает такая, что мы, честно, все элементы, вот идем справа налево, начиная от именно с первого
элемента, и все элементы, которые больше нас, нот, которые там, соответственно, больше нас,
мы так жественно копируем вправо. А потом, собственно, на освободившееся место вот мы, собственно,
тут вставляем вот эту tmp. Чего? Да, вот теперь, чем интересно это отличается, что если нам повезет,
то это сработает за линию. То есть, в отличие от предыдущей сортировки, мы оставляем в себе
возможность, что нам повезет. Чего-чего? Не, на каком стэке, где? Не-не-не, здесь нам не повезет,
потому что мы минимум в честную ищем. По всему суффиксу прям честный минимум ищем. А тут,
как вы видите, мы делаем, сдвигаем, то есть, ищем сколько элементов надо сдвигать и честно их
сдвигаем. Прям предельно честно. Нет, не-не-не-не. Нет, bubble это более, это другое немножко. Нет,
in session мы по одному элементу вот вставляем. Вот ровно по одному и не ноты. И причем именно
вставляем. Но на самом деле, можно как бы более тупо доказать, что он на самом деле работает за
О от количества инверсии в массиве. Да, даже не за О, а за тета от количества инверсии в массиве,
ну плюс N еще. Обратите внимание, в худшем случае. Но если инверсия у тебя будет N,
там О от Н, то алгоритм сработает за О от Н. Ну да, ну скажем так, да. Но да,
математическое ожидание количества инверсии в рандомном массиве, конечно, N на N-1 поделить на
4. Это да. Ну потому что всего пара элементов N на N-1 пополам и каждая будет составлять инверсию
с приоритетностью 1 до 2. Ну и что оба, когда вы считаете мат ожидания, зависимость вообще ни при чем.
Как бы, мат ожидания, скажем так, мат ожидания суммы случайных величин равно сумме мат ожиданий
случайных величин и абсолютно не важно зависимы они или нет. Да, да, легче всего это вообразить,
помните, мат ожидания это такой интеграл. А интеграл в сумме равен сумме интегралов независимости
от того, там зависимы эти функции или нет. Да, но нет, это на всякий случай здесь понятно,
что вы не знаете, что такое интеграл, что такое мат ожиданий, что такое случайная величина. Да,
поверьте, вы не знаете, что такое случайная величина. Нет, что сейчас, да? Нет, ну вы нельзя,
давайте проверяйтесь, просто вы сейчас реально готовы забабахивать за сигму алгебру. Ну кто-то
наверно готов, конечно, но вот. Но там как бы, чтобы это определить, вам придется реально вводить
понятие сигму алгебры, там вот и развлекаться с этим. Да. Нет, ну, а даже за линию ищем. Нет,
потому что мы читеры, мы ее ищем справа налево. Как только мы интертусируем на элемент,
который меньше нашего, значит все, здесь мы можем останавливаться. Вот. Ну, собственно,
вот в этом коде это даже определено. Хотя правильно замечено на самом деле, что теоретически есть,
да, возможны неосимпатические оптимизации у этого алгоритма. А вот смотрите.
Но нет, это скажешь так, в некоторых случаях это может быть чуть быстрее, потому что раньше вы и
искали за n квадраты, и сдвигать. Сдвигать, просто память сдвигать можно быстро, потому что там
компьютер это как-то хорошо умеет с более лучшей константой.
ДД, ага, это вероятност алгоритм, это нас не устраивает.
Ну, ей там нужно передать, куда вы копируете, что вы копируете и сколько, то есть начиная с
какого забора и до какого обеда. Нет, но нет, но это это сейшная функция, она вам в библиотеках
распроставляется. Ну, в итоге получится за n квадрат, но сильно меньшая константа вот в такой версии.
А когда вы ищете, вы можете искать за bin поиск. Смотрите, кстати, как интересно стало,
сравнение уже стало n log n. Ну, в такой версии алгоритма insertion сорта сравнение теперь стало
в худшем случае n log n. Ну да, правда алгоритм все еще работает за n квадрат, то есть у нас
присваивание теперь стало чуть побольше. То есть, ну не побольше, а все еще квадрат, правда,
константу мы уменьшили, но математически это еще не решение. А вот упомянутый ранее bubble sort,
более известный как сортировку пузырьков. То есть, это такой, да, это аналог insertion
сорта, но такой продвинутый. То есть, давайте пробежимся слева направо и будем говорить,
если я вижу инверсию, давайте я ее посвапаю. То есть, если очередной элемент больше следующего,
давайте я их посвапаю. Вот, ну, собственно, вот написано, в общем-то все. Ну, вообще нет. Да нет,
принципиально разницы нет, потому что, ну, как бы для любого плохого теста для одной версии
существует развернутый тест. Ну, скажем так, я так сказал, классическое представление bubble sort
это, конечно, когда вы слева направо пробегаетесь. Нет, нет, нет, нет, нет, вообще нет. Ну и что, да,
но bubble sort делает еще кучу всего дополнительного. Он еще какие-то элементы сдвинет влево,
а insertion sort этим не занимается. И потом в selection sort тоже минимум в начале,
оказывается в начале, но как бы. Да, но это не означает, что алгоритмы одинаковые.
Нет, ну вот. Значит, смотрите, внимательно. Значит, что такое bubble sort? То есть, видите,
то есть bubble sort тут фишка, что да, он, конечно, гарантированно за первую итерацию там, за первый
проход наибольший элемент отправит в начало, но тем не менее окажется, что до того, как он в этом
проходе встретил этот наибольший элемент, он там до этого действительно еще какой-то элемент куда-то
подвигает. Поэтому, строго говоря, это лучше. И действительно, но правда, заметим, что в лучшем
случае этот алгоритм, обратите внимание, вообще за линию работает, если вам подсунули отсортированный
массив. Ну почти, что такое почти? Ну почти отсортированный.
Параллельно.
Ну, не знаю, ну по-моему, ой-ой-ой-ой. Ну, знаете, это, по-моему, нет смысла.
Нет, ну понятно, ладно. Не сказал бы, что это, ну как сказать. Ну как? Ну в сортировке выбора мы
честно находим минимум и честно его там помещаем в начало. Это выбором было. В сортировке выбора мы
говорим так, из оставшегося берем минимум, помещаем куда надо. В сортировке вставками мы делаем
наоборот. Мы берем очередной элемент, первый попавшийся, и вставляем его куда надо. Но почему?
Ну не совсем, там много чего может происходить. Вот смотрите, вот давайте вот на этот тест
посмотрим. Вот, например, был такой тест. Смотрите, первое некоторое время вот этот элемент 20 будет
торжественно двигаться вправо. Но двигаться вправо он будет не до конца, только пока не встретит
больше элемент 25. Но 25 тоже пока никуда не двигается, потому что он отнется на 35, он чуть-чуть
подвигается, он отнется на 42, и после этого он уже додвигается до конца. То есть да, мы гарантируем,
что после первого его прохода максимальный элемент оказался в конце, но эта сортировка сделала
чуть больше. Видите, она перед этим тоже какие-то элементы куда-то подвигала. Да, ну заметим, что да,
на следующем проходе мы можем, кстати, по этому последнему элементу уже не проходиться. Да, вот
такие есть, да, вот это есть. То есть видим, что здесь как-то вот произошло, что за 6 проходов мы тут
в принципе победили. Вот, то есть проходов тут может быть больше. То есть про проходов тут может
быть меньше, чем в реальном там каком-нибудь Insection Selection. В худшем случае такая версия,
конечно, если у вас тупо убывающий массив, но это работает за n квадрат. Чего?
А при чем тут форма? Чего? Чего-чего? Так, давайте без умных слов сейчас лишних. Давайте так,
лучше так, умные слова должны поступать так, собственно, все-таки ограниченными порциями. Ну вот,
потому что можно, можно, конечно, их все забабахать там первым, там теоретически можно ужать лекцию
просто так, что я там просто весь курс расскажу за полтора часа, ну или ладно, за три. Ну так,
на уровне общих глобальных идей, если вы достаточно умные, вы сами додумаетесь. Тем более, что много
из этого вы все равно все знаете. Да, все, увидимся на экзамене. Но мы все-таки так делать не будем.
Вот, так вот. И так мы рассмотрели три алгоритма сортировки, поэтому все-таки. Вот, то есть выбором,
ставками, пузырком. В худшем случае они работают за n квадрат, несмотря ни на там какие их там
примочки на тему того, что они там в среднем лучше бы и так далее. А, ну в принципе, вчера мы еще
quicksort рассмотрели, но в худшем случае он тоже за n квадрат работает. Да, да, мы в прошлый раз
рассмотрели quicksort. Да, но там разные варианты, да. А, ну хотя нет, в итоге мы, если мы рассмотреть
quicksort с правильным выбором медиана, то да. Да, тогда это уже n log n, да. Но если мы выбираем там
детерминированный в плане, в качестве среднего элемента, выбираем, давайте, вот этот вот первый,
или вот этот вот последний, или вот этот вот в середине массива. Нет, это не quicksort, это quickselect.
Да, но quicksort он тоже помогает. Хорошо, углорили, углорили. Ладно, да.
Тупо лучше константа. Понимаете, зачем этот quicksort с рандомом вообще нужен? Он нужен для того,
что просто он, у него константа очень крутая, он очень, он быстро работает. В результате по факту
это все приводится к тому, что в quicksort у нас, что в SPL работает так называемый introsort,
который говорит так, запускаем quicksort, прям часто запускаем, но если в какой-то момент мы
обнаружили, что надо отсортировать вот эту часть массива, а глубина рекурсии уже больше, чем там
сколько-то логарифмов, там 2 log или что-то еще, то мы в этом месте конкретно этот кусочек
сортируем хипсортом. Ну, потому что хипсорт он позволяет делать там уверенно без доп памяти.
Можно, мы даже будем обсуждать, как этот inplace писать сводки единицы дополнительной памяти,
да. Но алгоритм такой относительно гадостный и там приличная константа. Так что quicksort,
а quicksort он как бы на мах, но мы увидим чуть позже, собственно, он тут тоже есть на самом деле.
Так, так вот, ладно, но напоминаю, мы тут не просто изучаем сортировки, а мы как бы это,
ищем лучше. То есть знаете, как это, да, вы ищете. Да, то есть как там, да, знаете, мы, да, мы
путешествуем, ищем, что-то ищем, но вот попутно еще смотрим, что вообще есть. Итак, точно ли это
оценка. Но, оказывается, есть, ну первая обычно сортировка zn log n, которая узнается, это сортировка
слияния. Ну, собственно, да, ну вот, ну базируется она на простой идее, просто давайте разделяем
властвой, как мы уже обсуждали, разбиваем массив на два равных, ну или там почти равных, сортируем
рекурсивно один, сортируем рекурсивно второй, а дальше объединяем две отсортированные последовательности
с помощью двух указателей в один. Так, если предполагать, что мы разрешаем себе пользоваться
линейной доп-памятью, надо подробнее обсуждать. А это потому что кодовое словосочетание вариант без рекурсии.
Ну да, тут 1, 2 и 3, 4, 5, 6 и 7, 8, а тут вот так, да. Ну, просто такая нерекурсивная версия.
Чтоб не было это там, возьми два массива, там я их засортирую там рекурсивно, потом вот это вот.
Ну, нелюбимые рекурсии. Где? Нет, 1, 2 это значит, у нас уже есть отсортированный, в 1 и 2 элемент
образуют отсортированный подмассив. А также есть массив 3, 4, 5, 6, 7, 8. Видите, тут в конце надо
отсортировать массив, который находится подмассив с 1 по 2 в степени k-1. По 2 в степени k. Ну вот.
Ну, как сказать, ну здесь, да, если, да, тут. Так, ну да, тут не совсем точно написано, это да, но
если n равно 2 в степени k, то это будет уверенно работало. Да, но не точность, не точность, согласен,
согласен, да, мелче. Ну, просто как вы делаете слияние двух массивов? У вас есть два указателя и вы
идете и в каждом интервью говорите, если у вас один элемент меньше другого, то вы этот элемент
куда-то записываете и сдвигаете указатель. Остается такой, а куда вы записываете? Ну вот. Для этого
нужна допамять, то есть вы создаете новый массив, в который вы эти элементы записываете. Ну а потом
там эти два, если вы там сливали два, находясь рядом массива, вы их, собственно, потом копируете. Вот.
То есть обойтись за вот единицу дополнительной памяти, это сильно усложняет алгоритм. Вот в следующий
раз мы, видимо, будем это обсуждать. Ну вот. Но там мясо. Ну, конечно, N log N. Да, это, ну вот. А, вот.
Да, это вот N log N. Ну, например, потому что есть вот такая рекуррента. Хотя можно понять и без
рекуррента, просто себе это вообразив, собственно, это там дерево нарисовав.
Ну да, да, да, да. Но это уже, но как говорится, вы уже решаете домашнее задание, поэтому мы как бы
сможем в этом месте говорить с вами на более высоком уровне. Вот. Ну да, но я говорю, мы как бы, давайте, в
этом месте мы как бы понимаем, что решение существует, поэтому уже не заморачиваемся. Ну вот. То есть знаете,
то есть знаете, в каких-нибудь там, знаете, как представьте, сценка из жизни, там, скажем,
Киргизхана. И там первая, первая, ну, там Чиргизхану приводит плен, ну вот. А, нет, там,
или какой-нибудь русский, он приводит к какому-нибудь там плене какого-нибудь Монгола. И Монгол сказал,
так, подождите, слушай, давай договоримся, на каком языке мы с тобой вообще говорим, а? А то малые
там в зале какой-нибудь дотошник там какой-нибудь сидит, называется, еще спрашивать будет. На каком
языке? Так, все, на русском, не заморачиваемся, это премьер-лига, да, все. Вот. Ну вот, но здесь
то же самое. Мы уже там как бы все про себя поняли, что там какие-то есть, там может быть мелочи,
типа там должны быть какие-то округления, какие-то более строгие доказательства могут быть. Там
понятно, что это нот, но как бы мы мысленно умеем это делать, но вот поэтому нам это хватит. Вот.
Итак, значит у нас есть вот batch sort, но мы уже даже более аккуратно доказывали, что он уже,
что это n log n, и вот мы обнаружили, что оказывается, да, сортировка может работать за n log n,
оказывается. Вот. То есть теперь можно, то есть можно t от n, то есть вот время работы там,
лучше время работы сортировки оценить сверху как o от n log n. Но нет, концепцию мы не меняем,
мы пока, у нас концепция, мы сортируем n камешков, которые мы умеем только там сравнивать,
только там один с одним и всё. Вот. Но оказывается, теперь это уже точная оценка. Почему? А потому что
давайте думать. Ну, во-первых, да, заметим, что t от n больше либо равно, чем это оптимальная высота
того самого дерева, да. Помните, да? Ну, вот этого. Вот вспоминаем. Сейчас. А теперь смотрите. Ну,
я сейчас вам примерно просто на примере этого дерева воспроизведу, что тут написано. Когда
мы строим это дерево на присортировку n камней, да, то у нас получается двоичное дерево, у которого
там n факториал листов. Понимаете, да? Вот n факториал листов. Ну, вот. Ну, в принципе отсюда следует,
что высота дерева, по крайней мере, в худшем случае, не может быть меньше, чем логарифом этого n
факториала. Ну, просто потому что, ну, утверждение такое, если высота дерева h, то листов не более
чем два в степени h. Ну, да, стандарта, это максимальное расстояние или минимальное? Максимальное. Да,
то есть, если максимальное расстояние до листа h, то листов всего не более, чем два в степени h. Ну,
там, формальное доказательство можно по индукции провести, но, я думаю, это и так должно быть более
или менее очевидно. Исходя из того, что, как бы, на каждом шаге у вас происходит, то есть, у вас как
происходит, вот вы идёте с нуля и идёте как бы вниз, да, и тогда на очередном шаге вы либо встречаете,
то есть, как бы, на очередном шаге, если вы там, вы либо раздваиваетесь, да, либо вы утыкаетесь в
лист и завершаетесь. Вот, а дальше начинается просто элементарная алгебра. Ну, мы не знаем,
чему он прям равен, то есть, тут нет такого log n факториала равен там, какой-нибудь там n
в степени n, поделить на e в степени n, умножить там на обратную функцию кирмана, нет, такого нет. Ну,
а симпатически оценить его точно очень просто. Вот, нет, у меня тут просто всё написано, на самом
деле, даже вот. То есть, элементарно. Смотрите, log n факториал, это что такое? Формально говоря,
это log 1 плюс log 2 плюс, так далее, плюс log n факториал, плюс log n. Ну, давайте, давайте
предположим, для простоты Shen чётная. Ну, для простоты там, для нечётной, я думаю, понятно,
тоже очевидно будет. Вот, тогда мы можем сказать, что это не менее чем, в общем, я написал то же
самое, просто вытянул некоторые слагаемые. Да, я просто тупо вытянул первую половину слагаемых.
Но вторая половина слагаемых, каждая слагаемая, можно оценить, как log 2 n пополам,
правда? И тогда получается, что я могу оценить это снизу, как n пополам log n пополам. Ну,
остаётся легко показать, что это ω от n log n. ω с константой, ну, я не знаю, 1 третье. Да,
почему 1 третье? Потому что log n пополам, это всё-таки чуть-чуть меньше, чем log n. Но так как
это равно по факту, но так как это log n пополам, это log n минус, умалое от log n. Ну, как умалое,
это вот единицы. Там минус 1 по факту, поэтому это всё. Это получается вот ω от n log n.
Ну, это типа, я могу доказать, что начиная с некоторого момента, вот это вот больше
либо равно, чем n log n поделить на 3. Ну, чтобы вот тут вот, чтобы был именно ω от n log n,
я должен доказать, что вот это вот не меньше, чем n log n умножить на какую-то положительную
константу. Вот у меня эта константа будет 1 делить на 3. Ну, правда, там начиная с
какого-то n, наверное, но хотя скорее, ну да, начиная с какого-то n, наверное, там, ну больше
в единицы, но понятно. То есть таким образом получается, что чем приятно, то есть t от n,
как мы уже поняли, t это от n log n, а merge sort это асимптотический оптимальный алгоритм. Ура! То
есть если мы хотим найти асимптотический оптимальный алгоритм, то получается, во-первых,
мы должны его предъявить, доказать его асимптотику, а во-вторых, доказать, что быстрее не получится.
Ну вот да, вполне. Ну типа да. Ну да. Ну любая сортировка в нашей модели. Посмотри,
любая сортировка, она по сути делает что? Она берет как-то детерминированно какие-то два камня
и их сравнивает, да? В зависимости от результат, она делает еще какие-то действия, берет следующие
два камня и сравнивает. Но какие она два камня возьмет на второй раз, детерминированно определяется
результатами, первым результатом сравнения, правда? Ну потому что у нас детерминированы алгоритмы.
Что значит выбирать роддомно? Нет, роддомные алгоритмы нас интересуют, нас интересуют
детерминированные алгоритмы. Я еще не понимаю, что ты говоришь, можно понять? Где я такое написал?
Ну в принципе, в случае Ошки вполне корректно. Ну понятно, что это не совсем формально, но как бы
понятно, что имеется в виду, что T от N меньше либо равно некоторой функции, которая является O от N
log N. Ну да, я думаю так, вполне может быть, скажем так, как говорят в английском языке,
тебя поймут и поймут адекватно. Вот если ты напишешь T от N больше либо равно, чем O от N log N,
то формально говоря это может быть, это ничего не значит, потому что единица это тоже O от N log N.
Да, не T это, но O. Ну тоже поймут. То есть формально мы, конечно, не вводили такого понятия T от N меньше
либо равно, но написать можно будет адекватно. Где? Ну конкретно в нашем контексте нормально,
да. Но именно в случае с Ошкой, меньше либо равно омеге, это конечно бесполезно. Ладно, так вот,
ребята-ребята-ребята-ребята. То есть мы, получается, оперируем три штамма слоев,
смогли доказать то, что у нас идеальная, детерминированная сортировка работает за O от N log N.
Ну да, ну за T это, да. Ну в худшем случае за T это, да. А как мы понимаем, какой нам в вершине,
какие элементы нам сравнить? Или неважно? Ну так это алгоритм задает. Нет, ну просто
от дерева, просто можно по любому алгоритму построить дерево, по сути. Ну вот. Почему?
Да, ну это, ну как бы, ну так поэтому этим деревом мы доказывали оценку с
низу. То есть мы говорим, что высота будет не менее, чем логариф на 2,9 факториал, а этот
это от N log N. Отсюда следует, то есть это омера от N log N. То есть получается, что быстрее,
чем за N log N, мы сортировку не напишем при всем желании. А за N log N мы ее напишем,
потому что у нас есть, вот мы предъявили алгоритм. Так что. Да, высота логарифа.
Нет, вопрос в дереве упоминается только сравнение. То есть мы смогли сделать, то есть как бы мы говорили,
что у нас оказывается, мы не можем сделать алгоритм быстрее, чем log N факториал,
потому что оказывается сравнений в худшем случае нам придется делать log N факториал.
Вот. Ну да. То есть в принципе альтернативное доказание, доказательство без этого дерева
могло выглядеть так. Сделаем, возьмем, то есть алгоритм, то есть наш алгоритм говорит,
сравни вот эти два камешка, да? Мы говорим, что высота больше, чем N log N, ну потому,
что у нас какие-то ветки прекращаются раньше, значит какие-то ветки должны идти дальше. Да,
но мы же вход. И уже исходя из того факта, что мы придумали merge sort, который работает за N log N,
нам нужно не только доказать то, что, не только взять логарифа от N log N,
но еще и построить алгоритм, который делает сортировку за N log N в ранении. Конечно. Да.
Ну да. Ну не двойное, а доказательство с двух сторон. Хочешь доказать что-то оптимальное,
докажи, что а, это достижимо, б, лучше нельзя. Логично. То есть то, что это достижимо,
это merge sort, а то, что лучше нельзя, вот собственно метод с деревом. Да, вот это хорошо,
что уточняем, потому что у вас, кстати, у вас домашнее задание есть на это задачка.
Нужно провести аналогичного рода анализ для следующей задачи. То есть вот тоже самое,
даны те же самые N камешков, и надо их отсортировать. Но кроме этого, вам дано еще число k,
и гарантируется, гарантируется, что каждый камешек находится на расстоянии не более,
чем k от своей правильной позиции в отсортированном массиве.
Вы уже прямо сейчас можете ее сделать. Это будет за N квадрат. А вы уверены,
что нельзя быстрее? Ну, во-первых, это надо доказать. Во-вторых, вы уверены,
что алгоритм нельзя написать быстрее, чем ZNK? Да, давай. Как считать оптимальную симпатику
если у нас два параметра? Так а также. Ну, на самом деле, не надо их считать. Формально так скажем,
достаточно предъявить асимптотику такую, что A быстрее, чем эта асимптотика, нельзя.
А что такое быстрее, если у нас две переменные? Ну, для любых K и N существует такая константа C
больше нуля, что любой алгоритм с параметрами N и K будет работать не менее, чем за C на вашу
функцию от N и K. Ну и что, если у одного есть константа C и у другого есть константа C,
вы берете минимум из этих константов и все равно мажорируется снизу. Так что какая разница?
Ну, теперь надо как бы общую точную функцию поделить. Ну да, для K равно 1 и K равно N мы
вот только что рассмотрели, то есть K равно N это означает просто элементы расположены как угодно,
и мы доказали, что это быстрее, чем Z log N не получится. Но если K равно 1, это означает,
что каждый элемент находится рядом со своей правильной позицией. Поэтому там можно
идти слева направо и сначала понять, кто минимум, первый или второй. Ну вот, взять этот минимум,
потом посмотрите, кто второй, это значит перебрать там, условно, первый, второй,
третий и посмотреть или взять минимум из тех из них, кто не занят. Ну и так далее.
Ну не совсем, вы делаете за от N, потому что вам надо вернуть ответ. Хотя по большому счету да.
Ну типа того. Ну как сказать, если вы создадите от этого памяти,
тоже не страшно в общем-то. Хотя можно удобно считать, что вы возвращаете перестановку.
Чего-чего? Какие соображения? Не понял. Нет, ну а что дальше? Нет,
чтобы обсудить дальше домашку, нужны еще два продвинутых алгоритма. А, не-не-не, вру-вру-вру,
нет. И там есть еще одна задача, которую вы умеете решать. Она называется дек теория.
Да, но дек теория, по сути, это вам нужно просто придумать дек, который, ну придумать дек,
который работает за вот единицы, ну там по аналогии с вектором. Ну одно по аналогии с вектором,
но соответственно, да, там амортизировано. Но внимание, амортизированность нужно доказать
как с помощью метода потенциалов, так и с помощью монеток.
То есть если придумать персистентный дек, то это не зачтется? Ну, формально говоря, зачтется,
в принципе, да. Ну, лучше нет. Давайте вот векторы, нельзя ничего амортизированного там локально
использовать. Лучше вот давайте использовать, то есть как бы все амортизировать надо полностью
использовать. Если будете использовать вектор, значит его тогда тоже придется описывать и
анализировать. Чего? Не, ну почему не обязательно, нет. На массиве можно. Не-не-не, ну сводить
одно к другому не надо. Хочется вот как бы смысл этого в том, чтобы вы как бы потренировались и так
и так делать, только чтобы это не было, что потенциалы мы сводим к монеткам. То есть да,
они там плавно перетекают одно в другое, но тут надо не забыть, что монетки это монетки,
потенциал это потенциал. То есть потенциал говорит, доказательство должно быть, что будем введем вот
такой потенциал и докажем, что относительно его учетная стоимость там адекватная. А, и важный
момент, по памяти, конечно же, должно быть так, что если у вас размер дк равен к, то
соответственно реальный размер памяти, который вы в этот момент используете, не превосходит отка.
Чего делать? Да, конечно. Да, мы лучше, чем истрейлевский вектор.
Зачем? Надо. А что значит делать дек на вектора? Да, только вот есть ограничение по памяти,
напоминаю, да? Нет, тета, тета должно быть. Ну в том плане, что, ну у тебя ж помнишь,
да, не должно быть так, что там условно остался один элемент и вектор на миллион. Ну что-то сделал.
Это уже детали решения там по-разному, можно? Ну это один из вариантов, там разные решения есть.
Нет, я сказал так, если вы, ну там так, если вы используете вектор, то тогда вам придется
описывать, как устроен вектор и доказывать театризированность и с его учетом тоже. Ну был
вопрос просто, можно ли использовать вектор? Если вы не хотите его использовать, можете не
использовать ни в коем случае. Да-да-да, именно. Так, ладно. Значит, идем дальше. Это как бы, да,
MeshStore как бы знаем, это не единственный алгоритм за NLogN, но для следующего классического алгоритма
нам потребуется, конечно, вот эту. Да, это такое абсолютно, вот это называется полное двойчное,
да, внимание, тут написано определение, как видите, на кучи на максимум, да, сразу поговорим,
вот мы будем оговариваться, потому что есть куча на максимум, есть куча на минимум. Ну,
куча на максимум, это когда родитель больше ребенка, куча на минимум, когда родитель меньше
ребенка. Вот здесь сейчас нарисовано куча на максимум. Значит, тут по-разному, ну как бы,
чаще всего мы будем все-таки разговаривать о кучах на минимум. Да, мы говорим говорить о кучах на
минимум, но имейте в виду, что в STL по умолчанию куча на максимум. Ну, куча это при приоритете QI,
конечно. Конечно, будем, вот она тут, где-то она тут даже будет вот, вот, вот, ну да, вот она. Ну,
то есть по большому счету да, то есть смотрите, то есть сразу давайте оговоримся, что на самом деле
сортировать за Эмблоген очень легко, если у нас есть адекватная реализация вот такой структуры
данных. Вот будем говорить, вот давайте, да, вот у нас в этой презентации еще используется понятие
абстрактный тип данных. То есть абстрактный тип данных, это значит, что у вас есть черный ящик,
который вот реализует там, там вот описано какие методы. Как он их реализует, мы не знаем,
мы знаем только, что он их реализует и знаем, за какой асимптотику он это делает. Вот. Хотя,
в общем, в абстрактом типе данных даже асимптотик особо нет, потому что на самом деле это,
ну, фактически интерфейс такой. То есть просто такой, ну вот, то есть может быть, вот вы,
ладно, с вильей вы когда-нибудь будете проходить, вот у вас-то будет какой-нибудь там виртуальные классы.
Бывает, знаете, вы будете реализовать классы, где там метод вообще не реализованный, это нормально.
То есть говорите, то есть это означает, что экземпляр такого класса вы не создадите,
но вот наследники у него будут. Ну, там как-то так это будет. Вот. Так вот. Пока нужно,
знаете, здесь у вас, пусть у вас есть черный ящик, который умеет реализовывать вот эти методы,
то есть прям честно, то есть добавлять элемент, там доставать элемент с наивысшим приоритетом и
там просмотреть элемент с наивысшим приоритетом. Вот предположим, что у вас есть структура данных,
вот мы назовем ее очередь с приоритетом. Если все эти методы вы умеете делать за алгорифом,
то тогда вы без труда сделаете сортировку с очередью с приоритетом. Как вы это сделаете?
Это очень просто. Ну, по сути, поместим, можно просто сказать, поместим все n элементов в эту
структуру, в черный ящик, а потом n раз достанем максимальный элемент и просто будем в классе
справа-налево. То есть, если у вас есть черный ящик с алгорифмическими сложностями,
то вы многое на сортировали уже. Но, как всегда, остается этот черный ящик теперь изобрести.
Но теперь мы забываем о сортировке, теперь наша цель реализовать этот черный ящик так,
чтобы он работал за алгорифм. Как мы это будем делать? Ну, вот, примерно так. Теперь подробнее.
Итак, значит, во-первых, значит, у нас в черном ящике, ну, там разные варианты,
мы могли бы там и овл-дерево, в общем-то, забабахать. Но мы начнем с более простого.
Значит, мы забабахаем, что у нас есть двоичная куча. То есть, двоичная куча – это не просто,
когда любой родитель больше детей, больше любого ребенка своего. Но, что для нас очень важно,
то, что это дерево идеально сбалансировано. Ну, в том плане, что уровни прям заполняются,
прям вот, тут, прям вот, сначала один, потом в следующем уровне два, потом на следующем
уровне четыре и так далее. И каждый уровень заполняется слева направо. Если в таком-то
уровне остановились, ну, значит, так и остановились. То есть, вот. Причем, что самое приятное? Что
такую кучу очень удобно хранить в, обратите внимание, массиве. Особенно массиве,
индексированном с единицы. Почему? Да, просто потому, что, на самом деле, попробую тут день
нарисовать. Что оказывается, если у вас есть элемент номер И, то очень удобно найти его
детей. Это элементы номер 2И и 2И плюс 1. А родитель это И пополам. Что 4Н? Что 4Н? Нет, в памяти Н.
Никаких указателей, с указателями, да, если вы кучу можно на указателях написать, но это будет
реально 4Н. А если в массиве, то ровно Н. Да. Если вы будете писать на указателях, то рядом с каждым
элементом вам придется хранить как минимум два указателя. Налево ребенка и направо. А в массиве
вам это не потребуется, потому что для элемента с номером И, то есть, который лежит в этой ячейке,
оказывается, дети это те, кто лежат в ячейках номер 2И и 2И плюс 1. Все. А если у него прикол очень
интересный, а у последнего элемента же 2Н будет лежать? Не, ну, значит, у Н-го элемента тупо нет
детей. Но если у него есть дети? А у него их нет, потому что у нас куча так устроена, что он на
последнем уровне находится. Так что да, то есть, пожалуйста, то есть, с точки зрения это, то есть,
вот куча звучит так. В корне лежит первый элемент, его детьми левым является А2, этим А3. Потом идут
4 и 5. Вот видите, я прям в порядке заполнения рисую. Если их 5, то будет так. Если 6, то еще вот так.
Если 7, то вот так. Еще есть 8. А причем тут ДОшка вообще? Ну, не знаю. Ну, в ДОшке индексация та же,
но суть принципиально другая. Да, потому что в ДОшке как бы сами элементы находятся в листях,
а в каждой вершине написано какая-то агрегация на подмассиве. А тут принципиальное отличие
от ДОшки, что каждый элемент это реальный элемент. Вот, поэтому... Нет, тут прям жестко,
что расположение элементов именно вот такое. Например, если тут на последнем уровне не 8 элементов
А3, то они расположены именно вот так и не как А3. То есть нет уже этот подвешен сюда, этот сюда,
этот там туда. Вот последний слой заполняется слева направо. Там все написано. Тут это прописано.
Это важный частин вариант. Да, видим, все очень жестко. Ну, поэтому возникает вопрос. Да, ну вот,
это мы поговорили. Ну да, если у нас индексация с нуля, то тут, конечно, плюс-минус единички
начинаются. Поэтому в этом месте лучше жить в один индексации, потому что приятно. Вот,
ну а теперь остается такая очень интересная идея. Если в куче меняется один из элементов. Вот
представим себе, что у нас там в куче... Так, давайте это сотрем. Так, зачем нам эта очередь на
шести стэков? Как мы уже выяснили, она нам все равно не нужна толком. Так, ну вот, то есть давайте
себе представим. Так, значит, смотрите, сейчас шоу мы себе представим. Мы себе представим, что у нас
есть вот мистическая куча. То есть прям большое-большое дерево. Прям очень-очень-очень-очень-очень-очень-очень-очень
большое дерево. Нет, больше не будет. И неожиданно вот этот элемент изменился. Что делать? Но,
оказывается, вы за логорифом можете поменять местами некоторые элементы так, чтобы все поправилось.
Нет, любой один. Нет, если мы там... Ну, как бы эти же элементы вы там как-то переставляете местами так,
чтобы свойство кучи сохранилось. Ну, например, если вы неожиданно... Вот пусть у нас куча на максимум,
и у нас неожиданно элемент увеличился. Тогда оказывается, что... Ну, тогда оказывается,
что достаточно этот элемент просто пропихивать наверх. Ну, в каком плане? Заметим, что кроме этого
элемента всегда верно то, что любой предок больше любого своего потомка, правда? То есть вот этот,
ну, по транзитивности, да? Проблема только с этим элементом. Но пусть он увеличился. Если он увеличился,
то он все еще больше своих потомков, правда? Но единственная будет проблема, что он может оказаться
больше своего родителя, правда? Ну, тогда идея такая. Ой, а давайте-ка их посвапаем. Тогда заметим,
что вот в этом вот поддереве полностью корректная куча, правда? Ну, и вообще она везде корректная.
Любой элемент больше любого своего потомка, если только мы не говорим про этот элемент. Вот,
но этот элемент он больше теперь все еще всего этого поддерева, но может быть меньше вот этого
своего родителя. Если что, значит свапаем. Ну и так далее свапаем до тех пор, пока он не окажется
меньше родителя, ну или там не воцарится в корне. Вот. Эта функция называется shift up.
Shift up, yeah, yeah, shift up, yeah, yeah. Не знаю, так вот, что-то тут начало сифдауна. Ну ладно,
давайте мы вот... О, да, вот такая красота была, да. Вот. Давай. Нет, сейчас увидите. Ну вот,
на самом деле вот shift up в ноль индексации может быть реализован вот примерно вот таким вот простым
вайлом. Видно, да? Понятно, да? Ну вот. Ну а теперь вот shift down. Значит, да, ну зачем нужен shift down?
Ну shift down... А, ну нет, все-таки используется хиппи. Чего? Ну. Это в ноль индексации, да. Просто
это в ноль индексации. Да, это... Да, то мы бы не вычитали, да. Так вот. А теперь просто еще
чит. Значит, смотрите, что делает shift down? Shift down делает ровно то же... То есть он делает то же самое,
если выяснилось, что вот там какой-нибудь вот этот элемент захотелось, он неожиданно уменьшился.
Тогда оказывается наоборот, он заведомо меньше родителя, но может так оказаться, что он оказался
меньше какого-то своего ребенка. Какого-то, обратите внимание. Что тогда делать? Ну тогда
мы смотрим на обоих детей, смотрим, кто из этих ребенков больше. Ну, допустим, вот этот. Ну да,
допустим, вот этот. И тогда свапаем, да, свапаем их. Вот это больший ребенок. Теперь заметим,
что этот больший ребенок, он как бы больше этого элемента, поэтому теперь в куче никаких проблем,
кроме этого элемента, нет. То есть любой предок больше любого потопка. Но теперь вот этот элемент,
он снова может оказаться меньше какого-то своего ребенка. Но, допустим, на этот раз вот этого. Ну и
тогда, значит, свапаем с ним и опять. И может так оказаться, что у вершин вообще стал только один
ребенок, и этот случай тоже надо рассмотреть. Но тут просто, если этот один ребенок, но этот
ребенок больше нас, значит мы тут тоже свапаем. Если мы уже дошли и ребенков нет, значит
останавливаемся. Ну и, конечно же, если мы уменьшили, и в какой-то момент обнаружили, что элемент
оказался больше своих детей, значит в этом месте тоже нужно остановиться. Вот. И в результате получается,
в общем-то, видите, чуть более сложный код, чем у сифтапа. Вот. Но, как бы, сложность такая незначительная.
Давай. А что означает слово сифт? А что такое? Ой, а куда у меня штучка? Ладно, придется ключ.
А, ну да, тут картинки, если надо есть. А, но на самом деле, смотрите, как строится куча. Да, кто-то мог
сказать, что давайте просто делаем и это, да вот, ам. Ну, то есть, как вставить элемент в кучу вообще, да?
Теоретически просто попушбэкать элемент, да, и просто попушбэкать элемент и сделать от него сифтап,
правда? Но на самом деле, если у вас есть n элементов, то на самом деле, оптимальнее сделать по-другому,
пробежаться с конца к началу и у каждого элемента сделать сифтдаун. А? Вот, оказывается, да, что это
круто по асимтотике. Ну, во-первых, да, понятно ли, почему это вообще работает правильно? Ну, то есть,
просто после каждого сифтдауна получится, что сифтдаун отсюда, по дереву этой вершины,
образует корректную кучу. Вот. Ага. Не, ну не по сортили, в данном случае, мы строим кучу. Мы не
сортим. То есть, мы именно строим кучу. Вот, оказывается, пробегаемся снизу вверх по дереву и
делаемся вдаун. Оказывается, что так куча строится за лигию. Ну, половина, ну и что? Не, ну. Ну,
потому что есть подозрение, что первый элемент, у которого есть ребенок, имеет номер ровно n
пополам. Ну, или в ноль индексации n пополам минус 1. А, да, да, правда. Да, но могли бы писать от
n до одного пробежаться, не поменял бы ничего. Ну вот, теперь смотрите, теперь давайте внимательно
думать. Давайте теперь, теперь смотрите. Теперь давайте вот каждую, каждую вершину говорить,
какая у нее высота, причем высоту на этот раз будем мерить как глубину под дерево. То есть, у этих
вершин высота ноль, у этих высота один, у этих высота два, три, четыре и так далее, да. Причем,
причем там амортизированность? Ну, не важно, ладно, давайте считать, что там. Ну ладно,
теперь смотрите, утверждение. На уровне h, то есть там вершин, у которых глубина h,
как бы есть подозрение, что не более чем n поделить на два степени, там h0, там плюс один.
Снизу? Снизу. То есть вот, например, если у нас, ну вот, ну, например, там, если у нас глубина 0,
то есть вот на этом уровне находится не более чем n пополам вершин. На этом не более чем там n
поделить на 4, ну и так далее. А, ну и тем более, что тут еще вот эти тоже считаются, видите, да? Вот.
И тогда начинается очень интересное суммирование. Уровней у нас всего от 0 до алгоритма, и мы суммируем,
то есть получается вот столько вершин, и shift down мы делаем на уровне h за o от h, правда? Или нет?
То есть получается, что это o от n умножить на вот такую интересную, вот такую, на сумму вот такого,
но это не ряд, конечно, но вот такой последовательность. Ну а теперь мистическое утверждение. Да,
можно просто там, что когда-нибудь в ботанализе вы докажете, что на самом деле, если эту сумму
взять до бесконечности, то она равна двойке. Вот. А сейчас мы не можем? Можем. Элементарно можем.
Сатрить. На самом деле элементарно. Сейчас я вам, собственно, сейчас покажу, тут сейчас просто это
красиво на пальцах делается, смотрите. Итак, что мы делаем, да? h, то есть получается у нас есть 1
1 делить на 2 в 1, плюс 2 делить на 2 в квадрате, плюс 3 делить на 2 в 3, плюс 4 делить на 2 в 4,
плюс 5 делить на 2 в 5, плюс там 6 делить на 2 в 6, плюс и так далее. Смотрите, как мы это запишем,
Смотрите, я это запишу в виде вот такой пирамидки, смотрите.
Одна вторая, одна четвертая, одна восьмая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцат
шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая,
одна шестнадцатая, одна шестнадцатая, одна шестнадцатая,
одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая, одна шестнадцатая,
одна шестнадцатая, uma, Gymno's embellishment,
Да.
Но там, конечно, чтобы доказать полную сумму, конечно, это
надо там более аккуратно предел доказывать, но,
в принципе, для наших целей этого достаточно.
Потому что нам достаточно, правда, что эта сумма не
происходит два.
Следовательно, вот.
А, ну, только тут С-шка забыта, конечно, немножко, но это
не глобально.
А, хотя С-шка не забыта, потому что есть О-шка, да.
Так что вот такая получилась красота.
То есть, оказывается, хип можно еще и за линию построить.
Но, обратите внимание, это только хип, это еще не сортировка.
Боже упаси.
Вот, ну да.
А, ну, а, еще момент, конечно.
Ради чего мы этот хип вообще писали?
Извлечение элемента.
Как извлечь элемент?
Да, ну, очень просто.
Свопнуть с этим последним, отпилить этого последнего ребенка
и сказать, что, ой, могут быть проблемы в корне, давайте
возьмем его севдалм.
То есть, получается, тоже такой красивый логарифм.
Так что тут, в общем-то, не очень интересно.
Вот, экстракт МАКС, видите, он работает за О от единицы
плюс севдалм.
Да.
Так.
Вот, да, нет, я как раз просматриваю зато, что я просто хочу
сейчас закончить с кучей.
Да.
Ну, чтобы в следующий раз как бы с кучей не начинать.
Да, в следующий раз мы начнем с воспоминания кусорта.
Ну, там, ладно, если кому интересно, там, так, ладно,
это мы промотаем, а вот тут начнется мясо, это вам
потребуется в третьей домашней задаче.
Кстати, сложные задачи сразу предупреждаю.
Ну, можете забить, но она 6 баллов весит, поэтому
тогда нельзя.
Так что нет, тут поятия у нас подряд.
А дедлайны работают еще раз?
Ну, так и работают, там, адекватная, собственно,
адекватная посылка должна быть сделана до дедлайна.
А если после дедлайна это типа не считаться будет?
Ну, да.
А если я немного подправил и после дедлайна вообще
чуть-чуть там подкорректировал, буквально?
Ну, смотрите, там два варианта.
Если проверяющий не успел добраться до вашей задачи,
то как бы, ну, значит он последнюю версию прочтет
и будет нормально.
Что считается адекватным посылком?
Ну...
То есть если, например, задалить решение, которое
на самом деле неправильно, считается адекватным?
Ну, скажем так, если оно доводится, скажем так,
ну, тут, конечно, такая неформальная замечание,
но обычно так, то есть если вы там целенаправленно
посылали условно чистые лица или просто какую-то
бла-бла-бла, чтобы сделать вид, что вы что-то сделали,
то это будет реджектно и сдавать задачу дальше нельзя.
То это тогда не считается.
Но если вы как бы заслали действительно какой-то
действительно адекватный, действительно там
добросовестные решения, в котором обнаружились ошибки,
то есть может не тривиальные.
Ну, тогда, конечно, эти ошибки можно и нужно исправлять.
Нет, а если, например, доказал задачу по мастер-тиореме,
заслал до дедуайна, а потом после дедуайна вспомнил,
что мастер-тиорема тут не работает?
Но если бы такое требование было, а мастер-тиорема
у нас можно пользоваться, напоминаю.
Не работает, потому что...
Нет, если вы...
Нет, если, например...
Скажем так, если мы в явном виде говорили на паре,
что нельзя пользоваться...
Ладно, давайте не мастер-тиоремой, чтоб не путаться.
Нельзя пользоваться тем, что там системы Кремля красные
московского.
Нет, там сейчас просили про то, что в этом случае
мастер-тиорема не работала, но ее и применили к задаче.
Она не корректно применялась была.
Ну, если не корректно, мы подумаем.
Как бы, возможно, мы посчитаем, что...
Возможно, какие-то баги мы подумаем, что это слишком
тупая бага, чтобы верить, что вы там вот так
добросовестно заглючили.
Дедлайн закончился, да?
Ну, дедлайн закончился, да.
А можно было мастер-тиорему использовать?
Нет, везде можно было.
Там, кажется, нигде не подходило мастер-тиорема.
Где можно было свести к мастер-тиореме?
Нет, ну где-то...
Ну, не помню.
Может быть, где-то и можно, не помню.
А может и нет.
Нет, нет, смотрите, смысл...
Смотрите, после дедлайна задача сдавать имеет смысл,
но проверяться они будут с, соответственно,
низким приоритетом.
Ну, то есть понятно, что, во-первых, будут...
Ну, как бы, проверяться будут по ссылке, естественно,
в первую очередь, с дедлайном.
Вот.
То есть там...
Ну, то есть, по большому счету, вот, надеюсь, что,
видимо, сегодня уже они будут начать и проверяться.
Вот, собственно, вот.
Вот.
Ну да, ну, как бы дедлайн.
Да.
Соответственно, но потом...
Ну, понятно, что ассистент, который будет это проверять,
он как бы это...
Называется занятой человек, он там еще что-то в этой
жизни не занимается, ну там на пары ходит, и так далее.
Тренируется там, и т.д.
Поэтому, может быть, проверять он будет не всегда постоянно,
но в любом случае он будет проверить актуальные пострелки,
потом только в последней очереди, если ничего нет,
то тогда он когда-нибудь проверит то, что после дедлайна.
То есть, не гарантируешь, что они вообще будут проверены когда-либо?
Нет, когда-либо они, конечно, проверены будут, но, естественно, это уже будет позже.
То есть, единственное такое, что разные детали могут быть, то есть, конечно...
Так что, послать всегда имеет смысл, но просто, скажем так, чем позже вы пошлете,
тем больше шансов, что он проверит это очень поздно,
ну и, соответственно, штраф по баллам.
Так же, соответственно.
Так, ну что? Давай.
Как мы экстракт максимум делаем еще раз, то есть мы...
Ну, смотри, свапаем первый корень сценным элементом вот последним листом, да?
А, и делаем севдал?
Да, ну, нет, во-первых, нет, мы делаем поп-бэк, то есть удаляем этот последний элемент,
и после этого у корня делаем севдал.
Да.
Так, ну еще, еще вопросы?
Вот, еще.
Еще.
Не совсем.
Хотя все остальные кучи действительно будут.
О, видали?
А, ну это так, это уже мелочи, но вот досюда интересно.
И вот.
Разобрали.
Еще перед самой кучей.
Так что вот, так, еще вопросы?
Так вот, я тебя спрашиваю, есть ли вопросы?
Что?
А, кстати, ну да, в свое время скину, да.
Ну, в группу, как всегда куда.
Ну, пока это бессмысленно, потому что мы TeamSort еще не обсудили, мы с этого начнем в следующий раз.
Вопросы не совсем по теме, но у нас будут параллельные алгоритмы?
Смотрите, сформулируем аккуратно.
Курс с таким названием у вас будет в четвертом семестре.
Причем уже без меня.
Вот.
Причем более того, насколько я знаю, это будет скорее всего не математически.
Курс, это будет больше такой...
Ну, сформулируем так.
На самом деле, на третьем курсе у вас должен быть такой предмет, как распределенные параллельные вычисления.
Вот.
То есть параллельные алгоритмы это такая, некоторая подготовочка, где там, ну, вот вы будете хоть что-то делать, хотя бы внутри языка C++.
Что внутри языка C++?
Там тоже есть там всякие треды и так далее.
Ну, и там какую-то параллельность там у себя локально запускать можно.
Ну, вот какие-то вот базовые вещи вы там будете рассматривать.
А потом там будут распределенные вычисления, где-то вы будете реально там на кластерах уже кодить.
Раскодирование считается?
Чего?
Чего раскодирование?
Чего вопрос какой-то был?
Нет?
Так, еще вопросы?
Нету?
Ну, тогда на сегодня все.
Благодарю.
