Так, пора начинать. Начнем с вопроса. Внезапно, что вы думаете насчет этого кода?
Ну, немного предыстории. Я решил немного посмотреть посылки ваши по заданиям и так далее.
Некоторые стали активно пользоваться исключениями. Это на самом деле здорово.
Но хочется как бы разобрать пару ошибок, которые на самом деле студенты каждый год совершают.
И каждый год так или иначе приходится к этому возвращаться.
В общем, что здесь происходит? Я написал функцию f, которая что-то делает.
Потом в какой-то момент у нее происходит что-то опасное.
Ну, в частности, опасный вызов функции g, которая потенциально может что-то бросить.
Я тут ловлю это исключение, а потом пробрасываю дальше. В чем беда?
Все понимают, что это бесполезное действие.
То есть вы поймали исключение, а потом сразу его выбросили обратно.
Грубо говоря, если вы тут не писали try-catch-блок, то программу вы сделаете то же самое.
То есть если у вас из g вылетает исключение, вы его никак не обрабатываете, но просто летит дальше.
Здесь вы написали то же самое, но просто некоторыми дополнительными средствами.
И потенциально замедлили свой рантайм и так далее. Здесь ясно?
То есть написать вот эту штуку это, по сути, то же самое, как если бы вы написали просто вызов функции g внутри функции f.
То есть если вам на самом деле не хочется эту ошибку обрабатывать, то есть если вам не нужно делать никаких лишних действий,
то и, соответственно, лишний раз ловить исключение, потом ее снова перебрасывать, естественно, не нужно.
Потому что это ровно то, как работает программа в нормальном режиме.
Ну и есть еще один более интересный кейс. Выглядит он следующим образом.
У вас есть функция f, которая сама что-то бросает.
И вот это само выбрасывание заворачивается в try-catch-блок, то есть вы в try делаете throw, потом это все ловите и выбрасываете.
Наверное, стоит прокомментировать, так как я это своими глазами видел.
Еще раз, что здесь происходит. Если вы хотите из функции f выбросить исключение, то просто бросайте его и все.
Не надо его бросать, подкидывать, ловить и потом дальше бросать.
Это бесполезно. Если вы уж решили бросить исключение, то бросайте.
Если вам нужно какие-то действия перед выбросом исключения сделать, то сделайте это до throw.
Не надо бросать исключение, потом вспоминать, ой, а я там память не освободил, давайте я в каче, это освобожу память и потом снова выброшу.
Просто сделайте все до throw и все будет работать как надо.
Это была небольшая преамбула.
Теперь давайте вернемся к нашему плану разговора про исключение.
Сегодня мы поговорим, так скажем, закончим разговоры про исключение.
Поговорим про исключение в конструкторах и деструкторах, про гарантии безопасности исключения и то, как писать безопасный код на C++.
Дальше немного поговорим про стандартную библиотеку исключений в языке C++.
Итак, исключение в конструкторах и деструкторах.
В прошлый раз, когда мы заканчивали лекцию, мы говорили, что одним из ключевых преимуществ использования исключения перед, скажем,
например, возвратом кода ошибки является возможность сообщить об ошибке в конструкторе.
Если вы используете возврат кода ошибки, то если у вас что-то идет не так в конструкторе, то у вас нет возможности об этом сообщить пользователю,
потому что конструктор ничего не возвращает.
Но если вы бросаете исключение, то у вас есть возможность из конструктора выбросить исключение и таким образом сообщить пользователю, что что-то пошло не так.
Но тем не менее, есть пара тонких моментов, про которые стоит поговорить, когда мы говорим про исключение в конструкторах.
Начнем с вот такого кода.
Есть у него структура A, и у нее есть два поля.
Одно имеет тип Вектор, второе имеет тип Сравоуказатель на int.
Ну и что я делаю? Я свожу дефолтный конструктор, который инициализирует вектор из ста элементов,
ну и дальше я сохраняю в ПТР указатель на динамическую область памяти.
То есть выделяю в динамическую область памяти некоторый кусочек и сохраняю указатель на него в ПТР.
И дальше я внутри тела конструктора, например, вызываю функцию F, которая чисто теоретически и потенциально может бросить исключение.
В чем потенциальная проблема?
Да, при этом у меня еще есть написанный деструктор, который вызывает далить ПТР.
С Вектором, естественно, ничего делать не надо, потому что деструктор для Вектора вызовется автоматически.
Что здесь может пойти не так? Догадки может какие-то есть.
Ну у меня же есть деструктор.
Ну в целом да, в общем правило здесь такое.
Дело в том, что если у вас конструктор бросает исключение, то объект считается не созданным.
То есть если конструктор не завершил работу все по какой-то причине,
ну там классическая причина, из конструктора вылетело исключение,
то считается, что в программе вашего объекта создана не было.
Ну, понятно, если конструктор разработMM для конца, то объект создан не до конца.
А следовательно, если объект не был создан, то и деструктор для него вызванock не будет.
Понятно?
Если объект создан не до конца, то есть его конструктор выполнился не полностью,
то и деструктор для такого объекта вызывать чисто теоретически опасно.
Деструктора для него вызывать нельзя.
То есть если у вас объект не создан до конца, то уничтожать его, естественно, нельзя.
Поэтому здесь возникает проблема утечки памяти.
То есть мы выделили память в списке инициализации для APTR.
Дальше у нас f бросило исключение, объект as был создан не до конца,
но при этом память мы выделили. Беда.
Как мы решаем эту проблему? Как и раньше.
Оборачиваем опасную функцию в try-catch-блок.
В try вызываем функцию f, в cache эту функцию ловим,
удаляем указатель и выбрасываем дальше.
Ну хорошо, эту проблему победили.
Второй вопрос.
Смотрите, у меня помимо APTR в моем классе есть еще и вектор.
То есть у меня класс A состоит из вектора и указателя на динамическую область памяти.
Ну хорошо, динамическую память я освободил.
Вопрос. Что делать с вектором?
Вызвать вектор-деструктора.
Вообще говоря, можно вызывать деструктора у объектов,
но скажем, если у вас есть вектор v, то чисто теоретически можно позвать вот так.
То есть это допустимо.
Но вопрос в другом. Нужно это делать или нет?
Ну короче говоря, ответ нет.
Дело в том, что в этом и заключается смысл раи,
в этом и заключается смысл вот этих классов оберток, которые мы и там пишем.
Вектор, умные указатели и так далее.
Дело в том, что они гарантируют, что для любого созданного объекта
для любого созданного объекта у вас в итоге будет вызван деструктор.
То есть какая здесь логика на самом деле?
Логика следующая.
У вас конструктор A завершился неполностью.
То есть у вас есть объект A, из чего он состоит?
Он состоит из вектора, и он состоит из указатель на динамическую область памяти.
Этот объект был создан неполностью,
поэтому для него деструктор не будет вызван.
Для объекта A как целого деструктор не вызывается.
Но при этом,
при этом, у него есть составная часть, это вектор.
То есть вектор, это часть объекта A.
И вот сам вектор, как часть объекта A, был создан целиком,
то есть это полноценный объект.
Но так, как он был создан,
то для него соответственно будет вызван деструктор.
Все нормально. Понятно?
То есть если у вас внутри класса есть поля,
которые имеют тип sd-вектор или у вас есть поля других классов, то если они были созданы в момент конструирования, то есть
в момент выброса исключения эти объекты успели создаться, то для них будет вызван деструктор.
Короче говоря, общее правило, без оглядки на исключение в конструкторах и так далее, для всех объектов, которые были созданы полностью,
будет вызван деструктор. Вот здесь вектор создаться успел до того, как мы выбросили исключение.
Соответственно для вектора будет вызван деструктор. Объект A не был создан до конца в момент выброса исключения,
поэтому сам деструктор A вызван не будет, и поэтому нам нужно самостоятельно здесь в страйке чблоке вызвать delete.
Окей? Все ясно.
Ну и собственно возвращаемся к морали с прошлой лекции. Не нужно использовать, в общем, уже сейчас на текущем этапе
не нужно использовать динамически выделяемую память. Вот этот сырой указатель, который был использован в предыдущем примере,
вполне спокойно может заменить на умный указатель, например, std.unic.ptr. И тогда все будет работать отлично. Почему?
Потому что если у вас в какой-то момент будет выброшено исключение, то есть смотрите, у вас был создан объект V,
а у вас был создан объект ptr, который является unic.ptr. И дальше, если у вас внутри конструктора F вызывается исключение,
то все будет очищено нормально. Для вектора будет вызван деструктор, так как он успел создаться,
и для умного указателя тоже будет вызван деструктор, потому что он успел в какой-то момент создаться. Все, никаких проблем.
То есть не нужно писать ни деструктора, не нужно писать копирования, перемещения и так далее. Все сделано за вас.
И код автоматически становится безопасным. Пример понятен? Мораль тоже понятна?
Тогда небольшой выточняющий вопрос. Хорошо, у меня в этом классе есть деструктор. Есть у меня в этом классе конструктор копирования?
А как выглядит конструктор копирования для unic.ptr?
Да, смотрите. Деструктор в этом классе есть. Дефолтный деструктор просто вызывает деструктор от всех полей классов.
Давайте начнем с того, что тут есть. Есть ли тут конструктор перемещения?
Конструктор перемещения есть. Потому что если мы не написали свой конструктор перемещения, ну и конструктор копирования,
то компилятор за нас создает перемещение и как оно работает.
То есть просто вызовется перемещение у поля вектора и перемещение у unic.ptr. То же самое с перемещающим присваиванием.
А конструктор копирования создан не будет. В этом классе, в классе A, конструктора копирования нет. Почему?
Потому что одно из полей у вас некопируемое. И это unic.ptr. Для unic.ptr конструктор копирования объявлен как удаленный.
Поэтому конструктор копирования для A тоже будет объявлен как удаленный.
Если вы заводите поле unic.ptr, наверное вы на это поведение рассчитываете.
Если у вас какое-то поле копировать нельзя, то понятно, что и класс целиком копировать, наверное, нельзя.
Все, что тут показано, демонстрирует так называемое правило нуля.
Мы прошли весь цикл эволюции. Мы поговорили про правила трех.
Потом, когда мы поговорили про семантику перемещения, мы поговорили про правила пяти.
И теперь переходим до правила нуля.
В общем, правило нуля звучит следующим образом.
Если вам вдруг в классе нужно реализовать конструктор копирования, конструктор перемещения, перемещающий присваивание,
деструктор или копирующий присваивание, то на самом деле вам это не нужно.
Если ваш класс как-то нетривиально управляет ресурсами, то, наверное, стоит использовать обертки в виде std-vector, std-unique-ptr, std-shared-ptr и не управлять ресурсами вручную.
А если вы вручную не управляете ресурсами, то, значит, вам и копирование перемещения и деструкторы реализовывать не нужно. Понятно?
Короче, правило нуля говорит следующее, что ваш класс управлять ресурсами не должен. В общем, делегируете это все необходимым классом-оберткам.
Единственное место, где вам возможно нужно реализовать конструктор копирования, перемещения или деструктор, это если вы пишете один из этих классов.
Вот если вы пишете вектор, который вам нужно будет писать в третьем задании, вот там нужно писать свои перемещения и копирования.
Если вы пишете не вектор и не умный указатель, грубо говоря, то никакие там конструкторы копирования и так далее вам не нужны.
Ну теперь про совсем плохую ситуацию, про исключение в деструкторах.
Ну хорошо, там разобрались исключения в конструкторах и так далее.
Что если у меня бросающий деструктор? Ну, снова пример. У меня структура A нормально создалась, то есть у меня выделилась динамическая память,
у меня создался вектор, и время жизни объекта A подошло к концу.
Вот вызывается его деструктор, и снова он вызывает функцию F, которая потенциально бросает исключение.
Ну понятно, что если мы это исключение не обработаем, то мы не дойдем до строки deletePtr, и у нас произойдет утечка памяти.
То есть если у нас вылетит исключение из деструктора, то деструктор отработает не до конца, и соответственно delete вызов не будет.
Это понятно. Ну и как проблему это решить? Ну достаточно просто.
Снова мы оборачиваем функцию F в tri-catch-блок, то есть говорим, что вызов функции F потенциально опасен,
мы это исключение ловим, удаляем указатель и пробрасываем исключение дальше.
Видит ли кто-нибудь здесь потенциальную проблему?
Снова давайте вернемся к коду. Ну проблему кроме, скажем, какого-то уродского кода, который дублирует код,
что мы и в каче делаем delete, и потом вне кача делаем delete, это просто необходимость.
Если абстрагироваться от чисто эстетических чувств, кто-нибудь понимает, в чем может возникнуть проблема.
Например, вот в таком коде. У меня есть функция H, я создаю внутри функции H объект A.
У объекта A известно, что его деструктор может бросить исключение.
Я вызываю функцию H, которая тоже может бросить исключение.
Что еще раз? Не, деструктор это будет вызван.
Нет, подождите, а в какой момент вызывается деструктор?
Деструктор вызывается, когда вы выходите из скопа, из области действия.
В момент вызова функции G, A существует, для A деструктора не будет вызвано.
Давайте по порядку.
Сценарий такой. Как работает функция H?
Функция H создает объект A.
Дальше функция H вызывает функцию G, которая потенциально бросает исключение.
Вот допустим, H бросает исключение. Что происходит при выбросе исключения?
Понятное дело, там завершается G, так как мы здесь функции H не обрабатываем исключение, то есть завершается H.
Что происходит перед завершением H?
Это было бы печально при завершении функций.
Короче, вызывается деструктор просто. Уничтожаются локальные объекты,
ну и при уничтожении локальных объектов вызываются их деструкторы, если это классы.
Ну и смотрите, у меня G бросила исключение, дальше началась размотка стека,
и деструктор A тоже бросил исключение. И теперь у вас что?
У H вылетело два исключения вместо одного.
Все понятно?
Ну а, собственно, если у вас из функции вылетает два исключения, то по стандарту это DefinedBehaviour.
Ну то есть просто неопределенное поведение.
Ну здесь, а что если вам на самом деле внутри функции G нужна A? То есть я вызываю G от A.
То есть если вам нужно создать объект A, обязательно до G.
Ну это будет печально.
Поэтому история следующая.
Если у вас из одной функции вылетает два исключения, то это DefinedBehaviour.
К такому компилятор не готов.
Соответственно, бросать исключение в деструкторах опасно.
Но вообще говоря, здесь все понятно.
Ну а не бросаем исключений из деструкторов, потому что если деструктор이다 бросит исключение
то если у вас так случилось, что кто-то бросил исключение и у вас начинает разматываться стег
и в этот момент из вашего деструктора вылетит исключение, то у вас из функции полетит два исключения.
И короче говоря, никак бы не обработать. Все будет печально.
Вот. Поэтому мы не бросаем исключения из деструкторов.
Вот.
Если коротко, то так.
На самом деле вы не можете бросить исключения из деструкторов не потому, что
запрещено бросать два исключения одновременно, а просто потому, что в современных плюсах
все деструкторы автоматически помечаются как noexcept.
Давайте просто проговорим, что начиная с C++11 все деструкторы автоматически помечаются как noexcept.
Мы говорили про значение ключевого условия noexcept. Если вы какую-то функцию помечаете noexcept,
то это означает, что вы гарантируете компилятору, что эта функция не бросает исключений.
Если вы из этой функции бросаете исключения, то вызывается автоматическое завершение программы sd terminate,
то есть без размотки стека и так далее. Соответственно, если вы бросаете исключения из деструкторов,
то на самом деле до выброса двух исключений не доходит, то есть компилятор просто вас сразу убивает.
То есть вы бросили исключения из деструктора, вы нарушили контракт.
Условно компилятор за вас пообещал, что вы ничего не будете бросать, и вы бросили.
Вопрос, а вот что если прям хочется бросить исключения из деструктора?
Здесь написано noexcept false. Условно, если вы хотите бросить исключения из какого-то деструктора,
то вы просто должны пометить, что ваш деструктор noexcept false.
И тогда чисто теоретически вы можете бросить исключения из деструктора.
Но опять же, повторюсь, так делать не стоит.
Это тоже не совсем правда. Существуют кейсы, когда вам нужно бросить исключения из деструктора,
причем это можно сделать, когда у вас уже летит какое-то исключение, но я сейчас не готов это обсуждать.
Если интересно, то можете пройтись по ссылке и почитать, что для этого нужно и как это все работает.
Да, сразу скажу, что, ну давайте, не знаю, сработает.
Ладно, забьем. Там есть две функции. По этой ссылке есть две функции.
Есть std-uncode-exception и есть функция std-uncode-exceptions.
Так вот, вам нужна вторая версия, так как первая считается устаревшей.
На всякий случай. Дальше? Хорошо.
Ну и давайте поговорим про гарантии безопасности исключений.
Попробуем формализовать, что такое безопасный код.
Когда вы говорите, что ваш код безопасный, вы должны как бы на что-то сослаться.
Вы должны в некотором смысле пояснить, в каком смысле ваш код безопасный.
То есть код может быть безопасным с точки зрения, что он в принципе никогда не приводит к ничему плохому.
То есть у вас код никогда не бросает исключения, никогда не приводит к undefined-behavior и так далее.
Ваш код может быть безопасным в том смысле, что если пользователь, который пользуется вашей функцией или вашим классом,
корректно обработает исключения, то все будет нормально.
Ваш код может быть небезопасным в том смысле, что если у вас внутри что-то пошло не так,
то это значит, что во всей программе все идет не так, и ее можно только перезапустить.
Дальше ее никак не восстановить.
Естественно последний случай отвратительный, поэтому давайте поговорим про то,
какие гарантии должен давать ваш код и как их собственно обеспечить.
Более-менее существует три гарантии безопасности.
Первая гарантия безопасности – это гарантия отсутствия исключений.
Она самая понятная.
Если у вас есть гарантия отсутствия исключений, то ваша функция или ваш метод класса гарантирует,
что у него отсутствует исключение, значит, что он в принципе никогда не бросает исключений.
Вот и все. Все просто.
Например, у стека есть метод size.
Метод size никогда не бросает исключения.
Поэтому его, во-первых, можно пометить noexcept, во-вторых, он удовлетворяет строгие гарантии безопасности.
Если мы рассмотрим конструктор копирования стека, то конструктор копирования стека не удовлетворяет строгой гарантии безопасности.
Понятно почему.
Например, почему конструктор копирования у стека не может давать гарантию отсутствия исключений?
Ну да, банально может опять же не хватить памяти.
То есть при выделении памяти, понятно дело, что если вы попросили создать стек из миллиона объектов
и ему не удалось выделить миллион объектов, то он сообщает пользователю с помощью исключения, что этого ничего не получилось.
Так, у меня, кажется, были демки.
Про остальные гарантии безопасности поговорим на примерах.
Так нормально видно?
Про гарантию отсутствия исключений поговорили.
Давайте еще пару примеров.
Например, метод swap.
Вот метод swap в стеке может давать строгую гарантию отсутствия исключений.
Почему? Потому что в чем заключается swap двух стеков?
Сваб двух стеков заключается в том, что мы свапаем размеры стека,
свапаем вместимости стеков и свапаем их указатели на массивы.
То есть тут происходит просто свап примитивных типов, то есть int, int и указатель на int, например.
Поэтому тут свап, короче говоря, в таких ситуациях никогда не генерирует исключения,
поэтому мы можем пометить new except и гарантировать, что наш свап никогда не бросит исключения.
Также операция перемещающего присваивания тоже может давать гарантию отсутствия исключений.
Каким образом это, например, можно сделать?
Например, можно вызвать конструктор перемещения от other
и дальше тот временный объект, который мы создали,
у него вызвать метод swap с нашим текущим объектом.
Вот такая реализация операции перемещающего присваивания в одну строчку называется moving swap idiom.
То есть перемести и swap-ни.
Короче говоря, что тут происходит?
Как правило, когда вы реализуете перемещающие присваивания или копирующие присваивания,
у вас происходит дублирование кода. Все писали, да?
У вас происходит дублирование кода в том смысле, что вам нужно создать новый объект и удалить старый объект.
То есть по сути вы заново переписываете деструктор и заново переписываете конструктор.
И все это делаете в операции перемещения.
Вот тут это все можно сделать в одной строке с помощью следующего трюка.
Вы вызываете конструктор, то есть создаете временный объект с помощью конструктора перемещения.
То есть тут происходит создание нового стека, то есть того стека, который вам нужен.
Ну и дальше вы просто swap-ите этот временный стек с текущим стеком.
Что у вас происходит? Содержимое other оказывается в Visi, то есть в вашем стеке.
А, ваше старое содержимое оказывается во временном стеке.
И когда завершается этот строк, что происходит?
Временный стек уничтожается и вот все ваши старые данные тоже уничтожаются.
автоматически вызывается деструктор. Трюк понятен?
Ну и соответственно, если у нас, скажем, конструктор перемещения не бросает исключения,
и swap, как мы написали выше, не бросает исключения, то, понятное дело, что такое перемещающее
присваивание тоже исключения бросать не может.
Теперь давайте поговорим далее.
Базовая гарантия безопасности говорит следующее.
Она не обещает, что вы не будете бросать исключения.
Может так случиться, что ваша функция в каких-то моментах может бросать исключения.
Но при этом необходимо гарантировать хотя бы базовую гарантию безопасности.
Что она означает? Она означает, что если у вас из функции или из класса в какой-то момент
выбросилось исключение, то, первое, никаких утечек памяти, никаких утечек ресурса не произошло,
и во-вторых, все ваши классы, все ваши объекты и так далее, в целом ваша программа
находится в согласованном состоянии.
То есть вы пользуетесь каким-то классом, вы у этого класса вызвали какой-то метод,
и этот метод сказал, что что-то пошло не так.
Если вы эту ошибку поймали, и после того, как вы эту ошибку поймали и обработали,
вам этот класс гарантирует, что этим классом можно спокойно продолжать дальше пользоваться.
То есть у него внутри ничего не испортилось, у него внутри ничего не испортилось.
Вашу программу можно чисто теоретически как-то вылечить.
Давайте пример приведем, тут может быть не совсем до конца понятно.
Рассмотрим операцию копирующего присваивания.
Понятно дело, что когда мы делаем копирующие присваивания, у нас может возникнуть исключение.
Но опять же, почему? Потому что мы тут как минимум должны выделить новую память.
Что мы тут делаем? Мы говорим, что наш размер теперь равен размеру другого стека,
наш вместимость тоже равна размеру другого стека.
И мы удаляем старый буфер, выделяем память для нового буфера,
и дальше в цикле копируем содержимое другого стека в наш новый буфер.
Понятно дело, что у этой операции присваивания нет гарантии отсутствия исключений.
Я утверждаю, что у нее нет даже базовой гарантии безопасности.
Я утверждаю, что если в какой-то момент что-то пойдет не так, то этим стекам в принципе нельзя будет пользоваться.
Ваша программа полностью похеренная, с ней ничего нельзя будет сделать. Почему так?
Давайте начнем с анализа того, какие строчки тут опасные.
34, 35, 36 строки, они не опасные.
37 я поняла, давайте проговорим здесь.
Тут просто происходит присваивание одного примитивного типа в другой, это безопасно.
Тут тоже присваивание примитивного типа в другой, это безопасно.
Что происходит, когда я вызываю delete-буфер?
Освобождение памяти, это не полный ответ.
Даже это не полный ответ, не туда копаете.
Когда я вызываю delete, что в первую очередь происходит?
Вызвать деструктор, да.
Опять же, стек теоретически может хранить себе строчки, другие вектора и так далее.
Поэтому прежде чем освободить память, отдать ее обсерсионной системе, нужно для всех объектов вызвать деструктор.
И delete здесь проходит по всем элементам и вызывает деструктор.
Но мы говорили, что деструкторы не должны бросать исключений, поэтому мы тут верим, что деструктор ничего не бросит.
Даже если деструктор что-то бросит, то нашу программу убьют и мы с этим ничего не можем сделать.
А вот в третьей седьмой строке действительно опасно.
В третьей седьмой строке снова мы выделяем память, тут может что-то пойти не так.
Тут есть еще один момент, кто понимает.
Допустим, у меня память просто море.
Просто куча памяти, у меня чистая система, я запускаю программу и выделяю 5 интов.
Не 5 интов, а просто 5 легких объектов.
Вот я утверждаю, что эта строчка все равно будет опасной, даже если у меня памяти просто дофига.
Что еще здесь может пойти не так?
Из чего состоит new?
Что происходит, когда я вызываю new?
Во-первых, выделяется память, а во-вторых вызывают конструкторы для каждых ячеек.
То есть когда я вызываю new, то у меня помимо того, что выделяется память,
еще вызывают конструкторы.
А вот конструкторы уже могут бросить исключения.
Поэтому тут необходимо быть параноиком.
Конструкторы тоже могут чисто теоретически бросить исключения.
В третьей седьмой строке выбросилось исключение.
Что не так? В чем проблема?
Почему стеком в принципе нельзя будет пользоваться?
Ну ладно, не выделилось, не выделалось, что бухтеть.
Да, отлично. Этот стек врет о своем состоянии.
Просто вот врет.
Смотрите, если у вас в 37 строке вылетело исключение, то в каком состоянии у вас находится стек?
У вас находится состояние, что он говорит, что у него other size равен 10.
И здесь тоже равно 10.
То есть ваш стек говорит, что у него 10 элементов,
и что у него памяти выделено под 10 элементов.
Но при этом реально у него какая память?
Да никакой у него памяти нет, мы ее удалили.
Все, и соответственно у вас нет возможности в принципе это восстановить.
Вот вопрос.
Допустим, у вас есть стек, который утверждает, что у него размер 10,
что у него есть память под 10 элементов,
на самом деле у него там в памяти лежит какой-то мусор.
Как такой стек исправить снаружи?
Никак не исправить.
Чтобы вы не сделали, вы работаете с неволидной памятью.
Это во-первых.
А во-вторых, когда у вас будет вызываться деструктор этого стека, что произойдет?
Двойное удаление.
То есть у вас память была удалена здесь.
Например, когда вы будете вызывать деструктор стека,
у вас эта память снова попытается удалиться,
а это как бы undefinedBehaviour снова.
Все, то есть этим стеком в принципе нельзя пользоваться,
и вы исправить это как пользователь не сможете.
Поэтому этот метод не обладает даже базовой гарантией безопасности.
Это понятно?
Отличие базовой гарантии безопасности от отсутствия гарантии безопасности заключается в том,
можно ли вашим объектом дальше пользоваться или нет.
Ну и в 39-й строке то же самое.
То есть чисто теоретически,
операция присваивания может бросить исключение.
Например, вы присваиваете один вектор к другому вектору вот здесь.
Ну и снова при присваивании одного вектора к другому
у вас может быть выброшено исключение.
И тут то же самое по сути.
На самом деле тут более легкая ситуация.
Она заключается в том, что у вас стек просто-напросто врет о размере.
То есть так-то у него и память нормальная и так далее.
Но вообще говоря, тут тоже беда.
Все понятно?
Вопросы есть?
Хорошо, этот код небезопасный.
Значит, как переписать этот код так, чтобы он давал хотя бы базовую гарантию безопасности?
Ну вот, например, вот так.
Ну что можно сделать?
Какая у нас тут проблема?
Проблема у нас была в том, что к моменту 37-й строки,
то есть тот момент, когда у нас потенциально может быть брошено исключение,
у нас объект находится в несогласованном состоянии.
В неправильном состоянии.
Поэтому возможное решение заключается в следующем.
Давайте просто-напросто следить за тем,
чтобы в каждый момент времени у нас стек находился в нормальном состоянии.
Ну вот как это можно сделать?
Ну, например, так.
Сначала мы удаляем старый буфер.
Удаляем старый буфер и сразу говорим, что буфер равен 0PTR.
Ну, точнее не так.
Мы удаляем старый буфер и сразу приводим наш стек в нормальное состояние.
То есть так мы удалили старую память, мы говорим, что теперь мы ни на что не указываем,
размер у нас 0 и capacity равен 0, окей?
Все, мы привели стек в согласованное состояние.
Ну а дальше мы делаем все, что хотим.
Ну вот, например, говорим, что буфер равно newT и так далее.
И если тут выбросить исключение, то все нормально.
Ну, выбросить исключение и просто мы его во внешнем коде обработаем
и просто заметим, что наш стек стал пустой.
Ну, как бы печально, но все равно этим стеком можно будет продолжить пользоваться.
Понятно?
Стек свое внутреннее состояние, свои внутренние инварианты никак не нарушает.
Окей, допустим, нам удалось выделить нормальную память,
и теперь мы вполне о себе можем установить новое capacity.
Согласны?
Все, выделение памяти прошло успешно.
Мы теперь назначаем capacity.
То есть у нас теперь capacity равен реально выделенному буферу,
size по-прежнему равен 0,
потому что мы реально его ничем другим не заполнили.
Ага.
Ну и дальше мы делаем следующий трюк.
Мы в качестве счетчика,
в качестве счетчика Cyclofor
используем непосредственно сам size стека.
То есть на каждой итерации,
то есть в начале каждой итерации у нас size
содержит реальное количество
успешно скопированных элементов.
Ага.
Ну то есть если мы успешно скопировали элемент,
то мы увеличиваем size.
Снова успешно скопировали элемент, увеличили size.
Если в какой-то момент у нас возникло тут исключение,
то снова нас это не беспокоит.
Почему?
Потому что память выделена,
capacity хранит реально
сколько ячеек памяти у нас выделено,
а size хранит реально сколько у нас элементов было скопировано.
Понятно?
То есть таким образом мы
обеспечили базовую
гарантию безопасности.
Вопросы по коду этому есть?
Окей.
Ну и наконец,
строгая гарантия безопасности
это про следующее.
Ну, снова,
допустим, мы не можем гарантировать,
что наш метод или функция не бросает исключений.
Так вот,
строгая гарантия безопасности говорит следующее,
что мы гарантируем,
во-первых, мы даем базовую гарантию безопасности,
то есть нашим классам можно будет пользоваться.
А во-вторых,
что самое главное,
это то, что если вдруг функция или метод
завершилась неуспешно,
то вся наша программа,
ну или весь наш класс,
находится ровно в том состоянии,
в каком он был до вызова этого метода.
Понятно?
То есть если вызывать какой-то метод,
если метод дает вам строгую гарантию безопасности,
то этот метод говорит следующее,
либо я завершаюсь успешно,
либо я завершаюсь неуспешно,
но при этом все остается как было.
То есть как будто бы ничего не произошло.
Понятна разница
между базовой гарантией
безопасности и гарантией
безопасности. Базовая гарантия безопасности вам говорит следующее,
что ваш стэк или ваш класс
находится в нормальном состоянии,
но в каком состоянии? Не понятно.
То есть чисто теоретически ваш стэк может опустеть,
как было в примере здесь.
Если что-то пошло не так,
то ваш стэк в нормальном состоянии,
но он опустел по какой-то причине.
Если бы стэк давал
строгую гарантию безопасности,
то он бы сказал, что хорошо.
Если присваивание не получилось,
что стэк содержит ровно те же элементы, что и до этого,
ни больше ни меньше.
Логически понятно разницу?
Окей.
Давайте попробуем, да, и соответственно понятно
тоже, почему вот этот код не дает строгой гарантии
безопасности.
Опять же, мы очистили стэк, потом вызываем new.
Если new выбросил исключение, то пользователь видит,
что у него стэк опустел.
Ну, естественно, это не то состояние, в котором
он отдавал нам стэк.
Как обеспечить строгую гарантию безопасности?
Ну, например, вот так.
Собственно, предложение заключается в следующем.
Давайте просто-напросто возьмем и вот эти два блока,
в котором мы что-то очищаем, то есть что-то назначаем
в буфер size и capacity, и в то место, где мы реально
выделяем память и производим копировки, просто поменяем
их местами.
Что у нас тогда получится?
Мы выделяем новый буфер и сохраняем его в отдельную
переменную.
Если у нас тут что-то пошло не так, то ну и ладно.
Но что пройдет, если у меня в 71-й строке выйдет исключение?
У меня стэк останется в прежнем состоянии, потому
что я состояние стэка не поменял, я еще со стэком
ничего не успел сделать.
Понятно?
Окей.
Идем дальше.
Дальше я в этот новый буфер, который выделил отдельно,
в этот новый буфер копирую содержимое вот этого other,
которое мне передали в качестве параметра.
Что пройдет, если тут вылетит исключение, я его не обработаю.
Вот почему я тут написал эту обработку?
Да, потому что если тут вылетит исключение, то мой
стэк по-прежнему останется в правильном состоянии,
то есть в нормальном состоянии.
То есть я у стэка самого ничего не изменил, но при этом
у меня произойдет утечка памяти.
Вот чтобы не отпустить утечки памяти, я оборачиваю
вот этот потенциально опасный участок кода в tri-cache-блок
и в каче просто-напросто удаляю новый выделенный буфер
и все.
Ну и перебрасываю исключение дальше.
И вот наконец мы доходим до 80-й строки.
Что произошло к моменту 80-й строки?
У меня выделился новый буфер, и я успешно все содержимое
other скопировал новый буфер.
Понятно?
Ну и что теперь?
Ну теперь я могу спокойно просто-напросто взять и
обновить мой стэк, сказать, что я теперь удаляю старый
буфер, говорю, что буфер равен новому буферу,
сайс равен новому сайзу, capacity равен тоже новому сайзу
и все.
Кажется, что мы добились строгой гарантии безопасности.
Потому что в какой бы момент, то есть тут потенциально
опять же две строки, в которых может что-то пойти не так,
и вот неважно, в 71-й строке что-то пошло не так, или
в 74-й строке что-то пошло не так, у меня стэк от этого
не изменится.
Потому что я изменяю это все только после потенциально
опасных операций.
Вот это копирующее присваивание дает строгую гарантию безопасности.
Ясно?
Нет вопросов.
Ну и примерно то же самое можно сделать проще, например,
если воспользуемся копией ансвап идеомой.
То есть когда мы писали перемещающее присваивание,
то же самое можно переписать и для копирующего присваивания.
То есть трюк абсолютно точно такой же, что мы делаем.
Мы вызываем конструктор копирования, дальше вот
то, что у нас получилось, свапим с this.
Содержимое this у нас удалится, так как оно окажется во
временном объекте, а все, что мы скопировали, окажется
в нашем стэке.
При этом, если у вас конструктор копирования обладает строгой
гарантией безопасности, то ваша операция присваивания
тоже обладает строгой гарантией безопасности.
Понятно?
Ну потому что мы не выполняем свап, мы не выполняем свап
до тех пор, пока у нас вот эта штука успешней отработает.
То есть у нас свап выполняет только в случае, если конструктор
копирования успешно отработал.
Вот как можно обеспечить строгую гарантию безопасности
буквально в одну строчку.
Продолжаем разговор про безопасность.
И мы наконец дошли до момента, чтобы понять, для чего на самом деле нужен noexcept.
Начнем с того, что я пытался рассказать в прошлый раз.
Повторюсь, что эффективный код и безопасный код, вообще говоря, не всегда, а если быть точным, то редко когда совместимы.
У вас есть такая вилка всегда, либо вы пишете безопасный код, либо эффективный код.
Тут далеко за примером ходить не надо, например, вот здесь.
Вот здесь мы обеспечили строгую гарантию безопасности относительно исключений, но при этом утверждается, что этот метод не самый эффективный.
Не самый эффективный в том смысле, что здесь в один момент времени у нас одновременно хранится и новый буфер, и старый буфер.
Мы, по сути, требуем в два раза больше памяти, чем, например, вот такой подход, где мы сначала удаляем буфер, а только потом вызываем новый.
Беда.
Здесь еще раз повторюсь, что у нас в каждом моменте времени, например, в 80-й строке у нас есть как новый буфер, так и старый буфер.
В общем, затрат памяти больше. Это вот такой небольшой пример.
Ну и, соответственно, если вы хотите добиться код какой-то безопасности, то вы используете менее эффективные функции.
Например, если вы хотите, чтобы вектор никогда не выходил за границу массива, и при этом вы хотите, чтобы программа сообщила о том, что вы вышли за границу массива, то вы используете метод add.
То есть у вектора есть метод v.add, который проверяет, вышли вы за границу массива или нет. Если вышли, то бросает исключение.
Но при этом на эту проверку коет лишнее время.
Если вы не хотите, чтобы компилятор за вами следил, то вы используете просто квадратные скобки. Квадратные скобки просто ничего не проверяют, а просто обращаются по элементу, берут указатель на начало массива и обращаются за скрытые ячейки.
Быстро, быстро, безопасно? Ну нет, тут вы уже обязаны сами следить за тем, чтобы там все было безопасно и корректно.
Вот такие вот небольшие примеры, что на самом деле сложно добиться одновременной безопасности и эффективности.
Но при этом noexcept, оказывается, если вы используете noexcept, то в некоторых ситуациях получается одновременно добиться и безопасности, и эффективности.
Пример. Пример следующий. Смотрите. Снова вернемся к стеку.
Допустим, в стеке я хочу написать функцию reallocate, которая просто принимает новые capacity, то есть у стека есть какой-то буфер, есть какая-то выделенная память,
и я вызываю у него reallocate, ну в смысле просто выделяю память другого размера, ну либо большего размера, либо меньшего размера.
Ну это часто приходится делать, когда вы работаете с памятью. Ну окей, как выглядит функция? Я создаю новый буфер.
Если я попросил capacity больше нуля, то я выделяю память с помощью new. Если у меня capacity равен нулю, то я просто возвращаю nullptr.
Дальше я говорю, что у меня есть новый размер, то есть если у меня capacity, новый capacity, он, короче говоря, меньше текущего размера,
то я просто говорю, что у меня размер ограничен new capacity. Если нет, то просто берет старый size.
Ну и дальше я просто-напросто беру и по элементу накопирую все содержимое из старого буфера в новый буфер.
После того, как копирование завершено, я удаляю старый буфер, говорю, что буфер равен новому буферу, size равен новому size, capacity равен новому capacity.
И тут сверху написано, что это очень плохая реализация. Она, во-первых, неэффективна, во-вторых, она небезопасна. Почему?
Давайте начнем с того, почему эта реализация небезопасна. То есть она не обладает, чего она не обладает?
Ну строк гарантии безопасности она точно не обладает.
Так, ну хорошо, в четвертой строке может не хватить места, или конструктор UT может произвести исключение.
Ну окей, ну если тут даже выбросить исключение, то, казалось бы, я мой стэк никак не изменил. Все продолжит работу.
Давайте обратим внимание на седьмую строчку. Тут же теоретически тоже что-то может пойти не так, но в частности при присваивании у вас тоже может возникнуть исключение.
Вот если тут возникает исключение, то что произойдет?
Ну тогда тупо утечка будет. Ну то есть, да, если у вас тут вылетело исключение, то вот этот новый буфер вы никак не освободили.
То есть вы тут чисто теоретически вызвали new, но при этом этот новый буфер не освободили. То есть эта локальная переменная просто уничтожится, ну все, банальная утечка памяти.
Как мы ее поборем? Try-catch, да. Напишем вот такой код. То есть снова создаем новый буфер, говорим, какой у нас новый размер.
Ну и дальше вот этот потенциально опасный цикл оборачиваем в try-catch-блок.
Если у нас вылетело исключение, то в catch-блоке мы удаляем выделенный буфер и пробрасываем исключение дальше.
Казалось бы, ну да, эта реализация обладает строгой гарантией безопасности, но утверждается, ну кто-то тут написал, что она неэффективна.
Почему эта реализация неэффективна? И это уже принципиально новый вопрос.
Как бы вы ускорили данную реализацию? Я понял.
Смотрите, вот вы когда-то жили, ну год назад, жили дома. У вас был дом, и вот там находились какие-то вещи.
Дальше вы переезжаете в общежитие. Ну нет. Вы переезжаете в общежитие и, соответственно, что вы делаете? Перевозите туда свои вещи.
У вас был какой-то компьютер, у вас была какая-то одежда, у вас было что-то еще.
И при переезде, что вы делали? Вы купили новый компьютер, вы купили новую одежду, вы купили новые книги.
И вообще все, что у вас было дома, осталось дома, а все, что вам понадобилось в общежитии, вы купили заново.
Ну вот у меня, собственно, вопрос. Какая у вас стипензия? То есть тут нет никаких криков, возмущений и так далее.
Ну естественно, нет. Естественно, это не происходило. Что происходило при переезде?
Вы переместили компьютер, переместили одежду, переместили и так далее.
Намек понятен? То есть смотрите, у вас есть вот старый буфер, старое содержимое.
Теперь оно вам понадобилось не здесь, а вот здесь. То есть теперь все содержимое вам нужно как бы убрать отсюда и перенести сюда.
Ну естественно, зачем это все копировать, если здесь это уже не понадобится? Естественно, нужно это все переместить.
Перемещение работает эффективнее копирования. Согласны?
То есть в большинстве ситуаций у вас перемещение работает за единицу, копирование работает за линейное время, если у вас объект большой.
Поэтому как сделать из этого кода эффективный код, который работает не за, ну не знаю там, если у вас размер объекта m, а размер массива вот этого m,
то вот этот код работает теоретически за отm, а хотелось бы наверное за отm. То есть просто за единицу заполнить каждую ячейку.
Как исправить? Да, просто взять и переместить. Это уже здесь сделано, вот.
Просто содержимое старого буфера не копировать, а перемещать. Согласны? Тогда у вас в случае тяжелых объектов перемещение будет работать за единицу и при этом старые объекты копироваться не будут.
Вот. Ну и теперь вопрос вам. Этот код обладает, ну то есть мы в прошлом, чуть выше мы поняли, что этот код, вот этот код, обладал строк гарантии безопасности, но при этом он не был эффективным.
Теперь мы здесь заменили копирование на stmove, то есть на перемещение. Вопрос. Является ли этот код одновременно и безопасным, и эффективным?
Что еще-то повторите?
Вот именно это и будет, да. Смотрите в чем беда. Вот у вас был какой-то старый буфер, вы перемещаете его содержимое, ну не знаю, в какой-то новый.
Что вы делаете? Вот у вас есть какой-то объект x, y, z, a, b. Что происходит при перемещении? Вы перемещаете x сюда, то есть здесь становится x, здесь объект каким-то образом удаляется, ну короче тут уже старого объекта нет. Согласны?
Дальше мы перемещаем y сюда, старого объекта тут больше нет. Перемещаем z сюда, старого объекта нет. Перемещаем a и вот тут возникло исключение.
Вот тут мы перемещаем a сюда, возникло исключение. Что делать? Вот этот код говорит следующее. Ну хорошо, если возникло исключение, то я это исключение ловлю и удаляю новый буфер. То есть вот то, что я новое выделал, я просто-напросто удаляю. Ну и продолжаю пользоваться этим. Что не так?
Что не так? Ну они не удалились, они просто опустели. То есть тут исчезла строгая гарантия безопасности. Понятно? То есть у нас старый буфер, он изменился, а именно часть объектов просто-напросто опустела. То есть они оказались здесь, но мы их удалили вместе с новым буфером.
А ячаи не понятны? Беда понятна? Ага. Предлагаю это все исправить вот таким образом. В кейчблоке дописать вот еще один цикл. Давайте я просто-напросто буду в отдельном счетчике запоминать, сколько объектов я переместил. В данном случае я переместил три объекта.
И вот если на очередном объекте у меня произошла беда, то что я сделаю? Перед тем как я буду удалять этот массив, я перемещу все обратно. Я перемещу все обратно, и только после этого удаляю массив. Нормальный план.
Что еще раз? Ну, по времени-то ладно. У нас симпатика все равно будет у отм, тут как бы... Во, да. Проблема второго уровня. Хорошо, вот тут мы перемещали, а возникло исключение.
И решили все вернуть обратно. Ну хорошо, Z вернули обратно, Y вернули обратно, возвращаем X обратно. Упс, исключение. Что делаем? Снова пытаемся обратно все переместить. И так до бесконечности.
Проблема ясна? Если при перемещении у вас может возникнуть исключение, то строго гарантии безопасности вы никак обеспечить не сможете. И вот тут как раз и содержится вот этот самый парадокс между эффективностью и безопасностью.
Перемещение, оно эффективно. Оно для тяжелых классов, для тяжелых объектов работает за единицу. Но при этом, если у вас перемещение потенциально опасное, хоть и эффективное, то никакой строго гарантии вы уже говорить не можете.
Ну вот пример. При перемещении старого буфера в новую у нас может возникнуть исключение, при перемещении обратно из нового буфера в старый тоже может возникнуть исключение.
Поэтому гарантируя, что вы целиком переместите все отсюда-сюда или отсюда-сюда, никак не получается. Беда.
И решение заключается в следующем. А давайте вспомним, что мы делали с конструкторами перемещения или перемещающим присваиванием. Пора.
Помните, что когда мы писали конструктор перемещения и перемещающий присваивание, мы там писали noexcept. Я говорил, что важно для перемещения писать noexcept.
И вот сейчас на самом деле становится понятно, почему. Дело в том, что в стандартной библиотеке, помимо функции std move,
которая просто делает из объекта временный объект, то есть говорит, что объект должен предвариться временным, есть такая функция, которая называется std move if noexcept.
Что она делает? Она смотрит, является ли конструктор перемещения или перемещающий присваивание, являются ли они noexcept.
Вот если вы дали гарантию, что перемещения у вас никогда не бросают, то происходит move, то есть происходит преобразование к временному объекту.
А если ваш конструктор перемещения или перемещающий присваивание не дает гарантию безопасности, то происходит обычное копирование.
Понятно? Ещё раз повторить или всё. Короче, move if noexcept, он перемещает, если перемещение безопасно, и копирует, если перемещение небезопасно.
То есть таким образом, что у вас получается? У вас получается следующая вещь, что если перемещение noexcept, то всё работает за o от m, и всё безопасно.
Если у вас перемещение noexcept, то всё работает за o от n на n, где n это сложность копирования, и тоже безопасно.
Ну вообще, в стандартной библиотеке C++ упор делается в основном на безопасность. Если есть возможность что-то гарантировать, что что-то работает безопасно, то это скорее будет работать безопасно, чем эффективно.
И вот как раз использование noexcept, это как раз тот момент, когда вы можете действительно гарантировать одновременно и безопасность, и эффективность.
И вот, собственно, пример это показывает. Понятно? Ну вот.
Да, ну давайте ещё раз на всякий случай пройдёмся. Что здесь происходит, зачем нужна функция move if noexcept и так далее.
Мы выделяем новый буфер. Если при выделении памяти у нас выбрасывается исключение, ничего страшного.
Ну хорошо, вылетело исключение. Мы наш стэк никак не изменили. Если мы наш стэк никак не изменили, то мы обладаем строк гарантии безопасности.
Дальше. Мы заходим в этот цикл. Если у нас перемещение noexcept, то есть мы пообещали, что наш класс, который мы сейчас копируем, не бросает исключений, то, во-первых, этот цикл не бросает исключений, и всё нормально.
Во-вторых, это всё работает быстро и эффективно. Всё. То есть код целиком и эффективный, и быстрый. И эффективный, и безопасный.
А если вы не обещали, то есть если вы не давали гарантию, что ваше перемещение безопасно, то тогда здесь происходит просто-напросто копирование.
Ну всё, происходит копирование. Если копирование успешно, то мы идём дальше. Если копирование не успешно, то мы можем спокойно удалить новый буфер и бросить исключения.
Если мы копировали элементы, то старый буфер у нас никак не изменился.
Поэтому снова строк гарантии безопасности, она удовлетворена.
Ага. Ну вот. Вопросы?
Ну окей. На этом про, скажем, ядро C++ или ядро стандартной библиотеки всё. Давайте поговорим про иерархию исключений C++, какие вообще классы исключений C++ есть и зачем они нужны.
Ну тут пара вопросов. В прошлый раз мы делали там штуки типа throw1, throw0, throw2 и так далее. То есть мы бросали объект типа int.
Вот первый вопрос, как вы думаете, нормальный или бросать int? В чём проблема того, что мы бросаем int?
Несодержательный. Да, несодержательный. Ну хорошо, мы бросили int, то есть бросили одно число.
Понятное дело, что в int можно там что-то сохранить, то есть сохранить какую-нибудь информацию.
Например, если бросили единицу, нам не хватило памяти. Если мы бросили двойку, то проблема в конструкторе. Если мы бросили тройку, то что-то ещё.
Но никакой возможности сохранить дополнительную информацию в int у нас нет.
Например, написать текстовое сообщение, что вот на самом деле пошло что-то ещё не так.
Ошибка возникла в такой-то строке, в таком-то файле, в такой-то функции и так далее.
Ну и второй вопрос, а хорошо ли вообще, говоря, ловить что угодно? То есть вот мы писали catch и три точки. В чём проблема?
Ну вообще говоря, да. Ну а что если мы не знаем, что может произойти?
То есть мы хотим обработать ошибку, но при этом мы не знаем, какая ошибка вылетает.
Ну как вы её обгоняете?
Catch многоточие.
Нет, ну catch многоточие вы ловите.
Вот, ну то есть мы не можем понять. Если мы поймали с помощью catch многоточия, мы ловим исключения, но мы не понимаем, что это за исключение.
Вот такая проблема. То есть бросать int и ловить что угодно не совсем хорошо.
Поэтому есть следующие принятые правила приличия.
Мы бросаем не int, мы бросаем не doubly, мы бросаем не bool, даже не строки, а мы бросаем специальные классы исключения.
То есть если вдруг вы пишете код, например, функцию divide, в которой чисто теоретически может возникнуть проблема с делением на ноль,
то будьте добры для этого типа ошибки написать свой класс.
Как он выглядит? Мы пишем класс divisionByZero, сохраняем в поле инфо, то есть некоторую информацию,
что пользователь вызвал в такой-то строчке, в такой-то функции метод divide,
передал такие-то аргументы и возникло деление на ноль.
В конструкторе естественно мы сохраняем эту информацию,
ну и дальше там заводим некоторый метод вот, который позволяет получить информацию о том, что произошло.
Ну и теперь, когда мы вызываем divide, если у нас происходит деление на ноль, мы просто бросаем ошибку divisionByZero.
И теперь пользователь может в кетче сказать, что я хочу поймать divisionByZero, то есть поймать исключение типа деления на ноль,
и при необходимости понять некоторую дополнительную информацию с помощью метода вот.
То есть мы теперь по типу ошибки понимаем, во-первых, что это за ошибка,
а во-вторых, можем получить некоторую дополнительную информацию, которая содержится непосредственно внутри объекта этого класса.
То есть при бросании int, естественно у нас такого добиться не получится.
Ну и собственно проблема с кетч многоточия, как я уже сказал, заключается в следующем.
Хорошо, у нас есть функция divide, которая чисто теоретически бросает исключение divisionByZero.
И мы говорим, что если у нас есть деление на ноль, то мы в лог ошибок выводим это самое сообщение или там,
некоторую дополнительную информацию. Ну хорошо, а что если мы хотим поймать вообще все остальные исключения?
Мы пишем кетч многоточия, то есть мы ловим все остальные исключения, но при этом мы не понимаем,
а что на самом деле произошло. То есть вот тут тоже, наверное, хотелось бы понять, что именно пошло не так,
и возможно там вывести куда-то, не знаю, в консоль или в отдельный файл лог,
или пользователю выйдет сообщение об ошибке, что у тебя вот это пошло не так.
Кетч многоточия этого сделать не позволяет.
Потому что когда вы ловите с помощью кетч многоточия, у вас объекта исключения на руках нет.
Потому что вы не знаете его типа. Проблема ясна?
И чтобы побороть эту проблему, предлагается делать следующую вещь.
Давайте заведем некоторый класс exception, который будет обозначать вообще любую ошибку.
Любая ошибка – это exception.
Мы написали класс exception, задали, например, виртуальный метод what,
мы говорим, что любой exception, любой класс ошибки должен уметь говорить, что произошло.
Мы заводим метод what, делаем его виртуальным, чтобы потомки могли его переопределить.
Дальше пишем наш класс ошибки, который наследуем от общего класса ошибки exception.
И дальше внутри него переопределяем метод what.
То есть exception просто говорит, что произошел exception, произошел что-то.
A division by zero говорит, что конкретно произошло.
Теперь вместо того, чтобы писать многоточие, мы можем делать следующее.
Мы можем ловить exception по ссылке.
Мы помним, что если у нас летит исключение, которое является наследником того, что мы ловим,
то мы его тоже поймаем.
Родитель может поймать наследника.
В данном случае exception является родителем division by zero.
Поэтому exception сможет поймать и это исключение, и это исключение.
Теперь я вызываю у exception метод what, и мне на экран выводится division by zero.
Почему выводится division by zero, а не exception?
Потому что метод what виртуальный.
Понятно?
Виртуальность ровно так и работает.
Если вы вызываете метод через указатель или ссылку на базовый класс,
то у вас реально будет вызываться метод, который соответствует типу брошенного исключения
или реальному типу объекта, а не типу ссылки.
Окей?
То есть если у вас тут реально в этом каче был пойман division by zero,
то при вызове метода what будет вызван метод именно класса division by zero.
Именно потому, что этот метод виртуальный.
Вот именно здесь нам пригодилось это свойство с виртуальными функциями,
с наследованием и так далее.
То есть теперь мы можем ловить любое исключение с помощью класса exception
и спрашивать what и этот what нам будет говорить, что на самом деле произошло.
Идея понятна?
Ну и естественно все, что было написано до этого, это все велосипеды.
И естественно базовый класс exception и так далее, это все есть в стандартной библиотеке.
Давайте в этом поговорим.
В общем, C++ принято, что любая ошибка является наследником стандартного класса std exception.
В стандартной библиотеке в заголовочном файле std accept или exception есть базовый класс std exception.
Он как и в том классе, который был написан на предыдущем слайде,
в нем есть просто виртуальный метод what, который говорит, что произошло.
Дальше есть другие стандартные классы ошибок, которые от него уже у нас следованы.
Например, logic error, то есть логический ошибка, runtime error, ошибка во время исполнения,
badcast, badalloc, badwigptr.
Badwigptr бросает charred pointer, когда вы создаете с помощью неправильного vigptr.
Badalloc бросает new, если не удалось выделить память, и так далее.
В общем, все эти классы ошибок у наследованы от std exception.
То есть какая бы ошибка у вас не была выброшена, вы всегда ее сможете поймать
с помощью ссылки на std exception. Понятно?
Потому что они являются наследником одного общего базового класса exception.
Ну и дальше существует целая иерархия вот этих самых исключений.
То есть от всех этих классов у нас следованы какие-то другие ошибки.
Ну вот в частности есть ошибка std outOfRange.
Она вызывается, когда вы в векторе выходите за границу.
То есть используйте метод add, когда вы в векторе вызываете v.add.
И если вы там выходите за границу массива, то этот метод вам бросает исключение outOfRange.
И вот этот outOfRange у наследован от класса logic error, а logic error в свою очередь у наследован от std exception.
Дальше есть ошибка badanycast, которая на самом деле является наследником просто std badcast, ну и так далее.
Существует целая иерархия ошибок.
Для чего это нужно?
Ну просто-напросто, чтобы вы могли группировать ошибки по смыслу.
Ну например, если у вас функция бросает outOfRange, то вы ее обрабатываете здесь.
Если вы хотите обработать все возможные логические ошибки, не только outOfRange,
вы идете вот во второй блок catch.
Если вам нужно обработать вообще все возможные ошибки во время выполнения программы,
вы пишете std runtime error.
И если у вас ошибка не подходит ни под outOfRange, ни под logic error, ни под runtime error,
то вы уловите любую ошибку с помощью просто std exception.
Ну и контрольный вопрос.
Зачем тут везде написана ссылка?
Чтобы не копировать, но это не самое главное.
Нет, std exception можно создать, он не абстрактный.
Даже если мы не напишем ссылку, то все равно можно будет ловить наследников.
Тогда будет происходить срезка.
Но самое главное, зачем мы ловим по ссылке?
Потому что иначе у нас виртуальные функции не работают.
Если вы тут поймаете просто по значению, то когда вы будете вызывать метод вот у logic error,
у вас будет вызываться метод вот у logic error.
Но если вы хотите, чтобы у вас метод вот возвращал именно то, что содержится в значаемом классе ошибки,
то мы должны ловить его по ссылке.
Потому что с помощью logic error мы можем поймать наследника logic error.
То есть мы хотим узнать, что произошло именно в наследнике logic error, а не в самом классе logic error.
Понятно?
И виртуальность нам как раз позволяет достучаться до метода производного класса с помощью ссылки на базовый класс.
Да?
Ну допустим.
Ну и соответственно, если вдруг вы захотели написать свой класс ошибки, то...
Ну соответственно, естественно вы пишете свой класс ошибки,
то есть для какой-то своей специфичной задачи, например,
вы хотите сообщить всему миру, что у вас там функция бросает исключения,
может теоретически что-то разделить на ноль.
Ну тогда вы выводите свой класс division by 0
и в обязательном порядке наследуете его от одного из стандартных классов ошибки.
Ну например, говорите, что он наследник runtime error.
То есть деление на ноль – это ошибка во время выполнения программы.
Ну и дальше там в паблике вы можете либо переопределить метод вот,
либо не переопределять, если вам это не нужно.
Вот, ну здесь...
Что здесь написано, кто помнит?
Что это такое?
Ну, не совсем.
Кто помнит, что означает эта строчка?
Она означает, мне лень писать конструкторы, используя конструктор runtime error.
Вот и все.
То есть чтобы заново не прописывать все конструкторы, которые там нужны division by 0,
просто говорите, что создать division by 0 можно ровно так же,
как мы создаем объект runtime error.
То есть мы берем класс runtime error и у него берем конструктор.
Вот, вот это все.
А имя конструктора совпадает с именем класса.
Ну и давайте пару таких необязательных моментов.
Вот вопрос такой.
Представьте себе, что у вас есть функция, которая вызывает...
Ну, очень часто вызывает такой вопрос.
Что это такое?
Что это такое?
Что это такое?
Функция, которая вызывает...
Ну, очень часто вызывает потенциально опасные методы или потенциально опасные функции.
И вы хотите навесить try-catch-блок на всю функцию целиком.
То есть вы хотите сказать, что если у вас хоть где-нибудь в функции пошло что-то не так,
то это все нужно обработать в едином catch-блоке.
Естественно, можно сделать следующим образом.
Можно сказать try, открыть фигурные скобки,
и весь код функции написать внутри блока try.
Дальше написать catch и все написать там.
И на этом закончить функцию.
Но это не очень удобно, возникает такая лейсинга.
То есть вы открываете фигурные скобки для функции,
потом открываете фигурные скобки для try-блока.
Соответственно, получается два уровня вложенности.
Ну, чисто эстетически, может быть, не красиво.
Вторая проблема.
Ну, тоже из того же порядка.
Ну, вот смотрите.
Допустим, у меня есть класс B, у которого есть указатель,
который мы предполагаем, который будет вести нас в динамическую область памяти.
Что мы делаем?
Мы вызываем тут newInt, сохраняем это все в указатель.
И дальше создаем объект A, который тоже является полем.
Ну, и тут возникает проблема.
Что если при этом конструкторе, вот здесь, при вызове конструктора A,
у вас вылетает исключение?
Если у вас вылетает исключение, то у вас происходит утечка памяти.
Вот эту память вы не освобождаете.
И при этом возникает вопрос.
Хорошо, а где обработать вот эту ошибку?
Где нужно обработать ошибку, которая вылетает из A?
Вы же try, вы по сути try можете писать только внутри функции.
А здесь вы еще внутри функции не вошли.
Что делать?
Проблема понятна?
Ну, и решение заключается в том, чтобы использовать так называемый function try-блок.
Try-catch-блок можно навесить на всю функцию целиком.
И делать это так.
Вы пишете прототип функции, ну или тип функции.
Дальше пишете try, и только после этого начинаете тело функции.
И вот в такой синтаксе означает, что вы try-блок навесили на всю функцию целиком.
То есть вы в try-блок навесили на всю функцию целиком,
и после того, как функция завершилась, вы выполняете catch-блок,
если реально там было выброшено исключение.
Ну, это просто чисто такая косметическая...
Ну, вот тут это косметическое изменение.
То есть вместо того, чтобы писать try-блок целиком внутри,
вы просто try-навешиваете на всю функцию сразу.
А в случае конструкторов это просто необходимо. Почему?
Потому что вы по-прежнему можете написать try на весь конструктор целиком.
И делать это ровно таким же образом.
Вы пишете прототип конструктора, дальше пишете try,
ну а дальше, собственно, все, что нужно сделать в конструкторе.
Ну, в частности, через двоеточие вы в списке инициализации
инициализируете ptr, инициализируете a,
дальше пишете тело конструктора и так далее.
И теперь, где бы у вас ни возникло исключение,
неважно, в списке инициализации или в теле конструктора,
у вас все это будет поймано вот в этом try-блоке в общем,
и, соответственно, оно окажется вот в этом catch-блоке.
Соответственно, если у вас из a вылетает исключение,
то вы это все ловите в catch-блоке здесь,
удаляете ptr и пробрасываете исключение дальше.
Вот. Все ясно?
Да, ну и, собственно, вот здесь вот во втором примере есть
небольшая проблема.
В общем, это не всегда будет работать корректно.
Короче, подумайте, что здесь не так.
Просто упражнение. Что здесь не так.
Ну и второй короткий бонус.
В прошлом году меня после лекции спрашивали,
я говорил, что когда вы бросаете исключение в метод вот,
вы можете записать какую-то полезную информацию.
Например, в какой строчке произошла ошибка,
в каком месте, в какой функции, в каком файле,
чтобы пользователь получил вполне себе нормальное сообщение об ошибке.
Что в файле main.cpp в функции f,
в строке номер 241 у вас произошла такая-то ошибка.
Пожалуйста, исправьте.
Ну и возник вопрос, а как это делать?
Как составить корректное сообщение об ошибке,
чтобы туда подставилось и имя файла,
подставилось и имя функции, и номер строки?
Естественно, первый вариант – это захардкодить все.
То есть просто написать, что мы находимся в 241 строке,
поэтому в 241 строке у вас возникла ошибка.
Но это как бы использует очень шаткое предположение о том,
что ваш код никогда не будет меняться.
Представьте, что у вас есть тот же самый файл,
и вы там дописали какой-то код.
И теперь во всех местах, где вы это прописали,
вам нужно номер строки изменить.
Изменили название функции, изменили название файла.
Вот вам везде это все нужно тоже изменять.
Так вот в C++, в языке C есть специальные макросы,
которые позволяют подставить это автоматически.
Макросы называются func.
Понятное дело, это имя функции, в которой вы сейчас находитесь.
Line – это номер строки, в которой вы сейчас находитесь.
Ну и файл говорит о том, в каком файле вы тоже сейчас находитесь.
Используя эти макросы, вы можете оставить нужное сообщение об ошибке.
Ну и, как бы это уже дело более современное,
в C++ 20 завезли класс STD source location,
который позволяет все эти штуки получить уже без использования макросов.
Ну ссылка тут приведена.
В общем, если вы хотите в сообщении об ошибке сохранить
какую-то метаинформацию, где это произошло в кумфайле и так далее,
то используйте класс source location или, соответственно,
макросы func line или file.
Продолжим говорить про хэштаблицы.
Знаете, небольшое напоминание.
У нас было простое равномерное хэширование.
И в случае простого равномерного хэширования мы говорили,
что среднее время работы find было у большого от единицы плюс,
ну, напишем, n на m.
Ну и небольшой кусок доказательства, который нам сейчас понадобится.
У нас там что возникало?
У нас там возникала такая сумма, сумма по i от единицы до n,
вероятности того, что h от x, то есть вот тот самый x, который мы ищем,
h от x совпадает с h от x и там, ну, где x это вот набор элементов,
которые уже вставлены в мою хэштаблицу.
Вот. И эта штука у нас была меньше либо равна, чем та же самая сумма,
1 на m или единица, если x и равен x и, если наоборот не равен,
x и равен x. Ну и так далее.
Короче говоря, у нас в доказательстве возникала вот такая вот штука,
и из этой цепочки равенств и неравенств, ну, здесь сам ли стоял равно,
из этой цепочки равенств и неравенств мы пришли к тому,
что у нас средняя длина цепочки, она не превосходит в такой величины,
ну, а из этого следует, что и find тоже в среднем не превосходит в такой величины.
Но затем мы поняли, что простого равномерного кшр не существует,
и сейчас попытаемся мы побороть эту проблему.
И поговорим мы про так называемое универсальное кширование.
Значит, что мы вообще хотим? То есть мы поняли, что простого равномерного кширования не существует.
Во-первых, даже если мы придумаем, как это все оформить,
нам придется хранить очень много памяти для хранения всего лишь одной хэш-функции.
Плюс, если мы будем генерировать нашу хэш-функцию как-то итеративно,
то есть нам приходит один пример, мы запомнили, что мы сгенерировали и так далее,
нам придется придумать хэш-таблицу, которая обходится без хэш-функций.
Ну, такого, естественно, мы себе позволить не можем.
Ну, что мы хотим? Мы хотим найти h, который появлялась под множеством множества всевозможных хэш-функций.
Вот. Давайте я напишу небольшое семейство,
которое обладало теми же свойствами, что и простого равномерного кширования.
То есть, смотрите, чего мы хотели от простого равномерного кширования?
От простого равномерного кширования мы добивались того, что все элементы у нас размазывались равновероятно по всем корзинам.
И вот, собственно, вот этим фактом мы здесь и пользовались.
И мы хотим найти какой-нибудь, уже искать функции не из всего множества всевозможных функций,
а найти какое-нибудь небольшое под множество, которое обладало таким же свойством.
То есть, мы берем из этого небольшого множества произвольную функцию,
и она бы тоже нам как-то равномерно размазывала все элементы по корзинам.
И вот такие под множества есть, они называются как раз-таки универсальными семействами.
Значит, семейство H универсально,
если при случайном равновероятном выборе H из H у нас бы соблюдалось следующее свойство.
То есть, вероятность того, что H от X, ну да, для любого X, Y, принадлежащего к X неравным Y,
то есть для любых двух неравных X, Y из множества ключей, у нас бы выполнялось следующее соотношение.
Вероятность того, что их хэши совпадут, была бы меньше либо равна, чем 1 деленное на m.
В чем смысл этого предъявления?
Мы берем некоторое множество хэш-функций, и наугад берем одну хэш-функцию.
Смотрим, совпали ли для х и у хэши или нет.
Если совпали, то ставим плюсик, если нет, то минус.
Ставим плюсики и минусики для всех функций.
И считаем долю тех функций, для которых у меня H от X совпало с H от Y.
И вот если доля таких функций, что у меня H от X совпадает с H от Y меньше либо равна, чем 1 на m,
то это семейство у меня универсальное, естественно, если это выполнено для любой пары х и у.
Понятно?
Давайте поймем, почему такие универсальные семейства тоже хороши.
Замечание.
Так, эта теорема у нас как-то обозначала, давайте ее обозначим теорема 1, если мы не обозначали.
Замечание.
Теорема 1 верна при замене простого рано-ярного хэширования на универсальное хэширование.
Ну, действительно, почему так?
Смотрите, вся цепочка, которая нас приводила до вот этого момента,
она на самом деле от свойств хэш-функции не зависит вообще никак.
Единственное место, где мы как-то использовали свойства хэш-функции, это вот здесь.
То есть что мы говорили, что вероятность совпадения H от X и H от X и,
она у нас раньше была равна 1 на m.
А теперь по определению вероятность такого совпадения у меня меньше либо равна, чем 1 на m.
Согласны?
То есть вот тут я просто меняю знак равенства на нестрогое неравенство.
Ну и все.
В остальном все то же самое.
Понятно?
Окей.
Окей.
Ну, в общем, рецепт такой.
Мы вместо простого рано-ярного хэширования пользуемся универсальными семействами, и все работает.
Ну, после прошлой лекции, я думаю, вы мне уже не поверите, что такое на самом деле существует.
Поэтому надо как-то доказать.
Ну, давайте приведем пример хотя бы какого-нибудь универсального семейства,
что вот то, что мы определили, на самом деле в природе есть.
Так.
Здесь нормально, если буду писать?
Ну, давайте.
Пример.
Рассмотрим пример для следующего кейса.
Для следующего случая.
В качестве множества всех ключей возьмем систему вычетов по модулю P,
то есть все положительные остатки от деления на P.
Знакомо такое?
Да?
Ну, то есть, если...
Ну, понятно.
В общем, где P – простое число, естественно.
P – простое число.
Так, так, так.
Да, ну и в качестве h возьмем следующее множество.
Ну, множество всех функций hA,B таких, что hA,B от X равно AX плюс B остаток от деления на P
и остаток от деления на M.
Причем A лежит в ZP без нуля.
Тут без нуля.
Вот.
Ну, то есть, это просто множество всех линейных функций без учета нулевого коэффициента.
И потом мы просто берем остаток от деления на P,
и потом дополнительно берем остаток от деления на M.
Ну, понятно, почему берем остаток от деления на M.
Ну, чтобы у нас номер корзины лежал в пределах от нуля до M-1.
Вот.
Ну, тут утверждается, что такое семейство множества вот таких всех функций – оно универсально.
Давайте поймем, почему.
Значит, ну, начнем вот с чего.
Ну, возьмем.
Ну, во-первых, давайте поймем, что нам нужно доказать.
Нам нужно доказать, что какие бы мы x и y не взяли, не равные друг другу,
у нас вероятность h от x равно h от y будет меньше или равно, чем 1 на M.
При условии, что мы h выбираем случайно.
Окей?
Вот если мы h выбираем случайно вот из этого множества,
то нам нужно доказать, что вот это выполняется.
Ну, возьмем.
Возьмем произвольные x и y.
x не равно y.
Ну, наоборот.
Значит, не принадлежат zp, и x не равно y.
Вот. Возьмем произвольные x и y и зафиксируем их.
Вот, давайте для них докажем, что вот это вот выполняется.
Значит, ну, первое, что стоит сказать, наверное, это...
Ну, обозначим...
Вот так.
Ну, возьмем h от x, обозначим за x штрих.
Возьмем h от y, обозначим за y штрих.
Вот. Я утверждаю, что x штрих никогда не равен y штрих...
А, нет. Простите.
Я возьму не такую штуку. Я возьму часть от этой штуки.
Процент p.
И ay плюс b, процент p.
Вот. То есть возьму всю вот эту функцию, но без последнего деления на m.
Я утверждаю, что x штрих и y штрих никогда не равны друг другу.
Ну, кажется, это понятно, но давайте это окажем.
То есть рассмотрим, например, x штрих минус y штрих, чему это будет равно.
Ну, арифметику остатков все знают, да?
То есть я могу остатки спокойно там вычитать друг из друга и так далее.
Ну, в частности, я могу вычесть ay плюс b минус... вычесть ay плюс b и ay плюс b.
Получится просто a на x минус y процент p.
Вот.
Ну, а эта штука уже гарантированно не равна нулю. Почему?
Ну, потому что a не делится на p.
Ну, помните, да?
Я a выбрал специально так, что у меня a никогда не равно нулю.
Если a не равно нулю, то, следовательно, a не может делиться на p.
x минус y, x это остаток вот деления на p, и y это тоже остаток деления на p.
И при этом они не равны.
Поэтому разность x минус y тоже не делится на p.
Ну, а произведение двух чисел, которые не делятся на p, не может делиться на простое число.
Да?
Ну, все.
Ну, то есть они не нулевые, понятно.
Окей.
Второй пункт.
Следующая.
Существует биекция
между
всевозможными х-штрих не равный y-штрих и парами ab.
Давайте сначала про смысл.
Что я хочу во втором пункте?
В втором пункте я хочу показать, что если я выбираю разные ab, разные пары ab,
то я буду получать всевозможные пары x-штрих и y-штрих.
То есть, грубо говоря, мне дали какие-то x и y,
и я утверждаю, что я всегда смогу выбрать такое a и такое b,
что я получу какие угодно, наперед, заданные x-штрих и y-штрих.
Понятно?
Ну, скажем, мне дают, скажем, x равны единице, y равны двойке.
И я из этого хочу сделать x-штрих равны тройке и y равны нулю.
Вот я утверждаю, что я всегда смогу найти такую пару ab.
В общем, для любой такой пары уникальная.
Окей?
Ну, почему это так?
Ну, просто, на самом деле, рассмотрим систему.
Осмотрим систему уравнений.
ax плюс b процент p равно x-штрих.
И ay плюс b процент p равно y-штрих.
Что здесь можно сказать?
Здесь можно, не знаю, воспользоваться каким-то сакральным знанием,
сказать, что вот тут у нас поле, вот, значит, тут линейное уравнение,
матрица невырожденная, поэтому тут система линейных уравнений
дает ровно единственное решение.
Ну, вот тут какая матрица у нас?
x единица, y единица.
x и y не равны друг другу.
И более того, x-штрих не равен y-штрих.
Поэтому эта система невырожденная, она имеет единственное решение.
Ну, если мы были в рамках линейной алгебры обычной.
Согласны?
Ну, на самом деле, в случае остатков тут все то же самое выполняется.
Ну, опять же, в случае, если у меня простой, модуль простой,
то есть все то же самое, но это можно показать в лоб,
например, просто-напросто воспользоваться методом подстановки.
Ну, например, мы можем вычесть одно уравнение из другого,
получить, что a должно быть равно x-штрих-у-штрих,
умноженное на x-у в минус 1.
Ну, опять же, так как у меня, да, по модулю P, все.
Ну, естественно, так как у меня модуль P простой,
то обратное число тоже существует, x-у не нулевое.
Ну, и отсюда, собственно, b, например, равно,
ну, вот, из первого уравнения можно вытащить, можно вытащить b.
Ну, ax-x-штрих, ax-x-штрих, процент b.
Ну, короче, так или иначе, вы пользуетесь либо этим способом, либо этим способом,
то есть мы получаем, что у этого уравнения существует единственное решение.
Окей? Хорошо.
И смотрите, что мы к текущему моменту имеем.
Вот мне приходят какие-то x, y.
А, нет, это еще не заканчивает вот это утверждение.
Тут еще можно, тут еще нужно заметить.
Ну, и заметим, что мощность множества всевозможных пар a, b равно чему?
Ну, наоборот, p-1 на p. Согласны?
Ну, h я могу выбрать p-1 способом, b я могу выбрать p способом.
Поэтому мощность множества всевозможных пар a, b равна вот такой штуке.
Ну, и по удивительному стеянию обстоятельств,
эта штука равна количеству всевозможных пар x-штрих и y-штрих,
таких, что x-штрих не равен y-штрих.
Ну, потому что мы в первом пункте сказали, что x-штрих не может быть равен y-штрих.
То есть все.
Теперь у меня есть два одинаковых по мощности множества.
И для любого x-штрих и y-штрих у меня существует ровно один ab,
который меня переводит ab в x-штрих и y-штрих.
Ну все, биекция.
Теперь смысл того, что мы доказали.
Смотрите, что мы сделали.
Мы сказали следующую вещь.
Мне дали произвольные x и y. Я не знаю, какие.
И мне на самом деле плевать.
Мне дали просто x и y и сказали, что они разные.
Дальше что происходит?
Дальше я выбираю случайную функцию h.
Ну, как происходит генерация случайной функции h?
Ну, я просто выбираю случайное число a и случайное число b.
А так как я выбрал a и b случайно,
то я получил случайную пару x-штрих и y-штрих.
Согласны?
Ну, так как каждая конкретная пара ab дает мне какую-то конкретную пару x-штрих и y-штрих.
Соответственно, если я случайно генеруру ab,
то я получаю случайную пару x-штрих и y-штрих.
То есть по сути получается, что мне дали какие-то числа x и y,
а я из них сделал вообще случайную пару x-штрих и y-штрих,
которая вообще почти никак не связана с исходными x и y.
Понятно?
То есть скажем, вы мне даете два числа какие-то,
а я у себя в голове придумал ab.
И вот вы ни за что не догадаетесь, в какую пару у меня все перешло.
А там?
То есть в этом и заключается свойство этого семейства,
что оно как-то равномерно размазывает все возможные числа по корзинам.
И вот на этом на самом деле можно было остановиться,
но давайте доведем до конца.
В общем, то есть третий пункт.
То есть теперь можем перейти от анализа h и x, y.
И x, y к анализу x-штрих, y-штрих.
То есть у меня теперь уже не интересует x и y,
я теперь могу анализировать тот факт,
что у меня x-штрих, y-штрих выбраются случайно.
Окей?
А x-штрих, y-штрих у меня вот такие.
То есть осталось показать,
что вероятность того, что x-штрих процент m равно y-штрих процент m,
меньше либо равно, чем m.
Вот это мне осталось доказать.
Согласны?
Все.
Ну при условии того, что x-штрих, y-штрих я выбираю как-то случайно и рандомно.
Ну вот.
Ну давайте оценим, чему равна эта вероятность.
Ну снова классическое определение вероятности.
Чему равно всевозможное количество исходов?
То есть чему равно потенциально количество пар x-штрих, y-штрих,
которые я могу получить?
Да, вот p-1 на p, ну все.
То есть количество всевозможных исходов у меня такое.
А сколько из вот таких исходов удовлетворяют вот такому свойству?
Ну это не так просто.
Давайте порисуем.
Ну вот они выглядят так.
Ну тут у меня m, тут 2m, тут 3m, тут 4m, ну и так далее.
Ну и тут где-то p.
Давайте по порядку.
Сколькими способами я могу выбрать x-штрих?
Ну просто x-штрих.
Сколькими способами я могу выбрать?
Ну p, естественно, да.
То есть у меня x-штрих лежит во множестве этих остатков от деления на p.
Ну хорошо, то есть я где-то выбираю x случайно, например вот здесь.
И теперь мне нужно подобрать такой y-штрих,
который бы давал точно такой же остаток от деления на m, что и p.
А какие это y-ки?
Ну которые находятся на одном и том же расстоянии от делителей m.
Ну то есть здесь, здесь, здесь.
Ну логика понятна, да?
У меня x-штрих дает вот такой остаток от деления на m.
Но соответственно, чтобы у меня y-штрих процент m совпадал с x-штрих процент m,
мне нужно чтобы y лежал либо здесь, либо здесь, либо здесь, либо здесь, либо и так далее.
Вот эта точка, естественно, выколота.
Потому что я в первом пункте сказал, что x-штрих не равно y-штрих.
Ага. Все ясно.
Ну все.
Ну и сколько вот таких точек зеленых у меня получается в итоге?
Ну p делить на m минус 1, ну округленное вверх.
Ну почему вверх? Потому что я еще могу вот этот вот неполный кусок,
который целиком не содержит отрезок деления на m, могу тоже захватить теоретически.
Согласны?
В общем, p деленное на m, округленное вверх, минус 1.
Минус 1, потому что вот эта точка у меня выколота.
Ну все. Вот это уже сразу можем сократить.
И получаем p деленное на m минус 1 делить на p минус 1.
Так. Теперь.
Ну все, короче, осталось вот поработать с этим уравнением, и мы все получили.
Ну мне не нравятся целые части, а вам?
Но с ними как-то неудобно работать. Давайте на что-нибудь заменим, на какую-нибудь верхнюю оценку.
Мне кажется, вот это вполне нормальная верхняя оценка вот такой штуки.
Нормально?
Вот.
Но я утверждаю, что это уже и есть 1 на m.
Все.
Ну вот это m деленное на m сокращается с этой единицей,
остается p минус 1 деленное на m и деленное на p минус 1.
Числитель сокращается, остается только m.
Все.
Все? Теперь верите?
Ну вот.
Значит, универсальная семейство существует.
И вот, например, вот оно.
Причем, заметьте, что теперь для хранения одной хэш-функции вот такой,
мне достаточно хранить всего лишь два числа, a и b.
То есть, по сути, я храню два nта и уже таким образом описываю хэш-функцию.
Потом мне очень просто ее сгенерировать случайно.
Ну то есть я генерурую случайное число a, генерурую случайное число b.
И в итоге получаю хэш-функцию случайную, которая обладает вот таким свойством.
Супер?
Что?
А п вам дано по условию сдачи.
То есть если вам сказано, что, например, все числа не превосходят миллиард,
ну вы в качестве п просто берете какое-нибудь простое число, которое больше миллиарда, и все.
Еще вопросы можно?
Ну ладно.
Так.
Давайте, может быть, приведем пример, чтобы закрепить понятие универсальной семейств,
давайте приведем пример функции, которая не является универсальным семейством.
Ну, например, семейство h, которое содержит всевозможные функции, надавайте вот такого вида.
h равно просто ax, процент p, процент m.
Вот такое не является универсальным семейством.
Ну, короче говоря, вот из этого семейства нельзя выкинуть член b.
Если мы избавляемся от члена b, то полученная hash-функция уже не является универсальной.
Ну, как мы доказываем то, что функция не является универсальным?
Ну, просто отрицанием определения.
Определение мы убрали.
Ну, короче, нужно показать.
Мы должны найти x и y.
x не равно y такие, что вероятность того, что h от x равна h от y, будет строго больше, чем 1 на m.
Согласны?
Ну, давайте приведем пример.
Ну, я заранее подготовил.
Сейчас, если вспомню.
Значит, если взять p равно 7, m равно 2, x равно 1, y равно 3, по-моему, то все должно получиться.
В общем, если вы хешируете множество из семи элементов и берете hash-таблицу размера 2,
то для таких x и y у вас не получится вероятности совпадения меньше, чем 1 на m.
Ну, в данном случае меньше, чем 1 вторая.
Ну, как это показать?
Ну, давайте просто рассмотрим всевозможные a и соответствующие значения h от x и h от y.
Ну, a пробегает значения от 1 до 6, так как a не равно 0.
Ну, чему равно h от x при a равным единице?
Напомню, x равно единице.
Ну, 1 на 1 процент p единица, процент m тоже единица.
Согласны?
Ну, давайте выпишем.
Чему мне равна хеш-функция ax?
Процент 7, процент 2.
Вот туда подставляю.
Так, a равно 2.
2 умножить на 1, процент 7, это 2, процент 2 это 0.
3 умножить на 1, процент 7 это 3, процент 2 это 1.
Ну и дальше, на самом деле, легко понять, что все то же самое будет, потому что у меня х единица.
Ну, там, 4 процент 7 это 4, процент 2 это 0.
5 процент 7 это 5, процент 2 это единица.
6 процент 7 это 6, процент 2 это 0.
Вот такие значения.
А теперь давайте посмотрим, какие значения у меня получаются для y.
y равен тройке.
Поэтому получается 3.
3 умножить на 1, это 3.
3 процент 7, 3 процент 2 это единица.
Дальше.
2 умножаю на y.
Получается 6.
6 процент 7 это 6, процент 2 это 0.
Вот, уже есть два совпадения.
Дальше.
Для тройки.
3 ж до 3, 9.
Процент 7 это 2.
2 процент 2 это 0.
Тут не совпало.
4.
4 умножить на 3, это 12.
12 процент 7 это 5.
Процент 2 это 1.
Снова не совпало.
Ну, пока равенство.
Интрига.
Смотрим для пятёрки.
y.
3 умножить на 5, это 15.
15 процент 7, это 1.
1 процент 2, это 1.
Совпало.
Ну и последнее.
6 умножить на 3, это 18.
18 процент 7, 4.
4 процент 2, это 0.
Сколько у меня совпадений h от x и h от y?
4 из 6.
То есть, вероятность того, что у меня h от 1 совпадёт с h от 3, равно 2 трети.
Что больше, чем 1 вторая.
Ну всё, это не универсальное семейство.
Понятно?
То есть, если мне кто-нибудь будет подавать значение 1 и 3, то с большой вероятностью я получу коллизию.
А я хотел, чтобы у меня коллизия была с маленькой вероятностью, то есть с вероятностью хотя бы 1 вторая.
Ага.
Всё.
Вопросы?
Ну не знаю, можно упражнения ставить кое-нибудь.
Доказать, что множество hb, h от x равно x плюс b процент p процент n, тоже не универсально.
Универсально.
Короче говоря, у этой формулы нельзя взять ни b, ни a.
То есть, если мы a отнимаем и привели пример, когда у нас существует пара x и y, что вероятность большая,
то тут тоже самое, но только для x плюс b.
Ладно.
Ну и третий пункт нашего разговора про hash функции, про hash таблицы.
Короче, про метод цепочек мы на самом деле закончили.
Если мы строим динамическую hash таблицу, то, вообще говоря, нам достаточно использовать универсальную hash функцию.
Универсальные hash функции существуют не только для целых чисел, как здесь.
Они существуют и для строк, и так далее.
Для строк используется полинамерный hash, и так далее, и все они универсальные.
Поэтому всё нормально.
То есть мы для каждого множества можем гарантировать, что мы сможем это всё в среднем захашировать так,
что среднее время поиска будет равно o большое от единицы плюс n деленное на m.
Ну и плюс мы помним, мы использовали схему с расширением,
поэтому мы можем обеспечить, что поиск в такой hash таблице всегда будет в среднем занимать от единицы.
Окей.
Здесь всё понятно.
Теперь давайте рассмотрим несколько другую постановку задачи.
Называется она
идеальное
хаширование статического множества.
Задача такая.
Ну вот, когда мы строили hash таблицу методом цепочек,
ну вот до этого мы строили там hash таблицу,
мы на самом деле наперёд не знали, какие нам объекты придут.
То есть нам приходит какой-то объект, и мы должны сразу же определить, в какую корзину его положить.
Нам приходит объект, нам говорят, что нужно его удалить,
и мы сразу должны пойти в нужную корзину и этот объект удалить.
И вот в этих условиях, когда мы заранее не знаем,
какие ключи нам придут,
мы должны как-то построить эффективную hash таблицу.
Вот нам удалось построить hash таблицу,
которая работает в среднем за единицу.
А теперь я ставлю другую задачу.
Дано фиксированное множество х
из n элементов.
То есть мне заранее сказали,
мне заранее говорят, что будут такие элементы,
и никакие другие.
И я хочу это множество захешировать.
То есть я хочу быстро отвечать,
какой это элемент лежит в этом множестве или нет.
Понятное дело, что я могу эту задачу решить старым способом,
то есть просто засунуть это всё в hash таблицу с методом цепочек
и работать с ней.
Но при этом что у меня может возникнуть?
У меня могут возникать коллизии,
чисто теоретически опять же могут возникать длинные цепочки.
Ну, наверное, если мне известно множество заранее,
я могу как-то построить мою таблицу как-то эффективней.
То есть сделать так, чтобы в ней, например, вообще не было коллизий.
И вот как раз такие задачи хеширования без коллизий
называются идеальным хешированием.
Соответственно, задача
будет построить hash таблицу
на множестве х
без коллизий.
Ну, вот этой задачей после первого займёмся.
Так, давайте продолжим.
Так, нам дано некоторое фиксированное множество ключей,
которое естественно является под множеством множества всевозможных ключей,
которые в принципе могут быть.
И нам нужно построить хеш таблицу такую,
что на таком множестве она не даёт коллизий.
То есть мы хотим сохранить все эти элементы
и условно хотим, чтобы операция
find от x работала за θ от единицы в худшем случае.
Ну, операции типа insert и erase, их нет.
То есть множество фиксировано,
и оно остаётся таким до конца жизни хеш таблицы.
Так, ну давайте попробуем как-то проанализировать
и решить эту задачу.
В качестве первого пункта давайте обозначим за c
число коллизий в хеш таблице.
Вот пусть c это общее число коллизий,
которое у меня есть в хеш таблице.
Значит математически число c я могу выразить следующим образом.
Сумма по всем i меньше, чем j.
Индикатор того, что h от x и совпадает с h от x j.
Согласны?
Я просто перебираю всевозможные пары x и y,
да, всевозможные пары x,
и спрашиваю, верно ли что хеш от x этого совпадает с хешом от x этого.
Если хешы совпадают, то есть коллизия.
Я делаю плюс один.
Если они совпадают, то коллизии нет, соответственно плюс ноль.
Вот если я всё это просумирую, то я получу как раз таки общее число коллизий.
Ну и давайте с этим числом что-нибудь сделаем.
Ну, например, оценим среднее число коллизий в хеш таблице размера m.
При выборе h из некоторого универсального семейства хешей.
Из универсального семейства.
Ну, снова, я как бы сейчас, сейчас я буду предполагать,
что я всегда работаю с хешами из универсального семейства.
Да, потому что они существуют и потому что они хорошие.
Окей?
Вот, то есть я случайно выбираю хеш функцию из универсального семейства,
беру хеш таблицу размера m и смотрю, сколько у меня в среднем,
в среднем будет получаться коллизий.
Я просто должен взять среднее число c.
Ну, среднее от случайной величины c.
Значит, это просто средняя сумма, которая была написана там.
h от x и равно h от xj и меньше, чем j.
Средняя сумма, это то же самое, что сумма средних в прошлый раз обсуждали.
h от x и равно h от xj.
А чему равно средние величины, которые понимают значение 0 или 1?
Да, равно просто вероятности вот этого события.
То есть это просто сумма по i меньше, чем j, вероятности h от x и равно h от xj.
Что можно сказать про эту штуку, про эту вероятность?
Да, меньше или равно, чем 1 на m.
Потому что h мы выбрали случайно из универсального семейства.
Средней суммой меньше равно, чем сумма по всем i меньше, чем j, 1 на m.
Но это чему равно? Чему равно количество слагаемых вот в такой сумме?
n на n-1 пополам, да.
Просто мы берем всевозможное количество неупорядочных пар.
Количество неупорядочных пар это n на n-1 пополам, ну и 1 на m.
Все, вот.
Вот такое число коллизий у меня получается в среднем.
Ну а мы-то вроде хотели вообще без коллизий.
Ну и в принципе, смотрите, эта формула уже что-то показывает.
Но в частности она говорит нам то, что чем больше у нас m, тем меньше у нас коллизий.
Логично? Очевидно.
То есть чем больше х-таблицу мы берем, тем меньше у нас вероятность того,
что у нас два объекта попадут в одну корзину.
Ну, кажется, понятно.
Значит, прежде чем доказывать что-то разумное, давайте докажем одну лему из тервера.
Лему Маркова.
Значит, сформирую ее в несколько упрощенном виде.
Потом, спустя какое-то время, на тервере докажете ее в общем случае.
Пусть х случайная величина.
Ну, что такое случайная величина?
Формально я опущу.
Ну, просто скажем, что х это некоторая величина,
которая принимает случайные значения на множестве натуральных чисел.
Окей?
Понятно?
Ну, не знаю, там, подбрасывание кубика.
То есть это случайная величина, которая принимает значения от 1 до 6.
Там количество людей, присутствующих на лекции.
Это случайная величина от нуля до, сколько у вас там может быть.
Соответственно, пусть х случайная величина,
тогда вероятность того, что х будет больше, чем ε,
ну, естественно, ε больше нуля, меньше либо равна,
давайте вот так.
Вероятность того, что х будет больше либо равней, чем ε,
меньше либо равна, чем среднее х разделенное на ε.
То есть смысл этой леммы какой?
Если у вас средней величины мало,
то и вероятность больших значений тоже мала.
То есть если вы знаете, что какая-то величина принимает в среднем значение 2,
то вероятность того, что она будет больше миллиона,
она стремится к нулу, то есть она тоже очень-очень мала.
Понятно?
Но это неформальный смысл такой, давайте докажем.
Очень просто, значит.
Нет, с другой стороны пойдем.
Наоборот, распишем среднее значение х.
Что такое среднее значение х?
Это сумма по всем х,
вероятность того, что х большое равно х.
То есть просто я беру все значения х
и уножаю на вероятность, потом складываю.
Просто усреднение.
Так, теперь оценю это все снизу.
Давайте я возьму и выкину те х, которые меньше, чем ε.
То есть просто возьму только те члены, которые нужны мне.
Вот это вот такие.
Никто не против?
То есть я просто выкинул какие-то члены из этой суммы.
Соответственно, не увеличил сумму таким образом.
Теперь давайте эту сумму еще больше уменьшу.
Ну а в частности скажу следующую вещь.
Ну смотрите, у меня здесь х, все больше либо равны ε.
Давайте я возьму все х и заменю просто на ε.
Согласны, что у меня значение суммы от этого тоже только уменьшится.
То есть возьму ε и вытащу сразу за знак суммы.
В итоге получится вот такая вещь.
Согласны?
Ну а чему равна сумма вероятности того, что х равен ε,
ε плюс 1, ε плюс 2 и так далее?
Ну кажется, это просто равно вероятности тому,
что у меня х больше или равней, чем ε.
Последний переход понятен?
Здесь я просто просуммировал все вероятности того,
что у меня х большое равен ε,
на ε плюс 1, на ε плюс 2 и так далее.
И так до бесконечности.
Ну соответственно, вся эта сумма это то же самое,
что вероятности того, что х у меня больше либо равен, чем ε.
Ну все.
Осталось, понятное дело, разделить обе части на ε
и получим как раз то, чего хотели.
Все, просто.
Окей.
Так, ну и наконец теорема,
которая будет говорить нам следующее.
Пусть h выбрано из универсального семейства
и размер х-таблицы m равен m квадрат.
Ну то есть снова я х-функцию выбираю случайно из универсального семейства
и беру х-таблицу, которая у меня имеет размер n квадрат.
Она имеет квадратичный размер относительно количества элементов,
которые в ней содержатся.
Тогда вероятность того, что у меня есть хотя бы одна коллизия...
ну c это число коллизий, мы за c обозначили число коллизий.
Тогда вероятность того, что у меня есть хотя бы одна коллизия,
меньше чем 1 вторая.
с очень большой вероятностью, с вероятностью больше, чем одна вторая, у меня в кэштаблице не будет коллизии вообще.
Смысл понятен? Давайте тут напишу.
С большой
вероятностью не будет
коллизий.
Доказательства.
Воспользуемся леммий Маркова.
Все условия соблюны. С у меня принимает только натуральные значения, то есть число коллизий это натуральное число, единица больше нуля.
Тогда по
леммий Маркова что получается? Это меньше киберно, чем среднее значение С делено единицу. Согласны?
А чему равно среднее значение С?
А мы вот считали.
Ну это давайте за звездочку обозначим, этот факт из звездочки.
Следует, что это меньше киберно, чем n на n-1
на 2m.
Так, а m у нас n квадрат.
Получается n на n-1 на 2n квадрат.
Доказывать, что это меньше, чем 1 вторая. Я не буду упражнений, окей?
Все понятно.
То есть таким образом, что из этого следует? Если мы хотим взять множество и идеально его захэшировать без коллизий,
то мы берем хэш таблицу размера m равный n квадрат,
хэшируем.
Смотрим, есть ли у нас коллизии или нет. Если коллизии нет, то все хорошо. Если коллизии есть, то
строим нашу хэш таблицу заново. Вот.
Ну и с большой вероятностью мы получим хэш таблицу, в которой коллизии нет. Понятно?
Ну на этом все. Всем спасибо.
Не повелись, ладно. Хорошо. Что смущает?
Что смущает?
Что смущает?
Только это.
Ну тогда посидим, ладно.
В чем проблема?
У вас, например,
ничего, что у нас хэш таблица имеет размер n квадрат, а
ничего, что я хочу хэшировать, например, множество размера миллион.
Ну, то есть, естественно, это не все.
Если мы будем действовать вот по такому плану, то наша хэш таблица будет жрать слишком много памяти, и это беда.
В идеале хотелось бы хэш таблицы, которая потребляет
линейное количество памяти. То есть, мне дали миллион объектов, я хочу, чтобы меня потратил порядка миллиона там байт, чего угодно, бит.
Давайте попробуем это как-то получить.
Иметь одну хэш таблицу
размер n квадрат
дорого.
Идея.
Заведем хэш таблицу
в каждой ячейке которой
мы будем хранить
другую хэш таблицу.
Ну вот, если я буду хранить одну хэш таблицу на все элементы, ну и говорить о том, что, ну вот там, если у меня хэш таблица большая, то у меня вероятность калидий будет маленькая, поэтому это меня устраивает.
Нет, не устраивает. Давайте я сделаю следующую вещь. Давайте я распределю
мои элементы по корзинам,
по некоторому большому количеству корзин, а дальше внутри каждой корзины построю свою хэш таблицу уже размера n квадрат.
Ну то есть, сделаю такую вещь. У меня будет одна
внешняя хэш таблица,
и внутри этой внешней хэш таблицы будет хэш таблица 1, хэш таблица 2, хэш таблица 3,
каждая из которых будет иметь размер n1 квадрат, n2 квадрат, n3 квадрат, ну и так далее.
Окей?
То есть, сначала я раскидаю элементы, раскидаю элементы по корзинам,
а потом внутри каждую корзину сделаю так, чтобы она там была без коллизий.
Ну и тогда у меня в целом вся хэш таблица тоже не будет иметь коллизий. Почему?
Потому что я буду всегда точно знать, где находится тот или иной элемент.
Ну скажем, сначала я иду в эту корзину, а потом внутри этой корзины я за единицу понимаю,
в какой ячейке у меня хранится тот или иной элемент. План понятен?
То есть у меня будет хэш таблица хэш таблиц.
Каждый из внутренних хэш таблиц будет иметь размер n квадрат.
Где n это количество элементов, которые попали сюда.
План понятен?
План понятен?
Возникает вопрос, ну хорошо, вот я взял одну большую хэш таблицу размера n квадрат,
или я взял много маленьких хэш таблиц размера n квадрат.
Вот с чего я взял, что общий размер этой штуки будет меньше, чем тот?
Ну давайте докажем, что это действительно так.
Давайте теорема 3.
Пусть m равно n, h из универсального семейства.
Пусть так-так, так-так, и дополнительно и в корзину и попало n и объектов.
Ну то есть все то же самое, я беру какую-то внешнюю хэш функцию h,
и все элементы распределяю по корзинам.
И пусть там выитую корзину, у меня попало n и элементов.
Вот это условие.
Тогда утверждается следующее.
Тогда среднее значение суммы n и в квадрате,
где i от единицы до n, меньше либо равно, даже строго меньше, чем 2n, кажется.
Ну сейчас поймем.
Понятно?
Утверждается следующее, что если я возьму хэш функцию из универсального семейства,
возьму хэш таблицу размера n, и буду случайно распределить все элементы по корзинам,
то сумма квадратов всех размеров внутренних корзин,
то есть я сказал, что у меня каждая корзина, это хэш таблица размера n квадрат.
Вот если я все размеры этих хэш таблиц просуммирую,
у меня в среднем получится величина, которая не превосходит 2n.
Понятно? То есть в среднем я получу хэш таблицу,
которая не более чем в два раза превосходит размер моего множества.
Круто?
Давайте докажем.
Вот так.
Давайте перепишем n и t в квадрате каким-нибудь способом
типа такого
n-1 в полам
плюс сумма х100m
Ну, кажется, не соврал.
Кажется, что эта сумма действительно совпадает с тем, что написано здесь.
Вот эта двойка с этой двойкой сократятся,
тут будет n и t в квадрате минус n и, и плюс n и.
Все, останется просто n и t в квадрате.
Для чего я это сделал? Давайте для начала поймем, что здесь написано.
Чему равна вот эта штука?
Чему? Просто n. Все видят.
Но если я просуммирую просто количество элементов, которые попало сюда, сюда, сюда, сюда,
то я получу просто n. То есть это не случайная штука, это просто
общее число всех элементов.
А вот это?
Вот это уже интересней.
Смотрите, я беру какую-то корзину
и т.
И смотрю, какое количество всевозможных пар я могу составить из элементов одной корзины.
То есть я беру все элементы, которые попали сюда,
и считаю количество всевозможных пар неупорядоченных здесь.
А потом все это суммирую.
Чему это в итоге будет равно?
У нас не так много вариантов. Мы не так много букв вводили.
C.
Всем понятно, почему C?
Всем ли понятно, почему это в точности равно общему числу коллизий?
Какие объекты у меня образуют коллизии?
Коллизии у меня образуют те объекты, которые попали в одну корзину.
Я смотрю эту корзину и смотрю всевозможные пары здесь.
Потом я беру эту корзину, смотрю всевозможные пары здесь и так далее.
И потом суммирую их количество. В итоге получаю общее число коллизий.
Здорово?
Так, в итоге получается среднее значение, ну двойку давайте сразу вынесу, в итоге получается среднее значение, среднее количество коллизий, плюс просто n.
Ну, среднее значение n-ки просто n.
Ну, то есть неважно, как я там расправляю элементы, у меня общее количество элементов, вот это не меняется.
Так, ну и кажется вот это я тоже считал уже когда-то.
Это n на n-1, деленное на 2m, плюс n.
Вот.
А чему равно m?
По условию у меня m равно n, да?
Ну все, и кажется это, кажется я даже угадал, то есть меньше чем 2n. Понятно?
Ну вместо m-ки ставлю n, сокращается, получается n-1 плюс n, естественно меньше чем 2n.
Все.
Почти все, мы почти готовы, осталось только доказать одно, ну не доказать, а просто привести следствие и пазл сойдется.
Следствие.
Вероятность того, что сумма n в квадрате будет больше либо равно, чем 4n, меньше чем, ну меньше либо равно, чем 1 вторая.
Ну даже строго меньше, чем 1 вторая.
То есть вероятность того, что у меня размер х-таблицы будет огромный, ну в смысле больше чем 4n, очень маленькая, меньше чем 1 вторая.
Ну при доказательстве воспользуемся просто Леммемаркова.
Это меньше либо равно по Леммемаркова среднее значение суммы n в квадрате, деленное на 4n. Согласны?
Ну а среднее значение suma n в квадрате мы считали здесь. Это меньше чем 2n.
Да?
Все.
Все, теорем больше не будет.
Как минимум сегодня.
Все, наконец-то переходим к алгоритму. Смотрите. Сначала в общих словах, потом напишем.
Что я буду делать? Я возьму какую-то hash функцию.
Распределю все элементы по n корзинам.
То есть возьму количество корзин, строго равное количество элементов во множестве х.
Распределю все элементы по корзинам.
Посмотрю, какое суммарный размер внутренней х-таблицы у меня может получиться.
То есть я просто возьму и просуммирую вот такое величину.
Если у меня так получится, что моя hash функция слишком неравномерно распиляет мои элементы,
то есть если у меня вдруг получится так, что suma n в квадрате больше чем 4n,
то я скажу, что у меня такая х-таблица не устраивает. Она слишком большая.
Я построю мою х-таблицу заново.
То есть если у меня сумма квадратов размеров внутренних х-таблиц будет больше чем 4n,
то я забываю про эту х-функцию и строю новую, какую-нибудь аж триг.
То есть выбираю другую случайно.
Снова смотрю, верно ли, что у меня суммарный размер всех х-таблиц не больше чем 4n.
Если он не больше чем 4n, то меня все устраивает, я перехожу к следующему этапу.
Вот на этом этапе, на первом этапе я гарантировал, что у меня размер х-таблицы будет небольшой.
То есть общий размер х-таблицы будет небольшой. Понятно?
Теперь, что я делаю далее?
Далее я просто прохожусь по каждой внутренней х-таблице
и выбираю там свою х-функцию аж ит.
Понятное дело, я говорю, что размер внутренней х-таблицы равен n и в квадрате.
Я смотрю количество элементов, которые попало сюда, говорю, что размер этой х-таблицы будет равен n и в квадрате.
И начинаю процесс подбора х-функции аж ит.
С какой целью я выбираю аж ит? Что я хочу?
Я хочу х-таблицу без коллизий. Согласны?
Ну вот, соответственно, я выбираю аж ит, и если у меня получилось так, что здесь коллизий нет, то я победил.
Если оказалось так, что здесь есть коллизия, то я забываю про эту х-функцию, генерирую ее заново.
И так далее, до тех пор, пока я не получу здесь х-таблицу без коллизий.
Почему я уверен, что я быстро найду такую х-функцию?
А потому что у меня была теорема, которая говорит о том, что вероятность того, что у меня не будет коллизий, больше, чем одна вторая.
То есть с вероятостью больше, чем одна вторая, на каждом шаге я получу х-функцию, у которой нет коллизий.
То есть в среднем примерно за два шага я уже найду нужную х-функцию.
Ну и так далее.
Ну давайте формально опишем то, что я сказал.
Так, алгоритм называется алгоритм ФКС.
ФКС.
Первый автор Фредман, точно.
Он вообще много чего придумал.
Про вторых, прошу прощения, я не знаю.
Вот так.
Алгоритм такой.
Первое.
Строим внешнюю х-таблицу с m равная n.
Естественно выбираем случайную х-функцию h.
То есть процесс построения х-таблицы включает в себя выбор случайной х-функции и дальше распределение элементов по корзинам.
Всего корзину у меня m равная n.
Если сумма ni в квадрате больше чем 4n или больше либо равная, не важно, давайте больше чем 4n, то повторяем один заново.
Если у меня получилась так, что сумма ины в квадрате, то есть сумма квадратов размерах ячеек у меня большая,
ну большая в смысле больше чем 4n, то я говорю, что такая х-таблица меня не устраивает.
Она слишком большая, она потребляет слишком много памяти.
Поэтому начинаю ее строить заново.
Здесь надо написать, что это займет примерно одну-две итерации.
То есть примерно уже на втором шаге я найду нужную х-функцию.
Уже на втором шаге я построю х-таблицу, которая будет маленький размер.
Почему? По теореме 3, ну или следствию из нее.
Следствие из теоремы 3 мне говорит, что вероятность того, что у меня будет сумма квадратов большая, меньше чем 1 вторая.
Соответственно с вероятностью больше чем 1 вторая я найду нужную мне х-функцию.
Все. Ну и дальше третий пункт.
Для каждой ячейки И строим х-таблицу размера Mi равная Ni в квадрате.
И выбираем Hi.
Если в х-таблице И есть коллизии, то повторяем пункт 3 для нее.
Понятно? То есть я беру внутреннюю х-таблицу и перестраиваю ее до тех пор, пока у меня не получится так, что в ней нет коллизий.
То есть я взял какую-то х-функцию, построил х-таблицу размера Mi в квадрате, смотрю, опция, есть коллизии.
Ну что делать? Надо строить заново. Построил заново, смотрю, опция, нет коллизий. Все, закончил работу.
Вот количество таких перестроений у меня сколько будет? Ну тоже примерно 1-2 операции.
Примерно 1-2 операции. Почему? По теореме 2.
Ну теорема 2 нам что говорила? Она нам говорила то, что если я возьму х-таблицу размера N квадрат, то с вероятностью больше, чем 1-2, у меня в ней не будет коллизий.
Вот и все. Ну вот и весь алгоритм.
Ну давайте оценим, что можем оценить. Время строения TOT N равно UOT N средним.
Понятно, почему UOT N средним? Потому что я примерно, то есть в среднем 1-2 раза перестраиваю внешнюю х-таблицу, а внешняя х-таблица имеет размер N.
И дальше примерно 1-2 раза перестраиваю каждую внутреннюю х-таблицу размера Ni в квадрате.
А сумма Ni в квадрате у меня не превосходит чем 4N. Это я гарантировал на первом шаге. Вот здесь. Понятно?
То есть общее время на построение всей х-таблицы UOT N в среднем.
Так, дальше. Память.
Сколько жрет память эта х-таблица? Суммарно.
Тоже TOT N. В среднем или в худшем случае?
В худшем случае. Вот. Тут уже не в среднем, а в худшем случае. То есть у вас гарантированно, то есть гарантированно у вас память уйдет, ну даже тут можно сказать не более чем 5N, 4N.
Почему? Потому что вот я строю х-таблицу до тех пор, пока не добьюсь вот этого.
Ну не вот этого, а обратной ситуации вот этой штуки.
Сумма Ni в квадрате меньше равно чем 4N.
Вот пока я этого не добьюсь, я буду повторять процесс построения снова и снова.
И вот только когда у меня получилось это гарантировать, я заканчиваю построение.
Ну соответственно у меня гарантированно после построения х-таблица имеет линейный размер.
Ну и поиск.
Время поиска.
Тета от единицы в худшем случае.
Понятно почему поиск за единицу теперь. А потому что у меня коллизий нет.
Как выглядит поиск? Ну давайте пропишем.
Find at x.
Значит я сначала ищу нужную мне х-таблицу.
А потом, собственно, возвращаю x равно равно a.
Как мы обозначали b, от hi от x.
Ну вот эта внешняя х-таблица у нас обозначалась буквой b.
b большая.
Понятно, что здесь написано?
Я сначала смотрю в какой корзине у меня лежит объект.
А дальше, так как сама корзина внутренняя b, у меня сама по себе является,
так как сама корзина у меня является х-таблицей,
я внутри этой х-таблицы иду по индексу hi от x.
И смотрю верно лишь, что у меня x совпадает с тем, что там лежит.
Так как у меня х-таблица без коллизий, то, собственно, у меня ответ всегда верный.
Ну и плюс весь find занимает всего лишь одно обращение к функции h от x,
одно обращение к функции cache от x, ну и просто обращение по индексу.
То есть все это занимается за единицу.
То есть никакого линейного поиска по цепочкам и так далее у нас нет.
Понятно?
Ну вот.
Спросить что-нибудь?
По алгоритму есть вопросы?
Ну тогда все, точно все. Спасибо.
