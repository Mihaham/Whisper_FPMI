Окей, сегодня, так опять же, тема довольно большая,
но я скорее так, широкими мазками, идейно расскажу
хотя бы кусочек из того, что происходит здесь.
Частично про это в том числе рассказывал Саша Панин
из Яндекса на семинаре по выбору, но он скорее рассказывал
о своих инженерных вещах, которые связаны, прежде всего, с тем, как это происходит у них в Яндексе
либо в тех продуктах, в тех библиотеках, которые он и его коллеги производят в свободное время
для такого массового общего пользования.
Окей, мы скорее сейчас поговорим про то, что происходит в теории,
но все равно, в любом случае, мне нужно дать вам интродакшн, чтобы было понимание того,
зачем мы вообще это все делаем.
А делать мы сегодня будем, соответственно, изучать распределенную оптимизацию.
Оптимизация, которая происходит не на одном устройстве,
потому что до этого мы с вами все делали все вычисления,
отталкиваясь от того, что у нас есть вот какой-то компьютер,
который умеет решать задачу оптимизации, окей, супер.
Теперь, соответственно, хочется перейти к ситуации,
когда у нас в вычислении делать не одно какого-то устройства, а сразу несколько.
Ну, это связано с тем, что наблюдается сейчас прям бум машинного обучения,
особенно языковых моделей, которые, я думаю, вы уже прекрасно знаете,
используются не только для того, чтобы там общаться с людьми,
генерировать запросы, там классифицировать тексты,
но и вот эти все языковые модели являются более того хорошими апроксиматорами,
которые, в принципе, можно использовать для любых задач,
не обязательно связанных с текстами.
Просто потому что модель огромная, куча весов, куча параметров,
по факту она может апроксимировать любые зависимости
и вытягивать любую полезную информацию не обязательно, это могут быть тексты.
Ну и, опять же, тенденция, как я уже сказал, ведет к тому,
что количество весов этих моделей, то есть оптимизационных переменных настройки,
модели машинного обучения растет просто экспоненциальным образом,
на графике видно, он заканчивается 2021 годом, сейчас 23,
но тенденция сохраняется.
К сожалению, пока комьюнити машинного обучения ничего лучше не придумала,
кроме того, как просто увеличить размер модели и размер обучающей выборки,
чтобы достигать более классных результатов.
Туда или это путь или нет, в любом случае это приносит людям огромные деньги,
поэтому почему бы нет, почему бы нет?
Кажется, что все же, конечно, более умные вещи, это придумывать что-то более хитрое,
более новое, идейное, а не просто увеличивать размер апроксиматора,
но как бы кто их осудит, это же работает.
Ну и, соответственно, с динамикой увеличения обучающих выборок ровно такая же ситуация,
просто тут по оси Y отложено в алгоритмическом масштабе,
поэтому тут тоже рост экспоненциальный, как и на верхнем графике.
Поэтому, чтобы обрабатывать все это в безобразии, решать такие огромные задачи оптимизации,
ну, современных вычислителей не хватает.
То есть на одном вычислителе вы не обучите современную модель машинного обучения,
точнее обучите, но к тому моменту, когда процесс обучения закончится,
она уже будет, скорее всего, не актуальна.
Поэтому крупные компании применяют такой подход, что они покупают целые дома
с видеокартами, забивают их, соответственно,
современными, этими самыми крутыми тензорными видеокартами,
которые как раз предоставлены, производятся для машинного обучения,
а не для игрушек.
И этот домик, соответственно, жестко греясь, считает,
вам обучает какую-то новую модель, которую потом выкатят в прод.
Нормальный подход раскидать данные между вычислительными устройствами,
и чтобы, соответственно, считать градиент, вам будут помогать не одна видеокарта,
а сразу несколько.
Второй подход такой, в некотором смысле, как раз более актуальный для наших реалий.
У нас эти видеокарты покупать сейчас стало, ну и на самом деле до этого тоже было,
далеко не самым приятным образом это можно было сделать,
потому что дефицит на вычислительное устройство наблюдался всегда.
Видеокарты, я не знаю, застали вы эти времена или нет,
в плане, как бы ощутили вы на себе это или нет,
но в какой-то момент эти современные видеокарты 30-го поколения NVIDIA,
на которых все игрались и все писались от них,
было сложно довольно купить.
Ну и на самом деле с картами для машинного обучения та же самая ситуация.
Хорошими вычислительными ресурсами сейчас в России, можно сказать,
владеют единицы компаний.
А если вообще говорить про прекрасные вычислительные ресурсы, то никто.
Потому что, даже если так посмотреть, то тот же СБР, Яндекс
и какие-нибудь там богатые университеты типа Скалтех,
они тоже жалуются, что им просто не на чем считать.
Хотя, на самом деле есть, но опять же,
мощности такие, как у каких-то западных компаний мы воспроизвести не можем.
Но есть из этого всего выход.
Можно объединять эти просто усилия.
Условно там крупные компании, плюс крупные университеты
накупили какие-то неплохие видеокарты для вычислений.
Это все можно объединить по сети интернет.
Понятно, что это появится в проблемы в плане того,
что это уже не так стабильно, как работа в пределах одного домика,
где вы все контролируете самостоятельно.
Третья парадигма, которая тоже становится суперпопулярной,
это федеративное обучение.
Это в некотором смысле диаметрально противоположный подход первым в двум.
Если в первых двух случаях вы просто обучаете что-то большое
на каких-то открытых данных и хотите это сделать быстрее,
поэтому объединяйтесь.
Федеративное обучение, ситуация иная, у вас здесь.
Обучается, возможно, что-то не очень большое,
но важно, что это обучается на каких-то приватных данных пользователей.
В связи с тем, что вы хотите оттолкнуться от того,
что у вас есть просто какие-то известные открытые датасеты
и хотите в некотором смысле открыть такие золотые залежи данных,
которые лежат на ваших телефонных планшетах в компьютерах.
Точнее, даже не вы, а крупные гиганты, которые за счет этого хотят зарабатывать большие деньги.
Они хотят, соответственно, залезть к вам в телефон,
и на самом деле они уже давно там лазят.
Просто вы этого не замечаете.
И более-менее уважающие себя производители софта,
типа Apple, Google, у них во многих сервисах уже встроены алгоритмы федеративного обучения,
которые как раз обучают эту большую модель,
не обязательно большую даже модель,
на каких-то ваших пользовательских данных,
которых просто тупо больше.
И это можно использовать и в каких-то их целях,
и в ваших целях, чтобы улучшать конкретно ваши продукты,
какие-то, которые хранятся у вас локально.
Плюс, соответственно, им зарабатывать на том,
что они тянут от вас информацию,
и как-то это используют в своей какой-то глобальной модели машинного обучения.
Формально, соответственно, задача распределенная постановка выглядит следующим образом.
Это далеко не единственное.
Тут как раз в кнопочках у вас написано
«Горизонтальная оффлайн постановка».
Понятно, что есть еще и вертикальная, есть и онлайн.
Вот как раз оффлайн онлайн мы уже знаем,
но горизонтальная и вертикальная мы не знаем.
Вертикальная сегодня касаться не будет.
Суть очень простая.
Хотите вычислить градиент, вот этой loss функции,
которую вы считаете, вам может помочь что?
Что может помочь?
Ну то, что у вас на самом деле функция потерь-то она сепарабельна.
Сепарабельна и разделяется на кусочки.
То есть это просто loss на каждой из точки данных.
Вот, поэтому вы можете теперь раскидать точки данных между устройствами,
и на каждом устройстве будет какой-то хранится
свой кусочек общей функции потери.
Вы по нему спокойно можете считать градиенты.
Ну и чтобы посчитать полный градиент функции f,
вам нужно просто собрать эти кусочки в едино.
И тогда получится уже полный градиент.
Все, вся суть.
За счет того, что вы разделяете данные,
вы хотите быстрее считать градиент.
Ну и вам помогает то, что как раз в некотором смысле
градиент по каждому из кусочек данных считается независимо.
Окей, самая простая процедура.
Как обратить обычный градиентный спуск в распределенный градиентный спуск?
Ну соответственно, берете веса модели,
оптимизационные перемены,
отправляете их всем устройствам.
Устройства у вас считают градиент по своей локальной функции.
Дальше они, соответственно, этот градиент отправляют обратно на сервер.
Сервер эти градиенты принимает,
усредняет, получает полный градиент,
ну и делает шаг градиентного спуска, например.
Дальше процесс повторяется.
То есть появились новые оптимизационные перемены,
сделан шаг метода,
опять рассылаете эти оптимизационные переменные устройства,
мне считают градиенты и так далее и так далее.
Очень просто с точки зрения теории,
с точки зрения теории это вообще не отличается от того,
что происходит в обычном градиентном спуске.
То есть тут какая-то специфика,
она вообще не прослеживается.
Реально, с точки зрения теории вот он шаг,
и он понятен.
Вы его можете спокойно сходимости следовать.
Специфика она вот скорее в том,
что это все вычисляется как на стороне именно реализации.
Как посчитать средний градиент и так далее.
Возвращаясь к вопросу, зачем нужна распределенность,
понятно, мы уже вроде поняли,
что за счет того, что мы раскидали данные,
то есть в некотором смысле разделили нашу всю функцию потерь,
мы можем вычислить градиент,
полный градиент по нашей выборке значительно быстрее,
то есть условно янустройство, они вычислят нам градиент вен раз быстрее.
Но возникает такой вопрос,
а в реальности почему-то не наблюдается полное распараллеливание при таком подходе.
Почему?
Да, происходят соответственно затраты на коммуникации,
которые могут сильно портить вашу вот эту кайф от параллелизации.
Причем эта проблема,
она актуальна не только в каком-то там федеративном обучении,
где у вас устройство там связано понятно по сети интернет
и могут спокойно вылетать просто потому,
чтобы там телефон отключили,
или отрубили его от сети интернет и ничего никуда больше не передается.
Ну и для коллаборативного обучения,
когда вы тоже по сети интернет связываетесь с остальными устройствами,
и тогда хочется как раз чтобы все работало быстрее,
но опять же сеть интернет это не самый быстрый способ коммуникации,
особенно когда вы там обучаете какую-то огромную модель,
у которой там миллиарды параметров,
эти миллиарды нужно передавать по интернету.
Вот.
Дорого, дорого, конечно, поэтому и долго.
На самом деле в кластерном случае там ситуация не особо радужная,
потому что там же тоже хочется, чтобы все это работало быстро,
и там тоже приходится бороться с коммуникациями,
несмотря на то, что там у вас все это соединено по какому-то кабелю,
причем скорее всего даже хорошему кабелю,
что-то типа того проволоконного,
но все равно, все равно.
Вопрос актуальный и полной параллелизации никогда нет.
Вот.
Сегодня поэтому мы говорим с вами про эффективные коммуникации,
понятно, что вопросы они есть разные,
какие можно вообще рассматривать в распределенной оптимизации,
в том числе там приватность, федеративное обучение,
но это тема не сегодняшней лекции.
Вот.
Сегодня мы про распределенные оптимизации.
Первое, соответственно, первый сюжет,
который вообще связан с эффективными коммуникациями,
это сжатие информации.
Сжатие информации, соответственно, все очень просто.
Хотите сделать общение быстрее, эффективнее?
Давайте тогда передавать не полную информацию,
а какие-то сжатые ее варианты.
Для этого используются, например, операторы квантизации,
которые вот формально описываются следующим образом.
Это некоторый какой-то стахастический оператор,
вот, для которого выполнены следующие свойства.
По матрежданию, этот оператор равен просто честному вектору X.
В второй момент у него ограничены константы Омега.
Общее определение, непонятно пока, что это такое.
На самом деле, с такого рода операторами в некотором смысле сталкивались.
Вот.
И такой оператор, это, например, случайный выбор координат.
Мы это затрагивали в координатном спуске,
когда говорили про то, что можно считать просто градиенты по координатам.
На самом деле, в случае координатного спуска есть и хороший бонус
с точки зрения коммуникации,
потому что вы не только считаете производную
только по некоторым координатам,
но еще и передаете только эти координаты.
То есть, если мы говорим про распределенный случай.
Вот.
Ну и здесь это все реализовано.
Соответственно, выбираете какой-то набор координат размера K.
Размера K.
Вот.
И, соответственно, эти координаты и передаете.
То есть, только их оставляете в итоговом векторе.
Иногда у меня к вам вопрос,
а зачем вот здесь дополнительно в бахана D делить на K?
Для мат ожидания.
Чтобы по математическому ожиданию у вас тут появился несмещенный вектор.
Когда вы берете мат ожидания от этого оператора,
чтобы там появилось все четко,
вам нужно D делить на K.
D делить на K.
Но это ровно потому, что мы, как уже много раз обсуждали,
в том же координатном спуске добавляем D.
Добавляли D перед координатой, чтобы, опять же, в среднем у вас все было хорошо.
Вот.
Окей.
Можно вычислить Омега.
В принципе, делается ровно то же самое, как с мат ожиданием.
В частности, вы расписываете выражение конкретно для оператора компрессии.
Расписываете его по координатно.
А дальше там математическое ожидание вносится под сумму.
И для каждой компоненты вы знаете, что с вероятностью K делить на D вы ее берете.
А с вероятностью, соответственно, 1 минус K делить на D.
Вы ее не берете.
Поэтому в математическом ожидании там будет K делить на D умножить на просто эту координату в квадрате.
Ну и D в квадрате делить на K в квадрате.
Это просто как раз вылезает из-за того, что мы в операторе тут накинули этот дополнительный множитель.
Вот.
Получается следующее.
И, как вы видите, Омега у этого оператора равно D делить на K.
Что может быть довольно большим числом.
То есть получается так, что дисперсия велика.
Но, опять же, мы видели еще и в координатных методах.
Поэтому, удивительно, тут ничего не должно быть.
Вот.
Окей.
Есть более такие, что ли, и хитрые схемы.
Сжатие, например, вот трехуровневая, так называемая, L2-квантизация.
Суть, ну, довольно агрессивный оператор.
Как вы видите, здесь не просто выбор случайных координов.
Здесь происходит более жесткая операция.
Смотрите, что тут предлагается передавать.
Здесь предлагается передавать просто норму вектора.
Норму вектора.
И для каждой координаты передавать только ее знак.
Вместо самой координаты вы передаете ее знак.
И получается, в некотором смысле, вы вместо каждой координаты
просто знаете знак и просто норму вектора.
И поэтому пытаетесь идти.
Более того, здесь еще добавляется один агрессивный член.
Это случайная величина axi, которая еще отвечает.
Вообще передавать эту координату или нет.
Если координата по модулю довольно большая,
то вероятность ее передачи увеличивается.
Если координата по модулю не очень большая,
то и вероятность того, что она будет передана,
она будет уменьшаться.
В итоге получается вот такое вот агрессивное сжатие.
Вы не только передаете только знак.
Каждый из координат вы еще и выбираете,
стоит ли ее передавать или нет из-за того,
что она там маленькая либо большая
по своему абсолютному значению.
Омега тоже можно вычислить,
равно корень СД.
Что еще?
Давайте я спрошу, а какие-нибудь там самые простые
операции округления.
Хотим, например, было число 10,5,
а мы его округлили до десятки.
Это такого рода операции у нас будут,
не смещенными или нет?
А в частном?
Ну, если в какие-то точки попадать хорошие,
то, наверное, да, там что-то...
Если в саму точку попадать,
то, наверное, когда условно 10,
мы округляем его до 10,
тогда, действительно, вектор остается верным.
А так, в какое число они вы,
не бы, попадали?
Вот. А, ну, там, в серединку?
Ну, может быть, да.
Ну, короче, в общем случае,
это не смещенная вещь.
А как можно тогда делать
округление не смещенным?
Вот, гарантированно.
Да, то есть, смотрите,
у вас есть некоторые уровни,
у вас есть некоторые уровни 1, 2,
до которого вы округляете.
Например, 10, тут 11.
Попалось вам число 10,5, 4.
С вероятностью, некоторые вы округляетесь туда,
с вероятностью, некоторые вы округляетесь туда,
некоторые вы округляетесь туда,
с вероятностью, некоторые вы округляетесь до 11.
Понятно, что эти вероятности
должны быть обратно пропорциональны
расстоянием для этих чисел.
То есть, близки вы к 10,
вероятность округления к 10 будет ближе.
Вот, близки к 11, соответственно,
вероятность к нему округлиться будет ближе.
В среднем, в итоге, будете получать 10,5,4.
Вот.
Окей, разобрались,
как сделать это рандомизировано.
Вот.
Ну, с точки зрения компьютера,
вообще округление до
каких-то знаков,
это мы в десятичной системе живем.
Какое округление будет более натуральное
с точки зрения компьютера?
Ну, смотрите,
мне, например, легче округлять как раз до 10.
Вам, я думаю, тоже, потому что мы привыкли
в десятичной системе счисления.
К компьютеру в десятичной системе
счисления жить неприятно.
Вот. Как он округлять?
Как ему округлять будет приятнее?
В двоичной. Да, в двоичной системе счисления.
Ну, и вот в этом
есть, как бы, одна из идей,
что можно сделать, округлять
в двоичной системе счисления,
и это делается, на самом деле, очень просто
в случае компьютера.
Опять же, если мы рассмотрим такой стандартный
вариант, 32-битовый тип,
1 бит на знак, 8 бит на экспоненты, остальные биты на мантису.
Получается, что знак и экспоненты вам отображают степень двойки.
Для числа мантиса его добивает до какого-то более приятного значения.
Ну, господи, давайте отрежем мантису просто.
Получается, мы будем таким образом просто это подбивать к степени двойки.
К степени двойки и более чем нормальный вариант вместо 32 бит передавать 9.
Знак и степень двойки.
На самом деле в современных каких-то задачах обучения такого рода способы округления,
которые просто в некотором смысле агрессивно меняют тип данных
с какого-то жирного, типа 32 бит или 64 бит,
на какой-то такой более лайтовый, в плане давайте отрежем мантису.
Но без этого уже очень сложно обойтись.
К сожалению, в этих миллиардных задачах все это очень дорого с точки зрения передачи.
Поэтому даже в пределах кластера все вычисления пытаются делать, ну или хотя бы передачу делать,
сжимая информацию вот таким вот образом, как минимум.
Окей, если мы говорим вообще про то, как решать задачу, которая у нас получилась,
ну вот, используя операторы компрессии, теперь мы хотим как бы их встроить в наш алгоритм.
Да все очень просто на самом деле.
Тут что делается? Вместо того, чтобы передавать полный градиент, я говорю, что я буду передавать
от устройств к серверу сжатую версию этого градиента.
Вот, и тогда у меня сервер будет принимать эти градиенты, ну сжатые версии,
усреднять и делать шаг градиентного спуска по ним.
Чем-то похоже на координатный просто спуск, только теперь у вас тут как бы,
если мы говорим про оператор random, окей, вот, только теперь у вас тут координат случайно выбирает
не одно устройство, а сразу несколько.
Вот, вся идея. То есть на самом деле тут, опять же, совсем базовая версия, такая простая,
ничего такого сверхъестественного нет.
Понятно, можете сказать, что на самом деле мы сжимаем информацию только в одну сторону,
потому что от сервера к устройствам информация идет не сжатая.
Вот, не сжатая, здесь это ровно так и написано, мы не сжимаем информацию.
Ну, это не страшно, на самом деле можно добавить сжатие и туда.
То есть на самом деле, когда вы посчитали вот этот жкат, и вы можете отправить
сжатую версию жката на устройство, и они сами сделают шаги градиентного спуска локально.
Вот, по сжатой версии жката. Ну, тогда у вас будет двойное сжатие.
Здесь скорее так, чтобы в теории у вас, ну, чтобы в теории хотя бы какие-то результаты сейчас
пополучать, мы рассмотрим такой вариант.
Плюс, часто замеры показывают, что именно основным узким местом является передача
от устройств к серверу, когда много устройств пытаются закинуть какую-то жирную информацию
на одно устройство, ему это необходимо в режиме реального времени все обрабатывать.
Вот, поэтому обратный бродкастинг, когда вы просто сервер раскидывает одно и то же
на все устройства, это дешевле. И там по замерам 5 раз быстрее, чем серверу принять
информацию от всех. Вот. Окей, доказательств давайте пролеснем. В принципе, идея понятна.
То есть тут ничего такого сверхъестественного по сравнению с координатным спуском нету.
Вот. Пробежались, пробежались. По мотожданию все замечательно, потому что оператор
не смещенный. Изжимаем что-то не смещенное, получаем что-то хорошее.
Дальше важные аспекты, которые нужно осветить. Ну, во-первых, что тут возникает из-за того,
что вы используете оператор сжатия. Это у нас в принципе и было в координатном спуске.
У нас вылезал здесь вот множитель D. То есть перед этим как бы членом, который у нас
возникал по разнице по функции, когда мы оценивали нормы градиента, там выскакивала D.
Здесь вылезает как бы, так как у нас оператор это уже более общая вещь, там не только координатные
вещи, там могут быть и какие-то там округления в том числе. Здесь вылезает, то есть омега,
то есть та дисперсия оператора. Для координатного спуска это была просто D. Вот.
Но важный эффект то, что здесь вылезает еще и M. M, потому что наблюдается, если у вас устройство
независимо между собой, появляется такой вот batch эффект. Как будто, как будто если мы говорим
про координатный спуск, вы уменьшаете дисперсию в M раз. В M раз, потому что независимое устройство
кажется, что если каждое пришлет по одной координате, все пришлют M координат, поэтому дисперсия уменьшится.
Вот и на весь эффект. То есть вот такая у него физика. Но это наблюдается только в случае независимых
устройств. Это важно. Вот. Плюс вот этот кусочек, который непрятен. Вот с этим все окей, вот с этим все
понятно. Мы его видели. Это было в координатном спуске. Вот этот. Этот был вообще в обычном
градиентном спуске. А вот второй кусочек, который я обвел, ну он, как вы видите, неприятный. Это опять же
дисперсия, которая у нас выскочила. Вот. И эта дисперсия в оптимуме. Понятно, что мы решаем задачу
минимизации функции F, при этом градиенты функции FM3 в оптимуме могут не равняться 0 в общем случае.
Ну, понятная ситуация. Уже много раз обсуждали, в том числе, почему HDD не сходится. Вот.
Начинаются осцилляции, потому что просто каждый тянет в свое место. Но здесь то же самое.
Появляется вот этот дисперсионный эффект, который не компенсируется. Вот. Который еще и не уменьшается.
Из-за того, что вы сжимаете что-то, что не стремится к нулю. Получается у вас как бы разница между честным
градиентом и стахастическим, который возникает из зажатия, не стремится к нулю, потому что вы жали
что-то, что не стремится к нулю. Поэтому и разность между честным градиентом и сжатой версией не стремится к нулю.
Вот. Получается вот этот дополнительный эффект, который мешает сходимости. Дальше бла-бла-бла пробежались.
С шагом все понятно. Ровно как в координатном спуске там Dшка возникала. У нас здесь возникла
Здесь возникла Омега делить на М. Вот. Получилась вот такая вот сходимость градиентного спуска,
либо координатного там градиентного спуска. Плюс асцеляции из-за дисперсии. Здесь шаг подобран опять же хитро.
Говорил про то, что это можно сделать в SGD. Вот. Но по факту это результатом означает то, что при фиксированном шаге,
при константном шаге, у вас будут просто асцеляции. Асцеляции вокруг решения.
Вот такая вот ситуация, к сожалению. Ну, не к сожалению. Вот. И в экспериментах она и наблюдается.
То есть до какого-то качества решения доползаете, потом начинаете асцелировать. Все. Конец. Вот.
Это можно решить. Это можно решить. Потому что, опять же, техники редукции дисперсии мы с вами проходили.
То есть суть такая, что не хотите, чтобы асцелировать в окрестности решения, нужно стахастику в некотором смысле сводить на ноль в ходе работы алгоритма.
Вот. Для этого, для этого вводится так называемая техника памяти. Алгоритм называется Диана.
Диана. Ну, это прям реально в честь девушки названа. В некотором смысле такая оптимизационная татуировка.
Вот. Вот. И в чем суть? В чем суть? Смотрите, поняли, что мы сжимаем то, что не стремится к нулю.
Давайте сжимать то, что стремится к нулю, тогда дисперсия будет тоже стремиться к нулю стахастического градиента.
Для этого вводится дополнительная последовательность H, которая называется последовательностью памяти.
Последовательностью памяти. И здесь, ну, идея близка вот ко многим техникам редукции дисперсии.
Если вы, мы уже когда-то что-то считали, когда-то что-то передавали, почему это нужно забывать?
Вот. В связи с тем, что, ну, ситуация такая, что у вас кажется в ходе работы алгоритма там все посылки, они будут более-менее сжимать одно и то же.
То есть у вас все стремится к оптимуму, градиенты стремятся к оптимуму. Градиент в оптимуме вот так вот.
Ну а значит и посылки будут пересылать примерно одно и то же, просто сжимая по-разному, там выбирая случайные координаты или там округляют и все как-то по-разному.
Вот. Ну давайте я в этой памяти буду сохранять то, что я передал в прошлые разы. Вот. И в этом вся соль.
То есть изначально это просто 0, это просто 0, а дальше ну, начинается алгоритм.
Я сжимаю то, что хочу переслать, ну изначально просто градиент. Я хочу переслать градиент, отправляю сжатую версию градиента на сервер.
Отправляю сжатую версию градиента на сервер, а он принимает и делает шаг градиентного спуска.
Но при этом сервер получает от меня эту посылку и у себя локально тоже сохраняет то, что он от меня получил вот эту посылку.
Вот это обновляется как бы и на устройстве, и на сервере.
Сервер сохранил посылку, то есть вот эту сжатую версию градиента, я сохранил то, что я серверу передал вот эту сжатую версию градиента.
И на следующей атерации что происходит? На следующей атерации я говорю, что а я буду досылать теперь не просто градиент,
ну мне же нужно посылать вроде как градиент, но я же знаю, что сервер от меня уже получал какую-то информацию и ее сохранил.
Окей, а давайте тогда я ему дошлю разность. Зачем мне посылать все, если я могу досылать разность?
Понятная тоже естественная идея. Если, опять же, h будет стремиться просто к градиенту, а так на самом деле и будет, что h будет стремиться просто к градиенту fn в эссо звездой,
то я буду по факту просто чуть-чуть модифицировать то, что у меня хранится на сервере, вот эту h, и добивать его до истинного значения.
Вот, поэтому пересылать разность и довольно такая понятная и естественная идея, которая играет ключевую здесь роль.
У вас вот эта разность действительно будет стремиться к нулю, потому что fmt будет стремиться к оптиму, вот к градиенту в оптимуме,
h тоже к этому будет стремиться, и вы его потихонечку таким вот небольшими шашками уже будете модифицировать.
Вот, опять же, вся суть в очень простой вещи запоминать то, что мы когда-то делали до этого.
Вот, и досылать, все, досылаем только разность, все, суть такая алгоритма Дианы.
Оценки исходимости хотелось бы на них посмотреть, вот, доказывать понятно, мы уже ничего не будем, вот такая вот оценка для Дианы,
для Дианы, вот такая вот оценка я напоминаю для обычного градиентного спуска, если бы мы тупо коммуницировали по полным градиентам.
Какая из наценок лучше, вы мне сразу скажите, какая?
Вторая, не верхняя, не правда, что верхняя, верхняя хуже, она же видите, у вас не просто единица стоит в скобках,
у вас там дополнительный множитель ω делить на m, ω может, как мы поняли, быть огромной,
передаете одну координату из миллиона, в итоге ω равна миллиону, вот, ну и все, получается верхняя оценка хуже,
нижняя лучше, и это означает, что вроде как градиентный спуск с точки зрения итерации лучше, вот.
Понятно, естественно, на самом деле эффект, передаете меньше, передаете, агрессивно сжимаете информацию,
с чего вы должны от этого не потерять с точки зрения итерации, конечно, потеряете, но вот здесь эта потеря и отражена,
но интересен не этот результат, интересен результат, когда вы говорите о том, что насколько вы меньше это передаете,
потому что да, с точки зрения итерации вы проиграете, но с точки зрения именно количества переданной информации,
а значит и скорости передачи, вот, вы можете выиграть.
Давайте ведем такой вот параметр β, во сколько раз вы сжали информацию,
потому что ω и β, ну они не всегда связаны прямым соотношением, что β равно ω, вот,
и тогда, а давайте, кстати, обсудим, чему равна вот эта β, во сколько вы сжимаете информацию, например, для random k,
когда вы передаете вместо k координат, вместо d координат k, вот, чему равна β в этом случае будет?
k делить на d, это получается что, ну точнее даже d делить на k, да,
потому что мы передали k координат вместо d, поэтому передали вроде как d делить на k раз меньше информации,
но давайте порассуждаем, а что мне нужно передать, вот, я вот хочу передать k координат вместо d,
ну да, мне сами значения координат нужно передать, а что мне нужно передать еще?
Ну, куда я ставлю эти координаты, потому что передал я вот это, одну координату вместо тысячи, а какую, вот,
это, конечно, самый интересный вопрос, пришло число, куда ставить его, вот,
поэтому дополнительно нужно еще, конечно, передать номера координат, которые вы передали,
поэтому если у вас там всего d координат, то вам нужно еще логарифм от двойки по основанию 2d бит,
чтобы закодировать все эти числа, вот, и вы дополнительно еще дошлете вот столько бит, чтобы просто передать эту информацию,
вот, и кажется, что тогда вообще бета станет меньше, чем омега, но тут можно выкрутиться,
можно выкрутиться, особенно с рандомизированной стратегией следующим образом, вот, маску можно на самом деле не передавать,
вот, как это сделать, ну, смотрите, ситуация следующая, координаты же выбираются каким-то случайным процессом,
алгоритмом, у которого, который на самом деле ни разу не случайный, и там просто это реализовано
псевдослучайность и случайные сиды и знание алгоритма вам в этом плане может помочь,
если вы воспользуетесь одним и тем же генератором случайных чисел, вот, на устройстве и на сервере, вот,
то устройство условно выберет координату с номером i, а сервер возьмет тот же самый генератор, возьмет тот же самый рандом сид
и сгенерирует ровно эту же координату, скажет, что устройство мне передало номер этой координаты,
точнее, вот, значение этой координаты, просто потому что я могу воспроизвести ту же самую случайность у меня локально,
вот, в этом помогает нам псевдослучайность, поэтому здесь вот эта дополнительная передача k умножить на алгоритм d бит,
она не нужна, она не нужна и окей, я вот здесь даже сразу в оценки положил, что бета равно омега,
разделил те оценки, которые у нас были до этого на бету и получил вот такое вот выражение для нашего метода,
такой множитель, ну а для градиентного спуска в связи с тем, что он не сжимает информацию, я просто разделил на единичку и ничего не сдвинулось,
вот, и вот здесь как раз уже виден эффект, виден эффект там, что вот этот множитель может действительно быть меньше единицы,
берете бету довольно большой, мку довольно, то есть берете 100 устройств, 1000 устройств учителей, получаете хороший множитель,
хороший множитель, который действительно показывает то, что ускорение-то оно и есть, вот, кстати, в том числе как бы показательный результат,
тут важно, что координатный метод, когда вы как раз делаете его распределенное, тут уже будет ускорение,
на одном устройстве никакого ускорения нет, потому что опять же у нас была мка равна единице на прошлом занятии,
ну и там ничего хорошего не произошло, вот, окей, вот такая вот ситуация, следующий сюжет, который вообще хочется обсудить,
вроде как получили, быстрее общаемся с сервером, меньше тратим на коммуникации, опять же, как вам рассказывал Саша из Яндекса,
у вас, к сожалению, наблюдается немного другая ситуация с точки зрения организации коммуникаций, общаться с сервером это не самый практичный вариант,
да, вы можете поставить, ну, в реальности, в этих кластерах действительно есть управляющий сервер, но он не синхронизирует процесс общения в том виде, в котором мы это описали,
модель вот этого общения с сервером, она скорее такая игрушечная и искусственная, вот, которая просто помогает пониманию того, что может происходить,
ну нам нужно усреднить, давайте как бы скинем все на сервер, он нам все усреднит, но существование сервера, оно предполагается скорее так, вот, в теории,
потому что в реальной жизни общение с сервером реализуется другим образом, другим образом, вот, реализуется оно через так называемый L-Getheral Reduce процедуры,
что это подразумевает? Подразумевает то, что у вас есть вот эти вычислительные устройства, они между собой как-то соединены в сетку, вот,
чаще всего в этой сетке еще есть все ребра, то есть это просто полный граф, между всеми видеокартами есть проводок, между всеми там процессорами,
между всеми вычислителями есть проводок, который их между собой соединяет, вот, лежат они там в пределе одной вообще платы или в разных, в любом случае связи есть все, вот,
и поэтому в некотором смысле вот эта процедура усреднения, которая у нас до этого делал сервер, вот, мы эту процедуру можем симулировать в такой сетке,
если каждый передаст каждой просто свое значение, они все усреднят внутри себя и получится итоговое осреднение, вот, и никакой сервер здесь особо и не нужен, вот,
в реальности так и происходит, то есть проводки, видеокарты между собой просто общаются и выдают ответы, выдают, ну, в итоге каждый получает среднее,
каждый делает шаг и на этом все обрывается, то есть нет никакого сервера, единственное, проблема, конечно, возникает в том, что, ну, давайте вот какой-то протокол,
я не знаю, вот, ходили на Саша Панина, его семинар или нет, не ходили, ну, давайте я тогда расскажу как раз, кто-то там ходил, ну, там, по-моему, человек 30 был,
в принципе, неплохо записал, конечно, 100, но дошло 30, ладно, суть вообще того, хочется, почему придумают про то, как делать вот эти процедуры усреднения без сервера более эффективными,
понятно, что передать все всем это, конечно, выход, вот, но дорого, дорого, вот, более дешевый вариант, это если все скинут, как бы симулируют работу сервера,
одно из устройств выступит данным случае сервером, все на него просто скинут, и усреднят, устройство усреднит внутри себя это все безобразие,
и потом это все отбродкастит всем остальным, симуляция работы сервера, симуляция, в такой системе это все работает, потому что, как я сказал, все связи есть,
но есть более эффективные вещи, есть более эффективные вещи, потому что, опять же, как я сказал, в случае, когда у вас одно устройство работает,
то ему нужно принять D посылок от всех параллельно, еще и усреднить полный вектор длины D, дорого, вот, можно дешевле, смотрите, следующая процедура называется Rinkle-reduce процедурой,
в чем суть? Пусть у вас есть 4 устройства, 4 устройства, раз 4 устройства мы разбиваем наш полный вектор, который мы хотим усреднить, на каждом из устройств на 4 равные части, вот, здесь это и делается, вот,
ну, в общем случае понятно, там условно K устройство, M устройство вы развиваете на M частей, вот, и что происходит? Мы передаем не все, первое устройство передает только первую часть вектора, передает только первую часть вектора,
второе устройство, причем соседу по кругу, вот, второе устройство передает вторую часть вектора, третью, третью и четвертую, четвертую, тогда вот после такой передачи на первом устройстве у меня скопится
первый кусочек от первого устройства и первый кусочек, который у меня и так там хранился, вот, ну и так далее, то есть вот здесь это скопится там B1, здесь дальше скопится C2, дальше скопится тут D3, вот, дальше происходит следующее, ну раз у меня тут скопилась A0 плюс B0, дальше я буду передавать его, дальше я буду передавать его, ну и во всех устройствах аналогично, то есть как они скопили сумму двух, вот, они ее и передали.
И далее, далее, далее у вас происходит абсолютно такая же вещь, здесь у вас дальше скопится уже сумма из трех, поэтому вы дальше будете передавать уже сумму из трех, по кругу, по кругу, там дальше скопится сумма из четырех, передайте сумму из четырех.
В итоге у вас, а, ну уже сумму четырех уже передавать не надо, потому что это все, больше четырех устройств у нас нет. В итоге на каждом устройстве будет храниться сумма всех четырех значений с разных устройств, но по кусочкам, не у каждого будет все, а у каждого будет только кусочек.
Понятно, что к среднему это легко привести, мы разделили на четыре, вот, то есть мы по факту усреднили вектор, но пока он так вот разбросанно хранится, ну а дальше вы по кругу это просто передаете.
У меня этот кусочек R0 хранится, ну окей, я его передаю, это он же не знает сосед, этот передает R1, этот передает R2, этот передает R3.
Дальше, соответственно, по кругу, то, что кто не знает, все передается и получается, что у каждого окажется полный вектор, ну то есть здесь, например, окажется в итоге R0, здесь будет R1, вот, ну дальше что нужно передать, вот этот, например, не знает R0, теперь я на следующей террации передам R0 сюда, вот, здесь скопится R3, дальше я буду передавать R3.
Ну вот так вот это по кругу все пойдет, пойдет, пойдет и получится вот такое вот честное усреднение. Такая процедура работает быстрее, чем, понятно, усреднение с одним устройством, просто за счет такой вот хитрой параллелизации, то есть каждый выполняет одну операцию, одинаковый пул операции, то есть делает вот такое вот усреднение.
Называется WrinkleReduce, опять же, Саша про это рассказывал, говорил про то, что то усреднение, которое у вас было, это, ну вот, честное усреднение через сервер это OAD операций, вот, ну и OAD получается временных тактов, потому что это все выполняется на одном устройстве, вот. С помощью такой процедуры можно OAD единицы временных тактов делать, и это значительно эффективнее.
Окей, смотрите, если мы говорим теперь про те методы сжатия, которые мы с вами вроде как проходили, вот, я не перестаю удивляться тому университету, восемь лет уже, восьмой год уже здесь, ну, может заплутал, вот, а то это вроде бы уверенно ходит, но явно не так.
Так, смотрите, в чем вообще возникают проблемы, то есть до этого как бы вроде как расобщение с сервером, мы передаем ему меньше информации, ну и что-то там вроде как действительно с точки зрения именно скорости передач, это хорошо.
Ну, если мы работаем в пределах вот такого кластера вычислительного, где нет сервера, где мы, например, запускаем OLD reduce процедуры по колечку, вот, какие вы проблемы видите, какие вы проблемы видите, насколько это вообще будет выглядеть эффективно?
Ну, это с одной стороны, да, ну, почему, на самом деле нет, когда вы усреднили у всех, они все посчитают среднюю точку, ну, следующую точку, да, без проблем, господи, у вас так вы ждете одного, когда он вам посчитает, а так вы сами посчитали, ну, с точки зрения вычислений не страшно.
Тут скорее другая опасность, тут, видите, возникает то, что с одной стороны вроде как мы обсудили, что эффекта того, что вы независимо на всех устройствах генерируете случайность, он хороший, он там проявляется в улучшении сходимости, но, с точки зрения OLD reduce процедуры, это тоже не очень хорошо, это как раз минус, потому что, ну, например, на какую-то из координатов выбрали все устройства, какую-то координат выбрало только два устройства, какую-то координат
из координат выбрали никто.
Как это делать эффективно, усреднять, делать all-reduce,
когда какую-то координату нужно усреднить у всех устройств,
какую-то координату нужно усреднить у частью устройств, какую-то ни у кого.
При этом, ну да, можно задать одинаковый рандом CD,
чтобы они в итоге знали, какую случайность сгенерировал каждый.
Но как это эффективно организовать именно менеджерские, это очень костыльно получается.
То есть, есть такие процедуры, которые работают с такого рода сжатиями
и как-то это костыльно преобразует в более-менее эффективное усреднение.
Но базово, лучше, чем просто запустить честный wrinkle-reduce
вот с этими незначащими ничего нулями, потому что вы как бы их не передаете,
ну не получается, не получается.
Поэтому возникает такая идея, возникает такая идея,
а давайте я сделаю тогда зависимую случайность.
И скажу, что я на каждом устройстве, опять же, задаю один и тот же генератор,
задаю один и тот же рандом CD.
И каждый из устройств генерирует перестановку, одну и ту же перестановку из номеров координат.
Номеров координат.
Нет, надо помочь явно.
Вот, номеров координат, и у каждого эта перестановка одна и та же.
Все эту, одну и ту же перестановку знают.
Вы заплутали, да?
А, понятно, понятно.
Главное, будьте уверены в себе.
Вот я уверен на сфоки.
Вот.
Смотрите, каждый знает эту перестановку.
Каждый знает перестановку.
И суть такая, что первое устройство выбирает,
условно там, перестановка, восьми координат,
у нас четыре устройства.
Один, восемь, семь, пять, четыре, три, пять, два.
Вот.
И первое устройство, соответственно, выбирает первую и восьмую координаты.
Второе устройство выбирает седьмую и пятую координаты,
третье, соответственно, третью и четвертую.
Четвертый вычисляет пятую и вторую.
В итоге, видите, каждый выбирает непересекающийся набор координат.
не пересекающийся набор координат, но это же по факту
эквивалентно вот той ситуации, которая нарисована здесь.
Получается у нас у каждого устройства есть не пересекающаяся посылка,
которую ему нужно послать. Просто по кругу запускаем, все пересылаем.
По кусочкам. Получается мы вот таким вот сжатием, мы all-reduce процедуру
упростили, потому что там не нужно считать что-то среднее в силу того, что
каждый из кусочков независим. Вот. И на самом деле эффективно поработали с точки
зрения компрессии, потому что эффект передачи опять же тоже будет наблюдаться,
потому что там вот это batch эффект тоже будет, потому что здесь есть случайность,
она такая конечно зависимая, но вот этот один делить на m он тоже будет. Вот.
Вот такая вот вещь. Соответственно, когда у вас нет сервера, идея более чем рабочая.
Хорошо. Обсудили такую вот идею. Перерыв делаем или идем дальше? Ну, давайте
дальше обсуждать. Сегодня без доказательств, поэтому мы скорее так
идейно обсуждаем, что происходит. Дальше. Следующий сюжет про то, что на самом деле
случайность, это конечно все классно, замечательно. Вот. Но вообще кажется, что
выбор чего-то не случайного может быть значительно лучше. Вот. Поэтому возникает
идея, что давайте-ка мы ведем более такой общий класс операторов, который назовем
смещенными операторами компрессии. Тут уже не будет то, что математическое
ожидание оператора равно самому значению вектора. Вот. Но такой класс можно погрузить
значительно больше операторов, и это как раз хорошо. В частности, погружается сюда
вот такой вот оператор, который называется TOP-K. Он же жадная спорсификация, он же в
некотором смысле аналог random-K на случай, когда вы вместо случайного набора координат
пересылаете максимальные по модулю. Пересылаете максимальные по модулю. Понятная тоже идея,
а суть тоже у нее как бы более чем ясна. Ну какие-то координаты может быть, могут быть маленькие.
Зачем их выбирать тогда? Давайте я перешлю самые большие там в слои или вообще во всей
модели. То есть, когда оба с данной нормализованы, вот, более-менее, то тогда такого рода пересылки
градиентов, они более чем имеют место, потому что, ну, каждый из признаков более-менее имеет
одинаковый размер. А значит, градиенты можно считать более-менее равномерными, и тогда,
где градиент меньше, тогда его пересылать вроде как не нужно. Поэтому нужно пересылать только
самое большое, и здесь эта идея как раз реализована. Понятно, все приятно. Единственное, что как раз
тут уже возникает смысл в том, что маску-то нужно будет переслать, потому что сервер уже не знает,
какие у вас конкретно топовые координаты. Вот, тут уже без маски не обойтись. Вот, это все безобразие
здесь есть. Разного рода операторы тут можно придумывать, в том числе вокруг округления,
вокруг, опять же, выборов каких-то координат. Можно и совсем извращаться, и предлагать сжатие
на основе всяких СВД-разложений, причем атеративных СВД-разложений. Тоже классная вещь, работает,
вот на практике вообще последняя вообще супер. Вот, вот выбор, там, условно, как координат работает,
а СВД-разложения вообще супер. В том числе, пробовали на экспериментах, обучение там всяких
больших языковых моделей, нормально отрабатывает. Вот, самая базовая идея, вообще, вот, ну, в силу того,
что вроде как мы используем оператор сжатия, ну, давайте тот же самый этот, который у нас был,
где мы просто сжимали передаваемые градиенты, ну, давайте его использовать, окей. Ну, и в случае,
вроде как, одного устройства, который не особо интересен именно с точки зрения практики,
потому что, ну, а зачем вообще распределено что-то вычислять на одном устройстве? Да, оно может
быть как-то круче с точки зрения вычислительных мощностей, но неинтересно. Интересно, конечно,
когда много устройств. И в случае одного устройства все это можно доказать, получается
линейная сходимость, все красиво, все стильно модно и не страшно. Вот. Проблемы возникают,
когда у вас устройств будет несколько. И вот здесь такая простенькая задачка, двоечка не влезла
по ходу. Три устройства, размерность задачи три. Вот. Квадратичная задача не сложная, видите,
что тут просто квадратичная функция зашита. Вот. Оптимум у нее в нуле. И вот такие вот градиенты.
Я беру стартовую точку, которая, например, она ТТТ. Вот. Просто, ну, там, 111. Вот. И, соответственно,
считаю градиенты. Градиенты получаются вот такие вот. Какой у меня тогда суммарный градиент будет,
если я никакие сжатия не буду использовать? Быстренько мне подскажите, какой будет суммарный градиент.
Ну, что там, Т пополам. И если мы все складываем и делим на три, что там будет? 11 плюс 9 плюс
9. Это что? 7, да? Минус 11. Да-да-да-да. 7 третьих. Вот. Ну и везде там будет 7 третьих. Давайте так,
вот так напишу. 111 и здесь еще 7 третьих. Вот. Но. А что будет, что в итоге у меня будет в качестве
градиента, если я использую топ-1 сжатия для каждой из компонентов? Минус 11, минус 11, минус 11.
Ну, давайте вот так. Ну и что вы можете сказать про вот этот градиент и про вот этот градиент?
Насколько они вообще отражают физику задач. Ну понятно, первые отражают полностью. Вот. Второй,
но он вообще указывает не туда. То есть это вообще противоположное направление. И оказывается,
ну действительно, вы таким образом просто от решения будете отваливать. Отваливать куда
подальше из-за того, что используете топ-1 сжатия. Получается вот даже для таких квадратичных
задачек. Для любого топ-1 сжатия, вроде как, как мы вроде прикинули неплохой вариант, вы будете
просто экспоненциально отваливать от решения, что явно нехорошо. Тут нам на помощь приходит тоже
в некотором смысле такая идея с памятью. Ну это называется техника компенсации ошибки. Идея с
памятью на самом деле здесь тоже может выстрелить. И дальше я покажу, что там и Диану можно сделать для
такого оператора. Вот. Но есть еще такая техника error-feedback, которая более чем является рабочим
вариантом. Суть тоже очень простая. Я хочу передать градиент. Вот. Передал в итоге сжатую версию этого
градиента. Давайте я сохраню то, что я не передал. Вот. Из честного градиента вычту посылку. Понятно.
Хорошо, вычли, так вычли. Вот. А к будущей посылке я добавлю то, что я не передал. То есть я хочу в
следующий раз послать градиент, но я говорю, а на прошлой итерации я не послал вот это. Вот. Не
дослал. Вот. Ну давайте тогда теперь моя новая посылка это то, что я не дослал, плюс то, что я
хочу послать сейчас. Вот. Сжимаю ее, получаю новую посылку. Ну и так далее. Сжатую посылку посылаем.
Новая ошибка это что? Это просто то, что я опять же хотел послать. Ошибка с прошлой итерации, плюс
новый градиент. Минус то, что я в итоге послал. Сжатая версия этого всего безобразия. Все,
простая идея, но она решает эту задачу. Решает проблему с тем, что ничего не сходится. Вот. Ну
и он, например, на каком-то там бейзлане можно посмотреть. Небольшая сетка. Несколько сотен тысяч
параметров. Ну, вы там обучали какой-нибудь на маршрумсах. Там сто переменных. Здесь ну там
200 тысяч переменных. И, соответственно, вместо передачи полного вектора я передаю пять компонентов.
Пять компонентов. Ну и все на самом деле живет. Живет и пахнет. Зеленым показан бейзлайн, как будто
я использую честный SGD. Синий. Передаю пять компонентов. Пять компонентов. Максимальный по
модулю. Вот. Желтый. Пять случайных компонентов. Ничего не обучается. Ну синий более-менее как-то
ползет. В случае с компенсацией ошибки все вообще замечательно. Все вообще замечательно. То есть видно,
что он работает, ну понятно, хуже чем зеленый. Вот. Потому что зеленый передает полные градиенты.
Но если вот это все безобразие отложить не в эпохах, то есть не в итерациях, а по количеству
переданной информации, то там красный он вот здесь вообще оказывается. То есть там сильно вообще, ну то есть
пять координат вместо там тысячи, сто тысяч это конечно там вот так что-то будет выглядеть. Это обучение.
Вот. Поэтому тут понятно есть эти значительные улучшения. Вот. Теория сходимости. Опять же линейная
сходимость. Вот. Плюс кусочек, который нужно компенсировать. Опять же сходимость к окрестности.
Вот. Можно опять же решить этот вопрос с помощью Дианы. Вот. Называется Error Feedback 21. По-другому
назвали алгоритм, но суть такая то, что это просто Диана. Вот. Память вводите, сжимаете и пересылаете не
градиенты, а пересылаете разность между градиентом и тем, что послали дальше. Вот. Та же самая идея. Вот.
Сходимости. Сходимости. Чтобы закончить сюжет с компрессиями, нужно обсудить сходимости. Вот.
Диана вот такая оценка, Error Feedback 21 вот такая оценка. Обе линейные, обе-обе вроде хорошие, но здесь есть
эффект от Эмки, он ключевой. Здесь этого эффекта нету. Вот. То есть, к сожалению, это вообще проблема
теории смещенных операторов сжатия, что для них не получается доказать, что они лучше,
чем обычный градиентный спуск. Вот. Но на практике все, конечно, летает. Единственное, что та теория,
которая вообще создана вот в этой распределенной оптимизации с смещенными компрессорами, она хотя
бы помогла прийти к тому, что вот с Error Feedback сходится, без Error Feedback не сходится, поэтому давайте
использовать. Опять же, Диана, ну или вариант Дианы, который назван Error Feedback 21, он помогает тоже
сходимости работать даже лучше, чем, например, обычный Error Feedback в некоторых ситуациях. Ну вот,
теория скорее про это. Пока получить улучшение, почему там топ-1 сжатия там работает, работает для
Server Feedback и работает лучше, чем обычный градиентный спуск, не получается. Хотя графики показывают,
что там реально просто замечательная сходимость. Вот. Но, в теории, все не так радужно. Вот в этом вопросе.
Окей. Второй сюжет. Можно же не сжимать информацию, можно пойти другим путем. То есть сжать информацию,
мы опять же коммуницируем каждую итерацию, но коммуницируем соответственно по сжатым пакетам,
поэтому за счет этого получается более эффективно. Второй подход. Давайте тогда не сжимать передаваемую
информацию, но коммуницировать реже. Коммуницировать реже не каждую итерацию. Диаметральный взгляд,
вот. Но тоже рабочий. Суть очень простая. Давайте я на каждом из устройств буду запускать
градиентный спуск. Стокастический либо обычный градиентный спуск. Вот. По своей локальной функции,
по своей локальной функции, не по функции f. То есть каждое устройство просто независимо начинает
спускаться по своей функции, получая там идя к своему оптимуму. Дальше я говорю, давайте как
каждую итерацию вы мне усредните это значение. То, что вы там наполучали, свои переменные,
вы усредните между собой. И дальше вы пойдете уже делать эти, опять же, локальные шаги не с той точки,
которая у вас была, а вот с этой средней точки. Вся идея. Очень простая. Называется параллельный
градиентный спуск, параллельный sgd. Придумано там больше 30 лет назад, но опять же она в некотором смысле
реэнкарнировала. В силу того, что распределенная оптимизация стала супер популярна, а такого
рода алгоритм очень просто. Что его реализовывает? Чтобы меньше коммуницировать, просто делай локальные
шаги и усредняйся. Проблема этого алгоритма заключается в том, что в силу того, что вы по факту
просто ползете к каждому из локальных оптимумов, это проявляется вот таким вот образом. Делайте одну
локальную итерацию и каждый раз усредняйтесь. Это просто градиентный спуск. Вроде как сходите все
хорошо, леднее на крешению. Делаете много локальных итераций, сходите к крешению быстрее с точки
зрения коммуникации, но начинайте стопориться. В какой-то момент начинаете асцелировать.
Чем больше локальных итераций, тем у вас асцеляция не хуже. Понятно, что там
две локальные итерации. Решение хорошее, но там уже 32 локальные итерации и у вас там решение
стало значительно хуже. И на самом деле этот фактор не убираем. Это физика этого метода, потому что
у вас есть какая-то стартовая точка и все как-то поползли в своем траектории. Ну пусть у них
там вот как-то так лежат решения. А оптивум где-то например здесь находится. Это оптивум каждого из
устройств. И вроде бы на начальных итерациях все хорошо. Вы усреднились, получили что-то здесь.
Дальше опять же все поползли по своим направлениям, усреднились, получили что-то здесь. Вы приближаетесь
и к своим локальным решениям и приближаетесь к оптивуму. Все хорошо. Но когда вы находитесь уже
близко к решению, ситуация резко меняется. Потому что ну вот например вы и дошли до какой-то
такой точки, она у вас стартовая. Вот вы начинаетесь каждый ползти к своему решению. Усредняетесь,
оказываетесь где-то здесь. Ну и опять же начинаете ходить к своему решению, усредняетесь опять же
оказываетесь здесь. При этом решение вот это х звездой оно остается в некотором смысле в стороне.
Вот. Решение х звездой она остается в стороне. Так, и соответственно.
Надо ответить. Просто это.
Она просто кофе-машину доставляет в лаборатории, надо ее принять. Вот. Получается вот такая вот
ситуация. Ну и как показывает теория, этот фактор не устраним. Этот фактор не устраним и ничего вы с
этим безобразием не сделаете. Поэтому приходится с этим жить. Но давайте попробуем придумать какой-то
способ, как это можно устранить. Вот что-то уже из машинного обучения знаете. Вот. Что-нибудь вы уже
знаете, да? Да, это хороший вариант, но хочется, не уменьшая глубину, вот как-то все равно это объезжать.
В чем эффект? Вот смотрите, я каждый раз, вот локальные шаги, мы поняли, это не очень хорошо,
потому что каждый из устройств начинает ползти к своему оптимуму, да? И поэтому усредненная точка,
она не очень хороша. А что значит вот с точки зрения машинного обучения, вот это локальный оптимум?
Оверфит. Правильно. Это эффект переобучения. То есть вы начинаете, чем больше вы делаете
локальных шагов, тем вы как бы переобучаетесь на своих локальных данных, и это переобучение,
оно вам мешает. Защита от переобучения? Как защититься от переобучения? Регуляризатор,
пожалуйста. Вот. Давайте тогда, когда я буду решать эту локальную задачу, я буду просить делать
шаги не просто по функции локальной, а по локальной функции плюс регуляризатор. И суть этого регуляризатора
заключается в том, что у меня есть некоторая точка В, которая является референсной. Ну,
например, последняя средняя точка, которую я там когда-то усреднял. Вот. И тогда в силу того,
что этот регуляризатор меня держит, я от нее не отвалю. Вот. Далеко. Из-за оверфитинга. Все. Вся
идея. Ну, вот здесь, например, она реализована. Там написано абсолютно по-другому. Там рассказываются
про шифты, какие-то дополнительные последовательности. Суть очень простая. Регуляризатор. Вот.
И, на самом деле, эта идея с регуляризатором в локальных методах, она такая, что ли, сквозная. И
сейчас мы посмотрим, как ее можно использовать. Вот. Но изначально вообще возникает вопрос. Вот.
Возникает вопрос. А зачем вообще нужны локальные методы? Потому что, ну, вот, кажется, что нижняя
оценка на число итерации, она же на число коммуникации, она вот такая. Вот. А какой метод дает такую оценку?
Нестер. То есть, кажется, что можно просто делать распределенный Нестеров. Вот. И все. И все.
Потому что, а лучше ничего не придумаешь, потому что лучше, чем нижняя оценка, вы не сделаете. И,
получается, как вот мы адаптировали градиентный спуск под распределенный сеттинг, можно также
адаптировать Нестерова. Вот. Единственное, что понятно, что все эти локальные методы изначально
придумывались не просто для детерминистического случая, когда у вас вот такие оценки. Они
придумывались для стахотического случая, когда у вас есть ограниченная дисперсия, ну, в теории. Вот.
И хотелось бы что-то как-то с этой дисперсией делать, потому что она вот о вас так вот возникает. Вот. А
какого бы эффекта хотелось добиться за счет большего числа вычислений? То есть, на одном устройстве
вы вроде как можете все решить. Получится там сигма, оценка какая-то гамма в квадрате и так далее.
Хотелось бы что сделать за счет большего числа в устройстве? Получить батч-эффект. Потому что с сил
того, что у вас стахастика везде независима, вы складываете независимые стахастические случайные
величины. Вот. И дисперсия у них уменьшается в М раз, потому что у вас используется М-устройство. Вот.
Вот такого эффекта хотелось добиться. И он реально, в реальности можно добиться, когда вы просто,
если не делаете никакие локальные шаги, просто, например, говорите, я посчитал градиенты
стахастические. Вот. На всех устройствах они мне его слили, и тогда дисперсия общего градиента
будет в М раз больше просто из-за независимости. Вот. Но этого эффекта нету, к сожалению. У локальных
методов вот его искали, показали, что его нет. И получается, что в некотором смысле в общем
сеттинге локальные методы, ну, ничего не дают. Вот. Хотя они классно работают на практике, все это
можно использовать, все это применяется в реальных задачах, в том числе в ваших телефонщиках это уже
давно крутится. Вот. Но с точки зрения теории, тут, к сожалению, есть более эффективные вещи.
Единственное, что хочется рассказать про сюжет, когда вообще локальные шаги действительно имеют
место. Вот. Этот сюжет называется Data Similarity, и суть этого сюжета заключается в том, что,
ну, не зря он так называется, похожесть данных. Похожесть данных и, оказывается, в случае
похожести данных вот уже можно вытащить то, что локальный метод дает улучшение, дает улучшение.
Так. В чем суть? В чем суть? Опять же, делим нашу выборку на кусочки. Вот. Только здесь эти кусочки будут
уже распределяться равномерно. Вот. Почему равномерно? На самом деле пока, пока. Я говорю равномерно,
в конце я сделаю референс, что на самом деле достаточно и обычного деления, вот, ну, произвольного.
Но пока будем считать, что пусть у нас будет все равномерно разделено. Вот. И что я хочу сделать?
Я хочу ввести дополнительное, в дополнительное предположение. Потому что мы понимаем, что без
дополнительного предположения тут не выжить. Это вот ровно то, что происходит, например, вот,
почему Нестеров, ну, не улучшаемый метод среди методов первого порядка, имеет какие-то определенные
оценки и лучше, чем они не получаются. При этом можно, например, в случае стокастической задачи
получить методы лучше. Там условно, как мы знаем, там редукция дисперсии работает быстрее, чем Нестеров
для стокастической задачи. Но вы ввели специфику задачи, вы говорите, что она имеет вид суммы,
потому что Нестеров это не учитывает, что можно считать сумму не полностью, то есть не полный
градиент, а по бачу. Поэтому вот, опять же, чтобы получить какие-то более классные результаты и
получить какой-то эффект от локальных шагов, нужно в некотором смысле сузить задачу, ввести
специфику, и эта специфика даст улучшение. Специфика будет следующая. Похожесть гесианов,
то что у меня гесиан функции fm и гесиан функции f, они похожи, отличаются на некоторую константу дельта.
Вот. Понятно, тоже хорошее такое свойство, потому что, опять же, часто рассматривают,
например, похожесть градиентов. Но это не очень классно, потому что для квадратичной задачи
матрица минус матрица, ну это как-то оценивается в духе матрица минус матрица на вектор х. Если х у
вас не ограничен, то у вас, соответственно, это просто устремляется в бесконечность. Вот. А здесь
гесиан, там будет вылезут просто разница матриц, все четко. Более того, на самом деле можно и доказать,
что все будет хорошо. Для этого нужны концентрационные неравенства, в частности, вот неравенство Хевдинга,
давайте я его пролесну, покажу, что оно используется. Потом можно в презентации просто посмотреть. На самом
деле, ну, предельно неравенства, они все более-менее похожи друг на друга. Суть их заключается в том,
что в некотором смысле оценить дисперсию. Здесь, ну, потому что мотождание тут ноль, здесь оценивается
дисперсия, тут можно эту щуянку впихать сюда. Вот. И тогда у вас здесь будет корень из N. То есть,
дисперсия вот такого вот, такой суммы матриц, оно для матриц случайно записывается, она уменьшается
как корень из N. Ну, понятный эффект вроде как. Вот. Понятно, что в тупом случае у вас вот этого корня из N
нету, вы просто дисперсию оцениваете как сверху, как А в квадрате, потому что матрица так ограничена
а в квадрате. Ну, оказывается, что если у вас они независимые между собой генерируются, понятно,
что возникает эффект, батч-эффект. Вот. И на самом деле можно воспользоваться теми равенствами хэудинга
для нашей задачи, для нашей функции fm. И почему я говорил про равномерность данных? У вас есть
гисиан один, гисиан другой. Вот. И получается, что здесь вот этот гисиан, который по конкретному
сэмплу, он зависит от этого сэмпла. И если этот сэмпл распределен равномерно, то есть вы конкретно
вот на этом устройстве их раскидали равномерно между собой, то в среднем этот сэмпл будет просто равен
честным гисиану. Это ровно как у нас был стахистический градиент, так взяли градиент по одному сэмплу,
в среднем это просто честный градиент. И здесь то же самое. Поэтому вот нужно равномерное деление,
чтобы воспользоваться хэудингом. И хэудинг вам даст, что оказывается, константа дельта, это
similarity, это просто константа l делить на корень из n, где n это количество данных, которые вы запихали
на устройство. И видно, что чем больше данных вы запихали, тем параметр похожести меньше. И вот
сейчас мы это будем использовать. Вот. Использовать мы это будем довольно-то хитро. Будем рассматривать
зеркальный спуск, знакомый уже с этим методом, но он возникнет сейчас в какой-то такой красивой
апостасе. Не для вот этих симплексов и так далее, а вот для конкретной задачи similarity. Вот. Как он
сходится, мы с вами знаем. Но здесь факт доказательства сделан другой через относительную
выпуклость и относительную сильную гладкость. То есть здесь предполагается относительная сильная
выпуклость относительно дивергенции Брегмана и гладкость аналогична. Но вы знаете, что там
дивергенция Брегмана, в частном случае, там евклидовой нормы, это просто вот такое вот. И вот
это определение, которое написано на самом деле по факту, ну в частном случае, эквивалент от
того, с чем мы обычно работаем. Но в общем случае можно определить вот так. Вот так вот гладкость,
вот так вот выпуклость. Относительную сильную выпуклость. В таком сеттинге тоже можно работать,
можно доказать сходимость. Вот. Вот такая вот получается, как у обычного градиентного спуска.
Только тут уже фигурируют константы сильной выпуклости, сильной гладкости в нашем конкретном
случае. Ну то есть вот эти относительные. Относительные дивергенции Брегмана.
И метод будет довольно хитрый. Давайте вот мы сейчас быстренько про него поймем физику. И
это главное, что нужно понять про этот метод. Дальше уже там скорее так. Будут больше такие. Я
вообще ни слова. Вот такой вот метод я хочу сделать, конкретно уже под нашу задачу. И
дивергенцию Брегмана породить вот такой вот функцией. f1, f1 то, что у меня хранится на сервере,
плюс дельта х. Дельта пополам х. Вот. Давайте порассуждаем. Вот я сделал к итерации этого метода.
К большой итерации. Сколько я сделал коммуникации? Вроде бы метод довольно сложный. То есть тут
нужно сначала градиент посчитать, потом вот эту аргумина отрешать. Вот. Сколько я при этом сделал
коммуникации? Вот. В этой методе. Опять же в ситуации, когда у нас есть просто сервер, например.
Вот. Куда мы все скидываем? Когда нам может понадобиться коммуникация?
Все правильно. Смотрите. Во-первых, понятно, нам нужно передать точку. Вот. Ну, вся операция,
которая, во-первых, мне точно нужна, это посчитать полный градиент точки VK. Поэтому мне нужно от
сервера передать точку VK. Все по ней посчитают градиенты. И дальше я на сервере соберу полный
градиент F. Вот. Окей, посчитали. Теперь мне нужно отрешать аргуминимум. Что мы можем про этот
аргуминимум сказать? Сколько тогда будет коммуникаций, чтобы отрешать этот аргуминимум?
Там же будет какая-то оптимизационная задача. Вот. Не самая простая, кстати. То есть, возможно,
этот аргуминимум придется решать численно. Вот. Не обязательно. То есть, там это будет явное
выражение. Он завязан на F1. Но то, что он завязан на F1, это ключевое. То есть,
аргуминимум зависит только от F1. Так. Получается, я посчитал градиент и больше его не трогаю. Так.
У меня осталась задача, которая зависит только от F1. Получается, я могу ее отрешать тупо на сервере.
Не коммуницирую я вообще. Вся идея вот в этом. То есть, вот за одну итерацию такого метода вы
коммуницируете один раз. Все остальные вычисления вы делаете тупо на одном устройстве. Это, кстати,
в некотором смысле новиночка тех методов, которые мы вообще рассматривали. До этого на все считали
все. И все были в некотором смысле равны между собой. Здесь у нас все вычисления делают одного
устройства. Ему нужно просто прислать градиент. И, оказывается, можно доказать сходимость этого
метода, оценить константы L и mu, и они окажутся довольно хорошими. L окажется единичке равна,
mu окажется равна своему значению. И получится вот такая вот сходимость. Сейчас покажу. Вот.
По количеству утераций вот так вот получаем. 1 плюс дельта делить на mu. 1 плюс дельта делить на mu.
Ну и давайте сравним, соответственно, с градиентным спуском. Ну, понятно, что лучше. Что лучше?
Какая лучше? Верхняя или нижняя оценка? Верхняя, конечно, лучше, потому что мы знаем, что дельта у
нас это L делить на корень из N, где N — это количество данных. Все. Вот он эффект. То есть вот мы
разбили вот за счет дополнительного предположения вот этого хитрого зеркального спуска. Мы пришли к
тому, что с точки зрения коммуникации и похожести мы вытянулись. Мы вытянулись отлично. Ну а теперь
немного про физику этого всего безобразия, чтобы стало еще более понятно. Смотрите, вот этот аргмент,
который я здесь записал, можно же честно реально подставить эту фи сюда и записать. Ну вот я
диверген субрегмана конкретно расписываю, который порождает функция вот эта фи, f1,
бла-бла-бла и так далее. Вот. Это вот порождается как раз вот этой нормой, просто этот ифклидова
норма в квадрате порождает вот такую норму. Вот. Получается вот такая вот задачка. Вот. И эту
задачку еще можно чуть-чуть покрутить, потому что под аргминемумом стоит, понятно, какое-то выражение.
Я, например, сюда могу написать vk дополнительно, потому что от vk у меня ничего не зависит. Ну,
аргминемум же это просто значение v. Поэтому добавление любого вещи, которое просто меняет
целевую функцию, оно не меняет аргминемум. Поэтому я могу сюда дописать vk, дописать что-то в духе вот
этого в квадрате, вот этого безобразия в квадрате. Вот. И занести это под норму. И получится вот такое
вот выражение. Вот такое вот выражение, что мы вот минимизируем на самом деле на каждой
итерации вот вот это. Вот. А это же на что похоже? f1 плюс, ну я могу даже дельту вот сюда написать,
плюс что? Что это? Ну вот это вот на что похоже. Я уже вроде показывал сегодня такое. Ну это
регулизатор. Вот. Это же просто регулизатор. Берем локальную задачку, говорим, минимизируем мне
эту локальную задачу. Там градиентным спуском, ускоренным, неважно. Вот, стахистическим методом.
Вот. Но минимизируй, пожалуйста, с регулизатором. И вот это в некотором смысле закольцовка идеи,
что здесь она тоже возникает. И без вот этой идеи с регулизатором жить довольно сложно. Вот. Тут
просто референс на точку довольно хитрая. Вот. Как еще на это все безобразие можно смотреть? То
есть мы поняли, сначала зеркальный спуск, первый вариант понятно. Оказывает, это еще и решение
регулизованной задачи. Но можно смотреть еще похитрее. Вот. Смотрите, как еще приятно это можно
смотреть, как будто у нас задача композитной оптимизации. Мы для нее знаем метод, этот метод
проксимальный. Проксимальный метод, который соответственно что? По одной из функций считает
прокс, а по другой честный градиент. Но это же здесь и записано было. Потому что здесь стоит как
будто градиент какой-то функции, а здесь другая функция. И оказывается, если эти функции g и g2
хитро определить, то у вас появится просто проксимальный метод. g2 это просто f1. Так. А здесь
у вас g1, в которой вы посчитали градиент. Разница f и f1. Тоже же вариант, потому что исходная задача
у вас f, а вы ее вот так вот расписываете на два куска. Искусственно, искусственно, но это же здесь
и проявляется. Вот. Получается вы сделали еще и проксимальный метод. Для такой вот задачи.
Композитный. Вот для такой. Единственная специфика этой композитной задачи заключается в том,
что у вас вот эта функция f-f1, она в общем случае вообще не выпуклая. Потому что разница двух
выпуклых функций, хрен знает, что с ней произошло. Но она дельта гладкая. Дельта гладкая, потому что как
раз у нее гессиан будет ограничен. Вот. А f1 выпуклая. Вот. Такая вот необычная задачка. Такая вот необычная
задачка. Получается, что вы делаете проксимальный метод для не выпуклой задачи. Ну, для не выпуклой
функции. Ну, общая, кстати, функция тоже будет выпуклая. Выпуклая. Как мы знаем. Вот. Получается у вас
один кусочек не выпуклый. Второй выпуклый. Вся функция выпукла. Но вот плохой кусочек. Он дельта гладкий.
А констат гладкости лучше. Поэтому вы как бы его выпихиваете на внешнюю террацию. А вот f1 вы
запихиваете в прокс. Вот. Еще один взгляд вот такой вот. Как еще можно на это все безобразие
посмотреть? Я здесь это не написал. Но смотрите, если вот для вот этого метода, который написан вот
здесь вот. Запишем шаг градиентного спуска. Запишем шаг градиентного спуска. У вас же что будет?
Считаться градиенту f1 в какой-то там новой точке. Ну, вот. Вы решаете тут вот этот аргминимум. Решайте
этот аргминимум дополнительным градиентным спуском. Ну, у вас что будет? Какой-то градиент
f1 считаться. Плюс градиент от этой нормы в квадрате. А из этой нормы в квадрате у вас
будет вылезать. Соответственно что? Градиент f в точке vk фиксированный. Минус градиент f1 в
точке vk. Вот что это такое? Там еще будут вылезать другие члены. Но вот. Вот так вот еще будут вылезать.
На что похоже? Честная функция, но в старой точке. Минус моя локальная функция в старой точке. Плюс
в новой точке. Редукция дисперсии. Ну, редукция дисперсии svrg. Но единственное, что тут стахастики
конечно нету, потому что у вас f1. Вот. Вот такую технику, которая, например, с проксимальным
оператором называется. Это называется слайдинг. Когда вы по одной функции сделали один градиентный
шаг, градиент зафиксировали. Но вот как здесь. Опять же, по функции этой вы сделали один
градиентный шаг, градиент зафиксировали. А по второй функции продолжаете итерироваться.
По этой функции вы итерируетесь, по этой функции у вас все зафиксировано. Это называется техника
скольжения. По одной функции вы скользите, а другой вы фиксируете. И по этой небольшой шаге
делайте по этой вот такая вот физика этого всего безобразия вот то есть тут
довольно такие красивые идеи смотрите заканчивать нужно ну давайте быстренько
совсем и обзорно покажу что еще тут можно сделать и что сделано смотрите то
есть вот наша оценка вроде как лучше чем у градиентного спуска у скорины
нестеров дает корень какая из них лучше вообще непонятно то есть корень может
быть даже лучше чем дельта делить на мю вот и была получила нижняя оценка там
в 15 году что вроде как можно добиться результата того чтобы получить
ускорение для similarity но 8 лет этого добиться не могли что-то куча работ было
от разных авторов но получилось у нас в прошлом году на конференции подали
статью что этот результат возможен вот такой вот метод довольно хитрый то есть
тут используется сразу три идеи 1 это ускорение нестерова плюс идея слайдинга
но первое как раз вот первое второе это понятно что это нужно делать потому что
чтобы получить ускоренный метод нужно ускорить его вот поэтому нестеров там
нужен слайдинг ну опять же слайдинг как раз нужно для того чтобы вытащить
similarity мы это и использовали для этого ну как называйте как угодно это мир
аппрокс там не зеркальный спуск такой специализированный слайдинг вот но
треть вот треть первые две идеи не давали результат на самом деле то есть
понятно что люди бились пытались третья идея на самом деле дала результат
использование экстраградиентного метода непонятно как бы физика поэтому понятно
что здесь это можно сделать да да что-то даст результат но оказалось дало дало
в силу специфики как раз задачки то что там есть не выпуклый кусочек вот а
экстраградиент он в некотором смысле как бы придуман то прежде всего для
седловых задач и вариационных неравенств и вот там вот не нужно как-то
пользоваться вообще существования функции там достаточно просто полипшится в
исте оператора все расписывать и эта идея выстрелил то есть тут вот видите такая
синергия трех идей ускорение слайдинг плюс метод вообще для седловых задач и
вариационных неравенств который оказался классный с этой точки зрения вот так
ну еще здесь еще рассказываю говорю о том что опять же результаты нестира можно
ускорить за счет специфики задачи и результаты семиллярити тоже можно
ускорить за счет специфики задачи вот потому что если у вас задача соответственно
дает вот такие вот оценки можно вы выбить оценки лучше за счет того что
вы введете дополнительную специфику еще например скажете что теперь можно
пересылать жатую информацию вот разрешите сделать компрессию потому что
нижние оценки для семиллярити были придуманы исходя из того что вы передаете
полные градиенты поэтому получается вот такая вот оценка и так далее дальше вы
говорите окей я разрешаю делать коммуника сжатия нижняя оценка становится лучше
нижняя оценка становится не ну меньше и метод станет появляется который это
может сделать вот введение опять же дополнительные специфики разрешить не
просто учитывать семиллярити но сделать еще компрессию соединять эти две идеи и
как раз может дать дополнительный буст дополнительный буст и получится еще более
такая хорошая синергия вот и более классный результат с точки зрения
исходимости в частности вот тут был м можно поставить им в степени 3 четвертых
здесь вот вот чуть-чуть улучшить результат ну в частности тут все статьи
которые написаны ну одна моя тут две моих первая ну она так вот вторая на
на текущем не все была только что вот ее пару дней назад постер в америке
представили вот третья она на айси лар это вторая по крутости конференции по
машинам обучение вот как-то так все это все на сегодня все ну и вообще это все
по всему курсу спасибо кто дожил в таком небольшом количестве но дожили
приятно вот от меня и от всех ребят кто делал этот курс ну все тогда
поздравляю вас наступающим желаю хорошо сдать сессию у вас была гана какая-то
такая довольно жесткая но я надеюсь там вы семинаристами договоритесь так
чтобы переход именно от зачетной недели по оптимизации к сессии у вас был
довольно плавненький все спасибо большое
