Сегодня поговорим про сложность задач опроксимации или про
приближенные алгоритмы. Ну и тут как обычно в теории сложности вычислений
значит идет двустороннее движение. С одной стороны находится все больше и
больше задач, которые можно решать приближенно, но с другой стороны для
большего и большего числа задач показывает, что это невозможно, если только p не равно
np. Вообще изначально задачи опроксимации воспринимались как ну такой как бы ключ
к проблеме p и np, то есть если p не равно np, то вроде как многие задачи не решаются,
в том числе многие задачи оптимизации, но на практике и не нужно решать задачи
оптимизации точно, значит достаточно решить с какой-то точностью. Например,
если есть задача минимизации расходов там на что-нибудь, ну например задача Коми-Ваежора,
значит где Коми-Ваежор должен проехать минимальное расстояние и посетить все
города. Соответственно, если эта задача взялась на практике, где реально нужно что-то объехать,
и вы, например, умеете ее решать не прямо-таки находя минимум, а находя минимум там плюс не
больше 5%, то это уже очень хорошо и на практике особо больше ничего не надо. То есть какие-то
там высчитывать копейки, снижать точность с 5% до 3%, это в общем обычно не нужно.
Вот. Но с другой стороны, если ваш путь, например, там в 5 раз длиннее минимального,
да, то это уже не очень хорошо. Да, хорошо бы, чтобы все-таки что-то близко к оптимуму находилось.
Вот. Ну и, соответственно, это предполагалось как некоторый такой ключ, на что если даже мы не
умеем решать задачи точно, но умеем делать это приближенно, то тогда в общем не страшно,
что P не равно NP, но мы как-то решим что-то приемлемое получим и будем использовать.
Вот, вообще такая была идея в 70-х, но потом к началу 90-х оказалось, что для некоторых задач
это так происходит, но для других задач приближение сверх какой-то точности уже будет NP трудным.
Вот. То есть тут, вот про это я хочу сегодня поговорить. Значит, что такое вообще задача оптимизации,
да, и связана с ней задача опроксимации. Так, значит, задача оптимизации,
значит, известна некоторая функция f от x и y, значит, известна некоторая функция f от x и y
с значениями, ну, каких-то числах, да, натуральных, там, рациональных, значит, функции f от x и y,
ну, с числовыми значениями. Вот. Ну и, соответственно, дано x, значит, а найти нужно,
значит, либо максимум f от x и y по y. Ну и тут предполагается, значит, тут, как обычно, очень много умолчаний,
да, то есть предполагается, что функция вычислимая и заполинальное время длины x, значит, вычислимо за
время полином от длины x, именно x, а не всего входа, да, потому что это нам дает и ограничение y полинной
длиной, да, то есть тут, соответственно, длина y меньше либо равна, чем какой-то полином от длины x,
и это дает нам конечную область, которую мы максимизируем, и, соответственно, максимум
точно достигается. Вот. Ну, соответственно, вот это, когда я говорю, найти максимум, то это прям найти
значение максимальное, вот, или другой вариант, когда нужно найти arg максимум, то есть точку максимума,
вот, ну или минимум может быть, да, то есть всегда можно, в принципе, сменить знак у функции и свести
задачу максимизации к минимизации наоборот. Вот, значит, это задача апроксимация, вот, а задача
оптимизации, ой, задача оптимизации, задача апроксимации несколько более со слабыми требованиями.
В общем, задача апроксимации, значит, с параметром rho от нуля до единицы, да, означает, ну, что нужно
найти у, да, значит, вот пусть опт, это оптимальное значение, значит, вот опт равняется,
то есть, как раз, максимум по y, f от x и y, и соответственно, нужно найти, значит, найти нужно число какое-то,
ну, такое тка большое в интервале от rho умножить на опт, то опт, это все для задачи
максимизации, ну, или y, или y такое, что f от x и y, ну, тут смотрите, когда я пишу
найти число, то нужно обязательно, чтобы он не превысило оптимум, если я конкретно y нахожу,
то там значение точно оптимум не превысят, и поэтому можно в одну сторону писать, что это
больше либо равно rho умножить на опт, ну, число у нас же функции с частотами значениями,
не, не взять даже одно из значений, просто заведомо, чтобы оно попало в этот интервал,
смотрите, это не так легко, как кажется, да, значит, потому что нужно заведомо не перескочить вот
этот опт, если бы у нас было только нижнее ограничение, то можно было там максимально
возможное значение взять и сказать, что это решение, вот, но нам нужно обязательно не превысить вот
эту границу, не, ну, вот так вот, но опт вычислено по f, и вот нужно найти k в этом интервале,
любое k в этом интервале подойдет как решение, но нужно заведомо, чтобы алгоритм давал число именно
в этом интервале, ну, типа того, да, конечно, то есть вот, да, вот с задачей оптимизации у нас
бывает два варианта, либо это само значение максимальное, либо точка, на которую оно
достигается, вот, вот если мы первые приближаем до значения, то нам нужно все-таки не превысить
абсолютный максимум, да, но при этом быть больше, чем rho от него, вот, если мы прям ищем, если на задачу
поиска нужно найти y, тогда только односторонняя граница, потому что вторая автоматически соблюдется,
вот, ну, а если минимизация, то, ну, либо там делить на rho нужно и все менять местами, либо считать,
что rho тогда больше единицы, и, соответственно, нужна, давайте я напишу, значит, если минимизация,
тогда тут k должно быть соответственно от opt до opt делить на rho, значит, ну, это вот если мы
хотим, чтобы rho было всегда 0.2 единицы, либо можно сказать, что rho будет больше единицы, и на него нужно умножать,
вот, а вообще тут как бы не сложилось такого универсального подхода, да, то есть для
максимизации обычно вот так вот, все-таки rho будет меньше единицы, и говорит, ну, да и даже бывает,
да, там если это rho близко к единице, то иногда там, наоборот, на 1 минус rho смотрят, да, то есть
приблизить 0.5 процентов это не значит 5 процентов от максимума, а наоборот 95 процентов от максимума,
такая обычно, вот, ну, а здесь, соответственно, когда у нас минимизация, то могут говорить
приближение с точностью две трети, а могут говорить приближение с точностью три вторых,
в зависимости от того, тут мы делим на rho или умножаем, вот, в общем, тут
не сложилось прям универсальных обозначений, да, то есть часто для, ну, отдельно авторы в своих
книгах или в отдельных задачах, в общем, своих договоренностей, которые как-то друг с другом
не стыкуются, но обычно из контекста понятно, что имеется в виду, вот, да, ну, и, соответственно,
допишу, а f от x и y будет меньше либо равно, чем opt делить на rho, вот, хорошо,
значит, ну, как я понимаю, вот, мы на лекции пропустили, а на сценариях была дарандомизация,
и там как раз задачи аппроксимации решались, так, а был, видимо, только была задача максимальном
разрезе, а еще что-нибудь было, например, max3sat, например, было, и 7-8 там прям было, да, а 7-8 было
очень хорошо, тогда будем считать, что вы знаете, вот, так, ну, хорошо, значит, тогда я этот пример не буду
повторять, вот, а покажу пример, когда вообще ни для какого rho нет приближения, значит, пример
когда нет приближения, значит, это задача комива-ежора с произвольными стоимостьями, да, с произвольными весами,
значит, задача комива-ежора с произвольными весами,
значит, тут, что имеется в виду, ну, вы можете считать, что просто есть матрица,
она там w, может быть, даже несимметричная, значит, w это матрица такая, что w и gt это стоимость проезда
из и в ж, ну, может даже считать, что и на диагональ не обязательно нули стоят, вот, но можете считать, что нули, так, давайте считать, что эти все
w и gt больше брона нуля, вот, хотя, если у нас задача комива-ежора и нужно один раз все обойти, то даже это не важно, можно к ним ко всем прибавить одно и то же значение, так, чтобы они стали больше нуля, даже если были меньше нуля, да, то есть, вообще, если, то, то есть, тут смотрите, чем плохи отрицательные веса, тем, что может получиться отрицательный цикл, а поэтому в отрицательном циклу дальше, как бы, можно ходить и накручивать сколько
угодно маленькое расстояние, но если мы потребуем, что нужно ровно один раз попасть в каждой вершине, тогда это не важно, да, тогда мы не сможем накручивать, вот, но все-таки, так, привычно, чтобы это были не отрицательные величины, так, ну, и, соответственно, нужно
ну, задача, значит, нужно минимизировать
нужно минимизировать
тумму
по и объединится до n
w и t сигма от и t
по всем сигма, значит, по всем
перестановкам сигма, состоящим из одного цикла
да, значит, можно вот так вот
вот, ну, соответственно, эта задача
непотрудная
ну, сейчас давайте покажу, что даже приближенные решения тоже непотрудные
причем с любым весом
ну, соответственно, там, не с любым весом в смысле, а с любой точностью, а с любым rho
вот, значит, это вот точная задача
ну, а приближенная, соответственно, найти какой-то, это минимизация, да, так что, найти какой-то минимизация
то есть, что мы будем делать
вот, значит, это вот точная задача
ну, а приближенная, соответственно, найти какой-то, это минимизация, да, так что, найти либо величину вот здесь вот, да, либо какой-то путь найти, который будет
не длиннее вот этого
вот, значит, ну, соответственно, это
эта задача
NP трудна
любой точностью
ну, не знаю, или для любой точности, да, давай выводится лучше
для любой точности задача NP трудна
значит, почему?
ну, потому что можно к ней свести гамильтонов цикл
сведем гамильтонов цикл
каким образом мы это сделаем?
ну, мы просто скажем, что WGT
равно единице, опять, вообще, если ноль разрешить, то можно даже
даже для неконстантных РО
можно это доказать
значит, WGT равно единице, если
было ребро ИGT
значит, если в графе
есть ребро ИGT
иначе получится, значит, на счет WGT
равно какому-то большому числу
равняется n большому
вот, ну, это получается, что если гамильтонов цикл есть
есть гамильтонов цикл, тогда минимальный вес
равен m
значит, потому что можно по нему пройти, и каждый ребро до склада 1
суммарно будет m, маленькое
n маленькое в смысле число вершин
а вот если нет гамильтонов цикла
ну, тогда, соответственно, в любом цикле, обходящем все вершины
у нас будет хотя бы одно неребро
и это неребро даст вклад n большое
значит, тогда минимальный вес
больше ли равной n большого
ну, и, соответственно, варьируя n большое
можно добиться любого отношения
вот, ну, а далее
если у нас есть гамильтонов циклов
вот, ну, а дальше
то есть, вы смотрите, что нужно
значит, если у меня n
n делить на ρ меньше
чем n большое
тогда получится, что по приближенному решению
по приближенному решению
можно найти
есть ли гамильтонов циклов графия
ну, потому что алгоритм, даже если он только число выдает
выдаст либо
приближенный алгоритм
выдаст
либо
k меньше, либо равно, чем n делить на ρ
либо k больше, равно, чем n большое
ну, и, соответственно
взяв такие сравнения, можно понять
что именно имеет место
ну, вот, соответственно
отсюда получается, что ρ
больше
не, лучше не относительно ρ
относительно n большое
а, собственно, уже все написано
относительно n большого
то есть, если есть n маленькое
и ρ
тогда, взяв n большое
вот таким вот
можно получить, что задача будет n п трудной
ну, то есть
итог
то
при n
больше, чем n делить на ρ
задача ρ приближения
будет
n п трудней
вот
так, ну что, прямо в понятном?
так, хорошо, с другой стороны
если рассмотреть не общую задачу мива и жора
а какой-нибудь частный случай
то тогда можно вполне с какой-то точностью решить
значит, например, можно рассмотреть
метрическую задачу кумива и жора
метрическая задача кумива и жора
значит, что там неравенство треугольника
выполняется
то есть w и jt
плюс w jk
будет больше
чем w и kt
вот
это, конечно, для нашего примера
предыдущего не подходит
потому что может быть так, что
тут 2 ребра есть и будет 2 единицы
а тут будет n большое
и, конечно, неравенство нарушается
вот
значит, тогда есть очень простой алгоритм
приближения с точностью 2
значит, алгоритм приближения с точностью 2
вот
но я не хочу в подробности вдаваться
на идеи, там следующее
вначале нужно
вначале нужно найти
минимально остовное дерево
и для этого есть специальный алгоритм
я знаю, вы это изучали
там есть, я не знаю
там есть, я не знаю
вы это изучали
там алгоритм
что еще раз?
ну там разное есть
сейчас
мне кажется, вы что-то другое хотите рассказать
чем-то, что я хочу рассказать
да
да, это правильная фамилия
сейчас
вы хотите сразу для цикла
или для остованного дерева сначала?
а, ну хорошо
да, в общем
они есть разные
а, вы прямо вот это рассказывали
а, на натуральном курсе
хорошо
да, в общем
есть разные
да, например
можно найти остовное дерево
и потом его обойти
два раза
и потом еще сократить
например
найти остовное дерево
и
обойти
и ребра
дважды
ну если это потом сократить
да
ну я обгадал, когда у нас есть не раз треугольник
то вместо того, чтобы идти в вершину потом
следующую можно прямую пройти
и это будет уменьшение
по крайней мере
значит
потом сократить
путь
вот, значит на самом деле
есть даже
алгрит с точностью
3 вторых
как недавно выяснилось
значит этот алгоритм
десятки лет
назывался алгоритм Кристофидоса
вот, а потом оказалось, что
независимо от Кристофидоса
в Новосибирске
математик Сердюков тоже его придумал
и опубликовал там
в какой-то локальном издании
вот, а потом
в Новосибирске
вот, а потом
в Новосибирске
в каком-то локальном издании
вот, так что
и это в общем признано
признано сообществом
так что теперь этот алгоритм
называется
алгоритм Кристофида Сердюкова
вот
значит
так же там
есть какое-то недавнее
достижение
где
вероятностный алгоритм
и там получается
3 вторых минус эпсилон
для очень-очень маленького эпсилона
вот,
реально очень маленького
10 минус 30
или что-то такое
в таком духе
это театрическое достижение
вот, но с другой стороны
с другой стороны
именно
ограничение с другой стороны
что с точностью вот такой вот
122-121
значит
это будет НВ трудно
вот, но вот
между этими величинами
разрыв происходит
то есть вот это 122-121
она тоже увеличилась
ну в смысле наоборот
дробь увеличилась
а числа уменьшались
там было сначала
200 с чем-то
потом там 180
но здесь вот имеется разрыв
и вот это на самом деле
довольно типичная ситуация
бывает так, что разрыва нету
вот как для 7-8
для Max-3SAT
там 7-8 есть
алгоритм, а 7-8
плюс эпсилон ЖНП трудно
вот, либо может быть
разрыв, либо вообще может быть
только с одной стороны что-нибудь
так, ну надо сейчас дать прерыв
сделаем потом поговорим
что-то еще бывает
может еще пара задач обсудим
так, я еще хочу немножко
про задачку
Комиевоежора
забыл сказать одну вещь
есть еще и частный случай
метрической задачи Комиевоежора
это Евклидова задача Комиевоежора
Евклидова задача
Комиевоежора
значит Евклидова означает
что все веса это просто расстояние
в Евклидовом пространстве
в каком-то может быть многомерном
может быть прям на плоскости
что собственно всей представляет
глядя на географическую карту
да, то есть тут
W ежито
это просто какое-то расстояние
от точек там и к слиту
и к сжито
вот, так вот в этом случае
все равно сдача НП трудная
точная оптимизация
да, значит тут соответственно
точная задача все равно
НП трудная
но при этом для любого Эпсилона
для любого Эпсилона 1 минус Эпсилон
приближения
уже Пальномиальная задача
но при этом Пальномиальная
она будет
от размера матрицы
то есть от N
но не от Эпсилон
то есть тут
Пальномиальная от N
и экспоненциальная
от 1 дель на Эпсилон
то есть если Эпсилон фиксирована
то тогда это Паленом от N
но если у нас и Эпсилон
тоже стремится к нулю
даже как там 1Н
то все равно
это будет экспонента в итоге
но если Эпсилон стремится к нулю
как 1 дель на логариф МН например
то это будет
Паленомиальная задача
в общем для таких случаев
используют аббревиатуру ПТАС
ПТАС означает
Полиномиал тайм апроксимейшн с ким
то есть схема апроксимации
за полиномиальное время
ну вот
Евкриза. комовые жоры
один из известных примеров
такой ситуации
бывает еще
FПТАС
FПТАС
это если бы
от 1 Эпсилона
было бы не экспонента
а полином
но такое уж совсем редко встречается
хорошо
теперь я хочу поговорить
про разные задачи
в частности про задачу
МАКС-3САТ
задача МАКС-3САТ заключается в том
что на 3 КНФ
и нужно максимизировать
число истинных скобок
нужно
максимизировать
число истинных скобок
при этом
3 тут реально 3
в каждой скобке ровно 3 литерала
ровно 3 литерала
в каждой скобке
тогда как вы изучали
на семинарах
есть полиномиальный метод решения
можно решить
за полиномиальное время
с точностью
7 восьмых
7 восьмых плюс Эпсилон
это называется PCP теорема
с точностью
7 восьмых плюс Эпсилон
это будет NP трудно
эта теорема
реально сложная
даже если тут не для 7 восьмых плюс Эпсилона
а просто для какого-то
множество
то
все равно это дело
много лекций
нужно изучить некоторую технику
под названием техника экспандеров
и даже с этой техникой
много нужно повозиться
я иногда читаю спецкурс
семестр доказывает теорему
изучая попутно
все что для него нужно
а вторую половину
и еще всякие другие
приложения, уточнения
почему PCP?
и это само по себе очень интересно
PCP означает
какие-то совершенно не связанные
с этим слова
а именно PCP это
probabilisticly checkable proofs
то есть вероятностно проверяемые доказательства
там нет ни слова про
проксимацию, про NP полноту
какие-то вероятностно проверяемые доказательства
и то, что это про одно и то же
это само по себе
некоторое интересное достижение
в общем
про это я сейчас не буду говорить
подробнее
а вот про что скажу
это про связь, вот это приближение
7 восьмых плюс эпсилом
с другими задачами
связь
связь Max3SAT
с другими
задачами
так, ну и план у меня такой
что я сначала поговорю
про вершинное покрытие
значит
minimum vertex cover
вот
а потом
проговорю про максимум
максимально независимое множество
maximum independent set
вот
и оказывается, что в случае
с вершинным покрытием там тоже есть
некоторое другое пороговое значение
которое точно так же
разделяет
вот
а в случае
а точнее
нет сейчас
это я немножко преувеличиваю
потому что
тут
как бы вот это вот
7 восьмых плюс эпсил
я переведу в некоторое другое значение
но вот этот алгоритм, который 7 восьмых
он не перейдет в алгоритм
с такой же точностью
там есть разрыв такой же
как для метрического комевого эжора
хотя и поменьше
ну а максимум independent set
получится, что на самом деле
ни с какой точностью не будет аппроксимации
то есть вот это будет NP трудно
при достаточно
хорошей точности
вот
а это водит NP трудно
при любой точности
вот
ну и в некотором смысле
вообще вся эта область
теории она повторяет
просто теория NP полноты
но тут
сводимости разрабатывают с таким расчетом
чтобы они сохраняли и
разрыв в приближении
то есть чтоб не только
точное решение одной задачи
превращалось в точное решение в другое
но и приближенное превращалось в приближенное
может быть и другим множителем
вот
и в зависимости от того
насколько это можно
превратить
насколько этот разрыв
сохраняется при переходе
на ту или иную сводимость
мы будем получать разные результаты для разных задач.
Так, ну хорошо.
Значит, минимум vertex cover.
Минимальное вершинное покрытие потребует некоторой
специальной свадимости. Значит,
не такой, как мы изучали раньше.
Ну,
ну,
ну,
ну,
ну,
ну,
ну,
ну,
ну,
ну,
будет следующее, первое для мини-вертых скавор, значит
тут n переменных m скобок превратится в 7m вершин.
Ну а ребер уж сколько получится, а вот n не влияет на, но n повлияет
на число ребер косвенно, но точно так же, как и в то
какие скобки.
Вот так что число ребер там не фиксировано уж какое
получится.
Вот, значит смотрите, у нас с каждой скобкой вязано
7 значений, при которых она истинна, то есть скобка
это 1,2,3, там 3 аргумента, 8 возможных наборов значений,
из них для одного будет 0, а для семи остальных будет
0, то есть например, значит p или не q или r, значит нам
даст значение так 0,0,0, и это же будут вершины, почему
7m, потому что 7 это число выполняющих наборов в одной
скобке.
Так, 0,0,0,0,1, дальше 0,1,0 как раз пропускается, потому
что 0,1,0 даст 3,0, значит 0,1,1, и дальше значит 1,0,0, 1,0,1,1,1,1,1.
Вот, и они все друг с другом соединены, да, значит я тут
уж не буду прям клик рисовать, ну там какое-то количество
проведу, да, значит это клик.
Вот, и так для каждой скобки, то есть например тут будет
какая-нибудь другая, скажем не p или r или не s, да, значит
тут соответственно будет все кроме 1,0,1, то есть тут
0,0,0,0, 0,1,0, 0,1,0, 0,1,0, 0,1,0, дальше 1,0,1 пропускается,
потому что даёт 3,0 здесь и соответственно 1,1,0, и
соответственно тут тоже тоже клика вот а теперь ну и так для каждой
скупки я уж не буду больше рисовать значит важно какие скупки мы друг другу
соединяем значит соединяем мы те которые противоречат друг другу
да значит например вот это вот мы соединяем вот с этим да значит потому
что здесь да значит смотрите тут цифр который здесь написано значение
переменных не значение литералов на то есть вот тут вот сказано что п равно
нулю а тут вот здесь вот сказано что п равно 1 и соответственно если значение
в двух наборах противоречит друг другу то это мы соединяем ребром вот или
например значит например вот это вот вот это мы тоже соединяем вот с этим но
не за п да п и там и там равно единица а противоречие возникает в эр значит
здесь вот и р тут на третьем месте поэтому тут р равно единице а тут р на
втором месте тут р равно нулю ну и так соответственно все пары которых
противоречащие друг другу значению одной переменной мы соединяем ребром вот
но вот такой граф получается
может быть конечно и два противоречия сразу вот у этого с этим сразу два
противоречия значит тут п равно единицы и р равно
единица вот а тут п равно нулю и р равно нулю
вот
вот так устроим граф начинает думать с понятием теперь вопрос
что тут с вершинным покрытием но утверждает что формула сначала давайте без
приближения просто вообще свадебность значит формул выполнимо
форму выполнимо тогда я только тогда когда в графе есть вершинные покрытия
из 6 им вершин
значит всего 7 вершин а покрытие 6 им вершин значит почему ну одну сторону
пусть порно выполнимо тогда есть выполняющий набор тогда что мы сделаем
значит у этого выполняющего набора есть соответствующий ему вершина в каждой
вот такой вот клике что выполняющий набор значение каждой переменной вообще
а мы для трех из данной скобки выбираем фрагмент этого
выполняющего набора и все остальные 6 вершин мы включим вершины покрытия тогда
что получится получится что внутри клик мы все ребра покрыли потому что мы 6
из 7 вершин взяли если с каждой у каждого ребра хотя бы один конец
попал вот а вот такие вот ребра между кликами не покрытыми остаться быть не
могут потому что они друг другу противоречат значение какой-то
переменной а то чтобы не покрыли совпадает друг другом по значению
переменной потому что мы взяли фрагменты домой того же выполняющего
набора вот поэтому и все ребра внутри клик
покрыто и между кликами тоже покрыто получается вершинное покрытие вот ну
значит это поэтому получается свадимость у нас ангель тоже самое то же самое
рассуждение можно обобщить на апроксимацию
да а подождите я только одну сторону доказал да я только сверху вниз
доказал но снизу я что же получается потому что смотрите в каждой клике нужно
хотя бы 6 вершин взять иначе там будет 5 из 7 две не покрытое нам между ними
ребра не покрыто поэтому если у меня ровно 6 тем вершин значит ровно по 6
каждой клике вот ну а тогда оставшиеся не покрытыми должны быть согласованы
друг с другом иначе скажем если вот это не покрыто и вот это не покрыто да то
вот между ними ребра не покрытое вот а раз они да значит ну вот значит если и
не согласованы друг с другом не покрытое то это не вершинное покрытие
вот значит они должны быть согласованы друг с другом то есть у каждой переменной
ровно одно значение во всех непокрытых и можно его взять как выполняющий набор
и это действительно будет полнейший набор потому что ну как бы все все вот
эти 7 фрагментов выполняющие для скобки вот не выполняющим и заранее
исключили вот так ничего понятно ну вот хорошо значит все-таки туда и туда и
обратно посуждение выполнено вот а для приближения получается так что в
значит формуля значит формуля выполнима значит доля скобок доля скобок больше
либо равно чем ров вот это будет равносильно тому что у графа у графа есть
вершинное покрытие
размера меньше либо равно чем 7 минус р умножить на им
то что мы уже доказали частный случай для ров равно единице
вот почему же это в общем случае выполняется
ну потому что смотрите но пусть пусть выполним вот опять же сверху не сначала пусть выполним
вот такая доля скобок но мы возьмем в плаще на возьмем набор при котором выполнена такая
доля скобок и тогда для тех скобок которые выполнены мы как раз возьмем 6 вершин все
кроме той 3 которые соответствуют фрагменту этого набора а для тех где которые не
выполнено просто все 7 возьмем вот ну и тогда получится что в случае рома взяли да значит
получится что ровно жить на
рон аэм да значит рон аэм число скобок и умножить на 6 не плюс 1 минус ро на им
на 7 вот это раз и будет 7 минус рон аэм 7 минус рон аэм вот
и это будет по тем же самым причинам что и раньше это будет вершины покрытия на то что
все где 7 они там вообще все покрыто а у тех где 6 не покрыты не могут соединить
ребра между собой так как они друг другу согласованы вот ну и другую сторону тоже
примерно также да опять же 5 вершин из клики у нас не может быть то есть если вот такое
число вершин взято то значит как раз 6 будет 6 вершин из вот такого числа клик и 7 вершин
из всех остальных и вот эти вот не покрытые вершины друг другу согласованы не дадут
набор при котором как раз все скобки которым соответствуют вот эти клики будут выполнены
вот и что же в итоге значит в итоге разрыв ро
значит разрыв между ро и единицей превращается в разрыв между 6 и 7 минус ро да и можно сократить
вот но получается например если если ро у нас 7 восьмых то тогда тут получается
есть и есть и одна восьмая да это у нас 49 48 получается да
ой не сейчас не сорок восьмых сейчас нет чуть-чуть 49 восьмых 6 49 восьмых то есть
вот это вот как бы если мы еще на 6 поделим на то множество получается 49 48 собственно
вот видите вот тут было там 122 121 это вот не случайно не так это на самом
121 получалось зазор вот а вот здесь зазор одна сорок одна сорок восьмая получается
значит зазор это смотрите тут одна восьмая тут одна сорок восьмая это как бы какую часть на
какую часть от вот этого будет больше вот это да то есть мы фактически 49 восьмых еще на 6
поделили значит получили 49 48 вот а зазор получается одна сорок восьмая но то есть
больше получается что-то больше и точностью будет np трудно приблизить задачу о вершинном покрытии
потому что если приблизили с большей точностью то тогда получится что мы с точностью больше
чем 7 восьмых решили задачу макстриса то это невозможно попись пятиоремии если только пони равно np
ну вот хорошо значит и теперь последние 10 минут немножко я поговорю про максимально
независимое множество значит я напомню что дополнение вершинного покрытия независимое множество
дополнение вершинного покрытия это независимое множество соответственно
ну как бы автоматически из предыдущих конструкций получается тоже разрыв причем как бы назад все
переворачивается и снова те же самые 7 восьмых получается из предыдущей из предыдущей конструкции
получаем разрыв
м и или роем на потому что всего всего 7 м вершин соответственно мы вычитаем либо 6 м либо 7 минус
ро на м и обратно получается либо м либо роем то есть то есть единицы или ро снова 7 восьмых
вот но после этого можно его увеличить значит можно разрыв
нарастить значит а именно это называется возведение графов степень некоторым специальным
образом значит из графа g можно перейти в же степень и к значит здесь вершины
да что-то это вот же а же это будет ве вершины же в степени к это к элементные
к элементные под множество в
вот ну и дальше значит
пара ст соедина ребром
точнее дайте я так напишу она не принадлежит значит не соедина
ребром если и осуглеение ст это независимое множество в графе g то есть если есть хоть одно
ребро в том числе внутри s то тогда с и т соединены ребром да в частности значит если
само себе с не независимое множество то она вообще со всеми соединено ребрами можно в принципе
вообще исключить вот а если с и т оба независимая но убедения уже не будут независимы тогда тоже
ребро между ним проводится вот дать грубо говоря получается что любое ребро из
ст поднимается ну из одной вершины с какую-то вершину т поднимается до либра между с и
т и если внутри с внутри ты есть ребра то они тоже поднимаются до с и т есть ничего нет тогда
ребра нету вот значит ну ясно что если к фиксировано если к фиксировано то число сочетания
пока это полином поэтому сводимость полиномиальная при фиксированном к
при
при фиксированном ка сводимость
полиномиальная вот ну а дальше утверждение такое
утверждение что если альфа это число независимости же то тогда число сочетаний из альфа пока это
число независимости же в степени к
но это как раз мы максимально но размер максимально независимого множества вот значит почему это так а
значит если мы докажем то дальше там некоторая выкладка в том что вот если
сейчас в общем выкладка такая что дальше с из ро м пока поделить на цзм пока это будет
иметь порядок рог степени к ну комбинаторное такое утверждение вроде должно быть понятно откуда
оно следует вот и тогда соответственно у нас рог было 7 восьмых а беряка все больше и больше
меток ну любому стремлять вот из чего же следует утверждение но во-первых если в графе же было
независимое множество размера альфа то все его к элементные под множество образуют независимое
множество в же степени к потому что все это объедение будет вложено в независимое множество да и
соответственно ребер не будет вот поэтому отсюда получается нижняя оценка значит нижняя оценка
будет вот такая вот но верно и верхняя оценка значит потому что если будет еще больше множество
к элементных то они все в объединение да может сказать так что есть у меня есть независим множество
вот в этом же степени к то объединив все эти множества я получу независим множество в исходном
графе вот но если их будет больше чем столь кто там точек будет больше чем альфа но тоже такая
комбинаторика значит нужно оценить что но это более-менее более-менее понятно да что если у
меня альфа точек то у меня вот столько к элементных множества есть у меня больше множества мне нужно
больше точек потому что альфа бы не хватило вот и тогда получилось бы больше чем альфа независимое
множество в исходном графе ну вот вот такая вот идея получается что независимое множество
но как следствие клика тоже это вот задача трудно поддающаяся аппроксимации вот что отнюдь не так
очевидно как для комивого ежора где все следует из гамильтонного цикла
вот ну и это действительно так то есть это и на практике сложная задача то есть насколько
я понимаю может быть так что у вас сеть скажем из 10 тысяч вершин и заведомо известно да то есть
как бы одна сторона берет какую-то случайную сеть или там какую-нибудь в общем какую-то сеть из
10 тысяч вершин и туда прям намеренно устраивает клику из 50 вершин вот и предлагается теперь ее
найти вот они получается получается максимум 25 найти задача встроенной клике что известно
что в граф встроена клика ну например можно можно взять например случайный граф там будет
по теореме средняя там клика будет так такого-то размера вот ну не средняя среднем по испытаниям
размер максимальный клики будет такой-то а мы устраиваем сильно больше и пытаемся его найти и
вот мне не получается вот но говорят что это может быть важная задача для спецслужб что находить
да это самое какой-то сети контактов находить скрытые клики которые возможно делать то что не
нравится спецслужбам но вот к счастью ли к сожалению значит это задача трудно решается так что
это не решить не получится вот так ну все значит на этом курс завершается спасибо что слушали
значит получается что у нас остается контрольная и какой-то там чего вопрос
вот
возможно я буду читать спецкурс осенью может быть как раз вот про это вот прописи пе может
нет это выложил канал там уж какой-нибудь опрос буду проводить что хотят слушать граждане
все спасибо
