Сегодня поговорим на тему, которая немножко особняком стоит. Эта тема называется схемная сложность.
Глобально оставшиеся три апрельские лекции будут посыщены различным вероятностным вычислением.
Поговорим про вероятностные классы, про их соотношения с разными классами, которые мы изучили,
и в том числе с этими схемными классами. Поэтому мы их сейчас немножко обсудим.
Еще будет тема про интерактивные доказательства. Насколько я понимаю, в одной группе про них уже пытались поговорить на семинарах,
но мы про них какие-то базовые вещи изучим, которые пригодятся осенью на курсе по криптографии.
Поэтому про схемную сложность я расскажу не очень много, какие-то самые базовые вещи, которые нам будут нужны
в теме про вероятностные вычисления. В некотором смысле эта тема стоит особняком,
потому что здесь вообще другая модель вычислений. Не совсем другая, но существенно отличная.
Это называют неравномерные вычисления.
Что это означает? Что за неравномерность, что за неравномерность?
Вообще мы все знаем, так как часть определения алгоритма, что алгоритм применяется одинаково к любым входам,
в том числе ко входам любой длины. А вот здесь, если совсем грубо говорить, то может быть свой алгоритм для каждой длины.
И зависимость от длины может быть какая угодно, даже неучислимая.
Интуиция такая, что свой алгоритм для входов каждой длины.
Но и соответственно зависимость алгоритма от длины может быть даже неучислимой.
Зависимость алгоритма от длины может быть неучислимой,
но сам алгоритм должен быть в некотором смысле простым.
Если у вас фиксирована длина, то у вас конечное число вообще входов, и в принципе можно хоть таблицей задать, что для такого-то входа такой-то ответ.
Но эта таблица называется таблица истинности, и у нее будет длина экспоненциальная от длины.
Соответственно мы хотим, чтобы для каждой длины был какой-то короткий алгоритм, который существенно короче, чем полный список ответов.
Тогда это все-таки не все функции будут вычислимы в этом смысле, а только какие-то в некотором смысле простые.
Зависимость алгоритма от длины может быть неучислимой, но в каждой конкретной длине алгоритм простой.
В каждой конкретной длине алгоритм в каком-то смысле простой.
Теперь может быть три разных подхода, которые все эквивалентны к тому, как мы понимаем, что в каждой длине свой алгоритм.
Три эквивалентных подхода.
Это схемы из функциональных элементов.
Это прямолинейные программы.
И это машины тьюринга с подсказками.
Схемы это некоторое такое обобщение формул, где можно под формулу переиспользовать.
Схемы это обобщение формул с возможностью переиспользования под формул.
Как это достигается?
Это достигается тем, что вместо дерева строится граф без циклов.
Формула может представлять как дерево, что в узлах связки из двух или одной или нескольких подформул получается некоторая составная формула.
В случае со схемами вместо дерева получается граф без циклов.
Ориентированный граф без циклов, где одна и та же формула как узел графа может быть использована потом в разных новых узлах.
Это получается, что дан ориентированный граф без циклов.
Например, можно договориться, что будет n источников, то есть n вершин со входящей степенью 1 и 1 сток.
1 сток, наоборот, не единица, а ноль.
Источник в входящей степени ноль, сток в исходящей степени ноль.
Ориентированный граф без циклов, n источников, где входящая степень равна нулю.
1 сток, где исходящая степень равна нулю.
На всех вершинах, которые не источники, стоит метка с какой-то бульвой функций.
Если вершина не источник, стоит метка, например, конъюнция, дезюнция или отрицание.
Если отрицание, то обязательно входящая степень 1.
Если конъюнция, дезюнция, то можно договориться, что входящей степень обязательно 2, либо какая угодно положительная.
Если метка отрицания, то тогда входящая степень равна 1.
Если метка конъюнция или дезюнция, тогда входящая степень 2, ну или вариант, что любая больше нуля.
Даже равную нулю можно разрешить, но если равна нулю, то это будет отдельно как источник.
Если на источнике написать какие-то бульво значения, то дальше можно, так сказать,
отсортировав вершину этого графа, вычислять значение бульвых функций.
Если на источниках заданы бульво значения, то можно топологически отсортировав.
Вершины. Можно последовательно вычислить значения в них во всех, ну и в том числе вот в этой самом стоке.
Можно последовательно вычислить значения во всех вершинах.
Согласно меткам. Примени функции согласно меткам.
Ну и значение в стоке это как бы ответ.
Значит ответ это значение в стоке.
Так, ну примерно понятно, да? Вот, тогда в такой схемы есть два параметра количественных.
Значит две количественные характеристики.
Размер и глубина.
Значит размер это просто число вершин.
А глубина это максимальная длина пути от источника к стоку.
Максимальная длина пути от источника к стоку.
Ну и вот нас интересует, для каких задач какого размера и какой глубины могут быть семейства схем.
Говорят, что множество или язык А распознается семейством схемы.
А распознается семейством схем.
Значит СН.
Так, наверное нужно от единицы, потому что когда ноль входов, то это выраженный случай.
Надо считать, что один вход все-таки будет.
Ну с другой стороны, когда ноль входов.
В смысле нет, почему нельзя?
А когда ноль входов?
Ну непонятно вообще, что будет.
Действительно, в любом органазе без циклов есть источник, поэтому ноль входов быть не может.
Соответственно либо мы случай вообще запретим, мы исключим из рассмотрения.
Либо можно чуть-чуть поменять модель.
То есть можно разрешить там тоже разные метки. Либо метка, что это вход, либо метка, что это константа.
И тогда, соответственно, число входов это число источников с меткой вход, а все остальные будут нулями или единицами.
В общем, в любом случае это выраженный случай, не важно, что там происходит.
Так вот, значит, язык А распознается семейством схем.
Если верно, следующее. Если для любого х...
Значит, верно, что х лежит в А тогда и только тогда, когда, если мы возьмем соответствующую схему,
соответствующую длине х, и на х запустим, то выдадим единицу.
Так, ну ничего, понятно определение?
Так, хорошо, значит, это первый подход. Это первый подход, когда у нас схема как обобщение формул.
Так, второй подход, это прямолинейные программы.
Значит, прямолинейные программы это программы без каких-либо разветвлений.
То есть там нет циклов, нет условных переходов, а есть только присваивание.
Значит, что такая-то новая переменная равна такой-то функции вот таких-то уже имеющихся переменных.
Соответственно, функция у нас тоже будет из какого-то небольшого набора.
Например, такого же, конъюнца-дезюнца, импликация.
И, соответственно, нужно постепенно вычислять значение все новых и новых переменных.
Ну а в конце будет ответ.
Сейчас каких ограничений?
Нет, это уже будут конкретные классы.
Есть одни классы, где ограничивается размер, другие, где глубина.
А, давайте пока вот что поймем.
То есть простое утверждение, что для любой вообще функции, для любого языка,
для любого языка существует распознающее его семейство схем.
Значит, глубины, видимо, 3, как я написал.
Это в предположении того, что здесь в скобках.
Если у конъюнца-дезюнца может быть любая входящая степень.
Значит, если любая, то глубина будет 3, а размер 2 в степени n.
Значит, это при произвольном числе аргументов конъюнца и дезюнца.
Ну или если если ровно два аргумента, то будет глубина n, видимо, и размер 2 в степени n.
Значит, или глубины n и размера 2 в степени n, если конъюнца и дезюнца с двумя аргументами.
Из чего это следует? Ну просто из KNF или DNF.
Значит, смотрите, если у нас n фиксировано, то получается просто какая-то объяснительность для 2 степени n.
Соответственно, получается бульевая функция. Любую бульевую функцию можно представить в виде KNF.
Ну а дальше, если KNF просто переделать в дерево, то там как раз будет глубина 3.
Сначала отрицание, потом дезюнкция, потом конъюнция.
Ну а размер, в принципе, пополам можно поделить, если или KNF, или DNF рассматривать.
Но неважно. В общем, такое максимальное число скобок.
Ну и для каждой скобки будет, соответственно, одна связка.
И еще одна, чтобы взять конъюнцию всех скобок вместе.
Вот. Соответственно, если...
А, тут, кстати, давайте я о большой напишу, потому что тут вообще n плюс лог n будет.
Значит, если у нас двоичные связки, то нам нужно много взять на конъюнцию большого числа,
то нужно превратить двоичное дерево.
Ну конъюнцию у нас как раз максимум вот такого числа.
И еще логарифм n нужен будет для дезюнкции на внутреннем уровне.
Потому что дезюнкты для n, соответственно, там нужен логарифм n.
Ну и, соответственно, размер тоже получается побольше.
Ну потому что у нас каждая...
Ну тут тоже сейчас будет какая-то константа. Давайте я о большой напишу.
Какая-то константа, потому что у нас каждая скобка длины n.
Но там, соответственно, n будет... там n минус 1 будет знак дезюнкции.
Ну и с каждому знаку будет соответствовать элемент...
А, нет, тут даже не нужно большое. Да, не нужно.
Просто каждому знаку будет соответствовать вершина вот в этом графе.
А знаков будет как раз столько. Ну, может быть, меньше, конечно.
Вместо большого можно меньше леброном написать.
Чего? Где логарифмы?
Правильно, когда у нас дезюнкты, там будет n элементов, и поэтому будет логарифм n.
Но когда берём конъюнкцию, там будет 2 в степени n элементов, и будет логарифм на 2 в степени n.
Если вы про глубину, то тут будет вот этого большое, это n плюс лог n.
Потому что они не умножаются, они складываются.
Сначала дерево для дезюнкции, потом большое дерево для конъюнкции.
Да, да, да, логарифм на 2 в степени n, то есть как раз m.
Так, значит, дальше есть теоремы, значит, теоремы Шинона.
Так, я что-то не помню, как он обычно пишется по-русски, через e или через е.
Да, в общем, Шинона и Лупанова.
Теорема такая, если мы нижнее рассматриваем,
теорема Шинона говорит о том, что существует a,
для которого нужны схемы размера ω от 2 в степени n делить на n.
То есть хотя бы такого размера.
Здесь было умножение на n, здесь деление на n.
Но это я доказывать не буду, но у Шинона несложная идея.
Идея просто в принципе дирихле, что мы считаем комбинаторно,
считаем общий количество, оцениваем как-то общий количество схем такого размера,
и оказывается, что оно меньше, чем число функций.
То есть всего функций там 2 в степени 2 в степени n,
но если не такого размера, то если аккуратно посчитать, то будет меньше.
Теорема Лупанова обратная, что для любого a достаточно схем размера ω от 2 в степени n делить на n.
То есть если схитриться и скомбинировать, то такого уже достаточно.
То есть тут просто верхние и нижние оценки совпадают друг с другом.
Ну конечно, если смотреть на константу, то константа вот здесь будет немножко больше, чем константа вот здесь.
В ином случае вообще и противоречие было бы, но равенства константа там нет.
Но было бы удивительно, если бы оно было с такой точностью.
Да, вообще не часто бывает, что верхние и нижние оценки совпадают.
Хорошо, но Теорема Лупанова я тем более не буду доказывать.
Там какое-то такое мутурное рассуждение на 15 страниц.
Как-то каким образом искать какие-то общие паттерны в разных штуках, как-то их объединять.
И что всегда обязательно их найдется достаточно много, чтобы получилось вот так вот.
Так, хорошо.
Значит у нас будут вот еще два подхода.
Значит еще два подхода.
Это прямолинейные программы и машинтюрнинг с подсказками.
Так, давайте я попробую так кратенько рассказать.
Прямолинейные программы это просто цепочки присваиваний.
Прямолинейные программы это последовательности присваиваний.
То есть какая-то новая переменная.
Значит, xкт.
Да, это какая-то функция f.
Вот каких-то там x и первая, и так далее, x и nt.
То есть просто такая программа, что есть какие-то исходные переменные.
И в каждой строчка берется новая переменная, она равняется какой-то функции от старых.
Ну есть, конечно.
То есть те функции, которые здесь были, как метки, те же будут и здесь.
Ну, в принципе, как и там, так и тут, можно какой-нибудь другой базис рассмотреть.
То есть можно рассмотреть какой-то базис, но чтобы любой функций, да, их использовать.
Значит, f, соответственно, в стандартном случае одна из отрицаний конъюнкции и дизюнкции.
Но с той же оговоркой про конъюнкцию и дизюнкцию, что может быть либо два аргумента, либо произвольное количество.
Соответственно, для отрицания m равно 1, значит, для конъюнкции либо 2, либо произвольное,
и для дизюнкции тоже либо 2, либо произвольное.
Вот.
Хорошо. Ну, значит, утверждается, что применение на программы это, на самом деле, просто другой способ представления схемы.
Значит, каким образом?
Ну, по схеме я там фактически написал, что нужно ее топологически отсортировать,
так чтобы сначала были все источники, а в самом конце сток.
Дороги не важно, и просто мы как бы для новой вершины завозим переменную
и прям пишем, что эта переменная равняется той функции, метка которой в вершине,
от, соответственно, тех вершин, из которых идут ребра в нашу.
Ну, наверное, понятно. В обратном сторону примерно так же.
Если есть применение на программы, то нужно вместо каждой новой строчки заводить вершину
и, соответственно, на ней ставить ту же метку, которая здесь функции, и вести ребра из вот этих вот вершин.
Вообще, когда рисуют, то обычно и стрелки не пишут на ребрах, а просто считают, что сверху вниз вычисляется,
что все ребра идут сверху вниз.
Так, ну хорошо. Ладно, можно дальше не писать.
Ну и третий подход, машинтюринг с подсказками.
Ну, это просто тут м от х и какого-то аэнного.
Два аргумента, но в отличие от NP, где сертификат свой для каждого х,
а еще его можно отвергнуть или не отвергнуть, значит, здесь аэнное одно и то же для всех слов длины m.
Значит, аэнное одно и то же для слов длины n.
Ну и, соответственно, нужно следующее.
Значит, нужно, чтобы х лежал в а, как мы говорим, что нож в а распознается.
Значит, х лежит в а тогда и только тогда.
Сначала существует последняя стоянная, тоже по n от 1 или от 0, если хотите до бесконечности.
То есть х лежит в а тогда и только тогда, когда м, то есть надо написать так,
значит, существует м, стоянная, что м от х и а с индексом длины х равно единице.
То есть подсказка должна быть одна и та же для всех слов длины.
Так, но вот это, что это то же самое, это немножко хитрее.
Но в одну сторону это несложно.
Если уж у нас есть схемы, то вот эту машину m можно понимать как просто вычислитель схем.
То есть m вычисляет значение схемы на входе х.
А в другую сторону нужно, наоборот, машину тюринга преобразовать в схему.
Так, ну, значит, соответственно, схемы в машине тюринга.
Значит, тут просто получается, что аn равняется той же самой схеме cn.
Да, кстати, схема это circuit.
Если вы будете переводить на английский, то scheme это неправильный перевод.
Правильный перевод circuit.
Это типа как электросхема.
Электросхема тоже circuit.
Поэтому cn не s.
Значит, подсказка это cn, ну а, соответственно, машина вот x и cn это просто cn от x.
Ну и нужно рассмотреть одну единую машину для всех языков,
которая занимается тем, что просто вычисляет значение схемы.
Ну и понятно, что такую машину можно написать.
Ну а топологическую шестировку вы, наверное, умеете делать у графа.
Да, и дальше просто идти и вычислять тоже понятно как.
Вот, хорошо.
Значит, соответственно, машина тюринга, схемы.
Ну, это, на самом деле, аналогично теореме Куклевина.
Значит, вот эта конструкция у нас уже несколько раз была.
Аналогично теореме Куклевина.
Вот, но как бы тут у нас исходно есть x.
Значит, x1, x2, x3 там и так далее, xn.
Вот, дальше еще нужно дописать начальное состояние на там q.
Старт какой-нибудь.
Вот, соответственно, тут еще нужно дописать там какие-то.
Тут, в отличие от теорем Куклевина, не будет никакого второго аргумента.
Будет только один аргумент.
А, нет, подождите, будет же второй аргумент, что я напишу.
Будет.
Так, а n это как бы номер.
Будет второй аргумент.
Давайте я сверху что линдекс напишу, а первое, а второе, и так далее.
И потом еще какие-то пустые клетки.
А нам известно заранее.
Смотрите, у нас есть машина, есть x.
Нет, x нет, x это аргумент.
Вот это будут входные символы.
Остальное это либо константы, либо это константы, если разрешаем константы.
Если мы не разрешаем константы, то их нужно вычислить.
По закону исключенного третьего 1 и 0 получить.
Ну и дальше соответственно мы...
Помните, что у нас из четырех таких штук это вычисляется так же.
И потом каждый из них...
То, что у нас было, что в каждой клетке значение определяется четырьмя более высокими.
Такую штуку нужно сверху вниз написать.
И дальше еще в конце небольшой модуль, что нужно сравнить,
сравнить то, что получилось с принимающим состоянием.
А если где-то в конце получилось принимать состояние, то вывести единицу.
А глубина у нас получается такая, какая максимальная время вычисления?
Да, глубина получается как время вычисления.
Ладно, дайте перерыв. Делаем небольшой...
Таким образом схемы приделываются в машину и обратно.
Какие же классы отсюда получаются?
Можно формулировать классы в терминах размера семейства схем или глубины.
Можно формулировать в терминах машин тюринга.
Например, есть вот такое стандартное обозначение.
Это означает, что существует машина тюринга, распознающая язык,
который как раз в этом классе, конечно.
С подсказкой длины U' от A от N за время U' от T от N.
Ну и самый главный язык обозначается вот так.
Вот P слэш поля. Чтут соответственно и T от N, и A от N должны быть пильномянами.
То есть это объединение под C и D.
Чтутся STD time от N степени C слэш N степени D.
И это будет то же самое, что языки, распознаваемые семейством схем, полимерного размера.
Эти рассуждения позволяют доказать, что это одно и то же.
Так, хорошо.
Кроме того, эта переделка машин тюрингов схемы показывает следующее.
Значит, что P у нас вложено в P слэш поле.
Потому что практически P то же самое, только без подсказки.
Более того, она строго вложена.
Более того, P не равно P слэш поля.
Почему?
Потому что в P как раз зависимость подсказки от N должна быть вычислимой.
А в P слэш поле может быть какой угодно и даже не вычислимой.
Простейший пример следующий.
Можно использовать какую-нибудь неразрешимую задачу.
Например, проблему остановки.
U halt это будет множество из N единиц подряд.
Давайте так напишем.
M кодирует пару mx такую, что m от x останавливается.
Смотрите, получается, что если эта пара mx лежит в halt,
то тогда один в степени N, то есть один повторенный N раз, лежит в U halt.
Ну а если там 0, то это точно не лежит.
Соответственно, функция будет конъюнкцией.
U halt ограничена на N, распознается конъюнкцией.
А конъюнкция всех ходов, как раз если все единицы, то будет единица.
Если хотя бы один ноль, то будет ноль.
Соответственно, если m от x не лежит в halt,
и эта штука не лежит в U halt, а с нулями тоже не лежат,
ну и тогда U halt, ограничена на N, распознается тождественным нулем.
Таким образом получается, что и в том, и в другом случае, схема будет маленькая.
Да, и у конъюнкции всех ходов маленький размер, у тождества 0 тем более маленький размер.
Но мы только не знаем, какая именно маленькая схема нам нужна.
Ну как-нибудь закодируем.
Но слушайте, мы это изучали много раз.
Как-нибудь так, чтобы было однозначно.
Да, то есть так, чтобы по N можно было понять, является ли оно кодом хоть чего-нибудь,
а если является, то какая там машина и какой там x.
На самом деле, тут вообще совершенно не важно, какой язык.
Если он унарный, то он точно лежит в P slash поле.
То есть можно даже не брать конкретно проблему остановки и не брать никакую другую конкретную неразрешимую задачу,
а просто из соображений мощности сказать, что у нас P вложено в разрешимое,
поэтому P это счетное множество, а P slash поле будет не счетное,
потому что уже унарных языков будет не счетное число.
Для каждого N слово из N единиц может лежать или не лежать.
В этом смысле для этого примера даже не важно, как вы кодируете.
Важно только, чтобы только для одной пары N было кодом, иначе будет просто непонятно, как определить.
Что дальше?
Это очень важно утверждение, что заведомо P slash поле шире, чем P, и более того, содержит даже неразрешимые языки.
Дальше давайте, наверное, изучим вот такую вот теорему Карпа Липтона.
Значит, возникает вопрос. Ну хорошо, а где здесь NP?
Может и так быть, что NP вложено в P slash поле? Ну а вообще, в принципе, может быть.
Ну и соответственно, зато если оно не вложено, то точно P не равно NP.
То есть вот в 80-х думали, что можно попытаться доказать, что P не равно NP,
взяв какую-нибудь NP-полную задачу, типа задача выполнимости, и доказав, что эта задача не решается семейством маленького размера.
Если мы это докажем, то получится, что все P вложено в P slash поле, а в NP мы нашли какую-то точку, которая не в P slash поле.
Вот так. Понятно, да? Но вот Карп и Липтон показали, что на это не стоит уж прям так надеяться.
Значит, они показали следующее, что если NP вложено в P slash поле, то тогда sigma2 polynomial равняется P2 polynomial.
То есть, что тогда polynomial hierarchy слопывается.
Так, ну давайте докажем прямо.
Так, доказательства.
Значит, мы рассмотрим задачу P2-сад.
То есть мы докажем, что P2-сад лежит в sigma2 polynomial.
Ну, получается, что P2 полное значение лежит в sigma2, значит они равны.
Так, напомним, что такое P2-сад.
P2-сад, потому что таки формул phi, что для любого х существует y такой, что phi от x и y.
Значит, х это группа переменных, y это группа переменных.
Соответственно, для любой фиксации значений первой группы можно выбрать значение второй группы, чтобы это равнялось единице, чтобы форма была верна.
Так, ну теперь смотрите, теперь мы х как бы перенесем в левую часть.
Теперь множество пар phi и x таких, что существует y, phi от x и y.
Значит, вот это вот множество, значит оно уже лежит просто в SAT.
Если оно не лежит в SAT, извините, оно лежит в NP.
Ну, это скорее под множество SAT в некотором смысле.
В общем, оно лежит в NP.
Так, что из этого следует? Из этого следует, что оно лежит в P-слэш-поле.
Значит, есть схема, которая проверяет, существует такое y или нет.
Так, дальше я, наверное, шаг в доказательстве оставлю в качестве упражнения.
Дальше нужно показать, что не только можно проверять, существует y или нет, то можно и искать.
Вот у нас было несколько примеров на как сводить поиск к распознаванию.
Ну а вот здесь он тоже применим.
Ну, если вкратце, идея такая, что мы как бы отдельный бит y переносим отсюда сюда.
И говорим, что вот у нас есть phi, у нас есть x, и еще мы фиксируем y1 равное 0, например.
И тогда вопрос, можно ли все остальные y зафиксировать так, чтобы форма была верна.
Это задача такого же типа, соответственно, для нее есть схема.
Соответственно, если да, то мы рекурсивно найдем оставшиеся y.
Если нет, то мы скажем, что тогда y1 равно 1, и мы тоже найдем оставшиеся y.
Так, ну, примерно понятно, да? Или как?
Ну, это так для выполнимости делалось, а здесь почти то же самое.
Да, то есть еще раз, пусть мы умеем проверять выполнимость, когда искать выполняющий набор.
Нужно фиксировать очередную переменную 0 или единицей и смотреть, что можно еще дополнить до выполняющего набора.
То, что можно фиксировать, если нельзя, то фиксировать противоположное.
Ну, и так постепенно ходить, так здесь тоже найдется.
Отсюда следует, что существует схема, ну, точнее, семейство схем.
Значит, cn, которые прям таки ищут y.
Смотрите, в принципе, можно обобщить схемы с бинарного ответа на любой другой,
просто увеличив число выходных вершин.
У нас будет не одна выходная вершина, а десять, тогда у нас ответ будет не один бит, а десять битов.
И в том числе битов может быть выходной столько, сколько у нас битов в y.
Значит, существует схема cn.
Значит, такое, что cn от φх равняется y.
Соответственно, что φ от xy равняется единице.
Причем, заметьте, что вообще это семейство, оно либо будет выдавать такое y,
либо будет выдавать, что такого y нет.
Но в данном случае у нас есть условие, что для любого существует y.
То есть оно всегда будет именно y выдавать, потому что оно всегда существует.
Значит, тут получается всегда y, а не ошибку.
Значит, так как для любого x существует y.
Это правда, но я утверждаю, что это будет равносильно тому, что φ лежит в нашем языке.
Значит, смотрите, я утверждаю следующее, что теперь φ лежит в π20 тогда и только тогда,
когда существует c.
Ну ладно, я напишу cn, но на самом деле n это будет просто суммарной длины записи φх.
Ну я про это упоминал.
Нет, не семейство-семейство, а просто схема не с одной выходной вершины, а не с несколькими выходными вершинами.
Просто в семействе-семействе там будет повторное использование одного и того же.
А здесь будет просто одна схема, но у нее не один выход, а много выходов.
Значит, существует cn такое, что для любого x φ от x и cn от x равно 1.
Или можно просто ничего не писать, да, истинно.
Слева направо я уже доказал, а справа налево...
Ну смотрите, если уж такой ценный существует, если существуют такие схемы, которые выдают решение для любого x,
то значит решение всегда существует.
И поэтому φ лежит в π20.
Ну а вот это как раз получилась σ2 формула.
И главное, что схемы полиномиального размера, поэтому квантор полиномиален по cn,
и вычисления ценные тоже полиномиален, потому что ценные полиномиального размера.
Ну вот, значит, все получилось.
Да, π2 вложено в σ2, но дальше, если перейти к дополнению, то получается, что σ2 вложено в π2, иначе они не совпадают.
А вот здесь у нас cn, нам не надо все cn перебирать в этом существовании, нам нужно только...
Ну да, все n не надо перебирать, нужно то n, которое равно там длине fi плюс длина x.
А вот здесь у нас cn перебирает.
А вот здесь у нас cn перебирает.
А вот здесь у нас cn перебирает.
А вот здесь у нас cn перебирает.
А вот здесь у нас cn перебирает.
А вот здесь у нас cn перебирает.
Так.
Так.
Ну, там еще теремма Меера, я, наверное, не буду ее доказывать, но сформулирую.
Значит, тут у нее будет более сильное условие и более сильное заключение.
Я доказывать не буду, но я немножко обслужу ее значение.
Значит, смотрите, теремма такая, что если exp вложено в p-slash-поле, то тогда exp равняется σ2.
Значит, у нее более сильное условие, что не только nph, а же на все exp попало в p-slash-поле.
Значит, удивительно, что мы не умеем это провергать.
То есть не умеем доказывать, что экспоненциальные равномерные вычисления не моделируют с пальными альмами неравномерными.
Вот это никто не умеет делать.
Но, конечно, и утверждение тоже более сильное.
Не только если σ равна p2, то пальмяльная аерархия слопается, а это еще больше, аж экспоненция совпадает с σ2.
И это тоже не умеет это провергать.
Но что тут можно заметить?
Что из этого будет следовать, что p не равно np.
Почему?
Потому что, смотрите, если p равно np, то p равно ph, и σ2 в частности.
А если еще exp равно σ2, то p равно exp.
Но про p и exp у нас есть теория об аерархии, которая говорит, что p не равно exp.
Вы ее на семерах обсуждали?
Нет?
Ну ладно, тогда без доказательств идет.
Теория об аерархии, что если больше времени, то значит шире класс.
То есть p не равно exp.
Поэтому будет противоречие, если п равно np.
И это пример того, что Скотт Арнсон называет иеронической теорией сложности.
Как из верхней оценки происходит нижняя оценка.
То, что exp вложено в p-slash-поле, это верхняя оценка.
То есть на все языки exp оценка пальномиальная на размер схемы, которые эти языки распознают.
Это верхняя оценка.
А то, что панировано np, это нижняя оценка.
То есть для задачи выполнимости нет пальномиального алгоритма.
То есть любой детерминированный алгоритм для выполнимости сверхпальномиален.
Это нижняя оценка.
И вообще нижняя оценка – это самое сложное, что есть в этой теории.
Ну и тут что получается?
Получается, что мы из верхней оценки получили нижнюю.
Но не стоит надеяться так доказать, что p не равно np, потому что вряд ли это верно.
Можете еще раз рассказать о рассуждении?
Еще раз о рассуждении.
Если вдруг p равно np, то тогда p равно ph.
Мы это обсуждали в пальномиальной арахе.
В частности, p равно σ2.
Тогда p равно exp, но это противоречит теоремы «я просто аерархия».
Ну об аерархии по времени это называется.
Ну ладно, и в последние 15 минут я бы хотел немножко сказать про еще одну аерархию,
которая связана с глубиной.
Значит, это называется nc или nc.
И аерархия – это удивительным образом в честь конкретного человека.
Названо, значит, nc – это nix-класс.
Значит, в честь ник – это Николас Пипинджер.
Там история такая.
Пипинджер приехал на стажировку к Стивену Куку, который как раз из Теремку-Клевина.
И Стив ему поручил это изучить и назвал Никс-класс.
А потом через некоторое время Пипинджер в ответ некоторый класс назвал Стивс-класс,
в честь Стивена Кука.
Стивс-класс – это, по-моему, одновременно по линомиальным времени поле логарифмической памяти.
То есть это шире, шире, чем l, но зато уже и чем p, и чем поле l.
Так, хорошо. Значит, что такое nc?
Здесь, на самом деле, две аерархии, которые друг с другом переплетены.
Значит, есть понятие nc dt.
Значит, это означает поле линомиальный размер.
Поле линомиальный размер и, значит, глубина
большого логарифма в степени d от n.
Смотрите, как мы изучили уже в начале.
Если у нас размер какой угодно, то глубина может быть константой.
Хотя только сейчас. Тут еще важно, значит, глубина большая.
Но при этом у каждой вершины с метками конъюнция и дезъюнция
вершины с конъюнцией и дезъюнцией имеют входящую степень равную двум.
А еще есть ac dt. Тут уже a, правда, не в честь кого-нибудь.
Хотя были гипотезы, народная этимология, что a это в честь
Аллана Бородина, который с ними там же работал.
Но это неправда. Буква просто значит альтернирование.
А c dt это аналогично, но конъюнция и дезъюнция имеют произвольную входящую степень.
Ну и уж по крайней мере для ac у нас точно есть, что если мы не ограничиваем размер, то глубина у нас константа.
Для nc такого не будет. Поэтому важно, что размер тоже полиномиальный.
Еще есть вариации с равномерностью. Неравномерная версия это просто как написано.
А еще может быть, например, полиномиально равномерная версия.
И это означает, что схема cn вычислима за время полинома t.
А может быть даже логарифмически равномерная версия, когда на логарифмической памяти вычислила.
Поскольку тут размер полиномиальный, то это точно все внутри p-slash поле происходит.
Пока я стираю, давайте обсудим, почему альтернирование. Дело в следующем.
Во-первых, отрицание можно все по закону деморгана перенести на самый верх.
Можно сказать, что у нас с самого начала есть переменная, у каждой переменной есть отрицание, а дальше у нас только конъюнция и дезъюнция.
Это, во-первых, отрицание все на самом верху.
А после этого, если у нас подряд две одинаковых метки, например, в одном из... да, конъюнция, из нее метка тоже конъюнция.
Тогда их можно просто склеить, потому что у нас неважно, сколько выходит.
Точнее, наоборот, если у нас, я не говорю, что если у нас вот так вот, конъюнция, скажем, вот так вот, а здесь тоже конъюнция.
Тогда это можно в одну склеить и вот эти перенести сюда.
Поэтому все идущие подряд можно склеить, а тогда они как раз будут альтернироваться.
Конъюнция, дезюнция, конъюнция, дезюнция. Вот поэтому АС.
Вот, соответственно, почему это иерархия?
Ну, ясно. Да, D может быть равно нулю.
D может быть равно нулю, тогда будет глубина константа.
Значит, Nc0 вложено в Ac0, это вложено в Nc1, вложено в Ac1 и так далее.
Ну и вообще, в целом, NcDt вложено в Acdt, вложено в Ncd1.
Вот такая будет иерархия.
Так, значит, почему это так?
Ну, значит, NcDt вложено в Acdt, это просто потому что 2 – это частный случай произвольного числа.
Валентность 2 – это частный случай.
Так, значит, Acdt вложено в Ncd1.
Ну тоже понятно. Вот тут мы и распользуемся полиномиальностью размера.
Что тут, конечно, произвольная входящая степень, но тем не менее полиномиальная.
Тут, соответственно, входящая степень полиномиальная,
и она преобразуется в двоичное дерево глубины логарифа полинома, то есть обольшое от логарифма N.
Значит, дерево глубины обольшое от логарифма N.
Вот.
Так, надо найти то, что понятно.
Возникает вопрос, насколько эти строгие, насколько эти вложения строгие.
Ну вот то, что Nc0 не равно Ac0, это вообще почти очевидно.
Потому что такое Nc0? Это означает, что глубина константная и при этом еще валентность 2.
Но это означает, что если у вас глубина c, то каждый раз у вас удваивается число аргументов,
значит, он точно не превысит 2 в степени c.
То есть вот из Nc0 все языки, они зависят только от фиксированного числа булевых аргументов.
Тут зависимость от фиксированного числа булевых аргументов.
Ну а, конечно, если мы возьмем, например, конъюнцию на конъюнцию всех,
то конъюнция все-таки от всех аргументов зависит, а не от фиксированного числа.
И это может быть фиксировано большое, то есть у нас может быть там глубина 100, тогда это будет 2 в сотый.
Но у нас же асимпатическая теория, поэтому есть числы больше, чем 2 в сотый.
Соответственно, у вас конъюнция там 2 в 101, уже будет от всех 2 в 101 аргументов зависеть,
и она в Nc0 будет, потому что там и 2 в 101 тоже может быть аргументов, а в Nc0 не будет.
Получается, не содержит просто конъюнцию.
Ну а ac0 содержит по определению.
Ac0 содержит, конечно, конъюнцию.
Дальше, что еще известно?
Еще известно, что ac0 не равняется Nc1.
Но вот это уже значительно более сложная теорема.
Так, там какая-то куча авторов.
First, Sax, еще кто-то.
Aitai, Semeredi, что ли.
Или кто-то еще.
Так, неважно.
Мы ее не будем доказывать, она действительно не простая,
но можно даже за 3 минуты, оставшись, понять, что функция XOR с N аргументами,
она лежит в Nc1.
Значит, почему?
Потому что, смотрите, что такое XOR2.
У нас есть Y, дальше вы берете отрицание.
Ну и дальше, например, берете вот так конъюнцию, берете вот так конъюнцию
и берете вот так дизюнцию.
Значит, XOR2 это глубина 3 получилась.
Ну а XORN это как раз дерево из XOR2,
значит, глубины как раз логарифм M.
Значит, XOR тоже ассоциативная операция, так что ее можно вычислять двоечным деревом.
Поэтому XORN в Nc1 лежит.
Ну а то, что XORN не лежит в AC0,
это не простая теорема, но идея следующая.
Идея состоит в том, что XOR это очень чувствительная функция.
Значит, XORN очень чувствительная функция.
Просто изменить любого аргумента меняет значение функции.
Да, ну XOR так устроен.
Изменение любого аргумента меняет значение функции.
А в AC0 таких чувствительных быть не может.
Это вот как раз надо показывать.
В AC0 таких чувствительных нет.
Но тут как бы идея такая, что как раз конъюнкция и дизъюнкция, они, наоборот, очень нечувствительные.
То есть это только где-то на краю меняется значение.
Так типично, если вы случайно аргументы взяли, то у конъюнкции будет результат 0, а у дизъюнкции 1.
И даже если вы один поменяете, то все равно будет у конъюнкции результат 0 и у дизъюнкции 1.
Только на самом краю, когда у вас все, кроме одного, одинаковые,
вот тогда замена этого одного поменяет значение.
Соответственно, у конъюнкции и дизъюнкции чувствительность очень низкая.
Ну и дальше нужно доказать, что константной глубины не хватит, чтобы это чувствительно сильно нарастить
до такой, которая нужна для ксора.
Вот такая общая идея, но дальше всякие сложные алгебры и так далее.
На самом деле дальше ничего не известно.
Начиная с НЦ1, неизвестно тут, строго или нестрого,
и даже неизвестно, лежит ли вообще все УНП в НЦ1.
Это не умеет опровергать.
Тут даже между АЦ0 и НЦ1 есть еще некоторые промежуточные классы.
Была очень большая, очень успешная теорема,
что НЭКСП не вложено в АЦЦ0.
АЦЦ0 – это такой класс, где вы добавили вот такой ксор,
и еще, кажется, сравнение по любому простому модулю.
То есть у вас есть такие еще элементы, у которых сколько угодно аргументов,
и они вам говорят, число единиц среди аргументов делится на по или не делится.
АЦЦ0 – это тоже 0, значит, константная глубина, а элементы – это конъюнкция, дизъюнкция и вот такие вот сравнители.
То есть ксор – это сравнитель по модулю 2, а сравнитель по любому другому модулю там тоже есть.
И была не такая давняя теорема, это 2011 год.
Теорем Уильямса доказал.
И там буквально вообще все техники, которые известны ученым, они были тут использованы.
Но тут нам-то мы хотим, что NP не равняется P, а еще лучше, чтобы NP не вложено в P слэш поле.
И тогда NP гораздо меньше, чем NX, а P слэш поле гораздо больше, чем вот эта штука, чем АЦЦ0.
То есть это то, что мы хотим, невообразимо дальше от того, что мы умеем.
Но, возможно, при нашей жизни это изменится.
Все, на этом лекция заканчивается.
Я обсужу с семинаристами. Мы не успели пройти только всякие маленькие схемы для конкретных функций,
например, для двоечного сложения. Двоечное сложение оно где-то вот тут.
Ну или даже вот тут, если постараться.
Но вот здесь точно.
И умножение там же.
Посмотрим, либо я это на первой половине в следующий раз расскажу, либо мы сразу про вероятность начнем.
Все, спасибо за внимание.
