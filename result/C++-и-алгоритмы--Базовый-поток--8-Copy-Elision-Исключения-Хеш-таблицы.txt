Так, давайте тогда начнем. Закончим то, на чем мы остановились в прошлый раз. Мы хотели поговорить
про Copy and Leash. Напомню, что Copy and Leash — это некоторая оптимизация компилятора, которая делает
вызов move-конструктора, так скажем, несколько затруднительным. А именно Copy and Leash полностью
убирает ненужные копирования и перемещения в случае, если он может или считает это целесообразным
сделать. Ну вот, например, давайте еще раз вернемся. Вот пример один, первый блок. Значит, здесь,
понятное дело, что у компилятора нет никакого выбора. Он обязан сделать перемещающий, он обязан
здесь вызвать перемещающий конструктор в строке 47. Почему? Потому что вы создали объект A, и дальше
говорите, что из объекта A вам нужно что-то переместить в B. То есть вы, грубо говоря, утверждаете,
что вам нужно одновременно и объект A, и объект B. Ну просто содержимое объекта A вы перенесли в
объект B. Ну и действительно, если посмотрим на вывод 1, то действительно мы увидим, что вызван
default-конструктор, и дальше вызван move-конструктор. Все немного интереснее, если, допустим, посмотрим на
блок номер 3. Здесь мы вроде как ожидаем то же самое. То есть я напомню, что функция F просто-напросто
берет и возвращает A. То есть просто создает в return statement объект типа A и возвращает его.
Вот. И здесь мы чего ожидаем? Мы ожидаем, что внутри функции F нам создастся некоторый объект,
точнее, функция F создаст некоторый временный объект, и который дальше будет перемещен в объект
A. То есть, собственно, то, чего мы ожидаем. Но на самом деле здесь происходит иначе. Здесь вызывается
всего лишь один default-конструктор. То есть объект, который создается функцией F, он создается
непосредственно в том месте, где он в итоге пригодится. То есть компилятор убирает все вот эти
ненужные объекты и создает его там, где мы, собственно, попросили. Ну и то же самое происходит с функцией
G. В функции G мы создаем локальную переменную A и потом ее возвращаем. Вот. Он возвращается в виде
временного значения, и дальше это временное значение должно, по сути, как мы ожидаем, переместиться в
объект A в строке 65. Но тем не менее это не происходит. Происходит всего лишь одно default-конструирование.
И вот удивительным образом оказывается, что этот default-конструирование — это то конструирование,
которое происходит внутри функции G. То есть локальный объект внутри функции G, он, по сути,
является тем же самым, что и объект в строке 65. То есть локальный объект внутри функции G
создает именно тот объект, который нужно. Вот. Соответственно, если тут поэкспериментировать,
например, давайте что мы тут можем сделать. Давайте выведем на экран адрес переменной A.
И внутри функции G. Тоже возьмем локальную переменную и выведем ее адрес.
И в итоге пример номер 4. Посмотрим, например, номер 4. Вот. И что мы здесь увидим? Смотрите,
мы здесь вызываем функцию G. Вот. Посмотрим на default-конструктор. То есть сначала у нас
внутри функции G вызывается default-конструктор. Это первая строка. Дальше вводится адрес локальной
переменной, а потом мы вводим адрес переменной, который находится внутри функции main. И оказывается,
что локальная переменная внутри функции G и локальная переменная внутри функции main
обладают одним и тем же адресом. То есть, грубо говоря, это один и тот же объект. То есть, казалось бы,
мы привыкли к тому, что у нас есть как бы стэк вызовов. То есть есть стэк функции main. Дальше идет
стэк функции G, в котором создаются локальные переменные. И после того, как мы выходим из
функции G, у нас стэк слопывается, и все локальные переменные функции G уничтожаются. В случае копии
legion, такого не происходит. То есть мы работаем с одним и тем же объектом. Ну и, собственно,
копии legion — это такая штука, которая на самом деле работает даже тогда, когда вы явно запретили как-то
копировать или перемещать ваш объект. Вот представьте себе, что у вас есть структура A, в которой
вы явно совсем запретили копировать ваши элементы. И кроме того, что запретили копировать ваши элементы,
вы еще запретили их перемещать. То есть вы в принципе запретили компилятор, запретили вашу программу и
как-то копировать элементы или как-то создавать одни элементы на основе других. Тем не менее,
копии legion работает в этом случае. Почему? Потому что копии legion в принципе не вызывает ни конструкторов
копирования, ни конструкторов перемещения, он просто делает то, что как бы семантически
ожидается. Ну вот, в частности, в строке 21 мы вроде как ожидаем, что мы создаем локальный объект,
а дальше этот локальный объект перемещаем в аргумент функции G. Тем не менее, такого не
происходит, даже несмотря на то, что вы запретили 아무 перемещений и копирований,
просто объект A сразу создается внутри аргумента функции G. И то же самое если мы вызываем G от F.
То есть, F казалось бы, казалось бы функция Ф создает временный объект, и дальше этот временный объект
должен как-то попасть в аргумент функции G. То есть с помощью копирования или перемещения,
тем не менее и этого не происходит. То есть копии legion делает так, что у вас объект,
который создается функцией Ф, он сразу же сразу же создается в нужном месте, то есть внутри тартинаCHS.
Так, да, ну в общем, CopyEleasion — это оптимизация, которая позволяет избежать лишних копирований или перемещений объектов,
когда вы работаете со временными объектами.
Ну и, соответственно, да, то есть если компилятор выполняет такую оптимизацию, CopyEleasion, то все побочные эффекты,
даже если таковые присутствуют на реконструкторе копирования или конструкторе перемещения, он игнорирует.
То есть более того, мы видим, я показывал пример, что если даже вы удаляете конструктора копирования и конструктора перемещения,
и более того, делаете их приватными, то есть вот полностью запрещаете, они и приватные, и удаленные, и тому подобное,
все равно остается возможность так называемой копии инициализации из временных объектов.
Да, ну и даже если вы как-то закладывались на то, что у вас конструктор копирования и конструктор перемещения имеет какие-то побочные эффекты,
или вы по какой-то причине написали конструктор копирования или конструктор перемещения, который на самом деле не перемещает,
а просто выводит там hello world, то этого ничего не будет, потому что копия иллюзион.
Существует три основных контекста применения, три основных контекста, когда выполняется копия иллюзион,
ну когда компилятор все это оптимизирует, значит первый момент, это когда вы инициализируете объект с помощью pair value,
то есть с помощью чистого временного значения, ну в частности, когда вы пишете a равно a с круглыми скобками,
то есть тут не происходит создание временного объекта, а потом его перемещение.
Нет, здесь объект создается сразу же в нужном месте, то есть по сути a создается с помощью дефолтного конструктора.
Ну и то же самое, далее a, b, дальше a в круглых скобках, то есть тут тоже.
То есть казалось бы, это синтактиз вызова конструктора копирования или конструктора перемещения, на самом деле нет.
То есть компилятор понимает, что вы создаете временный объект, а потом с помощью него создаете объект b.
Ну и понятное дело, что компилятор понимает, что зачем вам выполнить лишние действия, он сразу как бы создаст объект b с помощью конструктора по умолчанию.
То есть в первом примере и то и то, это просто вызов конструктора по умолчанию.
Ровно то, что мы обсуждали на лекциях по конструкторам.
Дальше, второй контекст, это return value optimization.
Значит, это про то, что если вы внутри return statement, то есть вы после return пишете pair value,
ну вот как здесь вот, то есть вы сразу внутри return создаете объект,
то этот объект на самом деле не создается на стеке функции f и потом возвращается в нужное место,
потом куда-то перемещается, нет.
То есть этот объект, он может быть сразу создан в том месте, где вы попросили.
То есть, грубо говоря, если вы инициализируете, аа равно f, то вот этот вот объект,
он будет создан сразу же непосредственно вот в месте памяти, который зарядили под a.
То есть по сути будет вызван тоже один конструктор.
Ну и named return value optimization, это тоже про оптимизацию возвращаемого значения,
но как говорится в названии named, то есть по имени.
То есть здесь вы создаете какой-то локальный объект f,
вы можете с ним как-то работать внутри функции, внутри функции f,
То есть можете как-то его заполнять, можете как-то его изменять и так далее,
но если в итоге вся цепочка действия привела к тому,
что вы этот объект просто-напросто возвращаете из функции,
то на самом деле оказывается, ну я показывал тоже пример,
то в итоге оказывается что вот этот объект, который вы создаете возвращаемым значением функции g
и вот этот объект, который находится, f, в примере.
И тот объект, который вы создаете внутри функции f, это один и тот же объект.
компилятор оптимизирует это так, что вот этот объект сразу же делается
эквивалентным вот этому объекту, то есть создается в том месте в памяти, и дальше
уже все манипуляции выполняются как бы с ним. И возвращение значения на
самом деле не происходит. Понятно? Есть вопросы?
Ну и там немного истории. До C++11, до 11 стандарта, вообще говоря,
в Copy and Leash был просто некоторые оптимизации, которые реализовали
компиляторы, и в стандарте языка такого понятия как Copy and Leash вообще в принципе не было.
То есть компиляторы это все реализовали не на свой страх или просто было понимание,
что это так эффективнее, поэтому, собственно, это было реализовано. При этом понятное дело,
что так как в стандарте этого нет, то вообще говоря, это могло приводить к некоторому
странному коду. То есть вы ожидаете, что, скажем, ваш конструктор копирования что-то
вводит на экран, а он на самом деле ничего не вводит. Поэтому возникало такое противоречие.
Ну и как выключать эту оптимизацию в стандарте C++11 и C++14? Я показывал, да,
то есть опция fno-elite-constructors. В C++11 Copy and Leash был легализован в некотором смысле,
то есть в C++11 просто добавили некоторые утверждения о том, что Copy and Leash возможен.
То есть некоторые компиляторы могут выполнять и такое, то есть они не обязаны это делать,
но вот в принципе такое может происходить. То есть это называется non-mandatory Copy and Leash.
Ну а в C++17 Copy and Leash стал обязательным, то есть в предпоследнем 17 стандарте вот это
вот поведение Copy and Leash в случае первого пункта, вот этого пункта, в случае return value
optimization, они стали обязательными. То есть теперь, собственно, вам гарантируется,
что именно это и будет происходить. Если вы как-то завязываетесь на то поведение,
что при вызове конструктора копирования или конструктор перемещения у вас что-то будет
происходить, то вот в случае 1 и в случае 2 вы не имеете на это права. В общем, компилятор
обязан выполнять вот эти оптимизации. С третьим пунктом все сложнее, вот третий пункт по-прежнему
остается необязательным, то есть в принципе компиляторы не гарантируют, что в случае
named return value optimization, что-то будет происходить. Но как правило, именно это и происходит.
Ну и в общем-то это амблюзибет того, что мы говорили на прошлой лекции. Мы говорили про
cdmove, cdforward и вот говорили про copy elision. В принципе, на этом с темами второго модуля все. Такие есть вопросы.
Ну отлично, тогда перейдем к темам третьего модуля или к темам третьего задания. Ну небольшой
анонс, о чем мы будем говорить. Мы будем говорить про исключение C++, про правила написания безопасного
кода, потом немного поговорим про стандартную библиотеку языка C++, как ей пользоваться, что там
есть, чего там нет и так далее. Ну и в рамках курса алгоритма и структуры данных рассмотрим
хэштаблицы. Вот такой план. Ну давайте двигаться к новой теме. Начнем мы с исключений. Сегодня
начнем так потихоньку втягиваться в то, что такое исключение, что такой безопасный код на языке
C++ и так далее. Значит, сразу же хочется сказать некоторый дисклеймер по поводу того, что мы сейчас
будем обсуждать, скажем так, ошибки при написании программ на C++. И когда я говорю о ошибке, я вообще
говоря говорю не про те ошибки, которые вы получаете в контесте, то есть не про wrong cancer и так далее.
Вот эти ошибки это полностью на вашей совести. Я говорю про те ошибки, которые на самом деле
являются некоторыми исключительными ситуациями. Ну смотрите, когда мы обсуждаем алгоритмы,
ну не знаю, алгоритмы сортировки, ну да, давайте возьмем какой-нибудь алгоритм
сортировки с влиянием. Вот алгоритм сортировки с влиянием, он что делает? Он развивает
элементы по одному, и дальше все эти элементы попарно сливает в некоторый временный буфер,
и потом из этого временного буфера копирует, собственно, исходный массив. И в принципе,
на словах все кажется понятно, то есть как запрогать тоже понятно, несложно и так далее.
И когда вы пишете программу, вы в принципе, до сегодняшнего момента, когда вы писали
программу, вы в принципе, наверное, не задумывались о том, что у вас что-то может пойти не так.
Опять же, я не говорю про ошибки, что мы там где-то набагали и так далее. Вообще говоря,
программы выполняются не в сферическом вакууме и так далее. Программы выполняются в реальных
средах. А в реальных средах может многое пойти не так. Ну, например, банальное, если мы говорим
про merge sort, merge sort может не хватить памяти. То есть вы внутри merge сорта вы выделяете
дополнительную память под хранение временных результатов. Ну а что произойдет, если операционная
система вам скажет, что нет у меня столько памяти, ну что делать? Описывается ли это там в рамках
нашей алгоритмической модели? Ну нет, алгоритм вообще в принципе не говорит о том, что делать,
если у вас в обычном классическом merge сорте не хватает памяти. Это первый момент. Второй момент,
ваши программы очень часто взаимодействуют, опять же, программы работают неизолированно,
они работают в некоторой среде. Они взаимодействуют с другими программами, с другими процессами,
которые они взаимодействуют с кем-то возможным по сети, с пользовательским вводом и так
далее. Ну и понятное дело, что, как бы предполагать, что ваша программа работает хорошо,
а все остальные компоненты с которыми она работает будут работать корректно, ну как-то грубо говоря
наивно. Да, то есть наивно полагать, что скажем пользователь будет водить там обязательно все
корректно, что сервер всегда будет вам отвечать, что соединение по сети всегда доступно, что процессы
там всегда работают тоже исправно и так далее. То есть всякие неожиданные ситуации, которые грубо
не описываются алгоритмически, но которые там чисто технические, технические
проблемы, которые могут возникать, они могут приводить к некоторым
проблемам. И, наверное, хотелось бы такие проблемы тоже решать оперативно,
то есть вряд ли хочется, чтобы на каждый неправильный пользовательский ввод
ваша программа просто-напросто брала и падала. Вряд ли, если вы заходите на
какой-то сайт, вводите свой логин-пароль, и в случае ввода неправильного
пароля у вас падает весь сайт. Такого явно не происходит.
В принципе, сложно каким-то запросам положить сервер. Большим количеством
запросов можно, но одним каким-то нет. И вот как обеспечить такую
бесперебойную работу или как вашему коду сообщать о том, что что-то пошло не так,
об этом мы и будем говорить все это время. Сегодняшнюю и следующую лекцию.
Мотивация понятна? Хорошо. Давайте посмотрим такой игрушечный пример.
Есть функция Divide, которая просто берет два произвольных. Давайте скажем, что
тип T это всегда число для простоты. Функция Divide берет два числа
произвольных и делит одно на другое. Ну и тут сразу возникает вопрос, а что
делать, если у вас в качестве y был передан ноль? В принципе, деление на ноль для
целых чисел приводит к undefinedBehaviour, то есть неопределенное поведение.
Функция Divide не может работать нормально в случае целых чисел и в случае
деления на ноль. Что делать? Как сообщить пользователю об ошибке, то есть как
сообщить тому, кто вызывает вашу функцию Divide, что что-то пошло не так?
Есть несколько вариантов. Первый вариант это не как. То есть просто-напросто
ничего не делать. И в принципе, там большинство из нас до сих пор этим
пользуется. Ну и на самом деле это не то чтобы прям очень плохой очень плохой
вариант обработки ошибок. Ну действительно, смотрите, то есть если вы, если ваш
контракт функции заключается в том, что вы говорите, что если вы делите одно
не нулевое, то есть если делите одно число на другое не нулевое, то у вас все
работает корректно. Если вы делите что-то на нулевой число, то произвести
может все что угодно. Если контракт вашей функции устроен так, то в принципе все
нормально. То есть вы можете эту ошибку не обрабатывать. Более того, все плюс-плюс,
очень большое количество функций и большое количество операций вот таких
проверок не выполняют. Классический пример — это выход за границу массива.
То есть мы все понимаем, что если выходим за границу массива, то ничего хорошего
от этого не получится. Но при этом компилятор не осуществляет никаких
проверок выхода за границу массива. Почему? Ну для эффективности.
Если мы постоянно на каждое обращение к массиву будем проверять
выход за границы, то это лишняя инструкция процессора, то есть лишнее
время работы. Ну а все плюс-плюс в принципе устроен так, что у него
философия такая, что мы не платим за то, что не используем. То есть если мы
корректно пользуемся массивом, то никогда не входим за границы, то есть пишем
логичные программы, то все работает эффективно без дополнительных
проверок. И вообще мы красной нитью так принесем через вот эту вот сегодняшнюю
и следующую лекцию вопрос о том, что на самом деле безопасность и эффективность
они не всегда совместимы, к сожалению. То есть к сожалению, безопасные программы
они редко когда эффективны, а эффективные программы они редко когда безопасны.
Ну вот собственно классический пример. То есть если вы не осудяете проверок, то
есть ничего не делаете в случае, если у вас некорректный пользовательский вод,
то в принципе у вас все эффективно. То есть вы выполняете всего лишь один
ретерн и все. Если вы выполняете дополнительную проверку, то это лишние
инструкции, соответственно происходит некоторая неэффективность. У вас вопрос?
Отличный вопрос. Контракт функций. Ну давайте скажем так, что контракт функций
говорит о следующем. Что эта функция принимает, что эта функция возвращает и
что происходит. То есть грубо говоря, эта функция описывает, что она принимает на
вход и что происходит в случае, если вы там подали ей то или иное. Ну например,
скажем вы решаете контест какую-то задачу. Там понятный контракт. То есть вам
говорят, что будет подано то-то и мы от вас ожидаем этого и так далее.
В принципе контракт функции может включать в себя какое-то описание, что делать,
если там не это. Скажем, если у вас задача стоит в том, чтобы разделить одно число на
другое, и при этом вам говорится, что если вы делите число на ноль, то
нужно там вывести ошибку. А если вам говорится, что вы делите одно число на
другое, и при этом не говорится ничего о том, что должно происходить
пределение на ноль, то в принципе вы можете делать что угодно. Собственно, это и
называется undefinedBehaviour.
Следующий способ как-то сообщить об ошибке, ну помимо того, что ничего не
делать, это вернуть некоторое специальное значение. Но, соответственно, у нас есть
х, у нас есть у, мы делим х на у. И если у нас у вдруг оказался равным нулю, то
этот способ предполагает, что мы вернем некоторое значение, которое будет
говорить о том, что вот что-то пошло не так. Да, то есть мы после вызова функции
divide просто проверяем верно ли, что то, что нам вернуло функции divide, это
некое специальное значение. Если да, то это значит, что у нас произошла ошибка, если
нет, то мы продолжаем работу. Ну и тут есть очевидная проблема, которая
заключается в том, что а как вообще говоря в рамках системы типов языка
C++ определить корректное значение от некорректного значения. Например, я
выполняю divide двух интов. То есть я делю один инт на другой инт. Что мне нужно
вернуть в качестве специального значения? 0, минус 1, 1, бесконечность и так
далее. Ну непонятно, потому что любой из этих значений там 0, 1, минус 1,
бесконечность, это в принципе корректный результат деления. Да, то есть если вам
функция возвращает ноль, вы в принципе не можете определить. То есть вам
действительно вернулся ноль как результат операции, ну как результат
вызова функции divide, или вам вернулся ноль в качестве некоторого
детектора ошибки. То есть не всегда возможно там отделить специальное
значение от результата вызова функции. Следующий пример, который очень
популярен в языке C, это возврат некоторого специального кода ошибки. То есть в языке C
большинство функций они возвращают не результатом выполнения функции или
результатом выполнения операции, а они возвращают собственно код ошибки. А
результат можно записывать, например, в специальную выходную
переменную.
Да, специальную выходную переменную. Что мы делаем? Если y равен нулю, то мы
возвращаем код ошибки единица. Если y не равен нулю, то мы просто выходную
переменную, которую принимаем, например, по адресу, вот по адресу, по этому
адресу записываем результат x деленный на y. И возвращаем ноль как
индикатор того, что ошибки не произошло.
Окей? То есть мы в качестве возвращаемого значения возвращаем, собственно, код
ошибки, а результат записываем в какую-то третью переменную, которую нам
передали. Ну и четвертый способ, который тоже присутствует в языке C, это
использовать некоторую глобальную переменную. То есть понятная проблема с
тем, что мы возвращаем код ошибки. То есть если мы возвращаем код ошибки, то в
принципе оказывается так, что у нас функция возвращает не результат, а
возвращает там нечто иное, нечто другое. Мы этого не хотим. Мы хотим, чтобы
функция возвращала результат, а ошибка была записана где-то в другом месте.
Но это может добиться, например, с помощью специальной глобальной перемены
rno. Вот если у вас функция отработала некорректно, то, соответственно, rno
устанавливается в какой-то код ошибки. Если функция отработала корректно, то
rno устанавливается в ноль. Ну а результат возвращается, как раньше,
в виде возвращаемого значения функции divide. Ну и проблемы этого похода тоже
понятны. У нас есть глобальная переменная. Почему глобальные переменные плохи, думаю,
объяснять лишний раз не нужно. Ну и да, собственно, как я сказал, в языке C принято,
принято стилем до языка C++, когда был язык C, было принято обработка
ошибок в виде некоторого возвращаемого значения. И код выглядел примерно вот
таким образом. Если функция f состоит из вызова функции g и h, то
происходит следующая вещь. Вы вызываете функцию g, смотрите на ее код ошибки. Если
произошла ошибка, то вы что-то делаете. Если нет, то идете дальше. Снова вызываете
функцию h, сохраняете результат ошибки в некоторую переменную. Ну и так далее.
Ну и недостатки этого подхода, они ясны. То есть код очень сильно раздувается, то
есть вы на каждый вызов функции делаете свой обработчик и
после каждого вызова функции делаете свой if, в зависимости от того,
что вам вернулось в качестве ошибки. Второй недостаток тоже понятен.
Чтобы получить результат, вам нужно не сохранить результат вызова функции, а вам
нужно передать некоторую дополнительную переменную, либо по ссылке, либо по
адресу. Ну и возвращаемое значение, на самом деле, легко проигнорировать.
То есть скажем, если функция, то есть в принципе, вас никто не обязывает
возвращаемое значение в функции g как-то проверять. То есть вы можете вызвать
функцию g, проигнорировать ошибку, и программа дальше продолжит работу.
Но при этом понятно, что там будет что-то сломано. Еще один дисклеймер, который
хочу сказать. Цель лекции, на самом деле, не заключается в том, чтобы
покритиковать обработку ошибок стиле c. Вот такой способ обработки ошибок, на
самом деле, популярен во многих языках программирования, в частности, там есть
популярный язык голанг, в котором тоже принято, что используется
идиома с возразом кода ошибок. Вот такая схема тоже норма, и она обладает
большим количеством преимуществ. В частности, мы тут явно видим, что
функции могут возвращать ошибки, мы явно видим их обработку. То есть плюс это
очень сильно дисциплинирует, чтобы вы понимаете, что как бы функции могут
работать некорректно, и поэтому их нужно обрабатывать, и так далее. Я сейчас лишь
хочу раскрыть некоторые недостатки, которые они обладают, и показать
схему, которая используется в языке C++, которая эти недостатки как-то
преодолевает. Ну и теперь, собственно, перейдем к тому, как все устроено в языке
C++, какие механизмы в языке C++ были добавлены, чтобы как-то работать с
невалидным кодом. В языке C++ используется схема с
исключениями. Что такое исключение? Исключение — это некоторый объект, который
генерируется во время, когда у вас происходит некоторая исключительная
ситуация или некоторая ошибка. Ну и, как правило, предполагается, что в этом
объекте у вас сохранена некоторая информация о том, почему эта ошибка
произошла, в каком месте она произошла, и так далее, и так далее. Чтобы сгенерировать
ошибку, нужно писать ключевое слово throw, и дальше после этого вы указываете
объект, который вы назначаете исключением. Но в данном случае у нас функция divide
возвращает исключение типа int. То есть вы говорите, что в случае, если у меня
что-то пошло не так, то я выбрасываю исключение типа int.
Что означает выбросить исключение? Выбрасывание исключения — это
артагональный механизм возврата из функции. То есть если у вас функция что-то
возвращает, то считается, что функция отработала нормально.
Если функция выбрасывает какое-то исключение, то функция завершилась
ненормально. У нас есть два возможных механизма условно возврата из
функции. Классический — это return, и вот с помощью исключения — это throw. Далее
поподробнее. Что происходит, когда вы выбрасываете throw? Когда вы выбрасываете throw,
у вас происходит так называемая размотка стека. То есть если у вас внутри
функции было сгенерировано исключение с помощью throw, то работа этой
функции полностью прекращается. То есть вот на этом месте функция останавливается,
и дальше, понятное дело, уничтожаются все локальные перемены, которые были созданы
до этого. Дальше это исключение попадает в функцию, которая вызывала эту функцию.
Понятное дело, что у вас программа всегда состоит из последовательности вызовов
функции f, g, h, main и так далее. Значит, если в функции h произошло какое-то
исключение, то это исключение попадает в функцию g, потом если g не смогло
обработать эту ошибку, она попадает в функцию f, ну и так далее. Вот так вот
каскадным образом все функции завершают работу. Ну вот пример. Допустим у меня есть
функция main, которая вызывает там функцию курения. Курение вызывает рак, рак бросает
исключение. Когда мы бросили здесь исключение, что у нас произошло? Функция
cancer перестала работать, то есть вот то, что идет после этого cdcout, это не будет
выведено, и дальше управление передается вот сюда, вот в эту строку.
Здесь функция smoking видит, что cancer бросила исключение, поэтому она тоже
прекращает работу. Дальше это все попадает в main, main видит, что и smoking было
выброшено исключение, и main тоже завершает работу. В случае, если исключение
выбрасывается из main, то есть если исключение покидает main, то программа
аварийно завершает работу. Ну вызывает нам функцию специально, cdeterminate.
Все понятно? Хорошо. Да, ну и немного подробнее про то, что происходит, когда вы
делаете throw некоторого объекта. Значит, когда вы делаете throw некоторого объекта,
то вот этот объект исключения, он сохраняется в некотором специальном
области памяти. Понятное дело, что объект исключения не может
храниться на стеке. Ну по понятным причинам, да? Потому что если в объект
исключения хранится на стеке, то когда у вас завершается функция, у вас
стек схлопывается и исключение погибает. Вот поэтому исключение хранится
в специальной области памяти, в которую все обращаются, когда хотят
понять, есть исключение или нет. Ну и понятное дело, что когда вы создаете throw
с помощью, когда вы передаете, скажем, какую-то переменную, например throw a,
то вот эта переменная a просто соберет и копируется в то место, где
хранится исключение. Если вы делаете throw от std-mufata, то понятное дело, что эта
переменная, она будет перемещаться в эту специальную область памяти. Ну то есть
в принципе все работает так, как там обычное копирование или перемещение
объектов, окей? Вот. Теперь, ну хорошо, мы понимаем, как сообщать об ошибке, то есть
мы понимаем, что если у нас там произошло что-то не так, то мы делаем throw, то есть
мы бросаем исключение. Ну возникает вопрос, хорошо, ну вот мы понимаем, что мы
бросаем исключение, и при этом это исключение приводит к тому, что у меня
завершается там первая функция, дальше следующая функция, и в общем-то
каскадным образом все функции завершают работу. А что если я не хочу, что у меня
программа завершала работу? Что если я хочу эту ошибку обработать? То есть я хочу
как-то попытаться решить проблему. И это можно сделать с помощью так называемого
catch-блока, точнее try-catch-блока. Что мы делаем? Ну вот, допустим, у нас есть функция
divide, про которую мы знаем, что она может бросить исключение. Что мы делаем? То есть мы
понимаем, что функция divide может бросить исключение типа int. То есть вызов
функции divide потенциально опасен. Мы делаем следующую вещь. Если мы вызываем
функцию внутри main или любой другой функции, мы оборачиваем эту функцию в try-блок,
то есть пишем try, ну и даже в фигурных скобках мы оборачиваем потенциально
опасный код. То есть говорим, попробуй выполнить вот этот код. И если вызов вот
этого кода, который находится внутри блока try, приводит к тому, что из какой-то
функции выбрасывается исключение, значит мы пытаемся его поймать вот это
исключение внутри блока catch. Значит, блок catch устроен следующим образом. Мы пишем catch, а
дальше в круглых скобках мы пишем, собственно, исключение, которое мы хотим поймать. В данном
случае мы пишем, что блок catch хочет поймать исключение типа int и назвать его r. То есть,
грубо говоря, создаем локальную переменную внутри блока catch. Ну и соответственно мы говорим,
что когда мы поймали исключение, то есть, собственно, мы его поймали, мы его захлопнули и
дальше там выводим какую-то, например, отладочную информацию. Важно понимать, что после того,
как отработает блок catch, программа продолжит нормальное функционирование. Вот блок catch как
раз отвечает за то, что вы обрабатываете ошибку и не даете ей полететь дальше. Вот если бы мы тут не
написали try catch block, то исключение, которое бы вылетело из функции divide, оно бы вылетело в
функцию main, дальше оно бы покинуло в функцию main и программа бы аварийно завершилась. Здесь такого не
происходит, здесь программа завершается нормально. Внутри блока try было выброшено исключение, в
кейче мы его поймали, то есть считается, что мы его обработали и пошли дальше. Ну и при этом мы
пошли дальше не от момента того, как мы выбросили исключение, а после catch блока. Понятно? То есть,
если у нас try block не получился, то дальше мы его выполнять не продолжаем. Мы продолжаем вот после
всего try catch блока. Окей? Все ясно? Да, ну соответственно, по завершению блока catch исключение
считается успешно выработанным и выполнение программы продолжается нормально в режиме.
Вот, соответственно, если здесь в divide выбрасывается исключение, то работает catch, выводится это
сообщение об ошибке. Вот это сообщение не выводится, потому что до него, собственно, наш... Что?
Дискуссионный вопрос, в общем. Короче говоря, это сообщение не будет выведено на экран,
это важно, это главное. То есть мы продолжим работу непосредственно сразу со следующей инструкцией,
то есть return 0. Да, значит, одному блоку try может соответствовать несколько блоков catch. Ну вообще
говоря, это стандартная ситуация, когда у вас из одной функции может вылетать исключение разных
типов. Ну, например, в случае деления на ноль вы бросаете исключение типа int, в случае, не знаю,
какого-то переполнения вы бросаете исключение типа в данном случае double. То есть это нормальная
ситуация, что у вас из одной функции могут вылетать исключение разных типов. Ну, в отличие от механизма
return, если у нас функция что-то возвращает, то она должна возвращать объект определенного типа.
Вот в случае, когда вы выбрасываете исключение, в принципе, вы можете бросить исключение абсолютно
любого типа. То есть можете бросить как int, можете бросить double. Ну и в этом случае у вас выбирается именно
тот блок, который соответствует типу исключения. То есть если divide, функция divide бросает исключение
типа int, то оно будет поймано в catch-блоке соответствующему типу int. Да, ну и соответственно,
если нужный catch-блок найден не будет, то исключение считается необработанным. В данном случае
у вас divide бросает int, но при этом вы написали два catch-блока, который принимает double и который
принимает констанция развёточка. int не является double и int не является констанция развёточки,
поэтому считается, что исключение необработанное, оно полетит дальше. Так как если бы вы не написали
трое catch-блок. Здесь может возникнуть вопрос. Ну смотрите, допустим, у меня есть функция, и функция
принимает double. Я же в эту функцию, в принципе, могу передать int. То есть я в функцию, которая принимает
не целые числа, могу передать целое число, и при этом у меня будет выполняться приведение int к
double. Ну казалось бы, а почему здесь не так? Ну здесь не так, потому что не так. Catch-блок работает не так.
То есть catch-блок не выполняет никаких преобразований. То есть catch-блок ищет соответствия именно по
точному совпадению типа. То есть он проверяет, равен ли int даблу, int не является даблом, поэтому этот
catch-блок игнорируется. Равен ли int констанция развёточки? Нет, не равен. Этот catch-блок игнорируется.
Catch-блоки закончились, всё, исключение летит дальше. То есть нужный catch-блок и ищется именно по
нужному, по точному соответствию. Никаких приведений типа не происходит за некоторым исключением.
Да, это тоже про то же самое. Да, вот про исключение. Значит, есть пара исключений, которые касаются
трай-catch-блоков. Первое исключение это void-звёздочка или void-указатель. С помощью void-указателя
вы можете поймать любой указатель. Вот такое правило. То есть если вы внутри трай-блока бросаете
исключение типа указатель на int или указатель на любой другой объект, то этот указатель вы можете
поймать с помощью указателя на void. То есть void принимает абсолютно любой указатель. Здесь
приведение типа происходит. Типизированный указатель приводится к нетипизированному указателю.
Это первый момент. Ну и второй момент. Происходит приведение в рамках иерархии
наследования. То есть если у вас стип B унаследован от A. При этом важно, что у вас стип B унаследован
публичным образом от A. То есть, грубо говоря, B является A. То есть мы говорили, что публичное
наследование реализует отношение являться. То есть если B унаследовано от A, то это значит,
что B тоже является A. Поэтому если вы бросаете в какой-то функции исключение типа B, то вы в
принципе его можете поймать в кетч-блоке, который ловит A. Это вполне корректно. То есть приведение
типов тут происходит. Все ясно. Еще одно правило выбора блока catch. Если так получается, что подходит
несколько блоков catch. Ну а такое может происходить только в случае наследования и в случае
указателей. Потому что все остальные кетч-блоки ищутся ровно по точному соответствию. Так вот,
если у вас есть несколько подходящих блоков catch, то срабатывает всегда первый подходящий. Вот пример.
Значит, у вас есть там некоторая функция, некоторый код, который генерирует исключение типа int
указатель. И у вас есть два кетч-блока, один из которых ловит void указатель,
а второй ловит int указатель. Так вот, отработает именно первый кетч, то есть int указатель
поймается первым кетчом. Потому что поиск кетч-блока происходит последовательным образом. То есть
сначала проверяется первый кетч-блок, подходит он или нет. Если нет, то идем дальше. Если подходит,
то все. Мы тут останавливаемся и обрабатываем ошибку здесь. Поэтому второй блок, в принципе,
никогда не будет отработан. Второй блок никогда не сработает. Любой указатель будет
пойман void указателем, поэтому все будет плохо. Ну и то же самое касается иерархии наследования.
Если у вас B унаследован от A, и вы бросаете объект типа B. Вот у вас есть два кетч-блока, один из
которых ловит объекты A, а второй из которых ловит объекты B. То в этом случае у вас первый кетч-блок
отработает, а второй выполнен никогда не будет. Почему? Потому что когда вы бросаете исключение
типа B, B является A, и первый кетч-блок подходит. Второй кетч-блок даже рассматриваться не будет.
Ну и так, что еще хотел сказать. Вообще говоря, нормальные компиляторы в такой
ситуации, они выдают вам предупреждение и скажут вам о том, что вот те кетч-блоки,
которые написаны снизу, они будут проигнорированы. Так что тут не все так плохо. То есть если вы написали,
ну допустим, вы перепутали кетч-блоки местами, скажем, ну написали void звездочка, потом int звездочка,
то компилятор вам любезно подскажет, что кетч-блок, который принимает int звездочка, он выполнен
никогда не будет. Почему? Потому что все будет поймано void звездочка, и он предложит вам поменять
их местами. Да, ну и вообще такое правило, что если у вас, что нужно идти от более специфичного типа к менее
специфичному. То есть если мы тут действительно, вот представим себе, что вот мы в этом примере
действительно хотим поймать и int звездочку, и void звездочку. То есть если мы хотим, чтобы когда
вы бросаете int звездочку, у вас ловилось, у вас срабатывал кетч-блок, который соответствует int
указателю. Если вы бросаете какой-нибудь другой указатель, вы хотите, чтобы работал именно кетч-блок,
который соответствует void звездочки. Ну чтобы решить эту проблему, достаточно просто поменять
местами эти кетч-блоки. Теперь у вас в первом будет рассматриваться кетч-блок, которому int указатель,
а дальше если int указатель не подходит, то будет рассматриваться void звездочка, который поймает
вообще в принципе любой указатель. Ну и то же самое касается кетч-блока, в котором два класса
связаны иерархией наследования. Вот в этом случае, если вы хотите ловить объекты типа B в кетч-блоке B,
а все остальные объекты в кетч-блоке A, то вы меняете их местами и тогда у вас сначала проверяется
верно ли что объект типа B. Если объект не типа B, то дальше проверяете объект типа A и все нормально работает.
Так, продолжим говорить про кетч-блок. В следующую очередь у нас ловили исключение по ссылке.
Помимо того, что исключение можно ловить просто по значению, исключение можно ловить и по ссылке
на объект. Так как я сказал, что исключение хранится в некоторой специальной отдельной области памяти,
ну опять же исключение, за ним стоит отдельная область памяти, соответственно это означает,
что само исключение, исключение которое летит, оно является lvalue. Если это lvalue, то на него
можно создать ссылку. Собственно, ровно это и происходит. Допустим, мы бросаем исключение типа
вектор из миллиона элементов. Сразу скажу, бросать вектор очень плохая идея, не бросайте вектор,
вообще в принципе не бросайте ни инты, ни даблы о том, что нужно бросать, мы поговорим позже.
Допустим, у вас судьба вынудила бросить какой-нибудь тяжелый объект, например, вектор. Чтобы его не
копировать, то есть понятное дело, что если вы напишете кетч и дальше напишете std-вектор и как-то
обзовете эту переменную, то у вас этот объект исключения скопируется внутрь блока кетч, то есть все
эти миллионы объектов будут скопированы и будет не очень эффективно. Чтобы не копировать лишний
раз исключения, их можно принимать по ссылке, либо по обычной ссылке, либо по константной ссылке,
как здесь. В этом случае объекты исключения копироваться не будут, они просто будут ссылаться
на ту область памяти, в которой хранится текущее исключение. Кроме того, еще одно преимущество
ловли исключений по ссылке заключается в том, что если объект класса, которого вы бросаете,
является наследником чего-то там или в принципе обладает полиморфным поведением, то есть у него есть
какие-то виртуальные функции и так далее, то мы помним, что с помощью ссылок у нас становится
доступно полиморфное поведение. То есть если у вас есть объект типа B, он наследован от A и,
скажем, внутри A есть некоторая виртуальная функция, виртуальная функция F, и вы бросаете,
скажем, какой-нибудь объект типа B, а потом ловите его по ссылке на A, то если вы через A вызываете
F, то у вас будет вызываться именно та функция F, которая находится внутри объекта B, а не внутри
объекта A. То есть это обычное классическое полиморфное поведение. Это бывает полезно, и более того,
это нам пригодится, когда мы будем говорить про стандартную иерархию исключения в языке C++.
Мораль ловить исключения по ссылке хорошо, не по ссылке плохо. Ну, опять же, если речь не идет
о какие-то примитивные базовые типы. Теперь, допустим, мы не знаем, что мы хотим поймать. Ну,
давайте так. Мы не знаем, какие типы исключений бросают в наши функции. Ну или в принципе нам
не важно, что они бросают, нам важно поймать какую-то ошибку и что-то сделать дополнительное,
дай как-то ее обработать. В этом случае есть специальный синтактик с кетч с многоточием. Вот если
вы пишете кетч многоточие, то это означает, что данный блок кетч ловит вообще любое исключение.
То есть, опять же, если вы дошли до блока кетча, то есть, понятное дело, у вас происходит проверка по
порядку, то есть сначала там один кетч блок, второй кетч блок. Если вы что-то не поймали,
попали в кетч блок с многоточием, то вот это любое исключение, какое бы оно ни летело, оно будет
именно внутри кетч многоточия. Ну и дальше внутри него вы можете как-то там обработать ошибку и
сделать там что-то более-менее полезное. Но у этого способа есть недостаток, который заключается в том,
что если вы писали кетч многоточие, то у вас в принципе нет никакой возможности получить значение
собственно ошибки. То есть, когда вы пишете кетч многоточие, вы говорите что, то есть вы как бы
дополнительно говорите о том, что вы не знаете, какого типа у вас исключения. И соответственно,
ну какого-то варианта узнать про это нет. То есть, если у вас есть кетч с обычной типа
или комплизированный кетч, то вы можете создать там переменную этого типа и как-то с ней работать.
То есть вы можете посмотреть, что там лежит, вы можете оттуда, например, вынуть какой-то там информацию
об ошибке, выбросать вектор ошибок. То есть с кучей вообще все плохо пошло, у вас там миллион ошибок.
Вот вы можете каждый из них посмотреть. В случае кетч многоточий у вас нет возможности заглянуть
в объект исключения и понять, что происходит. То есть вы можете делать какие-то некоторые общие действия.
Ну и, собственно, ключевой вопрос. Хорошо, что делать в кетчблоке? То есть, смотрите, казалось бы,
вот все то, что мы до этого обсуждали, там, не знаю, закончилась память, сервер не отвечает и так далее.
То есть кажется, что мы это починить не можем. То есть кажется, что есть причины, которые от нас не зависит,
и, наверное, единственный способ нам что-то сделать это просто завершить программу. Ну, как мы говорили,
что, как мы говорили, это не всегда вариант, так как, если вы там пишете какое-то серверное
приложение или там просто нарисовать какой-то сервер, то, если у вас там сервер из-за любого ошибки
падает, то это не очень хороший сервер. То есть, мы хотим, чтобы там ошибка была поймана,
была как-то обработана и дальше нам мы что-то делали. Вот. Соответственно, что обычно делают в кетчблоке,
для чего нужен кетчблок? Ну, первое очевидное, очевидное, что можно делать в кетчблоке,
это попробовать починить проблему. Да, то есть если вы понимаете, что у вас там произошло деление на ноль,
то вы можете внутри качблока написать на экран, что деление на ноль запрещено и дальше продолжить принимать пользовательский ввод, и так далее.
Еще одна причина, по которой нужно использовать качблок, это чтобы избежать усечек памяти.
Пример. У нас есть функция f, и она выделяет некоторую динамическую память.
То есть выделяет в динамической области памяти некоторый int.
Дальше вы понимаете, что у вас есть функция g, которая потенциально опасна, которая бросает исключения.
Допустим, я тут не написал tri-catch-блок. Что произойдет, если у меня внутри функции g выскочит исключение?
Очевидная утечка памяти. Потому что что происходит, когда у меня из функции выбрасывает исключение?
Если функция g бросила исключение, и я это исключение не обрабатываю, у меня функция завершает работу, все локальные перемены уничтожаются.
А если я выделил память с помощью new, то delete для нее, естественно, автоматически не вызывается.
То есть это абсолютно на вашей совести.
Поэтому, если вы хотите, чтобы при вылете исключений из какой-либо потенциально опасной функции у вас не возникало проблем с утечкой памяти,
с утечкой каких-то других ресурсов, вы можете сделать следующую вещь.
Вы можете сказать tri, обернуть потенциально опасную функцию или функцию i в этот tri-bloc,
дальше поймать исключение, и соответственно внутри этого catch-bloc вы делаете delete-ptr, то есть очищаете ресурсы.
Здесь пример функции, которая делает следующую вещь.
Вы пытаетесь выполнить какую-то функцию, если у нее все получилось, то вы идете дальше.
Если у нее что-то не получилось, вы удаляете память, присваиваете этому указателю null-ptr и идете дальше.
Понятно? Чтобы избежать утечек памяти, мы используем tri-catch-bloc, и внутри catch-bloc выполняем delete.
Этот пример немного странный, потому что он говорит следующее.
Если в функции g произошла какая-то ошибка, то я должен удалить память, присвоить ptr и null-ptr,
и в этом примере у меня функция f продолжает нормально функционировать.
Наверное, хотелось бы сделать следующую вещь. Для чего я поймал исключение в этом примере?
В этом примере я поймал исключение для того, чтобы его поймать и очистить память.
То есть я хотел избежать утечки памяти. Но при этом как обработать ошибку, я не понимаю.
Если я не понимаю, как обработать ошибку, то что мы делаем?
Переносим ее на следующий уровень, говорим, что мы не знаем, что делать, и пусть следующая функция с этим разбирается.
Вот как добиться такого поведения? Можно сделать примерно следующее.
Можно сказать, можно писать так. Я вызываю функцию g, если она зафейлилась, я удаляю указатель,
то есть удаляю память, которая была выделена в динамической области, и дальше бросаю исключение снова.
Ну вот так.
То есть вы поймали исключение, там что-то сделали, и потом выбросили его заново.
Но тут есть несколько проблем.
Первое. Если вы пишете вот так, то что происходит? То есть мы обсуждали.
Если вы пишете throw и дальше пишете там некоторый объект существующий,
то в специальной области, где хранится исключение, создается его копия.
То есть вы как бы заново создаете то же самое исключение, копируя его в ту же самую область памяти.
Или не в ту же самую, но просто берете то же самое исключение и копируете его.
Понятно? Ну а хотелось бы, наверное, просто из клетки выпустить то самое исключение, которое было до этого.
То есть не создавать новое исключение, а сказать, что вот то исключение, которое было до этого, оно должно продолжить лететь.
И вторая проблема заключается в том, что если вы тут написали кетч с многоточием?
То есть вы не знаете какого типа исключения, вот бросает функция g.
Ну и в принципе вам не интересно, какие исключения она бросает.
Вам просто хочется поймать исключение произвольное, очистить память и бросить его дальше.
Вот что нужно написать здесь, чтобы бросить исключение дальше?
Нам же хочется, чтобы летело именно то же самое исключение.
Мы не хотим создавать другого.
Потому что в исходном исключении хранилась некоторая информация о том, что пошло не так в той функции.
Проблема ясна?
То есть мы хотим бросить не копию исключения исходного, а именно то же самое исключение, которое летело до этого.
И это можно сделать с помощью специального синтаксиса throw без аргументов.
Вот если вы пишете throw без аргументов, то это дословно означает перебросить старое исключение.
То есть то же самое исключение должно лететь дальше.
Ну условно у вас было брошено исключение, вы его поймали в кетче, заковали в клетку.
А когда вы пишете throw без чего угодно, то есть throw и точка за пятой,
вы из клетки выпускаете зверя, которое вы поймали до этого.
То есть никакого дополнительного исключения не создается.
Вы бросаете именно то же самое исключение, которое летело до этого.
И поэтому нормальный пример, который фиксит вот проблему цитички памяти, выглядит так.
Вы потенциально опасный код оборачиваете в трайблок.
Дальше, если там что-то пошло не так, вы пишете catch, ловите что угодно,
нам вообще говоря, не важно что, мы очищаем память и дальше перебрасываем исключение дальше.
То есть та функция, которая нас вызывала, пусть разбирается дальше с этой проблемой.
Вот такой пример.
Ну и наконец, собственно, вернемся к разговору про рай.
Напомню, когда-то давно на лекции по деструкторам мы говорили,
что есть такая идиома языка C++, resource acquisition из initialization.
То есть захват ресурса есть инициализация.
И мы тогда говорили такие вещи, что если мы реализуем эту идиому,
то есть если мы захватываем ресурс в конструкторе, освобождаем его в деструкторе,
то это все классно, здорово.
Нам не нужно задуматься о том, чтобы автоматически вызывать самостоятельно delete.
То есть вы в первом задании написали свой класс динамические строки,
мы написали умные указатели и так далее.
В общем, теперь мы память вообще не управляем.
И вообще удобство использования, конечно, здорово.
То есть здорово, что мы вручную не пишем new, delete.
Но дополнительно преимущество стоит в том, что это рай.
Оно играет новыми красками, когда мы говорим про исключение.
Вот смотрите.
Чтобы избежать утечки памяти в случае, когда я выделяю сырую память,
то есть работаю явно с new и delete,
мне нужно написать вот такое количество кода.
А что произойдет, если я заменю, скажем так, обычный сырой указатель,
то есть обычное new, на умный указатель?
Только оказывается, что мне будет достаточно написать всего лишь две строки.
То есть смотрите, если я создаю умный указатель,
то я в принципе могу не задумываться об исключениях.
Точнее о том, что у меня в результате выброса какого-то исключения
будет утечка памяти.
Почему?
Потому что если вдруг G у меня бросает исключение,
то что у меня происходит?
У меня происходит раскрутка стека.
Или схлопывание стека.
А при схлопывании стека у меня уничтожаются все локальные переменные.
Хорошо, у меня уничтожается локальная переменная ptr.
Но если раньше ptr у меня уничтожалось как адрес,
при уничтожении адреса у вас delete не вызывается,
то здесь при уничтожении ptr у вас вызывается уник ptr,
то есть деструктор умного указателя.
А в деструкторе умного указателя у вас происходит ощущение памяти.
Понятно?
То есть мораль состоит в том, что когда вы используете всякие обертки вида умных указателей,
вектор, стринг и так далее, у вас код становится более безопасным.
Более безопасным в том смысле, что если вы пропустили какое-то исключение,
то у вас не происходит никаких утечек памяти, никаких утечек ресурсов,
потому что объекты сами контролируют свое время жизни,
и даже в случае исключения при раскрутке стека эти объекты будут корректно освобождены и очищены.
В отличие от сырых указателей или сырых ресурсов.
Мораль ясна?
На самом деле, RAI это как раз-таки скорее про безопасность,
в таком смысле, а не про безопасность, что ой, мы забыли написать delete.
То, что вы забыли написать delete, это, конечно, приятный бонус,
что диструкторы автоматически все делают из-за вас.
Но в случае написания безопасного кода RAI очень сильно помогает
и позволяет избегать таких больших длинных конструкций,
вида try-catch и так далее.
Хорошо.
На этом основная часть про try-catch и обработку исключения на сегодня закончим.
Продолжим в следующий раз.
Сейчас перейдем тоже к разговору про исключение,
но про некоторую другую пастась, именно про статическую спецификацию исключений.
Но, в частности, поговорим про слово noexcept
и наконец поймем, что оно означает.
Когда мы писали свой конструктор перемещений и пресваивающие перемещения,
я говорил, что нужно их перемещать в noexcept.
На самом деле не станет понятно почему, но станет понятно, что оно означает.
Для чего мы пишем noexcept, станет понятно в следующий раз.
Я умею держать интригу.
Что означает слово noexcept?
Noexcept – это спецификатор.
Один из смыслов слова noexcept – это спецификатор.
С помощью этого спецификатора вы можете поместить функцию как такую,
что она не бросает исключений, или она не генерирует исключений.
Если вы в конце функции написали, что написали noexcept,
то вы говорите или обещаете компилятору и вообще всем остальным,
что эта функция точно генерирует исключений не будет.
В частности, когда мы писали, что конструктор перемещения noexcept
или операция или перемещающий пресваивание noexcept,
мы говорили, что эти функции не бросают исключения.
Noexcept – это просто некоторое обещание.
Что будет, если это обещание нарушить?
Вообще говоря, я никому не рекомендую обманывать компилятора.
Это не касается не только noexcept, а вообще любой другой штуки.
Если вы бросаете исключения внутри функции,
которая помещена noexcept, то вашу программу просто убивают.
Вот здесь и сейчас.
Без возможности восстановления, без возможности обработать ошибку и так далее.
Если вы бросаете исключения из функции, которая помещена noexcept,
то это автоматическое прекращение работы программы,
и ничего с этим не поделать.
Поэтому если вы написали noexcept, то будьте добры гарантировать,
что это действительно noexcept.
Ну или не пишите noexcept, если вы не уверены, что она ничего не бросает.
Вообще с этим понятно.
Вообще с правилом использования слова noexcept есть более сильное правило,
которое называется правило, по-моему, Лакоса по имени,
по имени инженера.
Правило заключается в следующем.
Вы должны помечать функцию noexcept не только в случае, если она ничего не бросает,
но и в случае, если в ней внутри ничего не может произойти плохого.
То есть у нее внутри нет undefinedBehaviour,
у нее нет внутри чего-то другого плохого и так далее.
То есть если функция всегда работает в штатном режиме,
функция всегда завершается нормально,
функция всегда делает то, что она заявляет, то это noexcept.
Если в функции потенциально что-то может пойти не так,
она может бросить исключения или в ней может произойти undefinedBehaviour,
например, деление на ноль и так далее,
то эту функцию помечать noexcept не стоит.
Это не правило компилятора, не правило дискаута,
просто некоторое правило приличия,
что noexcept мы помечаем только в функции, в которых не происходит ничего плохого,
которые не только не бросают исключения,
а в принципе там все всегда хорошо.
Ну и соответственно здесь пример такой, что если вы внутри функции,
которая говорит, что она noexcept,
то если внутри нее все-таки приходится вызывать небезопасные функции,
то вы должны эти исключения как бы обработать сразу же внутри этой функции.
То есть noexcept говорит лишь о том,
что исключения не покидают эту функцию.
То есть внутри этой функции в принципе исключения создаваться могут.
В частности, вы можете вызвать функцию g,
которая потенциально может бросить исключения.
Вот если функция g бросит исключения, то ничего плохого не будет,
если вы это исключение обработаете.
вы это исключение обрабатываете, то есть корректно все работает и продолжаете дальше.
То есть это нормально.
То есть noexcept говорит о том, что исключения из функции f не вылетают.
То, что происходит там внутри, в принципе, у вас не касается.
Дальше. Следующее назначение слова noexcept это условный спецификатор.
Значит, помимо того, что вы можете написать просто noexcept,
вы можете написать noexcept в скобочках true.
И это будет абсолютно то же самое, как если вы написали noexcept.
Дальше. Если вы не пишете noexcept, то это то же самое, как если вы написали noexcept false.
То есть существует некий дополнительный условный спецификатор noexcept,
который принимает внутри себя некоторое выражение, которое может быть вычислено на этапе компиляции,
и которое вычисляется либо как true, либо как false.
И вот если оно вычисляется как true, то у вас функция noexcept.
Если выражение вычисляется как false, то у вас функция noexcept.
Для чего это может быть нужно?
Игрушеч, например, вот такой. Дальше будет более смысленно.
Ну, в общем, примерно так.
Ну, представьте себе, что у вас есть функция h, которая является noexcept в случае,
если у вас размер t достаточно большой, ну, например, размер типа t больше единицы,
то есть в памяти занимает больше 0 байта.
И является noexcept, если тип t занимает в памяти 1 байт.
Тогда вы это условие можете записать так.
noexcept и sizeof от t больше единицы.
Тогда, если sizeof t действительно больше единицы, то у вас функция noexcept.
Если sizeof t не больше единицы, то есть равен единице,
тогда эта функция у вас не noexcept.
Ну и третий смысл слова noexcept, то есть спецификатор noexcept,
условный спецификатор noexcept и есть операция noexcept.
Операция noexcept это некоторая операция,
которая говорит о том, является ли выражение,
которое стоит в круглых скобках noexcept или нет.
Ну, условно. У вас есть функция f, которая noexcept,
у вас есть функция g, которая не является noexcept.
Как понять, какая из функций noexcept, какая не noexcept?
Вы просто-напросто пишете noexcept,
и в круглых скобках пишете условно вызов функции f,
ну или как-то ее испортите.
И вот эта вот операция noexcept вам возвращает,
является ли вызов функции f безопасным или нет.
При этом важно понимать, что noexcept на самом деле ничего не вычисляет.
То есть если вы вызвали noexcept и в круглых скобках f,
то f на самом деле вызвано не будет.
То есть на accept он просто на этапе компиляции проверяет вот
потенциально вызов функции f может привести к чему-то плохому или нет.
Ну, равно как sizeof.
Да, sizeof он тоже не вычисляет, что стоит у него в круглых скобках.
Sizeof просто там смотрит на выражение,
смотрит на то, что он возвращает,
и вот то, что он возвращает, он как бы говорит, какой у него размер байтов.
Вот с noexcept то же самое.
Noexcept просто анализирует выражение, которое стоит в круглых скобках,
и говорит, вот оно потенциально опасное или безопасное.
Потенциально опасное будет в случае функций?
Нет, в случае функций noexcept просто проверяет,
все ли функции, которые написаны внутри круглых скобок,
помещены как noexcept или нет.
То есть в случае noexcept от f будет true, в случае noexcept от g будет false.
То есть noexcept просто смотрит выражение
и проверяет, есть ли там какие-то конструкции,
которые могут бросить исключение.
То есть есть ли там конструкции, которые не помещены как noexcept.
И все.
Ну вот в частности, если вы спросите,
является ли noexcept 1 делить на 0,
просто noexcept 1 делить на 0,
то вам вернется true.
Это выражение является noexcept. Почему?
Потому что деление целых чисел
никогда не приводит к выбросу исключения.
Понятно?
То есть операция noexcept проверяет верно лишь,
что все, что написано из круглых скобок,
не может бросить исключений.
Деление на 0 не бросает исключений хотя бы потому,
что язык C++ унаследован от языка C.
А в языке C никаких исключений нет.
Понятно?
Поэтому формально 1 делить на 0 является noexcept.
Более того, компилятор 1 делить на 0 даже вычислять не будет.
Он просто посмотрит, что слева стоит int,
справа стоит int.
Если я int разделю на int, то исключений
никакого не генерируется никогда.
Поэтому это noexcept.
А если я напишу v.pushback,
ну и дальше что-то,
то это уже false.
Почему?
Почему добавление в динамическую строку
или в динамический массив,
почему добавление в конец динамического массива
не является noexcept?
Да, не хватит памяти.
Если мы добавляем что-то в динамический массив,
в динамический массив он может расшириться.
А когда у вас динамический массив расширяется,
он запрашивает память. Памяти может не хватить.
Если у вас не хватает памяти,
то вам бросается исключение badalog.
Поэтому вот это вот выражение
не является noexcept не из-за того,
что вы 1 делите на 0.
То есть компилятор вообще плевать,
что вы разделили, он это не вычисляет.
Это не является noexcept,
ровно потому, что pushback потенциально
может бросить исключения.
Это как noexcept.
Если я напишу вот так,
вот это выражение тоже всегда true.
Почему? Потому что выход за границу массива
тоже никогда не приводит к исключениям.
То есть если вы выходите за границу
обычного C массива,
то C и C++ не проверяют выход за границу.
Поэтому это undefined behavior.
Вектор или любой динамическая строка,
динамический массив, они тоже не проверяют
выход за границу массива.
Поэтому вот это выражение,
несмотря на то, что оно потенциально опасное,
оно всегда noexcept, потому что оно никогда не так.
Оно является noexcept,
потому что функция...
Сейчас. Я соврал.
Я соврал.
Тут правило такое.
Если v это обычный массив,
ну, C-шный массив,
C-шный массив,
то эта штука скорее всего является noexcept. Почему?
Потому что
язык C++
совместим с языком C.
В языке C никаких исключений нет.
Поэтому это выражение с обычными C-шными массивами
и динамическими массивами
оно привести к выбросу исключений не может.
Так это выражение привести к выбросу исключений не может,
оно noexcept. То есть тут true.
Вот первый факт понятен, вот этот.
Если вы вызываете noexcept,
и вот тут написан обычный C-шный массив,
то это всегда noexcept,
потому что C-шные массивы не образуют исключений.
Теперь, если v это вектор,
то здесь noexcept false.
Почему это так?
Потому что
оператор
квадратной скобки,
который реализован
внутри вектора,
не помечен как noexcept.
Потому что правило лакоса.
Правило говорит о том, что
несмотря на то, что оператор квадратной скобки
не может выбросить исключения,
потенциально внутри вектора что-то может пойти не так.
Поэтому оно не помечается noexcept.
То есть noexcept проверяет,
верно ли что та функция, которую я вызываю,
является noexcept.
Внутри вектора оператор квадратной скобки
noexcept не является.
Поэтому здесь будет noexcept false.
Ну и финальный пример.
Соответственно,
мы приводили для условного спискатора noexcept,
мы приводили некоторые игрушечные примеры,
что у меня функция является noexcept,
если size of t больше единицы,
и не noexcept, если size of t не больше единицы.
Но это примеры игрушечные,
более-менее согласованные с реальностью примеров.
Вот я пишу функцию сам.
Давайте пока сюда только посмотрим.
Я пишу функцию суммы,
которая просто принимает два произвольных значения,
абсолютно произвольные значения,
x и y,
и складывает.
И я задаю вам вопрос, верно ли что
сумма x и y noexcept?
Сложение двух нотов когда-нибудь может привести
к исключению?
А двух доблов?
Я складываю два значения,
никогда не бросаю исключения,
поэтому надо пометь noexcept.
Что может быть проблема?
Я утверждаю, что сложение двух чисел,
так как сложение двух чисел,
они пришли к нам язык аси,
язык си не бросает исключения,
поэтому сложение двух чисел никогда не бросает исключений.
Что?
Указатель.
Указатель я в принципе не могу складывать.
Да, отлично.
Пора избавляться,
порадим мы первый семестр,
когда мы работали с примитивными типами и так далее.
У нас ООП.
В ООП мы пишем собственные классы,
у нас есть другие классы.
В принципе,
исходное предположение о том,
что в функцию суммы могут прийти только числа,
неверно.
У нас есть собственные классы,
у нас есть класс строки.
Строки все плюс-плюс можно складывать с помощью плюсов,
это просто-напросто конкатинация строк.
Что если я функцию сам передам две строки
и буду складывать две строки?
Верно ли, что сложение двух строк или конкатинация их?
Это noexcept.
Нет, потому что почему?
Ключение двух строк к чему приводит?
Вы выделяете память для хранения суммы двух строк
и копируете две строки туда.
При выделении памяти
эта память может закончиться
и вам будет выброшено исключение.
Поэтому x плюс y в случае строк
может быть исключение.
И вот тут возникает проблема.
Для int'ов
x плюс y это noexcept,
для строк x плюс y это не noexcept.
Как понять,
помечает ли мне функцию шаблонную сумму noexcept или нет?
Ну вот, собственно,
использовать условный спецификатор noexcept
и операцию noexcept.
Как это работает?
Я говорю, что у меня функция noexcept
при условии,
что noexcept x плюс y.
Что делает noexcept x плюс y?
Noexcept x плюс y проверяет.
Верно ли, что x плюс y никогда не бросает исключений?
В случае int'ов это правда.
В случае int'ов
вот этот внутренний noexcept
возвращает true.
Поэтому тут в итоге получается noexcept от true.
А noexcept от true это то же самое, что noexcept.
Для строк.
Если я спрашиваю для строк,
верно ли, что noexcept x плюс y?
Noexcept x плюс y для строк возвращает false.
Потому что x плюс y для строк
потенциально может бросить исключение.
Поэтому тут возникает noexcept в скобочках false.
А noexcept в скобочках false
то же самое, что мы не написали noexcept.
Поэтому у меня функция является noexcept или не является
noexcept, в зависимости от того,
верно ли, что x плюс y бросает исключение или нет.
Понятно?
Ну вот.
Такие дела.
Ну и последний пункт.
Он не связан с тем, о чем мы говорили.
Это просто как бы некоторый факт,
которым можно пользоваться.
Давайте скажу следующую вещь.
Вообще говоря,
давайте общие слова про исключения.
Что исключение?
Лучше чем возврат кода ошибки в языке C.
Во-первых, исключения они более явны.
Скажем, вы не можете
проигнорировать исключения.
Проигнорировать код ошибки вы можете.
То есть вы вызываете функцию,
то, что она возвращается вы можете приближать и проигнорировать ошибку.
Исключения в языке C dolly
вы не можете проигнорировать.
Если у вас возникает исключение,
то у вас программа завершается.
Это как бы более явно сказать,
что-то идет не так, как завершить программу, короче, способов нет. Поэтому ошибки вы
всегда обязаны обрабатывать. Вот это первый момент. Второй, еще один важный момент,
заключается в том, что делать, если у вас исключение возникает в конструкторе?
Вот, смотрите, допустим, у вас в конструкторе возникло исключение. Как вам сообщить о том,
что в конструкторе возникло исключение? С помощью кода ошибки это сделать невозможно.
Почему? Потому что конструктор ничего не возвращает. Конструктор лишь создает объект.
А вот если вы бросаете исключение и вы бросаете исключение из конструктора, то в принципе это все
можете обработать. То есть исключения обладают преимуществами, но и также обладают недостатками.
Например, один из недостатков состоит в том, что они достаточно тяжелые. То есть если у вас
возникает исключение, то в принципе программа начинает работать долго по сравнению с возрастом
кода ошибки. Возврат кода ошибки это всегда быстро. Просто одна ретерн инструкция и так далее.
И в принципе использовать исключение или нет, это полностью зависит от вас. На самом деле,
в ближайший год, наверное, не от вас, а от преподавателей, от работодателей, как принято в том
месте, где вы работаете и так далее. В частности, в Google Code Style явно прописано, что они не используют
исключения. То есть Google решили для себя, что мы не используем исключения, мы используем кода
ошибок и так далее. Некоторые считают наоборот, что мы используем исключение, кода ошибок это
некоторая устаревшая вещь и так далее. И тут возникает там некоторая проблема. Ну смотри, допустим,
вот вы приняли для себя решение, ну или кто-то принял решение, что с исключением мы не работаем.
То есть по какой-то причине нам не нравится исключение, то есть мы считаем, что они работают долго
и так далее. Возникает вопрос. Ну смотрите, new. Как я сказал, когда вы вызываете new, у вас
потенциально может не хватить памяти. Если у вас не хватает памяти, то new может бросить исключение.
И это как-то плохо соотносится с тем, что, скажем, мы не работаем с исключениями, и new бросает
исключение. То есть все-таки в некоторых ситуациях вам, казалось бы, нужно использовать исключение.
Но вот это на самом деле не так. Существует специальная форма оператора new, которая исключений
не бросает. И это так называемая no throw new, то есть не бросающий new. Как это выглядит? Если вы хотите,
чтобы new не бросал исключений, вы пишите new, дальше в круглоскобок std no throw, ну и дальше там
обычный массив или объект, который вы хотите создать. Этот new в случае нехватки памяти бросать
исключения не будет. А что он будет делать? Он будет просто возвращать вам nullptr или не nullptr,
но, собственно, как сишный молок. То есть если new завершился с ошибкой, то есть ему не удалось
выделить память или не удалось создать объекты, он вернет вам nullptr. Если ему удалось все сделать,
то он вернет не nullptr. Поэтому в случае, когда вы используете не бросающий new, вы пишете
ptr равно new что-то там, дальше проверяете верно ли что то, что вам вернулось, не является nullptr,
и если это не nullptr, то вы выполняете некоторые действия. Если nullptr, значит что-то пошло не так.
Ну, собственно, вот некоторый аналог возврата кода ошибки для new. Так, сегодня говорим про хэш таблицы.
Общие слова. Что вы знаете вообще про структуру данных поиска? Вот, допустим, вам дан
некоторый массив, произвольный вообще, в котором нужно найти определенный элемент. Вот дан массив
A, нужно понять верно ли, что х лежит в массиве A. За какое время это можно сделать? Ну, за линию,
да? Быстрее, чем за линию, скорее всего, не получится. Почему? Потому что если массив
действительно произвольный, то в худшем случае нам придется пройтись по всем его элементам,
и, соответственно, выяснение того, содержится ли там элемент x или нет, занимает линейное вот
размер массива время. Хорошо. Существуют ли примеры массив, на которых, в принципе,
можно это сделать быстрее, чем за линию? Ну, сортированный массив, да. То есть, если у вас
массив A сортированный, то выяснение, содержится элемент в сортированном массиве или нет,
занимает логарифмическое время. Почему? Потому что внутри массива есть некоторая определенная
структура, мы ее понимаем, мы понимаем, что, скажем, если мы смотрим на какой-то элемент,
то слева все меньше, справа все больше, ну и таким образом мы можем ускорить поиск.
Окей. Ну хорошо, ну вот есть замечательный отсортированный массив, в котором поиск
осуществляется за логарифмическое время. Ну все, отлично, логарифм на самом деле очень,
очень хорошая функция, она на всех разумных значениях, ну скажем, принимает очень маленькое..
Ну, короче, она принимает очень маленькое значение, поэтому, в принципе,
логарифма нам почти всегда достаточно. Почему бы в качестве структуры данных поиска,
скажем, мне хочется написать структуру данных следующего вида. То есть эта структура данных
должна хранить элементы. Я в нее хочу периодически добавлять элементы,
периодически удалятьank и-эт. Ну, и единственное там, наверное, запрос, который я хочу в ней
подсылать, это выяснять, содержится ли в ней элемент x или нет. В чём проблема?
Вот есть отсортированный массив, я в него периодически добавляю элементы,
удаляю элементы, и за логическое время узнаю, что в нём хранится.
Да, возникает естественный вопрос, как добавлять, как добавлять элементы в
массив. Ну скажем, понятное дело, что если вы добавляете максимальный элемент, то
вы его оставляете в конец и всё. Если вы добавляете минимальный элемент, то уже
проблемы. Вам нужно весь массив сдвинуть целиком на одну единицу вправую и так
далее. Если вы оставляете элементы в середину, то то же самое. Вам нужно
потенциально расширить массив, и потом все элементы, которые там правее,
их нужно каким-то образом сдвинуть. То есть вставка на самом деле занимает
линейное время. Существуют ли вы структуры данных, которые
позволяют осуществлять логарифмический поиск, но при этом вставку осуществляют
быстрее, чем за линию? Список. А как вы в списке собираетесь искать за
логарифмическое время? Дерево. Бинарное дерево поиска. В прошлом семестре вы
рассматривали бинарные деревья поиска. Ну и действительно, бинарные деревья
поиска, они тоже хранят элементы в некотором порядочном виде, а именно в виде
бинарного дерева. В качестве левого по дереву вступаются элементы меньше,
х в качестве правого по дереву все элементы больше х. Ну и в такой структуре
понятное дело, то есть понятное дело, как искать поиск, по сути, выполняется
точно так же, как в бинарном поиске, то есть в зависимости того,
чему равен х выведется либо в левое по дереву, либо вправо по дереву. Ну и плюс
из-за того, что это дерево, так скажем, оформлено в виде некоторого списка,
в виде списка узлов, которые легко удалять, которые легко добавлять, у вас
вставка удаления, в принципе, тоже может быть выполнена за логарифмическое время.
То есть все операции работают за логарифмическое время. Хорошо, но не кажется ли вам,
что тут есть, скажем так, некоторая неэффективность? И связана с тем, что,
ну смотрите, если я храню какие-то элементы х, то единственное, что я хочу узнать,
я напоминаю, единственное, что я хочу знать, это содержится элемент х в умножстве или нет?
Но помимо того, что я храню информацию о том, хранится у меня элемент в умножстве или нет,
я храню еще некоторые упорядоченные элементы. Ну то есть я знаю несколько больше, чем мне нужно,
ну казалось бы. И вот как раз и на поддержание вот этого факта того, что у меня дерево,
бинарное дерево поиска хранит, собственно, упорядоченность элементов, ну кажется,
что я за счет этого расплачиваюсь логарифмическостью поиска. Короче говоря,
цель хотелось бы вот эти операции выполнять за единицу, ну ровно как и вставку, удаление и поиск.
Короче, моя мечта? Построить такую структуру данных, которая бы все это делала за единицу.
И, ну кажется, что это можно сделать. Почему? Ну опять же, мотивацию я объяснил.
Почему здесь логарифм? Ну в логарифме здесь возникает потому, что я очень много сил,
трачу очень много сил и времени, трачу на то, чтобы хранить вот упорядоченность элементов между
собой. Более того, в бинарном дереве поиска мне что необходимо? Мне необходимо, чтобы элементы
были сравнимы друг с другом, то есть я мог сравнивать элементы на больше, меньше и так далее. Но вообще
говоря, для всех множество это справедливо. Ну скажем, не знаю, если я хочу хранить комплексные числа,
множество комплексных чисел, храню комплексные числа, добавляю, удаляю и спрашиваю верно лишь,
что комплексное число х лежит в этом множестве или нет. Как его оформить в бинарном дереве поиска?
Ну никак, там нет естественной операции меньше и больше. То есть бинарный дерево поиска здесь
не подходит. Ну вот, соответственно, выходом из этой ситуации является хэштаблиция. Идея такая.
Давайте для начала допустим, хотим хранить числа от нуля до m-1, где m мало. Ну что значит
мало? Это некоторая эфемерная понятия. В общем, считаем, что m достаточно маленькая, чтобы не
заботиться о том, что мы там много памяти потратим на хранение всех этих чисел, окей? Предложите
какой-нибудь алгоритм, который мог хранить числа из множества 0, 1 и так далее, m-1. Массив. Какой
массив? Какого размера? Что в нем хранится? Да, давайте заведем массив какого-нибудь b, размера m. Так,
окей. И что будем делать? Ну да, значит, как мы будем выполнять ставку? То есть как мы будем вставлять
элемент в наши множества? Ну очень просто. Будем говорить, что b от x равно true. Такой план. Да,
то есть если нам приходит число x, то мы просто говорим, что если нам пришла, допустим, двойка, то мы
говорим, что вот в этом месте мы ставим plus условно. Этот элемент в нашем множестве нет. В этом множестве
есть. Если мы хотим удалить элемент из множества x, то что мы делаем? b от x равно false. То есть если мы в
какой-то момент захотели удалить двойку, то мы просто здесь ударяем plus, ставим, допустим, минус. Да? Все
работает за единицу. Ну, поиск тоже понятно как. То есть просто смотрим, что хранится в ячейке b,
то есть plus или minus, и зависимо от этого говорим хранится наш элемент в множестве или нет. Согласны?
Окей. Ну в общем базовая идея понятна. Идем дальше. Хорошо, а что если теперь пусть k произвольное
множество ключей? То есть не обязательно числа, могут быть строки, могут быть комплексные числа,
вот все что угодно. В общем, k большое это просто некоторое произвольное множество ключей,
которое я хочу, для которого я хочу выполнять те же самые операции. Вставки в мое множество,
удаление из множества и узнавать хранится элемент или нет. Вот. Как мне в рамках той же идеологии
сделать, реализовать ту же самую идею? Предлагаю сделать следующую вещь. Для любого x,
принадлежащего k, я определю h от x. h от x, который принадлежит множеству 0 и так далее,
м-1. Так называемое hash значение. Ну и вообще говоря, функция, которая будет отображать множество
ключей во множество 0, 1 и так далее, м-1, будет называться hash функцией. Ну а m будем называть
размер hash таблицы. Вот. Ну то есть план такой. Допустим, у меня есть некоторая функция h,
которая умеет отображать множество ключей в конечное множество от 0 и так далее, м-1. Ну что я
тогда делаю? Я тогда по сути могу выполнить те же самые операции следующим образом. Вот insert,
от x у меня выглядит так, b от h от x равно плюс, и raise от x, b от h от x равно минус. Вот такая
идея. В чем проблема? Еще раз. Как по x получать что? А, ну в смысле, как построить функцию h?
Как построить обратную кашу? А зачем вам обратная кашу? Вот. Да, это, ну не знаю, вы хотели вытаскать то
или нет, но действительно. Смотрите, проблема в чем. Вообще говоря, я рассматриваю у k произвольное множество
ключей. И вообще говоря, множество k может быть достаточно большим. Например, ну короче говоря,
может возникнуть проблема с тем, что мощность k, она больше или даже много больше, чем m.
Ну скажем, m у меня 100, а k это множество всех строк. Вот открою тайну, но строк всего в мире больше
чем 100. Вот. Беда. То есть невозможно построить инъективное отображение из большего множества в
меньшее множество. Да? Вот. То есть возникает проблема или назовем беда. Беда заключается в следующем.
Существует x и y принадлежащие k, но при этом x не равны k. Такие что h от x равно h от y. То есть
проблема звучит следующим. А что если у меня нашлось два ключа, ну там два комплексных числа или две
строки. Такие что они попали в одну и ту же корзину. Да, я не сказал, но давайте вот эти вот.
Вот эти ячейки будем называть корзинами. Корзины или, от английского слова bucket. Вот. Проблема ясна?
Есть у меня два элемента. Попали в одну корзину, то что происходит? Приходит x и в соответствующие
ячейки ставят плюс. Приходит y. y не равен x, но их h значения совпадают. Я смотрю сюда и вижу плюс
и говорю, что y у меня в множестве. А это не так. Вот такая ситуация называется коллизией.
Коллизия. Вот. И собственно коллизия является, ну короче, коллизия является единственной
проблемой на пути к решению вот нашей задачи за от единицы. Понятно? То есть если мы разберемся,
что делать вот с такими ситуациями, то в принципе в рамках вот этого пайплайна у нас получится
построить структуру данных, которая позволяет за единицу вставлять элементы, удалять элементы и
делать поиск. Окей? Ну хорошо, мы осознали проблему. Давайте попробуем что-нибудь придумать,
чтобы ее решить. Наиболее популярным способом решения проблемы с коллизиями является метод
цепочек. Ну вот собственно его мы будем рассматривать. Следующий пункт. Метод цепочек.
Ну прежде чем я расскажу его, может кто-нибудь предложит решение. Может быть основываюсь на
названии или на своих догадках. Ну вот смотрите, повторюсь, в чем проблема. Возможно такая
ситуация, при которой x и y отображаются в одну и ту же ячейку. Мне хочется с этой проблемой как-то
бороться. Ну вот придумать какую-нибудь идею, чтобы я мог однозначно определять, что у меня
является x, что у меня является y. Ну возможно неэффективно. Давайте пока так. Что вы предложили,
чтобы разрешить эту проблему? Что? Многомерный массив и что в нем хранить? Да, да, отлично. Ну
собственно идея метод цепочек заключается в этом. Только мы храним не двумерный массив, а мы храним
все-таки массив списков. Что мы делаем? Если h от x равен h от y, ну понятное дело при x не равном y,
то в h от x, точнее в ячейке b от h от x храним список из x и y. Ну то есть в каждой ячейке мы
теперь храним не просто булевское значение true или false, есть там элемент или нет, а мы храним
список всех элементов, которые там содержатся. Понятен план? Если у меня вдвоем попали какие-то
элементы, то я тут храню x и потом храню, давайте отдельно. Здесь у меня находится список,
здесь хранится x, здесь хранится y, здесь может быть хранится какой-то z, ну и здесь может быть
тоже какой-то длинный список a, b, c. Ну некоторые списки пустые просто. Как теперь выглядит алгоритм
ставки? Что я делаю при поиске элементов? Сначала разберемся. Вот мне нужно найти элемент x, как я
действую. Я определяю номер ячейки, то есть я вычисляю хэш функцию и смотрю в какой ячейке
у меня лежит этот элемент, если лежит, конечно. И что я делаю дальше? Да, и дальше я просто-напросто
прохожусь по списку и смотрю, есть ли там x или нет. Если там x нет, то возвращаю false, если там x есть,
то true. Как выглядит ставка? Вставка выглядит точно так же, как поиск. Но только если я ничего не
нашел, то я дополнительно вот в этот список вставляю элемент. Как выглядит удаление? Опять же,
удаление выглядит так же, как и поиск. Осуществляя поиск, если я нашел элемент, то я его из списка
удаляю, если элемент не нашел, ну и ладно, удалять нечего. Все просто, да, пока? В чем проблема?
А зачем его ускорять? Он разве медленный? Он работает за линию. Ну, вообще говоря, да.
Давайте так. Будем анализировать время работы find от x. Ну и давайте замещение напишем, что
insert от x и erase от x. Время работы insert и время работы erase по большому счету совпадает с временем
работы find. Ну понятно, почему это так, да? Потому что чтобы вставить элемент, мне по сути надо
понять, был ли там ли этот элемент до этого, если его не было, то вставить. То есть по сути мне нужно
выполнить поиск. Для удаления элемента мне тоже, мне нужно его как минимум найти. Если я этот элемент
нашел, то я его за единицу из списка удаляю. Поэтому достаточно лишь оценить время работы find. И вот с
временем работы find от x все не очень хорошо. Время работы find от x занимает единицы плюс l от x,
где l от x это длина цепочки, с которой лежит x. Согласны? А чему у меня максимально может
быть равна длина цепочки? N. Да, то есть у меня может возникнуть довольно печальная ситуация.
Меня может так не повести, что я беру x, беру y, a, b, c, z. То есть вставляю их все в хэштаблицу и они
зараз такие попали все в одну ячейку. И просто выстроились в единый список. Ну то есть есть хэштаблица,
есть ячейка и в ней вот все элементы хранятся. И тогда сложность поиска в хэштаблице,
у меня ничем не лучше, чем поиск просто в обычном линейном списке, ну или просто в неотсортированном
оси. Согласны? То есть это не больше, чем N. То есть в худшем случае у меня действительно время
работы операции поиска N. Печально. Ну и действительно такую ситуацию очень легко устроить, но если,
например, взять какую-нибудь плохую хэш-функцию h от x тождественно равную нулю. Как вам такая хэш-
функция? h от x тождественно равную нулю, тождественно равной единице. h от x равная, не знаю, остатку
отделения на два, которая просто осуществляет распределение по нолику единичке. Поэтому в общем-то
основная проблема заключается в подбору хороших хэш-функций. Согласны? Теперь давайте определимся
тем, что такое хорошая хэш-функция. Ну вот как вы ее считаете? Что такое хорошая хэш-функция?
Из каких соображений ее лучше всего выбирать? Ну биекции у нас не получится.
Вот, да, я услышал слово ровномерно распределяет. То есть нам бы хотелось, чтобы наша хэш-функция,
ну, она не особо стремилась распределять объекты в одну корзину. То есть нам бы хотела чтобы
хэш функция, она как-то все элементы равномерно размазывала по всем корзинам. Да, если у нас
все элементы будут равномерно размазаны по всем корзинам, то каждая отдельная корзиночка,
она будет достаточно маленькая, да. И тогда в ней поиск будет осуществляться быстро. То есть хочется,
не понятно пока, что это значит чисто формально, да, в математичке, но хочется равномерно распределяющей
х-функции. Окей. Предложение. Можешь пока не записывать, просто предложение. Ну, смотрите,
вот, допустим, я знаю, что x это int, что я храню целые числа. Ну, давайте для простоты я возьму
беззнаковые целые числа. В общем, все числа принимают значение от нуля до там четырех миллиардов.
И я беру в качестве h от x вот такую х-функцию x процент m. То есть просто беру x, беру остаток
отделения на m и использую эту х-функцию. Вопрос. Удовлетворяет ли эта х-функция свойство
хорошести? Навек понятен. Казалось бы, эта х-функция хороша. Ну, то есть если я предполагаю,
что у меня x приходится случайно, например, то в принципе эта х-функция нормально размазывает
все числа равномерно по всем корзинам. То есть если x случайно, то и остаток отделения на m тоже
в принципе случайно некоторым образом. Но проблема в том, что пользователь непредсказуем. И более
того, никто вам не гарантировал, что числа будут расплены равномерно. А в нашем контесте уж точно,
никто вам это не гарантировать не будет. Поэтому, в принципе, существует для любой х-функции,
для любой х-функции существует некий плохой вход. Ну, в принципе, ну, там тест может быть
устроен таким образом, что вот он специально для этой х-функции будет подбирать плохие
значения, так чтобы они будут распределяться в одну корзину. Снова беда, пока не видно просвета.
Давайте откатимся немного назад в первый семестр. Вот там вы обсуждали быструю сортировку. Вот я
утверждаю, что у быстрой сортировки была такая же проблема. Какая там была проблема? Пивот, да,
смотрите, у нас был массив. Быстра сортировка устроена таким образом, что мы на каждом
этапе выбираем, ну, некоторый опорный элемент, который сбивает элементы там на правую часть и на
левую часть. И, в принципе, быстра сортировка не такая уж и быстрая на самом деле. Если мы
в качестве пивота всегда выбираем, допустим, первый элемент, то мы можем подстроить такой тест,
который бы все элементы назначал, ну, подавал на вход элементы от сортированной в обратном
порядке, да и тогда в качестве пивота у нас всегда бы выбирался, допустим, максимальный элемент.
Максимальный элемент всегда бы у нас делил массив в пропорции 1 ко всем остальным.
Но это соответственно квадратичная сложность.
Поэтому, вообще говоря, быстросортировка с детерминированным выборотом пивота
работает за квадратичное время, то есть долго.
Здесь то же самое, смотрите.
Если я фиксирую какую-то hash-функцию, то, в принципе,
очень просто подобрать вход, на который у меня все будет плохо.
Ну вот, например, такой.
Как мы решали эту проблему в случае быстросортировки?
Например, выбирая пивот случайно.
А что нам дает случайный выбор пивота?
Во-первых, случайный выбор пивота дает нам тот факт,
что подобрать тест довольно сложно.
Сложно подстроиться под случайность, если она действительно случайна.
Это первый момент.
А второе, что нам дает случайность?
Случайность нам дает возможность вероятностно оценить наш алгоритм.
Ну, помните, что быстросортировка работает за n log n в среднем.
Если мы пивот выбираем не случайно, можем ли ему утверждать,
что быстросортировка работает от n log n в среднем?
Нет, потому что у меня случайности в алгоритме нет.
Если я привношу в алгоритм случайность, то я уже могу анализировать средний случай.
Вот здесь то же самое.
Давайте ашу выбирать случайно.
Ну так, чтобы пользователь об этом не знал,
ну и так, чтобы у нас от запуска к запуску хэш-функция там как-то менялась.
Ну, чтобы пользователь не мог подстроиться под плохие данные.
Ну и, в принципе, чтобы плохой случай редко реализовывался.
А можно от m случайно выбирать?
С m...
У нас же m будет конечным числом.
Ну, m – это размер хэш-таблицы, вообще говоря.
Мы поговорим...
Давайте m пока не трогай, давайте считать, что m фиксировано.
Про то, как выбирать m, мы поговорим, это отдельная история.
Понятное дело, что m должно меняться.
Почему? Потому что если у вас m равен 1000,
а вы вставили миллион элементов,
то тут уж какую хэш-функцию не выбирай,
у вас, короче, маленькой цепочке не получится.
Поэтому m должен быть разумным.
Значит, как его настраивать?
Мы поговорим отдельно, отдельным пунктом.
Пока считаем, что m у нас фиксировано,
пока с такой проблемой разберемся.
Делаем хэш-функцию случайной.
Следующий пункт – простое равномерное хэширование.
Хэширование.
Хэширование.
Ну или буду сокращать до.
Что нам говорит простое равномерное хэширование?
Простое равномерное хэширование – это такой способ выбрать хэш-функцию...
Ну, короче, это просто случайный способ выбрать хэш-функцию.
Каким образом?
Ну, есть два определения, на самом деле, эквивалентных.
Давайте выпишем.
Первое – это h выбирается случайно
из множества всех возможных хэш-функций.
Такая запись понятна, да?
Ну, там MatLog и так далее.
B в степени a – это просто множество всех функций из a в b.
То есть здесь я убираю хэш-функцию из множества всех функций
из ключей в множество от 0 до f-1.
То есть я беру абсолютно произвольную функцию
и говорю, что вот эта хэш-функция и так далее.
Ну, если непонятно...
То есть тут, вообще говоря, это определение строгое,
но непонятно, как им пользоваться на практике.
То есть непонятно, как сформировать множество всевозможных функций,
как из него выбрать и так далее.
Поэтому существует эквалентное определение, которое,
так скажем, делает более понятным процесс выбора хэш-функций.
Давайте делать так.
Значит, если x – новый ключ,
то говорим, что h от x – это просто некоторое случайное число.
Ну, от 0 до m.
Вот нам приходит ключ.
Мы понимаем, что этот ключ мы никогда ранее не встречали.
То есть он никогда не был аргументом в файне, в инсерте, в эрейзе.
Ну и тогда мы просто геерим для него свое хэш-значение.
Вот приходит новый элемент, говорю, вот тебе хэш-значение.
Все, он берет номерок и уходит дальше.
А иначе, если x уже ранее используется,
то есть нам приходит новый ключ x,
и мы понимаем, что он уже ранее встречался, то что мы делаем?
Ну, просто используем старое значение.
Иначе используем старый h от x.
И уже вот эта функция получена с помощью простого равномерного хэширования.
Ну вот я утверждаю, что она в вполне себе в полном смысле
удовлетворяет вот этому требованию хорошести.
Понятно, почему так?
Потому что какой бы x у меня ни пришел,
я для него генерирую случайное хэш-значение.
А случайное хэш-значение, оно у меня равновероятно распределит в любую из ячеек.
Ну поэтому на таком бытовом смысле, наверное, понятно,
что если у меня хэш-функция, она случайно каждый элемент распределяет там по своей ячейке,
то в целом в среднем каждая ячейка у меня будет иметь небольшую глубину.
Пока все понятно интуитивно?
Ну давайте как-то вот это свойство попробуем формализовать и доказать.
Давайте попробуем доказать, что вот эта хэш-функция действительно в некотором смысле хорошая.
Прежде чем ее анализировать, мне нужно вести несколько понятий,
ну или просто напомнить несколько понятий из теории вероятности.
В общем, ничего сложного, а просто напомню какие-то школьные факты.
Никто не против?
Давайте так.
Ликбез по терверу.
Пункт номер ноль.
Пусть ω большое это пространство,
ну не пространство, а множество, давайте скажем множество.
Пространство слишком множество равновероятных исходов эксперимента.
Ну то есть у меня есть некоторый эксперимент,
и я знаю, что он может как-то завершиться каким-то результатом.
И вот допустим все эти результаты равновероятны.
Ну например, подбрасывание кубика.
В случае подбрасывания кубика, чему у меня равна ω?
Ноль, один и так далее.
Один, два и так далее, шесть.
То есть результат подбрасывания кубика, ну в принципе можно считать,
что это выпадение в какой-то грани, причем равновероятно.
Подбрасывание монетки тоже равновероятное выпадение орла или решки.
Окей?
Значит первое, да, нет, еще в рамках нулевого пункта остаемся.
Ну и событие называется множество а под множество ω.
Ну например, событие, что на кубике у меня выпало четное число.
Как описывается это событие?
Ну это событие просто описывается значениями два, четыре, шесть.
То есть каждое событие я описываю исходами, которые благоприятствуют этому исходу.
Ну, все понятно, да? Надеюсь.
Так, первый осмысленный пункт.
Никого не удивляет.
Вероятность события, это просто мощность а деленная на мощность вообще всех возможных исходов.
То есть количество благоприятных исходов деленное на общее количество исходов.
Второй.
Во втором пункте поговорим про среднее.
Значит, пусть х результат некоторого измерения.
Ну например, я бросил кубик и посмотрел какое там число.
Обозначил это число за х.
Среднее значение х я буду называть сумму по всевозможным х, х умноженной на вероятность того, что х равен х малым.
Ну, грубо говоря, я определил среднее значение.
Среднее значение некоторой величины.
Но чему равно среднее значение величины?
Я просто должен взять значение, которое оно принимает, с какой частотой оно его принимает, ну и дальше все это просуммировать.
Согласны?
Ну скажем, если у меня монетка, на монетке написано 0 или 1,
и она там единицу принимает в 75% случаев, а 0 в 25% случаев,
то тогда я говорю, что в среднем у меня монетка выдает 0,75.
Потому что в 75 случаях из 100 она выдает единицу, а в остальных 0.
75 деленное на 100, 0,75.
Тоже норм, да?
Так, давайте здесь.
Что еще мне понадобится?
Ну, такое свойство, я думаю, тоже никого не шокирует.
Средняя сумма то же самое, что сумма средних.
То есть неважно, я усредняю сумму, или сначала усредняю каждые слагами, а потом беру сумму.
То есть это называется линейность среднего, линейность в от ожидания.
Ну, почему это так?
Ну, тоже обосновать несложно.
Ну, вот это я посчитал средней суммой, согласны?
Я утверждаю, что это то же самое, что вот эта штука.
А это просто сумма средних.
Ну и все, наверное.
Я думаю, этого нам хватит.
Так, вопросов не появилось? Все нормально?
Ну окей, теперь давайте, собственно, покажем, что использование простого равномерного хэширования
позволяет нам добиться хорошей хэштаблицы.
Теорема.
А, сейчас, подождите, вернемся сюда.
Четвертый пункт понадобится тоже.
Пусть х и у независимы и принимают значения равновероятно.
То есть у нас все вероятности будут одинаковые.
И равновероятно принимают значения во множестве от 0 до m-1.
Тогда кто скажет, чему равна вероятность того, что эти величины совпадут?
То есть я провожу два независимых эксперимента, абсолютно друг от друга никак не зависит.
Ну, условно, подбрасываю один раз кубик, подбрасываю второй кубик.
С какой вероятностью у них значения совпадут?
Ну, 1m тогда.
Ну, тут, наверное, надо пояснить. Давайте коротко доказательства распишем.
Ну, просто по пункту 1, по простому определению вероятности.
Значит, х равно у. Что мне составляет множество всевозможных исходов?
Ну, согласны, что множество всевозможных исходов мне составляют всевозможные пары х и у ?
Да? Согласны? То есть я независимо, получаю значения з mich, независимо, поч seals значения у
Поэтому у меня тут получается все возможные значения и j, ну, понятно дело,
Жир лежит в промежутке от 0 до m-1, жир лежит в промежутке от 0 до m-1.
А что мне составляет множество благоприятных сходов?
Какие сходы из этих меня благоприятствуют?
Ну пары i, i.
Чему равно количество пар i, i?
m.
То есть это 0, 0, 1, 1, 2, 2 и так далее.
Чему равно количество пар i, j?
1 на m квадрат.
То есть я могу выбрать первое число m способами,
второе число m способами, m квадрат.
1 на m.
Все.
Окей.
Так, ну теперь возвращаемся к формулировке.
Значит при простом, просто при PRH.
А средняя длина цепочки...
Нет, давайте сразу Profite напишем.
Среднее время поиска find at x
составляет O от 1 плюс а.
Уже α это n на m.
n это количество элементов в хэш-таблице.
А m это, собственно как и раньше, размер хэш-таблицы.
Ну давайте с формулировкой разберемся, а потом на PRH пойдем.
Что мне говорит теорема?
Теорема говорит следующее, что если я использую просто равномерное хэширование,
то есть вот такой хэш, то есть случайно распределяю элементы,
случайно распределяю элементы по корзинам,
то в среднем у меня каждая корзина по сути,
то есть find зависит от длины корзины,
то по сути я говорю, что средняя длина корзины у меня равна n делить на m.
А n делить на m это как раз это самое равномерное размазывание всех элементов
по всем корзинам.
Понятно?
Ну хорошо, после PRH докажем.
Так, дополню, что вот это значение α еще называют load factor,
по всей степени загруженность хэштаблицы.
Это просто некоторая характеристика, насколько велики мои корзины,
насколько велики списки.
Ладно, перейдем к доказательству.
Как мы будем доказывать?
Понятное дело, что время поиска, оно тесно связано с длиной цепочки,
в которую попадает элемент х, в который потенциально может находиться х.
Давайте для начала определимся с тем, чему равна длина цепочки х.
Я утверждаю, что длина цепочки х может быть выражена следующим образом.
Давайте для начала здесь пропишем.
Пусть х, х1 и так далее, хн, элементы хэштаблицы.
То есть у меня есть хэштаблицы, в ней уже лежат элементы х1 и так далее, хн.
Заметьте, что х это не то же самое, что k.
За k мы обозначали множество всевозможных ключей.
То есть в принципе те значения, которые мы теоретически можем засунуть в хэштаблицу.
А х это те, которые фактически там уже лежат.
История такая вот.
Пусть х это элементы в хэштаблице, тогда как мы можем выразить длину цепочки,
в которую попадает элемент х?
На самом деле очень просто.
Длина цепочки выражается следующим образом.
Это сумма индикаторов того, что h от х...
Ну индикатор это просто функция, которая принимает значение 1 или 0.
В зависимости от того, верны ли там условия или нет.
Не знаю пропишем.
И от true равно единице, и от false равно 0.
Понятно ли, что длина цепочки действительно может быть выражена вот таким образом?
Что такое длина цепочки?
Что составляет вообще говоря цепочку?
Цепочка это те элементы, у которых одинаковый х.
Я беру h от х, то есть беру номер цепочки, в котором лежит х,
и проверяю, сколько элементов из х большого совпадает с моим хэшом.
И вот ровно эти элементы образуют нужную мне цепочку.
И количество совпадений это как раз есть длина цепочки, которая мне нужна.
Понятно?
Ладно.
Осталось всего лишь, так как мы хотим среднее время поиска find от х,
мы понимаем, что find от х напрямую зависит от l от x.
Мы писали, что время файнда есть θ от 1 плюс как раз таки l от x.
Чтобы посчитать среднее время работы файнда, мне достаточно посчитать среднюю длину цепочки.
Давайте это сделаем.
Средняя длина цепочки l от x.
Это есть средняя, вот такой вот сумма, i от равна 1 до n.
Ну и вот это переписываю.
h от x равно h от xi.
Так, как я могу переписать вот эту штуку?
Я могу воспользоваться свойством 3.
Ну, среднюю сумму я заменю на сумму средних.
Давайте я тут пользуюсь 8,3.
Сумма по i от 1 до n.
h от x равно...
Так.
А чему равно средние величины, которые принимают значение 0 или 1?
Ну, не 0,5.
Я не говорил, что вероятность этого события у меня 0,5.
Да.
Согласны ли вы, что вероятность события, которое принимает значение 0 либо 1?
То есть вероятность единицы...
Ой, че я хочу? Я хочу среднее.
Согласны ли вы, что среднее значение величины, которое принимает 0 или 1,
тупо совпадает с вероятностью события 1?
Ну, давайте я это пропишу.
Сумма i от единицы до n.
Вероятность того, что h от x совпадает с h от x i.
Вот.
А теперь вопрос.
Чему равна вероятность того, что h от x совпадает с h от x i?
При условии, что h от x у меня выбирается случайно,
и h от x i тоже выбирается случайно.
На отрезке от 0 до m-1.
Одна mt.
Ну, то есть утверждается, что вот так.
Ну, логика здесь понятна.
У меня h от x выбирается случайно.
Ну, вот, смотрим сюда.
x у меня выбирается случайно на отрезке от 0 до m-1.
h от x это y.
Тоже выбираются случайно на отрезке от 0 до m-1.
Поэтому вероятность х совпадения это 1 на m.
Тут есть небольшая несостыковка.
Ну, тонкая правда, но это почти правда.
Что здесь не так может быть?
Ну, смотрите, верно ли, что h от x и h от x i независимы?
Я бы даже так спросил.
В каком случае h от x и h от x i независимы?
Независят друг от друга.
Почти всегда, кроме одного случая,
когда я утверждаю, что вероятность того,
что h от 5 равно h от 5, есть 1 на m.
Как вы на это смотрите?
Ну, это бред.
То есть у меня h от x действительно независит от h от x i,
так как я каждое значение х-функции выбираю случайно.
Но это не выполняется в одном единственном случае,
когда у меня х и есть x i.
Поэтому тут мы немного исправим и напишем так.
Это сумма по i от 1 до n.
И напишем, ну как это пишется, вот так.
Что это единица, если х совпадает с x i.
Действительно, если х совпадает с x i,
то у меня вероятность того, что и х-ж значения совпадут, равна 1.
Ну, h-функция от одних и тех же элементов
должна возвращать одно и то же значение.
Но во всех остальных случаях она действительно равна 1 на m.
При х неравном x i.
Но это уже по свойству 4.
По этому 4.
Так.
Ну и что у меня получится, когда я все это просуммирую?
Ну, давайте так.
Сколько раз у меня может быть в этой сумме,
сколько раз у меня может быть выполнена эта первая строка?
Ну, только один раз.
Либо один, либо ноль раз.
В зависимости от того, лежит у меня х во множестве х большое или нет.
Согласны?
Поэтому я напишу так.
Что в случае, если х лежит во множестве х большое,
то это 1 плюс n-1 деленное на m.
В случае, если х малое, принадлежит х большому.
А во всех остальных случаях, к чему эта сумма равна?
Да, просто n на m.
1 деленное на m.
Ну, если х не принадлежит х.
Ну, так или иначе, то есть реализуется первый вариант
или второй вариант, неважно.
Это все меньше либо равно, чем 1 плюс n деленное на m.
Согласны?
Ну, кажется, что доказательственно это можно завершить.
Задайте какой-нибудь вопрос.
Ну, какой-нибудь не обязательно по доказательству.
Ладно, дела у меня хорошо, если что.
В общем, все ясно, да?
Я так полагаю.
Окей.
Ну и, собственно, отсюда следует,
ну, давайте сразу напишем.
Следствие среднее,
среднее,
среднее,
среднее,
среднее,
среднее,
среднее,
время работы
всех
операций
o большое от 1
плюс n деленное на m.
Все, то есть мы вроде как избавились
от линейного поиска
и теперь свели задачу
к поиску n деленное на m шагов.
Н деленное на m шагов в среднем.
Так.
Ну и теперь давайте вернемся
к вопросу
эффективности, а именно подбора m.
Ну, смотрите, снова есть проблема.
То есть, конечно, n делить на m это хорошо.
То есть то, что у нас хэш-функция размазывает все элементы равномерно,
это прям во, это прям замечательно.
Но проблема заключается, опять же,
вернемся к тому, что
если у меня число элементов n большое,
а хэш-таблица маленькая,
тысяча элементов,
тогда на поиск каждого элемента у меня уходит
в среднем тысяча шагов.
Что неприемлемо, да?
Ну и, собственно, вопрос.
Как подбирать m?
Может, кого-то готов ответ?
Ну так, вот с насколько?
В зависимости от х, который подается.
А как это?
А что значит х достаточно большой?
На самом деле, вот здесь,
в чем крутость этой теоремы,
ну и в чем крутость вот этого всего,
это в том, что я от ха теперь вообще никак не завишу.
То есть, неважно, х большой, маленький,
и так далее, у меня h от х
это случайная величина. То есть я
от анализа х перешел к анализу h от х.
Окей?
У меня х от х тут явно вряд ли что-то зависит.
Порядка n. Отлично.
А как мне это обеспечить?
Смотрите, я создаю х-таблицу.
У вас есть задача там, скажем.
Приходит произвольное количество элементов,
вам нужно быстро отвечать на запросы вида,
есть ли элементы, вы можете видеть их или нет.
Как вы определите, вам придет тысяча элементов
или миллион элементов?
Но идея правильная.
И снова вы с ней уже сталкивались
в первом семестре, даже в этом семестре.
Что нужно делать, если вы заранее не знаете
количество элементов?
Динамически расширять.
Динамически расширять. Отлично.
Идея такая.
Первый пункт.
Наблюдение, так скажем.
Если n деленное на m, скажем,
меньше либо равно единицы,
то сложность
в среднем какая?
Если я контролирую,
что n деленное на m
всегда меньше или равно единицы,
то средняя сложность поиска, вставки и так далее
всегда от единицы, согласны?
В среднем.
Отлично.
Как гарантировать...
Теперь вопрос как
гарантировать n деленное на m
меньше или равно единицы?
И ответ уже был
динамически расширять m.
Ровно как мы это делали в динамическом массиве.
Окей?
Ответ
динамически
увеличивать
m.
Ну, увеличивать...
Давайте напишем пару b и m.
Ну, m это характеристика b.
Понятно, что я по факту
увеличиваю количество корзин.
Что я увеличиваю?
Число корзин или сами корзины?
Идея понятна, да?
Грубо говоря,
что вы делаете? Вы стартуете с нуля корзин.
Вам приходит новый элемент,
вы его вставляете, но вставлять некуда.
И вы говорите, что у вас есть ровно одна корзина.
Приходит еще один элемент,
вы число корзин увеличиваете в два раза.
Ну и так далее.
Если в какой-то момент у вас число корзин
совпало с числом хранимых элементов,
то все, значит хэш-таблица уже заполнена.
При следующей вставке вы не можете
гарантировать вот такую штуку никак.
Поэтому вы просто берете и что делать?
Ну, увеличиваете число корзин в два раза, например.
Понятное дело, что нужно это делать
по мультипликативной схеме, так это
амортизированную единицу при увеличении.
Все, соответственно, мы готовы
выписать финальный алгоритм.
А в массиве у вас нет такой проблемы?
Тут ровно такая же проблема.
То есть у вас никогда
не получается так, что
число элементов, скажем так,
если вы выделите в два раза, то у вас число корзин
в два раза больше, чем число хранимых элементов.
Что миллион, что два миллиона,
не важно.
То есть если вы выделяете память ее недостаточно,
ну все, закончилась память.
Ошибка.
Это прям отличное замечание.
Да, мы к нему вернемся.
Грубо говоря, из вашего замечания следует,
что вот это вот все не имеет смысла и, короче,
вот так не получится. Но это спойлер.
Пока алгоритм,
который не работает.
Алгоритм.
Ну, давайте так.
Find и
Erase.
Понятно, да?
Ну, понятно, что происходит при Find и Erase.
Ну, при Find просто
ищем нужную корзину, ищем в этом списке.
При Erase тоже. Смотрим в нужную корзину,
ищем в этом списке нужный элемент
и удаляем его.
Давайте отдельно, давайте
insert распишем, как более интересный.
Insert.
Если...
Так.
Если n плюс 1,
деленное на m,
меньше либо равно единице,
то вставляем...
Да, ну и так.
Значит, давайте...
Если x принадлежит
hash таблице,
то сразу делаем return.
Ну, то есть в hash таблице мы храним
только уникальные значения, окей?
Все. Дальше я предполагаю, что
x у меня не содержится в hash таблице.
Значит, если при добавлении нового элемента
у меня получается, что
я остаюсь в рамках единицы,
то есть у меня load factor для степени загруженности
меньше либо равно единицы, то я просто вставляю элемент x,
вставляю x в
b от
h от x.
А
иначе
генерирую...
Давайте так.
Увеличиваю
размер b
до
2m, например.
Генерирую
h' от x.
Генерирую
hash функцию h',
которая
принимает значение от 0 до
2m-1.
И вставляю
x
в новую
hash таблицу.
Понятно?
Ну все. Если размер hash таблицы
не позволяет вставить новый элемент, я его вставляю.
Если размер hash таблицы не позволяет
обеспечить вот такое условие,
то я увеличиваю
число координат два раза. Естественно,
я должен
заново назначить hash функцию,
потому что старая hash функция мне генерирует значение
от 0 до m.
Новая должна генерирует значение от 0 до 2m.
Понятное дело, что я должен
перевставить элементы. Тут, наверное, не очевидно, но
плюс надо
перевставить
элементы
в новую hash таблицу.
Ну и даже вставить новый элемент.
Ну и работает это
от единицы в среднем
и
в амортизационном смысле.
Ну в среднем понятно, потому что
это зависит от случайности hash функции,
а амортизационный анализ
мне дает то, что
моя схема расширения
работает в амортизационном смысле за единицу.
Окей?
Не-не-не, их тоже надо вставлять,
потому что у вас hash функция могла измениться.
То есть у вас старая hash функция, она генерирует
значение от 0 до m, а новая будет
генерирует значение от 0 до 2m.
Их надо перевставить. Да, вот, собственно, вот это
замечание про это.
Что их надо заново перевставить.
То есть их
корзины могли поменяться.
Ну хорошо.
Так, вопросы по алгоритму есть?
Так, ну,
к сожалению, у этого алгоритма есть
несколько проблем.
Ну, начнем
с малых,
с малых из них,
а именно
ну сейчас будет пара технических деталей,
которые
могут
вызывать проблемы.
Ну, допустим,
у меня какая-то такая получилась,
ну, такая hash таблица.
Ну, смотрите, естественным свойством
любой структуры данных
является, ну, возможность пройтись
по всем ее элементам.
Ну, согласны, да? Если у вас есть массив,
то вы, наверное, хотите в какой-то момент
вывести все его элементы.
Скажем, если у вас есть бинарное дерево поиска,
наверное, тоже естественное желание
взять и вывести все его элементы.
Если у вас есть hash таблица,
то тоже, наверное, хочется взять и в какой-то момент
там вывести все его элементы.
Ну, почему нет, скажем.
В чем здесь может быть проблема?
Ну, давайте так,
сначала вернемся к...
Какая сложность вывода всех элементов из массива?
Вот у вас есть массив, нужно вывести все элементы.
Какая сложность этой операции?
ОАТН. У вас есть,
не знаю,
пирамиды или бинарное дерево поиска.
Какая сложность вывода всех элементов там?
Ну, тоже ОАТН. То есть это тоже можно сделать за ОАТН.
Ну, просто инордер обходом дерева
или поствор.
В общем, инордер обходом дерева, например.
А вот здесь.
Я хочу пройтись по всем элементам.
По этим элементам.
По порядку.
Какая сложность здесь?
Почему квадрат?
ОАТН.
О.
А как вы это себе представляете?
Ну, давайте попробуем это все проделать.
Понятно, что я иду в первую картину,
смотрю первый элемент, вывожу его,
перехожу в следующий элемент, вывожу его,
перехожу сюда, вывожу его.
Список закончился, перехожу в следующий картине.
Эта корзина то не пустая.
Ну, хорошо, пойду дальше,
Перехожу в следующий картине, она пустая.
Перехожу в эту корзине, они пустые, все так далее.
на что не наталкивает? n плюс m, да, то есть помимо того, что я прохожусь по всем
элементам, я еще должен пройтись потенциально по всем пустым корзинам.
Вот чтобы найти первую незаполненную корзину, мне тоже нужно потратить
m времени. Вообще говоря, это не очень приятно, потому что m может быть больше,
чем n, по крайней мере, мы так делаем, что с m хотя бы в два раза больше, а если мы
еще делаем и raisin, то есть скажем, у нас хэштаблица увеличилась до тысячи
элементов, потом в какой-то момент мы все элементы поудаляли, у нас осталось
десять элементов, а хэштаблица осталась размером тысячи элементов, ну в общем
неприятно. n плюс m. Хотелось бы это тоже улучшить до линейного
прохода, и классически это делается так. На самом деле, на самом деле, в нормальной
хэштаблице, то есть, хорошо, вот эта реализация хэштаблицы, она норм, вот, и сразу
скажу, что у вас там в третьем задании будет задача реализовать хэштаблицу, и в
принципе это нормально, то есть в качестве базового решения это зайдет, то есть балл вы
свой получите. Вот у нас будут дополнительные пункты, где надо будет реализовать
хэштаблицу по-человечески, а вот по-человечески это вот как. Вообще говоря,
вы не храните несколько разных списков, вот, кстати, хранить несколько разных
списков тоже в некотором смысле накладно, потому что вы должны, ну, несколько списков,
несколько различных переменных и так далее. Идея заключается в следующем. Я буду хранить
я буду хранить один общий список элементов, один общий список, ну, пусть так. Я храню один
общий список элементов, но причем не просто так вот, не просто в произвольном порядке,
а делаю следующую вещь. Элементы, которые лежат в одной корзине, обязательно должны
идти подряд. Вот это свойство. Скажем, вот так, и вот так. Ну, и скажем, у меня заполнена вот эта
корзина, это оранжевая, значит, вот эта зеленая корзина, красная корзина. Вот, то есть у меня есть
корзина, у меня есть общий список элементов. Вопрос, что я тогда должен хранить в самих корзинах?
Да, смотрите, мне достаточно хранить всего лишь указатель. Указатель на начало списка элементов.
То есть я понимаю, что вот элементы из зеленой корзины начинаются здесь, поэтому я храню
указатель сюда. Элементы из красной корзины начинаются здесь, храню указатель сюда. Оранжевая
корзина здесь. Отлично. Вопрос следующий. Как мне понять, допустим, я хочу пройтись по всем
элементам корзины. Как мне понять, что моя корзина закончилась? Что? А как я проверю,
совпал ли указатель? Как я проверю, что вот на этот элемент указывает кто-то или нет? Быстро. Парень
знает толпы в возвращениях, да, но нет. Что? Да, отлично. Чем характеризуются элементы одной корзины?
У них одинаковый хэш. Тут h1, ну хэш значения. Тут h3, тоже 2. То есть чтобы понять, вышел я за пределы
корзины или нет, мне достаточно посмотреть, какой хэш у этого чудака. Ага. Если у него хэш не совпался
с хэшом моей корзины, то все, это значит, что я перешел в другую корзину и все. На этом я
должен остановиться. Понятно? То есть достаточно сравнить хэш значения и все. Потому что каждая
корзина характеризуется своим хэш значением. В общем, это уже больше похоже на правду. Ну,
есть еще один момент. Еще один момент. Ну, он такой более тонкий, который заключается в следующем.
Ну, смотрите, мне вопрос. Какой список я тут должен хранить? Двусвязный или односвязный? Двусвязный.
Почему двусвязный? Да, ответ Cafe Jesus. Да, отлично. То есть кажется, что я должен хранить двусвязный список.
Почему? Потому что я хочу удалить, скажем, вот мне сказали удалить вот этот элемент. Если
я хочу удалить этот элемент, мне нужно, что делать? Я его удаляю и беру ссылку на предыдущий элемент и
провязываю его со следующим. То есть мне нужно хранить как ссылку на предыдущий а так и на следующий.
Вопрос. Можно ли как-то избавиться от этого? Ну потому что кажется, что на каждый элемент...
то есть смотрите, что у вас хранится в каждой ячейке.
В каждой ячейке у вас хранится значение value,
в каждой ячейке у вас хранится указатель на next,
хранится указатель на prev,
и еще, возможно, хранится hash.
То есть на самом деле hash можно хранить непосредственно в самом элементе,
а можно его вычитать на ходу,
но это в зависимости от того, работает ли у вас hash быстро или нет.
В стандартной библиотеке так и реализовано,
что если там, скажем, hash быстрый, то есть hash отчисел,
то он не хранится.
Если у вас hash от строк, а hash от строк работает долго,
он работает за длину строки,
вот тогда hash просто непосредственно хранится рядом с элементом.
То есть у вас получается следующая вещь,
у вас хранится value и плюс куча дополнительной информации.
Ну а память хочется экономить.
Можно ли как-то это все реализовать на односвязном списке?
А как это нам поможет?
Ну, допустим, я хочу удалить вот этот элемент.
У меня есть указатель на этот элемент, я хочу его удалить.
Да, нужно понять, какой у меня предыдущий элемент.
Нет, нет, нет, это прям связный список.
Ну, короче, идея стоит в том, что нужно хранить указатель
не на самый элемент, а на элемент перед ним.
То есть вот так, вот так, и вот так.
Если я храню указатель на элемент перед ним, то у меня все хорошо.
Ну скажем, я хочу удалить вот этот элемент.
Если я хочу удалить этот элемент, то я должен хранить итератор,
указатель не на него, а вот на этот элемент.
Если я храню указатель на элемент перед ним, то все хорошо.
Я удаляю этот элемент, и дальше просто провязываю ссылку вот сюда.
Все понятно или вопрос какой-то есть?
Ну, короче, чтобы у меня появилась возможность в односвязанном списке
удалить эти элементы, мне нужно на самом деле при удалении
хранить не сам указатель на элемент нужный, а на указатель перед ним.
Если хранить указатель на переднем, то все нормально.
Ну и собственно, по той же причине вы должны хранить указатель
здесь не на самый элемент, а на указатель перед началом списка.
Почему? Потому что если вы захотите удалить самый первый элемент корзины,
ну вот здесь, представьте мне, что из этой корзины соuinely
если вы хотите удалить самый первый элемент,
тогда вам нужно хранить указатель, который указывает на элемент перед ним.
В этом случае вы спокойно можете удалить первый элемент корзины и сделать вот так.
Понятно?
Но это уже на самом деле такие детали.
Кстати, в стандартном классе forward-list об этом мы еще будем говорить.
В связи с этой проблемой есть методы insertAfter.
В обычном списке есть методы просто insert и erase,
а в forward-list там другие методы.
Там методы insertAfter и eraseAfter.
Потому что мы можем вставлять только после элемента
и удалять элемент, который стоит после него.
Ну ладно, с этим закончим.
И наконец, финальная проблема,
которая уже была освещена,
состоит в том, что это все невозможно.
Это все не имеет смысла.
Давайте вернемся к определению простого равномерного х-ширования.
Что говорит простой равномерный х-ширование?
Давайте одно из них, что у меня h генерируется случайно
из множества от 0 до m-1 степени k.
Ну либо я генерирую так.
h от x равно random от m.
Либо беру старое значение h от x, если x у меня уже раньше встречался.
И я утверждаю, что простого равномерного х-ширования в жизни не существует.
Вот его реализовать у вас не получится.
Вот такой х-ш функции в реальности, в реальных приложениях быть не может.
Тут есть два объяснения.
Первая теоретика информационная, которая основана на первом определении.
Ну, смотрите.
Вот, допустим, у вас есть некоторое множество.
Множество размера n.
Сколько bit вам нужно, чтобы хранить в памяти компьютера
один элемент этого множества?
Ну, хорошо. У вас есть множество размера 10.
Возможно ли это множество представить...
Возможно ли каждый элемент этого множества представить одним bit-ом?
Нет, потому что 1 bit – это 0 или 1.
Возможно ли элементы 10-элементного множества представить двумя bit-ами?
Нет, двумя bit-ами можно закодировать только 4 числа.
То есть множество размера n можно закодировать только логарифмом доичным по n bit-ов.
Да?
То есть это...
Давайте, словами скажу, что это количество bit,
которое нужно потратить, чтобы в памяти компьютера
представить элемент n-элементного множества.
Какой размер этого множества?
Огромный, правильный ответ.
В степени k.
И беру мощность этого множества.
Ну, мощность этого множества вычисляется просто как мощность...
Ну, мощность вот этого множества, то есть m в степени мощности вот этого множества.
Ну, очень удобная аннотация, вот так.
Если возьму логарифм от этой штуки,
логарифм вот m в степени k,
то это будет мощность k, умноженная на лог m.
Ну, лог m, ладно, забили.
Меня интересует больше вот эта вот штука.
Bit.
Чему равна мощность k в стандартном случае?
Вот, допустим, мы хотим хэшировать n-ты.
Сколько всего n-тов?
4 миллиарда.
То есть, чтобы сохранить хэш-функцию,
которая хэширует n-ты,
нам нужно 4 миллиарда бит, ну, как минимум 4 миллиарда бит.
4 миллиарда бит это что-то типа полгигабайта.
Готовы ли вы на каждую хэш-функцию тратить полгигабайта?
Спорный вопрос.
Хорошо, k это не числа.
k это строки.
Строк еще больше.
Готовы ли вы тратить еще больше, чем полгигабайта?
Вряд ли.
Ну, в общем, хранить хэш-функции очень дорого.
В общем, представить в памяти компьютера не представляется возможным.
Это первый довод.
Вы можете сказать так, ну, смотрите,
а зачем нам хранить хэш-функции целиком?
Ну, кой нам смысл хранить все возможные хэш-взначения для всех элементов?
Мы же можем, как мы тут предполагали,
можем для каждого элемента просто динамически генерировать хэш-взначения
и хранить только их.
Не видите ли вы тут какого-то противоречия, парадокса?
Отлично. Как понять, встречался х или нет?
Ну, смотрите, у меня тут выглядит как.
Если х ранее у меня никогда не встречался,
я генеру рандомное число.
Если х ранее когда-то встречался,
то я использую ранее сгенерированное значение.
То есть мне нужно как-то хранить, как-то уметь хранить
ранее встречавшееся значение
и тот хэш, который я им сгенерировал.
Но кажется, что эта задача состоит
ровно в том, чтобы построить хэш-таблицу.
А чтобы построить хэш-таблицу,
мне нужна хэш-функция.
И, ну, понятно.
Проблема ясна?
Вот, поэтому
ни вот так, ни вот так
ничего не получится.
Нет.
Все нормально.
И победим эту проблему.
Видимо, не сегодня, но
я хотя бы
дам некоторую надежду.
Простого равномерного хэширования
не существует.
Но на простых равномерных
хэшах свет клином не сошелся.
Есть
другой хороший класс
хэш-функций.
Ну, это уже тема второй лекции,
ну давайте начнем ее, чтобы
в следующий раз
поменьше писать было.
Значит, универсальное
универсальное
семейство
хэш-функций.
Мотивация, идея.
Ну давайте
сегодня только идею, наверное, обсудим.
Смотрите.
Вот в чем проблема простого равномерного хэширования?
Проблема простого равномерного хэширования,
что я выбираю хэш-функцию
из вообще
из класса
всевозможных хэш-функций.
Этот класс хэш-функций
огромный.
То есть сохранить его в памяти компьютера
не представляется возможным.
Как-то представить компактным образом
тоже не получается.
Но что можно сделать?
Можно взять не все пространство
хэш-функций,
а лишь некоторые его подможества.
Давайте обозначу h от альфы.
Вот h от альфы это просто некоторое подможество
хэш-функций.
Я буду рассматривать не все
хэш-функции,
а только какой-то конечный поднабор.
Словно, есть пространство
всевозможных функций из r в r.
Какая мощность
этого множества?
Что?
Ладно, очень большая.
Я понял.
Короче, более чем консинвальная, да?
Хорошо.
А что если я вам скажу, что я рассматриваю
не функции из r в r, а только функции
f от x равно a от x.
a умножить на x, точнее.
Чему равна мощность
вот этого множества?
Мощность у всех функций, которые
имеют вид a умножить на x.
r.
Да?
То есть мощность этого множества совпадает
с мощностью r. Уже полегче.
А что если я скажу, что a принимает
значения,
ну, только натуральные значения?
Тогда множество всех этих функций это
просто счетное.
Да?
То есть мало того, что их счетное, так еще я могу
вот этому множеству компактным образом представить.
Чтобы сохранить одну такую функцию,
мне достаточно хранить всего лишь одно число.
Одно число a. То есть одно число a мне полностью
описывает всю мою функцию.
Ага.
То есть чего я хочу?
Я хочу построить h от альфа,
которое описывается
скажем так, небольшим
небольшим числом
параметров
и удовлетворяет
свойство.
Давайте свойство выпишем и закончим.
Я хочу, чтобы это семейство,
вот это маленькое подношество
всех хэш-функций,
обладало таким же свойством,
как и простое равномерное хширение.
А простое равномерное хширение, ну, какое
свойство мне от него нужно? На самом деле от простое
равномерное хширение мне нужно было только
вот это свойство.
Что вероятность совпадения элементов равна 1 на m.
И вот ровно это я и потребую
от вот этого небольшого множества функций.
Свойство
для любых x и y,
таких, что x не равен y,
вероятность того, что
h от x
совпадает с h от y
должно быть меньше вновь, чем 1 на m.
Вот если мне удастся найти
такое семейство хэш-функций,
которое я могу легко описать, ну, то есть вот
одним или двумя параметрами,
и плюс мне будет удовлетворяться
вот это свойство, что какие бы я два значения
не взял, у них вероятность совпадения будет меньше
вновь, чем 1 на m, то я победил.
Тогда я вот эту хэш-функцию могу подставить
вот сюда, и все будет то же самое.
Согласны?
Ну вот пример,
как может выглядеть вот эта хэш-функция,
мы приведем в следующий раз. Пока все.
