Всем доброго дня! Мы теперь встречаемся в немножечко другом формате, именно в
дистанционном. Я не знаю, куда отрендерится видео со мной, но если что, потом будем редактировать.
Сразу говорю, первая такая организационная вещь — берегите себя, потому что ситуация очень
плачевная и по официальной статистике как минимум тысяч человек с нашей страны пошло в иной мир.
Ситуация очень страшная, поэтому, пожалуйста, соблюдайте дистанцию, носите маски,
ну и старайтесь поменьше контактировать друг с другом, берегите себя, особенно если вы,
допустим, живете с родителями, так тем более, потому что они сейчас более уязвимая группа
населения. Вот такой небольшой спойлер в начале, авто в начале, который очень важно рассказать,
а сейчас мы с вами поговорим именно про лекцию. Значит, в прошлый раз мы с вами не закончили
говорить про лему о разрастании, точнее ее сформулировали, но сегодня нам еще она
понадобится. Давайте вспомним, что мы учились делать в прошлый раз.
Что мы на прошлой лекции научились с вами делать?
Нормальную форму Фомского находить и поэтому парсить.
Да, мы научились строить нормальную форму Фомского, показали почему это так и научились, построили
первый парсер, построили алгоритм Кока Янгера Кассами, который работает, напоминаю, за симптотику
о большое от длины слова в кубе на количество правил. Это достаточно большая симптотика,
но что поделать с ней? Пока что мы ничего с ней не можем сделать, и сегодня мы применим нормальную
форму Хомского для того, чтобы доказать один из алгоритмов, точнее одну из теорем. Давайте вспомним,
что такое нормальная форма Хомского. Грамматика у нас находится в форме Хомского, КС-грамматика,
контекст свободный. Если у нее все правила имеют такой и только такой вид. Первое, из не терминала
мы можем вывести терминал, то есть напоминаю, что большими буквами у нас обозначаются не
терминальные символы, то есть символы, порождающие, не то что порождающие, а специальные символы,
из которых могут выводиться какие-то правила. А терминальными символами мы называем символы
алфавит. Да, если есть какие-то вопросы, по ходу дела задавайте, будем разбираться. Наша цель не
прогнать какой-то материал достаточно быстрой скоростью, а именно посмотреть какие-то вещи,
разобрать более детально. Второе правило, которое у нас имеет вид, это правило из А следует БС,
где БС у нас являются не терминалами, но при этом мы не позволяем циклы в стартовый не терминал,
то есть у нас Б не С и С не С. Кстати, мышку видно? Вложу. Хорошо. И третье правило, если у нас
внезапно из грамматики выводится пустое слово, то мы должны добавить правило из стартового не
терминала, выводится пустое слово. И теперь давайте попробуем при помощи этого доказать
следующую лему. Значит, это лемма о разрастании. Опять же, мы ее называем Pumping Lema. В чем ее суть
состоит? Опять же, пусть у нас есть некоторый контекстно-свободный язык, тогда существует
такое П, такое, что для любого слова, длина которого достаточно большая, существует разбиение на Н слов,
Н в данном случае пять-пять, и смотрите, что происходит. У нас X, Y, Z. Наш слово представляется
в виде X, Y, V, Z, но при этом смотрите, что важно, что длина УВ больше чем ноль, то есть у нас,
давайте я даже буду подчеркивать, то есть у нас на вот эти вот слова есть ограничение, что это
слово не пустое. И есть ограничение на УВ, что длина УВ не больше чем П. То есть в отличие от
леммы разрастание для автоматных языков, у нас разрастание, у нас есть ограничение на начало,
здесь идет ограничение на середину. Вот. И благодаря этому мы немножечко с вами, у нас
усложняется работа, потому что если мы раньше могли придумать слово с каким-то хорошим началом,
то здесь надо обычно разбирать намного больше случаев. Если мы хотим доказать, что у нас какой-то
язык не является контекст свободным, а именно в этой концепции мы с вами будем применять ее.
И тогда смотрите, что у нас выполняется. Для любого камы, по сути, можем разрастать розовую часть. То есть
х, давайте я даже буду писать у вкатой. Так, какое там? У вкатой, да? У вкатой. Дальше у, в вкатой,
z будет лежать в нашем языке. Вот такая формулировка леммы. Разрастается второе и четвертое
слово. Пятое остается неизменным. Первое, третье тоже является, остается неизменным. Теперь давайте
попробуем эту историю доказать. Как эту историю доказывать? Ну, давайте возьмем грамматику и
рассмотрим ее в нормальной форме хомского. Тогда смотрите, что мы с вами можем заметить. Что,
если мы с вами попытаемся построить дерево вывода грамматики, то на самом деле у нас эта
история увеличивается не более чем в два раза. То есть, если мы посмотрим на первый уровень,
нулевой уровень, это s. Дальше посмотрим на первый уровень дерева грамматики. Допустим,
из него выводится какое-то a или b. Это первый уровень. То есть, зафиксируем уровни. Там из этого
какой-то cd, а из этого ef. Из-за того, что у нас грамматика в нормальной форме хомского, то каждый
уровень у нас разрастается не более чем вдвое. Но в нем могло уйти ответвление в чисто пустое
слово. То есть, в итоге у нас получается здесь количество символов не более чем 2 в нулевой,
здесь у нас количество символов не более чем 2 в первой, здесь не более чем 2 в второй. И тогда,
что мы можем с вами сказать из этого? Мы можем тогда сказать, что на каком-то уровне,
там, если обозначим, там у нас есть какое-то слово w, то у нас длина этого слова. Сейчас,
давайте подумаем, чем она у нас с вами ограничена.
В общем, мы можем получить оценку от высоты уровня. Теперь смотрите, вот эта идея понятна,
что каждый уровень дерева вывода увеличивает длину слова не более чем вдвое. То есть,
если у нас максимальный уровень второй, и после него вывод идет слово, то в слове не более чем
4 символа. Вот. А что это нам позволяет делать? Давайте рассмотрим. Слово, точнее, обозначим
p, равное 2 в степени количества не терминалов нашей грамматики, которые в нормальной форме
Хомского. Так, давайте это отделю. Тогда, если у нас слово w будет больше или равно, чем p,
2 в степени n. Тогда скажите мне, пожалуйста, какая минимальная высота дерева?
Можем ли мы ее оценить каким-нибудь образом?
Смотрите, существует ветка уровня больше равно, чем количество не терминалов. Потому что,
если у нас длина слова достаточно большая, то как минимум уровень такой мы должны задействовать.
А это значит, следовательно, давайте рассмотрим последовательность, рассмотрим ветку максимального
уровня, максимальной глубины. И тогда в ней количество не терминалов на 1 больше. Потому что у
нас с вами есть еще нулевой уровень, обращу внимание. Нулевой уровень плюс хотя бы n, это значит,
что количество не терминалов хотя бы n плюс 1. Тогда давайте поймем, что мы можем сказать с вами
про эту ветку и про то, какие не терминалы у нас там с вами встречаются. Есть как минимум два не
терминала, которые повторяются хотя бы два раза.
Вот, давайте рассмотрим эту ветку. И важное замечание среди
таких А выберем такой, который находится глубже всех, то есть он ниже всех.
И тогда смотрите, что у нас с вами получается. Я нарисую с вами дерево вывода, ну я его пока
продублирую. Вот, я сейчас нарисую на картинке. Смотрите, что у нас получается. У нас из С нашли
это первую встречу этого А, то есть предпоследнюю встречу этого А. Посмотрим в ту самую ветку.
Дальше у нас с вами идет некоторое ХЗ, ну потому что слева и справа от него мог
выводиться какой-то контекст. Дальше ниже от него тоже мог выводиться какой-то контекст АВ.
И дальше у нас из А могло вывести на терминал У. Тогда у нас что получается? У нас получается
как раз цепочка выводов из С, ХАЗ, ХУАВЗ, ХУЙВЗ. И смотрите, внимание, у нас появляется вот
такая вот вещь. Как раз из этого у нас будет с вами разрастание. Из того, что из А выводится УАВ.
А теперь давайте поймем, что нам надо доказать, для того чтобы доказать, что лемма работает.
Да, первый факт, который нам нужно показать, что длина УВ не больше, чем П. Которая у нас,
напоминаю свою очередь, равен 2 в степени N. Давайте понимать, почему это так. Ну на самом деле,
если внимательно посмотреть на картинку, если вдруг длина УВ больше, чем П, а это равно 2 в степени N,
тогда для дерева со стартом ВА мы можем проделать ту же самую операцию. Вот в это. То есть тыкаем
в дерево, которое находится здесь, проделываем те же самые операции, но при этом не считаем
терминал А. И тогда в нем количество узлов, как минимум, 2 в степени N. Даже больше,
чем 2 в степени N. Следовательно, уровень есть, давайте я буду подчеркивать, то есть со стартом ВТА,
есть уровень даже больше, чем N. То есть не меньше, а больше, чем модуль N. Это значит,
что мы даже ниже спустясь можем найти пару В, и из нее выводится В. В вот этом вот под дерево.
Вот давайте я вот так выделю. То есть в этом под дереве есть пара В,
которая и находится ниже, чем этот не терминал А. Вопрос, к какому противоречию мы с вами
приходим здесь? То, что А не самое глубокое. Да, вывод А не самое глубокое. Ну и это противоречие.
Ага, а второй факт, который нам надо с вами показать, какой здесь. То есть в первую штуку мы проверили
с вами. УВ не пусто. Да, нам нужно проверить, что длина УВ больше нуля. Смотрите, из какого это
факта следует. У нас мы знаем, что для любого, давайте напишем так, для любого не терминала,
давайте С его обозначим. С не терминал, у нас С не эпсилон порождающий. Это важно. То есть для этого
мы с вами убивали эти штуки. А это значит, что как только у нас, давайте напишем так, рассмотрим,
там я не знаю, символ В, давайте я его напишу где-нибудь, давайте не В, пусть будет Д. Вот этот
вот Д, вот я его вот тут вот сюда воткну, из которого за один раз мы получили А. То есть за один
шаг мы получаем А. Но он может быть слева, может быть справа. Ну давайте предположим, не ограничивая
общности, что у нас он появился слева. Причем он мог появиться только по такому правилу. И тогда у нас,
что мы можем с вами сказать? Мы можем с вами сказать, что из этого АК вывелся какое-то, какое-то
слово, я не знаю, Р. Но тогда Р у нас будет являться суффиксом У. Суффикс У. И при этом заметим,
что длина Р у нас обязательно больше нуля. Следовательно, у нас длина УВ будет больше
равна чем длина У, это в свою очередь больше равна чем длина Р, а это больше чем ноль. Вот. Если,
опять же, у нас Д порождало не таким образом, а образом АК, то история точно такая же, просто мы
рассматриваем это для слова В. Вот. Ну и дальше мы видим, что вот это вот правило, напоследок, что вот
это правило, мы можем поставлять К раз, и у нас получается х у вкаты, y вкаты, z. А может быть равно 0? Да,
конечно же. Как и в прошлые разы, К может быть равно 0. Спасибо за замечание, оно очень важное. Вот.
Можно еще вопрос в втором пункте? Мы там какую А используем? А с двумя подчеркиваниями? Нет,
нет, давайте я ее обведу, пусть она у нас А розовая будет. Вот эту А розовую. Вот я тут D
как раз написал, что D вот вводится, она здесь где-то. Да, понятно. Хорошо. Вот такое доказательство,
оно более муторно, чем время разрастания для автоматных языков, но вроде сложность относительно
его похожая. Давайте для того, чтобы понять, как эту штуку применять, если есть вопросы по
доказательству задавайте, в принципе мы доказательство закончили этого факта. Чтобы
понять, как это применить, давайте напишем отрицание лемма разрастании. Для этого что мы делаем? Мы
говорим, что для любого P существует такое слово из L, такое, что его длина больше равно P, что для
любых X, U, Y, V, Z из сигма со звездой. Существует для любого разложения слово в таком виде.
U, V больше нуля, Y, U, V не больше, чем P. Любого K, принадлежащего натуральному. X, U в катой,
Y, V в катой, Z не лежит в языке L. То есть нам нужно найти такое слово, такое разбиение, чтобы
это не работало. Вот. Так, это доказательство. Давайте пример разберем. Пример такой. Слово язык
A-venti, B-venti, C-venti. Опять же, смотрите, нам для любого P рассмотрим фиксированное P. Давайте
придумаем слово, длина которого хотя бы P. Я сейчас попробую окно закрыть, потому что кто-то решил
стучать. О, там по дворе забор прибивают. Какое слово рассмотрим? Длина которого хотя бы P.
Какое слово рассмотрим? Мы хотим взять слово вида A-venti, B-venti, C-venti так, чтобы у него длина была хотя бы P.
Ну да. A-venti, B-venti, C-venti. Вот. Тогда смотрите. Давайте попробуем для него доказать отрицание.
Что у нас получается? У нас получается, что слово W представляет в виде X, U, Y, V, Z. При этом что мы знаем?
Что длина U-V больше нуля, а длина U-Y-V не больше, чем P. Да? И тут самое важное замечание, которое можно сделать.
Заметим, что в Y-U-V не может быть трех разных букв из A-B-C. Вот не может быть, потому что если бы
они были бы, то включалось бы A, включалось бы C первое и расстояние между ними уже больше, чем P, а длина Y-U-V не больше, чем P. Вот.
И теперь это. Теперь смотрите, что у нас с вами происходит. Тогда, не умоляя общности,
неважно каких, пусть у нас количество букв в C равно нулю. Там неважно какое рассматривать, но мы знаем,
что не может быть трех разных букв. Длина Y-V-A-C меньше нуля, а количество букв там, не зная B,
больше нуля. Там в зависимости от ситуации может быть разные варианты. Но тогда если мы рассмотрим
кару на двойке и посчитаем, сколько у нас с вами, чему у нас равняется количество букв B в этой штуке,
мы получим, что это количество. Ой, сейчас, секунду. Y-V-Z количество букв B плюс U-V количество букв B. Так.
Но тут, смотрите, еще важно замечание, что на самом деле мы можем сказать то же самое и для
U-V. Вот. Поэтому давайте я тут немножечко пошаманю. Вот так. Тогда смотрите, что у нас получается.
Чему эта штука равна? Эта штука у нас равна P, потому что у нас B в этой P плюс количество букв U-V-B. А при
этом количество букв C, U-quadrat Y-V-quadrat C, будет равняться P плюс количество букв C. Это нулю,
а это больше чем. Так. Получается 0 плюс P равняется P, а это будет больше чем P. В итоге количество
букв B у нас оказалось больше чем количество букв C. И это нас приводит к противоречию. Вот.
Вот такой факт. Вот давайте теперь немножечко поговорим, если понятно,
пример не контекст свободного языка. То есть лемма о разрастании, тут более сложные немножечко
рассуждения идут, чем лемма о разрастании для автоматных языков. И теперь, смотрите, есть два
важных факта, которые мы должны обсудить. Это следствие леммы о разрастании, а именно следствие о
том, что это язык не является контекстно свободным. Следствие номер раз. Первый пример. Это следствие,
то что контекстные свободные языки не заднуты относительно пересечения. Да, давайте приведем
пример, который говорят нам про это. То есть первый пример. Это пусть у нас язык A вентой,
B вентой, C вентой, а язык L2 это у нас A вентой, B вентой, C вентой. Каждый из них, в принципе,
является контекстом свободным. Это несложно проверить. Нам достаточно задать количество букв
B равное количеству букв C и количество букв A равное количество букв B. Например, мы можем это
сделать вот для, например, для этого языка. Мы можем сделать такую вещь. ИЗСАТ, ИСТВБТЦ и ИСТВЭПСУМ.
Пример грамматики. Прям привести, может доказать, что он задает именно такие языки. А скажите,
чему равняется пересечение этих двух языков?
В предыдущем языке, в котором доказалось, что он не контекст свободный.
Да, он равен как раз предыдущему языку, который не является контекстом свободным. Поэтому у нас как раз
контекстом свободные языки, не знаю, куда точить перечень. Мы берем два контекста свободных языка,
пересекаем их, получаем неконтекстно свободный язык. Это важное замечание. Контекстно свободные
языки нельзя пересекать с чем попало. В следующий раз или в один из следующих разов мы покажем,
что контекстно свободные языки можно пересекать с регулярными языками, и это будут контекстно
свободные языки. Но для этого нам нужно перейти на другую абстракцию. Сегодня мы начнем, а в следующий
раз мы с вами это покажем. Так, это первое следствие. Второе следствие чуть сложнее. Его нужно будет
показывать. Вот, это у нас неконтекстный язык. Второй язык такой. Они не замкнуты относительно
дополнения. Если мы с вами посмотрим. Язык L равно A в ent и B в ent и C в ent. И рассмотрим дополнение
языка L. Это там можно в принципе его посмотреть. Он является неконтекстом свободным языком. Почему?
Там надо убедиться, либо чтобы как-то буквы A и B были перепутаны местами где-то. Это легко
той же самой регуляркой задается. Либо у нас язык имеет вид afkat и bv. Давайте я напишу какие-то
easy cases объединить с языками вида afkat и bv и cv. Где K не равно L или L не равно M или K не равно M.
Каждый этих случаев по отдельности K не равно L, L не равно M и K не равно M можно задать. А объединение
двух контекстов свободных языков построить достаточно просто. Нужно просто объединить эти
грамматики. Мне кажется, возможно на семинаре у вас подобные задачки уже разбирались. В своей
группе разбирал, где использовалась идея объединения двух языков. Почему еще раз дополнение
не замкнуто? Из дополнения следует? Нет, тут изо всех скобочек следует. Мы рассмотрим язык вот
такой вот. Дальше у нас смотрим чему равняется дополнение. У нас это либо такой язык afkat и bv
и cv. Либо у нас тут какие-то простые кейсы идут. Типа в духе, не знаю, перед B идет C. Тогда у нас
этот язык уже ломают зависимость. Да, потому что C, а потом B. Это уже явно не afkat и bv, а cvmt.
Ну и подобные порядковые истории мы смотрим. А это вообще задается регуляркой.
Да, то есть мы это просто берем, задаем регуляркой. Регулярку можно задать той же
правлении на грамматикой. А объединение грамматика – это грамматика. Для объединения языков можно
грамматику построить, если каждый из них является контекстом свободы.
Вот. Понятно вот эти вот факты? Ну то есть они такие фундаментально важные, что контекстные
свободные языки себя ведут сложнее, чем регулярные. Потому что в регулярных мы
устроили дополнение через PDK, напоминая пересень, мы строили через построение
грамматикартового произведения автоматов. Так, товарищи, давайте решать. Я предлагаю
сейчас сделать перерывчик на 5 минут, а дальше перейти уже к следующей теме.
Так, всем доброго дня. Еще раз мы продолжаем. Вот, сегодня мы рассматриваем тему новую.
Посмотрим, сколько успеем доказать. Посмотрим, сколько успеем посмотреть.
Это тема автоматы с магазиной памяти или mp-автоматы. Значит, определение у нас такое.
mp-автомата мы будем называть шестерку, q, сигма, гамма, дельта, q0 и f, где q множество
состояний, множество q конечное, алфавит конечный. Есть еще специальный алфавит,
он называется стековый. Мы его будем обозначать гамма, символы стека алфавита будем обозначать
большими буквами. Честно, это не совпадение. Вот, гамма меньше бесконечности, и тут важное
замечание, его можно в принципе соблюдать, можно не соблюдать, но особой роли у нам играть не будет,
в отличие от катей свободного грамматика. Давайте считать, что они зачастую не пересекаются эти
алфавиты стековые и обычные алфавиты. Дальше у нас с вами идет множество переходов, это страшный
термин, что-то q на сигму со звездой на гамма, на q на гамма со звездой. Опять же, количество переходов
у нас всегда конечно, q0 стартовое состояние, q, f множество завершает состояние. Вопрос, кто лишний, кто
добавился? Ну, стек. Да, стек добавился, это раз. А второе, что еще добавилось? Переходы какие у нас?
Ну, соответственно, переходы теперь изменяют состояние стека. Да, переходы изменяют состояние
стека. Нам нужно представить себе ситуацию, что у нас есть автомат, и к нему приделан стек,
то есть, когда вы идете по пути в автомате, вы пытаетесь либо добавлять буквы на стек,
точнее, делаете плату за переход по состоянию. Для того, чтобы заплатить по состоянию, вам нужно
снять со стека какие-то буквы, перейти по либру, и потом вам обратную дадут положить что-то в стек,
премию за то, что вы перешли этот переход. Вот, и наша цель понять, как выглядит переход. А
переходы мы будем означать вот таким вот образом, что пусть у нас есть, мы находили состояние q1,
мы находили слове w, снимаем со стека альфа, потом мы с вами переходим в состояние q2 и кладем на
стек бета. Неформально. Ну, я написал неформально, но важное замечание. Вот, смотрите, если у нас
написано q1, a, b, c, a, b, c, я не знаю, дальше мы переходим в состояние q2 и на стек кладем x,
то если мы с вами отобразим состояние этого стека, там какие-то последовательности,
не терминала находятся. Так вот, что важно нам замечать, что для того, чтобы перейти по
этому переходу, у нас буквы a, b, c должны находиться именно в таком порядке. Да, то есть мы снимаем
a, b, c, это значит мы снимаем вот эту вот последовательность. Если что, стек растет в ту сторону. Не в обратном
порядке, а именно в таком. То есть мы с вами снимаем со стека a, b, c и кладем x сверху. Вот,
теперь эту историю нам надо формализовать, потому что мы, конечно, молодцы, ребята, мы можем сказать,
вот стек работает так, вот, пожалуйста. Поэтому, опять же, нам нужно задать набор конфигурации.
Значит, смотрите, конфигурация. Это тройка Q, слово U и гамма. Q лежит в состоянии Q,
U из набора всех слов, а гамма находится гамма со звездой.
Давайте понимать, что означают эти символы.
Давайте вспоминать сначала определение конфигурации для обычного автомата,
а потом попробовать перенести на mp-автомат.
Видимо, Q – это текущее состояние, U – это слово, а гамма – это стек.
Да, смотрите, Q – это текущее состояние, U – это слово, которое нам надо прочитать в последствии,
да, но то, что у нас в очереди лежит на обработку, а гамма – это текущий стек. Вот, да. То есть
формально находимся в состоянии Q, неформально. Осталось прочесть слово U, и в стеке расположено,
лежит слово гамма. Вот, теперь как это задать? Задается это таким образом, что если у нас есть
отношение в выводимости, это наименьшее рефлексивно-транзитивное отношение,
опять же, что для любого перехода, я давайте запишу это Q1, U альфа, а я, кажется, с кубочку
не поставил все-таки дельта. Смотрите, что получается. Для любого слова W, которое мы
в последствии хотим прочитать, и для любого наполнения стека, это, по сути, у нас наполнение стека,
а мы делаем следующее. Q1, U, V, это альфа, выводит, Q2, V, это бета. То есть у нас,
смотрите, на стеке располагалось слово это, мы снимаем альфа, это у нас стек, снимаем альфа,
пойдем бета. Ну, а при этом, в этом переходе, если у нас находилось какое-то слово U, вот у нас
находился Q1, здесь это слово V, это слово U и слово V. Мы передвигаем каретку сюда, при этом делаем
операцию со стеком. Именно такое. То есть снимаем альфа, вкладем бета. Вот. И тогда, смотрите,
что мы можем сказать, что язык задаваем по автоматам, это множество всех слов,
или это равно множество всех слов, такие, что мы начинаем в стартовом состоянии,
нам надо прочитать слово W, при этом стек пустой, и мы выводим с вами Q,
Epsilon, Epsilon. То есть мы очищаем все то, что мы хотели прочитать, мы все прочитали,
при этом на стеке у нас ничего не лежало, и мы заканчиваем только с пустым стеком. Это важно.
Вот такое определение. Если непонятное определение, задавайте вопросы, это важно.
Я сейчас хочу рассмотреть один пример, связанный с этим. Это пример правильных скобочных последовательностей.
Для правильных скобочных последовательностей важно, значит, следующее,
а нам нужно эмулировать скобочный баланс.
Вот, и мы будем сохранять инвариант, то есть у нас с вами здесь хватает одного состояния,
которое является завершающим, и у него переходы видом. Мы снимаем со стека, точнее мы, первый переход,
мы берем с вами открывающую скобку, со стека снимаем Epsilon, на стек кладем A.
А здесь мы говорим обратную вещь, что мы снимаем A со стека кладем Epsilon.
Да, нотация правил. Для того чтобы упрощение написать на стеке перехода, мы на стрелочке
пишем следующее, что мы снимаем, что мы, точнее, какое слово читаем, что мы снимаем стек,
и что кладем на стек. А здесь наоборот. Давайте поймем, какой инвариант у нас выполняется,
как понять, какой текущий скобочный баланс, какой балансу префиксу.
Размер стека. Да, количество буква на стеке.
Давайте проэмулируем какую-нибудь скобочную последовательность, я не знаю, вот такую вот.
Давайте я их буду обозначать буковками, то есть это пусть у нас буковка A, это буковка B.
Вот, смотрим, что у нас получается. Сначала Q0, A, B, A, B, B. Стек у нас пустой. Потом мы читаем
букву A, у нас получается Q0, A, B, A, B, B. На стек мы кладем A. Видите, скобочный баланс 1. После этого,
как только мы читаем букву A со стека, точнее, следующая у нас буква A, это у нас правило,
опять же нам нужно снять пустое слово и положить A на стеке. Видите, скобочный баланс у нас 2,
вот здесь вот. Потом снимаем Q0, A, B, B. Чтобы пройти по B, нам нужно со стека снять A.
Q0. Так, дальше у нас идет B, B. Со стека нам на стек нужно положить A, A. Ну и дальше за два
перехода мы с вами можем сделать Q0, B, A и очистить стек следующим шагом.
Все. То есть мы проверили, что правильные скобочные последствия у нас задаются автоматами,
МП-автоматом. Но на одном примере можно, опять же, показывать вариантом, что скобочный баланс
от количества букв A на стеке. Этим как раз мы с вами будем на семинарах заниматься по аналогии того,
как мы делали это с КС-громатиками. Окей, если этот пример понятен, давайте двигаться к следующим
фактам. Вот давайте вспоминать, что мы с вами делали с автоматами, когда мы их ввели.
Упрощали. Упрощали. Вот здесь нам тоже самое надо сделать с вами как раз. Ну давайте это делать.
Как мы это с вами будем делать? Первое упрощение. Оно такое. Оно касается правил в правилах
грамматики. Ну и правил МП-автомат. Значит, смотрите, пусть у нас правила будут иметь Q1,
Q альфа и это переходит в какой-то Q2b. Первое упрощение, которое мы с вами можем получить,
это что все переходы не более чем однобуквенные, а количество букв, снимаемых со стека плюс
добавляемых на стекель, не больше единиц. Это вот этот вот факт. Ну я его заглавил,
что для любого МП-автомата существует эквивалентный МП-автомат, для которого выполнено вот такое вот
соотношение. Давайте я картинками покажу, как это доказывать. На самом деле нам нужно просто все
переходы разбить на куски. Смотрите, вот у нас есть такой переход, в котором есть последний символ
от A1 до A2. Замечу, что символы здесь расположены в обратном порядке для того, чтобы мы со стека
могли снимать. И потом добавляется B1 и так далее. Смотрите, что мы делаем. Тут, к сожалению, нет
дорисовки, но суть понятна. Значит, смотрите, мы берем сначала, читаем все буквы алфавита,
добавляем буквы на переходы, читаем все буквы по одной. При этом у нас модуль альфа плюс
модуль бета равняется единице. Раз. А вторая штука, мы начинаем снимать все, что у нас находится
сверху со стека. Мы сначала снимаем A1, потому что оно на стеке у нас находится наверху,
потому что, сейчас у меня переключится, вот. То есть у нас стек с вами находился, у него находил,
было что-то. Потом было ANT, AMT, AM-1 и так далее, A1. Ровно по этой причине мы сначала снимаем
букву A1 со стека, потом снимаем AM со стека. Ну а кладем в порядке в том,
которым нам нужен. То есть мы кладем B1, потом кладем B2 и так далее кладем Bкат.
Все достаточно просто здесь. Мы просто берем и делаем. Давайте попробуем, если это понятно. Ну,
я не буду формально это показывать, можно это сделать, но, мне кажется, смысла в этом нет.
Второе упрощение. Давайте посмотрим, как хорошо у вас развита интуиция.
Эпсилон-переходы можно удалить. Откуда? Ну, из автомата. Эпсилон-переходы почему? По стеку,
либо по обеим. Смотрите, один из фактов, такой более общий, он будет доказан после. То есть для
этого нам нужно будет перейти в другую нормальную форму. А первое упрощение, которое делается,
это, замечу, что давайте мы сделаем вот такую вот вещь. Модуль альфа плюс модуль бета равно единиц.
То есть при каждой операции мы с вами либо платим монетку за то, чтобы сойти со стека,
вот. Либо мы кладем монетку, точнее, либо мы снимаем монетку, либо нам дают монетку за проход.
Вот. Смотрите, в чем идея заключается. Вот у нас есть, нам надо смотреть, нам нужны рассмотреть те
переходы, в которых модуль альфа плюс модуль бета равняется нулю, потому что у нас изначально тут
ограничение на не больше единицы, значит, оно либо равно нулю, либо равно единице. Ну сделаем
ограничение на ноль. Да, вот, значит, у нас есть такой переход. Тогда смотрите, что мы с вами можем
сделать. Мы по сути можем сказать, а давайте-ка мы сначала положим монетку, а потом заберем.
Такая эффективная банковская система у нас. Этот. Есть классический пример из мульти-индустрии,
как этот губка-боб пытался продать продажу мыльных пузырей. Вот. Он там, по сути, сам у себя там,
там что было? Там, короче, губка-боб продавал их, а Патрик занимал у губки-боба, и губка-боб потом
это, возвращал обратно. В общем, нулевой цикл получается. Вот такая история. То есть мы сначала
кладем Z на символ, потом его снимаем. Ну, а тоже вроде бы эта история понятна. То есть,
ну, вот этим ограничением мы с вами будем как раз пользоваться. Сегодня. Да, все. Нам этого будет
достаточно. Так, с упрощениями понятно, что произошло? Ну, то есть тут ничего сверх сложного
нет. А теперь один из самых главных фактов, который, к сожалению, некоторые забывают,
как доказывается, но мы с вами их посмотрим. Это то теорема большая, что класс языков распознаваемых
МП-автоматов совпадает с классом языков, которые распознаются контекст свободными грамматиками.
Вот. И эта теорема состоит из нескольких пунктов. Возможно, что мы еще не успеем сегодня ее показать,
но мы с вами постараемся. Давайте я ее оформлю. То есть у нас получается КС-эквивалентный МП-автомат.
И первый факт, который мы с вами будем показывать, это то, что из МП-автоматов
можно получить КС-грамматику. Вот, смотрите. Давайте идею расскажу, чтобы она у нас была. А давайте
предположим. Так, только тут небольшая стрелочка, тут вывод у нас. Пусть у нас В лежит в языке,
задаваемом автомат. Давайте посмотрим. Q0. Нам надо прочитать слово. В эпсилон. В какой-то
момент мы с вами прочитаем Q эпсилон эпсилон. И в какой-то промежуточке давайте QF. А здесь у нас
есть какое-то Q, здесь у нас слово U, а здесь у нас на стеке гамма. Давайте построим график,
который будет показывать следующий длину стека относительно того, сколько мы прочли. То есть мы,
я сразу скажу, что у символов мы прочли. Давайте нарисуем этот график. Так, это у нас длина гамма,
это у нас длина слова. Давайте U префикса, то есть префикс. Скажите, какие две точки мы точно с
вами знаем на этом графике. 0, 0 и U, 0. Первое, отсюда мы начинаем, это 0, 0. А здесь длина слова
V и 0. Ну то есть мы должны опустошить стек в конце. И давайте посмотрим, как себя этот график ведет.
Он, во-первых, не падает ниже оси нулевой, потому что иначе у нас стек пустой. Но давайте посмотрим,
давайте я нарисую где-нибудь картинку. Вот, пирамидка. И давайте внимательно. А потому что у нас
стек не может быть менее чем пустой. Ну то есть он может до нуля упасть где-то, но ниже нуля он
не провалится. Потому что это длина стек. Вот, и давайте посмотрим, что происходит на моменте,
вот этот вот момент зафиксируем и посмотрим, что происходит на этом переходе. Напоминаю,
что все переходы у нас имеют вид, что либо мы на стек что-то кладем, либо мы со стека что-то
снимаем. Поэтому, когда у нас стек поднимается наверх, мы сюда кладем А. Ну какой-то символ А на стек.
Давайте посмотрим первое пересечение этого уровня с текущим. То есть первый раз,
когда мы пробили эту планку. Там еще и еще. Давайте поймем, можем ли мы понять,
что происходило вот на операции, которая привела к этому уровню? Что со стеком происходило?
Да, мы сняли, причем именно букву А. Это важно, то есть то, что мы положили на стек,
то мы снимаем. И теперь важная особенность. Давайте мы предположим, что здесь мы находились
в состоянии каком-то Qit, а здесь мы находились Qjit. И по сути нам нужно с вами сделать такой
сложный автомат, который будет правило грамматики, которое будет отслеживать пары состояний. То есть
допустим, здесь мы находились в Qf, в каком-то Q0, а вот это Q0. Тогда заведем пары состояний A0f.
Ну то есть A0f это получается мы ставим в соответствие пару Q0Qf. Это соответствие.
Теперь нам надо с вами продумать правила, как эти штуки у нас с вами будут отслеживаться. Я
сейчас попробую пояснить все эти правила Пашу Пахшагова. Во-первых, первое правило,
которое нам нужно из A и I, мы выводим епсилон. То есть если мы находимся в одном и том же
состоянии, то есть мы находимся по сути в паре QeQe и то, что нам нужно пройти на пути от Qe до Qe,
не меняя стэк, ну что мы можем сделать? В принципе, можем вывести пустое слово. Нам никто этого не
мешает сделать. То есть мы находимся в точке и ничего не делаем. Мы выводим пустое слово.
Дальше давайте сделаем переход такой, что из стартового состояния мы выходим пирамиду.
Где Qgt принадлежит конечному состоянию. То есть это по сути означает следующее,
что из стартового состояния, не терминала, в нашей грамматике мы с вами будем выводить,
ну по сути раскрывать эту картинку. Вот так вот. То есть мы говорим раз, кусок, два кусок. Ну а
дальше из него что-то выводится. И дальше сложный факт, который нам говорит следующее, что из A и
житого мы будем вывозить следующую вещь. A, Ars, B, Atgt. То есть смотрите, давайте я это нарисую на
картинке. Мы находимся в состоянии и. Вот это у нас состояние Qgt. Это в нашем графике где-то.
И у нас и состояние Qgt, которое находится на самом деле на том же самом уровне. Потому что A и житое
это то, что нам вводится на пути, не меняя stack. И тогда смотрите, что это означает. Как мы можем
пойти из этой стрелки? Мы можем пойти на самом деле только вверх. Не меняя stack это значит,
что не выкидывая из него что-то. Да, не меняя stack, не выкидывая что-то. Это просто важно,
я забыл это указать. Извините, пожалуйста. Смотрите, что мы делаем. Значит у нас добавляется какой-то
символ A. Мы переходим при этом в некоторое состояние QR. А здесь мы переходим, опять же,
все чтобы было согласовано. Мы говорим, что здесь для того чтобы это согласовать,
мы должны снять этот же символ A. И это делаем в состоянии Qs. Значит вот эта вот история,
это у нас с вами A и житое. А нет, стоп, нет, извините, сейчас я сотру. Я сотру, я объясню,
почему я стер. Потому что давайте найдем первый уровень, когда мы пересекли эту полосу. Потому
что мы могли ее пересечь именно в кружитом, а могли раньше. То есть мы берем, пересекаем,
это минус A. Я напишу, что это первый момент, первый момент пересечения. И пусть это у нас
состояние s, а вот это состояние t. Тогда это Qt, это Qs. Тогда вот это у нас, что с вами такое? Это у
нас A и ж по нашему обозначению. Вот это у нас с вами Atg, а вот это у нас с вами Ars. Ну потому что мы
тут уже не добавляем, не выкидываем что-то из тек, потому что если мы опускаемся ниже,
то мы получаем в этот уровень. Мы получаем с вами, что у нас и A и жт выводятся. Здесь пусть
какой-то символ A был. Здесь у нас был с вами этот Ars, B, который снимает отсюда символ. Видите,
скоро B, а мы снимаем всего, приходим в состояние. Так, а печатка здесь, здесь t, здесь t, Qt,
Эпсилон. Давайте напишу. Так, значит это если у нас Qea, Эпсилон, Qra. А здесь у нас с
вами получается Qrba, Qgt, Эпсилон. Вот так вот. Ой, не Qgt, а Qtt. И теперь нам надо это все
формально показать, почему это работает. Главная лемма, которая здесь у нас с вами появляется,
она заключается в следующем. Она говорит, что если мы A из A и житого выводим w тогда и только тогда,
тогда выполнно следующее соотношение QeTv Эпсилон, выводится QeT, Эпсилон, Эпсилон.
Здесь у нас это в грамматике, это в автомате, это в грамматике. Вот. То есть если мы это показываем,
то на самом деле уже победа. Потому что тогда мы из S заходим в Q0 в A0 житая, ну и дальше мы
выводим все слово целиком. То есть это лемма, которую нам надо будет с вами показать. Ну,
давайте начнем. Хотя бы один пункт из двух разберем здесь. На сегодня уже будет победа.
Так, смотрите. Давайте я правила буду держать при себе. Давайте докажем слева направо сначала.
Здесь у нас опять же классическая индукция, индукция по длине вывода в грамматике.
Не вывода в грамматике.
Скажите базов, какая у нас с вами. За сколько шагов мы можем вывести что-то из этой грамматики?
Вот в этих правилах.
Можем ли мы что-то вывести за ноль шагов?
Ну, если и равно жи, то да. А как? Как мы можем что-то за ноль шагов?
Нет, это за один шаг. Да, за один шаг. Если мы возьмем A и ИТ эпсилон. То есть один шаг.
Тогда мы с вами из A и ИТ выводим эпсилон. Только у нас вот это вот правило есть.
Следовательно, у нас с вами и равно жи, w равно эпсилон. Ну, из этого будет следовать, что qi эпсилон эпсилон мы выводим qi эпсилон эпсилон.
Ну, вроде честно.
Теперь переход. Мы с вами допустим из A и из ж вывели какое-то слово w за к шагов.
Тогда смотрите внимательно. Какое правило у нас может раскрывать меньшее количество шагов? Только вот это вот.
Тогда замечу, что A и ж раскрывается в A, A rs, B, A and jt. Только по такому правилу у нас что-то могло раскрываться.
При этом qi, a эпсилон выводится. Есть переход, точнее qr, a.
А здесь у нас qrt. Так, извините, пожалуйста, я еще одну, еще один бак у себя нашел. Давайте его пофиксим.
Здесь везде qst, видите? То есть мы из qs должны в qt переходить. Приношу извинения.
Из qst по B, A. Снимаем его и переходим в qt эпсилон.
Но мы знаем, что существует тогда, смотрите, слово w раскрывается в виде A, U, B, V.
Опять же, просто строим дерево вывода. При этом, что хочу сказать, что из A rs у нас выводится U, из A jt у нас выводится V.
И по предположению индукции каждого, потому что это будет сделано за меньше что шагов, то мы с вами получаем следующую вещь.
Что у нас из qrt у эпсилон мы можем вывести qst эпсилон, а здесь у нас из qt в эпсилон мы можем вывести qjt эпсилон.
Это по предположению индукции работает. Вот с этого факта.
Ну теперь давайте собирать все по цепочке. Если мы из qt, A, U, B, V и берем и раскрываем эпсилон.
Первый шаг, который у нас будет, давайте я их буду пояснять. Вот это первый шаг. У нас получается мы снимаем, читаем букву A, здесь мы переходим в R, здесь у нас получается U, B, V и на стэк кладем A.
Потом пользуемся вторым правилом. Здесь у нас второй переход. Мы получаем qr, U снимаем со входа, переходим в qs, при этом стэк у нас не меняется, B, V, а здесь у нас получается A.
Потом мы пользуемся третьим правилом. Вот этим вот.
Получаем, что у нас с вами. Мы из qs по B вход, A снимаем со стэка, получаем qt, V, эпсилон.
Ну и осталось четвертым шагом воспользоваться. Мы получаем с вами U, эпсилон, эпсилон. Все. Чистота, как говорится, мои руки чистые в этой штуке.
Вот. В обратную сторону чуть-чуть сложнее, но давайте как раз мы с вами в следующий раз и продолжим, потому что мне кажется, что лучше оставить время на вопросы.
Сейчас мы просто уже не успеем эту вещь ничего доказывать.
Ну там надо рассмотреть, типо, первый шаг, который нам нужно сделать здесь.
Так, давайте задавайте вопросы. Говорите, понятно было или нет.
А еще раз, как из LEM будет следовать теорияма?
Да, давайте тогда вот как раз на этот момент, как из LEM исследовать теорияма.
Это на самом деле не очень сложно. Смотрите, мы знаем, что, значит, нам что нужно показать, что любой mp-автомат распознается mk-автоматом.
Смотрите, из S выводится W. В обе стороны будем говорить. Что значит из S выводится W?
Это значит, что существует какое-то a и gt. Вот смотрите, вот у нас, точнее, видите, из S есть переходы только a0gt, в котором идет переход A0gt.
То есть у нас существует a0gt, для qgt принадлежит f. Такое, что S у нас выводят за один шаг a0gt, из этого выводится W.
Дальше, что это значит? Опять же, переписываем, что существует a0gt для некоторого qgt из f. Такое, что, иду с внимания,
у нас вот эта вот лемма. Эта вот лемма здесь используемся. Что из q0wε мы выводимся в qgt εε.
А это что у нас получается? Существует qgt из f. Такое, что q0wε выводится в qgt εε.
Но вот эта штука, тут надо сказать, что это у нас объективное преобразование из qgt в a0gt. А вот это означает, что W принадлежит языку, задаваемую автоматом.
Потому что мы, по сути, с вами сняли стэк, получили то, что получили. А здесь у нас получается, что это у нас W принадлежит языку, задаваемую грамматикой.
То есть самый тонкий момент, это просто, что у нас вместо из qgt мы можем сделать b.
Можно вопрос? Да.
По поводу второго упрощения, это уже даже не эта теорема, где мы на стэке либо забираем, либо отдаем хотя бы.
Да, да, да. Почему мы получим эквивалентную? У нас же получается, на стэке остается вот этот z?
Да, мы его сразу снимаем. Мы кладем и сразу снимаем его.
Когда мы пишем справа, это кладем, а слева забираем, да? Да, да. То есть слева плата за вход, а справа премия за переход.
Спасибо.
Ну ладно, давайте тогда. Все, всем спасибо, всем здоровья, всем не болеть.
