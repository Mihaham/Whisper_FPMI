Ну что, давайте начнем. Сначала восстановим несправедливость, потому что оказывается,
что в конце прошлой лекции я так увлекся вот все этими монадами и функциональным
программированием и забыл рассказать про важную вещь, прям вот важную очень для нас,
для нашего курса, про еще один экзекютер. Но давайте восстановим немного контекста. В прошлый раз
мы с вами говорили про различные... В прошлый раз мы говорили про фьючи. Вот они перед вами,
фьюча. И это для нас было еще одно средство выразительности. То есть с помощью фьюч можно
было бы описывать какие-то асинхронные цепочки задач, потом их исполнять в пуле поток. Для этого
у нас был метод subscribe асинхронный, и у нас была via, которая позволяла указать, где же именно
кулбек будет вызван. Ну а дальше мы могли с помощью этих subscribe и via писать комбинаторы,
которые реализуют синхронные и асинхронные продолжения. Мы это называли зеном, но вот знающие
люди говорят, что нужно назвать их совсем по-другому, мапы flatmap, потому что функторы монады. Ну в общем,
не так это важно сейчас. Важно, что изучая фьючи, мы столкнулись, обнаружили вернее, что тредпул,
что нам по-прежнему нужен тредпул. Что и фьюча, и файберы, которые у нас были. Давайте я открою
условия новой задачи, которые у нас уже на самом деле есть, а вы про это, может быть, еще не знаете.
И файберы, и фьюча, и стеклоскрути, на которых у нас еще не было, на которые будут, которые есть,
и плюс-плюс, вы их видели, наверное, коэвейт, вот все это. Это разные выразительные средства,
с помощью которых вы, как пользователь и разработчик, описываете свои конкурентные
активности, вы работчики запросов. Вот, и для вас, как для пользователей, все эти средства очень
сильно отличаются, но вот выглядят они совершенно по-разному, вряд ли вы файбер с фьючами спутаете.
Но если мы смотрим на эти инструменты не с вашей позиции, а с позиции среды исполнения, с позиции
тредпула, то в принципе никакой разницы между всеми этими механизмами нет, потому что для
тредпула все это цепочки задач. Исполняется одна задача, потом она завершается, и в конце, видимо,
как-то планирует на будущее запуск следующий. Ну, например, файбер заводит таймер и планирует
задачу, которая сделает резюм его корутина. Или мы подвешиваем на фьючо колбэк, который будет,
который запустится тогда, когда вот какая-то асинхронная задача выполнится. Ну, то есть,
вот такие цепочки задач, мы их планируем там динамически, статически, и в общем дальше они
бегут в этом тредпуле. А дальше мы говорим, но вот есть разные средства, и они используют один
и тот же механизм исполнения задач, тредпул. И как они его используют? Они просто вызывают
Submit, запланировать задачу на исполнение. Так вот, если задуматься, то, ну, во-первых,
это хорошо, это такой, у нас получается модульность, у нас есть тредпул, у нас есть фьючо и файберы,
они друг от друга ничего не знают. И поэтому тредпул подходит для разных инструментов,
он универсален. Но можно пойти еще дальше и заметить, что мы в прошлый раз и сделали,
что вот все эти средства, и файберы, и фьючи, и стеклоскорутина, которых у нас пока не было,
они всем, ну, в общем-то не полагаются на то, как именно задачи будут исполняться. Вот тредпул
то обещает этого достаточно, то есть, просто достаточно обещания исполнить задачу, где,
когда именно эта реализацию файберов вообще-то не беспокоит. Поэтому сам тредпул вот во всей этой
конструкции, во всем этом дизайне можно обобщить до понятия экзекьютора, сервиса, который исполняет
задачи. Экзекьютор, но вот он, у него единственный метод, экзекьют, запланировать задачу на исполнение,
где-то, когда-то она будет выполнена. Ни файберы, ни фьючи сами не понимают, когда именно. Вот, а вы,
как пользователи, сами настраиваете уже конкретный рантайм, то есть, конкретный экзекьютор, который
будет задачей исполнять. И, может быть, вам, может быть, вы берете в качестве экзекьютора тредпул и
запускаете в нем файберы. Это вы уже делать умеете. А, может быть, вы берете, как мы показывали,
как мы смотрели в прошлый раз, в качестве экзекьютора, manual executor, который запускает задачу в
ручную. Вот мы говорим execute и кладем задачу в очередь этого экзекьютора, просто задача лежит в
очереди, не исполняется. Кладем еще одну, а потом вручную запускаем одну задачу, запускаем еще три
задачи. Если вы подставите под файберы такой экзекьютор, то вы получите детерминированное
однопоточное исполнение файберов. Сами файберы при этом не поменяются, они просто зависят от
экзекьютора, а не от конкретного тредпула для планирования. А за счет того, что механика
исполнения поменялась, за счет того, что теперь это такая ручная очередь, то исполнение получилось
детерминированное, можно там uni-test писать, не меняя реализацию файберов. Вот, это были два
экзекьютора, про которые мы в прошлый раз говорили, тредпул и manual, но я не поговорил про еще один
очень важный, очень любопытный для нас в курсе, это executor-strand. Помните, когда-то давно я говорил
вам на лекции про кэши, что вот есть mutex и он не слишком хорош в точке зрения протоколок
герентности. Ну, потому что нужно постоянно двигать данные между кэшами для разных
критических секций. То есть вот мы знаем, что цена синхронизации в процессоре – это коммуникация по
шине памяти между кэшами, между ядрами, которые синхронизируют свои кэши. Чем меньше синхронизации,
тем быстрее все работает. Вот, а теперь представим, что у нас ядер много, там, не знаю, десятки, 64 ядра,
и мы запускаем на них критические секции, которые обращаются к одним и тем же данным. И вот в итоге
у нас на синхронизации получается очень много коммуникаций, просто чтобы критически, чтобы потоки
договорились, кто из них в каком порядке исполняется. А кроме того, сами критические секции исполняются
неэффективно, потому что вы поработали с данными на одном кэше, теперь они лежат в вашем кэше,
видимо, в состоянии modified, вы их поменяли. А потом критическая секция запустилась на другом ядре,
и там уже данных нет, потому что modified – исключительное состояние, оно исключает копии в других кэшах.
И вот данные едут с одного кэша на другой. Когда протоколок герентности нагружается, процессоры
занимаются обслуживанием всех этих сообщений ядра, какая-то не очень полезная работа. Так вот,
это с одной стороны, а с другой стороны, mutex в нашем случае плох еще и потому, что он плохо
вписывается в нашу модель, где число потоков ограниченное. Вот мы все задачи наши запускаем в
одном пуле из там фиксированного числа потоков. И если какая-то задача в этом пуле берет mutex
на продолжительное время, то пока она его держит, другие задачи, соответственно, будут ее ждать,
блокировать свои потоки, воркеры в пуле. И таким образом, другие задачи, ну, какие-то третьи
задачи, которыми mutex вообще не нужен, не смогут исполняться, потому что на одном потоке mutex держит
и работает под ним, а на другом потоке, на других потоках mutex аждут. И вот у нас вся система тормозится.
Вот. Предлагается обе эти проблемы решить с помощью нового инструмента, нового экзекьютора,
то есть нового механизма запуска задач, который называется Strand или, как это ни странно,
асинхронный mutex. Где же он у меня был? Вот что мы упустили в прошлый раз. Strand – это
не самостоятельный экзекьютор, это декоратор. Он оборачивает пул потоков. Собственных потоков
у него нет. То есть все, что он запускает, он запускает через тот пул, который он оборачивает.
Вернее, даже Strand не знает, что он оборачивает. Какой-то экзекьютор, в данном случае, это пул поток.
И какую же нам гарантию дает Strand? Все, что мы в него положим, все задачи, будут исполняться строго
последовательно, друг за другом. Причем порядок исполнения будет уважать порядок отправки задач
в Strand. То есть мы в него бросаем критические секции, фактически, а он их асинхронно последовательно
исполняет. В чем здесь профит? В том, что мы теперь можем избежать дополнительной нагрузки на протокол
к герентности. Вот обычному mutex, чем больше потоков с ним работают, тем хуже. А Strand – это такой
очень странный примитив, потому что чем больше на него нагрузки, тем под капотом будет меньше
синхронизации и тем эффективнее все будет работать. То есть чем больше нагрузки, тем меньше лишней
работы он делает. Это довольно интересный эффект. Где он может выигрывать? За счет чего он может
выигрывать? За счет того, что он не пытается данные возить между разными потоками. Он наоборот говорит,
что вот если у вас есть критические секции, то им и так исполняться последовательно по своей
задумке. Так вот, нужно их просто свести в один поток и там поочередно исполнить. Просто друг за
другом. Тогда между ними не нужна будет синхронизация, мы просто запускаем там три критические секции
подряд. Между ними синхронизация больше не нужна. Кроме того, все эти секции теперь в пределах вот
такой вот серии запуска будут работать над одним и тем же кышом. А значит, не потребуется инвалидация,
все данные будут под ногами. Вот на данном ядре. Понятна идея? Ну, пока минус в том, что он не то,
чтобы минус, но это все-таки Executor, то есть он вписан в наш framework и нам требуется framework,
чтобы с ним работать. Кроме того, но это вообще интересная история. Смотрите, он это асинхронный
мьютакс, говорю я о нем так. То есть, мы говорим Execute и вот задача как-то улетает куда-то в какую-то
очередь, там ждет своего часа. А если вы решаете задачи про файберы, давайте откроем задачи про
файберы, которые вы прямо сейчас должны решать. Это задача мьютакс. Вот, то там вас просят сделать
синхронный мьютакс для файберов. Совершенно обычный, да? Вы берете его, получаете и оказываетесь
в критической секции. Так вот, вы же знаете по другой задаче, по задаче slip4, внимание,
все связано, что файберы с помощью переключения контекста, ну, коррутины, могут асинхронные вызовы
превращать в синхронные. Понимаете это, да? Вот, ну, в этом, в этом задаче, в задаче slip4 занимались,
вы превращали асинхронный таймер, асинхронная операция async weight, в синхронную операцию slip4,
которой мы заходим и выходим, когда файбер уже проснулся. Так вот, если вы умеете делать
асинхронный мьютакс, хороший, если вы умеете делать из асинхронных интерфейсов синхронные,
то вы, объединив свои познания, которые вы получили из задачи slip4 и из задачи вот этой
новой прегзекьюторы, можете потом вернуться в задачу мьютакс и сделать там вот вообще
клевую хорошую реализацию синхронного мьютакса еще из гарантии лукфрии, который будет сериями
критической секции исполнять. То есть, он будет гораздо эффективнее, чем обычный мьютакс, потому
что, ну, а иначе зачем мы все это своими руками пишем, чтобы оно было эффективнее, чем стандартный
инструмент. Ну, в общем, время придет, и вы все это осмыслите, я надеюсь. Ну, все это вместе должно
сложиться в какой-то момент. Может быть, сейчас нет. Ну, в общем, имейте в виду, что все связано,
все задачи связаны, они вот так накапливаются, и вот этот пазл наш он увеличивается, становится
сложнее. Пожалуйста, старайтесь держаться в теме, не выпадать из нее. Что именно? Я пока и не
объяснил, как он работает, это очередная домашка его придумать. Он исполняет задачи последовательно,
которые у него бросают. Ну, для критических секций параллельности и так не было с самого начала.
Ну, значит, задачи, которые исполняют критические, ну, то есть, критические секции планируются
через стренд. Не критические секции планируются через пул. Вот, у тебя есть пул потоков,
над ним стренд. Может быть, даже много стрендов, может быть, тысячу стрендов. Вот, это, ну, такое
очень, мне кажется, изящное применение, я смогу вам показать осенью в курсе распределенных систем.
Вот, в RPC Framework есть такая сущность, канал, вот, в него запросы падают от пользователя,
и в него прилетают события из сети, что сообщения снаружи приходят. Их нужно упорядочить и
последовательно обрабатывать. Вот, каждый такой канал логический в RPC Framework — это отдельный
стренд. Он для исполнения использует отдельный стренд. А под ним — один общий пул потоков. И вот,
задачи, которые хотят исполняться параллельно, они исполняются, планируются прямо в пул. Задачи,
которые хотят исполняться последовательно, планируются в стренд. Но все вместе, все вместе задачи,
все в совокупности, работают в одном пуле поток. Вот, через стренд мы планируем только те задачи,
которые хотят, ну, то есть, критические секции, которые обращаются к некоторым данным. То есть,
раньше у нас данные защищал Mutex, а теперь может быть, что данные защищают какой-то стренд.
Вот, для своих данных — какой-то отдельный стренд.
Да, спасибо. Последствия рефакта. Итак, ну, смотрите, что еще в этой истории удивительного — то,
что мы хотим с вами в задачи построить некоторый лог-free Mutex и некоторый лог-free
стренд. Мы хотим, это, собственно, тема сегодняшнего занятия, мы хотим с вами изучить новую технику
синхронизации. Ну, почему? Потому что взаимное исключение нас немного тревожит. Но, чтобы объяснить,
почему, давайте вообще вспомним про взаимное исключение. Мы с вами когда-то курс начали
с изучения Mutex — это такой базовый примитив синхронизации. Нам нужно из разных потоков
обращаться к одним и тем же данным. Мы эти данные защищаем Mutex, и все обращения оборачиваем
в критической секции. То есть, говорим Mutex-Log, обращаемся к данным, потом говорим Mutex-Unlock.
Секция закончилась. И чего мы от такого инструмента ожидали? Мы ожидали двух гарантий. Во-первых,
мы ожидали взаимного исключения, собственно. Это safety-свойство. Ничего плохого не происходит.
Не может быть такого, что два потока находятся одновременно в критической секции между вызовами
Log и Unlock. И была вторая гарантия — гарантия прогресса. Что если Mutex свободен и за него
борются потоки, то какие-то потоки Mutex захватывают. Система не может стоять на месте. И вот эта
гарантия прогресса, пока неформальная, она у нас формализовалась в две конкретные гарантии уже,
в две строгие. Это гарантия свободы от взаимной блокировки, гарантия глобального прогресса. Если
Log свободен, то кто-то его захватывает обязательно. И вторая гарантия, более сильная, это гарантия
локального прогресса. Каждый поток, который встает на захват блокировки, обязательно ее получает.
Вот если вы писали самый простой спин-лог с операцией Exchange, то вы знаете, что если
много потоков борются за этот спин-лог, то кто-то обязательно выигрывает. Но каждый отдельный
поток может в принципе, ну в теории, проигрывать бесконечно долго. Ему ничего не гарантируется.
Это глобальный прогресс. Локальный прогресс, то есть свобода от голодания, что каждый поток,
который борется за блокировку, ее получает. Вот так было в TicketLock. Там у нас была очередь,
и вы встали в очередь, и все, вот неизбежно до вас очередь дойдет. Вот, ну две такие гарантии —
локального и глобального прогресса. Вот мы сегодня говорим про прогресс. Так вот, две эти гарантии,
на самом деле, в определении своем, полагались на некоторое поведение планировщика. А именно,
что планировщик работает, ну так, честно, хорошо, то есть он запускает все потоки, которые в нем есть.
Вот если поток зашел в критическую секцию, захватил блокировку, то он рано или поздно это
блокировку отпустит и пойдет дальше. В смысле, ему додадут работу и отпустит блокировку. То есть мы не
предполагаем, что какой-то поток может надолго, например, зависнуть или вообще навсегда. Вот сегодня
мы от этого предположения попробуем отказаться. Мы сегодня будем считать, что планировщик у нас
может взять и остановить любой поток между любыми вообще инструкциями на произвольное время.
И мы хотим даже в таком случае иметь гарантии прогресса. Вот смотрите, в такой ситуации локи
не работают. Почему? Потому что поток захватил блокировку, а потом планировщик взял его и остановил
на день, навсегда. Все, в системе никакого прогресса больше не будет. С другой стороны, наверное, такое не
слишком реально, чтобы поток остановился навсегда. Все-таки потоки этой, там, не машины, они не
взрываются, не сгорают. Ну, то есть если у вас сгорел компьютер, то вообще никаких потоков,
больше нет совсем, ни одного. Можно не беспокоиться за это. Но все же, мы говорим сейчас про гарантию
прогресса не с позиции того, что поток может остановиться навсегда. Такое только в теории возможно,
а даже там. А про то, что мы не хотим, чтобы пауза одного потока, скажем, вот поток зашел в критическую
секцию, взял спинлог, а его с ядра вытеснил планировщик, просто по кванту времени. Так вот,
мы не хотим, чтобы такие ситуации, такие паузы влияли на другие потоки, потому что у нас их
вообще ограниченное число, у нас тредпул. Понимаете, это проблема? То есть, когда мы работаем с мютоксами,
потоки начинают друг от друга сильно зависеть, потому что внутри критической секции под мютоксом
поток вытеснили, все прогресс, система глобально остановился. Мы сегодня хотим добиться более
сильной гарантии, мы хотим сегодня добиться неблокирующей синхронизации. Это пока не
формальное определение. Неблокирующая синхронизация – это синхронизация, при которой пауза произвольного
потока между произвольными инструкциями не может привести к тому, что в системе остановится
прогресс. Вот система совершает прогресс, где бы какой поток не остановился. Разумеется,
глобальный прогресс. Из нашего установки задач следует, что мютоксы мы использовать уже не можем,
видимо. Мы хотим придумать какой-то альтернативный инструмент. Но прежде, чем про него говорить,
давайте формулизуем, что именно я хочу. Гарантия неблокирующей синхронизации – это гарантия
которая выражает, формулизуется в двух конкретных гарантиях. Это weight freedom и log freedom. Давайте
начнем, наверное, с weight freedom. Она более простая в определении. Мы скажем, что пусть у нас есть
некий какой-то разделяемый объект, какая-то структура данных пусть, к ней обращаются
разные потоки. Мы скажем, что отдельный метод этой структуры данных многопоточной weight free
свободен от ожидания, если этот вызов завершается независимо от того, как ведут себя другие потоки,
как они работают, где они останавливаются, насколько они останавливаются. Вот вызов начинается,
и если процессор дает потоку, который этот вызов делает работать, то вызов непременно завершится.
Гарантия понятна? Это самая сильная гарантия, которую можно представить. Это гарантия локального
прогресса. Это вот гарантия свободы от голоданий, только не блокирующая, только мы не требуем
ничего от планировщика здесь. Планировщик может сделать что угодно, торматить любые потоки на
любое время. Вторая гарантия lock freedom, она более слабая, она про глобальный прогресс. Вот пусть мы
пишем некоторую многопоточную структуру данных, к ней обращаемся из разных поток, и вот зафиксируем
какую-то точку во времени, и вот сейчас стартовали какие-то вызовы. Мы скажем, что реализация,
вся реализация этой структуры lock free, если в будущем, независимо от того, как действует
планировщик, завершится хотя бы один вызов. Может быть, те вызовы, которые прямо сейчас
стартовали, никогда не завершатся, но какой-то вызов в будущем обязательно завершится. Если
говорить про бесконечное исполнение, то можно сказать следующее, что в бесконечном исполнении
завершается бесконечное количество вызовов. Вот обратите внимание, что я говорю о гарантии прогресса,
weight freedom и lock freedom, я не говорю, что там, я вот строго определяю понятие прогресса в
терминах завершающихся вызовов. Мне не важно, как структура данных устроена. Если вызови
завершаются, значит прогресс есть. Вот я так его формулирую. И вот weight freedom – это гарантия
прогресса завершаемости каждого отдельного вызова, независимо от того, как работают или не
работают другие потоки. А lock freedom – это гарантия глобальная, что какой-то из вызовов завершится в будущем.
Ну вот, мы хотим сегодня придумать механизм синхронизации, который будет одной или другой
гарантии удовлетворять. Мы хотим вот неблокирующуюся синхронизацию. Ну, у нас-то точно для конечного
числа поток, так что тут есть некоторые тонкости в определении. Число потоков будет бесконечное,
но оно в природе бесконечным не бывает, и у нас уж точно не бывает, потому что у нас стритпулы.
Вот, поэтому давай говорить, что число потоков конечное. Да, вот если у нас число потоков
конечное, то гарантия lock freedom переформулируется как бесконечное исполнение, бесконечное число
вызова завершается. Хорошо. Почему мы вообще об этом говорим? Потому что мы сегодня хотим делать,
ну какова наша цель вообще? Зачем нам такой инструмент? Мы хотим делать более эффективную
среду исполнения, более эффективный рантайм для наших фьюч и файберов. Вот мы пока занимаемся тем,
что оптимизируем, ну пишем хорошие фьючи и файберы, фьючи еще не пишем, файберы пишем,
в которых уже много всего происходит. Мьютокс, секундвары, там какие-то операции, каналы скоро
появятся. Мы можем их хорошо делать, но под ними пока очень плохой тритпул. Он в смысле корректный
тритпул, но очень медленный тритпул, потому что там одна общая очередь. Если вы запустите файберы
под профилировщиком, то вы увидите, что большую часть времени занимают вызовы lock-a-unlock в вашем
исполнении. Это довольно печально. Вот мы бы хотели планировщик сделать более эффективным, и мы
займемся этим через неделю. Но пока нам нужен просто инструмент. Вот смотрите, с чего мы начали
делать тритпул. Мы же начали с изучения мьютокса. Мы изучили инструмент, а потом с помощью него
сделали тритпул. Вот так же и сейчас. Мы хотим изучить некоторый инструмент, такой подход,
не блокирующий синхронизация, как альтернатива мьютоксам, а дальше его использовать, чтобы
оптимизировать рантайм, в котором исполняются файберы, фьючи, карутины будущей, что угодно.
Замысел понятен? То есть мы говорим сейчас не про то, как писать код, а про то, как его
исполнять эффективно. И вот для этого нам нужен новый инструмент. Отлично. Мы уже поняли, что мьютокса
использовать нельзя. Если поток зашел в критическую секцию, его заблокировали, его вытеснили с ядра,
то все, никакого прогресса нет. Как же быть? Ну, смотрите, да, вот, пожалуйста, lock-freedom означает,
что у нас нет, ну, как бы название говорит о том, что как будто нет локов. На самом деле,
если у вас просто нет локов, то это еще не lock-freedom. Lock-freedom — это когда у вас есть гарантия
прогресса, что в будущем хотя бы один вызов завершится. Это не одно и то же. Чуть позже покажу
пример сегодня. Итак, возвращаемся к истории. С помощью чего мы будем делать вот такую
не блокирующую синхронизацию? Что у нас вообще есть? Ну, мьютоксов нет, значит, мы спускаемся вот
к совсем базовым инструментам. Давайте починим интернет. Да. Нет, потоки на бесконечное время
остановиться вообще не могут. Ну, планировщик работает разумно. Зачем он останавливает потоки
на бесконечное время? Потоки могут останавливаться на какое-то время. И вот пауза потока под
критической секцией, она мешает прогрессу других потоков. И мы хотим вот это влияние исключить.
Цель такая. Я ответил на вопрос.
Еще раз. Мы хотим, чтобы прогресс был, даже если поток остановится на бесконечное время.
Поток в компьютере не будет останавливаться на бесконечное время. Но он может останавливаться
на какое-то время. И если он остановится под критической секцией, это проблема. Так вот,
если мы подготовимся к худшему случаю, то мы сможем обеспечить прогресс и вот просто в
реальном компьютере. Просто худший случай, он для нас упрощает модель. Мы не думаем,
как именно планировщик работает. Мы считаем, что он просто вот работает, ну, может, поток
остановится навсегда. Мы не строим там какие-то вероятностные модели, что он там останавливает
поток на такое время, там какие-то распределения. Нет. Мы говорим просто, вот, худший случай,
может быть. Итак, что у нас есть? У нас остается атомик для синхронизации. Как обращаться к общим
данным? Ну, атомики есть. Правда, вы, наверное, знаете, что в атомиках есть фундаментальная
проблема. Ну, не то, что проблема, а ограничение. Все атомарные операции в компьютере ограничены
одной ячейкой памяти. Может быть, это нам вообще мешает, наверное, если мы хотим что-то сложное
делать. Ну, ладно. Какие операции у атомика есть? Load, Store, Exchange, Compare, Exchange. Ну, наверное,
вы уже поработали с разными операциями и поработаете еще больше дальше, но, наверное,
у вас уже есть интуиция, какая операция из этих самых, из этих операций самая выразительная,
самая мощная. Ну, наверное, это Compare, Exchange. Что? T5.1 это не атомарная операция. Это сискол,
во-первых, во-вторых, про блокирующее ожидание. Блокирующее ожидание к нашей
лекции сегодня не имеет, оно просто перпендикулярно. Мы хотим из разных потоков работать с общими
данными. Блокирующее ожидание это вот не решает эту проблему. Решает проблема Mutex. Мы берем
Mutex, а потом знаем, что вот мы одни и можем состояние менять. Вот какую проблему мы решаем. А
сейчас уже не можем так делать, потому что Mutex больше нет. Потому что он нас лишает глобального
прогресса. Так вот, у нас остаются атомарные операции и самая, наверное, выразительная из них
это операция Compare, Exchange. Что она делает? Она берет, она сравнивает содержимое атомарной ячейки
памяти с некоторым ожидаемым значением. Если значение совпало, то ячейка перезаписывается
на новое значение. Если не совпало, у нас не работает интернет сегодня. Нет, ну мы так жить не
сможем, конечно. Если вы скачиваете фильм сейчас, то остановитесь, пожалуйста. Это нам не помогает.
Вот, Compare, Exchange. Что она делает? Она, значит, сравнивает содержимые ячейки с ожидаемым
значением. Если успешно сравнение завершилось, то перезаписывает и возвращает true. Если не успешно,
то через ссылку, через первый аргумент возвращает прочисленные значения и говорит пользователю
false. Операция провалилась, перезапись не состоялось. Смотрите, вы это, наверное, уже сами
видели. С вами хорошо представляете себе, что Compare, Exchange. Да, как мы собираемся этой операции
пользоваться? Давайте я покажу общий паттерн. Некоторый общий паттерн. Как с помощью этой
операции мы будем строить сегодня почти всё с гарантией lock-free? Мы будем использовать касс-луп.
Вот пусть мы хотим реализовать какую-то операцию атомарную. Fetch-increment, fetch-add. Что мы делаем?
Мы заводим цикл себе и в нем делаем такой снимок текущего состояния ячейки памяти,
ну или какого-то более сложного состояния. Потом локально применяем изменения, а потом
пытаемся их зафиксировать в разделяемом состоянии с помощью кассы. Если получилось,
то операция состоялась. Если не получилось, то почему не получилось? Видимо, состояние ячейки
поменялось. Значит, ну ладно, мы проиграли. У нас операция завершилась неудачей, попытка
завершилась неудачей. Но это означает, что какая-то другая операция завершилась успешно. Так что мы
пробуем. И вот это пример такого lock-free кода. Самое простое, которое можно представить себе.
Вот lock-free-increment. Ну это хорошее замечание. Да, выгоднее. Вот.
Можно сделать вот так вот, да. Да, это будет, ну код стал лучше. Идея понятна. Вот lock-free-код.
Просто у меня ломается документация. Я хочу, чтобы явно были шаги с нынешним состоянием,
а потом делаем попытку зафиксировать изменения. Поэтому код так написан. Вопрос.
Так это же есть гарантия lock-free. Глобальный прогресс. Какие-то операции завершаются,
какие-то могут не завершаться. Это же вот буквально определение lock-free.
Эта реализация lock-free, она не weight-free. В weight-free каждый вызов обязан завершаться. Здесь не обязан.
Ну как это в теории так. На практике, скорее всего, конечно, каждый завершится.
Итак, пример. И вы, ну, в нем видите и сами уже хорошо макаратно, наверное,
встречали в своих домашках, что почему-то в C++, в Atomic у вас не один compare exchange,
а два compare exchange weak и strong. И вы, наверное, знаете, чем они отличаются, что compare exchange
strong – это вот compare exchange, которую вы ожидаете. А compare exchange weak – это такая странная версия,
которая допускает ложно-отрицательные срабатывания. То есть она может сказать вам,
что сравнение завершилось неудачей и не перезаписать ячейку, хотя содержимые ячейки
совпадают прямо сейчас с тем, что вы передали первым аргументом. Вот. И, кажется, настал момент,
чтобы разобраться, почему так происходит. Вот смотрите, есть good bolt. Смотрим в него.
Смотрим на реализацию compare exchange weak и compare exchange weak, почему-то. Strong.
Будет очень тяжелый день.
Итак, смотрим на реализацию compare exchange weak и strong на нашем компьютере, вот на моем компьютере,
например. И оказывается, что реализация одинаковая. Это log compare exchange. То есть мы
лочим шину памяти и делаем такую сложную, неатомарную само по себе операцию. Итого,
под x86 реализация не отличается. И вот возникает разумный вопрос, а зачем же нам две реализации
compare exchange weak и strong, когда они устроены одинаковыми? Ну, дело, видимо, в том,
что есть разные архитектуры, и, видимо, на какой-то другой архитектуре может быть
другая реализация. Вот давайте посмотрим. Вот ARM, и на нем уже, смотрите, есть реализация weak,
вот она такая. И реализация strong, она отличается. И давайте я попробую пояснить вам разницу. Дело
в том, что на ARM вообще нет инструкции compare exchange, вот просто с такой семантикой. Вместо
этого есть две отдельные инструкции. Вот такая вот, это load acquire exclusive register.
И есть парная ей инструкция. Семантика у них следующая. Вот вы читаете ячейку памяти с
помощью этой инструкции. И как будто бы берете на нее такую аппаратную блокировку, ну, условно так.
А в этой операции вы пишете в ячейку, но запись, она условная, то есть запись совершается только если
с момента вот такого вот чтения не было других записей в ту же самую ячейку на других ядрах. Идея
понятна? Это в каком-то смысле проще и модульнее, чем compare exchange. У нас есть отдельная инструкция
для чтения, отдельная инструкция для записи. Очень разумная архитектура. Вот, и запись
условная. В общем случае такой набор операций называется load link and store conditional. Вот, разные
архитектуры поддерживают такие операции, то есть прочесть с блокировкой, записать, если значение не
изменилось. И как мы ими пользуемся? Ну, смотрите, вот наивная попытка. Мы читаем содержимое ячейки в
регистр, потом сравниваем его с ожидаемым значением. Это значение, прочитанное в регистр. И если, ну,
не совпало, то операция завершается провалом, да? А если совпало, то мы делаем store conditional. То
есть мы пишем в ячейку новое значение, если оно не изменилось. В чем подвох? В реализации. В том,
что вот эти инструкции, они скорее всего работают не на уровне отдельных ячеек, а на уровне целых
кэшлиний. И может быть такое, что, ну, может быть false sharing. То есть вы взяли блок такой аппаратный
на ячейку памяти, потом делаете в нее запись, но между вашим чтением и записью просто в ту же
самую кэшлинию, но в другую ячейку была сделана запись на другом ядре. И вот у вас из кэша кэшлинию
вымало. И store conditional, вот эта инструкция, store release exclusive register, она проваливается,
но не потому, что значение поменялось в ячейке, а просто потому, что, ну, вот так устроен процессор.
И вот это и есть ложно-положительное срабатывание. Вот такая реализация наивная,
она может вернуть вам false, даже если значение ячейки совпадает. Просто операция записи
провалилась, потому что кэшлиния, которую вы прочли, пропала из кэша. Понятна причина. Как
теперь на такой архитектуре сделать strong версию? Ну вот мы читаем, сравниваем, и если не совпало,
то операция проваливается. А иначе мы делаем store conditional и смотрим, как он завершился,
результат будет в этом регистре. Если он завершился успехом, то операция возвращает true. А если он
завершился провалом, то мы не знаем почему. Может быть, потому что ячейку перезаписали на другой
значение, а может быть, потому что там кэшлиния уехала на другое ядро. Поэтому в этом случае мы
пробуем заново. Вот получается такой встроенный цикл. Вот в ВИК версии в ней цикла внутри нет,
а в strong версии есть. И вот поэтому это две разные версии. Вот, а почему у нас вообще compare
exchange в библиотеке? Ну потому что на некоторых, ну потому что нельзя с помощью кассы выразить
такую семантику. То есть с помощью этих двух инструкций касс можно выразить, а наоборот нельзя,
поэтому кажется, что нельзя с такими же гарантиями. Поэтому в стандартной библиотеке у Atomic именно
compare exchange такой общий знаменатель. И какая из этого мораль? Если, ну такое правило не совсем строгое,
которым вообще можно пользоваться. Если вы пишете compare exchange в цикле, то используете ВИК
версию. На x86 разницы не будет, но на процессорах, где разница есть, не будет overhead просто лишнего.
То есть ваш цикл и так здесь исправляет вот это ложно-положительное, ложно-отрицательное
срабатывание. Да, кстати, вот на армии, если у вас есть вот такая вот пара операций, то все остальные
операции тоже выражаются через нее. То есть Fitch.at это вот, это тоже самый цикл. Вот Fitch.at на
армии реализован вот буквально так. То есть если вы скомпилируете этот код на армии, то он и
даст вам код Atomic с операции Fitch.at. Вот буквально. Это одно и то же. Хорошо, вот есть такие атомарные
операции. Но смотрите, есть такая атомарная операция. Но дело довольно плохо, потому что она
работает с одной ячейкой памяти. Вот раньше вы брали Mutex и могли сделать сразу несколько шагов
атомарно для других процессов, для других поток, относительно других поток. А сейчас вы можете
сделать атомарно манификацию только отдельной ячейки памяти. И вот в этом большая сложность
Lock-free. Раньше у вас операции над разделяемым состоянием, над структурой данных какой-то,
могут быть, могут состоять из нескольких шагов. И работая с блокировками, каждый поток видел
какое-то разумное, согласованное состояние всей структуры. Когда вы работаете с Lock-free,
у вас локов нет, и разные потоки работают вместе, одновременно трогают по одной ячейке,
и в итоге могут наблюдать друг друга и какие-то промежуточные состояния вашей структуры данных.
Это гораздо сложнее. Можно ли это обойти? Можно ли работать сразу с несколькими ячейками памяти?
Ну давайте совсем коротко расскажу, что иногда можно. Вот, скажем, есть на интеллах такая
особенная инструкция compare exchange 16b. Она означает, что у вас есть CAS сразу на двух соседних
машинных словах. В каких-то жизненных ситуациях это может вас здорово выручить, вообще говоря.
Но это операция специфичная для конкретного процессора, поэтому у нас к ней доступа нет.
Есть еще такая штука, как транзакционная память в интеллах, опять же. Это такая оптимизация,
которая позволяет вам на уровне процессора запускать транзакции, которые атомарно читают
и пишут сразу несколько ячеек памяти. И все это реализовано очень эффективно, прямо через
протоколк эгерентности. Вот протоколк эгерентности — это такой механизм для обнаружения конфликтов
буквально для хардварных транзакций. Но я про это пока не рассказываю, и, может быть, вообще не
рассказываю, скорее всего не рассказываю, потому что это всего лишь оптимизация. Это не может быть
решением задачи. Вот железная транзакция, аппаратная транзакция в процессоре, она может прерваться
просто потому, что она ступила себе на ногу, потому что она вытеснила свою же ячейку, свою же кошелинью
из кыша. Такое может случиться, это неприятно. Поэтому для таких транзакций должен быть обязательно
фолбэк на какое-то более надежное решение, вот на лог-фри или на блокировку. Так что мы остаёмся
с кассом. Но, оказывается, и про это я, может быть, тоже не расскажу вам, что касс — это, короче,
силу атомарных операций можно прямо измерить числом. Вот можно сказать, насколько хорош фич-эт,
насколько хорош касс. Вот, оказывается, что касс в бесконечный раз лучше, чем фич-эт. И с помощью
касса можно сделать всё, что угодно. В частности, можно с помощью касса сделать мульти-касс. То есть,
операцию, которая атомарно сравнивает сразу много ячеек, а потом атомарно их перезаписывает. И это,
разумеется, уже будет не инструкция процессора, это будет целый лог-фри алгоритм. И в какой-то
из последних лекций, когда мы будем говорить про лог-фри, реализацию канала и селекта в языке
котлин, я расскажу вам, как эту штуку можно сделать, как её можно воспользоваться, самое главное,
и зачем её вообще пользоваться. Но сегодня это слишком сложно для нас, поэтому мы будем работать
просто с одним кассом. Всё, что у нас есть, это один касс. Давайте с ним жить. Ну и что мы будем
делать? Мы, давайте, наконец, что-нибудь полезное сделаем. Давайте сделаем что-нибудь с гарантией
лог-фри. Мы поступим странно и сделаем лог-фри стэк. Вот не знаю, какие у вас ожидания. Делать,
скажем, лог-фри стэк выглядит, возможно, не самой полезной задачей на свете. Зачем в конце концов
стэк? Вот вам нужен стэк в жизни вообще? Часто вы им пользуетесь? Нет. Когда вы пишете промышленный
код, вы никогда не пользуетесь стэком, примерно никогда. Но для нас стэк, на самом деле, это более
хитрая штука. Лог-фри стэк – это совсем не контейнер для хранения данных. Вот оказывается,
что хороший Mutex устроен примерно как лог-фри стэк. И это совершенно не очевидно сейчас. Но если вы
будете решать домашнюю работу, если вы решите Exeggutor, напишите там Strand, а потом напишите
лог-фри Mutex в задаче Prom Mutex, вот здесь вот, то, вот здесь вот, то, возможно, вы удивитесь,
что внутри там будет почему-то лог-фри стэк. Так что пока я подробно не объясняю, зачем нам
лог-фри стэк, когда-нибудь мы в это увидим. А пока мы просто считаем, что вот давайте сделаем
структуру данных многопоточную с операциями push и pop, tri-pop, с которой могут работать разные
потоки, в которые нет взаимного исключения и есть глобальный прогресс. Как мы будем этот стэк
делать? Мы будем представлять стэк в виде односвязанного списка. Ну и забегая вперед,
вообще все лог-фри это, как правило, списки, даже массив лог-фри тоже списки окажется. В этом
списке узлы хранят значение, ну и указательный следующий узел. Голова вершины стэка — это
голова односвязанного списка. Ну и давайте теперь напишем операции push и tri-pop. Задача ясна,
что мы сейчас собираемся делать. Вот сделать push в голову стэка, в вершину стэка односвязанного
голова односвязанного списка и pop забрать узел значения из головы односвязанного списка.
Ну с чего мы начнем? Наверное, мы алоцируем узел. Тут есть некоторый подвох, потому что,
возможно, вы уже проиграли лог-фри. Потому что, может быть, в вашем локаторе есть блокировки,
скорее всего, там есть. Поэтому формально... Кот перестал только что быть лог-фри. Но все-таки
в локаторе на быстром пути локов нет, как правило. То есть он редко заходит, все-таки хороший локатор
редко берет локи. Поэтому, ну, такое вот некоторое несовершенство уже. Ну чем, если он будет часто...
Редко, потому что он хочет... Ну, потому что это синхронизация. Локатор там, не знаю, может быть,
в тред-локальном кэше уже что-то хранит, чтобы локации обслуживать без синхронизации. Ну,
хороший локатор так непременно делает. Вот. К мютоксам и к синхронизации хороший локатор
прибегает в последний момент. Давайте ускоримся. Дальше мы хотим этот узел вставить в голову
списка, в голову стека. Ну вот давайте прочтем текущую голову. И прицепим к ней наш узел.
Вот. А дальше, если мы пытаемся сделать вот так вот, то, наверное, это будет довольно провально.
Потому что зашли два потока, в пушь сделал, алоцировали свои узлы, прицепились к голове,
а потом обе перезаписали голову, и в итоге одна из тавок потерялась. Видимо,
мы хотим здесь сделать запись, но только если голова по-прежнему та же. Ну, смотрите,
что так и просится сделать. Наверное, нам нужен кастлуп. Вот мы прочитали топ, подвесили к нему
текущий свой узел, а потом, если топ не изменился с момента нашего чтения, то мы перезаписали его
на себя. Да? Ну вот, кастлуп, мы читаем текущее состояние стека, меняем его, возможно, и пытаемся
зафиксировать изменения с помощью каст. У нас свик-версия, потому что зачем нам стронг? Если
даже каст ошибся, он попробует заново. Ну вот, тот же самый код понятен, он очень прост,
давайте если что-то непонятно, то лучше сейчас узнать. Ну как, мы ацируем узел, читаем голову стека,
пытаемся к ней прицепиться, а теперь попытаемся поменять топ на себя. Мы хотим, чтобы в ячейке топ
были написаны мы теперь, но мы хотим сделать такую перезапись, только если с момента нашего
чтения топ не поменялся. Потому что, если мы напишем такой код... Нет. Ну как, мы сначала цепляемся
к голове, а потом вставка в односвязанный список, в голову односвязанного списка. Да,
ну а куда еще, мы же с головой работаем все время. Понятно, да? Вот, код можно написать чуть
аккуратнее. Вот как было замечено, можно вынести все это и вообще написать вот так вот. Сэкономить
усилия. Нет. Мы не пытаемся себя подставить в качестве следующего. Мы... Вот, Джон. Ну, сейчас...
Ну и вообще стоит написать, наверное, вот так. Мы читаем картоп, подвешиваемся к текущей
голове, а потом пытаемся, если эта текущая голова не изменилась, она написана здесь,
то пытаемся поменять ее на себя. А если проверка провалилась, то мы здесь увидели новое актуальное
значение топа. Сюда его перечитали. Вот, теперь пишем tri-pop симметрично. Ну тут, я надеюсь,
уже без комментариев особых обойдется. Если список пустой, если стэк пустой, то мы говорим,
что ничего нет. Иначе мы что пытаемся сделать? Мы пытаемся сдвинуть топ вперед. Мы ожидаем там
сейчас текущее значение, а хотим записать current top next. И вот если получилось, то мы извлекли
current top из головы стэка. Похоже на стэк? Вот, и можно его даже запустить и убедиться,
что он работает. Вот у нас стресс-тест, там потоки кладут стэк, потом берут из стэка и ожидает,
что сумма пуши и попов, она сойдется. Довольно естественное ожидание. Давайте этот тест запустим.
Ну, сначала потерпим, потому что опять не собрал позиторию вовремя.
Пока поищем стэки баги. Вдруг они у нас есть? Вдруг я их написал здесь неосторожно. Ну,
я не просто так написал этот код. Давай оставим все как есть. Итак, он не работает. Ну, значит,
мы где-то ошиблись, и вы невнимательно смотрите за лекцией. Ну, давайте искать, где я ошибся.
Аллоцируем узел, читаем голову, цепляемся к ней, и потом, если не compare and change new node,
next, new node, мы меняем top. Здесь вроде все правильно, да? А тут?
Kartop от локальной переменной.
Какая строчка? Локальная переменная. Ну, здесь мы увидели, значит, пустой стэк. Что ж плохого-то?
Что? Ну, там стэк развалился совсем. Он почти ничего не сделал. А, возможно... Ну,
потому что другой код запускается. Запускается неправильный код, а правильный код не запускается.
Вот, все работает. Ну, осторожно. Значит, варианты сошлись. Просто в коде утечки. Вот,
и это неудивительно, потому что я в коде написал new, а дырить не написал. Это было...
Это было странно. На самом деле, это было не странно, потому что, если его написать,
лучше не станет. Станет хуже. Потому что теперь у нас use of the free. Ну, и еще бы,
чего вы хотели. Смотрите на нашу реализацию. Смотрите на pop. Вот у нас есть tri-pop. Приходит
поток t1. Стэк сейчас выглядит так. Приходит поток t1. Он читает в current top. Я пишу abc,
в смысле адреса узлов. Читает адрес a. Потом приходит t2. Он читает current top b. Ну,
и дальше t2 завершает свой tri-pop. В частности, в нем t2 делает... Что? Дырит a. А теперь просыпается
поток t1, и он увидел a, и он делает этот касс. И в чем беда? Ну, беда вот в этом месте. Разумеется,
сам касс, он не может завершиться успешно, потому что current top уже поменялся. Ну, на самом деле,
это еще сложнее. Но вот беда не в том, что у нас здесь написано не null pointer, а тут теперь null
pointer. Беда в том, что мы идем вот под эти висящие ссылки теперь. Мы читаем поле next по адресу,
который уже освобожден. И вот здесь возникает user-free. Что значит заранее? Вот здесь прочитать.
Я боюсь, что... Зачем я трачу это время? Боюсь, что то же самое здесь произойдет. Какая разница?
Это не поможет никак. Управление памятью здесь сломано. И как можно было бы поступить? Проще
всего переписать это все на язык, где вы дырит и не пишете руками, где у вас есть автоматическая
сборка мусора. Вот писать lock-free на языке с автоматической сборкой мусора гораздо-гораздо
проще. Вот я утверждаю, что вообще сложность lock-free не вот в этом коде, а в коде управления памятью.
Ну, как можно еще было бы поступить? Смотрите, мы здесь освобождаем память, на которую ссылается
а потом читаем посылки. Ну вот сборки мусора у нас нет, но может быть мы хотели бы сделать
какой-то ручной референс каунтинг. Ну, смотрите, хочется использовать shared-pointer. Но shared-pointer,
вы, кажется, не чувствуете проблемы пока. Shared-pointer, они немного поточные совсем. Вот мы берем
shared-pointer и в одном потоке пишем в него, а в другом потоке читаем. Конечно же,
нет никакого атомика от shared-pointer. Ну, я объясню, что вы попробуйте его написать. Я думаю,
что его напишет полтора человека в аудитории. В смысле, что такой атомик shared-pointer это атомик,
который читает shared-pointer. Сейчас, давай разберемся просто с shared-pointer. Вот shared-pointer,
в нем атомарный счетчик ссылок, но он совсем не многопоточный. Почему? Потому что, ну вот вы в
одном потоке читаете shared-pointer. Что вы должны сделать для того, чтобы его прочитать, скопировать
его? Вы должны пойти в control-блок и увеличить референс каунт. А другой поток перезаписывать
этот shared-pointer. И вот вы здесь прочли pointer на control-блок, потом другой поток,
благополучно shared-pointer, опустил нем счетчик до нуля и control-блок удалил. А потом вы увеличиваете
по этому pointer счетчик ссылок. Мне кажется, что мы это уже только что видели. Вот так что сам
по себе shared-pointer не помогает. Но, возможно, вы хотите воспользоваться лог-фри, атомик
shared-pointer. Так тоже можно. И вот лог-фри-стэк на атомик shared-pointer выглядит как нормальный
лог-фри-стэк. Вот ничего сложного там нет. Только у вас теперь не атомик от node-звездочки, а атомик
от shared-pointer. Но shared-pointer такая сложная штука, это явно не атомарная инструкция в процессоре.
Это какой-то дико навороченный, дико запутанный лог-фри-алгоритм. Вот, поэтому мы пока пренебрегаем
всем вот этим, мы считаем, что у нас пока его нет, мы его пока не написали. Кто-нибудь из вас,
возможно, его напишет, но это очень сложно. Можно потратить, скажем, неделю времени и не написать
его. Будьте осторожны, когда вы пишете атомик shared-pointer. Но, тем не менее, вот так задачу можно
было бы решить, но с большим overhead-ом, потому что это некоторый более общий инструмент,
он не знает про специфику нашего stack-а. Можно было бы проще. Почистить в конце – это все равно,
что не чистить. Ну, потому что программа работает бесконечно, демон работает бесконечно,
никакого конца нет. 24 на 7. Это не поможет. Ну, давай объясню, почему, раз мы об этом говорим.
Можно было немножко жульничать и сказать, что давайте вот мы вытащили узел stack-а,
мы не будем его удалять, а мы вместо этого прибережем его на будущее, положим его в pull,
в другой lock-free stack. И когда нам понадобится узел, мы оттуда достанем и повторно положим,
повторно будем его использовать. Ну, то есть, смотрите, что я хочу сделать. Я хочу сделать
такой интрузивный stack. У него есть операция push и tri-pop, но тут просто я получаю готовый узел
и просто его запихиваю в stack. А здесь я его извлекаю из stack-а и не думаю, как с ним работать.
И теперь, что я делаю? Я пишу такой вспомогательный аллокатор. Когда я делаю операцию push,
я у этого аллокатора беру ноду, в нее кладу значения и кладу эту ноду в stack с данными.
Когда я делаю pop-ы stack-а, я извлекаю узел из stack-а, беру оттуда значения, а потом возвращаю узел аллокатора,
который сам по себе тоже lock-free stack. Раз stack, два stack. Понятно, да? Ну, то есть,
мы так перекладываем между двумя stack-ами эти узлы. Будет ли это работать? Ну, кажется,
я уже показал. Не должно. Почему не должно? Потому что аллокаторы системные, они уже делают пулинг,
они уже переиспользуют память. Поэтому мы всего лишь написали руками кусочек аллокатора. И было
бы странно, если бы он заработал. Смотрите, что происходит. Ну, да, теперь мы память не удаляем,
мы ее переиспользуем. И вроде бы вот висящей ссылки быть не может уже. Ссылки на узел,
который освобожден. Ну, ссылка на переиспользованный узел может быть. Смотрите,
вот это называется ABA-проблема. У нас был stack с данными, ABC, и был вот пул аллокатора.
Пришел поток T1, прочел в current top A, прочел в current top next B, готовится сделать CAS,
переставить голову stack с A на B. Потом приходит поток T2. Он извлекает из stack узел A, извлекает
из stack узел B и возвращает память аллокатора. Вот теперь такая конструкция. В данных узел C,
в пуле узлы B и A. Да? А теперь поток T3 приходит и делает push. Он из пулы A берет узел B и
засыпает. Потом приходит поток T2, он тоже делает push, он из пулы A берет узел A и кладет его на
вершину stack. А теперь просыпается поток T1, и он делает compare exchange с A на B. Схватили
проблему? То есть, у нас раньше stack был ABC, на вершине было A, а теперь stack стал AC. Но
поток T1 думает, что stack не изменился, потому что на вершине по-прежнему узел A. И он
переставит эту вершину stack на узел B, а узел B вообще не в stack сейчас. И вот мы разломали память.
Вот. Это называется ABA, и вот она у stack есть. Беда. Как быть? Очень сложно, я не буду рассказывать.
На семинарах поговорим, и в домашке вы напишете. Если захотите, конечно. Ну потому что сложность,
она не в этом. Она не в... Сложность не в лог-фри-стэке. Вот такой stack напишет и ребенок в конце концов.
Сложность, ну, тем более вот такой с дыритом. Сложность в том, чтобы сделать дырит и при этом
ничего не разломать. Вот это настоящая сложность лог-фрик, особенно когда вы пишете на C++. Но если
вы пишете лог-фри-мьютакс, то вам предлагается подумать. Потому что было бы странно, просить
вас написать лог-фри-мьютакс и при этом говорить, что я вам не рассказываю, как написать хороший
лог-фри-стэк. И при этом говорю, что stack – это мьютакс. Мьютакс – это stack, вернее. А может быть,
это все слишком непонятно, вы меня просто не слушаете. Так тоже можно. Ладно, давайте про stack
закончим. Мы в какой-то степени его сделали, а в какой-то степени нет. Давайте мы в такой же
степени, непонятно, сделаем теперь очередь. То есть структура данных будет сложнее. Итак,
проблемы у нас те же самые будут с проблемой памяти, но мы пока заботимся про сам контейнер. Мы делаем
очередь. И очередь – это будет тоже односвязанный список. У него будет голова и хвост. И голова – очереди.
И список ориентирован от головы к хвосту. Извлекаем мы отсюда, добавляем мы вот сюда. И у нас
будут два поинта. Head и tail указывают на первый узел списка, на голову и на хвост, соответственно.
И чтобы избежать некоторого… Да, и вот узел списка. Next, теперь atomic, но скоро увидим почему.
Очередь у нас немного сложнее, поэтому мы себя хотим обезопасить от граничного случая,
когда очередь пустая. Поэтому мы скажем, что очередь пустой не бывает. В ней всегда есть такой
узел Sentinel, который в себе значение не содержит. Он просто… Логически пустая очередь – это очередь
из одного физического узла, без значения внутри. Как из этой очереди извлечь голову?
Ну, в смысле, мы хотим извлечь первый элемент из очереди. Ну, я понимаю, что такой очередь с вами.
Как ее написать? Ну, кажется, что извлечение из головы очереди – это извлечение головы из
односвязанного списка все еще. Поэтому, кажется, TRI-POP должен быть устроен каким-то похожим образом.
Да, я не сказал, у этого стека, который мы изучили, есть свое имя – это stackTriber, а очередь,
которую мы сейчас пишем, называется очередь у Майкла Скотта. Вот так их можно в интернете легко найти.
Итак, что мы делаем? Как обычно, мы читаем голову. Если… Это Sentinel. Как узнать, что очередь пустая?
Ну, вот тут нужно еще кое-что другое написать, но я пока не стану. Если очередь… Если голова… Если
Next в голове указывает на no pointer, то, видимо, очередь состоит из одного физического узла – это пустая
очередь. Ну, а иначе мы делаем какие-то привычные вещи. Мы пытаемся передвинуть голову вперед. Мы
ожидаем увидеть, что currentHead хотим currentHeadNext. Если так получилось, то значение мы возьмем отсюда.
Понятно, да? То есть мы извлекли один узел, а значение взяли из следующего. И вот этот
следующий узел, следующая голова сама стала теперь Sentinel. То есть мы передали эту роль дальше
по очереди. Вот. Ну и снова мы здесь, видимо, не пишем the read, оставляем это до лучших светлых
времен. Да, Машке вы тоже напишите. Это делать на другим способе, не таким, как для стэк.
Tripop готов, потому что тут ничего принципиально нового не происходит. Вот. А push – он меняется,
потому что push теперь в два раза сложнее. Почему в два? Потому что… Ну, что такое push в конец
односвязанного списка? Нам нужно к последнему узлу прицепить еще один, а потом передвинуть tail.
И вот в этой операции мы уже трогаем две разделяемые ячейки памяти. Мы трогаем next у
последнего узла, и это могут делать разомного потока. А потом мы двигаем тоже общий tail. Вот
две ячейки памяти. Если бы у вас был mutex, то было бы просто. Взяли бы mutex, потрогали бы две
ячейки и всё. Отпустили бы mutex. Mutex теперь нет. Поэтому два этих шага, вообще говоря, теперь они
наблюдаются разными потоками. Ну ладно, давайте не будем пока плохого, давайте писать. Мы лазируем
новый узел. А дальше… Напишу пока так, потом объясню зачем. Читаем хвост.
Если… Ну и мы хотим прицепиться к next у текущего хвоста. Но может быть,
тут написано не null pointer. Что это значит? Что прямо сейчас выполняется какой-то конкурирующий
push. Согласны? Ну отложим нашу вставку. Если же current tail next null pointer, то есть у нас
есть теперь pointer на последний узел в списке. Ну давайте попытаемся этот null pointer поменять на себя.
Согласны? Это первый шаг. Вот, а второй шаг. Второй шаг.
Положили себя в tail. Пишу ерунду, простите. Мы пытаемся прицепить себя к хвосту списка,
если получилось, то вот мы пишем tail sort. Где? Я так не думал. Ну сейчас. Да, но нет. Вот,
это похоже на правду. Я где-то ошибся. Я ошибся, потому что у меня value в узле это на самом деле
optional и мне нужно написать вот так. И добрось. Сейчас узнаем. Ну что ж, очередь работает. То есть у нас
снова течет, но по крайней мере сколько в него положили, столько потом и достали. Правда есть
беда. Вот смотрите, что умеет наш framework. Он умеет тестировать lookfree. Каким образом? По
определению. Вот можно вставить в исполнение нового adversary, который перехватывает сбои,
и он будет вести себя так. Он может не только потоки переключать как-то хаотичным образом,
а он может их парковать. Ну что такое lookfree? Пауза бесконечная какого-то произвольного
потока между любыми инструкциями не должна привести к тому, что остановится прогресс,
что вызовы перестанут завершаться. Что делает наш stress-тест? Он вот в этом adversary иногда
паркует потоки на бесконечное время. И при этом он просит, что, пожалуйста, когда вы завершаете
вызовы на очереди, то сообщаете мне отверстие, что они заканчиваются, что прогресс происходит.
И если отверстие останавливает поток, а потом после этого в него сыпется сообщение, что вызовы
завершаются, видимо, реализация lookfree. А если вызовы перестанут завершаться, то, видимо,
не lookfree. Ну и давайте узнаем, является ли наша реализация lookfree. Ну, не является, она зависла.
Почему? Где нужно было остановить потоки, чтобы другие потоки не смогли завершаться?
Ну смотри, у нас здесь два шага. Первый шаг, второй шаг. Первый подвесится к концу,
второй передвинут tail. И вот здесь мы, смотрите, видим на шаге 1, что другой поток прошел через
шаг 1, но, возможно, не прошел через шаг 2. Ну вернее, как мы сначала прочли tail,
потом прочли tail next, и видим, что там не был pointer. Может быть, за это время tail уже
поменялись и сдвинули вперед, и все нормально. А может быть, другой поток просто уснул между
цеплянием своего узла и передвижением tail. И вот это конкурентный push, но он не завершится больше,
его остановили. А мы его здесь ждем, мы крутимся, пока он не завершится. Вот этот код, в нем нет
блокировок явных, ну в смысле, у него нет локов, но он не лок-фри, потому что он все еще ждет другого
потока. По сути, он такой спинлок вот в этом месте. Что делать? Что? Мне кажется, ты неверно
истолковываешь суть. Засыпать можно в лок-фри, это отдельная история, я про него тоже сегодня не
успею. Давайте, у нас осталось совсем немного времени, придумаем решение. Ну, смотрите,
у нас есть операция, она пришла, увидела, что другая операция, возможно, находится между первым и
вторым шагом. Что ей нужно сделать? Нашей текущей операции. Мы же не знаем, чего ждать,
другая операция никогда не завершится, просто никогда. У нас лок-фри, поток может остановиться
на бесконечное время. Ждать некого, надеяться не на кого. Ну, сейчас самому мы не можем, у нас уже
как бы другой push in progress. Откатиться это не прогресс, нужно докатить, нужно помочь другой
операции завершиться, чтобы нам она не мешала. Вот она уже подвесила свой узел, но не передвинула
тейл. Давайте ей поможем. Вообще говоря, она может помощь ей не просить, может быть она работает,
но мы здесь этого не понимаем, поэтому мы вот так вот консервативно попробуем. Что я хочу сделать?
Вот так вот. Вот это help, это базовая техника в лок-фри. У вас операции могут быть сложные,
составные. Вот если вы видите, что другая операция между двумя шагами находится,
то попробуйте ей помочь. Нет, ну вообще лок-фри нет никакого общего решения. Mutex такой общий
инструмент. Лок-фри это такое искусство изготовления, вручную структуру данных,
такой крафтовый искусство. То есть ты вот строишь, мастеришь свою специальную реализацию. Люди этим
занимаются очень долго. Написали миллион статей, как сделать крафтовый лок-фри стэк, мют, стэк,
очередь, хэш-таблицу. Больше особо ничего не делали. Там вот много разных способов. Здесь касс,
потому что можем помогать мы, а могут быть другие потоки, которые тоже помогают. Вот мы решили
помочь, а другой уже помог, и все убежало вперед, поэтому мы не можем просто стор сделать. Мы делаем
касс. Понятно, да? Вот, запускаем и смотрим, помогло ли это. Нет, работает. Ну, утечки памяти,
но работает теперь, потому что это лок-фри уже. То есть вот здесь вот пауза отдельного потока не
приводит к простою. Но есть одна беда. Вот смотрите, я здесь извлек узел, а потом напишу в нем
что-нибудь такое. Ну, просто какой-то мусор в адрес напишу. Почему нет? Могу я написать так
или нет? Я же извлек узел уже. Вот, все разломалось снова. Почему? Потому что мне еще кое-что нужно
сделать. Вот я здесь пишу, смотрите, на шаге два, tail store new node. Вот, я, смотрите, зашел в push,
я привязал свой узел к концу списка, потом я заснул, tail подвинули вперед, прошло очень
много вставок, а потом я взял и сбросил tail назад. Куда-то далеко в прошлое. Я не учел,
что мне могли помочь. Поэтому здесь я тоже должен вот это закомментировать и написать здесь.
Ну, и не знаю, мне чувствует прекрасно, почему-то от меня требуют, чтобы я написал здесь compare
exchange strong, хотя это вроде бы совершенно необязательно. Вот, если мне не помогли,
то я сам уж точно доделаю. А если помогли, то мой кассо уже ничего просто не сделает.
Ну, еще раз, вот я для этого вам это и рассказываю, что не нужно так рассуждать. Это неправильное,
это наивное рассуждение. То есть нельзя заменить сложную реальность простым правилом. Ну,
какая разница? Если даже наш касс провалился, на следующей этой рации какой-нибудь push
дотолкает. Ну, кто-нибудь вот здесь дотолкает в крайнем случае, поэтому проблем на самом деле нет.
Так что можно было бы написать wick. Ну, вот мне так чувство прекрасного диктует, что все-таки push,
вот если ему не помогли, то уж сам он точно должен завершиться. И не знаю, может быть,
даже для линейзуемости это, наверное, не очень важно. Ну, в общем, вот так. Ладно, давайте какие-то
заключительные слова, но заканчивается время. Не блокирующая синхронизация – это альтернатива,
не вютоксом. Вот можно приделать к лог-фри реализации ожидания. Это называется even count.
Вот если вы писали кондвар, то в принципе можно почти что как кондвар сделать кондвар для
лог-фри. Он будет немного хитрее устроен, намного хитрее устроен, но в принципе как вютокс,
в принципе как ваш кондвар. Только вы его логику немного размотаете наружу. Но наша лекция не про
это, а про то, как строить примитивы синхронизации, как строить структуры данных, как работать с
разделяемым состоянием, не используя мютоксы. Потому что мютоксы – это блокирующий примитив,
и если поток вытеснен под блокировкой, то глобальный прогресс остановится. Мы хотим использовать
не блокирующую синхронизацию, где пауза отдельного потока не влияет на другие. И вот у нас дальше
будут задачи, и во многих, в разных местах можно будет использовать именно лог-фри. Чем больше
лог-фри, чем больше глобального прогресса, чем меньше зависимость от планировщика, тем в итоге
меньше простоев на уровне исполнения будет. Тем меньше потоки будут зависеть друг от друга от того,
как они исполняются, как их планирует планировщик, когда он их вытесняет, когда нет. Понятная идея?
Тогда мы готовимся к семинару, где вам расскажут, как во всех этих примитивах управляться с
памятью, а через неделю мы поговорим про то, как сделать из нашего медленного тредпула очень
хороший и очень сложный тредпул, который будет исполнять вот именно файберы, именно карутины,
именно фьючи максимально эффективно. На сегодня все, спасибо.
