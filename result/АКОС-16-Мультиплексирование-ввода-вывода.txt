так тема сегодняшней лекции это продолжение с сукитами но в данном случае не только с сукитами
еще и с вводом-выводом давайте вспомним что такое сокет и просьба выключить микрофон если вы не
говорите что такое сукит это по сути некоторые файлы дескриптор файлы дескриптор это целое число
которое однозначно идентифицирует некоторые объекты ввода-вывода и с ним можно вытворять все что может
делаться обычными файлами дескриптора как мы получаем такие файлы дескрипторы и так можно
обработать ситуацию когда у нас получаются такие дескрипторы
вот рассмотрим обычный сервер который делает что-то очень полезное серверы бывают разные
например веб-сервер или это может быть ssh-сервер телнедсервер куча разных полезных применений что
должен делать сервер он должен создать сокет затем этот сокет связать с каким-то именем что
такое имя сокета это либо пара
двух чисел ip-адрес плюс номер порта либо просто какое-то локальное имя файловой системы если это
unix-сокет затем если мы сокет планируем не подключать к кому-то а сами принимать подключение
то нужно переключить режим прослушивания создать очередь на входящие подключения после чего брать
по одному соединению и уже дальше использовать стимулированный read-write для того чтобы общаться
это все хорошо когда у вас клиент один что если клиентов много здесь возникает проблема что у нас
есть какие-то блокирующие операции в нашей программе а именно сетевый вызов и read-write как они себя ведут
они пытаются что-то прочитать пока данные есть а сетевый вызов и read-write пытаются записывать пока есть место в буфере
когда вы взаимодействуете ровно с одним клиентом то все хорошо и замечательно
если клиентов несколько какая проблема возникает вы начали работать с одним клиентом все остальные
клиенты что нужно делать наверное мы должны подождать что не очень хорошо какой же это сервер если он
работает только один на один хотя должен работать со мной какие тут варианты решения этой проблемы но самое простое
очевидно из того что вы уже знаете уже умеете это сделать форк после того как примите очередное подключение
почему форк будет работать потому что при создании копии процесса у нас некоторые атрибуты процесса
не следуют в начальном процессе в том числе открытые файловые дескрипты если вы принимаете подключение после этого
делаете форк то родительский процесс может смело принимать следующие подключения от новых клиентов
а дочерний процесс уже взаимодействует непосредственно с новым клиентом
с тем клиентом ради которого он будет создан на самом деле это очень распространенная практика многие серверы так и работают
это достаточно надежный механизм потому что если дальше в процессе работы с каким-то отдельным клиентом
у вас возникнет какие-то проблемы которые могут привести всяким нехорошим последствиям вот до сегментешен флот
то других клиентов вы просто не заметите
вы
В каждом процессе общайтесь с отдельным клиентом, между
собой процессы никак явным образом не связаны, и клиенты
не мешают друг другу, есть полное изоляция.
Но здесь, если все-таки логика подразумевает, что
вы должны как-то организовать взаимодействие ваших клиентов,
то простым способом это не сделать, тут приходится
уже придумывать всякие обходные пути и межпроцессное
взаимодействие.
Так, в принципе, как избавиться от проблемы межпроцессного
взаимодействия, которые возникают при работе с
несколькими клиентами.
Кроме процессов есть еще такое понятие как бесконечные
процессы.
Их еще называют треды, их еще называют нити.
Так, у вас еще идет параллельно курс теории, практики англопоточной
синхронизации.
В этом уже успели изучить такое понятие, как потом
знать что-то.
То есть, в рамках одного процесса, если вы понимаете,
что вы можете создавать несколько потоков, и в принципе
все клиенты, вы все клиенты можете обрабатывать в отдельных
потоках.
Здесь решаются проблемы межпроцессного взаимодействия,
которые не нужны.
Так, добавился много других проблем, многопоточная
синхронизация.
Но это иногда решать проще и комфортнее, по части
оплаты в частности.
Но опять же здесь не решается основная проблема с большим
количеством подключений, то, что у вас на каждое подключение
должна быть одна задача, то есть когда звучит поток,
и чем же это плохо?
Плохо это тем, что это тяжело.
Что процесс, что поток, они достаточно тяжелые сущности.
Ну, кстати, по поводу того, как это все реализовано,
вот такая схема классического, как сейчас на данном слайде,
это обычный веб-сервер под названием патч.
Схема его работает.
То есть чем плохи процессы и потоки, в общем-то, тоже.
То, что при создании процесса или потока вам требуется
создать новую сущность планировщика заданий, это
подразумевает как создание новой сущности планировщика
заданий, так и выделение памяти, поскольку как минимум
у каждого потока, тем более у процесса, есть выделенная
область памяти, которая называется степ.
Вот.
По умолчанию в большинстве линук-систем размер стека
– это 8 мегабайт.
Можно, конечно, сделать поменьше, для процессов
настраиваться через Ulimit, для потоков это тоже можно
настроить и сделать это сильно меньше, но, тем не
менее, если у вас количество клиентов – это десятки,
то такой подход, он вполне себе приемлем, если у вас
количество клиентов уже исчисляется тысячами, то,
например, у вас будет много клиентов, то, конечно,
есть из них тысячи, то это становится очень дорого.
Ну и как можно эту проблему решить?
Вот, я как-то уже упоминал, что файлодескрипторы могут
быть неблокирующими.
Ведь основная проблема в чем?
У нас есть две стадии, которые тормозят взаимодействие
с другими клиентами.
В первых системах вызова read и write, во-вторых, есть у нас еще система вызов accept. Read и write у нас блокируются, если нет данных от клиента, то есть вы работаете с медленным клиентом, например. А accept у вас будет блокировать всю цифровую выполнение в том случае, если у вас не поступает наук подключения.
Вот если все это сделать не блокирующим, то, казалось бы, мы можем эту проблему решить. И как эта проблема может быть решена?
Есть такой замечательный заговорочный файл из некоторых нечитабельных букв, потому что в том названии только согласный, не одногласный, FCNTL. Название очень страшное, эрудимент еще в 70-е годы, когда экономили каждый символ.
Файл control, это просто такое сокращение. И там есть одноименный степный вызов. На самом деле, этот заговорочный файл вы видели достаточно часто, когда открывали файлы. Собственно, степный вызов open, он там же и объявлен.
Вообще, работа с файловыми дескрипторами, это не только открытие файла, его закрытие, но и изменение каких-то параметров. В частности, что вы можете сделать с файловыми дескрипторами? Вы можете создать его клуб.
С помощью системы вызова DAT или DAT2. Вы можете установить блокировку на файл с помощью системы вызова FLOG. И хотя есть отдельный системный вызов, который это делает, просто по соображениям совместимости, многое из этого можно реализовать как библиотечное высказывание функций поверх всего лишь одного системного вызова файл control, который просто берет некоторый творческий аргумент файловый дескриптор, какую-то команду, что нужно сделать.
В частности, файл control нам может быть полезен для того, чтобы узнать флаги открытия файла и, возможно, установить какие-то новые.
Но какие вы помните флаги? Флаг только для чтения, флаг только для записи.
Опять же, в Unix API есть одна особенность, что комбинация флагов.
Чтение и запись вовсе не дают флаг чтения плюс запись, и это есть отдельный флаг.
Зато можно делать комбинацию флагов, например, что запись в конец, либо создание файла.
И если вы внимательно посмотрите огромный список флагов, которые есть, например, в системе вызовы open, там есть флаг, который называется null.
Который нам сейчас будет интересен.
Что этот флаг означает?
Означает, что вы можете какой-то файл-дескриптор сделать у меня.
Не блокирующий, то есть при отсутствии данных у вас все равно будет возможно выполнение операции чтения, которое не будет останавливать процесс.
Но если вы файл не открываете, а уже имеете какой-то готовый файл-дескриптор, откуда этот файл-дескриптор может нам прилететь?
Например, вы выполняете систему вызов accept и уже получаете готовый созданный файл-дескриптор.
В данном случае нам может быть полезен систему вызов file-control, которая может модифицировать существующие флаги открытия файлового дискриптора.
И какие проблемы можно решать установкой флага null?
Во-первых, мы можем решать проблему с блокирующим выводом.
То есть так у нас работает файл-дескриптор.
Он работает системой вызов write и любая запись файла.
Если вы пишете куда-то в локальный файл либо файл устройства, то ядро Linux старается использовать всю возможную доступную физическую память, которая никем не занята, под бухгализацию вывода.
Тут, кстати, бывают иногда очень неожиданные побочные эффекты с ним связаны.
Если вы себе ставили Linux на реальное железо,
а на ядро Linux вы ставили Linux на реальное железо,
не виртуальную машину,
то наверняка вам нужно было сделать какую-то загрузочную флешку.
Вы скачиваете образ вашего дискриптива,
пишете команду dd, скопируете из одного файла файл устройства.
У вас все достаточно быстро может быть скопировано.
Но при этом флешка продолжает мигать, и вытаскивать ее из компьютера не нужно.
Команда dd завершила свою работу.
Сказала, что все, мы все скопировали, но на самом деле запись не произведена.
Из-за чего такой эффект возникает?
Такой эффект возникает из-за того, что запись произведена в локальный буфер.
То есть программа dd, которая копирует содержимое файла,
она честно завершила свою работу, честно выполнив системный вызов read и write.
Дальше уже задача ядра операционной системы.
Сбросить файл.
Сбросить буфер, и после этого только считается, что запись завершена.
Вот с файлами обычно проблема, что у вас закончился буфер для записи,
она не возникает, и маловероятно, что вы навопнетесь на эту проблему
используя системный вызов write.
Но кроме файлов у нас еще бывают другие объекты.
Во-первых, это пайпы.
В Linux есть размер...
Пайпа 64 килобайта.
То есть если вас никто из пайпа не читает,
а вы туда продолжаете писать,
то в какой-то момент наталкиваемся на ситуацию,
что запись невозможна, пока кто-нибудь из пайпа не прочитает.
Та же самая проблема у нас связана с сокетами TCP.
Но здесь достаточно гибкий размер буфера.
Вот есть некоторый файлик,
который вы можете прочитать с подобычного пользователя,
который содержит три числа.
Это размеры в байках.
Минимально возможный размер TCP буфера,
размер по умолчанию, который у вас сейчас используется,
и максимальный размер, который вы можете настроить.
Опять же вы можете значение дефолтное поменять до некоторого большего,
но для этого вам уже потребуется проворота.
Чаще проблема с блокировками,
с блокировками она возникает не на записи, а на чтении.
С файлами, опять же, маловероятно, что вы на эту проблему наткнетесь,
но только если у вас не очень много листов.
Системный мизофрит нам может что-то вернуть,
в том случае, если он может прочитать хотя бы один байт
из пайпа либо сокета.
Но если у вас нет даже одного байта,
байта в пайпе либо в сокете,
то, опять же, чтение у вас блокируется,
и процесс...
Что происходит с процессом,
когда он не может сделать чтение или запись?
Кто помнит?
В режим ожидания?
Да. Процесс переходит в состояние, которое называется слип,
то есть он не потребляет процессорное время,
он не расходует ресурсы,
его просто переводят в спящий режим до тех пор,
пока процесс не сможет...
какие-то данные прочитать.
Так вот, если мы ставим вот наш замечательный флагман блок
либо при открытии файла,
либо после создания файлового дескриптора,
то любые неуспешные попытки,
неуспешные – это значит, что данных нет при чтении
либо закончилось место в буфере при записи,
не приведут к ситуации,
когда процесс перейдет в состояние слип.
Ну, еще бывает состояние диск слип,
это именно файловый вот-вот.
Кстати, кто помнит, чем отличается слип от диск слип?
Напоминаю, что и слип вы можете сразу
процесс перевести в состояние зоны,
то есть в завершение.
То есть диск слип сначала в состояние раннего,
чтобы сбросить эфир,
только после этого в слип.
Так вот, если у нас есть флаг,
который позволяет не блокироваться,
то есть процесс у нас не будет переходить в состояние сна,
если у нас нет никаких данных, например, при чтении,
то стенозафрит вернет ошибку,
которая на самом деле ошибкой не является.
Ошибка – это значит значение минус один,
и в переменную ярло будет прописан код ошибки.
И есть отдельно выделенный код ошибки,
который на самом деле ошибкой не является.
На самом деле таких кодов два,
если посмотреть, например,
на системный вызов read.
Так, системный вызов read.
Вот eegl – это ошибка,
значит, что файл у нас помечен как файл
только для неблокирующего ввода-вывода,
но данных нет.
И есть еще одна ситуация,
когда никакой ошибки нет,
это просто к нам прилетел некоторый сигнал.
eenter означает, что у нас пришел сигнал,
и через segaction вы прописали поведение System5.
Помните, что бывают разные поведения?
PSD-стайл, System5-стайл.
Так вот, в PSD-стиле по умолчанию
подразумевается, что системные вызовы
должны сами возобновлять свою работу
после того, как им были прерваны сигналы.
В System5 как раз нет.
И в segaction есть flag sa-restart.
Вот если вы его не указали,
и во время какой-то длительной операции,
например, ожидания ввода,
вам прилетает сигнал,
то системный вызов возвращает значение минус один
и в ЯРНО прописывает как раз вот этот код,
что он был прерван,
с помощью сигнала.
Так вот, здесь системные вызовы read-write
могут вам честно возвращать минус один,
вы можете не ждать, пока медленный клиент
вам что-то напишет,
а переходить сразу в взаимодействие
с каким-то другим клиентом.
Впоследствии вернуться еще раз к тому же клиенту,
который нам ничего не ответил,
который не подготовил данные,
для того, чтобы попробовать еще раз
у него что-то запросить,
может быть, через какое-то время
его данные и появятся.
В случае для системного вызова accept
тут примерно такая же аналогия,
только здесь accept,
если он является неблокирующим,
то вернет значение минус один
в том случае, когда у нас нет новых подключений,
и эту ситуацию мы опять же можем обрабатывать так,
чтобы заниматься кем-то в другом клиенте.
То есть на самом деле взаимодействие
с большим количеством клиентов
мы можем организовать всего лишь в один поток.
На самом деле в реальной жизни
используется многопоточность,
просто для того, чтобы распроверить задачу
по обработке клиентов на несколько ядер процесса.
Так, если мы просто будем пытаться
выполнять неблокирующие операции,
получая ошибку переходить к обработке других клиентов
и затем возвращаться обратно к тем клиентам,
с которыми у нас ничего не получилось,
фактически мы превращаем нашу программу
в бесконечный цикл while true,
и чем это поможет?
Плохо это тем, что если у вас даже нет
никакой нагрузки реальной,
то есть, например, никто к вам не подключился,
клиентов много,
или один клиент очень медленный,
или несколько клиентов,
и они достаточно медленные и не требуют внимания.
Неважно, какая у вас нагрузка,
за счет этого самого цикла while true,
который фактически превращается
в конструкцию безусловного джампа,
у вас как минимум одно или другое процессор
будет всегда болтаться впустую,
что не очень хорошо.
Как с этой проблемой можно бороться?
Можно ставить какие-то периодически принудительные
паузы на определенное количество миллисекунд,
но это очень корявое, постыдное решение.
Все понимают, что так делать нельзя.
Чем это плохо?
Тем, что тут требуется знать некоторую константу,
а насколько именно вам нужно заснуть,
для того, чтобы сильно не нагружать процессор.
И эту константу вы в реальной жизни
не сможете оценить никогда,
потому что все зависит от того, какая у вас нагрузка.
Окей, вы можете подобрать нам константу,
если к вам никто не подключился,
никто не готов,
то раз в 100 миллисекунд
делать паузу на 100 миллисекунд,
после этого проверять заново.
Но это хорошо будет работать,
когда клиентов у вас немного.
Да, все, казалось бы, хорошо работает,
но как только клиентов становится много,
то 100 миллисекунд может быть
весьма существенной задержкой.
Но у нас есть еще и до.
И вообще говоря, ядро знает,
кто к нам подключился по сети.
Ядро знает, что мы прочитали
какой-то кусок из файлов
и можем это передать,
пользоваться тем процессом,
который занимается этими файловыми дескрипторами.
Почему бы нам просто не использовать ядро
и все его знания о файловых дескрипторах?
Для этого существует механизм.
Это нотификация со стороны ядра
о каких-то событиях,
связанных с файловыми дескрипторами.
А как это работает?
Пользовский процесс просто заявляет ядру о том,
что он хочет знать обо всех событиях,
которые возникают с каким-то файловым дескриптором.
Дальше он может вызвать специальный стимул вызов,
который ждет, пока не возникнет одно из событий,
которое было предписано ядру.
В этот момент, конечно, процесс находится в режиме сна,
но ядро обязано распутить процесс,
если возникнет хотя бы одно из событий,
которым процесс интересовался.
Казалось бы, очень простая концепция,
но она достаточно давно была реализована.
Что это могут быть за события?
Если вы хотите что-то читать,
то событием является поступление новых данных
в файл либо сайт.
Либо для системы вызова Accept
там может быть новое входящее подключение.
Также событиями значимыми являются
признак end of file,
то есть когда кто-то закрыл
противоположную сторону канала,
либо SOP.
Но также могут быть всякие дополнительные события,
например, полученный сигнал,
который мешает нам что-то дальше прочитать,
либо тайм-аут,
если вы хотите периодически все-таки
приостанавливать цикл ожидания.
Все это является событием.
И на самом деле все это было сделано
давным-давно, еще в 80-е или 90-е годы.
Да, но кто помнит историю Unix систем,
как раз в 80-е годы
появилось два разных развития.
Это BSD Unix и Unix System 4.
Поэтому весь API, который появился
уже в 80-е годы,
он может различаться в разных системах.
Современные системы Linux и FreeBSD,
ну и macOS как FreeBSD,
они поддерживают разные варианты API
из соображений совместимости.
И в этих системах существовало
два системного пользователя,
которые работали примерно одинаковым образом,
но просто с разными сигнатурами,
с разными структурами.
Один из них назывался Select,
другой назывался Poll.
В чем смысл этих системных вызовов?
Вы сканываете им
некоторый массив
из файлов-дескрипторов,
которые вам интересны.
Дальше вызываете системный вызов
Select и Warp Poll,
и они переходят в режим ожидания
до тех пор, пока не возникнет события,
связанные с одним из файлов-дескрипторов,
которые вы искали.
После этого вам нужно пробежаться по массиву
и посмотреть,
файл-дескриптор готов либо не готов
к операциям ввода-выбора.
Очень простой, казалось бы, механизм,
достаточно эффективный в некоторых случаях.
Более того, он стал настолько универсальным,
что его даже Windows портирует.
Но чем все-таки такой подход плох,
и почему сейчас новый код
не пишется с использованием
системных вызовов Select и Warp Poll?
Проблема заключается в том,
что когда у вас 10 000 подключений,
то все хорошо, все замечательно,
но на каждый вызов Select и Warp Poll
и после завершения работы каждого Select и Warp Poll
вам приходится заново пробегаться по массиву
из огромного количества файлов-дескрипторов
и проверять с каждым из них готовность,
что он действительно готов к работе.
То есть Select и Warp Poll –
это всего лишь частичное решение той проблемы,
которая, может, когда-то хорошо решалась
в 80-90-е годы, но не в современное время.
Потому что что такое 100 000
одновременных подключений?
Это совсем ни о чем.
Нормальная нагрузка на какой-нибудь
среднестатистический сайт.
Тут какой-то момент,
начало нулевых или конец 90-х,
была такая система FreeBSD,
она сейчас существует.
Там немножко по-другому реализовали механизм
под названием Select.
То есть главная проблема – это обход массива.
А еще есть такая структура,
которая называется очередь.
Чем хороша очередь?
Вы можете в конец очереди в хвост
записывать какие-то новые события,
а из головы очереди сначала вытаскивать
какие-то самые ранние события,
их обрабатывать, ну и хорошая такая структура.
Так вот, в системе FreeBSD реализовали
такую обработку событий через очередь,
которая называется очередь ядра –
Kernel-Q.
Как происходит взаимодействие с этой очередью?
Вы регистрируете точно так же,
как для SelectClickAll,
какие-то файлы и дескрипторы,
которые вы хотите мониторить.
Дальше, если происходят какие-то события,
то ядро добавляет в очередь
эти файлы и дескрипторы,
и пользовательский процесс
периодически может вытаскивать что-то
из головы этой очереди, из ядра.
При этом в ядре эти события помечаются,
как прочитанные они исчезают,
ну и дальше с ними что-то делать.
Поэтому здесь, если у вас огромное количество
файлов и дескрипторов, с которыми вы хотите
взаимодействовать, и, например,
только одна десятая часть из них реально готова,
вы честно получите от ядра
только одну десятую часть файлов и дескрипторов,
с которыми вы действительно готовы работать
и не тратить время на проверку всего остального.
Вот на базе этого механизма,
как это все делается с программной точки зрения,
очередь ядра это некоторый файл и дескриптор,
то есть похожий на файл и дескриптор объект,
идентифицируется целым числом,
их может быть несколько.
Если вас интересуют какие-то файлы и дескрипторы,
например, полученные от клиентов,
вы заполняете некоторую структуру,
где указываете, что для этого файла и дескриптора
вас интересуют события готовности к чтению,
добавляете прослушку на этот файл и дескриптор,
запихиваете это в параметры очереди.
После того, как вы все настроили,
вы задаваете еще раз системный вызов
немножко с другими параметрами,
куда передаете массив из структур
максимально возможное количество,
по аналогии с read,
которое можно прочитать количество,
но и для этого самого клиента он блокирует
выполнение до тех пор,
пока не возникнет хоть какое-нибудь событие.
Если у нас хотя бы один файл и дескриптор готов,
то он вернет некоторое целое число,
это количество элементов очереди,
которые он записал.
Вот такой простой механизм.
Дальше можно просто пробежаться по этой очереди
и обработать файл и дескриптор.
Ну и примерно в то же время
как раз появился веб-сервер.
Созданный одним из сисабминов компании Wrangler,
который называется Nginx.
Буквы страшные, тут всего лишь одногласные,
читается Nginx.
В чем особенность этого веб-сервера?
Он основан как раз на механизме очереди ветра,
поэтому он спокойно,
даже на слабых машинах,
выдерживает небольшую нагрузку.
Если лет 10 назад считалось,
что надо держать 10 тысяч одновременных подключений,
то для современных систем 100 тысяч одновременных подключений
это вполне нормальная практика.
Но, правда, здесь надо настраивать количество файлов и дескрипторов
одновременно открытых, чтобы было доступно и так далее.
Конечно, не любая доступная для двух систем по дефолту может.
И за счет чего это достигается?
Ну, во-первых, у вас есть несколько ядер процессора,
то есть вы можете задействовать несколько потоков,
какое-то фиксированное количество,
делать потоков больше, чем у вас реально есть ядер.
Это не очень осмысленно.
Ну и дальше мы просто поднимаем какие-то подключения,
обрабатываем, выдаем данные.
Данные, опять же, можно создать из памяти,
не обязательно брать из диска.
Что плохого во всей этой концепции?
Плохо то, что здесь нет никакой изоляции между разными клеммами.
Поэтому сервер Nginx,
в первую очередь используется как прокси-сервер,
который выдерживает большую нагрузку на входе,
дальше, возможно, выполняет балансировку нагрузки,
раскидывает это все по другим уже бэкэндам,
которые реально генерят контент,
ну или потоком дает стать.
То есть есть два основных веб-сервера для системы Linux.
Один называется Apache, другой называется Nginx.
Apache предназначен как внешне такое универсальное,
можно делать все, что угодно.
Запускать CGI-скрипты, делать очень простое взаимодействие с какими-нибудь бэкэндами.
Nginx на плане менее функциональный, но зато он более ориентирован на большое количество подключений.
Так, и это все начало нулевых.
Я вам рассказывал про некоторые серверы, которые есть в системе Linux.
Про это я говорил, что есть какой-то механизм,
который реализован в системе FreeBSD,
про который, наверное, не все из вас слышали.
Никого это не смущает?
Ну ладно, на самом деле в Linux то же самое.
Только называется по-другому.
И сделан тоже немножко не так.
В Linux примерно в то же время,
то есть в год 2004-2005,
в год 2006,
появился похожий механизм,
который фактически переписали с FreeBSD,
но немножко по-другому.
Назвали поля, по-другому назвали структуры.
Есть все то же самое,
называется Calipy.
Дизайн тот же самый.
Поэтому обсуждать что-то тут не очень,
но тут мы получаем некоторую проблему.
Представьте себе,
что вы хотите написать какой-то софт,
который должен работать везде,
неважно, это было сервер, FreeBSD, Mac, Linux.
Ну на Mac'е сервера это, конечно, уже экзотика.
FreeBSD, OpenBSD еще встречаются.
Особенно в каких-нибудь небольших системах.
И тут можно влиять тенденцию,
что с каждым годом эти системы
начинают расходиться друг от друга все дальше и дальше.
И, казалось бы, очень похожие концепции.
Реализуется все примерно одинаковым образом,
но приходится писать разный код для разных систем.
Как с этим можно бороться?
Либо писать какие-то куски под их дефами,
то есть проверять, что этот код нужно компилировать только под Linux,
а этот компилируют только в FreeBSD.
Либо воспользоваться некоторыми готовыми библиотеками,
которые за вас тоже сделаны.
В частности, для механизмов очередь, ядра и пол
есть библиотека Revalent,
которую потом в какой-то момент перенесли в LibEv.
И, если говорить про плюсы,
есть такой большой фреймворк, который называется Boost,
который очень не любят во многих компаниях.
И вот один из модулей этого Boost'а
как раз предназначен, опять же,
для такого синхронного взаимодействия.
И на разных системах,
используют разные механизмы,
которые, по сути, делают одно и то же.
В том числе, кстати, работает и под Windows,
где тоже есть некоторый аналог очереди, ядра.
Так, что еще есть в крови очередей?
Если вы...
Так, ну Python, по идее, у вас всех будет.
В Python, не помню, то ли с 3.6, то ли с 3.7 версии,
появились включены слова под названием асинхровые.
Встречали когда-нибудь такое?
Ну, что-то в синхронности такое, да.
На самом деле, это не только в Python,
есть еще и другие, извините, части JavaScript, Dart,
в которых есть такое понятие,
как асинхронно ориентированная программировка.
В чем оно заключается?
Если у вас есть какая-то потенциально долгая операция,
например, ввод-вывод,
который неизвестно когда завершится,
либо сетевое взаимодействие,
то функция, которая выполняет эти операции,
она возвращает не результат своей работы,
а некоторый объект, который называется future, или будущее.
В C++, кстати, тоже есть класс с таким названием,
делает примерно то же самое.
Дальше, около объекта класса future,
есть метод, правило называется ZEN,
либо еще как-нибудь,
которым можно скормить некоторую функцию,
обработчик, которая будет выполнена в тот момент,
когда данные реально будут готовы.
И эта функция выполняется.
Либо можно сделать привидительное ожидание
готовности объекта.
В некоторых языках программирования
существует конструкция под названием EVA,
ну, либо на плюсах привидительно вызвать ожидание future.
Когда объект будет готов, future.v,
как он называется.
И вот такой подход называется асинхронным,
когда вы откладываете какие-то вычисления
до тех пор, пока они не станут вам нужными.
На самом деле, примерно то же самое
еще у нас реализовано в ядре и по лиду.
Одинаково реализовано в BSD-системах и в Linux.
Называется API асинхронного ввода-вывода.
Примеры системных вызовов,
по которым можно что-то почитать
или посмотреть примеры, приведены на слайде.
Казалось бы, вот она, панацея,
красивое решение, как работать асинхронно с файлами.
Но до недавнего времени поддержка асинхронного ввода-вывода
в Linux была достаточно отвратительной.
За это ее сильно критиковал Linux.org в свое время.
Отвратительная вкладка,
а не производительность.
Поэтому особо популярным этот API не стал.
Хотя у них ядро 5.1
сделал хорошее улучшение.
Может, стало что-то и получше.
Так.
Ну и все это работает,
если вы хотите, BPUL работает с файловыми дескрипторами.
И на самом деле вы можете делать некоторую иерархию.
Что она возвращает?
Например, системный вызов epl.create.
Он возвращает некоторые instance-объекты epl в очереди ядра.
И при этом само возвращаемое значение типа int является файловым дескриптором.
Что можно сделать с файловым дескриптором?
Вы можете запихать его в другой epl.
В смысле на это?
На самом деле это очень удобная фича,
потому что вы можете делать некоторую иерархию древовидную
в ваших файловых дескрипторах.
Объединять файловые дескрипторы в группы,
и тем самым дожидаться готовности уже к определенной группе.
Вот кроме epl.create бывают еще другие специальные файлы,
которые используются только в Linux,
потому что в других системах они не реализованы.
С одним из них вы уже сталкивались.
Вызывается Signal-ID.
Помните такую штуку?
Signal-ID это специальный файлодескриптор,
из которого можно прочитать объекты по названиям информации о пришедшем сигнале.
Ну и кроме Signal-ID еще бывают файлодескрипторы, связанные с таймером.
То есть как сделать самый простой таймер на системе пользователя Linux.
Создать файлодескриптор,
в который периодически попадают некоторые объекты таймера и периодически их ищут.
Обычным блокирующим водовыводом.
Не блокирующего тут не особо есть.
Ну и еще есть event.evd,
предназначенный для общения между собой разных потоков,
куда можно передавать данные,
ну примерно как в Go-Channels.
В какую-то одну сторону.
Не будет гарантироваться на передаче данных,
потому что не будет возникать никаких проблем с мегаточной синхронизацией.
Так, ну и...
Что это за картинка от Rudali?
Такое очень позитивное что-то.
На самом деле это высокая нагрузка.
Ладно, на этом все.
Есть у вас вопросы?
Можно задавать голосом Zoom, если кто-то подключился дистанционно.
О задании.
Нам надо...
Мы делаем домашнее задание.
Надо думать о том, что во время ожидания ответа
прилетит сигнал какой-то.
Но в данном случае...
Смотрите, если вы обрабатываете сигналы,
вы можете при регистрации обработчика сигнала
поставить флаг из ареста.
И не задумываться об этом.
А если арест ставят, это значит продолжились?
Это означает, что да,
тот системный вызов блокирующий, который был остановлен сигналом,
он будет перезапущен.
И потому что у меня осталось место в этом значке.
А если не делаю обработчик?
А, то он не перелет всегда?
Нет, если вы не делаете обработчик сигнала,
то будет действие по умолчанию,
и как правило это совершенно бессмысленно.
Потому что для большинства сигналов действие это прибить процесс.
Еще вопросы?
Ну ладно, если нет вопросов,
тогда беспокойно.
