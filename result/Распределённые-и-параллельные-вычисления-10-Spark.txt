Дай позвонить, пожалуйста, если видно мой экран.
Да, и экраны вам видно.
Отлично. Прошу прощения, у меня здесь утренний кофе,
только что буквально 7 утра.
Я сейчас нахожусь в Северной Америке, именно в Канаде,
в Торонто, поэтому у нас разы по времени такой еще.
Здесь 7 утра, почти 8.
Поэтому для меня будет очень приятно,
здесь 7 утра, почти 8.
Поэтому для меня сейчас утренний кофе,
поэтому прошу внимания, пожалуйста.
Давайте познакомимся, наверное.
Может быть, я расскажу вам о себе,
а вы мне тоже вкратце кто-нибудь расскажете о себе,
о ваших интересах, что вообще изучаете,
какие у вас интересные направления, которые вам хотелось бы узнать,
изучить в плане дата инжиниринга
и в принципе про дата.
А также со мной здесь мой коллега Юрий,
с кем мы работаем в Москве на проекте,
в компании в одной,
где мы даже помогаем строить платформу Data Lake.
Юрий тоже про себя расскажет немного.
Поэтому будет здорово, если у нас будет
такое интерактивное общение.
Мне хотелось бы это делать,
почитать, может быть, уже прописано истинно для вас,
то, что вы уже другие преподаватели, вы сами изучили.
Поэтому начнем просто проходить по слайдам
и спело прерывайте меня или Юрия,
задавайте вопросы.
Можем даже перескотировать.
Будет здорово, если будет такое же общение.
Вопросы задавайте любые, как я уже сказал.
Сразу скажу, что презентация мне на английском языке.
Надеюсь, это никого не смутит.
Я буду переводить.
Я не буду говорить на английском языке.
Причина, почему я создал английский язык,
потому что самая простая причина,
потому что у меня нет русской раскладки.
У меня обязательно будет в определенное время
писать все русскими буквами.
Хоть я могу писать английскую раскладку русскими буквами,
но больше меня боится, что у меня будут очень глупые ошибки.
Ну и про дата.
Тренология IT.
Говорите на английском языке.
Потому что все книги на английском языке,
все статьи интересны на английском языке.
Даже если сейчас наблюдаю много очень интересных также
лекций, курсов ребят из Москвы,
из других городов.
Я использую уже такая тренология.
Считаю, что это очень интересно.
Иногда я даже не понимаю эту тренологию,
но все-таки источник, первый источник,
остается английским.
Английская тренология, она, мне кажется,
тоже важна для того, чтобы
читать и общаться все-таки на форумах
и на слаке.
Потому что много очень каналов на слаке,
здесь очень много.
И это очень интересно,
потому что это очень интересно,
потому что это очень интересно,
потому что это очень интересно,
потому что много очень каналов на слаке,
здесь тоже третий по датаспейс различных.
Поэтому английский.
Много себе.
Я работаю в IT уже 14 лет.
У меня такой опыт, наверное, интересный,
с одной стороны.
Потому что я начал буквально
с простых очень работ,
с простых карьер,
по крайней мере, просто простая.
Начал работать в университете.
Сказать, у меня два
высших технических образования.
Одно в поучиваю средней азии,
другое у меня в Москве, в Баманке.
Но во время первого университета
я начал работать,
я, по моему, со второго курса
занимался технподдержкой.
То есть, администрирование системы,
администрирование компов.
В то время я очень увлекался
FreeBSD, которая, по сути,
для меня было всем, хотя я хотел стать, именно, развиваться в плане security.
Ну, раньше так получилось, что я начал работать в компаниях различных,
когда учился в университете, и у меня на одно из мест работ случилось,
так что руководитель мой ушел в другую компанию, меня просили его заменить.
Ну, вот с момента началась моя карьера к менеджеру,
руководителя сначала группы, отдела, департамента, ну, и так дальше поехал.
Потом начал уже работать, был отработал в IT-консалтинге,
тоже создавая свою группу, ну, собственную команду и селфи-инженеров,
и таких продажников, и разработчиков также.
Мы делали custom development, и продавали там outsourcing,
и делали строение архитектуры.
И потом, когда уже переехал в Канаду, уже здесь тоже так случилось,
что моим первым местом работы был банк.
На самом деле на банке вообще не ориентировался, мне было как-то неинтересно работать в банке,
мне хотелось именно погрузиться в такой мир дата, который здесь сильно бурлит
и развивается в небольшую компанию.
Ну, так получилось, наверное, сложилось, что я начал работать в банке,
и там тоже все взвертелось.
Сначала у меня было два разработчика,
мы начали делать интеграцию, ну, в общем, простая задача по интеграции
с ITSM-системы, с системой распознавания инцидентов,
то есть некий такой ML-модель по управлению инцидентами,
то есть предректов модели, как управлять инцидентами.
Ну, потом приснился в команду Big Data в банке,
где вот, соответственно, было тоже три developer, они были на контракте,
и задача стояла, думаю, глобально.
Мы все должны были данные, которые, все различные источники данных внутри банка,
то есть загрузить в Hadoop environment, то есть Hadoop,
в то время мы использовали HDP, Hortonworks,
который был довольно-таки стильно мощным инструментом,
который купил компанию Haudera.
И там началось просто реально активное загружение в Data
различными proprietary tools, то есть IBM, это Data Stage,
это был NPIF, который был, по сути, написан на Spring XD,
который уже умер, но до сих пор живет.
Были также, когда вот уже уходил из банка,
мы назвали миграция всех legacy system framework, ETL frameworks на Talent.
Если вы не слышали про Talent, посмотрите,
вот довольно-таки очень интересный tool,
они развивают его как опенсорсно, так и коммерческое решение.
Даже в опенсорсном решении его можно использовать для различных целей.
Он написан на Java, поэтому и делает его супермощным,
у него очень много коннекторов для различных источников данных,
врачных баз данных, включается на УРА,
то есть надо делать, например, настройки в опенсорсе.
В коммерческой версии там уже все немного подготовлено,
но верю, что вы сможете разобраться в опенсорсной версии на УРА.
И сейчас, по сути, начал работать в IT компании,
мы создаем applications, строим Data Lake, сейчас выбираем ли между IWS и GCP.
Выбор непростой, потому что моя команда должна выбрать это решение
и защитить острое стратегическое назначение на три года вперед
со всеми там утекающими оттуда целями, задачами, как и по деньгам,
то есть по финансовому части, так и по всевозможным интеграционным
и до различных capabilities, то есть различным функциям, задачам,
которым должна выполнять Data Lake.
То есть это, конечно же, ML, это AI, который здесь тоже активно развивается,
но также в Москве, безусловно.
Ну, наверное, все такое длинное, вводное про меня.
Если хотите посмотреть или законатиться, здесь моя ссылка, LinkedIn,
буду очень рад пообщаться в офлайне.
Юра, тебе слово, давай ты про себя.
Тебе тоже громадный опыт разработчика, поделись, пожалуйста, этим.
Добрый день. Меня зовут Буковский Юрий.
Программист, опыт не многим более 20-ти лет.
В основном это было веб-роботы и с обратно стороны веб-программирование,
интеграционные какие-то решения между различными системами.
Даже там были блокчейны новомодные и прочие некуда модные вещи.
Ну и решения в области больших объемов данных.
То, чем в последнее время больше занимаюсь скорее.
В частности, это генетика, которая тоже сейчас набирает популярность.
И вот, чуть забегая вперед, один из примеров будет именно из генетики,
потому что это характерный пример.
Работал в различных организациях, практически все в Москве,
парочки только зарубежных. Ну и, пожалуй, все.
Хорошо, спасибо. Ребят, может быть, кто-то из вас расскажет про вас,
про вашу кафедру, что вы сейчас изучаете.
Какие у вас сейчас интересные, наверное, в плане обучения.
Ну, немного такую вводную, если бы вы сможете дать, было бы здорово.
Есть желающие? Нет?
Ну, вот это можно по-разному. Я, в общем, это не студент уже.
Я тоже один из семинаристов и, по сути, один из лекторов предыдущей части курса.
Вот, поэтому я не знаю, можно ли мне…
Конечно, можно. Раз находитесь здесь, конечно, можно.
Да, да. Я, на самом деле, тоже заинтересовался, пришел на лекцию,
заинтересовался, потому что сам-то работал тоже в EKS.
Но я работал в EKS Big Data с точки зрения организации инфраструктуры
для преподавания курсов по Big Data.
То есть, не связанную с тем, что именно работать на больших данных
каким-то специфичным образом, а именно настраиваться так,
чтобы люди попытались вкатываться в инфраструктуру,
ну, именно в инфраструктуру Big Data.
То есть, были опыты сбора кластеров в Docker образах
и аргистрация этого всего дела.
Ну, для того, чтобы ребята, которые хотели проходить курсы на курсере,
это могли сделать.
Ну, здорово.
Да.
Вы используете Databricks как кладное решение?
То есть, там, по сути, можно заводить несколько десятков аккаунтов
для тестирования, и там все готово, в принципе, вот.
По-моему, когда мы это делали, это было несколько лет назад,
по-моему, в Docker.
По-моему, когда мы это делали, это было несколько лет назад,
по-моему, Databricks еще не настолько был раскрученный.
Сейчас они мега-раскручены.
Сейчас они мега-раскручены.
Да, они мега-раскручены сейчас, но тогда, по-моему, там,
в то время еще инфраструктура около сырой находилась,
поэтому все искали так или иначе решения.
Ну, понятно.
Ясно.
Ну, окей.
А еще хотел бы добавить, что я не программист на Spark,
потому что у меня такая большая governance часть,
натурная часть.
Поэтому, Юра, по большей части по программированию,
я приступал к изучению программирования на Python,
то есть Python Spark Scala, но это не уровень такого разработчика,
который может делать какие-то серьезные разработки.
Это basic часть, конечно, да, но, точнее basics, да,
но просто по разработке.
Поэтому я бы хотел с вами поделиться именно своим опытом
исходя из своих мест работы,
посмотреть, насколько это вам будет интересно
поискутировать на различные темы,
которые здесь у нас есть в нашем деке презентации.
Узнать ваше мнение по Spark,
почему именно Spark такой популярный,
почему не Flink, почему вот именно Spark?
И какие задачи вы планируете решать с помощью Spark?
Самое главное.
То есть Spark звучит для того, что он сейчас популярный,
или потому что все-таки есть конкретные задачи,
которые вы знаете, которые он решает?
На этот вопрос нужно иметь четкий ответ,
потому что Spark не является потенцией от всех,
не от всех бед, но не для всех случаев, точно.
Нет, ну понятно, давайте тогда я это представлю.
У нас такое первое ознакомление именно с миром Big Data на курсе происходит,
поэтому, наверное, мы просто посвящаем сейчас всех нас
вообще во все сферы, которые есть на текущий момент,
для того чтобы, если что, потом можно было углубиться.
То есть у нас курс получается и немножко
в разработку параллельных систем,
то есть всякие MPA, CUDA и прочее.
И вот есть такой Big Data Stack.
То есть это курс такой, если настраиваться,
то это ознакомительный курс.
Ну хорошо, да.
Ну здорово тогда.
Надеюсь, мое присутствие вам как-то поможет
углубиться в мир Big Data,
посмотреть на него немного с точки зрения
через мой угол рассмотрения тех решений
и их использования.
Ну и подтолкнет вас к изучению каких-то
интересных инструментов.
В плане того, что Spark, по сути, да,
крутой инструмент, можно все делать в Spark,
но есть также еще различные другие инструменты.
И в частности, я бы призвал посмотреть вас
на Apache Flink также как альтернатива.
Ладно, давайте начнем.
Спасибо большое, Павел,
что дали такую вводную небольшую.
Если кто-то еще хочет что-то сказать,
пожалуйста, не стесняйтесь, давайте общаться.
Потому что это интерактивный курс,
если нет задач прямо читать без остановки,
скажем, вносить вас в какую-то информацию,
хотя бы делать это больше интерактивно,
через дискуссия.
Я бы дополнил по поводу Flink.
То есть действительно стоит посмотреть на него,
потому что в нем при разработке учитывались
болезни Spark.
Spark был одним из первых массовых инструментов
универсальных инструментов
обработки как небольших данных,
так и больших распределенных.
И во Flink это было, скажем так, учтено,
потому, скорее всего, когда он будет
наберет такую же популярность, как Spark,
он будет, наверное, более удобен в использовании.
То есть те же самые потоки в Spark,
они устроены микробачами.
А во Flink это реальные потоки,
которые ориентированы на единичную запись.
Вот так же, как, допустим, если кто слышал
про такой Apache Storm,
он, в принципе, уже не используется.
То есть это по сути была комбинация
из двух решений.
Это относительно Flink.
Я с ним, честно говоря, еще не работал,
только ознакомился.
Но тоже смотрю в эту сторону,
и тоже думаю, что у него потенциал будет
больше просто потому, что это продукт
сделан на основе ошибок другого продукта.
Да, совершенно верно.
То есть мы должны начать изучать Flink
в нашем проекте MAMAM, AWS,
по сравнению Data Lake на AWS.
И там Apache Flink интересные штуки может делать.
Ну ладно, давайте не будем про Flink,
давайте сейчас про Spark, про нашу тему.
То есть что хотелось сказать этим слайдам?
Здесь у нас такая немного историческая
вводная экскурсус в историю.
Потому что историю тоже надо знать,
понимать, с чего началось.
Ну, здесь до 2016 года,
потому что дальше уже там
просто уже вот так пошло все вверх.
Разве различные технологии начали,
просто, например, бешеный оборот.
Ну, началось, конечно, все с Google.
1998 год.
Первый, наверное, аккаунт, вспомните,
на Gmail раздавались приватно.
Приватно те, кто получил первые приглашения.
У них есть уникальный Gmail аккаунт,
имя, фамилия.
Все началось оттуда,
потому что на Google они были первые открывателями
именно distributed data systems,
то есть разделение нагрузки на системы,
используя commodity software hardware,
то есть не используя те proprietary железо,
то есть HP, IBM,
мегамонстров,
тем же самым MainFrame,
которые IBM сейчас,
если посмотрите на Северную Америку,
все сидят здесь, на крупной компании,
все сидят на IBM-овских MainFrame.
Даже некоторые говорят,
что IBM MainFrame это было просто
начало самого Cloud решения.
То есть они были тоже первыми открывателями,
в частности, computation,
развлечения computation от storage,
потому что их система это совершенно другой
параллельный мир, как работа MainFrame.
Довольно-таки я хочу сказать,
что работа в банке
и имея, скажем, контакт с людьми,
которые работают с MainFrame,
с MainFrame с ними довольно-таки интересно было пообщаться,
интересная система,
но их развитие, наверное, уже затухает.
Но, как я уже говорил,
здесь, в Северной Америке, даже в Европе,
то есть биржевые все,
то есть Nasdaq,
европейские,
те биржевые не сидят на MainFrame,
потому что довольно-таки устойчивая платформа.
Так, вернемся к Google.
Что он Google нам дал?
Ну, в 2003 году вышел MapReduce.
Все, наверное, слышали про MapReduce.
То есть, как данные читаются,
потому что им нужно было
быстро иметь доступ к данным,
чтобы создать свой Google.
Один из таких примеров.
Потом вышел сам Hadoop уже через 3 года.
Yahoo запустил этот
paper про Hadoop.
Если интересно, почитайте.
Там довольно-таки, я бы сказал,
в этих статьях, в этих паперах,
то есть white papers про эти времена,
там не только рассказано про технологию,
как они видят ее,
но и как они видят ее развитие.
Поэтому, если есть время,
обязательно, обязательно почитайте.
Там есть много что интересного,
можно узнать.
Даже если там будет старая версия уже,
никто не сваливает на MapReduce уже, по сути.
Но взгляд именно с тех разработчиков,
которые, по сути,
визженеры, инженеров,
он довольно-таки интересный.
Ну, дальше началось,
дальше Маттея Заккери,
который тоже выходится из Канады,
то есть не тоже,
а выходится из Канады,
он закончил университет здесь,
в Ботталу,
потом перешел в Беркли,
в Стэнфорде.
И вот там началась у него
идея создать вот этот Spark.
По-моему, это был
человек десять,
которые участвовали в этом проекте.
Он часто проводит
много встреч,
но до пандемии здесь проводил много встреч
по этапов,
где он сам принимал участие,
находил время, то есть это было здорово,
с ним пообщаться.
Очень потрясающий тоже человек,
у него много очень интересных идей,
поэтому если тоже
будет вам интересно,
посмотрите его записи на YouTube,
его точки,
его взгляды,
его прям, его
как бы идеи
по развитию дальше
датапроцессинга, датинжиниринга
и, в общем,
в целом, big data.
Ну дальше пойдем
быстрее, дальше там что?
Spark развивался, создался RDD,
Resilient Data Distributed Data Sets,
то есть то, что лежит в основе
на Spark.
Потом Spark присоединился уже к Apache
и, по сути, с этого момента
стал самым популярным, самым
востребованным
больше всего комитов
в этот фондейшн,
в Apache Foundation
до сих пор в мире
осуществляется,
то есть самый развивающий проект Apache является он.
Ну и дальше уже пошли в развитие Spark
в плане ввода по депутатегу,
то есть это вот Spark SQL,
Graphics,
ну и так далее, то есть там
Deep Learning, кстати, тоже вот этот 5.1 Deep Learning,
который также был разработан
профессором,
канадский профессором Waterloo
по Deep Learning,
там чисто математика.
Мне кажется, вам это будет очень, тоже
интересно и, наверное,
больше все будет понятно также.
Так, ну, наверное,
экскру в истории, наверное, все. Есть ли какие-то вопросы у вас?
Есть ли какие-то
не знаю,
точнее, где вы хотели спросить, что там?
Ну, что здесь?
Все началось, как я сказал,
с Apache,
с Hadoop, MapReduce
использовался,
потрясающая штука была,
ну, есть, используется еще в многих компаниях.
Было дешево и сердито
установить,
там, устроить Hadoop.
Hadoop был бесплатный,
до сих пор бесплатный,
если хотите использовать
консорсную версию,
если это какая-то
proprietary, то это только Caldera.
То есть Caldera является единственным сейчас таким
до сих пор
лидером на рынке
коммерческого Hadoop,
и если
хотите как-то
врубиться в мир Hadoop,
то очень призываю активно
только на Caldera,
потому что у них
просто уже все есть,
не надо спать на
грабли, которые там другие могут
сделать, используя подсорсный Hadoop.
Но у них также есть куча материал
по изучению их
CDP-версии,
Caldera Data Platform.
Ну, почему у нас все WebReduce?
Ну довольно-таки все просто,
MapReduce,
делаем
mapping, делаем
reducing, делаем
получаем данные,
они
распределены по различным нодам,
датонодам, есть
nameNode, которые там 2 nameNodes,
на standalone может быть,
все это распределяется между собой,
контролируется MapReduce
по
распределению
мощностей, как мы
сейчас не можем прочитать,
Processing Hadoop MapReduce,
это MR2, но
первый MR в Дульнике был
интересный с точки зрения
перооткрывателей,
потому что он написан полностью на джаве,
если кто-то хотел дописать что-то,
то он должен быть таким джавистом
тамоза костей, чтобы что-то там
променять, для
собственного
доработка MapReduce,
что мешало очень сильно
использовать
MapReduce в качестве
каких-то
дополнительных функций,
в качестве распределения
мощностей, то есть распределение
ресурсов
кластера на
определенные задачи.
Юра, ты хочешь добавить
здесь?
Я бы добавил
просто из теории,
если
само понятие MapReduce
сложно для
понимания, то это понятно
просто при образовании, а Reduce это
математическая свертка,
то есть это применение
чистой функции, то есть чистая функция высшего порядка,
которая применяется к чистой функции,
и нужно это было
во-первых, для отсутствия состояния,
потому что система была изначально распределена
и держать состояние,
тем более с блокировками и симфорами,
это
крайне сложно, есть еще такая
каптиорема,
которая соответственно
обозначает ограничения
в таких системах.
И плюс еще к тому,
что в распределённых системах
могут быть сбои,
то необходимо
перезапуск
определенных операций при сбоях.
Соответственно, сбои не должны влиять
на работу всей системы.
Именно это одна из причин,
почему использовался именно
этот подход MapReduce,
и к тому же это просто по себе достаточно простой,
легко масштабируемый подход.
Он же используется, кстати, и в Spark,
но я не буду вперед забегать,
пусть Игорь последовательно все расскажет.
Да, он там большое различие,
он используется в Spark и
используется здесь изначально в ходу,
потому что
все знаете почему,
потому что запись происходила на диске,
а здесь по Spark все в памяти.
То есть
чтение с диска, сами понимаете,
требует ресурсов, мощностей
и времени,
поэтому нефиксенно было.
Ну, естественно, развитие пошло вперед,
начали создавать,
думать, как мы можем оптимизировать
распределение задач
и балансирование нагрузки
на кластера, потому что самое,
что у нас драгоценное,
это computation.
Storage уже не так был важен,
сами понимаете,
сейчас покупают там, не знаю,
iPhone, можно уже
получить один терабайт данных
в одной коробочке, то есть это вообще
колоссальное прорыв
в технологиях по storage.
Ну, а самое, что важно остается,
то есть computation, но остается всегда.
Поэтому
был введен там MR2,
то есть это
yet another resource negotiator,
который, интересно, делает
распределение задач
между кластикластерами, понимает, какие задачи,
к какой ноде
отдать для того, чтобы выполнить
туальную задачу, когда мы делаем,
когда мы называем функцию MapReduce.
Вероятно добавить?
Давай.
Еще такой важный момент
нужно обязательно отметить, что система
распределенно состоит, собственно,
из распределенных компьютеров.
У каждого есть свою область памяти,
то есть диска и память оперативная,
RAM.
И задача MapReduce
не передавать данные,
а передавать вычисления.
Это, на самом деле, очень условная,
только логическая передача,
по факту работает как.
На каждом узле есть какая-то порция данных,
копии, обычно три копии,
на других узлах.
И планировщик, вот тот же, к примеру,
Yarn или
Standalone Mode
для распределенного Spark,
у него есть такой режим.
Они, в первую очередь,
отправляют
задание выполнять
операции над теми данными,
которые находятся локально на узлах.
И после того, как эти операции будут
выполнены, тогда уже
производится свертка с другими узлами,
с которыми необходимо.
То есть, суть всей этой распределенности системы
в том, чтобы не гонять по сети данные,
которые даже на быстрой сети будут
все равно давать большую задержку,
как минимум, за коллизии
на пути,
на сетевых путях.
И по максимуму вычислений
производится именно локально.
То есть, на приходе ФС позволяет определить,
на каком узле находится какой блок данных.
И, собственно, планировщик это использует.
То есть, он дает задание провести
ряд операций на узле,
имеющем данные данные,
данные, набор данных.
Такой очень важный момент
нужно всегда учитывать.
Спасибо, Юра.
Так, ну,
будем дальше тогда. Прямо придется, мне кажется, достаточно
уже ничего интересного.
Теперь про Patch Spark. Немного поговорим.
Почему именно?
Как он возник?
Ну, какие у него, в самом деле, преимущества?
То есть, в основу Spark
лежит тот самый RDD,
пищевой компонент,
Resilient Distributed Data Set.
Поддержка
Spark
сама написана на скале,
но поддержка через API,
через и билетеки,
не MapReduce, конечно же,
но и билетеки ML
и SQL
поддержка.
Но также преимущество основное
можно
те, кто программирует на Пайтоне,
используют Паспарчи,
используют Python,
Java, Scala.
Самое интересное,
что можно здесь подчеркнуть,
то, что различие Java и Python,
то, как они
компилируются,
то есть, эффективность при компиляции,
то, что Python не компилируется,
Java компилируется,
соответственно, можно отловить плаги
уже во время компиляции.
Юра,
Паспарко, что ты хочешь сказать
по этому слайду?
Добавить сложно.
Единственное, что хотя бы добавить,
что такой вот
особенность,
что если используется Python
на каких-то
операциях, которые не требуют
вычисления, а не памяти,
то с ним нужно быть осторожнее,
потому что UDF, так называемый
User Defined Function
на Python, они будут
как бы у них КПД ниже,
соответственно, это может замедлять
вычисление именно при использовании UDF,
а так разницы
сложно что-то добавить.
Да, здесь
по сути основные, скажем так,
такой
высокоуровневый
определение Spark
и выключение компонентов здесь
отражено все на этом слайде.
Если хотите знать, что
одно определение, одно понятие,
что такое Spark,
в принципе, можно посмотреть
на этот слайд и зафиксировать,
дальше уже
копаться в деталях.
Поехали дальше.
Здесь
как я уже о ней говорил,
здесь у нас идет
небольшой экскурс в релизы,
как он на
наиболее стабил релиз, который сейчас
начали использовать,
мы здесь дальше в панке,
в наших проектах, в List 1.6
не три, не два,
недавно вышел два,
не адаптировали,
потому что по различным причинам
перепрыгивать
версию на версию
довольно-таки сложно.
Если начали
использовать 1.6,
перейти на 2, в зависимости от
платформы,
которая работает Spark,
например, Hadoop.
Будет
для
производственных
нужд, для
проектов, которые уже запущены
в продакшене,
переход делать не просто.
Там нужно
делать
нагрузочное тестирование, проверять
совместимость бюллетек,
чтобы сделать
переход.
Обычно
редко делают переход.
У нас уже с 1.6 на 2
я не сталкиваюсь с этим.
Можно делать,
но это будет
не то что рискованно,
но проблематично.
Если работает 1.6,
достаточно функций, которые
выполняют Spark 1.6
без
добытельных преимуществ Spark 2.
Работка
у них
от
пересмотра RDD
была.
2 версии
2 и 3.
2 и 3
в США
были основные
изменения
с внутренней кухней,
а с 1 и 2 я даже не интересовался.
С RDD
за всю практику
сталкивался один раз.
Мне он абсолютно не нужен был.
Да, RDD
изначально был фаундэйшн,
но не используют
качество таком основного компонента,
который являлся
в Spark.
Задавайте, пожалуйста,
вопросы, если что-то
непонятное или хотите,
чтобы уточнить.
Мы сейчас просто идем
верхам и верхам проходим.
Не хотелось
погружаться
в детали.
Хотелось бы, исходя из ваших вопросов,
наверное,
что
интересно больше
рассмотреть про
DataSight, DataFrame, RDD,
что-то интересное про
библиотеки,
машин-леннинг библиотеки, либо еще что-то.
Пожалуйста, задавайте вопросы.
Давайте
какую-то дискуссию,
может быть, все будет
по вашим вопросам.
Думаю, было бы здорово уточнить
про RDD.
А что конкретно?
Что это для чего
используется?
С понятием раньше
не сталкивался.
С понятием RDD.
RDD это Distributed Data Set.
Что он делает?
Он распределяет
сам
процессинг данных
на микробаче, чтобы делать
процессинг данных
и
memory.
У меня сколько нужно memory на каждый
микробач.
Юра, у тебя есть что добавить по RDD?
Есть, да. Я бы немножко вперед
забежал, потом можно вернуться к RDD.
По факту, вот так называем
Batch это набор записей.
И набор записей в RDD,
это, грубо говоря, таблица прямоугольная.
Они не
именованы.
И если вот как бы чуть-чуть
забежать вперед, на самом деле,
это я в своей практике.
Любая работа с данными,
начиная со всем, что больше
массива единичных элементов,
все уже давно проработано
в релиционной алгебре.
То есть это то, что SQL,
базы данных с релиционной SQL,
если все с этим связанное.
И по факту,
опять же, это из практики,
только не из теории,
работать с релиционными данными
гораздо удобнее. И когда они
именованы, то есть колонки не имеют ни номера,
а какие-либо имена,
с ними работать
гораздо проще, используя именно
релиционную алгебру. То есть, опять же,
повторюсь за забеганием вперед,
переход от RDD к DataFrame,
DataSet и Spark SQL
это был вполне логичный
переход, потому что
есть уже наработанный
математический аппарат,
и очень много наработок как
в программном плане, так и в теоретическом
для работы с данными.
То есть любая таблица,
имеющая более одной колонки,
это уже претендент на
релиционную алгебру.
Повторюсь, я немножко забежал вперед, но
можно вернуться к RDD.
Ну, я же говорю, RDD,
оно, по сути, лежало в основе,
оно оттуда началось,
в принципе,
помните, до предыдущих слайда
начался Spark,
то есть Spark Foundation,
но там с
скажем,
с
как с появлением
открытия, я могу даже сказать,
Spark SQL все много
попростилось, то есть наверняка
SQL сейчас является языком,
который все владеют от
Малого велика,
строит запросы,
по сути,
это решило
просто с него колоссальное количество
недочетов,
можно так сказать, наверное,
и сложность работы RDD.
Я бы сказал, сильно снизило
пару ходов, потому что с RDD
фрагментированными
таблицами безымянными
работе было неудобно и сложнее.
Андрей, мы ответили на ваш вопрос?
Да, спасибо.
Отлично.
Есть у человека вопрос у кого-то?
Я, наверное, не то что
вопрос сказал, я, может быть, больше
понимания привнес, потому что
у ребят
знакомство с мап-редюсом, по сути,
был не через Classic Java,
а через стриминг.
Поэтому
наверное, как раз
самая оптимальная абстракция, которая
позволяет легко
достаточно перейти с концепцией
стриминга, когда мы просто берем
и там, где лимит от ключей
и значений пересылаем,
самая оптимальная как раз
представить, что каждая строка,
которая от дилиметра
поля у нас приходит в стриминге,
она как раз и представляется
в каком-то приближении
элемента RDD,
строку RDD,
чтобы было понимание просто
соотношения теории и практики,
что это такое.
Хорошо.
Спасибо за контекст,
спасибо за прояснение, Павел.
Согласен с вами.
Ты, кстати, допомнил бы еще
в этом вопросе, что
Spark на самом деле данные воспринимает
именно как потоки.
Идеологически так было задумано,
а не как таблицы.
Отсюда и плюсы, и ограничения.
Об этом мы улучшим позже
по ходу слайдов.
Тогда давайте двигаться дальше.
Но, кстати, по-моему, Юра, сейчас идет
твои примеры.
Как раз тебе оба, тебе, тебе сейчас.
Сейчас тогда сделаю.
Попробуй сейчас...
Прикачай, расшаривай свой экран.
Ты тогда расшаривай свой экран.
Так.
Весь экран, окно.
Вот, кажется.
Видно?
Да, я вижу.
Значит...
Вот это один из примеров
из реальной практики.
И как раз вот
из генетики я скажу, почему именно
этот пример взял и почему не из генетики.
Дело в том, что это такое характерное
применение именно Spark.
Вот, например,
опять же, из практики, когда...
Нет, вернее, сейчас
чуть откачусь. То есть, что
в данном примере
используется
ДИФ-генома, так называемый
ВЦФ-файл, вернее, преобразованный ВЦФ.
Это
типа этот ЦСВ-формат,
в котором
есть колонки хромосома,
то есть их там
22 плюс
еще
XY и метахондрия
и ее позиция,
также набор нуклеотидов, которые
указаны в референтном геноме,
и их замена, то есть так называемые мутации.
И этих данных,
то есть при полном геномном секвенировании,
у каждого человека накапливается
ДИФ, получается,
именно это ВЦФ-файл,
порядка 5 миллионов записей.
Это не такие большие данные,
не такой большой объем для обработки
тем же самым поздросом,
или MS SQL, или Oracle.
Но есть один серьезный момент,
что для того, чтобы закачать их туда,
нужно много времени.
То есть, чтобы закачать в хранилище поздроса
или даже того же клихауса,
который достаточно быстро принимает данные,
все равно нужно достаточно много времени.
И в этом случае
проще использовать SQL-движок,
то же самое,
вернее, в частности Spark SQL,
который позволяет
использовать внешние хранилища.
То есть, вот эти вот tab-separated
файлы, они, кстати, зажаты в GZ,
в GZIP,
причем на него там есть модификация
BGZIP,
либо просто
обычный GZIP.
Spark позволяет их читать
прямо из источника,
так же, как
любая
релиционная база данных
из своего хранилища
и воспринимает их как поток.
То есть, данные, на самом деле,
один раз читаются, обрабатываются, покачаются,
производятся какие-то действия
и выгружается их в выжимку
или обработаны уже
преобразованные данные.
И вот это вот было
одной из причин
использования Spark.
И по этой же причине он часто используется,
в частности, в генетике,
потому что данные достаточно объемные,
и заливать их в релиционные данные,
потом вытаскивать их обратно
нерационально.
Вот, собственно, один из примеров,
он написан на клоджере,
если кто знает современный диалект
Лиспа, я специально оставил его,
как есть, чтобы было понятно
контекст,
что именно,
как они преобразовывались.
То есть, также сам можно это написать на питоне,
на скале, поясню
основные различия,
даже не различия, а
логику, что здесь происходит.
Ну и, собственно, пойдем.
То есть, вот есть у нас
какие-то набор данных,
это вот хромосома позиция,
реф хальт, ну еще какая-то
информационная информация.
Есть база данных на Postgres,
где находится так называемый Лис,
лабораторная информационная система.
И вот в этой задаче, опять же,
я скажу,
то есть, суть там определилась какая-то
фармакинетика, я не знаю, что это такое,
потому что я программист,
этим занимались биологи, биоинформатики,
но эту информацию нужно было
сопоставить с тем
объемом данных
из VCF файлов преобразованных,
то есть, здесь они были
не в чистом виде, как они
подразумевают формат
VCF, это опять же тоже
мини-кассест, как сказали,
так и сделала.
И нужно было обогатить эти данные
и сагрегировать с данными из Лиса.
Ну и вот здесь
preparator
preparator функция, то есть здесь
делаются подготовительные работы,
в частности,
вот в
12 строке
переписывается драйвер Позгресса.
Я напомню, что Spark
это распределенная система,
и на каждом узле должен лежать
копия
jar файлов,
которые
необходимы для работы в данном узлу.
То есть, у нас есть HDFS,
Игорь говорил, что это
за система, то есть, это распределенная
файловая система,
имеющая,
в которой каждый узел имеет доступ
по одному и тому же пути.
То есть, в данном случае ходу
к мастер-хост это хост, и
tmp jar с позгресса или
это путь к этому
jar файлу, то есть, к драйверу
Позгресса. И каждый узел
может получить этот
jar файл и подгрузить его
с помощью класса удара для
дальнейшей работы.
Чтобы каждый узел мог
подключиться к Позгрессу, где находится
таблица.
Если здесь есть какие-то вопросы,
то лучше, наверное, задать их сразу,
потому что там я мог достаточно
сумбурно объяснить.
Продолжим.
Собственно, передается вот эта формака.
Один это
файл с данными,
связанный с формакологией.
И вот
в этой строке, 25,
это указание
спарку,
которая передается на все узлы,
какие
дополнительные jar файлы,
это jar в архиве,
на всякий случай напомню,
какие jar файлы
использовать при работе.
И дальше
идет непосредственно
подготовка.
Есть у нас свой файл, разделенный
с пербулястой.
Это separated
CSV файл
с заголовки. Вот у нас указан
header по поводу синтаксиса.
Эта
запись, начиная с 51-й строки
по 58-й, можно представить
к примеру на PySpark,
также как spark.read.format
в скобках
CSV
и далее options
в скобках
slash t.
То есть это
запись
в листовом варианте.
Она синтаксически
сильно отличается, но по факту это такой же
конвейер, как на PySpark.
Я не буду на нем застрять внимание,
что это второстепенный
момент.
Вернемся.
И что мы делаем здесь?
Здесь мы по сути делаем представление,
так называемое view
в терминологии
баз-данных,
то есть тех же всех
поскрусов, ороклов и так далее.
В Spark SQL тоже есть представление.
И в данном случае
из этого вот формата
1.txt
делается представление таблиц.
Здесь задаются колонки.
То есть у нее есть именованные,
она уже имеет именованные колонки,
но мы их вот
в 58-й строке
затираем и
устанавливаем свои. То есть
T0 нам не нужно, это не используется.
ID, хромосома, позиция,
ref, alt используется. Остальные тоже не используются,
но их нельзя отбросить, потому их просто забиваем
незначениями значениями.
Теперь у нас
FKView представляет
обычную релиционную таблицу.
Она смаплена на
текстовый файл, этот файл распределенный,
он Spark
рубится на определенные кусочки
те же сами RDD, они же
оборачиваются потом в датафреймы
и лежит распределен
на кластере.
Далее
у нас уже есть по сути релиционную таблицу,
мы рассмотрим ее именно как
таблицу.
Дальше тоже
выше есть эквивалентная запись.
Это тоже самое можно записать одним
только SQL.
То есть передается
Spark, набор SQL
и SQL-директив,
который выполнен тем же самым первым.
В данном случае
вот я специально выделю
это эквивалентная запись.
То есть мы создаем
view, то есть KritaReplace,
то есть если она существует, она не пересоздается,
с этим нужно быть аккуратной,
то есть лучше дропать.
KritaReplace, tempView, временная view,
то есть она существует только в пределах
данного соединения,
то есть другие
сессии ее не видят.
Вот так же самое
создается таблица, это обычная SQL-синтакс,
за исключением вот этой строки,
using.csv, это не характерно для
SQL-директива.
И дополнительные
options – это путь
к HDFS, который
одинаково видит каждый узел Spark.
Соответственно, истина,
потому что здесь первая строка
является заголовком,
но мы их переопределим, то есть они будут
по сути проигнорированы.
Ну и септор разделитель.
То есть это эквивалентная запись.
Вот того, что мы видим
с 51-й по 58-й строку.
То же самое можно
SparkShell передать
SparkSQL, вернее SparkSQL
есть такая утилита,
можно зайти в нее и прямо так
сделать
выполнить данную операцию.
Соответственно, это
farm-file, тоже
только это
таблица
без заголовков
и разделенная пробелами.
Вот, собственно, так же самое
можно сделать как вот выше,
replace.tmp-view, либо
в данном случае мне было удобнее
сделать именно так
просто
обычным кажур кодом.
Так же самое
из нее создается таблица sample
popgen, это там
популяционные геномные исследования.
Опять же, я не могу
ничего сказать
относительно области применения,
потому что я не специалист в этом.
Вот мы технически создаем еще одно представление.
Оно также смаплено на
этот farm-file, он может быть
кэширован, может
браться в определенные фрагменты
прямо вот
непосредственно из
блока
размещенного
на HDFS.
Для нас это такая же таблица,
как в реализованной базе данных.
Дальше
вот здесь немножко другой
момент. Здесь мы, начиная
с 72-й строки по 76-ю,
делаем
материализованную
запись, то есть у нас есть
запрос.
В частности, мы используем таблицу
fk-view, это она у нас
с 51-й по 58-й
строку была
определена как представление,
то есть для нас представление и
реальные таблицы с точки зрения
реализованной алгебры равнозначны.
И здесь мы выполняем
на ней запрос, то есть хромосом,
там хромосом заданный цифрами,
нам необходимо, чтобы у неё был
в соответствии с 38-м
по референсам,
представление было, то есть CHR и цифра,
цифра либо XY и
М-буква.
В частности, тут мы
выделим
просто вот так же
с таким же синтезисом,
как в поздросе.
Добавляем, делаем конкатинацию,
добавляем строку CHR
в хромосоме,
представим алиас как
хромосома.
Позицию преобразуем
из текста в int,
потому что у нас
текстовый файл, соответственно,
по умолчанию колонки имеет
текстовое значение.
Так что рефальт остаётся
немножко
как оптимизируем
данную таблицу
и убираем лишние, то есть вот эти
подчеркнение t0, t1, t2, они нам не нужны,
мы их здесь не используем.
А далее мы записываем их
так же в кластер
на HDFS в директории
FKSL.
Это не файл, это директория.
В ней хранятся
все секции,
так назовём партиции,
с каждого узла.
То есть они сгружаются в эту директорию,
но для нас
она также представляет
ту же самую таблицу, то есть к ней можно
обратиться именно как таблице.
И вот я могу даже дописать.
Если кому интересно,
вот здесь такой момент.
И вот эта вот запись
паркет, то есть помолчание сохранится
в формате паркет.
Сейчас не буду на нём останавливаться,
это очень интересный и эффективный формат хранения.
И к ним
в запросе в SQL
мы можем таким образом обратиться.
То есть паркет.backslash
и адрес
этой директории
на HDFS, где лежат
данные
из этого результата запроса
в нескольких файлов
по каждому, по каждой секции.
Их, кстати, может быть более, чем
один на узел,
в зависимости
от настроек с парка.
Берём.
Вот. И эквивалентно это
опять же вот такую запись.
То есть потому, что сам парк SQL
можно выполнить вот такую
drop table
в Exist я вкосил.
То есть удалить
её, если она не существует,
потому что у нас есть в 74 строке
метод
mode overwrite. То есть если эти данные есть,
то они перезатираются в кластере
по данному пути.
Либо и то же самое
можно сделать в соответствии
с ANSI SQL
create table using parquet.
В данном случае
здесь нужно учитывать,
указывать формат
сохранения.
Этот parquet очень широко
используется.
И location – это
путь, где именно будет
материализованная эта
запись.
Да-да.
Вот в этом вот
FCSL вы сказали, что там
по секциям лежат.
Будут лежать данные.
Что собой секция представляет?
Это файл.
Обычно у него формат такой.
Это OUID формат.
То есть OUID формат
все знают, я думаю.
То есть это
от 0 до
0 до 9.
То есть все цифры
и буквенные значения.
Не помню, Z там входит или нет.
То есть от A до Z разделенные
defisами.
Четыре символа
defis.
То есть буквенно-цифровой
нечитаемый формат
.parquet.
Это обычный файл parquet,
который имеет один и тот же формат.
Подразумевает, что они все имеют
одинаковый формат, то есть одинаковая
последовательность колонок и их названия.
Вот они вот так лежат просто
несколькими файлами в этой директории FKView.
То есть вы можете
сохранить и взять любой запрос,
выполнить там в парке в localmod
и запустить там, допустим,
на компьютере запрос,
сохранить его и увидеть
скорее всего несколько файлов
в данной директории.
Можете посмотреть, они бинарные, в них
так через просмотры
сидеть ничего крайне сложно.
Мало того, они еще сжаты,
и сжаты достаточно сильно.
Есть различные алгоритмы сжатия,
по-моему, там LZMA используется.
Не буду врать в такие подробности.
Собственно, все. Я ответил на вопрос
или, может быть, не точно еще.
Нужно уточнить.
Каждый файл — это информация там колонки
условно.
Нет, не по колонке, это срез,
это так же, как RDD, то есть это все колонки.
В данном случае
у нас колонки
угольные, такие куски таблицы
наши. Да, и причем они именованные.
То есть первая колонка имеет
название ID,
вторая — хром, третья — пост,
четвертая — реф, пятая — альт.
И, что важно,
в Spark'е важен порядок
этих колонок. То есть если ID
будет, допустим, после хромосомы,
то при сложении может быть,
то есть при чтении
всех этих файлов
из этой территории может быть
непредсказуемое поведение, потому что Spark
читает из первого файла
название колонок,
вот эти ID, хром, пост, реф, альт,
а остальные
он подразумеет, что они соответствуют,
что первая колонка соответствует ID,
вторая — хром, третья — пост.
И читать
он их может в любом порядке.
У него какая-то своя логика.
Если есть, допустим, 20 файлов,
он может прочитать первым, может прочитать
какой-то там предпоследний,
и какой он выберет —
это сложно сказать, но они
все должны совпадать.
Вот здесь есть
какие-нибудь вопросы, или
нужно дополнить? — Все ясно.
— Спасибо.
Тогда продолжим.
Вот это эквивалентная запись.
То есть мы создаем таблицу,
записываем ее по этому пути
sselect. То есть это, опять же,
дистанции SQL.
То есть можно
использовать либо этот запрос, либо
в частности
не было удобнее
писать это клажур кодом.
Здесь мы создали уже материализованную
таблицу. То есть
есть такой момент очень важный.
Spark это
использует линеевое вычисление.
То есть когда мы сделали какой-то запрос,
допустим, sselect что-то, потом из него еще что-то
сделали. Сделали sselect из вот этих
FKView, sample, popgen.
И
когда мы получили
DataFrame с результатами, вот, к примеру,
если мы выполним
Spark
SQL, вот до 73
строки, в результате
мы получим определенный объект.
Но при этом никаких
операций чтения на
FKView, в частности по файлу
вот в этой строке
56
формата txt1.txt
и по файлу sample.popgen
в частности
FKView.popgen не используется.
Никакого чтения произведено не будет.
Оно будет только в момент
записи этого файла
либо чтения.
Spark использует линеевое вычисление
и
будет читать файлы только по мере их
необходимости. Это нужно всегда учитывать,
потому что часто будут
странные ошибки, непредсказуемые,
когда
ошибка всплывает позже,
чем она ожидалась.
Потому что, повторюсь, Spark
использует линеевое вычисление.
Вот, в частности,
в 76 строке
будет
после выполнения сейфа, то есть записи
всех данных уже
на HDFS, будет файл
формака 1.txt
будет уже прочитан полностью.
Потому что он
задействован
в представлении FKView,
а здесь мы делаем
на 76 строке чтение из FKView.
И вот когда будем читать
уже записи, то есть
непосредственно постройочно,
только после этого
файл будет читаться.
Это нужно иметь в виду, это важный момент.
Я думаю, здесь понятно,
или все-таки есть какие-то вопросы,
потому что такая вещь
не очевидна, и люди
часто напарываются
на такие ошибки.
Нужно что-нибудь еще пояснить.
Видимо, не нужно.
Значит, продолжим.
Сейчас, секундочку, я включу питание,
а у меня наутро разряжается.
Далее.
Переходим
к строке 77.
Здесь у нас также выполняется запрос
и записывается
в качестве материализованного.
Но здесь мы используем
ANSI SQL,
WAV FK,
SELECT FROM.
Мы берем из той же
у нас есть материализован
представление FK cell.
Вот так мы к нему
обращаемся.
Мы читаем не таблицу,
мы можем прочитать
из HDFS,
Hadoop, Master, Host, MPF,
FK cell данные,
сделать CREED
REPLACE TEMP VIEW,
сделать представление
на непосредственно таблицу
без каких-либо преобразований.
Либо можем прочитать прямо
с HDFS.
Это один из примеров,
который я показывал.
Я выделяю вот так.
Можно обратиться
не указывая, не имяноя
через какую-то промежуточную таблицу.
Здесь есть какие-нибудь вопросы,
потому что тоже такая
нечасто используемая техника,
но она очень сильно
экономит силы и время.
Есть что-нибудь непонятное?
Вроде все понятно.
И дальше.
Это TTE,
Live Statement.
Здесь ничего нового нет,
но есть такой момент,
на который нужно обратить внимание.
В строке 80
у нас там комментарии.
Комментарии C-подобные
и в нем директива Broadcast FK.
В частности,
в качестве FK у нас
результат селекта
по FK cell,
но это
логическое представление
таблицы.
Но дальше у нас
берутся данные
из Multisample Unified.
В этой задачи
было много
переведенных в паркет
вот этих преобразованных
ВЦФ файлов,
где там хромосома, позиция
и так далее.
Их было большое количество,
и с ним производилась
операция Join.
Напомню, что Spark
воспринимает данный как поток
и индексировать он.
Из коробки он
индексировать не умеет.
Есть определенные техники,
использование хайва или секционирование
на уровне сессии Spark,
которая позволяет
сократить сканирование.
Партийцы.
Да, партийцы.
Но
сам по себе Spark
это потоковый движок,
он не разрабатывался
как замена релиционной
СОБД.
И вот эти данные
он читает потоком,
и если происходит необходимость
Join, все знают,
то есть операцию Join
в релиционной алгебре,
это достаточно тяжелая операция.
И вот тут есть такой момент,
мы делаем broadcast в ка,
результат Select
в 79 строке,
это маленький набор данных,
тысячи или миллионы записей,
обычно для кластеров
это очень маленький объем данных.
И вот этой операцией broadcast
мы указываем Spark
раскидать этот результат,
который мы получили,
на все узлы.
Вот параллельно по каждому узлу
блок из вот этой таблицы,
которая у нас указана
строке 81,
нам не придется читать
из других узлов,
из каких-то соседних результат
из 79 строки,
то есть он уже будет записан
на все узлы, и это будут локальные данные.
Как он уже делает там внутри
у себя Join,
это я не настолько хорошо знаю,
но там используются shuffles
и внутри
представление для индексации
данных, потому что сканировать их
постоянно это очень дорогая операция.
Внутри он проводит определенную
индексацию, не полностью,
не каждая запись,
я тонкости не знаю,
но за счет
вот этой техники broadcast
причем обращу внимание,
что плюс должен идти без пробелов
в начале комментариев.
Мы
очень сильно сокращаем
вычисления,
то есть по сути у нас
получается параллельная
обработка вот этой вот таблицы
из multisample.unified
на каждом узле без
каких-то перекрестных
обращений к другим узлам.
Это очень дешевая операция,
и ее нужно иметь в виду,
когда делается Join, потому что, повторюсь,
Spark не умеет в индексы
и воспринимает данные как поток.
Ну и дальше мы также
самозаписываем overwrite
также в директуре.
Это вот там tmp,
просто она бралась в время директуры,
это промежуточное вычисление на случай,
потому что вычисления длились по несколько часов,
иногда по несколько суток,
и если они падали, то
можно было их
не повторять заново,
а взять
промежуточных результатов
данные. Также сам
sp, также
их можно представить в качестве
SQL, мне было удобнее
так, если что-то падало,
то, конечно, проще было дальше повторять
просто SQL, Spark
в Spark SQL консоли.
Записываем
эти данные, ну и дальше.
То есть, вот, собственно,
тоже
похожий запрос, также
сам используется broadcast,
есть такой момент, смотрите,
в 82-й строке,
к примеру,
у нас
данные, ну,
joins по хромосоме, то есть хромосома,
и позиция, в данном случае fkpos,
она int,
а в datapos это и
alias на вот эту большую таблицу,
ну, я так называю, то есть большой директориум,
она там
была строковая,
и оно здесь приводится к int.
То есть, здесь мы джойнили, а здесь,
соответственно,
в джойне используется
вот это преобразование, где
дата хром
числовое,
но в текстом представлении
нужно добавлять
хромосома, и после этого
они уже джойнятся.
Здесь тоже ничего простого,
это обычная вытяжка, по-моему,
из open-source
тысячи геномов,
там, в сравнении, производилось
с образцами
из
репозитория тысячи геномов.
Дальше, собственно,
тоже здесь ничего
нового, также
джойн,
по безымянной таблице,
то есть, прямо обращение к директории
dbsnp, dbsnp
это, по-моему, база
соответствия
хромосом позиции
с непу или гену.
Опять же, этих
подробностей
не сильно знаю, потому что
не моя специфика.
Здесь такая же операция, мы также записываем
это в директорию.
Далее
более сложный запрос, и этот запрос
это обращение к лису, это непосредственно
обращение к позгросу.
Ему можно обратиться либо
к представлению, которое внутри позгроса есть,
либо можно прямо написать
запрос
к каждой таблице.
Вот, допустим,
эта таблица в позгросе,
она почему-нибудь
вернее, эта схема
таблицы у нее там
в таком регистрозависимом
записи.
MSP
это тоже схема
из позгроса, и вот
with и with sample
это представление определенное.
То есть, можно написать прямо запрос,
который уйдет непосредственно в позгрос,
он не будет, Spark не будет
дернуть каждую таблицу и сам выполнять запрос,
он его отправит именно в позгрос и получит
результат. И этот результат будет
скажем так, не записан,
а отображен на представление
pop-view, то есть
популяционное представление
было, по-моему,
в сравнении тасканцы, фины,
британцы
и так далее.
Здесь мы создаем представление, которое
отображено на запрос в позгросе.
Здесь же вот
можно указать ему
юзера, пароля
и вот dbtable либо
query можно указать.
В данном случае никакой причины
было написано dbtable.
Указывается, соответственно, в
options URL, это dsn
позгроса, то есть он
находится по хосту, у него list
host, база данных, list
лабораторная информационная
система.
Так же самое, это
операция можно сделать на обычном SQL
на, например, Spark
Console. Это 11 пример,
что пароли можно
пользовать, пароли можно
задать через set, чтобы
не писать прямо в запросе.
Это 112-113
строка. Так же самое делаем drop
tables.
Это, на самом деле, обозначается
как table, но по факту это является
представлением
запроса, именно уже в другом источнике,
в частности в позорстве.
Так же самое, create table using
gdbc, это формат.
Там у нас выходит Spark, здесь используется gdbc,
то есть
стандартный явский database
connector, options и
URL, query.
Кстати, здесь можно
пробиться, можно равно.
Вот запрос и также
пароль. Здесь
тоже все просто, и его можно
при необходимости закешировать, но вот
в данном случае здесь не было необходимости
закешировать, это просто
добавить метод cache, который
загрузит шафл.
На этом тонкости
я не буду их сейчас касаться.
То есть здесь создаем представление уже,
которое смотрит на подгроз.
Дальше
select из
этого же представления,
у нас там какие-то
sample
не помню,
это уже
операция, посредственная Spark
над представлением
данных из подгроза.
И дальше
уже такие более сложные запросы
идут, это уже
joins
данных
из предварительно подготовленных, допустим
fksp, fk 1000
и
fk
1000
с
нечитаемым
renbc,
это определённые т.е. промежуточные данные
не записывались
на hdfs
потому что, напомню, что Spark
это использует линейные вычисления
и эти данные
в принципе вот, запись на диске это аналог
кэширования, но в случае сбоя
не привез несколько часов или не ждать, пока основы эти данные будут вычислены,
в случае, если мы их запишируем, потому что кишер не пропадет, а материализованная
запись останется. Ну и дальше сложные джойны, это обогащение данными,
вот хромосом, позиция, вот с базы данных, рей, оверлапс, это встроенная функция
Spark, в частности это пересечение при, это джойн при условии, что альты в базе данных,
в базе данных с DBSNP, пересекают хотя бы с одним альтом из обрабатываемых нами данных,
вот с той большой таблицы, то есть это обычный джойн, это очень тяжелая операция, Spark ее не
любит, она требует много ресурсов и занимает большую шафу. Дальше еще более сложный запрос,
это как раз уже определение генотипа, тут скорее мне вопрос к аудитории, здесь нужно объяснять
вот эти тонкости или в основном понятно, что времени уже много, если буду дальше грузить,
ты такими техническими подробностями, то могу упустить что-то более важное.
Весь этот пример посвящен тому, чтобы у нас склеить две базы данных с информацией о динамах, да?
Да, да, да, даже больше двух, то есть есть какая-то база данных, то есть файлы с
какими-то результатами формакологическими, которые зависят как-то от каких-то генов или
рсов, есть у нас отдельно в паркете базы генов, соответственно есть подобные, есть у нас
эталонная база тысячи генов, которая лежит в интернете, и на ее основании нужно получить
чистоту влияния вот этой формакологии в зависимости от определенных генов,
все это по сути происходит в последнем запросе, гетерозиготы, гомозиготы, то есть гетерозиготы это
на одной хромосомии замена, гомозиготы это на двух хромосомах, которые повышают патогенность,
вероятность патогенности, и вот это все, то есть условно вся эта информация сливается в один
движок и обрабатывается обычными SQL-средствами, то есть здесь ничего такого сверхъестественного нет,
но есть определенные особенности, которые повторили, что Spark использует линейного
вычисления и не умеет в индексы, работает с потоками, вот это надо учитывать, а так вот
собственно, вот пожалуй и все, а вот кстати мы дошли до конца файла. Да Юр, спасибо тебе огромное,
мне кажется это было супер интересно, и наоборот, посмотрите на прям это пример,
Spark прямо не брав и глас может привести к сравнению, потому что Spark очень активно используется в
healthcare, то есть в здравоохранении, здесь очень много примеров, можно идти на GitHub, где
в частности там геномное сравнение, влияние, точнее там как развивается, особенно сейчас много
времени, развитие, претращение развития рака, и Spark здесь играет в один из ключевых ролей для
data processing, data, которая используется для этого через EMR, Electronic Medical Records, то есть на записи
всех пациентов, то чтобы строить машинное обучение, ML модель, то для именно вот
претращения, развития рака на первых его стадиях. Если посмотреть статики, посвященные этому
этим изучением, Spark является флагменом и инструментом для процессинга данных, для этого изучения.
Я знаю, что у нас время уже дошло к концу, есть еще у нас пару слайдов, они больше посвящены,
один из слайдов будет посвящен, наверное, про Databricks, я бы хотел сказать, что начните,
если еще не начали смотреть на Databricks, Юра сейчас расшаривает снайпер-экран,
то есть если хотите прямо сейчас начать попытаться, то есть запустить собственные какие-то проекты,
начать изучать, уже, наверное, погрузились в AWS, Azure и JCP. Призваю вас посмотреть на Databricks,
на их решения, на Data Lake House, у них много очень открытых источников книг, которые они публикуют
в этом доступе, которые по сути являются очень интересным для изучения, для чтения, то есть их
подход, Delta Lake, очень-очень интересно, как данные используют, то есть паркетные данные,
как это данные представляются в виде не само, как данных, а некий subset данных,
который нужен именно для процессинга, то есть не стриминг, а именно процессинг данных, такой
layer, который позволяет данным немного абстрагироваться именно от такого storage,
от данных классического и работа на уровне такого subset данных, которые позволяют быстрее данные
обрабатывать. Также у них есть книга сейчас про Lake House, тоже интересно, начало читать,
пока не могу ничего поделиться, к сожалению, только начало изучать. Ну, если будет время,
посмотрите, довольно-таки интересные статьи у них публикуются, и также различные конференции,
которые... вот сейчас будет в ноябре конференция по... так, наверное, экран не видно, да, экран по
side data bricks. Не видно? Видно, что здесь пора презентацию, да?
Нет, видно. Видно?
Да.
Так, я могу показать, learning, learning, yes, no, no.
То есть здесь можно проиграть по AWS, HTTP, заведите себе аккаунт, начните изучать,
параллельно вы будете изучать не только Spark, но и сами сервисы, и инструменты самого колодного
провайдера, там, HTTP и AWS, потому что, ну, это на самом деле будет очень полезно для развития вашей,
как карьер, карьерного развития и профессионального развития. Также хотел еще, наверное, поделиться
в оптимизации Spark, то, что моя предыдущая команда разрабатывала, то, как лучше оптимизировать Spark
в запросах в ходу. Ну, я, наверное, у вас есть эта презентация, не буду уже ваше время много
отнимать. Посмотрите, пожалуйста, если какие-то вопросы будут, я присоединюсь к вам в чат,
в телеграм. Могу ответить на какие-то вопросы, ну, и также поддерживать какую-то связь там,
там через LinkedIn, либо через телеграм. Телец может каким-то интересным тоже, там,
фидбеком по определенным решениям, и либо каким-то опытом, делиться опытом также. Ну,
наверное, на этом все. Большого всем спасибо. Надеюсь, было интересно. Если нет, то будем
работать над тем, что было бы, если сейчас было более интересно. Если опять какие-то вопросы
остались, можно сейчас посвятить этим вопросом. Если нет, то можно тогда уже в оффлайне пообщаться.
Такой достаточно общий вопрос. Я не очень имею представления о том, что такое вообще дат инжиниринг.
Это как раз про обработку данных и агрегирование какое-то, или что это вообще?
Не, вопрос очень хороший, но он такой больше является частью философский. Дат инжиниринг,
знаете, понятие, где же это было у меня, я его удалил. Что такое вообще инжиниринг?
Это ответ на ваш вопрос. Дат инжиниринг, что такое? Это использование всех различных
инструментов. Тоже они могут быть, имеют свои ограничения, имеют свои плюсы и минусы.
Нет такого единого инструмента, который может решить абсолютно все. И я также вас призываю
не использовать подход, потому что это такой подход, когда кто-то что-то разработал,
у него это работало или у нее это работало, значит я это могу переиспользовать, потому что у меня
похожая проблема, задачу похожую решаю. Я вас призываю не использовать такой подход в качестве
изучения примера, да, но не идите по этому пути никогда. То есть всегда пробуйте что-то
собственно дорабатывать, можно даже брать что-то, как я сказал, кто что-то разработал раньше,
но копировать один в один не надо. Это приведет к нарастанию большого и тех долга внутри компании,
ну и никакого прогресса по сути не будет, потому что какое-то решение, то есть какая-то
разработка основана для определенного решения. Она не была уникальна, она была именно конкретно,
точнее она была уникальна, не общая. И дата инжиниринга, он смотрит на разные варианты
развития решения задач по связанным с датой. То есть что такое вообще инженер, инжиниринг,
это вот решение различных проблем, имея какие-то limited resources и limited tools,
наверное. Поэтому в нашем варианте дата инжиниринг позволяет нам решать задачи,
связанные с данными, используя инструменты Spark, Flink, TouchSchool, какие-то proprietary инструменты,
сделать из данных, формировать их ценность в данных, то есть сделать какой-то там есть большой объем
данных. Мы вычисляем какие-то определенные элементы этих данных, которые нам необходимы для
аналитики, для решения задач, связанных с healthcare, допустим, определяя tumor, опухоль, рака, то есть
как формируется он. Это вот именно задача дата инжиниринга. Дальше вот эта фича инжиниринга,
это уже такой более математический подход для создания модели ML и data science, потому что уже
здесь мы определенно берем фичи, фичерсов дата, которые помогают нам строить именно такую целостную
модель ML, но начало всего это лежит в дате инжиниринге. Виктор, ответил наш вопрос или еще
больше вопросов возник? В целом, вообще понимание какое-то появилось, да, спасибо. Пожалуйста,
ну еще раз, если требуется больше какое-то пояснение или у вас возникнут какие-то вопросы,
после некоторого времени, когда вы отойдете от этой лекции, пишите либо мне в LinkedIn,
когда мы присоединимся мы с Юрой, будем поддерживать связь и, надеюсь, мы как-то вам
поможем в вашем развитии в обучении. Ваши преподаватели так, наверное, делают все возможное,
и вы передовой в институте всей России, да и вообще в мире, так что вам очень повезло,
наверное, быть настоящим путешественником, я бы сам хотел стать им, но уже, наверное,
много поздно. Так что всем спасибо еще раз большое и всего доброго.
