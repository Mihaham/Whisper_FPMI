Какой у нас план на сегодня? В прошлый раз я вам хотел рассказать про санитайзеры и
про тестирование в нашем курсе. Рассказал только про санитайзеры, да? Было такое? Вот. А про
fault injection я не рассказал вам ничего. Но я все еще хочу. А кроме этого я хочу еще,
наверное, рассказать про то, как устроен хорошее решение Mutex, которое самостоятельно не придумать,
а вот разобрать можно. И я хотел бы, наверное, это совсем бонусный уровень, я хотел бы рассказать
про то, как устроен кондвар настоящий. Вот вы там написали какое-то поделие из четырех строчек,
а настоящий кондвар выглядит очень сложно, он выглядит миллион раз сложнее, чем ваш. Вот. Ну и
может быть и не место здесь, может быть в шале нужно рассказывать. Но если время останется,
то я попробую. Но может быть у вас просто есть свои собственные вопросы и вам нет дела до Mutex
и кондвара, а у вас какая-то более насущная потребность имеется прямо сейчас. Все понятно пока,
да? Никаких вопросов нет. Да, конечно. Что такое трампин, спрашиваешь ты,
так завалированно. Идея простая. Давай мы найдем репозиторий какой-нибудь, где трампин нужен,
и посмотрим на него. Вообще мы же, наверное... Как переводится это слово?
Это не трампин, это батут. Вот так вот. Но меня уже не изменить, поэтому я буду говорить
трампин. Итак, в чем идея? У нас есть нечто под названием execution-context. Какая-то штуковина,
которая помогает нам... Давайте мы обновим execution-context. Потому что кажется,
он претерпел некоторые изменения. Вот так-то лучше. Нам видно или покрупнее сделать? И возможно,
нужно сделать менее ярко и менее ярко. Нет, не работает. Станет лучше? Лучше? Лучше, да. А так уже уже?
Или все еще лучше? Вот где-то здесь. И сделаем так, чтобы поменьше информации врезало на экран.
Итак, я напомню, о чем был execution-context. Это контекст исполнения. То есть состояние
исполнения. У исполнения есть некоторые структуры, необходимые ему. Есть call stack, есть таблица
страницы процесса. А есть состояние, которое на процессоре, на ядре сейчас. Это stack pointer,
это instruction pointer, это какие-то регистры, которые исполнение сейчас использует. И мы пишем какой-то
код, который это исполнение переключает на другое исполнение. Мы сохраняем в смене
текущий контекст. Вот текущее состояние на процессоре. Вот этот объект. И активируем контекст,
ранее сохраненный или ранее сконструированный с помощью метода setup. И активируем контекст,
который был ранее сохранен в свечту или сконструирован в методе setup. Это, собственно,
механизм переключения контекста. Мы разбирали, какой он устроен. Потому что на stack сохраняются
содержимые регистров. Потом при активации мы попаем со stack. Instruction pointer сохраняется с
помощью инструкции call red и активируется с помощью red. Но это все, мы, надеюсь, в какой-то степени
помним. А теперь ограниченный случай. Он начинается с того, что мы вообще должны сконструировать
некоторый контекст, на который мы переключимся первый раз. Вот если мы смотрим на fiber,
то как там устроено переключение контекста? Планировщик запускается. Давайте пойдем в пример.
Планировщик запускается. Говорит run. В нем говорит run loop. В нем берет первый fiber,
который мы вот здесь вот создали, и активирует его. Вот первое переключение в этом примере,
вообще в любом примере с fiber, это переключение из контекста потока, в котором выполняется
run loop планировщика, в контекст fiber. И вот этот контекст fiber он еще ни разу не был... Он активируется
первый раз. Он никогда еще не был на процессоре, этот fiber. Так что чтобы этот fiber запустился,
для него нужно контекст сконструировать вручную. Для этого мы вот где-то здесь говорим setup
контекст. И о чем эта процедура? О том, что вот нужно инициализировать исполнение руками.
Нужно что сделать? Подготовить stack для этого исполнения так, чтобы переключившись в него
в методе свечту. Давайте мы посмотрим людьми картинку. Ну что ж, надеюсь. Нет, все, мы потеряли
Silavin так бездарно. Во-первых, они ее продлили, во-вторых, причем здесь лицензия? Он просто тормозит.
Вот, мы должны подготовить контекст fiber, который еще ни разу не исполнялся к такому,
контекст вот этого вот fiber к такому виду, где лежит stack pointer, который указывает на верхушку stack
fiber, на котором лежат регистры, лежит адрес возврата, вот вся эта история. Вот, и когда мы активируем
этот контекст fiber, мы должны вот попнуть регистры со stack, сказать нет и оказаться где-то. Где мы
хотим оказаться? У нас есть некоторый пользовательский код, который хочет fiber исполнять
собственно его тело. Но мы не можем позволить себе начать исполнение fiber с исполнения сразу кода
пользователя. Почему? Потому что этот код рано или поздно завершится, функция идет до конца. В конце
этой функции конкаплятор расположит инструкцию red и процессор, увидев инструкцию red, должен
опнуться stack, адрес возврата. Но никакого адреса возврата нет, потому что мы и так до дня stack
находимся, мы с этого исполнения не начали. Вот, поэтому мы над function пользователя помещаем
служебную процедуру. Давайте мы запустим пример с fiber и это вот этот пример. Здесь уже
breakpoint стоит какой-нибудь и мы запустим и посмотрим.
Вот, где-то внизу находится служебная процедура, которая называется run. На дне еще что-то есть в
стеке. Некоторая магия, но вот она нас сейчас, наверное, не интересует. Главное, что код пользователя,
завернутый вот в эту вот unique function, ну не важно, контейнер с type array же некоторый, для
произвольных лямп, вот мы этот код вызываем из-за отдельного метода, который нужен для того,
чтобы из него не возвращаться. Вот мы не можем не вернуться из метода пользователя, потому что не
мы там код написали, но мы над этим вызовом разместили свой вызов, который вызовет код пользователя,
а потом скажет, но он все еще говорит switch to, а мог бы сказать exit to, по нынешним временам требуется.
Вот он зайдет сюда и никогда больше отсюда не вернется. Исполнение этой функции, оно до этой
точки не дойдет, потому что здесь вообще написано board. Мы зайдем в этот вызов и выйдем из него один
раз по планировщике, а вот из самого вызова terminate мы не вернемся уже никогда. Ну потому
что мы не можем туда вернуться, потому что здесь будет написана инструкция редкая, которая пробьет
одно стека. Мы не хотим, чтобы это произошло.
Не пустой. Ну вот тут какие-то, не знаю, естественно, тут локальные перемены.
Тут локальных переменных нет, по счастью, но могли бы быть.
В чем проблема?
Когда ты отдаешь память локатору, она тоже не пустая. Как может память быть пустой на бурбайт?
У них есть какие-то значения?
Так, а в чем вопрос?
Что значит почистить стэк?
Стэк это память. Что такое пустая память?
Что такое память? Память это диапазон адресов, виртуальная память. Что такое пустая память и не пустая память?
Что значит почистить память? Занурить ее?
Так, и что?
Когда ты говоришь дырит, когда у тебя строчка разрушается и в деструкторе память отдается
что с ней делается?
Она зануряется как-то?
Да все равно локатор, что там в памяти находится.
Я просто не понимаю, какую проблему мы решаем?
Ты хочешь что-то сделать, но ты не можешь мне объяснить, зачем ты этого хочешь?
С какой проблемой ты столкнулся? Какая у тебя потребность есть?
Какую задачу ты решаешь?
Не совсем понятно.
Когда мы сдаем стэк в курантине, там в стэке хранится указатель на сам стэк и наконец его, да?
Сейчас. Про какой код ты говоришь?
Ну, когда что-то не пишется, нам нужно печатать на работе.
Возможно, так.
Вот карутина, вот ее реализация, которую нужно чем-то заполнить.
Ну, ей нужен стэк, да.
Это диапазон памяти, в которой карутина будет хранить код стэк свой.
А вот в этой хранитель только два указательного начала и конец, да?
Это просто диапазон памяти.
А, то есть...
А когда он работает на стэк, он умеет свои там указательные, что он куда-то написал?
Я не очень понимаю. Вот это, мне кажется, путаешь.
Мы на первом семинаре говорили, что такое callstack?
Просто область памяти.
Ну да.
Вот она никакая не специальная, просто кусочек памяти.
И процессор рассчитывает, что в этой памяти, в этом диапазоне лежат не какие-то произвольные данные,
адреса возврата, аргументы, функции, там, локальные переменные,
и процессор хранит stackpointer на вершины этого стэка.
Но просто процессор так использует эту память.
Ну вот, mutable memview — это описание диапазона памяти,
которая будет использована для callstack.
Instruction stackpointer, который будет сохраняться в контексте,
но это вот stackpointer.
Но это вот разные вещи.
Но я все еще не понимаю...
А как процессор понимает, где он сейчас stackpointer?
Ну stackpointer у него есть.
Мы же вот смотрим stackpointer.
Ну да.
Это первый семинар.
Нужно посмотреть первый семинар.
Разобраться, как устроен процессор.
Или это...
Я просто не понимаю, в чем вопрос, если честно.
Как работает callstack в процессоре, это вот...
Как работает callstack, мы вроде бы уже говорили.
Повторять, наверное, уже поздно,
потому что мы столько раз с этим пользовались.
Или нет?
Просто если не понятно, то, наверное, вообще ничего не понятно.
Если не имеет смысла.
Поговорите со мной.
Ну я просто...
Конкретная часть...
Сначала казалось, что stackpointer,
он указывает до начала stack.
Это регистр процессора.
РСП.
Он указывает, понятно, куда.
Он указывает на вершину stack.
Ну и тут ничего не меняется.
Тут вообще нет никакого РСП.
РСП — это деталь реализации execution context.
А это просто область памяти.
За исполнение отвечает вот этот execution context.
Этот тема.
Где?
За исполнение отвечает execution context.
Но вот ему, чтобы сконструировать новое исполнение,
нужно подготовить callstack
и указать, с чего начнется исполнение.
Мы говорим, что если мы вручную изготовили
вот этот context,
то при переключении на него
начнется исполнение виртуального метода run
у этого самого трамплина батута
на вот этом стеке,
который будет храниться здесь,
в этой области памяти.
Вот как именно реализована эта функция.
Ну в какой-то степени можно не думать.
В какой-то степени можно не думать.
Впрочем, можно и посмотреть.
Я, кажется, немного переписал ее
и стало понятнее,
потому что она стала на ассемблере
и код стал гораздо короче.
Есть переключение стеков,
а есть подготовка стеков.
Мы выравниваем стек по 16 байт
от некоторых требований процессора.
Потом мы кладем аргумент
по интерно-трамплин,
потом мы говорим, что
адрес возврата будет
адрес специальной
функции,
вот такой вот.
А она уже
через седьмой аргумент,
просто поколен convention со стека,
возьмет pointer на трамплин
и запустит метод run.
И вот ровно эту функцию
мы на дне кулстека здесь и видим.
Вот с нее все начинается.
Она вызывает...
Тут некоторое проксирование есть,
в конце концов вызывает трамплин run
и получается fiber run, который
реализует этот интерфейс.
То есть это точка входа некоторая,
универсальная, и этот run
должен еще обеспечивать...
Гарантирует то, что этот run
не завершится как функция,
то есть мы из этого вызова run
никогда не вернемся. Если мы вернемся,
то будет беда.
Вот.
Ну а РСП,
как устроено исполнение на процессоре,
это первый семинар. Вот там мы говорили,
что нужно процессор, он двигается там
по вызовам функций, он использует кулстек.
Вот. Но
здесь,
вот в этом коде,
это не то чтобы прям вот...
Это не кулстек, это просто память,
это ресурс, которым используется
картина с программой.
Вот про ресурсы речь.
Вот это про ресурсы,
а вот execution-контекст,
которого здесь нет, который есть здесь,
это про исполнение.
Ну вот так вот обязанности поделены, довольно
логично. Есть ресурсы, есть
исполнение, это разные классы,
разные...
разные сущности в коде.
Трамплин.
Трамплин — это интерфейс,
через который
ты...
Трамплин
он объявлен для
всяких контекстов, потому что он про контекст
исполнения. Вот трамплин — это код,
с которого начинается исполнение
инициализированное вручную на
каком-то отдельном кулстеке.
Вот.
Вот.
Вот это интерфейс.
Кто-то, кто хочет
реализовать какую-то исполняемую сущность,
наследуется от этого
интерфейса, реализует метод run
и должен в конце позвать
exit2, чтобы выйти навсегда
из этого исполнения
и не разрушить стэк.
Вот. Тут из изменений есть
одно неприятное, потому что тут
некоторые нарушилось
и
появился еще один граничный случай.
Он появился, потому что санитайзеры
требуют специальных аннотаций при
приключении контекста. Ну, короче, чтобы код
работал с санитайзерами еще,
нужно отдельно-частно
случивать, к сожалению.
То есть он никакой
нового смысл для нас
не несет. Это просто
последнее переключение контекста, выделенное
в отдельный метод.
Это очень частая ситуация, когда
логически вам не нужно его
выделять, а
инженерная реальность устроена так, что иногда
нужно.
Что-нибудь еще?
Смотри.
Вот не надо так рассуждать.
Вот зачем я что-то делаю,
спрашиваешь ты.
Если тебе не зачем
делать, не делай.
Это вот кажется...
Вот ты смотришь на код, да?
В чем начинается хорошем коду от плохого? В хорошем коде делать только
то, что нужно.
Вот если тебе не нужно, не делай.
Давай так договоримся.
Это же задел в задачи
просто на светлое будущее. Вот кто-то может быть
где-то, когда-нибудь из вас
думает, как сделать хорошо и сделает.
И в задаче есть заготовка для того,
чтобы весь остальной код
переписывать не пришлось бы.
То есть ты переписал бы threadpool по-новому,
а весь остальный код продолжил бы работать
без изменений практически.
И там и тесты не разломались бы.
Но если тебе это сейчас не нужно,
ты не понимаешь как, это сложная задача
вообще-то, то
можно об этом не беспокоиться.
То есть ты не должен в принципе в курсе делать чего-то, что ты не понимаешь
зачем ты делаешь.
Если тебя что-то требует,
то, в смысле
требует непонятного, то спроси.
А если тебе не отвечу, зачем?
Потому что в условии задачи написано немного.
И если понятно, то понятно.
Если не понятно, то однажды я объясню.
Когда потребуется.
Когда в этом необходимость
появится.
Пока не требуется.
Так что ты можешь об этом думать
в фоне, но
делать эту задачу совершенно необязательно.
Потому, что
если уж делать,
делать очень хорошо нужно.
Иначе код испортится.
Нужно так, чтобы он и лучше стал,
и такой же симпатичный.
Задача кажется написана,
чтобы аллокации не было в коде.
Если Fiber позовет
100-500 раз yield
в хорошей реализации,
то в хорошей реализации будет ноль аллокаций
дополнительных.
Ноль упрощений к аллокатору.
Это очень тонкие штуки.
Конституирование STD-фанкшн это аллокация.
Вы же писали STD-фанкшн,
я, кажется, вас спрашивал.
Не все.
Значит, не у всех будет
аллокация, видимо.
Это объяснить очень легко.
Мне кажется, я говорил в прошлый раз,
вы же не можете вектор лямбды положить разный?
Потому, что это разные анонимные классы,
разные типы просто.
Это называется type array.
Тип стирается.
У вас было много анонимных, неизвестных типов,
а стало много STD-фанкшн одинаковых.
Так что, когда вы заворачиваете
лямбду в фанкшн,
то вы делаете потенциальную аллокацию.
Когда вы кладете что-то в вектор,
вы делаете потенциальную аллокацию.
У вас StartPool делает и то, и другое сейчас.
Кладет STD-фанкшн в контейнер.
И вот он уже сделал две аллокации.
Можно сделать ноль аллокаций.
Это требует некоторого размышления,
как устроен STD-фанкшн,
как вообще type array устроено.
Короче, это требует некоторого инженерного опыта,
которого у нас, возможно, нет,
поэтому мы сейчас об этом не очень сильно
обеспокоимся.
Задачи это не требуется.
Гораздо полезнее, мне кажется,
задача из чего-то лишнего
сделать вот этот самый процессор,
который генератор.
В этом гораздо больше пользы,
потому что это можно сделать сейчас
на нашем текущем уровне,
и кажется, что довольно полезный навык
понимать, как из корутина делать
генераторы, итераторы,
все вот это.
Я бы посвятил время, в первую очередь,
вот этой штуке.
Что?
Зачем я писать без корутина,
когда задачи корутина просят написать
с помощью корутина процессор
и налег?
Нет, это...
Ну и более того,
он находится в директоре...
Короче, тут много указаний,
прямых вообще,
что корутина нужна, конечно.
Да, действительно.
Что еще? В чатике я не отвечаю
человеку, а давно хочу.
Он написал, что он взял
свой минуток секунд вар,
положил их в threadpool,
и threadpool прошел.
В смысле, он работает.
Это довольно приятно.
Так вот, я предлагаю...
Я не знаю, чем это кончится,
может быть, это плохая идея,
потому что не испробована еще.
Ну вот, если вам
прям нечем заняться,
то вы можете в файберах
завести директорию...
Вы не видите ее, да, наверное?
Да, и сложить туда
ваш минуток секунд вар,
и дальше
с ним жить.
Что?
Ну то есть, вот ты пишешь код...
Ну, сейчас.
Речь про то, что ты можешь
накапливать решения в задачах
таким образом.
Это, с одной стороны, забавно,
поэтому я предлагаю кому-нибудь это попробовать,
но, наверное, не всем.
А с другой стороны, это немного опасно,
потому что раньше у вас был
Mutex, аннотированный для fault injection,
чтобы
ломаться в тестах,
а теперь у вас Mutex из Futex,
который аннотирован для fault injection.
И в итоге fault injection работает чуть хуже,
потому что вокруг него больше работы
лишней происходит.
Так что
может быть это повлияет на тесты,
а может быть fault injection настолько хорош,
что в тестах по-прежнему будут все хорошо работать.
Я вот скорее во второе верю.
Но кто-то может попробовать, и в любом случае
это будет забавно, когда
файберы будут накапливаться, расти,
и все это будет из одного атомика
по-прежнему.
Кажется, что это наша цель, которую я...
Одна из наших целей, которую я озвучивал
на первом занятии.
Вероятно, завтра у нас появятся две большие задачи.
Нет, одна большая задача.
Про
эхо.
Про то, чтобы написать эхосервер
с помощью файберов, которые реализованы
с помощью ASIO.
Ну, это вторая половина пред
последней лекции.
А в...
А через две недели у нас...
Короче, ладно, не буду показывать.
Так что, пожалуйста, файберы не откладывайте.
Вот уже неделя прошла,
полторы недели уже прошли.
Осталось немного времени.
Хоть кода там и немного, но подумать нужно
основательно, чтобы была польза.
Ладно, что-нибудь еще?
Попросы какие-нибудь?
По поводу Q,
короче,
не надо было
в общем,
в спинлоговом месте,
чтобы ждать, чтобы там указать
появился хороший.
Ты про спинлог, который
с протоколом куберетности кашей?
Да.
Там, короче,
я проверил,
если вот этот вот спинлог, который
ну, там надо будет ждать,
чтобы указатель поставился.
Да.
Или просто крутиться
на процессоре,
или ставить какую-то штуку,
наверное, одинаково на этой,
ну, на системе
тестирующей.
А она у меня на компьютере получается быстрее,
если он просто будет крутиться на процессоре.
Наверное, связано именно с реализацией
спинлога, который...
Смотри,
анализ производительности
это очень-очень-очень сложно.
У меня есть какой-то тест, и на нем как-то работает.
И я делаю из этого какие-то
далеко идущие выводы. Нет.
Так делать не нужно.
У тебя есть... Во-первых, ты вообще
не бенчмаркаешь, ты запускаешь стресс-тест.
Стресс-тест... Ну, я в чате кому-то отвечал,
пожалуйста, вот запомните это.
Бенчмарки — это отдельная история.
Это только ревизная сборка, разумеется.
Это минимальный оверхед.
Это очень разумный сценарий,
который тестируется. Ты можешь построить
бенчмарк, который тестирует
какой-то абсолютно синтетический сценарий, который
у тебя в коде не возникает.
Тут очень сильно зависит от того,
сколько в критической секции обращений к памяти,
насколько она большая, что делают потоки
между секциями, насколько там большой зазор.
Вот, бенчмаркать
такие отдельные синтетические кусочки
кода — это
в целом не очень полезно, это опасно,
потому что ты можешь оптимизировать их
вместо того, чтобы оптимизировать
свое реальное приложение.
Поэтому вот
смотреть на стресс-тесты на время точно
не нужно, они вообще не об этом, они не подходят.
И нужно смотреть,
если ты хочешь действительно сравнить
что-то, нужно сравнить на какое-то
смотреть на какую-то разумность
сценарий их использования. Кроме того,
код, который
спинлок, который в задаче,
в этой маленькой, будет
работать лучше,
он не про то, чтобы он работал быстрее
всегда, он про то, чтобы он лучше
масштабировался. То есть у нас лекция была про то,
что у нас число ядер растет
и между ними больше коммуникации
появляется.
И этот спинлок
он про то, что с ростом
числа ядер
у тебя замедление от этой
синхронизации внутри спинлока будет ниже
и замедляться
будет медленнее. Будет, конечно, замедляться,
потому что есть верховетная синхронизация,
ты за это плачешь неизбежно,
но замедление будет меньше.
И для того, чтобы увидеть,
что работает действительно хорошо,
нужно зайти на какой-нибудь рабочий сервер,
где 16 или 32 или 64 ядра
и там уже сравнивать.
На четырех ядрах ты там ничего
не увидишь. Там просто оверхед от сложности
спинлока будет пожирать весь выигрыш
от конкретности кэшей.
Так что на четырех ядрах
я не думаю, что можно что-то...
В общем,
нужна большая машина и нужен специальный
бенчмарк, нужна релизная сборка, и вот тогда
можно будет сравнить.
Вот я предлагал кому-нибудь
из семинаристов
на Демидрису я предлагал пойти на большую машинку
тестировать, может быть.
Если его упросить, он это сделает.
И что-нибудь нам нарисует,
какие цифры. Давайте его попросим.
Да, я спешу и...
Он нам это сделает.
Ещё вопрос.
Просто задают вопросы два человека, остальные.
Всё понимают?
Ничего не понимают. Как мне им помочь?
Что они здесь делают?
Скорее мотивация такая, что
семинары, которые, ну вот, например,
можно задавать вопросы по старому материалу,
их можно пересмотреть, а если задавать вопрос,
в моём семинаре как бы немножечко не случится.
В плане, вы не расскажете больше,
чем могли бы. Ну я вот сейчас что-то рассказываю
или я ничего нового не рассказываю, да?
Ну хорошо, хватит от
отвечать на вопросы, ни к чему.
Покончим с этой ерундой?
Ну всё, я тебя услышал.
Тогда поговорим про fault injection.
Как работают тесты
в нашем коде?
Ну я уже говорил, что мы запускаем
тесты с санитайзерами для того,
чтобы через обращение
к памяти разломанной находить
косты нашей синхронизации.
Мы запускаем стресс санитайзером
решения, собираем и запускаем,
чтобы находить
датарейсы,
определения которых мы даже не понимаем
до сих пор, что печально.
И это мы починим в ближайшие выходные.
Но вот и thread санитайзер,
и address санитайзер, и вообще
любой санитайзер отличает то,
что они проверяют не программу,
они проверяют конкретное
исполнение.
Ну это такой оракул, которому мы даем исполнение,
которое вот на процессоре реализуется.
А этот оракул, вот там, не знаю, моделирует
happens before, мы этого не знаем вообще,
моделирует там
локатор, запоминает, что алоцировано,
что нет, там ловит ошибки обращения
к памяти, смотрит на конкретное
исполнение. И у
этого подхода есть, разумеется, есть
такое очевидное ограничение, что если в
исполнении в конкретном ошибке не проявилось,
то санитайзер вам ничего не скажет.
Если он говорит, что ошибка нашлась,
то он ее нашел, он ее предъявляет, пишет
отчет, и вы знаете, что у вас проблемы.
Если санитайзер вам ничего не говорит,
программа успешно завершается, успешно
работает, то, видимо,
ну как вы это делаете, что с вами все хорошо?
А может быть, вам просто очень везет?
Ну или скажем, вам
пока везет, потому что
проблема редкая и просто не воспроизводится.
Вот скажем,
я, скорее всего, вам
однажды расскажу, когда у нас будет тема
про лог-фри, про лог-фри-алокатор,
который и в Яндексе давно-давно написали,
и потом, спустя, кажется,
даже годы
нашли в нем баг, который проявлялся,
когда у вас там машина с
6400 ядрами, и вот где-то очень
редко, вот она там работает 24 на 7,
там алоцирует-делоцирует постоянно,
и вот иногда очень редко что-то
ломалось, потому что в лог-фри-алокаторе
был очень хитрый баг.
Это было супер-редко и супер-редко
проявлялось.
Так вот, о чем мы сейчас
говорим? Мы хотим
каким-то образом подействовать на
исполнение программы так,
чтобы из нее вываливались
ошибки, чтобы
ошибки случались, а дальше
санитайзер их обнаружит.
Ну, либо санитайзер их обнаружит, либо, скажем,
какой-то ассерт у нас поломается.
То есть мы пишем, что
между мьютокс-лог и мьютокс-анлог должен
находиться один поток. Там увеличиваем счетчик,
смотрим, если он был равен единице уже до инкримента,
значит все, мы нарушили знаменитые исключения.
Ну вот, то есть чтобы
ломались ассерты в тестах, чтобы
санитайзер обнаруживал ошибки,
адрес LITRED, нужно, чтобы исполнение
было более интересным,
скажем так.
Ну, о чем идет речь? О том, что у нас
есть тест, там есть...
Мы говорим про многопоточное исполнение,
оно недетерминированное.
И оно может пойти очень разными
траекториями. И как можно
все эти исполнения разом
представить? Можно представить себе
их в виде графа, где каждая
вершина – это моментальное состояние мира,
такой снимок, снэпшот,
который состоит из
состояния кучи разделения памяти
и содержимого стэков.
То есть мы как будто бы фотографируем процессор, память
и у нас получается такое моментальное состояние.
Это вершина графа.
И можно из этой вершины
пойти в разные стороны, можно сделать
хоть одним потоком, другим, третьим и так далее.
Программа правильная, если
она...
Есть два типа свойств – safety и liveness.
Взаимное исключение, скажем,
это safety свойства, что никогда
не происходит ничего плохого.
Очень неформально говорить. Так вот, это свойство
в том, что в каждой вершине такого графа
свойство выполняется. В каждой вершине
такого графа нет двух потоков, которые находятся
между узами lock и unlock.
Мы бы хотели это проверить.
Мы пишем какой-то стресс-тест.
Что такое стресс-тест? Мы берем,
запускаем сколько-то потоков,
какое-то интересное число n.
И дальше они
в цикле вызывают lock-unlock,
а внутри написано sort. Внутри не больше
одного потока.
И на что мы надеемся?
Видимо, мы обойдем много
состояния этого исполнения,
много вершин графа мы обойдем.
Тут проблемы две. Во-первых, граф
очень большой.
Если у вас 10 потоков,
то с ростом числа потоков,
количество состояния растет экспоненциально,
потому что у вас все интерливинги получаются,
все переключения.
Вторая проблема в том, что планировщик
операционной системы
не то чтобы сильно потоки перемешивать.
У него же нет такой цели. У него есть цель
противоположная, чтобы все спокойно исполнялись.
Так что исполнится один поток некоторое время,
потом исполнится другой поток некоторое время.
Переключения редкие.
А баги сложные. Появляются тогда,
когда у вас буквально потоки делают по одному ходу
и так очередуются постоянно.
Две проблемы. Число состояния слишком большое
и планировщик
не перемешивает потоки достаточно
хорошо для вашего стресс-теста
и для санитайзера.
Как мы боремся с этими проблемами?
Во-первых, с числом состояния
мы не боремся особо.
Мы говорим, что мы просто не пишем стресс-тесты,
где у нас 100 потоков.
Потому что
вот так устроена Вселенная.
Это нельзя доказать,
но можно просто в это поверить.
Все сложные баги,
связанные с конкурентностью,
с чередованием,
и в потоках,
и в распределенных системах,
это одинаково справедливо.
Все сложные баги можно смоделировать
на очень небольшом количестве участников.
Такое свойство Вселенной.
Трех потоков достаточно для того,
чтобы смоделировать любой возможный баг, кажется.
Трех-четырех максимум.
Двух иногда достаточно.
Задача LifeLog. Вы построили LifeLog
из двух потоков.
Любые контры примера, которые вы строите,
можно построить для трех потоков во всех задачах.
Потому что это продакшн,
и там нет fault injection в продакшне, разумеется.
Совсем другая ситуация.
Я не про то сейчас говорю,
продакшн это не тестирование,
это разные вещи.
Если мы целенаправленно что-то тестируем,
то во-первых, нам не нужно иметь
много потоков,
поэтому в тестах везде их единицы.
Два, три, пять максимум.
А во-вторых,
чтобы получить большее
покрытие графа
состояний исполнения,
нужно каким-то образом воздействовать
на планировщика.
И вот техника называется fault injection.
Недрение сбоев.
Мы не просто
исполняем стресс тест,
мы внедряем в него сбои
и смотрим, как наш код реагирует
на эти сбои.
Но проще объяснить
на распределенных системах.
У вас есть распределенная система,
хотя вы про это мало что знаете.
Там есть отдельные узлы,
они общаются, передачи сообщений,
и система должна быть надежной
в том смысле, что она должна переживать
узлов.
Зачем система распределенная?
Затем, что одна машина может отказать,
это неизбежно, машины ненадежные.
Но пользователь ничего не заметит.
И как можно проверить,
что система надежная?
Можно дать на нее нагрузку
и ждать год.
За год у вас сломается 100 дисков,
у вас машина тысячу раз перезагрузится.
А что вы можете сделать иначе?
Вы можете построить
некоторые тестовые окружения,
выпустить узлы вашей системы, дать на нее нагрузку,
и просто ходить
и нажимать на кнопки Restart.
Вытаскивать из машины диски на ходу.
Выдергивать провода.
И система,
если вы выдерживаете все провода,
система не будет работать.
Но если вы
выдергиваете поочередно,
сломали одну машину,
потом включили обратно, сломали другую машину,
это бы и без вас произошло
просто за очень большое время.
А вы это время зажали.
Вы делаете это сами.
Вы внедряете сбои и рассчитываете,
что ваша программа по-прежнему продолжит работать.
В смысле, что ваша распределенная система
по-прежнему продолжит работать
и отвечать пользователю там без ошибок,
чтобы это не значило.
Вот идея Фолтин Джекшена.
И в курсе про распределенная система
мы только так жить и будем.
В нашем курсе
Фолтин Джекшен выглядит так.
Сбои, которые должна
переживать ваша программа,
это переключение и пауза поток.
Вот если вы берете,
вы пишете два атомика подряд,
в смысле две операции на атомика подряд,
не знаю, Store, там уходит Load,
то
внутри...
А что я рассказываю? Давайте я покажу.
Смотрите, вот вы пишете
какой-то код.
И нам хочется внедрять
в этот код сбои.
Еще
некоторое такое свойство природы,
что
в коде, где нет гонок,
переключение потоков
не нужно внедрять везде.
Достаточно переключить потоки в точках,
где потоки обращаются к приметилописно-хронизации,
где они общаются друг с другом.
Вот, ровно поэтому
в этом коде мы используем не стд-атомик,
не стд-мьютакс, не стд-кондвар,
а свои собственные обертки,
и вот при обращении к ним
внедряются сбои,
то есть переключаются...
потоки переключаются друг на друга.
И это происходит гораздо чаще, чем
они переключались бы в
обычном планировщике, планировщике
операционной системы.
На самом деле сложнее, конечно,
в библиотеке тут есть много
много слоев.
Вот есть слой фасад,
с которым вы работаете.
Тут лежит
некоторое объявление атомика.
На самом деле атомиков здесь два лежит.
В случае сборки с файберами,
в случае сборки с потоками.
Ну, давайте я пока расскажу
только про потоки,
а потом объясню, зачем файберы нужны.
Вот если вы собираете
код
с
в релизе
и без fault injection,
код, который мы написали в курсе,
то, скажем, Mutex
превращается просто
в STD Mutex.
То есть тут обычный Mutex, никакого оверхеда нет.
Если же
вы
в сборке устанавливаете
флажок
fault, давайте это
сделаем сейчас.
Активировалась другая ветка.
И теперь ваш
Twistas Delight Mutex
type alias другой.
Это некоторые faulty Mutex.
И чем этот faulty Mutex занимается?
В методе lock
у него есть реализация
и у него
вызывает в конце метода lock.
Но
перед локом и после лока
стоит вызов InjectFault,
который внедряет сбой.
InjectFault вызывает
некоторого adversary, злоумышленника,
который решает, когда же потоки
нужно переключать.
И вызывает у него fault.
И дефолтная реализация этого
adversary, она
иногда
переключает потоки.
Иногда вызывает yield по некоторому хитрому
правилу, который
магически работает и вытрясает
из вашего кода бага.
Эта стратегия внедрения сбоев,
она помещает в ваше
исполнение больше переключения контекста,
больше переключения потоков.
И в результате мы увеличиваем таким образом
покрытие графов в состоянии стресс-теста.
А значит, ломается больше ассертов,
выпадает больше датарейсов, выпадает больше
user-free и подобных вещей.
Итак, для fault injection
обернуты все примитивы, которые мы
используем.
Fetch эту атомику
до и после injectFault.
CompareExchangeWig
где он?
Написан вот так вот.
Иногда говорим false просто
потому что. Почему бы и нет?
Можем позволить себе это по семантике.
Вот это
следующий слой в библиотеке,
то есть мы можем использовать std.mutex,
а можем его обернуть,
ну, std.atomic можем его обернуть в такую
штуку. Или мы можем
взять std.mutex
и обернуть его вот
нет, не здесь.
Вот в такую штуку.
Это следующий
уровень библиотеки.
А под ним еще
один слой есть, а именно
он здесь называется strand
или виртуальный поток.
То есть мы, когда
внедряем сбой, мы переключаем потоки.
Ну, точнее мы переключаем не потоки,
а некоторые вот штуки, которые исполняются,
которые похожи на потоки.
И вот эти
потоки как будто бы
они могут
быть потоками и std.red могут быть.
А могут быть и не
std.red. Давайте я покажу
где они
объявляются.
Ну, наверное, здесь, да.
Вот этот strand
thread может быть thread,
а может быть, может быть
std.red по умолчанию.
А может быть
штукой, которая
маскируется по thread, то есть файбером.
Нет, не почему, а зачем.
Затем чтобы
моделировать потоки
под файберами, в смысле
пускать тесты, где каждый поток
это файбер, потому что, во-первых,
ну, это даже где-то там написано.
Ну, во-первых, файберы работают
быстрее, их быстрее переключать,
значит в единицу времени у нас
будет больше, мы
переберем больше исполнений.
Еще одно свойство, очень важное,
очень удобное в тестировании,
это детерминизм.
Вот с потоками это
еще ладно, а вот с распределенными системами
с детерминизмом тестировать просто
в миллион раз лучше.
Это то, чего люди решены
на планете в большинстве своем,
а мы осенью будем этим пользоваться, и это прекрасно.
Так делает очень мало кто на свете,
это очень сложно, но
с детерминизмом тестировать конкурентные баги,
отлаживать их гораздо проще,
но вы понимаете почему.
Тест, ну,
смотри, у тебя баги недетерминированные
по своей природе, вот как сложится исполнение,
оно выпадет или не выпадет.
А исполнение под файберами
там нет недетерминизма.
Там все в одном потоке,
и передача управления кооперативная.
Вот если мы инициализируем
адверсари некоторым Сидом,
одним и тем же, то он будет
генерировать одну и ту же череду
сбоев, переключений,
и это все детерминированно исполнено с под файберами.
И тест будет работать у тебя
так же, как и любой другой машине,
и ты можешь его просто по шагам воспроизвести.
Здесь мы этого не делаем, а вообще можно.
Осенью будем.
Это огромный бонус для тестов,
недетерминированные тесты это всегда очень плохо.
Кроме того,
ну, там есть детектор дедлоков еще заодно,
но вот еще одно
приятное свойство, которое мы получаем
именно используя файберы,
мы полагаемся теперь на планировщик
не операционной системы, а свой собственный.
И почему это удобно?
Почему это нам что-то дает новое?
Когда мы говорим
yield в исполнении с потоками,
то что мы делаем? Мы ставим поток
в конец очередной исполнения.
Когда же
мы для файберов
говорим yield,
то происходит нечто
более сложное, потому что
планировщик, когда
выбирает очередной файбер для исполнения,
он просто берет случайный.
То есть мы, моделируя код
под файберами, еще перемешиваем очереди
ожидания в мьютоксах, в кондварах
и очередь
рангью в планировщики.
Это вот
еще больше перемешивания, которое нам недоступно,
когда мы работаем с
тредами из планировщика
в операционной системы.
И эта комбинация
из всех этих режимов,
то есть в итоге
что мы получаем в библиотеке?
Мы получаем довольно много режимов сборки,
мы выбираем код по 100-500 раз.
У нас есть 3 направления,
в которых мы можем что-то варьировать.
У нас есть исполнение под тредами
или под файберами,
мы выбираем что-то, у нас есть
разные санитайзеры, тред-санитайзеры,
адлес-санитайзеры, и у нас есть fault injection.
И мы разные варианты можем комбинировать,
и каждый вариант по своему разуму.
То есть он какой-то класс багов старается поймать.
Идея fault injection такая,
что мы внедряем в исполнение сбоя
в нашем случае для переключения,
и за счет этого увеличиваем
покрытие графа состояния стресс-теста.
Поэтому в нем проявляется
больше ошибок, и они детектятся
ассертами
тред-санитайзером и адлес-санитайзером.
То есть fault injection и санитайзер
работают в комбинации.
Fault injection помогает санитайзерам.
Преимущество файбера,
по тому, что вы сказали,
почему она может потребоваться тестировать
именно на файберах?
Потому что это все-таки некоторое упрощение реальности.
У тебя настоящие труды параллельные,
а файберы не параллельные.
И вот, скажем, data-rays,
они проявляются именно
на потоках нужно тестировать,
а не на файберах.
То есть ты получаешь преимущество,
но с другой стороны теряешь физическую
параллельность. Это потоки
настоящие параллельные все-таки,
и об этом иногда нужно думать.
Ну что скажете, есть вопросы или нет?
Вот fault injection,
смотрите,
вряд ли
этому, мне кажется,
почти не учат, а мне кажется,
что это суперважно.
Вот без хороших тестов писать сложные системы невозможно,
и без хороших тестов невозможно
писать системы
многопоточные и распределенные особенно.
Потому что баги у них не детерминированные,
и никакими простыми тестами они не ловятся.
Вот. А с другой стороны,
это такие компоненты инфраструктуры,
на которых вот как бы все остальное,
весь остальной мир строится.
Вот вы пишете старт-ап,
где там, не знаю, вы
подбираете котят пользователям.
Вот. Ну и как бы все здорово,
но под капотом там какая-то база данных лежит,
и под капотом какое-то облако.
И облака и база данных,
вот на них живет, в общем-то, весь бизнес.
И если там будут ошибки,
это будет очень печально для всех.
А сам кот в этих базах данных
и в этих облаках, он очень сложный,
очень распределенный, очень конкурентный,
и тестировать
его нужно вот каким-то
специальными, особенными инструментами.
Вас это почти не касается на учебе,
потому что вы отправляете, вы нажимаете
какую-то магическую кнопку, и вот кот работает.
Но если вы пишете большой проект,
то вам просто необходимо с самого начала
подумать, как вы будете его тестировать.
И, скажем, вот для курс
распределенных систем я реализую некоторое
идеальное видение мира, как это должно быть.
Так делают, кажется, только в Apple
и только в одном месте.
И делают в Amazon, в ВВС.
Там тоже исповедуют
такой подход с fault injection
и с тестированием, как бы с дизайном,
который основан на тестировании с самого начала.
Ну, в общем,
об этом нужно думать
с самого начала,
когда вы пишете код.
И вот фреймворк, который мы пишем,
который будет использоваться осенью,
он написан поверх твиста,
потому что, я не знаю,
как писать сложный конкурентный код,
не умею его тестировать.
Я самому себе доверяю, но проверяю.
Не доверяю.
Примерно понимаю, что это правильно,
но как мне убедиться? Я должен написать инструмент,
чтобы это делать.
Как делают люди,
не знаю, в продакшене, на работе,
как они пишут код и просто
проверяют его глазами,
непонятно.
Вот, скажем,
я вам не успею рассказать уже без шансов, конечно,
но вот
я хотел вам показать
реализацию кондвара
в питредах.
И, ну, вот, смотрите, вы же писали
какой-то уже код на атомиках.
И вы понимаете, что если там один атомик,
то это простое решение. А если там два атомика,
то уже вот сильно сложнее. Если три атомика,
то, кажется, такого даже не бывало.
Но нужно представить себе больше интерливингов.
Вот в питредном кондваре,
который вот std-кондвар
под линуксом,
там атомика примерно дюжина,
и вот код на них он занимает,
ну, тут комментариев много,
но код из десяти строчек
в экспоненту сложнее,
чем код из трех строчек,
а здесь их, там, не знаю, несколько десятков,
вот именно содержательных строчек.
Как автор...
Я верю, что автор очень умный.
То есть я читаю комментарии, читаю...
Он очень умный, он все понимает, он очень аккуратен.
Но вот это, в конце концов,
человек, и
как бы он написал код,
он даже может быть очень умным
и знать, что он работает, но это
бас-фактор некоторый.
Вот, если этот человек уйдет с проекта,
то кто будет поддерживать этот код?
Может быть, его и не нужно рефакторить дальше,
но все равно это очень сложно.
Вот хорошо бы, чтобы можно было
опираться на инструменты.
Как люди обходятся без них,
я плохо понимаю, честно говоря,
поэтому я вот за то, чтобы с самого начала,
если вы пишете многопоточный код,
чтобы у вас были инструменты,
чтобы его тестировать.
Я об этом еще расскажу чуть позже,
сильно позже, в лекции про планировщик,
когда
в языке Rust вы, наверное, про него
слышали, писали
новый рантайм для асинхронности
планировщик в Токио,
то перед тем, как его написать, написали сначала инструмент,
который перебирает в нем все исполнения.
А только потом написали планировщик уже,
потому что иначе непонятно, как этот код тестировать.
Он очень сложный, на нем будет очень многое
завязано, к нему будет очень многое зависеть.
Он должен быть абсолютно надежным.
Вот человеку мы здесь не доверяем.
Человек не переберет в голове все вот эти там
сотни, тысячи состояния
исполнения.
Вот мы тоже не перебираем, но мы
увеличиваем покрытие. В идеале
есть другая крайность,
когда мы прямо перебираем все
исполнения. Так, в принципе, тоже можно сделать.
В курсе это однажды появится, то есть можно
написать тест на C++
и просто перебирать все его исполнения
очень хитрым образом.
В принципе, пример даже
у меня в
на GitLab можно найти Маша Фяфанова, студентка
два года назад писала такой перебор.
Вот, он работает.
И это будет как бы еще один
бэкэнд для
фреймворка
Twist в идеале.
Ну что, наверное, внушил
у вас эту мысль.
Понятно ли, зачем мы
тестируем код по несколько раз, если
запускаем те же тесты по несколько раз,
и зачем мы пишем все вот эти странные
штуки вместо STD?
Должно быть понятно, где нужно их писать,
где нет. Вот нам нужно подменять только
примитивы синхронизации, где потоки общаются
друг с другом, потому что вот в этих местах
переключения дают какой-то эффект интересный.
Во всех остальных местах нам этого не нужно.
Ну и вот еще одно ограничение,
которое из нашего фреймворка следует.
Вы его видели уже в задаче
RotRedPool, и давайте я просто
в документации это еще раз покажу.
Мы не можем использовать примитивы,
которые как-то завязаны на триды.
Вот мы не можем использовать
ThreadAtomicMute и Second War,
потому что для файберов должна быть
своя реализация. А кроме того, мы
еще лишаемся ThreadLocale.
Вот мы его заменяем таким классом.
Сильно не похоже на ThreadLocale
ключевое слово,
но с семантикой его остается
такое же.
Кстати, ThreadLocale вас не удивил, да?
Ничего необычного.
Немного необычного.
Но это такой целый
как бы класс переменных, у вас есть локальные
переменные, которые у каждого потока свои,
у вас есть глобальные переменные, которые у всех потоков общие.
А у вас есть ThreadLocальные, которые с одной стороны
глобальные и к ним можно обращаться всем.
А с другой стороны, это вот
логически одна переменная, у которой много значений
у каждого потока свое.
Вот это такое
довольно уникальная штука,
не выражающиеся через другие.
Если вы пишете файберы, то вы, в принципе, могли бы прикинуть,
как такая штука могла бы работать.
Могли бы сами написать при желании.
Можно так даже сделать.
Когда-нибудь.
Но правда, если вы пишете файберы сейчас в задачах,
то вы способны придумать реализацию такого объекта.
И вот так вы сможете понять, как именно он устроен.
Самый честный способ.
Ну что, если с фолтинжекшеном покончили,
то давайте я расскажу про задачу Mutex.
Я вам в чате писал, что вы можете пойти по ссылкам,
открыть ссылку с каким-то кодом, переписать его,
а я у вас в его сотрудно-защите.
Я так даже у кого-то сделал в прошлый раз.
Ну, я следую своим обещаниям, все нормально.
Я так делал не потому, что я вредный,
ну, то есть не только поэтому,
а потому что этот код...
Знания цены, когда вы сами к ним пришли,
а вот просто какой-то готовый рецепт с интернета
вас ничему не научит,
вы его, возможно, не поймете.
Тем не менее, это решение Mutex,
которое получше, чем у вас,
потому что, ну, что вы написали?
Сначала вы пишете...
А можно даже код показать, наверное, да?
Задача...
Mutex, Mutex.
А тут решение написано уже.
Вы с этого начинаете, да?
Вот вы пишете сначала какой-то спинлог,
потому что покрутиться вы засыпаете.
А потом вам говорят в защите,
или вы прошли внимательные условия,
что не нужно звать wake1 каждый раз в анлоке,
когда Mutex свободен.
Поэтому вы добавляете сюда еще счетчик.
И вот если счетчик больше нуря,
то, значит, нужно позвать wake1,
чтобы разбудить спящий поток.
Вот решение, которое...
Смотрите, это статью читать особо не нужно,
потому что, во-первых,
для того чтобы понять, что такое Mutex,
лучше прочесть комментарий из ядра,
а чтобы понять, что такое Mutex,
лучше прочесть статью, откуда автор скопировал это решение,
не понимая его,
потому что он даже не исправил метатонлог,
который можно было проще написать.
А эта реализация, она из довольно старой статьи,
одного из мейнтрейнеров ядра,
в Linux,
который называется Mutex и хитрые.
И вот там он пытается убедить вас,
что Mutex довольно сложные в обращении,
и пишет там сначала простой Mutex,
потом Mutex получше,
а потом Mutex совсем получше.
В статье была реализация
вторая, получше.
В чем ее цель?
В том, чтобы
немного сэкономить
в ситуации, когда contention нет.
То есть, у вас есть Mutex,
за него никто не соревнуется,
его захватывает только один поток,
и захват должен происходить
как можно быстрее.
Вот в нашей реализации,
на быстром пути,
когда Mutex свободен,
две атомарные операции.
Increment счетчика и Exchange
на флажке.
Вот автор хочет добиться того,
чтобы, когда Mutex свободен был,
то его захват требовал бы
одной атомарной операции.
Для этого
автор схлопывает
флажок плюс счетчик
в одну переменную
с тремя состояниями.
Ноль, один на два.
Ноль.
Lock свободен.
Один. Lock захвачен. Mutex захвачен.
И конкурентов нет.
Два. Mutex захвачен.
И при этом есть потоки, которые ждут освобождения.
Тут очевидно,
происходит какая-то потеря информации,
потому что раньше мы знали количество,
а теперь мы знаем, что больше нуля.
И это некоторую сложность добавляет.
Но на быстром пути
вот такие три состояния
позволяют нам сэкономить
на операциях над атомиками.
Каким образом?
Вот поток приходит в лог
и, смотрите, тут замечание
техническое.
Тут не атомарная операция,
в смысле не SD-атомики, тут некоторые псевдокод.
И вот atomic-dec, atomic-inc
это fetch-add, fetch-sub.
Fetch-sub, fetch-add.
Compare-exchange
вот такая штука,
такая функция.
Это как compare-exchange над атомиками,
но немного по-другому.
Потому что compare-exchange
в атомиках возвращает вам true,
если успех false, если не успех.
А в этой реализации
вам возвращают просто старое значение.
Потому что вы сами разберетесь
успех или неуспех.
Если вам вернули ноль, значит успех,
если вернули не ноль, значит не успех.
Как устроен вызов лог?
Мы говорим compare-exchange и пытаемся
поменять состояние спинлока,
состояние мютокса с 0 на 1.
Если это получилось,
то все, конец.
Лог захвачен, можно идти дальше.
Одна атомарная операция.
Если же лог не захвачен,
то,
видимо, поток, который
провалил этот касс, должен
уснуть в ожидании, что лог
освободят.
Потому что у него есть фьютекс вейт.
Но перед этим
он должен переключить
состояние мютокса из 1 в 2,
чтобы поток, который
освобождал мютокс потом,
нас разбудил.
Поэтому мы делаем compare-exchange
мы перед фьютекс вейтом
делаем compare-exchange
из 1 в 2.
Но либо не делаем, если мы видим,
что там уже 2 было.
Тогда просто засыпаем
и ожидаем, что там 2.
То есть мы спим на 2 только.
Что мы делаем в анлоке?
В анлоке написано какое-то дичное,
мой вкус.
Какова цель анлока?
Сбросить состояние мютокса в ноль,
во-первых.
А во-вторых, если были
ждущие потоки, то один из них разбудить.
Автор делает очень странно.
Он делает декремент
атомарный.
И если он получил...
А что он может увидеть в декременте?
Либо 1, либо 2.
Если он увидел 2,
то он делает
фьютекс вейк.
Если он увидел 1, то он уменьшил
из 0 из 1 в 0,
то он ничего не делает.
Потому что вот всё.
Я тоже спрашиваю себя
и не нахожу ответа.
Конечно же, то, что он хочет сделать,
описывается так.
И если эксчейнч 0 равен 2,
то фьютекс вейк.
Это гораздо проще,
потому что между этой строчкой и этой
может много чего произойти сложного.
А в эксчейнче уже не может.
Да, этот код нужно стереть
и написать здесь
если эксчейнч 0 равен 2,
то фьютекс вейк.
Это код здорового человека.
Ты просто доверяешь коду из интернета.
Ты для этого и учишься,
чтобы не доверять коду из интернета.
В интернет может написать любой человек.
Понимаешь? Никто его не остановит.
Он завел себе блог и пишет в интернет.
Поэтому ты должна очень аккуратно
фильтровать то, что ты читаешь.
Даже если пишут очень умные, казалось бы,
люди. У него была какая-то причина
так написать, наверное, но
это не может быть.
Это не может быть.
Это не может быть.
У него была какая-то причина так написать,
наверное, но
здравый смысл подсказывает,
что нет.
Но сложность не в этом.
Сложность здесь.
Если нас разбудили,
то мы хотим захватить
мьютекс.
И кажется, что мы хотим.
Если лог свободен,
то перевести его в один занят.
А если лог занят,
то перевести в двойку и заснуть.
Но поток действует уже не так.
Если он проснулся
после фьютексвейта,
то после этого он
пытается захватить лог
сразу, переводя его в двойку.
Он не пытается
сделать перевод в один.
Если вы напишете здесь один, то код сломается.
Но если вы любопытны,
то если вы писали такой код,
то замените здесь 2 на 1
и код повиснет.
И вот здесь
вся сложность задачи кроется.
Потому что смотрите, какая история.
Вот было у вас
три потока.
Пришел первый поток,
перевел лог из нуля в один,
прошел в критическую секцию.
Пришел второй поток,
он этот каст провалил,
сделал этот каст,
перевел лог в двойку и уснул.
Потом пришел третий поток,
провалил этот компер-эксчейнч,
увидел двойку и сразу уснул.
И вот состояние лока 2,
два потока спят,
или там три потока спят,
неважно.
Один поток в секции.
Пока все, как мы ожидали.
Когда начнутся не тривиальные вещи.
Предположим, первый поток, который
захватил мютекс,
делает анлог.
И чем он занимается?
Он
сбрасывает
двойку в ноль.
И поскольку там
была двойка, он будет
одного из спящих.
Пока все идет нормально.
А теперь представим, что
у нас было три спящих потока,
и один из них проснулся,
увидел в спинлоке ноль,
увидел в ячейке ноль,
и захватил ее в единицу.
Все, беда,
потому что после этого он отпустит лог
и никого не разбудит.
А два потока так останутся спать.
В чем идея?
В том, что мы теряем информацию.
У нас раньше был счетчик,
а теперь у нас просто двойка.
За этой двойкой скрывается
предвольное количество ждущих потоков.
И мы в анлог ее сбрасываем всегда.
Вот мы теряем эту двойку.
Но
если поток уснул
вот здесь вот,
то о чем
это говорить?
Он стал
свидетелем двойки.
Вот он либо сам туда ее написал,
либо прочитал.
Это означает, что есть группа потоков,
которая ждет мютокса.
И нужно как-то гарантировать,
что каждый из этих потоков проснется.
Поэтому он поступает
консервативно. Он не знает,
если другие ждущие, кроме него,
сколько их там будет.
Поэтому он
двойку дальше сохраняет, поддерживает.
То есть он, просыпаясь,
захватывает лог с двойкой,
чтобы после выхода в анлоге
другой поток,
который потенциально был с ним в группе
ожиданий, разбудить.
Понятная идея.
То есть они друг про друга не знают,
но поскольку их может быть больше,
чем один, то они помогают друг другу
таким образом.
Вся сложность это реализации
в таком сценарии.
И с кода это, конечно, плохо читается.
Что скажете?
Понятно или нет?
Почему здесь именно двойка?
Мы оказались в группе ждущих потоков,
мы не знаем, сколько нас всего,
мы не считаем это число,
поэтому мы просто говорим,
что каждый поток, который проснулся
из этой группы, разбудит еще один поток.
Этот поток есть или нет,
мы не знаем.
То есть если, скажем, у нас было два потока,
один проснул, а другой прошел,
то проснувшийся
поток, который проснулся,
сделает лишний вейк,
потому что он не знает, что больше никого нет.
Но если бы у кого-то был,
то этот другой бы проснулся.
Вот такие пироги.
Понятно.
Смотрите, что может быть.
Мютекс был захвачен,
два потока спали,
потом мы в анлоке один поток разбудили,
сбросили в ноль,
а перед тем, как он проснулся,
вклинился другой поток,
он увидел ноль при входе, записал единицу,
на выходе никого не разбудил.
Но тот поток, который проснулся раньше,
после этого запишет.
Вот эти двойки хитро потом проявляются,
и вейки зовутся.
Мы гарантируем такой вариант,
что на каждый вейд в будущем
будет вызван вейк.
Все. Зачем я все это рассказывал,
когда можно было так сказать?
Блестящее объяснение.
Вот, да, этим все объясняется.
На каждый вейд мы просто вызываем в будущем вейк.
Так что дедлога быть не может.
Пожалуйста, производите.
Просто что небольшой крайний вейд в будущем
сможет...
Ну, два тамарных...
Две тамарных операции против одной тамарной операции.
Ну, при этом мы в...
На логии, по поводу личного вращения в твоего,
как бы...
Еще раз, мы оптимизируем сценарий,
где контеншн нет,
где лог берут не очень часто.
А, ну, все хорошо.
Вот. А когда контеншн есть,
то эта реализация работает
одинаково плохо...
Ну, в смысле, одинаково с твоей реализацией.
То есть она деградирует до твоей,
но в некотором случае она работает быстрее.
Но в некоторых разумных сценариях она работает быстрее.
Вот.
А поскольку мьютекс — это такая универсальная штука,
то лучше один раз постараться
сделать ее максимально...
максимально эффективной.
Вот тут один человек постарался
на всю жизнь для всех,
но это разумно в таких местах.
Ну что, у нас закончилось время,
наверное, да, Ирия?
Пятьнадцать минут еще?
Не может быть.
Подождем.
Сколько проспецов осталось,
объясните мне?
Три минуты.
Не пятнадцать.
Я просто ничего нового не начну,
я могу на какие-то вопросы,
может быть, ответить еще,
если они вот возникли по пути или...
Просто не знаю, что можно было
за три минуты вернуть такого.
Есть у вас идеи?
Ну ладно, тогда на сегодня все.
Спасибо.
Хорошо.
Послушайте, там не сложно.
Что человек делает?
Рассуждения простые.
Это решение с флажком и счетчиком.
Оно практически неизбежно.
Если ты решила оптимизировать
быстрый случай, когда контеншина нет,
то у тебя такое решение рождается
просто на автомате.
А дальше ты на него смотришь и думаешь,
ага, я хочу один атомик,
но одну атомарную операцию вместо двух.
Видимо, я хочу склеить
флажок и счетчик.
И тут-то можно было бы склеить
флажок и счетчик, если ты умная.
А мы это не разобрали.
Вот на что можно было
потратить три минуты.
А почему экономия
атомарной операции
дает такую большую оптимизацию?
Дело не в том, что она дает
очень большую оптимизацию,
а в том, что
доля
время, которое ты потратишь на лишнюю оптимизацию
в Mutex, в твоей программе может быть очень
ничтожным.
Но с точки зрения Mutex это ускорение в два раза.
Короче, разные ситуации бывают.
Вот скажем, если ты придешь
к МС Яндекс и сэкономишь там себе
какую-нибудь
одну десятую процента производительности,
то ты сэкономишь себе
ну, ты очень много денег сэкономишь,
потому что одна десятая производительность
процента — это огромное количество машин
или сотни, которые стоят
многие-многие тысячи долларов.
Поэтому, если ты можешь в одном месте что-то ускорить в два раза,
то почему бы это не сделать?
Выиграть от этой программы или нет
в какой-то степени — это уже второстепенный вопрос.
Просто компонент настолько базовый,
что он должен работать быстро.
Да, он...
То есть ты же не пишешь
какую-то библиотепу, которую там будет использовать
в твоем проекте только. Ты пишешь Mutex,
который для всего кодовного и поточного в мире,
поэтому разумно в него вложиться
очень хорошо.
Может быть, на тебе это не сильно повлияет,
но
ты же...
Тут смотри, overhead,
ты обмениваешь
когнитивный overhead
на...
Что ты на что меняешь?
У тебя может быть когнитивная сложность
в смысле overhead реализации
во времени работы.
И ты говоришь, я готов в одном месте потратить
больше мозгов одного человека,
а я могу экономить процессорное время
очень многих.
Вот если ты пишешь код
на работе в рамках проекта,
на котором работает 10 человек,
то разумно экономить именно когнитивный overhead
читателя твоих коллег,
а не ускорить кто-то в десять раз
и делать код нечитаемым.
Тут какой-то разумный тридог нужно искать.
Да.
Спасибо.
Там же используется...
Там используется атомик.
У него не три возможности значения,
а больше. Почему не всем со сдвигом?
Да. Да.
Именно про это я не рассказал.
Ты можешь написать со сдвигом.
Это гораздо проще.
То есть ты можешь склеить...
Это был второй вопрос,
кроме эксчейнджа, с которым я сидела
над этой статьей. Я просто
смотрю и не понимаю.
Да.
Ну вот.
А напиши в чат, что
можно же просто с эксчейнджем сделать,
со сдвигом сделать. Так и напиши.
Мне кажется,
что никто никогда такой код не пишет.
Почему-то.
Ну да, ты делаешь...
Я не пишу, потому что я думаю, что его написал человек
не меня, если бы просто и всего прав.
Ну, у него были причины некоторые такой код
писать? Не знаю.
В общем, в этом кондваре, который...
Смотри, давайте сразу покажу.
В этом кондваре такой трюк используется
очень часто. Кондвар вейт,
битред кондвейт
с этого начинается. Мы добавляем двойку,
потому что в младшем битике что-то написано.
Да, я читала.
А, ну вот ты там подсмотрела эту идею, да?
Нет. Сама придумала? Нет, я не понимала.
Ну,
чтобы
этот код понять, нужно...
Я сначала объясню, когда этот код читать, потом мы
его почитаем по мере возможностей. А может быть, не будем даже
если время пока нет.
Но идея общая, ты можешь
написать, да, ты в локе
ты делаешь, что...
или нет.
Так не можешь там сделать.
Ну, ты можешь консервативно добавлять
переворачивать...
Что хочешь сделать в локе, если ты мержишь счетчик
и
счетчик и флажок? Ты
пытаешься переключить сначала из 0 в 1?
Нет, ты должна делать фетчат какой-то, да?
Да.
Ты делаешь фетч...
Нет, подожди, что ты делаешь в локе?
Как ты хочешь одной этамарной операции?
Ну, там будет цикл,
ты прочтешь...
Заифать как-то двое?
Нет, там не ифа нужно писать, там нужно while писать.
Ты пишешь while, читаешь значение атомика
и если там
если старший, младший битик в енице,
то ты делаешь плюс два. Ты делаешь
camperexchange плюс два. Там аккуратно
нужно.
А если там младший бит ноль,
ты делаешь camperexchange, переворачиваешь
фечку 41, делаешь.
Это делать нужно в цикле, потому что
ты не можешь гарантировать, что...
Ты не можешь заранее сделать или то, или то.
Тебе нужно сначала посмотреть, что там лежит, а потом
сделать. Но между тем,
ты посмотришь и сделаешь, может все измениться,
поэтому тебе нужен цикл с кассом.
Но на быстром пути, когда...
И ты уже поиграла, потому что
ты сделал сначала чтение, а потом
camperexchange.
Чтение оно дешевле
все равно будет, чем...
Вилот, я думаю, что он все уничтожит.
Нет, вилот нормально,
но любой лукфри, это лукфри
решение, оно так и пишется.
Но вот в этом коде
я не знаю,
что...
В этом коде этого
оверхеда на быстром пути нет,
но есть вот лишний
лишний вейк.
На каждую группу потоков, которые
ждут, лишний вейк делается.
Вот если у тебя Newton все время загружен,
то лишних вейков не бывает, потому что все
полезные. А если
лук вообще все время пустой стоит, то тоже
лишних вейков не бывает.
Так что эта реализация
получается...
Я бы сказал, что она
все-таки лучше,
чем идея с упаковкой счетчика.
Да, но почти ничего. Тебе все равно нужно делать
чтение. Вот если придумать реализацию,
где ты делаешь одну атомарную операцию
с этим счетчиком плюс битиком,
а точно нельзя? Наверное, можно.
Если у тебя битик стоит
младший, ты должна сделать...
Ты должна быть счетчик,
а бит оставить, да?
Нужно подумать.
Мне кажется, что это делается.
Ты можешь сделать за одну операцию или то, или другое.
Или младший бит в ноль.
Я думаю, что чтение должно делать.
Почему эксчейнч?
Эксчейнч точно не подойдет,
потому что тебе нужно
модифицировать значение.
Ты хочешь либо младший бит
поставить, если он стоял в ноль.
Если ноль...
