так поехали о да так же сегодня сегодня у нас будет очень много потоков
ну ладно может не очень но да так вот ладно нет я даже не буду нет я правда
даже не буду утверждать что там сегодня возможно мы потоки все и закончим потому
что есть подозрение что все-таки не настолько вот но то есть с огромной
вероятностью мы закончим следующий раз на самом деле прочь а впрочем прочим
прочим прочим не вон вот прочим не будем загадывать там всякая возможна да
в этом смысле у нас достаточно спокойные такие времена то есть там
сколько у нас там ну да если мы в апреле закончим потоки то посмотрим
сколько у нас занятия вообще в мае будет вот так но давайте вспоминать что у
нас прошлый раз было так в прошлый раз мы с вами но только из важного
теоретического доказали тирему форда фолкерсона было дело да да ну по-моему
теоретически мы на этом остановились потому что дальше там мы начали
обсуждать кучу задач там во главе там во главе с hard life вот так но сегодня мы
конечно в теорию глубимся больше но начнем мы тем не менее с такой
разминочки вот разминочкой будет у нас задача о пара сочетания вот да там так
тут таки оказывается есть что обсудить да что тут казалось бы можно обсудить
чего чего почему арабская кто говорит а он объясняет происхождение этого термина
я понял да ну окей оригинально но нет нет нет нам бы с вами собственно основной
что формально говоря мы даже с вами не знаем что такое алгоритм куна да ну
типичная ситуация да вот но собственно да почему мы не знаем нет ну конечно ладно давайте
задам тривиальный вопрос кто когда-нибудь хоть раз в жизни писал алгоритм куна глупо было бы
предполагать обратно и действительно вот так ладно а кто-то когда-нибудь изучал его доказательства
нет вот он действительно такая фишка да просто это приятно да что конечно же там если вы
изучали в каких бы только шахтинько фах или там действительно там прочих подобных местах то
обычно конечно там у вас алгоритм куна доказывается там по принципу действительно там рассмотрим
ваши текущие про сочетание рассмотрим максимальное там значит там блаблаблаблаблабла вот есть
удлиняющая цепь скорее всего такое заклинание вот вот но сегодня мы с вами посмотрим на это
дело с более высокой колокольни а именно с колокольни теории поток потому что действительно
достичь симптотики куна в общем-то очень просто и более того можно и за зачем кун что такое кун не
знаю никакого куна господи как к чему-то венгекский математик там какой-то да господи там все сложно
то есть действительно давайте просто найдем про сочетание потоками как найти про сочетание
потоками очень просто заводим и сток заводим вот такие ребра с пропускной способностью адын вот
вот что-нибудь такое а также заводим сток вот с такими ребрами да все вот тоже там один один один
один один один тут дорисовывать не буду потому что по барабану вот все а ну как бы уже наверное
нет нужно говорить что тут уже все ориентируем в эту сторону вот так вот вот вот вот и тут
получается один один один один один один там бабла бабла бабла один все и думаю достаточно не
сложно убедиться что любой поток в этой сети соответствует при сочетании аналогичного размера
вот так что все что вам остается найти поток но как же найти по максимальный поток в этой сети ну
у нас с вами есть метод форда фолтиксона кто и предлагает его искать едва ли не дфс в чем
каждый дфс он либо скажет что поток максимальный либо найдет вам собственно какую-то новую единицу
потока протолкнет поэтому асимптотика тогда от такого алгоритма получится о ац там можно
сказать зе на я это пишу так анс плюс один ну где анс это размер максимального пара сочетания в
общем-то ну вот то есть в общем-то все просто то есть если хочется достичь именно асимптотики
кунна то никаких проблем вот все поток вам уже это сделал вот но на самом деле кунн конечно это
не просто типа возьми потока и давайте сделать алгоритм тем более кстати еще хорошо просто
появилось раньше алгоритм куна или вся эта теория поток вот потому что кунн по моему работал
где-то в 50-е годы могу как-то ошибаться все-таки теория поток появилась там 60 и 70 это загорелось
вот но тем не менее но то на самом деле тем не менее алгоритм куна все-таки изучить стоит потому
что конечно же алгоритм куна он предложит вам реализовать этот алгоритм сильно проще вот ну
с чего можно найти но то есть как упростить реализацию ну простить реализацию можно например
такие способы чтобы вот эти вот s и t во-первых не создавать что тогда будет потому что заметим
что как устроен любой путь от s до t он устроен так то есть мы идем из вас в какую-то вершину еще
не покрытую очевидно по рассочетаниям потом тут идем как-то вот по какому-то пути причем
который идет вот так вот зигзагообразно доходим до вершины которые не покрыта по рассочетаниям и
идем еще более того когда идем справа налево это обязательно развернутый ребро то есть ребро из
присочетания вот то есть в результате то есть получается так что можно как минимум s и t не
создавать а просто на каждом шаге запускать dfs и из вершин не покрытых по сочетаниям причем
там там пока у нас доказательства то есть получается алгоритм такой то есть у нас есть
текущее по сочетаниям значит мы мысля на там раз вот то есть мы там разворачиваем все ребра
которые в этом про сочетания лежат после этого пробегаемся по всем вершинам левой доли не
покрытой по сочетаниям запускаем dfs причем когда мы запускаем из очередной вершины то есть когда
пробегаемся из этой вершины до fs теперь то когда мы потом бежим из этой то старые пометки мы
естественно не снимаем потому что наша цель достигнуть т ну смысле любой вершины справа не
покрытой по сочетаниям да вот и соответственно вот и получается но вот и получается за от там
в плюсе получается мы находим какой-то путь ну и соответственно вдоль этого пути проталкиваем
поток то есть разворачиваем но алгоритм куна действует еще хитрее что алгоритм куна дил делает
хитрее относительно того что я сейчас сказал ну да он как-то очень хитрый делает вместо того
то есть мы говорим что сейчас на каждом шаге надо пробегаться по вершинам запускать dfs он
говорит что просто надо один раз пробежаться и каждый раз снимать пометки потому что он почему-то
не нагло нам утверждает что если вы запустили из вершины dfs и удлиняющий цепи не нашли то вы больше
и видимо не найдете никогда почему-то он такое утверждает возможно в доказательстве без потоков
это на самом деле едва ли не самое сложное место на самом деле или вы это как-то просто доказываете
да действительно то есть что же делать как же у нас этот кунтик бенод так выясняется но мы
докажем сейчас это утверждение с точки зрения потоков потому что оно тоже следует более общего
потока вот сформулирую я его пожалуй следующим образом такой я его такой лемма не знаю давай не
буду я наверное его возводить в ранг теоремы поэтому давайте лемма там пусть у нас значит
на это уже абсолютно произвольная сеть вот не обязательно такая в е ц ст то есть пусть сеть в
который ищется поток методом forda fokerson вот пусть перед очередной итерацией
итерацией
обнаружилось
что
что не существует пути от вершины в
в и в соответственно сток в там же но вот в остаточной сети жф по не на по не нулевым
ребрам ну как всегда
во тогда говорим мы тогда
когда что как бы это сформулировать но идея простая я утверждаю что из
этой вершины в путь больше никогда и не появится тогда далее такого пути из такого пути
из в в т и не появится
красота вот вот такое мистическое утверждение вот ну думаю если мы сейчас поверим в
это утверждение то алгоритм куна конечно доказан автоматически правда вот
но теперь возникает вопрос как же такое доказать
вот эх надо было бы вам конечно это как теоретическую задачу вот и задать конечно
но как всегда да не будем этого делать давайте смотреть идея на самом деле такая и так мы
делаем начать перед очередной итерации такого пути нет и после следующей нету и после после
следующей нету но предположим что после какой-то итерации у нас неожиданно путь появился то есть
какая ситуация возникла у нас пути не было мы значит запустили одну итерацию форда флакерсона
то есть нашли какой-то пути застой и протолкнули поток и неожиданно пути от вд т появился
допустим да что же это за путь ну заметим что ребра в этом пути делятся на две части первая
часть это ребра которые существовали перед этой итерации вот я их черненьким нарисую вот
допустим вот в это а были ребра которых перед этой итерации не было но после они неожиданно
появились как они появились ну как обратно и понятно что хоть какой-нибудь хоть одно из них
явно появилась правда вот то есть как именно как обратно что это означает это означает что на
предыдущей итерации у нас пути от с дт выглядел каким-то таким образом то есть оно тут шло шло
шло шло может даже вот так кстати шло вполне себе и вот бабах и прошел он пер по этому ребро еще
погуляла погуляла и прошло например вот по этому ребро да дебильный рисовал давайте вот так вот
нарисуем вот вот и ну вот как-то вот так вот то есть да заметим да что ребра то есть этот синий
путь мог проходить вот эти ребра в общем-то абсолютно в любом порядке не обязательно конкретно в этом но нам
это не принципиально потому что заметим что черным и синим я нарисовал ребра которые были перед
соответствующей итерации форта фолкерсона да смотрите какая ситуация вот рассмотрим вот
эту вершину это самое это вот самая первая вершина с красным ребром на пути от в дт но
заметим что из нее какой-то путь дт существовал ну понимаешь мы пути протолкнули правда и вот
эти ребра существовали вот ну вывод очень простой значит у нас получается от в дт перед
итерацией тоже путь существовал мы просто должны были идти по вот этим ребрам до этой вершины
а потом просто вот по синим ребрам доходить дт все доказательства окончено вот ну собственно
абсолютно аналогичным образом кстати можно доказать и родного брата этой леммы такой
симметричного близнеца так сказать за это близнец будет заключаться в том что то же самое только
пропуть не из в не из в т а из с в соответственно то есть что если мы лемма ее двойственная то мы
можем просто сказать что если не существует длиннейший спирт через в именно через в то
ее не появится если он блокирует с какой-то стороны ну так ну по сути получается так да
действительно что если у вас не существует удлиняющего пути проходящего через вершину
в то значит до его и не появится потому что не существует его тогда и только тогда когда либо
не существует пути от с до в либо не существует пути от в дт даже не либо или потому что если
одновременно тоже на стрельб Нет вроде правда там надеюсь никаких за цикла вот этих не
появляется а ну даже если за циклы появляется то ладно мы живем в ориентированном графе поэтому
нам по барабану хотя хотя нет в ров-ров-ров-ров-ров-ров-ров этот нет вообще это неправда нет это не
совсем так нет ну там это видимо что то более надо как-то аккуратнее формулировки что в принципе
может возникнуть вот такая ситуация, но правда тут немножко наоборот,
удлиняющего пути через В нету, но оба пути есть, правда есть подозрение,
что через вершину В пути как не было, так и не появится, хотя здесь
можно пойти следующим образом, можно просто сформулировать ту же самую лему,
видя, что путь у нас не существует удлиняющего пути, проходящего через вершину В,
утверждение его и не появится, доказательства, а вот собственно, хотя давайте по эмулируем,
как там доказательства будет, так вот, жила была СВ, что если нет удлиняющего пути от С до Т,
проходящего через вершину В, то его никогда и не появится, так, ну да, предположим,
что какой-то появился, значит где-то тут есть красные ребра, там допустим, тут красные ребра,
но вот тут непонятно, кстати, где красные ребра, так-так-так-так-так-так-так-так-так,
ну просто вот давайте, ну просто тут есть три случая, как бы есть красные ребра только
здесь, есть красные ребра только здесь и есть красные ребра и там и там, допустим,
красные ребра только здесь, тогда что мы получаем, так, нет, а вот не скажите, сейчас хотя, так,
жил был у нас предыдущий путь и он через вершину В не проходил, это для нас важно, так, значит мы
каким-то шаманским шамань-шамань-шамань-шамань прошли сюда и можем пройти по В, так, более того
заметим, что нам сейчас было абсолютно, так, ну да, все, путь существует, так, но это мы воспользовались
тем, что тут красных ребр нету, обратите внимание, так, ладно, ну случай номер два, когда у вас тут
красные ребра только справа, но он кажется симметричным, да, он кажется симметричным, хорошо,
так что остается только теперь ситуация, когда у нас и тут ребра есть и тут ребра есть, так,
спрашивается, что мы делаем в этом случае, да кто-то вот, а вот мы нарисовали пример, который-то валит,
ну это не совсем так, тут кажется, что у нас есть и то и то, нет простого пути из СТ через В, но как бы есть и путь до СДВ, есть путь от В до Т.
Да, мы же хотим показать уже не вот такого же, который отличается, то есть, а в каком случае это действительно работает?
Ну тут уже можно видеть то, что это препарат, потому что если у нас длинная путь прошел сначала через ребра, которые справа,
то через ребра, которые слева, мы не сможем воспользоваться его отрезками, чтобы...
Так.
То есть, первое, что с ними существуют пути из СВ, тогда и не будет пути из СТ через В никогда.
Одно из двух, они в момент времени выполняются, на самом момент времени, когда нет пути из СВ-Т, либо то выполняется, либо то выполняется.
Возможно оба, конечно, не важно, оба не выполняются, но если оба не выполняются, то по монотонности у тебя либо префит, либо сувик всегда не будет выполняться.
Значит, они будут выполняться это упражнение.
То есть, это, например, что другое ломает, то есть, как бы он контрпозицию ломает, а мы...
Нет, он ломает упражнение о том, что если от СДВ есть путь и от ВДТ есть путь, то от СДТ тоже есть путь.
Ломает именно, что простой путь, правда, есть.
Нет, парадокс в том, что чисто теоретически, если разрешить удлиняющим путям быть непростыми, то вот в этой ситуации можно сделать удлиняющий путь, который через В проходит.
Просто надо не насыщать все вот эти ребра, типа если тут даже они по единичке, я скажу 05 05 05 05 05 05.
Там насытив, скажем, вот это ребро.
То есть, как бы при большом желании это делается.
А вот можно ли гарантировать, что...
А кто такие красные ребра еще?
Красные ребра это те, которые... Вот мы сейчас сделали итерацию, и эти ребра появились.
И в результате их путь от СДТ через В появился.
Появились обратные ребра, потому что...
То есть, да, это означает, что предыдущий путь, по которому мы прототули, через них проходил.
Так, в смысле? Нет.
Ну, через ребро, наверное, тоже это можно доказать, в общем-то.
Ну, потому что там...
Из этой вершины пройти до Т, да.
Как это пойти? Находим что-то или ничего не находим, и говорим, что все, отсекаем, идем к следующей вершине.
Это не означает, что через эту вершину векторов, потому что рассмотрели, нет вообще никакой удлиняющей цепи.
Она есть, мы ее найдем, если она есть.
Просто она выходит из истока через другой ребро.
Ну вот, главное шоки, да.
Правда, конечно, шок через вершину В ее искать не придется.
Из вершины В она не будет.
Но здесь, правда, оговорка, что вершина В будет в этой удлиняющей цепи, если она есть, она должна быть прям второй.
Точнее, первой после истока.
То есть это утверждение, да, это более сильное.
Но тут возникает вопрос, да, где тут у нас доказательства валятся, да?
Потому что здесь, конечно, противоречие начинает только возникать в том, что если этот синий путь сначала пришел в эту вершину,
а потом пришел в эту вершину.
Потому что если он пришел сначала сюда, а потом сюда, то получается, что путь через вершину В существовать вполне себе будет.
Правда, там начнутся оговорки, что он еще мог через вот эти вершины бегать.
Как то.
Да, слушайте, хороший вопрос.
Да, ну ладно.
Да?
Ну не знаю, не знаю, не знаю.
Ну не знаю, не знаю, не знаю.
Так, вот как был вопрос такой.
Вот действительно интересно, можно ли такое доказать?
Потому что слет вот действительно возникнет там.
Так, ну понятно, в чем затык, да?
Да.
Чего?
Нам вот для куна хватает вот это одно.
Потому что кун говорит просто, можно ли от вершины В дойти до вершины Т.
Все.
Если нет, то нельзя будет никогда.
А с другой стороны у нас, если мы из этой вершины сейчас не сделаем ребра просочетания, то в будущем оно никогда не появится.
То есть оно может появиться только если мы из вершины В в явном виде запустили просочетание.
Но так как в будущем этого пути никогда не появится, то как бы будущая удлиняющая цепь через эту вершину никогда не появится.
Так. Не то чтобы это тут при чем, но вот, но по сути так.
Ну то есть вывод простой. Из вершины В действительно запускать ДФС будет бессмысленно.
Больше этого.
А впрочем нам это даже не важно.
Потому что мы говорили о том, что из каждой вершины имеет смысл запускать ДФС не более одного раза.
Потому что если бы запустили ДФС, либо мы этот ДФС-просочетание нашли, тогда эта вершина уже вошла в прошлое.
То есть мы не будем вовремя запустили ДФС.
Ну в смысле стартовать ДФС не будем.
А если мы сейчас запустили ДФС и не нашли просочетание, значит ДТ пути нет.
Больше он никогда не появится, значит больше никогда из вершины В запускать ДФС не потребуется.
Все.
Так что нет, этого-то нам хватает.
То есть это мы сейчас, конечно, в ответвление немножко пошли.
То есть так просто.
То есть если мы запустили ДФС и не нашли просочетание, то мы не будем запускать ДФС.
А если мы запустили ДФС и не нашли просочетание, значит ДТ пути нет.
То есть в ответвление немножко пошли.
То есть так просто немножко почесались.
Потому что вопрос, конечно, оказался вот такой теоретически интересный.
Вот.
Так что да, ладно, не будем поэтому заморачиваться.
А вместо этого, значит, вернемся к просочетанию и пойдем дальше.
Да. То есть соответственно алгоритм Куна доказали.
Так, ну более того, да, на всякий случай допомним эту оптимизацию.
Обычно Куна пишут так, что лучше, чем за О от ВЕ его оценить нельзя.
Почему?
Потому что чаще всего, когда вы запускаете ДФС за четыре вершины, вы зачищаете юзет.
Ну чаще всего, да.
Ну на всякий случай просто отметим, что если вы будете зачищать юзет только после удачных итераций,
то тогда у вас ДФС будет работать не за О от ВЕ, то есть это Кун, а за О от Е на размер ответа.
Понимаете, да?
Чего?
А, в смысле, зачищать юзет за единицу?
Нет, тут фишка.
Это вам и симпатически не поможет.
Нет, понимаете, тут фишка.
Это вам не поможет, потому что как бы у вас дело будет не только в зачистке,
а дело будет еще, потому что зачистка сама вообще даже не за Е работает, а за В.
А дело в том, что просто, допустим, вы запустили ДФС из вершины и не нашли из нее просочетания, да?
Тогда, когда вы запускаете следующие вершины, то если вы зачистили юзет, то если вы не зачистили юзет,
то вы не ходите в те вершины, которые ходил предыдущий ДФС, да?
Потому что вы знаете, что там пути до Т уже нету, собственно, в этом идее.
А так, если бы вы зачистили юзет, то вы бы по ним еще раз ходили, я симпатично ломается.
А так получается, что до ближайшей итерации ДФС будет работать также, то есть в каждой вершине он будет не более чем один раз,
поэтому суммарно эти итерации будут работать за В плюс Е.
То есть, поэтому, да, зачистка юзета за О от единицы тут, собственно, не причем.
Хотя, конечно, это тоже, ну, то есть это тоже, конечно, можно, да.
Хотя, ну, в данном случае просто не сильно поможет.
Вот.
Так, ну, говоря, конечно, о просочетаниях, нельзя, конечно, не обсудить и связанное с просочетаниями вещи.
Да, говорили, что занятие будет о потоках, но да.
Так, ну, какие у нас вещи возникают?
Так, так, так, так, так, так.
Ну, первая вещь, конечно, возникает, это, конечно, поиски всяких независимых множеств и, минимально, и всяких покрывающих множеств.
И вот тут действительно оказываются интересные вещи.
Так, давайте посмотрим.
Так, ну, для этого давайте приведем немножко буквок.
Ну, давайте скажем, что π от g это размер максимального просочетания.
Так, что еще должен сказать?
τ от g это размер минимального вершинного покрытия.
Так, ну, сразу вопрос.
А что такое вершинное покрытие?
Так, ну, вершина, да, вершинным покрытием.
То есть, вершинное покрытие, давайте, ну, давайте, ладно, тут определение тогда напишем.
То есть, в чем определение, можно написать вообще для произвольного вопроса.
Пусть у вас g равно v, это там не, неориентированный граф.
Абсолютно произвольный.
Тогда, значит, у, такое подмножество v, это вершинное покрытие графа g.
Если для любого ребра там какого-нибудь, давайте, ab лежащего в множестве ребер,
оказывается, что a лежит v или b лежит v.
Да, это вот формальное определение того, что такое вершинное покрытие.
То есть, можно сказать, что, то есть, так, нет, чушь.
Конечно, тут u, а то так формально чушь какая-то болотная.
Так, ну и, конечно же, еще надо ввести братское определение про независимое множество.
То есть, опять же, a.
Нет, мы сократим себе немножко текст.
Вот.
Вот так сделаем.
Вот, то есть, ну независимое множество говорит о том, что никакое ребро не соединяет,
то есть, никакие две вершины u не соединены ребром.
То есть, вот.
Да, хорошо, да.
Да, вот так нам в математику неожиданно проникает c++.
Вот.
Нет, понятно, да, формально тут должен был конъюнкции написать.
Тут вот этот вот уголочек, вот этот вот, да.
Ну, я думаю, тут все и так понятно.
Да.
Но независимое множество, конечно, хочется, да, мы его обозначаем обычно как альфа адже.
Это будет размер максимального независимого множества.
Так.
Да, ну в принципе, да, вот так оказывается, если формально написать эти определения,
казалось бы, да, то есть, вершинное покрытие, это когда вершины покрывают ребра, да,
то есть, любое ребро зацеплено хоть вершиной, да.
Независимое множество, это никакие две вершины не соединены ребром.
Но выясняется, сразу возникает маленькое утверждение,
которое говорит о том, что действительно у, значит, оказывается вершинное покрытие,
покрытие тогда и только тогда, когда v без u независимое множество.
Заметьте, кстати, это утверждение, эти определения сами по себе с двудольностью графа не связаны абсолютно никак.
Обратите внимание.
И более того, это утверждение тоже.
Так, пока я тут это замечаю, уже стало понятно, почему это утверждение очевидно.
Нет, ну не совсем одно и то же, конечно, но если я тут формально начну расписывать,
то выяснится, что там в текстах будет отличаться практически пара символов.
То есть, независимое множество, потому что фактически неверно, что a лежит в u и b лежит в u,
то это что означает? Это означает, что a лежит в v без u или, соответственно, b лежит не без u.
В данном случае тогда появится, что это означает, что у любого ребра либо a лежит в u, либо b лежит в u.
Определение вершинного покрытия.
Так, в общем-то, в одну сторону получили, в другую сторону, согласен, скучно хочется спать.
Да, вот, кстати, маленькое приятное следствие заключается в том, что...
Чего?
Ну да, как бы это страшный сон войшника на экзамене.
Просто он приходит на экзамен, а его сразу профессор отвечает и говорит, ну-ка, отвечай, к чему равно t-a-g, просто альфа-a-g?
Давай быстро, вопрос элементарный, не знаешь? Все, два, все, вылетаешь.
Да, давай, вылетай, так, все, вылетаешь из свистехи километров за 500, все, сразу.
В общем, действительно, да.
То есть, пока, да, то есть, действительно, да, вот.
А так вообще страшная задача, да, посмотрите, дайте.
А, или другой вариант.
Да, вы там попадаете, да, то есть, вы пока попадаете в какую-то пирамиду, ищете там сокровище, и вот попадаете в какую-то, видимо, главную пещеру.
И там вот, или там, или вход в главную пещеру, а там перед ней вот вопрос.
Вот t-a-g плюс альфа-a-g равно вопрос.
Нет, нет, нет, нет, если бы от Huawei. Нет, от Huawei челленджа такой не будет, потому что на эту задачу ответ известен.
Хотя, нет, то есть, на эту задачу ответ известен.
Нет, нет, Huawei челлендж, на самом деле, мог вам подсунуть задачу, дам какой-нибудь граф.
И t-a-g равно, вот.
Почему? Потому что в общем случае задача NP полная.
Вот будет у вас сложность вычислений, вы это докажете.
То есть, ну а NP полная, это означает, что как бы, как бы, у науки есть сильное подозрение, что за полимерное время это не решается в принципе.
Да, ну или все банковские системы жутко ненадежны.
Вот.
Ну такое, да.
Вот, то есть, произволь найти, то есть, известно лишь только одно.
То есть, есть, конечно, такое общее утверждение о том, что, конечно же, p-a-g меньше либо равно, чем t-a-g.
Ну как-то логично, да, потому что если мы рассмотрим максимальное присочетание, то, как бы, на каждом из этих ребер хотя бы по одной своей вершине быть должно, поэтому очевидно.
Причем, да, в чем, будьте внимательны, не перепутайте.
t-a-g является n по полной задачей.
А найти максимальное присочетание не является, потому что существует там какой-то страшный алгоритм с кодовым названием g-a-t соцветий, который тоже z-v-e это находится.
Присочетание вам найдет.
То есть, присочетание найти можно, а вот t-a-g проблема.
И альфа-г автоматически, ну как вы уже поняли, найти t-a-g и альфа-g это, в общем-то, задача близнецы.
Вот.
Ну а это если мы говорим в общем случае.
Да, ну сразу скажем да.
А может, хотя действительно, насколько легко привести пример, в котором t-a-g больше, чем t-a-g?
Ну, чтобы строго больше было.
Ну да, самое тупое, да, самое тупое, вот, да.
То есть, t-a-g равно 1, t-a-g равно 2.
Все просто.
Вот.
Но для нас с вами оказывается интересная, интересная уже мистическая теорема.
Рискну, конечно, сейчас ищу.
Но для нас с вами оказывается интересная, интересная уже мистическая теорема.
Рискну, конечно, сейчас ошибиться, но ее, кажется, теперь можно еще пафосно назвать теорема Кёнига.
Кёнига, да, все, не наврал.
Теорема Кёнига.
Если g равно ve двудолен.
То, оказывается, p-a-g равно t-a-g.
Ну и, ладно, я так добавлю от себя в скобочках, равно модуль v минус альфа-g.
Да, вот такая теорема.
В общем-то, доказывается она вполне себе конструктивно.
То есть, по принципу, если вы уже нашли максимальное просочетание, то сейчас за 1 dfs вы найдете, собственно, и само верхнее покрытие такого же размера.
Так, кто когда-нибудь, кстати, этим занимался?
Ух ты, о, уже не все.
Окей, ну давайте вспоминать, как же мы это быстро делали.
Так, ну идея, оказывалось, очень, такой достаточно простой.
Оказывалось, что, давайте, пум-пум-пум, допустим, мы нашли просочетание какое-то.
Вот, эти геобромы как-то вот так вот ориентировали.
Вот, теперь идея такая, запустим dfs, как всегда, из всех вершин, которые не покрыты просочетанием.
На этот раз единый dfs из всех вершин.
До каких-то вершин мы дойдем, вот как-то вот так.
То есть, до каких-то дойдем, до каких-то не дойдем.
Вот, допустим, мы вот до этих вершин, получается, dfs дошел.
Нет.
Нет, мы допускаем только из вершин левой доли, внимание, да, это важно.
Да, мы запускаем именно из вершин левой доли, не покрытых просочетанием.
То есть, поэтому получается, что до каких-то вершин мы дошли.
Мы эти вершины будем означать l+, и в левой доле мы будем означать l+.
Поэтому получается, что до каких-то вершин мы дошли.
Мы эти вершины будем означать l+, и в левой доле, и r+.
По ребрам, по тем же, которые были.
То есть, по ребрам, которые ориентированы вправо, если ребро не из просочетания, и ориентированы влево, если ребра покрыта.
Ну, то есть, по сути, в той же самой остаточной сети.
Да, l+, здесь, значит, это вот l+, и это r+, и r+, вот так.
Это я тоже помечу как l+, это я тоже помечу как r+.
Остальные вершины я помечу как, естественно, l- и r-.
Теперь внимание, вопрос.
Как же мне теперь найти покрывающее множество хорошего размера?
Как же это сделать?
Почти.
Да, l- и r+.
Да, запомнить очень просто.
Надо брать те множества, ну, потому что очевидно, что нам не интересны вершины, которые не из просочетания.
Вот, кстати, давайте на эту тему сразу подумаем.
А могут ли в r+, быть вершины из просочетания?
Не из просочетания, точнее.
Ну, вершины, ну вот, у нас есть просочетания.
Максимальное просочетание, которое мы нашли.
Да, мы это поворачиваем с максимальным просочетанием, напоминаю.
Спрашивается, могут ли в r+, оказаться вершины не из просочетания?
Ну, да.
Да, даже можно без илья.
Можно просто сказать, что dfs мы запускали из вершин левой доли, не покрытая просочетанием.
Если мы дошли до вершины правой доли, не покрытой просочетанием, значит мы нашли путь из какой-то вершины левой доли, не покрытой просочетанием.
не покрытой пресочетанием, вершину правой доли не покрытой пресочетанием.
В науке такой путь называется удлиняющая цепь, все, вот, да, поэтому в R плюсе у нас вершин не из пресочетания нету,
а вот в L плюсе вершин не из пресочетания вполне себе может быть, поэтому тут берем L минус, тут R плюс.
Но остается только доказать, ну скучно, но надо проработать.
Вот, значит, соответственно, как теперь остается только сделать какие-то технические действия.
Так, ну, во-первых, докажем, что это покрывающее множество.
Ну, действительно, как оно может быть непокрывающее?
Как оказаться, что у нас есть какое-то ребро, соединяющее R плюс, R минус?
Спрашивается, в какую сторону смотрит это ребро?
Либо в эту, либо в эту.
А в чем тупой случай?
Ну, вот этого такого быть не может, ну, как-то вершина ребра не может вести из вершины покрытой DFS, вершины не покрыты DFS, да?
Ну, тупо.
Вот здесь уже не тривиальнее. С точки зрения теории ориентированных графов такое, в принципе, бывает.
А в чем же проблема?
А вот почему такого случая быть не может?
Да, совершенно верно. То есть фишка в том, что, да, можно сформулировать еще по-другому, что в эту вершину иначе, как по этому ребру, попасть нельзя в принципе.
То есть DFS из нее не запускался, как стартово, а прийти он в нее мог только по этому ребру, потому что у нас в одну вершину одно ребро сочетание.
Тогда получается, что если мы в эту вершину пришли, то и в этой вершине должны были быть.
Вот. И здесь мы уже пользуемся тем, что мы тут с парасочетанием каким-то работаем. Отлично.
Значит, мы показали, что это множество действительно покрывающее.
Остается только убедиться в том, что его размер равен в точности размеру парасочетания.
Как в этом убедиться?
Ну, план очень простой. Надо убедиться, во-первых, что, как мы уже ранее увидели, что все эти вершины из парасочетания...
Ну, R плюс из парасочетания мы уже, наверное, рассказали почему.
А почему эти все вершины из парасочетания?
Да, все еще проще.
Да, просто по определению DFS, который запускался принудительно из всех вершин, не из парасочетания.
Все. Поэтому да.
Поэтому да. Все это из парасочетания остается убедиться только в одном.
Теперь остается только доказать, что на каждом из ребер парасочетания взята ровно одна из этих вершин.
Почему?
Нет, пока мы получили только что у нас есть покрывающее множество, и мы получили, что все вершины лежат на парасочетании.
Да, такое вот может быть.
А это...
А мы еще этого не доказали, если что.
Ну, как минимум, да, безусловно.
Нет, правильно.
Нет, ну хорошо, да, давайте, да.
Можно сразу сказать, что да, что как минимум на каждом, так как это покрывающее множество, то на каждом из ребер парасочетания хотя бы одна вершина есть.
Да, потому что api adj как минимум tau adj, это правда.
Но мы хотим доказать равенство.
Но для этого нам достаточно доказать, что этих вершин ровно одна, а не ноль.
Но с другой стороны, что значит, что на ребре парасочетания мы взяли и эту вершину, и эту вершину?
Это означает, что эта вершина должна быть из R+, а эта вершина из L-.
То есть опять у нас ребро идет из вершины, посещенной DFS, в вершину, не посещенной DFS.
Не бывает.
Нет, мы еще не доказали, что их размеры равны. Мы это только что сделали.
Значит, еще раз давайте, план доказательства такой.
Сначала мы вот здесь доказали, что это вообще покрывающее множество.
Потом мы доказали, что все эти вершины лежат на парасочетании.
Потому что все вершины L- лежат на парасочетании, потому что у нас из всех вершин не есть парасочетания в L, мы просто запускали DFS принудительно.
А в R+, все вершины в парасочетании.
Потому что... siitä положим, что у вас какая-то вершина R+, такая как это plays, посещена DFS, не есть парасочетания.
Значит, мы нашли какой-то путь из вершины левой доли и непокрытой, вершину правой доле не покрыта парасочетанием, удлиняющая цепь.
Ура!
Значит все эти вершины есть парасочетания.
финалочка остается только доказать, что на каждом ребре просочетания выбрана ровно одна вершина.
Вот, ну на самом деле да, то есть мы доказываем, что двух вершин выбрать быть не может,
ну формально, но с другой стороны заметим, что нуля вершин быть не может просто по определению
покрывающего множество. Даже не потому, что там p i j меньше либо равно чего-то там,
а просто, что если ноль, значит это не покрывающее множество. Так что автоматически доказательство
получено, да, а по определению понятие покрывающее множество. Мы же уже доказали,
что это покрывающее множество, значит на каждом ребре, даже не только просочетания,
просто на каждом. Вот, так что вот такая красота. Вот, так что вот такая вот надежность. Так,
вот, ну и как вы уже догадываетесь, альфа j конечно берется как l плюс или l means.
Да, так что да, ну в принципе да, странно, да, так что вроде доказали. Нет, странно,
правда судя по вопросам, вы дикают ощущение, что вы просто выучивали, что берем вот это и не
паримся. Да, за что? Нет, ну просто как по мне, тут как раз-то случай, когда если вы понимаете
доказательства, то как бы я сам этого не помню. Я как бы сейчас там трачу 5 секунд всегда на то,
чтобы просто быстро вывести. Так, ну в трансляции, ну в трансляции. Нет, если бы вторая бага была,
я бы всего не угадал. Ну да, нет, ну тут по ситуации, что вам надо, мало ли. Аккуратно на сэмплах,
ну да, нет, в данном случае да, конечно на сэмплах скорее всего будет. Ну ладно, это уже нет,
тут тоже да, с инфинити конечно, да, в чем главное, в чем как бы еще подлость еще финала, кстати,
как вы уже могли убедиться, заключалось в том, что вам в тестивной системе на финале не сообщают
о каком тестива. Почему елки-палки потратили полтора часа на чемпионатку в инфините,
потому что им не сказали, что ва на тесте из условия. Так всегда было. Чего? Ну я не помню,
но есть подозрение, что там на тесте из условия инфинити быть могло. Ну вот да, ну да, так нет,
но это из цикла такое бывает, ничего не поделаешь. Вот, то есть нет, бывает вообще всякое, знаете,
у нас, пока я тут стираю, самая подлая ситуация была когда-то, в фитрозаводский мы нагрелись,
когда мы там написали какую-то задачу, получили VA, я ее честно там два с половиной часа дебарил.
Потом выяснилось, что оказывается по правилам, значит по правилам американских чекеров,
оказывается, если бы в какой-то строчке вывели лишний пробел после числа, то это автоматически VA.
Потому что по еще более старым правилам, оказывается, лишние пробелы засчитываться не
должны. То есть как потом Старк сказал, что вот мы, да, то есть да, это конечно у нас сейчас,
конечно, такое уже не, там на тот момент уже в России такое было не по понятиям, но как бы
американцы привезли такие чекеры, мы приняли решение, приняли решение это, то есть здесь оставить
без изменений, потому что вот, извините, формально в правилах такое написано было,
но это было в 2012 году, если что или 2013, то есть сейчас уже такого нет, сейчас уже даже в правилах
финала написано, что там лишние пробелы нормально, более того, там infinity можно было и капсом вывести
даже, а более того, можно даже было чередовать, то есть там прям принудительно сказано, что все
подобные вещи там, это регистры нечувствительные должны быть. Вот, то есть поэтому, поэтому сейчас
с этим не заморачивайтесь, но вот, но какие-то вот такие подлянки были, но вот с инфинити вот,
ну что делать, но вот, но тут вот как бы ничего не поделаешь, но вот это, это картинка называется,
вот так случилось, так произошло, вот, ладно, что еще про прочитание надо знать, так, ну кое-что
конечно знать надо, так, какие у нас еще теории, но вот, вот, да, но перед, ну перед дилвертом надо
еще дойти, потому что нет, на дилверт еще надо дойти, то есть да, я понимаю, что я, конечно,
читаю абсолютно стандартную лекцию по про сочетаниям, там, которую вам, наверное, уже читали
много раз, но тем не менее, нет, то почему, нет, ну не знаю, как бы тут сначала, как вспомнить,
нет, потому что нет, дальше возникает еще даже не дилверт, а возникает на самом деле более веселая
задача, задача называется покрытие ориентированного графа путями, то есть представить себе ситуацию,
дан, ориентированный, но при этом ациклический граф, вот, ну какая-то вот такая ситуация,
значит очень хочется все вершины этого графа покрыть путями, ну, например, вот таким вот каким-то образом,
да, пути должны просто быть простыми, да, да, и, да, и пути должны вершинно не пересекаться,
спрашивается, какое минимальное количество путей вы можете найти, желательно такие пути найти.
Так, ой, так, сейчас прошу прощения.
А он же покрыт именно ребра или вершины, вершины, вершины, конечно, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да,
так вот.
Важно, чтобы пути простые, чтобы... Но чтобы
через какие-то лишние петли не бегали.
Ну, я боюсь случаи не дага,
то решение, которое у нас будет, будут циклы.
Так, ну давайте.
А в чем проблема петель?
А, ну проблема.
А, стоп.
А, ни в чем проблема петель.
В циклическом графе в общем-то
непростых путей не бывает.
Кстати.
Так, ну давайте ладно.
Чтобы понять, какие проблемы будут в циклическом графе,
на самом деле давайте разберем решение
для циклического графа.
А решение возникает простое.
Вот допустим у нас эти вершины A, B, C, D, E.
А, B, C, D, E, F, G.
Вот немецкие когда учили.
A, B, C, D, E, F, G.
Вот это все.
G, H, J, K, L, M, N, O, P.
Вот.
Совершенно неожиданно выясняется,
что надо составить
по этому графу двудольный граф.
В чем относительно
неожиданным способом.
То есть я именно хочу сказать,
что в каждой доле вершин в так же,
сколько в исходном графе.
Более того, мы и будем называть
H, B, C, D, E и так далее.
И тут A, B, C, D, E, F, E.
Вот это вся радость.
И оказывается, что если у нас есть ребро,
допустим, из AB,
то мы здесь проводим ребро
из A, B,
но не наоборот.
Вот.
Дальше, что у нас там? Из A в C.
Ну, пожалуйста, A штрих, C два штриха.
Что там дальше? Ну, там дальше получается
B, D.
Там из C.
Ой, тут уже побольше.
Так, что у нас тут?
C, D, C, E, C, F.
Там из D у нас получается
куда-то в G и в E.
Ну, в общем, и так далее.
Я дорисовывать не буду.
Так вот, чем нам это поможет?
Теперь мистический факт.
Если мы рассмотрим ребра,
которые составляют это покрытие путями,
то я утверждаю, что
соответствующие ребра
в твудольном графе будут
образовывать просто по рассочетанию.
Почему?
Да потому что
эти цепи обладают таким свойством,
что в каждую вершину
входит не более чем одного ребра
из цепей и выходит не более
чем одного из ребра из цепей.
Вернее, можно рассмотреть покрытие
с таким же количеством детей,
что это.
Ну, не совсем.
Это называется...
Если у вас есть набор
покрывающих путей из карабер,
то в этом графе существует
просочетание из карабер.
Да, конечно.
Более того, верное обратное.
Если я возьму просочетание,
то здесь это просочетание приведет
к покрытию путями.
Приведет это к набору путей,
которые вершины не пересекаются.
Они могут не цеплять какую-то вершину,
но это означает, что мы просто возьмем
путь, состоящий из одной вершины.
Да, кстати, если уж говорить о циклических
графах, то в циклических графах
это будет называться покройте граф
минимальным количеством путей и циклов.
Потому что в циклическом графе
может возникнуть...
То есть каждый путь вполне себе
может оказаться циклом,
потому что цикл тоже будет удовлетворять
вот этим условиям, что в каждую вершину
входит не более чем одно ребро
и выходит не более чем одно.
Да, граф, естественно, должен быть не ориентирован.
Важно, что граф должен быть хоть циклическим,
но ориентированным.
Вот.
А зачем? Нет, этого не нужно.
С циклическими проблемом будет.
Нет, зачем? Потому что заметим,
сколько у нас в графе путей.
Путей в графе будет ровно
столько же, в сколько
вершин не входит ребро.
Ну, потому что на каждом
пути такая вершина ровно одна.
Это начало.
То есть это получается,
что чем меньше мы хотим
путей, тем меньше должно быть вершин,
в которые ребра не входят.
А это означает, что
тем больше у нас вершин, в которые ребра входят,
тем лучше.
То есть получается максимальное
просочетание даст нам минимейшие путей.
Да, в циклическом графе, кстати, это не сработает.
Потому что в циклическом графе у нас
можно будет найти эти
покрывающие пути циклы с минимальным
количеством ребер.
Точнее, наоборот, максимальным количеством ребер.
Но количество путей
это не максимизирует.
Там будет немножко другое.
Он даст вам следующее
найти покрытие...
Надо найти,
видимо, набор независимых
путей и циклов.
Вершин на независимых.
Так, чтобы в них участвовало как можно больше ребер.
Получается так.
То есть связано ли это
как-то с минимальностью количества путей?
Лично мне с лету непонятно.
Может как-то и связано.
Так что, в принципе, да.
Как-то можно
задачку придумать, я не знаю.
Такую маленькую, подлинку.
Нет, знаете, вот такие мелкие
надо придумать задачи.
Потому что я недавно
прорешивали в сервис с парой ребят
2000, какого-то 21-го года,
по-моему. И там
седьмая задача
на сервисе должна быть
сложная задача.
Но, оказывается, если вы изучали теорию
про компоненты вершины двух связанности,
задача становится простым упражнением.
Просто вот элементарнейшим, который в ДЗ
можно давать. Практически.
Да.
Нет.
А вот выясняется, что нет.
Да? Серьезно?
Нет.
Может 22-я?
Не помню.
Может и DX.
Но нет.
Про доставщика? Да.
Но это как-то да. Но причем это, главное,
так достаточно странно. Видимо, компоненты вершины
двух связанности считается сложной теорией.
Может так, к счастью, потому что кто-то...
Потому что ходили какие-то случаи, что если вы будете
по Emax изучать эту теорию, то у вас будет очень мутное
представление о том, что компоненты вершины
двух связанности.
Не, вот это и прикол,
что, видимо, это является не тривиальным знанием.
То есть если у вас просто есть понятие вершины,
есть понятие вершины, ну да, наверное, там...
Ну я не знаю, может я набрал, я не знаю.
Может это...
Вот прям по вам видно, что вы устали, вы еще не...
Потому что, конечно, я думаю, месяц назад
вы бы уже достали телефон и загуглили вопрос.
Но нет.
Так.
Нет, ну я не знаю, просто мог
с Emax, конечно, и упустить этот вопрос.
Хотя...
Ну вот.
Так что это...
Ну ладно, пока там гуглите, значит, соответственно,
с этой задачей в любом случае разобрались.
Так.
Что там у нас еще есть?
Нет, ну там да.
Да, дальше мог бы идти там какой-нибудь
это веселый прикол.
В духе там дан какой-нибудь граф,
найдите... там дан...
Дан какой-нибудь граф, найдите максимальное
количество... там...
Найдите максимальное количество ребер на не пересекающихся
путей, значит,
идущих из SFT.
Да.
И там будет
мистическая математическая теория.
Там максимальное количество этих путей
равно минимальному количеству ребер,
которые надо удалить из РАФа, чтобы от СДТ
пути не было.
Ну да.
Нет, в этом
и прикол. Там просто юмор был,
что в том, что как бы теория формулируется
абсолютно математически.
То есть как ее доказывать вопрос,
ну если вы знаем вот форда Фолкерсона, то как бы это
просто элементарная переформулировка.
Вот, то есть можно было там
с этого поржать, можно было про вершины еще там
что-то поржать там.
Ну, ребер на не пересекающихся.
Если вершины не пересекающиеся,
то нам бы пришлось вершины удалять.
Да, то есть там это пришлось бы раздваивать
вершины, и может быть у ребер там еще
ставить профессиональную способность плюс бесконечность
на всякий пожарный, да.
В этом смысле, да.
Ну ладно, мы сейчас там, ладно, юмором этим
заниматься не будем, а вместо этого
лучше докажем уже действительно солидную теорему.
Да, уже вполне солидную теорему вообще
про частично порядочное множество.
Нет, тут действительно просто интересно
в том, что сейчас вот это как бы просто абсолютно
чистая математика, которая могла у вас на дискретке
возникнуть.
В случае цикличества у игрока тут проблемка
в стиле, если
Гамильтонов.
Нет, понятно.
Нет, Гамильтонов не поможет, потому что
как бы был бы вопрос,
можно ли покрыть там,
нет, там будет другой.
Если можно сделать так, чтобы у
графа был, чтобы у этого
покрытия циклами был размер N,
ты получишь либо Гамильтонов цикл, либо там
набор циклов.
Поэтому как бы там, поэтому к сожалению
задача Гамильтонов в цикле таким образом
не решить.
Да, то есть
не все так, к сожалению, просто.
Вот.
То есть нет.
Ну да.
Ну да, да, да, да, да.
Нет, вот сейчас.
А нет, вот так вообще.
Нет, вот если нет цель задачи,
данный ориентированный граф,
можно ли все
шины покрыть циклами?
Циклы циклами, а естественно длины
больше чем один.
Нет.
По-моему движение такое, строим вот этот вот двудольный
граф, если там найдется полное просочетание,
значит можно, иначе нет.
Так все, да.
Выключаем камеру, вырезаем, даем на Код Форсис.
Или куда-нибудь еще.
Нет, я конечно
не гарантирую, что какие-нибудь там
координаторы не помочатся и не скажут,
что таких задач уже миллион было.
Или может там, я не знаю, может там
в полигоне
ЛКШ может такая задача уже давно есть,
я не знаю.
Ну так в принципе поржать можно.
Да, ну вот хорошо.
Хотя нет, задачи надо сохранить и спрашивать
на зачете.
Ну а что?
Ну вижу в прочем, да.
Чего?
Тайные знания.
Нет.
Минимальное
Максимально наоборот.
Да, но чтобы при этом вершины не пересекаться.
Ладно.
Так, кстати, про максимальное количество
ребер мы шейлеровый цикл с вами рассматривали.
Все, да, хорошо.
Ладно.
Давайте вернемся к частичному порядочному множеству.
Тут уже знания, которые
уже известны.
Ну во-первых, что такое
частичное порядочное множество?
Да.
Во-первых множество,
а во-вторых
с мистической операцией
ИТ.
Ну это бинарная операция.
Ладно, я даже вот так нарисую.
Это булевая операция.
Ну такой
фолстру такая, да.
Но чтобы это было частично порядочное множество
по этой операции
надо, чтобы выполнялись три аксиомы.
Первая аксиома.
То есть, что для любого А
было верно, что
А и А
равно один.
Дальше
было бы верно,
чтобы
для любого А, для любых
А и Б было верно, что
если там А и
Б и
там
Б и А, то
из этого всего следует, что
А тупо равно Б.
А третья транзитивность.
А третья транзитивность, да.
Что для любых А, Б, С
то есть верно,
что значит из
А и Б и
Б и С
следует, что А и С.
Да, ну называются они рефлексивность,
там антисимметричность
и транзитивность.
И транзитивность.
Я мог бы...
То есть, как бы для любых двух неравных
элементов, верно, что
либо А
не меньше Б, либо
А не является меньше, либо
равно Б, либо Б не является меньше, либо равно А.
Обычно смысл этого уйти
такой меньше, либо равно.
Самый типичный пример,
которого можно привести,
это, допустим, А
равно какой-нибудь
z в квадрате.
Там набор точек на плоскости целых.
И мы будем
говорить, что там
x1
y1
x2 y2
равно просто
x1 меньше, либо равно x2
and then y1 меньше, либо равно y2.
Вот это самый типичный пример такой.
То есть, в том плане, что
конечно, аксиомы
естественно удовлетворяются,
там могут быть пары точек, которые просто
несравнимы между собой.
Понимаете, да?
Да, тут, в общем-то,
тривиально. Вот. Ну, конечно,
такие чумы мы рассматривать не будем,
потому что нас интересуют, конечно,
конечные чумы.
Да, значит,
в чумах есть такие...
есть мистические понятия.
Значит, определение.
Значит, пусть
у меня
значит, вот это вот
а и ыть это чум.
Тогда
значит,
последовательность.
Значит,
последовательность а1, а2
и так далее, ак.
Ну, где каждый элемент
это из а.
Это цепь.
Если
оказывается, что
а1, ыть, а2,
end, end,
а2, ыть, а3,
end, end, и так далее,
end, end, там, ак-1,
ыть, ак.
Что?
Ну, нам по барабану будет, если честно.
Да.
То есть нам по барабану, да,
желательно, конечно, чтобы они там
соседние не были равные, но тем не менее.
Для нас более интересно то,
чем цепь, понятие цепь отличается от понятия
путь.
Она отличается тем, что
в отличие от обычного пути в ориентированном графе
здесь мы можем вытянуть вершину из середины
и цепь останется цепью, обратите внимание.
Потому что если изобразить это в виде
графа, то получится, да,
ориентированный ациклический граф, но с транзитивным замыканием.
Вот.
Так.
И второе.
Множество
а1, а2, и так далее,
ак
называется антицепью
если,
если что.
Если для любых ижи,
давайте я так напишу,
и не равно жи, оказывается
верно, что,
точнее оказывается не верно,
что аито ить ажито.
То есть наоборот, оказывается никакие
два элемента ни в какую сторону
не сравнимы.
Такая сеть.
Чего?
Такая сеть, потому что
просто множество.
Это буквально множество.
Нет, почему нет?
Анти какой-то есть, потому что, смотрите,
цепь, что такое цепь? Цепь это множество элементов,
любые два из которых сравнимы,
я мог сказать.
Да.
Потому что
есть такая церема, что
допустим у вас есть граф,
ориентированный граф из N-вершин,
такой, что
в любом, между любыми двумя
вершинами хоть в какую-то из сторон есть ребро.
Тогда
в этом графе есть гамильтонов
путь.
Так, так,
так, так, давайте.
Ну, была такая задача,
была в сеть бомб-классе.
Как говорится там...
А,
а даже так...
Чего?
Да.
Ух ты. А по какому поводу он ее дал?
Сортировки.
Да.
Ну, там алгоритм похож на сортировку.
Да?
Ну, не знаю.
Нет, ну понятно, что это
целом сортировка.
Нет, ну, нет,
а как вы там сортируете, учитывая, что в общем случае граф
может быть и циклическим?
Нет, там турнир, на каждой стороне сравним.
Ну, турнир, да.
Да, можно. Получается, что
нужно найти лимфоиск,
в первый момент разные
ребра.
Ну, это тогда.
Но это надо...
А, ну это да, но это правда надо вопрос,
потому что асимпатически обычно тут...
Как бы вопрос как ставить? Если ставить программистки, то вопрос как бы
либо вам дадут просто N квадрат ребер
и удачи, либо делать
эту задачу как-то интерактивной.
Генератор просто...
А, ну,
как угодно там генерировать.
Ну, ладно, давайте на всякий случай
расскажу это мистическое знание.
Понятно, что
могут там дать где-нибудь
в седьмом классе, действительно, на самом деле.
Но, правда,
если вы там случайно занимались олимпиадной математикой
в седьмом классе, мало ли там всякое бывает.
То есть да, мистическая теорема,
определение,
что ориентированный граф
там
g равно v e
это турнир.
Там
если...
Ну, допустим,
давайте скажем так, если нет
кратных ребер,
ну, вот, и...
Ну, и для любых
там uv
причем неравных,
верно, что, ну, допустим,
там uv
лежит в e,
xor
v
лежит в e.
Но обычно турнирам говорят, когда
ровно одно из этих ребер существует,
поэтому я тут xor пишу.
Чего?
Значит, да,
мистическая теорема
в турнире,
ну, по крайней мере, в конечном есть
гамильтонов цикл.
Ладно, да, пути, конечно,
но там
была задача на регионе, где надо думать,
что да, что...
Нет, там верно такое,
если граф является еленот,
там более продвинутая теорема будет такая,
если граф сильно связан, то есть
гамильтонов цикл.
И там на регионе была задача,
где вам надо было это все вывести.
Вот, не было?
Нет, была, была, была, вот кто-то, да.
То есть это, конечно, уже относительно
старый, потому что там старый, по современным меркам, регион,
но задача прям отпадная, да.
Ну, так, ладно,
давайте сейчас...
Но погодите, давайте сейчас обсудим,
раз об этом зашла речь, смотрите, и так есть
гамильтонов путь.
Так, как вообще это доказать?
Ну, доказывать будем просто по индукции.
Допустим, как перейти от...
Ну, понятно, в графе из одной вершины
гамильтонов путь, естественно, существует.
Как перейти от графа размера K
в граф размера K плюс один?
Очень просто, на графе размера K
гамильтонов путь существует, вот он.
Вот, один, два и так далее,
К, допустим, назовем вершину, вот еще одна вершина,
то есть ее куда-то в этот путь вставить.
Ну, куда ее можно вставить?
Либо ее можно вставить в начало,
либо ее можно вставить в конец.
Если нам оба раза не повезло,
значит, тут ребра устроены
как-то вот таким образом.
И тогда идея такая,
а давайте пойдем слева-направо,
и просто
найдем первую вершину, у которой
ребро ведет из этой вершины сюда,
такое найдется.
И все, вот вам, пожалуйста, в этом месте
вставляем вершину, радуемся.
Более того, в принципе,
если вам задача дана как-то интерактивно,
то вы это место можете найти за логарифом
просто бинпоиском.
Да, понятно,
что тут не обязательно сначала все ребра
сюда, потом сюда, тут может быть там как угодно,
но бинпоиском это работает.
Ну, в принципе, аналогичная ситуация,
то есть задача дана, какая-то
функция, найти ее хоть какой-нибудь
корень.
Надо просто найти точку, в которой
функция заведомо отрицательна,
найти точку, в которой функция заведомо положительна,
и после этого найти корень просто бинпоиском,
который найдет вам этот корень,
даже если функция устроена вот каким-то таким образом.
Нет, конечно.
Нет.
Вполне вероятно, что граф будет вот такой, например.
Что?
Кто сказал, что в графе нету циклов?
Нет, отсутствия циклов в графе
никто не обещал.
Ну, не граф вообще, конечно,
а именно граф турнир
сильно связан.
Да, в общем случае можно упасти, конечно.
Чего лоббист?
Что эквалентно?
Да.
Нет, ну это
в принципе, да.
То есть такой теория, да.
Если...
А, да, теория,
но все равно лучше в сильно
связанном турнире.
Так, в сильно
связанном турнире
есть
гамильтонов цикл.
Так.
Вот.
Так.
Так, ну вот
выясняйте первое просто.
Как доказать такое?
Так.
Так, давайте.
Так, ну давайте
разбираться.
Так.
Так, давайте.
Как действительно этот путь устроен?
Значит, это туда,
то есть мы знаем, что из этой вершины в начальную
какой-то путь есть.
Так, скачем.
Ага,
после первого жеребра я вам сразу скажу.
Кстати, оптичка.
Эдж гамильтонов путь, да, там все
вершины есть.
Вот.
А вот это интересно, что дальше.
Не, ничего неприятного на самом деле
нет. Ладно, давайте так сейчас
сократим себе жизнь вот
спокойненько.
Ладно.
Так.
И снова назад.
Сейчас куда назад?
Где назад?
Можно этот путь разбить
на черные ребра и еще какие-то
синие ребра, при условии, что
синие ребра будут только назад.
Так. Ну хорошо, так.
Ну так и что?
Ну хоть.
Давайте просто по индукции докажем
задачу. Ну с циклы мы сейчас
вместо куда вставать вершину.
А в фоне?
Что тебе ждут, да.
Ну с циклы по всем шинам.
Ну.
У тебя в индукции перестанет ломаться,
когда ты ударяешь вершину.
Тебе перестанет быть иметь, кажется.
Да, это странно.
Почему странно идут?
Ну, не совсем понятно.
Ты можешь просто взять и сказать...
Да, у тебя может быть любой граф изначально
добавить вершину.
Давайте нарисуем
синие ребра.
Так, ну нарисуем. И что?
Правда, может их и нету больше.
Но они, конечно, есть.
Ладно, да.
Да.
Что дальше?
Так.
Так, ну ладно,
не будем на этом зависать.
Нет, я просто... Ну скажем так,
честно скажу. На самом деле тут можно просто...
Нет, я имею в виду, можно
по своему опыту скажу, да, тут можно очень долго
и плодотворно думать.
Но, на самом деле,
одно из самых простых доказательств можно свести
к следующему. Потому что наличие вот этого
ребра приводит вас к тому,
существует вот такая конструкция.
Такая конструкция, покрывающая все
ребра.
Надо теперь будет просто аккуратненько
вот этот хвостик сокращать.
Как его сокращать?
Ну, самое тупое, что можно
сократить, это теперь давайте посмотрим на эту
вершину. У вас тут
как бы два варианта.
Ну, если тут... Вы тут просто идем
по этим ребрам и смотрим. Если выяснится,
что тут из какой-то вершины все-таки нашлось ребро
в эту вершину,
то тогда как бы
добавить эту вершину в цикл и вот
сократить хвостик уже легко.
Ну, вот так вот.
Вот. Но как бы такое
ребро... То есть просто вот идем
после вот этой вершины, идем-идем-идем.
Либо такая найдется, либо
вот уже более подлый случай.
То есть может быть
уже такой нетривиальный для нас.
Это если выяснится, что тут все ребра в эту
сторону.
Впрочем,
это нам сильно помогает. Это нам помогает
в том плане, что как бы я теперь этот
цикл к этой вершине могу прицепить за абсолютно
любую вершину.
То к чему это нас приводит?
Тогда это будет называться...
Берем теперь вот эту вершину.
Давайте тут хвостик подлиннее
сделаем.
Вот. Ну, так для удобства.
Ну, вот.
И тут просто, если...
И тут опять то же самое.
Смотрите, если мы опять же найдем
вот какое-нибудь ребро, ведущую
в эту вершину из этого цикла.
Вот.
То есть...
Если такое ребро найдется.
А можно даже еще проще.
Знаете, даже не вот так циклическо искать.
Смотрите, как надо искать.
Смотрите, из этого цикла
вот в эти вершины оставшиеся
хоть одно ребро да придет.
Иначе граф не будет сильно связанным.
Правда? Давайте
найдем самую близкую
к этому циклу вершину, в которую
ребро пришло.
Да?
Найдем самую близкую.
Тогда путь
будет...
Ну, вот.
Ну, тогда я утверждаю, что...
Ну, то есть, если это не эта вершина,
то путь, в общем-то, тогда автоматически оказывается
устроен вот по принципу там...
То есть, этот цикл пум-пум. Значит, тут
соответственно...
Нет, не так.
Только не сюда, а вот сюда.
Вот так, вот так, вот так, вот так,
вот так, вот так, вот так,
вот так и, соответственно, вот так.
Так.
Так.
Так.
Но там возникнет техническая
ситуация, что из этой вершины
ребро тоже может быть отправлено сюда,
поэтому придется эту пару там
более аккуратно искать.
Вот.
Да.
То есть, тут два варианта.
Либо эта вершина первая, с ней мы научились разбираться,
либо эта вершина не первая, и тогда мы
просто находим первое ребро и делаем вот так.
Вот.
То есть, получается, да, что вот... То есть, вот так
аккуратно съедая хвостик,
аккуратненько съедая хвостик,
мы понимаем, что
Гамильтона в цикл найдется.
Вот. Но, конечно же, в общем случае
это не обязательно так, то есть, в общем случае это будет
там...
То есть, в общем случае это будет, конечно,
вот какая-то такая ситуация.
Вот.
Но, впрочем, там...
Но, впрочем, то есть, Гамильтон в цикл,
Гамильтон в путь, конечно, организовать можно,
но тем не менее.
Так что, да, вот такая вот штука возникает
приятная. Значит, там
более-то можно придумать там разные сложности алгоритма,
которые это делают.
Ну, вот это вот можно забабахать, очевидно,
за n квадрат.
Может, даже если...
Может, даже если почесаться, можно даже как-то побыстрее.
А хотя...
Ну, да.
Нет, ну, Гамильтон в путь,
если вам ребро дается интеракторам,
то как бы можно за n лога найти.
Ну, там отдельная песня, как вы там
в этом бинпоиске еще вставлять будете куда-то.
Ну, мало ли.
Нет, ну, как бы...
Нет, ну, можно было себе подставить
допустим там
полный граф на 100 тысяч вершин.
Ну, вот граф слишком большой,
поэтому задается интерактором.
Найдите Гамильтонов... Скажите, пожалуйста,
существует ли у Гамильтонов путь за...
Я не знаю, сколько там...
Там 5 миллионов запросов.
Ну, да. Придется, да.
Придется пилить декартач.
Ну, декартач в том плане, чтобы там искать
катую в вашем порядке вершину и вставлять
куда-то там что-то там.
Вот.
Ну, или корневухой там вставлять еще можно, уже не важно.
Может, так...
Может, так проще будет, я не знаю.
А чего бы и нет, пожалуйста.
Нет, ну, зачем...
Нет, там фишка такая.
Вставлять-то вы будете корневухой, но как бы искать
все равно бинпоиском за энлога, за алгорифом.
В этом смысле все нормально.
Вот.
Ну, просто вставлять будет чуть удобнее, но, впрочем,
это как бы для тех, кто не любит писать декартач.
В принципе, ничего сложного
в нем нету, но уже...
Ладно, если вы уже написали задачу про
какой-нибудь там поиск
next permutation подотрески, то, в общем-то,
после этого, наверное, написать декартач
уже проблемы нет.
Или там сплей.
Или AVL.
Ну, и так далее. Так, ладно.
Так, ладно.
Так, господи.
Так.
А говорили мы вообще-то об одицепях, да?
Ну, хорошо.
Да, то есть...
А, это мы... Почему у нас это возникло?
Потому что мы неожиданно сказали, что
да, цепи антицепи.
Почему они так называются?
Потому что я тут мог сказать просто множество вершин,
любые две из которых попарно сравнимы,
они бы все равно оказались в последовательности.
Вот.
Ну, собственно,
теорема, которую нам очень
захочется доказать,
и более этого, честно говоря,
я бы ее до перерыва доказал,
потому что после перерыва у нас начнется шоу совсем
с этим не связанное.
Тема...
То есть...
Минимальное
количество цепей...
Да.
Это теорема Диллерта, собственно.
И Дилл Уорса там по-разному не называют.
Вот.
Ну, просто это из цикла.
Задача. Как прочитать вот эту фамилию?
Вот.
Ну, я не знаю. Я ее читаю Диллерт.
Ну, там другие есть версии Дилл Уорс.
А шо б я знал?
Ну, где-то они?
Нет, ну просто вот слово Уорс,
например, явно вы там, наверное, прочитаете
как Уорса, а не Уорт.
Наверное, да?
Расхождение от американец.
Ну, вот.
Так, ладно, давайте мы
и для конечного.
Значит, короче, минимальное количество цепей,
покрывающих чум конечного размера.
Ну, покрывающий, понятно, значит, что каждая вершина хоть
в одной цепи лежит.
Так, заметьте, кстати, нам здесь даже не принципиально
там пересекаются ли эти цепи.
Потому что если они пересекаются,
то они не пересекаются,
то они не пересекаются.
Потому что если они пересекаются,
то давайте возьмем точку переченья
и с какого-нибудь из пути ее просто выкинем.
Хуже не станет.
Вот.
Так вот, минимальное количество
таких цепей равно
максимальному
размеру антицепей.
Ну, на всякий случай скажем, в этом же чуме.
А то мало, а то мало ли, да.
Вот. Нет, мало ли, потому что
на разном максимальном размере антицепей в чуме,
который строится по этому каким-то там
экзотическим образом.
Берем то же самое, только строим там вторую крышу,
вот это все.
И более того, на поверху оказывается,
что ищется это максимально антицепей
вполне себе алгоритмическим образом.
Ну, потому что давайте сразу скажем,
как нам вообще найти
вот это
минимальное количество цепей?
Как мы уже с вами убедились,
это делается там
раздвоением чума
и поиском просочетания,
правда?
Понимаете, да?
То есть, ну находим
какой-нибудь там максимально, то есть получается
у меня такой же штрих
и находится максимальное просочетание.
И мы понимаем,
что вот это вот количество цепей
оно равно на самом деле к чему?
Оно разно...
Ну вот.
Да, то есть размер
g, ну пусть мне...
Ну давайте до a.
Хорошо, давайте a, а это а штрих, хорошо.
Да, минус
pi от а штрих.
Логично, да?
А теперь оказывается
неожиданной идеей.
Нашли множество, у которых столько
антицепей.
Это количество цепей, да, да, вот.
Так, ну во-первых, заметь...
Так, да, начнем со следующего.
Начнем с того, что антицепь...
Начнем с того, что
антицепь больше, чем стока,
мы точно не найдем.
Логично, да?
Да, для каждой...
Ну просто для каждой вершины
антицепи
должна быть своя отдельная цепь.
Вот.
Так что наша
теперь задача, хорошо, то есть
минимальное количество цепей мы уже поняли.
Оно равно вот этому, это мы уже знаем.
Знаем, знаем.
Колеса цепей не превосходят...
Нет.
Нет.
А про антицепь, да.
Пока мы знаем только больше либо равно.
То есть мы знаем, что
вот эта штука больше либо равна максимального
размера антицепи.
Потому что такое
количество цепей, во-первых, оно минимального,
во-вторых, оно точно есть.
Это означает, что
антицепь размера больше, чем стока,
вы не найдете в принципе.
Но правда, может, мы...
Так что теперь...
Нет, мы ее еще не нашли.
Нет, когда антицепь вот такого размера,
мы еще не нашли.
Но ша найдем.
Последние вершины тут ни при чем.
Смотрите.
Шаманство тут вот какое.
Значит, что такое антицепь?
На самом деле
антицепи по идее, чтобы тут никакие две вершины
не были соединены ребром.
В терминах двудольного графа
это означает,
что вы должны взять прям пары вершин,
и эти пары вершин тут никакими ребрами
не соединены.
Так вот, как мы это сделаем?
Значит, найдем в этом графе
максимальное независимое множество.
Как оно будет...
Как оно будет устроено?
Ну, заметим, что в каких-то парах никакие вершины
будут взяты, в каких-то парах
будет взято по одной вершине,
а в каких-то парах
будут взяты прям обе вершины.
Правда?
Видно.
Максимальное независимое
множество в этом двудольном графе.
Просто его рассмотрим.
И заметим, что
какие-то... Вот у меня все вершины
в двудольном графе делятся на пары.
Вот это а штрих, а 2 штрих, а b штрих, b 2 штрих, а вот это.
Так вот, в каждой паре
у меня в независимое множество
входит либо 0 вершин, либо 1 вершина,
либо 2 вершины.
Так вот, рассмотрим вот эти пары вершин.
Заметим, что эти пары вершин,
они соответствуют какому-то... То есть вот
набор вот этих пар вершин, которые попали
в независимое множество, они в исходном
графе соответствуют антицепи.
Логично, да?
Вот.
То есть вот такой антицепи.
Теперь рассмотрим, сколько этих двойчик
здесь есть?
Да, столько же сколько двойчик
в заполнении.
Да, ну вот.
Ну вот.
Так.
Сейчас, ну давай, ну вот.
То сколько и двойчик, надо пооценивать.
Потому что, в принципе,
ну давайте тут попишем, к чему равно
значит, вот это у нас
количество цепей.
Оно равно a-p от а'.
Но мы знаем, что p от а'.
У нас есть теория о том, что это,
давайте вот пишем, что это
модуль a-tau от а'.
Вот.
Но tau от а' к чему равно?
Нет.
Оно равно размеру двудольного графа.
А размер двудольного графа это вот.
Минус
а' от а'.
Понятно, да?
Ну вот. То есть равно
а'
минус модуль a.
То есть вот такая штука.
То есть вывод.
Вывод очень простой.
Вывод.
α от а' равно
модуль
a
плюс
количество цепей.
Ну что это означает?
У нас паре вершин
всего a.
А в независимом множестве
модуль a плюс
вот столько вершин.
Но отсюда автоматически следует, что пар
вот этих вот синих пар взятых
в независимое множество окажется
хотя бы вот столько.
Сейчас еще раз.
Колеса цепей равняется
а-tau.
Ну да.
Ну tau мы не замечаем, а просто
что такое tau?
tau это размер графа
минус а.
Да, ну вот мы это выявили сейчас.
Смотрите.
Независимое множество в а'
в каждой доле
ровно по модуль a вершин.
А в альфу
попала
модуль a плюс количество цепей.
Вывод. Я утверждаю, что из этого следует
следующее, что вот этих пар
вершин, именно пар вершин,
которые попали в независимое множество их
хотя бы количество цепей.
Но тогда заметим, что этих
если у нас есть получается
в независимом множестве, то есть есть множество
независимых пар размера хотя бы
количества цепей.
Но
так как этим паром соответствует антицепь
такого же размера то получается, что мы и нашли
в явном виде антицепь размера
не меньше, чем вот столько, потому что количество пар всего а.
Я могу тут расписать формальное доказательство, но желательно это увидеть.
Ну нет, но это опять приведет к формальному доказательству скорее,
конечно, потому что я бы сказал так, вообразите, в каждой паре мы берем 0, 1 или 2, правда?
Что вообще такое пары? Это вот синим, то есть что отмечен, это независимо множество, правильно?
Да, ну вот так, потому что вспоминаем, как мы вообще искали минимальное количество цепей,
как мы этот граф удольно вообще строили. Мы каждую вершину в чуме раздваивали, вот так вот,
да? И потом, значит, раздвоили, нашли просочетание, нашли независимое множество. Так вот,
я говорю, что пара попала в независимое множество. Если у меня там х- и х-2-, так вот,
теперь я утверждаю, что вот раз мы доказали, что независимое множество имеет вот такой размер.
Так вот, я утверждаю, что количество пар, попавших в это независимое множество, хотя бы вот столько.
Но количество пар в исходном чуме это антицепь, поэтому
я хочу сейчас доказать, что у меня сейчас в этом
независимом множестве найдется, то есть взято хотя бы вот
столько пар.
Так я это докажу, независимое множество у меня вот столько.
Я скажу так, наберем это независимое множество
следующим образом.
Если в паре нет ни одной вершины, то я ее приигнорирую.
Сделаем так.
Давайте в каждой паре, в котором взята хотя бы
одна вершина, я эту одну вершину возьму себе множество.
Беру, беру, беру, в общем любую пока, неважно.
Тем самым я взял себе, то есть теперь каждая следующая
вершина взятая, она будет давать новую пару, но при
этом до этого пока, так как я из каждой пары взял
не более одной вершины, то я взял не более чем вот
столько.
Следовательно, дальше я должен взять не менее чем
вот столько, следовательно паре, следовательно пар
я столько найду.
То есть более того, получается даже алгоритм, построим
такой граф, найдем независимое множество, рассмотрим все
вершины, которые прям парами туда вошли, вот вам антицепь.
Теорема-близнец этой теоремы, это более общий случай утверждения
про турнир.
Ну в турнире у нас покрытие антицепями единственное,
это ну типа все антицепи, все вершины это отдельная
антицепь.
Тогда соответственно, если мы воспользуемся теоремой
Близнеццом этой теоремы, то мы получим, что в турнире
есть цель длины N.
Ну вот тут возникает вопрос, а что такое близнец?
Тут не очень понятно, да?
Все-все-все, я не прав, турнир не обязательно ЧУ.
Да, ну нет, если он да, если он ациклический, то конечно
да.
Правда, если он ациклический, то доказать, что он гамиль
в пути есть, это тривиально, потому что сделаем топ-сорт.
Да, не находим независимое множество, а в этом независимом
множестве находим все пары вершин, которые попали.
Нету.
Нет, ребра из а штрих во два штриха мы не добавляем
никогда.
Не добавляем.
Нет.
Вот.
То есть нет.
Этого мы не добавляем, этого нам не нужно.
Вот.
Так что вот и оно вот.
То есть находим независимое множество, находим пары,
все, это антицепь автоматически.
Так что вот такая приятная вещь.
То есть вот так, что если потребуется.
Так, есть ли тут какие-то вопросы?
Так, нету.
Ну ладно, вроде как о просочетаниях это все, что я хотел сказать.
Поэтому, значит, пришло время перерыва, после которого
там перейдем уже плотненько в потоки.
Ну, точнее так, потому что сейчас как бы план действий
на самом деле с точки зрения глобальной теории потоков
у нас сейчас такой.
Ну начать мы должны будем с вами с того, что наконец-то
доказательность Акарпа.
А дальше мы перейдем к, называется двум просто,
можно сказать, парадигмам поиска потока продвинутым.
Там парадигма это, или концепция, в этом бы первая будет
концепция блокирующих потоков, видным представителем которого
является алгоритм Диница.
Вот.
А второе это будет уже что-то принципиально другое.
Это будет концепция, соответственно, даже концепция push relabel.
Она более известна как технология Голдберга.
Да, как всегда, еще одного американского математика.
Как вы уже помните, да, Эндрю и Владислав Голдберг,
но это я уже говорил.
Вот.
Да, Эндрю и Владислав, да.
American scientist, да.
Как всегда.
Вот.
Так что соответственно, да, причем обе концепции у нас будут
почти нечейные в том плане, что обе нам позволят
искать потоки закуп.
Вот.
Но правда, блокирующие потоки нам дадут, конечно,
чуть попроще, потому что, ну не попроще,
но с помощью блокирующих потоков у нас появятся алгоритмы,
как сказать, поток за VE log C и VE log V.
В чем VE log C достаточно халявно даже.
Вот.
Но VE log V это элементарно,
типа возьмите единицы и забабахайте туда линкат.
Да, идейно будет очень просто, но линкат, да.
Но вы, по крайней мере, с вами в отличие от ваших многих предшественников
как бы научились доказывать, что линкат работает с алгоритмами.
Ну, предшественников не совсем прям предыдущих, конечно,
но вот как бы предыдущие уже как минимум два поколения
как бы линкат умеют.
Нет, ну да, Катя, пора я мне точно это писала.
Так, а до этого...
Ладно, не важно.
Вот.
Значит, дальше.
Ну вот и так.
Ну вот.
Значит.
Так.
Ладно.
Давайте начнем с маленькой разминочки.
В роли разминочки у нас будет алгоритм Эдмонса Карпа.
И так.
Точнее его доказательства.
Вот.
То есть сам по себе...
Да.
Что такое алгоритм Эдмонса Карпа?
Алгоритм-то, конечно, тривиальный.
Потому что...
То есть тривиальный по формулировке имеется в виду.
Потому что мы берем просто метод Форда Фолкерсона
и ищем пути BFS.
Да, то есть запускаем BFS по всем ребрам
с любой пропускной остаточной способностью.
Понятно, да?
И вот возникает мистическая теория.
Алгоритм Эдмонса Карпа работает за ВЗ квадрат.
Или я ее переформулирую немножко по-другому.
Эдмонса Карпа выполняет...
Не более чем...
Ладно.
ВЕ итерации ФФ.
Да, формулировочка у нас, конечно, да.
Алгоритм ЭК выполняет ВЕ итерации ФФ.
Нормально.
Ну ладно, фураха не такое будет.
Ну Форд Фолкерсон тоже через DFS.
Да, действительно.
Да.
Да, согласен.
Давайте.
Ладно, хорошо, хорошо.
Чего?
Ну алг...
Это нормально, потому что это сокращение слова.
Чего?
Нет, ну тут уже совсем перебор, не надо.
Лучше вместо этого сосредоточим свои творческие силы на доказательства.
А доказательство на самом деле базируется на следующей лемме.
То есть базируется оно на такой лемме, что...
Ну скажем так, когда вы ищете BFS, вы находите такую штуку, как D от V.
То есть это расстояние от S до V по количеству гребер.
Понимаете, да?
Так вот, на самом деле высекает такая маленькая лемма.
В процессе ЭК D от V не уменьшается.
То есть не может быть так, что у нас было какое-то расстояние, мы сделали очередную
итерацию от бомса-карпа, и бабах, расстояние D от V стало меньше.
Вот я утверждаю, что в принципе из этой леммы, в общем-то, это все и следует.
Ну давайте поймем, как из этой леммы, в принципе, теорияма следует.
А очень просто.
У нас, как минимум, для одной вершины.
Нет, кстати, не факт.
Как минимум, потому что могут быть кратные ребра и просто такой же путь.
Вот, но фишка такая.
Потому что как из этой леммы следует теорияма?
Следует она вот что.
Дело в том, что каждая итерация форта Фолкерсона, она насыщает какое-то ребро, правда?
Именно насыщает, обратите внимание.
Да?
А как из этой леммы, в принципе, теорияма следует?
Ну теперь у нас возникает вопрос.
А сколько раз каждое ребро может насытиться?
Да, много.
Аж до V пополам.
Но как-то не больше.
Потому что вот какая ситуация.
Вот жило было ребро.
И оно насытилось.
А как-то не больше.
Потому что вот какая ситуация.
Вот жило было ребро.
И оно насытилось.
Но когда оно насытилось, тут было до этой вершины было расстояние L.
А до этой вершины расстояние L плюс 1.
Что?
В Edmunds Cart.
Да, в Edmunds Cart.
Вот.
Теперь возникает вопрос.
Может ли оно насытиться еще раз?
Конечно, может.
Но для этого нужно, чтобы у нас Edmunds Cart прошелся по ребру в обратную сторону.
Но когда это будет происходить, здесь будет расстояние хотя бы L плюс 1,
потому что у нас не уменьшается.
Но тогда вот у этой вершины, если у нас эта вершина там,
там какая-нибудь УВ, то как бы тут у нас ВУ.
И тогда здесь уже будет больше ребра равно, чем L плюс 2.
Значит, появилось это ребро.
А теперь опять обгон.
И теперь у нас должно возникнуть вот это ребро УВ.
Но так как тут уже расстояние хотя бы L плюс 2, тут L плюс 3.
То есть получается, если мы насытили ребро,
то на следующем насыщении расстояние до этих вершин увеличится хотя бы на 2.
Следовательно, насыщение будет не более чем В пополам.
А так как ребер у нас всего, которое могут насыть, это сколько?
Мимо.
Два Е.
Но дело в том, что у нас же насытится, может, обратное ребро.
А Е это у нас все-таки исходное.
Вот.
Нет, мы говорим, что их у нас двое.
Могли по-другому.
Рассмотрим ребро вместе с своим напарником.
Они суммарно насыщаются не более чем в раз к череду.
Как угодно.
Как удобно мыслить.
Идея одна.
Вот.
Но суть одна.
Но суть одна.
В итоге это нам приходит ВЕ.
То есть вот тут действительно тонко, потому что, видите, тут именно ВЕ.
Не от ВЕ, обратите внимание.
Именно ВЕ.
Вот.
Так что таким образом, если мы верим в эту лему, то теория автоматически доказалась.
Но как же мы будем доказывать эту лему?
А доказывать будем так.
Итак, вот пришло время сделать очередную итерацию Эдмонса Карпа.
Мы запустили БФС.
Вот.
Запустили БФС.
И вот, допустим, я нарисую так называемые слои.
Ну то есть здесь у меня будут вершины на расстоянии 1, вершины на расстоянии 2, вершины на расстоянии 3 и так далее.
Вот.
То есть у меня в каком-то слое у меня тут будет Т.
Могут быть, кстати, еще слои за ним.
Вот.
И тогда, значит, как устроены ненасыщенные ребра?
Они устроены так.
То есть есть ребра, которые идут из слоя в следующий.
Такие обязательно будут.
Между любыми двумя слоями такие обязательно найдутся.
Куда ж мы денемся?
То есть вот как-то так.
Вот.
Может быть вот так.
Вот так.
Может вот.
Ну вот тут еще что-то какая-то гадость.
Вот.
Да, могут быть еще какие-то вершины в ауте, но это нас не интересует.
Вот.
Какие еще бывают ребра, кроме вот таких?
Ребр такого плана.
Могут быть ребра назад, а могут быть ребра внутри слоя.
В любом количестве.
То есть единственное ограничение тут заключается в том, что
не бывает ребр, которые ведут из слоя в следующий, но не прям.
Вот следующий, а через один, там через два.
Вот.
Значит рассмотрим вот такие слои.
Значит рассмотрим какой-нибудь путь.
Вот.
Какой-то кратчайший путь, по которому мы будем проталкивать
Форда Фолкерсона, будет выглядеть вот таким вот нехитрым образом.
Значит мы что-то протолкнули.
И при этом образовались вот такие обратные ребра.
При этом какое-то из этих ребр точно убилось из зеленых.
Ну там допустим вот это.
Может еще вот это.
Ну остальные может убились, может нет.
Но это нам сейчас даже не сильно принципиально.
А теперь давайте подумаем вот о чем.
Каково будет расстояние до какой-нибудь вершины В
на следующей, допустим вот эта вот будет вершина В.
Каково будет расстояние до этой вершины на следующей итерации ФФ.
То есть вот прямо сейчас, вот сразу после того, как мы вот эти обратные ребра добавили.
Я утверждаю, что оно не уменьшится.
Почему?
Потому что если брать вот эти слои, которые были уже на предыдущей итерации,
мы заметим, что ребер скачущих через слой так и не появилось.
То есть у нас появились ребра, но все они ведут назад.
А вперед ни одного.
Поэтому если вершина В находилась скажем в третьем слое,
то расстояние на следующей итерации Эдманса Карпа будет не менее чем 3.
Именно не менее.
Ровно 3 никто не обещал, потому что одно из этих ребер могло убиться.
А то и несколько.
Да, могло не убиться.
Поэтому мы не утверждаем, что расстояние строго увеличится.
Но расстояние могло остаться, но меньше оно точно не станет.
Понимаете, да?
То есть вот таким образом получается, что расстояние от истока до любой вершины не уменьшается.
Так что таким образом мы доказали Циарему Эдманса Карпа.
Есть ли тут какие-то вопросы?
Хорошо.
Лежит, но он сложный.
Нет, утверждается, что придумал.
Глобально, да.
Это название грибов.
Да?
Это типа намек, кто его придумал или что?
Возможно, кстати.
Скорее даже вопрос на какую-нибудь графию, прочитание.
Нельзя сказать, что это хорошее правило?
Что-то более хорошее, прочитать точку Эдманса Карпа.
Нет.
Так, конечно.
Я вспомню, запускать эту игру на другую графию планеты будет быстрее.
Он будет работать быстрее?
Ну, нет.
Может быть, ассистически сказать, что он работает быстрее?
Я понял, что он работает быстрее.
Нет, это Дениц.
Не путайте.
Это будет Дениц.
Это будет, мы это докажем.
Но нет.
Это Дениц.
На нем работает неожиданно быстро.
Так, чего?
А это карта.
Нормально.
Это карта.
Это хорошо.
Эдман скрывается.
Но это да.
Некоторые люди не любят быть публичными.
То есть как-то не парадоксально.
Просто утверждается, что даже нет элементарно странички в каком-то инстаграме.
А, ну ладно, вас с этим тоже не удивить.
Да, да, да.
Как это называется?
У кого есть страничка в инстаграме?
Сопрещенная в России экранизация.
Вот это вот.
Так вот.
Но на самом деле просто эту картинку я, пожалуй, стирать не буду.
Потому что на самом, ну вот.
Потому что эта картинка, конечно, нам пригодится.
Да.
Есть Хопков карта.
Есть Эдманск карта.
Есть Рабинк карта.
Да.
Вот.
Ну нет, просто Карп это как бы тоже, как это часто бывает у ученых, он интересовался не только одним видом алгоритмов.
Вот.
Конечно.
Так вот.
Но потому что тут возникает, вот уже из этого алгоритма возникнет мысль.
Вот, действительно, вот мы много раз запускаем БФС и что-то думаем.
А теперь возникает такой вопрос.
А нельзя было бы на самом деле БФС не переспускать, а исходя из этой же сети как-то вот искать потоки.
Потому что есть же как-то подозрения.
Да, во-первых, кстати, вот из этой леммы есть важное следствие.
Следствие заключается в том, что в процессе Эдманса Карпа вообще-то расстояние до Т не уменьшается.
А можно еще заметить, что, заметить следующее, что вообще говоря, смотрите, вот если мы построили слои, и Т у меня находится в каком-нибудь там 57-м слое.
Так вот, у меня есть мистическое утверждение, что на самом деле пока расстояние 57 имеет смысл искать пути только вот в этих слоях, которые мы один раз нашли.
Вот фишка такая, смотрите.
Нет, ну не факт, ну вдруг там слои будут как-то меняться, но тем не менее там путь 57 мы будем находить.
Ну на следующем БФСе вообще, формально говоря, слои будут другими.
То есть какие-то вершины куда-то сдвинутся.
Вот.
Но у меня вытекает такое фантастическое желание.
А давайте с этим повременем.
Давайте я не буду пока двигать никакие вершины, а просто возьму эти слои и буду искать внутри этой сети.
Это будет называться у меня, кстати, слоистая сеть.
Вот я давайте спонтанно введу понятие.
Вот есть такое понятие – слоистая сеть.
То есть я говорю, что вот я запускаю БФС и оставляю в графе только ребра, ведущие слоя в следующий.
А внутри слоя нет.
Чего?
А внутри слоя выкидываем, вот эти вот еще назад выкидываем.
Ну временно естественно, да.
Вот.
И давайте я только на этих ребрах буду искать пути от СДТ и проталкивать по ним потоки.
Может вдруг мне это…
Ну вот.
Буду как-то искать.
Причем даже, не знаю, максимальный поток я нуду.
Или просто буду искать, искать, искать, пихать, БФС опихать.
И в какой-то момент неожиданно выясню, что оказывается очередного пути нет.
Так вот.
Я утверждаю, что расстояние ДТ в этот момент строго увеличилось.
Логично.
Ну потому что логично.
Логично.
Логично.
Логично.
Логично.
Логично.
Потому что если я делаю это много раз на одних и тех же слоях, то у меня и появляются только ребра, ведущие слоев предыдущих.
Правда?
Поэтому если у меня…
Поэтому пока я по таким путям ищу, значит, по таким путям делаю проталкивание, то оказывается, что пути длины 57 у меня будут только вот строго по этим слоям.
А как только у меня по этим слоям оказывается пути нет, то тогда оказывается, что и расстояние от СДТ будет строго больше.
А?
Фьюческие правды, что мы делаем, мы выкидываем все вот неинтересные на ребра и ищем вершины непересекающейся пути.
Ребрно непересекающиеся.
Ну нет, во-первых…
А, да, ребрно.
Во-первых, они и реберно пересекаются, потому что пропускные способности.
То есть вполне вероятно, что следующий путь пройдет еще раз по этому ребру.
Так что нет, тут можно упасть.
Конечно, если граф был единичный, то да, ребрно непересекающийся.
Но нет, пока у нас так.
Так что вот такая красота.
Вот, но заметим, что мы в итоге нашли, если мы тут вот…
Если мы тут неожиданно попихали вот такого рода поток вот в этой сети, да, вот как-то вот, допустим, у нас вот как-то так получилось, допустим, вот так получилось, там вот, может вот так получилось, еще там вот так.
И вот типа дальше от СДТ не пройдешь.
Казалось бы, да.
Является ли такой поток максимальным слоистой сети?
Слоистая, да.
Вот это нет, не факт.
Но именно максимальным он не обязан являться, конечно, потому что…
Ну, потому что у нас есть классический пример, напоминаю, вот этот вот, помните?
Вот, потому что вот слоистая сеть могла быть вот такой.
И вполне могло выясниться, что мы пропустили первым БФС-ом поток вот по этому пути.
И заметим, да.
И тогда в этом смысле окажется, что у нас в слоистой сети вот, чтобы расстояние было три, мы уже поток не улучшим.
То есть он, да, он не максимальный, но улучшить его прямо сейчас в слоистой сети нельзя.
То есть чтобы его улучшить, надо уменьшить поток по этому ребру.
Ну, да, но лучше, чтобы не возникало вот этом разрывов шаблон, лучше потреблялись слова «локальный максим».
Да. Нет, да, да, да, понятно, что у вас там было понятие «максимальный наибольший», это да, но вот такое.
Но мы там все равно любые два потока…
Здесь не очень корректно будет максимальный.
Нет, и здесь не очень корректно будет максимальный.
Нет, нельзя сказать, что он именно лучший возможный, но по крайней мере можно сказать, что его нельзя улучшить, не отменяя потоки.
Вот.
Да, если вот, то есть, но его нельзя улучшить, только увеличивая потоки. То есть нельзя найти такой путь.
Так вот, такой поток мы будем называть блокирующий.
Так, вот, так, вот, так.
Так, вот, так.
Так, вот, так.
Так вот, мы будем называть блокирующий.
Ну, в принципе, это можно общее определение вести.
Поток F называется блокирующим, если в остаточной сети не существует пути ZST, не идущего по обратным ребрам.
То есть, любой улучшающий путь от ZST должен отменить какой-то поток.
То есть, такой путь называется блокирующим.
И в принципе, тут предлагается некоторое обобщение.
То есть, идея такая. Заметим, что предположим, что мы построим слоистую сеть и построим какой-нибудь блокирующий поток как-нибудь жадно, или еще чем-нибудь еще.
Ну, просто построим блокирующий поток.
Заметим, что уже этого будет достаточно, чтобы сказать, что расстояние от ZST в остаточной сети увеличилось, правда?
Вот. В результате это приводит нас к тому, что я просто стираю эту теорему, а вместо этого пишу просто еще одну пафосную сеть.
Концепция блокирующих потоков.
В результате это приводит нас к тому, что я просто стираю эту теорему, а вместо этого пишу просто еще одно пафосное словосочетание.
Концепция блокирующих потоков.
Концепция блокирующих потоков, по сути, мета-алгоритм, устроена следующим образом.
То есть while действительно в GF есть путь от S до T.
От S до T по ненасыщенным ребрам.
Ненасыщенным.
Пфу, каким ненасыщенным? Не нулевым.
Ребра, как всегда.
Вот.
Значит, мы делаем так.
Строим в GF слоистую сеть.
Ну делаем мы это, естественно, BFS.
Я даже так напишу, BFS.
Не, ну то есть теоретически я мог бы как бы мета-алгоритмичность вставить и в этой строке, но это неинтересно.
Тут как бы все, уже есть BFS, там лучше, как бы сомнительно, что вы придумаете что-то лучше.
Ну а симпатически вы что-то лучше придумаете вряд ли, чем BFS.
Но может быть вы, ну может вы как-то BFS как-то там оптимальнее напишете, я не знаю, но сомнительно, что в эту сторону имеется мысль думать.
Так вот, потому что более интересно на самом деле, потому что как бы мета-алгоритмичность, а не алгоритмичность заключается в том, что мы ищем в слоистой сети блокирующий поток.
Вот.
Вот.
То есть это такой вот мета-алгоритм.
Тут как бы останется только вопрос, как искать блокирующий поток.
Что?
Нечего не видно.
Но на блокирующий поток все-таки пришлось, что они не идут по обратным рябрам.
Ну да.
Ну да, ну просто в слои, да.
Ну то есть определение мы говорим, что поток называется блокирующим, если не один из удлиняющих цепей, если все удлиняющие цепи идут хотя бы по одному обратному ребру.
Заметьте, да, в слоистой, конечно, да, тут надо не путать, что такое обратное ребро.
Потому что, заметим, блокирующий поток мы ищем в слоистой сети.
То есть в слоистой сети все вот эти ребра мы будем считать как бы прямыми.
То есть да, они могут быть относительно исходной сети естественно обратными, это да.
Но в слоистой сети они прямые.
Вот.
Да, ищем просто тем или иным способом блокирующий поток.
Ну как его искать?
Ну первый метод у нас уже придумался.
Такой алгоритм номер ноль.
Как-нибудь.
Просто хоть какой-нибудь.
Но от Edmunds Carp он отличаться по сути не будет.
Разница только будет, что в Edmunds Carp мы просто на каждый путь отдельный BFS писали, а тут написали BFS, а потом внутри этого BFS ходим видимо DFS.
То есть получилась такая пока усложненная версия Edmunds Carp.
Да, но даже даже не выбросили, я бы сказал проигнорировали.
Да, но по факту в реализации на самом деле мы просто в реализации забираю вперед, я скажу, что на самом деле мы ничего выкидывать не будем, а просто мы запустим BFS,
сохраним D и просто будем говорить, что если ребро ведет ни слой в следующий, мы его просто проигнорируем.
То есть это будет очень просто, позволит нам просто ничего не выкидывать.
Вот.
То есть самый тупой алгоритм мог бы выглядеть так.
Но есть более хитрая версия.
Хитрая версия такая.
Вот вы запустили DFS вот в этой сети и неожиданно выяснили, что вот попытались через это ребро пройти и неожиданно выяснили, что пути до T вы не нашли.
Тогда есть маленький приятный факт.
Вы через эту вершину пути уже не найдете никогда.
Да.
Здесь этот факт уже очевиден просто, потому что заметим, что у нас как бы потоки не отменяются, то есть сейчас пути нет, то им не откуда будет взяться.
Это понятно, да?
То есть не потому, что там какая-то лемма когда-то была, а просто вот жадный.
Сейчас пути нет, ну значит новых ребер у нас не появится.
Потому что в слоистой сети у нас новых ребер не появляется.
То есть если сейчас пути нет, значит его не будет.
Но тогда возникает естественная такая оптимизация.
С другой стороны, возникает такая идея.
То есть вот как там оптимизировать DFS?
Возникает такая идея.
Тогда давайте-ка вот если это ребро, вы по ребру попытались пройти и DFS не нашел никого пути, то давайте это ребро просто вытянем, чтобы следующие DFS по этому ребру не ходили.
Вот возьмем и вытянем.
Все, можно пока себе удобно это вообразить так, что предположим, что мы этих ребра храним в каких-нибудь там, я не знаю, двусвязных списках, и из двусвязного списка мы ребра выкидываем там на раз-два.
Ну пока себе для удобства такое вообразим.
Как мы потом убедимся, писать это естественно не надо.
Потому что понятно, что можно точнее написать и так, но тогда для каждого ребра в двусвязном списке вам нужно хранить еще указатель на то, а где у него там напарник там находится и так далее.
Потому что напарника тоже надо удалить.
Вот, хотя нет, напарников слоистой сети все равно нету, но вообще он все равно есть, потому что когда вы писаете поток, надо напарнику сообщить, что там вообще-то поток пустился, ну вот и все.
То есть это такая гадость истыкла, это делается, но это неприятно, но вообразить себе можно.
Или нельзя?
Ну да, как это?
Ну да, как это?
Как это?
Так вот, делаем в результате так, запускаем DFS.
Ну просто DFS у меня там будет возвращать что-нибудь типа, ну там самый тупой вариант, как int DFS.
Int v, int curc.
То есть это означает, что у меня сейчас в стеке лежит путь от s до v, по которому я могу пропустить путь curc.
Вот.
И дальше он будет работать так.
Перебираем все ребра.
Перебираем значит все ребра у там, ну там скажем, for там, edge, ampersand, там, e, там, graph, от v, ну и что-нибудь там сказать.
Ну и что-нибудь там сказать.
Если окажется, что там e.finish, точнее D от него, там не равен D от e.start плюс один, то просто continue.
Вот.
Ну ладно, не continue, а дилет edge от e.
Вот можно даже так сказать, delete edge, continue.
Да, сомнительно конечно, но тем не менее.
Да, сомнительно, но ok.
Сказал бы классик.
Вот.
Классика в банке нет, а кружок продолжается.
Приятно, да.
Вот.
Вот.
Выпустили она.
Ага.
Так вот, значит и так.
Так, ладно.
Ладно, значит далее, если оказалось, что, ну давайте я еще так напишу, если e.capacity оказалось 0,
ну в нашем случае равно e.flow, да, то тоже, вот, delete edge от e, continue, да, я даже в одну строчку напишу.
Вот.
А, ой, совсем забыл, в самом начале неплохо бы написать, что if v равно равно t, return e.
Нет, curc.
Да, curc, pardon.
Да, забыл.
Вот.
Значит int c, где равно равно?
Тут равно равно, тут не равно.
А тут равно равно.
Ну, e.capacity равно e.flow, это значит, что остаточная способность 0, да.
Так, дальше, c пусть у меня равно,
значит пусть у меня c это, значит, тогда результат,
значит, результат, соответственно, dfs из, значит, соответственно, e.finish
и minimum из curc и e.capacity минус e.flow.
Минус e.flow.
Вот.
Ладно, вот еще скобочка.
Так, потому что если он вернул мне c, то есть если он вернул мне 0, то есть сказал, что извиняйте, не получилось, извините, не получилось,
то что тогда можно сделать?
Совершенно верно.
Тогда мы торжественно удаляем ребро.
Elite edge от e и continue.
Господи.
Просто такой, тут прям хочется вставить этот define имени Тинькова, да.
Вот.
То есть который просто пишет вот это.
Вот.
Так.
Так.
Ну да, самое, самое тупое надо сделать так.
То есть можно так сказать, значит, push от e и c и return, ну вот.
Push это типа добавить налитие, добавить flow и обратно, ну и обратно.
Ну да.
То есть да, вот.
И в конце, если так ничего не получилось, то return 0.
Хочется ли нам сразу удалить ребро, если оно получится?
Ну как-то на самом деле ничего страшного, просто когда мы в следующий раз придем в эту вершину, мы это первое что сделаем.
Так что непринципиально.
Мы все равно, если шо, мы сразу выбросимся.
Да, заметим, что в следующую ротацию в форум мы придем через continue.
Вот.
То есть вот можно написать вот такой DFF.
Начнем вот уже с такого.
Хотя, конечно, сразу напрашивается, как написать хотя бы не асимпатически лучше, но это уже мы пока подумаем.
Не, даже не в этом дело.
Ну вот.
Ну пока давайте так.
Значит теперь давайте себе вообразим.
Как будет работать DFF?
Я утверждаю, что DFF будет работать за О от расстояния от СДТ плюс количество удаленных ребер.
Что?
А, потому что мы же удалили С.
Да, потому что смотрите.
Ну, заметим так, что, да, то есть мы, то есть фактически DFF работает.
Ну ладно, если уж очень хочется, плюс один.
Давайте напишем.
Вот этот один, это типа запуск работы в С.
Потому что когда мы работаем с вершиной, мы можем в это уже время включить и время работы с ребром, которое в нее привело.
Кстати, да, обратите внимание, ни одного юзера в этой DFF не нет.
Поэтому в принципе вполне вероятно, что мы в одну и ту же вершину будем несколько раз хранить разными путями.
Но это нас сильно не пугает.
Почему? Потому что заметим, что, ну, значит, фишка такая.
В каждой вершине, ну, то есть я утверждаю, то есть легко сказать, что в каждой вершине, то есть DFF работает за количество ребер, которые мы вообще видим.
Понятно, да?
Ну, потому что вот эти вот операции мы, значит, включаем в ребро, по которому мы вершину В пришли.
А вот то, что находится внутри фора, это, значит, мы включаем уже, ну, просто мы обрабатываем ребро Е.
И если у нас, то есть в том плане, что есть у нас возникнет DFF, который там за О от единицы выбросится, потому что там ребра закончились,
то мы этот DFF тоже как бы, это типа О от единицы обработки вот этого ребра.
Но заметим, что ребра у нас делится на два типа.
Либо мы вернули, либо через это ребро пройдет путь, вот этот вот, да?
Либо мы это ребро прямо сейчас удалим.
Поэтому суммарно все работает, поэтому один DFF работает вот за заявленную симпатику.
Понимаете, да?
Ну вот, но правда расстояние от S до T все равно больше либо равно единице, поэтому эту единицу мы выбираем.
А теперь, если мы просуммируем все это.
Так, ну теперь у нас есть какой-то вопрос.
Ну вот, то есть если мы просуммируем все эти суммы по всем DFF, то что получится?
Сумма расстояния от S до T по всем итерациям, а это не константа, да?
Ну DIST от S до T, он с каждой итерацией может с этим изменяться.
Плюс...
Ну давай, ну вот.
Ну плюс давайте так, сумма удаленных ребер.
Но, каждое ребро у нас из слоистой сети...
А, ну да.
А хотя нет, стоп, стоп, стоп.
А нет, стоп, да, не может удаляться, да.
Да, потому что да, мы рассматриваем одну итерацию поиска блокирующего потока, поэтому расстояние константное, да?
Поэтому как бы получается у нас количество DFF умножить на вот это расстояние.
И плюс количество удаляемых ребер.
Но удалиться у нас ребер не более чем E.
Вот давайте, не более чем модуль E.
А DFS, значит расстояние не более чем модуль V.
А DFS у нас сколько?
Нет, не больше чем E.
Да, не более чем E, почему?
Потому что DFS сам по себе блокирует хотя бы одно ребро.
Вывод.
Одна итерация такого DFS работает от VE.
Но, заметим, что давайте я тут глобальную левму сразу сформулирую даже, серию ему.
KBP выполняет любое KBP, но я имею ввиду любой алгоритм, основанный на концепции блокирующих поток, выполняет не более чем модуль V итерации Вайла, вот этого глобального Вайла.
Потому что основная теря заключается в том, что расстояние от СДТ, от итерации к итерации, строго увеличивается.
Понятно, да?
Давайте я это даже сформулирую.
Это вот.
Вот.
Итерации Вайл к итерации Вайл.
C Вайл.
Дист от СТ строго увеличивается.
Так, значит, что же у нас тут получается?
Вот мы с вами тогда, получается, этих итераций будет не более чем V, а на самом деле не более чем V-1, мы могли бы сказать, даже не более чем V-1.
И каждая итерация работает за VE.
То есть мы получили алгоритм за O от V2E.
Но правда, теперь осталось только его чуть-чуть получше реализовать.
Теперь, как удалять ребра так, чтобы не писать вот эту вот гадость с удалением из какого-то там списка?
Да.
Идея была уже озвучена.
Она очень наглядно видно из этого DFS.
ДФС, по сути, перебирает ребра просто в каком-то заданном порядке от начала до конца.
И фактически заметим, что если на какой-то итерации DFS у нас дошел до какого-то ребра, то тогда получается, что все вот эти ребра удалены, и в следующий раз он пройдется по этим ребрам и поймет, что тут все плохо и начнет с этого.
Тогда возникает естественный вопрос.
А почему бы нам не сохранить, где мы в прошлый раз остановились?
ДФС очень интересен.
Если он встал на какое-то ребро, то он с него не слезет, пока его не убьет.
Поэтому на самом деле все работает очень просто.
Поэтому вместо вот этого мы напишем такое.
Я напишу так.
Так, давайте я тут каким-то красивым красненьким напишу.
Ну вот, edge iterator ampersand it равно cur it от v, it.valid, знаете, я вот так напишу, it.next.
Что я тут имею в виду?
Ну потому что если бы с вами прям с нуля писали, вот к сожалению мы с вами не писали реализацию сети с нуля,
но там оказывается очень удобно на самом деле завести какой-нибудь магический итератор,
который смотрит на ребро и только через него вы разрешаете себе вообще что-то там делать push.
То есть соответственно it.
А так глобально вы заводите массив, то есть скажем так и напишите, там edge iterator cur it от, ну вот его размер соответственно на модуль v.
Ну это изначально где-то в инициализации пишете, что v от нуля до n-1, понятно, cur it от v равно get begin от v.
Понятно, да?
И в результате итератор хочется реализовать так, что next это типа он, вот, то есть next он как бы переходит в следующую итерацию,
а также он еще может принять состояние end, то есть типа он уже никуда не указывает и говорит, что он не валит.
В принципе, если вы программировали на языке Java, то итераторы там реализованы, вот, по-моему, чуть менее чем вот так.
Чего-чего?
Ну да.
Нет, ну это, да, это типичная Java, ну Kotlin это, в общем-то, извините, базируется на Java.
Вот, то есть может там с какими-то дополнительными плюшками, но как бы, но суть одна, то есть это все-таки как бы Java.
Значит, далее.
Вот.
Значит, смотрите, и тогда код превращается так, то есть каждая емрия придется заменить на it.finish вот так вот написать.
Вот так.
Так.
Но delete edge, конечно, вылетает, а заменяем мы его ничем, потому что мы здесь пишем it next.
Значит.
Так, вот эту, ну тоже надо it.ref, ну можно так написать, хотя по-хорошему я бы написал, конечно, it.isSaturated.
Ну, логично такой метод написать, который внутри себя вот это же и проверит.
Вы знаете, нет, не обязательно, не обязательно.
Это ты мыслишь как итератор, это как указатель на какое-то ребро.
А дело в том, что я хочу, чтобы у этого итератора, помимо всего, прочее, но я хочу так, я хочу, чтобы к этим ребрам у тебя доступа не было.
Почему?
Ну, потому что суть такая, как бы в сети у тебя есть какие-то инварианты, которые заключаются в том, что если ты пустил по ребру поток величины 5, то у тебя есть какие-то инварианты.
Ну, потому что суть такая, как бы в сети у тебя есть какие-то инварианты, которые заключаются в том, что если ты пустил по ребру поток величины 5, то по обратному ребру должен пойти поток минус 5.
Ну, хотелось бы, да.
Поэтому очень хочется, чтобы ты умел пускать нот.
А если тебе дать по указателю возможность смотреть на ребро, то в принципе ты там можешь взять поле и просто его переписать, как тебе угодно.
Да, тогда это должен быть либо константный указатель, да, но у тебя должна быть, но тогда, если какая-то вопрос, тогда ты по этому итературу вот здесь вот это ребро не пустишь, вот это не пустишь.
Я бы для себя сказал так.
Нет, и потом дело в том, что этот итератор, он позволит вам дать интерфейс, потому что в принципе он может дать вам возможность, ну потому что как это будет выглядеть на самом деле в сети.
То есть в сети, то есть в сети у вас возможно не будет, то есть у вас может быть не будет доступа просто к тому, как устроены ребра.
То есть непонятно, может даже вы не будете, потому что там отдельная песня, как вы эти ребра будете хранить и как вы по ним бегать будете.
Чего?
Вот, нет, потому что на самом деле, слушайте, по-моему, мы приходим к тому, что неплохо было бы действительно этот поток просто с нуля написать.
Нет, нет, непонятно, непонятно.
А идея с 41 была озвучена?
Ну когда-то, нет, она была озвучена.
Но там, нет, дальше начинается фишка, а можно ли обойтись без ресайда, без пушбеков вектора.
Нет, ну да, нет, ну там просто вот этот итератор мог быть устроен немножко по-другому.
Потому что если кто-нибудь когда-нибудь писал хотя бы обычные просто ориентированные графы на паскале.
Вот, а я писал. Нет, он напоминает, я как бы в школе олимпиады писал только на паскале, если что, как бы Сиел знал только в УЗе.
Вот, соответственно, вот, а Геннадий Каракевич вообще на паскале три междара выиграл. Я одно-второе место.
Да, на пяти.
Чего?
Чего?
Нет, ну сейчас. Нет, почему нет? Ну почему нет, он писал чисто.
Нет, ну, видимо, там стандартная логика вида. Нет, понятно, что он там Си на каком-то уровне знал, потому что топ-кодер он как-то писал, но топ-кодер и паскаля не было отродясь.
Ну, в общем-то, я тоже писал код на паскале.
Но правда там фишка такая, я не умел тогда открыть среду и там как бы настроить себе нормальный проект, но в топ-кодере этого не требовалось.
Почему? Ну там потому что там это экзотично было, там было понятие топ-кодер арена, надо было приложение открыть.
Нет, не на телефоне, естественно. Вот.
И там было понятие открыть задачу. То есть там вам включается окошечко, где вам показывают задачу, и вот в этом в соседнем окошечке надо вбить решение.
Причем не просто вбить решение, а решение там было, вы должны написать класс там с заданным названием, в котором есть публичный метод такой-то, который собственно решает задачу.
То есть мейн писать не надо, но и у вас там была возможность это запускать.
Вот, да, это было очень красиво и в принципе это позволяло возможность там, позволяло спокойно писать.
То есть для этого единственное, что вам нужно было в паскале узнать, как пишется вектор и стринг, все.
Ну и то, что там присваивание делается без двоеточия, ну и прочее.
Не, я помню, у меня когда-то были мелочи, когда я там не понимал, почему у меня код не компилируется, потом выяснилось, что оказывается в языке C нет оператора if с большой буквы.
Да, нет, паскаль в этом смысле как бы можно и так и так наплевать, да.
Поэтому я там все красиво.
Да, кто-то даже так и пишет, if, then, lz, там вот это все.
Вот, да, ой, извините, если кого-то разбудил там, да, вот.
Соответственно, вот, значит, так вот, так же соответственно.
Причем более того, в этом вот next может быть все, что угодно.
Ну, я давайте кратенько расскажу, не будем писать код, но вообще есть как писать вообще в паскале.
На самом деле в паскале список смежности написать достаточно просто.
То есть вы заводите список ребер, ну прям честно пишете список ребер, прям вот такой вот, вот такой там, там типа там 1, 2, там 3, 4, там 1, 4, там вот это все, да, 4, 2, ну и так далее.
Там 3, 2, вот.
Это будем называть ну просто честно список ребер, допустим, да.
Еще заводим два массива.
Заводим массив А, который для четырех вершин вам честно скажет, где находится последнее ребро, торчащее из этой вершины.
Ну, в данном случае здесь будет написано 3, там, допустим, 3, 0, значит, 5, 4.
Почему, да, да, в паскале можно все с один адексацией делать, поэтому там так принято и делать.
Да, это массивы с одной, с один адексацией.
Этого указали последнее ребро.
А еще здесь можно указать массив УК.
Да, ну я его называю УК, от русского слова указатель.
Вот.
А не то, что вы подумали, да.
Так.
Да, что вы подумали, да.
Отдельно пишем.
Ага.
Вот.
Вот.
Так, ну здесь идея такая, для каждого ребра просто надо сохранить, а где находится предыдущее ребро?
То есть, где находится предыдущее ребро?
Ну, если его нет, пишем ноль, то есть вот так пишет, ноль, ноль, там, ноль и два.
И тогда заметим, что pushbackнуть сюда ребро, то есть просто задаем ребро массив на нужного размера,
и когда вам нужно pushbackнуть новое ребро, то вы там за вот единицы разбираетесь, куда там что писать.
Ну типа сюда пишете то, что написано в массиве А, в массиве А пишете вот эту позицию.
Все.
То есть, поэтому получалось, что в паскале список смежности пишется элементально.
Более что?
Проблема только в том, что в плюсах вас разращает вектор-вектор.
Нет, я делаю один стат массив ребер.
Да.
Но в принципе, нет, можно это, нет.
Нет.
Мы только храним, где находятся, для каждой вершины храним, где находятся последние ребра.
Вот, как находятся, а очень просто, когда вы добавляете ребро, вы тут же добавляете обратное.
Чего?
Ну не хранишь, а просто, если у тебя ребро имеет индекс int, то индекс обратного ребра индекс XOR 1.
Чего?
Ну это да, но правда единственный минус, что иногда оказывается, что если вы хотите оптимизировать свой код где-нибудь там на 0,4 секунды, то оказывается, что избавиться от вектора-векторов это оказывается разумной идеей.
Знаете, вот есть такая подлая задача, у вас она даже в ДЗ есть.
Задача называется найдите отсвертку.
Нет, ладно, найдите SOS DP.
Так вот, ситуация.
Допустим, вы решили написать честное DP.
Ну в смысле?
Ну потому что если объяснять это детям, которые не знают там многомерного FFT, вот этой вот высокой математики, то как вы им будете объяснять?
Будете объяснять так.
Вот пусть DP от маск ИТО, это там сумма по всем подмаскам, которые в первые EBIT такие же, как у маски.
Так вот, и получается какая динамика?
Так вот, самый тупой вариант, а давайте вот честно эту динамику, прям двумерную напишем.
Так вот, как выразила практика, если вы напишете это на двумерном векторе, вы рискуете нарваться на TL.
Да, там его ужали на 0,8, но вот оказывается проблема.
Вот.
И там вот оказывается, ну вот, ну как-то вот, да, возникает проблема.
То есть там вот оказывается, что, по-моему, если замениться хотя бы на статику, то, по-моему, там уже оказывается, окей.
Вот.
Там двумерные?
Ну, в исходной версии, да.
Другой вопрос, что это можно допилить до одномерного массива, естественно.
Ну и вообще мы с вами уже убедились, да, что там.
То есть он на векторе TLется?
Вот.
Если TL закрутили за 0,8, то может по TL.
Нет, там много памяти, много векторов, то есть вот оказывается, вектора в этом плане дают.
Вот такие.
Ну тоже можно, да, но нет, понятно, что ладно, в СОЗДП не надо этого делать в принципе, на самом деле.
Но там просто оказывалось, что на двумерном массиве, оказывается, можно достичь там 0,3.
Вполне себе.
Да, массив там 2 в 20, если что.
Вот.
Так что можете, в принципе, поэкспериментировать на эту тему.
Вот.
То есть там вот, поэтому, поэтому иногда вот вектор векторов, это то, чем, вот, особенно, если вы хотите, там, вот, вот.
Вот.
То есть такие вот балансики.
Ну и тем более, нет, у меня был вообще прецедент, что даже вообще многомерными массивами иногда баловаться не надо,
потому что я рассказывал этот прецедент, когда я написал решение с пятимерным массивом, даже статическим, и получил TL.
Я поправил пятимерный массив на одномерный массив с, там, патчингом вручную, там, пяти индексов в один.
И получил там, окей, там, с полутора миллиметра.
Да.
Вот.
Так что тут...
Да.
Да.
Да.
Да.
Да.
Да.
Да.
Да.
Да.
Да.
Вот.
Обязательно вообще-то так торопиться, возвращать с из этого языка?
Вот.
А это, нет, это следующая оптимизация.
Да.
Нет, на самом деле, смотрите, лучше тут переписали.
Так.
Если с, значит, пишем, если с равно нулю, то continue.
Так.
Здесь мы напишем по-другому.
Здесь мы напишем it.push от c.
Вот так.
Нет, потому что, ну, вот, то есть вот такая вот идея возникает.
То есть, видите, мы ничего не удаляем, а просто вот двигаем итератор дальше.
Видите, тут, да, вот этот амперсант является важной частью алгоритма.
Вот.
Нет.
Нет.
Эктератора даже нет.
Это же не то, на что нужно...
Упрызать итератор, далее квейс на структуру.
Нет, просто, нет, важный момент, понимаете, что если я тут не напишу амперсант,
то он скажет, то как бы itnext будет работать просто для копии итератора.
А кур it от v не поменяется.
Да, здесь...
Ну, такой.
Нет, ну, здесь просто вот, может, корректнее так писать.
Потому что, мало ли, потому что такой интерфейс дает вам возможность внутри самой сети,
по идее, проявить там какую-то свою фантазию.
Потому что, по идее, если от вас требует такой интерфейс,
то это означает, что вы там в сети можете писать все, что угодно,
что поддерживает этот интерфейс.
Вот.
И это даст вам возможность, может быть, где-то что-то лучше сделать.
Вот как векторы, например.
Потому что векторы, что такое вектор?
Это, с точки зрения шаблона, это что угодно,
что поддерживает интерфейс с квадратными скобочками и всеми методами, которые там прописаны.
И еще требования, чтобы они там адекватно работали.
Например, за единицу, за амортизацию, бла-бла-бла.
Вот.
Но у нас есть возможность иногда подшаманить.
Потому что иногда выясняется, что вектор Bool, или вектор Int,
можно реализовать оптимальнее, чем вектор от произвольного типа.
Вот.
Поэтому, ну вот.
И как бы такая интерфейсизация вам дает возможность так сделать.
Но другой вопрос.
Да, там другой вопрос, что вектор Bool, конечно, мы там нарушаем,
или там нарушаем ее почему-то, да.
Но это уже другая история.
Вот.
Нет, ну просто нет.
Вектор Int, нет, но вектор Int, наверное, все-таки полегче.
Потому что вектор Int, есть подозрение, что какой-нибудь олдскульный C,
наверное, с массивом на Int, может уметь работать чуть лучше,
чем с массивом на абсолютно произвольные типы.
То есть там, ну, может быть, какие-то...
Ну, тем, что это более базовый такой C-шный тип.
И, возможно, там просто в каких-нибудь сях,
просто можно более удобно с ним работать, что ли.
А, или там, ну да, или там, если вызывается метод там,
какой-нибудь fill.
Нет, ладно, ну там, может там...
Например, resize, ты можешь не вызывать конструктор.
Да.
Ну, что-то такое.
Ну да, да, да, то есть вот.
Так, давайте...
Это текущий предвидел вопросов, но если что-то неправ.
Чего?
Ну так, не превращается в какой-то ассамбльный код.
Ну хорошо, хорошо, да.
Это работа на уровне компиляции.
Он понимает, о, мне, Int, ну...
Так.
Нет, если не компилятор, то сам оптимизатор как бы скажет,
что да, вот эта операция лишняя, мы ее выкидем.
Да, это интересно.
Да, да, да.
Ладно, да.
Ну не суй.
Нет, ну не суй, ладно, да.
Но вот этот коцикл пор конечный, он оптимизируется.
Ой, нет.
Не, ребят, все еще, нет, на самом деле, нет, ну тут как бы все еще круче.
Нет, ладно, более крутой пример это да.
Вопрос как бы, а, std set.
Потому что вы можете забабахать сет на, там в любом случае на красночерных деревьях.
А можете сказать, что если сет от Int, то давайте-ка лучше забабахаем там...
М-м-м.
Дереван.
Именно.
Именно, да.
Дереван Индебоса, да.
Вот.
Которая будет работать за какую-нибудь там крутую симптутику.
Да.
Непонятно, что круче LogN или LogInt.
Которая там будет.
А, нет, там будет LogLogN.
А LogLogInt это у нас сколько?
Logarithm 32, то есть...
Да, пять.
Вот.
Правда, да, правда вам придется какие-то там хэш-мапы использовать, да, но...
Но чисто теоретически обратите внимание, у вас такая возможность есть.
А у дерева Индебоса, у него же памяти будет больше, чем у...
Да, нет, но если вы не забабахаете хэш-таблиц, конечно.
Так-то да.
Ну, идеально дереван Индебоса потребует от количества чисел в Индебосе.
Это да.
Да, да, да.
В этом смысле да, но теоретически такая возможность есть.
Вот.
Нет, ну это на самом деле, да, дискуссия эта скорее по C++,
типа зачем нужны такие интерфейсы.
Ну, кстати, и в Олимпиадах тоже они могут пригодиться,
потому что на самом деле, да, то есть в Олимпиадах это редко надо,
но если вы пишете какую-то сложную задачу с несколькими составляющими,
то если вы пишете это в подобного рода логи, очень удобно.
Тем более, что этот интерфейс, ну, просто удобно про это писать,
ну, как минимум потому, что каждую часть программы пишете как черный ящик,
который общается с внешним миром только через заданный интерфейс.
А черный писал по реворту классы FFT.
Ну вот, ну класс-то.
Ну, замечательно.
Ну, у меня FFT это шаблоны класса двух аргументов,
она следует от класса FFT0, у которого есть вертальные функции FFT и NIP.
Боже мой.
А ты понимаешь, что это будет очень легко работать?
Виртуально нас и виртуально всегда писал в интерфейсе.
Ну, да.
Нет, ну это уже немножко о другом.
Ой, ой, да.
Да, да, да.
Нет, ну тут, да, бесконечно, может долго,
но тут в данном случае, конечно, разговор не о том, чтобы это было оптимальнее,
да, то есть это может быть лишние интерфейсизации иногда не даст вам возможность чуть-чуть оптимизировать,
но с другой стороны, если вы там пишете сложную программу или еще круче,
такой редкий случай, такой тоже бывает, если внутри команды, если код пишет более чем один человек,
а такое тоже бывает, между прочим, да,
что там один человек напишет вам там потоки, допустим,
то есть вы там даете кому-то, слушай, давай, напиши мне Динец,
у вас там сакоманник за 6 минут его пишет, допустим, да, вот.
Он говорит, где-то за.
Ну вот.
Нет, ну просто фишка, что вы с ним спаены, вы уже знаете его примерный интерфейс,
который вам предоставят, поэтому вы в принципе уже потом,
когда он допишет Динеца, вы за это время уже вывели, соответственно,
какую сеть вы хотите построить и запустить,
и после этого садитесь и вбиваете уже на заднем интерфейсе.
Но вот нет, нет, да, но нет, был-то он сакоманька, но вы его знаете,
потому что вы, скорее всего, с ним спаены, ну или он вам расскажет,
на первый раз расскажет, а потом он уже спаеный, так что это вещь такая.
Вот нет, на самом деле, знаете, классическая история из там статьи,
как стать три же, там, как и три раза выиграть чемпионат Урала по программированию.
Чего?
Ну, достижение, ну, достижение было такое.
Нет, ну, неважно, там парень, там это уральцы, там какие-то были,
но это неважно, у них было достижение, чтобы, помимо этого,
они еще взяли бронзу на чемпионате мира, так что нормально.
Вот, в чем более того, когда они выходили в финал,
говорит, я вот помню, когда мы не сговариваясь,
вот когда мы вот писали вот код вот параллельно,
и не сговариваясь, там назвали одинаково функцию,
которые стыковались в нашей модуле.
Так вот, именно в этот момент, за 10 минут до конца контеста,
я поверил, что мы выйдем в финал.
Вот, как вы понимаете, вот, в этом моменте,
за 10 минут до конца контеста, я поверил, что мы выйдем в финал.
Вот, команда вышла в финал и взяла бронзовую медаль.
Чемпионатурала все еще существует?
Кстати, да.
Да, мне что-то вчера шепнули, что вроде-то когда-то там в конце мая,
он там даже будет, может, мы даже туда съездим.
Не знаю.
В последнее время, как бы, да, хотите ли вы съездить 20 мая
на чемпионатурала?
Так, когда у меня там сессия?
Вы знаете, нет.
Хотя, хотя, с другой стороны, не знаю, какие-нибудь там вот...
Ага, тогда поедут, просто два потока поедут.
Нет, ладно, нет, Степанов, конечно, за такое бонус давать точно не будет, да.
Вот.
Нет, ну нет, ну на самом деле.
Ну, я боюсь просто, к сожалению, да, если бы всего-то
сдавался по всем предметам, тогда да.
Просто у вас же там зачет, зачет и еще там по мотонам всяким.
Так что нет, это вещь такая, да.
Вот.
Ну, хорошо.
Ну, как бы, да.
Вот.
Вот.
Так что нет, это вещь такая, да.
Вот, ну хорошо.
Ладно, если возвращаться к делу.
Ну, действительно, почему хотелось, значит, не дооптимизировать отсюда,
потому что, ну, по камере, по камере мы с вами будем считать,
что именно это называется алгоритм Диница.
Да.
Еще раз подчеркну, грамматический момент.
Неправильно говорит алгоритм Диницы.
Правильно говорит алгоритм Диница, потому что фамилия Диница,
то есть Диниц, пишется вот так.
Да.
Вот.
Вот.
Да, его зовут Ефим.
Да.
Да, там что-то Ефим, там Ефим, что-то там Диниц.
Мы там уже гуглили, да, советские позы, там позже израильские ученые.
Да, да, да, вот это вот.
Вот.
Поэтому правильно говорит алгоритм Диница.
И писать надо Диница, а не Диницу.
Вот.
Но с нашей точки...
Он как бы является, да, часто говорят еще,
что давайте писать блокирующие потоки как Диница.
Почему?
Ну, потому что, может быть, да, Диниц это, можно сказать,
человек, который ввел концепцию блокирующих потоков.
Вот.
Ну, как ввел?
Может он ее не вводил прям явно именно как концепцию,
потому что потом обнаружилось, что, оказывается,
можно блокирующий поток искать вот не таким образом,
как он предлагает, а чуть по оптимальнее.
И дело даже не в этой логичной неосимпатической оптимизации.
Потому что, да, есть логичная, потому что, в принципе,
вот есть такая неосимпатическая оптимизация,
которая говорит о том, что вот как правильно заметили,
что если мы сделали, пропустили С,
а тут курс С было больше, то возникает вопрос.
То, во-первых, это означает, что мы ребро насытили,
а во-вторых, а почему бы нам, собственно,
не пойти в следующее ребро и остаток не пихнуть дальше?
Что?
Ну, правильное... Смотрите, оптимизация пишется здесь так.
Значит, я убираю ретурн С и говорю так.
Курс С минус равно С.
Значит, если оказалось...
Нет, тогда тут неправильно.
Надо написать тогда так, int ans равно нулю.
Вот так напишем.
Ну, для удобства просто.
Значит, С равно вот это, значит, push С.
Значит, мы здесь напишем, курс С минус равно С,
а ans плюс равно С.
Значит, если оказалось, что курс С равно нулю,
то ретурн ans.
Вот. А если оно оказалось не равно нулю,
значит, мы ребро по-любому насытили,
и можно делать next и идти дальше.
Нет, если курс С осталось неравным нулю,
значит, мы его насытили.
Наверное. Нет?
Да, но смотрите, тогда два варианта.
Либо мы это ребро насытили, и тогда можно идти дальше.
Либо мы его не насытили, но у нас была возможность пихнуть там больше,
и мы этого не сделали.
Поэтому это означает, что через это ребро мы больше все равно не пихнем ничего.
Потому что, смотрите, здесь технология такая.
То есть запускаем мы этот DFS изначально,
то у нас как бы DFS от S и плюс бесконечность.
То есть как бы я хочу жадно пихнуть вот много-много воды.
Но DFS у меня говорит, что я пришел тут по какому-то пути,
и по этому пути я могу пихнуть там сколько-то.
Вот.
Там пихнуть, это пихнуть по этому пути сколько-то.
Я пытаюсь это пихнуть по максимуму.
То есть если я могу пихнуть 179,
я могу пихнуть только 57,
я хочу пойти в следующий ребро и допихать оставшееся 122.
Вот.
Да, и здесь, конечно, уже не ретурн 0, а ретурнация, естественно.
Вот.
То есть это такая более оптимальная версия 1.
То есть более крутого доказательства, чем вот этого у меня нет.
Но по слухам, по-моему, есть версия задачи пихните поток от Капилевича,
в которой исходная версия вот без синих оптимизаций тейлится.
Ну вот.
А вот это уже заходит.
Что?
Синяя оптимизация даст следующее, что мы за 1 DFS,
ну то есть за 1 DFS, то есть DFS исходно что делал?
Если нашел путь, то он просто по нему пропихнулся и выбросился.
Вот.
А здесь вот возникает идея, что
вот мы нашли путь и пустили по нему какой-то поток.
Величины 5.
Почему 5?
Потому что у вас тут в середине где-то было ребро 5.
А до него там были ребра 100, 200, 300, 400.
Возникает вопрос, а давайте мы вместо этого,
после этой пятерки тут еще в ребра пойдем и оставшиеся 95 распихаем.
Вот.
Ну да.
То есть смотрите, типичный пример, на котором эта ситуация проявляется,
выглядит вот так.
Вот, допустим, у вас там какая-нибудь сеть,
где у вас тут много-много-много, там 10 девятый, 10 девятый, 10 девятый, 10 девятый.
И куча вот такой вот гадости.
Вот.
По единичке.
Обычный единиц будет на пропих каждой единичке
тратить прям ОАТВ-времени.
Ну вот, то есть ОАТВ будет работать, там В в квадрат получится.
Вот.
А при вот таком жадной реализации,
он эти 10 девятый тут распихает, и это сработает просто за один ДФС.
Нет, ну скажем так, хуже не стало.
Потому что ДФС продолжает говорить, что как только ДФС идет дальше,
то есть ФОР идет дальше, значит, мы это ребро уже больше рассматривать не имеем смысла.
Поэтому он продолжает работать за количество удаленных ребер,
плюс какой-то последний может быть найденный путь.
То есть, в общем-то, у вас есть какие-то проблемы?
У вас есть какие-то проблемы?
У вас есть какие-то проблемы?
То есть какой-то последний может быть найденный путь?
Тут вот в чем идея.
Нет, хотя не совсем правда.
Нет, смотрите.
Дело не совсем так.
Значит, смотрите, теперь доказательство звучит так.
Каждое ребро либо сейчас удалено,
либо оно сейчас удалено,
либо по нему мы нашли путь и протолкнули.
Вот этот вот пуш был выполнен.
Но заметим, что понятно,
по каждому ребру пуш мог быть выполнен несколько раз, естественно.
Но каждый пуш будет соответствовать тому,
что мы теоретически нашли путь хотя бы один
и протолкнули по этому пути какой-то путь.
Таких путей будет не более, чем е, потому что насыщенное ребро.
Понимаете, да?
Поэтому асимптотика хуже не стала.
Другой вопрос, что у вас несколько пушей могли схлопнуться,
что там, может быть, вы через какое-то большое ребро
нашли много-много-много путей, но они разлетляются дальше.
Поэтому вы на них сделали,
конкретно это ребро сделали не много-много пушей,
а только один большой, который вот тут просуммировался.
Вот.
В этом и оптимизация.
Но как бы формально хуже не стало.
Так что вот получилось.
Это отдельная песня.
Но для этого нам придется изучить масштабирование.
Да, его можно оптимизировать с помощью масштабирования.
И мы сделаем это.
Но сделаем мы это, я думаю, как раз после перегрыва.
Так сейчас у нас в оставшейся части занятия у нас будет,
может быть, самые веселые факты, на самом деле, об этом всем.
Так.
С чего бы нам начать?
Нет, ну ладно, начнем с прикола.
Так.
Не, если бы.
Не, ну я могу, конечно, проанонсировать, что вот.
Да, собственно, вот эта игра с шутками про госуслуги
и прочие агитации на тему того, что надо читать,
это как бы вот игра вышла вот в субботу.
Так что мы уже можно посмотреть.
Вот.
Но это так.
И с какими-то там грустными шутками.
Господи, мне же все рассказали, у нас с 2008-го столько произошло,
там мы сняли фильм в космосе, мы выиграли чемпионат мира,
там мне все рассказали, выиграли чемпионат мира по хоккею.
Нет, тебе ничего не рассказали.
Ладно.
Не, но этого я, очевидно, тоже не рассказали, да?
Нет, я не знаю, может они там учатся в синергии, им все это рассказывать.
Что-то мне подсказывают, что нет.
Ну ладно.
Вот. Как это, ну?
Ладно.
Ладно, в общем, отдельно.
Значит, пока тут фишка такая. Дело в том, что вот алгоритм Диница,
это вот у нас первый алгоритм, значит, соответственно,
поиска блокирующих потоков.
Но вот возникает вопрос, а можно ли сделать это эффективнее?
Вот. Ну, тут произошла небольшая магия.
Потому что действительно достаточно скоро появился такой ученый
как Карзанов.
Так ладно, нет смысла в акценте, просто Карзанов.
Вот.
И нет, советский абсолютно.
И он подробно всем рассказал, как искать закуп.
Правда, в аналах истории это осталось с трудом.
Почему? Потому что дело в том, что он именно рассказал.
То есть имело место...
Но рассказал при этом достаточно официально.
То есть ситуация была такая, что была какая-то конференция в Советском Союзе.
Значит, где...
На очередной доклад вышел товарищ Карзанов.
И немножко, там, помахав руками,
рассказал, как упихивать блокирующие потоки закуп.
Вот.
Тезисы этих докладов вроде остались,
но вот описания, как он это сделал, равно как и статьи Карзанова,
насколько я понял, нет.
Или, по крайней мере, она мне неизвестна.
Почему это лучше, если у нас ассинточка В на Е?
Нет, ВЕ – это один блокирующий поток.
А суммарный алгоритм Диница – это В квадрат Е.
Вот, он пошаманил, пошаманил, сказал, как делать В квадрат.
В квадрат в смысле В куб.
Но более того, сведения об этом почему-то есть у Торьяна.
Я не знаю, то ли он был на этой конференции каким-то образом.
Нет, ну почему нет. В принципе, возможно.
Нет, как бы да.
Ну, как бы, я думаю, он мог к нам приехать.
То есть, как бы да.
То есть, конечно, забавно, что теория развивалась по обе стороны железного занавеса,
но как бы люди как-то между собой общались, явно.
Вот, и статьи друг друга, видимо, читали активно.
Проталкивали потоки друг к другу.
Нет, проталкивали потоки до другая концепция.
Не футать.
Да, потому что правительство не умело так хорошо конискать банкирующие.
Нет, нет, ребят, нет, нет. Смотрите, нет.
Это не совсем так.
Потому что железный занавес, это не означает, что как бы все, все, что мы знаем, это мы знаем.
И мы миру об этом не сообщаем. Нет.
Правда, как и народ. Вот так нет.
То есть, я думаю, там у продвинутых ученых, как бы, были возможности, собственно, читать международные журналы.
Правда, как и у наших ученых, были возможности опубликоваться так, чтобы, собственно, другие ученые знали,
что же надо демонстрировать, что мы крутые.
Поэтому, как бы, да, там честно скрывать.
скрывать то есть мы что не на уровне типа там но там типа мы умеем и так далее то есть вот более
того там где где-то там в каких-то заметах тарьяна тарьян даже примерно рассказывает значит как там
действительно этот выкуп но сейчас корзанов предлагает пихать но это достаточно но но это
было какое-то что-то сложное муторо поэтому привело это к следующему примерно значит через
не сильно долгое время появилась статья от трех индусов индусов звали значит фамилии этих
индусов молхотра кумар и махишвари вот да индуса 3 да кумар да да да вот пожалуйста да то не так
и писались прям вот как прям так и как как-то как слышится так и пишется да молхотра кумар махишвари
да все прям там там вот да в чем индусов 3 а страниц статья 2 2 правда и да правда обе
страницы а 4 и вот как бы его тут вот вот такие вот две колоночки нету кстати вы легко можете
сами загуглить на самом деле открыть там еще сложного вот а содержательных там всего полстранички
и в этой статье не подробно писали что у нас есть наш алгоритм ищется завокуп но на наш
скромный взгляд он сильно проще да в принципе кстати да это тоже на самом деле тема на самом
деле то есть как бы если какую-то задачу уже решили это не значит что не существует более
простого решения потому что в принципе по-моему чебушова такие прецеденты были потому что у
него но точнее так нет основным конечно человеком как в математике по моему связанным с подобного
рода фишками по мне является товарищ пол эрдыш вот то есть он вот и да то есть у него две
известности во-первых он там то есть количество коллабора там людей с которыми у него совместные
статьи там просто превыше там просто там превышает все разумные пределы ну не разумно просто фишка
в том что он именно вот то есть он вел именно кочевую жизнь он там перемещался из университета
университета в каждом из них он с кем-то что-то делал вот то есть более того математике есть
такая веселая вещь как число эрдыша то есть типа у самого число эрдыша 0 у всех его соавторов
один у соавторов соавторов 2 и так далее ну то есть аналог число рукопожатия такое да вот то
есть число эрдыша там потом вот и так далее вот это замечательная вещь и у него известно то есть
там здесь какие-то теории в математике которые может не он первым доказал но он доказал это
сильно проще ну то есть скажем там по-моему один из них это факт по-моему о том что вот есть такая
теория что для любого n верно что от n до 2 n минус 1 есть простое число что-то такое
да но я не помню насколько я помню было так вот теперь по-моему та теория мы это доказал по
первым едва ли не чебушов вот кто-то в этом роде ну постулат ладно так себе постулат сложно это
предполагать после там аксиомы вот такие вещи но вот но ты доказал как-то чебушов но чебушов
до О leadershiplloießührterte
потом спросили потом пообщались с редакторами журнала и выяснилось что они тоже ничего не
не поняли. Поэтому сказали, а давайте мы опубликуем, вот у нас попроще доказательства есть.
Опубликовали. Но я не могу ничего сказать за первое доказательство, второе доказательство
действительно понятное. Вот так же соответственно. Поэтому вот так и здесь. То есть здесь оказался
алгоритм, но он сильно проще. Но в данном случае он у нас может иметь и практическую ценность,
что бывает, что как бы асимптотика та же, а по константе сильно лучше и пишется проще. Вот и в
общем-то здесь тоже доказательства. Но давайте я кратко скажу, значит, идеи этого, потому что они
там фактически там две страницы, но там где-то часть этого литература, часть там описания того,
что вот там были там великие там, допустим, форт Валкерсон, есть Арема, есть там всякие
адманс-карты, всякие работы. Был вот великий Динец, у него есть блокирующие потоки. Ну вот и был
Корзанов, который что-то сказал, но мы ничего не поняли, там найти не смогли, поэтому вот сказали,
значит, у нас есть более простой алгоритм. И все это там на страницу или чуть больше.
То есть содержательная идея на самом деле умещается на полстраничке. И в общем-то она
оказывается даже не сильно сложной, но тоже такая достаточно поучительная, мы об этом сейчас тоже
будем думать. Значит, какая идея? Идея заключается в том, что, допустим, мы построили слоистую сеть
и хотим пропихнуть какой-то блокирующий поток. А теперь возникает вопрос, а сколько через каждую
вершину вообще может потока проходить? Так сказать, вот притекать через нее вот этих вот машинок
проезжает, сколько вообще может? Да, минимум из этих величин. Это даже официально, давайте это
введем. То есть определение. П плюс от В, пусть у меня будет П плюс от В, это вот сумма по всем
исходящим ребрам С от Е. Допустим, да, где прибираем все ребра, у которых Е точка старта равно В.
Чего? Нет, я тут пропускные способности пишу. Значит, есть П минус или, ну можно даже более
точно назвать, даже не П плюс П минус, а П аут и П ин. Это мы будем, вообще это как бы там авторы это
назвали исходящий потенциал и входящий потенциал. А есть просто потенциал. Значит, П от В это минимум из П аут от В и П ин. Вот такая
приятная вещь. Заметим следующее, что пока у меня идея просто, ну такое, допустим, я буду делать, я буду
иметь в виду сейчас именно слоистую сеть пока. Хотя парадокс в том, что мне по барабану, потому что на самом
деле вот эти величины в процессе любого Форда Фолкерсона не меняются. Потому что, заметьте,
предположим, я через вершину неожиданно пропустил одну единицу потока. Тогда, смотрите, у нас в остатке, казалось бы,
потенциал в остаточной сети стал меньше на единицу входящий. То есть за счет этого ребра, он как бы
потенциал входящий уменьшился на один, а исходящий, наоборот, увеличился на один.
Да, но в остаточной сети у нас пропускные способности. То есть, казалось бы, тут один потенциал уменьшился,
другой увеличился. Заметим, что за счет этого ребра уже наоборот. То есть, как бы, тут вот это ребро как бы
исходящий потенциал уменьшило, именно исходящ Alytein. А входящий увеличилось.
То есть, получается, здесь к исходящему потенциалу минус один, а здесь плюс один. То есть, в сумме
исходящий потенциал не поменялся. И входящий не поменялся. То есть, поэтому в принципе потенциал и вершина
это вещи, у которых они постоянны. То есть, это в принципе такая характеристика сети. Вот,
но это нам чуть позже понадобится. Сейчас пока нас это интересует вот на сколько.
Сейчас мы заметим, что когда мы пихаем поток через слоистую сеть, то вот эта
характеристика на то, сколько воды может протеть через конкретную вершину. Так вот,
что предлагают наши любимые три индуса. Сейчас вы их полюбите точно, если еще не полюбили.
Идея такая. Давайте построили бфс вот эту сеть и посчитали потенциалы за е.
Теперь у меня возникает неожиданная идея. Давайте найдем вершину с минимальным потенциалом,
прям честно найдем. Вот она. Она вот тут в каком-то слое. Вот тут у нас стартовые вершины.
Понятно, да? С минимальным. Так вот, у меня сейчас будет идея такая. Я сейчас хочу обнулить ее
потенциал в слоистой сети. В том плане, что я буду просто жадно пропихнуть через нее воды на вот
ее потенциал. Потому что как только я это сделаю, у нее потенциал ставит равен нулю и мы можем ее выкинуть.
Понимаете, да? А как мы это будем делать жадно? Очень просто. Смотрите, вот допустим у нее потенциал
равен ну я не знаю, п. Тогда идея такая. Давайте-ка посмотрим, какие ребра из нее торчат. И жадно,
вот тут распихаем. Тут у нас допустим f1, f2, f3. Жадно так, чтобы сумма была п. А мы это можем сделать,
правда? Теперь в следующем слое. Вот в эту вершину пришло f1 потока. Но так как у этой
вершины потенциал больше либо равен п, и тем более больше либо равен чем f1, то я могу здесь жадно
распихать вот так вот. Ну что-то такое могу распихать. И здесь тоже жадно распихаю, может даже в те же
вершины. Но в каждую вершину суммарно все равно придет не более чем п, правда? То есть я буду
просто жадно распихивать и кончится это тем, что вся вода течет, течет, течет, течет и придет в t.
А с чего в t? Да, ведь может вам показаться, что этот жадник пойдет мимо t, да? Но что это будет
означать? Это будет означать, что вода аналогично будет идти дальше, дальше, дальше и дальше. Но
фишка такая, что дело в том, что тут есть какой-то последний слой, а у этого последнего слоя тогда
потенциал будет 0. Поэтому заметим, что алгоритм начнет, а мы взяли вершину с минимальным потенциалом.
Да, это очень приятно, потому что это приведет вас к тому, что, обратите внимание, то есть вы начнете
с того, что все лишние вершины будут, все эти слои будут длины, и в этом слое останется только t.
Да, но важный момент, конечно, когда вы удаляете вершину, вы все ребра тоже должны выкинуть и
пересчитать потенциал. Понимаете, да? Ну, потому что вас интересует потенциал именно текущий,
сколько вы еще можете пропихнуть. И тогда вот в этом предположении вы будете вынуждены заключить,
что если вы потенциалы считаете везде там кроме t, то получается, что единственное, куда вода может
деться, это прийти в вершину t.
Я, может, пропустил, вершина с минимальным потенциалом считается, очевидно, без учета s и t.
Без учета s и t. Ну, хотя нет, не совсем так. На самом деле авторы предлагают следующее, то есть это вот такой
потенциал считает, что если v не равно s и t, ну вот, значит, предлагают, что p at это будет p out,
а p at это p in. Ну, или что то же самое, давайте будем считать, что входной потенциал s и выходной
потенциал t бесконечности. Вот, то есть авторы даже вот так предлагают. Ну, как вы уже догадались,
то есть из p мы припихнули такой поток, а как пихнуть теперь из p в s? Ну, просто то же самое,
только по обратным ребрам. Идейно легко, кодится мерзко. Ну, такая копипаста немножко получится.
Либо копипаста, либо вот когда-то у нас было задание, там, действительно, напишите вот это вот,
только без копипасты. И вот это было больно. Вот, но идейно очень просто. Ну, понятно,
что очевидным образом по ребрам входящим вы там до s дойдете. Понятно, да? Но более того заметим,
за какое время вы в принципе вот эту вот жадность распихаете? Квадрат? Нет, вот из одной вершины,
но не квадрат, но на самом деле за e, потому что из каждой вершины вы это сделаете жадно. Вот,
но при этом обратите внимание, что тут как в динице вы будете там какие-то ребра насыщать и
выкидывать. Можете опять же тоже хранить, где вы остановились, жадники, правда? Нет, алгоритм такой,
на каждом шаге у нас есть потенциалы, какие-то вершины, которые еще не убились, и потенциалы
их. Вы честно за v находите вершину с минимальным потенциалом и за v плюс количество удаленных
ребер делаете вот этот пропир, чтобы обнулить потенциал. Когда они насытились? Ну, тут просто
видите, из каждой вершины вы несколько ребер насытили, кроме может быть последнего, но кого
вы насытили вы удаляете тем же способом с двигом итератора. Каждый раз, когда вы пихаете,
впускаете воду по какому-то ребру, вы как бы уменьшаете там один из потенциалов здесь и здесь.
Нет, мы считаем потенциал по остаточной пропускной способности, при этом учитываем
только ребра из слоистой сети. То есть вот обратные ребра мы здесь не считаем.
Получается, один такой пропир с удалением такой вершины обнуление потенциала вы делаете вот за столько.
Нет, в остаточной сети этого не произойдет.
В остаточной сети мы рассматриваем только такие ребра, то есть мы не будем пихать воду обратно.
Да, но в веста мы пихаем по ребрам, которые сюда входят, то есть мы рассматриваем только ребра,
которые идут из этой сети. Вот, да, то есть здесь с этим надо быть аккуратнее, но тоже, то есть вам
придется ввести видимо не только список смежности исходящих ребер, но и список смежности входящих
ребер. Ну, то есть, понятно, чисто технический вопрос, там отдельные итераторы, но как бы это делается.
Ну вот, то есть одна итерация пропиха через вот какую-то заднюю вершину работает за вот,
получается, в плюс е количество удаленных ребер. Ну, количество не удаленных ребер тут как раз ве,
потому что из каждой вершины по одному. Ну вот, то есть если суммировать по это по всем
удалениям п, удаление нот, удаление, так сказать, ве, то получится что такое, то есть получится
суммарно, значит, что-то типа от в квадрат плюс, значит, сумма всех удаленных ребер, а это в квадрат
плюс е. Ну, если нет, ну, по модулю кратных ребер каких-то. Нет, понятно, да, вы там, в итоге официальная
асимптотика алгоритма получается о от в в кубе плюс ве. Ладно, вот эту штуку можно убить, если вы
убьете кратные ребра заранее. За от ве плюс е вы это сделаете. Да, именно, конечно. Ну, я уже говорил,
стандартный алгоритм, то есть стандартная задачка это как убрать кратные ребра за ве плюс е, а не за ве
квадрат. Нет, ну, ладно, сейчас не заморачивайтесь, значит, потом в случае еще придумаете, это не
проблема. То есть там, как говорится, если сделать, сделать просто правильную, правильную по разрядной
сортировку, собственно, никаких проблем не будет. А без хэшей? Нет, ну, на самом деле зачем, просто
правильная по разрядной сортировка решит вопрос, не проблема. Хотя нет, ну, формально, конечно, это
будет работать за ве куб плюс все равно е, потому что формально е может быть больше, чем ве куб. Ну,
теоретически да. Ну, это понятно, что по бреду, конечно, да. Да, то есть, ну, без вот этого вы
никогда не обойдетесь. Потому что считать вам придется граф. Потому что, значит, смотрите, нет,
есть несколько причин. Ну, во-первых, он относительно градусно пишется. Ну, не так, ну, понятно,
с копипастой. Да, не очень сложно, но, во-первых, ну, просто если у вас задача записать алгоритм
за ве куб, то есть более просто пишущийся алгоритм, нас, основанные на пушере лейбле, мы это изучим. Там
прям очень просто пишется, прям предельно тупо. Ну, видимо, уже в следующий раз мы с вами это очень
подробно обсудим. В смысле, почему он работает? Ну, потому, нет, а в чем проблема? Потому что мы,
ну, потому что каждый, если мы вершину выкинули, значит, что она уже заблокирована. Через нее нельзя
опустить путь в слоистой сети. Поэтому, когда мы делаем этого раз, мы фактически выкинули все
вершины. Это значит, что все вершины заблокированы, значит, ура, мы нашли блокирующий папа. Так что,
вот, так что ладно, если надо было формально обсудить, то мы вот, обсудили это вот таким вот
10-секундным способом. Вот, так что да, вот, то есть, есть вот такой, да, он, в принципе, красивый. А,
во-вторых, на самом деле, и сам Динец в большинстве случаев работает гораздо быстрее, чем ЗВ квадрат Е.
Вот, но правда, для того, чтобы это изучить, нам, конечно, но правда, чаще всего, конечно,
это происходит именно из-за того, что у вас сети целочисленные. Так, поэтому, если по этому алгоритму
вопросов нету, значит, смотрите, тут важно подчеркнуть. Оставшееся время сегодня мы будем,
мы посвятим именно внимание целочисленным сетям. Нет, Динец работает на любых сетях. Нет,
смотрите, до сего момента мы вообще не пользовались тем, что там пропускные способности целочисленные.
Они, то есть, пока они тут могли быть любыми, алгоритм работает. То есть, любой и Эдман Скарп и это.
А вот сейчас у нас будет, внимание, сейчас будет отдельный подвид алгоритмов, который будет,
ну, не алгоритм, даже в нашем случае, ну, хотя и алгоритмов тоже. Ну, вот, то есть, которые будут
работать именно на целочисленных сетях. То есть, можно сказать, такая у нас подглава такая, то есть,
будет такая голова, целочисленные сети. А в ней прям есть, ну, вот, ну, целочисленные сети, да, то есть,
ну, как бы, там, пока, например, на Олимпиадной практике в девяносто, там, в девяносто девяти
процентах случаев у вас пропускные способности будут целочисленные. Ну, а ставим один процент
это еще типа hard life. Вот. Хотя в hard life сети целочисленные были. А нет, не целочисленные, да, там, да, там дроби были, да.
Что? Что не так? Вот. Ну, на самом деле, да, ну, в целочисленных сетях, да, да, сейчас будем предполагать,
что у нас С от Е это целое число. Но начнем мы даже с разминочки. Потому что у целочисленных сетей есть еще один
такой экзотический вид, который тоже периодически встречается. Это, конечно же, единичные сети. Это когда
пропускная способность любого ребра один. Такое тоже встречается. Вот. Начнем мы с разминочки. За
За какой симптотику работают наши алгоритмы, если у нас единичная сеть?
Ну, на самом деле, что-что? Ну, как сказать, если нет кратных, ну, на самом деле, конечно, любой
работает за как бы ответ на Е. Хотя ладно, это и в целочисленной сети верно. Вот. Хотя можно попытаться,
наверное, но вот, но если мы будем говорить о 1, то на самом деле у нас, конечно, можно получить симптотику
гораздо лучше, чем В квадрат Е. Почему? Ну, не факт. Хотя нет, ну, за В Е, конечно. Ну, там зависит от Е,
конечно, там не факт. Если считать, что БФС работает за Е, то Эдманскарк работает за БЕ на единичных сетах.
Сейчас, БФС. У нас еще нет кратных ребер. Так, БФС. Ну, да. Ну, если нет кратных, ну... Потому что у нас не больше, чем В ребер в ходе стока.
Ну, в принципе, да. А, ну, Эдманскарк, ну, это тогда можно сказать, что Эдманскарк просто за сток работает. Да, но если нет кратных ребер, то, конечно, В. Может быть,
там еще теоретически можно запилить, но там, к сожалению, вот, если кратные ребра есть, то у нас там начинается вот такая вот гадость.
Да, но это В квадрат, он же В Е, он же Эд. Но это неважно. Важно для нас сейчас другое. Заметим, что, значит, это у нас Эдманскарк.
Вот. Если рассмотреть Диница, то здесь смотрите, какая фишка. Начнем с того, что блокирующий поток в единичной сети ищется вот просто методом Диница.
Не за В Е, а просто за Е. Почему так? Да просто потому, что каждый раз, когда вы нашли поток, то есть, нашли путь, вы убили не одно ребро, а все.
Понимаете, да? Да, вот, что приятно в единичной сети. То есть, в этот раз вы убили просто все.
Вот. И это означает, что фактически у вас одна фаза Диница работает фактически за сумму заудаляемые ребра.
То есть, получается, что она работает за ОА на количество там, итерации КБП умножить на Е.
Ну, в принципе, в Е это уже неплохая симпторика, да? Да, но я там называю нот. Но я могу круче.
Да. Ну, почти всегда это будет круче. Кроме экзотических случаев.
Значит, теорияма такая вот. Сейчас у меня будет утверждение, идея доказательства, которая будет хедлайнером всего оставшегося занятия.
Значит, в единичной сети количество итераций КБП не превосходит два корня Е.
Доказательства. Значит, смотрите внимательно. Значит, идея. Доказательства такое.
Сделаем. Ну, давайте не будем заморачиваться. Хотя нет, попробуем обобщить. Сделаем каэтерации Диница.
Хотя, ладно, просто КБП. Хотя, заметим, что это утверждение никак не зависит от того, Диницем вы ищете блокирующий поток или как-то еще.
Да, даже так. То есть, Диниц тут вообще ни при чем. Главное, причем он только на тему блокирующих поток.
Итак, давайте введем константу величину К и скажем, что после К итерации КБП. Концепция блокирующих поток.
Значит, сделаем каэтерации. У нас останется какая-то остаточная сеть, правда?
И заметим следующее, что в остаточной сети есть какой-то максимальный поток, правда?
Но заметим, что каждая итерация КБП хотя бы одну единицу потока припихнет, правда?
Поэтому, в принципе, мы оставшееся количество итерации можем оценить как максимальный поток в этой остаточной сети, правда?
И тогда итерацией у нас будет К плюс максимальный поток от вот этой вот, так сказать, ЖК, вот этой вот остаточной сети.
То есть, Ж с индексом Ф с индексом К. Вот так.
А теперь давайте подумаем, что мы знаем про вот эту остаточную сеть?
Да, мы знаем, что в ней, значит, в ЖФ, ну, во-первых, значит, все пропорционные способности равны один, естественно.
А во-вторых, что мы еще знаем? А мы кое-что еще знаем.
Да, СТ, даже там, больше либо равно К.
Да, даже давайте, давайте больше скажем.
Но смотрите, давайте найдем в этой сети максимальный поток.
Этот максимальный поток мы декомпозируем на пути.
Эти пути будут реберно непересекающиеся, правда?
Да, и каждой длины хотя бы К, даже хотя бы К плюс один.
Они могут, конечно, вершина пересекаться как угодно.
Да, они могут быть даже неодинаковые длины, что интересно.
Вот так, да?
Вот как-то так это может быть, как угодно, да?
Но сами эти, но вот, но каждый из этих путей содержит не более, чем каждый.
Да ЖК плюс один, да?
И это означает, но так как у нас реберто всего Е,
то тогда получается, что вот это вот МАКСФ от ЖФК,
оно получается не превосходит даже Е поделить на К плюс один.
То есть получается, это не превосходит К плюс Е делить на К плюс один.
Ну а теперь остается только подставить какое-нибудь правильное К.
То есть давайте меньше либо равно, ну вот,
ну вот, ну соответственно при, ну вот,
ну то есть если мы подставляем К равно корень из Е,
ну очевидно, что это примерно максимум, да?
Ну вот, то получится, что это количество итераций не превосходит корень из Е
плюс Е поделить на корень из Е плюс один.
Два корень из Е.
Ну да.
Ну не при любом К меньше либо равно, конечно.
То есть количество итераций получается суммарное,
всегда меньше либо равно, вот эта причина для любого К.
Я выбираю минимум по К, беру примерно,
ну даже может это не самый минимум,
может корень из Е плюс один надо брать, я не знаю.
Да, сомнительно, но вот.
Ну корень из Е не точно в конце концов,
надо куда-то округлять, может быть вверх, не важно.
Но я говорю, если примерно возьму корень из Е,
то есть не буду я сейчас заморачиваться об округлении,
то я получаю, что получается так.
Вот.
И получается тирему доказать.
То есть вывод такой,
что я здесь могу удинется заявить на самом деле асимптотику
даже вот так вот.
О от минимум из, формально говоря, В из корень из Е на Е.
Ну вдруг там корень из Е больше, чем В, я не знаю, да?
То есть формально, конечно, в адекватных графах
это, конечно, просто Е корней из Е.
Вот.
Кстати, я вас должен поздравить,
мы уже научились искать просочетания за Е корней из Е.
Но конкретно в просочетании все еще круче.
Да что такое?
Кажется, Е корней.
Итак, идем дальше.
Итак, вернемся, как мы ищем просочетания?
В просочетании мы тоже ищем в единичной сети,
но в единичной сети есть более крутая ситуация.
Заметим, что в единичной сети есть еще маленькое приятное свойство.
Мы можем заметить, что
то есть дело в том, что
когда мы исходную сеть делаем,
мы заметим, что в каждый момент времени
в каждую вершину либо входит ровно одно ребро,
либо выходит ровно одно ребро.
Согласны?
В самом начале это точно верно.
Но заметим, что и в каждый момент времени
это тоже будет верно.
Потому что когда мы через вершину пропустим
какой-то поток величины 1,
то у нас, допустим,
вот это ребро убьется,
JB, что место regthere и главное появится вот это.
И вершину в остаточной сети все равно будет входить ровно одно ребро.
Но это означает Das板,
что в каждую вершину
в остаточной сети после K
у вас все равно
в каждую вершину
будет либо входить ровно одно ребро,
либо исходить ровно одно ребро.
А означает это, что у вас вот эти вот пути
когда мы будем в этом же рассуждении,
не только реберно не пересекаться, но и вершинно не пересекаться. Понимаете? Поэтому мы можем
сказать, что в парасочетании, то есть если мы будем искать парасочетание единицам, то оно будет
работать не за Е корней из Е, а за О от Е корней из В. В данном случае мы просто доказали,
что фаз единица будет О от корней из В. Доказать это то же самое, просто тут будет как бы путей будет
не более выделить на этого, поэтому там как бы два корней из В будет, поэтому вот, поэтому никаких
минимумов, просто Е корней из В. Да, это кстати называется алгоритм Хобкровта-Карпа. Да, буквально,
ищем про сочетание единицам. Не, ну видимо достижение Хобкровта-Карпа заключается в том,
что они просто доказали, что единица оказывается, ну то есть возможно они, может они были первые,
кто построил такую сеть. Вот, ну вот и во-первых, во-вторых, они доказали, что это Е корней из В. Нет,
крутая симпточка. Кстати, я что-то слету вам не скажу, а существует ли более крутой алгоритм,
который ищет в додольном графе про сочетание. Ну это уже, да, на тестерке, ну, ну знаете,
это нет, мы помним эти стандартные шутки, да, как это, да, мы сегодня будем учиться программировать,
вот тебе задача найти Гамильтонов цикл в графе. А да, тут перебрать, тут перебрать, тут перебрать,
закуп могу. А если подумать, а ну тут отсечь, отсечь, а точно, сэн квадрат можно, ура! А ну это
рассказывал, да? А, ну всё, вот, не будем повторяться тогда. Да, на тестерчуре вообще линейно работать будет,
да, мы помним, так. Ага, не, в нашем случае лучше, точнее, там это называется лекция такая-то,
минута такая-то. Ладно, а теперь смотрите, значит, вот это, сейчас мы эту идею обобщим на более,
на более крутую ситуацию. Представим, ну потому что, смотрите, сейчас я, значит, что-то ещё можно
проделать. Значит, теперь, значит, что тут можно ещё проделать? Сейчас вот возьмём ту же самую идею,
но теперь представим, что сеть уже не единичная, а просто целочисленная. Тогда мы сделаем вот что,
мы введём понятие потенциал сети, то есть просто определение. Значит, p от g, будем это называть
потенциал сети, это будет тупо сумма вот тех потенциалов, которые мы тогда сказали, по всем
вершинам v. Ну, может быть, даже давайте и сток, и сток выкинем. Да, могли бы и не выкидывать, но давайте выкинем.
Вот, да, можно было и там по всем. Так вот, первая теория Бакарзанова.
В целочисленной сети
кбп выполнит не более чем два корня, я её так сформулирую, хотя там ошка была, корень из p иterации.
Вот, во многих задачах, кстати, это может вам сильно намекнуть, почему динец работает быстро,
потому что в олимпиадах программирования обычно принято, что есть задача на поток,
значит, напишите динец, а он точно зайдёт, потому что вряд ли от вас потребует что-то более крутое.
В большинстве случаев, на самом деле, уже на уровне этой теории, на самом деле, это окажется легко
доказать, потому что вы просто посчитаете потенциал и выясните, что там итераций немного, правда,
каждая итерация, конечно, будет работать за непонятно сколько, хотя за понятно сколько она будет
работать за суммарную пропускную способность ребер, кстати. Ну, потому что вы можете себе представить,
что ребро пропускной способности 57, это таких 57 единичных ребер, правда? Можете такое представить, да?
Ну, пока с масштабированием разберёмся позже, а мы разберёмся. Но пока просто факт, как бы вы не искали,
то есть как бы вы не искали блокирующий поток просто любыми способами, а итерация будет не более чем сток.
Почему? А, ну, во-первых, начнём с маленькой леммы.
П, потенциал. Во-первых, это F, а во-вторых, GF, это у нас стандартное обозначение остаточной сети.
Вот так вот, я утверждаю, что какой бы я поток вообще не пустил, а в остаточной сети потенциал будет
ровно такой же. Да, мы это уже даже обсудили, да. Так поэтому, как бы, поэтому в случае чего оставим в качестве упражнения.
Хотя, да, в качестве упражнения, да, там это найдите где-то там сколько-то там минут назад, собственно, как вы это обсудили.
Значит, и это очень приятно. Потому что, значит, логика та же теперь. Потому что доказательства просто абсолютно такой же.
Смотрите, что произойдёт после K-итерации? Что произойдёт после K-итерации?
Как мы уже, ну вот, то есть пути на этот раз уже будут пересекаться, в том числе и по ребрам, да.
То есть вполне себе там, пожалуйста, как угодно и по вершинам, и по ребрам, там как-нибудь вот так, вот там, ну, всё что угодно, да.
Но теперь заметим следующее. Рассмотрим вот какую-нибудь вот вершинку, через которую у нас тут какие-то пути проходят, допустим.
Вот. Смотрите, вот тут так вот, как бы, смотрите, теоретически я мог бы тут какой-то формализм вести, но мне как всегда не хочется.
Хочется, чтобы вы это увидели. Что вы увидели?
Если я эту вершину, ich... Смотрите.
Каждую, вот смотрите, давайте я могу этот максимальный поток в остаточной сети, после K-итерации, декомпозировать на единичные пути, да.
Ну естественно, там максимальный поток целочисленный будет, да.
Ну и более того, то не сложно доказать теорему, существуя в целочисленной сети, существует целочисленный максимальный поток, да.
Так вот, давайте я его декомпозирую на единичные пути.
Смотрите, заметим, что через каждую вершину таких путей будет проходить не более, чем ее потенциал, правда?
Ну, идейно, в общем-то, потенциал это он и есть, да?
Мы будем это мыслить в терминах, что каждый единичный путь скушал одну единицу потенциала в вершине, правда?
Ну, будем так просто это переформулировать, то же самое, да?
Потому что, как вы уже догадались, идея будет заключаться в том, что мне жутко интересно.
А сколько вершин, сколько единиц потенциала каждый единица потока скушала в целом?
Хотя бы длину.
Хотя бы длину. А длина?
Хотя бы k плюс один.
Но не совсем. Длина k плюс один, но промежуточных вершин тогда получается k.
Ну, хотя бы k, правда?
Потому что расстояние от s до t у любого пути теперь, по которому может идти поток в остаточной сети, она больше, чем k.
Но почему не ровно?
Потому что изначально-то она была один, хотя бы.
А что еще каждый путь съедает?
У каждой вершины, по которому этот путь проходит, этот путь съедает единицу потенциала.
Почему у нас же путь не меняет потенциал?
Мы от этих пришли.
Мы мыслим так.
Но будем мыслить так. У каждой вершины есть потенциал, да?
Когда мы рассматриваем, то есть мы знаем, что у каждой вершины количество путей, проходящих через нее, не превосходит ее потенциала.
Поэтому очень удобно мыслить в терминах, что каждый такой путь кушает потенциал.
Нет, я могу тут какие-то суммы подписать.
Нет, пожалуйста, если это непонятно, пожалуйста, я могу расписаться формализмом.
Но просто если вы поймете вот это, тут становится понятно.
В принципе, нет, вы можете там найти предыдущего поколения или может быть даже просто в Гугле, ну или просто попросить меня, я могу прислать там просто презентации.
Ну или просто зайти на Emax и почитать.
Там будет лемма, максимальный поток, там после L это рации не превосходит.
Чего он там не превосходит?
А чего он там, кстати, получается, не превосходит?
P делить на L плюс 1 или что-то в этом роде.
То есть да, заметим, что это единиц потока.
То есть получается, что их осталось не более, чем потенциал поделить на L.
Ну а то потенциал, сумма по всем.
Из этой суммы каждая единица потока жрет хотя бы L, то есть хотя бы K.
То есть получается у нас получается не более, чем K плюс P от GFK делить на K.
Но, собственно, это то же самое, что обычный потенциал.
Подставляем K равно корень из P, радуемся жизни.
Основная церема, на самом деле, вот такая, обычно пользоваться нужно именно ей.
На самом деле, да.
Вот эти вот штуки, это, конечно, просто ее подвиды.
Заметим, что потенциал, в принципе, очевидно, не превосходит суммы пропускной способности всех ребер.
Вот.
Но так видим, что потенциал, кстати, сети в просочетании равен TUPOV.
Понятно, да.
Поэтому там O от Е корней из V возникает сразу.
Вот.
А в общем случае, на самом деле, можно заметить, что в целочисленной сети,
если все ребра не превосходят С по пропускной способности,
то можно получить на единица оценку как ZC на корень из P.
Вот так.
Да.
Ну, фаз O от корней из P, а каждая фаза делается за CE.
Ну, потому что если вы вообразите себе, что каждое ребро это просто C единичный,
не более чем C единичных ребер, то вы эту фазу сделаете за CE.
Вот.
Но можно сделать еще более нетривиальный вывод из формулировки этой церемы.
Вывод называется.
Ну, раз есть первая церема, как заново, то, наверное, есть хотя бы вторая.
Нет, их всего две.
Нет.
Ну, вторая идея, но то же самое, да.
Но тут просто оценим немножко по-другому.
Ладно, ну вот, то есть вторая церема, как заново.
Значит, пусть Z целочисленная сеть,
численная сеть,
бескратных ребер, это все, что мы делаем,
это все, что мы делаем, это все, что мы делаем,
бескратных ребер, это важно.
Причем,
для любого E,
C от E не происходит какой-нибудь мистической константы C.
Та-дам!
Тогда количество итерации KBP
не превосходит два на
К сожалению, не на столько.
Так, знаете, честно говоря, я иногда с трудом помню, что там дальше,
но я помню доказательства.
Я помню, там какой-то там корень, по-моему, даже кубический там, что-то такое.
Вот.
Поэтому в этот раз я все-таки начну с доказательства.
Пуша, как я буду мыслить?
Ну, начало доказательства,
нет, ну,
нет, ну, смотрите, доказательства такое.
Ну, доказательства, очевидно, у вас будет
K плюс, значит, максимальный поток после K итерации, правда?
А как я буду оценивать максимальный поток после этой итерации?
А оценивать я его буду так.
Смотрите, я запущу BFS.
Вот у меня ноль, вот у меня там сеть,
там первая, вот у меня, прям, честно, вот эти вот слои.
И вот у меня T, и он находится в каком-то слое L.
И этот L у меня больше, чем K, если что.
Так вот, вот эти все множества я обзову.
Вот это множество я обзову V0,
это я обзову V1, это я обзову V2, это я обзову V3,
это я обзову V4 и так далее.
Так вот.
Ну, как мне известно,
ну, как мне, нам всем, я надеюсь,
величина максимального потока не превосходит,
равна величине минимального разреза.
А точнее не превосходит величины какого-то разреза, любого.
Поэтому давайте я оценю поток через,
ну, например, вот такой разрез.
Спрашивается, как можно,
как оценить пропускную способность такого разреза?
N на C.
Нет, можно поточнее.
Во-первых, C на модуль V3, на модуль V4.
Нет, ну, да.
Вот.
Но теперь заметим, что я могу взять еще вот такой разрез.
Можно оценить какой-то разрез, как C е делить на L.
C е делить на L?
Свои ребра где?
Ну, в принципе, да.
Да, заметим следующее, что каждый ребро у нас, у нас всего E-рёбер.
Ладно, два E-рёбер, ладно.
У нас, обратно, ребра не входят.
Да, да, да, согласен.
Да, да, да, да, согласен.
Ну, да, да, у нас, да.
У нас есть E-рёбер, которые могут входить в один из этих разрезов.
Каждый ходит не более чем в один.
Хотя нет.
Ну, можно оценить через C е, хотя тут рекомендуют через E квадрат.
Ну ладно, давайте через C е попробуем.
Сейчас, ладно, давайте.
Давайте возьмём множество, точность множества, которое не больше, чем…
Нет, ну ладно, можно оценить через E делить на K, но это как бы вам даст нот.
Нет, ну смотрите, мы можем оценить, что размер разреза не более чем…
Ну там минимальный из них разрез не более чем C е делить на K, это да.
Почему? Потому что у нас тут всего K, даже капли с один.
Но тогда это нам даст, что тут C, сколько там, C е делить на K плюс один.
И тогда здесь, значит, и что у нас тогда получится?
Корень из C е, но потенциал у нас и так не происходит в C е, поэтому ничего нового.
Ну, перемножек не надо, а надо вместо этого следующее.
Значит, смотрите, сейчас будет…
Ну просто нет, тут смысл в том, что обоценивать не через E, а чисто через C е и V.
Ну, значит, хотя да, в худшем случае тут корень из C е, но не совсем так.
Значит, смотрите, тут предлагается аккуратненько.
Потому что как действительно это оценить? Оценить получается так.
Хотя нет, в общем-то да, дальше на самом деле говорится так.
Да, можно оценивать корень из C е, но хочется получить тут красивую оценку.
Ладно, дальше делается так. Заметим, что так, как кратных ребер нет, а это важно,
то получается, что E суммарно не превосходит V квадрат.
Тогда получается, что E можно…
То есть, здесь тогда оценка получается K плюс C V квадрат делить на K плюс один.
K плюс один.
Так, нет, это плохая оценка.
Ну, V как-нибудь из C это неинтересно.
Нет, ладно, у меня будет лучше.
Нет, просто можно еще лучше сделать.
Смотрите, давайте сейчас мы просто немножко тут попишем алгебры.
Дело в том, что нас интересует, что нас интересует.
То есть, нас интересует C умножить на минимум из модуль 0 V1, модуль V1 на V2 и так далее.
Модуль там V, сколько там, ладно, пусть будет L минус 1, модуль VL.
Да, это не происходит C делить на L.
В общем, я просто беру пока среднее арифметическое.
Ну, в принципе, адекватная такая оценка, на самом деле, учитывая, что там тесты можно подогнать так, чтобы там действительно все они были плюс-минус равны.
Вот.
А, вот, нет.
Нет, давайте так, ладно, давайте C я напишу тут, а тут я напишу делить на L.
Так, теперь возникает вопрос.
Когда вот это вот, то есть, тогда что у нас получается?
У нас есть какие-то величины, сумма которых равна V, ладно, не более, чем V.
И нам теперь жутко интересно, когда это среднее арифметическое становится, там становится, ну, то есть, при каких V оно вообще максимально возможно?
На минимум.
На минимум.
Нет.
Сейчас нет.
Если у тебя есть нерадность, всегда выбираешь минимум.
Вот.
Ну, вот тогда, вот такой вот вопрос возникает.
Вот.
Ну, вот, как вот эту сумму?
Ну-ка, давайте-ка.
Чего, чего обожжем это?
Ну, это похоже, это похоже на 20 градусов.
Ну, и кажется, что надо просто не выгендриваться и завязать это просто.
Да, вот есть, ну, вот.
То есть, почему тогда, ну, вот.
Нет, ну, действительно есть подозрение, что если мы уж, то есть, как бы у нас есть L плюс, там какие-то числа мы хотим тут распределить.
И так, чтобы там сумма этого была как можно больше.
Сумма этого как можно больше, когда они...
Возрастают, как будто.
Чего объяснять там уже?
Тракторный раз ты получишь ценку C в b квадрате или очень классно.
Ага.
Так, как?
Как?
Как, может, он снирается и получил такую ценку?
Ты говоришь, что у тебя 2 и 1 совсем.
У нас есть V.
Первые множители с V0, первые множители с V1.
И вторые множители с 1, 2 по V.
Давай с 1, 2.
Поставим.
Это правда или нет?
А, можно дать половину.
Ну, тут условно.
Не, не воято.
А, ничего не получилось.
Почему?
Потому что, кстати, два числа.
1 и V.
Не, что вы сейчас не садитесь?
Мы можем все поставить V, L-1.
Так, мы можем поставить V0 примерно в половину V, V1 тоже примерно в половину V.
И уже поиграть.
Сейчас все проверяем?
Какой еще раз-то?
Если мы возьмем V0 примерно в половину V, V умножится на какой-то констант.
И V1 тоже в профессиональном V.
То есть, какую-то часть.
Допустим, четверть четверть.
Ну, может.
Нам не очень хотелось переходить к этому.
Последний переход, кажется, уже заранее.
Да, нет.
Почему?
Ну, потому что сейчас Рома прав.
Можно выбрать такой тест, на котором это уже Cb2d9L.
То есть, мы не улучшили нашу оценку.
Нет, Cb2d9L.
Как вы выберете, что именно в эква...
V1 равно V2 на 4, а все остальное какое-нибудь.
И все.
В единицы, да.
Ну, хорошо.
Ладно, сделаем аккуратнее.
Хотя странно тут.
Ладно, смотрите.
Тогда мы обнаглеем вот как.
Вот так.
Ну, в принципе, я могу сказать даже вот как.
Это равно C поделить там.
Нет, хотя нет, я оставлю так.
Это C из вот так вот.
Минимума вот этого вот всего.
Плюс модуль V1 пополам.
Модуль V1 плюс модуль V2 пополам.
И так далее.
Модуль VL.
Плюс модуль VL пополам.
И все это в квадрате.
Вот я буду вот этот минимум искать.
Вот.
Нам известно, что сумма этих элементов равняется не больше.
Да, это меньше либо равно как C.
И тут у нас получается среднее арифметическое.
То есть типа 1 на L.
Сумма.
Значит, по всем.
Значит, там V и минус 1.
Плюс модуль V и так далее.
Все это пополам.
И равно, допустим, 1 на L.
И все это в квадрате.
Но теперь приятно, что эта сумма не превосходит модуль V.
То есть не.
То есть не превосходит модуль V в квадрате
Вот ради чего мы все это делали.
Так, да, C забыл.
Делали мы для того, чтобы у меня был L квадрат здесь.
То есть получается, что здесь я пишу уже не CE делить на K плюс 1,
а CV квадрат делить на K плюс 1.
Так, только не на K плюс 1, а на K квадрат.
И тогда, ну там очевидно, да, это возрастает, это убывает, приравниваем.
И мистическая теорема получается, что здесь корень кубический из CV квадрата.
Да, вот так теорема формулируется.
Так.
А это означает, что надо кратные ребра сжимать?
Нет.
Проблема в том, что да, у тебя, да, вот эта цешка, к сожалению, увеличится.
А где мы пойдем сейчас?
Да, вот именно, да.
В чем смысл кратных ребра сжимать?
Ну мало ли. Было у вас между городами две дороги.
Называется хайвей и обычная.
Хайвей на пять полос и проселочная на одну.
Нет, минкост это другая задача.
А следует на практике кратные ребра сжимать?
Потому что, конечно, что-то все увеличится, тогда оценка будет, возможно, лучше.
Нет.
Когда вы сожмете кратные ребра, у вас как бы вот это вот с увеличится.
Нет.
То есть на практике это называется общая.
Если у вас, вы знаете, что между любыми двумя решениями общая профессиональная способность не более, чем с, то применять можно.
Я не знаю, конечно, есть ли там примеры.
Это просто красивая оценка для общего случая.
Чаще всего, конечно, я думаю, оценка потенциалом может оказаться точнее.
Впрочем, черт его знает.
Хотя в некоторых случаях, наверное...
Нет, если у вас потенциал равен...
Там потенциал равен... Чему он может быть равен?
Если у каждой вершины торчит по В, там по В ребер профессиональной способности С, то потенциал равен СВ, в смысле СВ квадрат.
Но правда, если потенциал СВ квадрат, то там будет корень обычный, а тут корень кубический.
Поэтому в некоторых случаях эта оценка все-таки лучше.
Правда, что все эти аремы нельзя подружить со случаем, когда мы проводим просто ребры бесконечной профессиональной сходности?
Ну...
Нет, конкретно...
Нет, вторая серия мы вылетим с трубу, а вот с первой как повезет.
С первой как повезет.
Нет, правда, фишка в том, что если ты добавил 2 плюс бесконечности вершины, то первое, что ты можешь сделать в потоке, через эти бесконечности пропустить поток.
Хотя оно там конкретно...
Ну, может быть, сломать, но сломать, да, потому что проведя одно ребро, один из потенциалов ты убил.
То есть, я правил бесконечности.
Так, интересно, выгонит ли нас?
Да я не знаю, ну просто нет, смотрите.
Так, ну в прочем ладно, давай я...
Нет, просто так жалко от этого уходить.
Просто, нет, смотрите, просто в идеале было бы так, просто если бы сейчас потратили, там, можем потратить не более чем 45 минут.
И в следующий раз тогда так жестно перейти, так жестно уже уйти от случаев себя.
Что идет дальше? Дальше идет масштабирование.
Потому что есть масштабирование просто, есть масштабирование 1.
И хочется, чтобы, ну вот, в общем, само все масштабирование в общем-то там как бы доказать просто.
Вот.
Но выгонит ли нас?
Нет.
Все?
Все, все, все, вы уже умерли, да?
Так, ну это да, ну хотела, ну вот.
Ну хорошо, с 9 утра, да.
А, ну да, сегодня мы лекцию даже без задержки начали, да, полка.
Так, ну ладненько.
Тогда в следующий раз, значит, тогда надо будет обсудить масштабирование.
Даже Диница с масштабированием.
Нет, в принципе, да, потому что в принципе, конечно, из Диница вы уже можете понять, как, кстати, с помощью линката придумать алгоритм ЗВЕЛОГВ.
А.
А.
Да.
А.
А, сейчас.
Нет, можно, можно.
Ты хочешь на пути что-то понимать?
Да.
А, такая связь.
Ну, блин.
Ну да, там и да.
Да, то есть давайте до каждой вершины поставим ребро, на которое сейчас смотрит итератор, да.
Заметим, что эти ребра, по идее, они образуют такое подвешенное дерево с корнем в Т.
Ну ладно, или подвешенное дерево что-нибудь там с корнем в ауте.
И надо тогда просто брать вот этот путь и к нему.
Мы насыщаем ребро и приподвешиваем.
Ну типа да.
Переподвешивание, да, это делается фактически, да, в линкате вот так вот, да.
Вот, то есть получается, да.
Ну единственное, что у вас, конечно, отложенная операция вида «пропихни поток через ребро», это да.
Да, пишется не очень приятно, но явно пишется, да.
То есть как бы вы сначала вычитаете в дереве, а потом, когда у вас отложенная операция, вы уже там делаете реальное проталкивание в этом, да.
Ну не, ну линка, понятно.
Ну типа да.
Но в итоге у вас получается алгоритм, так как вы это делаете, как бы таких проталкиваний вы делаете за «е», да.
Ну удали вот эти лишние ребра, кстати.
То есть получается у вас есть симпотика там «в» и «лог в».
Вот в принципе неплохая симпотика.
Ну не скажу.
Ну не скажу.
Ну не скажу.
Ну не скажу.
Ну не скажу.
Ну не скажу.
Нет, ну потому что у вас будет «ве лог с».
Я правда так и не помню все время, что мы будем делать.
Но алгоритм нет.
Вот этот алгоритм устроен очень просто.
Нет, там идея такая, просто мы будем блокирующий поток искать по принципу, сначала будем блокировать большие пути, потом в два раза меньше, потом еще в два раза меньше и так далее.
Да, и мы неожиданно докажем, что это делается за быстро.
Вот.
Что?
Не знаю.
Какой?
Нет, для этого…
Нет, ну как сказать, что будет…
Честно скажем, что будет в дивизионе, а вообще даже не совсем от меня зависит.
Вот.
А кто будет в дивизионе?
Хотя, ой, а кто его будет делать-то?
А, стоп, я же…
А, ну стоп, я же буду подбирать контесты, Господи, да-да-да.
Вот.
Вот.
Нет, ну в смысле нет, у меня есть какой-то архив хороших контестов, так что как бы это не проблема.
Вот.
Так что в этом смысле не волнуйтесь, нет, какие-то даже наметки есть, естественно, да.
Вот.
Так что, соответственно.
Вот.
Поэтому, да, это ВЛОКС, но откуда он берется, нам придется и масштабирование в целом изучить.
Потому что нам же просто надо, чтобы масштабирование вообще по идее подразумевает более простой алгоритм.
Говорит, что а давайте делать обычного Форда Фулкерсона, но только на первой фазе будем искать пропустые способности С,
потом С пополам, потом и так далее.
На самом деле это уже даст вам Е квадрат ЛОКС.
Вот.
Но, видимо, как бы уже в следующий раз придется.
Да, но видимо это в следующий раз придется изучить почему.
Вот.
То есть там, да, там не сложно, но соответственно.
Ладно, все.
Спасибо.
