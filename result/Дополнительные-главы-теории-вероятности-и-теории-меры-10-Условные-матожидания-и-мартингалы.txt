Пусть P есть какое-то число конечное, а f функция интегрированная в этой стиле.
Когда условные средние f сходятся к этому условному среднему b и b,
на самом деле они сходятся и почти всюду, но как ни странно, очень просто доказывается вот это утверждение.
А то, что они сходятся почти всюду, доказывается довольно сложным.
Поэтому я не стал в одну теорию группировать.
Хотя было бы изящно, конечно, что эти сходятся к этому во всех a и b и почти всюду.
Но вот давайте разделим.
Доказательства.
Доказательства.
Можно считать, что вот эта вся большая сигма алгебра, она и есть вот эта.
Мы просто перейдем к меньшему сигму алгебре, на которую все время просматриваем.
Если мы перейдем к этой меньшей сигме алгебре, то вот эти мат ожидания условные будут прежние.
До этого, в общем, видно и за пределами.
Давайте сначала докажем для индикатора.
Пусть f это индикатор множества из этих сигмал.
Давайте посмотрим сначала для таких.
То есть когда мы перешли и сделали это основной сигмал алгебры, ну просто индикатор измеримого множества.
Основное понять, почему для индикаторов.
Это верно. Вот это основное понять.
Значит пусть епсилон больше нуля.
А тогда смотрите, что получается.
А тогда в алгебре, которое есть объединение или bn, есть множество c такое, что bn.
Ну что симметрическая разность меньше епсилон.
Ну почему это так?
Потому что это алгебра.
Ну почему она алгебра?
Ну она, очевидно, что алгебра.
Потому что когда вы берете два множества из этого объединения,
одно пришло из одной bn, другое из другой bn, но вы берете с большим индексом,
и они получаются, когда два множества пришли из одной bn.
Но там с ними можно, поскольку это были все отморозки, с ними там можно делать операцию.
Поэтому это не сигмал гебр.
Потому что так вы не можете в расчетное видеть.
Потому что если вы, ну они строго возрастают, и вы берете множество из каждой,
которая не вижет с предыдущей с каждой, и у вас объединение не будет в одной из них.
Поэтому это счетное объединение, оно алгебра, но не сигмал гебр.
Сигмал гебр, она порождена, она порождена, вот этой алгеброй.
Но если у вас есть мер на алгебре, то по самому способу продолжения,
ну такому учебному как бы, из учебного кульса,
мера на сигмал гебру с алгеброй так продолжается, что есть мечта.
Ну тогда, смотрите, что тогда получается.
Тогда получается следующее.
Значит, берем функцию g, которая есть индикатора dvc.
И смотрим, что будет с этой функцией.
Тогда с этой функцией будет больше.
Эта функция будет в одном измерении относительно одной из этих,
потому что множество из одной из этих.
При больших, ну при всех больших, больших n.
Ну столь больших, что c попало в это bn.
То есть на такой функции, этот проектор, он просто совпадает с этой функцией.
Ну и тогда сравниваем lp0.
Ну и тогда смотрите, что получается.
То есть тогда получается вот так.
Ну тогда получается, что и вот это тоже будет вот так.
Ну и начинаем сравнивать.
Значит, вот это начинаем сравнивать dc.
Значит, что это будет?
Ну и здесь это вычитаем g и добавляем g.
Так, значит, вычли и добавили.
А потом, значит, вычли и добавили.
А потом, значит, что еще сделали?
А потом вычли вот это и добавили вот это.
Ну и осталось вот это.
Значит, вот так получилось.
Но вот эта средняя часть, вот эта средняя часть, она пропала.
Значит, эта средняя часть пропала.
Поэтому получается вот так.
Но про этих мы знаем, что это сжатие в lp.
Поэтому, значит, каждый из них оценивается, значит, перестает
изменить, что норма vp оценивается через норму vp.
Ну и также для t.
Значит, каждый из них оценивается через разность.
Ну и остается теперь оценить разность.
Значит, смотрите, чему равняется tp норма, ну в степени p, от разности.
Ну она равняется вот чему.
Это интеграл от единицы a, от единицы b, от единицы c, в степени q, до e.
Значит, вот что это такое.
Ну какая картинка.
Вот b, вот c, и вот они где-то совпадают, где-то отличаются.
Ну там, где они совпадают, значит, они обе по единице, и это разность 0.
А там, где они отличаются, эта разность равна единице.
Потому что где они отличаются, ну где одна единица, а другая ноль.
Поэтому это получается интеграл от единицы по симметрической разности.
Ну и это у нас есть мера по симметрической разности.
Ну и это меньшее все.
Так что вот доказали сходимость.
Значит, это было на индикаторе.
Поэтому получаем вот такую вот сходимость на простых f.
На простых f получается такая сходимость.
Потому что это линейные операторы, условные сведения.
Так что если на каких-то функциях верно, то на линейных комбинациях тоже верно.
Ну и теперь общий случай, значит, общий f.
Значит, пусть ε больше 0.
Находим простую f, простую g, с нормой не больше f.
На простых у нас есть сходимость.
Ну и, значит, остается, опять добираемся применить.
Значит, опять пишем, что f, ну, что вот эта разность, значит, это есть вот что.
Ну вот я пониже выкручу.
Значит, ну добавляем f.
То есть добавляем g.
Ну и вычитаем и добавляем.
Вычислить и добавить.
Вот здесь тоже вычитываем и добавляем.
Вот получилась такая вещь.
Ну и теперь каждая небольшая по своей причине.
Так.
Значит, вот эта средняя часть.
Значит, мала при больших m.
Куда становится меньше нудного f всего.
А две другие, ну, опять и оцениваются.
Так же, как и я.
Значит, и точно так же со вторым и последним.
Ну и опять получается, что уже сходимость на всех.
То есть видите, это все почти что без всякой науки.
Единственное, что нужно было, вот то, что этих операторов нормы оцениваются.
В общем, получилось все очень несложно.
Но сходимость почти всюду сложнее доказывается.
Сейчас мы ее докажем.
Но она так вот другими руками не делается.
А нужно неравенству дуба.
Это неравенство вообще, в принципе, очень полезно.
И в теории Мартленгала это одно из самых, так сказать, неравенств эффективных.
В теории Интеграа всякие неравенства эффективные типа Чебушова.
А неравенство дуба, ну еще вот есть там похожая на него неравенство Колмогорова.
Они, ну они напоминают неравенство Чебушова, но они сложнее.
Значит, неравенство дуба.
Вот у нас этот дуб уже по другому поводу напоминается.
Значит, опять, опять БМ и А возрастают.
Значит, и Ф интегрируют.
Вот тогда, тогда верно, вот такое вот интересное неравенство.
Мера тех Иксов, где Супрему по Н по модулю больше, чем Ц оценивается, ну вот как у Чебушова.
Значит, видите, у Чебушова для каждой в отдельности было без, вот тогда не было никаких условных средних, то это неравенство Чебушова.
А здесь, видите, берется Супрему.
Понятное дело, что когда берется Супрему, это может сильно увеличить.
У вас там несколько функций, для каждой из них нечто верно.
А когда вы взяли Супрему, ну для Супрему может быть уже и неверно.
Поэтому это неравенство довольно удивительное.
Ну, естественно, Ц больше, значит, для каждой, Ц больше.
Значит, доказательства, доказательства, достаточно взять Ф не отрицательно.
Ну, почему?
Ну, потому что, если здесь поставить модуль, то множество, ну, только больше ставить, так?
Поэтому, если у вас с модулем такое доказано, то и будет без модуля.
Кстати, сказать, почему эта штука вообще имеет смысл?
Ну, потому что эта функция измеримая.
Ну, Супрему последовательности измеримой функции тоже измеримая функция.
Так что вот эта штука есть.
Вот, если бы мы тут совсем тупо применяли Чебышова, то мы бы вместо Ф поставили бы вот этот интеграл.
Вот от этого дело.
Но только это неверно, что...
А грубо это не сделаешь.
А вот если сюда вместо функции модуль Ф поставить вот эту функцию, то, конечно, Чебышов даст неравенственно.
Но только когда у вас тут будет стоять вместо модуль Ф в Супрему интег, вы не сможете это оценить через модуль Ф.
Вот это уже неверно.
Поэтому так вот дешево тут одним Чебышовым тут не отделываться.
Значит...
Ну, вот берем...
Значит, вот берем...
Ну, скажем, ФИТЫ и берем вот такие.
ФИТЫ это просто для упрощения дела.
Это будут вот эти.
А Е это вот там, где Супрему.
По И ФИТЫ больше С.
Это множество Е.
А Ешитое...
Ешитое, вот это самое.
Цитровые доказательства Ютуба.
Это вот что такое.
Это такие Х,
что сначала было меньше либо равно С.
А вжитый момент...
Ну, мы считаем вот эти индексы как бы дискретными моментами времени.
Мы тут на эти Н и смотрим, как будут возрастающие времена.
И, значит, смотрите, когда Супрему стал больше С,
ну, он до какого-то момента был меньше либо равно, так?
Ну, а потом в какой-то момент стагнул.
Потому что если он всегда меньше либо равно, то и Супрему будет меньше либо равно.
Значит...
Значит...
Поэтому...
Значит, смотрите, что можно сказать?
Вот, давайте, значит, посмотрим, что можно сказать про эти множества.
Ну, они, конечно, измеримы.
Так?
Значит, эти множества измеримы.
Сейчас, у нас в Афите получается...
Ну, не убивающие.
Что-что?
У нас в Афите получается не убивающие, потому что у нас ДИД.
Сейчас, сейчас, кто не убивающий?
Ф, И, Д.
Нет, почему?
Сейчас, сейчас.
Ну, это означает, что...
Ну, это...
Да. Ну, да.
Ну, да.
Ну, да.
Но эти проекторы возрастают.
Ну, вот эти проекторы, они возрастают.
Значит, сейчас.
Почему...
Сейчас, почему...
Почему вот эти возрастают?
А?
Не знаю, просто я не угадался.
Так.
А...
Значит, х.
В смысле?
Нет, нет, нет. Ну, смотрите.
А...
Значит, сейчас.
Ну, давайте подумаем.
Ну, сейчас мы про это подумаем.
Но нам важно
следующее.
Ежитые.
Ежитые измерены.
Так.
Дальше. Ежитые.
Ну, ежитые, понятное дело, входят
в эти седьмалки.
В эти седьмалки.
Так.
И, значит,
что еще?
Ежитые.
Ежитые изюмплены.
Ежитые изюмплены.
Так. И...
Значит,
Е
это объединение ежитии.
Потому что, если в какой-то...
Ну, если когда-то
стало больше С,
то, значит,
ну,
в какое-то ежитые попали.
Ну, тут, правда, еще
тут надо еще вот
что-то сказать. Вдруг
в самое первое попали, да?
У нас тут не учтено...
Ну, у нас тут не учтено
в самое первое, да?
Значит, сейчас как
будет, значит...
Почему?
Е первое это, наверное, просто
в первом больше чем С.
В чем проблема?
Ну, Е первое это когда в первом от ИС больше
чем С?
Е первое
это когда...
Ну, да. Но тогда нет
предыдущего.
Ну, мы тогда...
Ну, для единообразия
нужно считать, что F0 равно 0.
Ну, например.
Ну, чтобы эта формула была единообразна,
нужно считать, что F0
равно, что есть еще нулевая
F0 равно 0.
Значит, сейчас вы говорите, что
нам вот это дальше нужно,
но давайте посмотрим...
Ну, это нам никак не поможет,
что они возрастают или нет.
Сейчас. Ну, давайте сообразим.
Обязаны ли они...
Обязаны ли они
возрастать?
Ну, не понятно, почему нет.
Понятно, что нормы не будут.
Проекторы возрастают.
Что такое проекторы возрастают?
Значит, у следующего
образ
больше чем в предыдущем.
Как операторы, проекторы возрастают.
Но на
на индивидуальные функции...
Сейчас, давайте.
Конечное разбиение.
Выписано по адресу. Да.
Мы сделали разбиение в 4 лет. Да.
У нас функция была в аджетании.
Да, в адресу. Теперь по аджетании.
Да, в адресе больше.
А, могла стать и больше, и меньше.
Ну да. Ну да, правда.
Ну да, то есть
в поточечном смысле...
Ну, вот в эгераторном смысле
возрастают в поточечном
смысле данные.
Так, значит, смотрите.
Вот такая получилась
конструкция.
Ну и смотрите, что получается.
Значит, интеграл
от функции
по всему пространству.
Поскольку у нас функция не отрицает,
но она оценивается
через интеграл по
е. Да.
Значит, интеграл по е
это сумма
интегралов
по
ежидам.
Да.
Ф или модуль f?
А, мы говорили шире.
Вот. Значит, это сумма
интегралов вот по этим.
Но на каждом
ежидам f
больше либо равна
чем c.
Поэтому это будет...
Поэтому это будет
больше либо равно
чем вот это.
Ну а это складывается
в меру
е умножить на c.
Вот мы доказали.
Вот мы доказали.
Ну казалось бы, что это очень дешевое,
но тем не менее
вот это
по-видимому дуб
придумал такой трюк
рассматривать
вот эти моменты
первых переходов за угрой.
Ну и дальше я сформулирую
немножко более общую
теорему дуба.
Действительно,
оказывается, что она равносильна
тому, что мы доказываем, но
чтобы увидеть, что она равносильна,
некоторая работа требуется.
Но вот в этой более общей теореме дуба
она уже про интегралы
тут, видите, пока
тут на самом деле
уже про интегралы появились.
Но вот
в той теореме будут чисто, видимо, интегралы
без всяких условий.
И там будет очень
похожий трюк,
но это мы уже не будем доказывать.
То есть, видите,
лемма такая совсем
из базового курса
меры интеграла.
Но в базовом курсе
ее ни к чему не приспособишь,
а вот здесь она
здесь она у нас сейчас будет
приспособлена
к сходимости.
Что там, что-то не так у нас?
Нет, вроде еще часто.
Действительно, давно этот трюк
придумали, и, по-видимому,
это самое простое
предназначение.
Как видно, что
маленький фрагмент доказательства
как учебного швова,
но только учебного швова, все доказательства
к этому маленькому фрагменту сводятся.
Мы уже узнали этот финт
с этими моментами
первых пересечений уровня.
Значит,
теорема
такая,
теорема такая,
значит, если
опять
ВН и А
возрастают,
и
значит,
Ф
значит, Ф
не интегрируема,
то
те, про которые
мы доказали,
что они сходятся
почти всюду,
то есть ВВП,
они на самом деле сходятся
почти всюду.
Значит,
вот это уже
менее очевидно,
значит, вот это уже менее очевидно.
Но, значит,
вот,
ну, в принципе,
последовательсти легко устроить,
которые в ВВП сходятся, но
вообще ни в одной точке не сходятся.
Но в данном случае
это последовательность довольно
специфического вида,
поэтому
значит,
ну, тут, в общем, заранее как бы не ясно,
какой был бы ответ,
но вот Дуб
догадался, что здесь будет так.
Значит, ну,
доказательства,
ну, доказательства не очень,
значит,
банальные.
Значит, доказательства
ну, оно использует Дуба,
но все равно это, так сказать,
не то, что в одну срочку сходится.
Значит, можно считать,
ну, опять можно считать,
что
а, и есть
вот эта большая сигнала,
так, ну, и тогда
надо доказать,
значит, тогда доказывать,
доказывать,
доказывать, что
просто
за 3 год
сходятся к F
почти все,
ну, так что убрать лишние символы,
просто сейчас,
значит, и так будет форма, у меня очень короткие,
полезно,
значит, эти лишние символы полезно убрать.
Ну, то есть, фактически
перейдя вот в какой-то меньший
сигман убивать, мы как-то
заменяем функцию F,
сразу же заменяем на ее
складной среде.
Так,
значит,
значит, вот,
значит, тут,
значит, вот, значит, вот, что
Дуб тут придумал.
Значит, вот,
значит, это он придумал.
Значит, берем C от X,
это
верхний
предел
при стремящемся бесконечности.
Ну, вот,
вот этих вот
разностей.
Так, значит, ну, что
мы хотим доказать?
Значит, нам надо,
нам надо доказать,
что C от X
равняется
почти всему.
Вот, если мы докажем, что
верхний предел почти всему 0,
то с 0 это и будет означать,
что сходимость
почти всему.
Так, то есть, вот параграф функции,
мы сейчас с ней будем бороться
с этой функцией.
А, значит, ну, пусть,
пусть L больше,
L больше.
Значит, ну, опять находим,
находим, значит,
bn
измеримую
функцию g,
такую,
что
f
отмечается
меньше,
чем
на епсиум квадрат.
Значит, нашли.
Ну, то есть, пока что
у нас действия похожие,
как если бы мы намеревались
доказать сходимость
в среднем, так?
Поэтому начало, ну, начало кажется
подозрительным,
потому что вроде, когда чего-то
в L1 приближаются,
то вроде как в итоге
исходимость должна быть вверх.
Но на самом деле,
на самом деле сейчас
с помощью дуба окажется,
что мы
вот из-за этого оценим
интеграл от psi
через epsilon.
Но если мы оценим интеграл от psi
через epsilon, и так будет
для всякого epsilon, то значит интеграл
от psi станет нулём, ну и
она ей никуда не деться, как быть нулём
почти в щуку.
Так вот, мы издалека
выбираемся к этому нулю.
Значит,
значит, значит, значит,
ну, это так тоже немножко
упрощённо стало, на самом деле
даже так ещё чуть-чуть внутренней будет.
Вот, тогда, значит, смотрите,
что получается.
Значит, тогда получается
вот такая вещь,
что начиная
с этого
номера,
все последующие
с ней совпадают.
Значит,
ну и вот, значит,
вот что это даёт.
Вот что это даёт.
Смотрите, значит, psi от x,
так?
Значит, меньше
либо равно, чем
верхний предел
внутренне стремящейся
бесконечности, вот отчего.
Вот так я напишу.
Значит, плюс верхний предел.
И плюс
вот это.
Так.
Значит, вот давайте посмотрим,
откуда это взялось.
Здесь
g. Давайте посмотрим, откуда
это взялось. Значит,
все это вот такая штука, да?
Значит, откуда
это взялось?
Ну, смотрите, откуда это взялось?
А, значит, мы
сюда вставили такую штуку. Действуем уже с большими
номерами, поскольку тут верхний предел, действуем
с большими номерами, для которых вот так. Мы сначала
вычли ж, а потом добавили ж, пока еще без модула. Дальше
с условным среднем вычли и добавили, а потом вычли
ж, и добавили ж. Ну и f еще вычиталось. Ну и раскрыли.
Получилось верхний предел суммы 3, но верхний предел
суммы 3 оценивается через сумму верхних предел.
Вот это исчезло при больших, поэтому получается
просто верхний предел. Ну вот этого одного, плюс вот
вот такая вещь получилась. Вот получилась такая вещь.
Теперь смотрите, что мы можем использовать. Ну теперь
неравенству дуба мы используем. Вот для этой штуки используем
неравенству дуба. И смотрите, что получается. Что дает
дуб? Он дает следующее. Мера тех х, где верхний предел
на этого дела больше епсила. Ну он оценивается через
supremo. И оценивается через единицы на епсила. Ну и меньше
епсила. Ну сколько это было меньше, чем епсилам квадрат.
То есть видите, значит, вот это получается маленькое.
А значит еще нам Чебышов дает, кроме дуба. Ну в принципе получается
Чебушов это частность мужчин дуба. Так что можно сказать
опять дуб дает. Значит, мера тех епсил, где просто вот эта
разность епсил, она тоже оценивается через епсилу.
Потому что интеграл от многого разности оценивается через
епсилу. Ну и получается, значит, получается весок. Веток
всей этой деятельности такой. Мера тех епсил, где все от
из больше двух епсил, оценивается через что? Через меру тех
крысов, где верхний предел больше епсил, плюс меру, ну плюс
меру вот эту. А еще вместе это оценивается, значит, через
два епсила. Значит, смотрите, что оказалось. Значит, оказалось
итог, значит, итог меры тех крысов, где все от из больше
чем два епсила, меньше дуба равно чем два епсила. Ну, это
значит, что, ну, из этого следует, что psi равняется
дубу. Потому что, ну, вот представьте себе, что оказалось,
ну, почему вот из этого следует, что psi равняется дубу?
Ну, представьте себе, что оказалось, что множество, ну,
давайте перечним. Значит, если, если мера тех х, где все от
из больше нуля, равняется, ну, какой-то дельта больше нуля,
то тогда из чего состоит это множество? Значит, из чего
оно состоит? Ну, оно состоит из тех, где больше какой-то
одной н. Тогда получается, что существует такое n, например,
что меры fx, епси от х больше одной н, что это, ну, больше
чем дельта попала, так, потому что эти меры стремятся к
этой мере. Ну, тогда нужно взять просто, ну, ну, из этих
двух чисел надо взять меньшее, из этих двух чисел надо взять
меньшее. И вот его объявить, что это 2x, ну, и тогда будет
противоречить. Так, поэтому, значит, видите, вот мы доказали
таким образом, что psi 0 почти всюду, ну, вот тем самым доказательство
закончено. Ну, как видно, оно, в общем, ну, сложнее, чем сходимость
выделения. Значит, выделение, вот, ну, вот, например, например,
полезный, полезный пример такой сходимости. Значит, смотрите,
значит, вот, возьмем, значит, вот, возьмем такой случай,
значит, пусть, пусть, значит, пространство наше, пусть это
пространство, ну, счетная степень T, а мера mu с счетной степень,
ну, ну, или давайте не обязательно степень, а пусть мера mu это
произведение, значит, меры мюитов, значит, мюиты, вероятностные
меры на T, потому что это их счетная степень. А, значит, кто
будет символгебра BN? Значит, BN символгебра, порожденная
первыми координатами. То есть, кто такие множества B из BN,
как они выглядят? Множество B из BN это множество, ну, такие
последовательства, так, что первая N, значит, ну, вот, первая
проекция на RM попадает в множество B0, а B0 это барельевское множество
ВР. Вообще-то такие цилиндры, цилиндры с основаниями ВР, но основание
какое-то барельевское множество ВР, и это основание конечномерное
домножается на остальные примуты. Вот, значит, вот эта сигма
алгебра BN, вот она выглядит, значит, вот таким вот способом.
А теперь, из того, что мера произведения, следует, что условное
условное массожидание F, это функция должна быть N перемен.
Что же это за функция N перемен? Значит, это вы интеглируете функцию,
вы фиксируете эти N переменные, а по остальным, значит, эту функцию интегрируете.
И это интеграл по произведению меры, вот этих вот меры,
D,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y,Y
Н плюс два, ну можно сказать так, что вы устраиваете произведение всех мер, кроме первых Н
И эту функцию, значит, от бесконечной последовательности переменных
Вы ее представляете так, у вас первые N аргументов фиксированы
А следующие дают как раз функцию на этом произведении и вы интегрируете
По этим мерам, по этим переменам
Что получается? Постепенно у вас переменных высвобождается все больше
Вы сначала приинтегрировали, по всем переменам получилось константа
Потом вы освободили первую переменную, и у вас стала функция одного переменного
Потом N возросло, и вот этих N становятся все больше и больше
И поэтому со временем эти функции зависят от все большего числа перемен
И вот теория маргуба говорит, что вот эти вот, вот эти вот
Они сводятся почти всюду, они сводятся почти всюду к функции
То есть у вас получается такие вот приближения интегрируемой функции вот такими вот интеграмы
То есть получается всякая функция на произведении может быть приближена вот такими функциями конечного числа перемен
Ну теперь спрашивается, а почему вот эти интегралы, почему они и есть условные средства
Я вот написал равенство, но это равенство нужно проверить
Ну вот давайте в качестве задачи на семинаре это равенство проверим
Вот это давайте я обозначу как упражнение, ну и на семинаре мы проверим это равенство
А сейчас, ну собственно, это равенство, это соотношение, это заключение теоремы
Если проверено, что вот это правильный ответ
Потому что для таких сходимость есть, но почему вот эти дают сходимость
Ну вот потому что они с ними совпадают, это надо проверить
Это качество на семинаре проверим
А теперь мартингау
Про мартингау я приведу основные определения, основные факты и как моменте пример
Ну пример вот собственно будет стилировать в предыдущем
Значит мартингау
Значит пусть вот дало вероятностное пространство
Пусть доно вероятностное пространство
И значит бн опять возрастающий сигнал приводит вот в этом апт
Значит последовательность интегрируемых ксилен мартингау относительно вот этой последовательности
Если верно следующее
Ксиен измеримо относительно бн
И условное среднее
Значит условное среднее
Сейчас как это лучше формулировать
Значит условное среднее
Ну вот так я формулирую
Условное среднее bx1 от ксиен совпадает с ксиен
Значит более общее определение
Что? Что? Что?
Сейчас я не там
Я не там mx1 не там поставил
Значит более общее определение
Значит bt
Где t
Ну без какого-то подмолвства t в r
Значит возрастающее семейство сигнал будет в a
И тогда уже не последовательность
А случайный процесс на этом множестве
Ну может быть семейство интегрируемых случайной величины
Это мартингау относительно вот этого набора сигмалга
Набор сигмалга называют фильтрацией
Фильтрация это возрастающий набор сигмалга
Просто для краткости называют фильтрацией
И тогда требуется чтобы xt измеримо относительно соответствующей сигмалгубы
А вместо вот того должно быть следующее
Условное среднее относительно вот этой сигмалгубы
Все от s
Будет все от t
Когда s больше либо равно t
Здесь я написал за один шаг
Здесь так не напишешь за один шаг
Потому что они друг от друга могут отличаться
Сколько года мало
Но это предыдущее
Смотрите, если тут начать увеличить
Если тут вместо n1 ставить больше
Ну и пользоваться тем, что
Ну давайте это запишем
Ну вот это конец определения
Давайте запишем вот в таком стиле
Предыдущее
Здесь будет не следующий n плюс 1
А какое-то большее
Значит почему это равно xm
При m больше либо равно n плюс 1
Давайте проверим
Почему из этого получается вот то
То есть проверим, что это определение согласовано
Значит смотрите
Что тут получается
Значит смотрите, что тут получается
Значит xm
Оно получается
Ну и с предыдущего
Значит оно получается вот так
Значит x
Сейчас
Сейчас нехорошо это писал
Сейчас
Нет, давайте я вот так напишу
Нет, ну напишу вот как там
Значит будет xm плюс 1
bm
Теперь давайте
Давайте
Ну вот эту штуку
Значит вытащим
И вот этого
Напишем вот так
xn
Значит
Значит xn плюс 1
Вот c
Минус 2
Вот так напишется
Значит заменили вот этого
Заменили на вот этого
Понятно, да?
Значит что дальше делать
Да, да
Но это
Вот этот проектор
Вот этот проектор на большее пространство, чем этот
Поэтому вот это равно
Вот это
Вот это
Вот это
Вот это
Ну и так далее
Ну и так далее потихоньку поднимаем
Ну и доходим до r
Вот поэтому
Значит эти два определения согласуются
Ну разумеется для последовательности можно тоже писать
Не обязательно в следующий момент
Значит
Значит вот пример маркингала
Вот пример маркингала
Значит первый пример
Вот первый пример
bm в ней возрастают
И x просто какая-то интегрирует
И в качестве cn мы берем
Ну просто ее проектируем
Вот эти
Ну тогда из определения
Значит условного моделетания как проекции получается что это маркингал
Ну вот мы сейчас обсудим вопрос
Все ли маркингалы так получаются
Сейчас мы обсудим вопрос все ли маркингалы так получаются
Это первый пример
Есть два основных примера
Первый пример
Второй тоже так может быть получен
При широких условиях
Но он не совсем такой
Второй пример
Не всегда так получается
А второй пример
Это мод какой пример
Второй пример
Пусть это n независимые случайные величины
С нулевым средним
Значит независимые случайные величины с нулевым средним
А xn это их
Последовательная сумма
Ну сейчас я говорю что не вижу просто суммы
Вообще это такая нарастающая сумма
Ну вот исторически наверное даже это было первым примером
Значит маркингалы появились в 30-х годах
Ну вы работали в Невиле, Дубах, Левиле
В общем там несколько отцов-открывателей
Почему называется маркингал
Ну это в точности никто не знает
Ну понятно что за этим стоит французское слово
Но у этого французского слова два значения есть
Значит первое значение несколько архаичное
Это там часть сбруи
Для вздергивания коня
А второе немножко хоть и не архаичное
Но несколько жаргонное
Это такая тактика игры
Ну там где ставки делаются
При которой при проигрывшей ставка удваивается
Ну вот что имели в виду отцов-открывателей не очень ясно
Но вот как бы и та и другая интерпретация
Возможно
И вот в особенности вот этот пример
Вот этот второй пример он как раз подходит под все эти интерпретации
Значит почему это маркингал
Ну давайте посмотрим проекцию
Да, да, маркингал относительно чего
Я не дописал
Маркингал относительно
Тут всегда важно относительно чего
И здесь это седьма аугубра порожденная первыми N
Значит давайте посмотрим
Такая будет проекция
Следующая
Ну понятно что тут будет
Поскольку сумма
То будет предыдущая
Плюс
Плюс условное среднее
Вот этого
Условное среднее последнее
И нам надо проверить
Что условное среднее последнее 0
Значит условное среднее последнее 0
Ну это конечно из-за того что это последнее
Всякий имеет предыдущий независимый и имеет нулевой средний
Значит давайте это проверим
Почему это так
Значит смотрите что нам нужно
Значит кто такое условное среднее
Значит условное среднее
Давайте вспомним
Кто такое условное среднее
Ну это некая функция
Вот
Раз седьма аугубра порождена конечным набором
Конечным набором сезжаемых величин
То это функция этих величин бареевская
Ну и такая что
Это n плюс 1
Минус эта функция
Ну давайте я здесь напишу
Она должна быть автогонайна
Получается что
Вот эта вот функция
Минус
Вот эта функция минус ее условное среднее
Вот так
Должно быть автогонально всем
Значит функциям g ограниченная
Значит bn измеримая
Так вот что должно быть
Должна быть всем таким функциям автогонально
Но что это значит
Ну эта функция же тоже
Значит вот n переменная
Значит должно быть так
Что это n плюс 1
Минус вот это
И вы это умножаете на
C тоже ограниченная
И вот это вот должно быть
Для всех вот таких C
С ограниченная бареевская
Для всех таких ограниченных бареевских
Это должно быть 0
Но значит смотрите
Случайная величина это независимо с этими
Поэтому интеграл
Вот такой интеграл
Из-за независимости
Он раскалывается
Ну он раскалывается в произведении интеграла
Ну и равен нулю
Поскольку это среднее нулевое
Значит и смотрите что же получается
Получается что интеграл от phi на psi
Получается что интеграл от phi на psi
Тоже должно быть 0
Потому что они равны
Но такое может быть
Только если вот эта phi равняется нулю
Ну точнее не phi равняется нулю
Вот это должно быть 0 почти всю
Потому что если не верно
Что она 0 почти всю
То мы берем psi
Ну какой-то индикатор
Возьмем например нулю 100
Где она отличная от нуля
И получим что противоречие
Поэтому получается
Получается что вот этого нет
Получается что этого нет
Ну и получается что мы проверили что это будет
Вот это весьма тоже общий вид
Маркенгала
Который в реальной задаче встречается
В теории вероятности
Очень многое происходит из-за того
Что мы складываем на всякие независимые эффекты
Вот там очень многое происходит из того
Что это вот этот пример маркенгала
Но этот маркенгал не всегда
Подпадает под первый пример
И сейчас я приведу теорему
Которая говорит
Какие именно маркенгалы
Подпадают под первый пример
Ну это тоже теорема дуба
Но я не буду про них всех писать
Потому что в этой области это большинство
Теорема дуба классическая
Значит теорема
Ну вернее так
Значит маркенгал
Маркенгал из первого примера
Называется
Замыкаемо
То есть это маркенгал
Который получен самым простым способом
Что это последовательные проекции
Одной и той же функции на возрастающем подпространстве
Значит теорема такая
Значит маркенгал
Маркенгал ксилен
Значит маркенгал ксилен
Замыкаем
Тогда и только тогда
Когда он равномерно интегрирует
Интегрируем
Тогда и только тогда
Когда сходится в элевий
Значит равномерно интегрируем
Это значит следующее
Значит равномерно интегрируем
Это значит следующее
Что если вы возьмете
Вот такую вещь
То это должно стремиться к нулю
Когда n идет к бесконечности
Но здесь это должно быть равномерно по n
Вот что значит равномерная интегрируем
Вот что значит равномерная интегрируем
Вот что значит равномерная интегрируем
Значит теперь
Как доказывается эта теория?
Я сейчас не буду все детали восстанавливать
Я сейчас не буду все детали восстанавливать
Но если
Если
Есть
Если замыкаем
Если замыкаем
То получается
Что
То получается
Если что
Есть равномерная интегрируемость
Есть равномерная интегрируемость
И сходимость в элевий
Это у нас было
Если у одной интегрируемой функции
Берем последовательный мат ожидания
То
Эти сходятся в l1
Из сходимости в l1
Там легко увидеть, что следует равномерная интегрируемость
Поэтому в одну сторону это
Довольно просто
А теперь в другую сторону
В другую сторону не так просто
Почему?
Потому что
Не так просто
Смотрите какие проблемы
Откуда возьмется
Откуда возьмется
Вот эта предельная функция
Вот это основное
Вот это основное
Если у вас есть
Если известно
Что они сходятся в l1
Если известно, что они сходятся в l1
То тогда конечно у вас появился кандидат
У вас появился кандидат
То к чему они сходятся
Это естественно и будет то, что надо
Вот эта имплигация тоже простая
Если сходятся в l1
То можно легко проверить, что это проект кандидата
Что наименее очевидно
Наименее очевидно следующее
Что если они равномерно интегрируемы
То они сходятся в l1
К чему они сходятся
Ну и будет проект
Это не очень просто
Поэтому не будем доказывать
Как факт, это надо знать
Из равномерной интегрируемости
Ну вот я так скажу
Примерно откуда берется нужная функция
Примерно откуда берется нужная функция
Если известно, что они равномерно интегрируемы
Вот если они равномерно интегрируемы
То можно
То можно
То можно проверить
Что у них есть
Подпоследовательность
которая сходится на
множество из сигналов
Ну в каком смысле сходится
Вот так вот я бы сказал
Я не буду в детали даваться
Первый этап такой, предположение равномерно интегрировано, доказывается, что есть подпоследовательность, у которой интегралы сходятся на всех множествах из вот этих сигмалов.
Это, к сожалению, тоже нельзя сказать, что это совсем очевидно, но, в общем, это делается. Ну и после этого оказывается, что там появляется мудная функция.
Но вот так совсем, так сказать, на пальцах, это не объяснишь. Вот это более трудная часть этой теории.
Это вот важная теория на сходимости маркингалов, и можно подобрать примеры второго сорта. Такие, что они не будут примерованы первого сорта из-за того, что последовательность этих сум не будет равномерно интегрирована.
Ну, в общем, это, так сказать, можно... Ну, я бы сказал, пользуясь всякими, типа, вернули случайных величин, в общем, это можно подобрать.
Но это нужно подбирать, потому что вообще-то для... Это не очень характерно. Все-таки большинство маркингалов, которые встречаются в задачах, они все-таки равномерно интегрированы, замыкаемые, так что они получаются из чего-то едины.
Ну, вот этот первый, вот этот второй пример, это, конечно, очень важный пример, в теории вероятности очень много задач про такие накакливаемые суммы. Ну, и вот он все-таки не, так сказать, не укладывается.
Так, значит, это... Так, сейчас. Значит, да, да, теперь смотрите, что еще получается. Если это соединить с теориямой Дуба, то получается такое следствие, это уже просто из теории Дуба.
Значит, если, если все равномерно интегрируемые, интегрируемый маркингал, то существует почти всюду предел, значит, равномерно интегрируемый маркингал сходится почти всюду.
Ну, это вот, это мы уже доказали, вот это мы уже по честному доказали. Но для этого нужно его представить, чтобы, ну, его нужно представить в виде последних подтверждений одной и той же функции.
Ну, теперь спрашивается, а как практически проверять равномерную интегрированность? Значит, практическая проверка, ну, когда их последовательно равномерно интегрируют. Ну, вот с любыми функциями можно возиться.
Вот, значит, достаточное условие, достаточное условие равномерной интегрируемости, вот какое. У них интегралы в степени P ограничены общей константой, ну, при каком-то P больше единиц.
То есть, видите, не при P равномерной, при P равномерной единицы этого недостаточного равномерного интегрированности. А вот нужно, чтобы степень была побольше. Ну, вот, например, двойка, годится двойка.
Значит, если они имеют ограниченные дисперсии, ну, вот, значит, тогда сходится. Это, конечно, ограничение, но, в общем, в практических задачах это не очень большое ограничение.
И, значит, вот так часто, ну, такое часто бывает. Поэтому, если у вас в первом примере, если у вас в первом примере, например, известно, что есть дисперсии, так? И ряд из дисперсий сходится.
То у вас вот это условие выполнено. Потому что для независимых, значит, с нулевым средним интеграл от квадрата будет равен сумме дисперсии.
И если вам дано заранее, ну, это, конечно, не само к себе, не оккультный следует, должно быть дано заранее, то если ряд из дисперсий сходится, то все окей.
И будет равноверная интегрированность и будет сходимость там, ну и так далее. Так, значит, это я закончил, сейчас, это я хочу сказать, я закончил портингал, но, увы, надо закончить тогда сейчас и лекцию.
Значит, получается так. Я вообще-то думал все-таки успеть начать слабую сходимость мер, но вот следующие две лекции уже все.
Значит, будет последний кусок, такой, значит, интенсивный обзор слабой сходимости мер.
Ну, на самом деле, значит, сейчас у нас 11, 10, 17 и 24 еще есть, но, в принципе, еще, если я не успею, еще 1, но мне казалось, что на декабрь плохо с лекциями приезжать.
А меня вообще тут как-то сторожилый человек говорит, что вообще на вестихе в декабре лекции не читают, не знаю, обратно это или нет?
Читает кто-нибудь лекции в декабре? Читают-читают? Нет-нет, ну а когда начинается реальная сессия?
Вот это число 15.
15-го?
За чертной недели 15.
А, за чертной недели 15 вообще. Ну да. Нет, ну понятно, что если и читают, то в начале не говорят.
Ну вот у нас еще первое число, оно почти что еще не декабрь, так что это первое число допустимо.
Но я, в принципе, планирую вот за две лекции слабую сходимость этот кусок разгадать.
Ну там что-то, конечно, что-то без догадательств.
Так, значит, давайте сделаем первый...
