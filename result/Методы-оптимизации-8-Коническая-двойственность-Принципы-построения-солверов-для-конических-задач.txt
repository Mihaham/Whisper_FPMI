Отлично. Запись поставлена. Сегодня, я надеюсь, мы успеем
две темы. Они обе просто не очень большие, и попробуем
не растягивать это на две отдельные занятия. Первая
коническая двойственность. Посмотрим, чем она отличается
от… Точнее, не отличается, а выделяется по сравнению
с той двойственностью, которая была в прошлый раз.
Мы контролили двойственные функции, получали некоторые
результаты по условиям оптимальности. Вкратце, надо бы их напомнить,
что если у нас там есть задача с выпуклыми… Наверное,
имеет смысл только про выпукло сейчас напомнить, что если
мы вот такую задачу решаем, где f и h житые выпуклые,
то при выполнении условий слейтера, то есть наличие
такой точки, в которой равенства выполнены, а неравенства
выполнены как строгие, у нас есть условия к т, найдутся
двойственные переменные, которые будут доставлять
сильную двойственность. И, собственно, будет выполнено
условие к т о том, что 5 штук меньше либо равно 0, а х со звездочкой
равно b. Двойственные множители для неравенств не отрицательны.
Дополняющая нежесткость, что по элементам равны 0,
и сационарность лагерныжана по х, то есть f штрих от х в
х со звездочкой плюс… Так, а давайте я сейчас вот так
напишу, это нам пригодится впереди еще. Что скалярное
произведение лямбда транспонировано на g в х со звездочкой, ну
g в х со звездочкой, это понятно, что такое. Ой, я не допишу.
У нас же нет никаких g, у нас есть ах со звездочкой
плюс мют транспонированный, а вот аш у нас уже есть. То есть
аш от х – это как бы вектор функции, который состоит
из элементов от х, па-па-па, там b от х, например. Вот
такой вот вектор. Так, градиент здесь, градиент… А, тут
на самом деле надо бы хорошо вот так по х. Плохо написано,
ладно, сейчас я перепишу. А транспонированная лямбда.
Вот, выполнены такие условия. Вот, их надо знать, понимать,
когда их можно применять, когда нельзя. Вот, и соответственно
делать, уметь делать свойствах решения исходя из того, что
у вас получается в процессе разрешения этой большой
системы с линиейными, с равенствами и неравенствами. Так,
это был прошлый разный результат. Вот, сейчас поговорим
немножко про то, что важно понимать еще про двойственность.
Потом рассмотрим некоторые примеры и контрпримеры. Вот, и
потом перейдем уже к второй половине. Значит, что важно
понимать? Важно понимать, что если у вас есть одна и
та же задача, вот, ну, например, ну, например, мы хотим
минимизировать что-то вот такое. Вот. И вам надо по каким-то
причинам, бывает, что так на самом деле проще решать,
построить для нее двойственную. Но поскольку в задаче нет
ограничений, то ничего путного у вас в таком виде не
получится. Поэтому ее переформулируют, введя дополнительную
переменную и ставя уже вот такую вот задачу по переменам
x и y. Тут уже ограничение появляется, лаганожан становится
не тривиальным. Вот. И поэтому можно получить какой-то
конструктивный результат через строение двойственной
задачи. Вот. То есть стандартный прием для рассмотрения, ну,
то есть в процессе анализа и исследования некоторых
задач бывает полезно вводить новые переменные, которые
будут позволять, которые позволяют, собственно, получить
ограничения, которые в дальнейшем помогают получить
нетрериальную двойственную задачу. Это первый способ. Ну,
и второй важный момент, что если у вас, например, была
какая-то такая задача линейного программирования, про
который мы еще поговорим чуть позже. Вот. Ну, например, x
было от 1 до минус 1, то у вас есть как бы два пути. Первый
путь смотреть на вот это вот как на ограничения, как мы
делали раньше. Тогда у вас там будет лагранжан иметь вид.
Так. А вот дальше будет что-то типа мю1 транспонировано
x-1 минус мю2 транспонировано. Давайте плюс. Чего? Минус
x-1. Это такое. Вы там этот лагранжан как-то анализируете,
находите инфимум, выражаете туда-сюда, все получается.
Получаете некоторую двойственную задачу в переменах
лямбда. Так. Какие тут переменные? Лямбда, мю1, мю2. Вот. При
этом понятно, что ограничения в двойственной задаче будут,
что мю1 больше либо равно 0, а мю2 тоже больше либо равно 0.
Это будут ограничения. Вместе с тем можно поступить иначе.
Можно сказать следующее, что наша задача это то же самое,
что, ну это буквально то же самое. Вот так вот. При условии,
что ax равно b. Тогда лагранжан, который у вас будет, будет
выглядеть вот так. Но в процессе поиска двойственной функции
вы будете искать инфимум по вот этому множеству. То есть
в каком-то смысле, то есть вот эту штуку, если вы решаете,
то у вас задача двойственная будет просто максимизация
g от лямбды, уже без ограничений. То есть если у вас есть какие-то
не очень сложные ограничения, то вы можете их явным образом
записать в область определения и посчитать по ним инфимум.
В чем плюс? У вас получилась безусловная задача двойственная,
то есть безусловная задача, никаких ограничений нет.
Решать такие задачи проще. В чем сложность? В том,
что находить инфимум, у которого нет никаких ограничений,
сильно проще, чем искать инфимум, когда ограничения
на x есть. Вот поэтому важно балансировать те ограничения,
которые вы выносите в собственно Лагранжан и те, которые вы
оставляете внеявным образом, чтобы их в дальнейшем учесть
в процессе поиска инфимум. Так, поставьте плюс, если вот
было до этого места все понятно или минус, если было
что-то непонятно. Так, пять плюсов вижу, примерно половина.
Так, у кого возникли какие-то вопросы, сомнения, непонимание
того, что происходит, пример 6 и 7. Так, и тишина. Ну ладно,
надеюсь, что тем, кто никак не реагирует, тоже все более-менее
ясно. Так, ну теперь давайте примеры рассмотрим, примеры.
Начнем с простейшей задачи линейного программирования,
которая нам некоторые нюансы в состоянии двойственной
задачи подсветит, можно так сказать. Так, ах равно b
и не отрицательный x. Вот, ну что, строим кишман Лагранжан,
давайте напишем его сбоку, чтобы сэкономить немножко
место, и все было немножко более компактно. Вот, так,
понятно ли, почему здесь минус? Да, потому что x в наших
всех построениях было, было что, что функция, которая
соответствует неравенству, у нас знак меньше либо равно,
тут у нас и больше либо, и мы на минус 1 умножаем, получаем здесь
OK, теперь g от λµ это infimum по x от Lx λµ, вот, и несложно
заметить, что мы берем infimum по x от вот такой вот замечательной
функции, c плюс a t лямбда минус мю спонирана на x минус
лямбда tb. Вот, эта функция является линейной, поэтому ее
infimum потенциально может улететь в миловесконечность,
и что ему не помешает это сделать. Вот, кроме того, если
вот этот коэффициент перед x будет равен нулю, поэтому
тут есть два варианта, понятно, у нас есть два варианта,
минус лямбда tb, если c плюс a t лямбда минус мю ноль, и
минус бесконечность иначе. Вот, отсюда получаем стандартный
вид двойственной задачи, максимизируем то, что у нас не
минус бесконечность, что довольно разумно, при условии,
что, во-первых, у нас, ну, это не минус бесконечность, она
как бы правомерна, вот, ну и второе, что мю больше либо
равно нуля. Понятно, что отсюда можно избавиться от
мю, другополучно, и у нас будет максимизация минус
лямбда tb при условии, что c плюс a t лямбда больше либо
равно нуля. Вот, опять получили, значит, линейное программирование,
вот, то есть все довольно прямолинейно, никаких особо
проблем здесь как будто бы не наблюдается. Вот, для
линейного программирования также можно выписывать условия
оптимальности, вот, и заодно понять, в чем будет основная
беда, то есть у нас будет a x со звездочкой равно b, x со
звездочкой больше либо равно нуля, опять же, мю больше либо
равно нуля, мю и t, x и t равно нулю, нежесткость, да, и
чего? Да, и, собственно, градиент Лагранжана, который мы,
по сути, уже выписали, a t лямбда со звездочкой плюс c
минус мю со звездочкой равно нулю. Вот, вот, в принципе,
если вы умеете такую систему решать за разумное какое-то
время, то вы получаете решение задачи. Вот, давайте посмотрим
на это внимательно и поймем, в чем сложность в решении
такой системы. Так, ну, матрица A, да, надо сказать заранее,
что она там m на n, m меньше n, ну и полного ранга, вот, чтобы
не было дополнительных сомнений. Вот, в чем проблема, так вы
думаете? Ну, может, то, что последние условия достаточно
нетривиальные, то есть, ну, не понятно, как перебрать все
такие, а ну, лямбда мю. Ну, смотрите, последние условия
это как раз довольно прямолинейно, оно типа линей систем
линейных уравнений, то есть у нас A t умножается на какую-то
матрицу типа минус единичную, да, вот, и это умножается
на блочный вектор лямбда со звездочкой мю со звездочкой,
и это равно минус c. Это, на самом деле, система линейных
уравнений, она, понятно, что недоопределена, вот, и тут
нам как бы, мы видим как бы две системы, одна система
нам двойственной переменной, другая система напрямую
переменной, они обе недоопределенные, и вот надо понять
теперь, как, что позволяет, что может позволить нам как-то
отсечь лишние столбцы так, чтобы системы стали с квадратными
матрицами и, ну, в отдельной теоремы, которая там будет
говорить, что они так будут невыраженными, вот, ну, пока
мы этого точно не знаем, это некоторые анонсы, анонс
на через там, полтора месяца, наверное, то, что может
заметить относительно сложности разрешения подобного
рода систем, ну, не конкретно, который я выписал в целом.
Так, ну, да, вижу, что какие-то затруднения есть, ну,
смотрите, в чем проблема, это основная. Основная
проблема, собственно, в условиях дополнительной
нежесткости, вот, на этих условиях, потому что они
требуют, по сути дела, перебора 2 в степени n вариантов,
и, собственно, как только вы определяете, какие иксы
у вас не ноль, точнее, какие иксы у вас ноль, вот отсюда
вы можете, ну, их там будет правильное количество,
ровно столько, сколько нужно для того, чтобы разрешить
систему, вот, они будут не ноль, соответствующие
mu станут нулями, вот, отсюда сразу вывалится куча всего,
вот, ну, и, соответственно, потом вы, да, определите те
лямбоды, которые будут соответствовать оставшимся
равенствам, вот, то есть здесь идет перебор, кто ноль,
кто не ноль, это довольно много, поэтому решать это
в явном виде в точности довольно затруднительно,
поэтому делать приближенно, и на этом основаны методы
внутренней точки, про которые мы тоже будем еще
говорить. Так, понятен ли этот момент? Так, ну, каких-то
явных минусов я не вижу, верно, верно, в целом понятно.
Окей, теперь важный момент, что в случае линейного
программирования, подожди, если у нас допустимое
множество прямой задачи не пусто, то выполнена сильная
двойственность, и это напрямую следует из того, что вот
здесь у нас, здесь, вот здесь у нас х лежит в подпространстве,
раз он лежит в подпространстве, то какой-то х неотрицательными
компонентами точно можно будет найти, в силу, ну,
короче говоря, построения подпространств, как он выглядит,
вот, поэтому условия сейтера выполнены, поэтому сильная
двойственность будет выполнена. Часто этот факт, доказывают
изолировано потому что, ну, в общем, можно его доказать
просто расписав аккуратно, расписав аккуратно неравенство в двойственности, вот, ну, сейчас
просто для экономии времени можно как бы сослаться на более общий факт. Вот, теперь следующая теорема,
которая как бы дополняет вот это утверждение, вот, она говорит нам о том, что если, если допустимое
множество в прямой задаче пусто, а в двойственных не пусто, будем разбираться, почему это условие
важно, то двойственное будет неограничено. Так, то давайте D со звездочкой стремиться к плюс
бесконечности. Вот, то есть, смотрите, если тут вот важный момент, что в двойственной задаче,
допустим, множество должно быть не пусто. Вот, оно как бы не, пока не до конца, возможно, очевидно,
почему тут эта приписка важна. Вот, ну и, собственно, это просто к тому, что до этого мы сказали,
что если в прямой задаче не пустое множество, все хорошо, а сейчас смотрим, что будет в пустой
случае, если оно пусто. Вот, то вот такая есть связь между неограниченностью и неразрешим,
ну и недопустимостью между прямыми и двойственными значениями для инопрограммирования. Вот,
соответственно, вы можете... Ну вот, смотрите, давайте посмотрим, вот эти максимумы. Вот,
ну, слушайте, можно на минимум спокойно, то есть, я написал, что плюс бесконечности, чтобы как бы
было коррелировано с тем, чтобы было перед этим написано. Вот, если сейчас в процессе доказательств
нам будет важно поменять, то поменять знак, то там будет просто бесконечности, ничего страшного не
произойдет. Вот, ну и доказывается это все дело довольно изящным, вот, потому что мы пользуемся
ранее полученным фактом, не зря же мы его получали. Вот, и смотрим на допустимое множество в прямой
задаче. Какой вид она имеет? Вот такой. Вот, значит, если это пусто, из этого следует,
Малимив Аркаша, напоминаю, был такой факт на втором или третьем занятии, у нас будет
существовать некоторый вектор P не нулевой, а такой, что B транспонированное на B будет меньше нуля,
а P транспонированное на A будет больше либо равно нуля. Теперь внимательно посмотрим на двойственную
задачу. Да, в двойственной задаче мы можем перейти от максимума к минимуму, просто заменив,
ну, понятно, λ убрав минус. Вот, то есть, можем сформулировать, что у нас двойственная задача
будет минимум λtb, а не максимум минус λtb. При все тех же самых условиях, что a t лямбда плюс
c больше либо равно нуля. Вот, теперь, возьмем какую-то допустимую точку в двойственной задаче. Пусть это
будет лямбда с чертой, допустимая точка в двойственной задаче. Вот, и стартуя от нее, рассмотрим вот
такое вот значение theta p, где theta число больше нуля. Давайте теперь подставим, посмотрим,
что произойдет. Во-первых, проверим, что лямбда с крышкой будет все еще допустимая. Это что такое?
Это лямбда t, так, плюс c, плюс theta a t p. Раскрыли скобки. Вот эта штука в силу допустимости,
она больше либо равно нуля. Далее, a t p тоже больше либо равно нуля, потому что у нас вот выполнено.
И это больше нуля, поэтому это все больше либо равно нуля. Теперь, a с крышкой, транспонированной
на b, это что такое? Это a с чертой, плюс theta p, множить на b. А это, в свою очередь, равняется,
ну, короче говоря, равняется лямбда с чертой, транспонированной b, это какая-то константа,
плюс theta, на p, транспонированная b. Вот p, транспонированная b, у нас меньше нуля. Вот,
и это константа некоторая. Поэтому это все при тесте theta с тремяющимся плюс бесконечности будет
стремиться к милу бесконечности. Вот, получаем неограниченность. Да, ну, учитывая, что у нас d
со звездочкой поменял знак, то мы... Ну да, тут на самом деле надо было хорошему написать вот так,
вот, и картины, чтобы ничего не поменялось совсем. Вот, ну и поэтому, следовательно, там d со звездочкой
будет к плюсу бесконечности стремиться. Понятен ли путь, которым мы все доказывали? Давайте
немножко сожму. Ставьте плюс, если понятно. Так, четыре, пять, шесть. Так, что, шесть? Все? Больше
никому ничего не понятно? Так, о, семь. Ну все, видимо, силы людей всякие. Ха-ха-ха, ладно. Так,
окей. Надеюсь, что все, кто не поставил плюсик, просто не поставили плюсика, ни то, что ничего не
понял. Ладно, теперь давайте посмотрим внимательно на то, зачем нам было нужно вот это вот условие
дополнительное требовать. Ну, то есть не то, что почему оно было нужно, оно было нужно, чтобы мы
могли найти вот эту вот эту вот допустимую точку и от нее отталкиваться. Вот, то есть если бы ее не было,
то мы как бы у нас непонятно было, почему можно было бы так делать. Теперь посмотрим, почему это
может вообще ломаться. Вот, то есть почему может получиться так, что и допустим, множество их прямой
и двойственной задачи окажутся пустыми. Неожиданный поворот. Строили-строили, получили там и там пустое
множество. Непорядок. Вот. Ну, давайте для примера рассмотрим простую задачу. Простым там пример
пустоты в, неправильно, пример недопустимости, наверное, лучше сформулировать, в прямой и
двойственной LP. Вот. Ну, смотрим на такое вот множество. Все будем в 2D делать для
простоты обычно. Все такие факты, они чаще всего в маломерном пространстве очень хорошо иллюстрируются.
х1 меньше или равно минус единице, х2 больше или равно единице и все они, понятно, дело не
отрицательно. Вот. Если приводить все к стандартному виду, то что у нас появится? У нас будет две
так называемые слаг-переменные, дополнительные переменные, которые превращают неравенство в
равенство. И матрица систем будет выглядеть таким вот образом. Да, кстати, давайте это упражнение,
давайте почитайте матрицу системы, что надо сделать, чтобы привести задачу к виду, а х равно b и x
больше либо равно 0. Вот. Какой будет матрица, какой будет вектор b? Давайте я вот сейчас a равно,
пару минут, в общем-то ничего сложного вроде бы нет. Вот. И давайте вектор b буду сюда записывать.
В смысле все не отрицательные? Ну, вот это да, что все переменные, которые у нас будут, будут
не отрицательными. Ну, тут уже и так написано, что они частично больше либо равно 0. Вот. Надо
будет еще такие же ограничения на дополнительные слаг-переменные добавить, и все будет в себе
хорошо. Можно написать матрицу a в чате построчно. Вот. Либо как-то, либо по столбцовой, не знаю,
кому больше нравится. Либо проговорить просто в микрофон, из каких элементов будет первая
срочка состоять. Извините, а почему мы сначала написали, что x1 меньше либо равно минус 1,
а потом сказали, что все x больше либо равно 0? Потому что там был нужен пример пустого
множества. Ну, давайте прочитаем заголовок. Мы строим пример недопустимости в прямой и двойственной
задачи. Вот. Допусти множество в прямой задачи. Оно пусто, поэтому прямая задача недопустима.
Сейчас будем смотреть на двойственную задачу и поймем, почему и двойственная задача тоже может
стать недопустимой. Так, отлично. Я жду все еще, чтобы кто-то проговорил, как будет выглядеть матрица
и вектор. Стоп. А мы только при этом, ну, матрицу только для условий делаем? Только вот эти три условия
переформулируем в виде матрицы? Ну, вот. Вот есть множество, да? Вот вам надо записать это множество,
как функциональные ограничения на вида равенства и вида не равен столько, чтобы x был не отрицатель.
Ну, x это наш вектор, который новый. А, хорошо, понял. Не, я просто подумал, что там x1, x2 в скобочках это склеронпроизведение.
Каких скобочках? И что множество, там, инфинум этого множества или что-нибудь такое. Ну, множество
Вот эта штука, это значит, что x1 запятая 2 больше 0. Нет, это r2. Нет, нет, нет, это r2. Давайте я уточню, да.
x, давайте вот так, из r2. Все, вообще не было разночтений. Склеронпроизведение в угловых скобочках пишем.
В круглых не пишем. Именно по этим причинам. А, ну, давайте в качестве нового x возьмем вектор из r4, x1, x2.
Лучше про матрицу давайте скажем. Просто нам надо дополнительные условия на неравенство. Да, ну, давайте сначала матрицу, а потом их добавим.
Ну, а матрица, мне казалось, тогда будет только на то, чтобы новые компоненты, минус 1, минус x1 и x2, минус 1, чтобы они были соответствовали компонентам x1 и x2, чтобы, типа, они в сумме или в разъединении.
Продиктуйте строки матрицы. Все прекрасно, все правильно. Давайте просто...
Просто сначала нужно, чтобы у вас на самом деле какая-то структура x будет, а от этого зависит строки матрицы.
Ну, вот вы сначала, давайте писать слева направо, да. Вы сначала нет матрицы, потом нет вектора, потом идет правая часть.
Ну, 1, 0, минус 1, 0, кажется. Так, давайте проверю. Нет, 1, 0, 1, 0, похоже все-таки.
Давайте сюда единичку поставим. Так, раз, строчка.
Минус 1 в векторе. В правой части, да? Да.
И ну, 0, 1, 0, минус 1. Что-то не то.
Ну, вот я же говорю, нужно сначала на x согласиться.
Не, не важно, согласились мы или нет, просто в том...
По-разному можно сделать, по-разному можно преобразовать, кажется.
Почему? Ну, хорошо, давайте, давайте обсудим, интересно. Так, какой будет вектор здесь? Диктуйте.
Ну, x1, x2. Так. А дальше, минус x1, минус 1.
Погодите, что это за минус x1, минус 1? У вас же, ну, типа переменная должна быть, какая-то буквка одна.
Что там за минус 1 взялся? Да, но, как бы, я описываю преобразование из вектора, ну, xv2 в векторе xv4, как бы.
А потом, ну, то есть, а условия нам, ну, вот это вот, как раз условия равенства...
Так, еще раз, смотрите, формально вот, вот, вот условия. Вот, надо записать, чтобы было вот так.
Можете вот в таком виде предоставить ответ.
Там, преобразование, все это дело, можно делать все что угодно.
Важно получить вот финальное вот в таком вот виде, чтобы был один вектор, была матрица, была правая часть.
Все, ничего больше как бы не требуется. Вот x1, x2. Тут еще какие-то две букурки должны быть.
Ну, x3, x4, если так.
Так, хорошо, x3, x4, давайте, да. Так, и давайте поймем теперь все реправильно.
А здесь какая будет правая часть для второй спроки?
Тут был минус 1. Ну, давайте проверим. Умножаем. x1 плюс x3 равняется минус 1.
Вроде правильно, потому что у нас изначально было x1 меньше, или, брай, минус единицы.
Мы к нему добавили что-то неотрицательное. Тут у нас, соответственно, будет x1, 2, 3, 4. Все неотрицательное.
Должно быть, по крайней мере. Все хорошо.
Теперь со вторым неравенством, с второй строчкой. x2 минус, почему-то, x4 получается равно минус 1.
Что-то не то. Было изначально x2 больше, либо равно единицы, но, по-моему, вот это неправда.
Я x4 чуть выше. Вот я поэтому как раз про образование описывал. Ну, можешь чуть выше поднять, а то я не...
Могу, конечно, без проблем.
Я предполагал, что x3 это минус 1 минус x1. У нас уже есть x1 и x2. Какие мы получаем следующие? x3, x4.
А x4 это x2 минус 1. А, да, и тогда там не минус 1, а 1 просто должно получиться.
Так, ну давайте 1 поставим. Что, здесь поставим единицы?
Да.
Так, давайте посмотрим.
Так, что получается? x2 минус x4, то есть у нас x2 больше минус единицы. Мы из нее вычитаем что-то положительное и получаем равенство единицы, да?
Да, вроде разумно. Так, поставьте плюс, если понятно, что произошло, и минус, если не очень понятно.
Так, вижу какие-то плюсы. Появляется хорошо. Раз, два, три, четыре, пять. Так, пока все еще только пять.
Так, ну что, кто-то еще хочет спросить по поводу подобных преобразований или может дальше идти? Так, видимо никто не хочет.
Окей. Так, давайте я сотру то, что мы тут проверяли. Ну и вот точно такое. Таким образом у нас записывается наше множество, которое пусто.
Давайте теперь построим множество для двойственных задач. Оно у нас как выглядит? Внимание на экран, что называется. Оно у нас выглядит как A транспонированное лямбда плюс C больше либо равно нуля.
Пока вектор C у нас никакого нет, поэтому давайте сейчас смотреть. A транспонированное лямбда плюс C больше либо равно нуля. Что такое A транспонированное?
Ну, в общем, транспонируем матрицу, я думаю никаких проблем тут не возникнет. Значит, это будет C1 плюс лямбда 1 больше либо равно нуля. C2 плюс, да, плюс лямбда 2, правильно же, да, больше либо равно нуля. C3 плюс лямбда 1 больше либо равно нуля.
И C4 минус лямбда 4 больше либо равно нуля. Вот такая замечательная система. Вот, и давайте посмотрим внимательно на то, что у нас. Ой, что за лямбда 4? Лямбда 2, простите.
Что у нас здесь вырисовывается? Вырисовывается, что одновременно будет выполнено, что лямбда 2 меньше либо равно минус C2 и лямбда 2 больше либо равно C4.
Отсюда следует, что может случиться так, что вектор C будет состоять из таких чиселок, что одновременно вот эта штука будет давать постоянную множество.
Ну, например, там, что, C2 будет равно C4 равно 1, например, да? То есть лямбда 2 одновременно меньше минус 1, но больше 1. Кажется, это не очень хорошо.
Поэтому за счет того, что в допустим множестве для двойственной задачи не последнюю роль играет вектор C, который у нас остался в степени свободы некоторое,
который не участвует в определении допустима множества в прямой задаче, то при его как бы некоторым случайном неудачном выборе может получиться так, что в двойственной задаче допустим множество также останется.
Понятен ли пример? Так, что-то примера стало понять только двум студентам. Интересно. Интересно, что непонятно остальным.
Так, ну что? Какие вопросы вы дали предложение? Ну, вроде вопросов таких громких нет.
Да, значит, это были некоторые факты про линейное программирование, мы к ним еще через некоторое время вернемся.
Теперь, собственно, давайте перейдем к конической двойственности. Для этого надо сначала поставить задачу исходную, используя общенную неравенство через конусы.
Все то же самое, в общем-то. Только теперь h' от x будет не просто меньше либо равно, а меньше либо равно в смысле некоторого конуса.
И для такого рода задач, ну, напоминаю, что это значит, что у нас был элемент больше либо равен нуля в смысле конуса, было равносильно тому, что он в этом конусе лежит.
Это было там, на втором или на третьем, на третьей лекции, когда мы про конусы начинали, у нас было обсуждение.
Вот. Тогда для таких задач все будет то же самое абсолютно, все те же самые условия оптимальности.
Погодите, с оптимальностью. Давайте сейчас с грызжаном разберемся. Грызжан будет абсолютно такой же, уже писал сегодня.
Вот. А двойственность, значит, изменится чуть-чуть. Вот теперь mu будет больше либо равна в смысле сопряженного конуса.
Это будет, это необходимо ровно по тем же причинам, по которым это было необходимо, когда у нас был конус rn+.
Вот. Что мы просто подбираем такие коэффициенты, чтобы их скалярное произведение было строго и отрицательно.
Вот. А это будет выполнено, когда у нас mu будет лежать в конусе.
То есть для, ну, вот у нас типа есть такая вот штука, да. И нам нужно, чтобы это было больше либо равно нуля.
Вот. При этом, а, наоборот, меньше, чтобы эта штука была, простите, меньше либо равно нуля.
Ну, потому что мы из f должны что-то вычесть. Вот.
При этом мы знаем, что минус h от x лежит в k.
Это значит, что mu transponable h от x больше либо равно нуля.
Только давайте я вот так это запишу, чтобы было попроще.
Минус h от x. Вот.
И нужно найти такие mu, для которых это будет работать.
Ну, раз выполнено вот это, то вот это неравенство будет работать тогда, ну, тогда и только тогда,
когда mu будет лежать в сопряженном конусе.
Понятен ли этот переход?
Все помните, что такое сопряженный конус?
Это я тут так терминами бросаюсь, может быть, уже все забыли.
Напомните.
Повторить, пожалуйста, как называется этот класс задачи?
Ну, название.
Обобщенное неравенство.
Ну, неравенство только обобщенное в смысле конуса.
Ну, в смысле, ну, в общем, у него нет какого-то, да, такого, прямо уж названия имени собственного, вот.
Но некоторое название, которое подчеркивает отличие от того, что было раньше.
Понятно. Спасибо.
Мы хотели пояснять более как-то детально, расписывать все переходы, которые были на прошлом занятии,
только с учетом того, что у нас теперь есть вот это вот условие,
а не просто, что h at x у нас меньше либо равен нуля.
Да, нет.
Нужно, не нужно.
Не нужно.
Окей.
Ну, и тогда, как at переписывается тоже достаточно прямолинейно,
у нас будет там ax со звездочкой равно b,
h gt at x со звездочкой меньше либо равно в смысле конуса нуля,
mu со звездочкой больше либо в смысле сопряженного конуса нуля,
там дополнительная жесткость, как была, так и останется,
на все выкладки это не повлияет никак,
ну и соц. нарастал граждан тоже не изменится.
Вот, то есть единственное отличие, которое происходит, ой,
оно происходит вот здесь, вот здесь, ну и все, наверное, да?
То есть в том, как неравенство между собой взаимодействует.
Вот, ну и отсюда как бы следует у него более-менее универсальный способ построения двойственных задач.
То есть если у нас задача вида коническая форма,
то есть мы минимизируем линейную функцию с афинными ограничениями,
и у нас x больше либо равен нуля в смысле конуса,
вот, то опять же, что мы делаем?
У нас будет жат лямбда, которая есть инфимум Лагранжана,
и тут я активно буду использовать то, что,
можно вот так написать,
x больше либо равен конусу,
больше либо равен нуля в смысле конуса,
то, что мы сегодня уже обсуждали.
А здесь, соответственно, x и лямбда,
мы понимаем, что инфимум для c плюс at лямбда,
спонированное x,
минус лямбда tb,
и это все для такого x,
равно минус лямбда tb,
плюс инфимум от этой штуковины.
Ну, давайте, x лежит в конусе, да?
Вот, и тут мы внезапно понимаем,
что все это, весь этот инфимум будет конечным,
только если эта штука снизу подпереть нулем.
Вот, снизу можно подпереть нулем,
только если у нас c плюс,
то есть это равняется минус лямбда tb,
при условии, что c плюс at лямбда
лежит в сопряженном конусе.
Ну, если лежит в сопряженном конусе,
это значит, что выражение под инфимумом
больше либо равно нуля,
значит, инфимум 0.
Если мы рассмотрим какой-то, ну,
рассмотрим ситуацию,
при которой c плюс at лямбда
не лежит в сопряженном конусе,
это значит, у какого-то x
выражение будет отрицательно, это значит, что умножив этот х на положительное число, мы
получим элементы с конуса и минус бесконечности. ну я не знаю, я надеюсь, понятно такое доказательство,
почему это в обе стороны работает. и соответственно, минус бесконечности иначе. в итоге двойственная
задача формулируется абсолютно прямолинейно. мы максимизируем минус лямбда tb при условии,
то c плюс a t лямбда лежит в спряженном конусе. то есть все то, что мы делали до этого, если у
вас задача в таком виде, автоматически позволяет строить двойственные задачи. вот зачем это все
было надо, в частности конуса, самоспряженные конуса, спряженные конуса, двойственность. ну зачем
нужна двойственность, мы прошлый раз обсудили. зачем нужны были конуса и представление задачи
в конической форме, вот сейчас я надеюсь понятно. то есть вы по сути дела, один раз проделав общую
выкладку, делегируете все вспомогательные операции, которые мы делали до этого, соотношение
между конусом и сопряженным к нему. понятно ли это? или есть какие-то вопросы по этой части?
на старте плюс, если все понятно, можно идти дальше. пока только четырем человек,
людям понятно. если что-то непонятно, в каком-то месте не понимаете, почему мы выполнили то или
иное переход, пожалуйста, сообщите об этом. иначе дальше будет не очень приятно со всем этим
работать, не понимая почему это все корректно. реакции новой никакой не появилось. раздавительно.
так, ну окей. к сожалению, пока нет запроса, очень сложно как-то что-то поменять или дополнить как-то.
ладно, давайте теперь рассмотрим задачу полуопределенной оптимизации, которую мы уже
частично говорили, и посмотрим какая двойственная будет для нее. а заодно обсудим ситуацию при
которой у нас выполнена... у нас и прямая и двойственная сдача имеют решение конечные,
но зазор двойственности положительный, хотя сдача в пуку. опять поиграем с тем, что условия
сайтера будут нарушаться, только если в прошлый раз оно нарушалось и у нас получалось, что в множестве
лагран же просто не существует оптимальных, которые условия как-то удовлетворяют. ну и если там
построить двойственную, то там будет она неограничена. сейчас посмотрим на пример, когда все
конечное, но зазора не ноль. вот такое тоже бывает. ну начнем с формулировки задачи с dp, с mdefinite
programming problem. надеюсь, вы помните обозначение. самый общий тип, наверное, задач, который более
или менее на практике встречается. вот и давайте запишем как это все выглядит. минимизация следа
произведения матриц при условии, что следы от произведения нашей целевой матрицы на матрицу
матрицы b. и сама матрица, понятное положение, полуопределена. вот такая вот задача. все почти
так же, как было в линейном программировании. был вектор c, стал матрица c. было скалярное
произведение для векторов, стало скалярное произведение для матов. тут обозначено в смысле rn,
в смысле sn. были строки матрицы aita и стали отдельными матрицами aita. но вектор b как было,
так и остался. был конус rn+, стал конус sn+. аналогия. то есть вот это вот часть lp,
это часть sdp. ну и соответственно как двойственно встроить? плюс-минус так же. можно воспользоваться,
давайте тоже проделаем все эти манипуляции с угрожаном. поскольку здесь ограничение вида
матрицы положить на полуопределена, мы знаем уже, что в этом случае двойственный получается
сопряженный конус, то тут может или Lagrange будет тоже некоторая матрица, которая будет положить на
полуопределена. сейчас мы это увидим. ну давайте Lagrange на чему будет равен? след плюс сумма лямда
it на след от aita x минус bita. ну там минус тоже понятно. минус скалярное произведение x на лямду.
теперь если мы как бы соберемся вместе, то будет понятно, что это в точности равно,
ну понятно, минус лямда it, bita вынесется. минимум по x большому. останется что? останется плюс
сумма след матрицы x умножается на что? на c плюс лямда it aita минус лямда. воспользовались
линейностью следа и соединили все, что касается матрицы x в одно выражение. кажется я ничего не
забыл. ну и опять мы видим, что вот эта штука она линейна, поэтому потенциально можем улететь в
минус бесконечность, поэтому g от лямда маленькой лямда больше получается. будет минус лямда tb при
условии, что c плюс aita it минус лямда равно нулю. минус бесконечность иначе. ну и соответственно
мы максимизируем минус лямда tb при условии, что c плюс, плюс сумма лямда it aita равны лямде и
лямда у нас не отрицательно определяно. давайте я сразу затру. скажу, что вот эта штука вот так.
получили вот такую вот задачу, которую первое преобразование, которое можно сделать, это
сделал взаимопеременных. а зачем взаимопеременных? просто давайте перепишем это все к минимуму,
то есть минимум лямда tb и те же самые условия. вот короче вот так. так сейчас секунду прошу прощения.
так все вернулся. при условии, что c плюс лямда it aita будет не отрицательно определено. вот то есть
смотри, что произошло. была исходная задача на матрицу двойственно оказывается уже на вектор rm.
при этом ограничения сохранились в том, ну ограничения в задаче остались ограничениями в смысле
матрицы. все было бы здорово, если бы эта штука не отличалась от линейного программирования в том,
что здесь все-таки слабая сильная двойственность не гарантируется. и не гарантируется она ровно
потому, что вот это вот условие не всегда выполняется. тут пространство такое вот не получается,
как оно было для линейного программирования. поэтому гарантии на то, что найдется такая матрица
строго положить на определенную, уже никаких нет. и сейчас мы собственно посмотрим, как это все
сломается. вот рассмотрим вот такую вот задачу. пока я тут пишу, если все понятно поставьте плюсик,
если есть какие-то вопросы по выкладкам, то пожалуйста поставьте минус или спросите что-нибудь.
вижу 5 плюсов. окей, спасибо. вот такая вот задача. мы ее можем благополучно, понятно дело,
переписать как там максимизация минус x2, чтобы вернуться к задаче, к которой мы
собственно здесь пришли, чтобы потом сказать, что если мы будем строить к ней двойственную,
то мы получим исходную. полезное упражнение проверить, что действительно будет так. так давайте
я воспользовался тем, что могу все стереть, пишу максимум минус x2. давайте проанализируем,
какое здесь допустимое множество. поскольку у нас здесь вот такой вот значок, ой хотел сказать был,
да, все еще есть. нам надо проверить не отрицательно определенность такой матрицы
по критерии челюсти. давайте проверять. x2 плюс 1 больше либо равно 0, x1 больше либо равно 0,
а дальше получается, что если посмотрим на вот этот вот минор, то здесь получается,
что минус x2 в квадрате больше либо равно 0, то есть x1 в квадрате меньше либо равно 0.
следовательно x2 только 0. то есть p со звездочкой здесь равно 0. это наша получается x2 равно 0,
допустимая точка вот такая. и оказывается, что если мы сейчас вот это вот x2 подставим,
то у нас в общем начнет ломаться строго положительная определенность. тоже можно это
проверить. теперь давайте запишем, как будет выглядеть двойственная задача. сейчас будет
следить за руками. не очень просто все эти преобразования проделать, но давайте. так,
чтобы это понять, надо выписать какая матрица c и какие матрицы аиты у нас были. матрица c у нас
тут вот такая. сейчас вот если будет непонятно откуда берутся эти матрицы, пожалуйста тоже
сообщите. a1 будет вот такой, ну и a2 соответственно будет вот такой. а что? вектор b соответственно
будет равен 0-1. понятно ли, как я вытащил эти все константные матрицы из постановки задачи
двойственной? глядя просто на соотношение между тем, что сейчас будет закрашено в зеленый и того,
что окрашено в оранжевой. если нет, поставьте минус. если да, поставьте плюс. похоже на черную
магию. никакой магии нет. ну смотрите. вот была у нас вот такая матрица. да, что-то как-то,
кажется, в новую тему я не успел начать. ну ладно. x2 плюс 1, 0, 0, 0, x1, x2, 0, x2, 0. вы ее как можете
представить? она равна. сначала это константная матрица. это 0. плюс x1 умножается на что-то и плюс
x2 умножается на что-то. вот то, что это умножается, это a1, это a2, это c. ну я верю, вы можете как бы
соотнести, что на что надо умножить, чтобы получить такие константные матрицы. а b? ну хорошо,
смотрим на b. ну и что? максимизируем минус с ляму транспонированной на b. у нас максимизируется
минус x2. это значит, что из нашего вектора x1, x2 вырезается вторая компонента. то есть на какой
вектор надо умножить, чтобы получился x2? ну на 0, 1, наверное. тут просто смотрим на задачу и
явным образом понимаем, из чего она собирается. то есть примерно то же самое делает солвер,
который мы не начнем. в следующий раз начнем и закончим. просто разбирает задачу на ингредиенты
и правильный образом переупаковывает. для того, чтобы можно было эффективно решить. так,
стала ли магия менее черной, скажем так? прекрасно. все, разобрались. ура. ну теперь давайте возвращаться
к исходной задаче. то есть мы ищем, будем искать некоторую матрицу, положить на полу
определенную. целевая функция это след от c на эту матрицу. ну след от умножения такой матрицы
c на другую матрицу. я думаю это очевидно, что пусть будет у. наша целевая переменная, целевая
матрица в двойственной. ну будет y1. то есть след от c на y равняется y1,1. потом скалярные
следы от a1 на x будут равны b1. поэтому при умножении на a1 получается y2,2. и при умножении
на a2 получается y1,1 плюс y3,2. и вроде бы y3,2 плюс y2,3. и это все равно минус 1. ну это будет
равно нулю. потому что b1 равен нулю, это b2 равен единице. так, сейчас единицы давайте я еще
раз аккуратно проверю. что-то мне не нравится, секунду. так, что мы тут делали? у нас получился
минус лямбда ит. и мы это максимизировали. при вот таком условии, да, тут все хорошо. а потом
был максимум минус b на лямбда т. и тогда у нас b получился 0,1. ну ладно, вроде все хорошо.
давайте тогда продолжим. да, сейчас правда есть риск, что мы получим не тот знак. сейчас она будет
внимательно подумать, как так вышло. окей. так ладно, давайте сейчас пока оставим как есть. а
нет, не как есть. все, я понял. я немножко напутал, прошу прощения. тут все надо вот так. то
сейчас ничего не поменяется принципиально. вот минимум оставим x2 и минимум x2 перепишем как
минус максимум. кажется минус x2 должен быть вот так. вот сейчас поймем, почему это будет важно. ну ладно,
вроде все плюс-минус честно. вот максимум минус x2 и b у нас тогда 0,1. если мы 0,1 умножаем на x1 x2
получаем x. да, тут стоит минус. это соответственно тому, что было выше. да, вроде все в порядке.
окей. теперь и тут соответственно единица стоит. давайте теперь посмотрим. то есть и наша матрица
y она вот такая. ну и у нас есть эти ограничения. давайте их аккуратненько распишем. y1,3, y2,1,2,2,2,3,3,1,3,2 и 3,3.
вот. что мы можем отсюда вытащить? ну во-первых мы можем вытащить, вот посмотрев на вот этот вот
минор, то y, да это все вот так. y2,2 умножить на y3,3 минус y2,3. ну тут можно квадрат поставить,
потому что там все симметрично должно быть. больше либо равно нуля? это за нуляется, потому что y2,2
0. вот. следовательно y2,3 равняется y3,2 тоже 0. отсюда следует, что y1,1 равняется единице. вот из
вот этого условия. вот. а мы его как раз таки пытаемся максимизировать. минимизировать неважно.
изначально мы его минимизировали. вот. получилось единица. до этого у нас получился 0. вот. и теперь
внимание вопрос, где мы потеряли минус? вопрос важный, потому что сейчас у нас получилось что-то,
что противоречит общей теории. вот. и давайте сейчас, я думаю, мы это благополучно сейчас
разрешим этот вопрос. если внимательно посмотрим на то, как у нас собиралась матрица, видимо,
да? то есть, ну не матрица, а как мы вот эти преобразования все делали, потому что видимо
что-то здесь со знаком пошло не так. давайте разберемся. это в общем-то кажется несложно.
получили вот такой вид. мы максимизируем минус a t лямбда b. вот. если мы сделаем замену
переменной, скажем, что минус лямбда у нас то же самое, что лямбда, то это все станет максимум
лямбда tb при условии, что c минус му лямбда итых аитых больше либо равно нуля. а дальше,
а дальше мы можем вернуть обратно, заменив переменную на, ну воспользуешься тем,
что максимум перейти, записать максимум через минимум. вот. и как раз-таки такая запись нам
даст минус лямбда tb. только теперь, так где-то что-то потерялось, по-моему. будет здесь,
наверное, минус и здесь останется плюс. вот. тогда у нас, короче говоря, задача сделать так,
чтобы, то есть все будет работать тогда, когда мы сможем показать, что на самом деле b должен
быть равен минус единичке. вот. то есть минимизация чего-то линейного при условии, при тех же самых
условиях. вот. просто если как раз-таки b будет равен, тут будет минус единица, то здесь будет
тоже минус единица, и у нас все получится. вот. так. 10.21. давайте я тогда, наверное, чтобы все было
аккуратно, в следующий раз начну с этого примера и его как-то более аккуратно поясню. вот. и как бы
основной результат, который будет до конца получен в следующий раз, будет заключаться в том,
что, смотрите, у нас случилось, что, так, где-то я тут что-то решал, что p со звездочкой, которое было
изначально, это 0. вот. а мы построили двойственную задачу и получили что-то, что не 0. ну, минус 1 до
конца получен в следующий раз. вот. сейчас как-то немножко сумбурно получилось. вот. и таким образом,
у нас зазор двойственности d со звездочкой минус d со звездочкой получил строго больше 0. то есть
для выпуклой задачи мы построили пример, в котором, в следующий раз до конца доделаем, будет
выполнено, что оптимальный зазор между решением прямой двойственной задачи оказывается положительным.
понятно ли то, что мы ожидаем получить до конца в следующий раз? вот. это да. или не очень понятно,
зачем мы все это делали? вот. то есть отсутствие выполнения условия слейтера может приводить не
только там к неограниченности двойственной и отсутствию множества лагранжа, но и к тому,
что вы как бы каждую задачу по отдельности можете решить, а решения у вас как бы оптимальные
значения совпадать все равно не будут. вот. такое тоже возможно. так. ну что? есть ли вопросы? или
все понятно? будет менее. так. если что-то не понятно, тоже, пожалуйста, поставьте минус,
я подумаю над тем, как поподробно по понятиям объяснить. так. ну. вроде вопросов нет. тогда
давайте на сегодня закончим. всем спасибо за участие и вопросы, которые были. в следующий раз
тогда обсудим solver и начнем числые методы уже быстренько. там. градиентная спуска, все такое. вот.
в общем перейдем немножко к коду, посмотрим как это все работает на практике, каким образом все
применять. ну это будет уже конец октября, два месяца на теорию, ну два месяца на практику. вроде
плюс-минус укладываемся в график. вот. все. всем спасибо и до следующей недели.
