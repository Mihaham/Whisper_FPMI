У нас с вами получается, кроме сегодняшней, еще две лекции. Третьего и десятого,
поскольку десятого – это учебный день. Вот, так что, может, сегодня так плохо.
Так, значит, мы в прошлый раз остановились на теореме Калмогорова-Хищина, повторю ее.
Рассматриваем последствия независимых случайных величин, вводим вот такую частичную сумму
центрированных случайных величин. Ну, это, значит, означает, что мы от ожидания подразумеваем
существование. И нам известно про эту последность, что сумма из дисперсии сходится, ну и, естественно,
подразумеваемых существования. Тогда оказывается, что существует такая случайная величина S
от Омега, такая, что эти частичные суммы сходятся к ней почти на верное. Ну, предел частичных сумм рядом
и обычно или всегда вот так обозначаем. Это просто обозначение, это не утверждение. Так, ну давайте
докажем. Давайте введем такое двухындексное множество. И он большой, он малый. Ну, так оно вообще в
исходном вероятностном пространстве как бы. Значит, максимум Sn плюс K минус Sn, когда K изменяется от одного до Н
большого, вот этот максимум больше Эпсилон. Вот такие. Это определение множества. Ну, тут еще есть
Эпсилон, но оно одно и то же, поэтому, ну по-хорошему, надо бы здесь это было Эпсилон еще прилепить,
но не буду этого делать. Вот. Что про эти множества можно сказать? Ну, во-первых, для любого N малого
эти множества расширяющиеся. А еще что можно сказать? Что их объединение в счетном числе по индексу
N большое. Есть вот такое множество. Супремум по K больше нуля Sn плюс K минус Sn больше Эпсилон.
Ну, так не вызывает, да, сомнений? Если Супремум больше Эпсилон, значит, при каком-то Омега,
входящем в это множество, Sn плюс K минус Sn оказывается больше Эпсилон. Ну, это K обязательно при
каком-то достаточно большом N вот сюда войдет и, собственно, Омега войдет и в это множество,
ну и в обратную сторону. Если это имеет место, то уже, заведомо, это имеет место. Вот. Ну, собственно,
теперь мы хотим найти вероятность вот этого множества. Ну, или точность. Ну, да, вероятность.
Или оценку вероятности. И по теореме о непрерывности вероятности, это есть предел при N большое,
стремящемся к бесконечности, P, A, N большое, N малое. Для любого N это все имеет место, верно.
Так, ну давайте этот P, A, N посмотрим. Значит, вероятность, еще раз перепишу, P, A, N,
большое, N малое равна вероятности того, что максимум, а вот здесь я перепишу вот так.
Сумма кси gt, центрированная g равно от n плюс 1 до, точнее говоря, чуть по другому индексу. Тут
напишем g плюс n, тогда g изменяется от 1 до n большого. Вот так, да. Больший епсилон.
Вот эта разность, это вот кусочек как бы этого ряда. А максимум, естественно, берется по,
извините, не точно, по k, а вот k изменяется от 1 до n. Вот так вот. Правильно, поправьте. Так,
а вот эту вероятность мы с вами как-то уже, по-моему, оценивали. Чем она оценивается,
по какому результату нашему? Полеммика у Могорова совершенно справедлива. И это меньше или равно,
меньше или равно, ну, там одна из форм, так сказать, верхней грани или ограничения верхнего,
это сумма дисперсий xi g плюс n. Вот теперь же g равно от 1 до n большое. Делить на епсилон квадрат.
Вот. Ну, если мы эту n устремим к нулю, бесконечности, n большой устремим к бесконечности,
то получим единица на епсилон квадрат и вот хвостик ряда d. Ну, тут дисперсия
xi g от n плюс 1 до бесконечности. Правильно, да? Ну, и мы видим, что вот эта вот вероятность
стремиться к нулю при n малой, стремящемся к бесконечности, правильно? Правильно? Это сходящийся
ряд n малую устремить к бесконечности, будет хвостик оставаться. А вот стремление к нулю,
вот только тут, слушайте, я написал. Тут вероятность надо. А вот когда такая вероятность стремиться к нулю,
это что значит? Это сходимость какая? По? По каши. Это сходимость по каши, да? Сходимость
почти наверное по каши. Помните, мы с вами доказывали про сходимость почти наверное,
что она фундаментально по каши. Ну и, собственно, сходимость по каши, мы с вами знаем, как раз
означает существование измеримого предела, то есть вот этой самой s большое от омега. Ну,
собственно, и все доказательства. Ну, не можем пройти мимо пару следствий. Значит,
теорема, у нее такое название, о двух рядах. Кого теорема-то? Калмагорова.
Теорема гласит следующее. Пусть у нас опять же есть последующий независимых случайных величин,
известно про нее, что ряд из мат ожиданий сходится и ряд из дисперсий сходится. Тогда утверждение
теоремы, что ряд из ксиэнных сходится почти наверное. Обратите внимание, тут уже нет
центрированности, просто ряд из ксиэнных сходится почти наверное. У этой теоремы есть как бы и второе
утверждение, если все ксиэнные с вероятностью единицы ограничены, равномерно ограничены,
то есть сходимости почти наверное, следует сходимость вот этих двух рядов, но мы докажем в
одну сторону, потому что уж ничего нам не стоит это. Итак, согласно теореме Калмагорова-Хинчина,
вот такой ряд ксиэнцентрированная, который на самом деле есть ксиэнная, минус мат ожидания,
но поскольку это предел случайно увлечена, то случайно увлечена меньше бесконечности почти наверное.
Ряд из е ксиенного сходится, просто безпочти наверное по условию, но и отсюда следует,
что ряд из ксиенных сходится почти наверное. Теорема о двух рядах. Следующая теорема
называется теоремой о трех рядах, ну и естественно тоже Калмагорова по-английски.
Значит все то же самое, ксиэнная последовательность независимых случайных величин. И существует такое
число С, ну больше нуля. Такое, что вот если мы введем такую случайную величину, ксиэнная с индексом
С по следующему правилу, она просто равна ксиэнной, если ксиэнная по модулю меньше или равно С,
и ноль если ксиэнная по модулю больше С. Вот такая случайная величина называется усеченной,
ну естественно так сказать по построению. И представляет из себя удобный теоретический прием,
введенный Калмагоровым. Вот и так значит пусть у нас есть последовательность независимых
случайных величин, при некотором С мы вводим последовательность усеченных случайных величин.
И вот про эти усеченные случайные величины известно следующее, что сумма из мат ожиданий ксиенного
сходится. Сумма из дисперсий усеченного сходится. И еще вот такой ряд сходится. Вероятность того,
что ксиэнная по модулю больше С. Знаете, это все равно, но немножко не привычно мне. Давайте вот так,
знак равно так сказать вот так. Меньше С и больше равно. Ну конечно это ни на что не влияет.
Так, и еще известно, что вот такой ряд сходится. Тогда утверждение теоремы состоит в том, что уже
не усеченный, а исходный ряд сходится почти наверно. Формулировка. Значит, ну как бы понятен прием.
Для усеченного ряда мат ожидания всегда существует, точнее для усеченной случайной величины. Дисперсия
всегда существует. Исследовали ряд. Если вот такому свойству удовлетворяет, то значит можно
и происходный ряд сказать, что он почти наверно сходится. Верное и обратное. Для равномерно
ограниченных с вероятностью 1 случайных величин ксиэнная. Исходимости этого ряда. Вот эти три
ряда сходятся для любого С. Для любого С. Но мы докажем в одну сторону. Значит, ну во-первых,
из теоремы о двух рядах следует, что вот такой ряд сходится. Ну меньше бесконечности почти
наверно. Усеченный ряд сходится. Потому что для усеченных случайных величин мат ожидания
и дисперсии сходится. А теперь давайте посмотрим, что это за событие ксиэнная больше или равно С. Ну
просто из определения видно, что ксиэнная по модулю больше или равно С. Это эквивалент на событию,
что ксиэнная не равно ксиэн усеченная. Не равно, да? Смотрите, вероятность событий ксиэнная не
равно ксиэн усеченная. Ряд из этих вероятностей сходится. Что отсюда следует? Лемма барреля
Вот настало время нам воспользоваться всеми теми знаниями, которые мы тут получали. Из
леммы барреля кантелли следует, что вот это событие ксиэнная по модулю больше С, то есть ксиэнная
не равно ксиэнная усеченная, происходит конечное число раз с вероятностью единица. То есть каждое
порождает последовательность ксиэнная, каждое омега порождает последовательность ксиэнная С и
эти две последовательности для почти всех омира обладают тем свойством, что ксиэнная
не равно ксиэнная усеченная конечное число раз, а два ряда, которые различаются только конечное
число членов, конечно одновременно сходятся или расходятся. Вот и всё.
Это довольно серьезные теоретические результаты,
но хочу обратить внимание, что накопленных нами знаний
хватило для того, чтобы в две строчки их доказать.
С теоремы Хинчина и очевидными выводами из нее, коими являются
теоремы о двух и трех рядах, мы заканчиваем и возвращаемся
к нашей тематике, связанной с Законом Больших Чисел.
Напомню, что мы с вами исследовали свойства случайных последствий,
которые называются Законом Больших Чисел.
Попросту это означает, что средние значения концентрируются
вокруг мат ожиданий.
И мы получили ряд результатов, достаточных условий, критерий
и Калмогорова, необходимые достаточные условия для
выполнения Закона Больших Чисел.
Следующее свойство случайных последствий, которые мы
рассмотрели, это так называемый усиленный Закон Больших
Чисел.
Усиленный Закон Больших Чисел.
Он называется усиленный, на самом деле, просто потому,
что в нем сходимость по вероятности заменяется
почти на верное.
Итак, для последствий КСН, если для последствий КСН
существует такая числовая последствия АН, такая, что
КСН среднее минус АН сходится к нулю почти на верное, то
мы говорим, что для данной последствия выполнен усиленный
Закон Больших Чисел.
Интерес наш понятен, мы тоже хотим указать какие-то
условия на случайные последовательности, при которых выполнен усиленный
Закон Больших Чисел.
И в этой области существует две главные теоремы.
Одна называется первая теорема Калмогорова, ну а вторая
теорема Калмогорова.
Перед тем, как бы к ней перейти, давайте опишем условия,
в которых мы работаем.
Значит, первый случай, который мы рассмотрим, это когда
АН, как и в Законе Больших Чисел, это математическое
ожидание, КСН среднее, тогда условия выполнения Закона
Больших Чисел, мы по аналогии, как и просто Закона Больших
Чисел, перепишем так.
Среднее значение случайных величин, у которых мы вычислим
от ожидания, будет стремиться к нулю, только теперь почти
наверное.
Вот.
Мы хотим получить какое-нибудь условие, достаточное для
того, чтобы вот такая сходимость выполнялась.
Значит, вопрос?
Здесь-то?
Прошу прощения, да, к нулю.
Да.
Вот.
Значит, ну и вот, собственно, первая теорема Калмогорова,
она про это, но мы, правда, докажем чуть более общий
результат, чем теорема Калмогорова, а теорема Калмогорова
будет следствием, первая теорема Калмогорова.
Значит, давайте вспомним из математического анализа
такой результат, Леммабеля, по-моему, называется.
Вот пусть у нас есть две последовательности,
хн и bn.
Про хн известно, что ряд из хн сходится, а bn – это
такая монотонно возрастающая последовательность, не
отрицательная, положительная, которая сходится к плюс
бесконечности.
Вот если две таких последовательности у нас есть, то тогда единица
делить на bн сумма хкт и bкт, k равно от 1 до n, стремится
к чему?
К нулю, коллеги, при этом стремяйся бесконечности.
Известен вам такой результат из математического анализа?
Не сталкивались?
Ну, несложный результат, не буду тратить время на
его доказательства.
Вот.
Ну и давайте теперь рассмотрим, возьмем вот такую последовательность
хн, это у нас будут независимые случайные величины, и введем
новую последовательность случайных величин, это n,
которая равно хн центрированная делить на bн, просто новую
последовательность.
Ведем вот такую.
Ну и давайте потребуем или рассмотрим такой случай,
когда сумма дисперсии это n, которая на самом деле
равна сумме дисперсии хн делить на bн в квадрате,
сходится.
Пусть такой ряд сходится.
Пусть.
Тогда отсюда следует, что ряд из это n, который
есть на самом деле ряд из кси n центрированных делить
на bн, он у нас тоже сходится, почти, наверное, и вот на
этом множестве, почти, наверное, с вероятностью единицы,
что и сходится вот на этом множестве, давайте рассмотрим
вот такую вот величину.
Единица делить на bн, сумма это kt умножить на bkt, k равен
единице до n.
На множестве, где вот этот ряд сходится, а еще раз
это множество меры единицы, на этом же множестве вот
эта величина будет стремиться к нулю, вот полемиабеля
прен, стремящаяся к бесконечности.
Понятно, да?
Ну, осталось, что называется, подставить, то есть это
то же самое, что единица на bн, сумма, кси, kt, единица
до n, кат, единица на n, стремится к нулю, почти, наверное.
Правильно, да, потому что это kt, кси, kt делить на bkt,
bkt сокращается, они у нас не равны нулю, получается
такая штука.
Ну, итак, мы с вами доказали следующий результат.
Есть ли вот такой ряд для последствий независимых
случайных величин и некой последствий bн монотонно
возрастающей сходится, то тогда вот такая величина
стремится к нулю, почти, наверное.
Чтобы получить теорему Калмагорова, осталось положить bn, это
аж здесь, на равно n, и мы получаем теорему Калмагорова,
первая, вот здесь, первая теорема Калмагорова.
Если для последствий независимых случайных величин вот такой
ряд сходится, то отсюда следует, что кси, n, центрированная
средняя стремится к нулю, почти, наверное, сходится
к нулю, почти, наверное.
Вот первая теорема Калмагорова, достаточно условия, достаточно
условия для последовательности независимых случайных
величин, и вот для такой последовательности а n выполнен усиленный закон
больших чисел.
Понятно?
Так, значит, дальше.
И вторая теорема Калмагорова, вторая теорема Калмагорова.
Вторую теорему Калмагорова я сформулирую, но докажу
в следующий раз, чтобы, ну, сейчас уже ближе к концу
семестра дать максимальный материал, чтобы вы могли
там задачи решать и так далее.
Значит, вторая теорема Калмагорова, вторая теорема
Калмагорова гласит, пусть ксиенная последствия независимых
одинаково распределенных случайных величин, то есть
мы ищем условия выполнения усиленного закона больших
чисел для последствий независимых одинаково распределенных
случайных величин.
Если ксиенные одинаково распределены, то в отожидании
ксиен среднего чему равно, раз они одинаково распределены?
Ну просто в отожидании кси, да, без индекса.
Вот, так вот, если ксиенные независимо распределенные
случайные величины, то, значит, если существует
А такое, что ксиен средний минус А сходится к нулю
почти наверно, или для того, чтобы ксиенная минус А для
какого-то А сходилась к нулю почти наверно, необходимо
и достаточно, чтобы существовало математическое ожидание
кси, равное как раз вот этому А.
Ну или там, чуть по-другому, если у вас есть последствия
независимых одинаково распределенных случайных
величин, для которых существует мат ожидания, то среднее
значение сходится к этому мат ожиданию почти наверно,
и наоборот, если вы установили, что среднее значение сходится
к какому-то числу почти наверно, то это означает,
что у кси существует мат ожидания в точности равная
этому числу.
Вот вторая теорема Колмогорова.
Значит, у нее такой вот теоремы классическое колмогоровское
доказательство, немножко, так сказать, не в две строчки
оно получается, но, тем не менее, с удовольствием
я вам его расскажу, потому что это, ну, как бы, просто,
как бы, красиво, да.
Вот.
Значит, это за мной должок.
Итак, мы с вами, ну, за последние там лекцию, пару лекций изучили
такое свойство вероятностной меры, как сходимость или
концентрация средних значений вокруг мат ожиданий.
Я в самом начале курса говорил, что это, ну, что как бы, основные
результаты теории вероятности, отличающие ее от просто
теории меры, это то, что в ней устанавливаются некоторые
факты концентрации вероятности меры для, ну, каких-то средних
или специальным образом нормированных значений
вокруг, так сказать, каких-то конкретных распределений
или величин.
И мало того, я здесь позволю себе повторить, это не просто
математический результат, это математическое описание
реально существующего закона, то есть, тот, который имеет
место в природе, это не абстракция, это описание
реальной картины мира.
Ну и сегодня мы как бы еще это, ну, я подчеркну, когда
будет об этом заходить вопрос, что называется.
Так, значит, следующий наш, следующая группа результатов
будет посвящена концентрации уже, там, ну, каких-то, так
сказать, там средних или других значений не в окрестности
числа, а в окрестности некоего распределения, некоего
такого предельного, финального распределения.
И в качестве первого примера мы рассмотрим теорему Пуассона,
но до этого введем просто число, в смысле, введем просто
некое понятие, ничего в нем особенного, ну, сократит
наши, так сказать, сложно подчиненные предложения.
Давайте введем такую двухындексную систему случайных величин.
Кад 1 до n, которые мы назовем сериями, серией случайных
величин.
Единственное общее свойство, которое мы, так сказать,
на серии накладывал, что случайные величины внутри
серии независимы.
С другими сериями могут быть зависимы, то есть это
не независимые все совокупности случайных величин, которые
выходят во все серии, только у нас требования к независимости
внутри серии.
Вот.
Просто термин, которым я буду оперировать, ничего
там особого нет, просто чтобы не говорить такие сложные
конструкции.
Вот.
Ну и давайте первый, так сказать, шаг, который мы
сделаем.
Давайте считать, что вот эта наша серия принадлежит
случайной величины с неким параметром pn.
То есть p, n, k, t – независимые одинаково распределенные
случайные величины с параметром pn, то есть параметр зависит
от индекса серии, так сказать.
Значит первое.
И второе, давайте на pn наложим еще одно симпатическое
условие, то есть это не произвольные pn от 0 до 1, а давайте считать,
что n умножить на pn сходится к некоторому числу лямда.
Ну ясно, больше 0.
Вот такие серии рассматриваем.
То есть в каждой серии это набор Бернулевских случайных
величин.
Я Бернулевский сказал или Бенемиалер?
Бернулевский.
Бернулевский.
То есть каждый из этих случайных величин принимает значение
0, 1, 1 принимает с вероятностью pn.
Вот такие серии рассматриваем.
И давайте введем такую же одноиндексную случайную
величину, эта n, которая просто равна сумме это n-катах.
Кат единицы до n.
Какое, кстати, распределение имеет эта n?
Бенемиальное.
Сумма Бернулевских случайных величин независимых имеет
бенемиальное распределение.
Так вот теорема Пуассона гласит, что эта n-ная сходится
по распределению Пуассоновской случайной величине с параметром
лямда.
То есть если вы будете генерировать случайные величины по этому
правилу, брать независимые, вероятность успеха будет
вот так себя вести, то в результате вы получите
случайную величину в пределе, которая по распределению
будет совпадать с Пуассоновской вот с этим параметром.
То есть сумма членов в такой серии при достаточно
большом n на самом деле имеет распределение Пуассона.
Хотя для каждого конкретного n это бенемиальное распределение.
Как будем доказывать, как думаете?
Характеристическими функциями воспользуемся.
Это, так сказать, самый удобный и простой аппарат в данном
Ну и давайте вот эту вот характеристическую функцию,
это n от t, напишем по определению, что это такое, это математическое
ожидание e в степени i t, сумма это n катых, кат единицы
до n.
Все n каты независимые одинаково распределены, поэтому это
произведение характеристических функций для каждого n-катого,
они у всех одинаково распределены, и это просто есть qn-ное плюс
pn-ное на e в степени i t в степени n.
Согласны?
Равно.
Ну вот в таком виде перепишу qn плюс pn плюс pn e в степени
i t минус 1, умножу на n и поделю на n.
Вот эта сумма чему равна?
Единица.
n на pn стремится к лямбда, значит к чему все вот это выражение
стремится, qn стремяще к бесконечности, кто мне скажет.
e в степени лямбда в показателе в степени e в степени i t минус
1.
А это чего характеристическая функция?
Это распределение Пуассона с параметром лямбда.
Итак, мы получили, что характеристическая функция
tn сходится к характеристической функции Пуассоновского
распределения, а это значит, как мы знаем, что эта n-ное
сходится по распределению к Пуассоновской случайной
величине.
Вот, собственно, первый результат из этого класса,
так сказать.
Ну, а дальше у нас, как говорится, будет посерьезней задача.
Я даже, пожалуй, вот здесь сотру.
Давайте рассмотрим серию.
Но здесь, кроме независимости, наложим еще дополнительные
условия на эту серию, которую будем рассматривать.
Мотожидание это n-катова равно 0, kat единицы до n, то есть
все они имеют нулевое мотожидание.
И еще есть условия на дисперсию.
Сумма дисперсии это n-катова, kat единицы до n, равно единице.
Ну вот, специфичные, пока специфичные, может быть,
не очень понятные условия, но рассматриваем вот такие
серии.
Если мы рассматриваем такие серии, то имеют место
следующие утверждения.
Первое.
Значит, если для любого tau больше нуля сумма kat единицы
до n интеграл по области x по модулю больше епсилон
x квадрат d f n-k от x, f n-k от x это функция распределения
случайной величины, это n-k.
Значит, если вот такая штука стремится к нулю, при
бесконечности.
И это условие, называется условие Линдберга, условие
Линдберга.
Если имеет место условие Линдберга, то имеют место
два следующих утверждения.
Во-первых, для любого епсилон больше нуля максимум вероятности
того, что эта n-кат по модулю будет больше епсилон, когда
максимум берется от единицы до n, стремится к нулю, при
н стремящейся к бесконечности.
Вот такое свойство.
Но если посмотреть на его определение, то это можно
назвать равномерной исходимостью по вероятности серии, равномерная
исходимость по вероятности.
Но в литературе встречается еще более такое поэтичное
определение вот этого факта, мало о чем говорящее, но
звучит неплохо.
Когда выполнено такое свойство, говорят, что серия – это
серия бесконечно малых, или пренебрежимо малых,
или асимпатически пренебрежимо малых.
То есть если просто услышать, непонятно в каком смысле
малых, что малое здесь.
На самом деле это просто как бы равномерная исходимость
по вероятности к нулю, но термин прижился.
Значит и так, если выполнено условие Линдберга, то серия
представляет из себя серию пренебрежимо малых, случайных
величин.
И, пожалуй, более важное свойство, три, это n, которая
есть сумма, это n-катах, кат единицы до n, сходится
по распределению к стандартному нормальному распределению.
Вот, конечно, ради чего всё это.
То есть сумма случайных величин в серии асимпатически
нормальна.
Обратите внимание, что здесь ничего не говорится
о том, какое распределение у них, какое бы ни было
распределение, сходится всегда к нормальному закону.
И это фундаментальный факт нашего мироздания.
Это был звонок, да?
Ну, отдохните и, собственно, приступим к доказательству.
А, извините, буквально за слово, чтобы не… Вот это
верно и в обратную сторону верно.
Вот, ну вот теперь отдыхайте.
Всё нормально?
Так, коллеги, ну, значит, собственно, переходим к доказательству.
Вот эта теорема, она называется или должна называться теоремой
Линдберг-Галевия.
Хотя результат, полученный этими учёными-мужами, сильно
отличался от того, как он сейчас формулирует, это
уже как бы современная трактовка.
Я сегодня приведу теорему Линдберг-Галевия, назову
её, так сказать, ретро-теоремой.
И хочу сказать, что это, пожалуй, единственная, может
быть, с какими-то небольшими оговорками, это единственная
фундаментальная теорема в теории вероятности, которая
не носит имени наших соотечественников.
То есть теория вероятности – это наша наука.
Вот, значит, ну, давайте, нам понадобятся некоторые
факты технического плана, которые я вот… Давайте
вот на этой доске выпишу.
Так, так, сейчас, для собственного удобства напишу разложение
e в степени и альфа в ряд.
Это единица плюс и альфа минус альфа квадрат пополам
минус и альфа в кубе на 6 плюс и так далее.
Вот, знакопеременный ряд, как бы, отсюда имеют
место следующее неравенство.
e в степени и альфа минус 1 по модулю меньше или равно
модуле альфа, e в степени и альфа минус 1 минус и альфа
по модулю меньше или равно альфа квадрат пополам,
и еще нам понадобится одно неравенство, чуть еще более
тонкое.
e в степени и альфа минус 1 минус и альфа плюс альфа
квадрат пополам по модулю меньше или равно модуль альфа
в кубе делит на 6.
Ну, это можно разными способами доказать.
То, что я написал, это не доказательство, но просто
поскольку это два знакопеременных ряда, это же на самом деле
косинус, альфа плюс и синус альфа, то остаток ряда
членов его ограничивается.
Вот таких вот три неравенства.
Так, ну и уже чего-то можем сделать.
Давайте докажем, что из 1 следует 2 для начала.
Это сделаем и потом про это забудем.
Результаты, которые будем получать, используя 2, будем
понимать, что они следуют из 1.
Итак, давайте напишем вероятность того, что это nkt по модулю
больше епсилонт через интеграл либега стилт ес.
Это что такое?
Это интеграл df nk от x при условии, что x по модулю
больше епсилонт.
Правильно, да?
Вот.
В области интегрирования x по модулю делить на епсилонт
больше единицы, поэтому могу написать, меньше или равно
единица на епсилонт квадрат интеграл x квадрат df nk от x,
x по модулю больше епсилонт.
Я беру максимум от обоих частей, знак неравенство
сохраняется, а здесь вместо максимума заменяю на сумму.
То есть получаю, что максимум k от единицы до n, вероятность
это nkt больше епсилонт, меньше или равна единица на епсилонт
квадрат, сумма x квадрат df nk от x, x по модулю больше
епсилонт.
Эпсилонт.
Ну в смысле, это tau, поэтому вот здесь давайте на tau исправим.
Ну а собственно вот это и есть условие Линдберг-Леве,
если оно стремится к нулю, значит и максимум стремится
к нулю.
Немножко заскочил вперед в том смысле, что хотел
сначала рассказать, как эти серии строить, чтобы они
для вас совсем не были абстрактные, поэтому давайте,
значит вот это могу стереть, запомним, что мы это доказали,
что из 1 следует 2, собственно что хотел сначала сказать,
ну вот у нас есть какие-то серии, что это за серии,
как с ними быть, бывает вообще в природе такие серии,
ну вот собственно на эти вопросы ответим.
Значит смотрите, пусть у нас есть привычная нам
последовательность независимых случайных величин, оказывается,
что серию можно построить по такому правилу.
Это nkt равно xkt-akt делить на bn, где akt это мотожидание
ксикатова, а bn в квадрате это сумма дисперсий ксикатова.
k равно от 1 до n, то есть это вполне легко, ну и давайте
в этих терминах переформулируем условия Линнберга, для этого
нам нужно понять, чего такое вот это fnk от x, это вероятность
того, что это nkt меньше x, если это nkt мы задаем вот
именно по такому правилу, то это вероятность того,
что xkt меньше bnх плюс akt, а это не что иное, как функция
распределения, напишу ксикатова, тройные индексы не будут
таскать, одноиндексная функция распределения
Взятая в точке bnх плюс akt, ну и давайте теперь перепишем
интеграл, x квадрат остается пока, x по модулю больше
tau, а здесь будет dfk взятая в точке bnх плюс ak, ну просто
на y заменим, y равно bnх плюс akt и тогда получим, ну я
напишу, а вы как говорится следите за руками, значит
1 на bn в квадрате интеграл y минус akt в квадрате dfk от
y, взятая по области y минус akt по модулю больше tau bn,
ну и собственно теория Малинберга-Леви, вот здесь
я ее запишу
Откуда вот это?
Bn я вынес, x равно y минус akt делить на bn, поэтому
x квадрате это y минус akt в квадрате делить на bn в квадрате,
значит теория Малинберга-Леви напишу здесь ретро, ну на
самом деле она нам полезна, мы этим в такой форме условиям
Малинберга будем пользоваться, значит изначально она
выглядела так, пусть выполнено условие Малинберга вот в
такой форме, ну как обычно ксиенные независимые случайные
величины, выполнено условие Малинберга, 1 на bn в квадрате
сумма интегралов x минус akt в квадрате dfk от x, взятая
по области x минус akt больше tau bn, k от единицы до n стремится
к нулю, при n стремящейся к бесконечности, то отсюда
следует, что сумма x kt минус akt k от единицы на n делить
на bn сходится по распределению к стандартному нормальному
закону, то есть только достаточно условия для последствий независимых
случайных величин, серии там необходимые достаточно,
это все потом как бы появилось, ну и вот видно собственно
о какой случайной величине идет речь, которая концентрируется
вокруг стандартного нормального распределения, это ведь
такая отнормированная на нулевое мат ожидания
и единичную дисперсию сумма этих случайных величин,
вот она нормально распределена, теперь я надеюсь нас не
пугают эти серии, мы понимаем как они строятся, понимаем
как это записывается в таком удобоваримом виде, ну и
можем собственно приступить к доказательству.
Сначала нам потребуется тоже там парочку вспомогательных
результатов, пока может не очень понятно зачем, но
давайте рассмотрим вот такую величину, фи nkt, характеристическая
функция это nkt в точке t, минус 1 по модулю, ну пока не очень
понятно, но дальше она нам сильно понадобится, и давайте
здесь как бы двумя способами мы к этому подойдем, ну во-первых,
сейчас я использую такой прием, мы его будем часто использовать,
подробно его распишу, значит фi nkt это что такое, это е
в степени и tx, минус единица, и вот здесь напишу, минус
и tx еще, df nk, понятно почему это равенство, смотрите е
в степени и tx, df nk это что такое, это характеристическая
функция, ну единицу проинтегрируем по мере, это единица, а вот
это что такое, это по определению и t на математическое ожидание
это nkt, которое равно нулю, мы такое условие наложили,
просто добавили ноль, поэтому меньше или равно интеграл,
здесь я возьму модуль и воспользуюсь вот этим неравенством
и напишу, что это меньше или равно tx, у нас роль альфа tx
играет в квадрате пополам, df nk равно на самом деле t квадрат
пополам, а то что остается x квадрат, это квадрат, x квадрат по мере,
это же что по определению, учитывая что мат ожидания
случайно равно нулю, это nk, x квадрат df nk, что такое, это дисперсия, дисперсия
это nk, ну теперь давайте просуммируем обе части по k и получим, вот здесь
вот, позвольте, я напишу и получим сумма крат единицы до n, phi nk от t минус 1 по
модулю, меньше или равно t квадрат пополам на сумму дисперсии, а сумма дисперсии
в нашей серии равна единице, видите, поэтому это просто меньше t квадрат
пополам, причем для любого t это выполнено, теперь по-другому подойдем к этой величине
phi nk от t минус 1 по модулю, значит это меньше или равно чем интеграл е в степени и t минус 1
df nk, nk от x и я этот интеграл разобью на два, один по области x по модулю больше
epsilon, а второй x по модулю меньше или равно epsilon, вот который x по модулю меньше или равно epsilon,
точнее x по модулю больше epsilon, я е в степени и t минус 1 по модулю заменю на 2, напишу,
что это меньше или равно, 2 интеграл df nk от x, взятый по области x по модулю больше epsilon,
а который меньше, воспользуюсь, что е в степени и t минус 1 по модулю меньше,
ну в нашем случае будет модуль t, модуль x, df nk x, x по модулю меньше равно epsilon, вот,
значит вот это что такое, этот интеграл, это вероятность того, что это nk больше epsilon,
а здесь x меньше epsilon, поэтому я заменю под интегральную функцию на максимальное значение,
вот это все меньше или равно, плюс модуль t умножить на epsilon. Ну и смотрите, значит второе
слагаемое можно за счет epsilon сделать малым, а первое можно сделать малым для любого epsilon
на основании свойства 2, вот, которое выполнено, поскольку мы считаем, что выполнено свойство 1,
и отсюда я получаю вот такой, ну и значит могу теперь еще максимум взять с двух сторон и
получить такую штуку, вот, максимум phi nk t от t минус 1 по модулю стремится к нулю,
максимум k от 1 до n, как до n стремится к бесконечности, вот такие важные для нас свойства.
Так, ну вроде подготовительная работа закончена, можем, что называется, по существу переходить,
хотя нет, еще вот здесь напишу одно свойство, логарифм 1 плюс z равно ряд минус 1 в степени s
минус 1, z в степени s делить на s, s от единицы до бесконечности, и ряд абсолютно сходится,
когда z по модулю меньше единицы. Еще такой факт. Идея доказательства опять же в использовании
характеристических функций, ну как не трудно догадаться, раз мы тут с ними возились. Мы
сейчас докажем, что характеристическая функция вот такой вот суммы стремится к характеристической
функции стандартного нормального распределения. А чему равна характеристическая функция стандартного
нормального распределения? Кто помнит? е в степени минус t квадрат пополам. Вот. Ну,
сразу напишу логарифм, phi это n от t. Значит, это n есть сумма независимых случайных величин,
поэтому характеристическая функция суммы равна произведению характеристических функций,
но поскольку еще логарифм взял, это получается сумма логарифмов. Сумма логарифмов phi nkt от t.
Это я преобразую таким образом. Логарифм единица плюс phi nkt минус 1. Вот. Становится понятие наш
замысел, чем мы возились с этими phi nk минус 1. Так, значит, смотрите, поскольку имеет место вот такое
свойство, это значит, что начиная с некоторых номеров n, но вот этот максимум можно считать
меньшим 1 и 2. Будем так и делать. Поскольку мы будем переходить к пределу, предоставляясь
бесконечности, будем считать, что вот этот максимум меньше 1 и 2. Настолько большие у нас
тогда phi nk минус 1 по модулю меньше 1 и 2. Это внутри сходимости ряда логарифма, и я раскладываю в ряд.
Выделяю первый член с s равно единице
и то, что остается.
Вот эту двойную сумму обозначим rn. Ну и, наверное, вы понимаете, к чему я веду, да? Что rn по модулю
будет стремиться к нулю. Мы сейчас это покажем.
Значит, rn по модулю
меньше или равна. К от единицы до n. Смотрите, берем модуль, тут все положительное становится.
s имеет минимальное значение 2, поэтому если мы во всех членах здесь s заменим на 2,
то ряд только увеличится. Поэтому я напишу 1, 2, а здесь напишу уже без двойки. Вот,
но что я здесь напишу? phi nk от t минус 1 в степени s, s от 2 до бесконечности. Внутренняя сумма,
значит, мы договорились, что phi nk от t минус 1 по модулю меньше 1 и 2. Такие большие n договорились
брать. Поэтому это геометрическая прогрессия, сумма геометрической прогрессии. Ну, я напишу,
ну, напишу равно пока, да, равно k от единицы до n, 1, 2, phi nk от t минус 1 в квадрате первый
член на единицы минус q на единицы минус phi nk от t минус 1. Еще раз напомню, что модуль phi nk от t
минус 1 меньше 1 и 2. Поэтому, если я сюда подставлю 1, 2, увеличу знаменатель, точнее говоря, увеличу
вот эту величину, значит, уменьшу знаменатель, могу поставить знак меньше или равно. Ну и сразу
смотрите, если это заменю на 1, 2, здесь будет 1, 2 с 1, 2 сократиться и получится меньше или равно
phi nk от t минус 1 в квадрате, в квадрате k от единицы до n. Дальше напишу меньше или равно
максимум phi nk от t, t у нас фиксированное, какое-то, но фиксированное, максимум k от единицы до n,
сумма phi nk от t минус 1, k от единицы до n. Ну, теперь смотрим вот сюда. Сумма phi nk минус 1, пока
модуль меньше t квадрат пополам, максимум стремится к нулю. Поэтому вся вот эта штука для любого t стремится
к нулю при n, стремящемся к бесконечности и для любого t это имеет место. Вот как бы важный
промежуточный факт, который нам нужен. Идем дальше. Значит, итак, мы с вами сейчас получили вот что.
Что логарифом phi nk t, то есть это nk t равно вот такой штуке, я перепишу, а потом сотру. То есть это
получается равно сумма phi nk t минус 1 по модулю плюс rn. Но я вот так сразу запишу. Минус t квадрат
пополам плюс t квадрат пополам плюс сумма phi nk от t минус 1, k от единицы до n, плюс rn. rn, помним,
стремится к нулю. А, и еще, значит, хочу обратить ваше внимание, потом на это я сошлюсь, что
представимость логарифма характеристической функции это n в виде вот такой суммы и остатка,
стремящемся к нулю, это следствие свойства 2. Нам свойства 1 не потребовалось. Ну просто,
поскольку мы отсюда доказываем сюда, мы говорим, что свойства 2, но свойства 2 само следует и
свойства 1. Но вот если есть свойства 2, когда мы будем в обратную сторону доказывать, если
свойство 2 выполнено, то для характеристической функции тоже имеет место вот такое представление.
Так, ну, собственно, можно сказать, последний рывок, вот эту штуку мы обозначим ρn. Ну и,
как вы догадываетесь, докажем, что ρn по модулю стремится к нулю. Но тут сейчас немножко повозиться надо будет.
Значит, ρn я сначала распишу неким специальным образом. Вместо t квадрат пополам я напишу такую
штуку. Сумма cat единицы до n интеграл t х в квадрате пополам df nk. Всем понятно,
что это t квадрат пополам? Ну, потому что t квадрат пополам выносим, остаются дисперсии,
сумма дисперсии равна единице. Ну и плюс вот эту сумму, которую я представлю в таком виде,
интеграл е в степени и t х минус 1, ну и минус и t х. Уже говорили, что это просто ноль. Теперь
разобьем это на два слагаемых. Первое это будет k равно от единицы до n. Так,
сейчас только. Значит, интеграл х по модулю меньше или равно е, т х квадрат пополам df nk плюс,
я пожалуй сумму вот общую возьму, плюс интеграл е в степени и t х минус 1, минус и t х по области
той же. Это первое слагаемое и второе слагаемое аналогично только по области х по модулю больше
е. И вот когда я буду х по модулю больше е, здесь я сразу преобразую t квадрат пополам вынесу за
скобки, а здесь останется х квадрат df nk, а вторую часть этого интеграла никак не преобразую,
просто можно не буду переписывать. Вот так же перепишу я, только по области будет х больше е.
Так, значит, вот это первое слагаемое обозначим ρ n штрих, а второе ρ n 2 штриха. И теперь каждое
по отдельности изучим. Ро n штрих по модулю. Вот оно. Смотрите, я это все вношу под один интеграл и
пользуюсь вот этим свойством. Вот сюда, вот этим свойством пользуюсь и получаю, что это меньше или
равно, интеграл х по модулю меньше или равно epsilon, t х по модулю в кубе делить на 6 сумма
df nk от x. Согласны? Все под один интеграл, е и t х минус 1 минус и t х минус t х квадрате,
точнее говоря, плюс t х квадрате пополам, это альфа, которая t х в нашем случае по модулю в третьей
степени делить на 6. Так, меньше или равно? Х максимальное значение вынесу за скобки и t в кубе
вынесу. Получу t по модулю в кубе на epsilon делить на 6 на сумму х квадрат df nk от x, x по модулю меньше
epsilon, меньше равно epsilon. Но если я расширю под интегральная функция положительная, расширю область
интегрирования минус бесконеч-бесконечность, все только увеличится, но тогда получится дисперсия и
вся вот эта штука будет меньше единицы, меньше равно единицы. И мы получили, что ρ n штрих по модулю
ограничено t по модулю в кубе epsilon делить на 6. Первое и второе, ρ n два штриха по модулю. Значит,
смотрите, вот это я перепишу как есть, меньше или равно t квадрат пополам сумма х квадрат df nk,
x по модулю больше epsilon, а вот здесь воспользуюсь вот этим вот неравенством модулем. Ну и получу t
квадрат x квадрат пополам, также t квадрат пополам вынесу за скупки, а под интегралом останется x
квадрат df nk, x по модулю больше epsilon, то есть это на самом деле просто t квадрат на сумму интегралов x
квадрат df nk, x по модулю больше epsilon, крат единицы до n. А вот это вот и есть условие Линдорга. Если эта
штука стремится к нулю, то и ρ n два штриха по модулю стремится к нулю. Итак, ρ n штрих ограничиваем,
делаем сколь угодно малым за счет epsilon, и при этом малым epsilon ρ n два штриха делаем сколь
угодно малым за счет выполнения условия Линдорга. Итак, мы с вами доказали, что логарифум phi
это n представимо в виде минус t квадрат и плюс два остатка, которые стремятся к нулю. То есть
логарифум phi это n стремится, при н стремясь к бесконечности, к минус t квадрат пополам. А
это значит, что phi это n, это n от t стремится к е в степени минус t квадрат пополам характеристической
функции стандартного нормального распределения. И это завершает наше доказательство в одну сторону,
в одну сторону. Значит, во вторую сторону все в принципе не сложно, но давайте все-таки успеем.
Итак, пусть у нас теперь выполнено два-три, то есть условия пренебрежимой малости а симпатической
нормальность. Тогда, как я обращал ваше внимание, мы можем утверждать, что логарифум phi это n от t
представимо в виде сумма phi n-катого от t минус 1 х 1 до n плюс rn, которая стремится к нулю на
основании свойства 2, я это обращал внимание. И все вот это, поскольку а симпатическая нормальность
имеет теперь место по условию, обязано сходиться к минус t квадрат пополам. Вот что такое выполнено
2 и 3. Ну и давайте, значит, перепишем это в виде сумма phi n-kат минус 1 плюс t квадрат пополам,
стремится к нулю, прен стремясь к бесконечности. Представим это в виде интеграла e в степени
и t х минус 1 плюс t квадрат х квадрат пополам df n-k от x кара в нот единицы до n стремится к нулю,
при n стремясь к бесконечности. Ну можно это вот дельта n так невязочку это назвать. Значит, смотрите,
ну понятно, да, что это и это одно и то же, потому что здесь опять дисперсии, сумма дисперсии опять
единица. Теперь смотрите, вот это же комплекс назначенная функция, она стремится к нулю,
отсюда следует, по крайней мере, что ее действительная часть тоже стремится к нулю.
Более того, это верно для любого t, в том числе и для t равного единицы, поэтому я все это учту
и напишу следующее утверждение, что сумма интегралов cos х минус 1 плюс х квадрат пополам df n-k
от единицы до n стремится к нулю, при n стремясь к бесконечности. Понятно, что я сделал, да? Выделил
действительную часть это cos х и положил t равно единицы, получил такую штуку. Значит,
обращаю ваше внимание, что под интегральное выражение больше или равно нуля достаточно взять
ее производную, убедиться, что минимум в нуле, но под интегральное выражение больше равно нулю,
поэтому для любого t больше нуля эта штука больше, чем интеграл х по модулю больше t cos х минус 1 плюс
х квадрат пополам df n-k. Так, и вот здесь есть такая штука, такое замечание. Вот смотрите,
вот эта функция cos х минус 1 плюс х квадрат пополам, я для нее делаю следующее утверждение,
что для любого t больше нуля существует некая функция k tau такая, что cos х минус 1 плюс
х квадрат пополам больше или равно k tau на х квадрат, как только х по модулю больше t.
Значит, это представляется вполне разумным, почему? cos х разлагаем в ряд, 1 сокращается,
х квадрат сокращается, остается х в четвертой степени, там ну на 24, да, х в четвертой больше
k tau на х квадрат. Ну понятно, что это как-то так. х квадрат и х в четвертой встречаются в единице,
вот это вот, не знаю, х квадрат или х в четвертой, вот это вот х в четвертой. Ну если мы какой-то
tau взяли, то мы за счет множителя можем сделать так, что вот в этой области х больше tau, х в четвертой
будет больше, чем х квадрат. Но вот это утверждение вроде бы достаточно очевидное и несложное,
но если с ним возиться, это минут 15, поэтому я его оставлю без доказательства, так сказать,
там, ну на любителя, что называется, так сказать. Ну так-то оно вполне оказывается разумным. И тогда
я пишу, больше или равно, больше или равно k от tau на сумму k от единицы до n х больше tau х квадрат
d f n k от х. А это и есть условия Линнберга. Эта штука стремится к нулю, значит выполнено условия
Линнберга. Что завершает наше доказательство? Был звонок, да, по-моему. Так, все коллеги,
значит, в принципе успели, там, ну по крайней мере, посередине не разорвали доказательства,
тогда в следующий раз продолжим с вами. Спасибо, коллеги.
