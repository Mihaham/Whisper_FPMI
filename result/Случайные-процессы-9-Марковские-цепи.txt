Сегодня мы хотим закончить обсуждение марковских процессов. Давайте я напомню, чем кончили.
Было уравнение Чепмана Колмогорова.
Вот этого Чепмана пишут по-разному, потому что он, можете догадаться, вот такой.
И поэтому в нашей литературе встречают при написании его 2е и 1е, 2е, но, по идее, можно было бы и второе, и 2е.
Но, кажется, такого я не встречал, но это вполне, так сказать, тоже было бы правильно.
Значит, уравнение вот какое.
Я еще раз его выпишу, просто чтобы прокомментировать, что оно означает.
Значит, смотрите, смысл левой части, переходной вероятности, это вероятность попасть в множество е в момент времени t, если в какой-то предшествующий момент процесс находился в точке x.
И вот эта формула, которая называется уравнением Колмогорова-Чепмана или равенством Колмогорова-Чепмана, смотрите, что оно говорит.
Что вот эта вероятность перейти из x в е считается так.
Значит, тут s, t и x фиксированы.
Значит, s, t и x в левой части, вот эти вот 3 фиксированы.
Теперь мы берем промежуточную точку u и вот эти вот вероятности.
Это перейти, сейчас только я.
Смотрите, считается, что мы как бы перебираем всевозможные точки y и переходим сначала из x.
В момент времени промежуточной оказываемся там, условно говоря, в dy, а потом переходим в е.
Смысл такой, переходим не сразу из момента времени s в момент времени t, а еще вводим промежуточный момент.
Сначала смотрим, находясь в момент времени s, где оказались в u, а потом из момента времени u перешли в момент времени t.
Конечно, в такой, в интегральной форме это нельзя сказать, что как-то очень интуитивно понятно.
Но это становится гораздо более понятным в дискретном случае, к которому мы сейчас и перейдем, в случае марковских цепей.
Это очень важный частный случай марковских процессов, который мы сегодня как раз очень кратко обсудим и на этом про марковость закончим.
Теперь еще, как связаны конечномерные распределения с переходными вероятностями.
Связь конечномерных распределений с переходными вероятностями.
Связь такая, обычная для процессов вероятность попадания в множество c вычисляется в такой довольно длинной, но тем не менее конечной формуле.
Значит, вот какой, форма такая немножко громоздкая, но интегрирование производится, вот это по dx1, оно последним будет интегрирование.
Сейчас тут будет, у нас было фазовое пространство x, кажется.
Значит, смотрите, что делается в этой формуле.
Значит, вот есть множество в Rn, ну или там не в Rn, а в x в степени n, если фазовое пространство не прямое.
Значит, вот мы берем, фиксируем все кроме xn вот здесь и интегрируем по xn вот по этой переходной вероятности.
После этого от xn зависимости нет, ну и дальше начинаем, то, что получилось зависит от x1, xn-1, и вот это интегрируем по dxn-1, ну по соответствующей переходной вероятности.
Ну и так наконец добираемся до x2, вот по этой интегрируем, и остается не связанной только одна переменная x1, ну и вот здесь мы интегрируем по распределению процесса в момент времени t1.
Так что получается так, что если знать начальное распределение и переходные вероятности, то можно вычислить, конечно, мерные распределения.
Естественно, на этот счет тоже есть теорема о существовании процесса, но я не буду ее приводить, она довольно и по формулировке громоздкая, и по доказательству довольно громоздкая.
Но важный момент вот какой. В исходном определении марковского процесса никаких переходных вероятностей не было.
А эта теорема, которая в прошлый раз была без доказательств, что они есть, это в случае, когда фазовое пространство, ну какое-то разумное, ну скажем Rn или его Борелевское подножество, ну или там изоморфное такому пространству.
Но вообще говоря, неверно, что есть для произвольного марковского процесса, что есть переходные вероятности, это неверно.
Но иногда само определение марковского процесса формулируется в таком несколько более узком виде вот как раз через эти переходные вероятности.
Так что такое вот в литературе и в учебниках такое можно встретить. Ну такое немножко более узкое определение.
Но для большинства того, что в реальных приложениях встречаются, это оказываются равносильные вещи, хотя вот существование переходных вероятностей,
которые в теореме последней прошлого раза было объявлено, надо понимать, что это вещь как раз весьма нетривиальная.
Вот это гораздо более трудное доказательство этого факта, чем вообще все что угодно из того, что у нас было с доказательством.
Поэтому для себя можно, так сказать, не совсем правильно считать, что марковские процессы, но это те, для которых есть начальное распределение и переходные вероятности.
Ну и это будет оправдано в случае разумного фазового пространства.
Теперь важный частный случай цепи Маркова.
Так, что-то я еще хотел сказать.
Вот однородный процесс.
Это когда переходные вероятности, значит, вот эти вот, значит, P, S, X, T, E,
зависит только от разности, значит, T-S, а не от пары точек.
В этом случае получается, ну, вот можно считать, что функция трех переменных.
Ну и это, значит, вероятность попасть в E в момент T,
а выйдя из X в момент ноль.
Вот дальше мы будем говорить про цепи Маркова, именно про однородные.
Это сильно упрощает дело, хотя, ну, в приложениях, конечно, бывают и не только однородные цепи, и не только однородные процессы.
Есть также некоторая конструкция перехода от неоднородных процессов к однородным, но это мы не будем обсуждать.
Будем просто считать, что дальше речь пойдет о однородных процессах.
Значит, цепи Маркова были введены сто с небольшим лет назад в начале 20 века нашим выдающимся вероятностником Андреем Андреевичем Марковым,
который для довольно специфической задачи вел эти цепи, а именно он исследовал чередование гласных и согласных в словах русского языка,
ну, на предмет того, насколько это, так сказать, случайно и какие там есть закономерности.
Так что у него процесс был с таким вот, ну, можно сказать, пространством из двух точек, ну, можно сказать, там, из 0.1, если там эти гласные и согласные так, значит, занумеровать.
Значит, давайте я приведу, так вот, чтобы не расходиться в обозначениях.
Значит, смотрите, я иногда все-таки расскажусь в обозначениях с тем, что в конспекте, но, значит, в конспекте я еще раз посмотрю и сделаю единообразным.
Ну, в частности, у меня там фазовое пространство, там где-то S, где-то X, но, в общем, понятно, что фазовое пространство, конечно, может быть разными буквами обозначено, так?
Но я, значит, в конспекте все-таки просмотрю, чтобы какое единообразие было.
Значит, теперь вот, значит, смотрите, что такое цепь Маркова.
Значит, это, значит, у нас будет, ну, давайте я сразу напишу, однородный, значит, однородная цепь Маркова, но дальше не буду каждый раз это подчеркивать.
Значит, это однородный Марковский процесс с конечным, ну, вот дальше у нас как раз в основном случае это конечного и будет, значит, или с счетным.
Значит, или с счетным фазовым пространством.
Ну, вот в случае Маркова, значит, фазовое пространство, в исходном случае Маркова фазовое пространство было из двух точек.
Значит, теперь, значит, чем, значит, чем этот процесс задается?
Значит, можно ввести вот такие вот, вот это важное очень, значит, понятие.
Значит, вероятность перехода из х итого в х сжитое за один шаг.
Значит, да, еще я забыл сказать, я еще забыл сказать, процесс со счетным, значит, ну, конечным или с чем.
И, значит, временем, вот это тоже очень важно, я про это забыл сказать, значит, временем натуральные числа и ноль, то есть временное множество, 0, 1, 2 и так далее.
Некоторые считают, что ноль это натуральное число, но вот я помню, Арнольд горячо это оспаривал и учил нас, что ноль это не натуральное число.
Так что, ну, вот тут, значит, на ваш вкус, если ноль натуральная, то его добавлять не надо, а если нет, то надо.
Значит, смотрите, ну, кто такие поижитые?
Значит, поижитые это не отрицательные числа и, значит, сумма, значит, сумма, ну, при всех и.
Ну, давайте, давайте тут пока будем считать, что счетное число состояния, но понятно, если число состояния конечное, то, ну, соответственно, и, там, значит, ну, эти и ижи, они, значит, будут, ну, до какого-то там фиксированного числа.
Значит, смотрите, в чем смысл, значит, в чем смысл вот этой единицы, значит, почему, ну, ну, значит, почему, значит, почему единицы, почему, естественно, ожидать, что эта единица должна быть в итоге.
Значит, смотрите, что мы суммируем, значит, мы суммируем, значит, вероятности перехода, значит, из и в ж, ну, при фиксированном и, так, при фиксированном и, значит, почему, значит, почему, естественно, ожидать, что это единица.
Ну, да, ну, потому что, значит, ну, куда-то она обязана перейти, но, но, но, но, когда говорят перейти, это не исключает, что она никуда не перешла, то есть, вероятность остаться в и, она тоже есть, конечно, так что, значит, обратите внимание, ну, перейти это в расширительном толковании, так.
Так что вот, например, когда вы говорите, что я там из общежития куда-то пошел, то, а на самом деле никуда не пошел, то это, в общем, так сказать, соответствует, значит, вот этим обозначениям.
Теперь, теперь, значит, пусть дано, значит, дано начальное, начальное распределение P0, так.
Ну, что это значит? Это значит P0 от XG, значит, это не отрицательные какие-то числа, но и тоже сумма по G их равна единице.
Ну, то есть, это мера вот на этом, значит, фазовом пространстве, но если оно счетное, то, значит, мера на счетном множестве, если конечная, то на конечном.
А, значит, вот разумные задачи возникают уже, когда это множество состояний из двух точек.
Ну, значит, смотрите, здесь пока что процесса-то нет, но в общем определении Марковского процесса.
А, значит, это был процесс, принимающий значения в пространстве X, так.
Значит, X было пространством с сигма-алгеброй, так.
И что такое процесс? Это просто набор случайных элементов со значениями в этом X, так.
Значит, когда у нас фазовое пространство конечное или счетное, то мы считаем, ну, по умолчанию, что там самая банальная сигма-алгебра.
Ну, значит, помним, что как только появляется фазовое пространство, там незримо, значит, еще предстоит какая-то сигма-алгебра.
Ну, в общем случае это, ну, какая-то абстрактная сигма-алгебра.
В практических задачах это пространство фазовое, ну, какое-то Борелевское множество и сигма-алгебра Борелевское.
Но когда все конечное или счетное, то все предельно упрощается, и сигма-алгебра это просто все подмножество, так.
В конечном случае получается конечная сигма-алгебра, но в счетном случае уже получается, ну, уже бесконечная, но довольно простая.
Так, теперь, значит, смотрите, значит, вероятность, вероятность нахождения,
нахождение процесса в XG, значит, при T равном единице, считается так,
значит, давайте, значит, напишем, значит, что это будет? Это будет сумма по I, P, значит, IG умножить на P0 от XI.
Ну, действительно, как, значит, процесс может оказаться в XG?
Ну, он мог быть, ну, в момент времени T1, значит, в момент времени T1, он мог в момент времени 0 быть в XI, и это вот с такой вероятностью было,
а из XI в XG он мог перейти с вероятностью вот такой, ну, поэтому получается вот такая вот формула.
Значит, теперь, значит, если, значит, смотрите, что получается, значит, если P0 мы отождествляем вот с такой вот строкой P01, P02,
ну, и так далее, значит, распределение P1 в момент времени 1
со строкой, значит, вот такой вот, значит, P0, то есть P1, значит, 1, P1, 2, и так далее, то получается вот такая формула.
P1, значит, P1, ну, значит, вот эта вот, значит, строка получается применением, значит, к строке P0 матрицы.
Значит, а матрица, ну, вот в случае счетного такая бесконечная матрица, а в конечном случае, ну, естественно, конечная.
Значит, вот такая вот матрица из этих переходных вероятностей, так, но матрица, ну, такая, видите, формула немножко необычная, матрица справа умножается.
Ну, как-то мы так в основном привыкли, что когда матрица применяется к вектору, то вроде как матрица умножается слева.
Но здесь можно так сделать, так переделать, но тогда будет вот какое небольшое эстетическое неудобство.
Тогда, естественно, нужно писать, здесь будет не строки, а столбцы, так, значит, вместо вот этих строк нужно будет столбцы писать.
Ну, что понятно, на письме крайне неудобно, там на доске еще можно, значит, на бумаге это крайне неудобно в печатном тексте писать столбцы, так.
Но это-то еще ладно, можно было с этим смириться и объявить, что вот на эти столбцы надо, так сказать, под другим углом зрения смотреть, так.
Но это ладно, но хуже то, хуже то, если так сделать, то, ну, матрицу, ну, на матрицу надо умножать слева будет, но, к сожалению, не на эту матрицу, а на транспонированную.
И это вот некоторые неудобства, но я считаю, что это, так сказать, это неудобство перевешивает вот непривычность, значит, вот такой вот записи.
Вот теперь, значит, для распределения, значит, вот это вот опять такая строка, значит, распределение, распределение процесса, значит, при t равном n, так.
Значит, и тогда получается, что Pn, это есть Pn-1 умножить на P, вот опять справа, и это будет P0 умножить на P.
Значит, таким образом, так сказать, состояние в момент времени n вот так, значит, описывается через матрицу.
Что, что? А, степень n я не дописал, да, значит, степень n, конечно.
Значит, смотрите, получается так, что если дана, значит, мера, вот это начальное распределение строка P0, и дана, значит, матрица перехода, то, значит, вот получается такое равенство для распределения процесса в момент времени n.
Ну, значит, формула, конечно, так сказать, очень короткая и простая, но надо понимать, что даже для небольшой цепи, не говоря уж про счетные цепи, но даже для, скажем, даже для цепи из двух элементов, конечно,
Практическое вычисление вот этой большой степени может оказаться довольно непростым, так сказать.
Сама формула короткая, но, так сказать, степень явности этой формулы, конечно, не следует переоценивать.
Ну и, значит, какие вопросы-то возникают в связи с цепями?
Ну, естественно, всякие практические вопросы, но, значит, первый теоретический вопрос вот какой.
Если у вас дано начальное распределение P0 и вот эта матрица P, раз дана матрица P, то даны, конечно, тем самым ее степени, но возникает...
Ну, значит, вы что-то можете посчитать, вот это Pn, но спрашивается, а что именно-то вы считаете?
Почему вы уверены, что это какие-то вероятности, связанные с процессом? Процесса-то вроде нет, так?
Это мы все насчитали, что так должно быть, что если есть процесс. Ну а почему есть процесс?
Ну, это, естественно, надо доказывать. И давайте я соответствующую теорему приведу, но мы все доказательства не будем расписывать на доске,
потому что там всякие выкладки по индукции проверяются. Я сейчас только объясню, в чем суть дела.
Значит, эти выкладки у меня тут, ну, примерно страница выкладок в конспекте, они там аккуратно выписаны, не хочется их на доску переписывать.
Давайте саму теорему я выпишу. Значит, теорема вот какая.
Значит, если даны начальная мера, ну, просто мера, мера P0,
х, которое с конечным числом состояний, и вероятности, ну, и вот эти вот матрицы переходов,
значит, матрица P, ну, вот с тем условием, с тем условием, что это соответствует вероятностям перехода.
То есть, никакая угодная матрица, значит, не отрицательная и сумма пожи единица должна быть.
Обратите внимание, матрица не обязательно симметричная. Вот это я сразу забыл сказать, но это, конечно, и не имелось в виду,
но вероятность попасть из 1-2 может быть совсем не такая, как из 2 в 1. Так что ничего такого тут не предполагается.
Так что, значит, матрица несимметричная. Ну, вот сейчас, когда я говорил про транспонирование, это вот как раз из несимметричности транспонированная,
может быть, уже не она сама. Значит, то существует цепь Маркова. Ну, я уже не оговариваюсь, что она однородная, мы только такие рассматриваем.
Значит, цепь Маркова с начальным, ну, с пространством состояния вот этим вот, конечным, значит, с начальным распределением.
Значит, начальным распределением P0 и, значит, вот этими P и житыми, которые должны быть, значит, условными вероятностями, значит,
перехода, ну, при всех N. Ну, поскольку цепь у нас однородная, то это все равно, что, значит, вероятности перехода за один шаг,
но, значит, вот можно их и так написать. Значит, смотрите, что здесь не очевидно? Ну, здесь не очевидно, что вот по этим данным можно такое, причем это обратить внимание,
это не очевидно уже, начиная с M равное 2. Вот если даже совсем минимальное пространство состояний из двух точек, ну, из одной, совсем минимальное, но тривиальное неинтересное,
а вот интересные вещи начинаются уже, значит, со случая двух состояний. Уже в этом случае получается не очевидно, что такой процесс есть.
Так, тут казалось бы, ну, все предельно просто. Вот эти точки, ну, их можно считать, что это просто 1M. Ну, давайте доказательства.
Значит, ну, это будет, я говорю, не полное доказательство, некоторые детали на конспект я перенесу. Значит, можно считать, что, значит, и X это просто 1M.
Вот M точек. Так, значит, нужно, нам нужно предъявить, ну, то есть это в R все происходит тем самым.
Значит, нужно предъявить конечномерные распределения, значит, ну, на пространствах Rn.
Так, но фактически, поскольку мы хотим, чтобы он принимал значение вот в этом конечном множестве, нам даже не нужны все множества.
Так, а на вот таких вот множествах, значит, ну, на степенях вот этого даже, не всего R, а на степенях вот этого конечного множества.
Так, значит, мера P1, значит, n на подмножествах, подмножествах вот этого конечного множества.
Ну, вот когда обычно какие-то меры на конечных множествах, то вроде, значит, первое впечатление это, что, ну, там все, так сказать, всегда верно, потому что все конечное и так далее.
Ну, тут, значит, есть вот какой нюанс. У нас не одно такое пространство, вот эта степень, не одна, а их много, при всех n.
Так, и вот нам нужно задать, значит, меры, чтобы они были согласованы, ну, в смысле Колмогорова, чтобы применить его теорему.
Я сейчас расскажу такое стандартное доказательство, как это делается с помощью теоремы Колмогорова, а потом сделаю замечание, как в этом конкретном случае можно сделать,
ну, так сказать, явно без теоремы Колмогорова, а проверку деталей в качестве задачи оставим.
Значит, вот эта мера сдается вот такой вот формулой, на точках сначала, на отдельных точках.
Значит, эта мера сдается на отдельных точках, вот такой вот формулой.
Так, вот эта двойка.
Значит, смотрите, на отдельных точках просто явные формулы сдаем меру.
Значит, дальше по аддитивности.
Значит, дальше по аддитивности.
Значит, распространили, так.
Значит, распространили, и теперь, значит, меры, меры, значит, при, значит, других комбинациях.
Вот здесь, смотрите, здесь мера, значит, подряд точки, но нам нужны еще меры, значит, вот на всяких таких комбинациях.
Так, значит, это проекции этой меры на соответствующие, значит, RL.
Значит, была мера со всеми индексами, часть, значит, индексов убрали, и что это должно быть?
Ну, как хотелось бы, чтобы Колмогоров работал, так и делаем просто.
Это должна быть проекция этой меры на это.
Так что, видите, получается сразу, по таким способам, сразу согласованная система.
Поэтому, значит, получаем сразу согласованные меры, значит, то есть, значит, есть процесс, так, ну, по Колмогорову, так.
То есть, тут не надо уже ничего не проверять, мы сразу так делаем, чтобы тут так все было.
Значит, но, что нужно, значит, но нужно проверить, нужно проверить, что процесс Марковский
И еще то, что, ну, вот нужное равенство получилось с этими условиями.
Мы шкотели, мы шкотели еще вот такую вот формулу.
Смотрите, мы процесс-то задали, и у этого процесса заданы конечномерные распределения.
Но для Марковости нас волнуют условные меры, так.
И кроме того, нас волнует, чтобы был процесс обещанный с переходными вот этими вероятностями, то есть, тут тоже условные меры.
Вот это все нужно проверять.
Ну, это некая страница выкладок, которая у меня аккуратно приведена в конспекте, так.
Давайте я здесь не буду его спроизводить.
Ну, вот заодно проверьте, значит, сколько аккуратно она в конспекте, значит, имеется.
Вот теперь, значит, теперь как можно, то есть, тем самым, вот это как бы получается остаток доказательства в конспекте.
Но как можно без Колмогорова, значит, замечание, без Колмогорова, значит, как можно такую цепь построить.
Ну, как вы понимаете, до появления теоремы Колмогорова народ особенно и не озадачивался,
почему существует тот или иной процесс.
Ну, это примерно как физики.
Вот им кажется чудно, что там математики что-то мучаются, есть ли уравнение на въезд Окса, решение или нет.
Они как-то считают, ну вы что, ребята, вот так сказать, а если у них нет решений, то вообще о чем разговор.
Ну, также и вот про процессы.
Ну, как-то считалось, ну как, ну, естественно, раз обсуждается процесс, то он есть, а если нет, то и обсуждать нечего.
Это только Колмогоров, так сказать, поднял вопрос, а вообще почему, так сказать, вообще, почему вы думаете, что процессы какие-то есть.
Ну, к счастью, оказывается, что они в основном есть.
Вот, значит, без Колмогорова можно сделать так.
Значит, берем, значит, значит, ксеноль.
Это случайная величина с распределением пеноль.
Ну, это естественно, раз мы хотим, чтобы процесс имел начальное распределение пеноль, ну, конечно, ксеноль и надо брать с таким распределением.
Вот, а дальше берем так.
Значит, берем, значит, берем, значит, последовательность.
Это Н, это независимые равномерно распределенные в 0,1.
Так.
Ну, почему такие есть?
Опять же, до Колмогорова никто в этом не сомневался.
Значит, ну, значит, пришел Колмогоров, внес сомнения, ну, и тут же его и разрешил.
Ну, есть такие, значит, с помощью теоремы Колмогорова такие есть.
И дальше делаем так.
Дальше делаем так.
Значит, кси1 задаем с помощью вот этой, это 1.
Значит, так.
Делим 0,1 на m промежутков.
Так.
С длинными, с длинными дельта 1, дельта m.
И где дельта kt выбирается вот так.
Это p0 от единицы умножить на p1 от k, плюс и так далее, p0 от m на p, m от k.
Так.
Значит, поделили отрезок.
И теперь кси1 от ω.
Это номер того, в который попало это 1 от ω.
Ну, и дальше, значит, то есть, видите, явным образом построили пока кси0 и кси1.
А дальше это по индукции продолжаем.
Так.
Дальше это, ну, кси2 строим.
Кси2.
С помощью это 2.
Это 2 попадает в свои промежутки.
Не вот в эти, так, значит, не в эти попадает, а для кси2, значит, ну, свои промежутки.
Вот эти дельты свои другие будут для, ну, на втором шаге.
Значит, смотрите они какие будут.
Значит, смотрите, ну, вот по индукции.
Значит, если кси n уже есть, то, значит, кси n плюс 1.
Номер промежутка, в который попало, значит, в который попало вот это n плюс 1.
Так.
Значит, видите, на каждом шаге, значит, это из этих независимых свое используется.
Так.
И, значит, длины промежутков, значит, длины промежутков.
Ну, ну, вот этих вот.
Ну, давайте скажем так, дельта 1, n.
Вот на шаге, на шаге n плюс 1.
Да.
Значит, на шаге n плюс 1.
Значит, промежутков число одно и то же.
Но длины подобраны так.
Ну, это, так сказать, каждый раз индуктивно, значит, ну, делаем.
Значит, подбираем, значит, длины так, чтобы, чтобы.
Значит, так, что вероятности вот такие вот, значит, были те, те, которые получаются по формуле.
Ну, вот с помощью вот этих переходных.
Так.
Ну, то есть они каждый, они каждый раз, ну, какие-то, так сказать, нам, нам даже не важно находить их.
Но они какие-то есть, которые диктуются формулой.
Вот, значит, по ним подбираем.
Ну, и вот получается, получается, видите, ну, ну, почти что, почти что формульно заданный процесс со значениями в этом конечном множестве.
Ну, и вот, значит, в качестве задачи разберитесь, почему этот процесс будет марковский.
Ну, вот, ну, вот с нужными условиями.
Значит, здесь видите, ну, ну, опять какие-то, тут опять, конечно, какие-то комбинаторные вычисления возникают, похожие на те, которые вот я опустил и заслал конспекту.
Но здесь зато не нужна теорема Колмогорова, а сразу более-менее явно строится такой процесс.
Но однако надо иметь в виду, что в значительном числе задач, вот про марковский процесс и про цепи Маркова, почему-то бывает не важно иметь сам процесс,
а бывает важно иметь, ну, вот эти вот переходные вероятности там, вот что-то с вероятностями с этими делается, с переходными там, с вероятностями значений, но не с самим процессом.
Так что вот почему-то вот в отличие от большинства других процессов там, скажем, Винеровского, там Мартингалов, вот почему-то с цепями процессы, они как бы на втором плане,
а основную роль играют вот всякие такие вот эти вещи с, значит, с вероятностями вот с этой матрицей.
Вот теперь, значит, в связи с этими же, значит, вероятностями, значит, стационарное распределение.
Значит, стационарное распределение, значит, пи, стационарная или инвариантная, инвариантная мера цепи, если она не меняется под действием этой матрицы.
Ну, смысл такой, что если вы процесс начали, если вы Марковскую цепь запустили не с произвольного начального распределения, а со стационарного, то как бы, так сказать,
распределение со временем не меняется, вот с этим смыслом.
Скажем, вы можете запускать Марковскую цепь с какого-нибудь очень простого начального распределения.
Например, вы можете взять начальное распределение меры Дерака в одной из этих точек фазового пространства и из нее запустить, то есть как бы из точки запустить цепь.
Но тогда у вас уже после первого шага цепь будет распределена, она не будет с вероятностью единицы находиться в другой точке, ну там кроме каких-то особо выраженных цепей,
а она уже, так сказать, так типично распределится по всему этому множеству, с какими-то вероятностями в любой точке будет сидеть.
Но если верно такое равнится, то распределение меняться не будет со временем.
Ну и вот простая теорема, теорема существует для конечного набора всегда есть стационарные меры, ну инвариантные меры.
Значит, ну доказательства, значит доказательства, значит множество П, значит это все вероятностные меры,
ну вот на этом множестве, из конечного числа точек, это конечномерный выпуклый компакт,
потому что вы всякую меру, всякую меру М, вы отождествляете с набором точек, ну скажем, альфа-1, альфа-М,
где альфа-ит и не отрицательны, и сумма альфа-ит их единица, то есть это такой даже не просто компакт, а такой, так сказать, ну многогранник, симплекс такой получается.
Вот и П, вот это отображение, так, это непрывное отображение, ну оно даже лучше, чем непрывное, это просто линейное отображение,
ну поэтому существует неподвижная точка, ну это по общей теореме Боля-Брауера, что если у вас есть выпуклый компакт,
и есть непрывное отображение этого компакта в него же, то у него есть неподвижная точка, а тут ситуация более благоприятная,
отображение не просто непрывное, а линейное, так что это можно доказать и без теоремы Боля-Брауера несколько проще,
но хоть и проще, но нельзя сказать, что это прямо сразу очевидно, вот попробуйте в качестве упражнения, попробуйте не пользуясь теоремой Боля-Брауера это доказать,
это в общем можно сделать, но это нельзя сказать, что прям какое-то упражнение для восьмиклассницы, но попробуйте сделать,
но мы естественно будем пользоваться теоремой Боля-Брауера, но там наверное она где-то была в каком-то из ваших многочисленных курсов,
ну вот в каком-то была, сейчас, но давайте я тогда сформулирую эту теорему, раз уж я ее воспользовался, давайте я ее сформулирую,
значит теорема, теорема Боля-Брауера, значит если F, ну давайте так, V выпуклый компакт,
компакт ВРМ, значит и F из В в непрерывное отображение,
тогда, тогда существует точка X0 такая, что V от X0 есть X0, ну для отрезка эта теорема совсем упражнение,
а вот уже там для квадрата, там для треугольника, для круга на плоскости это уже не банальная вещь, ну такая я бы сказал совсем не банальная,
но значит по идее, ну в каких-то курсах это должно быть, ну в каких это курсах может быть, ну например если у вас какая-нибудь там топология под разными соусами,
ну я не знаю у физтехов много ли топологии, вот у мехматян топологии всяких прорыва, и там вот даже не в одном даже каком-то курсе вот такой факт,
значит откуда-то всплывает, значит этот факт может быть скраплен в матанализ, ну например если у лектора много лекций, он не знает что бы еще им рассказать студентам,
думает ну вот что-нибудь забубенное про ряды фурье, думает да нет зачем им ряды фурье в 21 веке, давайте я ему расскажу вот теорему Боля-Брауэра,
значит и с помощью, ну ее можно действительно если пол лекции анализа не пожалеть, то можно элементарно доказать используя формулу замены переменных,
используя формулу замены переменных, это вот так сказать в том матане где многомерный анализ, там формула замены переменных, значит в интеграле,
вот с помощью этой формулы замены переменных это можно доказать, ну это у этой теоремы много разных доказательств, есть такие почти школьные,
ну я бы сказал даже может быть точности школьные, такие комбинаторные, комбинаторного плана, где кроме большой проницательности ничего не нужно,
но как бы то ни было совсем коротко это не объяснишь, это действительно нуждается в доказательстве, ну и вот это было открыто независимо,
значит Боля-Брауэр это два разных человека, это не как мамин-сибиряк, это два разных математика начала 20 века, вот они этот факт обнаружили,
значит факт не очевидный, видите, он такой нельзя сказать, что он интуитивно очевиден, вот даже из физических соображений,
ну вот смотрите, он что означает, ну вот предположим, вы решили изготовить какое-нибудь варьево, так в кастрюле,
значит ну наполнили выпуклую кастрюлю или кастрюлю гомеоморфную, ну предположим она у вас уже не выпуклая от долгого употребления,
значит ну по крайней мере она осталась гомеоморфно выпуклой изначальной кастрюли, вы наполнили там всем, чем полагается для варьева,
и там по технологии надо тщательно перемешать его, ну вот вы мешаете, мешаете, значит долго мешали, ну вот оказывается,
что как вы не мешали, с каким бы тщанием вы не мешали, останется точка после всех этих ваших манипуляций, останется точка,
которая не сдвинулась, и вот вы так сказать, ну эту точку следующим мешанием, вы эту точку можете устранить, она сдвинется,
но появится новая точка, которая встала на свое место, так что вот совсем в буквальном смысле перемешать не удастся,
ну если конечно вы не так ожесточенно мешаете, что у вас там разрыв жидкости произошел конечно, значит тут все-таки отображение непрывное конечно,
так значит вот такой важный факт, такая мера очевидна не единственная конечно, таких может быть много,
значит вот мы в следующей теореме, которая называется эргодической, ну это такой ее простейший вариант для конечных цепей,
ну опять конечная цепь, и при некотором N1 все элементы этой матрицы в степени N1 положительные,
вот тогда значит, тогда значит инвариантная вероятностная мера,
ну пусть будет μ, единственная,
она положительна на всех точках,
и причем к ней сходятся, сходятся меры
для всякого начального пиноль,
ну в каком смысле меры сходятся, ну тут пространство конечное, поэтому меры сходятся, ну просто их значение,
ну в этом случае тут все разумные виды сходимости мер равносильны, ну значит значения на точках их сходятся,
ну кстати сказать, если знать последнее утверждение, то тогда конечно, ну единственность тоже из него следует,
потому что вы можете начать с какого-то пиноля, и значит говорится, что к этому стационарному будут сходиться,
ну значит сходиться будет к нему, значит смотрите, если вы начали с начального определения стационарного,
то тогда конечно сходимость будет, потому что если пиноль стационарна, то по определению стационарного это и будет пиноль,
так что ничего доказывать не надо, но тут утверждается, что вы начали с какого угодно,
значит когда с какого угодно, то естественно эти уже разные, поэтому вопрос, почему они сходятся,
значит тут меры на конечном множестве, поэтому понятно, что у такой последовательности всегда есть подпоследовательность сходящаяся,
но тут утверждается больше не про подпоследовательность, а про саму последовательность тут говорится,
так ну давайте зафиксируем, фиксированная стационарная, она какая-то есть по теориям более бравая,
значит ну для упрощения считаем, что n1 единица, ну то есть что у исходной матрицы переходной все элементы положительные,
ну это не самый общий случай, но общий случай похож только, ну чуть-чуть там технической возни больше,
так что вот такое упрощение сделаем, значит это упрощение неравносильно исходно утверждению,
потому что легко вы можете привести пример матрицы, у которой есть нолик, ну например матрица 2 на 2 есть нолик,
а возвели в квадрат нолик исчез, так что это действительно упрощение неравносильно исходному,
ну в общем доказательства, в общем случае аналогично, значит теперь важное обозначение,
значит берем матрицу, значит матрица, все строки, которые, значит все строки, которые, вот это вот мю,
ну давайте считать, значит мю там от x1 и так далее, мю значит xm, так, значит вот такая матрица с одинаковыми строками,
значит эта матрица сейчас будет играть, значит важную роль, значит для этой матрицы верно,
следующая, ну вот ради чего она и вводится, так, значит вот, значит для всякой вероятностной меры
пи, если вы примените эту странную матрицу к вероятностной мере пи, ну я напоминаю, по-прежнему меры записываются как векторы строки,
то получится мю, так, ну вот собственно это м так специально подобрано, чтобы это получилось, ну вы числением проверьте, что так будет.
Теперь, значит существует такое дельта больше нуля, что p и житые больше либо равно, чем дельта на m и житые,
ну дельта, давайте я напишу не больше нуля, конечно, а дельта из 0.1, ну оно больше нуля, но еще оно и дельта оно еще из 0.1 будет,
ну почему это так, ну это просто потому что p и житые положительные числа, а эти числа, ну какие-то числа, поэтому в качестве дельта можно взять ну минимум,
например, вот этих, значит, так, теперь, значит, возьмем лямда равна единице минус дельта, вот тогда, значит, ну вот тут начинается некая некая махинация с матрицами,
значит, за которыми надо внимательно проследить, чтобы не было обмана, а я вот когда впервые доказательство это прочитал, мне показалось, что какой-то обман,
но потом я его с конспекте выписал вроде, ну вроде нет, ну не было, но не знаю, может за год появился, значит, вам надо проверить,
значит, тогда, значит, смотрите, значит, p можно записать вот в таком вот виде,
значит, где q, ну это тоже матрица, там с элементами q и житые, которые не отрицательны, значит, которые не отрицательны эти элементы,
и ну матрица вот такая тоже, так сказать, стахастическая, сумма по ж, q и ж равняется единице,
а кто такая q, ну естественно, если это верно, то конечно q, тут же все остальные даны, p дано, m дано, λ дано, так что если это верно, то q вычисляется из этой формулы,
и поэтому фактически, что нужно проверить, ну мы не будем этого делать, естественно, на доске, но проверьте, вот тут как раз, я когда это впервые увидел,
мне показалось, что тут какое-то надувательство, но потом я вот на бумажке проверил отдельно, но не в конспекте, чтобы не портить, так сказать, вам, значит, удовольствие проверить,
значит, проверьте, что если q из этого соотношения задать, то получатся такие условия, вот, и еще что нужно тоже проверить,
вот тот, кто придумал это доказательство, конечно, был весьма проницательным человеком, ну я напишу, что при этом, вот такие вещи понятно как проверять,
но непонятно как открывать такие вещи, вот такое вот соотношение верно, вот такое соотношение верно, верно такое соотношение,
ну откуда, значит, как проверять это соотношение, ну давайте я в скобках помещу, откуда это взялось, но это тоже надо проверить,
значит, можно проверить, что m в квадрате будет m, так, и еще можно проверить, что m и p коммутируют, и коммутатор, ну что они коммутируют, и что произведение будет вот такое,
вот есть ли эти два соотношения проверить, да, что, что, где, нет, сейчас, а, сейчас, здесь, слушайте, у меня, сейчас, сейчас, сейчас,
сейчас, п, сейчас, слушайте, вот, слушайте, вот я хвастался, что все проверил, но, значит, так,
да, слушайте, вы правы, нет, слушайте, все-таки,
сейчас, сейчас, нет, нет, вот видите, в этом есть некий, так сказать, изъян того, что не пишешь в конспекте полное доказательство, так сказать, оставляя что-то проверить,
сейчас, вот я, легче всего было бы сказать, что p в степени n тут должно быть, значит, сейчас, нет, знаете, вы правы, n все-таки, да, n, нет, соотношение все-таки с n, да,
ну, я почему сомневался, потому что сейчас дальше будет, ну, значит, так сказать, заключительное, заключительное соотношение, значит, ну, которое даст то, что нужно, и там, там как раз,
нет, вы правы, да, тут, конечно же, n, да, значит, тут n, а, значит, ну, ну, давайте, слушайте, ну, тут еще у меня несколько минут есть, давайте я их использую, чтобы это проверить все-таки, раз уж тут, значит,
значит, смотрите, значит, смотрите, вот, вот те, вот, вот нижние соотношения не буду проверять, значит, они, ну, они реально простые, значит, значит, смотрите, что еще получается, q на m будет m, так, значит, теперь, значит, значит, теперь по индукции,
получается так, а p в степени n плюс 1, это единица, ну, вот, если подставить, если сюда подставить вот это, значит, если сюда подставить вот это, то получится, значит, вот так,
ну, ну, и итог получается, ну, то, что должно быть по предположению индукции.
Ну, и итог получается, ну, то, что должно быть по предположению индукции.
Да, вот так, значит, таким образом это доказано, значит, ну, и окончательный итог, ну, и вот, значит, на этот окончательный итог мне еще оставшиеся минуты должны хватить, значит, итог.
Итог, значит, так как, так как p 0 m минус mu m равняется нулю, то имеем p 0 m минус mu m равняется 0, то имеем p 0 m минус mu m равняется 0,
то имеем p 0 p в степени n минус mu, это p 0 в степени n минус mu, значит, вот так.
Значит, это p 0 минус mu на p в степени n, значит, и это есть p 0 минус mu, вот на что.
Единица минус лямда, значит, вот на это, тут в степени n, значит, вот здесь, значит, вот здесь в степени n, и вот это я выпишу вот здесь.
И на этом это уже почти что завершает доказательства, значит, это будет лямда в степени n на p 0 минус mu в степени n, вот так получилось, так.
Ну и теперь, теперь давайте заметим, что вот это, что вот это стремится к нулю, так, значит, почему, значит, почему.
Ну потому что, потому что норма вот такого вот вектора, оно, она оценивается через два, так, норма такого вектора оценивается через два.
Ну если, как считать норму, как считать норму вектора, ну если норму вектора считать как, значит, как сумма модулей.
Ну норма, ну давайте так считать, норма вот такого вот вектора, это будет сумма модулей.
Вот если так считать, то, значит, из-за того, что это вероятностные меры, то получится, ну и q такая, вот такая, какая она там была, такая вот, так сказать, стахастическая матрица, то, значит, будет верна такая оценка.
А лямбда меньше единицы, ну и поэтому это стремится к нулю. Ну и, ну и, значит, значит, таким образом сходимость есть, ну а из этой сходимости, значит, вытекает единственность.
Значит, да, да, да, еще почему, значит, почему последнее, значит, последнее замечание, значит, последнее замечание, почему, почему все элементы положительные у mu значение, так, значит, почему,
почему mu от x итых больше нуля, вот это, значит, вот это мы еще не сделали. Значит, ну это вот почему, потому что p от n1 mu от x итых это больше нуля.
Так, это из-за того, что у этой матрицы все элементы положительные, а у этой, ну есть положительные, остальные не отрицательные.
Но, но и из-за инавариантности это есть вот это. Вот так будет, так будет не только для нашей mu, так будет вообще для какой угодно меры вероятностной.
Это из-за того, что у этой матрицы все элементы положительные, поэтому если вы ее примените к какой угодно такой вероятностной строке, то получится все элементы положительные.
Но когда вы примените именно к этой mu, то это будут из-за инавариантности будут сами эти. Вот так что все, вот, значит, таким образом доказана вот такая теорема,
что в случае положительных переходов есть, значит, единственность и сходимость.
Вот этот факт, он важен даже для цепей с двумя состояниями.
Ну, можно сказать, что для многих практических задач это условие выполнено, что вероятности положительные.
И поэтому во многих случаях стационарное определение не только, но оно и единственное, и вот к нему еще есть сходимость.
Это во многих приложениях вот почему-то оказывается важным, что есть такая сходимость.
Ну и исследуется там скорость сходимости, но это мы уже сейчас не будем обсуждать.
Для общих марковских процессов тоже наличие стационарного распределения это очень важная вещь.
И вот для диффузионных процессов это важная вещь, но это, в общем, мы уже не будем обсуждать, это такие уже, так сказать, более тонкие вещи.
Так, все, значит, таким образом основная теоретическая часть закончена, а следующие две лекции это решаем совершенно конкретные две задачи.
