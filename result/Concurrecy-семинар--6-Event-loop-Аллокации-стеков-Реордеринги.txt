Итак, у меня сегодня нет четкого плана на нашу встречу,
но я пообщался с вашим представителем в чате, в общем, на днях про ивент-лупы,
про E-Poll и прочее, и кажется, выяснилось, что всё, что происходит, у нас бессмысленно,
потому что мы вообще ничего не понимаем, и, возможно, нужно об этом поговорить.
Ну, может быть, кто-то один ничего не понимает, а все всё понимают.
Но разговор меня встревожил несколько.
Был самый сильный представитель от нас.
Вот, я поэтому и встревожился, что кажется, что это не последний среди нас человек,
поэтому, возможно, мы можем написать задачу, скажем, про Slip4 и вообще ничего не понять,
и это был бы, наверное, не слишком полезный опыт.
Так что давайте мы ещё раз поговорим, у нас была лекция там,
мы решали две задачи, я напомню, на одной лекции недавних.
Мы разбирались, как сделать файберы параллельными, выделив крутину,
декомпозировав её от пулла и собрав из этого всего файбера, и вы, кажется, это уже сделали.
Дальше мы сказали, как можно файберы научить взаимодействовать с внешним миром.
Тут у нас возникло понятие ивент-лупа, цикл событий,
ну, то есть мы можем просто исполнять задачи, которые что-то делают,
но откуда задачи возьмут себе работу? Видимо, она придёт по сети.
И есть другое состояние, когда мы не просто разбираем очередь задачи,
а когда мы разбираем очередь событий.
Эта очередь событий, она реализуется, видимо, в ядре,
и нам людям доступна в виде, ну, какого-нибудь еппола, да?
Ну, и мы разбирали на лекции так коротко всем этот псевдокод,
а потом смотрели, как можно этот псевдокод переписать на чём-то более, наверное, крупном.
Нам нужен более крупный шрифт.
Получше? Получше.
Вот. На чём-то более высоком уровне он, по сути,
код работает так же, но при этом всё же мы работаем, ну, с какими-то,
ну, какая-то модульность здесь всё же присутствует в отличии вот этого кода.
Ну, а дальше тут в нашей очередной домашке, которая прямо сейчас открыта,
мы с помощью, мы этот event loop встраиваем файберы, ну, точнее,
меняем планировщик файберов с тредпула на вот такой вот event loop,
и поддерживаем файберы с крипфо.
Но если мы не понимаем, как работает вот этот код,
то вряд ли мы понимаем, как работает написанный нами код,
потому что, в конце концов, под капотом это выполняется нечто такое,
только вместо ассинкрицам у нас задача ассинквоить на таймерах.
Вот. Ну, и давайте поговорим про епол и поговорим, что мы о нём знаем, чего мы не знаем.
Ну, вот, во-первых, понятно ли вам, что по сути,
меняя тредпул на некоторый загадочный его контекст,
в котором есть какой-то еполог, какая-то магия,
мы, по сути, ничего сложного не делаем, мы просто меняем планировщик.
Планировщик, который можно отправить задачу,
а ещё можно с ним связать ожидания некоторого события.
Ну, вот, в условии мы говорим, что мы просто умеем бросать вот епол
плямды, которые там будут исполняться,
а ещё мы можем с этим еполом...
в его контекст бросать плямды, которые там будут исполняться,
а ещё мы можем с этим его контекстом связать объект таймер
и вот подвесить на него кулбер.
То есть задача выполнится не сразу, а когда реализуется некоторое событие.
Вот. Но, как минимум, его контекст умеет просто задачи исполнять.
И в его контексте в этом есть два типа задач.
Вот есть ваши задачи, которые просто отправили лямбда,
которая там должна исполниться,
и задачи служебные, которые запускаются, когда реализуется некоторое событие.
Ну, в сокете появляются байты, там истекает какой-то тайм-аут,
и тогда обработчик, кулбек, запускается его контекстом.
Мы это, наверное, понимаем, да?
А теперь смотрите, вот если мы понимаем или нет?
Ну, значит, плюс-минус.
Смотри, вот не бывает плюс-минус понимания.
Вот ты говоришь про программирование.
Если ты не можешь объяснить, как всё написано, значит, ты чего-то не понимаешь точно.
Тот же не вопрос, как оно должно примерно работать.
Твоих знаний, мне кажется, что твоя предшествующая жизнь вот здесь, вот в этих стенах,
дала тебе все необходимые, ну, должна была по крайней мере,
тебе все необходимые знания для того, чтобы ты понимал, как эта штука работает,
и просто ей спокойно пользовался, потому что ты уже выучил ей пол-накваси.
Так что если ты чего-то не понимаешь, если что-то выглядит теомагическим,
то, вероятно, это нужно обсуждать.
Вот мы вроде бы в курсе, начали прямо с самого процессора, с атомика.
Что такое атомик, что такое мьютекс, что такое фьютекс, мы узнаем вот совсем скоро.
Содачка уже вот доваривается.
Так что не должно быть ничего, что нам кажется магическим.
Приключение контекста тоже разобрали.
Вот если что-то кажется магическим, что-то плюс-минус понятно,
значит, давайте это обсуждать.
Вот что кажется магическим? Можете ли вы написать его контекст своими руками?
Давайте так.
Нет, а что тебя останавливает?
Ну, вот смотрите, его контекст, в него можно бросить лямбду,
а потом вызвать ран, и этот ран заблокируется до тех пор,
пока там работа в его контексте не кончится.
Причем я говорю, что его ран можно запускать из нескольких потоков.
Видели такое в условиях?
Просто задача у нас файбер параллельная,
поэтому задача в его контекст запускается из разных потоков.
Ну, на что это похоже? Это же просто тредпул, нет?
Мы бросаем в его контекст лямбда, потом из разных потоков завем ран,
и, видимо, разбирают очередь задач и запускают их.
Вот если убрать таймеры и вот эту магическую привязку таймера к его контексту,
то можно подумать, что его контекст этот тредпул и, в принципе, так и есть.
И еще раз, что делает таймер? Почему мы вообще его пишем? Я смотрю на лекцию.
Ну, в смысле, зачем мы пишем таймер и соки?
Ну, потому что это способ взаимодействовать с внешним недопинированным миром.
Время, сеть, диск.
Это все какие-то внешние обстоятельства.
Мне кажется, что вот в этих слайдах нет понятия его сервис.
Правда?
Вот ты смотрел эти слайды, да?
Так вот они вот в условии посередине лежат.
Мне кажется, что стоит.
А, или это была какая-то ссылка из условия?
Видимо, хотят меня чему-то научить, чему-то лишнему.
Нет, это ссылка, по которой стоит пойти, почитать.
И вот то, что там написано, это буквально одна из очень важных тем,
что будет в очередной лекции, который будет в субботу.
Все очень связано.
Вот ASIO — это не просто event loop и не просто thread pool.
Это некоторый вот такой сложный на самом деле очень фреймворк.
Мы из него используем только какую-то мизерную часть.
Но в нем много всего.
И в какой-то степени то, что в нем есть, мы сами сейчас перепредумываем.
И там, кажется, вот your service — это понятие...
Это старое название его контекста.
Его давно перефакторили.
Но, мне кажется, в этих слайдах там никакого его сервиса нет.
И тут, мне кажется, очень хорошие слайды.
И тут все объяснено, в смысле, чем эти три вызова отличаются.
Почему это не методы, это свободные функции?
Система, в которой было слепка общежира с отсосом, это метод ASIO-диспаче?
Это какие-то синтаксические рассуждения.
Ну вот в фиберах, которые были у нас на лекции про однопоточные фиберы, был метод диспач.
И он занимался диспетчеризацией.
Что нужно делать сейчас?
Что происходит?
Если ты посмотришь на тот код, ты поймешь, зачем он нужен.
Но если ты не понимаешь, зачем тебе код, то стирай его.
Вот еще раз, смотри, очень большая ошибка в курсе
и в жизни ориентироваться на какие-то синтактические
сходства.
Вот ты пишешь код, который тебе нужен, и вот ты написал
код, а потом смотри на него, и если вдруг ты поймешь,
где у тебя в твоем коде есть метод, который похож
на диспетчеризацию в некотором смысле, то ты его выдержишь.
Если нет такого, то ты не выдержишь, просто придешь
на защиту, мы с тобой поговорим.
Просто в шаблоне есть некоторая заготовка, которая мне кажется
разумной, потому что, скажем, у Файбера есть, не знаю,
Файбер хочет уметь останавливаться, Файбер должен останавливаться
вот здесь, вызовет слиффора, потом возобновляться.
Поэтому очень разумно, скажем, чтобы в Файбере были методы
suspend и resume, потому что логически Файбер эти шаги совершает
в своей работе.
Но может быть ты написал так код, что тебе эти методы
пока не заполняешь, ты реализуешь свой Файбер, ты открываешь
шаблон, видишь там что-нибудь и говоришь, что-то мне не
понравилось.
И вот вытеряешь все и стираешь, и пишешь что-то свое.
Вот так правильно делать, а угадывать, зачем эти были
методы, лучше сделать это в конце, то есть необходимо
исходить из своих потребностей.
То, что следует сделать, написано в условиях, какие-то
направления, которым нужно следовать, все важно, условие
оговорено.
А некоторые вещи ты напишешь сам, и как они тебе получатся,
так и получатся.
Зависит от твоего опыта, от твоих знаний.
Как минимум, у тебя должен код работать, а по вторую
очередь, он уже должен быть написан модально, понятно,
и это получится, а у тебя сразу не получится, трудно
предсказать, и научить тебя этому так насильно невозможно.
Все равно потом дальше будешь писать свой код, и будешь
писать его по-своему.
Вот лучше писать по-своему всегда, и дальше уже мы на
ревью обсудим, насколько получилось удачно или неудачно.
Так что не подстраивайтесь под шаблон, там, где от вас
этого не требуется.
В публичном опе его нет теста, про этот файбер, про
этот объект ничего не знают, поэтому там может быть написано
любой код абсолютно.
Так, вернемся к ASIO, это некоторая штука, ее контекст, некоторая
штука, которая умеет запускать задачи, которые есть в очереди.
А еще можно завести таймер, подвести на него колбэк,
завести таймер, который привязан к его контексту,
подвести на этот таймер колбэк, и вызвать ран, и ран
будет крутиться до тех пор, пока таймер не сработает.
Вот как бы вы такую штуку сделали, если вы знаете про
ЕПО, конечно.
Ну, пока в его контексте есть работа, текущая или
будущая, или запланированная на будущее, пока хоть что-то
в нем есть, мы не останавливаемся.
Собственно, это отдельный вопрос на понимание, вот
вы реализовали файберы, вот почему и запустили их,
вот когда и уран остановится, потому что файбер же он
запускается, работает, работает, потом засыпает, и все.
И вот исполнения готового активного нет сейчас.
Но почему-то его контекст продолжает крутиться,
продолжает чего-то ждать, видимо, потому что задача
файбера живая заменилась на заведенный таймер.
Когда он сработал, появилась новая живая задача, и вот
это все так продолжается.
Так вот, как можно строить таймеры?
Ну, вот вы можете...
E-Poll в Linux поддерживает таймеры.
Ну, или вы хотите сделать socket, E-Poll поддерживает socket.
А дальше, как бы вы реализовали его контексте, вот этот
самый таймер?
Что в этом таймере есть?
Что в полях этого класса должно быть?
Что происходит, когда мы говорим о сингвейт?
Ну, вот, пофантазируйте.
У вас знаний достаточно для того, чтобы этот код
себе представить весь.
Ну, может, мы просто, когда закончилось, мы уже
закидывали события, то, что...
Что оно чуть закончилось.
Вот, смотри, вот...
У нас даже лямда завершилась, мы не можем просто...
Какая лямда завершилась?
Которую вы закинули в...
Как она завершилась?
Я спрашиваю, как тебе...
Как сингвейт реализовать?
Ты говоришь, лямда уже завершилась.
А вы точно писали E-пол?
Ну, в смысле...
Вы точно им пользовались?
Да.
У нас не можно писать.
Просто в чате мы несколько написали, что вы писали
эхо-сервер с одним буфером.
Да, а где?
Ну, это же чепуха.
Это же не имеет смысла абсолютно никакого.
Сколько там буферов было, а я писал, и он больше...
Нет, ну...
Эхо-сервер, который писал человек в чате, не имеет
никакого смысла.
Его нужно только удалять и не писать.
Вот если вы писали такой же эхо-сервер, то нужно
беспокоиться.
Зная Кирилла, скорее всего, он писал с этой лучше,
чем писали мне.
Ну, давайте разбираться, потому что, кажется, если
мы не знаем E-пол, то это большая проблема для меня.
Что такое E-пол?
Очередь событий.
Вы туда можете положить сокет, зарегистрировать
там сокет, и вы можете заблокироваться на сокеты,
заблокироваться на вызове E-пол-wait, и дождаться,
пока либо события не появятся, либо таймер не пройдет.
Ну, тайм-аут не пройдет.
И дальше вы получите сокеты, которые готовы к той
операции, для которой вы их зарегистрировали.
Там чтение, запись.
Ну, или просто таймер там готов выполнить.
Таймер сработал.
Неважно.
И дальше, если мы говорим про сокеты, например, то
что вы делаете?
Вы из них читаете сразу, ну, или в них пишете сразу.
И вы делаете это без блокировки, потому что вы
установили сокеты в неблокирующий режим сначала,
а потом зарегистрировали в E-поле, да?
А теперь представим, что мы пишем эхо-сервер.
Вот с чего эхо-сервер начинается.
Ну, видимо, мы создаем серверный сокет, привязываем
его к порту, начинаем слушать и регистрируем сокет
в E-поле.
Да?
С этого же начиналось.
Ну, вот давайте я буду код ASIO показывать, который
был на лекции.
Вот у нас EO-контекст.
В нем будет спрятано этот самый E-POL-OD.
Очередь событий.
И вот мы конструируем сервер.
И в конструкторе мы строим объект acceptor.
А почему мы в контекст прячем E-POL?
В смысле, у нас это представление event loop, кроссплатформенного.
E-POL под линуксом есть, под другими ничего другого.
Но вот этот самый EO-контекст представляет из себя абстрактный
event loop, который использует какой-то конкретный механизм,
какую-то конкретную очередь событий для данной операционной системы.
Что?
Это не pattern adapter.
Почему?
Ну, вроде как раз самая.
Ну, это не...
Pattern adapter – это не единый интерфейс.
Он к единому интерфейсу не имеет отношения.
Pattern adapter адаптирует один интерфейс к другому интерфейсу.
Адаптер – это клей.
Как одну библиотеку с клеем с другой библиотекой.
Здесь мы ничего не клеим.
Здесь у нас EO-контекст – самостоятельная сущность.
Мы выбираем для него некоторые общие API.
Правильно ли я понимаю, что внутри это защит,
ну, грубо говоря, за их, на внутренней библиотеке,
если это винда, запускаем один уксус ввода,
если это винок, запускаем неполностропный диплом?
Ну, это называется реактор.
В общем случае это называется реактор.
Но есть два паттерна асинхронного водовывода – реактор и парактор.
Давайте пока не будем об этом.
В документации это если время останется, я про это расскажу.
Ну вот, у нас есть некоторый механизм для ожидания событий,
для регистрации подписки на события и ожидания событий.
Вот полиноксом это E-Poll.
И вот EO-контекст, он в себе инкапсулирует
вот этот самый системный механизм ожидания событий.
И смотрите, что мы делаем, когда мы запускаем сервер?
Мы конструируем объект-сервер,
и в конструкторе мы конструируем аксептор некоторый,
привязываем его к EO-контексту и передаем туда порт.
Что делает этот аксептор в конструкторе?
Ну, видимо, он строит серверный сокет,
видимо, он его привязывает к этому порту,
и видимо, этот аксептор регистрирует этот сокет в E-Poll.
Да, и говорит, какие именно события ждать.
Ну да, то есть мы собираемся из этого серверного сокета читать.
Вот этот серверный сокет спрятан здесь.
Вот аксептор – это, по сути, серверный сокет.
Вот некой магии пока, да?
Да.
Отлично.
Что происходит дальше, когда мы пишем махо-сервер?
Ну, мы начинаем крутиться в цикле, слушать какие-то события.
Надо было написать обработчики разных событий.
На самом деле мы зарегистрировали в E-Poll объект аксептора вот примерно здесь.
Даже не в конструкторе, а мы сначала создали этот объект,
привязали его, создали сокет, привязали его к порту,
а потом уже подписались на события чтения в E-Poll.
Да? Это понятно?
А у нас уже мы считаем, что есть E-Poll внутри аксептора?
Нет.
Еще раз, что мы делаем?
Мы реанимируем ваши знания E-Poll и пытаемся их разложить
по каким-то сущностям в библиотеке ASIO, чтобы каждый компонент был сам по себе разумен,
чтобы не пришлось писать этот странный голый код на CIS с этими родливыми циклами.
Его контекст – это очередь событий.
Это E-Poll. В нем E-Poll.
Эта сущность представляет собой очередь событий в ядре.
Аксептор представляет из себя серверный сокет.
И вот тут мы этот серверный сокет связываем с его контекстом,
то есть с E-Poll.
И вот здесь мы подписываемся на события.
Мы вешаем обработчик, который будет вызываться тогда, когда на серверном сокете появится клиент.
То есть вот этот обработчик запустится, когда...
Вот он, по сути, написан.
И вот когда мы говорим Run после конструирования сервера,
то начинает крутиться вот этот цикл.
И когда-то в нем достается из E-Poll серверный сокет.
И вот мы вызываем этот обработчик.
Да? Никакой магии.
Что этот обработчик делает?
Ну, по сути, регистрирует новый сокет E-Poll.
Ну, тут уже много кодов написано за вас в ASIO,
а тут вы видите, вы в колбейке получаете уже готовый сокет на самом деле.
То есть ASIO за вас вызвало Accept,
получило сокет, перевела его в не блокирующий режим, не перевела, наверное.
И вот вы по обработчике его имеете.
А дальше что вы делаете?
Вы порождаете объект Sessia, который будет обслуживать одного клиента.
И после этого снова вызываете DoAccept.
То есть снова подписываете серверный сокет.
И тогда снова подписываетесь на события на нем в E-Poll.
Понятно, да?
То есть это не рекурсия ни в коем случае, это такой цикл из задачек.
А он нам учится только один сокет разрешать, да?
Ну, то есть в E-Poll мы же можем там массив, мы можем всю массиву произнести.
Ну, он может проходиться по массиву,
но обработчик, кто он занимается, зачем тебе про массивы думать?
Это деталь реализации E-Poll, чтобы минимизировать количество там вызовов.
И тут ты работаешь с отдельными сущностями.
Acceptor, Socket.
Внутри, что происходит внутри раны, тебя вообще мало волнует.
Тут, может быть, его контекст получил 10 событий,
и потом вызвал 10 обработчиков подряд.
Вот, но тебе же вот в этом контексте нужно знать про твой текущую задачу,
про то, как принимать клиента.
Вот, значит, никакой магии здесь нет, да?
А что происходит дальше?
Ну, дальше мы, видимо...
Ну, что происходит в их сервере? Давайте так.
Ну, нам нужно второе событие еще сейчас обработать.
Это получение...
Ну, когда в E-Poll пришел socket уже не серверный, а...
Ну вот, у нас появился клиентский socket.
И мы хотим теперь, с одной стороны, ждать события на серверном socket по-прежнему,
потому что клиенты все еще приходят.
А с другой стороны, у нас появился клиент, нужно его обслуживать.
Поэтому мы должны socket этого клиента тоже зарегистрировать E-Poll и ждать на нем ввода-вывода.
Поэтому мы здесь конструируем object-session,
и после конструирования вызываем этот метод start.
А метод start что делает?
Говорит socket async.readsum.
И вот этот async.readsum регистрирует наш клиентский socket в E-Poll
и подвешивает к нему еще callback.
Что когда из этого socket, когда на этом socket появятся данные,
E-Poll их здесь прочтет и в буфер переданный.
И вызовет вот этот callback.
Опять все понятно, да?
А вот что непонятно?
Потому что я просто обсуждаю, как эхо-сервер обернуть в классы.
Я понимаю, что обсуждается декомпозиция просто.
Не, не декомпозиция.
Просто интерфейс меняю.
Ну мы просто по сути переводим на более высокий уровень код, который мы видели в мане.
Не код, который вы видели в мане, а код, который вы писали.
То есть ты писала E-Poll когда-нибудь в своей жизни, использовала E-Poll, то?
Я пользовалась E-Poll в двух задачках.
Сейчас такое ощущение, что я не пользовалась E-Poll в двух задачках.
Я писала их сама.
Ну эхо-сервер ты писала?
Да, это же эхо-сервер.
Вот, и ты получала сокет клиента после того, как у тебя случилось событие на сервенном сокете.
Регистрировала E-Poll и ждала события.
А что ты делала, когда на сокете клиентском загоралось событие?
Что вот он готов к чтению.
Вот Асю что делает?
Он сам за тебя этот сокет берет в Event Loop, вот здесь вот, и вычитывает данные из сокета.
Тот буфер, который ты вот здесь передала.
Я вручную вычитывала, да.
Ну здесь тебя делает Асю.
И дальше вызывается вот этот колбэк.
То есть ты прочитала, и дальше вызывается вот этот код.
Здесь в данном случае он выполняет DoRight.
Я скорее не понимаю, я не особо часто работала с колбэками,
и поэтому когда я вижу колбэк, у меня немножко большие ступы каждый раз.
Ну колбэк это просто код, который вызывается в обработчике события.
Вот у меня есть серверный сокет.
Вот у меня есть событие на нем.
Вот он готов к чтению.
Вот у тебя есть обработка этого события.
Ну такая понятная. Принять клиента.
А дальше есть твоя логика уже, как ты этого клиента обработаешь.
Что ты сделаешь дальше.
И вот тут Асю говорит, напиши колбэк, что именно ты собираешься делать сокет, который Acceptor получил.
Асю уже не знает, как ты хочешь с этим клиентом работать, поэтому он тебя просит.
Вот в AsyncAccept напиши колбэк.
Я за тебя, Асю говорит, приму клиента, построю сокет,
а дальше вот напиши код, который скажет мне, что дальше с этим сокетом делать.
А я понимаю, что это все в одном потоке.
Ну а это происходит в том потоке, который вызывает ран.
Вот тот поток, который вызывает ран и крутит этот event loop и все это обрабатывает.
Вот именно здесь происходит вот это вот.
Кстати, есть такой вопрос, почему мы сейчас используем лямбда, а не указательную функцию?
Вот да, тот же вопрос.
Что?
Почему лямбда?
А не что?
А не указательная функция?
Зачем мы пользуемся удобными инструментами, а не едим блины с лопаты?
Хороший вопрос, потому что так удобнее.
Но причем тут, смотри, указательная функция это указательная функция, а лямбда это, например, замыкание.
Как ты реализуешь замыкание через указательную функцию?
Никак, наверное, да?
Ну, функцию мы уже в метагоге передали.
А как?
Это есть замыкание.
Пойнтер на функцию – это пойнтер на код.
А этому коду нужен некоторый контекст для исполнения.
Это называется замыкание.
Да, но…
Функция, захваченная из лексического контекста перемена.
Мы не используем звездочку, а во звездочку какого угодно размера сама распасется.
А откуда эта во звездочку возьмет данные?
В синксисиаре.
То есть ты еще заведешь структуру, в нее положишь какие-то объекты,
вызовешь функцию, которая эту структуру возьмет, закастит.
Ты знаешь, что такое замыкание?
Да.
C++.
Ты знаешь, что компедиатор генирует весь этот код за тебя?
В нем.
Он за тебя сгенирует класс, у которого будут нужные поля, метод…
Вот.
У нас что-то есть.
Зачем мы пишем много странного, уродливого кода вручную,
вместо того, чтобы воспользоваться компедиатором, который может сгенировать его автоматически?
Вопрос звучит так.
Я даже не знаю, как на него ответить, честно.
Ну, потому что компедиатор сгенирует весь этот код сам.
Это же удобно.
Нет, я, конечно, могу завести структуру, положить туда…
Вместо того, чтобы написать такой код вот здесь,
я могу завести структуру, в нее сделать поле shared pointer,
сделать какой-то оператор круглые скобочки, написать там какой-то код,
сконструировать этот класс, передать вот…
Ну, зачем?
Я вот просто пишу лямбду и говорю, что я хочу захватить в эту функцию такие вот переменные
из текущего лексического контекста и выполнить в ней такой код и принять такие аргументы.
Ну вот, просто язык мне дает инструмент, который решает эту задачу – построение замыканий.
Ну ладно.
Звучит так, как будто бы…
Смотри, замыкания – это конструкция языковая.
В компьютере замыканий нет.
И, по крайней мере, в наших компьютерах.
Я не понимаю, что просто более высоковыравленный инструмент,
к кому-то, наверное, бы удобный.
Они удобны всем.
Но я не понимаю, что заниматься вручную локацией,
писать какой-то boilerplate код, который просто…
Как тебе сказать?
Ты же не пишешь на Assembler, ты же пишешь классы.
А класс – что это такое?
Это набор функций, у которых есть дополнительный аргумент, неявный.
Пойнтер на объект.
Но ты, тем не менее, не пишешь все так, как на C.
А пишешь класс.
Ну давай не писать классы тогда.
Ну потому что зачем?
Они же тоже реализуются эквивалентно без классов.
Просто вот заводишь функцию, вместо класса, там, не знаю…
Вместо класса Vector ты можешь завести структуру Vector.
В ней сделать там char…
там t звездочка буфер.
И потом size t size.
И сделать мне функции pushback.
Ну ни к чему хорошему не приведут.
Ну то есть зачем?
Вот у тебя есть языковая конструкция, которая помогает тебе
удобно, емко выражать свое намерение.
Ты и пользуешься.
Так, все, давайте вернемся к происходящему.
Что?
Такого не было.
Ну потому что вот мы подписались на событие, что в socket появилась данное событие,
случилось все.
Мы второй раз подписываемся на него повторно.
Еще раз, мы ничего не понимаем.
Что такое oContextRUN?
Что такое oContextRUN?
Он вызывает этот цикл.
В этом цикле из Epoxy достается событие.
На серверном socket доступно чтение.
Мы в этом цикле понимаем, что это был серверный socket,
вызываем на нем accept не блокирующий.
Получаем socket, вызываем здесь обработчик пользователя.
Этот обработчик пользователя что делает?
Он вызывает doAccept.
Что делает doAccept?
Регистрирует в Epoxy событие.
То есть снова регистрирует Epoxy этот серверный socket.
Но это не рекурсия, это просто мы здесь, внутри этого кода, еще раз зарегистрировали socket.
И все, и вот обработчик завершился.
Операция поэтому и асинхронная.
Мы не дождаемся пока она завершится, мы просто подписываемся на ее завершение.
Так что здесь вот есть цикл.
Я показывал картинку на реакции, давайте я сейчас ее реанимирую.
Сейчас, секунду, можно я закончу?
Вот, это задача, которая вызывает aSyncAccept,
после которой когда-нибудь запускается Epoxy,
в котором зовется accept.
И после этого вызывается снова doAccept,
который снова вызовет aSyncAccept, который снова регистрирует.
То есть вот мы так, по сути, в этом цикле исполняем поочередно две задачи.
aSyncAccept, то есть обработчик пользователя,
и Epoxy и accept, который выполняет сам event loop.
И вот они так чередуются, эта задача порождает в конце концов эту задачу,
эта задача в конце концов запускает эту задачу.
И вот они так вот бегают по кругу, и вот соединение приходит, приходит, приходит.
Вопрос?
У меня вопрос не было, я просто не отдаю, что там еще лекция была.
Ну нет, если он сейчас.
Ты обесцениваешь наше усилие сейчас.
Ладно, я вопрос молчать буду.
Нет, ты можешь не молчать, но нам действительно нужно разобраться подробнее.
Итак, значит, мы с этим циклом разбрались, да?
Теперь мы идем дальше, смотрим на этот код.
Здесь у нас, ну не так, давайте не на этот код смотреть,
а вспомним, какой код вы писали.
Вот у вас есть Epoxy, вы в цикле принимаете соединение.
Вот, и вы регистрируете соки клиентские.
И вот у вас в цикле Epoxy случилось событие, на клиентском соке доступно чтение.
Что вы делаете?
Это вот по сути обработчик, вот асинкрица.
Что вы в нем пишете в своей реализации эхо-сервера?
Что вы там писали?
Вы достали сокет, дискриптор, на котором можно читать.
Ну, видимо, вы читаете.
Читаете в какой-то буфер, читаете без блокировки, потому что вы же знаете, что теперь сокет доступно чтение.
Что вы дальше делаете?
Какой код написан дальше?
Идем дальше по дискрипторам.
А куда ты данные прочитала сокета?
У меня буфер есть какой-то один.
Один буфер, да?
Один.
А вот теперь представь, что у тебя есть три клиента.
Да?
Они пришли к тебе конкурентно.
У меня три буфера тогда.
Ну, вот я просто не понимаю, как ты с одним буфером живешь.
Ну, у нас изначально была постановка такая, что у нас клиент один.
Ну, в общем, один здесь, один здесь.
Все удобно.
Как тебе сказать?
Даже если ты учишься, ты не должна делать бессмысленные вещи.
Ну, потому что зачем учиться бессмысленным вещам, правда?
Вот я тоже так думаю.
Я не понимаю, как можно с одним буфером.
Ну, вот у тебя есть три клиента.
Зачем тебе не блокирующий код?
Зачем тебе E-Pool, когда у тебя клиент один?
Ты с одним трудом прекрасно справишься с блокирующих вызовов.
Ну, какая польза от этого?
Никакой.
Польза есть, когда у тебя клиентов много.
А поток все еще один.
И вот у тебя есть три события из E-Pool.
То есть на трех сокетах загорелась операция чтения.
И что вы такого код не описали?
Подожди, что значит поток?
Поток один тут.
Клиентов, может быть, сколько угодно.
Надеюсь.
Я помню, что я открываю три окошка.
Из них писал стопы на сервисе.
Ты хочешь три клиента, а мой код обрабатываю?
Нет.
Ну, если бухер один, то нет.
Для каждого клиента.
Значит, у вас было много бухеров?
Каждого клиента один.
Хорошо.
А где вы его латировали?
На стеке.
На каком стеке?
Внутри функции отзыва.
Ну, вот, значит.
Звучит очень плохо уже.
Ну, хорошо.
Вот у тебя загорелось событие на сокете.
Сокет готов к чтению.
Ты прочитал, вызвал какую-то функцию.
В ней прочитал данные в буфер.
На этом стеке.
А на стеке этой функции что произошло дальше?
Ну, дальше я написал обратно.
Как?
Ты написал сокет-райт какой-нибудь, да?
Да.
А почему он не заблокируется?
Вот я клиент, я просто...
Что?
Это не так работает.
Сокет в неблокирующем режиме, это не когда он делает запись в неблокирующем.
А когда он не может сделать запись, он говорит, что он не может сделать запись.
Ну, нельзя просто в сеть писать бесконечно.
Ты знаешь, где CP устроено?
Подожди.
Нельзя писать в сокет бесконечно.
Конечно, есть congestion control, есть flow control.
То есть ты пишешь в сеть, и с одной стороны ты перегружаешь в сеть,
с другой стороны ты перегружаешь получателя данных.
И в TCP есть очень много сложных механизмов, которые позволяют вот так децентрализована,
принимая локальные решения, контролировать как нагрузку глобальную на всю сеть
между многими-многими парами участников.
Ну или скажем, вот у тебя есть сервер и клиент.
И сервер отвечает клиенту, а клиент просто не читает.
Он нашел пить чай.
А сервер хочет ему GIGABYTE данных отправить.
Но он же не может там отправить все GIGABYTE данных.
На клиенте они не поместятся.
Почему? Мы отправили, а вот как?
Кто уже получает эти наши данные?
Сейчас, подожди.
Я тебе могу про TCP объяснить?
В TCP так не работает, ты говоришь, разумеется.
Сеть не передает данные бесконечно.
Почему мы ее не видим?
Сейчас, подожди.
Мир так не работает.
Мир так не устроен, как ты говоришь.
Если у тебя есть клиент и сервер,
то между ними должен быть механизм Flow Control и Backpress, это называется.
Если с другой стороны данные не принимают, то отправлять их перестают.
Потому что это лишняя нагрузка на сеть.
Ну представь, я генерирую данные со скоростью миллиард,
не знаю, GIGABYTE данных в секунду, отправляю их в сеть.
И так делают много компьютеров.
Сеть не сможет такую нагрузку переживать.
Должен быть механизм, который обеспечивает обратную связь,
который запрещает клиентам, которые работают с сетью, так сеть нагружать.
Потому что один клиент убьет всю сеть.
Он займет всю пропускную способность.
Послушай, пожалуйста.
Поэтому на уровне протокола TCP, транспортного протокола,
который отвечает за доставку данных между парами клиентов,
есть механизм, который делает следующее.
Он отправляет данные, и если он не получает вовремя подтверждение,
что клиент их получил, если он способен другая страна их вырабатывать,
то он снижает скорость, с которой он все данные может писать.
У него есть некоторые ограничения, сколько байт он может писать в единицу времени через себя.
И ты не можешь просто взять и писать socket, взять и сделать write в socket.
Этот запись в socket может также заблокироваться,
как может заблокироваться чтение socket.
Здесь ситуация абсолютно симметричная.
Поэтому если ты получил событие, что socket готов к чтению,
то ты, безусловно, можешь без блокировки их прочитать.
Но ты не можешь в данном случае без блокировки их записать.
Если ты поставил socket в блокирующий режим, то может быть твоя запись случится,
а может быть тебе socket ответит, что он не готов сейчас к записи.
Он скажет, я был блок.
И все, и твой сервер разломается.
А если ты поставил блокирующую запись, а не неплокирующую,
то ты получил однопоточный сервер, который заблокировался на одном клиенте и других больше не обслуживает.
Поэтому, разумеется, так писать код нельзя.
Это полная бессмысленность.
Когда вы получили данные socket, вы их читаете в какой-то буфер.
А после этого вы должны в E-Poll зарегистрировать socket на события, он готов к записи.
И когда вы второй раз из этого E-Poll достанете события, socket готов к записи,
то вы уже из этого буфера, который где-то находится, запишете данные туда без блокировки.
Потому что E-Poll вам сказал операционную систему, что вот сейчас socket готов обслужить вашу запись.
И то непонятно всю или не всю.
И то вы здесь не знаете, сколько именно байт вы сможете socket записать.
Потому что, может быть, клиент с другой стороны сколько-то вычитал данных с socket,
но все-таки не все еще, что мог бы.
И вы отправитесь туда не 100 байт, которые у вас есть, а 50.
А остальные останутся в буфере.
То есть клиент должен снова отправить запрос, чтобы он готов столкнуть прочитание?
Нет, он не отправляет запрос.
Это просто механика TCP-соединения.
Там бегают дотограммы туда и сюда, а в одну сторону.
То есть не то, что туда и сюда, это же двунаправленный канал.
Вот ты отправляешь данные, отправляешь дотограмму,
а в обратную сторону ты получаешь подтверждение, что они доставлены,
плюс еще некоторую информацию о том, сколько еще данных клиент сейчас готов получить.
Вот там есть понятие окна.
Вот ты не можешь сказать socket бесконечно.
Вот у клиента есть с другой стороны окно.
И если окно заполняется в операционной системе, то есть буфер некоторый внутренний,
а клиент из него не учитывает, то все, отправка останавливается.
И в обратную сторону вылетает сигнал, что все остановилось, хватит отправлять.
Вот, и смотрите, что у вас получается теперь.
Вы можете из трех socket'ов прочесть данные,
а потом некоторое время не сможете их записать.
И вот у вас теперь есть три соединения, у вас должно быть три буфера,
потому что у вас три соединения находятся между чтением и записью.
Вот, но поток у вас всего один, поэтому никаких локальных переменных,
никаких глобальных переменных быть не может, вам нужна динамическая локация.
Вам буферы нужны на куче, которые живут до тех пор, пока живут ваши соединения.
И вот ровно поэтому мы здесь алоцируем структуру session на куче,
и в ее поле кладем этот самый буфер.
И когда мы принимаем клиента, мы вот этот session конструируем.
Вот он, этот объект, он и несет в себе буфер.
А когда мы планируем операцию учтения,
то мы захватываем в обработчик сильную ссылку на этот объект.
То есть мы продляем время жизни class of session, в котором лежит буфер,
до тех пор, пока socket не будет готов к чтению, не прочитает данные,
и мы их не обработаем.
А когда мы их будем обрабатывать, мы снова заведем асинхронную операцию,
то есть зарегистрируем socket уже на запись,
снова захватим сильную ссылку на текущий объект, чтобы буфер продолжал жить.
Ну короче, здесь ситуация симметричная.
И вот и чтение, и запись, и это абсолютно симметричные события,
и при работе с Epolem они обрабатываются, конечно, однородно.
То есть мы и то, и другое кладем в Epole, и читаем, и пишем,
только тогда, когда socket, когда Epole нам сказал,
что из socket можно читать или в socket можно писать.
Вот нам нужно много буферов, и собственно, вот эта программа,
она написана так, и ваша программа не может быть написана по-другому принципиально,
потому что мы все очень же заворачиваем код класса сейчас.
Я вас понял, честно говоря.
Просто две вещи.
Первое, мне не приходило в голову, что мы не можем просто кидать данные,
а вот как они идут, как вы, как они получаются, это не наша проблема, я так думал.
А во-вторых, по-моему, мне, ну,
я это вот показывал нескольким проверяющим в манере кто из них,
и не сказал никаких замечаний.
Поверяющие тоже студенты, поэтому...
Будь осторожен, не доверяй людям.
Мне кажется, ну, есть много мест, где можно про тебя прочитать,
есть очень-очень простая статья из очень хорошей книжки,
там вот все на пальцах.
Ну, эта книжка так называется, High Performance Browser Networking.
Ну, давай я просто чат отправлю общий потом, после семинара.
Вот тут какие-то очень поверхственные механики TCP,
и, по крайней мере, все важные вещи тут описаны.
Тут есть Flow Control описан, Congestion Control,
ну, то есть TCP, смотрите, это, на самом деле, сложная вещь.
Осенью мы с этого спецкурса начнем,
с распределенным системам.
TCP это распределенная система.
Есть вот один участник, другой, если участник не на разных машинах,
а между ними есть какая-то общая сеть.
И эти участники не понимают глобально, что происходит,
в каком состоянии их собеседник,
и в каком состоянии сеть.
Поэтому они пытаются принимать локальные решения,
так чтобы и адресаты не перегрузить данными,
и не захватить там всю сеть своим потоком одним.
Вот для этого в TCP много разных механика.
Это вообще-то очень сложный протокол.
И протокол установки, ну, не знаю, если вы когда-нибудь смотрели,
как вообще соединение открывается-закрывается.
Это очень сложно.
Вот какие-то внутренние состояния протокола.
Там можно шею себе свернуть.
Вот это хитрая штука.
И писать в socket просто так нельзя.
Мы должны блокироваться и в классе событий регистрироваться в Epoly
и ждать, когда из Epoly прилетит событие о готовности socket.
И вот я в чате спрашивал и столкнулся с тем,
что никто не ответил или человек один не ответил.
Но вот смотрите, когда мы регистрируем события в Epoly,
точнее не так, когда мы получаем события из Epoly,
то нам же отдают структуру некоторую.
И в ней есть в частности дискриптер, на котором возникло событие.
А еще есть, смотрите, какой-то поинтер.
Понимаете ли вы, зачем этот поинтер нужен?
Это так называемый непрозрачный указатель, который Epoly ничего не знает.
Вот когда вы регистрируете событие в Epoly сейчас,
если здесь, когда вы регистрируете событие в Epoly,
то вы же этот указатель передаете в Epoly.
А когда события наступают, вам его возвращают.
То есть сам Epoly никак этот поинтер не интерпретирует.
Это какие-то ваши данные.
И когда мы регистрируем socket, мы кладем туда какой-то поинтер.
Когда мы достаем событие, мы этим поинтером можем воспользоваться.
Вот, простое вопрос на понимание.
Если вы пишете асинхронный эхо-сервер, нормальный,
то как вы будете пользоваться этим поинтером?
Ну, вы в этот поинтер при регистрации socket
просто положите поинтер на буфер свой,
чтобы когда вы получили событие из Epoly,
вы взяли этот поинтер, его закастили в чар-звездочек каком-то,
и в него прочли данные.
Или если вы пишете ASIO, то вы можете через этот поинтер
связать события на socket с каким-то объектом таймер,
с каким-то объектом socket.
Понимаете?
То есть найти объект, к которому эти события логически привязаны.
Там не нужна никакая мэпа,
которая отображает дескрипторы в какие-то таймеры.
Вот ровно для этого и существует этот поле.
Это достаточно удобно.
Его можно по-разному использовать, но все применения примерно такие.
Ну, что мне сказать?
Мне кажется, что я код разобрал.
То есть сейчас должно быть все понятно.
Да?
То есть я понимаю, что...
Его контекст написан, конечно, сложно,
и там много всего внутри,
много всяких сложных непонятных штук.
Но мы, наверное, сейчас не хотим их разбирать.
Давайте я другой вопрос задам, лучше.
Вот его контекст крутит этот even loop, да?
А еще он же может запускать не только...
Сейчас давайте вернемся к этому примеру.
Вот мы здесь положили... Мы сконструировали таймер.
Видимо, здесь мы завели файловый дескриптор для таймера.
Здесь мы, видимо, зарегистрировали дескриптор в Epole.
А здесь мы крутим Epole и дожидаемся, пока это событие не наступит.
Там достаем таймер.
По поинтру из события достаем объект таймера, вызываем callback.
Как-то так можно было бы себе это представить.
А теперь...
Вспомним, что его контекст, это же не только Epole,
его контекст может исполнить просто задача.
И как бы мы одно с другим связали.
Но, видимо, в его контексте есть Epole,
а еще есть просто очередь задач.
И как нам между ними балансировать?
Ну, просто смотрите, в чем мой вопрос.
Когда мы спим на Epole, мы же блокируемся
и можем ждать некоторое время, пока событие не наступит.
А у нас же еще задача просто есть.
Вот как нам организовать код?
Не надо.
У нас есть однопоточный код. Его контекст.
У него есть очередь задач и есть Epole.
Как он будет в Run между ними балансировать?
Было бы странно ведь блокироваться на Epole в Wait,
когда у нас есть готовые обработчики для запуска.
Нет, не будем ничего такого делать.
Мы пишем простой однопоточный код.
Его контекст с вызовом Run, чтобы запускать его из одного потока.
В этот его контекст можно положить просто задачу,
а можно сделать Epole Wait внутри.
Так вот, смотрите, когда задач нет,
его контекст Run должен блокировать поток.
Разумно?
Да.
Вот.
Когда задача есть, задачи должны выполняться без ожидания.
Так вот. Как же нам такой код написать?
А если их надо управлять без ожидания?
Без блокировки потока, в смысле.
Просто брать и выполнять.
Мы пишем. Его контекст однопоточный.
Один Run вызывает из одного потока.
Ты что-то очень сложное сегодня говоришь.
Давайте я расскажу. Что-то не получается.
Какой поток? У нас всего один поток.
В этом примере всего один поток.
Откуда берутся еще потоки? Я не понимаю.
Мы пишем. Его контекст.
Мы в нем сделали Epole.
Умеем там заводить таймеры, умеем там поддерживать сокеты.
А теперь мы хотим просто иметь возможность
запускать в нем задачи без ожидания.
Ну просто чередовать два механизма.
Вот если у вас есть задача,
вы вызываете задачу, а потом вызываете Epole.
И смотрите, когда вы вызываете Epole.
Если у вас есть уже готовые задачи,
помимо Epole,
то вы вызываете Epole Wait без блокировки.
Просто берете готовые события,
но не блокируетесь.
Потому что прямо сейчас у вас есть задачи,
которые можно исполнить.
А если у вас очередь задач на исполнение пустая,
то так уж и быть.
Вы заблокируетесь на Epole Wait.
Потому что пока из Epole Wait не придет событие,
задач не появится.
Потому что только задачи порождают новые задачи.
Понятная идея?
То есть мы в Run засыпаем на Epole,
когда вообще делать нечего,
но если есть какие-то готовые задачи,
и ее положили с помощью пост,
то мы в этом Epole блокируемся.
То мы, наоборот, в Epole не блокируемся,
просто вызываем Epole Wait с нулевым тайм-аутом,
получаем готовые события,
обрабатываем их,
и просто запускаем задачи из очереди,
которые рядом лежат.
Но на самом деле можно сделать все по-другому.
Можно сказать, что его контекст просто запускает задачи,
а среди этих задач есть задачи ваши,
а есть задачи служебные,
которые вызывают Epole.
И Epole в этих служебных задачах блокируется,
когда других задач нет,
и не блокируется, когда другие задачи есть.
И вот получается, что он способен и кулбеки запускать,
и просто запускать задачи кулбеки,
такие без события,
и подписывать и заводить кулбеки,
которые запускаются по событию там таймера.
В смысле, каких два?
Я один рассказал.
Просто чередуем одно и другое Epole,
и запуск задач.
Просто тут у нас вопрос только в том,
блокироваться или не блокироваться в Epole Wait.
Мы блокируемся, если других задач вообще нет,
потому что задачи возникают только
к реакции на события.
То есть мы начали эхо-сервер писать,
точнее мы его запустили,
мы зарегистрировали в Epole серверный сокет,
а потом ничего не происходит,
клиентов нет.
Но Epole блокируется.
Теперь клиент появился,
мы его обработали,
мы создали для него сокет,
создали сэшн, зарегистрировали что-то еще.
И теперь...
В этом примере, кроме Epole Wait,
ничего нет.
А в этом примере уже появляется пост,
и в нем могут быть независимые задачи,
их просто нужно выполнять.
Так что не должно быть вопросов,
как это реализовано.
Можно себе представить целиком этот код,
а дальше можно представить себе,
что в таком планировщике мы запускаем файберы,
и вот эти кулбеки, которые там запускаются,
это не что иное, как резюм,
корутин файберов.
Вот нужно вот эту картинку,
ну в смысле наши файберы,
встроить вот в эту картинку,
и все должно сочетаться.
То есть в конце концов,
и его контекст и ThreadPool запускают задачи,
но в его контексте запускается
некоторая служебная специальная задача,
которая опрашивает очередь событий
операционной системы.
И вот мы с ней взаимодействуем
с помощью вот всяких этих примитивов,
типа таймера или socket.
И вот так все это вместе крутится.
Понятно, да?
На самом деле, конечно, понятно,
если ты напишешь шехосевер настоящий
на Японии руками,
тогда станет понятно.
Без этого мы не все понимаем.
Ну ладно,
я даже не знаю,
что еще можно про этот код рассказать.
Ну подумай, какие вопросы у тебя еще возникают,
или ты еще не делала задачу,
которая перед нами.
А с карутиной мы...
Там вопросов не осталось у нас.
В целом, мне понятно,
не кто у нее работал.
А с карутиной мы...
Там вопросов не осталось у нас.
А с карутиной мы...
А с карутиной мы...
Чем должен быть твёрдый уровень гестации?
Чем должен быть твёрдый уровень гестации?
То есть только из-за того,
что мы хотим, чтобы она была видна на бурном файде, да?
Ну давайте, набросайте какие-нибудь вопросы.
Вообще, меня интересна по поводу локатора.
Какого локатора?
Ну, нам же в задачах противно нужно написать свой вариант локатора.
Локатор астек?
Ну, так.
Так.
Я, конечно, писал что-то, но не самое глупое.
Мне кажется, что если бы мы, например, знали...
Мог ли эстеку сказать какой-нибудь число?
Допустим, он бы его помнил.
Может, было бы написать локатор гораздо лучше?
Чем он был бы лучше? И причем? Что такое число?
Ну, условно говоря, его номер.
Я просто честно говоря хотел написать фулл локатор.
Но понял, что это, наверное, можно делать.
Ну, в смысле, ты про тредлокал говоришь?
Нет, ну про стейк.
Ты точно понимаешь, что такое тредлокал?
Ну, там, в пуре потоков ты использовал тредлокал переменное.
Потом ты говоришь про какие-то номера потоков.
Номера потоков никому никогда не нужны.
Нет, я никогда номера попал.
Он говорит про локацию стейка.
Про локацию стейка?
Да.
Ну, ты говори, число какое-то?
Размерово.
Нет, не номер.
Ну, номер. Я хотел написать...
Номер чего?
Номер локатора, чтобы мы бы много раз не делали допрос к системе, чтобы он выделал нам память.
Так мы для этого и пишем локатор стейков для того, чтобы не обращаться к операционной системе и закутываться?
Да, я переиспользую старый память, но, тем не менее, прошу я...
Мне кажется, что то, как я прошу, я делаю не самым оптимальным.
Не очень понимаю.
В задаче говорят, сделайте пул стеков.
Либо берите стек, который уже использовался, который больше не нужен, либо алоцируйте новое, если в пуле ноль стеков.
Мне кажется, можно сделать оптимальный.
А как?
Что значит оптимальный?
Это просто идея. Она может быть реализована оптимальной или неоптимальной.
А сама идея пула, она не может быть более оптимальной.
Это просто идея пула.
Не очень понимаю, что ты имеешь в виду. Что значит неоптимально?
Пул означает пулинг.
Мы переиспользуем освобожденные объекты.
Мы не создаем новое, мы переиспользуем.
Ты имеешь в виду, допустим, сразу много выделить и потом кусочки почипывать?
Ага.
Или как бы другой локатор?
Ну, можно такой сделать, никто не мешает.
Еще раз, в локаторе стеков очень простой интерфейс.
Нет.
Ну, неважно, в смысле, ты можешь переписать весь код, который там написан.
Это не проблема.
Если ты говоришь, что тебе хочется вот так сделать, ну, я бы написал вообще вот так.
Если по-хорошему делать.
Почему мне такой локей нестек статик?
Почему мне такой локей нестек статик?
Я в шаблон смотрю, я просто локатор еще не написала.
Ну, неприятно.
Сейчас, можно я вернусь к этому?
Вот, хороший локатор выглядит, конечно, так.
То есть, нам просто отдают диапазон памяти.
Нам не навязывают какую-то структуру.
Просто говорят, что вот кусочек памяти.
И там, не знаю, есть guard page.
Нет guard page, а как ты это сделаешь?
Ты можешь, я наконец понял, что ты имеешь в виду.
Ты можешь аллоцировать через мэп большую арену.
Нарезать ее на кусочки.
Но это тебя спасет только для прогрева.
Что ты, собственно, этим экономишь?
Что ты не так уж сильно экономишь?
Ну, ты вместо двух системных вызовов будешь делать 1nmprotect.
Но это все равно сисколы.
Это все равно очень дорого для старта файбера.
Поэтому тут не сильно тебя это спасет, мне кажется.
Теперь возвращаюсь к твоему вопросу, которого я не понял.
На какой файл мне нужно посмотреть здесь?
Да, вот я здесь.
Тут нет статика.
Ну, cpp.
Так.
Там должен быть.
Так.
Почему он статик?
Какой выигрыш нам это дает?
Это не то, что выигрыш дает.
Это просто аккуратно написанный код.
Функция allocate new stack зависит от состояния аллокатора?
Нет.
Вот, конец.
А почему, например, allocate не статик?
Потому что plus используется.
Plus stack.
Ну, вот и все.
Ну, то есть это могла быть вообще свободная функция.
Но она логически привязана к аллокатору,
поэтому она метод аллокатора.
Но она не использует состояние этого класса,
поэтому она статическая.
Ну, то есть для нее stack аллокатор — это некоторый склуб,
в котором она имеет смысл.
Но при этом она к состоянию не привязана, поэтому она статик.
Но это просто быстро дает понять читателю,
что это такая функция, которая не апеллирует состояние.
Если убрать статик, то ничего, конечно, не сломается,
но и код станет хуже при этом.
Вот еще вопрос.
Зачем мы используем
именно коррутин импл,
а не коррутину?
То есть, ну, это скорее даже может
к названию вопроса.
Потому что такое ощущение,
что как будто коррутин импл,
она как бы не полная коррутина,
какая-то часть.
Ну, это деталь реализации, да.
Да, ну, а почему мы
можем использовать
это коррутину импла?
Ну, за тем, что мы здесь...
А?
То есть, на какой-то разум, то есть, часть
сходится в реализацию, а не...
Не то, что часть.
Задача декопозируется на разные.
Есть переключение контекста и коррутин импл
при переключении контекста.
Есть менеджмент ресурсов. Менеджмент ресурсов — это стэки.
И вот мы одно с другим,
одно другого отвязываем.
Две разные подзадачи,
они решаются двумя разными
компонентами системы.
Вот. Кроме того,
если ты пишешь...
Если ты
пишешь файберы,
то тебе, вероятно, нужно находить текущий файбер.
Ну, тут два отличия.
Почему коррут... Две причины,
по которой этот класс существует такой,
сам по себе. Во-первых,
он не управляет памятью и не пытается
понимать, откуда берутся стэки.
А во-вторых, в нем есть менеджмент
саспенд, который нестатический.
Почему
так сделано? Ну, потому что
вот коррутине такой, разумно
иметь статический метод.
Ну, просто вот мы в коррутине, вот мы
останавливаемся.
Вот такой API, он
менее безопасный,
потому что нужно сначала коррутину найти,
в смысле объект сам, и сделать на нем
саспенд. И можно перепутать.
То есть вызвать саспенд на другой коррутине.
Со статиком
ты всегда вызываешь саспенд
на себе. Вот тогда тебе нужно себя
найти, и у тебя появляется
тридлокал в коррутине.
Но файберу тоже нужен тридлокал, чтобы себя находить.
И зачем тебе делать два тридлокала,
когда тебе один не нужен?
Да? Ну, у тебя же есть вот
в файбере тридлокал-поинтер на себя.
Вот. Тебе получается
не нужен тридлокал, который будет в коррутине.
Если он тебе не нужен, то
было бы странно, если бы он в коде был.
Вот ты по таким соображениям можешь сделать
все аккуратнее. Такие тонкие, на самом деле, вещи.
Тут
я не то чтобы навязываю, я скорее
объясняю логику, в которой
в этом коде они разделены.
То есть есть некоторые вещи, которые
не всем нужны клиентам.
То есть вот есть коррутина как базовый
механизм, и с помощью нее можно делать разные
вещи. И вот
эти разные вещи могут
менять детали
в этой
базовой коррутине некоторые.
В импл осталось только то, что самое
общее про переключение контекста
и про ошибки.
А файбером,
процессором.
А файбер и процессор могут какие-то части
использовать или не использовать.
Добавлять свое, не добавлять.
Ну, короче.
Это такой
общий знаменатель.
Наименьший общий предок
всех реализаций.
Дальше мы из него
уже какие-то детали расти.
Ну так, вот
можно по-разному отнестись.
Зачем нам два Go?
Почему мы не могли сделать один?
Какой?
Я не знаю.
Может это было как
унтер сделать?
Не понимаю. Какую проблему ты решаешь?
Вот у тебя есть два
вызова Go. Один запуск.
Они по сути
повышают ясность.
Что значит повышают ясность?
Не понимаю, что повышают ясность. Они просто
для разных задач.
Не имеют мыслы их пытаться
сделать как один?
Чем ты предлагаешь это заменить?
Получилось бы
через унтер сделать.
Ты говоришь про реализацию.
Проблема, которую
ты хочешь решить.
Какой код ты хочешь?
Неважно, как они реализованы.
Они реализованы одно через другое.
Это же совершенно неважно.
Что ты от API хочешь?
Для меня это наоборот было.
Нет, для меня проблема была.
Потому что код мне не похож.
Если ты дублируешь код, то не дублируй код.
Когда ты дублируешь код,
это не проблема API, скорее всего.
Проблема твоей реализации.
Точно.
В жизни не нужно дублировать код.
Если у тебя код дублируется, значит ты в нем не выделил
нечто общее.
Это конституция факта.
Но ты как будто говоришь про API.
Реализация API это совершенно разные вещи.
Я не знаю.
Я посмотрю и момент,
где меня смущает.
Просто внутри смущает.
Есть же у класса
два конструктора.
Не, я не сполню.
Да при чем здесь перегрузка?
cessib Merge уже всеvetna и
reviewing
the
Ну то есть как я могу запустить
файбер в « reproduceEE ».
Их мы не совмещаем.
Они выполняют одну задачу,
они параметризуются.
Они запускают новый файбер,
За Wheat Cosmeticswny
запускают файбер
более тонко настроить запуск, в каком именно планировщике. Другой использует текущий дефолт.
То есть можно было назвать по-разному, я не знаю, как бы можно было их назвать иначе.
Но мне кажется, что они нормально одинаково называются, и реализация одна через другую выражается, так что...
Кажется, проблемы нет.
Еще что-нибудь?
А может, вы спросите что-нибудь?
Я что-нибудь могу спросить?
Да.
О чем угодно?
Вы, если спросите о чем угодно в курсе, то я точно не отвечу, хотя бы по крестности наших обсуждений.
Какое-то хорошее вопросное понимание, чтобы мы упоминали, что мы не понимали.
А мне кажется, не знаю, мне кажется, что мы уже все, что мне было важно, обсудили.
Сейчас подумаю.
Ну, есть еще вот этот субмит мутный и вот вся эта интрузивность.
Я поняла, что хотел спросить.
Вот, но я все равно бы не ответил.
Точнее, такое место, которое можно будет...
Мы будем решать задача, и вот в субботу у нас будут Future Executers.
И там мы еще немного дизайн улучшим, еще там немного что-то декомпозируем.
И задачи можно будет решать, там их написать, а потом можно будет во всех задачах что-то разом исправить,
и везде все продолжит работать, просто будет намного лучше.
Вот этот субмит, и он в будущем там переименуется во что-то другое, это как раз такой задел на будущее.
Но мне хочется, чтобы когда он возник, он возник не потому, что я его навязал.
То есть делайте интрузивность.
Пока вам это не нужно, не делайте интрузивность.
Когда вы поймете, что вы делаете лишнего, когда вы поймете, что у вас какие-то лишние аллокации ненужные происходят,
то, ну, в принципе, с делом Fiber вы могли бы это уже понять, что планировщик поток, планировщик задач,
Тредпул делает немного лишнюю работу в смысле аллокации, когда вы запускаете в нем Fiber.
Вот если вы это чувствуете, то вы можете в эту сторону думать.
А если не чувствуете, то, наверное, пока не обязательно.
Сколько у нас времени осталось?
Три минуты.
Три минуты.
Три минуты.
Три минуты.
Ну, вопрос, наверное, не хватит тоже.
Можно спросить.
Да.
Ну, в описании задачки была.
Какой?
Позвольте заменить Тредпул в Карен, на локальное монополие просто.
Да.
У вас чем это связано?
Ну, суббот, наверное, увидим.
То есть после суббота я смогу объяснить.
Потому что мы хотим абстрагировать понятие планировщика.
Ну, вот сейчас у нас есть конкретно Тредпул.
Вот он прям зашит в API.
Мы приходим сюда и...
Сейчас, где мы?
Вот сюда.
И написано, планировщик – это Тредпул.
Но, с другой стороны, что мы знаем про этот Тредпул?
Мы...
Что Fiber'ом нужно от него?
А от него Fiber'ом нужен только один метод SubmitTask.
То есть задача, запланированная в Тредпул, рано или поздно где-то там будет выполнена.
Ну, вот можно здесь от знания конкретно про Тредпул избавиться
и получить некоторые приятные бонусы.
Вот заменив этот Тредпул абстракцией.
И вот тогда уже не получится просто найти текущую реализацию планировщика,
потому что...
Ну, забегая вперед, это может быть декоратор несомостоятельной Тредпулы,
и там уже никакого Тредлокала разумного не напишешь.
Так что давай я все-таки...
Ну, я смогу через неделю это объяснить, зачем это будет нужно.
Может быть на лекции, но на лекции скорее всего времени не хватит.
Да, у меня большая просьба.
На лекции, мне кажется, я могу очень много рассказать.
Прям хорошие лекции.
Вот я вчера читал и не успел все, и время переполнил.
С вами постараюсь побыстрее, чуть-чуть оптимизировать.
Мне кажется, что очень клевая лекция.
Она мне очень нравится, и она должна многие вещи связать с новым.
Ну, то есть это не то, что там какой-то баловствок модыри памяти.
Вот отдельный топик, который можно в любой момент послушать.
Вот кажется, что следующая лекция, она вот в эту картинку добавит еще такое большое измерение,
которое будет при этом сочетаться со всем текущим.
И мне хочется, чтобы вы пришли и осознали все это.
Это важно.
То есть там разные лог-фри, устройства планировщиков, там все какие-то реализации корутин, потоков.
Это вы все можете в жизни не увидеть.
То, что будет на следующей лекции фьюча, это то, что, вероятно, то, с чем вы будете работать,
скорее всего, в любом языке программирования.
Джаваскрипта и раз-то совершенно неважно, чем вы будете заниматься, и там, и там это будет.
Ну, и я там еще наверну дизайна немножко.
Так что призываю вас прийти.
И через неделю у нас будет гораздо больше поводов поговорить.
А еще я думаю, что в субботу появится новая задачка, которая сейчас у меня приватно валится.
Я ее даже сегодня уже, наверное, выложу в репозиторию ее,
где мы будем делать фьютекс и всякие приметивы синхронизации.
Там много изменений по сравнению с текущей версией.
Я имею в виду собственный фьютекс, который нам понадобится.
Мы искореняем магию.
Можно я еще минутку потрачу? Простите.
Мы искореняем в курсе магию.
Мы фьютексом пользуемся, и фьютекс потом напишем.
Ну, сейчас напишем, в смысле, чтобы не было какой-то странной...
Чтобы искоренить вот наше магическое мышление,
что фьютекс как-то там что-то проверяет, какие-то очереди ставит.
Вот напишем и увидим, что это.
Абсолютно честно получится.
В курсе, наверное, в этом году это уже не улучшить, а в следующем году точно улучшается.
Вот можно как раз и в задачу про Slip4 вставить не ASIO готовый и сложный,
а свою собственную реализацию поверх, ну, не знаю, или E-Polo, или Event Loop.
Тогда вот все, что я говорил, можно будет в коде прочесть,
потому что ASIO слишком сложно, чтобы его читать.
Хедерон или библиотека.
Ну, в общем, все остальное, что у нас есть, мы напишем своими руками.
А ASIO, ну, я вот надеюсь, что вы их и себе написали на E-Polo в своей жизни.
И вот, возможно, не стоит на это рассчитывать больше.
Ладно, давайте тогда через неделю встретимся и продолжим.
Ну что, начнем?
Итак, о чем мы сегодня поговорим, зависит, наверное, от вас,
потому что на прошлой паре я рассказывал про ASIO,
про то, как правильно думать о том, что происходит в ее контексте,
про то, как писать Event Loop, про то, как пользоваться ими.
И мне интересно, наверное, узнать, как вы пользовались сами в своей жизни Event Loop,
в смысле, как вы писали какой-нибудь код на E-Polo в ваше предшествующее семястро обучение,
и насколько вообще нужно подробно про это говорить.
Потому что кажется, что в прошлой группе студентами многие писали какие-то очень странные решения,
ну, в смысле, эхо север, скажем, на E-Polo.
Точно неразумный код.
Не писали?
Не писали.
Ну, давайте тогда начнем с чего-то простого,
а потом по пути выясним, что вы писали, что-то разумное или нет.
Я надеюсь, что что-то разумное.
Итак, у нас задача сделать FiberSleep4,
ну, в широком смысле научить Fiber взаимодействовать с внешним миром.
Время, там, сети, это все проявление какого-то внешнего мира.
И поэтому мы в качестве планировщика Fiber'ов
используем некоторый Event Loop, который в данном случае представлен в виде ее контекста в библиотеке ASIO.
И для того, чтобы разобраться, как ваши Fiber интегрируются в этот самый его контекст,
нужно разобраться вообще, наверное, что это такое.
Вот как, скажем, такой пример работает.
Ну, или как работает тот пример, который был на лекции,
где мы писали эхо-север.
Ну, точнее, не писали, мы разбирали написано эхо-север.
И, ну, это какая-то библиотека, там есть какие-то классы, как-то распределены обязанности,
но, в конце концов, под капотом работает цикл Яполы.
Ну, и давайте вспомним, как вы начинали писать, как вы писали эхо-север, с чего вы начинали там работу.
Видимо, вы конституировали сервер на эхо-севере,
вот, вам нужен серверный сокет, вы его строите, вы его привязываете к какому-то порту,
вы начинаете слушать клиентов, тут все это пропущено.
Ну вот, это первое, что вы делаете.
А дальше вы, видимо, регистируете этот серверный сокет в очереди событий операционной системы в Яполе,
и дальше, видимо, ждете, что в этом Яполе появляются события о том, что сокет готов к чтению,
то есть из него можно понимать клиента.
Вот, как это выглядит на ASIO?
Ну вот, у вас есть EO-контекст.
EO-контекст – это класс, в котором разные вещи, на самом деле, происходят,
но Япол, в конце концов, ну то есть дескриптер Япола, находится внутри.
Вот этот объект представляет собой очередь событий на таймерах, на сокетах.
Дальше, что происходит с этим кодом?
Мы здесь конструируем объект сервера.
Мы конструируем аксептора,
передаем туда EO-контекст и
передаем туда порт, на котором мы собираемся слушать.
Ну вот, внутри этого аксептора конструируется серверный сокет,
который привязывается к порту и вызывает лист.
А дальше мы в конструкторе вызываем doAccept.
Что делает doAccept?
Ну вот, в конструкторе мы вызываем код.
А дальше мы в конструкторе вызываем doAccept.
Что делает doAccept?
На аксепторе вызывает asyncAccept,
передает туда обработчик.
Что происходит вовсе?
Сама себя вызывает в конце.
Сама себя вызывает в конце, да.
Но это же не рекурсия, это event loop.
Это callback и event loop.
Ну сейчас, по очереди.
Вот, в конструкторе мы вызываем doAccept,
в doAccept мы вызываем asyncAccept.
Что происходит, когда мы это делаем?
Вот где этот код написан здесь?
Ну, давайте перейдем к началу.
То есть, раз мы перейдем к чему-нибудь,
в этот фор даже их вытягиваем.
Фор?
Так, какое-то фундаментальное непонимание происходит.
Вот этот фор — это и есть цикл работы, да.
Там мы опрашиваем
епол на предмет готовых,
на предмет событий каких-то и там обслуживаем.
Но в этом коде вот этот код.
Вот здесь мы крутимся,
на еполе достаем вот это событие
и обслуживаем их.
А что же мы делаем здесь тогда?
Наверное, мы задаем...
Что значит асинхронная операция accept?
Ты себе представляешь реализацию асинхронного accept?
Ты можешь вызвать синхронный accept,
просто вызвать сисковый accept и заблокироваться
до тех пор, пока на серверном сокете не появится клиент.
А у нас здесь асинхронный accept.
Что же он должен делать, если мы говорим...
Если мы говорим про асинхронную версию?
В общем, как-то думал...
Как-то?
...давать заявку на accept и возвращать...
Что значит заявка?
Ну, как-то...
Мы говорим про код на C или C++.
Тут все очень конкретно.
Просто что тогда асинхронная операция?
Получается, мы не понимаем, что это.
Здесь не запускается обработчик.
Здесь стартует синхронная операция.
Что делает асинхронный accept?
Он регистрирует серверный socket в Epoly
и говорит, что мы ждем на этом сокете чтений.
Вот это есть асинхронная операция accept.
Она пока ничего не делает.
Мы просто подписываемся на событие,
что socket готов к чтению.
То есть на нем появился клиент.
Вот.
Так вот же.
Еще раз, мы здесь работаем с Epoly.
Мы сейчас, кажется, не перестали понимать, что такое Epoly даже.
Epoly — очередь событий.
Мы в ней можем зарегистрировать какой-то файловый дескриптор
и дождаться, пока событие реализуется,
потом его достать,
когда оно реализуется и обработать.
Вот, видимо, зарегистрировать дескриптор
здесь асинхронную операцию,
а достать и обработать — это вызвать callback, в том числе.
Ну а listen — это просто,
то есть просто listen.
Мы переводим socket в слушающий режим.
Это же не асинхронный.
То есть она не блокирующая и так.
Тут нечего делать асинхронным.
У нас есть синхронная API,
когда мы блокируем поток.
У нас есть асинхронная API.
И мы отказываемся от синхронного API,
кстати, мы заводим много блоков,
мы пользуемся асинхронным,
теперь нужно понять, что оно из себя представляет.
Ну вот, это, видимо, старт асинхронной операции.
А это — ее обработка.
Ну то есть вот мы вызвали это токсинка accept,
мы зарегистрировали socket серверный
в Яполе в очереди событий,
и все, вызов завершился.
Нам больше ничего уже не делал.
И вот вместе с этим завершился конструктор,
и вот мы перешли дальше к этой строчке.
В этой строчке мы вызываем его context-run,
и, видимо, в цикле мы достаем
из Яполвейта готовые события и обслуживания.
Ну, пока мы сделали только простое действие,
мы зарегистрировали обработчик,
подписались на события на серверном сокете.
Так что здесь мы блокируемся до тех пор,
пока этот серверный socket не станет читаемым,
то есть на нем не появится первый клиент.
Ну, смотри, тут это можно реализовать по-разному.
Пока можно мыслить, что оно одноразовое,
но потому что callback вызовется один раз.
Вот на этом уровне оно одноразовое.
Дальше мы вызываем его context-run,
и происходит какое-то событие.
В смысле, когда-то происходит событие,
что серверный socket готов к чтению,
и тогда, ну вот, в этом примере,
какой код вызывается?
Мы вызываем теперь accept на этом серверном сокете,
потому что теперь он завершится без ожидания.
Мы в этом уверены.
Мы получаем socket клиента,
переводим его в не блокирующий режим.
Тут сразу еще и в Epole его добавляем,
но вот ASIO делает только кусочек этой работы здесь.
То есть, когда вот в этом вызове run socket готов к чтению,
ASIO из него, на нем делает accept,
получает серверный socket,
и после этого вызывает наш обработчик.
Просто по семантике в async-accept
обработчик вызовется,
когда ASIO в этот объект socket уже заполнило
содержимым клиентским сокетом,
дескриптором клиентского сокета.
А дальше что мы делаем в этом обработчике,
который мы запустили?
То есть мы, по сути, вот в это место event-loop
поместили свой код.
Это обработчик, который мы запустили,
и дальше мы в этом обработчике что сделали?
Ну, во-первых, мы стартовали обработку
соединения клиента,
а во-вторых, мы вызвали do accept еще раз.
То есть мы вызвали accept, async-accept,
то есть мы снова подписались
на событие серверный socket
доступен для чтения,
то есть для не блокирующего accept.
Вот. Ну, и это все, что мы делали в этом обработчике.
То есть для не блокирующего accept.
Вот. Ну, и это ни в коем случае не рекурсивная функция,
потому что вот тело функции do accept
это просто async-accept.
И вот на одной итерации
будет вызван этот код,
а на другой итерации будет вызван вот этот код.
И вот так вот задачки они бегут
и там пинают друг друга,
порождают новые задачи.
Ну, помимо того, что мы
сконструировали,
помимо того, что мы повторно запланировали accept на socket,
мы еще сделали вот этот session,
make shared session, start.
Этот объект session, он представляет из себя
обработчик соединения клиента.
И мы, получая socket,
вызываем на этом объекте start,
в нем вызываем do read,
а в этом do read
мы стартуем socket, async, read sum операцию.
Ну, то есть мы вот теперь мы
положили в E-Poll socket клиента
и ожидаем на нем чтения.
То есть мы в обработчике async-accept
вызвали этот start, в нем вызвали do read,
а в нем вызвали socket, async, read sum,
а в нем, по сути, произошел вот этот вот код.
Так?
И после этого do read завершился,
start завершился.
И теперь у нас, получается, в E-Poll
лежит два файловых дескриптора.
Один мы положили вот здесь вот
и ждем события на socket.
Ждем готовности к чтению socket клиентского.
И вот здесь мы второй раз
положили в E-Poll socket серверный.
И дальше мы снова переходим.
Итерация заканчивается, то есть обработчик
завершился, итерация event loop заканчивается.
И мы снова вызываем E-Poll wait
и снова ждем новых событий.
И может быть это событие будет снова
на серверном socket, а может быть это
будет событие на socket клиента.
Тогда здесь сам ASIO прочитает в буфер,
который мы передали в операцию
данные и вызовет этот обработчик.
Что сделать этот обработчик?
Он вызовет do write, то есть он
стартует новую синхронную операцию
записи, то есть зарегистрирует
ASIO socket на события готовых записи.
Ну и вот так вот эти задачки будут
по кругу запускаться, порождать друг друга.
То есть мы начинаем запуск сервера
с вызова do accept. Do accept регистрирует
E-Poll socket, серверный socket на чтение.
Потом, когда из E-Poll этот дискиптор
достается, мы вызываем accept.
И после этого accept-а, с одной стороны,
мы снова вызываем do accept и порождать
еще одна такая задача.
С другой стороны, мы порождаем, мы
стартуем обработку клиента и вызываем
socket async-лица. То есть async-accept
потом сработал accept, потом сработал socket
async-лицам и accept-а async-accept.
И теперь у нас уже в E-Poll два события.
И вот, может быть, мы вызовем E-Poll
и получим событие на серверном
socket и вызовем accept. Может, мы получим
из E-Poll события на клиентском socket
и вызовем read. И тогда появится новая задача
запустить собработчик чтения, в котором
вызовется do write, в котором будет
вызвана async-write, который положит socket.
Ну и так, короче, понятно, да, что происходит.
Вот эта вся конструкция вращается.
Сначала нужно осинхронную запись,
чем она. В принципе, можно просто записать, чтобы
прочитать. То есть вы тоже не писали нормальный
сервер. Да, может быть, тоже мы не осинхронную
запись. Ну а синхронная запись может заблокироваться.
Ну как зачем? Вот зачем ты читаешь
асинхронную? Чтобы... У тебя задача. Ты хочешь
написать эхо-сервер, который обслуживает
многих клиентов. Что ты можешь сделать? Ты можешь
написать его на потоках, использовать блокирующий
IP. Можешь? Можешь. Ну вот пишешь код, запускаешь
там потоки. Потом оказывается, что так ты там, не знаю,
100 тысяч соединений не обработаешь. Ты говоришь,
ну зачем мне делать синхронную IP? Я использую
асинхронную. То есть у меня есть в операционной
системе механизм модификации о событиях. Есть очередь
задач. Япол. Я туда буду сходовать сокета. И потом,
по мере готовности, их вот только обработчики
вызывать. Тогда вся работа упаковывается в один
поток. И вот ты начинаешь вроде бы здраво. Ты слушаешь
серверный сокет, ты регистрируешь его в Яполе,
получаешь событие, что появился клиент. Аксептишь
этого клиента, регистрируешь сокеты на чтение. И вот
у тебя случаются события. Сокет, клиент, ты готов
к чтению. Ты вызываешь ритм на нем, он не блокируется,
потому что сокет готов к чтению. Ты заполняешь данными
какой-то буфер. А дальше что ты делаешь? Ты хочешь
записать обратно сокет. И какой-то код ты пишешь.
Но у нас, видимо, не возникало таких ситуаций,
где запись может блокировать. Ну смотри, ты отрицаешь
реальность. Нет, я не отрицаю. Ну нет, не смысляю. Твое
решение, аккуратно, твое решение отрицает реальность.
Вот твое решение не имеет смысла, потому что оно
заблокируется. Вот. И если твой вызов write заблокируется,
то все твои чтения синхронные тоже заблокируются, у тебя
сервер станет однопоточным. То есть с таким же успехом
ты мог бы написать такой код. Блокируюсь на accept и
получаю сокет. И while true там читаю, пишу. Ну ничем не
лучше особо. Ну мы должны делать точно так же, как мы
поступали с чтениями. Мы должны, во-первых, понятно
и почему в сокет нельзя писать без блокировки.
Непонятно. Ну почему читать нельзя понятно, наверное,
потому что никто не прислал ничего. Ну а теперь
представь, что TCP это очень сложная штука. Я вот не
знаю, что вы будете делать осенью, но вот осенью читать
спецкурс про спрелевленным системам. И там, ну в общем,
начинается все частично с TCP. По крайней мере, на
первом семинаре я об этом рассказываю. TCP – это транспортный
протокол, который помогает, который создает абстракцию,
который дает вам абстракцию прямого провода между двумя
машинами. Вот как будто бы есть, не знаю, дата-центр,
там стоят десятки тысяч машин, между ними какая-то
сложная компутационная фабрика, какая-то бешенная
конструкция из там сетевых коробок, которые там в какие-то
плоскости перпендикулярно организованы, неважно.
Но при этом, каждая, вы одна машина соединяете с другой,
думаете, что как будто бы между вами прямой провод,
по которому просто вы байты отправляете поточно, и
на другой стороне их в таком виде получают. Но прямо
скажем, что эта абстракция довольно сильно отличается
от реальности, потому что под вами есть вот эта сложная
компутационная фабрика из коробок проводов, вы
отправляете ваши данные, не потоков, разумеется, а
TCP датограммами, сегментами, делите кусочки,
положите поток на кусочки, отправляете его кусочками,
эти кусочки могут бегать, вообще говоря, по разным
маршрутам, доставляться в разном порядке, то есть
это все в сериальности сильно сложнее. Кроме того,
смотрите, нет, вы, конечно, можете их получать и
выстраивать в правильном порядке, вы, наверное, все
это понимаете, не понимаете, как организованы. Придется
осенью рассказывать тогда. Но смотрите, какая проблема
есть. Вот у вас много таких логических пар, не то что
даже клиент-сервер, просто два собеседника. В конце
концов, ладно, неважно. И вот эти много-много пар думают,
что они соединены отдельными проводами, а на самом деле
они делят какие-то роутеры, коммутаторы между ними.
И что будет, если какая-то пара начнет отправлять,
посылать друг другу данные с каким-то бешеным рейтом?
Они используют общий ресурс, все эти соединения, все эти
пары, они используют общую сеть, но при этом какая-то
пара может сильно нагружать эту сеть, и тогда она будет
отнимать пропускную способность у других участников.
Ну или, смотри, другая ситуация. У тебя есть, ты клиент,
есть сервер, и ты клиент готов вслать с бешеным рейтом
данные серверу. А сервер не может их в таком рейте
обрабатывать, он не может успевать вычитывать и
процессить данные. Вот. Обе эти проблемы нужно решать.
Нужен какой-то механизм обратной связи. Ну, back pressure
это называется в общем случае. То есть, если ты перегружаешь
общую сеть, то ты должен рано или поздно замедлиться.
То есть, ты не можешь писать в том темпе, в котором ты
мог бы. Себя ограничивать пропускную способность сети
и другие участники, с которыми ты эту сеть делишь.
Кроме того, ты ограничен не только своей скоростью
записи, своим сетевым интерфейсом, ты ограничен
скоростью получателя данных. Если ты будешь
если ты будешь слать данные в бешеном темпе, а сервер
будет их обрабатывать медленно, то у него просто
закончится память. Вряд ли оно так просто в ядре
закончится память. Вот. Мы бы этого не хотели.
И поэтому в TCP есть два механизма. Один называется
congestion control, другой называется flow control. То есть,
первый механизм он про то, чтобы не нагружать сеть
общую для всех пар собеседников. Второй про то, чтобы не
перегружать получателя данных. Вот. Ну, про это есть,
мне кажется, хорошая, хорошая статья, короткая, такая
вводная в книжке High Performance Browser Network. Она про то,
что в целом про сеть, а скорее про HTTP, но поскольку
это транспортный протокол общий, тут есть некоторые
механики. И вот идея в том, что ты посылаешь данные,
посылаешь данные, а потом в какой-то момент ты, ну,
ты посылаешь данные, тебе, как правило, в TCP на каждый
твой сегмент, тебе посылают в ответ, ну не на каждый,
не обязательно, посылают в ответ сегмент, в котором
будет написано, что вот получатель получил твои
данные и вот там достроил поток до какой-то позиции.
Вот. И может быть, ты подтверждения не получаешь,
потому что данные отправлялась, перегружено, и просто какая-то
сетевая коробка, но у нее уже, это же коробка, там
какие-то ограниченные буферы, фиксированная память, она
в какой-то момент стала просто дропать то, что у нее
приходит. Ну, потому что не резиновая. Вот. И тебе
перестали приходить подтверждение с другой стороны от твоего
собеседника, что он данные получает. И ты вот
используя такую потерю подтверждения, как обратную
связь, начинаешь сбавлять скорость. То есть, ты
ограничиваешь рейт записи, ты ограничиваешь в, ну,
в смысле, ты операционная система, которая реализует
TCP, а TCP реализован только на концах провода. То есть,
в сети-то его нет никакого TCP. Вы это понимаете?
Вся сеть про TCP ничего не знает. Вы, операционная
система, которая реализует endpoint TCP-соединения, понимает,
что нельзя больше в таком темпе пользователь данные
принимать на запись, и просто блокирует его вызовы
write. То есть, в ядре уже есть некоторый буфер на запись,
он заполнился, и он не проталкивается в сеть. Поэтому
вызов write блокируется, ну, то есть, просто обратная
связь такая идет. Мы блокируем запись. Поэтому, если ты
вызываешь write просто после чтения из сокета, ну, может
быть, тебе повезет. А может быть, клиент у тебя попался
вредный, он просто шлет тебе данные, но не вычитывает
из сокета. И тогда твой сервер просто застрянет в
этом write. И застрянет все остальное. Поэтому, если
ты пишешь неблокирующий код, ну, в смысле, если ты
пишешь неблокирующую реализацию своего эхо-сервера,
то она неблокирующая не потому, что где-то нет блокирующих
вызовов, потому что их нигде нет. Вот если хотя бы в
одном месте они остаются, то все идет прахом. Так что
ты, когда получаешь сокет, когда ты получаешь
от E-Polo клиентский сокет, который готов к чтению,
ты, конечно, можешь из него прочесть, но ты не должен
ожидать, что ты сразу же можешь сделать запись.
Вот, получается, существует еще какой-то новый тип
эвент, когда пользователь говорит о том, что он сейчас
готов... Ну, как у тебя, смотри, вот есть здесь E-Polo...
Мы просто E-Polo пользовались. Ну, у тебя есть события E-Polo
in, E-Polo out, и ты вот регистрируешь то событие,
которого ты ожидаешь. Вот сокет готов к чтению, сокет
готов к записи. Причем готов к записи, это же не
означает, что ты прочтешь, ты сможешь записать в него
весь буфер. Может быть, ты запишешь какое-то
количество. Вот ровно поэтому, кстати, в этом коде
на ASIO чтение из сокета это метод, а запись в сокет
это функция, потому что она внутри себя итерирует
попытки. То есть там много подписок происходит,
мы подписываемся, потом пишем, если в буфере остаются
данные, мы не смогли все записать, то мы повторно
подписываемся и снова пишем. Вот такая вот история.
Но тут райты, они симметричны ридом, они тоже асинхронные,
и вот поэтому они друг друга вызывают. Вот у нас
получается вот такой цикл из задач, которые пинают
друг друга. Что бы еще нужно было прокомментировать?
Ну, наверное, такой вопрос. Ну, это опять следствие
странного неправильного кода, которое мог написать.
Ты читаешь, у тебя сокет готов к чтению, ты из него
читаешь данные в буфер, а где этот буфер находится?
Ну, вот это работает, потому что ты прочел из буфера,
сразу записал, и все, он тебе больше не нужен. Но в
реальности, конечно, не так. Ты прочел из буфера,
а записать обратно не можешь. А потом появился другой
клиент, из которого ты тоже читаешь, и вот все, у тебя
уже нужно два буфера, а не один. Ну, то есть тебе
нужно для каждого клиента свой собственный буфер.
И вот смотри, в этом коде, что мы делаем, когда заводим
соединение. Мы алоцируем на куче объект сэшн. Этот
объект на куче нужно для того, чтобы в нем разместить
буфер как раз. Вот это динамическая локация буфера.
И мы этот буфер за собой таскаем в виде сильной ссылки
на объект сэшн. То есть мы стартуем синхронную
операцию, но перед этим мы берем сильную ссылку на
себя, ну, через интрузивный указатель, и вот захватываем
ее в лямбду, которая служит обработчиком нашей синхронной
операции. И пока обработчик синхронной операции не
вызван, то есть пока чтение не завершилось, мы удерживаем
ссылку на объект сэшн, то есть на буфер.
— У нас, получается, райды будут все необматывающие,
то есть, я скажу. В любом случае, у нас много лишних буферов
— Что значит «лишних»? Буферы нужны. Мы же не знаем,
когда они понадобятся. Это непредсказуемо, поэтому
да. Ну, а у нас они и раньше были, они у нас и в потоках
были, мы тоже сыруем буферы на каждом потоке, но, правда,
мы делаем это на стейке.
Вот, я на лекции рассказывал, это был очень содержательный
момент, что мы как потом преобразуем вот эту функцию
в синхронное решение? Мы просто берем нашу функцию,
где все жило на стеке, и трансформируем ее в класс,
который мы перемещаем на кучу, и локальные перемены
становятся полями этого класса. Это очень естественное
преобразование, которое следует просто из перехода
к асинхронным интерфейсам. Вот, а теперь вопрос, вы,
возможно, не умеете на него отвечать, потому что вы
писали какой-то альтернативный кон, но все же, вот когда вы
достаете из еполу события, то вам прилетает вот такая
структура, да? В ней есть файловый дескриптор, вы
на него смотрите и там понимаете, что происходит. Ну,
точнее так, вы из этого файлового дескриптора там
читаете, например, данные. А зачем здесь поэнтер есть,
некоторый непрозрачный? Водит звездочка. Вы когда
регистрируете события, вы вместе с дескриптором кладете
этот void звездочка в епол. Когда события наступают
на этом файловом дескрипторе, вы обратно получаете
структурку с этим void звездочка. Епол его никак не
интерпретирует. Нет, ну это, смотри, это какие-то данные
идут в нагрузку с дескриптором, и епол про них ничего
не знает. Так вот зачем? Нет. Сейчас, ну. Ну да, я кажется
вру. Ну да, это, это правда. Я думал, что это возможно
да. Вот это, да, это как раз способ связать события,
ну которые, связать события там, скажем, на сокете с
некоторым объектом, который понимает, как это событие
нужно обслуживать дальше.
Так, ну, что еще про этот код?
Ну да, окей. Что, давайте так, если мы понимаем, почему
такой код, в смысле, как вот такой код матчится в епол,
то дальше, наверное, вопрос такой, ну, про задачу
с липфор вы ее читали, вы ее делали, вы игнорируетесь,
ну тогда это некоторое, некоторое препятствие для нас
сейчас. Не делать не очень полезно. Сложно обсуждать
дальше. Ну, то есть пока ты не подумал, сложно ответить
на твои вопросы. Ну что ж, тогда, наверное, в этом месте
все. Тут нужно задачу решать, и тогда можно будет что-то
обсудить. Ну, задача, мы используем не сокеты, мы используем
таймеры, но суть абсолютно такая же. Вот мы заводим
таймер, он представляется там каким-то файловым
скриптором, допустим, ну, епол уже умеет скрипторы
для таймеров, вы знаете. Вот, здесь мы подписываемся
на какое-то событие, ну, в смысле, подписываемся на
тайм-аут, и, ну, операции другие, таймеры вместо сокетов,
но смысл абсолютно такой же, то есть механика исполнена
такая же. Правда, разве что, вот, в еполе есть еще, в ее
контексте есть еще возможность не только запускать события,
которые, вот, на каких-то скрипторах возникли, но еще
и просто рямды исполнять. И вот в условии пишу, что этот
цикл run в его контексте, который все это делает, можно
запускать несколько поток, и тогда в этом смысле его
контекст в таком узком смысле будет представлять из
себя полпоток. Вот, но среди задач, которые он исполняет,
есть задача вот ваши обработчики, а есть задача служебные,
где опрашивается епол. Вот, и если задача епол запускается
и мы видим, что других задач в планировщике нет, то мы
можем заблокироваться на еполвейте. А если она есть,
то мы просто выполняем не блокирующий еполвейт, сразу
доставим то, что готово, и обслуживаем. Вот, так что это
планировщик, но он, в отличие от трэдпула, блокируется
не на какой-то общей очереди. Ну, в смысле, поток в нем
блокируется не на общей очереди, а поток блокируется
на очереди событий операционной системы. Механика другая,
но, в общем, это все в какой-то степени обобщается. Ну,
а дальше мы, поскольку это все планировщик, он может
запускать лямбды, то мы поверх него можем запустить и
файбера. А дальше нужно все это интегрировать с
таймерами. Ну, то есть через таймеры и асинхронный
асинквейт выразить операцию Slipforge для файбера, которая
блокирует его, но не блокирует поток планировщика, в котором
поток этого event loop, в котором файбер запустился. Такие
пироги. Семинар по моделям памяти будет, да, но
все впереди. Мне кажется, там одним семинарам не
отделаешься. Ну, мне нужно про текущие задачи все же
поговорить. Давайте обсудим, что у вас еще есть, если вы
эту задачу не решали. Есть ли у вас еще вопросы?
Всему свое время. Не знаю. Ну, давай пробуй задать,
я могу, может быть, отвечу. Я говорил это в кавычках
каждый раз. Давай я тебе отвечу на все, что смогу, но я не
хочу говорить про слабые модели памяти. Это вот как
раз тема семинара. Смотри, я это говорил, когда… Ну вот
здесь, что как будто бы… Ну тут не то, что я говорю, а
тут сам процессор Intel говорит, что он как будто бы reordered
инструкции. На самом деле он еще ничего не… На самом
деле он не то что… Но он исполняет их, используя какие-то
свои вристики, типа storebuffer, чтобы сократить время
простоя ядра. То есть внутри он не то чтобы что-то
переупорядочил, он выполнил инструкции по порядку, сначала
store, потом load, просто store положил в этот самый буфер,
и другие ядра про эту запись ничего не знают. Ну, то
есть это скорее вот как ты, пользователь, можешь думать
об этом исполнении, как ты можешь себе объяснить, что
вот такое исполнение, исполнение такой программы завершается
слоем нулями. Что как будто бы store, load, preorder. Ну вот
для этого и нужна операционная модель памяти, которая
объясняет, как правильно об этом думать. Операционная
модель памяти говорит тебе, как моделировать исполнение.
Ну вот так, у тебя есть ядра, у каждого ядра есть storebuffer,
и все записи проваливаются в него, и иногда там проваливаются
вниз, как-то непредсказуемо. Вот отчтения они обслуживаются
либо из памяти, либо, если есть запись соответствующая
в буфере, она берется оттуда. Ну и вот ты уже на этой
абстрактной машине запускаешь свою накопуточную программу
и получаешь все возможное исполнение. То есть здесь уже не про
reordering речь, здесь про вот этот честный ответ, это
операционная модель. Вот она. Упрощенный ответ, что как будто
reordering происходит. Вот это упрощенная модель?
Нет, я про упрощенную модель, когда мы говорим про reordering.
Вот у меня просто возникла проблема. Ну она не нужна,
ты можешь о ней не думать. Я же тебе сразу говорю на этом
слайде, что на самом деле все немного не так.
Ну смотри, как устроены процессоры, трудно сказать.
У них сложные операционные модели. Одно из утверждений,
которое здесь делается в какой-то момент, что с
операционными моделями жить сложно. Они очень
специфичны для процессора, и в них сложно моделировать
исполнение. Вот. Поэтому мы от них вообще отказываемся.
При reordering, ну я не знаю, нигде в лекции не говорилось,
что думай про reordering. Наоборот, говорилось, что не думай
про reordering. Смотри, чем лекция заканчивалась.
Вот. Не думайте про reordering. Ну потому что нет
никакого универсального понятия reordering и барьера.
Это все очень специфично для конкретного процессора,
для его устройства, его операционной модели. Это
не обобщается слишком хорошо, зато обобщается понятие
порядков. А слово reordering я употребляю, потому что
это такой общий способ обозначить всю ту механику,
которая приводит к тому, что нарушается вроде бы
привычный ход исполнения, ожидаемый для нас. Как будто
бы что-то переставилось. Это не точно, но мне кажется,
что все люди примерно это слово используют. И
само по себе в этом ничего плохого нет, пока ты не
думаешь, не доказываешь через него корректность.
Пока ты им не оперируешь, чтобы объяснить, что программы
правильные, то ты можешь на пальцах назвать, что это
reordering. Ну вот там статья на Википедии про
memo reordering, она перечисляет типа reordering, которые могут
быть. Ну то есть это некоторая механика, которая
наблюдается человеком, условно, как reordering. Ну вот
представьте себе программу, у тебя есть два потока,
четыре потока на четырех ядрах, первые два потока
пишут, один пишет в X, один, другой пишет в Y, один, а
два других читают Y, X, X, Y в разном порядке, и видят
оба потока, третий, четвертый, что они читают 1, 0, 1, 0.
Вот скажем такие исполнения, они даже reordering'ом не
объясняются. Ну ладно, объясняются, можно как будто
бы чтение переставить. Но опять, вот механика другая,
просто две записи приехали на два других ядра в разном
порядке. Но это все такая условность.
Еще раз, пока ты говоришь там неформально, что вот
что-то происходит странное, ты говоришь про reordering'и
и про барьеры. Но когда ты начинаешь говорить честно,
то ты говоришь, что вот в X86 на самом деле вот так вот,
а инструкция MFN, которая барьер, она что делает? Она
флажит буфер. Вот это уже честный ответ. Но он просто
очень специфичен для вот конкретного процессора.
Для другого там будет что-то по-другому. Так что мы
неформально про reordering'и говорим, понимаем при этом,
что это действительно все не так. И вот конкретно в каждом
процессоре свои причины. И вот ровно поэтому слайды
вначале объясняют, как именно это произошло, что это
не перестановка инструкции местами. А дальше мы вообще
от этого отказываемся, от такого типа мышления,
и заменяем себе модель операционную в голове на
декларативную, где мы оперируем какими-то гарантиями,
которые у нас точно есть. Что у нас есть некоторые
частичные порядки, и чтение в программе с этими частичными
порядками согласовано. И вот на это мы уже можем полагаться
в своих рассуждениях. Вот замысел был такой.
Ну какие еще вопросы? Миллион вопросов можно задавать.
Там сто пятьсот слайдов.
На самом деле это была самая большая проблема в видео.
Я даже не понимал, что иордэнг просто обобщает
проблемы между всеми.
Смотри, в лекции иордэнг используется почти нигде,
но по крайней мере в той части, где мы говорим про
тресвой замысел. Мы сначала демонстрируем, что
исполнение программы отличается от наших наивных
ожиданий. Что у нас есть компедиатор, который может
представить местами две строчки. У нас есть процессор,
который может две строчки даже в правильном порядке
написанные исполнить как-то альтернативно.
Но они так исполняются. Мы делаем запись, и про нее
не знают другие процессоры. Это не похоже на запись
памяти все же.
Нет, мы этого всего не видим, но еще раз. Этот слайд
про то, чтобы объяснить, как оно работает. А то,
что мы видим, тут говорится в мануале, что как будто
бы мы преордали две инструкции для наблюдателей, ну
в смысле, мы процессор. Но поинт всего этого совсем
не в том, что как именно инструкции упорядочиваются,
а в том, что мы просто не можем полагаться на модели
чередования. А дальше мы разбираемся, а как же
тогда вообще жить, как можно прогнозировать, как
можно предсказывать, как процессор будет исполнять
наш код. Вот нам нужна для этого модель памяти. И вот
можно говорить про операционные модели памяти, вот такие,
а можно говорить про декларативные вот такие. И вот мы
двумя способами объясняем, как же все происходит. И
вот тут уже слово «реордеринг» нигде не проходит.
Потому что вот есть один стиль, другой стиль, и
как бы ты пользуешься тем, который, ну там, тебе в данной
задаче больше подходит. Если ты пишешь на C++ какое-то
кроссплатформенное приложение, то ты пользуешься декларативным
моделем памяти языка. Если ты пишешь там, не знаю,
что-то прямо для конкретного процессора там на каком-нибудь
древнем C, то ты используешь операционный модель процессора.
Оно тебя предсказывает, что может пойти не так.
К сожалению, как все будет исполняться на самом деле.
— Когда у меня еще один вопрос, может, существует еще
и проживутся в доступной и другие там…
— Да. — …меморы и ордеры, и мы можем
в них воспользоваться только из атомика.
— Да. — То есть, если мы пишем обычные
переменные, возможно, что мы получим какая-либо
неиспользованная атомика, там везде используются
ассоциации на системе? — Нет, ты ничего не понял,
к сожалению. Смотри, тут 150 слайдов, и тут нет почти
неважных. Каждый из них сообщает какую-то мысль,
сложно в углу держать аппарат.
В чем вообще была идея нашей модели памяти,
которую мы строили? Вот sequential consistency, мы говорили,
что для того, чтобы все было хорошо, нам нужно
расставить много барьеров. Значнее, у нас есть
простая модель, которую мы хотим получить, sequential
consistency. То есть, как будто бы все происходит
в глобальном порядке, потоки иногда переключаются
друг на друга. То есть, у нас есть простые модели,
которые мы хотим получить, sequential consistency.
Но беда в том, что процессор так не работает, он не
sequential consistent, и нам нужно расставить барьеры.
Опять, момент неформальный, нужно помнить слайды как
формальные и неформальные, строгие и нестрогие.
Это опять нестрогий слайд, что упрощенно барьеры,
написано, что упрощенно, барьеры запрещают отдельно
идти при ордерингах. К твоей неточной модели есть
неточный инструмент, упрощенный модели с реордерингом,
есть упрощенный инструмент барьеры, который помогает
упорядочивать что-то. Дальше вопрос, где эти барьеры
ставить? У нас получается проблема. С одной стороны,
мы хотим быструю программу, с другой стороны, мы хотим
программу последовательно согласованную, поэтому нам
нужно много барьеров. Мы не можем себе позволить
ставить барьеры между каждой парой соседних инструкций.
Это важный момент, переломный момент лекции, где решения
принимаются, что же мы делаем. Мы не хотим ни оптимизациями
жертвовать, не ставить много барьеров между всеми
инструкциями, не терять простую семантику для программ
многопроточных. Поэтому мы говорим, что мы просто
отказываемся от некоторых программ и обеспечиваем
видимость последовательного исполнения только для
разумных программ без гонок. И вот почему... Ещё один
важный слайд. Они все одинаково важны. Почему это
должно нам помочь? Потому что если программа
корректно синхронизирована, то окажется, что в ней
для видимости последовательного исполнения достаточно
будет расставить только очень немного барьеров. И вот
эти барьеры будут в тех местах, где выполняется
синхронизация, то есть в атомиках. Весь наш замысел
состоит в том, что мы, отказываясь от произвольной программы,
ограничивая себя только хорошими в некотором смысле,
можем в итоге расставить барьеры памяти только там,
где выполняется синхронизация. А синхронизацию мы
обозначаем явно в виде атомиков. Вот. И дальше
оказывается, что к империатору, но в самом конце
оказывается, что к империатору нужно вот ставить
барьеры только здесь. Что вот здесь он может творить
с этими записями всё, что хочет. Буферизировать их,
там не отравить память. Пока он не встретил запись
в атомик и барьер, он может копить записи в своём
storebuffer. Но когда он встретит барьеры, он всё-таки должен
их сбросить так, чтобы здесь, код, который прочёл
эту запись, увидел и вот эти записи тоже. И вот здесь
никаких барьеров больше не нужно. Барьеры нужны
вот где-то вот в этих местах, точка синхронизации.
Поэтому их будет очень мало, и ровно поэтому memory
order существует именно в атомике. Поэтому memory order
— это аргумент атомика. Потому что вот ровно в этих
местах ставятся барьеры, и ты с помощью memory order
регулируешь, насколько они, условно говоря, должны
быть сильными. Вот. А в других функциях никаких
барьеров, конечно же, нет. Но потому что компилиратор
же компилирует эти функции просто вот как отдельные
кусочки. И, представь, что он бы там пихал барьеры,
он тогда и в однопоточной программе барьеры бы пихал,
это было бы очень странно. Нет, ему нужна наша помощь,
в смысле ему компилиатору, чтобы мы сказали явно,
при обращении к каким ячейкам происходит синхронизация.
Вот мы эти ячейки обозначаем атомиками, и компилиатор
вот именно там разбрасывает барьеры. Где-то про это
тоже был слой.
Вот это был наш замысел, вот так и оказалось. То есть
вот мы ограничились, конечно, синхронизированными
программами, потому что барьеры нужны только там.
Во всех остальных не нужны, и, например, мы получаем
видимость последовательного исполнения. Это ли не успех
для нас? То есть барьеров в программе будет мало, они
будут только в атомиках. Ну и если нам очень хочется,
то мы еще можем их оптимизировать, если мы понимаем
как, если мы умеем пользоваться формальными гарантиями.
Ну, продолжай задавать вопросы. Мне кажется, что
чем больше ты говоришь, тем больше мы проясняем
картины. Я объясню немного замысел лекции. Лекция
почти ничего не говорит про Memory Order, что, возможно,
нам... Можно было бы представить, что вам полезнее всего
знать Memory Order, расставить, в конце концов. Вам это
хочется сделать, программу оптимизировать. Но с другой
стороны, чтобы разумно пользоваться материю памяти,
нужно понимать на таком глубоком интуитивном уровне,
почему она такая, почему она такими вообще сущностями
оперирует, как в порядке вот эти Happens Before. Вот лекция
про то, как построить материю памяти, в принципе, чтобы
она казалась интуитивной, чтобы было понятно, почему
все, откуда все это берется. Пользоваться ей без вот
этой интуиции, без того, соотношение ее с реальностью
очень сложно. Это все выродится в какие-то такие наивные
рецепты. А мы хотим понимать по существу.
Если мы в той программе, где, в принципе, в том процессоре,
где мы читаем из векса Y и пишем в первый день этого,
мы заменим на оптиминге, и не будем передавать отдельную
версию. Сейчас, но вот есть программа такая.
Да, если мы не релиз, а мы так поставим, то у нас,
ну да, потому что одно из требований, которые мы выдвинули,
это глобальный сквозной порядок на всех обращениях
к атомикам. Он назывался Synchronization Order. Это была
последняя гарантия, которую мы потребовали.
Вот, мы требуем упорядочить все обращения ко всем
Тамарным переменным.
В этой программе это гарантируется. А для программы,
где атомиков нет, там ничего не гарантируется.
Там процессор выполняет storebuffering, то есть бюферизирует
записи в кошах процессора, перед кошами процессора,
перед кошами процессора, перед протоколом гириантности,
и в итоге программа разваливается.
Ну, он нужен для того, чтобы, то есть мы ставим барьеры, тем самым
говорим, что вот компилятор точно расставил эти записи
в таком порядке, в смысле, что компилятор не переставил
дверить строчки, потому что тогда было непонятно, кто
виноват. Но вот виноват точно процессор. Ну, смотри, тут
можно раскомментировать mfence, вот, и все, по идее, должно
работать, действительно.
Ну, потому что там atomic store, он, ну, напишет там либо
exchange, либо этот mfence, напишет в зависимости от того,
компилятор ты используешь. То есть мы это написали
руками, а за нас это сделает компилятор в виде там
атомарной операции. В C++, вообще говоря, есть некоторые
совсем темные места, я про них мало что знаю, на самом
деле, потому что они прям очень... ладно, не получилось.
Потому что это прям совсем тонко. Вот там прямо есть
некоторые функции барьеры. Вот, и, ну, короче, и такое
там тоже есть. Ну, вот, если хочешь, да, ты можешь
спуститься вот на самое дно этого ада, и, ну, к сожалению,
в C++ там есть свои какие-то несогласованности в этой
модели памяти, поэтому сложно сказать, что насколько
хорошо это работает. Тут смотри какая ситуация, что
с одной стороны, ну, замысел в слабых модели памяти, он
очень разумен. Это тоже было, тоже был еще один важный
слайд, еще один среди череды ста важных слайдов, что
задумка слабых memory-order в том, чтобы ты, оптимизируя
программу в них, в декларативной модели, то есть минимизируя
порядки, которые в твоей декларативной, ну, в графе
появляются, ты тем самым бы оптимизировал программу
на конкретном процессоре. То есть ты оптимизируешь
программу в теории, в декларативной модели, а потом
компилятор для нее генерирует, оказывается, оптимальный
код. Вот. Ну, вот это работает, на самом деле, не всегда,
но, по крайней мере, просто потому что есть вот физическая
реальность, есть математическая модель, и не то чтобы
математическая модель вот прям идеально вписывается
в эту вот странную произвольную, порожденную человеком
физическую, ну, реальность. Где-то не очень вписывается.
Ну, и тогда возникают какие-то вот странные, странные
штуки. Вот фенс это как раз вот такой способ, когда
модели не совсем хватает, нужно вот ее докрутить, чтобы
можно было сделать еще оптимально.
— Как получается, мы ждем, пока приданут для этой модели
памяти все процессоры?
— Ну, тут двусторонний процесс, с одной стороны,
модель памяти придумывают, чтобы она лучше описывала
процессоры и как бы лучше вписывалась в их оптимизации,
в оптимизации компилиатора. А с другой стороны, компилиаторы
и процессоры тоже должны как-то учитывать, что их пытаются
описать математически и тоже не делать совсем уж диких
вещей. Вот мир в этом направлении движется такими
итерациями. Вот две эти реальности, математическая
и аппаратная, они влияют друг на друга каким-то образом.
Но про это есть хорошая статья в референсах. Вот первая,
вторая. Правда, кажется, по его образовался посылки.
Медленно.
У нас просто сломался интернет.
Ну вот, как раз про то, почему модели памяти такие,
как они пытаются текущая железа описать.
Ну да, мы причем на лекции даже это показывали.
Сейчас нет, на армах там все.
На армах там сложные сценарии реализуются, какие-то
очень подозрительные. Все потому, что у тебя там целая
иерархия кэшей, у них еще есть какие-то общие старбаферы
и все это как-то. Ну короче, там в операционной модели
предлагается думать про то, что записи и чтения, ну то
у нас будет дерево, и записи и чтения ползут к памяти
вверх по этому дереву, до корня, ну и могут иногда
встречаться, и вот чтение тогда прочтет запись, которая
еще до памяти не доехала. И вот они все это в разных
поддеревьях работают, как-то странно перемешиваются
друг с другом, и получается какие-то маргинальные
исполнения. Ну вот еще один пример операционной модели,
которая по-другому устроена, позволяет больше таких
странных поведений, ну больше ревордерингов, так условно
нет. Нет, но модели памяти мало кто понимает, в основном
пользуются какими-то рецептами, такими наивными,
какими-то готовыми паттернами, ну либо рассуждают, ну я
объясню на следующем семинаре, ну или на каком-то
семинаре, как рассуждают несколько наивно. Вот можно
себе позволить такую модель, ну это не модель памяти,
то есть модель рассуждений, которая в принципе разумна
сама по себе, но не точна, и вот лучше бы ее запретить.
Ну короче, люди как-то пользуются этим. Ну вот ты читал
себе перереференс про memory orders, наверное, до лекции,
и вряд ли, ну скорее всего на лекции я тебе по-другому
что-то рассказывал, очень сильно по-другому, потому
что непонятно откуда все это берется иначе. Ну вот
если человек будет просто читать перереференс или
еще хуже стандарт языка, то я боюсь, что там никакого
понимания точно не сложится. Но рядовому программисту
это и не нужно, если, опять про это тоже был слайд,
последний слайд вообще в лекции, про то, что вот
просто не нужно делать ничего сложного, и тогда можно
об этом не думать. Ну а если ты используешь Atomic все-таки
со слабыми моделями, то у тебя должны быть на это
какие-то основания, ты должен хорошо понимать, как все
работает. То есть ты просто так в беду не попадешь, пока
ты сам не захочешь себе выстрелить в ногу вот таким
образом, ты, с тобой ничего плохого не случится. Так что
Atomic тебе, ну то есть как бы Default Memory Order защищает
человека, который не понимает, как это все работает, от
потенциальных проблем. Ну а если ты решаешь оптимизировать,
то ты видимо разбираешься, что происходит.
Нет, еще раз, у нас была гарантия, ну смотри, чем мы
делали всю лекцию. Мы строили такой набор требований,
которые в совокупности давал бы видимость
последовательного исполнения. И вот, мы построили такую
штуку, в которой если мы используем, если программа
корректно синхронизирована, и если в ней используются
только Atomic с Default Memory Order, на которых в итоге получается
Synchronization Order, то есть сквозной порядок всех обращений,
то для человека это все выглядит как просто
исполнение программы, где потоки просто чередуются.
Нет, зачем? Ну если ты пишешь однопоточный код,
то у тебя есть... Ну я, кстати, субботы реакции немного
поменял, я вышки читал в понедельник и сделаю немного лучше.
С чего мы начинали? Мы начинали строить модели памяти
с... вот с Modification Order потом, Happens Before потом...
Вот нужно начинать с Program Order, конечно.
Вот Program Order — это такая базовая гарантия, которая
дается тебе компилиатором даже. То есть компилиатор
может что-то переставить местами, но он гарантирует,
что даже если он что-то переставит местами, то
чтения будут согласованы с порядком обращения просто
в тексте программы. Если ты сделал запись, а потом
сделал чтение своей записи, то ты должен ее, разумеется,
увидеть. Ну давай я сейчас покажу тебе, что я имею в виду.
Это вот базовая гарантия, на которую ты полагаешься
и которая тебе дается бесплатно. То есть ее не нужно как-то
форсировать с помощью барьеров или чего-то подобного.
Но сегодня ничего не работает.
Было бы приятно это показать.
Так, и мы выберем какой-нибудь.
Ну вот, мы сначала записали в B, потом записали в A.
Да? Видно? Вот. Ну компилиатор так мог сделать, потому
что кажется он не ломает. Мы тут вообще ничего не
читаем по сути. Точнее мы читаем B перед записью B,
и конечно тут чтение перед записью выполняется.
Все это компилиатор соблюдает. Ну а теперь мы сделаем
что-нибудь такое.
И кажется, если он переставит снова, то программа наша
поломается.
Вот, теперь он пишет сначала в A, а потом он пишет в B.
Увидим. Ну он стер вызов, да, и теперь снова пишет
неправильно в порядке.
А что если мы напечатаем только A?
Сейчас, только...
А, ну нет, чтобы мы не напечатали, он все равно должен
перестать.
Да неважно.
Не знаю, я не понял, что ты имеешь в виду, в смысле зачем?
Но он не может здесь в B написать единицу, потому что
он же должен ожидать там ноль.
Вот. Так что вот этот программ order — это бесплатная
для нас гарантия, самая базовая, которую мы имеем
У нас чтение согласовано с порядком обращения в...
У нас порядок исполнения не обязательно совпадает.
Порядок исполнения в отдельном потоке не обязательно
совпадает с программом order, то есть с тем
порядком, который мы написали. Но чтение согласовано
с ним. То есть чтение читает, как минимум, последнюю
запись программ order. Не может что-то другое прочесть.
Вот. А дальше мы этот программ order обобщаем
на разные потоки через synchronize this with на
happens before. То есть у нас есть причинность в одном
потоке, она достигается бесплатно. А есть причинность
между разными потоками. И она уже достигается вот
с помощью там барьеров в атомиках для синхронизации.
При синхронизации. Вот-вот. Вот здесь вот.
И вот эта бесплатная гарантия, потому что она есть в...
она соблюдается для однопоточных программ просто.
Ты компьютируешь код, и она у тебя есть, потому что
И вот эта бесплатная гарантия, потому что она соблюдается для однопоточных программ просто.
Ты компьютируешь код, и она у тебя есть, потому что компилятор просто знает, что он уважает зависимости.
Вот у тебя есть запись в A, а потом есть чтение A. И вот между двумя инструкциями есть зависимость.
Вторая инструкция, которая читает A, зависит от предшествующей записи в A.
Ну вот порядок между ними сохранен. Или ты, не знаю, читаешь ячейку памяти, а потом читаешь регистр,
а потом сравниваешь значения в этом регистре с каким-то... Ну короче, делаешь условный переход или не делаешь.
Ну опять там... А дальше внутри делаешь запись B. И вот у тебя есть снова зависимость по контролю
между двумя этими обращениями. Ты тоже их не можешь иордрить.
Вот компилятор это все уважает. Процессор тоже тут ничего не ломает, кажется, так что...
Для однопоточных программ все бесплатно. Ну то есть однопоточные программы – это первое,
на что ориентируется процессор, и они и процессоры компилятора из коробки однопоточной программы не ломают.
Но их оптимизации становятся видны тогда, когда программа становится многопоточной.
И тогда уже мы видим вот какие-то эвристики, которые раньше работали, а теперь...
Раньше были незаметные, а теперь стали наблюдаемыми.
Давайте продолжим серию вопросов. Пока все идет хорошо.
Так а зачем по-твоему эта лекция нужна? Вот с этого момента ты видишь атомик, ты можешь там memory-order писать.
Ну это же просто инструмент, как вот ты пишешь синхронизацию в курсе, и ты знаешь про там бьюток, секундвары.
Ты им пользуешься, когда тебе нужно. Вот ты пишешь атомик, ты можешь в нем не писать memory-order,
можешь написать memory-order, если ты умеешь объяснить, как именно, почему ты именно такое выбрал.
Но мы по сути, мы пока не упражнялись в выборе, поэтому я бы тебе предостерег.
Вот я через, ну не знаю, может быть на следующей неделе, может быть через две недели объясню,
как эти гарантии, то есть чтобы применять memory-order, нужно хорошо понимать,
во-первых, гарантии, которые они дают, во-вторых, как именно ими пользоваться.
Вот мы через некоторое время поупражняемся в этом, то есть возьмем какие-то небольшие примеры,
и в них будем рассуждать, какие гарантии нам нужны, чего мы ожидаем,
и как с помощью вот memory-orders эти гарантии обеспечить.
Какие оставшиеся четыре?
Ну есть Consume и есть Aquari-Release. Consume это, Consume не нужен, но он Deprecate тоже.
Это очень, Consume это неудачная попытка улучшить модель памяти.
Она провалилась, Consume бесполезен, но, к сожалению, он сильно изуродовал математическую модель с собой.
Но про это я расскажу, когда будет повод.
И есть Aquari-Release, это всего лишь комбинация релиза Acquire для операций, которые выполняют чтение и запись.
Если у тебя операция выполнена чтением и запись, то она может быть Acquire-чтением и Release-записью.
Внимание, это не означает, что если у тебя операция и чтение и запись, то в них должны быть два memory-orders таких комбинаций.
Просто могут быть.
Но по смыслу это просто комбинация этих двух, то есть она не добавляет никаких новых гарантий.
Тут все ортогонально, если ты понимаешь это и это, то ты просто комбинируешь с разных сторон.
Ну, Acquire-чтение и Release-запись, что надо говорить.
На семинаре про слабые модели мы это разберем и увидим, когда это нужно или когда не нужно, наоборот.
Может быть еще какие-то общие вопросы есть не про слабые модели, потому что про них я сегодня ленюсь говорить.
Мне нужно много времени.
А про саму большую конструкцию, есть ли в ней что-то, что еще нужно пояснить.
Ну вот нужно как-то схитриться и разом себе все представить, все эти 150 слайдов как-то в свое сознание загрузить, чтобы все было очень естественно, чтобы все было как-то на своих местах.
Не знаю, как объяснить.
У всего, что происходит, есть какая-то разумная мотивация.
Каждый шаг, который мы здесь совершаем, он очень естественный, он очень интуитивен, потому что мы что делаем?
Просто придумываем гарантии, причем придумываем гарантии, на которые мы и так уже полагались.
Вот мы пишем такую программу, мы ожидаем, что чтение увидит предшествующие записи в одном потоке. Разумно? Ну и разумно.
Вот мы придумали гарантию программ-ордер, ну в смысле придумали программ-ордер и сказали, что чтение согласовано с программ-ордером.
Потом мы говорим, ну вот есть ячейки памяти, которые используют для синхронизации, и вот на них все записи упорядочены, тоже разумная гарантия, разумная.
Потом мы говорим, нам причинность нужна. Вот если мы здесь читаем из буфера, то мы ожидаем, что здесь записали буфер.
Снова формализуем в виде happens before и видимости через happens before.
Опять все очень естественно. Так мы пишем нашу программу, это мы ожидаем.
А дальше мы говорим, что вот есть еще одна неприятность, вот есть такие странные сценарии с атомиками, ну давайте мы для них еще потребуем некоторого сквозного порядка.
Вот и его получили, а дальше все. Мы построили теперь исполнение, которое из этих порядков состоит.
И показываем, что эти частичные порядки в сумме дают нам видимость последовательного исполнения.
Ну так вот же он, ну вот она.
Ну вот Лок Петерсон, мы пишем, что мы хотим пройти.
А я не помню, запускал ли там так, чтобы оно не работало или нет. Мне кажется я прямо этот пример запускал.
Ну сейчас не помню, честно говоря. Нет, ну если напишет Лок Петерсон вот такой наивный, то он разломается, да.
Ну а почему бы он не разломался? Ты просто вокруг этого всего напишешь какие-то ифы, ну и там код как-то обернешь, но суть от этого не поменяется, суть сценария.
Ну там было без атомиков, да.
Ну и собственно поэтому я говорил на первой лекции, что я не могу вам объяснить, зачем мы пишем атомики, потому что нужны они.
А объяснение вот, объяснение занимает вот три часа, зачем нам нужны атомики. Чтобы компедиатор знал, где ему расставлять барьеры.
Чтобы он мог дать вам видимость глобального порядка, в положении которого вы пишете этот самый Лок Петерсон, если этого не написать.
Ну то есть формально там ячейки памяти такие же в памяти, но дальше рассуждать у корректности Лока вот модель чередования будет просто нельзя.
Вот так что мы все это время жили с атомиками, просто с некоторой данностью, что без них будет УБ.
А сейчас можно объяснить, что такое УБ. УБ – это то, что вы начинаете, что в программе просвечивает модель памяти конкретного процессора.
То есть теперь вы видите все эти store-buffer, видите store-buffer, эффекты от них, что что-то условно переупорядочилось, как будто бы в этом состоит УБ.
Не то чтобы что-то страшное, но просто думать об исполнении в простой модели чередования нельзя.
Ну и вот видишь, можно спокойно жить и не знать про модели памяти, а использовать атомики с таким простым правилом.
Читаешь несинхронизированно, там читаешь, пишешь несинхронизированно, сделает атомик, и все, бед не знать.
Именно поэтому это default модели памяти, если ты ничего сложного не хочешь делать, не хочешь оптимизировать программу сильно, то у тебя будет простая семантика.
Ну какое-то количество оптимизации, все-таки мы не все упорядочим.
Нет, там просто volatile есть, которые... Atomic Sequentially Consistent и все.
Но я не знаю, можно ли там совсем на низкий уровень спускаться, но в самом языке там слабых моделей памяти нет, они появились.
Вот в C++ они и появились.
Но на всякий случай, да, наверное, это на лекции я не говорил, можно про это слайд добавить, что вот все эти вещи, они не специфичны для C++.
То есть это просто мы перечисляем наши ожидания от программ. Happens before, порядок на атомиках, порядок на отдельном атомике, программ order.
Это все просто естественное ожидание, это исполнение любой программы на любом процессоре.
Поэтому, в общем, не удивительно, что разные современные языки программирования просто переиспользуют модели памяти C++.
Потому что уже просто разработанный аппарат, а свойства программы нет, языка мало зависит.
Что? Да, в 11.
В Java это появилось, не знаю, сильно раньше, где-то в середине 2000-х, или?
Ну, там у тебя, наверное, были какие-то интринитики в комператорах, то есть вряд ли бы ты это все руками делал.
Но декларативной модели не было, и какого-то разумного способа рассуждать об исполнении тоже не было.
Ну, как вот, пока мы не привели пример, очень сложно, как именно пользоваться моделями памяти?
Как именно эти слабые memory orders расставлять?
Вот чтобы их расставлять, нужно пользоваться математической моделью.
Нужно придумать, какие гарантии данному коду нужны, и как мы их обеспечим.
Вот здесь эти порядки помогают. В такой задачи порядки помогают.
А если ты живешь просто с какими-то интринистиками или ассамблярными вставками,
то непонятно, как тебе что-то доказывать про твой алгоритм, что тебе нужно, как это обеспечить.
Ты скорее пытаешься избавиться от reordering.
То есть ты думаешь, как гарантировать, что ты хороший, а как избежать всего плохого.
Ну, это сложно, потому что непонятно, как ты уверен, что ты всего плохого избежал.
Как люди жили? Ну, люди жили очень просто.
Вообще редко, когда людям нужно писать очень производительный код для произвольного процессора.
Ну, даже если мы говорим условно про места, где люди часто пишут производительный код,
это там какие-то большие компании, где пишут распределенные системы инфраструктуры,
то чаще всего дата-центры в таких компаниях – это какое-то предсказуемые машины.
Не то, что десяток разных архитектур. Мы покупаем только Intel или только ARM,
или только две такие архитектуры. Поэтому до C++11 люди вполне писали под Intel.
Они знают, что у них парк машин – это Intel, и оптимизируют код под них.
Код не кроссплатформенный, но просто и не нужно в этом месте кроссплатформенный код иметь.
Он не планирует запускаться на произвольных устройствах, на утюгах.
Но сейчас есть инструмент, с помощью которого можно отказаться от знания про конкретный процессор
и все равно оптимизировать под него.
Вот так вот. Давайте последний вопрос, потому что 4 минуты осталось.
Или уже закончилось?
Мы и позже начали на 5 минут, поэтому не знаю.
Нет? Ну вот мы дойдем до практики, и там, наверное, они появятся.
То есть я расскажу про слабые мемориордеры подробнее, и тогда уже вопросов больше будет.
