Добрый день, давайте продолжать. Нам осталось после метода гаусса просто уже
выписать решение системы, точнее доказать, что это действительно решение. Итак,
теорема, напоминаю, у нас была такая, что если у нас есть система AX равно B,
где матрица A имеет упрощенный вид, но пока что вот такой вот. У нас там был уже второй пункт,
мы считаем, что матрица A имеет вот такой вот вид, и тогда мы говорим, что фундаментальная матрица
нашей системы, то есть матрица, у которой столбцы это базис пространства решений однородной системы,
имеет вид вот такой вот. Ну а частное решение имеет вид, конечно же, вот такой вот B, после этого 0.
Ну и давайте вот мы это докажем. В случае, когда система не совместная, мы уже с вами разобрали в
прошлый раз, а вот совместные оставили на этот. Так, ну давайте разбираться по порядку. Для начала
частное решение. Ну что будет, если я матрицу A умножу на X0? Я умножу матрицу E аж 3 на B,
а дальше 0. Что у меня произойдет, когда я буду это перемножать? У меня элементы матрицы E,
когда я буду строчку на столбец умножать, элементы матрицы E будут умножаться на элементы вот этого
столбца B, правильно? А элементы матрицы аж 3 будут умножаться на нижнюю часть нашего столбца,
то есть на нули. Поэтому нам не важно, какая аж 3, нам важно только, что здесь у меня будет E умножаться
на B, ну и естественно получится B. Вот, ну я на всякий случай напоминаю, да, вот я формальные
доказательства привожу, но на самом деле ситуация-то у нас вот какая. Вот если мы
посмотрим на расширенную матрицу системы, E, затем аж 3, а вот здесь вот написан B столбец
свободных членов, то вы можете посмотреть, что получится, если нам говорят, что когда мы свободные
значения свободных переменных фиксируем, главные выражаются однозначно. Свободные переменные здесь
все кроме вот самых первых соответствующих матрицы E. И если вы все свободные переменные положите равными
нулю, как мы с вами и сделали, то мы увидим, что вот из этой системы главные переменные выражаются
очень просто. Каждая главная переменная равна своему элементу в правой части. Вот представьте
себе, что свободные переменные все обратились в ноль в этой системе. Вот это способ, как это,
конечно же, вычислить. Но аналогично вычисляется и фундаментальная матрица. Давайте разбираться с
фундаментальной матрицей. Это, напоминаю, в ней в ее столбцах должен стоять базис ее столбцы.
Должны быть базисом под пространство U, давайте я его сразу обозначу, их решений однородной системы
AX равно 0. Вот и давайте мы будем проверять, что ее столбцы образуют этот базис. Во-первых,
давайте мы проверим, это, конечно же, очень важно, что столбцы в этом пространстве U лежат.
То есть столбцы это решения однородной системы уравнений, то есть они лежат в U. Естественно,
это нужно проверить, чтобы базис проверять. Но для этого мне нужно матрицу A умножить на вот эту
вот матрицу, правда? То есть я матрицу A умножаю на каждый столбец, у меня должен
получиться 0. А что у меня получается? Я е а штрих умножаю на минус а штрих е. Обратите,
пожалуйста, внимание на всякий случай, вот это е и вот это е могут быть разными матрицами. Почему?
Потому что размер а штрих может быть каким угодно, он может быть прямоугольный. Поэтому
здесь матрица е имеет такой же размер, сколько строчек у а штрих, здесь матрица е имеет
такое же размер, сколько столбцов у а штрих, правильно? Как и раньше, матрица е при
таком перемножение блощных матриц будет умножаться на минус а штрих, матрица а штрих будет
умножаться на E, правильно, когда мы будем строчку на столбцы умножать, и значит
получится минус E' плюс A'E, то есть нулевая матрица. Это значит, что все столбцы
являются действительно решениями нашей системы, ну и давайте я на всякий случай
объясню, откуда они взялись. Эти столбцы берутся из очень простого
соображения. Опять же таким мы хотим построить решение, соответствующее хорошим
значениям свободных переменных. Свободные переменные у нас соответствуют нижним
координатам, и мы берем просто каждый раз одну единичку, полагаем, одну из
свободных переменных равна единичке, а все остальные нуля. И вот вычисляем
решение, если вы это решение непосредственно вычислите, так оно и
получится. Итак, столбцы у нас решение нашей системы. Что нам еще нужно проверить?
Столбцы линейно-независимы. Как мне проверить, что они линейно-независимы? Взять
любую их линейную комбинацию и посмотреть, что будет, когда она будет
обращаться в ноль, правильно? Линейная комбинация столбцов матрицы Фи, это
разумеется, я должен Фи умножить на какой-то столбец. Давайте я его назову С.
Когда я матрицу Фи умножаю на какой-то столбец подходящего размера, я как раз
беру линейную комбинацию столбцов матрицы Фи, как раз вот с коэффициентами
из этого самого столца. Ну а что это будет такое? У меня каждая строчка Фи по
отдельности умножится на С, поэтому сверху у меня будет минус а штрих на
столбец С, а снизу у меня будет Е умножить на С, то есть сам столбец С,
правильно? Ну и что это означает? Это означает, что если ми на С оказалось
нулём, то и С это ноль, потому что вот у нас С-столбец стоит внизу. Значит, если мы
взяли линейную комбинацию столбцов Фи и получился ноль, то мы взяли линейную
комбинацию с нулевыми коэффициентами. Это означает, что столбцы независимы.
Наконец В, любой элемент, давайте я его через игрока
обозначу, из У, то есть любое решение нашей однородной системы выражается
через столбцы Фи.
То есть мы проверяем, что элементы нашего вот якобы базисы лежат в
пространстве, что они независимы и что их линейная оболочка это всё это
пространство, правильно? Ну давайте мы рассмотрим наш столбец У и разделим
его на две части, ну часть соответствующую главным переменным и
часть соответствующую свободным переменным.
Тогда я утверждаю, что через столбцы матрицы Фи можно выразить решение с теми
же самыми значениями свободных переменных. Давайте я возьму линейную
комбинацию столбцов Фи с такими коэффициентами, так чтобы свободные
переменные были бы теми же самыми. Какие коэффициенты нам нужно взять?
Нам что нам нужно умножить Фи, чтобы значения свободных переменных получились
вот такими вот. И игрок 2, конечно, мы же сами знаем, что нижние элементы рогно у
нас и получаются тем, на что мы умножаем, правильно? Поэтому если мы Фи умножим на
игрок 2, то мы получим минус А штрих игрок 2, а здесь будет игрок 2.
Значит, это будет решение. Почему? Потому что мы сказали, что столбцы Фи — это
решение нашей однородной системы, но их линейная комбинация тоже будет
решением, потому что решение образует подпространство. Это будет решение, и оно
имеет те же значения свободных переменных. Но по значениям свободных
переменных решение вычисляется однозначно. Значит, если у нас есть два решения, у
которых это вычисляется, у которых эти значения совпадают, то это одно и то же и есть.
И мы с вами всю нашу теорему уже доказали.
Обратите, пожалуйста, внимание, мы с вами что сделали? Мы выписали решение
произвольной неоднородной системы уравнений, если ее матрица имеет вот такой
вид пока что. В частности, мы доказали, что у любого такого пространства заданного
нашей системы есть конечный базис. Мы же изначально даже не знали, конично оно
порождено или нет. Вдруг да нет. Но сейчас мы поняли, что базис у него, конечно же, есть.
Так, ну надо сделать замечание. А что делать, если упрощенный вид выглядит иначе?
Что будет, если мы, решая нашу систему, привели матрицу систему к упрощенному виду,
и вот они, главные столбцы, идут не подряд. Если главные столбцы будут идти подряд, то они
будут как раз образовывать матрицу Е, правильно? Но там еще правда внизу должны были быть нулевые
строки, но они на систему понятное дело не влияют, правильно? Мы считаем, что этих нулевых строк нет,
от них безболезненно можно уйти. Если бы главные столбцы стояли слева, то они бы как раз образовывали
вот такую матрицу Е, но они могут стоять не подряд. И вот здесь вот у нас такая ступенчатая
матрица нарисована. Здесь еще что угодно стоит. В такой ситуации мы можем, разумеется, переставить
столбцы нашей матрицы А. Что означает переставить столбцы? Поменять местами переменные. У нас каждый
столбец соответствует своей переменной, правильно? Это коэффициенты при той переменной. Ну и вот просто
можно представить себе нашу систему линейных уравнений. Что будет, если мы х2 и х3 поменяем местами?
Это означает, что мы столбцы нашей матрицы 2 и 3 как раз поменяем местами, правильно? Значит,
мы можем поменять местами столбцы. Это то же самое, что поменять местами ровно так же.
Переменные получив уже требуемую на систему х равно b. Столбец свободных шрифтов у нас останется
неизменным. У этой системы мы сможем выписать решение. В этом решении, чтобы перейти обратно
к исходному порядку переменных, нужно будет... Вот что нужно будет сделать в этом частном решении
и вот в этой матрице, чтобы перейти обратно к порядку переменных? Переставить обратно кого?
Здесь мы переставляли столбцы, правильно? А здесь у нас переменным, каждой переменной
соответствует строчка, правильно? Х5 соответствует пятая строчка вот этой вот матрицы, ну и здесь
х5 стоит на пятом месте. Поэтому мы должны обратно поменять местами строки в решении. Затем
надо поменять местами строки. Давайте я один пример на всякий случай разберу для ясности.
Пример, давайте представим себе, что матрица А у нас получилась вот какой.
Ну а столбец В у нас должен быть из двух элементов это 7, 8.
После перестановки столбцов, давайте я вот матрицу А со звездочкой напишу.
2, 3, 4, 0, 5, 6. Эта матрица будет соответствовать переменным x1, x3, x4, извините x2, x4 и x5, правильно?
Вот и поэтому решение нашей системы будет следующим. Мы с вами знаем, как выписывается
решение, давайте вот я его выпишу. Мы с вами переставили переменные, поэтому я могу сказать,
что столбец x1, x3, x2, x4, x5 будет выражаться как столбец x0, который мы выписываем следующим
образом. В ставим сверху, а дальше дописываем нули. И плюс общее решение однородной системы,
то есть линейная комбинация столбцов фундаментальной матрицы, то есть как мы
пишем линейную комбинацию столбцов фундаментальной матрицы, умножаем ее на какой-то столбец,
правильно? И умножаем на гамму. Ну и давайте я фи сразу запишу. Матрицу мы должны умножить на гамму.
Матрица сейчас выписывается ровно так, как мы с вами сказали. Сверху мы выписываем минус вот
эту вот матрицу, то есть я пишу минус два, минус три, минус четыре, ноль, минус пять, минус шесть.
Внизу я выписываю единичную матрицу. Вот. Вот наше решение в нужном порядке, а если мы хотим его
выписать в помененном порядке, а если мы хотим выписать решение исходной системы, то мы должны
обратно переставить столбцы и, соответственно, получить 7, ноль строки, извините, обратно
переставить переменные, то есть строки. Ну и, соответственно, вот мы видим, что здесь происходит.
На места, внимание, главных переменных, которые у нас х1, х3, мы ставим элементы столбца В, 7, 8,
правильно? Одни в результате стали. На места главных переменных у нас встает та самая матрица минус
h', а на места свободных переменных здесь встает единичная матрица. Поэтому вот так вот у нас
выписывается общее решение неоднородной системы, если у нас ступенчатая матрица, упрощенный вид матрицы
получился с длинными ступеньками. Ну последнее, что я хочу отметить, это то, что столбец гамма на
самом деле, это как раз значение свободных переменных. То есть гамма ничто иное, как х2, х4, х5.
Если мы здесь это вычислим, на втором, четвертом, пятом месте на местах свободных переменных будут
стоять как раз элементы столбца гамма. Ну что ж, мы с вами это дело закончили. Кроме главного
результата этих штудий, выписывания решения произвольной системы линейных уравнений,
мы получили следствие, которое нам будет важно в дальнейшем, прям сейчас. Следствие говорит вот о чем.
О однородной системе линейных уравнений мы ее записываем АХ равно нулю, где А это матрица размера
к на n. Напоминаю, у нас здесь k это количество уравнений, n это количество переменных. Давайте
представим себе, что n больше, чем k, что количество переменных больше, чем количество уравнений.
Всегда есть не нулевое решение, то есть решение, состоящее не из всех нулей, у кого-то такого значения
хотя бы одной переменной, не нулевой столбец. Доказательство очень простое. Когда мы приведем к
упрощенному виду, в упрощенном виде у нас будет не больше, чем х ступенек, ну то есть не больше,
чем к главных переменных, ну а значит хотя бы n-k, то есть уж хотя бы одна свободная. У нас будет
свободная переменная, ей мы можем присвоить какое-то не нулевое значение, всем свободным
переменным присвоим какие-то значения, ну в частности вот хотя бы одну не нулевую, и получим не
нулевое решение, правильно? Присваивая свободным переменным не нулевое значение,
получаем не нулевое решение. Ну или по-другому сказать, просто мы можем взять нашу
фундаментальную матрицу и сказать, что в ней это столбцы не нулевые и хотя бы один. Вот мы сказали,
что в фундаментальной матрице столбцов будет хотя бы n-k, то есть хотя бы один. А почему я,
кстати, там говорю, что у нас ступенек будет хотя бы n-k, а не ровно n-k? Потому что некоторые строки
нашей системы могут обнулиться, правильно? У нас изначально было k-строчек, мы когда мы приводим
ее к ступенечному виду, некоторые строки могли обнулиться, и тогда будет еще больше решений.
Вот так. Ну что ж, с этим мы с вами выяснили все. Ну и давай теперь идем дальше. Наше линейическое
отступление к системам линейных уравнений кончилось вроде как описанием решения. И
теперь мы можем с достигнутых высот заново взглянуть на любые линейные пространства и
понять, что такое их размерность, понять, как работать с их базисами. Я напоминаю,
что понятие базиса мы ввели, но мы пока что еще не были уверены во всяком случае в том,
что все базисы в одном и том же пространстве имеют одно и то же количество элементов. Ну и вот
давайте мы с вами это сейчас быстренько выясним, доказав следующую лему. Она еще называется основной
леммой о линейной зависимости. Итак, пусть E1 и так далее, E-каты, это какие-то
векторы в линейном пространстве. Ну и давайте мы возьмем векторы V1 и так далее, Vn в линейной
оболочке этих товарищей. Часто эта лему формулирует в ситуации, когда векторы E1 и так далее,
E-каты независимые или даже базис, но в принципе можно и вот в такой ситуации это тоже сформулировать.
Итак, пусть у нас есть n векторов в их линейной оболочке, где n больше чем k. Тогда система векторов
V1 и так далее, Vn линейно зависима. Если n векторов выражаются через k и n больше чем k, то эти n
векторов линейно зависимы. Вот что нам говорит лемма. Для доказательства давайте мы посмотрим,
что нам сказали. Нам сказали, что векторы V1 и так далее, Vn выражены через векторы E1 и так далее,
E-каты. То есть мы можем написать следующую строчку. Мы можем сказать, что V1 и так далее,
Vn, это E1 и так далее, E-каты умножить на некоторую матрицу А, где А это матрица, у которой в столбцах
мы напишем просто координаты выражения Я. Выйдет их через Е, правильно? То есть первый столбец
нам говорит, что V1 выражается как линейная комбинация этих товарищей с коэффициентами
из первого столбца и так далее. Так, матрица А у нас соответственно имеет какие размеры, скажите мне?
Осталось понять в каком? k на n, конечно же, правильно? У нее n столбцов, поскольку у нас
должно быть n векторов в результате. Матрица А имеет размеры k на n. Ну и как мы с вами только что выяснили,
по предыдущему следствию, мы можем найти не нулевой столбец, а f в n. Если мы А умножаем на
какой-то столбец, столбец должен иметь n координат такой, что А на гамма равно нулю.
Решение вон той самой однородной системы уравнений мы знаем, что есть не нулевое такое решение.
Ну давайте мы вот это вот равенство сейчас А на гамма равно нулю. Обратите, пожалуйста, внимание,
что ноль это у нас столбец какой-то, правильно? Давайте мы это равенство умножим слева на строчку
e1 и так далее и eкат. Тогда значит e1 и так далее и eкат умножить на нулевой столбец и это у нас
получится естественно нулевой вектор, правильно? Взяли эти векторы с нулевыми коэффициентами. Есть
e1 и так далее и eкат умножить на А на гамму, а здесь у нас написано не что иное, как v1 и так далее
vn на гамма. Что мы с вами получили? Мы с вами получили не нулевой столбец коэффициентов,
такой, что мы взяли линейную комбинацию наших векторов с этими коэффициентами и
получили ноль. Это и означает, что наша система линейно-зависима. Мы предъявили
нетривиальную линейную комбинацию равную нулю. Это и есть нетривиальная линейная комбинация наших
векторов, вот этих вот товарищей, равная нулю. Ну здорово! Теперь мы с вами имеем право быстренько
доказать следующую теорему. Пусть v это конечно порожденное линейное пространство над полем f,
можно этого даже не говорить, тогда все его базисы, напоминаю, мы с вами уже давно знаем,
что конечно порожденное пространство обладает конечным базисом, все его базисы равномочны в них
поровну элементам. Наказательство очень простое. Ну, собственно, применяем эту лему. Пусть e1 и e2
это два базиса. Тогда мы, скажем, знаем, что базис e2 линейно выражается через e1,
правильно? Любой вектор в нашем пространстве выражается через базис e1, в частности,
векторы из базиса e2 тоже выражаются. E2 выражается через e1, и более того,
e2 линейно независим, мы с вами знаем, поскольку это базис. Из нашей леммы, ровно по нашей лемме,
следует, что в e2 элементов не больше, чем в e1. Если бы здесь элементов было больше,
то вот этих вот свойств следовало бы, что e2 линейно зависим. Ну и аналогично, разумеется,
в e1 не больше, чем в e2, то есть их поровну. И мы с вами доказали весьма важную теорему и
получили весьма важную характеристику любого линейного пространства. Определение, соответственно,
нам нужно дать. Пусть v это линейное пространство, значит, конечно порожденное,
его размерность обозначается она вот таким вот образом, ну, например, английского слова
dimension. Это количество векторов в любом базисе v. Мы с вами поняли, что в любом базисе количество
векторов одно и то же. Вот это понятие называется размерностью нашего пространства. Так, значит,
еще раз напоминаю, мы с вами в этом семестре, во всяком случае и в следующем тоже, в основном,
будем иметь дела только с конечно порожденными пространствами, а ниже конечномерные пространства,
то есть пространства, обладающие конечным базисом. В принципе, эта теорема имеет смысл и верна и для
бесконечно мерных пространств. Если вы определите базис, как линейно-независимую систему, такую,
что любой вектор выражается через него, как конечная линейная комбинация, естественно, то,
во-первых, такой базис всегда будет в линейном пространстве существовать в предположении
аксиому выбора или в предположении, ну, для Эммы Цорна там для этого нужна, как обычно. Такой базис
всегда будет существовать и, более того, теорема по-прежнему будет верна. Любые два базиса пространства
будут равномощными и эту мощность можно будет назвать размерностью пространства.
Ну, вот мы сейчас не будем влезать во все эти дела с применением аксиому выбора. Я хочу сказать,
что этот факт сохраняется в бесконечно мерном пространстве, некоторые другие сохраняться не
будут. Поэтому я сразу предупреждаю, что дальше у нас принципиально конечномерная техника будет
присутствовать. Но, тем не менее, давайте за замечанием и скажем, теорема верна и для бесконечно
мерных пространств, естественно, в предположении аксиому выбора. Вы слышали уже, что такое аксиома
выбора, да? На пальцах. Ну, еще будет на самом деле. Тем более, сейчас не хочется в это углубляться.
На первом курсе не будет, а дальше точно будет. Предположение аксиомы выбора. Вот это очень важная
аксиома, на которой очень многие конструкции, связанные с такой суровой бесконечностью,
опираются и, которая сейчас повсеместно принято использовать, считается, что, во всяком случае,
получается непротиворечивая математика. Хотя некоторые занимаются и тем, что будет, если ее
исключить. Так, значит, замечательно. Ну, теперь мы можем сформулировать следствие. Теорем у нас
сейчас будет много, потому что у нас... Ну, просто потому что сейчас пошла очень важная часть теории.
Следующая теорема. Пусть у нас v1 и v2 это пространство над одним и тем же полем f. Напоминаю,
что конечнопорожденное. У нас везде конечнопорожденное. Эта теорема будет иметь
смысл и дальше, но, тем не менее, я уже говорю, что техника в доказательстве у нас будет
использоваться существенно, конечно, мерно. Тогда эти два пространства изоморфны. Я напоминаю,
что изоморфность пространства у нас запритывается вот таким вот образом. То есть существует биекция
между ними, сохраняющая операция, тогда и только тогда, когда размерность v1 равна размерности v2.
Доказательства. Значит, если... Давайте мы сначала слева направо докажем. Если v1 изоморфно v2,
то у нас есть изоморфизм. Биекция, сохраняющая операции. Давайте мы возьмем какой-нибудь базис v1.
Если мы взяли какой-нибудь базис v1, то phi от e, ну, то есть там вот phi от... Мы берем систему образов
векторов базиса. Вот это вот phi от e, естественно, будет базисом v2. Ровно потому что phi от изоморфизм и
любое соотношение, которое можно записать с помощью наших линейных операций v1, будет
работать и v2. Это будет базис v2. Давайте мы вкратце проговорим это, чтобы вот увидеть,
как изоморфизм работает. Что нам говорят? Если эти товарищи будут линейно зависимыми,
это значит, что прообразы их, то есть векторы e1 и т.д. будут зависимы здесь с теми же самыми
коэффициентами, правильно? При изоморфизме ноль переходит в ноль, ну и только ноль переходит в ноль.
Линейная комбинация переходит в линейную комбинацию. Если линейная комбинация вот этих товарищей
равна нулю, это значит, что phi от линейной комбинации e тоже равно нулю. Ну и это значит,
что исходные векторы были зависимы, что не так. Ну и дальше, поскольку любой элемент v1 выражался
через e, применяя наши phi, получаем, что любой элемент v2 выражается через вот эти вот образы
векторов. То есть действительно это будет базис. Ну в этих двух системах поровну векторов e и phi от e.
Размерность v1 это количество векторов v2, это же количество векторов phi от e, а это размерность v2.
В эту сторону мы доказали, ну а в другую сторону доказывается с использованием уже того,
что мы с вами доказывали раньше. Нам для этого даже не была нужна инвариантность базисного числа.
Если размерность v1 и размерность v2 это n, то есть у нас есть базис из n векторов здесь и базис из n векторов здесь,
то мы с вами знаем, что v1 изоморфно пространству столбцов длины n. Этот изоморфизм, напоминаю,
сопоставлял каждому вектору его координатный столбец, правильно, в нашем вот фиксированном базисе.
Ну и а этот fn изоморфно v2. Ну коль так, то v1 изоморфно v2 нетрудно понять, что композиция двух изоморфизмов это, конечно же, тоже изоморфизм.
И наша теорема доказана. Итого у нас пространства изоморфны тогда и только тогда, когда у них одна и та же размерность.
Можно, но это будет то же самое. То есть вот здесь же у нас написан этот изоморфизм.
Из v1 каждому вектору сопоставляем его координаты столбец, каждому столбцу сопоставляем линейную комбинацию базиса здесь с этими коэффициентами.
Это и означает, что у нас получился, по сути дела, изоморфизм, переводящий произвольный базис v1 в произвольный базис v2, правильно?
Такой изоморфизм у нас всегда есть, собственно говоря, он здесь у нас и строится.
Так, давайте двигаться дальше. Да, конечно же, следующая теорема у нас вот какая.
Давайте мы увидим, что базис пространства можно охарактеризовать несколько разными способами.
Пусть размерность пространства равна n, тогда, во-первых, любая линейно независимая система
из n векторов является базицем v.
Ну и пункт b.
Любая система векторов e1 и так далее, e n, порождающая все v, такая, что v это линейная оболочка этих векторов,
говоря приземленным языком, такая, что любой вектор из v выражается через них, тоже является базисом v.
Ну давайте мы сейчас сделаем перерыв, после перерыва это быстренько докажем.
Смысл теоремы вот в чем. У нас есть три свойства системы векторов.
Что она линейно независима, что она порождает все пространство и что в ней n векторов.
Мы с вами знаем, что первые два условия дают нам базис по определению.
На самом деле, если вы проверили любые два из этих трех условий, то получили базис.
Перерыв, после перерыва мы это быстренько докажем.
Так, давайте продолжим. Быстренько наше утверждение докажем.
Ну в пункте а, что мы с вами знаем? Мы знаем, что у нас эта система уже линейно независима.
Нам осталось доказать, что она порождает все v, что любой вектор v есть линейная комбинация этих.
Значит, если это не так, то v не есть линейная оболочка наших векторов.
То есть существует вектор v, который не выражается через наши векторы.
Тогда утверждаю я, система E1 и так далее E n v линейно независима.
Это следствие того утверждения, которое я напоминал.
Если бы первые n векторов образовали независимую систему, а при добавлении нового вектора получилось бы линейно зависимая,
мы с вами знали, что именно добавленный выражается через оставшийся, правильно?
Сейчас мы знаем, что он не выражается, поэтому и получилась линейная независимая система.
Но этого не может быть, ибо размерность пространства равна n.
В пространстве размерности n нет n плюс одного линейно независимого вектора. Почему?
Потому что мы знаем, что в пространстве есть базис из n элементов.
Если v есть базис f1 и так далее fn, то и наши вектора, вот все вот эти вот товарищи, через него должны выражаться.
То все векторы через него выражаются.
Ну и можно применить основную лемму о линейной зависимости.
Давайте я просто основную лемму напишу о линейной зависимости.
И получить, что если эти векторы выражаются через эти, то они линейно зависимы.
Мы получили противоречие, и значит у нас действительно получился базис.
Пункт b.
Для этого нужно проверять, что это изоморфизм.
Пока мы не знаем, что они.
Нам нужно понять, что это изоморфизм, что образ этого отображения будет всем v, а не чем-то меньшим.
Вот ровно это мы сейчас и доказывали, что образ такого изоморфизма был бы всем v.
Пункт b. У нас наоборот уже есть порождающая система.
И чтобы проверить, что она базис, нам нужно проверить ее линейную независимость.
Нам не хватает этого.
Значит если это не так, то e1 и так далее, e n была бы линейно зависимой системой.
Ну и значит один вектор выражался бы через остальные.
Кажем, e n выражается через предыдущие вектора.
Я это напоминаю не обязательно так, но один из этих векторов точно бы выразился через остальные.
Тогда и наше пространство было бы линейной оболочкой только первых n минус одного вектора.
Здесь есть e n, а значит есть и все, что выражается через e1 и так далее, e n.
А коль скоро это так, коль скоро все векторы в нашем пространстве выражаются через n минус один вектор,
по той же самой лемме о линейной зависимости в пространстве не может быть n независимых векторов.
Раз так, то в v нет n линейно независимых векторов по основной лемме.
Но мы знаем, что они есть, мы знаем, что в нашем пространстве есть базис из n элемента.
Это противоречие доказывает уже и вторую часть.
Итого, про систему из n векторов нам достаточно проверять только одно из свойств произвольное.
Если мы, конечно, знаем размерность пространства, ну а как вычислить размерность пространства?
Естественно, предъявить какой-то хороший базис, правильно?
То есть если мы с вами хотим вычислить размерность произвольного пространства, нам достаточно предъявить в нем один базис.
Тогда все остальные базисы будут иметь ту же самую мощность.
Так, замечательно. С этим мы с вами разобрались.
Двигаемся дальше. Следующее, хоть и важное, но все же таки, наверное, утверждение.
Пусть v это линейное пространство, размерность v равна n, ну и пусть u это некоторое подпространство v.
Тогда u тоже конечно порожденное пространство, и размерность u не превосходит размерности v, то есть не превосходит n.
Более того, если размерность u равна n, то как вы думаете, когда это возможно, когда u это на самом деле v?
Обратите, пожалуйста, внимание. В принципе, мы не могли так сразу сказать.
Вот у нас есть конечно порожденное пространство, оно порождено какими-то векторами.
Мы берем его подпространство u, непонятно, почему оно конечно порождено.
Все его векторы выражаются через конечное количество векторов из v, но они не обязательно лежат в u, правда?
И поэтому не очень понятно, можно ли породить u конечным числом векторов из u.
И вот мы сейчас отвечаем на этот вопрос утвердительно.
Доказательства очень, конечно же, не сложные.
Значит, мы знаем, давайте я так начну, что любые n плюс 1 векторов из u линейно зависимы.
Они выражаются через базис v, и по нашей лиме они линейно зависимы.
Значит, у нас найдется такое наибольшее k. Пусть k это наибольший размер линейно независимой системы в u.
Ну и пусть это система e1 и так далее ek.
Раз у нас размеры таких систем ограничены, у нас не может быть n плюс 1 независимого вектора,
то значит есть наибольший размер такой системы, пусть это k.
Ну тогда для любого вектора из u система e1 и так далее ek u получилась уже линейно зависимой,
раз k это наибольший размер.
Ну а значит, по тому утверждению, которое мы уже вспоминали, u выражается через e1 и так далее ek.
Что мы с вами получили? Что e1 и так далее ek, линейно независимая система, через которую все выражается,
это значит, что e1 и так далее ek это базит в u.
Размерность u таким образом равна k. Естественно, u порождено этими векторами, поэтому оно конечно порождено.
Вопрос, да? Давайте я договорю фразу.
Размерность u равна k, u в частности конечно порождено, ну и конечно же k не превосходит n,
потому что мы сказали, что k линейно независимых векторов есть, n плюс 1 быть не может. Вопрос?
Потому что e1 и так далее ek в u, значит все их линейные комбинации тоже в u.
Итого k не превосходит n, ну и наконец, мне говорят, что я могу писать на этой доске, правда ведь, да?
Тем видно.
Наконец, нам нужно последнее утверждение доказать в нашем утверждении.
Если k равно n, то конечно e1 и так далее en это линейно независимая система из n векторов v.
А мы с вами только что доказывали, что она базис в v.
Ой, ну что это я? Давайте уж я допишу.
Значит, мы с вами знаем, что u это линейная оболочка у этих товарищей,
ну а раз они базис в v, то это v, то эта линейная оболочка это v.
Значит, у совпадается v.
В n-мерном пространстве только одно n-мерное подпространство – это оно само.
Замечательно. Ещё одна важная теорема.
Наверное, последняя теорема, собственно, о базисах пространств.
Вот мы с вами постепенно понимаем, какие штуки можно с ними делать.
Последняя важная теорема.
Пусть v – это линейное пространство, конечно, порождённое.
Размерность v равна n.
Ну и пусть у нас есть произвольная линейно независимая система v.
E1, и т.д., E kt.
Тогда её можно дополнить до базиса v.
То есть можно, вот у нас были E1, и т.д., E kt.
Мы можем придумать векторы E k плюс 1, и т.д., E n.
Так что у нас получится базис v.
Тут можно уже в силу нашей развитой теории по-разному,
можно, например, так.
Давайте будем добавлять векторы в нашу систему,
сохраняя её линейно независимой, пока это возможно.
То есть вот глядите, у нас есть векторы E1, и т.д., E kt.
Я смотрю, можно ли в эту систему добавить ещё один вектор,
так чтобы она осталась линейно независимой.
Если можно, я его добавил.
Нет, сейчас скажу почему.
И т.д., пока это возможно.
Вот пусть я добавил вектор E m.
Обратите внимание, я должен закончить когда-нибудь,
потому что размерность нашего пространства n,
и значит в нём нет n плюс 1 линейно независимого вектора.
Потому что размерность нашего пространства n,
и значит в нём нет n плюс 1 линейно независимого вектора.
То есть до n плюс 1 вектора я добраться уже не мог.
Здесь m не больше, чем n,
ибо в любые n плюс 1 векторы линейно зависим.
Значит, я должен был остановиться на каком-то шаге.
Но давайте мы сразу скажем, что если m меньше, чем n,
то мы с вами знаем, что v это нелинейная оболочка вот этих вот построенных векторов.
Если бы v был линейной оболочкой, то v было бы m-мерным, правильно?
А это не так.
Если m меньше, чем n, то v это ещё не всё.
То есть линейная оболочка это ещё не всё v, наоборот.
То есть существует вектор v, который не лежит в этой линейной оболочке,
и его можно было бы к ним добавить.
Так, чтобы система получилась линейной независимой.
Значит, если m меньше n, то мы на самом деле не закончили,
а когда закончили, то этого быть не может.
Итак, m получилось равно n, а наша система получилась базисом
к силу того утверждения, которое мы с вами доказали.
Здесь у нас система из n-векторов, и эта система линейно-независима.
Значит, базис.
Обратите, пожалуйста, внимание.
Это уже утверждение, в частности, нам говорит, что базисов в пространстве очень много.
Я могу любой вектор взять и, начиная с него, достроить его до базиса.
То есть любую заранее мне данную линейно-независимую систему я умею достроить до базиса.
Причем даже на самом деле видно как, и видно, что этих способов очень много.
Потому что, глядите, вот если я дошел до какого-то ем,
какой вектор я могу добавить следующим шагом?
Любой, который через них не выражается, правильно?
Получится линейная независимая система, вот по нашему утверждению и Дахнему.
И значит, я могу это продолжить, правильно?
Поэтому вот видно, насколько много выборов базисов у нас может быть в любом пространстве.
Так, ну и, да.
Да.
Нет, нет, мы выбираем просто, мы пользуемся тем, что у нас есть два множества,
одно вложено в другое, да, и они не равны.
Значит, есть элементы с дополнением.
Аксиома выбора у нас все-таки требует, чтобы мы умели выбирать представителей
из большого количества множества, правильно, не из одного.
Здесь мы аксиома выбора, конечно же, не требуем, не пользуемся.
Если множество не пусто, из него можно взять элемент.
Это не аксиома выбора, правильно?
Это, в общем, нечто более тривиальное.
Так, ну, здесь я должен, конечно же, напомнить,
коль скоро мы с вами разобрались с инвариантностью базисного числа,
здесь я должен напомнить, что коль скоро у нас есть разные базисы,
у нас бывает матрица перехода от одного базиса к другому,
и опять же таки этот кусочек теории мы можем повторить дословно,
поэтому давайте я его просто сейчас проговорю.
Если E1, E2 это два базиса В, то существует матрица перехода от базиса E1 к E2,
имеющая размер N на N, где N это как раз размерность пространства, правильно?
Такая, что E2 это E1 на S.
Ну, матрица единственна, потому что координаты векторов единственны,
напоминаю, что в столбцах матрицы S стоят в точности координаты векторов из второго базиса в базисе первом.
Ну и если теперь произвольный вектор из нашего В имеет координатный столбец альфа в базисе E,
и имеет координатный столбец альфа штрих в базисе E,
давайте альфа один в базисе E1, альфа два в базисе E2, раз уж у нас E2 и E1.
По сути, я вторую половинку стрелочки не нарисовал.
То, разумеется, у нас происходит выражение этих координат,
напоминаю, что выражение происходит в обратную сторону.
Если E2 это E1 на S, то альфа один это S на альфа два.
Еще раз, доказательства у нас проходят дословно.
Все, что нам нужно для этого доказательства, это, конечно же,
единственность координатного столбца для вектора в базисе.
Она у нас уже давным-давно есть.
Так что все эти формулы перехода между базисами мы с вами тоже уже знаем.
В дополнение давайте мы с вами прежде, чем перейдем к следующему разделу,
давим еще несколько определений, связанных скорее с векторами,
а затем уже перейдем к матрицам.
Следующее определение, пусть S, пусть V это линейное пространство,
а S это какое-то подмножество V.
Конечное, бесконечное, неважно.
Тогда рангом системы S называется наибольший размер линейной независимой
вход системы в S.
Ну то есть наибольшая такая K, что мы в S можем выбрать систему из K линейно-независимых векторов.
Естественно, в конечномерном пространстве такой ранг будет существовать,
потому что мы с вами уже неоднократно говорили, больше чем N линейно-независимых векторов
мы отсюда выбрать не сможем.
Значит ранг S будет не превосходить N.
Ну и более того, давайте мы сразу накажем следующее несложное утверждение.
Так, ранг S будет обозначаться вот таким вот образом.
И нехитрое утверждение нам сразу говорит, что ранг S это не что иное, как размерность линейной оболочки S.
Если мы взяли произвольную систему векторов, мы можем взять ее линейную оболочку, получить подпространство.
Подпространство есть размерность и вот это то же самое, что ранг S.
Доказательства.
Ну давайте мы скажем, что пусть ранг S равен K и в S есть линейно-независимая система S1 и так далее СК.
Тогда я утверждаю, что S1 и так далее СК это базис линейной оболочки.
Это базис в линейной оболочке S.
Если мы это докажем, то мы как раз докажем, что ее размерность линейной оболочки равна K.
Почему это так?
Если у нас есть какой-то вектор, что я должен доказать?
Мы уже знаем, что эта система линейно-независима.
Разумеется, она лежит в этой линейной оболочке и значит нам нужно доказать, что она порождающая.
Если V лежит в линейной оболочке S, то V выражается через векторы из S.
Является линейная комбинация векторов из S.
Ну а более того, для любого вектора из S система S1 и так далее SKT, который добавлен в S, будет линейно-независимой.
Ну а значит S выражается через векторы этой системы.
S лежит в линейной оболочке S1 и так далее SKT.
Итого, что мы получили?
Любой вектор из линейной оболочки выражается через векторы из S, а каждый вектор из S выражается через векторы S1 и так далее SKT.
Значит, и V выражается через эти векторы.
И наше утверждение доказано.
Так, ну что ж, про линейное пространство, про размерность базис и связанные с ним понятия мы с вами поговорили достаточно.
Давайте переходить дальше.
Следующая наша большая тема, сейчас мы ее начнем, сколько успеем, столько и скажем.
Тема называется ранг матрицы.
Мы скачем как бы от векторов к матрицам и обратно и видим, как вот эти вот общие теории отражаются на матрицах, матрицы влияют на общую теорию.
Итак, определение, пусть A это матрица размера, скажем, N на K над полем F.
Тогда мы можем определить ее строчный ранг, давайте я так его буду обозначать, ранг с индексом R от A, от слова row, естественно.
Это ранг системы ее строк.
Каждая строка нашей матрицы, это какая-то строка длины K, правильно, элемент коммерного пространства всех строк длины K.
Мы берем эти строки и применяем к ним наше определение, то есть смотрим, какое наибольшее количество строк можно выбрать, так чтобы они образовали линейную независимую систему.
Это и есть строчный ранг нашей матрицы.
Это ее столбцовый ранг, ранг C от A, аналогично ранг системы столбцов.
Очень скоро мы с вами прекратим писать эти индексы, потому что наша первая цель заключается в том, чтобы доказать, что для любой матрицы эти два ранга совпадают.
Ну и это в принципе какое-то, на первый взгляд, весьма нетривиальное утверждение, потому что мы смотрим на строки, смотрим на столце, это какие-то совершенно разные объекты в разных пространствах, правильно?
Для этого нам будет нужна небольшая лемма, которая сейчас будет уже очень простой.
Значит, я утверждаю, что если A и B матрицы подходящего размера, сейчас мы увидим, что значит подходящего размера, то столбцовый ранг матрицы AB не превосходит столбцового ранга A,
ну а строчный ранг матрицы AB не превосходит строчного ранга матрицы B.
И с точки зрения той теории, которую мы с вами развили, это на самом деле утверждение уже должно быть очень простым.
Давайте я докажу, например, первое утверждение, мы с вами увидим, что второе утверждение аналогично. Доказательство для столбцового ранга.
Ну давайте я возьму систему строк матрицы A, давайте я ее обозначу через S, и давайте я обозначу через U линейную оболочку S пространство, которое им поражено.
Столбцов, конечно же, извините меня. Раз мы говорим про столбцовый ранг, то мы смотрим на пространство столбцов, на линейную оболочку всех этих столбцов.
И пусть у нас столбцовый ранг A, это размерность U, и она равна, скажем, K.
Давайте мы вспомним, что мы знаем про столбцы матрицы AB.
Именно так. Столбцы матрицы AB, мы с вами говорили об этом в самом начале, это линейная комбинация столбцов A.
Так как столбцы AB, это линейная комбинация столбцов A, они все лежат в U. Все столбцы матрицы AB лежат в этом подпространстве, а размерность этого пространства равна K.
Значит, из столбцов матрицы AB мы не можем выбрать больше, чем K столбцов, образующих линейную независимую систему. Они все сидят в коммерном пространстве.
Следовательно, ранг столбцовый AB не превосходит этого самого K. Из элементов коммерного пространства мы не можем выбрать больше, чем K образующих линейную независимую систему.
Это все еще та самая основная лемма о линейной зависимости.
Утверждение наше доказано. Для строчного ранга все происходит точно так же, только, разумеется, мы должны использовать то, что строчки матрицы AB это линейные комбинации строчек матрицы B.
Ну а теперь мы готовы с вами доказать теорему о ранге матрицы.
Так она и называется. И звучит она очень просто.
Строчный ранг матрицы A равен столбцовому рангу матрицы A.
Ну и далее он просто называется рангом матрицы A и обозначается RKA.
Ну далее это после того, как мы нашу теорему докажем.
Доказательства в некотором роде хитрые, а в некотором роде и простое.
Значит, пусть K это строчный ранг, например, матрицы A.
Давайте мы выберем в А К строк, образующих линейную независимую систему.
Все остальные строки через них будут выражаться, правильно? Мы с вами это уже понимаем.
Тогда в А есть К линейно-независимых строк, и значит все строки А через них выражаются.
Ну потому что это базис, собственно, в линейной оболочке строк матрицы А.
Давайте мы возьмем эти самые K строк и составим из них матрицу B.
То есть строки матрицы B это как раз вот эти вот K строк, строки которой это наши K строк.
То это означает, каждая строчка матрицы A, давайте я скажу ИТ-я строчка матрицы А,
это линейная комбинация строк матрицы B. Как взять линейную комбинацию строк матрицы B?
Домножить? Нет, не справа. Если бы мы взяли с линейной комбинации столбцов, то мы бы домножали справа на столбец, правильно мы это уже делали?
Сейчас мы, естественно, слева домножаем на строчку. То есть я беру строчку С1 и т.д. и СКТ, умножаю на матрицу B,
это как раз линейная комбинация этих строк с коэффициентными С1 и т.д. и СКТ, правильно?
Каждая строка матрицы A имеет вот такое вот выражение.
Ну а это значит, то всю матрицу A я могу выразить как произведение матриц С на B,
где С это матрица, ну вот, ровно с такими строчками, которые мы только что написали, правильно?
Мы строчки вот эти вот из коэффициентов выражения строк A через B запишем друг под другом и получим матрицу A.
Ну тогда, значит, мы с вами знали что-то про строчный ранг матрицы A, давайте мы поймем, что мы что-то знаем про столбцовый ранг матрицы A.
Что нам говорят про столбцовый ранг матрицы A?
Это столбцовый ранг матрицы C, B, и он, по нашему утверждению, не превосходит столбцового ранга матрицы C.
Ну давайте мы посмотрим внимательно на матрицу C. В ней всего-то-навсего ка столбцов.
В матрице B ка строк, правильно, вот в этом от совмножителе, в матрице C ка столбцов.
В каждой ее строчке ка элементов, вот произвольная ее строчка такой вид имеет.
Значит, раз в C ка столбцов ее столбцовый ранг не может быть больше, чем ка уж никак, правда?
Что мы с вами доказали? Мы доказали, что столбцовый ранг матрицы A не может превосходить строчного ранга матрицы A.
Ну, разумеется, аналогично.
Строчный ранг не превосходит столбцового.
Нужно проделать ту же самую операцию, просто выразить все столбцы матрицы A через какие-то вот столько ее столбцов.
И таким образом наша теорема уже доказана.
И мы знаем, что у нас есть такое понятие, как просто ранг матрицы.
Ну, давайте мы сейчас немножко ранг матрицы поисследуем.
Сформулируем несколько уже гораздо менее нетривиальных подтверждений.
Перед этим давайте я сформулирую небольшое упражнение для всех желающих разобраться.
Итак, внимание, пусть строки матрицы A линейно-независимы.
Тогда я утверждаю, что вот в этом неравенстве всегда достигается равенство.
Ранг AB равен рангу B.
Ну, для любой матрицы B, которая естественно подходит под...
Ну, которую можно умножить на А, правильно?
Так, ну и еще одно утверждение.
Да, наверное, на нем мы сегодня и остановимся.
В следующий раз уже пойдем дальше и докажем большую теорему какую-то.
Еще следующее утверждение.
Значит, пусть В это линейное пространство.
Утверждение тривиально, но стоит его сформулировать.
E1 и так далее, En это базис В.
V1 и так далее, Vkt это векторы В.
Ну, а Vt имеют в базисе E координатный столбец αi.
Тогда нас может интересовать ранг системы наших векторов V1 и так далее Vkt.
И утверждение состоит в том, что ранг этой системы это, конечно же, ранг матрицы,
столбцами которой являются α1, α2 и так далее αkt.
Ну, доказательства тривиальны просто потому, что когда мы, если мы смотрим на некоторую систему векторов,
непосредственно перед рангом матрицы,
ранг система это максимальный набор линейно-независимых элементов ее.
Максимальная мощность системы из ее элементов.
Ну, на самом деле V1 и так далее Vt будут линейно-независимыми.
Вот такая система из векторов будет линейно-независимой.
Тогда и только тогда, когда соответствующие координатные столбцы будут линейно-независимыми.
Из-за изоморфизма. Ну, а значит ранг V1 и так далее Vkt.
Это будет ранг системы столбцов α1 и так далее αkt.
Ну, а это то же самое по определению, что ранг соответствующей матрицы.
Давайте вот я назову эту матрицу А, чтобы еще раз не писать.
Это будет ранг А.
То есть, если нам векторы заданы в координатах,
для вычисления ранга системы нам достаточно посмотреть на ранг соответствующей матрицы.
Ну, в следующий раз еще поговорим о том, как его быстренько вычислить, а на сегодня, наверное, все.
