И сегодня у нас очень важный этап, потому что мы поговорим про то, как конкарнсия,
ну вот, про то, как самые в современном мире инженеры,
ну, которые, по крайней мере, занимаются разработкой на C++,
видят себе идеальное выражение конкурентных активностей,
как наиболее естественным образом, наиболее абстрактно представить их в коде.
Ну вот, мы к этому подойдем, а начну я довольно издалека.
В прошлый раз мы с вами говорили про стеклус карутины.
Про стеклус карутины – это другая реализация карутины, другая реализация конкурента.
Про стеклус карутины – это другая реализация карутины, другая реализация функций,
которые могут останавливаться во время своего вызова,
которые, останавливаясь, сохраняют только текущий стекловый фрейм
и никак не влияют на вызовы выше по стеку.
И мы в прошлый раз говорили как с помощью таких карутины,
с помощью некоторых точек кастомизации, которые назывались овейтеры.
Давайте я вам напомню это.
Получить асинхронность.
Как программировать задачи, которые могут останавливаться
и дожидаться каких-то событий.
Готовность фьюча, завершение водовывода, разблокировки мьютекса, чего-то подобного.
И сегодня у вас в репоститории открылась задача,
в которой вы можете с помощью стеклус карутины написать конкуренты.
Никакие новые примитивы мы там делать не будем.
Мы скорее должны посмотреть на, изучить в этой задаче дизайн карутин,
который представлен в C++.
И решая эту задачу, вы должны...
Тут есть зависимость у нее Fibers Mutex.
Видимо, предполагается, что вы должны сначала ее решить.
Но я бы сказал, что вы можете решать эти задачи параллельно.
Они друг друга дополняют, потому что, с одной стороны,
мы в Fibers Mutex придумываем дизайн,
потом встречаем его в стеклус-карутинах,
и он нам кажется уже знакомым, и мы понимаем, почему он такой.
А с другой стороны, если вы идете другим путем,
то, может быть, вы не понимали, как можно изящно решить Fibers Mutex,
как там построить правильно все эти абстракции границы,
и, посмотрев на то, как это сделано в стеклус-карутинах,
вы сможете портировать эту идею обратно в Fibers.
Ну и в итоге у вас в обоих случаях получится какой-то похожий код,
потому что, в конце концов, различие только в том,
как устроена карутина.
Она устроена в стеклус или она устроена в стеклус,
то есть через переключение контекста.
Но смотрите, почему эта задача еще важна.
Но даже не только эта задача, а еще парная задача,
которая появится вот-вот и вместе с фьючами.
Потому что стеклус-карутины, как здесь они описаны,
это не только способ, не только альтернатива Fiber'ам.
Это, скорее, более общий альтернатив, ну, смотрю, более общий инструмент.
И в этой задаче они называются, этот инструмент назван просто задачами.
То есть в этом задании мы пишем такую подбиблиотеку,
которая называется Tasks.
То есть некоторые обобщенные, универсальные кооперативные задачи,
которые, во-первых, могут вести себя, в общем, как Fiber'а,
то есть они запускаются и императивно через какие-то примитивы синхронизации
начинают, собственно, синхронизироваться.
Ну, там захватывают общие Mutex'ы,
и там синхронизируются с помощью WhiteGroup.
Это код, который похож на код, который мы писали для Fiber'ов,
только здесь у нас постоянно кое вейт, потому что нужно указать компиратору,
в каких точках нужно карутину остановить и подписаться на какое-то событие,
указать, когда ее возобновить нужно.
На другой стороны, мы в прошлый раз говорили,
что карутины выгодно запускать лениво.
То есть когда мы запускаем карутину, давайте я покажу вам пример,
который был в прошлый раз,
тут немного уточнились именами спейсов, стало только лучше.
Вот, когда мы запускаем карутину,
то есть делаем такой вызов,
то на самом деле никакого запуска не происходит,
потому что карутина возвращает объект Task,
и это такое представление созданной, но еще не запущенной асинхронной работы.
И вот эту работу можно запустить, ну, разными способами можно запустить.
Можно, например, самому стать карутиной,
и вот с помощью кое вейт запустить под задачу,
а самому остановиться до того, как задача будет завершена.
Вот, то есть у карутин, у вот этих асинхронных задач обобщенных,
которые мы называем задачами просто сейчас,
есть представление в виде объекта Task.
И с одной стороны, вот эти карутины асинхронные можно использовать
и смотреть на них как-то на альтернативу файбером оперативным,
а с другой стороны, можно эти объекты Task,
которые представляют собой остановленные еще не запущенные карутины,
остановленные задачи комбинировать и трансформировать в функциональном стиле.
И про это будет другая задача, и это все отсылает к фьючам.
И вот наш код в этой задаче будет помещен в namespace-tasks
именно потому, что карутины здесь – это такой инструмент для унификации.
Они связывают, в общем, и то, что мы делали в файберах,
и параллельную композицию во фьючах, и последовательную композицию в файберах
через некоторые общие инструменты.
Вот именно поэтому просто задача.
Это, на самом деле, не те задачи, которые, конечно, в экзекьюторах.
Но это такие универсальные задачи для исполнения в экзекьюторах.
Но это бы сложно прочувствовать, просто так услышав меня,
нужно только самому написать код и вот это увидеть своими глазами,
своими руками это вбить, тогда это станет понятно.
Но карутины, они претендуют на некоторую универсальность.
Вы можете через Task с ними работать в функциональном стиле,
собирая из них какие-то графы, либо же вы можете работать с ними в императивном стиле
с помощью примитива синхронизации.
Поэтому задача шутливой называется горрутины, потому что
такие вот императивные карутины с примитивом и синхронизацией.
Чем-то похоже на грутины из ГО.
Вот, эти карутины претендуют в итоге на универсальность.
Но на самом деле можно, если закопаться глубже в их реализацию,
то можно увидеть, что карутины это может быть не самый фундаментальный механизм,
не самая фундаментальная сущность, которая нам в курсе нужна
и через которую вообще можно говорить о вычислениях.
Мы сегодня хотим на лекции поговорить про то, как описывать произвольные вычисления.
В данной задаче, в данном дизайне предлагается строить эти вычисления,
описывать эти вычисления с помощью карутины.
Вот сегодня мы пытаемся подняться на еще один уровень абстракции
и вот еще какие-то механизмы под карутиными обнаружить.
Давайте я как-то попробую объяснить, откуда все это берется,
откуда вообще появляются такие мысли.
Ну вот, вспомним про пример из прошлой лекции.
Вот у нас какая-то асинхронная работа.
У нас есть функция, в ней мы запускаем в пуле потоков какое-то вычисление,
получаем future, потом дожидаемся, потом...
Ну, конечно, код довольно бесполезный, потому что он дважды одно и то же делает,
он мог бы сам это карутина сама могла бы переехать в пул потоков
и вычислить там какое-то значение.
Ну, не суться сейчас, а может быть, я даже пример получше найду, давайте я.
Раз уж у нас должен быть, я его сразу и покажу.
Ну вот, у нас есть какая-то карутина, которая телепортируется в пул потоков
и там что-то вычисляет.
Ну вот, асинхронное вычисление.
И это вычисление возвращает объект future.
А мы говорим, что можно же оптимальнее сделать, можно же возвращать не future,
можно же возвращать из асинхронного вычисления task.
Почему?
Потому что task, вот этот объект, который карутина возвращает,
он управляет запуском этой карутины.
И вот если мы, имея future, запуская, скажем, вычисления в пуле потоков
через асинхрея здесь, через future, сразу получаем и future,
и одновременно стартуем асинхронную операцию,
то в случае карутин с task-ами, когда мы стартуем карутину,
мы получаем объект task, который тоже представляет собой, в общем,
будущее какой-то результат, будущее вычисление.
Но это вычисление, оно еще не стартовало.
И мы можем сначала подписаться на него, потом стартовать
и обойтись без синхронизации, обойтись без локации shared state,
без подсчета ссылок.
То есть мы можем скрыть, избавиться от накладных расходов,
которые нам, в принципе, не нужны.
Если мы так структурировали код, что одна задача дожидается синхронно,
другую, пусть даже асинхронную задачу, то, в принципе,
overhead на future нам не требуется здесь.
Что мы сделали по сравнению с асинхрея?
Вот здесь мы одновременно планируем задачу в пул потоков
и встроим future и возвращаем ее.
И в итоге у вас уже есть задача, которая запланировалась в пул,
у нее есть promise, у пользователей есть future, ну и все.
Теперь есть гонка уже врожденная между ними.
Непонятно, как соотносятся lifetime продюсера и консьюмера.
Между продюсером и консьюмером нужна синхронизация.
Им нужно поддерживать shared state, держать на него сильные ссылки,
подчитывать, держать счетчик ссылок и атомарно инкрементировать,
декрементировать его.
Вот мы уже получили некоторые накладные расходы.
Потому что мы сделали два шага разом.
Мы и задачу запланировали, и future построили и вернули пользователю.
Вот что мы сделали в крутинах, что мы делаем в крутинах?
Мы разделяем два этих шага.
Когда мы получаем таск, то мы еще не стартовали под задачу.
Крутина уже построилась, а под задачу не стартовала.
И когда мы разворачиваем этот таск с помощью co-await,
мы вот запускаем под задачу, но перед этим мы подписываемся на ее завершение.
Вот два шага разделены.
Простые два шага, но они разделены все же на две разных операции.
Старт к крутину, вызов к крутины и старт к крутины.
Это теперь разные шаги.
И за счет этого мы сэкономим себе лишние аллокации, почет ссылок.
Кроме того, мы наблюдали другой пример.
Мы говорили о том, как можно написать эффективный тредпул для крутин.
Потому что пример, который был у нас на прошлом занятии,
ну вот такой avator.
Мы останавливались и планировали в тредпул лямбду,
которая резюмила к крутинам.
Это был неэффективный способ, потому что, ну вот, это лямбда, это некоторая...
Чтобы положить лямбду в структуру планировщика, нужно стереть ее тип,
нужно переместить ее на кучу, сделать динамическую локацию,
короче, какой-то стд-фанкшн использовать или аналогичный контейнер.
Вот мы тратим опять локации на такую задачу, хотя к крутинам это все не требуется.
Почему? Потому что можно сделать гораздо изящнее.
Можно вспомнить, что когда мы выполняем вот такой код,
то компиатор разворачивает его во что?
Он строит по этому выражению объект avator, собственно, вот этот вот,
и на нем вызывает avate suspend.
Но этот avator, как и любая локальная переменная в крутине,
компиатором переписывается в поля.
Ну вот мы знаем, что так работают крутины.
Локальная переменная становится полями.
Ну вот avator тоже становится полем.
Avator для тратпула.
И если мы скажем, что avator для тратпула будет узлом интрузивного списка
и положим в него pointer на какой-то следующий узел,
то мы можем через avatars, которые заинлайнятся в поля крутин,
связать эти крутины в список, ну и список в тратпуле получится интрузивным.
И мы можем добавлять крутины в планировщик, не выполняя аллокации.
Ну просто потому что каждая крутина – это уже сама по себе аллокация.
Ну и если сделать это совсем аккуратно, то пусть avator будет реализовывать интерфейс,
ну будет наследником нашей таски интрузивной,
и тогда крутины органично впишутся в наш фреймворк общих планировщиков, экзекутеров.
То есть смотрите, мы снова можем получить некоторый выигрыш
за счет того, что мы снова разделяем две задачи.
Вот нужно понять, где выигрыш берется.
Мы разделяем планирование задачи в пул потоков,
и мы разделяем аллокацию стейта для нее.
Ну то есть стейт – это вот некоторая хранилища,
где написано, там, аргументы, запускаемые задачи,
там, функции, которые мы хотим запустить.
Вот в наивном тредпуле у нас есть просто submit от function.
И тут и задача упаковывается, конкретная лямбда,
или что угодно упаковывается в std function, это уже аллокация.
И потом она планируется.
Вот снова мы вот с помощью интрузивности, с помощью крутин,
можем разделить два этих шага.
Мы можем разделить аллокацию стейта для задачи,
и мы можем разделить планирование задачи в тредпул.
Ну это тонкие материи, но с другой стороны, этап курса
уже достаточно поздний, поэтому мы занимаемся сложными вещами.
Ну вот, две такие оптимизации, и у них одна и та же природа.
Мы берем сложную задачу и ищем в ней подзадачи
и разделяем их на явные шаги.
И те применения, те контексты применения, там, тредпула
или асинхронности, которые могут сэкономить за счет знания
об отдельных шагах, они могут этим пользоваться.
А те, кто не может, ну вот работают как и раньше.
То есть мы получаем возможность для оптимизации,
потому что мы дробим составные операции на более примитивные,
более таки атомарные.
И в обоих случаях мы пользовались тем, что у нас задача – это крутины.
Так вот, я сегодня хочу обратить ваше внимание,
что крутины здесь в таких соображениях совершенно не обязательно.
Что на самом деле можно те же самые оптимизации придумать
и реализовать, забыв про крутины, а потом крутины в них интегрировать.
Ну, короче, мы сейчас ведем еще один слой абстракции,
еще одни промежуточные сущности,
и, с одной стороны, дизайн еще больше усложнится.
То есть у нас бы словарь расширится.
У нас так уже много всяких непонятных слов,
типа «крутины», «авейторы», «экзекьюторы».
«Экзекьюторы» – огромное количество слов,
уже это похоже на какой-то странный птичий язык.
Вот сегодня станет еще сложнее,
но, с другой стороны, станет еще аккуратнее.
Мы сегодня с вами разберем, по сути,
ну, по существу, не в подробностях,
но основные концепции дизайна пропозала STD Execution.
Это вот представление о светлом будущем C++
о том, как в нем, в этом светлом будущем,
нужно описывать произвольные вычисления.
Вот утверждается, что это некорутины,
то есть способ, которым нужно описывать
произвольные вычисления, это некорутина.
Это, к сожалению, не 23 уже,
это история более поздняя,
но, с другой стороны, это все можно
своими глазами пронаблюдать
в виде отдельной библиотеки.
Ну, то есть не требуется ждать будущего.
Это не языковая фича,
именно что библиотека, в отличие от корутины.
И мы сегодня разберем, на каких принципах,
на каких сущностях она построена.
Я так скажу, что на бумаге,
вот на уровне идей, концепции,
все выглядит чрезвычайно строено,
чрезвычайно изящно,
и, ну, по крайней мере, такого дизайна,
кажется, нет в других языках.
Он еще не сошелся, но выглядит все чертовски разумно,
и я хочу, чтобы мы сегодня, ну, попытались
все это сами прочувствовать.
Давайте начнем.
Говорить про этот самый CD-XQ.
Итак, дизайн строится, ну, поначалу
на двух сущностях.
На сущности сендера и сущности ресивера.
Мы сегодня снова будем писать все своими руками,
потому что иначе мы ничего не разберем.
Так что, пожалуйста, следите за тем, что я пишу,
у меня будут ошибки компиляции, помогайте мне их чинить.
Будет неизбежно.
Две сущности – сендера и ресивера.
Тут они вот так очень, очень наспех описаны
такими простыми концептами.
Давайте начнем с сущности ресивера.
Ресивер – это очень простая идея.
Это некоторое обобщение колбека.
А сендер – это некоторое представление
операции, которая что-то вычисляет.
Вот есть вычисление, и есть некоторые…
есть асинхронное или синхронное, не знаю, какое-то вычисление,
и есть колбек, который хочет получить результат этого вычисления.
Сендеры и ресивера.
Как мы представляем колбек, который ожидает
некоторого результата вычислений?
Это некоторый объект, который поддерживает вот такой вот протокол.
Три метода.
Во-первых, на нем можно сказать setValue.
Вот вычисление состоялось, вычислило значение value,
и вот ресивер получает это значение,
и как-то на него реагирует, как-то его обрабатывает.
Он его ждал.
Но, может быть, вычисление завершилось ошибкой.
Тогда мы отправляем ресиверу exception pointer,
ну и вот ресивер своим способом,
одному ему известному, обрабатывает эту ошибку.
Ну или setDone – это отдельный механизм,
про который мы совсем еще не говорили в курсе,
и, видимо, поговорим через неделю.
Это механизм для отмены операции.
Ну, потому что, может быть, вычисление,
которого ожидал ресивер, просто отменилось,
потому что оно уже никому не нужно.
Нет, вот может показаться, что да, но мне кажется, что нет,
потому что если бы там было похоже,
я бы назвал метод cancel, а я назвал его discard,
потому что discard – это про то,
когда задачу просто выбросили,
а cancel, скажем, для файберов,
он должен реализовываться совершенно иначе,
на другом уровне, не на уровне экзекютеров.
Ну, вот тонкие какие-то материи,
я сейчас не готов подробно их обсуждать,
но мне кажется, что это разные вещи все же.
То есть можно увидеть связь, но мне кажется,
что она не совсем точна здесь.
Так или иначе, вот callback,
который ожидает результаты вычисления,
может получить либо значение, либо ошибку,
либо сигнал о том, что вычисление просто отменилось.
Что?
Это описание того, что мы ожидаем от типа T.
Для лекции совершенно неважно
наличие в этом коде концептов,
это просто способ в одном месте,
но я буду в одном месте буквально этим пользоваться,
чтобы оператор QA weight перегрузить для нужных типов.
В общем, мы ожидаем, что есть
некоторый тип ресивера,
он поддерживает такой протокол,
вот что сейчас важно.
И откуда этот ресивер получает
вот эти вот все либо значения,
либо ошибки,
либо сигнал про отмену,
он получает его от сендера.
Вот сендер – это чуть менее интуитивная
сущность, хотя не знаю,
может быть и вполне интуитивная.
Сендер – это некоторое вычисление
это вот объект, который представляет собой вычисление.
У этого вычисления
должен быть value type,
ну то есть вычисление заканчивается
вычислением значения некоторого типа,
ну либо ошибкой, либо отменой.
И мы хотим
операцию,
которая собственно стартует
вычисление. Вот мы хотим разделить
описание вычисления и
старт вычисления.
И старт вычисления мы
представим вот таким образом.
У нас есть некоторый сендер,
у нас есть некоторый ресивер,
и мы скажем, что
сендер, сабмит, ресивер.
Но это такой очень странный написанный
шаблонный код, тут, конечно, такой описать нельзя,
но я намеренно все упрощаю, если вам кажется,
что я сильно упрощаю, то да, я упрощаю.
Вот мы хотим через
сендеры, ресиверы
и операцию сабмит,
выразить вот буквально все на свете.
Задача пока выглядит довольно амбициозно,
но вот давайте посмотрим на какие-то
примеры. Давайте напишем
какие-то сендеры, какие-то ресиверы
и увидим, как это работает.
Начнем с ресиверов.
Вот мы ресиверы, то есть
прям классы с тремя методами
писать не будем, это будет утомительно,
поэтому мы напишем, ну точнее,
мы уже написали вот такую
вспомогательную функцию,
с ресивер, которая
по лямбде, зачем я так написал
вообще,
которая по лямбде, которая ожидает значения
типа t, строит объект с тремя методами.
Вот у меня есть какой-то функтор,
какая-то лямбда,
и я для нее конструирую такой
объект, фактор ресивер,
у которого есть метод setValue, который
вызывает просто фактор значения
setError, который не реализован здесь,
и setDen, который тоже не реализован,
мы сегодня этими двумя вещами
заниматься почти не будем.
Вот, ну и мы построили ресивер,
теперь можно его вызвать,
и он должен напечатать, видимо,
17,
если все с нашим кодом хорошо.
Ну вот, пожалуйста, мы работаем с ресиверами, да?
Вот у нас есть некоторый кулбэк.
Пока смысла в этом мало.
Давайте теперь заведем некоторые вычисления
и воспользуемся вот наличием
ростованием сендеров и функцией Submit.
Я сейчас напишу какой-то код,
а вы
ответите на вопрос, а что я
имел в виду, а потом уже мы напишем
реализацию, то есть как он должен себя вести, а потом
реализацию напишем.
Я конструирую сендер
вот так вот.
Я конструирую ресивер.
Это вычисление,
а это обработчик, результат.
Вот.
Пока ничего не стартовало
никакого вычисления, а теперь я говорю
Submit Sender
Perceiver.
Что должно случиться
вот в этой строчке?
Утверждается, что я описал некоторые вычисления.
Не похоже, чтобы тут какая-то
асинхронность была, какие-то там
параллельности, полый поток в планировщики,
вот тут ничего такого нет.
Что я имел в виду?
Я имел в виду, что
вот тут ничего такого нет.
Что я имел в виду вот этими строчками?
Какое вычисление должно произойти?
Что вообще должно произойти?
Какой код должен исполниться?
Ну, видимо, я ожидаю,
что на ресивере
вызовется Set Value от 17
просто синхронно. Вот в этом вызови Submit.
Ну вот, давайте теперь напишем
этот самый Sender Just.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
Ну вот.
и в нем вызывается sender-submit-receiver, на экран печаталось бы 17.
Ну, там нет Receiver, там есть setValue. setR. setValue какого?
Ну, видимо, которого я не написал, да?
Вот я хотел сказать вот так.
Давайте проверим, что вычисления состоялось.
Здорово. Вот, смотрите, мы с помощью senders и receivers описали вычисления.
Ну, не очень пока полезно, но еще раз напоминаю, что наш фреймворк сегодня предназначен для того, чтобы описывать произвольные вычисления.
Появится скоро какая-то асинхронность, но вот пока можно описать что-то синхронное.
Вот мы написали Receiver, вот мы написали sender, самый простой синхронный, который прожидает значения.
Да, он не дописан, конечно же, потому что чтобы быть sender-ом, нужно объявить value type, который мы вычисляем.
Это нам...
Да, можно.
Так можно делать.
Ну, я в одном месте где-то мне необходимо сделаю, а в остальном я жизнь сложить не буду.
Но ты совершенно правильно говоришь, что зачем объявили концепты, когда им не пользуемся.
Было бы странно, нужно ставить ограничение на тип.
Давайте теперь напишем следующий sender.
Непонятно что.
А потом submit, sender, receiver.
Вот два вопроса, что я имел в виду, и какой тип должен получить вот здесь receiver.
Ну, я не знаю.
Я не знаю.
Я не знаю.
Я не знаю.
И какой тип должен получить вот здесь receiver?
Future?
А что значит future? Ну, future – это вообще-то не value, это вот...
Здесь я хочу обычно значение получать.
Вот значение, ну, receiver, он же получает результат вычисления.
Это не может быть future, потому что future – это некоторое еще незавершенное вычисление.
Я хочу уже значение получить.
Ну и к тому же, значение какого типа я хочу получить, когда у меня просто написано neutral без аргументов?
Никакого. То есть future от никакого значения.
Ну, тут...
Давайте, ну, нет, void мы не хотим писать.
Мы не угадываем.
Понимаете ли вы, что происходит?
Вот смотрите, здесь вычисление синхронное, да?
Это довольно непривычно, но пусть.
Но зато понятно, что оно вычисляет значение типа int.
А здесь вычисление у нас будет асинхронное.
Но, с другой стороны, что оно вычисляет – непонятно.
Но есть какие-то гипотезы, что оно вычисляет.
Ну, семантические. То есть не то, чтобы какой тип написать сначала.
Ну, может быть, мы дадим вот этот thread, в котором он сможет дальше другие...
Вот, это правильная мысль.
Мы здесь вычисляем, по сути, ничего, но асинхронно.
Вот. Но ничего можно по-разному представлять.
Вот, если вы когда-нибудь писали шаблонный код, то вы понимаете, что с void лучше не работать с шаблоном.
Что отсутствие значения лучше представлять типом unit, который имеет одно единственное значение.
Unit – это пустая структура. Вот.
И ресивер, и сендер здесь будет вычислять просто unit type.
Но асинхронно.
И здесь я хочу написать следующее.
Здесь же есть такое название.
То есть это demon estate совсем не похоже по названию на type unit, которым он является.
Поэтому я, если позволишь, воспользуюсь возможностью, напишу свой type unit с нормальным названием.
Может, ему стоит добавить новую негативность?
Так, давайте держать себя в руках.
Мы сейчас не пишем максимально хороший код, потому что я уже во многих местах написал его плохо.
Мы пишем простой код, который иллюстрирует то, что нам нужно сейчас.
Итак, давайте напишем теперь сендер neutral, который асинхронно вычисляет значение типа unit.
А, кстати, мы сегодня сдержаны границами времени, потому что мы не успеем?
Ну что ж, тогда сильно ускорится.
Итак. Нет, эту реакцию невозможно разорвать.
Итак, что мы здесь напишем?
И тогда мы будемByte.
Б Ting-tongue.
Д pitching-tongue.
ungkin.
И на этом environmental sequence.
Я создаю трэд, в него передаю лямбду, в которую захватываю,
давайте экономить время, захватываю ресивер
и вызываю ресивер setValue от экземпляра унита, ну и DetachThread.
Вот теперь можно наверное вызвать этот код,
но убедиться сначала, что мы в одном потоке.
Ну да.
Попробуем еще раз.
Ну вот, вот теперь мы научились стартовать асинхронную операцию,
которая ничего не вычисляет, но которая как бы запускает ресивер уже где-то в другом потоке.
Вот, довольно мощная идея, потому что сейчас мы с помощью нее напишем thread pool.
И я бы сказал, что сегодняшняя лекция, она с одной стороны про такой более общий фреймворк вычислений,
как можно вычисление описывать довольно абстрактно, а с другой стороны она вот как бы
закрывает эту длинную арку развития пула потоков, которая начала где-то в феврале еще,
да, наверное, где мы построили совсем скромный, совсем простой thread pool.
Потом мы его улучшили с помощью сложного алгоритма планирования,
мы там усложнили его интрузивностью, улучшили его интрузивностью, ну некоторые из вас.
А сейчас мы поговорим о том, как вообще должно выглядеть API thread pool,
потому что оказывается, что оно может выглядеть иначе, не так, как мы до этого момента полагали.
Вот, это такая очень сложная, очень длинная эволюция пулопотоков.
Вот, пожалуйста, зафиксируйте ее в своем сознании.
Итак, мы хотим написать thread pool, но не думайте, что сейчас буду писать thread pool прям заново весь,
я напишу его несколько проще.
Вот, у него будет метод Submit, который получает таску и исполняет ее.
Вот, это наш thread pool пока на сегодня.
Ну, то есть здесь можно представить себе какой-то более сложный код,
можно представить себе там шардированный планировщик с workstation,
ну или хотя бы блокирующую очередь и потоки, но здесь мне не важно, как он устроен внутри,
мне важно, как я с ним работаю, а я с ним хочу работать снова как с sender.
Вот, у меня есть пулпоток, и вот у меня есть ресивер.
Этот ресивер снова будет вычислять значение вой, значение юнь.
Как я хочу этот ресивер запустить в пулепотоков?
Ну, видимо, мне нужна будет операция запланировать в thread pool.
Давайте ее напишем.
Но в конце концов, какая разница?
Я планирую задачу в новый thread или в thread pool, да?
То есть и в том, и в другом случае sender, и я снова их не подписываю,
в смысле, обвращаемые типы совершенно напрасно.
В этом случае нам снова нужен sender,
который снова вычисляет юнит, но вот в одном из потоков воркеров пула.
Мы получаем ресивер, и что же мы с ним сделаем?
Ну, мы для начала построим thread pool sender,
запомним в нем thread pool, в который мы планируем задачу.
Ну и в методе submit мы напишем что?
Мы в методе submit напишем submit.
Вот, кажется, что все довольно разумно.
Вычисляем юнит и запускаем ресивер set value.
Получился thread pool sender, да?
И теперь мы можем в thread pool запланировать работу.
Давайте этот пример закомментируем, потому что он будет нас шуметь немножко.
Мы не сделали submit.
Как хорошо, что я не один.
Ага, ну невозможно установить эту плему или нет, потому что...
Ну давайте хотя бы здесь напишем следующее.
Это нас чуть больше убедит, что происходит нечто разумное.
Ну вот, мы построили sender для poola-потоков.
Вот прямо сейчас, мне кажется, что разумно еще немного наш дизайн усложнить
и вот к трем сущностям, которые у нас уже появились, sender и receiver,
добавить сущность, которая называется планировщик.
Как вы думаете, чем будет заниматься планировщик для poola-потоков?
Ну submit, так это деталь реализации планировщика.
Я хочу вписать же эту сущность в наш абстрактный дизайн, где есть sender и receiver.
Вот да, мы хотим придумать планировщики теперь, которые будут строить sender.
А sender – это представление каких-то вычислений синхронных, асинхронных.
Вот планировщик для poola-потоков будет строить sender,
который асинхронно вычисляет voids.
Понятно, да?
Давайте мы сейчас это все и напишем.
И мы немного перефакторим этот код.
У нас есть sender, и мы хотим написать планировщик для poola-потоков.
Какой-то конкретный планировщик.
И у него будет метод shadow, который
строит sender для poola-потоков.
То есть вот такие еще не стартовавшие асинхронные операции,
которые в случае poola будут асинхронно вычислять значение типа u.
И мы напишем метод getShadowler,
который возвращает планировщик для poola-потоков.
А это мы вообще сотрем.
И давайте, чтобы у нас не было соблазнов больше, уберем submit.
Submit – это какая-то деталь реализации.
В нашем фреймворке будут только sender, receiver и планировщики,
поэтому, чтобы запланировать задачу в threadpool,
мы должны сначала получить планировщик,
потом с помощью него
построить sender, который асинхронно вычисляет void,
а потом запустить.
Вот видите, мы разделили два шага.
Мы разделили представление нашего асинхронного вычисления unit void
и запуск планирования в threadpool.
Пока все довольно сложно выглядит,
мы атомизируем отдельные шаги в наших предшествующих операциях,
поэтому не удивительно, что появляются какие-то промежуточные сущности.
Итак, у нас есть теперь уже три sender,
и мы сейчас научимся делать вот что.
Вот вспомним про future.
В чем их замысел?
В том, что можно для future, для асинхронной операции,
запланировать продолжение с помощью метода subscribe
или с помощью комбинатора Zen.
То есть у нас есть future,
мы можем прицепить к ней следующий шаг вычисления,
то есть продлить вот этот граф вычисления.
И у нас здесь есть sender,
которые представляют собой по сути,
ну это не future, разумеется,
но суть очень похожая.
Это какое-то вычисление, которое еще не стартовало,
но про которое известно, какой результат оно построит.
Вот давайте мы для sender-ов
напишем теперь комбинатор,
который будет называться Zen,
и посмотрим,
чего мы от него хотим.
Мы начнем с какого-то вычисления
в пуле потоков,
вычисления unit.
А дальше мы хотим следующего от него,
мы хотим написать вот так вот.
Вот, по-моему, все правильно.
Вот, я хочу в пуле потоков вычислить 42.
Вот я вычислил в пуле потоков 42.
Я взял sender,
который вычисляет 42,
я взял его к асинхронному вычислению unit,
и вот теперь я асинхронно вычисляю 42.
А теперь я хочу
добавить
к вычисленному значению
еще один.
И все это вычисление
я хочу замкнуть
некоторым ресивером,
который напечатает результат на экран.
Вот.
Вот теперь я хочу, чтобы выполнился
такой код. Для этого мне нужен
комбинатор Zen, который получает sender,
то есть вычисление, которое вычисляет
некоторое значение, получает
продолжение синхронное,
и строит новое вычисление,
которое вычисляет
уже результат, который вычисляет
цепочку.
Давайте его писать.
Нет, мы этого не хотим
делать.
Назначение в общем случае
нон-копия было. Как мы можем использовать
назначение в нескольких местах?
Ну, если тебе хочется
циклы писать, то мне кажется, что
для всего можно придумать
решение, но
вот писать его в таком
фреймворке, мне кажется, уже нецелесообразно,
но есть разные мнения.
Давайте сейчас напишем Zen,
потому что у нас довольно мало времени остается.
Итак, у нас есть
sender, у нас есть некоторая
функция продолжения,
и мы пишем
комбинатор Zen, который получает
sender, который получает
продолжение и
возвращает
новый sender,
который вычисляет уже цепочку.
Вот тут нужно аккуратиться,
смотрите,
у нас есть
фреймворк,
у нас есть
фреймворк,
у нас есть
фреймворк,
у нас есть
фреймворк,
у нас есть
фреймворк,
у нас есть
фреймворк,
и нужно аккуратиться, смотрите,
у нас есть
sender, есть продолжение,
и нужно разобраться, что вычислял
S и что вычисляем мы,
Zen. Вот что вычислял S?
S вычислял
тип T,
который объявлен
у каждого sender.
Мы потребовали, чтобы каждый sender объявлял,
что он вычисляет. А что мы вычисляем?
А...
Итак,
как мы собираемся вычислить это значение
U? То есть смотрите, вот мы
Zen sender, который вычисляет U теперь,
поэтому мы ожидаем ресивера,
который ожидает на вход
U. Давайте мы так его назовем,
у ресивер, чтобы различать.
Вот. Но когда мы...
Но чтобы стартовать цепочку, мы же должны
стартовать ее сначала. То есть мы должны стартовать
наш sender, вот S, который нам дан.
Вот. То есть мы в конце концов напишем здесь,
давайте вот так напишем, T sender,
мы
стартуем вычисления,
а для этого должны передать сюда, видимо,
T ресивер. То есть ресивер
вспомогательный, который получит значение T
и преобразует его в U.
Ну, да,
она где-то ниже объявлена просто.
Вот. Мы сейчас напишем T ресивер,
который будет
ожидать значение
типа T,
от первого шага вычисления, ну вот,
как бы префикса вычисления, да,
которому мы хотим добавить еще одно звено.
И что мы хотим сделать
с этим T value?
Мы хотим применить
F к этому значению.
Давайте его захватим.
Получить значение
U.
И что с ним сделать?
Отправить его в ресивер.
Отправить его в ресивер.
Ну что ж, неплохо, да?
Вроде написалось.
Написалось, но,
как всегда, не комперируется,
потому что я не аккуратен.
А почему он не используется,
когда вот же используется?
Ну, давайте попробуем.
Я где-то что...
Ну да, я не объявил у Зэн Сэндера
тип, который он вычисляет.
Да.
Уют был, да, спасибо.
Здорово.
Работает.
Что?
Вот он.
Нет.
Не очень понимаю. Мы пишем Сэндер.
Мы пишем Сэндер, который...
Мы пишем вообще
Трансформатор, который получает Сэндер,
некоторое вычисление
и вот функцию, которая
хочет прицепиться к этому вычислению.
И строим новый Сэндер, который
называется Зэн, который представляет собой
вот такое новое длинное вычисление,
которое состоит из вычисления S,
которому конкатинируется
функция F.
Так что мы сначала
запускаем этот префикс вычисления,
а потом,
когда это вычисление завершается,
мы во вспомогательном ресивере
запускаем эту самую функцию F
и уже отправляем
результат в
ресивера всей цепочки,
которую мы построили.
Ну что ж,
достойный результат, а теперь
нужно представить, в какой-то кодке
это все скомпилируется. Вот смотрите,
что такое
ThreadPoolShadow?
ThreadPoolShadow or Shadow
это класс ThreadPoolSender,
да?
ThreadPoolSender, у которого есть... Где же он?
ThreadPoolSender,
у которого есть одно поле, это
ссылка на ThreadPool.
Потом мы строим по нему
Zen от S0.
Zen это класс
ZenSender.
У него есть два поля.
Это предшествующий
Sender и функция.
Предшествующий Sender это ThreadPoolSender,
то есть мы в поле этого класса заинлайним
ThreadPoolSender с одним полем,
ссылку на ThreadPool.
А теперь мы говорим
еще раз Zen.
И мы строим
еще один ZenSender,
у которого будет
поле S и поле F.
Поле F это предшествующий Sender,
в котором было уже
ссылка на ThreadPool и
первая функция.
И то есть, вот мы, смотрите, здесь
получим конкретный класс
неизвестного нам типа, у которого будут
три поля.
Ссылка на ThreadPool
λ1, л2.
И когда мы назовем, вызовем на нем
Submit, то что он сделает?
Он в ThreadPool бросит сразу
скомбинированную лямду, которая вызывает
сначала функцию,
сначала первое
Receiver, то есть первую функцию от
унита, а потом вызывает от результата
вторую функцию. То есть это все заинлайнится,
понимаете?
Но если не понимаете, то...
Если не понимаете,
то можно продемонстрировать.
Вот давайте мы
сотрем все лишнее,
что нам
сейчас помешает.
Сотрем...
Сотрем корутины,
которые нам
не нужны
пока.
Будь здоров. И
сотрем лишние
сложные функции.
И все еще очень
сложный код.
Я хочу, чтобы он был попроще,
но я где-то ошибся, нет?
Да, вот.
Вот что мне мешает,
чтобы получить простой код.
Мне нужно избавиться от этой строчки еще.
Вот, отлично.
Во что скомпинировался Main?
Он скомпинировался
в вызов 43.
Ну, то есть компилятор
все это заинлайнил, и
то, что мы делаем,
то, что мы делаем,
то, что мы делаем,
то, что мы делаем,
компилятор все это заинлайнил, и
ну, если бы здесь был Трэдпул,
то код бы выглядел сложнее,
то есть он бы заинлайнил Сендер,
то есть построил бы функциональный объект
с двумя полями функциями, там внутри
смог вызвать одно в другом и получить 43,
Трэдпул бы он сам не стер.
Но здесь он стер даже Трэдпул,
потому что у нас он ничего полезного не делал.
Вот, то есть
за счет того, что
мы вот здесь пишем все на шаблонах, за счет того,
что вот эти Зены можно заинлайнить друг друга,
и все это схлопывается в такие вот
атомарные шаги, и все получается еще
эффективнее.
Хорошо.
Вот утверждается, что мы построили
новый универсальный
API для Трэдпула. Вот так
в него должны планироваться все задачи.
В частности, корутины.
Почему бы в Трэдпуле не запускать корутины,
да? Мы же так делали уже.
Ну, то есть чтобы корутина стала
вообще какой-то асинхронной работой,
она должна переместиться в Трэдпул.
И раньше мы писали
Трэдпул Сенд для корутин.
Вот давайте начнем
это делать.
И вот у нас есть
пусть
корутина,
которая получает Трэдпул
и хочет в нем исполняться.
Ну ладно, мы сказали,
что мы работаем с планировщиками,
поэтому пусть мы получаем даже
не Трэдпул,
а мы получаем сразу
планировщик.
Планировщик, то есть штук,
который возвращает Сендр.
И мы хотим
перепланироваться в пул потоков,
в произвольный планировщик.
А произвольный планировщик строит Сендр.
Вот мы хотим каким-то образом написать
CoEv8
ShadowerShadow
Shadow, я напомню,
возвращает нам Сендр.
Сендр — это представление
для асинхронных операций,
которые потоки в Orkery вычисляют unit.
И мы хотим этот пример
сейчас написать.
У нас есть Трэдпул,
у нас есть планировщик,
и мы стартуем к корутину,
которая хочет переместиться в этот планировщик.
И вот это очень важный момент
лекции, может быть даже самый важный,
который поясняет,
демонстрирует нам,
почему вот этот дизайн чертовски разумен.
Сендр и ресивер.
Почему выгодно описывать
все вычисления в виде Сендр и ресивера
в конце концов?
Потому что эти Сендр и ресиверы
очень хорошо ложатся на корутины,
потому что на самом деле тут есть
совершенно прямая, очень ясная
параллель.
Вот.
Что такое у нас есть?
Какие у нас составные элементы есть?
Сендр – это асинхронная операция,
которая еще не стартовала.
Вычисление, возможно, асинхронное,
которая еще не стартовала,
ленивое вычисление.
Есть ресивер, который ожидает результат.
И есть операция, которая стартует,
то есть связывает Сендр ресиверы,
запускает вычисления,
все это случается.
А теперь у нас есть корутина.
Корутина хочет попасть в третпул.
Для этого она должна остановиться,
а потом в третпуле
возобновиться.
Вот видите ли вы
связь между корутиной
и Сендром?
Корутиной и планировщиком
пула, который строит Сендр для пула.
Или вообще связь между
произвольной корутиной и произвольным
Сендром?
Потому что, смотрите, что я утверждаю,
что операция коэвейт
от Сендора это чертовски разумная
операция.
Вот если у нас есть Сендор, который представляет собой
вычисление, то очень естественно
и универсально для него поддержать
оператор коэвейт.
И вот ровно здесь мне нужны концепты, наконец.
Понимаете ли вы, в чем связь?
Вот давайте
выпишем сущности. У нас есть ресиверы,
у нас есть в дизайне, в нашем Сендоре,
и есть Сабмит.
Ресивер это колбэк
обобщенный, Сендор
это ленивое, еще не стартовавшее
вычисление, Сабмит
это точка, которая связывает
Сендор и ресивер,
и сэндор это
ленивое, еще не стартовавшее
вычисление. Сабмит это точка,
которая связывает Сендор и ресивер
и стартует вычисление.
Вот можно ли
провести аналогию с корутинами здесь?
Проводи.
Вот ресивер
это что?
Другие попытки.
Ресивер это
сама корутина. Вот смотрите,
когда мы пишем коэвейт, почему вообще
мы пишем коэвейт?
Вот допустим, давайте откроем пример,
мы пишем коэвейт на фьюче.
Что мы имеем в виду? У нас есть
фьюча, некоторые синхронные вычисления.
Мы хотим корутину остановить,
а когда оно завершится, мы хотим корутину
возобновить и передать
ей значение, которое оказалось
во фьюче.
Ну вот возобновить
корутину и вызвать ресивер
с значением v
это же что-то очень похоже.
Потому что корутина это и есть
машинно генерируемый
колбэк.
Ну правда же.
Просто сам
компилятор перепишет функцию корутину
на объект с вызовом
резюм, который по сути является
колбэком. Мы вызываем этот резюм,
когда операция завершилась.
Вот здесь вот,
в овейтсаспенде мы подписываемся
на фьючу и вызываем
здесь резюм.
И передаем значение через поле.
Ну это же буквально
set value на ресивере.
Вот я утверждаю, что
повернемся сюда, что
корутин это ресивер в терминах
вот нашего фреймворка.
А что такое sender?
Сендер это некоторая синхронная операция.
На что она похожа в терминах
корутин?
Вот sender
это некоторое вычисление,
точнее, я говорю, синхронная операция все время,
но в общем случае вычисление.
Вот. Это
то, чего мы дожидаемся, да?
То, чего ресивер дожидается. То, чего дожидается
корутина. А то, чего дожидается
корутина решает овейтер.
Вот у нас есть некоторое выражение, кое вейт там
что-нибудь, и мы поэтому что-нибудь
строим овейтер, который знает, как дожидаться.
Вот.
Это овейтер.
А что такое submit?
Submit это вот, это операция,
которая стартует вычисление.
Это просто
кое вейт.
Вот кое вейт, он
и вызывает на овейтере овейт
suspend. Когда мы пишем в коде
кое вейт,
вот здесь вот, когда мы доходим
до его исполнения, то комператор
что делает? Он
строит овейтер и
в нем вызывает овейт suspend.
И связывает, смотрите,
сэндера
и ресивера.
То есть, овейтер с
конкретным хэндлом,
который нужно возобновить потом. То есть,
с конкретной корутиной, которую нужно возобновить.
То есть, у нас вот совершенно прямая параллель.
То есть, мы придумали фреймворк, который
более общий, чем корутина,
и в который корутины очень естественно,
очень органично интегрируются.
Поэтому мы сейчас можем сделать что?
Написать совершенно произвольный
написать
овейтер
для совершенно произвольного сэндера.
И корутины смогут дожидаться любого
сэндера. Синхронного,
асинхронного, что угодно. То есть, мы
свяжем одни сущности с другими.
Вот давайте мы сейчас это аккуратно напишем.
Тут
вот еще больше абстрактных слов
стало совсем много, но
ничего не поделать.
Что такое овейтер? Овейтер — это класс,
который реализует протокол овейтера.
Например, овейт, ну, в частности, овейт радио.
Корутина хочет остановиться.
Вот мы говорим, останавливайся.
А когда он останавливается, мы пишем
await suspend,
который получает корутин-хэндл.
И этот овейтер
решает, когда корутину нужно возмновить.
Когда? Когда сэндер вычислит значение.
А когда он вычислит значение?
Ну, то есть, во-первых,
мы должны стартовать это вычисление,
кажется, здесь, да?
А в качестве ресивера мы
передадим что?
В качестве
ресивера... А мы, кстати, не знаем, что
этот сэндер вычисляет, да?
Да, конечно.
Мы бросаем ресиверы,
и этот ресивер, когда вычислится
значение типа T,
мы должны передать его в
корутину. Но мы должны
корутину зарезюмить,
во-первых,
поэтому мы захватили ее хэндл.
А во-вторых, после резюма
она должна вернуть
значение типа T.
As receiver вот здесь.
Вот, но после возобновления мы должны вернуть значение.
Ну, так уж и быть.
Придется его вот в этом классе
запомнить.
Ой, ладно, что я мучаюсь-то?
Буду писать
неаккуратно.
Не делайте так, но вы и сами понимаете,
что так не сделать.
В общем случае.
Вот так вот.
Вот так вот.
Вот так вот.
Вот так вот.
Ну что,
утверждается, что я написал
вот
овейтер для
произвольного сэндера, если вы все еще
с нами, конечно.
И ровно поэтому мне кажется,
что у меня заработал кое овейт для шэдулера
шэдул.
Давайте мы в этом
убедимся.
Нужно что-нибудь вывести?
Где вообще?
Кто все эти люди?
Да, вот работает. Итак, смотрите,
что мы сделали. Мы увидели, что...
Ну, во-первых, чего мы достигли? Мы выдумали
новые сущности, сэндеры,
ресиверы, шэдулеры.
И утверждаем, что любое вычисление
можно выразить с помощью этих сущностей.
Выдумали новый аппетит
Редпула, потому что он должен
иллюстировать эту идею, что
можно выразить все в таком виде.
И мы увидели, что корутины, а вот это
довольно абстрактный, вот
почти что максимально абстрактный способ
описывать вычисления,
асинхронные в первую очередь,
интегрируются с этим фреймворком
очень органично. Мы можем
в корутине дожидаться произвольного
сэндера, потому что сэндер – это произвольное вычисление.
Почему бы и нет?
А ну, давайте, кстати, еще раз
проверим, что все работает. Вот у нас есть
корутина. Давайте мы
еще
напишем вот так.
Почему бы не дождаться
17?
Пустив при этом кучу скрытой механики, да?
Ну вот, замечательно.
Все работает.
А теперь
теперь
мы сделаем еще один шаг
и поймем, как можно придумать
интузивность в планировщиках.
И увидим, что еще в нашем коде есть
неоптимальность. Давайте я сейчас
перееду в
другой файл,
потому что мне нужно избавиться от
некоторого
накопленного кода.
Я хочу
хочу сохранить себе третку.
И я хочу, наверное,
сохранить себе
что бы я еще хотел сохранить.
Зен не хочу.
А я не здесь.
Ну, допустим, я хочу
сохранить корутины пока.
Я хочу сохранить корутины.
И я хочу сохранить
сабмит.
Итак.
Итак.
Мы с вами разделили
два шага
конструирования операции,
планирования асинхронных операций,
планирования шагов,
в виде цепочки, например, этих зенов,
и запуск операции.
И поэтому мы получаем возможность
писать код эффективнее.
Но у нас еще есть некоторая
неэффективность.
Где ее можно увидеть?
Ее можно увидеть,
как бы мне это успеть за 7 минут,
увидеть здесь.
Мы в третпул бросаем, в конце концов,
лямду, которая запускает
на ресивере сетвэлью.
Но лямда это очень неэффективно,
потому что это же аллокация памяти.
Мы оборачиваем произвольную
лямду в std function.
И она не возит.
Ну давайте я попробую это быстро
написать все же.
Что такое std function?
Давайте в третпул напишем чуть более разумным образом.
Где я ошибся?
Ну вот, это уже более разумный третпул.
Да, надо.
Ну вот, перенос кода не состоялся.
И конечно, здесь мы ничего
от императора хорошего не узнаем.
Ну вот, вот, вот.
Вот, вот.
Ну вот, вот.
Ну вот, вот.
Ну вот, вот.
Ну вот, вот.
Ну вот.
Ну вот.
А, ну потому что сейчас
А, ну потому что сейчас
это ерунда просто,
это нужно сценить.
А, я карутины не перенес
еще.
Третпул.
Нет, вот же она.
Я не тот код запускаю просто.
А у нас осталось 5 минут, да?
Мы не успеем ничего.
Ну то есть можно даже не начинать, мне кажется.
Если у нас правда осталось 5 минут,
то мы упустили
самую важную часть лекции.
Что?
Ну, я могу,
но только если,
только если по зуму уже.
Вряд ли мы будем собираться заново.
Вот, ну вот.
Давайте я за 5 минут расскажу,
что мы хотим сделать,
а мы продолжим,
и ты же смонтируешь просто потом
в один файл.
Смотрите, в чем у нас прямо сейчас
есть неоптимальность.
Вот, аккуратно.
Мы действительно построили
общий API.
Мы действительно разделили
два шага планирования операции
и запуск операции.
Но вот если мы пойдем
вглубь всей этой механики
и посмотрим на то,
что делает карутина, когда она пытается
перепланироваться в тредпул,
то она берет сендер
тредпула, который выглядит вот сейчас
вот так вот.
И с помощью
CoAwait
в AwaitSuspend
вызывает на этом сендере Submit,
а сендер для тредпула в методе Submit
вызывает непосредственно уже
Submit в тредпул. И здесь
ресивер, который
резюмит карутина,
отправляется
запакованным в лямбду
в пул поток.
Это неэффективно, потому что
что такое... Давайте про лямбду я как раз успею.
Как это вот работает?
Вот в тредпул бросаются
произвольные лямбды.
Эти произвольные лямбды
это вот какие-то классы какого-то разного размера,
потому что ресиверы это какие-то классы
разного размера, потому что у них какие-то произвольные поля
функторы.
Вот. Так что мы должны положить в
контейнер, вот в частности в дек
задачи
разного размера.
Но контейнеры так не работают, контейнеры гомогенны.
Это должен быть тип некоторого известного размера
size of t.
Поэтому мы должны каким-то образом тип стереть.
Поэтому мы пишем класс
task,
который как устроен? Ну вот...
Давайте
это фанкшн. Фанкшн, который
без
аргументов и без
возвращаемого значения.
И этот фанкшн
получает в конструкторе, ну почему
f?
Получает f. Ну я вот грубо копировать
буду, неважно. Вот. И я хочу сделать
этот фанкшн, который бы имел
такой предсказуемый размер.
Непроизвольный. Каким образом я могу
этого достичь? Но видимо, я не могу хранить
в полях фанкшна сам f.
Но я могу переместить его на кучу.
И хранить на кучу уже.
Да?
И дальше я мог бы сохранить
в полях
что?
Ну как будто бы function
storage
f звездочка, да?
И вот вызывать
все это.
В операторе круглые скобочки.
Ну вот не знаю, что...
Напишем что-нибудь.
Вот так не получится. Почему?
Потому что я же не могу хранить pointer
на класс
какой-то конкретный шаблон. Я не знаю,
здесь f заранее.
Понимаете проблемы, да?
Вот. То есть внутри
function, внутри std function,
внутри нашего function
должен быть
pointer на класс, который хранит
функцию. И умеет ее вызывать.
Произвольный фанкшн умеет его вызывать.
И этот класс
конкретный в данном
каждый раз имеет
некоторый свой тип,
зависящий от типа лямбда.
От типа функторов, которые в него попало.
Но я знаю, что у всех
этих функторов есть в конце концов
операторы круглые скобочки.
И мне нужно с ними работать как-то полиморфно.
Ну как я эту проблему решаю?
Я завожу интерфейс.
И переставляю местами.
Наследуюсь от этого интерфейса.
Здесь реализую.
И уже в поле храню
просто pointer на интерфейс.
Это называется TypeRaiser.
И вот здесь
у меня есть
это называется TypeRaiser.
А здесь
ну зачем так писать?
Похоже на правду?
Вот еще буквально минутку
и мы распустимся.
Если конечно все заработает.
Так, и где же я?
А, ну господи.
А, ну господи.
Я же наследуюсь.
Вот.
К чему я?
К тому, что вот так в конце концов
реализована steady function,
который таз, который мы храним в тредпуле.
И когда мы бросаем корутины,
которые уже динамически алоцированы
на куче, мы все равно
оборачиваем эти
ресиверы, которые
оборачиваем лямбды,
в которых лежат ресиверы, которые
соответствуют корутинам, вот в такие
вот объекты, которые
мы алоцируем на куче. И вот у нас есть этот
new. И вот этот new он
неестественный для нашего
приложения. Мы уже знаем, что
экзекьюторы, экзекьюторам
не нужны эти динамические аллокации.
Вот, видимо,
пока наш фреймворк не совершенен,
потому что он не позволяет этих динамических
аллокаций для корутины сбавиться.
В очередной задаче про корутины
вас просят напишите, пожалуйста,
вот эти самые корутины так, чтобы
никаких аллокаций при планировании
не было, чтобы мы получали как раз вот
эту вот интрузивность. А здесь
в нашем фреймворке мы пока ее потеряли.
Вот, видимо, наш фреймворк все еще не
совершенен, и нам нужно ввести еще
что-то, ну, еще что-то атомизировать,
и тогда мы избавимся от этого new
дека-рутина и станет вот совсем оптимально.
И вот в этом месте мы остановимся.
Ну, а пока остановимся сейчас,
сделаем это завтра. Спасибо
за внимание.
Меня зовут Рома Липовский, чтобы вы помнили.
Мы сегодня
продолжаем разговор про то,
как можно описывать
какие-то асинхронные задачи
или вычисления в более широком
смысле, как можно
более абстрактно, как можно более универсально.
В начале прошлой
лекции...
Так, будет тяжело.
В начале
вчерашней субботней лекции мы с вами
говорили, что, в общем-то, корутины претендуют
на некоторую универсальность, что корутины могут быть
такими вот универсальными асинхронными
задачами, которые могут императивно
друг другу взаимодействовать, которые
можно функционально комбинировать,
потому что у нас есть представление
для еще не стартовавшей задачи.
Это объект TaskT, такая
ленивая фьюча.
Но мы дальше заметили, что
даже вот с таким инструментом
мы можем еще более
абстрагировать природу наших задач.
Мы можем еще больше
обобщить понятия,
с которыми мы работаем,
показаться даже от корутин,
а говорить уже просто про произвольные
ленивые вычисления, которые
в нашем случае представлялись
в виде
пары сендеров
и ресиверов. Но вернее как,
мы сказали, что давайте представлять
вычисления в виде сендеров.
Сендер — это некоторое вычисление, которое
вот уже представлено
в виде какого-то объекта,
которое вычисляет некоторое значение
некоторого типа, но
это вычисление еще не стартовало.
А для того, чтобы этому вычислению
стартовать, нам нужен объект Receiver.
Receiver — это callback, который
готов принять результат
вычисления, который вычисляет
этот самый сендер. Давайте посмотрим
на код, который мы вчера писали.
У нас были такие
очень компактные концепты
Receiver и сендера.
Receiver принимал либо значение
вычисленное, либо ошибку,
либо сигнал об отмене
вычисления, а вычисление
стартовало, когда
ему подавали на вход сендер.
Ну и у нас была такая общая
операция, которая стартует вычисление,
которая называлась Submit,
которая вызывала Submit
на сендере от Receiver.
Ну и в случае ThreadPool
Submit был довольно естественным.
Давайте мы его найдем.
Так мы его не найдем, конечно.
В случае Pool подоков, который мог бы
строить сендеры через специальный объект
сэндер-долвер, метод Submit
у сендера ThreadPool просто вызывал
ThreadPool Submit. Ну вот так можно
объяснить себе, почему такое название.
Мы стартуем некоторые вычисления.
А дальше мы с помощью двух тех понятий
пытались выразить произвольные
синхронные и асинхронные вычисления.
Мы начали с
синхронного вычисления,
мы построили sender.just, который
просто вычисляет синхронное
данное значение,
вызывали Submit на этом сендере
и этот Submit привел к тому,
что просто на экране сразу
печаталось вычисленное значение
в этом кулбеке.
Дальше мы написали
другой ресивер, который называл
другой сендер, который назывался NewThread
и он уже был менее интуитивен,
потому что он
вычислял что-то асинхронно,
но вычислял не какое-то значение,
привычное нам, вычислял значение
типа Unit, то есть фактически
ничего не вычислял, зато асинхронно.
То есть он асинхронно запускал
ресивер кулбек
в новом потоке.
А потом мы подумали, зачем нам запускать
новые потоки на каждое вычисление,
у нас же есть пул потоков и сказали,
что давайте теперь пул потоков
будет строить нам сендеры, которые будут
асинхронно вычислять
юниты в
потоках ворковых.
Но для того, чтобы эти сендеры строить,
мы ввели еще вспомогательную сущность,
которая называлась планировщик.
Вот по Threadpool строили планировщик
и планировщик в методе Shadow
строил сендер, которому
можно было потом с помощью Submit
прицепить ресивер и стартовать
асинхронные вычисления, то есть фактически
здесь внутри Submit положить задачу
в Threadpool.
Какая нам польза была
от всего этого?
Польза состояла в том, что наши вычисления
теперь ленивые, но
и до своего запуска они имеют
некоторое физическое представление
в нашей программе. Есть некоторый объект
Sender, который представляет это вычисление,
который вычисляет некоторые типизированные значения,
и за счет того, что у нас есть
представление этого объекта, а операция еще не началась,
мы можем к этому объекту
прицепить какие-то дальнейшие шаги,
то есть планировать более сложные вычисления
с помощью
комбинатора, который называется Zen,
который получает одно вычисление,
получает функцию, которая хочет
к этому вычислению прицепиться
сделать последний шаг, получить результат предыдущего вычисления и
трансформировать его с помощью вот этой функции. И мы можем с помощью Zen
получить вот sender функцию и построить новый sender, который
выполняет уже более длинную цепочку,
вернее представляет более длинную цепочку вычисления.
Мы какую-то мелочь, кажется, здесь не сделали, мы не написали здесь простой
сахар, который, конечно, хочется иметь.
И вот этот пример можно было бы написать, наверное, посимпатичнее, потому что
зачем нам все эти промежуточные объекты? Мы сначала планируем вычисление, которое
ассинхронно в потоке пулопотоков вычисляет юнит, а потом мы к нему цепляем
продолжение. А потом мы делаем еще один шаг.
Ну вот и так мы декларативно описали вычисление, которое еще не стартовало и
стартует оно вот здесь. Напомню, что выиграли мы то, что мы разделили, ну давайте из
далека, с чем мы вообще начинали в прошлый раз. Мы начинали вот с такого
примера, где у нас была некоторая функция, какое-то ассинхронное вычисление,
которое мы вызывали, оно возвращало фьючу и одновременно с этим планировало
задачу в пул потоков, а потом мы подписывались на результаты этого вычисления.
Проблема с этим кодом состояла в том, что у нас уже есть фьюча, когда
вычисление стартовало, и когда мы подписываемся на результат этой фьючи, то
возникает уже гонка с продюсером, который в пуле потоков вычисляет значение. То есть
имея фьючу, фьючу существует тогда, когда вычисление уже стартовало, и поэтому,
когда мы планируем продолжение, когда мы ассинхронно потребляем результат этой
фьючи, то у нас возникает такая естественная гонка между продюсером и
консьюером, и нам нужна синхронизация, нам нужна динамическая локация, нам
нужен подсчет ссылок. Вот много разного оверхеда, который нам не требуется, если
мы разделяем старт операции, то есть планирование задачи в тредпул, и
конструирование некоторого представления для результата этой операции. Вот здесь
два этих шага они скрыты вместе, а мы их вот в этом коде разделили. Мы сначала
получаем представление для будущего результата, потом подписываемся на него,
ну вот таким вот замысловатым образом в конце концов, и только в конце стартуем
операцию, то есть вот здесь вот происходит сабмит задачи в тредпул, и собственно
начинается вычисление. Вот это первый выигрыш, который мы получаем от
использования наших новых концепций, то есть от нашего нового словаря, который
мы ввели для описания вычислений. Следующий эффект, который у нас получилось,
это то, что пул потоков изменил свой API. Вот вроде бы ничего проще, чем пул
потоков на свете не бывает, но тем не менее в нашем пуле потоков у нас нет
метода сабмита, наверное он где-то под капотом, разумеется, есть, но в нашем пуле
он приватный, и наружу торчит только метод getShaddler, который строит
планировщик, который в единственной своей операции shadow без аргументов
строит sender, который ассинхронно вычисляет юнит, и который в методе
сабмит, связывая, получая ресивер, отправляет уже в тредпул задачу, которая
отправляет значение ресиверу. Вот такая сложная история.
Ну, кстати, легко представить, кто будет звать setDone, то есть отмену операции,
то есть если, скажем, на пуле потоков позовут stop и операция отменится, то пул
потоков может на ресивере позвать в конце концов setDone, но здесь немного
сложнее будет. Окей, значит, мы с этим пока вроде бы разобрались, да, то есть мы
понимаем, что мы делаем, мы понимаем, кажется, зачем мы делаем. Дальше, мы сказали,
что, ну, а как же так? У нас были уже довольно универсальные задачи в виде
корутин. Давайте я покажу. Вот, а нет, сейчас я не покажу, это другая ветка. У нас
были довольно универсальные задачи в виде корутин, а мы почему-то переключились
на другой язык, на другие сущности для описания вычислений. Почему бы не вернуться
к корутинам? Ну, оказывается, что это вполне можно сделать и интегрировать корутины в
этот фреймворк с эндерами и ресиверами. Можно заметить следующее, что вот пусть у нас есть
какая-то корутина, которая чего-то дожидается. Ну, вот корутина, в которой написано co-await.
Давайте такую корутину найдем. У нас их должно быть изрядно.
Ну, с таймером это менее интересно, потому что таймер ничего не вычисляет.
Давайте, наверное, посмотрим здесь. Да, вот у нас корутина, которая синхронно дожидается в
фьюче. Ну, неважно, чего она дожидается. Важно, что есть некоторая синхронная операция. В данном
случае, это композиция двух синхронных вычислений. Есть помощь у комбинатора first of,
который вычисляет первое из двух, который возвращает результат первого из двух
вычислений. И мы хотим остановить корутину до тех пор, пока за этой фьючей first of не
появится некоторое значение. И вот тогда корутину возобновить и значение использовать.
Ну, то есть корутина останавливается и хочет быть запущена тогда, когда появится значение. Она
хочет потребить это будущее еще не вычисленное значение. В этом смысле она для нас вполне
вписывается в сущность какую? В сущность ресивера. Корутина это ресивер. То есть это колбэк,
который потребляет значения. Ну, вот когда мы писали с вами фьючи, то вот буквально корутины
и были и были колбэками. Вот можно посмотреть на этот код. Мы подписывались на фьючу и в обработчике,
в колбэке фьюче мы возобновляли корутину, которая потом потребляла вычисленный результат,
возвращала его через await resume. Ну, это у нас такой рукописанный код для корутин,
но вы, надеюсь, понимаете как он выглядит на C++, но в любом случае в домашней вы его напишете. То есть
корутина вполне пока вписывается в нашу сущность. Это, секундочку, это не что иное как ресивер.
Ну, в принципе остальные сущности для корутины тоже вписываются, потому что смотрите, вот что
такое coawait? Когда мы пишем coawait, во что он разворачивается? Coawait разворачивается вот в такой
код. Мы строим объект awaiter, который знает, как дождаться результата асинхронной операции,
и мы, в смысле компиратор, генерируем такой вот вызов. Мы на awaiter вызываем await suspend и
передаем туда корутину. Вот этот awaiter, он знает про вычисление, про то, как значение вычислить,
и он планирует возобновление корутины, получает callback и фактически планирует его запуск. То есть
у нас есть здесь слева некоторое вычисление, объект, который знает про вычисление и про то,
как его дождаться. Справа у нас есть callback, который хочет, простите, потребить результаты
этого вычисления, и у нас есть операция await suspend, которая одно с другим связывает. Ну,
опять, это все удивительно похоже на те сущности, которые у нас есть. Тут параллель не совсем прямая,
но есть некоторые нюансы, за которые можно зацепиться. Но все же, я бы провел такую параллель,
что awaiter в данном случае похож на sender, а submit очень похож на await suspend, который происходит
внутри коя await, и он вот связывает асинхронную операцию и callback корутину. Также как submit
связывает sender, вычисление и receiver, callback, который ждет результаты этого вычисления.
Ну а раз можно провести такую параллель, значит, можно переложить, значит, можно интегрировать
корутины и sender и receiver, а именно можно реализовать оператор коя await для абсолютно
произвольного sender. Ну раз sender вычисляет значения, а корутина умеет дождаться значений,
то почему бы корутине не научиться дожидаться произвольного sender? Когда мы пишем коя await от
sender, то оператор коя await строит объект sender awaiter, который в методе await suspend, получая корутину,
вызывает на sender submit, то есть говорит ему, что вот вычисление стартует теперь, когда корутина
решила его дождаться. И в качестве callback, в качестве receiver передает такой вот вспомогательный
callback, который в методе set value вызывает корутин handle resume. И вот корутина receiver, получив значение,
возобновляет корутину, которая этого значения дожидалась, ну и через await resume возвращает его
из оператора коя await. Вот пример, как корутина интегрируется с двумя sender. Это планировщик
пула, и мы вызываем на нем shadow, и планировщик пула про корутину ничего не знает. И мы здесь
синхронно вычисляем 17, но в этом смысле, конечно, мало, мы просто иллюстрируем, что коя await
интегрируется с произвольным sender, неважно, синхронный он или синхронный. Вот threadpool здесь,
это очень важно. Мы не требуем никакого знания про корутины. Ему это не нужно знать, потому что
связь происходит вот в этом месте, когда мы поддерживаем коя await. Мы с вами интегрировали
корутины и sender-ресиверы, что, видимо, говорит о том, что подход, который мы сейчас рассматриваем
универсальный. Мы уже получили пользу от sender-ресиверов, потому что мы получили
возможность лениво планировать вычисления. Где это мы делали? Вот здесь вот. И все это говорит в
пользу нашего дизайна, но пока есть момент, который мы до конца не разработали. А именно, у нас есть
все же в этом дизайне overhead. Overhead, который состоит в том, что мы выполняем все еще... Смотрите,
когда мы приходили к ленивости sender-ов, мы рассуждали как. Что вот с кодис фьючами у нас
асинкве выполняет сразу два шага. Он и работу в threadpool планирует, и фьюч строит. И в итоге
два этих шага они слиты вместе, и из этого возникает гонка, что подписываясь на фьючи,
мы уже конкурируем с продюсером. Мы разделили два этих шага, то есть построение фьючи, вернее
sender-а, и submit, который запускает вычисления. Но у нас внутри асинкве есть, на самом деле,
еще два слитых шага, которые мы не разделили. А именно, они происходят в методе submit полуопоток.
Ну вот давайте вернемся в наш написанный код. Мы в конце вчерашнего занятия успели перенести
threadpool в новый пример, избавились от всего лишнего, и теперь говорим про планирование карутин.
Вот у нас есть threadpool, вот мы построили по нему планировщик, который строит sender,
который асинхронно вычисляет юниты, и мы отправили карутину в threadpool. Ну то есть мы вызвали
карутину, карутина делает свой первый шаг, и доходит до кое вейта, в нем вызывает shader-shadle,
получает sender, с помощью avator дожидается значение на этом sender, то есть перепланируется
pool потоков, и вот здесь синхронный вызов карутины завершается. Что происходит в этом shader-shadle?
Мы строим sender, от которого потом строится sender-avator, и в этом sender-avator в конце концов
вызывается submit на sender-pool потоков, а sender-pool потоков, как мы уже много раз видели,
отправляет служебную задачку в threadpool, и эта задача вызывает на ресивере, который построен
специально для карутины метод setValue. Я не знаю, у меня лично, когда я это все говорю, мне становится
смешно, потому что слишком много странных слов, которые образуют очень длинные предложения,
но это так и должно быть, потому что мы сейчас находимся на очень поздней стадии курса,
я это еще раз проговорю, и мы сейчас занимаемся тем, что говорим про дизайн, над которым люди шли,
в общем-то, не одно десятилетие, который разрабатывают прямо сейчас, поэтому то, что в нем все слова,
которые мы произносим довольно абстрактные и не имеют физического представления в материальном
мире, ну вот такова наша участь, мы довольно далеко зашли, и сейчас мы зайдем еще дальше,
потому что мы пытаемся оптимизировать вот это место. Итак, что происходит? В конце концов,
когда выполняется эта строчка, в pool потоков бросается задача, которая должна сделать резюм на
карутине, ну вот если там все вот эти промежуточные шаги и всякие возникающие там между, в них
концепции стереть, то в конце концов в tradpool бросается задача, которая резюмит карутину.
Вот, задача для нашего tradpool это функция, то есть буквально объект function. Какие это
последствия для нас имеют? Ну вот здесь происходит, как мы в прошлый раз разбирались,
скрытая локация. Pool потоков хочет выполнять произвольные задачи. Произвольные задачи это,
ну вот, например, какие-то лямбда, а лямбда, мы с вами понимаем, могут иметь разный размер.
Ну вот скажем, у нас есть эта лямбда и эта лямбда, и вот у этой лямбды нет полей, у этой есть, ну,
эта лямбда ничего не захватывает, а это захватывает значение x. Что значит захватывает? Ну компиатра
берет эту лямбду и переписывает ее просто в класс функтор, некоторые анонимные, то есть мы
типа этого функтора не знаем, но, впрочем, можем на него alias поставить каким-то образом,
это не очень важно. Сейчас важно то, что alias классов в одном случае не будет полей, а вот в этом
случае будут поля, будет поле типа int и размер l1 будет меньше, чем размер l2. Ну давайте мы для
порядка запустим пример и увидим, что действительно это так. Вот l2 имеет размер 4 или 1 единица. И теперь мы
хотели бы, ну вот отвлекаясь даже от крутин, сейчас положить две такие лямбды в пул потоков. Вот они
имеют разный размер, поэтому было бы странно положить, ну непонятно, в какой контейнер их
можно было бы положить. Для того, чтобы с этим справляться, мы с самого начала, то есть еще с
threadpool, который мы написали где-то в середине февраля, мы оборачивали в threadpool задачи в std
function. std function это объект, который представляет собой некоторую функцию, которую можно выполнить,
вызвать с помощью оператора круглые скобочки. Но польза function в том, что этот объект стирает тип,
конкретный лямбда, который он внутри себя держит, конкретного функционального объекта. И этот
function стирает тип и имеет фиксированный размер, а значит этот объект уже можно положить в контейнер,
ну в какой-нибудь привычный нам дек. Каким образом этот function устроен? Вот на этом мы в прошлый раз
остановились. Мы сказали, что как сделать объект function некоторого фиксированного размера. Ну нужно
видимо лямбду, которую мы получаем в конструкторе, переложить на кучу. Для этого мы написали
вспомогательный класс function storage, который просто хранил этот функтор, функциональный объект, и вот
двигали его туда. Ну тут нужно более аккуратный код написать, конечно, но мы понимаем, что это
просто для упрощения нашего рассказа. Мы передвинули этот объект на кучу и вроде бы нам в самом объекте
функцион достаточно хранить просто указатель на этот storage, но не совсем понятно какого
типа указатель должен быть, ну то есть на какой объект он должен, на объект какого типа он должен
указывать. И тут мы говорим, что ну почему бы не работать с этим function storage polymorph,
почему бы не иметь некоторый общий указатель на интерфейс invocable. Вот он объявлен.
И function storage для конкретного вот некоторого уникального типа лямбда, некоторого уникального
типа функционального объекта, будет этот интерфейс реализовывать и в методе invoke вызывать этот
самый f, который он хранит. Тогда мы можем алоцировать этот function storage на куче и сохранить
этот function storage видя pointer на интерфейс invocable. А дальше в операторе круглые скобочки через
интерфейс polymorph вызвать оператора круглых скобочки на конкретном функциональном объекте
конкретного неизвестного нам типа. Вот эта техника называется type erasure, то есть у нас в функции
спрятан стерт тип этой лямбды и мы с ней в конце концов работаем прямой. Отлично, это просто мы
разобрали механику, теперь мы понимаем где здесь, ну где в threadpool, где в методе submit возникает
overhead. Overhead относительно чего? Относительно идеального решения, который выглядит вот так.
Если мы хотим класть в threadpool задачи, которые в конце концов резюмит корутины, то можно было
бы поступить эффективнее, потому что когда корутина планируется в threadpool, она дожидается на
некотором объекте awaiter и этот awaiter ну просто самим компириатором инлайнится в поле корутины.
Мы с вами это все проходили неделю назад, мы писали развертку кода, который генерирует
компириатор для всех этих корутин, он выглядел примерно так, ну и вот awaiter становился полем класса.
Возвращаемся на картинку и если мы теперь в awaiter сделаем поле next, то есть awaiter сделаем
узлом интузивного списка и в awaiter положим handle корутины, которая хочет запланироваться в
pool потоков и свяжем эти awaiter в список, то мы фактически свяжем сами корутины в список и у
нас получится такой интузивный список корутин внутри пула поток. Обращаем внимание, что нам
не обязательно опять писать pool потоков, которые знают прямо про корутины, потому что прямо в
домашней работе вам говорят интегрируйте ваши корутины с пулом потоков, интегрируйте,
но не то что ваши корутины, корутины C++ с вашим пулом потоков без оверхеда,
а воспользую этот факт, что pool потоков поддерживает интузивность. И вот смотрите,
какова наша цель на сегодняшнюю встречу. Наша цель написать код, уточнить, улучшить,
атомизировать еще больше наш дизайн сендеров и ресиверов, чтобы с помощью него можно было
планировать, чтобы threadpool работал по-прежнему только сендер, чтобы threadpool по-прежнему
строил только сендеры и ничего не знал про корутины, но при этом, когда бы мы интегрировали
корутины с пулом потоков через сендеры, вот через эту прослойку, мы все равно имели бы
возможность сделать так, то есть получить интузивность и избежать лишних локаций памяти.
Вот это наша цель. Я с тебе еще позволю маленькое отступление, раз уж я этот функцион написал,
я обращаю внимание, что std function совершенно не обязательно делает динамическую локацию каждый
раз, потому что если у вас объект f маленького размера, то в принципе мы можем здесь завести
небольшой буфер и сделать placement new, то есть алоцировать этот function storage прямо в самом
объекте, то есть не обязательно динамическую память использовать, но это оптимизация для
маленьких объектов, так же как вы можете там, не знаю, вообразить себе оптимизацию векторит для
маленьких векторов, но в общем случае это динамическая локация и мы хотим в общем случае от нее абсолютно,
в общем случае от нее избавиться для корутины. И тут нужно вспомнить, а как мы избавлялись от этой
динамической локации в файберах, но вернее, если вы избавляете динамической локации в файберах.
Ну я начну с обратного, с ответа, а потом объясню как он получился. Вот мы написали этот
function, этот объект function, внутри есть этот invocable, у которого есть invoke и через него мы вызываем
функцию. А теперь посмотрим на задачу, ну или планировщика, или стеклоскорутина. В ней вам
даны экзекутеры, которые нужно, в которых нужно работать уже с инкрузивными задачами. Экзекутер,
который принимает уже taskbase, а taskbase — это наследник itask. Ну вот смотрите, когда мы говорим
про пул потоков, когда мы говорим вообще про произвольный экзекютер, то мы пытаемся сейчас
разделить две задачи. Собственно планирование задачи в threadpool. Давайте я еще раз покажу место,
которое нас волнует. Вот здесь происходят два шага, и отсюда берется неоптимальность. Первый
шаг — мы берем некоторый ресивер, конкретный тип, и обворачиваем его в std function. В сигнатуре submit
это заворачивание происходит. Происходит динамическая локация, мы стерли тип. Вторым шагом мы
планируем в данном случае через ресивер карутину в пул потоков. То есть стирание типа с динамической
локации — раз. И два — это планирование задачи. И для произвольных лямп для произвольных ресиверов
наверное это нужно. А вот если ресивер является карутиной, это не нужно, потому что карутина сама
уже живет на куче. Поэтому мы можем разделить два этих шага. Мы можем сказать, что пусть операция,
которая запускается в пуле потоков, вот пусть ее состояние управляется снаружи пула. Вот собственно
здесь мы так поступаем. Мы говорим, пул потоков не знает, где живет сама задача, в смысле в какой
памяти она живет. Мы лишь получаем указатель на объект, который реализует интерфейс itask и
может запуститься. То есть мы сами не занимаемся локацией объекта, который хранит задачу. Ну там
какую-то произвольную лямпу с какими-то полями. Понимаете меня сейчас? Вот нам нужно, чтобы
где-то задача жила. Задача, вот в общем случае, это например лямпда, какое-то замыкание, у которого
есть какие-то поля. Вот этот объект где-то должен жить. И он должен дожить до того момента, когда
задача запустится. Вот в текущем дизайне, вот в таком наивном, мы обеспечиваем это сами. Мы
принимаем лямпду произвольную и сразу упаковываем ее, вот здесь мы принимаем лямпду и сразу упаковываем
ее в task, то есть переносим на кучу и сами гарантируем, что она доживет до момента старта, до момента
исполнения. Но возможно, не всем задачам это нужно, потому что остановленная корутина, которая
хочет попасть в пул потоков, она разумеется доживет, потому что пока она находится в пуле потоков,
она не исполняется, она же остановилась. Или скажем файбер, та же самая история. Файбер хочет
дождаться мютокса, вот он остановился, пока мютокс захвачен. Нам не нужно алоцировать некоторое
состояние на куче для этого остановленного файбера, потому что файбер уже живет на куче и он не
исполняется, пока его не запустят снова. Вот если он блокируется на мютоксе, то нам немного не туда ушел.
Вот не знаю, просто файбер сделал yield, вот он остановился и он не начнет работать, пока его не
запустит в пуле потоков. Вот сам файбер мог бы быть задачей, сама корутина могла бы быть задачей,
потому что и файбер и корутина живут на стеке. Но я напомню, что файбер мы сами на куче алоцировали,
а корутина на куче алоцирует, ну так скажем, компириатор, когда он не понимает lifetime этой
корутины, он ее state алоцирует с помощью оператора нее и дальше мы в конце корутины себя разрушаем.
Вот мы этот факт пока в пуле потоков никак не используем, а могли бы, и вот поэтому мы разделяем
в интрузивности два этих шага. Аллокация, слишком много примеров, аллокация стейты для задачи и
submit, то есть планирование задач на исполнение. Вот мы говорим, что пусть экзепьютер не отвечает
за это, пусть пользователь беспокоится о том, чтобы задача конкретная дожила до момента запуска ее в
пуле потоков. Вот, и ровно поэтому у нас есть такая вспомогательная функция execute для лямд. Что она
будет делать? Вот она будет делать ровно то же, что делает function. Вот буквально то же самое, вот
буквально то же самое. То есть мы должны будем в этом, в этой функции execute для лямды алоцировать
некоторый function storage, который реализует интерфейс itask и в методе run вызвать объект f. Ну то есть
мы буквально должны внутренности от функшена написать руками в этом execute. Выглядит странно,
зачем мы переписываем реализацию функшена за тем, что для лямд это нужно, а для файберов и для
корутин это не нужно. Понятен замысел? То есть мы даем возможность пользователям, которым не
нужно это заворачивание в функцию, не нужно это искусственное продление жизни, гарантии продления
жизни, не нужно management lifetime не получать overhead. Для лямд этот overhead необходим, а для файберов и
корутин нет. Поэтому мы трансформируем API экзекьюторов, полопотоков, разделяем два этих шага.
Аллокацию стейта задачи и собственно планирование задачи. Вот такой замысел в конце концов стоит за
интрузивностью в нашем курсе. Вот наша задача с самого начала к этому готова. Вот с момента,
кажется, корутин, с момента задачи корутина, где это в первый раз может потребоваться,
где возникают файберы, которые от интрузивности могут извлечь пользу. Ну и вы в принципе сразу
же во всех задачах могли бы этим пользоваться. Вот ровно поэтому вот еще отсюда, давайте я найду
пункт, где-то он был. Да, именно поэтому мы перестали вызывать метод submit на тратпуле напрямую,
мы вызываем такую вспомогательную функцию. И вот эта функция, она будет делать динамическую
локацию, а запуск файбера вот здесь не будет делать динамическую локацию, хотя будет вызывать метод
submit на пулья поток. Вот разница. А теперь мы бы хотели, вот если все это понятно, если не понятно,
то самое время спросить, потому что и задача с таковской корутин, и задача про планировщик
требует реализации интрузивности. Поэтому если вот сейчас не понятно, то лучше пользоваться моментом.
Ну хорошо, раз понятно, тогда возвращаемся к нашей исходной цели. Мы хотим поддержать вот такую
возможность пользоваться интрузивностью для, ну в случае фреймворка сендеров и ресиверов. Ну то есть
у нас есть тратпул, у нас есть корутины, и корутином может быть интрузивная задача для пулопоток.
Загостка в том, что теперь между тратпулом и корутиной есть объект sender. Вот эту проблему мы
сейчас и решим, уточнив наш дизайн. Вот мы скажем, что наша операция submit, она не годится,
потому что она на самом деле получает какой-то ресивер и должна в, должна обеспечить тот факт,
что должна отправить этот ресивер в конечном счете в sender пулпотоков. И sender пулпотоков
обязан продлить жизнь этому ресиверу, где-то его сохранить, управлять его storage. Мы скажем,
что эти два шага нужно разделить, и вместо функции submit мы сейчас напишем две другие функции. То есть
мы этот шаг submit разделим на два. Мы напишем функцию connect. Эта функция будет возвращать,
ну она будет вызывать как обычно sender connect ресивер, и замысел ее такой, connect должен построить
новую сущность в нашем дизайне. У нас есть sender, это представление вычисления, у нас есть ресиверы,
это callback, который ожидает результаты вычисления, и у нас есть shader, это объекты, которые строят
sender. Вот мы добавим к ним еще одну сущность, которая называется operation state. Вот она. Operation
state это объект, который представляет собой хранилище для асинхронной, объект, который представляет
собой, материализует асинхронную операцию. И вот его уже можно отправить sender для выполнения.
Точнее не так, все переврал. Operation state это вот, давайте, дайте мне еще один шанс. У нас есть sender
и ресивер, и вот что такое submit логически? Мы связываем sender и ресивер и запускаем вычисления.
Я об этом всегда так и говорю, как бы в два шага. Вот я сейчас хочу отдельно связать sender и ресивера,
а потом запустить вычисления. В случае threadpool'а, что это значит? У меня есть ресивер, это фактически
лямбда, которая вызывает routing handle resume, и у меня есть sender, это класс, который хранит ссылку на
пул потоков. Где же он? Секундочку, вот он. И я хочу их связать. А что значит связать? Ну я хочу
на самом деле построить интузивную задачу для пул потоков, вот что я хочу. Я хочу, чтобы мой
пул потоков стал лучше. Мне он не нравится, он неэффективен. Я хочу написать, я хочу вместо
task'и написать itask и хочу, чтобы мой пул потоков занимался выполнением этих itask. Когда я
планирую задачу, я получаю pointer на itask. Сейчас мы перепишем и все станет понятнее. Ну я не хочу
дек, конечно, иметь, я обойдусь просто односвязным списком. Когда я делаю submit, ну я пишу, конечно,
manual executor, если вы понимаете, что это. Ну смотри, мы не хотим, чтобы планировщик заботился о
времени жизни лямбды, которую он исполняет. Мы хотим, чтобы была снаружи некоторая задача, и пусть сам
пользователь заботится о времени ее жизни. Пусть сам пользователь заботится о том, чтобы задача
дожила до исполнения. Если мы говорим про файбер, то файбер пока он планируется, он точно не разрушится.
Ну просто потому, что он не работает, пока он в планировщике. Когда он запущен, тогда он может
разрушиться. Ну вот, так что мы переносим проблему управления временем жизни задачи пользователю.
Пусть он об этом беспокоится. А мы будем просто принимать itasks, ну или даже чуть аккуратнее
taskbase, который наследует itask, и внутри у него еще есть pointer next для того, чтобы задачи связывать
списки. В методе submit я должен задачу, которую дал мне пользоваться, привязать к своему списку.
Вот, кажется, я написал вставку в односвязанный список, если я не ошибся. Похоже на то. Ну и здесь
я что буду делать. Я буду исполнять все задачи. Ну вот, такой примитивный код, но в этом месте вы
можете представить себе какой-то сложный планировщик, шардированный с локальными очередями. То, о чем мы
говорили не так давно. У меня такая наивная реализация, и в методе submit, ну метод submit придется
переписать, но вообще-то я метод submit закомментировал, мне он уже не нужен. Мне нужно, чтобы, давайте я
напишу, что я хочу, наверное. Я хочу, чтобы пользователь, когда он хочет положить задачу в
пул потоков, давайте корутину спрячем. Корутина это довольно сложный пример. Я хочу следующего. Вот у
меня есть stratpool, и чтобы в него что-то запланировать, я должен построить сначала планировщик. Вот построил
планировщик. Допустим, я хочу запланировать в нем исполнение лямбда. Давайте назовем ее просто l,
а может быть и не будем их называть. Я хочу следующего. Я хочу иметь операцию. Сначала я
получаю sender, который представляет собой вычисление в пуле потоков, вычисление юнита,
а дальше я просто вызвал, дальше у меня есть receiver, который юнит потреблял. Значение его не
интересовал. У юнита всегда одно значение. Вот и синхронный receiver. И дальше я вызывал
обычно submit sender receiver. Связывал sender receiver и планировал задачу в пул поток. Делал два шага,
вот даже просто я произношу и говорю там что-то и что-то. Теперь я делаю два отдельных явных шага.
Я сначала говорю, что я связываю sender и receiver, а потом уже я говорю start операции. В чем замысел?
Если мы говорим про пул потоков, то для пул потоков вот такого эффективного нам требуется
иметь инклюзивную задачу. Она должна жить снаружи. Операция в случае конкретного sender
это будет объект, который реализует интерфейс itask. И вот я его здесь построил и вот у меня
объект есть и теперь я сам должен позаботиться о том, чтобы он дожил до момента запуска в пуле поток.
А вот здесь я просто стартую операцию, но видимо бросаю ее в пул. То есть вот эта
операция в данном случае это будет видимо реализация интерфейса task.
Ну а дальше, если я хочу, чтобы она прожила долго, я ее на кучу переложу. Если я знаю,
что скажем она доживет до времени своего исполнения, ну вот здесь вот так вот. То есть я
заблокирую, я сначала выполню все задачи, а потом выйду из кулопа. То есть здесь мне достаточно,
чтобы операция жила на стеке. То есть я не обязан даже лямбду на кучу перекладывать здесь,
потому что я знаю, что она доживет в момент своего исполнения. Замысел ясен?
Ну вот, то есть я здесь могу сэкономить даже для лямбд в таком дизайне, когда я понимаю,
что я синхронно дожидаюсь задач. Ну а для корутин и файберов уж тем более.
Вот, операция start, она будет будет тривиальной, если у нас есть теперь некоторая операция. Это
тоже некоторые неизвестный нам тип, потому что операция для каждого сендера будет своя. Для
threadpool'а это будет реализация интерфейса task, itask. Для какого-то другого пула она может быть
вот чем-то другим. И я здесь стартую операцию. Здесь ничего интересного.
И давайте теперь напишем сендер для пула потоков, который строит уже что-то,
которое умеет уже коннект делать. Да, у нас, кстати, поменялись концепты, теперь я хочу
коннект. Давайте я немного срежу угол. Я вот читал лекцию в шаде в начале недели, и мы там писали
сендер для... Я забежал вперед, извините. Смотрите это из своей памяти, пожалуйста. Давайте
напишем сендер для пула потоков. Нам теперь не нужен метод submit, нам нужен метод connect,
который что-то возвращает. Он получает ресивер и должен из него сделать задачу, объект задачи,
временем жизни которой будет управлять сам пользователь. Ну вот в терминах нашего
фреймворка это operation state. Вот мы так его назовем. И временем жизни этого operation state будет
управлять пользователь, поэтому мы назовем его manual operation state. Вот, мы такую штуку должны вернуть.
Для конкретного ресивера. В этом manual operation state будет жить ресивер. Ресивер,
который хочет в пуле потоков запуститься и получить оттуда юнит. И вот этот manual operation
state я должен в методе start потом уметь запустить. Поэтому, видимо, я должен сохранить ссылку на
полпотоков и сделать вот так. И я должен наследоваться от... То есть я хочу построить
задачу для лямбы. Ну, для ресивера вернее. Вот задача. Вот она и будет задача.
Нам нужен конструктор.
Нам нужно знать protrude pool и нужно знать ресивер. Почему-то все в обратном порядке получилось.
Так, что нам... Ну, не нам, что комператору здесь не нравится. Простите, у нас довольно много IDE.
А, но я не написал метод run, конечно же. Я строю задачу, а у задачи должен быть метод run. И в этом методе мы
подарим ресиверу этот самый вычисленный юнь.
Так. Правда ли, что я написал код? Или я что-то упустил? Давайте проверим.
Start реализован. Connect реализован. И connect для
полпотоков.
Медленный компьютер. Connect для полпотоков реализован. Ну, попробуем. Если не скомпедируется, то будем разбираться.
Так, ну тут много всяких бесполезных сообщений выводится. Давайте... Вот так.
Здорово, все работает. Все работает, причем смотрите как удивительно. Мы вот на уровне
этого сниппета оперируем максимально общими сущностями. Shader, Sender, Receiver, OperationState, Connect.
Ну, то есть вот мы используем большую часть этого словаря. Словаря концептов. Design execution.
Мы сделали очень много маленьких тамарных шагов. И что мы получили? Мы получили возможность запустить
задачу в пуле потоков, не выполнив ни одной динамической аллокации памяти. Потому что в
пуле потоков динамических аллокаций нет. Потому что пул потоков работает только с интрузивными
задачами. Тут нет контейнеров динамическими аллокациями. Тут нет функций, которые баллоцировали
память при стирании типа. Мы в Submit получаем Pointer, провязываем его в список через поле Next,
которое встроено в объект задачи. Вот. Ну и тут мы вручную вызываем функции. Ну, представьте
себе потоки Worker, которые зовут Run, доставая там задачи из какой-то очереди. Опять это все
вообразимо. То есть, в пуле потоков в самом динамической аллокации нет. И она не требуется даже
снаружи для лямбды. Потому что мы здесь знаем, что операция доживет до момента вызова RunTasks. Ну,
то есть, ну представьте, что мы здесь написали Start, а потом написали ThreadPool WaitIdle. И вот, то есть,
этот код гарантирует, что операция доживет до момента своего исполнения. И используя этот факт,
мы получили возможность сэкономить аллокацию для самой лямбды. То есть, фактически, что мы сделали?
Мы здесь сделали, мы понимаем, что лямбду на куче аллоцировать не нужно, и мы аллоцировали ее на
стейке. Ну, мы, вот давайте вернемся к этому FunctionState. Где я его писал? Вот здесь. Мы фактически
поняли, что FunctionStorage можно аллоцировать на стейке. И аллоцировали его здесь. То есть, можно,
в принципе, про все эти оптимизации говорить вне контекста сендеров и ресиверов. Тут важно, в данный
момент важно не это. Но к сендерам и ресиверам это имеет прямое отношение, потому что вот можно
все эти задачи в ThreadPool и вообще разговоры про ThreadPool, про все вот это обобщить и говорить про
сендеры, ресиверы и операции. И почему? Потому что теперь можно, используя вот эту идею, написать
хороший авейтер для корутины, который позволит ей перепланироваться в пул потоков без динамической
локации. Давайте я немного упрощу себе жизнь, потому что писать общий сендер я не хочу. Это
можно сделать, это будет просто немного сложнее. Больше головной боли, а суть продемонстрирует
то, что важно. Добавится больше деталей и отвлечет нас от того, что важно. Я хочу написать сейчас
оператор CoAv8. Не для произвольного сендера, фундаментальной проблемы здесь нет, такой написать,
а для конкретного сендера, для пула потоков. Это будет проще, потому что я знаю, что он возвращает
юнит и от знания конкретного типа мне будет немного легче жить, только и все. Нужно еще name
space закрыть. Что-то пошло не так, сейчас буду разбираться. Ну да, я понимаю, что хочу писать. У
меня есть name space с деталями реализации, у меня есть там CoAv8.
Сложно во всем этом говорить, столько абстрактных слов. Я-то еще себя понимаю,
вот какого вам я даже не представляю сейчас. Но тем не менее мы доведем работу до конца. Мы пишем
о вейтера, который сможет дождаться вычисления юнит в пуле потоков, то есть перепланировать
коротину в пул поток. Пишем о вейтер, ну и тут обычная рутина, мы пишем await radio, мы пишем,
вот да, в этом месте я себе немного упростил жизнь, await resume, который ничего не делает,
потому что я знаю, что мы возвращаем юнит в случае конкретного такого сендера. А теперь я хочу
написать await suspend, получить здесь коротин handle для коротины и запланировать его возобновление.
А у меня есть сендер для пула потоков. Как мне поступить здесь? Что я хочу? Я хочу алоцировать,
во-первых, я хочу построить ресивер. Сейчас я подумаю, нужно мне это делать или нет. Давайте
явно напишу, у меня будет ресивер для коротин handle.
И в... нужно мне это делать или нет. Так, решаю проблему по мере необходимости. У меня есть ресивер,
который будет резюмить коротину. Ну вот, я построил какой-то объект сейчас, ну то есть
у меня есть некоторый объект такого типа, у которого есть метод functor-receiver, у которого есть...
ну где-то я себе код сломал, ладно, потом... у которого есть set-value, set-error, set-done.
И я хочу, во-первых, сказать вот это, сендер,
connect, receiver. Вот получить операцию, то есть вот этот объект, который в случае threadpool-сендера
будет представлять из себя что. Тут, кстати, можно перейти, а тут не шаблонный, вот уже получается
конкретный тип. Построит мне manual operation state, который реализует интерфейс таски. Вот, и я хочу,
чтобы этот объект дожил до момента запуска задачи в пуле потоков. Ну, здесь он не доживет,
потому что вот я его построил на стейке этого вызова, вот я стартовал операцию, то есть бросил
эту операцию по поинтеру в threadpool, а дальше вызов завершился, операция разрушилась, не годится.
Но я знаю, что avator, он будет жить в поле крутины, поэтому если я сохраню этот объект операции в
поле avator, то я гарантирую, что объект операция доживет до момента запуска крутины в пуле потоков
через интерфейс itask. Хорошо, нужно это сделать, но для этого нужно знать type name для вот такой
операции. Да, вот именно поэтому мне нужно написать все-таки класс Receiver явно.
Receiver для крутины. Ну, сложно его написать.
Вот это мы оставим светлым в будущем. А нам value type еще не нужно или это для серии? Value type он
в sender, sender объявляет, кого он вычисляет. А дальше, когда мы их коннектим, то просто у нас
программа не скомпилируется, если у Receiver не будет set value с value type, который вычисляет sender.
То есть value type выявляет тот, кто вычисляет это value, это sender, а Receiver просто получает,
вот он в сигнатуре объявляет, что он получает. Понятно, да? То есть тут объявление value type
для Receiverа есть, оно вот тут находится. А теперь я могу объявить, что же будет operation state.
Конкретный тип. Это thread pool, manual operation state от Cora Receiver. Ура! И теперь я могу,
теперь я могу сделать следующее, кажется. Я могу завести еще одно поле, но тут,
простите, какой-то корд очень неупорядочный, но он пишется так спонтанно. Теперь я могу сохранить
вот эту операцию в поле овейтера, написать, все это стереть, написать здесь connect Cora Receiver от H
и положить результат в поле. Смотрим. Ура! И теперь уже я могу сказать start. Ну, стрелочка,
потому что option у нас завелся. Ну и ладно, я могу даже написать, где у меня, в каком порядке все это
объявлено, в правильном. Могу написать теперь вот так. Ну что, мне кажется, что я написал все,
нужно теперь проверить, что работает и прокомментировать, что случилось еще раз.
Корутина. Трэдпул. Шедулер. Вызываем Cora. В ней видим шедулер-шедул. Получаем сендер.
Строим по нему овейтер. В этом овейтере, в овейтсаспенде строим Receiver, который будет
возобновлять корутину. С помощью коннекта мы строим объект. Ждем, ждем, ждем. Строим объект
manual operation state, который реализует интерфейс задачи. Сохраняем его в поле овейтера, а овейтер
является полем корутин стейта. И после этого наконец стартуем задачу. И давайте посмотрим,
что нам все удалось. Да, было очень наивно рассчитывать, что мы уложимся в одну пару в
прошлый раз. Это была большая ошибка. Простите. Ну, блестяще. Мы написали код и да, непонятно,
что мы исполняемся в пулепоток, правда. Но вот давайте мы напишем здесь немного помощи.
Действительно, пулепоток исполняет теперь эту корутину.
Ну что ж, грандиозно. Смотрите, почему грандиозно. Потому что теперь в этом коде,
ну вот в этом коде и вот в этом коде нет ни одной явной динамической локации. То есть мы смогли
запустить корутину в пулепотоков. Мы знаем, что она, ну мы смогли запустить корутину в
пулепотоков. Мы воспользовались интрузивностью тредпула, но при этом мы отделили корутины от
пулепотоков с помощью вот такой прослойки сендеров и ресиверов. Ну вот прямо скажем,
в последнем шаге вот какого-то большого смысла, ну не то что большого смысла нет,
разумеется он есть. Это скорее препятствие. То, что мы сейчас сделали, вот это было препятствием
для нас. Но результат получился чертовски разумный. Объясняю еще раз. Мы с самого начала решили,
ну вот с самого начала прошлого занятия решили, что каким-то образом все наши вычисления,
вот любые наши вычисления мы можем представить себе с помощью, выразить с помощью такого
словаря. Сендеры, вычисления, которые что-то вычисляют, ленивые. Ресиверы это колбэки,
шедулеры это объект, который строят сендеры и operation state это материализация вот асинхронной
операции, которая связывает сендеры и ресиверы. Вот максимально абстрактные слова. И что мы
показали? Мы показали, что на них можно переложить, ну да в общем-то все подряд можно переложить.
Можно писать синхронные вычисления, можно написать асинхронные вычисления, можно комбинировать
вычисления. И можно интегрировать все это с корутинами, потому что вот есть такое соответствие.
Можно так поставить. Да, кстати, можно теперь написать к чему соответствует operation state в случае
корутин. Это корутин state. Вот этот самый объект, который живет на куче. Мы в корутин state inlinem
объект operation state. Собственно вот мы здесь это и сделали. Вот-вот-вот-вот здесь. То есть
наш словарь претендует на универсальность, потому что мы можем какие-то произвольные вычисления
писать. Причем мы можем даже писать их оптимальнее, чем раньше, за счет того, что мы атомизировали
отдельные шаги. И мы можем интегрировать это с корутинами опять без верхета. Видимо это доказывает,
что наш дизайн очень разумен, очень логичен. Ну просто вот он хорошо описывает любую реальность,
корутинную, некорутинную. Да, вот тут еще больше абстрактных терминов. Но это не удивительно,
потому что мы взяли простую операцию, вот такую. Вот сейчас давайте мы вернемся к примеру с
фьючами. Вот такую операцию, которая делает три вещи разом. Оборачивает лямбду в функцию,
бросает ее в пул потоков и возвращает фьючу. Вот три шага были сделаны разом,
поэтому были сделаны не оптимальны с разных позиций. Сейчас мы сделали все шаги отдельно.
Мы представили вычисление, мы алоцировали для него стейт и вручную им управляем. И только
потом мы сделали сабмит. Мы представили будущее вычисление с Эндером, мы алоцировали для него
состояние и мы стартовали. Вот мы три шага выполнили отдельно. И за счет того, что мы... Да,
для этого потребовались новые слова, ну потому что много шагов, много приручных объектов стало,
но зато мы получили возможность для очень тонкого управления всем происходящим. То есть
в этом смысле мы не придумывали ничего нового, мы просто подобрали слова для того,
чтобы описывать все промежуточные шаги. В этом смысле дизайн совершенно не удивителен и в
каком-то смысле не избежен. Мы просто зафиксировали реальность. Но тем не менее, это вот стоило
сделать. Это делается плюс-плюс только сейчас. Да, делают рано или поздно, надеюсь.
Наверное стандартизируют, это уже страостепенный вопрос. Но вот библиотеку пишут, ну или написали
уже в какой-то степени значительной, она называется Libionifex Unified Executors. Можно на нее посмотреть,
можно с помощью нее попробовать что-то писать. Возможности там гораздо шире, чем мы обсуждали,
потому что должна быть поддержка для потоков данных асинхронных, не только для просто
вычислений данных. Должна быть поддержка для отмены, должна быть поддержка водо-вывода-времени,
чтобы общаться с внешним миром. Ну вот это все в любом случае должно быть вписано в framework
on currency. Мы про это все мало говорим, все же у нас не хватает на все времени. Ну а вот в основе
те сущности, которые мы описали. В общем, можно пользоваться, можно попробовать руками это подрогать.
Ну что ж, на этом пожалуй и на сегодня все. В смысле, я выполнил поставленную самим
собой перед собой цель. Рассказал вам про sender и receiver. Кажется, попытался связать их
с корутинами, с интрузивностью. В общем, все, что мы в курсе наблюдаем, это все связано. И вот мы,
почти что уже до конца достроили нашу большую-большую картину, в которой очень-очень много теперь деталек.
И наша задача их осмыслить и дописать задачи, которые у нас вот сейчас есть. И планировщик
быстро дописать, и корутины дописать. И вот я в начале недели, в середине недели выложу future.
И вот за май, дописав все вот эти задачи, мы, кажется, сможем почувствовать, как все эти запчасти,
как все эти детали могут друг с другом взаимодействовать, сочетаться друг с другом,
не противоречить друг другу. Это все очень нетривиальная задача. В смысле, связать это все вместе.
Ну, кажется, что мы к этому сейчас близки. Ну что ж, да.
Вам не кажется вообще, что стоит так же написать простой интерфейс для пользователя?
То есть, условно говоря, чтобы он мог сделать tp create от количества подоков,
а потом просто закидывать в threadpool lambda? Ну, если он так будет делать, смотри,
такое интерфейс у нас уже был с самого начала, да? Мы с него начали. Нет, ты справедливо говоришь,
что у нас есть вот такой интерфейс, где все по шагам, но если пользователю это не нужно,
если он ленивый, если он не хочет оптимизировать ничего, то давайте сделаем для него просто вот,
ну, я не знаю, какой-нибудь грубный метод submit в threadpool, да? Ну да, можно выразить по-прежнему
submit sender. У нас был sender receiver, да? Мы можем его оставить. Ну, то есть, для этого мы в sender
должны поддержать и submit, который не будет перекладывать управление lifetime storage задачи
на пользователя, а разместить на куче. То есть, смотри, ты справедливо говоришь,
можно это прямо сейчас и сделать. Ну, то есть, можно написать здесь в sender еще один метод,
ну, точнее вернуть старый или можно его по-другому назвать. В общем-то, это делается точно так же,
как мы. Ну да, да, да. Это, наверное, просто дополнительные методы или перегрузки старых.
Ну, то есть, можно промежуточные шаги вскрывать. Вот, и можно сделать следующее. Мы лоцировали
эту штуку на кучу, мы говорим threadpool, как у нас там назывался, submit. Ладно,
давай я напишу тут. Писать-то еще 30 секунд. Тем более, я себе время сэкономлю и скопирую.
Threadpool нам не нужен. И я в методе run сделаю что? Ну, продиктуй мне, если ты все понимаешь.
Что? А, да, спасибо. Что я напишу в run? Вот, я уже лоцировал объект на кучу. То есть,
я говорю, что пользователь, не заморачивайся с тем, где хранить operation state. Я сам лоцирую
на кучу, а когда задача завершится, я сотру его. Вот, и теперь я могу еще написать
вспомогательный метод spawn, который будет избавлять пользователя от необходимости думать
про operation state. Ну, надеюсь, что нигде не ошибся. Сейчас можно это быстро проверить. Да,
я не хочу так делать. Сложно слишком, поэтому я говорю spawn sender receiver. У кого-то микрофон,
пожалуйста, заметьте себя. Тут стоит кое-что другое отметить. Что в std execution,
что в libunifex, там есть некая философия про то, что пользователь конечный, который пишет
бизнес логику ассинхронную, он вообще не должен знать ни про operation state, ни про receiver,
ни про что. Он знает только про sender, что-то, что их производит, и различные функции,
комбинаторы для их трансформации, типа when. Можно when all написать. В качестве заводов,
сендеров у нас дредпул, то есть любой шеддлер. Сокеты могут быть заводами сендеров, делать
сендеры, в которых появляются данные, когда они пришли в сокет, ну и так далее. В конечном
итоге получается интерфейс такой же, как у фьюч. Ну да, это совершенно верно. Так смотри,
вот пример с корутиной, он же это и демонстрирует. Мы просто пишем корутино, в нем говорим
кое weight, shader, shadle, и внутри все эти сендеры, ресиверы есть, а в коде их нигде нет.
Ну это пример на корутинах. Если мы пишем другой код, то там та же самая история. Ну и с фьючом
я это говорил, что если мы пишем код на фьючах, то промесов нигде не возникает. Промесы — это всякая
внутренняя инфраструктура. Ну, замечание очень хорошее, справедливое. Да, давай мы это еще раз
проговорим, что вся эта механика, она используется некоторой инфраструктурой, в которой пользователь
пишет свой код, но она пользователя большей частью скрыта. То есть, редко когда пользователь будет
писать вот прям вот так все голыми руками. Мы сейчас это пишем, потому что мы хотим проиллюстрировать
эту механику, то есть за счет чего достигается оптимальность. И иллюстрируем, что оптимальность
достигается с помощью корутин. Вот, но в корутинах никакого сложного кода нет. Мы получили планировщик,
сделали коэвейт на планировщике, и вот автоматически все получилось оптимально.
Вот это то, что, то что видит пользователь. А под капотом работает вся эта машинерия,
но вот она работает, обеспечивает оптимальность, то есть через нее можно все оптимально выразить,
но в прикладном коде этого всего быть не должно. Но даже если мы хотим работать как-то более-менее
прямой линейно с этим всем, то можно писать себе какие-то вспомогательные шорткаты,
которые вот все равно все это скрывают. И еще тут может встать закономерный вопрос,
я удивлен, что никто его не задал, хотя, наверное, не удивлен. Авейтер, ну или точнее сказать,
какой-нибудь awaitable, типа task, который можно коавейтнуть и получить там авейтер и дождаться
да можем ли мы его превратить в sender? По-моему закономерный вопрос, ну я сам на него отвечу,
да можем, но очень интересен вопрос как, потому что этот awaitable, task или еще что-либо,
он может нам к нам прийти из другой библиотеки, а другая библиотека уже написана и менять мы ее
не можем. Соответственно, то, что мы здесь разбираем, это типа минимальный в простоте пример
всего этого, а в жизни нужно немножко все усложнить, чтобы была возможность поддержать какие-то штуки из
других библиотек, которые тоже хочется объявить с sender. Ну и, так сказать, вопрос на подумать,
чем кто заинтересован, а лучше погуглить, как это сделать? Вообще, замечание чертовски правильное,
потому что если мы пишем что-то максимально абстрактное, да, ну то есть оперируем какими-то
такими абстрактными сущностями, то, разумеется, чтобы потом можно было на них плавно перейти в
любом промышленном козе, нам нужно иметь возможность сочетать наш framework, ну вот просто уже с внешними
библиотеками, которые какую-то функциональность реализуют, поэтому мы хотим, чтобы связи было
поменьше, чтобы не нужно было менять объявления, менять типы, которые мы используем, которых мы
дожидаемся, в частности, в корутине. Ну вот, по счастью, здесь все довольно декомпозировано,
не то что довольно декомпозировано, и нам не нужно знать про конкретные особенности реализации,
нам нужно иметь какие-то концепты, ну и адаптеры для них, в общем-то, и все. Ну,
мой поинт скорее про то, что мы сейчас говорим, что sender должен иметь метод connect, так? Вот,
а как мы метод connect допишем в другую библиотеку? Мы его не допишем. Ну а что мешает адаптер написать,
я пока не понимаю в чем фундаментальная сложность. А неудобно, тогда придется фасад для
всей библиотеки писать. А вот авторы STD execution умудрились сделать так, что этого делать не
нужно. Не нужны адаптеры, не нужны фасады, просто много хитростей, вот, которые я предлагаю погуглить.
Разве не нужно просто написать, ну, адаптера произвольного evitable, который будет, соответственно,
в коннекте сохранять, условно evitable, не запуская его, а дальше в старте. Это правда,
вот если только для evitable достаточно, да, вот по такой логике, как ты начал говорить, вот да,
можно написать, но помимо evitable в библиотеках бывают другие механизмы конкурентности какие-то
модели, которые могут быть не evitable, у них могут быть свои представления о том, как нужно писать
конкурентный код. Вот, и утверждается, что STD execution позволяет все это универсально очень легко
превратить в, ну, почти очень легко превратить нужные нам сущности в сендеры. Вот, ну, и интересно,
как они этого добились, какой ценой. То есть, еще раз, адаптеры не нужны для того механизма,
которые они придумали. Можно прямо с голыми типами, которые в библиотеке есть, работать,
но это удобнее, да, когда код не измазан кучей адаптеров, и можно напрямую там в дебагере
посмотреть, что за тип, и не нужно постоянно после вызова библиотечной функции еще оборачивать
ее в адаптерах или писать целый фасад для библиотеки. Вот, ну, Рома большой поклонник
Unifex, сложно ему отказать в его антидиазме. Я лишь замечу, что дизайн все же очень сложный,
ну, то есть, он очень точный, потому что он позволяет, ну, то есть, он вот максимально
аккуратно описывает все, делит на какие-то такие уже совсем уж неделимые атомы, но, ну,
прямо скажем, иногда кажется, что он слишком точен, и цена за эту точность, она тоже некоторая
имеется, но это можно почувствовать скорее на своем опыте, я сейчас не хочу навязывать
какое-то мнение, я говорю скорее, что автору Unifex существует его оптимальным решением,
ну, а вы можете, ну, вот у вас уже за курс сложилось какое-то количество решений,
задачи выражения конкуренции, вот, хорошо бы, чтобы вы попробовали написать своими
руками разные механизмы и почувствовать какой из них нравится вам больше, ну,
какой он просто удобнее, эргономичнее, оптимальность и там zero cost это одна из целей,
но это в общем не единственная цель, есть, ну, не то что не цель, а вот не единственные критерии,
единственная шкала, по которой можно что-то измерять, может быть вы готовы к чему-то
менее эффективному, но более простому, не знаю, в общем, это скорее самый детализированный,
самый абстрактный дизайн, к которому мы пришли, мы вот разделили, декомпозировали еще больше
сущностей, которые у нас уже были к этому моменту, и вот получили все эти сендеры,
ресиверы, операцион стейта, которые были раньше неявными и какими-то конкретными классами,
а теперь они вот такие абстрактные сущности и уже можно на этом уровне как-то их
комбинировать, то есть стало еще сложнее. Ну что ж, спасибо вам, что вы пришли сегодня в
воскресенье, послушали, в следующий раз мы поговорим про structured concurrency, видимо,
про то, чем наша функция Go, которую мы пишем в Fiber'ах, похожа на Go 2 из языков программирования,
почему Go 2 это не очень хорошо, наверное вы догадываетесь, почему, но еще раз проговорим,
и почему, видимо, Go не очень хорош. Через две недели мы с вами поговорим,
наверное, про какое-то занятное lock-free, про мультикассы, про какие-то структуры данных,
про задачу lock-free канал, про lock-free канал для Fiber'ов, который мы напишем,
ну не lock-free мы напишем, мы напишем со спинлоками, но попробуем написать в мае. И у нас остается,
кажется, третье-последнее занятие, на нем мы подведем итог всему курсу, соберем вместе все,
что мы делали, и мы это постараемся еще собрать вместе на уровне библиотеки, на уровне отдельной
задачи, прям вот все подзадачи, которые мы решали, мы соберем вместе и попробуем это все скомпилировать,
пройти тест, ну для тех, кто решит разные задачи. Поэтому я очень рекомендую вам потратить на это
силы, потратить оставшееся время для того, чтобы попробовать разные и потом совместить. Все,
спасибо вам большое, до встречи через неделю, в следующую субботу. Вопросы, да. Вопрос, а можно ли
как-то найти вот код про sender и receiver в свободном доступе, потому что... Который вот на этой лекции
пишется. Который мы на этих лекциях писали, да. Да, так есть же репозиторий курса, есть репозиторий
курса, а в нем в редми есть ссылка на репозитории, которые вот там по пути мы, с которыми мы работаем
в разных занятиях. Там их возможно нужно актуализировать, я их актуализирую, и там можно будет найти.
Вот для библиотекса тоже интересно почитать, много нового про C++ узнаешь, конечно его понять
весь так на втором курсе сразу невозможно, надо долго и тщательно вчитываться. Вот, но куча новых открытий
совершаетесь. Ну что ж, если вопросы закончились, то тогда прощаемся с вами, до встречи в следующую
субботу. До свидания, спасибо, до свидания. Счастливо. До свидания.
