тогда у нас сегодня по плану разговор про во-первых как написать или дописать или в общем как
реализовать мультипаксус достаточно хорошо и как реализовать raft наш следующий ацем ну давайте
начнем с мультипаксуса и если у вас есть что-то что вас уже накопилось и вы готовы этим
поделиться но у вас вопросы не знаю есть пожелания как досада за ваш код может быть
вот смотри задача сначала ложиться в тайм-лимит да мы говорим про первый шаг про то
даже не как захлеван сделать это отдельная история а про то как просто реализовать протокол
без даже выбора лидера когда у нас есть конкуренция первая задача это эту конкуренцию
постараться минимизировать даже не выбирая лидера и так с одной стороны минимизировать
конкуренцию с другой стороны минимизировать какие-то лишние действия протоколе вот очевидное
лишнее действие это ситуация когда у вас несколько реплик выступает пропаузерами для разных команд
пытаются их предложить в один слот но мы знаем что только у одной это получится смысле что только
одна команда выиграет фиксируется в логе но тем не менее если вы действуете совсем наивно то вы
запускаете на трех репликах три разных пропауза и каждый из них добивается того что он все-таки
завершается проходит через две фазы какой-то пропауз завершается первым и он собственно
фиксирует команду в логе а дальше два других пропауза они все-таки проходят через две свои
фазы хотя уже в общем пользователем большой нет потому что они уже проигравшие так вот зачем
же их так долго мучить вот если вы пропауз который выиграл просто расскажите об этом всем то есть
конечно же вашей реализации помимо фаза prepare и фаза accept в аксессе должна быть фаза commit
пропауза который проходит через первые две фазы просто отправляет напрямую всем другим репликам
сообщения о том что команда зафиксирована и если вы как это можно было бы в коде выразить можно
было бы по разному можно там отдельный сервис завести можно том же самом аксепторе завести
еще один рабочий для сообщения commit если вы получите сообщение commit то просто поставьте
в запись логов флажок о том что команда уже зафиксирована и там сообщить о том что ее
можно применять нет никакого смысла дальше пропихивать пропихивать вашу команду давно уже
смысла на самом деле не было это отдельная история но вот завершать пропауз тоже смысла нет потому
что уже известен результат чем быстрее вы это сделаете конечно же тем вам будет меньше
команды раундов и времени вы потратите это очевидная оптимизация и должны были сделать все без нее даже
пробовать не стоит потому что пропаузер может отказать это не то чтобы это взаимно
исключающая оптимизация ты можешь делать любые оптимизации которые нарушают сейф и которые
просто ускоряют выбор ускоряет принять решение тут не то чтобы лэмпард предлагать
акультар это альтернатива он просто описывает какой-то из вариантов вот разумеется если мы
говорим про сценарий где у нас отказа возможно где у нас перезагружаются и
совсем выключаются то скажем мы не можем делать так мы не можем доверять конкретному
пропаузеру что он если уж он работает то мы с ним совсем не конкурируем и дожидаемся пока
он отправит комит вот такая выстика не работает потому что нет гарантии что пропаузер закомитит
свое значение прежде чем он упадет или перезагрузится или что он успеет все-таки да отправить нам
комит после того как выберет значение может быть он выберет значение комит не отправит и в итоге
мы о нем не узнаем то есть секундочку так первая оптимизация которую мы в мультипакс делаем мы
добавляем фазу комит она конечно оптимистичная потому что нет гарантии что именно через нее мы
узнаем за комичным значение но идут видимо подойдут какие-то ретро и там с ограниченным
количеством попыток это первая оптимизация которая нужно было сделать а вторая оптимизация
касалась конкуренции для того чтобы протокол побыстрее завершался нам нужно чтобы пропаузеры
поменьше конкурировали друг с другом и для этого можно выбрать лидера просто среди них а можно
лидера не выбирать но при этом все же команда по логу размазывается вот пытался ли кто-то что-то
здесь разумное придумать это параллельно понятно что правильный разные команды расставляются
по разным слотам и запускаются пропаузы запускаются параллельно разумеется данный наивный мультипакс
у себя же три реплики могут получать 9 разных команд и на трех слотах соревноваться речь про
том чтобы не соревновались в этот момент ну или соревновались но как можно меньше
тут огромное количество иуристика можно выдумать ну скажем вот есть такая очевидная иуристика
если вы пропаузер и вы предлагаете команду слот лога и вы выполняете фазу при пер и вы
после фазы при пер узнаете что вы получили хотя бы один пустой голос то какие вы выдавались
два из этого делаете но что видимо на какой-то другой реплике существует другая команда
которая с вами соперничает так вот вы не можете просто уйти потому что но кто-то уже есть он
дальше за комитить значение может закомитить потому что перезагрузится и все и все застрянет но
с другой стороны нет никакого смысла вот вашу команду пытаться встроить вот этот слот она уже
проиграла вы ее не используете вы просто голосуете за то значение вы предлагаете то значение которое
вам вернулось с кворума там значение с максимальным бэлл от номера так вот если вы увидите что вы
от фазы при пер получили не пустой голос то просто отпустите свою команду и предложите в другой слот
потому что вы знаете что в этом слоте уже есть конкуренция при этом сам слот вы продолжаете
сам слот вы продолжаете комитить значение вы продолжаете работать с консенсом то есть вы
все еще пропаузер но вот именно команду свою вы отпустили это тоже такая очень очевидная
евристика без которой было бы странно жить кто-нибудь применял ее вы поменяли вообще какие-то
евристики или просто написали что-то в лоб потому что тут огромное количество всего можно придумать
что
ну вот это максимально не эффективный способ то есть вот ноль оптимизации сделана хотя
важно было бы очевидно применить вот такую простую оптимизацию
но для того чтобы это все было удобно писать вот я очень рекомендовал рекомендую использовать
тот дизайн который предложен в условии а именно если у нас есть для каждой команды
pipeline такой логический и в нем есть параллельные стадии параллельные для разных команд и
последовательные для разных команд то разумно последовательные этапы которые выполняются
которые не параллельна для разных команд вот если мы работаем с логом и мы работаем
Legacy под неутоксом то разумно делать это в отдельном файбеле просто ему поочереди
Breadwater команд если мы применяем команду кто там уже должна делать только в одном потоке в одном
файбере опять заведет файбер и он будет заниматься только этим для того чтобы что бы этот
чтобы этот код не размазывался дальше по применению команд и по выкладыванию у них
по всему multipax, нужно просто отделить эти два файбера от всего остального протокола с помощью
каналов. вот если у меня пропаузер понимает, что команда текущая, которая у него есть,
которая предлагает локальная реплика, ее предлагать дальше не нужно, потому что у нас
у нас есть конкурент, то я просто возвращаю команду в канал, который разбирает файбер,
который выкладывает команду в лок. то есть если мне приходит команда в execute, я бросаю ее в канал.
если пропаузер понимает, что он команду свою не закомменит уже в этом слоте, то он бросает ее в
канал. она сразу попадает в файбер, который выкладывает команду и запускает пропаузы,
и этой команде назначается какой-то будущий скот. ну а почему бы ему не знать про каналы?
он и про лог знает. ну ладно, про лог он не знает. ну конечно, если мы хотим что-то разумное написать,
то это, наверное, что-то нужно знать. почему много информации?
это не много, две перемены.
а индекс какие разделяются? разделяемые данные? ну лог, наверное, и канал, и все.
лог, канал, и более-менее ничего больше.
ну и вроде не страшно, так и должно быть.
как мы будем возвращаться из rpc вызова с таким дизайном? из какого rpc вызова? не понял
вопроса. нам нужно дождаться того, что закоммитится какая-то команда. ну не закоммитится,
а применится к автомату. да, применится к автомату. до того, как мы ответим клиенту,
что все хорошо, все применилось, и вот нам нужно ответить клиенту после этого,
и как-то нужно связь между файбером, в котором добавляется вот между этим вот главным файбером
и рпс вызовом сделать. у меня есть файбер, который выкладывает команды в лог и запускает
пропаузы, есть файбер, который применяет команды к автомату. я говорю про файбер,
который кладет команды в лог. но он с клиентом не работает. зачем работать с клиентом? он же не этим занимается.
я, видимо, не понимаю вопроса. а Зосяк? мне, видимо, нужно еще подумать. что? его задача
предлагать команды, чтобы запускать по аксессу. клиенту он не отвечает.
а если я хочу использовать по сути выкладывание команд в лог через callback-fuge? мне там нужно запуститься
тебе нужно остановиться. то есть не писать так? ну а зачем? у тебя есть, еще раз,
ты проигнорировал разумный дизайн, который написан на условии. у тебя есть стадия,
которая последовательно выполняется для всех команд. для того, чтобы делать что-то последовательно,
у тебя есть потоки файбера. а зачем на этом экономить? я не очень понимаю. но то есть
декомпозиции ухудшаются. у тебя действия не локализованы, они где-то как-то разбросаны.
во-первых, про oppose делать RPC-вызове вообще никакого смысла нет. мы же понимаем, да? зачем
делать RPC-вызов своему себя? это можно делать только от лени. я тоже не понимаю, в чем проблема
вообще. чтобы канал в конструктор передать, это не проблема. в смысле мы вызываем проползни
через RPC-вызов? зачем ты вызываешь на себе RPC-вызов? ты можешь просто вызвать код,
напрямую функцию вызвать. у нас там просто тогда изменить по сути модификатор доступа с
протектором на паблик. мы просто меняем дизайн. причем тут паблик? причем тут вообще код? у тебя
есть RPC-вызов propose, и ты посылаешь из узла себе RPC-вызов. зачем? ты посылаешь через сеть себе
сообщение о том, что запусти файбер на себе. ты можешь просто запустить файбер. причем тут паблик или
private? тут вообще RPC-сервис-пропозер не нужен. потому что пропозер работает на себе. еще раз,
ты можешь не через RPC-вызов файбер запускать, ты можешь просто написать файбер-го.
но это же странно иначе. зачем такую петлю к себе делать? ты не находишь, что это странно?
нахожу. вот, но вот в этот момент можно подумать и написать код проще.
что тебе мешает этот пропозер? сделать пропозер полем, сделать вообще просто функцию в классе
multiprocess, которая делает пропозы. тут можно много вариантов придумать, но все эти варианты RPC-сервис
не требует. ты можешь на себе через RPC-протокол запускать на себе файбер, но есть способ попроще это
сделать. получается, ну я вот сейчас подумал, то есть вместо callback-official, наверное, лучше
использовать канал, то есть из, по сути, первого файбера, который делает пропозы, кидать по каналу
результат в тот, который записывает влог. просто во втором файбере мы постоянно в цикле находимся,
как я понимаю. да, мы в обоих циклах, в обоих файберах в цикле находимся. и канал, мне канал нужен
в пропозере не для того, чтобы возвращать значение, которое я выбрал. мне нужен канал для того,
чтобы в него передавать команды, которые я не выбрал. еще раз, есть файбер, который выкладывает
команды в лог. он эти команды получает из канала. в этот канал кладут данные команды RPC-вызовы,
которые приходят от агентов, когда команда появляется. и в этот же канал я кладу команды,
которые просто проиграли выборы в своем слоте, когда они не нужны уже. то есть я пропозы запустил,
он понимает, что выберется другая команда, не моя. я в этот момент команду отпускаю,
бросаю ее в канал, и она предназначается на новый слот. в итоге один consensus уже работает,
то есть consensus продолжает работать в каком-то слоте, но команда уже перезапускается в новом.
потому что я раньше, чем consensus завершился, понимаю, что команда проиграла. зачем не дожидаться,
пока другая выиграет? это же разные спорты.
я же могу одно понять раньше, чем другое. если я получил не пустой prequart какой-то
реплики, то все, я уверен, что наша команда уже не выберется. я больше ее не предложу.
ладно, мы какие-то вялые овощи, что-то скучно.
но у нас для этого лог, сейчас еще раз, для хранили, у нас есть лог,
если мы используем кивали хранили, то мы не явно объявим задачу.
ну конечно, из чего бы она вдруг была атомарной?
мютокса что-то? из мютокса изобретать не надо, они уже вроде есть. но конечно,
запись не будет атомарной, из чего бы она была атомарной. она не атомарна,
в разных смыслах. в логе она сама по себе не атомарна, даже в один лог она не атомарна,
потому что ты можешь перезагрузиться, а запись, ну мы обсуждали на одном из семинаров,
что запись, просто файл не атомарен. ну и то, что все написано уже, потому что
райт и хэт лог у тебя написан в библиотеке. ну разумеется. ну очень лениво. вот он сейчас,
у нас есть библиотека, она опирается на файл, на интерфейс файловой системы. это еще раз,
мы нигде не пишем код, который делает нелегалистичные предположения. точнее,
ты можешь его писать, но не я. я не пишу такой код. и вот в этой библиотеке есть интерфейс файловой системы, вот он.
ждем, ждем. вот тут много-много методов. каждый из них возвращает статус или результат,
в зависимости от того. ну и для записи в... если мы хотим на этой абстракции делать лог,
то у нас вот есть ClassWriter, в нем есть append, который какие-то непрозрачные байтики добавляет к
отдельным записям. и он там использует... он там чексуму использует. он там использует,
скажем, обновляет персистент, обновляет данные директории. то есть все, что мы говорили на семинаре,
все это он делает. когда мы добавляем запись, где мы это делаем сейчас? мы делаем append. мы сначала
помещаем все в буфер, строим заголовок там, где есть какое-то магическое число,
чтобы понимать, что заголовок-то заголовок, что он вообще записался, что это просто мусорные байты.
мы считаем чексуму данных, мы пишем сначала заголовок в буфер, потом мы пишем сами данные и потом
делаем append и не предполагаем, что вот этот append файл завершится автомарно, скажем. он может
завершиться неатомарно. но для этого у библиотеки у нас есть, помимо райтера,
рейдер, который дальше читает записи. и он, конечно, ожидает... давай еще раз покажу код. он читает
заголовок. если он не может прочесть заголовок, то беда. то есть если там просто файлы байтов не
хватает. если в заголовке неправильный magic number, то, видимо, это не заголовок, тоже беда. то есть
нужно отбросить хвост этого лога. потом, когда мы читаем записи, оказывается, что ни у чексумы не
совпадает, то тоже мусор нужно отбросить конец лога. но весь код, который опирается на вот этот
write-head-log, который написан в библиотеке, он, конечно же, учитывает, что сбой может в любом месте
произойти. а дальше, поверх этого write-head-лога строится уже лог для rsm. и он все это учитывает.
то есть, когда мы говорим про сегментированный лог, скажем, то каждый сегмент, как он устроен, это
write-head-log, куда добавляются все правки, то есть все транкейты и все перезаписи ячеек. когда мы
перезаписываем ячейку, мы в write-head-log добавляем запись о том, что ячейка изменилась. то есть
вот здесь все абсолютно честно. если ты поверх вот этих честных инструментов пишешь честный код,
то ты можешь писать честный код. ты не можешь это сделать. еще раз, ты не можешь сделать это
автомарно, потому что это два разных файла, и ты можешь поверх этого придумать очень сложный
протокол, но вообще говоря, нет. файловая система так не умеет. файловая система вообще почти
ничего делать автомарно не умеет. все, что мы можем, мы можем про это write-head-log еще более-менее
писать. если ты, конечно, хочешь соорудить свой write-head-log поверх каких-то других объектов,
но мне кажется, что можно как-то проще это сделать. грубо говоря, найти какие-то стадии,
благодарит мне, чтобы ты мог после любой стадии восстановиться в корректное состояние. но вот
этого тебе достаточно будет. вот, но вообще весь код, который написан, написан, конечно, с учетом
всех возможных реальных век, и собственно, это моя задача на ближайшие две недели, чтобы поверх
под этим кодом написать настоящую файловую систему, и там TCP уже написан, чтобы этот код можно
было запустить. распределенно, абсолютно честно. при условии, что ты нигде углы не срезал и нигде я сам
не ошибся. но абстракция, которая у тебя есть, даже реализация write-head-log, она дает тебе ровно те
гарантии, которые дает тебе write-head-log в реальности. потому что вот эта библиотека, она ничего не
знает про симулятор, она ничего не знает про... короче, она знает только про то, что есть файловая
система и разумно опирается на какие-то гарантии ее. что вот append не отомален.
но есть вот способ фиксировать что-то надежно. есть синхронизация в sync на директории, есть и в sync
на... в sync на файле, где это можно найти.
если файловая система делает и сама не ошибается внутри реализации screwdriver, то значит,
наша реализация тоже будет сверхкорректна. а поверх этих вот кубиков ты можешь собрать какой-то свой
более сложный протокол, и он тоже должен быть корректным.
окей, тогда если примерно понятно, как оптимизировать multiplexos, ну, в смысле, какие там базовые оптимизации можно
предупредить, чтобы пройти тесты, то следующий этап это сделать exactly once и пережить restart.
ну и при restart-ах самое главное постараться не писать код про restart. вот в хорошей реализации
рестартов код... в общем, нет специальной логики про рестарты. у меня реплика перезагружается,
она просто получает команду, начинает ее проползить, если видишь, что что-то в логе есть, то вообще очень
удобный вариант, как в multiplexos не зависнуть. вы, наверное, сами это для себя понимали, когда писали код,
что если вы предлагаете что-то, очень простой способ не зависнуть никогда. если вы предлагаете
что-то в слот лога номер и, то вы должны запустить проползу на всех слотах до него. если вы так делаете,
то вам ничего вообще не угрожает. если вы перезагружаетесь и пытаетесь там где-то что-то не
делать, то, ну, где-то не запускать проползу, то, возможно, вы что-то сэкономите, но можете
проиграть с другой стороны. вот в любой непонятной ситуации делайте проползу. если проползу есть на всем
префексе, то точно ничего не сломается. ну, и вы таким образом автоматически накатите свое
состояние, на котором вы остановились перед рестартом. но когда вы делаете рестарты, вот
появляется потребность делать exactly once. и с exactly once тут есть вообще нюанс, потому что, если вы
пишете его, скорее всего, пишете его плохо. в чем проблема? в том, что, скорее всего, понятно, как
делать exactly once, наверное. нужно завести какой-то мэп, который хранит отображение из ID клиента,
не команда, а именно клиента достаточно, в ответ. то есть это последний ответ данного клиента. если
вы получаете запрос и смотрите, что у вас уже есть ответ, то вы на него отвечаете из мэп. вот так
делать не нужно, потому что это нечестно. это в вашей реализации честно, но если вы немного подумаете
и вот сделаете вот этот пункт, то вы поймете, что у вас ничего работы не будет. ну, потому что,
представь, ты заполняешь свою мэпу, ты кладешь туда ответы, потом ты обрезаешь, у тебя лог растет,
ты решаешь, что нужно наэкономить место, выкидываешь префикс лога, заменяешь его с неким
состоянием, лог обрезаешь, он недоступен, потом перезагружаешься. если ты подумаешь,
что настоящему RSM'у нужен и exactly once, и снапшоты, то ты поймешь, что в коде мультипаксиса
exactly once быть не может. exactly once должна быть внутри автомата.
то есть не в самом классе мультипаксиса должна быть эта мэпа, ты должен как-то ее сохранять с
помощью каких-то кастрюлей, словно сбоку. тебе нужно сделать автомат, который оборачивает
вот твой данный автомат и к нему добавляет еще эту мэп. то есть эта мэпа это тоже часть
персидентного состояния. и когда ты делаешь снапшот автомата, ты делаешь, конечно, снапшот не только
самих данных, ты делаешь еще снапшот этих вспомогательных данных с ответными клиентами,
чтобы их не забыть, потому что ты обрезал лог. так что этот код следует уносить внутрь автомата,
чтобы мэп снапшот на автомате его учитывал. это такая неочевидная вещь, если вы не делаете
снапшот, то можно об этом не подумать, если вы делаете снапшот, то у вас не остается никакого другого выбора,
потому что иначе... да, то есть это сделать здесь. ну иначе тебе придется дублировать код один
и тот же в разных местах. а зачем?
мультипаксусу не нужно знать про exactly once. ему достаточно at least once.
exactly once пусть тебе сделает автомат.
ну короче говоря, унести все-таки локализовать это ближе к месту применения команд.
вот это первое, что нужно заметить. второе, что нужно заметить, что кажется, что даже такая схема не практична,
все равно. ну по крайней мере она более практична чем ничего и более практична, чем хранение всех
команд, а ответов на все команды. то есть мы все-таки в памяти ограничены количеством клиентов.
ну а что если клиентов у нас все больше и больше и больше?
Ну или по-другому, клиент, не знаю, выключился на час,
включился, и мы должны помнить его ответ. За это время пришло еще очень много клиентов.
Мы же не можем для всех клиентов помнить последнюю команду в конце концов,
у нас рано или поздно кончится память. Так вот, тут есть с точки зрения реальности,
в самом деле две проблемы. Первая проблема, вот нужно, ну не то, что проблема,
первая, что приходит в голову, нам необходимо выкидывать команды из RSM,
забывать про них нужно. И вот для того, чтобы забывать, если мы будем забывать команда,
то есть по некоторому тайм-ауту, забывать клиентов вернее, то мы можем создавать трудности.
Понятно ли они? То есть мы не можем хранить всю мэпу с ответами, с последним ответом для каждого
клиента, потому что клиентов может быть слишком много на большом промежутке времени. Поэтому мы
какие-то команды, какие-то клиентов должны по тайм-ауту забывать, и вот если мы начинаем
так делать, то у нас с двух сторон возникают трудности. Ясно или нет, в чём дело?
Во-первых, вы клиент, вы сделали попытку, не знаете, в чём закончилась она, потому что,
не знаю, вот вы клиент на виртуалке, вас погасили в этот момент после запроса,
а запрос улетел и там применился дальше. Потом через час вас включили обратно, и вы продолжаете
с того же места, где вас заспендили. И вы делаете ещё один ретрай, и после этого ретрая команда
применяется второй раз, потому что RSM уже давно про неё забыл, про эту команду, про его клиента.
Это плохо. Но это плохо, но RSM не может не забыть. Плохо не то, что он забыл, а плохо то, что клиент
не понимает, что происходит. Клиента нужно отличать в таком случае. Команда была...
Если мы просто наивно получим повторный запрос от клиента и применим его, то все будут думать,
что всё хорошо. Вот наша задача, как минимум здесь, сказать клиенту, что исход неизвестен,
что мы не знаем, успешен он или нет. Мы видим, что это его попытка очередная, но мы не знаем,
что было с предыдущими попытками, потому что мы про них забыли уже, честно. И вот это разделение,
как бы не знаем или применяем, это очень важное разделение, потому что оно даёт клиенту шанс
как-то восстановиться из этого некорректного состояния. Вот так что любая система,
которая XF-Privanse использует, она, конечно, забывает про клиентов, но она с ними поддерживает сессии.
То есть когда вы пишете клиент в библиотеке клиента, то вы, конечно, открываете сессию
сначала. Система запоминает, что такой клиент есть и запоминает его тайм-аут. И клиент периодически
посылает хардбиты. И если клиент пропал, хардбиты от него исчезли, то RSM может забыть про ответы,
которые он на дню хранил. И если клиент придёт на следующем летраем, то система сессии не увидит
у себя и скажет, что ошибка. И вот на основе этой ошибки клиент уже может какую-то логику написать.
То есть лучше мы сделать не можем, но по крайней мере мы можем сказать ему явно, что произошло что-то не то.
А вторая беда связана с детерминизмом, потому что если у нас будет сессия, то, ну представьте,
сессия на одном узле на одной реплике стекла, а на другой ещё нет. И вот наш клиент затупил,
его сессия протухла, и он сделал ретрай на другую реплику, и эта команда применила. А потом эта
команда реплицировалась на другую реплику, а там тайм-аут уже. Так вот, если мы делали
им тайм-ауты, то в мультипаксе среди RAF-ти внутри RSM всё должно быть детерминировано, в том числе и тайм-аут
должен быть детерминировано. Да? Ну потому что, ещё раз, если нет детерминизма есть, то реплики ведут себя по-разному.
Но вот тайм-ауты, которые ты заводишь для клиентов, они же, это логика приложения твоего уже более-менее.
И вот она тоже должна быть детерминированной, поэтому... Ну вот лекции про зукиперов там в параллельном
курсе ещё не было, но вот зукипер, он как раз поддерживает сессию, это сервис блокировок, он
поддерживает сессию, и сессия тоже реплицируется. Но с зукипером ещё проще, если это не то, что с зукипером,
с сервисом блокировок. Если вы в сервисе блокировок берёте лог, то вы берёте его на сессию, и если вдруг
сессия протухает, то у вас лог честно отбирают, и для вас нормально получить ошибку, потому что ваш
сессия протухла, лога значит у вас уже нет. Тут вообще никакой проблемы нет.
Вот, с транзакциями похожая история. Тоже блок-менеджер берёт для вас логи,
заводит тайм-ауты для вас, и если тайм-ауты стекают, то вы просто транзакцию откапываете и получаете ошибку.
Ну, это нечестно. Сейчас, про снепшоты тоже. Мы обсуждаем, какие бы нюансы реальности,
мы всё равно опускаем задачи. Вот, ещё одна сложность, которую мы игнорируем,
вот прям совсем игнорируем, это взятие снепшотов. Это вот функция мэйк-снепшот в автомате.
Вот то, что она синхронная, то, что она возвращает на небольшой снепшот, и можно его передать по
сети одним RPC вызовом. Но если у тебя совсем снепшот маленький, ты можешь прямо в логе его хранить. Это правда.
А я не знаю, в этом большого смысла нет. Вот, ну и если вы начнёте делать снепшоты, то эти снепшоты,
они у вас проникают в весь остальный протокол, и скажем, вы acceptor, вам приходит команда prepare
для слота 5, а у вас минимальный слот уже 100500, потому что реплик где-то долгое время отдыхал.
И вот вы должны, вы не можете ответить на prepare, потому что вы уже забыли, что в этом слоте лога
было. Поэтому вы можете вправить ему только снепшот, и вот у вас ещё появляются две служебные команды.
Ну и такой специальный ответ на любое сообщение. Пожалуйста, забудьте, что ты сейчас делаешь,
и просто установи снепшот. Вот, и в итоге это всё начинает проникать друг в друга так вот. То есть
все эти задачи становятся довольно сильно связаны. Ну что ещё остаётся? Ну про Лизу мы с вами на
отдельный рецепт говорили. Не знаю, ну вот это, наверное, то, с чем можно столкнуться, если вы
вот частно сделаете какие-то более сложные пункты. Ну, проповзору нет смысла быть отдельным RPC
сервисом. Кажется, что от RPC польза только в том, что Fiber запускается во-таки в мощный
затеяривом способе. То есть никакой пользы этого нет. Но Acceptor — это RPC сервис, потому что он
взаимодействует с другими, потому что с ним общаются другие узлы. Вот. Ну, мне кажется, что всё
существенно упрощается вот этим замечанием, что Fiber, что выкладывать команды в лог и применять
команду в автомат нужно в один миг Fiber. Тогда вот общение между вот этими конкурентными... То есть
у тебя есть много параллельных пакс, у тебя есть последовательный Fiber, который выкладывает в лог,
у тебя есть последовательный код, который применяет команду, и вот у них общение через
каналы. Этого достаточно.
Не понял вопроса.
Ну, кажется, это не задача Acceptor, правда, делать Snapshots? Snapshots делаются тогда, когда ты применяешь
команды, когда у тебя лог растёт. Ну, в смысле, когда у тебя... не так. Ты можешь делать Snapshots,
когда у тебя накапливается закомиченный префикс. За закомиченный префикс тебе накапливается Fiber,
который применяет команду к логу, применяет команду к автомату. Вот ты применил в этом Fiber
команду к автомату, узнал, что у тебя вот лог вырос, долглины 100, ну и взял ответ вот него.
Что-то странно, у меня синхронизация есть, но Bluetooth называется. Ну, тут все подряд работают с логом,
поэтому все подряд берут Mutex. Fiber Proposer с Fiber, который применяет команду, никак не связанное.
Fiber, который применяет команду, он в вечном цикле спит на канале. Когда какая-то команда комитится,
в этот канал падает сообщение пустое, что вот какая-то команда закомитилась. После этого Fiber,
который применяет команду, просыпается, и от того индекса, на котором он остается, идёт вперёд и
смотрит, что вот следующий слот закомитчен, отлично, применяй его. Следующий слот закомитчен,
применяй его. Потом он остановился и снова заснул на канале, куда сыпятся сигналы о комитах. Он не
понимает, какие команды, где комитятся. Он просто сообщает, что какая-то команда закомитилась,
это повод попробовать проехать немного вперёд. Вот код получается очень простой.
Тогда с этим вопрос. Получается, Fiber, который применяет к автомату, он является полем класса,
по сути, multipaxis. Fiber-то полем не является, всё же. То есть, мы каждый раз в Execute должны запускать Go,
по сути. Ну, я так и делаю, я же Propose запускаю. Ещё раз, у меня есть два Fiber'а,
которые вечные живут, они на старте запускаются, и один из них начинает читать канал с командами,
чтобы проползить. И один Fiber, который читает канал комитов и применяет команды. Вот два этих
Fiber'а, они статичные. Плюс ещё есть Fiber'ы, которые рождаются на каждый Propose. Ну, а как без них?
Так, то есть, у нас каждый рождается... В условии. У нас есть последовательные фазы
и параллельные. Вот для последовательных у нас два Fiber'а, для параллельных у нас много Fiber'ов.
Тогда я не очень понимаю смысл первого общего Fiber'а. Ну, нет никакого общего Fiber'а. Откуда
он взялся? Что такое общий Fiber? Ну, скажем так, в общем, я называю те, которые последовательные. То есть,
которые мы запускаем на старте. Я так и называю, я говорю ещё раз, что у меня есть два Fiber'а. Один из них
выкладывает команды в лог, и получает их через канал. Третий выкладывает... Третий применяет их
к автомату. Но я просто повторяюсь уже в пятый раз. Я не знаю, что... То есть, я не сообщаю тебе
новой информации.
А, всё, я понял. Окей. Ну вот, тогда получается всё довольно локализовано.
Никакой сложности с синхронизацией нет. Код очень простой.
Ну, приятно же писать простой код. Гораздо приятнее, чем сложный. Ну, вот, ну, конечно, я понимаю, что нужно
немного подумать, прежде чем простой код написать. Но вот, если ты пишешь сложный код, то всегда нужно
остановиться и подумать, что ты что-то делаешь не так, скорее всего. Что что-то можно сделать лучше.
Ну, либо задача твоя безнадёжная. То есть, так тоже бывает. Но вот эта задача, она такая, более-менее
безнадёжная. То есть, тут простой код пишется. Вот, не более того, вот главная идея написана здесь.
Если её проигнорировать, то, скорее всего, получится хуже. Ладно, про... Exactly Once я поговорил, просто
что-то я немного поговорил про... Тесты без него проходят все. Бесконечный препарат называется RAFT.
Итак, вот давайте, если с Paxos примерно понятно, что делать. Ну, вот, главная оптимизация — это фаза
коммита и по возможности рассеивания команд по репликам, ой, по слотам лога с разных реплик, чтобы уменьшить конкуренцию
даже без выбора лидера. Ну, с выбором лидера всё понятно, собственно. Любой протокол, там, хардбиты и...
Вот multi-Paxos, он пишется довольно просто. Ну, вот давайте сейчас перейдём к RAFT'у.
С RAFT'ом немного другая история. Сейчас давайте перейдём к слайдам RAFT'а. Я коротко напомню, как он был устроен.
Ну, мы решаем ту же самую задачу. У нас есть лидер, у нас есть фаза выбора лидера.
Потом и так. У нас есть реплики. Они бывают в трёх состояниях. Есть лидер, который получает команды и выкладывает их в лог.
Есть фоллвер, который реплицирует команду на себя. Есть кандидат, который считает, что лидеру нужно выбрать нового лидера, а именно его.
И для каждой реплики всё время работает алгоритм, делится на эпохи, на термы, которые состоят из двух фаз.
На первой фазе каждого терма мы выбираем лидера. На второй фазе лидер получает команды и реплицирует их.
Может быть, голоса разделятся в каждом терме, поэтому лидера там не будет выбрана, тогда мы берём следующую терму.
Для того, чтобы каждая реплика, разумеется, надёжно помнит свой терм, потому что это более-менее аналог был от нам в факсусе.
Чтобы подтвердить, что лидер всё ещё жив, этот лидер посылает всем смысл о сообщении о хардбит, а каждая реплика, которая должна этот хардбит получать, заводит в себе таймер, и в течение этого таймаута ожидает тех самых хардбитов.
Если хардбиты в течение таймаута не доставляются на данную реплику, то данная реплика считает, что лидер умер, увеличивает свой терм, становится кандидатом и предлагает всем остальным проголосовать за неё.
Если вы пишете мультипакса с лидером, то, скорее всего, у вас что-то похожее должно получиться, но ровно по этим соображениям рафту в таком порядке и изложено.
Да, тут два замечания, что, во-первых, сейфти свойства. У нас есть, что в одном терме работает один лидер, это понятно, и мы рандомизируем таймаут в таком интервале для того, чтобы обеспечить прогресс, чтобы таймаут на разных фоллверах не стекали одновременно.
А дальше лидер получает команды и начинает выкладывать их в свой лог и реплицировать на другие, при этом сохраняя свойство, что если в слоте две команды совпадают, то совпадают и префиксы целиком в этих двух логах.
А если префиксы не совпадают, то мы начинаем их чинить, просто выкидывая из лога фоллвера неправильные, по нашему мнению, команды.
Ну, либо мы узнаем, что лога у фоллвера просто не хватает, поэтому нужно откатиться и узнать, с какого места мы совпадаем, либо же, если не совпадает предыдущая команда, то мы постепенно откатываемся, откатываемся и выкидываем свойство.
Ну, а дальше мы, я напомню, говорили, что не совсем понятно, что команда закомичена, то есть мало положить ее на хвором, нужно, чтобы сверху ее придавила команда из текущего терма.
И нужно аккуратнее голосовать за лидера. Мы голосуем за кандидата, точнее за кандидата, мы голосуем за кандидата, если у него старший терм в логе больше, или у него старший терм такой же, но просто лог длиннее.
Ну вот, это все алгоритм RAF, там он сейчас не очень, в смысле он важен, конечно, но мы сейчас не про алгоритм поговорим, мы поговорим про то, как его написать.
И писать его оказывается немного труднее, чем мультипаксус, потому что мультипаксус довольно хорошо декомпозируется, в смысле самого алгоритма, там есть отдельные слоты, они более-менее независимые.
То есть вы между ними можете какие-то иллюстики такие устраивать несложные, типа перекинуть и продолжить в другом слоте.
Но вот этот алгоритм RAF, он такой локальности не имеет, и он не работает со слотами отдельно нигде.
Он работает сразу с целым слогом целиком, с его суффиксами, и поэтому написать его чуть сложнее.
К счастью, для нас мы будем писать его не совсем с нуля, как мультипаксус, потому что мультипаксус с нуля проще написать, мы будем писать его по мотивам двух источников.
Во-первых, это референсная реализация самого автора алгоритма, он называется локабин, написан на C++, и вот буквально в одной директории все содержится, я бы даже сказал, что почти в одном файле содержится.
И что совсем приятно, ну вот тут реализация небольшая в принципе, но вот со всеми этими снапшотами тут столько тысячи строчек.
И по мотивам кажется, мне кажется, что эта реализация есть совершенно, ну очень удачная для нас, для вас, удачная для нас серия постов, где вот один известный товарищ пишет этот RAF на языке ГО.
Но поскольку у нас есть все, что есть в языке ГО кажется, ну то есть по крайней мере все, что он использует, то значит мы можем вот этим руководством, руководством C писать по нему.
А вот он буквально пишет по презентации. Он в таком порядке его читает, думаю, что он сначала прочитал целиком все же, но по крайней мере пишет он в том порядке, в котором авторы RAF-та алгоритм излагают.
По точки зрения понимания RAF-та это абсолютно не частный способ, потому что мы берем что-то неправильное и какие-то пределы непонятно почему работающие костыри и все начинает работать правильно.
Это понимание не способствует. Но действительно, если мы не стремимся понимать, понимать это отдельная история, про это у нас было занятие.
А если мы хотим просто написать, то вот такой способ он довольно удачный.
И кажется, что автор этого блога повторяет дизайн Лок Кебина.
И почему для меня это важно? Потому что вот просто так придумать реализацию способ написать RAF довольно сложно.
Давайте попробую объяснить почему.
Но вот до этого момента мы все время... Причину две.
Во-первых, в RAF-те есть стадии, которые логически какие-то последовательные.
То есть скажем, мы выбираем лидера, мы заводим тайм-аут, мы рассылаем всем реквест VOTE и дожидаемся, пока нас за нас проголосуют.
Собираем голоса, проверяем, что вот стали лидером, отлично.
Если мы стали лидером, то мы реплицируем команды.
Если дальше глубже закапываться, у нас есть какой-то код, который применяет команды.
И вот сейчас у нас есть... Ну, немного не аккуратно говорю, применять команды, это неважно.
Ну, в общем, в самом RAF-те довольно много всего контентов, которые мы можем изменить.
И вот сейчас у нас есть... Ну, немного не аккуратно говорю, применять команды, это неважно.
Ну, в общем, в самом RAF-те довольно много всего конкурентного.
Конкурентного и вот внутри этой конкурентности логически последовательного.
И довольно удобно запускать какие-то грутины, файберы для всего этого.
А с другой стороны, сама реплика RAF-та – это автомат с каким-то состоянием.
И в любой момент в эту реплику может прийти сообщение из старшего терма.
И эта реплика, получив сообщение из старшего терма, должна мгновенно стать фолвером и забыть про все, что она делает.
А она уже где-то в какой-то грутине собирает какие-то хворумы, собирает что-то сделать,
или какие-то аппетитные антрис посылает. Вот.
И если думать о том, как это написать, то вот ничего хорошего в голову не приходит.
И ничего хорошего в голову не пришло и автору RAF-та, и вот автору этого блога.
Поэтому то, что они написали, выглядит максимально неизящно, но зато максимально просто.
А именно, вот такой мета-подсказка к чтению кода RAF-та и кода, который написан здесь.
Мета-подсказка такая, что все состояние RAF-та защищено одним юдексом.
Ну вот буквально все переменные, то есть лог, текущий терм.
Собственно, в мультипакс все у вас тоже самое должно быть. Если нет, то скорее всего вы делаете что-то неправильное.
Ну да. Но это же автомат, он как бы реагирует, он получает сообщение, и вот должен резко трансформироваться.
А если у тебя в коде какие-то файберы уже бегают, то очень сложно получить сообщение и во всех что-то поменять.
Потому что кто-то спит, кто-то там RPC вызовы сейчас ждет.
Понимаешь, что сложность в тирении?
Про RAF.
Про RAF, да.
Ну, до такой степени... ну ты можешь, конечно, вот здесь два мутокса сделать, но это, в общем-то, несущественно,
потому что применение к автомату это уже... да, правильно говоришь, но это, в общем, мелочи.
Но, тем не менее, все переменные, которые в RAF-те есть,
вот там current term, собранные голоса, сам лог, какие-то другие переменные.
Вот когда мы с ними работаем, удобно думать в терминах каких-то атомарных переходов.
А с другой стороны, у тебя весь код написан на каких-то файберах, мутоксах и каналах,
и вот в нем очень сложно что-то атомарно поменять.
И вот, я не знаю, чувствую, что или нет, но это в мультипаксусе слабое чувствуется, потому что лучше декомпозируется.
А в RAF-те, если писать его с нуля, вообще, с чистого листа, то довольно сложно придумать, как это совместить все.
Вот предлагается совместить очень просто.
А именно, все делать под мутоксом.
Кроме чего?
Если мы делаем RPC-вызов, то мы, конечно, не можем делать его под мутоксом, потому что мы заблокируемся.
И мы не можем спать под мутоксом.
И у этого всего есть довольно любопытное посредствие, которое хорошо видно в коде RAF-та от его авторов и в коде RAF-та...
Ну, давайте я на этом покажу.
Вот тут человек начинает писать RAF-т с процедуры выбора лидера.
Но, точнее, он учится запускать этот election timer.
Как он это делает?
Если нужно запустить election timer, а его нужно запускать начале каждого терма, то для него это будет отдельная грутина.
И в ней он сначала запоминает текущий терм, то есть берет мутокс, запоминает текущий терм, а потом заводит тикер.
И тикер – это канал, из которого можно доставать раз в 10 миллисекунд пустое сообщение.
И вот он в бесконечном цикле достает из тикера сообщение, что проходит 10 миллисекунд.
А потом что делает?
Захватывает лог снова и проверяет.
А верно лишь, что election timer нужно вообще еще работать, потому что, может быть, терм изменился давно уже.
Этот election timer запускается на каждый отдельный терм.
И, конечно, он может усталеть.
То есть состояние реплики могло измениться, когда она вот здесь спала, ожидая очередного тика.
Так что весь процесс организован так.
Мы все делаем под мутоксом, но когда мы чего-то ждем, мы мутокс отпускаем.
А когда его берем заново, мы должны обязательно проверить, что та задача, которую мы решаем, все еще актуальна.
Поэтому мы перепроверяем свое состояние, мы перепроверяем текущий терм,
и если где-то что-то расходится, то мы просто таймер забываем, потому что задача уже не актуальна.
И вот мы такую грутину вот с таким вот тикером заводим на каждый терм.
Но тут не очень важно.
Дело не в том, что протухает или нет.
Это не пытаются оптимизировать, потому что, в конце концов, это не большая статья расхода.
У тебя термы не меняются там каждые 10 миллисекунд, чтобы в этом заводится.
Ты оптимизируешь простоту кода, то есть прямолинейность его.
Он не простой, он не такой лаконичный, его удобно читать.
Он, наоборот, написан слишком в лоб, и в нем нет никакого изящества.
Но идея в нем простая.
Все изменения в состоянии происходят под Mutex глобально,
а все ожидания из Mutex выносятся из критических секций.
Но после того, как мы завершили ожидания на тикере или на RPC вызове,
мы должны после взятия Mutex обратно проверить, что наша задача все еще актуальна.
Вот это первое такое дизайнерское решение глобальное, которое используется в этом коде.
А второе решение, оно будет не тривиально после Mutex,
а именно, когда мы думаем про Quorum, то мы обычно считаем,
что есть какой-то код, который должен отправить запросы,
реприцируй на Quorums, собрать ответы и там их проанализировать.
Вот это то место, которое может вызвать некоторые препятствия,
если вы пишете RAFT совсем с чистого листа, не думая, как в коде его,
как перенести его на код.
Сама статья здесь не помогает.
Сама статья про то, как протокол устроен.
А тут задача, как Quorums собирать.
Вот мы до этого всегда собирали Quorums с помощью комбинаторов,
но это было очень трудно, потому что мы не знали,
как это сделать.
Вот мы до этого всегда собирали Quorums с помощью комбинаторов
примерно одним способом.
RAFT по другому принципу построен.
Он делит наш алгоритм не по слотам, где собираются Quorums,
он делит их прямо по фазам.
И вот запросы в каждую реплику в RAFT вообще, говоря параллельно.
То есть у нас есть лидер, и он с каждой репликой работает независимо.
То есть у него есть отдельная грутина,
которая в эту реплику пытается записывать команды.
Никаких Quorums внутри этого кода не собирается.
Ну по крайней мере, вот так мы к этому привыкли.
Давайте код почитаем уже, и тогда станет понятно совсем все.
Ну вот, runReactionTimeout.
С этого мы начинаем, с процедуры выбора лидера.
Запускаем таймер и ждем хардбита.
Ждем 10 милисекунд, просыпаемся.
Если у нас изменилось состояние, то значит наша задача уже не актуальна.
Нужно просто выйти отсюда.
Или же прошло слишком много времени с момента последнего рестарта таймера.
Видите, мы не пробуем каким-то образом отменять тайм-аут.
То есть можно себе представить какую-то сложную инфраструктуру,
где вы получаете какую-то там, не знаю, фьючу,
а потом вам приходит через нее cancel на самом деле,
а не сообщение о тайм-ауте.
Так вот, здесь все очень тупо.
Здесь есть просто поле глобальное, где хранится,
когда последний раз таймер перезаводился.
И мы просто просыпаемся каждый 10 милисекунд,
проверяем разницу нау и этого поля.
Вот, есть, не всегда так стоит делать,
но есть много жизненных ситуаций,
где код, там, спим 10 милисекунд – это хороший код,
это самый лучший код, который можно написать.
Вот, мы весь прошлый семестр научились так не делать.
И теперь вы знаете, более-менее, когда так не нужно делать.
И надеюсь, что после этого вы сможете воспользоваться
таком способом, чтобы это пригодиться.
Вот здесь делают правильно.
То есть можно представить себе какую-то более сложную
и заощренную систему координации всех этих действий,
а можно делать вот тупо с локом,
спим 10 милисекунд, просыпаемся и проверяем переменную.
Вот, уметь это увидеть – это тоже некоторая…
ну, некоторая наука, чтобы не планировать сложности.
Окей.
Что делать, если у нас проток таймер?
Ну вот, мы запускаем выбор лидера.
Для этого мы все еще под локом
меняем свое состояние,
увеличиваем, становимся кандидатом,
увеличиваем терм,
запоминаем его, потому что мы собираемся лок отпустить дальше.
И после этого запускаем отдельный файбер
на запрос RequestVote в каждую реплику.
То есть проходим с папиром и говорим Go.
В этом Go мы говорим сервис ServerCall.
Вот, это мы делаем уже уже здесь…
Где мы отпускаем ютуб? Видите ли вы или нет?
Вот, это мы делаем уже где-то здесь. Где мы отпускаем urex? Видите ли вы или нет?
А, но мы отпускаем urex, на самом деле это не тут, а тут. А в start-reaction мы синхронно ничего сложного не
делаем. Но да, мы в этих файбрах, в этих грутинах мы уже запускаемся отдельно без мютокса, в них
делаем RPC-вызова, и когда мы получили ответ, мы должны его обработать. То есть учесть, что добавить
голос в хвором. Для этого мы снова делаем очень просто. Получим глобальный мютокс и смотрим.
Если вдруг мы уже не кандидаты, то опять можно бросать все это дело. Если вдруг мы получили
терм старше, чем у нас был, то, видимо, нам ответили с будущего. То есть реплик,
который мы отправили в сообщение, она уже перешла в более высокий терм, и нам просто нужно последовать
за ней. Вот, кстати, смотрите, мы становимся фоллером здесь, но в этот момент, кажется,
мы не знаем, кто такой лидер. Правда? Представьте, мы решили стать кандидатом, а потом заснули на час.
Отправили запрос все-таки. Уперлись фоллеры чужого. Он сказал нам, что он уже находится в
старшем терме. Мы-то получили этот ответ и понимаем, что мы уже не кандидат. Мы фоллеры для более
старшего терма. Но кто лидер, сейчас мы не знаем. Просто в шаблоне задачи там есть способ отметить,
что я не лидер, но я не знаю, кто лидер. Ну вот, например, такая ситуация, где такое может...
где такой сценарий возникает. Ну а если все складывается хорошо, то есть мы отправили голос,
request-vote, и нам ответили голосом, и терм совпадает, то вот мы выгречиваем счетчик для нашего узла,
и если quorum собран, то мы становимся лидером. Мы вот, смотрите, на любой чих буквально заводим
в конце концов берет лог и проверяет, устарел или нет. То есть код не пытается аккуратно все так
сразу все отменять, все что не нужно. Нет, рано или поздно все проснутся, возьмут минуту,
проверят, что они устарели, и выключатся. Ну и после этого мы... да, как только мы становимся
кандидатами, мы отправляем request-vote, и параллельно с этим мы стартуем election-timer.
Хорошо, теперь что делает лидер, когда мы собираем голоса? Ну мы меняем свой стейт,
и у нас еще один чудо-тикер, который раз в 50 миллисекунд отправляет hard-beat.
Отправка hard-beat это... ну опять то же самое. Проходимся по всем пирам, отправляем им
append-entries, и после ответа берем лог и смотрим, если нам ответили снова сервом старше,
чем у нас, то, видимо, мы снова устарели, и снова нужно стать follower. Ну а become follower
какой-то очень простой, то есть мы становимся follower, принимаем этот новый терм,
ну и снова стартуем election-timer. Это мы делаем каждый раз, когда мы меняем терм, переходим в
состояние. Вот это ровно пересказ первой части рафта, где, в общем-то, кроме выбора лидера ничего и нет.
То есть мы даже про лог пока не говорили, в этом коде логов пока не было. Это всего лишь
реализация процедуры выбора лидера. Заметим, что если вы пишете multipax, то вы можете сделать это
гораздо изящнее, потому что там выбор лидера не завязан на весь остальный протокол. Там вы
можете сделать, честно, отдельный интерфейс, который вам возвращает информацию, кто сейчас...
То есть такой модуль выбора лидера, который возвращает вам, кто сейчас лидер, и вы про его
реализацию ничего не знаете, и на весь вход она не воздействует. А тут все вот начинается с
глобальных методов совпеременных. Это такое решение, центральное решение в этом дизайне.
Следующий шаг. Нам нужно сделать лог.
Ну, для этого у нас есть...
Во-первых, у нас есть канал, через который мы уведомляем некоторую грутину, которая будет
командой из лога применять. В multipax следовало сделать уже так же. Эта идея понятна. И у нас
есть лог, который состоит из записи, и запись выглядит так. Это команда и терм, то есть эпоха
лидера, который туда эту команду положит. Когда мы получаем команду от клиента, то мы просто
опять берем юток, как обычно. Если мы лидер, то мы добавляем ее в лог. Если нет, то мы, видимо,
говорим клиенту, что клиент и пропси у нас, что мы не лидер, и нужно идти к какому-то другому узлу.
Вот в этой реализации предлагается делать очень тупо. Мы по-прежнему... Давайте...
По-прежнему, процедура выбора лидера, процедура грутина лидера в цикле в 50 миллисекунд отправляет
всем хардбиты. В рафте хардбит, в сообщении о репликации, это уже сам себе хардбит. Поэтому мы
меняем только смысл этой процедуры сейчас. Цикл в 50 миллисекунд остается, и мы в нем действуем
просто чуть сложнее. Мы для каждой реплики помним, на какой момент, на каком месте мы в репликации
в нее остановились, и с этого места продолжаем накатывать лог. Вообще может получиться так,
что мы лидер отправили в реплику сообщение Appententress, проспали 50 миллисекунд, проснулись,
через 50 миллисекунд, и снова отправили Appententress, и получилось это на предыдущий. Видимо, у нас
стало больше команд, мы отправим тот же самый кусок лога, только еще длиннее. То есть команда отправим
одни и те же. Но это не страшно, рафт с этим разберется. Получатель адреса реплика должна
понять, что какой-то диапазон у нее уже есть. То есть это нормально, что Appententress пересекающиеся
для двух суффиксов лога могут идти параллельно на одну и ту же реплику, и получатся даже в другом порядке.
И снова мы, получив ответ, проверяем, что если мы все еще лидер, то если терм больше, то мы
становимся флорером. Если мы все еще лидер, то мы, получив отдельный Appententress, запоминаем наш
прогресс относительно другой реплики, запоминаем, какой префикс у нас мачится, и вот на основе
префикса, который мачится, мы считаем до какой же позиции мы команду дореплицировали. Для этого мы
берем, обходим все реплики и смотрим, если вот для индекса И у нас matchIndex большинство реплик,
по крайней мере И, то с одной небольшой поправкой, что это неправильное определение
коммита пока. Но это почти правильное определение коммита. Вот если префикс совпадает и в этой
позиции еще и запись текущего терма, то мы знаем, что команда закоммичена. И мы отправляем эту
информацию в коммит-ченнел, и с другой стороны ее принимают, и до этой позиции накатывают все
в лог. Накатывается у нас там App.
Ну, разбирать, как именно реплик реагирует на команду тут, понятно, так же примерно, как это
реагирует, можно все написать. Единственное, что этому коду не хватает, это, во-первых,
персистентность. Этот код ее не учитывает совершенно, а нам нужно. И этот код действует очень тупо, а именно
он раз в 50 миллисекунд отправляет все, что у него накопилось. А может быть, вам уже пришла команда
прямо сейчас, и вы все равно ждете 50 миллисекунд до следующего такта. Как это починить? Как это оптимизировать?
Чтобы эти 50 миллисекунд не простаивать.
Ну вот, да, нам поможет сирект. Где-то здесь у нас есть процедура,
где мы посылаем hard-b to slash команды в логе, и мы где-то здесь должны ее...
Код здесь не написан, а мне кажется, что он должен быть написан.
Так это же не тот код. Совсем не то, что мне нужно.
Да, вот мы делаем сирект в груди не лидера, и мы либо просыпаемся по тикеру в 50 миллисекунд,
либо мы просыпаемся, потому что нам через специальный канал пришло сообщение, что в
RAFT появилась новая команда. Когда мы получаем команду от клиента, мы добавляем ее в лог под
видосом, и вот от нас бросаем сообщение о том, что новая команда есть. Эта команда триггерит в груди не лидера
новую фазу репликации. Ну не фазу, а новый попыток репликации.
То есть тут очень тупой код, в нем нет ничего, кроме грудин, каналов и одного сиректа.
Грудин каналов не лидерцев, одного сиректа. Ничего красивого в нем тоже нет. Но вот, к сожалению, сделать
красиво это довольно сложно. По крайней мере RAFT, там все настолько перемешано, что очень сложно
какие-то емкие независимые абстракции внутри самого лидерцев. Собственно, в RAFT их и нет, поэтому
это его не так просто понять. Но есть вообще альтернативный способ писать RAFT, а именно, если мы
посмотрим на самую популярную пенсос- реализацию, которая написана на ГУАГ.
Тут...
Сейчас мы быстро увидим примеры.
Ох.
то эта реализация, она повторяет логику RAF, разумеется,
там тоже есть become forward, become, все эти переходы,
но самая популярная open-source реализация RAF, она однопоточная,
не то, что она однопоточная, там concurrency вообще нет,
сам алгоритм – это автомат, буквально мы кормим его сообщением,
он внутри что-то делает, переходит в какие-то новые состояния,
а потом возвращает нам те сообщения, которые он готов отправить.
Вот где-то в нем есть такой, сейчас я найду.
Степов, к сожалению, много.
Вот, в нем есть такая большая функция step,
и вот эта большая функция step, она отвечает за то, чтобы обработать очередное сообщение.
И вот здесь просто автомат, то есть все переходы, которые в RAF-те есть,
они вот последовательно анализируются.
Так вот, если ты хочешь сделать конкурентное общение с этим автоматом,
то ты пишешь concurrency, все потоки и все RPC поверх этого всего.
То есть этот код, он ни с кем не общается по сети,
он получает на вход сообщение и возвращает тебе сообщение, которое он хочет отправить обратно,
и может быть написано это, которое он сделал, и что-нибудь еще.
Отдаст тебе список сообщений.
В этом проблемы нет.
Он реализован целиком последовательно, и вот это просто стоит машина.
Не знаю, чего это нас-то должно научить, в смысле.
Я не знаю, сколько это кратит, в смысле, это непроизводительно, конечно.
Ладно, на самом деле...
Что?
Почему непроизводительно однопоточная реализация?
Ну, тут snapshot-то делается последовательно, тут...
Ну нет, более-менее эквивалентно.
Но тут, смотрите, тут речь про другое все-таки.
Чаще всего в реализации параллелизма какой-то есть, его можно эксплуатировать.
Вы можете себе точно такое позволить, если вы...
Вот видите, здесь система...
В смысле, если вы используете этот рафт,
если вы шардируете состояние,
и на каждом узле у вас много вероценностей,
тогда даже вот что-то однопоточное вас совершенно устраивает,
потому что у вас много ассоциации,
тогда даже вот что-то однопоточное вас совершенно устраивает,
потому что у вас много однопоточных объектов на одном узле находится,
если они достаточно декомпозированы друг от друга,
то вы вполне можете позволить про релиз на уровне разных объектов
и утилизировать весь процессор свой.
Может быть, да, правда, в рафте мало последовательного итак,
скажем, в паксисе этого всего больше.
Но даже если у вас все-таки какой-то проелизм есть,
то если у вас много независимых RSM-ов на одной машине,
то вам этот проелизм, вы можете от него выйти в другом месте,
а сами отдельные RSM-ы использовать как автомат.
Причины здесь, я думаю, не связаны с эффективностью или нет.
Сейчас, давай вернемся на сайт.
Тут есть другие реализации, вот они все построены немного по-разному.
Ну вот, по-моему, только первая, она действительно однопоточная от других.
Там запускаются какие-то грутины, какая-то реализация есть.
В смысле, не так, у тебя среда, с которой ты работаешь,
в ней конкарнций много.
То есть ты получаешь сообщения одновременно,
ты там что-то пишешь на диск, ты что-то еще делаешь,
и ты, конечно же, эти вещи хочешь...
Ну, если ты можешь их делать параллельно или конкурентно,
ты там с ними так должен жить.
Не то, чтобы ты попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск, а чтобы ты не попал на диск,
а чтобы ты не попал на диск,
Такая реализация RAFTA, она обстраивается в любую инфраструктуру.
То есть, ты каким-то образом пишешь код, используя какие-то инструменты,
и реализация RAFTA не требует от тебя, чтобы ты вписывался в какие-то ее интерфейсы.
Интерфейс максимально общий, просто вызов методный.
А дальше ты можешь вставить совершенно произвольный код.
Вокруг этого написать произвольный код.
Конкурентный, многопоточный, многорутинный, или какой-то последовательный,
очень прямолинейный, ну как угодно.
Ну и плюс, конечно же, так гораздо проще RAFТестировать.
Если мы хотим протестировать реализацию, то тут есть разные цели.
Можно тестировать систему как черный ящик.
Но наши тесты тестируют наш код как черный ящик,
потому что они не знают, как именно он собирается работать.
Я не могу выбрать разные протоколы, разные сообщения добавить.
То есть я не могу это проверить.
Но если мы тестируем конкретно RAFTA,
то мы знаем, что если узел получает какое-то сообщение,
то он должен проявить какое-то такое-то сообщение, какое-то конкретное.
И имея RAFTA как отдельный класс автомата, мы можем тестировать,
ну просто unit-tester для него писать,
что если мы вкладем туда сообщение AppendEntrace,
то в ответ мы получаем такое-то сообщение.
Если мы вкладем сообщение TimeOut, то мы получаем другое сообщение.
Сообщение не TimeOut, а сообщение Tick.
Если мы хотим продвинуть время на автомате, мы говорим ему Tick.
Он тикает, увеличивает там черный ящик в себя.
Если мы говорим сообщение, он получает сообщение и возвращает нам реакцию на него.
И вот такой код тестировать проще, встраивать проще.
Поэтому он оказался востребан.
Тут есть другая реализация ногой, я не уверен, что она поддерживается,
кстати, уже.
Она написана более прямолинейно, в смысле с использованием конкарнс.
Ну вот такой вот урок.
Если вы сможете так сделать ради ГОГО,
но если вы не хотите думать, то есть чудесный человек,
который вас избавил от необходимости это делать.
Кстати, довольно смешно, что он пишет в начале, в самом первом просте серии,
почему он выбрал ГОГО.
Он говорит, вот конкарнс, есть имплюзия.
Ну я и не знаю, мне кажется, что результат, который получился,
он не то чтобы сильно пользуется конкарнсом,
он просто сильно выигрывает от нее,
скорее, конкарнс затуманивает алгоритм.
Однопоточный автомат, который просто получает сообщение,
он уж точно проще, чем все эти машины с селектами,
с каналами и с отменами, с постоянными перепроверками.
Перепроверки – это очень хрупкое место,
потому что вы забудете что-то проверить,
и в состоянии одного вы думаете, что другое.
Вот в коде с автоматом никаких проверок нет,
ошибиться сложнее.
Так что ГОГО не при чем.
То есть это, кажется, какие-то, ну не самые релевантные соображения.
Вот скорее ГО, но не то чтобы для рафта ГО нужен,
а вот как бы для всего кода, который использует рафт,
вот действительно ГО полезен, да.
Потому что все из коробки,
которые вы создали для того, чтобы по этике перекладываться,
ну вот вы перекладываете по этике.
А для самого рафта ГО, кажется, не очень нужен.
Сам рафт от него не выигрывает.
Ну вот вы как-то воодушевились от идеи
не писать ничего конкурентного,
просто в одном потоке все вызывать.
Но это, да, это...
В этом есть нечто очень разумное.
Тут заодно и все эвристики написаны,
всякие там приводы, кворумы, все...
Короче, вот...
Это довольно хорошая спецификация рафта,
потому что она читается еще лучше, чем...
Спецификация...
Она такая же не сложная, как Nutella Plus,
но уж точно проще,
чем большие логические формулы.
Ну и, конечно, понятнее, чем вот
вот это, например,
рассуждение про все эти перемены.
Тут, кстати, написано, как эти перемены
обновлять аккуратно в этой страничке,
поэтому неизбежно придется будет
аккаунт читать.
Ну что, на сегодня ты в национале.
Я думаю, что в ближайшие несколько дней.
Я думаю, что в ближайшие несколько дней.
Давайте план. В ближайшие несколько дней
я выкладываю рафт.
И в...
И к началу декабря я попробую сделать
для нас что-то
многопоточное параллельное.
И мы будем надеяться, что
хоть что-то у нас запустится.
Ну, то есть, как бы, я знаю, что
в библиотеке с конкарнсом и библиотеке с рекламой,
я думаю, что в ближайшие несколько дней
мы будем делать что-то
в библиотеке с конкарнсом и библиотеке с RPC
багов нет.
У меня осталось не набажить в слое
файловой системы.
Да.
Кода моего больше намного,
чем твоего, поэтому
я тебе довольно серьезно угрожаю
здесь.
Но мне кажется, что я уже
в самых важных местах
не ошибся, и там все проверено,
протестировано.
Вот переживет ли твой код
все это непонятно.
Стру таймом не переживет, потому что
стру тайма у нас не будет, как мы
понимаем.
А мультипрацис вполне можно завести.
И вот если мы это сделаем,
то мы увидим, что нам нужно просто бенчмарков
теста добавить к тестам
репозиторий, что без
оптимизации с групповым комитом, то есть
накапливанием бачек,
все остальные оптимизации вообще ничего не стоит,
потому что вы уплетите скорость
работы диска.
Если вы там сможете сто раз за секунду
в диск писать, то вы там сможете 100 км в секунду
вырабатывать.
И 100 тысяч км в секунду,
а там 100.
Это довольно
неэффективно.
Ну что, тогда
последний вопрос, уже не
к семинарам относящийся.
Нам нужно провести потерянное занятие.
Вам, наверное, нужно, и мне тоже хочется,
чтобы оно не пропало.
Вот.
Что?
Опрос
давно уехал из-за
нашей длинной беседы.
Я на него особо не надеюсь.
Но я вам предложу два варианта, либо
в сторону утра, либо следа вечера.
Может...
Чего это дистанционно? Нет.
Зачем дистанционно?
Что?
А
ты уже был.
Зачем себе ходить?
Ну, будет, но
ты переживешь, посмотришь в видеозаказ потом.
Вот.
Но про спанор, наверное, не будет
что-то принципиально нового, про
Кэрвин, про Ямуц Дипи. Я там довольно
в деталях мог бы закопаться
серьезно глубже.
Может быть, это там
Тайпония? Ну да, окей.
Вот. Но мне просто нужно знать,
какие варианты вообще у нас доступны.
Пересекаются ли моя возможность с вашими
возможностями?
Что?
Да.
Что?
Я бы сказал, что в субботу у меня тоже
была пара, но почему-то вы пошли в ТВКФ
в загадочном для меня обстоятельстве.
Не думал, что вас
так увлекает по жизни.
То есть, среда,
вторая половина дня вас больше устраивает, да?
Да.
Окей.
Тогда я смогу в 2 часа
к вам выехать
и в 4 часа приехать.
Вот если мы способны на такое.
Окей, тогда давайте придерживаться
пока такого плана.
А лекции по параллельному
курсу будут в пятницу,
правильно?
Я не знаю, что вчера была лекция,
но у меня ее не было.
Потому что никого в зуме не было,
и я...
Да, давайте тоже выясним,
что происходит, потому что вчера произошла
очень странная ситуация, мне кажется, что очень
некрасивая, и я бы не хотел в таком больше
участвовать.
Просто на самом деле можно очень красиво сделать вход.
Нет, подожди, нужно
разобраться, что пошло не так, потому что
было потрачено
время разных людей.
Но есть параллельный курс,
и я там должен прочесть 5 занятий.
И они вообще говорят,
не то чтобы...
Одно из них первое повторяет, более-менее,
то, что у нас было, краткий пересказ всего
за полтора часа.
Если выходит сюда бесполезно,
ну не бесполезно,
но в общем ничего нового вы не узнаете.
Следующие занятия они про
про звуки, про кавку,
про что-то еще,
про какие-то конкретные системы там,
как раз я мог бы какие-то параллельно вести с тем,
что было.
Но вчера случилось что-то непонятное,
потому что вроде бы
Олег мне сказал, ну в общем какие-то люди мне сказали,
что вроде бы занятие должно быть, но при этом там никого не было.
Ссылки не было
никакой. То есть я вот сейчас смотрю в чатик,
ссылки никакой не было, поэтому
нам просто не было куда подключаться.
Какой чатик?
Ссылка была?
Сейчас в эфирах не надо добавлять.
Это мне меньше всего нужно.
Но я хочу понять,
что произошло,
потому что вроде бы два человека сказали,
что они предупредили
вот кто-то с кафедры
и Олег Япченко.
Вот, и просто никто не знал,
что есть пара, да?
Короче,
по пятницам у нас занятия,
если что, вот на другом курсе.
Я не знаю, что будет в следующем,
я не знаю, что будет в следующем раз,
либо то, что было в предыдущем,
либо же кафка.
А, нет. Дальше там за уки, перкафка.
Короче, там, мне кажется, довольно полезные вещи.
Какой курс?
И вы сейчас не ходите на пары?
Возможно.
Непредсказуемо.
Я в этом ничего не знаю.
Ну, в общем,
я бы ожидал,
что в следующую пятницу,
в 12-20,
мы с вами должны увидеться.
То есть, если что-то пойдет не так,
и вы этого не ожидаете,
то поговорите со мной,
потому что я этого ожидаю.
И попрошу Олега все-таки разобраться,
что произошло.
Что?
Я не знаю, что, я не хожу.
Нет, но я, то, что мне неинтересно,
рассказывать не буду, конечно.
Нет, в смысле,
мне он не интересен,
потому что там рассказывают
о том, что больно,
что, конечно, важно.
Но мы здесь говорим,
как их делать.
Поэтому я по соусам
рассказываю, как она написана,
как она сделана внутри,
как и почему именно так.
Что делают остальные люди там,
я, честно говоря, не знаю.
Но судя по домашнкам,
вы там можете здесь
описать, пользоваться.
Правда?
Это дополняет картину,
но...
Так, есть win-win
стратегия в этом плане.
У нас же многие из этого курса,
из нашего вот этого курса,
они же ходят на параллельный курс.
Она в 15.30
в среду.
Ну, типа по расписанию.
Так что, раз они у нас в пятницу,
то можно эту занять.
Вот для пропущенного.
А мне казалось, что мы договорились
на среду уже.
Ну да, я просто говорю,
почему это еще один плюсик в кармах.
Я просто говорю о том,
что скорее всего так и будет,
что всем будет удобно.
Света нас устраивает, ты про это, да?
Да, просто там лексом мне как раз
там все удобно.
Прогуляно я вами занятия.
Да, да.
Отлично, все, хорошо.
Ну, ты можешь написать,
но он следующего занятия,
когда ему перекинем чар,
тогда все точно будет.
Понимаешь, у меня есть такой
косвенный, скрытый интерес
не подать в чужие чаты,
потому что...
Еще раз,
я не организатор курса,
я просто прихожу и трачу ваше время
потрачиться в этот момент.
Нет, я просто ассистент,
и я могу застегнуть.
Это хорошо, но правильный процесс
устроен не так,
что без ассистента, который
у меня нет сейчас,
понимаешь, что это процесс не самый
правильный.
И есть
сотрудника, когда
граница накатится.
За расписание.
За расписание, но вот
мне сказали, что я читаю векцию 5
и у меня вроде бы
и Олег опнул, что
предупредили, и она...
А звук такой-то должен быть
Ладно.
Я увидел, что
предупредили, я заметил.
Вот нужно, чтобы
такого не повторилось больше.
Так что я выражаю вас сейчас.
