Ну что, мы продолжаем нашу историю про конкурентность,
и давайте вспомним для начала, чем занимались в прошлый
раз.
Мы изучали устройство потоков, и я сказал, что для этого
мы изучим однопоточные фиберы, кооперативные однопоточные
фиберы.
И вот из понимания этих фиберов мы выведем для себя
понимание обычных поток.
Но у нас, точнее, у меня перед вами остался некоторый
долг, потому что, во-первых, я вас уверял, что если мы
поймем фиберы, то мы поймем потоки.
Хотя, конечно, фиберы отличались от потоков, они были кооперативные
и непараллельные.
Во-вторых, фиберы, которые мы в прошлый раз рассмотрели,
они не делали ничего полезного, они только запускались
и переключались.
На семинаре я поговорил про синхронизацию немного,
но по-прежнему эти фиберы не умеют общаться с внешним
миром, поэтому они, кажется, непригодны для исходной
задачи, которую они планировали решать, а именно построение
масштабируемых сетевых сервисов.
И я сегодня обещаю почти все эти проблемы исправить.
То есть сегодня мы научим фиберы быть параллельными,
одновременно запускаться на разных ядрах процессора,
а во-вторых, мы научим фиберы ввода-вывода.
Ну и давайте начнем с распараллеливания фиберов, а для этого я предлагаю
вам вспомнить один момент с прошлой реакции, который
может быть не слишком значительным, но мне кажется, что благодаря
нему мы сегодня фиберы распараллелим.
Помните, мы когда рассматривали пример, как фиберы работают,
мы говорили, что в этом примере самое необычное.
Это вот процедура yield, в которую мы заходим один
раз, выходим дважды с одной стороны в другом фибере,
а потом, в конце концов, возвращаемся обратно из
нее.
И вот там происходит некоторая магия, которую мы назвали
переключение контекста, и мы это переключение контекста
разбирали в прошлый раз.
Это такой, давайте я его открою, такой девайс, который умел
в себя сохранять состояние текущего исполнения с процессора
и активировать на процессоре состояние другого ранее
замороженного, ну или еще не стартовавшего ни разу
исполнения.
И обладая вот таким вот инструментом, который умел
операцию switch2, то есть сохранить состояние исполнения в
контексте слева switch2 и активировать состояние
контекста справа switch2, мы могли бы реализовать вот
наши кооперативные фиберы, потому что просто могли
бы переключаться с одного фибер на другой.
Но мы почему-то вот прямо так не сделали, то есть мы
не стали переключить фибер прямо на другой фибер, хотя
это в какой-то степени разумно.
Вместо этого мы ввели некоторую косвенность и сказали, что
между двумя фиберами всегда будет находиться планировщик.
То есть когда мы переключаемся, мы всегда передаем управление
не следующему фиберу, а планировщику.
Возвращаемся в цикл планирования, и он уже выбирает из очереди
следующий очередной фибер и запускает его, переключает
свой контекст на контекст этого фибера.
Этот фибер он либо еще не стартовал ни разу, либо
он уже находится внутри вызова yield, и этот вызов yield продолжится
после.
Вот вопрос, а зачем нам нужна была такая косвенность?
Ну, с одной стороны, она исправляла некоторые граничные
случаи, потому что у нас в конце концов есть там
фибер, у них есть свои стейки, а еще есть и основный поток,
в котором исполнится функция main, в которой исполняется
сам планировщик, ну и почему бы этот поток с его стеком
не отдать на исполнение цикла планирования.
Но мы увидим, что на самом деле так можно, так нужно
сделать, так следует делать еще по одной причине.
Но прежде чем я ее объясню, давайте я вам еще один пример
приведу.
Я, кажется, на семинарах, по крайней мере, рассказывал
про xv6, про учебную операционную систему в MIT, и вот там тоже
есть планировщик, разумеется, в этой операционной системе,
там есть многозадачность, там есть физическая параллельность,
и планировщик там тоже активный, то есть он переключает,
в нем есть цикл планирования, и вот он ищет очередной
процесс, который готов исполняться в состоянии runnable, и переключает
контекст планировщика на контекст этого самого
процесса.
Да и даже процедура переключения контекста там похожая, если
мы сейчас сможем ее быстро увидеть, то... секунду, сможем-сможем.
То процедура переключения контекста нам даже устроена
так же, как и наше переключение контекста.
Мы пушим на стэк, замораживаем его, замораживаем его исполнение
регистра, call you saved, потом переключаем стэки двумя
мувами, потом мы зеркально снимаем со стэка то, что
мы заморозили на нем.
Ну и у нас вот точно такой же код, просто для другой
архитектуры, поэтому немного отличается.
Ну вот, мы почему-то пренебрегаем возможностью переключаться
и добавляем вот эту косвенность в виде планировщика.
Это, да, делает наш код симпатичнее, делает наш код понятнее,
избавляет нас от некоторых граничных случаев, но все
же вот благодаря именно вот такой передаче управления,
благодаря тому, что там планировщик участвует, мы
можем сегодня увидеть, как эти файберы вот этот планировщик
сделать параллельно.
Но кажется, что задача не очень простая, потому
что вот мы смотрим на этот планировщик, и тут много
всего написано, и там разные очереди, контексты, переключение,
много сложной логики.
Но если вот вы смотрите этот планировщик, то в нем
есть две такие разные задачи.
Ну, во-первых, тут есть код, который переключает контексты.
Вот мы сохраняем контекст текущего исполнения в поле
файбера и активируем контекст планировщика, когда возвращаемся
в планировщик, ну и в обратную сторону, точно так же.
Это вот одни функции, которые планировщик, одни задачи,
которые планировщик решает.
Переключение контекста из файбера в файбер.
И вторая обязанность планировщика – это, собственно, планирование.
То есть он выбирает, какой файбер будет исполняться
дальше.
Вот для этого у него есть ранг-ю.
В планировщике вот мы видим одни поля про ранг-ю, другие
при переключении контекста.
И я не знаю, если у вас такое впечатление, но у меня оно
точно есть.
Мне кажется, что этот код, он очень монолитный.
Тут много разных задач сплавлено в один класс.
Тут и переключение контекста, и очереди, и планирование
этих самых файберов на единственный поток операционной системы.
И можно задуматься о том, а можно было бы этот код
как-то декомпозировать.
Вот что, если мы сможем как-то исключить из этого
кода планировщика, который, казалось бы, про планирование,
логику переключения контекста.
И вот оказывается, что если мы так сделаем, мы сейчас
этим займемся, то от планировщика останется только очередь,
и эту очередь уже можно параллелить.
Но вот мы этим недавно занимались, если вы помните.
У нас был полпоток.
Вот это наш план, такой короткий, пока очень туманный.
И давайте я даже не буду вас спрашивать, какую бы
абстракцию, какой бы механизм тут можно было выделить
при переключении контекста, а просто расскажу вам.
Этот механизм называется, если вы хорошо знаете программирование
и наблюдаете его в течение последнего полувека, то
наверное, вам механизм известен.
Но, возможно, нам он неизвестен, поэтому скажем, что этот
механизм – это корутина или сопрограмма.
Я буду говорить, наверное, и так, и так.
Обычно люди называют корутина.
Корректнее говорить сопрограмму, я, наверное, буду путаться.
Но попробую сопрограмму говорить сегодня.
Итак, сопрограмма или короутинг, по аналогии с подпрограммами,
это процедура, которая отличается от подпрограммы тем, что
в нее можно зайти несколько раз в один вызов этой сопрограммы
и несколько раз его покинуть.
Для этого у сопрограммы есть операция, для того, чтобы
остановиться внутри исполнения, внутри вызова, у сопрограммы
есть операция suspend, а для того, чтобы потом возменить
сопрограмму, есть операция resume.
Ну, эта сопрограмма естественным образом расширяет понятие
подпрограммы, subrouting, потому что у подпрограммы есть только
одну точку входа, в один раз ее вызываете, в один раз
она завершается, возвращает вам управление.
Вот в сопрограмму, в вызов сопрограммы можно заходить
несколько раз и несколько раз возвращаться из него
обратно.
И вот именно эта сущность в себе инкапсулирует логику
переключения контекста, и мы ее из планировщика
сможем изъять.
Ну, вот давайте посмотрим, как сопрограмма себя ведет.
У нас, вообще говоря, строго говоря, сопрограмма – это
некоторая сущность на уровне языка программирования,
то есть она как-то синтактически может быть представлена
и должна быть.
Вот наш класс coroutine, сопрограмма – это не прямо сопрограмма,
это скорее вызов сопрограммы, если быть строго, вызов
сопрограммы, который исполняет вот эту процедуру.
И вот видите, здесь операция suspend остановится, и у сопрограммы
есть операция resume возобновить исполнение.
Здесь мы конструируем экземпляр класса coroutine вызов сопрограммы.
И в этот момент пока ничего не происходит, мы просто
ее создали.
Дальше мы печатаем step1, и вот здесь вот уже мы первый
раз стартуем сопрограмму.
Мы начинаем ее вызов, говорим resume, и в этот момент управление
передается из этого вызова вот сюда.
Печатается step2, после чего сопрограмма встречает
операцию suspend для остановки и возвращает управление
к тому коду, который вызвал сопрограмму.
То есть мы заходим suspend и выходим из этого resume, возвращаемся
из него.
Но опять, нелокальная передача управления, оно окажется
после файберов, это не должно уже нас так удивлять.
Мы печатаем step3, после этого говорим resume, и возвращаемся
в вызов сопрограммы, выходим из этого suspenda, печатаем
четвертый шаг, и после этого вызов сопрограмма завершается.
Но вот это был один вызов, и мы в него зашли дважды.
Вот первый резюм, вот второй резюм.
Первый раз мы начали исполнение со старта процедуры, второй
раз мы вышли из этого suspenda.
Ну давайте, чтобы убедиться, что все работает так, как
должно, запустим и посмотрим, да.
Вот все произошло предсказуемо.
Пока ничего удивительного, да?
Все как обычно, хорошо.
Дальше можно заметить, что у сопрограммы, видимо,
вероятно, есть свой собственный stack.
Вот наши сопрограммы, которые мы здесь рассматриваем,
они носят название stackful сопрограммы, видимо, потому
что у них есть stack, потому что в самом деле мы создали
сопрограмму, которая будет исполнять функцию foo, и в
функции foo мы вызвали функцию bar, в функции bar мы вызвали
функцию bus, в функции bus мы собираемся остановиться.
И если мы запустимся и вот встанем на этом брейкпойнте,
то мы увидим, что мы находимся на стэке foo bar bus.
И когда мы наступаем вот на этот suspend, то мы фактически
останавливаем весь этот stack вызовов, то есть внутри
сопрограммы он был, и вот мы из этого stack выпрыгнули.
Все три вызова в сопрограмме заморозились как будто бы.
Есть и другие сопрограммы, они называются stackless
сопрограммы.
Ну, тут можно подумать, что у одних stack есть, а другим
stack как будто бы не нужен, но это, разумеется, не так,
потому что любому коду, чтобы исполняться, нужен
call stack, чтобы просто двигаться по вызовам функций.
Так что разница немного… конечно, речь про stack, но
разница немного тоньше, и придет время, мы об этом
поговорим.
Вот пока сегодня мы говорим про сопрограммы, которые
реализуются прямо нами на уровне библиотеки, и мы
называем такие сопрограммы stackless сопрограммами.
Как видно, сопрограммы напоминают файберы, ну, потому что
эти и другие умеют запускаться и останавливаться, и в тех
и других есть нелокальная передача управления, и
она реализуется с помощью механизма переключения
контекста.
Но все же разница между файберами и коррутинами
есть.
Давайте посмотрим такой пример.
Вот, собственно, где коррутины и файберы будут связываться.
Здесь мы запускали коррутину из… коррутина, начинаю
говорить, сопрограмму из вот этой функции, вот
дважды ее возобновляли.
У нас была одна сопрограмма, а в этом примере все немного
интереснее, потому что у нас здесь сопрограммы две,
каждый из них делает по два шага, каждый из них делает
suspend между двумя этими шагами, и мы чередуем исполнение
этих сопрограмм.
То есть мы делаем первый шаг – первый, первый шаг
– второй, потом снова первый шаг – первый, потом снова
первый шаг – второй, и печатаем что-нибудь, что-нибудь такое.
Один, два, один, два.
Вот видите, это же вот в чистом виде конкуренция.
У нас есть две сопрограммы, мы чередуем их исполнение.
Вот чередование – это же вот как будто бы про файберы,
но нет, файберов пока никаких нет, это именно сопрограммы,
и я бы сказал так, что вот конкуренция – это единица
конкуренции вообще на свете, это сопрограмма, вот она
в чистом виде эту идею выражает.
Я на первой лекции говорил вам, что конкуренция и параллелизм
– это вот вообще перпендикулярные вещи, может быть одно без
другого.
Вот в прошлый раз у нас были однопоточные файберы,
в которых никакого параллелизма не было, но там еще были
планировщики, очереди, вот какая-то дополнительная
механика.
Здесь сопрограмма – вот это вот чистое представление
конкарнации.
Но все же, вот файберы и сопрограммы – это разные
вещи.
Да, они похожи, да, они локальная передача управления, механизм
приключения контекста, свои стейки, чередование
на процессоре, но в чем же разница?
Вот когда мы говорим про файберы, то мы имеем в виду
как правило кооперативную многозадачность.
У нас есть какие-то независимые исполнения, там обработчики
запросов пользователей.
Они чередуются на процессоре, потому что разных пользователей
нужно обслуживать одновременно.
Эти обработчики, эти активности могут друг с другом синхронизироваться,
то есть файберам, наверное, нужны приметилы синхронизации
– мьютексы, кондвары, каналы и так далее.
Файберам, безусловно, нужен планировщик, который будет
их запускать.
Он будет решать в каком порядке, какие файберы будут запускаться
вообще.
Ну и файберы могут быть однопоточными, как в прошлый
раз, и могут быть и многопоточными, то есть они могут одновременно
исполняться на разных ядрах.
Тут никаких, вроде бы, ограничений в этом нет.
Крутины, сопрограммы гораздо проще устроены.
Вот они гораздо ближе просто к обычным функциям.
Они не связаны с потоками совсем.
Тут про параллелизм никакой речи не идет.
Сопрограмма – это как будто бы вызов функции.
И он ведет себя как вызов функции еще и потому, что,
скажем, с исключениями работает также.
То есть если мы вот запустили сопрограмму, и в ней было
брошено исключение, которое не было в этой сопрограмме
обработано, то это исключение вылетит на руль через вызов
резюм, и коллер его должен обработать.
Ну и собственно, роли такие же, как в вызовах функций,
вызовах процедур.
Есть коллер, который вызывает сопрограмму, и есть колли
– это сама сопрограмма.
Ну вот такие же роли, как в обычном структурном
программировании.
Параллельности нет, никакой конкуренции прямой здесь
в понятии сопрограммы нет, примитива в синхронизации
для сопрограммы не нужна.
Это скорее более базовый инструмент, более примитивный,
в смысле более универсальный поэтому.
Вот видимо, сопрограммы будут участвовать в построении
файберов многопоточных, ну или однопоточных, даже
не очень важно.
Но применение сопрограмм файберами не исчерпывается,
поэтому я вот хочу показать вам, как сопрограммы могут
быть полезны сами по себе.
Более того, они были придуманы как раз, ну, они были придуманы
даже не для многопоточности, не для конкуренции, а для
других задач.
Но перед этим маленькое замечание.
Чем сопрограммы отличаются, скажем, ну как можно разделить
в своем уме понятие сопрограмма и понятие переключения контекста,
execution контекста, который у нас был.
Вроде бы и то, и другое чем-то похоже, то есть мы нелокально
придаем управление, тоже какие-то классы, вот как
можно различать корутину и переключение контекста.
Ну, я бы сказал так, что сопрограмма – это сущность, которая,
как правило, имеет некоторое представление на уровне
языка программирования.
Вот эта сущность в языке программирования.
У нее есть просто лексическое представление какое-то.
Вот вы в языке можете сопрограмму описать.
Контекст исполнения – он гораздо ниже находится
на уровнях абстракции.
Он про процессор, он про регистры.
Вот на уровне языка программирования у такого execution контекста
никакого представления нет, конечно.
Ну вот, я вас убеждаю, что сопрограмма – это сущность
самостоятельная, у нее есть свой собственный независимый
смысл и можно применять ее без относительно конкуренции.
Ну и давайте я расскажу вам пример, который мне кажется
очень красивым.
Он связан с итерацией.
Вот представим себе, что мы пишем итератор.
Мы пишем итератор, скажем, по контейнеру эстедалист,
который устроен, видимо, как двусвязанный список.
Вот как будет выглядеть состояние итератора?
Итератор – это объект, у которого есть метод плюс-плюс
или move to next или что-нибудь подобное.
То есть сделать шаг вперед, сдвинуться к следующему
элементу контейнера.
Вот как мы опишем состояние итератора?
Какие у него будут поля просто?
Ты что-то сложное говоришь.
Я думаю, что состояние итератора – это указательный
текущий узел двусвязанного списка.
Этого тебе хватит, чтобы двигаться вперед-назад.
Вот, то есть один pointer просто.
На каком узле списка мы сейчас стоим?
Ну, конечно, итератор знает про внутреннее устройство,
но обычное дело.
А теперь представим себе, что у нас не односвязанный
список, а бинарное дерево.
Ну, откуда оно взялось – совершенно неважно.
А важно, что мы просто можем его построить.
Вот мы строим бинарное дерево.
У него есть внутренние узлы, есть листья.
И мы хотим построить итератор.
Мы хотим написать вот такой вот код.
Мы уже его написали, мы хотим итератор написать,
который бы работал.
То есть мы хотим итерироваться по дереву
и вот в цикле выводить данные очередного узла.
Вот давайте подумаем, как выглядит состояние
такого итератора.
Указатель?
Какая-то магия.
Я, наверное, не понял от тебя.
Во-первых, одного pointer будет мало.
У нас здесь дерево без polyparent.
Да.
Ну, вообще, как написать состояние,
как представить себе в уме такой вот итератор,
который ходит по дереву.
Его состояние – это узел в этом дереве,
где он сейчас стоит.
Ну, путь в дереве, грубо говоря.
А еще нам важно помнить, как мы в этот узел попали.
То есть мы пришли оттуда сверху, спустились.
Мы вернулись из левого по дереву.
Мы вернулись из правого по дереву.
Потому что без этого мы не знаем, куда идти дальше.
Вот.
Ну, короче говоря, у нас есть путь и плюс вот
три варианта, откуда мы пришли.
А теперь представьте, что вы пишете вот такой вот
итератор, который двигается так по дереву.
Я думаю, что это сложно было бы написать, да?
Ну, по крайней мере, не так приятно, как со списком.
Пришлось бы какие-то случаи обрабатывать как-то вот…
Ну, вместо этого можно поступить проще.
Вместо этого можно представить себе…
То есть если бы вас заставили такое писать,
вы бы не стали так делать.
Вы бы сказали, что давайте я лучше напишу рекурсивный
обход дерева.
Ну, потому что итератор для дерева делать неудобно.
Лучше я напишу вот такую рекурсивную процедуру
Три Волк, которая ходит по дереву в инордере.
Идет влево сначала, потом вправо.
И когда она приходит в узел,
то просто вызывает какой-то колбэк.
Делает обратный вызов, вызывает пользовательский
обработчик, и вот этот обработчик обрабатывает
очередной узел.
Если мы хотим вывести все узлы дерева в инордер-обходе,
то мы строим вот такой колбэк,
передаем его в рекурсивную процедуру,
и она уже реализуется совершенно тривиально.
Ну, то есть удобный способ написать итерацию по дереву –
это вот такая рекурсивная процедура.
Кажется, мы в этом не сомневаемся.
Мы сейчас говорим не про то,
как написать самый эффективный код,
а про то, как написать самый понятный код.
И, как правило, люди ставят приоритеты так.
Они сначала пишут хороший код,
а потом в рамках текущих абстракций
пытаются его оптимизировать.
Если абстракции хороши, то это получается сделать.
Вопрос, на самом деле, разумный,
т.е. стек всегда может переполниться,
но, в общем, мне кажется,
что гораздо проще решить эту проблему
в нашем случае, чем решать проблему
с нерекурсированным обходом дерева.
Но вопрос разумный, да.
Я сейчас скорее говорю не про то,
как делать это супероптимально,
а про то, как…
про инструменты выразительности,
про то, как писать код.
Вот так писать код гораздо проще для итерации по дереву.
Использовать обратные вызовы, использовать колбэки.
А теперь подумаем.
Вот мы вызываем колбэк.
Здесь вот, да?
Вот как описать состояние
нашей процедуры обхода рекурсивной?
Вот мы находимся здесь.
Вот здесь это что значит?
Ну, мы находимся где-то в рекурсии.
Мы находимся в каком-то узле,
и мы к нему пришли через цепочку рекурсивных вызовов.
И вот эта цепочка рекурсивных вызовов,
вот call stack,
это же буквально путь в дереве.
Вот каждый стековый фрейм, каждый вызов,
это обработка какого-то узла.
А еще, мы же в этом рекурсивном вызове
могли…
Ну, где мы можем находиться? Мы можем находиться вот здесь сейчас.
Мы можем выходить отсюда, можем заходить сюда,
можем заходить сюда, возвращаться отсюда.
Ну, короче говоря, у нас есть еще…
Помимо… Если мы хотим описать
мгновенное состояние этой процедуры обхода,
то мы говорим, что у нас есть call stack, во-первых,
а во-вторых, есть instruction pointer,
где мы сейчас стоим.
В каком месте этой процедуры?
И вот смотрите,
представьте себе обычный итератор
нерекурсивный. У него есть состояние,
вот там, stack, путь в дереве,
плюс состояние, откуда мы пришли,
слева, справа, там, сверху,
слева, справа.
Есть декурсивная процедура,
и ее состояние,
это call stack,
тоже, по сути, путь в дереве,
и instruction pointer, которые, по сути,
то же самое. Откуда мы пришли?
Сверху, вернулись слева,
вернулись справа.
Вот кажется, что очень похожие вещи.
А теперь внимание, что такое
сапрограмма? Это вызов,
из которого можно выпрыгнуть, который может
завершиться, ну не завершиться, а приостановиться.
И у сапрограмма появляется состояние,
у остановленной сапрограммы появляется состояние,
в каком стеке она сейчас
находится, в какой цепочке вызовов
она остановилась,
и где у нее стоит instruction pointer.
И вот понимая это, что вот, по сути,
сапрограмма сохраняет состояние,
которое нужно было бы итератору нашему,
можно написать
гораздо проще код, если у нас
вот есть такой волшебный инструмент.
Смотрите,
мы строим итератор, он получает
корень дерева и
конструирует сапрограмму.
Что она делает?
Она вызывает
рекурсивную процедуру treewalk.
И в этой рекурсивной процедуре мы идем
влево, идем вправо,
а между этими шагами мы
запоминаем, на каком узле
мы сейчас стояли, запоминаем данные из этого
узла чуть точнее.
После этого
говорим suspend,
приостанавливаем сапрограмму, мы выпрыгиваем
из этого рекурсивного вызова.
То есть мы фиксируем текущий
путь в дереве, мы при suspendi,
переключая контекст, фиксируем
в том числе instruction pointer,
как мы делали на прошлой лекции,
и выпрыгиваем
вот сюда.
Ну, точнее, выпрыгиваем из этого вызова
resume в moveToNext. Вот moveToNext
это значит возобновить исполнение
сапрограммы. Она
возобновляется, встречает очередной
suspend, и вызов
moveToNext завершается.
После этого мы можем вызывать метод
data, потому что мы знаем,
что перед suspend
корутина сапрограмма
запомнила в итераторе
фактически указательные текущие данные.
И вот мы с помощью
сапрограммы просто выпрямили рекурсию,
выпрямили ее в итерацию.
Вот это, мне кажется, ну, я не знаю,
как на ваш вкус, на мой вкус это
безумно красиво.
И вот мы фактически
взяли переключение контекста, мы
взяли рекурсивную процедуру, проанализировали,
что stack и instruction pointer – это
буквально состояние нерекурсивного обхода
дерева, и
сапрограмма здесь
такой клей, который склеил
наш линейный обход
и вот рекурсивные вызовы.
Скрыл для нас вот эту рекурсию.
Без сапрограммы мы такой код написать
бы не смогли. Ну, то есть мы бы смогли
написать код нерекурсивного обхода,
но он был бы очень сложный, очень непонятный,
его бы никто не прочитал. Этот
код читается очень просто, потому что, ну, вот он
тривиальный. Идем левое по дереву, идем вправое по дереву.
Можно эту идею
развивать и дальше.
Можно...
Ну, во-первых, все понятно пока.
Нужно ли что-то пояснять?
Вопрос? Нет?
Тогда следующий пример. Он уже
немного хитрее.
Точнее, я расскажу идею, этот самый пример
слишком сложный, чтобы целиком описывать.
Вот мы воспользовались
сапрограммой для того, чтобы
скрыть, ну, вот выпрямить рекурсию
для пользователя.
Написать итератор по рекурсивной структуре данных.
Но рекурсия, она же в программировании
встречается не только в виде
структур данных, она встречается
еще где?
Но где вы с рекурсией встречаетесь
в программировании?
В программировании.
Ну, ладно.
Если вы изучаете языки
программирования, давайте я так скажу,
то рекурсию вы встречаете в двух местах.
Во-первых, в виде
структур данных, во-вторых, в виде синтоксических
деревьев.
Вот синтоксические структуры в языке
это деревья, как правило.
По ним тоже нужно ходить.
Вот когда вы что-то парсите, вы
строите дерево.
Вы пишете какой-то рекурсивный парсер, который там
спускается там влево, вправо, в эфирических выражениях.
И вот дерево образуется.
А теперь представим
себе такую задачу. Ну, она выглядит довольно абстрактной,
в смысле довольно далеко от вас,
но тем не менее она возникает. А представьте,
что вы пишете какую-нибудь
сложную, распределённую систему,
которая вычисляет что-то,
делает какие-то вычисления, и вы
парсите поток данных из сети, и парсите
в нём, скажем, джейсоны. Ну, не важно что-то.
И вот
у вас есть процедура рекурсивного парсинга
вот такого-то джейсона. Ну, не знаю, дерево вы
строите, в конце концов.
Вам удобно писать в виде рекурсии.
Но при этом
вы парсите не статическую строчку,
которая у вас уже есть, а вы парсите
поток, который вы читаете из сети.
А его прямо сейчас нет, он
кусочком к вам приходит.
Вы читаете соки, то получаете очередной чанк.
И
вы не можете прямо в рекурсивной
процедуре запускать какое-нибудь блокирующее
чтение, которое даст вам очередной чанк,
потому что вы блокируете поток целое.
Мы этого не хотим делать. Это как бы вторая наша
половина истории сегодня.
Так вот, вам хочется как-то отделить
собственно парсинг рекурсивный
и вычитывание данных из сети,
сделать его синхронным.
И
сопрограмма – это способ
как одно отделить от другого, потому что
это тот же самый рекурсивный обход дерева,
который
можно выпрямить
и вот между...
и запускать вот этот самый
move to next только после того,
как у вас появится очередная порция данных.
Вы загрузите очередной
чанк из сети, возобновите
сопрограмму, которая парсит там очередной
JSON, она где-то в середине остановится,
потому что данных не хватает, и вы вернетесь
к себе и вот дальше
запланируете очередное синхронное
чтение. Но это может быть сложный пример, сложно
представить себя, но
давайте я покажу немного
более простой пример.
Вот с помощью сопрограммы можно
строить не только итераторы, можно строить
ну, генераторы можно строить,
здесь называется процессор.
Процессор – это такой объект,
который представляет собой исполнение,
у которого есть минут ресив.
Вот вы можете
что-то получать снаружи.
То есть, когда вы вызываете ресив
и ожидаете строчку,
то вызов этого процессора
останавливается до тех пор, пока строчку вам снаружи
не передадут. Не передадут ее
с помощью метода send.
Вот здесь вот,
смотрите, у нас такая цепочка.
Я строю ридер, который
получает откуда-то чанки.
Вот кусочки байт,
ну, какие-то порции байт.
Этот ридер берет и эти
чанки разбивает на символы
и кормит этими символами
токенайзер.
Токенайзер что делает? Он
пожирает эти символы по одному
и бьет
поток этих символов на слова.
И кормит
ими принтер. Принтер их печатает.
Вот представьте себе, что было бы,
если бы вы писали это
на процедурах
обычных, на вызовах.
Вот вам неудобно было бы писать
этот токенайзер процедурой, потому что у него есть
состояние. У него есть текущее накопленное
слово.
Если бы вы писали с помощью
обычного программирования, обычных там вызовов
функций, то вам бы пришлось
склеивать цикл
чтения
данных и
вот этот перемен и состояние токен
текущий. У вас они были бы
в одной функции. Это как бы
нарушение просто границ слоев.
Здесь
код, который получает данные
откуда-то, неважно,
ничего не знает про это политокен.
Про эту локальную переменную.
Она целиком спрятана вот в этом процессоре.
И вот токенайзер, он только про
собственно токенизацию, про взбиение
на слова. Он не знает
ничего, откуда данные берутся и
кто их дальше будет обрабатывать.
Ему безразлично.
Вот без сопрограмм
код с такой вот
изоляцией написать трудно.
И смотрите, что интересно.
Сопрограммы
это понятие, оно довольно
базовое, точнее оно супербазовое.
Это вот такое естественное
расширение понятия под программой.
И придумали его очень давно.
Вот придумали его
сейчас я найду
буквально
60 лет назад.
В 1963 году.
Это довольно удивительно,
потому что в C++ сопрограммы появились
только в C++20, то есть спустя
ну вот сколько времени.
Это, конечно, интересный вопрос, почему
так долго потребовалось? Почему так много времени
потребовалось? Потому что
сопрограммы появились, но перед тем, как они
появились, люди долго думали, о каком виде они
должны появиться. Были разные варианты, и вот
все могло сложиться по-другому.
Короче, вопрос сложный.
Да, и в C++
сопрограммы добавили именно
для того, чтобы делать асинхронность.
Чтобы запускать конкурентные
исполнения, которые бы там работали
с водом-выводом. Короче говоря,
делать, ну это не то, что файбер,
но вот конкурентность делать.
Но если мы вернемся в прошлое,
посмотрим на историю, то
сопрограммы появились как раз,
когда сопрограммы появились
в 1963 году, никакой конкуренции, конечно,
не было, и
они были задуманы для того, чтобы люди
писали компиляторы.
Вот буквально, была задача
декомпозировать разные
стадии компиляции.
И сопрограммы
это вот тот механизм, который изолирует одну
стадию от другой. Вот я пытался это вам
передать вот этим примером.
Короче говоря,
сопрограммы отличаются
от файберов, это более базовый
механизм, он скорее проузов функции,
и он позволяет вот эти функции декомпозировать
друг от друга, и вот выстраивать между ними
такой конвейер, pipeline.
Вот можно представить себе, что это такие шестеренки,
которые двигаются, ну, у них разное количество
зубьев, у них как бы разный масштаб,
тут строчки, тут символы, и вот они цепляются
друг за друга, и вот вместе работают.
Но
для нас, конечно же, корутины
интересны, потому что мы собираемся
из них строить файберы,
делать многопоточность. Вот для нас
сегодня сопрограммы – это
дорога к такому параллельному
многопоточному ГО.
Да.
Ну, в этом примере, может быть, можно было бы,
но
как тебе сказать, ты чертовски
прав.
Но пока я не могу тебе объяснить, насколько
ты прав.
Ну,
да, ну, скажем,
класс с методами, вот здесь ты мог бы
еще написать, но если бы у тебя
процедура, тут, смотрите, тут есть токеназер,
а после токеназера обычно парсер идет,
а парсер декурсивный, и вот
все, класс бы ты там уже не написал.
Во-первых, да?
Да, точно бы не написал.
А во-вторых,
во-вторых, ты прав. Иногда все-таки
можно написать класс, но мы к этому вернемся
через полтора месяца.
И я отвечу на твой вопрос, так ты.
Ну вот, мы
хотим, значит, пока с такими примерами
покончить на сегодня
и поговорить про параллелизм.
Вот для нас
сопрограмма – это дорога к параллельным
файберам.
Вот мы хотели бы с помощью этого
с помощью этих сопрограмм
взять наш планировщик
однопоточный для файберов.
И вот эти переключения контекста
из него спрятать.
Ну вот, в самом деле, смотрите,
у нас есть планировщик, он запускает
файбер. Файбер работает, доходит
до точки остановки, до какого-нибудь иилда,
возвращает управление планировщику
и вот выбирает новый
файбер. Вот
смотрите, у планировщика
и у файбера есть некоторая
иерархия. Вот планировщик запускает файбер,
и файберы у него возвращаются. Только так устроена передача управления.
И это же вот похоже
на тот
сценарий, с которым работают сопрограммы.
У нас есть колер, который говорит резюм
на сопрограмме. Сопрограмма возобновляется,
работает, встречает точку suspend
и возвращает управление обратно колеру.
Вот давайте подумаем, как теперь можно
планировщик наш декомпозировать
помощью сопрограмм?
Ну вот, как будто бы каждый файбер
это сопрограмма, да?
И мы резюмим эту сопрограмму.
Она работает, потом встречает
yield, потом возвращается обратно.
Ну, я бы сказал, что это не
точно. В смысле, файбер
это не только сопрограмма. Вот давайте
я вам покажу, как файбер мог бы
выглядеть.
Ну вот, у файбера чуть
больше полей, чем одна сопрограмма.
Но сейчас
это не очень важно. То есть пока можно
представить себе, что да, действительно
пусть файбер – это почти
то же самое, что сопрограмма.
И вот мы можем
эту логику вынести из планировщика
в сопрограмму, в отдельный класс.
А что
станет тогда в планировщике?
Давайте
по-другому. А что он вообще будет делать?
Ну, в нем по-прежнему есть очередь,
потому что планировщик, он про порядок
исполнения же, да? Он выбирает, в каком
порядке файберы запускаются.
А что значит запустить файбер?
Отлично.
Вот давайте теперь подумаем. Вот есть планировщик
такой монолитный. Мы из него вынесли
сопрограмму файбера.
В нем осталась очередь и запуск.
Запуск чего?
Ну, сопрограмм, да?
А с другой стороны, нужно
ли планировщику знать, что он запускает
сопрограммы?
Давайте вот склеим две последние лекции
просто сейчас.
Ну, смотрите, вот сопрограмма, она же
не про параллелизм, в конце концов.
Вот даже если мы скажем, что файбер, он
примерно похож на сопрограмму,
то как
исполнять вот такие вот сопрограммы файберы
параллельно?
Вот у нас есть тредпул. Это в конце концов
просто очередь, да? Очередь, которая запускает
задачи. Какие-то, неизвестно какие.
Неважно, какие задачи. Просто кусочки
синхронного кода, которые не блокируются.
Ну, а теперь давайте представим себе
что такое запуск
файберы. Вот мы стартуем
файбер.
Как это представить себе в коде?
Ну, в уме пока, разумеется.
Очереди. Какой у нас очередь?
У нас нет большей очереди. У нас есть пул потоков.
Смотрите.
Вот у меня сопрограмма.
И вот я бросил ее в пул потоков.
Вот пул потоков. Вот сопрограмма.
Я вот бросил сопрограмму в пул потоков. Сделал там резью.
И вот
кусочек этой
сопрограммы исполнился.
Потом она завершилась.
Ну, я дождался этого таким вот примитивным образом.
Потом бросил туда еще раз.
Она сделала второй шаг.
А что если у меня теперь много таких сопрограмм?
Я их бросаю все в пул потоков.
Ну, они исполняются параллельно.
И теперь я говорю, что сопрограмма,
ну, файбер, он включает
себя сопрограмму.
Собственно, исполнение файбера – это исполнение сопрограммы.
Когда оно запускается в пуле потоков,
ну, просто туда, чтобы запустить файбер
в пуле потоков, нужно
в пул потоков бросить задачу,
которая что сделает?
Резюм сопрограммы.
И что получается?
Ну, давайте пока
с этим остановимся.
Вот уже прямая дорога к параллельности
файберов.
У нас есть отдельность программы, отдельно пул потоков,
совмещаем их и получаем вроде бы
параллельное исполнение.
А что такое Yield в файбере?
Вот, в конце концов, чтобы сделать файбер, нужно написать Yield.
Вот что будет делать Yield?
Ну, я сказал уже, что сопрограмма
и файбер – это не совсем одно и то же.
Вот Yield приостанавливает
файбер.
После этого, ну, вот в однопоточных файберах как было?
Yield передает управление планировщику,
планировщик выбирает следующий файбер и запускает его.
Просто сделать suspend мало.
Ну, вот, да,
после Yield мы же хотим
попасть в конец очереди сами.
Но правда, у нас нет теперь очереди, у нас просто
есть пул потоков.
Поэтому, когда мы сделаем Yield, мы что сделаем?
Мы
сначала выполним suspend
сопрограммы.
Она становится
и после этого
в той же задаче пула
потоков
мы сделаем еще один
submit прямо из этого пула,
который добавит, который
снова нас запланирует на исполнение.
И если в планировщике,
если в пуле потоков есть вот такая
глобальная общая очередь,
то вот буквально мы переместимся в ее конец.
Но при этом, то есть у нас теперь задача
в пуле потоков – это не просто резюм
сопрограммы, это резюм
сопрограммы, после чего мы перепланируемся.
Схватили все?
И смотрите,
в этой конструкции, во-первых, получается
параллелизм совершенно тривиально.
То есть мы разделили пул потоков,
мы разделили планировщик на сопрограммы
и пул потоков,
это вот параллельно, это вот
независимо, а дальше мы их комбинируем,
причем пул потоков
понятия не имеет о том, что он
запускает, он запускает задачи
совершенно
непрозрачные ему,
а файберы
ничего не знают про пул потоков,
они пользуются только тем, что у
пул потоков есть метод Submit,
в который можно бросить задачу.
И вот мы получили
две совершенно перпендикулярные сущности,
которые друг про друга ничего не знают,
которые хорошо комбинируются
и которые полезны сами по себе,
они универсальные. Вот
пул потоков, он нужен для
файберов, допустим, а еще нужен просто для того,
чтобы какие-то вычисления делать
или там, не знаю, фьючи,
кулбеки для фьючи исполнять.
Он полезен сам по себе
и не знает ничего про файберы.
Также есть программа, она полезна сама по себе,
с помощью нее можно делать итераторы, с помощью нее
можно делать вот такие вот конвейеры
из таких зацепленных модулей,
а можно делать файберы.
Вот две штуки
полезные сами по себе и при этом, которые
хорошо сочетаются.
Между ними есть очень тонкая граница,
очень простая,
очень простая граница,
всего лишь один метод – сабмит.
Файберы рассчитывают, что
задача, запланированная через
сабмит, и в Энчуре исполнится,
где-то исполнится.
Вот этого достаточно,
вот такого знания достаточно файбером,
чтобы научиться,
ну, запускаться, научиться делать
yield, научиться делать,
ну, что еще можно делать.
Mutex'ы потом можно делать.
Уже файберные,
разумеется, которые не блокируют потоки.
Можно каналы делать.
Можно там
Select делать, как в Go.
И вот для того, чтобы
так вот в эту сторону файберы развивать,
нам не нужно знать ничего
про планировщика, кроме того,
что в нем есть один метод – сабмит.
И все благодаря тому, что мы вот
придумали с программы.
Ну, не мы придумали, а кто-то когда-то придумал
с программой.
Кажется, что очень мощная идея.
И ровно по этой причине
с программой есть
буквально в любом языке
программирования современным.
Ну, и не в современном тоже,
но в современном точно должны быть.
Я думаю, что вы с ними знакомы
по языку Python.
Ну, в C++ мы их тоже
в этом курсе изучим
когда-нибудь.
Итак, мне кажется, что
я объяснил, зачем...
объяснил, что такое
с программой,
как они могут быть полезны,
в каких сценариях, и как с помощью
них распролелить файберы.
Получилось у меня или нет?
Убедил я вас.
Хорошо, тогда можно
заняться чем-то совершенно другим.
А именно поговорить...
Ну, у нас две задачи было на сегодня.
Во-первых, как файберы распролелить.
Что?
Что?
А как резюм suspension?
Тоже.
Ну, конечно же,
это домашняя работа.
Вообще
все к этому идет. Я обычно на лекции рассказываю,
что мы хотим сделать, а в домашних ты это делаешь.
Так это обычно устроено.
Но в двух словах, примерно же понятно,
что такое резюм и suspension.
Это переключение контекста.
То есть нам снова нужен execution
контекст, мы как-то им пользоваться будем.
А как именно, ну вот, придется самому подумать.
Так нам и в файбере нужно было это понимать.
У нас для этого был трамплин, помнишь?
Вот такая же история.
Так, а вторая
половина
сегодня, это вот вывод.
То есть файберы научатся быть параллельными,
но пока файберы не умеют общаться с внешним миром,
они бесполезны для нас.
Да.
Тебе или...
Ну как же, мы же построили
вот специальный execution контекст,
и он был отдельной библиотекой,
потому что он был про исполнение,
он был очень низко на уровнях абстракции, и он
годится и для того, чтобы делать вот
файберы напрямую,
и годится также для того, чтобы сделать сапрограммы,
а сапрограммы сделать файберы.
Вот он слишком общий,
он подойдет тебе и в одном случае, и в другом случае.
То есть нового ассемблера
не нужно, достаточно вот этого switch2.
Хорошо.
Вторая часть нашего рассказа,
это вот вывод.
Я вам показывал уже этот пример,
вот на библиотеке Азио, который
многопоточно обрабатывает
соединение клиентов
к эхо-серверу.
Вот мы их принимаем с помощью метода accept.
Мы создаем серверный сокет внутри
этого объекта acceptor.
Там принимаем эти сокеты,
принимаем клиентов, конструируем новые
сокеты и обрабатываем каждый из них
независимо в отдельном потоке
в функции session.
В ней мы в бесконечном цикле читаем из сокета
и пишем обратно в сокет.
Что такое сокет?
Вы, наверное, уже представляете все, да?
На ОКОСе вы этим сейчас, надеюсь,
занимаетесь. Это
концы TCP-соединения.
TCP-соединение – это такая абстракция прямого
провода между двумя компьютерами, где бы они
ни находились, чтобы между ними не было.
Не знаю, магистальные кабели,
подводные кабели, какие-нибудь
коммутационные фабрики сложенные в дата-центрах,
это все неважно. Как будто бы у вас есть прямой
провод, его концы – это сокеты,
и вы можете на них говорить send
receive и отправить получать поток byte.
Этот поток byte как будто бы не перерывный,
нигде ничего не перепорядочивается, не рвется,
но не теряется и так далее.
Проблема этого кода в том, что
вызовы здесь блокирующие.
Когда вы вызываете лицам,
это в конце концов какой-то
syscall, и в этом syscall вы блокируете поток.
А мы говорим, что потоки –
это дорогой ресурс, мы не можем
заводить их в том масштабе, в котором у нас вообще клиенты
появляются.
Что же делать?
Вы, наверное, знаете, что делать.
Нужно использовать сокеты в неблокирующем режиме.
Мы ставим специальную опцию
флажок на сокете, и после этого,
когда мы читаем из сокета,
то либо мы получаем данные
оттуда, либо, если сокет не готов
сейчас, потому что клиент
ничего не прислал, мы вместо того, чтобы блокироваться,
возвращаем пользователю ошибку
evilblock. То есть я бы заблокировался,
говорит нам сокет.
Он сейчас не готов читать ничего.
Это, конечно, здорово, но пока не понятно,
то есть мы же хотим
от потоков избавиться, поэтому мы должны
перейти в какой-то неблокирующий режим.
Но пока не понятно, как
именно мы узнаем, когда же из неблокирующего
сокета можно читать.
И для этого нам операционная система дает какой-то
API. API называется,
если мы говорим про современную операционную систему,
про Linux конкретно,
то нам дается
епол. Нам дается некоторая
очередь событий,
которая поддерживает ядро.
Что вы можете сделать? Вы можете взять свой
сокет, файловый дескриптор, и зарегистрировать
в этом еполе. Сказать, что я хочу
получать уведомления тогда,
когда сокет какой-нибудь готов
обслужить
без блокировки операцию
чтения или без блокировки операции записи.
И с помощью этого епола можно
написать эхо-сервер, который
будет работать и обслуживать
десятки, сотни, тысяч,
миллионы клиентов в один поток
операционной системы.
Вот тут в документации
приведен некоторый псевдокод,
ну, почти что псевдокод, давайте
мы его быстро разберем.
Что здесь происходит? Мы
конструируем очередь событий,
получаем
епол.fd.
После этого мы регистрируем
в этой очереди
серверный
сокет, на котором мы слушаем клиентов.
После этого
мы крутимся
вот в таком цикле,
в котором мы вызываем сисколу
еполвейт. Семантика
еполвейт, мы туда передаем
некоторое количество сокетов,
точнее, мы зарегистрировали
в очереди события какое-то количество сокетов,
и мы блокируемся на некоторое
время, пока
либо это время не истечет, либо мы набиваем
какое-то количество событий, то есть до тех
пор, пока не появится некоторый сокет, который
готов обслужить нашу операцию
в неблокирующем режиме.
Когда еполвейт
под этом управление, мы знаем, что
какие-то сокеты готовы к чтению
записи, и просто перебираем
все готовые
сокеты. И смотрим,
если этот сокет
это серверный сокет, то, видимо,
мы готовы принять соединение клиента.
Мы вызываем accept, и мы уверены, что мы здесь
не заблокируемся уже.
Вот, получили нового клиента,
перевели его в неблокирующий режим,
и сказали,
что мы хотим на этом клиентском
сокете обслуживать, отслеживать события
сокет готов на чтение.
Регистрируем этот клиентский
сокет снова в еполе,
в очереди событий, ну и
завершаем обработку
готовности
серверного сокета.
Ну, а может быть,
события, а может быть,
сокет готов к чтению или записи,
а может быть,
к чтению или записи готов сокет
не серверный, а какой-то уже клиентский.
Вот мы обработаем его
тут.
Вот примерно так выглядит
любой код, написанный на еполе.
Вы, наверное, его писали, правда?
Вот. Тогда ответьте мне,
что такое вот этот фрагмент кода?
Ну вот, какие фрагменты кода написаны
здесь? Чем они занимаются?
Один занимается новым отключением,
другой обрабатывает запросы второго.
Ну, в общем случае, это обработчики
некоторых событий.
Обработчик события, серверный сокет
готов к приему клиента.
События, там, клиентский сокет готов
к чтению из него.
Клиентский сокет готов к записи в него.
Вот такие вот обработчики.
Но, конечно же,
да, и вот этот
способ, который позволяет вам писать код
эффективно, писать эффективный
код, который будет
гораздо лучше масштабироваться,
чем
чем вот такой
код,
где мы блокируем поток просто.
Но, с другой стороны,
писать код так совершенно невыносимо,
потому что, ну, дело тут не все
даже, а
в том, что этот код
это вывернут наизнанку.
Вот давайте посмотрим, как этот же код
можно было бы переписать на
C++.
Для этого нам потребуется
библиотека, фреймворк, который называется
ASIO, асинхронный вот вывод,
потому что, ну, это такой стандартный
event loop для C++, но
на всякий случай
мы сейчас не изучаем конкретную библиотеку.
Для нас ASIO это конкретная
библиотека, но это всего лишь какой-то пример
такого вот event loopа цикла событий.
Вот этот код, он называется
event loop, потому что мы
в цикле обрабатываем события
на socket, на файловых дискриптерах.
Окей, как бы этот код
можно было переписать
лучше, ну, как можно было
переписать его на C++?
Ну, смотрите, тут дело непростое.
Давайте я даже начну с примера не с
эквивалентного кода
эхо, а с кода, с примера,
попроще.
Давайте попробуем осмыслить
вот такую программу.
Вот вся программа умещается на один экран.
Какие сущности у нас появляются?
Ну, вот в этом коде
есть очередь событий.
Это вот епол.
И есть цикл, который
из этого епола достает
готовые события.
Этот цикл event loop
здесь называется ее контекстом.
И он крутится вот в этом
вызове run.
То есть где-то внутри этого кода спрятан епол
этого объекта.
И мы
крутимся на нем
вот внутри этого рана.
Теперь что мы делаем?
Мы создаем таймер. Мы допустим
хотим выполнить некоторый код спустя 3 секунды.
Мы создаем объект таймер, он называется
в ASIO IO object.
Мы говорим
на нем async weight.
Регистрируем обработчик
события.
Прошло 3 секунды.
Это происходит все мгновенно.
После этого мы блокируемся
вызове run.
И вот возможно внутри этого вызова
async weight мы зарегистрировали
в еполе таймер, который должен истечаться
спустя 3 секунды.
Кажется, епол таймеры умеет, да? Прямо вот напрямую.
Мы могли бы здесь
создать 100-500 таймеров.
Кажется, никакой проблемы бы не было.
Нам все равно
потребовалась бы одна очередь событий
и один event loop вот здесь.
Вот этот код нам
нужен, чтобы продемонстрировать, какие есть
участники. Есть io-контекст, это
епол, есть IO object,
это socket или таймер.
Есть асинхронная операция.
Сделать что-то в будущем.
И вот если это
примерно понятно, то давайте мы посмотрим
на то, как можно переписать
на таком фреймворке
echo-сервер.
Опять, есть некоторый
io-контекст,
в котором есть епол.
И вот мы его крутим,
и вот ровно здесь происходит исполнение
вот всего кода.
Что это за код?
Я уже показывал вам
этот пример и сказал, что
в этом цикле исполняются обработчики событий.
И наш код
он будет более высокоуровневым,
но в конце концов он состоит из обработчиков событий.
Когда мы его
стартуем,
когда мы пишем сервер на этом коде,
мы его конструируем здесь.
И в конструкторе этот сервер
стартует асинхронную операцию
accept.
Она не блокирует
текущий поток.
Это асинхронная операция,
которая просто говорит
еполу, что
вот я регистрирую
серверный socket.
Я...
Нет, серверный socket это accept, конечно.
И эта операция говорит,
что я хочу принять соединение от клиента
в этот объект socket.
Но я не буду дожидаться,
пока это случится.
Я вместо этого подпишусь
на результат.
То есть я регистрирую серверный socket,
вот этот вот,
в еполе,
который лежит здесь,
и прошу
этот ее контекст,
когда на этом socket-е серверном
случится событие, socket готов к чтению,
выполнить accept
и после этого вызвать
этот обработчик,
который я передал в операцию
вторым аргументом.
Так тут все в одном потоке
исполнится. Что значит два клиента?
Нет, просто вот соединение принимается
в этот socket, внутри этого socket.
Асинхронная операция
инициализирует вот этот socket, который передается
в этот объект.
Я бы сказал, что это
не при чем.
Нет, SharedPTR здесь совершенно по другим причинам.
Вот, давайте
чуть дальше пойдем,
я покажу еще один пример и дальше разберу
детальнее.
Вот мы получили клиентский socket,
где-то был вызван
наш обработчик,
и мы в этом
обработчике построили объект сессия,
ему отдали клиентский socket
и эта сессия
первым своим делом
выполнила на socket-е асинхронную операцию
readSAM.
Я хочу
из этого socket-а прочесть
данный вот в этот буфер,
который является полем моего класса.
И когда эта
асинхронная операция завершится,
я хочу, чтобы был вызван этот обработчик.
Я вот говорю слово асинхронная операция,
а кажется его еще не вводил.
Ну а асинхронная операция – синхронный вызов.
Вот что такое синхронный вызов? Синхронный вызов
это вызов, который
вызов синхронный,
если операция завершается
вместе с этим вызовом. То есть вызов
завершился, операция завершилась.
Вот вы блокируетесь на чтении socket-а,
и когда вы выходите
из readSAM, из этого вызова, то и операция
чтения завершилась.
Здесь вызов асинхронный,
то есть вызов завершается мгновенно,
а операция, ну вот,
будет исполнена в будущем где-то.
И когда она
исполнится, будет вызван этот обработчик,
который что сделает?
Вызовет do write,
в котором
стартует еще одно синхронную операцию,
которое пишет socket то,
что прочитал предыдущее.
И когда эта
синхронная запись завершится,
будет вызван
этот обработчик,
который что сделает?
Ну вот, эхо-север, он в цикле читает,
пишет, читает, пишет.
Вот вы запланировали чтение,
оно завершилось, вызван обработчик.
В этом обработчике вы стартовали запись
асинхронную.
Когда оно завершится, будет вызван следующий обработчик,
который сделает обратно в цикле чтения.
На всякий случай,
это не рекурсия, вы понимаете это, да?
Тут рекурсии вообще нет.
Ну это правда, да.
Если мы встретим ошибку, то мы просто перестанем
планировать эти задачи.
На всякий случай, как это все исполняется?
Давайте я картинку покажу.
В общем, как это все смачить в голове
с Яполом?
Вот в Яполе вы видите такие фрагменты
фрагменты кода, обработчики.
Они запускаются в некотором цикле,
в цикле Япола самого, в event loop.
Вот эти обработчики,
здесь вот они, то есть мы также делим
код на фрагменты, на кусочки.
И эти кусочки запускаются где?
Кто их запускает вообще?
Вот этот вызов run.
Что он делает? Смотрите.
Первым делом
в этот вызов run попадает
операция accept or async accept.
То есть код пользователя,
в котором пользователь говорит
я хочу принять очередного клиента.
И внутри этой операции,
внутри реализации accept
в этой асинхронной операции
мы регистрируем в Япол
серверный сокет
и кладем туда обработчик.
Вот его.
Вот такой вот лямбду.
Дальше event loop крутится
и блокируется на Яполе.
Ждет очередного события.
Когда вот этот
событие.
Когда в этом Яполе появляется событие
на вот этом сокете,
то
вот в этой ветке кода
мы выполняем accept,
переводим сокет в неблокирующий режим,
принимаем клиента,
переводим сокет в неблокирующий режим
и вызываем
вот этот обработчик.
А этот обработчик
делает две вещи.
Он, во-первых, снова планирует
следующий accept,
то есть снова бросает
такой вот, снова выполняет такой код
и снова подписывает Япол
на серверный сокет.
А во-вторых, строит
объект сессия
и в методе start у него
стартует асинхронную операцию
асинхронную операцию асинкрицам,
которая в Яполе
регистрирует уже клиентский сокет
и когда на очередной
итерации Япол
достанет этот сокет из
на очередной итерации event loop
из Япола
будет извлечен этот сокет клиента,
то на нем будет выполнена операция чтения
и
после этого
этот самый event loop выполнит обработчик
клиента, в котором написано,
что do write,
async write.
Этот async write
снова регистрирует в Яполе сокет
клиента, но уже на запись
и когда
event loop достанет из Япола этот сокет,
то
будет вызван сискол write
и после этого будет вызван обработчик
async write, то есть
то есть
то есть do read, то есть
асинкрицам.
Понимаете все, что происходит сейчас
или нет?
Это всего лишь способ обернуть
в некоторые объекты тот код,
который вы уже писали на C.
То есть вот такой вопрос,
то есть если в какой-то момент
вот концептор, не запланирован
новый асцепт, то сьемку с Япола он
снился. Вернее, когда
происходит событие, он снимается. Если не запланирован,
он туда же не положится.
И смотрите,
это же как раз и интересно.
Давайте еще раз я проговорю, понятно
ли, что здесь написано?
Ну, то есть понятно, что
новый фреймворк, новый билетек, вы видите
первый раз возможно, поэтому все непонятно
разумеется, но принцип должен быть понятен.
Картинка должна быть понятна.
Вот видите, мы как бы
такие вот очереди
цепочки, циклы
задач строим.
Вот такие отдельные
не блокирующие фрагменты.
Здесь нет ни строчки блокирующего
кода.
Здесь блокироваться может только вызов Япол,
который дожидается очередного события.
И все происходит в одном потоке.
А теперь вопрос на понимание.
Он довольно хитрый.
Вот смотрите, я создал
объект сессия, который представляет
собой обработчик клиентского запроса.
Я создал его на куче.
Забудьте, по-другому.
Вот
пойдем с другой стороны.
Вот у нас есть код
сначала неэффективный, на потоках.
Мы здесь
принимаем соединение клиента
с блокирующим синхронной
мопи. Создаем поток,
и в этом потоке мы читаем из
сокета в буфер,
пишем в сокет из буфера.
Где буфер
живет? Буфер живет на стеке потока.
Локальная
переменная. А теперь
вопрос, а где
будет жить... Ну у нас
теперь по-прежнему много клиентов, зато у нас теперь один
поток. Вот где нам...
Где будут жить буферы для каждого
соединения?
На стеке потока
у нас один поток,
а соединений много. Они же не могут с одним буфером
работать. Это было бы странно.
Они бы его перетирали постоянно.
Ну у каждого клиента свой буфер,
разумеется. Вот там 100 тысяч
клиентов прочитали в буфер свои данные,
потом должны записать.
Не подождите, забудь про класс, я вот зря про него сказал.
Вот нет никакого класса. Есть...
Где стеки... Где
буферы должны жить? На стеке... У нас...
А? Ну на куче, потому что
стеков больше нет у нас. Мы от них отказались здесь.
С одной стороны, это хорошо, у нас теперь нет потоков, решение
масштабируется. А с другой стороны,
где-то должны эти буферы жить.
И что мы делаем в этом коде? Мы
переносим их в кучу.
Мы
конструкцию сессия превращаем в объект
сессия, который мы
алоцируем на куче.
И буфер
становится его полем.
Схватили, да?
В этом есть некоторая глубокая мораль,
которую мы пока не понимаем.
Смотрите, что происходит дальше.
Мы конструируем объект сессия,
то есть мы конструируем
shared pointer, который ссылается на объект сессия.
А после этого,
после этой строчки shared pointer разрушается.
Странно, да?
У вас там совершенно
последний человек,
который сама принимает
владение собой.
Смотрите, после этой строчки shared pointer, который мы
конструировали здесь, будет разрушен. Это правда.
Это вообще странно.
Но мы успели
после конструирования и перед разрушением
вызвать старт.
А в этом старте мы вызвали дурид, а в этом дуриде
мы построили shared pointer
на себя
и в обработчик
асинхронной операции
мы передали не только
зыз, но и self.
То есть обработчик, пока
асинхронная операция не завершилась и не вызван обработчик,
этот обработчик,
находясь где-то в недрах
этого самого ио-контекста,
продляет жизнь объекту сессия,
продляет жизнь буферу.
И вот у нас
здесь получилось уже два shared pointer,
все это во-первых разрушился вот здесь вот
и остался один.
То есть пока в очереди,
пока есть хотя бы одна незавершенная
асинхронная операция для данной сессии,
она продляет жизнь этому
объекту сession.
А теперь вопрос, а почему мы
используем
error кода какие-то?
Почему мы так обрабатываем ошибки?
Понятно ли это?
Почему же у нас нет
исключений?
Медленно.
Черт.
У нас нет
ну да, вот исключения разматывают стэк,
а ну как бы вот у нас
стэка нету. У нас есть как бы один
ну нет у нас стэка здесь, у нас один
поток всего с одним стэком.
Кроме того, ну представьте себе,
исключение вылетает когда?
Когда вот во время выполнения операции
возникает ошибка.
У нас операция асинхронная.
Вот мы ее вызываем,
и вот внутри этого вызова
никакой ошибки,
насколько мы еще не получили. Мы просто
зарегистрировали его в Epole.
Тут как бы рано бросать ошибку.
Так что мы не можем использовать исключения,
мы можем только передать ошибку в
обработчик, в колбэк.
Ну вот.
А как вообще эти колбэки получились,
понимаете ли вы или нет?
Откуда они вообще взялись?
Чем они занимаются?
Ну или по-другому, как
из этого решения
простого, понятного
получилось вообще вот это?
Ну или как из этого решения
получилось вот такое вот?
Ну очень просто. Мы взяли
нашу функцию session,
нашли в ней блокирующие
вызовы.
И просто вот разбили функцию на кусочки.
И каждый кусочек
превратился вот в такой вот обработчик.
Раньше мы их писали вот
в коде на C. Мы писали
их вот прямо внутри этого event loop.
Сейчас мы одно от другого отделили,
но по-прежнему у нас вот есть такие фрагменты.
Наш код
разбился на вот такие вот
фрагменты.
Мы потеряли исключение.
Мы потеряли control flow.
У нас теперь нет циклов.
Вместо циклов, понятного while,
у нас вот есть такая вот странная, ну не рекурсия,
но вот такой цикл задач.
Ты верно говоришь,
но мы к этому и идем.
Вот что у нас сейчас есть?
У нас сейчас есть решение
очень простое, в смысле понятное.
Его удобно писать,
но не масштабируемое.
И у нас есть решение очень
хорошее, в смысле оно эффективное,
масштабируемое.
Но его и писать неудобно,
и читать сложно.
Ну вот попробуй здесь увидеть цикл while.
Это не очень тривиально.
А тут их даже два.
Вот один, а вот
второй.
Ну почему такая беда возникает?
Потому что мы не хотим блокироваться
нигде. Мы себе это запретили.
Мы запретили это на лекции про thread pool,
и вот снова себе запретили.
Потому что в конце концов мы снова хотим
делать это все в thread pool.
Так вот,
как же справиться с нашим кодом?
Он вывернут наизнанку. Вот этот код,
простите, этот код, он подчиняется
вашей логике. Вот у вас написан цикл,
потому что вы его написали, потому что вот в вашей
логике есть цикл.
А здесь исполнение подчиняется
циклу event loop. Вот вы под него подстраиваетесь.
Хочется как-то
проблему эту решить.
Вот у вас
есть некоторый фрагмент кода. Смотрите, вы
прочли данные из сокета.
И вот вы выполняете такой код.
Нужно стартовать синхронную
операцию записи обратно в сокет.
И вы,
у вас есть фрагмент кода
до записи в сокет
и после записи в сокет.
Но они разрываются,
потому что синхронная операция и callback.
Вот было бы здорово их склеить.
Было бы здорово написать
нечто такое.
Вот было бы здорово
написать код, который выглядит
как простой синхронный,
а исполняется как
асинхронный.
Ну не то, что вот похожим образом исполняется,
а вот ровно так исполняется.
То есть мы пишем вот такой код,
ну вернее вот такой код,
а исполняется он
вот ровно так.
Ну и давайте подумаем,
что можно было бы внутри этого
рецама написать.
Но, видимо, мы хотим
воспользоваться
сопрограммами, файберами,
что вам ближе сейчас, какое слово.
Вот что мы хотим сделать
внутри рецама?
Мы внутри рецама в конце концов должны
вызывать сокет асинкрецам,
асинхронный вызов.
И вроде бы наша текущая задача
завершится.
Но мы же говорили вот до этого в начале лекции,
что сокет это же, ой,
файбер это же буквально цепочка
вызовов задач,
которые перепланируются постоянно.
Но вот же она цепочка вызовов.
Раз-два, раз-два, они вращаются
просто.
Так вот, что мы сделаем внутри рецама?
Мы, конечно же, стартуем
асинхронную операцию.
Вот ее.
Но она же не может завершиться тут же.
Мы вроде бы должны завершить задачу.
Но мы при этом файбер. Что мы можем сделать
в таком случае?
Ну или сопрограммы.
Мы остановимся
внутри вызова рецам.
Из вызова не выйдем пока.
А что мы напишем в обработчики этого рецама?
Вот здесь, в колбеке.
А в колбеке мы напишем
резюм файбера и сопрограммы.
И когда
асинхронное чтение завершится,
мы зарезюмим корутину,
сопрограмму и вот наконец
выйдем из этого рецама.
И вот внутри этого рецама
есть такая склейка вот этих
вот задач.
Но при этом пользователь этого не замечает.
Пользователь просто пишет вот такой вот синхронный
код. То есть мы снова,
вот мы в примере с
чем?
В примере, в примере с
корутинами. Мы выпрямили
рекурсию с помощью файберов.
О, с помощью сопрограмм.
Вот здесь вот.
А здесь мы вот выпрямили такую,
ну не то что выпрямили, мы склеили
разрыв асинхронных операций.
С помощью файберов.
С помощью файберов, сопрограмм. Простите, я путаюсь постоянно.
То же самое
с socket-write.
Стартуем асинхронную операцию,
останавливаем сопрограмму, а в обработчике
мы эту сопрограмму возобновляем
резюме.
И вот получается такая
синхронная
асинхронность. У нас под капотом
асинхронные вызовы, потому что это единственный
способ эффективно
исполнять код. Эффективно упаковывать
много конкурентных активностей в малое число поток.
Но пишется он
совершенно прямолинейный цикл while есть.
Это первое достижение.
А второе,
буквально три минуты, но очень важные три минуты.
Вот смотрите,
я показывал вам вот такую реализацию
кода, вот такую реализацию
эхо-севера
с помощью синхронности.
И на потоках.
Вот
заметьте, что
преобразовав, что вот этот код,
этот код можно переписать
вот этот код
совершенно бездумно, совершенно механически.
У нас была функция
session
сейчас по-другому.
У нас была функция
session
она во что превратилась?
В класс.
В ней были локальные переменные.
Они стали
полями класса.
У нас
у нас
был такой цельный кусок
кода,
а он превратился в такую
стоит машину, автомат.
Мы разбили
его в точках блокирующих вызовов
и сделали из них обработчики.
Вот
обратите внимание, что это преобразование
абсолютно механическое, абсолютно предсказуемое.
И
ну забегая сильно вперед,
если вдруг
вы
разработчики
языка программирования
поддержите сопрограммы
прямо в своем языке
на уровне компилятора,
то вы можете
преобразовывать синхронный код
в осинхронный
как здесь вот
не на уровне библиотеки,
а просто вы можете
просить компилятор
переписать вот этот
код таким образом.
Просто сам компилятор за вас выполнит эту
трансформацию, потому что она
абсолютно понятная, она абсолютно структурированная
механическая.
Нужно ему только кое-что
объяснить, некоторые детали.
Объяснить ему,
где у вас в коде
будут синхронные вызовы,
а дальше он сам
ваш красивый синхронный код
вывернет наизнанку, построит вот такую
стейт-машину, локальные перемены
сделают полями, и
вы будете
писать простой код, а исполняется он будет
быстро. Вот мы сейчас
это сделаем вдомашки своими руками,
а потом мы посмотрим,
как эту проблему решает C++.
Но механизм один и тот же – это программа.
Все, спасибо.
