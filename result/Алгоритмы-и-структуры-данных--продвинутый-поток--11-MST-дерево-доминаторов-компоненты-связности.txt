так все пишем все работаем отлично так так а пишем ли мы так ну-ка на всякий случай
ой как хорошо вот так ну че вроде пишем так значит это мы пишем это мы о
красота какая это всегда так лексика ж проводить а то маркеры вот ну ладно
значит смотреть так на чем мы в прошлый раз остановились давным-давно когда это
было три недели назад страшно сказать так что мы делали нет а также компоненты реберной и
вершины двусвязанности вот ну все значит давайте чуть-чуть воспомним потому что сейчас уже начнем
из прямого продолжения этой все логики вот ну что у нас было но разговариваем мы в принципе
о dfs но как мы помним с точки зрения dfs что у нас бывает вот ну как мы помним в неориентированном
графе если мы запустим dfs то ребра у нас бывают двух типов бывает ребра дерева dfs то есть это вот
ребра в котором dfs не посредственно прошел а также у нас бывают еще образные ребра вот
то есть ребра соединяющие потомка с приятком вот как-то вот так то они достаточно произвольно
так я вот мы но от будем все их рыжим цветом обозначать раз у нас есть такая возможность
вот как но вот ну вот а хейта по разному то есть конечно идти ребра можно рассматривать как
обратной ребра и смотреть а потом как предку можно рассматривать как приемы альбер как
потомку но обычно их рассматривает как обратная но ключевой свойство тут у нас оказывается в
том, что у нас нет перекрестных ребер, то есть у нас, оказывается, пока не бывает вот каких-то
вот таких ребер, то есть которые там соединяют какие-то две вершины, которые не являются предком,
потомком друг друга. И, собственно, когда мы искали мосты точней сочинения, мы этим прям вот очень
сильно пользовались. Вот, но основная технология у нас там заключалась в том, что мы, ну, во-первых,
когда мы запускаем DFS, мы можем считать время входа и время выхода, время входа в вершину,
время выхода из вершины. Это, напомню, позволяет нам просто на халяву проверять для двух вершин,
является ли одна из этих вершин предком другой, ну или потомком. Вот, соответственно. Ну и в
результате, вот, оказывалось, что если так ребра, то есть если рассматривать вершины, там смотреть,
то достаточно легко, оказывалось, можно было найти компоненты реберной двусвязности, каким образом.
Ну потому что оказывалось, что каждая компонент, то есть оказывалось, что надо было просто, значит
обнаруживалось, что как бы вы не запустили DFS, а компоненты реберной двусвязности всегда будет
образовывать какое-то связанное под дерево, причём подвешанное за один корень, соответственно. Логично,
Оставалось только научиться понимать, как-то по DFS-у каждая конкретная вершина является таким
кохе в своей компоненты или нет. Как мы это делали? Для этого мы вводили не только функцию timeIn,
но и а также вводили функцию upTime. Что такое upTime? upTime от V это минимальный
timeIn от U. Что такое? Не понял. Это типа сюда не ходи что ли или что?
Значит равно. Значит минимальный timeIn у какой-то вершины U. Какой? Ну-ка, у какой напомните?
По любому? Да, совершенно верно. Где W, V и U обратное ребро именно в таком порядке?
Нет, нам это принципиально, ну как сказать, с точки зрения определения может и не принципиально,
но по модулю того, что из каждой вершины можно пройти по ребру, по которому мы просто DFS-ом пришли.
Поэтому лучше этого избегать. Ну вот и соответственно W потомок. Вот таким мы определением пользовались.
Вот такую функцию по такому определению насчитать ее легко и выяснялось, что для реберной двусвязности
вершина является корнем тогда и только тогда, когда upTime от V больше либо равен своему timeIn
этой же вершины. Но оказалось, что верный на ребрах. Выяснялось, что есть компоненты вершины двусвязности.
Что это такое? Вершина двусвязности это оказывается уже какое-то отношение на ребрах. И оказывалось, что компоненты
вершины двусвязности, что компоненты вершины двусвязности это набор ребер, который устроен, оказывается, тоже каким-то
подобным образом тоже образует какое-то поддерево, но при этом оказывается, что в дереве DFS оказывалось, что это тоже поддерево,
в чем висящее на одном ребре, что важно. Ну а также какой-то набор таких ребер и вот тут еще какие-то обратные ребра
среди этих вершин. Ну правда, среди этих вершин тут надо как-то аккуратно формулировать, потому что, как мы помним,
одна вершина может лежать в нескольких компонентах вершины двусвязности, мы помним. Но, тем не менее,
оказывалось, что действительно существует вот это ребро будет первое, в которое мы войдем в компоненты вершины
двусвязности, и идентифицировать такое первое ребро тоже оказывалось просто. То есть такое ребро у V дерево DFS,
первое ребро своей компоненты, тогда и только тогда, когда uptime от V больше либо равен, чем time in от U.
Было дело, да? Вот. В чем, если он больше либо равен time in от V, то оказывалось, что это мост, а мост у нас является
просто компонентом вершины двусвязности, из себя любимого. Вот. Это вот чем мы занимались в прошлый раз.
То есть это вот примерно такая технология была. А теперь мы попробуем себе жизнь немножко усложнить.
Хотя поначалу так может не показаться. Потому что мы сейчас перейдем в компоненту нотра,
сейчас мы перейдем в ориентированный граф и попробуем найти компоненты сильной связности.
Вот. Внимание, вопрос. Что же такое компоненты сильной связности?
Ну да, да, совершенно верно. Хотя я так задал вопрос, как будто это определение на лекциях уже звучало.
Ну хотя ладно, тут сложно предполагать, что его никто не знает. Хотя тут опасно, да, по-моему.
Чисто теоретически можно сильно сократить лекцию по принципу ну-ка поднимите руки, кто знает,
как искать компонент сильной связности за линию. Ну-ка поднимите руки, кто знает. Все, пропускаем.
Но нет, мы не пропускаем. Потому что давайте так, поднимите руки, кто умеет искать это за линию
с помощью двух DFS. А кто умеет искать с помощью одного DFS? Вот. Вот. Вот сейчас мы как раз одним DFS
научимся. Потому что как это не парадоксально, но компоненты сильной связности можно найти вот этой технологией.
Но придется почесаться. Чем мы сейчас и займемся. Но тут очень интересно. Вот эта технология прям классная.
Вот. Значит, смотрим. Так, ну действительно, давайте, да, вспомним, значит, еще раз. Определение, да,
ну вы уже его записали, я его тоже запишу уже для порядочка. Определение. То есть, так, значит,
у нас, напоминаю, что там у нас жиров новый. Так, напоминаю, что у нас что-то, так, не понял.
Господи, а доска знаете, что, видимо, маркер отличает. Ну ладно. Так, значит, ладно. Так, это мы убираем.
Вот. Значит, определение. Значит, в RGV у нас на этот раз ориентированный граф.
Значит, это такой ориентированный граф.
Вот. И, соответственно, определение. Вершины U и V, значит, соответственно, сильно связаны, если, вот тут как написать?
Вот я напишу надежно. Существует путь от U до V и существует путь от V до U. Вот.
Почему? Ну, потому что кто-то мог бы сказать, существует цикл, проходящий через вершины U и V,
но это, конечно, интуитивно небезопасно. Ну, потому что, как всегда, у нас существует там какие-нибудь вот такого, как видим, вот такого рода восьмерточные примеры.
Вот. Или там вообще какая-нибудь. Так. Так. Ну, конечно, ладно, это не показательный пример, конечно.
Ну, ладно. Не важно. Ну, хотя бы такой. Ну, тут не могу гарантировать, что тут хотя бы реберно-простой путь обязательно должен быть.
А, вот. Точно, точно, точно. Теретически вот еще такой супер показательный пример бывает между U и V. На всякий случай скажу.
Что видите, что как бы путь от U до V есть, путь от V до U есть, но при этом даже реберно-простого цикла здесь не найдется.
Вот. Поэтому то-то. Не ошибитесь. Вот. Ну, по крайней мере, здесь, конечно, халявность заключается в том, что то, что сильная связанность это отношение к валютности на вершинах, это очевидно уже.
Да, здесь уже тут транзитивность все-таки как бы сама себя доказывает. Потому что на путь мы никаких ограничений не накладывали.
Вот. Да, теперь выясняет вопрос. Как же найти компоненты сильной связанности?
Так. Ну, здесь тоже хочется запустить DFS и хочется посчитать какой-то аптайм.
Но смотрим. На самом деле какие у нас проблемы возникают?
Ну, проблемы возникают, что, во-первых, DFS обходит не всю компоненту связанности.
Как минимум, потому что в ориентированном графе нет понятия компонента связанности.
Да, вот, кстати, внимательно. То есть, на самом деле, если вы скажете, что в ориентированном графе есть компоненты связанности, это просто формально неграмотное предложение.
Потому что, как мы заметим, что связанность в ориентированном графе, там понятие абсолютно, ну, вообще просто непонятно какое. Что такое две вершины связанные вообще?
Вот. То есть, обычно либо уточняется, либо сильно связаны, есть еще понятие слабо связаны.
Слабо связаны, это типа, если мы уберем у ребер все, там, то есть, говорят, что у и в слабо связаны, если там между ними существует путь после того, как мы уберем у всех ребер ориентацию.
Да, это называется слабая связанность. Да, совершенно верно.
Ну, тогда так и говорят, есть путь хотя бы в одну сторону.
И, кстати, крайне редко это надо. Потому что, на самом деле, что надо? Обычно надо, чтобы был путь от У до В.
Но тогда, как в науке говорят, когда нужно сказать, что есть путь от У до В.
Да нет, так и говорят, есть путь от У до В. Ну или там, да, еще есть вариант В достижимый из У, и так далее.
Вот. Что-нибудь еще.
Вот. Поэтому, получается, если вы запустите ДФС из первой попавшейся вершины, то обойдется, что обойдется?
Ну, ее компоненты сильной связанности.
Ну, ее компоненты сильной связанности обойдется. И, более того, каждая компоненты сильной связанности в графе либо обойдется целиком, либо не обойдется.
Это да, но это и все, что мы знаем.
Потому что, значит, что у нас тут оказывается? То есть, если запустить ДФС, да, то есть могут обойтись не все вершины.
Причем тут мы могли сказать, что давайте без ограничений общества считать, что граф связанный.
Потому что если граф не связанный, давайте для каждой компоненты связанности это сделаем независимо.
Ну, тут уж совсем так сказать не получится.
Вот. Здесь у нас появится, значит, такой лес ДФС.
Вот какой-то вот лес. Красивый такой лес.
Вот. Тут еще какая-нибудь гадость такая.
Вот. Ну, значит, какие еще ребра могут быть?
Так. Ну, могут быть, конечно, как было раньше, обратные ребра.
Пожалуйста. Этого добра у нас навалом. Сколько угодно.
Вот так может быть. Что там еще может быть? Вот так может быть.
Что еще может быть?
Прямые ребра.
Да, но на этот раз, да, теперь могут быть и прямые ребра.
Вот дайте мне вот этот.
Вот дайте мне вот этот.
Вот.
О.
Ладно, не он. Так. То есть могут быть и прямые ребра вполне себе.
Вот. На этот раз, собственно, никто нам не мешает их существовать.
И это теперь не одно и то же.
И самое для нас вредное и неприятное.
Это перекрестные ребра.
Вот. Это, ну вот.
Но, правда, для них есть маленькая оговорщика.
Оговорщика у нас будет заключаться в чем?
Она будет заключаться в том, что не из любого ни потомка, ни предка,
в любой ни потомок, ни предок может вести перекрестные ребра.
Понимаете, мы в прошлый раз доказали одно маленькое уточнение,
которое заключалось в том, что перекрестные ребра всегда идут
из вершины с большим таймином в вершину с меньшим таймином.
Было дело, да?
Вот. Но я буду сейчас повторять доказательства.
Вот. Но суть вот такая. Вот такая, вот такая и вот такая.
Да. Да.
Самое подлое, что перекрестные ребра могут и между деревьями вполне
себе существовать.
Вот. Еще одна такая подлость.
Вот. То есть такое бывает.
Даже вполне себе вот так.
Так.
Хорошо. Ну теперь возникает вопрос.
Хорошо. Раз ДФС у нас обходит несколько компонентов сильной связности
целиком, а другие не трогает вообще, ну тогда возникает вопрос,
а верно ли, что компоненты сильной связности вообще образуют
дерево?
Ну так какое-то связанное, подвешенное под дерево вот в этом дереве ДФС.
Ну.
Почему нет? Посмотрите по первому вершину из компонентов,
в которые мы придем.
Так. Пришли.
Вот.
Ну тогда понятно, что все...
Понятно, что все ее...
Все элементы компоненты будут лежать просто в ее под дереве.
Так. Ну да, формально да.
Можно сказать полемия белых путях, если сломаться прямо до читеров.
Да. Ну в принципе да, понятно.
Хорошо. Да.
В ее под дереве-то лежать будут.
Да, потомками будут.
Вот так.
Соответственно осталось понять, почему это будет связано.
Ну да.
Можно противно.
Пусть мы в какой-то момент прошли
вершину.
Не из данной компоненты.
Угу.
Вот.
Так. Ну вот допустим.
Тогда что?
Ну соответственно,
вот тогда у нее есть...
Ну покажем, что на самом деле эта вершина
не может лежать в другой том моменте сильности.
Пусть мы до какой-то вершины прошли.
Да, вот такое утверждение.
Пусть мы дошли вот от корня компоненты
сильной связности до некоторые вершины.
Корень там, до какой-то вершины B, да?
Так. Вот.
Вот тогда все вершины на пути
лежат в компоненте сильной связности.
Ну не совсем.
Нет, пойдите, если у вас есть какая-то вершина,
у нее есть какой-то потомок из другой компоненты,
то не все вершины на пути лежат.
А, и B это из компонента сильной связности?
А, ну да. Но я, правда, да.
Я тут под A и B рисовал компоненты скорее.
Но суть верная, да.
Правильно. Самый простой способ это
пусть у нас есть действительно какая-то вершина.
Так сказать, корень нашей компоненты.
То есть первая вершина,
компонент, в который мы вообще вошли.
И у нее есть какой-то потомок
тоже из этой же компоненты сильной связности.
Утверждение.
На самом деле весь путь тогда...
Господи, что происходит?
Значит, весь тогда этот путь находится
в одной компоненте сильной связности.
Почему?
Ну просто потому, что, ну, например,
из этой вершины можно, как бы,
до всех этих вершин очевидно дойти.
А из самой нижней вершины
можно дойти до нее.
Следовательно, из всех этих вершин
можно дойти до этой вершины,
а потом прыгнуть в нее.
Все. Да, самый простой.
Да.
Здесь действительно пока все просто.
Остается только маленькое уточнение,
маленький момент.
А как же этот корень компонент
из сильной связности
идентифицировать?
Вот.
Ну, наверное, хочется, конечно,
попробовать какую-нибудь
вот такого рода аптайм.
Вот давайте вот подумаем.
А вот, например,
такого рода аптайм нам не пойдет?
Ну-ка, пока я тут чуть-чуть сотру.
Вот давайте подумаем.
Вот если я в принципе вот такой аптайм
я посчитать могу.
Более того, я даже могу
в DFS отличить обратное ребро
от прямого и перекрестного,
правда?
Вправивается.
Вот если я запущу такой аптайм,
можно ли как-то с помощью такого аптайма
отличить корень,
то есть корень компонент
сильной связности от некорня?
Ну, кажется, да,
потому что вот посмотрим на корень,
если его аптайм оказался
меньше, чем 3 над корнем,
так,
это значит, что
мы можем,
да, вот тогда
это значит, что мы можем из-под дерева
пойти в какого-то предка,
ну, соответственно,
у нас есть вот этот вот цикл,
да,
ну и, соответственно,
ну, этот цикл лежит в какой-то компоненте
сильной связности,
ну да,
и ее корень, типа, не ниже,
чем верхний.
Да, ну да, действительно,
то есть действительно мы можем ответить,
да, что оказалось, что
если аптайм от V
оказался меньше, чем теймен от V,
значит, тогда оказывается, что
вершина V как минимум со своим родителем,
точнее, со своими несколькими подряд
предками лежит в одной компоненте
сильной связности,
и это, конечно, не корень своей компоненты.
Да,
но, к сожалению, доказательств не полно.
Это нам говорит только о том, что,
ну,
да, о чем это нам говорит-то вообще?
То есть,
это нам говорит о том, что,
ну, понятно, у нас условия,
какое у нас условие?
У нас условие, что аптайм от V
там равно
теймы на V.
Ну ладно, больше либо равно.
То есть, мы говорим, что,
то есть это говорит только, что если оно не сработало,
то это не корень.
А если оно сработало,
обязательно ли это корень?
Ну, вообще, да.
Почему?
Потому что,
ну, вот рассмотрим
все под деревом в вершинке V.
Так.
У нас есть,
ну,
перекрестные ребра в прошлые деревья
в прошлые деревья
у нас узалов не слишком интересует,
потому что
из,
ну, из предыдущих деревьев
вершинка V очевидно недостижима.
Что такое предыдущие деревья, давайте аккуратно.
Вот у нас есть
перекрестные ребра
в,
как бы,
в то дерево,
ну, в какое-то другое дерево
в целом из леса до их носа.
Ну,
ну, может вполне себе
может быть такое, и что.
Вот.
Ну, тогда
ни с какой вершины того дерева
V недостижима.
Кто сказал?
Ну,
сейчас, разве это не прямой следствием
или вот в путях?
Сейчас.
Причем тут?
Причем тут вообще?
Как раз на ребро перекрестая,
то это как бы
потомком вершины V
не является.
Она говорила только что-то там о том,
что вы вошли только что в вершину,
и у вас есть там до каких-то вершин
можно дойти по белым вершинам.
Это все, что говорила Лемма о белых путях.
Ну,
ну,
ну,
ну,
ну,
ну,
ну,
ну,
ну,
ну,
ну,
ну,
ну,
ну,
ну,
ну,
ну,
ну,
ну,
Ну,
ну,
ну,
ну,
тогда
пусть есть какой-то путь
вот
из какой-то вершины того дерева
вершины V.
Рассмотрим вот момент, когда мы первый раз зашли в ту вершину.
В ту это какую?
Пускай в корень того дерева просто.
Что такое корень того дерева?
Ну корень, то есть у нас перекрёстное ребро в предыдущее дерево.
А что такое предыдущее дерево тогда, я не понимаю.
Они вообще тогда могут в одном дереве лежать.
Это же перекрёстное ребро, они могут и в одном дереве.
Пока что я говорю, что перекрёстные ребра, которые ведут нефть в текущие,
у которых конец нефть под деревья вершины В, в целом даже так.
Так, ну хорошо.
Так, допустим, вершины В есть такое.
Есть перекрёстные ребра, которые ведут из под дерева вершины В, не в под дерева вершины В.
И что?
Тогда утверждаем, что вершина, вот конец этого ребра, не сильно связана с В.
Да, кто сказал?
Ну.
Ну рассмотрим момент времени, когда мы пришли в ту вершину.
Рассмотрим.
Как вам такое?
А, ага, ага.
Сейчас.
Здесь не так.
Видимо условия надо как-то усиливать.
Ну да.
То есть заметим, что при таком оптайме тупо не работает.
Да, просто вот есть пример.
Точнее так, все корни будут идентифицированы, верно?
Нет, точнее так.
Нет, наоборот.
Если вы идентифицируете мне как корни, корнями действительно не будет.
Да.
Но зато есть наоборот, бывают ложные срабатывания.
То есть там могут быть корни.
Что же делать?
Да, вот действительно у нас, то есть как бы раньше у нас все работало
просто за счет того, все доказательства, что мы из-под дерева можем выйти только по обратному ребру.
А тут это, понимаете ли, не так.
Да, что нам сильно усложняет жизнь.
А что делать?
Вот какие еще варианты есть?
Если мы на это попытаемся что-нибудь еще с тайм-аута попробовать сделать нам этой помощь.
С тайм-аутом.
А что нам, а чем нам помочь?
Тайм-ауты нам будут помогать отличить там скажем обратное ребро от необратного.
Нет, то есть в принципе заслуживает внимания еще рассмотрение варианта такое обратное ребро или перекрестное ребро.
Да, вот.
К сожалению, нет.
То есть с одной стороны конечно кайф, что мы для каждого...
Да, конечно, мы же просто можем какую-то вершину типа внизу из другого дерева получить.
Ну, например, из другого дерева или просто из другой компоненты сильной связности.
Да, которую мы просто ранее обошли.
В таком случае у нас просто неравенственно тайм-аута перестает быть...
Ну да.
Но тут на самом деле правильная идея уже и начинает крыться.
Потому что есть подозрение, что если у нас есть какое-то правильное условие, то, наверное, если какое-то перекрестное ребро ведет в вершину из другой компоненты,
то эта другая компонента уже нами обработана и стека мы ее достали.
Правда?
Вот.
Ну, как-то есть...
Ну, действительно, есть такое подозрение.
Ну, действительно, давайте подумаем.
Так, ну на самом деле не такое тривиальное утверждение, на самом деле, как кажется.
Потому что, мало ли, вдруг тут возникнет какой-нибудь подобный случай.
Ну, действительно, давайте предположим, что у нас произошло.
Какая-то такая ситуация, что у нас возникла компонента этой сильной связности.
Значит, как-то вот ходил ДФС.
Мы тут пришли в этот ДФС, побегали, побегали, побегали, побегали.
Потом пришли откуда-то, и в нее неожиданно тут пришло перекрестное ребро.
Вот.
Так.
Ну, действительно, заведем, что в этом случае понятно, что мы тогда...
Если у нас есть какой-то с небес по факсу нам кто-то там...
Как это там?
От логики это небес по факсу называется оракул.
То есть, если у нас есть оракул, который сообщает, кто тут корень, кто тут нет,
то в тот момент, когда мы рассматриваем это перекрестное ребро,
мы вроде эту компоненту должны были уже рассмотреть.
Это могло быть не так, конечно, если на самом деле...
То есть, теоретически, конечно, могло быть так, если у нас тут вот этот вот LCA
этого перекрестного ребра оказалось внутри.
Вот, ну как-то так.
Но это нам ничего не дает.
Потому что это лишь означает, что мы из этой компоненты еще не вышли,
мы прямо сейчас в ней находимся.
Логично, да?
Вот.
Так что, да, тут вот с перекрестными ребрами получается так.
Нет, хотя нет.
Нет, хотя не скажите.
Есть еще один подлый случай.
Да, подлый случай мог оказаться, что эта вершина могла...
Да, могла еще оказаться не с такой LCA.
Нет, а на самом деле еще могло оказаться, что LCA этих двух вершин
окажется внутри компоненты, если эта вот вершина окажется где-нибудь вот потомочком.
Ну, то есть, что это обратное ребро?
Нет.
А, так даже?
Да.
Более того, в этот момент могло оказаться, что мы даже не всю эту компонент,
не всю эту компоненту даже рассмотрели, а тут еще что-нибудь есть.
На текущий момент не рассмотрены.
Так это даже наверняка так получится.
Ну, может получиться, но бывают и через обратные ребра.
В смысле, что...
Ну, правда, через обратные не получится, потому что тогда весь этот цикл лежит в той же компоненте.
А вот через перекрестное.
А кажется, с перекрестным тоже это может получиться, только пока мы эту компоненту не рассмотрели до конца.
Ну, по сути, да.
Да.
То есть, действительно, заметим теперь, что у нас есть какая-то компонента сильной связности, есть какая-то вершина,
из которой в нее можно прийти в компоненту и в которую можно прийти из компонента.
Но это очевидно означает, что на самом деле эта вершина в этой компоненте тупо лежит.
Логично, да?
Логично, да.
Вот такая красота.
Такая вот маленькая красота.
Вот, да.
Хорошо.
То есть, получается, тут есть такая вот взаимосвязь.
Такая интересная, да?
Что если есть аракул, то оказывается, что перекрестное ребро надо просто можно в таймине, то есть в аптайме рассматривать тогда,
и только тогда, когда он не ведет уже в ракуле.
Вот.
То есть, поэтому правильное условие действительно так и будет на самом деле звучать.
Прикрестное ребро ведущее в ранее найденную компоненту.
Вот.
Вот.
То есть, поэтому то есть правильное условие действительно так и будет на самом деле звучать.
Прикрестное ребро ведущее в ранее найденную компоненту.
Компоненту.
Ну, давайте.
Так, компоненту.
Ой, Господи.
Хочется кратко написать, написать компоненту СС не хочется почему-то.
Так.
Связанность.
Вот.
Но, правда, остается вопрос.
А как же нам, собственно, понимать, какая вершина в компоненте уже есть, а какая нет?
Ну, и здесь оказывается, значит, Альян тут предлагает вообще, то есть абсолютно такой неожиданный чит.
Значит, что помните, какие у нас цвета вообще бывают?
Да, у нас бывает.
Ну, когда у нас мы запускаем ДФС, у нас бывает белый цвет.
О, парадоксально, но тут даже видно.
Бьюзла я вообще сам не ожидал, но вот да.
Так, мне вот страшно.
Значит, что бывает еще?
Бывает еще серый цвет.
Где тут серый цвет?
А реально, а где тут серый цвет?
Нет, в середине снизу черный.
Вот.
Господи, кому нужен серый цвет, действительно?
Так, ну ладно, давайте вот.
Ну ладно.
Прикинемся так.
Нет, ну нет, нет, он это, видите, тут свет какой-то есть.
Так, ну ладно, вы видите, наши телезрители, я так понимаю, не видят.
Чего?
Ну не знаю, ну вы же как-то можете.
Ну понятно, давай камера.
Так, ну-ка.
Ладно.
Так, не можем, так не можем.
Хорошо, вот у нас есть черный цвет.
Ну ладно.
Ладно, прикинемся так.
Так, давайте, бывает серый цвет.
Давайте, бывает такой радикальный черный цвет.
И тут Тарьян отступает от собственных правил и объявляет фиолетовый цвет.
То есть чит заключается в том, что когда мы просто, когда мы достаем вершины из стека, объявляя, что это новая компонента сильной связности, все соответствующие вершины мы красим фиолетовый цвет.
Чем это нам помогает?
А тем нам это и помогает, что вот это вот условие, то есть что на самом деле это все означает маленькую приятную вещь.
То есть это на самом деле то же самое, что ведущие не в фиолетовую вершину.
В какой момент мы фиолетовый красим?
В тот момент, когда вершина достается из стека.
Нет, это не стек DFS, естественно.
Потому что помните, как у нас технология устроена.
То есть DFS устроен так.
Первое, что мы делаем с вершиной нот, это красим ее в серый цвет и добавляем в стек.
Потом пробираемся по всем ее, по всем инцидентам ее вершинам, из кого-то запускаем DFS, что-то насчитываем, оптаем.
А потом в конце говорим, опа, если бы неожиданно выяснилось,
то есть если неожиданно выяснилось, что оптайм от В больше ли бравен таймы над В,
то есть если выяснилось, что это корень компонента,
тогда мы достаем из стека все вершины до себя включителя и утверждаем, что это компонента.
Но там достаточно легко потом будет доказать, скажем, по индукции, что раз это корень,
то у нее есть дерево, на котором висят еще какие-то компоненты,
и они, естественно, ранее будут извлечены.
Поэтому зачем нам нужна была связность?
Ровно для того, чтобы убедиться, что в тот момент, когда мы из этой вершины будем ходить,
после вершины В будет находиться в точности вершины этой компоненты.
И в этот момент, когда мы из этого стека достаем, красим...
Да, и когда мы их достаем, мы их красим фиолетовый цвет, да, совершенно верно.
Но тогда, получается, эти вершины у нас...
Какие?
То есть они, кажется, должны быть черными?
Да, например, у нас четыре цвета, белый, серый, черный, фиолетовый.
То есть вершина в какой-то момент после того, как стала черной, потом становится фиолетовой?
Да, именно так.
Тогда почему мы смотрим в ребра, ведущие не фиолетовую вершину?
Потому что ребра, ведущие фиолетовую, это означает, что они ведут уже в другую компоненту
сильной связи, которую мы нашли, мы их игнорируем.
То есть вот так оказывается такой чит.
То есть вот таким образом получается, как бы мы и этот случай вроде скушали, и тот обошли.
Ну, само по себе это не доказательство, конечно, от того, что мы там каких-то пару случаев избежали.
Но тем не менее...
Но тем не менее, действительно, можно аккуратно теперь по индукции, причем по индукции по таймы,
ну, может быть даже.
Теперь можно попробовать аккуратно доказать, действительно, давайте попробуем более аккуратно доказать,
что вот такая более умная технология сработает.
Как мы это докажем?
А очень просто.
Ну, давайте то аккуратно рассматривать.
То есть жила была вершина В, которая является корнем компонента.
Корнем какой-то своей компоненты.
Мы же доказали, что эта компонента у нас образует тут какое-то поддерево, из нее там кто-то куда-то выходит.
Теперь надо доказать, что аптайм от В адекватный.
Но теперь заметим, куда из поддерева В, включающего эту компоненту, можно вообще выйти?
Ну, тут всякое бывает.
Так, ну да, как можно выйти?
Можно выйти по обратному ребру, но такого не бывает, потому что тогда аптайм будет заведомо меньше.
Прямые ребра не идти?
Нет, в рог, нет, пойдите, нет, логическая ошибка, внимание.
Как мы доказываем?
Мы хотим что доказать?
Вот у нас есть мистическое условие, мы хотим доказать, что для корней оно выполняется, а для некорней не выполняется.
Поэтому пользоваться тем, что для этого оно тогда не выполнится, мы не можем.
Но если у нас есть такой репорт, то аптайм у В точно окажется меньше.
Ну и что?
Нам же требуется доказать, что это не так.
Вот наоборот, еще раз я говорю, мы этим не можем пользоваться.
То есть мы хотим доказать сейчас утверждение вида, пусть вершина В корень компоненты, докажем, что аптайм от В окажется больше либо равен тайм и над В.
Ну окей, если у нас есть такое ребро, то В это просто не корень компоненты.
Да, действительно, если у нас обратное ребро есть, то вершина В как минимум со своим родителем в одной компоненте.
Хорошо, да, такого не бывает.
Так, как еще можно выйти?
Так, можно выйти по перекрестному ребру.
Но, как мы уже помним, действительно, если оно видит другую компоненту, то из этой компоненты мы уже вышли.
Потому что если мы не вышли, то означает, что там есть какой-то предок вершины В, лежащий в этой компоненте, из которого мы тут случайно что-то вышли.
Но тогда, если у нас тут в этой компоненте есть...
Из какого-то предка можно попасть в вершину В, а из потомка вершины В можно попасть в эту компоненту.
Значит это все лежит в этой компоненте.
Ну вот, ну а соответственно перекрестные ребра ведущие
из-под дерева в-под дерева нас не интересует.
Следовательно, uptime от V будет больше либо равен
таймин от V, ура.
Отлично.
То есть корни будут идентифицированы правильно.
Вот, но может быть помимо корней кто-то еще, может
будут ложные срабатывания?
В смысле, false-negative типа?
Ну да, вот сейчас вот начнем путаться, да.
Ну этого не может быть, потому что опять же, если
у нас, посмотрим как мы могли вообще получить uptime
меньше, чем тайна на V.
Сейчас, погодите.
Ну тут наоборот, теперь надо доказать наоборот, пусть
вершина V не корень своей компоненты, тогда докажем,
что uptime будет заведомо меньше таймына.
То есть надо теперь доказать наоборот, что мы выйдем.
Вот, жила была вершина V.
И вот, точнее так.
Нет, не так.
Это была вершина U, это реальный корень, а тут жила была
вершина V.
Тут еще какое-нибудь веселое поддерево красивое.
Надо доказать, что из вершины, вот.
Давайте рассмотрим поддерево V.
И вот, какое-нибудь, да, рассмотрим вершинку, вот, да.
Из вершинки V, поскольку она лежит в KSSU, есть путь в вершину.
Так.
Как он может быть?
Он может либо ребро из V, сейчас, у нас.
А, ну хорошо, вот так.
Возьмем произвольного типа ребенка U, соседнюю вершину.
Возьмем еще.
И теперь U, V.
Вот, и тогда из нее есть путь U.
Ну да.
Ну, кстати, не факт.
А, ну, точнее, да.
Ладно, путь какой-то есть.
И что?
Вот, ну тогда.
Посмотрим, вообще, какие ребра на этом пути могут быть.
Ну, соответственно, там есть, во-первых, это может быть
сначала несколько ребер просто дерева DFS.
Ну, или просто по поддереву ходить еще может быть, мало ли,
там как будет устроить.
Вот.
Ну, и соответственно, у нас есть, и у нас, соответственно,
есть первое, либо обратное ребро ведущее из-под дерева.
Ну да.
Либо перекрестное ребро.
Кстати.
Да, вот рассмотрим первое ребро, которое выходит из-под
дерева V.
Так.
Вот.
Что это за ребро такое?
Ну, это либо обратное.
Так.
Которое вышло из-под дерева, ну и, соответственно, тайны
в конечной вершинке будет меньше.
Да-да-да-да.
Ну, либо это перекрестное.
То тайны тоже.
Тайны тоже будет меньше.
Ну да, эту вершину мы, ну правда, тут надо теперь
сказать оговорчику, что мы эту вершину, другую компоненту
еще не идентифицировали.
Ну да.
Вот.
Да, здесь вот действительно очень важно это сказать.
Но там, да, видимо, рассматривать, видимо, надо, там, видимо,
эти вершины надо не в порядке таймы, а в порядке тайм-аута
скорее.
Ну да.
Вот.
То есть надо сказать, что если мы из вершины вышли,
то ее правильно идентифицировали, корень это или нет.
Вот.
Ну да, действительно.
Но, на самом деле, я только не очень понятно, зачем
вы тут брали ребенка.
Ну, потому что, я, ребенок я взял, потому что я подумал,
ну если у нас прямо из В есть.
Вот вопрос по тайму, у нас W может быть, может совпадать
с В?
Да.
Ну, напоминаю, у нас любая вершина является своим
предком и своим потомком.
И это очень важно обратить внимание, потому что, как
бы, вот, может же так случиться, что у вершины В вообще нет
детей?
Ну да.
В чем?
Даже не в этой компоненте, а вообще.
Как бы, тогда из нее же тоже как-то надо выйти.
Это важно.
Это очень важный момент.
Ну, я просто как-то, да.
Понятно, что в случае, если там у нее нет детей, в деле
ДФС разбирается, если и отдельно, то очень просто.
Ну да, но, в основном, не нужно это отдельно разбирать.
А так доказательство простое, даже не при ребенка беремо,
да.
Итак, из вершины В существует какой-то путь в вершину У,
причем строго по этой компоненте.
Что важно.
Значит, как мы это, значит, рассмотрим какой-нибудь
путь.
Этот путь как-то там ходит, ходит, ходит, ходит.
То есть, там вот этот путь, давайте, тут, то есть он
тут как-то ходит, ходит, ходит, ходит по поддереву как-то
и вот обнаружилось первое ребро, которое из этого поддерева
вышло.
И оно, очевидно, оно либо обратное, либо перекрестное,
причем это ребро на момент его обработки, по крайней
мере, ведет не в фиолетовую вершину.
Вот.
Соответственно, что это означает?
Ну, это означает, что за счет этого ребра тайма
ТВ будет меньше, чем ее таймин.
Почему?
Потому что если у нас, потому что перекрестное
ребро, очевидно, у него таймин будет меньше, чем
таймин от В.
Понятно, да?
Вот.
Так что вот такая вот красота.
Но это на самом деле, кстати, мы такого не доказывали,
но в качестве упражнений оставим.
Вот.
Да.
И таким образом получается, что всего одним, причем
не сильно сложным ДФСом компоненты сильной связности
вполне себе найти можно.
Вот.
Приятно?
Да.
Вот.
Хорошо.
Вот.
Ну, конечно, да.
Нельзя...
Ну, вот.
А можно что-то сказать про порядок, в котором наношли
эти компоненты?
Ну, можем.
Но на самом деле можем утверждать, что, как бы, если мы выпишем
компоненты в том порядке, в котором мы их достали
из стека, то получится политическая сортировка
этих компонентов.
Ну, потому что, действительно, давайте в этом убедимся.
А в чем?
Ну, как бы...
Вы найдете на этот раз?
А неважно.
Ну, нет, просто утверждение такое.
Вот, пусть у нас есть компонента сильной связности, из
которой введет ребро в другую компоненту сильной связности.
Я не знаю, в какую компоненту я войду первой, но я точно
знаю, что выйду я раньше из этой компоненты.
Почему?
Потому что, если я, предположим, первый вошел в эту компоненту,
то по лемме о белых путях до того, как я выйду из этой
компоненты, я войду сюда.
То есть получается, да, обратная топологическая сортировка
на лицо.
Да, ну и, на всякий случай, скажем, это термологический
момент, что если сжать компоненты сильной связи, каждую компоненту
сильной связости в одну вершину, то полученный граф
будет называться конденсацией.
Такое вот слово.
Тоже, тоже, без сомнения, практически всем известно,
но, на всякий случай, упомянуть надо.
Конденсация.
Так.
Вот.
Ну, конечно, да, нельзя не упомянуть, что да, есть,
конечно, и другой алгоритм, почему-то в олимпиадной
среде популярен другой алгоритм, который два DFS-а делает.
Ну, как простой?
В написании.
Ну, да.
Ну, как сказать, на самом деле, если хорошо понимать,
то этот, в общем-то, не особо сложнее.
Хотя, да, технология добавлять что-то там в стер, доставать
фиолетовое, да.
То есть, по написанию есть, конечно, более простой
алгоритм, он называется алгоритм Косараю, кстати.
Да, он тоже именной.
Да, Косараю.
Значит, как он работает?
Ну, работает он, тут уже известен алгоритм, что
действительно, давайте просто запустим DFS, то есть,
делайте два DFS-а, в первом DFS, то есть, все, что нам,
для чего нам нужен первый DFS, это выписать вершины
в порядке, в котором они, в котором мы выходим из DFS,
то есть, в порядке тайм-аута.
То есть, вот выписываем вершины в том порядке, в котором
они вышли, в котором мы из них выходили из DFS.
А что мы теперь делаем дальше?
Дальше мы делаем следующее, мы, то есть, что мы делаем?
Мы реверсим ребра, да?
Ну, да.
То есть, мы там, то есть, меняем направление всех
ребер, потом запускаем DFS, и причем в порядке обратном
вот этому вот уже найденному порядку.
И тогда оказывается, что каждый новый DFS обойдет
ровно новую компоненту сильной связности.
Вот такая неожиданная идея возникает.
Правда, в первую очередь возникает такое, а почему
это вообще так?
Да, почему в ЛКШ или в других школах почему-то берут
и рассказывают вот такое мистическое знание?
Да.
Да.
Да.
А почему же это вообще может быть так?
Так.
Так.
Так.
Так.
Да.
Да, но если мы в какой-то момент из нее вышли, ну,
в смысле, из этой компоненты связности куда-то пошли
дальше, то мы пришли в другую компонентную связность,
которую мы тоже обойдем полностью.
Да.
То есть, тогда получается, вот мы оказались в вершинке,
сначала выпишем полностью компоненты сильной связности
достижимые из нее, потом выпишем ее.
Так.
Ну, тут, смотрите, тут, ну, тут надо поаккуратнее,
потому что если вы утверждаете, что мы выпишем все компоненты
достижимые ее, то это тупо неверно.
Это тупо неверно, ну, например, вот по такой причине.
Сейчас, не совсем так.
То есть, когда мы вот приходим в эту вершину, возможно,
вот эту компоненту не выпишем, потому что мы ее уже обошли
ранее.
Достижимые из нее компоненты, вот, когда мы выписали какую-то
компоненту сильной связности, все достижимые из нее уже
выписаны раньше.
Ну, да.
Потому что они либо были объединены в более ранних
запустах, либо из нее были топы в этот раз.
Так, ну, это с этим я соглашусь, да.
Вот.
Так, ну, что это дает само по себе?
Тогда.
И как бы, да, насколько, и вообще, насколько это надо.
Вот.
Ну, и теперь тогда, когда мы развернем, ну, развернем
этот список вершин и развернем ребра в графе.
Ага, ага.
Тогда вот мы запускаемся от очередной вершины.
Ну, после разворота ребра очередные компоненты
сильной связности сохраняются.
Конечно.
Вот.
Но теперь, так у нас все достижимые, соответственно,
теперь, посмотрим, мы запустились в очередной раз.
Ну, запустились от вершинки, которая еще не была посещена.
Так.
Вот.
Соответственно, у нас опять утверждается, что по
развернутым ребрам, вот так, теперь будем говорить
только про граф на развернутых ребрах, чтобы, вот.
Соответственно, ни в какие вершины после, то есть вот
у нас есть эта компонента каким-то отрезком, да.
Ни в какие вершины после нее мы не зайдем.
Так.
Ну, это более сильное утверждение, однако.
Потому что одно дело, как бы, да, что, то есть как
бы ни одной, то есть как бы мы не обойдем ни одной
компоненты сильной связности, из которых в нее можно попасть,
это безусловно.
Ну, по крайней мере, в развернутом графе есть
в нее, в неразвернутом графе, наоборот.
Но там, как кажется, что-то еще надо более сильное.
Или на момент, или на момент точной формулировки.
Нет, вот суть, на самом деле, правильная, абсолютно, да.
Может быть, только надо ее, может быть, даже ее просто,
то есть где-то попроще сформулировать даже.
Может быть, даже не на языке пути, а на языке вот какого.
Смотрите, у каждой вершины, у каждой компоненты сильной
связности, в первом DFS была первая вершина в которой,
в этой компонент, в которой DFS вообще вошел.
Она же последняя вершина, из которой мы вообще вышли.
Так вот, идея такая.
То есть давайте я сейчас выпишу, то есть давайте вот
сейчас я как сделаю.
Я выпишу эти, вот, выпишу эти компоненты вот как.
То есть, смотрите, я отсортирую компоненты вот так вот,
снизу вверх по тайм-ауту, так сказать, корня.
В корне пишу, конечно, в колычках.
Понятно, да?
Вот.
Значит, почему нам это приятно, да?
То есть, если я так отсортирую пока компоненты,
ну, они там внутри себя как-то устроены, не важно,
а вот ребра между ними я нарисую чуть позже.
И теперь я говорю вот что.
То есть теперь, когда я буду идти в порядке вот обратном
тайм-ауту, то я в каждой компоненте буду в какой-то,
то есть в каждой компоненте я просто зайду в ее сначала
корень, а потом во все остальные вершины, но все остальные
я уже не зайду, потому что неинтересно.
Понятно, да?
Вот.
А потом в каком порядке я обойду корни?
Ровно вот в этом вот.
Логично, да?
Вот.
То есть, по крайней мере, так вот на такой картинке
удобно мыслить.
Это, конечно, пока еще не доказательство.
А в том, что я говорил, то, что мы не попадем ни в одну
компоненту, которая правее, это ведь действительно правда?
Можно попробовать это сделать, доказать от противного?
Ну вот.
А нам, на самом деле, сейчас нужно доказать только одно.
То есть, для того, чтобы сейчас победить, надо доказать,
что в исходном графе нет ребер, ведущих из более низкой
компоненты в более верхней.
Вот надо просто доказать, что вот таких ребер нет.
Потому что после того, как мы это докажем,
выяснится, что после того, как вы развернете ребра,
выяснится, что из этой вершины в развернутом графе
ребер куда-то еще нету, поэтому DFS просто первое,
с чего начнет, войдет в эту вершину, обойдет эту
компоненту.
Потом возьмет эту вершину, а из нее ребра куда будут
вести, только внутри себя и куда-то наверх, а мы его
уже обошли.
Ну и все.
Поэтому давайте докажем, что в исходном графе таких
ребер не было.
Поскольку у нас возрастает тайм-аут корня,
пусть такой ребро есть.
Рассмотрим момент, когда мы его просмотрели в той
компоненте, где оно начинается.
Если мы поэтому ребру не прошли, то какие у нас возможны
варианты?
Либо его конечная вершина была черной, либо серой,
либо белой.
Нет, если белый, то мы по нему прошли.
Так, а в чем проблема того, что по этому ребру прошли?
Потому что тогда бы мы обошли всю компоненту и вышли
из нее раньше, чем мы из этой.
Конечно.
Теперь, если мы по нему не прошли из-за того, что
оно было черным, значит мы из этой компоненты уже
вышли, значит тайм-аут у нее точно меньше, и она
точно меньше, чем мы вышли.
Теперь осталось понять, что серый, а серый это значит,
что оно лежит в этой компоненте.
Ну да, ну да.
Ну можно так, да, то есть действительно еще раз давайте
скажем, что в жилу было вот такое ребро, которое
ведет из компонента, которую мы закончили рассматривать
раньше, в компонент, который мы закончили рассматривать
позже.
Так, ну давайте посмотрим.
Как бы в какой-то момент ДФС у нас пришел в вершину
В, и я добежал до этого ребра, пытался его просмотреть.
Какие у нас были варианты?
Если эта вершина в этот момент оказалась белой,
значит, ну тогда вот этой вершиной вся эта компонента
вообще оказались потомками вершины В.
Но если они оказались потомками, например, это
был бы корень, но допустим это ребро могло вести в
вершину У.
Но проблема не в этом.
Проблема заключается в том, что если эта вершина
оказалась потомком В, то вся эта компонента окажется
потомком В, тогда получается тайм-аут корня окажется
меньше, чем тайм-аут В противоречия.
Хорошо, что еще могло быть?
Это ребро могло оказаться серым.
Так, но если это ребро оказалось серым, то тогда получается,
что у нас в этой компоненте где-то затесался предок
в ДФС вершины В, но тогда отсюда следует, что просто
здесь есть какой-то цикл, который проходит через
вершину В и эту компоненту, значит это просто не две
разные компоненты, а одна.
Так, что у нас еще теперь?
А еще у нас бывают случаи, когда эта вершина оказалась
черной.
Все, просто мы из нее уже вышли, значит тайм-аут
ее уже точно меньше.
Так, это из нее тайм-аут меньше.
Если мы вышли из вершинки, то мы точно вышли из всей
ее компоненты сильной связности.
Ну да, у нас действительно важное утверждение, которое
мы уже активно пользовались, не такое тривиальное,
что если мы из какой-то, что да, если мы тут идем-идем-идем-идем
пришли, и мы говорим, что, и вот мы пришли сюда и
говорим, что предположим, что мы тут пришли в вершину,
из которой ДФС уже вышел.
Ну вот, тогда утверждается, что, так вот давайте это
вот как-нибудь WETX, тогда утверждается, что если WETX
не лежат в одной компоненте сильной связности,
то тогда мы уже вышли, оказывается, из компонента
сильной связности X.
Ну вот, потому что если бы это было не так, то просто
легко было бы показать, что вершина W тоже на самом
деле там лежит.
Да, действительно, оказывается, такая простая штука.
Вот, ну так что, ну тогда действительно рассмотрели все
аккуратные случаи, убедились, что ребер, так сказать,
вверх не бывает.
Ну значит, получается, компоненты будут перебраны
сверху вниз.
То есть на каждое ребро оно либо внутри компоненты,
либо уже посещенную, либо больше вариантов.
Ну, типа да, вратлеры на том же графе, поэтому алгоритма
работает.
Да, ну вот такое, например, доказательство может вполне
себе быть.
Так, хорошо.
Так, так, так, так, так, так, так, так, так.
Так, ну вот, так, ну отлично, отлично.
Ну, значит, вот в этом месте мы, получается, компоненты
сильной связности и нашли.
Так, ладно, есть ли тут какие-то еще, а, нет, погодите.
На самом деле, да, хотелось бы, да, закончить с этой
темы мы не можем, но потому что, конечно, говоря еще,
говоря о конденсации, нельзя не поговорить о знаменитой
задаче два сад.
Так, ну-ка, кто знает, что такое задача два сад?
Так, кто знает, как ее решать за линию?
Так, что-то уже не уверена?
Так, ну давайте кратенько пробежимся, хорошо.
Значит, итак, значит, о чем вообще задача два, как бы
два сад?
О чем это вообще задача?
Вот, ну задача такая.
То есть у нас есть логическое выражение.
В чем логическое выражение вида x1 или x2,
and там x1 или не x3,
там and там не x3 или не x5
и так далее.
Вот.
То есть такая логическая формула,
ну, то есть вот есть такой вид логическая формула.
Нам жутко интересно,
существует ли набор переменных,
да, это булева формула,
существует ли набор переменных,
у которой при подстановке значений переменных,
то есть можно ли каждой переменной
подставить true или false так,
чтобы значение этой формулы оказалось истинно?
Вот.
Или она всегда ложна?
Вот такая задача.
Это называется два сад.
Вот.
Ну, как бы да.
То есть на самом деле это младший брат
такой более страшной задачи,
потому что есть задача три сад.
То же самое,
только в каждой скобочке по три переменные.
Ну, что-нибудь тут от балды.
Ну, просто парадокс в том,
что задача три сад
это одна из классических НП полных задач.
То есть это как бы одна из задач,
и человечество мечтает доказать,
что эту задачу заполиномиальная
от количества переменных
значит время, даже там за N в сотой,
за N в тысячной решить нельзя.
Да.
Ну вот мечтает человечество.
Ну, правда ладно,
или наоборот, формально может оказаться,
что на самом деле за N в какой-нибудь там миллионной
решить и можно.
Правда человечество, конечно,
жутко опасается, что если это атак,
то у нас там просто
вся система безопасности панков порушится к чертям.
К сожалению.
Ну, вот.
Ну, может быть.
Но все равно уже.
Ну, тут так можно сказать.
Наука имеет серьезное...
Скажем так, наука имеет серьезное
highly likely полагать,
что все-таки P не равно N.
Да.
Но наука понимает, что это именно highly likely.
Да.
То есть у нее там есть какие-то серьезные
основания полагать.
Ну, подробности я сейчас не буду рассказывать.
У вас будет курс сложности вычислений,
на котором вы это все очень подробно будете
рассматривать.
Вот.
Но здесь мы упомянем это следующее.
Три сад это у нас какая-то мистическая сложная задача.
А вот два сад, оказывается,
решается за линию.
В чем весьма
неожиданно...
Ну, вот.
Вот.
А, вот так.
Вот. Значит, каким образом?
Ну, потому что заметим,
что формула такого вида
на самом деле эквивалентна
в формуле вот такого вида.
То есть на самом деле, кстати,
в олимпиадах, когда говорят, что задача
1,2 сад, то на самом деле сводит
чаще даже
сразу к вот таким формулам.
Вот.
Ну, каждое такое
или можно заменить на такую
стрелочку. Так, ладно,
не стрелочку, а репликация.
А то там это стрелка,
стрелка кого-то там,
там, по-моему, есть, да?
Да-да-да-да.
Стрелка пирса, штрих шейфера, вот это все.
Да.
Ну, не важно.
Так, ладно.
Ну, это не важно вам
вообще, насколько я помню, экзамен
в этом году сдавать, да?
Ну, вот. Ну, ничего, ладно. Не самый
сложный экзамен.
Или сложный.
Нет, я помню, что-то в наше время
что-то кто-то паниковал, особенно
от такого мистического штуки, как
лямдоисчисление.
Все.
Будет такое?
Ну, вот. Ну, то есть, я не знаю.
Ладно.
Это вот забавно было.
Так вот. Но в нашем случае все просто.
У нас это обычная импликация.
И оказывается,
и оказывается тебе такая, что вот такую
штуку можно представить в виде графа.
Какого?
А вот такого. Значит, заведем на каждую переменную
две вершинки.
Типа на ее как бы
истинное значение и на ее
ложное значение.
И вот идея такая теперь.
Давайте для каждой стрелочки
нарисуем каждую стрелочку как ребрографа.
Но нарисуем не только ее,
а эквивалентную ей стрелочку.
Ну, потому что если из нее x1 следует
не x2, то то же самое, что не x2 следует x1.
Вот мы это вот возьмем и нарисуем.
То есть как бы вот.
То есть у каждой стрелочки есть
активный такой антипод.
Ну и так далее.
Вот.
Ну возникает такая идея. Вот рисовали такие стрелочки.
Давайте найдем у этого графа
за линию компоненты сильной связности.
Но очевидно, что в компонент...
Что нам нужно? Нам нужно
для каждой вершины присвоить 0 или 1.
Причем так, чтобы
в двум напарке кому-то
был присвоен 0, кому-то 1.
Но слава богу, мы выбираем, кому 0, кому 1.
Но теперь заметим, что
присвоить надо теперь так,
чтобы у каждой стрелочки
ни одной стрелочки не было,
чтобы стрелочка ввела из единички в 0.
Помним, да?
Так. Ну, во-первых,
тогда заметим, что внутри компоненты
сильной связности очевидно
всем вершинам нужно присвоить
одно и то же значение.
Но отсюда же автоматически следует,
что если внутри одной компоненты
сильной связности
оказалась переменная
и ее отрицание,
то мы автоматически
говорим, что это невозможно.
Потому что мы доказали, что переменная
эквивалентна
к своему отрицанию.
Но мистическим образом оказывается, что
если такого не наблюдается,
то, оказывается, решение существует
и, более того, его можно конструктивно
найти, оказывается.
Каким мистическим образом?
Очень простым. Вот давайте
рассмотрим топологическую
сортировку
конденсации. То есть вот у нас
какие-то ребра куда-то там ведут,
ведут, ведут, ведут.
Ну, кравка еще не совсем так в душонках.
Тогда рассмотрим самую
правую вершину.
Из нее ребр не торчит.
Поэтому я утверждаю,
что просто ей можно
всем вершинам нарисовать
единичку.
Тогда заметим,
что все стрелочки, связанные
с этой компонентой, будут автоматически
удовлетворены, потому что у нас,
потому что мы помним, да, импликация
такая штука, что если у нее справа единичка,
то она автоматически тру, независимо от того,
что слева. То есть типа,
да, помним, истинно следует
от чего угодно.
Ну и наоборот, из лжи следует
все, что угодно.
Ну тогда выкидывается эта компонента,
но заметим, что у каждой компоненты
есть напарник. То есть есть
вточная компонента, состоящая в точности
из отрицаний переменных, которые попали здесь.
Она не обязательно находится
прямо с краю. Гарантируется
только, что она тоже является
истоком. То есть в нее теперь
ничего не входит.
Но в ней мы тоже рисуем нули, и все стрелочки
из нее тоже удовлетворены,
равно как и внутри. Вот, отлично.
Нарисовали, выкинули. Идем дальше,
справа налево, берем следующую вершину.
Из нее все стрелочки,
ну все стрелочки, исходящие
из нее, уже удовлетворены.
Поэтому
давайте у нее тоже рисуем один,
у напарника там ноль, ну и так далее.
Просто идем справа налево. Все.
То есть все равно. То есть не только
то есть как бы, что приятно, да,
мы не только доказали, что это возможно, еще
в этом видео предъявили алгоритм, как находить.
То есть не этими
вашими, что там
это возможно. Почему?
Ну, потому что если посчитать
вероятность плохого исхода,
то вероятность плохого исхода будет
меньше единицы.
Так.
На эту тему вы тоже экзамены
сдавать будете.
Ой, там этого развлечения.
Или вы уже начали это изучать?
Нет, но
на всяких родных сборах Рейгородский очень радостно это рассказал.
О, да.
Такие только. Нет, он обязательно
на лекциях поищу, про это все расскажет.
Там, собственно,
очень много всего. Вот.
Так что да, это
возможно будет уже... А, ну да, в следующем семестре
видимо это и будет. Хотя...
Ну, тут как бы да.
Формально говоря, как бы в следующем семестре не будет
сервера.
Нет, по-моему, или...
У вас в следующем семестре будет теория меры.
Ну, как бы вроде была
идея
такая, что сначала вы изучите
теорию меры,
а потом будете изучать сервер.
Или вы это будете одновременно как-то изучать.
По-моему, там курс называется основа вероятности
и теории меры.
Ну, хорошо.
Ну ладно.
Не важно.
Ну, суть одна. Ладно, в любом случае, как бы
потом весь этот красивый дискран
у вас все будет.
Ой, от этого вы никуда не тянетесь.
Ну, вот. Ну, а, по крайней мере, вот в двасатом
получилось вот все. Действительно просто.
Да, вот действительно есть такой бы да.
Такой прошлый двасат.
То есть, как вы знаете, вот чалкот.
Потому что, в принципе, есть такой олимпиадный метод, да,
что если вам дают задачу, вы не понимаете, как решать.
А давайте решим задачу попроще, может поможет.
Но не в этот раз.
Да, тут как бы да.
Двасат за линию решили. Трисат.
Да.
Интересно, есть ли хоть доказательство,
что трисат за линию нельзя решить вообще.
Ну, хотя бы.
Ну, увы.
Ладно.
Так. Ну, что ж.
Так, это вроде.
Ну, что мы имеем? Так.
Так.
Это вроде все, что я хотел
рассказать.
Потому что про компоненты сильной связности
и связанные с ними вещи.
Так, ну ладно. Значит, пришло время,
видимо, сделать какой-то перерыв.
Вот, ладно.
После которого мы, видимо, перейдем
к чему-то. Продолжим говорить про
ориентированные графы.
Так.
Ну, впрочем, ладно.
Наверное, нет смысла добить темы.
Поэтому пришло время
поговорить про такую замечательную штуку,
как дерево доминаторов.
Да, ура.
Итак, ну вот.
Что же это такое?
Ой, это, оказывается, замечательная вещь.
Так.
Ну, во-первых, да.
Ведем такое неожиданное
определение.
Значит, тут я, честно говоря, даже не знаю,
как это толком переводить.
Видимо, обычно это термин
граф.
Здесь понятие граф потока управления.
Ну, на самом деле, английский термин
более как-то простой.
Это называется flow graph.
Значит, что это такое?
Это, значит,
соответственно, G, которая
VE
и, соответственно, R.
Значит,
R это какая-то вершина графа.
Вот.
Вот так.
То есть, вот эта проблема,
которую мы упоминали при компонентах
компоненток сильной связности,
то давайте я, чтобы совсем хорошо было
поймать, что это
ориентированный граф.
То есть мы говорим, да, помню, что у нас
не всегда у нас в ориентированном графе
вообще такое бывает, чтобы
существовала вершина, из которой
достижимы все.
Но мы будем сейчас рассматривать
специального вида графы. Вот графы, в которых
такая вершина есть.
Вот, понимаете, да?
Ну, в принципе, да, оказывается, что полезно
такие графы рассматривать. Ну, классические
примеры здесь это,
скажем так, графы состояний в каких-либо
ваших программах.
Или не только в ваших.
Потому что, знаете, у кого-то
возможно впервые за семестр,
просто за год, именно в этом месте
возникнет вопрос, а зачем эта структура
данных вообще нужна.
Да, ну вы пока не знаете, что это, но
теоретический вопрос может возникнуть.
А берется она
вполне себе из некоторых практических
нужд. Вот пример приводится, там,
классический пример такой.
Вот представьте себе, что вам,
вот у вас есть, вы пишете компилятор.
Вот, возможно, в следующем семестре вы даже
реально будете писать компилятор в каком-то
виде.
Ну, потому что у вас будут формалки.
Вот.
Но, как же, вы напишете еще в простом виде.
Но обычно, если писать реально компилятор,
то там есть такая важная штука, как
оптимизатор.
Есть такая, да?
То есть, говорите, хорошо написано,
оптимизатор обычно там где-то в приличное
количество раз вообще оптимизирует
вообще работу вашей программы.
Вот.
Но для того, чтобы оптимизировать,
ну, то есть, нужно как-то хоть как-то
понимать программу.
Вот. В частности, например, можно еще
понимать.
То есть, в частности неплохо было бы
вообще понимать,
там скажем, а верно ли что...
То есть, неплохо было бы понимать,
а через какие состояния
мы вообще проходим.
То есть, нас сейчас будет интересовать
вообще такая задача.
Вот, если уж формулировать задачу, будет
такая.
Даны
вершины У и В.
Можно ли попасть из корня
в вершину В,
минуя вершину У, да или нет?
Вот такую мистическую задачу мы себе
поставим.
Потому что в какой-нибудь оптимизациях это было бы
неплохо.
Ну, простой пример может быть такой.
Допустим, у вас написано так,
там А равно 5,
а потом B там равно
там А плюс А.
Допустим, да?
И вот возникает вопрос.
Ну вот, мы заметим, что в таком виде
есть простая оптимизация, можно
просто написать B равно 10 сразу, правда?
Но если тут написано что-то более
нетривиальное,
там между ними что-то есть,
тогда возникает вопрос.
Ну, возникнет один из вопросов.
А верно ли, что мы сюда попадем
только через эту строчку?
Ну и там еще какой-нибудь вопрос, верно ли, что
там вершина не поменяется?
Ну, просто может быть там было бы,
может еще там есть какой-нибудь там
А равно 7
или еще что-нибудь в этом роде.
Но как бы если гарантируется, что мы как бы в эту
строчку попадем только через эту, то
тогда здесь уже с некоторой
вероятностью можно считать, что B равно 10.
Понимаете, да?
Вот, классический пример здесь
приводится такой.
Вот.
Соответственно.
И вот, соответственно, мы будем пытаться
думать на тему того, что верно ли, что
действительно там
как бы можно ли попасть в какую-то вершину,
минуя другую?
Или наоборот нельзя?
Значит, определение здесь будет звучать так.
Определение.
Значит, U
значит, пусть
значит, U и V
это вершины.
Тогда, значит,
U
доминирует над V
будем говорить мы.
Если
любой
путь
от R
до V
содержит
ну и, пожалуй,
а, ну вот.
А, ну нет, ладно, пожалуй, так.
Обозначение
это U
доминирует над V.
Вот такая приятная штука.
Вот.
Так.
Ну, действительно.
Во-первых, что можно сказать про доминируемость?
Ну, заметим, что доминируемость это отношение
в частичном порядке.
Это нет, как-то ты.
Нет, вообще, да.
Да, ведь действительно.
То есть, действительно, мы можем заметить, что любая вершина
доминирует себя любимое.
Естественно, а также можно заметить, что
что, действительно, если U доминирует V
и там V доминирует
над W, то из этого следует, что
U доминирует
на V.
То есть, у доминирует W.
Ну, достаточно очевидно, думаю.
Но, правда, для частичного порядка еще надо сказать, что если
U доминирует
V и там
и V доминирует
U, то из этого следует, что
тупо U равно V.
Логично, да?
Да, можно говорить про частичный порядок.
Вот.
Но это даже нас не так, чтобы сильно
интересует.
Тут, как бы, можно
то есть, можно заметить и какие-нибудь
более, может быть, отчасти, хотя...
Ну да, можно заметить отчасти более веселую вещь, потому что, конечно,
структура доминируемости, конечно,
там имеет более строгую структуру, чем
вот эту штуку, чем частичный порядок.
Вот.
Потому что...
Тут не было еще каких-то простых свойств. Интересно, у меня случайно.
Сейчас я подгляну.
Кажется, если заметить, что
S доминирует,
R доминирует все,
то это нам даст более-менее полную информацию
о структуре.
Но не совсем.
Ну, все не даст.
Ну, как бы, все не даст, потому что...
Ну, например, просто в частичном порядке есть вот какие-то вот такие ситуации.
А здесь такого не будет.
Что такое не будет?
Значит, я сразу давайте сформулирую.
Давайте какое-нибудь мистическое утверждение.
Если
U дом
V
там W и V
дом W,
то
я утверждаю, что
U доминирует
над V или
V доминирует над U.
То есть нельзя просто...
Если две вершины доминируют
какую-то третью, то кто-то из них
доминирует кого-то.
Вот такое мистическое утверждение.
А, ну-ка, давайте так.
Для разминочки, действительно, это
мысли в эту сторону.
А, хотя нет, я должен был сразу задать это вопрос.
А кто вообще знает, что такое дерево доминаторов?
А, окей.
Так, но тем не менее, тогда хорошо, тогда быстрее будет.
Значит, тогда для разминочки.
А называется...
А почему же это утверждение вернуло вообще?
Рассмотрим...
Рассмотрим...
Вот так.
У нас, поскольку
обе вершинки доминируют
W,
все пути содержат
U и V.
Да.
Вот.
Так.
Ну, вот.
Ну, вот.
Да.
Ну, рассмотрим какой-нибудь из них.
Давайте.
Давайте.
Классический пример.
Рассмотрим такой путь.
Да.
Соответственно, это нам оставляет единственный вариант,
что U доминирует V.
Так.
Ну, давайте докажем это.
Ну, покажем тогда, что не существует
пути,
в котором есть
обратный парень.
Сначала идет V, потом...
А какая разница?
Нет.
Предположим, что у нас есть
такой путь, да?
Тогда...
А что нам даст, что есть путь
R, V, U, W?
Сам в себе он ничего не даст,
потому что...
Вдруг выяснится, что
на всех путях до W уйдет раньше,
чем V, но
U не доминирует над W, потому что есть
что-нибудь еще.
Ну, так сразу,
чисто логически. Зачем нам нужно искать
обязательно именно путь, где идет сначала V,
потом U?
Ну, хорошо, да.
Пусть у нас есть просто путь
из R в V, не проходящий через U.
Ну да, вот так.
На те вопросы на самом деле можно было ответить,
но давайте ускорим процесс и скажем.
Докажем, что U доминирует над V.
Пусть...
Действительно, скажем...
Пусть у нас, оказывается, U не доминирует над V,
то есть существует путь от R до V,
вот я так в обход нарисую,
существует путь от R до V,
который минует U.
Но тогда существует путь
от R до W, минующий U,
который просто от R до V пойдет в обход,
а от V до W пойдет по этому пути,
то есть при нем U все равно нет.
Все.
То есть следовать надо. Если U не доминирует V,
то U не доминирует W.
Ну и, собственно, все. Утверждение доказано.
Вот, понятно?
Ну вот.
Ну что из этого следует?
Тогда отсюда
на самом деле автоматически следует маленькое
приятное определение.
Значит, смотрите.
Пусть, там, допустим,
W не равно K.
Тогда, значит,
V непосредственный доминатор,
непосредственный доминатор W
значит, если что?
Если, внимание, важно,
если V не равно W
и для любой вершины U
не равной W,
доминирующей W,
оказывается, что U
доминирует V.
Вот так.
Обозначение
это будет называться у нас
item от W.
То есть вот такое определение.
То есть, как бы,
то есть V это непосредственный доминатор W,
если все, что доминирует W,
доминирует меня.
Ну и я доминирую.
То есть я доминирую W,
а все доминирует меня.
Значит, утверждение.
Для любой неравной
корню вершины
значит,
этот вот item
существует единственным.
Вот такой вот красота.
Вот спрашивается, откуда я это взял?
Вот почему этот,
почему он вообще существует
и почему он единственный?
Ну ладно, почему он единственный,
это достаточно очевидно,
потому что...
Ну, например, из определения,
из того свойства, что не могут
две вершины доминировать друг друга.
Да, хотя на самом деле
доказательства можно просто
легче даже взять тоже доказательства.
Потому что рассмотрим вершину W
и рассмотрим все, что ее доминирует.
Вот это будет вершина V,
а это вот все остальные вершины, которые тоже доминируют.
Ну я просто возьму,
обозначу последнюю.
Я думаю, что это и есть item.
Почему?
Ну просто потому, что
в экоши доминирует W,
а в тех, действительно, я утверждаю,
что все остальные вершины доминируют на W.
Почему? Ну, потому что если V3, скажем,
не доминирует на W,
тогда мы без вершины V3
доходим до W.
Понимаете, да?
То есть в данном случае технология очень простая.
Вот.
Так что он такой,
то есть действительно,
вот этот, очевидно, является
непосредственно доминатором, двух таких, очевидно,
тоже не бывает.
Вот.
Но тогда просто действительно,
что нам это дает?
А это дает нам очень
удобную штуку.
Смотрите.
Ну, во-первых, заметим,
важный момент, конечно,
в этом утверждении то, что заметим, что
у вершины W существует хотя бы
одна вершина, доминирующая ее.
Что это за вершина?
Да.
То есть, заметим, R доминирует всех.
Железно.
Ну, вот.
Ну, конечно, поэтому мы тут пишем
не равно R, потому что непосредственно доминатор
для R не существует, а для остальных существует.
Вот.
Но, на самом деле, заметим, что если
мысленно вот провести
скажем, вот такую штуку, то есть там вот
проводить в
непосредственного доминатора вот так вот
ребра,
вот, то там,
то получится какое-то очевидно
подвешенное дерево, правда?
Вот с корнем W.
Вот как-то вот так вот, там еще как-то.
Вот.
Это дерево и называется
деревом доминаторов.
То есть дерево доминаторов это
такое дерево на тех же вершинах
и с набором ребер из
у В таких, что у непосредственного
доминатора В.
Вот. То есть, может, там такие вот ребра из
I дом от W в W для всех W, кроме R.
Вот.
Ну, заметим, что такое дерево, в общем-то,
исходную задачу прекрасно решает.
Потому что теперь, если вы хотите проверить
вероятность, что одна вершина доминирует над другой,
вам просто нужно проверить, является ли
она просто предком в дереве доминаторов.
Логично, да?
Вот.
Такая вот маленькая приятная штука.
Такая вот маленькая приятная.
Ну, по модулю, конечно,
по модулю того, а как это дерево
доминаторов вообще строить?
Как дерево доминаторов строить-то вообще?
Чего?
Струтом.
Да?
Ну, скажем так.
Ну, тоже алгорита может быть не самой убойной,
поэтому нет и на каких-нибудь олимпиадах
дерево доминаторов даже подсунуть.
Нет, я как-то видел даже такое вот форси
заточенное дерево доминаторов.
Как это ни странно, да.
Но вот бывает.
Все в этом мире бывает.
Кроме того, что не бывает.
Вот.
Вот. То есть тут, к сожалению,
как нод
I, W, W, тут все
как пойдет.
Вот.
Ну, на самом деле,
как же его построить?
Ну, на самом деле, давайте себе
представим.
Значит, что мы себе
представим? Ну, давайте так, для разминочки.
На самом деле, можно для разминочки,
по крайней мере, попытаться подумать действительно
для каких-нибудь более простых
случаев. Ну, какие у нас есть тут еще
более простые случаи?
Вот.
Ну, на самом деле, есть, конечно,
но
более простые случаи.
Вот. Давайте себе представим, что у нас нет перекрестых
рыбек.
Ну, допустим, запустили DFS
и выяснили, что у нас нет перекрестых рыбек.
Ну, DFS из ДАРа.
Как тогда найти
доминатора?
Вот.
Как вообще понять, да?
Кто же тебя доминирует?
Кто тебя доминирует?
Вот. Ну, если у нас нет
перекрестых рыбек, то какие есть?
Есть, естественно,
обратные ребра
и есть
прямые.
Вот из-за которых, в общем-то, доминируемость
оказывается не такой
тривиальной штукой.
Вот.
Понимаете?
Вот.
Ну, на самом деле, заметим, что
обратные ребра на доминируемость, в общем,
влияют, от слова, не очень, правда?
Вот. То есть можно считать, на самом деле,
что если перекрестых нет, то с точки
зрения нашей задачи обратных нет.
А вот прямые есть.
И вот, внимание, вопрос.
Вот как же нам теперь
научиться находить
для каждой вершины
непосредственного доминатора?
Ну, кажется, в данном случае
если, ну, вот,
будем рассматривать
вершинки там, допустим, вот, по
ну, злобного перьего порядка.
Ну, да, допустим.
И будем с конца смотреть.
Прям с конца?
Вот.
Тогда...
Почему именно с конца?
Может, тогда по тайм-аутам смотреть?
Да?
Ну, порядок чуть-чуть-чуть поменяется.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Что?
Кажется, патейном смотреть нас, по идее, интересует, у нас есть вершинка и, по сути, нас интересует, чтобы, чтобы, ну вот, есть у и в, да, тогда нам интересно, чтобы из у в не было видимо.
Не было видимо пути, по вершинам, стейнам больше, чем у в.
Ух ты, а откуда у нас такие пути вообще возьмутся, учитывая, что у нас, как бы, прекрасных ребер нет.
Ну, в данном случае, соответственно, ну, если, а, то есть, соответственно, получается, это просто единственный вариант такого пути, это, типа, прямое ребро вниз.
Ну, не обязательно одно, не обязательно прямое ребро, ну, не обязательно одно, их может быть несколько.
Ну, потому что, на самом деле, какой-нибудь типичный набор пути от вершины R до какой-нибудь, оно как у нас может выглядеть?
Ну, вот, есть у нас R, вот есть у нас, конечно, классический путь, но как выглядят, допустим, в таком графе все остальные пути?
Они выглядят, то есть, тут есть какие-то прямые ребра, что могут быть прямые ребра, которые куда-то уходят ниже, но нас они не интересуют сейчас.
Вот, а может быть, как-то вот так, вот, то есть, как-то вот-вот так, что-то еще и так далее.
Как может выглядеть путь? Ну, путь может выглядеть там, дойти до сюда, пройти сюда, потом пойти сюда и так далее.
Понимаете, да? То есть, все пути, в общем-то, так выглядят.
И, на самом деле, мы замечаем, что вершина, какая-нибудь U, доминирует над вершину V тогда и только тогда, когда не существует какого-то прямого ребра,
которое как бы обходит вершину U. То есть, начинается выше, заканчивается ниже.
Понимаете, да?
Поэтому нас начинает жутко интересовать. То есть, надо найти самую низкую вершину, которую никто не обходит.
Ну, в данном случае, я, конечно, тут много ребер нарисовал, таких просто не существует.
Хотя нет, тут есть вот, видите, маленькая оговорка, правда, что бывают ребра, которые заканчиваются выше вершины и заканчиваются ниже,
но сейчас нас не интересуют те, кто заканчивается ниже.
Ну, давайте я более хороший пример нарисую.
Там какой-нибудь вот...
А, вот так, надо просто рисовать.
Вот.
То есть, тут какие-нибудь обходы могут выглядеть вот так, вот, еще вот, как-нибудь вот так, вот и как-нибудь вот так.
Нас интересует самое, ну, давайте и в качестве добивочки еще как-нибудь вот так.
И давайте еще вот, существует вот какое-нибудь вот такое ребро.
То есть, нам нужно рассмотреть все ребра, которые ведут из предка V в предк V.
Да?
Вот мы говорим, что, скажем, вот эта вершина не является доминатором V.
Почему? Потому что существует вот это прямое ребро, по которому ее можно обойти, правда?
Вот, понимаете?
Вот.
То есть, по сути, нам нужно делать какую-то такую штуку, что вот у нас есть дерево DFS.
Да.
Для каждой вершинки насчитаем, типа, из какой самой высокой вершинки в нее идет прямое ребро?
Ну, например.
Ну, и нам, грубо говоря, нужно сделать что-то типа минимуму на пути, ну, понятно, что это там...
Ну, тут аккуратно, ну, не совсем.
То есть, минимум-то не особо поможет, потому что надо найти самую...
Надо найти вершину, через которую никто не обошел.
То есть, кажется, более логичным, на самом деле, конечно, так.
Давайте, типа, вот если на этом пути забабахать дерево отрезков какой-нибудь, да,
то давайте просто для каждого прямого ребра, который мы тут нашли,
а мы будем прямые ребра находить именно по его концу,
то мы будем просто во всех вершинах, которые тут между ними, причем именно строго между ними находятся,
там, скажем, просто прибавлять единичку.
То есть, получается, в каждой вершине будет храниться, сколько ребер ее обходит.
И тогда вот в каждой...
Тогда получается, что надо просто найти самый близкий к вершине в...
Долик.
И ребра...
А, и, типа, мы сверху вниз идем, добавляя вот эти вот прямые ребра.
Ну да. То есть, идея будет такая.
То есть, мы когда идем DFS-ом, то есть, когда мы проходим в какую-то новую вершину,
то мы как бы делаем в наш вектор pushback.
Сейчас вот.
То есть, как бы вот, проходим вот сюда из вершины,
то есть, делаем как бы pushback, и...
Что такое?
Ну ладно.
И так, что?
Вот действительно, идем, идем, идем.
Каждый раз, когда приходим в новую вершину, мы делаем pushback.
И прибавляя... Ну вот.
Рассматриваем все ребра и делаем плюс один.
То есть, вершины храним вот в том порядке, в котором они в стеке DFS-а хранятся.
Вот. Ну и там, где... Ну, дерево отрезков, конечно, там.
Ну вот. Ну понятно. В дерево отрезков делать pushback, pushback достаточно легко.
Но для этого просто надо вести дерево отрезков на n элементов
и, в общем-то, просто следить за тем, где мы находимся.
Но тут фишка в том, что когда вы приходите в вершину,
надо вот ко всем вот этим...
Для всех вот этих ребр побавляйте единичку.
Хотя, видите, можете для всех, а можете, на самом деле,
для каждой вершины оставить только прямой ребро,
который ведет из самой высокой вершины.
Видите, да?
То есть, если у вас есть такое ребро,
то вот это ребро, на самом деле, уже практически ни на что не влияет.
Понимаете, да?
Вот.
Поэтому, значит, тут, когда вы проходите вот к этим вершинам,
прибавляйте единичку.
И когда вы ходите из этой вершины,
не забывайте эту единичку вычесть обратно.
Потому что, обратите внимание,
для этой вершины важно, что тут все единичка, единичка, единичка,
и эти вершины не доминируют.
Но, тем не менее, вот эта вершина теперь вполне может доминировать над этой.
Понимаете, да?
Потому что вот это ребро как бы достичь этой вершины не поможет.
Вот.
Поэтому вот такая вот приятная нота.
Поэтому здесь оказывается такая приятность.
То есть, получается, что у вас есть мистический запрос,
то есть у вас есть запрос к, там, допустим, дереву,
то есть у вас получается из дерева отрезков,
в котором вам нужно уметь прибавлять единичку,
вычитать единичку и находить самый правый ноль.
Понимаете, да?
Сейчас.
На какую точку мы вообще нацеливаемся?
Ну, в идеале на керману, конечно.
Так.
А что?
Не, просто...
Ну, давайте, а, кстати, вот вы, раз вы...
Так, а вы слушали лекцию на эту тему?
Да, да.
Так.
На какую точку нацеливались вы?
Ну, я знаю.
Я знаю, мы писали этот лог.
Так.
И примерно знаю, как оно называется, керману, но не особо.
Так.
Нет, ну вот сейчас мы разберемся с этим.
Вот.
Ну нет, я, конечно, не обещаю, что мы докажем о керману, естественно.
Хотя, кстати, завтра...
Ой, хотя лучше не буду я ничего обещать.
Ладно.
Не то у меня сейчас самочувствие, что я, честно говоря, обещал.
Если совсем честно, я был близок к тому, чтобы видеть,
что сегодня занятия не будет.
Но, слава богу, я жив.
Вот.
Значит...
Ну, неважно.
Вот.
Но, в принципе, кстати, вот такой алгоритм уже дает
нам примерно энложечку вообще.
Ну, вы же умеете находить самый правый ноль в дереве,
правда?
Да.
Это было очень мощное предположение.
Да.
Ну, как сказать...
Ну, понятие...
Нет, дело в том, что на самом деле основной алгоритм,
в общем-то, из этого предположения вырастает.
По большому-то счёту.
Потому что будет примерно вот...
Будет примерно то же самое, хоть, конечно, там и то,
что мы сейчас будем продлить, может показаться,
что это не оттуда.
Но, на самом деле, как бы суть примерно та же.
И алгоритм будет примерно тот же.
Ну, кстати, ладно.
Давайте, кстати, на будущее, если забросим мостик...
Вот.
Если использовать дерево отрезков, то получится алгоритм
за там...
Там сколько получается?
m лог n, да?
Спрашивается, можно ли быстрее?
Вот.
Вот выясняется вопрос.
Действительно, можно ли быстрее?
Вот, действительно.
А вот давайте, действительно, 3 минуты подумаем.
А как можно, действительно, вот в этом дереве,
то есть в этом алгоритме, попытаться обойтись без дерево отрезков?
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
А хотя, господи, чего я спрашиваю?
Вы ни одной структуры данных решений знаете, которая
это может сделать?
Ну, в смысле...
Ну, это выглядит, как...
Какой-то СНМчик, типа с чем-то дополнительным.
Ну, как вам сказать?
Ну, с чем пройдет?
Короче, кажется, там что-то, типа, нужно делать, делать
что-то типа СНМа с минимумом на множестве.
Ой, с минимумом на множестве.
Ой, ой, ой.
Это что ж там за минимум такой?
Даже нет, не так.
А, все.
Это...
Ты, короче...
Он уже решается все быстрее, чем Бог.
Это выглядит, короче, есть какое-то ощущение, что
нам нужно делать операции, по типу, у нас есть какое-то
дерево, нам нужно уметь, видимо, в вершинках есть числа,
и нам нужно уметь подвесить вершину, и на пути до корни...
Ну, вернее, подвесить корень куда-то, и на пути до корня
найти минимум.
А как это нам поможет?
Ну, то есть, такая структура данных, конечно, будет у нас
играть важную роль, это безусловно.
Вот, а идея типа...
Вот как же, например, давайте на примере хотя бы такого
действительно поймем, чем это нам вообще поможет.
Ну...
Ну...
Ну...
Ну...
Ну...
Ну...
Ну...
Ну...
Ну...
Ну, кажется, примерно такую штуку делаем, то есть вот
у нас есть вершинка В, возьмем самую высокую вершину,
из которой есть прямое ребро В.
Так...
А дальше будем, видимо, просто сверху вниз идти, строить,
находить доминаторов.
Тогда, вот, пусть мы пришли в очередную вершинку, посмотрим
все вершинки, которые лежат между...
Ну, видимо, начиная вот с этой самой высокой вершинки,
из которой есть прямое ребро, включительно, и до нашей
невключительно.
И что это даст?
Вот.
И найдем среди них ту...
Или до нашей включительной...
А, нет, наоборот, как раз, или до нашей включительной...
Сейчас, ну, короче, взять вот из этих вершинок
ту, у которой вот это вот прямое ребро идет из самой,
как бы, начинается в самой высокой вершинке.
Вот.
И, кажется, тогда...
Ну, да.
Так потом еще эту операцию повторять придется.
Ну, да.
Так, Катя, вы понимаете, что мы говорим вообще?
Да?
Хорошо.
Ну, давайте попробуем.
Вот.
Все-таки, да.
На самом деле, да, взгляд тут может быть немножко
такой.
То, что с деревом отрезков, это я, конечно, немножко
зарнул.
Хотя, как бы, в будущем дерево отрезков нам тоже может
пригодиться.
Но, на самом деле, альтернативный взгляд может быть на это
все такой.
Потому что как нам найти этого доминатора?
Можно найти его так.
Берем нашу вершину В.
Выбираем из всех прямых ребер самое высокое.
Теперь возникает вопрос.
Существует ли, если рассмотреть вот эти, скажем, вершинки?
Ну, можно и эту тоже.
Существует ли из них прямое ребро, ведущее из более
высокой вершины?
Если не существует, то, конечно, все.
Поздравляю.
Доминатора там этого...
Айдам нашли.
Но пусть, вот, пробежать в этом доминаторе, в этом
вершине.
Но пусть, вот, пробежались по всем этим вершинам, откуда-то
нашли.
Вот, допустим, отсюда.
Тогда заметим, что ниже, чем вот эта вершина, Айдама
нет.
И является ли она Айдамом?
Но возникает вопрос.
А может ли ее кто-то обойти?
Ну, надо перебрать все вот эти вершины и понять,
есть ли прямое ребро, обходящее ее.
Но заметим, что вершины ниже этой, конечно, перебирать
уже не надо.
Правда?
То есть, получается, теперь уже мы как бы начали с этого
ребра, перешли к вот этому ребру.
И для него уже надо перебрать все вот эти вершины и понять,
а куда мы вообще можем скакнуть.
Вот.
И если куда-то от этого ребра можем выше скакнуть,
то скачем.
Если нет, то, соответственно, нет.
Вот.
Но заметим, что так как мы скачем...
Ну, фактически у нас получается такая функция скачка от
вершины.
Правда?
То есть, в принципе, можно...
Ну, вот.
То есть, для каждой вершины получается...
Ну, то есть, в принципе, уже мысленность ее можно
вообразить.
Можно либо с тем же деревом отрезков, или там с какими-то
двоичными подъемами, например, еще можно.
Можно сделать так, например.
Ну, то есть, можно сделать так.
Можно, например, для каждого ребра насчитать вот это
предыдущее ребро, в которое мы скаканем.
И получится еще один алгоритм за n лог n.
Ну, m плюс n лог n, правда?
Ну, потому что заметим, что мы из всех напрямых ребер
оставим только одно, поэтому ребер у нас после этого
останется 2n.
Даже меньше.
Вот.
Можно так.
Но, правда, такими...
Ну, вот.
Ну, вот.
Но есть, конечно, и более читерский вариант.
Потому что можно...
Потому что на самом деле, если бы, конечно, умели...
Вот, если бы умели делать операцию pushback и найти минимум
на суффиксе, да, то мог быть, наверное, на самом деле
вполне-таки читерский вариант.
А давайте для каждой из этих вершин посчитаем не следующее
ребро, а насколько высоко из нее можно вообще доскакать.
Таким образом.
Ну, в принципе, нам уже информации хватает на то,
что вот для каждой из этих вершин мы знаем, а докуда
мы там вообще доскачиваем, где мы там вообще упремся.
Правда?
И тогда выясняется следующее.
Что если мы в каждой из этих вершин упремся где-то...
Ну, может так оказаться, что мы в каждой из этих вершин
где-то упремся, причем достаточно низко.
Но если мы во всех этих вершинах упремся где-то ниже,
чем вот эта вершина, то это есть, очевидно, айден.
Понимаете, да?
Вот.
Ну, если мы будем из всех вершин упираться в сам айден,
в саму эту вершину или ниже, то это тоже айден.
Понимаете, да?
Вот.
Но если хотя бы у кого-то из них мы упремся, значит,
мы все-таки упремся где-то выше, то, значит, это не айден,
и на самом деле у этих вершин просто надо, там, видимо,
просто из этих вершин возможно выбирать этого айдена.
Вот, понятно?
То есть в результате разные варианты получаются.
То есть теперь один из вариантов можно было...
Теперь давайте просто из этих вершин,
попытаемся на этом пойти, найти минимального айдена.
Понятно, да?
Ну, минимального по таймыну, естественно.
Вот, понятно, да?
Вот.
Но, правда, теперь у меня есть какая-то вопрос.
Даже если мы таким образом насчитываем минимального айдена...
Сейчас понятно, к чему мы говорим, да?
Если мы насчитываем...
Допустим, мы в каждую вершину приходим и насчитываем вот так вот
минимального айдена.
Но как бы...
Как делать вот этот минимум на отрезке?
Ну, получается, да, можно делать дерево отрезков ДО-шкой,
можно делать двоичными подъемами.
Вот вам, кстати, как предлагалось?
Чтобы я понял.
Я это делал точно...
Нам это не предлагалось в конкретной реализации,
нам было сказано, ну, придумаете сами.
Я придумал какой-то костыль.
Ух ты, прикольно.
Вот.
А кто рассказывал?
Не понял.
Окей.
Ладно, популярная вещь.
А где это было?
У меня 21...
21-22, видимо.
Ого.
Зима.
Зима.
Зима.
Ну да, логично.
В десятке рассказывали.
В десятке.
Ну, нормально.
И что, им много задач на это предлагали?
Аж четыре.
Аж четыре.
Ого.
Серьезно.
Окей.
Так вот.
Ну, значит, что тут предлагается?
На самом деле, да, есть способ, как это попытаться сократить.
Как асимтотику здесь сократить?
Но способ нетривиальный.
Мы его сегодня до конца, видимо, не изучим.
Вот.
Сейчас.
Ну, ведь нам же не только можно pushback и, типа, минимум
на суффиксе делать.
Ну, и popback еще.
Да, еще popback.
Но.
Это какая-то...
А в чем проблема?
Ну, если бы pushback минимум на суффиксе, можно было
было бы, типа, за n-nakerman сделать довольно тривиально.
Так.
Если что, говорите?
Если только pushback минимум на суффиксе, то это делается,
типа, за n-nakerman довольно тривиально.
А каким образом?
Ну да, тем более, что правда задача получится на бамбуке,
на самом деле.
Ну нет, если вы хотите делать только pushback и не делать
popback, то получится бамбук.
Ну да.
Так.
Ну, давайте ладно.
Не так же много дома.
Давайте я просто сразу скажу, в какой структуре данных
вообще хочется это сводить.
Вот.
На самом деле есть такая мистическая структура данных.
Называется там eval-link.
Ну, на самом деле такое.
Есть eval-link, а есть на самом деле eval-link-update.
Так.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Ну, может быть, более продвинутый, чем нам надо.
Вот.
Значит давайте, сейчас я просто возьму, даже просто
рисую, чтобы у меня определение было надежно.
Так.
Ой, мясо, мясо.
Значит что это за структура данных?
Значит структура данных такая.
Значит, у вас есть вершины.
Ну, практически чем-то
похоже на линкат, но более простая версия,
чем линкат.
Значит, у вас есть
какие-то подвешенные...
Значит, у вас есть вершины, которые составляют
набор корневых вот таких деревьев.
Какие есть операции?
Есть операция линкатува.
Ну, здесь все просто.
То есть, берем вершину У
и какое-то вот прям дерево В,
под деревом подвешиваем. В, конечно, должно быть
коке.
Что еще есть?
Есть еще какая-то мистическая штука.
Ну, вот. Ну, здесь на самом деле по-разному.
Ладно.
Так, ну ладно.
Значит, с Эволом будет звучать так.
Значит, на самом деле представим себе, что в каждой
штуке еще стоит
какое-то число.
И у нас появляется функция
там, допустим, Эвол
от В.
Что это такое?
Это означает, мы берем вершину В,
берем путь от ее корня до В
и возвращаем
что-то.
Ну, Эвол, на самом деле, там есть какие-то
ограничения. То есть, я там...
там какие-то там, я уже есть, честно, я даже не помню.
То есть, там какая-то...
Представим себе, что на этих числах есть
какая-то там ассоциативная операция с какими-то
свойствами.
Ну, правда, не любая ассоциативная операция.
К сожалению, не любая.
Ну, там как-то адекватно, потому что...
Ну, ассоциативная, конечно.
Ну, да.
Ну, залог, конечно, очевидно, да, потому что
двое там...
Стоп, а почему?
А, потому что линка там, да?
Нет, потому что...
При каждом Эволе можно эту операцию, типа...
Ну, типа, считать в тупую, а потом просто сжимать.
А, ну да.
В общем, короче, так, вот Эвол, ну, можете вообразить себе, что это какая-нибудь
функция на пути от R до V.
Что это может быть за функция? Может быть сумма,
ну, там по-разному, может быть сумма на пути, может быть
минимум на пути.
Может быть даже
arg-минимум на пути.
Ну, потому что, например, вот наши задачи нас будет
интересовать не сам минимум, а где он, собственно, находится.
Ну, что-то такое.
Ну, в принципе этого хватит, но на самом деле бывает еще
какой-нибудь апдейт.
Вот, не буду я сейчас рисовать, хотя там, возможно, даже выяснится, что апдейт
это просто, типа, давайте не будем заморачиваться
над значением в корне.
А, правда, еще маленькая оговоречка, что в этой структуре для удобства говорят, что
R может быть,
например, невключительно.
Так вот, давайте представим себе, что мы, ну, вот.
Значит, да, как это сделать?
Ну, на самом деле,
ну, мы сейчас не будем особо вдаваться,
но предположим,
что есть мистическая структура данных,
что, ну, что как-то можно это реализовать,
скорее всего, видимо, завтра уже будем обсуждать как конкретно,
что это можно сделать так, что все эти операции, хоть и амортизированы,
но делаются за O от
вот этой вот какой-то мистической там обратной функции Акермана,
уже даже не знаю, с какими аргументами там вставлять.
Ладно, если повезет, может завтра даже разберемся.
Что это такое вообще?
Вот, потому что, в принципе, разобраться-то можно.
Так что вот такая неожиданная штука.
Вправивается.
Значит, это у нас был линковал.
Вот предположим, что нам повезло, и мы такое умеем.
Ну, в принципе, да, залог, ну, скажем так,
оказывается, потому что в этой структуре, я так забираю вперед,
так просто для затравочки скажу, что оказывается,
ну, просто заветим, что это как бы облегченная версия линката,
потому что никто никого не режет, правда?
И это означает, что на самом деле эта структура поддерживает
эвристику сжатия путей.
Ну, потому что если вы там, скажем, пусть от V до корни искали,
то если вы когда-нибудь еще придете от вершины V,
то как бы можете второй раз этот путь не проходить,
а просто скакануть сразу, правда?
Ну, потому что все равно этот путь будет.
То есть, в другом случае, этот корень может еще к чему-то подвеситься,
поэтому как бы это будет, но сжатие путей остается сжатием путей.
Понимаете, да?
И там вот такая, ну, есть серия о том, что, в принципе, там,
ну, так в простой версии говорит так, что просто сжатие путей,
если вот просто рандомно, оно само по себе уже дает вам хоть амортизированное логорифом,
а если дерево еще какое-то хоть насколько-то адекватное,
ну, вот, то тогда, оказывается, обратная функция кирмана работает.
Ну, адекватность там что-то типа, что на каждой глубине вершин
там не более, чем там, сколько-то, какая-то там степень чего-то там.
Вот такая вот неожиданная радость.
Вот.
Ну, или что-то такое, не боимся скопать.
Так вот.
Ну, вот теперь вот предположим, что у нас откуда-то взялась вот такая структура.
Предположим, с минимумом, ну, или, понятно, одно и то же максимумом мы ее откуда-то возьмем.
Вправивается.
Чем она нам здесь может помочь?
Ну, почему неважно, корень включительна, корень не включительна, даже не так принципиально,
если честно.
Ну, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то, что-то
Откак, надам, поможет.
Вот тут хочется, чтобы вы поняли, чтобы вообще понимать происходящее.
Вот тут хочется, чтобы вы поняли, что происходящее.
Ну, кажется, если мы найдем вершинку на вот этом отряде,
то мы найдем вершинку на вот этом отрезке от В до, да, не знаю, короче, до самого высокого ребра,
короче, до самой высокой вершинки, из которой есть ребро В прямое.
Так, ну такое ребро мы найдем, естественно, легко.
Найдем вершинку, у которой ее прямое ребро выше всех?
Так, найдем. Ну или что, то же самое ребро ведет из вершины с минимальным таймином, да.
Вот, и кажется, доминатор для вершинки В просто совпадет с доминатором для...
Ну, не совсем, не совсем.
Давайте, а вот здесь я аккуратно скрою, потому что сейчас уже явно сложнее пошло,
видимо, надо, мне кажется, точнее формулировать.
Ну-ка, давайте внимательно.
Так, давайте, значит, введем, введем, значит, так.
Давайте вот это вот.
Значит, для каждой вершины В, значит, для вершины В можно ввести понятие, какое.
Так, ну давайте как, как вот эту, значит, ну давайте так и введем.
А под В.
А под В.
Это, значит, такой аг...
Там агмин такой, таймин.
От У.
Такой что?
У.
Значит, что...
Там УВ это прямое ребро.
Вообще, кажется, было бы очень сложно в самом начале сказать, но давайте перенабируем вершинки, чтобы...
Вот, то есть давайте, ну вот.
Так, ну правда маленькая оговорка, что делать, если в вершину В не ведет ни одного прямого ребра?
Ну тогда кажется, ее предыдущий является ее доминатором.
Ну да.
Потому что сверху в вершину В мы попасть не можем.
Да, поэтому давайте с этой целью скажем или там В, если таких ребер нет.
Так.
Ну я просто пока ввел такое АБ.
Ну, утверждение, да.
Понятно.
Если оказалось, что...
Там А под В равно В.
То, соответственно, как мы понимаем...
Айдом от В.
Равно перонт от В.
Впрочем, скажем так, если мы верим в кратные ребра, то можно еще уточнить.
Можно так сказать, если А под В равно В.
Или даже можно сказать не так.
Таймын А под В больше либо равен таймына...
Вот здесь четеньким напишу, перонт от В.
О.
Ну потому что я здесь имею в виду что?
Если у меня есть прямые ребра, но они все ведут из родителя,
то тогда родитель все еще доминатор, правда?
Ну может быть так, правда?
Так что получается вот такое простое утверждение.
Понятно, да?
А там не должно быть, что если таких нет, то не В, а родитель В?
А под В определится?
Ну кого нету?
Если прямых ребер нет, то да, Айдом от В это родитель В.
Ну родитель В, сам родитель В является заведомо доминатором,
потому что вы без него, мимо него просто не обойдете.
Вот.
Но это как бы еще простой случай.
Если так произошло, то да, нам повезло.
Вот.
Но что делать, если есть?
Значит давайте тогда попробуем так сделать.
Определение теперь.
Значит пусть А под В не, прям глубоко не равен ни В, ни Вр под В.
Тогда.
А что тогда?
Что тогда?
Тогда мы сделаем вот что.
Тогда нас очень интересует вот такой путь.
То есть как бы вот это вот пусть это будет вершина В, а вот это будет А под В.
Я сказал.
Вот.
Это называется, я сказал, Вася не тупи.
Вот.
Короче, я могу это сказать, потому что Вася здесь нет.
Это не будет подано, да.
Так.
Ну вот, значит это у нас тут такое ребро есть.
Тогда что нас интересует?
Нас жутко интересует прибежаться по всем, даже вот не вот этим, а всем вот этим вершин.
Видите, да?
И найти среди них минимум, да.
Понимаете?
Значит, я хочу ввести определение, поэтому я введу еще одну такую синенькую функцию.
Значит, что я хочу?
Я введу mean up от V.
Это на этот раз, давайте так, arg-minimum.
Arg-minimum чего?
Arg-minimum.
Давайте так.
Таймы от up от V.
Ой, может быть up.
Нет, нормально.
Только при этом, смотрите, я это, ну вот.
Знаете, я здесь вот так сразу нарисую.
Up от V.
А дальше я нарисую черненьким.
Только тут не up от V, а up от W, конечно.
Вот.
Так, я что-то вообще умное нарисовал, да?
Хотя на самом деле это, ну скажем так, это тоже стандартное обозначение Тарьяна.
Да, это тоже алгоритм Тарьяна.
Мы обсуждать сейчас будем.
Ладно, Тарьян там как соавтор идет, правда.
То есть мы берем arg-min по всем вершинкам, которые строго между V.
Ну, смотрите, нет.
Смотрите, вот этот значок означает, что существует.
Ну, в данном случае мы будем вот так говорить, если W это потомок up от V, причем строго потомок.
То есть по идее вот этот значок означает просто V потомок W.
А этот значок означает, что W потомок up от V, но не совпадающий с up от V.
Такой полуинтервал берем.
Да.
То есть вот это я давайте помечу.
Ну, просто вот если вы там будете читать статью, а возможно вы будете читать статью.
Ну, там, кстати, красивая статья.
Знаете, что можно сказать про статьи, которые писал Тарьян или его сокомандники.
Ну, кстати, к сожалению, я запамятовал, кто там идет сейчас как соавтор Тарьяна.
Но тут очень интересна, на самом деле, история.
Потому что, знаете, я как-то кому-то упомянул, что я многие лекции какие-то основываю на просто оригинальных статьях авторов.
Ну, вот.
И, собственно, кто-то.
Ну, ладно, как кто-то.
Глеб Левстропов, если быть точнее, если вы такого знаете.
Знаете такого?
Нет, не сталкивались?
А, ну да, логично.
Ну, вот, не важно.
Ну, в общем, был такой старый олимпиадник от МГУ.
Там, примерно, на год младше меня, там двукратный золотой призер СПС.
Вот.
В одно время, кстати, координатор Код Форсис.
Вот.
Так вот.
Значит, он сказал, ну вот.
Нет, он сказал, чего?
Читает, читает.
Пали просто по оригинальным статьям.
Там же вообще они же там мерзко написаны.
По ним разобраться невозможно.
Ты чего?
Ну, в смысле?
Нормально.
Читал статьи.
Нормально.
А, нет, ну, Тарьяна, нормально.
Да.
Вот.
Так что вот.
Ну, в принципе, действительно.
На самом деле, там, как и другие авторы, например, там
Паша Маврин, собственно, подтверждает, что там статьи
Тарьяна, на самом деле, достойны того, чтобы их просто
отдельно читать, потому что это действительно хорошие
статьи.
Вот, кстати, вот алгоритм Тарьяна про поиск компонентов
сильной связности тоже, на самом деле, можно почитать
просто в оригинальной статье.
В чем-то статья называется простым образом.
Там что-то Depth First Search and East Appliances.
Вот просто DFS и его приложение.
Прямо по названию у меня возникает ощущение, как будто
я не проверял, правда, что это реально первая, просто
едва ли не первая осмысленная статья про DFS.
Датируется в 75-м году.
Вот поэтому у меня возникает ощущение, что DFS у нас появился
в 75-м году.
Хотя нет, то есть сам по себе DFS там знали еще в 19-м веке,
в том или там, хотя бы в том или ином виде, хотя бы
в виде какого-то интуитивного перебора, судя по всему.
Ну вот, честно говоря, есть ли более ранние статьи
про DFS, мне неизвестно.
Вот.
И это при том, что, как вы помните, алгоритм Dijkstra
это 59-й год, там всякие прямые краскалы, это тоже 50-й,
Барубка вообще 26-й.
Ну нет, ну об этом мы явно будем разговаривать, может,
видимо, даже сегодня чуть-чуть затронем.
А может, правда, и не успеем, я не знаю.
Ну почему, ладно.
Будет зависеть от меня и будет зависеть от вас.
Вот.
Так вот.
Здесь вот про дерево доминаторов тоже, соответственно, есть
его статья, тоже рекомендую найти, и на самом деле
будет хорошо.
Вот мы будем следовать прям четко по ней.
Но, правда, честно скажу, то есть там просто идет,
что давайте введем такие понятия, докажем какие-то
теоремы, из этого выведем, что есть вот мистический
алгоритм, который работает.
Но я, конечно, иду не совсем так.
Я сейчас, прежде чем пройти по этой статье, хотя вот,
честно, лемма, которая есть, мы как бы скрупулезно
пройдем и докажем.
Ну вот.
Но, собственно, мне кажется, перед этим мы все-таки, значит,
рассмотрим вот такой алгоритм и, собственно, пытаемся
понять, откуда он берется.
Впрочем, итальян намекал, что на самом деле он берется
примерно отсюда.
Так вот.
Вот это тоже обозначение Тарьяна.
То есть это такое обозначение, что, значит, вот это обозначение,
которое говорит нам о том, что w предок v.
А здесь говорится, что a под v собственный.
Там предок w.
Вот.
Это просто вот эквивалент.
Ну вот.
Мы можем его означать так.
Может, нам это даже пригодится.
Вот.
Именно вот.
Нас интересует именно предок.
Не просто там какой-то там путь есть, а вот именно
так.
Так вот.
Рассмотрим вот этот минап.
Да.
Это я вот просто ввел такое определение.
Чем оно нам помогает?
Ну, во-первых, заметим, что, конечно, таймин от минапа,
он как бы либо таймин апа, потому что мы и вершину
вычитываем.
Либо кто-то выше.
Да?
Ну, теперь сразу возникает мистическое утверждение.
Так.
Нет, сейчас таймин.
Чего?
Вот.
Теперь мистическое утверждение.
Если таймин от этого минапа, если таймин от этого минапа
больше либо равен таймин от ап от v, то я жестко утверждаю
маленькую приятную вещь.
Догадываетесь, какую?
Вы нашли таймин апа?
Да.
То аидом от v это тупо ап от v.
Кстати, да, кажется, я вспомнил, что на самом деле правильнее
в ап от v знаете, что сделать?
То есть на самом деле написать здесь не v, а вот того самого
родителя.
Потому что заметим, что если я подставлю тут родителя,
то вот это утверждение, то тогда вот это можно вычеркнуть.
Да?
То есть просто, а, ну не важно, просто вот это условие
надо вычеркнуть.
То есть на самом деле просто мы убираем.
Слушайте, как классно.
Так.
И тут написать, на самом деле пусть, ну естественно,
v не равно r.
Понятно, да?
Так вот.
У меня возникает вот такое простое такое мистическое
утверждение.
Ничего мистического в нем нет.
Ну, потому что, по большому счету, оно нам говорит что?
Оно нам говорит о том, что вот у нас есть от v до ап от v.
Причем, кстати, знаете, тут для удобства вообще можно
считать, что любое ребро дерева dfs дублируется кратным
прямым ребром.
Да?
Но просто фишка в том, что как бы, смотрите, то есть у
нас есть вот из v мы скачем в ап от v.
Это самое высокое, куда можем скакнуть.
И при этом из этих вершин мы как бы в обход от ап
от v скакнуть не можем.
Но тогда, собственно, очевидно, что ап от v это непосредственный
доминат.
То есть, в общем-то, ничего пока, ничего сильно мистического
в этом утверждении нет.
А теперь давайте попробуем угадать напарника.
Если оказалось, совершенно случайно, что таймин от
этого минапа оказался строго меньше, то есть если мы
скакануть меньше можем.
Так, ой, а правильно ли мы сформулировали утверждение?
Погодите.
Таймин от минапа, заметим, всегда больше либо равен
таймин от ап от v.
Потому что это какая-то из этих вершин.
Видимо, апа от минапа.
Да.
Давайте вот так.
Ой, Господи.
Господи, кто эти обозначения выдумал вообще?
Так.
Подпишитесь, а почему я от этого отказываюсь?
Самое смешное, я вам даже больше скажу.
Так я об этой статье так и сделал.
Кстати.
Что, автор лекции ВЛКШа тоже так предлагал делать?
А, ну вот.
Ну понятно, да, на чем он базировался.
Но я вот не знаю, мне почему-то, вот мне эта идея почему-то не нравится.
Ну я не знаю, потому что это, то ли, потому что это надо либо держать в голове,
либо вот как-то путать, вот потому что у меня ощущение, что вершина это все-таки,
вот знаете, как в куче Фибоначчо вот он воображали, что вершина это не число,
вершина это какой-то камешек, объект какой-то.
Поэтому, поэтому соответственно.
Поэтому я все-таки предпочитаю писать на тайминах.
Хотя, в принципе, да, Тарьян честно так сказал, давайте перенумируем вершины в порядке тайминов.
Да, просто так и сказал.
Это же действительно очень сильно упрощает жизнь.
Ну, написание, по крайней мере, упрощает.
Ну как, а под минап он никуда не денешься?
Ну да.
Ну хоть в лажности поменьше.
Ну да, но неважно.
Нет, можно было по-другому, можно было ввести понятия, сравнивать по тайминам,
но это значит тут не писать тайминам, а тут неравенство, писать тут тейни какой-то.
Нет, у меня еще бывало сокращение от веса таймы на тайин, писал еще.
Вот, но неважно.
Ладно, ладно, суть в общем поняли.
В любом случае, да.
Это мы убираем.
Слушайте, вот тут.
Господи, слушайте, вот реально, по-моему, у этой аудитории единственный недостаток, по-моему, есть это.
Очень далеко ходить кофе брать.
А так прям, прям хочется прям из нее не вылезать.
Вот.
Так вот, значит, что делать?
Значит вот теперь у нас получается так.
Если у нас тут ни одно прямое ребро здесь так и не вылезло выше А под В, то аидом нашли.
А что делать, если...
А что делать?
Кажется...
Вот.
Если мы возьмем доминатора вот этой, доминатора А под В, не на под В.
Так.
Кажется он будет...
Вот, ну на самом деле, да, давайте вспомним, какая у нас вообще идея была.
Идея у нас была такая, что предположим, что здесь можно куда-то выскочить выше.
Тогда что мы делаем?
Мы находим вершину, с которой можно прям совсем-совсем максимально выше выскочить, да?
И в принципе говорим, что теперь из этой вершины надо повторять операцию.
То есть теперь из этих вот вершин надо скакнуть как можно выше.
Ну отсюда-то мы выше уже не скакнем, правда?
Поэтому надо из этих вершин скакнуть еще выше, еще выше, еще выше.
Вот, а там мы уже посчитали все эти...
Вот.
Да, но заметим, что это буквально...
Но заметим просто маленькую приятную вещь.
То есть если скакать вот так вот выше-выше-выше, то это будет идентично тому,
что бы мы делали, если бы для этой вершины искали айтом, правда?
Понимаете, да?
То есть отсюда следует...
То есть получается, можно сформулировать маленькое приятное утверждение.
Значит, формулирую.
Тогда отсюда следует, что айдом от V равен просто этому айдому от этого вот минапа от V.
Все.
Неплохо, правда?
Так, ну что ж.
Ну вот.
И выяснилось, что даже это не сильно сложно.
Типологично, да?
Ну это надо как-то аккуратно посчитать.
Ну теперь давайте подумаем, как это аккуратно посчитать.
Хотя с другой стороны, если у нас есть линк и вал, то в целом вот эти минимумы...
А, не скажите, не скажите.
То тогда аккуратно.
Потому что линк, ну как сказать...
Линк и вал, обратите внимание, в линк и вале мы и вал считаем до корня.
То есть опции там, как там хочется взять дерево, прорисовать к нему одну вершинку,
уметь считать минимум до куда-нибудь у нас не работает.
Поэтому идея на самом деле будет такая.
Значит, что нам вообще надо?
То есть минимум чего надо считать?
В общем, минимум, а под w, правда?
Ну, в общем, самое главное, что нам нужно...
Ну, в принципе, можно предположить...
Если предположить, что у нас DFS не один, а у нас DFS...
То можно даже вообще для простоты предполагать, что у нас есть самый нулевой DFS,
который просто определил, кто тут реабредиривает DFS, а кто прямые, да?
Тогда давайте сделаем так.
Это был нулевой DFS, мы это как-то выяснили.
Теперь давайте запустим DFS и попытаемся как-то насчитать, вот самое главное,
минапы.
Ну таймыны мы уже насчитали, это понятно, да?
А теперь давайте как насчитать минапы?
Вот как эти минапы насчитать?
А на самом деле весьма неожиданным образом.
То есть, как вы знаете, это будет сейчас очень просто, но придется немножко голову повернуть.
И голову повернуть предлагается следующим образом.
Смотрите.
То есть, вы запускаете DFS.
И вот приходите вы в вершину В.
Значит, когда вы приходите в какую-то вершину В,
значит, вы говорите следующее.
Так, переберем...
Значит, не только, ну понятно, там, переберем детей и запустим DFS от нее, естественно, да?
А еще скажем следующее.
Переберем все ребра ведущие в нее.
Вот, допустим, вот эти прямые ребра, да?
Да что это вы...
Вась, ну что ты тупишь ему?
Ай, Господи.
Умный какой.
Так.
В общем, возьмем все эти ребра.
Выберем из них самое высокое.
В высокое.
И, значит, это будет такое А под В.
Так вот.
И в эту вершину А под В, значит, у нее вот такое...
Запишем в ее некоторое множество вершину В.
То есть, идея такая.
Я хочу для каждой вершины посчитать, а для кого она А под В.
Понятно, да?
Вот.
И теперь у меня...
Ну, теоретически я такое могу делать.
Ну, тогда у меня просто будет идея такая, что я запускаю DFS.
Когда запускаю от детей, у меня по окончании запусков от детей есть полный список всех вершин, для кого я являюсь АПом.
Понимаете, да?
Вот, понимаете?
Так вот.
Для чего я это делаю?
Делаю я это вот для чего.
Дело в том, что я как бы не просто запускаю DFS по вот этому дереву черному.
А я это дерево как бы пытаюсь восстановить...
Ну, пытаюсь это дерево как-то восстановить...
В процессе с точки зрения линковала.
То есть у меня идея такая.
Изначально у меня все вершины лежат по отдельности, да?
Но идея у меня в том, что когда я выхожу из вершины DFS-ом, из этой вершины,
я это ребро как бы добавляю в линковал.
То есть просто подвешиваю эту вершину к этой.
Понимаете, да?
Для чего я это делаю?
Ну, я могу теоретически такое делать.
Это в общем не проблема, правда?
То есть просто как бы в каждой вершине V я запускаюсь от детей,
и после каждого запуска от ребенка я этого ребенка подвешиваю к себе.
То есть таким образом получается, что по окончании запусков от детей
получается у меня в линковале есть вот это поддерево вершины V
создано, то есть просто полностью воссоздано, причем оно подвешено именно к вершине V.
Пока логично, да?
Ну а теперь зачем мне это нужно?
А дело в том, что когда у меня будет вершина A под V, это произойдет, да?
То есть я запустился от детей,
я вот для A под V у меня есть в линковале поддерево с корнем в себе любимым,
полностью копирующее вот это, правда?
А также у меня в A под V есть список, для кого оно является...
для кого оно является АПом.
Ну тогда у меня идея такая, для всех этих, ровно в этот момент,
тогда вот этот вот mean-up я могу просто посчитать с помощью этого линковала,
если линковал у меня на минимум.
Причем на минимум видите чего?
Значит, на минимум, соответственно...
Видимо все-таки на A.
Нет, ну видимо на таймы.
Ну потому что идея такая, то есть как бы, смотрите,
то есть значение вершины в каждом мини... значение вершины это, собственно, таймы ее АПа,
понимаете, да?
Вот таймы.
И то есть значение такое...
Нам определенно нужно ARC минимум.
Что?
Нам определенно...
Ну хорошо, нужен, да, нужен, конечно, ARC минимум.
Да, ну точнее так, значение это таймы,
и нам нужно уметь искать не сам минимум, а откуда он взялся.
Ну да.
Да, безусловно.
Вот.
Ну как-нибудь...
Значение это таймы от АПа...
Так, ну да.
А искать нам нужно саму вершину.
Да.
Так что прям вот...
Да, совершенно верно.
Совсем частный ARC минимум получается.
Да.
Совершенно верно.
То есть тогда, если вы находите этот аккуратный минимум,
то есть тогда просто, если вы делаете, действительно, значит, eva-link на ARC минимум,
то тогда получается, что с помощью этих запросов вы для каждой вершины вычисляете вот этот минимум,
и, по крайней мере, в этом, так сказать, первом DFS не считая нулевого,
вы выясняете, по крайней мере, к кому из вершины V обращаться в поисках Айдама.
Ну вот.
Да, ну первое, что вы должны для вершины V сделать, это, конечно, ее AP насчитать, но это легко делается.
Понимаете, да?
Вот.
Значит, что у нас теперь?
Значит, есть вот такое утверждение.
Ну вот.
Но тогда, значит, если вы там каким-то DFS мы считали просто сами вот эти Min-Ups,
то после этого вам останется только, ну, самое тупое, что можете делать,
это вторым DFS приближаться по вершине, да?
То есть по вторым DFS приближаться и для каждой вершины сказать так.
Вот.
Ну, если это утверждение, то записываем Айдам тут же,
а если выполняется вот это утверждение, то Айдам просто копируем из вот этого Min-Ups.
Понимаете, да?
Вот, собственно, и все.
Вот.
То есть тогда получается, что мы справились с двумя, в скобках, тремя DFS,
хотя, видимо, если внимательно посмотреть, то, скорее всего, мы можем обойтись и без лишних DFS.
Ну, по-моему, там Тарьян, по-моему, одним DFS обходился.
Ну, потому что, по большому счету, вы таймы можете в онлайне насчитывать.
Ну, вы можете таймы насчитывать в онлайне, там АП насчитываете в онлайне, правда?
Да, а дальше там какие-то просто форики по горжинкам.
Ну, по большому счету, хотя...
Ну, по большому счету, да, потому что, скажем так, вот эти вот штуки на самом деле
можно вообще делать без DFS, а просто ленивыми какими-нибудь операциями.
Ну, можно ленивыми, а можно просто предположить,
что раз уж вы все равно вершины перенумеровали в порядке входа DFS в них,
то можно просто от 0 до n-1 пробежаться и честную динамику насчитать так уж по барабану.
Но это все мелочи, конечно.
Это вас не очень интересует.
Нас интересует то, что... Заметим, что мы сделали.
У нас всего... У нас, получается, есть n запросов к вот этой структуре, да?
И DFS, который работает за линию.
Ну, может, там пара DFS-ов.
То есть, получается, что мы получили...
Ну, фактически, я так формально скажу.
От n плюс...
Давайте так.
n...
Давайте так.
n эвалов
плюс, конечно, n линков.
Ну ладно, там n-1.
Вот так.
Ну, там n-1, конечно.
Ну, линки есть.
Ну, опять понятно, линков, понятно, столько, тут без вариантов.
Но эвалов у нас тоже не сильно много,
потому что в каждом АПе может быть несколько эвалов,
но для каждой вершины иницирует не более чем один эвал.
Ну, на самом деле, ладно, ровно один,
потому что мы АП от В всегда определяем.
Может быть, даже это родители.
Вот, очень удобно.
Вот, кстати, в этом смысле...
Ну, в этом смысле, да, кажется, очень удобно,
когда корень мы сам не включаем.
Понимаете, да?
Вот.
Ну, впрочем, тут как хотите.
То есть, на самом деле, это мелкая деталь,
потому что вы же сами выбираете,
что вы делаете раньше.
Подвешиваете дерево к корню
или делаете эвал, правда?
Так что это несущественная деталь.
Так.
Вот.
Это мы, конечно, победили, правда,
в каком-то жестко странном предположении,
что у нас есть только прямые обратные ребра.
Что никаких перекрестных ребр нет.
Хотя упреждается, что это уже неплохо, на самом деле.
Нам же, по сути, надо придумать способ
чуть более умного АП считать.
Ну да.
Вариант, что это все еще самая высокая штука,
в которой мы можем...
Ну, в которой можно что-то там.
Осталось только выяснить, что.
Сейчас уточним.
Нет, потому что на самом деле...
Я не знаю, у меня тут кто-то шпаргалку просто писал.
Не знаю кто.
И он тут пишет,
что на самом деле есть такой подвид графов,
называется сводимые графы.
Не буду писать, просто скажу для общего развития.
И написано мне следующее,
что сводимые графы – это такие потоковые графы,
в которых ребра делятся на прямые ребра,
которые формируют какой-то ациклический граф,
по которому достижимо все.
И какие-то обратные ребра,
у которых конец доминируется началом.
Ну ладно, это не совсем то, конечно,
потому что если формируется просто ациклический граф,
то перекрестные ребра, конечно, есть.
Вот. Ну, впрочем...
Ну, впрочем, тут почти все равно то же самое.
Вот. Ну, тут говорят, что это хорошо.
Кстати, да, а вот отсылку я все-таки напишу, наверное.
Вот отсылку, откуда это?
Ну, то есть не сам алгоритм, конечно,
но вот есть такая замечательная книжка,
Ахо Уильямс, да.
Ахо – это вот, да.
Это человек, который нам еще встретится.
Догадываетесь, где, да.
Ну вот. Нет, на самом деле вы не угадаете.
Потому что, конечно, вы догадываетесь,
что он встретится, когда будет звучать алгоритм Ахо Карасик,
но вы не догадываетесь, что, скорее всего,
вы столкнетесь с книгой Ахо Хопкофта Ульмана про компиляторы
в рамках тех же формалок.
Вот. Ну, а здесь немножко другая книжечка.
Нахит.
О, да, это немножко другое, да, не та классическая книжечка,
которая там считается, но тоже вот она есть.
И там, как это ни странно, упоминается дерево доминаторов.
Нет, там они ничего не говорят о том,
как его там строить, там еще не говоря уже о каких-то там асимптотиках.
Нет, они там только скажут, что есть на самом деле
какой-то практический жадник основанный, который пихает,
ну, там, который работает за асимптотику,
что типа n²m поделить на 32.
И вот примерно, уже из асимптотики можно примерно сделать вывод,
как он работает на самом деле, да.
Ну, по сути, вы там храните какие-то битсеты просто того,
в каждой вершине храним битсет типа там,
там без кого в меня не войдем или что-то в этом роде.
Вот. Ну, там понятно, ну, там что-то типа...
Ну, да. Ну, по сути, да.
Ну, там что-то да. То есть изначально в вершине там записаны все вершины,
но в корень записаны только корень.
И там у вас суть алгоритма заключается в том,
что вы там эти масочки пытаетесь пропихнуть.
То есть вы там берете масочку вершины U
и там endите ее с масочкой V, где V, где УВ это ребро.
Ну, там потому что в вершине V можно, соответственно,
за счет масочки U обнулить какие-то.
То есть там суть в том, что если в масочке U кто-то нулевой,
это значит, что без этой вершины до вершины U добраться точно можно.
Поэтому это можно как бы прирелаксировать по какому-нибудь ребру.
То есть на практике такая штука на самом деле работает очень быстро?
Вот они говорят, что да.
На каких-то реально практических...
Для практических, ну, что-то алгоритм часто вот так хватает,
хоть, конечно, официально, если точку у него так себе.
Вот. Ну, вот они реально такое пихают.
Хотя, конечно, то есть да, то есть там...
Ну, то есть, например, вот для вот каких вот этих вот ациклических графов вот этих, да?
То есть для ациклических графов это может работать за NM поделить на 32.
Почему-то.
Ну, я не знаю там, как они избавляются от этих обратных ребер, я так не скажу.
Хотя, видимо, если избавляются, то, видимо...
А, ну, что там, да.
Ну, потому что, да, если...
Да, ну, да, они избавляются от, значит, получается, обратных ребер.
А если граф у вас ациклический, да,
то, в принципе, вы просто делаете упихивание в порядке топ-сорта
и вдоль каждого ребра за N на 32 упихиваете масочку, все.
Получается, NM на 32.
А это часто тоже уже неплохо.
Так, вы знаете, в Петрозаводске это нормально,
когда вам подсовывают задача N квадрат поделить на 32,
а M10 в пятый.
Ну, не то, что будет там совсем нормально,
но вот лично на моей практике такие прецеденты были.
Ну, я не знаю, TL, наверное, там был какой-нибудь там 10 секунд, конечно, но все.
Вот.
Ой.
Да.
Так вот.
Красота, значит, красота.
Значит, какая тут красота есть еще?
Какая красота есть еще?
Вот.
Значит, ну, это...
Ладно, это, конечно, мы пока рассмотрели действительно более такой...
Странно, такой вот алгоритм,
но этот алгоритм, конечно, работает только в том случае,
если у нас есть только прямые ребра.
Ну и обратные.
А что делать,
если есть перекрестные ребра?
Даже интересно.
Я, конечно, могу сразу начать полить правильный ответ.
Но даже интересно, какие мысли тут вообще возникают?
Вот как тут...
Вот, действительно, то, что возникает, ощущение такое, действительно, что...
Ну, действительно, понятно, что если запустить DFS,
то этот аидом находится где-то на этом пути,
на этой вершины можно как-то обойти.
Ну, типа если посмотреть...
Попробовать какую-нибудь такую же штуку сделать,
то есть у нас есть перекрестное ребро.
Там есть какой-то...
Какой-то тип...
Ну, правда, там подлянка, что да.
Обход может...
На этот раз, кстати, перекрестное ребро позволяет нам сказать,
что обратные ребра тоже существуют.
Потому что есть всякие веселые подлянки.
Давайте вот теперь рассмотрим.
То есть если мы можем обойти с помощью обратных...
То есть вот раньше мы сказали...
То есть пока у нас не было перекрестных ребр,
мы просто сказали, что если есть обратные ребра,
то давайте их просто уберем, потому что они нам все равно не помогут.
А теперь говорим так.
Ну, хотя...
Хотя слушайте, а действительно,
почему они нам не помогут?
Ведь может же быть такое, что мы как бы
скаканем по прямому ребру сильно ниже,
а потом из обратного ребра скаканем выше.
А почему же мы тогда сказали,
что обратные ребра можно выкинуть, и ничего не поменяется?
Ведь смотрите. Ой-ё-ё-й!
Ой-ё-ё-ё-й!
Да, наши телезрители там уже,�데 мы уже видим,
где-то час уже сидят там в панике за голову хватает.
Просто видят вот такую замечательную картиночку.
Сейчас я просто Ameritr going through 시청opathia today.
Какаяuiten Camera...
Я significantly неlets the talk...
Знаешь...
Я уже хорошо mutant, christmas adds Halloween,
Merry Christmas....
Я не верю.
Просто, видя вот такую замечательную картиночку, потому что предположим, что у нас есть вот такое ребро.
Но оно говорит, что все равно не мешает нам сказать, что у этой вершины доминатор, наверное, допустим, вот эта вершина, а у этой вершины доминатор вот эта вершина.
А мы берем и говорим, ой, а у нас еще вот такое ребро есть. Упс! И тут выясняется, что эту вершину прекрасно можно обойти.
Обидно, да?
Да, а тут выясняется, поторопились мы избавляться от обратных ребр. Ой, поторопились.
Это вообще не понятно, как наше решение адаптировать под это?
Ну, адаптировать можно, но пока главное просто отметить, что это решение работает только в том случае, если здесь только прямые ребра.
У нас обвалилось утверждение, что при отсутствии перекрестных можно вытянуть и обратное, но если предположить, что нет ни перекрестных, ни обратных, то это решение прекрасно работает.
Ну, а теперь давайте думать. Смотрите, мысль тут такая, если мы хотим обойти, значит, жила была вершина В, да?
Значит, как мы кого-то хотим обходить? Ну, наверное, когда мы хотим какую-то вершину обойти, что значит обойти? Мы хотим стартовать где-то выше, сделать какой-то обход и стартовать и финишировать где-то ниже, правда?
Ну, где-то условно на этом пути, да? А теперь возникает вопрос, а какие у нас по таймыну вершины могут здесь быть?
Как вы думаете?
Ну, это только, видимо, большее.
Большее, чем кто?
Чем, видимо, В, ну, нижнее.
Ну, не совсем. Ну, давайте так. Допустим, пусть это В штрих и есть В два штриха, да?
Ну, что же это за такой мистический обходной путь?
Ну, на самом деле, да. Кажется, что здесь очень хочется, ну, как бы, да, это может быть просто прямое ребро, а могут быть какие-то вершины.
Почему-то кажется, что они могут быть все эти вершины, то есть где тут таймын от вот этих вот всех вершин.
Давайте пусть их назовем у1, у2, у3 и так далее, у к, допустим.
И тогда а именно какое-нибудь уитово почему-то всегда оказывается больше, чем таймын от W два штриха.
Ну, казалось бы.
Ну, вот, хочется нам чего-то такого.
Хотя казалось бы. А почему вообще?
Ну, действительно, так, может ли быть такое, что все эти вершины по таймину больше, чем W два штриха?
Ну, конечно, такое может быть. Ну, давайте, как всегда, будем предполагать, что когда мы рисуем дерево, мы предполагаем, что все дети обходились слева направо, да?
Тогда действительно заметим, что у нас могла быть какая-нибудь вот такая ситуация, что тут у нас какое-нибудь дерево, допустим, вот такое.
И мы его обходили, допустим, через какие-нибудь...
То есть мы его обходили как-нибудь через какие-нибудь перекрестные рога.
Или могли еще обходить через потомков.
Я думаю, что через какие-нибудь вот этих потомков, но потомки W два штриха тоже по таймыну больше, правда?
Такое вполне могло быть. То есть могло быть через соседние веточки, а может быть мы их обходили через вниз.
Могло такое быть? Могло, конечно.
А могло такое быть, что на этом пути действительно у нас таймын оказался меньше, чем W два штриха?
Вдруг этот путь скакал на самом деле как-нибудь вот так вот?
Нет, теоретически такое может быть, кто нам мешает.
Правда есть маленькое ограничение.
Мы помним, что... то есть смотрите, хорошо, мы могли оказаться в веточке левее, чем вот этот путь, да?
Но, а как мы могли скакнуть из веточки правее веточку левее?
Могли скакнуть по перекрестному ребру или выскочить из-под дерева, по какому-нибудь обратному, да?
Хотя нет, по обратному не могли, конечно, потому что по обратному мы сюда куда-то придем.
А с левее мы явно не обошлось без перекрестного ребра.
А с левее вообще проблема, если мы туда попали, как мы попадем оттуда обратно в W два штриха?
Ну, честно, теоретически есть вариант.
Вот те самые обратные ребра приведут нас куда-нибудь.
Потому что, может, смотрите, могло быть так.
А, да, в другое, по обратному и потом...
Да, то есть вы пришли куда-нибудь вот сюда, потом скаканули сюда и пришли в W два штриха. Такое могло быть.
Но важная лемма, принципиально других способов особо нет.
Смотрите, сейчас я вот сформулирую маленькое интересное утверждение на эту тему.
Так, ладно, давайте я это так сделаю.
Вот, кстати, что приятное, я могу потом вернуться к этой странице и сравнить шпаргалку.
Значит, утверждение звучит так.
Сейчас я сформулирую просто общее утверждение, можно сказать, из теории DFS.
Итак, пусть у нас оказалось, что таймин от V меньше, чем таймин от W.
Тогда утверждаю я, любой путь от V до W содержит какого-то, я прямо здесь подчеркну, какого-то общего предка V и W.
Сейчас.
Так, к сожалению, нам сейчас надо будет прерваться.
Но давайте, ладно, закончим на том, что докажем эту лему.
То есть, вот важно, видите, если таймин от V меньше, чем таймин от W, тогда любой путь от V до W будет содержать какого-то общего предка V и W.
Так, ну, очевидно, понятно, ладно, если W потомок V, то, в общем-то, утверждение самоочевидно.
Вот, понимаете?
Вот.
Сейчас, а так можно попробовать, типа, смотреть, какие у нас вообще ребра в целом в графе есть.
Вот мы пошли из V, сколько то времени мы жили в его под дереве.
Так, правильно.
Дальше будем смотреть, посмотрим на LCA V и W.
Так, ну давайте, вот у нас есть, ну, точнее так, вот есть R, есть путь до LCA, вот оно LCA от V, от V и W, есть W.
Вот, ну, в какой-то момент мы должны в любом случае выйти из вот того под дерева, под дерева, где лежит V.
Так, должны, как же мы это сделаем?
Вот, ну, у нас есть варианты, если мы оттуда вышли по какому-то обратному ребру, то мы уже оказались, получается, вот на этом.
Не факт.
Мы же могли оказаться вот где-то.
Не, не, я говорю, типа, все под дерево, короче, не под дерево в вершинке V, а то из под деревьев LCA, которое содержит V.
Нет, ну, как повезет, обратный ребро можешь привести и сюда, можешь привести и сюда, как повезет.
Ну, короче, мы же в любом случае начинаем свое существование, короче, вот рассмотреть именно самое большое, короче, под дерево не вершинки V, а вообще большое под дерево.
Вообще большое под дерево?
Типа, вот у LCA есть какие-то дети, да?
Есть.
И вот под дерево того ребенка, ну, возьмем под дерево одного из детей, в котором лежит вершинка V.
Ну, вот он.
Мы из этого под дерева большого должны быть.
Так, о, да, давайте так сделаем, да.
Вот.
Давайте, давайте, да, аккуратненько ходим, тут как-то вот ходим, ходим, ходим, и рано или поздно мы должны выйти.
Вот, куда мы из этого под дерева можем выйти?
Так, да, если, да, если выйдем по обратному ребру, то это автоматическая победа, потому что это является автоматически общий предок и там LCA.
Вот.
А что делать, если мы вышли по перекрестному?
А если в перекрестному, то это, сейчас, то это значит, что мы вышли, на самом деле, в вершинку с тыином меньше, чем LCA.
Правда ли это?
Конечно, неправда, конечно, неправда, но с тыином меньше, чем корень вот этого под дерева.
Так.
Значит, у нас есть новый LCA.
Так, нет, сейчас, ну, погодите, погодите, погодите.
Ну, тут возникает вопрос, да, что давайте, то есть утверждение такое.
Вот, есть такая, ну, вот, то есть на самом деле хочется утверждать, делать простое утверждение, что, как бы, какой-нибудь LCA от UEW находится не ниже, чем LCA от UEW.
Да, ну, потому что давайте посмотрим, куда вообще это обратное ребро могло вести.
Оно могло вести в другое под дерево, в более, как бы, в ранее рассмотренное под дерево LCA-шки UEW?
Ну, как бы, ну, вот.
Да, конечно, могло.
Вот, тогда у нас LCA остался на месте.
Вот, и теперь, а куда оно могло вести, если не в какое-то под дерево LCA UEW?
Ну, да, ну, можно так сказать, да.
Тогда это просто одно из под деревьев.
Да, ну, можно, да, можно просто сказать, что да.
То есть, да, рассмотрим просто все под деревья, которые были обойдены, например.
До вот этого под дерева.
Так, до вот этой LCA-шки.
То есть, заметим, что эти все под деревья до этой LCA-шки, это и представляют все вершины, которые были обойдены до этого под дерева, правда?
Вот.
Но тогда получается, то есть, у них у всех ответвление от этого пути произошло не ранее, чем, то есть, не позже, не позже, чем от LCA-2W.
Вот, да, соответственно.
Ну, да, ну, я не знаю, то есть, ладно.
Ну, вообще, это какая-то там типа, а, ну, просто мы и...
Ну, да.
Ну, философский вопрос.
Честно скажу, сейчас меня слетом возить все еще как-то немножко мутно.
Особенно, а теперь представьте, что вы пишете статью, а DFS не является таким алгоритмом, который знают прям вот все, и там это.
Там все есть пятый год, а CPC еще не изобрели.
Да, первый чемпионат CPC седьмом произошел.
Кажется, континентзукция по...
Ну, на самом деле, нет, на самом деле, да, более...
То есть, надежное формальное доказательство, конечно, звучит бы так.
То есть, интуитивно, конечно, вот хорошо понимать так.
Вот.
Формальное доказательство можно провести, а давайте прификсированной W проведем доказательство по индукции по...
То есть, для всех вершин в порядке возрастания таймы на АТВ.
Хотя для этого вам все равно придется доказать...
Ну, правда, чтобы...
Ну, вот.
Ну, для этого вам все равно придется показать, что...
Нет, для этого вам все равно придется показать, что, значит, этот...
Что LCA от UW не ниже, чем LCA от VW.
Ну, да.
Вот.
То есть, там...
Но это, в целом, кажется, тоже несложно делается.
Вот.
Потому что...
Ну...
Вот.
Ну, хотя, действительно, заметно...
Да, чтобы LCA был...
А, хотя, погодите.
Утверждение, что пусть LCA от UW окажется ниже вот на этой части пути.
Да.
Тогда мы заметим, что...
Ну, вот.
Что TIN окажется больше, чем у лишинки V.
Ну, по факту, да.
Все.
У нас LCA не может.
А, ну ладно.
Так или иначе выкрутились.
Отлично.
Вот.
Так что, да.
Отсюда, в принципе, интуитивно уже можно выговорить, что
в той ситуации обходы интересуют только те среди вот именно
больших.
Потому что, если они попали среди меньших, значит, они
попадут через предка, и значит, обход можно сократить.
Ну, да.
Вот.
Ладно.
Ну, на эту тему нам придется подумать чуть позже, потому
что, значит, сейчас у меня небольшой перерыв.
Мне надо прибежаться.
Так.
А, вторых.
Так.
Ну, к вам называется вопрос, как вы хотите ли вы пообедать.
Это вообще вопрос.
Ну, с помощью того утверждения, которое у нас возникло.
Значит, теперь действительно заметим, что если мы хотим
какую-нибудь заданную вершину X обойти, то мы замечаем,
что нас, на самом деле, начинает интересовать даже не столько,
может быть, обход вершины X.
То есть обход не просто обход, а, на самом деле, в некотором
смысле обход по вершинам именно с большим.
Действительно таймэйном.
Значит, ну, напомню еще раз.
Мы тут выяснили, что, оказывается, если мы идем из вершины
с меньшим таймэйном с большим таймэйном, то любой путь
от одной вершины друг к другу у нас с какого-то общего
предка их содержит.
Да.
Это необязательная лца.
То есть подчеркиваем, что, в общем-то, этот путь от
W до W не обязан лежать через лца.
Ну, как минимум, потому что можно тут через какие-нибудь
прямые вытянутые более высокого предка, а потом
через прямые ребра пойти либо просто в обход, либо
пойти через соседние под деревья, и там уже через
какие-нибудь перекрестные ребра разобраться.
Понимаете, да?
Вот.
Такие.
Ну вот.
Ну, к чему нас это приводит?
Вот давайте теперь посмотрим.
Так, вот давайте я...
Так, давайте я лучше новую картинку нарисую.
Значит, что у нас тут тогда получается?
Получается примерно следующее.
Следующее, следующее, следующее, следующее.
Вот.
Вот.
Вот, допустим, у нас ситуация какая-то возникла.
Вот.
И мы очень хотим найти айдома от вершины W, да?
Тогда первая идея, которая у нас возникает.
Так.
Первое, думаем, вот этот вот родитель, он вообще
не является ли он айдомом?
Или, для начала, не является ли он просто доминатором?
Вот вдруг является.
Ну, потому что если он является доминатором, то он айдомом
и является.
А что делать, если он не является?
Тогда это означает, что его можно как-то обойти.
То есть это означает, что существует какой-то там
супермистический путь.
Ладно, нет, фиолетовый плохой цвет.
Какого-то вот такого рандомного вида.
Который тут ходит, ходит, ходит, может там вот так
как-то ходит, вот так, вот так, вот так, вот так, вот так.
Но самое главное вот в эту вершину не заходит.
Так, но с другой стороны заметим.
Ну вот, но с другой стороны заметим вот что.
Так.
А давайте-ка от этого пути, то есть путь может быть
какой угодно, но давайте-ка мы, значит, так, небольшой,
небольшую дошку тут нарисуем.
А теперь давайте подумаем.
А давайте-ка будем идти по этому пути, но не от r
до v, а от вершины v до вершины r.
Вот давайте начнем с первой ребра.
Так, может ли оно быть перекрестным?
Действительно.
Вполне может быть тут пример легко нарисовать.
Какое-нибудь там ребро сюда или, пожалуйста.
Так, а может ли это ребро быть обратно?
Да.
Ну а что бы, собственно, нет.
Вдруг мы действительно тут скаканули по прямому ребру
в под дерево, из этого под дерево по обратному ребру
сюда пришли.
Могло быть такое же?
Вполне.
Так, хорошо.
Что это еще может быть?
А еще это может быть, может ли это быть прямое ребро?
Так, может.
Хорошо.
Да, может ли это, в общем, единственное, чем это не
может быть, это ребром дерева ДФС.
Логично, да?
Так, ну смотрите, как интересно.
Тогда у нас получается ситуация такая.
То есть мы, получается, сюда пришли.
Мы либо обошли вот таким вот образом, то есть просто
по прямому ребру какому-то, либо мы пришли из какой-то
вершины по таймыну заведомо больше, чем вот эта вершина.
Правда?
Есть такое ощущение, да?
Вот.
Но тогда идея такая.
Если мы пришли, допустим, я возьму такую, из вершины,
которая заведомо больше, а давайте вот некоторое время
идти назад по этому пути до тех пор, пока вот по всем
таким вершинам, допустим, там, у', таким, что таймыно
у', строго больше, чем таймыно у'.
Вот будем так идти.
Вот идем по этому пути.
Идем, идем, идем, идем, идем, идем, идем, идем.
Но смотрите, путь-то у нас заканчивается в вершине R.
То есть получается, рано или поздно возникнет вершина
R', то есть можно сказать, последняя вершина, то есть
последняя вершина на пути от V до R такая, что таймын
от V больше, чем таймыно от V'.
То есть понятно, что в принципе мы начинаем с R, то есть
у R таймыно заведомо меньше, но уж когда-нибудь такие
вершины кончатся.
То есть будет такая последняя вершина V', потом какой-то
обход по вершинам больше, и мы входим в вершину V'.
Вот.
Так.
Ну что можно сказать о вершине V'?
Как вы думаете, есть у нее простое, но важное следствие
вот из этой леммы.
Ну-ка, внимательно посмотрите на лему и скажите, что это
за следствие.
Да, именно.
То есть мистическое утверждение V' предок V.
Ну можно даже было написать еще собственное, конечно.
Почему так?
Ну потому что раз у таймыно от V' меньше, чем таймыно
от V, значит на пути от V' до V есть общий предок.
V' и V.
Но общий предок V' и V он по таймыно заведомо меньше
V, правда?
А у нас только одна вершина на этом пути меньше.
Сама V'.
То есть вывод такой.
Если мы эту вершину, смотрите внимательно, если мы эту
вершину можем обойти, то существует какая-то вот
вершина.
Вот даже вот мы неправильно нарисовали.
Что он рисует вообще?
То есть существует такая вот вершина V', что из V' V
существует обход такой, что в промежуточной вершине
значит все строго больше.
Кстати, заведем, что таким обходом может быть частный
случай такого обхода.
Это, собственно, прямое ребро.
Понимаете, да?
То есть у прямого ребра тоже все промежуточные вершины
по таймыну больше, чем V, потому что их нет.
Как хорошо, когда у нас что-то пустое множество, то
можно на него вешать там просто все грехи мира.
Или наоборот все мечты мира.
Слушайте, а давайте думать, хорошо, вот мы находим такую
вершину V', более того, давайте найдем минимальную такую
вершину V', то есть тот самый высокий такой предок, из
которого в вершину V' существует обход.
Тогда мы, что мы можем сделать?
Мы тогда можем гарантировать, что вот эти все вершины
айдамами не являются, правда?
Пока логично, да?
Вот.
Нет, что-то мы не будем по статье сегодня идти, по
ходу.
Но это и хорошо.
Вот.
Но теперь мне сказать вопрос.
А сама V' является полудомина...
Тьфу, является ли она?
Доминирует ли она на 2?
Ответ.
Как повезет?
Теперь у нас возникает задача, можно ли обойти эту
вершину так, что вот где-нибудь идя сверху, прийти вот в
какую-нибудь из этих вершин теперь?
Да, но это же буквально та самая...
Так.
Вот.
Минап.
Ну, не совсем минап.
Потому что...
Нет, ну тут не совсем.
Тут, видите, доказывать надо теперь аккуратнее,
потому что мы теперь не с прямыми ребрами, не только
с прямыми ребрами работаем.
Хотя логика абсолютно та же.
То есть, предположим, что этот V' можно как-то обойти.
Да?
То есть, откуда-то...
Значит, получается...
Ну, то есть, что мы видим?
То есть, у нас...
Итак, значит, что мы знаем?
У нас существует какой-то путь из RV-V'.
Да?
Ну, давайте рассуждать будем так.
Вот сейчас я...
Тут, видите, тут важна техника.
Потому что, как вы знаете, будет, может быть, идея...
Идейно, может быть, всё понятно, но на экзамене потом можно там...
В случае чего там просто всех выжить.
Если просто это делать неаккуратно.
Поэтому давайте вот аккуратно формулировать мысли.
Поэтому говорим так.
Давайте вот на этом пути найдём первую попавшуюся вершину.
Вот вообще первую попавшуюся вершину.
Значит, на этом пути, которая лежит вот на этой части.
То есть, она ниже V', но предок V.
Да?
Просто первую попавшуюся.
Ну, тогда заметим, что я могу без ограничений обществе считать,
что у меня путь просто пришёл сюда, а дальше просто сюда спустился
и уже не заморачиваемся.
Да?
Итак, смотрим отсюда.
Как у нас выглядел путь?
Значит, как у нас выглядел путь отсюда?
А тоже, смотрите, он, как мы уже поняли, некоторое время...
Значит, некоторое время...
Он тут шёл-шёл-шёл-шёл и попал в какого-то предка этой вершины.
Хотя он шёл до этого по вершинам больше, чем вот это.
Правда?
Понимаете, да?
Шёл-шёл-шёл и пришёл в предка.
Вот.
Ну, отлично.
Если он пришёл в предка, которая всё ещё ниже вершины V',
то не заморачиваемся, просто обрезаем не по этой вершине, а в этой.
Ну, теперь мы стали просто чуть выше.
Можно было сразу сказать, что давайте рассмотрим, какие вершины на пути,
и выберем самую высокую даже.
Логично, да?
И говорим, что...
Ну, там, правда, начнутся всякие оговорки,
что, может быть, мы в эту вершину пришли через вот эту,
но давайте за циклы мы будем выпускать.
Там, конечно, придётся аккуратную индукцию сделать,
но значит, мы говорим, что индукция у нас будет...
У нас всё время будет либо увеличиваться эта вершина,
либо уменьшаться к величеству ребер.
Если эту часть убираем, то вообще нормально будет.
Так вот, значит, что произойдёт?
То рано или поздно, если мы возьмём...
А, впрочем, даже и неважно.
Потому что, наконец, возьмём самую высокую.
Ну ладно, с оговоркой, что на самом деле тут ещё какие-то вершинки есть,
то предположим, что наш путь их не посещает.
Вот.
И тогда что же произойдёт?
Тогда получается, что обход из этой вершины,
то есть если идти, идёт конец, конец, конец, конец, конец,
больше, больше, больше, больше, и мы пришли в предка.
Но вершину в штрих мы обошли, правда?
Значит, мы, получается, пришли в какую-то ещё вершину,
теперь уже получается...
Вот если эту назвать, допустим, там w штрих,
то эту мы назовём w там 2 штриха какой-нибудь.
Ну ладно, v2 штриха какой-нибудь давайте вот так назовём.
Получается, что существует обход.
И тем самым мы гарантируем, что...
Ну вот.
То есть опять получается, что мы для вершины попытались рассмотреть,
то есть найти самого высокого предка,
из которого можно в эту вершину попасть,
используя в качестве привжуточных только вершины большие, чем она.
Но тогда опять же отсюда следует такое,
что если не для одной из этих вершин такого обхода,
то есть такой вершиной не является вершиной выше, чем w штрих,
то тогда мы вынуждены заключить, чтобы w штрих, доминатор v и не паримся.
Понятно, да?
Вот.
А если такая нашлась, ну что делать?
Находим самую высокую, естественно, да?
Ну тогда если мы находим такую самую высокую,
там может отсюда, откуда-то, неважно,
ну заметим, что ниже теперь уже...
То есть теперь мы должны обойти её.
Ну вот обойти и прийти в эти вершины мы уже не можем, очевидно.
Вот.
Но теперь уже из этих надо найти самый оптимальный обход и так далее.
То есть видите, рассуждение тоже, что у нас было раньше.
Вот.
И остаётся только...
То есть не говорит, что вот это вот самый минимальный предок,
который...
То есть мы уже слишком много заклинаний это произносим,
и мы уже убедились в том, что пришло время ввести определение.
Ну вот.
Ну, собственно, как это называется?
Это называется полудоминатор.
Значит, давайте синеньким напишу.
Так.
Значит, пишем...
Слушай, что у меня с маркером?
Вот.
Значит, определение...
Значит, пусть v не равно r.
Так.
Тогда...
Говорим мы полудоминатор...
Полудоминатор v или, как его ещё обозначают, s-дом от v.
Это...
Значит, пишем так.
Арг-мин.
Значит, тай-мин.
От у.
Где?
Значит, у предок v.
И существует...
Что существует?
Существует путь от у до v.
Такой, что...
Ну вот.
Что для любой промежуточной...
Вершины...
Значит, там x на нём.
Верно, что тай-мин от x строго больше, чем тай-мин от v.
О.
Так.
Кстати, но Тарьян, кстати, неожиданно сразу говорит...
На самом деле, из этого определения выкидывает требование, что у это предок v.
Но давайте сразу уговорим маленький момент.
Я утверждаю, что на самом деле то, что у это предок v, следует из всего остального.
Почему?
Ну, потому что начнём с того, что...
Так, ну, во-первых, начнём с того, вот это вот множество.
Вот давайте, если вот даже выкинуть предка.
А может ли это множество быть пустым?
Почему?
А предок нам чем не был доминал?
Какой предок?
Какой из предков?
Ой, в смысле родителей?
Во, да.
Да, употребляйте слова точно.
Да, совершенно верно.
Родитель нам подходит.
Это важно.
Но мало того, что раз родители нам подходят, значит, мы гарантируем, что тай-мин от этого s дома...
Ну, во-первых, он корректно определён, а во-вторых, он меньше, чем тай-мин от v.
Но, с другой стороны, заметим, что если мы рассмотрим любую вершину по тай-мину меньше...
То есть по тай-мину меньше, чем v, и от которой существует до v вот такой путь,
тогда по нашей вот лебе вы вынуждены заключить...
Ну, вот аналогично этому утверждению, что эта вершина автоматически предок.
То есть не родитель уже, но предок.
Понятно, да?
Вот.
И тогда...
Ну вот, то есть вот такой вот s дом.
Но теперь останется только...
Так, то есть теперь два момента остается.
Ну, в принципе, как найти s дома и зачем они нам вообще понадобились.
Ну, начнём с простого.
Мы, в общем-то, зачем они нам понадобились, уже диктуется тема, откуда мы вообще взяли определение этого понятия.
Вот откуда мы взяли это понятие.
Это очень про...
Ну вот, действительно, вот если нам эти s дома действительно прислались не без по факсу,
то высекает первое утверждение.
Ну, точнее даже не утверждение.
А давайте опять по аналогии.
Пока вот не утверждение.
А давайте сделаем пока определение.
Ну, потому что нам для s дома нужно вот эти вот минапы найти, да?
Понимаете, да?
То есть давайте так, определение.
Пишем аккуратненько.
Пусть v не равно r.
Вот.
Тогда...
Вот.
Тогда что можно сделать?
Ну, тогда давайте сделаем просто, что...
Ну, давайте просто не будем заморачиваться.
Минап от v.
Это просто будет argmin.
Значит, tajmin.
От s дом.
От...
От u.
Такое, что...
Значит...
Ну да, как мы уже писали.
Значит...
То есть это...
Вот так.
В штрих.
У.
В.
Точнее, вот тут плюсик.
Тут точечка.
То есть рассмотрим.
Так, вот так.
s дом.
От v.
Вот так.
Отклады не так.
Вот.
Ну, суть вот как раз буквально та же.
Понимаете, да?
Вот, мне жутко...
Вот.
Но меня жутко интересует сама эта вершина.
И выясняет сразу, как это работает.
Вот.
Вот.
И выясняет сразу простое утверждение.
Которое вот нам, нами уже выведено.
По сути.
Потому что, действительно, если оказывается...
Что мы берем...
Давайте я вот тут справа налево легче писать.
Если мы берем этот минап.
Берем от него s дом.
И у этого s дома tajmin
оказывается больше либо равен tajmin от s дом от v.
То, что получается.
То тогда я утверждаю, что
a дом от v тупо s дом от v.
Какое тут доказательство?
Вот доказательство мы только что провернули фактически.
Потому что понятно, что ниже s дома не будет, потому что есть обход.
А сам s дом обойти нельзя,
потому что если его можно обойти,
то просто мы аккуратно выводим, что у какой-то из этих вершин s дом явно выше.
Понимаете, да?
Да, здесь пока очевидно.
Но давайте возьмем напарника.
Если же tajmin от s дома.
В общем...
Ой, интересно, а тут нет вот этой опции выделить и скопипастить.
Select?
А ну-ка давайте попробуем даже.
Так.
А как сделать select?
Вот.
Не все так просто.
Ну ладно, не суть ваша.
Значит, если tajmin от этого оказался строго меньше,
чем tajmin от s дом от v,
то оказывается, что
a дом от v тупо равен айдому от этого минапа.
Ну, это более-менее тоже понятно, потому что...
Так.
Ну, вот то рассуждение, которое мы провернули,
ну, когда доказывали, что...
Первое утверждение.
Так.
Вот.
Дальше пусть мы нашли...
Да.
Вершинку, которую, ну, через которую мы можем обойти.
Так.
А вот на этом отрезке нам точно так же искать
более верхнюю вершинку, которая типа v...
Ну что начнем?
Ну да.
То есть можно в принципе сказать...
Да, можно по большому счету сказать, что вот мы нашли, допустим,
этот вот минап, то есть пусть вот это вот,
допустим, x равно
минап от v, допустим,
и из нее есть вот какой-то вот этот вот веселый обход.
Вот.
Как видите, вот жуткий аж вон куда-то вот сюда идет.
Так.
Что мы тогда можем сказать?
Так.
Ну, теперь заметим, что получается все вершины до этой включительно обойти можно.
Вот.
Ну, теперь мы искали вопрос, можно ли обойти эту вершину?
Ну, заметим, что обойти ее с точки зрения вот этого пути
это абсолютно то же самое, что обойти ее с точки зрения этого пути.
То есть получается она...
То есть это означает, что по сути...
То есть это будет означать, что как бы...
Ну, вот как бы это строго формулировать.
Ну да.
То есть получается надо теперь отсюда брать соответственно
теперь там минимальный какой-то s и так далее.
Но это получается, что просто если бы мы искали доминатор там айдом от нее,
то мы бы искали ровно тем же способом.
Можно так сказать.
Можно там как-то сделать тарьян, привести там какие-то более аккуратные доказательства.
Может быть какие-то.
Там, действительно.
Вот.
То есть обойти действительно тут...
Да.
Но нам они особо не нужны.
Вот.
То есть в принципе вот заметим, кстати,
вот тут действительно давайте верну старую страницу.
То есть в общем-то заметим, что
там не сильно у нас в общем-то викшдеги поменялись.
Вот просто можно сравнить.
Ну, по сути мы просто вот того...
Да.
Да, по сути да.
Мы просто вместо аппы сделали чуть более интересное.
Ну да.
Мы просто вместо аппы от минаппы сделали соответственно sdom.
Да.
Ну, кстати да.
Но заметим, что там sdom включает в себя апп.
Ну да.
Да.
Точнее варианты.
Потому что...
То есть все прямые ребра при вычислении sdom'а, конечно,
мы все прямые ребра ведущие вершину V все еще должны учесть.
Но маленькая проблема.
То есть мы еще, конечно, должны учесть еще кое-что.
То есть еще кое-что.
Так.
Ну, возникает действительно маленький интересный вопрос.
Что же мы еще...
Ну, теперь в принципе...
Ну, тогда что нам эти утверждения говорят?
Эти утверждения говорят, что если нам вот эти sdom'ы прислали с небес по факсу,
то дальше там простым DFS или, может быть, там двумя,
мы прекрасно по этим sdom'ам ID мы восстановим.
Правда?
Ну, кажется, там опять какая-то вот эта техника с минимумом...
Да, да, да.
Ну, нет, техника идентична абсолютно.
Потому что, по большому счету, мы по этому утверждению вот просто аппы заменили на sdom.
Ну, правда, разница только в том, что аппы вычислялись на халяву,
а вот sdom'ы придется откуда-то выкапывать.
Понимаете, да?
Так.
То есть нам сейчас осталось научиться sdom'ы считать?
Ну, по сути, да.
Так.
Ну, вот теперь давайте думать.
Как же нам теперь считать эти несчастные sdom'ы?
Так.
Sdom'ы будем считать следующему.
Ну, давайте думать.
Да, это уже, возможно, немножко новая для нас задача.
Так.
Значит, как же мы это будем делать?
Ну, во-первых, нам в sdom'ах надо учесть, типа...
Просто втупуя все ребра, приходя...
Ну, все прямые ребра.
Все прямые.
Нам в любом случае в какой-то момент надо будет перебрать?
Так, ну прямые...
Да, прямые, это, конечно, без вариантов.
Но что еще нам нужно учесть?
Да, прямые ребра, конечно, мы учтем.
А если просто перебрать, типа...
Вот пусть у нас есть какой-то путь.
Так.
Да, вот пусть у нас в b пришло какое-то ребро.
Так.
Из кого-нибудь там, конечно, где...
Где, наверное, w.
Ну, пришло.
Вот.
А какие у нас варианты есть?
Если у нас w это предок v, то понятно.
Это просто прямое ребро.
Да.
Хорошо.
А если это не предок?
Если это не предок, то посмотрим, что там с тайменами.
Так.
Если это таймен меньше и не предок, то это вообще не интересно.
Такого не бывает.
Не бывает.
Да, такого просто не бывает.
Да, просто не бывает, чтобы w меньше и не предок.
Да, да, да.
Да.
Может быть, подгляд, кстати, что это обратное ребро.
Что это ребро из-под дерева.
Да.
Да.
Вот.
Но если таймену этой штуки больше, то мы можем сказать,
что окей, это конец какого-то обходного пути.
Посмотрим, типа, какого.
Обходного пути.
Так.
Ну, это да.
Ну, то есть понятно, что рассуждение любое начинается
с того, что рассмотрим какой-нибудь нот.
То есть рассмотрим какой-нибудь вот действительно подходящий
путь.
Рассмотрим какой-нибудь путь.
Пусть он заканчивается каким-то ребром.
Ну, понятно, если это прямое ребро, то неинтересно.
Рассмотрим какой-нибудь путь хоть с какой-то прямежуточной
вершины.
Итак, вот у нас есть вершина w, которой таймен больше, чем
таймен от v.
Так.
Ну, заметим, что она с точки зрения дерева DFS что-то из
себя представляет.
Ну, допустим, вот как-то так.
У нее даже есть какая-то, не знаю, насколько нам пригодится
LCH.
Но как же этот путь устроен?
Так.
Ну, а первое, давайте можем рассмотреть, что действительно.
Давайте аккуратно, видимо, так.
То есть как-то путь это там шаманит, шаманит, шаманит.
А давайте на этом пути рассмотрим первую вершину.
Вот первую вершину, которая лежит вот на этом пути.
Вот, понятно, да?
Значит, первая вершина на этом пути.
То есть вот так, w'.
Первая вершина из вот этого вот на пути от r до dv.
Вот так.
То есть получается у нас тут, ну, то есть в принципе мы
без ограничений общества можем считать, ну, давайте,
даже если тут вот еще какие-то пути, что-то там еще есть,
можем без ограничений общества считать, что этот путь,
например, то есть он там пришел тем же образом в w,
а потом опустился сюда, прошел по этому ряду.
Ну, с точки зрения определения полудоминатора можно
рассматривать только такие.
То есть можно считать, что вот.
То есть если он заканчивается на w, попал в какого-то предка w,
но не предка v, то значит начиная с этого момента мы просто
пришли вниз и пришли.
Вот.
Хорошо, говорим мы.
Так.
А как же мы в эту вершину w вообще могли попасть?
Из r.
Так.
Ну, смотрите.
Ну, смотрите, что происходит.
А теперь давайте этот путь от r до w.
Вот у нас есть какой-то путь от r до w.
Так давайте по нему идти.
Значит, по нему давайте идти назад.
То есть давайте искать там какую-нибудь вершину w'
Последняя вершина на пути от r до…
До чего?
До w' такая, что, как вы уже догадываетесь,
time in от w' строго меньше, чем даже time in от v'.
Даже ослабим.
Я обязательно в, а именно вот w'.
Понимаете, да?
Что можно сказать про w'?
Я утверждаю, что w' значит предок w'.
Ну, мы этим уже пользовались, да?
Ну, в принципе это вообще…
Ну, по большому счёту заметим, что…
Ну, можно даже один а сказать.
W' – кандидат в эсдом от w'.
Понимаете, да?
Вот.
А ещё есть утверждение №2.
А ещё мы заметим, что w'…
Так, давайте этот пластик возьму.
И напишу нормально 2.
w' предок v'.
Помните почему, да?
Потому что мы видим, что у нас все предки w,
они либо так же и предки v, либо лежат на этом пути.
Но мы рассматриваем путь от r до этой вершины,
где мы от других предков w,
где мы от вершин вот этого пути просто избавились.
Ну, по построению, по сути, да?
Вот.
Значит, w' – это предок v'.
Но тогда отсюда следует утверждение, в свою очередь, №2a.
w' – кандидат в полудоминаторе.
Ну, не в смысле u, а вот в смысле…
Короче, в s дам.
Вот что для… ну, вот, атовая.
Так.
Так.
Так.
То есть, смотрите, вот как действительно интересно.
То есть, как у нас путь устроен.
То есть, путь у нас оказывается…
То есть, путь…
Ну, на самом деле, если мы рассматриваем какой-то…
вот такой вот путь из вершины v, да?
То получается, что у нее есть вот такая вершина,
№2' – общий предок.
После…
Хотя, стоп.
А кто сказал, что мы рассматриваем путь от r до v?
Ну, давайте вспомним.
А зачем мы этот путь вообще рассматривали?
Мы рассмотрели какой-то обходной путь.
Да.
То есть, смотрите, что мы делали.
Да.
Мы рассматривали, да, напомним, какой-то обходной путь.
Какой-то путь от r до v…
Ну, не от r до v, а от какого-то предка.
То есть, давайте еще раз я нарисую.
То есть, мы рассматривали…
То есть, по факту мы делали так.
Давайте еще раз.
Мы рассматривали какой-то путь от какой-то вот…
То есть, что нужно, чтобы…
То есть, от вот этого потенциального полудоминатора.
Какого-то кандидата в полудоминаторе.
То есть, от какой-то вершины x.
И у нее был вот какой-то тут вот такой вот красивый зелененький обходной путь.
Ну ладно, не факт, что зелененький.
То есть, мы говорили просто, что у него хотя бы одна промежуточная вершина.
На этом пути да есть.
Вот.
Ну, что у нас получилось?
Мы рассмотрели вот эту вершину w.
Там сказали, что…
Значит, как у нас этот путь устроен.
Так.
Давайте внимательно подумаем.
То есть, мы тут можем идти, идти, идти, идти.
И обнаружить, что у нас есть полудоминатор.
И в какой-то момент этот путь вольется вот в этот.
Может такое быть, да?
Вот.
Ну а на самом деле заметим, что можно заметить.
Так.
Как вы думаете, действительно?
Вот.
Спрашивается.
Может ли этот путь оказаться выше, чем вот это?
Ух ты.
Ух ты.
Какие я сложные вопросы тут задаю.
Так, а что это?
Нет, в общем случае-то, а что мешает-то?
Ну тут просто вообразить.
Во-первых, ничто не мешает находиться вот такому прямому
ребру в принципе, да?
А во-вторых, ничто не мешает находиться...
Нет, хотя нет, что-то.
Ну вот.
А, хотя стоп, погодите.
А как такое может быть, действительно, вообще?
Потому что, извините, ну вот.
Ну просто мы сказали, что у нас есть какая-то первая
попавшаяся вершина, допустим, да?
Просто какая-то первая попавшаяся вершина, из которой есть
путь в вершину В с таймынами больше, чем В.
Нет, больше, чем В.
Не W.
Да.
То есть заканчиваем W и с W идем либо по перекрестному
ребру, либо может быть там по...
Ладно, может отдельно случай рассмотрим по обратному
какому-нибудь.
Да, надо будет отдельно рассмотреть.
На всякий пожарный.
Ну что мы тогда можем...
Какой мы вывод можем сделать?
Так.
Ну, во-первых, мы можем...
Ну ладно, нам пока, кстати...
А почему так и быть в целом?
Ну, скажем так.
Не очень понятно.
Ну, смотрите.
Ну, просто скажем так.
Почему-то есть жуткое подозрение, что этот путь обязан проходить
через какого-то предка X.
Хотя нет, не обязан.
Значит так, не может быть так, чтобы если мы пошли
в полное ощущение, что если мы от предка W пошли,
то мы вряд ли придем куда-то выше.
Что-то у меня возникает такое жуткое интуитивное ощущение.
Кажется, просто с производством X мы ничего не можем.
Ну, смотрите, просто когда мы...
Ну, фишка очень простая.
А, слушайте, тупая идея.
Таймы над X меньше, чем таймы над W, правда?
Все, правда?
Значит...
Значит получается, путь от X до W содержит
какой-то общепредок X и W.
Но если X таким предком не является...
А, все, у нас...
Та вот развилка, которая выше X,
это в смысле развилка в дереве DFS.
Да, конечно.
Господи, все так?
Да, развилки выше дерева DFS не бывают.
Потому что в противном случае выяснилось бы,
что на пути от X до W какой-то общепредок,
не совпадающий с X существует.
Или просто говорим, что на пути от X до W
существует общепредок X и W.
Так, если...
Значит, если он...
Ну вот, он может являться только X.
Потому что все остальные предки X,
значит, они по таймы...
Значит, меньше X, а, следовательно,
меньше W.
Так, следовательно...
Значит, этого мы удаляем.
И заявляем,
для удобства картинки,
что у нас все заканчивается где-то ниже
или, в крайнем случае, в самом X.
Так, ну хорошо, говорим мы.
Так, тогда мы говорим,
тогда мы этот путь немножко оптимизируем.
Так, мы говорим,
что этот путь у нас как устроен?
Раз он приходит через W,
значит, мы можем, получается, сказать,
что этот путь на самом деле...
Что этот путь на самом деле
не совсем такой.
То есть он как бы...
Мы говорим, что он шел-шел.
Ой.
Ничего себе я стер.
Так, ну ладно, не важно.
Так.
Вот, ничего страшного.
Значит, это вот W.
Так, это у нас зелень какая-то.
Значит, это этот путь.
То есть мы говорим, что он как-то тут у нас
шел-шел.
Чисто справа от этого всего пути шел,
правда?
Ну, правее вершины V.
Ну, правее или ниже.
Вот.
Но при этом и при этом в какой-то момент
прям воткнулся
в какую-то вершину.
Мы ее назвали W'.
Вот.
Ну, мы сказали, что это, конечно, не обязан быть
непосредственно предок.
W, кстати, может быть W'.
Может из W совпасть вполне.
Я для удобства так нарисую,
что
такое вот.
То есть берем W и рассматриваем на этом пути первого предка.
W'.
А теперь замечаем,
что мы замечаем.
Вот.
А теперь мы взяли
вершину W''.
Внимание, вопрос.
Что мы взяли в качестве
вершины W''?
Что-что?
Кто?
Вот это вот?
Так, какой вопрос?
Где вопрос?
Да, это кажется, полудобинатор
W'.
Кто? X-то?
W''?
Нет.
У нас определение было другое.
Помните, у нас было определение, что W''
это последняя вершина
пути от, вот тут мы и запутались каком.
Но правда, ладно,
тут у нас путь от X до W'.
Так хорошо,
говорим мы.
Давайте тогда у нас W''.
Это будет не от R,
а от этой вершины X, на самом деле.
То есть допустим,
у нас тут еще что-то было.
И это зелень.
Кстати, заметим, что
хотя тут очень странно.
Хотя тут, смотрите, как очень
интересно получается.
Потому что, заметим, что ни в одну из
этих вершин этот путь упасть не может.
Потому что на этом пути,
напоминаю, все вершины больше, чем
W', следовательно, предками не могут быть.
Понимаете, да?
Не здесь, не здесь.
Вот.
Получается, да,
смотрите, как интересно. У нас есть путь от X
до W'.
Все вершины по таймы
больше, чем W'.
Но при этом ни одного предка
этой вершины
там нет.
Вот эти
пути туда просто не попадают.
Хотя тут действительно всякое
может быть.
Теперь возникает вопрос.
Возникает почему-то жуткое ощущение.
А нет ли ощущения, что
X это...
Отсюда можно сделать вывод, что...
Хотя нет, погодите,
определение W' осмысленное.
Прошу прощения, я уже путаюсь.
Действительно, мы ищем последнюю
вершину на этом пути, которая
меньше. Но, очевидно, она должна быть
предком W', правда?
Но здесь она не лежит
по определению.
Здесь она
не лежит...
Здесь она не лежит
тоже по определению, но еще по более раннему.
Следовательно, вот этот X
и есть на этом пути W'
Но тогда
вывод-то очень простой. Это получается,
что на этом пути от W'
до W',
все вершины,
то есть, на самом деле, все промежуточные
вершины по таймину больше, чем W'.
Понимаете, да? То есть, вывод.
То есть, получается,
мы доказали
мистическое утверждение.
То есть, если... Я могу так сказать.
То есть, на самом деле, так.
Значит, утверждение такое,
если X
кандидат
в полудоминаторе,
вот оно вот,
то есть, короче, S' от W', не буду уж стирать слово,
то
либо
существует
прямое ребро,
прямое ребро
из X' в W',
либо
существует
перекрестное
ребро
и тут вот ваша договорка
или обратная.
Значит, что будем говорить, так?
Ребро W',
вот.
А также...
А также
вершина
W'
предок
значит W',
но
не предок
от, соответственно, W',
такое, что
такое, что
X
кандидат
в S'
от W'.
Я совсем черную моду написал.
Хотя, вроде как, доказали мы,
если вы думаете, просто ровно это.
Ну, я просто, конечно, неформально понятие
кандидат в полудоминаторе.
Но, я думаю, достаточно очевидно,
что давайте, что скажем так,
назовем кандидатом в полудоминаторе
вершину, ну, в общем, вот такого
вида.
А реальным полудоминатором найдем минимального
кандида, то есть, кандидата с минимальным
понятным, да?
Вот.
Значит, ключевое
решение такое, что если вершина X
кандидат в полудоминаторе
W',
то она
кандидат, то есть, получается, ее среди кого
надо искать?
Ну, вот. То есть, получается,
давайте
подумаем, что у нас получается. То есть,
получается, искать,
достаточно искать
только среди вершин,
которые либо у нас тут
соединены прямым ребром, да?
Либо рассмотреть вот такие.
То есть, мы заметим, да, я тут доказательствия,
правда, немножко может быть,
может показаться, что я тут пользовался
тем, что это ребро перекрестное.
Но, я думаю, вы догадываетесь, что если W окажется
потомком В, то рассуждение будет такое же,
просто это ребро будет упираться в вершину В.
Так, в общем-то, тем, что эта вершина
упирается именно в В, мы, в общем-то, особо
не пользовались.
Вот.
Соответственно.
Так.
Вот.
Так что, получается, значит,
то есть, получается,
достаточно рассматривать только такое. То есть,
перебираем, то есть, по сути, рассматриваем
все ребра, которые входят в вершину В.
Если оно прямое,
ладно,
наврал.
Это тоже нас устраивает?
Ну, да.
Так, здесь такие выражения, как будто
тут началось, как будто я на китайском
заговорил.
А, вот здесь, здесь, здесь.
Нет, ну, слушай,
ты можешь просто в прямую
задавать такой вопрос, я просто тыкну.
Так быстрее просто будет.
Вот.
Значит, или
ребро дерева DFS.
То есть, либо просто мы на прямую пришли,
то есть, как мы пришли сверху, либо прямое ребро,
либо ребро дерева DFS. Вот.
Ну, в нашей классификации это разные вещи.
Вот. В других классификациях там по-разному
бывает. Либо, оказывается,
то есть, рассматриваем все входящие ребра.
Если это прямое ребро дерева DFS,
значит, вершина сама
может быть кандидатом по такому утверждению,
да. Либо, если
обратная,
значит, либо обратная, либо перекрестная,
то рассматриваем путь до
этой вершины. То есть,
до LCA, но не включительно LCA.
И на этом пути
расходим вот это.
И рассматриваем каких-то
кандидатов.
Вот.
То есть, получается,
чтобы рассмотреть кандидата V,
надо рассматривать кандидатов на
таких путях, а также включить прямое
ребро дерева DFS.
Получается,
этого достаточно.
То есть,
некоторые вершины подходят, может быть,
некоторые нет. Хотя,
заметим,
хотя важное утверждение
здесь заключается в том,
что, по-моему,
как бы
на самом деле любая вершина
описанного вида на самом деле прекрасно
подходит.
Ну, давайте так.
Если у нас есть прямое ребро
или ребро дерева DFS, то значит, X
заведомо кандидат в полудоминаторе. Правда?
То есть,
на самом деле, ну вот.
А если наоборот,
ну вот,
а если, допустим, выяснилось, что у нас
можно взять вот такую вершину W,
допустим, перекрестный ребро
откуда-то справа, да, рассмотреть путь
до LCA не включительно
и на нём рассмотреть какого-нибудь
кандидата в полудоминаторе
от W',
то это
ну вот,
это тоже кандидат в полудоминаторе.
Единственная только маленькая оговорка, что
этот кандидат в полудоминаторе
может оказаться где-то здесь.
Но это, кстати,
в этом смысле тогда оказывается очень удобным
и избавились от этого требования.
Ну, просто выяснилось, что ну не минимальный,
там, значит, меньше найдётся,
ничего страшного. Но это тоже кандидат.
Ну, в принципе, я можно сказать,
что они все, в общем-то, кандидаты в
полудоминаторе, да?
Так что
вот.
Но с другой стороны, заметим, что нам
имеет смысл рассматривать только
хотя вот здесь мы, ну вот,
вот тут, ну вот, хотя нет,
тут тоже получается где-то ошиблись,
потому что мы всё-таки явно пользовались тем, по-моему, что
X это предок.
Или не пользовались?
Пользовались или не пользовались?
Пользовались.
У нас кажется,
это более-менее следует за того, что
кандидат в полудоминаторе
Нет, нет, смотрите,
на самом деле не любой кандидат в
полудоминаторе S на мат В, предок В.
Но по такому определению, заметим, что
и сама вершина W,
весь вот этот вот путь является кандидатами,
потому что все эти вершины по таймену больше
чем В.
Да, мы тут, конечно, немножко формально страдаем, конечно,
да. Может вы там это
приготовили экзамен, может там
получится проще.
Поэтому тут, конечно, утверждение
получается, если тут ещё придётся
написать и X, предок
В.
Чуть-чуть другое
определение
Да нет.
Да нет,
я сейчас, конечно, пересмотрю, но у Тарья
оно ровно такое.
Сейчас скажу.
А, собственно,
с другой стороны
полудоминатор
с номером
это кажется
проблема вот этого кандидата
в полудоминаторе,
потому что это просто
кандидат.
Кандидат в полудоминаторе с номером
больше, ну,
с тайменом больше, чем В,
нас просто не интересует, потому что мы страдаем.
Ну, вообще говоря, да.
Ну, не важно, давайте так вот, в таком виде утверждение выверну.
То есть давайте так, если
X-кандидат и X-предок,
то получается
то либо тут прямое ребро,
либо существует тут вершины вот такого вида,
там для которой это тоже кандидат
в полудоминаторе, причем
тоже предок. Видите, да?
Вот.
Да.
Я бы так сказал. При этом,
как мы еще и доказали,
X-предок
W'.
Но при этом, смотрите,
но при этом
я утверждаю следующее,
что, предположим, что так,
ну, вот.
А теперь давайте предположим,
то есть давайте рассмотрим вот что,
что рассмотрим
любую такую W'
и рассмотрим любую
кандидат в полудоминаторе
для W'.
А зачем
рассмотреть? Ну, сейчас, ну, просто
у нас нет криволетности.
Нет, понимаете, в чем проблема?
У нас просто проблема такая, что множество,
то есть это доказывает следующее,
множество предков вершины W'
кандидатов в полудоминаторе
входит в множество кандидатов
в полудоминаторе для вот таких вершин.
Ну, плюс еще вот эти ребра, да?
Но для того, чтобы делать какую-то
тиремму, надо доказать, что там все подходят.
Потому что, может, вы там
в том множестве найдете минимум, а он как раз
придется на ту вершину,
за счет которой это вложение
как бы не точное.
Понимаете, да? Понятно, о чем я говорю?
Поэтому желательно
доказать, что эти множества идентичны.
Ну, там так, либо доказать, что самое тупое
доказать, что эти множества идентичны и не парятся.
Так, ну, точнее так, ладно,
они не идентичны, но, по крайней мере,
можно так сказать,
что действительно,
ну, скажем так,
то есть, может, получается так, что
если у нас получился кандидат
в СДМ от W' подобного рода,
что тогда получается?
Ну, тогда получается он
окажется,
то есть, действительно, вот такого рода.
Но заметим, что он по-любому окажется
кандидатом
депутата в полудоминаторе
В.
Логично, да?
Потому что там обход будет до W'
будет больше В, значит, вот еще.
Но тогда, если он окажется где-то здесь,
ну, значит, у него таймин больше
чем В. А если он окажется таймин меньше
чем В, то он просто вынужден будет оказаться
предком В. Понимаете, да?
То есть, получается,
не совсем так
получается.
То есть, правильнее сказать,
конечно, что
действительно,
надо, действительно, всех этих кандидатов,
то есть,
получается, что этот кандидат,
любой кандидат будет либо предком В
и прям вот совсем идентифицировать
удовлетворительную утверждению, да?
Либо он может
оказаться,
то есть, либо он может не
оказаться предком В,
то есть, вот совсем эквивалентность
неверна. Но тогда окажется,
что у него таймин просто больше, чем В,
и он просто на ответ не повлияет.
То есть, по большому счету,
получается, что
нам действительно нужно следующее.
То есть, как
кандидатов надо перебрать?
Зачем надо перебирать кандидатов, если мы можем
перебирать уже самих полудоминаторов?
Да, но заметим, да, что
как выбрать лучшего, да,
как для каждой вершины надо перебирать
не всех кандидатов полудоминатора, а лучшего
кандидата в полудоминаторе, правда?
А кто такой лучший кандидат в полудоминаторе?
Это полудоминатор.
По определению.
То есть, тогда получается...
А ну, а дальше конструкция,
как мы использовали в построении,
нам нужен какой-то армин опять же
на каком-то таком пути?
Ну, на самом деле, да. Да, но давайте внимательно
посмотрим, как же это можно сделать.
Потому что, значит, как нам для вершины В
теперь получается...
Так, давайте вот теперь попробуем заново.
Как нам это надо делать?
Жила была вершина Р, как теперь для вершины В
найти полудоминатора?
Да.
Да, то есть надо перебирать вот эту вершину.
Сейчас.
Давайте дойдем.
Надо перебирать все прямые ребра.
Значит, выбрать минимального, да?
Но это по прямым.
Если мы нашли какое-нибудь обратное
перекрестное ребро,
то что нам нужно сделать?
Надо перебирать все ребра,
то есть все вершины, которые идут пока
выше.
То есть, точнее, правее.
И на них получается
из этих вершин выбрать
минимального этого.
Да, то есть, соответственно, нам нужно, чтобы вот в этом
нашем линковале вот этот путь был,
а ребра не было.
Ну да.
Но это легко достигать, если мы идем по убыванию
тейно. Да, сейчас.
Но я сейчас давайте уже полностью сформулирую.
И еще нарисую я еще такой
мелкий случай.
Но еще бывает, что тут обратное ребро.
Вот.
Но тогда, значит, вот на этих вершинах
тоже, получается, эздом надо найти.
То есть, вот видите, как интересно.
То есть, получается,
в этом случае
надо
от каждой вершины, где нашлось
такое ребро, надо искать
минимального эздома,
где, на всем вот этом пути.
То есть, на пути
только вот идти по предкам, но вот
до тех пор, пока тут вершина
больше, чем вершина V.
И среди них искать
эздома.
Да.
Вот.
Поэтому получается, что, поэтому явно напрашивается,
что, оказывается, можно теперь
снова использовать нашу любимую
структуру everlink update.
Каким образом?
Ну, идем с конца.
Ну, да, да, да.
Идем, перебираем вершины в порядке
убывания таймына.
Да, не путать с порядком убывания таймаута,
это разные вещи.
Именно в порядке убывания
ну, вот.
Ну, хотя, да, сейчас.
Получается, да.
То есть, мы запустили DFS, идем в порядке
убывания справа налево.
Идем в порядке убывания таймына.
Идея такая.
Храним уже посчитанные эздомы.
И, значит,
ну, вот.
И из них, значит,
составляем, соответственно,
те же самые деревья.
То есть, как бы,
говорим, что, значит,
у всех вершин, которые...
То есть, идем справа налево,
и у всех вершин как бы восстанавливаем
ребра в детей.
И только на этой структуре умеем
хранить минимум по эздому.
Вот, по таймыну от эздома.
А заодно и можно аркмин.
А, ну, кстати,
по-моему, несколько страниц назад мы ровно этим и занимались.
Для того, чтобы хранить айдома.
Было дело. Вот.
И тогда получается, что вот идея такая.
То есть, надо теперь.
То есть, тогда, когда мы пришли в вершину V,
то есть, у нас есть какие-то деревья есть.
Но получается, что...
Ну, теперь легко заметить,
что, на самом деле, действительно,
если у нас есть какой-нибудь там
зелененькое ребро, допустим,
то тогда получается, что
восстановлены
здесь ровно
ребра до вот этой вот
ЛЦАшечки.
Вот эти ребра есть.
Поэтому минимум по эздому
можно просто вот, типа, запрос в Эваллинк апдейте.
Видно, да?
Запустили запрос
в Эваллинк, соответственно, апдейте.
И радуемся жизни.
Вот.
Если есть обратное ребро,
то тоже ничего страшного,
потому что пока мы детей не привентили,
тут как бы получается вот
какая-то такая вот ситуация.
И тоже
хорошо.
Точнее.
Вот так.
Если быть точнее.
Вот.
И тогда получается тоже
эздомы вот до сюда
выбираем. Из этих эздомов получается
просто выбрать минимум и все.
Вот.
То есть получается, соответственно,
что эздомы мы насчитали
за какое время?
Получается, мы насчитали
ну, за DFS
плюс сколько?
Значит, N эвалов
ну, плюс N линков.
Ну, N, давайте я тут
N-1 напишу.
Вот такой я вредный.
N-1.
Ну, тут конечно
меньше либо равно N.
Вот.
Ну, получается, что
то, что нам осталось.
То есть вот так мы вычисляем
эздомы. Ну, а дальше нам, конечно.
Так.
Ну, теперь возникает вопрос. А не можем ли быть
тем же DFS еще и айдомы насчитать?
А нет.
Нет, по-моему, нет.
Порядок вычисления.
Да, эздомы как бы вычисляются
в порядке убывания.
А айдомы придется восстанавливать.
Ну, правда, айдомы там можно уже без DFS
восстанавливать, по-моему.
Ленивый динамик или еще что-то.
Кажется, вообще, можно
DFS сделать
ровно один на то, чтобы
насчитать тенины.
А дальше фориком по убыванию
DIN-ов раз и потом еще раз.
Ну, по сути, да.
Да, но это как удобно мыслить.
Ну, правда, тогда этот первый
DFS должен для каждой вершины сохранить
детей. Да.
Но это мелче.
Так что вот. То есть получается,
что мы свели к линкой
валу, в общем, задачу свели.
Ну, или
вот. Ну, правда,
теперь, кстати, мелкая олимпиадная
проблема теперь заключается в том, что
вот такую технологию уже теперь
надо подумать, можно ли ее свести к дереву
отрезков какому-нибудь.
Зачем?
Линк валу же можно сделать
за вал. Да. Ну, с другой стороны
да. То есть олимпиадники в этом месте
говорят, а давайте делать линку, то есть
давайте делать линк в тупую, а вал
сделается в листике сжатия путей.
А у нас, как мы, видимо,
когда-нибудь завтра докажем, собственно,
в листике сжатия путей, даже если вы просто
неважно там даже большого к маленькому
подвешиваете, это вам гарантирует учетную
стоимость логарифа.
Вот.
Там есть какая-то более экстатическая,
конечно, эта оценка,
на самом деле. Ну, которая показывает,
что если m порядка большого,
n лог n или m квадрат, то на самом деле m это
уже становится там что-то типа вот единиц.
На самом деле.
Вот.
Там получается что-то там n квадрат
челить на m или что-то еще в этом
роде, там какие-то такие мерзи.
Но это неважно.
Вот.
Так что, то есть на олимпиаде как бы получается,
ну, то есть вот, конечно, повспоминать придется,
подписать придется, если вам кто-то, конечно,
случайно даст задачу на этот
алгоритм.
Вообще кажется, здесь у этого
тей-код довольно приятный.
Вообще-то да.
Потому что простая реализация линковала на этом
тей-код.
Да. ДСУ-шка только без ранговой евристики.
Да.
Да.
Ну,
по сути, да.
Ну, скажем так,
у этого алгоритма есть оговорка.
Вам будут давать мало задач на эту штуку,
поэтому у вас мало шансов ее написать.
Ну, правда.
Но если вам уже дали, то рекомендуется, конечно,
порешать, может быть, себе в тим ноутбук написать.
И может быть, вам повезет
и на каком-нибудь важном контесте
на эту задачку дадут.
Ну, может,
не повезет, я не знаю.
Потому что на каких-нибудь финалах,
по-разному, на финале несколько лет назад
решили в качестве гробовой задачи дать задачу
на быстрое преобразование фурье.
Потом так все удивились, что для русских
оказывается эта задача халява.
Вот.
Но это
нормально. Я вам, наверное,
открою страшные тайны, если скажу, что
на последнем финале была задача
на самом деле на
фурье. Из точки зрения нашего домашнего задания
это было практически упражнение.
Вот так скажем.
Так что
это скорее риск на то...
Но как бы это дать? Относительно стандартное
упражнение получилось.
Выяснилось, что русские умеют
упитывать за лучшую асимптотику,
чем там предполагалось.
Это как раз по камере русские в лице
Вани Андросова. Впрочем,
его метод я и рассказывал.
Ладно, не буду сейчас повторяться.
Это уже, как бы да,
отсылаем к прошлому семестру, соответственно.
Это жалко. Не удалось решать задачи
на фурежке.
Жалко. Но это я не проследил.
Жалко. Но ничего.
Ладно. Рекомендую
послушать, потому что фурьетина, к сожалению, нужна.
Это у вас, конечно, есть в команде человек,
который это все прослушал.
И, видимо, и пошел в основной поток.
Но как бы что делать?
К сожалению, практически все, что я вам рассказывал,
это, видимо, то, что Валипиадр знать надо.
Но если вот дерево доминаторов,
а так всякое...
А так что там еще дадут?
Всякое бывает.
Но это вот было дерево доминаторов.
Ну, как я сказал, линк и вал мы, видимо,
попробуем рассмотреть в следующий раз.
Так, есть ли тут еще какие-то вопросы?
Ой, нет.
Так...
Так, слушайте, а вот хороший вопрос.
А, нет, все, нет.
Так, ладно, есть еще одна вещь,
которую, пожалуй...
Смотрите, нет, просто так скажем.
Ну понятно, какие вещи у нас остались
в семестке, которые не хочется переносить
на следующий раз.
Это, конечно, разговор про Миностовы.
Ну, разговор про Миностовы
и связаны с ним разговоры
про СНМ.
Значит, про СНМ.
Но...
То есть, ну, по идее, да,
была бы мысль, на самом деле, перенести его на завтра.
Но есть одна еще маленькая мелочь,
которую, я думаю, мы, может быть,
сегодня пообсуждаем, и, может быть,
это будет все.
Я, конечно, говорю о поиске Миностова
на ориентированных рамах.
Сколько китайцев?
Ой, Господи, в старой версии экзамена
там даже эти два китайца были написаны,
но я помню только Ли Цзенхонга.
Это два слова.
Чу Йонджина и Ли Цзенхонга.
Так что китайцы нефиг четырех русских обзывать.
Ну вот.
Так что да.
Значит, так, ну что, вам перерывчик
требуется?
Нет, просто я говорю, как вам? То есть, можно
сделать перерывчик, а можно я там
по рассказам алгоритма вас пока ничего отключу.
Так, не требуется, да?
Чего?
Ну, давайте. Хорошо.
Значит, что у нас тогда
получается?
Итак.
Забываем о дереве доминаторов.
Сейчас мы будем рассматривать
принципиально другие вещи.
Но мы внезапно не забываем
о графе потока управления.
Значит, мы
снова живем. Итак, вот у нас
снова, опять же, так сказать,
В, Е и Р.
Это
граф
потока управления.
Вот.
Это мы
рассказываем, это мы любим.
Значит,
к чему это нас приводит?
Ну, а фишка теперь в том,
что граф взвешен.
То есть, будем говорить, что у нас есть
какие-то веса.
Достаточно произвольные.
Ну, мы будем считать, что они не отрицательные,
но нас в какой-то момент забирают вперед.
Но просто это не будет сильно
иметь значение.
Так вот.
Нас будет,
значит,
будет задача.
Какая задача нас
интересует?
Найти
такое подмножество Е.
Такое, что, значит,
внимание, В,
Е, Р.
Это
тоже
граф потока управления.
Ну, то есть, в переводе
говоря, что по Е,
все еще можно от Р дойти до всего остального.
Так.
Ну, еще
давайте скажем, что модуль
Е, равно модуль
В-1.
Ну, в переводе говоря,
это дерево.
И, конечно же,
сумма
весов
в Е'
естественно минимальна.
Вот такая
вот
задача.
Так.
Ну, начнем с разминочки.
Что там?
Там
какая-то конспекция.
Ну,
ну,
ну,
ну,
там
конспект того же
самого, вернее, код.
А, может
опять там, ладно, можем схалявить.
Так, хорошо, кто знает
как это искать за сим.ве?
Так.
Что, усомнились?
Так.
Так, вы это
поднимаете руку?
Так, хорошо.
Кто знает как это искать за е.лог.в?
Так. Окей.
Так, ну ладно.
Ну просто фишка,
заранее скажу, очень простая.
То есть нам нужно найти
то есть нужно взять
известный алгоритм.зв.е.
и попытаться оптимизировать его с помощью
сливаемых куч.
Все, не сталкивались?
Ну, давайте сейчас быстренько
начнем.
Ну, тоже ладно, тогда я не буду
долго заморачиваться над этим.
Вот.
Итак.
Ну, начнем с того, что можно
рассматривать веса
больше либо равной нулю.
Ну, потому что у нас идея такая, что
в каждую вершину кроме r в этом дереве входит
ровно одно ребро.
Поэтому если ко всем входящим ребрам
прибавить одну и ту же константу или вычесть,
то дерево не поменяется.
Потому что вес любого дерева
изменится на ту же самую константу,
поэтому принципиально ничего не поменяется.
Поэтому остается идея,
поэтому идея такая.
А давайте-ка прибавляем
по вычитаем из всех ребер
и добьемся того, что в каждую вершину будет
входить хотя бы одно ребро веса
ноль.
Ой, ну хотя да, сейчас будет
алгоритм из цикла да, что все знают,
а на доказательстве можно на экзамене
развлечься.
Поэтому будьте аккуратны.
Потому что
теперь после этого врубаем.
Если выясняется, что
после этого выясняется, что у нас
оказывается дерево, состоящее только из нулевых
ребер,
то можно сразу сказать, что
до свидания.
Ну в каком смысле до свидания?
Ну до свидания в том плане,
что дерево найдено,
но заведомо минимально очевидно.
Так, но если такого не нашлось,
что делать?
Ну, во-первых, запустим из зера
и пройдемся
по вот этим нулевым ребрам.
Так, а это в какой группе ЛКШ рассказывают, кстати?
Тоже.
А у вас?
Тоже в ЛКШ
или где-то еще?
Ну да.
Вот.
Хорошо.
Значит, вот дошли.
Ну, до куда-то дошли, тут еще какие-то вершины остались.
Но теперь утверждение такое.
Эти ребра
имеют смысл включить
в ответ.
Почему так?
Ну, тут
надо просто очень аккуратно,
потому что доказательства
будут построены на том,
что рассмотрим какое-то оптимальное дерево
и будем подменять у него ребра,
но вот эти и хуже становиться не будет.
Но, на самом деле,
это надо делать аккуратно,
чтобы случайно веточку не отпилить.
Как это делать аккуратно?
Ну, давайте здесь это будем делать аккуратно
в порядке БФС-а просто.
Ну, потому что
будем говорить так.
Аккуратно.
Сначала, давайте, пусть у нас есть какое-то
оптимальное дерево.
Такое.
Какое-нибудь там, красненькое.
Какое-нибудь вот такое.
Вот.
Какое-то такое.
Всякая гадость.
Вот так.
И тут мы и говорим.
Ой!
Говорим мы.
А если у нас тут 0,
точнее так,
давайте рассмотрим вот это ребро.
Если оно уже лежит в этом дереве,
все хорошо. А если оно не лежит,
то тогда оно очевидно
соединяет предка с потомком.
Правда?
Ну, потому что R все равно всеобщий предок. Правда?
Но, впрочем, это не особо важно.
Самое главное, что оно
не соединяет потомка с предком для нас,
по большому счету.
Вот.
Теперь мы заявляем следующее.
А давайте-ка,
вот это ребро ведущее в эту вершину уберем,
а вот это добавим.
Тогда достаточно легко
убедиться, что дерево останется деревом.
И хуже не станет,
потому что мы завинили какое-то ребро
не меньше нуля
на нулевое. Ну понятно, да?
Получается, эту вершину
подменили, эту вершину подменили,
эту вершину подменили, да?
То есть теперь у нас ребро,
дерево имеет вес. То есть оно как-то
начинается вот так,
а дальше идет какое-то безобразие.
То есть предположим,
что оказалось, что вот, допустим, в BFS
это следующее
ребро на самом деле
имеет
то есть может оно как-то
может оно как-то вот так вот.
Но это тоже не принципиально,
потому что, как я уже сказал, самое главное,
что мы гарантируем, что это ребро не соединяет
потомка с предком.
Потому что
если бы в красном дереве
был потомок, то у нас получился бы
зацикл.
Но раз это не так,
тогда мы без труда удаляем это ребро,
добавляем вот это и получаем
на одно ребро больше. Ну и так, собственно,
аккуратненько, просто в порядке BFS
эти ребра мы в дерево вставляем.
Понимаете, да?
Вот.
То есть первая идея такая,
то есть как бы все, что тут можно обойти
за ноль, собственно, мы без труда
обходим.
Так, что мы делаем еще?
Ну вот.
Но если нам повезло и мы так обошли
все, то мы победили.
Но что делать, если нам не повезло?
Давайте быстренько вспомним.
Тогда оказывалось, что жила была
вершина, до которой мы не дошли,
и у нее нулевое ребро входило, правда?
Так.
А еще у нас было
тут был ноль, тут был ноль.
Ну, в общем, нулевые ребра какой-то граф
образовывали. И периодически
они образовывают компоненту сильной связности.
Ну, потому что
скорее всего, какой-то цикл найдется,
какое-то сжатие точно произойдет.
А почему сжатие-то?
Да потому что идея такая,
давайте теперь возьмем на этих нулях
все компоненты сильной связности, которые
не дошлись.
И просто сожмем в одну вершину.
Потому что утверждение,
теперь будет более
жесткое утверждение,
утверждение, что
в, то есть существует ответ,
в котором
вот эта вот компонента связности
будет
давать связанное поддерево.
Понятно, да?
Причем более того,
то есть на самом деле мы доказываем
более сильное утверждение,
что существует ответ,
для которого каждый из этих компонентов
будет давать связанное поддерево,
и еще при этом вот это сверху.
Но заметим,
то есть как бы рассуждение
надо проводить так, чтобы для каждой компоненты
его можно было привести, и оно не портило соседей.
Но понятно,
что вот это у нас компоненты никак
не испортило, да?
Вот.
Ну вот.
Ну а теперь, если нам выдали потом
после этого какой-то ответ на задачу,
то что у нас тогда происходит?
Происходит вот что.
То есть у нас есть какая-то компонента.
Это компоненты сильной связности.
И вот мы, допустим, знаем,
что есть какой-то ответ,
тут 0, 0, 0, тут может быть еще какая-то
гадость, не нулевая,
мы не знаем. Но все-таки мы в какую-то
вершину первой пришли.
Тогда утверждение такое,
я внутри этой компоненты
просто запускаю
какой-нибудь DFS,
потому что я из этой
вершины могу просто
внутри этой компоненты
построить на нулевых ребрах такое дерево.
Но теперь заметим
следующее, что эта вершина
в том дереве, который у нас
получилась, ни одна из этих вершин
предком этой вершины
вроде как не является.
Это важно.
Потому что это дает
мне возможность ровно той же
самой технологии аккуратненькой
подменить ребра
в том дереве на вот эти вот.
Ну потому что я начну с этих ребер,
я могу эти ребра вставить, а входящие ребра
в эти вершины соответственно поудалять.
Почему? Потому что просто ни одна из этих вершин
не является предком
этой вершины.
Потому что эта вершина первая, в которую мы вошли.
Видите, да?
Аккуратно подменили, потом
в порядке BFS подменили и так далее.
В порядке BFS
это мы просто для доказательств
говорим. В реальности вам достаточно
будет просто понять, что
мы в эту компоненту вошли
соответственно
в эту вершину, поэтому
запускаем DFS, обходим компоненты,
всю эту компоненту тоже все эти ребра добавляем
в ответ. То есть получается
как алгоритм устроен в итоге?
Алгоритм устроен так. То есть мы
сначала за O от E
добиваемся того, что в каждую вершину
входит хотя бы одно нулевое ребро,
чем все ребра неотрицательные.
Потом, соответственно там
вот это дерево сжимаем.
А также сжимаем,
если сжалось все, то хорошо.
То есть мы добавляем все
эти ребра в ответ и сжимаем
все эти вершины в одну.
Сжимаем это означает, что
все ребра, которые у нас
соединяют
две вершины внутри жатия,
мы их выкидываем. Понимаете, да?
Ну или в будущем игнорируем.
Вот.
Значит тут сжимаем. А также
если граф остался, то мы находим
компоненты сильной связности, и каждую
компоненту сильной связности мы
тоже сжимаем.
Но как сжимаем?
Мы сохраняем
эту компоненту как
сильно связанный граф на нулевых ребрах.
Потом сжимаем это в одну.
И после, ну вот,
значит после этого жатия у нас получился
сжатый граф, в котором вершин, ну непонятно
насколько, но хотя бы на одну меньше.
Мы строим
рекурсивно, значит, мина стов.
Строим, да?
Строим, да?
А, ну вот. И собственно все.
Ну вот.
После этого для каждой этой сжатой компоненты выясняем
через какую вершину мы в нее вошли.
И собственно запускаем DFS
и там дерево на ней
строим. Понятно, да?
Ну вам понятно, да, вы собственно это
знаете. Это классический алгоритм
двух китайцев. Работает за, получается
в худшем случае ОТВ.
Ну к сожалению, да.
Да, кажется, что против этого алгоритма кажется и
контртест, в общем-то, придумать не сильно сложно.
Ну, хотя нет вопросов.
Чтобы там сжималось, чтобы и дерево
не схлопывалось и сжималось
по две вершинки, это не так
тривиально.
Вот, хотя
ну да, там
какой-то бамбуча такая должна быть зацикленная
с убывающими ребрами, будет нормально.
Да, вот.
Так.
Ну хорошо, говорим мы.
Значит, что будет дальше?
Ну я
утверждаю, видимо, финальное такое
утверждение, видимо, уже более не тривиальное,
что этот алгоритм,
что на самом деле
этот алгоритм прекрасно
оптимизируется.
Теперь вот, внимание, вопрос.
Ну вот, утверждается, что он
оптимизируется, если вспомнить, что у нас есть такое понятие,
как сливаемая куча.
Так.
Так, ну у вас тоже такое понятие было в прошлом году, да?
Конечно.
Вот, окей.
Вот, значит, что же тогда получается
за от е нот?
А как же нам
это сжатие вообще
может вообще как-то
помочь?
Вот, давайте подумаем,
внимание.
Ну вот, ну
почему так?
Нет, давайте.
Ну-ка вы мне действительно какую-нибудь идею скажите.
Чем нам может вообще тут сливаемая куча
помочь?
По сути нам нужно объединять
множество входящих ребер,
когда мы сливаем.
То есть нам уже нужно
кебера сделать, слить.
У некоторой множества вершинок
и
у вершинки,
которая может быть слиянием многих,
узнать самое легкое входящее ребро.
Ну и сделать
типа минус равно на все множество
этих вершинок.
Ну можно делать минус равно.
Соответственно, если мы храним
вот некоторые кучи
изначально из одного элемента,
когда мы сливаем,
мы можем
просто посливать эти кучи
в залог
и потом когда там...
Ну да, в первую очередь начнем с того, что можно
не вычитать.
Потому что, по большому счету, что такое для нас
нулевое ребро? Нулевое ребро
это минимальное торчащее
из вершины ребро, правда?
Это по большому счету все, что нам надо.
Вот.
То есть
в общем-то
фактически алгоритм у нас
может звучать так,
что говорит, что у нас в каждую
вершину ведет какое-то минимальное ребро,
кроме корня, конечно.
И в принципе можно сказать, что
если у нас в какую-то вершину есть путь
из корня по этим выделенным ребрам,
то значит эти вершины можно
объединять.
Но когда мы объединяем единственное,
когда мы объединяем две вершины в одну,
то минимальную ведущую в меня
вершину надо...
То есть надо учитывать, что это ребро
должно быть не как бы из себя любимой.
Но это не проблема.
Потому что из любой вменяемой сливаемой кучи
мы выкинуть ребро за линию, за алгорифом
вполне можем, правда?
Это называется экстракт-мин.
И тогда это приводит
к следующему алгоритму.
То есть давайте в каждой вершине
хранить ребра, ведущие в меня,
просто в сливаемой куче.
Изначально мы понятно
в каждую вершину просто смотрим все входящие
ребра и помещаем.
И дальше алгоритм оказывается
неожиданно тупым.
Кстати, алгоритм двух китайцев можно было
пытаться так реализовать.
Смотрите. Начинаем с первой
попавшейся вершины.
Первой попавшейся вершины В.
Берем выделенное ребро из нее.
Потом выделенное ребро из нее.
Из этой вершины.
И так идем, идем, идем.
Количество вершин у нас конечное,
поэтому может произойти два события.
Либо мы в какой-то момент упремся в корень,
и тогда надо просто
объединить эти вершины.
То есть слить эти кучи.
Ну, как мы уже сказали,
как мы избавляемся от плохих ребр.
Очень просто.
Когда мы из вершины пытаемся
посмотреть минимальное
ребро,
ну, детмин делается за единицу обычно.
Поэтому мы смотрим. Так, это ребро.
Так, а оно нам подходит?
С помощью СНМ мы выясняем, подходит оно нам или нет.
То есть если выясняется, что это ребро из вершины
в себе же, уже с точки зрения сжатия,
то значит мы
такжественно это ребро выкидываем и берем
следующий минимум. Понимаете, да?
Ну так вот, если мы дошли до эра,
то мы тогда объявляем
все эти ребра, можем просто
такжественно добавляем в ответ
и объединяем
все эти кучи.
А точнее можно просто объединяем.
Кучи можно уже не объединять,
а просто выкинуть, потому что
искать минимум в этой куче нам уже не понадобится.
Потому что это корень.
Понимаете, да?
Либо что у нас еще может произойти?
Может произойти
по цепочке, что
они просто зациклятся.
Но тогда этот цикл получается
и его можно сжать.
Но здесь нам потребуется конечно
маленькая аккуратность
с точки зрения восстановления ответа.
Но что тут поделать?
Придется каким-то образом
видимо запротоколировать, каким образом
мы сжимали.
Потому что здесь мы просто понятны,
что мы сделаем.
То есть мы объявим, что у нас есть новые вершины
более крутого номера.
То есть были у нас вершины от 0 до n-1,
а теперь будет n на n плюс 1 и так далее.
И мы про нее
запишем, что она у нас
была на самом деле...
То есть она образована циклом
из вот таких вершин.
Просто мы их запишем.
То есть у нас будет последовательность циклов и вот этих цепочек,
которые нас привели
к сжатию до просто большой вершины.
А дальше, когда мы это будем разжимать,
когда у нас будет цепочка,
мы просто эту цепочку уже
записали, какие ребра у нас в ответ пошли.
А когда у нас
вот эта вершинка,
пришло время ее разжимать,
мы запомнили, что
из этой вершины у нас ответ
это вот такое ребро.
В ребре мы какой-нибудь ID-шник записываем.
И тогда это ребро
будет так.
Если это ребро вело в какую-нибудь
из этих вершин цикла,
значит мы говорим, что в дерево
входит весь этот цикл,
кроме получается
вот этого вот одного ребра.
Понимаете, да?
То есть так вот аккуратно делается.
Видимо, это еще и писали, да?
Или там как-то хитрее есть?
Да, более-менее нет.
Только там
типа с этим...
Ну, там небольшой способ
просто примо немножко
с ID-шниками, на ID-шниках сделать.
Прим на ID-шниках, то есть?
Ну, короче, чтобы
явно не сохранять это все,
там был какой-то способ
сохранить какие-то ID-шники
вот этих зажимаемых циклов.
Я вот что-то попытался
понять, как оно работало, и не понял.
Ага. Не знаю, что там прям
очень мало строчек получалось.
Ну, типа все обстановление ответа
это типа
строго десять.
Да. То есть там прям очень приятное
обстановление ответа.
Ну, может быть.
Нет, потому что вот это, на самом деле, технология,
если ее правильно осознать, то в общем-то она неприятной
тоже не выглядит.
Если честно.
Там что-то надо понаписать?
Ну да. Ну, что-то
надо. Но знаете, вот иногда, как бы, знаете,
если вы не боитесь там вектор-векторов и прям
чисто все хранить, то на самом деле
такой метод получится, может быть, бронетанковый, но зато
там все надежно и работает.
То есть как бы да. То есть
будет иногда работать, по принципу
глаза боятся, руки делают.
Вот. Но
чем это приятно?
Это приятно тем, что, действительно, там у нас
каждое сжатие к
шин работает за, получается, k log n,
потому что сливаемые кучи.
Вот.
Ну ладно, правда, я наврал, а симптотика
правда...
Хотя нет. Хотя да, почему?
Да, суммарно в кучах
не более чем v элементов.
Нет, v.
Ну да, можно сделать, что v. Вообще, самая тупая
реализация, конечно, e log e.
Это как бы, чтобы не заморачиваться,
если вы сразу в кучи
пихаете все входящие ребра,
то как бы тогда получается
e log e.
А если вы там
как-то очень аккуратно следите,
что если там, типа, говорим, выкидываем
ребро, говорим мы, а мы говорим, окей,
так, давайте в каждой вершине отсортируем все
ребра и будем хранить, на ком мы сейчас
остановились. Вот это вытянули, берем следующее.
И так далее. То там можно,
по идее, и
log v добиться.
Впрочем, это, конечно, мелочь.
Впрочем, e log e
всегда можно оценить, типа, 2 log v?
Ну, формально
нет. Нет, формально мы должны произнести
чуть более сложное заклинание, вида
мы за o от v плюс e
или даже за v квадрат плюс e
можем вытянуть кратные ребра.
А после этого сказать,
что log e это
2 log v. Потому что формально
e может быть и v куб, и v в четвертой,
но на самом деле это легко.
Но с этой точки зрения
всем точку надо писать, там
формально o от
minimum из там
e и там v квадрат
там
log v, вот так.
И то, не правда, плюс
e. О.
Вот. Но это вот
как бы для любителей совсем уже
там это
какой-то экзотического формализма.
Но, к сожалению, на меня
такое настроение иногда находит,
поэтому бытьте готовы. Да.
Вот.
Так что вот. Да, получается, вот такой
на самом деле тоже алгоритм, может быть
он, кстати, даже приятнее исходного, если честно.
Хотя, кстати,
исходный тоже можно в этом стиле
написать, он тоже за v и e работает, а то
и быстрее, на самом деле.
Да.
Так что да.
Ну, тем более, что, да, сливаемые
ноты. Ну, кстати, надо еще подумать,
нужно ли, сейчас, а нужно ли писать
именно сливаемые кучи или хватит?
Хотя, может, хватит сливаемых
сетов, банально. Хотя и сливаемые сеты
ну, сливаемые сеты
log квадрат дадут. Ладно.
Да.
Да. Ну, ладно.
Зачастую можно v и e
упихать. Ну, бывает.
Ну, это, нет, дальше, нет, ну, как бы
тот как бы философский вопрос.
Ну, это зависит от того, как бы автор задачи
знал, что этот алгоритм там
оптимизируется до e log v или нет.
Потому что там, ну, как бы
есть три стадии, как бы
три стадии закрутки. Первая там,
может быть, автор тупо не знал, поэтому предположил,
что v и e. Вторая
нота, вторая, в случае
2a, автор добрый.
Он поставил асимптотику так,
чтобы v и e заходил.
Но он мог поставить, потому что он добрый,
а мог поставить, потому что там, как бы, скорее всего,
это только часть решения, а в
исходном ноте, в том решении там
по-любому будет v и e или что-то сложнее,
поэтому не принципиально.
Ну, вот.
Ну, и, соответственно, есть третий уровень,
автор закрутил все райки,
поэтому e log v.
Ну, как бы стипинг закрутки гаек
на самом деле сильно зависит от того,
насколько крутой контест,
то есть, насколько сложились контесты. Потому что
иногда, на самом деле,
как оказалось, например, на последнем
гуире оказалось интересное...
Там авторы рассказали, что произошло
интересное свойство, что
как-то они сделали контест,
просто на него посмотрели и поняли, что это перегроб.
Просто вот объективы
перегроб, расстрел, в общем,
такое на 5 часов давать не можно.
И что-то выкидывали, решили
что-то поупрощать. Ну, привело это...
Ну, знаете, к чему привело, да?
Что знаете, да?
А, вы смотрели трансляцию?
Нет? Ну, не важно.
В общем, привело это к тому, что команда FFTilted
закрыла этот контест
по-моему, что-то типа за 3 часа 12 минут.
Второе место...
Второе место заняла команда действующих
чемпионов России в лице
ну, собственно...
Вы знаете кого?
Которые закрыли этот контест за 4 часа слишком.
Вот.
Как ни странно, других закрывших контест
не было, поэтому контест удался.
Вот.
А, кстати, отдельная песня.
Ой, ну там, в общем-то, возникла еще одна задача,
которая тоже, наверное, имеет смысл рассказать.
Ой, ладно.
Так, сколько там времени?
15.
Без 15.
А впочем, знаете...
А впочем, ладно, знаете,
будет неплохо, если мы это в экзамен вставим,
на самом деле.
Нет, это, знаете, очень быстро, жалко.
На кубок МФТ и хотел дать, но, к сожалению...
А, ну, в общем, когда-нибудь, может,
еще дам, неважно.
Ладно.
Сейчас я расскажу не очень сложную задачку.
Напоследок.
Ну, собственно, ладно.
Будет полезно.
Это будет премьера, такого в экзамене у меня еще не было.
Теперь будет.
Хотя вот тоже
интересно для соцспроса, было ли такое у вас.
Значит, опять,
смотрите, сейчас мы забыли о графах.
Возвращаемся в сладостный,
чарующий упоительный мир структур данных.
Значит,
ситуация такая.
Дан массив.
Там написаны какие-нибудь,
ну, более-менее произвольные числа.
Ну, можно
иногда для простоты считать, что там
простые.
Ну, ладно, от 1 до n,
различные какие-нибудь.
Не сильно принципиально,
потому что сейчас видите.
Ну, там, как всегда,
n у вас там,
от 1 до n,
и у вас есть много
куз запросов.
И запросы бывают
только одного типа.
Отсортировать под отрезок.
Причем, чтоб жизнь
медом не казалась,
вам еще и указывают,
по возрастанию
или по убыванию отсортировать.
Так, вот давайте соцспрос.
А кто сталкивался?
Такая простая постановка задачи будет,
конечно, хотя бы
сделайте куз запросов, и вы увидите,
что в конце получится.
Хотя, в принципе,
можно в некотором смысле пытаться
делать онлайн.
Но хотя бы начнем с этого.
Так, вот внимание, вопрос.
А кто сталкивался с такой задачи?
Ну,
я с ней частично сталкивался,
потому что
примерно такая идея
пришла в голову
Дениса Мустафина, когда он видел
Next Permutation и решил усложнить.
Да-да-да.
Что-то они мне тоже сказали,
что на самом деле
в Next Permutation можно и это записывать.
Может, когда их тесты сделают, действительно.
Хотя, я не знаю,
в Next Permutation есть недостаток.
Если делать тесты только про сортировку,
то есть, если сделать задачу
только сортировку в одну сторону,
то может неожиданно выясниться,
что там все плохо.
Но, правда, мне и сейчас что-то прилетело
на тему того, что там зашла какая-то затычка.
Проходит затычка, типа
склеивать.
Если на одном и том же отрезке
есть Next Permutation
и Preparation, то радостно
сделать ничего.
Да-да-да.
Ну вот, проблема.
Ну да, после этого квадрат запихается.
Ну окей, значит, придется
думать. Окей.
Как это дальше водить?
Задача Next Permutation есть недостаток.
Если бы я не делал Preparation,
то есть жуткое подозрение, что
можно было Next Permutation делать втупую
и, возможно, это было бы там доказательно
что-то правильное.
Ну, в смысле, храним в каком-нибудь дикарточке,
это нормально, но если надо делать Next Permutation,
мы втупую прям идем
по этим элементам, значит, находим
этот убывающий отрезок, делаем свап и так далее.
И может возникнуть жуткое
подозрение, что это доказательно
быстрое решение.
Ну, с каким потенциалом вида,
я не знаю, там,
с каким потенциалом.
Ну, там потенциал такой
тупый, типа, там, количество инверсий
в перестановке.
То есть, заметим, что каждый Next Permutation
делает большой реверс, поэтому у вас
количество инверсий. Если вы там сделали
его за Color M, то у вас там
как квадрат инверсии и просто как корову
языком слезало.
Вот, понимаете, да?
Ну, вот. То есть, там, можно там,
можно потенциал сделать, наверное, там
что-нибудь в корень из количества инверсий,
что-то еще вы там вроде носим.
Поэтому вот Next Prep вот надо, чтобы было отменить,
а отменяемо.
Так что да, ну окей, хорошо,
хорошо.
Вот, но тем не менее, теперь пришло дальше.
Аккупировка. Давайте еще упихиваем.
Да, потому что, да, межнары,
ну, как вы уже поняли, там на бгуере было огромное
количество межнаров.
Просто, ну, как огромное,
можно сказать, походу, три из четырех
действующей сборной России, значит, были там.
Четвертый.
А где четвертый?
Нет, я не знаю, он там где-то с вами вроде
учится, где он? Где клич?
Нет?
Он же...
Что, он уже не учится?
В смысле, он как раз-таки не совсем с нами.
А с кем он?
Он же на ПМФе и только...
А, понятно,
ничего себе. Ну, правильно.
Причем с ним, ну, примерно нет.
Понятно, ладно, поэтому он живет.
Ну, ничего страшного, ладно.
Так, ну ладно, он уже, по-моему, не первый
у нас межнар с ПМФа, по-моему.
Нет, ну вообще, Никита Уваров у нас уже был.
И там, и ничего там,
по-моему, уже вице-чемпионом мира стал.
Собственно, нормально.
Да, вот.
Так вот, идем дальше.
Ну вот, все делать с сортировкой.
Это звучит как будто...
На самом деле, если поддерживать какой-нибудь декоративный,
ну, типа деревь,
какие-нибудь декоративные в плане
по-неясному, ну, в любом
целом, идеи его поиска,
которые мы можем встретить.
Так.
Вот. И...
Если
к нам приходит
запрос
поддерживать
какие-нибудь отсортированные отрезки точно.
Так, ну да.
Идея, конечно, да. То есть, напрашивается
идея, что сказать, что изначально
у вас действительно все состоит...
То есть, все у вас состоит из
отсортированных, ну, в том
или ином порядке отрезков.
И все элементы мы храним в каком-нибудь
декорточе.
Да.
Вот. То есть, как-то отсортировать.
Вот.
И тогда какая идея?
Тогда каждый запрос делается очень просто.
Ну, во-первых, там
сплитим, соответственно, какие-то
запросы, если надо.
Ну, декорточа-то там с алгоритмом как-то делает.
А вот...
Так. А дальше, казалось бы, просто
делаем какую-нибудь переливайку.
Потому что, естественно, каждый отрезок мы...
То есть, мы отрезки храним в декорточе или...
Ну, храним в декорточе, потому что
нам надо знать, где сплитить.
Поэтому Сэд, к сожалению, этого не умеет.
Вот. Но...
Но как бы отрезки храним в
декорточе. Ну вот.
А сами эти отсортированные массивы
тоже храним в каждой в своем декорточе,
но уже по явному ключу.
Так.
И хочется теперь сказать, что мы теперь
берем просто эти отрезки как-то сливаем.
Так. Как же мы это
делаем?
Переливайка. Переливайка это, конечно, хорошо.
Но замечаем, что у нас у переливайки есть
маленький недостаток. Она работает только в
предположении, что мы ничего не сплитим.
Да. Ну, то есть, короче, центральные действительно можно
просто...
Нельзя мы их...
Нам их придется сплитить потом.
Когда-нибудь.
И вся ваша амортизация кату под хвост.
Сейчас вот там же есть
какой-то кастиллер шаховца,
который, вроде, даже доказали, что работает
за лоб квадрат.
Да.
Ой, да. Кастиллер
шаховца. Отлично, да.
Надо будет посмотреть, что за кастыль.
Ну, я понимаю, да.
Значит, будем смотреть.
Ну, потому что... Да, потому что...
Нет, тут это очень забавно. Честно скажу.
Я вот, собственно, на Бугуире, собственно, там...
На Бугуире дали буквально такую задачу.
Вот. Я, собственно, поэтому и узнал.
То есть, там, не для наших,
не для вышкинцевых межнаров она новинкой
не стала.
Потому что они сказали, что основа была, на самом деле,
два-три года назад, была еще даже не от шаховца,
а еще какая-то старая китайская
техника, что я сейчас расскажу.
Вот.
Но на основе этого, то есть, там все, все знают.
Ну, как все?
Ну, все межнары знают, по крайней мере.
Как выяснилось. Ну, там всякие кандидаты
в межнары знают.
Ну, не важно.
Которые говорят, что давайте
сливать... То есть, у нас в чем проблема?
Надо слить два дикарточа по явному ключу,
при том, что у нас нету
сведений, что там
в одном из них значение меньше, чем в другом.
Так как же мы их будем сливать?
Очень просто. Так, вот корень одного,
вот корень второго. Ну, допустим,
пока скажем, что у нас...
Ну, будем сливать более-менее честно.
В том плане, что выберем,
то есть, кто из них там по приоритету меньше.
Значит, объявляем,
что он корень.
Ну, а что у нас
тут с правой стороны происходит?
Ну, тогда, значит,
с правой стороны мы, получается, должны это
с одной стороны как-то посплитить,
с другой стороны, ну, вот, на два дерева.
Вот.
Ну, точнее так, вот в этом дереве
мы должны его там сплитить.
Ой.
Да что ж такое?
Ну, вот. С другой стороны,
здесь у нас тут два дерева,
и, соответственно, после сплита, типа, как будто
вот это померзит с этим, вот это с этим.
Или сделать это как-то более аккуратно.
Вот.
Ну, там, типа, что-то там...
типа, что-то там
сразу отсекать, что-то там отпиливать.
Ну, я, естественно, когда тут два дерева имею в виду,
я имею в виду, что корень у этого меньше
корня у этого. Ну, если они совпали,
то мы просто эти две вершины
объединяем и как бы рекурсивно
сливаем это с этим и с этим неинтересно.
Вот.
А тут как бы...
Вот. Ну, и дальше... А вот дальше
начинается мистика.
Как, ну, вот.
Ну, тут дальше, ну, как бы, ну,
очевидно, что оно там как-то схлопывается и получается.
Примерно, да.
Я примерно процитировал моего тезку Грибова.
Вот.
Значит, Александр Бабин утверждает, что вот
есть дикарта, там есть действительно дикарта,
и вот меня как-то щенишь, вроде
как это делается за лог квадрат.
Сведения там от
Леши Васильева, значит, да, что вот да,
вот есть ощущение, что за лог квадрат, но у всех
это вроде так на уровне ощущений остается.
Вот может
лог квадрат, может даже лог куб.
Возможно, чтобы это доказать,
еще надо влезть в доказательство
того, почему дикарта вообще за логарифом
работает в принципе.
Вообще это очень похоже на... Я не
помню, это очень похоже на то, что было
в блоге у шаховца написано.
Нет, в блоге у шаховца, да, да.
Я не видел блог шаховца, но
его видели те, кто мне это
рассказывал. Так что не удивительно.
Но рассказали мне принципиально
другое. Я утверждаю,
что эту задачу я сейчас решу
без дикартачей за логарифом.
Это какие-нибудь
типы
мысль о каких-то неявных дожах,
которые как-то сливать. Да,
именно. Потому что
ладно, я не сказал. Это я еще более
сложную задачу сказал, потому что задача
была там более простая. В общем,
да, надо сортировать, но еще
при этом все числа от
1 до n это еще и перестановка.
Вот давайте
упростим себе жизнь.
Скажем,
что у нас тут все числа от 1
до n.
Тогда любой...
Тогда я утверждаю...
Во-первых, мы такого не знаем,
мы такого в прошлом году не проходили, но, думаю, вы догадываетесь.
Здесь такая вещь как неявное DO.
Что такое
неявное DO? Это означает, что
во-первых, мы храним DO на указателях,
а во-вторых,
все вершины, в которые мы не ходили,
мы их не создаем.
То есть наша
евристика,
технология
отложенных операций
просто вошла в абсолют.
Мы отложили уже не просто передачу
данных детям, мы отложили создание
самих детей.
То есть это, знаете,
это вообще шедевр.
То есть это как бы...
То есть я говорю, что у меня есть дети,
но как бы мне скажут, так, я хочу видеть твоих
детей, я говорю, одну минуточку.
И, собственно...
Причем, да, что важно, я создаю не двух детей,
а для экономии памяти только тех,
которые надо.
Ну типа все равно нули ни на что не влияют.
Так что вот
такая технология получается.
Вот.
Ну что делать? Так вот.
Ну это нам позволяет...
Ну зачем такое нужно?
Это нужно для того, что если у вас хочется создать
дерево отрезков длины массив 10,9
или там 10,18,
то на самом деле и сделать
к нему Q запросов.
То, соответственно, можно
тогда все сделать
Q log len, вот логарифом
этого длины дерева отрезков,
и ровно столько вершины создать.
Ну потому что все запросы
делаем, как обычно, запросы
сверху, соответственно, они делаются
за O отлена и обходят
O отлен вершин. Следовательно, не более,
чем O отлен вершин они вообще полезут.
Да, логарифом лен.
Да, O от логарифма лен.
Получается, сливаем.
Понятно, да? Ну тут
простая идея. Так вот, неожиданная
идея. А давайте
создадим сет.
То есть как хранить сет
чисел от одного до N
на вот этом вот?
Как это сделать?
Ну оказывается
очень просто. Ну давайте даже
от 0 до N-1 давайте
все-таки сделаем. То есть
как хранить сет? Да очень просто.
Ну вот,
давайте просто мысленно
вообразим себе дерево отрезков.
Вот, вообразить себе классическое дерево отрезков,
то мы просто будем хранить
0 или единичку в зависимости от того,
есть такое число или нет.
А во всех верхних
вершинах мы честно храним,
а сколько у нас, собственно,
вершин, а сколько
у нас тут в этом поддереве элементов есть?
Вот так сет можно хранить. Кстати, очень удобно.
То есть если у нас гарантируется, что все элементы
от 0 до N-1, то что вы можете сделать?
Вы можете добавлять сет элемент
за логарифом, удалять элементы сета
за логарифом. Можете там
найти ката-элемент, кстати, в сете за логарифом.
Это будет даже едва ли неприятнее,
чем делать это в дикарточке.
Ну, суть та же, но как бы вы корень
не обходите. Да?
Ну, понятная технология, да?
Так, но, конечно же, важный
момент, что, конечно, если мы
изначально создадим N таких сетов
один элемент и сделаем полное дерево,
то это будет N квадраты больно.
Но у нас же неявные ДО-шки,
поэтому все нули мы выкидываем.
То есть, да, если у вас много
элементов, то, конечно,
и много элементов может быть и в дереве.
Но суммарно заметим, что
если у вас изначально N пустых сетов
и вы добавляете в каждый сет
по одному элементу или там может быть
несколько элементов в разные сеты, но суммарно
добавляете N элементов, то тогда
получается суммарный размер,
у вас получится
N лог N, даже не О от N лог N, а буквально
N лог N, правда?
Вот, понимаете, да?
Теперь, значит, неожиданность.
Значит, теперь получается,
что с этими сетами
что вам нужно сделать с этим
набором непересекающихся сетов,
так сказать.
Ну, пока не пересекающихся.
Что вам нужно теперь?
Нужно делать две операции.
То есть как-то.
Да.
Да, disjoint.
Ой.
По-английски даже что-то не поменялось,
перевод как-то странно.
Ну да.
Ну, такое да.
Получилась тоже такая система
непересекающихся сетов.
Теперь, какие тут есть запросы?
То есть даны два сета, объедини их.
Как нам передают это отдельная песня?
Но, правда, заметим,
я тут, в отличие от классической ДСушки,
я не буду тут требовать представителя какого-то там.
Я просто говорю, так, объединяем
два сета, вот просто у меня тут есть указатель
на два сета, вот давай их объедини.
И второй запрос.
По сплит сеты.
То есть на сет с
меньше либо равными элементами,
и на к,
и на сет с больше.
Просто создай
по одному сету два сета.
Так.
Ну, поехали.
Как же сделать сплит?
Начнем с халявного.
Спускаемся и довешиваем.
Да, все предельно тупо.
Итак, начнем с корня.
Итак.
Допустим, выяснилось, что в нем 179 элементов.
А мы ищем 57 элементов.
Мы хотим первые 57
влево отправить, да?
Ну, что мы делаем?
Отлично, 179 элементов у нас есть.
Смотрим в левое-правое под дерево.
Сколько тут элементов?
Сколько?
Ну, 130.
Ну, тогда, значит, идея такая.
Мы уничтожаем корень
и создаем
два ответа.
Значит, что мы делаем?
Вот этот ответ будет для больше k,
а этот для меньше либо равно k.
Понимаете, да?
Понятно, что каждая вершина отвечает за какой-то подотрезок.
Эти вершины тоже будут отвечать
за подотрезок от 1 до n.
И тогда, значит, идея следующая.
Ну, кто пойдет?
Ну, во-первых, заметим,
что у этого под дерево,
у него правым ребенком окажется
просто вот это вот все.
Потому что тут все элементы больше k.
Можно прям вот это дерево
просто взять, переподвесить и не париться.
Понимаете, да?
Значит, что еще можно сказать?
А здесь, наоборот,
тут в правом под дереве не будет ни хрена.
Потому что он отвечает
от 1 до n, и тут все в левой половине.
Что мы теперь делаем?
А вот это вот все,
а здесь делаем очень просто.
У нас вот эта штука образует
какое-то под дерево.
Мы его на этом уровне распличиваем.
У него получается один корень
и такой корень вместо вот этого,
забирая вперед, скажем.
Хотя, может быть, там где-то
пустые будут.
Если выяснилось, что вы хотите посплитить
по размеру k, а выяснилось, что тут k элементов
и есть, то вам сплитить не надо.
Просто одно дерево возвращаете прям такое,
а другое пустое и не паритесь.
Или, наоборот, если выяснилось,
что k равно нулю, то значит
просто левое под дерево пустое, а правое какое есть.
Но тогда вы это создаете,
и тогда вот здесь
слева вешаете вот это,
а здесь слева вешаете
вот это.
Перемешка такая.
Результаты сплита вы вешаете
именно как левые деревья.
А правое под деревья, значит,
либо одно пустое, а другое то, что было.
Получается, смотрите,
мы умеем делать сплит
за log
за log n,
причем обратите внимание,
честного времени.
Очень приятно.
Ну, желательно еще вершины реально удалять.
Ну, можно не удалять, конечно,
но лучше поудалять.
Но как же делать объединение
двух сетов?
Ну, тут оказывается,
значит,
оказывается, можно делать так.
Смотрите, как объединять?
Ну, во-первых, пришли к вам
два сета, вам их надо объединить.
Но если одно из них пустое,
то объединяйте в тупую.
То есть возвращайте то,
что не то что…
То есть если одно из деревьев пустое,
верните в другое.
Если два пустых вообще,
то обычно это случае даже
не надо рассматривать.
То есть crow 37ract.
Ну, кто-то любит там писать,
если левое пустое и правое пустое
верните в пустое,
но этот случай на самом деле только
чтобы рассмотреть этот случай. Этого не нужно. Ну хорошо, но что делать, если оказалось, что вам
пришли два вовсе не пустых дерева? А мы железно не пустые, то есть мы стараемся, кстати, нулевые
вершины не хранить. Но мы тут можем аккуратно следить, что если у вас вершина нулевая,
то давайте ее вычерким. Кажется, корни мы просто значение складываем. Ну да, то есть смотрите,
то есть идея такая, то есть вот у вас тут есть левая, тут есть правая. Вот, тогда идея такая,
значит корни мы удаляем, вместо них создаем новый единый корень, в который, просто если тут
написан х, тут написан игрок, то тут пишем по количеству просто х плюс игрок и не паримся. А могли
бы даже не заморачиваться, потому что дальше идея будет неожиданной. Мы просто возьмем вот это,
там допустим, если это альфа-1 и альфа-2, а это бета-1 и бета-2, то значит мы слева от него вешаем
результат объединения альфа-1 и бета-1, причем запускаем рекурсивно именно на этом уровне,
а справа вешаем результат объединения альфа-2 с бета-2. Ну по большому счету это, в общем-то,
объединение более-менее в тупую идею работает. Понятно, почему это работает, непонятно,
вот в этом и мистика. Ну дикартач тоже понятно, почему работал, и тут, в общем-то, пока вроде
очевидно. Ну вот, тут вот действительно проблема. К сожалению, легко увидеть, что это не работает
за логориф, потому что если вы будете объединять циты там 1, 3, 5, 7, 2, 4, 6, 8, ну или более длинные
аналоги, то очевидно, что как бы слияние будет работать за линию, ну и вы ничего с этим не
сделаете. Да, то есть вот как бы вот такие там... А с другой стороны можно как-то попробовать
воспользоваться тем, что из-за количества отрезков зацепиться, типа последовательных. Ну да,
количество вершин, да. На самом деле заметим, что каждое подобное, если вы хотите сделать два
рекурсивных запуска, то вы убили вершину, то есть убили две, создали одну. То есть поэтому,
ну вот, то есть да, то есть EV это, то есть да, как бы не получается реального логорифма, ничего,
у нас есть амортизационный анализ, и мы вводим предельно тупой потенциал.
Вот. Ну, я буду говорить не нулевых вершин, но как я уже сказал, на самом деле это то же
самое количество вершин, если я предполагаю, что нулевую вершину я просто выбрасываю. Вот.
Ну что, действительно, что память засорять, если у нас есть... Вот. Ну то есть можно, конечно,
и не засорять, можно, конечно, куда-нибудь пихнуть и сказать, что гармош-коллектор когда-нибудь
разберется, но как бы, по крайней мере, но тогда вам придется учитывать, что если вершина нулевая
еще не удалили, то как бы... Ну, в общем ладно, не буду сейчас там в особенности, во всякие там
джавайные особенности лазить или что. Так вот. И так просто потенциал количества ненуевых вершин.
Правда, потенциал не совсем корректный, потому что заметим, что в самом-самом-самом начале потенциал
не равен нулю. Вот помните, у нас в партнеризационном анализе требование, что потенциал изначально 0,
и всегда он бывает не нулевой. Да. Да, ну можно сказать, что ладно, у нас еще бывает... Ну хорошо,
ладно. Аккуратность, на самом деле, один из самых таких аккуратных анализов у нас будет таким.
Да, то есть дано число х, создай, пожалуйста, сет из него любимого.
Ну, на самом деле, кстати, если бы мы могли тут... Ну ладно, потом додумаю. То есть этого нам хватает.
Так, ну и теперь давайте думать. Относить до этого потенциала. Сплит. Так, ну сплит работает
за реальный логарифм и, очевидно, больше, чем логарифм ненуливых вершин, он вам не создаст
в принципе, правда? Поэтому получается, что логарифм и честный, и логарифм... То есть,
ну вот, то есть здесь получается все честно, да? И, ну вот, реальный и учетный. Вот. Так что тут,
да, у нас в этом смысле хороший потенциал. Вот. Так, крейт. Ну, крейт получается тоже от логарифм.
И тоже пишем реальный и учетный. Ну, потому что, понятно, создается тупо логарифм вершин.
Я делаю это за логарифм, увеличу это за логарифм. В общем, кайф. А что происходит с юнионом?
А нет, это лог, все правильно. Почему? Ну, да, нет. Вы будете смеяться, но это единица.
А если сеты оба не пустые, то это вообще ноль. Да, учетная стоимость от нуля. Ну, почему бы нет?
Учетная стоимость может быть отрицательной, ничего страшного. Это нормально. Ну, понятно,
что если вы, конечно, если один из этих сетов нулевой, хотя бы, то, конечно, вы от единицы
никуда не денетесь. Но потенциал не поменяется, одно действие вы потратите. Вот. Но если оба сеты
не пустые, то на самом деле вы можете подвернуть слияние так, что фактически оценить количество
действий, которые вы делаете, количеством вот этих вот объединений вершин. А, ну да, то есть мы
тут сделали одно объединение вершины и одну вершину потеряли. Ну, смотрите, да, ну, тут первая,
просто простая мысль. Учетная, то есть можно сделать так, что учетная стоимость вот этой вот операции
ноль. Потому что мы сделали золото единицы и потеряли одну вершину. То есть оплачено, как говорится.
Понимаете, да? Вот. То есть на самом деле получается так не получится оплатить. Ну, понятно, за эту
единицу мы можем оплатить сами вызовы, по крайней мере. И тогда получается, что мы не оплатим
только те рекурсивные вызовы, которые соединяют пустое с непустым. Ну, там какие-то указатели
перекинуть надо, да? Но с другой стороны мы мысленно можем сказать, так, а давайте, прежде чем делать эти
рекурсивные вызовы, просто посмотрим. Если какие-то из них не тривиальные, то мы их просто за оплаченные
от единицы просто быстренько сделаем, например, без рекурсии. Ну, да. Ну, да. Ну, понятно, что в
реализации об это заморачиваться не надо. Это просто наши учетные особенности. То есть особенности
учета. Но просто, как говорим, что потенциальный вариант, что делать, если кто-то из них пустой или
этот, то мы как бы это в эту единицу учтем. Вот. Но тогда после этого получается, что мы скушали все мержи,
которые с пустыми, да? Вот. А все остальные мержи, получается, мы тоже скушали. Потому что каждый
не тривиальный мерч, он у нас там начинается с единицы. Все. То есть в результате получается,
значит, тут получается реально к черти шо, а тот учетно от нуля, если s1 и s2 не пусты, и от единицы иначе.
А это вообще уже технические детали, да. То есть понятно, что если возвращаться к
исходной задаче, то каждый отсортированный отрезок мы просто, то есть каждый сет, то есть просто
храним как сет сам. То есть храним как сет и флажочек, что нам сортируем. Ну вот. Да. Это уже такие
технические. То есть получается задача такая, техническая. Все. То есть знаете, это вот чем мне
это нравится вообще задача, то есть как может показаться, кто-то тут иногда любит говорить,
иногда даже я это бываю, что дерево отрезков вообще не нужно. Потому что ну как бы всякие
AVL дерева умеют все то же самое. Так вот, на самом деле у статики есть, то есть тупой пример,
это на самом деле такая классическая задача. Помните, есть такая задача, почти наверное встречали,
дана перестановка, и вам там нужно делать запросы вида сделай свап, и после каждого свапа скажи
количество инверсий. Вот. То есть на самом деле эта задача уже показательна, потому что я не знаю,
как ее без дерева отрезков решать. Ну классическое решение, потому что дерево отрезков дикартовых
деревьев. Ну понятно, да? Ну или ладно, кто-то любит решать деревом фер, дикартовых деревьев.
Не то чтобы принципиально менять. Ну суть, без изменения сути. Так в смысле? Так у нас же
никаких перебалансировок не происходит, когда мы делаем запрос на отрезки. Ну а свап вы как делаете?
Удалить, ну типа да, удалить сначала элемент, потом вставить. Нет, почему перебалансировок-то не
происходит? В смысле сейчас мы сделаем какой-нибудь условный АВЛ дикартовых деревьев? Ага, то есть в
переводе говоря мы делаем статически такой максимально статический АВЛ с адекватной
асимптотикой. А дерево отрезков не легче было сделать. Это же не дерево отрезков. Ну как бы нет,
да. Ну не знаю, я бы сказал, что дерево в данном случае, если вам нужно, ну просто тогда, если вы
используете АВЛ, то логично, наверное, использовать его инфраструктурно. А если его специально писать
отдельную версию, которая будет искать элементы и свапать их между собой, и еще проходить по
родителям что-то с ними делать, то знаете, легче дерево отрезков написать. И более того,
еще и по, в том числе и по константе, кстати. Я думаю, почти идентично будет. Вот, поэтому да,
это такое. Но вот это еще более продвижение. Вот как тут дикарта, АВЛ и так далее, там, наверное,
лог квадрат, лог куб может дадут. Но если вы пользуетесь сливаемым деревом отрезков,
то они вам дадут логн. Правда, с оговоркой, что мы здесь пользовались тем, что у нас это массив,
это перестановка. И каждый элемент от 0 до n-1 и ровно один раз. Ну да, потому что иначе мы
просто сложились. Так, хотя погодите. А что нам помешает? Хотя теперь давайте думать. А сильно
ли у нас будут проблемы, если у нас элементы будут от 0 до n-1, но будут встречаться несколько раз?
Нет у нас проблем. Да, то есть на самом деле никаких проблем нет. Просто здесь храним не единичку,
а сколько таких элементов. Все, ну мульти-сет. А какие проблемы нам даст, если эти числа не от 0 до n-1?
Логарифом более страшно будет. Да, логарифом будет просто не n, а ну какой-нибудь там. Ну,
в общем, вот этого max-c какого-нибудь. Тут max-c и тут max-c. Да, все. То есть не сильно сложно. Ну,
или там, ну в половине задачи, конечно, какое-нибудь там сжатие координат вам скорее всего будет в помощь.
А если прямо очень просят онлайн? Нет, ну как сказать, ну хорошо, будет вам max. Ну, как сказать,
там, знаете, там иногда начинает, какая-то перестройка начинает решать. Хотя, ну хотя нет. Хотя нет,
если прям совсем жестко онлайн, и вы заранее вообще не знаете туда, придется заморзаться делать. Но
правда, тут можно начать заметить, что это еще ущербная версия. Потому что действительно,
что тут, какие тут еще запросы сюда можно втрикивать? Ну, например, какой-нибудь insert
какой-нибудь можно сюда вставить в середину массива? Да, пожалуйста, посплите ли, вставили,
возрадовались. Так, ну про рейс я молчу. Ну, рейс даже еще может быть тупее, вам нужно просто из сета
удалить элемент и, возможно, удалить сет, если надо. Все. Вот. Так, что у нас еще бывает? Так,
сумма на отрезке. Да, ну да. Так, ладно, что там у нас еще? Сложно, на самом-то деле, нам поверг
этого придется какую-то структуру накостельнуть, потому что у нас может быть много отрезков. Не,
хит-сезона, присваивание до отрезки, во! Не, проблема в том, что если у нас много, сумма на отрезке не
так уж тривиальная, потому что у нас может быть внутри отрезка суммы много вот этих д.о.ш. отдельных,
так что нам придется, видимо... Ну, я думаю, нет, само посетить не страшно, потому что у нас же
исходные эти отрезки в д.о.ш. хранятся, помнится? Поэтому, знаете, мы же можем поддерживать в сете
операцию, значит, там, ну, какой-нибудь, ну ладно, нам даже не наше поддерживаться, как бы, если вы
делаете присваивание, то вам даже не надо отложенных операций, потому что вы просто удаляете несколько
отрезков, там, может быть, посплите, а вместо этого там вставляете один длинный отрезок, в котором
говорите, что... А, нет, если у нас сумма на отрезке, ну вы, ну и здесь, кажется, достаточно легко, потому что
вот в этом вот дереве легко поддерживать сумму на под дереве. Да, конечно, у нас этих деревьев на отрезке
запроса может быть много. Да, но мы же с ними ничего не делаем, поэтому, как бы, то есть, смотрите,
на каждом отрезке вы храните сумму, ну, напоминаю, сами отрезки вы тоже в д.о.ш. храните, а если вы храните
в д.о.ш. отрезки и в каждом отрезке храните сумму моего дерева, так что не проблема. Значит,
присваивание сделали. Так, что там еще есть? Прибавление есть на подотреске. Так, тут уже сложнее,
а тут так на халяву не выкинешь. Но отложенная операция тут тоже вроде вполне себе работает. Как
она работает? Плохо она работает? Нет, почему? А почему плохо-то? Отложенная операция, потому что
у нас есть глобальное дерево, глобальный д.о.ш. и есть д.о.ш. сливаемое, да? Ну, как бы понятно,
что вы сначала, ну, как бы у вас доступ сначала к д.о.ш. а потом через д.о.ш. к д.о.ш. Поэтому вам
никто не мешает в д.о.ш. хранить, значит, эти, значит, прибавления соответственно.
Ну, как мы потом мерчить будем? Две д.о.ш. к которым разные штуки прибавлены. Но дело в том,
что когда... А у нас мерчи-то в основном основано на том, что мы, типа, берем, и у нас структура
деревьев одинаковая. Не, а не понимаете, в чем основаны? Они основаны на том, что, во-первых,
вы находите какое-то два дерева, во-первых, вы находите два отрезка и сплитите, а когда вы до
них дошли, вы как бы, то есть прежде чем их сплитить, они узнали, что к ним, оказывается,
что-то прибавили, да? Да. Вот. Это, во-первых. Да, но у нас же есть вот эти внутренние отрезки,
которые тоже что-то прифабили, которые в итоге надо будет померчить, а мы можем померчить штуки
с разными отложенными операциями, с разным отложенным... Да, но дело в том, что если вы
захотите прям целый ряд померчить, то вы до них как бы по факту можете просто дойти и дотолкать
все операции. То есть сначала все дотолкать, то есть как бы, когда вы дойдете до самого отрезка,
все отложенные операции, которые с ним надо сделать, он узнает. В чем проблема? Да, но вот у нас есть два дерева. И к ним нужно применить... Их нужно смёржить? Нет,
погоди, погоди. Вот в этой вот задаче на самом деле просто так никакие два дерева смёржить не надо.
Я утверждаю так, более того, я утверждаю, что если мы хотим смёржить два дерева, то на самом деле мы в глобальном
дереве до обеих этих вершин тупо дошли. Да, конечно, вот мы смёржили, теперь мы дошли до них. Да. Но и в каждом из них получилась какая-то отложенная операция. Так. И, кстати, совпадающая. Ага. Так, хорошо. На структуры этих дуошек, после типа... Ах ты ж бяка какая. А ведь действительно, да, внутри дерева отрезков оказывается не так просто ко всем элементам прибавить х.
Потому что эта рука, типа, сделает сдвиг какой-то. Так. Ладно. Так. Пришла беда, откуда не ждали. Так. Но это уже весело. А чё, слушайте, хотя тут уже возникает вопрос. Слушайте, тут сделать этот сдвиг там случайно... Хотя нет. Нет, это, к сожалению, больно.
Потому что, да. Потому что, во-первых, да, вот через эту границу придётся в явном виде что-то делать, через вот эту границу. Да, и через каждую, по сути. Да. Так что тут прям неприятность. Да. О казе. Ну ладно, то есть совсем прибавлять не получится. Нет, ну, по крайней мере, на халяву. Ладно.
Понятно, что вот эти вот странные операции с декордачами, которые как будто лог квадрат работает. Ну да. Если мы в них верим, то тут они, конечно, на халяву работают. Это да. Это если мы в них верим. Да, но это есть... Ну, недавно. Ну, насколько недавно? Потому что эта технология, наверное, тоже пару лет назад уже там, на Кутфольсе висит. В чём даже... Технология появилась несколько лет назад, а пруд появился несколько месяцев назад, как будто.
Да. Ну, может быть. Может быть. Окей. Наверное. Наверное. Так. Нет, прибавить... Ну ладно. Нет, тут ладно, хорошо. Если у вас чисто прибавление, то возникает вопрос о насколько она вам портит жизнь вообще.
Просто, допустим, если вам надо делать ток прибавления. Ну, понятно. Присваивание просто убивает деревья. Поэтому давайте представим себе, что вам нужно, значит... Так.
Прибавить и отциртировать типа?
Нет, ну ладно. Лог можно превратить в лог квадрат, потому что, на самом деле, вот эти все ситуации можно... Ну, потому что, конечно, можно превратить в лог квадрат, потому что превратиться это просто в сумму на подотреске, как минимум.
Ну, там. То есть такие вот шифты. Ну, потому что, по большому счёту, когда вы сливаете два сетапа, в каждый момент времени нужно просто сдать чиселку тут и чиселку тут. Правда?
Это вообще пустые они или не пустые? Вот. А как делать вообще проверять? Ну, как это проверять? Ну, на самом деле, достаточно там. Вот. Ну, как же это сделать?
Ну, на самом деле... Так. Нет, ну, на самом деле, обычно это... Слушайте, по-моему, тут... Я, конечно, не знаю, но у меня что-то возникает такое странное подозрение.
Вот у вас есть две такие структуры, условно. Только одна из них не сдвинутая, а другая сдвинутая. Вот. Ну, допустим, мы там глобально... То есть мы ничего в дереве не делаем, просто глобально храним, насколько реально там надо сдвинуть.
Допустим такое. Вот. И после этого мы говорим, что когда мы сливаем деревья, то есть там условно, когда мы сливаем деревья, то есть мысль просто возникает такая, что, допустим, мы говорим, что все числа, которые тут хранятся, они на самом деле типа на 7 меньше.
И когда вы тут делаете вот это вот слияние, вам вот в этом отрезке нужно узнать, сколько чисел второго сета на самом деле лежат на этом отрезке. Да? Так.
А как организация не развалится после таких приколов? Нет. Ну, мне просто почему-то очень хочется доказать, что это едва ли не за 1 делается, если вы там правильные штуки храните. Потому что, например, вот идея такая.
Потому что, во-первых, просто если вы этот отрезок сдвинете, да? А, хотя нет, не получится. Если вы отрезок... Просто смотрите, вот у вас есть отрезок хороший, и насколько я его не сдвину, он как бы сдвинется либо в другой такой отрезок, либо вот на такие 2 соседа, да?
Ну, логично, да? Вот. То есть вот на соответствующем уровне он просто сдвинется либо вот на таких 2 соседа. А теперь идея такая. А давайте для каждого отрезка, например, пытаться тупо хранить минимальное число, которое тут есть, и максимальное число, которое тут есть, это вроде легко поддерживается, да?
Поддерживается? Ну да, если нам надо сдвинуть чуть дальше, чем... Вот. Но да, правда, если нам нужно сдвинуть чуть дальше, чем на соседа, то, конечно, нам становится больно. Вот.
То есть как-то на халяву это не держится? Ну да. Нет, ну да, просто как бы да. Если бы мы могли за быстро найти, куда тут сдвинулось, то мы нашли максимум тут, минимум тут, и легко все посчитали. Или поняли, что там пусто, поэтому до свидания.
Вот. Ну да, нет, ну не знаю, в полной очереди, что дальше можно пытаться накручивать на тему того, что давайте, когда мы движемся по отрезочку, мы для каждого отрезочка храним, где он там реально находится.
Или отсекаем от этого отрезочка те моменты, которые реально пустые, например. Ну там что-нибудь такое издевательство, а что не пустое мы там реально храним, где он.
А, ну, кстати, для каждого отрезка можно реально хранить, типа, отрезок, который должен был быть по координатам, а вот какой он с учетом сдвига? Мы же можем это в явном виде хранить?
Ну вроде. Чего? Ну просто говорим, что вот мы, ну то есть как бы, если бы это было нормальное слияние, то мы бы сливали вот такой отрезок с его аналогом там, да?
Но в реальности мы не сливаем не этот отрезок, а этот отрезок где-то сдвинутый, поэтому давайте во втором сете его в явном виде хранить.
На самом деле, как будто, можно достаточно бесплатно вот эти сдвиги поддержать, если хранить там типа, ну что-то типа, обыкновенный дикарточа, который просто кусок переложить нужный в соседние отрезки.
Ой, так опять сливание, опять сливаемые сеты, которые опять вылетают, потому что у нас сплиты.
Нет, ну просто допустим вы вот для этого, вы работаете с этим отрезком и вы знаете, куда его нужно сдвинуть, да?
Его нужно типа на половину дерева, условно говоря.
Да, но допустим вы знаете, куда, ну изначально-то вот в этом-то отрезке вы знаете, куда его нужно сдвигать, правда?
Мы знаем, где он должен быть постоянно.
Ну типа да, допустим вы теперь знаете, куда нужно сдвигать вот этот, но тогда есть ощущение, что за вот единицы вы тогда, если посплитите этот отрезок на два, то вы для этих двух отрезков знаете, куда их нужно поспличивать вот на этом уровне.
Да, но это какое-то очень странное взаимодействие между...
Под деревьями непонятно, что к чему.
Ну да, нет, ну почему, ну нормально.
Ну вот да, очень надо четко формулировать, но с льота прям как-то позитивно докручивается, я не знаю.
Ладно, ну я не уверен, что имеет смысл прям сейчас, конечно, прям жестко это докапывать, но мне полное ощущение, что прибавление можно.
Хотя да, неожиданно прибавление, потому что next permutation как-то на подотрезке делается тут сильно проще.
Не верите?
Да, ну потому что, во-первых, да, вы просто сплитите нужный отрезок, во-первых, а во-вторых, ищите максимальный убывающий префикс.
Потому что идете-идете и естественно оплачиваете это то, что вы идете-идете слиянием.
В чем, кстати, удобное слияние, потому что вы сливаете деревья по факту по явному ключу.
Ну в какой-то момент вы наконец-то находите первый элемент, который меньше предыдущего.
Ну вот, ну и дальше вы там катоэлемент тоже по явному ключу в дереве спускаетесь, свапаете, разворачиваете, радуете.
Кошмар, next permutation сделать легче, чем прибавление на отрезки.
Как?
А вот так вот, да.
Ой, красота.
Хотя, да, сколько операций надо добавить, чтобы легче это уже делать было какой-нибудь корнячкой.
Хотя, ладно, корнячки все равно все это придется делать, так что без вариантов.
Окей, что-то так, что там еще с массивом можно делать?
Ой, да, сорт на подотрески.
Так что вот, ладно, нет, красота, да, пожалуй, ладно, это хорошо, что действительно это вставилось.
Так, ну ладно, тогда можно, наверное, сказать, что на сегодня, наверное, у нас тогда все.
Да, слушайте, позитивненько закончили, конечно.
