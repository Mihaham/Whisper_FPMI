Давайте начнём.
Так, значит, главный сегодня такой.
Мы сначала завершим доказательство теории с прошлого раза.
Значит, про то, что для задачи унеизморфизма графов есть
интерактивный протокол с общими случайными видами.
Вот, а потом начнём оказывать, что теперь оно по space.
Так, значит, давайте я напомню.
Мы доказываем теорему,
то, значит, задача GNI
лежит в АМ.
То есть есть протокол с общими случайными битами.
Ну и построено доказательство было вот на кое идея.
Да, значит, чтобы мы рассматривали некоторые множества.
Так, давайте во-первых.
Значит, я напомню, что у нас GNI означает, что у нас есть два графа G0, G1.
Значит, таких, что G0 неизморфно G1.
Вот, ну и можно считать, что вершины одинаковое количество.
То есть число вершин уже 0 равно числу вершин G1 и равно n.
Вот, потому что иначе задача тривиальная.
Значит, если разное число вершин, то тогда точно они неизморфные.
И, соответственно, точно можно сказать, да.
А вот только если одинаковые, тогда там можно о чем-то рассуждать.
Вот, конечно, значит, вообще задача обыкновенной архитектуры графов,
она такая на непонятной сложности.
Потому что вообще кажется, что там, как мы будем ее решать,
ну, посчитаем к ней много характеристик.
Если разное число вершин, то неизморфно.
Если разное число ребер, то тоже неизморфно.
Посчитаем распределение степеней, там какие-нибудь структуры под графия,
там еще что-нибудь, минор какие-нибудь.
Но, кажется, вот так вот мы какие-нибудь такие характеристики найдем.
Так что если они все одинаковые, то графа изоморфная.
Но, тем не менее, так не получается.
Чем больше размер графа, тем больше нужно характеристик считать.
Но вот, тем не менее, есть алгоритм Бабайи,
который работает за квазиполеном, то есть за и на степени поленом от логарифма.
И там даже поленом небольшой типа логарифма в кубе.
Или там, может, два степена логарифма в кубе,
в общем-то надо посмотреть, что там заявляется.
Но, тем не менее, поленомиальный алгоритм так и неизвестно.
Хорошо.
Дальше мы рассматривали, мы обсуждали про группу автоморфизмов
и говорили, что нужно рассмотреть такое множество.
Значит множество С.
Значит множество пар из графа и перестановки.
Значит так, что H изоморфно же ноль,
или H изоморфно же один.
Вот, и при этом альфа это автоморфизм H.
Вот, и мы тогда обсудили следующее.
Значит, обсудили, что если они неизоморфные,
значит, если же ноль действительно неизоморфно же один,
то тогда размер этого S это двоим материал.
А если они изоморфные,
то тогда размер S это неизоморфная.
А если они изоморфные,
то тогда размер S это n-факториал.
Вот, при этом принадлежность к С можно удостоверять
сертификатом, как в NP.
Соответственно, стоит вопрос, размер этого множества будет большой или маленький.
Дальше первая идея была от метод Монте-Карло.
То есть просто будем брать случайный объект,
и смотреть, лежит он в С или нет.
В любом случае это S очень маленькая.
И, соответственно, скорее всего мы с ноль туда попадем.
Поэтому следующая идея — это использовать хэш-функции,
которая уменьшает все объявляющее множество,
но не сильно уменьшает вот это множество,
так что доля становится значительной.
Последнее, что мы в прошлый раз успели,
сделать систему хэш-функций нужных.
Так, и это у нас было довольно быстро,
так что давайте я вкратце напомню.
Так, значит, мы строим семейство
семейства папарно-независимых
семейства папарно-независимых хэш-функций.
Значит, там было такое h, n, k.
Значит, это семейство функций
из слов длины n двоичных в слова длины k.
Значит, как правило, k меньше n,
и у нас в приложении будет k меньше n,
но определять это можно для k равного n,
или даже для k больше n.
Вот, совместное определение три свойства,
ну или четыре, там смотря как определять.
Значит, первые два – это малый размер
и эффективная учислимость.
Значит, малый размер означает, что
в этом семействе будет два в степени
полинома от n, k функций.
То есть, просто экспонента.
Вот, и в данном случае экспонента – это маленькое число,
потому что общее число функции – двойное экспонента.
Вот, и экспоненциальный размер нам дает
полиномиальную длину описания.
То есть, как бы у каждой функции
есть индекс описания вот такой длины.
Так, значит, второе.
Второе свойство – это эффективная учислимость.
Эффективная учислимость означает следующее.
Что просто есть алгоритм, который получает описание функции
и вход.
То есть, по описанию h и входу x
можно посчитать h от x
за полиномиальное время.
Значит, за время
полинома от n, k.
Вот, и третье свойство, которое, собственно,
делает их по паре независимые.
Так, ну да, там был два варианта.
В прошлый раз давайте я один напишу.
Что если…
Который я… Который мы не будем доказывать.
Значит, если x не равно x-трих,
значит, а y…
Ну, сейчас, значит, эти вот x не равно x-трих, они длины n.
Вот, а y, y-трих, а длины k
уже может быть и равные, в принципе.
Вот, то тогда получается следующее.
Значит, тогда вероятность
для случайных функций h, значит,
того, что одновременно h от x
равно y и h от x-трих
равняется y-трих.
Так, значит, эта вероятность будет
1 делить на 2 в степени 2х.
Вот, ну и тогда, значит,
из этого можно вывести, что
для каждого отдельного x и случайный h
значение распределено равномерно,
и распределение для разных x и h-трих
будет независимое.
Поэтому мы только разудим по парам независимые хэш-функции.
Так, ну и последнее, что было в прошлый раз,
это конструкция.
Значит, конструкция была такая,
что мы рассматриваем поле
из 2 в степени аналиментов.
Значит, f с индексом 2 в n.
Значит, это вот поле
из 2 в степени аналиментов.
Дальше есть, конечно, вопрос,
откуда такое поле брать.
Ну, есть стандартная конструкция
через неправдивый многочлен.
И тогда в этом поле
элементы это просто строки из 0 единиц
на длины k.
И, соответственно, складываем их мы
просто по-координатно.
Сложение это по-координатной ксор.
А умножение,
это умножение по модуле
неправдивого многочлена,
то есть вот эти строки интерпретируются как
коэффициенты при степенях,
от 0 до n-1.
И, соответственно, мы умножаем
многочлены как обычно,
но потом то, что получилось, делим с остатком
на неправдивый многочлен,
который в поле задается.
И что-то получаем.
Ну, значит, там есть теоремы,
что это на самом деле только одно поле,
и какой бы вы неправдивый многочлен не взяли,
там все получится
изоможно друг к другу.
И, соответственно,
если вы хотите,
чтобы у вас был
единый алгоритм,
чтобы это не для фиксированного n,
а для любого n происходило,
то получается, что вам нужно
по n каким-то образом находить
неправдивый многочлен.
Ну и вот на этот счет
нет простого, детерминированного алгоритма.
Значит, вообще алгоритмы есть,
но довольно сложные
со всякой хитрой алгеброй.
Ну, относительно
простой метод вероятностный.
Ну, я тоже не буду доказывать.
Не знаю, это в теории коллекции
по линии доказывали,
но там теорема такая,
если брать случайный многочлен,
то есть...
Ну, там есть теорема о количестве
неправдивых многочленов,
что оно, типа, от 1 и 2 n,
до 1 и n, и там что-то такое.
Не доказывали такое, да?
Ну, вот.
Соответственно, что получается?
Допустим, вы в это поверили,
и вторая вещь, что есть
это алгоритм поверки неправдимости.
Вот, этот тоже не было.
Ну ладно, в общем, там...
Давайте тоже поверим.
Вот, там алгоритм кантера
и кого-то еще,
но это не тот кантер, который Георг
придумал в теории множества,
а более современный кантер, который,
не знаю, может, и жив еще.
Там 81-го года алгоритм.
Заксен Хаус, что ли,
что-то такого бы их фамилия.
Вот, и есть еще, в общем, ряд
алгоритмов в проверке.
Вот. И тогда получается,
что если мы в эти две вещи поверили,
то тогда получается,
что можно
брать случайный многочлен
и этим алгоритмом
проверять его неправдимость.
И поскольку их довольно много,
порядка 1n,
то за порядка n экспериментов
мы в среднем найдем неправдимый многочлен
и после этого уже будем вычислять.
Вот.
Но вот это вот то, что я сказал,
это там во всяких книжках по вычислительной алгебре
написано.
Да, в общем, это
в таких специализированных
учебниках есть.
А вот детерминированные алгоритмы я тоже поискал.
Оказалось, что их тоже
там есть несколько, но
они как только в оригинальных статьях есть,
больше нигде не описаны.
Так что, видимо, они не очень простые.
Да, я, конечно, в деталях
не разобрался пока.
Ну, не знаю, может, попробую разобраться.
Вряд ли там что-то элементарное,
что можно понять без глубокого погружения
в алгебру.
Так, хорошо.
Ну ладно, в общем,
теперь давайте мы в это поверим,
что такое поле есть, и можно в нем все вычислять.
Вот, и тогда
мы будем считать,
что k равно n.
Значит, конструкция
для k равна vn
заключается в следующем.
Значит, что
в функции сдается пара и просто элементов
этого поля.
H, AB.
Значит, задается
пара элементов.
Пара элементов A и B.
Вот, как это, соответственно,
они оба из поля.
Отсюда получается малый размер.
То есть 2n получается,
длина индекса одной функции.
И следующая формула
дает нам эффективную
учислимость.
H, AB, A, T, X.
Это будет просто A плюс BX.
Значит, где умножение
на B и прибавление A,
это операция из поля.
Ну, и тогда вот
последняя выкладка в прошлый раз,
которая довольно быстро была.
Сейчас еще повторим,
что если у меня получается
одновременно Y
равно A плюс BX,
а Y штрих
равняется A плюс BX штрих.
Вот если мы эту систему
начнем решать,
то мы получим...
Например, что мы вычтем
одно из другого,
когда сократится.
Y минус Y штрих равняется B
на X минус X штрих.
Ну, и второе равнение можно оставить.
Ну, можно второе, можно первое.
Давайте первое,
потому что у него
символов меньше.
Значит, Y это A плюс BX.
Ну, а после этого, поскольку это поле,
а X не равно X штрих,
поэтому X минус X штрих это не ноль,
и поэтому у него можно поделить.
Получаем, что B
будет равняться
Y минус Y штрих
делить на X минус X штрих.
Вот, а после этого
Y... Ой, не Y, а...
А теперь можно вычислить как Y
минус
вот это вот B
Y минус Y штрих
делить на X минус X штрих
и умноженное на X.
Вот.
Значит, что же получается?
Получается, что вот этот набор,
значит, набор
вот этих
X х штрих, Y х штрих
нам дает ровно одну пару A и B.
То есть, что получается?
Получается, что ровно одна пара
из 2 в степени 2n подходит.
Ну, вот если мы посмотрим
на третье условие,
то это ровно то, что нам нужно.
Значит, нам нужно, чтобы вероятность
была 1 делить на 2 в степени 2k,
а k равно n, поэтому 2 в степени 2k
то же самое, что 2 в степени 2n.
Ну и вероятность как раз
по классическому определению,
значит, одна подходящая
делить на 2 в степени 2n
его как раз будет то,
что нам нужно.
Вот, в общем, второе
второй свойств получается.
Вот, если k меньше n,
то что можно делать?
Ну, во-первых, можно взять просто префикс.
Значит, если k меньше n,
то можно просто взять префикс
на там h.
А b от x это будет
значит, a плюс bx.
И мы возьмем как бы первые
каобитов.
Вот, тогда что
получится?
Ну, первые, вторые свойства
понятно, никуда не денутся.
Вот, ну а третье
получится, что мы просто просунули
каобитов.
А третье получится, что мы просто просуммируем
как раз нужное количество,
на что
для одного и того же значения
вот этого a плюс bx
обрезанного
будет там 2 в степени n-ка
значений
соответственно
полного
2 в степени n-ка
вариантов продления.
Вот этого значения до
элемента поля.
Вот, ну и тогда
у нас получается 2 в степени
n-ка для y,
2 в степени n-ка для y штрих,
например,
примерно так получается, что теперь
2n-ка умножить на 2n-ка
мы делим на 2
в степени 2n,
и это получается в точности 1 делить на
2 в степени 2k.
То есть то же самое классическое определение
то же для невероятности применяем,
считаем число последующих вариантов,
делить на общий число вариантов и получаем то, что
требуется как раз в третьем
пункте.
Так, ничего, понятно.
Вот, ну на самом деле
есть еще чуть-чуть более эффективный
способ, потому что здесь получается
2n длина описания,
значит, можно это уменьшить
до n плюс k.
Значит,
другой вариант
такой, что мы
сначала
умножаем b на x,
потом
берем
первые k,
вот, и потом только прибавляем
так, давайте
я тут уже кторну напишу, потому что
это уже не в поле операция,
а с вырезанными значениями,
и тогда вот b должно быть из поля,
а а может быть только длины k.
Вот.
Ну и соответственно тут
правда немножко сложнее рассуждение
будет, да, почему это работает.
Вот.
Ну, в принципе,
да, вообще более-менее понятно,
почему, поскольку у нас
положение здесь
это тоже XOR, да,
то можно наоборот, вместо того, чтобы сначала
вкладывать, а потом брать префикс,
можно просто сначала и там, и там взять
префикс, а потом сложить.
Вот, но если мы взяли префикс,
то тогда лишние биты нам вообще
не нужны, и можно их и не хранить.
Вот.
Так, ну ничего, понятно.
Вот, в принципе, можно построить даже
для случая k больше n,
да, тогда можно там
дополнить нулями, а дальше взять ту же самую конструкцию.
Такое.
Ну ладно, в общем,
бывают и другие конструкции, значит,
я
наверное постараюсь
через там пару недель сделать первую домашку,
да, и там будет задача
про альтернативную конструкцию,
на которой не на
не на арифметике
поле основано, да,
на матричной арифметике.
Вот.
Так, хорошо.
Ну ладно, я надеюсь, что мы теперь с hash функциями
разобрались.
Вот, и теперь
я покажу, как их применять.
Ну, в принципе,
нужно реализовать ту же самую идею,
на что мы
hash'ируем наше значение
с уменьшением длины.
Да, значит, мы hash'ируем
наше значение,
вот, и хотим, чтобы
большое множество
не сильно уменьшилось,
то есть маленькое множество
в любом случае
не может увеличиться,
потому что это однозначная функция,
тут никакого раздваивания значений нету,
значит, поэтому увеличиться множество не может.
Вот.
Ну вот, у нас было
здесь изначально различие там в два раза,
соответственно,
мы хотим, например, чтобы
после hash'ирования, скажем, в полтора раза осталось
различие, и после этого
уже можно метамонты карлу применять.
Так.
Ну ладно, значит.
Так, значит, тут сейчас,
тут мне очень хорошо,
что у меня сейчас буква N будет в двух значениях.
Надо
с этим что-нибудь сделать.
Ну какую-нибудь из нее
переименуем. Давайте вот то,
то N, которое в hash функции, будет M,
а N будет числом вершин графа.
Так.
Вот N
и это число вершин графа.
Так, значит, теперь у нас,
давайте я
напомню наше определение.
Тут hash и альфа,
значит, такое, что hash
изомашено же ноль
или
hash изомашено же один,
то есть
hash изомашено же ноль,
а hash изомашено же один,
то есть hash изомашено же ноль.
hash изомашено же один,
значит, альфа автоматизм.
Так, значит, тогда типичный элемент,
сколько вообще битов требует
для описания.
Но этот у нас граф на N вершинах,
ну, например, с моего матрицы смежности
задаем,
ну, будет там
N в квадрате,
если экономить, будет там N, наверное,
за ним пополам.
Учитывая, что он обязательно...
Ну, в общем,
примерно,
примерно N в квадрате.
Да, это пополам,
нам совершенно не важно.
Это hash, а альфа,
это перестановка из СН.
Но их всего инфокатериал,
что там N
делить на E в N степени,
ну, в общем, тоже это
число битов.
А тут будет
примерно N log N.
Значит, N log N
будет
при
простом кодировании, да, что мы просто
подряд прям пишем, кто куда
переходит.
Прямо через запятую,
значит, каждый
образ занимает граф логарифма N битов
и всего N, поэтому N log N получается.
Вот.
Ну, и даже что это в квадрате,
это главное слагаемое, да, их же сложить нужно.
Вот. Соответственно,
вот теперь M
будет, значит, M это число
число битов
для описания
hash и альфа.
Значит, и M будет
то большое, вот N в квадрате.
Так.
И вот это вот M
будет тем,
что вот там вот N
то есть
вот эти все
пары мы будем подавать
на вход hash функции.
Так.
Значит, теперь K нужно откуда-то взять.
K нужно взять
не слишком, если K
взять не слишком,
то хеширование
как бы не сработает.
В том смысле, что все равно
это нож останется маленьким, да,
именно, но на каждом нельзя будет применить.
Если K взять слишком маленьким,
то может потеряться вот этот
разрыв в два раза.
Вот. Поэтому K нужно
взять прямо
в точности.
Вот. Ну, например,
можно делать так. Значит, сначала мы
да, значит, мы возьмем K
равное 2,
K большой равно 2 в степени K
малое,
с таким свойством.
Значит, так, что
ну, например,
2 в степени K минус 3,
то есть 1 восьмая K
большого, будет меньше
либо равно, чем N факториал,
а это будет, например,
там строго меньше,
чем 2 в степени
K минус 2.
Вот такой нераз, это однозначно определит
K малое.
Вот. Почему именно так?
Почему именно минус 3 и минус 2?
Ну, тут идея такая, значит, чтоб там потом
оценки сработали,
нужно, чтобы размер S
точно был меньше, чем половина
от K большого.
Вот. А размер S может быть N факториал
или 2 инфекториал.
Соответственно, когда мы сюда 2 еще припишем,
будет 1 вторая от K большого.
И вот это нужно, чтоб там потом
не равенство работало.
Вот.
Ну, а нижняя оценка
не так важна.
Значит, тут можно было бы K минус 10 написать
с тем же успехом. Да, просто
что-то конкретное надо написать. Напишем вот так вот.
Да, хорошо.
Значит, теперь
рассмотрим
семейство hash функций.
Значит, рассмотрим семейство hash функций.
Это наши hash красивые с параметрами
M и K.
Вон мы только что доказали, что оно есть.
Вот так.
И значит, теперь
будем доказывать,
то образ
вот этого S
что если
такая лемма
что если
если
размер S
так, точно условие сейчас
ну уж, по крайней мере, если он меньше
меньше, чем вот K пополам
K большой пополам, да, то есть 20K минус 1.
Вот, то тогда
размер hash от S
Так, тут, конечно, еще вопрос для какой hash.
Ну, для случайной, на самом деле.
Да, значит, сейчас.
Но сейчас из выкладок будет понятно,
правильно я написал или нет.
Но вроде так должно быть, что
мат ожидания по случайной hash
размер hash от S.
Значит, это будет
но это точно будет
меньше либо равно
когда я тебя тут напишу
значит, меньше либо равно
размера S.
Вот эта часть очевидная.
Эта часть очевидная, потому что
эта функция однозначна, когда она только склеивать может
разные элементы,
поэтому увеличиться образ не может.
Вот.
Ну а также, значит, что не очевидно
это будет больше или меньше, чем 3 четверти.
Значит, чем 3 четверти размеры.
Вот. И вот это второе неразбократно будем доказывать.
Ну.
Значит, в принципе
это ключевая лемма
для открытой теоремы,
потому что дальше происходит следующее.
То у нас может быть
вот эта S большая,
2 n factorial.
Тогда, соответственно,
после фиширования
оно будет не больше,
чем 3 четверти, а 2,
то есть чем 1,5 n factorial.
А если оно было маленькое,
наоборот, не больше,
чем n factorial,
то оно и останется не больше,
чем n factorial.
И получится этот разрыв между n factorial
и 1,5 n factorial.
И при этом этот разрыв
уже будет вот такой вот,
какая-то константа
от, соответственно,
его объема еще множества.
Вот.
И после этого уже можно запускать
момент Монте-Карло,
и забрать достаточное число случайных
достаточное число случайных
объектов вот отсюда.
Ну, значит,
нет, не отсюда, а из х значений.
И спрашивать у плувера,
есть ли вот в этом множестве
пара, которая
ну, во-первых,
в этом множестве,
во-вторых, дает такое х значение.
И тогда, значит,
в одном случае будет средняя
порядка
там вот n factorial
делить на k большое,
а в другом порядка
1,5 n factorial делить на k большое.
И это уже будет не порядка нуля,
то и другое, а вот типа там
ну, что-то между там 1 и 8
или 1 и 2,
какие-то два числа, которые различаются
в полтора раза.
И там уже можно
конечное число раз повторить,
чтобы, с большой вероятностью,
приблизить к настоящему значению.
Так, ну чего, пример понятного?
Да, дайте Лему доказывать,
потом я, может, что-нибудь подробнее напишу.
Так, значит, я думаю, давайте так,
я вот это все докажу,
потом сделаем перерыв,
потом начнем провайпировано про спейс.
Спасибо за внимание!
Так, ладно, конечно, давайте доказывать
Так, ну, смотрите,
Значит, вообще тут удобно говорить не в терминах мат ожидания, а в терминах вероятности.
Что вообще вероянство это же мат ожидания индикатора.
Поэтому можно от одной терминологии к другой переходить.
Так, хорошо, значит тогда мы будем смотреть на вот что.
Значит вообще пусть у меня даже функция h будет пока фиксирована.
А потом посмотрим, вроде даже будет больше верно, не только мат ожидания будет таким, но и для каждой отдельной h, если уж она из этого семейства.
Нет, так наверно нельзя. Нет, не надо аж фиксировать.
Значит, мы вот что будем смотреть.
Нужно смотреть на вероятность по случайной h и случайному y.
Значит того, что y попала в h от s.
Значит, что это значит? Это означает, просто по определению, что y попала в h от s.
И это означает, что существует x из s.
Значит такое, что y равняется h от y.
Ну что такое существует? Ну это объединение.
То есть можно сказать, что это вероятность объединения.
Вероятность объединения по всем x из s.
Да, как бы события.
Ну можно писать там событие ex.
Значит, где ex это, ну exy, наверно.
Значит, полностью писать h y, да, exy.
Значит, exy это событие как раз, что h от x равняется y.
Так, что мы знаем про вероятность объединения?
Ну мы знаем вообще форму включения исключений, да.
Что вероятность объединения это сумма вероятностей, минус суммы попарных пересечений, плюс сумма потрочных пересечений и так далее.
Но кроме этой полной формулы можно ее в каком-то месте закончить.
И тогда будет в ту или иную сторону неравенство.
Значит, если просто будет сумма вероятностей, это будет меньше либо равно.
А вот если, соответственно, еще вычесть попарных пересечений, то это будет больше либо равно.
Вот этим мы и воспользуемся.
Значит, это будет больше либо равно, чем сумма.
Сумма по всем x и z, вероятности exy.
Так, ну, обсуждайте, я и x буду писать.
Поменьше индексов.
Значит, это сумма вероятностей ex, минус сумма по x неравном x'.
Значит, а тут будет вероятность ex пересечения exx'.
Вот это вот первые два слагаемых формы включений и исключений.
И именно в такую сторону.
Значит, именно в такую сторону это нужно писать неравенство.
Так, хорошо.
Теперь же такой вероятность ex.
Ну, смотрите, пусть у нас вообще y фиксирован.
Сейчас пусть y фиксировано аж случайно.
Что такое вероятность?
И x тоже фиксирован.
Ну, тогда получается, что это вероятность того, что мы взяли случайную функцию,
и она на x нам дала значение y.
Ну, вероятность этого это как раз 1,9 на 2 вкатый.
Вот.
Теперь мы...
Да, и это для каждого y.
Значит, для случайного тоже.
Давайте я отдельно напишу.
Значит, для любых x и y вероятность по h, вот этого там, где ex,
значит, это 1 делить на 2 вкатый.
Но из этого следует, что и для любого x, значит, вероятность по h, y, ex, это тоже 1 делить на 2 вкатый.
Значит, мы все одинаковые значения усредняем, получаем то же самое значение.
Вот, значит...
Ну, что дальше?
Значит, дальше...
Нужно это теперь сюда подставить.
Мы это теперь суммируем по всем x и z.
Суммируем вот эти вот константы по всем x и z.
То есть теперь так.
Получаем, продолжаем вот эту вот выкладку.
Первая часть у нас, исходя из этого, получается s делить на 2 вкатый.
Так, ничего, согласна?
Теперь еще для пересечения нужна такую же выкладку сделать.
Так, давайте я вот здесь вот сделаю, а потом там напишу результат.
Значит, вероятность ex и ex'.
Значит, это что означает?
Это означает, что у меня одновременно h от x равно y
и h от x' тоже равно y.
Вот, но тут как раз используется попарнезависимость.
Соответственно, такая штука должна быть 1 делить на 2 в степени 2к.
Так, ну чего, согласна?
x и штрих неупорядоченная пара.
Ну, в общем, я не знаю, что делать.
Но, конечно, я не знаю, что делать.
Я не знаю, что делать.
Я не знаю, что делать.
Я не знаю, что делать.
Сопорядочная пара, да.
Ну, потому что...
Не, ну, сопорядочная это будет...
Только более сильно неравенственно, но она мне даст, что нам нужно.
Так что x и x' это неупорядоченная пара.
И тогда, значит, сколько у нас сегодня упорядоченных пар?
Ну, смотрите, это x.
x не равно x', но они при этом OBSS.
Написано, да, значит, они OBSS.
Поэтому тут будет, соответственно, s на f-1 пополам.
И еще умножить на 1 делить на 2 в степени 2к.
Так, но вот это вот minus 1 очень мешается, на самом деле.
Но оно минус на минус даст плюс.
И вот эту добавку можно просто вычеркнуть.
Это нам даст неравенственно нужную сторону.
Это будет строго больше.
И вот так вот.
Размер s делить на 2 в степени k минус 1 вторая.
А тут будет размер s на 2 в степени k квадратим.
Вот это уже очень простая функция.
И тут мы как раз используем, да, что вот размер, значит, размер s на 2 в степени k.
И это у нас какое-то число p, которое меньше 1 второй.
И это вот для этого мы такое k брали, да, вот здесь вот.
Вот это неравенственно теперь используется.
Потому что может быть два раза больше, чтобы как раз k минус 1.
И вот это 1 вторая.
Ну а в таком случае, значит, если p меньше 1 второй,
то тогда простое упражнение на анализ параболы,
значит, что p минус p в квадрате пополам будет больше,
если меньше, то тут строго больше, чем 3 четверти p.
Ну, действительно, в нуле будет равенство, значит, в 1 второй тоже будет равенство.
А между ними там парабол в нужную сторону выгнута, и поэтому будет больше.
Вот.
Поэтому получается, что теперь вот сюда вот, значит, это можно написать больше, чем 3 четверти,
чем вот это s делить на 2 в степени k.
Вот.
Но это вот вероятность, да, теперь если на, значит, если на размер объема еще много что умножить,
вот это 2 степени k, то как раз получим то самое неравенство, которое нам нужно.
Вот.
Даже строго получился неравенство, значит, если там строго меньше.
Вот.
Так.
Ну что, согласны?
Ну вот.
Ну теперь получается, что s может быть либо 2n факториал,
значит, 2n факториал, тогда получится, что, то есть размер s,
может быть, 2n факториал, тогда размер h от s будет больше,
чем полтора, да, 3 вторых н факториал.
Вот.
Либо оно n факториал, значит, тогда размер h от s будет меньше, вот здесь меньше либо равно, чем n факториал.
Вот.
Ну и тогда уже идея Монта-Карла.
Следующая, значит, идея.
Ну да, это в принципе правда, да, то есть там нужно...
Но тут, значит, смотрите, тут возможно...
Тут это вам можно сказать...
В общем, из этого можно выкрутить разными способами.
Можно делать более точные оценки там с неравенствами Маркова там или кого-то,
насколько много таких h, которые дают нужное неравенство.
Вот.
А можно сказать, что раз мотожидания больше, то значит, хотя бы одна h такая есть,
и такая же неравенство есть.
Вот.
А можно сказать, что раз мотожидания больше, то значит, хотя бы одна h такая есть,
и тогда эту h пришлет прувер.
Да, значит, просто сам Мерлин пришлет хорошую функцию h,
а Артур потом будет ее использовать.
Это там даст лишний раунд, но мы уже в прошлый раз обсуждали там...
Мы, правда, не доказали, но, я думаю, сейчас и не будем доказывать,
что число раундов можно снизить.
Вообще, это, конечно, правильный вопрос, чтобы в среднем доказали, да,
или конкретно h будет верно.
Но вот можно двумя способами из этого выйти.
Ну да, в общем, идея...
А давайте я прямо так и напишу.
Значит, Мерлин присылает h.
Вот.
И потом, значит, много раз...
Но потом параллельно нужно.
Значит, Артур делает следующее.
Значит, выбирает там какое-то количество случайной пары...
Не, сейчас неправильно я пишу, не случайной пары.
Но случайных есть значение.
Вот.
А потом Мерлин...
Значит, Мерлин присылает уже пары.
Значит, пары h, альфа, да, значит, и z...
С такими...
Значениями, значит, с такими h.
Вот, Артур все это проверяет.
Ну, как бы и плюс сертификаты, да, то есть,
Мерлин присылает пары и плюс сертификаты к ним.
Да, что эти пары действительно и z.
Вот, Артур это все проверяет.
Так.
Сейчас я тут не умещаюсь.
А после этого Артур проверяет
и сравнивает...
Сравнивает число подходящих.
Ну, тут получится, значит, между 1 и 3 вторых.
Там средние 5 четвертых.
Да, тут будет 5 четвертых n факториал
делить на вот это два степеника.
Вот.
Значит, если больше, то он говорит, что ас большое,
а если меньше, то что ас маленькое.
Ну и тогда реальное среднее
будет либо сильно больше этой границы,
либо сильно меньше.
Поэтому из достаточного раз повторить,
то и выбрученный средний будет, скорее всего,
с правильной стороны этой границы.
Ну да, в таком варианте это МАМ,
но еще там есть рем, что МАМ и то же самое, что АМ.
Я говорю, да, значит, можно так выкрутиться,
можно немножко по пристальнее,
более аккуратно неравенственно написать,
даже со случайной аж, скорее всего, тут правильно будет.
Ну, тогда можно смотреть не только на среднее число,
но и на то, как распределено размер аш-атес
в другую сторону.
Вот.
Ну, в принципе, это дальше можно...
Вот этот подход дальше обобщается.
Да, значит, и в целом...
В целом, там есть такая рема,
что IP
к раундами
вложена в АМ
ка плюс двумя раундами.
Отсюда получается...
Какие выводы?
Получается, что если IP из константы раундов,
то это то же самое, что АМ из константы раундов.
А АМ из константы раундов это просто АМ,
потому что там можно сократить число раундов.
И, соответственно, это будет лежать
на втором уровне полинамиальной иерархии.
Но, например, для полинаминального числа раундов
и архи для любого другого,
в общем, неважно будут
частные случайные биты или общие случайные биты.
Вот.
Но, например, что такое АМ с логарифмом раундов,
это как-то никто не знает.
Знаешь, что вот...
Знаешь, что вот АМ с полиномом раундов
это то же самое, что IP с полиномом, да, и...
Соответственно, PSPACE.
То, что мы сейчас будем доказывать.
Вот.
Что такое АМ с логарифмом раундов,
как-то никто не знает.
Или там сполил логарифм.
Хорошо.
Ну что ж, есть какие-нибудь вопросы.
Так, давайте сейчас делаем перерыв.
Ну, можно 15 минут.
12 небольшим начнем.
Ну, и где-то до часу.
Так.
Так.
Ну, значит, основная часть доказательства
будет в следующий раз.
А в следующий раз, получается, через две недели.
Через неделю выходной.
Вот.
А сейчас я расскажу некоторые базовые вещи.
Да, это как бы в чем общее идея.
И, может, немножко расскажу про историю вопроса.
Значит, смотрите.
Давайте, наверное, сначала про историю расскажу.
Значит, потом немножко про идею подхода.
Значит, вообще вот интерактивные доказательства
появились в середине 80-х.
Да, причем более-менее сразу в одной работе
с общими случайными битами,
в другой работе с частными случайными битами.
Вот, начали изучать там самые разные результаты.
Вот.
И что быстро выяснилось.
Ну, то, что, собственно, уже мы знаем.
Да, что, во-первых,
если у нас только
интерактивности, а случайности нет,
на детерминированном интерактивном доказательстве
это будет NP.
Да, то есть первый уровень полиномиальной иерархии.
Если у нас только случайность,
а интерактивности нет,
то это будет класс BPP.
И это заведомо второй уровень полиномиальной иерархии.
Может быть, даже это просто P.
Дальше.
Если у нас есть интерактивные доказательства,
то есть и интерактивность, и случайность,
но константное число раундов,
да, это вот мы сегодня и писали,
тогда это будет
AM, то есть тоже второй уровень полиномиальной иерархии.
Вот. И была ситуация такая,
что
вообще-то это все было известно.
И при этом тоже знали, что IP вложено в PSPACE,
но не знали никакого языка,
для которого было бы нужно
более чем константное число раундов.
То есть все примеры были типа вот
изоморфизма графа.
Точнее, не изоморфизма.
Вот.
Ну и думали, ну, наверное,
тогда и для полиномиальной числа раундов,
не понятно, как его можно использовать.
То есть, наверное, тоже будет
кто-то, может, тоже второй уровень,
или может там, где-нибудь еще.
Но оказалось, что это все совершенно не так.
Вот. И очень интересная история,
как именно это оказалось.
Да, я в перерыве немножко подслушал,
что вы там что-то про перманент
обсуждали.
Вот. Значит, соответственно, перманент
на самом деле был очень важен
в этой истории.
Да, что такое перманент все знают, да?
Это у вас где-то было.
Вот. Значит, соответственно,
ну,
это вот
известная, как бы, история,
что есть его
детерминат, определитель, да, и перманент.
И в них очень похожее определение,
да, там
просто знак убирается, да,
и детерминат получается перманент.
Но при этом для детермината
есть
известный
с XIX века алгоритмы, как его посчитать.
Вот. А для перманента
ничего не известно.
Вот. И наоборот задача для перманента
она сложная, она там
sharp P полная,
если кто знает, что это такое.
Ну, вот была последняя задача, дополнительная,
да, значит, дорежки в первой части.
Вот так раз про sharp P.
Вот. Тут
сначала не очевидно,
что она вообще в sharp P, да,
что подсчет перманента это подсчет
какого-то количества.
Вот. Но это, на самом деле, если там 0 к единиче,
то это можно интерпретировать
или там пар сочетания, да, или еще чего-нибудь.
Вот.
Ну и она там будет sharp P полная.
Вот.
Очень сложная задача.
Ну и, значит, соответственно
придумали некоторый способ,
значит, как вот
для перманента делать интерактивные доказательства.
Вот. И тут очень интересный
сюжет, да,
с такой социальной точки зрения, да, как
наука развивала, значит, это был конец 80-х.
Тогда еще не было
веба, да,
то есть не было веб-сайтов, это в первом плане 90-х
появилась такая технология, да,
что TTP.
Вот. Но уже была электронная почта,
были разные рассылки.
Вот. И, соответственно,
конечно, в университетах
уже многие
имели электронную почту, да, и регулярно
переписывались. И в том числе
была некоторая такая теоретическая
рассылка, да,
по теории сложности
вычислений, где был там
несколько десятков человек, да,
из разных университетов,
США, Европы, Израиля.
Вот. И, значит,
Ноам Нисан как раз
из Израиля
в конце ноября
1989 года
в эту рассылку
он забросил идею,
да, что вот
есть такая идея, как
использовать некоторое алгебро
для интерактивного доказательства.
И там как раз перманент
фигурировал.
Значит, он
эту идею забросил в рассылку,
а потом
уехал путешествовать в Южную Америку,
да, и, конечно, никого мобильного интернета
тогда еще не было,
тем более в Южной Америке.
Вот. Поэтому он, в общем, был без связи,
да, почта там,
телеграмму можно было послать, да,
или позвонить, вот.
Но, в общем, он
ходил там по всяким мачу-пикщу,
да, и от работы отвлекся.
Вот. Пока он на две недели
тогда уехал,
его коллеги из этой
рассылки начали развивать
его идею
и довольно быстро довели до
результата, что
для всей полиномиальной иерархии
есть интерактивное доказательство.
Значит, это
значит,
статья
LFKN
это, по-моему,
лунд
портную Карлов и, собственно,
Нисан.
Вот. Но Нисан только первую идею
подал, да, они потом ее развили.
Вот. Значит,
они доказали, что
pH
pH
вложена в IP.
Вот.
И в ту же рассылку написали.
В ту же рассылку написали,
что вот такой вот
результат.
Вот. Ну, и
это всех очень удивило.
И, в принципе, в общем,
стало ясно, чему дело
клонится, да, что
раз уж, ну, как бы, от pH
уже небольшой шаг.
Да, pH — это верхняя оценка.
Вот. Ну, и как там
наблюдатели пишут,
что началась такая гонка,
стало понятно, что, наверное,
тут есть результат, да,
и началась гонка
за то, кто первый
его откроет. Вот.
И в этой гонке участвовали там, по крайней мере,
дюжина человек, да, как там
пишут, что, по крайней мере,
мы знаем
только о тех попытках,
в которых были еще какие-то побочные результаты,
которые были рассказаны.
Вот. Ну, в общем, выиграл.
Да, вот эти все люди, значит,
Нисан тогда,
видимо, уже надо посмотреть.
Сейчас он, может, тоже в Америке был.
Вот эти все люди работали в Америке.
Да, Нисан обстрелял.
Сейчас он в Израиле,
тогда он где был, надо посмотреть.
Вот. И, в общем, выиграл
эту гонку
Адисшамир,
который
является буквой
С в РСА.
Значит,
протокол РСА, значит, для
шифрования с этим ключом, да,
это Ривисшамир и Эйдлман.
Вот. Вот Шамир и буквка С.
Вот он, соответственно.
Вначале в ту же самую
рассылку, в канун Рождества Католического
89-го года,
а также Ханоке, значит,
прислал, соответственно,
сначала анонс, что вот он доказал.
И потом через пару дней я уже написал
идею, чему
айпер равно П-спейс.
Вот.
Но, на самом деле, эта история
не закончилась.
Потому что дальше там какие-то,
в общем, про это разные рассказывают,
какие-то не очень красивые истории, да,
потому что Шамиру предлагали одну большую
общую статью написать.
А он сказал, нет, я получил этот
результат, значит, я хочу, чтобы
это называли потом теориям из Шамира,
поэтому я один опубликую
статью.
В итоге
все было рассказано, потом на конференциях,
и в итоге в 2002 году
вышел журнал,
в котором было по тря три статьи.
Первая
статья вот этих, вот четырех авторов,
ну, с каким-то таким
сухим названием,
типа
алгебрические методы в теории
интерактивных доказательств.
Вот, потом была статья Шамира,
что айпи равно П-спейс.
Вот.
А потом еще была третья статья,
которая написала известные вам
Александр Шейни.
Значит, и она называлась
айпи равно
П-спейс.
Значит,
simplified proof.
Вот, однажды
то доказательств я вам буду рассказывать,
когда вас придумал Шейни.
Но он, правда, он отнекивает, что он придумал,
он говорит, что он просто разобрался,
что хотел сказать Шамир, и сказал то же самое
более простыми словами.
Но, в общем,
это гораздо проще понять.
Вот.
Ну, если вам интересны
подробности этой истории,
то есть
такой обзор
Ласла Бабая.
Значит, я прям приведу
целиком его название.
Он называется
email
and
unexpected power
unexpected power
unexpected power
of interaction.
Значит, это обыгрывает
как бы и сам результат,
и то, как он был получен.
С одной стороны,
то, что вот айпи равно П-спейс,
это как раз unexpected power of interaction.
Неожиданно, что класс айпи таким большим оказался.
Вот.
А email – это как раз, что они
по email обсуждали это все.
Вот.
И получилось, что
это сообщество за счет
небольшой переписки
доказало вот такой
большой результат.
То есть вот эта неожиданная
сила и с точки
зрения теории, и с точки зрения
социального
процесса научного открытия.
Вот.
Хорошо, значит, это краткая история.
Теперь давайте
потихоньку
разбираться с тем,
в чем, собственно, заключается
алгебраический подход.
Значит, он вообще еще хорош
тем, что
вот тогда уже были известны
то, что называется
препятствия, барьеры
к доказательству.
Ну, точнее так.
Значит, вот там есть
natural proofs.
Значит, это правда статья
11-4 года, чуть позже.
Но, в общем, говорят,
что некоторые люди уже
в общем понимали. Значит, это вот
вопрос о том, почему p не равно np
не доказано.
Я, наверное, упоминал
на первой лекции
первого курса, что есть некоторые
барьеры к доказательству того, что p не равно np.
Значит, а именно
целый ряд методик
точно не проходит.
Ну, и одна методика
это диагонализация.
Тип того, как
доказывают,
что там есть перечислимое и неразрешимое множество
и так далее.
И вот все такие методики
и диагонализации.
Терема барархии по времени так доказывается.
И так далее.
Вот такие методики спотыкаются
в барьер релитивизации.
Значит, барьер релитивизации,
что то, что доказывает диагонализация,
будет верно и с оракулом.
Ну, а там
p равно np с одним оракулом
и не равно с другим оракулом.
Но дальше, в 80-х
стали появляться комбинаторные методы,
когда
мы рассматриваем
какое-то семейство, чего-нибудь,
и доказывают, что
в этом семействе есть все задачи
одного класса и нет какой-то
одной задачи другого класса.
Значит, эти классы неравны.
Значит, вот это вот подход
комбинаторный.
И он получил название
естественное доказательство.
Natural proofs.
Значит, он обходит барьер
диагонализации,
барьер релитивизации, потому что там
конкретика используется.
Но, оказывается,
что разборов Ирудич показали,
что p не равно np,
значит, у нас подыкается и вот эти
естественные доказательства,
что нельзя.
Как бы мы, в принципе, хотели
рассматривать маленький класс,
в котором есть p,
я тут еще порисую,
какой-то маленький класс,
что целиком внутри него p.
Ну, а, например,
вне него
внение его задачи сад.
И тогда, значит,
есть специальное...
Значит, а если мы так докажем,
тогда сад мне лежит p,
тогда p не равно np.
Ну, и вот есть
некоторые требования к тому,
что называется естественным доказательством,
что вот этот вот класс
требует конструктивности и объемности.
Объемность, что он достаточно
большой,
а конструктивность, что легко проверять,
данная точка в нем лежит или не лежит.
Ну, и вот Разборов и Рудич доказали,
что
нельзя такое
для p и np сделать.
Но идея там такая,
что...
Ну, то есть как нельзя? Нельзя, если выполнить
некоторые более сильные требования,
а именно
некоторые условия на псевдослучайность.
Потому что тогда,
если выполнены некоторые условия
на псевдослучайность,
то тогда получается, что...
Но псевдослучайность означает, что есть такие
конструкции, чтобы псевдослучайно не отличить
от случайной,
при помощи простых
отличителей. А вот эта штука как раз
дает простой отличитель.
Ну, а если, например, там все
p там
попало внутрь, а сад
не попало, то мы как раз
сможем отличать
при помощи этого отличителя.
Ну ладно, значит, я не хочу
вдуматься подробностей.
В общем, неформально
смысл такой,
что если
p не равно np, тогда есть сложные
задачи. Да, и в частности
сложно что-нибудь доказать. Но
дальше некоторым образом это перекрутив,
можно показать, что тогда и само доказательство того,
что p не равно np будет сложной задачей
настолько, что у нее не будет
доказательства. Вот такая
вот идея. Но вот это вот
алгебрический метод,
он обходит и этот барьер.
Там не получается вот такого
конструктивного объемного свойства.
Вот так.
Ну и напоследок,
прежде чем перейдем к конкретике, я еще
одну вещь хочу сказать.
Была такая гипотеза о случайном
оракуле,
то есть теорема,
что для случайного оракула p не равно
np f'1.
И была такая гипотеза, что
если
какое-то вот такое разделение
выполнено с равенствием 1 для случайного оракулы,
то оно и без оракулы тоже выполнено.
А оказалось, что это неверно.
А именно, что
вероятность того,
что
ip
в случайном оракулом a
не равно pspace
в случайном оракулом a.
Значит, вот это равно 1.
Там статья,
там какая-то схема авторов.
Хор, по-моему, первый.
Хор Галдрайхтон и какие-то еще
люди.
Вот, статья так и называется.
The random oracle hypothesis
is wrong.
То есть гипотеза о случайном оракуле
ложная.
Значит, для случайного оракула
это не равно, а для пустого
это равно.
Случайно, да, случайно.
Случайно, в том смысле, что каждое слово
независимо от других,
средство-то одно-второе.
Не, ну там какое-то такое
распределение
на этом континентном
имействе всех ораков получается.
Там уже настоящие вероятности
не дискретные.
Хорошо, значит, что же
все эти люди придумали?
Значит, они придумали следующее.
Да, значит, давайте
я вам сначала
покажу,
значит, что
задача от автологии.
Значит, задача от автологии
лежит в IP.
И даже
вот это, это уже усиление
по сравнению с
тем примером, которые были
раньше, потому что, смотрите,
задача от автологии не просто
CoNP, а она CoNP
полная.
Всякие примеры типа
не из-за маркетизма графа, не в CoNP,
но они там вряд ли полные.
Вот так.
Дальше
идея такая.
Для автологии
там, конечно,
вопрос для 3KNF будет
ревиальным.
То есть никогда не будет автологией.
А нет ревиальным CoNP
будет вопрос
о 3DNF.
То есть мы будем показывать
для 3DNF
является 3DNF автологией.
Идея такая, что мы перейдем
от логики к алгебре.
Значит, логика
превращается
в алгебру.
Ну, в общем-то,
переход довольно стандартный.
Отрицание
х
превращается
в 1-х.
Умножение...
Ой, наоборот,
конъюнция превращается
в умножение.
Вот.
Один юнция
превращается в х плюс у
минус ху.
Вот. Заметьте, что я тут
не ксор пишу, а плюсы и минусы.
Почему?
Потому что вот эти формулы верны
не только в поле из двух элементов,
но вообще в любом поле.
Значит,
вот эти вот формулы
верны
в любом поле.
В том смысле, что если
значение x и y
это 0 и 1,
то результат
установки такой многочлены
это будет тоже 0 и 1,
соответствующим вот этим логическим функциям.
Но вроде очевидно,
более-менее.
Вот. Хорошо.
Значит, тогда...
Смотрите, пусть у нас есть
какая-то формула Фи.
Значит, можно ее
превратить в какой-то многочлен
ПфиТ.
Значит, это
формула логическая.
Это многочлен.
Вот. В этом многочлене мы не будем раскрывать скобки.
Да, давайте вот для
такой функции какое-нибудь обозначение введем.
Да, не знаю, там дизюнкция
в кружочке, например.
Дизюнкция в кружочке — это
алгебрическая функция, значит, по определению
это и будет.
x плюс y минус x.
Вот. И тогда, значит,
тут будет, например, следующая, значит,
если мы про татологию, мы именно про ДНФ
говорим, значит,
тут будет, ну, что-нибудь, да, там
П, конъюнкция НЕКУ,
конъюнкция Р
или
там какой-нибудь П
или отрицание Р,
или отрицание С
или ИТ, вот здесь вот.
Или и так далее.
Значит, там многочлен
наш будет прям таким, да,
значит, будет там П умножить
на 1 минус
Q умножить на
R. Дальше, ко всему
этому месте мы применяем такую дизюнкцию
в кружочке, значит,
тут будет П
умножить там на
1 минус R
умножить на 1 минус С.
Дальше
дизюнкция в кружочке и так далее.
Вот.
Ну, и вот такую запись мы будем понимать
как запись многочленов.
Так, так вот, смотрите.
Теперь главная идея, значит,
фитофтология
фитофтология
тогда и только тогда,
когда сумма
по всем, как бы,
по всем, как бы, битам
на там
B
B1 там
из 0,1, да.
А дайте я вот такую сумму
напишу. Сумму по B2
из 0,1
и так далее. Сумма по
B
какое-то, да, там
карта из 0,1.
Так, здесь дальше
P фитая
P фитая
вот B1
и так далее Bk.
Такая сумма должна быть равна
всему.
Значит, если фитофтология
количество, ну, не количество сумм,
количество слагаемых, да,
что это будет за количество?
два степеника, да.
Совершенно верно.
Вот мы и перешли от логики калкгибрена.
Значит, теперь мы будем доказывать
вот такое вот утверждение
про значение многочленов.
Легче пока не стало, да?
Ну, хорошо, сейчас станет.
Значит, дальше
идея следующая.
Значит, идея такая, что вот эти вот значения
значения многочленов
и можем рассматривать
не только на нулях и единицах,
но вообще на любых значениях в поле.
Вот, и если мы не вздумаем раскрывать
вот тут вот скобки, да, конечно, если мы начнем раскрывать
скобки, это будет какое-то очень длинное выражение.
Мы так не будем делать.
Мы прямо в такое выражение будем подставлять как конкретные
значения.
Тогда мы, конечно, сможем посчитать.
Вот, при этом
да, конечно,
поле должно быть достаточно большим.
Потому что
ножет не слишком большим, да.
Значит, если это будет поле, ну, грубо говоря, там
действительных чисел, да, или рациональных чисел,
то
тут, наверное, слишком...
Ну, вообще тогда будут вообще проблемы.
Например, мы не можем взять случайный имен в поле,
если у нас поле бесконечное.
Но если поле действительных
чисел, то можем взять, но не можем в компьютер
поставить.
А если рациональных чисел,
то мы можем в компьютер
отправить рациональное
число, но не можем взять
случайное, да, потому что не бывает равноверного
шклеения на счетном множестве.
Вообще хочется,
чтобы поле было конечным.
На поле будет конечным.
Так, так не очень хорошо, что я здесь
букву P использовал.
Дальше у нас P будет простым числом.
Да, они были
выпеременной.
Вот, значит, здесь нам
не нужны вот эти всякие
поля
большого размера.
Значит, поля
Галуа нам не нужны. Нужны
самые обычные поля, просто поля вычетов.
Вот, так.
Ну ладно, сейчас я...
Я думаю, что я
вот про тавтологию
прямо расскажу,
как это потом
на TQBF
отстраняется. Изучим в следующий раз.
Так, вот, значит,
выберем
простой число.
Ну, насколько
большим оно должно быть,
то оно должно быть
не слишком большим, чтобы можно было вычислять.
То есть оно должно быть каково-то экспедиционного
размера.
Вот, но и не слишком маленьким,
чтобы там ошибка не получилась.
Но
сам放inos enrichment
geriоген worldwide
В общем, мы сейчас поймем, какого оно размера должно быть, чтобы тут все сошлось.
Значит, p — это простое число, связано f, p — это поле из p-элементов.
Так, и теперь, смотрите, мы возьмем и одну сумму снимем вот из этого выражения, снимем в одну сумму.
И будет у нас одна переменная.
Значит, посмотрим, выражение первое от x.
Значит, это будет такая же сумма, но начиная со второго, b2, 0,1 и так далее.
Тут, соответственно, bk.
Дальше будет p, и тут будет x, и дальше b2, и так далее, bk.
Значит, смотрите, что такое q1 от x? Это многочлен от x.
А какой степени? Ну уж точно не больше, чем длина формулы.
Или не больше, чем три числа переменных.
Но тут, смотрите, если мы вот так вот делаем, то у нас в этой дизюнции в кружочке тоже ведь есть умножение.
То есть у нас просто степени все складываются.
Ну, можно считать, что как раз три на число скобок можно считать.
Это будет очень верхняя оценка.
В принципе, если все скобки из трех, это прямо в точности только будет.
А, это будет чах. Нет, это будет неправильно.
Это верхняя оценка все равно будет.
Но это будет степень многочлен относительно всех переменных.
Относительно одной переменной, если у нас тут повторов нет скобок,
то будет не больше, чем даже число скобок, просто без тройки.
Но вообще-то все неважно.
Все неважно, значит, это степень точно полиномиального размера формулы.
Ку1 от х это многочлен степени полином, вот там размер формулы.
А что же это значит?
Это означает, что рувер может прислать его к эффициентам в явном виде.
Да, если мы просто раскроем все скобки,
то специальное выражение мы его не хранить, не получать, не посчитать не можем.
Но от одной переменной, да, и вот так вот свернутой
к последним переменным мы можем это получить.
Вот, соответственно, рувер.
И вот это я уже начинаю протокол.
Значит, рувер присылает в явном виде кэффициенты.
Присылает кэффициенты вот этого ку1 от х.
Рувер присылает кэффициент ку1 от х.
После этого что?
Должен проверить верификатор.
Но смотрите, если в этот ку1 подставить 0 и 1,
то должна получиться теперь такая сумма.
То есть верификатор проверяет,
то ку1 от 0 плюс ку1 от 1 равняется 2 в степени k.
Вот, если уж это не сошлось, то тогда нужно отвернуть.
Дальше происходит следующее.
Значит, что честный прувер, для которого это все верно,
пришлет многочленку 1, который по этой форме посчитан,
и все сойдется.
Нечестный станет перед выбором.
Либо прислать многочленку 1, который по этой форме посчитан,
но тогда он сразу проиграет, потому что это не сойдется.
Либо прислать какой-то другой многочленку 1 штрих,
который вот тут не верен, но по крайней мере вот эта проверка пройдет.
Но, конечно, на этом не нужно заканчивать.
После этого происходит следующее.
Теперь верификатор делает следующее.
Верификатор выбирает случайный элемент поля.
Верификатор выбирает случайный А1 из FF.
И после этого начинает ожидать...
Значит, ожидает доказательства следующего факта.
Сумма теперь по B2 из 0,1.
Сумма там по B3 из 0,1.
И так далее.
Сумма по Bk из 0,1.
Значит, тут будет FF, где в качестве первого аргумента
уже вот это вот случайно А1 подставили.
А все остальные аргументы, они все еще вот эти B2, это дальняя Bk.
И чему это должно быть равно?
Смотрите, вот это, что я написал, это вообще то же самое, что там написано.
Только вместо X я A1 подставил.
Ну, тогда, если Q1 правильное, то это должно быть равно Q1 от A1.
Так, ну, смотрите.
Получается, на самом деле, утверждение примерно того же вида,
то и раньше, то есть тоже какая-то такая сумма равняется чему-то.
Только теперь сумма на единицу короче, значит, на одно суммирование меньше.
Ну, и здесь тут немножко другое получается.
Получается FF, получается FF с подставленным A1.
Но дальше, в общем, происходит все то же самое.
Сейчас я дайте здесь сотру, я напишу немножко подробнее.
То есть идея, что дальше рекурсивно происходит то же самое,
а потом, когда мы сведем к базе рекурсия,
то верификатор сам сможет проверить, совпало или не совпало.
Ну, дайте я еще, там, второй шаг я еще подробно напишу.
Значит, теперь Q2.
Значит, Q2 от X, и это будет то же самое.
Теперь мы еще одну сумму снимаем.
И теперь вместо B2 вставляем произвольный.
Q2 от X это вот сумма по B3 из 0 единицы и так далее.
Сумма по ZK из 0 единицы.
И тут будет PFE от A1, потом X.
A1, X, B3 и так далее, BK.
Вот, это тоже многощина одной переменной, тоже степень небольшая.
Теперь прувер присылает, соответственно, коэффициенты Q2.
Значит, теперь верификатор проверяет,
то Q2 теперь от 0, Q2 от 0 плюс Q2 от единицы
равняется Q1 от A1,
ну и после этого выбирает случайное A2,
выбирает случайное A2,
ну и, соответственно, ожидает доказательства на единицы.
Ну, и после этого выбирает Q1 от A1,
ну и, соответственно, ожидает доказательства на единицу меньшего.
Так, дайте, я вот тут напишу.
Значит, ожидает...
Ожидая доказательства, что сумма теперь начинает с B3.
Сумма начинает с B3.
И так далее.
Значит, кончая BK там.
И тут, соответственно, тут будет прэфи от A1, A2,
а потом B3,
а и так далее.
И так далее BK.
Ну и, соответственно,
а и так далее.
И так далее BK.
Вот это будет равняться, соответственно, Q2 от A2.
И все это продолжается точно так же.
То есть теперь еще одна сумма убирается,
еще одна переменная, еще один крицентного члена,
еще одно суммирование, и так далее.
Вот, в самом конце.
И так далее.
Значит, и в конце получается, что верификатор сам может проверить.
В конце верификатор сам проверяет.
То он проверяет.
Ну что?
Этот многочлен, который мы все уже выбранные значения подставили,
равняется как бы последнему многочлену.
Да, то есть тут будет Kt,
а тут как бы уже пустое множество сумм,
что прэфи.
Вот, соответственно, A1, A2, и так далее.
Kt, что он равняется Qt от A.
Вот, и это верификатор сам может проверить.
Потому что, когда все значения фиксированы,
он уже их может подставить, многочлены посчитать по формуле.
Ну, значит, тогда смотрите, на чем основана идея корректности.
Во-первых, если его по-честному,
то есть если действительно тавтология,
тогда исходное равенство верное,
и просто каждый раз будет по формуле считать многочлен и именно его присылать.
И тогда все проверки, конечно, пройдут.
Теперь, пусть условие неверное,
но тогда вот эта проверка все-таки прошла.
Значит, тогда что нужно, что проверки придется сделать?
Проверу придется вместо Q1 прислать какой-то Q1 штрих.
Да, то есть вот может быть что-то такое,
что вот, например,
для настоящего Q1, Q1 от нуля плюс Q1 от единицы
равняется 2 в степени K.
Вот, а для того, что прислал прувер,
будет какой-то Q1 штрих.
Нуля.
Сейчас, тут не равняй.
Значит, это если неверное движение,
то для честного Q1 будет не равняться,
а для того, который прислал,
будет равняться.
Что из этого следует?
То есть следует, что он прислал что-то другое.
Ну, логично.
Из этого следует, что как бы как многочлен формальный,
Q1 это не то же самое, что Q1 штрих.
А тогда получается, что вероятность того,
что Q1 от A1 совпало Q1 штрих от A1.
Это вероятность, что A1 это корень разности.
Разность, поскольку и Q1 штрих,
и Q это на очень маленькой степени.
Да, ну Q1 как бы автоматически,
а Q1 штрих, потому что мы так воспринимаем.
Чтобы не прислал прувер на этом этапе,
мы это воспринимаем как эффициентом многочлена
на небольшой степени.
Поэтому Q1, исходя из определения маленькой степени,
Q1 штрих исходя из конструкции маленькой степени,
соответственно, вероятность того,
что мы попали в корень, тоже будет маленькая.
Значит, это будет меньше либо равно,
чем верхняя оценка на степень.
Ну, там 3m это уж точно верхняя оценка.
Делить на размер поля.
Значит, это будет P.
Если вдруг верификатор попал в корень вот этой разности,
то тогда после этого у прувера
остается вежное утверждение,
и он его радостно доказывает.
m это число скобок, я имею в виду.
Но даже в принципе тройка можно убрать,
если там переменные дублируются.
Ну, в общем, в числителе стоит некоторая верхняя оценка
на степень, которая полиномерная.
Вот, в общем, вот эта вот штука, это вот 3m.
Так, вот, значит, если случайный верификатор попал в корень,
тогда пруверу повезло,
и после этого заставшиеся раунды он все докажет.
Но, скорее всего, это не будет.
То есть нам нужно, чтобы за все раунды
вот эта ошибка не накопилась к большой величине.
Ну, конечно, если P будет там экспоненциальным от m,
а раундов у нас полиномерное число,
то она и не накопится.
Вот.
Ну, собственно, вот и доказательства.
Получается, что если не на одном из этапов
верификатор не попал случайно в корень вот этого многочлена,
ну, какого разности между тем, что на самом деле
должно быть, и тем, что прислал прувер,
то тогда, соответственно...
Ну, только на следующих этапах тут, конечно,
если прувер что-то не то прислал,
q1 будет q1 штрих.
Здесь используется то, что прислал прувер,
а не то, что должно быть на самом деле.
Ну вот.
Получается, что с маленькой вероятностью
на одном из этапов верификатор случайно выберет корень,
а с дополняющей вероятностью там в конце
все еще останется неерное утверждение,
и верификатор его отвернет.
Вот, вот такое рассуждение.
Так, ну чего, понятно?
Не, а почему один раунд?
Не один раунд, а для каждой переменной свой раунд.
Все-таки тут именно важно именно пленнельство раундов.
Да, и то, что они именно последовательно идут.
Да, что сначала прувер фиксирует q1,
потом верификатор там фиксирует элемент a1,
потом прувер прислает q2,
потом верификатор фиксирует a2.
Да, то есть раундов, ну, таких парных раундов,
да, прувер и верификатор
будет только же сколько переменных формуля.
Вот, и это, конечно, очень важно, да,
если бы их была константа, да,
то тогда это был бы am, а не ip.
Не, ну, в смысле...
Вот это вот,
вот это вот это ошибка,
которая добавляется на первом раунде.
Дальше будет такая же ошибка
на втором раунде.
Вот, и так далее.
Соответственно, общая ошибка
будет вот это вот умноженное число раунда.
Ну, давайте, а число раундов
собственно как число переменных, да,
то есть общая...
то есть, общая ошибка,
то есть общая ошибка будет 3mn делить на p.
Да, стандартно n число переменных, m число скопок.
Что?
А, k переменных.
Ну ладно.
Ну, в данном случае можно p от пруера попросить.
Да, можно сказать, что пусть p будет прошлое число больше, чем такое,
то пришлите нам, пожалуйста.
Вот, либо можно действительно выбирать там и искать его там как-нибудь.
Так, не, ну вообще вроде да, вроде можно так сделать.
Ну она была на первом ходе, но дальше она увеличивается.
Если хотя бы на одном шаге верификатор попал случайно в корень,
многочлена, то после этого прувер уже докажет.
После этого у прувера остается верное утверждение, он его докажет.
Поэтому это нужно, нужно еще умножить на число раундов.
Так нет.
Алгоритм нельзя обрубать, потому что нам кроме, кроме вот этого,
нужно проверить еще и вот это вот.
А это мы доказываем, это мы проверяем рекурсивно.
Поэтому нет, это нельзя просто так прекратить.
Тут как бы и на чем основано, да, что скорее всего,
если изначально было утверждение неверное, то оно скорее всего
и на втором шаге будет неверное, и на третьем, и так далее,
и на последнем тоже, а на последнем верификатор
может его сам проверить, уже без помощи прувера.
Вот такое рассуждение.
Так, ну ладно, получается на сегодня все.
В следующий раз расскажу о том, что происходит.
На сегодня все, в следующий раз распространим на вот ЭКБФ.
Все, спасибо.
