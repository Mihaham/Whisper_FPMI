Итак, ребят, ну, лучший технический вуз, как вы понимаете, техника
работает как надо.
Итак, сначала пара организационных моментов.
Спасибо, что большинство из вас записались на курс,
там сейчас 321 анкета.
Собственно, касательно семинарский групп.
Там, как и предполагалось, половина хочет ходить
чисто в лекционную аудиторию на семинары после лекции.
Вопросов нет.
Это абсолютно рабочий вариант.
Семинарские группы, собственно, семинарские занятия предполагаются
по вторникам и средам в 18-30 вечером очные, то есть
туда можно записаться, мы скинем опросик, чтобы
понимать, кто куда, когда пойдет, уже маленькие просто
в чатике.
Пожалуйста, отметись.
Онлайн занятия, скорее всего, будут в районе пятницы,
потому что, потому что, потому что так сложилось.
То есть на них тоже можно прийти.
Вопрос.
А кто хочет сегодня ходить в другую семинарскую группу?
А вы точно на нее ходить будете?
Если да, то можно.
Просто ранее получалось так, что ставили семинары
параллельно с лекционным потоком, туда приходило
два человека, в итоге они просто-напросто переставали
работать.
Если есть необходимость, можно поставить в понедельник.
Хорошо?
Да, ходить можно всем по умолчанию.
Вопрос в том, кто-то будет в 18-30 по понедельникам
ходить не сюда.
Тоже вечерня.
Смотрите, все семинары по умолчанию будут в 18-30,
если не оговорено обратно.
Потому что все, как правило, преподаватели, это действующие
специалисты, которые работают, и они все это делают после
работы.
Так, здесь какие-то вопросы есть?
Окей, смотрите, тогда еще пара организационных
моментов.
В репозитории появилась, соответственно, информация
про то, про все, плюс-минус, что необходимо.
Там появилась примерная программа экзамена, там
появилась табличка, где будут лежать все записи
лекций.
Запись первой лекции там доступна.
Второй пока обрабатывается, потому что мы нанимаем
нового монтажера, но появится на канале буквально сегодня-завтра,
я надеюсь.
Там же есть список необходимых знаний, скажем так, необытимых
фактов, пререквизитов для курса.
Короче, списочек из формата прочитать и понять, знаете,
вы из этого списка все или нет.
Намек, все, что без звездочки знать должны, наверное,
все вот прям совсем, причем сходу в три часа ночи разбуди,
чтобы вы это помнили, поэтому, пожалуйста, проверьте сами
себя.
Проходите.
Вот.
И что еще, там же появилось первое домашнее задание,
его можно решать.
Оно максимально простое, прямолинейное, там все описано.
Сама проверяющая система сейчас подымется, мне надо
деньги закинуть на ту виртуалку, на которую она крутится.
Чтобы сдать домашку, вам достаточно будет загрузить
домашку, так как указано в инструкции, в проверяющую
систему, она вам скажет, сколько у вас баллов, один
это сто процентов, короче, вероятность единица, то
есть вы все решили.
Один значит полный балл, ноль значит не полный балл,
нулевой балл, ноль пять значит половину решили,
какие тесты у вас не прошли, вам напишут.
Вопросы, пожелания, комментарии есть?
Окей, надо открыть видимо, надо будет написать видимо
более явные инструкции, короче, там как правило
всегда есть в папке ноутбук, который называется Assignment,
вот это ваша домашка, все остальное, вспомогательные
файлы, внутри ноутбука Assignment написано, вся инструкция,
что надо делать.
Конкретно в данном случае у вас есть ноутбук Assignment,
там по сути какие-то вопросы, что-то, что вам необходимо
сделать, по факту вам необходимо что, реализовать класс
кнн в пай-файлике, а чтобы у вас проверяющая система
отработала и дала вам, скажем так, развернутые
комментарии, пока что это немного на костылях, но
вам нужно весь текст этого файла, когда у вас все работает,
запихнуть в template и сдать его, там инструкция написана,
не спать.
И вы и ноутбук.
Пока нет дедлайна, да, после дедлайна можете доздавать,
что вы получили до дедлайна.
Там написано, чем нельзя пользоваться, то есть к слову,
вам говорят написать кнн, использовать кнн на заскалерной
нельзя, вам надо его написать, ну и так далее.
Ну оно там ограничено каким-то здоровым числом, пока что
за всю историю никто его не перебрал, ну то есть там
нельзя сделать, полностью не ограничить, там какая-то
станция стоит, то ли 100, то ли 1000, короче, у вас раза
с пятого, я думаю, зайдет.
Ну если не идет там, например, четвертая домашка сложная,
она раз с пятнадцатым может зайти.
Это нормально, она примерно, это просто то, что сдавали
люди весной 21 года, поэтому она примерно.
Ну смотрите, то, что вам написал бот, я прошу прощения,
я на стену закинул разболовку раньше, чем мы ее согласовали,
на это пока не смотрите, я ее сейчас удалю.
То, что там написано, это то, что было год назад.
Оно сейчас немножко поменялось, поэтому то, что там написано,
это неактуально.
Ну что ж, еще вопрос-комментарий есть?
Окей, смотрите, я на всякий случай напоминаю вот про
этот файлик пререквизитов, я про него еще раз в чате
напишу, но по сути это то, что вам хорошо бы знать,
и это то, что мы с вас спросим где-то в районе, сейчас
на сколько, 19 сентября, в районе 3 октября мы скорее
всего вас спросим, вот с вас спросим вот эти факты,
то есть хорошо бы их вспомнить, запомнить, заботать и так
далее, вы из них большинство знаете, но, скажем так, опыт
показывает, что многие эти вещи, типа что такое финное
преобразование, далеко не сразу люди помнят, а?
Да, да, то есть ну представьте себе, что это какой-то потоковый
грубо говоря экзамен, кстати да, если будет соответственно
переполнение, такое может быть, мы просто еще одну
аудиторию возьмем, типа 123 ГК и туда часть выгрузим,
ну чтобы не сажать тут людей прям совсем как сосиски,
это будет на семинар, то есть лекция пройдет как
обычно, потом кусочек семинара мы обсудим то, что необходимо,
там коротенький семинар специально сделан, а потом
где-то час будет на вот эту контрольную, вот, ну соответственно
на нее явка плюс-минус обязательно, то есть неявка в формате
заболел-уехал, заболел-уехал и принимается, но это надо
тогда отдельно согласовывать, то есть в принципе на посещение
прям так по желанию, но на контрольную как вы понимаете
надо прийти, да, то есть, не, погодите, вот там это будет
конкретно просто в этот день контрольная грубо
говоря, можете считать, что она фиксированная для
всех, это к семинарской группе не имеет отношения.
Решим. Просто я изначально предполагал, что понедельника
нет других семинаров, поэтому сейчас вы меня немножко поставили в тупик.
Хорошо. Так, окей, еще вопросы есть? Ну ладно, тогда, собственно, вспоминаем,
что у нас было в прошлый раз, мы с вами чуть-чуть поговорили про линейную
алгебру, вспомнили какие-то базовые понятия, что-то починили,
что-то разобрали, где-то вы меня даже поправили, большое спасибо,
поправляйте меня абсолютно свободно. Сегодня нам это дело пригодится,
мы с вами поговорим про ужас линейную регрессию, но те, у кого была статистика,
прекрасно понимают, что это такое, те, кто ходили на лабо по общей физу, тоже
прекрасно понимают, что это такое, в принципе, штука максимально простая,
но при этом и очень красивая. Итак, сегодня в меню. Во-первых, мы с вами поговорим о том,
что такое линейная модель, в принципе, как они работают, зачем они нужны и почему они
используются повсеместно. Во-вторых, мы поговорим о том, какие именно подходы к
регрессии с точки зрения линейных моделей есть и какие есть подходы для получения аналитического
решения и, собственно, какого, градиентного решения. Вот, потом поговорим про теорему Гауса Маркова,
классная теорема, одна из немногих теорем машинного обучения, поэтому, пожалуйста,
не забивайте на вот те там три-четыре теоремы, которые у нас есть, типа теоремы Экрата Янга,
теоремы Гауса Маркова и так далее. Штука классная. Да, на экзамене это тоже понадобится и, в принципе,
это понадобится, чтобы понимать. То есть, вот если я говорю, обратите внимание на теорему,
да, ее лучше заботать. Причем заботать не формально о тараторике, а понять то,
что регулярно люди не понимают чуть такое. Потом поговорим про регуляризацию, по сути,
первый раз в таком более-менее явном виде. Сегодня у нас будет регуляризация потихонного,
но на самом деле она много где еще применяется и называется по-разному Way Decay и так далее. И
поговорим про то, как понять, что ваша модель нехорошая. Сказал бы по-другому, но мы все-таки
в университете. Итак, если вопрос есть, задавайте, руку поднимаете, задаете. Поехали. На предыдущей
лекции, предыдущей, которая не по линалу, были разговоры у нас про что? Про понятие в машинном
обучении, про то, что такое наивный байвский классификатор, про теорему байвса. Коротенько
мы поговорили про КНН на прошлом занятии. Это все, в принципе, работало. На всякий случай,
эта камера точно меня видит, а то он куда-то туда смотрит. Хорошо, спасибо. Вот. И сегодня мы
переходим к линейным моделям. Как вы уже помните, линейная модель это так, кто раздает линейное
отображение из пространства параметров, признаков в пространство ответов. Вот то, что мы с вами на
прошлые недели разбирали как линейные, по сути, отображения с почвы матричек, это, по сути,
все есть линейная модель. Все, что можно представить в виде линейной комбинации наших признаков,
является линейной моделью и так далее. Бывают линейные модели в регрессии, понятное дело,
есть точки, провели палку. Бывают в пластикации, есть точки, разделили палкой. Бывают линейные модели
даже там, где у нас не стоит задача обучения с учителем, например, в задаче снижения размеров.
Это unsupervised задача, но на самом деле переходим в supervised режим, то есть наша задача, у нас есть
данные в размерности 25, мы хотим использовать не 25 признаков, а 3 признака. Как нам понизить
размерность, потеряв наименьшее количество информации. Понятное дело, полностью мы не
сможем сохранить всю информацию, потому что у нас размер с 25 на 3 не отображается, если не вырублено.
Но, тем не менее. Сегодня мы с вами поговорим про регрессию и классификацию. Это следующая лекция,
а снижение размерности это через одну лекцию, там поговорим про PCA. Но, я думаю, про метод
главных компонентов тоже из вас многие слышали, правильно? Кто слышал? Понял, не многие слышали.
А что такое сингулярное разложение? Может больше слышали? Хорошо, а что такое разложение по собственным
векторам? Может больше слышали? О, вот. Ну, по сути, почти все одно и то же. То есть из разложений по
собственным векторам можно дойти до PCA, причем достаточно быстро. Ну что ж, и также стоит сказать
про линейные модели, что это крайне важная штуковина по двум причинам. Первая, наверное, в доброй
половине задач, которые решается машинным обучением, вам достаточно линейная модель. Вот серьезно,
вам не нужны убер нейронки, огромные бустинги и так далее, вы берете линейную модель, вставляете
ее, она быстрая, устойченная, интерпретируемая, легко реализуется, короче, дешевая, сплошные плюсы
и дает хорошее качество. Второе, без понимания того, как работают линейные модели, понять,
как работают все эти новомодные нейронки, ну, в принципе, нельзя. То, что нейронки — это
эдакие линейные модели на стероидах. В них понапихали нелинейные функции активации,
придумали какие-то, скажем так, обоснованные некоторыми свойствами наших данных и какими-то
мыслями о симметрии в наших данных преобразованиях. Например, свертки — это, по сути, тоже в некотором
смысле линейное преобразование, его можно так представить и так далее. Поэтому понимание
линейных моделей — это вообще кругольный, наверное, камень понимания двух третей всего машинного
обучения. Поэтому, пожалуйста, не пренебрегайте им. И начнем мы с линейной регрессии. Собственно,
что такое линейная регрессия? Это задача регрессии. В данном случае будем рассматривать
одномерную, то есть мы просто-напросто предсказываем одну чиселку. Также есть векторная регрессия,
линейная регрессия, где мы предсказываем много чиселок, то есть мы отображаем наши признаки в одно
число. По сути, у нас есть датсет, пара x и y, x и y — наши объекты, y — целевые переменные,
y приходит из R. Если у нас в общем случае это будет векторная регрессия, то есть с из Rk,
где Rk — это какая-то камерная векторная штуковина. И, соответственно, наша задача найти некоторую
линейную комбинацию наших признаков, чтобы получить ответ. Ну или можно записать вот в
таком виде омега 0, это наш свободный член, плюс взвешенная сумма всех x, xкатый — это именно
катый признак, не катый объект на всякий случай, но омегк, где у нас всего p признаков. Или что то
же самое, так как математики, народ, скажем так, который любит писать все коротко и понятно,
очень часто переписывают вот в таком формате. xу, скажем так, виртуально добавляют вот нашему
каждому признаку, каждому объекту добавляют пективный признак на первое место, который всегда равен
единице. Ну тогда, соответственно, вектор x — это 1, а потом x1, 2, 3, т.т. Зачем это надо? Ну потому что
тогда мы можем с вами записать экспонированная омега, вот наша с вами линейная модель. Не надо
никого в плюс b и так далее, все максимально красиво, понятно записано. Хорошо? Но еще раз обращай
внимание, это чисто для удобства записи, потому что, когда мы начнем говорить про регуляризацию,
вот здесь объявится большая проблема, и об нее можно споткнуться. Омега — наш вектор весов,
омега 0 — свободный член, соответственно, он может его в себя включить, или же мы можем просто добавить
со всей матрицы объект-признак столбец из единичек, и тогда у нас только будет омега-вектор весов,
где омега 0 — это краска свободного члена. С ним вроде все понятно. И задача оптимизации, которую мы
решаем, это минимизация какого-то функционала, например, функции ошибки, например, средней
квадратичной, где у нас есть наши y и есть наша оценка y, то есть предсказание нашей модели. Мы
можем с вами минимизировать средние квадратичные отклонения, можем минимизировать средние
абсолютные, можете придумать там какую-нибудь квантильную функцию потери, что придумаете,
то и будет, и это от вас зависит. На всякий случай. Вот эта конкретная постановка задачи МНК методом
наименьше квадратов она решается. Тут вопросы есть, все понятно? 3, 2, 1, хорошо. Ну и соответственно,
с этой задачей можно работать максимально просто почему, потому что это один из единственных
случаев, где в машинном обучении у нас есть аналитическое решение. Не какая-то там попытка
аппроксимировать непонятно что, непонятно как градиентными методами, а просто получить
аналитическое решение. На всякий случай, вот этот вывод тоже хорошо бы уметь делать,
потому что, во-первых, хорошо бы уметь матрички дифференцировать, во-вторых, на экзамене тоже
спросим. Смотрите, вот наша функция, наш функционал, средней квадратичной ошибка, правильно? Ну или,
как еще можно назвать, наша функция эмпирического риска может быть записана тем образом. Это квадрат
отклонений, правильно? Ну или, что то же самое, мы пытаемся посчитать вектор отклонений и посчитать
квадрат его второй нормы. Согласны? Тогда можем это переписать в каком виде. Собственно, как мы с вами
на прошлой неделе разбирали, y-xω транспонированный на y-xω. Или, что же самое, вторая норма вектора
отклонений, в квадрате. Почему, кстати, в квадрате, как вы думаете, почему бы это еще под квадратный
корень не засунуть? Да, так проще считать. А решение задачи оптимизации поменяется, если под корень
засунем? Нет, все это понимают. Все помнят, что корень у нас, как бы, какая величина, функция точнее,
а везде монотонная. Молодцы, на области определения. Потому что, если вы будете корень из отрицательного
числа доставать, то бескомплексной плоскости что-то как-то будет печально. Хорошо. Все, соответственно,
вот наш x. На всякий случай, здесь с x-ами абсолютно все равно, или у нас не свободный член, или мы сюда
вот включили нашу, нашу столбец из единичек, поэтому у нас свободный член сидит в матрице весов,
пока все нормально. Ну и замечательно то, что мы с вами знаем, что в точке у оптима у нас производная
равна нулю. Вообще говоря, квадратичная функция потерь парабол у нас выпуклая, правильно? Минимум там
один, поэтому мы с вами можем найти решение для данного, для данной оптимизационной задачи.
Приравниваем нулю, знаем, что у нас там минимум, там, где она равна нулю, и получается простенький
вывод, что ω это x транспонированное x минус 1, x транспонированное y. На всякий случай еще раз
проверьте себя вот сейчас визуально, какие размерности должны быть у x и у y. Вот я поэтому
говорю сейчас, пожалуйста, внимательно проверьте размерности. Давайте вот сейчас все 10 секунд подумать,
я пока горло смочу, а потом соответственно мы с вами скажем, что да как.
Размерность в смысле матрицы, вот матрица x у нас в какой размерности, матрица y и матрица ω,
соответственно, которую мы проравниваем. Это просто, чтобы вы в уме это все проверили и
поняли, что здесь нигде ошибки нет. Потому что когда вы начнете это руками вводить,
у третьей, наверное, появятся проблемы с тем, что краски и ничего не сходится, да?
Ну, смотрите, здесь как раз-таки вот вопрос, если она вырожденная, вопрос. Пока считаем,
что x транспонированное y, не вырожденное, все в порядке. Ну, давайте, хорошо. Собственно,
матрица x. Какие у нее сейчас здесь размерности? Ну, что такое m, что такое n? Объектов? Аp,
количество признаков. Хорошо, тогда это у нас n на p, тогда x транспонированное x,
размерность какая будет? p на p. Все согласны? Эта матрица вам, кстати, ничего не напоминает,
ну, вопрос к тем, кто статистику изучал. Хорошо, тогда потом про это. Хорошо, предполагаем,
что она у нас не вырожденная, мы ее можем обратить. Потом опять x транспонированное y,
p на p, на p на n, правильно? То есть здесь получается p на n, итоговая матрица. А y у нас в какой
размерности? y это наши целевые переменные. По сути, это матрица, да, n на 1. Получается,
размерность какая остается? p на n на n на 1, p на 1. Ну, короткий, вот наш вектор весов получился.
Все правильно, все сошлось, ничего не перепутали. Я почему на это обращаю внимание, когда это начнете
в коде писать, а вы начнете это в коде писать, это будет во второй домашке, можно перепутать
матрицу, допустим, и транспонировать, тогда размерность матрицы весов окажется какая-то
неправильная и так далее. И плюс, собственно, ваш вопрос, а что делать, если у нас свободный
член добавился? А нам вообще все равно у нас размерность y зависит от размера обучающей выборки.
Размерность x это p на n, n на p точнее, где n это количество объектов, а p количество признаков
фиктивным, безфиктивного. Вы можете туда хоть еще 10 добавить, он все равно слопан. Уловили? Все
поняли? И заметьте, мы с вами получили аналитическое решение для задачи линейной регрессии
со средней квадратической функцией потерь. Все, вот оно у нас есть, на самом деле можете его
запомнить, просто полезно его помнить, чтобы резко кому-нибудь ответить на собеседование, вам скажут,
ух ты классно, вывести тоже можно за 20 секунд, так что выводить тоже полезно. Но, собственно, вопрос
на экране, а что делать, если матрица x transponирована x выраженная? Что такое выраженная матрица? Все
помнят, я надеюсь, правильно? Обратить мы ее не можем, если она прям выраженная, но, на самом деле,
даже если она плохо обусловленная, то есть ее детерминат близок к нулю, то у нас с обращением
будут большие проблемы. Потому что если на детерминат ближе к нулю, то когда мы с вами будем
пытаться посчитать обратную матрицу, нам придется делить на определитель, это деление на очень маленькое
число, это увеличение вычислительной ошибки и так далее, так далее, так далее. С этим все понятно.
Хорошо, что делать? А главное, ладно, что делать, я вам скажу, а в каком случае это может возникнуть?
Так, линии зависимых элементов, хорошо. Признаков или объектов? Ну вот, признаков или объектов?
То есть у нас, на самом деле, система, как правило, переопределенная, если все хорошо, то есть у нас
больше объектов, чем признаков, то есть у нас больше ограничений, чем наших свободных переменных.
На самом деле, ответ правильный, если наши признаки линией зависимые, то вот в этой матрице
появится, опять же, линия зависимости X transponable X. Вы посмотрите, как она получается. Когда мы с вами
считаем X transponable X, по сути что? Мы берем и, по сути, transponable X, мы говорим, вот этот признак
равен вот таким величинам у этих объектов, правильно? И другой признак равен таким-то величинам
у этих объектов. Если у нас два признака, ну, для простоты, например, одинаковые или они
пропорциональны друг другу, то получается, что для всех объектов признак 1 будет там равен 0, 4, 2, 7, 5,
а признак 2, который с ним линией зависим, например, будет ровно всегда в два раза больше. Согласны?
Соответственно, мы умножаем эти строки сами на себя и получается что? Что у нас, как раз таки,
два признака линии зависимые, у нас получается матрица выраженная, потому что мне теперь строки,
ну, или столбцы, потому что она, вообще говоря, квадратная линия зависимая, и у нас проблемы с этим.
Обратить мы ее не можем. Тобственно, когда у нас появляются с вами зависимые признаки, мы не
можем найти решения. Но тут, на самом деле, на это можно посмотреть и с точки зрения просто физического
смысла. Смотрите, предположим, у нас с вами есть два признака, которые зависимы друг с другом,
например. Для самого выраженного случая, но просто с ним проще, мне не надо в уме какие-то
преобразования делать. Представим себе, что у нас в выборке два признака, вес 1 и вес 2. Это абсолютно
один и тот же признак. Окей? И мы, на самом деле, знаем, что вес человека влияет на солевую переменную,
допустим, с коэффициентом 5. Вот Омега для веса, где она тут, вот здесь, будет равна 5. Но у нас с вами
два раза вес присутствует. Значит, соответственно, первые элементы, второй элемент веса суммарно
должны делать склад равной 5. Согласны? Но потому что первая половинка делает там склад какой-то,
вторая кое-то, вместе они влияют как 5, потому что вес-то один, просто он почему-то был продублирован.
А теперь внимание, проблема. Если я возьму веса, у веса, да, веса, параметр значения,
Омега 1 для веса 1 будет равно 10, а Омега 2 для веса 2 будет равно минус 5, в сумме у них что
получится? 5, 6 и минус 1, 7 и минус 2. У вас получается континенуальное множество решений. У вас
континенум решений, вы можете любую пару чисел, которые в сумме дают вам 5, взять и получить
абсолютно тот же самый ответ. Так что то, что мы здесь не можем на самом деле найти аналитическое
решение, а у нас оно в любом случае не единственное. Так что это на самом деле нормально и физическая
обоснованность тоже имеет. Улавливаете пока? То есть линейно-зависимые признаки аналитическое
решение мы найти не можем, плюс мы не можем найти. Единственное решение в принципе, его не существует.
Классный вопрос и классное предложение. Если признаки линейно-зависимые, их можно выкинуть.
Если мы об этом знаем, конечно надо выкинуть. Но проблема в том, что я вам привел пример совсем
игрушечный. А на практике нам абсолютно не важно, у нас линейная зависимость, два признака равны
друг другу или признак номер 328 это линейная комбинация предыдущих 327. Плюс у нас есть шум,
плюс признаков может быть там 10 тысяч. Так что найти какие из них линейно-зависимые друг с
другом может быть большой большой проблемой. Просто дорого и мы просто мы не можем этого явно
увидеть. Поэтому выкинуть в общем случае нам плыжновато. Окей, с этой проблемой разобрались?
Ну что ж, давайте тогда пытаться это чинить. Да?
Что разошелись объекты?
Вы имеете для одного и того же признаков описания два разных ответа?
Ну окей, ну так бывает. Например, ну есть понятие выбраться, где у вас для нормального объекта
абсолютно неправильный ответ, например. Или у объекта в принципе неправильный признак
описания. С этим придется работать, так как мы если мы не можем их отфильтровать,
значит придется строить такие модели, которые устойчивы к наличию выбросов. Правильно тоже
поговорим. То есть в общем случае, смотрите, когда мы решаем с вами оптимизационную задачу,
вот методом оптимизации в принципе оптимизируем функционалу абсолютно по барабану, что у нас там
с данными. Грязное, нечистое. Мы засунули на вход выборку, по сути мы засунули систему линейных
уравнений, ответов по сути ограничения мы дали. Оно нашло ответ. Все. Так что если у нас плохие
данные, это наша с вами проблема. Мы с этим будем жить. На самом деле принцип, ну его обычно по
английски называют garbage in, garbage out, он работает почти везде. Если у вас плохие данные, у вас могут
быть хоть идеальные модели, у вас будет плохое предсказание. Так что нам придется как-то чистить
данные, строить более устойчивые модели и вообще оценивать насколько плохие у нас данные. Ответил
наш вопрос? Супер. Ладно, матрица может быть выраженной. Давайте вам на примере как раз покажу. Вот
собственно ситуация, где у нас два признака или там несколько признаков, короче зависимые между
собой, в простейшем случае два признака линей независимая. Матрица X и X соответственно выраженная.
Вот у нас есть истинное значение omega true, мы с вами на семинаре сегодня ровно проделаем, это оттуда
скриншоты. Допустим вот 268, минус 0.52, минус 1.12. Второй-третий признаки между собой зависимы, то есть это
почти один и тот же признак, с точностью дам до какого-то маленького-маленького шума. То есть
мы все еще можем обратить матрицу X и X, но ошибка у нас большая. Вот аналитическое решение,
которое мы получаем буквально формулой за пистом. X и X минус 1, X и Y и так далее. Смотрите,
первый член абсолютно правильно определен, с точностью до того, что у нас присутствует небольшой
шум данных, то есть 268, два знака после запятой, правильно. Второй-третий член, минус 186, 184, ровно
то, о чем я вам говорил. Но обратите внимание, сложите второй-третий признаки, веса точнее их.
Получится примерно минус 0.6. Фу, минус 1.06, согласны? Здесь положите. Получится то же самое. У нас
одно ограничение, потому что у нас по сути признак один, но он дважды продублирован. У нас одно
ограничение, поэтому на их сумму у нас ограничение есть. На каждой подельности у нас ограничений нет.
У нас любая комбинация может этому быть равна. Ну, собственно, возникает вопрос, а что с этим делать?
Там уже маленький спойлер был, где-то полсекунды. Что делать, если мы с вами не
можем эту матрицу обратить? Вообще, что делать с матрицей, если она необратима? Пошуметь?
Классно, зашуметь. Но вот мы с вами зашумели матрицу, но мы с вами при этом потеряли
достаточно много информации из-за этого, потому что мы шум добавили прям явно туда. А чем больше
у нас, грубо говоря, чтобы у нас матрица была точней выраженная, шум должен быть достаточно
большой. Потому что если у нас шум будет крайне маленький, то он мало повлияет на определитель,
и, соответственно, у вас матрица все еще будет очень близка к выраженной. Что еще можно сделать?
Убрать скоррелированные признаки можно, но если мы их знаем. Если у нас там 10 тысяч признаков,
и у них зависимости крайне сложные, то их сложновато убрать. Что еще можно сделать?
Классный вопрос. А в чем вообще беда? У нас получилось два признака, они в
сумме дают что-то там правильное. Они же все равно правильную сумму-то дают. А ответ на самом деле
простой. У нас данные на самом деле всегда содержат в себе шум. И, во-первых, у нас вот эти
параметры конкретно, значения параметров подобраны под шум в обучающей выборке, и, как правило,
очень часто у нас будут получаться значения, которые почти противоположны друг другу. Потому
что они как раз подстраиваются под шум, характерное значение шума маленькое относительно признаков,
поэтому пытаются настроиться именно на шум, поэтому эти значения большие. Но на новых данных,
которых мы не видели на этапе обучения, шум будет другой. Потому что он случайный, он каждый раз
случайно генерируется. И у нас может казаться, что вот на этот признак, условно, прилетело значение
шума 0.1, а вот на этот не прилетело. И у вас целевая перемена завышена на 186,0 на 10. Потому что мы
вот за счет вот этих вот величин начинаем переобучаться под обучающую выборку. То, что у нас
два параметра для того, чтобы запомнить только одно значение. Соответственно, у нас по сути один
параметр есть, чтобы запомнить что-то специфичное только обучающей выборке. Абсолютно значить? Не,
надо уменьшить. Классное замечание. Собственно, мы к нему сейчас придем. Коллеги, смотрите, на это
очень полезно смотреть, с какой стороны, и я неспроста вот так медленно это все разжевываю. Я хочу,
чтобы вы до этого прямо сами додумались, а не просто я вам это сказал. Мы же с вами изначально
сказали, у нас проблем в чем? У нас с вами решений множество, вообще континуум. У нас не единственное
решение, правильно? Если у нас не единственное решение, мы бы хотели все-таки одно решение как-то
получить. Согласны? Решать другую задачу. Классно. Какую? Смещенную. Ну классно, вы понимаете,
о чем речь. Супер. Давайте тогда наложим какое-то дополнительное ограничение на наш вектор весов.
Вот тут было классное предложение. Раз у нас присутствует шум, шум случайный, особенно на тестовых
данных, тогда давайте потребуем, чтобы, например, этот вектор был наименьший по какой-нибудь норме.
Ну, например, тогда, если у вектора маленькая норма, значит у него все члены тоже маленькие.
Согласны? Но норма это все равно, если ограничивать норму, ограничивать значение членов. Я согласен.
Можно это посмотреть, на самом деле, с другой стороны. Можно посмотреть вот на эту матрицу.
На самом деле, как из выраженной матрицы сделать невыраженную. Вот проще, чем зашумить. Мысли
более детерминированно. Ну, например, прибавить единичную. Она явно диагональная, тогда у нас
получится явно невыраженная матрица. Заметьте, эта матрица квадратная всегда. Согласны? Так что,
если мы добавим к ней диагональную матрицу, то мы получим невыраженную матрицу. На самом деле,
то, что мы сказали, это плюс-минус одно и то же. И это, по сути, называется регуляризация по-тихому.
Мы можем с вами всегда добавить единичную матрицу. Ну, домножим на какой-то коэффициент лямбда. И на
самом деле, тогда вот эта матрица у нас явно будет невыраженная. Её всегда можно обратить. Согласны? И
это у нас будет решением вот такой задачи оптимизации. Вот этот вывод мы вас сейчас попросим сделать
самостоятельно. Это можно вывести на семинаре, но практика краски. Он отличается от вот этого на
две строчки, поэтому я вас прошу сделать самостоятельно. Окей? Можете считать частью
домашней. Собственно, вот наш функционал. И теперь мы помимо средней квадратической ошибки
минимизируем вторую норму вектора весов в квадрате с коэффициентом лямбда. Вот. Что такое лямбда?
Лямбда, по сути, это гиперпараметр, который говорит нам, насколько важно для нас, чтобы норма вектора
весов была маленькая. То, что мы теперь, по сути, два функционала минимизируем. У нас вот этот
функционал хочет лямбду как можно более подходящей, чтобы ошибка на выборке обучающей была минимальной.
А этот функционал говорит, что не, слушай, давай-ка Омега у нас будет как можно меньше, потому что
иначе штраф большой. По сути, мы пытаемся с вами решить две задачи, которые в разные стороны нас на
самом деле тянут. Но здесь на самом деле есть еще один большой плюс. Если у нас ситуация невыраженная
и все хорошо, то у нас вот эта задача имеет единственное решение. Все прекрасно. Если у нас
решение здесь не единственное, у нас вот эта задача минимизации все равно имеет единственное решение.
То есть среди всего континуума значений, которые заставляют одинаковое значение функции потерь,
только одна пара даст нам, не одна пара, одно под множество значений весов, даст нам минимальное
значение функции ошибки. Но почему? Что такое вторая норма квадрата? Это сумма квадрата. Это выпуклый
функционал. Согласны? Согласны. Тишина. У пара был один минимум. Точно? Ну, короче, мы делаем задачу
выпуклой, грубо говоря, за счет этой регуляризации. И, собственно, отсюда и появляется вообще у нас
в курсе термин регуляризация. На самом деле регуляризацию называют, опять же, от английского языка,
ограничивать. Мы, по сути, дополняем нашу задачу некоторыми ограничениями, потому что мы не можем
решить исходную задачу единственным образом или таким образом, чтобы это удовлетворяло нашим
интересам. Мы не знаем, какое именно решение выбрать, поэтому мы дополнительное ограничение кладем.
Например, накладываем, чтобы у нас норма вектора в основном была минимальна. Тогда решение единственное,
плюс мы уже знаем, какие свойства ожидать от нормы нашего вектора весов и от вектора весов,
соответственно. Смотрите, почему такая функция потерь? Ровно потому, что у нас просто, по сути,
добавляется вторая норма вектора весов. Со чем? Со второй нормой вторая норма вектора весов,
а лямбда это просто коэффициент, в котором мы ее вкладываем. По сути, это коэффициент регуляризации.
Чем больше лямбда? Ну, предположим, мы лямбду стремили в бесконечность. Там где-то вот она очень
большое число. Тогда для решения задачи оптимизации, какое решение будет оптимальным?
Ну, примерно да, нулевые веса, потому что у нас вклад вот этого члена будет много больше,
чем вклад вот этого члена. Если лямбда близка к нулю, то какое решение оптимальное? То,
которое позволяет переобучиться под этот функционал. Лямбда это просто наш, грубо говоря,
регулятор, насколько важно нам получить невыраженное решение. Все.
Эта схема работает всегда в том, что если вы к невыраженной матрице добавить диагонально,
она выраженной не станет. О, кстати, кстати, кстати, кстати, кстати, кстати, вот тут квадрат не
хватает. Ну, в смысле, лямбда должна быть положительная. В такой формулировке, вот,
прошу прощения, с опечатком. Ну, тут или ограничение, что лямбда больше или равна нулю,
или, соответственно, здесь надо везде квадрат писать. Окей, чтобы вас не запутать.
Не, смотрите, мы реальное значение с вами уже никогда не узнаем почему, потому что если у нас
с вами два признака, грубо говоря, дублируют друг друга, то вот у вас 2, вес 1, вес 2. Вы только знаете,
что вклад вес 1 и вес 2 вместе равен 1. Нет никакого правильного значения признака веса для веса 1 и
вес 2. Поэтому мы с вами, собственно, и разрешаем эту неопределенность, говоря, окей, выберем тот,
который доставляет на меньшую норму векторовесов. Если лямбда больше или равна нуля, матрица не станет
выражена и почему. Смотрите, что у нас здесь стоит? X транспонировано X. На диагонали что стоит?
Что? Это что вообще? X транспонировано X, что задается в точке верения там аналита или нала?
Вам слово квадратичная форма ничего не говорит? Ну, смотрите, у нас, собственно, здесь на диагонали
будут стоять квадраты X. Мы к ним добавляем строг не отрицательную диагональ все остальной нули.
Невыраженная она будет. Так, хорошо. Собственно, еще раз повторяю. Да. Какую? Смотрите, тут можно
зайти с двух сторон, собственно, они на самом деле эквивалентны. Мы можем сказать, эта матрица
выраженная, сделаем ее невыраженной как? Добавим к ней диагональную матрицу. Ну, например, лямбда,
опять же, здесь лямбда не отрицательная, здесь тогда квадрат по-хорошему надо добавить, это
опечатка. Тогда матрица невыраженная. Но это эквивалентное решение вот такой задачи. На самом
деле я не уверен, как было изначально, то есть можно просто добавить ограничение на нашу норму
векторовесов и получится, что есть аналитическое решение, которое ровно такой формат имеет. То есть
с двух сторон приходим к одному и тому же. Вот. Ладно. И почему это называется, еще раз, регуляризация?
Ограничение, которое мы наложили. На всякий случай, вот эта вот норма вторая векторовесов,
это далеко не единственный способ регуляризации, мы с вами их десятку видим. Можно ограничивать
количество признаков в модели, можно ограничивать ее структуру в нейронках, глубину дерева в деревьях,
другую норму взять, что угодно. Любое ваше априорное предположение, которое вы накладываете на
решение задачи, это ваши ограничения, ваши регуляризации. И с регуляризацией, как и со всеми
предположениями, работает какое правило? Если у вас хорошее предположение, которое подходит под
решение для задачи, вы получаете хороший результат. Если ваши решения противоречат задачи, то от них
станет хуй. Поэтому нет такого правила, что с регуляризацией всегда лучше. Окей? Да. Лямду
выбирать из соображений того, что у вас есть гиперпараметры, гиперпараметры, как правило,
подбираются на кросс-валидации. Про кросс-валидацию мы в конце лекции как раз поговорим. То есть гиперпараметры
мы не можем автоматически подобрать, мы их выбираем, например, по качеству поведения нашей модели на
валидирующей выборке, то есть на отложенной выборке. Хорошо, еще вопросы тут есть? Окей,
я тогда сразу маленький спойлер делаю. Я думаю, многим из вас очевидно, что вторая норма, это далеко
не единственная норма, которая здесь может стоять. Согласны? С второй нормой есть только одно
важное замечание. Для второй нормы у нас есть аналитическое решение, что с регуляризацией,
что без регуляризации. Это, наверное, единственный случай, где в линейной регрессии есть аналитическое
решение. Вы можете сюда первую норму подставить, решаться это будет, но только градиентным методами
аналитического решения уже не будет. И вторая важная вещь про вторую норму. Теориям Гаусс Маркова.
Теориям Гаусс Маркова дает нам очень важные гарантии, на самом деле, и это та причина,
почему среднюю квадратичную ошибку вообще любят, в том числе. Вот у нас есть наша целевая
переменная. Заметьте, это уже не наша оценка, это вот наше предположение, что есть целевая
переменная, которая зависит от XA линейным образом, но в наличии также какой-то шум. Идет?
Все согласны. Так, на всякий случай, а кто вообще знает теорию Гаусс Маркова? Никто. Классно. Не,
ладно, бывает. Поэтому мы ее разбираем. Еще раз, ε это у нас случайно величины, это наш шум. Данных
присутствует шум. Всем окей это, правильно? Наши предположения, во-первых, эти у нас величины
независимы, на самом деле, в идеальном случае, когда мы хотим. То есть в идеале наш шум должен
быть независимый. Почему? Потому что если наш шум зависимый, то, в смысле, он от переменной как-то там
зависит от XA, например, то что-то это на шум не похоже, на самом деле. Но теориям Гаусс Маркова
делать, на самом деле, три очень маленьких и простых предположения. Во-первых, у нас шум не
смещенный. То есть мат ожидания каждого ε равно нулю. То есть мы можем как завысить наше
предсказание, так и занизить. Хорошо? Целевой пример. Во-вторых, у нас есть какая-то дисперсия,
которая конечна. То есть у нас нету случайных величин здесь, которые имеют бесконечную дисперсию.
Мы не можем получить, как бы, с какой-то значимой вероятностью там отклонения в десятки миллионов.
Да? Да, конечно. Хорошо. И третье, собственно, у нас для всех и не равно 0, ковриация между ними
равна нулю. Шутка ковриации все помнят? Хорошо. Вар дисперсия варианс. Ну можно еще написать вот
такую D, но лотех в ней не умеет. Поэтому написано вот так. Вот, три условия. Все условия понятны,
правильно? Еще раз, у нас все ошибки несмещенные относительно нуля. У нас есть конечная дисперсия
и ковриация наших ошибок равна нулю. Да, в данном случае давайте будем считать просто
фиксированная дисперсия, окей? Которая конечна, главное. На самом деле можно пойти на какие-то
обобщения, чтобы даже были разные дисперсии, лишь бы они были все конечны, но пока вот просто
равно сигн. Хорошо. И, собственно, в этих предположениях вот это решение, которое мы
с вами только что видели. Омега транспонирована х, х транспонирована х-1, х транспонирована у,
то есть решение задачи на меньше квадратов является оптимальным среди несмещенных. Говоря
по-русски или по-английски best linear unbiased estimator. Наилучшей среди несмещенных. Вопрос,
собственно, такой. Во-первых, что значит несмещенных? Без лямбда. Хорошо. А на практике что значит?
Мат ожидания кого? Бинго. Наша оценка является несмещенной, у нас же омега с крышкой, что будет?
Она же у нас зависит от каких-то случайных величин, правильно? Вот у нас тепсилы сидят,
так что это по сути тоже случайная величина. Мат ожидания омеги с крышкой равно омеги. Это
значит, что наша оценка несмещенная. Вот. Это решение заставляет нам несмещенную оценку. Это раз.
Просто обращаю ваше внимание, потому что иногда начинают говорить, что у нас несмещенная оценка
у. Тоже вариант, но в данном случае теорема гласит именно обоим. На что значит всё это наилучшее?
Ладно, что такое линейное, понятно? А что про эффективную говорили? Окей, что такое эффективная
оценка? Да, на самом деле. Можете ещё рассказать? Опять же наименьшую дисперсию имеет кто? Бинго.
Смотрите, наилучшая или оптимальна в середине смещенных. Омега с крышкой, во-первых, несмещенная,
то есть мат ожидания омеги, равно омега с крышкой. И у неё наименьшая дисперсия опять же у омеги с
крышкой. Не у какой-то там ошибки, у чего-то. Окей? Собственно, у нас есть гарантия. Эта теорема
на самом деле оказывается в три строчки. Можем доказательный семинарию или сделать самостоятельно
опять же на лекцию. Я стараюсь доказательств теорем не вытаскивать. Это решение у нас является
оптимальным в середине смещенных. Окей? Мы-то на практике с вами не знаем реальное значение,
но мы с вами знаем выборку. У нас есть выборка. И мы можем получить оценку наших параметров на
основании выборки. Вот с такими предположениями, тремя, оценка, которую мы получаем вот отсюда,
будет оптимальным. Х и Х? Вот как раз-таки это очень хороший вопрос. Здесь мы предполагаем,
конечно, что она обратима. Если она не обратима, то мы это просто посчитать не можем. И вторая
проблема, если она, скажем так, обратима, но почти выражена, тут возникает другая проблема,
что у нас вычислительная точность наших машин конечна. Поэтому чем ближе она к сингулярной,
тем больше у нас здесь будет вычислительная ошибка. То есть это конечно работа, когда мы можем
посчитать омегу. Если у нас матрица выраженная, то у нас вообще не существует такой оценки,
потому что она не единственная. Хорошо. Ну и теперь, собственно, пара замечаний. Смотрите,
возвращаемся назад. Вот у нас с вами минимизация среднеготоритичной ошибки. Задача линейной
регрессии. Теория Магауса Маркова работает? Предположение о тех свойствах шумов наших данных.
Ещё раз. Минимизируем вот эту функцию ошибки. Теория Магауса Маркова работает,
если эти три предположения выполняются? Да, классно. Минимизируем вот такую, вот
такой функциональный амперический риск. Теория Магауса Маркова работает? Почему? Ага, классно.
А решение у нас какое? Бинго. Ребят, ещё раз. Теория Магауса Маркова гласит, что вот это решение
является оптимальным решением для задачи на меньше квадратов. То есть для минимизации среднеготоритичной
функции ошибки только. Всё. Если вы добавляете вот сюда любую другую функцию, любой другой
функционал, если у вас не прост среднеготоритичная ошибка, у вас уже посылка теория Магауса Маркова
неправильно. Вы не задача на меньше квадратов рассматривать. Поэтому теория Магауса Маркова работает
тогда только, когда у вас минимизируется среднеготоритичная функция ошибки. В данном
случае у вас уже появился второй член. И здесь на самом деле можно увидеть ещё одну вещь. У вас
оценка будет априори смещенной. Почему? Потому что для минимизации среднеготоритичной функции
ошибки вы явно не хотите минимизировать норму вектора весов. Собственно, у нас добавление
регуляризации, как правило, даёт нам смещенное решение, потому что теперь относительно изначального
оптимума нашего функционала мы ищем другой оптимум, который обладает заданными нами
свойствами. Нет. А как? Мы с вами, смотрите, мы с вами сделали по сути что? У нас была изначальная
оптимизационная задача. Мы сказали, что мы не можем её решить либо технически, либо у неё не единственное
решение. Мы придумали, по сути, как поставить новую оптимизационную задачу. Вот она теперь, вот её мы
решаем. И, собственно, для этой оптимизационной задачи найти решение. Вот её мы решили. Мы не решали
другую оптимизационную задачу. Мы не знаем какое у неё решение. У нас нет обратного хода. Мы
решили ту задачу, которую мы поставили. Да? Да. Там В с крышкой был набор случайных величин, в
теории, так как у вас Х, в общем случае, это всегда реализация, как и Y, реализация случайной величины,
вы получили точно так же оценку. Это набор чиселок. Конечно. Смотрите, вы, собственно,
и получаете, на самом деле, когда вы средний квадрат ошибки минимизируете, вы считаете
краски мат ожидания вот этой величины. Всё правильно. Вот. Добавляя по одному признаку. Да,
смотрите, вы предлагаете... Замечательный комментарий, собственно. Коллега ваш предложил
отфильтровать признаки, то есть отобрать только те, которые образуют некоторые линии независимые
под выборку. Да, так можно делать. Такие подходы тоже есть. Отбора признаков. Итеративные. Минус
в том, что когда у нас, опять же, очень много признаков, например, там десятки тысяч, это
очень дорого вычислительно. Вам для каждого надо всё равно тогда решить оптимизационную задачу,
причём для каждого подможества выбрать оптимальный, повторить. Это просто дорого. Вот.
Собственно, а с регуляризацией плюс в чём? Да, мы получаем смещённое решение. Но, во-первых,
у нас от лямбды зависит, собственно, насколько сильно оно будет смещённым. Чем меньше лямбда,
тем меньше у нас смещение. Во-вторых, решение вы всё равно получаете, которое обладает заданными
вами свойствами. Даже если там есть краски зависимые признаки, вы точно знаете, что их
суммарный вес будет близок к оптимальному, а каждый вес подельности будет вообще минимальный из
возможных. Потому что, начиная в квадрате, он сразу будет выше. Вот и всё. Так, понятно? Ещё раз,
что такое оптимальная середина смещённых? Понятно? Обладает наименьшей дисперсией. То есть,
любую другую оценку вашей матрицы весов вы можете сделать, но дисперсия вот этой случайной
величины это случайный вектор. Потому что он зависит от случайных величин. У неё дисперсия будет
выше. Настолько, насколько подходит линейный модель для вашей задачи. То есть, если вы пытаетесь
условно параболу линейной моделью описать, то у вас в принципе не очень подходящий класс моделей
используется для решения задач. Ещё раз, это теоретический результат. То есть, это обосновывает нам,
что в хорошем признаковом описании у нас решение задач на меньше квадратов обладает хорошими
свойствами, что это оптимальная оценка средней смещённой. Нет, смотрите, вот речь только про
линейные модели. Всё, вот и начальная постановка. Если у нас зависимость не линейной модели,
не линейной, никаких опять же договорённостей у нас нет, у нас условия теремии выполняются.
Вот, хорошо, да. И да, и нет. Смотрите, ещё раз. А теперь, собственно, когда брать какую норму.
Давайте сейчас покажу, что бывает, например, первая норма, что вы понимаете и сами, но какие у неё
есть свойства. Но, во-вторых, норм можно брать раз. Собственно, здесь мы подходим с вами опять к
очень важным факту. Так, вам видно там справа? Я не сгораживаю. Смотрите, если модель смещённая,
значит она решает не ту задачу, которая у вас, вот, тогда она решает, например, не минимизацию,
как бы, той функции ошибки. Короче, если у вас модель смещённая, значит она не минимизирует
чистой функции ошибки. Смотрите, что такое, давайте я ещё пару тогда этих терминов веду. Вот есть
функция ошибки. Её, на самом деле, очень часто путают в интернете друг с другом. Давайте называть так.
Функция ошибки — это именно вот ошибка предсказательной нашей модели. То есть насколько мы ошибаемся,
предсказывая целевую величину. Вот будет эта функция ошибки. Хорошо? Вот всё вместе можно
назвать там, например, функционал имперического риска. Потому что это ошибка плюс какая-то
регулярность. Это ровно тот функционал, который мы с вами минимизируем. Несмещённая у нас оценка
тогда, когда минимизируем чистую ошибку. Если минимизируем что-то там ещё, то к правилам
получаем смещённую. Потому что на этом можно на самом деле посмотреть абсолютно банально со
второй стороны. Смотрите. Вот у вас 1 функционал, 2 функционал. Те же помнят, что градиент можно
посчитать. И мы на самом деле сейчас про это говорим, можем градиентными методами найти
оптимальное значение матрицы Омега. Ну или вектор Омега в данном случае. У вас градиент,
производная сумма чему равна? В сумме производных. Поэтому у вас для Омеги будет отсюда идти градиент,
который тянет её в сторону оптимальной оценки краски. И отсюда будет идти градиент, который тянет
её в ноль. Вот откуда у вас появляется смещение. У вас оценка Омеги по сути съезжает в сторону
вот этого градиента. Это совсем на пальцах, если. Ну так это и есть то же самое. У вас то, что Омега
с крышкой теперь тянется в сторону нуля, это смещает её относительно мат ожидания. Потому что иначе
бы она кратки была в мат ожиданиях, которая вот эту штуку минимизирует. Окей. Так, на всякий
случай это тогда тоже можно проделать дополнительно. Так, коллеги, давайте так. Вот, что такое оценка
максимального правдоподобия? Кто помнит, вообще знает. Понял, тогда про это можно прямо отдельно
до семинара провести, собственно. О чем речь? Мы с вами на самом деле... Ну вот, как раз когда
обсудите, мы здесь на семинаре тоже можем обсудить. По сути, когда мы с вами минимизируем среднюю
квадратичную ошибку, мы по сути ищем оценку максимального правдоподобия для средней...
Когда минимизируем среднюю квадратичную ошибку, мы ищем оценку максимального правдоподобия в
предположении, что у нас краски и ошибки нормально распределены. Вот все. Эта краска будет средняя. Нет,
это на статистике прямо отдельно выводится где-то полсеминара. Я поэтому и говорю, кто знает, мы это
можем на каком-нибудь допсеминаре провести, потому что сейчас у меня записи нет, я это буду из ума
выводить минут 20, наверное. Извините. Да? А, это да, сейчас я его потрогаю. Вот, хорошо. Собственно,
нормы у нас бывают разные. И возвращаясь к вопросу, а правильно ли, что всегда брать вторую норму и не
выпендриваться? Вообще говоря, нет. Потому что выбор того функционала, который вы будете
минимизировать, опять же, зависит от вас. Это, на самом деле, одна из самых важных частей в любой задачи
машинного обучения. Не уметь там строить классные нейронки, деревья и так далее, ансамбли. Умение
правильно из неформальной задачи, ну, например, вам там научу говорит, что надо сделать то-то,
или на работе вам говорит, не знаю, менеджер, что надо сделать что-то другое. Короче, как это обычно
говорят из бизнес задачи, ну или из научной задачи, формулировать уже математическую
это скажу. Минимизация квадратичной ошибки дает нам среднее, минимизация
абсолютной ошибки, то есть, например, первые нормы, будет давать нам медиану. Как
-то доказать краски можем с вами сделать сегодня, например, после там
семинара в конце. И, собственно, нормы бывают разные. На практике, как правило, в
задаче регрессии применяют в основном две. Ну ладно, три. Первая это квадратичная
ошибка, это, наверное, 70 процентов всех случаев. Вторая это средняя абсолютная
ошибка, или же их называют МСК и МАЕ на том, что mean squared error, mean absolute error.
МАЕ это сумма модуля отклонений, и, соответственно, для нее мы точно так же
можем все посчитать, но для нее нет аналитического решения. Градиентная, хотя
все еще присутствует. И, собственно, третья функция ошибки, которую часто еще
используют, это так называемая квантильная функция ошибки. Короче, там у вас
зависимости от того, какой у вас квантиль важен, например, вам сильно важнее там
не завышать, чем не занижать. У вас может функция ошибки иметь какой-нибудь вид, типа вот
такая галочка, здесь она плавно, растет здесь быстро. Но все понимают, что у нас
для модуля график, как вы, просто галка, правильно, отклонения. Причем с углом 90
градусов. У вас угол, на самом деле, может быть другой. Такую функцию ошибки тоже
можно подобрать, она иногда тоже подходит. Причем этот угол даже является
гиперпараметром, ну там можно подбирать и так далее. Вот. Все. Вот у нас есть раз-два
именно для функций ошибок. Но также у нас есть и регуляризация, которую точно
также можно использовать со второй нормой, с первой, с четвертой, если вам вдруг
захотелось, на практике обычно используют, и так далее. И на всякий случай, только
вот этот случай MSE без регуляризации работает с теориями Гаусса-Маркова. То, что
он в условии теориями Гаусса-Маркова стоит. Мы решаем задачу на меньше квадрат.
Все. Линейная модель. Все остальное, как бы, это что-то там другое. Так что, если вы
добавили регуляризацию, вы добавили свои ограничения на задачу, но вы ушли от
изначальной задачи найти оптимальную оценку, чтобы минимизировать ошибку. Вы что-то
другое уже решаете. Поэтому оценка у вас априори смещенная, вы другую задачу
решаете. За это вы получаете какие-то хорошие свойства. Например, она у вас более
устойчивая. Устойчивые краски под устойчивостью будем понимать следующее.
Это такое, так сказать, определение. Оценку будем называть устойчивой, если
малое изменение обучающей выборки приводит к малому изменению вектора
параметров. То есть, если условно мы на Эпсилон, грубо говоря, изменили выборку,
но там шум чуть-чуть поменяли, у нас матрица весов тоже поменялась не больше, чем на Эпсилон,
например. Потому что, если у нас, например, наша ситуация выраженная, наша матрица выраженная,
регуляризации нет, вы можете чуть-чуть шум поменять. Мы это с вами на семинале опять же
сделаем. Здесь может оказаться 50-50, например. Видите, шум там будет меняться на 10-1, 10-2,
а здесь будет меняться на 10-2. Вот, значит, оценка неустойчивая. Поняли, согласились,
ловили? Вопросы, комментарии? Ну, собственно, как это происходит? Во-первых, если у вас есть
возможность на некоторых, на различных выборках ее посчитать, ну, например, у вас там есть две
выборки, вы можете посчитать оценку на первой выборке и на второй. Если у вас какие-то признаки
получать сильно разные веса, скорее всего, у вас оценка неустойчивая или у вас очень разные
выборки. То есть надо или надо проверять распределение у этих выборок по признакам,
или, значит, у вас оценка неустойчивая. Второе, если вы, сейчас мы дойдем до градиентов краски,
до градиентов меттов, если у вас для каких-то признаков градиенты, для весов признаков
градиенты здоровые, и они постоянно туда-сюда меняются, это тоже проблема. Вот, так, на всякий
случай, там звук работает, он не сел еще. Супер. Если он вдруг перестанет, вы, пожалуйста, это
голосуйте. Хорошо? Ну и, собственно, вот наши сравнения, наши параболы замечательные и наши
галки. На всякий случай, внимание, вопрос. У нас же модуль, функция вроде как в нуле недифференцируемая,
а что делать? Как мы вообще можем его оптимизировать? Да, то, что у вас вроде как эта функция не совсем
дифференцируемая, на практике нас абсолютно не волнует. Почему? У нас производная слева от нуля
минус один, производная справа от нуля один, производную в нуле доопределяем нулем и радуемся.
Если ошибка ноль, никакого градиента нам не надо. Все, все счастливо, все работает. Соответственно,
MSE дает нам blue best linear unbiased estimator, оптимально средний смещенный к оценку, работает с теориями
Гаустамаркова соответственно, дифференцируемо, и она чувствительна к шуму. Потому что, если у
вас, например, шум достаточно большой, то есть у вас Y, это краски, истинный сигнал, плюс какой-то
шум. Чем больше у вас отклонения, парабола вам еще и в квадрат возведет это самое отклонение.
Ошибка будет большая. А чем больше ошибка, уже с точки зрения, например, градиентных методов,
давайте сюда внимательно посмотрим. Градиент у вас здесь слева будет что? Минус два х, а справа 2х.
Согласны? Но если минус два модули х, а справа 2х. Вот. Короче, у вас х там присутствует. То есть,
чем больше у вас отклонения, тем больше у вас будет градиент, тем больше у вас каждый объект
будет влиять на решение. Она чувствительна к шуму, поэтому. Моя, собственно, у нее что?
Отклонения слева дают нам градиент минус один, справа плюс один. Абсолютно все равно сильная там
ошибка, слабая. У нас просто не попали точно в цель. Поэтому она гораздо менее чувствительна к
шумам. Улавливаете почему? Правильно? Все. Плавно. Тут всем тоже понятно. Что? Еще раз,
она не дифференцируема с точки зрения вот мотона. Нам не нужно, чтобы она была дифференцирована
всюду. Она дифференцируема на r+, то, что там всегда производная плюс один, на r-, а в нуле
просто определяем производную нулем и все. То, что у нее производная как бы не является гладкой
функцией, а нам не нужна гладкость. Нам надо, чтобы мы в каждой точке могли посчитать производную. Мы
можем. И, соответственно, с регуляризацией. С регуляризацией тоже любопытная вещь. Во-первых,
L2-регуляризация — это тот случай, когда у нас есть аналитическое решение, все замечательно. Она
дает нам более устойчивое решение, потому что у нас теперь есть единственный вектор, который
минимизирует норму вектор весов. Устойчивая, значит, при малом изменении нашей выборки у нас
будет мало изменений нашего вектора весов. А вот L1-регуляризация. Она не дифференцируема,
но нам, опять же, все равно абсолютно, потому что доопределяем в нуле нулем. То, что она не
является гладкой, нам это не требуется. Типа того, когда мы в функции ошибки добавляем норму вектора
весов. Можем взять вторую норму, можем взять первую норму. Все, собственно. Как вы понимаете,
третью норму брать немножко странновато, потому что она может быть отрицательной,
нам это вообще не надо. Окей? Ой, простите, третью норму, господи, третью. Ладно, вы меня поняли.
Да. В смысле, с функции ошибки третьей степени не надо брать, я заговорился. Да. Значение весов
или значение параметров. Да. Смотрите, я сейчас на ваш вопрос отвечу, как бы предполагаю. Так,
собственно, L2 регуляризация, как вы понимаете, работает и с МСЕ, и с МОЕ, верно? И с любой другой
функции ошибки, на самом деле. Например, на следующей неделе мы поговорим про задачи классикации,
там у нас будет лог-лоз, логистическая функция потери. Туда точно также можно запихать вторую
норму вектора весов, ничего не поменять, все хорошо. Возникает вопрос, зачем нам L1 регуляризация?
Во-первых, она дает нам чуть другие свойства, потому что, например, она отбирает признаки. Что
это значит, я сейчас скажу. Во-вторых, у нас не всегда есть требования получить наименьше значение
вектора весов, это зависит опять же от ваших предположений. А касательно того, что у вас нет
аналитической формулы, а нам все равно, даже если считать градиентное решение, у вас будет
решение, грубо говоря, не единственное, все равно вы сойдетесь согласно шуму к какому-то решению,
если вы используете выраженную матрицу, просто градиентным методом, но она у вас, собственно,
получится тоже каким-то непонятным, каким-то вот таким может получиться и любым другим,
потому что вы под шум переобучитесь. То, что шум, у вас все равно данных присутствует. А когда вы
используете L2 регуляризацию, вы все равно получите решение, которое гораздо ближе вот сюда. Но не вот
сюда, а тут будет примерно минус 0.7, 0.8 и минус 0.8, они будут гораздо ближе друг к другу. Да, это SL2,
SL1 примерно тоже самое. Заметьте, это тоже функция, по сути, выпуклая, поэтому она все равно дает вам
какое-то единственное решение. Но оно работает чуть по-другому. И здесь обычно начинается какая-то
очень странная разговора. К сожалению, Анимашка почему-то померла. Может, на нее можно посмотреть.
Нет, нельзя, ладно, потом покажу. Ну тут просто это все должно ездить, я вам лучше сейчас на пальцах
объясню. Смотрите, L1 отбирает признаки. Вот это очень такая нестандартная вещь, от нее, к правилу,
все начинает немножко зависать. Что значит L1 отбирает признаки? Я вам давайте сейчас даже
попробую это нарисовать. Благо у нас есть доска. Пока она загружается, собственно, что сделаем? Что
значит L1 отбирает признаки? Давайте пока что подумаем. Вот мы с вами, когда решаем оптимизационную
задачу, нам нужно найти решение, которое минимизирует сумму квадратов отклонений, например, в СМСЕ. Но
при этом мы хотим еще и минимизировать первую норму вектора весов, правильно? Давайте на это посмотрим
с точки зрения градиентных методов. Что? Рисовать на черном фоне классно, мне нравится. По-моему,
так даже лучше видно. Итак, смотрите, вот у нас с вами есть, собственно, первая норма, вектор
омега. То есть это у нас получается сумма омега итой по модулю. Согласны? Давайте мы теперь попробуем
эту штуку минимизировать. Причем градиентный метод. Когда у нас получается d омега первая норма,
по d омега и будет чему равна? Ну по факту это будет плюс один, если омега и больше нуля. Ноль,
если омега равно нулю и минус один, если омега и меньше нуля. Или, что на самом деле эквивалентно,
так просто проще записать, это просто сигнум омега и. Хорошо? О, спасибо. Современные технологии.
Ладно, с этим все согласны. А теперь давайте посмотрим, предположим, что у нас какой-то
признак, например, вообще не влияет на решение. То есть он не нужен, он шумовой. Он неважно там
положительный, отрицательный вес имеет, он на решение не влияет. Тогда что мы получим? У нас,
когда мы с вами пытаемся минимизировать нашу функцию имперического риска, q от омега,
которая в общем случае равна l, это наша функция потерь. Что с тобой не так? Залипло,
наверное. Собственно, у нас есть l, это именно функция ошибки, ошибка предсказания нашей
целевой переменной. Плюс первая норма вектора весов. Согласны? Когда мы с вами считаем производную,
у нас получается dq по d омега. Это что? Это у нас dl по d омега плюс d, кратски, омега 1 по d омега.
С этим все согласны. Давайте добавлю λ. Я сейчас показываю именно тот факт, почему при лямбда равна
1 или лямбда равна 0,5, ничего не поменяется. Если у нас какой-то признак не влияет на функции
ошибки, то что значит будет с этой производной? Она будет равна 0, потому что она от нее не зависит.
Ну или в среднем равна 0, потому что у нас есть шум, одни объекты будут тянуть наверх,
другие вниз, чтобы не засыпали и так далее. Да что с ними не так сегодня? Ой, ладно. Короче,
довки устали. Короче, эта штука примерно равна 0. Нет, все, да ладно, мы почти закончили. Короче,
все согласны, я надеюсь, что вот эта штуковина, она примерно равна 0, если признак не зависит.
Что у нас когда остается от градиента? У нас остается вот этот вклад, а когда вот этот вклад
будет нулевым? То есть когда у нас градиент не будет тянуть данный вес, признака куда-нибудь.
Когда он равен нулю? Потому что всегда когда у нас признак больше нуля, у нас градиент плюс 1,
соответственно антиградиент будет минус 1, всегда когда признак меньше нуля антиградиент будет
плюс 1, то есть у нас градиент будет всегда толкать значение нашего веса в ноль. Да вы меня достали,
«Господи, не вы в смысле о доске?»
Соответственно, всегда, когда значение нашего
признака не равно нулю, веса нашего признака не
равно нулю, если он неважен, то, соответственно, он будет
просто загнан в ноль, потому что вот эта штука компенсировать
это не будет, а эта штука будет его толкать в ноль.
Собственно, ровно поэтому и говорят, что L1 регуляризация
отбирает признаки в смысле того, что если у вас какой-то
признак неважен, он получит на любой вес в конце кону.
То просто, собственно, первая норма загонит в ноль.
Более того, на самом деле, тут даже что можно сказать?
Если у вас вот этот коэффициент регуляризации достаточно
большой, то есть признак все равно имеет там какой-то
мизерный градиент, то есть очень маленький градиент,
он, возможно, как-то очень мало значим для решения
задачи, а здесь коэффициент лямбда большой, то получается,
что вот этот градиент, он же всегда как бы пропорционален
единице, потому что, ну, лямбде, лямбда на единице,
потому что здесь или плюс, или минус один, поэтому
если у вас какой-то признак мало влияет на решение,
допустим, там есть какая-то связь между признаком и
целевой переменной, но она крайне там маленькая,
допустим, там влияет на нее в четвертом знаке после
запятой.
У вас L1 регуляризация с лямбдой больше, чем 10-4, все равно
загонит его в ноль, потому что отсюда у вас градиент
будет порядка 10-4, отсюда порядка единиц, уловили?
Я уловили.
Картиночка.
Ну, визуализировать, так я, собственно, и пытался
вам это визуализировать.
Смотрите, вот вам картиночка, у вас получается, что производной
здесь всегда плюс один, минус один, здесь плюс один,
если у вас производная от функции потери меньше
чем вот эта штука, она ее доминирует, значит, она
загоняет в ноль.
То, что если она вышла из нуля, она сразу получает
пинка в сторону нуля с силой 1, а функция потери с силой
меньше единицы.
Она зайдет именно тогда, где минимум.
Все, он нам больше не нужен.
Да.
А теперь посмотрим на L2, смотрите, L2 у нас какую производную
будет давать?
Два Омега.
Поэтому если Омега около нуля, то у нее градиент становится
уже меньше, чем вот этот самый условно Эпсилон, который
нам дает функция потерь, поэтому она просто загоняет
их близко к нулю, но не ровно в ноль.
L1, собственно, за счет вот этой ступеньки, у нас производная
либо минус 1, 0, 1, у нас ступенька, резкий переход, за счет
этого он ровно в ноль загоняет, а ОL2 плавно убывает производная,
чем ближе к нулю, тем меньше производная, поэтому он
их просто догоняет примерно до нуля, но не выкидывает
полностью.
Именно в этом смысле говорят, что L1 регуляризация отбирает
признаки.
На всякий случай, когда вы используете L1 регуляризации,
вы просто в векторе весов можете получить некоторые
нулевые элементы, но вектор весов будет точно такой
же размеренский.
Это частая ошибка на самом начале работы с машинным
обучением, когда ожидают, что вы применили L1 регуляризацию
и у вас почему-то вектор весов стал меньше.
Нет, конечно, у вас просто такие члены будут равны
нулю.
И именно их мы считаем выкинутыми признаками, ну и после этого
как правило есть еще подход, что после этого вы перезапускаете
вашу модель, оптимизацию, выкинув эти признаки вообще
из обучающей выборки, можете даже после этого уже L2 регуляризацию
взять и уже оставшиеся признаки просто подогнать
поближе к нулю.
Вопросы, пожелания, комментарии.
Все поняли, что L1 делает с признаками, с весами?
Тут тоже.
Зануляет, если они не важны для решения задачи, то есть
если они достаточно не важны относительно коэффициента
лямбда.
И собственно здесь коэффициент лямбда как раз явно видно,
что делает.
Если лямбда большая, то если наш признак влияет
на ошибку, на градиент ошибки меньше, чем на лямбду,
то он будет выкинут.
Если больше, чем на лямбду, то он не будет выкинут.
Все.
Вот.
И это на самом деле штука, я ее потом подвигаю, это
второе объяснение.
Что это такое?
Это шар.
Но во второй норме.
Это шар в первой норме.
Заметьте, у вас вот это, по сути, что здесь, я потом
она подвигается, я пока на пальцах опять же покажу.
Что вот это за эллипс такой?
Это линии уровня квадратичной функции потерь.
То есть линии уровня это что?
Это эквапотенциальная поверхность, то есть на линии уровня
у вас одинаковые значения функции ошибки.
Оптимальное решение у нас где-то вот в этой точке.
Мы именно в нее хотим попасть.
Но когда мы, например, говорим, что рассмотрим все решения,
у которых норма вектор весов первая равна единице,
у нас в среднем вот эта точка, вот эти точки, так как
они у нас по первой норме на шаре лежат, по сути они
в вершинах нашего четырехугольника, они в среднем будут ближе
к центру, чем те, которые лежат между ними.
Опять же, это можно формально доказать, эта штука по хорошему
должна двигаться.
Давайте я вам ее покажу.
Я надеюсь, ссылка еще работает.
Во!
Вот давайте посмотрим, скажем так, за этим, как его.
Бледите за нахождением желтой точки.
Видите, здесь она ездит совершенно свободно.
Она находится всегда на окружности радиуса единицы
от центра и абсолютно все равно у нас есть центральная
симметрия.
Здесь точка почти всегда находится в вершинах.
А это ровно есть та ситуация, когда у вас один из весов,
собственно, оси ω1, ω2, один из весов равен нулю.
Понимаете, потому что его вклад в качестве ошибки
вот здесь гораздо меньше, чем его вклад в качестве
регуляризации здесь.
Только и всего.
Это такая визуальная картинка.
Мне, честно говоря, вот это объяснение было непонятно
наверное первые года 3, как я на него смотрел, с градиентами
было гораздо проще понять.
Но кому-то возможно так понять.
Окей, тут вопрос есть?
Ну почему?
Воспроизводная тогда чему равна?
2 ω всегда.
Так, ребят, сейчас дайте мне еще 5 минут, пожалуйста,
мы тут чуть позже начали, поэтому мы не до конца
уложились.
Что?
Да, да, но ровно поэтому, чем ближе вы к нулю, тем меньше
у вас вклад регуляризации в решение.
Ну да, слушайте, я вас плохо слышу, тут уже пошел, давайте
в перерыве тогда отвечу.
Хорошо.
Ладно, ребят, собственно, бывают различные еще способы
померить качество в регрессии не только МСЕ и МАЕ, например,
есть коэффициент-детерминация R2, есть МОПЕ, средняя абсолютная
процентная ошибка, есть СМОПЕ симметричная, на них
проще на семинаре, посмотрите, они в принципе, это все
мои МСЕ, только чуть-чуть преобразованные.
Ну и последняя, но тем не менее очень важная вещь,
потому что уже второе занятие, скажем так, чисто по машинке,
у нас была еще лекция по линалу, и чтобы все модели
строить, надо уметь оценивать их качество.
И как сказал очень умный, талантливый человек, вы
ровно настолько можете доверять своей модели, насколько
вы доверяете своему пайплайну валидации.
Вот шутку о валидации я как раз сейчас скажу.
Собственно, давайте скажем, что у нас есть выборка,
мы можем решать задачу регрессии, можем решать
задачу бинарной классификации, абсолютно неважно.
У нас есть некоторая модель, которая предсказывает значение
целевой перемены для каждого объекта.
Наша задача – минимизировать вот эту самую функцию имперического
риска, ну или функцию потери, опять же, на практике ее
просто всегда вызывают функции потерь, главное понимать,
что вы в это вкладываете, включает она в себя регуляризацию
или нет.
Собственно.
И у нас может быть три ситуации.
Собственно, недообучение, модель слишком простая
для решения задач.
Собственно, линейная модель, например, пытается, мы
пытаемся ее использовать в явно нелинейной задаче.
Тогда все плохо.
Может быть, хорошая модель, вот то, что мы всегда хотим,
может быть, переобучение, когда модель, по сути, запомнила
ответ на каждом объекте и явно вот такая поверхность
решений как-то больно сложной выглядит для такой задачи.
То есть, что такое оптимальная сложность модели, на самом
деле, можно долго говорить, и это зависит от того, что
мы сформулируем как оптимальная модель.
Но есть вот эта классная картинка из книжки Гудфеллу
и Бенджоу.
И Арен Курвилла, она у нас вторая в списке рекомендованной
литературы.
Собственно, здесь у нас по оси х ошибка, по оси y у
нас, скажем так, сложность модели, капасти, то есть,
количество степеней свободы модели, грубо говоря.
Можете очень грубо это оценить, как количество параметров
модели.
Хорошо?
Сколько данных она может запомнить?
И, собственно, у нас есть две ошибки.
Тиненькая.
Это ошибка на обучающей выборке.
Она у нас снижается примерно к нулю.
Она может достичь нуля, если у нас нету явно шума
в наших данных.
Она не может его достичь, если у нас, например, два
объекта одинаковых с разными предсказаниями.
Тогда не сможешь ничего сделать.
А вот у нас ошибка обобщающая, ошибка обобщения или generalization
error или ошибка на отложенных данных.
Как видите, она до какого-то момента снижается вместе
с ним, а потом начинает краски расти.
Это называют переобучением, когда наша модель переобучается
под обучающую выборку, то есть запоминает специфичные
вещи только для обучающей выборки.
Но это красивая теория.
Тут, на самом деле, есть еще у этой картинки продолжение.
О нем говорят последние годы, и все еще идут научные
изыскания.
Непонятно, что происходит.
Называется она Double Decay.
В некоторых случаях вот эта штука может начать расти,
а потом опять начать падать.
Но это конец второго семестра.
Возможно, про это поговорим, если будет именно как это
обосновать то, что есть просто несколько работ на
эту тему научную, где говорят, ну вообще так бывает.
Вот.
Собственно, недообучение и переобучение.
Проблема в чем?
Если вы модель сделанной слишком простой, усложнить
ее вы всегда можете.
Если слишком сложной, можете ее всегда упростить.
Но, собственно, как понять, насколько ваша модель
переобучена?
Что она недообучена?
В принципе, можно понять достаточно легко, у вас просто
качество в модели недостаточно хорошее.
У вас либо данные плохие, либо модель недообучается.
Именно на обучающей выборке.
Что делать, если модель переобучается?
Вы для этого сначала должны обнаружить переобучение.
Потому что вы не знаете, как ваша модель себя ведет.
Где-то кроме обучающей выборки покажут.
Поэтому можно использовать, скажем так, метод отложенной
выборки.
И я не рекомендую его использовать сейчас, когда мы будем говорить
про какие-то крупные нейронки.
У нас не будет выбора другого, но тем не менее.
Как правило, вот есть такое понятие обучающей выборки
– train, тестовой выборки – test.
И я сразу скажу, что есть, собственно, валидационная
выборка.
Все, чтобы вас сразу не консьюдить, скажем так,
не запутывать.
Собственно, в хорошей нотации тестовая выборка – это то,
что у вас вообще лежит где-то вне, и вы к нему
либо никогда не получите доступа, либо вы получите
к нему доступа, грубо говоря, пройдя точку невозврата.
Ну, словно вот, тестовая выборка – это как будто
вы сдали работу преподавателю на экзамене, и уже преподаватель
вам говорит ответ, хорошо вы решили экзамен или нет.
Вот это ваш тестовая выборка.
Вы не можете сказать преподавателю, а, я здесь ошибся, дайте
я перепишу и опять ему сдать.
Некоторые пытаются, как правило, это не работает.
Валидационная выборка – это все то, что вы делаете
у себя локально, это ваши локальные тесты на ваш код
где-нибудь там на проге, это ваша проверка своей
домашки или попытка соседа попросить проверить вашу
домашку и так далее.
То есть валидационная выборка – это то, что вы сами используете.
Поэтому у нас есть, собственно, train validation test framework.
Train – это то, на чем вы настраиваете параметры в вашей модели.
Вот именно параметр.
Валидация – это то, на чем вы выбираете гиперпараметры
и то, на чем вы проверяете качество в вашей модели.
Обращаю ваше внимание, если вы подбираете параметры
на валидационной выборке, вы уже посредством взаимодействия
самостоятельно с гиперпараметрами, точнее, переобучаетесь
под валидационную выборку и вы можете под нее переобучиться,
если будете долго это делать.
То, что у вас, по сути, утечка данных идет через
вас в ваши гиперпараметры.
Если достаточно долго будете это делать, вы подберете
оптимальный для вашей валидационной выборки, но не факт для
всего распределения, откуда приходят данные.
собственно что можно делать вариант где вы просто от рейна отрубили тест один раз на нем
проверились идея плохая почему то что как минимум вы можете случайно выбрать плохую под
выборку на которую будет тестироваться но например у вас сюда попали только объекты класса 1 тогда
если у вас абсолютно тупой классикатор который умеет предсказывать только объекты класса 1 у вас
100 процентная accuracy у вас все правильно по факту ваш классикатор мусор ну или у вас здесь просто
или здесь у вас только студента например у вас задача там не знаю предсказание среднего дохода и
у вас несколько социальных групп короче как дробить данные там будет различность процедуры
стратесикации нормализация так далее про это мы тоже поговорим собственно как делать пока у вас
маленькие модели это вот примерно до восьмого занятия нашего курса пока мы делаем так мысли так
делают всегда когда маленькие модели когда не слишком много данных когда мы себе подводим можно
собственно или разделить выборку над train validation и тест вы можете либо выбрать
валидацию прям вот очень хорошо проверить все статистики классно пока выборка маленькая
можно сделать сильно проще можно использовать cross валидацию а именно вы сразу иметь какую-то
отложенную выборку вот тест это то что у вас или вам вообще недоступно или вы изначально ее
отложили как правило тест у вас короче вы как правило тест себе не выделяете то есть тест это
либо то что вы будете сдавать там контест либо то что вы издаете на соревнования либо то что вы
завтра тестируетесь на работе на проде и так далее если все упадет плохо что я делал с
валидацией у вас есть все ваши данные обучающие вы их можете побить на различные чанки кусочки и
повторить много раз процедуру выбираем все фолды кроме одного фолт краски в данном случае ну все
куски на котором побили на них обучаемся на последнем валидируемся на всякий случай тут
написано тест волк я когда-нибудь все-таки перепишу валидационный на последнем проверяемся и
повторяем так чтобы качестве валидационного использовался каждый из фолдов который был то
есть по сути мы если у нас есть фолдов 10 раз обучаем нашу модель на различных подвыборках
10 раз тестируем на опять же различных подвыборках валидационных нас получается на самом деле 10
моделей и 10 раз мы посчитали ошибку потом можем усреднить и вот это усредненная ошибка есть наиболее
наверное качественная оценка качества нашей модели да это конечно все умеет собственно мы
с вами этот крас мы вас будем явно просить делать именно так потому что один раз побить пополам
плохая идея плюс это вам позволяет экономить на самом деле данные потому что теперь вы по сути
пробежались протестировались на все обучающие выборки и вы обучились на все обучающие выборки
тут маленькое замечание что делать когда у вас получил 10 моделей на выходе ведь у вас здесь
здесь здесь и здесь получил здесь разных моделей тут есть два варианта первая модель линейная
допустим от линейной регрессии можете банально усреднить их веса и все долго не думая второе
модели какие-то сложные например это какие-то деревья тогда потом одиннадцатый раз обучаете
модель с нужными вам гипер параметрами гипер параметры вы тоже можете подбирать по кросс
валидации просто качестве скоров вы выбираете усредненность и тогда собственно вы просто
потом берете все обучающую выборку нужные вам гипер параметры обучаете модель целиком еще раз
но уже с теми гипер параметрами которые у вас были а как обнаружить пере обучение
нет две вещи первое вы можете так посмотреть вы подкрутили гипер параметры посмотрели на кросс
валидации как поменялся скор стало лучше или хуже на отложенных данных второе вы тем самым
детектируете пере обучение если у вас начинает резко расходиться качество на обучающей выборке
и на валидационной то тут два варианта либо валидационная выборка плохая сильно хуже чем
обучающие либо и пере обучает кросс валидации вас по сути спасает от того что вы пере обучаетесь
то что тьфу от того что она плохая потому что вы пробежались по всем под выборком если на всех
стало хуже значит вы пере обучились под обучающую выборку да конечно то есть по-хорошему если вы
смотрите просто отклонения назначение ошибки вы смотрите на его средний по-хорошему посмотреть
именно на статистике ошибки возможно вас на каких-то классах ошибка больше и так далее
анализировать ошибку более глубоко абсолютно верно но по крайней мере вот базовая вещь вы
по кросс валидации можете выбрать себе так не выбрать а заметить что у вас на отложенной выборке
всегда ошибка сильно выше чем на трейновый на обучающей значит скорее всего слишком сложная
модель она просто-напросто пере обучается под ваши данные и вы находитесь где-то вот здесь надо
делать модель попроще и так далее вот 10 это просто количество фолдов это чем больше тем лучше но
чем больше тем дороже у вас сложность линейно растет со увеличением количества фолдов ранее
вот совсем давным-давно когда данные были маленькие отрава зеленая даже был отдельно
называемый метод л л о о ли ван аут короче оставь один то есть там в качестве трест обучающий
выборке использовал вся выборка с заключением одного объекта соответственно одном объект тестировались
но если у вас выборка размером там миллион то миллион раз обучать вашу модель вы замучаетесь
поэтому условно обычно будет там на 5 10 20 фолдов в зависимости от сложности то есть грубо говоря
сколько вы можете себе позволить именно поэтому кросс валидации с ким-то убер нейронками не
используется потому что обычно там одна модель обучается месяца так два на кластере сгп у если
вы будете это 5 раз делать то это почти год дорого просто дорого вот поэтому когда мы дойдем до
сложных моделей мы краски поговорим еще раз как нам выбирать уже хорошую одну валидационную выборку
там должны совпадать распределение по классам там или каким-то категориальным переменным по ошибке
короче по всему они должны визуально выглядеть как выборки из одной той же из одного это уже
распределение тогда все хорошо ну что ж она это мы подходим к финалу нашей лекции собственно
линейный модели это замечательные модели которые работают половине случаев не как говорит мой
например новочек руководитель это так называется метод палки и веревки очень простой он не может
не работать он может не работать только если у его слишком сложная задача для линии на модели
там ломаться нечему понимание линейных моделей позволит вам работать и с нейронными сетями и
на самом деле с деревьями потому что как мы с вами видим деревья это тоже в некотором смысле ли
неймуте ли просто надо очень странными признаками и собственно стройте валидацию так что вы могли
Если вы не уверены в вашей валидации, значит ровно настолько не уверены в том, что ваша модель вообще делает нефигню.
То есть вот валидация и постановка задачи оптимизации, это, наверное, два таких кругольных камня, вокруг которых строится все остальное.
Если у вас ошибка там или здесь, то остальное бесполезно.
Вот. Ну, на этом лекция завершается, перерыв 15 минут, дальше семинар.
