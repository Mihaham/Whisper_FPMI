Итак, добрый день. Мы с вами в прошлый раз выяснили следующий факт. Давайте я его немножко напомню,
потому что мы его сейчас обобщим. Факт был такой, что если у нас phi линейный оператор на
пространстве, P его аннулирующий многочлен, и он разложен в произведение двух взаимнопростых
сомножителей, то тогда всё пространство раскладывается в прямую сумму следующих двух ядер.
Ядро P1 от phi и ядро P2 от phi. Вот это мы с вами вроде как доказали в прошлый раз, правда?
Ну и нам потребуется обобщение, естественно, на случай, когда сомножителей больше двух,
то есть следствие, которое мы сейчас докажем, то же самое, но с несколькими слагаемыми. Итак,
если у нас phi линейный оператор на V, P это его по-прежнему какой-то аннулирующий многочлен,
а P раскладывается в произведение ка-сомножителей, которые, внимание, попарно взаимнопросты. То есть нот
P1 и P2 равен единице при и неравном ж. Неравном, конечно. Тогда всё пространство раскладывается
в прямую сумму ядер соответствующих многочленов, то есть ядро P1 от phi плюс и так далее, плюс ядро
PkT от phi, или, напоминаю, вот так же как со значком суммирования, можно писать вот таким вот образом.
Прямая сумма по и от 1 до k, ядер поитого от phi. Здесь и здесь написано буквально одно и то же,
просто вот я то ли напоминаю, то ли, может быть, ввожу это обозначение, которым удобно пользоваться.
Ну и если утверждение для двух многочленов у нас уже есть, то следствие получается, естественно,
практически непосредственной индукцией по k. База для k равна 2, это в точности вот наше утверждение
с предыдущей лекции. База по k равном 2 уже доказана, и давайте мы докажем переход.
Ну и для этого, естественно, мы можем опять же таки применить наш базовый случай,
поскольку у нас есть разложение нашего многочлена, вот в каком виде,
p1 и так далее, pk-1 умножить на pkT, и вот эти вот два уже сомножителя также взаимно простые,
нод вот такого произведения икатова многочлена равен единице. Почему это так, на всякий случай,
например, это следует, конечно же, из основной теоремы об арифметике, правильно? Что мы говорим,
когда мы говорим, что нод двух многочленов равен единице? Это означает, что если мы разложим каждый
из них на непреводимые сомножители, то среди этих сомножителей здесь и здесь не найдется общего,
правильно? Ну точнее не общего, а ассоциированных не найдется, потому что у нас разложение с точностью
замены до ассоциированного. Ну и тогда, мы можем вот эти вот многочлены разложить на непреводимые
сомножители, и вот этот многочлен разложить на непреводимые сомножители, у нас получится опять же
таки два разложения без общих сомножителей. А это и означает, что многочлены взаимно
простые. Вот, итак, нот этих двух товарищей равен единице, ну и следовательно мы можем
разложить В в прямую сумму двух ядер. Первое ядро будет оператора, полученного подстановкой вот в этот
многочлен нашего phi, то есть P1 от phi, P2 от phi и так далее, Pk-1 от phi. Вот ядро вот такого
вот большого оператора композиции вот этих вот всех плюс ядро Пкатова от phi. Давайте я вот это
первое ядро обозначу через U. Ну и тогда, чтобы нам применить предположение индукции, давайте мы
сделаем вот что. Давайте мы рассмотрим ограничение нашего оператора на подпространство U. Чем оно
хорошо? Оно хорошо тем, что, смотрите, что у нас написано здесь. Ну, во-первых, конечно же, давайте
я напомню, мы с вами это говорили. Вот эти вот ядра, разумеется, являются инвариантными относительно
phi, то есть мы такое ограничение рассматривать можем, правильно? Значит, это U, в частности,
инвариантно относительно phi, и рассматривать такое ограничение мы имеем право. А во-вторых,
глядите, раз U это ядро вот такого вот товарища, если мы подействуем на любой вектор из U вот этим
вот оператором P1 от phi и так далее, Pk-1 от phi, получится 0, правильно? Ну это то же самое,
что сказать, что если мы подействуем для любого вектора из U, если мы подействуем на него P1 от
psi и так далее, Pk-1 от psi, то получится нулевой вектор, потому что psi это как раз вот ограничение
phi на U, и когда мы действуем всеми вот этими вот операторами, мы за пределы U, естественно,
не выходим, правильно? Замечательно, это означает, что просто-напросто P1 от psi и так далее,
Pk-1 от psi, это нулевой оператор, он каждый вектор отправляет в ноль, ну то есть P1 и так далее,
Pk-1 это аннулирующий многочлен для нашего оператора psi, Pk ты уже не нужен, потому что мы работаем
только вот в этом вот ядре произведения первых многочленов от phi, ну и коль и так, то вот теперь
мы можем применить предположение индукции к нашему оператору psi, применяя предположение индукции к
psi и к вот этому вот аннулирующему его многочлену, получаем, что U раскладывается в прямую сумму
ядер P1 от psi, обратите внимание, прямая сумма, конечно, уже до k-1, правильно? Потому что у нас
произведение k-1 многочленов. На самом деле я могу сказать, что ядро пыитого от psi, это то же самое,
что ядро пыитого от phi, ну естественно при i меньше, чем k, то есть при наших i, эти ядра это
на самом деле ядра пыитого от phi всего. Почему это так? Если какой-то вектор, давайте вот я так скажу,
вектор лежит в ядре пыитого от phi, это означает, что Pt от phi, применённый к этому вектору, это нулевой
вектор, ну а значит, тем более, если я применю весь вот этот вот оператор к нашему вектору,
то я тоже получу ноль, потому что что такое этот оператор? Это произведение пыитого от phi,
умноженного на ещё какие-то операторы, правильно? Более того, все они попарно коммутируют, мы с вами
об этом говорили, потому что любые многочлены от phi друг с другом коммутируют перестановочно,
и поэтому мы можем этот Pt вытянуть как бы в самый конец, то есть я могу сказать, что если я применю,
давайте вот так вот, Pa1 от phi и так далее, Pi-1 от phi, Pi-1 от phi и так далее, pkt от phi,
я взял произведение всех, кроме it, а затем применю Pt от phi, ну точнее, затем напишу Pt от phi,
применю это к V, вот такое вот произведение, это что такое? Сначала, наоборот, я применяю к V
Pt от phi, получаю ноль, затем я применяю все остальные операторы, получаю тем более ноль,
конечно же, правда? Это ноль, то есть V лежит в U, ну и значит, конечно же, V лежит в ядре
Pt уже от psi. Разница этих ядер заключается только в том, что phi и psi действуют на разных пространствах,
правильно? Здесь у нас сидят все векторы из U, которые обнуляются Pt от psi, ну или Pt от phi,
здесь у нас сидят все векторы из всего пространства V, которые обнуляются Pt от phi. И вот я объясняю,
что если вектор обнуляется этим товарищем, то он на самом деле всегда в U лежит, ну и значит,
эти ядра совпадают. Ну и таким образом мы получаем уже то, что нам нужно. Наше пространство V раскладывалось
в прямую сумму U и ядра Pt от phi, U, в свою очередь, раскладывается в прямую сумму вот этих вот ядер,
Pt от 1 до k-1, ядер Pt, здесь я могу написать не psi, а phi, потому что я это только что доказал,
и все это плюс ядро Pt от phi по-прежнему. Ну а это то, что нам нужно, это как раз та самая прямая сумма,
которую мы и хотели получить. Это уже прямая сумма по I от 1 до k-1, ядер Pt от phi. Всё,
таким образом наше следствие доказано, ну и вот это вот на самом деле и есть то,
что нам в первую очередь хотелось получить, то на что мы дальше будем опираться. Итак,
мы с вами поговорили об аннулирующих многочленах, и вот, по сути дела, главное утверждение,
которое нам в дальнейшем потребуется, ну кроме некоторых вспомогательных, это именно вот это
следствие, и мы можем переходить к следующей части, собственно говоря, как эти аннулирующие
многочлены нам сейчас помогут. Я обещал, что если характеристический многочлен оператора раскладывается
на линейные сомножители, то мы сейчас, то мы сможем его привести к достаточно удобному виду,
найти базис, в котором матрица имеет хороший вид. И вот мы добрались до того пункта, когда мы можем
сформулировать этот самый вид, ну и сейчас постепенно будем доказывать эту теорему.
Жарданова нормальная форма, следующая тема. Эти слова мы будем употреблять часто, они часто
сокращаются до gnf. Почему она нормальная, я через некоторое время тоже поясню. Ну и давайте я сразу
определю, к какому виду мы будем приводить нашу матрицу. Итак, определение, самый базовый объект,
кирпичик, из которого мы будем все строить, это жарданова клетка размера n с собственным значением
лямда. Такой вот объект. Это вот какая матрица, мы ее будем обозначать через gn от лямда, g как раз от
фамилии жардана. Следующая матрица размера n на n. Давайте я сразу скажу, что она размера n на n.
По диагонали у нее стоят лямды, по главной диагонали. Непосредственно над этой диагональю,
вот в этих вот n-1 клетках, стоят единички. Все остальные элементы равны нулю. В частности,
давайте я сразу скажу, что gn от 0 мы будем обозначать просто через gn, и это матрица,
в которой всего n-1 не нулевой элемент. Единички над главной диагональю, нули везде в остальных
местах. Вот из этих кирпичей у нас будет строиться наша жарданова форма. Прежде чем двигаться дальше,
давайте я сделаю небольшое замечание и скажу, что не зря я говорю, что у этой клетки собственное
значение лямда, она верхнетреугольная. Поэтому ее характеристически многочлен
написать очень просто. Характеристический многочлен gn от лямды, это лямда минус x в n-й,
потому что мы x по диагонали вычтем, возьмем определитель, этой верхнетреугольной матрице
получим как раз лямда минус x в n-й. Вот это у нас жарданова клетка, а жарданова матрица,
это матрица, у которой на диагонали стоят жардановые клетки. Сейчас я более формально это скажу.
Жарданова матрица, я продолжаю определение. Это так называемая
блокнодиагональная матрица. Сейчас я скажу, что это такое. Блоки которой это жардановы клетки.
То есть жарданова матрица имеет следующий вид. Мы по диагонали друг за другом
выстраиваем несколько жардановых клеток. Здесь вот наверное стоит многоточие поставить.
Здесь какая-то одна клетка, здесь какая-то другая клетка и так далее. Все остальные элементы этой
матрицы равны нулю. Обратите, пожалуйста, внимание, что означает, например, что оператор в каком-то
базисе будет иметь вот такую вот матрицу. Это означает, если у меня здесь клетка размера n1,
что первые n1 векторов порождают инвариантное подпространство. и матрица ограничения на это
инвариантное подпространство это именно вот эта жарданова клетка. Они переходят линейные
комбинации из себя и там на этом пространстве организуется вот эта жарданова клетка. Следующие
n2 векторов базиса также порождают инвариантное подпространство, матрица, ограничения на которое,
Это вот вторая Жарданова клетка и так далее.
Пространство на языке линейных операторов, если оператор имеет...
Давайте мы это опять же оформим в качестве замечания.
Если оператор в некотором базе имеет Жарданову матрицу,
то мы получаем, что все пространство В распадается в прямую сумму
инвариантных подпространств, порожденных как раз вот последовательными
кусками этого базиса, инвариантных подпространств.
И матрица ограничения на каждая, естественно, в соответствующем базисе,
в базисе, составленном из фрагмента нашего вот этого базиса,
это Жарданова клетка.
Ну и вот на самом деле мы утверждаем, что к такому виду матрицу любого оператора,
если характеристический многочлен хороший, можно привести.
Точнее давайте я сформулирую теорему о Жардановой нормальной форме.
Она звучит следующим образом.
Пусть Фи, линейный оператор на каком-то пространстве В,
ну и характеристический многочлен этого Фи раскладывается на линейные
сомножители. Вот нам обычная формула.
Лямда ИТ минус Х в степени альфа ИТ.
Давайте я ее снова обозначу через звездочку.
Тогда существует базис, в котором матрица Фи – это Жарданова матрица.
Более того, есть утверждение о единственности.
Давайте мы его сейчас грамотно сформулируем и поймем, что оно означает.
Если матрица оператора в некотором базисе Жарданова,
естественно мы можем привести его к такому Жарданову виду немножко по-другому.
Например, мы можем первые два фрагмента базиса переставить местами,
и тогда вот эти клетки на диагонали тоже поменяются местами.
Так вот, это единственное, что может случиться с Жардановой матрицей.
Точнее я формулирую так.
Более того, если А и А' – это две Жардановых матрицы оператора Фи в разных базисах,
то эти матрицы отличаются лишь перестановкой клеток на диагонали.
Обратите, пожалуйста, внимание. Сейчас я написал точную формулировку,
потому что когда я немножко махал руками, я не совсем четко все сформулировал.
Я не утверждаю, что если вы в каком-то базисе получили Жардановую матрицу А,
а в другом базисе получили Жардановую матрицу А',
я не утверждаю, что эти базисы отличаются только перестановкой векторов.
Эти базисы могут отличаться гораздо более существенным образом.
Но, тем не менее, таких базисов может быть великое множество,
а вот Жарданова матрица получится всегда одна и та же с точностью до перестановки клеток.
Вот такое у нас большое утверждение, большое теоремы,
которую мы сегодня, наверное, полностью еще не докажем,
но будем уже двигаться в эту сторону.
Здесь стоит сделать сразу много замечаний.
Базис, который мы получаем, то есть базис, в котором Фи имеет Жардановую матрицу,
естественно, называется Жардановым базисом для Фи.
Матрица, которую мы получаем, вот эта вот Жарданова матрица,
называется как раз Жардановой нормальной формой
оператора И, оператора Фи.
Жардановой понятно почему? Слово «нормальная» как раз говорит нам,
что эта матрица единственная, что каждый Фи мы можем привести
путем правильной замены базиса лишь к одной такой вот Жардановой форме с точностью до перестановки клеток.
Слово «нормальная» часто отвечает именно, когда мы говорим про нормальную форму,
и отвечает именно за вот такую вот единственность.
Замечательно, это было первое замечание.
Давайте я сразу для ясности сделаю второе замечание, чтобы избежать недомоловок и кривотолков.
Как вы думаете, что такое Жарданова клетка размера 1 собственным значением лямбда?
Матрица 1 на 1, в которой только лямбда и стоит, правильно?
Поэтому в Жардановой нормальной форме могут появиться вот такие клетки 1 на 1, в которых стоят лямбда, правильно?
В частности, если оператор оказался диагонализуем, то есть в некотором базисе он имеет там вид лямбда 1 и так далее, лямбда n,
то это и есть его ЖНФ.
Мы с вами написали блоксно-диагональную матрицу, в которой каждый блок имеет размер 1, правильно?
Это и есть его ЖНФ. Нам больше ничего искать не нужно.
Но бывает, как мы знаем, недиагонализуемые операторы, и для них конструкция будет немножко более тяжелой.
Здесь стоит обратить внимание на какую деталь.
Даже уже из этого соображения понятно следующее.
Если мы приводим оператор к диагональному виду, у нас вполне может быть, что одна и та же лямбда, одно и то же собственное значение, встретится несколько раз на диагонали, правильно?
Мы с вами знаем, что бывают собственные подпространства размерности больше чем 1, тогда эта лямбда встретится больше чем один раз.
То есть в этих разных клетках жардановой матрицы одно и то же собственное значение, одна и та же лямбда, вполне может повторяться несколько раз.
Одна и та же лямбда, одно и то же собственное значение, может участвовать в нескольких клетках.
Давайте я это для ясности сразу скажу.
Ну что ж, теорему мы с вами сформулировали, и даже вроде как что-то немножко сказали.
Через некоторое время, когда мы будем искать жардановую форму, станет немножко яснее, в чем смысл этой жардановой формы.
Ну вот давайте мы об этом поговорим чуть позже, когда мы придем к соответствующей тематике.
А пока что мы начинаем постепенно доказывать нашу большую теорему.
Давайте вот что я сделаю, граждане.
Давайте, чтобы нам не путаться, я на всякий случай где-нибудь в углу доски, вот например здесь,
напишу, пока мы все это до конца не запомнили, напишу как выглядит жарданова матрица,
чтобы иметь возможность к ней апеллировать и не напоминать, что это такое.
Это блочно-диагональная матрица, состоящая из вот таких вот клеток.
Первая клетка какого-то размера лямбда 1 на диагонали единички над диагональю, все что я не пишу это нули,
потом следующая клетка и так далее.
Лямбды в разных клетках не обязательно различны, чтобы можно было туда посмотреть я это выписал.
Мы с вами начинаем с первой части теоремы, мы собираемся выяснить, что жарданова нормальная форма
у любого оператора, вылитворяющего звездочки естественно, то есть характеристический многошлен какой нам нужно, существует.
Я забыл сказать, но давайте я сейчас скажу. Какие у жардановой матрицы собственные значения?
Те же самые лямбды в тех же самых количествах, правильно?
На самом деле, если вы внимательно посмотрите на эту матрицу, ну или даже вот лучше на эту матрицу,
она по-прежнему верхнетриугольная, правильно? Она по-прежнему верхнетриугольная,
и поэтому все ее собственные значения написаны на диагоналях ровно в количествах равных алгебравическим кратностям, правильно?
Вот эти лямбды, это и есть ее собственные значения, так будет всегда.
Так, давайте мы будем доказывать существование нашей формы,
и первым делом мы сведем этот вопрос к более простому,
используя то самое следствие, которое мы сегодня доказали.
Итак, пусть у нас выполнена звездочка.
Мы с вами более того знаем, что характеристический многочлен Фи является аннулирующим для Фи.
Это теория Магамельта на Келли, и в этом частном случае мы ее уже точно доказали, правильно?
Значит, мы имеем право воспользоваться следствием,
и взаимно простые многочлены, здесь у нас уже выписаны, взаимно простые многочлены, на которые раскладывается наш многочлен,
вот они, вот эти вот сомножители.
Значит, характеристический многочлен аннулирующий, и он представлен в виде, давайте я это еще раз даже напишу,
лямбда катой минус Фи, минус, извините, х, конечно же, да, минус х в альфа катой,
где сомножители попарно-взаимно просты.
Значит, по нашему следствию, с которого мы сегодня начали, пространство В раскладывается в прямую сумму,
давайте я их обозначу подпространств, нет, давайте я лучше сразу введу нормальное обозначение для этих подпространств,
эти подпространства обозначаются вот таким вот образом, В с индексом лямбда ИТ сверху,
В лямбда ИТ, это те, кто помнит следствие, уже знают, что это такое,
это ядро одного сомножителя, в который вы подставили Фи, то есть ядро лямбда ИТ минус Фи в альфаитой степени,
ну или давайте я сразу уж сменю знак, потому что нам так будет удобнее работать, это ядро Фи минус лямбда ИТ в степени альфаиты,
понятно, что эти операторы либо не тем не отличаются, либо отличаются знаком, ядра у них в любом случае совпадают.
Итак, эти подпространства достаточно важны, В лямбда ИТ называется корневым подпространством,
соответствующим собственному значению лямбда ИТ, соответствующим собственному значению лямбда ИТ.
Так, ну давайте мы сразу сделаем замечание, вот у нас было два обозначения, мы ввели обозначение В с нижним индексом лямбда ИТ,
это собственное подпространство, правильно, и В с верхним индексом лямбда ИТ это корневое подпространство, вот такое вот.
Как эти два подпространства соотносятся друг с другом? Какое вложено в какое? Левое вправое или правое в левое?
Геометрическая кратность меньше либо равна алгебравической, говорят нам, но тут пока не понятно, какая размерность у вот этого товарища,
но на самом деле вы правы, левое подпространство вложено вправое, почему? Потому что В с нижним индексом лямбда ИТ это ядро просто фи минус лямбда ИТ, правильно?
А здесь ядро какой-то степени этого товарища, то есть если вектор лежит здесь, он обнуляется фи минус лямбда ИТ, и тем более он обнуляется какой-то степенью,
а может быть, что некоторые векторы обнуляются только степенью, но еще не первой степенью фи минус лямбда ИТ, правильно?
Поэтому оно вложено в ядро фи минус лямбда ИТ в какой-то степени альфаитой, а это уже В лямбда ИТ верхний.
Итак, собственные подпространства являются подпространствами корневых, ну и на самом деле это можно было увидеть еще и из вот этой вот формулы.
Мы с вами знаем, что собственные подпространства образуют прямую сумму, правильно?
Но в случае, когда оператор не диагонализуем, эта прямая сумма еще не В, поэтому там больше они быть не могут, а меньше они быть могут.
То есть как раз может так случиться, что собственные подпространства, действительно подпространства здесь, и их прямая сумма это еще не В, а вот прямая сумма корневых это уже В.
Так, прежде чем двигаться дальше, давайте я чуть-чуть скажу про то, что такое корневое подпространство, несколько элементарных свойств корневых подпространств.
Сразу выясним, чтобы после этого на них уже не останавливаться.
Так, ну для начала давайте я напомню обозначения, которые мы уже вводили, потому что нам сейчас будет очень удобно ими пользоваться.
Если у нас есть преобразование фи, то вот это вот фи минус лямбда, которое у нас сейчас будет появляться частенько с различными скалярами лямбда, мы сокращаем до фи лямбда.
Ну лямбда это естественно скаляр, правильно?
Ну а матрица вот этого товарища, если фи имеет в некотором базисе матрицу А, то, разумеется, фи лямбда в этом же самом базисе будет иметь матрицу А минус лямбда Е, правильно?
Матрица оператора умножения всего на лямбду это лямбда Е, и эта матрица естественно тоже будет обозначаться через А с индексом лямбда.
Вот так, первым делом давайте я некоторое количество совсем базовых свойств вынесу даже прямо в замечание.
Переходим к корневым подпространствам. Корневое подпространство естественно является инвариантным относительно фи.
Ну просто потому что это вот это вот ядро, мы как раз говорили, что в этой прямой сумме все подпространства инвариантны, правильно?
Оно инвариантно относительно фи, ну и следовательно оно инвариантно относительно любого оператора вида фи лямбда.
Мы говорили, что у фи и у фи минус лямбда запас собственных подпространств, извините, инвариантных подпространств одинаковый.
Значит, более того, если мы рассмотрим оператор ограничения нашего фи на вот это вот корневое подпространство,
то что мы будем понимать, то фи минус лямбда ит в степени альфа ит будет нулем.
Раз корневое подпространство это ядро вот такого вот оператора, точно так же как мы сегодня с вами уже делали,
мы скажем, что фи минус лямбда ит в альфа ит, если мы его применим к любому вектору из нашего в лямбда ит, то получим ноль, правильно?
Значит, это нулевой оператор.
Таким образом, х минус лямбда ит в альфа ит это аннулирующий многочлен для вот этого вот псиитова, извините, тут псиитое должно быть, правильно?
А мы с вами говорили в свое время, что если, ну да, извините, еще один шаг, это аннулирующий многочлен, значит, минимальный многочлен тоже имеет такой же вид, может быть, с меньшей степенью, правильно?
Если минимальный многочлен для нашего оператора псиитова делит любой аннулирующий, его минимальный многочлен также имеет вид х минус лямбда ита в какой-то, может быть, меньшей степени, правильно?
В частности, мы с вами говорили, что у минимального многочлена корнями являются все собственные значения преобразования, правильно?
Значит, поэтому у псиитова есть единственное собственное значение лямбда ита. Если бы было какое-то другое собственное значение, то оно тоже было бы корнем минимального многочлена, а это не так.
Значит, собственное значение у нас единственное.
Мы этот шаг уже сегодня делали в другой ситуации с общим многочленом. Глядите, в корневое подпространство, в лямбда ита, это ядро вот такого вот оператора, правильно?
То есть если мы фи минус лямбда ита в степени альфа ита, ну давайте я это еще раз напишу, если есть какой-то вектор из нашего корневого подпространства, то просто по определению фи минус лямбда ита в степени альфа ита, примененный к этому вектору, это ноль, правильно?
Ну а это и значит, что фи минус лямбда ита в альфа ите, примененная к нему, это ноль, правда? То есть фи минус лямбда ита в альфа ите, примененная к любому вектору из пространства, на котором фи ита определено, дает нам ноль.
Так, замечательно, еще пара свойств наших корневых подпространств, которые нам пригодятся в дальнейшем, такое вот утверждение.
Если мы возьмем два различных собственных значения лямбда иты неравная лямбда житому, то оператор фи лямбда ита действует невырожденным образом, сейчас я расшифрую, что это такое.
На корневое подпространство, соответствующее лямбда житому, то есть формально, если я возьму фи лямбда ита, ограничу его на В лямбда жита, напоминаю, сделать я это могу, потому что подпространство является инвариантным для вот этого товарища, правильно?
Так вот, этот оператор, это у нас действительно преобразование нашего корневого подпространства, и это невырожденный оператор.
Ну а что такое невырожденный оператор? Мы с вами уже давно знаем, что оператор невырожден тогда, когда его ядро нулевое, если его ядро нулевое, образ получается всем оператором, и он осуществляет биекцию на этом подпространстве.
Образ является всем пространством естественным. Ну так и давайте докажем, что ядро этого оператора невырожденное, значит ядро оператора фи лямбда итого, ограниченного на В лямбда жита.
Такого вот ограничения. Что это такое? Это все векторы из нашего подпространства, которые при действии этим оператором переходят в ноль, правильно?
Ну это значит, что это все векторы из вот этого вот подпространства, которые лежат в ядре просто фи лямбда итого. Я как раз и написал то, что я сказал. Векторы из подпространства, которые он обнуляет.
Ну а это что такое? Это корневое подпространство, соответствующее лямбда итому пересечь с, кто такой 2й член? Даже не корневое?
Это собственное подпространство, соответствующее лямдоитому, правильно?
Пересечь собственное подпространство, соответствующим лямдоитому.
Ну, собственное лежит в корневом.
Так что это точно содержится в пересечении двух корневых.
А мы с вами знаем, что корневые подпространства образуют прямую сумму.
Поэтому это пересечение нулевое.
Итак, что мы получили? Мы получили, что ядро нашего оператора нулевое.
Это и означает, что он невырожденный.
Так, ну и на всякий случай...
Так, Жерданову форму, Жерданову матрицу я не стираю.
На всякий случай еще одно техническое утверждение, чтобы у нас не возникало после этого вопросов.
Глядите, мы с вами сказали, что корневое подпространство, соответствующее лямдоитому,
это все векторы, которые переводятся в ноль вот такой вот степенью фи лямдоитого, правильно?
На самом деле, конечно же, мы можем эту степень заменить на любую большую.
То есть, давайте я это формулой напишу.
Корневое подпространство это множество всех векторов из В, для которых существует хоть какое-нибудь Т.
Такое, что фи лямдоиты в этой степени обнуляют наш вектор.
Понятно, вот здесь нам говорят, что мы полагаем Т равное альфаитому, ну или меньше, правильно?
На самом деле ничего кроме этого не будет, даже если мы степень будем повышать.
Ну, для доказательства достаточно, опять же таки, воспользоваться вот каким соображением.
Давайте мы возьмем какое-нибудь натуральное число Т, может быть большее, чем альфаит, и возьмем ядро фи лямдоитого в этой степени.
Нам хочется доказать, что это ядро лежит в нашем корневом, правильно?
То, что нам утверждается, правда ли, что оно лежит в нашем корневом подпространстве?
Если мы это поймем, то мы поймем, что правая часть лежит в левой, ну а левая часть лежит в правой, понятно, потому что по определению В лямдоитого, правильно?
Ой, извините, тут, конечно же, тоже итое, правильно? Здесь везде итое и житое нигде не должно быть.
Нам достаточно доказать, что это ядро содержится в лямдоитом.
Давайте мы посмотрим на ограничение нашего фи на подпространство У.
Оно, естественно, тоже инвариантно. Ядро любого подобного оператора инвариантно относительно фи, мы с вами это в свое время доказывали.
У инвариантно мы смотрим на его ограничение.
Тогда ψ аннулируется следующими двумя многочленами.
Во-первых, ψ аннулируется многочленом х-лямдоиты в тетой степени просто потому, что У это ядро вот ровно такого оператора, правильно?
Вот это мы два раза с вами это рассуждение уже применяли.
А также оно аннулируется, естественно, характеристическим многочленом фи.
Потому что все фи аннулируется характеристическим многочленом фи, а значит и наша ψ тоже.
Следовательно, ψ аннулируется их нодом, нодом многочленов, характеристическим многочленом фи, и х-лямдоит в т, в этой степени.
Давайте мы даже предположим, что t не меньше, чем αi t, потому что для меньших будет понятно все, правильно?
Если t меньше, чем αi t, то векторы этого ядра обнуляются даже меньшей степенью нашего оператора.
И уж тем более альфаиты степени тоже обнуляются.
Ну тогда этот нод, что это такое?
Характеристический многочлен у нас раскладывается на линейные совмножители вот так вот.
Второй многочлен это просто х-лямдоит в т, степень t не меньше, чем αi t, поэтому здесь будет х-лямдоит в альфаиты.
Ну что это означает? Это означает таким образом,
ψ-лямдоит в альфаиты это уже ноль, а это и есть то, что нам нужно.
То есть, если мы ψ-лямдоит применим к любому вектору нашего подпространства у альфаиты раз, то уже получим ноль.
Значит, это и говорит, что наше подпространство есть подпространство v-лямдоитова.
Итак, корневое подпространство – это подпространство всех векторов, которые хоть какой-то степенью ψ-лямдоитова обращаются в ноль.
Ну и всё это даёт нам возможность, даёт нам право изучать действия phi на каждое корневое подпространство по отдельности.
Мы сейчас это сделаем, но перед этим, чтобы у нас в голове была некоторая связь с тем, что мы доказываем,
как вы думаете, если матрица оператора, вот такая вот Жарданова, я взял базис, в котором матрица оператора Жарданова,
где здесь находится корневое подпространство, соответствующее, скажем, лямбдо первому?
Не обязательно один, может быть, несколько блоков вот с этим вот самым лямбдо первым.
Все векторы, которые участвуют в блоках именно с этим собственным значением лямбдо первое, оно у нас будет собственным значением ограничения на этот блок, правильно?
И корневое подпространство будет порождаться именно этими самыми векторами.
То есть, по сути дела, когда мы с вами разложили пространство в прямую сумму корневых подпространств,
мы с вами сказали, что мы разделили наши пространства на прямые слагаемые,
из каждого из которых будут получаться вот эти блоки с фиксированным значением лямбдо итого.
Сейчас я скажу это еще немножко на другом языке, то же самое, может быть, станет яснее.
Давайте я сделаю еще одно полезное для нас сегодня определение.
Для ясности давайте я скажу, что оператор PSI называется нельпатентным,
вроде теперь все буквы отчетливо назвал, это N, это P.
Ну, по сути дела, от латинской корней нулевая степень, если у него есть нулевая степень.
То есть, если существует такое T, что PSI в тетой это ноль.
Так вот, все эти слова мы с вами уже сказали.
Вот у нас написано, что PSI it-лямдо it в степени альфа it это ноль.
То есть, оператор phi-лямдо it, то есть phi-лямдо it, ограниченный на корневое подпространство,
но это то же самое, что PSI it-лямдо it, правильно?
Ну, по сути дела, я два раза написал одно и то же, он как раз нельпатентный.
И вот мы сейчас приступим к изучению как раз таких операторов.
Ну, давайте я сразу сделаю еще одно замечание для ясности.
Замечание второе.
Нам это даже может быть не потребуется, но полезно это понимать.
Глядите, у PSI it-ого мы с вами говорили, все собственные значения равны лямдо it-ому, правильно?
То есть, у PSI it-ого минус лямдо it-ого, вот у этого нельпатентного оператора,
все собственные значения будут равны...
Нет, еще раз, у PSI it-ого собственное значение лямдо it-ое, а сейчас я это лямдо it-ое вычел.
Что произойдет с оператором, если вы из него вычтете константу?
Из собственных значений тоже вычтется константа, правильно?
Поэтому все его собственные значения будут равны нулю.
И это общее свойство всех нельпатентных операторов.
Все собственные значения любого нельпатентного оператора нулевые.
Потому что если у нас есть какой-то вектор v, что PSI от v это лямдо v,
то тогда мы знаем, что будет, если к v применить степень нашего PSI.
Каждый раз мы будем получать вектор, умноженный на еще одну лямду, правильно?
PSI в тетой от v это будет лямдо в тетой на v.
Ну и коль скоро PSI в тетой, это 0, мы берем тот самый показатель нельпатентности,
как он называется, равен нулю.
Ну а значит, если v не был нулевым, если v был собственным вектором,
то и лямдо в тетой равно нулю.
Это случается только тогда, когда лямдо равна нулю в поле.
Так что у нельпатентного оператора все собственные значения нулевые.
И вы видите, что мы с вами сделали.
Мы с вами сказали, что наше пространство разбилось в прямую сумму корневых.
На каждом корневом ограничении нашего оператора, если мы из него вычтем
лямдоитую, получится нельпатентным.
И на самом деле это означает, что нам достаточно каждой из этих ограничений
суметь привести к жардановую виду, для того чтобы и весь phi привести
к жардановую виду.
Это мы сейчас с вами и будем делать.
Итак, нам остался последний ингредиент.
После этого все эти ингредиенты мы соберем в теоремовом существовании gnf.
Итак, нам осталось понять, давайте так, gnf нельпатентного оператора.
И мы с вами доказываем вот какую теорему.
Мы ее даже, наверное, через некоторое время двумя способами докажем.
Если psi нельпатентный оператор, то у него есть жарданова форма.
То есть в некотором базе его матрица приобретает нужный нам вид.
Обратите, пожалуйста, внимание, когда я формулирую эту вспомогательную теорему,
я ничего не говорю про характеристический многочлен нашего опси,
он нам уже будет не нужен.
То есть вот это условие о том, что характеристический многочлен раскладывается
на линейные сомножители, у нас сейчас будет следствием из того, что оператор нельпатентен.
У любого нельпатентного оператора на самом деле характеристический многочлен раскладывается
на линейные сомножители, и мы даже знаем на какие, потому что все собственные значения равны нулю.
Характеристический многочлен – это просто плюс-минус степень х.
Вот это мы сейчас с вами докажем.
Теперь после того, как мы корневое подпространство выделили,
характеристический многочлен нам больше не нужен.
Итак, если пси нельпатентный, то у него есть жарданова форма.
Так, как она будет выглядеть?
Конечно же, раз нам сказали, что все собственные значения нули,
то значит у нас вот в этой матрице будут нули по диагонали
и время от времени единички на следующей диагонали.
Она имеет вид следующий.
Клетки могут быть разного размера, может быть просто клетка из нуля, правильно, и так далее.
Эта жарданова форма будет иметь вот такой вот, разумеется, вид.
Ну и давайте мы сразу, прежде чем доказывать это, выясним,
какой должен быть базис для того, чтобы в этом базисе матрица имела жарданов вид.
Но для этого нам достаточно понять, какой должен быть базис
для того, чтобы матрица в этом базисе была жардановой клеткой.
Потому что из таких фрагментов мы составим весь жарданов базис.
Давайте вот мы, давайте даже не в качестве замечания,
а просто ответим на такой вопрос.
Каким должен быть базис?
Ну может быть какого-нибудь подпространства, правильно?
И так далее.
Чтобы оператор, некоторые фи, в этом базисе имел в качестве матрицы жардановую клетку жс.
Я напоминаю, что это как раз жарданова клетка собственным значением ноль.
То есть нули по диагонали, единички над диагональю,
в длинных местах нули, размер этой клетки с.
Ну а что у нас здесь такое написано? Давайте посмотрим.
У нас здесь написано, как действует наша ψ на элементы этого базиса.
И написано у нас следующее, что ψ от Е1 есть 0,
0 столбец 0, правильно?
ψ от Е2 есть Е1, единичка у нас стоит в первой строке, правильно?
И так далее, ψ от Еs, это Еs-1.
Ну то есть по сути дела, оператор должен на эти векторы действовать просто с двигом индекса на 1, правильно?
Еs-3 должен под действием нашего ψ переходить в Еs-1,
тот должен под действием ψ переходить в Еs-2 и так далее до Е1, который уже должен обращаться в ноль.
Если мы хотим получить жардановую клетку, то наш фрагмент базиса должен получиться вот такой вот.
Весь жардановый базис должен быть объединением нескольких вот таких вот цепочек, правильно?
Такая, давайте даже скажем, система векторов называется жардановой цепочкой.
И таким образом, если мы хотим построить жардановый базис для нашего нельпотентного оператора,
то этот жардановый базис должен просто состоять из нескольких жардановых цепочек, каждая цепочка соответствует какой-то клетке.
Жардановый базис должен состоять из нескольких таких цепочек.
Может быть и одной, конечно.
Ну и вот для того, чтобы как бы удобно об этом говорить, давайте мы сразу ведем определение.
Значит, это определение порой работает не только для нельпотентных операторов, поэтому я его дам сейчас в общем виде,
но применять мы его будем только к нельпотентному оператору.
Пусть psi это некоторый оператор, u это подпространство v.
Так вот это самое подпространство u называется циклическим относительно psi.
Если существует такой вектор v в нашем u, что у есть линейная оболочка вот каких векторов v,
psi от v, psi квадрат от v и так далее. Что значит и так далее?
Вообще говоря, я должен дойти до бесконечности, я должен взять все возможные итерации.
Но понятное дело, что в некоторый момент, поскольку мы сидим все-таки в конечномерном пространстве,
в некоторый момент у нас какой-то вектор вот этой последовательности выразится через предыдущее,
тогда и дальнейшие векторы будут выражаться через предыдущее, поэтому вот на этом месте можно будет оборвать этот ряд.
Итак, циклическое подпространство относительно psi это подпространство, порожденное таким вот вектором.
Что это на самом деле такое? Это я взял вектор v и построил самое маленькое инвариантное подпространство, которое содержит v.
Давайте я это напишу. Иначе говоря, у это наименьшее инвариантное относительно psi подпространство, содержащее v.
Просто потому, что если я хочу построить подпространство инвариантное относительно psi и содержащее v, то кроме v я туда обязан включить psi от v.
Если v лежит в подпространстве, то psi от v там тоже должен лежать. Если этот товарищ лежит в u, то psi квадрат от v тоже должен туда включить.
Так что все эти векторы обязаны лежать в инвариантном подпространстве, содержащем v.
Ну и значит, если я ими породил подпространство, то оно как раз и будет самым маленьким. Ну и инвариантным оно естественно тоже будет.
Общее определение вот такое вот. В нашем случае, обратите, пожалуйста, внимание, эту цепочку мы точно можем оборвать, потому что наш оператор нельпотентен.
Пси в тетой равно нулю, поэтому в некоторый момент в этой цепочке появится ноль, правильно?
Значит, давайте я сделаю замечание. В случае, когда psi нельпотентен, но оператор нельпотентен,
у это будет линейной оболочкой v, psi от v и так далее, psi в k-1, скажем, от v, где psi в k-t от v, это уже нулевой вектор.
В некоторый момент там начнутся нули, и вот в этом месте мы и оборвемся.
Ну и глядите, если у нас вот такое вот подпространство есть, хотелось бы сразу сказать, что это и есть жардановая цепочка.
Что мы возьмем вот эти вот векторы в качестве базиса нашего u, и они будут вести себя ровно так же, как написано в жардановой цепочке.
Каждый из них под действием psi переходит в следующий, правильно? Ну а последний переходит уже в ноль.
Правильный вопрос. Почему они линейно-независимы? Сейчас мы докажем, что на самом деле это автоматом будет так для нельпотентного оператора.
Точнее мы сделаем вот что. Давайте вот я чуть-чуть преждевременно ввел вот это вот k.
Значит пусть psi это нельпотентный оператор, v это вектор в нашем v, тогда высота вектора v это наименьшее k.
Ну давайте я скажу наименьшее целое не отрицательное k. Такое, что если я применю к нашему вектору psi в k, то уже получу 0.
Чтобы понять, кто такие векторы высоты 0?
Высоту 0 имеет нулевой вектор и никто кроме, правильно? psi в ноликовает тождественный оператор, как обычно.
Высоту 1 имеет лишь 0. Высоту 1 имеют те векторы, которые при однократном применении psi переходят в 0, правильно?
То есть не нулевые векторы из ядра psi, но или по-другому сказать собственные векторы нашего psi. У нас собственное значение это как раз 0, правильно?
И вот полезное утверждение, которое нам сейчас часто будет пригождаться, заключается в следующем.
Пусть v1 и т.д. выкатые не нулевые векторы по парноразличных высот.
То есть нам нужно разное количество раз применить psi к ним, чтобы в первый раз получить 0.
Тогда они линейно независимы. Вся эта система векторов будет линейно независима.
Для доказательства давайте мы обозначим эти высоты. Все высоты этих векторов натуральные числа, потому что векторы не нулевые, правильно?
Пусть h1 и т.д. это высота вектора v1 и т.д. Естественно мы можем упорядочить по высоте. То есть мы можем считать, что h1 и т.д. упорядочены по возрастанию.
Ну и давайте мы предположим, что наши векторы оказались линейно зависимыми.
Если v1 и т.д. выкатые линейно зависимы, то у нас нашлась их линейная комбинация, которая равна 0 и при этом нетривиальная.
То существует нетривиальная линейная комбинация, сумма αi и vi и т.д. равная 0.
Линейная комбинация нетривиальная, это значит, что у нее есть хотя бы один не нулевой коэффициент.
Давайте мы будем считать, что последний коэффициент не нулевой. Если это не так, то мы просто откинем несколько последних слагаемых и перейдем к меньшей системе.
Тоже векторов попарены различными высотами. Мы можем считать, что αкт не 0.
Давайте мы применим тогда к этому равенству ψ в подходящей степени, а подходящая степень это hkt-1.
Давайте уже закончим доказательство, потом пойдем на перерыв.
Альфа и т ψ в степени hkt-1 от vi. Что это означает?
Когда я применяю вот этого товарища к vi при i меньше, чем k, то я применяю ψ хотя бы в степени hk-1.
И значит должен получить 0.
ψ в hkt-1 от vi это 0 при i меньше, чем k, потому что hi-1 не превосходит вот этого товарища, и значит у нас уже должен получиться 0.
Здесь у нас будет всего-то навсего альфа катоя на ψ в степени hkt-1 от vi.
Ну а это не 0, потому что коэффициент не нулевой, и вот этот вот вектор еще не нулевой, потому что мы применили ψ в степени на 1 меньше, чем высота нашего вектора.
Значит это не 0. Ну и естественно это противоречие с тем, что мы применили наша ψ в hkt-1 к вот этому равенству, то есть должны были получить естественно тоже 0.
Итак, утверждение мы с вами доказали, давайте на этом месте устроим перерыв.
Доказали, что векторы различных высот не нулевые, естественно линейно независимые, ну и как следствие мы получаем то, что я обещал.
Давайте я так это скажу, пусть v это вектор высоты t, ну и давайте мы возьмем линейную оболочку v,
ψ от v, ψ квадрат от v и так далее до какой степени? t-1 конечно же, правильно? Вот оно, это циклическое подпространство.
Тогда естественно v, ψ от v и так далее, ψ в t-1 от v, это базис в u.
То есть если мы берем вот такое вот циклическое подпространство, действительно мы получаем фрагмент, который можно использовать в железновом базисе.
Ну можно было бы, не всякий такой фрагмент получится использовать на самом деле, как мы через некоторое время увидим, но тем не менее.
Тогда это будет базисом в u. Доказательство теперь уже очень простое, просто высота вектора ψ в i t от v равна естественно t-i, правильно?
Если к v нам нужно t раз применить ψ, чтобы получить 0, то к этому осталось ψ применить t-i раз, правильно?
Поэтому эти векторы линейно независимы, ну и кроме того они естественно порождают u, потому что мы ровно так и написали, правильно?
u это циклическое, оно порождено ими, и они линейно независимы.
Еще раз, это мы и сказали, да. Мы именно это и доказали, любые векторы разных высот будут lnz, но здесь мы применяем это к векторам просто последовательных высот, правильно?
От t до 1. Ну и теперь мы уже можем двигаться к доказательству нашей теоремы.
Итак, мы собираемся доказать вспомогательную теорему, правильно, о существовании, напоминаю, gnf у нелепотентного оператора ψ.
Ну, как мы с вами видим, если мы сейчас поняли, что произошло про циклические подпространства, нам достаточно разложить v в прямую сумму циклических подпространств.
Я это еще раз поясню в конце, но давайте пока что скажем так.
Если мы v разложим в прямую сумму циклических подпространств, то каждое циклическое подпространство нам даст как раз одну клетку в жардановой матрице.
Как это сделать?
Итак, ψ, да, но напоминаю, что у нас ψ – это линейный оператор на пространстве v, он нелепотентен, у него есть какая-то степень, в которой, если его возвести, то получится 0.
Давайте мы выберем, давайте я даже леммус сформулирую, чтобы было понятнее, что произойдет дальше.
Пусть v – это вектор наибольшей высоты. У нас существуют векторы различных высот, тогда мы выбираем наибольшую из них.
Так, наибольшей высоты, скажем, t, и давайте мы возьмем циклическое подпространство, порожденное этим вектором.
Тогда у этого подпространства существует прямое дополнение, которое является инвариантным относительно ψ.
То есть тогда существует инвариантное подпространство относительно ψ такое, что v – это прямая сумма u и w.
Ну, собственно говоря, если мы это сейчас докажем, то нам останется просто провести индукцию, поэтому давайте мы это будем доказывать.
Итак, мы выбрали вектор наибольшей высоты. Обратите, пожалуйста, внимание, это существенно.
Если бы я выбрал не вектор наибольшей высоты, а просто какой-то вектор, скажем, не нулевой, породил бы им циклическое подпространство, совершенно не обязательно у него бы нашлось инвариантное прямое дополнение.
Прямое дополнение есть, а вот инвариантного среди них может не найти.
Если я выбираю в качестве v вектор наибольшей высоты, то вот Лемма нам говорит, что это обязательно будет.
Ну, для доказательства давайте мы выберем к u, то есть давайте мы взяли вектор v, породили подпространство u,
и давайте мы попытаемся выбрать инвариантное подпространство наибольшей размерности, которое образует еще прямую сумму с u.
То есть выберем инвариантное подпространство w наибольшей размерности, такое, что они попросту пересекаются по нулю.
Ну, то есть их сумма – это прямая сумма.
Естественно, мы хотим доказать, что w – это именно то, что нам нужно, то есть что эта прямая сумма будет все наше пространство v.
Но почему мы такое подпространство можем выбрать?
Нам нужно для этого сказать, что хоть какое-то инвариантное подпространство, пересекающее с u по нулю, есть, но это просто 0, правильно?
То есть если такого не нулевого подпространства нет, то мы возьмем просто 0.
Если не нулевое есть, то опять же такие вот выбираем подпространство наибольшей размерности.
И давайте мы предположим, что вот эта прямая сумма еще не есть все v, и, следовательно, есть какой-то вектор v вне этой суммы.
Так, давайте мы эту прямую сумму на всякий случай каким-то образом обозначим.
Это будет у нас v'.
Выберем произвольный вектор x из v без v'.
Сейчас мы собираемся это привести к противоречию.
Но первым делом давайте мы x немножко улучшим.
Давайте мы посмотрим на последовательность применения psi к нашему вектору x.
Посмотрим на последовательность x, psi от x, psi квадрат от x.
Когда-то в ней встретится 0, правильно?
psi у нас нелепотентный оператор, поэтому когда-то все сойдется к нулю.
Вектор x у нас еще не лежит в v'.
Когда мы придем в 0, этот вектор уже, конечно, будет лежать в v', правильно?
Значит, в некоторый момент у нас наступит такая ситуация, что очередной член еще не лежит в v', а следующий член уже лежит.
То есть у нас будет такая ситуация, что psi в i-1 от x еще не лежит в v', а psi в i-t уже лежит в v'.
Так вот давайте мы сразу заменим наш x на вот этого товарища, на psi в i-1 от x.
Мы же выбрали вектор просто так, чтобы он лежал в v', но не в v', правильно?
Вот этот вот товарищ тоже, конечно, будет лежать в v' без v', мы выбрали его таким, что он не лежит в v'.
А psi от него уже будет лежать в v'.
Тогда, если мы применили к нему psi, то он уже лежит в v', в нашей прямой сумме, у плюс w.
Что это означает?
Это означает, что он у нас раскладывается в следующую сумму.
Ну, раз он лежит в v', то он раскладывается в сумму вектора из u и вектора из w.
А вектор из u у нас, конечно же, раскладывается по вот этим вот векторам, правильно?
То есть x – это вот что такое, вектор из u, сумма по i от 0 до t-1, какие-то коэффициенты, скажем, гамма, it на psi в it от v,
и плюс некоторый вектор y, содержащийся уже в подпространстве w.
Вот я применил нашу прямую сумму.
Да, спасибо. Разумеется, это psi от x – это важно.
Важное соображение. Давайте мы вспомним, что t – это у нас была наибольшая высота вектора.
Это что означает? Если я вот к этому вектору сейчас применю еще psi в t-1, то получу уже 0, правильно?
Мы знаем, что t – это наибольшая высота вектора. То есть если я применю psi в t к x, то я получу 0.
Это psi в t-1 от psi от x, и это означает, что я psi в t-1 могу применить к каждому члену этой формулы по отдельности.
Сумма по i от 0 до t-1, гамма, it, psi в степени t-1 плюс i от v, и плюс psi в t-1 от y.
Что здесь может быть не нулевым?
Пси в тетой мы уже знаем. Это 0, он любой вектор переводит в 0.
Значит, все вот эти слагаемые у нас обратятся в 0, кроме одного. Кроме слагаемого при i равном 0.
То есть из первой суммы у нас может не обнулиться только гамма ноликовая, psi в t-1 от v.
Он еще не 0, а при i равном 1 у нас здесь будет уже гамма первая на psi в тетой от v, то есть 0.
И еще плюс psi в t-1 от y.
Ну, глядите, какая петрушка. 0 разложился в сумму вот этих вот двух векторов.
При этом первый вектор у нас, конечно же, лежит в u, просто по определению.
А второй вектор у нас лежит в w, потому что w у нас было инвариантным.
Как такое может быть? Мы с вами знаем, что если у нас есть прямая сумма,
то 0 единственным образом раскладывается по векторам из этих двух подпространств.
Как 0 плюс 0. Если 0 разложился в сумму вектора из u и вектора из w, а сумма была прямой,
то мы понимаем, что гамма 0, psi в t-1 от v и psi в t-1 от y, хотя это нам не нужно, равно 0.
Ну а первый вектор может обратиться в 0, ровно тогда, когда гамма ноликовая равно 0, правильно?
Потому что psi в t-1 от v это еще не 0. То есть мы поняли, что гамма ноликовая это 0.
Это и есть то, что нам хотелось. Вот почему.
Глядите, что у нас получается. У нас получается, что psi от x теперь это такая сумма,
в которой каждый раз хотя бы 1 psi применяется.
То есть здесь у нас написано вот в этой вот сумме теперь, когда гамма ноликовая равен 0,
то есть когда коэффициент при v 0, в этой сумме каждый раз написано psi от кого-нибудь, правильно?
И значит вот этого кого-нибудь мы сейчас можем из x вычесть.
Положим, скажем, x' это x минус вот эта вот самая сумма как бы прообразов этих векторов.
Сумма, внимание, по i от 1 до t-1, гамма i t на psi в i-1 от v.
Поскольку гамма ноликовая у нас равен 0, то мы имеем право это сделать.
Тогда psi от x'. Давайте мы формально это напишем.
Это сумма, по i от 0 до t-1, гамма i t, psi в i t от v. Извините, я здесь напишу,
по i от 1, потому что гамма ноликовая 0, правда?
Плюс y и минус psi, примененная к этому, то есть снова сумма, по i от 1 до t-1,
гамма i t, psi уже в i t, я еще раз psi применю от v.
И эти суммы замечательным образом сокращаются, это y, лежит в w.
Теперь глядите, что у нас получилось.
Давайте посмотрим на наши три подпространства.
У, w и подпространство, порожденное x-штрихом.
Обратите внимание, что я сделал с x-штрихом?
Я из x вычел какой-то вектор из u, правда?
Вот эта вот линейная комбинация, это вектор из u.
Значит, я из вектора вне нашей прямой суммы вычел вектор, который лежит в прямой сумме, правда?
Следовательно, x-штрих тоже не содержится в v-штрих.
Вот этот вектор не содержится в v-штрих,
поэтому сумма вот этого подпространства, это v-штрих плюс x-штрих,
сумма v-штрих и вот этого одномерного подпространства является прямой.
Понятное дело, раз x-штрих там не лежит, то их пересечение нулевое.
Значит, у нас здесь написана прямая сумма вот таких вот трех подпространств.
Давайте я ее вот так вот напишу.
И обозначу вот этого кадра через w-штрих, то, что в скобках.
Обратите, пожалуйста, внимание, что такое w-штрих?
Это инвариантное подпространство.
w-штрих, инвариантное подпространство,
потому что psi от w содержится в w, w было инвариантным, правильно?
psi от x-штриха тоже содержится, тоже лежит в w, мы этого тщательно добивались.
Значит, оно порождено векторами, которые переходят при применении psi в w-штрих.
Значит, w-штрих инвариантно образует прямую сумму с u
и имеет большую размерность, чем w.
А мы выбирали w максимальной размерности.
Итого мы получаем противоречие.
Размерность w-штрих, конечно же размерность w плюс один,
и это противоречит выбору w.
И таким образом лему мы с вами доказали.
Еще раз давайте мы пробежимся по шагам доказательства, самые главные леммы.
Мы выбрали инвариантное пространство наибольшей размерности,
которое пересекается с u по нулю, которое с u образует прямую сумму.
Предположили, что их прямая сумма это еще не все пространство w,
а какое-то под пространство v-штрих.
Нашли вне этого v-штриха вектор, который переходит в вектор w под воздействием psi.
И поняли, что тогда этот вектор можно добавить к нашему w так,
чтобы оно осталось инвариантным, увеличило размерность
и продолжило образовывать прямую сумму с u, то есть продолжило пересекаться с u по нулю.
Противоречие с выбором w.
На самом деле в некотором роде это доказательство даже конструктивно,
потому что мы это самое w можем таким образом по шагам строить.
Другое дело, что существуют гораздо более экономные конструкции.
Мы о них еще поговорим.
Итак, лему мы с вами доказали.
Нам осталось доказать теорему.
Возвращаемся к теореме.
Итак, мы уже говорили, мы зашли в самую глубь.
Сейчас всплываем постепенно. Возвращаемся вверх.
Итак, докажем, что w вверх.
Докажем постепенно. Возвращаемся вверх.
Итак, докажем, что w раскладывается в прямую сумму
циклических подпространств.
Индукции по, разумеется, размерности w.
Если размерность w нулевая, то доказывать нечего.
База при размерности w равна 0.
Тривиально.
Просто у нас уже все разложено в прямую сумму 0 циклических подпространств.
Для перехода давайте мы выберем вектор v наибольшей высоты.
Породим этим вектором циклическое подпространство.
И из леммы, давайте я его даже u1 обозначу для ясности,
из леммы мы получаем, что v представляется в виде прямой суммы нашего u1
и какого-то инвариантного подпространства w.
Теперь нам осталось применить предположение индукции
к оператору psi, ограниченному на w.
Мы старались изо всех сил, чтобы w оказалась инвариантным относительно psi.
Значит, ограничение psi на w это тоже, конечно же, оператор и тоже, естественно, нельпотентный.
Мы получим, что w раскладывается в прямую сумму каких-то циклических.
Где это циклические подпространства?
Циклические подпространства относительно ограничения, то есть относительно psi, конечно, тоже.
Ну а тогда и w разложилась в прямую сумму циклических подпространств.
И мы доказали то, что нам нужно было. Мы разложили w в прямую сумму циклических подпространств.
И я на всякий случай обращаю ваше внимание, как этот процесс будет идти, если мы залезем немножко глубже.
Вот мы в v выбрали вектор наибольшей высоты t, породили им т-мирное подпространство у1 циклическое.
Выбрали для него инвариантное прямое дополнение.
В w совершенно необязательно найдутся векторы высоты t.
Вот так случится, что в w все векторы имеют уже меньшую высоту.
Там мы выберем вектор максимальной высоты из имеющихся в w, отрежем снова вот такое вот циклическое подпространство и продолжим процесс.
Если мы вот так вот будем все выстраивать, то у нас высота векторов будет все время не увеличиваться.
Размерности вот этих вот циклических подпространств.
Ну а тогда давайте уж мы еще раз это дело проговорим.
Значит, если у it это циклическое подпространство, порожденное v it, psi от v it и так далее,
давайте я напишу t it-1 от v it.
Ну то есть если у it циклическое подпространство, порожденное вектором v it и высота у него t it,
то мы знаем, что в u it есть жарданов базис.
Как он будет выглядеть, кстати?
Как написать базис, чтобы матрица в этом базисе получилась жардановой клеткой?
Неправда.
Нам нужно начинать наоборот, правильно?
У нас вектор e1, напоминаю, в жардановой клетке переходил в ноль.
То есть это должен быть последним вектором из вот этих вот.
Их надо написать в обратном порядке.
psi в t it-1 от v, psi в t it-2 от v и так далее v it.
У it есть жарданов базис вот такой вот.
Каждый вектор этого базиса переходит в предыдущий при действии psi,
а самый первый вектор переходит в ноль.
Давайте я его назову e it.
То есть если я возьму ограничение psi на u it,
оно, конечно же, инвариантно напоминает,
то в этом вот самом базисе его матрица будет жардановой клеткой.
Просто потому, как мы его выбираем.
Еще раз напоминаю, это базис, мы это в свое время с вами доказали.
Правильно, что векторы эти все линейно независимы.
Значит, объединяя эти базисы, получаем жарданов базис для всего psi.
Просто потому, давайте я сюда перейду,
что матрица как раз и окажется блочно диагональной.
Давайте я еще раз это дело на всякий случай проговорю.
Вот у меня пространство разложилось в прямую сумму наших циклических подпространств.
Они все инвариантны относительно psi.
Правильно, раз они циклические.
В каждом из них мы выбрали вот такой вот жарданов базис.
Если мы объединим эти базисы,
получим базис E.
Сюда поставим сначала фрагмент E1, потом фрагмент E2 и так далее.
Мы получим, естественно, базис V,
поскольку V разложилась в прямую сумму этих самых циклических.
И psi в этом базисе как раз имеет нужный нам вид.
Блочно диагональный вид.
Здесь стоит жарданова клетка размера T1,
здесь стоит жарданова клетка размера T2 и так далее.
Для любого нелепотентного оператора мы жарданов базис нашли.
Ну и давайте, как следствие, за оставшиеся 10 минут,
как раз поймем, что жарданова форма всегда существует.
GNF всегда существует.
Ну и, естественно, в предположениях звездочка.
В предположениях напоминаю, как обычно,
что характеристический многочлен раскладывается на линейное сомножителе.
Итак, давайте вспоминать все то, что мы сегодня наговорили,
и поймем, что это соберется в доказательстве нашего следствия.
Значит, если характеристический многочлен phi раскладывается
на линейное сомножителе лямда Ит минус х в степени альфа Ит,
то мы с вами знаем, что В раскладывается в прямую сумму корневых подпространств.
Фи, да?
Значит, далее, если мы возьмем ограничение нашего фи, давайте,
лямда Ит на В лямда Ит, давайте мы его оба значим через ψ ит.
Мы с вами знаем, что это нильпотентный оператор на корневом подпространстве.
То есть в В лямда Ит существует база.
Здесь давайте я, чтобы не путаться с еитом, который у нас был только что,
назовем его еит верхнее, такой, что если я возьму ограничение ψ ит,
то есть фи с индексом лямда Ит, ограниченное на корневое подпространство,
он будет иметь матрицу Жарданову.
Вот мы с вами говорили, что здесь Ж с индексом Т1, Ж с индексом Т2 и так далее получается.
Это базис фи с индексом лямда Ит.
А что будет, если мы посмотрим на фи, ограниченное на наше корневое подпространство?
Ну это просто-напросто что означает, что я должен вычесть из фи лямда Ит,
а потом добавить лямда Ит, правда?
Вот у этого товарища матрица Жарданова с нулевыми собственными значениями,
когда мы добавляем лямда Ит, мы к нашей матрице добавляем лямда Ит на Е, правильно?
То есть просто-напросто добавляем лямда Ит по диагонали нашей матрицы
и получаем матрицу, которая тоже Жарданова, но уже собственными значениями лямда Ит.
Ж Т2 от лямда Ит и так далее.
Просто по диагонали добавились у нас лямда Ит в этом же самом базисе ЕИТ.
Ну и наконец, глядите, что мы сказали. Мы сказали, что мы наше пространство
разложили в прямую сумму инвариантных подпространств, вот этих вот корневых, правильно?
Они все инвариантны. В каждом из них мы нашли Жарданов базис.
В каждом из них мы нашли базис такой, что в этом базисе матрица имеет такой вид.
Но теперь нам осталось объединить этот базис в одно.
Объединяя полученные базисы
получаем требуемый Жарданов базис Е1 в первом корневом пространстве, Е2 во втором корневом пространстве
и так далее до Яката.
Просто если мы на ФИ посмотрим вот в этом базисе, то матрица получится блокно-диагональной
с блоками вот такого вот вида, правильно? Это и есть Жарданова матрица.
И таким образом теорему о существовании Жардановой формы мы с вами уже доказали.
Наверное, стоило бы поговорить сейчас о других подходах к этому построению, в частности о более конструктивных.
Но если я сейчас это дело начну, то я боюсь, что я ничего существенного не успею сказать.
Поэтому давайте мы на этом чуть пораньше сегодня и закончим.
Оставим время на вопросы, если они возникают по какой-то части вот этого доказательства.
Доказательства сложные, в нем, естественно, стоит разобраться.
Ну вот я призываю это сделать.
