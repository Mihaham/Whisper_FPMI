Итак, напомню, мы с вами уже два-три месяца говорим про определенные системы и говорим про них по двум причинам.
Во-первых, нас интересует масштабируемость, мы хотим добавлять новые узлы, система должна расширяться и работать также эффективно и хранить и проводовать больше данных.
Во-вторых, нам нужны узлы, все больше и больше, потому что мы хотим справляться со сбоями.
И вот все эти три месяца мы работали с очень простыми сбоями.
Мы работали с отказами узлов, когда узел просто выключается и больше не включается никогда, и не посылаете отправлять никакие сообщения в будущем.
И мы с вами переживали рестарты узлов.
Ну вот давайте для начала вспомним, с помощью каких инструментов мы справлялись с первой проблемой и с второй.
Отказы узлов. С ними мы справлялись с помощью...
с помощью кворумов.
Вот мы никогда не требовали, чтобы для записи в систему должны обратить все узлы.
Мы требовали доступность, ну скажем, большинства узлов.
Если мы можем получить ответ от большинства, то мы делаем запись, мы подтверждаем ее клиенту.
Когда мы читаем, мы снова читаем с большинства и мы знаем, что давайте их большинство пересеклись, по крайней мере, по одному узлу.
И вот та реплика, которая была в пересечении, она про записанные данные сообщит.
Ну, строго говоря, большинство узлов тут не обязательно. Мы говорили про системы кворумов.
Про системы подножеств, такие, что любые два множества этой системы пересекались.
И на лекции про Paxos Made Life мы с вами обсуждали, как можно сделать системы кворума более гибкими.
Так, чтобы они содержали меньше, чем большинство узлов, но при этом давали нужные нам гарантии.
Ну, там была еще история про доменный отказов, это, в общем, сложно повторять сейчас некогда.
Это мы, наверное, понимаем хорошо.
Вторая проблема, второй тип сбоя, с которым мы работали, это рестарты узлов.
Ну, с рестартами там решение было даже не алгоритмическое, а скорее инженерное.
Мы разделили наше состояние на персистентное и волатильное и сказали, что вторую часть состояния можно потерять.
А вот первую часть состояния, персистентное состояние, нужно хранить отказу устойчивого на диске, на каком-то внешнем устройстве.
Ну, и мы хранили его в каком виде? В виде LSM, то есть в виде базы данных или в виде просто голого райта хэтлога.
Но на самом деле LSM в конце концов хранит в виде сортированных пайлов и тоже райта хэтлога,
поэтому в конце концов все упирается в лог, куда мы записываем все наши мутации последовательно.
Ну, и делаем все это аккуратно.
На позапрошлом семинаре мы говорили про чексумы, про вообще как лог аккуратно вести.
То есть мы с этими проблемами, с этими отказами умеем бороться.
Но, конечно же, мы себя в чем-то здесь ограничивали.
Мы ограничивали здесь мир, потому что мир может уломаться не только так.
В мире у нас что может происходить? У нас могут происходить аппаратные ошибки, например,
когда космический луч переворачивает бит в нашей планке памяти и дальше последствия плохо предсказуемы для нас.
Диск может покарабтить данные, которые он хранит.
Вы, как разработчик, можете совершить ошибку.
Не знаю, в конце концов узел нашей системы может захватить злоумышленника,
а может быть даже не один узел, а несколько узлов.
И они будут вести себя как-то координированно и действовать против нас, против нашего алгоритма.
Короче говоря, мы сегодня хотим обобщить модель отказов, с которой мы работаем.
Мы сегодня хотим поговорить про византийский отказ.
То есть мы хотим позволить сбойным узлам вести себя абсолютно произвольным образом.
Но вот все, что мы можем себе вообразить, мы можем им позволить.
То есть в частности они могут произвольно отступать под протокол, по разным причинам.
Оборотной сбой, баг в программе, злоумышленник.
Все это может послужить причиной такого поведения.
И, разумеется, никакие наши алгоритмы к такому приспособлены не были.
Но представим, что у нас есть алгоритм RAFT, и там лидер посылает...
И там какой-то узел в любом состоянии получает сообщение append-entries из старшего терма.
То есть он как будто бы думает, что с ним говорит лидер и говорит ему,
реплицируя команды в свой лог, либо со три команды из своего лога.
И если мы такое сообщение получаем, то мы переходим в терм этого лидера в будущий,
и стираем в свои команды, например.
Вот мы обязаны так делать.
Если нам это сообщение отправил узел, который просто выдумал это сообщение,
то, конечно же, наш алгоритм пострадает, наши данные будут потеряны.
Ну, с multipax-ом то же самое, в общем-то, один и тот же алгоритм.
Так что никакой надежды, что наши алгоритмы будут работать в такой модели отказов нет.
Вот мы должны специально об этом позаботиться сегодня.
И наша цель на сегодня даже не то, чтобы алгоритмы строить.
Про алгоритмы мы будем говорить в следующие два занятия.
Мы будем говорить про BFT и про алгоритмы биткоина.
Это два очень разных алгоритма, но чтобы до них добраться,
нужно в принципе понять, с помощью каких инструментов мы собираемся бороться
вот с такими вот произвольными, очень сложными отказами.
Но прежде чем с ними бороться и прежде чем говорить про инструменты,
которые нам в этом помогут, давайте обсудим, почему вообще мы до сих пор
игнорировали все эти проблемы.
Привет, заходи.
Почему мы игнорировали, не то чтобы мы совсем игнорировали,
мы обсуждали немного аппаратные сбои, но давайте проговорим это еще раз.
Вот все перечисленные проблемы, которые могут привести к нарушению поведения протокола,
проведение узла.
С аппаратными сбоями мы справляемся более-менее с помощью чексу на разных уровнях.
Но мы чексу мы используем в планках памяти прямо.
Мы используем чексу, мы когда храним что-то на диске, мы записываем чексу,
потом поднимаем с диска и проверяем, что чексу мы все еще сходим,
что диск не испортится в наши данные.
И, конечно же, мы отправляем данные всей только если мы тоже их снабдили контрольной суммой.
Все это позволяет нам, мы не можем защититься от аппаратных сбоев.
У нас большие системы, там кластеры из тысяч десятков, тысяч сотен машин,
и в таком масштабе даже самые редкие аппаратные сбои все равно проявляются.
Так что наша задача здесь с помощью контрольных сумм не избавиться от ошибок,
а локализовать ошибки.
Вот если где-то ошибка произошла, то мы хотим максимально уменьшить ее радиус поражения.
Вот будет очень печально, если мы запишем данные на диске,
данные на диске испортятся, потом мы их поднимем и отправим снапшот нашего автомата в РСМ,
и отправим его в другую машину, и другая машина его накатит, и все.
После этого мы ни на что рассчитывать не можем.
Мы хотим ошибку локализовать в пределах одной машины,
ну или в пределах провода, чтобы она дальше никуда не распространялась.
Так что вот с аппаратными сбоями мы в принципе живем.
Другая причина – это багги в алгоритме.
Ну это уже чуть хуже.
То есть понятно, что вы можете придумать правильный алгоритм, вы можете его доказать,
вы можете написать спецификацию, потом вы пишете код два года,
и окажется, что в нем бага.
Ну как с этим бороться, мы немного уже обсуждали,
мы говорили, что, скажем, model checking вам не поможет здесь,
и спецификация уже при реализации непосредственно, но поможет fault injection.
Вот и fault injection может быть разного вида, он может быть в виде симулятора, как у нас,
он может быть в виде внешнего фреймворка, как Jepson.
Но тем не менее он все же нам не гарантирует, что все баги будут найдены.
Он стремится увеличить покрытие графа состояния, но при этом ничего не гарантирует.
Как же нам обходиться быть с багами в алгоритме, в реализации?
Если баг в реализации приведет к тому, что наш протокол начнет действовать иначе,
то он же бедно творит.
Что делать?
Ну, я бы сказал, что да, нужно просто добавлять,
нужно постоянно проверять варианты.
Опять же, нужно, чтобы если какое-то странное состояние,
которое не должно было возникнуть, все же возникло, мы как можно раньше это заметили
и как можно раньше упали.
Вот неработающий узел гораздо лучше, чем узел, который работает неправильно.
Но в случае с репликацией тут есть один нюанс очень печальный для нас.
Вот если ошибка аппаратная, то, скорее всего, она произошла на отдельной машине.
И мы с помощью контрольных сумм там ее можем блокализовать, машина выйдет из машины,
откажется, забудет про все свои данные, скажет, что я больше не могу ничего делать,
ничего обещать, там мультипаксы все.
Но это одна машина, в конце концов, она готова пережить отказ этой машины.
Но вот если у нас баг в нашем алгоритме репликации,
в нашем алгоритме репликации, что паксы, что мультирафт,
он существенно опирается на детерминизм реализации,
то если у вас, вот, не знаю, процесс пакса, что мультирафта,
то если у вас, вот, не знаю, процесс падает, процесс вашего РСМа падает и там пишет корку на диск,
то, скорее всего, он падает на разных, на всех узлах,
потому что все узлы проходят через детерминистическое состояние.
То есть если у вас узлы падают, то они падают вместе.
И это уже довольно печально, но, с другой стороны, они все еще не делают ничего плохого.
Ничего хорошего тоже не делают, но, вот, по крайней мере, не вредят.
Так что мы, да, действительно проверяем, делаем очень много проверок,
даже если мы не умеем после них восстанавливаться, все равно их нужно делать, чтобы в случае чего
отказать и, по крайней мере, не нарушить гарантии.
Гарантии сейфти, в смысле.
Ну и, наконец, последняя причина, которую мы до сих пор игнорировали,
это злоумышленники, которые могут захватить узлы вашей системы и поместить там свой код.
И дело не в том, что, там, не знаю, узел, сбоенный узел посылает некорректные сообщения,
потому что там переворачиваются битики.
А он отправляет корректные сообщения просто по смыслу разным и разным узлам.
То есть протокол соблюдается, узел посылает синтетически корректные сообщения,
но при этом выдают остальные возбуждения.
И поэтому могут нарушаться какие-то глобальные варианты.
Но почему мы до сих пор это все игнорировали?
Точнее, как? Не то чтобы мы игнорировали.
Мы-то как раз сегодня перестанем.
А вот разработчики, скажем, Google Spanner не пытаются в систему
встроить какие-то механизмы, которые от подобного поведения защищали бы
саму систему.
Ну вот, да, пока мы говорим про системы, которые живут в пределах какой-то условной компании,
и вот в таком мире, в таких ограничениях гораздо разумнее от злоумышленников
избавляться не в алгоритме, тем самым усложняя его и замедляя,
а просто построить аккуратненький забор вокруг системы,
ну, этим займется служба безопасности.
И, наверное, ничего плохого не произойдет.
Но другое дело, что, может быть, мы не хотим доверять какой-то одной службе безопасности
каким-то конкретным людям, какой-то конкретной компании.
И вот тогда уже эти проблемы нужно решать на уровне протоколов.
Собственно, поэтому мы к византийским отказам и переходим.
То есть, проблему с злоумышленниками мы сейчас решим алгоритмически.
Проблему с аппаратными сбоями, но, видимо, нам придется примерно так же решать.
По крайней мере, чексу мы нам уже помогали, нет причин, по которым мы от них откажемся.
А с багами в протоколе, но, боюсь, тут лучше ничего не сделать.
Если вы пишете неправильный код, то что тут уже сделаешь?
Окей, значит, наша модель – это византийские отказы.
Модель подразумевает, что сбоенный узел может вести себя совершенно произвольным образом.
Почему византийские?
Да, потому что Лэп когда-то в 82-м году написал статью,
которая называлась «Задачи византийских генералов» про византийскую армию,
которая осаждала какой-то город, и генералы, которые руководили дивизиями в этих армиях,
должны были вместе атаковать или вместе отступать.
Но делать это согласовано обязательно.
Если кто-то из них поступит одним образом другим, другим противоположным, то все погибнут.
Но среди генералов были предатели, они могли протоколу спотировать,
принимать произвольные решения, врать остальным.
И задача состояла в том, чтобы принять решение координированно среди корректных узлов,
то есть генералов, которые соблюдают все-таки протокол.
Это задача византийского консенсу, как вы можете понять.
У нас есть входные данные, решение каждого генерала отступать или атаковать, 0 или 1,
и все корректные, несбойные генералы должны принять одно и то же решение.
Ну и, разумеется, если не все на старте разумно предположить хотя бы одного и того же,
то они должны принять вот это самое решение.
Если у всех на входе 0, то они должны выбрать 0.
Короче говоря, это задача бинарного консенсуса.
И свойства такие же, но они касаются только несбойных узлов.
Сбойные узлы предателей действуют произвольным образом, мы их уже не контролируем,
поэтому зачем от них чего-то ожидать вообще.
Пока эта постановка задачи, мы не про нижние оценки пока не говорим.
Вот мы сегодня эту задачу обсудим, потому что, в общем, консенсус.
Потому что консенсус нам по-прежнему важен, по-прежнему он лежит в основе репликации,
этого никуда не уйти, но задача решается уже в более сложной модели.
Прежде чем обсуждать, как она решается или как она не решается,
мы должны еще в модели внести некоторую поправку.
А именно, мы все же в чем-то сбойные узлы ограничить можем,
потому что без этого жить совсем будет невозможно.
А именно, мы должны запретить византийским сбойным узлам представляться другими узлами.
Потому что без этого вообще сложно себе что-то представить разумное.
Как это запретить? Какой инструмент для этого нужен?
Нет, для этого нужна криптография, потому что мы хотим решать задачу аутентификации.
Вот если мы получаем сообщение, то мы хотим удостовериться,
что действительно тот, кто заявляет о том, что он автор этого сообщения, им является.
Вот для этого нам потребуется механизм...
В общем, можно представить себе по-разному.
Вот давайте представим себе наиболее общий механизм,
который мы можем использовать, это цифровые подписи.
Цифровые подписи – это три алгоритма.
Во-первых, мы можем сгенерировать пару из приватного и публичного ключа.
С помощью приватного ключа мы можем подписать сообщение.
А дальше получатель этого сообщения может действительно удостовериться,
что удостоверится в авторстве этого сообщения.
Верифицировать авторство.
Вот отправитель подписывает своим приватным ключом отправляемое сообщение.
Получатель, зная публичный ключ от правителя, может удостовериться,
что действительно это сообщение отправило.
Вот это максимально эффектно.
Этот механизм, кажется, дает нам самые сильные гарантии, которые только можно представить.
Но он на самом деле кое-чего требует от нас.
В смысле, от системы, которую этот алгоритм использует.
Да, чтобы этот механизм работал, узлы должны знать публичные ключи друг друга.
Вообще говоря, это некоторая подзадача, подсистема, которая тоже касается распределенности,
которая тоже нужно как-то решать.
Мы это чуть подробнее обсудим в следующий раз, когда мы будем говорить про PBFT.
Вот там у нас будет инфраструктура публичных ключей.
Но в конце концов, вы знаете, что интернет на сертификатах работает.
Вы, заходя на какой-то сайт, должны удостовериться, что действительно это публичные ключи.
Ну а для этого у вас есть публичные ключи, опять же.
Ну а почему вы им доверяете?
Откуда вы их берете?
Об этом нужно задумываться.
Но можно себе представить и чуть более слабые гарантии.
А именно, можно считать, что вот если у нас есть два узлы,
и этот узел отправляет сообщение этому,
то этот узел всегда может проверить, что действительно сообщение отправлено этим узлом.
Вот кажется, что это одно и то же, но на самом деле цифровые подписи дают нам чуть больше гарантий.
Но поскольку мы пока их использовать не будем, мы можем эту разницу отложить.
И мы будем использовать эти гарантии.
И мы будем использовать эти гарантии.
Но поскольку мы пока их использовать не будем, мы можем эту разницу отложить опять до следующего раза.
Короче говоря, мы либо верим каналу, либо мы верим прям подписям.
Это вот немного разные вещи.
Но так или иначе, византийский сбоенный узел не может представляться другим узлом.
Это для нас важно.
Хорошо, ну тогда давайте, если ограничения, если сбои нам понятны,
то давайте обсудим какую-то задачу.
Ну вот задача бинарного консенсуса.
Вспомним, с чего мы начинали говорить о консенсусе обычном, с отказами узлов.
Мы сначала обсуждали, в каких условиях задача не решается.
Ну понятно, что мы наследуем теоремы ФЛП, потому что куда надеемся.
И вроде бы ее уже усиливать особо некуда.
Была другая теорема, другой результаты невозможности.
Он состоял в том, что он ограничивал отказу устойчивости в том смысле,
что ваш алгоритм, если он переживал много сбоев и при этом завершался,
то в некоторых сценариях он не может быть успешным.
Если алгоритм переживал много сбоев и при этом завершался,
то в некоторых сценариях он начинал неизбежно врать, то есть нарушать агримент.
Мы доказывали такую нижнюю оценку.
N больше 2F.
Она означала, что если алгоритм готов пережить вот такое количество сбоев
и готов завершаться, то чтобы не нарушать агримент никогда,
то нужно сделать такое количество узлов.
Мы сегодня начнем с того, что докажем такую же оценку снизу для византийской модели.
И что удивительно, она кажется не сильно хуже.
И тут есть некоторая тонкость, которую нужно сразу обсудить.
Модель отказов максимально общая.
Вот она допускает любое поведение.
Кажется, что задача сильно усложнилась.
При этом оценка снизу ухудшилась, она же, заметьте, ухудшилась,
но совершенно незначительно, мы двойку заменили на тройку.
Кажется, что это совсем не страшно.
Но тем не менее, беда наша не в этом.
Не в том, что 2 на 3 поменялось.
Давай рассуждать, что мы в таком плоском мире живем,
где у нас отдельные узлы.
Мы не думаем, как они локализованы, какими группами узлы отказывают.
Вообще, ты про очень интересные и разумные вещи говоришь,
когда мы говорим про византийскую модель,
у нас византийскими могут быть, конечно, не только узлы системы,
у нас могут быть византийскими клиенты.
И они могут честным узлам отправлять очень странные запросы,
абсолютно безумные.
Они будут корректными эти запросы, но они будут какими-то видоносными.
И нужно как-то с этим бороться.
Или, скажем, с протоколом общения клиента и системы.
Но это тема следующего раза.
Сегодня мы говорим про бинарный консенсус, про такую задачу
как раз, чтобы не касаться многих сложностей,
которые нас пока не волнуют.
Мы хотим пока какие-то базовые алгоритмические идеи обсудить,
которые даже от конкретных клиентов,
от конкретного состояния,
которое мы реприлицируем, не зависит.
Да, вот именно.
Мы в наш алгоритм можем заложить какое-то f,
какое-то значение.
Мы готовы пережить два отказа, поэтому берем 5 реплик.
И если отказов не больше, чем два,
то наш алгоритм работает, он отвечает клиентам, все хорошо.
Если же отказы становятся больше, чем два,
то, опять, ничего прям смертельного не происходит.
Потому что, ну, что происходит с нашим алгоритмом?
Он просто не может собрать quorum больше.
То есть он не может обслужить ни чтения,
может быть, что, допустим, обслужить.
Но вот запись в случае он уже не может.
Система не может нарушить safety-свойства,
потому что она не может принять сбойный узел
за работающий.
Вот беда наша не в том, что мы увеличили вот этот коэффициент.
Беда наша в том, что...
Беда наша случается в тот момент, когда мы переходим
через границу числа заложенных отказов.
Вот если отказов в византийском сеттинге
у нас больше, чем заложенное f,
то нет никакого разумного способа
от этого защититься.
Потому что византийские сбойные узлы...
Ну, они, конечно, могут просто, скажем, не работать, не отвечать.
Ну, потому что отказы узлов – это частный случай византийского поведения.
Но они могут притворяться, что не работают корректно.
И если их слишком много,
то наш алгоритм ничего не сможет сделать.
Ну, а действительно, мы же настоящего f не знаем.
Вот это беда.
Ну, мы должны с этим смириться.
Тут мы ничего сделать не можем уже.
Наша задача сначала доказать, что действительно лучше не получится,
а потом уже постараться узнать,
достигается ли вообще эта оценка снизу.
То есть можно ли построить алгоритм, который будет
устойчив к f византийским узлам
и при этом будет использовать всего лишь там 3 f плюс одну реплику.
Ну, давайте сначала поговорим про невозможность.
Итак, мы хотим доказать сейчас, что
для того, чтобы пережить f отказов,
нам требуется, по крайней мере,
3 f плюс один узел.
Мы будем эту тарему доказывать в два шага.
Во-первых, мы рассмотрим частный случай,
когда n равно 3
и f одному.
Сначала поговорим про частный случай, когда у нас
всего лишь 3 узла и покажем, что с тремя узлами
пережить один византийский узел не получится.
Докажем это от противного.
Предположим, что алгоритм все-таки нашелся.
Про алгоритм мы мало что знаем, но вот пусть
он состоит из трех узла,
состоит из трех разных алгоритмов PQER.
Эти три узла способны,
запустив на себе эти три алгоритма,
пережить византийское поведение
любого из них, скажем, узла R.
Покажем, что такого на самом деле не бывает.
Давайте я немного картинку смещу.
Итак, пусть PQER такие нашлись,
что эти три узла могут решить
византийский консенсус, могут решить задачу
консенсуса при условии, что какой-то один из этих узлов
может позволить себе произвольное поведение.
позволит себе произвольное поведение.
Построим некоторую вспомогательную конструкцию, которая будет
очень индуитивной, надеюсь, я смысл ее продемонстрирую вам.
Возьмем 6 узлов.
Вот сейчас я рисую провода.
То есть каждый узел может общаться только с двумя соседями,
только про них знает.
И вот на эти 3 узла мы посадим алгоритм ПКУ и Р.
И дадим им на вход нули.
Да, мы показываем невозможность чего-то, для этого достаточно
рассматривать случай бинарного концерна, как византийских генералов.
А на эти 3 узла мы посадим снова алгоритм ПКУ и Р, но с другими входами.
Вот это, это вход.
Вот это, это алгоритм.
Вот у нас есть 6 узлов.
Им на вход подаются значения.
И мы в этом странном шестиугольном мире эти алгоритмы запускаем.
Вот получается некоторое исполнение альфа 6, назовем вот так.
Есть ли в нем какой-то смысл?
Ну, во-первых, почему я вообще могу так сделать?
Почему я могу запустить алгоритм?
Тут есть на самом деле некоторые тонкости, я их позже прокомментирую.
Но когда мы запускаем эти алгоритмы, конечно, мы каждому сообщаем,
что он на самом деле живет в треугольном мире.
И вот сообщаем узлу вот этому экземпляру алгоритма ПЭ,
этому узлу мы сообщаем, что он живет в мире вот из трех этих узлов.
Он только с ними может общаться, только про них знает.
Поэтому он как-то локально функционирует, думая, что он решает вместе с ними задачу консенсуса.
Так думает каждый.
Что они делают вместе совершенно непонятно.
То есть требовать от них, чтобы они выбрали, скажем, одно значение,
это было бы странно, потому что явно алгоритм для такого не рассчитан.
Так что они просто запускаются, работают и, может быть, что-то выбирают.
Но вот нам сейчас не очень важно, что они решают консенсус.
Каждый из них думает, что решает консенсус, но вместе делает что-то странное.
Но, тем не менее, давайте посмотрим на какие-то пары этих узлов.
Вот, скажем, посмотрим на эту пару.
П0 и К0.
Вот они оба корректны.
Вообще в этом исполнении Альфа-6 византийских узлов нет и не будет.
Тут все действуют честно по протоколу.
Но вот подумаем, как мир выглядит для этой пары узлов.
Вот я бы сказал, что он выглядит, как будто бы эти два узла живут в некотором треугольном мире.
И с ними общается один византийский узел R, волнистый.
Вот у этого узла на входе 0, у этого на входе 0.
И они живут в мире с каким-то странным узлом R с волной, который с Q0 общается, как будто бы у него 0.
Ну, короче, он с Q0 общается, как R0.
А с P0 он общается, как R1.
Ну, или можно сказать иначе, что мы поместили P0 и Q0 в византийское треугольное исполнение,
в котором узел R с волной просто в голове симулирует
вот такую конструкцию.
То есть он как будто бы у себя в голове поместил еще 4 копии алгоритмов, их запустил и вот общается с P0 и Q0 таким вот образом.
Ну, а вот в этом же случае, как бы он и византийский узел,
он просто в голове симулирует вот такую конструкцию.
Ну, окей, наш алгоритм обещал нам в таких ситуациях завершаться и достигать agreement.
Вот здесь на входе у узлов 0, поэтому они должны выбрать только 0.
Так что они вот рано или поздно завершатся, и каждый из них выберет этот самый 0.
По нашему предположению, что этот алгоритм такой нашелся.
Окей, теперь посмотрим на другую пару.
Вот на эту.
Ну, понятно, к чему я кладу.
Вот можно нарисовать такую же картинку.
У нас есть узел R1, у нас есть узел Q1.
У них на входе единицы, они ведут себя честно.
У нас есть узел R1, у нас есть узел Q1.
У них на входе единицы, они ведут себя честно.
И они как будто бы общаются с узлом волнистым P, византийским, который общается с R1,
как будто бы он P0 в этом шестиугольном исполнении,
и ИСКО 1, как будто бы он алгоритм P со входом 1.
Ну опять, вот этот византийский узел, давайте его перекрасим.
Этот византийский узел, можно сказать, что в голове у себя эмулирует вот такой набор, такой подграф.
Ну и по тем же самым соображениям, алгоритмы Q и R должны решать консенсус
при условии византийского P и должны выбрать неизбежную единицу, потому что у обоих на входе единицы.
Значит, вот это исполнение мы обозначим давайте за Δ1, это Δ2.
Ну а дальше какое исполнение мы рассмотрим?
Да, вот мы рассмотрим вот эту пару и подумаем, что происходит с ней.
Ну опять те же самые соображения, это все для них не отличается от треугольного исполнения.
P0, R1 и с ними общается византийский узел Q.
Что же им делать? Что же им выбрать?
В этом исполнении они завершаются, потому что алгоритм решает задачу консенсуса для трех узлов с одним византийским отказом.
Они выбирают что-то общее и выбирают из набора 0 и 1. Оба входа были, поэтому можно выбрать что угодно.
Но для нас важно, что они выбирают одно и то же.
А вот по двум другим соображениям они должны выбрать разное, неизбежное.
И в этом заключается противоречие, и видимо оно нас убеждает, что наше предположение было неверное.
Можно это все объяснить немного по-другому, то есть чуть более интуитивно, а именно сказать, что кажется узел P0 не отличает исполнение
дельта 3 от дельта 1, где вот здесь византийский узел моделирует вот такую часть графа, а здесь византийский узел моделирует вот такую часть графа.
такую часть графа. А узел Q1 не отличает дельта 2,
нет, узел R1 не отличает дельта 2 и дельта 3. То есть можно
с другой стороны на всю эту конструкцию посмотреть,
ну и прийти к тем же самым выводам. Итого алгоритма
для трёх узлов быть не может. Понятно?
Окей, тогда небольшое замечание по поводу этого алгоритма.
А именно мы здесь предполагаем, что византийский узел,
вообще говоря, может симулировать поведение других узлов.
Так чтобы вот эти узлы ничего ни о чём не догадались.
Это, вообще говоря, довольно сильное требование.
И, скажем, если у нас есть приватные ключи, если мы работаем
вот с цифровыми подписями, то было бы странно ожидать,
что византийский узел может моделировать поведение
узла P с его приватным ключом. Него его нет.
Короче говоря, тут нужно быть очень аккуратным,
а способен ли алгоритм понять, что он находится
на самом деле не вот... По-другому скажу.
Вот узел R, он византийский, он, конечно, может делать
всё, что угодно. Но он не может придумать сообщения
от имени, скажем честно, узла P.
И это всё-таки некоторое ограничение.
Так вот, в этой теории на самом деле не явно полагается,
что у нас здесь не цифровые подписи, а у нас здесь есть
провода, в которые мы верим. Это не одно и то же.
Но вы же есть приватный ключ R.
Ну ещё раз, смотри, у тебя византийский узел может
сказать вот этому узлу Q, что он получил от узла P что-то.
Вот если ты веришь в провода, то он может тебе соврать.
А если у тебя есть цифровые подписи, то он про P соврать не может,
потому что ты можешь проверить, что подпись P совпадает.
Вот такая система из зацепленных троек.
Тут сложно понять, что происходит. Мне с трудом удается.
Но ты всё-таки должен понимать, что византийский узел в некотором
смысле ограничен возможности симулировать по единению
других узлов, потому что алгоритм может быть произвольным.
И если алгоритм пересылает постоянно все сообщения всем узлам,
то вот R византийский здесь не может придумать сообщения,
от имени P отправить его Q, если есть цифровые подписи.
А если цифровых подписей нет, и ты просто доверяешь каналам,
то такой обман возможен.
Так вот в этой теории мы предполагаем, что мы доверяем
именно каналам, но без подписи живём.
Потому что иначе ты можешь кочевно догадаться всё же.
Ну смотри, ты взял алгоритм P и поместил его в такой граф.
Он вообще для такого не задуман. Правда ведь?
Вот. И вдруг у тебя алгоритм устроен так, что все узлы посылают
постоянно всем сообщения, которые они от других узлов получали.
Ну ты, конечно, можешь о чём-то умолчать, но с другой стороны,
ты не можешь византийский узел соврать о том другому узлу,
что ты получил от другого честного узла сообщения.
Правда ведь?
Вот R с волной не может наврать Q0, что он получил что-то от P0.
То есть здесь он, конечно, может сказать, что он получил от P1 какое-то сообщение.
Вот. Но он же не знает приватного ключа P. Не может знать.
Поэтому алгоритм может о чём-то догадаться.
То есть, короче говоря, наш R в чём-то ограничен.
В это время мы такие ограничения не учитываем, мы считаем, что эти алгоритмы ничего не поймут.
И это означает, что мы живём в модели, где мы верим в провода.
То есть если мы получили сообщение от R с волной, то мы считаем, что он его отправил.
И мы считаем, что да, он говорит, что ему кто-то сказал.
То есть установить подлинность последнего утверждения мы не можем.
Но, по крайней мере, мы не спутаем сообщение от R с волной от сообщения от P0.
То есть чувствуете разницу между моделью, где мы доверяем каналам и где мы используем цифровые подписи?
Ну вот, здесь мы доверяем именно каналам.
Вот тогда действительно алгоритмы ничего не поймут, что они живут в таком шестиугольном мире.
С этим случаем мы...
Что?
Доверяем каналам, мы как будто прислали цифровый транспорт.
Нет, как будто бы у нас есть некоторый сессионный ключ.
Тут же вопрос про транзитивность.
Ну то есть это и по-другому называется.
Я через неделю об этом подробнее расскажу, когда будет больше поводов.
Речь про то, что происходит, когда один узел получил сообщение от другого и пересылает его третьему.
Что значит цифрование? У тебя есть цифрование между двумя узлами.
У них есть какой-то секретный сессионный ключ.
Они общаются друг с другом, они уверены, что...
Но пересылки ты гарантии теряешь.
И здесь пересылка...
Еще раз.
Мы не решаем задачу шифрования нигде здесь.
Это неважно. Мы решаем задачу аутентификации.
Мы должны проверить авторство.
От кого мы здесь не шифруем данные?
Это хороший вопрос в смысле, что Тебяна спросила, но это не наша цель.
Наша цель аутентификация.
Ладно, давайте вторую часть докажем, потому что нам нужен теперь общий случай.
А именно мы покажем, что не существует алгоритма, когда у нас n не больше 3f.
Как мы собираемся это сделать?
Предположим, что нашелся алгоритм, который решает задачу консенсуса,
переживает f византийских отказов и обходится вот таким числом узлов.
То есть представим, что у нас нашелся алгоритм, который переживает 4 отказа
и обходится 11 узлами.
Вот некоторые произвольные числа.
Почему бы и нет?
Так вот, я сейчас хочу показать, что имея такой алгоритм, мы назовем его a.
Мы с его помощью можем построить алгоритм b для трех узлов,
который переживает один отказ.
Но поскольку такого алгоритма не существует, как мы ранее показали,
то значит не существует алгоритма a.
Ну вот давайте строить алгоритм b.
Здесь было 11 узлов, у нас будет 3 узла, и мы должны посадить на эти 3 узла
алгоритмы P, Q и R.
Вот я предлагаю исследовать немножко некорректной, но довольно смешной
нотации авторов статьи про генералов и говорить, что у нас здесь генералы есть
и здесь генералы есть, их нужно различать.
Здесь будут албанские генералы, здесь будут византийские генералы.
И как будут устроены византийские генералы?
Ну вот у нас есть алгоритм a, который, скажем, работает на 11 узлах.
Тут отдельные алгоритмы на отдельных узлах могут быть разными, неважно.
Мы знаем, что поскольку выполняется такое соотношение, мы можем разделить
группы этих алгоритмов на 3 группы, так чтобы в каждой группе было не более,
чем f узлов.
Вот мы эти группы назовем P, Q и R.
И скажем, что каждый византийский генерал будет у себя в голове моделировать,
так же, как здесь византийский узел симулировал группу других узлов,
здесь вот каждый алгоритм будет симулировать поведение своей группы
албанских генералов.
То есть мы вот этим 3 алгоритмам раздадим вот эти группы алгоритмов.
Дальше.
Когда византийские генералы будут получать на вход значение, скажем,
1 или 0, то это будет означать, что все албанские генералы,
которые, поведение которых симулируют в голове византийский,
тоже получат то же самое значение.
Вот здесь будут все нули, соответственно.
Итого, мы раздали вот этим 3 узлам алгоритмы,
мы дали им входы, они их передали этим албанским генералам,
а дальше мы запускаем протокол, то есть запускаем византийских генералов,
они начинают решать задачу консенсуса.
Это означает, что эти албанские генералы внутри этих византийских
начинают делать то же самое.
Ну и по пути они обмениваются сообщениями.
Так вот, если сообщение, то есть у нас начинается исполнение алгоритма B,
и вместе с ним разворачивается некоторое исполнение алгоритма A.
И в этом исполнении алгоритма A какие-то албанские генералы обмениваются сообщениями.
Так вот, если сообщение отправляется албанским генералам внутри его группы,
то это все происходит в голове одного византийского генерала,
и он просто отправляет и все.
А вот если сообщение пересекает границу групп,
то surrender, то есть албанский генерал A отправляет албанскому генералу C
из другой группы какое-то сообщение, алгоритме A.
То это означает, что византийский генерал L, R отправляет сообщению
византийскому генералу Q, что его албанский генерал A
отправляет его, албанскому генералу C узла Q, какое-то сообщение.
То есть алгоритм начинает работать.
И в ходе работы этого алгоритма B возникают византийские отказы.
То есть какой-то узел Q может отказать.
Что это означает для алгоритма A?
Что в соответствующем исполнении алгоритма A у нас отказывает
некоторая группа албанских генералов.
Но только группа целиком.
То есть у нас к каждому исполнению алгоритма B соответствуют некоторые
исполнения алгоритма A. Но мы такой симуляцией не покрываем
все возможные исполнения алгоритма A. Мы покрываем только те исполнения,
в которых византийскими может оказаться только группа целиком.
Ну, а мы знаем, что алгоритм A по предположению нашему переживает
отказ любых F узлов.
А это означает, что рано или поздно A завершится.
И мы знаем, что внутри каждой группы, которая уцелела все коллектные
албанские генералы, выберут одно значение.
То есть не бывает такого, что в одной группе оказались и сбойные узлы,
и честные. Все сбойные локализованы в пределах одной группы.
Поэтому если узел корректный и завершается, то завершаются и все другие узлы
этой же группы.
Ну, допустим, все выбрали один.
Ну, вот таким образом, если в группе все завершаются и все выбирают одно и то же,
то значит определено понятие выбора для византийского генерала.
То есть можно сказать, что когда первый генерал из группы завершится и выберет значение,
тогда византийский генерал может считать, что он тоже выбрал значение.
Ясно?
Вот вроде бы алгоритм описан, правда?
Это какая разница, что они делают? Они уже контролируются злоумышленником.
В смысле, контролируются злоумышленником узелку. Вот все, эти уже...
Непонятно, что мы от них ожидаем.
Мы предположили, что алгоритм А решает задачу византийского консенсуса и переживает
любые четыре отказа.
Так что если у тебя какой-то византийский генерал сходит с ума,
то сходит с ума разом вся его группа, но другие группы остаются невредимыми.
Потому что мы рассматриваем задачу в таких ограничениях, что у нас BF не больше, чем F.
А если усыреет вся группа целиком, она сохранит свой разум, значит определено,
почему такой выбор для византийского генерала R или P.
Значит говоря, для любого допустимого исполнения алгоритма B на трех узлах
с не более чем одним отказом, ему соответствует допустимое исполнение алгоритма A
с не более чем F отказами. Ну а значит алгоритм A выполняет все свойства консенсуса,
значит наследуется сюда, и здесь они тоже выполняются.
Ну что?
Кажется, что это делать неразумно, потому что цель у нас другая.
А? Нет, не пройдет, конечно, потому что если у тебя в одной группе будет, скажем, 5 генералов,
ну вот скажем, в группе Q у тебя будет 5 генералов, да? Давай сотрем одного здесь и добавим сюда.
Вот, да, избойной будет... Нет, еще раз, если избойной будет группа P, то что страшного-то произойдет?
Ну алгоритм A переживет отказ трех узлов.
Еще раз, когда мы строим алгоритм B, мы берем любое разбиение алгоритмов A на три группы,
нам важно лишь то, чтобы размер каждой группы был не более чем F узлов.
Прости, я, видимо, не схватываю твой вопрос.
Нет, мы не предположили, что они избойные, мы предположили, что алгоритм есть.
Если мы предполагаем, что алгоритм есть, и он переживает F отказов и использует n не более чем 3F узлов при этом,
то я могу разделить их на три группы и построить алгоритм для трех узлов.
И отказ любого византийского такого узла будет отвечать отказу не более чем F узлов в алгоритме A.
Алгоритм A с этим справится и свойства консенсуса не растеряет.
Нет, но если откажет...
Нет, речь, видимо, я, кажется, понял вопрос.
Он переформулирует так.
Рассмотрим другое разбиение, где в одну группу будет одна очень маленькая,
другая очень большая, и если в маленькой группе кто-то сойдет с ума, то это не страшно, да?
Нет, конечно, потому что сойти с ума из византийских узлов может любой.
Я говорю, кто бы из этих трех не сошел с ума, все равно для алгоритма A у нас будет не более чем F отказов.
Если ты их распределишь неравномерно, то если сойдет с ума узел P, у которого один албанский, то, конечно, никто не пострадает.
А вот если сойдет с ума узел Q, то алгоритм A потеряет византийскими сразу много узлов, и тогда никаких гарантий для него уже не будет.
Окей, с этим разобрались.
Ну что, кажется, теорема доказана, да? Что мы скажем?
Обычно она вызывает больше вопросов, но почему-то здесь мне сразу верю.
Ладно, тогда давайте я поговорю про замечание относительно условий этой теоремы.
Вот я сказал, что мы говорим, что у нас нет приватных цифровых подписей, но мы доверяем каналам.
Еще один аспект. Мы нигде не делаем предположения оба синхронности сети, правда?
Вот кажется, что эта теорема, эти рассуждения работают в ходе синхронной сети.
Так что с одной стороны теорема довольно сильна, то есть даже в синхронной сети выполняется такая оценка снизу,
но с другой стороны она исключает цифровые подписи. А мы собираемся использовать цифровые подписи.
Это значит, что каждое сообщение доставляется за некоторое ограниченное время.
Есть оценка сверху, надо время доставки сообщений.
Короче говоря, мы здесь нигде не требовали о сети, чтобы она могла позволить себе работать медленно.
Мы нигде этим не пользовались. Если мы нигде не пользовались этим способствием, то, видимо, его не нужно включать в условия теоремы.
Но можно эту же оценку снизу доказать для других условий, а именно где у нас цифровые подписи могут даже быть,
то мы готовы воспользоваться синхронной сетью, точнее частично синхронной.
Итак, посмотрим на... Ещё раз доказываем, заново доказываем ту же самую теорему,
только теперь не делаем предположений про то, что один узел может симулировать много других.
Это может быть слишком практический случай цифровых подписей.
Но зато у нас есть частично синхронная сеть, которая может задерживать сообщение.
Опять покажем, что у нас имеется до края нижняя оценка. Опять начнём со случая N3F1.
Предположим, что у нас есть три алгоритма.
И пусть... Три алгоритма P, Q и R.
И пусть снова этот алгоритм получил на вход 0, этот алгоритм получил на вход 0, этот алгоритм получил на вход что-нибудь.
И мы запустили этот алгоритм, и может быть даже R не византийский, просто сеть между этими узлами работает очень быстро,
а здесь у нас сообщение задерживает.
И такое исполнение для узлов P0 и Q0 неотличимо от исполнения, где узел R вообще отказал, и дождаться мы его не можем.
И в этом случае мы по свойствам задачи консенса должны рано или поздно завершиться.
В мире, где R отказал, мы обязаны завершиться и выбрать 0.
Просто потому что здесь медленная сеть.
Рассмотрим другое исполнение.
Три узла.
И теперь, чтобы мне не сбиться...
Давайте скажем, что у Q на входе 1, у R на входе 1, у P на входе что-то,
но по-прежнему с ним очень тяжело общаться, потому что сеть очень медленная.
Мы задерживаем здесь сообщение, насколько это потребуется.
И снова алгоритмы Q1 и R1 не могут отличить это исполнение от исполнения, где P вообще отказывает.
Не то чтобы он византийский, а просто не работает.
И по тем же самым соображениям они в этом исполнении должны завершиться и выбрать 1.
Ну а теперь строим третье исполнение.
Вот здесь на входе будет 0, здесь на входе будет 1,
а узел Q будет византийским.
И он с узлом P будет общаться так, как общался узел Q в этом исполнении.
То есть как будто бы у него сознание разделено на две части, и вот здесь он Q0, а здесь он Q1.
А этот канал по-прежнему медленный.
Давайте я буду медленный канал как-то обозначать, чтобы мы его отличали.
Какой-то очень медленный канал.
Здесь медленных каналов было 2.
И здесь медленных каналов было тоже 2.
Ну и что получается?
Что вот это исполнение delta3, оно для узла P0 неотличимо от delta1.
И так же, ну поскольку это исполнение неотличимое, то вот за некоторое время P0 неизбежно выберет значение,
потому что он выбирал это значение в delta1, он выберет значение 0.
Ну и по тем же самым рассуждениям, узел R1, поскольку эти два исполнения для R1 неотличимы от исполнения delta3,
поэтому если он завершался здесь и выбирал 1, то он также завершится здесь и тоже выберет 1.
Гораздо проще, оказывается, да?
То есть у нас либо нет цифровых подписей, либо у нас есть задержки в сети,
все это приводит к тому, что мы не можем преодолеть даже 3 отказов.
Но для того, чтобы обобщить эти рассуждения на общий случай, когда у нас n не больше, чем 3f,
то что мы делаем? Как легко догадаться, наверное.
Ну да, мы разделим на 3 группы и сделаем примерно то же самое.
Что? Что значит повести?
Нет, ну не хочешь неверно.
Если ты говоришь, что клиент своему, у меня так не бывает, то он тоже может тебе поверить.
Но если так случится, то ты ничем себя не защитишь.
Вот мы хотим строить алгоритмы, которые не то чтобы верят или не верят, что бывает или не бывает,
бывают по-всякому.
У нас есть вот уж точно разными способами, в разных предположениях,
оценка снизу, что для преодоления f сбоев в византийском окружении нам требуется,
по крайней мере, 3f плюс 1 узел.
Какие вопросы у нас остаются?
Достижимы ли это оценка снизу?
То есть можем ли мы построить алгоритмы 3 f плюс 1 реплики?
Ответ – да, можем. Через неделю мы это увидим.
У нас остается замечание о том, что когда f, когда действительное число отказов византийских
превышает заложенное значение, то мы теряем всякие гарантии, мы уже не можем
отличить сбоенный узел, мы можем принять сбоенный узел за корректный,
в отличие от модели, где у нас были отказы узлов.
Ну и давайте за оставшееся время попробуем и попробуем вам объяснить,
с помощью каких инструментов, помимо криптографии,
помимо цифровых подписей и хэш-функций, про хэш-функции я вам не сказал,
помимо всего этого, какие инструменты могут быть использованы,
какие инструменты нужно использовать для того, чтобы жить в такой модели отказов.
Да, маленькое замечание, которое я упустил.
А именно, что когда мы пользуемся цифровыми подписями, то мы, как правило,
подписываем не само сообщение, это может быть довольно затратно,
мы подписываем хэш от сообщения.
Хэш-функции тоже могут быть криптографическими, как цифровые подписи.
Да, и, наверное, я не сказал какие-то очевидные вещи,
но, надеюсь, мы, люди, все понимаем здесь, что подпись – это не то,
чтобы ее можно оторвать от сообщения, прикрыть к другому сообщению,
подпись от сообщения неотделима.
То есть, вы подписываете хэш, и вы не можете, если вы адверсере,
то есть, вы злоумышленник, вы числительно ограничены,
то вы не можете ни коллизии хэш-функций подбирать,
так бы вы могли подобрать другое сообщение с тем же самым хэшом
и переиспользовать подпись.
И вы не можете, конечно же, саму подпись подделать,
потому что вы не можете дискретно алгорифом считать эффективно,
или вы не можете на простые множители складывать что-то.
Вот мы в это верим, в смысле, что это нельзя делать эффективно,
и вот на этом предположении все держится у нас, вся аутентификация.
Ну что ж, оценку снизу мы доказали, давайте теперь построим какой-то алгоритм.
Он будет решать задачу бинарного консенсуса,
что оно абсолютно бесполезно, но цель этого алгоритма не в том для нас,
не в том, чтобы консенсус решать, а в том, чтобы продемонстрировать,
с помощью какого инструмента мы в следующий раз можем строить
какие-то уже разумные и полезные алгоритмы.
Итак, решаем задачу бинарного консенсуса алгоритм Ben-Ora.
У нас есть n узлов, у них на входе 0 и 1, они должны выбрать общее значение, как обычно.
Давайте я сначала расскажу про версию алгоритма,
которая работает в модели crash-failures, то есть с отказами узлов, но без изантийского поведения.
У нас для этого уже есть Paxos и Raft, но мы удобно алгоритм сначала изложить в этой модели отказов.
Итак, у каждого узла будет вход, и на старте каждый узел будет...
У каждого узла будет состояние.
Это состояние образовано, во-первых, переменной preference,
в которую изначально передается вход узла.
Preference это текущее пожелание узла относительно выбора.
Вот он хочет, чтобы было выбрано такое значение.
И у каждого узла будет переменная round, в каком round он находится,
и в каждом раунде алгоритм пытается что-то выбрать.
Изначально все в нулевом раунде.
Алгоритм делится на раунды, в каждом раунде две фазы, в каждой фазе два шага.
Итак, первая фаза.
Каждый узел отправляет другим узлам, всем другим узлам сообщение vote,
куда прикладывает свой preference и номер раунды.
На втором шаге первые фазы.
Каждый узел дожидается, пока он не соберет...
Сколько у нас всего узлов, я не сказал.
Всего узлов у нас...
Ну, видимо, 2F плюс 1 для случая crash failures.
Пока не соберет большинство сообщений о других узлах.
Где white? Ну, либо 0, либо 1.
Давайте это напишем, что задача бинарная.
Вот только 0 и 1.
На второй фазе, перед второй фазой, вернее, после того, как узел,
после того, как он собрал большинство голосов, он смотрит на эти голоса.
Если он видит, что все входы, все волты, которые он получил с одним и тем же значением,
то он посылает всем узлам сообщение propose.
Ну, либо если голоса разделились, которые он получил, там были и 0, и 1,
то вместо V посылается знак вопроса.
То есть, либо propose знак вопроса R.
И на втором шаге второй фазы каждый узел опять собирает большинство пропозов.
Знак просто плохо рисовать уже. V или знак вопроса R.
И дальше анализирует то, что он собрал. У нас три ветки.
Если все сообщения, пропоз, который он получил, содержали одно и то же значение V,
оператор мне видно?
Давай проверим, в смысле, удостоверим все, что меня видно.
Видно, да? Давай все-таки немного смещусь, чтобы было безопаснее.
Если все пропозы, которые узел собрал, содержали какое-то значение V,
то алгоритм просто выбирает в этом раунде V.
Вот это выбор в смысле консенсуса.
Если же узел получил хотя бы один пропоз без знака вопроса,
то тогда он обновляет свой преференс.
Если же все пропозы содержали знак вопроса,
то тогда в качестве преференса для следующего раунда выбирается что?
Нет, ты совсем не чувствуешь идею. Мы подбрасываем монетку.
У нас же бинальный консенсус. Нам нужно выбрать у ныря единицы.
Мы знаем, что у нас есть у ныря единицы среди узлов, так что мы подбросим монетку и выберем что-то случайное.
Вот такой алгоритм. Нам нужно теперь доказать, что он коллекционный,
а потом дальше из него сделать какую-то византийскую версию.
Но для начала вопрос на понимание, а верно ли, что алгоритм коллекционно сформулирован вообще?
Нет, ну разумеется, он может не закончиться. Мы все время доказывали про это.
Конечно, он уже монетки подбрасывает.
Тут можно усомниться просто в корректной постановке этого алгоритма.
Ну вот смотрите, у нас есть три ветки, по которым мы можем пойти в конце каждого раунда.
Да, вот мы выиграли один из трех исходов и после этого перешли в следующий раунд, увеличили наши перемены.
Так вот, второй переход вызывает сомнения, потому что а вдруг мы получили прополз и с нулем, и с единицей?
Не совсем понятно, как мы тогда действуем. Правда?
Ну вот утверждение, что такого не бывает просто.
Что в пределах одного раунда вы не можете получить два проползу с разными значениями.
Почему? Потому что если вдруг такое произошло, то есть какой-то узел х отправил прополз 1r,
то это узел у отправил в этом же раунде прополз 0r.
Так вот, такого не бывает, потому что чтобы отправить прополз 1r, нужно сначала собрать большинство голосов за ноль,
за единицу, простите, а здесь точно также за ноль.
Ну а значит в пересечении есть какой-то узел, который поголосовал из-за ноль из-за один из предел одного раунда,
такого не бывает. Так что алгоритм, по крайней мере, можно закодировать, и тут ни однозначности не будет.
Но что нас беспокоит? Опять нас беспокоит agreement.
Мы хотим показать, что если два узла убирают значения, то они убирают одно и то же.
Ну мы поступим так, мы скажем, что пусть какой-то узел в конце какого-то раунда пошел по этой ветке.
То есть он получил, почему он это сделал? Потому что он получил все проползы, скажем, за ноль.
Ну тогда я утверждаю, что в следующем раунде у всех узлов на входе будет один и тот же preference.
Ну не на входе, а просто все узлы. Почему?
Если какой-то узел пошел по первой ветке, то это означает вот какой-то узел х.
Если он сделал выбор, скажем, выбрал один, то это означает, что какой-то quorum прислал ему
прополз 1r.
И при этом любой другой узел y в этом же раунде собрал тоже большинство проползов каких-то.
Ну в том числе, по крайней мере, один прополз от узла, который был в пересечении, то есть в этом quorum.
И вот какой-то узел, по крайней мере один, прислал y прополз со значением 1.
Ну а мы сказали, что в этом случае этот узел пойдет по этой ветке и обновит себе preference до 1.
То есть если в каком-то раунде один из узлов выбрал значение, то в следующем раунде в preference
каждого другого узла будет то же самое значение, а дальше они уже просто не могут сделать что-то иначе.
Ну вот, абсолютно бесполезный для нас алгоритм, который что-то делает, мы как-то доказали.
Короче, дальше нам нужен для другого, для того, чтобы из него сделать византийский.
Ну вот, я сейчас хочу сделать из него византийский, при этом не сильно что-то меняю.
Сейчас я не буду строить его инкрементально, я просто сейчас с неба его брошу на вас,
а дальше мы из него сделаем какие-то выводы. Вот целыми будут выводы и не самый алгоритм.
Во-первых, чтобы сделать из этого алгоритма византийский, мы возьмем 5f плюс один узел.
Тут сейчас будут какие-то подогнанные числа, опять же, не нужно сейчас сильно в какую-то интуицию погружаться,
нам это не очень важно. Мы скажем, что опять у каждого узла есть preference, узлы находятся в раундах,
и в начале первой фазы каждого раунда мы отправляем вводы, а потом дожидаемся какого числа вводов.
Какого числа мы можем себе позволить дожидаться, если у нас 5f плюс один узел, и мы готовы пережить f отказов.
И мы дожидаемся 4f плюс одного ответа.
И если оказывается, что среди этих ответов, среди этих вводов больше 3f одинаковых,
то мы посылаем всем проповз с этим значением.
Ну а иначе посылаем снова знак вопроса.
Ну а здесь мы снова дожидаемся 4f плюс одного проповза.
И если мы получили больше 3f проповзов с одним и тем же значением, то мы его выбираем.
Если мы получили по крайней мере f проповзов с одним значением, то мы обновляем свой preference,
чуть хуже. Ну а в остальных случаях мы подбрасываем монетку.
Да, забыл провалидировать ваше понимание в прошлый раз, в смысле в алгоритме без византийских отказов.
А почему он завершается?
Ну давайте по-другому. Можно ли в нем заменить вот эту процедуру подбрасывания монетки, скажем, на ноль?
Или на один? Дотерминированно?
Что бы это значило? В смысле, могу ли закодировать так?
Ну действительно, если ты получил только знаки вопроса, ты знаешь, что у тебя на входе 0 и 1 есть.
Но стоит ли так делать?
Не стоит, потому что, понятно, тогда получится детерминированный алгоритм, подверженный FOPтиареме.
В нем есть лайфлог, который может длиться бесконечно.
С подбрасыванием монетки все лучше. Мы знаем, что на каждой фазе у нас могут быть проповзы
только со знакомыми вопроса или с одним из значений, либо с 0, либо с единицей.
Так что в каждом раунде у нас все узлы делятся на узлы, которые получили одно значение,
и узлы, которые получили только вопросы.
Так что в каждом раунде вероятность того, что в этом раунде все закончатся одним и тем же преференсом,
она кажется не меньше, чем единица на 2 в степени N.
Верно?
Потому что какие-то узлы уже получили общее значение, в качестве преференса уже выбрали общее значение,
а какие-то узлы подбрасывают монетки, но в худшем случае это все узлы.
Ну а так что у нас есть, пусть экспоненциальные, но все-таки от ожидания того,
что алгоритм какое-то количество итерации сделает и выберет значение.
Но он довольно тупой, он даже не пытается консенсусить, он просто подбрасывает монетки,
он проверяет, что они правильно упали все.
То есть не то, что очень сложно.
Ну а дальше мы с ним делаем византийский.
Подкручиваем параметры, теперь у нас 4f плюс 1q, и 3f это пороги.
Так вот, давайте сейчас покажем, что примерно таким же образом,
что алгоритмом остается коррекцион даже при условии византийских отказов.
Ну давай напишем else.
Это конечно не остается, потому что у тебя византийские узлы могут просто выдумывать что-то.
Те же самые шаги в рассуждениях.
Опять нужно побеспокоиться о том, что вот эти 3 ветки корректно определены.
Почему не может быть такого, что во второй ветке мы можем пойти и по ветке с 0, и по ветке с 1?
То есть почему не может быть такого, что какой-то узел получил 2 f проповозов,
f плюс 1 проповоз с 0, f плюс 1 проповоз с 1?
Опять, почему так могло случиться?
Потому что набрался quorum узлов, которые отправили x, допустим, единицы в качестве голосов,
а другому узлоне отправили в качестве голосов 0.
Вот сейчас говорю некорректно.
Нашелся quorum, который отправил в качестве ваута единицы, нашелся quorum,
который отправил в качестве значения ваута 0.
Какого размера эти quorums?
Ну нет, это сейчас неправда.
Еще раз, чтобы проголосовать за проповоз, мы дожидаемся 4 f плюс 1 от ваута,
и если среди них по крайней мере 3 f одинаковых, то мы посылаем какой-то проповоз.
Вот если мы посылаем проповоз 1, то это значит, что мы получили по крайней мере 3 f ваутов с единицей.
И здесь мы получили по крайней мере 3 f ваутов с 0.
Больше 3 f, да. Спасибо.
Но какие дальше рассуждения? Дальше наши рассуждения вообще, говоря, ломаются.
Но по крайней мере нельзя сказать, что quorums пересекаются по одному узлу,
а этот узел отправил только один ваут. В пересечении этих quorums могли находиться византийские узлы,
они могли врать, они могли отправить разные вауты разным узлам в одном раунде.
Сколько узлов в пересечении?
Вот здесь всего у нас 5 f плюс 1, здесь по крайней мере 3 f плюс 1, а здесь по крайней мере 3 f плюс 1.
Значит, в пересечении у нас больше f узлов.
А это значит, что среди них есть по крайней мере один корректный.
И вот ровно поэтому мы получаем наше утверждение, что не могло быть такого,
что получилось два разных проповза в пределах одного раунда.
Первый шаг готов. Второй шаг, напомню, в чем он состоял.
Мы говорили, что если какой-то узел корректный пошел по этой ветке, по первой ветке, то есть он выбрал значение,
то в следующем раунде все корректные узлы в качестве преференса будут иметь одно и то же вот и это же значение.
Почему узел x пошел по первой ветке? Потому что он получил много одинаковых пропозов.
Посмотрим на другой узел y в пределах того же раунда.
Вот он ожидал 4 f плюс 1 пропоз.
Сколько в пересечении узлов?
Изучаем рифметику.
Вот в пересечении у нас такое количество узлов.
И смотрите, среди них могут быть византийские, но их этих византийских не более чем f.
А значит, по крайней мере, f плюс 1 честных.
А это значит, что если какой-то узел в раунде пошел по первой ветке, то любой другой узел получил,
по крайней мере, f плюс 1 пропоз с вот этой самой единицей, вот честных узлов.
Поэтому он идет по второй ветке. Значит, он обновит себе преференс.
Ну а других пропозов, конкурирующих в одном раунде, не бывает, потому что мы от них защитили здесь.
Так что в следующем раунде на старте у всех честных узлов на входе будет одно и то же значение.
Ну вообще говоря, и этого мало, и нужно дальше убедиться, что оно не потеряется.
То есть, если вы честный узел, и дальше вы собираете, скажем, 4 f плюс 1 голос от всех узлов,
то вы знаете, что среди этих 4 f плюс 1 не более чем f византийских.
Поэтому после первого раунда вы получите, по крайней мере, 3 f волтов с одинаковым значением.
Так что если на старте раунда все корректные узлы стартовались с одинаковым преференсом,
то это значит, что дальше они его тоже не потеряют. Ну и такие же рассуждения для второй фазы.
Вот такой алгоритм. Почему он нам полезен? Он нам полезен, потому что алгоритм сам бесполезен.
Предлагается его забыть сразу же. Он нам полезен будет, потому что он демонстрирует технику,
которую мы дальше собираемся использовать, а именно он нам говорит о том,
как правильно работать с коровами в византийском окружении.
Вот давайте алгоритм сотру, чтобы забыть о нем. Он нам правда не важен.
Нам важно, что мы в нем увидели, как работают византийские клорумы.
Это второй наш важный инструмент вместе с криптографией и с цифровыми подписями,
с криптографическими хэш-функциями. Давайте вспомним про интуицию, стоящую за кворумами.
У нас узлы могут отказывать, поэтому мы не хотим дожидаться ответа от всех.
Вспомним, как мы кворумы использовали на второй лекции, когда мы говорили про атомарный регистр.
У нас была операция записи, операция чтения, и мы писали версионируемые значения,
чтобы потом отличать старые от новых. Вот пусть мы что-то на кворум пишем,
кворум на запись, а потом с кворума читаем, кворум на чтение.
Пишем мы какую-то пару значения и временная метка.
Что нам кворумы гарантировали? Что если мы записали значение на кворум,
версионируемое, чтение завершилось, и после этого мы стартовали чтение,
то кворум на чтение пересечется с кворумом на запись.
Как мы по-другому, как мы читаем? Мы собираем ответы с любого кворума на чтение.
Эти ответы могут быть двух сортов. Во-первых, мы могли получить ответ от реплик,
которые вошли в R, разумеется, но не вошли в W, и в них будет устаревшее значение.
И актуальные ответы от реплик, которые входили в кворум на запись.
Как мы отличим эти два типа ответов? Вот актуальные от устаревших.
Просто по временной метке. Мы выберем максимум, и мы будем уверены,
что мы взяли ответ с одной из репликов пересечения кворумов.
А теперь представим, что у нас мир византийский. И теперь у нас от реплик кворума R
три типа ответов. Это устаревшие ответы от честных реплик, которые не вошли в пересечение.
Это актуальные ответы от честных реплик, которые вошли в пересечение.
И выдуманные ответы от византийских реплик, каких угодно.
Давайте я нарисую зеленым.
Это реплики с актуальным значением, которые ведут себя честно.
И они дают нам максимально актуальную версию значения.
И есть византийские узлы. Они находятся здесь, они находятся где-то здесь, и они значения выдумывают.
И теперь вы не можете просто так отличить. То есть вы можете по-прежнему отличить корректные
устаревшие значения от корректных актуальных по временной метке.
Но вы не можете отличить корректные актуальные от выдуманных.
Вы не можете отличить зеленые ответы от красных.
В самом деле, что мешает византийскому узлу просто выдумать значения с временной меткой 100-500.
Как же быть?
Но зачем? Я вам только что алгоритм рисовал, а потом стирал его.
Потратил столько сил.
Вот мы не можем просто выбрать значения с максимальной временной меткой.
Нам нужно какой-то более сложный протокол чтения с Quorum теперь.
Нам нужно, чтобы зеленые ответы подавили красные ответы.
Вот предлагается сделать так. Сказать, что у нас теперь любые два Quorum'а в нашей системе
византийских Quorum'ов пересекаются. Вот Quorum на запись, Quorum на чтение.
Что два этих Quorum'а должны пересекаться, по крайней мере, по какому количеству узлов.
У нас, видите, здесь было два варианта. Я, собственно, хочу сейчас про эти два варианта рассказать.
По 2F плюс 1 узлу. Иначе говоря, в пересечении, по крайней мере, F плюс один корректный.
То есть я хочу, чтобы число честных репликов пересечения Quorum'ов на запись чтения
было больше, чем число византийских узлов, которые могут выдумывать ответы.
Тогда читать я буду так. Я соберу ответы с Quorum'а, оставлю только те, которых просто больше, чем F,
и среди них выберу максимальный timestamp. То есть я хочу, чтобы честные реплики с актуальным значением нашего регистра
количеством просто задавили византийские реплики, которые выдумывают значения.
Для этого я беру Quorum'ы пожирнее.
Ну максимально, разумеется. Если ты ничего не понял, нужно заново объяснять.
С какого момента?
У тебя проблема в том, что не актуальные ответы от честных узлов, это вся белая область,
актуальные ответы от честных узлов и выдуманные ответы от византийских узлов.
И вот эти ответы от этих ты легко отмечаешь, потому что у этих меньше timestamp.
Беда в том, что ты не различаешь зеленые и красные. На уровне твоей логики с версионированием.
Но ты различаешь их количеством. Ты говоришь, сделаю так, чтобы зеленых было больше, чем красных.
Если я это гарантирую, то есть если я гарантирую, что у меня зеленых, по крайней мере F+,
то я могу, получив ответ из Quorum'а, сначала оставить только те ответы, которые повторяются,
по крайней мере F+, один раз, и среди них выбрать максимум.
Вот максимум отфильтрует эти вопросы, эти ответы, а ограничение на F+, F1 копию отфильтрует красные ответы.
То есть я два фильтра использую.
Такая система Quorum'ов называется маскирующей.
И есть второй тип Quorum'ов. Второй тип систем Quorum'ов.
Где Quorum' на запись и Quorum' на чтение пересекаются, по крайней мере, по F+,
или иначе, по крайней мере, по одному корректному.
Вот нам здесь этого было достаточно. Мы выбирали между 0 и 1, грубо говоря,
и нам нужно было убедиться, что никакой корректный узел не мог проголосовать дважды.
Есть более общая интуиция. Эта система Quorum'ов называется
disseminating, рассеивающая.
Тут название, я не знаю, насколько они удачно говорящие. Мне кажется, что не очень.
Но суть такая, если у вас данные, вот как здесь, нельзя никак верифицировать,
что они не выдуманные, то тогда вы должны задавить византийские узлы количеством.
Поэтому вы используете систему Quorum'ов, где пересечение довольно жирное.
Но предположим, ваше значение, которое вы пишете, а потом читаете,
это не просто какие-то значения, это то, что называется сертификатом,
это значение, подписанное снабженной цифровой подписью.
И византийский узел не может его выдумать.
В следующий раз мы будем как раз собирать, у нас в Quorum'ах объекты,
которые мы передаем через Quorum, будут являться сертификатами.
То есть мы будем собирать чужие голоса, потом их куда-то передавать.
И вот византийские узлы не могут их уже выдумать.
И нам достаточно, чтобы в пересечении был, по крайней мере, один коллектный узел,
потому что византийский узел может только скрыть информацию, но он не может ее породить.
Поэтому одного честного узла достаточно, чтобы раскрыть полную информацию.
Ну вот две такие системы Quorum'ов.
Правильным образом из них, выбирая ту или иную, которая больше подходит,
вы можете дальше Quorum'у использовать живя с византийскими отказами.
Ну что скажете? Есть вопросы?
Если нет, то главное сегодня все, а в следующий раз мы, воспользуясь нашими наработками,
а именно нижней границей, цифровыми подписями, то есть криптографией,
и византийскими Quorum'ами такими и такими, построим, ну, некоторый аналог, не знаю,
рафта, мультипаксиса, но то есть алгоритм, который реплицирует произвольное состояние
и справляется с византийскими отказами лидеров, клиентов, реплик, разумеется, чего угодно.
Вот он будет более-менее похож на рафт и будет повторять его идеи, правда, вот с такой византийской спецификой.
А еще через неделю мы поговорим про Bitcoin, который решает, в общем-то, ту же самую задачу,
но делает это совершенно иным образом, и мы вот почувствуем,
почему он делает все по-другому и чем это ему обходится.
Там вообще-то сложно, то есть тут много чего в нем меняется, вот давай доживем,
и я разницу приористирую, а в самом-самом конце, на последнем занятии, я расскажу про результат 2019 года, кажется,
где научились совмещать одно с другим и получать сильные стороны двух протоколов.
Еще вопрос, последние хворомы использовали здесь?
Ну вот мы использовали в том-то и дело, что мы в этом алгоритме Benora использовали оба типа хворомов,
когда мы выбирали, за кого, какое значение предлагать, мы использовали такие вот хворомы,
нам было достаточно, чтобы в пересечении был только один ответ,
потому что тут выбор бинарный, либо 0, либо 1, поэтому куда бы лизантийские узлы не примкнули, нам не страшно,
а здесь уже было важно, что пересечение хворомов довольно большое,
короче, мы использовали здесь и вариант, когда в пересечении много корректных узлов больше, чем в лизантийских,
и когда всего лишь одного корректного было достаточно.
Ну здесь это немного по-другому было, мы не можем поделать, потому что у нас бинарные значения,
там были 0 и 1, тут поделывай, не поделывай.
Ну что, если вопросов не остается теперь, то перерыв.
