Отлично. Тогда смотрите. Наш план на сегодня. Я могу что-то рассказать, но в первую очередь я бы
поговорил про задачи, которые есть в домашней работе, и про ваши вопросы, которые должны были
возникнуть там. Ну, если они не возникли, я сам их обозначу, потому что в задачах есть,
безусловно, о чем подумать. Ну, конечно, было бы здорово, если у нас было больше сейчас,
потому что вопросов всегда было бы больше. Да, отлично. Я хотел бы поговорить сейчас в первую
очередь про две задачи. Про мютекс в смысле про фьютекс, на самом деле, и про атомики,
про спинлок в смысле про атомики. Вот. Там есть еще другие задачи. Ну, дедлок мы, кажется,
обсуждали, философов. Про философов можно было бы поговорить, но, наверное, в чуть более полном
составе. Давайте сначала поговорим про задачу спинлок. Вот, обращаю внимание, кто здесь делал,
вообще, из присутствующих? А вы избегаете этой задачи? Ну, тогда я... Не знаю, может быть,
для тебя так будет даже удобнее, а, может быть, и лучше было бы наоборот, кто знает. В этой
задачи, на самом деле, есть две... Есть формальная задача. Написать какую-то реализацию. Так ты в
курсе про условия, да? Вот. Написать о тамарной операции, которая позволит спинлок работать. И вот у вас
есть какая-то заглушка. Она, ну, вроде бы, в какой-то степени даже реализация, непонятно, тамарная или
нет, просто скорее иллюстрирует семантическую операцию, что каждый из этих лоудов, сторов,
вообще, что-нибудь должен делать. Вот одна половина задачи — это и про то, что такое отомарность. Какие
инструкции мы считаем отомарными? Как вообще об этом можно думать? Как реализована разная тамарная
операция? Вторая часть задачи, мне кажется, не менее важная. Может быть, даже она точно не менее
важная, и она точно намного более сложная. Это вот этот пункт из условия. Про то, чтобы подумать,
а почему атомик ваш отличается от стд-атомиков, в котором на самом деле стор — это не одна операция,
а... Ну, это один метод с тремя разными аргументами. И эти аргументы, дополнительный memory-order,
который называется, почему-то влияют на реализацию. И это тоже можно поисследовать. Ну, в общем,
без этих вопросов, без этого пункта задача, конечно, неполна будет. И про эти тесты это
совсем не самая интересная задача. Это скорее первый, самый незначительный ее шаг.
Задача, на самом деле, про исследование. Вот у вас есть первый понятный пункт — реализовать
атомарные операции. И вы пишете какой-то код, вы, может быть, даже где-то его не меняете,
где-то вы меняете его. Он начинает работать. Но вот, смотрите, одного этого мало, конечно же. То,
что вы прошли тесты, ничего не означает. Это дает какую-то надежду, но, с другой стороны,
вот вас самих это убеждает, что ваша реализация атомарная, что ваша реализация правильная или нет?
Нет. Ну, то есть вы должны убедить... Конечно же, вы учитесь для себя, чтобы себя убедить,
что вот действительно вы написали правильную реализацию. Но и на защите нужно будет убедить меня.
Поэтому вам нужны какие-то более убедительные аргументы, нежели чем пройденные тесты. Тем более
тесты, еще раз повторяю, у нас недетерминированные... Ну, в смысле, баги недетерминированные,
поэтому если баг просто не возник в тестах, это не значит, что его нет. То есть если он возник,
то точно знаем, что он есть, но если не возник, то, возможно, он есть. Возможно и нет. Мы эти
ситуации не различаем здесь, поэтому нам нужен какой-то более надежный референс, на который можно
соспаться. Ну, прежде чем эти референсы обсуждать, давайте какие-то общие свойства там атомарности
на уровне процессора обсудим, то есть то, о чем мы точно верим. Вот скажем, ясно ли, что если
мы на Assembler пишем две инструкции, то они точно в совокупности не могут быть атомарными. Вот
между двумя этими инструкциями что может случиться? Чуть аккуратнее, может случиться
прерывание интерапта. Вот процессор просто переключится на исполнение обработчика этого
интерапта, но, видимо, на какой-то код ядра. Потом он к нам вернется. Ну, то есть и что в этом обработчике
ядра может происходить? Может быть, это было прерывание по таймеру, там запустится процедура
планировщика операционной системы, планировщик выберет другой поток и намажет его регистры на
процессор, и процессор побежит дальше в другой код исполнить другие инструкции. Так что две
инструкции это точно не атомарно. Но с другой стороны, есть инструкции, которые, скажем, работают только
с регистрами. Вот мы двигаем что-то из одного регистра в другой регистр. Вот такие операции... Тут
про атомарность вообще смысла говорить нет, потому что операции над регистрами это дело локальное
для ядра. Каждого ядра свой собственный набор регистров, и пока это ядро общие ячейки памяти
не трогает, вообще вопрос об атомарности не встает.
По-моему, у нас может быть есть... Ну в МУВ МУВ он атомарный, потому что это же всеизмичное
уритмное слово. А вот МУВы, которые МУВы меньше объема, они, кажется, не атомарные, потому что там еще
поравнивание включается. Нет, все атомарно, конечно. Ладно. Аккуратно. Все атомарно. Конечно не все атомарно.
Аккуратнее. Вот есть две инструкции, они в совокупности не атомарные, это мы хорошо понимаем. Еще одно
свойство, которое важное, в котором мы тоже сомневаться не должны, но которое я не проговорил,
а очевидным оно, возможно, не является. Вот мы смотрим на Atomic, у него довольно много операций
атомарных. Сейчас мы вернемся. Вот фиджи, всякие вот вариации фиджи чего-нибудь,
Compare, Exchange, Exchange, Load, Store. Но я Wait на TFI не беру, потому что это все сколы в ядро, это вообще не
про атомарность операции, не про инструкции процессора. Так вот, вот все эти операции, Load,
Store, Exchange, Compare, Exchange, Fidget, у них есть общее свойство. Они все работают только с одной
разделяемой ячеек памяти. Вот, скажем, вы смотрите на операцию Exchange, и вот если вы, скажем так,
неаккуратно, вы можете подумать следующее, что операция Exchange свопает две ячейки памяти. Вот то,
что в аргументе и то, что слева от вызова, перед точкой написано. Это, конечно же, не так. Мы понимаем это?
Или не понимаем? Вот мы передаем туда аргумент, значение, которое мы хотим записать. Аргументы
передаются через регистры, ну или через стэк. Но что регистры, что стэк? Это вот память,
которая локальна, она не разделяется между разными потоками, по крайней мере, пока мы сами это,
народ, что не сделали. Вот у всех инструкций, через которые реализуется атомарная операция,
есть общее свойство. Они всегда работают только с одной ячейкой памяти и с какими-то регистрами.
Вот то есть, если мы говорим про реализацию Exchange, собственно, в «домашке» нужно будет найти
инструкцию, которая реализует эту операцию. Вот вы там свопаете значение из регистра, то есть,
локальное значение для вашего ядра, с содержимым ячейки памяти. У вас есть более сложные инструкции,
вот скажем, есть операция Compare Exchange. Знакомы ли вы с ней? Вот. Ну, небольшой спойлер, но,
кажется, уже не страшно. Есть задачи в «домашке», которые специально про то, чтобы про эту операцию
узнать. И вот, она довольно... Что? Тебя интересует формальный ответ или содержательный? Содержательный,
я от содержательного уклонюсь. Формально отличается тем, что Вик может, во-первых,
семантика. Сравнить, если совпало, то записать, и вернуть true, если не совпало, то вернуть false.
Вот. Само по себе операция сложная. И вот для неё есть какая-то отдельная инструкция,
которая её реализует. И опять она работает с одной ячейкой памяти и набором регистров. Вот в
регистры вы помещаете, перед выполнением этой инструкции, что вы хотите, что вы ожидаете,
увидите ячейки памяти, что вы хотите записать в ячейку памяти. Вот. И инструкция выполняется,
и вот, как бы, статус, то есть, результат, и ещё какой-то регистр. Опять, всегда любая сложная
Тамарная операция, любая сложная такая инструкция, она будет трогать только одну ячейку памяти. В
процессоре в любом, в принципе, невозможно написать инструкцию, которая была бы... Нет таких
инструкций, таких процессоров, кажется, с такими инструкциями, где можно было бы, скажем,
свопнуть две ячейки памяти или скопировать ячейку памяти в другую ячейку памяти Тамарную. У этого
правила есть некоторые исключения. Вот, скажем, есть Compare Exchange 16B, то есть это Compare Exchange
на 16 байтах, то есть на двух машинных словах. В некоторых современных процессорах Intel вы
можете сделать Compare Exchange над 128-битным словом, то есть на двух ячейках, но только при условии,
что они лежат прямо в памяти рядом, подряд, там и выровнено определённым образом. Или, скажем,
есть такое понятие, как транзакционная память. Вот вы базу данных посещали, вы знаете,
что есть транзакции? Есть транзакции, не знаете про транзакции. Ну, в общем, если коротко говорить,
то некоторые процессы, не знаю, удачная эта идея или она оказалась неуспешным экспериментом,
но в общем, в некоторых процессорах есть поддержка так называемой транзакционной памяти,
где вы можете атомарно потрогать сразу несколько ячеек. И, может быть, операция будет успешной,
а может быть, она провалится, потому что вот что-то пошло не так, почему это отдельная история,
а она скорее про... В лекции про QC немного про это расскажу. Ну, в общем, это всё некоторые
исключения, некоторые маргинальные случаи. Вот, в общем, можно считать, по крайней мере,
про Atomic, что все операции, которые он умеет, он... Все операции, которые он выполняет на процессоре,
здесь атомарные, Ridley-Fairbite, они все работают всегда только с одной ячейкой памяти. Это ячейка
памяти, это сам Atomic. Все остальные аргументы – это регистры. Значит, это второе наблюдение
про атомарность операции. То есть две инструкции не атомарны, между ними может вклиниться другой
поток, может приключение случиться. Атомарные инструкции могут работать только с одной ячейкой
памяти. И третье важное замечание, что отдельная инструкция не обязана быть, вообще говоря, атомарной.
Ну, ответ здесь я не знаю, почему, я могу только некоторую интуицию предложить. Вот, скажем, есть
инструкция Move. Чем она занимается? Move? Только этим занимается.
Можно регистр скопировать, можно из памяти в регистр прочесть, можно из регистры в память
записать. Вы же понимаете, что это не может быть одна инструкция в процессоре? Не атомарно. Нет,
это дело не в атомарности, а в том, что инструкции процессора, инструкции в ассемблере – это же,
ну, некоторый интерфейс. Понимаешь, что Move не может выполнять и то, и другое. Реализации в
процессоре должны быть разные. И вот в процессоре есть некоторый микрокод, то есть, как он по-настоящему
работает, а есть некоторый интерфейс, который просто он сохраняет, чтобы ваши программы старые не
развалились ассемблянные. Вот, поэтому отдельная инструкция атомарности не означает само по себе.
Ну, вот Move будет атомарен, а вот, скажем, вот этот самый Compare Exchange, он уже не будет атомарен. То
есть, сама инструкция, она не атомарна. И для того, чтобы она стала атомарной, чтобы она превратилась в
операцию Compare Exchange, там, Vicarious Strong, нужно кое-что еще сделать. И вот, ну, в этом и смысл Домашки,
чтобы узнать, что нужно сделать. Вот здесь это как раз написано, я не буду просто подчеркивать это
сейчас в скринкасте. Ну, вот, в частности, на этой страничке можно найти ответ. И вот задача в том
числе про то, чтобы такие странички поискать, найти их, прочитать и разобраться с гарантиями. И вот так
вы сможете убедить себя и меня. Вот, но есть, как бы, еще один вопрос. А как эти странички вообще
найти? То есть, как найти инструкции, которые вы должны использовать? Ну, в условии есть дежурная
подсказка и вот на предыдущем семинаре почему-то никто не заметил этой подсказки. Я тоже не знаю,
мне тоже кажется, что очевидно. Ну, короче, вот нужно узнать про инструкции, нужно пойти в какой-нибудь
мануал процессора или там найти хороший референс и там уже разобраться, с какими гарантиями у вас все
работает. То есть, вы учитесь не для того, чтобы узнать, что вот здесь нужно вставить такую инструкцию,
а чтобы понимать вообще, ну, такие вопросы, ответы находить. Это, кажется, более общий навык,
более полезный. Ну, и про инструкции тоже разобраться. Сейчас, возвращаюсь к тому вопросу,
наконец, я сбился, прости. Вот есть Compare Exchange Week и Strong. И вот оказывается, что на x86 две эти
операции компилируют один и тот же машинный код. Ты можешь это проверить. Тебе следует это сделать.
Вот. То есть, они на x86, вот на этом ноутбуке, они не отличаются ничем. Но формально они отличаются
своими гарантиями, что Compare Exchange Week может вернуть false, даже если значение атомика ничей
к памяти совпадает с аргументом expected. И более того, мы же используем Twist с вами для того, чтобы
код тестировать. Сейчас, секунду, я просто предостерегу тебя и тех, кто, возможно, это
посмотрит. Вот смотрите, что я недавно закоммитил, и в шаде это кому-то уже сломало решение. Вот наш
атомник, он может иногда сказать Compare Exchange Week просто false, потому что имеет право на это
формально. Почему так происходит? Я честный ответ дам на семинаре где-то спустя месяц-полтора, когда
мы будем говорить про лукфри, и там вот эта операция Compare Exchange станет вот, мы с помощью
лукфри еще не будем все на свете делать. Дело в том, что есть разные процессоры с разными
атомарными инструкциями под капотом, и есть стандартная библиотека языка C++, есть атомик,
и вот все операции, которые атомик предоставляет, должны быть реализуемы на каждом процессоре.
Разумное требование, да? Ну то есть некоторые общие знаменатели. Вот, разумеется, процессоры,
они разные по разным причинам, но может быть исторически по разным причинам. Вот у разработчиков
процессоров был разный подход к тому, какие инструкции нужно иметь для синхронизации, но все-таки
мир не совсем произвольно устроен, есть некоторые фундаментальные в нем законы, в том числе и
синхронизацию, поэтому скорее набор разумных инструкций не такой уж и большой. Но вот в случае,
скажем, Arma X86 этот набор отличается, и подход немного отличается к атомарности и к реализации
таких операций, поэтому вот оказалось, что на Arma реализовать Compare Exchange, ну то есть там нет вот
такой специальной инструкции прочитать, сравнить, если сравнить, то записать, вот просто такой готовой
инструкции там нет, там есть другие отдельные инструкции чтения записи с некоторой хитрой
дополнительной семантикой, и вот беда в том, что инструкции, которые есть на Arma, на X86 не выразить,
но то, что есть на Arma, из них можно построить Compare Exchange, то есть вот из инструкции Arma можно
построить вот такую инструкцию, ну примерно, наоборот нельзя, поэтому в Atomic есть такая операция,
но оказывается, что на Arma ее можно написать по-разному, и одна операция будет иметь семантику WIC,
но она будет иметь меньше аверхед, а другая реализация будет иметь семантику Strong,
но иметь больше аверхед, и вот есть разные случаи, про которые мы поговорим в теме Prologue Free,
когда тебе достаточно более слабые семантики и меньше аверхеда внутри реализации этой операции,
я не знаю, запутать тебя или нет, то есть есть процессоры, где Compare Exchange, вот как сама
логическая операция реализуется разными способами, вот есть две реализации, и одна из них может
ошибаться, но иногда этого бывает достаточно, поэтому можем себе это позволить, в смысле ошибка,
она не повлияет на корректность кода, а есть случаи, когда повлияет, ну вот, скажем, если ты пишешь
Trialog в задаче против Kitlog, то ты понимаешь, что, ну видимо, там разумно использовать сильную
гарантию, потому что если лог свободен, то он должен быть захвачен. Да, теперь у тебя был вопрос.
То есть еще раз, регистры у нас у каждого ядра свои, и даже если это ядро при этом моменте прижмут,
и вот когда оно вернется к исполнению этой функции, регистр окажется теми же самыми, которые были?
Да, разумеется, ну представь, что ты компаниятор, ты генерируешь машинный код, и вот между двумя
инструкциями все остальное может, все твоё состояние исполнения могут стереться, процессор, это было бы
очень печально. Так что этим занимается процессор, то есть он поддерживает механизм прерывания,
которым пользуется операционная система, и вот при прерывании делается снимок состояния регистров.
Когда мы там переключаемся обратно, то мы снимок устанавливаем, намазываем процессор, и поток
исполнения продолжается с того же места, где оно остановилось. То есть, разумеется, компилятор,
или вот ты, когда смотришь на последовательный код, ты можешь считать, что возможно чередование,
что потоки могут друг на друга переключаться, но при этом сам поток выполняется относительно
какого-то стабильного состояния регистров. Память там может меняться, если между двумя инструкциями
кто-то другой вклинился, память, конечно, может измениться, а регистры нет. Ну и есть частные случаи,
когда ты вызываешь функцию, разумеется, когда ты пишешь инструкцию call в ассемблере, то после
возврата из этого кола ты ожидаешь, что у тебя сохранились только часть регистров. Это про
соглашение вызовов в Сталии. А вы не можете вообще рассказать про мембрио? К сожалению, я не могу,
то есть я могу, конечно, но я не стану этого делать, потому что рассказ занимает шесть часов времени. Я
могу только прокомментировать, чего мы хотим, чего я от вас хочу сейчас. То есть смотрите,
вот этот пункт про atomic store и разные версии atomic store, о чем он вообще? О том, что вы пишете
какой-то код, вот вы пишете atomic store, и вы как-то себя убеждаете, почему он атомарен. Вот,
может быть, вы говорите, инструкция move просто атомарна. Вас это устраивает, вы пишете код,
вот он копируется, работает. Вы думаете, но похоже на правду. А с другой стороны, вы смотрите
на STD atomic, ну или вас призывают, посмотрите на STD atomic, и вот вы открываете любую операцию,
в частности, store, и вы видите, что у нее есть аргумент, что записать, и у любой
операции есть аргумент memory order. И очевидно, этот аргумент каким-то образом влияет на поведение
этого store. И условия вам говорят, что от memory order вообще много разных бывает,
но не все комбинации разумны, и вот в случае со store можно написать relax store,
можно написать release store, и можно написать sequential и consistent store. И если вы научились разбираться,
а как понять, ну то есть если вы научились смотреть assembler для ваших реализаций,
то вы можете убедиться, что, скажем, в зависимости от аргумента, от выбранного memory order,
ваша реализация, не ваша, а реализация store в STD Atomic меняется. Помните, я говорил, как вот
найти вот эту инструкцию Comparachy, как вообще про нее узнать. Вот если вы знаете, как про нее
узнать, то вы можете также узнать, что atomic store реализован по-разному, в зависимости от memory
order, точнее, может быть реализован по-разному. Вот, ну и это первое наблюдение, которое вы должны
сделать, что вот есть на самом деле много разных stores, то есть много разных способов записать
значения в ячеек памяти разделяемую, ну и такой первый технический вопрос разобраться, а какую
именно версию вы написали? Вот какой store у вас? Ну просто будет странно, если ваш store не совпадет
не с одним, это будет подозрительно все же. Вот видимо совпадет. А дальше вопрос, ну там как бы есть
много, не то что много, там есть еще интересные вопросы, но это скорее они для защиты предназначены.
А вот второй вопрос сложный. Вот вы, допустим, узнали, что store есть разные, что они реализованы
могут быть по-разному, что вы написали вот какой-то из них. А дальше вопрос, какой вам нужно было
написать? Вот такой правильный. Ну под правильностью здесь можно разное понимать, ну во-первых,
корректность разумеется, мы не должны нарушать, во-вторых, может быть есть разные корректные
способы, а среди них есть вот более оптимальные, менее оптимальные. Вот ничего не объясняя, можно
так сказать, что memory order, он нужен для того, чтобы оптимизировать. То есть это некоторая оптимизация.
По умолчанию выбирается, видимо, самый надежный способ. Вот sequential и consistent atomic. Вот если вы не
пишете дополнительных аргументов в операции атомика, то выбирается такой memory order и,
видимо, он позволяет вам меньше всего думать про memory order. В примерах каких?
Капер экченч. Если операция, если со мне неудачная, надо перезаписать, то мы используем
релиз, а если неудачная и нам все равно, то релакс. Ну смотри, я бы предостерег тебя от таких, прямо скажем,
очень поверхностных рассуждений. Они не имеют никакого понимания, никакого отношения к пониманию
модели памяти. Не то чтобы это критика тебя, потому что ты не можешь сейчас его иметь, потому что
sweeper-reference — это, прямо скажем, последнее место, по которому стоит учиться моделям памяти.
Я начну и попробую объяснить про memory order немного, не забегая сильно вперед. Вот смотри,
тебе нужно описать, что такое стандарт C++ или стандарт языка C. Вот какую задачу он решает?
Стандарт фиксирует для вас семантику языка. Вот что значит программа на языке C,
которая написана там int main, принтеф, потом return 0. Короче, вот семантика программы — как она
себя ведет, грубо говоря, как можно об этом думать, о ее исполнении. И вот стандарт, скажем, C, он как
решает этот вопрос, как он описывает семантику, он вам описывает некоторую абстрактную машину и
как она исполняет вашу программу. Или, скажем, стандарт C++, я не помню, там же, наверное, нет понятия
кучи и стек, но там есть automatic storage и еще какое-то название. Короче говоря, вам описывают машину,
как она исполняет вашу программу. Скажем, там вот может быть описано, что если вы берете int 32
и со значением 2 в 31 и минус 1 и добавляете к нему единицу, то что после этого последует?
То есть вам говорят, что будущее состояние неизвестно. Или говорят, что будет, если у вас на самом
деле переменная без знаков, и она переполнится. То есть описывают поведение двоустройства. И дальше
компилятор обязуется при компиляции, компилятор для конкретной архитектуры обязуется обеспечить
вашей программе вот такую вот семантику, потому что реальный компьютер может отличаться. В модели
памяти это тоже ответ, как ведет себя программа. Это тоже описание семантики языка, но только
программа многопоточной. То есть как ведет себя программа, в которой есть несколько потоков,
которые общаются с общими человеками памяти. И ответ тут, ну и не то чтобы ответ пока, а реальность
тут сложная. Вот мы на лекциях смотрели, вот такой пример. У нас были два потока и две ячейки
памяти, разделяемые х и у. Ну и были еще две локальные, но вот с ними работает только один поток,
поэтому ячейки, регистры, тут уже разницы нет. Поэтому они называются R1 и R2, это скорее регистры.
И что делали потоки? Первый поток писал в X, читал из Y. Второй поток делал симметричный,
писал в Y, читал из X. Ну вот очень простая программа на C++, в которой есть потоки,
и эти потоки работают с несколькими ячейками памяти разделяемыми. Вот мы задаемся вопросом,
какова симантика этой программы? Вот наивный и неправильный ответ – это модель чередования,
когда мы переключаемся после любой инструкции на другой поток, но как будто мы исполняемся на
одном ядре. А дальше мы запускаем этот код и видим, что реальность в эту модель не вписывается.
То есть в этой программе можно увидеть и в R1 0 и в R2 0. Никаким чередованием такой ответ,
такой исход не объясняется. Ну это же недetermинированные эффекты, это может,
там не знаю, полминуты работать и не ломаться. Ну вот, смотри. Тут прошло много итераций. Тут
процессор R1, а он сейчас у меня там IDE, код индексирует, там запись, видео пишет, скринкасс пишет.
Много вещей влияет. Так вот, видите, что реальность сложная и нужно как-то описать,
какие вообще исходы возможны. Вот модель памяти, если забегать сильно вперед,
это способ описать семантику произвольных подобных программ. Как они могут себя вести,
какие исходы в них возможны. И беда в том, что эта семантика, есть семантика операционная,
есть семантика декларативная. Вот операционная семантика, это когда вам рассказывают, что вот
есть там условно такая абстрактная машина, она вот так-то исполняет код. А есть семантика
операционная, когда вам описывают, декларативная, когда скорее вам описывают наблюдаемые поведения
всевозможные и не описывают, как они реализуются. То есть это посторонний вопрос. Почему так
получилось? Вот модель памяти не пытается вам объяснить, почему так получилось. Почему здесь
получилось два нуря? Она объясняет вам, какие исходы здесь вообще в принципе были допустимы. То
есть на какие гарантии можно полагаться. И это сложно по двум причинам. Потому что сама по себе
эта семантика сложная. А еще сложно, потому что она декларативная, а весь основной язык, а во всем
остальном языке у вас семантика операционная. И вот это как бы плохо друг другу подходит. Ну и беда еще
в том, что вот все эти референсы, именно такие программистские, инженерные, они не справляются
с разумным. Операционная декларативная семантика это вообще, говорят там,
некоторая формальная система. Это математика, короче говоря. Вот читать на программистском сайте
про какую-то математику не стоит. Там плохо описано. Ну смотри,
чтобы понять, изучать формализм редко, когда полезно. Формализм не объясняет,
ну формализм, он формализм. Он просто тебе говорит вот так вот. Но с другой стороны,
почему он такой? Вот тут вопрос не про формальное понимание гарантии, а про интуитивное понимание.
Почему формализм именно такой? Потому что это же человеческий произвол. Вот модель памяти,
это не то чтобы с неба спустилась, это же творение рук человека. Почему оно такое? Почему правила такие?
Вот понимание модели памяти, оно не про то, какие правила есть, а про интуитивное понимание,
почему они такие. Вот модель памяти это очень неинтуитивная штука для тех, кто ее изучает в
первый раз. Но если ты ее поймешь по-настоящему, как она работает, почему все так, то все становится
очень интуитивно. И вот тебе, наоборот, не хочется думать про процессоры, про то, что в них что-то
там переставляется местами. То есть можно было бы ожидать, что, например, процессор вот эту инструкцию
выполнил до этой, переставил их местами. И тогда бы это все объяснило. И в каком-то смысле так и есть.
Но это сделает конкретный процессор, а другой процессор, там какой-нибудь ARM, Macbook, он сделает
по-другому. И вот думать нужно не про то, что именно он сделал, а про то, на какие гарантии мы можем
полагаться. Вот модель памяти про это и вот настоящее понимание модели памяти, оно про то, откуда эти
правила берутся, почему они именно такие. Потому что вот в моделях памяти очень много терминов. Там
десятки каких-то понятий, они как-то вот связаны между собой, там какие-то исключения есть. Очень
много комбинаций мем реордеров, которые можно использовать. Вот если просто читать референс,
то запутаешься просто-напросто. Нужно подходить по-другому. Вот мы на реакции попытаемся пойти по-другому,
я объясню, откуда этот формализм берется, как его интуитивно понимать. Ну и вообще тема,
которая до сих пор люди исследуют, хорошего решения нет. Вот модель памяти C++, в ней есть некоторые
противоречия, ну точнее некоторые, в общем дыры в ней есть и есть что-то, что лучше бы вообще в ней
не было. Ну не знаю, как это объяснить. Короче, очень сложно, не нужно сейчас это понимать, невозможно
это сейчас понять. Можно пробовать. В задании про... нет, ты не понимаешь мой замысел. В задании
смотри, что просят. В задании просят, во-первых... сейчас мы вернемся. Во-первых, вас спрашивают,
вот посмотрите, вот на Atomic Store, и убедитесь, что там есть аргумент memory-order, и вот есть три
варианта. Первый шаг, второй шаг. Ну нет, их меньше, потому что не все они разумны просто. Вот некоторые
не стоит писать, потому что ты не знаешь, что будет. Это будет... я бы сказал, что TOB будет, если ты напишешь
Store с memory-orderm Acquire. Это бессмысленно. Вот в условии написано, какие варианты осмысленные,
какие значения осмысленные. Вот, и ты дальше исследуешь, что вот для каждого из них может быть
своя реализация, а может быть какие-то... а может быть даже странно очень, что memory-order бывают
разные реализации одна. Вот, ну это как бы ты все еще способен это постичь, потому что ты можешь
посмотреть просто на то, в какой Assembler компилируются вызовы Store для разных memory-orders. Как это
сделать, написано в условиях, в общем-то. Вот дальше вопрос. Store для какого memory-order вы
реализовали? Ну опять, просто сравниваешь свой код, сравниваешь там разные реализации, которые
ты видишь, говоришь, вот такой вот я реализовал. Вот, это пока никакого понимания не добавляет. Это
скорее просто добавляет тебе понимание, что мир сложен. Вот, дальше ты спрашиваешь, какая версия
нужна спинлоку? И тут ты пытаешься ответить. А как это просто ответить, не разбираясь? Невозможно.
Невозможно. Ну, то есть, чтобы ответить на этот вопрос, нужно хорошо понимать модель памяти.
Если вдруг ты хорошо понимаешь модель памяти, ты сможешь на него ответить. Если нет, то ты просто
этот вопрос в голове себе подвесишь, и рано или поздно мы его разберем. Ну, просто смотри, я же
не могу прийти на лекцию и сказать, а вот сегодня на смотри памяти. И ты такой, ну хорошо, изучим и это
сейчас. Должна быть какая-то мотивация к этой теме. Ну вот, я так очень издалека к этому подхожу.
Вот, видимо, какая-то мотивация есть. Видимо, ну, почему ты, то есть, ты видишь, что в Atomic есть разные
версии Store. Ты не понимаешь, какую версию нужна спинлоку. Какая из них корректная, какая из них
оптимальная. И вот у тебя вопрос, почему в Atomic Store три версии, и какую из них подобрать спинлоку.
И вот, в частности, этот вопрос мы отвечаем на лекции про модель памяти. То есть, у тебя уже есть какой-то
открытый вопрос. Сейчас ты вряд ли сможешь ответить на него сам. Ты можешь попробовать читать документацию,
но смотри, я очень предостерегаю всех, кто, не знаю, послушает эту запись, и тех, кто присутствует здесь,
пока memory-ордеры какие-то писать. Вот ты мне говоришь, я подсчитал, там есть какие-то примеры,
вот релиз, релакс, что-нибудь еще. Вот это такое абсолютно, ну, за этим никакого понимания не стоит.
Такие-то общие рецепты. Нужно писать вот так вот. Там написано так. Пока, вот, смотри, универсальное
правило, которое точно верно. Если ты не уверен, что ты хорошо понимаешь memory-ордеры, и модели памяти,
в принципе, то не нужно писать memory-ордеры, потому что правильно ты их не сможешь представлять.
Если ты не будешь писать ничего, то есть, будет представляться дефолтный, то дефолтный дает самые
сильные гарантии. То есть, он наиболее безопасен. То есть, если проблема будет, то она будет не с
memory-ордерами. Так что пока я призываю просто писать, там, сторы, лоды, лишних аргументов не
добавлять. После лекции про модели памяти можно будет, когда это уже будет осознанно. Просто там
копировать какие-то рецепты из документации, это, вот, боюсь, что не сработает. Там нужно
некоторые общие правила в голове иметь, которые в документации не описаны, к сожалению. Ну, они мало
где описаны. Вот мы их обсудим на семинарах позже. Вот это, то есть, сложная тема, и в задачу
предлагается в нее немножко закопаться, просто поисследовать, как тут устроен мир. Хорошо,
давайте про FUTX поговорим теперь. Мы на лекции почти ничего не успели, просто сказали, что он есть.
Вот. Для чего он есть? Для чего нам предлагается его использовать в домашних работах? Для
блокирующего ожидания. Мы в домашних работах пишем свой Mutex, который блокирует потоки,
которые ждут блокировки. Она захвачена другим потоком. Мы пишем сейчас уже кондвар, с помощью
которого можно дожидаться выполнения некоторого состояния, некоторого предиката на некотором
состоянии, блокирующей очереди. Вот. И задача подождать чего-то — это задача, которая не
решается на уровне процессора, на уровне ваших инструкций. Потому что, если вы на ядре,
то вы исполняете инструкции, а вы в Mutex Log хотите не исполнять инструкции, из процессора уйти.
Единственный способ для этого — обратиться к ядру и сказать, чтобы она вас с процессора сняла.
То есть, сделать сискол в планировщиках. У вас есть этот сискол, он называется Futex. Если вы на него
посмотрите, то окажется, что он чертовски сложен. То есть, это сискол один, но у него есть аргумент
Futex Op, то есть, операция, которую мы выполняем с ним Futex, и тут много вариантов. Wait, wake,
и мы про другие даже ничего не говорим. И есть еще какое-то количество разных других. Вот. Мы в это
не погружаемся, нам и двух хватит, уже довольно сложно. Значит, в чем идея? Это очередь для ожидания.
Ну вот, мы так интуитивно представляем себе планировщик. В нем есть какая-то очередь потоков,
которые готовы исполняться, но еще не исполняются. И мы, видимо, на ближайшие лекции это обсудим,
когда будем рассматривать Fiber, как они устроены. Там будет планировщик с очередью. Но вот Futex — это
тоже очередь, только не на исполнение, а на ожидание. То есть, это очередь, которая находится снаружи от
планировщика, и мы в нее встаем, когда не хотим исполняться. Мы говорим atomic wait, или прямо
говорим syscall Futex с режимом Futex wait, и встаем в эту очередь. Когда другой поток говорит Futex wake,
Futex с Futex wake, то он нас в этой очереди будет, и мы возвращаемся в планировщик. То есть, мы
перемещаемся из одной очереди в другую очередь. Но есть тонкость, потому что, как мы, кажется,
из условия и вообще из описания atomic wait в STD видим, семантика вызова wait — не просто запарковать
поток в очереди. Она немного сложнее. Она про то, чтобы сравнить значение atomic с аргументом,
и только если оно совпадает, то тогда уснуть. И вообще, сам Futex, ну просто by design, он связывает
очередь ожидания с некоторым адресом в вашей памяти, то есть, с некоторой ячеек памяти.
То есть, семантика Futex — это не просто добавить поток в очередь, а прыгнуть в syscall, там прочесть
содержимое вот этой ячейки памяти, сравнить его с передным аргументом, и если совпало значение,
то тогда запарковать поток в очереди. Если не совпало, то просто разбудить сразу, выйти из wait
обратно. Ну вот, такая довольно нетривиальная семантика, и хотелось бы понять, почему все
именно так. Вот, есть ли у вас понимание, почему, казалось бы, проверка, сравнение содержимого ячейки
с значением? То есть, если совпало, то заснуть. Вот почему, если совпало, то нужно делать user
space в ядре? Зачем это прямо в syscall тащить? Почему в нашем коде не прочитать, не сравнить,
и только после этого просто запарковать поток в очереди? Что значит можно? Тут вопрос уже не про
можно, тут вопрос как бы, что будет работать не так? Ты решал задачу Mutex? Это усложняет
меня этот вопрос, потому что задача Mutex про это. А кто решал задачу Mutex? И вы знаете ответ?
Нет. Что значит нет? Я не понимаю, зачем вы вообще что-либо проверяете. Ты хочешь запарковать поток?
Там же в задаче говорят, что для тех, кто не хочет ничего сравнивать, там же есть вот такой
странный вспомогательный класс, у которого есть просто методы park и wait. Я реализовал почти такие
методы, как там сам. Но с ними невозможно в сеть Mutex? Ну не знаю. Он не будет работать,
он будет зависеть. Я еще один вопрос. Атомик, возможно, немного кастритный, но по-моему,
который дает нормально в городе. Нет, то, что ты мог написать кастрит, я не сомневаюсь,
это можно было бы сделать. Но вот таких методов точно недостаточно. Вот вот таких просто запарковать
и разбудить. И объяснить это очень легко. Что такое Mutex? Это, в конце концов, ячейка памяти,
которая написана в простейшем случае. Либо 0, либо 1. 0 свободен, 1 захвачен. И вот вы приходите и
пытаетесь его захватить. Делаете, видимо, экченж. Пишете единицу, читаете то, что в нем было. Читаете,
допустим, 0. Ну отлично. Вызов лог завершился, вы захватили его. Ладно, второй случай,
прочитали единицу. Это значит, лог уже захвачен, и вы должны ждать. И тут, казалось бы, нужно просто
взять и заснуть. Ну а теперь ситуация. Два потока. Один вызывает лог. Делает экченж, видит,
что в ячейке единица. То есть Mutex захвачен. И у него следующая строчка заснуть. И вот между
этими двумя строчками выполняется онлог до второго потока. Второй поток, что он делает? Сбрасывает
ячейку в ноль и говорит на tify. И никого не будет, потому что в очереди пока никто не спит. И все.
И Mutex свободен, а поток засыпает. И он блокируется вот навсегда. Проблема понятна, да? Казалось бы,
почему проверка в ядре этому должна помочь? Почему вообще важно нам в ядре или в userspace? В конце
концов, когда мы сделали экченж, мы уже сделали сравнение. Мы уже прочитали значение и сравнили его
с нулем. Не совпало. Зачем нам прыгать в ядро и еще раз перечитывать ячейку и проверять ее?
Ответа на этот вопрос нет, пока мы не знаем реализацию Fuedex. Такая штука, про которую нужно
знать, как она устроена. Потому что иначе она полностью понятна не будет. Смотрите, Fuedex это очередь
в ядре, которую мы адресуем с помощью ячейки памяти, с помощью поэнтера. Конечно же, ядро не то,
чтобы отдельную очередь заводит для каждой ячейки памяти, с которой вы работаете. Устроена эта
техническая подробность. Можно в принципе об этом не думать, но раз уж картинка есть, покажу. Вот вы
приходите в ядро с адресом A, допустим, и ядро хэширует его, и вы падаете в бакет. И в этом бакете
сложены все ждущие потоки для всех адресов, которые хэшом отображаются сюда. Когда вы засыпаете на
адресе A, вы падаете в эту очередь. Когда другой поток будет вас по адресу A, делает Fuedex wake по
адресу A, то он адрес снова хэширует, падает в бакет, идет по этому бакету и будет только те потоки,
которые привязаны к адресу A. Если вы сделали Fuedex wake и будет один поток, то разбудится один. Если
O, то все зеленые. Нет никакого спонтанного пробуждения, почему? Там же написано, это A или B. Вот
ядро посмотрит, что вот A и раз будет в A, B не будет. Вот видишь, на картинке написано, что A. Вот мы это
используем. Тут ничего криминального нет. Просто такая вот очередь. Это очередь, в которой работают
разные сисколы. На одном ядре выполняется Fuedex wake. Мы просто списки храним в общем, много списков храним в одном.
Причем тут хэширование? Мы не хэш таблицу строим, мы списки храним. Ну это не хэш таблица,
она не хранит. Ладно, это довольно правильный вопрос. Зачем мы используем хэширование? Нам
в списке именно нужно обходить списки. Вопрос посторонний обсуждается. Это способ, каким ядро хранит
все эти очереди. Можно считать, что для каждой человек своей очередь, свой список не важно. Но важно,
что у вас есть два ядра, скажем, в процессоре. И на одном ядре выполняется сискол Fuedex wake,
на другом исполнится сискол Fuedex wake. И они работают с одним списком. И, разумеется, уже на уровне ядра
нужно делать взаимные исключения. Поэтому этот список, вот этот бакет, он защищается спинлоком в ядре.
И в условии задачи вам предлагают, пожалуйста, сходите по очень хорошей ссылке, где все написано,
как все работает. Это ядро Linux, это то место, через которое нужно изучать ядро Linux. Это
такая наименьшая косменность возможная. И смотрите, что здесь написано. Когда мы делаем сискол
Fuedex wake, вот с такой ячейкой памяти, с таким значением, то мы читаем, вот такая вот наивная
реализация. Мы читаем ячейку памяти, сравниваем, потом берем бакет, лочим бакет и вставляем в очередь.
Вот такого, конечно же, делать нельзя. Почему? Потому что, ну смотрите, вот еще раз повторю пример.
Вы прочли ячейку памяти, а потом ее сравнили со значением. Оно совпало. Но между вот этими
двумя операциями вклинился другой поток, который ячейку памяти изменил и сделал wake.
И в итоге этот поток все равно заснул. То есть он прочел старое значение, оно тут же изменилось,
но первое ядро этого не увидело и заснуло. Это вот ровно сценарий зависания в Fuedex. Поэтому
настоящий Fuedex устроен по-другому. Он сначала лочит бакет и только после этого читает содержимые
ячейки. И именно поэтому все в ядре происходит. Именно поэтому чтение в ядре повторяется. Как это
помогает? Вообще говоря, после этого чтения на другом ядре может быть выполнена запись в ячейку
памяти. То есть вы пытались взять Mutex, сделали Exchange, увидели единицу, пошли во Fuedex спать. Во Fuedex
еще раз перечисли ячейку, увидели там снова единицу. Но вроде бы нужно засыпать. И тут на другом ядре
сразу после этого в операции Unlock другой поток ячейку сбрасывает в ноль. То есть все, ваша проверка
дважды устарела. Но это не... В сущности, нет, ячейка не залочена. Почему залочена? Вот ячейка,
она просто ячейка. Вот вы ее здесь прочли на одном ядре, а на другом ядре ты записал в эту ячейку.
Никто никому не мешает. Вот, смотрите, мы можем, как и раньше, прочесть старое значение, его тут же
перепишут. Но раньше Fuedex Wake мог уклиниться между вот этой чтением и проверкой. А сейчас Fuedex Wake
он берет лог на bucket. А у нас лог уже взят. И поэтому он не может вот сюда вставиться. Вот этот
код, он не может выполниться... Вот этот wake не может выполниться вот здесь вот. То есть, смотри,
weight относительно store не атомарин, разумеется. То есть store может вклиниться в середину weight,
а вот здесь вот. Вот store, а вот weight исполняется в ядре. Но natify в weight вклиниться не может,
потому что natify и weight работают с общим спинлоком в ядре. И именно поэтому чтение внутри
сискола, потому что чтение внутри спинлока в ядре. Ну тут такой тонкий момент, но если его понять,
то гарантия станет ясной. То есть нужно понять в первую очередь, от какого сценария мы стараемся
избавиться. Вот от такого сценария, где поток анлочного видоса и другой поток не увидит,
а твой засыпает навечно. Это вообще псевдокод. DataRace в смысле, потому что у тебя есть просто
ячейка памяти, и ты в нее пишешь и читаешь. Смотри, ядро линукса это не язык C++ уж точно,
и там своя модель памяти. То есть там свои правила, что считать DataRace, что не считать,
какие там гарантии. В C++ вы даны одни правила. Ну еще раз, это правила. Понимаете, правила,
они говорят, это УБ, но компьютер от этого не взрывается. В этой программе УБ. То есть просто
напросто вам не говорят ни про какие гарантии здесь. Но при этом программа, она вполне себе
компилируется в какой-то понятный код и потом исполняется процессором. И там никаких ошибок,
конечно, не возникает, никаких проблем нет. Просто модель памяти отказывается вам давать
гарантии относительно поведения этой программы. Может быть у ядра линукса более сложные гарантии,
более сложные модели памяти. А давайте мы ее найдем. Это очень любопытный пример.
Я хочу прямо... Сейчас, если быстро получится найти. Вот описание модели памяти линукса,
то есть как ядро работает с ячейками памяти. Ну и... Такое-то очень короткое описание. Это не то.
Сейчас это... Explanation, вот. Explanation, по-моему, оно. Смотрите на размер ползунка. Вот. Это как бы
главы. 25 таких параграфов. Вот. Довольно сложно. То есть как ядро работает с памятью и какие там
возможны сценарии. Их много, они сложные, и там гарантии сложные. Это вот декларативная модель
памяти для ядра линукса. Она своя. То есть формально в C++... Можно я закончу ответ на вопрос?
Формально в C++ это был бы датарейс. Если это просто ячейка памяти, не атомика, и ты пишешь,
читаешь без синхронизации. Линукса просто свои правила. И правила не влияют на реальность. Поэтому
противоречия нет никакого. Вот C++ это датарейс. Да, слушаю тебя. Во-первых, видимо, да. Во-вторых,
нет, не легче. Дело-то не в том... Проблемы с моделью памяти в любом языке, они примерно одинаковые.
Тут выбор на стороне разработчиков языка, насколько большую свободу ты дашь разработчику. Вот в
Java, скажем, нет вот этих всех memory-ордеров. Там модель памяти сложная по-своему. Получился
семинар про модель памяти. Не то, что я хотел. В Java модель памяти немного принципиально такая же,
в некоторых местах отличается, но в ней memory-ордеров нет. Там буквально вот можно считать, что там есть
вот memory-order sequential consistency. А вот этих всех вариаций нет. В C++ это все есть, потому что C++
дает тебе очень большую гибкость, и ты можешь вот очень тонко настраивать перформанс. То есть,
ты можешь очень глубоко оптимизировать код. В некоторых языках все проще, потому что тебе не
дают таких тонких настроек. С другой стороны, сама семантика получается проще. Я забыл вопрос,
если честно. Скажем, я просто не знаю про нее, не буду спекулировать. В языке раз,
смотрите, что сделали. Ну, я на лекции потом покажу. Там вообще не определились еще. Там как бы ждут,
пока научное сообщество все-таки построит нормальную модель памяти без дыр. Что? Ну,
не говорят. Ну, как C++. Да. Сейчас, значит, модель памяти — это не вопрос, это не run time,
это вопрос семантики. Не через run time же это определяется. В смысле, ты про то,
что в run time реализована абстракция транзакционной памяти. Но ты слишком далеко от реальности в мире
хаскере, потому что модель памяти C++ пытается математически описать зоопарк процессоров,
что довольно сложно сделать. То есть нельзя очень аккуратно математически описать
вот некоторый человеческий произвол инженерный. Не всегда это возможно. Либо ты говоришь просто,
что я не думаю про процессоры, я строю свою абстракцию с транзакционной памятью и описываю ее.
Зачем стд-атомик в weight проверяет еще раз ее после? У меня есть гипотеза,
что, смотри, фьютекс, курс, у него есть некоторая смещенность в сторону, во-первых,
x86, во-вторых, линукса. Фьютекс — это сискол для линукса, в других операционных системах его нет.
И скажем, для некоторых реализаций, давай я прям покажу в условии, там же есть в условии задачи,
есть ссылка на реализацию этого самого weight. Не то, чтобы я предлагал это читать,
потому что код стд не для людей написан. В некоторых случаях weight эмулируется через
кундвары. У вас в операционной системе нет никакого готового примитива для этого,
поэтому вы описываете weight через кундвары. И там получается вот такая семантика более слабая,
не то что более слабая, немного другая. И опять, кажется, что просто это общий знаменатель.
Я не знаю, мне кажется, что это неважно. Перепроверил это еще раз, не перепроверил,
это, кажется, какая-то минорная деталь. Ну, значит, я бы предлагал твой код ударить
и переписать как-то иначе его. Мне кажется, что нормальная реализация, она от этой подробности
не зависит. Просто это дополнительная проверка, она почти не должна влиять. Ну, не знаю, ладно,
нужно код смотреть. То есть, это моя гипотеза, почему так? Потому что сискол фьюдекс — это
вот сискол на одной операционной системе, на других могут быть другие способы это weight выразить,
и, возможно, что это такая минимальная семантика, которую удается везде написать, везде реализовать.
Так, ну, с фьюдексом, наверное, хватит. Тут еще есть забавная подробность про модели памяти,
я не знаю, усугубляет ли этот разговор про модели памяти еще больше. Но, короче говоря,
если вы почитаете эту документацию, вот этот комментарий, то вот окажется, что в ядре линукса
возникает ровно вот такой сценарий, который мы рассматривали на прошлой или позапрошей
лекции в этом примере. Вот буквально в коде фьюдекса, при конкуренции вейка и вейта,
возникает вот такой вот паттерд. И вот мы видим, что процессор в нем генерирует довольно неожиданный
исход. И если бы так было, то вот ядро во фьюдексе ломалось, там происходило бы зависание, поток
зависает, простите, поток засыпает и не видит на тифая, точнее поток засыпает, а другой поток не
может его разбудить, потому что там две ячейки памяти вот так вот с два потока, два ядра с двумя
ячейками памяти так поработали вместе. Короче, вот этот сценарий выглядит довольно синтетически,
но вот в ядре, в реализации фьюдекса он прямо возникает и может, если ядро об этом не позаботится,
то он приведет к зависанию. Да, это можно почитать, это может быть поможет пониманию модели памяти в
будущем, но в любом случае я это все буду потом пересказывать. Так что сейчас скорее понимания не
требуется, требуется понимание вопроса, а понимание ответа не является необходимым.
Что еще в домашке может быть сейчас непонятно? Что еще я могу пояснить?
Про гарантии Comperexchange мы сказали, про Atomic сказали, про Mutex, в Mutex поговорили,
LifeLog, LifeLog там вроде все понятно должно быть, DeadLog там тоже все понятно должно быть,
про философов непонятно. Вот возможно, что? Философы все просто, а это легко узнать просто
или непросто. Есть очень простой тест. Давай сейчас попробуем, попробуем кое-что сделать.
Вот сразу узнаем, все тебе понятно. Ну тут присутствующие уже некоторые знают.
Вот берем философа и...
Тут ничего не написано вообще. Это шаблон, да? Тут ничего не было. У него есть правая елка и левая елка.
Просто где мой CodeCompletion? Спрашиваю я в ВДЕ и не получаю ответа.
Я пишу DeadLog, да? Мы понимаем это. То есть все философы взяли в руку левую
вилку и все. На этом обед закончился. И дальше я хочу запустить этот код, CodeThreadSanitizer.
Ага. Вот критерии понимания задачи. Вы можете так сделать? Ну понятно, что возник DeadLog.
ThreadSanitizer это, видимо, нашел. Но он написал следующее. Он написал LogOrderInversion,
на скобочках, потенциальный DeadLog. И вот что он имел в виду этим сообщением? Он же не написал,
что у вас DeadLog. Судя по этому сообщению, он не понимает, DeadLog у вас или нет. Вот что все это значит?
Ну давайте разберем. Наверное, осталось 10 минут, да? Кажется, это подходящий момент, чтобы это сделать
в тот день, когда никого нет. Ну, запись будет. Ну, сообщение Релинсуторвальца, оно зачем в условии
задачи дано? Во-первых, оно про анлоки. А мы говорим сейчас про локи, а не про анлоки. А во-вторых,
оно про то, что нужно быть вежливее и добрее. Вот это второй посыл этой ссылки. Вот по поводу того,
что анлоки... Проблема-то не в анлоках здесь. Вот, наоборот, письман говорит, что чтобы мы в
релиз Forks не написали, вот все что угодно сойдет. Не то чтобы это прям хорошая идея что угодно
написать. Но это не влияет на DeadLog. Вот Ред Санитайзер говорит, что он даже не... Давайте по-другому.
Почему у нас философы заблокировались и умерли с голоду? Потому что все взяли левую вилку,
так сложилось исполнение, и они зависли. В условии задачи говорят, что вот... Ну, вы понимаете,
что это DeadLog. Но вот есть какой-то более формальный способ об этом говорить. Он называется
WaitForGraph. Вы строите граф, где есть вершины Mutex и вершины потоки. И вот как в нем появляются
направленные дуги. Если поток T вызывает лог и ждет Mutex, то возникает дуга из T в M. Поток T
ждет Mutex M. Когда лог завершается, то есть поток T захватывает Mutex, то мы проводим дугу... То есть мы
ту стираем, проводим обратную сторону другую. Что Mutex M теперь принадлежит потоку T. Когда
мы вызываем Unlog, то просто стирается дуга между M и T. Вот в терминах этого графа DeadLog это что?
Это цикл. Поток ждет Mutex, который владеет другой поток, который ждет Mutex, и вот возвращаемся в
восходное место. А дальше вас просят в терминах этого графа придумайте... Ну, в общем, задачи.
Про что задача? Про то, чтобы придумать некоторый общий рецепт, как брать вилки так, чтобы DeadLog
не возникало. Но DeadLog... Что я несу? Какие вилки? Как брать в потоках Mutex, чтобы DeadLog не возникало?
Вилки и философы — это просто частный пример, когда у нас есть вот N потоков, N Mutex, и вот они
так распределены. У каждого потока по два Mutex нужно взять. В общем случае у нас приложение
произвольное, там какие-то... Ну, в произвольном приложении, может быть, скорее всего, много потоков,
неизвестное количество, но и, видимо, какое-то фиксированное количество Mutex. Ну, потому что Mutex
спонтанно не заводится все же чаще всего. У Mutex они защищают какие-то данные, но вот этих данных,
вы знаете про эти данные, вы объявили Mutex. И вот как использовать этот WaitForGraph придумать
некоторое общее решение и доказать, что оно корректное? Но вы не можете придумывать, может быть,
общего решения сразу, поэтому вы придумываете частное решение. Как оно выглядит?
Нет, нет, мы говорим про философов сейчас.
Ну вот, ты придумал какое-то частное решение, которое вот помогает философам за круглым столом.
Вот, а хочется, чтобы из этого частного решения родилось какое-то общее решение. Вот некоторое
общее решение, которое ты применил к этой задаче и получил свое частное. Вот. Ну, решение такое, вот
сказать, что у нас есть... Ну, у философов есть номера, да, но не у философа, ну, места за столом
пронумерованы. И, скажем, можно написать какой-то такой код, что нулевой философ берет вилки в одном
порядке, а все остальные в другом порядке. То есть все сначала левую, потом правую, а один сначала
правую, потом левую. И это вот помогает, потому что разрывает вот этот цикл гигантский. Но это
вот какое-то частное решение, а хочется, чтобы оно стало общим, прям вот глобально общим для любой
подобной задачи. Вот. И это общее решение. Как выглядит? То есть у нас, в общем случае, нет
никаких мест, нет никаких вилок, там круглого стола левый и правый, это все. Но вот общая идея
такая. Мы можем взять и Mutex изонумеровать. Просто вот статически заранее это выглядит. Мы знаем,
что у нас в программе там, не знаю, 10 Mutex, мы их пронумеровали произвольным образом. А дальше,
ну, чутику. Буду говорить аккуратнее. Мы их пронумеровали каким-то разумным образом и
придерживаемся следующего правила простого, что мы берем Mutex в каждом потоке только строком
монотонно. Почему? Тут разные вопросы. Почему это помогает, в общем случае, то есть почему это
избавляет от цикловой этфрографии? И как связано наше решение с философом, который вот один берет
вилки наоборот, с этим общим рецептом? Вот второй вопрос. Как мы на него ответим?
Ну вот, как ты нумируешь вилки в итоге? Как ты нумируешь Mutex?
Нет, еще раз. Общий рецепт пронумеровать Mutex, а потом брать сначала меньше, потом больше.
Нумерация Mutex глобальная для всех философов разума, сквозная. Она глобальная для всех, еще раз.
Ладно, наверное, мы понимаем все, но не можем потом сказать друг другу. Я по-другому скажу проще.
Возьмем и пронумеруем вилки за столом по часовой обстрелке, ну или против часовой, неважно. Тогда
почти для всех монотонность сначала левая, потом правая, а для одного, который сидит там, где
нумерация wrap around делает, сказать по-русски, для него получается наоборот, что справа от него меньше
номера, справа с левой больше будет. То есть получается, что когда все делают одинаково, а один
наоборот, то это на самом деле глобальная монотонность для всех, для каждого из них в предположении
о нумерации по или против часовой обстрелке, не знаю, как там лево-право сложится. То есть вот это
частное решение философов, это проекция такого вот общего рецепта. И теперь, кстати, можно объяснить,
почему вот на такое решение трансценитайзер пишет вот такое вот сообщение. Он вам вот тем самым
говорит, что он видит, что, похоже, вы не соблюдаете монотонность налогов. То есть он не понимает,
что у вас дедлог, но он чувствует, в смысле наблюдает, что вы нарушаете общий рецепт. То есть
с одной стороны у вас как бы все одинаково. Сначала левая, потом правая. Но это как бы для вас,
которые думают про круглый стол, про философов, которые за ним сидят. А у трансценитайзера просто
есть пачка мьютокса в программе, и он видит, что какие-то потоки захватывают их в одном порядке,
какие-то в другом порядке. И у него общий порядок не выстраивается никакой, просто там цикл в графе
появляется некоторый. Не цикл wait for графе, а вот он просто собирает такие вот пары,
что вы лочили мьютокс B, когда лотили мьютоксом A. Что? Нет, я не понял просто вопрос.
Что значит выбор мьютокса? Выбор мьютокса кем? Можешь просто переформулировать вопрос по-другому?
Не, я не знаю, то или не то, я не могу понять, что именно ты, Миша.
Кто такие мы? Ну, философ берет левый и правый. Сначала левый, потом правый. В каком порядке они
будут выполнять свои локи, это конечно от планировщика зависит. Просто сложилось такое
исполнение, где Трэд Санитайзер увидел, что вы берете разные локи. Короче, он видит,
что явно вы не соблюдаете какой-то глобальный порядок, какую-то глобальную монотонность,
и поэтому он жалуется, и поэтому он пишет потенциальный дедлог. Он даже не понял,
что дедлог произошел, но вот он видит, что вы рецепт нарушаете. Это и есть почти что
понимание задачи. Последнее, что нужно сделать, нужно просто доказать строго,
что монотонности в логах достаточно. Очень просто делается. Итак, предположение. Мы берем локи
монотонно в каждом потоке, и при этом возникает дедлог. От противного доказываем. Что такое дедлог
WaitForGraphy? У нас есть поток Т1, который ждет нюдекса М1. Нюдекс М1 при этом принадлежит
потоку Т2, который хочет в свою очередь захватить нюдекс М2, который принадлежит нюдекс МК и,
в конце концов, Т1. Мы скажем, что с каждым нюдексом у нас ассоциировано некоторый номер.
Это просто монотонный номерат, но не нумерация их. И мы ведем такую величину L от T. L от T это
максимум L от M по всем М, которыми владеет поток T. Это максимальный номер нюдекс,
которым поток Т уже владеет. Ну а теперь просто выписываем все эти L вот здесь. L от T1 и L от M1.
Каком они отношения состоят? Это простой вопрос. L от T1 это максимальный номер потока, максимальный
номер нюдекс, которым Т1 уже владеет. И мы знаем, что каждый поток захватывает нюдекс строго монотонно.
Две минутки буквально. Строго монотонно. Это значит, что здесь знак меньше. L от M1 и L от T2.
Ну вот M1 уже принадлежит потоку T2. Значит, эта L входит вот сюда. Значит, меньше либо равным. Ну и вот
так в конце концов получается, что L от T1 меньше, чем L от T1. Ну вот чуть корректнее. Вот так. Нет,
да, вот так. Ну и вот получается противоречие, а значит циклов возникать не может. Все. Ну вот это
уже полное такое основательное решение философии. На сегодня тогда все.
