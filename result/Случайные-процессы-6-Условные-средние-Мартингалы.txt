Сейчас мы обсуждаем условные и средние.
Ситуация такая, есть вероятностное пространство, есть под сигма алгебра,
и есть оператор условного среднего, который определяется одним из двух способов,
как вам больше нравится, либо как в L2 ортогональная проекция на подпространство,
порожденная А-измеримыми функциями, либо с помощью теоремы Радонна-Никодима.
Для первого способа сначала это делается, естественно, для функций из L2,
ну раз уж что-то делается в L2, но как потом получить обычные свойства условного среднего,
которые приистекают из Радона-Никодима. Можно заметить, что если функция не отрицательная,
то ее условное среднее не отрицательно, ну как водится в таких делах, почти всюду.
Ну раз почти всюду, то можно выбрать версию, которая всюду не отрицательна.
Почему это так? Ну это потому что вот это для всех множеств будет не отрицательно,
а это есть интеграл условного среднего. Ну и поэтому раз от этой функции интегралы
по множеству не отрицательны, значит она сама почти всюду не отрицательна.
Из этого вытекает такое, что если кс меньше либо равно это, то условные средние также расположены.
Ну разумеется тут все почти всюду. Ну вот если это сначала получено хотя бы для ограниченных
функций, то перейти к L1 можно так. Перейти от кси из L2 кси из L1, значит можно так.
Значит сначала для не отрицательных, ну а потом естественно общую разложить в разность.
Значит для не отрицательных делаем так. Берем ксиэнные, которые есть, ну обычная
технология срезок. Значит берем вот такие вот срезки. Значит для них условные средние есть.
Значит для этих срезок условные средние есть. Значит эти срезки возрастают, поэтому условные
средние тоже возрастают, ну как водится почти всюду. Значит получилась такая последовательность
функций возрастающая. И интеграл, ну как всегда интеграл, это есть интеграл с единицей и поэтому
получается вот так. И это не отрицательно, то что не отрицательно, это не важно, это меньше
либо равно, чем вот это. Ну и поэтому получилась последовательность функций возрастающая с
ограниченными интегралами. Значит следовательно существует вот такая вот функция, ну дзета,
которая есть предел вот этих вот, почти всюду. Почти всюду и в L1. Ну и из этого очевидным
образом следует, что, ну если перейти к интеграмам по множествам, то из этого следует,
что эта функция служит условным средним. Ну и получается, что на L1 аналогичные свойства
выполняются. Ну вот если через Родон Никодима делать это сразу, ну а здесь получается как следствие
того, что это было в L2. Значит, ну свойства такие. Значит вот такое соответствие линейно.
Так, дальше значит оно монотонно. Вот в этом смысле. Дальше интеграл, ну или вот мат ожидания
от условного среднего есть ростом от ожидания. Так, и если функция эта ограниченная, а измеримая,
то тогда можно ее выносить из подусловного среднего. Значит, тогда условное среднее с ней
будет вот так выглядеть. Ну откуда это следует? Значит, откуда это следует? Значит, как это
свойство проверяется? Ну в случае L2 это просто из свойств артагональных проекций, конечно,
следует. Но если это делать из Родона Никодима, ну или вот выводить из L2, то получается так.
Значит, мы берем интеграл от этого дела по множеству а. Ну естественно, а из сигма-алгебры.
И получаем, что это есть вот это. Получаем, что это есть вот это. А это можно записать
как интеграл по всему пространству. Вот от чего. А это по определению, поскольку эта функция,
вот эта функция, она а измерима. Поэтому вот этот интеграл можно скрутить обратно в интеграл
с условным средним. Ну и значит, это последнее есть интеграл по множеству а. Вот от этого дела.
Ну и что и доказывает, поскольку множество а произвольно, то получается такое равенство.
Значит, вот это свойство, в частности от констант, конечно, будут получаться ниже.
Значит, вот это свойство, ну такое вот, такое вот мультипликативное свойство, оно на самом деле
описывает все условные средние. Значит, вот в качестве упражнения проверьте такую вещь.
Значит, пусть оператор дан. Это ортогональный проектор ВЛ2П. Причем он обладает вот каким
свойством, ну вот аналогичным, вот этому. Значит, интеграл. Значит, интеграл. Сейчас,
значит, как это лучше написать? Ну, давайте я сразу напишу вот так. Значит, вот так давайте
напишу. Значит, вот так без интегралов. Напишу прямо в терминах самого этого оператора,
в терминах этого проектора. Значит, это верно для всех, для всех ограниченных F и G. Вот задан такой
ортогональный проектор. Ну, то есть что такое ортогональный проектор? Значит, ВЛ2 есть какое-то
замкнутое подпространство, и на него дан ортогональный проектор. И у этого проектора вот такое
свойство на ограниченных, ну вот аналогично этому. Но тут, видите, тут никакой пока сигма-алгебры
нет. Но тогда существует сигма-алгебра, сигма-алгебра А в B такая, что этот проектор есть условное среднее
относительно этой сигма-алгебры. То есть условные и средние характеризуются, стало быть, двумя
свойствами. Они ортогональные проекторы и плюс еще вот это свойство, что можно выносить, значит,
аизмеримые функции из-под них. Но когда еще сигма-алгебры нет и нет аизмеримых функций,
это трансформируется вот в такое вот условие. Так, значит, что-то я еще хотел сказать про условные
средние. А, ну вот несколько еще простых вещей. Ну тоже, это все вроде бы должно быть где-то
там раньше в теории вероятности, но такие вещи всегда полезно напомнить. Значит, если, значит,
если А0 лежит в А, то когда вы возьмете сначала спроектируете на одно подпространство, а потом
на меньшее в нем, то это то же самое, что сразу проектировать на меньшее. Ну в терминах ортогональных
проекторов это совсем очевидно. Ну и если это записывать через интегралы, ну тоже это из
определения сразу вытекает. И, значит, еще неравенство, неравенство Йенсона полезная вещь.
Значит, неравенство Йенсона оно для функций выпуклых, значит, в выпуклая функция, ну скажем,
для упрощения дела на всей прямой. Тогда выпуклая функция от интеграла оценивается через интеграл от
композиции. Ну, разумеется, тут требуется, чтобы интегралы существовали. А аналогично для условных
средних, значит, для обычных интегралов это неравенство для чисел, а для условных средних,
значит, для условных средних, значит, вот так это будет. Значит, это будет вот так. А, значит,
В от условного среднего оценивается через условное среднее от композиции. Если, если
кси и композиция интегрируемы. Так, значит, ну как это доказывается? Ну, это можно доказывать
разными способами, но, наверное, самый наглядный такой, но это не единственный способ, но, мне кажется,
он самый наглядный. Значит, обоснование, как это обосновывается, сводим срезками к ограниченным,
к ограниченным кси. Значит, ну, то есть, замечаем, что достаточно доказать это для ограниченных,
а потом, значит, с помощью предела это можно распространить. А, значит, равномерными приближениями
сводим к простым, к простым кси. Значит, ну опять, если для простых, ну, то есть, с конечным
числом значений это известно, то понятно, что, когда вы будете равномерно приближать ограниченную
простыми, то, ну, очевидно, что, значит, ну, давайте это я замечу. Значит, если ксиены сходятся кси равномерно,
то тогда получается, что V от ксиенных равномерно сходится V от кси. Ну, мы тут пользуемся, конечно,
не явно тем, что функция выпуклая непрерывно. Так, и, значит, теперь, значит, мы только еще
замечаем, что из свойств, из свойств, значит, условного среднего, значит, смотрите, что получается.
Получается, что если Gn равномерно сходятся к G, то тогда условные средние равномерно сходятся
к условному среднему. Ну, это из-за вот, из-за оценок, которые были для условных средних. То есть,
если функция по модулю меньше либо равно epsilon, то условные средние тоже. Значит, поэтому достаточно,
поэтому достаточно рассмотреть случаи, когда кси простая. Значит, вот теперь, значит, кси простая.
Значит, что это значит? Это значит, что она есть вот кто. Так, значит, она вот такая есть, где, значит,
омега это дизюнктное объединение. Так, значит, омега разбили на дизюнктные куски, ну, разумеется,
из сигмала вибры. Так, то есть, не, конечно, не из A, а из B. Значит, омега разбили на куски,
на каждом куске функция постоянна. Так, теперь давайте, сейчас, ну, давайте я среднее лучше
затру. Значит, давайте посмотрим, значит, что, значит, что тут будет. Значит, смотрите,
чему равно, чему равно тогда условное среднее. Значит, условное среднее это сумма. Значит,
вот такая сумма. Так, ну, как водится почти всюду. Значит, это из-за линейности. Так,
теперь, кто будет, кто будет условное среднее от композиции, кто будет условное среднее от
композиции. Значит, ну, это будет вот кто. Композиция, значит, композиция, значит, смотрите,
функция была константой на каждой из этих. Значит, когда применили V, то что оказалось? Ну, оказалось,
что она стала другой константой. Так, значит, вот, вот так поэтому будет. Ну, и здесь будет вот,
что V от C1 на условное среднее от этого, плюс, ну, и так далее, плюс V от Cn на условное среднее
от последнего. Так, значит, это вот такая правая часть. А теперь мы хотим применить V вот к этому
делу. Так, и увидеть, что это оценивается через правую часть. Ну, как это увидеть? Ну, замечаем,
что сумма вот этих вот тождественно равна единице. Так, из этого следует, что сумма условных средних
тоже единица, но только почти всюду. Так, но тогда смотрите, что здесь стоит. Здесь стоят какие-то
числа. Ну, они случайные, конечно, но, тем не менее, они хоть и случайные, но у них сумма единицы
почти всегда. И, значит, их комбинация с какими-то весами, циитами. Значит, V выпуклая,
значит, V выпуклая. Из этого следует, что V вот от этого дела, значит, V вот от этого дела будет
оцениваться, ну, как полагается, для выпуклой функции будет V от C1 на вот это, значит,
плюс-плюс и так далее, V от Cn на вот это. Ну, почти всюду. Значит, вот так будет почти всюду. Ну,
а это и есть то, что мы хотели получить справа. Так что получается, что для конечно значных функций
это непосредственное следствие выпуклости, для ограниченных функций результата равномерного
предела, а для функций уже неограниченных, ну, ну, чуть там, чуть более изысканный предел с помощью
срезок. Вот, значит, так что вот, значит, вот основные свойства. Так, если я ничего не забыл,
что хотел сказать. А, вот, вот еще две, вот еще две полезные задачи. Значит, две задачи, значит,
ну, они в конспекте тоже есть. Ну, давайте я их здесь выпишу. Эти задачи мы дальше будем использовать.
То есть, это такие задачи, которые надо решить. Значит, задача один. Значит, задача один. Значит,
пусть интегрируемая кси независимо, независимо с а, то есть со всеми а измеримыми функциями. Так,
тогда ее условное среднее, а есть просто ее обычное среднее. То есть, значит, это, ну, вообще говоря,
для большинства функций условное среднее это функция, так, но в некоторых случаях эта функция
может становиться константой. Вот константой она становится тогда, когда вот эта функция,
случайная величина, независимость сигма-алгебры. А независимость сигма-алгебры понимается как
независимость со всеми случайными величинами оттуда, измеримыми относительно нее. Вот, значит,
первая задача и вторая задача тоже в таком же духе. Значит, это вот какая задача. Когда же
случайная величина, значит, случайная величина кси, ну, уже не обязательно интегрируемая,
независимо, независимо с а. Значит, тогда и только тогда, когда, значит, верно следующее,
значит, когда вы берете ее, подставляете в Борелевские функции ограниченные, и у вас получается всегда
вот это для всех ограниченных Борелевских ф. Значит, то есть, видите, по одному такому равенству,
по одному такому равенству еще нельзя судить, что случайная величина независима с сигма-алгеброй.
Но если равенство из предыдущей задачи выполняется не для одной только нее самой,
а еще и для всех функций, ограниченных от нее, то тогда это равнозначно, значит,
независимости относительно сигма-алгеброй. Так, значит, ну, дальше, значит, смотрите,
значит, дальше нам эти условные средние понадобятся для двух оставшихся основных классов
случайных процессов, для маркенгалов и для марковских процессов. Ну и вот, значит,
сейчас я начну про маркенгалы, ну, видимо, в следующий раз закончу про маркенгалы,
потом будет небольшое обсуждение, значит, другого важного класса марковских процессов,
где тоже условные средние фигурируют. И на этом, так сказать, общая, как бы, абстрактная,
так, ну, в кавычках абстрактная, ну, она может, конечно, и отчасти и правда абстрактная,
ну, такая или, скажем, теоретическая часть закончится, а мы должны будем разобрать еще
две, ну, вот с помощью этих технологий, так сказать, основанных на абстрактных вещах,
две конкретные задачи, которые классики решили еще очень давно, еще когда не было маркенгалов,
всей этой техники, но вот, значит, как-то искусно они, значит, голыми руками эти задачи взяли,
ну, а мы, значит, руководствуясь вот этими теоретическими, значит, построениями, ну,
решим эти задачи несколько короче, чем их решили классики. Значит, вот, значит, следующий раздел,
значит, фильтрации и маркенгалы. Значит, теперь Т у нас будет не абстрактное параметрическое
множество параметров, а под множество R. Ну, в общем-то, для части обсуждения будет неважно,
что это именно R, будет важно, что T упорядоченное множество, но все-таки давайте, чтобы немножко
технически, так сказать, приземлить наше обсуждение, пусть T будет частью R. Что? Нет,
не обязательно. Ну, T может быть, например, целые числа, натуральные числа. Нет, связанности не
требуется. Значит, что такое фильтрация? Значит, семейство сигма-алгебр FT, содержащихся в этой
основной сигма-алгебры. Фильтрация, значит, если оно, значит, вот связано вот таким вот соотношением
для элементов времени. Ну, мы так будем условно на это тесселлаться, как на время. Ну, еще иногда
говорят поток сигма-алгебр. Теперь, ну, какой практический смысл вот этих множеств в реальных
задачах. Ну, это речь идет о событиях, о наступлении или ненаступлении которых,
известно уже в момент времени, ну, до момента T или в момент времени T. Так вот, если интерпретировать
события, ну, как что-то, что наблюдается, то вот, так сказать, такая вот простая интерпретация. Но
это совершенно, это совершенно не обязательно расшифровать, потому что, ну, если взяться за это,
то тогда возникнет вопрос, что такое известно, там и так далее. А, значит, здесь, ну, вот такой
чисто теоретико множественные условия. Значит, значит, определение, значит, случайный процесс,
значит, вот с этим параметрическим множеством согласован с фильтрацией.
Значит, вот это и вот. А, если ксиат T, ft измеримо для всех T. Значит, смотрите,
общий случайный процесс это какой угодно набор случайных величин, а согласованный с фильтрацией
это еще дополнительное требование, чтобы они были измеримы не относительно большой сигмал гибр,
относительно которой все должны быть измеримы, а относительно своей меньшей. Значит, всякий
процесс, значит, всякий процесс ксиат T порождает, порождает фильтрацию. Значит,
А, которую мы обозначим вот таким символом, значит, это сигма алгебра, порожденная всеми
случайными величинами до момента времени T. Ну и, очевидным образом, он с ней согласован.
Ну, разумеется, очень легко привести пример процесса, который с какой-то фильтрацией не
согласован. Так что, значит, бывает так, а бывает, значит, и не так. И, значит, теперь вот основное
определение, ну, смотрите, парамартингалы, значит, получается так. Значит, есть такие побочные
тоже определения, ну, что это такое фильтрация, что такое согласованный процесс. Ну, и есть основное,
что такое мартингал. Значит, определение, значит, процесс, значит, процесс ксиат T мартингал
относительно, значит, фильтрации. Значит, если, значит, он с ней согласован,
значит, кси T интегрируемый, и выполнено вот такое вот тождество, значит, условное среднее,
значит, условное среднее. Ну, вот здесь бывает удобно обозначить условное среднее вот так,
а не обычным нашим символом. Значит, ну, давайте я здесь помечу, что вот такой символ это, значит,
такой же, как этот. Ну, почему так удобней иногда бывает? Ну, в общем, дальше это будет видно. Это
из-за того, что иногда вот здесь, ну, какие-то довольно длинные выражения возникают, и очень
неудобно их все загонять в верхний индекс. Ну, и кроме того, такова традиция. Вот, в принципе,
я бы даже сказал, что вот более распространен такой символ, но такой просто немножко короче,
я поэтому для краткости вот такой использую. Но вот наступают времена, когда надо, ну,
так сказать, более громоздкий символ, оказывается, удобнее. Значит, ну, естественно,
значит, естественно, это все должно быть почти всюду, конечно. Так, значит, если этот процесс
квадратично интегрируемый, но этого не предполагается, но если он квадратично интегрируемый,
то что геометрически означает мартингальность? Значит, вот эти сигма-алгебры, получается,
что они задают проектирование на такое возрастающее семейство замкнутых подпространств. Значит,
каждая сигма-алгебра, значит, порождает замкнутое подпространство. Большая сигма-алгебра,
большее подпространство. И получается, что есть такой вот веер, раскрывающийся подпространств
замкнутых, а процесс, это такая кривая в гильбертовом пространстве. И вот получается так,
что тут реально требуется, что когда вы проектируете точку кривой на меньшее подпространство,
то у вас должна получиться точка искривой при этом меньшем моменте времени. Так что многие
свойства мартингалов из этого, так сказать, соображения усматриваются. Давайте заметим,
ну давайте что-нибудь докажем. Давайте я вам сразу скажу, что мы будем доказывать про мартингалы.
Про мартингалы у нас будет несколько примеров и паратиарем. Причем одна из них, может быть даже
и самая важная про мартингалы, будет без доказательства. Прежде чем говорить про некие
свойства, эти примеры и теоремы будут как бы крутиться вокруг свойств мартингалов. Но
прежде чем говорить про свойства мартингалов, намечание про терминологию. Почему такое название
мартингал? Этого никто не знает, потому что это название появилось у классиков в 30-х годах,
у них не спросишь. Но французское слово мартингал имеет такое отчасти архаическое значение,
там ну часть иконской упряжки, ну в общем-то, так сказать, там наездники, наверное, сейчас там
французские это используют слово. А другое значение, ну тоже довольно старое, французское, оно такое
немножко жаргонное, и оно означает, значит, такую тактику игры в азартные игры со ставками, ну вот
таких там типа бросания монетки, когда вы при проигрыше удваиваете ставку. Ну вот чем из двух
руководствовались классики, когда выбрали такой термин для этого процесса, ну вот сейчас, так сказать,
уже спросить не у кого. Ну а теперь это слово, значит, ну перекочевало во все языки, ну и в том
числе русский. Значит, мартингал это, ну вот из общих классов процессов, это один из самых важных
процессов. Вот я уже говорил, из конкретных процессов два самых важных, это Виннеровский
и Пуассоновский, а из классов процессов, ну вот мартингал один из самых важных, вот самые важные,
можно сказать, мартингал, Марковский, ну и Гауссовский, наверное. Теперь, что можно наблюсти про
мартингалы? Значит, давайте заметим, что, значит, если, значит, ксиат Мартингал, то у него среднее
постоянно, так, значит, давайте, давайте поймем, почему у него среднее постоянно, так, значит,
есть идеи, откуда, как это получить, почему среднее постоянно. Ну у нас, смотрите, что известно,
кто такой, вот этот, ну скажем, пусть, пусть с, скажем, меньше, так, значит, при меньшем, значит,
он кто будет? Он будет условным средним от большего, так, а теперь, если, если навесить
среднее, так, если навесить среднее, то справа получится, то есть слева получится, ну просто
среднее, так, а справа средний от условного среднего, но средние от условного среднего
вот у нас было такое свойство, что это просто среднее, так вот, поэтому про некоторые процессы,
у которых средние непостоянно, но сразу можно сказать, что они не мартингалы,
например, Пуассоновский процесс. Но на самом деле очень многие важные процессы
получаются из мартингалов какими-то очень довольно простыми манипуляциями,
например, вычитанием среднего. Дальше у нас будет несколько таких утверждений, частично в виде
задач, ну из которых будет видно, что мартингалы это вещь такая довольно распространенная. Так,
теперь, значит, что мы хотим доказать про мартингалы? А, вот давайте я сразу сделаю
замечание, значит, если вместо равенства у нас будет вот такое вот неравенство, так, то это
получается супер мартингал. А если вместо, ну а если равенство противоположное, то суп мартингал.
Ну вот из дальнейшего будет видно, что большинство разумных процессов представляют собой либо мартингал
с какой-то такой уже специфической добавкой, ну либо суп мартингал или супер мартингал,
ну тоже с какой-то специфической добавкой. Так что вот все вместе это уже очень широкий класс
процессов. Но это я к сведению привожу, у нас не будет, вот про это у нас ничего не будет, но единственное,
что можно сказать, что из неравенства Йенсона видно, что если мартингал подставить, ну выпуклую,
ну или вогнутую функцию, то получится, ну там, соответственно, суп или супер мартингал. Так,
но это вот, так сказать, прямое следствие Йенсона и вот этого неравенства. Так, теперь,
вот давайте примеры. Ну один из первых примеров, который рассматривали классики такой, вот у нас
будет два общих примера, а потом будут, ну так сказать, про конкретные вопросы, про конкретные
процессы мы зададим вопросы, мартингалы они или нет. Но скажем про Пуассона, мы уже выяснили,
что он не мартингал, но будет интересно, как он связан с мартингалами. Значит, ну вот,
значит, первый пример, пусть ксииты независимые, случайные величины, значит, с нулевыми средними,
так, пусть сн, это их сумма, так, и фн, это порождена первыми n, так, значит, ну вот,
время натуральное, так, значит, время натуральное, значит, тогда, да, да, и еще конечно, значит,
еще конечно, мы требуем раз говорится про средние, ну конечно требуется, чтобы они были интегрируемы,
так, а тогда, тогда сн мартингал относительно, ну вот этой вот фильтрации, значит, вот,
обратите внимание, что мартингал, он всегда связан с какой-то фильтрацией, значит, если
заменили сигма-алгебры, то мартингал, конечно, может перестать быть мартингалом, так, ну давайте
проверим, почему это, значит, давайте проверим, почему это мартингал, вот это, ну можно сказать,
один из самых главных примеров мартингалов, ну и в общем-то в дискретном варианте, ну вот,
можно сказать, один из основных примеров, а, значит, в непрерывном варианте, который мы не будем
тут обсуждать, а мартингалы это стахастические интегралы, то есть это некие такие вот непрерывные
обобщения сумм, так, значит, ну давайте проверим, значит, давайте проверим, почему это мартингал,
значит, ну пусть, скажем, м, значит, пусть м больше n, так, и вот мы хотим взять условное среднее,
значит, мы хотим взять условное среднее вот этой суммы, значит, относительно вот этой сигма-алгебры,
ну из чего она эта сумма состоит, эта сумма состоит из суммы до n и оставшегося куска,
ну сумма до n она будет, естественно, при взятии условного среднего себя воспроизводить,
а дальше будет сумма условных, сейчас только я не то написал, вот смотрите, вот вы видите,
вот почему нас все время обманывают, а видим какую-то лажу и, так сказать, спокойно,
значит, да, начали как-то спокойно, значит, ее проглатываем, значит, а дальше здесь будет,
вот и от всего этого остается только вот этот первый кусок, так, значит, остается первый кусок,
значит, почему, потому что, вот это м, значит, вот это м, значит, почему, потому что условное
среднее ксижитово относительно вот этой сигма-алгебры равно нулю при g больше n,
ну почему так будет, значит, почему так будет, значит, откуда это видно, ну это, конечно,
должно следовать из независимости их, так, из равенства нулю средних, так, но, значит,
давайте посмотрим, почему так будет, ну потому что, значит, еще раз, значит, так как, потому что
интеграл от ксижитово и от всякой функции вот такой вот, так, значит, от этих переменных, ну где
фи-Борелевская, значит, фи-ограниченная Борелевская из-за независимости равен вот такому интегралу,
ну и равен нулю из-за того, что у этих нулевые средние, а интеграл распадается, ну это,
ну можно сказать, по определению независимости, вот, значит, значит, это, значит, это первый,
значит, это первый, значит, очень важный пример Мартингала, значит, теперь, значит, второй пример,
ну давайте, это будет первый пример, вот так его сделаем, так, значит, и теперь, значит,
значит, и так первый пример суммы независимых, ну вот надо не забыть, правда, про средние, ну почему
надо не забыть про средние, ну потому что если забыть про средние, то, конечно, нарушится вот это
условие постоянства среднего, так, и это, ну это напоминает, что надо не забыть, но получается,
что легко, когда средние не нули, то получается, что очень легко к этому перейти, ну нужно просто
вычесть из независимых их средние, ну и складывать вот центрированные, так что, в общем-то, поэтому так
вот обычно говорят без уточнения, что, значит, первый пример это суммы независимых, так, ну вот,
если даже забыли, значит, про средние, ну потом, значит, подкорректируем, теперь второй важный
пример, значит, пусть кси интегрируемая, так, значит, f от t, значит, f от t фильтрация,
тогда кси t, которые по определению получены как условные средние, вот этой одной, это мартингал,
так, то есть, видите, значит, второй пример, это вы берете одну, так сказать, случайную величину и
ее проектируете на эти подпространства, ну и из определения очевидно, что это мартингал,
ну если она из l2, то это просто очевидно из определения, потому что получаются такие вот
протагональные проекции, а если она из l1, ну из свойства условного среднего, это получается,
так, вот такие мартингалы исчерпывают, ну большинство, большинство, так сказать,
ну я бы сказал так, большинство непривывных мартингалов, вот у нас дальше будет теорема,
показывающая, что при широких условиях мартингал имеет такой вид, ну, например,
например, ну вот забегаю, я это приведу, теорема, ну просто сейчас сразу скажу,
например, если мартингал, то есть, если не мартингал, ну, если заранее дан мартингал,
который просто равномерно ограничен, или у него дисперсия, скажем, дан мартингал с нулевым
средним и равномерно ограниченными дисперсиями, вот у него тоже такое представление будет,
значит, не всякий мартингал так сдается, вот можете придумать пример из пункта 1,
так, ну, показывающий, что вот такая вот сумма, значит, такая сумма может не быть такого вида,
так, ну, оно и понятно, почему, ну, почему у суммы такого может не быть, ну, в общем,
вот в качестве примера придумайте такую ситуацию, когда вот это такая нарастающая сумма,
вот так не получается, вот, значит, вот, значит, вот это два основных примера, и сейчас мы приведем
третий пример, сейчас, значит, если я, сейчас, секундочку, значит, если я что-то еще не забыл,
что хотел сказать про них, вот, значит, значит, вот еще, значит, еще одно замечание, ну,
прежде чем будет следующий пример, значит, замечание, значит, если, значит, ксиате мартингал,
и он квадратично интегрируем, то это процесс, это процесс с ортогональными,
с ортогональными приращениями, ну, это значит следующее, что приращение,
значит, приращение ортогонально, если вы берете, ну, вот такие вот, значит, точки последовательные,
так, значит, ну, вот упражнение, докажите это, это, значит, очень несложное упражнение,
которое надо сделать, чтобы, ну, так сказать, как-то понимать, что такое мартингалы, так,
значит, но единственное, что обратите внимание, что так, чтобы так записать, конечно, надо,
чтобы он был из l2, если мартингал не квадратично интегрируем, такой вопрос не возникает,
значит, таким образом, видите, процесс с ортогональными приращениями, ну, это
что-то такое послабее, чем процесс с независимыми приращениями, так, ну, вот скажем, если это
гауссовский процесс, то это то же самое, а если не гауссовский, ну, это послабее, чем с независимыми
приращениями, но с другой стороны, если, значит, процесс с независимыми приращениями в l2,
так, то получается, значит, такая теорема, значит, пусть, значит, ксиат-т мартингал
квадратично интегрируемый, так, пусть у него ксеноль постоянная, так, ну, давайте только вот так
сделаем, чтобы ксеноль был, вот так сделаем его с неотрицательным временем, ксеноль постоянная и
средняя тоже постоянная, так, значит, сейчас, я чушь написал, наоборот, это еще пока не мартингал,
значит, это процесс с независимыми приращениями, процесс с независимыми приращениями,
квадратично интегрируем и, значит, как, ну, полагается мартингалу с постоянным средним,
тогда, значит, этот процесс мартингал, мартингал относительно чего, относительно
порожденной им самим фильтрации, так, вот смотрите, всякий процесс согласован со своей фильтрацией,
но отнюдь не всякий процесс будет мартингалом относительно порожденной им фильтрации, но это,
в общем, довольно очевидно, значит, но оказывается, что процесс с независимыми приращениями будет
мартингалом относительно порожденной им фильтрации, ну, тут вот еще технические условия, ну, они нужны,
конечно, потому что среднее должно быть постоянного мартингала, значит, ну, чтобы говорить,
значит, ну, здесь еще требуется, что он из L2, так, для независимости приращения это не требуется,
а вот тут это требуется, так, и, ну, еще вот он выходит из нуля, ну, это можно немножко
модифицировать, но вот формулировка, короче всего, так получается, значит, таким образом, ну,
вот если пренебречь такими техническими мелочами типа того, что он в L2, там еще вот этими вещами,
то получается, что мартингал это нечто среднее между процессом с независимыми приращениями и
процессом с некоррелированными приращениями, вот видите, значит, вот одно условие, есть более
сильная, значит, независимость, вот, значит, большинство общих мартингалов он где-то вот между этими
двумя, ну, конечно, за рамки этого можно выйти, если брать неквадратично интегрируемый, так,
так, что это, это, конечно, надо, так, ну, сказанное, так сказать, так воспринимать немножко,
как, ну, такое, так сказать, не совсем точное утверждение, вот, ну, а точно и вот они, так,
значит, ну, давайте, значит, так, сейчас, только надо сообразить, сейчас, я все время забываю время,
нет, нет, время еще есть, да, значит, ну, я думаю, что это мы сейчас и докажем, даже кажется,
меньше нужно, чтобы доказать, значит, значит, доказательства, значит, при S меньше T,
значит, смотрите, что у нас будет, значит, условное среднее, значит, условное среднее, можно записать так,
ну, тут, естественно, условия подсказывают, к чему надо стремиться, значит, надо делать из
процессов, надо делать их приращение, так, но так просто нельзя заменить, значит, надо вот так
заменить, так, значит, надо вот так заменить, теперь, значит, смотрите, что получается, получается,
что из-за, значит, линейности среднего, условного среднего, вот эта штука выйдет, но она будет сама
собой, и плюс еще будет, ну, вот от этой первой части будет, вот это, так, но вот это будет 0,
почему, значит, почему это будет 0, так, потому что, значит, ну, давайте это докажем, значит,
давайте это докажем, что почему будет 0, значит, а, значит, почему будет 0, а, значит,
значит, ну, давайте, значит, я здесь это напишу,
значит, почему это так, значит, ну, потому что
кси t минус кси s независимо со всеми кси tau при tau меньше либо равном s, но это из-за того,
что независимо с кси tau минус кси 0, а и кси 0 равняется нулю, значит, она вот это приращение
независимо со всяким таким приращением, но из-за того, что кси 0 0, то другое приращение,
оно просто кси tau, значит, получается, что вот эта штука независимо со всякой случайной величиной
кси tau, ну, значит, независимо с сигма-алгебрами порожденной, то есть вот с этой вот, с этой так,
значит, таким образом, значит, получается вот такой ответ. Так, теперь, значит, теперь,
значит, давайте вам, значит, будет задача. Да, ну вот, например, какой из этого проистекает
пример, значит, вот, значит, пример. Винеровский процесс, процесс WT-мартингал, а относительно,
значит, порожденной им фильтрации. А по-асоновски, ну, как я уже говорил, нет. Ну и вот давайте,
значит, задача, значит, задача, значит, пусть, пусть t это натуральное время, так, значит,
FN фильтрация, значит, и, значит, процесс, значит, кси N-мартингал относительно нее, причем,
значит, причем верно следующее, значит, значит, дисперсии равномерно ограничены. Значит, тогда,
тогда существует кси из L2 такая, что они получаются условными средними, значит, этой кси. Так, ну,
это такая вот, как бы, это задачка, так сказать, про проекторы в Гильвертовом пространстве, можно
сказать. Так, и, значит, значит, без доказательства, значит, без доказательства вот такая теорема,
которая усиливает эту задачу. Ну, впрочем, нельзя сказать, что это какая-то уж очень такая жестокая
теорема. Ну, в принципе, если бы лекция была 25, то такую теорему можно было бы и доказать,
то есть она вполне себе укладывается, значит, в те результаты, которые можно доказывать,
но вот когда лекции меньше полутора десятков, то, значит, такие вещи лучше оставлять без
доказательств, хотя теорема очень важная. Значит, теорема дуба о сходимости мартингалов.
Ну, дуб это был такой математик американский, но дуб, он не случайный дуб, он чешского
происхождения, и когда он был, значит, еще у себя на родине, ну, а он где-то там в тридцатых
годах прошлого века перебрался в Америку, то он таки был просто дуб, ну и писался, ну вот был
наш обычный дуб, но когда он, значит, перебрался в Америку, ему не понравилась транскрипция вот
этого дуба через ю, потому что многие американцы стали его называть дабом, и он поэтому такой вот,
так сказать, ну как бы французский вариант избрал написание, ну и вот стал, так сказать, стал дубом,
таким вот. Ну, а по-русски он, вот как был дуб, так и остался. Значит, теорема вот какая,
значит, пусть ксиен, значит, это вот, так сказать, один из отцов-основателей вот всей этой науки
мартингальной, значит, пусть ксиен мартингал относительно вот этой вот фильтрации,
значит, где n, значит, натуральная. Значит, этот мартингал, мартингал сходится в l1,
значит, в точности тогда, значит, в точности тогда, когда существует такая функция кси из l1,
которая дает, которая дает, значит, ну вот по этой технологии, значит, все эти, значит, функции.
При этом, при этом ксиенная сходится к этой кси еще и почти всюду. Тут, значит,
основное утверждение про, когда он сходится в l1, так, то есть вот получается так, а, значит,
существование вот такой порождающей одной функции, порождающей всех, это есть просто ситуация,
когда исходный мартингал к чему-то сходился в l1, так, но если он сходится в l1, то он сходится и
почти всюду, так, а вот тут важно, что первичная сходимость в l1, значит, если он просто сходился
почти всюду, то это еще не означает всего этого, так, так что здесь все-таки, ну, такая основная
сходимость в l1, а вот это второе утверждение, ну, это такой, так сказать, дополнительный бонус за
эту сходимость, значит, он ей не равносилен, но он присутствует, потому что, вообще говоря, из
сходимости интегральной, ну, обычно не следует сходимость почти всюду, там интегралы могут
сходиться к нулю, а функции вовсе не обязательно сходиться к нулю, но вот в этой специфической
ситуации оказывается, что и, ну, есть сходимость почти всюду, ну, еще можно заметить, что, значит,
сходимость в l1 равносилена также такому, что называется равномерная интегрируемость,
значит, вот я давайте здесь выпишу, но это уже, так сказать, дополнение, это не в самой теореме,
а это тоже, так сказать, полезное дополнение, к чему это равносильно, это равносильно вот к чему,
что когда, значит, возьмем интеграл вот такой по множеству, где это больше либо равно r,
возьмем sup по этим n, и тогда вот это должно стремиться к нулю, когда r идет в плюс бесконечность,
так вот, и это же еще равносильно вот к чему, что существует выпуклая функция v, такая,
которая растет на бесконечности быстрее t, такая вот функция, которая на бесконечности растет
быстрее t, такая, что интегралы вот от этих вот v от xn, значит, равномерно ограничены, ну вот,
поэтому ваша задача, но она более простая, чем теорема дуба, но она вот охватывается этим случаем,
потому что как раз ваши задачи вот этой предыдущей, где квадраты были, интегралы от квадратов были
ограничены, ну она соответствует функции v от t, t квадрат, но вот из этого дополнения видно,
что годится какая угодно выпуклая функция, ну вот t не годится, значит, смотрите, а ограниченности
ограниченности v1 мало, так, значит, вот давайте это будет упражнение, ограниченности v1 мало,
из нее не следует, но если есть ограниченность чуть-чуть лучше, чем v1, значит, вот там vlp каком-то
там с p чуть больше 1, то уже все окей, вот, значит, так, значит, это кажется,
значит, это кажется все, что я хотел сказать про мартингалы, а вот еще задача, вот еще тоже
полезная задача, значит, так, ну давайте вот это я сотру, значит, задача, значит, пусть
значит опять процесс с независимыми приращениями, так, значит, с неотрицательным
временем, с независимыми приращениями, так, и пусть, ну пусть он выходит из нуля и давайте
сразу его сделаем с нулевым средним, значит, вот такой процесс, тогда вот такой вот процесс
нелинейный, видите, такое нелинейное преобразование процесса с независимым,
значит, ну мы знаем, что сам, значит, да, да, еще, ну еще, еще важно, конечно, это я тут имею в виду,
но давайте явно запишу, значит, он еще и из l2, значит, смотрите, значит, мы разобрали,
что он сам будет мартингалом, так, значит, он был с независимыми приращениями, он сам был
мартингалом, но оказывается, не только, значит, вот, ну, что он сам мартингал, еще вот такой
процесс, тоже мартингал относительно, ну, порожденной им фильтрации, так, ну вот, в частности,
смотреть, что получается, значит, если в качестве процесса, ну вот мы уже знаем, что винаровский
процесс мартингал, так, из-за того, что он подпал под этот пример с независимыми приращениями,
но получается еще один интересный пример мартингала, такой довольно неочевидный, значит, ну вот, например,
значит, если wt винаровский, то тогда wt в квадрате минус t мартингал, вот, это так сразу не очень
очевидно, ну вот, например, совершенно очевидно, что wt в квадрате не мартингал, так, ну хотя бы
потому, что среднее непостоянно, так, но оказывается, что вычитанием среднего получается мартингал,
то есть вот, ну, здесь тоже, видите, какая ситуация, сам процесс, ну, вообще говоря, не мартингал такой
в квадрате, а тут сделали банальную вещь, вычли, ну, просто сделали его центрированным, сделали нулевое
среднее, и вдруг оказалось, что это мартингал после вычитания, ну, конечно, ситуация специфическая,
к сиатте, конечно, никакой угодно был процесс, он был с независимыми приращениями, это, конечно,
очень важно, но, тем не менее, такой довольно неожиданный эффект, значит, вот тоже задача, ну,
я бы сказал, не сложная, но полезная, в общем, значит, ее, значит, хорошо бы ее сделать, так, и,
значит, сейчас, но вот сейчас, кажется, уже время кончается, правильно? Да, ну, давайте,
давайте не буду следующую важную вещь начинать, потому что, ну, вот еще будет одна теорема,
связанная с Дубом и его учеником, Полем Андреемиером, но это давайте в следующий раз,
потому что, ну, как-то вроде нехорошо, важную вещь в ППХ в конце, но хотя, с другой стороны,
Штирлиц учил нас, что последняя фраза запоминается лучше всего, так что, в общем,
тут не поймешь, кого слушать, Штирлиц или методистов, так, все, давайте на этом закончим.
