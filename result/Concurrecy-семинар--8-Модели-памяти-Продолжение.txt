Вопрос, как проверить, что мы проставили memory-order правильно, но правильным единственно верным способом является защита, желательно мне.
Чтобы я посмотрел глазами, правильно ли мы поставили memory-order и разобрались вообще, каким принципом ты их расставлял.
Не только важно, чтобы они попали в правильные, а в первую очередь важна логика, которую ты руководствовался, когда их выбирал, что ты с чем синхронизировал, какую цель ты преследовал.
Мы же на прошлом семинале говорили про release-acquire, помните этот пример, мы с вами разбирали, да?
И тут же не просто нужно было ставить, что load – это, наверное, acquire, store – это release, а логика была такой, что мы пытались понять, что мы с чем упорядочиваем, какие неатомарные обращения.
Вот первая запись в буфер, вот здесь какой-то слот, должна быть упорядочена с первым чтением, а первое чтение должно быть упорядочено со второй записью, чтобы не было гонки.
И мы дальше смотрели, какие же отношения нужно выстроить между этими чтениями и записями, чтобы достичь нужной гарантии, чтобы было отсутствие гонок и была видимость записи в чтениях.
Вот это в первую очередь важно, никакой автоматики и такое понимание не проверить, разумеется.
Еще одна проблема, которая здесь есть, техническая, в том, что вот у тебя процессор сам по себе не может...
Ну вот наш процессор, если бы у нас были ARM, было бы интереснее, но у нас Intel, и там memory-памяти процессора самая достаточно сильная, и release и acquire комплиируются просто в move.
Это означает, что слабее, чем move, ты получить просто... слабее, чем release и acquire, семантик, ты получить не можешь.
И даже если ты используешь везде чтение с relax, и после чтения с relax ты делаешь выводы о содержимом других ячеек памяти, что вообще говоря нельзя делать, все равно у тебя будет код работать.
Но вообще-то thread sanitizer умеет такое отслеживать.
Даже вот в этом примере, хоть у нас и невозможно было получить семантику слабее, чем release и acquire, если бы мы написали здесь где-нибудь relax в неправильном месте,
и запустили бы код с thread sanitizer, что мы в прошлый раз делали, то мы видели, что он ошибку находит.
Ну, надеюсь, найдет сейчас.
Да, он это есть нашел, потому что он не то что проверяет...
thread sanitizer действует по-другому, он не то чтобы ловит вот какие-то последствия проявления железной модели памяти, нет, он прямо отслеживает в программе happens before,
то есть он обнаруживает гонки по определению, два неотомарных обращения к памяти конфликтующих, которые неупрядочно через happens before.
Как он это делает, это вообще очень интересная алгоритмическая задача, инженерная задача, и я про это поговорю, наверное, не сегодня, мы пока еще не разобрались с такими более базовыми вещами.
Но вот этот инструмент, он независимо от того, какая модель процессора под тобой, какие-то гонки может поймать, не все.
Но если вот ты где-то переборщил и прям relax выставил, то он это заметит.
Вот нарушение sequential consistency, вот какие-то такие тонкости он не почувствует, не почувствует, скорее всего.
То есть тебе может быть нужна sequential consistency, у тебя будет release require написан, и этого будет где-то недостаточно вдруг, вот он этого не заметит.
Кроме того, еще почему сложно проверить, насколько хорошо ты это сделал, ты можешь проверить, что у тебя достаточные memory orders, но ты не можешь проверить, что они minimally.
Может быть, где-то можно оптимальнее поступить, может быть, ты где-то лишнее выбрал, вот опять.
Это может сделать, вообще говоря, только человек, который понимает, что за задача решается.
Так что правильный способ – это приходить на защиту и разговаривать, потому что модель памяти – это самое сложное, что у нас в курсе.
Не то, что самое сложное, это такая отдельная перпендикулярная всему сложность, и там глубина очень сложная, это очень большая.
Но вообще ставить memory orders в нашем курсе – это очень хорошая идея, потому что опять тема перпендикулярна всему, и весь код, который мы пишем, можно этими memory orders ускорять.
Вот чем дальше мы пишем файберы, тем меньше там mutex в хороших реализациях.
Вот в Домашке вас просят написать mutex для файберов без взаимного исключения с lock-free.
В weight-группе вас просят обойтись, там тоже поменьше mutex вставить, используется тамарная операция.
В самом планировщике, который у нас сейчас плохой, в субботу станет хорошим, но у меня, по крайней мере.
Там тоже будет мало блокировок, и тоже будет много lock-free.
Ну и у нас в Домашке сейчас про lock-free.
Короче, вот сейчас, в данный момент курса, мы переходим к сложным вещам уже, к содержателям,
и появляется очень много мест, где можно вот таким образом код оптимизировать.
И мы сейчас вот этот код оптимизируем, потом оптимизируем сам планировщик,
и вот в конце курса, если с теми, кто хочет закрыть курс на отличный, причем на хороший, основательный, отличный,
мы сможем собрать в итоге полную библиотеку и ее протестируем на производительности.
Это можно сделать только ближе к концу, когда все вместе соберется.
Вот сейчас мы можем оптимизировать файберы, но под ними сейчас очень медленный планировщик.
Если вы запустите профайлер, посмотрите на Flame Graph, чем ваш код занимается,
то вы увидите, что он занимается, в общем, каким-то сомнительными делами.
Он делает явно не то, что он должен делать.
В смысле, тратит время не там, где он должен его тратить.
Так что пока мы просто пишем код и стараемся писать его оптимально,
а когда у нас все компоненты сложатся вместе, мы сможем прям быстрые и быстрые файберы сделать,
то есть построить такой быстрый ГО.
И в принципе тут никаких ограничений нет, потому что мы с вами в курсе не делаем что-то игрушечное,
мы пишем настоящий ГО без всяких скидок.
То есть вы можете закончить его с ГО, который может быть лучше.
Но это только от вас зависит, что вы напишете в конце.
И вот если вы на каждом этапе делаете все хорошо, то в конце что-то хорошее выйдет.
Но в любом случае мы профилируем, в конце увидим, где у вас там время тратится, что можно пооптимизировать.
Но да, я указываю на это, что давайте стараться, раз уж мы про Memory Order узнали,
стараться их использовать, стараться думать, как учиться их правильно использовать.
Такой затяжной ответ был на твой вопрос.
Но вроде я все, что мог, сказал.
Я могу указать, что ты слабее, и мне в первую очередь важно понять, как ты рассуждаешь.
Правильно ли ты рассуждал, когда эти Memory Orders ставил.
Это важнее, чем угадать правильно.
Давайте какие-нибудь вопросы накидайте, мне наверняка вот что-то волнует, что-то вам непонятно.
Может быть, вам непонятно, что происходит.
Вот вы сейчас в такой точке курса, вы не понимаете, что происходит.
Где мы, что мы делаем, зачем мы что-то делаем, каковы наши цели?
Нет, если все понятно, то это хорошо, но если...
В Slipform мы можем использовать... Смотри, задача...
Ответ такой. У нас в задачах, по крайней мере, по моей задумке, нет искусственных ограничений.
Вот у тебя есть задача, как задача на работе, задача просто в жизни.
У тебя есть инструменты, доступные тебе для ее решения.
И вот ты используешь инструменты, доступные тебе для того, чтобы решить данную тебе задачу.
Ну вот, ты можешь делать все.
Если я тебе что-то запрещаю, то мы оба должны понимать, почему я тебе это запрещаю.
Если я тебе запрещаю что-то, потому что мне так не нравится, это плохой аргумент с моей стороны.
Если у тебя есть инструмент, он решает... У тебя есть задача, у тебя есть в ней проблема,
некоторые есть инструменты, которые эту проблему решают, но вот используй его, видимо, инструменты нужны.
Мы не пытаемся понять, что можно использовать, что нельзя использовать.
Используй все, что тебе нужно.
Вот как ты код будешь просто в жизни писать.
Никто не говорит, вот такие вот ограничения на реализацию.
Нет, ты просто пишешь решение задачи.
Вот конкретно Per Defer, ну вот да, его, видимо, нужно использовать, потому что, видимо, он дает тебе...
Он решает ровно твою проблему, что тебе нужно упорядочить задачи Sleefer, засыпание,
пробуждение в колбеке по таймеру и засыпание в текущем потоке картины.
То есть ты можешь остановиться в текущем...
Еще не успеть остановиться в текущем потоке, но уже завести таймер.
Этот таймер быстро сработает, и картина запустится в другом потоке, пулопоток.
И в итоге у тебя получится гонка.
Ты уже активировал контекст исполнения, который еще не успел сохранить.
И в итоге у тебя программа разваливается.
Ну, тебе, видимо, нужно упорядочить два этих шага.
И вот Defer, он это позволяет делать, собственно, поэтому в условии и было написано.
Сейчас, давай мы вернемся в условие.
Где-то...
Так давно это было уже.
Вот.
Где-то написано, что планировать задачи можно по-разному.
Вот есть DeferDispatch и есть, мне кажется, очень хорошая презентация,
которая отвечает на все вопросы, как что работает.
Ну, вот, в принципе, все, что здесь есть, можно использовать.
Вот, например, Strand есть, которые у нас были на предпоследней лекции.
Экзекьюторы на предпоследней были.
И Strand появились, которые позволяют цепочку задач прямо выстроить так, чтобы они не пересекались во время.
То есть, критические секции запускать.
В принципе, можно прямо Strand приделать задачу, но это будет тяжеловесное решение.
Более легковесное решение — это Defer, который откладывает планирование задачи до тех пор, пока не завершилось текущие.
Но в любом случае, это не то, чему мы в задаче учимся.
Мы в задаче не про то, чтобы исследовать, чтобы узнать про Defer.
Это, скорее, какой-то костыль, который у ASIO есть.
На самом деле, мы хотим все же для файберов использовать простые экзекьюторы,
которые в задаче следующей предэкзекьюторы есть.
Вот планировщик, который умеет просто запланировать задачу на исполнение.
И ничего больше не знает про нее.
То есть, нет никаких более тонких семантик, типа запланировать строго, пост и текущий?
Нет. Мы хотим использовать более общие механизмы планирования.
Так что, видимо, решение, которое мы найдем для задачи, для проблемы в задаче Slip4, оно не является хорошим.
Но вот в задаче Mutex, собственно, она и продолжает этот Slip4, и поэтому она от нее зависит.
Вот решая уже задачу Mutex, нам требуется, от нас требует найти более универсальное решение.
Ну потому что вот проблема, которая у нас возникала, это всего лишь частный случай более общей проблемы.
Ну вот мы строим в Mutex, и там нужно добавить себя в очередь, файбер в очередь, а потом уснуть.
Смотрите, вот задача Slip4, запланировать возобновление файбера, это подписаться на таймер.
В случае с Mutex, запланировать возобновление файбера, это положить себя в очередь, с которой нас достанут, разбудят.
Ну то есть выглядит совсем по-другому, но смысл тот же.
Когда мы говорим yield, то мы засыпаем и сразу просыпаемся.
В случае с Future, когда у нас есть некоторая асинхронная операция, есть представление ее результаты в виде Future,
то мы подписываемся на наполнение этой Future, и там себя резюмим.
Ну короче, можно придумать себе самые разные сценарии, в которых файбер чего-то ждет, а потом просыпается.
И все эти сценарии, они про ту же самую проблему, что нужно аккуратно заснуть до того, как мы можем проснуться.
И вот в задаче как раз говорится, что вот есть самые разные сценарии, они все не похожи друг на друга, но у них должно быть общее решение.
И это решение, разумеется, не defer, потому что наши экзекьюторы под капотом не будут уметь ничего, кроме просто запускать задачу,
но и Тредпулутов не умеет и не хочет уметь.
Поэтому мы должны придумать какое-то более универсальное решение, которое мы назовем Awaiter.
Awaiter – это та стратегия, которая в себе инкапсулирует логику возобновления файбра.
Ну и в задаче дана серьезная подсказка, как с этими Awaiter-ами работать и как правильно декомпозировать код.
И вот в хорошем решении у вас будет FiberCore, вот этот кусочек кода, кусочек библиотеки.
И предполагается, что добавление новых приметивов синхронизации от вас не потребует доработки вот этой директории.
Вы один раз там какую-то универсальную логику реализуете, которая не знает ни про файб...
Ой, не про файбр.
Не про там каналы будущие, не про селектант-каналами, не про фьютексы, не про Yield можно даже не знать.
Вот Yield можно вполне себе переместить в другую директорию и просто использовать...
То есть не нужно Fiber узнать про операцию Yield.
Не нужно прямо в Fiber какую-то логику Yield'а писать.
Не нужно в Fiber делать метод Yield.
Вот в задаче Coroutine мы, конечно, с этого начинали.
Мы вот в этой задаче как делали Yield, который нам был нужен?
Вот там Fiber пока ничего другого не умели.
И мы в этой операции Yield что делали?
Выходили из Coroutine, а внутри Fiber смотрели.
Если она завершилась, то, видимо, нужно разрушить Fiber.
А если не завершилось, то точно был сделан Yield, значит, мы это знаем.
Просто метод исключения, больше ничего и нет.
И поэтому бросали Fiber обратно исполняться в планировщик.
То есть мы прямо захард кодили Fiber и логику Yield'а.
А теперь мы столкнулись со Sleep Forum и поняли, что вот хочется обобщить немного.
Хочется уже не тащить Fiber знания про таймер и про засыпание.
А теперь мы делаем прям совсем универсальные решения,
так чтобы Fiber ничего не знали про приметивы синхронизации, про блокирующие ожидания.
И в итоге код Fiber только упростится.
Он станет более универсальным.
Но для этого нужно придумать, что такое Awaiter, зачем Fiber Handle,
ну и сделать код по оптимальне.
Хорошее решение получится в хорошем смысле.
Вы поймете, что оно хорошее.
Там все будет очень гармонично.
Это вообще такой верный признак, что вы делаете все правильно.
Если вы смотрите на код и думаете, боже, какое уродство, неужели от меня это вы хотели.
Ну, во-первых, не нужно думать о том, что от вас хотели,
потому что откуда вы знаете.
Вы решаете просто задачу, которая спустилась на вас с неба.
И вы не знаете, есть ли у него хорошее решение или нет в общем случае.
Но так уж и быть, я вам скажу, что здесь хорошее решение есть.
Мы его разбираем.
Хорошее решение выглядит довольно гармонично.
Хорошее решение – это решение, в котором связность маленькая.
Разные части кода мало знают друг про друга.
Поэтому легко о них думать в изоляции.
Так что если вы пишете хорошее решение, то, скорее всего, вы понимаете, что оно хорошее,
потому что оно такое локальное.
Вам не нужно думать, что происходит в другом месте далеко.
Вам не нужно думать, как устроен планировщик.
Вы пишете фибер и не думаете про фьютаксы.
Вы пишете фьютаксы и не думаете про планировщик и про механику фиберов,
что там внутри написано.
Хорошим решением такая связанность очень низкая,
и рассуждать о коде просто.
И поэтому он кажется, собственно, хорошим.
О нем просто думать.
Забегая вперед, осенью, когда мы будем писать распределенные системы,
там вообще будет очень много кода.
Но процента 95 кода напишу я.
А вам нужно будет...
Ну, то есть, сложность, конечно, в реализации распределенной системы
не в том, чтобы написать алгоритмы, а в том, чтобы все вокруг написать.
Но все вокруг очень сложно написать, поэтому научить этому невозможно на третьем курсе.
Ну, и для этого нужно потратить несколько лет.
Но суть в том, что очень много кода, очень высокая сложность.
И чтобы ее поддерживать вообще в уме, чтобы один человек с этим мог справиться,
нужно, чтобы были очень четкие границы,
чтобы мы опирались на абстракции, чтобы мы не думали про то,
как устроено все вокруг.
Мы бы работали с одним компонентом, развивали бы его,
а другие компоненты, детали их реализации из ума можно было бы вынуть.
Вот мы сейчас сделаем то же самое, только в гораздо более мелком масштабе.
Но проблемы те же самые.
Чем лучше код, тем проще думать о нем, тем проще думать об отдельных его кусочках
и взоряться от остальных.
Вот мы пишем фьютекс в этом коде, и ему мало что нужно знать про...
Ну, вообще, в этом коде это шаблон, он будет...
Шаблон обязательно в хедре должен быть реализован.
И вот в этом коде не должно быть просто знания про файбер вообще никакого,
то есть если мы заинклюрируем здесь файбер, то все,
эта деталь реализации попадет в пользователя.
А мы не хотим, чтобы она попала в пользователя.
Мы не хотим, чтобы пользователь вообще знал и имел доступ к структуре файбера.
Поэтому у нас есть вот некоторые файбер-хэндл,
который от нас, от пользователя...
То есть это штука, которая позволяет нам пользователям
писать новые примитивы синхронизации для файберов,
расширять их поведение,
но при этом не знать про то, как файберы устроены.
Ну, и еще забегая вперед, вот этот дизайн,
который мы в этой задаче придумываем,
он для нас важен, потому что уже через неделю,
то есть не в эту субботу, а в следующую,
мы будем говорить, как быстро время бежит,
мы уже будем говорить про стеклоскорутины в C++.
И вот дизайн стеклоскорутин, вот он такой, как в этой задаче.
Ну или эта задача.
В этой задаче такой же дизайн, как в стеклоскорутинах.
Короче, если вы сейчас это придумаете,
то вы поймете, как устроены корутины в C++.
И наша цель в том числе и в этом.
Ну то есть с одной стороны файберы сделать,
а с другой стороны разобраться, как в C++
сделали стеклоскорутины, которые...
Я вам показывал их много раз уже.
Можно еще раз показать.
Как все это работает под капотом.
Там довольно сложная механика,
но вот эта докуменция точно не способ,
как ее можно изучить.
Но в общем, под капотом там все довольно затерево,
и вот эти корутины, они тоже сделаны так,
чтобы их можно было расширять,
в смысле, кастомизировать их поведение.
Что именно они здесь делают?
Это не компаниятор решает, не библиотека решает,
мы пользователи.
И с файберами точно такая же история.
Мы сами решаем, как делать блокирующие ожидания.
Чего файберы вообще дожидаются, когда они засыпают?
Мы как пользователи можем расширять их поведение.
Так что вот задача, она в том числе про то,
чтобы изучить некоторый глобальный дизайн,
который в C++ используется, и в C sharp используется,
и в некоторых других языках.
Такой вот довольно масштабный замысел за всем этим стоит.
Вот я бы хотел, чтобы в следующий раз
мы бы уже на семинаре столько всего,
как мы это все успеем вообще не понять.
Нужно про слабой модели поговорить,
нужно про троценитайзер поговорить,
нужно про лукфрии поговорить.
Нам нужно в два раза больше семинар.
Непонятно.
Останемся не очень, ужасно.
Так вот, на следующем семинаре я бы хотел,
чтобы мы просто устроили код-ребью такой,
более-менее массовый, но не то, что массовый,
но в таком составе нам подойдет.
Но нужно, чтобы вы пришли с решением,
а там уже до длани стучит, кажется,
у вас будет повод прийти с решением.
И мы обсудим его, насколько оно хорошим получилось у вас.
Да, вот это задача про Mutex.
Мне кажется, что это разумнее будет сделать
прямо на семинаре, потому что,
ну, прямо скажем, вот эта задача,
она уже, будь здоров, про дизайн,
она довольно сложная,
и тут много подсказок в условии,
но, может быть, вы не все поймете
или не все сделаете хорошо,
и нам нужно вместе всем посмотреть на это,
подумать, а как можно сделать хорошо,
что можно улучшить.
Нет, ну, конечно, попытайтесь сами в первую очередь,
но, короче, я вас ожидаю,
что в следующую среду
я посмотрю на какой-то ваш код,
и вы сами мне расскажете,
что вы пытались сделать,
что вам не нравится в этом коде,
и мы подумаем, как его можно улучшить.
Для начала вы должны его написать,
и вам он должен не нравиться.
Ну, или вы напишите код,
он вам понравится, это лучку,
которую вы писали в жизни,
и вы можете посмотреть.
Тут вопрос про дизайн уже,
дизайн — это такая очень сложная тема,
очень сложный топик,
он требует довольно большого программирования,
которого у нас пока нет,
так что нужно этому учиться.
И еще что-нибудь?
Ну, не знаю,
пойдемте вы, наверное,
про лок-фри поговорить.
Про лок-фри, а про модели памяти мы не хотим поговорить?
Просто мы остановились,
мы разобрали два примера с вами, да?
Мы с вами разобрали спинлок,
поставили там барьеры памяти.
Мы хотели упорядочить записи
в предшествующей секции с чтениями
в последующей секции, но вообще обращение
конфликтующей в предшествующей и последующей.
Мы сказали, что у нас есть предшествующие и последующие,
потому что есть modification order
на одном атомике.
А дальше мы сказали, что как обеспечить
видимость записи из предшествующей секции
в последующей, сделать happens before.
А что нужно сделать, чтобы получить
happens before? Нужно получить
отношение synchronizes with.
Это единственный способ этот happens before
достичь.
А он достигается, когда у нас есть
атомарная запись, атомарное чтение,
и чтение видит запись, и запись она
по крайней мере с memory order release,
а чтение по крайней мере с memory order acquire.
И вот у нас есть
пара запись,
есть
чтение, и мы крутимся
мы здесь до тех пор, пока
мы не увидим эту запись.
И когда мы увидели, значит начинается
новая секция.
Поэтому мы здесь ставим release, здесь мы ставим
acquire.
Ну и опять, если мы умеем
пользоваться, если мы знаем
про таковую когделенность кашей, то мы конечно
такой спинлок не пишем, да?
Мы знаем, что
вот порядочному
джентльмену такой спинлок не подойдет,
мы пишем что-нибудь такое.
Вот.
Ну и в домашке вы пишете
фьютокс, там у вас будет спинлок,
ну вот пожалуйста, напишите спинлок
хорошо.
Потому что еще раз, в конце
концов, мы хотим все пооптимизировать.
И нам каждая деталь пригодится.
Вот если вы знаете, как хорошо написать спинлок,
то напишите его сразу.
Хорошо.
Да, и я обращаю внимание в шаблоне задачи,
я не знаю, пользуетесь вы этим или нет,
пока я не особо замечаю.
Но вот во всех задачах есть Victoria Support.
И
зачем она нужна?
Предлагается туда складывать
какие-то компоненты общие,
которые
нужны в файберах, нужны в тредпуле,
нужны еще где-то,
но которые имеют смысл более широкий.
Ну скажем, мы пишем спинлок
для фьютакса.
Очень странно класть код спинлока прямо
во фьютакс, потому что спинлок гораздо
более общий примитив, чем фьютакс, и можно
использовать в других местах.
Вот выгодно его, разумно положить его
туда. Или мы пишем
вейт-группу, ну для потоков,
для того чтобы в планировщей, в тредпуле
ее использовать. Но опять,
это примитив синхронизации, который более общий,
чем тредпул, и
вейт-группа всего лишь применяется
в тредпуле. Опять, можно вынести ее сюда,
в эту директорию.
Что значит синхронизируется? Мы просто
размещаем код в библиотеке.
Если у нас есть компонент A
и компонент B, и компонент
B зависит от компонента A,
но компонент A напрямую не связан
с B, то видимо они должны лежать в разных
местах.
Но вот спинлок используется
в файберах, но с ними
напрямую не связан.
Просто общий примитив синхронизации.
Положим его отдельно.
Вейт-группа опять используется в пуле потоков,
но прямо к пулу потоков
она не привязана,
она полезна сама по себе.
Опять можно вынести ее, положить отдельно.
Ну вот все, что вам кажется
таким более общим, можно складывать сюда.
Ладно.
Возвращаемся к
MemoryOrder.
Спинлок разобрали.
Циклический буфер
тоже в прошлый раз разобрали.
Мы упорядочиваем обращение
к буферу вот здесь вот и вот здесь вот.
И что мы делали?
Мы говорили, что у нас есть
продюсер и консюмер, два потока всего,
которые работают с этим буфером.
И продюсер
и консюмер
и продюсер
единственный поток,
который увеличивал tail,
а консюмер единственный, кто
увеличивал head, двигал head.
Увеличивать не совсем, конечно,
говорить, потому что там может все зациклиться.
В частности,
поэтому мы
использовали здесь чтение с relaxed.
Потому что каждый поток видит собственные
записи. Потому что как иначе?
Так работает однопоточная программа.
То есть мы полагались
на гарантию program order, что
чтение учитывает program order,
не противоречит ему.
Это мы понимаем, да?
А теперь вопрос чуть более сложный.
А что если два файбера,
которые исполняются на двух разных потоках,
работают с этим циклическим
буфером?
И вот вообще-то файбер может
записать в ячейку 42
в одном потоке
пула,
сделать релиз записи tail,
а потом перезапуститься
и продолжить работу на
другом потоке пула и сделать чтение
с relaxed. Вопрос.
Откуда
вот это чтение, почему это чтение
непременно увидит свежее значение
tail?
Вот relaxed сам по себе этого не обещает.
Relaxed говорит, что мы читаем просто некоторую
точку под истории.
Почему бы нам не прочесть
старое значение?
Потому что в текущем потоке мы еще ни разу
ничего не писали в tail.
Понятен вопрос?
Пока мы пользуемся гарантией,
что чтение не противоречит программу
order.
Мы читали этот tail
даже с relaxed и мы знали,
что мы увидим самую свежую запись, потому что она была
в одном же потоке. Сейчас она уже в другом потоке будет.
Как вас просто поставить в тупик?
Давайте вот как просуждаем.
У нас есть чтение
в запись в ячейку памяти, а потом есть
чтение из этой ячейки.
И как в общем случае гарантировать,
что чтение увидит запись?
Главный вопрос в модели памяти.
Но если ему в одном потоке, то он есть.
Потому что программа order это
часть happens before.
А что если вот
Fiber запустилась
в другом потоке?
Программа order там уже нет.
Программа order он внутри потока,
а мы исполнили сначала в одном, потом в другом.
Проблема понятны?
Вопрос понятен, с которым я к вам пристал?
Вопрос кто делает это?
Можно ли написать relaxed?
Это худший способ
просуждать о чём угодно.
Наш код не корректен.
Наш код корректен, когда он работает везде.
Мы же пишем не на x86, не на
Assembler x86, мы пишем на C++.
У нас корректность
понимается в смысле модели памяти языка,
а не конкретного процессора.
Ну код, давайте так,
давайте проверим вашу интуицию,
хотя бы знание мы не можем проверить пока.
Проверим интуицию.
Relax правильно написано или неправильно?
Мне кажется, нет.
Просто в этом,
в нашем тесте у нас есть вообще,
у нас есть два потока,
а если что, у нас много теперь потоков
и продюсеры переезжают
между потоками.
Ты сказал, что неправильно написано.
Есть какие-то альтернативные мнения?
Вариантов всего два.
Есть ли оппоненты?
Или все считают,
что неправильно?
Ну просто было бы
странно, что казалось бы,
потоки, ну смотрите,
как можно было бы рассуждать совсем иначе,
даже не по модели памяти.
Вот мы пишем файберы,
и для нас файберы это потоки.
Вот мы как пользователи меньше всего
хотим думать, что файберы это не потоки,
это какие-то специальные штуки.
Они только оперативные, то есть их не могут вытеснять.
Но это, в общем, единственное отличие,
на которое мы согласились.
Вот прям серьезное, единственное отличие.
Его, и его можно преодолеть было бы,
просто мы не хотим, потому что
не нужно в наших задачах.
Но в остальном
они должны быть неотличимы.
А в итоге мы говорим, что с потоками это работает,
а с файберами этого уже не работает.
Это было бы очень странно, согласись, да?
Кажется, что у нас какая-то плохая...
Что?
Ну мы же разбирались в прошлый раз.
У нас есть программ-ордер.
Нет, у нас сама структура для двух потоков.
Один продюсер, один консюмер.
Два потока всего работает.
Только один пишет, только один читает.
Ну иначе как мы можем двигать tail
без синхронизации просто сторон?
Это работает, потому что только один поток
двигает tail.
Вот, теперь мы меняем два потока на два файбера,
и внезапно мы говорим, что вот
поведение вдруг изменилось.
В смысле, было корректно, а стало некорректно.
Нет, я не это не ожидал.
Ты говорил, что и с самого начала было некорректно.
Нет, когда одна пара, все хорошо.
Я думаю, когда несколько пар...
Так когда несколько пар, нужно код по-другому писать вообще?
Нет, этот код и не должен работать
для большего числа потоков.
Это же сингл-продюсер, сингл-консюмер.
У любой очереди есть ограничения,
в каком режиме она работает.
Мы писали в Тредпуле блокирующую очередь,
и прямо на лекции вам не просто так распинался минуту,
что мульти-продюсер, мульти-консюмер.
То есть мы закладываем в очередь
такой сценарий. В смысле, что вот может быть много потоков, которые пишут,
много потоков, которые читают.
Здесь у нас всего два потока. Мы ограничились,
и вот иначе не предполагаем.
Ну, а теперь мы меняем эти потоки
на файбера.
И теперь вот как бы файберов два по-прежнему,
один пишет, другой читает,
но файбер запускается на разных поток.
И ты в этот случай
что говоришь, что правильно релакс стоит или неправильно?
Да, то неправильно.
Тоже правильно. А почему?
Потому что, ну, можно же пользоваться тем,
что потоки...
На потоках это работало.
Ну, потоков работало,
но мы пользовались гарантией
ProgramOrder, а теперь у нас ее нет.
Так.
То есть на потоках
у нас была гарантия...
Ну, еще раз.
Ну, она же для потоков определена,
если ProgramOrder говорит порядок
обращения к ячеекам памяти
в тексте программы
в одном потоке.
Вот это отношение
на операциях в одном потоке.
И компилятор, и процессор
действия одного потока уважают.
Мы читаем,
по крайней мере, последнюю запись в том же потоке.
А других записей из других потоков
в Тейлы не бывает.
Поэтому релакса здесь достаточно, пока мы на потоках.
А на файберах... Ну, давайте кто-нибудь другой
что-нибудь скажите.
Про что ты считаешь?
Не знаю, мне кажется, все нормально.
Все нормально.
Внутри потока есть отношение к проблему,
значит, внутри файбера будет...
Почему внутри файбера будет?
Внутри файбера будет то, что мы...
Внутри потока не все у нас...
Ну, у нас разные потоки. Теперь файбер запустился на одном потоке,
а потом на другом потоке. Он на одном потоке записал
в TailStore, а потом
перезапустился на другом потоке и там
прочитал TailRelax, LoadRelax.
И вот между этим Storm
и этим Load отношения
Program Order уже нет.
Это же разные потоки. Обращение к памяти
из двух разных потоков.
Program Order больше нет.
Он внутри одного потока.
Лечей к памяти одно и то же.
Лечей к памяти одно и то же.
Ну, смотрите,
вопрос очень простой, мы чего-то совсем
не понимаем.
Вот были мы файбер, да?
И мы исполнялись вот...
Значит, FiberProducer.
Его жизнь.
Вот был поток T1.
Он там исполнялся.
Он там делал TryProduce.
То есть, он внутри
записал в буфер
в позиции 42
свой X, а потом
на потоке T1 все еще
записал в Tail 43.
А потом
что-то случилось,
и вот он уже на потоке T2, T3,
и он говорит
TryProduce.
И он здесь сначала
читает
Tail с Relaxed.
Мы спрашиваем, почему он, собственно,
прочтет актуальное значение Tail?
Потому что если прочтет ставое значение Tail, то все, беда.
Он перезапишет буфер там, не в том месте.
Ну вот, если бы
между этой записью и этим чтением было бы
HappensBefore, то все было бы хорошо, да?
Давайте раскроем многоточие.
Fiber сделал
Produce.
Что он сделал?
Ну он сделал Suspend, видимо.
Он остановился.
А что он сделал после Suspenda?
Ну, допустим, он Yield
сделал. Сделал Produce, потом Yield.
Что в этом Yieldе
случилось?
Мы сначала сделали Suspend.
А потом что мы сделали?
Это через Suspend?
Ну, это и был Suspend.
А, вот так.
Но мы все еще...
Мы специально сферировали,
но пересланируясь.
Ну, не знаю, что именно такое, да?
А теперь,
спустя какое-то время...
Ну, то есть, а вот что произошло внутри
этого сагмита?
Вот так, да?
А здесь
Threadpool Worker Routing
Suspend вызвал
tasks
get
и
запустил таск.
Но мы же с вами, представляете, блокирующую очередь.
Мы там берем
Mutex, пишем.
Потом берем Mutex, читаем.
А Mutex там уже дает happens before
между секциями.
Так что у нас вот между этим Mutex
и Mutex есть happens before.
И вот это синхронизация
в планировщике, она и протянула
нам happens before
вот в это чтение.
Поэтому мы вот в этом чтении
в relaxed непременно увидим вот эту запись.
Ну как, сошлось?
Вот такой был несложный вопрос.
Просто у нас синхронизация обеспечивается
из-за примитива и синхронизации.
Ну то есть у нас happens before
получается, когда мы читаем
там пишем в атоме, потом читаем из него
и вот получаем транзитивность.
Ну а также мы получаем
мы протягиваем happens before
через все примитивы дальше.
Сделали Mutex, он тоже нам дает вот этот
синхронизация with happens before.
Сделали очередь, она тоже дает нам
синхронизацию между потоками.
Вот это мы и понимаем, потоки синхронизировались.
Получился happens before.
Ну у тебя же здесь Mutex есть.
Пойдем еще глубже.
Здесь мы
положили в
ну я какой-то псевдокат пишу,
не обращайте внимания.
Вот, а здесь мы внутри
гета в
Т3 взяли
Mutex log и
здесь увидели в
увидели здесь нашу таску.
Ну и вот эта критическая секция
она нам дала happens before.
Мы собственно в спинлоке
его сделали, а Mutex тоже с нами.
У нас Mutex
отличался от спинлока только тем, что мы
добавили ожидания с помощью
фьютекса.
Ну это посторонний вообще момент сейчас.
Ну что, точно
разобрались?
То есть у нас любую примитив синхронизации,
которая построена на Mutex,
уж точно, будет
давать happens before.
Будет через себя передавать его.
Поэтому если мы пишем что-то
в память, потом кладем значение
в очередь, а потом из очереди
это значение достаем,
ты уверен, что мы можем прочитать то,
что было сделано до пута.
Ну и так с любым примитивом синхронизации,
который мы напишем.
С кондварами тоже самое. Все, что было до
notify, будет видно после вейта.
Все, что сделано было до
онлока, будет видно после лока.
Собственно,
это же такая базовая гарантия примитива
синхронизации, которыми
мы пользуемся.
Вот мы ими пользуемся этими гарантиями,
потому что вот на уровне модели памяти они так достигаются.
Окей,
разобрались.
Давайте перейдем
к темным местам модели памяти
и поговорим про
такой пример.
Итак,
у нас есть
вот такая штука LazyValue
называется.
LazyValue это контейнер
для значения, который
для некоторого объекта,
типа t, который лениво
инициализируется.
Вот мы в
конструктор придаем функцию,
которая строит,
странно, что она на куче строит,
но бог с ней,
строит на куче объект, типа t.
И у этого объекта
есть единственный метод
access,
который возвращает ссылку на t.
Но вот если t еще не
сконструирован, то нужно его сконструировать.
Если t уже сконструирован,
просто вернуть ссылку на него.
Вот здесь происходит ленивое конструирование.
Каким образом?
Вот в этом pointer будет
храниться указатель на сконструированный объект.
Поначалу там
pointer, то есть объект пока не сконструирован.
И вот мы приходим в access,
читаем этот pointer.
Если мы видим, что там null,
то значит объект не сконструирован еще.
Мы первые, кто к нему пришли.
Поэтому нужно сконструировать.
Нужно позвать функцию create
и сохранить
результат в pointer.
Но что если
пришли два потока,
увидели
в value pointer null,
оба поняли, что объект еще не сконструирован,
и поэтому
решили оба сконструировать его.
Получится между ними гонка.
Поэтому мы берем mutex
и еще раз
проверяем, сконструирован ли объект.
И вот если два потока решили
разом сконструировать объект,
то тот, кто возьмет mutex первым
и перепроверит value pointer,
он сконструирует объект.
А поток,
который придет вторым,
он увидит уже. То есть он сначала подумал,
что объект не сконструирован, потом взял mutex,
но пока он его дожидался, объект уже сконструировали.
И он это проверит и
передумает и не будет
сконструировать во второй раз.
Вот этот паттерн называется
double-checked-locking. То есть мы сначала
проверяем предикат. Если он не выполнен,
то мы берем блокировку и еще раз
проверяем предикат.
Потому что объект инициализируется один раз,
а потом 150 миллионов раз к нему обращаются.
Зачем нам
150 раз
брать блокировку, когда нам нужно
в первый раз?
Вот и вопрос. Какие memory-orders нам
здесь нужно расставить?
А чтобы на этот вопрос ответить, нам нужно
как обычно рассуждать, а какие
неатомарные обращения к памяти
мы хотим упорядочить?
Для начала
первое, что хочется сказать,
если кто-то объект сконструировал,
то все остальные об этом должны знать.
То есть, если мы к объекту
обращаемся, то он уже сконструирован.
Твои слова
переформулировал более аккуратно.
Стой, еще раз.
Неатомарные обращения к памяти – это
неатомарные обращения к этому объекту T.
И вот мы хотим упорядочить
конструирование объекта T и обращение
к нему.
Конструирование происходит здесь.
Обращение
происходит
снаружи
этого аксесса.
Давайте подумаем,
как упорядочить
конструирование
и обращение.
Вот пришел какой-то поток,
он зашел в аксесс, прочел поинт,
увидел там не ну, и все.
Получилась ссылка на объект.
Может теперь по ней читать память?
Теперь смотри.
Мы разобрались, какие неатомарные
обращения к памяти мы хотим упорядочить.
Между ними нужно сделать
HappensBefore.
HappensBefore через какую
ячейку в итоге попадет
в поток, который
обращается к объекту?
Ячейка, перегращая
под VaryPointer.
Мы, читая VaryPointer, если мы
здесь увидим не ну, то мы должны
увидеть и в объекте
инициализированный объект.
То есть мы по содержимому VaryPointer
должны...
По содержимому VaryPointer
мы делаем вывод
о содержимом
памяти под объект T.
Вот причинность.
Нужен HappensBefore.
Значит, видимо, нужно здесь написать что?
А релиз мы где напишем?
Вот, если мы
прочитали, здесь
не NullPointer, то, видимо, здесь
его записали, а значит, мы прочитали
запись, которая была сделана здесь в этом чтении,
значит, возник Synchronize the Swiss по определению,
а значит, между вот этой строчкой
и обращением после Access
будет HappensBefore.
Это правда все.
А что мы скажем про этот MemoryOrder?
Вот, у нас два потока. Увидели NullPointer,
решили зайти и оба
инициализировать объект.
И поток, который сделал, взял
меток с первым, он объекты сконструировал,
записал VaryPointer
в Pointer с релизом
и ушел. Потом появляется второй поток,
и этот VaryPointer
читает и видит там не Null.
Он видит там
не Null, а значит,
будет, а значит, вот прямо
прочитанное значение пользователю и отдаст
этот адрес.
И пользователь
будет по нему читать.
Это означает, что снова между этим чтением
и вот, ну,
это чтение должно с чем-то синхронизироваться.
Ну вот, оно должно увидеть этот Store.
Ну вот, тут мы воспользуемся тем, что вот этот Store,
предшествующий этот Load,
они случились в одной критической секции.
А на критических секциях у нас уже есть
HappensBefore.
Поэтому здесь достаточно написать
std MemoryOrder
Relaxed. То есть мы
здесь получаем HappensBefore,
но не сами его строим, а мы пользуемся
тем, что в Mute-оксе оно будет между
Lock'ом и Lock'ом. То есть между Unlock'ом
первой секции и Lock'ом вот второй секции.
Хорошо.
А теперь, теперь...
Смотрите, какие
пироги.
Нет, это работает.
Это работает, и
ну, оказывается,
Modern Memory TC++
позволяет нам сделать немного
максимальный...
Вообще, то, что я расскажу сейчас,
об этом лучше и не знать.
То есть можно прожить счастливую жизнь и не знать об этом.
Но, поскольку
MemoryOrder C++ есть, я чувствую,
что мой долг прокомментировать.
У нас отворился интернет.
А нет, не отворился,
а я его сбросил.
Потерпим.
Вот. Мы воспользовались...
Смотрите, мы пользовались уже Relaxed,
мы пользовались Sequential Consistency,
мы пользовались Release Acquire, есть еще Consume и
Acquire Release.
На Acquire Release, наверное, сегодня не хватит,
а вот про Consume мы сейчас поговорим.
Смотрите, были два потока.
Поток Producer
и поток Consumer.
Что сделал Producer?
Он сконструировал
объект в памяти
и
а потом
он
записал
вот этот ValuePointer.
Это называлось здесь CarPTR.
Давайте так и напишем.
Consumer
он этот
ValuePointer прочел
а потом
он получил ссылку
на объект, а дальше
поэтому CarPtr
пошел и вызвал
этот фу какой-то на объекте.
Так вот.
Помните, я в прошлый раз вам объяснял, почему
мы пишем Release Acquire?
У нас причинности есть, да?
Вот мы
здесь читаем, идем по стрелочке
и вызываем Full, потому что
мы здесь увидели не NullPointer, значит вот здесь
записали, значит уже объект сконструировали.
Но есть некоторые отличия
между вот таким кодом
и вот таким кодом, когда мы пишем
в X, пишем
в Y, а потом
если в Y единица, то
читаем из X
и непременно видим в нем тоже единицу.
Вот этот пример, он отличается от этого примера.
Почему?
Первая половина, вот эта, скорее
не отличается. Тут мы пишем в одну
память, потом пишем в другую ячейку.
Какие-то две записи.
А вот эта половина
отличается.
Вот здесь мы ставили, помните,
Release запись, а здесь Acquire
Чтение.
И запрещали как будто бы переупорядочить вот эту
запись с этим чтением.
Ошибся.
Release это был такой односторонний барьер,
который запрещал переупорядочить вот
эту запись с этой записью.
Двинуть ее вниз.
А Acquire был односторонний барьер,
который запрещал двигать это чтение
выше.
Ну, это такая была грубая
семантика, я примерно объяснял, почему она
нужна, потому что здесь StoreBuffer,
здесь InvalidationQueue, помните, такое
было.
С этим кодом не так,
но здесь Release нужен.
А здесь разве может
процессор переставить вот это
чтение и вот это чтение?
Ну, смотрите, что происходит.
Мы в Consumer
сначала читаем
в регистр
некоторые значения,
ну, некоторый адрес
из памяти,
а потом мы
читаем...
Вот сейчас давайте я напишу на каком-то
условном ассемблере.
У нас была
переменная, в которой был написан адрес, мы по нему
прочитали что-то.
А потом мы читаем
вот по тому адресу,
который мы прочли здесь.
Да?
То есть мы прочли pointer,
а потом по pointer
снова читаем.
Схватили, да, что происходит?
То есть у нас была одна ячейка, там был
написан адрес, мы ее прочли в регистр,
а потом этот регистр подставили
как адрес в следующем чтении.
Процессор...
Вот как может
процессор два этих обращения
преордерить?
Ну, у нас второе обращение зависит от первого.
У нас входной
аргумент для второй инструкции
это выход первой инструкции.
Между ними есть зависимость по данным.
Data dependency.
Согласны?
Почему тогда
нам здесь нельзя написать
просто relax?
Ну, просто не должно быть
процессора, который возьмет
и что-то тут натворит.
Ну, короче, здесь acquire выглядит
избыточным, потому что
не должен процессор это преордерить.
Вот. Но, к сожалению, relax
писать нельзя, потому что есть
процессор, который называется alpha.
Вот есть некоторый процессор, который
все-таки делает что-то странное.
Он никому не нужен.
Но
поскольку он есть
и в нем
поведение будет отличаться
от relax-то формально,
в C++ выдумали новый
memory-order, он называется
consume.
И вот этот consume – это альтернатива
acquire, когда мы читаем поинтеры.
Вот если мы читаем поинтер,
а потом читаем по поинтеру,
то вот тут вместо acquire
со стороны, когда мы делаем
happens before,
со стороны получателя данных
можно сделать consume
поинтера, а потом
по поинтеру прочесть
и будет
видимость записей в чтении.
Но
если мы напишем вот такой код
и если мы напишем, я не знаю,
давайте вот вставим сюда,
давайте в псевдокоде лучше вставим,
вставим сюда просто запись, не знаю,
ячейка X,
записали один,
а здесь мы из X прочитали.
Вот здесь мы увидим
эту память,
а вот этого
X мы уже не обязаны
увидеть. Почему?
Потому что
модерипамяти C++ странная.
И вот тут
я не помню, показывал ли я вам на лекции,
там точно был слайд,
я
говорил вам, что вот есть определение
happens before,
вот такое транзитивное
замыкание просто.
И в модерипамяти Java так и есть.
У нас есть happens before,
когда в программ-ордере есть порядок,
у нас есть happens before, когда синхронизуется Swiss,
и у нас есть транзитивное замыкание.
А в C++
у нас много happens before,
и определение
выглядит вообще-то жутковато.
Оно выглядит как?
Что A happens before B,
если A sequences before,
это программ-ордер на C++
так называется,
или A intsthread happens before.
А intsthread happens before это еще
сложнейшая штука, с каким-либо длинным
комментарием.
Зато есть,
смотрите,
есть другой мемориордер,
simply happens before.
И вот simply happens before это то, что мы и ожидали.
Это когда A sequences before B,
или A synchronizes with B,
или транзитивное замыкание.
И говорится, что если бы не consume,
то happens before
и simply happens before были бы одним и тем же.
Поэтому
мораль такая прикладная.
Во-первых,
не пишите consume никогда.
Во-вторых, если вы не пишете
consume никогда, то для вас
различия настоящего
happens before C++ и вот этого упрощенного
нет. Вы разницы не чувствуете.
Это вот еще одна причина
не писать consume. Он не нужен никому
кроме альфы. Альфа никому не нужна, то есть он никому
не нужен просто.
В общем,
и если вы этим consume
не злоупотребляете нигде,
то получается, что
для вас happens before становится
сильно проще. А в C++
он такой сложный просто потому, что
happens before в C++
строго говоря, нетранзитивный.
Потому что когда вы пишете
здесь
store с релизом,
а здесь load с consume,
то формально тут возникает
не synchronizes with.
Тут возникает отношение, которое называется
Kareous
dependency
ordered before.
То есть это такой специальный случай,
что у вас есть зависимость по данным.
А когда вы читаете поинтер, а потом
читаете данные по поинтеру,
это называется
Kareous dependency.
Вот, и
формально у вас есть
happens before
между
этой записью
сюда,
потом сюда, потом
в чтение.
Но
к этому happens before
нельзя прилепить еще
один шаг.
Вот нельзя к концу
happens before в C++
в случае
прилепить еще один шаг
sequence before.
Потому что
не знаю, что сказать.
Когда-то
какая-то светлая голова решила, что раз есть
какой-то маргинальный процессор,
и под него можно пооптимизировать еще больше код,
то давайте так и сделаем
и введем memory order consume.
И из-за него модель памяти дико усложняется.
Кажется,
консенсус такой, что это была очень плохая идея,
это была ошибка, но отменить уже
ничего нельзя.
Если мы посмотрим на какую-то разумную библиотеку,
вот
я на лекции про фьючи не помню,
показывал вам ее или нет.
Вообще-то хорошо, чтобы показывал вот
о фолле библиотека общих компонентов Фейсбука.
И
вот там есть
экзекьюторы,
там есть фьючи,
файберы.
Короче, вот большая библиотека
общих компонентов, на которой Фейсбук пишет
свой сервис.
И
давайте посмотрим
memory order
aquaio. Встречается ли там?
Кажется,
встречается и часто.
Где-то его используют.
А что
по поводу memory order consume?
Вот
хотя бы так.
Можно по-разному
его немного писать.
Нет, это другие
consume.
Можно еще там memory order вот так
бывает.
Короче, нет там consume,
потому что...
А нет, я видимо опечатался где-то.
В каких-то маргинальных тестах есть,
он видимо игнорируется.
Да, он нигде
не используется.
О чем он нам говорит?
Что он не нужен?
Вот объективная реальность указывает
нам на то, что он не нужен.
Вот где-то
ну вот,
заменили везде на aquaio.
В будущем, смотри,
жизнь устроена не так.
У тебя есть вот какой-то странный частный случай,
который нарушает общий формализм.
Вот идея такая,
что не то, чтобы процессоры
творят что угодно,
а академики, которые проектируют
внутри памяти, под это подстраиваются.
Это как бы взаимодействие.
Ну, это смысл.
В общем,
я думаю, что
у нас есть такой
это сотрудничество.
Производители процессоров
тоже были заинтересованы в том,
чтобы программы на их процессорах
вели себя разумно.
Поэтому они сотрудничают,
и никто не станет делать новый процессор,
который не вписывается в декларативную модель.
Потому что декларативная модель отвечает
просто здравым каким-то разумным гарантиям.
Короче, в общем,
не нужно делать странные процессоры,
и тогда формализм будет работать,
потому что формализм, он просто фиксирует
Ну, то есть, да, в теории есть
такой странный частный случай,
но можно себе представить процессор,
можно себе представить, что да, здесь
две разные ячейки памяти, а здесь
все-таки зависимость по данным,
и процессор мог бы вести себя
немного по-разному.
Но вот
попытка это использовать
закончилась плохо.
И поэтому модель памяти C++
очень сложна, и поэтому
мы на лекциях разбираем
некоторые упрощения к ней,
то есть, то, что я рассказываю на лекциях,
оно мачится в C++,
но только в том случае, когда вы
откажетесь
от консюма в своих программах.
Ну, и не просто так
модель памяти
я не здесь,
нужно идти в стандарт.
Я не знаю, почему они депрекейтят,
в C++ очень сложно
запретить в обратную сторону.
Ну, как запретить?
В обратную сторону.
Программы есть,
существуют процессоры, на которых
программа может работать оптимальнее,
поэтому мы не можем запретить
сказать, что теперь ваша программа
замедлится, потому что мы завершили ошибку.
Уже кажется поздней.
Не знаю. Ну, в общем, закончу мысль,
что сам стандарт вам говорит,
что
модель памяти Happens Before
сложная, но если вы
откажетесь от консюма,
то вы можете думать про Happens Before
как про простой транзитивный порядок.
Это, кстати, большая проблема,
скорее формальная, чем практическая.
Ну, вот представьте,
с одной стороны,
Happens Before не транзитивный,
строго говоря, потому что здесь
Happens Before есть, между этим строчкой
и этой,
но к нему еще один шаг добавить
нельзя. А теперь
вернемся к примеру про циклический буфер,
я вам показываю код и говорю,
ну, у нас же есть очередь, а значит Happens Before
надает. Мы положили
X, достали X, значит есть Happens Before.
Но если Happens Before
не транзитивный, то толку с этой гарантии.
Поэтому нетранзитивность
формальная Happens Before,
это, вообще говоря, проблема для модели памяти C++,
и там ее как-то тоже
костырит. Но если вы консюм нигде
не используете, то у вас Happens Before все-таки
не транзитивный, и тогда
такими гарантиями уже можно
пользоваться.
Так что
мое предложение, забудьте
про консюм, не пользуйтесь им,
просто знайте, что это была
неудачная перфоманс-оптимизация, которая
завершилась очень неприятными
последствиями для
формализма.
Такое бывает.
Кажется, что большинство
компиляторов не будут различать
Consume и Acquire, то есть
нормальный компилятор, если он не хочет проблем,
он просто...
Скорее всего, в реализации любого компилятора
Consume и Acquire будут
одними и теми же инструкциями.
Так что вы на разумной архитектуре
выигрыша никакого не получите, зато
гарантии формально из себя ослабить.
Ладно, в общем, забудьте про это, если вы можете.
Если знаете, что...
Плохая идея. Итого, мы, значит,
для Relaxed мы использовали
Acquire, Reiss, Consume даже
и поиспользовали. То есть это некоторое ослабление
для Acquire.
Остался еще этот Memory Order.
Вот про него мы тогда
уже в следующий раз поговорим.
Будет повод, поговорим.
Повод, кстати, есть. Хорошее решение
Weight-группы использует его.
В задаче Mutex вас просят, напишите
хорошую Weight-группу.
Хорошую, это такую, которая
вызывает эды и данные,
то есть плюс и минус
просто с помощью
атомарного инкремента-декремента.
Там никаких Mutex хватает
постоянно.
Просто тут написано будет Fitch-add,
а тут почти всегда Fitch-sub.
И вот с такой реализацией, если ставить
Memory Order, то можно их...
То оптимальные Memory Order, они там будут
нетривиальные, вы их ставить не умеете
пока.
Но если вы можете их ставить, то
не умеете пока.
Но правильное решение будет использовать
Aquarelease.
Ну что ж, на сегодня все тогда?
Спасибо.
Какой у нас на сегодня план?
Я хотел бы
продолжить разговор про слабые модели
памяти. В прошлый раз мы разобрали
Spinlock, мы разобрали циклический
буфер. И не просто так,
потому что нам потребуется в субботу
на рекции про планировщик.
Там мы использовали
Aquarelease.
Немного научились
рассуждать о том, как именно
Memory Order выставлять,
руководствуясь какими соображениями.
Мы каждый раз... Что делали?
Давайте откроем
примеры и
напомню.
Мы каждый раз руководствовались
такими соображениями. Нужно найти
в программе неатомарные обращения
к памяти, которые мы собираемся упорядочивать
с помощью Memory Order на атомиках.
Вот это мы сегодня сделаем,
но перед этим может быть
у вас есть какие-то собственные вопросы
про домашние работы, про то,
что вообще в курсе происходит, куда мы идем,
зачем мы туда идем, куда мы
хотим попасть.
Я бы сказал, что задача про него.
Если задача...
То, что в шаблоне есть,
там действительно некоторые подсказки
к хорошему решению. Давайте я
поясню, в чем вообще
глобальный смысл происходящего.
Смысл начинается
в том, что мы
делали в шаблоне.
Смысл начинается
где-то давным-давно в задачах про корутины.
Вот про что эта задача была?
Про то, чтобы написать файберы, которые умели
только yield. И как мы
в этой задачи писали yield?
У нас был файбер,
в нем была корутина, она исполняла
какой-то...
иначе.
Был файбер,
в нем была корутина, которая
исполняла код пользователя.
И когда это...
и когда файбер делал yield, он должен был
остановиться
и запустить...
Этот файбер, это была цепочка
таких вот ходов.
Ход, который завершается либо yield, либо завершением
файбера. И вот, по сути, в третпуле
исполнялась цепочка таких задач.
И метод yield, он останавливал
текущую корутину, завершал текущую задачу.
Но перед тем, как задача
совсем может завершиться, мы планировали
продолжение файбера, бросали
третпул с помощью submit следующую задачу,
которая возобновляла корутину,
и файбер бежал с того места, где он остановился,
в yield.
Где был реализован yield? Ну, он был реализован,
вероятно, у вас в ходе прямо в теле
файбера.
Был какой-то метод, который представлял собой
задачу.
И вот в этом методе вы резюмили
корутину, файбер делал шаг,
корутина останавливалась, а дальше вы разбирались,
почему он остановился, этот файбер.
Либо потому, что просто корутина
завершилась, то есть файбер подошел к концу,
либо методом исключения,
вы решали, что если
файбер, если корутина еще готова исполняться, значит,
это был yield. И бросали
в третпул новую задачу.
Для вот
этой задачи такое решение,
оно сойдет.
Но дальше
мы делали задачу strip4.
И в задаче strip4,
где же она?
Здесь ниже. Мы
немного
усложняли файбер, мы говорили, что давайте
добавим к ним еще одну операцию,
которая будет
реализовывать блокирующие файбер
ожидания через
подписку на таймер.
Мы в методе
function strip4
файберный, вот здесь
конституировали таймер
и подвешивали к нему callback,
в котором этот файбер
возобновлялся.
После этого останавливались.
Точнее, не так, чтобы сначала подписывались
на таймер, потом останавливались, потому что
это была бы гонка, и в эту проблему задачи должны
были решить. Как упорядочить возобновление
файбера и установку файбера.
Но смысл был примерно такой.
Вам нужно было подписаться
на, повесить на таймер
обработчик и пробудиться
в этом обработчике и заснуть.
После того, как вы...
И в каком порядке
неважно сейчас заснуть.
Завершите текущую задачу
остановить текущий шаг карутина.
Завершите текущий шаг карутина.
А дальше вы крутитесь в event loop
и event loop решает, что таймер
готов.
Timeout истек,
таймер сработал, callback запустился
и запускают вашего обработчика,
в нем запускается карутина и файбер
продолжает бежать.
То есть, на первый взгляд задача
про то, чтобы
обработать просто события
в файберах, внешние события,
таймеры, вот вывод, что угодно.
Но вместе с тем
в эту задачу просят вас
пожалуйста, напишите код так,
чтобы вот это знание
про таймеры и сама реализация
slip4, сама логика slip4,
она, по возможности, не просачивалась
в сам файбер.
Но пусть все, что касается slip4
остается функцией slip4.
Почему?
Ну, потому что, видимо,
можно придумывать себе другие примеры,
там, не знаю, мы сокеты
хотим сделать, мы мьютексы хотим сделать,
мы кундвары хотим сделать, мы каналы хотим
сделать. И для всего этого тоже требуется
какая-то поддержка, и было бы
очень неудобно каждый раз менять
вот прямо сам класс файбер
для того, чтобы новый примитив поддержать.
Вот к такому выводу вас приводит
эта задача.
А текущая задача мьютекс, она вот доводит
этот вот мысль до конца.
Там говорится, что
ну, опять, сначала сделайте
что-то такое кастомное.
Вам нужно сделать примитивы синхронизации,
они все реализуются через фьютекс,
поэтому как-нибудь сделайте фьютекс.
Вот вы как-нибудь
фьютекс делаете, и вот снова та же проблема.
Вы как-то закастырили еще один примитив.
А теперь у вас, кажется, есть
ну, некоторый опыт наблюдений
за вашей реализацией, за эволюцией
вашей реализации. У вас был slip4,
у вас есть фьютекс,
и можно себе представить сразу много
других примеров.
Вот о чем slip4 и о чем
фьютекс? Они
оба этих применения, они
про одну и ту же общую задачу.
У вас есть файбер, он работает, работает, работает,
а потом он хочет чего-то дождаться.
Там
пройденного времени,
данных из сокета, но
сокетов не было пока,
пройденного времени или
это сигнала
к пробуждению от другого файбера.
Реализованы это
совершенно по-разному.
В одном случае мы подписываемся на таймер,
там крузим какой-то event loop.
В случае с фьютексом
запланировать пробуждение файбера
это значит положить себя в очередь.
А потом другой
файбер достанет, нас разбудит.
То есть на уровне реализации все это очень
по-разному выглядит. Но суть одна и та же.
Мы хотим остановиться
и запланировать свое возобновление.
А дальше можно представить себе
очень много сценариев, где нам
нужно это сделать каждый раз по-своему,
но в принципе
сделать те же самые шаги.
Вот фьютекс и
вот этот метод park.
Yield.
Вот тоже, это же по сути
остановиться и запланировать возобновление.
Запланировать когда? Сразу же,
моментально, ничего не дожидаясь.
В принципе тоже вкладывается,
вписывается в эту общую задачу.
Следующая. У нас
были future. Future, я напомню, это
представление
для будущего значения.
Ну вот, я рефактор и код и делаю это не аккуратно.
А, это не здесь нужно искать.
Не искать здесь.
Да, у нас есть некоторое future.
В данном случае это timeout.
То есть future, которое наполнится пустым
значением void.
Ну не пустым значением void, это вообще
тип без значений.
Ну в общем future, которое заполнится через там 250
миллисекунд. А потом я могу
заблокировать fiber до тех пор, пока
в future не появится значение.
Вот опять,
как я хочу это
сделать? Видимо у future,
если вы помните на лекции,
у них был метод, который назывался
future уже.
Subscribe.
Сейчас я про это расскажу.
Subscribe, который позволял подписаться
на...
Нам кажется,
не хватает заголовка thread.
У future был subscribe,
который позволял подписаться,
поместить callback,
который вызовется, когда
в future появится значение.
И вот опять, как сделать синхронное
ожидание future?
Повесить на него callback, что когда future выполнится,
то нужно нас разбудить,
а самим остановиться.
Ну, селект на каналах,
которых мы еще не писали...
Знаете, что такое селект?
Я столько раз про него
говорил, и вы...
В канале было
на первой неделе сообщение,
изучите язык ГО немножко,
почитайте про него, чтобы было понятно,
что мы делаем.
Вот, два канала,
две грутины пишут,
отправляют сообщение в эти каналы,
третья грутина ждет этих сообщений,
и вот с помощью конструкции селект
блокируется до тех пор, пока сообщение
появится либо здесь, либо здесь.
То есть такое блокирующее,
мультиплексированное ожидание.
Ну, как вот, не знаю,
как селект на сокетах,
только на превратилосинхронизации.
В общем, во всех этих сценариях
возникает...
Во всех этих примерах возникает одна общая задача
остановиться и подписаться
на возобновление
по какому-то правилу.
В yield одно правило, во futhex другое правило,
в future третье правило, в селекте четвертое правило.
Было бы, наверное,
очень странно,
если бы появление
каждой очередной
такой задачи,
каждой очередной функциональности
потребовало бы
от нас переписывать код файберов.
Вот прямо лезть в структуру файбер,
добавлять еще какие-то условия.
Вот файбер знает про таймеры,
знает про futhex,
знает про future, знает про селект,
он с ума сойдет.
Это, во-первых, было бы очень сложно,
а во-вторых, это было бы не расширяемо.
Вот представьте себе,
вы написали библиотеку файберов
и отдали ее пользователям,
а пользователь захотел свой примитив написать.
Или у него есть свои future,
и он хочет файберы подружить со своими futureми,
их дожидаться.
А как он это сделает,
если у него нет доступа к вашей
реализации файберов,
он просто ее использует,
он не хочет форкать вашу библиотеку,
у него есть какой-то инструмент,
который позволит
файберам взаимодействовать,
с помощью которого
он выразит свою задачу.
Вот он хочет новой примитив синхронизации,
он написал RVLog.
И вот он пользуется некоторым инструментом,
который позволяет ему реализовать
блокирующие ожидания для RVLog,
или для future,
или для еще чего-нибудь,
что он захочет написать.
То есть нам нужен инструмент,
который позволяет расширять функциональность файберов
без необходимости
менять собственно реализацию файберов.
Но в условии явно написано,
что нужно сделать,
чтобы кастомизировать поведение
этого самого suspenda,
предлагается самому пользователю
писать просто стратегию,
которая определяет
для конкретного примитива синхронизации
или для конкретной реализации,
когда файбер нужно возобновить.
По таймеру, моментально,
когда достанут из очереди.
Любая логика должна быть
выражена не внутри файбера,
а в самой операции Yield,
в самой операции Slip,
в самом Utox, в самом Utox,
в самом канале.
Поэтому мы хотим,
чтобы из файберов это все унеслось,
а в файберах остались
авейторы, стратегия
и некоторые файбер-хэндл,
который это такой технический момент,
потому что все-таки пользователь,
когда он
пишет свой примитив синхронизации,
он же должен в конечном итоге
файбер будить.
Но он не хочет, точнее мы не хотим,
как разработчики файберов, чтобы
в него попадали прямо детали реализации,
то есть сам класс файбер.
Поэтому пользователь пишет стратегию,
как именно он файбер собирается
разбудить, а сам файбер
в его стратегию попадает
в остановленном виде,
во-первых, а во-вторых,
в виде файбер-хэндл.
То есть такой непрозрачный поинтер,
вот здесь реализация
файбера не торчит в пользователя,
здесь никакого инклуда файбера нет и не должно быть.
Пользующийся файбер-хэндл, он его
использует. То есть код Flutex
не знает про структуру файбера,
про класс файбер.
Flutex реализован с помощью
использования файбер-хэндл.
Ну, а причем тут овейтеры
и как это все написать
хорошо, это же
задачи про это и есть.
То есть она на первом уровне про реализацию
Flutex, что сама по себе полезно,
а во-вторых, она про то, чтобы
придумать, как должен
выглядеть вот такой вот хороший,
расширяемый, кастомизируемый дизайн.
Вот вы это попробуйте сделать,
сделайте так хорошо, как вы можете,
а по задумке
мы через неделю встретимся,
у вас там уже пройдет дедлайн
и вы расскажете,
что у вас получилось.
Мы прямо вот здесь поговорим на паре,
потому что вопрос сложный,
то есть хороший дизайн придумать сложно
и
он должен получиться хорошим.
И смотрите, какая история.
Вот этот дизайн, который мы придумываем
здесь, он не просто
какое-то решение,
это дизайн,
который в конечном итоге
использует
корутины C++.
Вот через
две недели,
то есть не в эту субботу, а в следующую
субботу у нас будет
лекция, возможно опять двойная,
потому что там нужно за раз
многое рассказать про корутины,
про очень важный механизм
асинхронности конкуренции
в C++.
И вот эти корутины,
это максимально общий,
максимально абстрактный инструмент,
это некоторая компираторная языковая фича
без конкретной семантики.
То есть корутины C++ не знают,
что их собираются использовать для асинхронности.
Они хоть и называются коэвейтны,
то есть как будто бы
остановиться и дождаться чего-то,
но на самом деле у корутины
такой семантики нет.
Семантику определяете
только вы.
Семантику определяете с помощью
авейтеров. То есть тот дизайн,
который будет в корутинах на лекции,
это тот дизайн, который придумываем сейчас вы,
сейчас мы. Если мы его придумаем,
то вот мы поймем, как корутины работают.
Причем,
в чем разница?
Почему мы делаем это, а не просто изучаем корутины?
Потому что в корутинах этот дизайн,
все это работает на уровне компилятора,
мы не можем это увидеть.
А на файберах мы можем это руками написать.
Но идея абсолютно одна и та же.
Так что мы попытаемся придумать
хороший дизайн. Получится у нас или нет
непонятно, но вот то, что мы придумаем,
мы обсудим на следующем занятии.
Поэтому я вас очень прошу как-то
постараться. То есть мало просто решить задачу.
Если вы просто решите эту задачу, но не придумаете
хороший авейтер, не попробуйте
придумать, то, боюсь, вы
самое интересное выпустите.
Это очень важный шаг.
Но я пока подсказывать, что именно не хочу.
Просто смотри, каким принципом ты руководствуешься?
Ты должен написать код, который будет выглядеть хорошо.
Что значит хорошо?
Хороший код
это код,
в котором...
Я вообще-то писал это в канал. Это такой базовый принцип
программирования. Если вы не знаете, его
программировать вы вообще не должны.
Это solid.
Знаете ли вы про паттерны проектирования?
Вот их не нужно знать вообще.
Это абсолютно естественные вещи,
которые выводятся из некоторого здравого смысла.
Здравый смысл это solid.
Вот паттерны проектирования
как изучают? Изучим сегодня
паттерн-адаптер, завтра изучим паттерн-визитер.
Не нужно. Нужно всегда
исходить из задачи.
Вы не решение задачи учите,
сначала решаете задачу, а потом находите в ней паттерн.
Но если вы даже паттернов не знаете, вы можете
их не знать, но их использовать,
потому что это просто разумные решения.
А разумные они в том смысле, что
они делают только то, что нужно,
и в себе заключают некоторую
суть задачи.
И вот здесь также
овейтеры это суть
задачи кастомизации поведения
файберов.
В хорошем решении у нас
файберы не будут знать ничего про
конкретные фьютексы,
гилды,
кондвары,
вообще ни про что такое.
Файберы упростятся.
В кондварах не будет
снова знания, в кондварах мютексов,
в фьютексах не будет никакого знания про внутренности
файберов. Там тоже это не нужно знать.
Будет просто файбер-хэндл.
И все вот это вместе
не будет ничего знать
про тратпул, который все это исполняет.
То есть будет хороший модульный
код с низко связанностью,
где
любая логика, она локальная,
вы можете ее менять и не думать,
как это влияет на какое-то далекое другое место
в коде. Вот если у вас код
написан так, то с ним жить очень просто.
И это вообще-то очень важное
наблюдение про модульность
и про такую локальность,
потому что представьте себе, что вы пишете большой проект.
Вот осенью
с теми, кто пойдет учить с распределенным системом,
мы будем писать распределенный код
и
ну там
студенты, вы напишете 5%,
а 95% напишу я.
И это скорее самое сложное.
То есть это не алгоритмы будут, это вся инфраструктура
вокруг, но вот
она очень сложная, очень большая.
И ну
в нашем курсе там будут
десятки тысяч строчек уже, это очень много.
А в большом проекте,
который развивается там лет 10, может быть сотен тысяч
строчек. Ну и представьте, как
может человек ориентироваться сотен тысяч строк.
Сотни тысяч строк.
Но это гораздо
больше кода, чем можно вместить
в одну голову. Ну ладно, есть разные головы,
можно вместить на самом деле.
Но вы сможете с этой сотни тысяч
строк управляться только тогда,
когда они максимально декомпозированы.
Вот эта сотня тысяч строк, это 10 тысяч строк
в одном месте, 10 в другом, 10 в третьем.
И они друг с другом общаются только через очень
простые абстракции.
И вот если это так, то вы можете
ну вот представьте себе,
что мы пишем сейчас файберы, и мы их там
оптимизируем.
А в субботу я расскажу вам, как написать
хороший тредпул, эффективный,
быстрый, потому что текущий не годится совершенно.
То есть хороший планировщик.
И планировщик сложный очень.
И файберы сами по себе
будут сложные.
Но нам не нужно думать про их
сложность, не нужно их перемножать
от этой сложности.
Нужно их складывать.
Понимаете идею?
То есть мы ровно для этого и повели декомпозицию
между файберами и
экзекьюторами. Мы отдельно пишем экзекьютор,
отдельно пишем файберы, и сложности их
суммируются, но вот
файберам не нужно ничего знать про
реализацию тредпула.
Я вру на самом деле.
А тредпулу не нужно знать ничего про файберы.
Только про задачи.
И вот ровно благодаря
хорошему модульному дизайну,
потому что каждый компонент
занимается только одной задачей,
это принцип единой ответственности
в SOLID, и каждый компонент
слабо связан
с другими, еще один принцип,
то вот благодаря
этому мы можем управлять всей
сложностью нашего проекта.
Только так
и можно жить.
С большим сложным кодом.
Мы сейчас
на файберах учимся как раз
этой сложностью управлять, то есть
декомпозировать файбер-скор
от всего того, что можно
для синхронизации придумать.
Пока это кундварф, ютекс, мютекс,
вейтгрупп, дальше можно добавить канал,
селекты, там еще что-то, и вот так
вот продолжать еще долго.
Там таймер добавить, тикеры как
уго.
Очень долгая дорога, мы конечно не успеем
все сделать, но
должно быть понятно, что можно так долго
продолжать. И наш код
должен быть к этому готов.
В общем, напиши какое-то решение,
подумай, где оно тебе нравится, где не нравится.
Откуда пользователь
берет файбер-хэндл,
ты спрашиваешь.
Ну, видимо, сейчас.
Ну, подумай,
как это все должно работать.
Файбер-хэндл,
ну, это как бы такой
хэндл на файбер.
Ну, файбер-хэндл
на файбер,
это как бы такой хэндл на файбер.
Ну, видимо, его строит сам файбер.
Откуда он еще возьмется?
Вот. Но при этом
в твоем коде внутри директории
синг не должно быть никаких обращений
к файберам. Ну, просто их не должно
быть. Вот, в частности, фьютекс
это же шаблон, он реализован в хедере.
Если ты напишешь здесь include-файбер, то все,
ты проиграл, потому что он попадет
ко всем пользователям этого самого
фьютекса.
Вот, я еще обращаю внимание,
что у тебя файбер-хэндл – это хэндл
именно на остановленный файбер.
То есть, когда ты его получаешь,
то есть, в хорошем коде, если у тебя есть
файбер-хэндл,
то он
определенно указывает
на файбер, который уже остановлен.
И его можно запустить.
Ну, или он пустой вообще.
Он пустой ты сам сконструируешь, может быть.
Но если тебе дали файбер-хэндл,
то ты точно знаешь, что он у тебя
уже заполнен файбером, и этот файбер
остановлен, и его можно будить.
Вот это важная подсказка.
Хороший код будет только с таким
файбер-хэндлом работать.
Ну, и у задачи есть, конечно,
третий бонусный уровень.
Вот он самый клевый. Он прям очень клевый.
И он очень...
И он матчится с
следующей темой
наших лекций, с планировщиком.
И с задачей
новой простренд
это лог-фри-мьютекс.
Потому что мы делаем в мьютекс,
а в нем есть спинлог, а в спинлоге есть
взаимное исключение, а мы работаем в пуле,
и мы блокируя другие потоки,
блокируем вообще всех.
Вот можно сделать мьютекс, которым
не будет взаимного исключения на уровне
поток.
И вообще,
во всем нашем коде мы
сделаем лог-фри-мьютекс, можно сделать
лог-фри-планировщик,
и в хорошем коде
можно сделать почти все, что...
почти все с лог-фри и без
взаимного исключения. Но это очень сложно,
но тем не менее можно так сделать.
Вот это очень клевая часть задачи, и она вот
это на самом деле не то, что вот просто
сделаем лог-фри-мьютекс. Он очень сильно
ускоряет реализацию
файберов именно за счет того,
что в нем можно сделать серийность.
А что такое серийность? Но про это у нас задача
текущая.
Короче, тут все связано, вы даже не представляете
насколько все связано.
Вот те, кто
пройдут до конца, они
это все почувствуют и, возможно,
восхитятся. Мне это поражает
все лично, как все в итоге
сложилось. Ну, очень красиво все
вместе сходится.
По поводу фьюч, ты спрашивал
еще, да, или кто-то спрашивал?
Ну, вот фьюч они сами по себе,
но в принципе можно научиться
научиться научить файберы их дожидаться, с ними
работать.
А мы
настолько, да.
Но мы это все вместе свяжем.
Вот мы пишем эту
библиотеку EXE, которая называется, здесь, да,
Pro Execution.
Чуть позже, но я думаю, что
где-то к концу апреля у нас появится задача,
которая,
ну, такая домашка
общая, куда нужно все складывать.
Мюток, секундвары наши,
потом из них сделать файберы,
ну, туда планировщик положить,
разные планировщики и файберы
положить, и фьюч положить.
И в итоге у тебя и файберы будут
файберы будут использовать
разные планировщики, будут их
поддерживать те, которые мы делаем в новой
задаче
в виде экзекьютора. Будут исполняться уже
в них, а не конкретно в тратпуле.
И могут дожидаться фьюч.
Ну, то есть все это вместе можно будет слепить.
И все будет сделано хорошо.
Ну, то есть если ты сделаешь все хорошо, то все будет работать
хорошо, и все будет друг с другом сочетаться.
Это сложно.
Вот я прям...
Люди разные думают, как это сделать, я тоже
думаю уже несколько лет. Ну, вот это некоторые текущие
итогы, как это все можно совместить.
Но я подумал за вас, поэтому я знаю, к чему
мы можем прийти, и мы так неспешно
идем.
Еще один нюанс.
Ну, возвращаемся уже к моделям памяти
текущим.
Мы изучаем модели памяти,
и
это такая тема
перпендикулярная почти всему, что
происходит.
И эта перпендикулярность, наоборот,
полезна. Вот мы пишем файбер,
и там возникают атомики.
В конце концов, мы делаем все из атомиков.
А вот атомик, и каждая операция над ним,
это повод
поставить какой-то memory order.
Поэтому, пожалуйста, если вы пишете код,
если у вас есть атомики,
то давайте начнем думать, какие
memory order там ставить.
И вы будете решать задачи, а потом
вы будете приходить на семинары и говорить, что
вот у меня была такая задача, я там написал спинблок,
мне там нужно было поставить memory order.
Но это вы уже умеете, кажется,
делать.
Или вы пишете вейт-группу.
И в хорошей вейт-группе задача там тоже
не будет
mutex в основном, будут
в основном атомики.
Плюс-минус.
И тоже можно ставить memory order.
Но это сложная тема.
Короче, и в планировщике у нас будут
тоже лог-фри, и там будут
очереди циклические, и там
снова нужно ставить memory order, который мы разбирали в прошлый раз.
И если вы все будете хорошо делать,
то в конце курса у нас будет возможность
код попрофилировать.
Вот мне это хочется сделать,
мы никогда этим не занимались, вот прям
пооптимизировать большую библиотеку и еще
и пооптимизировать ее.
Но пооптимизировать не так, как вы там
привыкли алгоритмически пооптимизировать.
Это не важно как раз в жизни.
А пооптимизировать именно вот на уровне
синхронизации, на уровне memory orders,
на уровне там лишних аллокаций памяти.
И можно все это увидеть, как
все это вдруг будет
ускорять, ускорять, ускорять ваш код.
Вот на рекции про планировщика
эту тему продолжу.
Пока оптимизировать трудно, в смысле, потому что измерить трудно.
Вот если вы запустите профайлер,
если вы делали это когда-нибудь,
то вы увидите, что сейчас
реализация файберов может быть очень хорошая,
но под ними может быть очень медленный планировщик.
Вот Redpool это очень плохой планировщик
для файберов.
Мы про это в субботу поговорим, научимся его делать хорошо,
и потом про это будет домашко.
И вот тогда уже, когда и файберы будут
хорошими, и планировщик, можно прям
будет оптимизировать.
Но пока, пожалуйста, оптимизируйте файберы.
У вас плохой планировщик, но файберы уже могут быть
хорошими.
Там может быть мало локаций,
меньше синхронизаций.
В общем, подумайте, на что вы там
тратите лишнее время.
Объясню, что происходит, да?
Вот в конце может получиться очень крутая вещь,
потому что мы не пишем с вами какой-то учебный код,
мы пишем вполне настоящий го.
То есть тот го, который у вас получится,
он будет настолько хорош, насколько вы напишете его.
Тут нет никаких искусственных
ограничений, что мы какую-то поделку получим.
Вот вы можете получить код, который
будет настолько же эффективен.
Вопрос только в том, насколько вы
вложились в отдельные маленькие
детали. Ну а мы с вами
учимся каждую деталь оптимизировать.
И теперь мы возвращаемся
наконец к моделям памяти.
Что мы с вами делали
с моделем памяти?
Мы...
Вообще у нас еще локфри
пропадает. Мы до сих пор
не разбирали локфри, который был на последней
лекции. А там было управление памятью,
и мы по нему ничего не сказали до сих пор.
А еще
мы знаете, что упускаем, пока у нас не хватает
времени на все? Мы
все еще не поговорили про то, как устроен
третцинитайзер.
А ведь третцинитайзер, он крутой,
потому что он умеет находить
баги очень сложные. Вот помните,
мы расставляли барьеры в циклическом буфере.
Мы говорили, что вот здесь
мы
пишем с релизом.
Здесь мы читаем с
Acquire и...
Давайте это
сотрем, пока это не нужны
подсказки нам. Мы пишем
здесь в буфер
и двигаем вперед хвост с
релизом. Здесь мы читаем хвост,
и если мы видим, что вот он впереди, то значит
можно читать из текущего слота.
И вот если мы напишем здесь
не Acquire, а Relaxed,
ну вот правильно это Acquire,
чтобы была синхронизация с
то есть запись
буфер была упорядочена
через Happens Before с первым чтением.
И вот нужен BlockWire.
Но если мы вдруг написали Relaxed
и запустили
код под третцинитайзером...
Нет, это не тот код.
Под третцинитайзером,
то что мы там увидим?
Он неспешно запускается
и ловится DataRace.
А почему это сложно?
То есть почему это неожиданно вообще, что DataRace мы поймали?
Это неожиданно, потому что
мы с вами говорили, кажется, что
на x86
и Release, и Acquire,
и Relaxed компилируются просто в Moves.
Ну то есть
модель памяти самого процессора
достаточно сильная,
и просто вот голый
Move — это уже Release-запись.
Голый Move — это уже Acquire-чтение.
То есть сам процессор
обеспечивает нам причинность.
То есть в исполнении
на вот этом компьютере вот этой программы
ничего плохого случиться не могло.
Потому что вот что Acquire,
что Release — это один и тот же машинный код.
И вот именно третцинитайзер
это находит, потому что он
прям явно проверяет, что Happens Before есть.
Он прям явно трекает
вот эти вот частичные порядки.
А как он это делает? Это достаточно не тривиально,
это достаточно интересно.
И алгоритмы некоторые,
и инженерная задача алгоритмическая — она интересная.
Хочется про это поговорить однажды,
когда у нас появится время.
Ну а сегодня нам нужно разобрать
Memory Order дальше, потому что мы еще не все изучили.
Вот мы с вами научились
использовать Relaxed,
Acquire-Release,
ну мы и так использовали,
а Acquire-Release научились использовать Relaxed.
Ну вот здесь мы как использовали Relaxed?
Мы говорили,
что вот у нас есть операция,
за потоком Producer-Consumer,
и Producer добавляет данные
в буфер, двигает вперед Tail.
А потом он
сам Tail перечитывает.
Ну а у нас здесь гарантии,
которые мы ожидаем от однопоточной программы.
Если однопоточная программа записала что-то в ячейку,
а потом сама читает,
то, разумеется, она видит собственные записи.
То есть
это у нас называлось в модели памяти
гарантия Program Order,
частичный порядок Program Order,
который связывал все обращения
в одном потоке.
И мы говорили, что чтение не противоречит
Program Order. То есть чтение читает, по крайней мере,
последнюю запись в Program Order.
Поэтому здесь могло быть
написано Relaxed.
Да?
А теперь вопрос.
А пусть теперь с этим
буфером работают не два потока,
а два файбера?
И файбер...
Ну в чем разница?
Файбер запускается на одном потоке
в треттпуле,
делает продьюс,
пишет в 42-й слот,
пишет в tail 43,
а потом вдруг говорит yield
и оказывается на другом потоке
треттпула. И в нем
он читает свой tail.
Вопрос. Почему он увидит
актуальное значение?
Вот Relaxed не гарантирует актуального значения.
Relaxed говорит, что у вас есть на Atomic
Modification Order, то есть все записи
упорядочены,
но при этом чтение может какую-то более
старую прочесть.
Главное, что монотонно по истории.
Так вот, если этот код работает
с файберовыми, с потоками и запускается
в разных потоках,
то можно ли здесь писать Relaxed?
Или нельзя?
Проблема понятна?
Но Program Order это точно больше нет,
потому что мы в одном потоке были потом в другом.
Этим мы пользоваться не можем.
То есть мы этот код выполнили в одном потоке,
потом перезапустились в другом потоке,
и здесь в новом потоке делаем
Relaxed.
И Relaxed нам не обещает
самую свежую запись.
Можем ли мы на это рассчитывать тогда?
На этот Relaxed.
Но я не знаю, это к тебе вопрос.
Смотрите, о чем мы
говорим сейчас. У нас были два потока,
и с ними код работал.
А теперь мы заменяем потоки на
файбера.
Но
было бы странно,
если бы
при переходе от потоков к файберам
нам бы пришлось ставить другие Memory Order,
потому что для нас файберы это просто реализация
потоков. И было бы
странно, если бы мы поставили другую реализацию,
и вдруг бы гарантии поменялись.
У нас файберы
в смысле наблюдаемого поведения,
в смысле их использования, они должны ничем
отличаться от потоков настоящих.
Но вру, они у нас
кооперативные, они не умеют выяснения.
Но это
такая деталь,
не очень важная для нас.
Она ни на что не влияет.
Точнее, она влияет, конечно, но в нашем коде
мы предполагаем, что файберы не будут долго
работать, не переключаясь.
Так что мы готовы это пережить.
А во всем остальном, абсолютно во всем
остальном, файберы должны вести себя так
к потоке.
И было бы странно, если бы при переходе
от потоков к файберам нам пришлось бы выставить
другой мой реордер.
Действительно, не нужно.
Но нужно понять, почему теперь релакс от чтения
все равно прочтет последнюю запись.
Вообще, как
гарантировать, что
чтение прочтет запись? Это такой
фундаментальный вопрос по модели памяти.
Как это гарантировать?
Как мы это гарантировали раньше,
на прошлом занятии?
Ну, это частный случай.
Общий случай.
Happens before. Но program order
это же частный случай Happens before.
Program order – это порядок внутри одного потока,
то есть тоже причинность. А Happens before
обобщает причинность на разные потоки.
Как обобщает? Ну, вот там появляется
synchronize the Swiss.
Вот у нас один поток записал
что-то, а другой прочитал то, что было
записано. И вот мы теперь
рассчитываем на причинность.
Вот здесь, в этом коде,
в этом мысленном эксперименте с файберами
это и происходит. Смотрите.
Был у нас файбер.
Был у нас
некоторый файбер-продюсер.
И он исполнялся в потоке
пулаты 1. Он там
исполнил try produce x.
В нем он положил в буфер
в позицию 42x.
А потом он сделал
trail store 43.
Что произошло дальше?
Дальше
файбер сказал yield.
Ну, сейчас
давайте пока я на этом закончу,
а дальше поставлю многоточие, а потом
скажем, что файбер запустился дальше на потоки
t3, и в нем вызвал
снова try produce.
И начал он
с того, что
прочитал себе
loads relaxed.
И мы хотим, чтобы он увидел 43 здесь.
Но давайте подумаем, что
происходит посередине.
Вот посередине мы в файбере
в потоке t1 сказали yield.
А что внутри
этого yield произошло?
Ну, мы сначала сделали
core suspend,
наверное, да?
Остановили корутин.
А потом
мы сказали
планировщик, threadpool,
submit,
и передали туда
pointer на наш файбер,
и запустились.
Запустимся, когда задача
будет выполняться.
А что внутри submita происходит
внутри потоков?
Кладем задачу в очередь.
А что происходит там?
Ну, мы берем mutex,
а потом мы в какую-то
очередь добавляем
какое-то абстрактное значение.
Ну, это если вот
разворачивать все, что происходит
в нашем коде, да?
А потом на потоке t3
что случилось?
Threadpool в процедуре
worker routing
взял задачу из очереди,
а для этого он
снова взял mutex
и
сказал
вот так.
Понятно, да?
Ну и все, смотрите, мы же уже научились
писать вам spinlock.
Spinlock, вот он был.
Как он работал?
Он в онлоке делал store с релизом,
в чтении он делал,
в захвате в онлоке он делал
log exchange с aquire
и вот с помощью этого
релиза aquire, то есть мы крутили здесь,
пока мы не увидим эту запись,
и когда мы увидели, у нас получился
synchronize with.
И таким образом все критические секции
связаны отношением happens before.
Поэтому у нас,
в нашем коде, в нашем мысленном
эксперименте,
вот этот онлок
будет упорядочен
с этим локом
через happens before.
Ну а значит мы упорядочили
через happens before этот store и вот этот
лод.
Ну и все.
То есть у нас
happens before получился
не напрямую
за счет атомика какого-то,
а он получился, потому что
мы воспользовались где-то в недрах
нашего runtime
и файберов примитивом синхронизации.
Ну это такой общий рецепт.
У вас happens before
продляется, переносится
из одного потока в другой, когда вы пишете
в атомик, читаете из атомика, или когда вы
отпускаете лог, берете лог,
или когда делаете push в очередь, потом
извлекаете, делаете pop в очереди.
То есть любые примитивы синхронизации, они
этот happens before продляют.
Ну мы как бы
опираемся к этому нашему
реализацию?
Ну мы полагаемся на то, что в планировщике
есть корректная синхронизация.
Это довольно разумно.
Как иначе задача
созданная в одном потоке
попала в другой поток?
Через синхронизацию.
Ну то есть если планировщик
устроен корректно, если в нем
синхронизация корректная, то
и наш файбер, будучи запущен на другом
потоке, обязан тоже
испытать на себе
последствия этого happens before. То есть он может
на это рассчитывать, и поэтому использует здесь
релакс.
Все верно?
Точно, без обмана?
Какое-то сомнение есть, да, у вас?
Ну я просто не знаю, как
Мельчер списать. Тут я могу
написать, конечно, вот тут был
вот здесь был
еще в онлоке
был там
locked store, значит
store 0 с релизом. Здесь
в локе
был
lock
exchange 1
acquire, и он
прочитал 0, и вот здесь
и здесь возник синхронизация
Swiss, и дальше он.
Смотри, мы не
предполагаемся на какое-то конкретное
устройство планировщика. Для нас
он абсолютно
произвольно устроен, для нас это абстракция.
Это экзекьютор, который умеет запускать
задачи. Но если он
многопоточный, если он получает
задачу на одном потоке, а потом запускают ее
в другом потоке, то
видимо в нем должна быть синхронизация,
с помощью которой задача переедет.
Разумное же ожидание?
Так что мы на это вполне можем полагаться,
что в самом планировщике синхронизация
корректная. Если она
корректная, то значит она
и для нас даст вот эту причинность.
В конце концов, смотрите, какая
история. Мы работаем с потоками,
а потоки-то...
Да, смотрите,
это же прекрасная иллюстрация.
Мы говорим
про то, что в одном потоке все бы
работало. Но у вас
на самом деле же,
когда процессор вам говорит
про memory order, про барьеры,
он говорит не про потоки, он говорит
про ядра.
Так что все гарантии на самом деле не про ядра.
Просто планировщик
операционной системы тоже так же
устроен, тоже корректная синхронизация,
поэтому он может запустить
вот первый
продьюс на одном
ядре, потом второй продьюс
запустить на другом ядре, но все равно гарантия
будет, потому что опять вот те же самые
рассуждения. Тот же планировщик тоже
обеспечивает такую гарантию. В смысле планировщик
уже операционной системы.
Но у него в распоряжении только барьеры,
которые про ядра на самом деле,
а не про потоки.
То есть потоки-это более высокоруневая
сущность. Ну и здесь мы вот те же самые
идеи воспроизводим на уровне еще выше.
Ну потому что мы делаем то же самое.
Мы пишем кусочек
операционной системы.
Сошлось?
Так что везде обман, везде
нужно думать.
Можно полагаться на некоторую абстракцию,
что вот поток-это для нас
такое виртуальное ядро. Ну а под
капотом все равно есть некоторые конкретные
организмы, которые это абстракцию обеспечивают.
Ну что, с циклическим буфером мы
покончили, я надеюсь.
Давно пора. Слишком простой пример.
Он столько сложностей вызывает.
Он нам пригодится
в следующую, в эту
субботу. Вот он станет
такой рабочей, лошадкой в планировщике.
Без него сложно будет.
Идем дальше.
Мы воспользовались теперь relaxed,
acquired-release, sequential-consistency.
Остался consume и acquired-release.
Давайте про
consume сейчас.
Итак, пример.
Но он довольно искусственный.
Можно было бы его аккуратнее написать.
Но я до сих пор полегился это сделать.
Итак, у нас есть такая штука
lazy-value. Такой контейнер
для объекта типа T, который
инициализируется лениво.
В момент первого обращения.
Вот у нас есть
lazy-value, у него есть
метод access,
к которому мы обращаемся.
И в этом методе access
мы должны сконструировать объект,
если он еще не был сконструирован.
Для конструирования у нас есть вот такая
вот функция, которая умеет построить
где-то на кучу объектов.
Ну и в методе access,
мы храним в объекте
нашим lazy-value pointer
на созданной T.
Если там null-pointer, то, видимо, нужно создать.
Но инициализация объекта — это что-то,
что происходит один раз, а обращения
частые.
Поэтому мы хотим оптимизировать
обращение, сделать так, чтобы на быстром пути
это был просто load.
Вот мы проверили pointer, если там
не null,
то просто возвращаем этот pointer.
Ну, то есть прям в ссылку
возвращаем на объект.
Значит, объект уже инициализирован.
Это быстрый путь.
А иначе медленный путь.
Нужно объект
проинциализировать.
Но что, если у нас два потока пришли
до первой инициализации,
увидели null-pointer
и решили оба проинциализировать
на тот же объект?
Между ними гуманка.
Ну, давайте мы поставим
mutex, чтобы
среди них этих двух потоков был
первый и второй.
И каждый поток после
захвата mutex еще раз проверит
value-pointer.
И если он по-прежнему null,
то, так уж и быть, объект сконструирует.
А если же поток,
который пришел сюда и увидел null-pointer,
окажется на mutex-е вторым,
то он увидит, что
объект уже инициализирован
и не будет его
инициализировать второй раз.
Вот поэтому double-checked locking.
То есть у нас есть быстрый путь,
быстрый оптимистичный сценарий
и медленный пессимистичный.
Ну вот.
Есть такая штука, и в ней нужно пооптимизировать
memory-order.
Но чтобы их оптимизировать, нужно снова
понять, какие неатомарные
обращения к памяти мы собираемся
упорядочивать.
Вот всегда, когда мы ставим memory-order,
мы должны не про атомики
думать, а наоборот про неатомарные
обращения. То есть какие неатомарные
обращения, неатомарные записи и чтения
мы хотим упорядочить в этом коде.
Ну вот, в 24-й строчке мы
в некоторой памяти строим объект,
а потом другие потоки
вызывают access, получают ссылку
на эту память, и вот в этой памяти
эту память читают, работают
с ней.
Вот неатомарные обращения, нужно их упорядочить.
Ну предлагайте что-нибудь.
Ну да.
А, ну в смысле, ты про...
Поставь мысли на relax везде, давай так.
То есть какие самые слабые
memory-order тебе нужны?
Тебе достаточно.
Сейчас давай по-другому. То есть дело не в том,
что какие memory-order стоят.
Ты должен, видимо, между вот этими
записями в память и вот последующими
чтениями получить
Happens Before.
Как ты это Happens Before обеспечишь?
У тебя же конституирование
происходит в одном потоке,
а чтение потом в другом потоке.
То есть тебе нужен какой-то
Happens Before Synchronize With.
Что?
Ну говори, где что писать?
Acquire?
Нет, там проиграть надо...
Релиз на чтение Acquire.
Да.
Релиз на чтение Acquire.
Итого, если ты в методе Access
получил pointer на объект,
то значит, ты его здесь прочитал.
Если ты прочитал не null,
то, видимо, здесь его записали,
а значит, перед этим конституировали объект.
Но и причинность у тебя есть
в стиле Happens Before.
Что?
Давай теперь подумаем
про вторую строчку.
Это еще одно чтение.
Если тут мы прочитали не null pointer,
то мы сразу выйдем
и вернем этот current pointer
пользователю.
То есть, если мы здесь
увидели не null pointer,
то мы, исходя из этого, обязаны
увидеть и записи в память вот здесь.
Как нам это обеспечить?
Ну или что здесь нужно написать?
То есть,
код, который вызывает
меня от Access,
он получит pointer отсюда
из этой строчки
и будет считать, что, видимо,
раз он получил не null,
то можно к объекту
обращаться.
То есть, он уверен почему-то,
что вызов create произошел
до этого чтения.
А как мы это обеспечили?
Вот так предлагать.
Но кажется, что это
тот же самый случай, что и здесь, да?
Но тогда было бы неинтересно.
Зачем-то показывать пример,
тут все интереснее.
Ну что значит какие-то?
Мы написали mutex, мы знаем, что он обеспечивает.
Мы знаем, что критические секции
упорядочены через happens before.
Между ними есть этот порядок.
Вот. И мы, смотрите, что делаем.
Мы в критической секции здесь.
И мы знаем, что мы вторые.
Ну вот, значит, мы уже видим
все записи из предшествующей секции.
То есть, мы видим, раз мы видим
и value pointer, раз мы видим
и value pointer, то мы видим остальные записи.
То есть, и create тоже.
Так что здесь достаточно
релаксно просто.
Если мы во второй секции, то вторая секция
видит все записи первой секции.
То есть, мы здесь
гарантированно прочтем
уже и в value pointer не null, и в create
уже будут.
В памяти,
в которой create разместил объект,
тоже уже будут все данные видны.
Поэтому мы просто
возвращаем пользователю
ссылку.
Вот. Так работает,
но я вроде бы обещал вам другое
показать. Я же хотел показать вам, зачем
нужен Consume,
а его здесь пока нет.
Вот это очень темная история, смотрите.
Можно представить
себя, когда мы говорили про
RealizeAquire, мы говорили про такой пример.
Был поток,
ну ладно, ядро даже,
C1, и в нем делались такие записи.
Сначала мы писали в X1,
а потом мы
писали в Y1.
А потом на ядре C2 мы читали
из Y,
и если мы тут видели,
давайте помедленнее напишу,
читали из Y,
и если
видели один,
то читали
из X.
И тоже ожидали здесь увидеть единицу.
Ну точнее как,
мы пишем такой код,
и чтобы он работал, нужно каким-то образом
обеспечить выполнение,
видимость причинности.
Поэтому мы говорили, что
вот на этот случай нам
memory-памяти дает
memory-order-release,
а здесь memory-order-Aquire.
Зачем? Ну, за тем, чтобы
нельзя было преордерить, грубо говоря,
эту запись ниже этой,
а эту запись, это чтение выше этого.
Ну потому что они вроде как независимые,
ну или даже вот давайте попроще
напишем, вот так.
Вот тогда причинность у нас была.
Мы не можем увидеть единицу здесь,
увидеть 0 здесь.
Но сейчас у нас написан
несколько другой код.
У нас ядро C1
делает что-то такое.
Ну как?
Вызывается сначала конструирование
объектов памяти, а потом
мы по интерпишем
вот этот адрес.
Ну я какой-то псевдокод пишу,
такой условный, понимаете?
Ну вот, вот, вот.
Вот, вот, вот.
Вот, вот, вот.
Вот, вот, вот.
Вот, вот, вот.
Я какой-то псевдокод пишу, такой условный.
Понимаете, наверное, меня, да?
А над C2 происходит вот что.
Мы читаем
в регистр
по вот этому адресу.
Сейчас мы читаем
в регистр
адрес point,
ну, который хранится в pointer
в переменной.
Вот.
А потом
мы
читаем данные
по прочитанному адресу.
Видна ли разница
между двумя этими примерами?
Вот разницы существенные между
вот этим кодом и вот этим
нет, а вот между этим
и этим есть.
Потому что здесь мы читаем две независимые
ячейки памяти.
И процессор, вообще говоря, может
выполнить это чтение раньше этого.
Ну, вот так захочется, условно.
А здесь?
А здесь у нас зависимость
по данным. Здесь у нас
выход первого чтения
подается на вход второму чтению.
У нас есть зависимость по данным здесь.
Понимаете, что это?
Так вот.
Как же может процессор взять
и выполнить это чтение до этого?
Ну, это же совсем странно.
Правда?
Поэтому хотелось бы здесь написать
Relax вообще.
Но вот так нельзя, потому что
оказывается, что есть процессор, который
так не работает.
Но, тем не менее, есть
Memory Order, который как раз вот нужен
для того, чтобы получить более слабые гарантии.
Это Memory Order Consume.
Memory Order Consume
он про то, что если
вы здесь что-то записали в Pointer,
а здесь вы подшли Pointer, а потом по нему подшли данные,
то вы вот здесь непременно
увидите вот эту запись.
Но совершенно не факт, что вы
при этом увидите
вот такую запись.
То есть вот здесь
вы непременно увидите данные, которые
вы записали здесь.
Но никакие гарантии
на вот эту запись,
что она будет видна этому чтению, нет.
То есть, да, вы знаете, что вот
здесь вы прочли Pointer, который записали здесь.
Но при этом вы из этого не можете
делать вывод о том, что
вы можете, что в Z
уже тоже сделана запись единицы,
что она видна в памяти.
Это вот ограничение консюма.
Да вот,
смотри, да вот в том-то и дело, что
консюм он почти нигде не нужен.
То есть почти, ну, все процессоры
практически на свете
уважают зависимость
по данным.
И вопрос тут не почему
консюм, а не Acquire, а почему здесь
Consume Unrelaxed.
Вот, оказывается, есть
некоторый процессор, которому явно
нужно сообщить об этом.
Есть какая-то альфа.
Кажется, что это
архитектура, которая никому не нужна.
Ну, не знаю, может быть, кому-то нужна.
Но
смотрите, почему это
плохо. Вот здесь такой консюм, у него
гарантия вот такая, да, что мы
здесь, даже с консюмом,
вот этот консюм он,
если мы через консюм
увидели вот эту запись с релизом,
то мы увидим и данные по поинтеру.
Но произвольную ячейку, записанную
до, мы уже можем не
увидеть после.
И это проблема,
потому что этот консюм, он
существенно усложняет модели памяти
C++. Вот на лекции
я вам показывал, что мы определяем
HappensBefore и в джаве HappensBefore
определяется вот просто как положено.
Мы говорим, что между x и y есть
HappensBefore, если
x и y это действия
просто в одном потоке, между ними есть
программ Order, или x
синхронizes with y,
или транзитивные замыкания.
А вот в C++ все намного сложнее.
И там HappensBefore
определяется
вообще-то жутковатым
образом.
Он определяется вот так.
HappensBefore это либо
A SequencedBeforeB,
SequencedBefore это в C++ так называется
программ Order. Или
Interstrat HappensBefore,
который определяется вообще вот так,
очень как-то заковыристо,
и этому всему еще
к этому всему предлагается
длинный комментарий, почему так получилось.
А еще
в C++ есть
Simply HappensBefore.
И в нем уже все как положено.
A SequencedBeforeB,
A SYNCHRONIZES WITH B,
и транзитивные замыкания.
И говорится, что
если бы не Consume,
то HappensBefore и Simply HappensBefore
определялись бы одинаково.
Но не тут-то было.
Вот из-за того, что в C++ есть этот MemoryOrderConsume,
который позволяет
что-то соптимизировать
для какого-то маргинального процессора,
модель памяти сильно усложняется,
и в ней появляются два новых порядка.
Вот DependencyOrderedBefore.
DependencyOrderedBefore – это отношение,
которое возникает между
релиз-записью и Consume-чтением,
которое видит эту запись.
И если мы
прочли с Consume-поинтер,
а потом по нему читаем,
то вот это чтение
и это связаны
с отношением
Dependency.
И вот конкотинация
вот этих DependencyOrderedBefore
и CarriersDependency
тоже образует HappensBefore.
Но он уже не транзитивный,
потому что
вот к нему
вот здесь будет CarriersDependency,
здесь будет DependencyOrderedBefore,
а, к сожалению,
здесь будет
SequencedBefore, и SequencedBefore
нельзя приклеить к этой цепочке.
Но если вы не понимаете ничего,
то можно это все забыть
и просто не использовать никогда Consume.
Но вот если вы понимаете,
то вы можете потом осмыслить,
почему модерипамяти C++ такая сложная,
почему в ней так нетривиально,
так избыточно сложно
определяется вроде бы простой по смыслу HappensBefore.
Ну, потому что есть
Consume.
Но он никому не нужен,
я вот, смотрите, давайте
убедительно докажу это.
Вот из библиотека Folia
это библиотека общих компонентов Facebook.
И там, кстати, много интересного для нас
есть, в частности, там написаны Executor,
там есть Fiber, там есть
Future.
И вот можно погуглить,
как в этой библиотеке
используется, например, MemoryOrderAcquire.
Я где-то, наверное,
ошибся.
Но он непременно
должен использоваться.
Мы ничего не находим.
Ну, я что-то исправил,
ну ладно, я понял, что...
В общем, много где используется он.
Вот какие-то примитивы синхронизации.
Много какого-то кода.
А теперь меняем Acquire на Consume.
И он используется
только в нескольких тестах,
и то для того, чтобы игнорировался он.
Вот. Так что
этот MemoryOrder, ну в общем,
он никому в реальности
не нужен.
И если его в реальности нет,
то предлагается его
из своей картины мира вычеркнуть
и вместе с этим Consume
исчезнет для вас
вот этот избыточно
сложный HappensBefore.
И хоть он формально
так определяется,
но поскольку...
Вот вам MemoryOrder сама говорит,
вам сам стандарт языка говорит,
что если бы не Consume, то
HappensBefore можно заменить
на такое простое определение.
Поэтому я на лекции вам его и рассказываю.
То есть формально это
не определение HappensBefore все плюс-плюс,
но фактически
если мы от Consume отказываемся,
то им можно пользоваться.
Ну в том, что есть некоторые процессоры,
на которых от Consume можно получить больше
пользы.
То есть, смотри,
вот есть такой паттерн,
где ты читаешь pointer, потом читаешь
по pointer. И вроде
тебе не нужно там сильные барьеры
ставить, ты мог бы обойтись
почти без барьеров.
Но какому-то процессору барьеры все-таки нужны.
Поэтому нам нужна еще одна
ступенька.
Но эта ступенька, она сильно-сильно
усложняет модель теоретическую.
Вот, поэтому мало кто от этого
получает выигрыш, почти никто в реальности.
Но зато все мы получаем
очень большой когнитивный проигрыш.
Потому что
вот мы
перфоманса дополнительного получить
от Consume мы не можем
на наших компьютерах разумных.
Но при этом нам становится сильно сложнее
модель памяти изучать и пользоваться ей.
Ну вот, такая
странная мораль.
Понимаете ситуацию?
Вот пример неудачного дизайна.
Люди попробовали, решили, что
C++ должен давать
нам zero cost абстракции.
То есть, если нам что-то не нужно,
мы за это можем не платить.
Руководствовали с таким соображением
разработчики модели памяти и добавили Consume.
И действительно,
кто-то, кто может этим Consume воспользоваться,
он воспользуется им.
Но в реальности им никто
не пользуется, но при этом
за счет него сильно-сильно-сильно
усложняется модель.
Так что эксперимент неудачный, но
кажется, что закатись обратно это уже невозможно.
Потому что не скажешь
же так, что все ваши
быстрые программы на этих странных
альфах отменяются и теперь будут работать медленнее,
потому что мы решили исправить ошибку.
Это не в духе C++ ломать обратную
совместимость.
Вот, так что Consume остается,
но вот его, как
некоторая ступень ослабления
Acquire, но лучше его
из своей памяти вычеркнуть.
Пользоваться им не стоит.
По-прежнему настаиваю, что есть
Relaxed, есть Release Acquire
и есть Sequential Consistency.
Мы выбираем, по сути, этих трех.
Есть еще Acquire Release
и мы
с ним
сегодня не успели.
А может быть успели, кто знает?
У нас 10 минут еще, да?
Или сколько?
Семь?
Ну, нет, давайте уже как-нибудь.
Либо до пяти, либо не в этот раз вообще.
Нет, вот Acquire Release
это просто комбинация.
Релизы Acquire, они полезные.
И более того, я утверждаю, что если вы пишете
в домашней хорошую weight-группу,
то оптимальные memory-ордеры будут там
такими, как я мог бы рассказать.
Нет, это полезная штука
и пример будет полезный.
Пример важный на самом деле сейчас будет.
Да не выгодно.
Смотрите, давайте перейдем на доску сейчас.
Нет, давайте сначала на экране
покажу.
Где еще memory-ордеры могут понадобиться?
Утверждается, что
они могут понадобиться, но
вы знаете про SharedPointer.
И я вам на лекции показывал, что SharedPointer
это такая штука, которая
с одной стороны в ней атомарный
счетчик ссылок,
а с другой стороны с ним работать
из разных потоков нельзя.
Но все же в нем атомарный счетчик
ссылок. Там есть
FetchSub, FetchEd, а значит
в них можно писать memory-ордеры,
при почете ссылок. Вот вопрос,
какие memory-ордеры нужно писать?
Ну, ищем.
Ну вот, Lipsy++.
Вот, RefCountIncrement,
RefCountDecrement.
Смотрите, increment
relaxed, decrement
acquiredRelease.
Разбираемся, почему так.
Еще одно
темное место обнаружено
с моделем памяти.
Вот чувствуете ли вы, где связь
с своей группой?
Ну ладно, прямая.
Там тоже FetchEd, FetchSub.
А теперь
смотрите.
Ну опять, что с чем
мы упорядочим?
Вот есть у нас
SharePoint, где они живут как-то.
Вот это их lifetime.
Вот здесь FetchEd,
здесь FetchEd,
здесь FetchEd,
здесь FetchEd,
здесь FetchSub,
FetchSub, FetchSub.
А тут FetchEd
и
для деконструирования, тут, наверное,
даже не FetchEd, а просто единиц
перевелось, да?
Здесь мы увеличили
1, 2, здесь
2, 3,
здесь
3, 2,
здесь 2, 1,
здесь 1, 0.
Это все атомарные операции.
А какие неатомарные операции
мы собираемся упорядочивать с помощью
атомарных?
У нас здесь
где-то есть обращение.
Ну есть, да.
Но это же обращение к объекту.
Ну, то есть
то, что если мы из разных потоков
вращаемся к самому объекту,
наверное, там внутри должна быть синхронизация.
А вот в смысле
самого shared pointer, что нам еще нужно
упорядочить?
Понимаете?
У нас времени мало, давайте
расскажу. Деструкторы же у нас
еще есть.
И вот им занимается сам shared pointer.
И вот нужно упорядочить
обращение к памяти здесь
и разрушение объекта здесь.
Нужно, чтобы это было
happened before.
И что мы делаем?
Мы...
Ну, у нас есть обращения разные.
Вот здесь вот оно есть.
Вот здесь вот оно есть.
Вот здесь вот оно есть.
И здесь есть программа
order всегда.
Ну, и пока вот этот деструктор
увидит это чтение,
это обращение.
Ну, как его заставить
увидеть эти?
Мы пишем здесь
acquiredRelease.
Что такое acquiredRelease?
Вот у нас операция, она
читает,
модифицирует, пишет.
И вот для
того, чтобы
и вот для
чтения, это будет
acquired чтение,
а для записи это будет
release запись.
И как это работает?
У нас здесь, смотрите, release запись
войки,
а потом есть фейчсап, которые читают
войку и тоже с acquiredRelease.
Так?
И получается, что
мы здесь пишем войку с release,
а потом мы читаем войку с acquired.
Потом мы здесь пишем
единицу с release, читаем
единицу с acquired.
Ну и все.
Теперь у нас все обращения, они у порядочных деструкторов.
Пока все просто, да?
Комментируем динамик,
поменим вводы,
да, только если у нас операция
делает и чтение, и запись.
То есть она ведет себя на какое
отчтение при release запись.
Но у нас тоже была операция,
которая и читала, и писала, и чтение,
но там нам не нужно было и то, и другое,
нам только какое было.
Так что нужно снова применять.
А теперь,
это понятно, да?
А теперь, собственно,
теперь смотреть шнап.
Теперь мы немного перейтируем пример.
Единица
Fetch add
1, 2
Fetch
sub 2, 1
Fetch add
1, 2
Fetch sub
2, 1
Fetch sub
1,
0
Деструкты.
Раз с обращением,
два с обращением,
третий.
И здесь
у нас по-прежнему какое
от release?
Здесь
Aqual release.
А здесь что?
Давайте вернем экран.
А здесь relax.
И вот
это некоторая техническая трудность.
Потому что
теперь у нас Fetch add.
Вот эта единица, которая записала Fetch sub,
читает вот этот Fetch add.
The last.
А потом мы и пишем двойку.
А потом мы двойку читаем самую.
И вот непонятно, как связь здесь
случается. То есть здесь связь
будет, да?
Как обычно.
Как на прошлой картинке.
И здесь программа order тоже есть у нас.
Но непонятно, что вот с этим
происходит.
С этим потоком.
И
это еще одно
темное место
от repartice++.
Но не то, что темное место.
Смотрите.
Synchronize with – оно про причинность.
То есть оно
это формальное обветрение, которое
фиксирует, что причинность передалась.
Мы здесь записали двойку,
мы почитали двойку.
Значит, вот этот поток будет знать,
что вот это уже произошло.
А здесь у нас, смотрите,
у нас операция
Fetch sub.
Это вот запись с
релизом.
Давайте так.
Запись с релизом.
Эту запись читает кто?
Операция
Read the correct
с релизом.
А потом
происходит чтение
с такое.
Опять
не просто чтение, не просто запись,
а томатная
операция.
Так вот, будет здесь причинность
логическая.
Но по идее
да, потому что мы здесь
написали что-то, а потом мы скажем по инкрименту.
И если мы видим здесь,
то мы знаем, как будто бы
эта операция сохраняет
причинность.
То есть если мы здесь
просто записали что-то другим,
то скотчка провала тебя.
Мы не можем больше ничего ожидать.
А тут мы как бы
усложнили, продлили
историю модификации.
И история модификации продолжилась.
Начинность продолжилась.
Вот поэтому C++
есть такое специальное понятие.
Оно называется
reverse sequence.
Давайте я уже это покажу.
В стандарте.
А мы сейчас ничего не увидим, наверное,
на такой доске.
Вот определение
synchronize this with, оно в C++
тоже сложнее, чем я вам показывал.
Вот я вам показывал такое определение.
Ну пойдем.
Неспешно появляется.
У нас есть
атомарная запись с релизом,
есть атомарное чтение с акварием,
и чтение читает запись, тогда синхронизуется.
В C++
вводится вспомогательная
конструкция, которая называется release sequence.
Это релиз-запись,
за которой исследует цепочка
read and write
операции.
И она называется release sequence.
И мы говорим, что
запись с релизом синхронизируется
с чтением с акварием,
когда чтение
с акварием читает
результат
release sequence,
начавшийся в
этой релиз-записи.
Вот можно открыть
определение синхронизации
с C++, и вот тут написано, что у нас есть
релиз операции A
на объекте M
и acquire операция B.
И вот B читает сайд-эффект
release sequence
с головой в A.
Вот, release sequence
с головой в A, и мы читаем результат ее,
то есть вот это значение.
В нашем примере
вот этот фей часа
прошедал бой,
который является
release sequence
из пятой операции
и вот этой операции.
И вот головой
релиз sequence вот этот
релиз-записи.
А мы читаем результат
этой релиз-записи, а вот
короче, вот эта штука.
Это релиз-записи.
Это релиз-записи, и вот
между
между вот этой записью
и этим чтением уже возникается
релиз-записи.
То есть формально
вот у нас здесь тоже есть
релиз-записи.
И опять все
упорядочено.
Вот такие жуткие штуки.
Это всего лишь
фиксация реальности. Мы ожидаем,
что вот такая цепочка операции
они логически справят причинность,
поэтому мы просто
немного усложним определение.
Но вот оптимальные memory
ордеры для инкремента и декремента
в SharePoint, они такие.
В декременте у нас фейчсап,
в декременте у нас square плюс релиз,
в инкременте у нас релакс.
В вейт-группе, в домашних получается
что-то то же самое.
Но началось с того, что мы поняли,
что нужно упорядочивать запрощение
и диструктор.
Ну все.
Хватит у нас на сегодня.
Да, все это последний memory
ордер. У нас был
relaxed, acquired-release,
их комбинация был consume
ну и default.
