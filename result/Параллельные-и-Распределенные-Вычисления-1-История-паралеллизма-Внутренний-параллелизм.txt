так ну что давайте начнем времени у нас не так чтобы много как уже предыдущий ратор говорил я
закончу эту это занятие эту лекцию и проведу еще одну поэтому здесь у нас осталось чуть
больше половинки давайте сосредоточимся и пожалуй я думаю что сейчас вы уже немножко
отдохнули пока мы здесь настраивали все поэтому давайте без перерыва хотелось бы там что-то
успеть и так вот олег уже сказал что первое два занятия и несколько семинаров у вас будет
посвящены параллельным вычислением да называется параллельные вычисления то есть там будет
mpi и куда еще но в целом хотелось бы начать вообще с того откуда это все идет почему нужно бы
рассматривать как mpi куда там еще были такие слова как open mp возможно вы будете что-то успевать по
но я в этом не очень уверен по-моему успевает ну значит отлично значит успеете но здесь за
скажем так чуть больше чем полторы лекции трудно осветить весь такой объем материала который
посвящен какой mpi так и open mp поэтому сначала мы вообще коснемся того почему это все изучается
почему изучается mpi open mp в дальнейшем куда ну и так далее почему в том числе в дальнейшем вы
будете проходить курс о распределенных вычислениях работать с большими данными то есть откуда
вообще все это идет и почему это нужно изучать вот поэтому давайте начнем значит вообще нужно
определиться с тем что такое суперкомпьютер ну есть если так для людей не посвященных это
можно показаться в общем-то банальным таким вопросом но суперкомпьютер это там где производит
супер вычисление но нас это не очень устраивает на самом деле поэтому здесь давайте как-то
формули формализовать хоть как-то о том что это такое например вот попытались это сделать в 86
году например воксфордском словаре было такое определение что суперкомпьютер это очень мощная
мвм который обладает производительностью в 10 миллионов операций в секунду то есть плавающей
точкой получается 10 мегафлопс но проходит какое-то время и уже в начале 90-х это нужно
было зачеркивать и переписывать словарь значит что будет сказано что у нас в начале 90-х уже
суперкомпьютер является таевым которая обладает производительностью производительностью 300
мегафлопс проходит еще несколько лет и производительность доходит до некой такой
магической цифры цифры в 5 гигафлопс и так далее но в общем-то возникает вопрос если каждый раз
приходится переписывать определение то может быть самим определением что-то не так потом
наверное здесь стоит отойти от этого потому что у нас есть прогресс вычислительной техники и
вообще говоря производительность так или иначе но постоянно растет производительсти в м растет но
это может быть и нельзя оставить как 100 процент на определение но в голове держать нужно
естественно дальше что еще можно взять за определение суперкомпьютера но вообще говоря
суперкомпьютер это такие мм которые обладает большой мощностью значит они обладают всеми
например большим количеством современные суперкомпьютеры большим количеством процессоров
здесь разные системы пожаротушение система охлаждения подвода энергия то есть электро энергия
поэтому вообще говоря это системы довольно-таки дорогие вот поэтому здесь тоже можно некоторым
смысле операция и на стоимость в какой-то мере это действительно дорогие электроны вычислительной
машины но опять же это нельзя ставить во во главе угла потому что что может быть например часто
или ну не часто в сети можно найти что у состоятельных у людей там есть мышки из золота или там
полированные кости древних животных инкрустировано бирлиантами и так далее это будет является дорогом
дорогим аж дорогой машины дорогим компьютером но будет ли являться суперкомпьютером ну ответ
очевиден или майнер может прийти или так значит да в какой-то мере естественно дорогие системы
но это опять же нельзя ставить как определение в конце 80 шутку было сказано горненом белом
и доном нельсеном и том что суперкомпьютер это тяжелая машина большая действительно это так и
всегда суперкомпьютеры занимали там одну или две комнаты действительно это тяжелые машины и
сейчас естественно большие суперкомпьютер занимает тоже не одну комнату на самом деле со всеми своими
системами но это конечно было сказано в шутку тем не менее тоже логично и в общем-то правильно так
что же на самом деле или что можно подразумевать под суперкомпьютером но в целом можно сказать что
или можно считать что суперкомпьютер это такая в м которая по своей мощности вычислительной
мощности на несколько порядков сильнее мощнее чем современно доступный персональный в м опять же
это не точное определение но хоть на что-то где-то можно ориентироваться итак это все что пока вот
говорится о том что такое да супер компьютер и о чем идет речь во что идет игра теперь
почему давайте коснемся того почему нужно изучать параллельно программируем не в том или ином виде
на самом деле можно сказать что вообще на в течение развития вычислительной техники и
программного обеспечения можно отметить скажем так три кризиса программного обеспечения и
связанного с развитием вычислительной техники значит сейчас считается что есть ну как не то
что читается все языки программируем там делится условно на две большие ветки это языки низкого
уровня и высокого уровня высокого уровня это когда тогда когда мы ну то есть когда при написании
программы мы не учитываем какие-то архитектурные тонкости или вообще архитектуру компьютера вот
низкого уровня это машины коды либо языки очень приближенные к машинам кадам это ассемблеры
всевозможные и в общем-то на заре вычислительной техники именно низкое программирование в общем-то
было единственно возможным и на это на основе низких но вернее языков низкого уровня можно
было писать программы и конечно же они писались но потом прошел путь там от ламп до транзисторов и
в итоге вычислительная техника стало более компактной более мощной и это все произошло вот
на рубеже там 50 и 60 годов и продолжалось 60 и оказалось что компьютеры позволяли писать уже
большие программы на ассемблерных языках это можно было делать но это было в общем-то довольно
проблематично писать большие программы но это было просто сложно плюс к тому же здесь есть вопрос
о переносимости программ с одной системы на другой и вот без существенной переработки кода вообще
говоря это было невозможно поэтому естественным был переход к языкам высокого уровня появились
языки алгол фортран си вы все должны знать по крайней мере слышали на чем-то даже и писали то есть
это модульное программирование который позволял писать больше все то есть программы которые
являются большими их можно было писать легче дальше прошел переход к большим интегральным схемам
появились процессоры вот опять же на самом деле получается как обычно тем людям которые
разрабатывают числительной системы в некотором смысле проще потому что программистам и тем кто
связан с софтвэ приходится их все время догонять но был переход на большие интегральные схемы и
что оказалось оказалось что да опять же на модульных языках скажем так можно писать большие
программы но здесь если говорить о каких-то больших проектов которые задействует большое число людей
сотни людей и большое количество строк кода там сотни тысяч миллион то опять же эти языки не
совсем подходят для этих вещей но в общем-то естественно опять же по требованию времени скажем
так выросла и объектно ориентирование программирования соответствующими языками все опять стало
нормальным программное обеспечение в некотором смысле догнала развитие железа и позволила
использовать себе возможности но это все было хорошо до каких пор примерно до рубежов до рубежа
веков наших почему потому что здесь вычислительная техника столкнулась с определенными проблемами
проблемами вдаль в плане дальнейшего своего развития повышение производительности в чем
же здесь дело до этого все развитие практически по крайней мере вот если представлять себе
персоналки то как было как происходило развитие все больше количества транзисторов умещалась на
одном кристалле что позволяла увеличить частоты и таким образом вы используя одну и ту же программу
подождав какое-то количество времени вы просто могли пользоваться той же программой с увеличенным
быстродействием почему то есть она считала быстрее потому что новый компьютер считал быстрее но
уменьшение транзисторов и увеличение плотности их нахождения на кристалле соответственно порождает
проблему проблему тепловыделения и уже наконец 90-х годов это на тепловыделение составляла там
больше чем 10 ватт на квадратный сантиметр если бы такими темпами пришло увеличение
тепловыделения то там в компании intel посчитали что уже ближе к концу нулевых годов тепловыделение
на кристалле было бы как в ядерном реакторе естественно что это невозможно правильно уже
тогда стали устанавливаться естественно охлаждающие системы кулеры и нужно в итоге
упёрлись и в частоту около 3 гигагерц и компоновка уже не позволяла увеличить не количество
процессора не количество транзисторов не частоту но здесь опять же стоит что сказать что вот развитие
процессор фоно шло двумя путями даже до двухтысячных годов первое это как раз
увеличение количества транзисторов это один путь но этого было мало потому что если сравнить
например частоты тактовые частоты компьютеров на заре то есть там 50 60 лет назад и тех которые
были около нулевых годов то их отличие в частотах было несколько тысяч раз ну скажем так 5000 5
мегагерца и там 2 с половиной гигагерца вот 5000 получается но производительность машин выросла
не в 5000 раз она выросла значительно больше и дело здесь не только в частотах тактовых частотах но
и во внутреннем устройстве процессор они стали сложнее у них так или иначе внутри был уже за
шит невидимый скажем так для обыкновенных людей какая-то степень парализма была параллельная
выборка данных из регистров либо конвертного устройства но так или иначе был еще второй путь
повышения производительности не только увеличение тактовой частоты но и внутренний парализм какой-то
внутри самих ядер но здесь все упёрлась физические принципы в определенные нужно было что-то
делать и в общем-то взяли опять решение которое уже было сделано но раньше использование много
ядерные машины взять несколько одинаковых процессоров это еще самый первый компьютер на
самом деле были уже многоядерные скажем так по современным слов современными словами просто
взяли несколько одинаковых процессоров соединили между собой вот получили компьютер который обладает
более высокой мощностью так появились многоядерные процессоры это произошло где-то в 2005 году то есть
ну я имею в виду бытовые бытовые процессоры и что оказалось что если вы используете старую свою
последовательную программу и запускайте ее на новом процессоре которым например с начала была два
ядра у нее производительность точно такая же как и на одноядерном процессоре ну потому что
частот у них одинаково и внутренней архитектуры очень похоже к примеру проходит еще какое-то
время еще 5 лет 4 8 ядер вы запускайте вашу программу и ее время работы не сильно уменьшается по той
же самой причине нужно значит каким-то образом воспользоваться тем что у вас есть многоядер
здесь возникает вопрос параллельного программирования как написать такую программу
которая будет пользовать использовать все возможности все потенциальные вычислительные
возможности вашей машины ну и здесь стоит отметить что все современные в общем-то машины
состоят из типичных ну более менее типичных процессоров которые ставится на обыкновенные
компьютеры или на ноутбуке то есть принципы принцип принципы распараллеливание как для
вашего ноутбука так и например для суперкомпьютера они будут одни и те же на самом деле но опять же
здесь стоит еще что отметить что все современные компьютеры ноутбуки даже телефоны они многоядерные
то есть многоядерность она вообще вокруг нас и вообще говоря не знать как использовать эту
многоядерность ну было бы плохо однако здесь какая проблема то возникает что автоматического
распараллельно то не существует почему по многим причинам во первых компьютер не может до конца
анализировать алгоритм второе не всякий хороший последовательный алгоритм можно хорошо распараллелить
и наоборот бывает так что хорошо распараллельный алгоритм он как бы вырастает из не самого
лучшего последовательного алгоритма поэтому здесь не все так очевидно и в некотором смысле здесь
нет какой-то автоматизации процесса здесь этому нужно научиться почувствовать это и вот с этим и
связано наше обучение итак какие есть вопросы примерно потому о чем я сказал есть ли они
теперь давайте вот коснемся тогда для чего нужны супер компьютер мы разобрали разобрали
с тем что это такое ну или примерно и теперь для чего они существует значит они существует
для чего для уменьшения времени каких-то расчетов то есть решение задачи временной
сложности обычно это очень часто какие-то научные расчеты которые мне требует определенного скажем
так времени окончания расчета но хотелось бы чтобы эти расчеты длились поменьше но таким
типичным опять же примером который у всех на слуху это прогноз погода вы все этим пользуетесь но
что за этим стоит на самом деле за этим стоит использование каких-то математических моделей они
бывают разные их много но их запускает на супер компьютерах на самом деле это просто программа
которые работают на супер компьютере входных данных у них данные со всего мира или там с
какой-то области земного шара данные температуру давление направление ветра там влажности и так
далее входные данные есть есть модель она запускается на супер компьютере для чего потому
что если взять типичную сетку для там атмосферы там километра на километр то есть кубический
километр и высотой там 30 25 30 километров то вообще чтобы покрыть какую-то область даже
всего шарика это будет например один миллиард ячеек таких если запустить это расчет на персоналке
то вообще говоря можно ожидать того что вы получите результат вашего расчета в момент когда вы
можете просто открыть окно и посмотреть эту погоду то есть это в общем-то не будет являться
прогнозом погода проще будет действительно убедиться этого очью вот поэтому нужно использовать
естественно супер компьютеры у них есть разные модели и вот разные модели они показывают разную
достоверность своего расчета или например там всевозможные расчеты начинает проблема
турбулентности до расчета движения динамики звезд в галактиках если например в одной галактике
11 миллиардов звезд например или там 100 миллиардов звезд и вот посчитать один временной
шаг или один шаг интегрирования для всего эту скопища звезд может потребоваться тоже один
год или порядка этого а нужно чтобы целом оценить динамику развития этой галактики нужны опять же
миллиарды шагов ну в общем-то время трудно просто представить даже так или иначе нужно
уменьшить время расчета в общем дни для всех задач это есть не для всех задач сейчас подходят
мощности но всегда для того или иного суперкомпьютера найдется задача которая ему будет по зубам и
которая будет успешно нем решатся вторая задача то как раз и вот да первая часть вашего курса она
вот будет именно с этим связано написание какой-то программы которая будет обладать высокой
эффективности высоким ускорением но не требует какого-то ну скажем так времени выполнения
определенного оно будет меньше чем при последовательном алгоритме вторая задача связанного
с обработкой большим объемом данных это может быть визуализация какая-то либо это просто
действительно обработка информации которая находится в интернет поисковики здесь определяющим
является то что человек является в общем-то медленным устройством и нужно за момент реакции
человека выдать какой-то результат то есть здесь есть уже определенная временные рамки ограничения
то есть некая интерактивность либо поиск либо визуализация то есть это одна примерно 1-2 секунды
или доли секунд но это вот с этим будет связано как раз вторая часть курса ну не только с этим но
примерно в этой плоскости лежит еще есть задачи управления там промышленными установками то есть
то что нужно компьютер на многопроцессорный компьютер управляет различными роботами на каком-то
предприятии производит определенные действия или в том числе включая станки хоть это с цифровым
управлением но это некоторым там в стороне но это тоже сюда можно как-то привлечь и еще и задачи
это системы высокой надежности например если это речь идет о космическом парате там что высокая
радиация и недопустимость каких-то ошибок в вычислениях поэтому если это необходимо произвести
какие-то вычисления там пересчет новой орбиты то есть какие какой импульс нужно дать сейчас это
часто выполняется именно борту они на земле ну и в общем-то нужно что сделать запустить эту
программу на нескольких одновременно нескольких процессорах получить разные или одинаковые
результаты но их должно быть несколько кстати больше чем сколько если несколько несколько
ответов 1 или 2 хватит но минимум хорошо минимум 3 да если 2 ну да а если 3 разных
тоже плохо ну ладно их больше двух должно быть естественно чтобы было понятно очень
маловероятно то что у вас на трех машинах будет все одинаково абсолютно разные результаты
абсолютно разные да вот поправлю значит это последняя часть курса и да вот в первом первой
части вот если вот здесь в первой части здесь у нас говорится о том что наша компьютерная
система должна быть надежной и бесперебойной то во второй части курса здесь уже вносится то что
она может отказать может быть возможность отказа и это тоже уже лежит внутри скажем так фреймворк в
который вы будете изучать то здесь предполагается что система может отказать в первой части обычно
это не предусматривается считается что она абсолютно надежно в второй части есть частичная
автоматизация на пополам решена проблема параллельность автоматического создания параллельности
это она есть темно немножко и в упон и пи но не полностью вы можете там рассматривать ну например
в упон и пи есть распараллельную циклов можно сказать что это распараллеливание в принципе
автоматическое но в целом как бы алгоритм да частично где-то можно а в целом это нужен
человек пока еще так да по поводу теперь давайте перейдем знаете к чему к рассмотрению
классификации систем почему потому что это тесно связано в том числе с библиотеками программного
программирования mpi упон и пи там не типосекс и других которые вы услышите то что они связаны
именно с тем а что это за супер компьютеры и почему именно эти библиотеки нужно опять же изучать значит
систем классификации их тоже много остановился на той которая в принципе описывает все машины она в
общем-то показала свою состоятельность это классификация флина но она вот основана на таких
определениях по-английски это будет single multiple instructions in data то есть одни одно много
инструкции и данные и вот из этих вот если взять первые буковки то из них можно составить вот
такие комбинации ну так получается что оказывается что вот с асд получается single instruction single
data это вот обыкновенные последовательные машины у которых есть но инструкция значит прос
программа дейта это значит какие-то там переменные которые с которыми работает программа и оказывается
что у вас это просто последовательный код который работает с одним потоком данных условно дальше
с амд то есть это одни данные и множественные ой множественные данные и вот одна инструкция это
значит такие векторные вычисления грубо говоря представьте себе два столбца вектора да там у
них там может быть 100 координат и вот операции сложения множество данных это их координаты
этих векторов и на выходе тоже получать сразу 100 ответов то есть такие машины они в основном ну
на самом деле современных процессорах такое есть внутри и вот векторные конвертные машины не
были очень популярны 70 80-е годы как в сша так и советском союзе вот поэтому они существуют а
вот машин которые работают над одним набором данных ну в общем-то говоря они широко не
представлены они там в отдельных скажем так реализация есть но они вот как я сказал широко
не представленных пока вот можно не рассматривать на самом деле современные машины они сидят вот
в этом классе множественная инструкция которая действует над множественными данными ммд это вот
все остальные высокопроизводительные современные машины то есть все что сейчас есть вот в этот
класс попадает но этот класс делится еще на две ветки значит это машины с массовым параллелизмом
смотрите это вот машины с распределенной памятью называется почему я пишу здесь на английский
потому что часто и по-русски говорят без три билет машинцы или вы будете это встречать в
литературе очень часто это попадается русский и английский аналог по-русски я скажу английский
вот на доске это часто встречается потому что это все на самом деле пошло все эти определения не
у нас эти были сделаны поэтому нужно еще источник по-хорошему смотреть значит что это такое это вот
кластеры что такое кластеры это просто супер компьютеры которые построены на скажем так бытовой
элементной базе на обыкновенных бытовых процессорах они появились вот на рубеже 80 90
годов как раз до этого были специализированы супер компьютеры а после этого начали появляться
и вытеснять специализированного кластеры это значит что у нас грубо говоря обыкновенные
однопроцессорные компьютеры соединены какой-то сетью они могут быть специализированы немножко
отличаться конечно бытовых сама сеть может быть быстрой так или иначе можно в голове себе именно
так и представлять его для работы с такими системами я сейчас сразу скобочек скажу и
предназначена библиотека mpi когда вот у того или иного компьютера нет прямого доступа к
оперативной памяти своего соседа или какого-то еще компьютера и второй широкий класс это машины
с общей памятью shared memory machines вот они и называется еще symmetric multiprocessing или uniform
memory access то есть это однородный доступ к памяти или симметричный это одно и то же связано с
тем что у вас процессоры они подсоединены к одной оперативной памяти и по времени доступа
к этой памяти у них одинаковые возможности есть машины с неоднородным доступом к памяти там
схемка чуть-чуть попозже будет я поясню это когда у нас дело в том что когда много процессоров
подсоединяется к одной оперативной памяти у нас есть шина данных условно да вот это является
бутылочным горлышком для этой системы нельзя сейчас технические возможности не позволяют там
скажем так 10 тысяч процессоров подключить к одному блоку оперативной памяти это не позволяет
технические возможности поэтому ну не 10 тысяч этого совсем загнул на самом деле там например 128 вот
а чтобы подключить еще 128 нужно их через какой-то коммутатор подключать и вот когда у вас идет
а коммутатор позволяет делать то что у вас то или иной процессор либо к своему блоку оперативной
памяти либо к памяти который идет сигнал через коммутатор ну и через коммутатор время доступа
будут побольше поэтому называется non-uniform то есть неоднородный доступ к памяти и вообще под
памятью здесь подразумевается именно оперативная память и есть еще системы CCNUMA то есть cash
coherent с этим вы тоже столкнетесь когда будете программировать на OpenMP там есть такая проблема
синхронизации потоков там есть проблема кэш памяти когерентности кэш памяти называется такая
проблема она может быть решена программно может быть решена на железном уровне вот это решается
на железном уровне это работает быстрее но значительно дороже чем системы не обладающие
такой возможностью вот теперь вот по схематике с массивным парализмом как я уже сказал каждый
этот вот кластер кластер состоит из узлов современный кластер состоит из такого узла гибридного
то есть он может включать себе несколько одновременных то есть несколько процессоров которые
подключены к одной оперативной памяти то есть узел может представлять себе из себя машину с
общей памятью и в которой также могут находиться видеокарты но представим себе пока что без такого
усложнений каждый узел представляет себе просто одно процессор на одноядерную машину одна машина
вторая третья они себя представляют просто обыкновенный компьютер однопроцессор и
соединены интерконнектом то есть интеркоммуникационной сетью эта сеть должна быть довольно-таки
быстрой потому что как вы увидите и на лекции успею надеюсь показать и это вы можете ну по
крайней мере должны проследить на семинарах что сеть влияет на самом деле на ускорение работы
вашей программы то есть это кластер и а теперь вот каждый узел может состоять из машины с
общей памяти вот из такой когда у нас несколько ядер подсоединены к одной оперативной памяти а
вот это у нас неоднородный доступ к памяти например здесь ядро или несколько ядер у них
есть прямой доступ к своей оперативной памяти но также у них есть доступ через коммутатор к
другому блоку оперативной памяти но вот это время дохода сигнала или передачи данных от
памяти до ядра через коммутатор но естественно это может быть несколько раз больше чем напрямую
получается у нас неоднородный доступ но так или иначе это можно подключать большее количество ядер
какие-то вопросы я может быть немножко тороплюсь чтобы успеть но давайте если что-то непонятно
давайте задавайте вопросы по этому материалу я пойду дальше что нас еще хотят бы кое-что успеть
ну можно добавить да то есть на самом деле если современные как я уже сказал суперкомпьютер то
есть вот такая штука вместе с видеокарточкой да у нее через дополнительные скажем так микросхемы
как сказала каде через южный мост идет общение потому что у нас там должна быть перекачка данных
видеокарту это вы тоже с этим столкнетесь это тоже является неким бутылочным горлышком узким
местом в этой системе и вместо однопроцессорной машины сам в простейшем случае у нас будет
многоядерная машина с общей памятью еще с видеокартами то есть это современный суперкомпьютер
чего с нума а это просто машина с общей памяти просто нужно смотреть на ее документацию это что
системы скорее всего это будет система с неоднородным доступом с памяти современно
системы обычно именно такие которых 256 там ядер однородной трудно обеспечить но это
просто вот если мало вот например у вас компьютер это будет однородный доступ там 4 8 ядер скорее
всего так и есть а вот там побольше 128 256 скорее всего там будет неоднородный доступ но конечно
это нужно смотреть на документацию как сделано то есть как
если есть сомнения мы открываем документацию там все написано что там у них такой-то или
такой-то по скажем так по внешнему виду не скажешь но то есть компьютер и компьютер это
нужно смотреть устройство реальное устройство и как его как он был сделан скажем так на заводе
или на фабрике есть еще вопросы так вот про внутренний прорелизм теперь смотрите сам смысл
параллельных вычислений в чем состоит вот у вас есть параллельно машина у нее есть допустим теперь
давайте мы будем говорить об mpi то есть будем считать что у нас есть кластер и каждый узер
кластера это у нас однопроцессорная машина для простоты теперь у нас программа как она
должна использовать всю мощь этого кластера например у него 10 ядер значит каким-то образом
нашу программу нужно написать так чтобы отдельные части считались на каждом из 10 процессоров
тогда то что считается а эти все части должны быть в каком смысле независимы друг от друга чтобы
их можно было запустить одновременно вот такое свойство алгоритма когда отдельные его части
можно запустить для вычислений на разных процессорах называется внутренним прорелизмом это не связано
не самой не самим суперкомпьютером не с библиотекой параллельных вычислений это связано с самим
алгоритмом он обладает таким свойством что его можно распараллелить вот такой свойство называется
внутренним параллелизмом и вот давайте теперь об этом дальше поговорим на чем основано или скажем
так что нужно достигать что нужно достичь чтобы понять что мы делаем все хорошо так
косноязычное оно примерно по смыслу похоже нам нужно достигнуть выигрыша во времени сделать
так чтобы программа или алгоритм считался быстрее вот это вот и характеристика говорит о том что
наш наш программа считает быстрее это называется ускорение ускорение это просто отношение времен
времени работы этой программы на одном процессоре или на одном ядре я буду иногда говорить либо
и д Wahl процессор делённый на время работы на нескольких ядрах но очевидно что если у нас все
хорошо то время работы на нескольких ядрах должно быть меньше чем время работы на одном
ядре правильно в идеальном случае если у нас есть 10 ядер значит время в идеальном случае время
работы этого алгоритма, он будет в 10 раз меньше.
Ускорение будет десятки равно.
И вот идеальный случай показан здесь, в штрихпунктной
линии.
На графике ускорения от количества процессов у
нас будет безсектристо при одинаковом масштабе.
Ну, в общем-то это понятно.
Однако в реальности не всегда все так гладко.
В реальности у нас в какой-то момент график этого ускорения
будет отклоняться от этой безсектрисы.
И на это есть несколько причин.
О причинах мы тоже поговорим чуть позже.
Эта причина, ну сейчас если так коротко, то причина
связана с самим алгоритмом, что мы не можем полностью
распараллелить наш код.
Вторая причина лежит в области как раз интеркоммуникационной
сети.
Потому что она обладает определенными свойствами,
задержками временными.
И она накладывает как раз некие ограничения на
рост ускорения, на рост на нашем графике ускорения.
Вот это вот самый первый параметр, который вы будете
смотреть на семинаре.
Потому что нужно достигать две цели при написании
параллельной программы.
Первая цель это правильный ответ.
Ну что такое правильный ответ?
Либо он совпадает с аналитикой, либо он совпадает с ответом
полученным на последовательном алгоритме.
То есть, что ваше распараллелие не вносит каких-то деструктивных
действий.
Что ваш ответ остается.
А вторая цель – это получить ускорение.
Потому что если у вас правильный ответ, но у ускорения такой
же или меньше, чем в последовательном алгоритме, смысла нет распараллеливать.
Поэтому ускорение – это один из самых важных параметров,
который вы будете анализировать и на семинарах вы будете
строить вот такой график ускорения от количества
процессов.
Есть еще один интересный параметр, он называется
эффективность работы вашего алгоритма.
Это ускорение, деленное на количество процессов.
Это на самом деле просто степень загрузки физических
ядер.
Если у нас ускорение в отдельном случае равно
P, то эффективность будет равна единичке, то есть 100%.
Это значит, что все ядра работают в полную мощность.
Если по какой-то причине ускорение у вас равно меньше,
представим себе, что это равно P пополам, то есть мы
на этом графике лежим на середине между идеалом
и ноликом, вот здесь вот точка, то у нас эффективность
будет 0,5, то есть 50%.
Значит, по какой-то причине ваши ядра работают не в
полную силу.
Либо это связано самим железом, либо это связано самим алгоритмом.
Тут тоже есть разные причины.
Но это тоже показатель того, как хороша ваша программа.
И вот если вернуться обратно, для чего предназначены
суперкомпьютеры, первая часть, уменьшение времени
работы, то здесь хотелось бы достигать именно высокого
ускорения при высокой эффективности.
Потому что, как вам сейчас уже говорили в самом начале,
у вас будет доступ к удаленным машинам.
Обычно это машины какого-то коллективного пользования.
На этих машина выделяется, здесь маленькие машинки,
а есть большие, там много людей, большие задачи решаются.
И вот владельцы этих центров коллективного пользования
хотели бы, чтобы эти машины использовались наиболее
эффективно.
Эффективно это значит, что как можно больше ядер
использовалось, как можно больше высокой эффективностью.
Вот эффективность, вот здесь вот она и сидит.
Вот она эффективность, чтобы можно запустить программу
на 100 процессах, но она будет использовать 1% всех мощностей.
Это не эффективная программа, это не целесообразное использование
электроэнергии и вообще ресурсов этого центра коллективного
пользования.
И есть еще один параметр, такой масштабируемость
алгоритма.
Вот здесь он показан, например, что это такое?
Насколько ваш алгоритм может быть запущен на как
можно большем количестве вычислителей, то есть ядер
или процессов.
Например, ваш график ускорения ведет себя следующим образом.
И у него есть очевидный максимум.
Правильно?
И вот максимум, можно, то есть дальше этого максимума
вы по ускорению не продвинетесь.
Ускорение меньшее можно получить при меньшем количестве
p, чем p со звездочкой, то есть вот здесь и вот здесь.
Но очевидно, что такое количество процессов, то
же не целесообразно использовать, потому что такое же ускорение
можно получить на меньшем количестве.
Ну вот и говорится, что это масштабируемость, то
количество, то есть можно сказать, что ваша программа
масштабируема вот до такого количества p со звездочкой
процессоров, почему?
Потому что она на этом количестве достигает максимального
ускорения.
То есть какое минимальное число ядер, при котором
вы получаете максимальное ускорение, так? Дальше нет
смысла уже расти. Это вот масштабируемость алгоритма.
Теперь давайте поговорим о том, что может приводить
к тому, что ваш график ускорения отклоняется от идеального.
Первая причина – это когда вы не можете полностью
распараллелить ваш алгоритм. Это самая первая и фундаментальная
причина. Мы посмотрим сейчас, почему это так. Почему не надо
браться за те алгоритмы, которые полностью или почти
полностью нельзя распараллелить. Эта штука называется законом
ДАЛА. Вот представим себе, вот этот прямоугольник
– это алгоритм. И вот представим себе, что это одна часть нашего
алгоритма. И здесь альфа – это последовательная часть,
ее нельзя никаким образом распараллелить. А беленькая
часть распараллелить можно. Вот если запустить наш алгоритм
на одноядерной машине, мы получим время T1. То есть
это время работы нашего алгоритма на последовательной
программе. Это все хорошо. Теперь, если мы запустим
этот же алгоритм на многопроцессорной машине, то какое время
мы получим P процессов? Обычно можно оценивать, ну
на лекциях это как будет. P – это обычно процессоры,
то есть это P – это процессы. S – это ускорение от speed-up.
Слово speed-up. Здесь используется не acceleration, как в физике,
а вот все-таки другое слово будет speed-up. Поэтому P – это
количество процессов. Какое будет время? Альфа у
нас никак не распараллелится. То есть альфа T1 останется,
а вот этот белый прямоугольник, его можно поделить на части.
Он может быть распараллелен, то есть время может быть
уменьшено в P раз. Ну и плюс еще некие накладные расходы.
T, S – это время передачи сообщений. Поскольку у нас сообщения
работают, вернее процессы работают на кластере, они
между собой могут обмениваться, и обычно так и происходит,
поскольку они решают одну задачу. S от слова send, то
есть передача сообщений – это накладные расходы.
Вот такое время для нашего параллельного магаритма.
Теперь давайте оценим ускорение. Ускорение – это нужен
T1 поделить на вот эту штуку. Пока кажется громоздкой,
но можно рассмотреть всякие такие граничные, пограничные
варианты. Например, если у нас все можно распараллелить
и у нас нет накладных расходов, то если посмотреть вот на
эту формулу… Ой. Короче, S будет равно P. Ну в общем,
S равно P. Альфа равно 0, и тогда у нас и T, S равно 0, тогда
у нас получится T1, грубо говоря, на T1. В общем, это идеальный
случай, получается, S равно 5. Потом, если у нас время
накладных расходов больше, чем время расчета последовательного
алгоритма, есть ли смысл даже из логики параллелить
или нет? Ну в общем-то нет, потому что ускорение будет
явно меньше единицы, и в общем, нецелесообразно
это делать. Интересным случаем представляется, когда
у нас накладных расходов нет, а вот альфа, то есть
та часть, которую нельзя распараллелить, не равна
нулю. То есть есть маленькая часть, которая всегда будет
читаться последовательно. Тогда в этом случае ускорение
будет представлять себе вот такую формулу. Она
простая, но что она говорит? Давайте рассмотрим график
ускорения в зависимости от альфа, ну при P, например,
100. Вот сюда 100. У нас 100 ядер, это довольно-таки приличное
число. И давайте теперь смотреть. Когда у нас альфа
равно нулю, то ускорение у нас будет идеальным, будет
равно 100. Альфа равно единицы, ускорение падает до чуть
больше 50%. То есть оно падает почти в два раза. Альфа равно
двойке, падает в три раза. Вот альфа равно пяти, падает
больше, чем в пять раз. То есть маленькая часть нераспараллеленного
алгоритма приводит к сильному уменьшению ускорения работы
программы. И поэтому даже если у вас есть, ну, пара
процентов, ну ладно. Но вот как только уже это составляет
существенную часть, несколько процентов там до десяти,
это прям сильно все портит. Или такой еще график, смотрите.
К чему стремится максимальное ускорение при как можно
большом количестве процессоров? Вот P стриминг бесконечности,
то S у нас стремится к дроби. Один поделит на альфа. Давайте
посмотрим на графике. Альфа равно пяти. Зеленый график.
P большое, ну две тысячи и считаем, что это почти бесконечность.
Ускорение у нас ограничено двадцатью. Альфа равно десять,
ограничено десятью. Альфа равно двадцать пять, ограничено
двумя. И вот представьте себе, половину программы
можно распределить, половину нет. Вы берете супермашину
с бесконечным количеством вычислительных ядер. И
вы как не хотите, но не можете достичь ускорения больше
двойки. Никак. Вот о чем говорит закон Амдалла. Поэтому здесь
нужно очень четко понимать, какие задачи можно взять,
какие нельзя. Какие можно распараллелить, какие нельзя.
Какие можно хорошо, какие параллелиться плохо. Это
самый простой закон. Самое первое, на что нужно обратить
внимание, когда вы соберете что-либо, там распараллелить
какую-либо программу. Нужно сначала проанализировать,
можно или нет. Все, на сегодня достаточно. Что успели, то
успели. Думайте.
