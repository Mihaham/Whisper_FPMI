Прошлый раз мы обсуждали логигмическую память при
детерминирных вычислениях. Мы обсудили две группы задач.
Одна группа это разного рода арифметические операции над двоечными числами,
а вторая группа это разного рода синтактический анализ, то есть
проверка баланса скобок и так далее. Но теперь я хочу еще про одну задачу
рассказать. В принципе тоже включается в некоторый более широкий контекст.
Продолжим имирацию с прошлого раза. Третья область, про которую мы поговорим,
это теория графов. Про графы очень много, задач НП полных и всякие
другие задач интересных очень много. Но сейчас поговорим про такую
стандартную задачу. Она называется U-path. U от слова undirected, то есть
ненаправленной, неориентированной. Это множество таких троек из графа
начала и конца, что в неориентированном графе
есть путь из S в T. Если буквки U нету, то это будет просто PATH, то же
самое, что в ориентированном графе. Но из точки зрения времени, значит, и та и
другая задача. Давайте я их сразу напишу. Просто PATH. В общем, то же самое, только
в вор графе. Но в ориентированном графе и, соответственно, путь тоже должен быть
ориентированный. В точки зрения времени работы эти задачи не сильно друг от друга
отличаются. Решается примерно одинаково. Наверное, вы это изучали,
поиском, в ширину, глубину. Много есть разных вариантов, но можно описывать так,
что у нас есть граф, у нас есть вершина S, и мы красим вершину S в какой-то цвет.
Помечаем. Дальше, на следующем этапе помечаем все соединенные с ней вершины в
неориентированном случае, а в ориентированном все, в которой из нее идет
ребро. Ну и дальше для вновь помеченных вершин делаем все то же самое. И если
рано или поздно процесс дойдет до T, то значит, T достижимо. А если в какой-то
момент у нас новых вершин не появится, а T все еще не будет отмечено, значит,
T недостижимо. Этот алгоритм довольно хороший, но проблема в том, что он
требует пометок на графе, то есть он требует примерно линейной памяти.
То есть стандартные алгоритмы требуют линейной памяти, хотя и
работают за полинамеральное время. Вот. Но окажется, что с точки зрения
алгоритмической памяти неориентированный случай и ориентированный случай
друг от друга отличаются. Вот. Но ясно, что и то, и другое лежит в НЛ.
Мы еще не знакомились близко с этим классом, но сейчас как раз с ним постепенно
переходим. Ясно, что оба языка лежат в НЛ. Но хотя, может, не очень ясно, чтобы
совсем ясно, там нужно немножко другое определение НЛ дать. Но в принципе, можно
сказать так, что у нас будет счетчик, все-таки можно сказать, почему ясно, у нас
будет счетчик числа шагов. И дальше мы начинаем с С и просто начинаем
недетерминированно идти по ребрам. То есть сколько там ребер выходят, столько у нас
вариантов действия, и мы один из них выбираем. И делаем столько шагов, сколько
вершин у графия. Дальше, если есть какой-то путь из С в Т, то есть путь без циклов,
потому что все циклы можно удалить. Этот путь из циклов будет не длиннее, чем
число вершин в графе. Поэтому можно сделать N шагов. Если хотя бы одна ветка
придет в Т, значит путь есть. А если ни одна не придет в Т, значит пути нет.
И это как раз то же самое, что происходит в НЛ. Поэтому действительно оба языка
лежат в НЛ. Но дальше есть довольно сложная
теорема Рейнгольда, что U path
на самом деле лежит в L. Что может каким-то образом на логографической памяти
именно для неориентированного графа понять, лежит он в L или нет. Но это реально
сложная теорема, она доказана не так давно, в 2005 году, уже в этом веке. Используй
довольно сложную технику. Я ее иногда рассказываю на спецкурсах, но это
занимает 3-4 лекции. Там нужно изучить много специальных конструкций. Но знать
эти мнения полезно, потому что, например, можно с ее помощью про какие-нибудь другие
задачи тоже доказывать, что они лежат в L. Например, следствие такое,
что 3 лежит в L, но 3 означает, что граф является деревом. Вот почему, но что такое
дерево вообще? Дерево связано с графом без циклов,
вот. Это даже более простой шаг, что просто проверка
на связанность лежит в L. Потому что проверка на связанность означает, что мы
для каждой пары вершин проверяем, есть между ними путь или нет. Ну и, соответственно,
можно устроить перебор. Да, 3 это немножко более сложно, более простое следствие,
что язык связанных графов connected лежит в L, потому что нужно по циклу устроить перебор.
Но если примитивно делать, то нужно выделить перебор под X, перебор под Y, и дальше проверка
наличия пути из X в Y. Ну и, соответственно, можно перебирать X, перебирать Y и
на одной и той же памяти проверять, соответственно, всех вершин N. Поэтому тут
у нас логарифм N битов занят, и тут логарифм N, и еще какой-то большой логарифм на эту проверку.
Поэтому получается логарифмическая процедура. Ну а после этого проверка на древесность будет
работать так, что такое дерево. Значит, по определению, связанный граф без циклов.
Соответственно, мы сначала проверили связанность, а потом проверили, что нет циклов. Ну как это проверять?
Можно что-нибудь другое проверять. Например, можно проверять, что есть такая теремма,
что граф — это дерево тогда и только тогда, когда он связан, и в нем число ребер одно меньше,
чем число вершин. И вот это вот число ребер гораздо проще подсчитывать, чем проверять,
что нет циклов. Вот. Можно, если только в рамках связанности оставаться, можно такое проверять,
что сам граф связан, но если любое ребро из него вычеркнуть, то получится несвязанный граф.
Это тоже критерий. На древесность можно его проверять. Что еще раз?
Ну понятно, как это будет сделано, что когда мы проверяем, когда мы хотим узнать, есть ли ребро в том графе,
который мы проверяем, то мы сначала смотрим, есть ли оно в исходном графе, а потом смотрим,
не совпадает ли оно с тем, который вычеркнули. Вот. Если есть и не совпадает, то оно есть,
а если есть и совпадает, или если его изначально не было, то его нет. Вот. В общем, так или иначе это
можно проверить. Ну и другие такого же рода вещи, там какая-то уницикличность, там еще чего-нибудь.
Это все можно проверять. Там двудольность даже можно проверить. В общем, это все можно сводить
к наличию пути. Вот. Хорошо. Значит, соответственно, вот, а для пути в ориентированном графе ничего такого нет.
То есть в то же время задача ПФ, ориентированная, будет НЛ полной. Вот. Это мы обсудим попозже,
почему это так. Но вот тут видна некоторая разница, что в неретеронографе это Л, а в ориентированном
это НЛ полная, и гипотетически это не ВЛ. Вот. Это мы поговорим попозже. Да. Ну, относительно
логарифмической, конечно, да, нет. Потому что это все внутри П происходит, поэтому старую
полинарную нельзя использовать. Вот. А относительно логарифмической, что конкретно это означает,
вот, поговорим попозже. Потому что сейчас я хочу сказать следующее, что на самом деле то, что вот
проверка надревесности лежит в Л, можно доказать более элементарными методами, и довольно красиво.
Значит, без ссылки на тиреморинголь, да. Элементарное доказательство соответственно
того, что проверка надревесности лежит в Л. Так. Ну, смотрите, значит, что мы знаем про дерево,
и что мы умеем проверять точно. Ну, а мы умеем проверять, что в графе на одно, значит,
ребер на один меньше, чем в вершине. Ну, то есть, вот это как первое соображение, значит, что можно
проверить. Значит, можно проверить, что в графе число ребер на единицу меньше
числа вершин. Ну, это как бы у нас граф не задавался, уж ребра мы как-нибудь сможем посчитать
на логарифмической памяти. Заведен для них счетчик. Да, если он смотрит за смежностью, то мы
просто идем по ней, считаем единица. Ну, может, пополам делим, если она симметричная. Если у нас
просто список ребер, то мы просто идем по нему и считаем, сколько там ребер. В общем, вот это вот
можно проверить на логарифмической памяти. Значит, дальше. И это, конечно, еще не критерий. Потому
что что может быть? Либо это дерево, либо это несвязанный граф, у него несколько компонент,
и на самом деле, грубо говоря, не совсем точно, но если грубо говорить, там будет циклов столько же
на один меньше, чем компонент связанности. Это не совсем точно, но это, интуитивно говоря, за счет
того, что мы одно ребро убираем, у нас граф распадается. Мы его должны добавить где-то еще, за счет
цикла появится. И, может быть, там что-то еще делаем. Так, в общем, что точно можно сказать? Значит,
что если при этом, значит, если это не выполнено, значит, точно не дерево. Если это выполнено,
то, вообще говоря, есть два варианта. Может быть так, что там есть несколько нетривиальных
компонент, в каждой из которых есть ребра. Тогда, соответственно, в каждой компоненте
число ребр будет меньше, чем m-1. Значит, если это неверно, то есть два варианта. Да, значит,
либо в каждой компоненте связанности число ребр строго меньше, чем m-1, где n число вершин
во всем графе. То есть, n-1 число ребр во всем графе. Либо у нас есть несколько компонент,
связанных с ребрами, тогда в каждой из них меньше, чем m-1 ребро. Либо есть изолированные вершины,
либо есть изолированные вершины, которые ни с какой другой не соединены. Но, соответственно,
наличие изолированных вершин тоже можно проверить. Если там вообще в графе больше,
чем одна вершина, но при этом есть изолированная, значит, он тоже не дерево. Получается, что вторую
часть наличия изолированных вершин тоже можно проверить на логеретнической памяти. Тоже проверяется,
n это число вершин во всем графе. Соответственно, m-1 это число ребр во всем графе. Либо у нас
ребра разбежались по разным компонентам, тогда в каждой компоненте меньше, чем n-1. Либо они все
собрались в одну, но тогда, если это не дерево, значит, есть изолированные вершины. Ну вот,
соответственно, если есть изолированные вершины, то это тоже мы проверим, это будет не дерево. А дальше
в первом случае можно начать проводить некоторый обход. Тут, значит, можно устроить обход графа.
Значит, я сейчас так неформально нарисую, а потом говорим формально, что это значит. Значит,
вот два варианта. Тут пусть будет дерево, а тут пусть будет не дерево, но, например, такой
нециклический граф. Это, что в графе число ребер на единицам меньше, чем числа вершин.
Ой, да, сейчас, правильно, это да, не то. Сейчас, правильно вы говорите, не то я написал. Если,
наоборот, если это верно, но граф не дерево, если это верно, но граф не дерево,
то тогда вот два варианта. Спасибо за уточнение. Вот, значит, смотрите, я тут так хорошо нарисовал
на плоскости, и такие вот графы можно обходить по правой-левой руке. Тут берем, берем вот так вот
обходим. Значит, тут всюду есть там какое-то направление движения, и получается, что мы на
самом деле каждый, значит, каждый ребро мы проходим два раза, если это дерево, значит, один раз в
одну сторону, другой раз в другую. Ну, я написал планарный, да, сейчас поговорим о том, как это вообще в
общем случае делать. Вот, а вот если, например, тут будет один цикл, то тут получилось, что не все
ребра прошел два раза туда-обратно. Вот, и вообще, если вот только на этот обход смотреть, то может
показаться, что нужно просто его устроить этот обход и посмотреть, прежде чем мы пришли на то же
самое ребро в том же самом направлении, мы все ребра прошли туда-обратно. А как это проверить?
Ну, нужно посчитать, вернее, что мы там два, наверное, минус один шагов сделали, прежде чем
вернуться обратно. Вот, но, к сожалению, только для планарных графов это верно, что, действительно,
если это дерево, то мы пройдем два раза туда-обратно по каждому ребру, прежде чем вернемся на исходное,
а если это не дерево, но планарный граф, тогда мы меньше, чем два раза пройдем по некоторым
ребрам. Вот, но, к сожалению, в общем виде для непланарх это неверно. Вот, неверно, что мы, что если мы
прошли два раза по каждому ребру в одну и другую сторону, то этот граф был деревом.
Ну, это вы правильно говорите, да, и вообще у нас, на самом деле, это такая иллюстрация, да, а на самом деле у
нас нет никакого расположения на плоскости, и мы вам ничего не можем сделать. Вот, поэтому, значит,
без рисунка на плоскости обход делается так. Значит, как устроен обход? Как устроен обход?
Значит, после, значит, в отличие от самого графа, обход ориентированный, да, то есть у обхода есть
направление. Соответственно, после ребра и ежи, значит, обход идет в точку K,
которая равна следующему, да, значит, K у нас минимум из х больше и таких, что есть ребро и ежи в х,
вот, если это множество не пусто, да, то есть если ежи соединена с какой-то вершину,
которой номер больше, чем и, тогда, соответственно, минимально из таких вершин ребро идет, значит,
если это множество не пусто. Но это и, соответственно, K равнеется просто минимум из таких х,
что gx лежит в е, соответственно, иначе. Вот, в крайнем случае, если у нас g это вообще висячая вершина,
да, то тогда обход пойдет обратно в и. Вот, но можно расставить номера так, чтобы вот этот обход
соответствовал тому правилу, но более-менее номера так и должны быть расставлены. Значит,
тут один, два, три, четыре, пять, шесть, семь, восемь, девять, десять и дальше одиннадцать,
двенадцать, тринадцать. Да, тогда, смотрите, мы начинаем с один два, начинаем с один два,
но два это висячая вершина, поэтому мы собираемся только с единицей, мы возвращаемся с единицей.
Дальше, смотрите, мы пришли из двойки, соответственно, мы идем в минимальный следующий номер, который
соединен с единицей, это тройка, в данном случае. Да, возвращаемся все обратно, потом в четверку,
потом обратно, потом в пятерку, потом это уже не висячая вершина, мы идем в минимальную,
с номером большей единицы, с которой соединена еще пять, а дальше соединен шестой из одиннадцатой,
поэтому выбираем шестой. Ну и так дальше. По этому правилу, теперь из шестой нужно минимальную,
с номером больше пяти, которая соединена, это из семьи и восемь, это семь получается. Ну и так
далее. В общем, обход будет завершен, и мы, соответственно, обойдя все ребра, два раз туда
обратно, придем снова вот сюда. Ну это пресне еще важно. А понимаешь, что мы завершились,
когда то ребро, с которым мы стартовали, снова пройдено в том же самом направлении,
с которым мы стартовали. Вот, тогда смотрите, значит, ясно, что при таком обходе,
значит, при таком обходе каждое ребро мы можем пройти максимум дважды. Потому что если мы его
прошли трижды, значит, два раза было в одном направлении, значит, мы уже зациклились.
Получается, что при таком обходе, при таком обходе каждое ребро, каждое ребро пройдено
максимум дважды. Нет, мы как раз, мы, конечно, можем зациклиться, но нас именно интересует
размер цикла. Мы не только можем, но и должны зациклиться. Но утверждение, что это случится не
позже, чем мы два раза пройдем по каждому ребру. Вот, соответственно, если, да, теперь вот в этом
случае, значит, если число ребра меньше чем n-1 в компоненте связанности, да, ясно, что при обходе
мы также не можем выбраться за пределы компонента связанности. Да, мы только по ребрам будем ходить,
поэтому за пределы компонента не выберемся. Вот, да, соответственно, при этом, при этом он останется
внутри компонента связанности. Вот, ну, соответственно, получается, что если ребер меньше чем n-1,
то тогда шагов будет меньше, чем 2 на n-1 до зацикливания. Значит, если ребер меньше, чем n-1,
то тогда получается, что длина цикла должна быть меньше, чем 2 на n-1. Вот, ну, и остался
доказать, что с деревом все-таки все будет нормально, независимо от нумерации, да, это вот,
я там пронумерал так, чтобы именно тот обход, который я нарисовал, получился, а так при любой
нумерации вершин на дереве будет цикл, проходящий по каждому ребру, два раза. Да, то есть, соответственно,
если, значит, если ребер в точности n-1 и это дерево, значит, и это дерево, то тогда получается,
что длина обхода будет 2. Да, не, меньше либо равно в точности равно 2 на n-1. Вот, ну, это доказывается
более-менее по инукции. Да, вообще, давайте я попробую сношу руменифировать на картинке,
потом обсудим, как это превратить в формальное рассуждение. Ну, значит, на самом деле удобно, да,
хотя префрес даже неважно, да, неважно, откуда мы начинаем. Вот, пусть есть, значит, пусть есть
какой-то корень, значит, мы одну вершину выбрали, и это у нас будет корень. И дальше есть у этого
корня, значит, есть непосредственные потомки, значит, ну, например, вот, и j и k. И, соответственно,
у каждого потомка есть какое-то поддерево. Вот, и, например, значит, например, мы начали
с ребра из r в i. Смотрите, значит, по правилам, если это не висячая вершина, а тут еще что-то есть,
то тогда дальше обход должен быть, то есть дальше шаг из i должен быть не обратно в r, а куда-то
здесь внутри поддерево. Да, то есть если есть еще какие-то соседи, кроме r, то тогда шаг будет
в минимального соседа, у которого номер больше, чем r. И дальше все будет проходить вот внутри этого
поддерево так же, как если бы только оно и было. Вот, и нужно только доказать, что обратно из i в r
пусть пойдет, только когда он уже целиком обойдет это поддерево. Вот, ну а почему это будет так? Ну,
потому что вот у i есть какие-то соседи, есть r. И здесь вот под деревья она обходит в порядке,
соответственно, номеров этих соседей, и только когда она их всех обойдет, она уже вернется в r.
Поэтому, соответственно, идет поход сюда, дальше обход вот этого поддерева, и потом только
возвращение сюда. И дальше точно так же по очереди будут обходиться все остальные поддеревья. Вот,
ну и дальше получается, что по индукции в поддеревях каждое будет пройдено дважды туда обратно, и вот эти
ребра тоже будут пройдены дважды туда обратно, когда мы идем в поддерево, и потом их не возвращаемся.
Это хороший вопрос, но, опять же, потому что, если посмотреть на номера всех соседей i, то они как бы цикл образуют,
да, r, потом минимальное больше r, потом минимальное больше того, и тогда, и потом, как перескакивает
через ноль, да, будет просто минимальный, минимальный на следующий, потом снова r. И, соответственно,
вот здесь соседи в том порядке будут обходиться, когда они все будут объединены, то после этого
нужно будет обязательно вернуться в r. Нет, не обязательно, у нас все по циклу. Да, у нас пока есть
больше, пока есть номера больше, чем тот, куда мы пришли раньше, мы идем в большее, а когда они
закончились, мы приходим по циклу в самые маленькие и снова идем по возрастанию.
Ну тогда сначала будут объединены те, у которых номера больше, а потом те, у которых меньше, а потом вернемся в r.
Ну, потому что мы каждый раз собираем минимальное доступное.
Нет, ну сначала будем обходить те, у которых номера больше r, да, потому что вот, ну в данном случае и
у нас получается, что g вместо вот этого i, да, а вот это i вместо r. Сначала, пока есть номера больше r, мы их обходим, а потом с 0 начинаем, да.
Нет, не больше, но раз это для любых верен. Просто потому что, ну если, если в третий раз все в два направления, то если мы в третий раз посетили, то он
в два направления повторил, значит, мы уже зацепились. Поэтому до начала цикла, значит, до начала цикла больше двух нельзя, но просто для деревьев ровно два, а для остальных меньше ровно двух.
Ну вот, значит, что здесь осталось сказать, что вот этот вот обход можно запускать на логатмической памяти, да, то есть нужно запомнить, с какого ребра мы начинали, а, вот, каждый раз
помнить предыдущую вершину и текущую, перебирать там всех соседей текущей вершины и искать минимальные, которые подходят, и после этого, соответственно, предыдущую
заменить на текущую, а текущую на ту, которую мы нашли, вот, и еще каждый раз сравнивать ребро из предыдущей в текущую с запомненным начальным, и еще нужно считать число ребер, вот.
Ну вот, получается несколько счетчиков, да, то есть, самая первая вершина, вторая вершина, значит, предыдущая вершина, текущая вершина, счетчик для перебора икса и счетчик для подсчета шагов.
Так, ну, вроде, шесть основных счетчиков получается, ну, может, еще несколько технических, чтобы работать, собственно, с графом, в общем, десятка счетчиков хватает, каждый из них не больше, чем м, и получается, что на все нужна логеркеническая память.
Вот, так, ну, ничего, понятно? Ладно, да, сейчас перерыв, потом поговорим про NL.
Так, давайте переходить к вопросу про NL, ну, видимо, сначала нужно поговорить про то, какая там свадимость, что такое логеркеническая свадимость.
Ну, если коротко, то это свадимость, которая задается логеркенической вычиненной функцией.
Да, то есть, в целом, определение такое же, как и обычно, значит, а-логеркенические свойства к b, если существует логеркенические вычислимая функция f, такая, что, значит, для любого x,
x принадлежит a, тогда, только тогда, когда f от x принадлежит b. Вот, ну, и нужно сказать, что такое логеркенические вычислимая.
Значит, ну, для этого есть два подхода.
Значит, два определения логеркенической вычислимости, да, NL, можно считать одно из них определением, да, а другое свойством.
Вот, значит, первое такое, что, значит, у нас есть логеркеническая машина, но еще с выходной лентой, на которую биты ответы печатаются один с другим.
Да, значит, то есть первый вариант, есть логеркенические вычислимая машина,
значит, ну, которая, соответственно, x преобразует в f от x, но и здесь имеется в виду, что биты f от x печатаются слева направо,
да, значит, без возможности изменения.
Здесь биты ответа
печатаются слева направо
и, соответственно, не меняются, не запоминаются.
Вот, тогда, соответственно, есть там входная лента неизменяемая тоже, но по которой можно двигаться в любую сторону и читать.
Есть маленькая рабочая, на которой памяти считается,
и есть выходная, на которой вот биты печатаются один с другим, и потом их уже печатают слева направо.
А также читать оттуда нельзя.
Вот, еще есть второе определение.
Второе определение, что просто есть два языка, значит, множество пар.
Таких, что длина f от x больше либо равно i, значит, и множество пар x и i таких, что i тыб и i больше либо равно i,
значит, и множество пар x и i таких, что i тыбит f от x равен единице, значит, вот эти два языка лежат в L.
Вот, я тебе вкратце скажу, почему это эквалентное свойство.
Значит, с первого и второго, пусть у нас есть такая машина, тогда мы можем ее запускать и просто игнорировать все, что она печатает,
но мы только будем считать, сколько бит она напечатала.
И дальше она в какой-то момент остановится, и у нас будет число напечатанных битов, это есть длина.
И после этого нам просто нужно будет сравнить эту полученную длину с i, и это нам даст ответ вот на этот вопрос.
Вот, а на этот вопрос нужно их тоже считать, пока соответственно не встретится i ты.
И если до i-того дела дошло, он выведен равен единице, тогда тут нужно ответить да, а во всех остальных случаях нужно ответить нет.
Это хороший вопрос, значит, это на самом деле зависит от деталей модели, но тут вроде бы стандарт модели должно следовать,
потому что у вас число конфигурации определяется числом возможных записей на рабочей ленте плюс число указателей, и оно будет просто полиномиальным.
Поэтому получится, что если вы уже вывели больше знаков, чем у вас есть конфигурации,
то у вас конфигурация повторила, значит вы зациклились и будете до бесконечности печатать ответ.
Так что это, конечно, должно быть, но вроде бы это просто будет следовать отсюда.
Но в некоторых других ситуациях это может быть важно,
например, в некоторых моделях вероятных вычислений нужно дельно потребовать, кроме логерсимической памяти, еще полиномиальное время,
а в других не нужно, начинаются такие нескоро у него особенности.
Ну, а значит, это если из первого-второго, ну и из второго-второго,
получается так, пусть мы уже сколько-то битов напечатали и мы запомнили сколько, нам нужно очередной печатать.
Тогда сначала запуская машину для первого вопроса мы понимаем есть вообще такой бит или нет.
Если его нет, значит уже все напечатали, нужно остановиться.
Если он есть, тогда мы запускаем машину для второго вопроса и понимаем, равен ли он единице.
Если он равен, то печатаем единицу, если не равен, то печатаем ноль.
Дальше увеличиваем счетчик и идем дальше.
Вот.
Так, хорошо.
Ну, такая вот, значит такая сводимость применительно к лог-памяти,
играет уже роль, что и полиномиальная сводимость для полиномиального времени.
Вот.
Вот, то есть тут будут всякие стандартные свойства выполнены типа того, что там транзитивность будет,
или что если там A сводится к B, значит A в L,
то тогда A в L.
Вот, всякие такого рода утверждения, тут все будут выполнены.
Ну и определение трудностей и полноты тоже будет аналогичное.
То есть будет, значит, язык B, NL полон.
Значит, если он сам лежит в NL,
и для любого A из NL, значит, верно, что A логарифмически вводится в B.
Вот. То есть, в общем, все определения те же самые, значит, с заменой полиномиальной сводимости на логарифмическую.
Ну и всякие теремы будут те же самые, типа того, что если у нас какой-то там NL полный язык лежит в L,
то тогда A равно NL, и так далее.
В общем, это я все повторять не хотел бы, значит, хотел бы сосредоточиться на конкретных NL полных задачах.
Ну и докажем то, что я уже анонсировал,
что задача о наличии пути в ориентированном графе будет NL полный.
Так, значит, теорема, что P, это будет NL полная задача.
Но тут тоже есть много технических деталей, на которых я не хотел бы заострять внимание,
хотел поговорить про саму суть этой теоремы.
Значит, а суть состоит в том, что для логарифмической машины есть конфигурационный граф полиномиального размера.
Значит, для логарифмической машины есть конфигурационный граф полиномиального размера.
При этом, поскольку это недоторминированная машина, то там исходящей степени может быть больше единицы.
Соответственно, если участие недоторминированное, то из каждой конфигурации есть ровно одна следующая допустимая.
Если недоторминированная, то может быть больше, чем одна.
Но так или иначе у нас определяется результат работы конфигурации этой недоторминированной машины.
Так что если у нас достигнуто принимающее состояние, то ответ «Да».
Если хоть на какой-то ветви достигнут, то ответ «Да», если на всех ветвях не достигнут, то ответ «Нет».
Но можно искусственно сделать ровно одну принимающее вершину, и тогда вопрос о том, лежит ли слово в языке эквивалентен вопросу о том,
есть ли в этом графе путь изначальной вершины вопринимающее.
То есть х лежит ва, тогда и только тогда, когда в конфигурационном графе для ма,
ма вместо машины, которая распынует а, в конфигурационном графе для ма есть путь из начальной вершины в принимающее.
Но вот это и есть сводимость, то есть произвольный язык сводится к наличию пути, и дальше начинаются технические детали, почему аналогарифмическая.
Ну, по крайней мере, это так может быть, потому что конфигурационный граф имеет полимерный размер.
Вот как вы уточняли, что должно быть полимерное время работы, но раз у нас выход полимерной длины, то по крайней мере может быть полимерное время.
Нам нужна более того логографическая память, и чтобы это аккуратно показать, нужно четко договориться о кодировании конфигурационного графа.
То есть нужно, чтобы все конфигурации каким-то образом легко кодировались, так чтобы, ну тут удобно вот на это определение смотреть.
Значит, х, х это как бы исходный х, по которому строится конфигурационный граф, а и, ну можно считать, что это пара вершин,
да, можно считать, что граф задан на матрице смежности, а и задает пару вершин, и нам нужно понять между этой парой вершин есть ребро или нет.
Ну вот если там кодирование какое-то достаточно хорошее, то тогда по этим кодам действительно можно на логографической памяти понять, есть там ребро или нет.
Ну потому что что такое конфигурация? Конфигурация это содержимые рабочей ленты, внутреннее состояние машины и положение указателей на рабочей ленте и на входной ленте.
Ну и соответственно у нас есть две таких конфигурации, нужно проверить, что из первого и второго идет переход в соответствии с программами машины Тьюринга.
Ну грубо говоря, как это проверяется, что почти во всем эти конфигурации совпадают, кроме небольшой окрестности указателей, а в этой окрестности переход проводится по программам машины Тьюринга.
Вот программ машины Тьюринга, это хоть и довольно большой текст, но он константной длины, то есть он вообще не зависит от длины входа, поэтому считать, что он просто дан целиком.
Ну и мы соответственно ищем в этой программе нужную команду и проверяем, что то, что у нас произошло соответствует этой команде.
Ну в общем такая вот идея, дальше можно это технически уточнять.
Так, есть какие-нибудь вопросы?
Конечно, потому что, смотрите, что дает X в точке зрения конфигурационного графа.
X это фиксированные содержимые входной ленты, поэтому для разных X будут совершенно разные конфигурационные графы.
Хотя, да, поэтому, когда мы вычисляем, есть ли там ребро, язык же или нет, мы должны посмотреть и на тот бит X, на котором стоит указатель, и это использовать при проверке.
Ну они все, но они все для фиксированного X, то есть у нас X фиксированный, а содержимый рабочий лент какой угодно, новой графической длины.
X это вход, да, X это вход, вход фиксирован, а содержимый рабочий лент какой угодно.
Так.
Так.
Так.
Так.
Так.
Так.
Так.
Так.
Так.
Хорошо.
Но теперь надо изучать разные другие, значит, разные другие.
НЛ полная задача.
Так, давайте начнем с того, что изучим язык сильно связанности.
Значит, S connected, S connected это множество таких G.
Значит, G таких, что G это сильно связанный, сильно связанный ориентированный граф.
Так.
Значит, он, NL полный, эта задача.
Ну и давайте сначала обсудим, почему она лежит в NL.
Ну, смотрите, что такое сильно связанный.
Сильно связанный означает, что для любой пары вершин i и g есть ребро из i в g.
Не ребро в смысле, а путь, значит, путь из i в g.
На самом деле, для этого достаточно, чтобы был путь из первой вершины во вторую,
из второй в третью, из третью в четвертую и так далее, и из N в первую.
Значит, соответственно, сильная связанность, сильная связанность.
Верна тогда и только тогда, когда есть пути, значит, из первую в вторую, из вторую в третью,
и так далее, из N минус первой в N и из N в первую.
Вот. Ну и, как и прежде, значит, если есть какой-то путь, то есть путь без циклов.
То есть, суммарная длина всех этих путей будет не больше, чем N в квадрате.
Значит, суммарная длина всех путей будет не больше, чем N в квадрате.
Максимум N в квадрате.
Вот. Тогда, соответственно, недоторминированный алкоголь будет таким,
что мы начинаем недоторминированные блуждания с первой вершины,
и последовательно ждем, пока там встретится вторая, третья, четвертая и так далее, N и первая.
То есть, тут получается недоторминированный алгоритм.
А алгоритм заключается в том, что мы запускаем из вершины 1 недоторминированные блуждания
на N в квадрате шагов.
На N в квадрате шагов.
Значит, и, соответственно, ждем встречи, соответственно, второй, третьей и так далее, N и первой.
Ну, если они все встретились именно в таком порядке, то говорим да, а если нет, то нет.
Ну вот, соответственно, если сильно связанность есть, то есть вот и такое блуждание, и алгоритм его найдет.
Значит, одна из ветвей ровно по нему пройдет.
Если сильно связанности нет, то какого-то одного из этих путей нет,
и тогда, соответственно, если машина до него дойдет, например, если из пятой в шестую, например, нет,
то даже если она дошла до пятой, потом она не сможет лечь в шестую.
Либо она и до пятой не дойдет.
В общем, так или иначе, так или иначе проверка не пройдет.
Вот, поэтому этого N лежит.
Так, ну что, понятно?
Вот, а теперь почему N полнота?
Значит, N полнота, значит, нужно свести, свести P, алгоритмически, к S connected.
Так, как это можно делать?
Так, смотрите, я картинку нарисую, значит, вот есть граф, вот есть вершина S, вот есть вершина T.
И мы сделаем следующее.
Значит, из всех остальных вершин мы добавим ребра в S, а также добавим в них ребра из T.
Вот, тогда смотрите, во-первых, если пути из S в T не было, то он и не появится.
То есть получается, что в исходный граф добавляем ребра T в S.
Соответственно, если пути не было, то он и не появится.
Почему? Ну, если пути есть, то он есть там без циклов, тогда там по дороге S и T не встречается, только на краях S и T.
А тогда, соответственно, вот эти добавленные ребра, они либо приходят в S, либо выходят из T, поэтому не могут там встретиться.
Иначе там как раз второй раз по дороге встретится S или встретится T.
Поэтому, значит, если в новом графе есть пути из S и T, то он был и в старом.
Вот, а если путь был, ну, путь из S в T, понятное дело, то теперь есть все пути из U в S, потом в T, потом в V.
Вот, ну, это для случаев, когда U и V не совпадают с S и T, когда не совпадает, там тоже все случаи перебираются.
Да, то есть, например, ну, из T в S автоматически получается.
А, ну, все остальные либо автоматически получаются прямо под добавленным ребром, либо аналогично, там не знаю, если U совпадает с S, то оно аналогично тоже получается.
Вот, ну, то есть граф сильно связан, значит, граф сильно связан.
Вот, а если пути не было, то он не появится, и, соответственно, граф не связан.
Вот, ну, вот и получается, что действительно равносильно, то есть, вот эта вот тройка GST лежит в PATH, тогда и только тогда, когда наша построенная игра в G-штрих лежит в S-Connected.
Вот, ну, действительно, сводим слогарифмическое, да, тут очень легко, просто, особенно в моде смежности легко.
Мы проверяем, что если конец ребра это S, то добавляем единицу, если сначала ребра это T, то тоже добавляем единицу, а иначе берем тоже то же самое, что было в исходном графе.
Вот, ну, вот пример, значит, пример другого NL-полного графа, NL-полного языка.
Так, ну, что, какие-нибудь вопросы?
Так, ну, у нас еще некоторое время есть, значит, для дальнейшего мне понадобится альтернативное определение NL, NL-сертификатное.
Значит, сертификатное.
Значит, CNP было очень удобно.
Вот, было определение через нетерминированные машины, было определение через сертификаты, и в большинстве случаев мы излагали, как должен быть устроен сертификат, чтобы было принадлежно CNP.
Здесь я пока что излагал, как должна нетерминированная машина быть устроена, чтобы, соответственно, вернуть правильный ответ.
Вот, ну, первая идея сертификатного определения состоит в том, что, ну, просто будет то же самое, вместо полиминальной вычислимости будет логарифмическая, то есть тот же самый вертификатор, вот X и Y.
Но просто мы скажем, что он будет не полиминальный по времени, а логарифмический по памяти.
Но так в существовании не получится. Значит, если такое определение дать, то тоже NP получится.
Если просто вертификатор логарифмический по памяти, но тем не менее он может как угодно изучать сертификат, то это будет тоже NP.
Можете проверить, что когда мы проверяем три раскраска, например, нам не нужно хранить и работать со всей раскраской, а нам нужно в каждый момент проверять два соседних цвета, проверять, что они разные.
И это будет вполне себе логарифмическая процедура.
Поэтому здесь определение такое, да, с одной стороны все так же, да, должно быть, что X пронжета тогда и только тогда, когда существует Y такой, что V от XY равно единице,
и V использует логарифмическую память, но кроме этого есть должно быть еще одно условие.
Значит, V читает Y слева направо, то есть это такой сертификат для однократного чтения, и получается, что нельзя его целиком никуда копировать, можно запоминать только маленькую часть.
Ну а, конечно, любые эти проверки коррекции три раскраски, они требуют, что мы туда-сюда ходили и все время разные цвета сравнивали, поэтому такого для NP уже не получится сделать.
Ну а почему это так? Ну, на самом деле, это, конечно, примерно логично, да, то есть из нетерминированного сертификатного, но мы просто в сертификат запишем нужную ветку вычислений, и нужную ветку вычислений как раз слева направо нужно читать.
Тут получается, что Y это ветвь вычислений, приводящая к положительному ответу.
Но в обратную сторону сертификатного, из сертификатного в нетерминированные вычисления, ну просто тоже будем угадывать битв сертификат по одному. Мы все равно только слева направо читаем, поэтому каждый раз, когда хотим прочесть новый битв сертификата, мы вместо этого идем по одной из ветвей нетерминированного вычисления.
То есть получается, что угадываем биты сертификата, ну а в остальном те же самые учления проводим, что были.
Поэтому получается, что это одно и то же. Ну и тогда то, что у нас было, можно изложить попроще. Почему наличие ориентированного пути лежит в НЛ? Потому что в качестве сертификата мы сам этот путь можем передать.
И как раз будем идти по нему от начала к концу и проверять, что действительно между соседними вершинами есть ребра. И будем каждый раз хранить там текущий вершин предыдущего, ну и какие-то счетчики, чтобы искать в графе есть там это ребро или нет.
Вот почему сильно связан будет лежать в НЛ. Ну мы то же самое, то же путь туда положим, только вот такой вот длинный, который сначала проходит через один, потом через два, потом через три и так далее.
И в итоге приходится снова в один. И то же будем идти по этому длинному пути, проверять, что он путь, что там все ребра есть необходимое, и что действительно встречается вершинами в таком порядке. Один, потом два, потом три и так далее.
Вот. Ну вот оказывается, что хотя вот в этом случае довольно легко это излагалось и в тернах недотриминированного блуждания, в общем случае это будет не очень легко.
Так, под конец я анонсирую то, что мы будем в следующий раз делать, по крайней мере на первый плане лекция. Значит на первый плане лекция, ну посмотрим, может это на всю лекцию затянется.
Мы обсудим такую теорему, значит теорему Иммермана, теорема Иммермана Сейлопченья, которая заключается в том, что NL равняется QNL.
В свое время в конце 80-х годов эта теорема Большой Фурор произвела, потому что до этого думали, что в общем L и NL примерно так же, как P и NP.
И в NP есть гипотеза довольно широко принятая, что NP все-таки не равно QNP. То есть мы не можем быстро доказать, что чего-то нет. Можем только быстро доказать, что что-то есть.
Но оказывается, что если речь идет не о времени, а о маленькой памяти, то тогда все-таки можно доказать, что чего-то нет, используя такую же память, как нужно для того, чтобы доказать, что оно есть.
Ну вот, в общем мы это докажем, и это нам даст еще несколько других NL полных задач. Я думаю, что на сегодня можно поставить точку. Спасибо за внимание.
