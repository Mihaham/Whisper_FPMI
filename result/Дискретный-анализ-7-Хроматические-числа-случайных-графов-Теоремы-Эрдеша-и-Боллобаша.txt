Вот, ну давайте заниматься, как я уже обещал, просто хроматическими числами случайных графов.
Это очень важная вещь, и мы сейчас постепенно, последовательно будем выходить на полную картинку того, как это жить устроится.
Давайте я прямо сформулирую эту тему так.
То есть, под случайным графом я, естественно, понимаю ровно то, что понималось в прошлый раз.
В прошлый раз мы потратили значимое время на то, чтобы разобраться во всяких неравенствах.
И, в общем, мы можем много чего теперь сделать.
Значит, начну я, наверное, все-таки не с картинки, а с одного замечательного утверждения,
которое некоторые, возможно, слышали в школе или даже когда-то кто-то кому-то их доказал.
Это будет чуть-чуть в сторону, хотя безумно красиво, и я постараюсь дополнительно замотивировать, зачем изучать вообще эту штуку.
Значит, есть такая прекрасная теорема, которую в 1957 году доказал тот самый Эрдеш, имя которого присутствует в названии модели случайного графа.
Там была большая история на самом деле, появилась задача лет за 20 до того, как Эрдеш ее решил, но в 1957 году она как бы завершилась.
А именно был доказан такой совершенно удивительный, на первый взгляд, результат.
Пусть фиксированы произвольные числа KL, тогда существует граф, ну конечно и граф, а на скольких вершинах бог его знает,
такой, что его хроматическое число больше, чем K, а сейчас скажу, что это такое, так называемый обхват больше, чем L.
Значит, вот это называется обхват по-русски, по-английски это называется KERS, ну переводится тоже как обхват,
от сюда собственно вот эта G маленькая, а определяется очень просто, это длина самого короткого цикла в графе.
Длина самого короткого цикла в графе.
Ну, то есть, например, утверждение о том, что обхват графа больше тройки, что оно означает?
Что в графе нет треугольников, да? В нем есть цикла, но в графе нет треугольников.
Это то же самое, что в G нет треугольников.
Это прямо роднит определение вот этого обхвата с теми понятиями, которые мы в прошлый раз изучали.
Но утверждение о том, что G от G больше, чем L, это утверждение о том, что в графе нет никаких циклов заданной длины вплоть до какого-то определенного значения.
Нет ни треугольников, ни циклов длины четыре, таких квадратиков, ни пятиугольников, но ничего нет.
Граф безумно дырявый, в нем дырки огромные, понимаете, самый короткий цикл имеет длину, ну может быть L плюс один, а может и больше.
В нем огромные дырки, в которых внутри нет ребер никаких, они не замыкаются ничем.
И вот несмотря на то, что он такой дырявый, у него этот обхват огромный, его трудно покрасить.
Он требует для своей покраски огромного числа цветов.
Ну что значит огромного? Ну зафиксировали, я не знаю, K равное чему-нибудь, там 10 в сотой степени, L равное тому же самому.
И вот утверждается, что может быть есть гигантский граф, там у него 10 в степени, 10 тысячу раз вершин, там сколько угодно.
Но он точно есть такой, что ему и в кадр цветов нельзя покрасить в 10 в сотой степени.
И дырки все размера 10 в сотой и больше.
Можно в такое поверить?
Не, ну так, я просто давлю на интуицию, я хочу, чтобы вы почувствовали, да?
Вообще это удивительный результат.
Вот он доказывается с помощью g от Np.
Сейчас мы его докажем образцово, показательно, и уже после этого будем создавать всю картинку.
Вы просто лучше почувствуете, зачем эта картинка нужна.
Как в зависимости от того, каким мы выбираем вот это p в зависимости от N, ведет себя хроматическое число графа.
Оказывается, что очень причудливо.
Наверное, вам-то думалось, что все-таки омега, там все время в голове сидит омега, омега, омега, кликовое число, вот оно влияет.
Но помните, я же вас разубедил.
Я же вам доказал, что лучше снизу оценивать хроматическое число не омегой, а мощностью V поделить на альфа.
Слушайте, а какая омега у графа, у которого g обхват больше, чем l?
Кликовое число?
Два!
Вы понимаете, что два?
Ну нет треугольников, значит нет и k4, нет и k5, нет треугольников.
А это еще маленькая l, l равна 3.
g от g больше 3, это значит, что в нем нет клик, кроме ребер.
Ребра это самые большие клики.
Вот это еще для себя прочувствуйте, и тогда у вас в голове будет вся картинка будущего катарсиса, когда я докажу эту теорию.
Ну, повторяю, кто-то может слышал, что поделать, сейчас будет чуть поменьше катарсиса.
Забыли наверняка.
Так, все, я доказывал, оно не такое простое доказательство.
Оно вероятностное, я же обещал, что было случайно и графы.
Давайте возьмем g от nb, причем p выберем таким специфическим образом.
p возьмем, зависящим от n, и имеющим вид m в степени θ-1.
Напишем, где θ в свою очередь, это 1 поделить на 2l, вот так.
l это зафиксированное заранее число, которое в конечном счете будет отвечать за размер ограничения на величину цикла.
Так, ну, я надеюсь, понятно, что такое p корректно выбрано, оно из 0,1 из отрезка.
Понятно? В этом смысле все хорошо, почему оно такое выбрано?
А вот это нам предстоит понять.
Ну, это неспроста. То есть вот зачем-то надо такие ситуации тоже уметь изучать.
Давайте изучим. Давайте введем случайную величину x с индексом l.
Ну, она, естественно, будет зависеть от графа, потому что это случайная величина на случайном графе.
xl от g это будет, по определению, количество простых циклов длины не больше, чем a, вот в этом графе g.
То есть нам-то теоретически нужен граф, для которого xl равно 0, правда?
Но нам не только это нужно, нам нужно, чтобы у него еще было большое хроматическое число.
Поэтому я предлагаю немножко поговоряться с этим xl.
xl звучит как известный язык, xl какой-то, да, ну или файлик икселевский.
Так, первое, что я предлагаю посчитать, это математическое ожидание от этого файлика, мат ожидания xl.
Но надо воспользоваться линейностью, которую я рассказывал в прошлый раз,
и которую, конечно, знают точно уже все, кто находится не на мат плане, а на мат плане я пока не знаю, надо спросить.
У вас пока все еще сигма-алгебры, я поговорю еще с Владимиром Игоревичем, я хочу понять, какой у него план вообще в целом.
Я расчитываю, нет, мат план, конечно, это все классно, я просто хочу, чтобы там мат ожидания в какой-то момент появилась тоже,
но, видимо, это произойдет, мне надо уточнить, когда.
Ну хорошо, я пока болтал, вы могли сообразить, чему это равняется?
Сколько есть в случайном графе циклов простых, конечно.
Я надеюсь, вы понимаете, что если простые циклы не бывают короче, чем l, то и никакие не бывают.
То есть нам достаточно считать простые циклы, это понятно?
Да.
Ну и чего?
Ну как надо xl представить?
Надо сначала просуммировать по длинам циклов, которые нас интересуют, правда?
Ну какие там длины бывают? R, от тройки до A, правда?
Потому что цикл от длины меньше, чем 3 не может быть, у нас граф обыкновенный.
У нас нет ни петель, ни даже кратных реток, то есть циклов длины 2 и 1 не бывают.
То есть мы суммируем здесь мат ожидания случайных величин,
каждая из которых уже отвечает количеству циклов вот этой конкретной длины.
Теперь, когда мы зафиксировали длину, надо разбить как сумму индикаторов.
Ну, там во-первых надо зафиксировать c и z по r вершины, правильно?
А потом еще зафиксировать r-1 факториал пополам способами один конкретный цикл на этих r вершинах.
То, что циклов на r вершинах столько, это понятно?
Это мы вроде проходили, унициклические графы-то были.
А дальше уже остается индикаторная случайная величина, то есть она единичкая.
Если вот этот конкретный цикл присутствует в случайном графе, ну или иначе?
То есть ее мат ожидания это просто b в r к степени.
Мы зафиксировали совершенно конкретный цикл с совершенно конкретными ребрами.
Мат ожидания индикаторной величины это вероятность того, что она один.
То есть что все эти r ребра в нашем графе есть.
Остальные могут там быть, не быть, это совершенно неважно.
Всем понятно? Точно?
Ну, смотрите.
Ну, в данном случае мы, группа, все оценим.
Это во-первых не больше, даже меньше, чем n вертый уделить на r факториал умножить на r факториал и умножить на b вертый.
Ну, то есть я цешку оценил совершенно стандартным способом.
Это наше универсальное неравенство, которым мы постоянно пользуемся.
А вот эту дровь грубо оценил факториалом, просто чтобы, как обычно сказать, шлеп-шлеп.
И получить сумму геометрической прогрессии, которую считать не собираюсь.
Потому что это глупая арифметическая прогрессия.
Кто-нибудь понимает, что такое умная арифметическая прогрессия, а что такое глупая арифметическая прогрессия?
Значит, сейчас вы увидите.
np основание, знаменатель геометрической прогрессии, np.
Это n в степени тета, правильно?
Ну, то есть это больше единицы, это растущая функция.
Это не бесконечно убывающая геометрическая прогрессия, это, наоборот, растущая геометрическая прогрессия.
В этом смысле она глупая.
А самое главное, что l, товарищи, это же у нас константа.
Может, она и равна к углу, или там 10 в степени 10-10 тысяч раз.
То есть, может быть, она зафиксирована очень огромной.
Но параметр, в котором мы могли управлять, это число вершин графа.
Вот его можно взять сколь угодно большим в зависимости от этого l.
Понимаете замысел, да?
То есть l это константа.
Не важно, что она большая.
Поэтому я тупо вот это все оценю вот так.
Это меньше, чем l умножить на n в степени тета l.
Ну, то есть я возьму самое большое слагаемое в этой сумме,
подставив r равное l.
Оно будет самое большое.
И просто тупо оценю сумму количеством слагаемых в ней,
но тоже увеличенным на двойку, умноженным на это самое большое слагаемое.
Видите, да?
Я сделал грубая оценка.
Грубая, но это константа.
Какая разница, l или l-2?
Совершенно не важно.
Так, а вот это равно l умножить на n в степени.
Смотрите, это 1 на 2 l.
Вот проясняется, зачем я так выбирал параметры.
Можно было, конечно, любое другое взять, но так удобно.
Вот 1 на 2.
После умножения на l будет просто 1 на 2.
Успеваете, да?
Так, ну ладно, посчитали l-карнейзен.
Видите, как хорошо?
Ну, не больше, меньше, чем l-карнейзен.
Теперь давайте вспомним неравенство Маркова.
Я очень старался его подробно прояснить в прошлый раз.
Вспомним неравенство Маркова.
Что оно нам говорит?
Оно говорит в частности, что вероятность,
с которой xl больше, например, чем n пополам,
ну или больше либо равняется, я, может, писал, это не важно,
больше либо равняется n пополам,
не превосходит мат ожидания xl,
поделенная на n пополам.
Ну, а это строго меньше, чем l-карнейзен,
поделенная на n пополам.
То есть это стремится к нулю,
при n стремящемся к бесконечности.
Так, ну давайте я, может, где-нибудь вот здесь
буду фиксировать выводы, которые у меня промежуточно получаются.
Сейчас я бы зафиксировал так.
Существует n1 такое, что для любого n,
больше либо равного n1,
это я сейчас преобразую стремление к нулю
в некоторое конкретное неравенство.
И сейчас я еще напишу отрицание.
То есть я напишу вот так,
вероятность того, что xlt меньше, чем n пополам,
больше либо равна,
нет, это строго больше, чем 1 х 2.
Вот это вот первый вывод, который я хочу зафиксировать.
Ну, то есть вероятность того, что xl большая,
стремится к нулю, значит,
вероятность того, что xl маленькая,
стремится к единице,
начиная с какого-то момента и до бесконечности,
она будет больше, чем 1 х 2.
Нет, это вроде очень просто.
Нет, я сейчас немножко сыронен,
потому что это просто вывод из стремления к нулю
вероятности отрицания этого события.
Может, просто быстро говорю.
Ну ладно, с циклами локально разобрались,
но пока непонятно.
То есть, смотрите, вот словами что получилось?
Словами получилось, что очень высока при больших n
вероятность того,
или даже, можно сказать, доля тех графов,
для которых вот это выполнено,
при больших n больше половины в каком-то смысле,
вот очень высока вероятность этого.
А вероятность чего?
Вероятность того, что у нас вредоносных циклов,
то есть циклов длины не больше, чем m,
мало, ой, мало, да, мало.
Поняли, что циклы длины не больше, чем l, они нам вредят.
Мы же хотим графов,
в котором вообще нет циклов длины не больше, чем l.
А тут у нас находятся графы,
в которых таких вредных циклов,
от которых хотелось бы вообще избавиться,
но хоть сравнительно мало.
Вот таких графов, где этих бяк,
сравнительно мало, их много,
самих графов много.
Вот такой выбор.
Суть его понятна.
Очень много графов,
у которых очень мало вредных циклов,
вот так, совсем коротко.
Если еще окажется, что очень много графов,
у которых большое хроматическое число,
ну, наверное, мы пересечем два эти множества
и получим то, что нам нужно.
Вот такая такая замысла, понятно?
Но это еще предстоит реализовывать.
Сейчас будет рассуждение,
похожее в каком-то смысле
на то, которое доказывало теорему
про оценки омегой и мощностью В
поделить на альфу.
Я понятно говорю?
Потому что хроматическое число не меньше
омега, там 2 лог 2 х н получалось,
или не меньше, чем n поделить на альфу,
там тоже знаменатели 2 лог 2 х н.
Но сейчас будет нечто похожее.
Давайте через у,
теперь новая случайная величина будет,
не х, а у.
Через у с индексом,
такое, тикс маленькое,
обозначим
случайную величину,
которая
знаете чему равна?
Она равна
количеству
независимых множеств
независимых множеств
размера,
ну то есть количество вершин, в которых
такое, размера х
в графеже, размер в данном случае это
количество вершин,
просто мощность,
количество независимых множеств
мощности х в графеже,
размер и мощность.
В данном контексте я посчитал синоним.
Так, вот что такое х?
Давайте я сейчас еще х прямо напишу.
Ну я его знаю наизусть.
Вот так в принципе понятно.
Сейчас вы поймете как
он был найден.
Но чуть позже.
Сейчас я его напишу, верхняя целая часть,
три логарифма n
поделить на p.
Такой вот риск.
Ну давайте чтобы сразу было чуть-чуть
понятнее,
я не знаю, можно это не записывать, это пойдет
просто на видео, но вам так лучше будет
восприниматься. Представьте себе, что p
равно 1 и 2. Оно у нас не такое
конечно, но пусть, допустим,
p равно 1 и 2. Есть примерно
6 логарифм в n получается.
Ну это вот
что-то похожее на 2 лог
двоичный n из той тяги.
Ну 6 это просто я о группе.
Мне сейчас точность не важно.
Понятно, что х
это величина большей единицы, что это
нормальное такое натуральное число.
Не, ну друзья, p у нас стремится к 0
по условию, так мы его построили.
И тут еще логарифм n.
То есть это растущая величина с роста m, конечно.
Поэтому я, например, могу пользоваться
тем, что она симпатически равна
просто 3 логарифм n на p.
И буду этим пользоваться
просто потому, что
под целой частью стоит
нечто растущее в бесконечности.
Ну, хорошо.
Давайте посчитаем мат ожидания
ух.
Я на вас так смотрю
в надежде, что кто-нибудь скажет,
чему оно равно, то мне не сказали.
Оно попроще.
А тут размер фиксирован.
А, ну все.
Количество независимых нож, точности, мощности
х. Ну и что тут надо написать?
c из n по х?
Да, c из n по х, это правильно, да.
На p в степени c из x, господи,
c из x по 2?
Ну только на 1 минус p.
Потому что p это вероятность сохранения ребра.
Да, правильно, Саша.
Ну вот сейчас вы поймете,
откуда взялось вот это выражение,
грубо говоря. Значит, смотрите,
это меньше либо равно,
я просто тупо
напишу n в степени х.
Это c из n по х, я даже х факториал
забью на него, не буду
заморачиваться.
На e в степени минус c
p на c из x по 2.
Извините, а почему у нас l равен n
стремиться к бесконечности?
Потому что p, стоящая в знаменателе,
это функция, стремящаяся к нулю,
а стремится она к нулю, потому что
n возводится в степень меньше
у единицы, из которой вычитается единица.
Из одной 2n вычитается единица,
это меньше, минум меньше нуля.
Получается уже вот эта вся разница.
Значит, n в этой степени стремится к нулю,
и она же еще стоит в знаменателе.
Так что это стремится к бесконечности,
с хорошим запасом.
Вот этот переход
научились уже в уме делать?
Нет.
Стандартный переход, 1 минус p,
это e в степени логарифма от
1 минус p, а это
не больше, чем e в степени минус p.
Много-много раз
делали логарифму от 1 минус p
не больше, чем минус p.
И все, вот я это подставил, получилось.
Вот привыкайте, да,
это совершенно стандартная выводка, она
с первой лекции у нас на самом деле тянется.
Ну и переписываем, e в степени x
логарифма от n,
минус, давайте, асимптотику
учтем.
Так, все помнят, нарисовать тильду
или написать равно
и потом умножить на 1 плюс
умалое от единицы, это одно и то же.
f тильда g
и f равно 1 плюс
умноженное от единицы на g, это одно и то же.
Поэтому тильду
я здесь заменяю, и дальше
я пишу, вы, наверное, смотрите так, почему
1 плюс умалое от единицы и все.
Не все, не все.
Так, p
x квадрат пополам.
c из x под 2, асимптотически
равно x квадрат пополам.
Поэтому вот здесь вот я написал
1 плюс умалое от единицы.
Не x на x минус 1 пополам,
а x квадрат пополам.
Но x на x минус 1,
асимптотически равно x квадрат.
Потому что x стремится в бесконечность.
Потому что эта асимптотика выражена
в записи 1 плюс умалое от единицы.
Теперь смотрим на
вот этот вот показатель экспонента,
выносим x со скобку,
в скобках остается логарифом n
минус почти что единичка
умножить на p
и разделить пополам.
Согласны?
Или x потерялся?
Теперь согласны, x потерялся.
Теперь согласны.
Но виноват.
Так, теперь вот это вот,
то что стоит в скобках,
переписываем снова.
Это логариф m,
минус 1 плюс другое
умаленькое от единицы, не такое как здесь.
Потому что я сейчас x заменю
на свою асимптотику.
Значит x у нас асимптотически
3 логариф m поделить на p,
потом мы умножаем это на p.
В уме делаем шлёп-шлёп.
Так, поняли? p сокращается с p.
Не, не поняли.
Вот смотри, здесь p умножается на x.
А x асимптотически равен
вот этому. Значит p шлёп-шлёп.
Ну что, теперь поняли?
Так, а что осталось?
3 логариф m и пополам.
3 вторых
логариф m. Смотрите, какая красота.
Ну, я конечно здесь
мог написать не тройку, а двойку.
Всё равно всё получилось.
Почти что.
Ну, двойку не получилось.
Вот 2,1. Мне важно,
что вот эта разность,
на которую умножается x,
она очевидно стремится к минус бесконечности.
Так, друзья, я надеюсь,
все понимают, что вот это просто стрелочка,
а это значок стремления к минус бесконечности.
То есть вот мы видим, что
эта разность стремится к минус бесконечности,
значит и произведение туда же
стремится x положительной,
да ещё и растущей.
То есть вот это произведение стремится
к минус бесконечности с ещё большим свистом,
чем то, которое внизу.
Ну вот. А стало быть,
вся экспонента стремится к нулю.
Вся экспонента стремится к нулю.
Так, ну то есть
сама от ожидания y,x вот так
подобранным x, оно стремится к нулю.
Так, ну надо ещё раз воспользоваться
неравенством Маркова.
Давайте я вот здесь это сделаю,
где оно прямо написано.
Вы же сказали,
что стремится к минус бесконечности,
только скопка.
Ну правильно, да. То, что в скопках стремится к минус бесконечности,
x положительной,
и притом даже растущей,
поэтому всё произведение по-прежнему
стремится к минус бесконечности.
Причём с ещё большим свистом.
Да, но мы умножаем
нечто,
家 и вот это.
Причём gi-го� Sorry- sorry.
к минус бесконечности.
Причём в третий раз повторяюсь,
ещё больше式.
Просто потому что
Вероятность того, что альфа от g, альфа это число независимости, больше чем х, это в точности вероятность того, что у с индексом х больше либо равно единице. Согласны?
Ну как? ух это количество независимых множеств на х вершинах. Если оно не меньше единицы, а, ну, наверное, вот так надо написать, тогда это правильно.
Альфа от g не меньше, чем х, это в точности значит, что в графе есть хотя бы одно независимое множество на х вершинах. Вот так будет совершенно правильно.
Дальше применяем неравенство Маркова, е, у, х поделить на единицу, вот к этому, ну поделить на единицу это. Понятно? Оно стремится к нулю, как мы только что доказали.
Ну, значит, второй вывод такой, существует n2, такое, что для любого n больше либо равного n2, вероятность того, что альфа от g строго меньше х больше, чем 1,2, вот так.
Опять написал отрицание, вот здесь, отрицание того, что стремилось к нулю. Ну, значит, отрицание большое. Вот, ну, как я и обещал, понимаете, да, что если я возьму максимум из n1, n2, то эти два события пересекаются.
Все понимают, что если каждое из событий, не важно какая там вероятностная мера, если каждое из событий имеет вероятность больше 1,2, то эти события пересекаются непустым образом.
Умеете это доказать? Гениальное утверждение. Ну, упражнение, товарищи, это упражнение. Ну, слушайте, теоретика множественное просто упражнение, напишите там, вероятность пересечения.
Можете написать ее как единица, минус вероятность отрицания пересечения, объединение отрицания, что-то такое. Там легко все оценивается.
Вот, короче говоря, вывод-то какой? Давайте я где-то сокру. А вот когда я тут пишу, все видят, нормально? Хорошо, тогда вот это тоже можно стереть.
Так, значит, мы говорим, что если N больше, чем максимум из N1 и N2, то существует граф такой, что одновременно в нем мало вредных циклов,
то есть циклов длины не больше, чем L, и в нем альфа меньше, чем X. X я пока не стер, это хорошо. Вот один и тот же граф одновременно обладает вот этими двумя свойствами.
Ну, это не совсем то, что нам нужно, у нас все-таки циклы-то есть, а нам нужен граф, в котором вообще циклов нет, правильно?
Давайте из графа G, который точно существует, сделаем уже без всякой случайности детерминированно. Граф G штрих. Очень просто.
Из каждого вредного цикла выдернем любую вершину. Так, можно я не буду писать, а вы словами скажу, а вы запишите, если вам нужно.
Мы из графа G получаем G штрих следующим простым путем. Мы берем в графе G все вот эти его немногочисленные вредные циклы и из каждого из них выкидываем какую-то одну вершину вместе со всеми примыкающими ребрами.
Так, ну давайте обсуждать, что такое XL от G штрих. Это ноль. То есть G от G штрих больше, чем M.
Мы разорвали все они хорошие циклы, новые циклы при этом очевидно образоваться не могли. Как, друзья, могли? Нет, конечно. Ну как они могли образоваться? Не могли?
Так, вот еще важный вопрос. А сколько вершин в графе G штрих? У нас в исходном графе G было N вершин. Мы взяли каждый цикл в этом графе и из него выкинули какую-то вершину.
Могло даже так получиться, что для некоторых двух циклов или трех или десяти, я не знаю, одна и та же вершина разрушала их все сразу. Но мне на это плевать. Я просто скажу, что это больше, чем N-N.5. Уж точно.
Я не буду пытаться оптимизировать. Я понимаю, что разрывая N-1.5 циклов, я при этом использовал уж точно не больше, чем N-1.5 вершин. А всего было N, значит осталось больше, чем N-1.5.
Так, еще один важный момент. Альфа от G штрих. Мы как делали G штрих? Мы брали каждую вершину и вместе со всеми ребрами удаляли. Могло вырасти независимое множество?
Очевидно, нет. Альфа от G штрих не больше, чем Альфа от G, а это меньше, чем Х. Значит, вот отсюда следует из всего вот этого неравенства, следует, что Х от G штрих больше, чем N-1.5, поделенное на Х.
Я пользуюсь все тем самым неравенством. Мощность В поделить на Альфа. Мощность В больше, чем N-1.5. Вот я написал N-1.5. Альфа меньше, чем Х, и оно в знаменателе. Поэтому опять знак правильно.
Может я очень медленно говорю? Или нормально?
Вот. Это асимпатически по-прежнему равно чему? Ну, по-прежнему в том смысле, что я пользуюсь по-прежнему вот этой оценкой.
Значит, Х у нас 3 логарифма на П. У нас получается вот здесь 3 логарифма, а П сюда перепрыгивает. О! Какая удача! Смотрите, что сохранилось.
НП равно N в степени тета. На 6 логарифмов N. А тета не сохранилась, но тета это одна-два х. Это мне легко напомнить.
Что можно сказать про функцию, которая тут написана, независимо от того, каким огромным мы фиксировали с самого начала L.
Она стремится к бесконечности, правильно? Со знаком плюс. Она стремится к плюс бесконечности. Даже если это очень маленькое число, логарифм еще медлен.
Она стремится к плюс бесконечности. Поэтому все, все. Существует такое N3, что для любого N, больше либо равного N3, х' больше, чем K.
Где K то самое число, с которого начиналась теорема. Вот она же сохранилась. Я доказал теорему? Да, этот граф может быть колоссальным, но я доказал.
Этот граф не содержит циклов, мы специально вот такого подпоцали, чтобы в нем циклов совсем не было. А хроматическое число у него все равно очень большое.
А теперь, конечно, хороший вопрос. Как представить себе такой граф? Мы же начинали с того, что это контр-натуитивно, да? А он есть.
А какая вероятность в него попасть, если просто случайный граф на большом греческом леве?
Ну, вроде как, мы оценивали все вероятности. В принципе, все кретиницы стремятся. Да, да, да. То есть можно найти скорость стремления.
Помните, я про свист говорил? То самый свист. То есть вероятность довольно большая. В общем, все не так плохо.
Другое дело, что N очень большое. Вам просто придется очень большие моделировать графы.
Я не буду рассказывать никаких конструкций. Я просто скажу, что первая конструкция появилась примерно через 10 лет после работы Эрдеша.
То есть Эрдеш доказал существование. А сконструировать такие графы, ну так, чтобы это было писательно, ну, полинамиально сложно.
Смогли только через 10 лет. Это сделал выдающийся математик Ласло Ловас.
Ласло, это имя Ловас, это фамилия, если кто вдруг не знает венгерских имен, который много чем прославился.
Но это один из самых крутых сейчас вот ныне здравствующих комбинаторщиков в мире. Ему уже, конечно, за 70, но он активен.
Он пишет статьи, книги. Он один из самых крутых специалистов области, и мы его точно встретим в этом курсе еще как минимум два раза.
Он придумал такие мощные инструменты, которые удается использовать для весьма интересных приложений.
В 90-е годы он довольно долгое время возглавлял исследовательский отдел в Microsoft Research.
То есть его вот эта вот математика комбинаторная там исключительно была тоже полезна, применялась.
Сейчас он главный венгерский академик, он руководит тамошней академией наук.
Ну а когда-то еще в начале шестидесятых он был, кажется, трижды победителем межнарога в математике.
Такая вот интересная судьба.
Так, ну что, теорему я доказал. Теперь давайте я, наверное, перейду, собственно, к общей картинке, которую я обещал.
Дозвонка я мало что успею, но давайте одну тривиальную вещь я расскажу.
Вот еще раз, чтобы вы почувствовали, логика-то какая. Есть очень крутой, красивый результат.
Ну, может быть, он сам по себе прикладного значения не имеет, он просто проясняет, как жизнь устроена на графах.
Что, оказывается, бывают очень нетривиальные конструкции.
С другой стороны, она мотивирует, в свою очередь, рассмотрение различных функций P от N и в попытке понять,
а как ведет себя хроматическое число случайного графа для данного вида функций.
Вот этим мы сейчас как раз и займемся, причем довольно долго будем заниматься.
Первый случай, который я хочу рассказать, который действительно тривиальный, это пусть у нас сейчас P от N,
это O маленькое от 1 поделить на N в квадрате. Ну, например, 1 поделить на N в кубе.
Или 1 поделить на E в степени N. То есть как-то очень быстро стремящаяся к нулю величина.
Как вы думаете, дорогие товарищи, чему в этом случае, скорее всего, я же говорил термин асимпатически почти наверное, да?
Вот чему асимпатически почти наверное равняется хроматическое число такого графа?
Один абсолютно правильно, потому что, ну, я не знаю, пусть X от G это число ребер в графе G,
тогда мат ожидания X это, очевидно, C из N подло умножить на P. Очевидно?
Ну, те, кто знают схему вернули, могут апеллировать к этому понятию, но это очевидный этап.
Значит, это ведет себя как P N квадрат пополам, ну, а N квадрат-то, вот оно где, это маленькая от единицы, все.
Так что, все. Вероятность того, что есть хотя бы одно ребро не превосходит EX стремится к нулю,
но значит, вероятность того, что нет ни одного ребра, стремится к единице.
Их сравняется нулю асимпатически почти наверное, ну, а значит, асимпатически почти наверное х от такого графа равно единице.
Раз у него ребер нет, можно все вершины спокойно в один цвет покрасить.
Граф целиком это такое независимое множество.
Перерыв 5 минут.
Так, ну давайте продолжим.
Ну, то есть совершенно неважно, как ведут себя функции маленькие по сравнению с 1 на N в квадрате.
Для всех для них уже ответ очевиден, хроматическое число почти всегда единица,
а остальными графами можно и пренебречь всеми остальными.
Настолько малая вероятность ребра.
В третьих других графах просто маловероятность.
Следующий результат очень походит по своему доказательству на то, о чем мы рассуждали до сих пор, но проще гораздо.
И так будет, как я говорил, плохая или дурацкая, глупая геометрическая прогрессия, а там будет умная.
Значит, второй случай пусть теперь F от N.
Ну, я не знаю, вот такое обозначение тоже было.
Омега маленькая от единицы на N в квадрате.
Ну, то есть обратная к маленькому.
То есть, давайте напишу, F на N в квадрате стремится к плюс бесконечности.
Но при этом F это все-таки у маленькой от 1 N.
Поднимаемся как бы на следующий этажик, и вот на этом этажике тоже окажется, что хроматическое число ведет себя совершенно четко.
Я утверждаю, что тогда асинтетически почти, наверное, х же равняется двойке.
Что такое х1 равняется омегам?
А я написал то есть, я даже написал.
Ладно.
Слушайте, я написал там.
Вот есть такие стандартные обозначения.
Омега маленькая это обозначение, противоположное о маленькому.
То есть, быть о маленьким это значит, когда вы P домножаете, то получаете в пределе 0.
А быть омега маленьким, это когда вы P домножаете, получаете в пределе бесконечности.
Вот то, что написано здесь, и то, что написано здесь, это одно и то же.
То есть, пояснение.
Я понял, что в анализе такого обозначения не было, но вот так.
А для у большого, например, противоположным является омега большая.
Это тоже стандартное обозначение из анализа, которого, видимо, в курсе просто не было.
Омега большая была?
Была, да, омега маленькая.
А, понятно.
А омега маленького нигде, или оно в алгоритмах было?
А омега маленького нигде не было?
А вообще нигде не было.
Ну не важно, ну не было, не было, но вот я вам рассказываю.
Вот, ну чему.
С одной стороны, поскольку Qn квадрат стремится к плюс бесконечности,
почти, наверное, ребро есть.
Ну, это можно как доказать.
Можно просто посчитать вероятность того, что есть хотя бы одно ребро.
Но какая? Нет, ну как это посчитать?
Это не так просто посчитать.
Х больше ребра в ноль единицы.
Я хочу доказать, что это стремится к одному.
Кто-нибудь понимает, как это сделать?
Я в прошлый раз рассказывал.
Некий общий рецепт.
А?
Э-э.
Э-э.
Про треугольники.
Помните вторую теорему?
Неравенство Чебышова.
Неравенство Чебышова.
И там был прямо рецепт.
Вот такой.
Единица минус dx поделить на мат ожидания х в квадрате.
Не помните такого неравенства?
Я очень четко тогда постарался подчеркнуть.
И надеюсь, что мне это удалось хотя бы с точки зрения записи на видео и ваших записей в конспектах.
Так-то я чувствую, что не удалось.
Потому что вы не помните.
Но я очень старался сказать, что это верно ведь не только для количества треугольников.
Но для любого счетчика на графе.
То есть если мы считаем в графе какие-то характеристики.
Число ребер, число треугольников.
Число, я не знаю, циклов какой-то длины.
Всегда можно сделать вот такую оценку.
Если х на графе или вообще на каком-то случайном объекте.
Принимает не отрицательные целые значения.
То это неравенство всегда верно.
И оно следует из чебыша.
Вы как-то на меня очень печально смотрите.
Было же такое, да?
Вы его прямо доказали.
Но тут я думаю, что не очень велика эта проблема.
Может правда посчитаем.
Нам нужно, чтобы вот это стремилось к нулю.
Как и в прошлый раз, когда мы с треугольниками работали.
Чему равна дисперсия числа ребер?
Они независимы.
Да, ребра независимы.
Поэтому дисперсия это сумма дисперсии.
Правильно совершенно.
То есть дисперсия х это снова ц из n по 2 умножить на дисперсию индикатора ребра.
Вот такой вот величины.
Единица и ноль.
Здесь если данное ребро присутствует.
Данное ребро в графе g.
Ну а ноль иначе.
Вот ц из n под вот таких слагаемых формируют дисперсию.
На что надо умножить?
На дисперсию вот такой случайной величины.
Чему она равна?
F-P².
F-P².
Совершенно правильно, да.
F-P умножить на 1-P.
И это конечно тоже базовая вещь из курса теории вероятности.
Когда там начинаются биномиальные случайные величины.
Нормальный темп?
Не нужно что-то пояснить.
То есть отношение дисперсии к квадрату мат ожидания такое.
C из n по 2 на P на 1-P.
А мат ожидания у нас c из n по 2 получается на P.
И это всё в квадрате.
Шлёп.
Не шлёпнулось, да?
Ну я хочу вот так сделать.
Тогда вот так ещё надо.
И по-моему получилось, да?
По-моему получилось.
Так, то есть у меня получилось 1-P поделить на P.
И на c из n по 2.
Но по-моему всё очевидно.
P на c из n по 2 стремится к плюс бесконечности за счёт вот этого условия.
Согласны, да?
Ну тут P на квадрат стоит.
Оно стремится к бесконечности.
Ну а за счёт вот этого условия с запасом P это само стремится к нулю.
То есть числитель это единица.
В общем, всё стремится к нулю, как нам-то бы и хотелось.
Но я хочу, чтобы вы научились этим инструментам-то пользоваться.
Это просто, это упражнение.
А может быть ещё раз тем, что P маленькая от единицы на n?
А может и нигде.
Наверное здесь мы и не воспользуемся.
Я глупость сказал. Я сказал, что вот это примерно единица.
Но это и так не больше, чем 1.
Конечно, всё.
Правильно, правильно. Сказал глупость. Это излишество.
Здесь совершенно неважно, что P маленькая от 1n.
Вот сейчас мы будем доказывать, что Хи обжав точности равно 2.
И вот тут мы этим воспользуемся.
Пока я доказал, что оно не меньше 2.
Так, друзья, вы понимаете, что оно не меньше 2?
Потому что есть хотя бы одно ребро.
И уже его точно в два цвета придётся красить.
Я пока доказал только это.
Я доказал, что асимпатически,
почти наверное,
Хи от g больше не бромняется к 2,
потому что я доказал,
что с вероятностью стремящихся к 1
в графе ребра есть.
Теперь мне надо обратное неравенство доказать.
Вот тут я воспользуюсь, конечно, вот этим.
Я возьму новую случайную величину,
напусти грехла от g.
Это будет количество простых циклов.
О, слушайте, а может я этого не говорил
ни в какой момент на этих лекциях?
Я вообще думаю, что это должны разбирать
как минимум на семинарах.
Но давайте я это зафиксирую.
Есть такой прекрасный критерий.
Граф двудолен тогда и только тогда,
когда в нём нет ничётных простых циклов.
Давайте я это напишу.
Утверждение.
Теорияма на самом деле.
Я считаю, вы должны уметь её доказывать,
но я обычно это в курсе не делаю сам.
Граф двудолен,
то есть у него хроматическое число 2,
хи от g равно 2.
Тогда и только тогда,
когда в g нет ничётных простых циклов.
То есть простых циклов ничётной длины.
Это упражнение, докажите сами.
Хотя интуиция,
смысл за ним очень важный.
Понятно, что если в графе
есть цикл ничётной длины,
то он не красится в два цвета.
Очевидно, правда же?
У любого цикла ничётной длины
хроматическое число 3.
Но обратное тоже можно доказать.
Оказывается, что это критерий.
То есть если в графе нет ни одного
ничётного простого цикла,
то он красится в два цвета.
Но вообще ни одного,
не путайте с предыдущей теоремой.
Может быть предыдущая теорема
в свете вот этого нового знания
для некоторых из вас,
она ещё интереснее звучит.
Если вообще нет ничётных простых циклов,
то хроматическое число 2.
Но оно может быть,
хроматическое число может быть
сколь угодно большим.
Если мы избавимся не от всех циклов,
а только от коротких,
но при этом в степени их короткости
вы помните какая.
Сколь угодно большая.
Понимаете, да?
То есть в свете этого
простенького результата
ещё больше играет
такими красками теоремы Эрдаши,
с которой мы начали.
Ну ладно, если вы это знаете,
то вы понимаете, что мы с запасом
получим нужный нам результат,
если докажем, что асимпатически
почти наверное у равняется 0.
Вообще нет никаких циклов
не чётных, а не только простых.
Ну тут простые, конечно.
Вообще никаких нет циклов.
Слушайте, а если в графе нет циклов,
то что это?
Лес, правильно?
Почему только один человек говорит?
Лес, конечно, в графе нет циклов, это лес.
Если бы он был связанным дополнительно,
было бы дерево, но так это лес.
То есть мы сейчас докажем, что
при p равном о маленькой от одной n
граф случайный, это лес,
почти наверняка.
Вы себе это как-то помечайте,
потому что это всё важно.
Надо максимально неформально понимать
то, что происходит.
Я же не просто доказываю, что
хроматическое число это двойка,
а я ещё параллельно поясняю, почему двойка,
а потому что там ничего кроме деревьев нет.
Конечно, такой граф в два цвета красится.
Даже вот этот критерий,
я его просто походу вспомню.
Он здесь не нужен.
Граф совсем простый.
Так, доказываем
мат ожидания y, почему равняется.
Мы сегодня это уже проходили,
но тогда нас интересовали циклы длины
больше, чем l, а сейчас нас интересуют
все циклы.
Поэтому будет сумма по r от тройки
теперь уже до n, а не до l,
до n, l сейчас никакого нет.
Ну а тут всё то же самое,
c из n по r
на r-1 факториала
пополам
и на p в этой степени.
То есть это прямо повторяет то, что у нас было
для x и этого в доказательстве.
Услеживаете, да? Всё нормально?
Не гоню.
Вот, ну оценка будет точно такая же,
идиотская поначалу.
Сумма по r от тройки
до n.
Давайте сразу напишу n по r,
чтобы не морочить голову.
Просто в точности такая же.
Мы c из n по r оцениваем как n в r
и поделим на r факториал,
сокращаем, остаётся n по r.
Но вот я ещё раз напоминаю,
товарищи, помните, я говорил глупая
геометрическая прогрессия и умная.
Та была глупой, потому что n по p
было больше единицы.
Но сейчас у нас n по p
это...
это что?
Это маленькая от единицы, потому что
p этого маленькая от 1n.
Значит, n по p этого маленькая
от единицы.
То есть это убывающая геометрическая
прогрессия. Поскольку я предпочитаю
суммировать бесконечно, я напишу вот так.
Это меньше, чем сумма по r
от тройки до бесконечности.
n по p в n.
То есть я не могу здесь так оценивать,
как оценивал в теории Мердыша.
Я не могу написать n умножить на n по p в n
или что-то такое.
Здесь более умная геометрическая прогрессия,
более сложно устроена.
Но идёт, мы умеем суммировать.
Это получается n по p в кубе
на 1
1 минус n по p.
Так.
У нас целые формальные степенные ряды были.
Так что вы должны помнить.
Так суммируются бесконечные геометрические прогрессии.
n по p стремится к нулю.
То есть вот это вот
стремится к единице.
Это стремится к нулю в кубе.
То есть к нулю.
Значит, всё стремится к нулю.
Ну и опять стандартный вывод.
Вероятность того, что y
больше либо равно единице, согласно
неравенству Маркова не больше, чем
ей, он стремится к нулю.
Но, следовательно,
асимптатически
почти, наверное, y равен нулю.
То есть циклов нет.
То есть асимптатически
почти, наверное,
форматическое число леса
оно не больше 2.
Но ребра есть.
Пересекаем два события, значит оно
в точности равно 2.
Почти, наверное.
Нормальный пока темп?
Вот, а у нас уже полно времени.
Так.
Ну, следующий пункт я
пока, по крайней мере, не буду доказывать.
Я его оставлю, может быть
оставлю на совсем без доказательства.
А может быть я позже успею что-то
про это рассказать, но это будет другая
тема, и там, если что, я к этому
моменту вернусь.
Давайте пока это будет теорема
без доказательства.
Ну, может быть
что-то из этого я потом докажу.
Если докажу, то к этому
вернемся.
Третий пункт такой будет.
Пусть
теперь
В на Н стремится
в плюс бесконечности.
Ну, или что то же самое
В это омега маленькая от одной Н.
Пусть В на Н стремится в бесконечности.
А, нет, не хорошо, зачем?
Чтобы оно стремилось в бесконечность.
Правильно, извините, извините.
Нет, конечно.
Вот такой будет бесконечность,
это позже.
Нет, вот такой будет интересный
случай, мы пока границы не рассматриваем.
Пусть В
равняется С
поделить на Н.
Заговорился. Нет, это будет
пограничный случай. Видите, В на Н
не стремится пока в бесконечности.
Просто равно константе.
Причем константа будет
меньше единицы строго.
Оказалось.
Но вот для чего-то это нужно.
Отвертается, что тогда
симпатически
почти
наверное
Ну, давайте я
напишу коротко.
С
от Ж
равняется тройке.
А в скобках поясню
почему.
То есть, когда мы пункт 2 доказывали,
это получилось, потому что граф не
являлся лесом, но при этом какие-то
ребра содержал.
А здесь я объясню, почему тройки.
Более разверженное утверждение
того же самого результата,
из которого просто следует, что
хеоджером на тройке. Утверждение такое.
Существует
какая бы функция,
давайте, С
функция,
зависящая от n,
такая, что
ψ этого маленькая
от n.
Так.
И
а симпатически
почти наверное
n
минус
ψ от n
вершин
графа
g от np,
случайного графа g от np,
принадлежат
древесным компонентам,
ну древесным,
то есть тем, которые образуют целиком
и полностью из себя день,
древесным компонентам.
Ну сейчас я еще подробнее скажу.
Значит, n минус
n вершин графа принадлежат древесным компонентам,
а ψ от n вершин
оставшиеся
принадлежат, что бы вы думали?
Циклам?
Ну не циклам.
Как вы их называете?
Унициклическим компонентам.
Солнышком.
Нет, ну не совсем солнышком.
Дерево с ребром?
Ну да, дерево с дополнительным ребром.
Вы их называли унициклическими компонентами.
Унициклическими графами.
Я их сосчитал даже.
Асимптотик.
В прошлом году количество, а в этом году асимптотик.
Так, принадлежат унициклическим компонентам.
Ну то есть понимать надо так.
В случайном графе, асимптотически,
почти наверное,
все связанные компоненты это либо деревья,
либо унициклические графы.
То есть либо, если у компонента К
вершин на ней К-1 ребро,
либо К ребр.
Причем вершин,
принадлежащих
древесным компонентам,
очень много,
это почти все вершины.
Сима маленькая от Н.
Почти все вершины графа,
это вообще вершины,
принадлежащие только деревьям,
древесным компонентам.
И лишь малая часть от общего числа вершин
является все-таки унициклическим компонентом.
И там, среди циклов, есть циклы нечетной длины,
поэтому оказывается,
что х все-таки в точности равно тройке.
Так я достаточно ясно проговорил?
Ну,
поскольку я пока это не доказываю,
вот так, ни в какую сторону,
не то что хи ажже
не превосходит тройке,
не то что оно больше либо равно трех,
пока это как бы идет в курсе так.
Если я успею прочитать
то, из чего будет хотя бы часть этого следовать,
я расскажу.
Я вернусь к этому.
Пока так.
Вот, ну и теперь хочется понять,
конечно, казалось бы, что будет,
если ц больше единицы,
про это я сейчас умом молчу.
А я все-таки буду рассказывать
про случай, когда Pn стремится
к бесконечности.
Чуть было не началось.
Я сформирую сейчас
две теоремы.
Обе они принадлежат
еще одному замечательному математику,
который сегодня еще не упоминался.
Сегодня было два Генгра.
Три!
Два.
Но у вас два, у меня три.
Помните Козлика?
Вот те, кто пришел пораньше,
там Козлик был нарисован.
Это про Петра Франкла.
Он тоже Генгр.
Но это я первокурсникам рассказ.
Про Козлика.
Я так понимаю, что не все помнят про Козлика.
Некоторые помнят.
Как так вышло, я не знаю.
То ли я школьникам кому-то рассказывал.
Похоже, что я вам, как первокурсникам,
про Козлика не рассказал.
Ну, значит, расскажу,
когда про Петра Франкла зайдет речь.
У вас сегодня я говорил
про двух венгерских математиков.
Это Эрдеш и Лоос.
Вот еще один великий
венгерский специалист
по теории случайных графов,
зовут его
Поттах
Белла
Боллобаш.
Ну, тоже очень заслуженный,
пожилой человек,
под 80 сейчас.
Тоже активен как математик.
У него куча учеников,
много очень интересных результатов.
Теоремы, о которых пойдет речь,
это 80-е годы 20-го века.
Тоже очень интересная, кстати,
его история.
Он приезжал в Советский Союз
еще в каком-то 68-м или 9-м году.
И был год
на стажировке у известного
такого советского математика
Гельфанда.
Может, слышали?
Очень известный товарищ.
Может, по линейной алгебре
какой-нибудь вам учебник советовал,
но он выдающийся был академик.
В общем, в 60-е годы
Балабаш приезжал сюда.
Ну, не на Фистех,
а в Институте Клоу.
А потом он сбежал
из Советского лагеря,
и сейчас он такой именитый
профессор
одновременно в Великобритании и в США.
Но в Великобритании
он просто в Кембридже, причем он там
такой очень серьезный
фелло этого Клинди Колледжа.
А в Америке он в каком-то
Мемфисе профессор.
Он один из самых заслуженных товарищей
в этой области.
Нашу страну очень любят,
всегда с удовольствием в нее приезжала,
к моему же приглашению тоже.
В общем, первая теорема, которую я хочу сформулировать,
звучит так.
Пусть П.
А, еще один момент.
Вот эта вот Белла, это мужское
венгерское имя, если кто вдруг не знает,
то может кто-то сидит и думает,
что это я все? Он, он, он.
Сексизм какой-то.
Ничего подобного, это он
действительно, просто мужское имя.
Белла Бартек это тоже мужчина-композитор,
если кто не знал.
По-английски пишется Балабаш вот так.
Ну, не по-английски, по-енгерски.
Имейте в виду, что если там С написано,
то это Шэ.
По-енгерски это Шэ.
А вот Ловас, помните, он не Ловаш.
Он вот так пишется.
Вот это СЗ, это С.
А если бы было С, то был бы Ловаш.
Но он не Ловаш, он Ловас.
Ладно, пусть П
равняется Н в степени
минус альфа.
Вот у нас сегодня ровно такая
ситуация была.
Н в степени тета минус один.
Но если через альфу обозначить
один минус тета, то будет Н в степени
минус альфа.
У нас прямо такая ситуация была.
Пусть давайте альфа
от 5 шестых давайте.
От 5 шестых до единицы.
Понимаете, что значит, что альфа
меньше единицы?
Это значит, что мы здесь уже находимся
в ситуации, которая
противоположна данному.
П умножить на Н,
тут вот, стремится к бесконечности.
Видите, да?
Если альфа меньше единицы, то все.
П на Н стремится к бесконечности.
Вот цепь п умножить на Н
то все. П на Н стремится к бесконечности.
Вот с этим режимом мы разберемся.
То есть абсолютно полную картинку я не сообщу,
но очень близко к полной расскажу.
Так, пусть П вот такой,
как здесь,
тогда
существует такая функция
У,
зависящая от Н, от П
ну или от альфы, если хотите.
П, назначено определяется альфой.
Что, вероятно,
вероятно,
стремится к единице,
а симпатически почти наверно
происходит следующее.
Хиадже
принадлежит У,
У плюс один,
У плюс два,
У плюс три.
Это совершенно офигенный результат.
Но можно, конечно, пошутить.
Вот мы шли до пункта 3,
и у нас все время хроматическое число
концентрировалось в одном значении.
Концентрировалось, то есть принимало его
с вероятностью стремящееся к единице,
правильно?
Сначала оно концентрировалось в значении
1, потом в значении
2, потом в значении
3, а теперь не в значении
4, а в четырех значениях.
Ну так, тоже довольно смешно.
Но это скорее просто для смеха,
сейчас я объясню, почему это.
Не существенно.
В любом случае, очень важно,
что даже когда вероятность
ребра относительно большая,
гораздо больше, чем в пунктах 1-3,
достаточно большая,
хотя все еще стремящееся к 0,
то имеет вместо вот этот феномен
концентрации хроматического числа
в очень маленьком количестве значений.
Я понятно говорю?
Или немножко уже
тяжело воспринимать.
Смотрите еще раз, хроматическое число графа
это же число, которое может быть
любым от единицы до числа вершин, до n.
Может же хроматическое число быть
1, 2, 3, 10, 100, n,
любое.
Мы берем случайный граф
и с вероятностью стремящееся к единице,
или что то же самое, а симпатически
почти, наверное, его
хроматическое число почему-то
прочитает кучковаться.
Вот я это называю концентрироваться,
ну нормально по-моему называют,
все так называют, и слово интуитивное
понятное, да?
Собирается лишь в кучке значений.
Все остальные оно скорее всего отвергает.
То есть вы знаете, что если вы при таком
распределении получаете
на вход случайный граф,
скорее всего вы неправильно посчитали
его хроматическое число,
если оно не попало вот в это множество.
Я могу так прокомментировать с практической
точки зрения.
Понимаете, да?
Своего посчитали,
оно не попало в эти 4 числа,
ой, наверное вы ошиблись.
Я правда не пишу, что такое
функция У. Значит, замечание,
подумайте, это очень несложное
на самом деле упражнение,
но мы любим его спрашивать на экзамен,
если у вас будет время подумать заранее,
будет полезно. Ну, спрашивать
на высокую оценку, конечно.
Замечание состоит в том, что вот эта
патент П, она всегда стремится
к плюсов бесконечности.
То есть, если до пункта 3 включительно
у нас концентрация была в константном
значении 1, 2, 3,
то здесь концентрация
в четырех значениях,
величины которых с ростом n растут.
Это неожиданно.
Да, ну вот, тем не менее,
это не очень сложно.
Нет, в смысле неожиданно, что при том,
что они растут, но все еще концентрируются.
Да, вот они растут, а оно все еще
концентрируется. В этом тоже некий пафос.
Да, правильно. Вы правильно совершенно
отмечаете. Понятно, да, о чем мы сказали?
Это тоже очень важно.
То есть, оно нефиксированное само вот это вот
множество значений, оно от n зависит,
но оно все время мощности не больше четверти.
Такой вот
удивительный совершенно результат.
Мы его практически полностью докажем
там по модулю некоторого факта, который
я оставлю в заскобке.
Это удивительно совершенно,
это мегакатарсис, это очень красивая
теория. Это один прямо из
одна из жемчужин этого курса,
но тут жемчужин будет еще много.
Курс такой очень много
их содержит.
И вторая теорема,
которую мы докажем, тоже по модулю
некоторого факта,
интуицию, которую я постараюсь
создать, того же самого факта,
что теорема 1,
тоже принадлежащая
Балабашу, доказанная примерно тогда
же,
теорема 2,
80-е,
точный год Янику.
Мы находимся
в каком-то смысле здесь
на правой границе спектра значений,
которые разумно присваивать
в величине P, а именно пусть P
это просто одна вторая.
То есть мы возвращаемся
к самой простой ситуации,
когда все графы равны вероятности.
Помните, что P равно 1 и 2,
это значит, что у нас просто равномерное распределение
на множество всех графов.
Но это уж совсем не стремячусь
к нулю функция.
Пусть P равно 1 и 2
утверждается, что тогда существует
такая функция phi,
что phi это
O маленькое от
чего?
От N поделить на логариф N.
А phi-то от чего зависит?
Ну phi от N зависит, конечно.
Я на самом деле не знаю, зачем
я в прошлый раз это написал.
Если я пишу, что phi маленькое от чего-то,
значит phi от N зависит.
Это в принципе подразумевается.
Phi, зависящая от N, которая
мала по сравнению с N на логариф N.
И такая, что асимпатически
почти наверная,
то есть
я вот так
напишу N
поделить на 2
двоичных логарифма N
минус phi от N
меньше либо
равняется phi от G,
меньше либо равняется N
поделить на 2
лог двоичной N
плюс phi от N.
Так, что здесь сказано?
Здесь сказано, что тоже имеет
место в каком-то смысле концентрация.
Но не такая яркая
не в одном значении
или в четырех значениях,
а на целом
отрезке значений.
Но тем не менее, поскольку phi
бесконечно мала по сравнению с N
делить на логариф N,
а вычитается или прибавляется она
к величине порядка N
поделить на логариф N,
то отрезок как бы асимпатически
притесняющийся вот к этой величине.
Понятно говоря, нет?
Отрезок тех значений, которые
почти с гарантией
будет принимать хроматическое число
равномерно случайного графа,
он не то чтобы сужается, он конечно растет,
потому что phi может стремиться к бесконечности,
но асимпатически каждая
из его границы, левая и правая,
ведет себя как N поделить на 2
лог двоичной N.
Тильда N поделить на 2
лог двоичной N.
И вот это вот тоже
тильда N поделить
на 2 лог двоичной N.
Сейчас понятно, что я говорю?
Поскольку phi это он маленький,
ну я надеюсь всем понятно,
логариф натуральный, логариф двоичный
отличается в константу раз.
Я конечно могу здесь написать логариф двоичный,
но от этого ничего не поменять.
Так, просто на всякий случай,
мало ли вдруг кому-то это не понятно.
То есть получается, что
асимпатически, почти наверное,
оно может разбегаться
от своего вот этого какого-то такого
притягивающего центра,
но если не разбегается, то на величины
бесконечно малые по сравнению с величиной центра.
Так.
Вот это то, что мы почти докажем.
И начнем мы этим, видимо, заниматься уже в следующий раз.
Кстати, помните, я в прошлый раз
не доказал третье неравенство.
Было Марков, Чебышов и некое мифическое
третье неравенство.
Вот с него я начну в следующий раз.
Я сегодня его опять не успел,
потому что много рассказывал,
но в следующий раз я точно с него начну,
потому что без него мы не сможем понять вот того
главного инструмента, который позволяет доказывать
такие теоремы.
Так, чего я еще напоследок,
у меня еще есть несколько минут, хочу сказать.
Во-первых,
это то, что мы докажем.
Но сейчас умеют
вот эти 5 шестых заменять на одну вторую,
то есть это не самое лучшее,
что известно,
расширяет интервал значений альфы,
для которых все это верно.
Ну, это не обязательно знать,
но если хотите, это вот как на себя пометьте,
это хотите, если хотите, неважно.
А вот здесь вот умеют
писать у плюс один.
То есть концентрации даже не в четырех,
а в двух значениях на самом деле.
На большем интервале возможностей для альфы
и всего в двух значениях.
Но мы докажем только для альфы больших 5 шестых,
и в четырех значениях докажем.
Уже будет не тривиально,
очень красиво.
И я считаю, что оно вполне достаточно для курса,
который слушают второкурсники,
потому что лавриата, наверное, достаточно.
Теперь смотрите сюда.
Здесь есть концентрация,
но она симпатическая.
А тут есть концентрация,
и она офигенная совсем.
И вот был вопрос.
Долгое время открытый.
Гипотеза такая.
Гипотеза? Проблема.
А можно
вот здесь вот в этом месте написать
не phi, он маленькая
от центра,
а phi равное константе.
Ну как, вот здесь phi равно константе.
Ну плюс-минус один,
грубо говоря.
А здесь вот к нему плюс-минус один,
а плюс-минус что-то, что может расти к бесконечности.
Ну важно, что мало по сравнению с этой дроби.
И вот долгое время не понятно было,
то ли можно константу поставить,
то ли нельзя.
Буквально пару лет назад,
буквально, вот я читаю этот курс давно,
и вот пару лет назад
произошли изменения.
Оказалось, что нет.
Сейчас строго доказано, что заменить phi на константу
в этой теории в принципе нельзя.
То есть вот тут уже
концентрации в нескольких значениях нет.
Здесь она есть,
при том, что у стремится к бесконечности.
Здесь у тоже стремится к бесконечности.
Но вот это phi,
как бы мы ни старались,
оно точно
больше, чем корень четвертой степени
из N.
Ну или даже не больше, а давайте вот так.
Омега большая
от корни четвертой степени
из N. Это сейчас доказано.
Невозможно подобрать такую функцию,
которая была бы мала по сравнению с корнем
четвертой степени,
и которая бы вот здесь вычиталась, а здесь прибавлялась.
Все-таки рост вот этой
phi, он выше, чем
рост корни четвертой степени из N.
Это мы, конечно, не собираемся доказывать.
В курсе я это не включу.
Это сложно.
Ну, наверное, все на сегодня.
Что я еще успею-то?
Давайте так.
