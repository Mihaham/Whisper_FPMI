Ну, что мы сегодня с вами будем заниматься? Мы сегодня будем оптимизировать Флойда.
Свидетели помогут нам оптимизировать Флойда, да. Хотя свидетели они казут... Ну правда, ладно, не
всего. Ну, потому что, да, вот тут сразу можно ввести так терминологию, которая может, значит,
появиться там в некоторой литературе. Вот, допустим, у нас есть, допустим, у нас есть какой-то неориентированный,
еще у нас будут неориентированные графы. Вот такие вот. Иногда, может быть, даже взвешенные. Вот. И
нам три нод. И мы хотим искать корчайшие пути. Так вот, значит, нод. На самом деле,
постановки задачи могут быть разные. Вот. Значит, смотрите. Может быть, постановка SPD. Угадайте,
что это. Что это может быть? Это в контексте корчайших расстояний. Ну, почти. Значит,
это означает Single Pair Distance. Совсем. Ну, как бы да. Вот. То есть, это означает,
в этой постановке задачи вам нужны две вершины. Тупо две вершины. Найдите между ними корчайший путь.
Вот. Есть братская постановка SP SP. А вот здесь уже возникает Short SP. Вот. Как вы думаете,
чем эта постановка задачи отвечает? Совершенно верно. Да. То есть, здесь нужно найти тупо
чесеку, а здесь нужно выставить корчайший путь. Да. Это разные, да. Это разные задачи. Иногда даже
с разными симптомчиками. Вот. Значит, есть. Ну, соответственно, что будет означать D и SP,
мы уже поняли. Вот. Значит, Single Pair означает, что просто данная пара, разберитесь с ней. А есть
есть постановка задачи Single Source. То есть, это означает, что мы ищем корчайшее расстояние от одной
вершины до всех остальных. Ну, и корчайшие пути, соответственно, тоже. Ну, там, имейте в виду,
дерево корчайших путей. Ладно. Значит, есть Single Source. Что дальше? Вот. Есть еще, значит,
ну, соответственно, какие еще могут быть постановки? Между всеми парами. Мало
подсорс. Правильно. Но, на самом деле, как ни странно, есть постановка SDD. И вот это, честно
говоря, меня удивляет такая постановка, но, видимо, когда-то она имеет место. Это Single Destination.
Я тоже не понимаю, но, видимо... Нет, ну там, нет, нет. Я себе могу вообразить, почему могут
быть проблемы. Смотрите, потому что в реальной жизни граф не обязательно задан вам, вот как он вам
задан, да? То есть часто он может быть так, что ребра вам не заданы в явном виде, есть какой-нибудь
мистический итератор, который внутри себя и два линии из интернета подгружает эти ребра по одному
или по несколько. Вот. И тогда получится, что там, то есть просто так на соляву себе взять вершину и
перебирать все ребра, которые в нее входят, у вас не получится. Ну, знаете, мне кажется, такое объяснение
может быть. Но, конечно же, нас будет интересовать APD, APSP. Что это значит?
Совершенно верно. Вот это, собственно, эта задача нас и будет интересовать. То есть это называть,
когда мы ищем качайшие там, возможно, пути или расстояние в том или ином виде, вот, собственно,
между всеми парами вершин. Вот. Ну, там дальше еще могут быть различные модификации. Ну, там на
тему того, какие ограничения там мы с вами любим. Вот. Значит, собственно, что мы, какую задачу мы сегодня
с вами попытаемся решить. Попытаемся мы сегодня с вами решить задачу, то есть задачу действительно
сначала APD, а потом APSP, но в предположении, что все веса ребер единичны. Возможно, даже для
достаточно разреженных графов у нас, собственно, ничего не получится особо интересного. Вот. Но тем
не менее. По крайней мере, получится вот такое вот чисто теоретическое, по крайней мере, чисто
теоретическая интересность. Называется будем смотреть. Вот. Значит, что будет дальше? Ну, за
какой симпточку? Ну, конечно, в тупую мы могли бы решить эту задачу. За какую симпточку? Ну, а быстрее.
Как? Ну, по BFS за сколько работает? Да. Ну, так. То есть, по-хорошему, решение с BFS-ом это от NN. Да.
Но сегодня, вероятно, мы попробуем решить задачу по-другому. Ну, вероятно, быстрее, чем за N2. Вряд ли.
Быстрее, чем за N2. Вряд ли. Да. Но за N2 у нас и не получится. Максимум, что у нас теоретически может
получиться, это N2 log2 N. И то вряд ли, если честно. Да, спрашивается, да. Спрашивается,
почему я не знаю точного ответа. Потому что, значит, в нашем решении будет фигурировать такая
красивая штука, как M от N. Где N от N, это называется время перемножения матрас.
Незапно. Да. Ну, почему? Вот. Ну, почему это M на N? Ну, потому что точную симпточку за сколько
это можно сделать, конечно, никто и не знает. Но в том плане, что нет вот такой симпточки,
что за столько можно, а быстрее вот железобетонно нельзя. Вот прям наука умеет показать. То есть наука
как бы умеет показать, что, наверное, M от N равно ω от N2. Вот. Больше пока наука ничего не умеет.
С одной стороны. С другой стороны, как бы наука умеет, конечно, показать, что там M от N равно
ω от N в степени 2.3279. Бла-бла-бла. Вот есть какой-то там вот супер умный метод,
который это делает? Триоконстант. Не знаю. Ну, скорее всего, бородская, да. Ну, как бы это тоже крутой метод.
Нет, я не прав, не прав, не прав. Тут 7, тут 2. Это важно. Нет, это важно, потому что это улучшение,
знаете, тут замечательно написано, это улучшение метода Копперсмита Винограда, который работает
за O от M в степени 2.3754. Да, вот там чемпионат вот до такой степени идет, да. Хотя вот туда-то вот.
Ну, это нормально, там в науке бывает такое, знаете. Потому что Регародский рассказывал историю, что как-то
вот Регародский участвовал в решении одной задачи. Там, в чем забавно было, что сначала задача
оставилась там, то есть была там постановка задачи вида. То есть можно ли придумать множество чего-то
там с такими-то свойствами. Долгое время наука считала, там думали-думали, как доказать, что нельзя,
что-то доказывали, а потом в итоге пришли какие-то израильцане и доказали, что там такое множество
существует, причем размеры тысячи с лишним. И начался чемпионат на кто меньше. То есть он там
рассказал такое, что сначала там что-то пришли, кто-то там рассказал на 700, потом пришел на 500,
потом пришел Вайсбах. Он говорит, там пришел некто Вайсбах, там доказал, что что-то там типа на 400.
Потом пришел лично Григородский и доказал, что можно сделать за 260. Так вот, говорит,
Вайсбах не сдавался. И он просто, вот это, и он сумел доказать, что можно за 260. Вот это Григородский
грустно рассказал, но я там просто не досмотрел, он просто там взял мой метод и просто там аккуратно
допилил. В итоге потом пришли еще какие-то люди там и доказали, проступися. Собственно, да,
но вот такие чемпионаты, вот такие чемпионаты, в общем, в науке сплоши рядом происходит. Так что,
как говорится, занимайтесь математикой, вот будете, как говорится, это будет круче чемпионат мира
футбола. Так, значит, мы не будем изучать, хотя могли бы, наверное, но не будем, пожалуй,
изучать этот метод. Вместо этого подумаем, чего можно сделать вообще, вот, чем это нам может помочь.
Тут как бы тоже нам из случаев заявляют, что на практике, конечно, с большим удовольствием Штрассена,
конечно, напишут. Но вообще давайте подумаем, а чем нам вообще перемножение матриц могло бы вообще помочь?
Ну, давайте скажем, что А это матрица смежности. Так, ну вы, собственно, изучали, что такое динамическое
программирование. Поэтому к вам вопрос, что такое А в степени D? Вот, допустим, А, ячейка УВ, А в степени D.
Там единичка, видимо, если есть путь для нырога D, что-то, да. Так, очки.
Давайте, можно прям вот максимально точно сказать, что это за число?
Какие? Ровно, ровно. Ну да, то есть это да. Да, правда, не обязательно простых путей, правда, при этом.
То есть путей, состоящих из дырёбер, но это могут быть какие-то вот такого вот рода, вот туда-сюда,
обратно пути. Да, то есть это вот количество путей длины D. Да, но ровно D, это важно. Ну, потому что,
когда вы перемножаете, там, как бы, например, А на А, да, то есть вот там, то есть, как бы, и что вы вот в УВ,
тогда вы перебираете все вершины W такие, что из УВ идёт ребро и ВВ. Из УВ, в общем, идёт ребро,
так что, поэтому тут ровно. Поэтому, если хочется там что-то меньше либо равно, то придётся,
возможно, что-то по сумме. Ну, значит, давайте думать, чем нам это теоретически может помочь?
Ну, много чем. Ну, на самом деле, да. Давайте представим вот что. Значит, начнём мы с вами,
то есть, может быть, начнём мы с вами даже вообще, сейчас вот без всяких вероятностей поначалу,
потому что мы будем искать даже не кратчайшие пути, а, собственно, сами расстояния. То есть,
вот давайте себе скажем, что у нас, объявим себе вот эту мистическую матрицу, что D УВ,
это вот, допустим, расстояние от УВ. Тогда при неё можно сформулировать некие мистические свойства.
Какие свойства можно сформулировать? Вот давайте прям это можно назвать как леммайки.
Свойства можно сформулировать такие. То есть, для любой вершины W, являющейся, допустим, соседом У,
что можно сказать? Можно сказать, что D от УВ, это что такое? Это, соответственно,
не более чем D от, соответственно, УВ плюс один, но, с другой стороны, и не менее чем D УВ минус один,
потому что, напоминаю, граф у нас не ориентирован. Подсорялся с таким вот вершин?
Ну, если мы знаем правое из них, то левое то же самое. Ну, типа того, да. То есть, мы просто
замечаем, что к ревру можно относиться как в одну, так и в другую сторону, но при этом ещё важно
заметить, что существует такое W, красивое, очень, что D от УВ равно D В плюс один. Согласны?
Или не согласны? Ну, если они неравны. Нет, в смысле неравны. Нет, существует такое,
да? Ну, как сказать, нет. Ну, потому что, смотрите, рассмотрим, как чаще путь УВ.
Ну, если У равно В, то это ноль. Ну, хорошо, ладно. То есть, давайте, если называть путь
неравновое, хорошо. Или даже, возможно, нам будет даже полезно рассматривать это,
что то же самое равенство в виде, что D В В равно D У В минус один. Вот так. Вот. Ну,
то ж понятно почему, правда? Да. То есть, просто первая вершина на пути. Вот. Так что, соответственно.
Вот. Ну, в принципе, да, то есть, мы могли бы пытаться решать задачу нот. Ну, в принципе,
на самом деле, да. То есть, имея в принципе вот это вот свойство, можно было бы пытаться
решать действительно задачу за m от n умножить на n. Ну, да, в том плане, давайте найдем все матрицы
от нуля до n. Ну, и там, соответственно, для каждой ашки, то есть, для каждой пары УВ найдем минимальную
матрицу, в которой ее значение отлично от нуля. Вот. Ну, там, да. Вот, конечно, возникнут всякие
экспедиционно растущие коэффициенты, потому что мало или сколько там существует путей,
называется, если граф полный, например. Сейчас, еще раз, мы будем для каждого пара искать
минимальную матрицу, для которой там ни 0. Ну, могли бы, да. Но это уже n куб. Да. А, ну да. Ну,
m от n на n, да. Могли бы. Поэтому мы пойдем другим путем. Значит, смотрите. Следующая идея,
да. Ну, вот. То есть, следующая идея возникает такая. Смотрите. Итак, вот у нас, допустим,
вот этот вот граф g. А, ну давайте, наверное, давно было там пора, собственно, назвать его g равно
в E, да. Ну, как всегда. А теперь сюда, да. А теперь давайте превратим матрицу G в матрицу G'.
Ну, граф превратим в G', где равно с теми же самыми вершинами на E'. И при этом УВ лежит в E',
тогда и только тогда, когда расстояние в графе G от УВ не превосходит внезапно 2. Вот. Вот такая
красота. Так. Вот, кстати, скажите мне, пожалуйста, чему равна матрица h3? Ну да. Ну да. То есть,
так. В калычках Рабло, а квадрат плюс а. Ну и там, соответственно, до единицы довести, если что. Ну,
в том плане, то есть, то есть, основная суть такая, что матрица смежности этого графа получается
по матрице смежности этого графа за умножение матрицы по плюсн квадрата. Ну, короче, за умножение
матрицы. Вот. Ну, теперь вы искали вопрос. Просто в чем идея? Идея заключается в том, чтобы найти
расстояние, то есть расстояние в матрице h', то есть в графе G', и после этого каким-то мистическим
образом сделать какие-то дополнительные действия по матрице расстояния в ашрихе найти расстояние
собственно в графе G', то есть в матрице A'. То есть, если мы это каким-то образом научимся сделать,
то все, что нам останется, это просто проделать вот эту операцию логарифом раз, правда? Ну, потому
что диаметр, ну, допустим, мы будем считать, что граф связный, мы там вначале можем запустить
быстрый ДФС и все про его компоненты связанности узнать. Итак, пусть у нас граф связный, допустим,
но тогда диаметр его не превосходит n, даже меньше n, получается, что через логарифум таких
итераций диаметр вообще останется единичным, правда? То есть, если быстро выяснится, что граф станет
полным, тогда там вся матрица будет единичной. Да, это называется заканчивался на яблоке.
Мы планируем по, значит, смотрите, мы планируем, значит, алгоритм будет устроен так, мы по матрице
А строим матрицу А', запускаемся рекурсивно, получаем, соответственно, матрицу D', вот эту матрицу
расстояния в D', и, собственно, по ней еще какими-то дополнительными средствами получаем D'. Ну,
понятно, здесь мы говорим магическое слово рекурсивно, типа рекурсия, смотри, рекурсия,
и, наконец, D', и после этого D' превращаем в D. Ну, каким же образом? Вот давайте это и поймем.
Ну, начнем с того, что, давайте так, как связаны между собой D от УВ и D' от УВ?
D от УВ это либо 2 на D' от УВ, либо 2 на D' от УВ-1. Ну, давайте так. Ну, думаю, вот такое утверждение
сомнений не вызывает, правда? Вот. Ну вот, но, на самом деле, да, правильно, на самом деле,
думать на тему четности. Ну вот, вот давайте попробуем сформулировать утверждение на тему
четности вот в этом вот стиле. Вот. Ну, то есть, в принципе, заметим, да, что у нас есть какая-то,
то есть, как бы есть матрица, какой-то, ну скажем так, есть какая-то вершина W, которая будет первая
на этом кратчайшем пути, правда? Ну и заметим, что, то есть, можно сформулировать так. Давайте,
допустим, да. Значит, говорит так. Если D от УВ четно, но тогда я утверждаю, что для любого W,
лежащего в соседях вершины У, что верно? Что D' от УВ равно D' В.
Мы знаем, что D' УВ и D' В отличаются не больше на 1. Да, но как бы заметим, что это отличие на 1,
да, они, ну вот, то есть, они всегда отличаются на, соответственно, плюс-минус 1. Если D от УВ на 1 больше,
то D' УВ будет больше. Да, правильно, правильно. Так какое же правильное утверждение мы можем здесь
сформулировать? Ну либо так, либо они равны, либо D' УВ на 1 меньше. Ну да, в переводе говорят вот так.
Да. То есть, для всех соседей, то есть, у всех соседей, для всех соседей расстояния не меньше.
Так, ну тогда вы, наверное, без труда догадаетесь, а что я скажу, если D' от УВ нечего?
В обратную сторону. В обратную сторону. Можно, но мы поступим по-другому. Мы скажем, что существует
такой мистический сосед, что D' от УВ равно D' УВ плюс 1. Ну или, короче говоря, тут минус 1 равно 1.
Вот видите, вот в том стиле. Вот. То есть, в принципе, получается следующая интересная вещь. То есть,
как можно было бы действительно, то есть, как можно хотя бы теоретически, пока забьем нот,
пока не будем думать, за какую асимптотику, по матрице D' восстановить матрицу D теперь?
Как это сделать? Ну мы все, кроме единицы, знаем все разряды двоичные, понятно. Видимо, нужно как-то
в чудесе нечетность понять. Ну вот, ну не совсем двоичный разряд. Видите, тут округление вверх все-таки.
Ну хорошо, да. Да, то есть, как бы было бы округление вниз, да, это был бы от пил последнего разряда,
так не совсем. Но общая суть остается. То есть, если я знаю D' от УВ, то я знаю, что D от УВ,
это у меня либо 2D' от УВ минус 1, либо 2D' от УВ. Вот. И нам нужно отличить один случай от другого.
Но мы, но как бы, заметьте, как бы, по такой линии можно сделать все наоборот, что если вот это, то есть,
если существует вот такой W, то надо брать вот этот вариант, если такого W не существует, то надо
брать вот этот. Из-за того, что можно прям в явном виде это, собственно, и сделать.
Да, ну правда, заметим, что если делать это совсем в тупую, то есть, если делать это прям вот так вот
в тупую, честно все ушки перебирать, да, то действительно могут получиться проблемы.
То есть, проблемы получатся, но получатся долгие секунды. Ну что тогда можно сделать? Что тогда
можно сделать? Вот. Ну, на самом деле, имеет смысл уточнить. Смотрите, здесь имеется в виду, что всегда,
то есть, тут всегда меньше либо равно, да? А как вы думаете, а Вегноли здесь будет, что всегда здесь
будет больше либо равно? Когда? Потому что D-AW максимум на один больше, а дальше, если вычислить на один, то по тренировке, то на два.
Да, да, да. Вот, отметите внимание. То есть, можно сказать так, что для любого W есть вот это. Вот. Просто, на самом деле,
просто теперь эту левочку давайте, просто теперь два штриха, можно пересписать в следующем виде.
Значит, пусть у меня, ну да, то есть, пусть у меня, допустим, S, допустим, УВ, это будет равно,
допустим, сумме по всем W, по всем соседям такой замечательной величины, как D, соответственно, D-штрих от W.
Вот, ведем такую сумму. Что тогда?
Тогда, я утверждаю, что если D от УВ четно, то S от УВ, ну вот, вот, то тогда можно сказать, что, действительно,
вот, если, ну вот, то есть, тогда, действительно, что можно сказать?
Ну, S от УВ не больше, чем степень У на... Да, то есть, S от УВ, значит, оно больше либо равно, вот так вот пишем, да,
тем, соответственно, D-штрих от УВ умножить на степень У. Ну, то есть, что я пишу себе, давайте, модуль N от УВ.
Так, согласна с таким точкой, не? О, а если D от УВ не четно, ну, то, вот эта штука, я утверждаю, строго больше, да,
потому что все будут... Наоборот же, S от УВ строго больше. А сейчас, там, в первом случае... Тут. Да, то есть, видите, тут УВ и W, тут УВ и W.
То есть, видите, как бы оно, как бы, у УВ всегда больше либо равно, притем найдется тот, у кого строго меньше.
То есть, очень такая получается удобная красота. Остается только один вопрос. А как найти S? То есть, заметим, что если бы мы нашли S, то, знаете, мы просто теперь потом прогулялись бы по всем вершинам, по всем парам вершин и возрадовались бы, правда?
Такая там операция над матрицей D штрих. Так, какая? Какая? Ну, домножение D штрих на матрицу смежности. Да, мистическое утверждение. S тупо равно A над D штрих. Все.
Вот так. Верите, Леша, в такое утверждение? Порядок матриц такой, да? Ну, да. Ну, потому что, раз у нас W тут стоит, то да.
Хотя, ну, в общем-то, по барабану можно было бы быть, на самом деле, потому что матрица A по-любому симметричная. Но, так, ну, смотрите, давайте так.
S у V, это прям по определению, да, W, Леша, это все, то есть A у W на D штрих W. Ну, то есть, заметим, что это в точности сумма по всем таким W, что A у W равно 1, то есть W, то есть, соответственно, N от D штриха W. Вот W, то что надо.
Вот. Так. Ну, что? Не отдава ощущение, что мы получили алгоритм за какую-то не самую плохую асимптутику. Ну, если, конечно, умножать матрицу адекватно.
То есть, получается, асимпточка такого алгоритма O от M умножить на N на log N. То есть, вот таким вот не очень и прям образом мы нашли расстоять.
Ну, потому что, видите, мы сделали одно умножение, вызвались рекурсивно, сделали еще одно умножение, ну, и там какие-то действия за квадраты. Так, вот до этого момента понятно?
Вот. Да, причем, заметив, что, да, как бы, возможно, высекает какой-то не мой вопрос, сразу отвечу, да, никаких вероятностей.
Да, действительно, обратите на это внимание. Ни таких вероятностей нет. Все в порядке. Все хорошо.
Так, далее. Ну, вот. А вот где начинаются вероятности? Вероятности начинаются, если мы хотим, если нам почему-то очень хочется начать восстанавливать этот путь.
Ну, вот. Ну, а теперь возникает вопрос. Вот, глядя вот на это, попробуйте угадать, в каком виде и в каком месте этого алгоритма мы хотим восстанавливать путь?
Ну, точнее так, что нам нужно? Потому что, конечно же, если восстанавливать путь, понятно, что не идет речь о том, что для каждой пары вершин мы этот скорейший путь напишем, потому что это тоже путь.
Просто чисто на уровне размера output.
Но...
Но, мне кажется, путь первый.
Да. Ну, как вы можете догадаться, да, у нас будет идея в том, что давайте найдем, попытаемся найти теперь не только матрицу, то есть вот тут мы решили задачу APD, нашли вот этой кочейшей пути, нашли матрицу D.
Ну, хочется теперь найти матрицу, собственно, так сказать, первых вершин. То есть для каждого UV вот эта вот первая W пути хочется найти.
Как же это сделать?
Как же это сделать?
Вот.
Ну, идея, на самом деле, может быть такая.
Смотрите.
Ну, что бы вообще нам действительно хотелось?
Вот. У нас есть вот вычисляется вот эта вот матрица S, которая вот подмножает A на D4.
Понятно, да?
Угу.
Вот.
Вот, действительно, какую бы иногда дополнительную информацию нам бы иногда, может быть, хотелось из нее выкарабливать.
Вот.
Вот. Ну, я сразу скажу.
То есть задача будет в том, чтобы, то есть хочется свести эту задачу к поиску чего-то в перемножении булевых матриц.
Ну, то есть представьте, то есть обычно то есть матрица из 0 единиц перемножаемых по принципу вот там через конверсию дебилцев.
Вот так вы думаете, причем это?
Вот.
Вот.
Пока я не знаю.
Еще, когда у нас D2OV отчетное, да, у нас, у той вершины,
у той вершины, которая была первой на пути, у нее будет такой же даже трех.
То есть вот в одном случае мы хотя бы можем сказать, какой критерий того, что вот соседнесу вершина на пути.
Если отчетное, то даже этого не можно сказать.
Не знаю, это D2OV.
Да, проблема. А когда бы мы могли?
Так.
Так.
А идея на самом деле такая.
Смотрите.
Да, ну ладно, тут на самом деле.
Прикрасил действительности.
Такая простая вот идея.
А идея такая.
Дело в том, что по матрице D я могу построить такие матрицы, как D0, D1 и D2.
Приматрица.
Где D с индексом G от UV.
Это оно равно, вот так вот, оно равно будет 1.
Если D от UV, процент 3 равно G и 0 иначе.
Внезапно, да?
Внезапно.
Вот.
Тогда мне вот очень хочется найти, действительно, вот это вот W.
Ну, смотрите, то есть для каждой задати UV я хочу найти такое W,
что D от W равно, соответственно, ну такое, что D2W равно D от UV-1
и при этом, как вы уже догадываетесь, W, естественно, сосед.
А то там просто расстояние минус 1 ничего не значит.
Ну да, а так как они все от D2OV-1 до D2OV-1, то остаток, по-моему,
это однозначно задает единственный, ну, отходящий.
Ну вот, то есть поэтому можно было бы сделать действительно следующее.
То есть, допустим, попытаемся найти ответ для всех D, то есть для всех пар вершин,
у которых расстояние, допустим, имеет остаток G.
Тогда идея такая, рассмотрим такое произведение,
А умножить на D с индексом G-1 mod3.
Ну, тогда очевидно, что если D2W, допустим, действительно имеет остаток G,
то очевидно, что, соответственно, это вот произведение, допустим, UoT,
оно очевидно будет больше 0, правда?
Если что?
Ну, если D2OV, то есть если D2OV реально имеет остаток G,
тогда логично, что произведение этой матрицы будет больше 0, согласны?
Но нам будет интересно даже не это.
Нам будет интересно, а благодаря какому моному,
потому что вот эта штука, это что такое, да?
Напоминаю.
Это у нас сумма по всем W, лежа себе в множестве V,
а у W на, соответственно, D вот этой вот блаблаблашки,
от W в.
Пока логично, да?
Ну да, и мы хотим найти, где именно единица.
Где именно единица хотя бы какая-то.
Нет, и вот хочется найти, то есть как бы хочется найти хотя бы одно W,
при K2OV, действительно, вот этот моном отличен от 0.
Согласны, да?
То есть, в общем-то, на самом деле, можно,
то есть, на самом деле, теперь эту задачу можно свести теперь к перемножению волевых матриц.
Потому что, ну, по большому счету, нам не важно,
к чему равно конкретно D, правда?
Логично, да?
То есть главное, что оно к чему-то не равно 0.
И вот тут-то и возникает задача с гордым именем.
Ну там, по-английски, собственно, звучащим нормально.
Значит, ну конечно, я счастлив.
Вот, Boolean product witness, соответственно, Matlix.
Ну или, соответственно, как вы уже догадываетесь, BPWM.
Ну вот, ну или, по-русски это называется.
Соответственно, да, да, да, именно так.
Как вы в прошлый раз обсуждали, да.
Свидетели Boolean'а перемножения матриц, да.
Значит, а об чем вообще вот эта задача?
А об чем эта задача?
А задача вот об чем.
Итак, даны Boolean, значит, пишем.
Даны Boolean на этот раз в матрице.
Это в матрице.
Ну, допустим, BAC.
А за сколько мы, кстати, можем перемножать Boolean в матрице?
За столько же.
За столько же.
Быстрее не будет.
А что с четырьмя русскими?
Ну, с четырьмя русскими это потеряет налог, к сожалению.
Так что, увы, не сильно нам эти четыре русских помогут.
Значит, даны Boolean матрицы BC.
Пусть, допустим, ну, такие матрицы там BC.
Ну, допустим, понятно это скажем.
Размера n на n, естественно.
То есть, пусть у них есть произведение.
Так, как мы обозначим произведение?
Какую букву не жалко?
Ну, жаль, свободно видим F.
F?
Ну, давайте.
То есть, пусть E.
Ну, вот.
То есть, пусть, так сказать, действительно B будет произведение.
Да, вот.
Как бы написать это произведение?
В равно, там, такая disjunction по W лежащим.
От одного, да, я.
На этот раз.
Значит, В от W.
And B от W.
Чего?
А, вот так, да.
Так вот.
Хочется создать.
Значит, хотим.
Значит, такую матрицу.
Такую еще матрицу.
Ну, допустим, H.
То есть, вот.
Значит, H.
Ну, допустим, H.
То есть, вот.
Хотим, чтобы было H от УВ равно.
Ну, например, нулю.
Если F от УВ равно нулю.
И такое W.
Что В от УВ.
Там, равно C от УВ.
В равно 1.
Иначе.
Вот эта вот матрица.
Матрица H и будет называться
этой матрицей этих вот свидетелей.
Вот.
Я нашел.
Загуглил как раз.
Нашел статью с алгоритмом.
Который.
Дерминированный.
За асимпточек умножения матрицы
умножить на алгоритм в константной степени.
В константной степени?
Да.
Константа то какая?
От единицы вижу только.
Ух ты.
А насколько новая статья?
Сейчас скажу.
Это непонятно.
Смотрим.
Нет, посмотри.
Нет, хотя бы.
Какого года статья то вообще.
По ссылкам не скажешь.
Что там у вас?
О!
Она еще.
А вот третья ссылка.
Это другое.
Другое?
Фаст практикал.
Другое не другое.
Господи.
Странно как-то, что в статьях такое
не пишут.
Да, вот тут умножено на алгоритм.
Так.
А, expected, yeah.
Нет, ну одно дело.
Вот worst таки есть комплекция написана.
Да, прям в степени.
Прям в степени.
They regulate this law,
but it's higher.
Ага.
Понятно.
2376 старая.
Ну, нет.
Ну или, по крайней мере, upgrade.
Ну ладно, в общем, да.
Пока мы, наверное, не будем претендовать
на то, что мы тут изучаем
так называемый самый текущий алгоритм, так сказать.
Вот.
Ну вот.
Ну, по крайней мере, хочется знать, что такое
по крайней мере есть.
Значит, давайте разбираться.
Как же это все хоть за какую-то
адекватную синтетику можно сделать?
Вот.
Ну,
мистическое утверждение.
Ну, на самом деле, смотрите.
Давайте
сделаем вот что.
Давайте скажем, что найдем еще какую-нибудь
матрицу, допустим, матрицу K.
Которая будет перемножать
значит, матрицу
B' на C.
Где B'
у ВТ
там у W лучше напишем
будет равно W
умножить на B.
Вот так.
Вот.
Давайте попробуем такая идея.
Вот чтобы, да, на этот раз переможем
честно. То есть не в этом смысле,
а прямо вот честно, как число.
Тогда я утверждаю, что
в некоторых случаях
эта матрица, тогда матрица
K поможет нам найти свидетелей.
А именно
я утверждаю
это утверждение.
Ну, утверждение такое
если
для каких-то
УВ, значит, существует
единственное такое W что
значит, допустим
В у W равно
C у W равно
1
то тогда я утверждаю,
что в K у В
ровно это W будет записано.
Логично, да.
Вот. Мы вычислили это пока.
Пока вроде как
логично.
Ооо.
Поэтому, да, то есть
то есть в принципе один из таких
лайфхаков, который мы могли бы применить
за O от L, это сказать
а давайте-ка переможем вот эти матрицы
и после этого
пробежимся
по всем течейкам K
посмотрим, что там лежит
и то, что там лежит мы можем легко проверить
является ли оно
свидетелем или нет. Правда?
Ну, по крайней мере
проверить является W
Свидетелем для вершин УМВ
это не проблема.
Так свидетеля такому-то не может быть.
Такое число да.
Короче, вот это
W называется свидетель.
Долго вы там говорили
в итоге.
А, ну я
я вот уже подумал, что это уже понятно
но я потом проговариваю явно
W это
есть свидетель.
То есть проверить
является ли W свидетелем
для каких-то вершин УМВ это без проблем
вот найти
его это не тривиально.
Такое ка могло бы конечно
пролить свет, но проблема в том
что если свидетелей
2, 3, 4, 5, 8, 10
то в кашке будет написано
сумма этих свидетелей.
Правда?
Это нас не устраивает.
Что делать?
Но идея
такая, смотрите.
Идея на самом деле
заключается в том, что
можно было бы эту матрицу K немножко проведить.
Вот идея такая.
А давайте в некотором смысле
ну давайте так
возьмем эту матрицу K
но занулим в ней
некоторые строки.
Остальные строки оставим теперь.
Тогда что можно заметить?
Тогда можем найти свидетелей
которые до этого не находились.
Ну да, скажи так
утверждение такое
если мы занулим некоторые
строки, а именно
занулим
действительно строки
в K
действительно строки
для каких-то там
значит у или жахик в каком-то
мистическом множестве там я не знаю
Ладно, давайте так
В
там без какого-то мистического множества
Н
Мы разве не в K
должны замножать что-то разумный матрица, который мы
умножаем?
Ой, прошу прощения, да, в B3.
Хорошо. А еще
там, наверное, имелось в виду
там буквка A, наверное, имелось в виду буквка B
потому что там у нас нет
Существо единицы, да?
А, это B
Это B
Да, B
Действительно
Заметьте, что если мы в B3
что-то занулим
то есть занулим все строки кроме строки множества A
тогда утверждение
будет абсолютно тем же самым
только
после этого
будет такое утверждение
ну давайте так скажем
получим матрицу
давайте аккуратно скажем B'A
тогда
мистическое утверждение
если
существует единственный свидетель
внимания в множестве
A такой, что
B от УВ
равно от УВ
то?
то что?
Ну вот, то тогда очевидно, что
мы не должны были стабты
занулять
короче
у нас же как раз
мы хотим как бы от некоторых W
избавиться, чтобы
вот я возражаю
а мы избавимся
от У
если У попало в L
то мы просто целиком занулили
а иначе ничего не изменится
ну да
так
да, отлично
да
как тебе, преподаватель, читаю лекцию
просто где-то быстро
начинаются образованные меньшинники
ну в общем
Вэштер должен занулять столбцы, соответствующие
ну не столбцы, а строки
вы все-таки забыли
у нас же W
это вторая координата Вэштер
так
мы хотим сказать, что
теперь все W
конкретно какие-то не являются свидетелями
значит, что все БУВ
для всех У ноль
это столбец
ну да, так ладно
с этим действительно согласились
ага, ну да
хорошо
хорошо, столбцы
уговорили
молодцы
хорошо
да, ладно
теперь мы с этим утверждением согласны
ну вот
что нам теперь просто для этого нужно сделать
теперь нам нужно определиться
как это под множество L
или под множество L
как-то брать
вот
и у нас есть мистическая лемма
внезапно 4
видимо лему 2 шлифт надо было лему 3 называть
или я че-то
а нет, слушайте, да
лему 2 шлифт на самом деле лему 3 называется
так вот, мистическая лемма
значит, внимание, сейчас я на самом деле
сформулирую лему, которая могла у вас возникнуть
в домашнем задании по теогверу
или даже по дисплею
значит, пусть
есть
значит, N
больше одного шага
вот пусть у нас такие шары
ну вот, в том числе
W
допустим, белых
и N минус
так, ладно, W давайте не будем
K белых
и N минус K черных
понятно, да?
пусть также у нас есть еще такое
число R
тоже натуральное
что N пополам
меньше либо равно
K на R
меньше либо равно
вот такая вот идея
тогда
случайное подмножество
из соответственно
R шаров
содержит
ровно один белый шар
ровно один белый шар
с вероятностью
не менее чем
1 делить на 2
вот такой вот угол
вот, ну как всегда
остается два вопроса
первый, конечно
почему это верно
и второй
и что
кратко, да, первый вопрос
и второй
и что
с какого
чего начнем?
ну давайте
решим простую задачу по комбинатуре
так, а давайте скажите, пожалуйста
почему у нас вообще с точки зрения комбинатурики
вообще равна
вот эта вероятность
да, ну как вы догадываетесь
у нас есть N шаров
с вероятностью одна вторая
независимо включаем
с какой вероятностью у нас будет
ровно один белый шар?
ну сколько
подходит у нас набор
из R шаров
K умножить на C
К умножить на R-1
ну да, хотя нет, это неправда
нет, не, я просто
пространство не правильно сказал
да, мы берем сущное подножие
из как фиксированного числа
мы получаем то, что из R
у нас К на C за M-K
R-1 делить на C за M-P-R
на C
это подножие с ровно
одним белым, а всего
C за M-P-R
хорошо, да, отлично
а то осторожно, а то дадут волны
дадут волны тебе
так, ну давайте
разбираться
что это вообще такое
ну если честно расписать
факториалы, да, то получится
значит N-K факториал
там R-1
поделить на что-то там надо, да
R-1 факториал
и на какой-то еще висели
N-K-R-1 факториал
все это надо поделить
на N факториал
на R факториал
на N-R факториал
так
ну что
ну заметим, что кое-что можно пошлеп-шлепать
ну тут R остался, да
поэтому можно сказать
следующее
то есть можно сказать так
это равно K-R
R соответственно у нас
вверх вылез
дальше получится
давайте если честно написать
N-K факториал на N-R факториал
на N факториал
на N-K-R
плюс 1
факториал
так
смотрите, как интересно получается
если сократить вот эти два факториала
попробуй, то тут останется
произведение
искать чисел, да
а если вот эти сократить, то сколько
останется чисел сверху
K-1
сколько?
вот этот с этим
ну разность
аргументных факториалов
это K-1
ну вот да
остался такой, да, кого с кем
ну потому что дальше тут идея выскакивает такая
давайте напишем, что это равно K-R поделить
на N
умножить, ну давайте вот так
K-1
поделить на N-1 факториал
и дальше
значит тут будет N-R факториал поделить
на N-K
N-R
так
вот такая вот
вот такая вот, да
вот
ну вот
ну в принципе
можно это написать в следующем вроде
пробегаемся
то есть это можно написать такое
в произведении некоторых пробей
где вот здесь будет написано
N-1-R
а здесь будет написано
N-S
N-1-R
вот
вот
и G соответственно
здесь прибегают какие значения
почему именно так
это мы что с чем
какую тропу смотрим
ну смотрите
если я вот тут сокращу, у меня тут получится
N-1 на N-2 на N-3
и так далее, да
на N-K
плюс один, да
а, ну да, да, да
здесь нет единицы, согласен
так
и G прибегают у нас какие значения
ну соответственно
от нуля до
видимо K-2
пока лучше, да
да
так
ну это
можно написать это так
можно в скобщиках
написать один, минус
такая замечательная штука
как
как такая
минус R-1
поделить на N-1
минус G
вот
вот такое вот интересное
произведение
но заветим следующее
я могу теперь это оценить снизу
как я могу это
оценить снизу
если я хочу это оценить снизу
то каждую скобочку я должен уменьшить
ну да, значит дробь увеличить
чтобы уменьшить скобочку надо вот этот дробь
увеличить
скобочку
надо
вот хочется знаменателя
избавиться от этой вот жишки
знаменателя
тогда мы уменьшим
скобку
потому что мы будем
делить на большее число
так, значит хорошо
давайте еще раз, это мы уменьшаем
это мы увеличиваем
давайте так
нет, тут отрижается
на оборот
мы должны тут K написать
мы должны вместо N-1
написать?
вместо N-1
написать N-K
так можем
мы уменьшаем знаменатель
и увеличиваем дробь
и уменьшаем все
ну да, чтобы уменьшить
надо было читать как можно больше
поэтому давайте вычтем еще
мы вычтем K-1
и получится это больше либо
чем K-R-R-N
на произведение g равно от 0 до K-2
и соответственно пишем
1-R-1 делить на
N-K
так
что это такое вообще
это равно
ну можно так теперь написать
K-R-N на
1-R-1 делить на
N-K
в степени
соответственно K-1
так, ну теперь пришло
время, наверное, это R оценить
ну как его
ну как-нибудь пооценивать
будешь помнить, что
как видите, K-R у нас
от 0 до N
то есть, с одной стороны
это
больше, давайте вот так
с одной стороны
это больше либо равно
чем, ну K-R поделить на N
это у нас как минимум 1-2
как мы понимаем
так, а вот здесь как минимум
избавится от R
да, то есть, здесь
наоборот
R надо сказать, что это не более чем
ну да
то есть, можно действительно сказать, что это
давайте попробуем
1-N делить на K
делить на
N-K
в степени K-1
так, это у нас равно
1-2 на 1-
так, смотрите
что получается
N-K
поделить на
да, господи, что тут парится
это 1 делить на K
ну как-нибудь
нет ощущения, что это
1 делить на K
вот, ну и все
и утверждается, что это
больше либо равно 1 делить на 2e
но это там, видимо, из какого-то
париза вы уже знаете
хорошо, да
то есть, да
нет, мерзопакриска, да
надо правильно расписать, но суть оказывается так
ну смотрите, к чему
это нас вообще приводит
к чему это нас вообще приводит
это нас приводит к тому, что
да, то есть, оказывается
то есть, ну правда
единственная проблема, то есть у нас в чем проблема
то есть, нам
казалось бы, нам теперь просто остается
так, если мы знаем, что у нас K свидетелей
то давайте вот такое R подгоним
и получится хорошо, правда?
правда, есть одна маленькая проблема
для каждого УВ
количество свидетелей
различно, правда?
поэтому
ну а как бы что делать?
алгоритм разноцветов перебрать?
ну да
и для каждого только запусков?
ну для каждого
вот сколько-то, а вот сейчас будем прикидывать
действительно сколько запусков надо
то есть алгоритм действительно будет так
то есть алгоритм, да
то есть он будет говорить так
то есть перебираем
значит for допустим
допустим R равно
один, два, четыре
восемь, шестнадцать
в общем, бла-бла-бла
допустим N, ну или там
2 в 4, не округленный
алгоритм N вот этот вот, да?
то есть, значит
перебираем все эти R
и дальше
for там допустим
значит дальше
значит for ить, так что вот
господи
ну вот
тут я уже не могу держаться
там конечно
где каштих, это будет какая-то
сейчас
другая буква нужна, потому что это какая-то
какая-то константа, которую мы там потом
ну не константа, а какое-то
мистическое число, которое мы пытаемся вычислить
вот
все, такой буквы точно не было
вот
и дальше получается
следующее
то есть, генерируем
не знаю, случайно
под множество
вершин
то есть, случайно под множество
действительно L
размера
соответственно
какого?
соответственно R
то есть, понятная нот
ну и дальше там строим, понятная
то есть, будем говорить, что строим соответственно матрицу
B'L
то есть, дальше говорим, что
матрица K
допустим L, присвоить
B'L умножить
на C
и
проходимся
по
В
и
проверяем
N
свидетелей
из K
то есть, в переводе говорят
мы сгенерили O
то есть, мы сгенерили что-то типа логарифом R
умножить на вот это
каких-то матриц свидетелей
ну мы все перепроверили
и для каких-то пар
УВ мы свидетеля нашли
а для каких-то не нашли
понимаете, да?
ну и в конце нам остается
там для всех
для всех УВ
без свидетеля
будем говорить, что
найти
свидетеля
в тупую
слово
да, вы же знаете, если там
что единичку произведение, что они должны
свидетель купить
ну единичка, не единичка
то есть, допустим, у нас есть матрица
там, допустим, ans
либо написан 0, если свидетеля нет
или там, минус 1, там, все что угодно
либо, если свидетель есть, то там
пишем прямо этого свидетеля
я про то, что мы не будем пытаться
свидетелей у тех, у которых просто 0
случайно
сейчас, то есть, 0
ну в смысле, ну есть
QV, что там, произведение
ну, по элементу
в этой 0, но мы же уже знаем
мы уже знаем результат
ну вот там так скажем, что
ну как сказать, просто свидетель
мог не найти
потому что мы говорим, что вероятность
теперь нам надо просто теперь
оценить, значит, за какое
время это работает
и где вообще
ну вообще, как мы заметим
что мы работаем за O от
M от N умножить
на вот это вот
умножить на
лог N
плюс
плюс N умножить
на
в общем, короче, количество
ненайденных свидетелей
вот
и заметим, что количество ненайденных
свидетелей, это как раз вот и есть
единственная случайная величина
от ожидания которой мы хотим
оценить
а теперь
утулажаемые знатки, до этого остается простой вопрос
ну, думаю, очевидно
все это сводится к простому вопросу
а с какой вероятностью
для заданных вершин
UV не будет
найден свидетель
один минус ненайдение 2E
в степени
то есть заметим следующее, что
как бы для каждой, то есть мы
скажем так, мы не знаем
сколько там соседей у вершины U
да, но
если их K, то как бы
какой-то из R обязательно под эту лему
подойдет, правда?
вот, поэтому получается, что
вероятность того
то есть действительно вероятность того, что
для U и V
не будет найден свидетель
она получается
не превосходит
1 минус
1 на 2E
в степени
вот это вот зю
или
C
ну ладно
ладно, лучше назвать зю
потому что я чуть не уверен, что
буквы в таком написании в реческом ухудении вообще есть
там скорее всего там
за корючек
знаете это как это
больше как-то
когда ребят в первый раз столкнутся с соответствующим понятием
и там
в математике есть булевая алкебра
вот это вот все
так вот
поэтому, значит, идея будет такая
в качестве буквы зю
мы возьмем логариф по основанию
1 минус 1 делить на 2E
вот
1 делить на N
ну да, тогда это
то есть как бы
если мы возьмем вот такой
зю
то тогда мы просто заметим, что
действительно это тогда
что действительно такая
вероятность у нас
не будет превосходить
1 делить на N
и тогда получается
что
вот
то есть из этого следует
что мат ожидания количества
ненайденных свидетелей
то есть E
количество
ненайденных свидетелей
не превосходит
ну получается
значит чего?
N квадрат поделить на N
то есть не происходит N
и мат ожидания этого времени работает
соответственно будет седено
вот этим безобразием
ну то есть это означает в принципе
что вероятность
набрал набрал набрал
набрал тут N от N конечно
то есть это означает
что вероятность резистора крайне
и у нас еще один логарифм
из-за того что у нас
у нас логарифм здесь
и логарифм здесь
это же мы только
на одном шайке наш
нет смотрите
история такая, у нас есть часть
логарифма которая работает
за вот эту осень точек
здесь она невероятно
она вероятно
но и время работы невероятно
есть вероятность
время вот здесь
но мы замечаем что
мат ожидания
оно по видимому
N квадрат
да это понятно что здесь N
тогда в изначальной задаче
поиска у нас будет N
почему?
у нас же там
нет погодите, зачем?
мы исходную дешку
мы свели
мы только на одном шаге
будем выполнить
если вспомнить как мы это делали
то там история такая
алгоритм был такой, сначала мы находим матрицу D
честно находим и
сведите и пока не ищем
из матрицы D мы получаем
булевые матрицы
на тему того делится
или расстояние на 3
или остаток 1, остаток 2
и сводим задачу к 3 поискам свидетель
там на самом деле такая идея была
вот
то есть каждую из этих задач
и вот каждую из этих задач
мы уже начинаем развлекаться
вот на этой осень точек
вот
вот такой вот прикол
то есть ладно
видимо
судя по результатам гугления
видимо наука умеет и круче
там пишут
я нашел две статьи в которых
написано что они имеют детерминирование
за мат на лог
в контактной степени
они говорят что они докручивают алгоритм
чего докручивают?
вот этот алгоритм
ну как тогда
ну молодцы
нет, то это то да
если говорить про докрутые
ну тут на самом деле есть еще такой
то есть у меня тут на самом деле
написан теперь еще бонус
бонус говорит что
на самом деле можно этот алгоритм
докрутить так что вон тот алгоритм квадрат
можно убить
вот эти
тялочка
какие свидетели
вот эти три
сейчас
до 0
до 1
если воспоминать тот алгоритм
алгоритм еще раз
алгоритм поиска свидетелей
для задачи поиска качающих путей
и вот звучит так
найдем качающие расстояния
нашли да?
у нас получилась матрица
начали писать
начали писать
д
по ним
я сейчас начну писать следующее
я по матрице
создаю 3 матрицы
булевые матрицы
д0, д1, д2
я говорю что
gt с индексом uv
равно 1
если d от uv процент 3
равно g
и 0 иначе
вот мы создали вот такие матрицы
понятно да?
тогда теперь у меня идея такая
для каждого g
я например пытаюсь
нот
я пытаюсь
ищу свидетелей
запускаю эту задачу
для перемножения матриц
а на
д2
значит
а на д0
почему я сейчас в таком порядке пишу
а, д1
почему я это
делаю
потому что
допустим я перемножу
матрицу a на d2
предположим что у меня
uv делится на 3
для каких-то вершин uv
тогда заметим что
в этом перемножении
uv будет равен единице
потому что если у нас есть
скачайший путь от uv
то значит есть
вершина w
и где 3 на l-1
плюс 2
тогда получается
если матрицу a
вы перемножите на d2
тогда благодаря
какому-то из w
будет единица
если мы рассмотрим каждое w
где возникла единица
обнаружим что каждое w это вот такая штука
так что вот такая идея возникает
из этого произведения
то есть для всех
качающих путей в эту первую вершину нашли
из этой пары
делаем то же самое для всех у кого остаток 1
тут остаток 2
вот такая красота
остается только
один маленький тупой момент
тупой момент заключается в том
что
этот алгоритм
может попытаться ускорить
давайте подумаем за счет чего
ну не этот
а вот этот
дело в общем
заметим что в этой матрице
вот например у нас в матрице b'a
у нас всего r не нулевых строчек
у нас действительно сколько-то столбцов
вот
а возникает вопрос
а в c нам
а не имеет ли смысл нам на самом деле
сделать то же самое
вот например нарисовать какую-нибудь такую
аналогичную матрицу c
который занудит те же самые
столбцы
а если мы будем делать
то же самое
то мы будем делать
в которой занудить те же самые
нужные строки
да?
ну тут вот так
занулили столбцы вот я так напишу
столбцы
а тут
занулили строки
ну как бы почему-то вы себе очнили
что результат от этого не поменяется
есть такое ощущение?
чего?
ну потому что
строки которые
с теми же w которые исключены
они
у ч-элемента
у w
на cw будут ноль если w
гаджет l
поэтому в c можно те же самые строки тоже
нарисовать
да но единственное только разница
что тут мы на w
ни на какие индексы ничего
домножить не будем
то есть давайте вот здесь это напишу
а
давайте тогда это будет не c шлифа
cl
то есть за нуление это дает
индекс l
ну занулили столбцы, занулили строки
просто смотрите
а в чем фишка?
фишка заключается в том что
тогда если у нас есть
когда мы домножаем r ненулевых столбцов
на какие-то r ненулевых
строк то есть подозрение что это
можно свести к перемножению матриц r на r
это проще
ну типа
на блоке
на r по r
да даже нет
давайте подумаем
просто по большому счету
жили были
две матрицы
в одной живы сколько-то столбцов
в одной живы
сколько-то строк
тогда по большому счету
заметим что я вот в этой матрице
могу вот просто взять
соответствующие столбцы и сказать
что а давайте будем домножать вот эту матрицу
только на наборы этих столбцов
и результат этот
только там строки
с правой
ну если мы же в c
с нулями строки не слушаются
мы должны одновременно
ну можем типа взять
в больших трех отелях
только r строк
а в c это только c столбцов
но это только наоборот
короче в левую
с матрицей берем оставляем l столбцов
а в правую l строк
у нас получается матрицы
размера
берем не вычеркнув под матрицу
по штрихе
и не вычеркнув по матрице
ну да нет тут заметим что
столбцы которые мы не вычеркнули
а строки которые мы не вычеркнули
это одни и те же строки
поэтому по большому счету
когда вы будете перемножать
строчку на столбец здесь
то у вас будут нули нули нули
и когда мы попадем на строчку столбец
будет одно и то же
поэтому по большому счету
имеет смысл
оставить только тут нужные строки
и обнаружить
что это можно теперь сделать
за r
теперь вот
давайте я вот тут синеньким буду
писать что тут l да
вот за нули
строки
строки
и мы теперь обнаруживаем
что мы это умеем делать
за время
теперь m от r
потому что
р осталось
р осталось
потому что
если вы тут оставили
вы тут оставили r строчек
да
м от r надо обращать в квадрат
квадрат матрицы r на r
а у нас матрица r на n
умножить на матрицу n на r
ой ну да
так
хорошо
вы домножаем матрицу
n на r на матрицу r на n
умножить
на r на n
так
так
так
так
ну и теперь да
так
мы утверждаем
что мы
давайте прикидывать
за сколько мы можем умножить
матрицу
ну если мы поделим блок р на r
там может быть получится что незадолго
ну давайте так
m от r умножить на
n на rlat что то такое
я делю это в квадрате
потому что
тут блоков n поделить на r
каждый блок на каждый
поэтому
тут получается умножить на
n в квадрат
и тут на r
нормально получается. Так, ну давайте подумаем. Ну, смотрите, просто идея теперь заключается в том,
что для каждого R мы как бы тут можем написать, да. Ну, не для каждого R, а теперь для каждого
фиксированного вот этого вот, видите, да, можем перебрать вот эти R, да. То есть, на самом деле,
асимточка у нас теперь получается от, ну вот, то есть от получается все еще это zhu на log n умножить на,
нет, не на log n. На log n было, когда мы тупо перемножаем n на n и еще на n. А zhu мы теперь
домножаем на сумму по всем, значит, R равно 1, 2, бла-бла-бла, 4, бла-бла-бла, в общем, короче,
m от R на n квадрат делить на R квадрат. Да или нет? Значит, это равно, ну короче, o от n квадрат log n
на, значит, сумму такой величины, как m от R, ну, сколько там, значит, m от R, значит,
поделить на R квадрат по всем вот этим вот степеням двойки. Это очень странно, потому что если,
допустим, мы когда-нибудь придумали алгоритм такое, что m от R квадрат, здесь получится, ну,
просто n квадрат log квадрат, то есть m от n log квадрат. Да, вот в этом ты и парадокс. А если m от R,
ну, там, понимаешь, строго больше, то там будет... Да, то какие странно это дрюкс лопнется. Да,
она сходится в константу и все. Да. Только, ну, как бы... О, тогда это вообще будет n квадрат log n,
там даже не будет m от n в константе. Что прикольно. Нет, то это растрак. Нет, это странно, будет как-то,
если бы m от R большое, то 8 точек будет меньше. Нет, то скажешь так, как минимум одно из этих m от R
никуда не денется. Там будет просто растущая, ну, типа растущая... Ну да, давайте так. Пусть у нас, да,
давайте так. Пусть от m от R равно, допустим, n в степени 2 плюс епсилон. Понятно. Ладно,
x в степени 2 плюс епсилон. Тогда у нас сумма получится по g равно от нуля до логарифма m.
Получается, значит, тут будет что-то типа... То есть 2 в степени g на 2 плюс
епсилон поделить на 2 в степени 2g. То есть, как бы, получается геометрическая прогрессия 2 в
степени епсилон, где епсилон больше нуля, да, и это в степени g, где суммируем по всем g от нуля до
лог 2n. Ну это понятно, это растущая геометрическая прогрессия, то есть это равно θ от, получается,
2 в степени епсилон на лог 2n. Ну и получается, что это равно θ от n в степени епсилон. Чего?
Ну да, нет, все нормально, будет как раз m от n на логарифму. Так, ну да, то есть, получается,
нет, ну там от n в степени 2 плюс епсилон на логарифм n, это равно от m от n на логарифм. Да, вот такая вот
пока вы умножаете матрицу чем-то, типа 2n в степени 2 плюс епсилон, то логарифм можно успешно схлопнуть,
вполне себе достаточно естественным образом. Но, действительно, парадокс, парадокс, парадокс,
да, если m от r равно r квадрат, ну вот, если удастся, там, наука научится переножать матрицу за r квадрат,
уж не знаю каким образом, то называть будет печально, но не печально, но просто r квадрат
ну и тоже хорошая симпозиция. Так, ну что, есть ли тут какие-то вопросы?
Вроде понятно, прикольные были. Да, нет, тут все и так, а если будет?
