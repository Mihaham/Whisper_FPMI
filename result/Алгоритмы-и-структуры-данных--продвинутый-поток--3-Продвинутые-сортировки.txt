Так, ну что ж, господа, наконец-то, собственно, так, можно попробовать такой-то начать.
Всё, всем добрый день.
Так, ну что ж, давайте попробуем с четвёртого раза всё-таки войти в программирование.
А то, что вот это никто никогда не умеет.
А, прям сразу, да?
О, нет.
Так, ну ладно, как говорится, да.
Так, сейчас вы видите краткое содержание предыдущей серии.
Вот, и ещё в складе.
Да, ну я же говорю, краткое.
Вот, да-да-да.
Ой, это даже, это даже было две серии назад.
Две серии назад.
Вот, да.
Ну, если в кратце у нас в прошлый раз было много сортировок,
в частности, мы убедились, что в некотором смысле,
это важно, именно в некотором смысле,
быстрее, чем сортировать n элементов, нельзя.
Ну, как вы чуть позже говорили, это, конечно, не совсем так.
То есть, тут очень важный контекст, в каком вы это имеете в виду.
Вот.
Ну, а начнём мы с достаточно такой нетрибиальной вещи.
Вот.
То есть, сейчас мы поговорим о такой сортировке как TeamSort.
Вот.
Ну, с точки зрения нашей глобальной теории,
в общем-то, это, как бы, ничего нового не даст,
потому что, в общем-то, вы знаете, что быстрее, чем Zn Logar,
сортировать нельзя n элементы.
Там Zn Logar мы уже сортировать умеем.
С какими способами?
Три.
Три, да?
А, ну да, если QuickSort с адекватным выбромидианом, то да.
Ну, почему QuickSort, QuickSort и Куча?
Ну да, логично, логично.
А что HipSort?
Да, HipSort и Куча это одно и то же.
Три сортировки это MerSort, HipSort и QuickSort.
Где QuickSort, да?
Где карта?
Где карта?
Не, ну где карта?
Вероятно.
А, ну да.
А, ну да.
Что такое?
Нет, ну, как сказать?
Ну, AVL мы с вами не знаем, да?
Ещё.
Ну, AVL там, да, понятно, сортировка с помощью красночёрного дерева это да.
А вот свой невероятно стоит.
Да, так невероятно стоит.
Вероятно стоит.
Нет, вы не переживайте, да деревья мы тоже доживём и будем о них все поговорить.
Вот.
Дальше соответственно.
А так?
Ну, вот.
Ну, вот.
Ну, вот.
Ну, сегодня мы в пороге, ну, по крайней мере начнём, конечно, мы не будем о них
говорить все, там, четыре с половиной часа.
Вот.
Но эта сортировка, она, действительно, имеет отношение именно вот к практике.
То есть, ну, в общем-то, многие взрослые про неё слышали, потому что считается,
что она просто лежит в основе дворей, там, зашита в питон.
А то и в джавы.
Вот.
Ну, как мне, в джавы сильно.
Поэтому питон такой у нас медленный?
Нет.
Нет.
Нет, питон медленный, как бы, не в этом месте он медленный.
Потом, на самом деле, питон надо просто правильно использовать.
Потому что, как сказал один специалист по машинному обучению, на самом деле, питон
это такой язык обвязки разных кусков кода, написанного насях.
На самом деле.
Вот.
То есть, там, видимо, с точки зрения машинного обучения, это, там, явно не лишено
какой-то, какого-то измеренного зерна.
Нет.
Ну, если использовать чисто втижные плюсовые библиотеки, можно действовать в девятые
на секунду.
Ну, так и работает же машинное обучение.
Там есть пять строчек кода в питоне, а всё зафиксируется.
Ну, вот, да.
Да, да.
Именно.
Именно.
Вот.
Так нет.
Ну, в принципе, мы замечаем, действительно, оказалось бы, зачем, если у нас изобрели
машинное обучение, изобретать ещё какие-то сортировки.
Да.
Там не даже, когда ещё и СИП сотни.
Константу меньше.
Совершенно верно.
Да.
То есть, хочется меньше, ну, там, хочется меньше константа, в чём в каком смысле.
Не только, потому что константу можно мерить, действительно, в некоторых худших случаях.
А, с другой стороны, есть ещё, вот, там, в этой всей математике часто можно упустить
такой важный момент, что нам хочется сортировать так называемые реальные данные.
Ну, потому что, помимо олимпиад, обычно, там, сортировка вызывается на каких-то
абсолютно реальных, собственно, данных.
И хочется делать так, чтобы в худшем случае было, действительно, ну, как-то, там, достаточно
хорошо, ну, или хотя бы сильно плохо.
Но зато на реальных данных желательно летал.
Ну, какой тут можно пример привести.
Вот, действительно, неплохо было бы, на самом деле, требовать от сортировки, чтобы,
чтобы, если вы хотите отсортировать уже отсортированный массив, то, наверное, хочется это
делать, ну, совсем быстро, правда?
И вот.
Более того, вот, есть мысль, что бывает, что иногда массив, ну, например, почти отсортирован.
Ну, тут разные смыслы могут быть.
Бывает, что, там, массив, там, отсортирован, но, там, взяли потом пару-тройку, там, несколько
элементов и переставили их выставить, там, например.
Или, вот, например, актуальный, например, для нас случай будет, вот, в Тимсоке.
Это если массив представляет собой, там, конкатенацию не сильно большого количества
уже отсортированных массивов.
Ну, он всегда представляет конкатенцию, но не всегда не сильно большой.
Да.
Ну, конечно, да.
Всегда можно сказать, что этих отсортированных массивов не более чем пополам.
Да, бывающие нас тоже устраивают, очевидно.
Ну, вот, и будут нас сейчас устраивать.
Ну, вот.
Но, как-то хочется, что если их, например, выяснится, что этих массивов всего, там,
три, то, наверное, есть подозрение, что за NLG это можно не NLG.
То есть, вот, на самом деле, сортировка, собственно, Тима Петарса, это сортировка,
которая будет пытаться этим активно заниматься.
Ну, то есть, она такая чисто практическая.
Ну, вот, соответственно, то есть, ну, да, по статье, на самом деле, самого Тима Петарса
явно видно, что это, как бы, не математик.
Вот.
Собственно, в домашних заданиях мы будем пытаться это исправить.
Очень жаль.
Да нет, на самом деле.
Сейчас, видите, ничего страшного нет, на самом деле.
Вот.
Итак, значит, как же мы будем пытаться, значит, пытаться, там, пытаться проверять,
что это верно, или что, на что-то, там, негативно сортировано.
Ну, значит, смотрите.
Краткое содержание выглядит примерно так.
Ну, во-первых, мы не очень хотим, вот там, как вот такой,
ну, вот, то есть, например, первое, что нам выясняется,
то, что Н пополам отсортированных массивов...
Да, мы хотим разбить массив на отсортированные куски.
Но Н пополам отсортированных массивов, по два элемента,
это не то, что нам нужно.
Оказывается, гораздо, то есть, выгляделие все-таки,
делается так, чтобы эти отсортированные массивы были размера,
не менее чем какой-то вот мистической концентраты минералам.
А.
Под массивы это не под отрезки, это...
Ну, в общем под отрезки.
Да, подотрески, но забирая вперед, скажем, что, оказывается, ну вот начнем с того, что задача, надо сортировать элементы, да?
Спрашиваю, сколько элементов надо отсортировать? Ну, десять.
Тогда выясняется, что, наверное, мегсорты и кусорты, наверное, это не самое оптимальное, что в этом случае можно использовать.
Так что вы можете потестировать, можно потестировать и обнаружить, что, знаете, там, сортировка вставками может неожиданно начать работать быстрее.
Потому что, во-первых, ну, просто чисто констант тут начнет хорошо работать, просто потому что, ну, во-первых, нет рекурсии.
А во-вторых, что самое главное, то есть у вас все расположено в очень-очень микроскопическом, собственно, кусочке памяти.
Скорее всего, тогда этот доступ, тогда эта память будет, соответственно, у нас находиться в кэше.
И это означает, что, соответственно, работа с этими элементами будет просто, там, едва ли не десятки раз быстрее.
И сортировать можно быть пузырьком?
Ну, практически, да. Ну, как сказать, ну, там, можно уже выбирать, там, есть пузырька и, там, вставок.
Ну, там уже можно думать, но это уже другой вопрос.
Ну, собственно, кстати, да, кэше мы тоже, в общем-то, сегодня будем говорить в какой-то момент.
То есть тут тоже, ой, как бы, ну, повезет.
Может в конце этой лекции, может в начале следующей.
Как пойдет, я не знаю.
Вот.
Так вот.
Значит, поэтому возникает идея такая, что оказывается, что давайте разбивать будем на сортированные подотрески не менее, чем какая-то константа Минран.
Ну, забираем вперед, скажем, что будем, в случае чего, там, эти, там.
Если так жадно не получается, то, значит, будем, там, досортировать их, там, достаточно быстро.
Это все равно формально, там, Минран будет считаться константой.
Ну, вот, поэтому это все равно, вот это.
Каждый Минран – это минимальный размер ран.
Ну, да. Ну, как бы, да.
Ну, сейчас увидите.
Да, Минран, да.
Потому что, да, что такое ран?
Да, ран – это вот тот самый, вот, будем называть под пассив отсортированный по угловой расстоянию, будем называть его ран.
Так вот, мы разобьем массив на такие раны, вот, каким-то образом.
Вот, каждый будет размеры желать на не менее, чем Минран.
А потом эти Минраны мы будем сливать.
То есть, у нас будет такой, давайте я начну тут рисовать.
Так.
Что такое Минран?
Чава?
Что такое Минран?
Ну, пока некоторое мистическое число.
Мистический смысл просто.
Ран, любой ран должен быть размера не менее, чем Минран.
У нас же, может быть, как раз НППан ранов?
Может.
Может.
Но мы будем с этим бороться чуть позже, поймем как.
Давайте только по порядку.
То есть, это пока вот в общем, действительно в общем чертах.
И потом, значит, у нас получится, что массив разбит на раны.
Вот у нас есть.
Так.
Так, а в телевизор это попадает?
Посмотрите, пожалуйста.
Ну, как?
Ну, сколько там хорошо видно?
Нет, ну, доску видно, конечно.
Надо потыть на угол.
Так, давайте сюда.
Посмотри, что видно.
Вот, а так видно?
Ну, я просто пока сюда, наверное, доску там поверну.
Ну, нет, там тяжело уже расследить.
Ага.
Так.
А вот так?
Вот так видно.
Ага.
Хорошо.
Значит, так вот.
Вот.
Значит, так видно.
Вот есть массив.
Мы его разделяем.
То есть, мы его разделиваем на отсортированные подмассивы.
Ну, некоторые из них там могут быть отсортированы по убыванию, но понятно, что развернуть их трудами составляет.
Вот.
Ну, и вот.
И теперь идея, значит, эти раны надо слить.
Как их будем сливать?
Ну, основная идея такая.
На каждом шаге мы будем брать два каких-то рана.
Вот, каких-то.
И их сливать.
То есть, торжественно превращать их в единый отсортированный ран.
То есть, теперь у нас есть четыре.
Вот, получите теперь, что у нас есть четыре рана.
Ну, теперь же их тоже выберем какие-нибудь два.
Ну, вот.
Ну, и так далее, пока массив не будет отсылен.
Пока у нас не останется единый ран.
Что?
Два минимальных.
Э-э, да.
Но проблема в том, что мы будем обязательно брать два рядом стоящих.
Поэтому там позинки вопрос, что делать вот в таких вот ситуациях.
Поэтому там совсем просто два минимальных слить, конечно, не получится.
Хотя, конечно, иногда очень хотелось бы.
Вот.
И каким-то мистическим образом надо это сделать так, чтобы этим точкой решения была R log.
Итак.
Как говорится, теперь.
Ну, как говорится, это был краткий анонс.
Теперь о том и о другом подробнее.
Вот.
По некоторым мистическим причинам мемран предлагается вычислять именно так.
Так, давайте посмотрим.
Так, ну вот.
Ой, так, нет, не то.
Так.
Так, ну вот.
Так, ну вот.
Вот.
Ну, там, смотрите, вот давайте кодовую фразу сразу прочитаем, все остальное это будет понятно.
Ну да.
Ну, то есть видите, то есть он почему-то делает следующее.
Что он от этого оставляет старших 6 бит, соответственно.
Ну вот.
И прибавляет, ну вот.
Ну ладно, не, ну ладно, не 6.
А, ну да, 6.
И почему-то прибавляет единичку, если там среди отрезанных бит хотя бы один был единичка.
Ну, то есть честно скажем, это, то есть это вот немножко черной магии.
То есть, честно говоря, я себе светлую не скажу, может у Тима Петерса там есть объяснение, откуда он это вообще взял.
А другие алгоритмы не работают?
Ну, как сказать.
Как бы что-то.
Ну, с прогулятором так.
Как говорится, он там проводил исследование, что-то там шаман, вот дайте, шаман не шаман, шаман не шаман, он пришел вот к этому.
Вы можете по шамане прийти к чему-то другому.
То есть, все кроме первых 6 бит он объявляет, есть ли где-нибудь кроме первых 6 бит единица.
Ну да.
И к итогу вот прибавляет.
Вы видите, ответ это вот эти первые 6 бит и плюс возможно вот этот один.
А, первый.
Нет, стоп, стоп.
А это лунный, это весь код.
Нет, он проиграет все кроме последних 6 бит.
Кроме главных 6 бит.
Кроме старших 6 бит.
Да.
Нет.
Да.
Последний это младший.
Последний это старый.
Он старший 6 бит.
Ну да.
Можно просто?
Да.
Можно более семидесятными делать.
Ну как сказать?
Ну теоретически, ну вот, написать-то его может и можно.
Но практически тут как бы цель понять, понять о чем он вообще делает.
То есть, так-то, пожалуйста, его там можно и золотой единицей написать, да.
Но уже не эффективно получается.
Ну вот, но это не особо важно, понимаете, потому что минран.
Нет, эффективность в данном случае не важна, потому что, напоминаю, эта функция дед-минран.
То есть, она вычисляется один раз в самом начале.
Вообще.
Так что можете её хоть за 1?
Ну там, по крайней мере, делать там за от единицы, за единицу локенду, это как, вроде, в принципе?
Ну вот, поэтому да.
То есть, по вот таким местеческим причинам мы заключаем, что у нас вот этот вот...
То есть, минран обычно лежит на отрезке от 32 до 65.
Вот.
Ну, то есть, видите, он не тянет, он не тянет.
Ну, то есть, видимо, если у вас n изначально меньше, то как бы есть подозрение, что, господи, ассоциируйте уже сразу пузырьком, что вы паритесь.
Ну да.
Ну да, да, да.
Ну сейчас, да, ну, просто сейчас увидите, что мы будем делать дальше. Пока как бы вот этот ход на симпатику, очевидно, не влияет.
Так, сейчас давайте попробуем.
Ну потому что, смотрите, ну, как связано.
Скажем так, мне надо решить в этом отрезке, ладно, вот более формально утверждение, при достаточно большом n.
Во-первых, там 65 грану, до 64 грану, потому что у нас n меньше, грану 63, после замыслов.
Ну формально, да, да, да.
А, ну там да, это как-то стандартный отрезок, так это всегда пишут.
Ну окей.
Почему 64?
А потому что, ну, потому что, когда мы останавливаемся на n, n строго меньше, чем 64.
Поэтому при прибавлении r, оно больше 64 не станет.
Так что замечание правильное, спасибо.
Ну правда ладно, отметим, что, формально говоря, если n изначально было 18, то, в общем-то, оно останется 18.
То есть это просто, если n больше или равно 64, то это n по моду 64 плюс 1?
Нет, нет, нет, нет, нет, нет, мы не те биты отрезаем.
n по моду 64, если бы мы оставляли 6 младших бит.
А здесь мы, обратите внимание, оставляем старшие.
Очень интересно нам так.
Я думаю, когда можно было бы просто лито 64 сказать, оно бы работало.
Ну вот, я не знаю, по каким-то причинам.
Честно говоря, честно скажу, я не готов.
Говорить, почему он нам врубил именно такую моду.
Стоп, нам нужно будет это доказывать.
Что доказывать?
Почему он?
Почему что, что вот это работает с залога?
Не, что он говорит?
Что он говорит?
Ну вот, не знаю.
Значит, это вот, соответственно, да, вот такой вот минран.
То есть, видимо, знаете, одно из объяснений у меня, знаете, вот сейчас мне пришло в голову.
Знаете, объяснение может такое.
Что он хотел, чтобы не раны были по размеру степени двойки,
а чтобы самих ранов было приблизительно степень двойки.
Ведь обратите внимание, количество ранов, на самом деле, это, то есть, количество ранов размера, ну допустим, вот такого размера.
То есть, если n поделить на вот это, то сколько получится?
Примерно два в степени, правда?
Два в степени, там, сколько там было бит в числе n, минус шесть.
И, видимо, накидываем еще, ну вот, поэтому там вот получается, как раз вот, приберем стоп.
Может быть, там, плюс-минус один.
Сейчас, как можно, как, из каких соображений мы видим, что если n поделить на вот это, то получим два в степени стопа?
Ну, потому что, ну, смотри, потому что, если ты там можешь это число на количество бит минус шесть,
то есть, на два в степени количества бит в числе n, минус шесть, получим что?
Мы получим эти шесть бит и ноль эти, правда?
Вот.
Ну, да, я не знаю, да. Дальше, правда, да, дальше то, что получится, конечно, да, еще там что-то добавит.
Ну ладно, гипотеза была привязана.
Ну, вопрос.
Ну, порядок такой. Ну, как-то, ну, я не знаю, я не знаю. Так, да.
А, вот, если у нас n огромное, и здесь, значит, а4, то вина будет размиграть 1?
И будет, почему она 32 становится?
Потому что мы в балландии.
А, хотя это неважно, да, там. Ну, просто так-то, если n большая и степень двойки, то минран будет 32.
33. 32. Или это 32, вот эта r никогда не сработает.
А, а с черным это и вы.
А, я вот так и вырисовал.
Да, да, да.
Честно скажем, не знаю. Все вопросы к Тиму Петрусу.
Так хорошо.
Да, вы сюда. Сотировки Тима Петрусу, да.
Ну, да. Комитета, как вы их сюда, как звали? Как звали главу этой комиссии?
Ага, так еще комитета постарается.
Да, да, да.
Итак, вот. Итак, вот минран мы, ладно, вот откуда-то вот взяли.
Ну, тоже честно скажу. То есть, это вот, как бы, Тим Петрус сказал, что вот, по моему мнению, получается так.
Ну, вот, давайте.
Так вот, теперь, следующий номер нашей программы, это, конечно, разбить массив на ран.
Но, как мы его будем избивать? Тупо, отжадно.
А, или просто идем сначала массива, видим два первых элемента, и после этого идем, идем, идем до тех пор, пока массив отсортирован.
рense, по возрастанию или убывание.
То есть, обратите внимание, что при этом, да, то есть, вполне может оказаться, что там 2-й элемент допустим, меньше 1-го.
Но ничего страшного, этого означает, что мы дальше идем-идем-идем-идем до тех пор, пока массив не перестанет быть отстанут по убываниям.
Значит, говорим хлоп.
И продолжаем, ну вот. И начиная с этого момента наг canereading новый ран.
момента набираем новый ран, смотрим. Так, тут у нас 3, 4. О, а это уже массив по возрастанию. Давайте 5, 7, 9, 12, 2.
Значит, еще ран набираем, ну, еще может быть после, ну и так далее.
Стоп, а мы в итоге минран не оставим? Да, это конечно мы делаем, я так на маленьком массиве показал без учета минрана.
А с учетом минрана это будет? А с учетом минрана будет так. А с учетом минрана это будет так.
Так, набрали ран, так смотрим, набираем элемент. Так, что-то, ой, он что-то не отсортирован. А что, там этот ран мелкий? Да.
Ну, давайте его вставим.
Что еще? Вставим.
Что куда? Вот этот элемент вставим вот в эту отсортированную.
А мы должны перевернуть сначала? Нет, пока не нужно.
Да, пока этого не нужно. Даже не за от, а за от расстояния от этого элемента до того, куда он должен сдать.
Ну, у нас минран константный, поэтому за от должен.
Ну, по факту, получится за от, да, за от, так как минран это константно, да.
Ну, вот работать это будет просто, это очень просто.
То есть, потому что как делается вставка? Я очень просто говорю, так, так, надо ставить в отсортированной побывании массив вот это.
Так, тройку, идем с конца. Так, минус 5 меньше, чем 3.
Да, отлично, свапаем.
Значит, тут будет теперь 3, так минус 5.
Так, теперь, так, слева решить минус 2. Минус 2 меньше? Да, свапаем.
Так, единица меньше тройки, да, свапаем.
А мы еще должны хранить по возрастанию любого убывания у нас идет раньше.
Ну, господи, да, да, придется хранить эту огромную размеры на байк более вы перемен.
Вот.
И, вот, тройка, так, следующий элемент. Тройка меньше тройки? Нет, все, стоп.
То есть, ну, помните, да, у сортировки вставки есть такое маленькое преимущество, что если вставлять куда-то недалеко, то она будет работать за год недалеко.
А там же в кэш оно записывает, ну, те элементы, которые у нас меньше, и записывает?
Ну, в кэш она записывает все, она записывает элементы, там не от того зависит большая анимация, не зависит от того, насколько они ближе в памяти.
Да, я имею в виду то, что она же записывает после индекса и элемента в кэш, а не до индекса.
Если мы стоим в какой-то клеточке памяти, то он записывает все те клеточки, которые уже после нашей памяти.
Ну, скажем так, скорее всего, означает, что он автоматически себе в кэш запишет эпсилон на креслость этой эпсилики, так или иначе.
И если мы из этой эпсилонопистости еще не будем вылезать, то там, то по минимуму он в этом кэше будет работать.
И это будет за... там очень быстро.
А характер монотонности мы объявляем просто по первым двум элементам блока?
Да. Ну, ну и все равно, ну, значит, идем дальше до тех пор, пока не определились.
Да, просто свалка вперед, а не работа без того, чем свалка наделка.
То есть я помню, да?
Видимо, тема у тебя так с другом выйдет потом.
Потому что, что-то я не помню, что он предлагал, что если он ориентарально предлагает, то просим его справа и направо.
Нет, стоп, а какая...
Мы стоим в текущем элементе. Вот он поделит кэш, начиная с текущего элемента.
Ну, я, конечно, тут не могу сказать, что я там прям идеальный эксперт, но у меня что-то подозрение, что там, скорее всего, память уже заранее раздана на некоторые наборы.
И классно будут именно скорее эти наборы.
Ну вот, да и... ну я писал на кресло, что логично все-таки там прямо с обе стороны, так что я думаю, это не представляет.
Хотя...
Кресло самоопределение берется в обе стороны.
Ну да.
Ну да, ну правда, опять же, это, конечно, мои интуитивные представления, но...
Вот, тем не менее.
Значит, далее.
Значит, смотрите.
Итак, мы говорим, что он...
Ну, соответственно, да, значит, мы набираем таким образом рам, если ее слишком мелкие, то добиваем ставками.
Если он ассортирован по убыванию, то мы его разворачиваем.
Ну вот.
Там, соответственно, а, ну тут предлагается, нужно ворот сначала развернуть и потом это.
Ну, в общем, тут это не принципиально, если честно.
Ну, отлично.
Ну вот.
Хотя...
Сначала развернуть, чтобы писать цифру.
Ну да.
Ну, там, правда, да.
Ну, хотя, да, при прочих равных нарисоварок мы потратим меньше времени.
Это да.
Ну вот.
Соответственно.
Да.
Ну вот.
Ну, впрочем, это тут.
А вот дальше начинается самое интересное.
Вот.
Так, ну вот, тут написан какой-то текст.
Значит, давай оно.
Ой, ой, ой, ой.
Ладно.
Так что давайте посмотрим, пойдем на доску и порисуем, отчего это вообще все значит.
Вот.
Ну или я пока пристираю, вы можете...
А последний ранг, он же может быть меньше миндрана.
Не меньше миндрана.
Ну, может.
Ну, он один.
Да.
Не так страшно.
Короче, не так страшно.
Так.
Вот.
Значит, смотрите.
Итак, у нас с вами есть последовательные страны.
Вот.
Ну, там разных размеров.
Кто-то больше, кто-то меньше.
Или там в рандомном порядке в каком-то находится.
То есть, мы сейчас не выбираем сервенную руку?
Чего?
Нет, нет.
Боже упаси.
То есть, как бы в том-то и смысл, что у нас если...
То есть, как бы можно сказать, что массивы всего три рана.
Один длинный, два короткие.
Это нас устраивает.
Изначально, может, ради этого мы, собственно, этот тимсорт вообще изобретали.
Ну, там такие массивы сортировались быстро.
Нет, в каком же доме медраны считались?
Ну, медраны считали, чтобы ранов было с другой стороны не слишком много.
Потому что там...
Ну, скажем так.
Потому что мы сейчас, смотрите, мы сейчас будем их все сливать.
И тогда мы рискуем погрязнуть в сливании кучи пар ранов размера по два-три.
Вот.
По константе, видимо, вот тут уже...
Видимо, по константе оказывается, что быстрее уже...
Лучше вставка, видимо, сортировать, чтобы ранов было меньше.
То есть, вы видите, разные триелки такие здесь происходят.
Так вот.
Что мы делаем с этими раными?
Вот, собственно, это будет у нас...
Вот, собственно, основная, самая мистическая с точки зрения математики часть.
Значит, тут я описываю, что предлагает непосредственно Тим Гетерс.
Значит, он предлагает...
Ну, точнее так, общий механизм будет один, но конкретные детали могут отличаться.
Общий механизм такой, что мы будем идти по этим ранам слева-направо.
Да, вот.
Ну, раны уже все напоминаем.
Ацактиброны.
Вот.
И эти раны добавляются вот так вот в стек.
Ага.
Вот так.
Вот это стек.
Ну, там...
И какой-то...
X.
Видимо, в стеке всегда не больше, но...
Ну, да.
У нас будет такая мечта.
Пока само по себе это не очевидно.
Но, значит, будет ситуация такая же.
Мы будем не просто добавлять эти раны в стек, но и поддерживать следующий вариант.
Значит, мы их будем формулировать так.
Ну, вот, смотрите.
Вот тут начинается аккуратность.
Потому что, честно скажу.
То есть, там...
Потому что следующий вариант будет такой.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
И сейчас мы будем смотреть.
Типа...
Ну, потому что, честно скажу.
То есть, там...
Потому, что, скажем...
Там у Тима Петерса в этом месте...
Там начинается мульт, потому что я не человек, а формулирован Дота.
А математические формулированные не замарачиваются.
Вот.
Ну, значит, мы будем говорить так.
Что если у нас есть...
Идут...
Значит, если у нас есть вот такие допустим X, Y и Z...
Вот.
Те-ті три идущих подряд.
то соответственно должно быть выполнено два условия, ну во первых должно быть конечно там x, ну например меньше y, меньше z, ну это на утипе, так сказать, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да, да,
да, x должен быть на самом деле больше не просто y и плюс z, но вот, а на самом деле даже y и плюс z, вот этого можно даже и все, да, достаточно вот это.
Вот.
Ну вот, ну если там понятно, для первых двух ранов конечно тоже выполняются условия, что вот это вот конечно должно быть.
Вот.
Что значит то, что один будет?
То есть значит, ну, по размеру.
А.
Да, мы будем все равно, да, сразу по размеру.
Да, я тут должен был модуль нарисовать, но.
Вот.
То есть мы добавляем и проверяем.
В какой-то момент может так случиться, что вы добавили очередной ран, и вот бабан для вот этих вот троих неожиданно инвариант не срос.
Ой.
Что делать?
Объединить новый слегка, да?
Вот тут предлагают своими нотами.
Вот тут на самом деле так.
Добавили.
Тот, чем Петер говорит так.
Так, хорошо.
У нас есть сверху три, ну скажем так.
Ладно, простой случай.
У нас может добавиться очень большой.
Сейчас, погодите.
Ну, но там так, смотрите, там в этом смысле интересно работает.
Там, ну вот.
То есть там в этом смысле работает так.
Что, вот так, если у нас два рана внизу, и вот этот оказался там больше либо равен, то мы их просто быстренько объединяем.
То есть да, может так случиться, что тут есть мелкий ран, а тут большой, но как бы они тогда быстренько объединятся, и тогда большой ран ставит куда-нибудь.
Вот.
Дальше Петер говорит так.
Так, ну если у нас вот тут нарушилось, то мы говорим так.
Так, вот пусть у нас сверху x, y и z.
Вот.
И мы говорим так.
Мы хотим свить игр.
С кем?
Ну давайте посмотрим на соседей.
Выберем из них внезапно меньшего.
И с ним и садим.
Мы сливаем в два минимума.
Нет, нет, не обязательно.
А, ну вообще, да.
А, ну да, так как игр меньше x, то конечно, то по факту получается в два минимума.
Да.
Но тут лучше не иметь в виду, что два минимума, в смысле может быть, когда мы сливаем x и z.
Нет, такого не будет.
Мы сливаем только два соседних.
То есть x и z никогда не будут в два минимума.
Ну да.
Но тогда просто зачем?
Нет, мы сливаем и как, и с кем-то из соседних.
С кем?
Ну вот, кто меньше.
Ну если разные, ну выбираем любого.
Ну если разные, ну выбираем любого.
Ну в каком случае мы сэксон?
Да, ну потому что z это ранг, который нам положили только жену.
Ладно, z может быть меньше, чем игр.
То есть z может быть кто угодно вообще.
z может быть меньше, чем игр, но...
А может быть больше.
А может быть, пока его только что положили, может быть меньше.
Но среди двух минимальных всегда есть тени.
Ну типа бывает.
Вот, поэтому там иногда бывает.
Правда?
Ну вот.
Ну дальше вот формально только аккуратно.
Потому что если брать статью Тима Петерса, то как бы тут дальше говорит,
а что делать, если после этого слияния там инвариант там все еще нарушен здесь или там где-нибудь еще ниже.
Ну теоретически это может быть.
Ну вот.
Ну тут мы что-то как-то вот не заморачиваемся.
Ну все очевидно, что мы дальше делаем.
Или там читайте мой код, там все понятно.
Вот.
Ну вот, а нам с вами собственно предстоит в этом разобраться.
Ну тоже самое.
Что конкретно делать?
А что то же самое в каком виде?
Ну...
У нас есть не отсортированная тройка.
Ну такая, не плохая, но подобная.
Ага, какая?
Как ты мне сказать?
Ну верхняя.
У нас не изменилось ничего.
Верно ли, что все остальные тройки после этого отсортированы?
А, кстати, нет.
То-то оно.
Могло так оказаться, что когда вы получили тут х плюс икрыт, вот этот вот, да?
То есть тут, видите, не оказалось ли, что вот этот плюс икрыт теперь стало просто больше, чем вот этот?
Или тут х плюс икрыт больше?
Х плюс икрыт может быть больше, чем вот этот плюс икрыт.
А может он и меньше, чем сейчас?
У нас нижняя штука была больше.
Да-да-да.
Для следующей тройки есть.
То есть х плюс икры точно меньше, чем позже было ниже.
Да.
Нет.
Нет, вы гарантируете?
Этим третьим пунктом был вот этот ран.
То есть да, мы гарантируем, что вот это заведомо меньше, чем вот это, это да.
Но верно ли, что вот это плюс это меньше, чем вот это четвертый ран?
Давайте если произойдет так, отложим Z назад и будем проверять линию с игры.
Ну вот один из вариантов такой, да.
Потому что все остальные точно не изменились.
Нет, ну на самом деле да.
Еще раз так.
Но один из вариантов такой.
Ну предлагается так, смотрите.
Мы пока сразу после рана мы можем гарантировать, что вот до вот этого момента все в порядке.
То есть проблемы только вот в этих тройках.
В первых четырех элементах.
Поэтому идея такая.
Давайте в каждом момент времени поддерживаем, где самая низкая тройка, в которой могут быть проблемы.
И говорим, что если в ней проблемы, значит давайте их решать и там уходить.
Там как-то дальше глубоко, если нужно.
Или мы можем догадаться с теком.
Да.
Ну понятно.
И в любом случае скорее всего амортизация сработает.
Ну да, вот эту амортизацию собственно.
Да, в этом-то и будет задача, собственно, доказать свою амортизацию.
Сейчас.
Все.
Дичь.
Нет, зачем?
Нет, у нас есть тек.
Нет, правильно сказали, можно сказать так.
Давайте если вы сливаете их с игр, давайте лучше так Z временно выкинем, да.
То есть, знаете, можно так сказать.
Вот у нас с X Y Z сверху возникла проблема, да.
Тогда идея такая.
Так, если нам надо сливать X игр, то значит мы сливаем X игр и кладем X игр обратно в стек.
Так просто можно сказать рекурсивней.
Если там какие-то, если после этого там в верхней тройке проблемы, ну значит тоже достаем эти три.
Там какие-то два сливаем.
Ну и там.
1 и 5 мы выкидываем куда-то.
Ну типа того, да.
Вот так вот получается.
Да.
То есть после того как бы тут у нас все закончилось, потом Z мы еще раз добавляем и собственно там работаем дальше.
Вот.
То есть вот примерно, примерно вот таким вот образом это будет работать.
Ну один из вариантов такой.
Итак, что же у нас тут будет теперь происходить?
Вот.
Значит смотрите.
Ну вот.
Ну давайте так.
Ну со слиянием вот это мы сказали.
Значит ну давайте смотреть.
Тут как бы могут быть маленькие неосимпатические оптимизации.
Вот.
Ну то есть вот как бы как уже сказано.
Это вот 32.
Это вот экспериментальная оптимум.
То есть понятно, что вот это вот между 32 и 65 вот хочется.
То есть видимо где-то так.
Вот.
Вот.
Вот.
Между количеством стояний и количеством ставок.
Вот.
Ну вот.
Ну и да.
Еще конечно для того чтобы оптимизировать там копирование.
Потому что как мы обычно сливаем два рядом стоящих массива.
Мы обычно куда-нибудь копируем, а потом начинаем записывать результат.
Правда?
Ну ладно.
Ну в реальности.
Показывайте до этого.
Ну да.
Ну да.
Да.
Ну обычно как бы допустим надо отцирктировать вот эти.
Слить вот эти два.
Вот эти два.
Тогда что вы делаете?
Вы берете какой-то буфер, копируете туда эти два под массива.
А потом начинаете прям сюда.
Этим мерджом честно записывать, записывать, записывать.
Вот.
Ну вот соответственно.
Вот.
Идея.
Но идея на самом деле возникает в том.
Да.
То есть читерская идея заключается в том, что в реальности достаточно копировать.
То есть такой вот интересный лайфхак.
Только левый под массив.
Правый вот на метро.
Не, не минимальный.
Именно левый.
А вот смотрите.
Потому что.
Да, да, да.
Да, потому что тут вот очень интересно.
Да, у вас как бы есть два указателя на самих сливаемых.
Ну давайте уже разбегаемся.
Да, то есть у вас есть два указателя на сливаемые массивы.
И вот указатель, который, который записывает.
По большому счету мы можем перезарядить.
То есть этот указатель может там наслаиваться сюда.
Но самое главное, чтобы этот указатель не обогнал вот этот указатель.
Правда?
А при чем тут бинарный поезд?
Вот так.
Нет.
Так, давайте так.
Мы обсуждаем сейчас второй пункт.
Третий пункт.
Вот.
Значит смотрите, внимательно.
Ну вот.
То есть в принципе самое нам главное, чтобы вот этот указатель, в который мы записываем ответ.
Ну как записываем?
Вот типа этот вот элемент, типа меньше этого.
Ну отлично.
Значит записываем, сдвигаем этот указатель.
Вот.
Теперь решили этот записать.
Вот.
Но самое главное, заметим, да, что по идее с точки зрения этого указателя то, что левее,
как бы уже типа для него потеряно.
То есть нас уже не интересует, потому что эти элементы уже куда-то перешли.
Вот.
Поэтому самое главное, чтобы красный указатель не обогнал черный.
А он его не обгонит.
Почему?
Ну потому что он к нему приближается только в тот момент, когда мы записываем элемент отсюда.
А расстояние как раз между ними изначально было как раз в точности равного.
Так что получается, что в реальности вы можете делать за, то есть сливать за, там, за О от левого массива дополнительной партии.
Ну при желании, если вы готовы это делать и с левой, и с правой, то, пожалуйста, вы можете это сделать за, там, там О от минимума.
Но у нас левый массив очень ребраем право, полосы, наверное, реально.
Поэтому мы ничего не делаем.
Ну, кстати, ну, ну.
Ну может баран, скажем.
Не, ну да, скорее да.
Ну да, скорее всего левый да.
Не, ну как сказать, левый, не, почему левый у нас чаще будет больше правого.
Он вариантов всегда больше.
Ну да, поэтому да.
Поэтому да, но здесь, да, но здесь что-то, видимо, экономично особое.
Не всегда.
Если ты сливаешь Игорь и З, то З может быть.
Нет, он приближается к вот этому указателю только тогда, когда элемент отсюда.
Потому что если мы берем элемент отсюда, то эти два указателя двигаются синхронно.
Вот.
Вот, что именно.
Вот.
Так что тут вот.
Ну, какие еще идеи?
А, ну вот, да.
Неожиданно оказывается, что да, есть голову.
Потому что как искать непосредственно раны.
Ну вот оказывается, что.
Ну, вообще так.
Если в процессе слияния, как мы говорили, обнаруживается, что у нас.
Оказывается, что уже к счетной несколько раз подряд мы взяли не элементы из одного и того же.
Массива.
То возникает интересный лайфхак.
А давайте.
А давайте просто попытаемся каким-то бинпольском найти.
А сколько там еще элементов надо брать?
Все, можно даже.
А можно брать-то где и о чем речь?
Можно как-то.
Сейчас.
У первого массива.
Нет, смотри.
Сейчас все будет.
Тут как будет.
Сейчас, Оскар.
Смотри.
Бинпольск может навесить лишний логарифм, если на каждые 7 элементов среда.
Ну теоретически может.
Поэтому лучше использовать.
Нет, посмотрите.
Логарифм, ну как сказать.
Хотя да, теоретически может.
Но тут, во-первых, есть специального вида правильный бинпольск.
Если мы будем просто скакать по спирянбоке, то у нас.
Ну да, сейчас все расскажу.
Значит, смотрите.
Вот такая идея.
Вот допустим мы сливаем два массива.
Допустим такое, да?
Вот мы там дошли и здесь до какого-то момента, и здесь дошли до какого-то момента.
И вот сливаем, и сливаем, и сливаем.
И говорим, так, кто меньше?
Так, вот этот.
Отлично, идем.
Этот идем.
Ой, что-то мы тут слишком долго идем.
И тогда выскакать идея.
Давайте бинпольском каким-нибудь сначала.
То есть, просто смотрите.
То есть, смысл такой.
Какая у нас в этих всех n log n-ах самая дорогая операция?
Обычно самой дорогой операцией является операция именно сравнения.
Вот.
Потому что там, скажем, n log n копирований это не то же самое, что n log n сравнений.
Поэтому возникает такая неосимпатичная оптимизация, как...
Действительно, давайте попробуем тут бинпольском понять, сколько элементов надо просто взять и подряд скопировать.
Но, как было правильно замечено, есть, конечно, проблема, что если окажется, что этот элемент один,
то теоретически может быть так, что на слияние каждого элемента мы тратим многолитвное время,
и это как бы может испортить итоговую ассимптотику.
Но, к счастью, есть такая замечательная штука, как адаптивный бинпольск.
Давайте, смотрите.
Адаптивный бинпольск.
Ну, суть заключается в следующем.
То есть, я ее сформулирую так.
Смотрите.
Допустим, у меня есть этот сактированный массив и элемент x.
Я хочу понять, где этот элемент x, вот находится, где тут граница между...
Меньше x и больше.
Да?
Но.
Так вот.
Но я это хочу сделать...
Ну, могу просто глобально алгорифом на весь массив навесить, да?
Ну, это будет.
А я хочу навесить...
Но я утверждаю, что я могу сделать это за o от log a,
где a это, собственно, расстояние до ответа.
То есть, вот это вот.
Как это сделать?
Внезапно, оказывается, очень просто.
Давайте сначала попытаемся вставить x после первого элемента,
после второго,
после четвертого,
после восьмого,
после шестнадцатого,
ну и так далее.
Ну, по степеням двойки паскать.
То есть, за логарифум l времени мы поймем, между какими двумя степенями двойки лежит l, правда?
Вот.
Допустим, между шестнадцатью и тридцатью двумя.
Здесь у нас прихват 16.
Вот.
И тогда, после этого,
между шестнадцатью и тридцатью двумя,
и на этом подотреске мы тоже можем теперь уже запустить, собственно, абсолютно честный бинпольс.
И тогда это получится именно не log n, а именно log a.
То есть, вот такая вот интересная идея получается.
Это называется адаптивный бинпольс.
Ну, учитывая, что сумма ларифум l по всем, ну, этим длином.
Ну, че очень-очень?
Нет.
Ну, вот эта точка нам теперь точно не испортит,
потому что мы-то сделали, за o от log l мы нашли, куда вставлять.
То есть, сколько элементов надо копировать.
Но копировать нам надо как с l элементов,
и все равно за o от l мы сейчас копируем.
И просто сумма l по всем l равна l?
Ну, не совсем.
Нет, сумма...
Ну, как сказать, не совсем.
То есть, как бы, каждый элемент будет участвовать не в одном слиянии, а в нескольких.
Там отсылка сверху n log n.
Да.
Нет, ну, я предупреждаю здесь мыслить всем, что, как бы,
вы все равно собирались копировать эти элементы.
Да, просто количество сравнений не превосходит l,
поэтому, с точки зрения секунд, уже попало.
У нас сумма всех l это размер первого массива.
Э-э-э, чего всех l?
Левого массива.
Ну, l1 это количество всех элементов,
ênasure,
ну, l1 это количество 아니야 меньше, чем первое элемент второго,
l2 это количество элементов больше, чем первое,
так равно меньше...
Но там 베ом добавляют нули.
Ну, нули мы обработаем.
Это просто нам приводит размер второго массива.
Что мы сделали с нердерог...
Поэтому сумма l это размер...
Чего мы сделали?
Как мы 생각을 сустрельку?
Очень просто.
Очень просто. Смотрите, мы шли по преефиксу, то есть мы шли по степеням двойки, пытались тестировать l равно 1, 2, 4, 8, 16 и так далее.
Наш зал Огрей мы нашли минимальную степень двойки, которая там больше l, ну и там больше либо одна.
Ну и все, значит ответ между этой степенью двойки и степенью двойки предыдущей.
Остается теперь только между ними уже честным билпоиском найти точные.
Куда конкретно сказать?
И почему это сработает сразу?
Ну смотрите, у нас задача отсортировать эти массивы, ну потому что смотрите, потому что в итоговое слияние сработает карм.
Значит мы взяли этот элемент и смотрим сколько элементов, то есть мы должны по-любому все элементы подряд идущие, которые меньше его, скопировать.
Их как раз будет где-то l, и мы их за л от l скопируем.
Поэтому получается, что batch продолжим работать за l, потому что как минимум копирование мы делаем.
Другой вопрос, что элементы мы копируем за l, а ищем сколько копировать мы делаем быстрее, чем за l.
А, то есть мы за л от l ищем, а за л копируем.
Да, это важно. То есть асимпатически ничего не поменялось.
То есть это неосинтетическая оптимизация, направленная на то, что constant в сравнении это не то же самое, что constant копирование.
Еще, мы можем же скопировать за l от l, если же мы все время из l 8 элементов уже брали, то мы можем скопировать за l от l, а нет, не можем.
Нет, там по-любому придется копировать за l от l.
Ну, видимо, да. Но тем более, что в худшем случае, по-любому, вы там на самом деле этого галоп работать не будете, потому что вы будете копировать за l от l.
Это так, если очень не повезет.
Тут еще, кстати, тоже на тему realer данных, чтобы realer данных поможет перенести.
Кажется, что чаще можно скорее нести. То есть со всем, что они там будут прям вот так вот вставляться, это как бы...
У нас же раньше сливание было за l от l, а не за l от l.
А у нас и сейчас оно такое же.
А сейчас у нас стало log l на log l плюс l.
А, нет. Потому что за log l вы работаете над тем, чтобы скопировать вот эти l элементы.
За l.
Еще раз, еще раз.
Эти log l сравнений, то есть для поиска, тратятся на то, чтобы понять, какие следующие l элементы...
Какие l элементы надо просто взять и подряд скопировать.
Они по-любому будут скопированы, поэтому я все-таки не поменял.
А, окей. Мы за log l определяем l и скопируем.
Да.
Так что вот такая красота у нас получается.
У нас log l плюс l.
Ну, типа да. log l плюс l это l. Раньше в этом месте был l плюс l. Раньше мы не заморачивались.
Вот. А теперь вот оказывается, что если идут подряд, то тоже можно это вот подкрутить.
Да. Такие подкрутки тоже есть.
Вот. Ой.
l это размер левого массива.
Ну да.
Да. Ой. А, это все? А, типа все.
Сейчас мы надо подавки на бинокль просто сжигать по степеням койки.
Ну да.
Не-не. В данном варианте он просто прыгает вверх и подавит поиск.
Ну да.
Ну только когда он начинается прыгать константно, да.
То есть если мы обнаружили, что несколько подряд раз у нас элемент крывется с одного и того же массива,
значит вырубаем этот дипметин поиск.
Почему?
Ну потому что это тоже какую-то константу топ-росходов накладывает.
Ну не так. Ну опять это уже экспериментальные данные.
То есть можете проводить свой эксперимент и сказать, что Тим Ветерс неправ.
Это вот просто вот.
Тим Ветерс, он подер, он предлагает.
Ладно.
Так. Ладно. Что-то у меня резистенция немножко наметками, поэтому значит придется продолжить вот таким вот образом.
Ох, да будет свет.
Ой, господи, это погодка. Какое-то ощущение, что уже пять вечера.
Ощущение, что уже декабрь.
Чего?
Чего ощущение?
Ощущение, что уже декабрь.
Ощущение, что уже пять вечера.
Ну да.
Да, как это называется, да.
Как разин мира.
У кого-то 30 сентября, а у нас уже декабрь.
Ну в общем, как в таких случаях говорят, на дворе идет дождь, а у нас идет концерт.
Так вот.
Ну потому что на самом деле, как бы да, мы обсудили практически только две фазы.
Значит соответственно.
Темсор-то есть еще и три.
Нет, не-не-не, фаза алгоритма.
Чтобы не лезть с алгоритмом все время.
Потому что отметим одну маленькую, значит внимание, одну маленькую важную часть.
Потому что в самом конце никто не сказал, что у вас в третьей останется один ран.
Ой.
Вполне вероятно.
Вполне вероятно.
Вот.
Что у нас просто будет некоторый набор ранов, каждые три подряд идущие.
Из которых чему-то удовлетворяют, там...
А можно все перевернуть и послевать?
А зачем переворачивать?
Нет, там будет проще.
Мне кажется просто послевать.
Да, проще то есть, да.
Ну естественно, идея, ну, круче.
Давайте вот это.
Возьмем два верхних, сольем результат.
Сольем с третьего.
Потом в четвертый мы покажем.
А это разве не долго?
9 лет.
А это по-моему как-то.
И это с сельси.
Ну да.
Ну да, для того чтобы.
С сельси.
Ну да, не сельси.
Так.
В чем это?
Не знаю.
потом в четвертом и так далее. А это разве не долго?
Ну как сказать? Не, это не долго.
Сейчас скажи так. Привожу аргументацию тима 1.
Не, ну какой там худший случай?
Ну как бы будет вот это 256, 128, 64, 32, 16, 8, ну и видимо 8. Ну что-то типа того, да?
Ну там по модулю медран, конечно.
Вот. Ну и давайте так. Сначала мы там сливаем 8 плюс 8, потом 16 плюс 16, потом там 32 плюс 32, ну и так далее. Ну и кайф.
По фактам размазано.
Красивый у него худший случай, конечно.
Да. Ну как там? Ну это типа иллюстрация, да. Ну а что там? Формальное заказательство, что...
Иди сам нагревай.
Ну камон, камон, камон.
То есть вы знаете, когда у нас аргумент еще сломается вот этот стек, вот это вот одно из правил, то мы просто сливаем игре...
Нет, смотрите, сейчас мы вообще не заборачиваемся. Сейчас, вот до последней фазы мы тупо сливаем вот каждый раз...
Ну очень кажется, это 8, 8, 16, 24, 40, 64.
Ну тогда мы берем, значит берем, берем...
Ну, кстати, формально берем так. Берем самую нижнюю тройку, в которой правило сломалось.
В ней берем средний элемент и сливаем его с меньшим соседом.
А если там еще...
Если там еще после этого остались тройки, в которых проблемы опять же, берем самую нижнюю и так далее.
То есть тайно проверяем.
Ну да, тайно.
Вот. Так что вот получается, тут примерно такая красота.
Ну и теперь давайте думать, да.
И вот теперь мы поняли весь алгоритм.
Ну теперь нам с вами все-таки предстоит все-таки навести тут математический марафет.
Ну давайте посмотрим.
Ладно, начнем давайте с первой фазы начнем.
За сколько работает первая фаза?
Вот самая первая, когда мы на рану вообще разбирали.
Она работает в задах.
Формально она работает в худшем случае за ОАТН умножить на минран.
Вы тогда ищете минран или какая фаза?
Нет, когда мы разбиваем на рану.
Это вторая.
Ну минран и что за там, видимо логН, да?
А вторая фаза?
Нет, это нулевая фаза.
Я встал на нулевая.
Первая фаза, когда мы на цифру разбиваем на раны.
Мы его разбиваем за Н умножить на минран, но минран это константа, поэтому ОАТН.
Поэтому хорошо.
Вот.
Так что первая фаза не интересна.
Теперь перейдем к третьей фазе.
Так.
Ну что мы видим?
Так, у нас есть некоторые раны.
И их размеры ассортированные.
Будьте здоровы по умыванию.
Это?
Вы последний.
Да, в другую сторону, да.
Вот так вот.
Вот.
Ну вот теперь внимание вопросу.
Там Сима еще.
Еще раз.
У нас еще есть Игры Пиусе.
Ну да.
Ну правда, ну и что?
А надо?
А нам что?
А этого условия нам не хватит?
Я думаю, что нет.
Почему?
Если они там...
ОАТН и ОАТН.
Ну на самом деле там.
Да, заметим, что только этого условия нам недостаточно,
потому что если мы хотим разбить Н на убивающие слагаемые,
то их может быть ОТН.
Понимаете?
Ну смотрите.
Задача.
У меня есть...
Значит смотрите, у меня есть последовательности.
Х1 там, допустим, больше х2,
больше х3, больше и так далее,
больше хк, больше нуля.
И вы знаете, что...
Ну все это целые числа.
Х1 плюс х2 плюс и так далее плюс хк
равно Н.
Внимание, вопрос.
Чему может быть
типа К максимальное равно чему?
Вот такая вот.
Количество.
Кажется, нам нужно не К максимальное,
а скорее...
Ну вот, но нам...
Нет, ну это тоже нам интересно.
Потому что можно оценить, как бы,
что все это вот это конкретное слияние будет работать не более,
чем за ОАТН умножить по высоту стека.
Ну, это понятно.
Да.
Теперь заметим, что К максимальное,
то есть на самом деле максимально возможное К,
это, так скажем,
это от органа.
Это от органа.
А вот почему.
Потому что минимальные...
Ну, какие самые минимальные раны тут могут быть?
Они могут быть
К, К минус один, К минус два и так далее.
А у нас же тогда не выполняется,
сумма двух...
А мы пока не понимали.
Мы в этом уровне это забыли.
Да.
Вы про это забыли пока условия.
Да.
Я просто говорю, почему вот этом условия недостаточно.
Мы просто запоминали,
почему вот это условие недостаточно.
Ну, и почему вот этом условия недостаточно.
Мы просто запоминали,
то есть скажем так,
это у нас когда-то пригодится,
поэтому так затянуть удочку на будущее не помешает.
А соображение важное.
Ну вот.
То есть заметим следующее,
что в идеале получается,
что вот это должно быть там больше либо равно К,
это больше либо равно К минус один,
и так далее,
больше либо равно одного.
Тогда получается,
N суммарно больше либо равен,
чем один плюс два плюс и так далее плюс К.
Это у нас равно, как известно,
N вместо К,
а К вместо D.
То есть, но отсюда следует,
что K это что-то типа там корень из двух N.
Что-то приблизительно.
Ну да, корень из двух N.
Ну приблизительно что-то такое, да.
То есть, да, K не превосходит корень из двух N,
но видно, что отсветка точная.
Поэтому вот именно поэтому
нам, собственно, да,
просто отсортированных рамок недостаточно.
Нам придется еще вспоминать,
что каждая сумма,
сумма каждого из двух меньше следующего.
Ну то есть, негрочистый ровочный рост.
Вау.
Ну да.
Что?
А, ну вообще говорят, да,
можно оценивать чистом лифтепондаш.
Оценивать чистом лифтепондаш.
Можно ступенями двойки просто сказать,
что так у нас,
во-первых, у нас сумма больше этой штуки,
а во-вторых,
ну как во-второй снизу.
Ну да.
Он больше либо равен тому,
что был до этого.
Да, да, да.
То есть, на самом деле,
можно сделать гораздо проще.
Правильно, правильно, правильно, правильно.
Действительно.
Можно просто сказать,
что на самом деле,
просто х он больше,
чем х плюс z,
а х в свою очередь больше,
чем 2z.
То есть, элемент,
то есть, каждый элемент,
он более,
если смотреть,
придвинуть через один,
то он будет меньше,
чем два рамок.
Это вот так,
как минимум.
То есть, как минимум.
То есть, получается высота
с этой алгоритмой,
получается конкретно вот эти
финишные излияния,
явно за алгоритмом вот и работает.
Но оно же за вот и в общем.
Это если повезет.
Мне кажется, оно всегда будет?
Нет.
Кто сказал,
непонятно.
А давайте,
а давайте подумаем над этим вопросом.
Сейчас, мы вторую стадию пропустили.
Вторую, вторую, вторую стадию.
Да, пока пропустили.
А мы перейдем,
когда у нас уже остаться так и просто.
Да, да, да.
Сумма стабилизируется.
Сумма стабилизируется.
Так, ну давайте думать.
Действительно.
Вот это финальное слияние
происходит.
Не выясните,
действительно, что
слияние происходит,
что это снимал вообще золото.
Ну,
там все-таки два вказа,
две карты из первой и так далее,
до трансферного влога.
Ну,
ну,
вообще у нас скировка сомнения,
поэтому нам не поет,
она с самого начала влога.
Но мы хотим быстро.
Мы хотим констант уже.
Когда мы говорим,
у нас есть время для работы,
мы забываем про констант,
мы просто населяем.
Ну,
если мы константы,
мы просто населяем.
Ну,
давайте подумать.
Мы пытаемся.
Ну,
у нас есть третья,
третья фаза.
Типа,
типа сливать,
ну,
эмоцитированных пассивов.
Ну,
это точно многое будет.
Но это,
как бы,
возможно,
не самое быстрое,
что можно их обвести.
Это кучу еще какую-то
доставать,
вот это все.
То есть,
пока константы будут,
уже,
как бы,
аналогом явно быстрее
будет,
если мы просто
их будем аккуратно
сливать.
В общем,
более того,
у нас есть подозрения,
что это будет быстрее,
чем за аналогом,
потому что у нас постепенно,
видите,
вот,
как бы,
этот пример,
вот,
явно намекает,
что,
вот,
скорее всего,
слияние будет,
как-то,
суммарно,
за видео сделать.
Правда?
Потому что,
у нас 8,
там же все,
4,
и так далее.
А теперь,
вот,
возникает вопрос,
о общем случае этого нода,
не за линию ли это,
нод,
не за линию ли это,
вот,
вот,
интересный вопрос,
который будет
действительно
интересным,
будет.
Ну,
я бы написал,
просто,
рекурсивно,
ну,
по индукции,
по индукции,
что,
если последний число
и он за ОАТ,
то мы добавляем,
ну,
и поэтому,
да,
хорошо,
хорошо,
так,
хорошо,
так,
значит,
смотрите,
давайте формализуем задачу,
у нас есть последовательность,
давайте,
х1,
х2,
х3,
там,
и так далее,
х,
давайте,
я вот,
буду я себе воображать,
что у меня,
вот,
степь действительно,
вот,
как ты говоришь,
х1,
х2,
х3,
х4,
х5,
х6,
х7,
х8,
х9,
х10,
х11,
х12,
х13,
х14,
х15,
х16,
х17,
х18,
х19,
х21,
х22,
х23,
х24,
х25,
х26,
х27,
х28,
х29,
х29,
х29,
х30,
х30,
х30,
х4,
х2,
х3,
х4,
х5,
х6,
х7,
х8,
х9,
х9,
то есть Jennyய91 с х3,
actions 진짜,
Hera,
Khan,
54,
rD mog % b,
sel,
nex,
x5,
7,
x6,
x6,
Cont Ок полож這些 now progress.
Ну вот, куда идти?
Ну вот, значит, смотрите, мы хотим их сливать.
Теперь внимание, вопрос, за какое время мы их сливаем?
Ого, есть! Мы их сливаем, внимание, за х1 плюс х2.
Потом, теперь, этот вид, вот, плюс х1 плюс х2 плюс х3.
Вот, ну это вот.
А кто сказал, что мы не можем как-то автоматически это сделать?
А нам не нужно автоматически.
А мы сливаем два минималики и два верхние?
Два верхние.
А там получается, в какой-то момент, верхний может обогнать тот, который лежал под дозой.
Можно. Ну как-то с точной зрения, мол, гэна нас это не волнует, потому что мы сатанстеком играли.
Ну а теперь нас, ну а пока, теперь нас позиционно подозрили, что они может ли так случиться, что на самом деле...
Не окажется, что здесь, что на самом деле вот эта сумма при этих условиях, это от.
Ну где n, это соответственно сумма всех условий.
Ну теперь, смотрите.
То есть если все это, ну скажи так, точное время всех смеяний вот было, да?
Понимаете, да?
Ну и по факту, это для нот, можно сказать так, что это равно, что-то типа х1.
Ну это давайте так, меньше либо равно.
Значит х1 умножить на k, плюс х2 на k, минус 1.
Ну это с точки зрения.
Нет, не в точности, тут тоже к, минус 1 надо писать, но это тут не удобно.
Потому что, видите, все элементы тут уменьшаются, а вот х1 и х2 остаются одинаковыми.
Понимаете, плюс и так далее.
Плюс хk умножить на это.
Вот, такая вот неожиданная красота.
Понимаете, да?
Ну, хит можно оценить как хт поделить на что-то в степени а-хит.
Ну, на какую-то эканастанцию.
Ну вот.
Ну х и минус второе, это не больше, чем х ита делить на 2.
Ну вот, да, то есть на самом деле х ита, да.
У нас есть мистический факт о том, что х ита это меньше, чем х ит, плюс второе пополам.
Понятно, да?
И получается следующее.
И получается следующее, что у нас две суммы.
Одна из этих сумм выглядит так.
хk плюс хk минус второе умножить на 3.
Плюс хk минус 4 умножить на 5.
Плюс там, ну и так далее, короче, да.
Может быть в самом конце либо х2, либо х1 будет.
Ну, допустим.
Ну, давайте я предположу сейчас, для простатей, что к отчетное, да.
И на там сколько там получается.
Видимо на 2k.
Ну, видимо так.
То есть тут как бы 2 на номер слагаемый минус 1.
Номер слагаемый получается, номер слагаемый включить.
На последний без 2.
А, да, да, да.
Вот так, да.
2 на к пополам, ну короче, на к минус 1.
Вот.
Хк минус 1.
Чего?
У нас хк плюс хк.
А потому что, я говорю, мне интересно рассматривать.
Мне интересно рассматривать только слагаемое k к минус 1, 2 к минус 4.
Ну, во-первых, как бы заметим, что вторая сумма она не приводит.
Ну, скажем так.
Вторая сумма, очевидно, это о от этой суммы.
Правда? Почему?
Ну, потому что, во-первых, каждый х меньше либо равен соответствующего коллеге.
А, да, при нем больше коэффициент.
Но этот коэффициент больше не более чем в два раза.
Да, мало кто знает.
Но если вы прибавите к натуральному числу единицу, то оно уграничится не более чем в два раза.
Вот.
Ну, хотя, я исходно писал, что давайте рассмотрим вот эту сумму.
Там вторая половина за вторая половина рассматривается.
Может даже еще проще.
Ну, вот.
Там уже как угодно.
Так, вы знаете, это выходит уже можно как угодно.
Сейчас судим.
Так вот.
Теперь замечаем, что это меньше либо равно.
То есть, это меньше либо равно х.
Плюс х попало на три.
Плюс х на четыре умножить на пять.
Там плюс х на восемь умножить на семь.
Плюс и так далее.
А эта сумма н делить на двадцать три.
Ну, смотрите, х ка поделить на два в степени, там, ка пополам минус один получается.
Ну, вот, умножить на вот этот вот кольцет.
Ка пополам минус один.
Вот.
Ну, то есть, получается какой-то вот интересный ряд.
Ну, по сути получается н делить на два в степени.
Получается х ка значит на сумму по всем i равным, там, допустим, от единицы до ка пополам.
Значит, что-то типа два и минус один поделить на два в степени.
Ну, что-то, по-моему, мы уже примерно обсуждали.
Примерно такой ряд и доказывали, что он, как бы, ограничен сверху констанции.
То есть, получается, что эта сумма равна о от х ка.
Ну, и, соответственно, это означает, что влияние будет за о от н ура.
Да, кстати, дай.
Так что, получается, вот такая приятность.
То есть, в точке зрения НЛОГНа можно было не заморачиваться.
Но мы обнаружим, что наша финалочка, то есть, финальная база, оказывается, тоже работает прекрасно за лидию.
Единственный НЛОГН у нас.
Да. Ну, понятно, что, заметим, что, так как эта сортировка вполне себе вписывается в модель с х мешками.
Ка мешками.
Господи, индийское слово.
Камерный оркест.
Нет, камерный фор это другое, да.
Да, напишите тоже.
Ну, там ГК на первом этаже.
Как-то они репетируют на первом этаже, на западном районе, да.
Так вот.
Ну, а теперь основная задача, она переходит к вам вот, вот.
То есть, соответственно, она переходит к вам, вот.
То есть, соответственно, домашнее задание.
Это, собственно, теперь попытаться доказать, что, собственно, основное вот это мясо на второй фазе.
Так, не базе, а фазе.
Вот, соответственно, оно будет работать за НЛОГН.
Значит, смотрите.
С оптимизациями со всеми или...
Вот, вот там есть.
Значит, ну, проговорим.
Ну, я могу дать подсказку.
Ну, тем более, что, что и не давать, она там в тексте задачи прописана.
Как бы, как примеры, значит, какой амунициационный анализ там удобно забавахать.
Вот.
Но забавахать можно примерно...
То есть, идея будет такая.
Да, вы знаете, у вас есть мистическое знание о том, что высота стека не более логеритма всегда.
Правда?
Ну ладно, двух логеритм.
Ну, может, хотите там через число и по начи оцените, там лог по основанию ФИ какой-нибудь там, вот это.
Почему двух логеритм?
Ну, потому что...
Почему двух?
Потому что для того, чтобы увеличить раму в два раза, вы все-таки скальчите через, знаете...
Поэтому, поэтому число и два.
Нет, если вы докажете, что не более чем одного лога, ну не раскроете.
Ну, это неправда.
Да, ну это да.
Но, как говорится, ну вот.
Но я боюсь, вот этот вот тест вам немножко обален и испортит.
Нет, и конкретно этот не испортит, потому что, например, 2,4 равно 6.
Ну, как сказать, ну, смотри, просто в самом конце здесь...
Ну, как бы, если у вас n...
4 плюс 8 больше, чем 8, да.
Да, вы можете написать 1, 2, 3, 5, а, ну, собственно, чисто.
Ну, ладно.
Ладно.
Как говорил наш эндорист по физике, под гонкой это все, под гонкой.
Ладно, он не к этому, правда, это говорил, но не важно.
Так.
Ну, ладно.
Это все уже детали, но направление такое.
Значит, что будет дальше?
Так вот, дальше идея такая.
Значит...
Значит, смотрите, что нужно...
Так, вот, ребят, сейчас слушайте внимательно.
Потому что, во-первых, сейчас через 5 минут мы будем на перерыв пойдем.
В смысле, кушать.
Ну, вот.
А, во-вторых, как бы, я говорю, длайв у вас через неделю, то есть останется неделя на том, чтобы это передумать.
А там еще две задачи есть, и там только в одной из них будет не надо совсем.
А еще 5 непроверенных есть.
Ну, это другой вопрос.
Так.
Значит, что будет дальше?
Ну, вот.
Тогда идея такая.
Вы говорите, что если у вас образовался ран длины L, и он висит на высоте H, то возникает идея.
Да.
Давайте, если он тут оказался, когда мы кладем такой stack его, то давайте положим на него, там, я не знаю, A, L, H монеток.
И будем следить за вариантом, что каждый раз, когда ран размера L лежит на высоте H, рядом с ним лежит вот столько монет.
И когда этот ран будет там опускаться, мы эти монетки будем каким-то образом прятать.
Вот.
Еще раз.
Если есть какой-то ран, он лежит на высоте H от низа, скажем.
Да.
Да.
Именно вот это.
Причем сьединиться один, два, три, четыре и так далее.
То мы не уходим в A или H монетки?
Где A это какая константа?
Ну да.
A или L?
Да.
Ну да.
A это какая-то константа, как вы сами выбираете, вы поняли?
Сейчас.
А почему мы не можем в него положить?
А именно A или H?
Почему?
Мы же можем в него положить или умножить на A?
Нет.
Можете.
Но просто...
Вот.
Смотрите.
На счет на то, что сливать вы эти A-товарищи, будут сливаться, видимо, у АТАШ раз где-то.
Ну да.
Ой, это я чужую.
Более-менее очевидно.
Да вот.
Это из факта того, что sin2x равно...
Хотя нет.
Сливаться, точнее, опускаться он будет у АТА, что там проблема в том, что он, наверное,
там будет сливаться с кем-то более высоте.
Но за его монеткой будет сливаться.
Ну вот.
А там вот это надо аккуратно, потому что там дальше начинаются детали, которые, собственно,
делают эту задачу реально сложной задачей до шесть баллов.
А мы же когда обсуждали метод бухгалтерского учета, мы говорили, что мы за операцию
можем давать только константное количество монеток.
Не обязательно.
Нет, смотрите.
В данном случае, да, мы будем за операцию, нам будут давать там логарифом монеток.
Но ничего страшного.
Потому что, как бы, если окажется, что мы, как бы, в сумме нам дали n log n монеток,
а это очевидно так, потому что, как бы, h никогда не превосходит от логарифма,
то значит получается все оплаченные действия суммарно n log n.
Неоплаченных действий.
А, вот так мы это можем оценить, как сумма по рейтам это n, то есть n на a на log.
Все суммарные монеты.
Ну да.
Кстати, стоп.
Когда же мы ушли в страйк, то мы ушли за вот единицы.
Да.
Но, да, но, как бы, видим, учетная стоимость конкретно этого действия будет, будет...
Да.
А если...
Когда мы наделали обычный тушь, мы давали эти элементы, давали на него константные
сумма монеток.
Ну а теперь оно будет неконстантное.
Сейчас.
До этого мы...
Да.
Нам просто раньше не надо было класть, не надо было класть неконстантное число
монет.
Но вообще говоря, вам никто не мешает этот действие.
Просто это надо правильно учитывать в анализе.
Потому что, например, еще раз.
В чем смысл бухгалтики у учета, да?
То есть вы говорите, что у вас появляются какие-то монетки, да?
Они сначала появляются, потом вы их на что-то тратили.
И вы...
И тогда, если вы успешно проследили, что у вас в монетке...
У вас никогда не тратится больше монеток, чем получено, да?
То тогда получается, что вы можете все действия изделить на два множества,
напоминаю, да?
Те, которые оплачены, и те, которые не оплачены.
Вот.
Если окажется, что не оплаченных мало, а оплаченных...
Ну а когда вы говорите оплаченных, не превосходит какое количество
монет, как нам дали.
А если нам суммарное количество монеток дали там адекватное,
значит все в порядке.
В данном случае мы боимся, что как бы суммарно нам дадут...
Мы как бы доказали ОАТН-логер-монеток.
Поэтому надо просто за эти ОАТН-логер как-то успешно оплатить все мерки.
Ну или там не все оплатить, но доказать, что не оплачено,
то тоже логер.
А если я, допустим, захочу мне это по ЦЦАЛу...
Ну скажем так, пожалуйста.
Если получится подогнать прям крутой четкий потенциал, то да.
Но он просто не так.
Просто лично у меня подозрение, что просто в теменах монеток
будет просто сильно удобнее.
Там дальше начинается замечательное мышление.
Давайте там по шесть монеток.
Или там для иллюстрации кто-то когда-то писал.
Давайте положим там два ИЛЛЯЖ красных монет,
три ИЛЛЯЖ зеленых монет и там ИЛЛЯЖ синих монет.
И там я писал, что красные буду использовать,
тогда-то зеленые, тогда-то там синие вообще еще в каком-то границе.
Ну это не удобно для доказательств.
Ну кому как.
Потому что самое подлое это даже не это.
Потому что самое подлое, что как бы не...
Ну вот.
Ну то есть дальше надо просто очень аккуратно.
Потому что если вы откроете статью Тима Петерса,
который там просто не заморачивается,
давайте верхнюю тройку проверять и не заморачиваться.
Тогда если у нее все в порядке, значит дальше не думаем.
То дальше, то тогда там, честно, на уровне звуков ходило,
что это можно просто тогда придумать тест,
на котором это реально не за многое работает.
Поэтому то, что тут было написано на доске,
это одна из, скажем так,
один из вариантов доведения этой общей идеи до правила,
до, собственно, какой-то адекватной работы.
То есть более того, с нерадистами тоже можно теоретически играться.
Можно и строгие делать, можно нестрогие, не сильно глобально.
Вот.
Поэтому, значит, от вас потребуется, соответственно,
четко сформулировать точные варианты.
То есть варианты, собственно, что конкретные, когда вы сливаете.
Потому что, как уже было сказано,
в оригинальной сортировке это прописано очень много.
Вот.
Собственно, прописание это и после этого все аккуратненько,
соответственно, следует.
То есть после этого тогда и доказывают.
Ну, доказать, что там потребуются полные.
Да, ну, там полные.
Докажите, что тюрсорк работает за НЛОГН.
Ну, соответственно, там первую-третью фазу, соответственно, вы,
собственно, без труда докажете, что там нужно за НЛОГН точно.
Там нужно доказать не только.
Ну, по-хорошему, да.
Ну, в первой-третьей фазе это все.
Просто там заказывают, что третья фаза работает за ЛАТЭМ,
а потом этой задачей не погребают.
А стоп-1 фазан тоже за ЛАТЭМ.
Так, ну что, господа.
Так, все, давайте можем начинать.
Да, и свет выключается.
И начинается кино.
Да.
Могло показаться, что мы поговорили, как говорится,
о сортировках уже достаточно?
Ну, нет.
Как говорится, нет, о сортировках нам придется еще поговорить еще.
Сколько это?
Ну, конечно, да, тема сортировок, может быть, теоретически,
ну, не то, что она бесконечная, конечно,
но на самом деле НЛОГНностью-то у нас все не ограничивается.
Потому что всегда начинаются всякие детали, всякие примочки.
Вот уже, например, на уровне просто том, что делать с равными элементами.
Ну, чаще всего, конечно, если вы сортируете инты,
то в каком порядке у вас там инты будут идти вам по барабану?
Но ведь, как говорится, думаю, в подавляющем большинстве случаев
вы сортируете не сами инты, а какие-то объекты
по каким-то интам или под какому-то другому компаратору,
не правда ли?
Поэтому, оказывая нот, поэтому равные элементы,
это не значит, что они там просто абсолютно совпадают.
Вот.
Ну, поэтому иногда возникает желание сортировать элементы
так, что равные элементы должны идти в том же порядке,
что и были, такие сортировки называются стабильными.
Ну, типичный пример, действительно, сортировка по старшему разряду.
Действительно.
То есть, если мы хотим сортировать их по числу десятков,
то тогда стабильная сортировка будет обязательно оставлять 36,
пока раньше, чем 32.
То есть, видите, вот именно в том порядке 31, 36, 32.
Да, то есть, заметим, это не алгоритм, это определение.
То есть, да.
Ну, как сказать, вот по-разному бывает.
Потому что пары это означает, что вы создаёте эти пары,
скорее всего, этот лишний элемент копируете
или там указатель на него какой-то направляете, да?
То есть, это даёт какие-то накладные расходы.
Ну, я сформулирую так.
Идейно, скажем так, с точки зрения асимптотики, да, никакой проблемы нет.
Вот.
Но с точки зрения технической всё-таки желательно было бы там лишнего не создавать.
Тем более, что в некоторых случаях...
Тем более, что не всегда сортировку делаем за НЛОГН,
иногда мы её там можем делать и побыстрее.
Да, ну, вот, правда, есть ещё...
Тем более, что иногда бывает большое желание,
потому что мы помним о том, что у нас есть, конечно, основной критерий алгоритма это время,
но вообще как бы есть такой второй тоже достаточно важный критерий,
это сколько памяти мы жрём.
Вот.
И вообще очень неплохи те сортировки, которые не требуют дополнительной памяти,
или, ну, если быть точнее, требуют от единицы дополнительной памяти.
Ну, понятно, что когда вы там запускаете форик,
то вы тем самым там создаёте новую переменную И,
то есть, конечно, совсем без дополнительной памяти вы не обойдётесь.
Ну, вот.
Но, тем не менее, хочется, чтобы её было от единицы.
И вот с этой точки зрения тоже, вот, оказывается, хип-сорт и мэкш-сорт они различаются.
Потому что, скажем, хип в том виде, в котором мы его с вами обсуждали,
вполне можно реализовать локально, правда?
Потому что можно всё хранить в едином массиве,
и, соответственно, там в правой его части отсортированные максимальные элементы,
а в левой части элементы образуют кучу.
Это вполне возможно и удобно.
А вот в том виде, в котором оно у нас, мэкш-сорт это нелокально.
Почему?
Потому что для каждого мэржа мы требуем какую-то, ну, хотя бы от размера,
там, хотя бы одного из сливаемых подмассивов, но размер требуется.
Вот.
Ну, на самом деле, конечно, можно на самом деле извратить и сделать мэкш-сорт от единицы.
Кстати, вполне вероятно, что сегодня мы будем даже это обсуждать.
Ну, вот.
Но по умолчанию мэкш-сорт в том виде, в котором у нас есть.
Ну, не скажите.
Там такой...
Ну, как сказать?
Смотря какая идея имеется в виду.
То есть да, алгоритм нельзя сказать, что там супермиро сложный, конечно,
но и сказать, что он...
Чего?
Да нет.
Ага.
Ну, как сказать?
Подводить с индексами, понять, как туда можно впихнуть корень.
Да.
Да, совершенно внезапно, чтобы слить два или два массива за линию,
оказывается, нам нужно делать что-то с корнем.
Да, Зиня.
Ну, вот.
Это так.
В краткий анонс.
Да.
Как корень используется в линейных алгоритмах.
Да.
Это про мэкш-сорт за до памяти от единицы.
Да.
Или, точнее, что то же самое, как слить два под массива за от единицы.
За от единицы до памяти.
Да, конечно.
Ну, а, симптотика от n, конечно.
Потому что так-то есть тупой алгоритм хип-сорт называется.
В общем-то.
Вот.
Но.
Но бывают ситуации, когда, конечно, сортировать за n лог n, конечно,
можно.
Потому что, когда мы говорили, что быстрее, чем за n лог n нельзя,
что мы имели в виду, что мы сортируем конкретные, вот,
мистические непонятные объекты.
И у нас есть только какой-то вот черный ящик, которому дали эти два объекта,
он их просканировал, сказал, что вот этот меньше.
Вот.
Да.
Мы эти объекты называли камешками.
Вот.
Но.
На самом деле, конечно, это не то.
На самом деле, отчасти вы сортируете элементы, по которой вы таки что-то знаете.
Самый простой пример, это, конечно, представим себе вот такая, дайте, задача на турбо-паскале.
Дано 100 тысяч элементов, каждый из которых от 1 до 100.
Вывести их в сортированном порядке.
Да.
Первая идея.
Вы бежите писать кусок, кусок, но понимаете, что это бесполезно.
Почему?
Потому что турбо-паскаль это 16-битный компилятор, и массив на 100 тысяч он просто банит на этапе компиляции.
Что, не было у вас такой ситуации?
На серву пасхаль.
Да-да-да.
Да, точно.
А ради интереса, ну поднимите руки, кто писал на паскале когда-нибудь.
Да.
Круто, круто.
Спасибо, да.
Не, ну как сказать, я вам скажу, я на турбо-паскале почти, ну это почти, едва ли до всех серсов дошел.
Ну так честно скажу, я вообще на турбо-паскале не пишу.
Едва ли до всех серсов дошел.
Ну так честно скажу, я вообще на самом деле до ВУЗа программировал на паскале, ну или там на Дэлфи соответственно.
Ну это ладно, я еще ладно.
А Геннадий Короткевич вообще на паскале три межнара выехал.
Ну так нет, он может там как что-нибудь умное там состоянием там на сях писал, я не знаю, но основным его языком тоже был паскаль вполне.
Вот так что.
Так что на самом деле, да, паскале это на самом деле очень красивый язык, на самом деле о нем хорошо жить можно.
Ну в принципе да.
Ну вы считаете по скорости, да, сопоставимы.
Ну там правда да, бывают всякие глюки, что вы посылаете пять раз задачу под Дэлфи, получаете ВА-1.
Или там рантайм, не понимая, что делать, посылаете под фри-паскалем, получаете окей.
Еще такое бывает.
Вот.
Ну так вот, я что про турбо-паскале.
Вот турбо-паскале, думаешь, сто тысяч ничего не сделаешь.
А потом ваш сосед попал, а потом ваш соседник попал, и парень говорит, да там массива на сто элементов достаточно.
Вы говорите, а, точно, и быстренько пишете.
А собственно что вы пишете?
Ну вот собственно вот это и пишете.
Да.
То есть действительно, если вы сортируете элементы числа от одного до ста, то вы создаете массив от одного всего лишь до ста.
И для каждого из них просто считаете, сколько раз вам соответствующее число встретилось.
То есть пока вы сортируете именно сами по себе инты без каких-то дополнительных примочек, вы не заморачивайтесь.
Вот.
То есть выглядит это, ну я даже не буду там тянуть интригу, в общем, примерно вот так это может выглядеть.
Вот.
Да.
Да, ну здесь обращается, то есть видите, это код написан на олдскульном Си.
Вот, экологически чистом.
Да, страшно говорить.
Можете выяснить, что это посфиксный инкримент, какой-нибудь это Си++, но вряд ли.
Чего?
New Delete это Си++.
Черт.
Ну ладно.
Как говорится, упражнения для изучения, да-да, аллок, диалог какой-нибудь там, молок эти все написать, честно говоря, в них я уже вообще молчу и там ничего не понимаю.
Хотя теоретически можно.
Но как бы да, если вот тут никаких векторов уже не надо, то есть вы честно создали массив на К.
Вот.
Кстати да, честно фориком в сишном стиле написали нолик.
Потому что реально на Си++, боже вас упаси так писать.
А хотя и на Ся.
На самом деле вот эти вот две строчки, конечно так никто не пишет.
Потому что, ну смотрите.
Смотрите, во-первых, значит начнем со следующего.
Непосредственно на Си.
На Си++ в эстреле есть такой алгоритм Филл.
Зачем?
Который, ну вот, в данном случае он бы работал как С, С плюс К, ноль.
Он работает очень просто.
Он берет заданный диапазон по двум итераторам, пробегается по ним и всем элементам присваивает вот это.
Там есть его аналоги, там можете поискать типа Generate, которому там какой-то генератор передаете.
Или что-то еще в этом роде, разные там вещи.
А, ну есть конечно это, где-то очень глубоко в эстреле есть конечно хит сезона Иота.
Который, если просто ему написать вот этот С, С плюс К, он будет писать, заполнить типа ноль, один, два, три, четыре и так далее.
Вот.
Ну там вот разные варианты.
Но это все как бы в С++ эстрель соответственно.
На самом деле, если ваша задача обдулить массив, то есть, как говорится, старая сишная команда Memset.
Работает она заклинание, будьте здоровы, пишется так.
Memset.
С?
С, ну вот, С, ноль, size of C, да.
Ну можно писать size of a C.
Вот, можно просто выучить заклинание, вот так пишете и массив зануляется.
Ну вот.
Ну, как повезет, вот в таких нюшках может и не повезти.
А сейчас скажу, чего говорите сейчас?
Если брать, мы говорили про С, если брать в С не стандартным полоком, а кодлоком, то будет было 0.
А, ну окей, хорошо, может быть.
Ну ладно, конкретно Memset оно заполнит не нулем, но то на самом деле Memset это хитрая функция.
Которая говорит следующее, возьми участок памяти, который начинается вот здесь.
Имеет длину вот этот параметр.
В байтах.
И каждый из этих байтов заполнит, вот тут написано чем от 0 до 255.
То есть, например, если вы напишете, возьмете интовый массив и напишете тут 255, то к чему каждый элемент будет равен?
Да, минус 1, совершенно верно.
Да, для массива это будет вполне работать, да.
А потому что 255 это все биты будут единичными, а инт, у которого все биты единичные, это минус 1.
Нет-нет-нет, нет, потому что я весь массив взял.
Потому что если вы хотите заполнить не весь массив, а скажем первые L элементов, то вы бы написали size of от int умножить на L.
Да, совершенно верно.
То есть, если хотите весь массив так, но если у вас, например, есть один глобальный массив, но вы хотите заполнять его не весь, а только у отель,
это в задачах с мультитестами это все постоянно встречается, то как бы можно тогда написать что-нибудь подобное.
Вот.
А это работает за ωт?
Это работает, да, это будет работать за θ от количества байт, но с очень крутой константой.
Потому что функция, скорее всего, реализована даже не на осях, а на чем-то более низкоуровневом.
А fill тоже?
А fill нет.
А fill это какая-то высокоуровневая шаблонная функция, в которой, скорее всего, написано что-то там for pum pum, там begin не равно end,
плюс, плюс, бегим, там бум, там звездочка, бегим, равно x, ну или как там это называется.
Скорее всего там буквально вот это написано, только обернутые в шаблоны.
Ну подробнее вы с ними там, я думаю, еще в этом семестре уже познакомитесь.
Может такой сиклс все равно аксимизируется?
Что?
Может такой сиклс все равно аксимизируется?
Ну это уже другой вопрос.
Да, если мы считаем, что оптимизатор сооптимизирует все, то это уже другое.
Но, конечно, это так, это, на самом деле, лирическое отступление.
Потому что, на самом деле, основное, что нас интересует, конечно, идет дальше.
То есть классическая реализация, ну вот, перебираем все элементы и делаем плюс, плюс, ц.
Да, ну то есть был бы вектор, вы бы там что-нибудь с двоеточием бы написали, конечно.
Вот, но тут именно плюс, плюс, ц.
Да, здесь тоже обращаем внимание, кстати, еще такое, важное требование код стайла еще обычно.
Что при прочих равных, если вам все равно с какой стороны писать плюс, плюс, пишите его в начале.
Почему так?
Ну вот, ну это, или я вам это рассказывал.
А, ну все, тогда я не буду повторять.
Конечно, конечно.
Просто этот плюс, плюс делает лишнее копирование, там копирование этот не делает, так что.
Ну, господи, не надо, ну, скажем так.
Знаете, тут очень хорошо подходит поговорка на Бога, надейся, а сам не плашай.
То есть все-таки тут как бы, ну вот.
То есть как бы, знаете, да.
То есть все-таки самим все-таки тоже от себя зависит все, для этого надо делать.
Вот, поэтому, ну вот.
Ну а дальше что вы делаете?
Ну, дальше вы действительно заводите переменную постик, сейчас вы записываете все элементы.
Вот видите, обратите внимание, конкретно здесь пост фиксный плюс, плюс вполне оправным.
Вот, отлично.
Вот, ну и конечно не забывать, ну и конечно там, во всех код стайлах конечно больно бьют по рукам, если вы там что-то создали по нюшке, а потом забыли удалить.
То есть помните, да, потому что как бы C++ это как бы место, где вы как бы сами работаете с памятью и полностью за нее отвечаете.
То есть там есть какие-нибудь другие языки, Java и Python, которые наоборот эту функцию берут на себя, но с другой стороны тогда,
ну вот, тогда вам собственно приходится там писать и ваша программа будет работать по принципу, что в любой момент программа останавливается и включается пылесос.
Что такое делить квадратные скобки?
Это удалить массив, то есть очистить соответствую память, именно память, которая была вынята под массив в переменную C.
Это важно, потому что самое страшное, что если квадратные скобки не напишете, делиться сработает, но удален будет только int.
Ведь обратите внимание, сама переменная C это всего лишь указатель на int.
А у нас C это указатель на int, а где у нас там хранится длина массива?
Ну вот, а вот это вот компилятор каким-то образом вкупит.
Там система, по сути, ты же с памятью обучаешься к системе, потому что так же ты обучаешься к системе, она хранит, что вот этот блок памяти ты выделил, я тебе по-моему такой делаю.
А эта система, знаю я.
Это буквально на таком уровне работает, что в других способах будет.
Да.
Так вот.
А статистический массив, который был создан так через нее, он работает хуже, чем тот статистический массив, который имел константный размер, которым еще был известен на этапе компиляции?
Ну, как вам сказать?
Нет, смотрите, нет, константный массив на этапе компиляции, тут как бы две проблемы будут.
Ну, во-первых, как бы тогда у вас как бы тогда вы гарантируете, что этот counting sort будет сортировать только ограниченное число какое-то?
Нет, я имею в виду просто абстрактная ситуация.
Почему, почему не вести плюсы так, чтобы можно было оставить массив не константного размера?
А, нет, так-то, пожалуйста, проблема.
То есть вы тут, в принципе, тут могло быть написано int c и в квадратных скобках k, пожалуйста.
Вопрос тут просто такой, что вопрос в какой памяти тогда бы у вас создавался массив?
То есть так бы это создавалось?
Ну, как бы там какие, просто есть память, вот действительно это динамическая, к которой вы обращаетесь, new delete, она вот типа большая, да?
А есть какая-то вот память, которая выделяется на вот, собственно, непосредственные нужды, вот в них вот эти вот все ints появляются и исчезают.
Вопрос, как бы в какой памяти вы это вызовете?
Просто разница в том, что обычно в этом вот случае, где вот эти ints, там на самом деле памяти немного.
Поэтому там большие массивы, она может просто не потянуть.
Поэтому такие подобные вещи отправляются в динамическую.
Почему всегда не создавать динамическую память?
Прям, ну, прям все вот эти ints.
Ну, да.
Ну, это долго, но просто дольше работать будет.
Потому что, естественно, память статическая вот эта, она, так сказать, больше под рукой, что ли.
А еще, как минимум, даже если создать такой память, тогда указатель будет подниматься статически все равно.
Нет, статически она чаще попадает в кэшку.
Ну, вот. Ну, правда, она чаще попадает в кэшку, потому что вы чаще с ней работаете.
То есть в динамите в том, что она цельным куском лежит.
Ну, и это...
Ну, это да.
То, что раскидано на динамической памяти, оно реально раскидано.
Ага.
Ну, да. Ну, да.
Ну, да. Вот и такое есть, да.
Да, тут много причин.
Вот.
Да, если вернуться к точке.
То есть это была вот сортировка в точке, там прям самая простая.
То есть когда вы сортируете прям буквально ints.
Но чаще всего вы, конечно, будете сортировать не сами ints,
а, ну, там самый простой пример, какие-нибудь жуткие структуры данных,
у которых есть какое-нибудь поле, и вы хотите поэтому поле сортировать.
Ну, например, да.
Или там, ну, вот.
Ну, например, так, да.
Ну, вот. Как тогда?
Ну, тогда, оказывается, это можно сделать следующим образом.
То есть тогда вот, ну, действительно, пример будет, конечно, указываться,
тоже мы сортируем типа ints,
но просто по-другому будем делать, то подразумевает,
что вместо ints здесь могли быть любые структуры.
Идея будет на этот раз такой.
Значит, смотрите.
Опять же, ну, первая фаза, собственно, не отличается.
То есть заведен тот же самый массив c,
где там посчитаем, сколько раз каждый элемент встретился.
Вот.
Но теперь дальше все будет отличаться, каким образом мы будем записывать.
Вот.
Ну, значит, да.
Ну, вот. Потому что идея такая.
Потому что как только вы посчитали, сколько элементов равны нулю, 1, 2 и так далее,
вы можете заранее теперь еще и посчитать,
а где вообще эти элементы будут лежать, правда?
Ну, например, там, скажем так, сейчас, где тряпочка?
А, вот она.
Вот.
Там, тогда что у нас получится?
Пу-пу-пу.
Вот.
Значит, тут получается такая красота.
Вот.
То есть, например, если вы вот, например, узнали,
что, скажем, вот у вас там числа 1, 2, 3, 4, 5,
и там единица у вас, допустим, 8,
2, 3,
3, 15,
4, 7,
и я не знаю, 4, 5,
то в принципе уже сразу можно сказать, что в массиве, наверное, 11, 26, 33, 37 элементов.
И более того, единички лежат в диапазоне от 1 до вот это первые 8 элементов,
вот можно заранее сказать.
Двоечки, это вот с 9 по 11, троечки с 12 по 26,
ну и тут, соответственно, с 27 по 33, и тут с 34 по 37 будут пятерочки.
Вот. Это вы уже можете прям заранее сказать, правда?
Прям в массиве С можно такое написать.
И здесь разные варианты есть.
Ну, например, вот на слайде сейчас написан вариант,
что давайте для каждого С посчитаем, где должны начинаться эти элементы,
а потом дальше вот у вас исходный массив есть,
и давайте просто пробегаемся слева направо,
и говорим, что если я тут вижу троечку, ну отлично,
значит, я эту троечку, соответственно, записываю типа вот сюда и сдвигаю указатель.
Потом я тут вижу пятерочку, отлично, вижу указатель и сдвигаю.
Ой, вижу еще троечку, ну отлично, пишу сюда, сдвигаю указатель.
Ну, думаю, принцип вы поняли, правда?
Ну, чаще на самом деле для некоторой простоты делают наоборот.
Обычно ставят указатель на конец и бегут наоборот справа налево.
Просто насчитывайте.
Ну, просто тогда вот эти концы по массиву С насчитывать проще,
тем более, что хочется это без лишней памяти делать, правда?
А так как насчитать, например, концы?
Ну, очень просто, потому что концы будут равны 8, 11, 26, 33, 33.
Можно, не выходя из этого массива, просто говорить, давайте тут каждому элементу прибавим предыдущий по очереди.
Это случай, а не радикс?
Нет, это карманная сортировка является, ну как сказать, может быть, она же радикс,
она же, может быть, часть радикса, ну, в общем, примерно это мы об одном и том же говорим.
Собственно, в радикс-сорте, более того, кто-то вообще может говорить, да это не суфмасс.
Нет, я имею в виду, это сортировка, не радикс.
Ну, нет, ну как сказать, радикс-сорт – это как бы цифровая сортировка.
Вот, ну то есть, как бы радикс-сорт будет заключаться в том, что мы перебираем разряды в порядке от младших к старшему
и по каждому разряду применяем вот эту, да.
И получается, что мы умеем сортировать числа за n умножить на количество, максимально на количество разрядов в числе.
Вот.
Ну, смотрите.
Ну, смотрите.
Ну, трех справа налево.
То есть, смотрите, альтернативная версия этого алгоритма говорит о том, что после того, как мы посчитали эти группы,
мы указатели будем ставить не на начало, а на конец.
Ну, вот.
Ну, нет, меня попросили, ну вот.
Ну, изменится, ну, глобально ничего, но просто, может быть, чуть проще кодить будет.
Ну, просто, а вот где концы находятся, вот проще вычислить, не вылезая за пределы этого массива.
Ну, просто, смотри, тут ты в коде напишешь там 4 и от двух до пяти и к этому элементу прибавь именно с первой.
А там ты будешь писать там, а там ты будешь, тебе эти суммы все равно там, возможно, придется насчитать, потом этот массив сдвинуть, там на единичку уменьшить, тут нолик добавить.
Ну, да, просто лишнее делать.
Просто так ты вот один раз эти префиксные суммы написал и все.
А там надо вот это еще что-то дополнительное делать.
Ну, вот, да, ну не суть, тут по-разному можно делать, это все мелче.
А, ну вот, да, ну и в чем трюк, да, трюк заключается в том, что, да, указатели поставили на конец, идем на этот раз справа налево и говорим там, видим двоечку, значит, сдвигаем указатель, рисуем двоечку.
Там видим четверочку, сдвигаем указатель, пишем четверочку, ну и так далее.
Там видим, допустим, еще раз двоечку, пожалуйста, сдвигаем указатель.
Вот мы с тобой храним все указатели.
Ну, храним, да, ну суть-суть-то.
Ты памяти столет.
Чего?
Нет, ну по памяти, да, я говорю, просто чисто по коду, то есть различия не такие большие, просто чисто кодит чуть удобнее.
Может же, может быть.
Ну вот, а, ну вот, собственно, да, так вот было бы проще, а так, на самом деле, если прям сортировать вот указатели с самого начала писать, то код будет вот как-то чуть более экзотически выглядеть.
Вот, видали, то есть придется тут насчитывать вот примерно вот такую гадость, то есть, ладно, проход-то один, но действие чуть больше.
Вот, и это, собственно, не то чтобы сильно приятно.
О, где?
А, нет, Memcpy – это копирование памяти.
То есть, когда вам нужно копировать какой-то кусок памяти, вы передаете, значит, куда надо копировать, то есть, начало, то есть начиная с какого места, откуда начало места того, что нужно копировать и сколько в байтах.
Где похоже?
Похоже, что наоборот мы же возвращаемся, мы возвращаемся в Bund A, нам же вернуть надо в A, а не в B.
А, ну получается, наоборот, да.
Да, ладно, здесь маленькая оговорочка, что-то надо A и B местами поменять, да, да, да, да, да.
Да, потому что в Memcpy там все хитрое, там сначала вы пишете, куда копировать, а потом пишете, откуда.
Вот.
Почему не заводим?
Почему не заводим?
С заводим.
Ну, С мы заводим, так или иначе.
Да, С мы в любом заводим.
Да, ну вот.
Ну, тут не лишняя память, а вот эта вот, лишняя мерзкая переменная.
Просто, если бы вы заводили конец, то здесь было бы написано, for i равно 1 и меньше k плюс плюс i, C i t плюс равно C i минус первое.
Все.
Это все, чтобы тут было написано вместо вот этого.
Вот.
Ну вот, поэтому, ну ладно, это не заморачивайтесь.
Вот.
То есть ладно, самое смешное, конечно, это вот скорее вот здесь.
Да, видите, так масштабное заклинание, конечно, тут написано.
Но типа берем очередной элемент i и t, берем из какой он корзины.
И, собственно, записываем в массив B в это место, записываем этот элемент.
Но при этом не забываем этот указатель этой корзины увеличить.
Вот.
Так что.
Да, такое вот небольшое заклинание.
Вот, понятно?
Мы храним всего лишь одну переменную лишнюю.
Ага.
Ну, на самом деле, да.
Нет, на самом деле, да.
Поэтому я говорю, не так принципиально, но вот просто.
Просто тут код чуть более гадостный.
Но это как бы опять же, это вкусовщина.
Вот.
Так.
Ну вот.
Так.
Вот.
Так.
Так, сейчас это.
А, ну вот.
Да, ну, да, то есть действительно.
А, ну вот, собственно, у меня вторая реализация это есть.
Чего я вам, собственно.
Вот реализация, если вы действительно указатели в конец ставить будете.
Вот как-то вот есть ощущение, что кода стала буквально чуть-чуть меньше.
Ну, в середине она.
А нет ли ощущения, что после этого она стала нестабильной?
Нет.
А, ну вот, в этом случае мы здесь с конца бежим.
А, с конца.
Да.
А, еще дополнительная приятность, вместо постфиксного инкремента у нас приучился префиксный декремент.
Чего я сказал.
Да.
Ну, вот.
Так что.
Так что тут еще как бы, да.
Как бы лишний инт не копируем еще.
Ну и там могли сделать префиксный, но надо было как-то и вначале.
Ага, только, да.
Ну, вот.
Суть одна.
Вот.
Так что соответственно.
Да, ну и здесь вот можно обнаружить, как это действительно примерно будет выглядеть.
То есть, если корзины у нас с нуля, то как бы, смотрите действительно, что у нас получается.
Так, сейчас.
Можете, пожалуйста, посетить назад.
Назад это вот сюда.
Вот.
Ну, это не оптимизировали, а просто.
Видите, это проходит под ником другая реализация.
Просто другая реализация.
Почему мы, вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Почему мы, вот.
В B ставим просто минус-минус.
C от A и D.
А потому что, когда мы делаем правую границу, мы, по традиции, делаем ее не включительно.
Я имею ввиду, почему мы не делаем N минус вот.
С, до C.
А N минус нам зачем?
Кажется, что сейчас мы, а, мы не считали, сейчас.
Мы же тут вот снова слева-направо считали C.
Ну, скажем так.
Смотрите, когда мы считали количество C, нам по барабану в каком порядке считать, правда?
Вот.
Потом.
Теперь мы пробежались.
И для каждой группы, если считать их слева-направо, мы считаем C.
Вот.
Вот.
Слева-направо.
То есть, скажешь, если эти группы будут реально расположены слева-направо, где они будут заканчиваться?
Вот.
Такая радость.
Так что вот.
Так, сейчас, куда оно делось?
Вот сюда.
Вот.
Ну вот.
Так же, соответственно.
Ну, то есть, да, здесь приведена иллюстрация, правда?
Да, она не совсем соответствует этому.
Здесь тоже хранится правая, то есть, здесь хранится правая граница, но уже включительная.
То есть, где они реально будут заканчиваться.
Поэтому.
Вот.
Ну, неважно.
А теперь, смотрите.
Ну вот.
Теперь, вот, если говорите о радикс-сорте или по разрядной сортировке, то, собственно, вот, да.
Ну, то есть, на самом деле, тут, конечно, разные варианты есть.
Ну, потому что, действительно.
Потому что, действительно, вы хотите сортировать инты.
Да, кайф.
Хочется их сортировать за линию, да, вот, в какой-то момент там.
Рассказываю.
Ура, инты можно сортировать за линию.
Но, правда, выясняется, что за линию их можно сортировать, только если они мелкие.
А если к числу, там, скажем, до миллиарда, то, сортировка, то, как вы помните, да, что линия относительная.
Сортировка под счетом работает не за О от Н, а за О от Н плюс К.
То есть, где К – это максимальный размер чисел.
Если это число слишком, число слишком большие, то, то есть, когда оно слишком большое, то не пойдет.
Все большие числа можно разбить на что-то меньше?
Ну, один из вариантов.
Ну, какие варианты есть?
Но, на самом деле, числа целые можно и на разряды, собственно, разбить в какой-нибудь системе счисления.
Двоичной, троичной, десятиричной, стотыщичной, в принципе, можно.
Ну, вот, и, на самом деле, действительно, можно сортировать.
Ну, и основная идея действительно, что можно сортировать по каждому.
То есть, мы же должны сортировать по старшему разряду, при равных старших – по следующему, ну, и так далее.
И это можно делать подсчетом.
Это такое общее направление.
Вот, но тут тоже, на самом деле, рассматриваются разные варианты.
Потому что вопрос, с какого разряда смотреть?
С младшего или со старшего?
Вот.
Ну, с младшего, это, конечно, такой классический вариант.
Классический вариант радик сорта, конечно, говорит, что давайте я сортирую.
То есть, давайте я сделаю, будем сортировать сначала по младшему разряду, вот, например, если в десятичной системе.
Потом мы отсортируем по следующему разряду и потом по самому старшему.
Причем, что очень важно, мы это будем делать устойчиво.
То есть, видите, в данном случае устойчивость важна, потому что при равных разрядах на соответствующем уровне,
мы говорим, что чисто будто сортированный по предыдущим разрядам.
Собственно, ровно ради этого мы по этим разрядам вообще и сортировали.
Вот.
То есть, вот такая примерно красота получается.
Вот, и тогда видим, что тогда получается, что...
То есть, это работает, собственно, за...
То есть, асимптотика получится O от N логарифом, собственно, этого максимального числа K по основанию base.
Ну, потому что, да, вопрос будет, как бы, в какой системе счисления вы эти числа запишете, правда?
Когда?
Сейчас.
Ну, по-по-по-по-по...
А, да, согласен.
Да, O от N, да, N плюс base, и будете вы это делать вот...
Да, это вы будете делать за O от N плюс base, и будете делать вот за это.
Да, в принципе, заметим, что base-то вы можете подогнать так, что base...
Ну, заметим, что если будет большой base, то base тут за N вылезет, правда?
Но с другой стороны, пока base меньше, чем N, то тут будет вылезать N, и тогда получается, чем больше логарифом, тем лучше.
Ну, можно base подогнать, кстати, как N, и тогда у вас получится что-то типа O от N лог по основанию NK.
Ну, не обязательно.
Ну, вы можете просто сказать, что давайте в качестве base выберем N или что-то похожее, и вот у вас такая симптомика есть теперь.
Base это что еще?
Система счисления, в которой вы разряды строите.
Просто их можно делать в двоих системе, можно в десятичной, можно там, в какой хотите.
Вот если...
А если делать в системе счисления, в которой вы разряды строите?
Да, ну, чтобы вам было проще, это можно сказать, что на самом деле это N лог K поделить на лог N.
Сейчас это будет на каждом слое.
Да, максимальное число, да.
На каждом слое же у нас...
Ну, там не просто base будет, там...
На нижних слоях, там...
На нижних слоях.
На нижних слоях.
На нижних слоях.
На нижних слоях.
На нижних слоях.
На нижних слоях.
На нижних слоях.
Но каждый слой вы сортируете за N плюс base.
Слоев вот столько, да.
Так что, ну, здесь по-разному можно делать.
То есть, конечно, вот...
То есть, мало ли, если K прям очень-очень-очень-очень большое,
прям настолько большое, что лог K это больше, чем лог квадрат N,
то тогда возникает ощущение, что уже легче было просто это, кусорт запустить.
Вот.
Какая? Вот эта?
Ну, вы каждое число, там, скажем, раскладываете в системе числения с основанием N.
Такая стандартная задачка седьмого класса.
Ну и все.
Ну и все.
Ну вот, у каждого числа получается вот столько разрядов.
И, собственно, вы сортируете сначала по-младшему, потом по-второму, потом по-третьему и так далее.
Вот как здесь.
Почему на первом возряде там по углованию от всех сторон?
Где, где, где?
Где A.
Потому что это как бы...
А потом остальные по возрастам.
Да.
Ну, потому что, видимо, здесь скорее сказали, что вот изначально числа вот такие, давайте вот их возьмем вот так.
Скорее так.
Да, потом так уже не будет работать, но вот.
Хотя нет, устойчиво отсортированы, поэтому теперь получается так, и мы их также и сортируем, то есть ничего не поменялось.
А потом мы уже сортируем это.
Да.
Так.
Так, кто что там?
Вот, там же округление вверх, конечно же.
Что? Где округление? Какое округление?
А, ну ничего.
Нет, ну в лог К округление, ну, округление бы в симптотике не пишем особо.
Нет, просто он спрашивает, как у нас получилась асимптотика меньше, чем у АТА.
Ну, N делительного угла.
Я ему говорю, что K больше, чем N, а если нет, то надо округлять вверх.
Ну вообще да, да, да, да. Ну вообще хорошо, да, что иногда.
Ну с другой стороны, ничего не да.
Ну ничего удивительного да, если K меньше, чем N, то это получится вот N, это настраивает.
Нет, часто в таких случаях пишут там log base K плюс 1 тогда, чтобы этого избежать.
Ну это уже да.
Ну вот.
Так, ну вот, ну тут действительно разные варианты есть.
Да, можно в принципе просто сказать, да, внимательно, что.
А, ну мы написали так, тут написано немножко по-другому.
Ну хотя нет, то же самое написано, да.
N плюс K на количество разрядов.
Вот.
Ну количество разрядов это вот log base K, мы даже чуть посильнее написали.
Так что вот соответственно так может что еще можно делать.
Но, как-то ни странно, да, есть, конечно, и альтернативные версии, которые и уже
к примеру написаны,oting game changer.
То есть к примере, что это N Plaid 1.
Есть, конечно, и альтернативные версии, которые иногда могут
работать эффективнее, а иногда, наоборот, сильно
хуже.
Альтернативный вариант, давайте попытаемся наоборот.
Там что-то типа, давайте сортировать по старшему
разряду, а потом брать подотрезки из одинаковых
и сортировать уже по следующим как-то, типа рекурсивно
что-ли.
Вот, то есть группы… Ну, давайте смотреть.
Ну, по-разному, то есть, конечно, всё зависит.
Ну да, ну как сказать, да, тут как бы ставится, но
тут подозрительно, что это как бы будет работать
за там R на N на K.
Хотя вот действительно, вот, да, кстати, действительно
заметим, что, кстати, тут до памяти N плюс K, а вот
тут, на самом деле, может быть, всё похитрее.
Вот, кстати, если проанализировать память такого алгоритма,
то да, она может оказаться немножко хуже.
Почему?
Ну, потому что у вас тут происходит получается
N рекурсивный… там получается в рекурсии может быть
стек из получается R запусков и в каждом из них до память
K.
И то, дай бог, скорее всего, у вас там… Ну ладно,
вам там… Ну ладно, больше N вам в дополнительной памяти
не надо, потому что вы можете завестить один глобальный
эстетический массив, который там… который использовать
как буфер.
Тогда логичный вопрос, а чем использовать NFD?
Вот.
Ну, как минимум, потому что такой подход тоже есть,
вот.
Ну, а во-вторых, там иногда у него могут работать отсечения
в духе, что если вам передали… если вам передали под массив
размера 1 или какой-нибудь мелкого, то как бы мы сразу
выбрасываемся.
Нет, это понятно.
Поэтому как бы… Ну, как бы такая отсечка там иногда
тоже может сработать.
Вот.
Ну вот.
Вопрос, как бы, да, за какое время это работает?
Ну здесь… Ну как бы есть подозрение, что R, наверное,
на K это, видимо, как-то так просто совсем шапку
закидать.
Такие написали.
Но есть подозрение, что там можно поменьше.
— Кажется, что меньше, по константе это будет больше,
чем LSD.
— Э?
— Ну у нас в этой курсе и весь этот мусор…
— Не, ну меньше, чем LSD я не обещаю.
Ну, с другой стороны, давайте подумаем.
А сколько у нас, в принципе, будет под отрезков, на которых
будет что-то запускаться?
— Много.
— Да, вот много — это сколько?
— Это поздно.
— О, от N это в предположении, что каждый отрезок делится.
А еще бывает, что взяли отрезок, проверили по разряду,
поняли, что он всегда одинаковый и запустили от него же рекурсивно
дальше.
— Ты сам можешь просто вернуть на…
— Могу.
Ну вот, ну смотрите, сначала мы отсортировали по старшему,
вот.
Потом говорим, что у нас теперь есть три блока.
— С отчетом считали, с отчетом сортировали.
— Да, тем же, тем же по счетам, да.
Потом теперь дальше сортируем по второму разряду, но отдельно,
вот эти четыре элемента отдельно, этот один, и отдельно
вот эти два.
Видите?
— А у нас же там основание системы исчления, вот когда
у нас уже, мы сведемся к маленьким блокам, по
самым конец уже.
— Ну.
— У нас нужно, у нас с отчетом работает за количество
элементов плюс размер…
— Ну да, плюс, плюс основание системы исчления, да.
— Да.
— И…
— У нас там блок от трех элементов может сортировать
за очень долго, если мы возьмем большую систему.
— Ну это да, ну за три плюсбейс, да.
— Да, есть такое, есть такое.
Ну давайте считать, сколько, сколько теперь так будет.
Ну формально, можно, как бы, если в тупую говорить,
что, формально говоря, у нас есть, как бы, R уровней,
то есть логбейс, да, на каждом из них под отрезков
до N, и каждый мы сортируем, ну если это все просуммировать,
каждый мы сортируем за количество элементов плюс
K.
То есть суммарно они сортируются за N, там, плюс K умножить
на, там, количество блоков, в которых в лучшем случае
отсюда R.
R умножить, наверное, умножить на катку, и оттуда и берется.
Так что да, тут такие вот развлечения есть, то есть
можно тут тоже еще поразвлекаться с конкретной асимптотикой.
Вот, но, пожалуй, не будем этого делать.
Но на самом деле нет, у этой штуки на самом деле есть
на самом деле красивый вариант.
Ну вот, так называемый бинарный квиксорт.
Ну, давайте представим себе, что B равно 2.
Тогда в каждом под отрезке вы, по сути, их перепорядочиваете,
что типа сначала идут чисто с нулевым битом, а потом
по первым.
Если нам плевать на устойчивость, то на самом деле это можно
делать без допамяти красивым квиксортом.
Вот таким вот.
Ну, типа да.
То есть да, пусть W указывает, по какому биту, в каком бите
мы сейчас находимся.
А в том же, смотрите, ну как бы, то есть это то же самое
вот это, только система чтения двоичная.
Тогда получается, что в этой штуке, в этой штуке
вот это, только система чтения двоичная.
Тогда получается, что в каждом отрезке мы должны перепорядливать
числа так, что сначала идут нулевые биты, а потом единичные.
И, собственно, ровно это мы вот и делаем, на самом
деле.
Есть вот такой красивый вариант.
Ну, то есть формально, с точки зрения квиксорта,
это называется, там вот, есть фиктивный пивот, вот
такого вида, красивого.
Ну, на самом деле мы, конечно, его не используем, а вместо
этого, обратите внимание, видите, что происходит.
То есть, как работает квиксорт?
Вот, в принципе, как квиксорт, в принципе, пишется, да?
То есть, он пишется так, что мы находимся на подотрезке
ИЖ сейчас, да?
То есть, мы говорим, то, что было раньше И, это как
бы уже нолики, то, что было после Ж единички.
И мы говорим, так, пока тут нулевой бит, мы И двигаем,
пока тут единичный бит, мы Ж двигаем.
И вот, оказывается, они указывают и смотрят, вот И указывает
на единичный бит, Ж указывает на нулевой.
Ну, так давайте мы их посвапаем и тоже сдвинем.
И так будем двигать, пока они, собственно, не наложатся
друг на друга.
То есть, мы здесь рандомного не выбираем?
Не.
Нет, мы здесь рандомного не выбираем, поэтому, формально
говоря, это за n лог n работать не обязано.
Но это обязано работать за n на количество разрядов
уж точно.
То есть, n лог k это уже точно будет.
В общем, лог на этот раз двоичный.
Можно еще раз начинать с этой позиции?
Ну, вот, смотрите, ну, классический крестов говорит,
что мы хотим сортировать в массиве А под отрезок
от LDR.
Вот.
И мы говорим, вот у нас есть два указателя И и Ж,
которые начинают навстречу друг другу двигаться.
Так, давайте я лучше порисую на доске.
Как это примерно вообще выглядит.
Так, так, тихо, тихо, тихо, тихо, тихо, тихо, тихо.
Сейчас все будет тут красиво.
Смотрите.
Сейчас тут будет прям вот так вот.
Смотрите.
То есть, вот Ж был массив, мы сортируем какой-нибудь
под отрезок LDR.
И у нас есть два указателя И и Ж.
Они хотят идти и поддерживать вариант,
что все, что строго левее И, это нулевые биты.
Там с нулем.
А все, что правее Ж, с единичным.
Поэтому говорим условно, если тут 0, 0, 0, 0, 0.
Там И, соответственно, останавливается в этот.
Если тут было И, то вот единичка, стоп.
И Ж, там идет 1, 1, 1, 1, 0.
Вот дошли.
И говорим, так, отлично.
И все еще левее Ж.
Ну, тогда нам получается, что надо сделать.
Посвапать эти два элемента.
То есть, вот посвапать будет теперь 0, 1.
И И и Ж теперь так жественно сдвинулись сюда и сюда.
И будем так повторять операции, пока они не слопнутся.
Она будет стабильной?
Стабильной она не будет.
Но нам даже задачи НТ отсортировать.
Раньше должна была стабильность для того,
что при равенстве текущих разрядов все было отсортировано еще помладше.
Сейчас у нас этой цели нет.
Потому что мы просто с другой стороны идем.
Ну, так QuickSort вообще так и пишется.
Просто в QuickSort в этом месте написано АИТ меньше пайвата и АИТ больше пайвата.
Вот.
Дальше начинается небольшая хитрость на тему того,
что делать, когда И и Ж схлопнутся и как они это сделают.
Но, на самом деле, теоретически тут два варианта.
То есть, либо окажется, что Ж и И указывают на соседние элементы.
Вот так вот.
И тогда тут 0, 0, 0, 0, 0, 0, и 1, 1, 1, 1.
И тогда в соответствии с этим мы и пишем,
что у нас тут binary QuickSort, соответственно, вот тут L, Ж и R.
Вот.
Но, на самом деле, может еще так сложиться,
что и и Ж на самом деле просто совпали.
Ну, потому что вы там посвапали два элемента.
Там 1, 0, 0, 1, посвапали и и Ж напали на один элемент.
Вот.
Но, как бы, можно на эту тему дополнительный ифчик тут написать,
но, на самом деле, необходимости в этом нет.
Чего?
Но, нет.
Это не NLGEN, конечно.
Это NLOGEN.
Конкретно это N на количество разрядов числа.
NLOGEN.
Да, NLOGEN.
Это конкретно NLOGEN.
Вообще QuickSort, конечно, но дальше QuickSort будет работать
на тему того, как вы будете выбирать Pivot.
Не, ну почему?
Это NLOGEN, но LOGEN по основанию CAP.
Значит, NLOGEN, только LOGEN по основанию CAP.
Чего-то у меня вызывается статус, да я все правильно решал,
просто у меня ответ неправильный получился.
Ну вот, да.
То есть, как бы, LOGEN и LOGECA это разные вещи.
Разные логи.
Ка это, ну да.
Нет, основание это два.
Чего?
Когда мы запускаем рекурсию, еще раз топим.
Не-не-не, тут на этот раз важно, что тут никаких минус одинов нету.
Чего?
Здесь ОМЕГА, МИНУСОДИН.
А, ну в этом смысле, да, здесь W минус один.
Но здесь вот важно, здесь никаких минусиков нет.
Сейчас они могут встретиться, только если, то если у нас хотя бы 1 0 хотя бы один есть, они встретятся.
Чего?
В одном или ими есть.
Ну почему нет?
Это самый тупой тест на эту тему.
Это вот 0 0 0 1 там, ну какой-нибудь 1 1 0 там 1 1 1 1 1 1.
тогда вот и придет вот сюда, ж придет вот сюда, они посвапаются и столкнутся, то есть в принципе такое
возможно, то есть не сильно глобально, потому что как бы там, если это допустим единица, ну там
типа будет подсортировано, тут будет не пойдет, у нас while и меньше ж, обратите внимание, так как
только и станет равно ж, вот в этом месте, оно больше ж больше никуда не пойдет, свапнули и и ж и
дальше плюс плюс и минус мин ж, то есть и и ж придут вот сюда и станут равны, так что нет, это возможно,
но обычно, то есть это не сильно глобально, то есть честно говоря, это много лет, то есть да,
на паскале нет встроенной сортировки, ну что, чтобы избежать лишних сравнений что ли,
ну так в принципе да, так ну что, еще опросим, так вот, ну вот, ну здесь действительно можно так
думать, что да, сортировка как правильно отмечена, она вообще нестабильна, вот, то есть если хранить
число в личной системе счисления, то вот можно это вот примерно так, то есть тут немножко другое
к и получится rn поделить на log n, но тут дальше, но правда честно скажем, в этом месте можно
остановиться на том, что есть конечно одна мелкая оговорка, что по идее вообще сортировку эту можно
написать за n log log, но оговорка это даже не совсем эту сортировку, а здесь ситуация такая, ну здесь
можно поговорить о, ну вот, ну вот, ну здесь можно поговорить вот о чем, то есть на самом деле да,
то есть часто в алгоритмах мы неравно предполагаем, что якобы там все инты и там числа у нас не
ограничены, да, вот, но на самом деле, то есть на самом деле в компьютере скорее всего конкретные
числа, то есть с которыми можно работать за вот единицы ограничено, да, это называется битность
компилятора, правда, то есть есть 32-битная, сейчас вот все 64-битные, может там когда-нибудь
будут сразу 128 и так далее, вот, поэтому, ну здесь на самом деле да, можно, ну вот, то есть, ну на
самом деле да, можно немножко поговорить о том, так, вот давайте сейчас тогда мы достанем, вот,
попробуем сейчас найти кое-что и тогда сейчас мы просто поговорим о том, знаете, можно более
формально поговорить о том, о какой модели мы вообще живем, но обычно, потому что в том плане
вот мы nonsense.com мы то опустили немного, ну вот мы говорим, что мы тут считаем какое-то количество
действия какую-то асимптутику, да, но немножко опускаем, какие действия там вообще можно делать,
вот, но на самом деле есть более конкретные модели, на самом деле тоже мы там конечно
оговариваемся, потому что там иногда, знаете, начнется, верим в кое-что, так, ну вот, смотрите,
то есть на самом деле это у нас выглядит примерно следующим образом. Так, давайте тут я, пожалуй,
свет уже включу, потому что этого у меня на слайде нет. Смотрите, то есть на самом деле, да,
сейчас мы попробуем поговорить о такой вещи, как RAM-модель. Вот, ну по крайней мере, по крайней
мере, да, вот примерно таком первом приближение. Сейчас мы, я говорю, сейчас будем рассматривать
RAM-модель. То есть это, по сути, модель, в которой мы с вами создаем алгоритмы, там пытаемся
создавать алгоритмы и оценивать их асимптотику. Ну, то есть эта модель такая максимально приближена,
на самом деле, к тому, что мы реально делаем. То есть, конечно, понятно, что базовая, конечно,
модель в теории сложности, это, конечно, машина тюринга, но в машине тюринга эффективно будет
сильно меньше. Правда, там обычно в машине тюринга там проще, там просто говорят, что там главный
алгоритм полиномиальный или не полиномиальный, а там N в пятой, он или N в пищеный, нам по барабану.
Главное, как бы, да, главный вопрос человечества, да, верно ли, что любой алгоритм, который можно
проверить за полином, можно и решить за полином. Да, можно, наверное, да, это называется, да,
можно эту вот, да, эту проблему P равно NP, наверное, и так переформулировать. Ну, в общем, ладно,
тут я не буду копать подробнее, как у вас будет предмет сложности вычислений, где это вы будете
очень подробно изучать. Вот, ну вот, ну мы же, значит, будем, мы живем в следующем мире. Значит,
смотрите, в нашем мире, значит, есть черный ящик, ну ладно, не черный, сейчас мы в него полезем,
и смотрите, так давайте, лучше возьму с собой тетрадочку, чтобы как бы случайно не наврать.
Значит, смотрите, у него есть входная лента, ну это, так сказать, input, можете сказать,
то, откуда вы там сканфуете, ну или там цените, как вы там это, как вы там считываете. Вот,
то есть это будет называться входная лента, это будет называться выходная. Ну, здесь все просто,
то есть из входной ленты, значит, вы данные считываете прям, можно сказать, ну не совсем
побитого там пословно, и тут выводите. Но здесь все просто, то есть как бы считать вы можете,
то есть вот проводится последовательно, вы каждый байт считываете один раз, вот, и, соответственно,
когда печатаете, то есть просто вы печатаете один раз, все, до свидания, то есть в точке зрения
этого ящика, как бы вы сказали, дай следующий байт, вот тебе следующий байт, все, то есть сказали,
ну вот, и все, еще дай байт, он тебе да следующий, то есть сказать, так, погоди, а что там 5 байт
назад было раньше, нет, так нельзя. Ну и наоборот, как бы выход, это называется, так, у меня есть там
мусоропровод там, ну или как-то еще, но все, так, мне надо напечатать байт, так все, я кидаю
мусоропровод, то что там в мусоропроводе, я не знаю. Вот, то есть черный ящик туда не лезет,
это как бы не его зона ответственности, хотя да, почему мусоропровод, в общем-то, да, нет, ладно,
это не мусоропровод, конечно, это на самом деле, да, так вот, значит, смотрите, что тут еще есть,
значит, у него есть, значит, ну, мы будем считать, что, то есть, конечно, это не совсем, то есть,
помните, да, это, конечно, чуть более приближено к архитектуре реального процессора, но это не оно,
значит, мы будем разделять место, где написана программа, и у нас есть еще память,
что такое память, значит, память это набор регистров, вот это вот называется регистры,
что это такое, по сути, это W-битное число, ну, что такое W-битное, это от 0 до 25, W-1, то есть,
в современных компьютерах можете считать, что W равно 64, например, вот, ну, вот, там R4 и так далее,
но теперь выясняет вопрос, сколько регистров, ну, иногда для простоты говорят, что регистров
сколько угодно, ну, сколько угодно в данном случае, это, конечно, в два степени W, вот,
но, может быть, в некоторых моделях можно думать и более аккуратно, ну, вот, ну, часто этого хватит,
но, в общем, сейчас увидите, на самом деле, к чему тут эта, как говорится, лишняя махалота может сейчас
привести, сейчас будет, там сейчас в какой-то момент смешно будет, чего? Это, да, ну, например, да,
но это модель такая, они у нас сразу есть, да, как говорится, да, не пугайтесь, да, это расходится
с реальностью, но вот для простоты можно считать, что есть. Где вы увидели? W-битное число. Нет,
не надо, не надо, не надо. Нет, я не знаю, где-то из физики, да, в физике, наверное, рядом со словом
регистр стоит какое-то слово чистота, но это не тот случай. Ну вот, так вот, смотрите, а теперь
самое интересное, а, еще самое важное, а, ну вот, теперь самое интересное, как устроена программа.
Значит, ну, программа – это последовательность команд. Ну и делается все очень просто. То есть,
ну, программа просто часто проходит по вот этому списку и часто каждую команду выполняет. Правда,
конечно, по умолчанию она идет сверху вниз, но, как мы увидим, из некоторых команд, возможно,
мы будем куда-то прыгать в другое место. Ну да, ну, потому что самое, ну, во-первых,
начнем вот с чего, смотрите. Вот, потому что, на самом деле, ну, во-первых, введем там, ну,
во-первых, понятно, там не просто команды, там есть всякие обозначения. То есть,
например, там типа, ну, вот, можно найти, значит, смотрите, то есть, там, например, вот,
бывает написано там что-нибудь типа равно 5, там, соответственно, 5 и звездочка 5. Вот в параметрах
в параметрах программы это будет три разные вещи. Нам это парсить так. Равно 5 это означает,
что в данном случае имеется в виду именно число 5. Вот в случае этой пятерки это означает,
имеется в виду то, что написано в пятом регистре. А звездочка 5 это означает, вот это очень важный
момент, называемая косвенная адресация. Это что написано в регистре, номер которого написан в
пятом регистре. То есть, типа вот R5, вот что-то такое. Это типа R5, это типа просто 5. Вот там это
записывается, ну, по этой версии так. Да, я честно, давайте, ну, вот, ну, вот, это, ну, это, значит,
что это? Значит, теперь просто с помощью этого записываются команды. Да, давайте я сошлюсь,
откуда я это все взял. Давайте сошлемся на первоисточник. Значит, просто есть такая книжка,
действительно, про компиляторы. Ну, не помню точное название, но я помню точно авторов. Культовая
книжка Ахо-Хопкрафт-Ульман. Можете даже сразу нагуглить. Ну, да. Да, я, конечно, не проверял,
но что-то я не слышал про существование двух Ахо, но вроде, да, тот самый Альфред, да. Вот. Хопкрафт.
Ну, да, скорее всего, тот самый, который алгоритм Хопкрафта-Карпа, да. Да, Ульман. Да,
не помню алгоритма с такой фамилией, но не важно. Так вот, значит, как теперь могут выглядеть команды?
Ну вот, значит, смотрите. Значит, смотрите. Ну, во-первых, а, ну и, конечно, еще, а, и еще
маленькая добивочка. Дело в том, что все регистры равны, ну вот, а нулевой регистр ровнее. Ну ладно,
он, конечно, вообще не ровнее. Он называется сумматор. Значит, дело в том, что все, не тревяя всякие
аритметические операции, а такие будут, будут выполняться через него. Понятно, да? Нет, в нем они,
нет, класс, они в другие места. Да, вот смотрите. Вот с этого можно начать. Потому что для того,
чтобы какие-то операции с какими-то числами делать, можно ввести операцию, ну, например,
лоад. Вот, например, у нас будет операция лоад 5. Ладно, давайте, только не лоад 5, а давайте,
например, лоад 9. Фактически, это операция, ну, на нашем языке сишном, это эквивалентно r0 присвоить r9.
Вот. Но есть, конечно, у него напарник. Там store 11, это будет написано там наоборот, r11 присвоить r0.
Но можно было, если бы я написал звездочка 11, то это было бы с индексом r11 было бы присвоено r0.
Понятно, да? Store. Это мы наоборот. Вот взять эту ячейку и записать в нее то, что написано в сумматоре.
Пока никак. Пока я не ввел таких команд. Пока это как бы доставать элементы и записывать их в сумматор,
и наоборот. Вот за это отвечают вот эти две команды. Да, если мы хотим считывать и записывать,
да, есть, конечно, еще операция read и write. Они вообще без параметров. Они отвечают за то,
что достань, пожалуйста, wbit из входной ленты и положи их в сумматор. А write наоборот. Возьми
этот сумматор и отправь его по адресу. Вот. Но, конечно, этого еще мало. Значит, если вы заказываете
какие-нибудь арифметические операции, то, ну, конечно, стоит начать с операции add. Но если вы
напишите add18, то это будет эквивалентно тому, что r0 плюс равно r18. Ну, как вы догадываетесь,
add звездочка 18, это будет означать r0 плюс равно r с индексом r18. Ну и, соответственно,
если у вас add равно 18, то тогда r0 плюс равно r18. Это вот, собственно, можно привести пример,
вот зачем эти обозначения вообще нужны. Вот. Понятно, да? Вот. Значит, ну, аналоги этого add,
да какие? Ну, конечно же. Господи, зачем у нас телевизор горит вообще? А, так, кстати, тоже
может. Но не нужно. Вот. Во, просто сколько? А, да, так. Так, а камеры это уловят? Аргумент.
Давайте, да, действительно, так, пожалуй, удобнее будет. Так. Вот. Значит, какие еще,
помимо add, тогда можно добавить функции? Ну, конечно. Ну, смотрите, тут дальше тоже в разных
статьях, может, там разные базисы операций. Там, на самом деле. То есть, по умолчанию хотелось бы
вставить, скажем, вычитание. А, ну, естественно, да, мы тут оговариваемся, что все вычитания идут,
естественно, по модулю 2 в w, да? Ну, как, кстати, и в обычном компьютере. Ну, да, то есть вся арифметика,
то есть, если происходит переполнение, то просто, на самом деле, все, то можете считать, что все
сложения вычитания умножения идут по модулю 2 в степени w. Ну, вот, собственно, в современных
компьютерах по умолчанию это так. Хотя, если вы в стандарте c, это, на самом деле, не прописано.
То есть, как это ни странно, стандарт, как-то мы, по-моему, пару лет назад копали, на самом деле,
выяснили неожиданную вещь, что в стандарте c, на самом деле, только про беззнаковые целочисленные
типы требуется, чтобы там, в случае переполнения, все было по модулю 2 в степени w. А как это
делать? Чего? Ну, у нас беззнаковые, ну, например, со знаковыми там просто вопрос. То есть,
например, два, если вы там складываете 2 entire, у вас переполнение, что-то может быть, на самом
деле, там, по-моему, стандарт, в общем, так и жестко не требует. Чего? Ну, да. Ну, да, причем
ub, почему там написано ub? Потому что он рассчитывает, что там, рассчитывает, что c++ может быть написан,
видимо, под какие-то принципиально другие архитектуры компьютеров. Потому что обычно вот эта
модульная аритметика, по модулю 2 в степени w, она, на самом деле, просто на аппаратном уровне
прописана обычно. То есть, обычно... Ну вот, да. Да-да. Ну, просто понятно, что это... Ну, как, знаете,
это из цикла... То есть, знаете, это работает из цикла, что в подавляющем большинстве случаев это так,
и с этим можно... Ну, с этим обычно работаем. Но как бы чисто теоретически где-то там, называется там,
в закрытых конструкторских бюро могут быть другие архитектуры, да. Ну, правда, если... Ну, правда,
конкретно архитектура, у вас будет курс, даже в котором есть словосочетание архитектуры компьютеров.
Да. Да, вторые две буквы означают операционные системы, да.
Ну вот, смотрите, что дальше? Ну, дальше могут быть там разные, на самом деле, операции, потому что,
ну, чисто теоретически есть, конечно, операция ДИФ. Ну, это словчисленное деление. Дальше можно вводить
мод, но заметим, что мод можно не вводить, потому что на этих базистых операциях мод можно уже
реализовать, правда? Ну, потому что, по сути, что такое мод? То есть, что такое там x мод y? Это x
минус x ДИФ y умножить на y, правда? Да. Да. И такое бывает, да. Вот. Но, на самом деле, бывает такое.
Бывает, иногда там в базе смогут вставить какие-нибудь вот эти вот наши любимые ваши битовые сдвиги. Вот. Ну,
то есть, там разные, разные, на самом деле, самые, честно скажу, совсем глубоко так не копал, что бывает.
Вот. Ну и так далее. А, но, конечно, этих операций недостаточно. То есть, самое интересное, это не это,
потому что на этих операциях вы можете только последовательные программы написать, правда? То
есть, на самом деле, чтобы написать что-то не тривиальное, нам нужно какое-то ветвление, правда?
Ну, нет, смотрите, сам по себе, да. Начнем с функции jump. Но сам по себе jump равно 38. Да, то есть, это
прыгнуть в 30, это называется прыгни в 38 строчку программы. Да, здесь равно принципиально, то есть,
никаких вот этих вот прыгний в номер программы, там в конструкцию номер, что там написано в 57
регистре. Нет, так нельзя. Ну вот, а вот так написано. Вот тут жесткие требования, чтобы программы и
регистры друг на друга все-таки влияли не очень. А то как-то знаете. Да, то есть, все-таки аккуратно.
То есть, да, конечно, когда вы будете изучать там, там, современная там гарвардская архитектура
компьютера, они там, конечно, программа и память, конечно, они, то есть, программа в той же памяти и
находится, чисто теоретически она себя сама, наверное, менять может. Но, как говорится, знаете,
но это, как говорится, знаете, результат вызовет нездоровый смех всего зала, но это совершенно
не та реакция, которая нам нужна. Вот. Пока и как. Такой джамп, да. Но для ветвления есть другая функция.
Она сделает следующее. Так, ну вот, но тут, так, так, так, ну дай бог памяти, но, конечно, по умолчанию
она делает так. Она лезет в сумматор и говорит, если там ноль, то, пожалуйста, пойди и прыгни вот в
это место. А если там не ноль, ну просто иди дальше в следующую строчку. Вот. Ну, для удобства что-ли.
Передаю. В смысле? В сумматоре. Ну, здесь раздаем. Ну, там понятно, что теоретически, наверное, можно,
как бы, на этот раз и в регистр какой-нибудь полезет там уже в четвертый, пятый, десятый,
тридцать восьмой. Вот. Ну, то есть, вот, примерно, вот таким образом, вот, на самом деле, это все вылепшим.
Ну, в общем-то, заметим, что подобного GZERO с метками на самом деле достаточно, чтобы реализовать
практически любой цикл, правда? Ну, да. То есть, по большому счету, задача у вас в R0 записано число N.
Ну, вот. И вам, например, нот. И вам, соответственно, очень хочется там записать, скажем, нот. И вам
хочется считать числа от 1 до N, да? То есть, числа N читал и записать их вот в R1, R2, R3 и так далее. Ну, вот.
Ну, и, соответственно, как это сделать? Ну, если, например, в обратном порядке записывать, то это
можно написать что-нибудь в духе, что, там, допустим, GZERO куда-нибудь там в N, там, в конец куда-нибудь.
Ну, вот. Ну, и, соответственно, говорите, нот. Ну, вот. Ну, дальше мы говорим что-нибудь в духе, значит,
там, RID. А, нет. А, в таком RID у нас не получится, потому что у нас это должно. Так, ладно, давайте
все-таки какой-нибудь тут регистр мы все-таки напишем, наверное. Не, ну, как сказать, ну, не совсем
Да, только нам этот счетчик желательно куда-нибудь сохранить, да? То есть, видимо, придется там, ну, вот.
То есть, знаете, вот тут всегда, на таком базе все действительно так начинаются всякие мелочи, типа,
как хранить переменные. То есть, скорее всего, это будет означать следующее, что там совсем уж
массив от 1 до N вам ввести не удастся, потому что там первые, скажем, 5-10 регистров вам придется
завести под свои нужды. То есть, вы будете называть там первые регистры этой переменной и второй
регистр переменной G и так далее. Вот, понятно, да? Вот. То есть, допустим, вы там, ну, кстати,
в реальных компроцессорах тоже так происходит, потому что там есть там какие-то, начинаются уже
всякие регистры, типа, там E-AX, там E-BX и так далее, которые там имеют какие-то там специальные
назначения. Вот. Ну, честно скажу, я, как бы, ассемблер не копал, но там вот какие-то такие аббревиатуры
мелькают. Вот. Так что по факту в итоге получится, что, допустим, если вы тут заведете и будем
называть эти переменные N и G, да, допустим, вот первые три, да, вот, интересно, нам их хватит сейчас
вот. А, и давайте еще в четвертую X назовем. Так, чисто на всякий пожарный, да? То я вот, у меня задача,
я хочу, например, в элементы с пятого по N плюс четвертой, собственно, считать числа. Ну, и сначала
еще считать N. То, видимо, это как у нас будет выглядеть? Давайте попробуем. То есть программа может
выглядеть примерно, примерно, следующим образом. Ну, во-первых, считаем N, да? То есть это будет
выглядеть так. То есть, во-первых, читаем Read. Ну и пишем дальше, соответственно, Store. Ну, Store
равно 1. Все, N считали, понимаете, да? Что-что? Нет, Store равно 1, значит, берем значение из сумматора
и кладем в первый, где я определял это. Нет, просто... А, да, согласен, согласен, да, извините,
извините. Окей, да, Store 1. Хорошо. А, не-не-не. А, сказать, что запиши в первую перемену число 57.
Нет, это не была проблема, потому что мы бы сумматор написали, сохранили бы 57. Нет, почему? У нас была бы, нет,
могла быть звездочка 1. Извините, если мы пишем Store просто 1, то мы записываем в ту ячейку, у которой номер лежит в ячейке 1.
Ну, тогда это означает, что равно 1. Ну, я бы сказал так, скорее это означает, что то ли равно, то ли звездочка в этой операции невозможна.
Ну, казалось бы, мы кладем в регистр, поэтому... Да. Регистр это либо просто чиселка, либо звездочка числа. Ну, да. Это не регистр, это просто чиселка. Ну, да. Так что можно и так.
Так, да. Ну, давайте будем считать, что ячейку.
Когда мы пишем 1, мы имеем в виду ячейку с номером 1. Да, вы правы. А когда мы пишем, допустим, когда мы хотим записать из ячейки 1, мы пишем точно так же, но из ячейки мы уже не пишем.
Да, пожалуй, да. Ну, ладно, пока мы тут делаем визуально, давайте быстренько подправим базис. Ну, хорошо, ладно, давайте тогда...
Что произошло?
Ну, как сказать... Нет, мы тут обсуждаем, действительно, просто по сути вопрос, да, 101, это считать, что мы в первый регистр кладем или считать, что это хрень.
Почему это может быть плохо?
Ну, вот возникло ощущение, что тогда это будет не соответствовать. Ну, потому что, например, add 18, это означает, что мы, имеем в виду, добавляем к сумматору то, что написано в 18-м регистре, да?
Ну, это однородный состав, что получается.
Ну, да. Хотя 101 адекватно, потому что тогда это означает, что кладем в первый регистр. В чем проблема?
Да, то есть то, что в первый...
А, ну, да. А, ну, тогда кайф, да, слушайте, хорошо. А, что мы парились тогда?
Просто у нас не имеет смысла 100 равно 1.
Да. Ну, 100 равно 1, да, потому что положить в...
Во что? Да.
Да, давайте такое.
Ладно, давайте кладем R1.
Теперь.
Так, теперь давайте думать, как же нам реализовать форик на переменных И.
Вот.
Но, правда, для того, чтобы его реализовать, нам, конечно, придется...
Действительно, тут...
Да, ну, вот, действительно, сделать такое, что интересно.
Вот.
Ну, потому что, смотрите, да, у нас тут J0.
Значит, теперь как мы это будем делать?
Ну, давайте, значит, делаем так.
Ну, давайте напишем.
Значит, ну, давайте вот со стором у нас проблемы, поэтому пишем.
Так, сейчас.
А, ну, давайте пишем так.
Load на этот раз...
А, нет, ну, вот.
Load, ну, допустим, равно 0.
А, вот зачем.
То есть загрузить-то мы число 0 в регистр вполне можем, правда?
И давайте запишем его в переменную И.
Там стор, ну, допустим...
Ну, стор, ну, соответственно, 2.
Вот, понятно, да?
Ну, и теперь будем идти...
Ну, хочется идти, пока у нас...
Ну, вот, значит...
Да, ну, команды, значит, мы давайте писать там.
Ну, скажем.
0, 1, 2, 3.
А вот дальше начинается цикл.
Значит, начинается с этого момента.
Сейчас я буду проверять.
Как я это буду проверять?
Ну, вот.
Действительно, разность 0.
Ну, как вычислить разность?
Ну, разность мы, соответственно, вычитаем очень просто.
Загружаем, то есть load.
Ну, а для того, чтобы вычислить разность...
Ну, а для того, чтобы вычислить единичку...
Ну, во-первых, мы не хотим терять m.
Это типа работа с переменной.
А во-вторых, и мы тоже будем приобреть.
Но во-вторых, мы теперь заметим,
там мелкую приятную вещь,
что, как вы прибавляете и вычитаете единицу,
мы все равно можем только через сумматор.
Значит, и пишем, соответственно,
load 1.
Теперь пишем sub 2.
Вот, понимаете, да?
И теперь, соответственно,
если оно равно 0,
то мы должны, видимо,
выброситься в конец.
Потому что, типа,
считывание закончилось, правда?
Ну, а если не 0,
то продолжить.
Правда, у нас тут изврат.
То есть у нас тут, как говорят,
если 0, то как бы надо прыгнуть.
Ну, вот.
Если не 0.
Что это так не совсем формально?
J 0
плюс бесконечность.
Ну, я мысленно напишу
плюс бесконечность.
Да, потому что мы допишем код,
а потом, собственно, поставим, да.
Ну, то есть в реальном месте, знаете,
вот примерно отсюда уже появляется
такой уже удаленный из всех плюсов
оператор go2 с метками.
Чего?
Ну как?
Ну, даже можно пользоваться.
Ну, философский вопрос, по-моему.
Возможно, по-моему, из стандартов он даже выпилен,
несмотря на даже наплевав на любую
обратную совместимость.
Хотя, по идее,
не должны выпиливать, но вообще, как бы,
как говорил мне еще мой,
собственно, еще мой преподаватель по алгоритмам,
оператора go2 в C++
нет.
Совсем нет.
Если ваш код с ним компилируется,
значит, ошибка
компилятора.
Вот.
Так что, собственно говоря,
говорил мне мой преподаватель,
но это был Виталий Борисовский Кольштейн,
если вы такого знаете.
Вы могли с ним, наверное, уже не сталкиваться,
потому что он уже несколько лет назад там уехал вместе с гуглом.
Ну вот, но неважно.
Чего?
Зачем?
Выпить?
Выпить?
Не, ну...
Ну, как сказать, да...
Как бы, я тоже люблю выражение
пойти выпить.
Да, но лучше тут, конечно, да.
Правильно говорится, чего.
Так, но...
Нет, ну, я не знаю, знаете,
вот, ну, философский вопрос.
Честно сказать, пока бы не хотелось, хотя бы,
хотелось бы тут немножко закончить с этим.
Давайте уж алгоритм-то напишем.
Значит, G0.
Так, значит, смотрите.
Значит, если 0,
то выбрасываемся.
Если нет, значит, делаем очередную итерацию.
Очередная итерация
заключается в том, что мы должны,
значит, увеличить и на единичку.
Там и
что-то там записать, правда, или наоборот.
Так, ну, записываем
мы куда? С пятого по n плюс четвертой,
правда? Так, ну,
во-первых, что мы делаем? Инкрементируем
и. Как мы инкрементируем
и?
Правильно.
Load два.
Add равно один.
Так.
А, ну, и в принципе, да, можно
на самом деле сразу сказать,
давайте для удобства пишем.
Store два.
Всё, переменную и сохранили,
но в сумматрии она тоже сохранилась.
Так, ну, правда, единственная проблема,
что у нас, да,
поэтому теперь в сумматрии
мы пишем read, то есть считываем
как раз чиселку.
Вот. И теперь её
куда-то надо загнать.
Куда её загнать?
Кажется, что мы хотим
начиная с том, что регистр, например,
это записывает, тогда нам нужно
вор и ноль загрузить тройку, прибавить
i,
для этого store равно...
Да, и это загнать.
Поэтому я здесь вёл регистр x, обратите внимание.
То есть сейчас я, значит, скажу,
что это будет равно store четыре.
И что теперь будет?
А ничего нет, ну вот.
Так, ну, отлично. Теперь, значит,
достаем переменную i.
Так, ну, опять же, да,
store два.
Так, store два.
Add...
Ну, ладно, не будем
сейчас заморачиваться.
Теперь пишем.
Но мы снова достаем переменную i.
Из второго...
Нет, ну, если плюс...
Нет, тогда load два.
А, ой-ой-ой, да-да-да.
Сейчас ещё раз, зачем мы...
Четвёртый.
Нет, мы занимаемся
записыванием n
чисел входящих вот свода
в регистре с пятого
по n плюс к четвёртой.
То есть вот, да.
То есть это так.
Для того, чтобы пощупать, действительно,
как это вообще примерно работает.
Нет, именно store четыре,
потому что я это в перепоказ
записываю в переменную х.
Потому что мне сейчас
с ума, потому что... Ну, смотри.
Ну, давай так, смотри.
В store у меня один параметр.
То есть я тут должен...
То есть я должен записать туда...
Смотри, тут какая ситуация.
Я должен записать store
то, что написано в сумматре.
То есть я должен взять...
Ну, вот мы сейчас хотим...
Вот мы её хотим как бы сейчас и вы.
Только нам для этого надо её вычислить.
И плюс пять тут написать.
Потому что пока для того,
чтобы прибавить пять, нам нужно освободить сумматор.
И поэтому то, что мы считали,
вот эту переменную,
мы её вот в эту вот себе, в переменную х,
пока сохранили.
Вот.
Значит, пишем add
что там мы пишем?
Ну, add мы пишем. Ну ладно, add
наверное там... А, ну да, мы пять.
add равно пять пишем.
Нет, пять.
Потому что мы же...
Мы с нуля переменную и забабахиваем.
Начиная с какого места мы будем записывать
элементы в массив.
Вот.
Значит, пишем...
А, тогда четыре.
Согласен.
А, ну хорошо.
Значит, пишем add
соответственно, равно
там...
Add равно четыре.
Сохраняем мы это теперь
в третий регистр.
С какого момента?
Так.
Где равно пять тут?
Тут больше нет
такой строчки. Ну ладно.
Значит, поехали. Тринадцать.
Add равно четыре.
Четырнадцать. Store три.
И что-то еще.
Нет, сейчас не должны.
Нет, Store один мы точно
не должны, потому что n мы один раз читали
и оно меняться больше не будет.
И это важно для нас.
Поэтому Store один мы один раз
делали.
Читален больше мы не трогаем.
Внутри цикла мы этим не занимаемся.
Ну вот.
Ну вот.
Так, теперь load
собственно к четыре.
Так, и теперь вот эту переменную
мы отправляем по адресу
j.
То есть теперь мы и пишем
Store
Звездочка три.
Получается звездочка три.
Ну да.
И мы прибавили.
Ну вот, это прибавили.
И теперь остается действительно
сделать, внимание, jump
шесть.
Нет, jump четыре, наверное.
Мы хотим забыть первую.
Да, согласен.
Да, jump четыре.
Чего?
Ну в данном...
Ну смотрите, в случае...
Ну ладно, давайте равно четыре писать.
И тут будем писать равно, да.
Ну j0 и jump
это все-таки да.
Обычно константы числовые, мы их так
говорили списать, значит так и будем.
А, ну и здесь тогда, если мы считаем, что цикл
закончит, значит мы пишем
равно восемнадцать.
Чего?
Где четыре?
Ну добавляй, ну вот.
Ну потому что смотрите, изначально у нас i было
равно нулю, потом мы к ней прибавили единицу.
А записать этот нулевой
элемент нужно в пятый регистр, поэтому
мы как бы, поэтому мы тут прибавляем
четыре.
А куда мы прыгаем? Jump четыре?
Jump четыре означает мы прыгаем в строчку
номер четыре.
А не от R четыре?
Нет, мы ж
в регистр, во-первых, не смотрим, мы просто
прыгаем. Мы ж не, как бы мы не прыгаем
в строчку, равную там, которая записана
в регистре.
Почему вы не написали jump равно четыре?
Да, тут равно написано.
Ну да, скорее всего, было бы некорректно,
потому что, насколько я помню, такие операции запрещены.
То есть как бы просто прыгаете в номер и все.
И как бы, то есть давайте
регистр вам не должен подсказывать,
куда скакать.
Так что, видимо, если
будете куда-нибудь кудить на ассемблере,
то, возможно, вот примерно чем-то
подобным будете заниматься.
Нормально.
В принципе, на ассемблере написали C.
Компилятор, в смысле, C.
Ну ладно,
наверное, не на нем.
Но там все постепенно было.
Есть совсем язык базовых машин и кодов.
Есть там ассемблер, язык
каких-то там минимальных сокращений,
мини-процедурочек.
Ну и там уже пошло-пошло-пошло.
Но как бы ассемблер...
Но объективно, какое-нибудь децентральное описание не на ассемблере,
потому что, начиная
с почти самых ранних версий, написано
того, чтобы собрать, вам потребуется
компилятор C.
Ну да, более базовые, да.
Ну, конечно, конечно, конечно.
Скорее всего, какая-то совсем-совсем базовая штука
написана.
Современные игры уже на бесконечности акции.
Ну, поэтому да.
Ну да.
Ну да.
Так, ну ладно.
Так, ну ладно, с этим справились.
Кажется, что действительно теперь можно пойти
попить.
Так, ну ладно, тут на всякий случай.
Пока что тут появилось, тут за перерыв
действительно появились уточнения к этому коду.
То есть, так, может быть, более точная иллюстрация
того, что тут реально происходит.
Вот.
Ну это так, комментарии для нас, да.
Ну то есть, да, не очень удобно, но, как видим,
все равно наши классические там всякие
подобного рода вещи, они все равно
делаются за 1.
Вот.
Ну вот.
То есть, это по-любому у вас тоже, знаете, особенно
полезно это воображать, если вы пишете на языке
Паскаль, на самом деле, даже еще удобнее.
Потому что на Паскале все переменные, которые
вы используете, вы прописываете перед началом
программы.
То есть их будет у отъединиться.
Поэтому, в общем-то, на самом деле,
то есть Паскаль может быть даже где-то ближе
к вам модели. Ну, по крайней мере, легче, что
вы можете хотя бы заранее там прописать
действительно, какие у вас будут одиночные
переменные, какие там массивы,
и так далее. Но, впрочем, там, кстати,
что интересно,
там,
то есть это там, сейчас
как-то выразится, то есть там все
массивы действительно будут.
Там массивы в Паскале, там они прописаны
заранее, то есть массив размера N вы там
создать не можете, правда.
Ах.
Сравнить?
Два часа.
А, ну, смотри,
ну, сравнить два,
сейчас.
Си-си-си-си-си-си-си.
Ну, смотри, смотри,
какие числа сравниваем.
Потому что, ну, завод ЕДИ сравнить
можно так.
А можно же знак проверить.
Сначала можно, ну, знак,
ну, знак сложно проверить.
Ну,
если мы вычитаем одно из другого,
то у нас получается, что это, что
первый вид будет.
Ну, там переполнение будет, понимаете.
Смотри, вот, ты когда вычитаешь,
ты когда сравниваешь 0 и 2 в 63 минус 1,
там 2 в 64,
или сравниваешь там,
скажем, 8 и 7.
Когда ты вычитаешь там первое,
скажем, из 2-го,
первое, там из 2-го,
первое результат будет один и тот же.
Поэтому тут как бы нот.
Нет, ну, это за ОАВ.
Нет, на самом деле необходимости нет. Смотрите.
Можно сделать так. Во-первых, сравнить
с первой 1 разряд, да?
Ну, если они совпали,
если они не совпали, то значит там
выдаем какой-то ответ.
Вот.
Это чего?
Нет, ну, смотрите.
Ну, первый разряд проблемы. Берем эти два числа,
делим их на, там, 2 в 60,
там, скажем, на 2 в 63.
Ну, вот.
Видимо, с этой целью обычно вот эти операции
все-таки, битые операции, все-таки
за вот единицы делаются.
А, или даже, нет, зачем вы их просто там делаете
вот хресь-хресь, там, соответственно,
63, ну или сколько у вас там битности.
Вот. И после этого
вот, и сравниваете.
То есть, если они не равны, то у кого там
больше, кто-то меньше.
А если они равны,
то тогда вы уже с чистой совестью
вычитаете одного из другого и смотрите,
какой знак получился.
А очень просто.
Смотрите, предположим, что у вас,
ну, давайте для простоты скажем, что у вас
числа от 0 до 2 в 63-1, да?
То есть, старше бит нулевой, да?
Так вот, идея, давайте,
вот, там, сравниваем х и у. Давайте
учитываем число игр к минус х.
Если игр больше либо равен х,
то тогда у этой разности старший
разряд тоже будет нулевой.
А если игр меньше х,
то старший разряд будет железной единицей.
И все.
А нельзя просто поделись первым и вторым?
А если х, ну,
а если кто-то второй ноль?
Ну, это можно уже разобрать.
Ну, откровенно говоря, да,
тоже можно развлечься, да.
На самом деле, что если
мы из меньшего читаем больше
и у обоих этих часов
старше разряды 0,
то мы получим то, что старше
разрядом единицей.
Ну, так переполнение же будет.
Да, переполнение. Ну, то есть, смотри, вот,
если пусть у тебя, там, ты из пятерки
вычитаешь семерку, условно, да?
Тогда ты из пятерки вычитаешь семерку.
Это значит, давай, вообразим все,
что вычитаешь семь раз по единичке.
На пятом вычитании у тебя появился нолик.
На шестом вычитании у тебя появились все единички.
И дальше у тебя еще одно вычитание.
Вот. Но старший разряд остался
единичкой, очевидно.
И, как бы, если ты после этого
будешь вычитать не более чем 2 в 63,
то этот старший разряд у тебя никуда не денется.
Ну, он, как бы,
так вот.
Так вот. Значит, это вот такая
вот модель, значит, в ней мы
примерно живем. То есть,
как бы, этим иногда пользуется. То есть,
на самом деле, благодаря вот такой модели
на самом деле в науке
есть просто целое направление
алгоритмов,
в котором есть W-битные
числа.
В котором
мы говорим, что мы работаем с W-битными
числами, и у нас
получается, ну, то есть,
на самом деле мы даже проще иногда
себе воображаем, что на самом деле
представь себе, что мы, как бы, программируем
на обычных плюсах
на чем угодно, но при этом
у нас мы за O от единицы
умеем работать только с числами
размера W.
Понимаете, да?
То есть, если хотите работать
с большими числами, ну, вас
приветствует длинная рифметика.
И тогда, вот, и на самом деле
получается такое целое направление
алгоритмов, в которых W на самом деле
становится тоже параметром асимптотики.
Ну, вот, например,
если мы хотим отсортировать
N W-битных чисел,
ну, и подразумеваем, конечно,
во всех таких случаях часто подразумевается,
что N, типа, ну, меньше, чем 2
в степени W, ну, как минимум, для того, чтобы
число N хотя бы
можно было с ним работать, да?
Спрашивается,
за какую асимптотику мы могли бы их отсортировать?
Да, совершенно верно.
То есть, это...
Наша сортировка, вот это вот,
наш RadixSort, по идее, это делает за
N W.
Вот, понимаете, да?
Ну, это если так,
соответственно, в тупую.
Вот. То есть, можно попытаться
это сделать за...
Ну, с более продвинуто можно это попытаться
сделать за O от N там W поделить
на лог N.
Но если брать все-таки
то есть, разряд не 0,1,
а все-таки, там, энергичную
систему счисления, да?
Кстати, а вот
в той рычной системе счисления
мы же на одном слое,
у нас уже не только 0 и 1,
мы будем брать
рандомный элемент?
Не-не, мы там QuickSort'ом это делать не будем,
то есть, QuickSort работал только если
именно в бинарном случае, все.
В других случаях придется страдать.
А в других случаях мы можем сделать
Нет, в других случаях мы будем честно
там это считать, сколько там у вас
ноликов, единичек, двоих, десяток и так далее.
Тогда может быть такое, что мы
придем к какому-то отрезку, а
основание системы счисления оно будет
больше длины этого отрезка.
Основание системы счисления?
Чего?
Ну, у нас R, от рычности
у нас R будет больше, чем
длина отрезка, на котором мы работаем.
И так сортировать невыгодно?
Ну, возможно, да.
Но да, поэтому это как бы не лучшая стратегия
сортировки, в принципе, да.
Так, а как тогда
сделать так, чтобы все это
работало за n log log n?
Нет, потому что, ну это другая сортировка.
Нет, n log log n это какой-то очень
сложный алгоритм.
Да, сейчас,
ой, там на чем у нас
новым я вам даже не скажу.
Нет, ну погодите, давайте, так, давайте постепение.
Так, давайте двигаться постепение.
Ну, во-первых, да, вот этот алгоритм
на самом деле, это мы уже обсудили.
Ну, потому что w,
на самом деле, вместо w можно сказать,
что давайте скажем, что там
2w равно, ну, допустим,
там, какое-нибудь u большое, красивое, да.
И тогда этот алгоритм будет работать
за o от n
log u делить
на log n.
Понятно, да?
Вот, то есть, в принципе, вот, ну, разные
обозначения, видите?
Ну, вот, ну, на самом деле,
пользуясь знанием, что мы сортируем
именно w-битные числа,
можно пытаться
сортировать еще быстрее.
Каким образом?
Ну, давай сейчас я вот как раз
расскажу алгоритм, который просто
создан именно под эту модель.
Но тут чит.
Он явно
будет пользоваться тем, что у нас тут память
бесконечная.
Да, сейчас шедевр будет,
смотрите.
Давайте, смотрите.
Значит, чит такой,
ну, я сразу ставку скажу,
ну, ладно, n log n там w
какой-то делить, так вот, вместо
этого, так, ну, давайте.
Ну, ладно.
Так, ладно, это еще стирать можно?
Так, ну, ладно, давайте
я вот это вот постираю.
Думаю, вот это вот стирать можно.
Но пока скажу ставку.
Значит, сейчас хочется
рассмотреть сортировку,
которая будет сортировать w-битные числа
за o от n
на log w.
Ну, или, соответственно,
o от n там понятно,
ну,
вот.
У, это, типа, максимальное
число, да?
Что такое?
Вот. Соответственно.
Так вот. Значит, это у нас
n log w.
И получается, примерно,
ну, вот, и дальше происходит,
значит, как мы это будем делать?
Значит, внимание.
Такой чит, значит, предлагается
делать следующее. Так, ну, ладно,
давайте, как, так, этот алгоритм мы,
пожалуй, уби, это, нет, входную ленту
я зря убрал, но вот это,
так, это вот мы все убираем.
Так, это мы все убираем, и тут сколько
всего. Красота какая была.
Ой.
Вот.
А теперь, смотрите.
Значит, ну, теперь, вот, веселое,
значит, сейчас будет шедевр,
значит, смотрите.
Работает, значит, теперь происходит
такое. Значит, у нас,
смотрите, представим себе,
значит, внимание,
предположим, что у нас есть
W-битные числа, да?
Вот N W-битных чисел.
Вот, W-битных, N штук.
Так вот, значит,
идея такая.
Сейчас мы делаем что-то типа
вот этого вот МСД,
но неожиданно жестко.
Значит, смотрите, мы
поделим каждое
число
на две части.
По W пополам бит.
Вот, понятно, да?
А теперь идея такая,
мысленно,
мысленно.
Значит, смотрите,
для каждого из чисел
от нуля до 2 в степени
W пополам минус 1,
я сказал мысленно,
в реальности форик, конечно, такой
бегать не будет, боже упаси.
Мы создадим
список чисел
с таким началом.
Понятно, да?
Нет, я же говорю,
фориком мы реально бегать не будем.
Потому что по факту, да?
По факту это будет
работать так.
Мы каким-то образом,
мы там условно,
значит, мы условно
заведем,
ну, во-первых, да, можно даже не булив
массив, а просто,
ну, во-первых, смотрите, первая задача, давайте
для каждого числа от нуля
для каждого от этих чисел посчитаем,
а сколько у нас чисел с таким началом, да?
Ну, как это сделать?
Ну, заведем массив такого размера,
занулим его, потом пробежимся
по инкриментам, правда?
Да,
но очень хочется, конечно, делать это не за такую
симпатику, но теперь замечаем, что нам
на самом деле понадобится только значение
с вот этими индексами, а если индекс
не встречается, он нам и не нужен, правда?
Поэтому,
смотрите, поэтому единственное, что мы
делаем за от вот столько, это зануление.
Мы регистры,
мы за такую симпатику не создаем, они нам и так
уже даны.
Поэтому работает
это так, пробегаемся
за ОАТН и во все ячейки
с вот такими номерами
записываем ноль.
Да, номера ячейок может
быть очень большими, но ничего страшного.
Для каждого
вот этого, для каждого
числа пытаемся понять, сколько у нас существует
чисел, которые начинаются вот с
этого.
Да, только у нас
как бы это не хэштаблица, а
что-то честное.
Да, то есть в реальном коде, конечно, это будет
хэштаблица, да.
Да, по сути, да, это будет
хэштаблица, где для каждого потенциального
начала мы храним, собственно, сколько
чисел с него начинаются.
А в будущем, на самом деле, да, реально мы строим
хэшмап, там в котором
по каждому числу хранится просто вектор
соответствующих вторых половинок.
Но прикольно, что в этой
модели, ну понятно, что такое хэш?
Хэш это плохо, да?
Почему? Потому что хэш это
какая-то полувероятостая
полу...
Да, я там
полувероятостая, полу...
называется верооптимистическая
гадость.
Ну что-то такое.
Вот,
соответственно, если мы не верим
хэши, честно скажу, в какой-то момент
нам придется в них поверить.
Ну вот, ну когда-нибудь, наверное,
в третьем семестре мы даже с ними
поработаем, потому что
вероятности, да?
Ну вот, но здесь
так нельзя, но если у нас
бесконечная память, то есть идея такая,
вместо хэш таблицы мы говорим, что давайте
вообразим себе, что у нас есть
вот такой массив, ну то есть для себя
выделим какие-нибудь там
сколько-то подряд идущих ячеек, да?
И говорим, что пользовать реально из них мы будем
только те, которые вот тут встречаются.
Поэтому мы можем сначала пробежаться
и присвоить всем вот этим ячейкам
нолики, правда?
А потом пробежаться еще раз и, соответственно,
все инкриментить, правда? То есть количество точно
посчитать.
Ну а теперь, а после этого
ну вот,
ну после этого
там, соответственно, останется вам
только каким-то образом для каждого
из этих чисел где-то завести, соответственно,
массивчик, куда
эти элементы записать?
Вот я об этом и говорю, что она делает.
Я все дикие рассказы.
То есть по факту делает она следующее.
То есть она, значит, берет все эти
вторые половинки, которые вообще встречаются
и вот
W пополам старших, да?
Вот. И для
каждой встречающейся второй половинки
мы тут храним
такой
мы храним списочек.
Да.
Пум-пум-пум, да,
вторые половинки. Это тут все
W пополам младшие.
Да.
Но не для всех,
а только для тех, которые реально встречаются.
Как храним список?
Ну, можно, например, хранить так.
Смотрите.
Ну, во-первых, мы для каждого
для каждой
старших W пополам
уже научились считать сколько таких
чисел, правда?
Да.
Ну, теперь идея такая. А давайте
пробежимся по ним еще раз, прям вот в
этом же порядке, и для каждой половинки
говорим, а давайте создадим
для нее и запишем там где-нибудь рядом
собственно, где будет соответствующий массив
для нее.
Причем будем еще помечать,
осознан уже этот массив или нет.
Вот, приблизительно идея
будет такая.
Совершенно
верно.
Совершенно верно.
Да.
Нет, ни левые не отсортированы,
ни правые не отсортированы.
То есть мы их группируем.
Но самое интересное, что эти группы тоже у нас
расположены в экзотическом порядке
каком-то. И внутри каждой группы
все элементы тоже расположены в экзотическом
порядке.
А то.
Ну, я бы не назвал это, я бы
сказал это, это больше на список
смежности похоже, если честно.
По каждому, по каждой старшей половинке
выдается список всех младших.
Вот.
Ну, а теперь идея такая. Во-первых, мы
теперь, ну, заодно
мы создаем список всех старших
половинок без дубликатов.
Сортируем его.
Вот, допустим, у нас тут
допустим, тут у нас
их количество оказалось кол.
Да.
А здесь у нас, соответственно, длины
списков L1, L2,
или так далее, где-нибудь будет L кол.
Ну, L с индексом кол.
Количество списков.
Нет, количество списков это кол.
Это длина
списка номер кол.
Ну, L1 длина списка с номером 1.
L2 длина списка с номером 2.
L кол длина списка с номером кол.
В смысле?
Потому что мы должны каждый из этих
списков отсортировать.
Нет.
Вообще нет.
Нет.
Не-не-не-не. Ну, то есть там,
ну, хотя что-то похожее, наверное, есть,
но в данном случае мы дерево не строим,
а просто запускаем
рекурсивные сортировки.
То есть мы рекурсивно сортируем каждый
список из этих.
И также рекурсивно сортируем
вот эти все штуки.
Понятно, да?
Ну, и после того, как вы отсортировали
старшие половинки, для каждой старшей
отсортировали все младшие, ну, записать
теперь правильный ответ вам уже труда не составляет.
Ну, типа у нас, то есть
до список из N элементов
длины В, теперь у нас
N плюс один элемент длины В пополам.
Нет, почему N плюс один?
Их тут все еще не более чем N, но точнее
их кол.
Нет, в смысле у нас левая половина
один список, который нам надо отсортировать,
и правых половинок у нас N штук.
Нет, их не N штук, их кол штук.
И это для нас будет важно, потому что чем больше
списков, тем короче сами списки.
Чего?
Ну, мы сначала же подсчитали,
сколько каждого В пополам.
Чего?
Ну, да. Нет, это
была, короче, основная задача была
посчитать, найти вот эти списки.
Все, что мы до этого делали, это просто
описание техники, как это сделать.
То есть ключевая идея
заключалась в том, что мы можем
отправиться в ячейку номер 2 в степени
W пополам. И что-нибудь в ней
хренеть.
На одном левом и на каждом
из правых по отдельности.
Так.
Чего?
Потому что, смотрите,
эти списки суммарно требуют
N памяти.
Ну, понятно, если N совсем
близко прям к W,
там 2 в степени W, то да, могут быть
затыки, это да.
Поэтому давайте для простоты считать, что N
значительно меньше, чем 2 в степени W.
Ну, там 100 хотя бы раз, тысячу
где-то так.
Да, сортируйте, да.
Как говорится, да, у вас размер 2 в степени W,
то есть все редисторы уже забиты
самими элементами, а там еще и подсчеты делай.
Ага, удачи.
Ну, для того, чтобы хотя бы
переменная, ну, чтобы она меньше, чем 2
в степени W, чтобы переменная N влезала
в редистор для начала.
А чтобы значительно меньше,
чтобы у вас не только сам массив влезал,
но еще и с этим массивом там можно было копии создавать,
что-то сделать, у нас еще и рекурсия там напоминаю.
Так, нет, симпточку мы вообще
еще не доказывали.
Не, не волнуйтесь, не волнуйтесь, симпточку
это следующий ход. Пока как бы вопрос в понятии
для алгоритм.
Ну, вроде, да.
Да, ну давайте, ну давайте
поехали. Да, вот, кстати, в вашем
задании там был вопрос, а как считать симпточку
от двух переменных?
Ну, как всегда, мы говорим, что алгоритм
работает, скажем, за от, там, я не знаю,
NW, если
он работает, он выполняет действие
не более, чем C умножить на N умножить на W
для какой-то константы C, да?
А?
У этого есть название?
Да. У этого
есть название Kirch-Patrick sort.
Kirch-Patrick, да.
Это про алгоритм, да?
Про что?
Про алгоритм сортировки?
Да, то есть то, что мы обсуждаем, называется
Kirch-Patrick sort.
Да, то, что вы видите,
называется
да.
Вот. Так вот.
Теперь давайте попробуем показать, что это работает
за N logW.
Ну, давайте
для начала напишем рекурренту. Заметим,
что T от N и W
равно, да?
Чему оно равно?
Ну, T от col
и, соответственно, W пополам
плюс
T от L1
W пополам
плюс T
от L2 W пополам
плюс и так далее
плюс T
от L col L пополам
W, W пополам.
Вот. Ну да.
Col и L1, конечно, могут сильно
зависеть от входных данных, правда?
Но рекуррент примерно такая, да?
Что мы с этим хотим делать?
Мы хотим показать,
что T от N
W меньше либо равно
C
N logW, да?
Очень хочется доказать,
правда?
Ну, давайте думать.
Тогда, если мы... Ну, как?
Как вот чего-чего?
Чего есть еще?
Ах, да, да, да.
Плюс O от N, конечно, да.
Да.
А то ну лично получается, да.
Итак,
C N logW,
господа.
Значит, поехали.
Как мы это будем делать?
Ну, как вы делали? Вот я как бы...
Да, вот, собственно, поэтому я и просил,
чтобы пораньше сделали домашние задания,
чтобы как бы следующие шаги были естественными.
То есть вы же там на спинном мозге,
наверное, пишете, да?
T от N W, да?
Получается, меньше либо равно
получается, да?
C col
и дальше пишем
logW-1,
да? Ну, потому что
logW пополам, это logW-1, да?
Или нет?
Ну,
C logW-1 вообще можно
выяснить, как общему вважить.
Давайте в тупую сейчас напишем это, да?
Плюс...
Господи.
Господи, какие у нас большие головы.
Так.
Так. Господи, где ж
писать-то?
Да.
Эх, вторая доска бы не помешала.
А то что-то стащили у нас
доску называется.
Ой, или правда это завести какую-нибудь
планшетку и писать по телевизору там, я не знаю.
Я не знаю, но...
Ну, это
да, это да.
Но это...
Нет, это, знаете, это просто как
писать.
Нет, знаете, тут...
Ну, тут по-разному, понимаете, да?
Нет, я вот встречал разные системы
на эту тему, знаете, так, если чуть-чуть
выдохнуть, прежде чем как мы сейчас это сделаем.
Там просто у меня был такой,
потому что как-то раз мы давным-давно,
в стародавние времена,
нет, в очень стародавние времена,
как говорится, когда...
Да, как говорится, 13-й год.
Крым еще был не наш.
А мы туда ездили.
На сборы по программированию.
Ну вот.
Так вот, знаете, там вот почему-то вот единственный такой видел,
что там действительно как-то устроено было,
что значит, есть огромный элекционный зал.
И там один из вариантов,
что есть действительно большой экран.
И, собственно, на трибуне там
стоит практически планшет, на котором, собственно,
лектор спокойно рисует.
Вот, собственно, это было очень удобно.
Вот.
То есть как бы дафистер сейчас только
к этому движется в том плане, что у нас есть
хотя бы есть там
где-то там на фисте в элекционных аудиториях
там могут стоять два больших телевизора,
на которых можно рисовать.
Чего?
Почему?
А, ну бывает.
Ну да.
Нет, бывает такое,
что нет. В этом смысле да.
То есть нет. Ну или простая классика.
Говорят, что есть в МГУ, но я ее впервые увидел
там, когда я ездил там в Марсель.
Ну я там был там.
Ну там есть такая штука, как Люмени.
Ну это типа стутгородка Марсельского университета.
Но внутри него что-то там базируется
французская там, собственно, штат
квартиры французского матца общества.
Вот.
Так вот, в основном зале у них на самом деле все просто.
Там обычные меловые доски.
Но при этом аудитория большая,
а вот эти доски три, вы там с помощью кнопочки их
отправляете в небеса.
Прям вот буквально.
То есть я вот представьте, я вот это вот отправил на высоту
как минимум вот этого экрана, а то и выше.
А, ну и себя вы представьте,
что вы вот не так сидите, а вот хотя бы вот
кто был вчера на тренировке, вот хотя бы такой зал.
Да.
Так вот.
Так вот, смотрите.
Итак, ладно. Это было так, это
мое лирическое отступление на тему досок.
Там, да, вот.
Значит, теперь смотрите.
Внимание.
Ладно. Значит, смотрите.
Дальше.
Значит, теперь пишем так.
Значит, T от NW, да.
Меньше либо равно C кол
на лог W
минус один.
Плюс CL1
на лог W
минус один. Плюс
CL2
значит
лог W минус один.
Плюс и так далее. Плюс
C кол. Значит,
от, тьфу, не кол, а L кол,
конечно.
Лог W минус один. И плюс
еще AN, да.
Это равно
фактически, значит,
это C лог
W и умножить это на,
ну получается кол
плюс N получается, правда?
Ну, если я просумирую сельки,
получится N.
То есть, минус
что?
Ну вот. То есть, минус
C
на кол
плюс N
плюс AN.
И теперь получается
это должно быть
должно быть меньше
равно, чем
CN лог W.
А что
нехорошо?
Ну, заметим,
что
ну...
Ну, в общем-то, ничего страшного
в этом нет. То есть, видите, на самом деле,
вот этот C, как бы, особо лишний кол здесь погоды не делает.
Да.
Но у нас, составная проблема, есть
лишне слагаемый C лог W кол,
где кол вообще-то не вот единицы.
Он может быть там вплоть до N.
Вот.
Вот такая мелкая проблема.
Что делать?
Что произошло? У нас взялся лишний кол
в C лог W.
Ну, мы, честно, вот это просуммировали.
Вот.
Кол взялся из первослагаемого.
Да.
Да.
И видим, что что-то доказательства
не сходятся.
Да.
Да.
Да.
Да.
Да.
Да.
Да.
Да.
Да.
Да.
Да.
Да.
Вот как бы, C лог W-то есть.
Но надо чем-то убить
D кол лог W.
И к чему убивать?
У нас тут слагаемых нет для того, чтобы убить.
Давайте добавим.
Ну, в смысле, отнимем с левой и с правой части что-нибудь.
А что?
Ну, что-нибудь, видимо, зависище
от N, например.
Ну, как сказать, можно попытаться
убить, например, D лог W?
Ну, это не...
Ну, тогда... Чего-чего?
Это
D лог W?
Ну, да.
Нет, просто D лог W, конечно,
можно вычесть.
Но просто там прибавляется куча
вот этих дешек, и этот кол все равно
останется.
А, ну хотя...
С левой у нас вычтется
что-то очень много раз.
А так что, а реально, если вычесть
D лог W,
то тогда у нас получится кол слагаемых
с D лог W,
и как-то нам прямо приятно станет.
Ну, хотя, как сказать, если у нас D умножить
на кол, наверное, вот этим вот можно
попытаться убить, конечно.
Но, правда, при этом
нам-то требуется, чтобы, да, там, если...
У нас вообще вот по всем этим...
Ну, короче, у нас же
понявится по всем
слагаемым D вот
что-то там W пополам,
у нас же понявится, в итоге,
минус D пол плюс один.
Так, ну давайте, так, давайте
просто проверим эксперимент.
D лог W.
Да?
Так.
Так.
Сейчас давайте.
Рисуем. D от NW.
Меньше либо равно. Значит,
что у нас там получается?
C кол
на лог...
С кол
на лог W минус один.
Минус D
на лог W минус один.
Плюс, давайте я сразу в виде суммы буду
писать. И равно один кол.
Что там будет получаться?
C умножить
на кол.
Ах, да-да-да.
C на лит
на лог W
минус один.
Минус D лог W, да?
Да.
Так, отлично.
И плюс АН, конечно.
Так, что это равно?
Так.
Лог W.
Д лог W.
Да.
Так, ну давайте, смотрите.
Схлопываем то, что было раньше, да?
C на кол плюс
кол плюс N на
лог W, да?
Минус C на кол
плюс N.
Так, что там дальше?
И теперь с дэшками.
Так.
Минус D на
лог W минус один
умножить на, внимание, еще
кол плюс один.
И все это меньше или равно?
А, нет, хуже.
Нет, у нас кое-что еще есть.
И плюс АН.
И это все еще должно быть
меньше либо равно, чем C
лог W.
Минус
D лог W.
Где?
Где?
Минус D лог W.
Потому что правая часть не равен.
Ах, да, да, да.
Ой, у нас еще и D лог W должен
выжить.
Как сложно.
Нет, ну ладно, это не принцип...
Так.
Ну то есть слева оставить...
Ну да.
Так, давайте так.
Что там надо?
Нет, ну давайте смотреть.
Если C лог W убить, у нас тут останется
D кол на лог W.
Минус C на кол плюс N.
Так, смотрите.
Минус D кол лог W.
Почему не кол плюс один?
Потому что мы с этим убиваем.
Кол на лог W.
И плюс, внезапно,
D на кол
плюс один.
Плюс АН.
И это меньше либо равно нуля.
Ну, что-то похоже.
С этим же лучше уже.
С этим что-то можно делать.
Мг.
Так.
Так.
Нет.
Нет, ну извините, ниже не могу.
Так.
Так, ну теперь смотрите.
Теперь для того, чтобы желательно убить
кол лог W, наверно, нужно, чтобы D
было больше либо равно C, да?
Ну, вот.
Ну, с другой стороны,
для того, так как у нас
тут D на кол, то, наверно, есть
подозрение, что...
Ну, что тут можно сделать?
Кол может быть вплоть до N.
Да, правильно.
Поэтому, вот видите, тут C кол лог W.
Тут минус D.
Да.
А теперь вот этот C кол
плюс N должно убить вот этот D
на кол плюс один и АН.
Да, но только для того,
чтобы, например, C кол убил
D кол, нужно, наоборот, чтобы C
было больше либо равно.
Да, но нам еще
АН надо убить, помните, да?
Ну, у нас же D,
напоминаю, больше либо равно C,
мы это уже выяснили.
Так.
Не, ну, как я...
Ну, вот.
Сейчас C на два кол?
Сейчас где?
Ну, вот.
Ну, вот.
Да, тут на кол плюс N.
Поэтому давайте заменим
там, не знаю, на два кол.
То есть увеличим практически.
Ну, в смысле N заменим на кол.
А АН вы чем убивать будете?
Еще константу вычтем.
Кол может оказаться
и меньше N.
В логариф МН раз, например.
Да, но мы же не умеем
убивать на кол.
Ну, вот.
Ну, вот.
В логарифу МН раз, например.
Да, но мы же вычитаем.
Ну, давайте вот прицежки заменим N на кол.
То есть у нас будет минус C на два кол.
Если у нас после этого АН
остается лишнее, ну, давайте кроме
D, O, D вычтем еще константу E
и у нас все сойдется.
Ой, Господи.
Я вам так домашку сдавал.
Ага, только она еще не проверена, да?
Ну, да, разумеется.
Ага. Может там и бага окажется?
Там нет бага.
Нет, пока вот как-то сюда
что-то, ну, вот.
Что-то как-то надо...
Да, по идее надо как-то желать и...
Если все очень плохо,
взять еще минус E просто добавить.
Минус E?
Да.
Так я же об этом говорю.
Еще константу вычтите все этим.
У нас АН сократится.
У нас АН никогда не сократится.
А че?
Нет, а че?
Нет, а...
А что это E даст?
А, окей, да. Действительно же.
Чего?
Если D равно C, при C равно D
все работает прекрасно.
У нас окажется типа
минус CН плюс АН.
Ну, смотрите, нет.
Нет, конкретно сейчас, если C равно D
еще и равно А...
Нет.
Просто C равно D,
у нас не достанется
минус CН плюс АН.
Ну, возьмем там типа
C равное D
и сильно больше, чем А, и все хорошо.
Ага, ну да.
А если W там совсем мелкая константа,
то можно и за линию отсортировать.
А, то есть типа и так...
То есть типа утверждается, что такой алгоритм не работает?
То есть такой алгоритм тоже работает?
Просто автор в это не верит.
Ну...
Нет, почему?
Нет, просто
скажем так, автор, видимо, столкнулся с этой
проблемой,
поэтому порешал он ее принципиально
другим способом.
Нет, ну я
не знаю, вообще, конечно, да.
Нет, пока похоже, что в таком
виде вроде
тьфу-тьфу-тьфу тоже работает.
Особенно если там...
Да.
Особенно если N это от единицы,
то мы там тоже сортируем за O от единицы.
Ну или если там W
оказалась совсем уже один,
то, наверное, мы за линию
как-нибудь отсортируем эти все элементы
из одного бита.
Нет, там просто...
Нет, автор в этом месте сказал другое.
Что нам не нравится?
Нам не нравится то, что у нас в 8-м точке
кол, потому что если бы вот этого хотя бы
кола не было, то мы победили сразу, правда?
Ну, конечно.
Так вот, что сделать, чтобы
кола не было?
Так вот, он сделал так.
Ну так давайте просто
сделаем так, чтобы в каждом
массиве сортировать на один элемент
меньше.
Вот, то есть он
предлагает, что давайте в 8-м точке
запишем вот так.
Догадываетесь каким образом?
Ну один раз за линию пройдемся.
Да, совершенно верно.
Прежде чем запускаться рекурсивно, например,
в этом списке найдем максимальный элемент.
Если запускать рекурсивно, будем только
после этого.
Нет, реально, это в статье написано,
на полу, серьезно, да.
Все в порядке.
Да, и тогда вот в таком алгоритме
получается хорошо.
Нет, это не то же самое.
Одно дело анализ, нет, он реально
этого алгоритма предлагает делать.
Нет, если что, это то же самое, что
сказали мы с Дэшкой, потому что
фактически у нас
ну да.
О господи, вы за лог W
ищете максимум.
Ну как-то вот да, тут
хорошее же, да.
Но,
ну реально, в статье
написано реально, давайте перед
рекурсивным запуском найдем максимум,
тогда точно красиво будет.
Правда, сейчас скажу, таких рекуррент
он, конечно, не расписывал,
но, видимо, там как-то вот
видимо,
по крайней мере в его сообществе
и после этого интуитивно все сходилось,
а до этого как-то были вопросы.
А, ну то есть
логика такая, да, что мы
переходим на уровень W пополам
и там сортируем массивы суммарного
размера ОАТН, да, то есть получается, что
уровни у нас лог W и на каждом
хочется работать за ОАТН суммарно.
ОАТН, а не за ОАТН плюс
что-то там.
Ну, как бы, потому что мерч сорты
в общем-то тоже, наверное, вы ж
в 7 классе не через рекурренты
доказывали, правда?
В 7 классе доказывал мерч сорт,
поднимите руку.
Да, кстати.
Я в 6 классе доказываю, не буду.
Понятно, ну бывает, да.
Ну ладно.
Денис, ты мне конкуренция.
Так, ну ладно,
это условно.
Ладно, кто-то в 7, кто-то в 9,
ну вот.
Ты вообще в школе ничего не доказывал.
Ну да.
Чего? Значит, статья
говорят следующие.
Для каждого из этих массивов,
прежде чем запускаться рекурсивно,
пробежимся
за линию, найдем максимум,
запишем его в конец, и сортировать
рекурсивно будем все остальное.
Чисто для того, чтобы в
рекурсию мы тут, ну чтобы
в рекурсию было вот здесь запущено
не L1, а L1-1.
И тут L2-1,
и тут Lcol-1.
А, вот эта пробежка, она у нас
в ОАТН, получается, идет.
Нет, тогда получается, смотрите,
просто вот этот кол убился,
то есть этого кола
уже в принципе нет.
А, ну вот,
а тогда вот эта АН прекрасно
убивается вот этой С.
А, кстати,
второго кола тоже нет, но
это тоже уже не принципиально.
Да, СН убивает
АН, просто С
больше либо равно А и все.
Да,
да, то есть просто вот,
да, то есть просто не
заморачиваемся.
Да.
Так что это,
так что это первая такая
наша сортировка, когда можно сортировать
за Nlog-logU.
Конечно, если мы поверим в
существование дерева в андебоаса,
это что?
А, дойдем.
Я, правда,
уже не гарантирую, что в этом семестре.
А можно просто поверить в unordered map?
Как unordered map?
А, ну если мы захотим это реально
написать, то да.
Ну тогда в таких вещах
да, придется там верить, либо в
unordered map, либо там в какие-то еще структуры.
Да.
Чего? Кто?
Сортировка?
Нет, ну реально да, как бы подобного
рода алгоритма они сугубо теоретически.
Да.
Хотя не знаю, может там
в семьдесят каком-то году, может это и работало,
не знаю.
Ой, надо будет, надо будет
хоть вспомнить где-то статья вообще там.
Потому что я помню, только что там есть вот фамилия,
там кирпатрика, есть еще вот такая
фамилия.
Да.
Ну вот.
Да, но там
вот.
Ну и там соответственно было какое-то издевательство.
Так.
Так, ну что, еще какие-нибудь?
Так, ладно, по вот этому
еще вопросы есть?
Нет.
Рукописи не горят.
Особенно опубликованные в интернете.
Ну и потом, ну что, ну если
весело, в конце концов зачем
это все нужно, чтобы было весело?
Ну как бы глобально,
ну что такое весело?
Потому что одно из интерпретаций слова весело, помимо
каких-то этих там практических
мистических,
то есть это чтобы еще вот интересно было, да?
Ну как сказать?
Ой, упоролся.
Ну да.
Так, ладно.
Так, ладно,
вроде как про сортировки,
так, сейчас я просто прикидываю,
про сортировки все рассказал?
Или какие-то...
А, ой, не-не-не-не,
не все, нет.
Боже упаси,
нет, придется так, что снова включаем телевизор.
Чего?
Так, ладно, слушай.
Так.
Как это называется?
Да, видимо это метод
как алгоритм отжига.
Как говорится, некоторое время
после того, как вы изучили алгоритм,
очень хочется постоянно употреблять свои речи
его названия.
Не до сих пор.
Не до сих пор.
Не до сих пор.
Не до сих пор больше.
Ну, конечно.
Так, телевизор, включайся.
Телевизор.
Я сказал...
А, окей.
Да, потому что
на самом деле, ну, как сказать,
с сортировками у нас сейчас связано
на самом деле осталось два объекта.
Во-первых, ну, скажем так,
один сложный, достаточно сложный алгоритм,
который мы вот сейчас тут за
оставшиеся там 15 минут
явно не покроем.
Это алгоритм, собственно, как слить
два сортированных массива
от единицы дополнительной памяти.
Да, согласен, полностью.
Ну, философский вопрос
что сложнее, если честно.
Тут уже кому как удобнее мыслить.
Подождите, а зачем вам сортировок
за n вовтолгань фортериала?
Нет, это не фортериал,
это радость.
А, ну, это, ну, когда
если вы сортировали прямо по разряду,
то есть там, как бы, оставаясь в системе
с линией 2, то как бы это работает
за вот количество разрядов на n.
Да, а как это в рычной системе сделать
фортериал?
Рычная система – это r разрядов.
R по факту – это log2n.
Log2n максимальных чисел.
Где написано?
А это уже не binary.
Тут не точно написано, тут уже не
binary quicksort имеется в виду.
Хотя...
Не-не-не, ну просто не binary.
Ну, то есть там...
Чего еще раз?
Ну да, ну, смотрите, давайте,
пусть у нас там...
Ну вот, так вот, да,
действительно...
О господи, так, странные тут
буковки, конечно.
Ну, не важно, ладно,
тут, видимо...
Нет, ну, очень ладно, на самом деле,
да, тут как бы немножко не отсюда фраза,
в общем-то, мы это уже когда-то обсуждали,
вот такую симпатику мы уже получали,
потому что r – это, помните, логарифом
по основанию base, да?
Возможно, сортировка за от
log2n.
Вот, а я вот, собственно,
да, я, собственно, этого
вот этого все безобразия к чему рисовал.
Молодец.
Да.
Так вот, я, собственно, это к чему...
Так вот, на самом деле, вот это утверждение в формале звучит так,
смотрите, потому что действительно задается вопрос,
а за какое время можно отсортировать
nw-битных чисел?
Ну, при n там достаточно
там чуть меньше, чем 2 в степени w,
желательно, ничуть.
Так вот, ну, на самом деле там
начинаются алгоритмы, где все-таки
это делается уже независимо от w.
Лучший, по крайней мере, мне известный,
он датируется 2015 годом.
И говорят, что там алгоритм
в данной статье мы опишем,
как это делать за n log log n.
Подождите, за сколько они умеют сравнивать числа?
За да?
Нет, в смысле, та же модель,
та же самая модель с регистрами.
Как бы числа сравниваются,
ну, как мы уже с вами убедились,
любые два числа сравниваются за 1.
Да, мы уже обсуждали,
как примерно это сделать.
Даже на том убогом базисе,
который у нас есть.
А понятно, что в науке, наверное,
явно можно этот базис спокойно расширить,
заявляя, что каждый из этих действий делается
как процедура за 1.
Но там это еще круче,
потому что написано, делаем за n log log n.
Этот алгоритм является
оптимизацией нашего
предыдущего алгоритма,
который работает за n log log n
log log log n.
Вот.
Нет, напоминаю,
мы сортируем w-битные числа
в w-битных регистрах.
Как мы уже выяснили, сортировать камешки
в модели сравнений
мы быстрее, чем за n log m, все еще не можем.
Но мы сортируем не камешки,
мы сортируем конкретное w-битные числа.
Может w-боже.
Ну да,
по сути, да.
Значит, мораль.
Если у вас есть
доступ к бесконечного размера
регистрам, то да,
вы умеете сортировать целые числа
за n log log m.
Но вы знаете, что это целые числа,
а не что-то там это ваше.
Да. Совершенно верно.
Именно так и работает.
Пусто?
Ага.
Да.
Как орбит сучный регистр, да-да-да.
Киктор.
Вот эту?
Так, ребят, у нас останется когда-нибудь...
Нет, когда-нибудь, во-первых,
если у нас останется где-нибудь в конце
время, и у меня останется время
на то, чтобы сесть и там попробовать
как-то заботать, тогда, может быть,
обсудим.
А если хорошо, да, может быть, если хорошо
обсудим, тогда вы это будете рассказывать
на экзамене.
Ага, по вот этим?
Ага.
Да нет, сдадите все,
потому что на самом деле, да,
вряд ли будут задачи, в которых будут тесты,
на которых надо это реально писать.
Так, стоп!
Так, давайте вспомним на тему того,
что у некоторых из вас это последняя пара.
Что?
У кого?
Ну, сегодня я имею в виду,
а не вообще.
Это не правильное расписание,
ни у кого оно не последнее.
Последняя ваша пара?
Нет, моя следующая тоже
через неделю будет.
Сегодня?
Нет, тогда все равно, тут два варианта,
либо у вас это последняя пара, и тогда сейчас раньше
начнем блок, раньше закончим,
либо у вас это не последняя пара,
и тогда значит у нас ограниченное время.
Все, значит у нас ограниченное время.
А нам нужно поговорить
еще об одной жизненной
задачи.
Прямо жизненной, смотрите.
Потому что, смотрите, в реальной жизни
есть такое понятие, как
оперативная память, правда?
Ну, обычно
когда вы там пишете
какие-нибудь олимпиады,
вы в этой оперативной памяти живете.
Ну и рам-модель тоже
олицетворяет, как будто у вас все в оперативной памяти лежит.
Но
реальность устроена буквально
чуть-чуть сложнее очень сильно.
Вот.
А именно, что есть
оперативная память, в которой можно работать,
но данные находятся где-нибудь
вовне, как минимум, потому что данных больше,
чем у вас оперативная память.
Вы имеете право
оттуда выгружать.
Ну, допустим, сейчас самый простой вариант
это, допустим, у вас там данные лежат
на каком-нибудь жестком диске.
Может там на харде каком-нибудь, я не знаю,
который вы там по USB подключили.
Ну, например, да.
То есть, где-нибудь
вот оно лежит.
Там далеко-далеко.
Поэтому проблема основная даже
то есть вы можете их подгружать
и сохранять, но проблема, во-первых,
но проблема в том, что
их можно подгружать только частями.
Вот такая задача.
То есть одновременно вы можете
подгружать и работать только с каким-то
ограниченным количеством данных.
А диск у нас рандом аксесс или нет?
Что?
О, хороший вопрос.
Тут называется
ответ не так просто, как кажется.
С одной стороны,
он, конечно,
рандом аксесс.
И казалось бы, да, то есть формально
с точки зрения NLogN, собственно, не заморачиваемся.
Ничего не поменялось.
Но важный практически нюанс.
Произвольный доступ к абсолютно
рандомному месту этой памяти
будет, например,
то есть будет, например,
тратить вон несколько миллисекунд.
Но устроен он
будет так, что на самом деле, если вы хотите
несколько последовательных ячеек,
то он-то может вам зато последовательных ячеек
вон грузить вон
10 мегабайт в секунду.
Это, кстати, больше, чем он
фактически может быть. Там, наверное, можно
на 3 дни в этом станке.
Ну, там, говорят, да.
Понятно, что не всегда, но как бы бывает.
Если же будет жесткий диск, то можно
на 3 дни в этом станке.
Ну, знаете, диски бывают
разные.
Черные, белые.
Ну, еще
а, ну, потому что в реальности, как бы
на самом деле... Смотрите, давайте я тут тоже картинку
порисую. Смотрите, тут
можно себе этого образить еще
вот как, смотрите.
Вот так вот. Знаете, смотрите.
Так, где?
Так.
Так, что?
Куда делась тряпочка?
А, вот она.
Вот она.
Значит, смотрите, так, убираем
этого вот
безобразия.
Ой,
Господи.
А вы производно уже
проходите?
Нет.
А.
Окей.
Ну ладно.
Илья Дубрович, скажите, пожалуйста, а потом скиньте
всю эту презентацию. А, как же?
Она еще нигде не лежит.
Ну, сейчас
она пока нигде не лежит.
Ну, вообще, да.
А после этого занятия скиньте?
Ой, ну можно, наверное,
и после этого. Это последний блок ассортировок,
как там дальше кучи идут.
Хотя, да, могу скинуть и с кучами
в качестве анонса того, что будет, да.
Ладно.
Так, значит, смотрите.
Просто реально, на самом деле, если
смотреть на этот диск немножко с боку
и убрать эти стенки,
то увидится
примерно следующее.
Вот.
Не, ну,
вот.
Ну, как сказать, это не Ханой Скайбашем,
что все диски одинакового размера, скорее всего.
Вот.
И они крутятся.
Очень-очень-очень быстро.
Вот.
И тут на них вот есть какие-то вот эти вот дорожки,
которые по факту ячейками памяти являются.
Вот.
Вот, они крутятся.
И тут какая-то есть вот головка,
которая вот может смотреть на какой-нибудь дисочек.
Не, не только. Она может тут перемещаться
и смотреть на любой. Ну, там вот несколько головок.
То есть несколько дисочков.
Может быть и несколько головок там,
я не знаю, но вот тут по-разному бывает.
Да, то есть может быть так, что там вот
как-то так. Ну, тут...
Это не выдуманный диск?
Ну, плюс-минус не выдуманный.
Да.
А, значит точка, она не только сверху играет,
а на самом деле... Ну, типа того, да.
Ну, вот.
Поэтому тут говорят количество там,
то есть количество пластин головок, да,
то есть головки тоже соответственно там, да,
на каждый дисочек, видимо, своя головка есть.
Так что, да, он может играть одновременно
до шести или двенадцати мелодий
сразу, да.
Не, ну у меня просто ассоциация, я не знаю,
если кто-нибудь когда-нибудь видел такую вещь, как хромофон.
Ну, вот, то есть вот...
То есть такой хромофон, который играет одновременно
на двенадцати пластинах.
Ну, так.
Да. Так вот, смотрите.
Ну, это была пластинка.
Значит, что тебе... Ну, вот.
Ну, вот, и соответственно он вращается.
Вот видите, когда к нему приходит запрос,
он так устроен так, что...
Действительно, что конкретную ячейку памяти
ему надо еще тут это там, что-то выискивать конкретно,
там перемещаться, тут вот как-то
там на нужную окружность там ловить ее еще.
Вот. Но если вы хотите прям лежащий подряд
ячейки памяти,
то как бы они под ним вращаются,
он их вот замгновенно считывает.
Поэтому оказывается, что последовательный доступ
получается вот именно такой блоковой.
Вот. Вот такой блоковой.
Поэтому, то есть как бы с точки зрения
хотя бы практики имеет смысл
действительно делать так, чтобы мы
как можно реже
действительно делали доступ рандомной
и как можно чаще делали доступ так,
чтобы если уж считываете, то сразу много.
Хорошо.
Мы можем последователь писать несколько файлов.
Например, параллельно
писать несколько файлов, допустим.
То есть по одному можно писать
на высшем пластинке?
Ну,
но думается, что нежелательно, конечно.
Хотя
теоретически можно,
но практически не уверен, что нам это даже понадобится.
Понимаешь, потом тебе эти элементы
еще придется куда-то записывать.
То есть, во-первых, записывать,
потом еще как-то рекурсивно запускаться,
еще и глубина рекурсии
тут вот такая будет, знаешь,
хорошая.
Ну, условно допустим, да.
В современным меркам не очень, конечно,
но и презентация, в общем-то, тоже.
Ей как бы не 2 и не 3 года,
на самом деле.
Ну, честно скажу, знаете, тут легко видеть.
То есть, на самом деле, какие-то вот, знаете,
есть тут какие-то вот,
более классический такой шрифт.
Он, на самом деле, честно скажу,
он остался еще от моего великого предшественника.
Ну, его зовут Степан Мацкевич.
Может вы сталкивались с таким?
Нет?
Ну, как бы ныне вроде как
сотрудник Яндекс.Текси, там работает
Яндекс.Текси, руководитель группы.
Нет, ну в смысле руководитель группы
разработки, естественно, да.
Ну, вот.
Так вот, дальше, смотрите.
Это было 100 мегабайт, ну вот.
Так вот, идея, соответственно,
примерно такая.
Значит, как это у нас все сходится?
То есть, идея такая.
Значит, ну, во-первых, значит,
с чего начнем? Во-первых, говоришь,
что пусть у нас разделим мысли на наши данные
на блоки по 100 мегабайт.
То есть, мы будем делать
по 100 мегабайт.
То есть, мы будем делать
мысли на наши данные на блоки по 100 мегабайт.
И можно сделать так.
Давайте их по 100 мегабайт, честно,
по очереди считаем.
Каждый там стабильно отсортируем.
Ну, например, там есть любым квиксортом, да.
И загрузим обратно
на диск.
И после этого
у нас есть ка отсортированных блоков.
И возникает идея, что давайте их
отсортируем ка путевым слиянием.
Ну, что такое, ну, как сказать?
Ну, представьте себе, что у вас есть надо слить
не два отсортированных массива а ка.
Вот сегодня, кажется, эта идея уже звучала.
Как мы это делаем?
Да, совершенно верно.
Да, метод ка указателей.
То есть, единственная только проблема
для того, чтобы быстро выбирать минимум ка элементов,
которые вы сравниваете, надо хранить где?
Да, правильно,
в куче.
Да, удобнее, конечно, было бы в сете, но мы не знаем,
что такое красно-черное дерево, поэтому увы.
Чего?
Конечно.
Ну, доступ да, но мы ж там примерно знаем,
где там на диске все лежит.
Ну, в смысле, блоками по 100 мб
и пишем, в чем проблема.
Ну, скажем так,
давайте так, это не один и тот же диск.
Ну, давайте так, давайте считать,
что у нас какие-нибудь там,
то есть, есть,
ну, можно считать так,
давайте будем считать хотя бы,
что у нас есть, допустим,
ну, как минимум один запасной диск есть.
Тогда мы на этот запасной диск вот эти данные
запишем,
вот, а потом
а потом, соответственно, с этого диска
уже капучевое слияние будет записывать
на оригинальный.
Ну, вот, собственно, это был как раз вопрос,
можно ли вы хотя бы пару местами написать?
Ну, да, ну, типа того, да.
В любом случае, мы условно, у нас есть, допустим,
две иглы, мы первой иглой
сохраняем в кучу информацию,
сколько там
подъезжаем в оперативку, потом
второй иглой записываем, а можно
даже с одним диском.
Ну, совсем с одним не очень,
потому что мы же там...
Мы сначала подгружаем в кучу элементов, сколько хватает
на оперативку,
но за этой кучей все достаем элементы.
Нет, ну, просто когда, нет, в один диск
просто вот эта вот часть
не очень понятна, как это делать.
У нас же
последовательные элементы, видите?
Ну, это да, но когда у вас, ну, блокит у вас
после вот второй фазы блоки расположены
нетривиально.
Да, мы сразу из блока подгружаем
кучу элементов, вот такими,
из каждого блока по куче элементов.
Ну, правильно, а записывать ответ куда?
А потом переставляем иглую,
начинаем записывать ответ, где по куче,
пока она не кончается.
Ну, там просто, как бы, вы чуть-чуть
подгрузили из первого блока,
не все 100 мегабайта меньше, да?
А потом при слиянии выяснилось, что у вас
там, там вы дошли до
этого момента, когда то, что вы подгрузили, закончилось,
и тогда вы что, перезаписывать начинаете?
Да.
Ой-ой-ой-ой-ой.
Ну, знаете, давайте без...
Тут давайте смотрите.
Значит, смотрите, как предлагается это делать,
по камере, по умолчанию?
По умолчанию делать предлагается так.
Давайте каждый блок, действительно,
подразбиваем на качастей.
Да, ведь сейчас мы не подразбиваем, что у нас
вообще один диск, что надо чтение и запись
в одно место.
Вот. Но идея, конечно, простая.
То есть, на самом деле, конечно, имеет смысл загрузить
себе в память не по одному элементу
из каждого блока, а, конечно, по там
100 мегабайт поделить на к, конечно.
И потом у нас будет, ну, или чуть меньше,
чтобы осталось там на кучу
размера к еще осталось.
То есть, мы их, честно, загружаем
в оперативную память, результат складываем
в отдельный файл.
А почему на к?
Ну, потому что все равно там около 100 мегабайт будет.
Скорее м, типа, на к, потому что
у нас... Потому что к, как минимум,
потому что у нас к блоков.
Ну, из каждого загружаем на
обучение, у нас получается, типа там, около
м оперативной. У нас получается
к квадрат.
Что, что как квадрат?
К блоков и в каждом еще...
Ну, в каждом...
Ну, да.
Поделим обучение по одной, чтобы
от каждого из к блоков по одной
вот.
Вот.
Ну, то есть, давайте
вот внимательно читать. Каждый момент времени
загружено не более ка частей.
Да?
Объемом каждой 100
мегабайт поделить на к.
Ладно, на самом деле немножко
разъем, потому что каждый блок мы подразбиваем не
на ка частей, а
ну, на какие-то части размера
100 мегабайт поделить на к.
Хотя, да, это все равно ка частей.
Ну, да.
Ну, просто удобнее мыслить с другой стороны,
хотя приходим к одному и тому же.
Да. Так вот, все эти части
помещаются в оперативную память,
ну, и получается как квадрат частей. Да.
Вот. И вы опять смотрите, то есть
исследовать можно действительно очень нетривиально,
потому что, во-первых, действительно
что мы делаем? Во-первых, есть
ваше действие, во-первых, что мы делаем
в как бы в нашем
вот это так называемое оперативное
запоминающее устройство.
Да. То есть, знаете, ты программист,
да, ну и что такое ОЗУ?
Все, не знаешь, ну какой
штайтишник. Да.
Иди, да. ОЗУ, да.
Как какой штайтишник, иди чайник
чини. Вот.
Значит, есть, но
так же есть количество произвольных доступов
соответственно к этому жесткому диску,
но есть объем
последовательных операций.
Ну и оказывается, что нам
это как бы дает то, что
как бы считывать пока, то есть
мы как бы считываем получается
все красиво два раза подряд, правда?
То есть два раза. Сначала один раз
считываем весь жесткий диск, потом аккуратненько
другой, в принципе получается суммарно.
То есть
подряд считываем 2n.
А рандомных доступов нам требуется
получается всего лишь
сколько? Ну 2k получается.
А?
Сколько блоков получилось?
Нет, смотрите, потому что это еще
потому что это еще первый
потому что это еще первый этап, когда мы
давайте так попробуем. Считали блок, отсортировали,
запихнули, да?
Тогда у нас получается
2 блоков, на каждый надо
2 произвольных доступа,
один на чтение, другой на запись.
Поэтому получается 2k.
Видите, тут написано
n log m, а не n log n,
потому что мы как бы у нас
потому что у нас всего n поделить на m блоков
по факту.
То есть k равно n поделить на m
на самом деле.
То есть тут знаете, у нас есть
мистическое тождество такое, да?
То есть k равно по факту
типа n поделить на m, ну
что-то типа, потому что да, мы количество элементов
делим на мегабайлы, да, но
вот, но я думаю, суть вы понимаете.
Нет, сейчас вообще не очень понятно,
почему m это m log n.
Что?
А потому что, смотрите,
каждый, вы сортируете,
у вас есть k блоков, каждый из них
вы сортируете за его
размер,
вот, log его размер, вы прям честно
тут сортируете, тут без вариантов.
k на m log m.
Но km равно n,
получается n log m.
Ну или n поделить
на m блоков, каждый вы сортируете
за n log m, получается
n log m.
А?
Почему у нас там количество
произвольного
диска 2k, если когда
мы пьем блоки опять на блоке, мы же будем
видимо как квадраты?
Это не тот этап.
А, на этом этапе?
Да, у нас этот этап-то вообще было бы странно,
что мы вроде сортировку сравнениями делаем,
а не m log n.
Да, это еще первый этап,
обратите внимание, да, вот тут словосочетания
тоже не случайно написаны, да.
А?
Это второй этап,
то есть у нас есть...
Мы поделили на k блоков...
У нас есть k блок.
Каждый делим еще на k частей,
и в каждый момент времени
одна из этих частей загружена в оперативную память.
С какой целью?
Дело в том, что мы на них делаем
k-путевое слияние.
И для этого мы делаем так,
что мы храним
очередную часть,
то есть вот эти элементы,
которые уже в сортировку записаны куда-то,
вот,
этот блок еще не полностью обработан,
а эти еще ждут своей очереди.
То есть когда указатель пройдет весь этот блок,
мы, собственно, честно на его место загружим следующий.
Вот прямо в процессе слияния.
Да.
Да.
Ну, вот давайте смотреть,
да.
Ну, да, получается,
да, произвольных доступов 2k квадрат,
но считываем и все равно...
Считываем и записываем 2n.
Ну, то есть n-считывание, n-запись.
Вот.
И получается, да, в оперативной памяти n лог k,
потому что каждое движение указателя
работает за лог k.
Ну, всего получается
n лог n и n лог k.
То есть это n лог на m умножить на k,
то есть n лог n.
Да.
Чего?
Нет, мы блоком объявляем то,
что как раз в оперативку вот прям в точности влезет.
Для того, чтобы у нас...
Потому что на второй фазе нам нужно,
чтобы у нас было k частей,
которые сливаются.
Поэтому от каждого отсортированного блок
у нас есть k-т часть.
Нет, мы это сделали,
но одно дело...
Нет, когда бы блок сортировали, мы так и делали.
Но теперь-то нам эти все блоки слить надо.
Да.
Так, у вас там встреча пара не началась?
А, не было.
Отменили?
Да.
Почему?
Это непреодолимая обстоятельность.
Цитата.
Рустам, все, что придется сегодня отменить.
А, окей.
Да, у нас нет граничного времени,
да.
Граничный, граничный.
Да, у нас нет граничного времени, да.
Да, у нас нет граничного времени, да.
Антонич,
завтра пара начинается...
Завтра он лайн будет?
Нет, ну как сказать?
Нет, ну есть, ладно, нет,
есть вообще стандартные читы.
Мы сегодня спокойно продолжаем кучу,
а потом сообщаем Ещерину, что завтра, что в следующий раз,
у вас там на занятия больше.
Можно сейчас продолжить?
Нет.
Так, ладно.
Нет, ну можно не сообщать.
А, ну хотя да, если это потом лишняя свободная пара,
потом вам это в зачетную неделю будет,
она вам, конечно, и как понадобится.
Это да.
Так, ну ладно, давайте так.
Ладно, давайте сначала эту тему разберем.
Да.
Ладно, сначала эту тему разберем,
тут правда не очень много осталось,
но подумать надо.
Так.
А, ну ладно, раз у нас время есть, давайте разбираться.
А, за оставшееся время вам можно это слияние,
чтобы в следующий раз прям кучей пойти
и разбирать. Слушайте, кайф, мне нравится.
Так, значит, смотрите, итак внешняя сортировка.
Нет, ну успокой, давайте уж.
С нуля так сначала.
Давайте лучше с нуля все, что было тогда.
Нет.
Как говорится, нет, это называется, смотрите по телевизору.
Так, а?
Еще раз, что мы делаем со свободной парой?
Так.
Значит так, пока мы ничего не делаем,
давайте разбираем эту тему.
Вот так, пользуясь тем,
что как бы, да, тут у вас кто-то не пришел.
Вот, что мы будем делать потом, мы подумаем.
Так.
Так.
Значит, смотрите.
Итак, значит, смотрим.
Мы хотим отсортировать данные, которые
все вместе в оперативную память
влезают мне.
Совсем.
Вот.
Значит, что мы делаем? У нас есть жесткий диск,
то есть мы
как бы себе воображаем так,
что да, есть некий жесткий диск,
значит, мы имеем право с него тоже
произвольно считывать, произвольно записывать,
но желательно, если мы это делаем хорошими
такими хорошего размера блоками,
то это делается сильно быстрее.
Поэтому нам хочется, чтобы
как бы, чтобы
произвольный доступ в памяти был поменьше.
Вот. Ну и записывать, правда, тоже
желательно за линию, желательно, чтобы
потому что вот жесткий диск
это долго.
То есть это долго, то есть это
как бы просто, то есть константа доступа к диску
сильно больше, чем константа доступа
к оперативной памяти.
Поэтому надо минимизировать.
Что мы делаем?
Ну, потому что третье,
произвольный доступ, это означает, что
вы должны вычислить, на какой
диск вам лазить,
на какую вот
из дорожек, это не одна дорожка, то есть
у диска на самом деле тут много дорожек,
вот этих вот, да.
Значит, то есть это куда, да,
с какого блина читать, значит, где
собственно, читать, где начинать
читать, еще дождаться нужного момента,
да.
Вот. А под следующий доступ, так,
отлично, вот и считай с этого момента, дай мне 250
мегабайт, а, ну отлично, давай, проворачиваем
диск, радуемся.
Ну, перескочим на соседнюю,
все равно быстрее.
Ну, относительно быстро.
Ну, то есть понятно, именно поэтому, то есть как бы
нельзя сказать, что тут прям все мегастабильно,
но в любом случае значительно быстрее
будет.
То есть даже, то есть это все равно будет, скорее всего,
один-два диска, да, один-два диска,
поэтому там не более чем один перескок такой,
поэтому суммарно получается классно.
Вот.
Так вот.
Значит, как мы это делаем?
Делаем так. Во-первых,
значит, начинаем с того, что давайте
попробуем еще картинку тоже порисовать тогда.
Значит, убираем
это безобразие.
И говорим.
Все. И говорим. Значит,
вот у нас жил был огроменный массив,
мы его делим на блоки
по нашему стопа 100 мегабайт,
100 мегабайт,
100 мегабайт, 100 мегабайт, 100 мегабайт.
100 мегабайт, 100 мегабайт.
Мегабайт.
И
на первый, значит, этап первый.
Тупо каждый блок загружаем
в оперативную память,
честно его сортируем
и, собственно, записываем
обратно на его место.
Вот.
Ну и,
соответственно, говорим, что
получается
произвольных доступов
у нас получается ровно столько, сколько блоков.
А блоков у нас 1, 2, 3,
к.
То есть на первой фазе мы просто каждый блок
честно считываем и честно сортируем,
честно записываем.
Можно сказать, что примерно туда же.
Вот. Понятно, да?
Фаза вторая.
Как из этих к от сортированных массивов
сделать один?
Вот.
Идея такая.
Каждый мы подразбиваем
еще на к частей.
И каждое...
Ну вот.
Так.
Ну да.
Хочется, чтобы, значит,
подразбиваем на блоке размером делить на к,
почему? Для того, чтобы...
Ну, смотрите, что мы вообще делаем?
Мы хотим эти к блоков отсортировать,
мы применяем к путевой слияние, да?
То есть, если бы нам было начхать
на счит, да, подряд идущие считывания,
что бы мы делали?
Мы бы тупо завели у себя в оперативке
к указателей и кучу.
Логично, да?
И дальше n раз сделали бы что-то
типа достань элемент,
минимально из кучи, посмотри, откуда он.
Вот таки, запиши его в ответ,
посмотри, откуда он взялся,
и тот указатель, откуда он взялся,
сдвинь на единичку, посмотри, что там за элемент
и запихни его в кучу, правда?
Это бы так работало.
Но мы не хотим по одному элементу
с диска доставать, мы хотим доставать
сразу по много, правда?
Поэтому мы делаем следующее.
Мы их делаем...
Мы достаем эти блоки не по одному элементу,
а по m делить на k.
Почему именно по m делить на k?
Ну, потому что чтобы, как бы, суммарно
эти части блоков там из разных мест
тоже умещались в оперативную память.
Понимаете, да?
Вот.
И тогда получается, что...
То есть вы честно, значит, с каждого момента времени,
значит, тоже там...
Вот какие-то блоки сейчас
в мерже участвуют.
Если в какой-то там указатель сдвигается,
если выяснилось, что вот этот мы полностью
уже записали, да,
то мы тогда торжественно объявляем,
что...
Тогда мы торжественно объявляем, что, значит,
тогда вот теперь берем следующий блок,
блок и загружаем уже его.
И продолжаем.
Вот, понятно, да?
Но мы же у себя в оперативке храним там,
сколько элементов мы уже считали.
Потому что в оперативке
у нас как бы хранятся
к блоков из разных мест.
Вот они блоки.
Нет, и указатели
в каждом блоке.
И вот эти элементы, на которые указывают
эти указатели, хранятся в куче.
Ну как сказать?
Куда мы пишем?
Короче, куда-нибудь
допишем.
Да, по факту тут, конечно, да,
это не совсем 100 мб лучше по 50,
потому что тут идея в том, что завести лучше еще
там половину оперативки можно
отдать под ответ, и когда у вас там
типа полная маршрутка ответа набралась,
собственно, ее торжественно куда-нибудь вот в ответы
и отправить.
Ну, чтоб не по одному элементу печатать, а по-моему.
Нет, ну по их... Да, по-любому.
Поэтому, как бы, поэтому мы и пишем,
что количество подгрузов на второй файле
их
как квадрат будет.
Когда собираем
отрезок длиной k, то мы его можем сразу
подгрузить.
Потому что у нас, если мы соберем
отрезок длиной k, мы его можем...
Ну не длиной k, а длиной m, наверное.
Ну по-разному, да.
А длиной k это...
То есть мы подгружаем себе блок
оттуда и заодно ответ печатаем.
Но это...
Но размер блока...
Ну, напоминаю, размер блока m делить на k,
тогда не k. Да, в принципе,
тут это и подразумевается, и чтоб делать
за там 2k квадрат.
Но, правда, записывать там непонятно, куда ответ,
потому что тут... То есть, как бы, в данном
случае вот то, откуда вы черпаете
вот эти отсортированные блоки, и то,
куда вы записываете ответ, это должно быть заведомо
разными вещами.
Потому что просто записывать вот ответ, не глядя
на тему того, сколько тут блоков было, вы не можете.
Мы храним
кучу размера m,
которые... Вы храните
кучу размера k.
Потому что в каждый момент времени в куче находится
один элемент из каждого блока.
Ещё m элементов. Чего?
Ещё m элементов. Ну,
m элементов этих самих блоков, да.
То есть мы не уместили в операционном.
Но, да, видимо, придётся считать, что
оперативная память всё-таки не совсем 100, а
где-нибудь там 200-300. Всё.
Ответ мы куда забудем? Ответ мы куда забудем?
Вот, ответ, мы уже как договорились, ответ записываем
железобетонно отдельно куда-то.
То есть, можете считать, что у вас там есть
входная лент...
Ну, к ответу вам уже... Ответ не нужен,
что ответ вы вводите уже в соответствующем порядке.
То есть, можете считать,
что у вас три жёстких диска,
на котором есть вход,
на который вы используете за своих
промежуточных целях, и куда вы записываете ответ.
Сейчас, аж мы узнали, что вот это число
нужно добавить в вот
сортированный массив. Куда мы его добавляем?
Ну, вот там вот определённо. Ну, мы его записываем
в себе локально. Пока.
Ну, да. Ещё один массив у меня?
Ну, да.
Какого размера? m? Да.
Выучите про ним пары,
потому что вы понимаете сейчас, куда брать
следующий блок?
Нет, ещё круче. Мы в куче
сразу храним...
Ну, как сказать, если это единый массив,
мы можем в куче хранить просто индексы блоков,
но если так, детали. Но вообще, можете считать, что пары храним,
это ладно.
А можно просто хранить индексы,
и по нему понимать, из какого блока это взялось вообще.
И там, ну и в кучу, понятно,
компаратор свой запихнуть, естественно,
но это уже детали,
это как бы не принципиально.
Да вот, поэтому получается, что
на второй фазе у нас получается
произвольных доступов уже как квадрат.
То есть, более того, ну там дальше всё зависит
от того, какой кап. Потому что, как говорится,
если оказывается, что кап большое...
Ну, кап, по факту, это просто
m. Да.
То есть, тут вопрос, во сколько раз
то, что вы хотите отсортировать, больше
вашей оперативы?
Потому что дальше тут есть интересная мысль,
что если прям 500,
прям сильно много, да,
то иногда возникает ощущение,
что вместо одного путевого слияния
имеет смысл сделать два
путевых слияния.
Ну да. Ну, например,
давайте...
Ну, например, сделаем так,
разделим массив на 20,
ну вот.
Ну, смотрите, 500 это 25 на 20, да?
Давайте каждые 20 блоков
посартируем отдельно, да?
И тогда у нас получится
25 раз по...
что-то типа 25 раз по 20 в квадрате
произвольных доступов, да?
Да.
Нет. Да и последний, нет, дальше
другое.
Да. То есть, смотрите,
то есть сначала вы делаете 25 раз
сортировку за 20 в квадрате
считываний,
а потом...
а потом, интересно, вот,
а потом дальше у вас тоже квадрат,
то есть получается 25 в квадрате
произвольных доступов.
Ну вот, но хотя нет.
Можете, пожалуйста, это первая оптимизация.
Единственная.
Единственная. Нет. Ну, что значит
оптимизация? Ну...
Ну...
Да.
Значит, оптимизация.
А вот она написана.
То есть идея такая, вместо того,
чтобы делать прямо делить на блоке по 500,
чтобы избежать того, чтобы у нас не было
500 в квадрате произвольных доступов, да?
Есть идея, что их можно делать чуть-чуть
поменьше.
Вот, раз в десять. А идея такая.
Давайте сначала сделаем
просто поделим не сам
массив целиком, посартируем
то, что описали раньше,
а разделим его на 25 частей
и каждую посартируем отдельно.
Тогда произвольных доступов будет
25 умножить на 20 в квадрате.
А теперь идея такая.
Теперь нам нужно сделать одно
мега двадцати пяти путевое
слияние.
Понимаете, да?
Вот.
Ну а теперь давайте думать.
Ну вот.
Сколько придется
делать там,
если у нас есть 25?
Вот.
То есть сколько там этих
считываний? Придется, значит,
у нас есть, у нас на этот раз...
То есть смотрите, то есть у нас...
Так, сейчас посмотрим.
То есть частей у нас всего 25.
Каждая...
Вот. Каждую из них мы подразбиваем...
То есть каждая из них имеет еще
20
оперативах размера, правда?
Поэтому, чтобы адекватно ее вписывать,
нам придется делить ее уже не на
качестей, а на 20
качестей.
Нет, вру, на 25
качестей.
Сейчас, или нет?
Ну да, 25 качестей, да,
20 мегабайт.
Вот. Поэтому получается,
что там действительно подгружать
мы будем уже не просто 25 в квадрате,
а 25 в квадрате еще умножить на 20.
Вот. Поэтому тут еще на 20
возникает.
Но тем не менее, в сумме это оказывается,
вон, видите, просто там где-то
раз в одиннадцать меньше, чем...
Там раз в одиннадцать меньше
произвольных доступов, чем было у вас
перед этим.
Чего?
Чего?
Чего умножается на 20?
У нас 25 блоков, мы протеняем
25 в квадрате.
Ну, давайте
думать. Ну, просто
скажем так,
потому что у вас размер блока...
Ну, смотрите, давайте так.
У вас есть...
Давайте еще раз. У вас есть...
Вы сортируете 25 массивов,
да?
Каждый имеет размер 20 М.
Получается, что
вы одновременно храните блок
размера М поделить на 25, правда?
Тогда получается,
что из одного этого блока
размера 20 мегабайт,
то есть вы получаете считывание
и сделаете 20 на 25.
Почему на 25?
Потому что мы сейчас сливаем
25 от сортированных
массивов размера...
А, нет, размера 20 М.
В каждом блоке у нас
столько будет частей.
В каждом блоке
части будут вот такого размера.
Поэтому частей всего 20 на 25.
Но так как у нас всего блоков
25, то получается, вот откуда мы
эти 25 в квадрате на 20 взяли.
Какое из 25?
Ну, смотри, если ты сливаешь
25 массивов, да?
И в оперативу
ты можешь загрузить суммарно М элементов.
Значит, из каждого
блока ты будешь грузить одновременно
сколько элементов?
25 массивов
в каждом 20 М.
Ну, это не важно,
сейчас наплевать, что их 20 М там в каждом.
Главное, у тебя
ты можешь загрузить одновременно
хранить М элементов, да?
Из каждого блока хочется поровну.
Блоков всего 25.
Вот.
Теперь, значит, получается,
ты будешь подгружать частями
по М поделить на 25.
Тогда сколько
частей блок будет разбит?
Если размер блока 20 М,
а делить ты его будешь на части
по размеру М поделить на 25.
И блоков 25 всего, поэтому
сошлось.
Ну, вот тогда
отсюда получается, что
такое нетривиальность возникла.
Это увеличивает вам, конечно,
это
произвольных, то есть абсолютно
доступа к памяти, да?
То есть последовательных,
не абсолютно.
Но зато произвольных у вас
уменьшилось раз в одиннадцать.
Так что, может быть,
даже это и сработает.
Или нет,
я не знаю.
Ну, да.
Мы сэкономили число произвольных доступов
за счет последовательных.
Вот.
Но с другой стороны,
да.
Но само по себе
мы пугаем, что может быть для нас
это не страшно.
Так. Ну ладно, господа.
Значит, смотрите. Дальше у нас происходит
теперь следующее. Смотрите.
Можно сделать так.
Если к нам сейчас никакого
семинара по 7 не будет,
то, по идее, смотрите.
Дальше, по идее, следующее у нас
по плану идет, значит,
как сделать слияние
за вот единицы памяти
дополнительной, да?
И после этого мы переходим
в сладостный, чарующий и упоительный микс,
вливаем их в кучу.
И просто кучу.
Вот.
Поэтому, в принципе, есть...
Ну вот, поэтому, в принципе, да.
То есть опция может быть такая.
Смотрите. Если мы сейчас обсуждаем merge sort,
то есть этот merge,
ну, честно скажу, скорее
всего всю пару обсуждаем.
Он такой слой?
Ну, понимаешь,
просто...
Ну, мы уже 20 минут от предыдущей пары
захапали это раз,
а во-вторых, наверное, вам
захочется еще, может, небольшой перерыв какой-то
сделать, правда?
Вот. Ну, можно не делать и так далее.
Вот. А тогда в следующий раз можно думать,
может быть, там
запросить у Мещерина там лишнее занятие.
Или когда-нибудь иметь в виду,
что как бы там можно провести на одну пару меньше.
Так и хочет?
Как говорится, мне бы он об этом сказал когда-нибудь.
Ну, ладно.
В общем, когда-нибудь он еще и хочет. Ну, окей.
Кажется, он как раз дистантует.
Нет, наоборот.
Он дистантует.
Не, он дистант-дистантует.
Чем?
Дистант? Так, это проблема.
А!
Там у него есть другое сообщение, Реплайд.
Там два сообщения, один с дистантом,
другой на вашей паре.
В общем, Мещерин хочет дистантом,
в смысле.
В чем проблема сейчас продолжать
вести пары?
Потому что четыре пары альбосов в день.
Да, я вас обрадую.
У вашего предыдущего поколения так и было.
Потому что
там возникла такая идея.
Вместо того, чтобы там Мещерин проводил какую-то
удаленную пару в девять утра, давайте лучше проводить
ее в какое-то более удобное время.
И там семинар тоже.
А вместо этого по алгоритму можно делать четыре пары
и считать, что в среднем раз в месяц
можно делать выходной.
Можно делать пять пар.
Когда выходной два раза в месяц.
Как вы это, вы выдержите?
Нет, иногда это работает.
Потому что софт хип, например, это тема на четыре пары.
Поэтому, знаете, иногда
потратить на нее четыре пары единым блоком,
это хорошо.
Хотя бывает иногда,
как показала практика,
темп изучения
материала, по-моему, увеличивается
от этого даже.
То есть от этого увеличивается, как это ни странно.
Даже не в четыре третий раз.
Да, но понимаете,
просто смотрите, есть такой спецэффект еще,
что если мы изучаем, мы допустим
сложную тему. И сегодня мы скажем,
ой, так зачем я вам это показываю,
так.
А, впрочем, это и не важно, я вам уже
это не показывать. Так.
Смотрите, просто, ну вот,
мы изучали сложную тему,
и в середине прервались.
В следующий раз мы с вами увидимся через неделю.
Следовательно, придется потратить время
на то, чтобы мы вообще там воспоминали,
что там вообще было.
Особенно, если там уже сложные идеи были,
то как бы вот тоже. Поэтому это тоже,
на это тратится время. А так, если мы как бы
единым блоком изучили тему, то как бы
в следующий раз повторять не надо,
что в следующий раз мы будем изучать что-то независимое.
Вот отсюда получается
тема и получается ускорение,
неожиданно.
Ну, а так много пар в день.
Ну, по текущему раскладу
у вас столько же пар в день, просто
вместо всех алгоритм, а так еще
еще одну пропустить, еще пропустить,
и в результате в какой-то момент
миссерин попросит, чтобы я вышел
на выходной.
А он там пришел и, собственно, там
скажем, четыре пары сей.
У нас просто перед сей будут
дополнительные пары.
Нет, пока... Нет, давайте так.
Нет, дополнительных...
Нет, ребят, давайте так.
О дополнительных парах речь пока не идет,
потому что речь пока идет о том, что некоторые пары сей,
некоторые алгоритмов меняются
между собой местами.
Не более того.
Так, ладно.
Так, давайте-ка так. Давайте-ка мы все-таки
минут десять выдохнем, действительно.
А потом все-таки это называется...
А потом два массива все-таки сольем.
Итак, чем мы занимаемся?
Значит, теперь будем
решать такую задачу.
Внимание. У нас есть
массив,
который делится
на два отсортированных массива.
Допустим, красный и, допустим,
синий.
Ну, удобно
вести наглядное обозначение.
Наша задача
отсортировать этот массив.
То есть, первопорядочить элементы так,
чтобы они были отсортированы, но при этом
разрешается использовать
исключительно от единицы
дополнительной памяти.
Вот, понятно?
Нам нужно отсортировать
с помощью ножа сорта.
Нам отсортировать хоть как-нибудь.
Но самое главное, чтоб за линию.
За линию...
Вот хипсорт у нас.
Он отсортирует за НЛОГН.
А, нам нужно
еще раз. Нам нужно...
Смотрите, нам нужно отсортировать вот этот
массив, но нам дано, что он
уже делится
на две отсортированные части.
Надо эти две отсортированные части
превратить в одну единую отсортированную часть
за линейное время.
А сложность в том,
что нам на это нужно затратить
О от единицы
дополнительной памяти.
Вот, понятно, да?
Что нам для этого нужно?
Упреждение номер раз.
Начнем с того, что, как мы уже
заметили, предположим...
Нет, мы можем...
Ну, во-первых, что можно делать в массиве...
Давайте сразу себе вообразим.
Что можно делать
внутри массива
за от е?
Переместить каждый элемент
направо. Да, можно
сделать циклический звук.
Вот, давайте сразу еще.
Давайте, можем вам качественные упражнения ставить.
Как сделать циклический звук?
За один элемент, а на к элементов
за от единицы дополнительной памяти
и за линию времени.
Чего?
Можно и так.
Я по-другому делал,
но так прикольнее.
Не важно.
Хотя, да, видимо.
Не, ну просто задача.
Что такое...
Ладно, давайте обсудим, если так интересно.
Что значит циклический звук
на к, ну допустим, влево?
Это означает посвапать местами два вот этих
массива, правда?
Тогда идея такая.
То есть давайте эти... Сначала сделаем реверс.
Если мы сделаем реверс этого массива,
то мы тогда получаем просто
два эти массива в нужном порядке, но
развернуты. Остается только каждый под массив
развернуть. Все.
Да.
Ну, можно было там что-то там найти
в НК и что-то там по циклу.
Ну, давайте реверс.
Ну, лучше так.
Да.
А потом реверс каждый из частей.
И получил сразу то, что надо.
И по это циклический
звук на к, влево.
Красота.
Вот.
Красота.
Все еще можно сделать.
А еще можно массив
отсортировать пузырком.
А их нет.
Залинь его на держку.
Нет, квадрат. Правда
с маленькой оговоркой. Не массив,
а под массив, размер которого
не происходит, ну, что-то типа кое-что.
Можно и встать. Или двух хорнил.
Или трех хорнил.
А нам сейчас все пригодится.
Сейчас весело будет, смотрите.
Значит, это первое, да. То есть
что, в принципе, массив размера корень
и зен можно отсортировать пузырком
и чем приятен пузырек
или вставки, они работают за вот единицы
дополнительной памяти. Правда?
Та перечерк.
Значит, с другой
стороны. Хорошо, да.
Какое дополнительное память нам нужда?
Ну, вообще говоря,
значит, вообще говоря,
заметим,
что если бы у нас была,
допустим, дополнительная
где-нибудь вот, например, мысленно
вот здесь была
какая-нибудь дополнительная память
размера синего массива,
было бы совсем просто.
То тогда мы бы могли в тупую
сливать просто вот честно двумя
указателями и записывать, начиная сюда.
Ну и там с конкретными...
Ну вот. Ну и там
соответственно с конкретными доказательствами
в духе, что если мы там уже сюда записываем,
значит, этих элементов мы уже ушли.
Мы уже обсуждали. Сегодня тогда нет смысла повторяться.
Правда?
Только не синий был, а красный?
Ну, в данном случае. Какой из них синий был?
Ну, это синий, так...
Ну, я не знаю.
В смысле, не видно что ли?
Просто кажется, что
мы обсуждали, что мы берем
левую часть скопируемую, правую.
Ну, как сказать, то давайте...
Ну вот.
Мы можем скопировать минимальную, если...
Ну, в данном случае...
Смотрите, в данном случае нужна синяя,
потому что как бы тут будет
два указателя, да?
Два указателя здесь и один ответ. И этот ответ
как бы при записи именно вот этой правой
частью должен догонять. Поэтому как бы нам нужен
буфер именно... Если у нас, скажем так, где-то
буфер слева, да? То он должен быть
размером именно этого. Спасибо.
Нам вроде не жалко
правую часть, мы ее никогда не забудем.
В крайнем случае мы можем
перевернуть эти два куска и
помернуть. Это да.
Нет, это пожалуйста, да.
Всегда можем сделать меньше, да, это тоже
не проблема.
Просто смотрите, чит такой.
Сейчас будет такой маленький чит.
Значит, мы хотим себе все-таки
создать буфер.
То есть мы хотим вот себя...
Хочется...
Ну вот, хотим создать себе все-таки буфер
какой-то, да?
Чтобы хоть как-то что-то записывать, да?
А именно, значит, мы хотим, чтобы у нас...
Мы хотим свести задачу, чтобы
мы сливали два массива,
но при этом у нас был буфер размера
корень и зен. Или от корня и зен.
Как мы это сделаем?
Что именно, получим или соленое?
Значит, смотрите.
Вот. Ну потому что, смотрите.
Ну потому что в данном случае, когда
говорили... Вот мы говорили буфер, да?
То есть мы говорили, что это просто лишняя память,
которую мы как-то вот используем, да?
А мы теперь представим себе вот что.
Значит, мы теперь сделаем так.
Как создать буфер себе
размера корень и зен?
Мы сделаем это следующим образом.
Вот у нас два массива.
Пробежавшись нужной число
итерации двумя указателями,
вот так.
Вот так. Ну, пробежавшись
соответственно двумя указателями.
Что нам нужно... Что мы делаем?
Что мы делаем?
Мы, значит, можем
найти корень и зен
максимумов
в этом общем массиве. Правда?
Ну, точнее, где они лежат?
Еще раз, что?
Мы хотим в этом массиве найти корень и зен
максимумов.
Это можно найти на корень и зенах?
Да.
Просто подвигав указатели,
то есть получится вот
сколько-то максимумов отсюда,
сколько-то максимумов отсюда, да?
Да, теперь смотрите.
Теперь смотрите.
Теперь мы желтаем
за... Тогда идея теперь такая.
Что некими ОАТН
перестановками
мы можем добиться того, что у нас массив
разделится на три части.
Первое, префикс
вот этого красного массива.
Префикс вот этого синего
массива.
Видите, да?
Вот. И...
Не суфикс, видимо.
Вот. И, значит, суфикс,
в котором находится
корень и зен максимумов.
Логично, да?
Так вот.
Значит, наша теперь задача...
Значит, смотрите.
Сейчас вот будет такая идея такая.
Наша задача теперь смёржить вот эти
два массива.
Смёржить вот эти два
массива, используя вот
эти элементы как
буфер.
Что это означает?
Это означает, что если мы там
слияния... Ну, давайте рассмотрим
простой пример.
Смотрите, простой пример.
Предположим, давайте, что
красный массив случайно оказался
размера меньше, чем корень и зен.
Понимаете, да?
Ну, это совсем холодное положение.
Ну, давайте вот...
Так, можете считать, случай номер один.
А мы можем найти максимум, потом в каждый элемент
записать по два элемента?
Не, не надо в каждый элемент.
Что значит в каждый элемент записать по два элемента?
Ну, типа, элемент
первый плюс, максимум
множество второго элемента.
Мы камешку сортируем.
Все, это камешки.
Все, забыли об обидных
числах, забыли.
Все, это камешки.
Так вот, предположим,
что нам фантастически повезло,
и этот массив размера корень и зен.
Что мы тогда делаем?
Тогда идея такая.
Делаем классическое слияние
двумя указателями, только справа
налево. И записываем
ответ вот сюда.
Но с неожиданным
читом. Ведь, допустим, мы решили
записать вот этот синий элемент,
записать сюда.
Но ведь этот же элемент потеряется, правда?
Но теперь идея.
Если вы хотите записать элемент туда,
где находится какое-то черное безобразие,
значит вы свапаетесь с этим черным
безобразием.
То есть, выглядеть это будет примерно так.
Смотрите, давайте сейчас я покажу на примере.
А корень и зен максимум у нас отсортирован или нет?
А это не важно.
Корень и зен мы можем пузырком
отсортировать.
Так, потому что если у нас в конце, окажется,
вот это отсортировано, в том конце эти элементы
в любом порядке, вот тут основная идея гласит,
то вы потом их пузырком
отсортируете.
Ага.
Значит, идея.
Если вы, значит, идея,
мы хотим, глобальная идея,
мы хотим смершить
вот эти, допустим, вот мы хотим,
давайте пока без корней,
мы хотим смершить, то есть добиться того,
чтобы вот эти элементы все
соответственно уже превратились
во что-то едино отсортированное.
И тут шли вот эти элементы,
тоже те же самые
корень и зен элементов,
но условно
пошапленные.
Вот какая наша цель.
То есть, заметьте, нас
устраивает, то есть фактически
это уже отсортированный массив,
в котором последние корень и зен
элементов пошаплены, правда?
Поэтому
последняя фаза, тогда будет просто
отсортируемся квадрат любой интересующей вас сортировкой.
Сейчас.
А мы разве когда справа-налево движемся, у нас
иксы не влево двигаются?
Ну, двигаются, ну, господи, ну,
подсыплу потом сдвинем, если у вас там будут тут иксы,
а тут отсортированные.
Видимо синий должен быть размер
у корень, у корень красный.
Нет, красный, красный.
Когда вы записываете синий, у вас эти два указатель одновременно
сдвигаются, а когда красный,
зеленый приближается к синему.
Синий должен обогнать синий, поэтому
количество шагов не должно быть,
расстояние между ними должно быть...
Красного массива.
Смотрите, мы изначально
были в массиве, были два массива, мы нашли
корень и зен максимум, да?
А как мы сделали же танцы,
что они у нас оказались в конце, можно, пожалуйста?
Просто, да, просто
двумя указательами,
просто мы их никуда не записывали.
Ну, да.
Ну, по сути, да.
По сути, вы вот...
Ну, как сказать, по сути, вы вот эти
два, две части массива... Так, ребят,
через тех тех... Так, пойтишь?
По сути, вы вот эти две части массива посвапали,
то есть вам сейчас, на самом деле, как вы уже поняли,
надо абсолютно все равно отсортированно эти элементы
или нет сейчас?
То есть они сейчас просто... Мы знаем, что это корень и зен максимум,
в каком... Кто из них первый максимум,
кто третий, кто пистолет, кто корень и зен,
и нам по барабану.
Корень и зен максимум, два массива, первый корень и зен.
Ну вот, пока...
Общий алгоритм все равно вот так
работает, остается... То есть теперь наша задача.
Даны два, пока в общем случае, просто отсортированных
массива,
и есть вот этот буфер размера корень и зен,
состоящий из максимума.
Мы хотим добиться того, чтобы
на месте этих двух родился один отсортированный,
а в конце все равно
состояли те же элементы, может быть в другом порядке.
А почему это получится?
Нет, а почему это получится,
это основная часть алгоритма.
Это я огласил,
что мы хотим.
Если у нас есть черный ящик,
который умеет делать вот это,
то мы решили задачу.
Да, и вот единица дополнительной памяти.
Понятно, да?
Так, кстати,
обратите внимание, кстати,
если вы хотите вот единицы дополнительной памяти,
то не забудьте слово рекурсия.
Или пока добьетесь того,
что рекурсия будет вызываться от железа
от единицы раз.
Можно помнить, каждый вызов функций
создает от единицы дополнительной памяти.
Помните, да?
К сожалению, да.
Да, так что...
Так что...
Итак!
Итак, внимание!
Так, ладно, поняли,
какой задачи мы все свели, да?
Вот!
То есть мы сортируем два...
То есть по сути, мы сортируем два массива,
и у нас есть буфер размера
Колинзе.
Но мы хотим, чтобы эти элементы
сохранились и потом тоже были в конце,
только может быть в другом порядке.
Так, сейчас, вот этот буфер как работает?
Просто...
Ну, пока непонятно как.
Пока он просто есть.
Если мы туда хотим записать,
то мы свопаем элементы оттуда
и...
Именно так.
Но если мы...
Но чтобы эти крестики
не куда-то в середину переместятся...
Смотрите!
Так, смотрите!
Сейчас я на уровне идей покажу,
что я вам хотел показать.
Если тут меньше либо равно
Колинзе, то это делается в тупую,
сейчас я вам покажу как.
Предположим, что
у меня есть...
Значит, смотрите, что.
Предположим, что у меня есть элементы, допустим.
Я сейчас обволочу и напишу.
Три,
пять, девять.
Есть синенькие
вот эти элементы какие-нибудь там.
Один, четыре,
шесть, семь,
там восемь, одиннадцать.
И буфер.
А, большие. Ну вот.
Буфер, давайте. Вот так и будет.
Пятьдесят семь, сто семьдесят девять,
две тысячи семь.
Не,
тогда сначала двести тридцать девять, потом две тысячи.
И то.
Ладно, по барабану.
Да, вы правы.
Это будет буфер, то есть я специально
взял числа побольше, чтобы сразу
понимать, что это буфер у нас не интересует.
Я думал вообще об РСД написать, но не важно.
Значит, смотрите,
ответ это будет там.
Заводим два указателя.
И третий в ответ.
Так вот.
Так что, смотрите.
Поехали. Зеленый.
Сначала увидим, да.
Так, девять и одиннадцать.
Кто больше? Одиннадцать.
Следовательно, мы свапаем в этом месте
двести тридцать девять и одиннадцать.
Сейчас.
Зачем?
Если бы вы посмотрели в Вистайме,
то вы делали обычный имя.
Сменчивый, уменьшивый, больший.
Ну, Господи.
Можно и так.
На вкус их цвет
фломастера разная.
А мне легче так, что
я на весь день.
Ну, я просто прям показываю, как можно
сливать, пожалуйста.
Так, далее. И синий указатель
с движами.
Так, теперь 9 и 8. Кто больше?
Девять.
Да?
Десять.
Круто.
Значит, свапаем теперь 9 и 2007.
То есть теперь 2007 находится где-то здесь.
Девять находится где?
Там.
Там.
Вот ты видишь.
Да.
Что будет происходить?
Вот, теперь зеленый.
Так, опять сейчас.
Так.
Так, красный.
Пять или восемь?
Очевидно.
Вот.
Но соответственно да.
Значит, конечно восемь, поэтому свапаем восемь и 179.
Вот 179, вот восемь.
Реально разбилось.
С права то твою школу, а слева какие-то.
Есть.
Ага.
А справа правую.
Как говорится, кто сказал что-то?
Ай.
Так.
Да, погоди.
Сейчас все исправится.
Они-то все сейчас пошапятся.
Так.
Что дальше?
Семь или пять?
Девять.
Так, отлично.
Значит свапаем семь и пятьдесят семь.
Пятьдесят семь и семь.
Вот.
Обратите внимание.
Зеленый указатель торжественно вышел в зону какой-то не принадлежащих ему элементов.
Ну и что?
Ну и еще страшного не происходит, потому что между зеленым указателем включительным и синим не включительным находится сплошн гуферные элементы.
Вот.
А если бы...
Так.
Ну и сейчас мы соответственно видим, что теперь у нас теперь свапается шесть и двести тридцать девять теперь, да?
Давайте мы уже поверим, что...
Ну я не знаю.
Почувствуем.
Мы уже чувствуем.
Чувствуем, да?
Дальше не надо?
Да, мы чувствуем.
Я не верю.
Давайте.
Хорошо.
Не, ну давайте-давайте.
Так, ну вот.
Зеленые отправляются сюда.
Тем более, что наконец-то мы вспомнили о красном.
Как говорится о красном?
О красном, потому что пять на этот раз больше четырех, поэтому сто семьдесят девять отправляются на этот раз куда-то далеко.
Как кто-то вывезался куда-то там к не топовым школам, да?
Как говорится, ладно.
Это да.
Это замечание оставим на его совести соответственно.
Так.
Ничего, самая ирония эта крутая.
Это да.
Так, далее.
Что теперь?
Четыре.
Ну теперь, да, теперь посвапаем четыре пятьдесят семь.
Вот, пятьдесят семь очень активно участвует вообще в этом всем процессе.
Вот.
Так, действительно так.
Вот пятьдесят семь.
Вот четыре.
Два указателя сдвинули.
Так, два указателя.
Так, указатель вот и указатель вот.
И двести тридцать девять теперь тоже отправляются в начало массива.
Отправляются, ну вот.
Отправляя свапой с тройбаном.
Вот тройбан.
Вот двести тридцать две.
Так.
Ну и все, что нам теперь остается.
Ну вот.
Ну фактически нам теперь просто остается в оставшейся просто этот синий массив такжественно сдвинуть.
То есть, ну, в общем, все, что нам нужно теперь это посвапать один и пятьдесят семь.
Вот.
Тут будет пятьдесят семь.
Тут будет один.
Вот.
Значит, что получилось?
Обратите внимание.
Теперь обратите внимание, что у нас теперь в конце получился в точности отсортированный массив.
А в начале образовались эти буферные элементы.
Ну, поменять местами эти два массива за ВАТН, как мы уже с вами выяснили, труда не составляет.
Ну, сейчас мы занимаемся математикой, поэтому как бы мы сейчас не будем заморачиваться в том, как это сделать наименьшее число проходов там каких-то.
То есть, это не нужно.
Вот Эм, вот Эм.
Угу.
Да.
Да.
Ну, два указателя на массиве и один на ответ, да.
А можно теперь нескромный вопрос?
Давай.
Что если у нас размер краевого массива все-таки больше?
О, сейчас все будет.
Не волнуйся, все победит.
Ну, вот таким образом, таким образом продемонстрировано, то есть, зачем нам может помочь буфер размера полинизен.
Как минимум, если и левый массив оказался не более чем полинизен, то слияние делается легко.
Если правый массив больше либо равен полинизен, ну тоже без проблем, правда?
Ну, нам просто их переставить сначала, это буфер придется сделать, то же самое с лева направо, вообще проблем нет.
Согласны?
Вот, понятно?
Отлично.
Значит, теперь идея.
Ну вот, значит и так теперь мы можем считать, что у нас буфер размера полинизен есть, и в конце мы с ним разберемся.
Вот, понятно, да?
Понятно?
Не слышу.
Сейчас можно еще раз усмотреть, у нас два указателя.
Она красная и насилья, да?
Ну?
Красная.
И мы берем из них наибольший, меняем зеленый.
Ну да, сменяем местами с тем элементом, куда указывает зеленый.
Дальше зеленый двигается, и вот...
И тот, который обменяли, тоже двигается.
Ну, честно говоря, пластическое слияние.
Да?
Я не случайно, в общем, рассмотрел этот случай перед общим случаем.
Потому что сейчас он нам тоже немножко пригодится.
Знаете, смотрите лайфхак следующий.
А теперь я хочу добиться...
Ну давайте так, у меня будет мистическая константа К,
которая будет равна кореньизен.
Ну, допустим, округленный вверх.
Ну, допустим, да?
Так вот, смотрите.
То есть на языке К у нас получается сейчас есть...
Мы сливаем мотив и у нас есть буфер размера К.
И там каких-то два на этот раз достаточно больших массивов.
Ну, как мы уже сказали, если один массив имеет размер меньше, чем...
Там меньше либо равно К, то мы как бы уже победили.
А теперь идея такая.
Я хочу добиться того, чтобы размеры каждого из этих массивов делились на К.
Вот я так хочу.
Но если быть точнее, я хочу каждый из этих массивов разбить на блоке размера К.
К, К, К, и в конце меньше К.
Потому что может не поделиться зараза, правда?
Давай.
Блоки меньше К мы можем тоже запихать в конец.
Ну, правда, да.
Какая идея?
Мы их тоже можем запихать в конец, но единственная проблема, что эти блоки не обязательно образуют глобальные максимумы.
Правда, оставшимся?
А, ну да.
Хотя бы один из них образует.
Нет.
А, нет, не правда.
Скажем так, понятно, что максимум, хотя бы один максимум среди них есть, это да.
То есть у них есть хотя бы К максимум.
А, на самом деле...
Ну, на самом деле...
Не, не обязательно.
Там зависит от того, сколько их.
Есть там в одном три, в другом пять, то поэтому там может быть...
Коррентируется, что там есть три максимума.
Из минимума их размеров, оставшихся к максимуму.
Да, но это не важно.
Потому что мы сделаем следующее.
Смотрите.
Значит...
Но мы, тем не менее, эти элементы сейчас в буфер попробуем запихнуть.
Да, потому что идея будет такая.
Не слушаем.
Это легким циклическим звуком.
Мы сделаем вот что.
А, мы можем отсталить, потому что у нас есть буфер размера К.
Значит, у нас есть буфер размера К.
В конце, если сейчас массива будут стоять вот эти вот кусочки размера меньше К.
Кстати, в идеале могут быть... В идеале ноль, кстати.
Мы можем из них сделать один кусочек.
Вот.
Сейчас. Ну, погоди, погоди.
Сейчас мы сделаем вот это.
И после этого у нас идут вот эти вот блочки.
К, К, К.
Отсортированные.
Это мне сделает циклический звук на подвасиве.
Ну, типа.
И тут, соответственно, тоже флоп, флоп, флоп, флоп.
К, К, К.
Еще раз.
К.
Вот так.
Так вот, идея теперь такая.
Давайте эти...
Значит, теперь идея такая.
Давайте К.
Ну, давайте так.
Можем даже не совсем так сделать.
Можем так сделать, а можем сказать, давайте мы их...
Мы про них временно забудем.
Что такое временно забудем?
Регульсивно забудем.
Ну, нет.
Нет, мы скажем так.
Мы сдвинем буфер.
Да, мы сдвинем буфер.
И скажем, что мы временно сосредоточимся вот на этой части.
А вот эти мелкие два блочка у нас останутся.
Да.
Вот у нас количество звегов было константов, потому что каждый из звегов работал за лаком.
Ну, у нас их пока константов еще.
Как бы, или для вас 10 уже не константов.
Как это называется, да?
Два константа, десять не константов, три константа, девять не константов.
Ну, и в пределе А6.
Ну, как бы да.
Григорий Астер предсказывал эту ситуацию, да.
Правда, он объяснял эту ситуацию на кокосах, но...
А вот эти последние два блока вообще в конец запутали?
Да.
Время назабили.
Время назабили, да.
Перекинули и забыли.
Почему?
Потому что, смотрите, предположим, что мы сейчас победим, да.
Что мы сейчас вот это вот торжественно сольем.
С использованием вот этого буфера, да.
Главное, соль им не слиться.
Вот.
Но это от вас зависит.
Как бы, я так.
Я так.
Я так.
Значит, вот вы взяли этот кусочек.
А теперь идея такая.
Теперь...
Ну вот.
Ну вы, конечно, можете приписать вот этот буфер, но теперь идея такая.
Да, вот у вас есть вот это и есть вот эти два кусочка.
Так вот, идея такая.
Давайте, во-первых...
Значит, теперь идея такая.
Давайте отсортируем этот кусочек в тупую.
Ведь заметим, там размер не более чем 2К, поэтому тоже за ОАТ можно отсортировать тем же кузырком, правда?
Значит, отсортировали.
Меньше 2К.
И после этого...
Ну, я могу сейчас попереставлять еще массивы.
Но вы можете убедиться, что теперь надо слить два массива, отсортированных массива.
Как мы лево слили?
Да, как мы красный синим слили.
Можно, пожалуйста, сделать?
Это самый сок.
В смысле?
Их суммарный размер этих красных?
Нет.
Нет, это самое...
Я говорю, это как всегда.
Я оставляю самую сложную часть на сладенькое.
Я просто доказываю, что если мы оставим только самую сложную часть, если ее победим, то все остается.
Это очевидно.
А дальше очевидно, да?
Делаем.
То есть мы просто пометим местами и предъявим то, что мы делали.
Да, правда, ладно.
Только оговорка, что в уфер К, тут все-таки больше, чем в К или...
Это ОАТ К.
Да, ну это да.
Ладно, мы сливаем этот массив на...
Ладно, сливаем сначала с этим, потом сливаем с этим.
Да.
Вот так слышишь.
Ну, ситуация...
Ну, просто садите.
Ну, потому что садите.
У вас есть этот...
Нет, стоп, стоп.
Да.
У нас же работает...
Если один не больше, чем К, а на второй нам пофигу.
Нет, смотрите, у нас один больше...
Нет, нам не на один из них не пофигу, но самое главное, что уголь сортирован.
Да, вот прям так.
Поэтому идея такая.
Мы можем сначала слить вот этот с этим, используя этот бушер.
Правда?
А потом все.
А потом результат слить вот с этим, тоже используя этот бушер.
Сейчас как мы бьем.
Как мы красный, синий.
Нет, как бы вот это сделать, я же говорил.
Это мы вот оставим на конец.
Хорошо.
Я хочу...
Если мы в это поверили, то значит у нас теперь есть три отсортированных массива.
Два из которых размера меньше К.
И бухер размера К.
Есть подозрение, что как бы за О от Н вы как-нибудь это сольёте.
Правда?
Потому что мы сначала вот этот с этим сольём.
Да, мы этим уже занимались, да.
А потом результат сольём вот с этим, используя тот же самый бушер.
Сейчас, то есть, что мы получается сделать?
Вот мы выделили эти два блока меньше К, да?
Да.
И потом их как-то между собой сливали.
Нет, мы их между собой даже не сливали.
Их удобнее даже не сливать.
А, это что?
Потому что гораздо удобнее будет...
Ну, дело...
Потому что, смотрите, когда мы сливали с бухером размера К, мы пользовались тем, что у нас один из массивов размера меньше, чем К.
Правда?
Да.
Поэтому, когда он размер 2К, нам будет неудобно сливать.
Поэтому мы делаем следующий фильм душами.
Мы эти два массива в первозданном виде отправляем в конец.
И добиваемся того, что вот эти отсортировались, да?
Да.
Теперь говорим так.
Теперь заметим, что вот этот и этот красненький кусочек мы с этим бухером слить можем, правда?
Да.
И тогда у вас останется один какой-то большой кусок, который надо слить с вот этим сливем, с тем же бухером.
Тоже надо.
И вы это тоже делаете.
И тогда у вас останется то, что вы хотели.
Единый отсортированный кусок, и в конце бухер из...
В конце бухер.
В конце бухер?
Да.
Ну, бухер из тех самых максимальных элементов, помните?
Да.
Понятно?
Вот.
А теперь...
Ну вот.
Нет, видите, то есть мы себе последовательно упрощали задачу в том плане, что...
Смотрите.
То есть у нас каждый отсортированный массив можно прям четко разбить на блоке размера К.
И при этом у нас есть буфер размера тоже К.
Ну, один из вариантов был на самом деле тоже сказать, что это буфер, потому что это отка, но мы не будем.
Итак.
Итак.
А теперь самое интересное.
Внимание.
Значит, смотрите.
Итак.
Давайте-ка...
Теперь я вот это вот лишнее убираю.
Вот.
Видите?
Ничего не поменялось.
Вообще.
Угу.
Поменялось все.
Мы теперь...
У нас есть буфер размера К.
И мы сливаем два массива, размер каждой из которых делится на К.
Все предыдущие мотивации были ровно ради этого.
То есть, как вы знаете, это были только махания руками из цикла, как избавиться от этих мелочей.
А сейчас начинается, собственно, самая ядерная идея.
Внимание.
Значит, смотрите.
Значит, идея такая.
Давайте отсортируем эти блоки по максимальному элементу.
Да, ладно.
Важная оговорка.
При...
Ну вот, отсортируем эти блоки.
Ну подожди.
Это...
Нет, вы не поверите.
Смотрите.
Блоков...
Нет, ребят.
Количество блоков у вас не более, чем N поделить на K.
Это равно...
То есть, N поделить на корень из N, округленный вниз.
То есть, это меньше либо равно корень из N.
То есть, у вас не просто каждый блок размера корень из N, но и блоков размера корень из N.
Правда?
Ну их смотреть надо.
Умеем.
Мы умеем их сваппать за OOTK.
Что именно сваппать?
Любые из этих двух блоков мы имеем право сваппать за OOTK.
Это правда.
Ну прям взять два блока и пить.
Вот.
Да, теперь.
Как же этим вас курили?
Поэтому сейчас неожиданно начинает играть.
Дело в том, что мы это будем делать.
Мы это будем делать за K квадрат.
То есть, N с сортировкой выбором.
Вот с чем ее придумали.
Да.
Ну ладно.
Придумали ее, наверное, не за этим.
Но она сыграла.
Смотрите.
То есть, смотрите.
Что такое сортировка выбором?
Это когда вы думаете, кто тут самый минимальный.
Кто тут самый минимальный, вы понимаете за OOTK количество блоков, да?
А потом...
Вы понимаете.
Так, вот это меню.
Ну отлично.
Вот этот блок с вот этим за OOTK теперь посвапаем.
Потом, кто из оставшихся минимум.
Тоже за OOTK принимаем, за OOTK свапаем.
Ну за OOTN поделить на K, точнее.
Понимаем, за OOTK свапаем.
То есть, обратите внимание, да?
То есть, как бы...
То есть, свапов мы делаем корень из N.
То есть, чем хороша сортировка выбором, да?
Потому что свапов мы делаем OOTN.
Хоть, конечно, и не сравнение, мы делаем N квадрат.
Так еще, это мы хотим в блоке посортировать?
Да.
Целиком.
А почему вставками нельзя?
Вставками нельзя, потому что вставками вы будете делать очень много свапов.
Потому что вставками это значит, что вам циклички зли.
То есть, мы свапаем элементы одного с элементом одного.
Да.
Ну правда, да.
Тут, правда, есть одна маленькая тонкость.
Что...
Ну ладно.
Ну, смотрите, тут есть одна маленькая тонкость.
Что делать, если вы сравниваете, и вам встретились два равных максимума?
Ничего не делать.
Нет, на самом деле, как чуть позже убедимся, я просто сразу скажу.
Но лучше, чтобы мы потом это не додумывали.
Надо сортировать, и второй параметр сравнивать по минимальному.
А если они тоже совпали?
А сейчас...
А здесь ли у двух блока подсортированных?
Так, ну тут...
Это еще ничего не значит.
Не, ну, как сказать.
Там просто, понимаете, зачем я это сделал?
Нам просто будет принципиально, чтобы сортировка была в некотором смысле устойчива.
Чтобы там два красных блока...
Ну, потому что могло быть так, смотрите, что у вас красный блок был вот такой,
и второй блок вот такой.
Просто из тупо, из равных элементов.
И тогда могло оказаться, что вот этот блок окажется раньше этого.
А если у них равные и минимумы, и максимумы, то это блоки разных?
Ну там, если они еще и одного цвета, то это означает, что это просто два вот таких блока, и нам по барабану.
А если они разные, то они равны разных цветов?
А если они разные, то нам без разницы, да?
Так, а цвет мы не храним.
Очень жаль.
Нет, это нам не важно.
Сейчас вы увидите, есть алгоритм с этим справиться.
Я не понял, вот если они одинаковые, то почему нам не важно?
Если это два одинаковых блока из ка элементов, где все элементы одинаковые...
Нет, точно так, у всех...
Нет, у всех, смотри.
У всех как-то могут быть они вот так.
Не могут.
Так, обрати внимание.
Блоки внутри одного цвета устроены так, что минимум следующего больше чего.
Да, то есть внутри одного цвета, если они как бы одного цвета у них совпали максимум, а совпали минимум, то это означает, что это два блока из одного и того же элемента.
Это понятно.
Вот, нам просто в будущем в конкретном доказательстве это пригодится.
Ну тогда минимум сразу...
А что мы делаем сейчас?
Максимально минимум?
Нет.
Нет, раньше должен идти только у кого элементы меньше.
Все, давайте делать финиш.
Финиш можно.
Ну мы...
Растянем, растянем.
Не, ну мы как бы...
Мы как бы постепенно въезжаем, действительно, в каждые руки.
Нормально.
Теперь смотрите.
Дальше шоу будет такой.
Итак, значит, после этого безобразия, значит, у нас, конечно, эти блоки чуть-чуть между собой пошафлились.
Ой, every day I'm shuffling.
Ой.
Состя, ничего, что я сейчас все это без микрофона говорю?
Очень жаль.
Так, ладно, давайте напоследок я микрофон...
Нет, я очень надеюсь, что мой громкий голос как бы докрещится голосом.
Чего?
Вопрос, до этого момента все было очевидно?
Да, материал Коля вам можно не рассказывать.
А, ну давайте, да, сразу, да.
Те, кто очень захотят...
Да, давайте лучше сразу.
Некоторые виды десоциации предельных углеводородов.
Так вот.
Значит.
Значит, смотрите.
Предположим, дальше у нас идет какие-то вот абсолютно рандомно там пошафленные, значит, элементы.
Но нам, в общем-то, с этого момента сейчас будет достаточно начихать.
Значит, теперь смотрите следующее.
Дальше это будет, на самом деле это будет работать так.
Смотрите.
То есть по факту у меня есть несколько отсортированных блоков.
И я с ними сейчас буду что-то делать.
Раз.
Ну, допустим, вот у меня там, ладно, побольше давайте.
Два, три, четыре.
Допустим, пять, шесть, семь.
Теперь идея такая.
Каждый блок отсортирован, правда?
Да.
И теперь я иду.
Теперь я иду, иду, иду, иду, иду.
И вот до какого-то...
Иду пока блоки составляют отсортированный префикс.
Ну, если так до конца и дошел, то я возрадовался.
Но мне могло не повести.
Да.
Да.
Видите, максимум-то по-любому выше будет, да?
Чем вот это.
Так вот.
Что я теперь буду делать?
Я сделаю неожиданный финт ушами.
Я солью вот эти два массива.
Использую вот этот буфер.
Вот.
Здравствуй, я квадрат.
Чего?
Не-не-не-не.
Ну, на самом деле...
А как, мэй?
Нам тогда этот буфер сначала к ним нужно за корень приставить?
Чего приставить?
Не, ну, смотрите, технически это не проблема.
Потому что вы просто виртуально считаете, что...
Потому что вы же можете виртуально считать, что вот это вот плюс вот это вот равно один массив.
Вот.
Поэтому вы там сольете, у вас там в начале будет буфер.
А, даже не в начало.
Вы можете считать виртуально, что это начало буфера.
Что это в начале стоит, потому что у вас, видите, в конце мелочи стоит, правда?
Поэтому как бы вы сольете, у вас получится примерно следующее.
Что у вас тут начинается отсортированный массив.
Потом вот тут продолжается.
И вот тут буфер.
Вам останется только тут цикли... немножко циклический подвигать.
Так, чтобы буфер вернулся на место.
Как-то получится.
Да, как-то получится.
Или хотя в данном случае окажется удобно этот буфер реально в начале хранить, кстати.
Мы его...
Ну, циклический двиг сделаем и передвигаем.
Ну, в общем, да.
Ладно, это детали.
Это...
Как это говорить?
Это...
Так, как говорил у нас преподаватель в группе CLKH, это детали реализации.
Вот все.
То есть просто сразу видно, что как бы такие вещи вы должны додумывать сами.
Вот.
Да.
Знаете, там просто очень много там преподавателей в группе или там...
Знаете, иногда вы обращаетесь с одногруппником за помощью.
Некоторые одногруппники тоже там пафос на вам заявляют.
Некоторые такие вещи нужно самим додумывать.
Больше вы к ним за помощью не обращаетесь, сами понимаете.
Чего?
Ну, да.
Ну, как сказать?
Ну, тут вопрос, как бы, да.
Понятия тут, правда, проблема в том, что вы и по другим вопросам, как бы,
к ним уже опасаетесь, и как бы вот...
Как тебя зовут?
Филипп...
Чего?
Так вот, ладно.
Так...
Так что не надо.
Тем более, что на всякий случай...
Тем более, что на всякий случай предупрежу о том, что на самом деле, знаете,
очень полезно кому-то что-то объяснять просто потому,
что в это время вы сами можете понять, что вы там что-то не понимаете.
Лучше это понять сейчас, чем на экзамене, правда?
А то, знаете, потом жалуется там, что как-нибудь Богданов
потом спрашивает...
Спрашивает доказательства.
А потом спрашивает ноут.
И вы ему говорите, как это доказывается?
Это доказывается вот это- вот это воспознание вот этого утверждения.
А как это утверждение доказывается?
Ну вот это вот это леммо.
А это леммо, как доказывается вот так-то, так-то, так-то,
где-то на седьмую интерация у вас зацикл.
Вот, внезапно выясняется.
яйца ну вот так вот нет не просто когда ну просто реально у нас так это
заводит аксет на первый курс помните это реально сильный студент так кстати
попался неожиданно вот так вот значит чему я это все я это все потому что значит
в результате получается здесь от сортированной массив да ну за от суммы
вот этих длин нет это не вот это вот именно вот этих длин а теперь вот
теперь внимание я неожиданно утверждаю ну максимум конечно ну понятно что
максимум здесь не поменялся согласны но и при сорте там со вторым минимум если
тут равный максимум и то тоже видимо все в порядке было да хотя хотя нет не
ну вот здесь наверное максимум не поменялся так вот нет просто утверждение
такое что вот до этого момента я утверждаю теперь все элементы находят
стоят абсолютно правильно вот вот до этого момента то есть теперь вот эти
минимум они точно правильно стоят вот да это интересный вопрос действительно
почему потому вот а вот а происходит это вот почему дело в том то есть
смотрите где но вот но дело в том что эти вот два блока они явно разных цветов
правда вот давайте пусть эти блоки это вот синий блок это красный блок ну там
порядок сейчас вообще не важен тогда смотрите вот что тогда но вот
заметим следующее что каждый из вот этих эллинот но то есть
а
чего еще сейчас да нет ну что с этим блоком и сейчас скажем но пока я просто
хотя бы на первый раз утверждаю что как бы и после того как вы тут смёрзете вот
эти элементы тут находятся правильно но вот посмотрите да потому что обратите
давайте подумаем сколько у нас то есть заметим следующее что все элементы вот
эти вот правее они заведомо больше вот этого согласны но больше либо равны а
сколько элементов меньше его сколько а сколько элементов меньше его ну как
минимум вот все они плюс еще несколько отсюда согласны
ну тогда из этого следует что смотрите то есть то есть этот элемент если
посмотреть пусть он пусть он имеет x порядковую статистику но глобально он
пусть имеет x порядковую статистику да ну ладно x плохая буква она уже
задействована пусть он имеет z порядковую статистику да
тогда да давайте еще скажем что вот это вот смотрите пусть это будет l
суммарно но это будет к но это понятно это ка по-любому правда но вот это l это
ка так вот теперь мы замечаем следующее то есть мы замечаем что ну z очевидно
больше либо равен чем l
но вот но при этом z откровенно меньше либо равен а то и просто меньше чем z
плюс к
и z но пусть вот у этого элемента реально вот сортированном этом слитом
массиве порядковая статистика равна z ну то есть чтобы сортированном массиве
он будет стоять на z месте да вот этот вот да вот вот этот потому что все вот
эти элементы все кроме вот этих l плюс к элементов они заведомо больше они
будут правее
да только есть одна маленькая проблема все эти элементы они тоже либо синий
блок и тогда не точно больше его либо красный блок и тогда не больше вот этого
элемента который в свою очередь больше вот этого ну больше ну короче больше
либо равны его короче ну потому что каждый следующий синий блок больше
предыдущего синего блока да между ними влезли какие-то красные но синий
между вот то есть нам очень важно что это два разных блока понимаете что все
что правее оно заведомо получается больше ну хотя бы этого уж точно
понимаете да
но я рассматриваю вот этот элемент мне интересно сколько элементов может быть
слева от него вообще слева от него в принципе сколько элементов меньше его в
этом глобально где но это не важно если тут красный синий рассуждение тоже самое
абсолютно сейчас там абсолютно это уже синий красный они сейчас абсолютно
равноправно и так и должно быть просто потому что мы нигде не пользуемся тем
что красный левее синего потому что мы перед перед слиянием могли их
посвапать так что вот это неважно вот и так то есть получается что сколько
элементов меньше либо равно его ну давайте вот можем да если для простопы
считать шуравных элементов нет да то тогда меньше его получается как минимум
z-1 элемент но как максимум там z плюс к уже все вот эти элементы заведомо
больше его так сейчас только тут не за это сейчас тут l надо написать но да
даже там этот один можно выкинуть потому что это все равно больше но это уже мелочи что
это вообще означает это означает что l минимальных элементов глобально вот
этого массива находятся где-то здесь
потому что у нас есть элемент такой что все эти элементы больше и существует не
менее чем элементы в которые не было который его меньше но меньше либо
равно то есть значит они находятся где-то здесь следовательно когда если
вы эти два массива сольете то тогда окажется что эти l минимальных элементов
оказываются просто на своем месте и тогда получается что у вас но вот то есть
получается теперь вам нужно добить что оставшиеся штуки но в оставшихся штуках у
вас есть будущие блоки синие красные и теперь один блок уже непонятно какого
свойства но давайте считать его под цвету его последнего элемента который по
любому не поменялся правда но будем считать красным хотя тут конечно уже
намешана вот но нам это но вот но нам это не важно нам самое главное как я уже
сказал нам надо делать так чтобы как бы то есть вики доказательство основано то
том что как бы каждый следующий блок одного и того же массива заведомо больше
предыдущего то есть этого нам достаточно в общем то есть мы знаем что если этот
элемент красный то чтоб тут хвостей не было все будущие красные элементы будут
больше да просто мы начинаем вот отсюда то есть теперь начинаем отсюда и тоже
уже идем по отсортированным, отсортированным, и находим
следующий блок.
А теперь мытическое утверждение, что все это работает за
ОАТН?
Да, но все это работает за ОАТН по одной простой
причине.
Вы каждым шагом съедаете l элементов, правда?
То есть вы ставите на правильное место l элементов, согласны?
Отлично.
Но, заметим, что все, что вы делаете, это ОАТЛ, потому
что вы сливаете массив размера l с массивом размера меньше,
чем l, меньше либо равно.
Но ОАТЛ плюс k.
Да, но k меньше, или правда?
Потому что l делится...
А у нас еще есть...
Мы сейчас сливаем через буфер, поэтому это ОАТЛ
плюс 2k.
Но попит с собой.
Да, но это ОАТЛ все равно.
Я не уверен, что можно говорить ОАТЛ, потому что, условно,
если мы первый делаем за l, второй за l пополам, третий
за l.
А мы не будем следующий делать за l, потому что l это конкретная
длина, и мы это делаем за ОАТЛ.
Я имею в виду, что я не уверен, что корректно говорить,
что раз мы все делаем за ОАТЛ и тратим l, то у нас получается
линия.
Ну это корректно.
Смотрите, на первом шаге вы сделали ОАТЛ действие.
Нет, смотри.
Нет, ну давай, чего некорректного, смотри.
На первом шаге ты потратил...
Допустим, мы делаем за l, второй за 2l, третий за 4l,
пятый за 8l.
Да, только ты не учел...
Только один маленький нюанс.
Ты не просто сделал за ОАТЛ, а ты поставил на правильное
место l элементов.
Да.
То есть если ты мог сделать сначала l, потом 2l, потом
4l, потом 8l, но тогда это означает, что ты поставил
на правильное место l, плюс 2l, плюс 4l, плюс 8l элементов,
то есть n было как минимум 15l.
Да.
Ну конкретно в этом случае понятно, что да.
Так и в будущем так тоже будет.
Нет, я имею в виду, что конкретно для этого доказательства
у нас ОАТЛ просто меньше высовывает 2l, поэтому работает.
А если мы в вакууме говорим, что типа мы ставим на
правильное место l элементов за ОАТЛ и само по всем l
равное n, то мы работаем за ОАТЛ.
Я не уверен, что это работает.
В таком виде звучит, как работает, ну или...
Или я просто не ловлю, как и ассоциацию тебе вызывают
эти слова.
Потому что пока выглядит...
Тут работает.
Ну, смотри.
Тут мы можем всегда сказать, что вот это соединение
у нас работает, ну, не больше, чем за 3l операции.
А здесь работает.
Ну да, здесь работает.
Ну...
Нет, ну ладно, я не знаю там, я понимаю, что там
возможно там есть какие-то другие алгоритмы, в которых
звучат похожие слова с потенциальной подлянкой, да,
я понимаю.
Ну ладно, ну, как бы да, тут сложная ассоциация, ладно,
давайте пока оставим.
Так, чего?
То есть мы отсортировали эту штуку, отрезали последний
блок, и дальше идем вместе с этим последним блоком
делаем тоже самое.
Да, то есть начиная с этого момента, теперь делаем
то же самое.
То есть мы сначала...
То есть тоже там находим вот это вот, то есть отсортирован
и тут...
Упс!
Делаем абсолютно то же самое, только теперь вот
и это тогда позволяет нам вот уже на эти части поставить
тоже правильные места.
Доказательство абсолютно то же самое.
То есть, получается, мы сливаем последний красный
с синего или с синего?
В смысле?
Отсортированный с красного?
Нет.
Нет.
С каким красным?
Ну, эльска мы сливаем.
Да, мы сливаем.
Но вот этот вот последний кай элементов отсортированного,
да, это мы считаем это красным блоком, с тем же максимумом,
который был.
И мы продолжаем.
Да, ну здесь случайное совпадение, здесь мог быть и синий блок,
конечно.
Но тогда мы как бы...
Что?
Почему мы это красный блоком считаем?
Потому что максимум этого блока не поменялся.
То есть мы можем считать, что это красный и поддерживается
вариант, что типа красные блоки образуют отсортированный
массив.
Заканчивается он красным, поэтому начинается он красный?
Да.
Заканчивается синий.
Если это закончится синий, будем вот этот галактизер
считать синим.
Да.
А вот то, что неравенство, вот это как оно у нас получилось?
Какое?
L плюс K больше либо равно Z.
Ну, еще раз.
Оно получилось...
Ну, про L плюс K оно получилось просто...
Просто, что такое картная порядковая статистика?
Сколько элементов меньше либо равны вот этого?
Утверждение.
Их не более, чем L плюс K, и они вообще все находятся
здесь.
Почему?
Потому что все вот эти элементы больше его.
Больше они, потому что они либо синие, и они точно
его больше, либо красные.
Тогда они больше этого, а этот больше этого.
Следовательно, Z не более, чем L плюс K.
Но, с другой стороны, он больше либо равно L, потому
что вот, нашли все элементы больше либо равно.
Следовательно, L минимумов находятся здесь.
Вот такое рассуждение.
Нет, линия из того, что...
Ну, потому что вы взяли этот шаг и сделали O от L действий
и поставили на правильные места 1 L минимум.
На следующем шаге вы тут найдете...
У вас тут это будет...
Сделаете O от L2 действий.
Вот это жадно тут найдете отсортированность.
Возьмете следующий блок.
За O от L2 их тут посортируете.
И после этого у вас тут L2 минимум, окажется.
Ну, тогда получается, что это будет работать
за L1 плюс L2 плюс L3 и так далее времени.
И за это время вы на правильные места поставите L1 плюс L2
плюс L3 элементов.
А это, соответственно, N.
Ну, даже чуть меньше.
Вот и все.
Чего?
То есть...
В смысле?
Если мы вот эти больше никогда трогать не будем.
Мы их поставили и все.
Несколько раз трогали.
Несколько раз трогали, значит...
Да, у нас могут быть элементы,
которые тут поучаствуют в нескольких мержах.
Да, вполне.
А, мы сказали, что мы ставили L минимум,
и мы еще массиво обрубили его.
Да, да, да.
Но в новую группу.
Да.
У нас получается элемент,
который не может участвовать больше,
чем в группе мержах.
В группе K находится?
Он в начале влевом?
Не, не совсем.
На самом деле, может быть так,
что у вас тут фейл будет сразу,
просто вот здесь, да?
И тогда этот элемент поучаствует
еще в одном мерже.
Или там вот этот поучаствует
еще в одном мерже,
он, оказывается, достаточно большим,
и тогда в следующем мерже
он тоже может поучаствовать,
если тут тоже какой-то глюч.
А, хотя нет, тут глючик оказаться не может,
потому что следующий.
Так что, скорее всего...
Скорее всего, да,
но нам это просто неважно.
Вот.
Так, ну что?
Есть ли еще какие-то вопросы?
Чего?
Чего, буфер?
Так, давайте,
так, давайте,
так, ребят, ребят, ребят,
так,
может, ребят,
давайте у меня другой предложение,
давайте, может, я...
Так.
Вот.
Вот.
Так, может, ребята, давайте... У меня другое предложение.
Давайте, может, я кратенько повторю все шаги алгоритма.
Нет, без вот таких деталей, да?
Значит, смотрите, ладно. Или я даже по-другому делу.
Сейчас мы вначале скручивали пружинку,
а теперь ее раскручиваем.
Утверждение номер раз. Предположим, что мы сортируем
два делящихся на к, значит, по длине массива.
И у нас есть буфер размера к.
Вот мы это только что обсудили, как делать, да?
Понимаете, да?
Значит, допустим, вот, в чем это просто буфер, да?
Как сделать... Теперь давайте предположим, что у нас...
Значит, уровень следующий.
Предположим, что у нас есть буфер размера к, то есть корень,
но при этом у нас эти размеры этих массивов на к не делятся.
То есть тут к, к, к, и тут меньше к, и тут меньше к.
Тогда мы говорим, что давайте сведем это к случаю,
когда у нас все делится на к. Как мы это сделаем?
Потому что справа от буфера мы запишем эти два несчастных массива.
Тогда в конце нам нужно будет слить...
То есть получить вот этот большой массив мы получили,
как сказали ранее.
И с помощью буфера мы сливаем его сначала с этим массивом размера меньше к.
А потом результат сливаем с этим массивом размера меньше к.
Понимаете, да?
То есть таким образом мы научились...
Если у нас есть буфер размера корень из m,
то мы произвольные массивы размера не более n сливать
на зал от n научились, правда?
И, наконец, финал.
Как сливать без буфера?
Как сливать без буфера?
Ответ, у нас нет буфера, а мы заведем.
Как сказал бы классик, как мы их заведем?
Да очень просто.
Мы... Ну вот.
Мы говорим... Так, вот у нас есть два сортированных массива.
Как всегда, синий и красный.
И мы создаем буфер очень простым образом.
Мы в этих массивах находим k максимальных элементов.
Честно, двумя указателями говорят, что понятно,
из k максимальных сколько-то здесь,
столько-то отсюда, сколько-то отсюда.
И, если правильно переставить,
то как раз эти максимальные элементы у вас и превращаются в буфер.
То есть мы их используем как буфер.
То есть идея в том, что
когда мы хотим сюда записать элемент,
мы его просто свапаем.
Потому что мы никуда не перезаписываем,
мы элементы не копируем, мы их как бы перекидываем.
То есть как бы над камешкой.
Поэтому в данном случае просто свапаем.
И в самом конце тогда, когда мы эти два массива сольем,
у нас окажется просто отсортированный массив.
И в конце еще несколько элементов,
которые они все больше, чем вот эти.
Но не в том порядке.
Но так как у нас k это o от Курни и Зен,
то, соответственно, в завершающей фазе
становится сортировка буфера
любым пузырком или чем вы там хотите.
Главное, чтоб без допамяти.
А там вставки, это хипсорт, кусорт на ваше усмотрение.
Вот.
Кажется, хипсорт нужна вставка.
Что?
Хипсорт кажется нужна.
Нет, в хипсорте не нужна,
потому что там вы можете тоже,
во-первых, делать это как сортировку выбором,
и тогда у вас массив делится на две части.
В правой части уже отсортированный суффикс,
а в левой части хип.
И никакой допамяти.
Ну что, еще вопросы?
Стабильность есть?
Стабильность есть? Нет.
Хотя надо подумать.
Да, но это вот он допамяти.
Но да, проблема, но да.
