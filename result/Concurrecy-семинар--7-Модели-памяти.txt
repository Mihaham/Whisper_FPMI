Ну что, начнём? С какого места вопрос? На чем мы остановились в прошлый раз и сколько мне нужно
повторить про модели памяти вообще? Давайте решим. Повторить всё нужно. Сложно сказать,
значит всё нужно повторить. И так, конечно, лучше какое-то знание в себе сохранять,
потому что я однажды перестану повторять и всё, и вы останетесь своими знаниями. Итак, разговор
про модели памяти начался с того, что компьютеры ведут себя странно, что в ячейке много разного
значения в один и тот же момент времени, что компьютер может записывать в память не в том
порядке, в котором вы написали в тексте программы, что процессор может исполнить программу уж явно не в
модели чередования. Почему? Потому что в нём есть кэши и он пытается оптимизировать работу с
протоколом конвериентности, коммуникацию, которая для этого протокола необходима, чтобы инвалидировать
копии в других кэшах и поддерживать инварианты. Так что для человека, который пользуется
просто прям компьютером, думает про компьютер, мир выглядит очень сложно. Непонятно,
на что можно положиться, какие ордеринги могут происходить или не могут, где там, в процессоре,
в компьютере. Всё это очень сложно. Нужна точка опоры. Вот эта точка опоры — это модель памяти.
Модель памяти — это часть темантики языка, которая объясняет вам, какие исполнения программы вообще
возможны. Ну или вернее, как мы их наблюдаем. То есть, что может в программе увидеть каждое
конкретное чтение, а что не может. Или ещё аккуратнее, как гарантировать, что какое-то
чтение увидит какую-то запись. То есть, мы положили, там отправили из одной грутины сообщение в
другую, то другая грутина достанет сообщение, и тогда она будет уверена, что всё, что произошло
до отправки, теперь этой грутине тоже видно. Ну, в общем, какие-то ожидания, которые у разработчика
есть, модель памяти должна обеспечивать и объяснять, при каких условиях эти ожидания выполняются,
что нужно сделать для этого. И есть разные подходы к тому, чтобы вот на все эти вопросы отвечать.
Есть операционный подход, где мы объясняем, как программа исполняется. Правда, мы сложный
процессор заменяем на какую-то простую модель, на какую-то простую абстрактную машину, которая,
конечно же, устроена гораздо проще, но в частности, для такой абстрактной машины, для процессоров
Intel AMD нет никаких общих кэшей, но при этом пользователь наблюдает те же самые исполнения.
То есть, он видит те же самые результаты чтений, а это единственный способ как-то об исполнении
наблюдать. И операционный модель памяти для x86 выглядит вот так. У нас были ядра, они общались
с памятью, но между ядром и памятью, при записи, между ядром camping находился буфер, и
все записи подали в него. Все записи подают в память через буфер, только если мы читаем данный,
читаем ячейку памяти, то мы читаем либо из памяти, либо если в буфере уже есть запись, который
мы просто допоминания не протолкнули, то мы читаем ее из буфера. Ну, в зависимости от того,
где вот. Если здесь есть более свежая запись, читаем отсюда, иначе читаем из памяти. В протоколке
кэшей с их протоколом когерянности на этой картинке вообще нет, потому что в конце концов
в существовании протокола когерянности его цель этого протокола в том, чтобы быть незаметным,
в том, чтобы скрывать этот пояс за тот факт, что ячейка памяти логически такая цельная,
единственная, представлена в виде нескольких копий в разных кэшах. Вот эта распределенность
протокола когерянности скрывает, и в операционной модели этого всего вообще нет. Но проблема
в том, что операционная модель была для каждого своя, у Арма другая операционная модель, про которую
нужно по-другому рассуждать, и это довольно печально. Поэтому мы хотим какой-то более универсальный
инструмент, который будет нам объяснять исполнение нашего многопоточного кода, как этот код на разных
ядрах работает с общей произведением памяти. И этот инструмент — это декларативная модель памяти,
которая оперирует не вот триордерингами, буферами когерянностью, а оперирует порядками. Вот в этой
модели исполнение — это граф, которым вершинами являются обращения к памяти, а дугами, дуги — это
частичные порядки, которые в исполнении возникают. И вот эти частичные порядки ограничивают то,
что мы можем прочесть из ячейки памяти. Всё-таки в исполнении, может быть, глобального порядка и нет,
но есть какие-то частичные, на котором мы полагаться всё-таки можем. Это такая вот принципиальная
разница между операционным и декларативным подходом. И мы к декларативному придём сегодня чуть
позже, но пока мы... С чего мы начали? Мы сказали, что на самом деле мы не хотим ни про графы думать,
ни про какие-то абстрактные машины, мы хотим жить в модели sequential consistency, где исполнение
программы неотличимы от последовательного, который просто уважает порядок обращения к памяти в каждом
потоке. Но проблема в том, что компьютеры так не работают, такую границу нам не дают, поэтому они
вместе со своими всякими там реордерными оптимизациями отдают нам барьеры, инструкции,
которые позволяют форсировать порядок, чтобы можно было из не sequential consistent
процессора сделать sequential consistent исполнение. Ну, на не sequential consistent процессоре сделать
sequential consistent исполнение. Ну вот, в частности, на x86 у нас есть барьер, собственно, единственный почти
influence, который гарантирует, что если у нас есть вот запись потом чтения, то непременно
запись станет видимой глобально до этого чтения. Но тут возникает проблема. С одной стороны,
мы хотим, чтобы программа, чтобы об исполнении программы можно было рассуждать в модели
чередования, чтобы у нас была sequential consistency, но при этом мы хотим, чтобы все-таки процессор
выполнял какие-то оптимизации, а барьеры, кажется, этому препятствуют. Так что мы должны
разобраться, а где именно мы хотим барьеры расставлять. Ну, точнее, не так. Мы хотим как-то
расставить приоритеты, что нам важнее. Ну, то есть у нас есть цель, чтобы было, чтобы о программе
можно было просто рассуждать об исполнении, а с другой стороны, чтобы процессор и компедиатор
имели большую свободу для оптимизации. И это противоположная цель, они противоречат друг другу,
и чтобы это противоречие разрешить, мы сказали, что мы не тем, ни другим жертвовать не будем,
мы откажемся от некоторых программ. И вот для программ, которых мы назовем плохими, программы
с гонками, программы с некорректной синхронизацией, мы обеспечивать sequential consistency не будем.
Мы просто скажем, что не пишите такие программы. Но если программа хорошая, если в ней синхронизация
устроена корректно, а определение корректной синхронизации будет позже, то такая программа может
порождать только sequential и consistent исполнение. То есть разработчик и сама программа не сможет
отличить исполнение от последовательного. Вот это была наша цель. Почему это была наша цель?
Потому что в чем был замысел отказа от таких вот некорректных, плохо синхронизированных программ.
Оказывается, что так вот мир устроен, что если программа корректно синхронизирована, то для нее
достаточно поставить очень мало барьеров памяти в машинном коде и получить одновременно и оптимизации
процессора комператора, и видимость последовательного исполнения. Вот поэтому мы фокусируемся и усиливаем
на таких программах. И вот гарантия о нашей модели памяти звучит так, что есть в программе нет гонок, а гонка
это, напомню, несинхронизированное обращение, два несинхронизированных конфликтующих обращения
к одной и той же ячейке памяти, то такая программа наблюдает только последовательно согласованный исполнение.
Про конкурс надо еще добавить, где одна анализ этих обращений, это запись.
Это значит не конфликтующие. А конфликтующие подозревают, что одна из них запись.
Это определение, да, оно у нас было вот здесь.
Два обращения конфликтует, если они обращаются к одной ячейке, по крайней мере, одной из них запись.
Вот это есть... Можно сказать, что два обращения образуют гонку, если они обращаются к одной ячейке памяти,
одной из них запись, они не в порядочной синхронизации. Ну, либо два конфликтующие обращения памяти не в порядочной синхронизации.
То же самое, только короче. Вот. Ну и каков был наш план? Вот мы хотели построить декларативную модель.
Декларативную модель для пользователя. Что у нас было? У нас есть процессоры, у каждого из них есть какая-то модель памяти,
какие-то барьеры, каждый процессор какие-то реордеринги делает. А с другой стороны, есть разработчик,
который пишет программу для этих процессоров, и он явно ожидает, что все-таки программа не будет
исполнится произвольным образом, а все-таки, что на что-то можно полагаться, на какие-то гарантии.
Это пока не гарантии, это пока ожидания. И вот мы, разработчики модели памяти, берем эти ожидания, берем
процессоры, и с одной стороны пользователю, разработчику отдаем как раз гарантии видимости, то есть
что он может прочесть, что он может увидеть в чтении в своей программе. И эти гарантии мы формулируем в виде
частичных порядков, которые эти чтения ограничивают каким-то образом. А с другой стороны, мы через
комператор обеспечиваем выполнение этих гарантий на конкретном процессоре, но фактически ставим
барьеры памяти в машинном коде. Вот, и наша цель придумать такой набор гарантий, разумный, который
потом можно через барьеры выразить, такой, чтобы, с одной стороны, в совокупности эти частичные
порядки, вот эти гарантии давали нам видимость последовательного исполнения, а с другой стороны, у нас
было бы как можно меньше ограничений, так чтобы процессор мог побольше риордерить. И мы с вами дальше,
ну не то чтобы выдумывали гарантии, мы их не выдумывали, мы скорее пытались понять, а на что мы
рассчитываем при исполнении программы, чего мы ожидаем. Ну первое наше ожидание, оно, да, и вот эти
наши ожидания мы пытаемся формулизовать. Вот первое, что мы ожидаем, это программа Order. Ну вот,
смотрите. Пишем мы такую вот программу. a равно 0, b равно 0, пишем в a, b плюс 1, в b равно 1.
И получается, что почему-то запись в b происходит до записи в a. Вот, как будто бы в программе
компилятор может взять и переставить две строчки местами. Но вы же писали в своей жизни
однопоточные коты, вы все-таки полагаете, что он работает, как вы написали. Вот. Все действительно так.
Но это не значит, что компилятор и процессор не могут ничего поменять местами. Это значит, что они
могут поменять что-то местами до тех пор, пока вы вот не полагаетесь на... Если вы делаете запись,
а потом не читаете, то, наверное, можно ее как-то свободно в текстопрограмме однопоточно расположить.
Но скажем, если вы вот записали в a, а потом напечатали a и b, а потом записали в b,
и напечатали a и b, то вот такая программа, она уже, если она увидит запись в b и не увидит
запись в a, то она удивится. Поэтому компилятор это понимает и теперь в такой программе сначала
пишет в a, а потом пишет в b. Ну то есть компилятор и процессор они не ломают поведение ожидания
однопоточной программы. И вот эти ожидания мы формулируем в виде программ Order. Программ Order
это частичный порядок, который связывает все обращения к памяти в пределах одного потока.
Программ Order сам по себе не означает, что инструкции будут в таком порядке выполняться на процессоре.
Он лишь означает, что исполнение программы, что чтение, которое вы делаете в одном потоке,
они программ Order не противоречит, они с ним согласованы. Если вы сделали запись,
а потом читаете ячейку памяти, то, конечно, вы ожидаете, что запись произойдет.
А если вы еще не сделали запись, то будет странно, если вы ее увидите.
Вот, это базовая гарантия, которую вы пользуетесь уже просто...
Если вы программируете что-то однопоточное, то вы уже пользуетесь этой гарантией.
Это первое ожидание, которое у нас есть. Видимость через программ Order.
А дальше мы говорим, хорошо, однопоточная программа ведет себя так, как мы ожидали.
Теперь вопрос про многопоточные программы.
И в этих многопоточных программах мы разделим ячейки памяти на два класса.
Во-первых, ведем понятие конфликта, и вот с помощью этого понятия конфликта
разделим ячейки памяти на два класса. Ячейки первого класса — это ячейки,
для которых конфликтующие обращения неупорядочены. Логика самой программы.
То есть мы пишем спинлог, разные потоки приходят в его ячейку логика
и пытаются с ней что-то делать. Конечно же, эти обращения неупорядочены,
потому что сам спинлог упорядочивает обращения к другим ячейкам памяти
с помощью себя. Так что ячейка логика у нас особенная.
Но дальше в программе еще много других ячеек, и вот к ним уже доступ
конфликтующих операций должен быть упорядочен. В частности, тем спинлогам,
которые мы пишем вот здесь.
И что мы дальше говорим? Давайте явно компилятору сообщим,
какие ячейки мы собираемся использовать для синхронизации, то есть для каких
ячеек конфликтующие обращения будут неупорядочены.
И мы вот эту аннотацию называем атомиком. Bool и AtomicBool в процессоре
представлены одинаково, просто ячейка памяти, но при этом компилятор
понимает, что это особенный ячейк памяти.
И дальше мы, разделив ячейки на атомики и неатомики,
выдумываем следующие гарантии. Во-первых, посмотрим на атомик
и на историю записи вот этого атомика. Напомню, что картинка
про тест, но не то что про тест, про программу, в которой разные ядра
сначала пишут свой номер в одну ячейку, а потом читают содержимое.
И вот они читают разные в одни и те же моменты времени, но при этом
все-таки картинка имеет некоторую структуру, а именно тут можно
углядеть, что история, которая прочитана, то есть та цепочка чтений,
та цепочка значений, которую увидел каждое ядро,
она является под последовательностью некоторой общей последовательности.
И мы эту общую последовательность называем modification order. Мы говорим,
что в исполнении, вот программ order – это порядок просто в тексте программы,
а modification order – это порядок уже в исполнении реализуется.
Так вот, все записи атомик, они упорядочиваются, на них есть порядок,
и чтения в каждом потоке наблюдают под историю этого modification order.
Вот что эта картинка и демонстрировала. То есть тут уже появляются разные потоки,
которые работают с одной и той же ячейкой, и все записи этих потоков
выстраиваются в некоторую последовательность.
Какая она будет, мы, конечно, не знаем. Ну вот какая это.
Следующее. Да, ну и вот это еще одно ограничение на чтение, то есть что
чтение читают под историю modification order на данный момент.
Следующее наше ожидание, наверное, самое важное. У нас есть два потока –
producer и consumer. Producer пишет что-то в буфер, потом ставит флажок.
Consumer читает флажок, и если он видит там true, то он читает из буфера.
И ожидает, что в этом чтении он увидит эту запись, потому что, ну в самом деле,
почему он читает из буфера? Потому что он видел флажок, значит,
флажок уже записали, а в продюсере запись буфер шла до записи его флажок
в тексте программы просто. Ну вот мы видели, что поэток в тексте программы
вообще, как говорят, никому ничего не обязывает. Так что вот это ожидание,
что если событие произошло до, то мы должны, если есть причинность,
то мы ее наблюдаем. Вот эту гарантию нужно как-то формализовать
и потом обеспечить. Просто из коробки она в процессоре может даже
и не иметь места. Ну а дальше мы занимались тем, что формализовали,
что такое вот причина, что такое произошло до. И для этого мы пользовались
определением из распределенных систем. Мы говорили, что у нас есть там,
не знаю, узлы, они общаются при задаче сообщений, у них нет синхронизированных
часов и быть не может. Поэтому мы вводим на события в такой системе
отношения чистичного порядка happens before. Мы скажем, что если событие A
произошло до события B в пределах, ну, предшествовало событию B в пределах
одного узла, то, разумеется, A произошло до B. Потом мы говорим,
что если A – это отправка сообщения, а B – это получение этого сообщения
на другом узле, то опять, видимо, A произошло до B. И замыкаем
по транзитивности. И вот такое определение, оно, такой чистичный порядок,
оно отражает причинность в системе, что какое-то событие могло стать причиной
другого события, повлияет на него. И вот здесь ровно такая история.
Эта запись должна повлиять на это чтение. Но чтобы объяснить почему,
нам нужно перенести это определение на happens before
на модель разделяемой памяти. Вот. Что такое предшествовало до
в пределах одного узла? Это программа order. Ну, просто в тексте программы
одна инструкция шла до другой. А что такое отправка сообщения?
Вот это запись в Atomic и чтение из Atomic. Запись в Atomic мы как будто бы
отправляем сообщение значения в провод, в ячейку памяти, а потом другой поток
из этого провода получает сообщение, то есть читает значение из ячейки.
И вот если мы здесь записали, а потом прочли, то вот как будто бы
сообщение отправилось. Ну вот спинлоки такая штука есть. Мы сбрасываем флажок
Atomic, а потом сбрасываем флажок в Unlock, а в Lock мы делаем Exchange,
в том числе это чтение, до тех пор пока мы не увидим ноль. И вот мы как будто бы
получили сообщение в локе от Unlock. Вот мы такую связь Store и Load зафиксируем
в виде отношения synchronize with. Мы скажем, что Store и Load synchronize with,
если Load из одного потока увидел значение, которое записал Store в другом потоке.
Вот эта пара, она связывается с такой красной стрелочкой и вот это аналог
передачи сообщения. Коммуникация двух потоков через разделяемые ячейки памяти.
Ну а дальше мы замыкаем это по транзитивности точно так же и получаем
Happens before, но уже в будущей программе. Вот если это чтение увидело эту запись,
то мы ожидаем, что это чтение случилось после этой записи и видимо увидят
результат этой записи. Это вот еще одно наше ожидание. Мы теперь его
формализовали. Почему мы в этой программе должны увидеть запись буфер?
Ну потому что это чтение упорядочилось с этим через Happens before. Мы это
наблюдаем, мы это понимаем, значит и видимость, значит это чтение обязано
увидеть эту запись. Вот еще одно наше ожидание и мы его формализовали.
Все понятно пока, да? Ну а дальше мы замечаем, что тут требуется некоторое
уточнение, потому что может быть одному чтению предшествуют разные цепочки
Happens before, это же частичный порядок. И может быть вот две записи
предшествуют в Happens before за чтению, но при этом эти две записи, трудно сказать
какое из них было последнее. Ну поэтому мы говорим, что это какая-то плохая
программа. У нас есть две записи, они не упорядочены через Happens before между
собой, не конфликтуют, не упорядочены. И вот мы назовем это гонкой. Это два
конфликтующих неатомарных обращения памяти, которые не упорядочены через
Happens before. Вот мы такие программы запретили вот ровно поэтому. Ну а дальше мы
замечаем, что и всего придуманного нам недостаточно, потому что остается такая
программа. И требований гарантии модификацион ордера и Happens before недостаточно,
чтобы запретить для этой программы исполнение, в котором и в R1 и в R2 в итоге
окажется 0. Вот. Это все еще допустимо даже с нашими ограничениями, поэтому мы
придумываем еще одну гарантию, усиливаем гарантию модификацион ордера,
говорим, что нам теперь нужен порядок на всех обращениях ко всем атомикам.
То есть в исполнении есть вот такой вот сквозной порядок на всех обращениях,
сторах, лодах, ченжах ко всем атомикам в программе. Ну и разумеется порядок снова
согласован с программом ордера. Тогда вот такое исполнение уже кажется
недопустимо и вот теперь мы собрали все вместе все частичные порядки, которые
образуют исполнение. Вот исполнение в нашей декларативной модели это
реализация всех этих порядков. Модификацион ордер, happens before,
synchronization order. Ну они многие связаны между собой и мы считаем, что вот эти
порядки согласованы в том смысле, что их объединение новоцикличное, что они
не противоречены друг другу. Довольно естественное ожидание. А дальше оказывается,
что если объединить все эти порядки и все ограничения, которые они в себе
несут на чтение в программе, в совокупности дают видимость
последовательного исполнения. Ну вот такова была наша изначальная цель. Мы хотели
каким-то образом обеспечить для программы, для разработчика видимость глобального
порядка всех обращений к памяти. То есть должен быть какой-то порядок, в котором
можно объяснить все, что мы читаем из ячеек. Как мы этот порядок объяснения
построили? Мы взяли все эти частичные порядки ацикличные, объединили их,
построили топологическую сортировку. И дальше показали, что если исполнять все
обращения к памяти в таком порядке, то каждое чтение вернет то же самое. То есть мы
получили то, что хотели с одной стороны, а с другой стороны мы получили еще и
риординги. Потому что если в программе гонок нет, а про программы с гонками мы не
волнуемся, мы не думаем про них вообще. Если в программе гонок нет, то никакая
программа не сможет различить порядка записей неатомарных, между которыми нет
атомарных записей. Вот если у вас есть запись неатомарных ячеек памяти, то вы
можете про них узнать, только выполнен синхронизацию. Когда вы выполнете
синхронизацию, то есть там что-то прошло здесь из атомика, то кажется по гарантии
видимости через Happens Before вы увидите разом эффекты всех этих записей. То есть
корректная программа, программа без гонок наблюдать порядок этих записей не может,
поэтому компедиаторы, процессоры могут эти неатомарные записи друг с другом
переставлять. Ну вот, мы получили с одной стороны оптимизация компедиатора и
процессора, с другой стороны видимость глобального порядка, ну и вот это был для
нас успех. Но дальше мы говорим, что может быть нам не нужен sequential
consistency, может быть программа наша устроена не так совсем. То есть может быть
мы пишем программу на гарутинах, и вот эти гарутины в го, они общаются через
каналы, отправляют сообщения, получают сообщения. То есть программа из гарутинов
такой граф, по которому текут данные через каналы. Ну или мы говорили про
future на последней лекции, и там тоже говорилось, что вот можно написать код на
future, на rpc future, так чтобы у нас были такие асинхронные конвейеры, асинхронные
графы, по которым данные текут. Вот в таком мире нет sequential consistency, в смысле
мы не рассуждаем про глобальный порядок, мы рассуждаем про продюсеров и
консьюмеров. То есть про happens before. Поэтому мы должны оставить программисту
свободу для того, чтобы он мог оптимизировать код, которому не нужно
sequential consistency, и ставить там меньше барьеров. Ну а барьеры, я напомню, они
возникают в тех местах, где мы к экономикам обращаемся. И для этого у нас есть
слабые модели памяти, слабые memory orders, которые, с одной стороны, отнимают у
нас видимость глобального порядка, но зато дают больше оптимизации. И какие же
гарантии эти memory orders дают? Ну вот тут мы перечислили их, и наша цель сегодня
как раз разобраться, как этим всем пользоваться. Про sequential consistency мы уже
поговорили. Это synchronization order, то есть все обращения на всех атомиках
глобально упорядочены, и sequentially consistent атомики участвуют в образовании
happens before. То есть если вы в одном потоке пишете в ячейку, а из другого
потока читаете эту ячейку и видите запись, то значит вы видите и то, что было, вы
можете прочесть уже все, что было записано в первом потоке до записи. Следующая
ступень, ну вообще memory orders, их там шесть штук, но их можно вот на три ступени
разбить. Следующая ступень — это Release Acquire. Release Acquire по-прежнему участвует
в образовании happens before. То есть если вы пишете в атомик с memory order Release,
а в другом потоке читаете с memory order Acquire и читаете то, что было написано, то
между записью и чтением образуется синхронизация Swiss, а значит образуется и
happens before в конце концов. Но эти memory orders отнимают у вас synchronization order.
То есть на каждом отдельном атомике порядок записи все еще есть, но главное
глобального порядка записи, который был бы согласован с порядком в тексте
программы, вы лишаете, его уже нет, вы его лишились. Ну вот опять пример store load,
store load, и вот если его запустить без изменений, то есть sequentially consistent
атомиками, то скомпилируется другой код. Если этот код скомпилировать, запустить,
то смотрите, что произойдет. Ну ничего не произойдет, код работает, он не видит
никогда два нуля, он не ломается. Ну вот смотри, если мы их ослабим, то мы...
Вот, то мы получаем два нуля, то есть мы и synchronization order лишаемся здесь.
Ну а если мы... но все-таки happens before у нас остается. Если мы используем
memory order relaxed, то мы, кажется, лишаемся почти всего, мы только остаемся с порядком
на одном отдельном атомике. Happens before у нас нет, и вот это означает, что если вы там
прочли с relaxed чтением значение атомика, то это означает, что вы просто не вправе
на основание этого чтения, на основании того результата, который вы увидели, делать
какие-то предположения о содержимых других ячеек памяти. Просто так делать нельзя.
Ну или если у вас была relaxed запись, то тоже, а о ее после чтения судить о содержимом
других ячеек тоже не стоит.
Можно?
Да.
Можете, пожалуйста, открыть код, который у вас, тот, что было. Можете объяснить,
что тут идет не так, если у нас стоят такие набли ордера?
Ну у нас просто нет гарантии, которые бы запрещали два нуля.
Нет, мы так не говорим. Мы не говорим, когда мы используем адрепамяти, мы не говорим,
что там что-то с чем-то переупорядочилось. У нас модели про порядки и про ограничения.
Если нет ограничений, которые запрещают два нуля, значит такое исполнение возможно.
Вот какая гарантия, какой частичный порядок запрещает здесь два нуля?
Вот у нас есть программа, здесь чтение y дало 0, чтение x дало 0. У нас может быть
modification order в программе, да? Должен же быть на каждом атомике.
Ну он есть. Вот сначала в каждом атомике был 0, потом в каждом атомике стала единица,
и каждый поток читал под историю этой истории. То есть прощал 0, ну вот под история,
безусловно. У нас в этом исполнении не возникло Happens Before никакого.
Чтобы возникло Happens Before, должен быть возникнуть Synchronize the Swiss.
Для этого какое-то чтение должно увидеть какую-то запись.
Но не увидело, значит никакого Happens Before, Synchronize the Swiss тоже нет.
Synchronization Order тоже нет, потому что у нас более слабый Memory Order.
У нас есть гарантия Program Order, но она тоже здесь не очень помогает.
То есть у нас один поток читает одну ячейку, а пишет другую.
Так что нет никаких ограничений, которые бы препятствовали результату 0.0.
Просто мне хочется представить исполнение, которое позволяет на текущей модели памяти,
и которое бы этим видео могло быть 0.0.
Ну вот, ты говоришь уже не про модель памяти, а про некоторую мотивацию этой модели.
То есть почему реальность такая, ты спрашиваешь?
Просто если ты оперируешь моделью памяти, то ты не должен об этом думать.
А если мы говорим про конкретный процессор, то давай вот про это и поговорим.
Почему вообще... Я даже не про это поговорю в пример, а про дугой.
Рейзер Куайлор. Потому что может быть непонятно, почему Рейзер Куайлор это два-разный Memory Order,
почему они такие бардые, несимметричные.
И почему вообще эту причинность нужно обеспечить.
Почему ее в старом кино.
Представим себе, что у нас есть два ядра.
Ну, было какая-то марка... А, вот что. Подавал на зеркало.
Есть два ядра.
И на этом ядре исполняется поток, который мы назовем продюсером, который что-то пишет,
а на другом ядре исполняется поток консюма, который хочет получить данные от первого потока.
Что делает поток на первом ядре как продюсера?
Вот он, допустим, пишет в X, а на этом ядре поток читает от Y.
И если он там увидел единицу, то читает из X.
И мы ожидаем, что если здесь вы увидели антаризму, то здесь вы увидели ржавину.
Здесь ядромерка по коннекту.
Ну, это просто процессор.
Ядромерка это вот здесь. Где-то вот с него однажды.
Это есть еще своя цель. Цель этого примера объяснить, почему есть релиз...
Ну, почему вообще в принципе существует релиз Aquarium,
почему Command & Reform не обеспечивается просто с коробки, что может помешать кино.
И почему релиз Aquarium это два-разный Command & Order, то есть два-разный парикад.
Ну, смотрите, вот у нас есть ядро.
И в этом ядре, как удобно можно вводить, у этого ядра есть кэш.
И напомню, что после реакции кэши мы знаем, что все записи памяти происходят через кэш,
но потом когда-нибудь сбрасывает данные тюкли в память.
Нам нужно работать с двумя ячейками.
У зверя кэшлини. В одной лежит x, в другой находится y.
И пусть оказывается так, что ячейка x, ее в нашем ядре, в нашем кэше сейчас нет.
То есть кэшлини в состоянии дуэлина.
То есть нет ее вообще.
А вот ячейка сириков, она у нас в кэшее действует на состоянии вскрытия.
Что это означает?
Что если мы пишем x, то мы можем написать без коммуникации.
Сразу кэш очень быстро.
А чтобы записать x, нам нужно пойти к другим ядрам и инвалидировать их по x.
Забросьте память, потому что я пишу.
Это коммуникация, которую ядро хочет изображать.
Что оно делает? Оно линьится.
Вот я поставлю между перед крышом StorePack.
В простыке случая, я сейчас не про x86 говорю.
Я говорю про некоторый абстактный процессор, который может какие-то активизации делать.
Это не x86.
В StorePack у него немного другое поведение.
Что мог бы сделать такой ленивый процессор?
Он мог бы запись x положить вот сюда.
А запись в y положить сразу сюда.
И с такой активизацией уже эта программа развалится.
То есть причина теперь причина.
Мы прочитаем из y один.
Пообщаемся с этим хорошо.
А потом из x прочитаем что?
Прочитаем ноль, потому что этот x еще не добрался, не был брошен.
Разрывается.
А когда он сбросится память?
Ну это уже посторонний вопрос.
Может быть какие-то барьеры специальные.
Может быть просто процессор решил, что пора.
Не понимаю.
С этой стороны что-то может пойти не так.
Но не так может пойти и со стороны получателя.
Почему?
Что он может активизировать?
Вот здесь мы активизируем коммуникацию.
Здесь мы активизируем какого-то перикоперенности.
Вот здесь тоже.
Пусть ядро занимается чем-то полезным, а ему приходится общение, могут придаться и какое-то кашление.
Что ядро говорит?
Ну не очень-то и хотелось.
Я сделал эту эвалидацию, но вот не прямо сейчас.
Я не буду написать, просто напишу.
Ну можно себе это представить.
Видите, такое активизация Evaluation Queue.
То есть мы ассинхронно пишем память, я ассинхронно потом вырабатываю эту эвалидацию.
Мы отвечаем другому ядру, что да, мы как-то сделали эвалидацию сразу же.
Но при этом мы не...
Пока мы физически ее не сделали.
И что могло пойти не так?
Допустим, даже стопаквы не было.
Но у этого второго ядра был кэш,
где кэш-линия с х была эксклюзивная.
Она была в состоянии эксклюзивной.
И тут лежал норм.
И вот мы делали запись в х и в итрик,
и запись в х требовала отдаст наблюдации.
То есть пусть вот это ядро оно честно написал в х,
отправил нам сообщение, вы делайте, пожалуйста, у себя копию,
а мы этого не сделали сразу.
А потом мы язык сам прочитали из своей копии ноль.
Ну вот, вот и правда.
Так что мы можем, используя вот такие эвалистики,
получить нарушение причинности по вине продюсера
и получить нарушение причинности по вине консюма.
Эвалистики разные, но эффект один неприятный.
Поэтому мы должны...
Ну это, еще раз, это такой эксперимент,
который мы проводим в уме,
потому что мы просто реально так делаем.
Мы не можем так делать.
И это по-своему разумно.
Поэтому мы, с одной стороны, с помощью memory-order-релиз,
будто бы чиним продюсера с помощью memory-order-acquire,
чиним консюма.
Каким образом?
Ну, в этой картинке релиз он требует сброса сторбактора,
а acquire он требует все-таки разбора и эвалидашенки.
Ну можно думать об этом...
Ну это прям совсем наивно, в смысле не нужно так думать,
но для первого понимания сойдет.
Можно сказать, что релиз-запись
это такой односпоронний бое,
который запрещает тому, что выше, продекать ниже.
А acquire-чтение это односторонний барьер,
который наоборот запрещает тому, что ниже, продекать выше.
Ну, выше-ниже, как будто как с reordering,
но на самом деле reordering-ов нет.
Но вот эта оптимизация, это как будто бы
это чтение переехало позже,
эта запись переехала позже этой.
Не то чтобы так буквально произошло,
но в каком-то смысле переехало позже.
Но не то чтобы ядро переставил,
вот здесь то же самое,
как будто бы мы прочли их из прошлого,
как будто бы мы выполнили чтение раньше.
Почему два номера reorder-а разные,
но вот не работают в паре?
Потому что нужно со стороны релиза запретить такие,
чтобы быть со стороны записи запретить,
со стороны чтения запретить.
То есть на железном уровне можно представить себе такие ристики,
которые нарушают причины из двух сетей,
которые нарушают причины из двух сетей,
которые нарушают причины из двух сетей,
которые нарушают причины из двух сетей,
которые нарушают причины из двух сетей,
которые нарушают причины из двух сетей,
которые нарушают причины из двух сетей,
которые нарушают причины из двух сетей,
которые нарушают причины из двух сетей,
которые нарушают причины из двух сетей,
которые нарушают причины из двух сетей,
то есть это такие ристики, которые нарушают причины
из двух сторон.
И мы их запрещаем в этих ристиках,
а в коде мы выражаем через три заклона.
А в декларативной модели мы говорим,
что релиз записи синхронизируется
с aklой чтения вложения из печени.
Замысл ясен?
То есть из коробки у васcorобки у вас причинности
может не быть,
как она, но в процессе.
То есть из коробки у вас хептаут у вас причинности может не быть в процессе
Он может ее не обеспечивать
Мы ее обеспечиваем, говоря явно, что в этом месте мы до потока общаемся между собой, передавим данные
Я как правило говорю, что мы теперь в спинлоке можем интеракция с коробками
Заменить их на действия и раскрывать
Сейчас разберемся, мы, например, еще не дошли, я просто гарантия объясню
Резервация на урон?
Все нужно, раз оно есть, то нужно
Это же инструменты
На что я еще хочу обратить внимание
Смотрите, вот x86 устроен не так
Модерепамяти x86, оно такое
Тут видите, все записи проходят через storebuffer
Не может быть такого, что одна прошла, а другая застряла в буфере
Нет, они все через него проходят
К чему я веду? К тому, что x86 просто из коробки гарантирует, обеспечивает причинность программе
Он не может ее нарушать
И вы это могли видеть, потому что вы могли компилировать атомики, решая задачу спинлок
Вы не видите, а видите
И вы видели, что релиз и релакс компилировались
Ну нет, вы видите, сейчас другое
На x86 релиз и релакс компилируются в один и тот же move
А ну-ка, компилируйся
У нас сломан интернет
Отлично, в общем
Релиз и релакс компилируются в один и тот же move
Почему?
Ну вот не нужно процессору явно сообщать про причинность
Он и так ее обеспечит
То есть в модере памяти x86 довольно сильная
Там любое чтение по умолчанию имеет семантику aquire, а любая запись имеет по умолчанию семантику релиз
На x86 не поможет, но тем не менее это не значит, что можно писать любой релиз
То есть если ты пишешь кроссподформенный код, ты должен писать релиз в анлоке
Короче, понимаешь меня
Но при этом процессор конкретный, от этого выигрыша не получит
Но этот не получит, другой получит
Поэтому в модере памяти есть такое количество
В смысле memory order такое количество
Вот у нас здесь есть одна инструкция, а здесь другая
Чем-то мы сумели ослабить исполнение
Отлично, значит, про причинность поговорили, про happens before поговорили
Теперь, наверное, нужно про примеры говорить
Ну а relax просто мы никакой гарантии не имеем
Relax компилируется...
По задумке, relax компилируется просто в голую инструкцию записи и речтения
Соответственно, причинность никаким образом не обеспечивается, все эти барьеры не расставляются
И ожиданий про другие ячейки делать после чтения relax-то не нужно
Атомика с relax-том не нужна
Ну, видимо, иногда не нужно форсировать это happens before
Ну, я не знаю, ты делаешь счетчик запроса в свою базу данных
Ну, просто считаешь и все
Ну, вот fetch от relax
Надеюсь, успеем, но успеем, конечно, использовать relax сегодня
Давай его используем и увидим
Ну, во-первых, там все-таки может быть формально не relax
Во-вторых, мы разделяем...
Ну, сложный вопрос, сейчас я не знаю, наверное, к нему удачно ответить
Дизайн ясен, ты хочешь разделить ячейки, которые не испытывают на себе не синхронизированного конкурентного доступа
И ячейки, которые испытывают
Ну, то есть довольно естественно, давайте классы явно разделить
И отдельно про них сравнивать какие-то гарантии
У нас формально это не будет?
Сейчас, ну, давай я так скажу
У тебя есть atomic с операциями relax, потому что, может быть, тебе нужен atomic как интерфейс к атомарным операциям более сложным, чем loadstore
Но никакого memory order форсировать там не нужно
Вот, а может быть, у тебя может быть один atomic
Ну, собственно, у нас будет в примере всего сейчас atomic, где одна операция может быть relax, а другая может быть там release
Ну ладно, не бывает такого, что только release, relax, разумеется, должен быть acquire
Ну, короче, вот в пределах одного atomic можно использовать прям вот разные варианты
Три разных варианта можно использовать
Но это все еще атомарный ячейк памяти
Она вот как бы вписана в гарантии atomic в модели памяти
Разумно ее отделить, мне кажется
Давай посмотрим на какой-то пример
Ну, пример самый незамысловатый, но нужно его аккуратно обсудить
Вот нам нужно написать spinlock
И по какому принципу мы в нем будем memory order расставлять?
Какими соображениями будем руководствоваться при этом?
Это самое важное
Вот почему нам нужны, что мы хотим отсекомолвить?
Вы знаете, когда мы говорим про упорядочивание, мы уже упорядочивали, что мы уже упорядочивали
И мы уже упорядочивали, что мы уже упорядочивали
И мы уже упорядочили, что мы уже упорядочили
И мы уже упорядочили, что мы уже упорядочили
И мы уже упорядочили, что мы уже упорядочили
И мы уже упорядочили, что мы уже упорядочили
И мы уже упорядочили, что мы уже упорядочили
И мы уже упорядочили, что мы уже упорядочили
Что мы уже упорядочили
Что мы уже упорядочили
Смотрите, порядок на атомиках возникает просто в силу исполнения, в силу гарантии матрики памяти
На каждом атомике есть порядок за амбисей
Не нужно ничего делать, он просто уже есть
Определили матрику памяти, у FK шуток
Когда мы ставим numRewarder, мы всегда думаем не про атомики
Хотя мы уже ставим атомики
А мы думаем про не атомики, про не атомарные обращения памяти
Потому что мы не на них упорядочили
Мы хотим обеспечить видимость happens before без не атомарных обращений памяти
И вот такой универсальный ответ
Какие не атомарные обращения в памяти мы хотим в этом?
С помощью спинлока
Те, которые случаются между спинлоком и амблоком
Матрическая секция
У нас есть спинлок
Мы используем спинлок в матрической секции
Вот эти матрические секции в разных потомах происходят
И эти матрические секции зачем они вообще появились?
Потому что, видимо, потоки работают с некоторыми делами состоянными
С некоторыми общими ячейками и не читают, а пишут
И вот у нас был потом, который обращался с ноги
Писал какие-то не атомарные ячейки
А другой поток в следующей секции решил прочесть
Вот два обращения
К одной это же ячейки памяти
Конфликтующие пары
Конфликтующие пары обращения
По крайней мере, одно зависит
И в разных потомах
Значит, просто по требованиям нашей модели
Такие конфликтующие не атомарные обращения
Обязанны быть спрятаны, что через хэббл-грифон
Но они в разных потомах
Значит, хэббл-грифон, как оно образуется?
Ну, есть программа ломинг, да?
Делать одного потомка
А как распишите happens before
Между записями и чтениями в разных потомках?
Ну, вот happens before складывается из двух компаний
Из программа отора и Synchronize with
Нужно Synchronize with
Вот хорошо, чтобы здесь возник Synchronize with
Когда он возникает?
Когда есть какой-то атомик, через который
Допустим, программируется
Когда один потомк читает то, что записал другой
Но что делаем мы вот здесь в онлокере?
Мы говорим
Log
Store
0
Что мы делаем в онлокере?
Мы крутимся, да?
Мы пишем while
Log
Exchange 1
И вот, когда мы здесь запишем 0
И когда мы здесь его увидим мы из циклы
То есть мы ждем, пока Exchange не прочтет
Ноль записанной где-то в онлокере
И вот тогда
Говорят их и начинают заслуживаться
Если у нас будет между вот этим онлоком
И этим локом станет заслуживаться
То значит будет пример позже порт
Принадлительности отначить
Вот это чтение оказывает увидеть
Свету записи из предшествующей секции
Ну это вроде бы то, что мы добивались
Но теперь можно ослабить наши номере ордеры
Программа ордера у нас так будет
Что бы мы не делали
Какие номере ордера мы не оставили
А сентябрьисуис возникает либо между
Секунджской консистенцией
И чтением
Либо между лидерами
Кажется, что можно здесь ослабить до релиза
Ну и вот
И вот
И вот
И вот
И вот
И вот
И вот
Оно здесь ослабится в металличном доме ордера
Ну вот смотрите
У нас здесь
Чтение это операция
Она более сложная
И чем просто чтение
Она и чтение, и запис
В данном случае нам не важно
Тут есть запись
Нам важно, что это чтение
И вот это чтение должно быть аккуратно
Чтобы здесь возникло сентябрьисуис
Чтобы мы получили
Ну почему-то там не важно, что это еще и запись
Ну как бы
Ну это благо
Как мы собираемся использовать
Что нам нужно
Нам нужно обеспечить
У порядка, что они не томатно отборщены в памяти
Через каком-либо форме лидерической инсекции
Ну вот мы обеспечены
Просто у нас может быть два спинного позиций
Я еще не понимаю
Что-то ну два спинного, а у них две
Ну и они должны
Кажется, что между лидерическими секциями
Дороза спинного
И тут гарантии нет
Я так говорю
У нас на блоке они совершенно независимы
Ну они могут
Exchange единица
Нам нужно, чтобы ровно один
Минут пиломан
Второй
И
Кто-то, кто видит, может поставить
Диаминсу
И второй должен быть
Диаминс
Ну это же вот
У нас есть один андроид
И вот на нем есть modification order
Modification order
Мог есть всегда
Даже если
Даже если
Тут такая базовая гарантия
А я не помню
Объяснял я вам почему
Из modification order
Ну в смысле
Что
Modification order
Modification order
Понятно, сквозной на одном лампке
Из него не следует
Modification order
Понятно или нет?
Ну вот скажем
Программа такая
У нас есть четыре потомка
Один пишет в X
Другой пишет в Y
Третий
Читает
Из X
Читает
Из Y
Четает
Из Y
Читает
Из X
И можно ли увидеть
Один ноль, один ноль?
Можно
Если мы используем
Remaxed
или API release
Вот потому что вот на каждом
Оторнике
Сносится на каждый
Ичейкин
Будет modification order здесь
То есть все записи
Они у нас Remaxed
На каждой ячейке
Есть modification order
Ноль, один
И этот поток читает
Пусть
Ноль
А этот читает
Пусть, один
А этот поток
Саксона, ноль
Но это равные
В порядке нерасогласованные
В итоге
Будут видеть
Два потока
Как будто бы
Наблюдают
Разную
Разную
Последовательную
Запись
Две ячейки
Но это modification order
В них не представляется
У таких примеров есть
Называется
Independent reads
or
Independent writes
Ну вот
Спинок мы разбрали
Да?
Не впечатляю
Еще раз
Обращаю внимание
Что
Мы
Оставляем
Мои ордеры
Думая не про атомики
А думая
Наоборот
Про неатоматные
Ячейки в памяти
Собственно
Доступ Которые
Мы не упорядочно
Всегда
Нужно думать
Про
Эти самые
Обращения
Снаружи
Которые
Кодятся
На блоке
Вообщения
А вот
Про пример
Где мы
Считаем
Количество
Просто
Хороших обращений
Мы же там
Не можем
Сделать
Неатоматных
Потому что
Прямо скажем
Нам нужен фичет
Да
То есть
Мы пользуемся
Здесь тем
Что атомик
Не используется
Для упорядоченного
Не обращения
К памяти
То есть
Не то, что мы
Не читаем
Какие-то
Еще 4 квеста
Думаем
А вот
Значит
Какая-то
Другая ячейка
В программе
Тоже что-то
Там равна
Или что-то там
Соединить
Мы так и думаем
Поэтому для таких
Сцена
Релакса достаточно
Итак
Значит
Мы здесь
Думали про неатомарные
Ячейки памяти
И возвращаемся
В
Так что вот
Для порядка
Здесь мы напишем
Релиз
А здесь мы напишем
И идем дальше
Следующий пример
Это
Ну мы его уже видели
В лекции про кэши
Это циклический буфер
Массив фиксированного размера
С ним работают
Два потока
Один поток
Почему-то я сбросил
Все хорошие названия
Отлично
Один поток
Продюсер
Пытается в этот
Циклический буфер
Что-то писать
Для этого
Он читает хед
Читает тейл
Смотрит если
Тейл
Еще не догнал хед
То
Пишет
В буфер
По индексу
Тейл
И двигает
Тейл вперед
Ну с учетом
За циклический
Буфер
По индексу
Тейл
И двигает
Тейл вперед
Ну с учетом
Ну с учетом
За цикливание
Консьем
Действует симметрично
Читает хед
Читает тейл
Смотрит если
Буфер
Не пуст
То извлекает
Элемент из головы
Буфера
И двигает
Тейл
Хед
Вперед
Вот мы на лекции
Про кэши
Оптимизировали здесь
Работу
Оптимизировали
Фолл шеринг
Так чтобы
Продюсеры
И консюмер
Работали с разными
Шлиниями
Когда они
Добавляют хвост
Извлекают из головы
Но сейчас у нас
Другая забота
Сейчас мы
Пытаемся расставить
Оптимальные
Memory order здесь
Про кэши
Можно подумать
Ну в смысле
С кэшами
Там можно скомбинировать
Ну давайте
Подумаем
Какие memory order
Можно здесь
Ну в принципе
Поставить
Смотрите
У нас есть
Два потока
Они общаются
Между собой
Один другому
Посылает
Другой
Извлекает
Обрабатывает
Продюсер
Видимо
Тут нам
Не нужен
Никакой
Sequential consistency
Нам будет
Достаточно
Happens before
То есть
Release acquire
Наверное
Но
Но кое-что
Можно заметить
Сразу
Смотрите
Вот есть
Продюсер
Он читает
Head и tail
А потом
После того
Как положит
Tail
И больше
Никто
Кроме него
Tail не двигает
То есть вот
Tail
Меняет
Только один
Поток
Вот это
Означает
Что здесь
Можно
Поставить
Relax
Потому что
Просто
В силу свойств
В смысле
Однопоточный
Код
Обязан
Свои же
Записи
Видеть
Поэтому нам
Никакие
Больеры здесь
Двигает
Вперед
Head
Поэтому он
Своё собственное значение
Тоже всегда
Видит
Ну а теперь
Подумаем
Какие
Не
Атомарные
Обращения
Мы хотим
Упорядочивать
Строчки скажи
29
Ещё раз
Я повторяю
Что
Упорядочиваем
Всегда не
Атомарные
Обращения
К памяти
Если ты
Думаешь про
Атомики
То ты думаешь
Не в ту сторону
Ты неправильно
Пользуешься
Модой памяти
Memory order
Для упорядочивания
Не атомарных
Обращений
Вот какие
Не атомарные
Обращения
Нужно упорядочивать
Какие
Не атомарные
Обращения
Подумать
Какие
Попробуем
Упорядочивать
Какие
Записи должны быть
Видны
Каким
Чтением
Ну
Из
Empty
На
Тридцать первой
Строчки
Должны
Видеть
Что
Мы
Мне вот
Из Empty
Кажется
Работает
С двумя
Регистрами
Ммм
Но мы
Уже положили
А
а потом мы в консьюме из этого буфера читаем.
Ну вот для примера, пусть у нас есть слот 42,
и продюсер сначала пишет слот 42,
а потом консьюмер когда-нибудь читает из слота 42.
Вот это одна и та же чейка памяти.
К ней есть два конкретующих обращения,
записи здесь и чтение здесь, из разных потоков.
Поэтому они должны быть упорядочно через HappensBefore, думаем мы.
А вот дальше думаем, как это обеспечить HappensBefore
между двумя этими обращениями.
Ну давай помедленнее.
Вот я, поток-продюсер, что я делаю?
Я пишу в слот 42 значение x.
Потом я пишу в tail 43.
Потом я, продюсер, пишу в слот 43 y.
Потом я пишу в tail 44.
Потом проходит еще много времени,
потом я что-то еще делаю, пишу в tail значение 51.
Консьюмер пусть пока сейчас не исполняется.
Потом возникает консьюмер, он читает Head.
Ну как вообще консьюмер мог дойти до чтения слота 42?
Вот здесь вот.
Что он должен был для этого увидеть?
Ну видимо он должен был прочесть из Head 42.
А чтобы читать слот 42, он должен быть уверен,
что буфер не пуст.
То есть, что tail больше, чем 42.
Ну и вот допустим, консьюмер прочел из tail 51.
Какие выводы из этого делает консьюмер?
Что видимо буфер точно не пуст,
и что в слот 42 продюсер уж точно записал.
Ну потому что вот написал он здесь,
а перед этим он написал много раз в последующие слоты,
значит и в 42 уже тоже написал.
Ну то есть вот мы пользуемся причинностью.
Если мы увидели в tail 51, то мы уверены,
что продюсер написал уже в слот 50, 49, 48 и так далее, 42.
Ну а чем это, то есть это причина,
с которой программист ожидает,
а чем она обеспечивается в коде?
Ну видимо synchronizes with happens before synchronizes with.
Ну и как мы это сделаем?
Мы вот здесь напишем видимо release, да?
А здесь мы напишем...
Ну вот, мы добились чего хотели.
Но у нас осталось еще что-то, вроде бы пока это все не нужно.
Давайте мы поступим оптимистично.
Здесь что еще осталось?
А, вот здесь еще.
Ну ничего, вспомнишь.
Тут 4 строчки, в смысле 6 строчек.
Оперативный памятник человека, 7 элементов.
Можно запомнить.
Да, мы не исчерпали еще.
Ну вот, смотри, здесь мы читаем собственный tail, да?
Вот здесь, поэтому нам не нужен никакой memory order.
Мы свои записи собственные видим в платоке.
Здесь мы пишем release в продюсере для того,
чтобы консюмер, который увидел наш tail,
был уверен, что он увидит и записи,
предшествующие этому tail у слоты продюсеру.
Вроде все логично.
И теперь можно запустить вот этот код,
который запускает два потока,
запускает их под ThreadSanitizer.
И посмотреть, что произойдет.
Произошел DataRace.
DataRace чего с чем?
Try produce строчка 22
и try consume строчка 46.
Подозрительно, потому что мы это упорядочили.
Но на самом деле немного хитрее все.
И даже по этому отчету можно понять,
что несколько хитрее.
Есть у вас идеи, что пошло не так?
Потому что ThreadSanitizer здесь дает вам подсказку.
Не то чтобы он про нашу программу что-то знает,
но...
В общем.
Объясните мне, почему мы получили DataRace,
хотя мы упорядочили продюсера и консюмера?
Когда надо переписывать?
Когда надо переписывать?
Что нужно, простите.
Как меня переписывать?
Да нет, нужно переписывать программиста.
В смысле поменять.
Ну чего, нет идей?
Вот смотрите же, тут что-то идет...
В смысле, вроде бы мы исправили RACE
между упорядочили записи чтения, да?
Упорядки у нас снова, записи чтения.
Но тут написано интереснее, что у нас продюс,
то есть вот эта запись, она гоняется
с предшествующим консюмом.
Нужно понять, что происходит.
Прежде чем что-то исправлять,
всегда в любом баге нужно понять, в чем он состоит.
Мы упорядочили продюс и консюм, да?
Но при этом у нас транслятор говорит про другое.
Он говорит, что у нас сейчас продюс в этой строчке
гоняется с вниманием предшествующим консюмом
вот в этой строчке.
Нужно подумать.
Нет, не получается.
У нас буфер циклический.
Мы упорядочили первый продюс с первым консюмом.
То есть первую запись слота 42,
с первым чтением из слота 42.
А дальше у нас буфер загругляется,
и мы снова пишем 42.
И вот мы первое чтение не упорядочили со второй записью.
То есть смотрите, вот мы здесь, уже в продюсере,
прочли хед,
и мы читаем хед.
Давайте зафиксируем.
В хеде мы прочли 37,
а в тейле мы прочли 31.
Нормальная ситуация для буфера, который пошел на второй круг.
И смотрите, мы уверены, что мы можем в тейл 31 записать что-то.
Почему?
Потому что хед больше,
то есть консюмер уже подвинул хед,
а значит уже перед этим прочел.
Но опять рассуждение.
Мы смотрим на ячейку, а перед ней была другая запись или чтение,
значит она уже случилась.
Ну или давайте вот так прям совсем плотненько, чтобы было 33.
Вот мы читаем currentHead 33,
мы уверены, что консюмер уже из слота 32 и 31 достал значение.
И значит можно туда писать.
Но пока вообще-то это ожидание ничем не подкреплено в смысле порядков.
Потому что здесь просто стоит relaxed,
и мы не можем на основе еще раз relax-чтения хеда
делать выводы о других чтениях и записях.
Случились они или нет.
Поэтому мы здесь должны тоже поставить релиз
от консюмера к продюсеру.
То есть это не то чтобы кто-то увидел нашу запись,
нет вообще глобальных записей.
Но мы просто хотим упорядочить два неотомарных конфликтующих обращения.
А здесь мы сделаем aquire соответственно.
Ну вот, как бы тут гармония восстановилась,
потому что два потока были такие, они зеркальные друг друга.
Так что им реордеры теперь зеркальные.
Но это так себе объяснение.
Это скорее нас просто успокаивает.
Ну а почему это было необходимо, мы, кажется, объяснили.
Мы упорядочили с помощью этого релиза и этого aquire
первый продюс и последующий консюм.
А с помощью этого релиза и этого aquire мы упорядочили
этот консюм и следующий в цикле продюс.
Да.
В втором случае, ну да.
Но правда тут было бы еще проще, потому что зачем нам было бы читать.
Ну ладно, окей.
Если бы у нас был бесконечный буфер, то...
На самом деле бесконечно растущий массив
это даже то, что мы сделаем в одной из...
где-то там близко к финальным сложных...
в одной из лекций, которая будет близко к финалу курса,
мы будем говорить про локфри-канал,
как можно сделать локфри-канал для файберов, для грутин.
Но там, в принципе, по мотивам следующей лекции
из той очереди, которую мы придумаем на следующей лекции в эту субботу,
мы построим расширяющийся бесконечный локфри-массив.
Но это такое будет.
Не самое очевидное действие.
А здесь у нас циклический буфер,
и циклические буферы у нас будут еще в планировщике.
И, в общем, вот тут нужно морочиться про Memory Order.
Ну либо не морочиться, просто писать default,
и тогда просто программа будет исполняться.
Ну, этот буфер будет работать там в два-три раза медленнее, но зато...
Ну я показывал в прошлый раз... Ой, на лекции показывал уже.
Сейчас можно воспроизвести, наверное.
Я не уверен, что быстро получится.
Получится ли вообще?
Давай вспомню.
Тут уже все расставлено, да?
И...
Сейчас давай я покажу, как он сейчас работает,
а потом закачу все обратно.
А дальше начнем закатывать.
Значит, нам нужно вот эту оптимизацию закатить.
А, нет, так несчастно, да? Мы хотим закатить только Memory Order.
Ну, давайте попробуем.
Ну вот, мы теперь... Мы сейчас заменяем все load и store.
Ну, все store, которые раньше были move, мы сейчас заменяем на Exchange.
А все load мы заменяем с move на move тоже.
Ну, если вы помните, что там во что комперируется, то...
Ну, я в смысле про Assembler, который меняется.
Вот loadRelaxed и loadSequentialConsistency,
в x86 это просто move. Ну, все loadы одинаковые.
А store, вот...
Так, ладно, запустим.
Кажется, я все поменял.
Стало хуже.
Да, все поменял.
Тут, правда, есть что-то.
Тут, правда, и компьютер нагрелся, поэтому надо сейчас...
восстановить.
Выкатить обратно, и...
Нет, снова быстро работает, значит...
Эффект устойчивый.
Ну, вот так вот.
Кажется, что пример уже был.
Кажется, что пример уже достаточно нетривиальный,
и вот я еще раз обозначаю самый важный момент,
что чтобы расставлять memory-order, нужно понять, зачем расставлять memory-order.
Они расставляются...
Они ставятся на атомиках, но думать нужно не про атомики, а про вот все вокруг них.
Сначала найти неатомарные обращения к памяти, которые мы собираемся упорядочить
с помощью атомиков.
И дальше уже думая о них, про happens before между ними, прогонки между ними,
расставлять memory-order на атомиках.
Вот, не думаю, что где-то в документации на себе референс написана вот эта интуиция,
а вот вокруг нее все...
Без нее невозможно.
Без нее все это превращается в какую-то, не знаю...
Ну, попытку угадать.
Тут понятно, что у нас есть два потока, там один пишет, другой читает,
поэтому, наверное, release acquire, но это вот...
Может быть, это приведет к правильному результату, но...
Логики за этим, мне кажется, никакой не стоит.
Просто какое-то формальное синтактическое рассуждение.
Вот здесь, пожалуйста, есть...
Да, ну и еще раз пример, что на одном атомике можно использовать
разные memory-order, relax, release acquire.
Ну, вообще, смешивать не очень рекомендуется,
то есть здесь это все очень естественно произошло,
но если в программе у вас есть sequential и consistent атомики,
ну, в смысле, одни операции sequential и consistent, другие,
там, release acquire, это все об этом думать очень сложно становится.
Ну и вообще, я не знаю, честно говоря,
как люди memory-order расставляют, они их расставляют.
В простых примерах можно разумно их расставить и объяснить, почему.
А сложные примеры не такие сложные, что вот трудно понять.
Как именно, ну, то есть...
Как люди в голове все эти memory-order выстраивают.
Вот, вопрос, да.
Смешать consistent и relax, там, допустим, в двух средних атомиках.
Вот один из них требует, чтобы все атомики были, как бы,
имели какой-то глобальный порядок, что ли?
Ну, все атомики, на которые...
Все операции над всеми атомиками, которые промаркированы вот так,
вот для них будет глобальный порядок.
Но если у тебя некоторые релизы acquire, то, короче,
это все как-то начинает встраиваться друг с другом,
это сложно, сложно об этом думать.
То есть у тебя есть synchronization order на таких вот операциях,
у тебя есть happens before,
которые реализуются через вот такие операции,
у тебя есть modification order,
и все это в объединении ацикличный,
ты должен это по-честному все представить.
Поэтому лучше, ну, как бы, такого избегать
и искать каких-то простых продюсеров-консюмеров в своем кое.
Вот код, где два атомика, а не один,
это уже во много раз сложнее код.
А если там четыре атомика, то я не знаю что.
А вот... Можно я покажу?
Я, по-моему, показывал, ничего не объяснял,
наверное, уже не буду.
В задаче «Кундвар» была ссылка на «Кундвар», который петроедный.
Я вам показывал его, кажется, может быть, даже пугал ему,
потому что там буквально то ли десяток, то ли дюжина атомиков разных,
и весь код на каждой операции там memory order стоит.
Правда, не C++, а C, поэтому вот такие вот интристики, но неважно.
Короче, код сложный, очень сложный, много атомиков,
а еще к тому же в нем бага есть.
Вот «Кундвар» петроедный зависает.
То есть вы можете заснуть, получить на «Тифае» и не проснуться.
То есть разумная программа на петроедном «Кундваре» может зависнуть,
потому что «Кундвар» очень сложный, и человек не справился.
То есть он был очень умный, он очень долго думал, в 4 года,
а все равно бага получилась.
Поэтому лучше сложные вещи не писать такие.
Вот 10 атомиков — это верный признак того, что вы проиграете.
Нужно Model Checker использовать.
Ну, Refault Injection, на худой конец.
Ну, короче, как-то нужно тестировать нечеловеческим умом.
— Есть какой-то способ формально писать, что я ожидаю от программы?
— Да, есть.
Ну, это Model Checking.
Я скорее осенью про это буду на спецкурусе рассказывать,
про определенные системы, там более универсальные инструменты.
Да, ты можешь прямо написать, что я хочу прогресса,
я хочу взаимного исключения написать это на языкеологике вообще формально.
И свой код на языкеологике формально написать.
Ну, или на псевдокоде, который будет переписан в какие-то логические конструкции,
а потом эта все машина переберет за тебя.
Ну, по сути, это перебор получится, который просто строго описан.
То есть представь себе язык с формальной семантикой.
Не C++, там, где на Define Behavior какая-то абстрактная машина,
а вот прямо строгое.
Ну, вот так можно делать.
И это, по сути, единственный, ну, скажем так, Model Checker,
то есть инструмент, который перебирает все исполнения,
не важно на каком языке программа описана, на C++ или на формальном языке,
тебе нужен инструмент, который переберет все достижимые состояния
и проверит у них все необходимые свойства.
Вот это единственный частный путь.
Вот мы и Fault Injection пытаемся увеличить покрытие графа этих состояний,
а можно прямо вот все перебрать.
Вот, может быть, в курсе это однажды случится через Gotary,
но так тоже можно делать.
О, он очень старый.
Я не знаю, но в мире пишется огромное количество кода
и до сих пор пишется без Fault Injection и Model Checker.
Просто человек смотрит на код и думает, ну, я вроде понимаю, почему он правильный,
я его напишу.
Да.
Ну, видишь, он, во-первых, написал неправильный код, во-вторых,
не могу это объяснить.
Вот если ты один раз почувствовал, что такое хорошее тестирование,
ты потом не можешь без него жить, потому что тебе неспокойно.
А хорошее тестирование требует прям больших затрат перед написанием кода.
Ты должен подготовить весь свой код к тому, чтобы его можно было
тестировать, перебирать все исполнения.
То есть ты должен перед тем, как писать код, подготовить всю свою кодовую базу
к тому, чтобы ее можно было так тестировать.
Это очень дорогое удовольствие.
Ну, у Petrata они гораздо старше, чем люди так стали делать.
Вот есть не так уж много мест, где люди так пишут код.
Ну вот, мы пишем код так.
Без этого кажется невозможно.
Я не знаю, даже в чате уже задачи Slipforge страдают,
потому что она исполняется недотерминированно.
Почему? Потому что в ASIO нет Fault Injection,
потому что мы не можем тестировать задачу под файберами,
потому что внешний библиотек, она не адаптирована к этому.
И вот уже мы лишились Fault Injection, лишились файберов,
и все уже стало работать хуже.
Стали тесты хуже работать, изменение предсказуемо.
А бак там очень простой.
Так что то, что у нас в домашниках работают тесты,
и мы это принимаем как должное, это на самом деле нифига не должное.
Это очень большая работа, потому что они так работали предсказуемо.
Вот без этого код тестировать сложно.
Люди все равно до сих пор пишут код,
полагаясь на собственный опыт.
И в какой-то степени их можно понять.
Ну то есть если они действительно понимают, что они пишут,
то скорее всего они пишут без ошибок.
Но как отличить это, скорее всего, от действительно без ошибок?
А вот ЧВАП1 писал ли?
По-моему, этот код, у него автор один,
ну и там бак уже достаточно давно существует,
но вот он не поправлен на сих пор.
Кажется, что никакого простого способа поправить его нет.
Кажется, бак довольно фундаментальный.
Просто за 4 года это не попробовать?
Ну какие-то тесты наверняка есть,
но вот бак, он очень сложный, там много шагов,
и вот просто стресс-тест, там он не поймается.
Нужно, чтобы случилось очень много маленьких шагов в очень правильном порядке.
То есть число состояния очень большое.
Нет.
А можно еще вопрос про...
Вот вы сказали, что x86 архитектура на некоторые гарантии сама в себе несет?
Да.
То есть получается, у вас на сервере тестируется не под x86, чтобы...
Под x86.
Ну смотри, ты можешь написать memory-ордеры неправильные,
то есть слабее, чем ты имеешь право.
То есть ты можешь написать спинлок с релаксом.
И поскольку он скомпилируется в тот же самый move, то никакой проблемы не будет.
Но тесты запускаются под thread-санитайзером.
А thread-санитайзер...
Ну я вообще-то надеялся про это рассказать.
Может быть, на следующей неделе я расскажу.
Вот thread-санитайзер явно отслеживает happens-before.
То есть ему неважно, там реализуется бага или нет.
Но если у тебя была критическая секция, а потом другая,
и вот между обращением к памяти у тебя не выстрелилось happens-before формального,
то как бы неважно, что ты на процессоре на текущем прочьешь то, что хочешь.
Просто thread-санитайзер поймет, что у тебя формально упорядочивания не было
из-за репорта датарейс.
Ну собственно, чего я далеко хожу...
Вот мы пример видели только что.
Это же он и был.
Мы поставили здесь relaxed.
Relaxed на x86 не отличим от release-acquire,
а при этом thread-санитайзер ошибку нашел.
То есть он просто вот честно отслеживал happens-before,
понял, что его не было.
Но при этом программа, если мы ее компилируем
под x86 без thread-санитайзера, под release-ом,
то она будет исполняться всегда правильно.
На арме уже может неправильно исполняться.
На тестирующем сервере у нас x86,
но мы надеемся на thread-санитайзер.
Вот такая история.
Вот, давайте закругляться.
