Тема нашей сегодняшней лекции это примитивы синхронизации и вообще параллельное
программирование. С помощью параллельного программирования решается достаточно широкий
класс задач, который без него было бы решить достаточно тяжело и в этом смысле без него мы
сейчас уже обойтись практически не можем, особенно учитывая, что все современное развитие аппаратуры
оно в первую очередь направлено на увеличение количества ядер. По производительности одного ядра
мы пробуксовываем, так скажем. Нельзя сказать, что развития в этой области прям совсем нет,
но оно совсем не такое быстрое, как некоторое время назад. Но с использованием параллельного
программирования есть некоторые проблемы и, пожалуй, основная из них заключается в том,
что люди плохо приспособлены для того, чтобы писать параллельные программы. Это отдаётся очень
тяжело, а еще тяжелее дается писать параллельные программы без ошибок и, собственно, поэтому
появляется много всяких смешных картинок и комиксов в интернете, но, несмотря на проблемы,
все равно приходится использовать без этого никуда. Сегодня мы рассмотрим материал в таком
порядке. Сначала поговорим про аппаратные возможности по синхронизации в самой платформе и то,
как язык C абстрагирует эти возможности. Дальше мы поговорим про блокирующие примитивы
синхронизации для создания параллельных программ. Ну, это, по сути, это локи. После этого поговорим
немножко про не блокирующие примитивы, это про атомики. Ну, у нас еще в конце, где-то в районе
12 лабы будет такая более обширная лекция про атомики и про не блокирующие алгоритмы. Сейчас мы
так это пока чуть-чуть затронем. И в конце поговорим про самые такие основные классы ошибок,
которые встречаются при использовании разных примитивов синхронизации. Ну и перейдем уже
к сдаче лабораторок. Для начала я бы хотел задать вам вопрос. Как вы думаете, если у нас есть
программа на языке C, которая считывает одновременно из нескольких потоков глобальную переменную,
возможно ли такое и что будет происходить? Нет, ну а если да, если у нас только считывание.
Хорошо, а если будем записывать? А что может произойти, если мы не будем этого делать?
Ну да, на некоторых архитектурах может быть так, что вообще там записи
перемешаются и половина числа от одного потока запишется, вторая половина от другого. Ну и
соответственно раз записывать нельзя, то и параллельно считывание записывать тоже.
С точки зрения ассемблера в принципе никто вам не запрещает это делать, ни то ни другое. Но
с точки зрения именно стандарта языка C, да, чтение в стандарте определены как поток
безопасный, операции записи не являются потоком безопасными, то есть если мы только читаем
переменную, если она какая-то константная, то в принципе можно даже никаких дополнительных
действий не предпринимать, хотя зачем вам считывать константную переменную, ее можно и так в коде
записать. Ну бывает конечно иногда случаи. Ну допустим, допустим там, не знаю, когда-то в самом
начале записали один раз переменную, а потом мы, после этого мы уверены как бы, что следующие
потоки они уже запустились после того как сделана эта запись. Каким-то другим образом мы эту
гарантию получаем. В таком случае, да, чтение будет thread-safe. Или, например, если это была
проницилизирована переменная заранее, то есть до запуска программы операционная система,
когда загружала файл, проницилизировала область и ее можно спокойно считывать после этого.
Да, значит, операции записи не потоку безопасные и, соответственно, для того чтобы мы все-таки могли
эти операции делать, в C существует специальный набор инструментов. Например, это атомарные
операции из header-std-atomic.h. Про них мы поговорим чуть позже. С точки зрения логики, вообще говоря,
если у нас есть какой-то разделяемый ресурс, например, участок переменная памяти, то не может
быть такого момента, что мы одновременно к ней получаем доступ. Причем, если начтение и записи
одновременно еще как-то там может быть, то если это, например, две записи, то одновременно их быть
не может. Они в любом случае должны быть как-то упорядочены. Либо внутри на уровне железа,
либо уже самим программистам. И здесь появляется такая абстракция, как критическая секция.
Что это такое? Таким образом называют участок кода в программе, который предназначен для
обращения к какому-то разделяемому ресурсу. И смысл здесь в том, что внутри этого участка кода в
один момент времени может находиться только один поток. То есть один поток его выполняет,
все остальные ждут. У примитива критической секции, как правило, есть две операции. Это,
соответственно, захват секции и освобождение. То есть, как правило, как происходит работа. У нас
есть несколько потоков, в котором нужно обращаться к одному ресурсу. Это, в принципе,
может быть и область памяти, и какое-то устройство, и там, допустим, порт в процессоре. У нас в
процессоре есть память, в интеловской архитектуре, по крайней мере, есть память, есть пространство
портов. Вот когда, если кто-то делал четвертую лабораторку, то вы как раз пользовались портами.
Соответственно, у нас есть несколько потоков. Какой-то первый поток, допустим, добрался до входа в
критическую секцию, он сделал операцию по ее захвату, и после этого, когда остальные потоки
делают операцию по захвату секции, они просто ждут, пока она освободится. Первый поток в это время
выполняет какую-то свою работу, закончил и вызывает операцию освобождения критической секции. После этого,
соответственно, будет выбран следующий поток, который ее выполняет.
Здесь критическая секция нужна для того, чтобы синхронизировать доступ к ресурсу. Само по
себе именно код, который исполняется, в принципе, не обязательно, что это должен быть один и тот
же участок кода, по которому все потоки идут, но у них должно быть какая-то общая сущность,
через которую эта синхронизация происходит. Чуть попозже, когда я буду говорить про реализацию
критической секции, я думаю, будет понятнее. Про захват и освобождение я уже сказал. Еще в некоторых
реализациях таких более продвинутых бывает операция try lock, то есть попробовать захватить,
но если не получилось, то не ждать, а вернуть какое-то там ошибочное значение, и тогда можно
продолжить программу как-то по-другому. И еще одна операция, которая бывает реализовывать,
это проверка из locked, когда мы не хотим захватывать секцию, но просто хотим проверить,
захвачена сейчас или нет. Здесь есть один важный момент, это то, каким образом выбирать
следующий поток после освобождения критической секции. Зачастую на реальных машинах
у нас топология ядер может быть таким образом сделана, что там шина данных, она не совсем
одинаковая. Точнее, задержка доступа к памяти, она не совсем одинаковая у разных ядер процессора.
Допустим, в современных AMD сервенных процессорах, например, они организованы в блоке ядра в
процессоре. И теоретически там на пару секунд у одного ядра может быть больше задержка, чем у
другого. И если мы будем просто выбирать следующий поток, который должен войти в секцию просто по
принципу, кто первый сумел захватить, тот и продолжает, то мы можем попасть в такую ситуацию,
когда один и тот же поток, если он, например, в цикле захватывает критическую секцию, он так и
будет один и тот же поток в цикле в нее входить, а все остальные будут бесконечно ждать. Чтобы
такого не происходило, почти во всех существующих реализациях, которые работают на практике,
применяются те или иные способы, как можно обеспечить, ну, по-русски обычно не говорят
справедливость, обычно используют термин fairness. То есть, например, здесь на слайде
приведены пары алгоритмов, таких самых простых, как можно это сделать. Ну, алгоритм ticket-lock это
просто обычная очередь. То есть, как с бербанки, мы приходим, получаем, когда поток захватывает секцию,
он получает там какой-то номер, встает в очередь и, соответственно, в том порядке, в каком они
захватывали секции, так они будут в точно таком же порядке, они в нее и войдут.
Ну да, есть, действительно, в операционной системе, когда мы пользуемся критическими секциями,
действительно реализован такой механизм, что когда поток встает в ожидание, он, как правило,
снимается с исполнения в этот момент и процесс переходит в какое-то другое состояние, а-ля спящие,
это уже детали реализации, то есть, в зависимости от того, как планировщик реализован в операционной
системе, в принципе, это не обязательно. Можно реально просто в цикле ходить, жечь
электричества, это с точки зрения именно логики работы, это на это не влияет. Так, ну и вот мы
переходим непосредственно к примитивам синхронизации, то есть, критическая секция,
это такая абстракция, которая, в принципе, она может существовать не только в софте,
она примерно в таком же виде существует и на уровне железа, то есть, в процессоре тоже
есть критические секции для доступа к памяти в первую очередь. До того, как появились аппаратные
возможности атомарного доступа, примитивы синхронизации были сделаны с помощью какой-нибудь
внешней сущности, на которую мы можем временно переключить исполнение, чтобы она проверила,
чтобы она проверила, захвачен ли сейчас ресурс, выбрала, если не захвачен, то выбрала,
какой поток должен следующим войти в критическую секцию и так далее. Как правило, как это происходило,
программа, которая хочет захватить критическую секцию, генерирует прерывания, поскольку контроллер
прерываний у нас один в системе, то мы в этот момент можем заблокировать приход других прерываний,
после этого мы попадаем в операционную систему, в ядро, и она как раз является такой внешней
сущностью, мы можем специально сделать так, чтобы она работала только в однопоточном режиме,
чтобы у нас не было никаких проблем. Вот мы выпустили прерывания, попали в операционную систему,
в ядро имеется в виду, сделали там какие-то операции, добавили поток в очередь, решили,
какой поток нам надо переключиться, уже переключились обратно из ядра, программа
делает то, что она хотела сделать в критической секции и снова генерирует прерывания для того,
чтобы критическую секцию отпустить, освободить. Да, я как раз про них буду говорить чуть попозже.
На прерываниях они как раз уже практически нигде не сделаны, за исключением, ну на одноядерных
системах можно делать это через прерывания, но как вы понимаете, процесс генерации прерывания
он весьма затратный, и пожалуй единственный его плюс в том, что вот как раз операционная система,
поскольку мы в нее, мы попадаем в ядро операционной системы, там мы можем решить,
что если потоку нужно ждать, то мы можем его снять вообще с исполнения, чтобы он не тратил в пустую
вычислительные ресурсы. Самый классический пример реализации критической секции – это
mutex от слов mutual exclusion. Это как раз примитив, который позволяет защищенную им секцию
исполнять только одному потоку в определенный момент времени. То есть вот пример кода,
у нас есть операция захвата mutex. Дальше здесь зачастую бывает удобно иметь рекурсивный mutex,
когда мы можем несколько раз делать в одном и том же потоке захват этого mutex. Как правило,
это удобно для реализации всяких библиотечных функций, чтобы тот человек, который их использует,
не заморачивался о том, что там надо захватывать, что там не надо. У нас есть операция захвата,
внутри после нее сразу можно делать какие-то действия, которые можно делать только одному
потоку в один момент, и после этого мы вызываем процедуру unlock и выходим из mutex.
Как правило, рекурсивные mutex сделаны таким образом, что повторный lock ничего не делает,
он только будет потом в конце считать, чтобы количество локов было одинаково к количеству
unlock. Еще один классический пример это симафор, это такое обобщение над mutex скорее. То есть это
критическая секция, в которой может быть, которая может одновременно исполнять n потоков. То есть
не один, там бывают такие алгоритмы, не так часто они встречаются, в которых допускается
исполнение, одновременное исполнение не одним, а несколькими потоками. Симафоры тоже бывают
рекурсивными, также в литературе встречается понятие бинарный симафор, это симафор, у которого
n равно единице. Это то же самое, что и mutex. Я сейчас рассказывал, как эти все примитивы были
реализованы раньше, в то время, когда не было аппаратной возможности атомарного доступа к
памяти. После этого, когда это все стало более-менее широко распространяться, эти же примитивы стали
реализовывать уже с помощью lock-free механизмов, и внешне они как бы остались такими же для
программиста. Но при этом внутри они уже как бы являются не совсем блокирующими, потому что они
уже не используют вот эти все механизмы с окруживаниями и всем таким. Но понятие осталось,
и здесь существует такая небольшая путаница, что, как правило, алгоритмы, которые используют
локи, они являются блокирующими, но они называются блокирующими, но внутри эти локи уже могут
быть реализованы и не обязательно с помощью блокирующих примитивов. Так, значит,
атомарные операции бывают нескольких видов, то есть самое основное это чтение и запись,
и в принципе на их основе уже можно реализовать достаточно много всего. Здесь есть даже целый
класс алгоритмов, который называется weight-free алгоритмы, которые используют только атомарное
чтение и запись. Как правило, они используются во всяких real-time-системах, в которых
обязательно в которых необходимо высчитывать гарантии времени исполнения. То есть мы в любой
момент программы должны знать, сколько времени она будет выполняться, даже в худшем случае. Но
этого недостаточно для того, чтобы реализовать примитивы синхронизации типа критических секций,
и поэтому существует еще как минимум две операции. Это compare and swap и пара load link
store conditional. Кто-нибудь встречался из вас с таким? Мало ли, может быть там.
Эти две операции, они взаимозаменяемые, их еще в литературе зачастую называют базисными,
то есть вот как раз с помощью них можно строить всякие разные лог-free алгоритмы, и при этом,
по крайней мере с точки зрения теории, они взаимозаменяемые, то есть можно реализовать
одну через другую. Поэтому, как правило, архитектуры реализовывают либо одну,
либо другую. У нас есть только одно исключение, это ARM, в которых в последней версии издались и
все-таки сделали тоже compare and swap. Я здесь сразу покажу пример, думаю так будет понятнее.
Операция compare and swap, здесь на примере указано, как можно реализовать функцию захвата критической
секции с помощью одной либо другой операции. Операция compare and swap принимает на вход три
аргумента, это переменную, в которую мы хотим записать значение, то значение, которое мы там
предполагаем, что оно там сейчас есть, и третий аргумент, это значение, которое мы хотим туда
записать. Что делает эта операция? Она считывает переменную, проверяет, сравнивает ее со вторым
аргументом. Если сравнение произошло успешно, то мы туда записываем значение по третьему
аргументу и возвращаем true, что операция прошла успешно. Если же в переменной оказалось не то,
что мы ожидали, то запись не происходит и возвращается false. Эта операция атомарная,
то есть это все происходит как бы за одно действие для внешнего наблюдателя. Ну и как бы вот в качестве
примера, если мы, допустим, у нас есть флаг, который как раз обозначает захвачен у нас мютекс или нет,
то есть если флаг выставим в true, значит он захвачен, если false, то он свободен. И когда мы
хотим захватить этот мютекс, мы проверяем с помощью этой операции в цикле захвачен или нет,
если он не захвачит, мы туда записываем значение true и возвращаемся из этой функции и мы в
критической секции. Если же он в этот момент захвачен, процедура CAS будет возвращать все
время false и мы будем крутиться в цикле до тех пор, пока у нас не получится все-таки эту
переменную захватить. Здесь понятно, как работает. В операциях load, link, store, conditional операцию
чтения и записи были разнесены на две, то есть тут это все прям одной инструкцией выполняется,
и как вы можете увидеть, в основном это все CAS реализовано на всяких таких более больших
архитектурах, а на тех архитектурах, которые изначально задумывались как строго риск,
такие операции, в которых есть три аргумента, это уже слишком много и поэтому там были
позеленное разделение их. Что здесь, как здесь происходит операция? Сначала мы с помощью функции
load, link считываем значение флага, при этом в отличие от обычной операции чтения у процессора внутри
есть специальный регистр, его не видно снаружи, но как правило реализация происходит именно так. Там
внутри есть специальный регистр, который после использования операции load, link в нем запоминается
значение, которое было считано, и потом, когда мы после этого попробуем сделать store, conditional,
в этом процессор проверяет текущее значение этого флага в памяти и у себя вот в этом внутреннем
регистре. Если оно не поменялось, то значит все хорошо, мы можем произвести запись, если нет,
то соответственно кто-то другой уже захватил секцию и мы возвращаем false. Здесь нужно
иметь ввиду, что вот то, что мы считали значение, это не вот этот внутренний регистр, это мы его
считали для себя, а внутренний регистр он нам недоступен, поэтому мы должны сами тоже считать
это значение и его проверить в условии. Нет, это регистр, который вот всегда есть, он не может
закончиться. Это только на время одной операции, то есть он запоминается до следующего store
conditional и все. Тутс, понятно, что происходит? Тогда у меня есть парочка вопросов. Допустим,
между операцией llsc кто-то записал туда в область памяти точно такое же значение,
которое там уже было. Что тогда будет происходить, как вы думаете?
Тут как сказать, вот в примере с mutex, да, там если кто-то запишет туда такое же значение,
в принципе это не страшно. Но вообще бывают такие алгоритмы, в которых сам факт того,
что произошло какое-то изменение, это важно. Ну, точнее не изменение, а что произошла какая-то операция.
Тут само по себе запись в memory map устройства можно защитить с помощью mutex,
но саму эту запись с помощью атомарных операций делать не стоит. Это обычно,
ну, зачастую это даже запрещено архитектурой, потому что это разные вещи. Окей, а если посередине
между loadlink и store conditional мы, планировщик, решил нас остановить? Ну, в принципе,
на существующих архитектурах мы никак не сможем этот момент отловить. То есть в стандарте C для
этого существует операция, это реализовано только через componentswap, и там есть операция componentswap weak
и componentswap strong. То есть сильный componentswap, он позволяет такие штуки тоже отлавливать,
но он гораздо труднее в реализации, и поэтому его вынесли специально в отдельную функцию и объявили
его опциональным. То есть если componentswap weak всегда есть на платформе, если она поддерживает
атомики, то componentswap strong он может быть, может не быть. На x86 и на ARMv8 он есть,
наверное, есть еще на Power, а где еще, я, честно говоря, не в курсе. Да, в принципе,
с переключением контекста примерно такая же история, то есть точно также, если мы используем
операции со слабыми гарантиями и произошло переключение контекста и там не поменялось
значение, то мы этого не заметим у себя в процессе. И есть еще такая проблема в этих
lock-free-алгоритмах, которые называются eba-problem, то есть что будет, если мы сначала туда запишем
другое значение, а потом запишем снова то значение, которое там было до этого.
Можем ли мы как-то задетектить, что произошла запись?
А если у нас есть только операции со слабыми гарантиями? Можем ли мы что-то сделать как
программисты с этим? Сейчас, у нас есть поток, который очень часто считывается переменно, хорошо.
Тут как? Этот поток будет работать на одном ядре, а на втором ядре, возможно, мы еще не увидели этих
сайд-эффектов и как нам нужно как-то успеть сообщить? Вот я приведу пример. Допустим, у нас есть
список. Мы взяли, атомарно удалили из него элемент, а потом взяли и сразу же записали туда на его
место другой. Как правило, если мы, ну не как правило, зачастую, если мы освобождаем память,
а потом снова алоцируем примерно такого же размера, то очень часто может получиться так,
что указатель по факту его значение нам выдали такое же. И если это применить к значениям списка,
то у нас получается, что, допустим, мы удалили элемент и ссылку на следующий элемент у нас
стало ноль, а потом мы туда добавили и снова туда записали точно такой же указатель. По факту,
это уже элемент-то другой получился. Как нам задетектить тот факт, что список-то поменялся?
Не-не-не. Элемент списка, у него содержимое может быть другое, но мы же когда проходимся по списку,
если мы будем заглядывать в содержимое, это будет очень дорого. Как нам можно было бы задетектить изменение?
Есть даже для этого фича, что там выставляют как раз, чтобы реанализировать указатель, если между
доступами произошло рискезли. В общем, если планировщик, если было зафиксировано, что между
последним и последним указателем и тем, что у нас сейчас, планировщик не шел, то указатель нужно, типа,
это было про кэши, то есть если мы освободили память, как сделать так, чтобы другие процессоры это тоже
заметили. Это было про кэш-трансляции, наверное. А здесь просто память еще раз залоцировали в том же
месте, но память то уже другая, то есть туда записали другое значение. Ну ладно, обычно
обычно делают так. Вместе со значением новым записывают какой-то тег, который каждый раз был бы
уникальный для каждой записи, и таким образом, когда мы должны считывать такой список, то мы
должны проверить указатель и сам тег, что он не поменялся. То есть обычно решение
этой проблемы называют ABA-штрих, то есть это как бы A, но это уже не совсем тот A, который был в начале.
Ну почему? Вот, например, на x86 есть операция Compare and Swap, которая позволяет оперировать 16-байтными
значениями. То есть 16-байт – это куда два указателя помещается. И что иногда делают? В одну половину
записывают непосредственно указатель, а во второй половине у тебя есть целых 64 бита для того,
чтобы реализовать энтропию. То есть можно просто счетчик каждый раз инкриментировать и, ну например,
инкриментировать счетчик. В принципе, тегирование может каким-то другим образом быть реализовано,
но 64 бита вполне достаточно для того, чтобы там за какое-то обозримое время этот счетчик не
переполнился, а если нужно обеспечивать там гарантию на более длительное время,
то тут уже есть место для того, чтобы это как-то разрулить. Другие проблемы, связанные с атомиками,
можно продемонстрировать на таком примере. Вот здесь у нас есть два потока. Здесь опущен код,
который их создает. Ну, допустим, у нас создаются два потока, и они работают строго,
каждый на отдельном ядре, на одном и том же. Ни каких там перепланирований не происходит,
вот все просто они работают одновременно. Что выведется?
Ну, про то, что он может вывести один, здесь, наверное, понятно, да, что вот у нас второй
поток будет ждать, пока мы не запишем потом Eq и потом выведем. А может ли вывестись 0?
И что должно произойти, чтобы вывелся 0?
То есть, запись этой переменной мы увидим, а запись этой переменной мы в кшах не увидим.
Нет, вот этот поток на одном ядре работает, а вот этот на другом.
Ну, в принципе, такой вариант, конечно, тоже возможен, но если вы напишете такую
программу, то вы столкнетесь гораздо быстрее с другим поведением, из-за которого тоже выведется 0,
может вывестись 0. Но тут вообще нужно определиться с тем, что мы поднимаем под
операции atomic read и atomic write. Если это просто инструкция атомарного записи чтения, то действительно
может вывестись и 0 и единичка в конце. Но если у нас здесь под этим подразумевается такая семантика
атомарных операций, которая поделена в стандарте из оси, то тогда здесь все строго. Здесь обязательно
выведется единица, там никаких вариантов быть не может. Почему так? Здесь у нас вступает в работу
две сущности. Это компилятор, который из сишного кода нам генирует ассемблерный код, и процессор,
который ассемблерный код потом исполняет. Вообще говоря, с точки зрения стандарта си,
если мы видим в одном блоке две переменные, которые между собой никак не взаимодействуют,
то есть когда мы компилируем этот поток, то мы видим, что у нас есть в одну переменную
запись и в другую переменную запись. Они вообще никак между собой не связаны. И для таких переменных
компилятор вполне себе может их сгенировать ассемблерный код в любом порядке. То есть присваивание
может быть и вот так, и наоборот, и посередине может быть какая-нибудь еще операция туда вставлена.
Здесь у компилятора достаточно большая свобода. Это так происходит из-за того,
что он в рамках одной функции не видит взаимодействия между ними. То есть в ассемблерном
коде у нас записи могут быть в другом порядке. И уже на следующем уровне это на уровне процессора.
Современные процессоры у нас тоже делают много всяких вещей под капотом, таких как спекулятивное
исполнение и предсказание переходов и чего там только нет. И он тоже может исполнить инструкции,
если между ними нет зависимости в том порядке, в котором он захочет. Что с этим можно сделать?
Ну да, почему-то все вспоминают про волатайлы, но волатайл спасет только от одной ситуации,
когда мы вот эти две переменные объявим как волатайл, то они не будут переупорядочены компилятором.
Но ассемблерный код, если вы посмотрите, что с генерируемым из такого кода, что с волатайлами,
он не будет отличаться. То есть у нас все равно остается проблема с процессором. Почему так
происходит? Я уже объяснил. Как от этого защищаться? Что он не обязательно может
исполнить инструкции в том порядке, в котором они записаны. А как нам тогда определять,
какие случаи его включать? В принципе, мысль интересная и даже в некотором смысле в правильную
сторону, но отключить конвейер, как мы можем отключить конвейер, а как мы по-другому будем операции доставать?
А что делать с тем, что у нас уже там есть конвейер?
А если мы делаем как в M1, когда мы параллельно начинаем парсить инструкции,
вот просто типа с этого места, потом в другой стадии конвейера, с этого места. То есть мы вот
это вот еще не распарсили, а тут была вот эта вот инструкция. Да, давайте просто зайдем на
Авито, купим там 386 процессор и будем под него программировать. В принципе, действительно есть
специальная операция, которая позволяет избежать такого поведения, чтобы ни компилятор, ни процессор
не могли переупорядочить инструкции. И такие операции называются барьерами памяти. То есть это
можно себе представить таким образом, что, допустим, вот у нас есть блок, да, и компилятор считает,
что здесь можно переупорядочить инструкции. А мы берем и вот здесь вот такую линию чертим и говорим,
что типа вот можно вот тут вот переупорядочивать сверху линии и под этой линии можем, а вот за нее
переходить нельзя. Так я же говорил, что тут есть две сущности. Здесь есть компилятор, который
может сгенерировать уже ассемблерный код. Сейчас объясню. Вот, то есть для этого вводится такое
понятие барьера. И барьеры также как, поскольку у нас здесь существует две сущности, барьеры могут
быть компиляторные и процессорные. Вот то, что вы говорили, что можно использовать volatile,
это по сути будет компиляторный барьер. Мы запретим компилятору переупорядочивать
инструкции, а процессора нет. Для того, чтобы запретить еще и процессору переупорядочивать
инструкции. Для этого существует специальная инструкция на x86. Она так называется mfence.
То есть барьер памяти. Никакой, эта инструкция такая же как. В x86 там барьеры памяти можно
реализовывать с помощью такой инструкции. Еще есть вариант добавить prefix log. К некоторым
инструкциям позволяется такой префикс добавить. Это будет как бы импевалентно записи сначала
mfence, а потом этой инструкции. А также на старых процессорах, на которых еще mfence не было,
использовали инструкцию cpoid в качестве барьера. У нее есть такой side-effect, она тоже запрещает
переупорядочивать процессоры инструкции до нее и после. Не, ну он в программе есть,
то есть вот здесь, что будет означать, если мы поставим здесь барьер. Это будет
значить, что нам нужно вот именно в таком порядке исполнить эти команды и по-другому никак.
Ну вот эту и вот эту, соответственно, если между ними стоит барьер. Это инструкция,
которую генерирует компилятор во время генерации кода. И вообще говоря, почему я говорил,
что если мы понимаем atomic-rit и atomic-rite как атомарные операции в языке C, то они по своей
семантике выступают сразу как компиляторный и как процессорный барьер. То есть когда мы пишем
atomic-rite, используя вот функцию из std atomic.h, она по стандарту C11 должна быть также и барьером,
поэтому компилятор не сможет переупорядочивать вот это вот присваивание за atomic-rite.
Вот. Да, барьеры в принципе бывают... процессорные барьеры различаются по
такому понятию как memory order. Грубо говоря, в том же интеле, например, есть не только инструкция
mfence, есть еще sfence и lfence. То есть, соответственно, барьер только на запись или барьер только на
чтение. То есть он в зависимости от этого разрешается переупорядочивать либо одни,
либо другие операции. Ну, мы к этому вернемся, где-то там в районе 12-й лабораторки, там будет
такое более обобщенное представление о том, как все это работает. Для тех, кому интересно,
у меня там в конце лекции есть ссылочка на такой интерактивный инструмент,
который позволяет играться с моделью памяти языка C. Вот. Ну да, вот здесь важный момент упомянут,
что когда мы ставим инструкцию барьера, по сути это означает, что мы хотим, чтобы вот результаты,
которые были до этого барьера, они были видны всем процессорам. То есть мы таким образом forсим
синхронизацию. Вот. И вернемся к самим примитивам. То есть с помощью вот этих лог-фри операций
можно сделать примитив spinLog. Это, по сути, аналог мютекса. Только чем он отличается? Это тем,
что он реализуется вот как раз таким образом, как я приводил пример вот здесь. То есть он просто
в цикле будет ожидать по... будет в цикле ожидать бесконечно, пока какой-то участок памяти не
изменится. И это достаточно затратная операция в том плане, что если он будет ждать мало, то это
будет быстрее, чем переключение контекстов в ядро. Но если он будет ждать долго, то мы будем отбирать
ресурсы у компьютера на то, чтобы просто ожидать в цикле. В этом минус этого примитива. И поэтому
придумали еще такую штуку, как адаптивный мютекс. То есть это мы сначала подождали в горячем цикле
какое-то время. И если за это время мютекс не освободился, то мы уже все говорим операционной
системе, что все, мы ждем. Можешь нас прибить на время. Также я уже этого касался с помощью
лог-фри операцией. С помощью вот этих атомарных операций существуют weight-free и log-free алгоритмы.
Это как раз weight-free в первую очередь. Это алгоритмы, в которых вот таких вот конструкций,
когда while что-нибудь не равно true, таких там вообще не может быть. Потому что сколько времени они
проживут, в смысле сколько времени они будут работать, предсказать заранее невозможно.
Так вот мы подошли к ошибкам, которые встречаются при параллельном программировании. Здесь
следует рассказать про два понятия. Это потока безопасности и реантерабельность.
То есть потока безопасности это такой код, который можно из нескольких потоков одновременно
вызывать, и он будет работать корректно. То есть здесь на примере вот этой функции можно видеть,
что у нее есть глобальная переменная, но она объявлена как локальная в данном потоке.
То есть если мы запустим эту функцию в другом потоке, то переменная tmp у него будет своя
собственная. И за счет этого вот эта конкретная переменная, вот эта конкретная функция может
быть вызвана из нескольких потоков, все будет нормально, она отработает. Но здесь в этой функции
есть другая проблема, и это то, что она не реантерабельная. Например, если после
чтения случайного числа операционная система захотела, ну тут даже нет, тут наверное лучше
сказать, что например, если у нас вот в этот момент прилетело прерывание, и соответственно мы
обязаны закончить исполнение этой функции временно и переключиться на выполнение этого прерывания,
то когда мы вернемся обратно, мы уже не можем гарантировать, что значение tmp осталось такое же,
как было до этого. Его мог кто-то другой изменить, кто тоже работает в контексте этого потока. И
в случае с прерываниями такое как раз возможно, потому что во многих операционных системах прерывание
оно исполняется в контексте того потока, который исполнялся в тот момент, когда оно пришло. То есть
вот эта вот переменная будет там доступна. Если она допустим, обработчик прерывания вызвал
эту функцию getNumber, то tmp поменяется. Тут понятно. Еще один пример нереантерабельной функции
представлен вот здесь. Это в принципе вообще такая не шибко корректная конструкция, но возможно
позволит чуть получше понять саму идею. То есть здесь у нас там допустим в операционной системы
есть функция panic, которая вызывается при какой-нибудь ошибке, когда мы уже не можем из этой ошибки никак
восстановиться и вызываем ее для того, чтобы она просто напечатала причину падения операционки и
спокойно упала. Но в реализации вывода сообщения у нас здесь существует еще одна проверка,
которая сама тоже вызывает функцию panic. Это другой способ как продемонстрировать нереантерабельную
функцию. То есть здесь если вдруг при ее вызове вот эта проверка вернет true, то что произойдет,
произойдет конечно произойдет, но в каком виде он будет понятно не до конца. Я имею в виду если мы вот
по этой ветке пройдем, так мы уже как бы в процессе. Там насколько я помню,
как бы на самом деле функцию panic в многих операционных системах она просто синхронная,
то есть она сделана таким образом, что когда ее можно вызывать, то у нас один всего поток остается
и еще одна популярная к сожалению ошибка это допущение в программе гонок или race condition
по-английски. Вообще этот термин он пришел в программирование из электроники. У них там
бывают случаи, когда нужно один и тот же сигнал получить в разных участках платы,
но например дорожки которые ведут к приемникам этого сигнала на плате, они разные длины и может
получиться такая ситуация, что они настолько разные длины, что задержка между получением сигнала в одной
точке и в другой она уже будет ощутима и плата может, само устройство может работать неправильно
из-за этого. Там это называется гонка сигналов и соответственно в программировании подобная
ситуация тоже называли race condition. То есть идея в том, что такая ситуация возникает в тот
момент, когда в зависимости от того в каком порядке потоки будут обращаться к общему
ресурсу результат будет разный, результат выполнения всей программы и очень часто это
приводит к таким ошибкам, которые тяжело найти, потому что зачастую их воспроизведение
и зачастую воспроизвести их получается только на каком-нибудь конкретном компьютере, только если
мы запустили еще 10 программ это 11 и только в четверг в 3 часа ночи. Все это как бы реальные
случаи, когда люди пытались люди пытались отловить гонку в программе и ладно бы если бы это были
просто ошибки, которые трудно поймать и они достаточно редко стреляют, но такие места в
программе они открывают целый класс уязвимости, который успешно эксплуатируется и позволяет в
принципе любые ну зачастую можно там и удаленное выполнение кода выполнить с помощью эксплуатации
гонки и там привилегии повысить и еще что-нибудь такое, то есть
ну да, то есть как бы собственно именно такой пример у меня здесь и есть. Такие ошибки
такой класс ошибок называется time of check, time of use. Ну почему это ошибки связаны с многопоточностью,
потому что все-таки для того чтобы ее про эксплуатировать нужно одновременно выполнить,
то есть у нас есть исполнение, у нас исполняется атакуемый поток и нам нужен еще один атакующий
если у нас и если мы например находимся в каком-нибудь среде, в которой вообще можно
выполнять только один поток в один момент времени, в принципе такую гонку про эксплуатировать будет
ну как минимум сложнее. Я еще раз проговорю в чем здесь идея, то есть допустим мы хотим
проверить перед запуском файла, мы хотим проверить можем ли мы его запускать там,
это может быть проверка подписей, проверка про доступа или
ну может такое быть, почему нет. Ну сейчас имеется в виду, что пока мы считываем в этот
момент, еще пока мы не успели дойти до конца, еще туда что-то дописать. Ну если смотреть этот
вариант когда мы то есть один из способов как можно таким ошибкам противостоять это
считать сначала файл полностью до конца и только потом его проверить. Так мы проверяем уже после
того как мы его считали, то есть если мы его будем просто дописывать, то у нас операция считывания не
закончится. Когда она закончилась уже то что мы считали поменять будет нельзя, но при условии
что операционная система, ну что есть какая-то область памяти, которая доступна только вот этому
потоку, ее никто больше менять не может. Сейчас я все-таки не сказал в чем заключается ошибка,
мы хотим проверить файл, вызываем функцию его проверки, которая это делает прямо на диске и
после этого уже считываем файл, запускаем и вот в этот момент между проверкой и считыванием может
возникнуть другой поток, может попробовать вклиниться в исполнение первого потока для того чтобы как-то
там подменить файл или еще что-нибудь сделать. Еще один вариант это еще один вариант как можно
защититься от такой проблемы, например если у нас файл большой, мы не можем его полностью в память
считать или это очень медленно будет. Как правило в операционных системах есть возможность
заблокировать файл эксклюзивно, то есть только один какой-то поток может вот к нему обращаться
когда файл заплокирован, но это вот что-то такое типа критической секции получается.
Еще один класс ошибок это deadlocking, взаимоблокировки, здесь наверное проще всего опять же на примере
показать. Допустим у нас есть переменная tmp, которая защищена двумя mutex, lock1 и lock2 и один
поток у нас входит в нее захватывая сначала первый а потом второй, а второй поток захватывает
сначала второй потом первый. Ну и понятно что если мы запустились вот прям строго одновременно,
то вполне возможна такая ситуация когда одновременно оба потока выполнили вот эту и вот эту операцию и
тогда они оба застрянуты здесь будут бесконечно друг друга ждать. Такие такие ошибки в принципе не
так уж сильно страшны, они достаточно легко видны в отладчике, то есть это не такая большая проблема.
Обычно всегда видно что вот какой-то один поток бесконечно простаивает ничего не делает,
можно эту ситуацию отловить. Потом в некоторых местах даже существуют специальные механизмы
для отлавливания этих ошибок именно вот прям в runtime. Я такое видел ну такой наверное самый
простой пример это базы данных, то есть в них всегда ну в современных во всех базах данных есть
специальный процесс который следит за тем чтобы SQL запросы не блокировали друг друга и если
такая ситуация произойдет то транзакция просто откатывается. Ну в базах данных такое возможно они
специально сделаны таким образом что любая операция пока она не закончилась она может
быть откатана до начала и да в общем там за блокировками за дудлоками прям следит отдельный
процесс. Еще один класс ошибок уже гораздо более неприятный это лайфлоки или динамические
взаимоблокировки. Тут на первый взгляд может показаться что вроде бы все нормально функции
работают какой-то код исполняется но по факту по факту ничего не происходит. Ну я думаю пример
который указан на слайде он говорит сам до себя то есть если у нас можно представить что есть у нас
есть узкий коридор в котором может пройти только один человек и два человека с двух его концов
стартуют начинает идти друг напротив друга и они останавливаются в середине и они такие
вежливые люди они просто разворачиваются и идут до начала надежды что кто-то другой пройдет
быстрее. Если они будут двигаться с одинаковой скоростью постоянно то они так и будут ходить
туда-сюда бесконечно и вот такую ситуацию в программе ее отловить уже значительно сложнее
да то есть там в отлачке это так просто не видно это вот нужно именно прям сидеть вникать
в работу чуть не пошагового в уме все это дело исполнять. Такое происходит когда есть какая-то
зависимость циклическая между ресурсами но она не одноуровневая а там значительно
значительно сложнее то есть того чтобы ну какой-то такой пример наверное трудно составить потому что
как правило такие ситуации вот по крайней мере то с чем я сталкивался возникают когда мы
забыли вот часть какую-то зависимость неявную когда писали код забыли что вот он там вызывает
какую-нибудь функцию она там внутри через 10 функций захватывает какой-нибудь вот такой ресурс
а мы об этом не подумали и сами тоже сами тоже пытаемся что-то с этим ресурсом сделать
нет в отлачке обычно видно просто что процесс просто в цикле исполняется все время бесконечно
видно в таком смысле то есть ну как правило как правило видно что вот процесс просто висит
жжет достаточно большое жжет процессор и вот обычно вот этот факт виден в отлачке
так ну на сегодня это все вот тут есть парочка ссылок первые это вот как раз про модель памяти
язык оси но я говорю мы собираемся к этому вернуться я надеюсь в конце там после после
всех лекций по лабораторкам будет еще вот одна поро модели памяти и несколько примеров
уязвимости и атак на них так ну все
