мы подошли к самому интересному unordered map вам ее реализовывать надо будет
первое задание вам нужно будет лист с локатором написать а 2 unordered map
но unordered map там будет уже с еще с несколькими дополнительными приколами
сейчас мы обсудим такой базовый вариант unordered map
некоторые проблемы мы отложим на потом так вот четко unordered map это хэштаблица
я не очень понимаю как я буду основному потоку объяснить
потому что они не проходили хэштаблицы
у них тяжелая судьба их то в первом семестре то в третьем то в втором
никак не может коллектив определиться когда правильно рассказать людям хэштаблицы
но там же проблема в том что там вероятность вся кофигурирует в доказательствах
но нет про хэштаблицы строго со всеми доказательств я вам сейчас не расскажу
но я не помню там все эти доказательства сходу мне надо готовиться повторять их
но идейно я думаю вы так знаете что такое хэштаблица поэтому о чем рассказать
ну кто кто понимает что такое хэштаблица
ну кто пользовался в своей жизни хэштаблицей хотя бы раз
ну да ну король ну ну типа ну короче ладно ну давайте я идейно расскажу что такое это
ну смотрите ну во первых он ордерт слово он ордерт само говорит за себя
мы хотим такую структуру которая ну те же задачи будут решать что и дерево поиска по сути
только мы потеряем упорядоченность ключей но за счет этого более быстрый поиск будет
вот идея в том чтобы в среднем за от единицы делать поиск по ключу причем в среднем тут
понимается не амортизировано а по вероятности ну то есть скорее всего и вот тут как раз основная
основная сложность вот все этой возни заключается в том чтобы формализовать что
значит вот это скорее всего ну да но мат ожидания по чему типа по какому
параметру у тебя там должно быть какое-то вероятностное пространство из него нужно
там выбирать там какие-то случайные элементы мат ожидания случайной величины а случайная
величина должна действовать на каких-то исходах а что такое исходы ну и вот в общем
весь этот геморрой но этот тярвер начинается и поэтому не будем углубляться но так типа понятно
что в среднем хотим чтобы все было хорошо в среднем в том смысле что вероятность того что все
плохо низкая вот ну что мы делаем мы заводим такой да что я не очень
но иногда сделает что вероятностная структура тоже может иногда ли линию сделать что мэпта
почему если у тебя загрузка комнате может собраться в одной точке от ожидания максимальной длины
ну есть такой параметр который называется load factor его можно поставить ну если у тебя
элементов лежит уже больше чем там некоторая константа умножить на размер таблицы то кажется
что все плохо ну и поэтому ты можешь ты можешь этот load factor поставить таким что все будет
испорчено скорее по умолчанию он просто стоит таким ну да можно и уб вызвать в принципе так я
объясняю что хэштаб лица вкратце ну чего вот у вас есть такой массив и вам надо не знаю ключи в
нем хранить вы берете такие и говорите окей ну давайте не знаю вот допустим у вас ключи это строки
вы для каждой строки вычислять кончить функцию которая называется хэш да которая обладает таким
свойством что она ну скажем так очень непредсказуемо по строке и небольшое изменение
строки сильно меняет функцию и меняет совершенно непредсказуемо но поэтому называется хэш хэш
вообще значит типа рубить мелко перемешивать вот так вот ну там типичная ситуация это вы берете
там какие-нибудь символы ну символы строки интерпретируете как числа представляете число
там в виде что это как будто число в какой-то системе счисления и после каждого операции
берете по модулю какого-нибудь еще простого числа скажем то есть вы берете там какой-нибудь
простое основание системы счисления и еще берете какой-нибудь большой простой модуль и по модуле
этого простого вычисляете свое свое значение ну вот кажется что там при нужном подборе всяких
там параметров вот этих чисел то у вас будет функция обладать ну плюс-минус такими свойствами
как надо ну там дальше длинный разговор о том какие конкретно хэш функции лучше какие хуже там
есть криптографически надежные хэш функции есть не очень криптографически надежные ну
криптографически надежные в том смысле что за за разумное время по значению этой функции нельзя
подобрать то от чего она посчитан была вот так называемые односторонние функции когда вы можете
быстро посчитать значение функции на входе но если вам дано значение функции то найти вход на
хоть какой-нибудь вход на котором было бы такое это там трудная задача
здесь мы хотим упихать да и угловое значение вообще размеры массива а изначально хотя бы
ты имеешь в виду что криптографически надежный в нашей задачи не нужны да и понятно я говорю
просто про то что хэш функции там бывают с разными свойствами и для разных задач бывают нужны
разные вот но у нас кстати биткоин примерно там похожая задача там вам нужно подбирать такой
вход чтобы на нем значение хэш функции было там оканчивалась на сколько-то нулей вот и это
сложная задача именно этим занимаются майнеры они собственно подбирают такие ключи чтобы на них
хэш был каким-то каким надо кого надо вида но неважно мы этим всем не будем заниматься майн не
будем чего ну на третьем может чуть-чуть помайните но не сейчас ну это же не значит
что вы майнить будете может вам ну неважно в общем это сейчас мы не будем обсуждать хэш
таблица ну и что это нам позволяет добиться мы в хэш таблице мы можем есть два подхода
первый подход называется хэширование с открытой адресации второй подход называется хэширование
методом цепочек что такое хэширование с открытой адресации это когда у вас в массиве собственно и
лежат вот эти строки сами ну то есть вот вы хэшируете какие-то объекты и массив собственно
из них но он изначально пустой да ну не совсем хэш взятый там либо хэш либо еще какая-то
функция от хэша хорошо поправь мы взяли строку мы посчитали мы взяли строку мы посчитали к
нее хэш стд хэш это всегда число single log ну неважно нам в любом случае нужно число в диапазоне от нуля
до n поэтому дальше мы просто берем по модулю n обычно вроде это да это как раз мы получили
какую-то позицию вопрос что делать мы не можем в эту позицию положить нашу строку или значение
связано нет нет ты сейчас начнешь рассказывать про разрешение коллизий это следующий вопрос
я как раз говорю что изначально и индексами и ну это будет изначально позиции вопрос был
насколько я понимаю про то чем индексируется массив но он индексируется значит как вот как ты
по строке понимаешь где она должна лежать посчитать хэш возможно взяли его по модулю чего-то
возможно еще какую-то операцию над ним произвели ну чтобы уложиться в этот массив и чтобы
возможно еще как-то дополнительное распределение на возможных выходных значениях задать и пошли
в эту ячейку вот смотрим лежит там что-то или не лежит нос не лежит значит такого ключа нету
сейчас мы про это поговорим пока мы и фиксировали размер но очевидная проблема
которая возникает вдруг случилась коллизия то есть у двух разных строк совпали хэши такое
конечно же может быть потому что если такое было невозможно это бы означало что возможных
значений хеша столько же сколько возможных значений наших объектов но тогда какой смысл
хеш таблицы массив должен быть размера как всего может быть разных значений так это вообще тогда
можно было бы не вычислять никакой хэш поэтому коллизии всегда неизбежно они происходят и
вот вопрос о том как быть в этой ситуации это собственно основной предмет изучения в этой в
этой области ну если там целые главная главная наука про хэш таблицы заключается как раз в том
как быть если совпали элементы совпали хэши у разных элементов но есть разные подходы и тут
можно просто не то что нужно курс лекции прочитать про то какие есть подходы разрешения коллизии но
самый тупейший метод это просто в следующую ячейку тыкаться чего
сейчас еще раз я не понял подожди в чем твоя идея типа ты считаешь что их просто нет
а ты говоришь про поиск по строке в строке что ли не по 10 9 и не по 10 18 вероятно
были коллизии почему потому что если ты положишь если возьмешь 10 пятый строк сравнишь хэши по
парно у тебя будет порядка n квадрат сравнений и у каждого варианта и у каждого шанс сломаться
то есть шанс коллизии один день на м есть модуль чуть-чуть больше чем количество строк сейчас
причем тут вообще количество сравнений дело же не в том просто дело в том что размер массива
меньше чем размер возможных чем чем количество значений в диапазоне не надо говорить про
лимпиадку потому что наша задача не решить не решить олимпиадную задачу а построить структуру
данных которая гарантированно делает поиск по ключу у нас как бы мы решаем не эту задачу не
решаем задачу поиска но мы надеемся что все будет хорошо нет нам нужна структура которая точно
отвечает есть ключ или нет она просто может иногда это долго делать если не повезло но ответина
всегда правильно должна иначе если бы структура там иногда отвечала неправильно то в общем
наша цель построить структуру которая всегда отвечает правильно но возможно иногда делать
это долго так вот ну вот самый тупой метод как быть сколизм вот пришли сюда вот вам говорят положи
в хэш таблицу значение а вы вычитайте хэш и видите что туда куда надо положить она уже есть там
ну вы говорите окей пойду в следующую ячейку тогда и туда положу но и так буду идти пока не
найду пустую ну и скорее всего там по пляшам с вероятностями ну наверное это не очень долго
в среднем будет происходить что да возникает возникает следующий вопрос а как удалять тогда
к чему не ну как ты как по ключу ты вычитаешь точно также вычитаешь хэш идешь в ячейку
нет идем дальше там оно нет пока не найдем пустую либо пока не найдем его вот когда удаляем вот
в таком подходе удалять проблема потому что мы не можем просто ее сделать пустой ведь вдруг
после нее что-то лежало что мы добавили в виду коллизии а тогда когда мы будем снова искать то
мы его потеряем что будет пустая и мы не дойдем до нужного поэтому обращение по индексу по ключу
работает так вычисляем хэш от ключа идем в ячейку соответствующую этому хэшу смотрим что там
лежит за значение если это то самое значение что мы ищем мы храним и ключи значит конечно мы
значение храним ну и ключи значение мы храним в ячейках но я сейчас говорю про хэш сет скорее
они про хэш мэп но если это хэш мэп то мы конечно храним ключ значение пару но значением я
называю ключ на самом деле когда про это говорю то что вл ю это не важно вл ю мы никогда не
сравниваем мы ключи сравниваем ключ это и есть строка мы сравниваем тот ли ключ лежит там который
мы ищем вот ну и идем пока не найдем либо его либо пустую как тогда удалять это проблема
потому что если мы удалим сделаем пустой мы потом можем не найти что-то что после нее лежало поэтому
вот с таким подходом удаление это трудность нужно ну можно помечать вершину там как фиктивную
например и типа помечать специальный флаг ставить тут что-то лежало но было удалено вот ну и вот
дальше свистопляска очередная очередной танец бум нам мы говорим что ну это там среднем наверное
если там правильно выбрать хэш функцию и правильно там размер таблицы то нормально все будет вот если
у нас оказалось что слишком сильно таблица заполнена ее возможно нужно пери перезаполнить
полностью если если мы с таким подходом в таблицу положим элементов столько сколько всего размер
таблицы у нас получится что последние уже операции за линию работают вот поэтому размер
таблицы во-первых должен быть больше во сколько-то раз чем количество элементов во-вторых этот слишком
тупой подход и обычно делают что-то другое например ну там можно например делать так вот есть такой
хэш сейчас бы не соврать хэш кукушки по моему называется а ну во-первых можно делать не линейное
пробирование квадратичное пробивание ну например не в следующую идти а по какому-то другому алгоритму
вычислять следующую для данной ну то есть функция перехода не случайную а в какую-то вычисленную
еще другим по другому ну потому что кажется потому что так у тебя следующее будет зависеть от того
следующее может зависеть как от твоего хэш значения так и вот того какая сейчас то есть
функция перехода к следующей зависит от того какой у тебя хэш тоже ну хорошо она может зависеть там
это номер ячейки она может зависеть от значения оригинального хэша ну или еще чего-то ну короче
ты можешь как угодно построить функцию перехода так что у тебя не будут образовываться длинных
таких последствий у тебя будет просто ну да просто у тебя не будет у тебя будет меньше шанс
что тебе придется пройти там очень длинный путь потому что следующий для этой он будет другим в
зависимости от того что ты ищешь ну да ну можно там подобрать там повозиться и там вот ну хэш
хэш можно например такой подход выбрать давайте так называемый хэш кукушки это что такое это я
просто беру и для каждого ключа вычисляю на самом деле два разных значения ну то есть у меня ключ
он да вот у меня две разных функции есть одна меня приводит сюда другая сюда и я когда делаю
insert я смотрю ну хоть одна из них свободно если хоть одна из них свободно то классно туда вставлю
а если вот ни одна из них не свободна тогда я а я тогда посмотрю вот на эту например и посмотрю
а свободно ли вторая для нее которая была и попробую эту перепихнуть туда на вторую доступно для
нее позицию а свою положить сюда ну и вот так действовать в общем очень много это можно игру
это можно целых лекций 5 прочитать про разные варианты как можно решать эту задачу там очень
сложная математика и это прям вот тут оптимизируешь недооптимизируешься но это был подход про открытую
адресацию так называемого еще подход методом цепочек что такой подход методом цепочек это
вы в каждой вершине храните не сам объект ваш а ну скажем массив или список и просто у вас
получаются такие бакеты в каждой ячейке у вас висит список того кто попал сюда потому что у
них хэш одинаковый и тут легче становится с удалением потому что у вас нет вот этой проблемы
что вы удаляя свой испортите чего-то там с чужим хэшом вот вы просто идете в соответствующую ячейку
смотрите как какой там сейчас список если там нет ничего то понятно ничего и нет а если там
что-то есть но вы проходите по этому списку к тех кто попал туда и среди него ищете ну или удалять
понятно как теперь вот но вот unordered map это как раз вот такая хэштаблица которая со вторым
подходом а именно эта хэштаблица методом цепочек смысл в том что вы ну скажем так надеетесь что
коллизии будет не слишком много поэтому там средний размер цепочки будет очень маленьким там и
близко к константе и поэтому у вас добавление удаления будет средним работать за от единицы
а не как в красно-черном дереве за логарифом но понятно что вы при этом теряете вы теряете
упорядоченность ключей то есть вы не можете спросить там lower bound upper bound equal range
никакой вот вы ключи в рандомном ну потому что все перемешано просто суть хэша в этом что все
перемешано непонятной порядке лежит
да ну понятно что в среднем одна сколько n поделить на n
нет нет если ты считаешь мат ожидания то это сумма индикаторов того что в данной ячейке
лежит элемент индикатор это вероятность просто что в данной ячейке лежит элемент а это будет
ну не важно это уход в сторону я не хочу в это уходить я хочу просто поговорить уже про то
как собственно вот реализовывать это хэш к счастью реализовывать нам не надо он реализован есть
функция стд хэш которая для всех стандартных типов но это не функция это класс это функциональный
объект шаблонный класс который для всех стандартных типов имеет для всех имею
ввиду как примитивных типов так и библиотечных стлевских типов он имеет оператор круглые
скобочки который по объекту данного типа возвращает там он глонг скажем ну вот все эти
стд стринг стд вектор стд что угодно для них для всех это сет конечно ну для всех объектов ну
возможно там за исключением каких-то я не помню но для всех скорее всего типа в которой ты можешь
придумать который тебе может захотеть сохранить стд хэш определен я ничего не могу сказать про
надежность этого хэша хоть какой-нибудь точки зрения не изучал вопрос но можно считать что
для наших целей он годится вот мы ну да наша задача мэп написать сейчас ну в смысле понять
как он устроен unordered map хэш будем считать что реализован для всех типов за нас и
как-то работает вот если мы хотим работать с каким-то хэшом который с каким-то типом
который не стандартной библиотеки нужно стд хэш доопределять самому для него то есть
прям нужно взять и ну допустим я хочу в хэш таблицу покласть положить там в качестве
ключа что-нибудь мое собственно big integer например вот ваш вы писали вот почему что плохой big
integer что ли получился не ну если про твой говорить то я тоже не стал не ну я честно говоря да когда
последний раз читал такой то там а ты меня потом право написал объяснение но я я что-то не я его
по моему не прочитал короче unordered map какие у нее шаблонные параметры очевидно ключ значение
дальше третий шаблонный параметр это собственно хэш который по умолчанию равен стд хэш от ключа
вот дальше да четвертый шаблонный параметр сейчас я скажу какой но пока про то сразу как свой
хэш доопределить то есть если вы хотите в мэп положить что-то свое например тот же big integer
стд хэш него неопределен вы получите ce со словами я не понимаю что такое хэш big integer нет такой
функции вот ну нету оператора квадратной скоб ну да нету структуры просто такой вот ну то есть
она есть но там стоит заглушка типа ну как фактически это же специализации для всех
типов просто вы стояли написано вам нужно тогда определить свой хэш как вы это делаете вы в
своем коде пишете namespace стд фигурная скобочка открывается и пишете template пустые угловые
скобочки struct хэш вот того чего вам надо понятно то есть вы можете иногда дописывать
сущности вы на им space стд вот это один из примеров когда такое может быть нужно то есть вам нужно
это значит официально по стандарту дописывание чего-то namespace стд это убе кроме ограниченного
списка случаев которые перечислены это вот один из них то есть то есть вот можно в namespace
стд добавить специализацию сюда хэш до конца его типа и это не убе это прямо вот официально
написано что так можно делать и всячески поощряется такое поведение вот дальше
хорошо ну чего у нас давайте подумаем как вообще это все устроено значит у нас должен быть внутри
какой-то массив и в этом массиве что у нас должно быть но у нас должны быть связанные списки то есть
фактически unordered map хранит такой массив ну можете считать вектор связанных списков вот
нет просто вы связанный список свой напишите потом его заиспользуйте здесь нет вектор ну тут
от вектора почти ничего не надо тут тут реаллокация не нужна ну то есть не нужна но
она вручную ее можно сделать вектором наверное даже можно будет пользоваться он тут не особо
поможет вот хорошо из чего состоит эта штука изначально из этот вектор изначально ну то есть
фактически у вас есть давайте скажем вектор от листа от чего ну не пар а ноут ну хорошо да нет
ладно лист наверное от пар лист пар но правильнее наверное сказать что у меня ну да хорошо давай
скажу что у меня лист из пар лист из value type опять это будет value type это опять пара
value type это пара как и в случае с обычным мэпом это пара из const.key.value ключ опять
константный по той же причине что и в обычном мэпе потому что нельзя взять и поменять его в
вручную если вы с какой-то вершины имеете дело если бы вы умели менять ключи произвольно то
у вас бы ну понятно что вы у вас сделали ключ не такой какой должен быть при данном данной
ячейке хэш у него не совпадает вы все испортили такого быть не должно вот поэтому в value type как
и раньше это вот такая штука и у меня есть ну вектор листов в value type там не знаю назову
его array ну блин array плохо а вот теперь что еще мне надо изначально там везде пустые листы так ну
спойлер это плохо сейчас ничего не получится сейчас мы поймем что так не работает надо переделать
изначально там пустые листы теперь давайте подумаем как работает ну что ну давайте подумать как
работает ну как работают квадратные скобочки опять же начнем по порядку значит оператор
квадратной скобочки как и в обычном мэпе вычисляем хэш от ключа который нам дали идем в соответствующую
ячейку смотрим ну если там ну фактически да опять же если там не пустой лист если мы в этом
листе не нашли то значит мы должны создать вершину новую для этого листа и туда ссылку вернуть на вот
то value которая получилось если мы не нашли в списке вершину с таким ключом то мы ее создаем и
возвращаем ссылку на вэлью этой вершины как работает это точно так же только мы кидаем
исключения в случае если не нашли ну не совсем потому что нам надо вернуть ссылку на вэлью они
на ноду листа ну можно наверное вызвать это листа но просто из того что нам вернет надо
вернуть не это а ссылку на вторую второй элемент пары как работает инсерт в принципе тоже понятно
как работает также да как работает и рейс тоже понятно а вот кстати уже как работает и рейс не
очень понятно тут мы приходим к разговору про итераторы у нас должны быть итераторы помимо
все прочее так нет итераторы остаются сейчас и итераторы да итераторы остаются не валить
становится неволидными я имею ввиду после вставки после удаления после удаления блин
понятно что итератор на твой элемент неволидным становится который удалял это всегда так остальные
итераторы портится или нет на на этот который ты удалил ну да я я и сказал что так по моему или
остальные итераторы остаются валидными а итератор на удаленный элемент никогда не обсуждается
очевидно с неволидным про него мы не говорим вопрос остаются ли итератор валидными на
остальные элементы вот тут есть некоторые трудности связанные с реэшированием но пока
их оставим в стороне вот давайте считать что размер таблицы фиксируема таблицы не перене
реалацируется пока вот если в этом предположении работать то что происходит ну вот это хороший
вопрос ну то есть казалось бы мы просто и итератор по сути это итератор на лист на лист и казалось бы
ну чё и рейс там или insert все нормально но вопрос в том как сами итераторы-то устроены что
такое итератор в unordered map, а кто помнит какой итератор в unordered map, какой у него вид
нет мы обсуждали когда таблицу рисовали форвард итератор на самом деле тут не лист а
форвард лист блин я забыл вам сказать что кофе а нет я говорил о форвард лист ну то есть
односвязанный список да потому что нет никакого смысла делать двусвязанный список потому что
все равно порядка никакого не гарантируется все равно они в рандомном порядке лежат идти хоть
вперед хоть назад одинаковый рандомный порядок и гарантии поэтому ну просто форвард лист у нас
здесь будет форвард лист но это не снимает вопроса как же итератор устроен вот че хранит итератор
как инкрементировать итератор если ты стоишь в конце листа
у тебя еще и не валидные элементы листа бывают а окей так следующую ячейку таблицы а если она
пустая а если она а если тебе так придется от n пустых ячеек нет а потому что ты не хочешь
чтобы инкремент работал за линейное время да только ты хочешь чтобы инкремент работал за
вот ты хочешь чтобы представь представь что ты завел хеш таблицу там на миллион
элементов и положил у нее всего два элемента у тебя получилось что эти элементы оказались
вот здесь тогда тебе чтобы обойти таблицу который всего два элемента лежит потребуется
миллион операций потому что размер таблицы ты большой сделал заранее надо чтобы обход
итератором работал за о от количества лежащих в ней элементов они от размера таблицы вот в чем
как поддерживать ну давай просто вместо того чтобы лист хранить но точнее в каждой
вершине действительно хранится лист на лист указателей то есть есть лист всех
элементов и а в вершине хранится лист указателей на элементы чего на последующие элементы нет
нет нет вот у нас в каждой вершине вот есть лист так да и это есть указателей на вот носить
какой-то просто список всех элементов которые у нас есть общий зачем нам вообще зачем вообще
сделать проход по мапе если можно отдельно сохранить раз уж никто не просит какой-то порядок можно
типа отдельно сохранить лист всех элементов и просто по нему ходить на нас проще правильно так
так надо то есть на самом деле вектор листов мы не будем хранить мы будем хранить один общий
лист а также один вектор которым jestemenga грн珠 и не листов указателей нам достаточно хранить
вектор одиночных указателей нам нужно хранить лист а еще вектор каждый элемент которого это
указатель на некоторые элементы того листа так так в смысле мы мы когда мы хотим
поиск, зачем нам вектор листов хранить, мы храним вектор указателей, одиночных
указателей, а когда нам нужно сделать поиск, мы прыгаем по этому указателю, а
дальше-то идем по листу просто. Мы смотрим хэш все еще такой же или нет. Его
можно закэшировать и хранить в вершинах листа, помимо всего прочего еще и хэш
текущей вершины. Просто хранить вектор указателей, лист указателей, это достаточно
расточительно, потому что у тебя тут, у тебя постоянно будут эти прыжки по
указателям многократные, а это не очень хорошо. Лучше ты будешь один. Да, но только тебе
нужно двойной прыжок по указателю делать. Чтобы понять какой у тебя следующий
элемент, ты не просто идешь в следующий элемент листа, ты идешь в следующий элемент
этого листа, а потом в тот элемент, который в нем написано еще. Зачем? Ну, типа, просто
можно идти по листу.
Можно еще раз концепцию сделать в общении?
Итак, у вас есть лист, форвард-лист на самом деле.
Можно эту концепцию изобрести из того, что у нас было. У нас куча листов была в вершинах.
Давайте соединим все эти листы в один большой.
Я уже не понимаю, что у вас лист, а что у вас вершина. Можно как-то конкретики
какой-то добавить. Что ты хочешь, в смысле? Что такое лист? Лист, который лист?
Лист, который лист. СТД-лист. Хорошо.
Так, смотрите, у меня будет форвард-лист из таких штук, которые называются, но это
будет не совсем value-type, потому что пара и еще кэшированный хэш. Значит, у меня
будет форвард-лист из... Ну нет, я не хочу пару из пары.
Ну давайте я назову лист-ноуд ее. Ну просто ноуд давайте я назову.
Нет, давайте сделаем юзер, напишем какой-нибудь...
Нет, давайте я назову лист-ноуд, потому что ноуд может как бы...
Значит, value-type, value-type-qv и еще... Какой там вы говорите тип правильный?
Int64t? Что?
Size-t. Хорошо. Size-t. Size-t. Ну давайте я назову хэш.
Хэш это... Господи.
Давайте я назову его caged. Или просто caged. Вот смотрите, есть кэш, а есть хэш.
Не путайте.
Так, вот такая структура. Вот из них состоит лист.
Это, значит, elements. Собственно, элементы, которые в хэш-таблице лежат.
А еще есть вектор из вот forward-list от лист-ноуд, двоеточие-двоеточие-итератор.
Они переиспользуют прям forward-list?
Не знаю.
А чем еще?
Скорее всего они не используют прям std-forward-list.
Потому что forward-list это же на самом деле...
Оболочка?
Ну конечно. Там и хэш-таблица-то нормальная тоже не unordered-map.
У них же написано во внутреннем nmsp-се куча всяких структур данных, которые они там в нужные моменты говорят,
Давайте вот это мы назовем forward-list, а это мы назовем unordered-map.
Но они в unordered-map используют какие-то внутренние структуры, не внешние forward-list.
У них какой-то свой собственный оптимизированный forward-list, вероятно, написан.
Так вот. Короче, вот такая штука.
То есть у меня есть forward-list из элементов и вектор из итераторов на этот лист, который хранит как раз...
Ну, понятно что.
Вот как...
Понятно?
Сейчас поймешь, что нет.
Как происходит поиск?
Ну, у меня вот есть этот массив.
Тут везде установлены нул-пойнтеры.
Вот тут, допустим, у меня...
Вот так выглядит лист.
Да, вообще говоря, конечно, не обязательно в таком порядке.
Оно может вести там, куда-то, не знаю, вот сюда, например.
Вот тут начинаются элементы с таким ключом.
Тут опять ничего, эта штука меня ведет сюда, то опять ничего, эта штука меня ведет сюда,
и тут опять ничего.
Вот так вот это выглядит.
То есть у меня ситуация такая.
У меня два элемента с таким хешом...
Один элемент с таким хешом, один элемент с таким хешом, один элемент с таким хешом.
а да конечно да да да да теперь как мы делаем что как мы делаем ну как мы
делаем find понятно в принципе понятно как мы делаем и find и insert и race да все в
принципе понятно по этому листу с первого указателя пока не дойдем до
другого хеша да значит мы как мы делаем find ну мы идем в эту ячейку прыгаем в
этот лист и идем по этому листу пока не увидим что хеш стал другим ну значит
если мы дошли досюда и не нашли ну не повезло но если нас просили если нас
просили квадратной скобочки при этом то мы создадим ноду вот тут вот и ее вернем
это правильный вопрос отлично детектив да все так что делать смотрите допустим мы
хотим давайте сначала про insert поговорю вот понятно ли как работать insert должен
ну хорошо допустим мы как вставить сюда понятно а что если нас попросили вставить вот
сюда проверяем что там пустое вставляем на угодно можно в конце начала у нас forward
лист поэтому в начало то есть если нас просят вставить и мы видим что ячейка массива пустая
мы просто делаем начало списка теперь вот этим так insert работает а как работает и race что если
нас прости ну если нас попросили там какой-то элемент из середины удалить понятно а что если
нас попросили удалить элемент да а энт не знаю а последний элемент перед
рендом нельзя найти за единицу господи у форвард листа сайз работает за линию
интересные факты от Ильи Мещелина да в общем да я удивился когда узнал но это кажется так они
потому что не хотели поддерживать сайз в виде поля и они его вычисляют проходом если надо ну чтобы
минимали чтобы чтобы минимум ну например для этого да ну и чтобы был минималистичный такой лист
с минимумом так как делать и рейс как делать и рейс вот мне надо сделать и рейс допустим вот
этого элемента что сделать не надо что
да вот как этому
ну в общем есть два варианта
они оба плохи они оба мне не нравятся но я лучше ничего не знаю и я не знаю как сделано
вст л на самом деле но я есть два варианта первый вариант первый вариант это хранить указатель не
на начало списка на вершину перед ним второй вариант это хранить двусвязанный на самом деле
если мы хотим удалить ее это значит что мы шли не с нее а с какой-то с левее нее
все указатели которые мы не можем в смысле вот вот этот указатель мы не сможем перенаправить
а окей тогда видимо это решение тоже не работает ну короче да плохо в общем ну я в общем не знаю на
самом деле более красивое решение чем двусвязанный список просто сделать вместо односвязанного ну
возможно есть просто есть решение которого я не знаю я не знаю кто-то сделанного стель возможно
там это ничего не значит у них знаешь ли хэштаблица с открытой адресацией тоже
реализована но на ее нам не предоставляют ну в смысле там много чего реализована что
нам не предоставляют пока потому что они еще не до конца уверены в том что его предоставляет
пора не знаю ну хэштаблица ну там вы же вы же вы лучше меня знаете что там реализована наверное
там всякие какие-то есть структуры там свои деревья свои умные что-то быстрые а
нет ну там наверняка есть какая-нибудь более быстрая хэштаблица но просто она не вынесена
ну например ну те это ты ты родина то я не помню хорошо техник в общем на самом деле как вы так
короче вот понятно что с двусвязанным списком это будет работать можно ли обойтись без
двусвязанного списка и делать красить и делать нормальное удаление не знаю наверное как-то
можно но тут вопрос что вам больше нравится ну наверное можно но я не уверен что-то более
да мы можем вызвать диструктор и просто не обращаться к нему да такому нет так
можно да я не говорю что это не рабочие решения наверное оно рабочее но в общем не знаю что вам
больше нравится вот то и то и выбирайте я не уверен что быстрее вообще из этого но
поняв что тут связан список накладные расходы но это тоже какие-то накладные расходы с другой
стороны если поставить то сколько у тебя будет работать
амортизировано или в среднем
так давайте дальше поговорим про то что еще все окей мы поняли мы поняли короче
идеи на как это устроено все давайте пожалуйста надо дальше дайте пожалуйста дальше продвинемся у
нас еще один есть шаблонный параметр это компаратор ключи да мы можем какой-то другой
компаратор передать необычное сравнение по умолчанию стд equal to это как стд less только
оператор равно равно вместо прятал меньше вызывает но мы можем и свое передать то есть
нам нужно сравнивать ключи тоже уметь на равенство сравнивать вот ну как вы понимаете все это может
кидать исключения и давайте подумаем если что-нибудь из этого кидает исключение не
сломается ли у нас все хэш хэш может кинуть исключение да мы должны стронг exception
guarantee ничего не произойти должно с контейнером если кто-то кинул исключение используется к
функции вот ну если компаратор кидает исключение это плохо или нет да ну кажется нормально вот ну
надо просто будет аккуратно написать то есть будет я кстати кстати в тестах прошлого года у меня
по мне было теста когда компаратор кидает исключение в этом году надо добавить ну там там
ну я не могу гарантировать что я прям все возможные случаи провели ну там понятно что обязательно будут
тесты когда короче короче тесты когда все вот какие вл ю хэш икул все будет время от времени
кидать исключение там будут специальный тест на исключение и в общем я буду проверять что с
контейнером ничего не случилось что все лежит как раньше еще еще локатор иногда может кидать
исключение это отдельная история но мы пока про это не говорим еще пятый пока не знаю что такое
локатор я не а как я буду проверять что ничего не поменялось что-нибудь придумаю вы
мне сами подскажете еще каких тестовых случаев не хватает как обычно вы это делаете так что так
дальше что еще давайте поговорим про какие про специфические методы хэштаблицы ну хэштаблицы
есть такой очень важный метод reserve как у вектора прям reserve от n вот reserve это метод который говорит
сделай мне хэштаблиц такого размера чтобы мне хватило на нее на н элементов да вот так а как
он понимает сколько нужно элементов хэштаблицы сколько какой должен быть размер хэштаблицы в
зависимости от н нет какой хэш мы передаем это вот наш мы плохой хэш передали он вот у него есть
некоторая внутренняя константа которая называется load factor у него есть такая константа которая
называется max load factor и есть текущий load factor текущий load factor это отношение количества
элементов которые сейчас добавлены в хэштаблицу к размеру вот этого массива max load factor это load
factor при достижении которого он сделает перехэширование всех элементов
если у него очень много ну очень много элементов в одной вершине ну нет насколько я знаю вот под
это нету ничего типа или или очень хорошие ключи наоборот хэш хороший просто ключи специально
так подобрал чтобы у всех хэш был одинаковый в общем есть есть load factor это вот отношение
текущего количества элементов к размеру массива есть max load factor по умолчанию он равен вот я не
помню чему ну что-то там типа блин нет конечно ну какая какое-то число от нуля до единицы но я
забыл какое не помню какое ну можно можно носить переференс просто посмотреть чему он равен по
умолчанию его можно поменять то есть вы можете сказать какой вам max load factor устраивать вы
можете есть функция set max load factor и get max load factor то есть вы можете спросить вы можете
у хэш таблицы спросить какой у нее сейчас max load factor то есть по достижении какого load
фактора она перестроится и вы можете сказать set max load factor то есть какой бы вы хотели чтобы
он был чтобы допустим она бы перестраивалась раньше чтобы у вас load factor это отношение
количества элементов которые в ней лежат к размеру массива ну а что rational это должен
быть это отношение ну типа ты ты смотришь на него как на вещественное число потому что у тебя
размер таблицы он может меняться а max load factor будет оставаться одним и тем же вот и собственно
есть функция rehash rehash это функция которая как раз перестраивает хэш таблицу вот я не помню
принимать ли она какой-то параметр вот нет она ее вызвать можно да можно делать rehash самостоятельно
если там вы вдруг поняли что что-то но вы допустим поняли что что-то не знаю там ну хотя нет как
вы это поймете никак не поймете ну в общем не знаю вы там что-то вот поняли и решили rehash
делать что делает rehash вот это самый интересный вопрос все вот это мы классно построили а
теперь нам нужно хэш таблицу расширить ну то есть ну скажем в два раза или не знаю в три
rehash мы поняли что все что-то элементов стало слишком много нам добавляют еще один мы уже
превысили max load factor значит нужно перестроить эту всю штуку и переложить все элементы значит
ну вот на cpp референс написано что rehash работает в среднем за линию но worst case quadratic
да ну давайте подумаем как rehash делать как вот во всем этом то есть нам нужно список
сохранить постараться ну или нет нам может быть нам уже новый список построить но нам нужно вот
короче как-то умудриться вот эти все штуки переложить вариант считать удаляем таблицу
да да окей то есть мы что делаем мы говорим окей давайте просто новую таблицу создадим
не забывая что у нас все может кинуть из ключей то есть нам надо старую мы не удаляем мы сначала
создаем новую пытаемся все положить в правильном порядке только после этого удаляем старые потому
что если вдруг по дороге кто-то кинет исключение мы должны оперативненько все обратно убрать как
было вернуть таблицу назад ну собственно да это как раз наверное из-за того что мы можем в
худшем случае у нас может линейное время занимать то мы делаем мы дропаем эту таблицу и просто для
каждого элемента списка делаем как бы insert фактически уже в новую таблицу вот понятно почему
это может плохо медленно работать вот вопрос что происходит с итераторами и
со ссылками на элементы а вот нифига вот сейчас я вам скажу еще одну замечательную вещь ссылки
и указатели на элементы не инвалидируется при инсерте в том числе на элементы да на
элементы да но если вы другой список создадите то это будет означать что ссылки на старые
элементы списка не ну почему не можем переложить или указатели тоже указатель может переложить
указатели видимо честно мы не можем хранить значение нужно везде хранить указатель и нет
а вот интересный факт для интов и он глагол макс вот фактор вторая единица я не знаю почему
сейчас я проверю потому что я сомневался
так короче нет все правильно я ничего не напутал я испугался что я вас обманул нет значит если вы
правильно помните таблицу которую мы рисовали в самом начале когда про контейнеры говорили то
мы говорили что в unordered map инсерт инвалидирует итераторы но не ссылки указательные элементы
и тогда мы ничего про рехэш не знали но теперь знаем и это требование надо соблюсти то есть
unordered map должен делать рехэш так чтобы ссылки указательно старый элемент остались валидными то
есть если я завел там у меня вот тут лежал там какой-нибудь стринг и я там сделал не знаю
авто амперсант там x равно там моя мэпа по ключу к а потом такой хоба а это опять ты я понял
м.рехэш то вот по этому x все должно по-прежнему быть нормально потому что если я новый лист создам
и дропну старый лист мы дропаем таблицу и хотим этот список таблица сейчас в два раза
больше станет это значит что вот эта вся структура совсем изменится потому что у меня теперь будет
другая таблица нет она изменится абсолютно непонятным образом то есть теперь у меня должно вот так
выглядеть теперь у меня короче вот это ячейки должны соответствовать вот эти оба элемента вот
это ячейки должен соответствовать только этот элемент вот это ячейки должен соответствовать этот
элемент вместе с этим элементом вот так у меня изменилось как мы теперь должны перестать мы должны
то есть она совершенно не по рандомным образом перестроилась и теперь множество как-то поменялись
совершенно произвольно что надо сделать да ну то есть мы берем теперь то есть мы не делаем новый
список на самом деле мы берем очередную берем вершину списка и чего мы как бы создаем получается
новый список в список мы ничего не делаем со значениями да то есть фактически мы если бы нам
не нужно было сильную гарантию давать ничего да то мы могли бы сделать следующее берем первый
элемент списка удаляем его из списка и вставляем новый список ну нам надо просто эти указатели
сейчас давайте считать что у меня как бы есть новый список который пока пустой
теперь я беру беру вот это вычисляю хэш и делаю как бы инсерт но что такое
инсерт список я выцепляю вершину и с этого списка и помещаю в новый мне не надо для этого
копировать well you type ничего с well you type делать не надо идеологически не надо но если у вас
обычный стд лист ну конечно у меня необычный стд лист я пишу список как я делаю список как
я просто то есть я не заново создаю список из этого а я беру очередную вершину отцепляю
от списка и зацеплю присобачу в новый список нужное место ну и все и так иду что если вылетит
исключение нет и кол мы вызываем потому что мы инсертом список мы идем по спитну там
сейчас чего нет ну когда я делаю инсерт новый список я а да хорошо и кол мне не надо вызывать
согласен но мне надо что если что если хэш кинет исключение самый главный вопрос
не искать мы
нам не нужно все равно сравнивать сами штуки мы знаем что все именно условные элементы разными
даже нам просто по хэшу сравнить да это идеологически нам нельзя будет переиспользовать
описанный инсерт это отвратительно но это реально реалистично а вот на хэши посчитать сразу пройтись по
всему списку один разочек и насчитать хэши старые видимо сохранить пока что на время но это
то есть то есть мы сначала насчитываем заранее все хэши и
ну что
вдруг пока мы уже частично список перестроили и тут какой-то хэш кинул исключение нам
нужно список обратно тогда перестроить будет поэтому давайте заранее посчитаем все хэши
вот мы и пересчитываем а старые сохраняем типа доп. веков как вот это и вот мы
кстати да хорошая идея может быть может быть и так можно даже можно просто хранить
что стд хэш от этого элемента результат вызова стд хэш от этого значения от этого ключа
ну тут ну тут у нас как бы проблема посерьезнее так ну что справитесь написать теперь это
это второе задание шутка сейчас произошла в чем не вызывает хэш не но получается тогда
нет но исключение всегда может вылететь из-за там реаллокации например нет нет реаллокации
всегда может кинуть исключение это что нью кинет исключение сейчас а мы ориентируемся на то что
не ю может кидать исключение в этом случае мы тоже должны все нормально сделать что мы должны
оставить хэштаблицу в неизменном состоянии несмотря на это мы просто выделяем сначала все
что мы мы заранее всегда когда мы exception safety пишем мы заранее выделяем все что надо то есть
мы выделили себе большую хэштаблицу и если не получилось то мы еще ничего не меняли просто
выходим все мы заранее все выделили а потом начали перекладывать уже нью мы никогда не
вызываем где мы хотим еще от единицы там память на указатель сохранить ну заранее надо значит это все
так минуточку минуточку я говорю про вызов нью на стеке какая разница нью кидает исключение
если ты создал локальных переменных больше чем размер стека да ну это ты никак от этого не
защитить если у тебя локальных переменных больше чем размер стека ну сорян но такого мы считаем
никогда не происходит потому что ну там просто там никаких исключений вообще не речь не идет
речь идет только обе прятали нью когда он когда я про exception safety говорю ну вот такие дела значит
вот он ордер не знаю не знаю во сколько раз честно говоря не помню но вот сколько-то
значит ну на самом деле я вам уже значит смотрите у вас на практике вы не вызываете
нью напрямую еще раз у вас это спойлер на следующую неделю следующая тема у нас
будет создаться локаторы мы поговорим о том что на самом-то деле здесь есть пятый параметр
который называется локатор и он во всех контейнерах есть и на самом деле он ордер как и любой
контейнер никогда к нью не обращается напрямую он всегда через класс локатор просит выделение
памяти и вот как раз а локатор может кидать исключение вот про это мы отдельно поговорим
то есть а локатор может кинуть исключение например потому что оператор нью внутри него кинул
исключение что было первым а локатор это еще одна абстракция над оператором нью да
так окей это было да и еще и с муф семантикой да после локатора у нас будет муф семантика
нет здесь пререхеша мувать ничего не надо будет но там есть много разных мест где потенциально
конечно ну слушайте в общем давайте не будем но там методы просто соответствующие но там надо
иногда не копировать и перемещать кое-что вот у нас значит ссылки не инвалидирует а итераторы
почему инвалидируется кстати но итератор да тут написано что итератор хранил что что
нет тут не написано ну короче мы считали что итератор по хэш мэпу это на самом деле был
итератор по листу но это неправда потому что это на самом деле не был не совсем лист и не
совсем итератор на него ну не настоящий форвард лист потому что настоящий форвард лист не вот
такого как мы тут проделали нельзя сделать ну ты же сам говорил что нельзя но это не настоящий
стд форвард лист это форвард это внутренний наш лист с дополнительными поддерживаемыми операциями
ну итератор на этот лист тоже не совсем то что мы понимали да то есть на самом деле это будет
просто указатель на вершину листа не итератор стандарта в классическом понимании итератор
на лист а просто указатель на вершину листа и что тогда такой его инкремент этот переход к
следующему в терминах этого листа но проблема в том что когда мы сделаем rehash у нас порядок
может нарушиться и переход к следующему станет да например например у нас end потеряется
ну у нас точно инвалидируется end предыдущий да у нас еще да еще у нас же надо надо end поддерживать
я рад что для вас уже это стало привычной ситуацией не прошло не прошло и двух недель
сначала семестра недели не прошло еще сначала семестр хорошо так ну ладно короче ну все понятно
отлично так ну а что а сколько а время то у нас уже закончилось же да
