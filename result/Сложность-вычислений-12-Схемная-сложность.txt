Добрый день. У нас уже остается не очень много лекций.
Основная цель – успеть изучить схемную сложность и вероятностные вычисления.
Соответственно, сегодня со схемной сложности начнем.
Давайте я начну демонстрацию экрана.
Вот схемная сложность.
И хочу я начать анонсированную разговору про быстрые сумматоры.
Мы в главе про логермическую память изучали, что самый обычный метод сложения столбик
использует логермическую память, если записи лежат отдельно.
Даже логермическую память не нужна. Нужна константная память.
Сложение дуэчных чисел – это базовая операция в процессоре.
Поэтому важно, чтобы она происходила очень быстро.
Если мы посмотрим на то, как она происходит в нашем протоколе
Обычное сложение столбик с подсчетом переносов.
Пусть будет два числа.
И у них тут какие-то биты заданы.
На самом деле нам тут много не надо. Пусть будет 4-битовое число.
Их обозначим.
По-всякому бывает, что сначала индексируешь, что с конца.
Теперь надо делать x1, x2, x3, x4.
Здесь y1, y2, y3, y4.
Как устроено обычное сложение столбик?
Смотрите, мы берем два последних бита и с ними делаем две операции.
Одна операция – это ксор.
И это уже будет ответ.
Другая операция – это конъюнция.
Конъюнция говорит, будет ли перенос следующий разряд.
Дальше мы уже складываем следующие два бита.
И мы уже будем делать конъюнцию.
Это конъюнция.
И конъюнция говорит, будет ли перенос следующий разряд.
Дальше мы уже складываем следующие два бита и перенос.
Дальше будет получаться, что у нас 1, 2, 3.
У нас опять ксор.
Это очередной бит ответа.
Дальше нам нужно еще получить перенос на следующий раз.
И он на самом деле получается функцией большинства.
Если хотя бы две единицы есть, то в сумме будет больше.
И больше, поэтому будет перенос.
Тут только максимум есть.
Будет функция большинства.
Если две или три единицы, то будет перенос следующий разряд.
Ну и дальше это продолжается.
Тут получается ксор.
Дальше получается большинство.
Ну и еще раз.
Давайте уже дорисуем полную картину.
Получается ксор.
Соответственно, из вот этого, вот этого и вот этого.
И, наконец, возникает большинство, которое будет пятым битом.
Поскольку это уже будет на выход.
Соответственно, получается вот так вот.
Тут получается вот таким вот образом суммирование 4-битовых чисел школьным алгоритмом.
Ну что мы здесь видим?
Мы здесь видим, что чем больше разрядов в числах, тем длиннее цепочка зависимости.
Чтобы посчитать результат в некотором разряде, нужно посчитать перенос.
Значит, для этого посчитать результат в предыдущем разряде, а для этого посчитать перенос в предыдущем разряде.
Ну и так далее.
Соответственно, если вычисление результата операции занимает время Эпсилон,
то, соответственно, такая длина максимальной цепочки зависимости будет как раз временем выполнения вычисления.
Ну а поскольку время это то, что нас больше всего интересует, то нас как раз интересует вот такая вот цепочка.
Ну вот на самом деле процессоры, настоящие компьютерные процессоры, как правило, устроены так.
Пока у них еще 4-битовые числа, они делают примерно то, что здесь нарисовано.
Но когда возникают более длинные числа, то они их бьют на блоке по 4-бита и как-то комбинируют результаты.
Вот. Это называется быстрые сумматоры.
Значит, быстрые сумматоры.
Быстрые сумматоры – это процедуры,
которые позволяют вычислить биты переносов, не проводя все промежуточные вычисления.
Ну и один из примеров давайте изучим.
Значит, пример быстрого сумматора.
Для каждой позиции, не для каждой позиции, а для каждого промежутка от и до жи,
значит, выведем 2 бита.
Значит, j и jt означают, что на этом промежутке
генерируется перенос.
Значит, то есть, если мы возьмем фрагмент х и сложим с фрагментом у,
это будет больше либо равно, чем 2 в степени g- и плюс 1.
То есть, смотрите, что 2 в степени какое-то число занимает как раз n плюс 1 бит,
а любое число меньше, чем 2 в степени занимает максимум n битов.
Вот, соответственно, получается, что если вот здесь, на этом промежутке,
генерируется перенос, то, соответственно, не важно, что там в хвосте происходит после житого,
все равно будет... Ну, например, идея такая, что если тут x, 3 равно единице,
то не важно, придет ли перенос отсюда, точно уже большинство равно единице,
поэтому сюда перенос уйдет.
Вот, и есть еще другой бит, p и gt.
Этот промежуток сам не генерирует перенос, но проталкивает его.
То есть g от слова generation, p от слова propagation.
Значит, проталкивает означает, на самом деле, что вот такая вот сумма соответствующих фрагментов
равна 2 в степени g минус и плюс 1, минус 1.
Да, то есть и это равно 1, 1 и так далее, 1. Значит, здесь будет g минус и плюс 1 раз.
Вот, хорошо. Значит, теперь эти биты можно считать рекурсивно.
Так, значит, рекурсивный подсчет g и gt и p и gt.
Так, начну. База. База это когда и равно g.
Тогда g и t и t это просто конъюнкция.
Ну, это x и t конъюнкция y и t.
Вот, а p и t и t это соответственно ксор.
Значит, x и t плюс ксор y и t.
Переход. Переход будет выглядеть так, что g и kt будут равняться следующим.
Это будет g и gt или g plus 1 kt и p и gt.
То есть либо у нас перенос прям сгенерировался уже в голове, либо он сгенерировался в хвосте и, соответственно, протолкнулся через голову.
Потому что, смотрите, если вот эта тут сумма будет не из всех единиц,
тогда даже если в конец перенос придет, то он будет обнулять, обнулять эти единицы, а потом там, где будет 0, там получат единицы и все, дальше перенос не протолкнулся.
А если, соответственно, те единицы, то если с хвоста придет единица, то они все обнулятся и вперед тоже придет единица.
Так, дальше, соответственно, p и kt, это будет равно p и gt и p g plus 1 kt.
Да, то есть тут получил суммы всех единиц в большом интервале, если и в первой половине все единицы, и во второй половине все единицы.
Так, ну и дальше получается идея следующая.
Значит, идея такая, что мы посчитаем сначала для каждого бита.
Значит, потом, значит, для цепочки из двух битов, вот так вот выровненный.
Значит, потом для цепочки из четырех битов.
Сейчас потом для цепочки из восьми, ну и так далее.
Ну, давайте еще один шаг, так легко копировать.
Вот так вот у нас здесь получается вот так.
Ну и теперь смотрите, например, в каждом из этих отрезков можно вот так рекурсивно посчитать биты генерации проталкивания.
Ну а теперь нам нужно понять, будет ли перенос в какой-то конкретной точке.
Значит, перенос к точке И.
Значит, это на самом деле генерация от И до Н.
Ну, например, нам нужно понять, будет ли перенос, ну скажем, через эту точку.
Значит, тогда мы весь хвост от этой точки до конца.
Представим, как объединение вот таких вот выровненных кусочков.
И для каждого из этих кусочков мы уже посчитали генерацию и проталкивание.
Ну и тогда получается, давайте я тут запятую поставлю, чтобы было и Н, а не И.
Так же и Н.
Ну а дальше получается так, что же и Н.
Да, значит, это будет там какое-то g и gt.
Или, соответственно, g, g плюс 1, kt и p и gt.
Или g, k плюс 1, lt и p, g плюс 1, kt и p и gt.
Ну или и так далее.
Соответственно, все вот эти биты, генерации проталкивания, они на предыдущем шаге подсчитались.
Ну и тогда получается, что максимальная длина зависимости будет как раз порядка логарифма.
Ну представите, если тут всего n-битов, то по высоте тут будет как раз порядка логарифма.
То есть если, значит, вот эта длиция, если, значит, по ширине получается n-битов.
То по высоте получается логарифма n-битов.
Ну там верхняя целая часть, давайте я куда-то напишу.
Целая часть логарифма n-битов.
Соответственно, здесь получается длина зависимости как раз порядка логарифма n.
Потому что каждый переход на следующую строчку – это вложенность длины либо 1, либо 2.
Поэтому все вместе длина зависимости будет порядка логарифма, может, на 2 умноженное.
Ну и вот здесь, поскольку тут разложение в двоечную запись, то получается, что здесь спочку тоже длины порядка логарифма.
И в скобках тоже порядка логарифма.
Поэтому там длина зависимости тоже будет, в принципе, можно даже сказать, что будет повторный логарифм.
Поэтому это будет на длина зависимости все вместе порядка логарифма.
Если битов всего 4, то в сравнении с этим не будет особого выигрыша.
Но если битов больше, там уже даже 8.
Так скорее, современные процессоры работают с 32-битовыми, с 64-битовыми числами.
Там как раз что-то похожее нужно делать.
Иначе они будут работать сильно медленнее.
Есть какие-нибудь вопросы по поводу этой конструкции?
Давайте я напишу вывод.
Максимальная длина зависимости будет не больше.
Так, не больше, просто будет побольше, это и так не больше.
Ну ладно, если нет, то перейдем к общей теории.
Что здесь нас вообще интересует?
Общая теория – схема из функциональных элементов.
На самом деле есть три взгляда на схему.
Первая – это размеченные ориентированные графы без циклов.
Вторая – это машины тьюринга, получающие подсказку.
И третья – это прямолинейные программы.
Соответственно, давайте на все три способа посмотрим и докажем, что они эквивалентны.
Так, первая – это арграфы без циклов.
Здесь – арграфы без циклов.
Чահя цикл,
Вершины могут быть помеченными несколькими метками.
Так, первая in – это входящая вершина, выходная вершина.
Так, out – это соответственно выходная вершина.
Ну и дальше, третья – это логическая операция.
Их список можно варьировать.
Давайте будем считать, что операция – это только отрицание, конъюнкция и дезюнкция.
При этом входящая степень у in – ноль, у out – один.
С out в принципе есть два варианта.
В этой картине направление имеется сверху вниз.
И один вариант – это считать, соответственно, вот эти вот x – это входящая вершина, а y – это исходящая вершина.
Можно считать, что от этих голубых вершин еще одно ребро идет как раз в формальную входную вершину, и там просто копируется.
А можно считать, что тут наша метка out может быть совмещена с любой другой меткой.
Соответственно, вот эти вот метки, вершины помещены xor и out.
Вот эти помещены majority и out.
Понятно, что у меня там в списке базовых операций нет xor и majority.
Поэтому их нужно еще выразить таким же схемами через что-то.
Но в принципе можно наоборот ввести любые булевые функции в список возможных типов элементов.
Я считаю, что out – это будет отдельный вершин, который мы там не нарисовали.
У in 1, у out 1, у отрицания 1.
А про конъюнцию и дизъюнцию – два варианта.
Либо два, либо произвольная.
Соответственно, если степень 2, то получается, что этот элемент вычитает конъюнции только двух.
Если степень произвольная, то конъюнцию всех своих аргументов он может вычислить.
Ну а исходящая степень можно считать так, что у out 0, значит у остальных произвольная.
Ну тогда получается, что если…
Ну можно еще назвать высотой вершины.
Значит, высота вершины – это длина пути от входной вершины до данной.
Соответственно, если всем входным вершинам задать более вызначение,
то и всем остальным вершинам тоже можно задать значение рекурсивно по высоте вершины.
То есть у входящих получается высота 0.
Каждый раз, когда мы значение всем вершинам высоты k сопоставили, то дальше высоту k плюс 1 тоже можно посчитать.
Просто потому что все вершины, из которых идут ребра в данное значение, можно их подставить в blue функцию.
Ну а в out надо просто копировать из предыдущего.
Поэтому как раз отдельно вершины out можно не заводить, а можно делать это как пометку.
Значит, значение out вершин зададут значение…
Новый результат работы. Вдут результат работы всей схемы.
Если выходная вершина 1, то схема с n входными вершинами распознает некоторое подмножество.
А n будет некоторое подмножество 0,1.
Если входных вершин больше, то вычисляется некоторая дискретная функция.
Вот, хорошо.
Ну и еще можно сказать, что если для каждого n задана некоторая своя схема,
с одним выходом, то все это семейство распознает некоторый язык, но уже произвольные длины.
Ну имеется в виду, что если выход будет 1, то вход должен лежать в языке.
Если выход будет 0, то вход должен не лежать в языке.
Ладно, я тебе еще какой-нибудь пример приведу.
Так, например, вот как, собственно, XOR выглядит.
Значит, вот есть два бита, x и y.
Дальше мы добавляем отрицание.
Дальше будет еще конъюнция.
И в итоге дисьюнция.
Отрицание, конъюнция, конъюнция и дисьюнция.
Ну или там можно и наоборот, в принципе.
Значит, вот мы сделали не x, сделали не y.
Дальше мы понимаем, что не x и y, то есть это 0,1.
Значит, может быть наоборот, x и не y.
И, соответственно, вот одно из двух.
Ну и тут, в принципе, можно условно еще дописать вершину out.
Вот, да, а сейчас у нас тут есть два важнейших, значит, две важнейших характеристики.
Значит, размер схемы, размер схемы – это общее число вершин в графе.
А глубина схемы – это максимальная высота вершины.
Ну и, соответственно, теорема, любая бульва-функция вычисляется схемой от n переменных.
Вычисляется схемой размера O от n на 2 в степени n и глубиной.
Но тут, смотря, опять же, что считать, значит, глубина 3 имеется в виду, что входные и выходные не учитываются.
То есть, если входные ноль, то будет 1, 2, 3.
Значит, с учетом out получается 4.
Ну, потому что вот то, что ясно, это DNF, а мы знаем, что функция ворота через DNF или через KNF,
поэтому такого рода схема возможна для любой функции.
Вот. Значит, это простая теорема, которую мы на первом курсе изучали.
А также есть теорема Лупанова.
Уже без ограничений на глубину. Тут будет вместо умножения на n будет деление на n.
Так, и теорема Шинонна.
Ну что, некоторые волевые функции от n переменных вычисляются только схемами размера Омега от 2 в степени n и глубиной.
Ну вот, идея теоремы Лупанова – это хитрое переиспользование каких-то фрагментов функций, которые похожи в разных частях.
А идея теоремы Шинонна – это просто принцип Дерехлия, что мы докажем, что просто не может быть слишком много разных схем меньше размера.
Вообще в целом можно сказать, что схемы – это такое обобщение волевых формул.
Только тут получается, что одну и ту же часть можно использовать несколько раз.
И в этом смысле они как раз похожи на прямолинейные программы.
Давайте сейчас о них поговорим.
Значит, схемы как прямолинейные программы.
Так, а что такое прямолинейная программа?
Значит, это SLP, Straight Line Program.
Это программы, не имеющие ни циклов, ни условных операторов, а только лишь операции присваивания.
Например, если переложить эту картинку на прямолинейную программу, то она будет примерно такой.
Значит Z равняется отрицанию X.
Дальше T равняется отрицанию Y.
U равняется Z и Y.
V равняется X и T.
Ну и в конце W равняется U или V.
Вот эта прямолинейная программа, ее можно сверху вниз по очереди исполнить.
Ну и тогда, соответственно, мы считаем, что N переменных заранее перечислены и даются извне.
Вот остальные вычисляются по командам программы.
Ну и, соответственно, последняя переменная дает ответ.
Ну или сколько-то последних переменных.
Вот.
Дальше идея такая, что можно переделать схему CoreGraph в прямолинейную программу.
Если завести переменную для каждого узла и в порядке увеличения высоты,
значит записать соответствующую команду присваивания.
Ну, собственно, то, что я сделал, когда писал вот это вот, значит, я сказал, что теперь вот тут будет Z, вот тут будет T,
тут будет V, тут будет W и, соответственно, каждую команду запишем.
Ну и обратно можно превратить программу CoreGraph,
значит, заведя вершину для каждой переменной и проведя, значит, проведя ребра от переменных, участвующих в правой части.
К переменной, стоящей слева.
Вот. Поэтому, на самом деле, более-менее ясно, что схемы и прямолинейные программы – это более-менее два способа описания одной и той же структуры.
Ну а машинная тюринга с подсказкой – это немножко другая вещь.
Значит, машинная тюринга с подсказкой Advice.
Значит, эта машина, которая дополнительно ко входу X длины N, получает подсказку AN,
но которая одна и та же, одна и ту же для всех слов данной длины.
Вот. Ну и тогда, значит, тут есть определение.
Значит, тут идея следующая.
Да, значит, тут уже любую…
В любой схеме можно сопоставить машину, которая может вычислять значения произвольной схемы
и получает эту схему в виде подсказки.
То есть машина получает какой-то X и схему, а дальше просто эту схему применяет к X, и вот это ее ответ.
Ну и наоборот, значит, наоборот, машину можно превратить в схему.
Значит, это несколько более хитрое действие.
Значит, я так аккуратно напишу. Значит, это аналогично теореме Кукалевина.
Но не то чтобы аккуратно.
Идея такая, что у машины может быть некоторый вход, ну и дальше машина начинает с ним что-то делать,
но каждый раз можно считать, что следующая конфигурация получается по какой-то схеме из предыдущей,
а схема такая же, как в теореме Кукалевина.
Машину можно превратить в схему аналогично к теореме Кукалевина и затем зафиксировать подсказку.
И тут есть обозначение, значит, Dtime от t от n slash a от n.
Значит, это класс языков, которые распознаются машиной тюринга с подсказкой длины a от n за время t от n.
Ну и в частности, значит, есть класс P slash Poli.
Это у нас объединение по c и d от единицы до бесконечности.
А тут будет Dtime, значит Dtime от n степени c.
От n степени c slash от n степени d.
Ну и с другой стороны, это самое P slash Poli.
Так, P slash Poli – это класс языков, которые распознаются семействами схем полиномерного размера.
В смысле числа вершин.
Ну как раз вот это вот объяснение показывает, почему это одно и то же.
Потому что с одной стороны, если у нас есть такие схемы полиномерного размера,
тогда мы можем их превратить в подсказку, и подсказка будет тоже полиномерного размера.
Ну а в другую сторону вот так вот.
Давайте превращаем машину и фиксируем подсказку полиномерной длины, получаем схему полиномерного размера.
Вот получается эквивалентность про P slash Poli.
Ну в принципе из обоих определений получаем, что P вложено в P slash Poli.
Вот при этом вложение строгое.
Потому что P slash Poli может содержать даже не вычислимые, не разрешимые языки.
Пример такой, пример унарный язык, 1 степени N, так что машина тюринга на N останавливается.
Называется unary halt. Унарная проблемная остановка, оно словно 1 единиц.
И нужно проверить верно ли что машина номер N останавливается.
Это не you halt, а you self-applicability.
Унарная задача у самопременимости, верно ли что если N машину запустить на ней самой, то тогда она останавливается.
Это вообще неразрешимый язык, потому что проблема установки, проблема самопременимости, как ни скодируете, все равно они будут неразрешимыми.
Это язык неразрешим, так что точно не лежит в P, но он лежит в dead time.
Это вообще можно прям точно сказать, dead time, slash 1, dead time от N, slash 1.
Это зеленейное время, подсказка длинная 1.
Читаем вход, если в нем есть нули, то отвергаем. Если нет, значит если он только из единиц, то смотрим подсказку.
Подсказка нам скажет, остановится она или нет, и это даст правильный ответ.
Вся сложность получается именно в том, что непонятно как зависит эта подсказка от длины, а не в длине подсказки.
То есть сложность, неразрешимость берется из-за того, что нельзя вычислить, как подсказка зависит от длины.
Ну ладно, соответственно, может быть вариация проблемы.
Вариация проблемы P и NP. Вариация проблемы P и NP это вопрос о том, верно ли что NP вложено в slash поле.
Если вдруг вложено, значит если NP вложено в slash поле, то для решения NP-задач фиксированного размера
можно изготавливать малые микросхемы, которые их решают, и потом их использовать.
Соответственно, получается, что это важный вопрос, но есть некоторая связь этого вопроса с вопросами обычной сложности.
Это называется теорема Карпа Липтона.
Если NP вложено в slash поле, то тогда на самом деле полинарархия схлопывается на втором уровне.
Поэтому, если мы верим, что полинарархия не схлопывается, тогда схема нам тоже не подведет решение NP-задач.
Попробую за 10 минут доказать, и на этом сегодня закончу.
Смотрите, нам достаточно доказать, что P2 равняется sigma2.
Это мы уже изучали про иерархию, что если на каком-то уровне схлопывается, то их последующие тоже схлопываются и наоборот.
А для этого достаточно доказать, что задача P2-сад лежит в sigma2.
Смотрите, что у нас такое P2-сад. Давайте вспомним.
P2-сад. Это есть множество таких phi, что для любого x существует phi от x, y.
Если мы x зафиксируем и рассмотрим теперь такой язык, то пар phi, x таких, что существует phi от x, y, лежит в NP, потому что тут существование.
Следовательно, лежит в P slash поле по предположению, которое у нас предположительно вложено в P slash поле.
Что это значит? Это означает, что есть некоторое семейство схем, которое мы как-то обозначим Dn.
Есть семейство схем Cn такие, что Cn от phi, x равно 1, если существует y, такое, что phi от x, y.
И 0 иначе.
Их можно переделать в семейство схем Dn такие, что Dn от phi, x.
Dn от phi, x. Это будет решать задачу поиска.
У такой, что phi от x, y равно 1, если такой у существует.
Это стандартный переход от распознавания к задачам поиска.
Упражнения используя идеи, которые у нас были.
Переделаем семейство схем, которые ищут.
Ну и тогда получается следующее.
Фи лежит в P2SAT, тогда и только тогда.
Когда существует Dn такое, что для любого x, phi от x и Dn от phi, x.
Фи от x равно 1.
Почему это верно? В одну сторону слева направить это из предыдущего следует.
Фи от x и Dn от phi, x как раз такой у возвращает, что phi от x, y равно 1.
То есть эта часть будет как раз нужным у.
В другую сторону, даже не важно, Dn будет так или не так.
Для любого x найдется такой у, взявшийся Dn от phi, x, такой, что phi от x, y равно 1.
Вот так вот.
Это уже sigma2 формула.
Вот.
Вот такая вот теорема.
Какие-нибудь вопросы может быть есть?
Ладно, дайте я тогда анонсирую на следующий раз.
Теорема мейера будет такой.
Если exp вложено в p-slash поле, удивительно, что это не умеет опровергать.
Если exp вложено в p-slash поле, то exp будет равняться sigma2 полиномиально.
Во-первых, более сильное условие.
То есть тут из вот этого следует вот это, конечно.
Но и более сильное утверждение.
Опять же, из этого следует вот это, потому что pH будет между exp и sigma2.
Хорошо, тогда на сегодня получается всё.
В следующий раз теорема мейера докажем.
Поговорим про разные другие задачи, вроде быстрого суммирования, потому что там важен не только размер, но и глубина.
Ну и, наверное, как раз этого будет достаточно для следующего раза.
Значит, если закончим раньше, то начнём изучение вариации классов.
Какие-нибудь вопросы?
Ну и сегодня всё. Спасибо за внимание.
