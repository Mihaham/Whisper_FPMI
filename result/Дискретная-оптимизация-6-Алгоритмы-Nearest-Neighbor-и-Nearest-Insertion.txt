Прошлый раз мы только-только, по-моему, определили задачиками Вежора, что это такое, но мы уже
определили ее в трех вариантах. Первый вариант – это самый общий для произвольного графа,
второй вариант – для аметрического графа. И, кстати говоря, аметрический граф, он какой?
Аметрический, да? Какой? Полный, да? Значит, полный, потому что, если между двумя вершинами есть
путь через третью, то и ребро напрямую должно быть, и вес этого ребра должен не превосходить
суммы весов двух ребер через промежуточную вершину. Из этого следует, что наш граф вообще
полный, и у нас не возникает вопрос, существует в нем гамильтонов цикл, например, или нет,
поэтому на аметрическом графе как раз осмысленно решать задачиками Вежора приближенно. Вот в
отличие от совсем произвольного случая, где, ну вообще говоря, гамильтонов цикл даже может
не быть, и тогда не очень понятно, что значит, что мы приближаем решение задачи, да? Значит,
так вот, мы с вами будем во всех дальнейших рассуждениях, когда мы будем какие-то показатели
аппроксимации получать для алгоритмов, мы будем предполагать, что граф у нас полный и метрический,
функция весов метрическая. Вот, но еще мы рассмотрели один специальный случай, когда граф евклидов,
то есть вершины графа это просто точки на плоскости, а ребра графа это отрезки между
точками и длины отрезков, это соответствующие веса ребер. Те примеры, которые мы будем рисовать,
естественно, мы будем понимать, как бы эти примеры, как метрические графы, что это удобно,
потому что сразу на доске не надо подписывать веса ребер, мы сразу видим вот отрезок,
этот длиннее, чем вот этот вот, да, и мы понимаем, как алгоритм должен действовать. И вот мы с вами
в прошлый раз рассмотрели два алгоритма, два приближенных алгоритма для метрической задачикам
его ежора. Один алгоритм назывался ближайший сосед, а другой алгоритм назывался кратчайшие
вставки. Наоборот, да, ближайший сосед это NN, а другой назывался кратчайшие вставки. Вот,
и оба алгоритма они такие жадные, очевидно, жадные, один из них каждый раз идет в ближайшую
точку из еще непосещенных, а другой алгоритм вставляет вершину на такой маленький цикл,
но ближайшую из всех вершин к этому циклу, поочередно там вставляет по вершинке,
пока у нас не получается цикл, охватывающий все вершины графа. Вот, начнем мы, пожалуй,
с анализа более простого алгоритма, и хотя вот какой из этих алгоритмов кажется более простым,
наверное, ближайший сосед. Ну, у него какое-то правило более простое, не надо ничего никуда
вставлять, просто бабах, ребро провел, потом бабах, следующее ребро провел, да, а вот здесь вот все
время что-то надо удалять одно ребро и вставлять два других ребра. Процедура чуть посложнее,
но оказывается, что анализ этого алгоритма, он в итоге проще, и коэффициент опроксимации,
который мы сегодня получим, он тоже поприятнее. Значит, вот у этого алгоритма ближайшего соседа
оказывается, что коэффициент опроксимации порядка в худшем случае, порядка логарифма от числа
вершин графа, а вот у этого алгоритма коэффициент опроксимации не порядка, а просто двойка. Вот,
здесь как в рюкзаке получается, а здесь получается как в покрытии, да, в покрытии у нас тоже там
логарифмичный был по размеру матрицы коэффициент. Ну вот, поехали. Значит, мне нужно будет в анализе,
чтобы вы вспомнили, чтобы мы с вами вместе вспомнили, как работает алгоритм Прима.
Алгоритм Прима решает задачу о минимальном основном дереве, minimal spanning tree, МСТ. Вот,
можете напомнить, как работает этот алгоритм? Ну, у нас там все алгоритмы жадные, Примы,
Барувки и Краскала, вот как именно он жадно действует. Да, мы в этом смысле жадничаем,
мы выбираем каждый раз ребро самое легкое. А среди каких ребер? Вот Краскал, он выбирает
просто среди всех ребер минимальная по весу, лишь бы только циклы не создать. А Прим, да,
Прим стремится к тому, чтобы каждый раз множество вершин, охваченных нашими ребрами, образовывало
связанный кусочек графа. То есть, грубо говоря, алгоритм Прима, он наращивает вот это вот остальное
дерево. Значит, оно просто сначала не покрывает все вершины графа. У нас есть много-много в графе
вершин, но он поочередно растит это дерево, добавляя каждый раз к текущему дереву вершинку,
которая, ну, фактически ближайшая к уже покрытым вершинам. То есть, мы рассматриваем множество
всех не покрытых, не охваченных вершин и множество всех охваченных вершин. И вот где здесь
кратчайшее ребро, вот алгоритм ищет, и вот именно это ребро и вставляет, добавляя тем самым
еще одну вершину ко множеству охваченных вершин. Такая, не знаю, какие приводить примеры линия
Пронта. Да, что-то в голову лезут какие-то кривые примеры вот в последнее время. Ну вот,
на ощупь, охваченные вершины, неохваченные вершины в алгоритме Прима. И, значит, в итоге он
всей вершины покрывает. То есть, как раз достигает островного дерева. И алгоритм кратчайших вставок,
если мы с вами вспомним, как он действует, он действует следующим образом. Я этот алгоритм
прям вот здесь справа попробую нарисовать. НН. Миростный. Да, что этот алгоритм делает? Он
начинает, помните, с кратчайшего ребра вообще в графе. Потом он добавляет вершину ближайшую
к этому кратчайшему ребру, строит такой треугольничек. А потом ведь у него правила ровно такое же. То есть,
он берет какие-то охваченные вершины. Ну вот, я здесь уже нарисую какую-то общую картину. И эти
вершины охвачены циклом. И он берет к этим охваченным вершинам, добавляет еще неохваченную,
одну из неохваченных вершин, неохваченных процессом. И добавляет из всех вершин самую
ближайшую. А потом он уже, когда выбрал вершину, которую добавляет в этот цикл,
что он делает? Он убирает ребро из цикла одно и добавляет два других ребра так, чтобы эта вершина
встала на цикл. Ну, делает он это оптимальным образом. То есть, здесь дальше происходит, как бы
здесь происходят два шага. Первый шаг — это выбор добавляемой вершины. И вершина — это та же
самая, что и в алгоритме Прима, по сути дела. И второй шаг — это выбор оптимального способа добавить
уже зафиксированную вершину на цикл. Тут тоже происходит минимизация, еще одна. Вот. Но что
можно сказать? Вот из того, что правила выбора добавляемой вершины и в nearest insertion и в Приме
одинаковое, что на каждом шаге множество вершин, охваченных процессом, охваченных вот под графом
специального вида, только здесь это дерево, а здесь это цикл, оно будет одно и то же. Правильно?
Вот. Если на каждом шаге выбирается одна и та же вершина и с левой и справа, значит,
и на каждом шаге множество охваченных вершин одно и то же. И это очень полезно. Это очень
полезно нам будет заметить. Вот. Но давайте теперь, я не знаю, вот где-то это можете записать,
да, но давайте я справа вот здесь запишу, что множество вершин, покрытых на каждом шаге,
соответственно, деревом и циклом в алгоритме Прима и в алгоритме nearest insertion одинаково.
Множество охваченных вершин на каждом шаге
в алгоритме Прима, ну я вот так и буду писать, Прим, и в алгоритме Ni одно и то же.
Так, это первый факт. Давайте теперь посмотрим на самое-самое начало алгоритма Прима и nearest
insertion. Вот в самом начале алгоритма Прима выбирается кратчайшее ребро и в алгоритме
nearest insertion выбирается кратчайшее ребро. То есть, вот самый первый шаг, здесь вообще еще цикла
даже нету и вот эти два подграфа выглядят абсолютно одинаково. А потом мы добавляем вершину ближе
к этому ребру, ну и в Приме мы тоже добавляем вершину ближайшую к этому ребру. Просто здесь мы
проводим одно только ребро, чтобы получилось маленькое дерево на трех вершинах, а здесь мы берем
тоже самую вершину, но мы вынуждены добавить два ребра, потому что нам цикл нужен. И вот с этих
пор уже графы вот здесь, вот здесь будут все-таки они будут разные. Но что мы можем сказать относительно
суммарного веса ребер, которые здесь нарисованы и тех ребер, которые здесь нарисованы? У нас же
есть неравенство треугольника, мы с вами будем анализировать все только в предположении аметричности
графа. И исходя из неравенства треугольника, если мы посмотрим на вот это вот ребро, у него же все
равно вес не больше, чем сумма весов вот этих вот двух ребер. Что мы можем сказать про вот этот
вот под граф целиком и вот этот вот под граф целиком? Если это ребра, значит, давайте я вершину
назову A, B и C. Соответственно здесь у нас вес под графа, это вес AB плюс вес BC, а здесь у нас вес
AB плюс вес BC, ну и плюс, конечно, вес AC, но по неравенству треугольника вот эта штука не превосходит
веса AB плюс веса BC. По тому же ровну принципу, что и в приме, то есть это вершина, ближайшая к
охваченным процессам вершин. Нет, то есть просто вот представьте, что у вас есть множество вершин,
входящих в цикл, и вот вы выбираете вершину, ближайшую к этому циклу, то есть вы рассматриваете
всевозможное расстояние от каждой вершины графа, изолированной пока что, к каждой вершине цикла,
и берете минимум фактически вот такой штуки W от XY, где вершина X принадлежит циклу,
которую у вас на данный момент есть, а Y не принадлежит циклу, а в приме у вас происходит
ровно то же самое, вы ищете вершину, которая минимизирует вес XY, где X принадлежит вершинам
охваченным деревом, а Y не принадлежит вершинам охваченным деревом, это абсолютно одинаковые на
самом деле правила, просто тут дерево, тут цикл, а множество вершин, на которых существует это
дерево, этот цикл совершенно одинаково. Так, ну вот, это мы потрем, ну и что получается,
да, что раз вот эта вот штука по неравенству треугольника не превосходит на самом деле вот
этого, то суммарный вес вот этих вот трехрёбер, он не превосходит удвоенной суммы W от AB плюс W
от BC, правда, вот, и значит, вот можно сказать, что вес текущего цикла, который у нас с вами тут,
он не превосходит удвоенного веса текущего дерева, который у нас с вами здесь, это T маленькое
такое пока очень, а вот это вот C тоже маленький пока очень, а в конце, после всех всех шагов,
вот этот вот цикл C, это гамильтонов цикл уже будет во всем графе, а это дерево T, это будет
остывное дерево во всем графе, да, но давайте мы сейчас докажем с вами, что на каждом шаге та
прибавка, которая у нас получается к циклу, когда он растет немножко, да, разрастается,
она не превосходит удвоенной добавки, которая вот к этому дереву у нас прирастает. Сейчас мы
это в общем случае с вами проверим, значит, ну, давайте я пока напишу то, что мы здесь, то,
что мы здесь с вами имеем, а здесь мы имеем вот что, что после первых двух шагов,
после первых двух шагов, когда мы имеем дерево на трех вершинах в приме и цикл на трех вершинах
в nearest insertion, вес цикла в алгоритме nearest insertion не превосходит не больше удвоенного
удвоенного веса дерева в алгоритме prima. Вот пока нам нужно только вот это, в это поверить,
ну и дальше давайте вот проанализируем в общем виде, что будет происходить при
добавлении, что будет происходить при добавлении. И представьте себе общую картину, вот здесь
какой-то опять prim и ni, вправо, вот, и вот есть какое-то множество вершин, совершенно одно и
то же, просто оно, на нем разные графы у нас сидят, да, вот здесь вот у нас в приме сидит какое-то
дерево на этом множестве растет, а здесь у нас, значит, некий цикл по этому множеству проходит,
но в общем-то множество вершин одно и то же, и вершина, которая добавляется к этому, вот это
вот новая вершина, ну давайте я ее обозначу v, пусть она будет v, она абсолютно одна и та же вершина,
которая добавляется. Так, как эта вершина добавляется на цикл? Как она добавляется на цикл?
Мы минимизируем при добавлении ее на цикл, что мы выбираем две какие-то вершины, соседние по циклу,
да, минимум, и мы минимизируем, что добавку, которая получается, если убрать ребро между
этими вершинами и вставить вот эти вот два ребра, то есть какая получается у нас добавка здесь,
вот давайте посмотрим, что именно мы минимизируем при добавлении вершины, но если эту вершину назвать
a, а эту вершину назвать b, то тогда мы минимизируем сумму весов va плюс vb и минус вес ab, правда?
Вот мы берем минимум вот такой вот величины по всем возможным соседним по циклу вершинам ab,
таким-таким-таким-таким вот перебираем, да, все такие пары, по вершинам a и b,
соседним по циклу, значит, по всем a и b, соседним на цикле. Так, окей, окей, а что у нас прим делает?
А прим он в этом смысле он немножко посвободнее, потому что здесь мы выбираем все-таки, мы не можем
взять просто две произвольные вершины вот на всем этом множестве, да, мы берем именно пару вершин
соседних на цикле, которые у нас уже здесь есть, а прим более свободный в этом смысле, он может
выбрать вообще любую вершину вот здесь вот, да, среди охваченных деревом и просто провести в нее
ребро, то есть то, что делает прим, он добавляет, вот здесь у нас добавляется к весу, да, вот такая
вот величина, а прим добавляет нам к весу минимум wx по всем вершинам x охваченным, да, вот здесь вот,
по всем возможным вершинам x, согласны, но этот минимум же достигается на каком-то x все-таки,
да, вот пусть вот этот вот минимум достигается на каком-то конкретном x, давайте рассмотрим
этот самый x со звездочкой, на каком-то же x он достигается, x со звездочкой или x с волной, да,
то есть реальная добавка получается это все-таки w какого-то конкретного там vx с волной, бамс,
если бы мы взяли и посмотрели на этот самый x с волной, ну, допустим, это вот этот вот x с волной,
допустим, это вот этот x с волной, давайте я a и b уберу здесь, мы же не знаем какие конкретные
это a и b там будут выбраться, но вот где-то здесь все равно живет вершина x с волной,
и у этой вершины x с волной есть сосед по циклу, ну, какой-нибудь там y с волной, вот мы можем
здесь рассмотреть на этом цикле ту самую вершину x с волной, которую выбрал прим, вот здесь,
и ее соседа y с волной, согласитесь, что вот эта вот добавка, где берется минимум по всем возможным
выборам пар соседей на цикле, эта добавка не превосходит добавки, при которой мы конкретно взяли
x с волной и y с волной его соседа, удалили ребро между ними и вставили вот такие два ребра, правда?
Значит, добавка у нас здесь получается не больше, чем wvx с волной плюс wvy с волной минус wx с волной
y с волной, добавка получается не больше, чем такая, давайте просто проверим, что вот эта вот величина,
которая добавлена у нас к весу цикла вот этим алгоритмом, не превосходит удвоенной вот этой вот
величины, проверяем, проверяем, ну давайте я это вот здесь вот попроверяю, значит верно ли, что wx
с волной v плюс y с волной v минус x с волной y с волной не больше, пока под вопросом, чем два веса ребра x с волной v.
Ну давайте как-то это преобразуем, да, значит во-первых мы можем убрать вот эту штуку, а вот этот вот
коэффициент двойку заменить на единичку, а дальше мы можем перенести вот эту штуку вправо, да, то есть
вот это вот неравенство, оно эквивалентно неравенство такому, w y с волной v не превосходит,
эту штуку вправо перенесли, получается такая штука, x с волной y с волной плюс x с волной v. Как же это
неравенство доказать? Я в замешательстве. И откуда оно следует? Откуда следует такое неравенство?
Да, это же неравенство треугольника, да, вот у нас треугольник на точках y с волной v x с волной,
и мы говорим, что напрямую пройти между этими двумя точками не дольше ходить, чем ходить через
какую-то точку, сначала пойти из y с волной в x, а потом из x пойти в v, и это ребро не больше,
чем вес этого ребра, не больше, чем сумма весов вот этих вот двух ребер, это просто неравенство
треугольника, а мы предполагаем, что у нас задача решается на метрическом графе, это важно,
без метричности ничего не работает, но метричность это в точности вот это вот неравенство,
и следовательно у нас вот это вот неравенство выполнено, и следовательно добавка к алгоритму
nearest insertion на этом шаге не превосходит удвоенной добавке алгоритму прима на этом шаге, а мы
рассмотрели с вами общий случай, какой это произвольный шаг, то есть мы с вами получаем
сейчас третий пункт, что на каждом из следующих шагов, на каждом из остальных шагов добавка
к весу цикла в алгоритме nearest insertion не превосходит удвоенной добавке
к весу дерева в алгоритме прима, чудесно, и какой же вывод можно сделать из этого,
если после первых двух шагов вес цикла не больше удвоенного веса дерева, маленького-маленького,
а потом на каждом следующем шаге добавка к весу цикла не больше удвоенной добавки к весу дерева,
какой из этого вывод можно сделать? Да, точно, что вес цикла итогового не превосходит удвоенного
веса дерева, итогового, а алгоритм прима, теперь мы уже вспоминаем, что алгоритм прима
это шняба, что алгоритм прима строит минимальное основное дерево графа, следовательно, мы можем
из вот этих вот пунктов сделать такой вывод, что вес алгоритма, вес цикла, который построен
алгоритмом nearest insertion не превосходит удвоенного веса дерева, который строит алгоритм прима,
но алгоритм прима строит минимальное основное дерево. Вот пока мы с вами вывели такое неравенство.
Ну и осталось нам заметить, что вообще в любом метрическом графе вес минимального
основного дерева не превосходит веса гамильтонного цикла, любого. Давайте посмотрим, почему.
Конечно. А просто по определению, вот мы сказали, что алгоритм nearest insertion, он так работает,
мы выбираем сначала, какую вершину будем добавлять, и только когда мы уже зафиксировали,
какую вершину добавляем, тогда мы только выбираем оптимальный способ вставить ее на циклу.
Сперва ближайшую. Но понятно, народ, смотрите, да, это вопрос хороший, потому что он нас
определяет. Вот это алгоритм, который специально сформулирован так, чтобы его было удобно
проанализировать, потому что он работает очень похоже на алгоритм прима, потому что мы контролируем
как бы то множество вершин, с которым имеем дело на каждом шаге. Но в реальности, естественно,
вы можете немножко здесь смухлевать, и не то что сначала выбирать добавляемую вершину,
а потом уже выбирать, как ее добавить, а сразу минимизировать по всем возможным вершинам и по
всем возможным способам их добавить. То есть вроде каждый шаг по-прежнему получается такой
локальной вставкой, но эта вставка может быть уже более оптимальна на практике, чем вот такая
теоретическая вставка из двух шагов. То есть практическая реализация алгоритма, она может
быть немножко другой. Получится такой алгоритм nearest-insertion-штрих, или nearest-insertion с крышкой,
который на практике будет невозможно также проанализировать четко, но он может быть
практически лучше. Так, ну вот нам остался последний шаг здесь. Вот доказать, что осталось
доказать. Осталось заметить, что вес МСТ не превосходит вес любого гамильтонного цикла на самом
деле, но в частности оптимального гамильтонного цикла, естественно, раз любого.
Почему? А давайте мы в графе возьмем, вот у нас граф G, на котором мы решаем задачу. Давайте возьмем
там самый-самый оптимальный гамильтонов цикл. Да, любой гамильтонов цикл возьмем. Что будет,
если у гамильтонного цикла одно ребро удалить? Получится остовное дерево, да, ну или остовное
дерево, я не знаю, как там лучше ставить ударение. Получится, значит, остовное дерево. Оно, конечно,
очень специфическое, оно называется гамильтоновой цепью. Вот есть гамильтонов цикл, а есть гамильтоновая
цепь. Тоже цепь, проходящая через все вершины по одному разу. Но кто поспорит с тем, что это
дерево? Конечно, дерево, а циклический связанный граф. Остовное, конечно, остовное. То есть это
какое-то остовное дерево, которое, очевидно, имеет вес не больше, чем вес этого гамильтонного
цикла. Потому что мы удалили из него одно ребро, а веса всех ребер не отрицательная. По предположению,
я уже забыл, мы предполагали, я думаю, сначала. В метрическом графе у нас по определению веса
всех ребер не отрицательные. И минимальное остовное дерево, очевидно, имеет вес не больше,
чем какое-то остовное дерево. А это остовное дерево имеет вес не больше, чем гамильтонов цикл,
из которого оно получено. Вот и все. Отсюда следует это неравенство. То есть вот это
неравенство, оно вообще выполняется для произвольного графа абсолютно. Оно просто следует из вот этих
соображений, что из цикла гамильтонного элементарно получить гамильтонову цепь,
которая является частным случаем остовного дерева. И это неравенство не опирается на... ну,
оно опирается единственное на что, что веса всех ребер не отрицательная. Но сложно себе представить,
чтобы вы задачу решали на отрицательных весах. Ну, можно, но сложно. Вот. Но во всяком случае это
неравенство не требует метричности. А вот весь предыдущий анализ алгоритма у нас требует
метричности. У нас вот это неравенство, оно не прошло бы без метричности графа. Ну и все. Вот мы
это с вами заметили, вот этот факт. И теперь мы получаем, да, что... такой вывод.
Алгоритм кратчайших вставок, это алгоритм, имеющий показатель аппроксимации два. Да, то есть это
два аппроксимация для алгоритма... для аппроксимации, значит, для задачи ТСП. Ну вот. Мы с вами
разобрались с более простым из алгоритмов, с кратчайшими вставками, и на это у нас ушло пол
лекция. Так что, может быть, мы не успеем целиком сегодня разобраться с ближайшим соседом. Но мы с ним
начнем разбираться, во всяком случае. Так. Давайте сохраним это как замечание, кстати говоря,
то на практике... на практике вставку не обязательно выполнять в два этапа. Не обязательно выполнять
в два этапа. Ну, то есть выбор вершины, а потом только вставка, да. Выбор вершины, выбор вершины,
выбор вставки, способов вставки на цикл, да. Значит, может... может получиться лучше, если вы
сразу выбираете оптимально и вершину, и способ вставить. Значит, может на практике получиться лучше, да.
Лучше, но без теор-анализа. То есть, для теоретического анализа нам это было важно,
что два алгоритма можно параллельно запустить, и у них будет много общего, но без теоретической
гарантии. Так, ну, давайте мы пойдем теперь анализировать ближайшего соседа. Если, да,
если здесь могу что-то прокомментировать, то, пожалуйста, сейчас еще, пока не стер, все могу.
Так, поехали к ближайшему соседу.
Значит, мы с вами докажем, что вес ближайшего соседа не превосходит... ну, я не помню уже,
какой там коэффициент у меня, по-моему, 4 алгоритма количества вершин в графе помножить на вес
оптимального галитонного цикла. Вот, причем по порядку вот эта штука достижима. Значит,
достижима по порядку. То есть, не то что я вам там поленился предлагать какой-то хороший анализ
этого алгоритма, просто действительно этот алгоритм можно опять-таки заставить ошибаться
во столько раз. Мы не будем здесь приводить пример аналогичный вот тому, что у нас был с матрицы,
потому что пример чуток посложнее, время жалко на него, но вот верхнюю оценку мы здесь получим. Мы
с вами будем доказывать вот это утверждение. Тихо. Мы с вами будем доказывать это утверждение
следующим образом, просто чтобы мы сразу с вами представляли план доказательства. Значит, вот у нас
есть граф. У ближайшего соседа есть такая особенность, что вот из каждой вершины графа
торчит ровно одно ребро, которое было добавлено ближайшим соседам ровно в тот момент, когда мы как
бы в этой вершине сидели. Мы на каждом шаге вот из какой-то вершины проводим очередное ребро.
И мы с вами можем просуммировать по всем вершинам графа веса вот этих вот ребер.
У каждой вершины такое волшебное ребро есть, добавлено ближайшим соседам. Но это, если вы
помните, мы уже чем-то таким занимались. Мы при анализе жадного алгоритма в покрытии тоже там
что-то такое связывали. С каждым шагом, правда, несколько каких-то пометок, которые мы на столбцах
матрицы расставляли. А здесь вот у нас с каждой вершиной графа связана вот эта вот величина,
длина торчащего из нее ребра, которая выбрана ближайшим соседам. Мы с вами проделаем следующее.
Мы с вами выберем в графе некоторое подмножество вершин, и нам удастся доказать, что в этом
подмножестве достаточно много вершин, и при этом сумма весов-ребер, которые из них торчат,
выбранных ближайшим соседам, общая сумма весов не превосходит веса оптимального гамильтонного цикла
в графе. Вот каким-то таким чудом нам это удастся сделать. Не превосходит WO. Дальше, я думаю,
что можно догадаться, что будет. Вот дальше мы возьмем вот эту часть графа, и здесь снова
попытаемся откусить какой-то кусочек, так чтобы сумма весов-ребер, торчащих из этих вершин,
тоже была не больше, чем WO. И так дальше. Вот так вот мы из графа пооткусываем кусочки до тех пор,
пока весь граф не закончится. Как вы думаете, сколько примерно будет вот таких вот кусочков?
Ну так, судя по оценке, вы же физики, вы от ответа как бы можете танцевать, да?
Значит, если у нас в итоге должна получиться какая-то такая оценка, то это означает, что если у
нас много-много кусочков, и в каждом сумме не больше WO, значит кусочков, скорее всего,
будет как раз логарифмичное число относительно размера вершин графа. То есть мы проделаем
логарифмическое по размеру графа число шагов вот в этом процессе. Выбираем множество вершин,
оцениваем сумму весов и ребер, которые торчат из этих вершин в ближайшем соседе. Из оставшегося
графа тоже выбираем множество вершин, оцениваем и так дальше и так дальше. Вот давайте мы попытаемся
этот план теперь воплотить в жизнь. Давайте обозначим для каждой вершины графа такую величину,
возьмем, назовем ее, ну, например, L от V. Вот пусть это L от V, это и есть длина
ребра, вес ребра, вес, вес ребра, добавленного, добавленного в тыкву алгоритмом nearest neighbor,
момент, момент, когда вершина V была активной такой, когда мы как раз в ней сидели и думали,
куда дальше пойти. Вершина V была активной. В фокусе была эта вершина, вот в этот момент.
Ну и сразу заметим то, что мы уже здесь заметили, что сумма вот этих вот L от V по всем вершинам
графа, это и есть вес цикла, построенного алгоритмом ближайшего соседа. Так что нам с вами надо
оценить вот эту сумму, и мы ее оценим, разбив ее на много-много мелких сумм. Внутри каждой мелкой
суммы у нас получится нечто непревосходящее Wopt, а всего таких сумм у нас получится логарифмичное
число по размеру вот этого множества, по числу вершин графа. Давайте докажем пару лемм, но они не
сложные, то есть то, что они называются леммами, это нас не должно пугать, вот, но все-таки я их
сформулирую отдельно. Значит, во-первых, для каждого ребра графа, для каждого ребра, вам вот эти
обозначения не сбивают вас в толку, там E от G, V от G, ребра графа, вершины графа, для каждого ребра
графа выполнено одно из двух неравенств, а может быть оба. L от A не больше W от AB, или L от B не
больше, чем W от AB. Вот, а можете как-то это обосновать, причем эта совокупность, да, это не
система, вот нам гарантируется, что хотя бы одно из этих неравенств имеет место, может быть оба, вот,
но хотя бы одно. Точно, да, точно, то есть какое бы ребро, действительно, мы не рассмотрели, AB,
но я вот так пунктиром возьму. Вот, ближайший сосед, он путешествовал по графу, он либо сначала
посещал вершину A, либо сначала B, но допустим, что он сначала посещал вершину A, стартовал
откуда-то и шел-шел-шел-шел, но находясь в вершине A, алгоритм мог потенциально выбрать вот это вот
ребро AB, да, но в любом случае он выбирал самое оптимальное ребро, и он мог выбрать вот это ребро,
в числе прочих, потому что вершина B еще не была посещена, можно было бы выбрать ребро AB,
но поскольку жадный алгоритм, у нас жадный по сути алгоритм, да, он выбирал ребро непревосходящее,
значит, по весу AB, здесь же минимум берется фактически, да, вот в этот момент, минимум по всем
возможным ребрам, которые можно из вершины A взять, вот, а это просто одно из ребер, которое торчало
из вершины A и которое потенциально можно было взять, то есть, если вершина A посещалась раньше,
то у нас гарантированно выполняется это неравенство, может быть, это тоже выполняется, мы не знаем,
если вершина B посещалась раньше, то гарантированно выполняется второе неравенство, может быть,
даже и первое, не знаем, но хотя бы одно из них точно выполняется, вот, это на самом деле как раз
важный момент, который следует из, ну, определения того, что наш алгоритм, это жадный, по сути, алгоритм,
не знаю, доказать, что писать какое-то или нет, или так, в общем, оставить,
давайте так оставим, да, так, сейчас я и это потру, все равно я не помню точно,
но константа там 4 или не 4, удастся она получить четверку здесь или что-то большее,
но важен здесь порядок. Давайте мы рассмотрим с вами теперь, рассмотрим с вами легкие ребра графа,
назовем ребро легким,
если его вес не превосходит удвоенного, например, среднего веса ребер в оптимальном
гамильтоновом цикле. Давайте мы ребро E обозначим, легкое, да, если вес этого ребра
не превосходит удвоенного среднего веса ребер в гамильтоновом цикле. А какой средний вес
ребер в гамильтоновом цикле? Ну, число ребер в гамильтоновом цикле в оптимальном
равняется количеству вершин в графе. Количество вершин в графе
обзовем n. Пусть будет n. Это средняя, это удвоенная средняя. Давайте заметим, что
легких ребер у нас в гамильтоновом цикле не слишком мало. В оптимальном гамильтоновом
цикле, в оптимальном гамильтоновом цикле, легких ребер не меньше половины,
не меньше n пополам. Почему? Ну, потому что иначе очень легко получить противоречие. Иначе было бы
такое неравенство. Если бы легких ребер было меньше, чем n пополам, значит тяжелых ребер было бы
больше, чем n пополам, правда? И вес гамильтонового цикла, это же сумма всех входящих в него ребер. И
получается, что он было бы больше, чем количество тяжелых ребер, помножить на вес тяжелого ребра.
А вес тяжелого ребра, ну, не легкого ребра, это что-то большее, чем вот эта вот величина. 2 делить
на n на w опт. Значит, это вот вес тяжелого ребра, вес нелегкого ребра, нелегких ребер. Ну,
нижняя оценка этого веса, а это количество нелегких ребер. Противоречие. Не знаю,
как это противоречие, вот так обозначим. Так, это, кстати говоря, такой дискретный аналог
неравенства Маркова. А у вас уже было неравенство Маркова? А у вас тервера еще не было, да?
А у вас уже было неравенство Маркова? А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да
А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова
Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да.
А у вас уже было неравенство Маркова? Да. А у вас уже было неравенство Маркова? Да.
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
Продолжение следует...
