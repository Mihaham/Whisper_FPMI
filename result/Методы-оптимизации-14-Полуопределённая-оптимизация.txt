все отлично на запись поставлю запись включена теперь давайте начнем наше занятие сегодняшнее и
сегодня обсудим полуопределенную оптимизацию так сейчас надо выводить правильный цвет и
правильную толщину полуопределенную оптимизация ну это может быть не самый удачный это прекрасно
не самый удачный перевод термина семи-дефинит-семи-дефинит-програминг-программинг-проблемс
вот то есть как бы их СДП вот то есть у нас были разные конусы и когда у нас был конус положительно
полуопределенных матриц то мы называли такие задачи именно полуопределенной оптимизации сегодня
мы про них поподробнее поговорим но самое главное пытаемся понять зачем они нужны и какая ну какие
они какие приложения существует у подобного рода задачи вот значит ну давайте начнем немножко
издалека и скажем откуда вообще их можно вывести что ли как каким образом можно
получать подобного рода задачи вот ну вот смотрите у нас было линейное программирование
в какой-то момент когда мы минимизировали линейную функцию при условии что у нас было
линейное ограничение равенства и условия отрицательности вот и тут у нас был переменным
понятное дело что у нас был xzrn вот и мы искали вектор значит теперь если мы переходим от вот
этого конуса который у нас rn плюс к точнее неправильно не до стрелочка вот так а rn плюс у нас
перейдет в sn плюс то есть конус полосимметричных положительно полуопределенных матриц то что
изменится то есть у нас переменная становится матрицей вот и отсюда получается что в этом
случае у нас мы минимизируем скалярные произведения по-прежнему а скалярный прием между
матрицами это след от их произведения вот это раз второе что происходит это вот вот эта штука
ой вот эта штука она переписывается как так что то есть здесь что написано сомнелись
написан набор скалярных произведений строк матрицы а на x равный боитому вот опять все
свели к скалярным произведениям для того чтобы потом просто заменить скалярное произведение
строк матрицы а на x на скалярный произведение между некоторым матрицами аитами умноженными на x
и сказать что это равно тем же самому тому же самому числу боитому вот ну и соответственно
не отрицательность по элементное которая является коническим ограничением она переписывается
просто что у нас x не отрицает на определенные матрицы вот таким образом можно обобщить задачу
линейного программирования стандартной то есть вот это вот лп задачи
в канонической или стандартной форме вот и из нее мы получаем собственно с дп задачу в
я конечно забывать терминологию в стандартной форме да потому что есть еще не совсем стандартный
который мы сейчас с вами получим записав двойственную к этой задаче все у нас лежит в
сн и все аиты тоже симметричны ну это будет просто-напросто нужно чтобы мы всегда по умолчанию
живем в мире симметричных матриц для того чтобы у нас были прекрасные характеристики симметрики
прекрасные характеристики определенности связанные со спектром вот понятно ли какие
преобразования мы проделали почему-то в общем-то все это более-менее работает
так прекрасным теперь давайте поймем каким образом мы можем двойственно получить к этой
задаче вот наше любимое занятие это настроение двойственных задач к исходным для того чтобы
затем используя прямо двойственные методы которые мы видимо поговорим в следующий раз
которые одновременно обновляют и прямые двойственные переменные ну то есть решает
одновременно и прямые задачи двойственную получить гарантии в терме зазора двойственности на
сходимость вот ну что обычно пишется лагранжан возможно мы это уже какое-то время назад делали
вот ну давайте быстро повторим пишем не будет след а и т x минус б и т и минус скалярные произведения
лямбада на x вот ну здесь тоже след поэтому мы просто выносим все что связано с x а именно
c плюс сумма лямбда и т а и т минус лямбда большое это все умножается на x вот и остаток остается
остается только минус ой не равно а минус сумма лямбда и т б и т вот из чего следует что когда
мы будем минимизировать это все дело по прямым переменам то есть по иксу по вот этому то у нас
останется только вот эта штука вот а вот все вот это вот благополучно благополучно должно быть
за нулено за счет убирания вот это вот коэффициенты которые в рамочке находится вот есть наша двойственная
задача будет максимизировать отрицательную линейную линейное выражение относительно лямбд вот и
потребовать дополнительно чтобы что чтобы ц плюс сумма лямбда и т а и т было бы равно лямбаде и
ну и лямбда было бы не отрицать напрямую как нож селила гранжа вот то есть вот такая вот довольно
прямолинейная прямолинейная форма будет у двойственной задачи понятно ли что здесь происходило так
отлично можно также немножко сказать сравнить просто вот то с чего мы начинали вот это вот
все вот это вот сравнить с тем что у нас получилось в случае когда может так типа лп с дп
вот здесь у нас допустимое множество это многогранник
но гол гранник вот то есть у нас подпространство и мы вырезаем отрицательный актант в этом
подпространстве вот здесь допустимое множество что-то странное то есть здесь допустим но что
не многогранник вот и оно выражается более сложным некоторым образом так так так так так так так
так так все ли я правильно написал бом бом бом больше либо равна нуля
ну да двойственная форма правильная да здесь допустим но что некоторые сложно структуру имеет
потому что у нас переменами является уже матрица и запись уравнений на их коэффициенты
и это что-то ну будет какая-то нелинейная поверхность будет ограничивать наша выпуклая
множество скорее всего там будут если так пытаться в 2d на 2d что-то набрасывать то это
будут какие-нибудь там типа кривые второго порядка которые будут как-то вот там пересекаться хитрым
образом и в результате пересечения образовывается равно некоторое вот такое вот выпуклое множество
вот то есть кривые возникнут понятное дело из критерии сельвестр не дорицательной определенности
о котором как бы который собственно явным образом и задает нам допустимое допустимое множество так
понятно ли почему так получается так хорошо про допустимое множество поговорили теперь следующий
пункт нашей программы это двойственность какие результаты про двойственность у нас были
в линейном программировании и насколько они прямолинейно переносится на полупределенную
оптимизацию здесь у нас так здесь у нас была всегда сильная двойственность
потому что условия сеттера всегда выполнялась
вот поскольку там было пространство и всегда можно было найти точку который внутри него лежит
с положительными собственно коэффициантами здесь не всегда то здесь возможны возможен больше 0
давайте так возможен зазор двойственности больше нуля вот то есть ну и мы вроде бы
какие-то подобные обсуждали ранее про то что здесь может случиться так что переменная которая
будет давать допустимую точку будет ее давать только строго ну только в выраженном виде то есть
не найдется ни одного допустимого икса для при котором матрица будет строго положительно
определена вот это первый факт возможен так и возможно недостижимость минимума
вот то есть можно привести примеры в котором соответственно что произойдет мы будем
икс бесконечно нам куда-то устремлять и мы все еще будем допустить множество но тем не менее
целевая функция все будет уменьшаться уменьшаться и мы как бы до этого мимикой дойдем вот это тоже
некая особенность полу определенно оптимизация так это был собственно первый пункт второй пункт
третий пункт алгоритмический для линейного программирования есть условно simplex метод
идея которого в том чтобы многогранник в многограннике гулять по вершинам
перепрыгивая из вершины вершину так чтобы значение целевая функция уменьшалась вот у
простой идеи есть довольно непростая геометрическая геометрической геометрической
понятная интерпретация не очень простая гиброрической интерпретации через соответственно
элементы задачи то есть через запись матрицы через запись матрицы а и б и вектора ц таким
образом это все дело обеспечивается то есть как вот эти вот вершинки связаны с векторами столбца
матрица это не очень простая история вот но идея очень простая давайте поэтому пока что на этом
остановимся что мы просто переходим из вершины вершину вот и за конечное число шагов гарантированно
доходим до до решения вот поскольку вершин конечное число то в худшем случае мы всех
просто переберем вот и получим соответственно встретимся так или иначе с решением и это будет
наш ответ понятно ли основная идея метода и то почему он будет сходить за конечные шагов так
прекрасно к сожалению в так ну тут вот про конечные ну да наверное правильная аргументация то есть
есть патологические случаи когда симпелисмерт начинает зацикливаться и гулять по диме тем же
вершинам вот но с этим есть есть способы который позволяет с этим пороться диме за конечное число
число вот а здесь к сожалению такого нет нет никаких поскольку видите допустим но что более
сложное вот то никаких результатов про то что мы должны каких-то там угловых точек пересечения
поверхностей которые задают наши границы что-то искать никаких результатов нет вот и поэтому
сложно что-то сложно предполучить такую же аналогию с такими же замечательными
теортическими гарантиями как это было для для линии на программирование поэтому здесь работают
методы внутренней точки интерационные специально это отмечу что это интерационные методы вот
которые могут давать решение только с некоторой точностью вот ну и внутренние точки они потому
что их идея это не гулять по пограни по граничным точкам ну то есть по точкам которые жанр границ
в частности в случае симпелисмерт это были вершины а идти изнутри и куда-то вот у нас какой-то
страны множество и мы начинаем с некоторого x 0 и потом постепенно у нас x 1 потом какой-то
x 2 потом уж какой-то x 3 и потом мы куда-то там бла бла бла бла приходим ну например сюда
везапную x n большое вот почему мы не как каким образом мы гарантируем что мы точно не выйдем
из границы множества вот это делать с помощью называемых барьерных функций про которые я
возможно поподробнее расскажу в следующий раз вот сейчас только пример раз на им приведу вот
это такие функции которые опроксимируют индикаторную функцию множество которым мы
про которую хорошо раз говорили плюс бесконечности x не лежит в ц и 0 если x лежит в ц вот барьерные
функции короче опроксимируют индикаторную функцию вот поэтому как только но вот и в случае причем
опроксимировать так что как только мы находимся то есть давайте то есть рисовать если мы хотим
чтобы у нас x был строго больше либо равно нуля вот то наша барьерная функция на типа вот какой-то
такой вот вид может иметь например то есть при приближении границы значит при x стремящимся к
границе множество наша барьерная функция должна стремиться к плюс бесконечности вот это важно
потому что если мы перейдем к задаче минимизации от x плюс б мю от x то вот за счет вот этой штуки
у нас x точно будет лежать множество иначе мы получим просто бесконечности понятно ли мотивация
построения такого рода объектов так хорошо может быть вы примеры предложите что это за пример
таких функций ну например для вот линейного программирования где у нас x больше вернули
ограничение можно просто сумму один поделить на x и t так первый вариант годится да действительно
есть такая есть такой подход называется 1 на x и t поделить так хорошо это называется там ну как
обратная функция не обратно и пербаллический что ли это называется барьер вот хорошо еще
наверное можно так еще раз не расслышал второй вариант а мамика динамиком есть
наверное можно обобщить и сделать один дилет на x и t в п этой степени где и поэтому давайте
я вот тут по и поставлю еще даток можно степень степень подкрутить хорошо еще чем можно сделать
ну то есть вот это вот единственное условие тут кстати вот если я просто нарисую графику сразу
поймите какой ответ вот поэтому хочется чтобы вы только на основе того чтобы мы хотим вот это бы
что-нибудь еще предложили ну для каких функций у нас еще есть условия что они там куда-то стремятся
при иксе который там около нуля но может быть я просто может что-нибудь с экспонентой сделать
тогда уж если ну минус логариф но минус логариф конечно да все правильно минус логариф вот
называется логарифмический барьер и как раз таки логарифмический барьер именно он чаще всего
используется на практике вот для собственно для рэн плюс вот ну а для соответственно нашего
конуса для сн плюс используется барьер под названием минус логариф терминанта x вот и именно вот
эта штука которая мы кажется уже несколько раз ее встречали она нужна именно для этого чтобы
предотвратить вылеты множество которая представляет из себя не относительно конус положительно
конус симметричных положительных полупрелых матриц вот нет все это рационный процесс будет
который будет сходиться к решению там доказывается некоторым некоторым не очень не очень сложно
образом возможно все еще раз я как раз таки это все выкутки попытаюсь провести вот и отсюда следует
что в отличие от линейного программирования здесь у нас только интерационный метод и только
сходимый с некоторым точностью вот так это еще один пункт далее полезные упражнения упражнения
это показать что с дп на максимум наиболее общий является наиболее общим конусом по сравнению
со всеми полусами которые мы до этого обсуждали то есть лп под множество задач на положить на конус
второго порядка и это все под множество с дп задачи вот возможно тоже это уже было когда мы говорили
про конус и но сейчас про это очень своевременно вспомнить вот ну теперь несколько приложений
все этой технологии вот в частности там примеры давайте
пример номер один давайте мы попытаемся минимизировать спектральный радиус
вот у чего есть интерпретация с точки зрения энергии потому что грубо говоря если у вас есть так
была какая-то физика кстати то еще спор энергии начинает говорить при этом я еще понимаю
только школьная у нас в программе физики нет а у вас в программе физики нет все понятно ладно
хорошо тогда давайте так ей у нас допустим есть несколько некоторая некоторая динамическая
сеть а дефуру у вас были да дефуру были уже хорошо есть некоторая динамическая система которая
записывается динамик который записывается официальным уравнением линейным и там еще есть
дополнительный контрол управление через вектор у вот то есть мы варьируя вектор у с помощью и
преобразовывая матрица б можем как бы влиять на динамику понятно да и надеюсь то есть если бы было
если бы было без вот этого у нас была просто там как бы линейная система с понятным свойством
сходимости и расходимость зависит от свой сфекта матрица вот а если у нас появляется
дополнительная слагаемая вида б на у это типа считается называется управлением вот ну если
вы там второй закону распишите то у вас в это управление отправится просто величины которые
связаны с внешними силами вот так понятно куда-то берется
окей вот и бывает нужно что управление как бы представляет себя некоторую супер позицию
неких нескольких разных управлений вот которые например формируется за счет там линейные
комбинации некоторых матриц то есть типа и и вот и где все это нет симметричное вот и вот
иногда бывает нужно найти никаких коэффициентов скульптуральный радиус у этой штуки будет как
можно меньше вот этого есть там свои интерпретации уже в теории не хочу сильно глубоко погружаться
вот если мы хотим вот так сделать с минимизировать максимальное собственное значение вот такой вот
матрице по иксу то есть найти коэффициенты с которыми надо сложить известный матриц так чтобы
результаты был поменьше поменьше максимально собственное значение вот то причем тут с дп вот
оно тут при том что вот это тоже самое сейчас давайте поим почему что искать минимум числа
т при условии что вот это наша матрица от икс минус т на единичную матрицу является отрицательно
определенной вот то есть с одной стороны мы ищем икс а с другой стороны мы ищем т вот причем
так чтобы вот это было выполнено это ограничение собственно задает нам положение ну экивалентным
образом преобразуется в ограничение положительной полуопределенности понятно ли почему так
ага вижу отлично вот ну и так он это я верну уже всего вот второй пример к на который мы еще
потратим наверное оставшуюся часть занятия заключается в том что если у нас есть какая-то
не выпуклая задача квадратичного программирования вот типа двойчика да второй пример вот есть у
нас вот такая вот задача икс т а икс плюс бета икс при условии что какие-то квадратичные
ограничения икс т а и икс плюс бы это транспонированный смешали б равно нуля вот и при этом это все не
выпукло ну какие могут быть причины матрица а какая-нибудь либо а либо и ты они не положительно
полуопределены например мы все еще считаем что у нас и матрица симметрична пока что вот как
только они перестают положительно определенно хотя бы одна из их вы сразу вываливаемся в область
не выпуклых задач с которыми очень понятно что делать вот при этом можно построить некоторую
некоторое приближение которое будет с помощью которого можно некоторым образом приблизить
решение исходной задачи каким образом это делается давайте заметим что вот это все числа раз это
все числа то мы можем добавить операцию взятия следа что мы уже не разделали по моему вот и
сказать что это след от а икс икс т то есть след некая матрица которая нам была дана на некоторую
неизвестную матрицу x из большой вот то есть равносильным преобразованием привести задача по
такому виду и икс равно икс икс транспонированная вот кто понимает в каком месте куда мы перенесли
проблемы с выпуклостью понятно вообще откуда это все взялось то я вот понаписал может быть
какие-то преобразования непонятны не преобразование непонятны так преобразование понятно прекрасно
скажите теперь пожалуйста до стипа ясно ли что вот это вот и вот это вот это выпуклое функции по
матрице сейчас но просто у нас это функции еще берут себя x маленькая которая может быть не
однозначно останавливается из x это правда но это мы сейчас отдельно обговорим то здесь у
нас переменных 2 x большой x маленькая просто вот эти функции они зависит только ну можно
написать там плюс 0 умножить на x маленькой окей а тут уже есть x маленькой да ну в любом случае
они выпуклые ясно икс маленько считать независимо то но это просто это же ну а след у нас выпуклый
ну это вот хороший вопрос давайте ну а их нас афина то есть я забуду ждать что все выпукло значит
я должен быть выпуклый ну будет ли свет выпуклым или нет след будет выпуклым так как сумма выпукла
да прекрасно ура забрались то есть вот здесь все остается выпуклым то есть становится выпуклым
по сравнению с тем каким оно могло быть кривым косым вот здесь вот и вся не выпуклась она
упирается вот в ограничении на ран на самом деле вот то есть здесь давайте это как-то красненьким
обведу вот это не выпукло ограничение вот и чтобы сделать его выпуклым использует следующий прием
называется выпукла релаксация гречень типа ранга так выпукла релаксации вот и говорят что давайте
мы все оставим а вот в нашем ограничении который у нас есть на ранг мы кое-что подправим и будем
надеяться что получившиеся выкукло задачи будет не сильно хуже чем то что у нас был до этого так
вот так и икс становится минус икс икс транспонирование положительно определенной
матрице вопрос подводу вопрос как на внимательность что ли почему теперь вот это стало выпуклым
ограничению просто тех кто внимательно слушал предыдущие лекции кажется давайте какие будут
идеи но по иксу большому просто линейно но вот правда но проблема лежит вот здесь потому что
произведение иксов это плохо любые произведения переменных это чаще всего плохо вот в таком виде но
к счастью чаще всего это преобразуется в более комфорт компактный вид который позволяет это
все записать выпуклой форме вопрос как именно она может рассмотрим для произвольного вектора а
а что вы хотите рассмотреть
транспонированный на эту штуку на цейск а что должно быть больше ну больше рана нуля уже число
просто определение распишем нет и сегодня определенность не не это чё у вас будет бесконечно
много ограничений что ли это грустно и из этого получим аналитически что-то более удобное но
опять же вектор цель убой мы от этого вряд ли куда-нибудь избавитесь видите проблему
так ладно чтобы вас не томить давайте я скажу как это как с этим работать я потом покажу пример
как как solver выпуклой задачи таким справляется смотрите вот эта штука это на самом деле
дополнение пошуру в некоторые блочные матрицы может быть не самый очевидный ход вот ну давайте
сейчас я это все ой все это запишу так помните что такое дополнение пошуру или надо допомнить
напомнить надо так не помнить понятно мы это обсуждали когда когда что
я уже забыл когда мы это обсуждали лучше напомнить да ну давайте сейчас то есть у нас есть такая
блочная матрица так про сори меня могло сейчас быть плохо слышно когда у нас есть такая блочная
матрица вот то для некоторого блока например а мы можем записать так называемые дополнение
пошуру которая по сути дела является результатом процедуры блочного исключения вот когда мы
решаем блочную системы линии в сравнении с такой блочной матрицей то у нас там может возникнуть
необходимость выразить одни переменные через другие вот и промежуточная система которая
возникает в процессе такого исключения она называется дополнение пошуру для той матрицы
которая которая исключалась вот и сейчас давайте я постараюсь это все дело сформулировать более
менее аккуратно так там правда ведь не я забываю с какой стороны там что начинается вот думаю
сейчас все получится то есть да например да тут еще важно что это сделал симметрично поэтому
я тут напрасно написал это тут на самом деле б транспонированная должно быть вот и соответственно
если у нас дополнение пошуру ну например к матрице д то мы делаем следующие мы говорим что берем
мат берем матрицу которая напротив по диагонали и вычитаем из нее б да и минус 1 б транспонированная
то есть грубо говоря берем вот эту матрицу потом идем по кругу по часовой стрелке вот и
конструируем такого рода выражение вот и собственно результат который мы будем использовать заключается в
том что если в данном случае у нас д положительно полуопределивать строго положительно оправдана
потому что мы тут обратно считаем вот то это будет м то не отрицательная определенность
м равносильна тому что соответствующие дополнение пошуру тоже не отрицательно определено вот то есть
смотрите вот здесь фигурирует какие-то произведения а здесь фигурирует сама матрица и поэтому мы
можем благополучно записать наше исходное выражение x минус x и транспонировано больше
это то же самое что и и матрица блочно x икс икс транспонирована единичка больше либо равна нуля
вот потому что мы строим дополнение пошуру для единицы тут стоит икс и мы пишем икс
большое минус икс единичка минус первая единичка на икс транспонированная получаем
дополнение пошуру и оно не отрицательно определено поэтому вот это вот выражение которое у нас
обозначена звездочкой можно заменить на выражение который обозначена крики плюсиком то есть
звездочку у нас переходит в плюсик а плюсик уже явным образом это блочная матрица которая не
отрицательно это выпукло ограничение потому что когда мы потом используем матрицу x и матрицу
и вектор матрицу к большой вектор x малая по отдельности то это тоже самое что и вырезать из
большой блочной матрицы куски а это вырезание эквивалентно линейному преобразованию который
ничего не меняет понятно ли это кажется да так это хорошо вот теперь я хотел показать пример
кода когда как бы solver понимает с одной стороны в одном с чем понимать что ему дана выпукло задача
другой страна не понимает что ему дана выпукло задача так раз таки в зависимости от того в какой
форме вы ее записали так ой не то так сейчас попробовал быстро набросать так 942 но надеюсь
что все успеется несмотря на и некоторые перерывом так ну вот короче говоря cx пой наш пакет который все
будет нам делать x будет наша переменная доумерной давайте для простоты а x большое будет наша матрица
ой
вот
да да но мы еще знаем что она положительно определена поэтому такой ключ можно написать что
она true позитив сами дефицит вот и значит чего у нас будет проблема которую будем решать
вот а перед тем как мы ее решим и надо создать проблему точек solver
так ну хочется что-нибудь ой проблему равняется cvx точка минимай
проблем
x точка минимайс так ну минимайс 0 это не как бы неважно или можно какой-нибудь там
рандомный вектор умноженный на x давайте ц равняется так он да сейчас нам по s&p
нп рей тогда что-нибудь там не знаю один минус один например ну не знаю для простоты так
а экран ты видно да видно да это хорошо вот ну и соответственно давайте ц на x будем
минимизировать но самое интересное будет в ограничение то есть в одном случае давайте в объем то
как мы это понимаем что у нас x минус cvx outer по моему там есть такая функция сейчас зато проверим
если он там или нет положительно полуопределена вот видите есть специальный значок который
отвечает за положительную полуопределенность то есть можно задавать вот так может быть вот так
пробуем решить по идее сейчас должен сломаться а да сломалась но не по той причине по которой
должен должен был сломаться так нет автора понятно ну давайте сделаем вот так я еще очень не
люблю так делать но видимо в этот раз придется 2 1 ладно посмотрим я надеюсь что что он справится
если не справится прирус чинить дополнительно так 2 1 на 1 2 транспонировано во ведь он написал
что нельзя проверить на выпуклость потому что вот есть такая такое вот выражение которое
произведение переменных а произведение переменных нельзя проверить на выпуклость
если нет каких-то полных ограничений это собственно то что хотелось хотелось продемонстрировать вот с
другой стороны если теперь мы вместо этой штуки напишем другу штуку который ей полностью
только что написали это называется кажется бимат типа блочная матрица так осталось понять
какая она там блочная икс так давайте икс там столбец запятая строка 1 и вот это вот бимат
который здесь образовался он не отрицает на определен так
так я догадываю еще проблемы довольно неприятно но видим и без этого никак не обойтись
так что ли
все еще не так
на пеже был конструктор единичный матрица
да но тут не единичный матрица единичка число и надо чтобы она а вы хотите
сказать запихнуть и давайте так что ли
нет ему еще что-то не нравится сейчас 2 1 икс 2 2 икс т 1 2 и ай
хочется сказать что все в порядке но ему что-то не нравится сейчас как бимат работает
есть примерчик тут нет он как-то парсит это все добро и вываливается лен лен моутол
дам давить это афинная функция через аж так записывается пам пам пам так так не помогло
так он давайте пойдем просто в севикспай туториал и да посмотрим на то на то как
бимат работает просто хотелось бы поспользоваться без каких-либо дополнительных дополнительных
проверок но видимо так чего то миг фанкшнс так вот видите сколько этих атомик фанкшнс тут
вот есть макс и всякие логедеты и прочее нам нужно более хитрая штука а именно бимат вот
вектор матриц фанкшнс вот видите типа бимат она афинная и она увеличен типа инкриментал так
не слушать действительно икс 1 1 икс 1 ку то есть вот так идем потом следующие строки так что все
было в общем-то правильно еще правда аж стэк вот такой вот хитрый может быть коризонтал да
коризонтал стэк которая просто в ряд всех дел кладет и наверное есть стэк который кладет это
все в большой большой столбец вот так когда ставить эту штуку компилиться правильно так
все-таки тут был правильно икс тут правильно икс транспонированный может тут какой-нибудь
шейп показать
дает скажут и неправильно пример ай так икс т.д. здесь тяну и ай же наверное правильно мне все создаст
и на 1 так хорошо если я вот так сделаю
так все еще мимо
икс
но не работает
возможно этот бумаг не предназначен для таких но блог матрицы не только для них то он и предназначен
как бы то есть иначе он не очень пойду чем нужен вот сейчас надо куда-то так 952 уже
потому что не весь другом метку какой-нибудь разрешает не одинаковые размеры не не с
размерами вроде все в порядке сутки проблема что и чернул лист и стэк коризонтали стэк
ну все нормально вроде икс у нас 2 1 это столбец
может я здесь двойчик сейчас уберу и все заработает очень конечно это верить
нет так это просто
может поменять икс икс т.д. попробовать просто-то я
пробовал что-то вроде не заработала на не заработала
на поразительно так точно есть
единица да
так слушайте ладно давайте сейчас я не буду тратить это больше времени я после лекции пришлю
ссылочку на актуальный примерчик вы сможете его там подопускать настоятельно вот ну короче это
все будет будет нормально работать вот просто какие-то проблемы с индексом 2 я решу их там
после лекции в чем не сложно вот и таким образом конструирование такой матрицы оно
позволяет продемонстрировать что все будет работать с точки зрения выпуклости так давайте
последний попытка кое-что я хочу проверить может получится так ладно это я к чему это я к тому что
мы сейчас преобразовали это все выпуклой задача вот в результате которой у нас что получится у нас
получится их большой со звездочкой и маленькой со звездочкой и в идеале у нас должно будет
получиться что вот будет такое вот равенство вот понятное дело что в реальности скорее
всего такого в точности нравится не будет вот отсюда возникает резонный вопрос каким
образом нам из получившихся матрицы вектора доставать решение исходной задачи вот есть
понятное дело разные подходы вот и один из наиболее успешных для наиболее что ли интересной интересной
задачи я сейчас попытаюсь оставший 20 минут рассказать вот задача называется понятная max
кат то есть ищем максимальный разрез график вот формально это все дело ставится как
кимизация некоторого вектора x 1 четвертая сумма две суммы по и и по g w и g на 1 минус x и x g
где соответственно x и лежит в множестве плюс 1 минус 1 ну то есть w это соответственно матрица
весов симметричной
понятно ли постановкой почему она такая
прекрасный вопрос смотрите если у нас иксы разных знаков тут получается двойка и у нас
сумма весов как будто боится поэтому одна двойка отсюда берется а под а вторая двойка
берется из-за того что мы идем по всем индексам ну то есть дважды учитываем одно и то же
вот я надеюсь всем видно что это очень-то квадратичная сдача вот вот эту силу того
что у нас вот вот x и на x g это куда и w i j это квадратичная сдача которая записывает
цену то есть которые следы ранее обозначенной технологии она переписывается в куклу с следующим
образом мы говорим что мы максимизируем теперь уже по иксу маленькому и иксу большому вот где у
нас одна черта остается сумма по и сумма по жи ой я тут махнул как-то сильно и остается
w i j единицы минус x i j вот и соответственно тут у нас икс большой равняется x икс транспонированная и
икс и т во-прежнему равняется плюс ну с одним вот собственно как побороться с этим ограничением
как побороться с явным наличием вот этого ограничения очень просто достаточно заметить
что есть это правда то из этого следует что диагональ у матрицы x равна и векторе всех единиц
ну диагонали потому что икс и т в квадрате вот и соответственно получаем что достаточно
сказать что на единичке на диагонали и хватит понятно ли это
отлично во значит ну и плюс у нас вот это вот не выпук ограничения которое понятное
дело что заменяет всего лишь на ну на например либо на то что у нас было до этого что не
отрицательная определенность и выполнение по шуру либо же говорят что просто не отрицательно
определенной какой там рамк не важно вот то есть выпуклая релаксация в одном из вариантов
прием ну как бы общего потребимых скажем так это вот табло ю а и джей единицы минус икс а и джей а
понятно что вот эта штука и вот это это просто след ну понятно до следа с произведением матрицы
вот при условии что диагональ у матрицы икс равна ой я тороплюсь немножко диагональ у икса равна
веку всех единиц и например икс не отрицательно по длину ну например вот так значит в дальнейшем
оптимальное значение вот этой вот для вот этой вот задачи которая еще не ослабленная исходной
п со звездочкой тимальное значение то есть значение целевой функции так сейчас секундочку может
быть я вам с обозначением немножко да прошу прощения здесь будет с давайте все со звездочка
здесь оптимальное значение и п со звездочки тут оптимальное значение выпуклая релаксация
как связано п со звездочкой со со звездочкой какой между ними знак ну конечно п со звездочкой
сейчас да по со звездочкой больше или равно по большому нам что именно так именно так поскольку
мы сказали что у нас икс икс не не ровно ранга 1 а какой-то нет и сайт на определенный то конечно
мы допустим множество расширили поэтому п со звездочкой будет больше поскольку мы
максимизируем вот окей это наш первое первое важное неравенство которое нам понадобится в
дальнейшем теперь самое интересное вот решили мы вот эту задачу мы умеем решать сейчас я покажу
как делается на тестовом примере вот у нас получилась некоторая матрица икс большой со
звездочкой возникает резонный вопрос а как отсюда вытащить разрез я думаю что разрез у нас это
вектор из плюс-минус единиц вот и на помощь приходит алгоритм джомонса вудемсона это два разных
человека
который звучит максимально просто и скажем так не очень очевидно почему это будет что-то нам
разумное давать вот мы постараемся доказать первые шаг генерируем случайный вектор на сфере
на единиче
и второе формируем наш разрез из ну один из понятных разрезов из тех индексов таких что
скалярное произведение векторов с соответствующим вектором уитом будет больше ли бравнули где уит
это столбцы матрицы у такой что икс представляется видим у транспонированная у икса звездочкой то есть
вот это вот вот этот икс со звездочки он вот сюда улетает то есть мы получили икс со звездочкой
факторизовали в произведении у транспонированная у а потом берем столбцы и считаем набор скалярных
произведений с случайным вектором единичной сфере вот индексы для которых это больше либо равна
нуля это будут единички все остальные будут минути и получили разрез вот вот такой алгоритм
всего два шага но оказывается что работает удивительно хорошо вот в частности в частности
справедливость оценка что вот эта штука дает намеки разрез которые соответствует
р со звездочкой значение целевой функции значение
или функции на полученном разрезе
так алгоритм понятен или есть вопросы значит справедливая оценка что c со звездочкой напоминает
наши исходные задачи ну как бы самое правильное больше либо равно чем r со звездочкой то есть он
оценку снизу нам некоторые дает ну что разумно и это что самое интересное больше либо равно
чем 0 8 7 8 умножить на п со звездочкой то есть получили связь между идеальным решением
идеальное решение сейчас покрасить идеальное решение то что легко посчитать и то что дает наш
метод понятно так что это за что означает каждый этих буквок и самое замечательное что в общем
вот это вот вся история вот про оценку про вот этот алгоритм это премия фолкерсона в 2000 году
авторы получили за то что вот предложили такой метод получения разреза это одна из таких жемчужин
жемчужин на получение дискретных решений из непрерывных релаксации вот не совсем немного задач
которые для которых такое существует вот я поэтому решил включить это наш курс вот значит давайте
посмотрим как это происходит давайте доказательств что я не знаю что происходит в этом методе этот
метод предлагает нам некоторым случайным образом отобразить столбец в плюс-минус один вот а раз
у нас тут вектор и вы случайно то можно общать мотождание разреза ну то есть мотождание нашей
целевой функции по распределению вектор в что это такое ну собственно мотождание тут уже будет
одна вторая сейчас увидите почему тут опять две суммы потому что только только от повторного
суммирования останется ношитель дубль выжитая а тут остается что остается индикатор индикатор
того что знак у этой транспонированная в не равен знаку у житые транспонированная в так понятно
ли запись так вижу 1 плюс вижу второй прекрасно простым от ожидания то мы можем его по сути
дел явно образом записать что это есть одна вторая ну то есть поскольку вот эта штука равна
единице и один или ноль том от ожидания вырождает ну вырождается сводится к просто взвешенами
вероятность из сумме вероятности того ну что собственно то написано что знак у этой транспонированной
в не равен знаку у житой транспонированная в вот и все так теперь осталось вероятностями
разобраться давайте посчитаем эти самые вероятности на основе геометрической интерпретации вот сейчас
может быть он не сам кружочек нарисую о класс получился ровный кружочек это это здорово у нас
значит есть случайный вектор в какой-то да который как-то торчит ну так себе да это вектор в что
такое что знак скалярного произведения двух векторов уита и у житая отличается
что это говорит о взаимном положении этих самых векторов что не в разных полу полу окружности
относительно перпендикулярно к в давайте да отличность в вот у нас есть такой перпендикуляр
кривенький конечно но я думаю понятно вот и у нас есть два век то есть есть два вектора у
которого как бы грубо говоря заштриховать область и понять чему равна эта самая вероятность если вы
уже осознали то можно сказать итоговое выражение а вы у нас равномерно распределена на единичной
именно так
равно давайте даже может быть не так неправильно нарисовал все-таки у нас же в случае поэтому давайте
я лучше нарисую то что фиксировано а фиксировано с два вектора типа у и ну и например как-то
тут направлен уже во наверное так будет правильнее вот есть как есть какой-то вектор в который типа
куда-то смотрит вот сюда куда-то например вот где какую область какую область он может попасть так
чтобы скалярное произведение отличалось вот так вот так правильный вопрос формулирует но
перпендикуляр к нему должен лежать между уже ты и уитая то есть слева и справа симметричной области
такого же углового размера как расстояние меньшее между понимаем мы типа вот так вот надо сделать да
нет скрипки на 90 градусов углы там будут одни и те же конечно же вы наверное так понимаете что
это будет минус то же самое так ну давайте я как-то поближе в н рисую чтобы перпендикуляры
смотрелись как-то по аккуратнее так блин так радикально решим вопрос с тем где лежит в
давайте его сюда отправим так вот здесь 13 не очень я успеваю так вот один будет
смотреть сюда а другой будет смотреть например сюда да я правильно рисовал смотри давайте так
высоко уровневая будет некоторая дробь что будет в знаменателе или тропе и ну 2 пи да давайте
2 пи будет знаменателе вот а что будет в чистить в счастливе образуется наверное понятно и
в счастливе два угла между ну именно так именно так два угла уитая уже все верно все гениально это
это и требовалось осознать что по сути дела мы ограничен тем какую то с чем больше угол
чем больше вероятность что мы попадем на случайный вектор будет иметь одинаковые скалярные произведения
я думаю довольно довольно прямолинейно все так геометрия понятно или нужно еще что-то подробнее
нарисовать в итоге у нас получается что здесь сидит угол у и уже делить на пи вот а угол мы
знаем чему равен угол рай наркосинус от скалярного произведения соответственно у и транспонированные уже
ну потому что мы дополнительно можем тут как бы прикинуть что вектора будет нормирно там
а снормированный короче аркосинус от скалярного произведения да нормально делить на пи все это
почти что победа потому что так надо теперь вот так сделать чтобы было все видно потому что мы
можем записать нашему от ожидания замечательную с которой все начиналось как одну вторую сумма по и по
и джей дабл ю ай джей а дальше смотрите следить за руками два аркосинуса собственно у ай транспонированные
у джей делить на пи а сюда добавим один минус у ай транспонированные у джей а сюда добавим
один минус у ай транспонированные у джей делить пополам то есть вот это вот выражение нам нужно
ровно для того чтобы приблизиться к тому с чем мы начинали а именно с вот этого выражения где
было как были какие-то произведения вот и далее рассмотрим вот такую вот прекрасную функцию
ашат икс которая равняется два аркосинус ой икс делить на пи 1 минус x то есть вот вот вот
эта штука некоторая функция вот минимум который мы сейчас будем искать ну я сейчас просто покажу
как она будет выглядеть так где-то у меня была картинка заранее подготовленная которую куда-то
делать сейчас обычно во картинку нашел сейчас я ее покажу вот так выглядит функция аш ну у нас
икс от минус одного до одного понятное дело потому что роги метракосинусов вот то есть видите что
при единичке она понятное дело стремится к безконечности потому что мы делим на 1 минус x но
у нее есть какой-то минимум вот тут вот где-то вот видите да так если вы видите что есть
какой-то минимум плюс поставьте пожалуйста так окей увидели что есть минимум это замечательно
вот теперь если вернуться к нашим формулам то становится ну и в общем этот минимум на самом
деле что аш от икса звездочки примерно там численно если искать примерно 8 8 8 7 8 5 обозначим
это число как альфа gw вот значит из этого тогда ночь можно ценить что нашим от ожидания от
разреза больше либо равно чем вот это вот альфа gw умножить на 1 четвертую две суммы ай джей
дабл ю ай джей единицы минус у ай транспонированная у джей что в точности да и равно и икса и джей
который был ранее поэтому это равняется альфа gw на п со звездочкой что в свою очередь так же
больше либо равно чем альфа gw умножить на ц со звездочек в силу соотношения между п и ц вот в
итоге в общем практически получить то что в точности то что нам надо вот да далее поскольку наш
метод дает какой-то разрез вот то ну то есть для мот ожидания справедливо что там ц со звездочки
будет больше либо равно чем это самое мот ожидания тоже же среднем они самые лучшие больше либо
равно чем ну в общем то же самое что я сейчас просто перепишу что мы получилась альфа звездочки на
п и больше либо равно соответственно чем альфа joman williamson ц со звездочкой то есть если мы
теперь все понятно ли логика получения тех не равенств то есть хотим оценить то насколько у
нас большой зазор между тем что мы в идеале можем получить если дискретную задачу решим с тем что
мы получаем после всех этих аппроксимаций сначала в непрерывную задачу а потом получение
дискретного приближения из joman williamson в итоге что если мы теперь все это сложим то получится что
ц со звездочки меньше либо равно п со звездочкой который меньше либо равен чем один альфа jw ц со
звездочкой вот а это уже в свою очередь примерно 1 1382 ц со звездочкой то есть то решение которое
мы получаем просто из дискретной из непрерывной релаксации оно вот всего лишь там на 14 процентов
да правильно говорю 14 процентов отличается от ну или больше ну то есть лежит от правильного
решения до вот почему таков так понятно ли это то есть некоторые дополнительная оценка которая
позволяет понять насколько мы вот вот насколько грубо мы вот это вот оценили то есть где где где
вот тут отцанк сверху относительно ц со звездочки она оказывается вот какая то есть это не так
много как на самом деле ну как принципе гипотезически могло показаться так финальное финальное
финальное завершение в общем в завершении хочется показать картинки сейчас я их покажу
ой так так так так так так так а тут картинок нет потому что их отдельно решил я их решил
отдельно да все открыть так сейчас и будет так кажется это демо и нет с дп тест
на это с дп тест окей сейчас а что в демо тогда
так как будто бы то же самое ну ладно так парам пам пам сейчас он не скажет что что-то
не установлено приятно так ладно видимо тогда мне придется казаться т.д. все это запустить прям
онлайн да поскольку времени уже нет а то я бы конечно все это был запускал давайте я тогда
покажу как оно есть короче говоря смотреть что происходит берем генерируем случайный граф
регулярный такой что каждая вершина соединена с какими-то тремя другими вершинами вот вытаскиваем
смежности и строим специальную матрицу название лоплосиан вот вот тут визуализация графа и
визуализация его матрицы его лоплосианом можно показать я это сейчас не привел потому что там
еще выколотки минут на 10 наверное пояснений вот что наш разрез это на самом деле квадратичная
форма от лоплосианом вот и мы можем генерирует рандомный разрез вот он раз мы его сгенерируем
можем посчитать значение ну типа 38 и нарисовать как именно разбиваются на два подножия вершинки
вот теперь если мы сделаем с дп релаксации смотрите вот здесь вот почему-то оно работалось
таким вот образом вот ладно я еще проверю и пришлю ссылочку на актуальную актуальную новость
вот значит трейс скалярного произведения диагональ и не отрицательно определенно все как мы писали
формулу решаем теперь эту штуку все решается как-то там получается икс получали так получилось такой
икс что ли от него свд и увидели что ранг действительно не один а раз два три три ранга
оказался равен трем все остальное типа 10 с 8 что очень мало поэтому считаем нулями вот ну
картинка этих сингулярных значений вот потом мы считаем матрицу у и показываем что действительно
она удовлетворяет тому свойство которое нам было нужно вот а дальше начинаем сэмплировать много
разных векторов на ящине сфере вот и используя алгоритм джома сулимсона смотреть на на что
на назначение разреза полученные для соответственно р на норму р нормировка у транспонированное это
собственно по элементу по числению скалярных произведений вот из взятия знака это плюс или
минус один вот после чего мы берем среднее берем дисперсию и максимально значение в итоге
получаем что у нас среднем разрез равен 63 с лишним максимально же значение 67 вот если на всякий
100 грамм кто но вот так вот так вот выглядит вот это сэмплирование по собственно много разных
случайных векторов на сфере взяли вот давайте проверим то есть наше значение 89 поправка
81 средний 63 максимум 67 и 113 это 76 вот то есть все соотношения выполняются самое интересное
сравнить с рандомом то есть в принципе могли бы на рандомить наши случайные разрезы и построить
то же самое гистограмму так вот оказывается если рандомить совсем рандомить просто случайный
брет разрезы то распределение вот такой то есть они где-то в районе 30 и 40 расположены а если
рандомить случайные векторы на сфере использовать джомас уильямсон то они вот как распределили то
есть видите тут существенный зазор между тем что вы будете рандомить просто рандомить и тем что
вы будете рандомить на сфере и использовать джомас уильямсона к результату выпукла релаксации
понятно ли картинка так хорошо это прекрасно что картинка понятно вот если возвращаться к
теории всего этого дела последняя последняя ремарка заключается в том что забавный факт что
неизвестно можно ли получить оценку лучше чем алгоритм джомас уильямсон для этой задачи то
есть нельзя неизвестно можно ли получить лучше но известно что получение оценки в 16 17 от
оптимального уже непосложная задача то есть известно отрицательный результат что вот на уровне
16 17 все плохо а вот между этим уровнем и тем что джомас уильямсон еще насколько я знаю является
открытой проблемой вот поэтому значит надеюсь понятно что за мета что за задача вот и также
понятно зачем с дп использует как с дп может может помочь для релаксации задачи искренней
оптимизации вот так наверное сегодня все спасибо большое за внимание слайды в смысле записи я
пришлю и ссылочку на коллаб где все будет работать сравнение двух эквивалентных записи одно и
то же задачи которые в одном случае проглатывается солвером в другом случае нет тоже выложу все если
есть какие-то вопросы то давайте обсудим можно написать в чат и спросить если вопросов нет то
можно заканчивать
