У нас сегодня будет не меньше одной и не больше двух лекций. Я пытался компенсировать четвертые и
восемнадцатое, но восемнадцатое может еще не придется компенсировать, может восемнадцатое будет
нормальная лекция. В общем, я хочу, как я уже тут объявил, разбить традицию этого семестра,
когда какая-то сложная сумма, как мне сказали, вводится в конце лекции, а уже подсчитывается
на следующий. Я постараюсь дойти до какого-то катарсиса и на этом остановиться. Но пока мы эту
традицию не разбили, то есть прошлая эта лекция закончилась, если не суммой, то некой случайной
величиной. И нам вообще бы вспомнить, что мы с вами доказываем. Давайте я вот здесь, во-первых,
сформулирую теорему, которую мы доказываем. Это теорема Балабаша. Так, ну, Балабаша тут
просклонял я эту фамилию, то есть это не в именительном падеже, а в родительном. Так,
теорема Балабаша утверждает, что если вероятность ребра случайного графа ведет себя как n в степени
минус альфа и альфа больше пяти шестых, то асимпатически, то существует такое у,
зависище только от n и от альфа, что асимпатически почти, наверное, хроматическое число случайного
графа принадлежит множеству у, у плюс один, у плюс два и у плюс три. Такой вот совершенно
замечательный результат. Но мы довольно сильно продвинулись в его доказательстве. У нас есть
лемма, которая утверждает, что в тех же условиях следующая вероятность достаточно велика. Так,
нет, наверное, для любого лучше писать. Мы ее оценивали сверху, когда существует. А писать надо
для любого. Вероятность того, что для любого s, мощность которого не больше, чем корень из n на
логариф mn, хроматическое число g, ограниченного на s, не больше тройки. Вот эта вероятность не
меньше, чем один минус один поделить на логариф mn. Ну, конечно, начиная с какого-то нулевого,
но я надеюсь, это вы как-то осознаете, помните. Дальше мы, собственно, начали доказывать теорему,
и мы ввели определение вот этого у. Определение было неявное, мы сказали у, это минимальное,
да, конечно, у это минимальное у, это будет не очень хорошо так написать. В общем, это минимальное
такое число, что вероятность хроматического числа случайного графа вот в этой нашей
ситуации, фиксированного альфа, для фиксированного n достаточно большого, вероятность которой это все
еще так. Как там это было у нас? Больше либо равняется у? Нет, сейчас, меньше либо равняется? Меньше,
да? Меньше, конечно, да. А вот здесь больше, да? Больше, чем один поделить на логариф mn. Вот так,
вот так. Ну, это вы можете посмотреть в предыдущей лекции. В частности, из этого сразу, конечно,
следовало, из минимальности такого у следовало, что, наоборот, вероятность, с которой хиадже больше
либо равняется того же самого у, больше, чем один минус один на логариф mn. Правильно? Больше,
строго, но уже вот этой разности. Именно в таком определении. Вот, для нас принципиально вот это
лемма, для нас принципиально вот это утверждение, и дальше там появилась такая хитрая случайная
величина, которая вроде как обозначалась у, зависела, конечно, от графа, и определялась как
минимальное число k. k, да, оно обозначалось. Хочется сохранять обозначение такое, что существует w из
w. А, здесь было s, да? А, w было заменено на s. Да, да, вот это. Понял, да. Конечно, вот оно s, и вот оно
s. Ну, так гораздо удобнее, да, это правильно. Это мне из аудитории подсказали. Так, я не вижу никакого
чата, но если, в принципе, если есть желание писать в чат, можно через вас транслировать.
Не обязательно, чтобы я смотрел, если вдруг вопросы возникают, что-то непонятно надо задавать.
Минимальное такое k, что существует s мощности k, такое, что hi от g, ограниченного на v-s,
меньше ли обровняется u. Вот такая вот хитрая штука. Но я в конце прошлой лекции уже комментировал
вообще всю идею доказательств. Там должно было быть понятно, к чему дело идет. Наша задача каким-то
образом оценить математическое ожидание у и воспользоваться концентрацией мер, но более
мощной, чем та, которая вытекает из Чебышовского неравенства. Вот это, наверное, придется сейчас
здесь тоже как-то напомнить. Что у нас было? У нас было такое дело. Давайте, прежде чем дело,
попробуем понять, а у, она Липшицева или нет? Ну, конечно, опять же, могли за полторы недели забыть,
что такое Липшицева, случайная величина. Мы говорили, что случайная величина Липшицева по
ребрам, если два графа отличаются только на одно ребро, у них одинаковое множество вершин, вот это v,
но отличаются они в одном ребре, то есть в одном графе это ребро есть, в другом графе этого ребра нет.
Вот тогда мы говорим, да, и если вот так вот f от g минус f от g штрих для этих двух графов всегда
не превосходит единицы, то мы говорим, что f Липшицева по ребрам. Два графа отличаются только в одном ребре,
и мы точно знаем, что f минус f не превосходит единицы, тогда Липшицева по ребрам. Если
отличаются в одной вершине, в окрестности одной вершины, мы долго это дискутировали тогда,
помните, что мы зафиксировали одну вершину и испортили как-то ее окрестность, вот у графа g
была какая-то вершина, в ней были какие-то ребра, вот мы можем часть удалить, часть добавить,
получится граф g штрих, но только в окрестности одной вершины, тогда мы можем утверждать,
что f Липшицева по вершине. Но опять же, если в любых двух таких графов модуль разности не превосходит
единицы, мы говорим, что f Липшицева по вершинам. И кроме того, там было вот это неравенство Азумы,
которое я сейчас напомню, но мы выяснили, что f Липшицева по вершинам лучше, чем f Липшицева по ребрам,
концентрация выше. В таком темпе понятно? Ну потому что иначе придется все переписывать заново,
что было на прошлой лекции. Вот, f Липшицева по вершинам лучше, вот здесь какая f Липшицева имеет
место. Можно сказать, что y Липшицева по ребрам или по вершинам? Минимальное количество вершин,
минимальное количество вершин, удаление которых приводит к раскраске в не более чем у цветов.
Да даже на вершины похоже. Нет, ну понятно, что если f Липшицева по ребрам, то и по вершинам тоже.
То есть одно из другого следует. Рёбер тоже верно. Другое дело, что f Липшицева по вершинам,
как мы выяснили, лучше. И вот она здесь есть. Это f Липшицева по вершинам. Потому что если вы
испортите окрестность только одной вершины, ну как вот эта минимальная k может измениться
больше, чем на единицу? Вам все равно докрашивать только эту вершину в худшем случае. Добавлять
новый цвет, если, например, в этой вершине появились новые ребра. Или если часть мы удалили,
ну может быть лишний цвет тут был. Поэтому при наличии этой вершины минимальное множество,
минимальное множество удаления которого дает там какую-то раскраску, и при отсутствии этой вершины
два таких минимальных множества могут разниться не больше, чем вот на эту собственную вершину.
То есть она Липшицева по вершинам. Красивое слово, которое выглядит как такая подпись.
Липшицева по вершинам. Ну это круто! Это значит, что сейчас будет очень высокая плотность концентрации.
При этом мат ожидания такой штуки посчитать, я и в прошлый раз говорил, так каприори, это совершенно
непонятно как делать. Тут линейностью не пахнет. Когда у нас случайная величина является счетчиком
количества чего-то, число треугольников, число независимых множеств и так далее. Ну там понятно,
надо просуммировать индикаторы, воспользоваться линейностью. А тут-то какая линейность? Тут непонятно.
Так вот мы сейчас вспомним Липшицева по вершинам. Вот было такое неравенство Азумы.
Я в прошлый раз без доказательства давал. Оно было очень похоже на неравенство блуждания пьяницы.
Вот, неравенство Азумы. Но утверждало, что если f Липшицева по вершинам,
то, ну я писал вот так, вероятность с которой f минус математическое ожидание f больше либо
равняется А, ну или больше, строго чем А, это неважно как писать, меньше либо равна 2 помножить
на Е в степени минуса квадрат на 2 н-1. Так, товарищ, это тоже было в прошлый раз, это надо как-то
слечить. Мы сейчас раскроем этот модуль. Понятно, что как и в случае случайного блуждания пьяницы,
на самом деле верно и без модуля то же самое, но без двойки соответственно. То есть я напишу это
вот в такой форме. Во-первых, вероятность того, что f минус Еf больше либо равняется А, не превосходит
Е в степень минуса квадрат на 2 н-1. И во-вторых, вероятность с которой f минус Еf не превосходит
минуса не больше чем Е в степени минуса квадрат на 2 н-1. Мелл пишет шикарно, но я ожидаю, что когда
я начну стирать, будет не так красиво. А пока очень здорово все проявляется на доске. То есть вот на
самом деле верны оба этих симметричных неравенства и из этого уже следует то, что написано сверху. Ну,
какая разница? Я не доказывал ни то, ни другое, ни третье, поэтому поверить надо вот в эти оба,
то, что тут есть полная симметрия, это, по-моему, более-менее очевидно. Из этих двух, конечно,
вот это следует. А почему любой из них верно? Ну, это уж другой вопрос. Я в прошлый раз говорил,
что я подумаю, может доказать это. Ну, так подумал, кокнет. Ну, поверить в это можно,
оно как-то сопоставляется с пьяницами, поэтому только по модулю этого останется дырка. Так,
сейчас будет полный катарсис. Потому что, смотрите, я сейчас буду оценивать математическое ожидание
исходя вот из этого, наверное, второго варианта одного и того же неравенства. Ну, то есть я
подводил вас к мысли о том, что само математическое ожидание фиг посчитаешь, но у нас есть вот это
неравенство плотной концентрации меры, куда как более плотной, чем неравенство Чебышова,
конечно. Ну, уж неравенство Чебышова, это было бы что-то типа 2n поделить на а в квадрате. И это,
конечно, нам никак бы не помогло. Вот сейчас я хочу воспользоваться каким-то чудом этим
неравенством для того, чтобы оценить математическое ожидание. Так, ну, давайте а возьмем сейчас равным.
Это же верно для любого а, товарищи. У нас зафиксировано альфа и зафиксировано n с самого
начала доказательства. Мы вольны вот это число а выбрать таким, как нам заблагорассудится. Вот я
возьму и определю его как корень из двух повторных логарифмов. Не, ну вы не воспринимаете уж как прям
троллинг какой-то. Я не издеваюсь. Нет, ну вот так вот, да. Не, ну смотрите, как сейчас будет все красиво.
Все объясняется очень быстро. Берем такое а и подставим. Неправильно определил. Вот тут надо,
конечно, n-1 добавить. Но это виноват, да, это очевидно. Конечно, n-1 забыл добавить. И все,
сейчас все будет понятно. Смотрите, если а возвести в квадрат, а потом результат
возведения в квадрат поделить на 2n-1, то останется повторным логарифом. Так,
успеваете, да? А в квадрате корень пропал. Делим на 2n-1 на 2n-1. Случаем просто повторный
логарифом. Не в степени минус повторный логарифом. О, чудо! Это опять 1 поделить на логарифом n.
Так, это значит вот тут будет 1 поделить на логарифом n. И вот тут будет 1 поделить на логарифом n. Ну,
то есть мы зафиксировали в начале доказательства n. Взяли вот такое а, подставили сюда и получили
вот эти неравенства. Они правильные, что f липшится. Так, теперь смотрите. Вот сейчас будет главный катарсис
этой части лекции. Предположим, что математическое ожидание f, ох-ох-ох-ох-ох. Наверное,
меньше липр равняется, чем а. Или больше липр равняется. Сейчас секунду. Больше липр равняется.
Больше липр равняется. Ну, чем вот это а. Ну, что бы не предположить? Вдруг оно больше липр
равняется, чем а? Ну, может такое быть. А может не может? Сейчас посмотрим. Вот давайте сюда
посмотрим. Тогда вероятность того, что f-ef меньше либо равняется минуса. Ну, с одной стороны она,
конечно, не больше, чем 1 поделить на логарифом n. Это не тогда. Это просто мы знаем. А вот что будет
тогда в этом предположении? Мы сейчас напишем. Это равно вероятность того, что f меньше либо
равняется e-f-a. Ну, это тривиально. Я просто e-f перенес направо. Но мы еще предположили,
что e-f больше либо равняется а. Тогда e-f-a больше либо равняется нуля, правильно?
Так, дайте я вот здесь напишу. Больше либо равняется нуля. Секундочку, мне опять что-то прислали.
Ясно. Так, e-f-a больше либо равняется нуля. Вот смотрите, f не превосходит чего-то,
что само по себе не меньше нуля. Но, наверное, эта вероятность больше либо равна вероятности
того, что f не больше нуля. Ну, вы меня сейчас убьете, конечно, и я сам себя убью, потому что я,
конечно, забыл сказать, что f-то это нераненство азумы, но нам-то сейчас надо вместо f-y написать.
Что-то я зарапортовался. Ну, то есть нераненство азумы сформулировано абсолютно правильно. Другое
дело, что применить-то его нам нужно к y. Виноват. Вот здесь везде, вот тут вот y. Тут, конечно, y.
Что-то я зарапортовался. Это верно для любой липшицевой по вершинам функции. y липшицевой
по вершинам. Поэтому просто везде вместо f пишем y, конечно же. Друзья, это что-то я поторпился,
не продумал момент. Конечно, y везде. Везде здесь y стоит. Нормально? Ничего? Ну, извините. Да,
здесь, конечно, стоит y. И здесь y. Но я уже все перепишу. Здесь y. Здесь y. Только тарсиса не будет.
И здесь y. Я же еще раз, с чего я начал. Я сказал, что вот есть y, которая липшится по вершинам. Нам
надо каким-то образом сейчас оценить ее математическое ожидание. Вот мы смотрим на нее и делаем такой укол
пальцем в небо. А вдруг математическое ожидание y не меньше, чем вот это вот загадочное a. Но оно не
совсем загадочное, потому что согласно неравенству азумы, которая верна для любой липшицевой функции,
для y тоже будет вот такое неравенство. То есть оно вот тут есть. А с другой стороны,
мы получаем вероятность того, что y не больше нуля. Так, что значит, что y не больше нуля? Смотрите
на определение. Это значит, что вообще ничего не надо удалять, и граф сам по себе красятся в у цветов,
правда? y не больше нуля, значит он равен нулю, но то есть нам вообще по минимуму ничего не надо
удалять, и уже сам граф красятся в у цветов. Сейчас будет катарсис. Это вероятность того,
что хиадже не превосходит у. Не будет катарсис? Будет катарсис. Идем сюда. Во, и камера сюда
приехала. Смотрите, как определялся у. Это такое число, но минимальное нужно для того, чтобы вот
это выполнялось. Но главное сейчас, что это просто такое число, с которым выполнено прямо
противоположное неравенство. Вероятность того, что хиадже не превосходит у больше,
чем один поделить на логориф men. Я сюда теперь возвращаюсь, пишу больше, чем один поделить на
логориф men. Смотрю сюда и смотрю сюда. Какое красивое противоречие. То есть если вы поняли,
это должно пробрать. Вот мы за счет неравенства зумы, причем в одном из вариантов своих раскрытия
модуля, мы получаем такое удивительное, совершенно противоречие. То есть у не может быть не больше,
не меньше, чем а. Он меньше, чем а. Вывод отсюда. Мат ожидания у меньше, чем а. Если мы
предполагаем противное, то мы получаем такое фантастически красивое противоречие. Ну раз ей
меньше, чем а, то давайте воспользуемся, сейчас я вот сюда немножко вернусь, вот этим первым
вариантом неравенства зумы. Сейчас мы еще его используем. Мы пишем вероятность того, что у,
давайте я сразу напишу, больше либо равняется а плюс математическое ожидание у, не превосходит
1 поделить на логориф мэна. Перенес сразу вправо просто математическое ожидание у и переписал
первый вариант следствия из неравенства зумы. Так, ну теперь мы знаем, что мат ожидания у строго
меньше, чем а, ну или там не больше, чем а, здесь это не так важно. Не больше, чем а. Тогда то,
что стоит справа не больше, чем 2а, значит, наверное, эта вероятность больше либо равна,
нежели вероятность того, что у просто больше либо равен 2а. Отодвинутся вправо от 2а менее или
столь же вероятно, скоро-то отвинутся вправо от а, плюс что-то меньшее, чем а. Правильно? Правильно,
правильно. Но можете начертить прямую, если вы не представляете. Смотрите, где эти две точки
расположены, вот это и вот это. Понятно, что вероятность не вырастет. Вот так, ну это у нас
вероятность того, я просто перепишу, что у больше либо равняется 2 корень из 2а n-1,
помножить на повторный логориф мэн. Так, ну дорогие товарищи, теперь я раскрываю здесь карты. Это,
конечно, меньше с запасом, чем корень из n на логориф мэн. Ну корень из n на логориф мэн-то
откуда взялся? Он взялся вот отсюда. Ну вернее, он тут взялся из тех соображений, чтобы заведомо
мажорировать вот такую противную величину, как двойный пинец повторного логорифма. Чтобы не писать
здесь какую-то длиннющую бяку повторного логорифма корень из 2-ки, я написал с запасом. Но все равно
же получилось даже с запасом. Потому что чего я хочу теперь сказать? Я хочу сказать, что раз
вот такая вероятность не превосходит 1 поделить на логориф мэн, то вероятность того, что у больше
чем корень из n на логориф мэн, тем более не превосходит 1 поделить на логориф мэн.
Отодвинутся вправо от относительно маленького числа менее вероятно... сейчас... от относительно
маленького более вероятно, чем от относительно большого. Но опять та же самая история. Сдвинут
вправо точку по прямой, вероятность получилась только меньше. Вот, с огромным запасом, ну я просто
хотел унифицировать обозначение, чтобы не было какой-то вот такой громоздкости в лемме. В лемме,
еще раз вернусь, прошу прощения, в лемме, если вы поняли ее доказательство в прошлый раз, написать
вот здесь логорифм, логорифм в 45-й степени, какой-нибудь е в степени корень из логорифма,
да наплевать. Все, что хотите. Корень из логорифма, да, правильно сказал, е в степени корень из
логорифма. Все, что хотите, лишь бы не степяное паэн. Вот этот самножитель из доказательства леммы
видно, что совершенно паразитический. Можно написать все, что угодно, растущее медленнее
наперед-заданной степени, любой наперед-заданной степени. Но я написал логорифм просто для такой
унификации. Ну все, товарищи, теперь мы готовы завершить доказательство теоремы ровно так,
как я обещал в конце прошлой лекции. Ну где бы мне его завершить? Давайте я, наверное, компактифицирую.
Все, вот это можно убрать. Это было напоминание. Не равенство зумы. Не, в принципе, нормально.
Грязная доска написать будет хорошо. Без воды лучше, я думаю, что вот так как раз нормально.
Значит, мы получили еще вот что, что вероятность, с которой у больше, чем корень из n, на логорифм n,
ну зря я так стал писать, конечно. Меньше либо равна 1 на логорифм n, ну а значит вероятность,
с которой у не превосходит корень из n на логорифм n, больше либо равняется 1 минус 1 на логорифм n.
Вот это то, что мне нужно. Мне нужны вот эти три вещи.
Ну как? Давайте, например, вот это событие обозначим буквой а. Событие, состоящее в том,
что хроматическое число не меньше, чем у. Событие, которое фигурирует вот в этой лемме,
обозначим буквой б, а последнее событие обозначим буквой с. То есть у нас есть три вероятности,
каждая из которых отмечена такой вот квадратной скобочкой. Под знаком вероятности стоит какое-то
событие, но вот здесь оно обозначается а, здесь обозначается b, здесь обозначается с. Вот давайте
рассмотрим совершенно любой граф, который принадлежит пересечению а, b и с.
Что-то мне, по-моему, опять прислали. Да что ж такое? И правда?
Ох, ух, онюшки. Сейчас отвечу, виноват, к сожалению.
Так, любой граф вот в этом пересечении, какими свойствами он обладает? Ну,
во-первых, хроматическое число графа больше либо равняется у. Это просто потому,
что он принадлежит множеству а. То есть уже хорошо. Но это с самого начала было понятно. Во-вторых,
у от g не превосходит корень из n на логариф mn. Ну, просто потому, что он принадлежит событию с.
Ну, что это означает? Это означает, что вот в этом графе можно выделить некоторое конкретное подмножество
s. Вот такой вот мощности не больше, чем корень из n на логариф mn. Просто по определению у, смотрите,
можно выделить подмножество мощности не больше, чем столько. Такое, что вот эта вся часть графа g
минус s, на v минус s ограниченного, вот эта вся часть красится в у цветов. Просто вот этот конкретный
граф, принадлежащий данному пересечению, он так устроен. Она красится в у цветов. Теперь в-третьих,
g принадлежит множеству b. Это последнее, что мы используем. Следовательно, каким бы ни было вот
это s, выкидывание которого привело к раскраске в у цветов оставшейся части графа, мы это конкретное
множество спокойно покрасим в три цвета. Какие-то, наверное, новые три цвета. Не в те, которые вот
здесь задействованы среди этих у цветов, но, наверное, в какие-то новые три цвета. Следовательно,
вот это множество s, это, то есть найденное на шаге с номером 2, вот здесь, в пункте с номером 2,
это множество s красится в три цвета. В смысле, что граф ограниченный, на него красится в три цвета.
Ну все, из объединения пунктов 2 и 3 следует, что хроматическое число графа не больше,
чем у плюс 3, потому что мы покрасили вот эту всю внешнюю часть в у цветов и докрасили еще в три
цвета за счет того, что граф g принадлежит событию с леммом. Любой граф из этого пересечения точно
имеет хроматическое число не меньшее, чем у и не большее, чем у плюс 3. Ну а вероятность этого
пересечения, это, конечно, простое упражнение по теории вероятности. Ну ладно, я так и быть напишу.
Это, конечно, что такое? Это вероятность a с чертой, объединенная с b с чертой, объединенная с c с чертой,
все с чертой. У нас точно есть среди слушателей один человек, который является поборником вот этой
аккуратности, но сейчас его, по-моему, среди нас нет. Возможно, он есть с той стороны экрана. Вот,
поэтому я распишу подробно. Но, в принципе, это можно было считать упражнением. Так это правильно?
Ну там какая-то формула из логики, из теории множеств. Да-да-да-да-да, вот какая-то такая.
Это есть единица минус вероятность a с чертой, b с чертой, c с чертой. Это больше либо равно,
ну давайте здесь не пишу, больше либо равно. Один минус вероятность a с чертой, минус вероятность
b с чертой, минус вероятность c с чертой. Но потому что вероятности объединения
не больше чем сумма вероρώдностей. Вероятность a с чертой не превосходит один поделитель на
логориф men. Вероятность a больше либо равна 1 минус 1 на логориф men, а вероятность a с чертой не
больше, чем 1 на логориф men. То же самое для b с чертой, то же самое для c с чертой,
То есть всё это не меньше, чем 1 минус 3 поделительно логарифа m, и это, конечно, стремится к единице всё.
Ну то есть почти каждый граф действительно красятся в u-у плюс 3 цвета.
Потому что а пересечённое с b пересечённое с c это почти все графы.
Вероятность этого события стремится к единице.
Всё.
Ну вот здесь катарсис, это вот где-то тут случился, когда мы от ожидания оценивали.
Это самое красивое место, как вот прийти к противоречию. Вот так вот подобрали.
Вот, но я напоминаю, что эту теорему люди научились ещё усиливать, то есть можно довести до u-plus 1,
и альфа можно брать не большим пяти шестых, а большим, чем одна вторая. Ну, в общем,
тем не менее.
Так вот, на гребне знаний практически находимся. Давайте я, наверное, сейчас всё сотру и
буду рассказывать ещё про один последний случай,
связанный с хроматическим числом случайного графа. Теорема тоже будет балабаша. Что?
Агрегат есть.
Ну, в принципе, можно воспользоваться агрегатом, тогда придется сделать 5-минутный перерыв. Ну, пока там будет сохнуть.
Так, ну, мы вернулись, товарищи. Значит, у нас
последняя теорема про хроматическое число. Больше красить ничего не будем.
В общем, я понимаю, что кого-то уже, может быть, немножко так поднапрягло, сколько можно красить. Есть какие-то другие задачи.
Их много, они у нас будут. Но вот один случай такой, прям ключевой, мы до сих пор не рассмотрели.
Мы, конечно, кучу случаев не рассмотрели, потому что у нас всё время вероятность довольно быстро стремилась к нулю, но
есть совсем ключевой случай. П-ровняется 1 и 2.
Ну, граф случайен в том смысле, что он просто вот случайен.
Классическое определение вероятности.
Тучка, в которой летели графы, была целиком равномерно беленькая такая, да?
Вот. Ну, смотрите, кое-что мы с вами можем про такой случайный граф сходу сказать.
У нас в своё время было такое замечательное утверждение,
что асимптатически почти, наверное, альфа от такого графа
меньше, ну, если хотите, равняется, это неважно, чем два
двоичных логарифмена.
Это было утверждение, которое, в частности, свидетельствовало о том, что
гораздо лучше хроматическое число оценивать с помощью дроби n поделить на альфа, а не
омеги от g, которая тоже почти всегда меньше либо равна вот этой величине.
Вот. Ну, соответственно, что?
Значит,
конечно же, асимптатически почти, наверное,
хроматическое число не меньше, чем
n поделить на два лог двоичные.
Ну, вот, пользуемся, собственно, этим неравенством, n поделить на альфа.
Альфа, почти, наверное, не больше, чем два лог двоичный. Ну, значит, х не меньше, асимптатически почти, наверное, чем этот дробь.
Ну, оказывается, оказывается, что это почти не улучшаемый результат.
То есть, мало того, что неравенство n поделить на альфа
гораздо, конечно, сильнее для почти всех графов, чем просто омега,
оно еще и не улучшаемо, асимптатически.
То есть, вот этот результат, лучше которого в среднем нету, ну, для почти всех графов нету.
Теорема, которую доказал тот же самый Балабаш.
Вот.
Предыдущую теорему доказала Балабаша, а эту теорему доказал Балабаш.
Я здесь не стал склонять.
Она утверждает следующее.
Существует такая функция phi
от n,
что
phi
равняется о маленькое от n поделить на логариф mn,
и асимптатически почти, наверное,
хроматическое число случайного графа отличается
от n поделить на 2 лог 2-ичный n
не больше, чем на величину вот этой функции.
Ну, то есть, можно, конечно, с самого начала было неформально сказать, что асимптатически почти, наверное,
хроматическое число случайного графа
симптатически равно вот этой дроби.
Но это не очень понятно, что значит. Я строго это сформулировал.
Для большинства графов, для почти всех графов,
отличие значения их хроматических чисел от вот этой величины, которая служит заведомо нижней оценкой,
не превосходит величины, которая бесконечно мала по сравнению с этой оценкой.
Ну, то есть, хроматическое число болтается в окрестности вот этой вот дроби
на расстояние плюс-минус
величина бесконечно малая по сравнению с этой дробью.
Ну, я здесь написал о малой от n поделительной логарифм натуральной,
здесь стоит логарифм двоичный, да еще умноженный на двойкунный, но я надеюсь, понятно, что это без разницы.
Возникает вопрос, а есть ли здесь такая плотная концентрация, какая была в предыдущей теореме?
Все-таки, там концентрация была вообще офигенная.
У стремилась к бесконечности,
а хроматическое число принимало только значение у и у плюс один, или там у плюс один, у плюс два, у плюс три.
Вот здесь, как совершенно недавно доказали, такой концентрации нет.
Буквально в прошлом году это стало.
Теоремы свои Балабаш доказал в 80-е годы, так, чтобы было понятно.
Это результаты примерно сорокалетней давности, тоже очень-очень свежие, конечно.
Понятное дело, что очень важные.
Вот, и вот эта теорема, и предыдущая, которую мы уже доказали, это 80-е годы.
А вот утверждение о том, что phi at n нельзя заменить на константу, это буквально прошлый год.
Сейчас я понятно говорю, да? Вот здесь phi at n, это o маленькое от n поделить на логариф mn,
но оно может стремиться к бесконечности.
И вот недавно доказали, что в утверждении подобного типа, где вот здесь вот написано симпатически почти наверно,
нельзя phi at n заменить никакой константы.
Судя по всему, правильный порядок роста, это что-то типа корень четвертой степени из n, но это пока не доказано.
Но правильный порядок величины разброса, скажем так, насколько от вот этой дроби
реально уклоняется хроматическое число. То есть вот какая-то дисперсия
оценивается, видимо, как корень четвертой степени из n, но это гипотеза, которая пока не доказана.
Вот такие вот продвижения. В прошлом году я говорил, что
это нерешенная проблема. Говорю, что это вот уже известный результат.
Нельзя константы заменить.
Вот. Я хочу эту теорему доказать.
Очень амбициозная задача. В прошлом году я это сделал по модулю некоторого противного вычисления,
которое прокомментировал, но сказал, в большей степени его считать не нужно. Экзамены не потребуют.
Вот. Там идентично все опять основано на неравенствах Азумы.
Но тут своя специфика, поэтому, ну, черт возьми, черт. Время есть, черт не доказать.
Нет, я ни в коем случае не собираюсь использовать сегодняшний бонус в качестве бонуса по отношению к 30 лекциям, которые должны быть в двух семестрах.
30 их останется. 31 я не сделаю.
Вот. Но в прошлом году я успел, так что и в этом году, наверное, успеем.
Посмотрим. Ну, я даже не стану писать доказательства, но, в общем-то, я не буду писать доказательства.
Ну, я даже не стану писать доказательства слова, потому что я его сейчас потом буду долго что-то рассуждать, рассуждать.
Ну, в общем, мы начинаем доказывать теорию.
Вот. Ну, смотрите, значит, доказательство будет состоять из
как бы двух блоков. Один занудный, а другой содержательный и красивый.
Ну, занудный, это я сейчас буду вводить некоторые функции, некоторые параметры в духе самых неприятных семинаров про асимптотики.
Виноват. Вот. После того, как я их введу, появится уже красота, катарсисы и так далее.
Ну, а для чего я их именно так буду вводить? Ну, это будет понятно ближе к концу.
Значит, параметры. Это довольно ужасно.
Параметры. Это довольно ужасно. Ну, давайте сделаем вот так. Есть
сначала такая случайная величина из KTAG. Это будет просто по определению количество
K-элементных
независимых множеств
в случайном графе G. Ну, или просто в графе G, не важно, случайно, какой-то фиксированный.
XKTAG.
Ну, она реально зависит, конечно, еще от N, она зависит от P. Ну, P у нас равно 1 и 2.
Я напоминаю. А N, ну, мы N всегда опускаем.
Понятно, что зависимость от N тоже присутствует.
Так, ну, что мы с вами точно знаем? Это, конечно, математическое ожидание XKTAG. Я не буду в очередной раз спрашивать, чему оно равно. Я просто напишу.
Это, конечно, c из N по K
умножить на 2 в степени минус c из K по 2. 2 в степени, потому что вероятность ребра 1 вторая.
Ну, раз она 1 вторая, значит 1 вторая в степени c из K по 2. Это вероятность отсутствия всех ребр.
Мат ожидания мы знаем.
Давайте
временно...
Тут будет довольно забавно. По ходу доказательства эта штука будет переобозначаться самыми разными способами, но мы не запутаемся, я вас уверяю.
Это уже опыт показывает. Но временно это предпозначим вот так. FKTAG.
Здесь укажем зависимость от N, потому что я чуть-чуть хочу порассуждать о поведении этой величины. И в зависимости от K, и в зависимости от N.
Хочу порассуждать.
Так, ну и как же она зависит, правда? Вот, например, f1 от N. Это просто метод тыка называется. Давайте попробуем угадать чего-нибудь.
Что именно сейчас хотим угадать, скоро поймете.
Так, f1 от N это N.
По-моему, и все, да?
С из одного по два это ноль, два в степени ноль это единица. Ну ладно, f1 от N это N.
f2 от N. Я хочу вас подвести к пониманию какой-то простой вещи, но чтобы это неформально было, ну порассуждаем вместе.
f2 от N это...
Давайте я асимптотику буду писать сразу. Это N квадрат пополам, c из N по два, N квадрат пополам.
Ну а тут еще на 2 в минус первой степени.
Ну, дальше я не буду мучиться, но видно, что вот эта штука стремится к бесконечности.
Эта штука тоже стремится к бесконечности, в чем с одной стороны как бы побыстрее, да, потому что N возвелось в квадрат.
Но с другой стороны, как это не смешно бы прозвучало, но помедленнее, потому что поделили на 4, а тут ни на что не делили.
Но это издевательство, понятно, что это быстрее стремится к бесконечности, да?
Вот, ну ладно, ладно. А теперь смотрите вот сюда.
А теперь смотрите вот сюда. Симпатически почти наверное, альфа, ну давайте я все-таки оставлю меньше, это неважно, там и так, и так получается, альфа меньше, чем 2 лог 2 х N, это вы помните, да?
Симпатически почти наверное, как это доказывалось?
Это доказывалось
просто это равносильно тому, что асимптотически почти наверное
х kt
равняется нулю,
если k
равняется 2 лог 2 х N. Вот так. Мы же это доказывали.
Число независимых множеств вот этого размера равняется нулю, это просто равносильно тому, что альфа меньше, чем это число.
Правда?
Дальше, как мы это доказывали? Ну, вспоминайте, это же было просто неравенство Маркова. То есть мы сосчитали мат ожиданий х катово и убедились, что оно стремится к нулю.
Привод таком k.
Не, ну вы можете себе это сейчас, конечно, как-то пометить, но вот когда мы в начале семестра доказывали вот это вот утверждение,
мы пользовались просто неравенством Маркова.
Посчитали вот это математическое ожидание,
подставили в него вместо k 2 лог 2 х N и убедились, что вот тут оно уже к нулю.
Смотрите, f1 стремится к бесконечности, f2 стремится к бесконечности,
вы можете там f3 посчитать, f5 посчитать, f10, они вроде всех к бесконечности стремятся.
Но, когда вы вместо k подставляете ни 3, ни 5, ни 10, а вот так растущую функцию,
начинает стремиться к нулю, потому что 2 в степени минус k квадрат пополам,
оно в конце концов перестает быть просто константочкой в знаменателе, про которую я вроде как шутливо говорил, что побыстрее стремится,
помедленнее стремится к бесконечности.
Оно перестает быть вот этой смешной константой,
которая якобы не вредит стремлению к бесконечности, а она таки начинает в знаменателе забивать вот этот числитель и все вместе стремится к нулю.
Понятно?
Короче,
можно, и это вы можете уже самостоятельно попробовать обосновать, но это не очень сложно, просто не хочется тратить на это время,
можно дать корректное определение величины, давайте назовем ее k1, например,
давайте k0. k0 от n
это
минимальное такое k,
что f
kt от n
ну да, это больше либо равно
единицы, вот так.
Да нет, ну тут вообще ничего не нужно особенно обосновывать, для каждого n найти такое минимальное k можно просто перебором,
не надо знать никаких сложных алгоритмов, просто тупым перебором такое k найдется, и это видно вот из всех этих выкладок, которые я сейчас показываю.
Видно, что в какой-то момент оно станет
достаточно II и перестанет
быть больше либо равной единице, вот оно стремится в бесконечности, стремится к бесконечности,
а потом бац, это начинается стремиться к нулю.
А я не в ту сторону нераненства написал, ну дайте я меньше либо равно единицы напишу, сейчас, подождите. Да, да да да, да, конечно! Спасибо!
Спасибо, это меня аудитория, которая здесь сидит правильно поправляет, да, меньше либо равно единицы, это я описался, конечно, да вот оно
оно большое-большое, но уже как бы поменьше. Вот для каждого конкретного n в какой-то момент
настает вот такое, что оно перестает быть большим. Находится минимальная k, при
котором в k-ты не превосходит единицы.
А, знаете, я какое вам упражнение задам? Я понял, это понятно. Ну, дали такое
определение. Хорошо, нашли k нулевой для каждого n. А я вас попрошу доказать,
докажите, что если k, ну скажем, не превосходит два лог, двоичный n, минус
какая-то там, с огромным запасом напишу 100, а дальше какая-то константа, я хотел
сказать, с огромным запасом напишу 100, напишу повторный двоичный логариф
m или натуральный там, какой хотите. Ну, просто удобно в одинаковых основаниях
мыслить. Вот, минус 100 раз двукратный логарифом двоичный n. Вот, если такое k,
то уже fk-ты от n стремится к бесконечности.
Ну, это вот упражнение гнусное, обычное на симпатический анализ. c из n по k
это n в k-ты поделить на k факториал. Тут примерно 2 в степени минус k квадрат
пополам. Тупо это подставляем и проверяем, что это стремится к бесконечности.
k факториал заменяем какой-нибудь своей хорошей оценкой, типа стирлинга, там,
чего хотите. В общем, тупо проверяется, что вот тут уже стремится к бесконечности.
Соответственно, минимальная k таким образом лежит где-то между вот этой
величиной, ограничена она сверху этой величиной, а снизу она, соответственно,
ограничена вот этой величиной. Это понятно? То есть, если вы доказываете вот это, а это
простое упражнение на асимптотике, то из этого, конечно, следует, что k0 от n асимптотически
равняется 2 лог 2-ичные. Но одно небольшое упражнение, это можно сделать. Мне кажется,
оно проще, чем иные упражнения на OKTCH. Поэтому ничего страшного тут нет. Ну хорошо,
поверили, что k0 такое? Это вот такой нудный выбор параметров. Дальше мы вводим в величину,
виноват m, равную целой части от n поделить на логарифом в квадрате n. То есть, это меньше,
чем количество наших вершин, меньше асимптотически, и даже меньше, чем n поделить на 2 лог 2-ичный n,
асимптотически это сейчас сработает. Но меньше не сильно. Вот ни корень четвертой степени из n,
в каком смысле это как раз про это. Возьмем такое m и обозначим k1 от m, или просто k1,
величину k0 от m виноват минус 3. Что такое k0 от m, я надеюсь, понятно. Это то же самое,
что мы здесь мучительно определяли, только вот для m, а не для n. Теперь смотрите, поскольку
m выбрано именно вот так, а не, например, как корень четвертой степени из n, n делится на какую-то
фигню, на логарифу. То когда вы, смотрите на эту асимптотику, сюда m подставляете, k0 от m,
асимптотически равно 2 лог 2-ичный m. То асимптотика по n такая же. Я хочу сказать,
что вот это все это 2 лог 2-ичный n тоже. Ну и m, конечно, и n. Ну то, что минус 3,
это я надеюсь, вообще понятно, что никак не влияет. Да, это 2 лог 2-ичный n. Зачем
минус 3 вы узнаете сильно позже? А сейчас пока такая асимптотика. Вы выбрали такой параметр k1
от m, он асимптотически равен вот этому. Это совершенно понятно. Так, что еще на самом деле
понятно, это что fk1 от m, fk1 от m. Это знаете, что такое? Мы отступили от минимального числа,
при котором f все еще не больше единицы, на троечку. Ну если вы посмотрите снова внимательно сюда,
это я думаю тоже надо рассматривать как такое небольшое упражнение, то вы увидите,
что при каждом уменьшении величины k на единичку, k уменьшаем на единичку. Вот здесь вот происходит
уменьшение, но это вообще очевидно, примерно в n раз. Ну когда k само порядка логарифма,
там в знаменателе еще какой-то логарифм появляется, ну в общем я хочу сказать,
что вот это это m в степени 3, ну плюс какое-то умалое от единицы в показателе этой степени.
Имеется в виду, что m в степени умалое от единицы это какая-то степень логарифма
m, на самом деле. Но я так о грубе, просто более грубо написал. Нет, имеет конечно, она тоже от
м, естественно, да. Да-да-да, конечно, ну так я просто не дописал. Просто вот это коротко
обозначается k1, но конечно от m, да, то есть мы всюду предполагаем, что это зависимость от м. Так
понятно сказал, да? Вот еще раз понятно, чего я утверждаю. Видно, что c каждый раз это n в степени
k, там n в степени k-1, n в степени k-2, но при этом в знаменателе было k факториал,
потом станет k-1 факториал, это в k раз уменьшение, но k порядка логарифма. Поэтому,
когда вы k уменьшаете на тройку, m-ка в данном случае, m-ка не n-ка, потому что, ну понятно,
да, m-ка возводится в третью степень, ну а куда-то там в знаменателе лезут эти логарифмы, ну и черт бы
с ними я их загнал в маленькой от единицы. Вот это ружье, которое выстрелит самым последним,
я его приберегу, это будет такой тоже мегакатарсис. Зачем бы это было нужно? Но пока так вот,
это понятно чисто аналитически? Вот все, все, параметры мы, кажись, выбрали. То есть мы будем
работать с вот этим k-1 и будем работать с вот этим m. А теперь будет сформулирована ключевая
лемма, из которой мгновенно будет следовать доказательство, собственно, теоремы. Да, я, может быть,
забыл сказать, в одну-то сторону неравенства вообще очевидно, то есть phi равняется нулю. Мы
его уже фактически доказали. Нам нужно теперь доказать, что phi не превосходит n поделить на 2
лог 2-ичный n плюс какой это phi от n. Вот все, что нам осталось доказать. Согласны? Потому что
нижняя оценка даже с phi равна нулю уже доказана. Вычитать ничего не надо, минус phi писать не надо.
Мы сейчас верхнюю оценку хотим сделать. Вот сейчас мы сформулируем ключевую лемму,
которая сложно доказывается. А симпатически, почти наверно, выполнено следующее замечательное
утверждение. Для любого s из V, в этом множество вершин случайного графа нашего,
как всегда, мощность V равняется n, если вдруг кто-то не помнит и не понимает. Берем наш n-вершинный
граф с вероятностью ребра 1 на 2 и говорим, что а симпатически, почти наверно, для любого s мощности
m, вот этой мощности, которая меньше, для любого под множество, меньше, но не сильно меньше,
мощности. Хроматическое число g, альфа от g ограниченного на s, альфа именно число независимости,
от g ограниченного на s не меньше, чем k1, ну а от m. Давайте сначала пафос этого утверждения,
чтобы оно точно было понятно. Вот сарделька, это V мощности n. Что утверждается? Давайте сначала
сюда посмотрим. Вообще говоря, мы знаем, что а симпатически, почти наверно, альфа меньше,
чем 2 лог 2 х н. Помните это? Вот запомните это, держите это в голове, а сейчас вернемся сюда.
Альфа меньше, чем 2 лог 2 х н, а лемму утверждает, что какое бы множество,
ну такой сравнительно большой мощности, вы бы не взяли. Не, ну она конечно бесконечно маленькая
по сравнению с n, это я плохо нарисовал. Наверное, лучше все-таки не так рисовать, а вот так.
Какое угодно, какое бы множество, вы не взяли, но вот этого размера, m. В нём есть независимое
множество, и тут есть независимое, и тут есть, и тут есть, и тут, и тут, и тут, везде есть. Какого
размера? Почти такого же. Да, там мы его долго мучительно выбирали, потом будет понятно,
почему именно так выбирали, но факт тот, что асимптотика этого размера почти такая же,
как у той величины, которой уже ни одно вообще независимое множество не соответствует. Нет,
ни одного множества вот такого размера, ни одного. Почти, наверное. Я туда специально водил,
больше не поведу, должны помнить. Вот такого размера асимптотически почти, наверное, нет,
но вот такого размера, который ну вообще почти не отличается от этого, да, ну подумаешь,
там какой-то стол эго рифмов повторных надо вычислить, чёрт его знает, ну фигня какая-то. И не то,
что оно уже есть. Мало того, что оно есть, оно повсюду, оно повсеместно. Знаете,
какой резкий скачок в проявлении свойств случайного графа. Такого почти, наверное,
нет нигде вообще, нигде, а такое есть почти везде. Я всегда в этом месте цитирую рекламу,
даже в маленьком кусочке есть лесной орех. Это довольно маленький кусочек, в общем,
ну так. Я его сначала плохо нарисовал, он всё-таки маленький, но орешек-то ещё гораздо меньше,
конечно. Вот такое вот удивительное утверждение. Почему оно сразу решает нашу задачу про оценку
хроматического числа, это я сейчас объясню. Давайте, вот на оставшейся доске. Это как раз
просто совершенно. Если мы верим в справедливость Леммы, которая удивительно совершенно звучит,
вот для неё как раз нужна опять концентрация меры. Чебышёвского неравенства не хватит отнюдь.
Оно докажет только, что есть такое множество, что оно повсюду есть, оно не докажет. Вот. Значит,
как решать задачу? Ну, давайте вот это событие, как обозначим буквой А. Всё вот это событие,
всё вот это событие. Это всё буква А. Рассмотрим любой граф из А. Ну, вероятность такого же
стремиться к единице, это мы поверили. Вероятность вот этого события, что же попадает в А,
конечно, стремится к единице. А симпатически почти, наверное. Вот. Но если мы просто посмотрим на
любой конкретный граф, почти любой, да? Почти любой. То каким свойством он обладает? Ну,
ещё раз, рисую картину. Вот этот граф. У него повсюду есть довольно большие лесные орешки,
островки независимости. Ну, давайте возьмём какой-нибудь один такой островок и покрасим
его в первый цвет. Мы же можем независимое множество красить в один цвет. Можем? По
определению. Взяли, он точно есть. У нас сколько вершин осталось? Ну, я имею в виду, что этот
островок будет размером в точности к1. Если есть больше либо равные, давайте в точности к1 возьмём
вершин. Тех, которые можно спокойно покрасить в один цвет. У нас останется n вычесть к1 вершин,
правильно? Но у нас же всюду есть независимое множество размера к1. Найдём ещё одно и покрасим
его в второй цвет. Граф же таким свойством обладает. Наша-то цель, да конечно, почти любое
обладает. Это трудно. Но если он обладает, то ясно. Вот нашли одно, потом нашли второе,
потом также третье. Покрасили в третий цвет. Сколько можно таких островков независимости выделить?
Да, наверное, но не совсем. Потому что нам-то важно, чтобы кусок, в котором мы ищем вот этот кусок,
в котором есть лесной орех, чтобы он был хотя бы размером m. Как только мы выкинем столько множеств
мощности к1, что у нас не останется м вершин, мы уже не сможем гарантировать даже для этого графа,
что среди оставшихся вершин есть независимый кусочек. Я бы сказал вот так. n-m поделить на
k1. Целая часть. Вот столько шагов мы проделаем, после чего у нас останется, ну, вообще говоря,
уже не больше, чем m вершин или примерно m. Поэтому мы не сможем после этого уже гарантировать
наличие там островочка независимости. Так понятно говорю? Вот это количество цветов,
которые мы наберем к тому моменту времени. Но после этого останется не больше, чем m вершин
вот этого графа g, который пока что не покрашен. После того, как мы выбрали столько цветов каждой
мощности k1, у нас остается не больше, чем m не покрашенных вершин. Дайте каждую из них покрасим
свой отдельный новый цвет. То есть цветов будет в итоге вот столько, как максимум.
Ну, m бесконечно мало по сравнению с n, поэтому вот эта штука ведет себя симпатически как n
поделить на k1, то есть как n поделить на 2 двоичных логарифм n. А это бесконечно мало по сравнению с
n поделить на лог двоичный n. Потому что на логарифм в квадрате делится. Ну и все. Значит, вся эта
сумма тоже вот такую асимптотику имеет. Любой граф, который находится в событии а, может быть
покрашен бы симпатически столько цветов. Ну, можно отсюда выделить явный вид функции phi от n,
который у нас получился, но кажется, что это не очень важно. Так, понятно объяснил? Вот, то есть все
теорема доказана, но по модулю это сложного утверждения. Сейчас я подпишу бумаги там снаружи,
и в принципе кажется, что можно тоже устроить пятиминутный перерыв на стирание с доски. Так,
ну, видимо мы вернулись, да? Давайте пытаться доказывать лемму. Ну, как я тут в кулуарах говорил,
это длинная, конечно, история. То есть мы сейчас ее сведем к чему-то, потом это еще к чему-то,
но ничего. Значит, так, прежде всего давайте напишем отрицание этого утверждения и будем
оценивать вероятность сверху, доказывая, что она в итоге будет стремиться к нулю. Ну,
то есть прямо честно напишем вероятность уже от того, что существует s из v мощности m такое,
что α от g на s не больше, чем k1. Это же отрицание, правильно? Так, ну, кажется совершенно очевидным,
что какая разница, какое именно множество мощности m смотреть. Случайный граф однороден.
Если мы выделили в нем кусок размера m, то фактически он просто индуцирует такой случайный
подграф на m вершинах. Я понятно говорю или это страшно звучит? Ну, а раз это понятно,
тогда вероятность существования, как обычно, не больше, чем сумма, и мы просто вот так напишем
эту сумму. Ну ладно, и надо даже сумму писать. Ну что, я же вроде все сказал. Сумма превращается
в c из n по m одинаковых слаганин. Она просто превращается в c из n по m умножить на вероятность.
Ну, вот тут я временно нарисую буквку m, подчеркивая, что вот эта вероятность в отличие от вот этой
будет на графе с m вершинами. Ну, а здесь уже будет просто альфа от g не превосходит k1. Вот так.
Если вдруг кого-то смущает, что я здесь написал букву g и здесь написал букву g,
я, конечно, могу здесь написать букву h, но, я надеюсь, понятно здесь же имеется в виду просто,
где, где, где? Вот здесь мера множества всех таких графов g. То есть g это не единственный граф,
а это просто обозначение типичного представителя из множества тех графов,
которые обладают вот этим свойством. И здесь то же самое. Мы берем просто какой-то граф,
который обладает вот этим свойством, но среди всех графов уже на m вершинах.
Может, я сложно как-то выразился, но смысл-то вроде простой. gm написать? Нет, ну gm. Не,
ну формально надо вообще, знаете, как писать? Здесь g, а в скобках n запитает 1 вторая,
а здесь g и в скобках m запитает 1 вторая. Тогда вот это, конечно, писать не нужно. То есть всякий
раз, когда я здесь пишу g, я, конечно, должен по-хорошему писать все вот это обозначение для
случайного элемента, но это страшно. Ну, давайте я m здесь напишу хорошо, как вам удобнее, но могу
вообще его не писать. Но просто вот надо помнить, что вот в этом месте мы переходим от n вершинных
к m вершинным случайным графам. Я могу вообще нигде m не рисовать. Я это пояснил, вы запомнили
все. Вот здесь m вершинные все. Так, ну я не буду долго нудить по поводу того, что такое c из n по m.
Вот здесь специально для нас сохранили напоминание о том, что такое m. Можно, конечно, очень аккуратно
по стирлингу посчитать и сдохнуть. Конечно, это что-то субэкспоненциальное. Это не экспонента.
Вы помните первую лекцию курса? Экспонента там получается только, если вы берете c из n почему-то
линейно-зависящему от n. По а n. c из n по а умножить на n. Вот тогда будет экспонента. Если там не а умножить
на n в c-шке наверху, а что-то вот такое, например, то это уже будет субэкспонента, конечно. Ну,
суб-то суб. Уж точно не линейное ничего-нибудь и уж точно не полином. Будет какая-то жуткая биака,
которая растет, если не экспоненциально, то очень близко к тому. Короче, я тупо оценю это как 2 в
степени n, но просто чтобы по мне не придирались и не говорили мне, что вот это я здесь оценил,
вот эту вот вероятность как 2 в степени n, вот поэтому-то мне пришлось использовать неравенство
зумы. Нет, не поэтому. Если бы я даже честно сосчитал вот эту штуку и ее асимптотику,
ну было бы что-то чуть меньше, чем 2 в степени n, типа 2 в степени n поделить алгорифом n. Все равно биака.
Ничего хорошего не будет. Поэтому я тупо оценю, но неравенство зумы такое мощное, что даже вот эта
тупая оценка с запасом пройдет. А неравенство чебышова здесь не катится совсем, я это даже покажу.
Ну здесь опять пишем альфа дже, не превосходит к1, по-прежнему не забывая, что тут уже всюду
букс к м. А вот тут н, ну это по делу. Так, ну смотрите, можно я чуть-чуть поиздеваюсь? Чуть-чуть.
Ну так, чуть-чуть. Маленькая такая вставочка, свидетельствующая о том, почему неравенство
чебышова здесь не работает. Этого я мог не делать, потому что мне же надо доказать теорему. Я могу
просто взять, сразу привезти здесь неравенство зумы и все получить. Но я хочу, чтобы вы поняли,
просто чем азума здесь спасает. Почему неравенство чебышова не работает. Я хочу, чтобы это как-то
усвоилось. Поэтому вставочка сейчас будет неправильное. Продолжение доказательства называется.
Попытка доказать с помощью неравенства чебышова. Что значит доказать с помощью неравенства
чебышова? Ну очень просто. Надо написать вот так. 2 в степени n умножить на вероятность того,
что x... А, кстати, я неправильно написал. Меньше строго. Меньше строго. Отрицание не совсем
правильно написал. Там же было больше либо равно. Отрицание это строго меньше. Ну мелочь,
конечно, но так приятнее. Тогда действительно будет корректно написать вот так. xk1adg равняется нулю.
Так, кто-нибудь еще помнит, что такое x с индексом kadg? Количество независимых множеств на k вершинах.
У нас сегодня такое было. Вот утверждение о том, что альфа меньше, чем k1. Мы сегодня тоже это
вспоминали, равносильно тому, что x с индексом k1 равен нулю. Нет ни одного независимого множества
на вершинах в таком количестве. Так, дальше можно переписать вот так. Ну, во-первых, вот так написать.
Я надеюсь, что это не очень кокает, чтобы еще там дважды переписывать. Величина заведомо не отрицательная,
конечно, но я для красоты добавил. И дальше стандартно. У нас уже было. Можно было даже на
него сослаться, но вы его забыли, поэтому я его напишу заново. 2 в степени n, вероятность e xk t1,
которая, как вы помните, еще fk t1 от m обозначалась. Кстати, минус xk1, но это неважно, я просто
напоминаю, e xk1 х, ну и применить неравенство Чебышова. 2 в степени n умножить на d xk1 поделить на
e xk t1 в квадрате. Ну, было у нас такое неравенство, я еще говорил, что его можно вообще всегда применять,
не только для какого-нибудь конкретного числа, но для любого, который считает что-нибудь
не отрицательное. Ну и все, и облом нас подстерег, потому что мат ожиданий xk t1,
пойдемте сюда. Вот оно, мне его тут очень хорошо сохранили, эта величина m в кубе. Ну то есть в
знаменателе стоит что-то порядка m в шестой степени, и рассчитывать на то, что такая дробь забьет
экспоненту, или даже субэкспоненту вот эту, ну не приходится, товарищи, ну никак. Видите,
это всего одной строчки хватило, чтобы убедиться, что неравенство Чебышова здесь ну вообще не катит.
Именно из-за того, что мы попытались доказать вездесущесть вот этих независимых множеств,
что в каждом кусочке есть лесной орех, если бы не было вот этого каждого кусочка вот этого
сомножителя, то конечно нам бы удалось доказать стремление к нулю вот этой величины, все было бы
классно. Понимаете, да? Но нам надо в каждом кусочке, иначе вот тот алгоритм, который я там
прописывал, не сработает по краске. Нам в каждом надо. Нам надо как-то эту экспоненту чем-то забить,
поэтому я вот это все зачеркиваю, прям зачеркиваю, не стираю, чтобы вы видели,
что это неправильный ход рассуждения. Дальше я говорю следующее, но смотрите, если бы xkt1 было бы
Липшицева, то можно было бы не зачеркивать, а попробовать вот все вот это превратить неравенство
Азумы. Но xkt1 нифига не Липшицева. Количество независимых множеств. Представьте себе,
у вас было две вершины, соединенных ребром, и вот тут была целая туча независимых множеств. Тут
была целая... ну понятно. Кок? Или наоборот надо рисовать? Ну понятно, да? То есть одно ребро удалили.
А, понял, наоборот. Вот так было. Туча независимая. Кок наоборот, вот такой кок. Провели ребро,
и все, они все пропали, они перестали быть независимыми. То есть добавление всего одного
ребра, и тем более порчат нам какой-то окрестности вершины, и куча всего порушится. Никакой тут нету
Липшицевости. То есть к иксу не получится применить неравенство Азумы ну никак. То есть надо
вычеркивать и вообще забывать. Надо придумывать какую-то величину, которая удовлетворяла бы
неравенство Азумы, и равенство нулю которой было бы равносильно вот этому неравенству.
Быстро произнесли? Понятно. У нас была понятная случайная величина хкт. Ее равенство нулю,
конечно, равносильна вот этому неравенству. Но она оказалась не Азумлемой.
Не применима неравенство Азумы. Так, цветочек-то я сотру с независимой множеством. Вот. Она не
удалась. Мы сейчас офигенную величину предложим. укт аж. Ну, в частности, укт первое. Какое
хотите. Вот укт аж. Сейчас будет офигенная величина. Вот это я очень люблю момент.
Давайте я лучше словами скажу. Это максимальное количество или лучше написать. Да, давайте я
лучше все-таки напишу, не словами. Словами скажу, а то долго писать и понятнее не станет. Сейчас
формально напишу. Это максимальное такое, какую букву мы еще не использовали,
Т. Максимальное такое Т, что существует С1 и так далее СТ под множество множества вершин
всего графа. Так. Такие, что для любого И мощность СИТ равняется К. СИТ независимо, ну, в смысле,
что не содержит ребер, независимое множество вершин. И еще, ну ладно, прямо вот здесь продумал,
для любых ИЖ мощность СИТ пересеченного с СИТ не превосходит единицы. О, какое роскошное
определение. Жуть полная. Нет, смысл-то очень простой, но картину надо опять нарисовать. Вот
наше множество вершин В. Ну, кстати, оно теперь у нас из А элементов состоит, потому что мы с таким
графом работаем. Ну так, чтобы не запутаться, сразу напомню. Но это не так важно, можно
определять с любым количеством вершин, конечно. Вот. И мы хотим в нашем конкретном графе, вот в
этом графе же, найти какие-то под множество, которые мало между собой пересекаются. Ну,
тут можно какую-нибудь такую вот сардельечку прицепить, пришпандорить. Немножко она не влезла,
правда. Ну понятно. Рисую плохо. Вот. Чтобы они мало попарно пересекались, но они могут очень
хитро пересекаться. То есть, каждые два не больше, чем по одной общей вершине, но их может быть много
таких. Вот. И чтобы каждый из них был при этом независимым. Ну и каждая мощность СК. То есть,
максимальный размер такой гирлянды ИСК вершинных сарделек, которые попарно пересекаются не больше,
чем по одной вершине. Каждые две имеют не больше, чем одну общую вершину. И при этом все эти
сардельки независимы. Не содержат ряда. Понятно, да, как это устроено? Ну, я часто про это рассказываю,
веселую интерпретацию. Представьте себе, что К равняется тройке. Знаете, есть веселая задача.
Собрались пьяницы. Каждый вечер они собираются на троих, выпивают, потом бьют друг другу морду
и на следующие вечера, и на последующие вечера они уже вместе не пойдут. Вот как долго это может
продолжаться. Это задача про у3 от КМ с чертой. Вот это задача про пьяниц. Ну то есть, если мы берем
полный граф на М вершинах и начинаем в нем выбирать такие треугольники, тройки, но выбирать так,
чтобы каждый вечер они пересекались не больше, чем по одному пьянице. Иначе они уже подрались,
они просто выпивать вместе не хотят. Вот это будет в точности то, что мы сейчас ищем для конкретно
вот этих параметров. Понятно сказал, да? Ну, веселая такая интерпретация, запоминающаяся. То есть,
здесь речь идет о том, что не все К-элементные множество пьяниц в принципе могут собираться. То
есть, речь идет не про полный граф, а про какой-то его подграф. То есть, есть заранее какие-то запреты
на то, как соображать на троих или там на пятерых или на сколько-то. Вот есть заранее те запреты,
которые диктует нам граф. А так нас интересует, как долго может продолжаться это безобразие. Вот
на этом конкретном графе. Такая вот смешная интерпретация. Ну ладно, это очень интересная
задача. Мы про нее будем говорить дальше, а не сегодня, когда будем изучать некоторые
характеристики гиперграфов. Это отдельная, очень важная, интересная история. Там теория
кодирования вылезет, про которую мы когда-то с вами говорили еще на ОКТЧ. Ну, в общем,
это просто как для примера, чтобы весело было. Так, вернемся сюда. Так, друзья, ну на самом деле
совершенно очевидно, что здесь звездочку нарисуем, что звездочка это в точности вероятность того,
что yкт равняется нулю. Ну, если в графе нет независимых множеств, то и размер самой большой
гирлянды из каких-то мало пересекающихся независимых множеств тоже равен нулю. Вроде
ужасное совершенно определение, но тривиальным образом, конечно, yкт равняется нулю. Если вообще
нет ни одного независимого множества на к1 вершине, вообще ни одного, то вы не сможете
собрать гирлянду из таких множеств. Гирлянд будет ноль. Пафос-то в чем? Пафос в том, что,
конечно, эта величина Липшицевая. Но по кому? Понимаете вы или нет?
По вершинам не знаю. По вершинам не знаю. Понимаете, вот тут опять может быть гирлянда вот такая. Вот они
все по одной вершине пересекаются, эти независимые множества. Выкинули эту вершину, и все, не осталось
ни одного независимого множества. Ну, не выкинули, а испортили. Там добавили какие-то ребра вот так,
и не осталось ни одного независимого множества. Понимаете? То есть по вершинам эта величина не
обязана быть Липшицевой и не является. А вот по ребрам является, потому что специально так сделано,
чтобы вот эти сосиски из гирлянды не могли иметь общего ребра. Удаление или добавление каких-либо
ребер не может поменять вот эту структуру больше, чем на единицу, максимальную структуру в графе.
Потому что если бы она поменялась больше, чем на единицу, это бы означало, что у ново появившихся
множеств есть общее ребро, а они вот так вот устроены. Там нет общего ребра.
Вот это такой тонкий момент, который всегда вызывает определенные трудности. Она так замудренно
вымрана, чтобы быть Липшицевой. Если мы предположим, что удаление одного ребра изменяет значение этой
величины больше, чем на единицу, то это означает, что концы этого ребра принадлежат сразу нескольким
независимым множествам, которые были изначально. Но так быть не может, потому что любые два пересекаются
не больше, чем по одной вершине. Поэтому вот она Липшицева по ребрам. Видите, как интересно,
в предыдущей теореме Балабаша была Липшицевость по вершинам, и без нее ничего бы не получилось.
А здесь нам хватит Липшицевости по ребрам. И даже убьем вот эту экспоненту, в отличие от Чебышова,
который не убил. Но это мы выясним. Так, друзья, я не очень взорвался, не слишком сложно рассказываю,
понятно? Я очень стараюсь рассказывать суть, и из-за этого может быть чуть труднее следить тем,
кто хочет записывать формально. Я неправ? Понятно, точно все понятно. Формально я это мог рассказать за
пять минут. Вот просто двигаемся формально, вот вводим такое формальное определение, вот оно равенство,
ну да, она Липшицева. Я потратил на это 20 минут, желая просто пояснить суть происходящую. Вот,
а дальше делаем то же самое. А? Да, это разумный ход. Да, на 2 в степени N, конечно, надо, да,
множить, да, и тут тоже. Так, 2 в степени N, ну а здесь делаем стандартную процедуру,
минус yk1 больше либо равняется 0, 2 в степени N на вероятность того, что, что ты будешь,
на вероятность того, что e yk1 минус yk1 больше либо равняется e yk1. Так, ну я не буду сейчас с вашего
позволения напоминать неравенство азумы в той форме, которая для ребер, вы посмотрите потом
в записи, с прошлого раза или сейчас посмотрите. Вот, значит, здесь получится 2 в степени N умножить
на e в степени минус, ну тут, конечно, а квадрат, но а это то, что стоит справа, то есть математическое
ожидание yк в квадрате. А поделить надо на 2, там, c из чего-то по два, да? Ну, c из m по два,
из m прямо в точности как в той формулировке, потому что сейчас у нас именно мэвершин в нашем
случайном графе. На 2, c из m по 2, ну это просто вот говорю, смотрите утверждение азумы. Я не
рисую дополнительную двойку, потому что тут нет модуля, он мне и не нужен. Так, ну лемма в лемме,
куда же деваться. Лемма в лемме вот так. Ну, это шутка, конечно, но мы лему доказываем,
а чтобы его доказать, но я обещал, уже придется доказать некое еще одно вспомогательное утверждение,
а утверждение сейчас будет такое, eyt больше либо равняется m в квадрате, поделить на 2k1 в четвертый,
умножить на один плюс о малой от единицы. Ну, плюс это на самом деле минус, но вы понимаете,
о малой может быть отрицательным, я это каждый раз напоминаю. Просто не принято писать минус о
малой от единицы, принять плюс, но если неравенство снизу, то имеется в виду, что существует функция
отрицательная, конечно, которая стремится к нулю при нашем параметре, стремящемся к бесконечности.
Так, если поверить в справедливость леммы в лемме, то мы можем продолжить вот это неравенство,
давайте вот так отчертим, у нас получится 2 в степени n на e в степени минус m в четвертый на 2k1 в
восьмой на один плюс о малой от единицы, совсем фигня. Так, это я возвел мат ожидания в квадраты,
поскольку оно с минусом, то неравенство идет в правильную сторону.
Но еще на два, что надо? На 2c и 2c надо поделить, да? А на что еще? Какую-то двойку потерял?
Так, так, так, так, так, подождите. А, вот здесь 4k1 в восьмой, да? Вот здесь 4,
ну, 4, конечно, да, 4. Да, да, да, еще в знаменателе 2c из m по 2, ну,
2c из m по 2 это асимптотический m в квадрате, а асимптотика у нас уже
тут написана, так что не жалко. Давайте я вообще вот так напишу, все, сразу, чтобы не переписывать.
Было m в четвертый, потом разделили вот на этот m в квадрате, двойки сократились, а асимптотика пошла сюда.
m в четвертый на 4k1 в восьмой, но m в четвертый сократилось вот с этим m в квадрате.
Где? Здесь? Здесь пофиг абсолютно. Здесь совершенно пофиг, потому что запасом стремится к нулю.
Смотрите, тут стоит 2 в степени n, ну, давайте я напомню здесь прямо, что m это асимптотический n поделить на логарифа в квадрате n.
А? Асимптотика сюда пойдет. Ну, то есть, это равно 2 в степени n на e в степени минус n в квадрате поделить на...
Чего? На 4k1 в восьмой и на логарифом в четвертый. Ну, в квадрат m возводим.
Вот здесь еще логариф m в четвертой степени. Ну, и там какая-то фигня, 1 плюс о малые от единицы.
Так, ну, может быть, кто-то забыл, что k1 это 2 лог 2kn.
То есть, k1 в восьмой, это логарифом в восьмой степени. Тут еще логарифом в четвертой степени.
Но будет логарифом в двенадцатой степени с какой-то константой, с какой-то асимптотикой. Да наплевать!
Потому что на этот логарифом в двенадцатой степени делится n в квадрате, а тут с плюсом всего лишь n.
С плюсом идет n, а с минусом идет n в квадрат поделить на какую-то дурацкую степень логарифма.
Конечно, вычитаемая забивает n с огромным запасом, то есть это стремится к нулю.
Все. Со свистом стремится к нулю. Отлично все.
Вот, честно говоря, я бы не мучил вас сейчас и вот эту лему и завершение доказательства доказывал бы уже в раз следующий.
Потому что это еще час. Мы так, в принципе, больше полутора часов говорим. Я могу начать,
могу, но это сейчас некоторых усилий потребует. У меня время формально есть. Я могу.
Не против чего? А, доказательства. А слушатели, которые там ли, все умерли уже. Там-то хоть кто-нибудь остался?
Или только те, кто сюда пришел?
Офигели, наверное, уже от происходящего. Ну, я не знаю, очень надеюсь, что нет. По-моему, все довольно так, но нетривиально, потому что много.
Много. Вот я поэтому думал, что может быть продолжить в следующий раз. Что тут, конечно.
Ну, смотрите, я на самом деле все-таки предлагаю в следующий раз, но что я хочу сделать прямо сейчас?
Я хочу прокомментировать это. Опять в терминах условных пьяниц. Ну, или просто, даже без пьяниц, просто прокомментировать.
Смотрите, вот если мы возьмем yкт от km с чертой, вот в этом смысле про условных пьяниц.
Так, а все понимают, что km с чертой это просто пустой граф на мэ вершинах?
km это полный граф на мэ вершинах, km с чертой это пустой граф на мэ вершинах. Без единого ребра.
Вот если мы рассмотрим такую величину, то она очевидно не больше, она очевидно не больше,
чем, ну очевидно не очевидно, это мы сейчас обсудим, чем c из m подва. Запомните это, кстати,
это будет потом, нам тоже потребуется когда-нибудь, на c из k подва. Но это может не очевидно.
Ну ладно, я объясню. Значит, что такое yкт от km с чертой? Ну, это значит,
что мы берем какую-то такую вот гирлянду из сосисок, то есть цепочку из кавершинных независимых
множеств, вот в этом пустом графе. Ну, то есть просто цепочку каких-то k-элементных под множество,
м-элементного множества, правильно? Лишь бы они пересекались каждые два не больше,
чем по одному элементу, по одной вершине. Ну, давайте их как-нибудь обозначим, а1,
а, s1 они обозначались, вот пусть будет s1 и так далее, st. s1 и так далее, st. Это будут те самые
независимые множества, которые образуют гирлянду. То есть мощность каждого из них это k,
отлично. Так, вот смотрите, как бы это обозначить-то. Дайте я словами скажу,
сколько всего отсутствует ребер в множестве s1, оно независимое, ну, сколько в нем всего отсутствует
ребер. Понятно, что csk по 2, и тут тоже отсутствует csk по 2 ребер. Значит, суммарно отсутствует
сколько ребер? t умножить на csk по 2, правильно? Причем общих отсутствующих ребер нет. Они не
пересекаются эти множества. Множество отсутствующих ребер не пересекаются, потому что сами эти
множества пересекаются только по одной вершине или вообще не пересекаются. Значит, здесь свое
множество отсутствующих ребер, тут свое, тут какое-то тт по счету. Так, это суммарное количество
отсутствующих ребер. А всего ребер вот в этом смешном графе отсутствует csk по 2. Это всего,
сколько в нем отсутствует ребер. Ну, так ясно, что соотношение вот такое. Все, я доказал вот
неравенство. Это действительно очевидно, надо просто написать, чуть подумать. Поняли, да? Вот,
то есть верхняя оценка имеет, ну скажем так, порядок роста m квадрат поделить на k квадрат.
Ну, роста там или чего-то, порядок своей величины. m квадрат поделить на k квадрат. То есть утверждение
леммы нетривиально в том смысле, что когда мы заменяем абсолютно пустой граф на случайный
его под граф, то в среднем, если мы и теряем, то не более чем какую-то логарифмическую в квадрате
величину в знаменателе. Тут верхняя оценка вот такой величины, а тут нижняя, ну почти такое же. Тут
было k квадрат, тут становится k в четвертый. Значит, друзья, если вас еще так заводит прямо от чистой
математики, то я вам так скажу. Гипотеза, которая, по-моему, до сих пор не доказана и не опровергнута,
вот я ее не встречал, доказательства, пока что, состоит в том, что даже в этой лемме четверку
вообще можно на двойку заменить, ну поставишь тут какую-то большую константу. Никто не может доказать.
То есть утверждается, что, знаете, вот это просто пустой граф, в нем вообще нет ни одного ребра,
а тут случайный граф, то есть половина ребер возникает в среднем. Реброядность, ребра одна-вторая же,
правда? Значит, вот у этого случайного графа половина ребер откуда-то появляется. Тем не менее утверждается,
что вот эти сосиски не набегут, вернее, не пропадут, не пропадут, не съедятся. Их
все равно будет порядка столько же, сколько верхняя оценка, вот эта простая верхняя оценка. Я понятно
объясняю, да? Ну ладно, в общем, вот это нам предстоит доказать. Я все-таки хочу, чтобы люди,
которые готовы в четверг, уже не в выходной день, честно прийти на лекцию, с удовольствием послушали,
как это доказывается. Потому что доказывается это очень красиво. Мы доказываем вероятностное утверждение,
добавляя в доказательстве некую дополнительную случайность, и за счет этой дополнительной
случайности удается все доказать. Но там придется довольно много аккуратно объяснять,
ничего сложного нет, но надо просто, чтобы вы прочувствовали. Но очень красиво. Вероятностным
методом доказывается вероятностное утверждение. Строго говоря, до шести я, наверное, бы уложился,
но что-то мне вот кажется, что время у нас пока есть в семестре, давайте все это продолжим в четверг.
Но, по крайней мере, вроде мы традицию это разбили. Я остановился, конечно, не доказав всю теорему,
но тут нет никакой страшной формулы, которую нужно доказывать в следующий раз. В следующий раз я
просто напоминаю, что такое YK, и мы прямо начинаем доказывать это утверждение. Думаю,
что за пару мы за все завершим. Аккуратно, спокойно. Что еще раз? Да-да-да, это проблема
нерешенная. То есть можно ли четверку заменить на двойку, мы не знаем. Ничего не знаю. По-моему,
как четвертый, это самое лучшее, что известно. Вот по-моему, это самое лучшее, что известно.
Я не встречал других утверждений, но это удивительно совершенно. С точки зрения вот этой задачи убрать
какую-то степень логарифмов знаменателя, но это никакого значения не имеет. Что вы видите,
это двенадцатая степень, ну, сто сорок пятая, какая хотите. Вот. Если просто интересоваться тем,
а насколько же плотно сконцентрировано, можно ли улучшить это неравенство. Есть
альтернативные неравенства, более сильные в некоторых случаях, чем неравенство Азу.
Называется неравенство Тологра. Я про них здесь рассказывать не буду. Но вообще,
завершая лекцию, еще один важный комментарий. Мы много рассуждаем про неравенство плотной
концентрации мира. Чебышов сломался, вот у нас Азума сработала. А кроме Азумы,
сейчас вот прозвучало, есть какие-то Толограны еще. Но Тологранов я рассказывать не буду.
Вот если кого-то, может, по ту сторону экрана и здесь присутствующих, протаскивает, так сказать,
не только от чистой математики, в которой доказываются вот такие офигенные теоремы,
но еще и от каких-то таких явлений прикладной математики, то есть не совсем сугубой прикладухи,
но когда стык, вроде как, и чистая математика, и в то же время бах, и какие-то приложения. Я вам
скажу, что вот эта вся деятельность неравенства плотной концентрации меры исключительно важна
для задач оптимизации. Вот задача оптимизации в очень существенной степени повязана на то,
как плотно сконцентрирована мера около какого-то своего среднего. И вот все эти неравенства Zoom,
это Лограна и так далее, они там используются на пропалую, а оптимизация это, по сути,
машинное обучение и статистика. То есть это уже, конечно, прямые приложения, и вот у нас тоже
люди этим занимаются, в тот же Гасниках, например, очень много про это рассказов. Но это так в сторону.
Ну ладно, тогда на сегодня все.
