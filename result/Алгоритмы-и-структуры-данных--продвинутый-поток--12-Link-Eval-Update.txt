Вот. Молимся мы сегодня на мистическую структуру данных.
Link eval update. Вот. Ну давайте сегодня мы ее еще раз сформулируем.
Так что это такое? Значит, это следующее. У нас есть n вершин.
У Кая, ну вот эти вершины образуют лес.
Вот как-то так это звучит. В смысле выглядит.
То есть они образуют в каждом момент времени лес.
Вот. То есть как-то вот так. В чем именно лес.
То есть вовсе не обязательно дерево. Если дерево, скорее всего, все уже тривиально.
Вот. А еще, значит, у каждой вершины есть так называемая метка.
Лейбл от V. Это некий элемент из S.
Про S, ну, по умолчанию мы знаем только одно.
Что S является полугруппой относительно операции ыть.
Да. То есть это полугруппа, да.
Нет. Вот. То есть у каждой VS поставляется так называемая метка.
А по этой что? Вершина.
Каждой вершине написано метка.
Да. На каждой вершине написано метка.
Деревья у нас это ориентированы, да?
Да. Деревья совершенно верно ориентированы.
То есть, более того, хранятся они в формате. У каждой вершины написан родитель.
Родитель. Да. Родитель.
А потомка мы не знаем. Именно родитель, да.
Потопков мы можем вообще не знать, да.
Ну да, вы видите. Ну или понятно. Написано ну, если родителя нету.
Вот. Это вот у нас такая, ну вот эта полугруппа.
То есть, операция ыть ассоциативно.
Это все. Что мы по камере по умолчанию знаем.
Впрочем, не то чтобы мы сегодня будем сильно копать вам совсем в абстракционизм.
Потому что мы на самом деле сегодня попробуем поиграться с конкретными примерами.
ыть.
Вот. Да. Что мы совсем этим хотим делать?
Ну, мы хотим выполнять, как следует из названия, три типа операции.
Значит, ну, во-первых, хочется, конечно, выполнять эвал.
Это что значит?
Значит, эвал от В.
Это значит следующее.
Рассмотрим вершину В.
И рассмотрим ее путь до корня.
Ну, до корня ее дерева, конечно.
Давайте себе представим, что эти вершины мы назовем.
То есть, допустим, вот это корень.
Это у нас вершина Вк.
То есть, тут получается В1, В2 и так далее. Вк-1.
Вот.
И мы очень хотим вычислить такую величину, как
вот будьте внимательны, давайте тут с размерностями.
То есть, label от В0, ыть, label от В1, ыть, label от В2, ыть и так далее, ыть, label от Вк.
Что такое эвал?
Вот эвал это функция.
То есть, запрос.
Эвал от В это вершина.
Да.
Который дается на вход В.
И мы хотим вычислить вот такое значение.
Где это вот все, ну, в родители приходим каждый раз?
Ну, по сути, да.
Только обратите внимание, видите, мы идем слева направо от корня к вершине В, а не наоборот.
Это важно, потому что это какого-то друга.
Ассоциативность.
Ассоциативность есть, это и есть определение понятия полугруппа.
Но помните, ассоциативность и есть коммутативность.
Логично, да?
Да, коммутативность никто не обещал.
Да, это может быть произведение матрицы.
Там скажем.
Ну, а какие примеры это?
Некоммутативных ассоциативных операций вы знаете.
Некоммутативных ассоциативных.
Ну, окей, в каждой вершине стоит перестановка, да.
Действительно.
Вот, окей, ладно.
Нет, или там, ладно.
В алипиадах примеров бывает в каждой вершине написана строка «посчитайте хэш».
А мы не знаем, что это такое.
Вот.
Увы, после аналогов MAP мы знаем, что такое хэш.
Нет, я бы сказал, что мы верим в его существование, да.
А что такое вот этот строковый полинарный хэш, мы все-таки не знаем.
Ну и неважно, в общем-то.
Нам он и не понадобится.
Так вот, это вот eval, это вот, собственно, то, что единственная операция, которая будет что-то реально возвращать.
Что мы еще хотим делать?
Еще мы хотим делать линк.
Линк вот так вот делаем.
От V и W.
Значит, ситуация такая.
Значит, здесь есть ограничение, что V и W это не просто вершины, но это оба раза корни своих деревьев.
Ну, естественно, различные.
То есть у нас вот будет вершина V, на которой что-то вот висит.
Там, условно, под дерево какое-то.
И W, на которой тоже висит какое-то под дерево.
Ну и, собственно, от операции линк требуется только одно.
Подвесить W, объявить W ребенком V.
То есть вот примерно вот так это и будет выглядеть.
То есть, в общем-то, то есть, да, никакие лейплы не меняются.
Ну, конечно, результаты эвалов, конечно, принципиально меняются.
Обратите внимание, да.
Ну, таки так, у вершин вот этого под дерева они не меняются от слова никак.
А у этого под дерева к ним всем, ну, к ним всем, так сказать, они все там слева домножаются на label от V.
Кстати, на тему умножения слева.
За это у нас еще дополнительно отвечает операция update.
Update от R.
Да, то есть, да, подчеркиваем.
А, нет, вру, вру, вру.
Не R, а R и X.
Значит, R это корень, а X это мистическое значение.
Является мистическим значением.
Это новое значение label от R?
Нет, нет, нет.
Тут еще круче.
Тут, то есть, да, label от R изменится.
Да, вот я и пишу, что оно делает.
Так вот, оно делает label R, да, хочется написать функцию it равно, но это будет неправда.
Потому что, да, мы просто берем label cork и домножаем его слева на X.
Вот так.
Да, хочется написать it равно, конечно, но вот.
Ой.
R равно it.
Такую операцию еще не изобрели, кстати.
Неоднозначно.
Да.
Такое.
Не надо.
Да, да, да.
Вот.
Вот, собственно, и все.
То есть, опять, обратите внимание, то есть, мы просто говорим, что значение всех evals тогда во всех вершинах дерева с cork в R,
тогда просто все будут домножены слева на X, по сути.
Вот.
Больше ничего не поменяется.
Вот.
Вот у нас вот есть такая мистическая структура.
Вот.
Вот.
Ну, как она работает?
Ну, работает она, конечно, предельно просто.
То есть, она...
Ну, вот, действительно, все деревья вот так хранятся.
То есть, у каждой вершины есть parent и практически все.
По камере, самые базовые.
В первой реализации, то есть, это все.
Что?
Вот.
Ну, понятно, label, да, и label, конечно, да.
И, соответственно, можно вот так вычислять.
Но с другой стороны, заметим следующее.
То есть, у нас структура, конечно, может не все.
То есть, в отличие от линката, то есть, у нас подвешивается только корень к корню.
То есть, если у вершины появился родитель, то он навсегда.
То есть, да, она может долго появиться.
То есть, тут как бы она сначала появляется,
а потом через некоторое время когда-нибудь у нее появляется родитель.
Вот.
Но если он уже появился, то он навсегда.
Ну, на уровне определения, конечно.
Вот.
Но внутри себя, конечно, это нам уже дает возможность
сделать мистическую операцию, ну, на русском языке, сжатия путей.
Потому что, раз уж родители навсегда определены,
вот мы думаем, так, вот у меня, допустим, есть вершина В.
Чтобы вычислить ее значение, я должен прогуляться по всем вот этим вот вершинам,
прям по родителям, и, соответственно, вычислить вот это значение.
Но когда-нибудь этот родитель может быть подвешен еще к кому-то.
Это будет означать, что нужно все равно прогуляться по этим вершинам, вычислить это значение,
но просто потом его домножить еще там на что-то там дальше.
Возникает естественная мысль.
Ну вот.
А нельзя ли, так сказать, просто для вершины В сохранить, что как бы мы,
как бы мы не вычисляли ИВАЛ, мы дойдем досюда и наберем там значение какое-то?
Ну, то есть сохранить значение.
Ну вот.
Да, то есть вот какая-то вот такая мысль.
И потом, ну, то есть это что-то типа рекурсии с запоминанием, что ли.
Вот.
Ну, в общем-то, да, идея, в общем, классическая.
Вот.
И просто приводит нас, ну, тут на всякий случай давайте употребим выражение,
которое тут сразу у Тарьянов водится в этом месте.
Вот.
Это так называемое виртуальное дерево.
Значит, смотрите.
Просто каждая из этих штук называется дерево.
Да, поразительно, да?
Но тем не менее, она реально называется дерево.
Но это, ну вот.
Но, но, но, но.
То есть если это дерево, то мы можем вместо дерева хранить виртуальное дерево.
Так называемое виртуальное дерево.
Значит, аксиоматика у него предлагается следующее.
Значит, что это такое?
Значит, вот сейчас я просто вот давайте, просто вот возьму, чтобы не перепутать и напишу просто в формальное определение.
Значит, что это такое?
То есть это тоже дерево.
Значит, аксиомы следующее.
Аксиома номер раз.
Аксиома номер раз.
ВТ хранит те же вершины, что ИТ.
Вот.
Прямо на уровне концепции, да?
Значит, еще.
Ш, где украинский?
Челты.
Давай не надо.
Не, причем тут краинцы?
Это просто такая нотация есть.
Ну, как бы вопрос к Тарьяну, я не знаю.
Нет, может там, конечно, рядом с ним в этом месте сидел такой, это, американский ученый Эндрю Вячеслав Голбер, конечно.
Но что-то я сомневаюсь.
Хотя, нет, хотя он мог в принципе там.
Альгоритм Голбера Тарьяна же существует.
Ну, вот.
Машина Голберга.
Машина Голберга.
А, вот этот вот БМБ там на парковке, да?
Так.
Куда-то мы не туда пошли.
На нашем изучении.
Не, ну, что-то мне подскажешь, у него машина есть на Векторе.
Как-то в Америке сложно жить без машины.
Ну, вот.
Ну, я не знаю.
Так вот, ладно.
Т и ВТ.
Даже У, Т и ВТ.
Один и тот же корень.
Корень Р.
Я еще так напишу.
С одним и тем же лейблом.
Вот.
То есть, ну, тут предлагается такая аксиоматика.
Ну, тут как-то будет, знаете, это...
Как бы Гайден Вёрс строго аксиоматику, строго ей привекался.
Потом пришел...
Да, у корня, да.
То есть, в переводе говоря, то есть, пишем, что это будет называться у нас так.
Лейбл Т от Р равен лейбл ВТ.
А так вот.
Ну, тут удобные такие обозначения.
Ну, впрочем, на самом деле, конечно, это уточнение может быть...
А, хотя нет, оно...
Хотя нет, оно...
Хотя где-то оно достаточно излишнее, если честно.
По одной простой причине.
Что если корень Р, ну, вот.
Что дело в том, что, на самом деле, для любой вершины В...
Верно.
Следующая штука.
Вот я так напишу.
Вот.
Так вот.
Если вы вычислите эвал...
Давайте я вот так напишу.
Эвал с индексом Т.
То есть, в дереве Т, если мы вот этот вот эвал честно вычислим.
То он равен...
Эвалу от вершины В вычислен в уже виртуальном деле.
В виртуальном деле.
Вот такая вот базовая аксиоматика.
Вот.
Ну, то есть, мы тут наложили на себя некоторые ограничения.
То есть, мы хотим работать в некотором виртуальном дереве.
То есть, как хранить дерево не в таком виде, а в каком-то другом.
В котором мы могли бы что-то модифицировать, за счет этого получать профит.
А не вычислять этот эвал просто от расстояния от вершины до корня.
Вот.
Соответственно.
Поэтому иногда хотим наложить на себя какие-то аккуратные ограничения, чтобы что-то гарантили.
Ну, это вот такой самый простой вид.
То есть, на самом деле, у нас сегодня от каких-то аксиомат будем отказываться.
Другие, наоборот, вводить.
То есть, там это веселье будет.
Да, конечно.
Ну, Тарьян это успешно делает.
Как бы выкинем И, врубим там И4.
А, кстати, это римские цифры, на самом деле.
Вот.
Правда, римские цифры забавны?
Нет.
Нет, только как Тарьян написал, я так и воспроизвел.
Только на русский перевел.
Вот.
Так вот.
Значит, чем приятно такое дерево?
В этом дереве можно оценивать.
В этом дереве можно ввести...
То есть, в таком виртуальном дереве можно ввести такую внутреннюю функцию.
Такую подкапотную.
Как компресс.
Это виртуальном дереве.
Да.
Вот.
Ну, потому что...
Заметим теперь следующее.
Вот.
Рассмотрим какую-нибудь вершину В.
Вот опять, да?
Вот.
Ну, вот.
Вот рассмотрим, рассмотрим, рассмотрим, рассмотрим.
Вот она дошла до корня, да?
Тут тоже.
Равно.
Это В0, В1, В2.
Вот.
В3 и так далее.
Ну, и тут ВК равно В.
И самое главное, что у них есть лейблы.
Я эти лейблы так и помечу.
L0, L1, L2, L3 и так далее.
LK.
Вот, понятно, да?
Ну, вот.
Так вот, действительно возникает интересная мысль, что при вычислении...
То есть, что, на самом деле, раз мы все равно будем прибираться по всем этим вершинам до корня и вычитать эти произведения,
а не стоит ли их один раз пробежаться и предподсчитать?
И в результате получается следующая штука.
Такая классическая, СММная.
То есть, смотрите.
То есть, мы берем те же самые вершины.
В1, В2.
В2, я сказал.
Так.
В3.
Еще вот ВК.
Вот.
И теперь мы говорим, что они все подвешены...
Вот как-то вот так.
Все подвешены к корням.
И меточки у них теперь новые.
Какие меточки?
Ну, легко догадаться.
А вот дальше будет интереснее.
Значит, у В1 она тоже не меняется.
А вот у второй вершины она меняется.
И у третьей меняется.
А почему не L0 на L1?
L0 на L1?
L0 на L1?
Да.
А вот почему. Смотрите.
Дело в том, что когда вы будете вычислять значения от В1,
вы рассмотрите метку здесь,
рассмотрите метку здесь и перемножите их.
Если вы напишете L0 на L1, то получится L0 на 2 раза.
Тут вообще удобно очень понимать,
что чиселка написана на ребре, исходящем из вершины.
Правда, у корня она тоже есть.
Но тут получается, в общем, полуинтервал.
Ну, и здесь у нас остается L1, L2, L3, Lk.
Вот такая вот красота у нас.
Вот.
Вот.
Ну и действительно легко убедиться,
что при введении таких меток действительно вот эти все условия сохраняются.
Ну, это условие очевидно, это тоже.
Ну, вот. Ну, самое нетривиальное вот это.
Но здесь действительно суть в том,
что если у нас там как-то эвал попал в какую-нибудь там вершину,
допустим, V3,
то дальше он в ряд, записывая справа налево,
должен записать L3, L2, L1, прежде чем попасть в L0.
А так мы теперь просто туда попадаем и записываем L1, L2, L3,
правда, в виде их произведения.
Вот тут мы явно пользуемся, конечно, ассоциативностью.
Чего?
Ну, как бы при любом эвале мы на L0 все равно тут ручками будем домножать всегда.
Вот.
Вот. Вот такой компресс.
То есть в принципе это можно его код написать какой-нибудь рекурсивный,
но необходимости...
Значит, смотрите.
Вот давайте себе представим,
как мы вычисляем...
как мы вычисляем эвал от V1?
Он будет равен L1, там L0 умножить на L1, правда?
То есть когда мы... идея в том, что когда мы пересоединяем,
мы будем искать эвал от V0, который в старом деле...
Нет, ну от V скорее.
Не-не-не, я не...
Ладно.
Ну нет, мы как бы все равно будем вычислять делать...
эвал будет делать абсолютно то же самое.
Только родители просто будут немножко другие.
То есть как всегда, смысл ребра любого, это...
говорим, что если там в дереве T пробежаться по ребрам,
то вы рано или поздно добежите вот до этой вершины,
и причем более того, прежде чем вы до нее дойдете,
у вас наберется вот такая чиселка.
Вот.
То есть...
Еще раз, смысл, почему это L1?
То есть V1 или L1?
А смысл очень простой.
Ну, дело в том, что...
как бы, смотрите, эвал от V1, здесь L0, ведь L1.
Вот.
И здесь он тоже должен остаться тем же.
Вот.
Но если мы тут заменим L1 на L0-L1,
то получится тогда вот эвал в виртуальном дереве,
получится L0 на L1, и еще на L0 замножить.
А это немножко не то.
Ну, конечно, слева.
А если мы не делали бы так, что нам приходилось по-настоящему замножать,
а просто везде бы L0 добавить?
Эвал-то же самый.
Нет, ну тогда это надо было бы...
О, все, все.
Я понял.
Нет, ну тут можно было бы замножить всех на L0
и объявить, что у них родителей нет, но это было бы неправда.
Я понял, да.
Так что вот.
Вот такая красота.
То есть вот такой компресс.
То есть вот, в принципе, это более известен,
то есть это более известен как эвристика сжатия путей.
Ну, вот такие в SNM.
Ну, правда, SNM, как видим, это не совсем это.
Ну, почти.
Но по большому счету нам там...
То есть на самом деле SNM это такой,
может быть, упрощенный частный случай этого.
Ну, потому что там у нас единственное заключается суть в том,
чтобы когда мы подвешиваем,
то есть нам нужно было просто,
скажем, в каждой вершине стоит там фиксированное число,
нам очень хочется там
выполнять какую-то операцию в духе A и B равно A.
Соответственно.
И потом их там соответственно сравнивать.
Ну, то есть по сути просто выяснять, кто корень.
Причем нам, в общем-то, по барабану на самом деле
кого куда подвешивать.
Вот.
Поэтому на самом деле, то есть SNM это
на самом деле просто частный случай этой штуки.
Вот.
Ну, в общем, ладно, отдельно потом можем обсудить что-то такое.
Что такое SNM.
Вот.
Никогда не писал.
Ну, мало.
Всякое бывает.
Может вы это никогда не писали SNM,
но являетесь богом DSU, мало ли.
Ну, что такое DSG, не знаю уже я.
Ну, может быть.
Вот.
Так.
Так что оказывается, что если вы,
ну, то есть крайне логично,
то есть просто уже
хотя бы и вристика сжатия путей.
Вот.
Но оказывается, что она, в принципе,
сокращает работу достаточно серьезно.
Значит, смотрите.
Значит, а именно следующее.
Значит, есть мистическая теорема.
Мы ее пока проанонсируем.
А успеем ли мы сегодня хоть что-то доказать из этого или нет,
я пока не знаю.
Значит, мистическая
значит, мистическая.
Ну, значит, теоремы тут,
значит, все работают следующим образом.
Значит, мы представим себе,
что у нас есть n вершин
и, внимание, m, вот именно сжатий.
Вот именно сжатий.
Не путать с количеством операций.
Ведь обратите внимание, что в такой реализации,
наверное, эвал будет предназумевать внутри себя сжатие.
Правда?
Понимаете это?
Ну да.
То есть базовая реализация такая.
Мы храним вот такое виртуальное дерево
и внутри эвала всегда выживаем сжатие пути.
Вот.
То есть вот такое вот сжатие вызываем.
Ну, естественно, мы его можем спокойно сделать
за о длины пути.
Ну, тут я думаю понятно.
Вот.
Значит, m сжатий.
Так вот.
Значит, n вершин, m сжатий.
Зачем?
Эвал должен возвращать вот это значение.
Это все, что он должен делать.
Нет.
Ну, так в виртуальном дереве мы его переписываем.
Нет.
Нет.
А что с точки зрения кода?
У вас в каждой вершине хранится parent.
И мы говорим, что если у вершины, значит, если у вершины,
ну, если в вершины нет родителя, то ничего не меняется.
Если есть родитель, но нет дедушки, то тоже ничего не меняется.
А в противном случае мы запускаемся рекурсивно от родителя.
И после этого присваиваем себе...
Берем все parent родители.
Нет.
Да, нет.
Ну, не все, у него один родитель.
То есть берем тупо parent родителя, а в качестве лейбла
себе пишем то, что у родителей и домножаем на себя.
Все.
Вот.
Да.
Такая.
Достаточно классическая.
Так вот.
Мистическая терема.
Значит, мистическая терема номер раз.
Значит, суммарная длина.
У нас же именно длина интересует.
Суммарная длина.
Значит, m сжатий.
Вот я даже так пишу.
На n вершинном лесе.
Что сжатием считается?
Какой подъем?
Сжатием считается вызов функции компресс от какой-то вершины.
Да, то есть, например, компресс, конечно, в eval.link.update,
то есть, в явном виде мы компрессы можем не вызывать,
но eval вызывает компресс.
И кто еще вызывает компресс?
Eval вызывает компресс.
И кто еще вызывает компресс?
А, собственно, больше никто.
Вот.
Но мы можем просто предположить, что мы просто вызываем...
Иногда, то есть, представим себе, что у нас такая структура называется link-compress.
То есть, мы иногда делаем линки, иногда говорим вершину,
ой, давай сделай мне компресс.
И делаем вот ровно вот это.
Так вот, суммарная длина m сжатий на n-ом весе.
Что значит длина сжатия, подождите, мы говорим, что сжатие это будет компресс.
Потому что, да, вот, ну, например, здесь сжатие, ну, будет то ли k, то ли скорее k плюс 1.
Потому что вот к этому сжатии вот у нас в данном случае поучаствовала k плюс 1 вершина.
То есть, за длину сжатия мы будем называть длину до корня в момент вызова.
Да.
Ну да.
Ну, заметим, что, по сути, это, собственно, ровно там...
Ну, вот.
Так же классика такая, да.
Так вот, суммарная длина m сжатий на n-ом весе.
Лесе не превосходит чего?
Ну...
Нет, никакие ребра убиваться не будут.
Они будут перевешиваться.
Поэтому это...
Поэтому убить...
Нет, тут, понимаете, тут такая подлянка такая, что очень хочется мыслить в терминах, что это все работает за o от m.
Там n плюс m, наверное, да.
Потому что...
Ну и действительно, на самом деле, заметим, что если вы сначала сделаете все линки, прям все, действительно, сделаете прям единое дерево на n-вершин,
а потом будете делать компрессы, то это суммарно реально за n плюс m будет работать.
Да, но иногда, к сожалению, это не так.
То есть, мы иногда хотим вычитать валы до того, как, собственно, все на все повесится.
Ну вот.
Ну, по-разному, на самом деле.
Ну вот.
Ну, в первую очередь, оказывается, что это от m на самом деле может серьезно зависеть.
Значит, ну здесь сейчас будет кое-что достать.
Ну, тут разные варианты.
Вот я, значит, убойная теорема говорит следующее, что тут написано m плюс n умножить на максимум из единицы.
Значит, дальше, логарифом двоичный n квадрат делить на m плюс n делить на логарифом двоичный 2m плюс n поделить на m.
Так, сколько скобочек я тут должен закрыть?
Нет.
Логарифом двоичный с скобочкой 2 на m плюс n делить на m?
Да.
То есть, это один логариф по основанию другого?
Ну, на самом деле, да.
Более того, кто-то вообще предложит, что давайте, в этом месте вообще не заморачиваемся.
Давайте, там Паша Маврин, скажем, вообще предлагает.
Давайте для удобства считать, что m у нас где-то между n и n квадратом.
Ну, давайте вообще смотреть.
Какие тут крайние случаи вообще?
Ну, m.
Ну, во-первых, если m, допустим, меньше либо равно n, то вот это вот все превращается в n лог n банально.
Логично, да?
Нет.
Почему мы это делаем?
Ну, давайте внимательно.
Ну, давайте внимательно.
Смотрите, вот m плюс m.
Это там не более чем 2n.
Логарифом.
Значит, смотрим тут.
n квадрат поделить на 2n.
Это n.
Ну, n пополам.
А в знаменателе получается, ну, что-то константа какая-то, короче.
Вот.
Ну, в худшем случае 4, да.
Ну, не суть.
Вот.
Так как у нас все равно ошка, то есть получается вот n лог n.
То есть, в принципе, оказывается, что можно считать, что учетная стоимость каждой операции логарифом.
Вот.
Ну, в принципе, это можно будет даже достаточно просто доказать.
Ну, в свое время мы их даже и сделаем.
Вот.
Есть другой, значит, ну вот, другой крайний случай.
m равно n квадрат.
А почему это крайний случай?
Можно это объяснить?
Ну, то есть, почему может быть больше, чем n квадрат?
То есть, будет сжато все после n квадрат сжатки, как я, наверное, понимаю.
Ну, там не совсем.
Нет, это не обязательно будет сжато именно все.
То есть, вопрос такой.
Сколько сжатей нужно провести, чтобы сжать все дерево?
То есть, у нас получилось солнышко, кажется, называется, да?
Нет, тут это не...
То есть, можно сжать каждый раз, чтобы тоже вершина где-нибудь была.
Да, может быть такое.
Но при этом, если ты один раз ее сжал и потом попросил тут же второй, то второе сжатие будет за вот единицы.
Поэтому там включится амортизация.
То есть, как бы этих единиц...
То есть, там будет либо они все сожмутся в одно дерево, либо их будет так много, что там этих сжатий одинаково, что там будет очень много единичек, и в среднем получится, на самом деле...
У тебя имеют предпосылы к тому, чтобы сказать, что m равно n квадрат?
Нет, ну просто представь себе, что у нас очень много запросов.
Вот так.
Ну какова есть такая?
Ну вот, то есть такое.
Ну вот, действительно, если мы подставим n квадрат...
Нет, почему вот именно n квадрат?
То есть, если в эту формулу подставить, то можно заметить, что тогда вот эта штука вообще превращается в от m плюс n, на самом деле.
Какая?
Вот эта вся.
Если квадрат или больше, то как бы здесь вот эта штука превращается в что-то меньше единиц.
Вот.
Ну а здесь, а это растет.
Нет, а на самом деле тут от m плюс n начинается даже раньше, обратите внимание.
То есть, в такой формулировке это надо подогнать такое m, чтобы вот это стало равно вот этому.
И на самом деле легко убедиться, что как бы...
Ну есть понятно, что m должно быть больше n, поэтому симпатически m плюс n то же самое, что m.
И оказывается удобно считать, что m это просто будет n в степени полтора.
Да, то есть вот на самом деле тут вот такая заява.
То есть, начиная вот где-то с...
Получается m больше либо равно n в степени полтора, то есть это получается m плюс n просто.
Нет, ну что касается, если брать именно квадрат, то на самом деле если вы заранее знаете, что у вас квадрат запросов будет, да,
то это означает, что вы там лишний квадрат действия можете делать.
А на самом деле как бы сделать это так, чтобы у вас было n квадрат плюс m действия очень просто.
Просто вы говорите следующее, что каждый раз, когда вы подвешиваете корень к корню, вы делаете компресс у всех его потомков.
Ну, смотрите, вот вы подвесили, вы говорите там подвесили вершину w вершину.
Ну, по сути да, хотя на самом деле, в чем каждый компресс будет работать за вот единицы,
потому что очевидно, что при такой штуке у нас всегда будет, то есть на самом деле все деревья будут выглядеть вот таким вот нехитрым образом.
Нет, ну вот...
Да, конечно.
А изначально у вас есть n деревьев по одной вершине, естественно, то да, то есть просто храните набор звездочек и, собственно, переподвешиваете.
Хотя это уже практически то же самое, как для каждой вершины храните ответ, храните кто там корень, если кто-то кому-то подвесился, значит к этим вершинам вы там добавляете лейбл от w.
Вот. И в принципе это, если это совсем в тупую делать, то есть обратите внимание, мы сейчас тут не заморачиваемся на тему того, как тут там какой-то там меньше к большему подвесить и так далее,
то получается за n квадрат, даже так уже за n квадрат делается.
Но тут вот теорема чуть более сильная.
Вот.
Но это первая теорема.
Но оказывается, что она работает, то есть у нас на подвешивании никаких ограничений нет, то есть подвешивается что угодно к чему угодно.
Вот.
Но на самом деле бывают более красивые случаи.
Бывают ситуации, когда получаемые деревья, когда дерево t сбалансировано.
На самом деле да.
Потому что на самом деле я еще не сказал определение слова сбалансировано.
Вот.
Значит смотрите.
Определение.
Так.
Ну во-первых, определение даже не сбалансированности, а введем такое понятие, как пусть h от v,
такое равное h вотvals индексом ti от v, а вот так напишем.
Значит оно нас будет интересовать именно в дереве t.
Это, значит максимальная, максимальная Analogity specia,
Colin area.
mericicka Fredericka.
В applicable conditions,
максимальное расстояние от v до какого-то потомка v.
Да, максимальная глубина поддирала.
На самом деле в SNM это называется ранг.
Потому что в ранговой евристики вы вычисляете ровно вот это.
Ну да, вы ее можете через size записать.
Но на самом деле тут парадокс в том, что можно считать через это, можно считать через size,
и анализ будет примерно один и тот же.
Но тут предлагается ввести такое h, то есть такое максимальное расстояние.
Так вот, теперь определение, важное определение.
Как бы его написать-то так?
Дерево t, обратите внимание, мы говорим сейчас именно о дереве t.
Про виртуальные деревья мы сейчас не говорим от слова ничего.
Так вот, дерево t сбалансировано, вот, значит сбалансировано.
Если существуют такие константы, значит a больше 1 одного и c больше либо равно, ну допустим одного, хотя там можно больше нуля написать.
Такое, что для любого h верно следующее.
Количество вершин с, вот давайте так, h' я напишу, с h от v равно h', не превосходит cn поделить на a в c.
На a в степени h'.
Ну да, причем так, так сказать, экспоненциально меньше.
Ну это конечно не совсем экспоненциально, конечно.
То есть a не обязана быть z или больше.
Чаще всего там, например, в каких-либо классических примерах обычно a равно 2.
Ну то есть в частности, например, если вы гарантировали, что вы всегда подвешиваете меньшее дерево к большему, например, то тогда это дерево будет сбалансировано.
Вот, кстати, давайте для разминки такое мистическое утверждение.
Вот представим себе, что вы, когда, что у вас каждый раз, когда вы делаете линк, у вас как-то так всегда получается, что в поддереве вершины w вершин не более чем вершин в поддереве v.
Ну предположим, что вам тут всегда фантастически везет и там size of w меньше либо равно size of v.
Тогда я утверждаю, что все эти деревья, то есть тогда все деревья, которые у вас будут получаться, они будут сбалансированы.
Вот, понятное утверждение?
Ну да.
И в общем-то даже, может быть, даже где-то понятно откуда оно берется.
А при этом мы просим, чтобы w тоже будет сбалансирована в том валище?
Нет, ну они изначально будут сбалансированы, потому что одна вершина.
Да, и они постоянно. Постоянно в каждый момент времени все деревья, которые у нас будут, они будут сбалансированы.
Нет, на самом деле просто идея такая.
Нет, ну идея на самом деле в следующем.
То есть там просто идея будет в том, что если h от v равно h', то это означает, что size от v больше либо равен 2 в степени h'.
То есть если глубина под дерева 5, то там хотя бы 32 вершины до найдется.
Причем более, это первое такое.
А во-вторых, еще конечно есть очень важное такое свойство, что h от v всегда строго меньше, чем h от parent от v.
Ну это правда.
Ну вот.
Высота от v меньше, высота от v приятная.
Ну в общем, h от низ, глубина.
Ну h от глубина.
Глубина вершины меньше, чем глубина родителей?
Ну да.
Нет.
Да.
А у нас в определении h это максимальное расстояние до потомка.
Да, потомка.
Поэтому как бы, если у вас от вершины v есть расстояние до потомка 8, то от родителей есть расстояние как минимум 9.
Хитровое, хитровое.
Да, так что в другую сторону.
Вот.
А доказательство на самом деле проводится по индукции.
То есть там доказательство будет примерно следующее, что вот когда вы что-то подвешиваете, ну заметим следующее.
У вас два варианта.
То есть, ну у вас так, если вы подвесили вершину w, оказалось, что вот h от v.
Ну то есть смотрите, вот у нас, если мы подвешиваем w к v, и вот скажем h от v было больше, чем hw,
то тогда заметим, что тогда h вообще не поменяются.
А единственное, что поменяется, это size от v, и он увеличится.
Поэтому ничего не поменяется.
Но поменяется другое.
Вот, поменяется другое.
То есть давайте, то есть с другой стороны могло быть так, что rank v, он там оказался меньше, чем rank w.
Ну хорошо, h.
Ну действительно, смотрите.
То есть предположим, что h от v меньше h от w.
Тогда это означает, что у нас h от w переприсваивается в h от w плюс 1.
Логично, да?
Но с другой стороны, заметим следующее, что по предположению индукции, у нас здесь тогда получается было больше либо равно 2 в степени h от w вершины.
Но, как мы помним, size от w меньше либо равен size от v.
То есть это означает, что тут тоже как минимум 2 в степени h от w.
Но тогда получается, что в сумме будет хотя бы 2 в степени h от w плюс 1.
Так что вот таким образом и получается.
То есть на самом деле, если вы ботали доказательства ранговой евристики, то это практически оно.
Ну, например, вот так.
Ну, например, вот так.
Значит, это отчему?
Итак, смотрите.
То есть действительно, если у нас, вот мы рассматриваем вершин.
Допустим, если оказалось, что у нас rank h3, то у вас по дереве висят 2 в степени h3 вершин хотя бы.
И заметим, что rank их строго меньше.
Это означает маленькую приятную вещь.
То есть это означает, что ни одна вершина rank h3 не является предком или потомком какой-то другой вершины того же rank.
Ну, вот отсюда.
То есть у нас все так устроено, что когда вы приходите к родителю, rank строго увеличивается.
Ну, rank логично.
Да, мы это аж так определили.
Вот.
Но тогда это означает, что получается можно каждой вершине h3 поставить в соответствие своей 2 в степени h3 вершин.
То есть по дереве они пересекаются.
А это означает, что таких вершин высоты h3, их не более чем...
Сколько их там получается?
Не более чем n поделить на 2 в степени h3.
Ну, вот c равно 1, a равно 2. Пожалуйста.
То есть таким образом получается, что если вы всегда ухитрились устроить себе переподвешивание так, что вы всегда подвешиваете меньшее под дерево к большему, то тогда ваше дерево сбалансировано.
Вот. Ну, это вот такое вот.
А вот все это, что за структура данных? Это link и bound rate?
Нет, это пока... Ну, сейчас. Ну, вот эта структура да, но это пока базовая, потому что...
Так и называется.
Да, так и называется.
Вот.
Ну да. Сейчас. Не понял вопроса.
Ну, какая структура данных?
Ну...
Волюбная скорее.
Не-не-не. Ну, скорее... Не-не-не. Пока link и bound rate, это собственно не структура, это интерфейс, в общем-то.
Другой вопрос, как мы ее реализовываем.
То есть у нас есть теория о том, что мы ее реализовываем, просто делая сжатие путей.
Первая теория была о том, что если мы делаем только сжатие путей, то там каждая из m операции будет в среднем работать за... Вон там написано сколько.
Так вот. Но есть вторая теория. Предположим, что нам фантастически повезло, и деревья сбалансированы.
Так вот. Теория мистическая.
Чего?
Нет, у нас теория опять. За сколько у вас будет работать... За сколько вы сделаете m операции, если вам фантастически повезет, и деревья у вас в процессе сбалансированы.
То есть вот эта асцент была не сбалансирована?
Да.
Да. Ну как всегда, да.
Нет, snm это частный случай этого.
Сейчас мы в этом можем... В какой-то момент давайте сформулируем, что такое snm, и в этом увидимся.
Ну с минимум, правда, да, отдельное. Но в snm не нужен минимум.
По сути, да. Так вот. Нет, не доказали. Судя по всему, такие у нас...
Тарьян доказал?
Тарьян доказал, да.
Так, нет, ну да. Ну посмотрим по темпу, кстати. Я не уверен, что мы сегодня успеем ее подоказывать.
Вот. То есть возможно мы сегодня поговорим скорее о применениях этого, чтобы там...
Ладно, давайте... Так, ребята, давайте попробовать. Чему равно a от единицы запятая g?
Есть один случай a от 0.1. Это то же самое, что a от 0.2, то есть 4.
Так, a от 0.2. Так, хорошо.
Два в степени a от g.
Ну не знаю, это прямо нот. Так, а остальное что?
А остальное что?
А остальное ноль g. То есть ноль запятая a от предыдущего.
Так, давайте так. a от 1 g.
Два в степени предыдущее число.
Так, хорошо, да. То есть a от нуля, там, a от соответственно 1 g минус 1.
То есть в переводе говоря, это равно, ну фактически, ну начиная с какого-то момента действительно,
запустить это равно 2 в степени a от 1 g минус 1.
Вот, мясо, да.
То есть это... тут четыре даже удобную цепь в виде два в квадрате.
Так что тут будет два в степень 2.
Тут будет два в степени 2 Edinburgh.
Тут будет два в степени 2 Edinburgh.
Тут будет два в степень 2 Edinburgh.
и так далее. Так, ну давайте смотреть. Хорошо, что тут дальше? Так, а, ну да, а от и1 мы наконец
ну вот, а нет, так просто не получится. Здесь-то все просто, потому что в этом столце будет то же самое, что в этом, только сдвинута вот так.
Сразу можно два в степени, два в степени два написать. Нет. Дааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааааа
Тут будет то же самое, что тут. Да, но его мы еще не писали. Да, совершенно верно.
Так, ну давайте смотреть. Ну давайте смотреть. Значит пишем a от 2 g в адекватном случае. Это что такое?
Это a от 1 значит и соответственно a от 2 g минус 1. То есть что мы должны сделать с предыдущим числом?
Мы должны взять 2 и написать тут башенку в количестве равном этому предыдущему числу.
Да, то есть условно, да. То есть здесь я должен 2, то есть я здесь почти должен написать 2 в степени, ну что-то вроде, там вот так написать.
Два, два, пол, пол, пол, два в количестве, два в степени, два в степени, два.
Вот. Здесь, здесь я должен написать два в степени тоже два, два, пол, пол, пол, два, где эти двойки написаны в количестве два в степени, два, два, пол, пол, пол, два, в количестве два в степени, два в степени, два.
Нормально?
Два в предыдущем, все нормально.
В общем, и так далее, да? В общем, это быстра растущая функция, да?
Сейчас, а это всегда два в степени предыдущего числа? Нет. Что?
А, нет, почему? Там, нет, ну скажем так, a от единицы g в данном случае, это что такое? Это два в степени башенка из g2.
Окей.
Поэтому я здесь ровно это и пишу.
Потому что a от 2g это a от 1, то есть это нот. То есть это два в степени, а сколько тут нот.
Так что получается вот такая вот очень-очень-очень-очень-очень-очень быстра растущая функция, мне страшно даже писать, что будет дальше.
Вот. Поэтому да, не будем этого делать.
А теперь ведем обратную функцию, да.
Так вот, что такое альфа?
Обратная функция, все.
Обратная функция.
Почти надо ее обратно, да?
Да.
Нет, нет, нет, смотрите.
Нет, нет, сейчас напишу, не волнуйтесь.
В общем, альфа от, ну давайте, чтобы м и н не путать, я напишу x и г.
Значит, альфа от x и г это минимальное такое.
Какое и что?
Да, больше либо равно одного.
Такое что?
Значит, а от, значит, х.
Ну тут пишут, пишут почему-то примерно следующее, х.
И дальше получается такое округление, 2х поделить на y.
Так, а нет, набрал, набрал, набрал, набрал, набрал.
И это больше, чем лог 2 и как.
Да, к чему-то вот, да, в самой статье тут м и н написано, но кажется вот это немножко вот, есть м и н, а тут м плюс н.
И это надо не перепутать.
Ну я поэтому на всякий случай так написал.
Ну нет, просто вот это м поделить на н, это у нас как всегда важно будет.
Потому что, возможно, мы уже с этим стартились, у нас когда-то уже были логарифмы по вот этому основанию.
Не надо.
Уже было какая-то там у нас.
У нас там по-моему оптимальная, там dx с оптимальной кучей по-моему работал за какую-то вот такую симптомию.
Не надо.
Там м умножить на там, логарифм, логарифм в по основанию вот этого вот.
Как работал, так и не работает.
Вот.
Так, ну теперь остается только выяснить, да, что это.
Вот.
Но здесь, значит, тут честно сошлёмся.
Значит, утверждается, значит, для любого n меньше, чем 2 в 16 утверждается, что а от м плюс н, н равно 1.
А вообще на н?
Н мы в похрен.
Н в похрен, потому что м плюс н.
Ну что значит?
Ну м больше не правда нуля, хорошо.
Ну да, в смысле.
Альп уже зависит от x, а переданного?
Уже не зависит.
Зависит.
Если передать...
Ну начиная с какого-то момента не зависит.
Вот.
А нет, вот видите, n-то, видите, тут достаточно мелкие n просто.
Два в степени, два в степени.
Да, там соответственно.
То есть просто первая же ячейка в этой строке уже будет...
Нет, это...
Ну это альфа, да.
Начиная...
Сейчас.
Что?
Это же бред какой-то.
Почему бред?
Что такое?
Что такое агрессивное сегодня?
Первая...
Какое-то.
Да?
То есть если n равно 1, то у нас получается...
А, там лого-ритм ещё есть.
Лого-ритм.
Это 16.
А.
А.
Первая.
Ох.
О господи.
О-хо-хо-хо.
Что же это такое?
Ясно.
Давайте найдём функцию...
Ну вот, в этом месте да.
Тальян сам испугался там конкретно считать дальше.
И просто сказал...
For all feasible M&M, альфа is not more than two.
Так и написал.
Да, физиолог, типа хоть насколько-то адекватных вообще для нашей жизни,
но там есть...
Чем больше х, тем нам лучше, тем меньше и.
Да.
Ну да, то есть на самом деле это действительно такой парадокс.
Чем больше m, тем как бы быстрее в среднем эти операции работают.
Но заметим, что в общем-то это сегодня для нас не новость.
Потому что обратите внимание, у нас тут ставка на то, что сжатие путей без...
Даже без ранговых иллюмистик вообще тоже работает за какую-то ассинтотику,
которая бы тоже откровена чем больше m, тем лучше.
Обратите внимание.
То есть схлопывается то, что начинается с какого-то момента,
это вообще ввод единиц превращается.
С момента примерно какого?
Ну вообще там m это n степени 1,5 на самом деле.
Но это совсем слабенько.
Ну, ничего слабее.
В общем, m как бы, это как бы из n запросов, как бы теперь каждый делает за ввод единицы,
но это уже не слабенько.
Славенько это если бы мы писали m равно m квадрат.
Вот.
А тут на самом деле вот в этой ассинтотике вот там m степени 1.
Сильнее, чем ничего, но ладно.
Нет, ну окей.
Нет, я понимаю, что там можно, наверное, какую-то камевуху забабахать.
Ну а что?
Ну, это утверждение очевидное тогда получается.
Потому что n до 16, значит нужно выбрать a первое, что-то хотя бы равное 2, больше 16.
А у нас там a первое, а второе, а второе, а второе, и повесьте 16.
Ну, типа того.
Ну, типа того, типа того, да.
Узнание как бы несложное.
Ага.
Ну окей.
Ну, как бы да, тут можно, да.
Как бы можно тогда посчитать, можно в принципе просто в данном случае поверить в авторитет.
Да, не в нашем, конечно, это стиле, но.
Ну, мы можем.
Вот.
Ну ладно, в конце концов, честно скажу, я говорю, как уже все это становится понятно,
мы все равно все-таки доказывать не собираемся пока.
Ну, в следующий раз, я надеюсь, надеюсь, честно скажу, надеюсь, мы все-таки это докажем.
Это, это что?
Вот это.
Так, кстати, не теряем 1, не теряем 2, если что, для двух пришедших мы не доказывали еще.
Сейчас.
Это, это теряем 1, теряем 2, мы собираемся потом доказать.
Да.
Все хорошо.
То есть пока, да, то есть сегодня у нас занятие не о том,
сегодня у нас как бы занятие поговорить об собственно структуре EvalLink Update
и собственно, что с ней вообще можно сделать.
Вот.
Так.
Значит, смотрите.
Да, да, собственно, мы тут, да, постепенно приближаемся к перерыву, но давайте смотреть.
Вот, хорошо.
Вот у нас есть вот, пока не меряете теории.
Из точки зрения EvalLink Update, они говорят следующее.
Что, соответственно, если вы просто делаете, то есть если вы просто делаете тупо сжатие,
ну, это практически всегда можно тупо делать.
Вот.
Тогда у вас получится какая-то адекватная асимпдотика,
ну, там типа не превосходящая логарифм, там логарифм N на операцию,
ну, а чем больше M, тем на самом деле это среднее будет еще уменьшаться.
И в конце конца оно сойдется к единице.
Вот.
Но если вам удастся реализовать все таким образом,
чтобы у вас деревья были еще и сбалансированы,
да, то есть у вас там, ну, скажем,
количество вершин какого-то ранга там всегда не превосходило,
давайте, какого-нибудь адекватного числа.
Ну, вот.
Ну, тогда, ну, вот.
Сейчас.
Хотя интересно, не превосходит или не имеешь?
А то что-то я подумал, а бамбук, это сбалансированное дерево?
Ну, по-другому определение.
С HV хотя бы.
Чего?
Ну, с HV хотя бы, типа, ну, это просто.
Нет, ну, по-другому определение.
Ну, да так.
Нет, а что?
А, ну, хотя нет, бамбук, знаете, почему не подходит?
Там ранг слишком большой.
Ну, просто вот эта штука означает,
что H не может превосходить логарифма N по основанию A.
А в бамбуке есть ранг N.
То есть, поэтому такая определенная отсечечка тут все-таки на лицо.
Так что, да, тут вроде еще адекватно.
Вот.
Значит, теперь давайте смотреть.
Значит, к чему это все нас приводит, да.
То есть, если нам удастся как-то сделать.
Вот.
Ну, например.
Ну, самый классический, конечно, самый такой простой пример мог бы быть.
Это пример, в котором вообще не нужен апдейт.
Это пример собственная СНМа.
Вот давайте посмотрим, что может сделать СНМа.
Так, вот давайте это уберем.
Значит, смотрите.
Что?
Нет?
Нет, бывает, конечно, может быть, СНМ, которому еще нужно что-то прицепить.
Но давайте подумаем.
СНМ, вообще говоря.
Это он поддерживает что?
Технологии.
Инновации, да.
Ну, вот.
То есть, ДСУ.
То есть, говорим, что у нас тоже есть Ender Shift.
И они в каждый момент времени разделены на подмножество.
То есть, на какие-то подмножества, не пересекающиеся.
Вот.
И у нас есть там операции Find от В.
То есть, это найти представитель, да.
То есть, это найти представителя так называемого.
Ну, то есть, в каждой вершине, то есть, в каждом множестве есть так называемый представитель.
Вителя.
Множества.
Содержащего В.
Вот.
И Юнион.
От В и В.
То есть, объединить клетки множества с В и В.
Вот.
Множества.
С В и В.
То есть, по сути, вот СНМ.
По крайней мере, на уровне интерфейса требует вот этого вот.
Значит, теперь, если мы верим в Evil Link Update.
То есть, следующая идея.
То есть, давайте каждое множество хранить в виде, соответственно, подвешенного дерева.
Ну, достаточно произвольного.
Там как-то так оно может быть.
И самое главное, что и представителям мы будем объявлять корень.
Вот.
Сколько у нас тут?
Семь, да?
Ага.
Три, пять, допустим шесть, семь.
Ну, разное тут все может быть.
Ну, вот, я что-нибудь еще туда.
А тут вообще может быть тупое.
Вот.
И когда мы будем искать родителя, представителя, мы просто будем добегать до корня.
То есть, чтобы совсем это свести к Evil Link, чтобы это функция Evil.
То есть, как вы уже сказали, нам просто достаточно будет вести вот эту операцию такую, что A и B равно A.
И еще объявить, конечно, что label от каждой вершины будет равен, ну, я не знаю, самой этой вершине.
Вот.
Вот.
Да.
То есть, самое главное, самое приятное у нас в этой структуре то, что когда вы объединяете два множества, то кто там будет представитель, вы выбираете сами.
Самое главное в юнивере, чтобы в файне было, что как бы у двух вершин один одного и того же множества представитель находился один и тот же, а кто он конкретно, в общем-то, уже и не важно.
Вот.
То есть, замечаем тогда, что получается, что при таком хранении мы реально свели операцию к Evil Link Update.
Даже просто к Evil Link Update.
Вот.
Ну, тогда, значит, как же нам, то есть, тогда замечаем, что, то есть, тогда из этих теорем уже, заметьте, мы сейчас ничего не догадываем, просто смотрим на теоремы и замечаем, что если мы просто храним подвешенные деревья и применяем эвристику сжатия пути, то тогда вот эта теорема нам гарантирует, что мы уже за логарифум мы как-нибудь справимся, а если запросов много, то еще быстрее справимся.
Вот.
Ну, вторая теорема говорит, что если мы все-таки будем подвешивать деревья там не абы как, а так, чтобы деревья были сбалансированы, сбалансированы, то тогда оказывается, что вы тогда, действительно, в среднем каждая операция будет выполняться за обратную функцию герману.
А как нам это сделать?
Ну, по-разному, можно ввести, да, можно в явном виде вычислять рамги, хотя, хотя нам будет даже удобно не вводить даже не рамги, а честно вычислять сайзы.
Я не помню, почему это.
Нет, смотрите, ну, нет, вот, вот, давайте, давайте в каждом корде хранить, сколько, сколько.
Они растут очень быстро.
Сайзы?
Относительно.
Потому что за одно обгнение у вас высота не увеличится, чем там большая ничка.
Нет, с одной стороны, да, но сайзами просто приятнее то, что мы уже доказали, что там, если нам гарантируется, что мы там, если, что размер нас он как бы не более чем, что он там хотя бы в два раза меньше, чем размер родителя, а мы можем подвешивать так, чтобы это было, чтобы это было правда, то это дерево сбалансированы, мы это уже сегодня доказывали.
Нет, правда, то, что два раза не было, это было то, что у нас после гарантизации мы подвешиваем, когда мы подвешиваем к W к V, то у нас сайз, ну, не важно.
Ну, не важно.
Да, хорошо, тогда гаранти, ладно, тогда, ну, не важно, то есть, да.
Нет, я имею ввиду следующее, что.
Да, то, что сайз W и меньше сайза V.
Ну, это, это тоже, но да, но просто из этого автоматически следует, что в каждый момент времени у вас должно быть, что сайз от V меньше либо равен, чем сайз от parent от V.
Попало.
Ну, то есть, на самом деле, если мы будем всегда подвешивать меньше или больше, то это будет правда.
Логично, да?
Наверное.
Вот.
Ну, не важно, можно либо так, либо через ранги, но в общем убедиться в том, что действительно в этом случае можно показать, что тогда дерево является, любое дерево, все деревья, которые у нас образуются, является сбалансированными вот в этом смысле.
Вот, и тогда это автоматически означает, что вот обратная функция кермана воспринимается.
Ну, то есть, по сути, да, все, что мы сейчас сделали, это свели СНМ к Эволлинку.
Категорически приветствую.
Вот.
То есть, на самом деле, да, то есть, это вот, есть основная черная магия.
Вот.
Но, нот, ну, в этом месте, конечно, нельзя не поговорить о том, действительно, а что с этим СНМом, что сами по себе СНМом можно сделать, потому что в конце концов есть алгоритм Тарьяна оффлайн поиска ЛЦА.
Ну, а, конечно, да, немножко бессмысленно мы и так уже там это все за линию умеем искать.
Ну, вот, там за НПЛЦМ, но тем не менее.
Так, ну, кстати, так, не пришло ли нам время, о, по-моему, пришло время перевернуть.
Нет, вот, да, можно действительно подумать, действительно, что с этим можно сделать.
Ну, во-первых, непосредственно с СНМом, да, есть такой классический алгоритм, как искать ЛЦА оффлайн.
Да, сейчас он нам уже не поможет, потому что мы с вами ЛЦА уже умеем за вот единицы искать.
Да, потому что дерево, к сожалению, фиксируем.
Вот.
Антон.
Чего?
Держи.
Осторожно.
Вот, ну, просто, ну, вот, то есть, и так, вот снова у нас что-то представим в задаче, что дано дерево.
Так, что происходит?
Вмолим, вмолим, вмолим.
А, вмолим.
Ой, это да.
Будем повернуть.
Так вот.
То есть, и так представим, что у нас здесь задача, действительно, дано дерево, даны запросы, там каждый запрос две вершины, найдите ЛЦА.
Да, мы, конечно, с вами уже умеем эту задачу решать так, чтобы сделать предподсчет за ОАТН, а потом каждый запрос за ОАТ единицы.
Вот.
Но, конечно, нельзя такой, хотя бы для разминочки не обойти вниманием вопрос о том, называется, а нельзя ли как-то попроще, но при этом не сильно проиграть по ассимдотике.
Ну, потому что вот в этом смысле, с точки зрения Альфы, то есть Альфа, на самом деле, эта функция достаточно мелкая, как мы уже сказали, чаще всего это не более чем двух для, по крайней мере, обозримых каких-то, я думаю, которые нам могут реально встретиться.
Или можно даже еще по-другому.
На самом деле, еще есть такое мистическое утверждение, именно просто мистическое утверждение, сейчас доказывать не буду, если...
Но утверждение такое.
Почему-то там утверждается, что Альфа от НН это лог звездочка Н.
Прямо равно?
Вот кто-то утверждал такое.
Ну, давайте, ладно, для надежности скажем так.
Мне самому, конечно, так кажется, но вот кто-то утверждал такое, то ли Маврин, то ли Тариян.
Лог звездочка, это же вторая строчка.
Ну, сейчас, там не всем так можно рассуждать, но, короче...
А, нет, это... Что такое Альфа от НН?
Это первый столбец.
Так.
Мы не совсем разговаривали, что первым столбцем происходит, но вроде, наверное, что-то быстрее.
Нет, не совсем.
Сейчас, подожди.
Давай так.
По определению пишем А от НН.
Это минимальное И такое, что А от И, внимание, два, больше, чем логарифом два Н.
Кажется, второй столбец растет два Н.
Нет, второй столбец и первый столбец растут абсолютно одинаково.
Это одно и то же, потому что с точностью до...
Да, до И. Хорошо, да.
Вот этого вот сдвига.
Да.
Ну, вот.
То есть теперь, когда возникнет отдельная песня Шоэта, ну да, пока, конечно, похоже больше на...
И на что?
Ну да.
Нет, почему?
Нет, пока больше похоже действительно на то, что...
Ну вот.
Так, нет, ну да, лоб два Н.
Нет, тут просто проблема такая, что у нас действительно определенная пашенка.
Есть подозрение, что вряд ли тут будет в этом столбце что-то меньше, чем лоб два Н.
Да.
Есть?
Есть у нас такое подозрение?
Вот почему-то есть.
Вот.
Ну вот.
И тогда получается, что...
Да, поэтому лучше, наверное, написать петч или бараболок звездочка хотя бы.
И уже не заморачиваться.
Вот.
Вот.
Вот.
Вот.
Вот.
Значит, далее.
Ну а замечаем, что функция тут устроена так, что, соответственно, чем больше будет х, тем больше будет это число и, соответственно, чем и будет, на самом деле, даже меньше.
Что интересно.
Так.
Ну вот.
Ну ладно, значит, смотрите.
То есть раз такая хорошая симптомика.
К чему мы это все?
Значит, как же можно было бы искать лца за адекватно...
Вот хочется обработать m запросов за асимптотику вот m лцаша за m на вот эту же обратную функцию АК.
Но с маленькой оговоркой.
Мы это хотим сделать оффлайн.
То есть там сразу данные вот m запросов, мы для каждого из них должны найти ответ.
Но в каком порядке мы их будем искать, это глубоко наше личное дело.
Вот.
Ну как же это делать?
Кстати, в качестве соц. запроса.
А кто знает, кстати, как это делать?
Я понимаю, что соц. запроса примерно в этом районе.
А можно повторить, пожалуйста, что?
Оффлайн лца за вот такую асимптотику, если в конце.
То есть дано дерево и даны m запросов, заранее все данные.
Хочется для каждого запроса найти лца и сделать это за вот такую асимптотику.
Это статик.
Мы можем решить за вот единица, а вот единица это вот эта штука.
Да, мы умеем решать за вот единица, все, спасибо.
А вот единица это вот эта штука и все.
Ну давайте просто немножко поговорим на эту тему.
Значит, как же это делать?
Ну просто технология она может пригодится еще для непривианной задачи.
Поэтому обычно работаем мы по следующему принципу.
То есть вот у нас есть мистическое дерево.
Ну вот, мы в каждой вершине записываем с какими запросами она связана.
Вот с какими запросами она там связана.
То есть у каждой вершины там есть какой-то набор запросов и при этом каждый запрос связан только с двумя вершинами.
И мистическая идея заключается в следующем.
Значит, смотрите.
Мы заведем SNM и будем запускать DFS, целью которого будет объединить все вершины в под дерево.
То есть суть будет примерно следующая.
То есть мы запустим DFS, запускаем, запускаем и вот из этой вершины возвращаем множество из нее любимых.
А из этой вершины мы возвращаем множество уже из всех этих трех вершин.
Ну и так далее.
То есть в каждый момент времени в зависимости от того, до куда мы вот дошли.
Тут будет пум, пум, пум, потом пум, ну и так далее.
Значит, при чем тут LCA?
А вот при чем.
Самое важное, что мы будем делать в SNM.
Да, мы делаем SNM.
Но самое главное, в каждом множестве.
Ну например, в каждом корне этого множества.
Да, обратите внимание, корень множества может отличаться от корня под дерево.
Понимаете, да?
Ну почему он может отличаться?
Потому что, когда мы там захотим подвесить, скажем, множество из этой вершины к множеству, множество из этой вершины к множеству из этой вершины, то наверное мы скорее эту сюда подвесим, чем эту сюда.
Ну вот.
Тем не менее, ссылку на того, кто тут корни под деревом, мы хранить явно в виде мужа.
И тогда будет идея такая.
В этом всём процессе мы, когда приходим в вершину, ни в коем случае не забываем о запросах, которые с ней связаны.
И в каждом запросе мы храним, а сколько вершин из этого запроса мы уже помедали.
Вот, допустим, у нас есть запрос из двух вершин.
И вот, допустим, шёл ДФС и зашёл в какую-то из этих вершин.
В этом месте мы просто говорим, угу.
Просто тупо ставим галочку, что в этом запросе, осторожно, одна вершина уже была найдена.
Вот, понимаете, да?
Вот.
А теперь предполагаю, когда мы пришли во вторую вершину, то есть мы тоже там смотрим запрос, говорим, ой, это уже вторая вершина запроса.
То теперь я утверждаю, что мы, в принципе, за у от единицы можем прямо сейчас найти лца этих двух вершин.
Почему-то.
А вот почему.
Значит, смотрите.
Потому что вот предположим, что вот эта вершина была у, а эта вершина была w.
Да?
Вот первая мы галочку поставили в u, и тут w.
Это значит, что ДФС был устроен так.
Вот у нас есть корень, и мы дошли до вершины w.
Видите, да?
Вот.
Дошли до вершины w.
И, значит, где-то в общем случае, значит, и где-то тут у нас были какие-то, вот слева есть какие-то под деревья, и справа какие-то под деревья.
Чем отличаются под деревья слева, под деревья справа.
Ну, по традиции то, что слева это мы уже обошли, а то, что справа еще не обошли.
Ну, это мы так всегда рисуем, да?
Но самое главное, что где-то в этих под деревьях, где-то в этих под деревьях, вот.
Да, вот обратите внимание, да?
То есть сами вершины по нашему определению пока еще как бы не объединены вот с этими, да?
То есть это мы там, ну там, в зависимости от реализации.
Ну, пока мы как бы только в конце это будем делать.
Вот.
Но у нас действительно что мы имеем?
То есть у нас есть вот какие-то под деревья висящие.
И самое главное, на самой вершине w, в самом, тоже мы уже запустились от ее детей, и тоже тут все эти под деревья объединены.
И мы знаем, что вершина u висит где-то вот в одном из этих под деревьев.
Но я утверждаю, что LSI теперь найти очень просто.
Надо просто найти корень под дерево, это u, в котором она висит.
То есть с помощью SNM-ки мы это уже сделали.
Взять родителя этого корня, и этот родитель и будет вот Сашкой.
Все.
Ну, с оговоркой.
Если, конечно, не окажется, что вершина u просто лежала на этом пути.
Ну, подобные вещи.
Ну, тут два варианта.
Во-первых, подобные вещи мы с точки зрения теории так уже легко умеем проверять за вот единица.
А во-вторых, на самом деле можно просто поправить немножко реализацию.
То есть реализацию можно сделать так.
То есть реализация будет так, что когда мы находимся в вершине, мы говорим так, вот у меня есть множество из себя любимых.
И теперь говорим, запускаем DFS, вот запустились от ребеночка, вернули множество и объединились быстренько.
Потом пошли с соседнего ребеночка и с ним тоже объединились и так далее.
И тогда окажется, что тут на самом деле уже просто можно обратиться в корень этого поддерева и это и будет S&M.
То есть это, кстати, сработает и в том случае, когда u была потомком.
Так что вот получается вот такая идея.
Понятная идея?
То есть просто DFS и S&M еще.
Ну да, то есть, ну, да, DFS, S&M, который вот, который вершина объединяет со всеми ее потомками.
Вот.
Ну и для каждого запроса еще хранить сколько вершин мы в нем обошли.
И еще мы в S&M храним корень дерева, потому что мы не можем...
Да.
Да, и ваша оговорочка, что корень в S&M и корень под дерево, который в этом S&M хранится, это две большие разницы.
Поэтому в корне под дерево, то есть в корне дерева S&M, в корне дерева S&M мы храним, собственно, храним, собственно, кто там был реальным корнем под дерево.
То есть надо просто помнить, что это надо делать, потому что поддерживать вы это можете без труда, естественно.
Вот.
Ну, собственно, это одна.
То есть это теперь дает вам возможность подвешивать к меньшему дереву больше.
И, соответственно, гарантировать, что тогда, действительно, все там сжатия путей внутри у вас будут за такого красивого керма.
С точки зрения практики, на самом деле, не важно, кого за что подвешивает сжатие путей.
Делает так, что ощущение, что вы должны дымиться.
Э-э-э...
Ну, вот именно, что ощущение.
Ну, в смысле, существует одна задача на все вот это вот.
Вот это вот в раме олимпиадной практики.
Там действует восьмой запросов.
Два действует восьмой запросов.
И там еврестика рамков замедляет решение, а не ускоряет.
Ох ты, красиво.
Точно уверена, что это не в тестах дело.
Ну, я думаю, там тестами постарались.
Возможно, да.
Но тут надо уже смотреть.
Нет, ну, правда, нет, мечта, конечно, есть, но тут просто одна.
То есть, с точки зрения олимпиадной практики, как мы уже выяснили, там это альфа, все равно двойка.
Ну да.
Так что, в общем-то...
То есть, это...
Я не знаю, когда человечество дорастет до того момента, когда оно поймет, что это все-таки не константа.
То есть, он будет это ощущать на практике.
Ну, примерно никогда.
Возможно, да.
Ну, это называется оффлайн олца.
Это один из вот таких классических алгоритмов.
Но его, если мы верим в SNM, то можно реализовать.
Вот.
Но на самом деле...
Но это, заметим, что SNM реализуется с помощью просто эволинка и вообще без апдейтов.
А вот, например, если реализовать...
А вот на самом деле было бы круто реализовать эволинк апдейт, где быть равен минимуму.
Или максимуму.
Вот.
Но здесь, правда, вытекает маленькая проблема.
Мы там хотим получать минимум на пути до корни?
Да.
Ну, там, да.
Определение в самом начале точно и было, что мы хотим.
Да.
Ну, неважно.
Но в данном случае, да.
Но заметим, что если мы научимся делать минимум, да...
То...
То есть, научимся как-то минимум.
Но нам удастся, на самом деле, решать еще какие...
Ну, какие нам задачи тогда мы научимся решать.
Ну, как мы в прошлый раз выяснили, дерево доминаторов мы научимся вот такую симпатику делать.
Потому что, как вы помните, у нас алгоритм свелся к...
Там просто к...
Там некоторым просто количеством ОАТМ запросом, там, вот, чьи-то.
Там в них надо было минимумы искать.
Помните, да?
Вот.
Вот.
Правда, обратите внимание, что интересно, там тоже не было апдейтов.
Там, по факту, у каждой вершины мы определяем функцию.
И, собственно, когда она вообще появляется в игре, там у нее уже написано, к чему она равна.
И она равна навсегда.
Так, помните, было дело.
Да, у вас, конечно, чуть больше, чем на прошлой лекции, но все.
Чуть-чуть.
Вот.
Но дерево доминаторов это даже еще...
Ну, вот.
То есть это еще не единственный пример.
Потому что, на самом деле, есть еще такая нетривиальная задача.
Дан граф.
И дана стов.
Внимание, вопрос.
А это стов минимальный или нет?
Вау.
Вау.
Можно управлять, что любой лектор не гном.
Да.
Оно хотя бы...
Да.
То есть, действительно, основная идея, действительно, у нас есть...
Если вспомнить, вернуться немножко к теории миностолов,
ну, конечно, раз уж мы говорим, нельзя не упомянуть алгоритм.
Ну, во-первых, нельзя не упомянуть алгоритм краска, давайте сначала начнем.
Да?
А то мы...
А то мы такие дурачки.
Мы это, миностолов только примом умеем искать.
Да, зато, правда, крутым правдейчином с кучей фибоначи и атомик-сипом.
Да, фибоначи у кучи с огромной константом.
Ну, вот.
А потом с атомик-сипом.
А краскала мы не знаем.
Но краскала...
Ну, в данном случае, да.
Что предлагает алгоритм краскала, если так кратко сказать.
Он предлагает там использовать миностолов...
То есть использовать лему о безопасном ребре по принципу,
а давайте просто добавлять на столов минимальное ребро,
которое мы в общем можем добавить.
То есть просто вот, у нас в каждый момент времени есть какое-то поддерево,
даже не под дерево, а несколько там компонент,
некоторые вершины отдельно.
И давайте просто говорим, что,
давайте там найдем просто минимальное ребро,
которое вообще соединяет две разные компоненты
и говорим, вот давайте его добавим.
Ну, лемми о безопасном ребре,
о безопасном ребре она же теперь разреза удовлетворяет потому что можно
рассмотреть разрез вот например вот такой
ну не судим да то есть возможно вы сейчас может не помните что такое лемма о безопасном
ребре или погреб не это ладно ну вот но это как с минусом как ценност основу
который нам дает но сейчас погребет но я не то я просто тут сошел что мы говорим
эсэнэмэ то нельзя уже не упоминать об алгоритме краскала но то есть алгоритм да то
есть это сводится к чему то есть это сводится к то есть алгоритм краскала в этом
месте просто теперь предлагает так а давайте тупо отсортируем ребра по весу вот
возьмем отсортируем а потом прибежимся по отсортированному списку и будем прям
тыкать и будем там прям все добавлять то есть мы будем добавить пока же ребра
говорить так если мы его можем добавить во стоп то есть она там цикл не стянет то мы
его добавим вот это будет работать за сколько ну это будет работать за сортирую
вот так ссортировку от мрюбер плюс
плюс ну вот ну плюс ну плюс ну и здесь я утверждаю что это будет просто плюс м
плюс м в общем на на ну фактически на альфа от м плюс сэнэмэ
идея просто ну потому что все эти компоненты мы будем ходить тупо в
сэнэмэ ну тут по разному как вы помните на самом деле мы ухитрились там вообще была
помнится черная магия что когда мы когда у нас тут были целые числа мы вот по
моему вот эту вот часть вообще по моему научились о вот это делать если я правильно
было у нас было у нас от алексии ну правда а про там сортировки не было там не было
там не было краскала там был другой алгоритм какие-то дикие штуки типа давайте
строить меня стоп не не там не там другой метод был там был ограниченный прим в духе что давайте
там то есть там давайте возьмем вершину и будем делать прима но не до бесконечности а пока у
нас там не до количества вершин не станет что-то типа к но да то есть сначала фред монтарья мы
выяснили что он с кучей фибоначи имеет там а симптотику там типа называется какую-то
м лог звездочка n или даже там при достаточно больших м вообще просто золотые а потом
но но но но там обнаружилось просто все за счет того что кара но там сначала два сначала там
2 м поделить на n потом 2 в степени 2 м поделить на н потом 2 в степени 2 в степени 2 поделить на
н и так далее и там вот с кучей фибоначи складывается а потом выяснилось что есть атомик хип
который все доставания не делает не за логарифом а за логарифом поделить на логарифом логарифа и
выяснилось что там к можно вообще подогнать просто вот сделать там операцию что типа
первая кара было 2 в степени 2 м поделить на н а вторую уже не заморачиваем все и и обнаружило
что там обе там обе террации работают заряд поэтому оказывалось что если вы то есть
То есть, оказывалось, что там просто, если вы веса ребер умеете заранее посортировать и заменить на числа там, скажем, от 1 до n, то тогда оказывалось, что у вас называется просто линейный алгоритм построения дерева.
Так, ну это было из разряда, краткое содержание предыдущих серий.
Да, тем более что атомик хипа, к сожалению, так и не добили.
Ну и ладно, не буду сейчас рассказывать все перепитие атомик хипа.
Не надо, это флешбейки очень много.
Ну вот, это тоже было больно.
Так вот, тогда это было так.
В данном случае мы не паримся, в данном случае у нас просто оказывается, что узким местом оказывается сортировка ребер.
То есть, по большому счету все за сортировку ребер, а так мы в общем-то, в общем случае, мы целый чисел, даже вроде как за линию сортировать не умеем на самом деле.
Ну, если это целые бейбитные числа, вот эти вот в нашей рам-модели.
То есть, наука пока еще не умеет этого делать за линию.
То есть, она закроет там m log log m, она это сделает.
Вот, ну вроде пока не больше.
Тоже не плохо.
Чего?
Тоже не плохо.
На самом деле да.
Ну тут как всегда, потому что часто бывает, что ребра нам даются уже в каком-то отсортированном виде, поэтому если они отсортированы, то вот, пожалуйста.
Ну, отдельная песня, что, как я уже сказал, на самом деле с помощью софтхипа можно просто выкинуть эту сортировку и просто все сделать за эту асинтутику.
Типа, а n еще можно убить по той простой причине, что когда мы ищем м на 100, то m это как минимум n-1.
Вот.
Но это уже там отдельная песня, хотя надо бы ее тоже, наверное, петь, потому что мы зря софтхип изучали, что ли.
Вот.
А то я сейчас скажу, слета я даже не помню, а если у него другие применения у этого софтхипа.
Ну, как вас...
Вот.
Да, реально.
Близкие сортировки.
Да, но, значит, да.
Значит, хорошо, краскалы обсудили, да, тут все понятно.
Поговорили, значит, это было...
А теперь вернемся, значит, к задаче, что теперь у нас такая более быстрая задача.
То есть хотя бы для разминочки, то есть дан астов, скажите, пожалуйста, минимален ли он.
Да или нет.
Ну, и здесь тоже есть, честно скажем, не идеальность с точки зрения современной науки алгоритм.
Ну, хотя нет, ну вот.
Нет, ну, просто сейчас наш алгоритм будет работать за вот М на альфа.
Просто есть алгоритм, который за М плюс С работает.
Да, пока его оставят в стороне, совершенно верно.
Хотя там в вероятностных алгоритмах на него как минимум ссылка будет.
Вот.
Ну, а смотрите, просто к чему.
В чем устроен этот алгоритм?
В чем устроен этот алгоритм?
Ну, а смотрите, просто к чему.
В чем устроен этот алгоритм?
Потому что в миностолах есть мистическая теорема.
В вашем задании тоже есть.
Оно как бы есть.
Но там, да, но теорема звучит так, что астов является, вот рассмотрим, пусть у нас есть граф и в нем есть астов.
Так вот, астов является минимальным тогда и только тогда, когда любое ребро не из астова, значит, стягивает, соответственно, в этом астове цикл.
Ну, в общем, это не утверждение.
И при этом вес этого ребра оказывается больше либо равен веса любого из ребер.
То есть любого из ребер на этом стянутом цикле.
Ну, то есть, условно, если у него там вес, скажем, 12, то тут могут быть веса 8, могут быть 11, могут быть 0, может быть 3, может быть там минус 6.
Вот, но 13 быть не может.
Ну, сейчас, можно определить?
Формально определить.
Значит, формально так, каждое ребро не из астова стягивает в астове цикл.
Формальное определение таково, что если это ребро УВ, то стянутый цикл это путь в дереве от УДВ, ну, это единственный путь у такой есть.
К которому добавили ребро УВ.
Это вот формальное определение стянутого, то есть того, что ребро стягивает цикл.
Так вот, заметим, что необходимым условием, то есть для того, чтобы это был минимальный астов, является тот факт, что какое бы мы ребро вот это ни из астова не взяли, оно должно оказаться максимумом на стянутом астове цикле, правда?
Ну, действительно, если тут скажем...
Ну, действительно, если тут скажем...
Если где-нибудь вот тут оказалась соточка, то мы можем просто вытянуть эту соточку и добавить 12.
И астов от этого только уменьшится, правда?
Вот.
Так вот, но есть более...
Но это говорит о том, что это необходимые условия.
То есть необходимо, чтобы любое ребро было максимумом на стянутом цикле.
Но более сложное утверждение утверждает о том, что это и достаточно.
Что этого и достаточно.
То есть если вы вот так астов улучшить не можете, значит вы его не можете улучшить в принципе.
Вот.
То есть вот такая теорема есть.
И это, ну, теорема, если речь критерий.
И что нам этот критерий дает?
То есть теперь тогда получается, что, чтобы проверить является ли заданный астов минимальным,
нам просто нужно проверить, а не является ли, соответственно...
То есть для каждого ребра проверить, а является ли оно максимумом на стянутом цикле.
Понимаете, да?
Вот.
Но тогда идея, оказывается, такая.
Предположим, что мы умеем...
Значит, эту задачу мы сведем к...
Я так напишу.
evil link update с минимумом.
Ну, то есть операция уйти это минимум.
Предположим, что мы каким-то мистическим образом научились ее делать за альфа.
Хотя заметим, что по умолчанию, кстати, это не так просто.
Потому что, как можно легко будет убедиться, вы, когда будете подвешивать деревья, вы там не сможете сказать, что, ой, если мы вмешиваем большое к меньшему, давайте вмешиваем к меньшему к большему и скажем, что так и было.
Вот.
Там будет эта вообще отдельная заподробительная песня, как это делать будет.
Вот. Так, чтобы было хорошо.
Но если мы научимся это каким-то образом делать,
то тогда смотрите, что нас ждет.
Тогда я утверждаю, что алгоритм проверки будет работать просто аналогично алгоритму поиска ЛЦА оффлайне.
Ну, заметим, что нам для каждого ребра нужно проверить минимум на стянутом цикле, правда?
Вот. Согласны?
Согласны?
Да, нет, наверное.
Есть кто живой?
Да.
Вот.
Или пока все просто.
А аналогия?
А аналогия вот в чем.
Смотрите.
Рассмотрим, представим себе, что наш этот остов еще и подвешенный, да?
Ну, то есть просто подвесим?
Да.
Ну, просто подвесим, как всегда, за любую вершину.
Ну да.
Ну или там за 57.
57.
Чтобы напакостить авторам тестов.
Ну да.
А то знаете, как бывает, вы там, напишите там какие-нибудь хэши бабахвы, а мы поменяли модуль там миллиард семь на миллиард девять и получили окей.
Ну это какие-то авторы очень слабенькие.
Ну я их взял, нет?
Нет.
Ну это странно, если я автор пишу, они один модуль завалили, а другой нет.
Нужно, чтобы десять модулей писали.
Ага.
Ну, там это уже может ПТЛ, он там просто...
Обычно просто не принято так валить, потому что, как бы, вы всем, все модули в принятость.
Вы не завалите.
Поэтому, как бы, надо, потому что надо же, как бы, либо, либо валить все модули, либо валить, либо не валить ни один.
Ну ближайшие десять, а один не семь.
Вот.
Так вот.
Вот у нас есть миностов.
Что нам надо проверить?
Каждое ребро, которое не в миностове, оно у нас соединяет два, то есть вот соединяет две вершины.
Ну вот.
Ну вот.
И теперь замечаем, что такое стянутый цикл.
Тогда замечаем, что такое стянутый цикл.
Это мы от этой вершины, вот, если она соединяет У и В, мы, как бы, от У поднимаемся до С толца.
И потом спускаемся обратно.
Видите, да?
Ну вот.
Но тогда фактически, то есть логика будет, может быть, примерно, ну, почти такая же.
Ну, почти.
Потому что работать это будет так.
Ну, во-первых, мы можем за эту асимптотику найти для всех пар вершин лца.
И тогда сделать следующее.
То есть смотрите.
Когда мы запускаем DFS теперь, для каждой вершины, то есть наша цель, действительно, это дерево построить с помощью операции ЛИК.
То есть каждый раз, когда мы выходим из вершины, последнее, что мы делаем, это подвешиваем ее к ее родителям.
То есть у нас, когда, то есть получается, когда мы выходим вот из листа, то есть у нас возвращается вот это дерево, мы его подвешиваем вот сюда.
Потом подвешиваем и подвешиваем сюда.
Тут вот идем потом вот так и так далее.
То есть в каждый момент времени получается такие вот, то есть набор подвешенных деревьев.
И в совокупности у нас получится единое дерево, которое совпадает с исходным.
То есть обратите внимание, не путайте, это не виртуальное дерево, да, это реальное дерево.
Но, смотрите, фишка в том, что на этом дереве мы как бы не просто работаем на этом дереве, но еще мы на нем умеем делать функции eval с минимумом.
В данном случае максимум, да, можно минимум, можно максимум, да, это в данном случае одно и то же.
Ну, в смысле одно в другом слоится.
И тогда, ну вот, ну тогда идея такая, давайте скажем, что у каждой вершины будет вес равный, ну просто вес у ребра из нее в родителя.
Ну а если вершина корень, то, ну по-разному, можно сказать, что там, скажем, минус бесконечность, а можно там просто чуть аккуратнее реализовать и прицеплять детей к вершине до того, как вы там будете какие-то лцашки искать.
Вот, и тогда получается следующее, что когда вы, то есть идея такая, что вы теперь можете в каждой вершине, когда вы вот уже пришли, создали тут, подвесили, подвесили, подвесили.
То есть идея такая, что вы теперь можете в каждой вершине, когда вы вот уже пришли, создали тут, подвесили все дерево.
Теперь вы просто перебираете все запросы УВ, то есть все ребра УВ такие, что лца от УВ равно этой вершине.
И для каждого из них просто вызываете два эвала, эвал от У и эвал от В.
Эти эвалы выдадут вам максимальное ребро на этом пути и максимальное ребро на этом пути.
Ну и все, что вам остается, это проверить. Не окажется, верно ли, что эти все оба максимума окажутся меньше, либо равны вот этой вершине?
Нельзя в одном порядке. Нельзя за один ДФС это сделать.
Потому что множество деревьев будет в вершине В.
Но можно потом запустить ДФС в обратном порядке.
За первым проходом я утверждаю, что можно будет только в вершине У это сделать.
Ну, в принципе, я не утверждал, что я бы будет делать это за один ДФС.
Вы сказали, что нужно будет вызвать эвал от двух вершин, а это как бы один в одном проходе, другой во втором проходе.
Мы же сказали, что мы сначала от Сашки, а потом...
Да, мы сначала запускаем один ДФС и ищем все у Сашки.
И тогда мы не только нашли в ЛЦАшке, только для каждой вершины записали все эти ребра, то есть пары вершин, у которых ЛЦА равно ей.
И тогда во втором ДФСе мы проделаем то, что я сказал.
У нас во времени ДФСа должен быть шаг, на котором есть дерево, соединяющее нашу вершину ровно с этим корнем.
Да, будет.
На выходе ДФСа из вершины у нас как бы есть это дерево, так что все есть.
И тогда получается, что пока проверять какой-то остов мы умеем залог такую классную семдуть.
Неплохо так, правда?
У нас здесь при линке нужно линковать только один корень одного дерева к другому корню другого дерева.
Мы вообще ничего больше не будем делать.
Мы всегда только корень корня.
Нет, у нас в определение вал Винкоптейта, кстати, входит, что мы подвешиваем только корень корня.
Это важно.
Нет, если мы подвешиваем что угодно к чему угодно, это линкат.
Но нет, даже если только корень к чему угодно.
Ну...
Тем более, что в линкате мы умели переподвешивать вершину дерева с другого.
Да, но линкат это лазарис.
А мы тут ставим чуть более компактный.
Так, сколько у нас на времени?
Вот.
Но смотрите, это все.
То есть мы заметим, что мы полностью задачу пока не решили.
Мы ее свели.
Мы ее свели.
Мы ее свели.
Ну...
Мы ее свели к вал Винкоптейту.
Мы ее свели к вал в Винкоптейт, где идь должен быть равен минимуму или максимуму.
Ну...
К сожалению, у этого черного ящика есть один изъян.
Изъян заключается в том, что均 произвольную операцию довести до альфа, он не обещает.
Ну...
Произвольную ассоциативную операцию.
ассоциативную операцию. То есть сделать компрессы, конечно, это пожалуйста, то есть первое, сделать вот так, чтобы все запросы работали за сток, это пожалуйста, это сколько угодно.
То есть вот за такой нот. Но если же балансированность не гарантируется, то и со второй теремой напрямую.
Но с другой стороны заметим, что как тут можно было реализовать Валлинг кавдей?
То есть как вы уже поняли, если мы будем реализовывать в тупую, используя только сжатие путей, то Альфу не обещают будет токовый гаив.
Но возникает вопрос. Нельзя ли как-то конкретно в случае минимума или максимума, чуть-чуть подмодифицировать структуру данного,
так чтобы она сводилась с Валлинг кавдей на сбалансированных теремиях и, как следствие, работала за нужную ситуацию.
То есть вот такой вопрос нас будет интересовать. Так, понятно, о чем я вообще предвидительно говорил?
Ну а дальше давайте попробуем. Но для разминочки мы попробуем немножко другое.
Вот, значит смотрите. То есть для разминочки мы попробуем поиграться вовсю.
То есть наша цель, предположим, что рассмотрим операцию ить какого-нибудь специального вида
и попробуем для этого специального вида сделать более хитрый Валлинг кавдей, так чтобы деревья в нем были сбалансированы.
Вот, например, представим себе, вот давайте себе представим для разминочки, что, например, ить это не просто дает полугруппу, она дает группу.
На самом деле даже более слабое условие сказать, что на самом деле для каждого элемента есть так называемый правый обратный.
Вот, смотрите. Вводим абстракционизм. То есть мы забываем о минимумах и максимумах. Чуть позже мы к ним обязательно вернемся.
Итак, смотри. Итак, представим себе, что у нас, допустим, оказывается верно, что для любого х, действительно там существует, то есть для любого х существует так называемый х-1.
Что это такое? То есть это означает, что для любого у верно, что ух, вот этот х-1 равен у.
То есть вот давайте представим себе, что мы живем вот в полугруппе С и у и выяснилось, что в этой полугруппе для каждого элемента существует правый обратный.
Правый обратный не совсем. Ну это не совсем правый обратный. А правый обратный, когда он существует, ну типа говорит, что это такой нейтральный элемент?
Ну, можно говорить так. А можно не вводить понятие обратный элемент, то есть этот нейтральный элемент, а можно ввести вот это.
Ну да, может быть, ну это просто примеры этой операции здесь группы, например.
Ну в данном случае, то есть сюда подходит, скажем, если там, скажем, С это какие-нибудь числа, а вот эта штука это, скажем, их сумма.
Или там какие-нибудь остатки, не нулевые остатки по модуле еще могут подойти. Ну с произведением, конечно.
Ну слета не скажу.
Вот. Ну а давайте предположим, что вот мы не будем сейчас заморачиваться определением группы, а будем просто говорить, что у нас вот есть вот такое условие.
Прямо то, что минимум акции на такое условие не удовлетворяют.
Не удовлетворяют. Да, не удовлетворяют. Но я, собственно, этот случай рассматриваю скорее как разминочку, чтобы просто вот ощутить, собственно, в какую сторону мы мысли.
Да, это минимум акции, ну вот. Но тем более, что здесь конкретно решение простое. Значит, что мы вообще хотим?
Мы говорим, что вот у нас, то есть мы хотим делать как-то линки, да? Вот V и W, да? Вот у нас есть.
И допустим, нам вызывается операция линк от W.
И оказывается, что вот и В должно оказаться родителем W. Вот так.
Но при этом, заметим, что если мы будем реализовывать по принципу, просто не заморачиваемся и просто подвешиваем, как подвешиваем и делаем сжатие путей, то никакая альфа нам не светит.
Потому что можно привести такие примеры линков, чтобы дерево было не сбалансировано.
Иди в пост там, где, я не знаю, у нас есть вершинка, один потомок с одной стороны, с другой стороны, помнишь, где его дальше?
Ну все шоу будет, да.
Да, господи, ну тупой пример. Тупой пример – бамбук.
Ну и бамбук не построен.
На линках построен.
Линки устроены, могут быть устроены так, что это может оказаться и бамбук.
Нам что-нибудь конкретно надо было.
Линки-то не от нас зависит, к сожалению.
Но нас может быть бамбук, но только после первого же где-то сожмется.
То есть бамбук, как контртестка времени работы ДСУ или еще где-то из одной структуры, не работает?
Ну не совсем сожмется, понимаете.
Скажем так, если с конца будете его запускать, то одно дело, если где-то из середины, то там же будет он.
Ну не совсем.
И будут промежуточные.
Посмотри, совсем у бамбука еще всякие вопросы были, что Джим был бамбук.
Ты, допустим, захотел сжать вот отсюда-сюда, да?
У тебя там получилось что? У тебя там получилось вот это и вот это, да?
И дальше там все равно.
Когда ты эту вершину начнешь там даже куда-то вешать.
Вот если куда-то вешать, это уже не бамбук.
Ну, скажем так.
Смотри, тут не надо путать реальное дерево и виртуальное дерево.
Да, виртуальное дерево, конечно, никогда не бамбук, но я имею в виду, что...
Но тут имеется в виду, давайте уточним, раз об этом зашла веки, что когда мы тут говорим о теореме 2, нам требуется, чтобы реальное дерево с точки зрения линков было сбалансировано.
Именно реальное.
Если такое гарантируется, то тогда мы с ним бы там тупо сжатие путей дает вот эту осень.
Вот.
То есть наша цель, то есть как бы подмодифицировать внутри структуру так, чтобы она сводилась там каким-то подвешенным деревьем, в котором мы тоже делаем Эмалвин Камптейт, но чтобы деревья были сбалансированы.
То есть поэтому внутри себя мы вот вместо этого дерева хотим хранить кое-что еще.
То есть какое-то вот немножко другое дерево.
Какое?
Какое?
Ну в данном случае идея будет очень проста.
Смотрите.
У каждой вершины, в каждой вершине тут хранится лейбл от V, да?
И лейбл от W.
Хранится.
Ну помним, да, в каждой вершине у нас меточка хранится, помните?
Ну то самое число, то есть то самое число, что когда мы там запускаем эвал, мы там прибегаемся от корня до вершины и ичкаем.
Да, напоминаю, что, кстати, что ичку выполняем именно от корня к вершине.
Вот, кстати.
Так вот, значит, что мы тут хотим делать?
Смотрите, немножко магии.
На самом деле, заметим, что нам, в общем-то, достаточно по барабану, что мы будем хранить внутри.
Самое главное, чтобы ответы были правильные.
Поэтому давайте поддерживать вот такой вариант.
Ну, значит, наше внутреннее дерево, значит, без компрессов, да?
То есть мы в нем, вот, помните, вот у нас были три аксиома, да, что мы с ним делаем, да?
Так вот, у нас будут только первая и третья, но без второго.
То есть так же.
Если вспомнить, что это все значило, то значило это следующее.
Что у нас, мы вместо каждого дерева будем хранить какое-то альтернативное дерево, которое все равно, который содержит те же вершины.
И результат эвалов от этого дерева виртуального и от того, что он уже материалит, будет тоже.
Но мы откажемся от требования, что корень совпадает.
Вот, понимаете, да?
Ну, в общем-то, давайте смотреть.
Что нам это дает?
То есть это нам дает следующее.
Значит, вместо вершин V и W, да?
На самом деле нам теперь даны два дерева, корни, то есть корни, из которых в нашем виртуальном дереве в реальности это, скажем, условный V' и W'.
То есть это могут быть прям где-то другие корни.
Ну, вершина V может тут лежать где-то в поддереве.
Вот, понимаете, да?
Мы сейчас доказываем, что если у нас операция дополнительно обратимая, то мы всегда можем сбалансировать лес.
Точнее так, допилить структуру так, чтобы лес получался сбалансировать.
Но цель у нас будет очень простая.
Когда нам надо объединить два поддерева, нам нужно подвесить меньше к большему.
Ну, мы уже доказали, что если подвесим меньше к большему, то дерево будет сбалансировать.
Но как же это сделать?
Значит, корни теперь принципиально другие.
Ну, в общем, кто они конкретно, кстати, можно вызвать компресс от V' и W', это явно не делается.
Вот. Так вот.
Ну, теперь идея такая.
Итак, мы хотим вот это дерево подвесить сюда.
Ну, как вы понимаете, да, причем мы точно знаем, что значение эвалов для вот этих вершин или этих вершин, оно то, что нам надо.
Вот, понимаете, да?
Вот.
Ну, значит, теперь давайте думать.
Что тут можно сделать?
Ну, во-первых, если нам потребовалось, если это дерево оказалось меньше, чем вот это по размеру, то, в общем-то, можно не заморачиваться.
То есть мы просто подвешиваем вот это дерево к этому и говорим, что на этом все.
Непонятно.
Мы хотим...
У нас есть V' и W'.
И мы хотим их подвесить друг другу в реальном дереве.
Ну да.
А в виртуальном дереве они являются корнями?
Не являются.
Но мы хотим сделать так, чтобы ответы на вершины были все равно те же самые.
Почему они будут те же сами?
Подождите, это же завершение значек и вариантов.
Мы же требовали, что у нас даже конец.
А теперь не совпадает.
Как мы на это запили?
Вот, почему, если в левом дереве все евалы сходят, в правом дереве все евалы, не смотря на их, какие надо, то если мы подвесим не вершину W' а W' W', почему у нас будут все евалы сохраняться?
Так.
Ну вот.
На самом деле, действительно вопрос.
Да.
И все так просто.
Даже если мы поймем, что мы просто имеем право сделать вот такое подвешивание и не заморачиваться с точки зрения сайза.
Но проблема в том, что как от того, что мы сделаем вот это подвешивание, изменятся сайзы?
Сайзы отлично изменятся.
Да, сайзы все нормально.
А как изменятся евалы?
Ну, у этих вершин не изменятся от слова никак.
А у этих вершин, они все домножатся на W'.
А должны были домножиться на W'.
Да, а хотелось бы на label of W'.
Ну вот.
Ну теперь вот, нот.
Ну вот, возникает вопрос, действительно, что бы тут можно было сделать?
Можно бы вторую штриху себе подвести, наверное.
Да.
Ну действительно, заметим, что приятно, мы действительно можем на label of W'.
Можем за вот единицы влиять, правда?
Конечно.
Вот.
Ну вот.
Ну а теперь остается только понять, как же нам конкретно повлиять.
А у нас W' и W'.
Это...
А, то есть мы вызвали где-то W и где-то W.
Ну да.
Да.
То есть заметим, что если бы это была, например, идеальная группа.
Идеальная прям вообще, да?
Ну я не знаю, что такое понять идеальная группа.
Ну в смысле, это реально группа, в которой что-ли там элемент там обрати, причем как справа, так и слева.
И там даже существование нейтрального элемента.
То тогда можно было бы сделать примерно следующее.
То есть вместо label of W'.
Мы бы написали бы что-нибудь в духе label of W' в минус 1.
И label of W'.
И label of W'.
И label того, что там было.
То есть вот такой неожиданный чит.
То есть вот такой вот неожиданный чит.
Ну и все отлично это, и просят только правое и обратное.
Да, если бы.
Почему нет?
Потому что я боюсь, что это нам потребует скорее левое и обратное.
Потому что теперь для любой вершины отсюда.
То есть у нас было вот что-то такое, а теперь оно домножилось в итоге.
То есть путь любой вершины доходит до W'.
И потом идет W'.
И тогда получается, что мы должны вычислить такую величину, как label of W'.
И вычислить такую величину, как label of W'.
И label of W' в минус 1.
Значит label of W'.
На label of W'.
Ну и так далее.
Ну да.
Отлично.
Ну как отлично.
Если сказать, что вот эта вот штука равна label of W', то конечно да.
Да.
Только маленькая проблема. У нас тут в ксиоматике немножко другое прописано.
Но это же не отменяет правости и ветости обратно.
У нас в ксиоматике странная штука написана без нейтрального варианта.
Угу.
Ну вот я бы утверждал, что можно это сделать именно вот в таком более сильном виде.
Можно как-то доказать.
Почему не можно Y справа написать вместо Y слева?
И сказать, что у нас есть минус 1 на Y, это то же самое, что Y.
Я не знаю может.
Сейчас.
У меня даже пример такого.
Нет, ну да. Вот в итоге хочется конечно написать слева, но...
Как бы...
Следует ли из правой обратимости левой обратимость?
Это не правая и левая обратимость же.
Это мы еще и для любого Y зачем-то написали.
Ну да.
Нет, ну как бы, мы говорили, что для любого Y существует вот такой элемент.
На что там слева не домножай, будет вот такое счастье.
Правда, заметим, что из этого следует вообще...
Ну теперь давайте думать, насколько это принципиально правая и левая.
Ну начнем с того, кстати, что из этого...
Из этой штуки, кстати, существование нейтрального элемента хотя бы справа следует.
Ну, просто рассмотрим вот это вообще.
Аксиомы нет.
Но рассмотрим какой-нибудь элемент X и его напарника.
Их произведение равно какому-то мистической штуке, назовем ее Y.
И теперь заметим, что у нас есть интересное утверждение, что...
Для любого игрока верно, что Y умножить на E равен Y.
То есть, по крайней мере, правый и нейтральный элемент на лицо.
Ну вот.
Теперь возникает вопрос.
Следует ли из этого, что в данном случае и вот это E умножить на Y тоже будет равно Y?
Нет.
Вот да, вот тут и проблема.
Само по себе вроде как и не следует.
Вот.
Почему-то.
Единственное только, конечно, мы ответим, что если для любого элемента, то...
Как бы скорее, то как бы нейтральный элемент у нас полнится всегда один.
Где?
А, хотя нет.
А, если он только справой, хотя...
Правых и нейтральных может быть больше.
Да, чисто правых.
Ну получается так вот.
Интересная интеракция.
Интересно, но как бы вот.
Интересно, а почему тогда...
Почему Тарьян тут утверждает, когда это пишет вот?
Именно в виде правого обратного, а не левого.
А можно повторить, что мы еще раз слайва сделали?
Или пока еще мы пытаемся это сделать?
Нет, вроде все, что хотели, сделали.
Мы вообще думаем о том, какую сторону что обратим.
Надо?
Виртуально.
Для которых все явалы были корректными.
То есть, отчего бы ты не вызвал явал, он бы дал такое же значение, как будто ты в реальном дереве.
И выяснили, что тогда, если нам нужно подвесить в реальном дереве вершину w к вершине v,
и нам повезло, что размер w штрих меньше, чем размер w,
меньше размер v штрих,
то можем просто подвесить и изменить один лейбл.
Вот на это вот число.
Синим цветом, да?
Да, синим цветом.
Мы в реальном дереве подвешиваем w и qv, а в виртуальном w штрих и qv штрих, и меняем один лейбл.
И утверждаем, что после этого все явалы тоже будут корректными.
Ну, то идите там.
Пока утверждение такое, если мы верим в обратимый дават не только справа, но и слева,
то в общем-то все в порядке сразу.
Ну, понятно, что эти штуки сокращаются и остается, собственно, то, что нам надо.
Только утверждать, что...
Может, я хотел снизу вверх вычислять, а снизу вверх вниз?
Тут и проблема идет точно сверху вниз.
Вот прям железно.
Вот прям я железно, собственно, и копал.
Вот.
Ну, я не знаю, может быть...
Может быть, конечно, просто это...
Все кроме нас с вами знают, что это называется непринципиально, потому что...
Знаете, в чем парадокс будет?
Если мы потом это под дерево еще к чему-то подвесим,
то к чему-то подвесим, то утверждение будет верным.
То есть, как бы, смотрите, мы не можем гарантировать, что вот эта штука равна чему-то надо,
но если тут будет что-то еще, то это будет правда.
Остается только доказать, что...
Просто можно доказать, что тут какой-то существует лево-нейтральный элемент.
И справа обретимости.
Тоже верно-право.
Ну вот, вот...
Если у нас хотя бы маной, то вроде все пошло.
Ну да.
Ну, в общем, конечно, да.
Но это очень странный, действительно, момент.
Почему мы это все делали?
Ну вот, пока вы просто понимали, что можно делать.
Пока это заметим, мы еще не стали...
Пока еще это мы еще предполагаем, что нам повезло,
и это дерево меньше, чем это.
Ну на самом деле, смотрите, основная идея такая, что...
Ладно, давайте без правых оборотов, давайте просто скажем,
что у нас есть обороты в разные стороны.
То есть, есть и такой оборот, и...
И, допустим, одновременно еще и, скажем, вот такой.
Ну то есть, действительно, ладно, пусть есть нейтральный элемент, короче, это группа.
Маной.
Да, достаточно там, что маной.
Ну...
Нет, ну...
Не-не-не, нам принципиально существование обратного.
Так что групповый.
Так вот, а теперь давайте подчеркнем вот же.
Какой тут хак можно сделать?
Какой тут хак можно сделать?
Если оказалось...
То есть, если оказалось, что вам требуется подвесить вот это дерево к этому,
но очень не хочется.
Че?
А я предел еще.
А не хочется по той простой причине, что это дерево больше, чем это.
Ну уже.
Тогда предлагается...
Тогда вот, предположим, если оказалось, что, так сказать,
size от W' оказался неожиданно меньше, чем size от W'.
Вот.
Но тем не менее, а подвешивать хочется.
Но оказывается, что можно неожиданным образом выкрутиться.
И выкрутиться можно следующим образом.
Смотрите.
То есть, мы все-таки подвешиваем вершину W'.
Но теперь что...
Но как теперь нам поменять...
Как теперь нам поменять лейблы?
Секунду.
Мы же просили другое.
Нас просили подвесить W' к УКВ.
Да.
А мы заявляем, что...
Нас просили подвесить W' к УКВ, вот так.
Правильно.
Так мы мало того, что сказали, что у нас тут другие корни.
Так еще и сказали, что, ой, а знаете, я все равно хочу подвесить W' к W'.
Ага.
Но я же должен сделать вид, что у меня все в порядке, да?
Да.
И значит, что тогда должно произойти с этим под деревом?
Значит, смотрите.
То есть, у нас были тут, значит, допустим, меточки.
Была тут метка L' и была тут метка L''.
Да?
Лейбл?
Да.
А теперь я хочу, значит, подменить в этих корнях тоже меточки.
На, так сказать...
Хочется написать L' от W'.
Нет.
Не надо, да?
Давайте.
Вот, подменить так.
Вот.
Вот.
Значит, подменить.
Но теперь смотрите.
А теперь давайте, как они должны поменяться?
Заметим, что...
Значит, эвал...
Вот, допустим, у меня есть тут вершина X и тут вершина Y.
То и тут будет вершина X, вершина Y.
И мы говорим, что эвал X должен теперь перейти во что?
А не во что.
Он поменяться не должен.
Ну, вот так вот.
Ну, потому что, реально, когда мы вот это под деревом подвесим к этому,
то есть, для висящих на вершине V вершин,
результаты эвалы не должны поменяться от слова «никак».
На коку мы согласились уже, да?
Нет, то есть...
Ну, не знаю, по-моему, реальное дерево, по-моему...
Это все равно не работает на комплотивности.
А нам не нужна.
Ну, в том смысле, у тебя порядок определенный есть.
Если меняешь порядок установки L, V...
Да, напоминаю.
А эвал, напоминаю, от игрока...
Правильно.
Должен стать...
Должен стать теперь...
L, V.
Причем именно L, V, обратите внимание.
L, V, L, V, да?
Умножить на эвал от игрока.
Значит, ну, чтоб понять...
То есть давайте вообразим себе реальное дерево.
Потому что в реальном дереве как бы все по тесноку, да?
Есть вершина X, на ней что-то висит, то есть есть вершина V,
на ней что-то висит, да?
Да, в том числе и X где-то там висит.
Есть вершина W.
И на ней что-то висит.
Исключительно что-то исключительно висит.
В том числе и где-то E.
и мы хотим добавить вот это ребро
тогда получается у всего вот этого поддерева все эвалы должны
увеличить там домножиться слева на lv
а тут они не должны домножаться от слова ни на что
ну тогда пойдем как изменять как бы лейбл в наших кругах
если это возможно
если это группа, то возможно
не, ну идея очень простая
понятно, что для того чтобы у нас в w штрихе все поменялось
то есть в этом поддереве игребки поменялось
то очевидно имеет смысл сделать r в штрих
равно просто lv умножить
на соответственно то что там было раньше
а, ну да
тогда с этим диремием все в порядке
а почему r это новое в смысле лейблы
чего?
р мы обозначили новое лейблы
ну вот
а тут теперь надо, а теперь заметим следующее
что у нас тут произошло
эвол х теперь тогда
сейчас давайте я скажу
жил был эвол х
но если мы так подвесили
то все эти эволы по умолчанию домножаются
домножаются на rw штрих
и нам его надо нейтрализовать
тогда я предлагаю нейтрализовать его простым дедовским способом
то есть нам надо чтобы
рw штрих в минус 1
на то что там было раньше
то есть тогда заметим, что когда
у всех этих вершин будет домножаться на r
и в общем-то радостно нейтрализуется
ну а у этих товарищей вроде все в порядке
то есть получается, что в некоторых случаях
например когда у нас операция обратима
то есть обратима
ну просто давайте скажем
то обратима в обе стороны
с нейтральным элементом
то тогда у нас никаких проблем нет
ну думаю, так сколько у нас там времени?
45 даже надо закончить
ну да
ну ладно
ну ладно
у Тарьяна тут есть такое
чуть более сложное в этом смысле мероприятие
то есть он утверждает, что достаточно только
там есть такие условия
что элемент должен быть либо вот таким
именно вот с правым обратным
либо право обратимым
либо он должен быть правым нулем
ну там еще было дополнительно
там написано что-то там типа
то есть это такой
то есть x еще может быть правым нулем
ну типа для любого y там верно
y и x равно x
ну там в этом месте там что-то выяснялось
что в этом месте выяснялось
что в общем-то если это оказалось правым нулем
ну вот
то есть там где-то
значит вообще все неважно
ну да
а или наоборот
хотя тут может быть наоборот
только надо x и t
ну помните пожалуйста
почему все это разлирование делали?
нет это мы
пока мы это делаем для того чтобы хотя бы примерно понимать
то есть как все-таки уметь балансировать деревья
если например у нас сумма на пути
сумма на пути там или произведение там
каких-нибудь по какой-нибудь модулю
простому не нулевых остатков
ну и так далее и тому подобное
суммы уже проблем нет
ну как сказать
ну проблем нет
ну теперь вот проблем нет
вот именно теперь проблем нет
ну минимум конечно это все не решает
то есть минимум это вот просто
то есть это просто чтобы немножко войти
понять что мы хотим добиться того
что мы хотим подвешивать не только то
то есть хотим подвешивать иногда
не то что надо к чему надо
иногда наоборот
но при этом все равно выкрутиться так что все хорошо
Жанна самое страшное я вам скажу
мы еще не все проблемы тут решили
потому что хорошо мы научились сделать линк
но вообще-то еще есть операция апдейт
ну в целом понятно как сделать апдейт
хотя в общем-то
ну да
хотя в общем-то никаких проблем нет
на самом деле с апдейтом
а это не важно
на самом деле с нашей точки зрения
это просто дало по дереву сделать так
что все эвалы слева доложились
да он обновляет корень это важно
корень не важно виртуальный корень
единственное тут упоминается маленький технический момент
что вам этот корень придется найти
то есть вам в запрос там
вам передают реальный корень
а у вас там он
нет а у вас там в виртуальном дереве
корень другой
да совершенно верно да именно
именно это да делаем компресс
родителя родитель корень
невероятно
да как бы классик поразительный
я не могу в это поверить
я смотрю на это 5 часов
но
сейчас тут просто еще будет страшное шоу
куда уже страшнее
это ну помилуйте
а теперь что делать если у вас максимум
потому что максимум к сожалению
не обратили
хотя есть вообще для любой операции
не не не
и не мечтайте
такого наука не умеет
а максимум каким
ну коммутативность
он коммутативен
да идем патентом
там это не поможет
а что там поможет
а вот сейчас увидите
а там прям минимум
поможет короче
там прям максимум
короче функция очень
делаем максимум
если не успеем придется в следующий раз продолжать
но ничего страшного
максимум
значит смотрите
давайте вообще себе
представим
как выглядит вот представим себе
реальное дерево это реальное дерево
вообще не виртуальное да
сейчас будет реальное дерево
да
а
это умный кокон
да
это как дайте
смерть какая то
при слове реально обычно там возникают пацаны где то
да
оман
то есть если мы
рассмотрим реальное дерево
и у меня тут написан
допустим петачок
это означает
я могу гарантировать что тогда
эвал от любой вершины в этом дереве
не менее чем 5 правда
но можно заметить
что более того
для некоторых вершин
он даже будет
равен петачку
чтобы их найти
надо просто запустить dfs
по всем вершинам которые не происходят пяти
правда
но может тут вот найти какая нибудь вершина
если тут написано например 7
максим
я вот прописал
еще максим
если вершины 7 это не позиция это лейбл
это не композиция
что не композиция
он разбивает
тогда замечаем
что а теперь заметим
что если тут написан 7
то в некотором смысле
можно это дерево
на самом деле мысленно отпилить
ну по крайней мере отпереть
потому что заметим что тут дальше
все вершины все равно меньше чем 7
поэтому как бы дошли до сюда
и остановились
то есть либо 7 и подвесимся
пока мы почему-то не подвесимся
ну конечно да не только
еще может быть апдейт
то есть смотрите апдейт превращается
в максимум
поэтому мы тут петачок можем заменить на 57
мы можем уметь
делать апдейт
увеличивающий
и уменьшающий тоже
апдейт у нас увеличивающий
потому что напоминаю апдейт у нас
напоминаю что
лейбл от R
присваивается
X with лейбл от V
поэтому как бы да
мы только максимум равно делаем
то есть заменить на рандомное
не получится
это смешивание к дереву
только что созданному
мы нельзя сказать
что апдейтов вообще нет
а есть только создание
новой вершины и подвешивания
потому что количество апдейтов
в симпатике в другом смысле
тогда у вас вершин будет не N
а M
если у вас M все равно порядка N
то можно и так сделать
а симпатика будет чуть-чуть другая
очень сильная
если N равно M
что самое страшное
у вас тут плодориф будет
да
ну вот
а мы еще и альфа хотим
поэтому
смотрите
шоу у нас будет в реальности
виртуальные дерева
мы сейчас откажемся
даже от такой аксемы
что у нас это все хранится в едином дереве
смотрите
в реальности
вот это все
будет храниться вот так
это вот корень
так вот в реальности
у нас будет несколько деревьев
все эти вершины
из одного дерева
так сказать
в этом виртуальном дереве
будут храниться в нескольких деревьях
желательно гарантированно сбалансировано
так
да
гарантируется естественно
что эвалы в этих деревьях
от каждой вершины будут совпадать с правильными
но при этом важно
еще следующее
эти деревья мы будем хранить вот в такой цепочке
обратите внимание
эта цепочка не является
указанием на то что это
чей-то предок
но при этом значит
эти вершины это корень будет
мы его будем называть R0
R1, R2 и так далее
Rk
и при этом
мы про эти корни будем гарантировать
что
лейбл
от R0
меньше либо равно лейбл
от R1
меньше либо равно
лейбл
не можем строгие знаки
не можем
потому что мало ли вдруг у нас равные элементы найдутся
у нас может быть так
что все лейблы
все вершины равны
теоретически можно
нет
надо признать в принципе
как мы сейчас увидим можно гарантировать
что они с равными не заморачиваемся
теперь заметим следующее
мы можем заметить
что если бы мы объявили
что у этого корня родитель предыдущей корень
то на ответ бы это не повлияло
потому что
вот эти все вершины все равно меньше
но это не важно
мы все равно тем не менее подчеркиваем
это я поэтому и пунктиркой нарисовал
что в реальных деревьях
к реальным виртуальным деревьям
что мы тут храним это отношение не имеет
то есть это корни у них в виртуальном дереве родителя нет
да
а где же он содержится
кто содержится
у нас структура данных
внутри себя
что у нас все вершины содержатся
в наборе деревьев
у этих деревьев есть корни
эти корни мы храним в таком списке
а теперь смотрите
что это нам дает
ну во первых начнем с простого
эвал делаем как обычно
поддерживаем вариант
что эвал правильный
причем не выходя из дерева
понимаете да
уровень чуть повыше
как сделать
как сделать апдейт
как сделать баг с равно
ну идея простая
по лейблам
и допустим они там 9,7,5,3,1
и нам неожиданно пришел апдейт
что очень важно
у этого дерева с минимальным лейблом
это корни
это тоже важно
корни реального дерева
и нам пришел апдейт R
и
допустим 6
тогда смотрите какая идея
чем нам сейчас будет приятен максимум
потому что заметим что что поменялось теперь
идея
поменялась следующая
что мы ко всем
у всех эвалов должны брать теперь максимум
из того эвала что был раньше
и 6
но теперь заметим маленькую
приятную вещь
для вершин из этих под деревьев
ничего не поменялось
потому что там у них уже точно
были больше
для этих могло поменяться
нет
никаких свойств куч нет
мы гарантируем только одно
что в корнях
они отсортированы
а во всем остальном
никаких гарантий нет
кто угодно там будет брать больше
меньше любого рода
главное что эвалы
совпадают
и более того
с этими вершинами что то поменяется
я утверждаю
что с точки зрения адекватности
эвала
адекватности эвала
мы теперь можем заменить
все вот эти
вершины на 6
я утверждаю что если мы сделаем
вот такую замену
теперь поменяется
причем так как нам надо
эвалы в этих деревьях
поменялись на максимум
из того что было раньше
в какой вершине сделали максимум
6
во всех корнях у которых
в реальном дереве
в реальном дереве
в корне да
корень всегда соответствует
корень всегда соответствует
мы должны в них теперь
из деревьев играть
сейчас
чтобы как-то этим точку
да вот правильно
с точки зрения того что
эвалы были правильные
то что я сделал этого достаточно
а вот с точки зрения этим точке
напряг
потому что мы это по факту делаем
из этих деревьев
а еще мы видимо должны хранить себя
в обратном порядке
чтобы мы из корня как раз понимали
на самом деле да
в принципе тальян даже так и предлагает
у каждого корня хранить так называемый чайлд
в чем чайлд это вот
но
можно чайлд хранить
можно вектор хранить
но действительно
нам не очень хочется бегать
по этим всем корням
если я возьму два дерева с одинаковыми корнями
с корнями
с одинаковыми корнями
и подвешу одно к другому
то тоже ничего не поменяется
правда
вот
мне плевать тут есть
где тут больше шестерки элемента
где тут меньше
главное если вы повесьте шестерки
шестерки любую больше
то ничего не поменяется
поэтому для того чтобы себе
изнацию
мы сделаем следующее
мы теперь вот эти деревья объединим в одном
по я думаю уже интуитивно понятному принципу
берем вот эти два дерева
и вешаем одно из векторов к другому
какое? ну естественно меньше и к большему
то есть тут вешаем меньше и к большему
потом у результата тоже
объединяем с этим вешаем меньше и к большему
и так далее
а верно что когда мы их объединили
если посмотреть на начальное дерево Т
там это тоже будет связанная компонента
ну с корнем
сейчас чего там будет
как мы получили вот эти нижние деревья
как мы их получили
в каком процессе у нас поединились
вообще деревья на
мультирных ребрах
на линках
на линках
да мы их до линков
пока еще не дошли
хотя на самом деле ввергнуты движения
заметим что в результате этих апдейтов
конечно не будет вверх
что корень самого верхнего элемента
будет совпадать с реальным корнем
нам это не особо важно
в общем то нам это не особо важно
потому что по факту
то есть мы уже поняли что корень нам не особо важен
когда нам просто приходит апдейт
значит просто у всех эвалов
надо сделать максимум равно и мы это сделаем
корень все таки должен быть в корневом дереве
все таки
я утверждаю что будет вверх
на следующее утверждение
корень все равно
может быть даже не корнем
этого первого дерева
но где-то в нем точно будет
и более того эвалок его будет ему равен
вот
потому что
это следует просто из общего ныря
вот
так что здесь разобрались
здесь мы вроде добились того
что все новые
рёбра которые появляются тут в подвешиваниях
они хорошие
да
что такое хорошее ребро
назовем ребро хорошим если при движении по нему
сайс увеличивается хотя бы в два раза
вот так вот
то есть давайте можем начать
определение
ребро хорошее
через минус 3
понял
сейчас мы сейчас оцениваем симпатику
и что мы делаем
ребро parent от v
я пока пробую
parent от v хорошее
я понятно сейчас
на чем мы сейчас останавливаемся
и что будем делать в прошлый раз
что будем делать в прошлый раз
да если
оказалось что
с z от v меньше
если мы завтра придем
и на автомате тут начнем
если мы завтра
то большие проблемы
ну мало ли
если мы идем вчера
если вчера
ну мало ли
профессор мог перепутать эпохи и прийти на занятия в римской
всякое бывает
будет такое определение
на самом деле
на будущее будет такое
ребро хорошее
ребро v parent от v
имеется в виду
именно вот такое
убеждение тут такое
что если все ребра хорошие
то все деревья
сбалансируют
и тогда это получается
правда к сожалению
линк у нас будет устроен так что все ребра хорошие
мы обещаем
но у нас здесь более
чуть более слабо устроено
ребро хорошее
если у тебя при переходе к родителю
происходит удвоение
у дедушки
ребро называется среденьким
метеоком
средничковое
ребро средничковое
если к родителю еще не удвоение
а у дедушки удвоение
тогда оказывается что дерево тоже сбалансировано
и там правда вот этот констант
равно корень из двух
там достаточно легко будет убедиться
и тогда вот оказывается
что мы ухитримся сделать линк так
чтобы
ребра были ну если не хорошими
то уж средничковыми точно
метеок
там это будет
весьма забавно
так что
с этого увидим в следующий раз
