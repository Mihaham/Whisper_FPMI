Коллег, один из студентов, я бы хотел вам его задать.
Я предлагаю это даже на запись уже включить, все, скринкаст
запись экрана тоже пошла, 3-2 раз, 1-2-3, потому что вопрос
достаточно актуальный.
А именно, вот есть у вас лабораторная работа, там как раз есть
задачка применить PCA, куда-то все спроецировать, и тут
скорее вопрос не про лабу, а про PCA.
Если у вас нет главных компонентов, применяем
к самой выборке, к самому датсету.
Внимание, вопрос.
Вот мы взяли с вами PCA, взяли датсет, и выбрали
количество главных компонентов, равное количеству признаков
в нашем датсете.
Условно у нас была 10-мерная выборка, 10 признаков, мы
взяли 10 главных компонентов, применили, PCA соответственно
выучили все главные компоненты, на них отобразились.
Получили ли мы тождественное преобразование или нет?
Нет.
Кто за да, кто за нет, подумайте, пожалуйста.
Вопрос, есть ли метод главных компонентов, в качестве
главных компонентов используют столько же главных компонентов,
сколько у нас координатных осей в байсе пространства?
Получим ли мы тождественное преобразование или нет?
Ну вот, коллеги с правой части для меня зала считают,
что нет.
Коллеги с левой части зала.
Ну да, домножаем, вопрос, эта матричка будет единична
или нет?
Хороший вопрос.
Ну давайте, кто за то, что да, оно тождественное?
Даже те, кто спрашивали, говорят, что уже нет.
Кто за то, что нет?
Большая часть аудитории воздержал, я понял.
Ну хорошо, давайте те, кто за то, что нет, дадут какое-нибудь
обоснование.
Ну пожалуйста, вот вы говорили в начале.
Ага, классно, пример с овальчиком, работает.
Если вы эллипс нарисуете, у вас первая главная компонента
будет направлена вдоль первой главной полуаси.
Вообще не обязательно, что она совпадает с осью
координат.
Теперь как это обосновать в общем случае?
У вас главные компоненты – это направление наибольшей
дисперсии по убыванию, если вы их отсортируете.
Соответственно, у вас направление наибольшей дисперсии вовсе
не обязательно координатной оси вашего пространства,
тем более в том же порядке.
Поэтому, конечно же, в общем случае PCA все равно меняет
ваше пространство признаковое.
По сути, вы его поворачиваете.
Так что, если вы примените к выборке PCA и сохраните
количество компонентов, равным количеству координат
осей вашей выборки, вы просто-напросто в другой
базе спирейете в том же пространстве.
Вы не потеряете ни йода информации, у вас все останется
на месте, но тем не менее база у вас будет другой.
Данный вопрос понятен?
Супер.
Хорошо.
Еще какие-то вопросы по предыдущим занятиям есть?
Мало ли там что-то еще в голове сло, мы можем с вами их
обсудить вначале.
Три, два, один, ну ладно, тогда предлагаю продолжать.
И сегодня мы с вами поговорим о градиентном бустинге,
о ужас, о той технике, которая немножко, скажем так, затмила
нейронные сети в начале нулевых, в 2001 году был представлен
GBM, Grading Boosting Machine, и за счет этого в том числе нейронные
сети на 10 лет ушли в подполье и сидели там крайне тихо
развивались.
Собственно, градиентный бустинг это на данный момент
наверное некоторая максимально высокая точка развития
классических моделей, в каком смысле, он все еще актуален,
все еще широко применим, все еще крайне любим и
не сдает позиции нейронным сетям в том смысле, в смысле
подходу, где мы используем какие-то дифференцируемые
преобразования, каскадом их выстраиваем и так далее.
То, что нейронные сети и линии на модели суть примерно
одно и то же, можем их отнести примерно в одно семейство.
Отдельно могут стоять метрические алгоритмы, тот же самый
KNN и так далее, отдельно может стоять дерево и их
ансамбли.
Сегодня мы с вами поговорим про ансамбли деревьев, про
градиентный бустинг, не обязательно на самом деле
деревьев, но исторически он используется в основном
на неглубоких деревьях, но опять же это исторически
сложилось, его можно и с другими моделями использовать.
И сегодня у нас в меню 4 основных шага.
Первое, мы с вами постараемся интуитивно понять, что такое
бустинг и как он вообще работает.
Второе, мы с вами попытаемся математически объяснить,
что происходит и как мы можем градиентные методы
использовать вроде как деревьями, которые недеференцируемы.
Ну а дальше поговорим еще чуть-чуть про другие техники
ансамблирования, будь то стекинг, блендинг и про
что-нибудь еще.
Вопросы сегодня приветствуются, в какой-то момент придется
чуть-чуть расширить сознание и понять, что такое градиентный
спуск в пространстве моделей, если так грубо
говорить.
Если у вас был уже функкан, то вам, наверное, будет
чуть проще, если у вас его не было, вам все равно
будет нормально.
Функкан нам сильно не понадобится, но понимать, что у нас это
выражение в разных местах работает полезно.
Но перед этим давайте коротенько вспомним, что было на
прошлом занятии, конкретно про random forest поговорим,
про случайный лес и про ансамблирование деревьев
в лоб.
Вот у вас есть куча деревьев, вы взяли их, усреднили.
Что можно сказать первое?
Во-первых, все деревья были построены независимо
друг от друга.
Правильно?
Вы можете одно строить на одной машине, другое
на другой, на разных датсетах, на разных признаках, подможествах.
Они все независимы.
Но тут, если вспомнить опять же, не знаю, там, электричество,
электродинамика, то же самое, то у нас есть последовательная
сеть, какие-то вот элементы последовательные и параллельные.
Вот здесь мы явно все строим параллельно, поэтому оно
независимо друг от друга.
Можете сразу напроситься вопросом, а что если строить
последовательно?
Это мы как раз к бусинку и подойдем.
Во-вторых, какие основные свойства у Рэндом Фореста
и ему же подобных бэггинг-моделей, но Рэндом Форест, наверное,
как некоторая высшая ступень развития этого подхода.
Давайте еще раз повторим.
Во-первых, деревья сами по себе хорошо работают
с пропусками раз и со скоррелированными признаками два.
Рэндом Форест это все у них перенимает, потому
что скоррелированные признаки абсолютно по барабану мы
их раздельно рассматриваем.
Пропуски в данных.
Если есть пропуск, то мы используем оба поддерева,
потом усредняем ответ в зависимости от мощности
левого и правого поддерева в смысле объема выборки,
который туда и сюда пошел на этапе обучения.
И в-третьих, мы можем использовать out-of-back оценку для того,
чтобы получать оценку на не увиденных ранее данных.
Короче, валитационная выборка бесплатна, нам не нужно
делить наши данные на две части.
Тогда мы получаем с вами оценку сверху на ошибку
модели, потому что если мы работаем out-of-back, у нас
лишь часть ансамбля работает.
Вот вы здесь можете видеть, что мы все модели, у которых
данный объект не попал в обучающую выборку используемую.
Соответственно, размер ансамбля меньше, эффективность
ранним фореста меньше, поэтому качество тоже ниже.
Ошибка выше.
Ну и также я говорил коротко в конце занятия, что мы с
вами можем использовать другие версии вот этого
самого случайного леса.
Extremely randomized trees, там мы вообще доводим до абсурда
случайность, если у нас краски сильно скоррелированы
и множество.
Или Isolation forest, Isolation forest — это техника поиска аномалий,
как я уже говорил.
Повторить про нее еще раз, или все уже все помнят
и движемся дальше.
Повторить.
Ну хорошо, давайте тогда еще раз, тогда это было в
конце занятия.
Еще раз формулируем.
Что такое вот аномалия или же выброс с точки зрения
именно признаков описания, не будем пока смотреть
на таргеты вообще.
Вот у вас есть множество точек, какие-то из них какие-то
аномальные, какие-то нестандартные.
Вы можете какие-то свойства их описать самостоятельно,
не глядя на выборку.
Ну кто-нибудь, давайте, не смейте.
Легко от других точек, классно, что-нибудь еще?
Легко отделить.
Хорошо.
Ну по сути, если мы с вами нарисуем какое-то наше
множество, мы с вами краски заметим, что у нас наши данные
могут образовывать какую-то там достаточно плотную
группу, причем она вообще не обязательно какая-то
правильная условно, у нас может быть просто какое-то
облако точек круглое, а может быть какая-нибудь
непонятной формы, вот бука ФКС, и внутри у него у нас
накиданы точки.
И, допустим, вот эта точка, она в среднем-то не так
уж далеко до всех, но она будет выбраться от того,
что у нас плотность как-то вот таким образом распределена,
а здесь у нас краски низкая плотность объектов, а туда
кто-то попал.
Вот все.
Соответственно выборку мы можем, точнее не выборку,
а выбросами или аномалиями мы можем называть те точки,
которые визуально выбиваются из вот этого нашего общего
распределения, из генералит с вакуумности, откуда все
пришло.
Грубо говоря, если вы нарисуете многомерную функцию плотности,
то они краски будут торчать там, где у вас плотность
вашего распределения очень низкая.
Ну, с простейшим случаем для гауссовского распределения,
например, слева-справа, вот там, не знаю, за двумя
с половиной сигмами, можете считать, что это у вас какие-то
аномалии, так обычно и поступают в статистике.
Типа, если у нас там три сигма, это вот почти, наверное,
все хорошо.
Там 99,7 нам уже достаточно, в принципе, из 100.
Так вот, isolation forest работает ровно на этом принципе.
Давайте попытаемся тогда отделить наши объекты от
всего остального и попробуем это сделать наименьшим
числом разделений.
Тогда мы можем это с вами делать каким образом?
Ну, вот чтобы эту точку отделить, можем там 1, 2, 3, 4, все, условно
как-то так.
Но при этом, если вы попытаетесь отделить ее с самого начала,
вас, наверное, вызовет какие-то проблемы, гораздо
проще будет выделить вот такую точку, ее вообще
там можно одним ихом отделить и так далее.
А те точки, которые сидят здесь внутри, их будет отделять
гораздо сложнее, потому что их нужно вообще прям
очень точно от всех остальных отводить и так далее.
Понятная идея, правильно?
То есть, чем меньше точка похожа на другие, тем меньше
нам в среднем нужно шагов, чтобы ее откинуть от остальных.
Плюс там точно также используется идея того, что мы используем
случайно признаками подможества и какие-то там буддстрапированные
выборки используем и так далее, чтобы деревья были
не похожи.
Соответственно, тогда мы имеем для каждой точки,
мы строим дерево, например, до какой-то глубины, для
каждой точки мы имеем глубину, на которую мы ее выделили
в каждом дереве, или что мы ее вообще не выделили
отдельно.
И тогда вот скор для каждой точки, это что?
Это средняя глубина, на которой она была отделена.
Тогда у вас получится, если отранжировать точки вот
по этой средней глубине, получится кто-то сидит слева,
все остальные где-то там справа или вообще делены
не были.
А те, кто сидят слева, мы говорим, ну хорошо, это
вроде как аномалия.
Понятное дело, это тоже не всегда хорошо подходит
и так далее.
Ну представь себе, я не знаю, там завернутую, вот представь
себе, что у вас все точки лежат на эдаком многообразии,
вот у вас есть двумерная плоскость, там все точки,
потом вы взяли и ее свернули в рулу, вот коврик для йоги
мы так сворачиваем.
Теперь это все в сверхмерном пространстве.
И теперь там все точки, по сути, лежат вот на этой
закрученной поверхности, а некоторые между слоями
лежат.
В точке зрения расстояния до стальных расстояние
будет маленькое.
В точке зрения отделения тем же самым изволоченным
форстом проблем будет много.
Тем не менее, это тоже точки являются аномалиями, они
как раз не лежат на вот этой общей гиперповерхности.
Это нормально, этот метод не универсальный и он не
всегда подходит.
Просто чтобы вы понимали, это некая церебряная пуля,
что вот мы ее запустили и все работает.
Но с этим вот сложным многообразием вообще бывают проблемы.
Тут вопросы есть?
Три, два, один.
Хорошо.
Ну и в целом, если у вас есть какое-то желание работать
с данными, я надеюсь, у вас оно есть, раз вы ходите
даже очень на лекции, то изволоченный, ой, изволоченный,
random forest это классный такой подход, который можно в
копилку себе положить и всегда его использовать.
Одно маленькое но.
Пожалуйста, будьте осторожны, если вы пытаетесь его использовать
а, с данными, которые упорядочены во времени, потому что вам
нужно все-таки четко понимать, что у вас валидация работает
как.
Харехно с точки зрения течения времени, потому
что вот эта ваша аутов бэк оценка может казаться
так, что вы оцениваете, по сути, на прошлых точках,
а лес обучался на будущем, если у вас точки упорядочены
во времени.
Это не очень хорошо, потому что у вас распределение
х новый, у новый при условии х, у предыдущего.
Если вы пытаетесь построить наоборот х, у предыдущий
при условии новых, вы по сути что-то другое делаете,
вы нарушаете ход событий и ваша модель учится чему-то
не тому.
Поэтому, пожалуйста, всегда, когда данные упорядочены,
будьте очень осторожны с этими всеми случайными
подвыбреками и так далее.
Тут вопрос есть?
Все понятно, все просто, едем дальше, правильно?
Или ничего не понятно, ничего не просто спасите, помогите.
Вы про изволейшн форс сейчас или про кого?
Вот про эту штуку.
Сейчас, я вопрос не понял, к сожалению.
Не, не, я говорил, что изволейшн форс работает не всегда,
он все равно смотрит на то, что у вас точка находится
как-то подаль от всех остальных.
Ну, условно доведите вот этот пример до абсурда,
заверните эту спираль очень сильно, у вас все лежит
на спирали.
А какие-то точки лежат не на спирали, а между слоев
спирали.
В точке зрения какой-то закономерности, они выбиваются
из этой закономерности.
В точке зрения расстояний, они все равно рядом со всеми.
Поэтому этот мет просто не сможет их отделить.
Это нормально, он не рассчитан на все, он в среднем работает
неплохо.
Половили?
Так, больше вопросов нет, едем дальше.
Ребят, вы какие-то скучающие, вы меня пугаете, у вас уже
все, подкрадывается сессия, в середину семестра все
сложно?
Или вам просто скучно?
Снег не выпал, рано ботать, а чего вы тогда это делаете?
Хорошо, ладно.
Ну и давайте тогда чуть-чуть поднимем градус настроения
в аудитории.
Мы с вами чуть-чуть говорили про bias-variance, я решил его
вынести на отдельный доп-семинар, чтобы мы с вами могли более
развернуто поговорить.
Да, кстати, на всякий случай онлайн-семинары идут по
средам и субботам, все, туда можно ходить, это особенно
всем тем, кто в онлайне нас смотрит, приходите, подключайтесь,
все ссылки есть в чате, каждый раз они публикуют
заранее.
Ну, давайте по одному, там будет то же самое, но с маленькими
оговорками в каком-то смысле.
Материал опорный, то есть ноутбук и тема, они те же самые,
но во-первых, там учитывается, что у вас уже есть запись
этого семинара и вы можете его посмотреть, то есть там
как правило разбираются больше вопросы, которые
идут уже от аудитории, потому что они пришли уже после
лекции, возможно, люди что-то смотрели, обдумали и так
далее.
Во-вторых, все равно каждый преподаватель чуть по-своему
подает материал, например, Валерий, он больше расписывает
все руками на планшете, потому что у него есть такая
возможность, потому что у него рядом все книжки,
у него рядом планшет, у него есть время это дело,
круговоря, заранее вопросы, видите, и так далее.
Альбина, я думаю, наоборот, будет делать это все попроще
и с красивым визуализажкой.
То есть я больше стараюсь захватить теорию и практику,
чтобы держать максимальный баланс между тем и другим.
То есть там, грубо говоря, больше уклон в одну или в
другую сторону.
В принципе, можете посмотреть запись, ей будет лучше.
Да.
Да, мои семинары остаются до конца симметрии.
Ну, с оговоркой, что в какой-то из дней я могу оказаться
в отъезде, и тогда меня кто-то заменит.
Так, хорошо.
Ладно.
И давайте тогда коротенько поговорим про bias variance.
Ладно, давайте про него в конце поговорим, я представлю.
Давайте тогда перейдем к бустингу, цель наша сегодняшняя.
Тобственно, что такое бустинг?
Ну, понятное дело, что бустинг, опять же, от английского
boost, как-то усиливать, улучшать, я думаю, вам знакома библиотека
boost, правильно?
Ну, по крайней мере, те, кто на плюсах писали, и все
они знакомы, те знают, что это такое.
Вот.
Давайте тогда подумаем, как нам перейти от идеи
параллельности, где у нас все независимо, к идее
последовательности наших моделей, чтобы каждое следующее
делало предыдущую лучше.
Тогда у нас получается некоторый каскад моделей, которые
все вместе работают как единое целое.
Прям замечательно.
Но возникает вопрос, а как нам обучать каждую следующую
модель?
То, что в принципе с тем же самым решающим деревом
мы с вами можем сказать, что взяли мы решающее
дерево, мы его можем просто обучать до упора, оно всю
выборку обучающую запомнит, переобучится под нее, ошибок
не будет, исправлять нечем.
Почему нам нужно строить каскад модель?
Также можно заметить, что вот здесь предлагается
самая простая версия, просто линейная комбинация моделей.
Как вы думаете, если у нас в качестве базовых моделей,
вот эти вот, ашитый, аш-1 и так далее, аш-н, будет
линейная регрессия?
Смысл это вообще какой-то имеет?
Не имеет, потому что линейная комбинация линейных отображений
есть линейное отображение.
Все, конец.
А если логистическая регрессия?
И сверчок такой на фоне.
Да, и что?
Зачем?
Ну, если я сюда просто линейные модели засуну, тоже нейросеть
можно обозвать.
Линейное регрессие тоже однослойное нейросеть без нелинейности.
Ладно, хорошо, смотрите, тогда в конце к этому вопросу
вернемся, если коротко, да, логистические регрессии
бусить можно, даже иногда работает.
Хорошо, вот вам выборка.
Вот вам задачка.
Давайте-ка попытаемся ее решить с помощью решающих
деревьев, а точнее, решающих деревьев, доведенных до
иступления, решающих пней, то есть единых ифов.
Каждом модели будет решающий пень.
Она говорит, налево или направо, вверх или вниз.
Больше она ничего делать не умеет.
Как видите, у нас выборка явно не делится ни одним
пнем поровну, правильно?
Давайте попробуем это сделать последовательностью
пней.
Ну вот, первый пень мы с вами обучаем.
Ладно, он все три показал.
Хорошо, первый пень мы с вами обучаем.
Отделили правые две точки и сказали, справа все синие.
Слева тогда логично, что все красно.
Тогда у нас появились синие точки, вот эти три рите,
они специально пожирнее нарисованы, на которых ошибка
выше.
Согласны?
То мы можем сделать.
Мы можем с вами на каждом шаге перевзвешивать наш
обучающий выборку, отдавая больше вес тем объектам,
на которых мы совершили ошибку классификации.
Например, погрессия абсолютно все та же самая.
Давайте показывай классификации.
Теперь у нас соответственно, на этих точках, видите,
они стали поменьше, вес маленький, потому что у нас
ошибка маленькая, а на точках с левой синень instruction
вес большой, потому что они были ошибочно классифицированы.
Теперь мы строим вторую модель.
Бац, теперь все что с левой красное, все, что справа
синее.
Теперь у нас получается, что вот эти точки получили
вес поменьше, эти вес поменьше, потому что они тоже синие,
синие, красный вес побольше, потому что их неправильно классифицировали, правильно?
Строим третью модель. Соответственно, те, кто сверху синие, те, кто снизу красные. Хорошо,
супер. И в итоге у нас получаются вот такие три модели, которые, если с какими-то весами
сложить, возникает вопрос, с какими весами, то у нас получится вот такая нелинейная разделяющая
поверхность. По сути такая ступенчатая. На самом деле, пример абсолютно игрушечный, но в чем суть?
Здесь мы с вами только что увидели, что мы с вами из множества простых моделей, вот у нас три
решающих пня, которые могут построить вам только линейную разделяющую поверхность, да более того,
она должна быть параллельна оси координатной какой-то. Мы из трех моделей, которые очень простые,
получили гораздо более сложную модель. То есть три простых модели объединились в одну более сильную.
Логично? Ро-1, Ро-2, Ро-3 это ровно те веса, с которыми мы их объединяем. Откуда их брать,
мы сейчас тоже с вами поговорим. Ну мы с вами эти классификаторы, вот у нас есть 1, 2, 3, соответственно.
Чего? Ну у вас каждый классификатор предсказывает какую-то чиселку, например, вероятность или там,
в общем случае, логит. Вы строите линейную комбинацию вашей модели. Линейная комбинация бывает
взвешенной. Вот это веса, с которым вы их добавляете. То есть мы с вами можем из трех получить более
сложную модель, но на самом деле гораздо больше, чем из трех. Вы можете 25 штук построить, но тут
3 достаточно. И давайте теперь вернемся вот к этой вот красивой картинке. Вы ее видели на третьей
лекции, на четвертой лекции. Что у нас здесь нарисовано? У нас здесь нарисованы все вот эти наши
верхние оценки на истинную, в кавычках, функция потерь, на ошибку классификации. И тут у нас с вами
сидела еще экспоненциальная функция потери. Вот она. Давайте попробуем ей заодно и воспользоваться.
Когда мы на самом деле переизобретем алгоритм, который был предложен в 97, что ли, а допустим
назывался или 99, и сделаем что? Давайте скажем, что у нас функция потерь с вами экспоненциальна.
Е в степени минус маржина. Логично, тогда она у нас справа убывает, нормально слева она растет
экспоненциально. Вон она. То есть чем глубже объект оказывается вне своего класса, тем больше у нас
ошибка, причем растет экспоненциально. Сразу можно заметить, что так себе результат, экспоненциальный
рост вообще не очень хорошее дело. Примерно везде. Все может сломаться, взорваться,
вычислительная точность конечная и так далее. Мы сейчас по сути придумаем. Смотрите, мы с вами
выбрали пока что простую функцию потерь экспоненциальную. Почему? Сейчас увидите. И для нее как раз-таки попробуем
вот это перевзвешивание, переизобрести. А потом, в общем случае, уже просто по стопам Фридмана
пройдем, которые как раз-таки... Фридман же. Я надеюсь, Фридман. Я в начале лекции говорил имя,
сейчас я уже запутался. Просто есть еще классный автор, в MIT ведет лекции, на ютубе у него прикольный
подкаст Lex Friedman. Сын, собственно, выпускника физтеха, если мне не изменяет память. И у него классный
подкаст. По-моему, все-таки тоже Фридман. Давайте скажем, что у нас с вами функция потерь экспоненциальная,
то есть E в степени минус маржин. Хорошо, тогда у нас есть с вами над этом шаге наш алгоритм. Это
ансамбль из предыдущих первого по Т-большого алгоритма. Вот он. И вот наша функция потерь L от Y
и предсказание F с крышкой от T. Это что? Экспоненты минус Y на F с крышкой от T. Согласны? Пока просто
маржин написали. Супер. То есть мы можем это расписать как экспонента минус Y на сумму вот этих
штук. А что мы с вами знаем про экспоненту от суммы? Логично, что если у нас в степени экспонента
стоит сумма, мы это можем разделить на произведение экспонентов. Логично. Работаем. И мы отсюда с вами
можем совершенно спокойно взять и вытащить последний элемент. Давайте скажем, что мы сейчас находимся
над этом шаге, и у нас есть все модели, кроме последней, обученные. То есть у нас уже есть
с первой по T-большой M1 модели, которую мы обучили, они отлиты в бетоне, их трогать нельзя. И есть
последняя H-T-большая модель, которую мы сейчас должны обучить. Ну, собственно, вот она. И получается,
что на шаге T вот это у нас константа. У нас ничего не меняется. И мы должны минимизировать ровно
вот эту штуку. Потому что все предыдущие модели уже обучены в ансамбле. Ну, замечательно. Но раз это
константа, получается, что у нас для каждого объекта функция потерь приобретает вот такой вид.
Возникает вопрос, зачем нам здесь экспоненциальная функция потерь? Потому что по ней краске очевидно,
что такое взвешивание объекта. Смотрите, вот ваш вес. На каждом шаге ошибка нашего алгоритма,
который был построен до текущего шага, это и есть вес объекта. Если объект был классифицирован
правильно, ошибка у него маленькая, вес маленький. Если ошибка большая, то есть объект был
классифицирован неправильно, мы хотим на нем учиться. Понятно, что происходит? Понятно, зачем здесь
экспонента? Потому что если бы не был экспонент, мы не могли бы вот так факторизоваться и выделить
отдельный член. Ну, назвали это дело Adaboost, от слова адаптивный boosting, adaptive boosting, и вроде как
казалось, что вот классно. Мы придумали, как работать, но у Adaboost была куча проблем, он
переобучался в лед, у него вот эта экспонента мешала вычислительно всем процессам, и далеко
не всегда экспоненциальная функция потерь хорошо подходила. В том числе у нас с вами есть не только
задача классификации, а еще и задача регрессии. Там не очень понятно, как сходу это исправить. Тоже
можно, но тем не менее. Но на самом деле, в 90-х было множество различных подходов. Adaboost,
Brownboost еще был, многие там называли фамилия автора Boost, и так далее. А потом в 2001 году к краске
пришел градиентный boosting, который показал, что все вот это вот многообразие, это на самом деле
частный случай общей истории градиентного boosting. И с ним давайте краски сейчас и попробуем
разобраться. Во-первых, я сейчас сразу вас немножко попрошу, наверное, напрячь внимание. Сейчас
будет немного больше математики, чем на предыдущих слайдах. И здесь будет, наверное, тема, которая
в первом семестре кажется одной из наиболее сложных, наряду с свмом, который часто вызывает
вопросы. В этом году мы оттуда почти полностью выполнили двойственную задачу, поэтому он стал, кажется,
очень простым. Но, тем не менее, и вместе с, не знаю, кому-то первые лекции сложные, там всякие
правдоподобия вылазят, кому-то всякие нейронки становятся сложными. Короче, давайте сейчас
напряжемся на 10-15 минут, все осознаем. Итак, шаг номер один. Как всегда, постановка задачи. У нас
с вами есть выборка, пара X, Y, причем абсолютно все равно. Регрессия, классификация, что-нибудь еще
там придумайте, неважно. У вас есть множество пар объект-ответ, и у вас есть функция потеря. Мы
хотели бы с вами найти такую модель, которая достигает оптимума на данной выборке, минимума,
нашей функции потерь или что-то же самое, минимума эмпирического риска. Ну, что мы хотим? Мы, на самом
деле, не имеем доступа ко всей генеральной совокупности, ко всему распределению, откуда пришли наши данные.
У нас есть только наша выборка, поэтому вместо нашего вот этого отождания по факту мы с вами
будем брать что? Среднее по всей выборке. То есть мы хотим получить модель, которая в среднем
получает наименьшую ошибку. И пусть у нас с вами не просто какое-то семейство моделей, с которых мы
ищем оптимальную, потому что среди всех, типа среди линейных, метрических, деревьев, их ансамблей,
непараметрических и так далее, сложно найти оптимальную, надо все перебирать. Давайте пусть
будет какая-то параметрическая патрика моделей, параметрическая семейство моделей. Что это значит?
Что модель параметризуется вот этим вектором тета, неважно, что это это вектор параметров
нашей линейной регрессии, множество параметров неровной сети, просто множество плитов вот этих
трешолдов и фичей для дерева или что-нибудь еще. Главное, что мы вот эту запихнули все наши параметры,
которые мы можем каким-то там образом менять, градиентным, неградиентным. Все нормально. Тут понятно?
Вот здесь? Ну, я так скажу, здесь это скорее... Хорошо, здесь, наверное, стоит сказать,
что х приходит из какой-то генерально-совокупности и здесь мы, собственно, по нему мат ожидаем. Короче,
вот это просто выкиньте и все. Выкиньте второй член. Грубо говоря, это эквалентные записи в том
смысле, что у нас с вами х и у приходят из вот этого нашего распределения, откуда пришли данные.
Тут просто мы явно это написали. Тут, наверное, да, не совсем корректно написано. Наверное,
надо поправить. f это краски. Смотрите, мы говорим, у нас вот что такое оптимальная модель. А,
которая достигает минимума мат ожидаемости нашей функции потерь. Далее мы говорим, нам ее надо как-то
найти, поэтому пусть наша f будет из код параметрических 8s. То есть мы можем каким-то
векторам параметров ее определить. Пока у нас ее нет. Пока мы договорились, что...
Ф от... Ну, функция потери от у и от нашего предсказания. Предсказания. Ну, смотрите,
функция потери у вас обычно что считает? У вас есть ваше истинное значение и предсказанное значение.
Средне квадратичная ошибка. Разница квадрат. Квадрат разницы течения.
log loss. p log q. И так далее. То есть это ваша функция потерь. Вы ловили, нет?
Так, коллеги, кто-нибудь вообще записывает за вашим вопросом. Я в тот раз еще на самом деле просил,
если вы вот такие штуки видите. Вот да, здесь надо написать f от x. Так будет лучше. Можете,
пожалуйста, после занятия, если кто-то это логирует, кидать в чат, тогда это будет все
оперативно поправлено. Я, к сожалению, забываю через два с половиной часа, после того, как я это
услышал. Спасибо. Хорошо. Опечатки вроде починили. Еще что-то понятно? Не понятно, точнее.
Вроде все окей. Хорошо. Давайте тогда разобьем нашу вот эту текущую модель краски в том смысле,
что мы знаем, что у нас с вами последовательность наших моделек. Классикаторов, например,
или регрессоров. Последовательность алгоритмов. И мы знаем, что на текущем шаге у нас есть,
допустим, с нулевого по t минус первое уже обученные. Все. Вот мы их обучили каким-то образом,
не важно, но вспомните мат индукции. То есть тут мы сейчас говорим про шаг индукции. У нас уже
что-то обучено, мы хотим еще одну модель дообучить, номер t. То есть нам, по сути, надо для модели на
шаге t, ρt это ее вес и ттt это ее параметры, решить вот такую задачу минимизации. У нас есть y,
истинный, который у нас есть. И, собственно, f от x, причем с крышкой вот все, что было раньше,
плюс ρ на h от x. Вот это вот h от xt это наша новая модель, которую мы хотим добавить.
Чего? Говорите погромче, пожалуйста, я вас плохо слышу отсюда. Еще раз, мы с вами, вот это было,
в общем случае, написано это работать для всего. Теперь мы говорим, давайте будем строить модели
последовательно. Каждое следующее будет улучшать результат предыдущего ансамбля. Значит у нас
модель общая, вот алгоритм, ансамбль, давайте вот так называть, представим в виде суммы наших
моделей. Каждое следующее, это все модели вместе что-то предсказали, получили результат. Согласны?
Вот мы с вами пока что прошли t-1 шаг, и у нас есть вот эта вот f с крышкой, она уже каким-то там
образом обучена. Пока не важно каким, мы, собственно, сейчас с вами на шаге индукции покажем,
как мы ее обучили. Соответственно, на новом шаге нам нужно дообучить еще один кусочек ансамбля,
вот он. Все согласны? Что? Базу индукции сейчас мы до нее дойдем. Пока давайте сначала шаг
индукции опишем, потом базу, окей? Если у нас уже есть с вами обученная часть ансамбля,
как нам к нему добавить еще один элемент? Вот что мы сейчас делаем. Понятно? Хорошо. Тогда мы с
вами можем разбить в нашей функции потерь вот это на две части. Наше текущее предсказание и,
по сути, поправка к тому, что есть. Верно? Все вот это понимают, правильно? Тут, тут, тут, тут.
Нормально. И тогда краски оптимальная, наша t-t модель, вот f с крышкой t, которую мы должны
сюда добавить, это будет ρt на h х θ t. Нам надо вот этот дел найти. Теперь у меня есть вопрос,
как нам найти ρt и tt? Это основной вопрос. И здесь вступают краски в силу гридент и бусик.
Вопрос, вы видите уже на экране. А что если бы мы могли использовать гридентный спуск не в
пространстве как-то там параметров и так далее, а в пространстве моделей? Что это значит? Помните,
вот эту картинку она у нас была на втором занятии, если исключить занятия по повторению линии на
регрессии. Это вот у нас линии уровня или же эквипутенциальной поверхности, тут оптимум,
вот наша начальная инициализация, вот первый гридентный шаг, второй, третий и так далее. Вот
мы куда-то там шагаем. Но мы с вами привыкли это делать, где в пространстве параметры. У нас
есть гиперповерхности, эквипутенциальной поверхности функции потерь, и мы с вами шагаем туда-сюда,
пытаясь понизить значение функции потерь. Верно? А кто сказал, что только в пространстве параметров
мы можем это делать? Мы это можем делать в пространстве модели и вообще где угодно. На самом деле,
я поэтому говорил, что если у вас был функкан, вам будет проще. У вас есть какое-то пространство,
а потом есть какие-то эквапутенциальные поверхности, и в котором, допустим, каждая точка
соответствует какому-то отображению. В модели это и есть отображение. Можем так сделать? Можем.
Остается вопрос, где нам взять вот этот самый гридентный спуск? И вся красота в том, что нам
достаточно с вами одного единственного допущения. Давайте договоримся, что вот эта функция потерь,
которую мы с вами выбрали, дифференцируема. Хорошо? Чего? Да, например. Вот. Каждая модель — это,
по сути, некоторый оператор, сдающий отображение из пространства исходного,
в пространство таргетов. Идет? Все, супер. Поэтому я и говорил, что функкан здесь полезен,
просто чтобы вы понимали, что пространство операторов тоже можно задать, оно тоже существует.
Хоть и не столь привычно. Так вот, единственное ограничение. Пусть вот эта функция потерь
дифференцируема. Договорились? Но, я думаю, слово «градиентный бустинг», вот «градиентный» намекает,
что где-то там будут градиенты. Нам нужны градиенты. Вот. Функция L — дифференцируема. Что мы тогда
можем видеть? Ну, тогда давайте шагом. Вот наша текущая с вами константа, которая предсказывает
на каждом шаге. Она у нас есть. Тогда теперь мы с вами что можем сделать? На каждом объекте из обучающей
выборки у нас с вами есть истинный ответ. Правильно? И у нас с вами есть что? У нас с вами есть какое-то
предсказание нашей текущей модели. Правильно? Ну, давайте я назад лисну. Вот оно. Предсказание
нашей текущей модели для каждого х тоже есть. Она же у нас уже обучена. Плюс у нас есть какое-то
ρ на h х тета. Правильно? Вот давайте вот эту штуку обзаваем просто ритой. В данном случае где-то он у нас. Вот. А, нет. Вот. Df от х тета.
Короче, вот это наша добавка. ρ на h х тета. Это краткий f. Наговорились? Согласитесь, что если вот эта штука
дифференцируема, L от y, f плюс какая-то поправка. Мы же можем с вами по этой поправке продиференцироваться.
Это проф наш свободный член. Вспоминаем производную сложные функции. dl по d вот эта поправка. Это что?
Это dl по d сумма и d сумма по вот этой штуке. Согласились все? Все согласны. И внезапно у нас получается,
что для каждого объекта обучающей выборки, обратите внимание, для каждой пары x и y мы можем
посчитать с вами функцию потерь, предсказание и соответственно значение производной. И получается,
что для каждого объекта из нашей обучающей выборки, для каждой пары у нас есть поправка. Причем
это не просто поправка. Это ровно то значение градиента, которое показывается. Вот настолько надо
здесь поменять предсказание, чтобы стало лучше. Что такое градиент? Направление нескорейшего
возрастания функции. Антиградиентное направление нескорейшего убывания. То есть ровно вот так мы
должны поменять предсказания на этом объекте, над этом шаге нашего ансамбля, чтобы ошибка
в ансамбле стала меньше. Вот это понятно? Сейчас еще раз проговорю. То есть мы с вами посчитали
производные функции потерь по предсказанию нашей новой модели, которую мы пока не обучили. Это
наш свободный член. Вы ловливаетесь? Давайте попробуем это на доске тоже написать. Вот у вас
по сути L. Белый. L у вас зависит от Y этого, потом F от X этого. Вот с крышкой. Это все то, что мы
сейчас обучили. Давайте. Вот. Да. X у нас есть. Вот. Взяли один объект, обучающий выборке. Только
один. Взяли и с ним работаем. Все. Соответственно, у нас вот эта штука есть. Правильно? Давайте
вот эту штуку я просто для удобства обзову кси. Хорошо? Тогда мы говорим с вами DL по DL. От Y и
кси по D кси и опять же. Чему-то равна. Согласны? То есть это вот та величина, это наш градиент.
Это то, как нам надо поменять предсказание, чтобы стало лучше. С этим все согласны? Ну так мы ж с
вами только что говорили, что мы будем наше предсказание менять ровно вот на эту величину.
А вот нам примерно что надо его менять. Все. Мы с вами получили оценку градиента в точке. То есть
насколько нам нужно поменять предсказание на каждом объекте. А теперь фентушами. Мы для каждой
точки из нашей обучающей выборки или, грубо говоря, для каждой точки в признаковом пространстве,
до которой мы знаем значение таргета, мы понимаем, как нужно исправить предсказание. Вот наш градиент
для градиент Loss по предсказанию. То есть надо идти по антиградиенту. Верно? Так давайте на него
и обучаться. Давайте наша новая модель будет апроксимировать не ответ сам по себе, а антиградиент
функции ошибки по предыдущим предсказаниям. То есть наша новая модель, мы когда добавляем новую
модель, мы по сути делаем градиентный шаг пространства модели. У нас была какая-то модель, мы
добавили новую, которая апроксимирует градиент. Уловили, что произошло? Мы не параметры поменяли,
у нас новая модель апроксимирует градиенты, вы ее туда добавляете. Все. Ну смотрите, у вас модель,
вот ваш ансамбль, это последовательность моделей. Вот сумма. На новом шаге вы к ней добавляете еще
одну модель. Вот это все у вас уже обучено, оно уже где-то есть, оно уже прибито гвоздями. Все,
вы его трогать не можете. На N плюс первом шаге вы говорите, хочу найти новую добавку к моему
ансамблю, чтобы стало лучше. Как мне эту добавку обучать? Мы ищем антиградиент ошибки по текущим
предсказаниям ансамбля, понимаем, что надо подменять предсказания ансамбля вот так и на них
учимся. То есть наш новый элемент ансамбля апроксимирует антиградиент предыдущих ошибок
в ансамбле. Наш новый элемент что-то, ну вот смотрите, вот наша H X TETA, вот он ваш. Новая
модель, которая пока не обучена. Еще раз, вот ваш текущий ансамбль, вот вы к нему добавите
РО на H X TETA. РО это learning rate просто, это градиентный шаг, размерово. Все, теперь вы нашли
антиградиент, говорите, вот мой антиградиент. Вот ровно на него вы вашу новую модель, поправку
будете обучать. Кто? H малая, это ваш алгоритм, который вы будете учить. Какой он будет, от вас
абсолютно зависит, может быть, линейная модель, КНН и так далее, по барабану. Нет, H это просто
модель из какого-то семейства. Единственное, что вам нужно, вам нужно уметь H обучать по выборке.
То есть, если у вас есть множество пар, объекты, ответы, вы можете по ним настроить H.
Ну да, то есть H приходит из какого-то параметрического семейства. То есть,
вам не надо ее искать везде. Например, вы сказали, H это решающие деревья. Все, тогда у вас для каждого
объекта есть X, признаковое описание, есть новый R-итый, который оценка антиградиента. На парах
X и R-итый, X и R-итый, вы обучаете ваше новое дерево. Все. Почему именно квадратичное? Смотрите,
потому что, по сути, у вас теперь от задачи регрессии, правильно? И вы сюда можете абсолютно,
на самом деле, ошибку запихнуть. Квадратичные краски потому, что, когда вы минимизируете квадрат,
вы получаете именно оценку среднего, и у вас там под капотом зашито гауссовое распределение. Все.
Бинго. Абсолютно неважно, если у вас функция потерь есть дифференцируемая. Регрессия,
классификация, какой-нибудь там ранжирование придумайте, вам вообще все равно. Есть дифференцированная
функция потерь, вы знаете, как сделать ее лучше. Все. Вам вообще не дифференцируем. Более того,
у вас изначально вот эти вот модели, опять же, в чем вся прелесть границного бустинга, они могут
быть недифференцируемыми. Тот же самый градиентный бустинг надо решающим деревьями. Деревья сами
по себе градиентной оптимизации не поддаются. Каждое дерево это кусочек непостоянной функции,
но вы их можете использовать для опроксимации градиентов в каждой точке пространства. Все. То
есть у вас, получается, в ней дифференцируемые модели сидят как базовые алгоритмы в ансамбле типа
градиентный бустинг. Да. Это не очень логично, а дальше что? Почему это не очень логично? Смотрите,
давайте я это напишу тогда на доске. Смотрите. Не, здесь у нас любые модели абсолютно. То есть
про деревья я просто говорю, что даже дерево и даже какой-нибудь КНН здесь будет работать. Смотрите,
у вас есть текущая модель, вот F от X крышкой. Это ваша текущая модель. Мы говорим, хочу получить
новую модель, которая лучше. Вот это у меня на шаге T. Мы хотим получить F T плюс 1 с крышкой
опять же от X. Тогда у нас здесь есть два допущения. Первое, мы говорим, что F T плюс 1 с крышкой,
это что? Это F T с крышкой от X плюс какое-то РО на какое-то H от X. Ну, с параметрами тета. Вот,
чтобы как там было. Согласны? Это мы пока сказали. И теперь, соответственно, вот это наша первая,
по сути, посылка. И второе, мы говорим, хорошо, как мне, вот у нас есть F, да, и у нас есть L,
функция. Как нам лучше всего исправить ошибку нашего текущего ансамбля? Ну, давайте посчитаем,
D L от Y и F с крышкой T от X по кому? По, ну, даже может T плюс 1, по D краске F с крышкой T плюс 1 от X.
Всё, вы говорите, как мне лучше всего исправить предсказание? Чистая математика, вот она вам.
Вы поняли, как лучше всего исправить предсказание? Ну, теперь добавьте, вот вам ваш,
по сути, шаг исправления предсказаний. То есть, вроде как, логично. Мы хотим оценить,
насколько нам нужно подвинуть предсказания на каждом объекте, чтобы стало лучше.
Чего? Я понял. Ой, хорошо, давайте посчитаем. У вас L считается от Y, да, и от F с крышкой T
плюс РО, H, X и T по. Вот с этим согласны? Давайте я для начала вот это обозначу просто как
кси, просто чтобы было удобнее писать. Тогда D L Y кси по D кси чему равно? Ну, вот чему-то там равно,
мы не знаем, это от функции потери зависит. Хорошо, но мы это дифференцировать умеем.
Это у нас есть. Что мы можем дальше сделать? Это у нас есть галка. Дальше мы с вами можем
посчитать D кси по кому? По D РО. Ой, ну D тета я забежал вперед. По D РО можем продиференцировать?
Чему это будет равно? H X тета. Все, хорошо. Соответственно D кси по D тета. Можем посчитать?
Это соответственно будет D кси по D H на D H по D тета. И тут еще РО будет сидеть. Согласны?
Вот вы градиенты посчитали в лоб. Супер. Да, спасибо. Я его просто потом явно написал.
Мысли зачем? Не, в смысле вот вам все, вот ваши все градиенты, откуда они взялись. Если вот
отсюда получили по сути оценку D тета или просто вам достаточно D кси по D H нарисовать, вы знаете,
чему оно будет равно? У вас будет вот эта штука, умноженная на РО, это ваша D кси по D H. Это то,
как надо настроить H. Все. Чего непонятно, ребята, я не понимаю. Ну да. Не, погодите,
я вам всего лишь показываю, что вот у вас эта штука F от X, правильно? Она в себя включает
константную часть, ваше текущее предсказание, вы по константе не можете продеференцировать,
она константа. Плюс ваше новое предсказание, которое вы краски будете на него обучать.
Так, что я сейчас сделал? По шагам. Первое, у нас есть текущая модель, которая предсказывает
что-то, правильно? Вот. Сейчас она уже, вот эта часть, она обучена. Вот скажите мне, кто-нибудь
может продеференцировать лост по константному предсказанию? Оно константное, вы его поменять
не можете. Есть смысл деференцироваться по константе? Не очень. Хорошо. То есть мы говорим,
хорошо, давайте в целом по предсказаниям, считая, что оно может линейно как-то меняться,
продеференцируемся. Вот я только что это писал. Вот это у вас констант, а это у вас туда краски
входят каким-то образом. По нему продеференцируемся и получаем, что вот это та же производная. Потому
что у нас есть член, который свободный, он обладает крепким свободным, мы его менять можем. Мы на
него краски обучаем кого? Нашу новую модель, которую у нас есть. Есть модель, она делает
предсказания. У вас вы берете предсказания модели как просто какую-то свободную переменную,
кси. Все, вот она. Дл по дкси. Можете посчитать? Можете. В каком месте я вас запутал, ребят?
Хорошо, ладно, это было лишнее. Ну, в плане, сейчас ладо для прав, для понимания скорее вредит. Вы правы.
Я всего лишь хотел показать, что это все дифференцируемая операция, то есть у вас нет
того, что вы дифференцируете по какому-то константному предсказанию. Потому что
дифференцируемся по свободному члену, получаем как надо
изменить текущие предсказания, обучаем новую модель ровно
на то, как надо его изменить.
Логично то, что у нас, скорее всего, модель не сможет
идеально аппроксимировать градиент в каждой точке.
Поэтому мы с вами не получим идеальную поправку, мы
получим какое-то движение в сторону антиградиента
ровно как здесь у нас указано, мы за один шаг не попадем
в оптимум.
В том числе потому, что чтобы попасть даже в случае
выпуклой задачи в оптимум за один шаг, нам нужны методы
второго порядка применять, метод ньютнеравсн и так
далее.
А егебьяны считать и гессианы никто не любит, особенно
на больших водах.
Нет, это все для любой задачи, смотрите.
Именно поэтому я вам уже пятую лекцию говорю, четвертую.
Мы предсказываем вероятность, все, забудьте про метки
класса, это слишком детский сад.
У нас там вектор вероятности, по нему можно совершенно
дифференцировать.
Так, еще вопросы есть?
Да.
Сейчас, смотрите, мы должны аппроксимировать наши
антиградиенты.
Это уже просто какой-то вектор в общем случае в
каком-то пространстве, правильно?
Если мы решаем задачу, где надо аппроксимировать
вектор, это какая задача?
Регрессии.
Регрессию можно решать с помощью минимизации МСЕ,
МАЕ, МАЕ и кучу других там всяких функций ошибок.
Когда мы с вами минимизируем среднюю квадратичную ошибку,
мы на самом деле делаем оценку максимального
правдоподобия, если у нас гауссовский прайор.
Ну, это из статов просто вытекает.
Оценка максимального правдоподобия при предположении,
что у нас нормальное распределение, это называется эквивалент
минимизации среднего квадратичной ошибки.
Вот.
Поэтому я и сказал, что по сути это говорит, что
у нас где-то там гауссовский прайор.
Запихнуть сюда МАЕ, у вас будет лапласовский прайор.
Все.
Так, у вас тоже был вопрос.
Вот, смотрите, что такое РО, давайте вспомним.
РО – это просто наш размер градиентного шага.
Помните, мы с вами когда говорили про градиентный
спуск, у нас там была какая-то тета, это на размер градиента.
Вот.
У нас функция наша с вами, она умная, она аппроксимирует
чисто наш градиент.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Вот.
Да, это believing that.
Да.
Смотрите, вы сначала аппроксимируете антиградиент каким-то
там образом.
А потом вы, уже зная, что идём в этом направлении,
ищете оптимальное значение ρ.
Потому, что ρ – это, грубо говоря, растяжение и сжатия
в этом направлении – куда именно нам шаг consid Ricardo.
Стильно или слабо?
Ну, слушайте, по сравнению с тем, что на каждом шаге
вы какой-то модели обучаете подобрать коэффициент,
У вас же тут, ну, сами посмотрите, линейны, по сути, все линейны.
Производную вы уже считали, чтобы вот это получить,
вам достаточно всего лишь сюда подставить в аналитическое
выражение ваше новое предсказание и подобрать порожки-производную.
Все.
Так что ничего страшного.
Не, ну, второй вариант вы можете, если совсем не
хочется, может каким-то, не знаю, там, линейным поиском
пробежаться и все.
Тоже вариант.
Да?
Да?
Сейчас.
Что значит?
А, смотрите, argmin, что такое?
Ну, min – задача минимизации, argmin – это задача поиска
аргументов, при которых доходится, достается минимум.
То есть, минимум выражения – это его экстремум, argmin
выражение – это значение аргумента, при котором достигается
экстремум.
Ну, экстремум минимум, в смысле argmax при котором
достигается максимум, соответственно.
Все.
Продолжаем.
Сначала вы нашли параметр θ, вы знаете, какая модель
у вас новая на новом шаге.
Все, модель зафиксировали.
Теперь вы говорите, с каким весом мне добавить
ОМАнсамбль.
Все.
Я еще этот вопрос-то не понимаю, почему мы в один
шаг не нашли и роет эту одновременно?
Смотрите, мы с вами с помощью дифференцирования нашли
наш градиент.
Градиент мы потом аппроксимировали каким-то там образом.
Он неточный, это уже оценка градиента, она уже имеет
ошибки.
Теперь мы говорим, с такой оценкой градиента, насколько
нам нужно сместиться.
Все.
Если бы у нас с вами был точный градиент, еще вопрос
бы, наверное, имел смысл.
У нас вообще оценка градиента, нам не понятно, насколько
он вообще хороший.
У вас градиент оценивается трехслойным деревом в глубиной
3.
Он очень грубо оценивается.
Вопрос, насколько нам вообще надо идти.
Может, нам вообще с таким градиентом идти никуда
не надо, потому что слишком паршивая оценка.
Все.
Еще вопросы тут есть?
Ну давайте тогда посмотрим на простой пример.
Сразу дисклеймер.
В случае регрессии и средней квадратической ошибки
это все вырождается вообще в детский сад, это частный
так работает не всегда.
Хорошо?
Поехали.
Давайте посмотрим на среднюю квадратичную ошибку.
У нас тогда лос это квадрат отклонения, правильно?
То есть 2у с крышкой минус у.
У с крышкой наша оценка, у то, что есть.
Правильно?
Ну видим, что по сути пропорционально с кефисентом минус 2у с крышкой
минус у.
Верно?
А?
Пропорционально.
Ну ладно, ну наверное все-таки пропорционально, потому что
я эти слайды составлял.
Вывод про это.
Так, какой символ вам не нравится?
Ребят, ну нам же основная суть какая, мы должны условиться
об обозначениях.
Я хоть горшок на доске нарисовать могу, если вы понимаете,
что это такое, абсолютно неважно.
Что мы здесь с вами видим?
Что у нас градиент по сути пропорционально чему?
Реально отклонению нашего предсказания от истинного
значения, правильно?
То есть мы на каждом шаге с вами будем пытаться
оценить что?
Мы на каждом шаге будем с вами пытаться краски
оценить, насколько мы ошиблись и каждая новая модель будет
предсказывать именно ошибку предыдущей модели в прямом
смысле.
То есть надо было предсказать 25 овец, мы предсказали 21,
надо поправить на 4 овца.
Я понять не имею причем здесь овца, мне только что
в голову пришли.
Извините, я вспомнил мимачик, который я вчера видел.
Да, именно, ну то есть смотрите, это именно предсказание
в каждой точке.
Я просто говорю, почему я это расписывал, потому
что если у вас уже модель фиксирована, все в ней все
параметры фиксированы, вы не можете по константе
продиференцироваться, чтобы вы понимали, что это
значит.
Понятно?
Супер.
То есть в случае с линейной регрессией градиентный
бустинг вырождается в то, простите, с минимализацией
среднего трагичной ошибки, задачей регрессии, градиентный
бустинг вырождается в том, что каждая следующая
модель обучается на ошибке предыдущей буквально.
Все, он просто, вот вы предсказали, 25 надо было, 30, он очень
обучится на 5, но это работает, потому что у вас производная
будет вот такая линейная.
Условно с какой-нибудь средней абсолютной ошибкой это
уже не работает.
То, что производом будет какая?
Сигнум вот этой величины.
Согласны?
Уловили?
Ну и давайте посмотрим на классную демку, которую
в далеком 2016 году запилил мой тогда еще коллега, мы
с ним последние годы точно вообще не общались, но
классный следователь, классный преподаватель приложил
руку к различным задачкам и преподаванию и в шаге
много где.
И в принципе достаточно, смотрите, во-первых, вот
наше решающее дерево, давайте, наверное, на него сначала
посмотрим.
Вот у нас с вами гиперповерхность, видите, да, такая волна.
Вот, что у нас делает решающее дерево, глубины 1, глубины
2, 3, 4, 5, 6, вот такая вот ступенчатая функция у нас получается.
Погодите, пока что одно дерево, сейчас, или что?
Линейная комбинация, да.
Погодите, вот же мы с вами только что это писали, вот
каждое с вами дерево, вы просто добавляете его
находится в гридентном какой-то оптимизации, опять же, маленькую
подзадачу решаем.
Погодите, у вас всегда будет ступенчатая функция при
сумме, а ступенчатая функция не линейная.
Ну, смотрите, давайте я вам это нарисую.
Вот у вас одна модель, вот у вас вторая модель.
Давайте их просуммируем, соответственно, тут у нас
был 0, тут 1, тут опять 0, 1, 1, 0, получается у вас будет
0, потом 1, потом 2, потом опять 1, вот, всё, просуммировал.
Ну, вот этого края, правда, нет.
Уловили?
Короче, вот у нас одно дерево может вот так максимум
сделать, дерево глубиной 6.
Возникает вопрос, а что если у нас с вами гораздо
больше деревьев, но они все глупенькие.
Вот вам гридентный бустинг из ста решающих деревьев.
И давайте посмотрим, вот у нас 100 деревьев глубиной
3.
Ну, согласитесь, кажется, гораздо более плавно описывает
нашу вот эту гиперповерхность по сравнению с одним деревом
глубиной 6, ступенник меньше и так далее.
Можно даже сделать глубину поменьше и видеть, что всё
равно достаточно плавно он его описывает, хотя,
на сами пике не может добраться, почему?
Потому что глубина дерева слишком маленькая, деревьев
маловато.
Если увеличим глубину дерева, даже он, решающие пни, они
из-за того, что каждый раз только по одному признаку
они вторую ось не распознают.
Всё.
Ну, соответственно, вот вам два признака уже есть,
вот он хорошо работает.
3, и того краше 4, ну, практически на таком, скажем так, удалении
не видно вообще гладкой поверхности или куча
ступенек, по факту это куча ступенек.
Ну, соответственно, то дерево глубиной 6, ну, вот
вам замечательная опроксимация той самой вашей гиперповерхности
работает.
Хотя одно дерево глубиной 6, как видите, даже рядом
не лежало, и тут очень такое всё дискретно и не очень
красивое.
Понятно, что происходит, правильно?
Вот.
И ещё раз, собственно, возможно вам тут станет понятно,
вот ваш ансамбль, вот первое дерево, второе дерево и
так далее, и все их мы обучаем.
На четвертом шаге три дерева уже построены, мы говорим,
что это три дерева плюс четвертое, это наша f от x.
Давайте поймём, как нам поправить предсказания
и обучим на этой краске наше четвертое дерево.
Всё?
Вот оно.
Вот, смотрите.
Вот наша целевая функция, и теперь, кстати, да, вернёмся
сразу к краске с вами, к самом начале, помните, я
говорил, что мы только шаг индукции с вами обозначили.
Где взять базу индукции?
Эдман, предложивший градиентный бусинг, предложил очень просто.
Абсолютно неважно, с чего вы начинаете, потому что
каждая следующая модель будет всё равно всё поправлять.
Давайте всегда у нас в начальной модели будет просто среднее
значение таргета.
Констант.
Всё.
Соответственно, вот у вас слева, вот наш таргет.
Видите, просто ноль.
Вот эта гиперпло… вот эта плоскость, это наша текущая
оценка.
Каждая следующая модель будет её исправлять.
Чего?
Среднее в данном случае это интеграл у вас?
Просто среднее значение y, просто выборочное среднее
Взяли, да и всё.
У нас так как нет распределения, у нас интеграла нет, просто
среднее выборочное.
Всё.
Соответственно, вот у нас первое дерево, смотрите.
Мы его построили, с каким-то весом его сюда добавили.
Добавили второе дерево.
Эх, жалко он нас, эти, не строит нам, как его называют,
остатки.
Третье, четвёртое, пятое, шестое… А, не, вот, смотрите,
справа видно остатки.
Посмотрите, слева полностью наш ансамбль, вот он нарисован,
и наша целевая функция.
Справа каждая новая дерева и та гиперповершенность,
которую дерево должно опроксимировать, это ровно те самые наши
градиенты, антиградиенты.
Следите за гиперповершенностью справа.
Пока нормально, одно дерево добавили.
Заметьте, видите, уже тут появились какие-то неоднородности,
вот их видно.
Если идти дальше, видите, у нас уже, где появляются,
тут у нас почти всё хорошо предсказано, поэтому тут
у нас никаких впадин нет, тут почти константа грубая.
Вот эта штука всё ещё торчит, потому что мы здесь, видите,
сильную ошибку имеем, тут градиент большой.
Едем дальше, заметьте, у нас опять гиперповерхность,
которую наше дерево опроксимирует, она уже сильно отличается
от исходной.
Она уже больше на шум какой-то похожа по центру.
6, 7, 8, 9, 10, вот, здесь в конце совсем хорошо видно.
Видите, ошибки у нас большие только в районе пиков.
В районе пиков у нас всё ещё есть градиенты, в остальных
местах у нас скорее какие-то небольшие девиации.
И отсюда мы, собственно, с вами видим, в чём суть
градиентного бусинга.
Если до этого момента мы с вами всегда, когда решали
задачу какую-либо, мы пытались построить всё более-более-более
информативное признаковое описание, мы пытались упростить
признаковое описание, придумать новые признаки, придумать
подходящее ядро, сделать нелинейную нашу модель,
то же самое дерево.
Градиентный бусинг заходит с другой стороны.
У нас на каждом шаге признаки те же самые остаются, мы
каждый раз упрощаем таргет.
По сути мы говорим, вот смотри, мы уже вот здесь
хорошо предсказываем, не обязательно на этом объекте,
вот в этой области хорошо предсказываем, а вот тут
у нас всё плохо.
Поэтому надо фокусировать внимание вот здесь.
Вот вам пример.
Мы в центре уже всё достаточно хорошо предсказываем, а
с краёв у нас всё плохо.
Поэтому следующие модели будут всё больше и больше
фокусироваться на краях, игнорировать центр.
Если говорить с точки зрения дерева, дерево будет что-то
вроде вот такого, иметь столбца, где-то там слева
с краю, а по центру будет просто нулевой констант предсказывать.
Улавливаете?
И почему это важно?
Потому что когда мы с вами говорим про градиентный
бустинг или про линейные модели, про всё это остальное,
это не какие-то два абсолютно разных мира, это просто
две крайности.
Мы можем либо только работать с признаками, либо только
работать с таргетом.
Как вы понимаете, мы можем работать и с тем, и с другим.
И поэтому это занятие у нас предшествует введению
в диплёринг, потому что когда мы доберёмся с вами
до нейронных сетей, мы ровно открываем глаза на то, что
мы на самом деле можем строить с вами некоторое
отображение из пространства объектов, пространства
ответов, и мы менять можем как одно, так и другое,
причём последовательно.
В чём проблема градиентного бустинга, если про него говорить?
В том, что он строго последовательный, и попав на шаг n плюс 1, мы
теряем возможность поменять предыдущий шаг.
Это дерево, если там стоит дерево в качестве базового
алгоритма, в основном деревья.
В общем случае, вы всё равно построили модель, она
фиксирована, вы от неё считаете градиенты и так далее,
вы не имеете права предыдущей модели менять.
Поэтому, когда вы попали на n плюс первый шаг, всё
то, что было до шага n, отлитый в бетоне, больше его не трогайте.
Проблема в том, что это не всегда корректно, и иногда
нам хочется что-то в начале поменять, потому что ошибка
в начале, она очень дорога, она потом всегда нам будет
аукаться.
Нейронные сети ровно краски этим нам потом и помогут,
и мы сможем менять любые шаги, любые преобразования
в любой момент.
Но об этом на следующих рексах.
Просто, чтобы у вас не было вот этого разделения,
что вот бустинги, а тут нейронные сети, нет, одно к другому
очень хорошо подводит.
Более того, бустинг появился после появления нейронных
сетей, просто он менее прожорливый с точки зрения
данных, поэтому он в начале нулевых зашёл гораздо больше.
Нейронные сети к тому моменту показали свои, скажем
проют suburbanassa, свои группы уielaCal и стали переобучаться
в лед на всё что только можно.
Гråдиентный бустинг, казалось что о, Крулёва он не перебучается,
ладно сделали просто побольше ансамбль тоже стал
переобычаться, все опять перегарюнились.
То же самое было с нейронными ст Service, что сначала нейронные
сети были маленькие, а даце тоже накопили большие,
казало-с что нейронные сети и это идеально ониback
работать везде, они не переобучаются.
Просто потому что вычислительные мощности на тот момент были
слишком маленькие, чтобы построить достаточно
большую сеть, чтобы все переобучилось.
Построили большую сеть и всё переоб Laughing.
Бабусинг не переобучается, переобучился. Потом опять неровные сети, в итоге пришли к выводу,
что все переобучается, грузь, печаль, беда, обида, но при этом с этим можно бороться. Хорошо. Вопрос
сейчас есть? Давайте как раз на примере еще вот простеньком, как это называется, регрессии
разберемся. Вот что нам надо. Нам нужны данные, дифференцированная функция потерь. В чем, кстати,
плюс? Вы можете сразу аналитически посчитать производную функции потерь по предсказаниям один
раз и потом сразу эту формулу эксплуатировать. Вас никто не заставляет на каждом шаге градиента
считать, вам не надо. У вас аналитическое значение градиента есть, если у вас функция
дифференцируемая. Вот у нас какая-то семейство алгоритмов, число итераций и initial value. Давайте
просто константой первой модель. У нас будет и все. Например, вот у нас будет вот такая зависимость,
cos, plus epsilon, то есть каким-то шумом. Функция потерь будет MSE. Опять же, в случае MSE все слишком
просто. Мы просто предсказываем ошибку предыдущих моделей. В случае с log loss это уже не работает.
Будьте осторожны. У нас будут решающие деревни глубиной 2, уже не совсем пни. Три итерации в
начале константа. Что мы видим? Слева опять же наш ансамбль полностью, справа наша текущая модель.
На первом шаге у нас только константа и, соответственно, ее ошибки. Это уже ошибки модели,
это наши эти градиенты. На втором шаге вот наша добавочная модель, которая на это была обучена,
вот наш полный ансамбль. Потому что средняя была 0, соответственно, 0 плюс наша модель,
получилось то же самое. Посмотрите на наши остатки на третьем шаге. Вот на что обучается
вторая модель, ну третья, если с 0 считать. Это уже далеко не везде похоже на наш костюм. Вот общий
ансамбль. Вот четвертый шаг. Вот на что похожи наши остатки, на которые учится четвертая модель.
Вот наш полный ансамбль. То есть каждый раз у нас все ближе и ближе к какому-то шуму становится наш
сигнал, таргет, на который пытается обучиться наша модель. Все. Стал понять, что происходит?
Замечательно. Ну и как бы пара графиков. Вот вам пример при увеличении числа деревьев для
бэддинга. Просто видим, что он выходит на переобучение в районе там 500 деревьев. Вот для рэндом
пороста, синий, он гораздо лучше держится. Итоговая ошибка у него ниже, то что деревья менее
скоррелированные, у нас больше эффект снижения вот этой самой дисперсии, но тем не менее он
тоже уходит куда-то на насыщение. Вот наш градентный бустинг. Он выходит на насыщение только в районе
тысячи деревьев, но заметь, итоговая ошибка еще ниже. Почему? Потому что все равно решающий лес,
решающее дерево, оно может переобучиться. Когда мы с вами усредняем их между собой, мы просто-напросто
избавляемся от ошибок остальных деревьев, но тем не менее мы итоговую сложность модели усреднением
повысить не можем. Потому что у нас невзвешенные средние, они просто друг к другу пытаются,
грубо говоря, скраховать везде. В градентном бустинге каждый следующий модель усиливает
предыдущую, поэтому чем глубже в лес, чем больше моделей, тем больше у нас с того его будет качество
по крайней мере на обучающей выборке. Понятное дело, на тестовый в какой-то момент у нас все переобучится и
будет плохо. Но градентный бустинг замечательный, переобучается, будьте осторожны. Его можно
переобучить в лед, и в чем проблема градентного бустинга? Если рано-форос вас кое-как страхует от
переобучения в том плане, что переобучилось одно дерево, не беда, много деревьев, краски, проблемы
с переобучением нивелируются, потому что они усредняют друг друга. С градентным бустингом,
если одно дерево было обычно, ладно, одна модель была обучена, где-то в ходе, все что после нее это
мусор. То, что у вас переобученная модель, повлияет на все оставшиеся граденты, соответственно,
если у вас один элемент ансамбля переобучен, весь ансамбль с этого момента и далее это мусор,
он бесполезен. Поэтому следить за градентным бустингом надо очень аккуратно и там смотреть на
валидацию. А потому что у вас градент станет сильно меньше, у вас ошибок стало сильно меньше на
обучающей выборке. То есть вы уже переподстроились под обучающий выборку, у вас граденты почти все
слопнулись. А следующая модель пытается подстроиться под градент, которых нет. Вот как-то так.
Ну и вот вам пример краски из начала. Вот вам опять две концентрические окружности, очень старые
картинки надо перерисовать. Короче, снаружи красные точки, в центре синие точки. Ну, поверьте
мне на слово, потом можете посмотреть записи и я перерисую, наверное. Синие точки в центре,
красные по кругу. Линейная модель одна не способна отделить, правильно, то что линия разделима и выборка.
Но мы можем вспомнить, что логистическая регрессия это ни разу не линейное отображение,
это сегмойда от линейного отображения. Поэтому их линейная комбинация уже вполне себе может
задавать что-то нелинейное. Вот вам градентный бустинг над логистическими регрессиями.
Замечательно, ограничивает центр. Уловили? Каждая полоса соответствует какой-то логистической
регрессии. То есть каждая из них дает линейную разделяющую поверхность, но все вместе они смогли
отделить центр от всего остального. Да, в идеальном случае мы с вами можем три прямых провести и
треугольником отделить все. Но так, у нас там шум присутствует и так далее, вот за 40 шагов он
хорошо отделился. Хотя мы видим с вами, что за первые там 10, на самом деле он уже примерно
перестал ошибку ронять. Вот, ну что, градентный бустинг вас вызвал страх и ненависть в БХИМе.
Вот здесь. Ну, смотрите, это тестовая ошибка, поэтому то, что она себя ведет таким образом,
абсолютно нормально, потому что обучаемся мы на трейне, а на тесте валидируем. То есть на трейне
она, как правило, падает достаточно равномерно, если считать по всей выборке. Если считать по бачам,
то она себя будет вести вот так, потому что у вас от бача зависит хорошо или плохо, вы там на этом
баче конкретно отработали. Вот, смотрите, тут она, например, сглаженная, во времени, видите,
она в среднем-то падает, достаточно стабильно. Тут сглаживание применено, чтобы мы видели,
что вот эти вот всплески, они на самом деле в среднем, все равно идут вниз. Ну и коротенькое,
наверное, утро. Собственно, рано-пороста у вас работает строго параллельно на уровне деревьев,
поэтому вы его можете хорошо парализовать. И если у вас словно есть 40 потоков, 40 деревьев
можете одновременно построить, будет быстро. Применять тоже можете быстро. Гридентный бусинг,
он не парализуется в лоб, но при этом стоит помнить, что дерево можно тоже строить достаточно
эффективно. Если вы строите, например, гридентный бусинг над деревьями, каждый дерево может строиться,
грубо говоря, на два под дерево поделили, они могут параллельно строиться. Поэтому не стоит думать,
что гридентный бусинг уж совсем медленная штуковина. В современном мире он, конечно,
медленнее, чем рано-пороста, но при этом он тоже достаточно быстро строится и, как правило,
сильно быстрее всяких нейронок. Окей, сложных нейронок. Ну что, тут какие-то вопросы есть?
Ещё раз, я именно и говорил, что если он переобучится, то всё плохо. Именно поэтому в
среднем исторически глубокие деревья не используются, потому что неглубокое дерево
переобучить сложно. Глубокое дерево переобучить легко. Опять же, это в среднем, это не то,
что только так и никак иначе. Скорее так, если вы не понимаете, что делать, лучше использовать
неглубокие деревья с гридентным бусингом и глубоким и с рано-поростым. Если вы понимаете,
что вы делаете, плак вам в руки, барабан на шею. Делать можете что угодно. Просто пока у вас нет
понимания, как бы как в данной задаче отработать тот или иной алгоритм, например, сильно у вас там
шум присутствует или слабый, лучше придерживаться каких-то общепринятых норм. Вот как-то так.
Короче, моя главная цель была на самом деле, чтобы сегодня вы поняли простую вещь, что гридентный
бусинг строит именно на каждом шаге аппроксимацию антигридиента вашей функции потерь по предсказаниям.
По сути, в каждой точке пространства, где есть обучающие значения из пары из обучающей выборки,
вы строите ваш антигридиент и его аппроксимируете. Вот это коровая вещь. Все остальное это всякие
там свистопляски и так далее. Это осознали? Хорошо. Ну, смотрите, у меня на самом деле еще
про тейкинг и блендинг, дополнительные слайдики. Я, наверное, предлагаю что сделать. Продолжаю даже
прямо сейчас сделать перерыв, потому что не самая легкая была штуковина. Где-то 18-40
мы продолжим тогда, то есть 15 минут перерыва. И там мы поговорим сначала на практике про деревья
и про бустинг, а потом я вам еще про то, как стакать это все дело расскажу. Все, лекция over.
